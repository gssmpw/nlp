\documentclass[conference,review]{IEEEtran}
%\documentclass[sigconf,review]{acmart}

\pagestyle{plain}  % Enables page numbers, to be removed in the submitted version 

\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
% \usepackage{calrsfs}
% \usepackage{rsfso}
\usepackage{mathrsfs}

\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Our packages 
\usepackage{tikz-cd}
\usepackage{stmaryrd}
\usepackage{hyperref}
% \usepackage{lmodern}
% \usepackage{latexsym}
% \usepackage{amsmath,amsthm,stmaryrd}
%\usepackage[mathscr]{eucal}
% \usepackage{enumerate}
% \usepackage[makeroom]{cancel}
% \usepackage{ifxetex,ifluatex}
%\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
%  \usepackage[T1]{fontenc}
%  \usepackage[utf8]{inputenc}
\usepackage[all]{xy}


% some commands 
\newcommand{\dua}{\mathord{\hbox{\makebox[0pt][l]{\raise .6mm
                           \hbox{$\uparrow$}}$\uparrow$}}}

\renewcommand{\labelenumi}{(\roman{enumi})}
\newcommand{\remove}[1]{}
\newenvironment{removed}{\remove{}}


\newcommand{\derul}[2]{\frac{\displaystyle{#1}}{\displaystyle{#2}}}
% various symbols 
\newcommand{\lra}{\,\rightarrow \,}
\newcommand{\subtype}{<:}
\newcommand{\meet}{\sqcap}
\newcommand{\consist}{\ \uparrow\ }
\newcommand{\defeq}{\triangleq}

% syntax symbols 
\newcommand{\bfomega}{{\boldsymbol{\omega}}}
\newcommand{\lo}[1]{\operatorname{#1} \,}
\newcommand{\sample}{\lo{sample}}
\newcommand{\score}{\lo{score}}
\newcommand{\inter}[1]{\lo{c_{#1}}}
\newcommand{\ldot}{\, . \,}
\newcommand{\rmin}{\lo{min}}
\newcommand{\gtz}{\lo{(<0)}}
\newcommand{\cplus}{\lo{(+)}}
\newcommand{\cminus}{\lo{(-)}}
\newcommand{\ctimes}{\lo{(\cdot)}}
\newcommand{\cdiv}{\lo{(/)}}
\newcommand{\negation}{\lo{neg}}
\newcommand{\rmax}{\lo{max}}
\newcommand{\dig}{\lo{dig}}
\newcommand{\aff}[2]{\lo{t_{#1,#2}}}
\newcommand{\digi}[2]{\lo{d_{[#1,#2]}}}
\newcommand{\affi}[2]{\lo{t_{[#1,#2]}}}
\newcommand{\mult}{\lo{mult}}
\newcommand{\add}{\lo{add}}
\newcommand{\ave}[1]{\lo{\oplus_{#1}}}
\newcommand{\rexp}{\lo{exp} \,}
\newcommand{\ttt}{\lo{tt}}
\newcommand{\ff}{\lo{f\!f}}
\newcommand{\step}{\lo{s}}
\newcommand{\en}{\mathbf{en}}
\newcommand{\pif}[3]{\lo{pif}_{\iota} \ #1 \ \lo{then} \ #2 \ \lo{else} \ #3}
\newcommand{\ifte}[3]{\lo{if} \ #1 \ \lo{then} \ #2 \ \lo{else} \ #3}
\newcommand{\av}{\lo{av}}
\newcommand{\pr}{\lo{pr}}
\newcommand{\integral}{\lo{int}}
\newcommand{\osup}{\lo{sup}}
\newcommand{\dif}{\lo{D}}
\newcommand{\der}[1]{\frac{d \, #1}{d \, x}}
\newcommand{\St}{\operatorname{St}}
\newcommand{\In}{\operatorname{In}}
\newcommand{\emb}{\operatorname{em}}
\newcommand{\llderiv}{\operatorname{L}}
\newcommand{\cepsilon}{\operatorname{\varepsilon}}
\newcommand{\Comp}{\mathrm{Comp}}

% sets and domains
\newcommand{\nat}{\mathbb{N}}
\newcommand{\reale}{\overline{\realLine}^+}
\newcommand{\interval}{\mathbb{I}}
\newcommand{\realLine}{\mathbb{R}}
\newcommand{\realDom}{\mathbb{IR}}
\newcommand{\Dom}{\mathbb{D}}
\newcommand{\BC}{\textrm{\bf{BC}}}
\newcommand{\D}{\textrm{\bf{D}}}
\newcommand{\BCG}{\textrm{\bf{BC}}_{G}}
\newcommand{\PD}{\textrm{\bf{PER}}}
\newcommand{\RD}{\textrm{\bf{RD}}}
\newcommand{\id}{{\sf id}}
\newcommand{\B}{\textrm{\bf B}}
\newcommand{\Set}{\mathcal{Set}}
\newcommand{\sle}{\sqsubseteq}
% function and denotational semantics
\newcommand{\grouphom}[1]{\overline{#1}}
\newcommand{\sem}[1]{\llbracket{#1} \rrbracket}
\newcommand{\bsem}[1]{\mathcal{B}\sem{#1}}
\newcommand{\esem}[1]{\mathcal{E}\sem{#1}}
\newcommand{\lifted}[1]{(#1)_\bot}

%environments
\usepackage{amsthm}
% \newcommand\qedsymbol{$\blacksquare$}
% \theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]
% \theoremstyle{lemma}
\newtheorem{lemma}[theorem]{Lemma}
% \theoremstyle{corollary}
\newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
% \theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
%\theoremstyle{proposition}
\newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{proof}{Proof}




\begin{document}

\title{A Domain-Theoretic Framework for Conditional Probability and Bayesian Updating in Programming
%\thanks{Identify applicable funding agency here. If none, delete this.}
}


\author{\IEEEauthorblockN{Pietro Di Gianantonio}
\IEEEauthorblockA{% \textit{Dept. of Mathematicic, Informatics and Phisics} \\
\textit{Univesity of Udine}\\
Udine, Italy \\
pietro.digianantonio@uniud.it}
\and
\IEEEauthorblockN{Abbas Edalat}
\IEEEauthorblockA{% \textit{} \\
\textit{Imperial College London}\\
London, UK \\
ae@ic.ac.uk}
}


\maketitle

\begin{abstract}
We present a domain-theoretic framework for probabilistic programming that provides a constructive definition of conditional probability and addresses  computability challenges previously identified in the literature. We introduce a novel approach based on an observable notion of events that enables computability. We examine two methods for computing conditional probabilities—-one using conditional density functions and another using trace sampling with rejection—-and prove they yield consistent results within our framework. We implement these ideas in a simple probabilistic functional language with primitives for sampling and evaluation, providing both operational and denotational semantics and proving their consistency. Our work provides a rigorous foundation for implementing conditional probability in probabilistic programming languages.
\end{abstract}
\section{Introduction}

Probabilistic programming languages (PPLs) have emerged as powerful tools for modelling complex systems involving uncertainty, enabling programmers to express probabilistic models and perform statistical inference using familiar programming constructs. Notable examples include BLOG \cite{Milch2005}, Church \cite{Goodman2008}, Anglican \cite{Wood2014}, and Stan \cite{Carpenter2017}, with applications ranging from artificial intelligence to scientific modelling.

Functional programming features have proven valuable in this context, offering natural abstractions for expressing probabilistic models and compositional reasoning about probabilistic computations. However, providing formal semantics for such languages presents significant challenges, particularly when dealing with continuous probability distributions.

Traditional approaches to denotational semantics for probabilistic languages have encountered the well-known Jung-Tix problem \cite{JungT98}: the difficulty of constructing a Cartesian closed category with probabilistic domain constructors. This has led researchers to explore various alternatives to classical domain theory, such as quasi-Borel spaces \cite{HeunenKSY17} and measurable spaces with random elements \cite{Staton2017}.

An alternative approach is to model probabilistic computations in terms of random variables rather than probability distributions. 
Random variables have been employed in denotational semantics of programming languages in various work \cite{BacciFKMPS18,GoubaultV11,HeunenKSY17,HuotLMS23,Mislove16,Scott14,Vakar2019}. However, defining an appropriate monad structure for random variables has proven challenging. Recently, \cite{DiGianantonio2024} proposed a solution based on domains with partial equivalence relations (PER), a concept used previously in several contexts including in~\cite{AP90,bauer2004equilogical,AL00}.

Another challenge in probabilistic computation is the treatment of conditional probability. The seminal result of Ackerman et al.\cite{ackerman2019} demonstrates that conditional probability is not computable in its classical formulation, even for simple cases involving continuous distributions. This non-computability arises from the fact that conditioning on a Borel subset that is not an open set, though well-defined in classical probability theory, cannot be effectively computed: its membership predicate is not an observable property or semi-decidable predicate in the sense of observational logic~\cite{smyth1983power,abramsky1991domain,vickers1989topology}. This theoretical limitation has profound implications for the design of probabilistic programming languages and their semantics.

In this paper, we extend the framework in~\cite{DiGianantonio2024} in several directions, with a primary focus on addressing the challenges posed by Ackerman et al.

We address these challenges by introducing a constructive notion of events--in which an event and its opposite are disjoint pairs of open sets and thus are observable properties--leading to a computable treatment of conditional probability that avoids the pathological cases identified by Ackerman et al. The domain of disjoint pairs of open sets of a topological space, first used in~\cite{edalat2002foundation} to develop a computable framework for solid modelling and computational geometry, establishes a proper domain of events, which makes conditional probability computable. Furthermore, we show how Bayesian updating can be implemented using weighted sampling through a score operator, necessitating a shift from probability distributions to more general measures.

A distinguishing feature of our work is the comprehensive treatment of continuous distributions combined with constructive real number computation. While previous approaches have typically relied on floating-point approximations, we develop a rigorous framework for exact real number computation in the context of probabilistic programming.
Specifically, we present a functional programming language that integrates three key features: continuous distributions, score-based weighted sampling, and exact real number computation. We provide both denotational and operational semantics, introducing new techniques to handle the interaction between these features. The correspondence between these semantic approaches is established through an adequacy theorem.

The paper is organized as follows: Section II presents the domain theory and measure theory basics. Section III introduces our valuation monad for PER domains. Section IV develops the treatment of conditional probability, addressing the computability issues highlighted by Ackerman et al. Section V presents extended random variables. Section VI deals with Bayesian updating. Section VII describes our probabilistic functional language and its semantics.

% All proofs are presented in Appendix I.

\subsection{Related work}
There exists a large literature on denotational models for probabilistic computation. Many of these works differ substantially from ours in two aspects. First, they do not use random variables and, instead, model probabilistic computation using probability measures~\cite{DanosE11,EhrhardPT18,HeunenKSY17,Vakar2019}, or continuous distributions~\cite{GoubaultJT23,JiaLMZ21}; second, these works do not use Scott domains but instead employ a larger class of dcpo's~\cite{JiaLMZ21,GoubaultJT23}, probabilistic coherence spaces~\cite{EhrhardPT18}, or categories built from measurable spaces~\cite{HeunenKSY17,HuotLMS23,Vakar2019}.  

In the existing literature, there are a limited number of constructions of a probabilistic monad based on random variables. A monad construction quite similar to ours, but not incorporating soft-conditioning, can be found in~\cite{DiGianantonio2024}. In~\cite{Barker16}, random variables are defined as pairs consisting of a domain and a function, but without discussion of monad commutativity. A strong monad of random variables is defined in~\cite{GoubaultV11}, although the construction differs significantly from ours. Domains of random variables with structures similar to our approach are defined in~\cite{Mislove16,Scott14}, but without presenting monad constructions. Random variables are also used to define quasi-Borel spaces by Heunen et al.~\cite{HeunenKSY17}.

The treatment of conditional probability in probabilistic programming has received significant attention. Various approaches to soft conditioning can be found in the literature: Staton~\cite{Staton2017} employs metric spaces, Park et al.~\cite{park2008probabilistic} use sampling functions, and Goubault-Larrecq et al.~\cite{GoubaultJT23} develop a domain-theoretic framework. The relationship between scoring and conditioning has been explored in several works~\cite{Staton2017,Vakar2019}, with different approaches for implementing conditioning in higher-order languages.

\section{Domain-theory and measure-theory basics}
We use standard notions in domain theory, as described in~\cite{abramsky1995domain} and~\cite{gierz2003continuous}. 
A {\em directed complete partial order} (dcpo) $D$ is a partial order in which every (non-empty) directed set $A\subseteq D$ has a lub (least upper bound) or supremum $\sup A$. The {\em way-below relation} $\ll$ in a dcpo $(D,\sqsubseteq)$ is defined by $x\ll y$ if whenever there is a directed subset $A\subseteq D$ with $y\sqsubseteq \sup A$, then there exists $a\in A$ with $x\sqsubseteq a$.  A subset $B\subseteq D$ is a {\em basis} if for all $y\in D$ the set $\{x\in B:x\ll y\}$ is directed with lub $y$. By a {\em domain}, we mean a non-empty dcpo with a countable basis. Domains are also called {\em $\omega$-continuous dcpo's}. In a domain $D$ with basis $B$, we have the interpolation property: the relation $x\ll y$, for $x,y\in D$, implies there exists $z\in B$ with $x\ll z\ll y$. For any $x\in D$, we write $\dua x=\{y\in D: x\ll y\}$, and for any finite subset $A\subset D$, we write $\uparrow\hspace{-.7ex} A=\{x\in D: \exists a\in A.\,a\sqsubseteq x\}$. 

A subset $A\subseteq D$ is {\em bounded} if there exists $d\in D$ such that for all $x\in A$ we have $x\sqsubseteq d$. If any bounded subset of $D$ has a lub then $D$ is called {\em bounded complete}. Thus, a bounded complete domain, also called a {\em Scott domain}, has a bottom element $\bot$, which is the lub of the empty subset. 

We denote the interior and the complement of a subset $S$ of a topological space by $S^\circ$ and ${S}^c$ respectively. The lattice of open sets of a topological space $X$ is denoted by $\mathcal{O}(X)$ For a map $f:X\to Y$, denote the image of any subset $S\subseteq X$ by $f[S]$.

The set of non-empty compact intervals of the real line ordered by reverse inclusion and augmented with the whole real line as bottom is the prototype bounded complete domain for real numbers denoted by $\realDom$, in which $I\ll J$ iff $J \subseteq I^\circ$. It has a basis consisting of all intervals with rational endpoints.  If $I\subseteq \realLine$ is a non-empty real interval, its left and right endpoints are denoted by $I^-$ and $I^+$ respectively; thus if $I$ is compact, $I=[I^-,I^+]$. A {\em dyadic} number is of the form $m/2^n$, for some $m,n\in \nat$.



The Scott topology on a domain $D$ with basis $B$ has sub-basic open sets of the form $\dua b:=\{x\in D:b\ll x\}$ for any $b\in B$. We let $\D$ denote the category of domians with Scott continuous maps, whereas $\BC$ denotes the full sub-category of bounded complete domains. 
%The upper set of an element $x\in D$ is given by $\uparrow x=\{y\in D:x\sqsubseteq y\}$. 

If $X$ is any topological space with some open set $O\subseteq X$ and $d\in D$, then the single-step function $d\chi_O:X\to D$, defined by $d\chi_O(x)=d$ if $x\in O$ and $\bot$ otherwise, is a Scott continuous function. The partial order on $D$ induces, by pointwise extension, a partial order on continuous functions of type $X\to D$ with $f\sqsubseteq g$ if $f(x)\sqsubseteq g(x)$ for all $x\in X$.  For any two bounded complete domains $D$ and $E$, the function space $(D\to E)$ consisting of Scott continuous functions from $D$ to $E$ with the extensional order is a bounded complete domain with a basis consisting of lubs of bounded and finite families of single-step functions. 

If $X$ is a topological space such that its lattice $\mathcal{O}(X)$ of open sets is continuous and $D$ is a bounded complete domain, with $f:X\to D$ a Scott continuous and $d\chi_O:X\to D$ a single-step function, then we have~ \cite[Proposition II-4.20(iv)]{gierz2003continuous}
\begin{equation}\label{way-below}d\chi_O\ll f \iff O\ll_{\mathcal{O}(X)} f^{-1}(\dua d)\end{equation}

\subsection{Computability in domain theory} We adopt the notion of effectively given domains as in~\cite{DiGianantonio2024}, which for Scott domains is equivalent to~\cite{plotkin1981post}. We say a domain $D$ is {\em effectively given} with respect to an enumeration $b:{\mathbb N}\to B$ of the countable basis $B\subseteq D$ if the relation $ b_m\ll b_n$ is decidable. If $D$ has a least element $\bot$, we assume $b_0=\bot$. If $D$ is, additionally, bounded complete, we further assume that the relation $b_m\sqcup b_n=b_p$ is decidable. We say $x\in D$ is {\em computable} if the set $\{n:b_n\ll x\}$ is r.e. The latter is equivalent to the existence of a total recursive function $g:\nat\to \nat$ such that $(b_{g(n)})_{n\in \nat}$ is an increasing sequence with $x=\sup_{n\in\nat}b_{g(n)}$. \remove{A sequence $(x_n)_{n\in \nat}$ is said to be {\em computable} if there exists a total recursive function $h$ such that $x_n=x_{h(n)}$ for $n\in \nat$.} A continuous map $f:D\to E$ of effectively given domains $D$, with basis $\{a_0,a_1,\ldots\}$, and $E$, with basis $\{b_0,b_1\ldots\}$, is {\em computable} if the relation $b_n\ll f(a_m)$ is r.e. 

\subsection{Elements of measure theory}
 Recall, say from~\cite{athreya2006measure}, that a measurable space on a set $X$ is given by a $\sigma$-algebra $S_X$ subsets of $X$, i.e., a non-empty family of subsets of $X$ closed under the operations of taking countable unions, countable intersections and complementation. Elements of $S_X$ are called measurable sets. For a topological space $X$, the collection of all Borel sets on X forms a $\sigma$-algebra, known as the $\sigma$-Borel algebra: it is the smallest $\sigma$-algebra containing all open sets (or, equivalently, all closed sets). A map $f: (X,S_X)\to (Y,S_Y)$ of two measurable spaces is measurable, if $f^{-1}(C) \in S_X$ for any $C\in S_Y$. Any continuous function of topological spaces is measurable with respect to the Borel algebras of the two spaces. 

 Let $\overline{\realLine^+}$ be the set of extended non-negative real numbers (including $+\infty$)  with the usual ordering, equipped with is Scott topology, i.e., for any $a\in \realLine^+$, the set $\{x:a<x\}$ is open. The extended set of non-negative rational numbers $\overline{\mathbb{Q}^+}$ is similarly defined. 

A measure on a measure space $(X,S_X)$ is a map $\nu:S_X\to \reale$ with $\nu(\emptyset)=0$ such that $\nu(\bigcup_{i\in \nat}\nu(E_i))=\sum_{i\in \nat}\nu(E_i)$ for any countable disjoint collection of measurable sets $E_i$ for $i\in \nat$. if $f:(X,S_X)\to (Y,S_Y)$ is a measurable map then it induces a measure $\nu\circ r^{-1}$ on $Y$ called the {\em push-forward measure}.

A {\em probability space} $(\Omega,S_\Omega,\nu)$ is given by a probability measure $\nu$ on a measure space $(\Omega,S_\Omega)$, where $\Omega$ is called the {\em sample space}, $\nu(\Omega)=1$, and measurable sets are called {\em events}. A subset $A\subseteq \Omega$ is a {\em null set} if $A\subseteq B\in S_\Omega$ with $\nu(B)=0$. 

Given the probability space $(\Omega,S_\Omega,\nu)$, a random variable on a measurable space $(Y,S_Y)$ is a measurable map $r: (\Omega,S_\Omega,\nu)\to (Y,S_Y)$. The probability of $r\in C$ for $C\in S_Y$ is given by $\operatorname{Pr}(r\in C)= \nu(r^{-1}(C))$.  Two random variables $r_1$ and $r_2$ are {\em independent} if $\operatorname{Pr}(r_1\in C_1,r_2\in C_2)= \operatorname{Pr}(r_1\in C_1)\operatorname{Pr}(r_2\in C_2)$ for all $C_1,C_2\in S_Y$.





Recall that for any measure $\nu$ on a measurable space $X$, any measurable map $w:X\to \realLine^+$ defines a measure, which we denote by $\nu_w$, with $\nu_w(S)=\int_S w\,d\nu$, for any measurable $S\subset X$. This construction has a converse. Recall that a measure $\nu$ on $X$ is $\sigma$-finite if $X$ is the countable union of measrable sets with finite $\nu$-measure.  Now, suppose $\nu_1$ and $\nu_2$ are $\sigma$-finite measures on $X$ such that $\nu_2$ is absolutely continuous with respect to $\nu_1$, i.e., for any measurable set $S\subset X$, we have: $\nu_1(S)=0$ implies $\nu_2(S)=0$. Then there exists, essentially, a unique measurable function $f:X\to [0,\infty)$, called the Radon-Nikodym derivative of $\nu_2$ with respect to $\nu_1$ and denoted by  $f=\frac{d\nu_2}{d\nu_1}$ such that  $\nu_2(S)=\int_S f\,d\nu_1$. In addition, for any measurable map $g:X\to \realLine$ and measurable set $S\subset X$, we have~\cite{rudin1987real,billingsley2017probability}: 
\begin{equation}\label{rel-density-int}
    \int_S g\,d\nu_2=\int_S g\frac{d\nu_2}{d\nu_1}\,d\nu_1=\int_S g\cdot f\,d\nu_1.\end{equation}

Consider the domain $D\in \Dom$, with countable basis $B_D$,  equipped with the sigma algebra induced by the Scott topology as a measure space.  Then $\mathcal{O}(D)$  has countable basis $B_{\mathcal{O}}$ consisting of opens sets $\dua b$ with $b\in B_D$.  A {\em valuation} is a map $\alpha: \mathcal{O}(D)\to \overline{\realLine^+}$ satisfying (i) $\alpha(\emptyset)=0$, (ii) $\alpha(O_1)\leq \alpha(O_2)$ if $O_1\subset O_2$, (iii) $\alpha(O_1)+\alpha(O_2)=\alpha(O_1\cup O_2)+\alpha(O_1\cap O_2)$. A {\em continuous} valuation is a valuation that is continuous with respect to the Scott topology.

We say a continuous valuation on $D\in \D$ is {\em $\sigma$-finite} if there are open sets $O_i$ for $i\in \nat$ with $D\setminus \{\bot\}=\bigcup_{i\in \nat} O_i$ such that $\nu(O_i)<\infty$ for all $i\in \nat$. We know that every bounded continuous valuation on $D$ extends uniquely to a Borel measure on $D$ and that every $\sigma$-finite continuous valuation on $D$ uniquely corresponds to a measure on $D$ except for the arbitrary choice of the measure on the single element $\{\bot\}$~\cite{alvarez2000extension}. Moreover, any $\sigma$-finite continuous valuation on a locally compact Hausdorff space
can be extended to a Borel measure~\cite[Theorem 5.3]{KL05}.

The notion of $\sigma$-finite measure and $\sigma$-finite valuation are related via spaces of maximal points, i.e., a domain $D$ whose set of maximal elements $\operatorname{Max}(D)$ equipped with its relative Scott topology is a Polish space (i.e., a separable, complete and metrizable space)~\cite{lawson1997spaces}. On these domains, $\operatorname{Max}(D)$ is a $G_\delta$ subset, i.e., a countable intersection of open sets.  If a continuous valuation $\nu$ on $D$ has its support on $\operatorname{Max}(D)$~\cite{edalat1995dynamical,lawson1998computation}, i.e., $\nu(D\setminus\operatorname{Max}(D))=0 $, then $\nu$ is $\sigma$-finite iff its restriction $\nu\restriction_{\operatorname{Max}(D)}$ on the maximal elements is a $\sigma$-finite measure.

We let $\mathcal{V}(D)$ denote the set of continuous  valuations on $D\in\D$ with pointwise ordering induced by their values on opens of $D$.  For any $d\in D$, the {\em point valuation} $\delta(d)$ at $d$ is given by $\delta(d)(O)=1$ if $d\in O$ and $0$ otherwise. A {\em simple valuation} $\alpha$ on $D$ is the finite sum of points valuations. Let  $\alpha=\sum_{i\in I}^nr_i\delta(d_i)$ be a simple valuation and $\beta\in \mathcal{V}(D)$. 


\begin{proposition}\label{kirch}~\cite{kirch1993bereiche}
    \begin{enumerate}
        \item[(i)] $\alpha\ll \beta$ iff for all $J\subset I$,
        \[\sum_{i\in J}r_i<\beta\left(\bigcup_{i\in J}\dua d_i\right)\]
        \item[(ii)] $\mathcal{V}(D)$ is a domain with a countable basis $B_{\mathcal{V}(D)}$ of simple valuations $\sum_{i\in I}^nr_i\delta(d_i)$, obtained by choosing $r_i\in \mathbb{Q}$ and $d_i\in B_D$, for $i\in \nat$.  
    \end{enumerate}
\end{proposition}

It follows from Propositon~\ref{kirch}(i) that if $D$ is effectively given, then the way-below relation on $\mathcal{V}(D)$ is decidable and thus $\mathcal{V}(D)$ inherits an effective structure. 

Let $B_{ (D\to \overline{\realLine^+})}$ be the countable basis of the function space $ (D\to \overline{\realLine^+}) $ consisting of step functions of the form $g=\sup_{i\in I} r_i\chi_{O_i}$ where $r_i\in {\mathbb{Q}^+}$ and $O_i\in B_{\mathcal{O}(D)}$. Let $\alpha=\sum_{i\in I}^nr_i\delta(d_i)$ be a simple valuation. We now define:
\[F: B_{\mathcal{V}(D)}\times B_{(D\to \overline{\realLine^+}) }\to \mathcal{V}(D)\]
\begin{equation}\label{int-on-basis}(\alpha,g)\mapsto\sum_{d_i\in O_j}r_iq_j\delta(d_i)\end{equation}
%\[F(\alpha,g)(O)=\int_{O}g\,d\alpha \] 
We note that $F(\alpha,g)=\lambda O.\int_Og\,d\alpha$. 
It is straightforward to check that, for $\alpha\in B_{\mathcal{V}(D)}$ and $g\in B_{(D\to \overline{\realLine^+})} $, we have:
\begin{equation}\label{cons-ex}
    F(\alpha,g)=\sup \{F(\alpha',g'):\alpha'\ll \alpha,g'\ll g\}.\end{equation}
It follows, from~\cite[Section 2.2.6]{abramsky1995domain},  that $F$ has unique conservative extension to 
\[F:  {\mathcal{V}(D)}\times {(D\to \overline{\realLine^+}) }\to \mathcal{V}(D),\]
given by Equation~\ref{cons-ex} for any $\alpha\in \mathcal{V}(D)$ and $g\in {(D\to \overline{\realLine^+})}$. 


\begin{proposition}\label{functionalF}
\begin{itemize}
    \item[(i)] 
The functional $F$ is Scott continuous, and if $\alpha$ is a $\sigma$-finite valuation then $F(\alpha,g)=\lambda O.\int_O g\,d\alpha$.
\item[(ii)] $F$ is computable with respect to any effective structure on $D$, and the resulting effective structures on $\mathcal{V}(D)$ and $(D\to \overline{\realLine^+})$.  
\end{itemize}
\end{proposition}
{
    \begin{proof}
   (i) The Scott continuity of $F$ follows from the construction~\cite{abramsky1995domain}. If $\alpha$ is a $\sigma$-finite valuation then it has a unique extension to a Borel measure~\cite{alvarez2000extension}. Let $\alpha\in \mathcal{V}(D)$ and $g\in (D\to \overline{\realLine^+})$. Assume $\alpha_i\ll \alpha$ for $i\in \nat$ is an increasing sequence of simple valuations with $\alpha=\sup_{i\in \nat}\alpha_i$.  Then, $F(\alpha_i,g)=\lambda O. \int_Og\,d\alpha_i$. By the Choquet's formulation of the Lebesgue integral~\cite{mesiar2010choquet}, we obtain: $\lambda O. \int_Og\,d\alpha_i=\lambda O. \int_0^\infty \alpha_i(g^{-1}((a,\infty])\cap O)\,da$. Since the sequence of maps $\lambda a.\alpha_i(g^{-1}((a,\infty])\cap O)$ for $i\in \nat$ is increasing with $\sup_{i\in\nat} \lambda a.\alpha_i(g^{-1}((a,\infty])\cap O)=\lambda a. \alpha(g^{-1}((a,\infty])\cap O)$, by the monotone convergence theorem we obtain: $F(\alpha,g)=\sup_{i\in \nat} F(\alpha_i,g)=\lambda O. \sup_{i\in \nat}\int_Og\,d\alpha_i=\lambda O. \int_Og\,d\alpha $.

   (ii) Let $\alpha$ be the simple valuation and $g$ the step function in Equation~\ref{int-on-basis}. By Proposition~\ref{kirch}(i)  the relation,
   \[\alpha'\ll F(\alpha,g)=\sum_{d_i\in O_j}r_iq_j\delta(d_i)\]
   is decidable for any simple valuation $\alpha'$. Hence, $F$ is computable. 
\end{proof}
}


\remove{Recall that given two topological spaces $D$ and $E$, the point-open topology $[D\to E]_p$ on their space of continuous function $(D\to E)$ has sub-basic open sets of the form \[(x\to O)_p:=\{f:X\to Y: f(x)\in O\},\]
where $x\in X$ and $O\subseteq Y$ is an open set. 
\begin{proposition}~\cite[Lemma 5.16]{goubault2010groot}
 Suppose $D$ is a domain and $E$ a bounded complete domain. Then the Scott topology $\mathcal{O}{(D\to E)}$ and the point-open topology $[D\to C]_p$ on $(D\to E)$ coincide. 
\end{proposition}}
\remove{We have a splitting lemma for the way-below relation on normalised valuations. Suppose $\alpha=\sum_{1\leq i\leq m}p_i\delta(c_i)$ and $\beta=\sum_{1\leq j\leq n}q_j\delta(d_j)$ are normalised valuations on a continuous dcpo. 
\begin{proposition}\label{simple-valuations-way-below}~\cite[Proposition 3.5]{edalat1995domain} We have $\alpha\ll\beta$ if and only if there exist $t_{ij}\in [0,1]$ for $1\leq i\leq m$ and $1\leq j\leq n$ such that 
\begin{itemize}%\setlength\itemsep{.5em}
\item $c_{i_0}=\bot$ for some $i_0$ with $1\leq i_0\leq  m$ and for all $j$ with $1\leq j\leq m$, we have $t_{i_0j}>0$,
\item $\sum_{i=1}^m t_{ij}=q_j$ for each $j=1, \ldots, n$,
\item $\sum_{j=1}^n t_{ij}=p_i$ for each $i=1, \ldots, m$.\
\item $t_{ij}>0\,\Rightarrow c_i\ll d_j$. 
\end{itemize}
\end{proposition}

More generally, we have the following result. 
\begin{proposition}\label{simp-val-way}~\cite[Proposition 2.6]{DE24}
    Suppose $D$ is a continuous dcpo with a simple valuation  $\sigma=\sum_{i\in I} p_i\delta(d_i)\in PD$  and  a continuous valuation $\alpha\in PD$. Then $\sigma\ll \alpha$ iff there exists $i_0\in I$ with $d_{i_0}=\bot$ such that for all $J\subseteq I\setminus \{i_0\}$ we have: 
    \begin{equation}\label{simp-way-below-eq}\sum_{j\in J}p_j<\alpha\left(\bigcup_{j\in J} \dua d_j\right)\end{equation} 
\end{proposition}}

\remove{Let $\Sigma=\{0,1\}$ be the two-point space with its discrete topology. The uniform measure on $\Sigma$ induces the product measure on $\Sigma^\nat$.
 Our probability space $\Omega$  is one of the following.  
\begin{itemize}
    \item[(i)] The Cantor space $\Sigma^{\nat}$ of the infinite sequences $\bfomega=\bfomega_0\bfomega_1\cdots$ over bits $0$ and $1$ with the product topology $\mathcal{O}({\Sigma^{\nat}})$ and product measure $\nu$ induced on $\Sigma^\nat$ by the uniform distribution on $\{0,1\}$.
   \item[(ii)] The unit interval $[0,1]$ with its Euclidean topology $\mathcal{O}({ [0,1]})$ and Lebesgue measure $\nu$.
   \end{itemize}\remove{All four probability spaces presented above are Hausdorff and countably based. The two probability spaces $\Sigma^\nat$ and $[0,1]$ are compact, whereas $\Sigma_0^\nat$ and $(0,1)$ are only locally compact. 
Some of the results we present are only valid for the probability spaces $\Sigma_0^\nat$ and $(0,1)$.
To denote either the probability space $\Sigma_0^\nat$ or $(0,1)$, we use the symbol $\Omega_0$.}

It follows that the probability measures $\nu$ defined on all four spaces are unique extensions of the continuous valuation induced by them~\cite{lawson1982valuations}.
\begin{definition}
    The {\em probability map} $T_{RD\to PD}:(\Omega\to D)\to PD$ is defined by $T_{RD\to PD}(r)=\nu\circ r^{-1}$.
Two random variables $r,s\in (\Omega\to D)$ are {\em equivalent}, written $r\sim s$, if $T_{RD\to PD}(r)=T_{RD\to PD}(s)$.
\end{definition}
\remove{
\begin{proposition}\label{way-below-random}
    Suppose $r\in (\Omega\to D)$ is a random variable with a simple valuation $\alpha\ll T_{RD\to PD}(r)$. Then there exists a simple random variable $s$ with $s\ll r$ and $T_{RD\to PD}(s)=\alpha$.
\end{proposition}
\begin{proposition}\label{eq-uniformity}
 Consider any two simple valuations \[\alpha_1=\sum_{i\in I}p_i\delta(c_i)\qquad \alpha_2=\sum_{j\in J}q_j\delta(d_j)\]in $(\Omega\to D)$ with $\alpha_1\sqsubseteq \alpha_2$ and dyadic coefficients $p_i$, $q_i$.
 For any simple random variable $r_1\in (\Omega\to D)$ with $T_{RD\to PD}(r_1)=\alpha_1$, there exists a simple random variable $r_2\in (\Omega\to D)$ with $r_1\sqsubseteq r_2$ and $T_{RD\to PD}(r_2)=\alpha_2$. 

\end{proposition}\begin{proposition}\label{way-below-random}
    Suppose $r\in (\Omega\to D)$ is a random variable with a simple valuation $\alpha\ll T_{RD\to PD}(r)$. Then there exists a simple random variable $s$ with $s\ll r$ and $T_{RD\to PD}(s)=\alpha$.
\end{proposition}
\begin{proposition}\label{way-below-random-random}
  If $r\in (\Omega\to D)$ is a random variable, there exists an increasing sequence of simple random variables $r_i$ with $r_i\ll r_{i+1}$ for $i\in \nat$, such that $T_{RD\to PD}(r_i)\ll T_{RD\to PD}(r)$ with $\sup_{i\in \nat} r_i=r$ a.e., with respect to $\nu$.   
\end{proposition}}
\remove{Let $R_0D:=(\Omega_0\to D)$.
\begin{theorem}\label{random-valuation}
The map $T_{RD\to PD}$ is a continuous function onto $\mathcal{P}(D)$, mapping step functions to simple valuations. In addition, $T_{R_0D\to PD}$ is an open map, preserving the way-below relation.\end{theorem}
Let $B_{(\Omega\to D)}$ be the collection of step function in $(\Omega\to D)$ and $B_{(\Omega_0\to D)}\subseteq B_{(\Omega\to D)}$ be the collection  of step functions that take the value $\bot$ in a non-empty open set. \begin{lemma}\label{way-below-A-0}
   $B_{(\Omega_0\to D)}$ is a basis for $(\Omega_0\to D)$.
\end{lemma}
\begin{proposition}\label{random-simple-way-above}
For $b\in B_{(\Omega_0\to D)}$, we have $T[\dua b]=\dua (T(b))$.
\end{proposition}}

\begin{definition}
We say a Scott open subset $O\subseteq (\Omega \to D)$ is {\em R-open} if it is closed under $\sim_D$, i.e., $d_1 \in O$ and $d_1\sim d_2$ implies $d_2\in O$.
\end{definition} 

\remove{\begin{definition}\label{simple-R-open}
  Given an open set $O\subseteq D$ of $D\in \BC$ and a real number $0\leq q\leq 1$, the subset $[q\to O]$ of $\langle RD,\sim_{RD}\rangle$
  is defined by
  \[[q\to O]:= % \]\[ 
  \{ r: (\Omega \to D) : % r \mbox { Scott continuous}, 
  \nu(r^{-1}(O))>q\}. \]
\end{definition}

\begin{lemma}\label{is-scott-open}
The set $[q\to O]\subseteq (\Omega\to D)$ is R-open for any R-open set $O\subseteq D$, for all $q\in [0,1]$. 
\end{lemma}}

 A {\em PER domain} $(D,\sim)$ is a Scott domain $D$ with a symmetric and transitive {\em logical} relation $\sim$, i.e.,  satisfying:\\
(i) $\bot\sim \bot$ and (ii)  for increasing chains $(d_i)_{i\in \nat}$ and $(d_i')_{i\in \nat}$,\\ $\forall i\in \nat$ $d_i\sim d'_i\Longrightarrow \sup_{i\in \nat} d_i\sim \sup_{i\in \nat} d'_i$. 
 Equivalence of random variables satisfies these conditions. 
For $f,g:D\to E$, define $f\sim g$ if $d\sim d'\Longrightarrow f(d)\sim g(d')$
Morphism $[f]:(D,\sim)\to (E,\sim)$ as PER class of maps
$((D,\sim_D)\to (E,\sim_E))$ is defined as PER of maps. Similarly, $(D,\sim_D)\times (E,\sim_E)$. 
The category {\bf PER} of Scott domains with PER is a CCC.



 The random variable functor $\mathcal{R}$ is defined on ${\bf PER}$ category by:
{ On objects:} $R(D,\sim_D)=((\Omega\to D),\sim_{\Omega\to D})$ with \\
$r\sim_{{\Omega\to D}}s$ if (i) $\forall \bfomega\in \Omega.\,r(\bfomega)\sim_D r(\bfomega)\,\&\,s(\bfomega)\sim_D s(\bfomega)$, and (ii) $\forall O\in \Upsilon_D.\,\nu(r^{-1}(O))=\nu(s^{-1}(O))$. 
{On morphisms:} $[f]:(D,\sim_D)\to (E,\sim_E)$ with 
$R[f]:((\Omega\to D),\sim_{\mathcal{R}(D,\sim)})\to ((\Omega\to E),\sim_{\mathcal{R}(E,\sim)})$ as
$R[f]=[\lambda r.\,f\circ r]$.

Let $h:(\Omega,\nu)\to (\Omega^2,\nu\times \nu)$ be a measure-preserving continuous bijection on a set of full $\nu$-measure on $\Omega$.   
For example:
 For $\bfomega\in \Omega = \{0,1\}^\nat$, define 
  $h(\bfomega) = (\bfomega^{\operatorname{e}}, \bfomega^{\operatorname{o}})$, where $\bfomega^{\operatorname{e}}$ (respectively, $\bfomega^{\operatorname{o}})$ is the sequence of values in even (respectively, odd) positions in  $\bfomega$, i.e., for $i\in \nat$$(\bfomega^{\operatorname{e}})_i=\bfomega_{2i}\qquad$ and $\qquad(\bfomega^{\operatorname{o}})_i=\bfomega_{2i+1}$. Then, $h$ is a homeomorphism with inverse $k:=h^{-1}:\Omega^2\to \Omega$: $k(\bfomega,\bfomega')=\bfomega''$, where $\bfomega''_{2i}=\bfomega_i$ and           $\bfomega''_{2i+1}=\bfomega'_i$ for $i\in \nat$. For $\Omega=[0,1]$, let $h:[0,1]\to [0,1]^2$ be the Hilbert curve. 

 We now have a monad $\mathcal{R}: {\bf PER}\to {\bf PER}$ with natural transformations 
{\bf Unit:} $\eta_D: D\to (\Omega\to D)$ with $\eta_D(d)(\bfomega)=d$.
 {\bf Flattening:} $\mu_D:(\Omega\to (\Omega\to D))\to (\Omega\to D)$ with 
$\mu_D(r)(\bfomega)=r(h_1(\bfomega))(h_2(\bfomega))$. }


\section{Random variable \& valuation monads on {\bf PER}}
We here first recall the definition of the category of PER domains from~\cite{DiGianantonio2024}; then define a parametrised family of random variable monads on this categroy and finally extend the monad introduced in~\cite{kirch1993bereiche} to the catgeory of PER domains.

A {\em PER domain} $(D,\sim)$ is a bounded complete, i.e., Scott domain $D$ with a symmetric and transitive {\em logical} relation $\sim$, i.e.,  satisfying:\\
(i) $\bot\sim \bot$ and (ii)  for increasing chains $(d_i)_{i\in \nat}$ and $(d_i')_{i\in \nat}$,\\ $\forall i\in \nat$ $d_i\sim d'_i\Longrightarrow \sup_{i\in \nat} d_i\sim \sup_{i\in \nat} d'_i$. 
 %Equivalence of random variables satisfies these conditions. 


For Scott continuous functions $f,g: D \to E$, we define $f\sim g$ if for all $d,d' \in D$, $d\sim d'\Longrightarrow f(d)\sim f(d')$ and $f(d)\sim g(d)$.
A morphism $[f]:(D,\sim_D)\to (E,\sim_E)$ in the category of PER domains is a partial equivalence class of Scott continuous functions.
The product of PER domains $(D,\sim_D)\times (E,\sim_E)$ is the product of the underlying domains equipped with the PER defined by $(d,e)\sim (d',e')$ if and only if $d\sim_D d'$ and $e\sim_E e'$.
Finally, the function space $(D,\sim_D)\to (E,\sim_E)$ consists of the Scott continuous functions between the underlying domains with the PER defined as above.
The category {\bf PER} of PER domains forms a Cartesian closed category (CCC).
Any domain $D$ is a PER domain by taking identity as a partial equivalence relation. The mapping $D \mapsto (D, =)$ defines a full and faithful functor from the category of domains to the category of PER domains.

An element $d\in (D,\sim)$ is {\em self-related} if $d\sim d$. A Scott open subset $O\subseteq D$ in a PER domain $\langle D,\sim_D\rangle$ is {\em R-open} if it is closed under $\sim_D$, i.e., $d_1 \in O$ and $d_1\sim d_2$ implies $d_2\in O$. The R-open sets  form a topology called R-topology denoted by $\Upsilon_D$.

For the sample space $\Omega$, we take a countably based, locally compact Hausdorff topological space $\Omega$, for which $\mathcal{O}(\Omega)$ is equipped with an effective structure,  with a  computable continuous valuation $\nu:\mathcal{O}(\Omega)\to \reale$ on it. If $\nu$ is $\sigma$-finite then it always extends to a Borel measure on $\Omega$~\cite[Theorem 5.3]{KL05}.



The random variable functor $\mathcal{R}$ is defined on ${\bf PER}$ category by:
{ On objects:} $\mathcal{R}(D,\sim_D)=((\Omega\to D),\sim_{\Omega\to D})$ with \\
$r\sim_{{\Omega\to D}}s$ if (i) $\forall \bfomega\in \Omega.\,r(\bfomega)\sim_D r(\bfomega)\,\&\,s(\bfomega)\sim_D s(\bfomega)$, and (ii) $\forall O\in \Upsilon_D.\,\nu(r^{-1}(O))=\nu(s^{-1}(O))$. 
And {on morphisms:} $[f]:(D,\sim_D)\to (E,\sim_E)$ with the map 
$\mathcal{R}[f]:((\Omega\to D),\sim_{\mathcal{R}(D,\sim)})\to ((\Omega\to E),\sim_{\mathcal{R}(E,\sim)})$ as
$\mathcal{R}[f]=[\lambda r.\,f\circ r]$.

  Let $h:(\Omega,\nu)\to (\Omega^2,\nu\times \nu)$ be a continuous and measure-preserving map that is a bijection on a set of full $\nu$-measure on $\Omega$. It is shown in ~\cite{DiGianantonio2024} that such $h$ makes ${\mathcal R}$ into a monad on the category {\bf PER}:
 $\mathcal{R}: {\bf PER}\to {\bf PER}$ with natural transformations 
{\bf Unit:} $\eta_D: D\to (\Omega\to D)$ with $\eta_D(d)(\bfomega)=d$.
 {\bf Flattening:} $\mu_D:(\Omega\to (\Omega\to D))\to (\Omega\to D)$ with 
$\mu_D(r)(\bfomega)=r(h_1(\bfomega))(h_2(\bfomega))$. 
  
In~\cite{DiGianantonio2024}, two standard probability spaces and monads were considered for $(\Omega,\nu)$ as follows: (i) Take $\nu$ to be the probability measure on $\Omega=\{0,1\}^\nat$ with the measure of any cylinder set of length $n$ to be $1/2^n$.
 For $\bfomega\in \{0,1\}^\nat$, define 
  $h(\bfomega) = (\bfomega^{\operatorname{e}}, \bfomega^{\operatorname{o}})$, where $\bfomega^{\operatorname{e}}$ (respectively, $\bfomega^{\operatorname{o}})$ is the sequence of values in even (respectively, odd) positions in  $\bfomega$, i.e., for $i\in \nat$, we have: $(\bfomega^{\operatorname{e}})_i=\bfomega_{2i}\qquad$ and $\qquad(\bfomega^{\operatorname{o}})_i=\bfomega_{2i+1}$. Then, $h$ is a homeomorphism with inverse $k:=h^{-1}:\Omega^2\to \Omega$ given by $k(\bfomega,\bfomega')=\bfomega''$, where $\bfomega''_{2i}=\bfomega_i$ and           $\bfomega''_{2i+1}=\bfomega'_i$ for $i\in \nat$. (ii) For $\Omega=[0,1]$, let $h:[0,1]\to [0,1]^2$ be the Hilbert curve with the Lebesgue measure on $[0,1]$.
  
\subsection{A parametrised family of random variable monads on {\bf PER}}

We now introduce a parametrised family of monads using Cantor sets.  Let $\Sigma_n:=\{0,1,\ldots,n-1\}$ and let $X$ be a compact metric space and consider an iterated function system (IFS) consisting of $n$ contracting maps $f_i:X\to X$, for $i\in \Sigma_n$, each given a probablity weight $p_i>0$ with $\sum_{i=0}^{n-1}p_i=1$, such that $f_i[X]\cap f_j[X]=\emptyset$ for $i\neq j$. Then the unique attractor $C\subset X$  of the IFS is a Cantor set, i.e., a non-empty, perfect, compact, totally disconnected set and satisfies $C= \bigcup_{i\in \Sigma_n}f_i[C]$; in addition $C$ is the support of the unique invariant measure $\nu$ of the IFS satisfying~\cite{hutchinson1981fractals,barnsley2014fractals}:
\[\nu=\sum_{i\in\Sigma_n}p_i\nu\circ f_i^{-1}\]The map $s: \Sigma_n^\nat\to C$ given by \[s(m)=\bigcap_{n\in\nat} f_{m_0}\circ f_{m_1}\circ f_{m_2}\circ \ldots\circ f_{m_n}[I],\] gives a homeomorphism of $C$ with $\Sigma_n^\nat$ with inverse $t:=s^{-1}$. A domain-theoretic representation of generating points of $C$ uses the Plotkin power domain of the upper space of $X$~\cite{edalat1996power}. The invariant measure $\nu_C$ can also be obtained domain-theoretically~\cite{edalat1995dynamical,edalat1996power} and we have $\nu_C=\nu\circ s^{-1}$, where $\nu$ is the product measure on $\Sigma^\nat$ induced from the finite probability space $\Sigma_n$ with $p_i$ the probability of $i\in \Sigma_n$.  

Recall that in a compact topological group, the Haar measure is the unique non-trivial left-traslation-invariant measure (up to a positive constant) with respect to the group operation~\cite{alfsen1963simplified}. When $p_i=1/n$ for all $i\in \Sigma_n$, then $\nu$ is the unique Haar probability measure on $C$ with addition defined component-wise as $x+y=(x_0\oplus y_0)(x_1\oplus y_1)\ldots$ where addition mod $n$ in $\Sigma_n$ is denoted by $\oplus$. 

Observe also that $\Sigma_n^\nat$ is a compact metric space with the metric $d$ defined as $d(x,y)=0$ if $x=y$ and otherwise
$d(x,y)=1/2^m$, where $m\in \nat$ is the first natural number such that $x_m\neq y_m$. Moreover, the maps $f_i:\Sigma_n^\nat\to \Sigma_n^\nat$, for $i\in \Sigma_n$, defined by $f_i(x)=i:x$ are contracting and $\Sigma_n^\nat$ is itself the invariant attractor of the $n$ contracting maps $f_i$ for $i\in \Sigma_n$. For the Cantor set $\Sigma_n^\nat$, as in the case of $n=2$ above, put $h:\Sigma_n^\nat\to (\Sigma_n^\nat)^2$ with $h(\bfomega)=(\bfomega^{\operatorname{e}},\bfomega^{\operatorname{o}})$, which gives a monad.
We can now define, for the attractor $C$ of the IFS with $n$ maps, $h_C:C\to C^2$ by $h_C=\langle s\circ\pi_2,s\circ \pi_1\rangle \circ h\circ t$, which gives a monad for the probability space $(C,\nu_C)$. Note that for $X=[0,1]$ and $n=2$ with $f_0:x\mapsto x/3$ and $f_1:x\mapsto x/3+2/3$, we obtain the canonical Cantor set. 
  

\subsection{Valuation monad of {\bf PER}}
  
We now introduce the continuous valuation PER domain of a PER domain. First, we need to define the PER domain of the lattice of open sets of a PER domain. 


\begin{definition}
Given a PER domain $(D, \sim_D)$, the lattice  $\mathcal{O}(D)$  of its open sets is a PER domain with the partial equivalence relation defined by $O \sim_{\mathcal{O}(D)} O'$, if for any pair of equivalent elements, $d \sim d'$  we have $d \in O$ iff $d' \in O'$.

Given a PER domain $(D, \sim_D)$, define its valuation power domain $\mathcal{V}(D, \sim_D)$ as the PER domain $(\mathcal{V}(D), \sim_{\mathcal{V}(D)})$ where $\mathcal{V}(D)$ is the domain of continuous valuations on $D$, while $\sigma \sim_{\mathcal{V}(D)} \sigma'$  iff for every pair of equivalent open sets $O \sim_{\mathcal{O}(D)} O'$ we have that $\sigma (O) = \sigma' (O')$.
\end{definition}

It is immediate to check that $\sim_{\mathcal{O}(D)}$ and $\sim_{\mathcal{V}(D)}$ are closed under lub. Note that the R-topology consists of the self-related open sets in $(\mathcal{O}(D), \sim_{\mathcal{O}(D)})$.

On morphisms, given $[f] : (D, \sim_D) \to (E, \sim_E)$, we define
$ \mathcal{V}( [f] )= [\lambda \sigma , O \,.\, \sigma (f^{-1}(O))]$. It is straightforward to check that if $f \sim f'$, $\sigma \sim \sigma'$, and $O \sim O'$ then $\sigma (f^{-1}(O)) = \sigma' (f'^{-1}(O'))$ and therefore the action on morphisms is well-defined.

By repeating the standard construction of the continuous valuation monad on domains as in~\cite{kirch1993bereiche}, $\mathcal{V}$, itself a variation of Giry's monad, is a monad on PER domains with $\epsilon'_{(D,\sim)}: (D,\sim) \to \mathcal{V}(D,\sim)$ given by $\epsilon'_{(D,\sim)}=[ \lambda d . \delta(d)]$ and flattening operation $\mu'_{(D,\sim)} :\mathcal{V}(\mathcal{V}(D,\sim))\to \mathcal{V}(D,\sim)$ given by $\mu'_{(D,\sim)} = [ \lambda \kappa , O \,.\, \int_{\sigma \in (\mathcal{V}(D), \sim)} \sigma (O)\,\,d\kappa ]$. 
More explicitly by $\int_{\sigma \in (\mathcal{V}(D), \sim)} \sigma (O)\,\,d\kappa$ we denote the integration along the measure uniquely induced by the continuous valuation $\kappa$. 

It is immediate to check that if $d \sim_D d'$ then $\delta (d )\sim_{\mathcal{V}( D)} \delta (d')$ and therefore $\epsilon'$ is a well-defined equivalence class. 

On the other hand, if $O \sim O'$, $\kappa \sim \kappa'$, we observe that for any real number $a$ the subsets $W_a, W'_a$ of $\mathcal{V}(D, \sim)$ defined by
$W_a = \{ \sigma \mid \sigma(O) > a \}$, $W_a' = \{ \sigma \mid \sigma(O') > a \}$ are equivalent open sets ($W_a \sim W_a'$). it follows that $\kappa (W_a) = \kappa'(W'_a)$. 
By Choquet's formula for conversion of the Lebesgue integral to a Riemann integral~\cite{mesiar2010choquet}, we then have:
\begin{multline*}
    \mu_{(D,\sim)}'(\kappa)(O)=\int_{x\in\mathcal{V}(D,\sim)}x(O)\,\,d\kappa=\int_0^1 \kappa(W_a)\,da \\
    =\int_0^1 \kappa'(W'_a)\,da=\mu_{(D,\sim)}'(\kappa')(O')
\end{multline*}
which implies $\mu'$ is well-defined. The commutativity of the monadic diagrams for $\epsilon'$ and $\nu'$ follow directly from those of $\mathcal{V}$ in~\cite{kirch1993bereiche}. 

\begin{definition}
    The map $T_{{\mathcal R}(D)}:{\mathcal R}(D)\to \mathcal {V}(D)$ is defined as the push-forwrd $r\mapsto \nu\circ r^{-1}$. 
\remove{Two random variables $r,s\in (\Omega\to D)$ are {\em equivalent}, written $r\sim s$, if $\nu\circ r^{-1}=\nu\circ s^{-1}$.}
\end{definition}
  We often write $T$ for $T_{{\mathcal R}(D)}$ since its type is clear from the context. The map $T$ extends that in~\cite{DiGianantonio2024} from random variables defined on probability spaces to random variables defined on sample sapces equipped with arbitrary (computable) measures. Since $T$ maps step functions to simple valuations, it is a computable map with respect to effective structures on $\mathcal{R}(D)$ and $\mathcal{V}(D)$. If $\nu$ is an unbounded valuation then $T$ is a surjection. 

  If we restrict to continuous normalized (probability) valuations, we write $\mathcal{V}(D,\sim)$ as $\mathcal{P}(D,\sim)$. The monad $\mathcal{P}$ then extends the normalised probabilisitc power domain monad to ${\bf PER}$.

\subsection{Natural transformation}

Since $\mathcal{R}$ and $\mathcal{V}$ are monads on different categories---namely, {\bf PER}, i.e., PER bounded complete domains and {\bf PER}-$\D$, i.e., PER continuous domains---it is not possible to define a natural transformation between them. However, using the forgetful functor $\mathcal{U}$ from {\bf PER}
 to {\bf PER}-$\D$ we can take the two compositions $\mathcal{U} \circ \mathcal{R}$ and $\mathcal{V} \circ \mathcal{U}$, which are both functors from {\bf PER} to {\bf PER}-$\D$ and note that $\phi : \mathcal{U} \circ \mathcal{R} \to \mathcal{V} \circ \mathcal{U}$ defined by  $\phi_{(D,\sim)} = T_{\mathcal{U}(\mathcal{R}(D,\sim))\to \mathcal{V}(\mathcal{U}(D,\sim))} = \lambda r , O \,.\, \nu( r^{-1} O)$ is a natural transformation as it can be easily checked. 
 
 The map {$T_{\mathcal{R}^2(D,\sim)\to \mathcal{V}^2(D,\sim)}$} acts on simple random variables to give simple valuations in $\mathcal{V}(\mathcal{V}(D,\sim))$:
\begin{equation}\label{double-random}
   \sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\longmapsto \sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right),\end{equation}
where we have assumed the basic open sets $U_i$ and $V_{ij}$ are disjoint for $i\in I$ and $j\in J_i$.

\begin{lemma}\label{double-random-d} Let $D_0:=\operatorname{Im}(r)$, where $r=\sup_{i\in I}\chi_{U_i}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\in \mathcal {R}^2(D,\sim)$, then
    \[T_{\mathcal{R}(D,\sim)\to \mathcal{V}(D,\sim)}\circ \mu_{(D,\sim)}:\]\[r\mapsto\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d):\mathcal{R}^2 (D,\sim)\to \mathcal{V}(D,\sim)\]
\end{lemma}
\begin{proof}
   Note $\mu_D(r)=\sup_{i\in I}\chi_{h_1^{-1}(U_i)}(\sup_{j\in J_i}d_{ij}\chi_{h_2^{-1}(V_{ij})})$. Since $h_1$ and $h_2$ are independent and measure preserving, the result follows. 
\end{proof}
 
 We can now show that $\phi$ preserves the monadic structures of the monads $\mathcal{R}$ and $\mathcal{P}$ in the following sense.
\begin{proposition}
   Consider $\epsilon$ and $\mu$, respectively $\epsilon'$ and $\mu'$, the unit and flattening operations of $\mathcal{R}$, respectively $\mathcal{P}$. Then, for $(D,\sim)\in \text{PER}$, the following two diagrams commute:
\begin{center}

\begin{tikzcd}[row sep=huge, column sep=huge]
\mathcal{U} (D,\sim)\arrow[rd, "\epsilon'_{\mathcal{U}( D)}" ] \arrow[r, "\mathcal{U} (\epsilon_D)"] & \mathcal{U}(\mathcal{R}(D,\sim))
    \arrow[d,"\phi_{D}"]& \\
    &\mathcal{V}(\mathcal{U}( D,\sim))
\end{tikzcd}

\bigskip

\begin{tikzcd}[row sep=huge, column sep=large]
\mathcal{U} (\mathcal{R}^2 (D,\sim))\arrow{r}{\mathcal{U} (\mu_{(D,\sim)})} \arrow[swap]{d}{\mathcal{V}(\phi_{(D,\sim)}\circ \phi_{\mathcal{R}( D,\sim)})} 
&  \mathcal{U} (\mathcal{R}(D,\sim)) \arrow{d}{\phi_{(D,\sim)}} \\
 \mathcal{V}^2(\mathcal{U}( D,\sim))\arrow{r}{\mu'_{\mathcal{U }(D,\sim)}}&\mathcal{V}(\mathcal{U}( D,\sim))
\end{tikzcd} 
\end{center}
 
\end{proposition}

\begin{proof}
 The commutativity of the first diagram is straightforward. To show that the second diagram commutes, it is sufficient, by Scott continuity, to prove it for a simple random variable  
 \[r=\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\in \mathcal{R}^2(D,\sim)\]
 By Lemma~\ref{double-random-d}, we have 
 \[\phi_{(D,\sim)} \circ \mathcal{U} (\mu_{(D,\sim)}(r))=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(U_i)\nu(V_{ij})\delta(d)\]
 By Equation~(\ref{double-random}), we let:
 \begin{multline*}
\kappa:= (\mathcal{V}( \phi_{(D,\sim)})\circ \phi_{\mathcal{R}(D,\sim)}) (r) \\
=\sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right)
 \end{multline*}

    If $O\in \mathcal{O}(D,\sim)$, then we have 

\begin{multline*}
        \mu_{(D,\sim)}'(\kappa)(O)=\int_{x\in \mathcal{V}(D,\sim)}x(O)\,\,d\kappa \\
        =\sum_{i\in I,j\in J_i}\sum_{d_{ij}\in O}\nu(V_{ij})\nu(U_i) 
\end{multline*}
    
It follows, as required, that\\ $\mu_{(D,\sim)}'(\kappa)=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d)$.
\end{proof}
 
 \remove{The map {$T_{\mathcal{R}^2(D,\sim)\to \mathcal{V}^2(D,\sim)}$} acts on simple random variables to give simple valuations in $\mathcal{V}(\mathcal{V}(D,\sim))$:
\begin{equation}\label{double-random}
   \sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\longmapsto \sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right),\end{equation}
where we have assumed the basic open sets $U_i$ and $V_{ij}$ are disjoint for $i\in I$ and $j\in J_i$.

\begin{lemma}\label{double-random-d} Let $D_0:=\operatorname{Im}(r)$, where $r=\sup_{i\in I}\chi_{U_i}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\in \mathcal {R}^2(D,\sim)$, then
    \[T_{\mathcal{R}(D,\sim)\to \mathcal{V}(D,\sim)}\circ \mu_{(D,\sim)}:\]\[r\mapsto\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d):\mathcal{R}^2 (D,\sim)\to \mathcal{V}(D,\sim)\]
\end{lemma}
\begin{proof}
   Note $\mu_D(r)=\sup_{i\in I}\chi_{h_1^{-1}(U_i)}(\sup_{j\in J_i}d_{ij}\chi_{h_2^{-1}(V_{ij})})$. Since $h_1$ and $h_2$ are independent and measure preserving, the result follows. 
\end{proof}
 
 We can now show that $\phi$ preserves the monadic structures of the monads $\mathcal{R}$ and $\mathcal{P}$ in the following sense.
\begin{proposition}
   Consider $\epsilon$ and $\mu$, respectively $\epsilon'$ and $\mu'$, the unit and flattening operations of $\mathcal{R}$, respectively $\mathcal{P}$. Then, for $(D,\sim)\in \text{PER-}$, the following two diagrams commute:
\begin{center}

\begin{tikzcd}[row sep=huge, column sep=huge]
\mathcal{U} (D,\sim)\arrow[rd, "\epsilon'_{\mathcal{U}( D)}" ] \arrow[r, "\mathcal{U} (\epsilon_D)"] & \mathcal{U}(\mathcal{R}(D,\sim))
    \arrow[d,"\phi_{D}"]& \\
    &\mathcal{V}(\mathcal{U}( D,\sim))
\end{tikzcd}

\bigskip

\begin{tikzcd}[row sep=huge, column sep=large]
\mathcal{U} (\mathcal{R}^2 (D,\sim))\arrow{r}{\mathcal{U} (\mu_{(D,\sim)})} \arrow[swap]{d}{\mathcal{V}(\phi_{(D,\sim)}\circ \phi_{\mathcal{R}( D,\sim)})} 
&  \mathcal{U} (\mathcal{R}(D,\sim)) \arrow{d}{\phi_{(D,\sim)}} \\
 \mathcal{V}^2(\mathcal{U}( D,\sim))\arrow{r}{\mu'_{\mathcal{U }(D,\sim)}}&\mathcal{V}(\mathcal{U}( D,\sim))
\end{tikzcd} 
\end{center}
 
\end{proposition}

\begin{proof}
 The commutativity of the first diagram is straightforward. To show that the second diagram commutes, it is sufficient, by Scott continuity, to prove it for a simple random variable  
 \[r=\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\in \mathcal{R}^2(D,\sim)\]
 By Lemma~\ref{double-random-d}, we have 
 \[\phi_{(D,\sim)} \circ \mathcal{U} (\mu_{(D,\sim)}(r))=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(U_i)\nu(V_{ij})\delta(d)\]
 By Equation~(\ref{double-random}), we let:
 \[\kappa:= (\mathcal{V}( \phi_{(D,\sim)})\circ \phi_{\mathcal{R}(D,\sim)}) (r)=\sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right)\]
    If $O\in \mathcal{O}(D,\sim)$, then we have 
    \[\mu_{(D,\sim)}'(\kappa)(O)=\int_{x\in \mathcal{V}(D,\sim)}x(O)\,\,d\kappa=\sum_{i\in I,j\in J_i}\sum_{d_{ij}\in O}\nu(V_{ij})\nu(U_i)\]
    
It follows, as required, that\\ $\mu_{(D,\sim)}'(\kappa)=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d)$.
\end{proof}}

\section{Conditional probability }
 Using the sigma algebra of the unit interval as events, Ackerman et al.~\cite{ackerman2019} have shown that two computable random variables on the unit interval can have a conditional distribution that encodes the halting problem, and hence non-computable. In this section, we introduce a domain-theoretic framework for conditionaly probability, based on a notion of open sets as observable property,  and show that it is computable. 

 
 \subsection{Probability of an event}

 Following the principles of observational or semi-decidable logic~\cite{smyth1983power,abramsky1991domain,vickers1989topology}, we take only the Scott open sets of a domain $D\in \BC$, rather than all its Borel subsets, as obervable properties or events. This is the approach to probabilistic computation used in~\cite{DiGianantonio2024},
 
 However, if we naively take $\mathcal{O}(D)$ as our domain of events, we cannot develop a computable notion of conditional probability as we now see. Suppose $\sigma\in \mathcal{P}(D,=)$ is a continuous probability valuation and %$T_{\Omega\to D}(r)=\sigma$. Suppose 
 $O,U\in \mathcal{O}(D)$ are two events. Then, we have the classical conditional probability $\operatorname{Pr}(U|O)=\operatorname{Pr}(U\cap O)/\operatorname{Pr}(O)=\sigma(U\cap O)/\sigma(O)$ if  $\operatorname{Pr}(O)=\sigma(O)\neq 0$ and $0$ otherwise. Then, $\operatorname{Pr}(\cdot\,|O):\mathcal{O}(D)\to ([0,1],\leq)$ defines a continuous valuation. However, $\operatorname{Pr}(U|O)$ is not monotonic in its second argument, which implies we cannot obtain a Scott continuous map for the conditional property. 

 The problem can be resolved if we include in our formulation, not just the obervable event $O$ but also its opposite event. In classical measure theory the opposite event is simply the complement of the event, but here the complement of $O$ is not open and thus we need to take an open set $O'$ disjoint from $o$ as is opposite. we are then led to the domain of disjoint pairs of opens $(O,O')$ of $D$, ordered by the subset inclusion of open sets. The domain of disjoint pairs of open subsets of a topological space was called the solid domain of the topological space and first used for developing a computable model of objects in solid modelling and computational geometry~\cite{edalat2002foundation}. 
 
 This domain gives a proper framework for observable events, including an interval notion of probability. 
In this paper, however, we take a simpler approach and retain the notion of probability as a real number rather than a real interval. We can then rewrite the conditional probability, for $\sigma(O)\neq 0$, as follow:
\[\operatorname{Pr}(U|(O,O'))=\sigma(U\cap O)/(1-\sigma(O'))\]
which is now monotonically incraasing in $(O,O')$ as required providing a Scott continuous and computable map in the second component; see Theorem~\ref{prob-comp}.   


\remove{Assuming we can the effective structures stipulated above, we note the following. 
 
 Suppose $D\in \D$ is effectively given with respect to an effective enumeration of the basis $B_0=\{b_0,b_1,\cdots\}\subseteq D$. If $D\in \BC$, we assume further that $B_0$ is closed under existing binary lubs and it then follows that the basis of $\mathcal{O}(D)$ is closed under binary intersections and the binary lub operation on $\mathcal{O}(D)$ is also decidable. 
 
 The set of open sets of the form $\dua b_i$ provides a basis of the continuous lattice $\mathcal{O}(D)$. Then $b_i\ll_D b_j$ implies $\dua b_j\ll_{\mathcal{O}(D)} \dua b_i$. To obtain an effective structure on $\mathcal{O}({D})$, the relation $\dua b_j\ll\dua b_i$ needs to be decidable. For $\realDom$, this is easy to check. We will now show that this is also the case for some basic types constructed from $\realDom$, which can be given an effective structure by using an effective enumeration of dyadic intervals as a basis of $\realDom$.

 \begin{proposition}
 \begin{itemize}
   \item[(i)] If $(D,\sim)$ has an effective structure, so have $\mathcal{P}(D,\sim)$ and $\mathcal{R}( D,\sim)$.
   \item[(ii)] The effective structure on $\realDom$, using dyadic compact intervals as basis, induces an effective structure on $\mathcal{O}(\realDom)$. 
 \end{itemize}
   
 \end{proposition}
 \begin{proof}
   (i) By~\cite[Proposition 3.5]{edalat1995domain} the effective structure on $D$, induces an effective structure on $\mathcal{P}(D)$.  

   (ii)
 \end{proof}
 

 
 Assume now an effective structure on $\mathcal{O}(D)$.

Suppose we have a computable probability distribution $\sigma\in PD$ and a computable open set $O\in \mathcal{O}(D)$, considered as an event. Then it follows that the probability $\sigma(O)$ is a left-computable real, but not necessarily a computable real number. 

We will now see that for conditional probability distribution, the situation is even more problematic if we adopt a rather naive approach, closely following classical probability theory. We will see how it is inadequate in that it cannot lead to a computable framework. We then introduce in the next subsection a more appropriate framework in line with observable or geometric logic, which provides a computable setting for Bayesian statistics. }


 


 

 
\subsection{Domain of disjoint events}
 Since our main purpose here is focused on probability theory, we will use the phrase {\em event domain} rather than the original name, the solid domain.
\begin{definition}
For a PER domain $(D,\sim)$, its {\em event domain}, denoted $\mathcal{E}(D,\sim)$, is the dcpo of pairs of elements $(O_1, O_2)\in (\mathcal{O}(D))^2$, with $O_1\cap O_2=\emptyset$ called {\em disjoint event-pairs}, partially ordered componentwise by the lattice order with $(O_1,O_2)\sim (O_1',O_2')$ if $O_1\sim O_1'$ and $O_2\sim O_2'$.

\end{definition} 
\begin{proposition}
  \begin{itemize}
  \item[(i)] For a PER domain $(D,\sim)$, the event-domain $\mathcal{E}(D,\sim)$ is a PER domain. 
     \item[(ii)] We have: $(O_1,O_2)\in \mathcal{E}(D,\sim)$ is maximal iff 
     $O_1=(O_2^c)^\circ$ and $O_2=(O_1^c)^\circ$.
    
   \end{itemize} 
\end{proposition}


\remove{For our application, we need the following property:

   \begin{proposition}
       \begin{itemize}
           \item[(i)] If $L$ is a countably based continuous lattice, then $\mathcal{E}(L)\in \BC$. 
           \item[(ii)] For any topological space $X$, an isomorphism $\mathcal{E}(X) \cong (X\to {\sf Bool}_\bot) $ is induced by the mapping \[(O_1,O_2)\mapsto \lambda x. f(x)=\left\{\begin{array}{ll} \ttt&x\in O_1\\\ff&x\in O_2\end{array}\right.\]
       \end{itemize}
   \end{proposition}

\begin{definition}
If $L = \mathcal{O}(X)$ is the lattice of open sets of a topological space $X$, and $\sigma$ is a normalized continuous valuation on $\mathcal{O}(X)$, we define the probability of a disjoint event-pair 
$(O_1,O_2)\in \mathcal{E}(L)$, under the valuation $\sigma$, as $\operatorname{Pr}_{\sigma}(O_1,O_2):=[\sigma(O_1), 1-\sigma(O_2) ]$. We say $(O_1,O_2)\in \mathcal{E}(L)$ is a classical disjoint event-pair with respect to $\sigma$, if $(O_1,O_2)$ is maximal and $\operatorname{Pr}_{\sigma}(O_1,O_2)$ is a single point, equivalently $\sigma(O_1\cup O_2)=1$.\end{definition}
Note that we always have $\sigma(O_1)\leq 1-\sigma(O_2)$ as $O_1$ and $O_2$ are disjoint. 

  If $L$ is a sup-lattice and $\sigma$ is a normalized continuous valuation on $L$, the join and meet of disjoint event-pairs $O=(O_1,O_2)$ and $U=(U_1,U_2)$ are defined, respectively, as $O\vee U=(O_1\cup U_1,O_2\cap U_2)$ and $O\wedge U=(O_1\cap U_1,O_2\cup U_2)$. We say $(O_1,O_2)\in \mathcal{E}(L)$ is a classical disjoint event-pair with respect to $\sigma$, if $\sigma(O_1)+\sigma(O_2)=1$. It is easily checked that the join and the meet of classical disjoint event-pairs are classical disjoint event pairs. 
  
  \begin{definition}
      
  Two disjoint event-pairs $O=(O_1,O_2)$ and $U=(U_1,U_2)$ are said to be {\em independent} if  $\operatorname{Pr}_{\sigma}(O\wedge U)=\operatorname{Pr}_{\sigma}(O)\operatorname{Pr}_{\sigma}(U)$.
  \end{definition}
   \begin{proposition}Two disjoint event-pairs $O=(O_1,O_2)$ and $U=(U_1,U_2)$ are independent iff $\sigma(O_1\cap U_1)=\sigma(O_1)\sigma(U_1)$.
 \end{proposition}
 \begin{proof}
     We have:
     \[\operatorname{Pr}(O\wedge U)=[\sigma(O_1\cap U_1),1-\sigma(O_2\cup V_2)],\]
     \[\operatorname{Pr}(O)\operatorname{Pr}(U)=[\sigma(O_1)\sigma(U_1),1-\sigma(O_2)-\sigma(U_2)+\sigma(O_2)\sigma(U_2)],\]
     and the result follows.
 \end{proof}}
 
 
  \remove{
  

Assume now we have an effective structure on $(D,\sim)$.
\begin{proposition}
  If $(O_1, O_2)\in \mathcal{E}(D,\sim)$ is a computable element of $\mathcal{E}(D,\sim)$, and $\sigma$ is a computable element in $\mathcal{P}(D,\sim)$, then $\operatorname{Pr}_{\sigma}(O_1,O_2)$ is a computable element in $\realDom$.  If $(O_1, O_2)$ is also a classical disjoint event-pair with respect to $\sigma\in \mathcal{P}(D,\sim)$, then $\operatorname{Pr}_{\sigma}(O_1,O_2)$ is a computable real number, i.e., $\sigma(O_1)$ and $\sigma(O_2)$ are computable real numbers with $\sigma(O_1)=1-\sigma(O_2)$. 
\end{proposition}}
We define the {\em conditional random variable operator}: \[\label{crv}\operatorname{CR}:\mathcal{R}( D,\sim)\times \mathcal{E}(D,\sim)\to \mathcal{R}( D,\sim)\]by 
 \begin{multline}
 \label{rvc}\operatorname{CR}(r,(O_1,O_2))(\bfomega)
 \\
= \left\{\begin{array}{cl}
  r\circ  h_1\circ h_2^n(\bfomega)    & \exists n\in \nat (i<n \\
  & \Rightarrow r \circ h_1\circ h_2^i(\bfomega)\in O_2\;\\&\& \; r \circ h_1\circ h_2^n(\bfomega)\in O_1)\\
     \bot & \mbox{otherwise}
 \end{array}\right.    
 \end{multline}
 
 It is easily seen that $\operatorname{CR}(r,(O_1,O_2)$ and $\operatorname{CR}$ are continuous. It is also clear that  $\operatorname{CR}(r,(O_1, O_2))$ is a step function if $r$ is a step function. We write $r_{(-|(O_1,O_2))}:=\operatorname{CR}(r,(O_1, O_2))$.

 An informal characterization of $\operatorname{CR}$ is the following: from the sample value $\bfomega$ one derives the infinite sequence of sample values $\langle h_1 (\bfomega), h_1\circ  h_2 (\bfomega), h_1\circ  h_2^2 (\bfomega), \ldots \rangle $ and sequentially searches the first value $\bfomega'$ in the sequence with $r(\bfomega') \in O_1$.  Note that the map $\bfomega \mapsto \langle h_1 h_2^i (\bfomega) \rangle_{i \in \nat} $ is a measure-preserving map from the sample space to the countable product of sample spaces with the product measure. 

We say $(O_1,O_2)\in \mathcal{E}(D)$ is a {\em classical} disjoint event-pair with respect to $\sigma\in \mathcal{P}(D,\sim)$, if $(O_1,O_2)$ is maximal and  $\sigma(O_1\cup O_2)=1$.
 \begin{proposition}\label{cond-rand}
 Suppose $\bot\notin U(\mathcal{O},\sim)$ and $(O_1,O_2)\in \mathcal{E}(D,\sim)$.
 \begin{enumerate}
     \item If $\nu(O_1)>0$, then we have: \[\nu(r^{-1}_{(-|(O_1,O_2))}(U))=\nu(r^{-1}(U\times O_1))/(1-\nu(r_2^{-1}(O_2))).\]
\item For $\nu(O_1)=0$, we have $\nu(r^{-1}_{(-|(O_1,O_2))}(U))=0$.
\item If $(O_1,O_2)$ is a classical event with respect to the probability measure $\nu\circ r^{-1}$, then we have:\\ $\nu(r^{-1}_{(-|(O_1,O_2))}(U))=\nu(r^{-1}(U\times O_1))/\nu(r_2^{-1}(O_1))$.
 \end{enumerate}
 \end{proposition}
{
\begin{proof}
(i)  In Equation~(\ref{rvc}), with $O_1$ is replaced by $U\cap O_1$, the events for different $n\in \nat$ are disjoint, and 
 \begin{align*}
     \nu(r^{-1}_{(-|(O_1,O_2))}(U)) & =\sum_{n=0}^\infty \nu(r^{-1}(U\cap O_1))(\nu(r_2^{-1}(O_2)))^n
     \\
     & =\nu(r^{-1}(U\cap O_1))/(1-\nu(r_2^{-1}(O_2))).
 \end{align*}
  Items (ii) and (iii) are straightforward. 
\end{proof}}

From item Proposition~\ref{cond-rand}(iii), it follows that $\operatorname{CR}(r,(O_1,O_2))$ extends the notion of conditional random variable to general disjoint event-pairs, which coincides with the classical notion when the disjoint event-pair is classical.

\remove{Consider, for $r\in \mathcal{R}(D,\sim)$ and $(O_1,O_2)\in \mathcal{E}(D,\sim)$, the Scott continuous map\[\Psi_{r,(O_1,O_2)}: \mathcal{R}(D,\sim)\to\mathcal{R}(D,\sim)\]
\[\Psi_{r,(O_1,O_2)}(s)(\bfomega)=\left\{\begin{array}{cc}
  r h_1(\bfomega)   &  r h_1(\bfomega)\in O_1\\
  s h_2(\bfomega)   &  r h_1(\bfomega)\in O_2\\
  \bot& \mbox{otherwise}
\end{array}\right.\]  
\begin{proposition}\label{lfp}
The least fixed point of $\Psi_{r,(O_1,O_2)}$
is $r_{(-|(O_1,O_2))}$.
\end{proposition} 
 \begin{proof}
    For $m\in \nat$, the $m$th iterate $\Psi^m_{r,(O_1,O_2)}(\bot_{(\Omega\to D)})$ is given by:
\begin{multline*}
   \Psi^m_{r,(O_1,O_2)}(\bot_{(\Omega\to D_0)})(\bfomega)  \\
   =\left\{\begin{array}{cl}
   rh_1h_2^n(\bfomega)    & \exists n\leq m(i<n \\
   & \Rightarrow r_2h_1h_2^i(\bfomega)\in O_2\;\& \; rh_1h_2^n(\bfomega)\in O_1)\\
     \bot & \mbox{otherwise,} 
    \end{array}\right. 
\end{multline*}
    from which the result follows.
 \end{proof}
 Assume $(D,\sim)$ and $\mathcal{O}(D,\sim)$, and thus $\mathcal{E}(D,\sim)$, are equipped with effective structures. 
 \begin{corollary}
    If $r\in \mathcal{R}(D,\sim)$ and the disjoint event-pair $(O_1,O_2)\in \mathcal{E}(D,\sim)$ are computable, then $\operatorname{CR}(r,(O_1,O_2))$ is computable. 
 \end{corollary}
 \begin{proof}
It is easy to check that $\Psi$, viewed as an element in the domain $\mathcal{R}(D,\sim)\to \mathcal{E}(D,\sim) \to \mathcal{R}(D,\sim)\to \mathcal{R}(D,\sim)$, is computable as a composition of the computable functions used in its definition. It follows that if $r$ and $(O_1, O_2)$ are computable, then $\Psi_{r,(O_1,O_2)}$ is computable, and therefore so is its fixed point.
\remove{
  Since the least fixed point of a computable function is computable~\cite{plotkin1981post}, it is sufficient, by Proposition~\ref{lfp},  to show that $\psi:(\Omega\to D)\times E\mathcal{O}(D)\times (\Omega \to D)\to (\Omega \to D)$, with $\Psi(r,(O_1,O_2),s)=\Psi_{r,(O_1,O_2)}(s)$ is computable. We need to show that for simple random variables $r$ and $s$ with computable $(O_1,O_2)\in E\mathcal{O}(D)$, the predicate $d\chi_O\ll \Psi_{r,(O_1,O_2)}(s)$ is decidable for any single-step function $d\chi_O\in (\Omega \to D)$. But this is equivalent to, 
  \begin{multline*}
      O\ll (\Psi_{r,(O_1,O_2)})^{-1}(\dua d)
      \\ =((h_1^{-1}r_1^{-1}(\dua d))\cap (h_1^{-1}r_2^{-1}(O_1)))
      \\ \cup ((h_2^{-1}s^{-1} (\dua d))\cap (h_1^{-1}r_2^{-1}(O_2)),
  \end{multline*}
 which is decidable since $r$ and $s$ are simple random variables and $O_1$ and $O_2$ are computable open subsets of $D$. In fact, $O$ is a finite union of cylinder sets and for any open set $W\subset D$, the open subsets $r_{i}^{-1}(W)$ is a finite union of cylinder sets, for $i=1,2$ and so are $h_jr_i^{-1}(W)$, for $j=1,2$.} 
 \end{proof}}
 Similarly, we define the {\em conditional probability}: \begin{equation}\label{cond.prob}\operatorname{CP}: \mathcal{P}(D,\sim)\times \mathcal{E}(D,\sim)\to \mathcal{P}(D,\sim)\end{equation} by 
 \begin{multline*}
     (\operatorname{CP}(\sigma,(O_1,O_2)))(U) \\
     =\left\{\begin{array}{cl} 1& \bot \in U\\
     \sigma(O_1\cap U)/(1-\sigma(O_2)))& \mbox{otherwise}.\end{array}\right.
 \end{multline*}
 

 
\begin{proposition} \label{CRandCP}
 The map $\operatorname{CP}$ is Scott continuous, and the following diagram commutes:  
 \[ \begin{tikzcd}[row sep=huge, column sep=large]
\mathcal{R}(D,\sim)\times \mathcal{E}(D,\sim) \arrow{r}{\Large{T_{\mathcal{R}(D)}\times \operatorname{Id}}} \arrow[swap]{d}{\operatorname{CR}} & 
 \mathcal{P}(D,\sim)\times \mathcal{E}(D,\sim) \arrow{d}{\operatorname{CP}} \\%
 \mathcal{R}(D,\sim)\arrow{r}{{T_{\mathcal{R}(D,\sim)}}}& 
\mathcal{P}(D,\sim)
\end{tikzcd}
\]
\end{proposition}
\subsection{Computability of the conditional probability}
We note that an effective structure on the domain $(D,=)$ induces an effective structure on the domain $\mathcal{R}(D,=)$ by using Equation~\ref{way-below}, which shows the decidability of $f\ll g$ for step functions $f,g\in \mathcal{R}(D)$. It also induces an effective structure on $ \mathcal{V}(D,=)$ using Proposition~\ref{kirch}(i) which gives the decidability of the way-below relation on simple valuations. It furthermore provides an effective structure on $\mathcal{P}(D,=)$ based on~\cite[Proposition 3.5]{edalat1995domain}, which establishes the decidability of the way-below relation on normalised simple valuations. Finally, an effective structure on $\mathcal{O}(D,=)$ clearly induces an effective structure on $\mathcal{E}(D,=)$. An effective structure for $(D,=)$ also directly provides an effective structure for $(D,\sim)$. In general, an effective structure for $(D,=)$ does not lead to an effective structure for $\mathcal{O}(D,=)$, though it does so for $D=\realDom$ and domains constructed from it using product and function space constructors.
\begin{theorem}\label{prob-comp}
    If $(D,\sim)$ and $\mathcal{O}(D,\sim)$ have effective structures, then the map $\operatorname{CP}$ is computable. 
\end{theorem}
{
\begin{proof}
    The effective structure on $(D,\sim)$ induces an effective structure on $\mathcal{P}(D,\sim)$. We need to show that for disjoint basic disjoint open sets $(O_1,O_2)\in \mathcal{O}(D,\sim)$ and a simple normailised valuation $\sigma\in \mathcal{P}(D,\sim)$, the predicate $\sigma'\ll_{\mathcal{P}(D)} \operatorname{CP}( \sigma, (O_1,O_2))$ is decidable for simple normalised valuation $\sigma'\in \mathcal{P}(D)$. This follows from Proposition 2.6 in~\cite{DiGianantonio2024} since the values of $\operatorname{CP}( \sigma, (O_1,O_2))$ are rational numbers and there are only a finite number of comparisons to check.  
\end{proof}
}
The map $\operatorname{CR}$ is also computable, which follows from a more general result, namely Proposition~\ref{CR0}, in the next section.  




\remove{\subsection{Interval notions of conditional probability}

On disjoint events, it is possible also to define an interval notion of probability of events and two interval notions of the conditional probability of events. 
\begin{definition}\label{int-prob)}
 Given $\sigma\in PD$, the {\em interval probability map} on the space of disjoint event-pair is given by $\operatorname{Pr}_\sigma: \mathcal{E}(D,\sim)\to \interval[0,1]$ with $\operatorname{Pr}_\sigma((O_1,O_2))=[\sigma(O_1),1-\sigma(O_2)]$.

 
\end{definition}
It is easily seen that $\operatorname{Pr}_\sigma$ is Scott continuous and also Scott continuous with respect to the parameter $\sigma\in PD$. Given an event-pair $(O_1,O_2)$, the real interval $\operatorname{Pr}_\sigma((O_1,O_2))\in \interval[0,1]$ captures the minimum and maximum probability $\sigma(O_1)$ as the event-pair is refined in the information order.

Given $\sigma\in \mathcal{P}(D)$ and $(O_1,O_2)\in \mathcal{E}(D,\sim)$, the conditional probability $\sigma(-|(O_1,O_2)$ defined in Expression~(\ref{cond.prob}), gives rise by to an interval conditional probability $\operatorname{PR}_{\sigma(-|(O_1,O_2)}$. 

Using the interval extension of division of real numbers, we can also obtain another interval notion of conditional probability, as follows. Given $\sigma\in \mathcal{P}(D)$, the map $\operatorname{Pr}_\sigma(-|-):\mathcal{E}(D,\sim) \times \mathcal{E}(D,\sim)\to \interval[0,1]$ is defined as $\operatorname{Pr}_\sigma((U_1,U_2)|(O_1,O_2))=\operatorname{Pr}((O_1\cap U_1,O_2\cup U_2))/\operatorname{Pr}_\sigma((O_1,O_2))$,
where, as usual, we let $a/b=\bot$ for $a,b\in \interval[0,1]$ with $0\in b$. Note that if $U_2=\emptyset$ and $(O_1,O_2)$ is a classical event-pair, then we have $\operatorname{Pr}_\sigma(U|(O_1,O_2))=\operatorname{Pr}_\sigma((U,\emptyset)|(O_1,O_2))$. 

It follows easily that we have two interval notions of conditional probability, which are both computable; we now show that these two interval notions of conditional probability are consistent but do not coincide:
\begin{proposition}
For any continuous valuation $\sigma\in \mathcal{P}(D)$ and two disjoint event-pairs
 $(O_1, O_2), (U_1, U_2)\in \mathcal{E}(D,\sim)$, the two intervals   
 \[\operatorname{Pr}_{\sigma}((U_1, U_2)| (O_1, O_2)),\qquad\operatorname{Pr}_{\sigma(-|(O_1, O_2))}(U_1, U_2),\] have the same left end-point, but, in general, the right end-point of either can be greater than that of the other. 
 If, however, $(O_1,O_2)$ is a classical event-pair, then the two intervals coincide. If, in addition, $(U_1,U_2)$ is also a classical disjoint event-pair, then this interval is the classical conditional probability, namely the real number $\sigma(U_1\cap O_1)/\sigma(O_1)$.
\end{proposition}
\begin{proof}
We have: \[\operatorname{Pr}_{\sigma(-|{(O_1, O_2)}}(U_1, U_2)=\left[\frac{\sigma(U_1\cap O_1)}{1-\sigma(O_2)},1-\frac{\sigma(U_2\cap O_1)}{1-\sigma(O_2)}\right]\]
\begin{multline*}
    \operatorname{Pr}_\sigma((U_1,U_2)|(O_1,O_2))
    =\frac{[\sigma(U_1\cap O_1),1-\sigma(U_2\cup O_2)]}{[\sigma(O_1),1-\sigma(O_2)]} \\
    =\left[\frac{\sigma(U_1\cap O_1)}{1-\sigma(O_2)},\frac{1-\sigma(U_2\cup O_2)}{\sigma(O_1)}\right]
\end{multline*}

It follows immediately that the two notions of conditional probability have the same left end-point. Furthermore,
\begin{multline*}
 \Delta:=\left(\operatorname{Pr}_{\sigma}((U_1, U_2)| (O_1, O_2))\right)^+-\left(\operatorname{Pr}_{\sigma(-|{(O_1, O_2))}}(U_1, U_2)\right)^+ \\
 =\frac{1-\sigma(U_2\cup O_2)}{\sigma(O_1)}-1+\frac{\sigma(U_2\cap O_1)}{1-\sigma(O_2)}.   
\end{multline*}

If $O_2=\emptyset$, $1>\sigma(O_1)>0$ and $U_2=D$, the above reduces to $\Delta=-1 +\sigma(O_1)<0$. If, on the other hand, $O_2=\emptyset$, $\sigma(O_1)<1$ and $U_2=\emptyset$, then the difference would become $\Delta=(1-\sigma(O_1))/\sigma(O_1)>0$. When $(O_1,O_2)$ is a classical disjoint event-pair, from $O_1\cap O_2=\emptyset$ and $\sigma(O_1)+\sigma(O_2)=1$, we obtain: 
\[\Delta=\frac{1-\sigma(U_2\cup O_2)-\sigma(O_1)+\sigma(U_2\cap O_1)}{\sigma(O_1)}=0,\]
thus the two interval conditional probabilities coincide. If, in addition to $(O_1,O_2)$, the disjoint event-pair $(U_1,U_2)$ is also a classical disjoint event-pair, then $(O_1\cup U_1,O_2\cap U_2)$ is a classical disjoint event-pair too, and thus $1-\sigma(U_2\cup O_2)=\sigma(U_1\cap O_1)$ and the result follows.

\end{proof}
\begin{corollary}
    

If $(O,O')$ and $(U,U')$ are classical event-pairs, then 
\[\operatorname{Pr}_\sigma((U,U')|(O,O'))=\frac{\operatorname{Pr}_\sigma((O,O')|(U,U'))\sigma(U)}{\sigma(O)}\]
\end{corollary}
\begin{corollary}
    

If $(O_i,O_i')$, for $1\leq i\leq n$,  and $(U,U')$are classical event-pairs with the event-pairs $(O_i,O'_i)$ independent for $1\leq i\leq n$, then 
\begin{multline*}
 \operatorname{Pr}_\sigma\left((U,U')|\bigwedge_{1\leq i\leq n} (O_i,O_i')\right)
 \\
 =\frac{\prod_{1\leq i\leq n}\operatorname{Pr}_\sigma((O_i,O_i')|(U,U'))\sigma(U)}{\sigma(\bigwedge_{1\leq i\leq n} (O_i,O_i'))}   
\end{multline*}

\end{corollary}}
\remove{

% The equivalence relation $\sim$ between random variables induces a partial equivalence relation (PER), on the function spaces defined on domains of random variables. Therefore, we used the notion of PER domains, i.e. domains with a partial equivalence relation on its elements, introduces in \cite{DE24}, similar notions can be found also in \cite{AP90,Danielsson2006,sabelfeld2001per}. 

% \begin{definition}
% A partial equivalence relation (PER), on a generic set, is a relation that is symmetric and transitive but not necessarily reflexive. A PER domain $\langle D, \sim_D \rangle$ is a bounded complete domain, $D \in \BC$, with a partial equivalence relation $\sim_D$ on it which is also a logical relation~\cite{mitchell1989toward}, i.e. it satisfies the following two properties: 
% \begin{itemize}% \setlength\itemsep{.5em}
% \item $\bot \sim_D \bot$,
% \item for any pair of increasing chains $\langle d_i \rangle_{i \in N}$ and $\langle d'_i \rangle_{i \in N}$, if $\forall_i \ldot d_i \sim_D d'_i$ then $\sup_{i \in N} d_i \sim_D \sup_{i \in N} d'_i$.
% %    \item if $d_1 \sim_D d_2$ and $d'_1 \ll d_1$ then there exists $d'_2$ such that $d'_1 \sim_D d'_2$ and $d'_2 \ll d_2$.
% \end{itemize}
% Observe that by Proposition~\ref{sup-closure}, the equivalence relation for random variables on a domain satisfies the conditions of a logical relation, which is then extended in the above definition to PER domains. We denote by $\PD$ the categories whose objects are PER domains and whose 
% morphisms are \emph{equivalence classes} of Scott-continuous functions between the underlying bounded complete domains, under the PER $\sim_{(D \to E)}$ defined by: 
% \[ f_1 \sim_{(D \to E)} f_2 \mbox{ iff } d_1 \sim_D d_2\, \mbox{implies}\ f_1 (d_1) \sim_E f_2(d_2).
% \]
% Composition of morphisims is defined by $[f] \circ [g] = [f \circ g]$
% \end{definition}

% \begin{definition}
% We say a Scott open subset $O\subseteq D$ in a PER domain $( D,\sim_D )$ is {\em R-open} if it is closed under $\sim_D$, i.e., $d_1 \in O$ and $d_1\sim d_2$ implies $d_2\in O$. \remove{The R-topology $\Upsilon_D$ on a PER domain $D$ is the sub-topology of the Scott topology such that $(d_1\sim_D d_2)\iff \forall O\in \Upsilon_D. (d_1\in O\iff d_2\in O)$.}
% \end{definition} 
In this section, we aim to show that in our framework, conditional probability can be formulated and is computable for some basic higher types. 

\begin{definition}
A Scott open subset $O\subseteq D$ in a PER domain $\langle D,\sim_D\rangle$ is {\em R-open} if it is closed under $\sim_D$, i.e., $d_1 \in O$ and $d_1\sim d_2$ implies $d_2\in O$. 

A PER domain is R-T$_0$ if any pair of self-equivalent elements $x, y$ that cannot be separated by R-open sets are equivalent.
\end{definition} 

It is easy to check that the collection of all R-open sets of a PER domain $\langle D,\sim_D\rangle$ is a topology, i.e., R-open sets are closed under taking arbitrary union and finite intersections. We call this topology the {\em R-topology} on $\langle D,\sim_D\rangle$ and denote it by $\gamma_{(D, \sim_D)}$.

We denote by $|D|$ the set $\{d \in D \mid d \sim_D d\}$ the set of self-equivalent element in PER domain $(D, \sim_D)$

\begin{definition}
  We say a Scott continuous map $f:(D_1,\sim)\to (D_2,\sim)$ of PER domains is {\em R-continuous} if it is continuous with respect to the R-topology on $D_1$ and $D_2$. 
\end{definition}

\begin{lemma}\label{func-r-top}
 \begin{itemize}
     \item[(i)]  A Scott continuous map of the function space  $((D_1,\sim)\to(D_2,\sim))$ is self-related iff it is R-continuous. 
     \item[(ii)] Two maps $f,g:(D_1,\sim)\to(D_2,\sim)$ are equivalent, i.e., $f\sim g$, iff we have: $f^{-1}(O)=g^{-1}(O) \in \gamma_{(D_1, \sim)}$ for $O \in \gamma_{(D_2, \sim)}$.
 \end{itemize}
\end{lemma}

\begin{proof}
    (i) Suppose $f\sim f$ and $f^{-1}(O)$ is not R-open for R-open set $O$. Then there exists $x,y\in D_1$ with $x\sim y$, $x\in f^{-1}(O)$ and $y\notin f^{-1}(O)$. But then $f(x)\in O$ and $f(y)\notin O$ with $f(x)\sim f(y)$ which is a contradiction as $O$ is R-open. 
    Next suppose $f$ is R-continuous but $f$ is not self-related. Thus, there exists $x,y\in D_1 $ with $x\sim y$ and $f(x) \not\sim f(y)$. 
    Hence, there exists and R-open set $O\subseteq D_2$ with $f(x)\in O $ and $f(y)\notin O$. But then $f^{-1}(O)$ is R-open with $x\in f^{-1}(O)$ and $y\notin f^{-1}(O)$, which is a contradiction.
    
    (ii) Suppose $f$ and $g$ are equivalent, and $O\in \gamma_{(D_2,\sim)}$. If $r\in f^{-1}(O)$, then $f(r)\in O$ and since $O$ is R-open and $f(r)\sim g(r)$, it follows that $g(r)\in O$, i.e., $r\in g^{-1}(O)$. By symmetry, we have $f^{-1}(O)=g^{-1}(O)$. On the other hand suppose $f^{-1}(O)=g^{-1}(O)$ for all $O\in \gamma_{(D_2,\sim)}$  and $f(r)\not\sim g(r)$ for some $r\in (D_1,\sim)$. Then there exists $O\in \gamma_{( D_2,\sim)}$ with $f(r)\in O$ and $g(r)\notin O$. But then $r\in f^{-1}(O)$ whereas $r\notin g^{-1}(O)$, which is a contradiction. 
\end{proof}

\begin{lemma}\label{func-r-top}
 \begin{itemize}
     \item[(i)]  A Scott continuous map of the function space  $((D_1,\sim)\to(D_2,\sim))$ that is self-related is also R-continuous. 
     If $(D_2, \sim)$ is R-T$_0$ the converse holds.

     \item[(ii)] Given two Scott continuos maps $f,g:(D_1,\sim)\to(D_2,\sim)$, if $f, g$ that are equivalent then they are also R-continous and for any R-open set $O \in \gamma_{(D_2, \sim)}$, we have: $f^{-1}(O) \cap |D_1| = g^{-1}(O) \cap |D_1| $. 
     If $(D_2, \sim)$ is R-T$_0$ the converse holds.
 \end{itemize}
\end{lemma}

\begin{proof}
    (i) Suppose $f\sim f$,  for any R-open set $O$, $x \in f^{-1}(O)$ and $y \sim x$, we have $f(x) \sim f(y)$, $f(x)\in O$ and therefore $f(y)\in O$, it follows that $y\in f^{-1}(O)$ and therefore $f^{-1}(O)$ is R-open. 
    Next suppose $(D_2, \sim)$ is R-T$_0$, $f$ is R-continuous, for any pair of equivalent elements $x \sim y$, 
    and for any R-open set such that $f(x)\in O$ we have that $y \in f^{-1}(O)$, since $f^{-1}(O)$ is R-open, therefore $f(y) \in O$, by the generality of $O$ it follows that $f(x) \sim  f(y)$ and therefore $f$ is not self-related. 
    
    (ii) Suppose $f$ and $g$ are equivalent, and $O\in \gamma_{(D_2,\sim)}$. If $x \in f^{-1}(O) \cap |D_1|$, then $f(x)\in O$ and $x \sim x$, it follows $f(x)\sim g(x)$, and $g(x)\in O$, i.e., $x\in g^{-1}(O)$. By symmetry, we have $f^{-1}(O)  \cap |D_1| = g^{-1}(O) \cap |D_1|$. 
    On the other hand suppose $f^{-1}(O)  \cap |D_1| =g^{-1}(O)  \cap |D_1|$ for all R-open setes $O\in \gamma_{(D_2,\sim)}$,
for any pair $x \sim y$ and any R-open set such that $f(x)\in O$ we have that $y \in f^{-1}(O) = g^{-1}(O)$, since $f^{-1}(O)$ is R-open, therefore $g(y) \in O$, by the generality of $O$ it follows that $f(x) \sim  g(y)$. 
\end{proof}}


\section{Extended Random variables Monad}

To give semantics to the \emph{score operator}, which is commonly used to implement Bayesian inference or, more generally, score sampling, it is necessary to extend the semantics.  In particular, the semantics of an expression is associated not to a probability distribution but instead to a general measure. In our case, this generalization is achieved by transitioning from sample spaces of total measure $1$ to sample spaces having arbitrary  measure.
These measures are obtained by means of Scott continuous functions  $w : \Omega \to \overline{\realLine^+}$.
Given a sample space $(\Omega,\nu)$, equipped with the measure $\nu$, a weight function $w : \Omega \to \overline{\realLine^+}$ induces the measure $\nu_w$ defined by $\nu_w (O) =\int_{O} w \, d \nu $, for any measurable set $O$. 
\remove{Indeed, Equation~\ref{rel-density-int} can be easily checked to hold for simple functions $w$, which by the monotone convergence theorem then gives the equality for all measurable $w$. }

% We denote by $(\Omega, w)$ the sample space $\Omega$ with the measure induced by $w$. 

\begin{definition}
Given a PER domain $(D, \sim)$, the PER domain of extended random variables,  $\mathcal{R}_0(D, \sim)$, is the domain $(\Omega \to \overline{\realLine^+})  \times(\Omega \to D)$, with the partial equivalence relation defined by $(w_1, r_1) \sim (w_2, r_2)$ iff (i) $\forall \bfomega\in \Omega.\,r(\bfomega)\sim_D r(\bfomega)\,\&\,s(\bfomega)\sim_D s(\bfomega)$, and (ii) for every R-open set $O$ in $D$, $\nu_{w_1} (r_1^{-1}(O)) = \nu_{w_2}( r_2^{-1}(O))$.    
\end{definition}

Any continuous extended random variable defines a continuous valuation.

\begin{definition}
   Define the map $T_{0 \mathcal{R}_0(D,\sim)}: \mathcal{R}_0{{(D, {\sim)}}} \to \mathcal{V}(D, \sim)$, from extended random variables on $(D, \sim)$ to (non-normalized) continuous valuations on $(D, \sim)$ by
$ T_{0 \mathcal{R}_0(D, \sim) } (w, r) (O) = \nu_w (r^{-1} (O)) $. 
\end{definition}
We often write $T_0$ for $T_{0 \mathcal{R}_0(D, \sim) }$.  
Thus, $T_0 (w,r)$ is the pushforward measure of $\nu_w$ under $r$, denoted also by $r_*\, \nu_w$. Since ${T}_0(w,r)= F(w,\nu\circ r^{-1})=F(w,T(r))$, it follows from Proposition~\ref{int-on-basis}(ii) and computability of $T$ that ${T}_0$ is computable. By definition, the mapping $T_0$ preserves the equivalence relation on extended random variables.

It is easy to check that $\mathcal{R}_0$ is a functor, with the action of morphisms defined by: given $f : D_1 \to D_2$, $\mathcal{R}_0 f (w, r) = (w, f \circ r)$.

The functor $\mathcal{R}_0$ becomes a monad by letting 
$\eta_D : (D,  \sim~) \to \mathcal{R}_0(D, \sim)$ as: 
\[ \eta_D d = ((\lambda \bfomega \,.\, 1) , \ (\lambda \bfomega \,.\, d))\] and defining
$\mu_D : \mathcal{R}_0^2(D,  \sim) \to \mathcal{R}_0(D, \sim)$ as:
\[\begin{array}{ll}
\mu_D (w, r)  = &( (\lambda \boldsymbol{\bfomega} \,.\,  w (h_1 (\bfomega)) \cdot (\pi_1 (r (h_1 (\bfomega))))(h_2 (\bfomega)) , \\
     & \ \, (\lambda \bfomega \,.\, \pi_2 (r (h_1 (\bfomega)))(h_2 (\bfomega)  \ )
\end{array}
\] 
we note that in the above definition $r$ belongs to the domain $\Omega \to (\Omega \to \overline{\realLine^+}, \Omega \to D))$.

The correctness of the multiplication $\mu$ uses the following.

\begin{proposition}
If $h : \Omega \to (\Omega \times \Omega)$ is a measure preserving function, then $h$ is also a measure preserving function from $(\Omega, {(w_1 \circ h_1)  \cdot (w_2 \circ h_2)})$ to $(\Omega, {w_1}) \times (\Omega, {w_2})$, where by the expression $(w_1 \circ h_1)  \cdot (w_2 \circ h_2)$ we denote the weight function obtained by point-wise application of the product.
\end{proposition}


Any random variable can be readily transformed into an extended random variable. In fact, given $r : \Omega \to (D, \sim)$, the extended random variable $(\lambda \bfomega . 1, r)$ induces the same distribution as $r$, i.e., $T_0(\lambda \bfomega . 1, r) = T(r)$.

Let $r: \Omega \to \realDom$ be a random variable whose image lies on the maximal points $\operatorname{Max}(\realDom)$, i.e., it defines a function $r: \Omega \to \realLine$. If $r$ has probability density function $f: \realLine \to \realLine$, and $t : \realLine \to \realLine^+$ is a continuous function, the extended random variable $(t \circ r, r)$ induces a continuous valuation $T_0(t \circ r, r)$ defined by the density function $\lambda d . f(d) \cdot t(d)$. From this fact, we build the following example.
% \begin{example}
%   When $\Omega$ is the unit interval $[0,1]$, the map $T_0 (\lambda \bfomega . 1 , \lambda \bfomega . \bfomega)$ defines the uniform distribution on the interval $[0,1]$, while
% $T_0 (\lambda \bfomega . \bfomega, \lambda \bfomega . \bfomega)$ is a continuous valuation assigning to each interval in the form $[0,x]$, with $x\leq 1$, the value $x^2/2$. 
% \end{example}
\begin{example}
By the Box-Muller transform, a standard normal random variable \( Z_0 \) with mean $0$ and standard deviation $1$ is given by:
\[
Z_0(\bfomega) = \sqrt{-2 \ln (h_1 \bfomega)} \cdot \cos(2 \pi (h_2 \bfomega))
\]
The generalized random variable $(\lambda \bfomega . 1, Z_0)$ induces a continuous valuation defined by the density function of the normal distribution $\mathcal{N}(0, 1)$, that is:
\[T_0 (\lambda \bfomega . 1, Z_0) (a,b) = \int_a^b \frac{1}{\sqrt{2 \pi}}\exp{\left( -\frac{x^2}{2} \right)}\,dx\]

Using the normal distribution $\mathcal{N}(1, 1)$, with density
$f(x) = \frac{1}{\sqrt{2 \pi}} \exp{\left({(x - 1)^2}/{2} \right)}$, one can construct the generalized random variable given by $(f \circ Z_0, Z_0)$. It induces in turn the continuous valuation $T_0 (f \circ Z_0, Z_0)$, which
is characterized by the density function:
$ g(x) = \frac{1}{\sqrt{2 \pi}} \exp{\left( -\frac{x^2}{2} \right)} \frac{1}{\sqrt{2 \pi}} \exp{\left( -\frac{(x-1)^2}{2} \right)}$, 
simplified to: \[ g(x) = \frac{1}{2 \pi} \exp{-\left( x - \frac{1}{2} \right)^2}.\]
Note that $g$ corresponds to an unnormalized density function of the normal distribution \(\mathcal{N}\left( \frac{1}{2},  \left( \frac{1}{2}  \right)^2 \right) \), which is the posterior probability obtained from a prior normal distribution \(\mathcal{N}(0,1)\) conditioned on a normal distribution \(\mathcal{N}(1,1)\).
  
\end{example}

\medskip 

We next show that the conditional probability can be given also on extended random variables on PER domains $(D,\sim)$. Let us start by extending Equation~(\ref{rvc}).
\[\label{crv0}\operatorname{CR_0}:\mathcal{R}_0(D, \sim)\times \mathcal{E}(D,\sim)\to \mathcal{R}_0 (D,\sim)\]
$\operatorname{CR_0}((w,r),(O,O') )= (w', r')$ where 
\begin{multline*}\label{ervcn} (w'(\bfomega),r'(\bfomega))= \\
 \left\{\begin{array}{cl}
  (w\circ h_1\circ h_2^n(\bfomega), \, r \circ h_1\circ h_2^n(\bfomega))    & \exists n\in \nat \,.( i<n \Rightarrow \\
  &  r\circ  h_1\circ h_2^i(\bfomega)\in O' ,\\
  & \,\,  r \circ h_1 \circ h_2^n(\bfomega)\in O\\
     (0, \bot) & \mbox{otherwise}
 \end{array}\right.
 \end{multline*}

\begin{proposition}
  The map $\operatorname{CR_0}$ is self-related.
\end{proposition}


The map $\operatorname{CR_0}$ can be defined via the fixed-point operator in the following way: consider the Scott continuous map
\begin{multline*}
\Psi: (\mathcal{R}_0(D, \sim))\times\mathcal{E}(D,\sim)\times(\mathcal{R}_0(D,\sim)) \\
\to (\mathcal{R}_0(D,\sim))
\end{multline*}
\vspace{-5ex}
\begin{multline*}
  \Psi((w,r), (O_1,O_2), (w', r'))(\bfomega) \\
  =\left\{\begin{array}{ll}
  (w h_1 (\bfomega), r h_1(\bfomega))   &  r h_1(\bfomega)
\in O_1\\  (w' h_2(\bfomega), r' h_2(\bfomega))   &   r h_1(\bfomega)\in O_2\\
  (\lambda \bfomega \, . 0, \bot)  & \mbox{otherwise}
\end{array}\right.
\end{multline*}
We note that if $(w,r)$ and $(w',r')$ are step functions, then $\Psi((w,r), (O_1,O_2), (w', r'))$ is a step function for any basis element $(O_1,O_2)\in \mathcal{E}(D)$. Note also that $\operatorname{CR}_0((w,r),(O_1,O_2))$ is the least fixed point of $\Psi(((w,r),(O_1,O_2), -):\mathcal{R}_0(D) \to \mathcal{R}_0(D) )$ with  $(w',r')\mapsto\Psi((w,r), (O_1,O_2), (w', r'))$. 

Note also that, as in the previous section, an effective structure on $(D,=)$ induces an effective structure on the domain $\mathcal{R}_0(D,=)$ and thus on the PER domain $\mathcal{R}_0(D,\sim)$.

\begin{proposition}\label{CR0}
    The map $\operatorname{CR}_0$ is computable. 
\end{proposition}
{
\begin{proof}It is easy to check that $\Psi$, as an element in the domain $\mathcal{R}_0(D,\sim) \to \mathcal{E}(E ,\sim)\to \mathcal{R}_0(D,\sim)\to \mathcal{R}_0(D,\sim)$, is computable as a composition of the computable functions used in its definition. In fact, for any basic step functions $(w,r),(w',r'),(w'',r'')\in \mathcal{R}_0(D,\sim)$, and basis element $(O_1,O_2)\in \mathcal{E}(D,\sim)$, the relation $(w'',r'')\ll \operatorname{CR}_0((w,r),(O_1,O_2),(w',r'))$ is decidable since the latter is a computable step funcition. It follows that the map $\operatorname{CR}_0$ is computable. 
\end{proof}
}
Let $w=w'={\bf 1}$, the constant function with value $1$, to obtain the computability of $ \operatorname{CR}$ of the preceding section. 

On the domain of continuous valuations, we introduce the notion of {\em conditional valuation}: 
\begin{equation}\label{cond.eval}\operatorname{CV}_0: \mathcal{V}(D,\sim)\times \mathcal{E}(D,\sim)\to \mathcal{V}(D,\sim) \end{equation}
\begin{multline*}
    \operatorname{CV}_0(\alpha,(O_1,O_2))(U) \\
 = \left\{
 \begin{array}{ll}
   \begin{array}{ll} 
 \alpha(D)& \mbox{ if } \ \ \bot \in U\\
 0 & \mbox{ if } \ \ \bot \notin U \ \wedge \alpha(O_2) = \alpha(D) \\
 \end{array} & \\
 \alpha(O_1\cap U)/(1-(\alpha(O_2)/ \alpha(D))& \mbox{otherwise}
 \end{array} \right.  
\end{multline*}
 
 %Write ${\alpha(-|(O_1,O_2))}:=\operatorname{CV}(\alpha,(O_1,O_2))$.
  
\begin{theorem} \label{CVandCP}
 The map $\operatorname{CV}_0$ is Scott continuous and computable with respect to effective structures on $\mathcal{R}_0(D,\sim)$, $\mathcal{E}(D,\sim)$ and $ \mathcal{V}(D,\sim)$, and the following diagram commutes:   
 \[ 
 \begin{tikzcd}[row sep=huge, column sep=large]
\mathcal{R}_0(D,\sim)\times \mathcal{E}(D,\sim) \arrow{r}{\Large{T_0\times \operatorname{Id}}} \arrow[swap]{d}{\operatorname{CR_0}} 
& \mathcal{V}(D,\sim)\times \mathcal{E}(D,\sim) \arrow{d}{\operatorname{CV}_0} 
\\
\mathcal{R}_0(D,\sim)\arrow{r}{{T_{0}}} 
&  \mathcal{V}(D,\sim)
\end{tikzcd}
\]
\end{theorem}
{
\begin{proof}
 The Scott continuity and the commutativity of the diagram are straightforward. Note that for a simple valuation $\alpha$, the outpout $\operatorname{CV}_0(\alpha,(O_1,O_2))$ takes only a finite number of rational numbers. The computability of $\operatorname{CV}_0$ , for effective structures on  $\mathcal{V}(D,\sim)$ and $\mathcal{E}(D,\sim)$ follows, similar to Proposition~\ref{prob-comp}, for $\operatorname{CP}$. This time the decidability of the relation in Proposition~\ref{kirch}(i) for continuous valuations is required, which follows again since there are only a finite number of comparisons between rational numbers to check. 
\end{proof}
}
In the following, we consider pairs of dependent random variables and the conditional probability of one with respect to the values assumed by the other. For such cases it is convenient to use a derived notion of $\operatorname{CR}_0$ as follows:
\[\operatorname{CR}_0':\mathcal{R}_0(D \times E, \sim)\times \mathcal{E}(E,\sim)\to \mathcal{R}_0 (D,\sim)\]
$\operatorname{CR}_0' ( (w, (r,s)), (O, O')) = (w, r')$ \ \  if \\ $\operatorname{CR_0} ((w, (r,s)), (D \times O, D \times O')) = (w, (r', s')).$

\section{Bayesian updating}

In this section, we show that the conditional probability can be evaluated using the Bayes rules, on the hypothesis that the probability density of the likelihood is known.

In our domain setting, we first formulate the notions of density function and conditional density function.
Given a PER domain $(D, \sim)$, with a continuous valuation $\alpha$, and an extended random variable $(w, r) \in \mathcal{R}_0 (D, \sim)$, a \emph{density function}, $f_{(w, r)}$, for $(w, r)$, with respect to $\alpha$, is a continuous function in $(D, \sim) \to (\overline{\realLine^+}, =)$ such that for every R-open set $O$ in the $(D, \sim)$ one has:
\[ T_0(w, r)(O) = \int_{O}  f_{(w,r)} \,  d\alpha \] % = E( \nu, f_{(w,r)})\]
%The above equation is equivalent to $r^* \nu_{w} = \alpha_{f_{(w,r)})}$. 

Note that not  every extended random variable $(w,r)$ has a corresponding density function.  In particular, no simple random variable on $\realDom$, with the standard continuous valuation, has a density function.  
Moreover, any function $f'$ that coincide with $f_{(w,r)}$ on a subset of  full measure is also a density function for $(w, r)$.

Given an extended random variable $(w,(r,s))$ on the domain $(D \times E, \sim)$ with a continuous valuation $\alpha$, a \emph{density function of the conditional probability} $f_{(w,\, r \mid s)}$, with respect to $\alpha$, is a continuous function $(D \times E) \to \overline{\realLine^+}$ for which there exists a subset $S \subseteq (D \times E)$ of full measure such that for any pair $x, y \in S$, if $f_{(w, s)}(y) \neq 0$, the following equality holds:
 
\[f_{(w,\, r | s)}(x,y) = \frac{f_{(w, (r,  s))}(x,y)}{f_{(w,s)}(y)}\]
% if the density functions ${f_{(w, (r,  s))}(x,y)}, {f_{(w,s)}(y)}$ exists, 

We present an example of how classical conditional density functions are translated into our domain theory setting.
\begin{example}
    

Consider the case where $D = E = (\realDom, =)$, the PER domain of compact intervals with equality of real numbers as PER, and the continuous valuation $\alpha$ on $\realDom$ defined by $\alpha(O) = \lambda(O \cap \realLine)$, where, with an abuse of notation, we denote by $\realLine$ the set of maximal elements of $\realDom$, and $\lambda$ is the Lebesgue measure on the real line. By definition, the set $\realLine$ has full measure.

Given a pair of classical continuous random variables $X, Y : \Omega \to \realLine$, and a pair of continuous functions $f_X, f_{X|Y} : \realLine \to [0,\infty)$ that are, respectively, the probability density function of $X$ and the conditional probability density function of $X$ given $Y$, the pair $(\mathbf{1}, X)$ and $(\mathbf{1}, Y)$, where $\mathbf{1}: \Omega \to \overline{\realLine^+}$ is the constant function $1$, defines a pair of extended random variables on $\realDom$. 

Any continuous extension $f_{(\mathbf{1}, X)}, f_{(\mathbf{1}, X|Y)} : \realDom \to ([0,\infty),\leq)$ of $f_X, f_{X|Y}$ defines the density function of $(\mathbf{1}, X)$ and the conditional density function of $(\mathbf{1}, X)$ given $(\mathbf{1}, Y)$, respectively. The function $f_{(\mathbf{1}, X)}$ can be chosen as the maximal continuous extension of $f_X$, defined by:
\[
f_{(\mathbf{1}, X)}([a, b]) = \min \{ f_X(z) \mid z \in [a, b] \},
\]
and similarly for $f_{(\mathbf{1}, X|Y)}$.
\end{example}
 %    $(w, r), (w, r')$ be two independent random variables defining the normal distribution with mean $0$ and standard deviation $1$. By the Box-Muller transform they can be defined by:  $r(\bfomega) = \sqrt{-2 \ln (h_1 \bfomega)} \cdot \cos(2 \pi (h_2 \bfomega))$ and $r'(\bfomega) = \sqrt{-2 \ln (h_1 \bfomega)} \cdot \cos(2 \pi (h_2 \bfomega))$,  .    Define the random variable $(w, s)$ as the pointwise addition of $(w, r)$ and $(w, r')$   $s(\bfomega) = r(\bfomega) + r'(\bfomega)$.   
 % The density functions for $f(w, r) =  f(w, r'): \realDom \to \overline{\realLine^+}$ can be defined as any maximal extension to the whole domain of  to the function the fur

\remove{-------------------------------

Alternative to the above definition (where E(D) denotes the domain of disjoint pairs of open sets of D:

 The \emph{density function of the conditional probability} $f_{(w,\, r | s)}:D_1\times \mathcal{E}(D_2)\to \overline{\realLine^+}$ is given by

 \[f_{(w,\, r | s)}(x,(O_1,O_2)) 
 = \frac{\int_{O_1}f_{(w, (r,  s))}(x, \_)\, d \alpha_E}
    {\int_\Omega w\,d\nu - \int_{O_2} f_{(w, s)} d \alpha_E}  \]

    where $\alpha_{E}(O)$ is the marginal measure define by $\alpha_{E}(O) = \alpha(D \times O)$.
-------------------------------------}

Next, we relate the conditional probability density function $f_{(w,\, r | s)}$ to the
conditional probability map $\operatorname{CR}_0'$.

\begin{lemma} \label{CR-PDF}
    Given $(w, (r, s)) \in  \mathcal{R}_0 ( D \times E, \sim)$ and a continuous valualtion $\alpha$ on $( D \times E, \sim)$, if the density functions ${f_{(w, (r,  s))}(x,y)}, {f_{(w,s)}(y)}$ exists, then:
    \begin{multline*}
    T_0 (\operatorname{CR}_0' (w,(r,s)),  (O_1, O_2))(O) = \\
    \frac{\int_{O \times O_1} f_{(w,\, (r, s))} \, d\alpha}{1 - (\int_{O_2} f_{(w, s)}\, d\alpha_{E} / \int_\Omega  w \, d \nu )}    
    \end{multline*}
\end{lemma}
{
\begin{proof}
    The following chain of equations holds:

    \begin{align*}
      &  \ T_0 (\operatorname{CR}_0' (w,(r,s)), (O_1, O_2))(O) \\
    =  & \   T_0 (\operatorname{CR}_0 (w,(r,s)), (D\times O_1, D\times O_2))(O \times E) \hfill \ \ \ \\ & \ \text{by Theorem \ref{CVandCP}}\\
    =  &  \ \operatorname{CV}_0 (T_0(w, (r,s)),   (D\times O_1, D\times O_2))(O \times E)\\
    =  & \ \frac{T_0 (w,(r,s))((O \times E) \cap (D\times O_1) )}{1 - (T_0 (w,(r,s))(D \times O_2)/ (T_0 (w,(r,s))(D \times E))}   \\
    =  &  \ \frac{T_0 (w,(r,s))(O \times O_1)}{1 - (T_0 (w,s)(O_2) / \int_\Omega  w \, d \nu )}  \\
    =  &  \  \frac{\int_{O \times O_1} f_{(w,\, (r, s))}\, d\alpha}{1 - (\int_{O_2} f_{(w, s)}\, d\alpha_E / \int_\Omega  w \, d \nu )} 
    \end{align*}
\end{proof}
}

% \begin{lemma}
% Let $b \in E$, and $\langle O_i, O'_i \rangle_{i \in \nat}$ a list of events in $E$ such that $\{b\} = \bigcap_{i\in \nat} O_1 = \bigcap_{i\in \nat} (O'_1)^c$ and $\lim_{i \to \infty} \alpha_E(O_i)/ \alpha_E (O'_i)^c = 1$, the following equality holds:
% % On the special case where $E = \realDom$  and the support of the valuation contains only maximal element of $\realDom$ from the above equation one can derive: 
% \begin{multline*}
%   \int_{O \times  O_1} f_{(w,\, r | s)} \, d \alpha \\
%   =  T_0 (\operatorname{CR}' (w,(r,s)),  (O_1, (O_1^c)^\circ)(O)
% \end{multline*} 
% \end{lemma}
% \begin{proof}
% \begin{align*}
%   &  T_0 (\operatorname{CR}' (w,(r,s)),  (O_1, (O_1^c)^\circ)(O) \\
% = & \frac{\int_{O \times O'} f_{(w,\, (r, s))} \, d\alpha}{1 - (\int_{O_i} f_{(w, s)}\, d\alpha_E / \int_\Omega  w \, d \nu )} \\
% = & \lim_{i \to \infty} \frac{\int_{O \times O_i} f_{(w,\, (r, s))} \, d\alpha}{\int_{(O'_i)^c} f_{(w, s)}\, d\alpha_E} \cdot \int_\Omega  w \, d \nu \\
% \in & \lim_{i \to \infty} \left[
% \frac{ \alpha_E(O_i) \cdot \argmin_{y \in O_i}\int_{O}f_{(w,\, (r, s))(\_,y)} \, d\alpha_1}{\alpha_E(O'_i)^c \cdot \max_{y \in (O'_i)^c} f_{(w, s)} (y)} ,
% \frac{ \alpha_E(O_i) \cdot \max_{y \in O_i}\int_{O}f_{(w,\, (r, s))(\_,y)} \, d\alpha_1}{\alpha_E(O'_i)^c \cdot \min_{y \in (O'_i)^c} f_{(w, s)} (y)} 
% \right] \cdot \int_\Omega  w \, d \nu \\
% \end{align*}
%\end{proof}

% In the proofs of the results in the rest of this section, 
For a real number $a\in \realLine$ and $\epsilon>0$, we use the notation $a\pm\epsilon:=[a-\epsilon,a+\epsilon]$

{
\begin{lemma}\label{int-cond-rand-var}
For any extended random variable $(w, (r, s)) \in  \mathcal{R}_0 ( D \times E, \sim)$, continuous valuation $\alpha$ on $( D \times E, \sim)$, conditional density function ${f_{(w, (r |  s))}(x,y)}$, open set $O \subseteq D$ and element $e \in E$,  such that 
$f_{(w, s)}(e) \neq 0$,
we have:
\begin{enumerate}
    \item  if $\alpha_E(\dua e) \neq 0$ and $\alpha_E(\dua e \cap ((\dua e )^c)^\circ)^c = 0$ then 
\begin{multline*}
  \int_{O} f_{(w,\, r | s)}(x,e) d \alpha_D(x) \\
  \leq (T_0 (\operatorname{CR}' (w,(r,s)),  (\dua e, ((\dua e )^c)^\circ) (O)) / \int_\Omega  w \, d \nu
\end{multline*} 
\item 
if
% if the set $M$ of maximal elements in $(D \times E)$, $M = \operatorname{Max}(D \times E)$, has full measure and the restriction of the conditional density function on $M$, i.e., ${f_{(w, (r,  s))}|_M} : M \to \overline{\realLine^+}$, is continuous with respect to the Euclidean topology on $\overline{\realLine^+}$, and there exists a base $B$ for $E$ such that $\forall b \in B \,.\, \alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ then, for any $\epsilon > 0$ there exists $b \in B$ such that: $e \in \dua b$ and     

\begin{itemize}
\item
the conditional density function $f_{(w, r | s)}$ is bounded on the subset $O \times \{e\}$,
\item
there exists a subset $M$ of full measure in $(D \times E)$, such that the restriction of the conditional density function on $M$, i.e., $f_{(w, r | s)}|_M : M \to {\realLine^+}$, is continuous with respect to the Euclidean topology on ${\realLine^+}$,
\item
there exists a base $B$ for $E$ such that $\forall b \in B \,.\, \alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ 
\end{itemize}
then, for any $\epsilon > 0$ there exists $b \in B$ such that: $e \in \dua b$

\begin{multline*}
T_0 (\operatorname{CR}' (w,(r,s)),  (\dua b, ((\dua b )^c)^\circ) (O) / \int_\Omega  w \, d \nu  \\
  \in \left( \int_{O} f_{(w,\, r | s)}(x,e) d \alpha_D(x) \right)\pm \epsilon
\end{multline*}     
% \begin{multline*}
%   \left| \int_{O} f_{(w,\, r | s)}(x,e) d \alpha_D(x)\right. \\\left.
%   - (T_0 (\operatorname{CR}' (w,(r,s)),  (\dua b, ((\dua b )^c)^\circ) (O)) / \int_\Omega  w \, d \nu \right| < \epsilon
% \end{multline*}     
\end{enumerate}

\end{lemma}
\begin{proof}
Point (i) is proved by the following chain of relations:
\begin{align*}
  & T_0 (\operatorname{CR}_0' (w,(r,s)),  (\dua b, ((\dua b )^c)^\circ)(O)) / \int_\Omega  w \, d \nu
\\
= &\frac{\int_{O \times \dua b} f_{(w,\, (r, s))}(x,y) \, d\alpha_D(x) d\alpha_E(y)}
    {\int_\Omega  w \, d \nu - \int_{((\dua b )^c)^\circ} f_{(w, s)}(y)\, d\alpha_E(y) } 
\\
= &\frac{\int_{O} (\int_{\dua b} f_{(w,\, (r \mid s))}(x,y) \cdot f_{(w, s)}(y)\, d\alpha_E(y)) \, d\alpha_D(x)}
    {\int_{\dua b} f_{(w, s)}(y) \, d\alpha_E(y)}  
    \\
\geq &\frac{\int_{O} (\int_{\dua b} f_{(w,\, (r \mid s))}(x,b) \cdot f_{(w, s)}(y)\, d\alpha_E(y)) \,  d\alpha_D(x)}
    {\int_{\dua b} f_{(w, s)}(y) \, d\alpha_E(y)} 
    \\
= &\int_{O}  f_{(w,\, (r \mid s))}(x,b) \cdot  \frac{\int_{\dua b}f_{(w, s)}(y) \, d\alpha_E(y)}
    {\int_{\dua b} f_{(w, s)}(y) \, d\alpha_E(y)} \, d\alpha_D(x)
    \\
= &\int_{O}  f_{(w,\, (r \mid s))}(x,b) \,  d \alpha_D(x) \\
\end{align*}

 Point (ii), let $\epsilon' = {\epsilon}/{(3 \cdot \alpha_D(O))}$, by continuity, for any $d \in O$ there exists a neighbourhood, $O_i$, of $d$,  and a base approximation $b_i$ of $e$, such that $\forall (d', e') \in (O_i \times \dua b_i) \cap S \,.\, | f_{(w,\, (r \mid s))}(d',e) - f_{(w,\, (r \mid s))}(d',e')| \leq \epsilon'$. Let $k > 1$ be a bound for the set of real values $f_{(w,\, (r \mid s))}[(O, e)]$, and let $I'$ be a finite subset of indexes such that, having defined $O' = \bigcup_{i\in I'} O_i$ one has $\alpha_D(O) - \alpha_D(O') < {\epsilon}/{(3 \cdot k)}<\epsilon/3$, let $b = \bigsqcup_{i \in I'}b_i$. By repeating the first steps in the previous chain of equations, we have: 

\begin{align*}
  & T_0 (\operatorname{CR}_0' (w,(r,s)),  (\dua b, ((\dua b )^c)^\circ)(O)) / \int_\Omega  w \, d \nu
\\
= &\frac{\int_{O} (\int_{\dua b} f_{(w,\, (r \mid s))}(x,y) \cdot f_{(w, s)}(y)\, d\alpha_E(y)) \, d\alpha_D(x)}
    {\int_{\dua b} f_{(w, s)}(y) \, d\alpha_E(y)}  
    \\
\in &\frac{\int_{O'} (\int_{\dua b} f_{(w,\, (r \mid s))}(x,e) \cdot f_{(w, s)}(y)\, d\alpha_E(y)) \,  d\alpha_D(x)}
    {\int_{\dua b} f_{(w, s)}(y) \, d\alpha_E(y)}  \pm 2 \epsilon /3
    \\
= &\int_{O'}  f_{(w,\, (r \mid s))}(x,e) \,  d \alpha_D(x) \pm 2 \epsilon /3 
\\
\subseteq  &\int_{O}  f_{(w,\, (r \mid s))}(x,e) \,  d \alpha_D(x) \pm \epsilon \\
\end{align*}


\end{proof} 
}

{
In the case where $E$ is the domain of real numbers $\realDom$, or a finite product of $\realDom$, and the measure $\alpha_E$ is the measure inherited from the Lebesgue measure on $\mathbb{R}$, the conditions in point (ii) are satisfied: the set of maximal elements has full measure and $\alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ is satisfied by any element $b$ in $E$. It follows that the condition also holds if the measure $\alpha_E$ is absolutely continuous with respect to the measure on the finite products of $\mathbb{R}$ inherited from the Lebesgue measure.
}
% \begin{align*}
%   & \lim_{i \to \infty}  T_0 (\operatorname{CR}' (w,(r,s)),  (O_i, O'_i)(O) \\
% = & \lim_{i \to \infty} \frac{\int_{O \times O_i} f_{(w,\, (r, s))} \, d\alpha}{1 - (\int_{O'_i} f_{(w, s)}\, d\alpha_E / \int_\Omega  w \, d \nu )} \\
% = & \lim_{i \to \infty} \frac{\int_{O \times O_i} f_{(w,\, (r, s))} \, d\alpha}{\int_{(O'_i)^c} f_{(w, s)}\, d\alpha_E} \cdot \int_\Omega  w \, d \nu \\
% \in & \lim_{i \to \infty} \left[
% \frac{ \alpha_E(O_i) \cdot \min_{y \in O_i}\int_{O}f_{(w,\, (r, s))(\_,y)} \, d\alpha_1}{\alpha_E(O'_i)^c \cdot \max_{y \in (O'_i)^c} f_{(w, s)} (y)} , \\
% &
% \frac{ \alpha_E(O_i) \cdot \max_{y \in O_i}\int_{O}f_{(w,\, (r, s))(\_,y)} \, d\alpha_1}{\alpha_E(O'_i)^c \cdot \min_{y \in (O'_i)^c} f_{(w, s)} (y)} 
% \right] \cdot \int_\Omega  w \, d \nu \\
% \end{align*}

{
\begin{lemma}\label{relative-density}
For any extended random variable $(w, r) : \Omega \to (D, \sim)$ and a continous function $f (D, \sim ) \to \overline{\realLine^+ }$, the following equality among continuous valuations holds:
\[
 \, F (T_0(w,r)) \, f = T_0( (w \cdot (f \circ r)), \ r)
\]
\end{lemma}
\begin{proof}
Lemma~\ref{relative-density} follows by letting $g=f\circ r$ in Equation~\ref{rel-density-int}. In fact: 
$$
\begin{aligned}
& F \, (T_0(w,r)) \, f \, O = F \, (r^*\nu_{w}) \, f \, O \ = \ \int_O f \, d (r^*\nu_{w}) \\
& = \int_{r^{-1}(O)} f \circ  r \, d \nu_w \ = \ \int_{r^{-1}(O)}(f \circ r) \cdot w \, d\nu  \\
& = T_0( (w \cdot (f \circ r)), \ r) O
\end{aligned}
$$
\end{proof}
}
There are two different approaches to evaluating conditional probability: a general approach that uses the $\operatorname{CR}'_0$ operator, discharging the traces of computation where the condition is not satisfied, and a second, more efficient approach that applies Bayes' rule. The latter assumes that the dual conditional density function is known and uses the score operator.
The following theorem states that these two approaches yield consistent results.
\begin{theorem} \label{bayes-rule}
Given an extended random variable $(w, (r, s)) \in  \mathcal{R}_0 (D \times E, \sim)$  such  that the dual random variable  $(w, (s, r)) \in  \mathcal{R}_0 (E \times D, \sim)$, has a conditional density function  $f_{(w, s | r)}$,  we have that, for any  value $e \in E$, such that $f_{(w,s)(e) \neq 0}$ we have that 
\begin{enumerate}
 \item  if $\alpha_E(\dua e) \neq 0$ and $\alpha_E(\dua e \cap ((\dua e )^c)^\circ)^c = 0$ then 
\begin{multline*}
  T_0 ((\lambda \bfomega \, .\,  w(\bfomega) \cdot f_{(w, s | r)}(b, r(\bfomega) ) / f_{(w,s)} (b)), r) \\
  \sqsubseteq T_0 (\operatorname{CR}_0' (w,(r,s)),  (\dua e, ((\dua e )^c)^\circ)  / \int_\Omega  w \, d \nu
\end{multline*} 
\item 
if 
% the set $M$ of maximal elements in $(D \times E)$, $M = \operatorname{Max}(D \times E)$, has full measure and the restriction of the conditional density function on $M$, i.e., ${f_{(w, (r,  s))}|_M} : S \to \overline{\realLine^+}$, is continuous with respect to the Euclidean topology on $\overline{\realLine^+}$, and there exists a base $B$ for $E$ such that $\forall b \in B \,.\, \alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ 
\begin{itemize}
\item
the conditional density function $f_{(w, r | s)}$ is bounded on the subset $O \times {e}$,
\item
there exists a subset $M$ of full measure in $(D \times E)$, such that the restriction of the conditional density function to $M$, i.e., $f_{(w, r | s)}|_M : M \to \overline{\realLine^+}$, is continuous with respect to the Euclidean topology on $\overline{\realLine^+}$,
\item
there exists a base $B$ for $E$ such that $\forall b \in B \,.\, \alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ 
\end{itemize}
then, for any $\epsilon > 0$ there exists $b \in B$ such that: $e \in \dua b$ and     
\begin{multline*}
  T_0 (\operatorname{CR}_0' (w,(r,s)),  (\dua b, ((\dua b )^c)^\circ) (O)) / \int_\Omega  w \, d \nu 
  \\
 \in 
    T_0 ((\lambda \bfomega \, .\,  w(\bfomega) \cdot f_{(w, s | r)}(e, r(\bfomega) ) / f_{(w,s)} (b)), r)(O)
     \pm \epsilon
\end{multline*}     
\end{enumerate}
\end{theorem}
{
\begin{proof}
By the previous lemma and Equation~\ref{rel-density-int}, one can write: 
\[
\begin{aligned}
& = T_0( (\lambda \bfomega \, .\,  w(\bfomega) \cdot f_{(w, s | r)}(e, r(\bfomega) ) / f_{(w,s)} (e)), r) O \\
& = T_0( (w \cdot (f_{(w, s | r)}(e, \_ ) / f_{(w,s)}(e)) \circ r), r)) O \\
& = \int_O (f_{(w, s | r)}(e, x ) / f_{(w,s)}(e)) \, d (r^*\nu_{\bfomega}) (x) \\
& = \int_O (f_{(w, (s,r))}(e, x ) / (f_{(w,r)}(x) \cdot f_{(w,s)}(e))) \, d ((\alpha_D)_{f_{(w,r)}}) (x) \\
& = \int_O f_{(w, (r,s)}(x, e) / f_{(w,s)}(e) \, d \alpha_D (x) \\
& = \int_O f_{(w, r|s}(x, e) \, d \alpha_D (x) \\
\end{aligned}
\]
Both points (i) and (ii) follow from the above equality and from Lemma~\ref{int-cond-rand-var}.
\end{proof}
}
In the case where $E$ is the domain of real numbers $\realDom$, or a finite product of $\realDom$, and the measure $\alpha_E$ is the measure inherited from the Lebesgue measure on $\mathbb{R}$, the conditions in point (ii) are satisfied: the set of maximal elements has full measure and $\alpha_E(\dua b \cap ((\dua b )^c)^\circ)^c = 0$ is satisfied by any element $b$ in $E$. It follows that the condition also holds if the measure $\alpha_E$ is absolutely continuous with respect to the measure on the finite products of $\mathbb{R}$ inherited from the Lebesgue measure.

\begin{example} A standard example where the above statement can be applied is when $(w, (a,b))$ is a random variable representing the prior distribution of two coefficients in a function $g_{(a,b)}(x)$, for example the linear function $g_{a,b}(x) = ax + b$. The random variable $(w, s)$ represents the prior distribution of measurements of $g_{a,b}(1)$, with the hypothesis that the measurement is obtained using instruments affected by error $e$, whose probability distribution is described by a random variable $(w,e)$ following a normal distribution with mean $0$ and variance $\sigma^2$. The random variables $(w,(a,b))$ and $(w,e)$ are independent, while $(w,(a,b))$ and $(w,s)$ are related by the formula: $s = g_{a,b}(1) + e$.
In this case, the conditional probability is given by the formula:  % (not the ) 
\[
f(w, s \mid (a,b)) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(s - g_{a,b}(1))^2}{2\sigma^2}\right).
\]
\end{example}

\remove{
    
\subsection{R-topology in basic higher types}

To obtain computability results for conditional random variables for some basic higher order types, we need to characterise the R-topology and show that for these basic types its lattice of open sets as well as its space of disjoint event-pairs are equipped with an effective structure with which conditional probability is computable.  
\begin{proposition} \label{w=r}
The $R$-topology, on the space of random variables, $(\Omega\to D)$, where $D\in \BC$, is the weakest topology making the function $T:(\Omega\to D)\to PD$ continuous.
\end{proposition}

\remove{\begin{proof}
    It is an immediate conseguece of Theorem~\ref{random-valuation}. For any open set $O$ in the $R$-topology we have $O = T^{-1}(T(O))$, that is $O$ is the inverse image of the open set $T(O)$.
\end{proof}}
\begin{proof}
  We need to prove that $U\subset (\Omega\to D)$ is R-open iff there exists Scott open set $O\subset PD$ with $U=T^{-1}(O)$. 
  We first show that for any open set $O\subset PD$, the set $T^{-1}(O)\subset (\Omega\to D)$ is an R-open set. In fact, if $r\sim s$ then, we have: $T(r)=T(s)$ and thus: $$r\in T^{-1}(O) \iff T(r)\in O \iff T(s)\in O \iff s\in T^{-1}(O).$$ 
  Next, we show that the weakest topology induced by $T$ is finer than the R-topology. Assume the subset $U\subset (\Omega\to D)$ is R-open and let $r\in U$. By Proposition~\ref{way-below-random}, let $s\in U$ be a simple random variable with $s\ll r$ such that $T(s)\ll T(r)$.  
  Then, 
  % $T(s)$  is a simple valuation. 
  $r \in T^{-1}(\dua T(s))$ and $T^{-1}(\dua T(s)) \subseteq U$. In fact, let $f\in T^{-1}(\dua T(s))$ be a simple random variable, i.e., $T(s)\ll T(t)$. Since $T(s)\ll T(t)$, there exists, by Lemma~\ref{eq-uniformity}, a simple random variable $f'$ with $s\sqsubseteq t'$ and $T(t')=T(t)$. Then $t'\in U$ and since $U$ is closed under $\sim$ we also have $t \in U$. Thus $ T^{-1}(\dua T(s))\subset U$. 
\end{proof}
\begin{corollary}
   A basic open set of the R-topology on $(\Omega\to D)$ for $D\in \BC$ is given by $T^{-1}(\dua \sigma)$, where $\sigma\in PD$ is a simple valuation.
\end{corollary}
Denote the lattice of R-open sets of the PER domain $(D,\sim)$ by $\gamma(D)$, by the previous proposition we immediately have. 
\begin{corollary}
 The frame map $T^{-1}: \mathcal{O}{PD}\to\gamma_{(\Omega\to D)}$ is a lattice isomorphism.   
\end{corollary}
\begin{proof}
  Since $T^{-1}(O)$ for $O\in \Sigma (\mathcal{V}(D)$, by Proposition~\ref{w=r}, gives all the R-open sets of $(\Omega\to D)$, we conclude that $T^{-1}:\Sigma(PD)\to \gamma{(\Omega\to D)}$ is a lattice isomorphism. 
\end{proof}
Remark:  Without going into the details, we recall that the Stone Duality theorem holds for continuous domains. That is, there is an isomorphism between any continuous domain \(D\) and the set of completely prime filters in the lattice of open sets of \(D\). From the preceding corollary, it follows that \(PD\) is isomorphic to the set of completely prime filters in \(\gamma_{(\Omega \to D)}\). Each completely prime filter of open sets consists of Scott open neighbourhoods of upper sets of the form $\bigcup_{T(r)=\sigma} \uparrow \hspace{-.5ex}r$ for $\sigma\in PD$.  

We can also give an intrinsic characterisation of the  basis $T^{-1}(\dua \sigma)$ of the R-topology on $(\Omega\to D)$, where $\sigma\in B_{PD}$, as follows.
\begin{corollary}\label{r-open-basis}
  Consider a finite list of pairs $(d_i,  q_i)$, with $d_i\in D$, dyadic numbers $q_i>0$ for $1\leq i\leq n$ and $\sum_{i=1}^nq_i<1$. Then, we have $r\in T^{-1}(\dua \sigma)$ for $\sigma=\sum_{0\leq i\leq n} q_i\delta(d_i)$, where $d_0=\bot$ and $q_0=1-\sum_{1\leq i\leq n}q_i$, iff there are pairwise disjoint basic open sets $U_i\subseteq \Omega$ with $q_i=\nu(U_i)$, $U_i\ll r^{-1}(\dua d_i)$ and $q_i<\nu(r^{-1}(\dua d_i))$ for $1\leq i\leq n$. 
\end{corollary}
\begin{proof}
Let $\sigma$ be given as above and $r\in T^{-1}(\dua \sigma)$. Then, by~\cite[Proposition 3.7]{DE24}, there exist disjoint open subsets $U_i\subseteq \Omega$ with $\nu(U_i)=q_i$,  $U_i\ll r^{-1}(\dua d_i)$ and $q_i<\nu(r^{-1}(\dua d_i))$ for $1\leq i\leq n$, which satisfy $s:=\sup_{0\leq i\leq n}d_i\chi_{U_i}\ll r$ and $T(s)=\sigma$. Conversely, suppose  there are pairwise disjoint basic open sets $U_i\subseteq \Omega$ with $q_i=\nu(U_i)$, $U_i\ll r^{-1}(\dua d_i)$ and $q_i<\nu(r^{-1}(\dua d_i))$ for $1\leq i\leq n$. Then, by Proposition~\ref{simp-val-way}, we have $\sigma\ll T(r)$.  
\end{proof}

\begin{proposition}\label{r-open-basis}
  Consider a finite list of pairs $(d_i,  q_i)$, with $d_i\in D$, dyadic numbers $q_i>0$ for $1\leq i\leq n$ and $\sum_{i=1}^nq_i<1$. Let $\sigma=\sum_{0\leq i\leq n} q_i\delta(d_i)$, where $d_0=\bot$ and $q_0=1-\sum_{1\leq i\leq n}q_i$, the following statement are equivalent:
\begin{enumerate}
    \item [(i)] $r\in T^{-1}(\dua \sigma)$;
    \item [(ii)] for all $J\subseteq I\setminus \{i_0\}$ we have: 
    \[\sum_{j\in J} p_j \, \, < \nu\left( r^{-1}\left(\bigcup_{j\in J} \dua d_j\right)\right);\] 
    \item [(iii)]  there are pairwise disjoint basic open sets $U_i\subseteq \Omega$ with $q_i=\nu(U_i)$, $U_i \ll r^{-1}(\dua d_i)$ and $q_i<\nu(r^{-1}(\dua d_i))$ for $1\leq i\leq n$. 
\end{enumerate}  
\end{proposition}


Note that, in the proof of Corollary~\ref{r-open-basis},  for the probability space $\Omega_0$, the relation $d_i\chi_{U_i}\ll r$ implies $q_i=\nu(U_i)<\nu(r^{-1}(\dua d_i))$ for $i\in I$ as the map $T$ is open in this case, but for probability spaces $\Sigma^\nat$ and $[0,1]$ we need the condition $q_i=\nu(U_i)<\nu(r^{-1}(\dua d_i))$, in addition to $d_i\chi_{U_i}\ll r$, for $i\in I$. 
There is a more compact form to represent the basis of the R-topology on $(\Omega\to D)$: 
\begin{corollary}\label{countable-uion-r-open}
 For a simple valuation $\sigma\in PD$, we have:
 \[T^{-1}(\dua \sigma)=\bigcup\left\{\dua r:r \mbox{ simple random variable with }\sigma\ll T(r)\right\}.\]
\end{corollary}
It is convenient to have a notation for this intrinsic definition of the R-open basis. 
\begin{equation}\label{infinite-r-open}\Xi_{1\leq i\leq n}[q_i\to \dua d_i]:=T^{-1}\left(\dua \left(\sum_{0\leq i\leq n} q_i\delta(d_i)\right)\right)
\end{equation}
for the normalised valuation $\sum_{0\leq i\leq n} q_i\delta(d_i)$, where $d_0=\bot$ and $q_0=1-\sum_{1\leq i\leq n}q_i$. When $n=1$, we drop the  sign $\Xi$ and simply write: $[q_1\to \dua d_1]$ instead of $\Xi [q_1\to \dua d_1]$. Note that, using this notation, $[q_1\to \dua d_1]$ is precisely the set defined in Definition~\ref{simple-R-open}. 
\remove{We also note that if $D=\realDom$, then $\Xi$ will simply be the pointwise extension of sum of (interval-valued) random variables.} 

\begin{proposition}\label{R-open-iff}
  The R-topology $\gamma_{(\Omega\to D)}$ satisfies:  
  \[r\sim s \iff \forall U \in \gamma_{(\Omega\to D)}. (r\in U \iff s\in U).\]
\end{proposition}
\begin{proof}
    The LHS to RHS implication is simply the definition of R-open sets. To prove the RHS to LHS implication, assume $r\not \sim s$. There exists a simple random variable $r_0\ll r$, with $r_0 {=\sup_{i\in I} d_i\chi_{O_i}}$, such that there exists no simple random variable $s_0\ll s$ with $r_0\sim s_0$, since otherwise we will obtain $r\sim s$ by the closure of the equivalence relation under taking supremums. But then, we have: $r\in \dua r_0\subseteq \bigcap_{i\in I} [\nu(O_i)\to \dua d_i]$, whereas $s\notin [\nu(O_i)\to \dua d_i]$ where the latter set is R-open. 
\end{proof}

\begin{corollary}
    Suppose $D$ and $E$ are bounded complete domains. If $f:(\Omega\to D)\to (\Omega\to E)$ is continuous with respect to the R-topology, then $r\sim s$ implies $f(r)\sim f(s)$
\end{corollary}
\begin{proof}
Suppose $r\sim s$ but $f(r)\sim f(s)$ does not hold. Then, by the previous proposition, there exists an open set $U$ in the R-topology of $(\Omega\to E)$ separating $f(r)$ from $f(s)$. But this implies that $f^{-1}(U)$ separates $r$ from $s$.
\end{proof}


% \section{Characterisation of the R-topology} \label{characterization-R-topology}
\remove{From this point on, we use the samples spaces $(0,1)$ or $2^\nat_0$, i.e., we work with $A_0$. This means that the map $T:(\Omega_0\to D)\to PD$ preserves the way-below relation. We also use the basis $B$ (which we call simple random variables) of $(\Omega_0\to D)$ provided in Lemma~\ref{way-below-A-0}. In particular, this means that for any simple random variable $r\in (\Omega_0\to D)$, we have $\dua r\neq \emptyset$. We first consider a ground PER domain $\langle D,\sim_D\rangle$ with $\sim_D=\operatorname{Id}$.}



\remove{\begin{proposition}
The R-topology on $(\Omega\to D)$ is generated by a subbasis consisting of Scott open sets of the form $[q \to O]$, with $O\in \Omega D$ and dyadic $q\in [0,1]$.
\end{proposition}

\begin{proof}
By the previous Proposition~\ref{w=r}, the inverse images of the elements of a subbasis for the Scott topology on $\mathcal{P}(D)$ form a subbasis for the R-topology.
By Corollary~\ref{simplest-simple-way-below}, a subbasis of the Scott topology on $\mathcal{P}(D)$ is given by sets of the form:
$$O(q,d):=\dua (q\delta(d) +(1-q) \delta(\bot))$$ with $d$ belonging to a basis of $D$, $q$ rational number and $0\leq q\leq 1$.  
We shall show that $[q\to \dua d] = T^{-1}(O(q,d))$.

To prove the inclusion $[q\to \dua d] \subseteq T^{-1}(O(q,d))$, i.e.,  $T([q\to \dua d]) \subseteq O(q,d)$, since $[q\to \dua d]$ is Scott open, it suffices to show that for any step function $f=\sup_{i\in I} d_i\chi_{O_i}\in [q\to \dua d]$, where $d_i$'s are assumed to be distinct and $O_i$ disjopints, we have $T(f)\in O(q,d)$. But $f\in [q\to \dua d]$ implies that 
\[\nu(f^{-1}(\dua d))=\nu(\bigcup_{d\ll d_i}O_i)>q.\]
On the other hand, we have \[T(f)=\nu\circ f^{-1}=\sum_{d\ll d_i}\nu(O_i)\delta(d_i)+\sum_{d\ll\hspace{-1ex}\not \;\;d_i}\nu(O_i)\delta(d_i) \]
Hence, 
\[\sum_{d\ll d_i}\nu(O_i)=\sum_{d\ll d_i} \nu(\bigcup O_i) >q\]
and thus by Corollary~\ref{simplest-simple-way-below} we have $T(f)\in O(q,d)$. 

To prove the opposite inclusion, $[q\to \dua d]\supset T^{-1}O(q,d)$, it is sufficient to show that if a simple valuation $u=\sum_{i\in I}q_i\delta(d_i)\in O(q,d)$, then any function $f:A\to D$ with $Tf=u$ satisfies $f\in[q\to \dua d]$. In fact, any such $f$ will satisfy $\nu\circ f^{-1}=u$ and thus 
$\nu (f^{-1}(\dua d))=\sum_{d\ll d_i} q_i>q$ by Corollary~\ref{simplest-simple-way-below}. i.e., $f\in[q\to \dua d]$.
\end{proof}}

%\subsection{R-topology in higher orders} Denote the map $T:(\Omega\to D)\to PD$ , introduced earlier in this paper, by $T_{RD\to PD}:=T$.



Next, we characterise the R-topology of $(\Omega\to ((\Omega\to D))$ for a domain $D$, i.e., when $\sim_D=\operatorname{Id}$. We consider the space of continuous valuation on function space $(\Omega\to D)$ with its R-topology rather than the usual Scott topology. Any continuous valuation on $((\Omega\to D),\gamma_{(\Omega\to D)})$ is of the form $\nu\circ r^{-1}$ for some random variable $r:\Omega\to (\Omega\to D) $, which means that it is the restriction to $\gamma_{(\Omega\to D)}$ of a continuous valuation on $(\Omega\to D)$ with its usual Scott topology $\mathcal{O}{(\Omega\to D)}$. 




We have a map 

{
\[T_{R^2D\to P^2D}:(\Omega\to (\Omega\to D))\to P(P D),\]}
given by $T_{R^2D\to P^2D}=PT_{(\Omega\to D)\to PD}\circ T_{(\Omega\to \Omega\to D)\to P(\Omega\to D)}$.  A simple derivation shows that we have \begin{equation}\label{formula-PPD}T_{R^2D\to P^2D}(r)(O)=\nu\circ(r^{-1}(T_{RD\to PD}^{-1}(O)),\end{equation} for $O\in {\mathcal{O}{P D}}$. Since $T^{-1}_{RD\to PD}$ is a lattice isomorphism, $T_{R^2D\to P^2D}$ is a continuous map. 

\begin{proposition}\label{random-random-eq}
For $r,r'\in R^2D$, we have $r\sim r'$ iff $T_{R^2D\to P^2D}(r)=T_{R^2D\to P^2D}(r')$.
\end{proposition}
\begin{proof}
   We need to show that for any $R$-open set $U\in \gamma\foot$ we have: $\nu(r^{-1}(U))=\nu(r'^{-1}(U))$. Since $U=T_{RD\to PD}^{-1}(O)$ for some $O\in \mathcal{O}(D)$, the result follows from Equation~(\ref{formula-PPD}).   
\end{proof}


 The map {$T_{R^2D\to P^2D}$} acts on simple random variables to give simple valuations in $P(PD))$:

  \begin{multline*}\label{double-random}
    T_{R^2D\to P^2D}:\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i} \\
    \longmapsto \sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right),
\end{multline*}
where we have assumed the basic open sets $U_i$ and $V_{ij}$ are disjoint for $i\in I$ and $j\in J_i$. In fact:

\begin{multline*}
  T_{R^2D\to P^2D}(\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}) \\
  =PT_{(\Omega\to D)\to PD}\circ T_{(\Omega\to D)\to P(\Omega\to D)}(\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}) \\ =PT_{(\Omega\to D)\to PD}\left(\sum_{i\in I}\nu(U_i)\delta(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\right) \\
  =\sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right)
\end{multline*}
From Proposition~\ref{random-random-eq}, we now  obtain: \begin{corollary}\label{eq-double-simple}
    For two simple random variables $r,r'\in R^2D$, with
   \begin{equation}\label{two-higher-random}r=\sup_{i\in I}(\sup_{j\in I_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\quad r'=\sup_{i\in I'}(\sup_{j\in I'_i}d'_{ij}\chi_{V'_{ij}})\chi_{U'_i}\quad \end{equation}
    we have $r\sim_{R^2D} r'$ iff up to a permutation of indices with $I=I'$, $I_j=I'_j$ and for $i\in I. \sup_{j\in I_i}d_{ij}\chi_{V_{ij}}\sim_{RD\to PD} \sup_{j\in I_i}d'_{ij}\chi_{V'_{ij}}$ with $\nu(U_i)=\nu(U'_i)$, where we have assumed all $d_{ij}$'s are distinct and all $d'_{ij}$'s are distinct. 
\end{corollary}
For two simple random variables as in Expression~\ref{two-higher-random}, we also obtain:
\begin{proposition} We have $\mu_D(r)\sim_{RD} \mu_D({r'})$ iff $r$ and $r'$ are defined with the same set $D_0\subset D$ of values and
\begin{equation}\label{muD-condition}\forall d\in D_0.\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)=\sum_{d'_{ij}=d}\nu(V'_{ij})\nu(U'_i) \end{equation}
   
\end{proposition}
\begin{proof}
   It is immediate that $r$ and $r'$ must be defined with the same set $D_0$ of values in $D$ to have $\mu_D(r)=\mu_D(r')$. Assuming this,  since the events $U_i$ for $i\in I$ are disjoint, we have:
  \[\forall d\in D_0.\operatorname{Pr}(r=d)=\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\]
  with a similar expression:
 \[\forall d\in D_0.\operatorname{Pr}(r'=d)=\sum_{d'_{ij}=d}\nu(V'_{ij})\nu(U'_i)\]
 and the result follows.
  
\end{proof}
We note that Equation~(\ref{muD-condition}) is necessary but not sufficient to have $r\sim_{R^2D} r'$. A counter-example is given by 
\[r=\chi_O(\sup(\chi_{O_1}d_1,\chi_{O_2}d_2)), \quad r'=\sup(\chi_O\chi_{O_1}d_1,\chi_{O'}\chi_{O_2}d_2),\]
with $d_1\neq d_2$ and $\nu(O)=\nu(O')$. 
    
This makes $ T_{R^2D\to P^2D}$ onto simple valuations in $P(PD)$ and it follows by Theorem~\ref{random-valuation} that $ T_{R^2D\to P^2D}$ is a surjection. In addition, $T_{R_0^2D\to P^2D}$, where $R_0D=(\Omega_0\to D)$, preserves the way-below relation and is thus open. 

Let $r_i=\sup_{j\in J_i}d_{ij}\chi_{V_{ij}}$, for $i\in I$, in Equation~\ref{double-random}. Using the notation in Lemma~\ref{way-below-A-0}, assume $r_i\in B_{(\Omega_0\to D)}$ for $i\in I$ and,
\begin{equation}\label{double-random-b}
     r:=\sup_{i\in I}r_i\chi_{U_i}\in B_{(\Omega_0\to (\Omega_0\to D))},
\end{equation}
with $\sigma:=\sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J_i}\nu(V_{ij})\delta(d_{ij})\right) =\sum_{i\in I}\nu(U_i)\delta(\sigma_i)$, where $\sigma_i:=\sum_{j\in J_i}\nu(V_{ij})\delta(d_{ij})$. We have $\sigma= T_{R_0^2D\to P^2D} (r)$ and similar to~\cite[Proposition 3.11]{DE24}:
\[\dua \sigma=\dua (T_{R_0^2D\to P^2D} (r))\]

\remove{By Corrollary~\ref{t-way-below}, the map $T^{-1}_{(\Omega_0\to D)}$ preserves the way below relation and thus so does $PT_{(\Omega_0\to D)}: P(\Omega_0\to D,\gamma)\to P(PD)$. In fact $PT_{(\Omega_0\to D)}:\alpha\mapsto \alpha\circ T^{-1}$ and hence $\alpha\ll_{PT_{(\Omega_0\to D)}} \beta$ implies $\alpha\circ T_{(\Omega_0\to D)}^{-1}\ll \beta\circ T_{(\Omega_0\to D)}^{-1}$.}
Similar to Theorem~\cite[Theorem 3.14]{DE24}, we have:
\begin{proposition}
  If $r\in (\Omega\to (\Omega\to D))$ for $D\in \BC$, then there exist an increasing sequence $(r_i)_{i\in \nat}$ of simple random variables $r_i\in (\Omega\to (\Omega\to D))$ with $r_i\ll r$,  $ T_{R^2D\to P^2D}(r_i)\ll  T_{R^2D\to P^2D}(r)$  and $\sup_{i\in \nat} r_i=r$ a.e.
\end{proposition}
\begin{proposition}
    A basis of the R-topology on $(\Omega\to (\Omega\to D))$ is given by $ T_{R^2D\to P^2D}^{-1}(\dua \sigma)$, where $\sigma\in B_{P^2D}$. 
\end{proposition}


   
  \remove{Consider two simple random variables $r,r':\Omega\to (\Omega\to D)$,
   \[r=\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\quad 
   r'=\sup_{i\in I'}(\sup_{j\in J'_i}d'_{ij}\chi_{V'_{ij}})\chi_{U'_i}\quad \]

  
To derive necessary and sufficient conditions so that $r\sim r'$, we can assume $U_i$, respectively $U_i'$, are disjoint crescents for $i\in I$, respectively for $i\in I'$. Similarly, for each $i\in I$, we can assume $V_{ij}$, respectively $V'_{ij}$, are disjoint crescents for $j\in J_i$, respectively for $j\in J'_i$. 

\begin{lemma}\label{double-random-d} Let $D_0:=\operatorname{Im}(r)$, where $r=\sup_{i\in I}\chi_{U_i}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}}):\Omega^2 \to D$, then
    \[T_{(\Omega\to D)\to PD}\circ \mu_D:r\mapsto\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d):(\Omega\to (\Omega\to D))\to PD\]
\end{lemma}
\begin{proof}
   We have $\mu_D(r)=\sup_{i\in I}\chi_{h_1^{-1}(U_i)}(\sup_{j\in J_i}d_{ij}\chi_{h_2^{-1}(V_{ij})})$. Since $h_1$ and $h_2$ are independent and measure preserving, the result follows. 
\end{proof}}




\remove{

********

 
We note that $T:U R\to P U$ with $T_D:=T_{R D\to PD}$ is a natural transformation between the functors $R:\BC\to \BC$ and $P:\D\to \D$, as it can be easily checked. We can now show that $T$ preserves the monadic structures of the monads $\mathcal{R}$ and $\mathcal{P}$. Recall that, as a variation of Giry's monad, the functor $P:\D\to \D$ is a monad with $\epsilon_D:D\to P(D)$ given by $\epsilon'_D(d)=\delta(d)$ and the flattening operation $\mu_D':P(PD)\to PD$ given by $\mu_D'(\kappa)(O)=\int_{x\in \mathcal{V}(D)}x(O)\,\,d\kappa$, where $O\in \mathcal{O}(D)$. 

\begin{proposition}
   Consider $\epsilon$ and $\mu$, respectively $\epsilon'$ and $\mu'$, the unit and flattening operations of $\mathcal{R}$, respectively $\mathcal{P}$. Then, for $D\in \BC$, the following two diagrams commute:
\begin{center}

       
   
\begin{tikzcd}[row sep=huge, column sep=huge]
D\arrow[rd, "\epsilon'_D" ] \arrow[r, "\epsilon_D"] & RD\arrow[d,"T_{RD\to PD}"]& \\
&PD
\end{tikzcd}

\begin{tikzcd}[row sep=huge, column sep=large]
(\Omega\to \Omega\to D)\arrow{r}{\mu_D} \arrow[swap]{d}{PT_{RD\to PD}\circ T_{(R^2D \to D))\to P(RD)}} & 
 RD\arrow{d}{T_{RD\to PD}} \\%
 PPD\arrow{r}{\mu'_D}&PD
\end{tikzcd} 
\end{center}
 
\end{proposition}
\begin{proof}
 The commutativity of the first diagram is straightforward. To show that the second diagram commutes, it is sufficient, by Scott continuity, to prove it for a simple random variable  
 \[r=\sup_{i\in I}(\sup_{j\in J_i}d_{ij}\chi_{V_{ij}})\chi_{U_i}\in (\Omega\to (\Omega\to D))\]
 By Lemma~\ref{double-random-d}, we have \[T_{RD\to PD}\circ \mu_D(r)=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d)\]By Equation~(\ref{double-random}), we let:
 \[\kappa:=T_{R^2D\to P^2D}(r)=\sum_{i\in I}\nu(U_i)\delta\left(\sum_{j\in J
    _i}\nu(V_{ij})\delta(d_{ij})\right)\]
    If $O\in \mathcal{O}(D)$, then we have 
    \[\mu_D'(\kappa)(O)=\int_{x\in \mathcal{V}(D)}x(O)\,\,d\kappa=\sum_{i\in I,j\in J_i}\sum_{d_{ij}\in O}\nu(V_{ij})\nu(U_i)\]
It follows that $\mu_D'(\kappa)=\sum_{d\in D_0}\sum_{d_{ij}=d}\nu(V_{ij})\nu(U_i)\delta(d)$, as required.
\end{proof}
}

Given two simple random variables $r,r'\in (\Omega^n\to D)$ of the form 
\begin{multline*}
r=\sup_{k_1\in I}\sup_{k_2\in I_{k_1}}\ldots\sup_{k_{n-1}\in I_{k_1k_2\ldots k_{n-2}}}\sup_{k_n\in I_{k_1k_2\ldots k_{n-1}}} \\
d_{k_1k_2\ldots k_n}\chi_{W_{k_1k_2\ldots k_{n}}}\chi_{W_{k_1k_2\ldots k_{n-1}}}\ldots \chi_{W_{k_1k_2}}\chi_{W_{k_1}}    
\end{multline*}
\begin{multline*}
  r'=\sup_{k_1\in I'}\sup_{k_2\in I'_{k_1}}\ldots\sup_{k_{n-1}\in I'_{k_1k_2\ldots k_{n-2}}}\sup_{k_n\in I'_{k_1k_2\ldots k_{n-1}}} \\
  d'_{k_1k_2\ldots k_n}\chi_{W'_{k_1k_2\ldots k_{n}}}\chi_{W'_{k_1k_2\ldots k_{n-1}}}\ldots \chi_{W'_{k_1k_2}}\chi_{W'_{k_1}}
\end{multline*}

where we can assume that the crescents $W_{k_1}$ for $k_1\in I$ (respectively $W'_{k_1}$ for $k_1\in I'$) are disjoint. Similarly, we can assume, for and $1<i<n-1$ the crescents $\chi_{W_{k_1k_2\ldots k_{i}}}$ (respectively, $\chi_{W'_{k_1k_2\ldots k_{i}}}$)   are disjoint for and $k_i\in I_{k_i}$ (respectively, $k_i\in I'_{k_i}$). 
\begin{proposition}
For simple random variables $r,r'\in(\Omega^n\to D)$, we have the equivalence $r\sim r'$ iff $D_0:=\operatorname{Im}(r)=\operatorname{Im}(r')$ and 
\begin{multline*}
  \forall d\in D_0.\sum_{d_{k_1k_2\ldots k_n}=d}\nu({W_{k_1k_2\ldots k_{n}}})\nu({W_{k_1k_2\ldots k_{n-1}}})\ldots\nu(W_{k_1}) \\
= \sum_{d'_{k_1k_2\ldots k_n}=d}\nu({W'_{k_1k_2\ldots k_{n}}})\nu({W'_{k_1k_2\ldots k_{n-1}}})\ldots \nu(W'_{k_1})
\end{multline*}
\end{proposition}

We can deduce the following as in Lemma~\ref{w=r}.

\begin{corollary}
    $T_{R^2D\to P^2D}^{-1}:\mathcal{O}{P^2D}\to \gamma_{R^2D}$ is a lattice isomorphism.
\end{corollary}

The above construction can be inductively extended to $R^nD$ and $P^nD$. Inductively define
\[T_{R^{n+1}D\to P^{n+1}D}:R^{n+1}D\to P^{n+1}D,\]
by $T_{R^{n+1}D\to P^{n+1}D}=P^nT_{RD\to PD}\circ T_{R^{n+1}D\to P^nRD}$ with $T_{R^{n+1}D\to P^{n+1}D}(r)(O):=\nu\circ(r^{-1}(T_{R^nD\to P^nD}^{-1}(O))$ for $O\in {\mathcal{O}{P^n D}}$. Since $T^{-1}_{R^nD\to P^nD}$ is a lattice isomorphism, $T_{R^{n+1}D\to P^{n+1}D}$ is a continuous map. 




Then, we have the following generalisations of the above results.
\begin{proposition}
  If $r\in R^nD$ for $D\in \BC$, then there exists an increasing sequence $(r_i)_{i\in \nat}$ of simple random variables $r_i\in R^nD$ with $r_i\ll r$ and $T_{R^nD\to P^nD}(r_i)\ll T_{R^nD\to P^nD}(r)$, for $i\in \nat$, and $\sup_{i\in \nat} r_i=r$ a.e.
\end{proposition}

\begin{proposition}
    A basis of the R-topology on $R^nD$ is given by $T^{-1}_{R^nD\to P^nD}(\dua \sigma)$, where $\sigma\in B_{\mathcal{V}(D}$. 
\end{proposition}



We can deduce the following as in Lemma~\ref{w=r}.

\begin{corollary}
    $T^{-1}_{R^nD\to P^nD}:\mathcal{O}{P^nD}\to \gamma_{R^nD}$ is a lattice isomorphism, and, thus, $\gamma_{R^nD}$ is countably based continuous lattice.
\end{corollary}

\subsection{Function space}

\remove{Recall that $\Omega_0=(0,1)$ or $\Omega_0=2_0^\nat$. Thus, the mapping $T:(\Omega_0\to D)\to PD$ preserves the way-below relation and is an open map. }
\remove{\begin{lemma}\label{way-below-cylinder}
    Let $D\in \BC$. 
   Consider a simple random variable in the form: $r\in B_{(\Omega\to D)_0}$. Then, we have:
\[
(r\ll f )\Rightarrow f \in T^{-1}(\dua(T(r)))
\]
   
\end{lemma}
\begin{proof}
    By Proposition~\ref{way-below-random}, there exists $s\in B_{(\Omega\to D)_0}$ with $r\sqsubseteq s\ll f$ and $T(s)\ll T(f)$. Thus, $f\in T^{-1}(\dua (T(s)))\subseteq T^{-1}(\dua (T(r)))$.
\end{proof}}
In this subsection, we show that the R-topology on $(RD_1\to RD_2)$ for $D_1,D_2\in \BC$ coincides with the point-open topology on the function space when $RD_2$ is equipped with its R-topology. We then show that the lattice of open subsets of the R-topology on the function space is countably based. 

We now consider the function space $((RD_1,\sim)\to (RD_2,\sim))$. We note that a step function of type \begin{equation}\label{step-R-open}
    g=\sup_{i\in I} \chi_{O_i}t_i:(RD_1,\sim)\to (RD_2,\sim),
\end{equation}  where $O_i\in \mathcal{O}({D_1})$, and $t_i:\Omega\to D_2$ for $i\in I$, are self-related step functions, is R-continuous if $O_i\in \gamma_{D_1}$ for $i\in I$.
However, the sub-basis of $\gamma_{D_1}$ consisting of R-open sets of the form $\Xi_{1\leq i\leq n}[q_i\to \dua d_i]$ is the countable union of upper sets given in Corollary~\ref{countable-uion-r-open} and has thus an infinite structure. We therefore endeavour to approximate self-related elements in $(\Omega\to D_1)\to (\Omega\to D_2)$ by suitable step functions. 

\begin{lemma}\label{s-step}~\cite[Proposition 9]{davari2019convex}
    Suppose $f\in D_1\to D_2$ is a Scott continuous map with $D_1,D_2\in \Dom$. If $u\in D_1$ and $r\in 
     D_2$ are elements with $r\ll f(u)$, then $r\chi_{\dua u}\ll f$.
\end{lemma}

\remove{We use the work in Section~\ref{rand-from-simple} to develop a finitary construction of equivalence of two functions in $((RD_1,\sim)\to (RD_2,\sim))$. 

\begin{definition}
   For two simple random variables $r,s:A_0\to D$, we write $r\sim_D^ns$ if they have equivalent representations of degree $n$. The least such $n$ is called the {\em equivalence degree} of $r$ and $s$. We say $f,g\in((RD_1,\sim)\to (RD_2,\sim))$ are {\em $n$-equivalent},  written $f\approx^n g$, if whenever $r$ and $s$ have equivalence degree at most $n$, we have $f(r)\sim g(s)$. We say $f$ is {\em $n$-self-equivalent} if $f\approx^nf$.
\end{definition}
We note that given simple random variables $r$ and $s$, we have:  $r\sim^n s$ implies $r\sim^{m} s$ for all $m\geq n$ by taking finer representations of $r$ and $s$. In addition, if $r\sim s$ then there exists $n\in \nat$ such that $r\sim^ns$. 
\begin{proposition}
Two functions in $((RD_1,\sim)\to (RD_2,\sim))$ are equivalent iff they are $n$-equivalent for all $n\in \nat$. 
\end{proposition}
\begin{proof}
If $f\sim g$, then by definition whenever $r\sim^ns$ we have $f(r)\sim g(s)$. For the converse, suppose $f$ and $g$ are $n$-equivalent for all $n\in \nat$. Assume that we have two random variables $r\sim s$. We invoke Theorem~\ref{two-eq-rand} to have two increasing sequences of simple random variables $r_i$ and $s_i$, for $i\in\nat$, such that $r_i\sim^{n_i} s_i$, where $n_i $ is the common equivalence degree of $r_i$ and $s_i$ with $r=\sup_{i\in \nat}r_i$ a.e., and $s=\sup_{i\in \nat}s_i$. By assumption, since $f\approx^{n_i} g$, we have $f(r_i)\sim g(s_i)$, for $i\in \nat$, and thus by taking supremum we have $f(r)\sim g(s)$. 
\end{proof}
To have a finitary element for the function space, we introduce, for each $n\in \nat$ and dyadic $0<q<1$, the subset
\begin{equation}\label{finitary-cyl-set} [q\to \dua d]^n\subseteq [q\to \dua d]\end{equation}
defined by $f\in [q\to \dua d]^n$ if there exists a basic open set $U\subseteq A$ of degree $n$ such that $U\ll f^{-1}(\dua d)$ with $\nu(U)=q $. 

\begin{proposition}\label{cylinder-union}
We have  $[q\to \dua d]^n=\bigcup_{j\in J}\dua (d\chi_{U_j})$ where $U_j$ is a Scott open set with $\nu(U_i)=q$ for $j\in J$ with $J$ finite. 
\end{proposition}
\begin{proof}
 Let $U_j$, for $j\in J$, be the finite set of basic open sets with $\nu(u_j) =q$ and degree $n$, then $[q\to \dua d]^n=\bigcup_{j\in J}\dua (d\chi_{U_j})$. 
\end{proof}  
Thus, $[q\to \dua d]^n$ is Scott open. Observe that $[q\to O]^n\subseteq [q\to O]^{n+1}$ for $n\in \nat$.

Based on Proposition~\ref{cylinder-union} and the notations there, we define $[q\to \dua d]^n_j:=\dua (d \chi_{U_j})$ so that  $[q\to \dua d]^n=\bigcup_{j\in J(n,q,d)}\dua (d\chi_{U_j})$. 



\remove{ It follows that a semi-self-related step function preserves the equivalence relation on random variables belonging exclusively to a ground-level input open set. It is however easy to show that the equivalence relation is not in general preserved by semi-self-related step function. To see this, it is sufficient to consider two pairs $(r_1,r_1')$ and $(r_2,r_2')$ of equivalent simple random variables in $(\Omega\to D_2)$, i.e., $r_1\sim r_1'$ and $(r_2\sim r_2')$ such that the pairs $(r_1,r_2)$ and $(r_1',r_2')$ are both consistent with maximal binary lubs and $(r_1\sqcup r_2)\not\sim (r_1'\sqcup r_2')$.
\begin{example}
   Consider $A=2^\nat$  and $D_2=\realDom$. Denote the complement of a basic open set $O$ by $O^c$. Let 
   \[\begin{array}{lllllll}
   r_1&=&\sup (d_{11}\chi_{O_1},d_{12}\chi_{O_1^c})&&r_1'&=&\sup(d_{11}\chi_{U_1},d_{12}\chi_{U_1^c})\\
   r_2&=&\sup (d_{21}\chi_{O_2},d_{22}\chi_{O_2^c})&&r_2'&=&\sup(d_{21}\chi_{U_2},d_{22}\chi_{U_2^c})
   \end{array} \]
   and assume the lubs $r_1\sqcup r_2$ and $r_1'\sqcup r_2'$ exist as in the following:
   \[\begin{array}{lll}
   r_1\sqcup r_2&=&\sup((d_{11}\sqcup d_{21})\chi_{O_1\cap O_2},(d_{11}\sqcup d_{22})\chi_{O_1\cap O_2^c}, (d_1\sqcup d_2)\chi_{O_1^c\cap O_2}, (d_{12}\sqcup d_{22})\chi_{O_1'\cap O'_2})\\
  r'_1\sqcup r'_2&=&\sup((d_{11}\sqcup d_{21})\chi_{U_1\cap U_2},(d_{11}\sqcup d_{22})\chi_{U_1\cap U2^c}, (d_1\sqcup d_2)\chi_{U_1^c\cap U_2}, (d_{12}\sqcup d_{22})\chi_{U_1'\cap U'_2}),\\ 
       
   \end{array}\]
   where we have assumed all intersections of basic open sets in the above are non-empty and the binary lubs of the pairs of elements in the above two expressions exist in $(\Omega\to D_2)$ and are pairwise distinct. We now let the four basic open sets have the values: $O_1=00$, $O_2=0$ and $U_1=000\cup 100$ and $U_2=1$. Then $O_1\cap O_2=00$ and $U_1\cap U_2=100$. Since $\nu(00)=1/4\neq 1/8=\nu(100)$, it follows that $(r_1\sqcup r_2)\not\sim(r'_1\sqcup r'_2)$. If we now choose $d_{11}=[0,1]$ and $d_{21}=[1,2]$, then $d_{11}\sqcup d_{12}=\{1\}$ which is maximal. We conclude that there is no pair of equivalent random variables above the pair $r_1\sqcup r_2$ and $r_1'\sqcup r_2'$.
\end{example}
The above example shows that in general the non-ground-level values of a semi-self-related step function cannot be redefined to create a semi-self-related step function from a semi-self-related step function. }
\begin{lemma} We have the following relations:
    \begin{itemize}
        \item $[q\to  O]\subseteq  [q'\to  O']$ iff $q'\le q$ and $O\subseteq O'$.
        \item $[q\to  O]\ll  [q'\to  O']$ iff $q'< q$ and $O\ll O'$.
        \item $[q\to  O]^n\subseteq  [q'\to  O']^{n'}$ iff $q'\le q$, $O\subseteq O'$ and $n\le n'$.\item $[q\to  O]^n\ll  [q'\to  O']^{n'}$ iff $q'< q$, $O\ll O'$ and $n\le n'$.
        \item $[q\to O]=\bigcup_{n\in \nat}[q\to O]^n$
    \end{itemize}
\end{lemma}

% \begin{lemma} We have the following relations:
%     \begin{itemize}
%         \item $[q\to  \dua d]\subseteq  [q'\to \dua d']$ iff $q'\le q$ and $d' \sqsubseteq d$.
%         \item $[q\to  \dua d]\ll  [q'\to  \dua d']$ iff $q'< q$ and $ d' \ll d$.
%         \item $[q\to  \dua d]^n\subseteq  [q'\to  \dua d']^{n'}$ iff $q'\le q$, $d' \subseteq d$ and $n\le n'$.
%         \item $[q\to  \dua d]^n\ll  [q'\to  \dua d']^{n'}$ iff $q'< q$, $d'\ll d$ and $n\le n'$.
%         \item $[q\to \dua d]=\bigcup_{n\in \nat}[q\to \dua d]^n$
%     \end{itemize}
% \end{lemma}

\remove{\begin{definition}
Given a finite indexing set $I$ and two sets of $I$-indexed rational $\{q_i\}$ and open sets $\{O_i\}$, we define the set $\Sigma_{i\in I}[q_i\to O_i]$, by $r \in \Sigma_{i\in I}[q_i\to O_i]$ if there exist a finite number of disjoint open sets $(Q_i)_{i \in I}$ in $A$ such that, for every $i$, $\nu(Q_i) > q_i$ and $r(Q_i) \subseteq O_i$.  
\end{definition}

\begin{lemma}
    The set $\Sigma_{i\in I}[q_i\to O_i] \subseteq (\Omega \to D)$ is an R-open set.
\end{lemma}

\begin{proof}
Rephrasing the proof of analogous Lemma 4.7, we first prove that  $\Sigma_{i\in I}[q_i\to O_i]$ is Scott-open. Clearly $\Sigma_{i\in I}[q_i\to O_i]$ is upper closed. Let $r_n \in (\Omega \to D)$ be an increasing sequence with $r = \sup_{n \in \nat} \in \Sigma_{i\in I}[q_i\to O_i]$. 

For every $i \in I$, we can write $\nu (Q_i \cap r^{-1}(O_i) )$
\end{proof}}

For positive dyadic numbers $q_i<1$ ($1\leq i\leq m$) with $\sum_{1\leq i\leq m}q_i<1$, we define  the subset $\sum_{1\leq i\leq m}[q_i\to \dua O_i]^n\subseteq (\Omega\to D)$ by $r\in\sum_{1\leq i\leq m}[q_i\to \dua O_i]^n$ if there exist a finite number of disjoint open sets $(U_i)_{1\leq i\leq m}$ of degree $n$ such that $\mu(U_i) = q_i$ and $U_i \ll r^{-1}(O_i)$ for every $1\leq i\leq m$. Letting $\sigma=\sum_{0\leq i\leq m} q_i\delta(d_i)$, with $d_0=\bot$ and $q_0=1-\sum_{1\leq i\leq m} q_i$, we have: 
\begin{multline}
  \label{finite-r-open} \sum_{1\leq i\leq m}[q_i\to \dua O_i]^n=\bigcup\left\{\dua b:  b\mbox{ simple random variable} \right.
  \\
  \mbox{with minimal degree }n,\;T(b)=\sigma \left. \right\}  
\end{multline}
We note that there are only a finite number of simple random variables $b$ of degree $n$ with $T(b)=\sigma$ and thus the union in Equation~\ref{finite-r-open} is over a finite set. We call $\dua b$ a {\em band} of $\Sigma_{1\leq i\leq m}[q_i\to \dua O_i]^n$.


\begin{lemma} 
Any two bands $\dua b_1$ and $\dua b_2$ of the set $\sum_{1`\leq i\leq m}[q_i\to \dua d_i]^n$ are isomorphic through a measure preserving homeomorphism. 
\end{lemma} 
\begin{proof}
 Since $T(b_1)=T(b_2)$ we have $b_1\sim b_2$ and there exits an isomorphim $h:\{0,1\}^n\to \{0,1\}^n$ such that $b_1=b_2\circ h$. We extend $h$ to a measure-preserving homeomorphism $\hat{h}:\{0,1\}^\bfomega\to \{0,1\}^\bfomega$ by defining $\hat{h}(x_1\ldots x_n x_{n+1}\ldots)=\hat{h}(x_1\ldots x_n):x_{n+1}x_{n+2}\ldots$ as required. 
\end{proof}


 \remove{\begin{lemma}Given two semi-self-related step functions below of type $ (\Omega\to D_1)\to (\Omega\to D_2)$,
 \[f=\sup_{i\in I,j\in J_i} r_{ij}\chi_{[q_i\to \dua d_i]^{n_i}_j}\qquad f'=\sup_{i\in I',j\in J'_i} r'_{ij}\chi_{[q'_i\to \dua d'_i]^{n'_i}_j}\]
 the relation $f\approx^n f'$ holds iff, up to a permutation of indices, we have:
\[I=I'\quad \forall i\in I.\,J_i=J'_i\quad \forall i\in I,j\in J_i.\,r_{ij}\sim r'_{ij}\,\quad \forall i\in I.\,q_{i}=q'_{i}\;\&\; d_{i}=d'_{i}\; \& \;n_{i}=n'_{i}\;\&\;n\leq  n_{i} \]
\end{lemma}}
Let $S_{(\Omega\to D_1)\to (\Omega\to D_2)}\subseteq ((\Omega\to D_1)\to (\Omega\to D_2)) $ be the set of semi-self-related elements of $((\Omega\to D_1)\to (\Omega\to D_2))$ with the partial orderdefined by: $f\sqsubseteq_s f'$ if $f\sqsubseteq f'$ and there exist $n,n'$ s.t. $f\approx^nf$ and $f'\approx^{n'}f'$ and $n\leq n'$.

\begin{lemma}
  The poset $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$ is a dcpo.   
\end{lemma}
\begin{proof}
Suppose $(f_i)_{i\in I}$  with $f_i\approx^{n_i} f_i$ is a directed set of semi-self-related  elements of $((\Omega\to D_1)\to (\Omega\to D_2))$ with $f=\sup_{i\in I}f_i$. Consider the two possible cases: 

(i) Let $\sup_{i\in I}n_i=n<\infty$. By removing a finite subset of $I$, we can assume $n_i=n$ for all $\in I$. We claim that $f\approx^n f$. Suppose $r\sim^n s$ for simple random variables $r,s\in(\Omega\to D_1)$. Then, since $f_i\approx^nf_i$ for all $i\in I$, we have: $f_i(r)\sim f_i(s)$ for $i\in I$. As $\sim_{(\Omega\to D_2)}$ is closed under directed sets we obtain $f(r)\sim f(s)$. Thus, $f\approx^nf$.

(ii) Next, let $\sup_{i\in I}n_i=\infty$. Assume $r\sim s$ for simple random variables $r$ and $s$. We show that $f(r)\sim f(s)$. We have $r\sim^m s$ for some $m\in \nat$. Let $i\in \nat$ be large enough such that $m\leq n_i$, which implies $r\sim^{n_i} s$. Then, from $f_i\approx^{n_i}f_i$ we obtain $f_i(r)\sim f_i(s)$ and thus $f(r)\sim f(s)$ by taking supremum.
\remove{Suppose $r\in [q\to \dua d]\iff s\in [q\to \dua d]$. Then, there exists a basic open set $C_r$ with $r[C_r]\subseteq \dua r$ and $\nu(C_r)>q$, and a basic open set $C_s$ with $s[C_s]\subseteq \dua d$ and $\nu(C_s)>q$. Let $m=\max\{d(C_r),d(C_s)\}$ and take $i\in I$ with $m\leq n_i$. Then, $f_i\sim^{n_i}f_i$ For each $m\in \nat$, the number of basic open sets of degree at most $m$ is finite, and thus there exists $i_m\in \nat$ such that $f_{i_m}\sim^m f_{i_m}$ and hence $f_i\sim^m f_i$ for $i\geq i_m$ which implies, by the first part (i), that $f\sim^m f$.} Hence, $f\sim f$.
\end{proof}
\remove{For a step function $\sup_{i\in I}d_i\chi_{O_i}:X\to D$ from a topological space $X$ to a bounded complete domain $D$, we call the open set $O_i$ for $i\in I$ a {\em ground or zero-level input open set} and the value $d_i$ for $i\in I$ a {\em ground or zero-level output value}. Similarly the intersection $\bigcap\{ O_{i_j}: {i_j\in I, 1\leq j\leq n}\}$ is called an {\em $n$-level input open set}. }
We now formulate a representation for semi-self-related step functions and show that they provide a basis for $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$. 
We say a step function $\sup_{i\in I}d_i\chi_{O_i}:X\to D$ from a topological space $X$ to a bounded complete domain $D$ is in its {\em canonical form} if the collection of open sets $\{O_i:i\in I\}$ is closed by non-empty binary intersection. As an example, given two intersecting open sets $O_1$ and $O_2$ and two consistent elements $d_1,d_2\in D$, the step function  $(d_1\chi_{O_1})\sqcup (d_2\chi_{O_2})\sqcup ((d_1\sqcup d_2)\chi_{O_1\cap O_2})$
is in canonical form whereas $(d_1\chi_{O_1})\sqcup (d_2\chi_{O_2})$, representing the same step funciotn, is not. If $X$ is also bounded complete domain, then a sub-basic open set is given by $\dua u$ for $u\in X$ and we have $\dua u_1 \cap \dua u_2= \dua (u_1\sqcup u_2)$. Thus, the canonocal form of a step function in $((\Omega\to D_1)\to (\Omega\to D_2))$ can be represented as 
    \begin{equation}\label{canonical-form-step}\sup_{i\in I} r_i\chi_{\dua u_i} 
    \end{equation}  
where $\{\dua u_i: i\in I\}$ is the collection of all non-empty open sets in the semilattice generated by the open sets in the input of the step function satisfying the monotone condition: $r_i\sqsubseteq r_j$ whenever $u_i\sqsubseteq u_j$ for $i,j\in I$. It then follows that any step function has a unique canonocal repersentaiton. Recall that for each level $n\in \nat$ there are only a finite number of equivalent simple random varibales in $(\Omega\to D)$ equivalent to a given simple random variable. We define the {\em $n$-equivalence completion} of a set $E$ of $n$-equivalent simple random variables as the set $\hat{E}=\{r\in (\Omega\to D): \exists s\in E. r\sim^n s\}$. We say $E$ is {\em $n$-equivalence complete} if $E=\hat{E}$. \remove{More generally, if $F$ is a finite set of simple random variables then the {\em $n$-equivalence completion} of $F$ is the union $\hat{F}=\bigcup\{\hat{E}:E\mbox{ closed under $n$-equivalnce }\& E\subseteq F\}$ and $F$ is said to be {\em $n$-equivalence complete} if $F=\hat{F}$. }

Given a finite set $E\subseteq B_D$ of basis elements $B_D$ of a bounded complete domain $D$, we denote by $\operatorname{Lub}(E)$ the closure of $e$ by all lubs, i.e.,
\[\operatorname{Lub}(E)=E\cup\left\{\bigsqcup E':\mbox{consistent }E'\subseteq E\right\}.\]
\begin{proposition}\label{lub-complete}
 For a finite subset $E$, of simple random variables in $(\Omega\to D)$, we have:
 \[\operatorname{Lub}(\hat {E})=\widehat{\operatorname{Lub}}({\hat{E})}\]
\end{proposition}
\begin{proof}
    It is sufficient to show that for any pair of consistent simple random variables $r_1,r_2\in E$, whenever $r\sim (r_1\sqcup r_2)$, there exist $r_1',r_2'\in (\Omega\to D)$ with $r_1\sim r_1'$, $r_2\sim r_2'$ and $r=r_1'\sqcup r'_2$. So let $r_1=\sup_{i\in I}d_{1i}\chi_{C_{1i}}$ and $r_2=\sup_{j\in J}d_{2j}\chi_{C_{2j}}$, where $C_{1i}$ for $i\in I$ are pairwise disjoint cresents and $d_{1i}$ for $i\in I$ are distinct values of $r_1$ (including $\bot$), and similarly $C_{2j}$ for $j\in J$ are pairwise disjoint cresents and $d_{2j}$ for $j\in J$ are distinct values of $r_2$ (including $\bot$). For each $i\in I$, let $j_{i1},j_{i2},\ldots,j_{in_i}\in J$ be the set of indices $j\in J$ such that $C_{1i}\cap C_{2j}\neq\emptyset$. Then, $r_1\sqcup r_2=\sup_{i\in I}\sup_{1\leq k\leq n_i}(d_{1i}\sqcup d_{2j_{ik}})\chi_{U_{ij_{ik}}}$. Put $C'_i:=\bigcup_{1\leq k\leq n_i}U_{ij_{ik}}$ for $i\in I$. Similarly, define $C'_j$ for $j\in J$. Then, let $r_1':=\sup_{i\in I} d_{1i}\chi_{C'_i}$ and $r_2':=\sup_{j\in J} d_{2j}\chi_{C'_j}$. We have $r=r_1'\sqcup r_2'$ with $r_1\sim r'_1$ and $r_2\sim r'_2$.
\end{proof}
Consider a step function in its canonical form as in Equation~\ref{canonical-form-step}.
\begin{definition}
    We say the step function $\sup_{i\in I} r_i\chi_{\dua u_i}:(\Omega\to D_1)\to (\Omega\to D_2)$ is {\em $n$-equivalence complete} if for all $i\in I$ and $u\sim^n u_i$, there exists $i'\in I$ with $u=u_{i'}$. It is also {\em lub complete} if whenever $i_1,i_2\in I$ and $u_{i_1}\sqcup u_{i_2}$ exists then there exists $i\in I$ with $u_i=u_{i_1}\sqcup u_{i_2}$. The step function in {\em $n$-complete} if it is both lub complete and $n$-equivalence complete. 
\end{definition}
For example, consider a step function of the function space $((D_1,\sim)\to(D_2,\sim))$ made up of single-step functions with domain of definition given by the Scott open sets $[q\to \dua d]_j^{n} $ for $j\in J(n,q,d)$. It follows from Proposition~\ref{lub-complete} that the set $\operatorname{Lub}\{d\chi_{O_j}:j\in J(n,q,d)\}$ is $n$-equivalence complete. The non-empty open subsets of the semi-lattice of open sets generated by the above Scott open sets can be writen them as $\{\dua u_i:i\in I(n,q,d)\}$. Hence, the step function
$\sup_{i\in I(n,q,d)} r_i\chi_{\dua u_i}$ is an $n$-equivalence complete step function. 

More generally, consider a step function with input open subsets given by $[q_k\to \dua d_k]_j^{n_k} $ for $j\in J(n_k,q_k,d_k)$ and $k\in K$ with $n\leq n_k$ for $k\in K$. In its cannonical form, the collectoin of input open sets can be expressed as $\{\dua u_i: i\in I(n_k,q_k,d_k),k\in K\}$. Let $F=\{ u_i:i\in I(n_k,q_k,d_k),k\in K\}$ and put $\operatorname{Lub}(\hat{F})=\{u_i:i\in \hat{I}(n_k,q_k,d_k,K)\}$. Then the step function
\[\sup_{i\in \hat{I}(n_k,q_k,d_k,K)}r_i\chi_{\dua u_i}\]
is $n$-complete. 
\remove{\begin{lemma}\label{way-below-set}
  Let $r_i\in (\Omega\to D)$, for $i\in I$, be a finite collection for simple random variables.  Then for each $i\in I$, there exists a simple random variable $r\in (\Omega\to D)$ such that $r_i\ll r$, and the relation $r_j\ll r$ implies $r_j\sqsubseteq r_i$.
\end{lemma}}

\begin{proposition} Suppose $g=\sup_{i\in I}r_{i}\chi_{\dua u_i}$ is an $n$-complete step function. If $r_i\sim r_{i'}$ whenever $u_i\sim u_{i'}$, then $s\sim^n s'$ implies $g(s)\sim g(s')$. 
\end{proposition}
\begin{proof}
 Let and $s\sim^n s'$ and $u_i=\sup\{u_j:u_j\ll s\}$. Then $u_i\ll s$. Since $s\sim^n s'$, there exists $i'\in I$ with $u_{i'}\ll s'$ and $u_i\sim u_{i'}$. Thus $g(s)=r_i\sim r_{i'}=g(s')$. 
 
 
\end{proof}

\remove{A {\em semi-self-related step function} of degree $n$ takes as its domain of open sets the finite union of open sets generated under $n$-equivalnce completion by $[q_k\to \dua d_k]_j^{n_k} $ for $j\in J(n_k,q_k,d_k)$ and $k\in K$, which we can write as \begin{equation}\label{sssss}g=\sup_{i\in \hat{I}(n_k,q_k,d_k,K)}r_{i}\chi_{\dua u_i}\end{equation} satisfying $g(t_1)\sim g(t_2)$ whenever $t_1\sim^nt_2$. }

 


We take the collection of all semi-self-related step functions and aim here to show that the set of semi-self-related step functions way-below any semi-self-related $f$ is directed with a supremum equivalent to $f$. }

\begin{theorem}\label{semi-self-from-step}
 Given any Scott continuous function $f:D_1\to D_2$ for $D_1,D_2\in \BC$, step functions of the form $\sup_{i\in I} r_{i}\chi_{\dua u_{i}}$, with $r_{i}\ll f(u_{i})$ for each $i\in I$, are way-below $f$  and are directed, with supremum $f$. 
\end{theorem}
\begin{proof}
  
  
\end{proof}
\remove{Consider the dcpo $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$ of all semi-self-related functions in $(\Omega\to D_1)\to (\Omega\to D_2)$. 
\begin{definition}
   The binary relation $\ll_s$ is defined on  $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$ by $g\ll_s f$ if
   for all directed set of semi-self-related functions $(h_i)_{i\in I}$ the relation $f\sqsubseteq \sup_{i\in I}h_i$ implies there exists $i\in I$ with $g\sle h_i$.
\end{definition}

\begin{corollary}
The two relations $\ll$ and $\ll_s$ coincide on $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$.    
\end{corollary}
\begin{proof}
    Clearly $g\ll f$ implies $g\ll_s f$.  Next suppose $g\ll_s f$. By the theorem, $f=\sup\{g_0\ll f: g_0 \mbox{ semi-self-related step function}\}$. Thus, $g\ll_s f$ implies there exists $g_0\ll f$ with $g\sqsubseteq g_0$. Hence, for any directed set of functions $(h_i)_{i\in I}$ with $f\sqsubseteq \sup_{i\in I}h_i$ in $((\Omega\to D_1)\to (\Omega\to D_2))$, there exists $i\in I$ such that $g_0\sqsubseteq h_i$ which implies $g\sqsubseteq h_i$ as required. 
\end{proof}
\begin{corollary}
   The dcpo  $S_{(\Omega\to D_1)\to (\Omega\to D_2)}$ is a domain.
\end{corollary}

\begin{proposition}
   Consider a pair of self-related functions $f,f':(\Omega\to D_1)\to (\Omega\to D_2)$ with $f'= f\circ h$ a.e., where $h$ is a measure-preserving homeomorphirsm of the sample space $A$. Then, there exist two increasing chains of semi-self-related step functions $f_i,f'_i:(\Omega\to D_1)\to (\Omega\to D_2)$, for $i\in \nat$, with $f_i\ll f$, $f'_i\ll f'$, $f_i(t)\sim f_i'(t)$ for $t\in (\Omega\to D_1)$ and $\sup _{i\in \nat}f_i=f$  and $\sup_{i\in \nat} f'_i= f'$ a.e.
\end{proposition}
\begin{proof}
    Let $f_i\ll f$, for $i\in \nat$, with $f_i= \sup_{j\in J_i}\chi_{\dua u_{ij}}r_{ij} \ll f$ where $u_{ij}: A\to D_1$ and $r_{ij}:A\to D_2$ are step functions for $i\in\nat$ and $j\in J_i$, with $r_{ij}\ll f(u_{ij})$ be an increasing sequence of semi-self-related step functions with $\sup_{i\in \nat}f_i=f$. Put $f'_i=f_i\circ h$ for $i\in \nat$;  then  $f'_i$ is an increasing chain for $i\in \nat$. The continuity of the composition operation yields: $\sup_{i\in \nat} f'_i=\sup_{i\in \nat} (f_i\circ h)=(\sup_{i\in \nat} f_i)\circ h=f_i\circ h=f'_i$ a.e.

    
\remove{Since $f(u_{ij})\sim f'(u_{ij})$, there exists, by Proposition~\ref{way-below-random}, for $i\in I$ and $j\in J_i$, a step funciton $r'_{ij}$ with $r_{ij}\sim r'_{ij}$ and $r'_{ij}\ll f'(u_{ij})$, implying $f'_i:=\sup_{j\in J_i}\chi_{\dua u_{ij}}r'_{ij}\ll f'$. Since for any $t\in (\Omega\to D_1)$, we have $f_i(t)\sim f_i'(t)$, it follows that $f_i'(t)$ is an increasing sequence with $f(t)=\sup_{i\in \nat} f_i(t)\sim \sup_{i\in\nat}f_i'(t)\sqsubseteq f'(t)$. By Lemma~\ref{rand-below-eq}, it follows that $\sup f'_i=f'$ a.e.}
    
    
    
    
\end{proof}}
Finally, we consider the R-topology on function spaces of two PER domains.

 \begin{definition}
The {\em point-R-open} topology on the function space $((D_1,\sim_1)\to (D_2,\sim_2))$ is defined as the point-open topology when $D_2$ is equipped with its R-topology, i.e., it has open sets of the form $(t\to O)_p$, where $t\in D_1$ with $t\sim t$ and $O\in\gamma_{(D_1,\sim_1)}$ is R-open.
 
 \end{definition}

\begin{proposition}\label{R-open-func}
    Any open set of the point-R-topology of $((D_1,\sim_1)\to (D_2,\sim_2))$ is R-open.
\end{proposition}
\begin{proof}
    Consider the point-R-open set $(t\to O)_p$, where $t\sim_1 t$ and $O\in gamma_{(D_1,\sim_1)}$. Suppose $f\in (t\to O)_p$ and $f\sim g$. Then $f(t)\sim_2 g(t)$ and since $f(t)\in O$, it follows that $g(t)\in O$. Hence $g\in (t\to O)_p$ as required.
\end{proof}
\begin{proposition}\label{p-open-f-s}
In the function space $((\Omega\to D_1)\to (\Omega\to D_2))$, for $D_1,D_2\in \BC$, the R-topology coincides with the point-R-topology.
\end{proposition}
\begin{proof}
   First, by Proposition~\ref{R-open-func}, we already know that $(t\to O)_p$ is R-open for each $t\in (\Omega\to D_1)$ and each R-open set $O\subseteq (\Omega\to D_2)$. Now suppose $W\subseteq ((\Omega\to D_1)\to (\Omega\to D_2))$ is R-open and $f\in W$. We construct a point-R-open set of the form $\bigcap_{i\in I} (t_i\to O_i)_p\subseteq W$ with $f\in \bigcap_{i\in I} (t_i\to O_i)_p$. By Theorem~\ref{semi-self-from-step}, there exists, a step function 
   \[g=\sup_{i\in I}r_{i}\chi_{\dua u_{i}}\ll f\]
   with simple random variable $r_{i}\ll f(u_{i})$ for $i\in I$ and $g\in W$. By Proposition~\ref{way-below-random-random}, for each $i\in I$, there exists an increasing sequence of simple random variables $(r_{ij})_{j\in \nat}$ 
with $r_{ij}\ll r_{i(j+1)}$ and $T_{RD_2\to PD_2}r_{ij}\ll T_{RD_2\to PD_2}r_{i(j+1)}$ for all $j\in \nat$, satisfying $f(u_i)\sim \sup_{j\in \nat}r_{ij}$. Invoking Proposition~\ref{way-below-random}, there exists a simple random variable $s_i\in (\Omega\to D_2)$ with $s_i\ll \sup_{j\in \nat} r_{ij}$ and $r_i\sim s_i$. Hence, there exists $j\in \nat$ with $s_i\sqsubseteq r_{ij}$. Put $r_i':=r_{ij}$ and define the R-open set  $O_i:=T_{RD_2\to PD_2}^{-1}(T_{RD_2\to PD_2}r_i')$. It follows that we have $f(u_{i})\in O_{i}$ for each $i\in I$. Thus, $f\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$, where the latter is a point-R-open set.
    It remains to show that $h\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$ implies $h\in W$. But $h\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$ gives $h(u_{i})\in O_{i}$. By Proposition~\ref{way-below-random}, there exists $r_i''\sim r'_i$ with $r_i''\ll h(u_i)$ for $i\in I$. Let $g':=\sup_{i\in I} r_i''\chi_{\dua u_i}$. Then $g'\sim g$ and hence $g'\in W$. On the other hand, $g'(t)\sqsubseteq h(t)$ for $t\in (\Omega\to D_1)$ and thus $g'\sqsubseteq h$. Hence, $h\in W$ as $W$ is upper closed. 

 
   
   
\end{proof}


\remove{For the next result, We use the probability space $\Omega_0$. 
\begin{proposition}\label{p-open-f-s}
In the function space $((\Omega_0\to D_1)\to (\Omega_0\to D_2))$, for $D_1,D_2\in \BC$, the R-topology coincides with the point-R-topology.
\end{proposition}
\begin{proof}
   First, by Proposition~\ref{R-open-func}, we already know that $(t\to O)_p$ is R-open for each $t\in (\Omega_0\to D_1)$ and each R-open set $O\subseteq (\Omega\to D_2)$. Now suppose $W\subseteq ((\Omega_0\to D_1)\to (\Omega_0\to D_2))$ is R-open and $f\in W$. We construct a point-R-open set of the form $\bigcap_{i\in I} (t_i\to O_i)_p\subseteq W$ with $f\in \bigcap_{i\in I} (t_i\to O_i)_p$. By Theorem~\ref{semi-self-from-step}, there exists, a step function 
   \[g=\sup_{i\in I}r_{i}\chi_{\dua u_{i}}\ll f\]
   with simple random variable $r_i\in B_{(\Omega_0\to D_2)}$  and $r_{i}\ll f(u_{i})$ for $i\in I$ and $g\in W$.  Define R-open set $O_{i}=T^{-1}(\dua T(r_i))$. Since $r_{i}\ll f(u_{i})$, by Proposition~\ref{random-simple-way-above}, we have $f(u_{i})\in O_{i}$ for each $i\in I$. Thus, $f\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$, where the latter is a point-R-open set. It remains to show that $h\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$ implies $h\in W$. But $h\in \bigcap_{i\in I} (u_{i}\to O_{i})_p$ gives $h(u_{i})\in O_{i}$. By Proposition~\ref{way-below-random}, there exists $r_i'\sim r_i$ with $r_i'\ll h(u_i)$ for $i\in I$. Let $g':=\sup_{i\in I} r_i'\chi_{\dua u_i}$. Then $g'\sim g$ and hence $g'\in W$. On the other hand, $g'(t)\sqsubseteq h(t)$ for $t\in (\Omega_0\to D_1)$ and thus $g'\sqsubseteq h$. Hence, $h\in W$ as $W$ is upper closed. 

 
   
   
\end{proof}}

\begin{corollary}
 The R-topology $\gamma_{((\Omega\to D_1)\to (\Omega\to D_2)}$ satisfies:  
  \[f\sim g \iff \forall O\in \gamma_{((\Omega\to D_1)\to (\Omega\to D_2)}. (f\in O \iff g\in O).\]
\end{corollary}
\begin{proof}
    We only need to check the RHS to LHS implication. Suppose $f\not\sim_{((\Omega\to D_1)\to (\Omega\to D_2)} g$. Then by definition there exists $r\in (\Omega\to D_1)$ such that $f(r)\not \sim g(r)$. Thus, by Corollary~\ref{R-open-iff}, there exists an R-open set $O\in \gamma_{(\Omega\to D_2)}$ such that $f(r)\in O$ and $g(r)\notin O$.  It follows that $f\in (r\to O)_p$ and $g\notin (r\to O)_p$ as required.
\end{proof}
\begin{corollary}
    The lattice of the R-topology of the function space $((\Omega\to D_1)\to (\Omega\to D_2))$ is continuous and countably based.
\end{corollary}
\begin{proof}
    We have $(t\to O)_p\subseteq (t\to O')_p$ iff $t\sqsubseteq t'$ and $O\subseteq O'$. It follows that $\gamma_{((\Omega\to D_1)\to (\Omega\to D_2))}\cong (RD_1)\times \gamma_{RD_2}$. Since $(\Omega\to D_2)\in \BC$ and $\gamma_{RD_2}$ is a countably based continuous lattice, the result follows. 
\end{proof}

Next, we consider continuous valuations with respect to the R-topology on the function space $((\Omega\to D_1)\to (\Omega\to D_2))$. First, we note the following general result.
\begin{proposition}
For any PER domain $(D,\sim)$, the set $\mathcal{P}(D)$ of continuous valuations on the topological space $(D,\gamma_D)$ is a dcpo and any such continuous valuation is the supremum of simple valuations in $(D,\Sigma_D)$ way-below it. 
\end{proposition}
 \begin{proof}
 Any continuous valuation of  $(D,\gamma_D)$ is of the form $\nu\circ r^{-1}$, where $r:A\to (D,\Sigma)$ is a random variable. Thus, any such continuous valuation is the restriction of a continuous valuation on $P(D,\Sigma)$ to the sub-topology $\gamma_{(D,\sim)}\subseteq \Sigma_D$. Thus, if $\nu\circ r^{-1}_i$, for $i\in I$, is a directed set of continuous valuations on $(D,\gamma_D)$, then the $(r_i)_{i\in I}$ is directed with $r=\sup_{i\in I}r_i$ as its supremum, implying that $\nu\circ r^{-1}$ is the supermum of the continuous valuations $\nu\circ r^{-1}_i$, for $i\in I$. Since $P(D,\Sigma)$ is a continuous, any continuous valuation is the supermum of simple valuations way-below it. 
\end{proof}

\begin{corollary}
    Any continuous valuation on  $(((\Omega\to D_1)\to (\Omega\to D_2)),\gamma)$ is the supremum of an increasing sequence of simple valuations on $(((\Omega\to D_1)\to (\Omega\to D_2)),\gamma)$.
\end{corollary}
\begin{proof}
 By Theorem~\ref{semi-self-from-step}, any element of the function space is equal to the supremum of a set of step functions way-below it. Thus, given any continuous valuation $\alpha$ on $((\Omega\to D_1)\to (\Omega\to D_2),\gamma)$, the collection of simple valuations of the form
 \[\beta=\sum_{i\in I}m_i\delta(f_i),\]
 where $f_i$ are step functions, way below $\alpha$ is directed with supremum $\alpha$. Let $f_i=\sup_{j\in J_i}\chi_{O_{ij}}r_{ij}$ for $O_{ij}=\bigcap_{j\in J_i}{[q_j\to \dua d_j]_{n_j}}$ and $r_{ij}:A\to D_2$ a step function for $i\in I$ and $j\in J_i$. Put $\hat{f_i}=\sup_{j\in J_i}\chi_{\hat{O}_{ij}}r_{ij}$ for $\hat{O}_{ij}=\bigcap_{j\in J_i}{[q_j\to \dua d_j]}$ and \[\hat{\beta}=\sum_{i\in I}m_i\delta(\hat{f}_i)\] Then $\hat{f_i}$ is an R-continuous step function for each $i\in I$ and thus $\hat{\beta}$ is a simple evluation in $((\Omega\to D_1)\to (\Omega\to D_2),\gamma)$ with $\beta\sqsubseteq \hat{\beta}\sqsubseteq \alpha$. It follows that $\alpha$ is the supremum of the directed set of simple valuations $\hat{\beta}$ for simple valuations $\beta\ll \alpha$.
\end{proof}

\remove{Now consider the domain $(\Omega\to (RD_1\to RD_2))$ for domains $D_1,D_2\in \BC$. 

\begin{proposition}
  The R-topology $\gamma$ on $(\Omega\to (RD_1\to RD_2))$ has sub-basic open sets $[q\to O]$ where $O\in \gamma_{(RD_1\to RD_2)}$.
\end{proposition}
\begin{proof}
    We already know that $[q\to O]$ where $O\in \gamma_{(RD_1\to RD_2)}$ is R-open. Suppose $M\subseteq (\Omega\to (RD_1\to RD_2))$ is R-open and $f\in M$. Let \[g=\sup_{k\in K}\chi_{U_k}s_k\in (\Omega\to (RD_1\to RD_2))\] be a step function built from semi-self-related complete step functions \[s_k=\sup_{i\in I_k} r_{ki}\chi_{\dua u_{ki}}\] for $k\in K$ in $(RD_1\to RD_2)$ with $g\ll f$, $r_{ki}\ll f(u_{ki})$, for $k\in K$ and $i\in I_k$, and $g\in M$. Then, for each $\bfomega\in A$, we have $g(\bfomega)\ll f(\bfomega)$. Let $r_{ki}=\sup_{j\in J_{ki}} \chi_{W_{kij}}t_{kij}$. Put $O_k=\bigcap_{i\in I_k}(u_{ki}\to O(r_{ki}))_p$, for each $k\in K$, where $O(r_{ki})=\bigcap_{j\in J_{ik}}[\nu(W_{kij})\to \dua t_{kij}]$. Then , we have: $f\gg g\in \bigcap_{k\in K}[\nu(U_k)\to O_k]\in \gamma_{(RD_1\to RD_2)}$. 
\end{proof}}
\remove{\section{PER domain with basis}

An effective construction of an PER domain can be given by
$(D, B, \equiv, C_o, C_p)$  where D is a continuous domain, B is a base, $\sim$ is an equivalence relation on the base and $C_o$ and $C_p$  are set composed by subsets of the base B, with the condition that any $c \in C_o$ is a subset of an equivalence class of $B$.

The self-related elements in $D$ are the elements that can be defined as 
$\bigsqcup (\bigcup_{i \in I} c_i)$ with $c_i \in C_p$.

While the $\bigcup_{b \in c} \dua b$ with $c \in C_o$ define a base for the R-topology.


On the hierarchy of domains constructed using the probabilistic powerdomain and the function space constructors the base can be defined as follows:

For standard domains, $\equiv$ is the identity relation and $C_o$ and $C_p$ are composed of the whole singletons.

For $PD = A \to D$ the elements of the base, written in canonical form, are step functions in the form:
$\sup_{j\in J}b_j\chi_{C_j}$, with $C_j$ disjoint rational crescent and $b_j$ element of the base of $D$.

The equivalence relation on the base is defined by:
\[
\sup_{j\in J}b_j\chi_{C_j} \equiv \sup_{j\in J}b'_j\chi_{C'_j} \mbox{ iff }
\forall j\in J . b_j \equiv b'_j , \mu(C_j) = \mu(C_j) 
\]

The set $C_o$ is composed of sets in the form:
\[
\{ \sup_{j\in J}b_j\chi_{C_j}  \mid  \mu(C_j) = q_j, b_j \in c_j
\}
\]
with $q_j$ rational number and $c_j$ in $C_o$ of the domain $D$.

The set $C_p$ is composed of sets in the form:
\[
\{ \sup_{j\in J}b_j\chi_{C_j}  \mid  b_j \in c_j
\}
\]
with $C_j$ fixed and $c_y$ in $C_p$ of the domain $D$.


For $D \to E$ the elements of the base, written in canonical form, are step functions in the form:
$\sup_{j\in J}e_j\chi_{d_j}$, with $d_j$ disjoint rational crescent in $D$ and $e_j$ element of the base of $E$.

The equivalence relation on the base is defined by:
\[
\sup_{j\in J}e_j\chi_{d_j} \equiv \sup_{j\in J}e'_j\chi_{d'_j} \mbox{ iff }
\forall j\in J . d_j \equiv d'_j , d_j \equiv d'_j
\]

The set $C_o$ is composed of sets in the form:
\[
\{ \sup_{j\in J}e_j\chi_{d_j}  \mid e_j \in c_{Ej},  d_j \in c_{Dj} 
\}
\]
with $c_{Dj}$ in $C_p$ of the domain $D$ and  $c_{Dj} $ in  $C_o$ of the domain $E$.

The set $C_p$ is composed of sets in the form:
\[
\{ \sup_{j\in J}e_j\chi_{d_j}  \mid e_j \in c_{Ej},  d_j \in c_{Dj} 
\}
\]
with $c_{Dj}$ in $C_o$ of the domain $D$ and  $c_{Dj} $ in  $C_p$ of the domain $E$.}

}
\section{A probabilistic functional language}

Next, we present a simple functional language, which we call PFL, having a probabilistic evaluation mechanism and enriched with two primitive operators for nondeterminism: $\sample$ to sample real values from a uniform distribution on the interval $[0,1]$ and a primitive $\score$ that changes the weight associated with different traces of the probabilistic computation. The language can be described as Plotkin's PCF, a simply typed $\lambda$-calculus with constants, extended with a type for real numbers and probabilistic choice.
In defining the language, we choose a minimalistic approach and introduce only those types and constructors necessary to illustrate our approach to probabilistic computation semantics.

The type of real numbers is necessary to deal with probabilistic distribution over continuous spaces.  PFL performs a simple form of exact real number computation.
In this way we can define a precise correspondence, i.e., adequacy, between the denotational semantics base on continuous domain, and the operational semantics without bothering about the errors generated by the floating-point computation, but also without introducing unrealizable assumption in the language as having a language constant for each real-number or a decidable order relation $<$ on real-numbers.
In defining the language, we choose a minimalistic approach and introduce only those types and constructors necessary to illustrate our approach to probabilistic computation semantics.

% \subsection{Types}

The types of the language are defined by the grammar: 
\[\tau \ ::=  \iota \ \mid \ \ o \  \mid \ \nu \ \mid \  \rho \ \mid\  \ \tau \rightarrow \tau \]
where $\iota$ is the unit type, $o$ is the type of booleans, $\nu$ is the type of natural numbers, $\rho$ is the type of real numbers.

Some languages, e.g.|~\cite{GoubaultJT23}, introduce a type constructor $D$ for probabilistic computation: in this setting, the terms of type $\rho$ can perform only deterministic computations and return single values, while terms of type $D \rho$ can also perform probabilistic computation and return a distribution.  For simplicity, we consider all terms as potentially probabilistic and therefore denoting distributions.  By standard techniques, it would be straightforward, to transform our type system into a more refined one. 
The set of expressions in the language is defined by the grammar: 
\begin{equation} \label{grammar}
   e ::=  \lo{c} \ \mid\ x^\tau \ \mid\ e_1 e_2 \ \mid\ \lambda x^\tau \ldot e \ \mid\  \lo{ite} e e_1 e_2 \ \mid \pr e \
\end{equation}
where $x^\tau$ ranges over a set of typed variables, and $\lo{c}$ over a set of constants. The constructor $\lo{ite}$ is an if-then-else operator.  The constructor $\pr :  \rho \rightarrow \rho$ represents a function projecting a value on the unit interval $[-1,1]$. The behaviour of $\pr$ is defined by $\pr(x) = \rmax(-1, \rmin(x , 1))$.  The constructor $\pr$ plays an essential role in allowing the termination of recursive definition of functions on the real type $\rho$.  

The main constantsin probabilistic computation, are:
 
 \begin{itemize}
 \item For any pair of rational numbers $a \leq b$, a real constant $\inter{[a,b]} : \rho$ representing the result of a partial computation on real numbers, returning the interval $[a,b]$ as an approximation of the exact result.

\item a sample function $\sample : \rho$ implementing a probabilistic computation returning a real number uniformly distributed on interval $[0,1]$  

\item for any function type $\sigma \to \tau$ a fixed point operator $Y_{\sigma \to \tau} : ({\sigma \to \tau} \to \sigma \to \tau) \to \sigma \to \tau$

\item  an integration functional $\integral_\rho : (\pi \rightarrow \rho) \rightarrow \rho$, giving the integral of a function on the interval $[0,1]$, 

\end{itemize}

We do not fully specify the set remaining constants. They should be chosen in such a way to guarantee the  definability of any computable function on natural and real numbers. Typically the set of constants contains the test for greater that zero functions on natural and real numbers  $(0<)^{\rho} : \rho \to o$ and some basic arithmetic operations on natural numbers and real numbers such as $\cplus^{\nu}: \nu \to \nu \to \nu$, $\cplus^{\rho} \rho \to \rho \to \rho$.

\hypertarget{operational-semantics}{%
\subsection{Operational semantics}\label{operational-semantics}}

We define a small-step operational semantics. In the operational semantics, we need to address two main problems: modeling probabilistic computation and implementing exact real number computation.

The modeling of probabilistic computation is approached using sample-based operational semantics \cite{Park2008,Lago2019}. The intuitive idea is that probabilistic computation is modeled by deterministic computation with an extra parameter that introduces a source of randomness; in our case, this extra parameter is a sequence of random bits. Each bit is independent of the previous ones and has equal probability of being $0$ or $1$.

The $\score$ operator adds an extra level of complexity, since different execution traces, generated by different sequences of random bits, may have different weights. This is handled by explicitly maintaining the weight as an additional parameter during evaluation. The probability of obtaining a value $v$ as the result of the computation is then computed by integrating the weights over all random bit sequences that lead to that result $v$.

In contrast to other approaches to probabilistic computation, we directly address the issue of real number computation by defining a way to implement exact computation on real numbers.  Exact real number computation is considered also in \cite{GoubaultJT23}, but there the operational semantics is simplified by assuming the existence of a constant for each real number. To avoid extra complexity, we use a simplistic approach. The valuation of an expression $e$ receives an extra parameter, a natural number $n$, representing the level of precision, i.e., the effort with which the computation of $e$ is performed. If $e$ is an expression of type real, the result of the computation will be a rational interval $[a,b]$. Greater values of $n$ will lead to smaller intervals and, therefore, more precise results. In a practical implementation of exact real number computation, to avoid unnecessary computation, it is necessary to choose the precision used for the intermediate result carefully. Here we neglect the efficiency problem and content ourselves with the fact that sufficiently great values of $n$ will return the final result with arbitrary precision.  This approach to the operational semantics is somewhat similar to and inspired by~\cite{ShermanMC19,bauer08}.

We implement the three points outlined above using two techniques. First, within the operational semantics rules, we extend the syntax of PFL by adding expressions of the form $\langle e \mid s, n \rangle$.
%( or $\langle e \mid s, (m,n) \rangle$)
 Here $e$ is the PFL term to evaluate, and $s$ and $n$ are two parameters used in the evaluation:
\begin{itemize}
\item $s$ is the source of randomness, a string of digits generated by the random bit generator.
\item $n$ 
(or the pair $(m,n)$) 
is the level of accuracy for real value calculations when evaluating the expression $e$.
\end{itemize}
Formally the extended language is obtained by adding to the grammar defined in Equation \ref{grammar} the new production 
\[ e::=  \langle e \mid s, n \rangle   \]
with $ s \in \{0,1\}^\star$ and $n \in \nat$.

Second, the operational semantics reduction steps are of the form $(w,e) \to (w',e')$, where $e$ is an extended PFL expression and $w$ is a rational number representing the estimated weight of the current computational trace.

The operational semantics makes it possible to derive judgments of the form $(\langle e \mid s, n \rangle, w) \to^* (\inter{[a,b]}, w')$, whose intended meaning is that the expression $e$, given the source of randomness $s$ and accuracy level $n$, reduces to the interval $[a,b]$. During this reduction, the weight of the computation trace changes from $w$ to $w'$.

Higher values of the parameter $n$ imply more effort in the computation so it will always be the case that if  $n_1 \leq n_2$, and $s_1 \sqsubseteq s_2$,  $\langle e \mid s_1, n_1 \rangle \to \inter{[a,b]}$ and $\langle e \mid s_2, n_2 \rangle \to \inter{[c,d]} $ then $[a,b]  \supseteq {[c,d]}$.  We prove that the valuation of $\langle e \mid s_0,  0 \rangle, \langle e \mid s_1, 1 \rangle, \langle e\mid s_2,   2\rangle$, \ldots,  with $s_0 \sqsubseteq s_1 \sqsubseteq s_2$ \ldots,  produces a sequence of intervals each one contained in the previous one and converging to the denotational semantics of $e$.

Given a standard term $e$, the reduction steps start from an extended term in the form $(\langle e \mid s, n \rangle, 1)$. The reduction steps are of two kinds. Some reduction steps substitute some subterm $e'$ of $e$ with some extended terms of the form $\langle e' \mid s', n' \rangle$; essentially, these steps define the parameters used by the computation on $e'$. Other reduction steps perform more standard computation steps, for example, $\beta$-reduction.

 The valuation mechanism in PFL is call-by-value. A call-by-name mechanism of valuation will have a problem when a term representing a real number is given as an argument to a function, the formal argument of the function can appear in several instances inside the body of the function, and there is no way to force these several instances of the formal argument to evaluate to the same real number.
This behaviour is unnatural since it introduces in the computation more non-determinism than one would like to have.   

The computation halts on pairs $(e, w)$, where $e$ is a value. The values, $v$, on the types $o$ and $\nu$, are the Boolean values and natural number constants. The values for type $\rho$ are the rational intervals, $\inter{[a,b]}$. The values for function types are the $\lambda$-expressions and the functions constant in the language. 

The valuation contexts are standard ones for a call-by-value reduction:
\[ %\begin{multline*}
E[\_] ::= [\_] \ \mid\ E[\_] \, e  \ \mid\ v \, E[\_] \ \mid\ \lo{op} v \, E[\_]  
% \\
\ \mid\ \lo{ite} E[\_]  \, e_1 \, e_2 
\] %\end{multline*}

For any reduction context $E[\ ]$, there is the rule:
\[
\frac{(e_0, w_0) \to (e_1, w_1)}{(E[e_0], w_0) \to (E[e_1], w_1)} 
\]
The reduction rules for application are: 
% call-by-name 
% $$
% \langle e_1 e_2 \mid s, n \rangle \to  \langle e_1 \mid s, n \rangle e_2
% \hspace{2em}
% \langle \lambda x . e_1, \mid m \rangle e_2 \to  \langle e_1 [e_2/x], m \rangle
% % \hspace{2em}
% % \langle c , m \rangle e \to  c \langle e, m \rangle
% % \hspace{2em}
% % \langle c \, v, m \rangle e \to  c \, v \langle e, m \rangle
% $$
% call-by-value
\begin{align*}
(\langle e_1 e_2 \mid s, n \rangle, w) & \to  (\langle e_1 \mid s_e, n \rangle \langle e_2 \mid s_o, n \rangle , w) 
% \hspace{2em}
\\ 
(\langle \lambda x^\tau \ldot e_1 \mid s, n \rangle, w) & \to  (\lambda x^\tau \ldot \langle  e_1 \mid s, n \rangle, w)
\\
((\lambda x^\tau . e) v, \, w) & \to (e [v / x^\tau],\, w)
\end{align*}
where $s_e$ and $s_o$ denote the sequences of bits appearing in the even, respectively odd, positions in $s$.

The constant $\sample$ is not a value and the associated reduction rule is:
\begin{multline*}
(\langle \sample \mid \langle s_i \rangle_{1 \leq i \leq m} , n \rangle, w) \\
\to ([\Sigma_{i=1}^{o} s_i \cdot 2^{-i}, \ (\Sigma_{i=1}^{o} s_i \cdot 2^{-i}) + 2^{-n} ] , w)  
\end{multline*}
with $o = \min(m, n)$

The rule for $\score$ is the only one explicitly modifying the weight associated to a computation:
\[
(\score [a,b], w) \to ( (), a \cdot w)
\]


The constructor $\pr$, as $\lo{ite}$, does not always force the valuation of its argument:
\begin{align*}
(\langle \pr \mid s, 0 \rangle e, \, w) & \to ([-1,1], \, w) \\
(\langle \pr \mid s, (n+1) \rangle [a,b], w) & \to
\begin{cases}
    ([-1,-1], w) & \mbox{if } b \leq -1 \\
    ([1,1], w) & \mbox{if } a \geq 1 \\
    ([a,b] \cap [-1,1], w) & \mbox{otherwise}
\end{cases}
\end{align*}

For the other constructors and constants $c$ we have the rules: 
$$
( \langle c \mid s, n \rangle, w) \to (c, w),
$$
together with specific rules concerning the constants in the language that denotes functions. 

% The reduction rules for a generic binary operation on $\operatorname{op}$ have form 
% $$
% \langle e_1 \, \operatorname{op} \, e_2 \mid s, n \rangle \to 
% \langle e_1 \mid s_e, n \rangle \, \operatorname{op} \, \langle  e_2 \mid s_o, n \rangle 
% $$
% \begin{align*}
% \langle \osup f, (m,n)\rangle  & \to \rmax \langle \osup \lambda x . f( x / 2), (m-1,n)\rangle  
%                                       \langle \osup \lambda x . f((x + 1)/ 2), (m-1,n)\rangle
% \end{align*}
For the fixed point operator, $Y_\sigma$, we distinguish whether the type $\sigma$ is in the form 
$\sigma = \sigma_1 \rightarrow \ldots \sigma_n \rightarrow \rho$, or not; that is, if the final return value is a real number or not.  
In the first case, the operational semantics makes use of the parameter $n$, and it is defined as
\begin{align*}
% Y_{\sigma} (\lambda x \ldot \langle e \mid s,  0 \rangle) & \to \bot_\sigma  \\
(Y_{\sigma} (\lambda F \ldot \langle e \mid s, n \rangle),\, w) & \to 
  (\langle e [(Y_{\sigma} \, \lambda F \ldot e)/ F] \mid s, (n - 1) \rangle,\, w)
\end{align*}
% where $\bot_\sigma$ is defined as follows $\bot_{\rho} = (-\infty, +\infty), \bot_{\sigma \rightarrow \tau} = \lambda x_\sigma . \bot_\tau$.
Intuitive explanation: in order to have a convergent computation, in an expression of the form $Y_{\sigma} (\lambda F \ldot e)$ any recursive call of $F$ should be guarded by an application of the projection operator $\pr$, that is any instance of $F$ in $e$, should be inside an expression in the form $\pr e'$. In this way, when the parameter $n$ in the valuation of the recursive call
$\langle e [(Y_{\sigma} \, \lambda F \ldot e)/ F] \mid s, n \rangle$ reaches the value $0$, the recursive call 
$(Y_{\sigma} \, \lambda F \ldot e)$ is avoided and $\pr e'$ generates the value $[-1,1]$.


In the second case we use the more standard rule: 
\[
(Y_{\sigma} (\lambda F \ldot \langle e \mid s, n \rangle),\, w) \to 
  (\langle e [(Y_{\sigma} \, \lambda F \ldot e)/ F] \mid s, n \rangle,\, w) 
\]
The operational semantics rules for the constants representing the operation on real numbers $(0 <), +, -, *, /, \rmin, \rmax$ are the standard ones, for example:
\begin{align*}
\\
  ((0 <)\inter{[a,b]},\, w) & \to (\ttt,\, w) \ \ \text{ if } a > 0
\\
  ((0 <)\inter{[a,b]},\, w) & \to (\ff,\, w) \ \ \, \text{ if }  b < 0
\\
 (\inter{[a_1, b_1]} + \inter{[a_2, b_2]},\, w) & \to (\inter{[a_1 + a_2, b_1 + b_2]},\, w)
\\
\ldots  
\end{align*}
The remaining rules are standard for a call-by-value typed $\lambda$-calculus. 

% In particular, we have:
% \begin{align*}
%   \mathsf{ite} \, \ttt \, e_1 \, e_2 & \to e_1
% \\
%   \mathsf{ite} \, \ff \,  e_1 \, e_2 & \to e_2
% \end{align*}


\subsection{Denotational semantics}\label{denotational-semantics}

A call-by-value $\lambda$-calculus is usually modelled considering a category of domains without bottom~\cite{Win93}, in which to interpret values, and raise objects, with bottom, in which to interpret general expressions. In our setting it is quite straightforward to define a category of PER domains without bottom $\PD_s$; for lack of space we omit the explicit definition.
The semantics interpretation is given in terms of the computational monads.  In our case, the monad of computations, transforming the domain of values, on a given type, to the domain of computation, is defined as $\mathcal{C} = \mathcal{R}_0 \circ (\ )_\bot$ where $(\ )_\bot$ is the lifting monad, necessary to give semantics to recursion, and $\mathcal{R}_0$ is the monad for random variables. The lifting monad $(\ )_\bot$ is generated by an adjunction pair from the category of PER domains without bottom $\PD_s$ to the category of PER domains with bottom, $\PD$, and strict functions as morphism, while $\mathcal{R}_0$ is a monad on the category of $\PD_\bot$, it follows that $\mathcal{C}$ can be defined as the composition of an adjunction pair and therefore is a monad. Since both $\mathcal{R}_0$ and $(\ )_\bot$ are strong commutative monads, $\mathcal{C}$ is a commutative monad too.

The natural transformations 
$\eta^\mathcal{C}_{\langle D, \sim_D\rangle} : \langle D, \sim_D\rangle \to \mathcal{R}_0(\langle D, \sim_D\rangle)_\bot$ and 
$\mu^\mathcal{C}_{\langle D, \sim_D\rangle} :   \mathcal{R}_0(\mathcal{R}_0(\langle D, \sim_D\rangle)_\bot)_\bot \to \mathcal{R}_0(\langle D, \sim_D\rangle)_\bot$ making $\mathcal{C}$ a monad are:  
\begin{align*}
   & \eta^\mathcal{C}_{\langle D, \sim_D\rangle} (d) =  (\mathbf{1}, \lambda \bfomega \,.\,\lifted{d}) \\
   & \mu^\mathcal{C}_{\langle D, \sim_D\rangle} (w,r) =  
    \\
   & \hspace{1em} \begin{aligned}[t]
           & (\lambda \bfomega \,.\, \mathrm{let}\ (w_1, r_1) \Leftarrow r (h_1 (\bfomega)) \ \mathrm{in} \ w(h_1 (\bfomega)) \cdot w_1(h_2 (\bfomega)), \\
     & \ \lambda \bfomega \,.\, \mathrm{let}\ (w_1, r_1) \Leftarrow r(h_1 (\bfomega)) \ \mathrm{in} \ r_1(h_2 (\bfomega))) 
    \end{aligned}
\end{align*}
where $\lifted{d}$ denotes the lifted element of $d$, while \\ $\mathrm{let}\, x \Leftarrow d_1 \, \mathrm{in} \, d_2(x)$, denotes the value $\bot$ if $d_1$ is $\bot$, and the value $d_2(d)$ if $d_1 = \lifted{d}$.

The  PER domain $\Dom_\tau$, used to give semantic interpretation to values having type $\tau$, is recursively defined as follows: $\Dom_o = \langle \{ \lo{ff}, \lo{tt} \}, \id_o \rangle$, $\Dom_\nu = \langle \nat, \id_\nu \rangle$, $\Dom_\rho = \langle \realDom, \id_\rho \rangle$,  $\Dom_{\sigma \to \tau} = (\Dom_\sigma \to C \, \Dom_\tau)$, where $\id_o, \id_\nu, \id_\rho$ are the identity relations on the corresponding domains.

The semantic interpretation of \emph{deterministic} constants is derived by the standard deterministic semantics of this operator by the composition of the natural transformation $\eta$.  For example the denotation of the successor operator $\lo{succ}$ on natural numbers, $\bsem{\lo{succ}}$ is an element on $\Dom_{\nu \to \nu} = \Dom_\nu \to \mathcal{C} \, \Dom_\nu$ defined by  $\eta_{\Dom_\nu} \circ \bsem{\lo{succ}}^{\mathbf{st}}$, where $\bsem{\lo{succ}}^{\mathbf{st}}$ is the standard, deterministic semantics of $\lo{succ}$.

The semantic interpretation of $\sample$, that it is not considered a value, is parametric on the sample space $\Omega$ and on a function $u : \Omega \to \realDom$ which is measure preserving:
for $\Omega = [0,1]$, $u$ is the immersion function, for $\Omega = 2^\nat$,
$u (\langle x_i \rangle_{i \in \nat}) = {\Sigma_{i=1}^{\infty} x_{i} \cdot 2^{-i}}$

\[ \esem   
{\sample}_{\sigma} : \mathcal{C} \Dom_\rho = ( \mathbf{1}, \,\lambda \bfomega \,. \lifted{u(\bfomega))}
\] 
The semantics of $\score$ satisfies the condition of being a continuous function from $\realDom \to (\Omega \to \overline{\realLine^+}$), and it is consistent with the weight function providing a lower bound for the valuation function associated with a random variable. 
\[ \esem   
{\score}_{\sigma}([a,b] ) = (\lambda \bfomega \,.\, a, \, () )
\] 
% The semantics of integral is ...
% \[\bsem{\integral } f =  \int^\mathsf{d}_{[0,1]} f(x) dx \]

The semantic interpretation of the fixed-point operator is: 
\begin{align*}
&  \bsem{\lo{Y}_{\tau} } F  = \bigsqcup_{i \in \nat} (\mu^\mathcal{C}_{\Dom_\tau} \circ F)^i (\bot_\tau) 
\end{align*}

with $F : \Dom_{\tau \to \tau} = (\Dom_\tau \to \mathcal{C} \Dom_\tau)$

The semantic interpretation function \(\mathcal E\) is defined, by structural induction, in the standard way. 
More specifically, given a (well typed) term $e$ of type $\tau$ with free variables on the list $x_1^{\tau 1}, \ldots x_n^{\tau n}$, the denotational semantics of $e$, $\esem{e}$ is a continuous function from PER domain $\Dom_{\tau 1} \times \ldots \times \Dom_{\tau n}$ into $C \Dom_{\tau}$ preserving the partial equivalence relation, i.e. $[\esem{e}]$ is a morphism on the category of PER domains. 

\[\begin{aligned}
  \esem{c}_\rho &= \eta (\bsem{c})\\
  \esem{x^\tau}_\rho &= \eta (\rho(x^tau))\\
  \esem{e_1 e_2} &= \mu \circ (T \lo{eval}) \circ t \circ  \langle \esem{e_1}, \esem{e_2}\rangle \\
  \esem{\lambda x^\tau.e}_\rho &= \lambda d \in \mathcal D_\rho.\esem{e}_{(\rho[d/x])}\\
%   \esem{\mathsf{if} \ e \ \mathsf{then} \ e_1 \ \mathsf{else} \ e_2}_\rho &= \begin{cases} \esem{e_1}_\rho,& \esem{e}_\rho=\ttt\\ \esem{e_2}_\rho &\esem{e}_\rho=\ff\\ \bot,& \esem{e}_\rho=\bot \end{cases} \\
%   \esem{\mathsf{pif}_{\iota} \ e \ \mathsf{then} \ e_1 \ \mathsf{else} \ e_2}_\rho &= \begin{cases} \esem{e_1}_\rho,& \esem{e}_\rho=\ttt\\ \esem{e_2}_\rho &\esem{e}_\rho=\ff\\ \esem{e_1}_\rho \sqcap \esem{e_2}_\rho,& \esem{e}_\rho=\bot \end{cases}\\
\end{aligned}\]

\subsection{Adequacy}\label{adequacy}

The correspondence between the denotational and the operational semantics is shown by the following result. 
Let $S$ be a finite set of disjoint binary sequences, we define the measure of $S$ as 
$\mu(S) = \Sigma_{s \in S} 2^{- \mathrm{lengh}(s)}$. 

For a rational number $q$, constant $c$ and closed FPL expression  $e$ of ground type $\tau$, i.e. $\tau \in \{ \iota, o, \nu, \rho \}$  we write \( (c,q) \ll_o Eval(e)\) if there exists a natural number $n$, a finite set of disjoint binary sequences $S$ and an $S$-indexed set of rational numbers $\{ q_s | s \in S\}$ such that 
for any $s \in S$, $(\langle e, n, s \rangle,\, 1) \to^* (d,\, q_s) $ with  $q < \Sigma_{s \in S}\, q_s$ and $c = d$ for the ground types $ \iota, o, \nu$ , for the ground type $\rho$  $d$ has to be an interval contained in the interior of the interval $c$   ($c= [a,b], d =  [a',b'] $ and $a < a' < b' < b$).

Similarly, for any PER domain $(D, \sim)$, element $d \in (D, \sim)$, $(w, r) \in \mathcal{C}(D, \sim)$, and rational number $q$, we write 
$(d, q) \ll_d (w, r)$ if $q < \nu_w r^{-1}(\dua d)$.
\begin{theorem} \label{adequacyT}
The operational semantics is sound and complete with respect to the denotational semantics, that is for any  ground type $\tau$,  constant$c$,  closed expression $e$ of type $\tau$  and dyadic number $q$, $(c, q) \ll_o Eval(e)$ iff 
$(\bsem{c}^{\mathbf{st}}, q) \ll_d \esem{e}$ 
\end{theorem}
{
\begin{proof}
We use the standard proof technique of computability predicates.

We define a computability predicate $\Comp$, first on closed terms of groung type \( \tau\), by requiring that the denotational and operational semantics coincide. That is, 
$\Comp(e)$ when for all $q, c$ $(c, q) \ll_o Eval(e)$ iff 
$(\bsem{c}^{\mathbf{st}}, q) \ll_d \esem{e}$ 

The computability predicate is then extended to closed expressions of arrow type by requiring the preservation, to closed elements of any type, and by closure, to arbitrary elements.

Using the standard technique of computability predicates, it is possible to prove that all constants are computable, and that \(\lambda\)-abstraction preserves the computability of expressions. Therefore all expressions are computable.
\end{proof}
}

\subsection{Conditional probability }
 The conditional probability can be expressed in our language in the following way.
Given a term $e_r : \tau$ describing an extended random variable $r$ on $(\Dom_\tau)_\bot$, that is, $r \in \mathcal{C}(\Dom_\tau) = (\Omega \to \overline{\realLine^+}, \Omega \to (\Dom_\tau)_\bot)$ such that $\esem{e_r} = r$, and
a deterministic term $e_t : \tau \to o$ describing a disjoint event-pair $(O_1, O_2)$, that is $\esem{e_t} \in C(\Dom_\tau \to C(\Dom_o)) = \eta^{\mathcal{C}}_{\Dom_\tau \to C(\Dom_o)}(f)$ with $f : \Dom_\tau \to C(\Dom_o)$ and $O_1 = f^{-1}(\eta^{\mathcal{C}}_{\Dom_o}(\ttt))$ and $O_2 = f^{-1}(\eta^{\mathcal{C}}_{\Dom_o}(\ff))$,
the conditional random variable $r_{(-,(O_1,O_2))}$ is equal to the denotational semantics of the term:
\[Y_{\tau} (\lambda x^{\tau} \,.\, ( \lambda y^{\tau} \,.\, \operatorname{if} \, e_t \, y^{\tau} \, \operatorname{then} \, y^{\tau} \, \operatorname{else} \, x^{\tau}) \, e_r )\]
A general function whose arguments are two variables $x^{\iota \to \tau}_r$ and $x^{\tau \to o}_t$, with $x^{\iota \to \tau}_r$ the descriptions of a random variable on $r$ $\Dom_\tau$ and $x^{\tau \to o}_t$ the description of a disjoint event-pair in $\Dom_\tau$ returns the conditional probability can be define as follows:  
\begin{multline*}
    \lambda x^{\iota \to \tau}_r \,,\, x^{\tau \to o}_t \,.\, \\
    Y_{\tau} (\lambda x^{\tau} \,.\, ( \lambda y^{\tau} \,.\, \operatorname{if} x^{\tau \to o}_t y^{\tau} \operatorname{then} y^{\tau} \operatorname{else} x^{\tau}) (x^{\iota \to \tau}_r *) )
\end{multline*}
 It is convenient to describe random variable $r$ in the domain $\Omega \to D$ using thunks, that is terms in the form $\lambda x^\iota \, . \, e$, a thunk is a to pass, in call-by-value language an expression $e$ to function $f$ without forcing its valuation, or in other terms, to simulate a call-by-name passage of arguments in a call-by-value language.  

\section{Conclusion}
We have presented a domain-theoretic framework for probabilistic programming that addresses four main issues: the treatment of conditional probability, continuous distributions,  exact computation, and higher-order functional programming. 

In particular, we have shown that in the domain-theoretic framework of open sets as observable events, the conditional probaility and conditional random variables are computable on effectively given domains.

Our framework provides a constructive definition of conditional probability through observable events and proves the consistency between scoring-based and rejection sampling approaches.

Future work includes developing interval notions of computability to effectively normalize general valuations into probabilistic valuations. Additionally, we plan to apply our semantic framework to develop formal reasoning principles for establishing equivalence between probabilistic programs.


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
%% \bibliographystyle{ACM-Reference-Format}
\bibliography{CCCRandomVariables,library_ord}
\bibliographystyle{ACM-Reference-Format}


\end{document}

  \remove{

Consider the bounded complete domain $D$ equipped with the sigma algebra induced by the Scott topology as a measure space. We know that every continuous valuation on $D$ uniquely corresponds to a measure on $D$. Any simple valuation on $D$ therefore corresponds to a unique measure on $D$. In addition every Scott continuous function $g:D\to \realDom^+$ with $g=[g^-,g^+]$ gives rise to the semi-continuous and thus measurable functions $g^-$ and $g^+$, and if $g$ is a step function then $g^-$ and $g^+$ are simple functions in the sense of classical measure theory.  Given step functions $g_0=\sup_{i\in I}a_i\chi_{O_i}\in (D\to \realDom)$ and $r_0=\sup_{j\in J}{d_j}\chi_{U_j}\in (A\to D)$, define
\[E(r_0,g_0):=\sum_{i\in I,j\in J} \left\{a_i\nu(U_j):d_i\in O_j\right\}=\left[\int g_0^-\,d\nu\circ r_0^{-1},\int g_0^+\,d\nu\circ r_0^{-1}\right]\in \realDom^+,\]
where the integrals donote Lebesgue integrals.

Then $E$ is monotone in its two arguments and by properties of the  continuous domain $\realDom$, it defines a continuous map 
\[\hat{E}: (A\to D)\times (D\to \realDom^+)\to \realDom^+,\]
by taking $\hat{E}(r,g)=\sup\{E(r_0,g_0): r_0, g_0 \mbox{ step functions with }r_0\ll r,g_0\ll g\}$. It is also easy to check that $\hat{E}(r_0,g_0)=E(r_0,g_0)$ for step functions $r_0$ and $g_0$. Therefore, we can, for convenience, simply write $\hat{E}$ as $E$.

If $r=\sup_{i\geq 0}r_i$ and $g=\sup_{i\geq 0}g_i$, then the continuity of $E$ implies:
\[E(r,g)=\sup_{i\geq 0} \sup_{j\geq 0} E(r_i,g_j)=\sup_{j\geq 0} \sup_{i\geq 0} E(r_i,g_j)=\sup_{i\geq 0} E(r_i,g_i).\]



\begin{theorem}  For any random variable $r:2^{\nat}\to D$ and any Scott continuous map $g:D\to \realDom^+$, the map $E$ computes the expected value of $g^-$ and $g^+$ with respect to $r$:
 \[\ {\bf E}(g^-(r))= (E(r,g))^-\qquad {\bf E}(g^+(r))=(E(r,g))^+\]
\end{theorem}
\begin{proof}
Suppose $r=\sup_{i\geq 0}r_i$ and $g=\sup_{i\geq 0}g_i$ where $r_i: 2^{\nat}\to D$ and $g_i:D\to \realDom^+$ are increasing sequences of step functions. Let $\alpha_i=T(r_i)=\nu\circ r_i^{-1}$ and $\alpha=T(r)=\nu\circ r^{-1}$. We show the result for $g^-$; the case of $g^+$ is similar. We have: \begin{equation}\label{lebesgue-int}{\bf E}(g^-(r))=\int g^-\,d\nu\circ r^{-1}=\int g^-\,d\alpha.\end{equation}

 For each open set $O\subset D$ we have $\alpha(O)=\sup_{i\geq 0} \alpha_i(O)$ and it follows that for the simple functions $g^{-}_j$, with $j\geq 0$, we have
\begin{equation}\label{simple-function}
    \int g^{-}_j\,d\alpha=\sup_{i\geq 0}\int g_j^{-}\,d\alpha_i.
\end{equation}

From $g^-=\sup_{j\geq 0}g^-_j$, by monotone convergence theorem (MCT) and Equation~(\ref{simple-function}), we obtain:
\[\begin{array}{rcll}
\int g^-\,d\alpha&=& \sup_{j\geq 0}\int g^-_j\,d\alpha&\mbox{MCT}
\\
 &=&  \sup_{j\geq 0}\sup_{i\geq 0}\int g_j^-\,d\alpha_i&\mbox{Equation}~(\ref{simple-function})\\
 &=&\sup_{j\geq 0} \sup_{i\geq 0}(E(r_i,g_j))^-\\
 &=&(E(r,g))^-
\end{array}\]

The first equality follows. The second equality is similar. 

\end{proof}Let $\mbox{Max}(D)$ denote the maximal elements of the bounded complete domain $D$ with its relative subspace Scott topology. We know that $\mbox{Max}(D)$ is a completely metrizable separable space, also known as a Polish space. Let ${\bf M}^1X$ denote the space of probability measure on $X$ equipped with the weak topology of convergence in measures. Then $\mbox{Max}(P(D))={\bf M}^1X$ and the relative Scott topology on $\mbox{Max}(P(D))$ coincides the weak topology on ${\bf M}^1X$. 

For $g:D\to \realDom$ and the simple valuation $r_j=\sup_{k\in K_J}{d_k}\chi_{U_k}\in (A\to D)$, as in Theorem~\ref{lebesgue-int}, the expression
\[E(r_j,g)=\sum_{k\in K_j}g(d_k)\nu(r^{-1}(U_k))\]
 generalises the notion of R-integration to any bounded complete domain and hence to Polish spaces. When $g$ restricts to a real-valued function on maximal elements $g:\mbox{max}(D)\to \realLine$,  the expression provides a formal setting for deriving an exact version of the Monte Carlo method of finding the integral $\int g\,d\nu\circ r^{-1}$. If, for each $k\in K_j$, we sample a point in $g(d_k)$  with probability $\nu(r^{-1}(U_k))$, then we obtain an approximation of the integral of $g$:
 
 \begin{corollary}
 For each $j\geq 0$, take any point $q_k\in g(d_k)$, for $k\in K_j$, then  as $j\to \infty$, \[S_j=\sum_{k\in K_j}q_k\nu(r^{-1}(U_k))\to\int g\,d\nu\circ r^{-1}.\]
 \end{corollary}
 \begin{proof}
 For each $j\geq 0$, we have $S_j\in E(r_j,g)$ and the result follows from the theorem, since $\int g\,d\nu\circ r^{-1}=\lim_{j\to \infty} E(r_j,g)$.
 \end{proof}In particular when $D=\realDom$, if, for each $j\geq 0$, we pick $p_k\in d_k$ for each $k\in K_j$ then we have:
 \begin{corollary}
 \[S_j=\sum_{k\in K_j}g(p_k)\nu(r^{-1}(U_k))\to\int g\,d\nu\circ r^{-1}\] as $j\to \infty.$
 \end{corollary}}