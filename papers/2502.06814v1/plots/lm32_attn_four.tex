\begin{figure}[h]
    \centering
    \setlength{\tabcolsep}{1pt} % Adjust spacing between images
    \renewcommand{\arraystretch}{1} % Adjust vertical spacing between rows
    \begin{tabular}{cc} % Create a 2x2 grid
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S12900_woman_distance.png}} &
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S9300_woman_horse_is.png}} \\
        % Author & Child & Man \\[10pt]
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S7900_young_boy_standing.png}} &
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S7800_man_walking_busy.png}} \\
        % Author & Child & Man \\[10pt]
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S3100_man_woman_is.png}} &
        \adjustbox{valign=m}{\includegraphics[width=0.2\textwidth]{figs/lm32_full_f1kc1_fm/S7800_playing_screen_video.png}} 
    \end{tabular}
    \caption{\textbf{The per-word VLM attention maps are aligned to the Stable Diffusion (SD) after tuning with Lavender.} Results are from Lavender-Llama 3.2-11B implementation. More results are available in Appendix \cref{fig:attention_maps_full_fm}.}
    \label{fig:lm32_attn_4}
\end{figure}