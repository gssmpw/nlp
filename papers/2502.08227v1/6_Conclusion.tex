\section{Conclusion}
In this paper, we uncovered an oversight in existing methods for learning with noisy labels by demonstrating that not all mislabeled examples harm the model's performance equally. We identified a specific subset termed \emph{Mislabeled Easy Examples} (MEEs)—mislabeled samples that the model learns early and that significantly mislead the training process. To address this issue, we proposed \emph{Early Cutting}, a counter-intuitive sample selection strategy that recalibrates the confident subset by leveraging the model's later training state—which is typically considered unreliable—to effectively filter out MEEs. This work provides a practical solution for learning with noisy labels and advances the understanding of how different mislabeled samples affect deep learning models.