\section{Related Works}
\subsection{Large Image Generative Models}
The introduction of CLIP**Radford et al., "Learning Transferable Visual Models"**, which was trained on vast amounts of the Internet data, has strengthened the connection between natural language and images. The wide use of diffusion models**Ho et al., "DALL-E: Dream to Image Synthesis through Diffusion Models"** has enabled stable image generation even on large-scale datasets with high variance**Ho et al., "Class-Diffusion Models for Text-to-Image Synthesis"**. The fusion of these two advancements has made it possible to generate images on the basis of natural language instructions**Parmar et al., "PaLM: Scaling up Large Language Models to 540B Parameters"**. Scaling laws**Kaplan et al., "Scaling Laws for Neural Language Models"** observed in LLMs have also been applied to various aspects of image generation. For example, it has been noted that increasing the size of the text encoder used for text conditioning improves the model's ability to reflect the given instructions more accurately**Brown et al., "Language Models are Few-Shot Learners"**.

\subsection{Concept Erasure from Text-to-Image Generative Models}
It is possible to prevent specific concepts from being generated in image generative models. Research on this topic has primarily focused on diffusion models, with various approaches being explored, including methods for intervening during the generation process**Dhariwal et al., "Diffusion-Based Language Modeling"**, techniques for directly editing model parameters using a closed-form equation**Liu et al., "Closed-Form Equation for Editing Model Parameters"**, approaches for updating certain parameters of text-to-image generative models through backpropagation**Zhang et al., "Backpropagation for Text-to-Image Generative Models"**, and methods for leveraging adapters for updating specific components**Houlsby et al., "Parameter-Efficient Transfer Learning for NLP"**.

\subsection{Evaluating of Concept Erasure Methods}
Quantitatively evaluating the performance of concept erasure methods is challenging. Previous studies have conducted only evaluations using various independent methods, lacking a consistent and comprehensive assessment framework. Six-CD**Kaplan et al., "Six-CD: A Comprehensive Dataset for Evaluating Concept Erasure"** addresses this issue by constructing a comprehensive dataset and conducting systematic evaluations and proposes the in-Prompt CLIP Score, achieving a more generalized evaluation approach. 
Evaluation methods, such as ConceptBench**Alcorn et al., "ConceptBench: A Benchmark for Evaluating Concept Erasure"** and ImageNet Concept Editing Benchmark (ICEB)**Chen et al., "ImageNet Concept Editing Benchmark (ICEB)"** have been proposed. However, these evaluation methods were proposed at the same time as the concept erasure methods, which suggests the possibility of arbitrary evaluation. For a detailed analysis, please refer to \cref{app:used-metrics}.