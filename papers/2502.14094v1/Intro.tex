%The Industrial Internet of Things (IIoT) is gaining rapid popularity in solving industrial scale problems, such as supply chain management, quality control, process automation, and predictive maintenance \cite{gungor2021dowell}. 
%Industry 4.0 is transforming industry by integrating cyber-physical systems with advanced intelligent computing. This revolution relies on the Industrial Internet of Things (IIoT) to gather and process data \cite{gungor2021dowell}. 
%IIoT value is projected to be worth \$7.1 trillion in the United States by 2030 \cite{daugherty2015winning}. 
%Given the serious importance of data and technologies IIoT covers, it is important to address the IIoT security. 
%Due to its increasing connectivity, large-scale networks, and poor security management, IIoT is vulnerable to various cyber attacks, e.g., StuxNet, Industroyer \cite{tange2020systematic}.
%Thus, the implementation of comprehensive and robust security protocols is imperative for IIoT. 

In today’s digital landscape, cybersecurity is essential for safeguarding sensitive data and maintaining trust in digital systems. With cyber threats becoming more sophisticated, organizations must adopt thorough security measures to protect against breaches and unauthorized access \cite{emerging2023kumar}. A critical part of such security measures are intrusion detection systems (IDS) which identify malicious network traffic and computer usage \cite{liao2013intrusion}. Recently, Machine Learning (ML) has become a popular IDS solution due to its great attack detection performance and less requirement for human knowledge \cite{gungor2024roldef}. However, state-of-the-art (SOTA) ML-IDS solutions often fail to adequately address the challenges posed by (i) the evolving nature of cyber attacks and (ii) the lack of attack labels.


A University of Maryland survey predicts that a new cyber attack happens somewhere on the Internet every 39 seconds \cite{hackerstudy2007}, underscoring the need for dynamic IDS. %To defend computing systems against ever-growing cyber attacks, ML-IDS solutions should evolve continuously and effortlessly learn from the newer attack data. 
However, most SOTA ML-IDS approaches are static (offline) % where they follow the \textit{train and deploy} technique
and cannot easily adapt their behavior over time \cite{verwimp2023continual}. ML models, when taught new knowledge, \textit{catastrophically forget} previously known information. To efficiently address this problem, continual learning (CL) is proposed which is capable of learning from an infinite stream of data \cite{wang2024comprehensive}. %aiming for extending acquired knowledge and using it for future learning \cite{de2021continual}. CL can learn new knowledge while minimizing forgetting.
% CL can learn new skills with minimal forgetting of what they had learned previously, transfer knowledge across tasks, and smoothly adapt to new circumstances when needed \cite{verwimp2023continual}. 
%CL-based IDS can significantly reduce the costs of required periodic model retraining as they can recognize new patterns given only a small batch of system data \cite{oikonomou2023multi}. It is also capable of reducing false alarms significantly since it can adapt to changes. 
An experience is defined as a shift in the data stream distribution, and CL models are designed to function well across multiple experiences. This capability is currently essential in cybersecurity, where each new attack type can be considered as a new experience\cite{kozik2019balanced}. To illustrate, an intrusion detection model trained for a group of attacks (experiences) such as \textit{worm}, \textit{shellcode}, and \textit{exploits} should be able to identify new types of attacks (experiences) such as \textit{backdoor} and \textit{fuzzers} \cite{karn2021learning}. Some studies have adopted CL for intrusion detection \cite{kozik2019balanced, karn2021learning, prasath2022analysis, kumar2023augmented, oikonomou2023multi, channappayya2024augmented}, but they rely on labeled attack data, which may not always be feasible to obtain. This causes the ML model to overfit to common attacks in the dataset, resulting in a failure to detect rare and zero-day threats.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/binary_models.pdf}
    \caption{State of the art machine learning intrusion detection performance on known/unknown attacks}
    \label{fig:unknown_attacks}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
%In addition, \cite{prasath2022analysis} show that IDSs are deployed in changing environments. Utilizing a series of statistical tests, they show that the NSL KDD and CICIDS 2017 suffer from distribution shifts through the training and testing sets. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/model_diagram.pdf}
    \caption{Continual Novelty Detection IDS (\Design{}) Framework}
    \label{figure:model_diagram}
\end{figure*} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%On the other hand, most SOTA ML models are static (offline) where they follow \textit{train and deploy} technique and cannot easily adapt their behavior over time. They are built on the premise that all data are sampled \textit{i.i.d.} (independent and identically distributed) from a single, stationary data distribution \cite{verwimp2023continual}. Under shifting data distribution (due to changes in system architecture and characteristic), the model's prediction performance could deteriorate. One possible solution is to retrain these models from scratch periodically, yet this might be infeasible due to high computational and memory costs, e.g., resource-constrained edge devices, or privacy issues \cite{de2021continual}. To efficiently cope up with this problem, continual learning (CL), sometimes referred to as lifelong learning or incremental learning, is proposed. CL is a novel learning paradigm capable of learning from an infinite stream of data, aiming for extending acquired knowledge and using it for future learning \cite{de2021continual}. CL can learn new skills with minimal forgetting of what they had learned previously, transfer knowledge across tasks, and smoothly adapt to new circumstances when needed \cite{verwimp2023continual}.


SOTA ML-IDS solutions have been shown to have high accuracy on well represented attacks within the data, however have low precision on infrequent attacks \cite{macas2022survey}. It is extremely difficult for zero-day attacks to be well represented in the data. Figure~\ref{fig:unknown_attacks} illustrates the limitations of current ML-IDS methods in handling zero-day attacks, revealing a substantial decline in performance when faced with previously unseen threats. To address this issue, novelty detection (ND)-based ML methods have demonstrated significant promise in detecting both known and zero-day attacks without requiring a labeled dataset \cite{verkerken2022towards}. 
%These ND solutions %, i.e., novelty detection methods, 
%are capable of detecting attacks from information gained on purely normal data. %To detect attacks, the model finds statistical outliers from the normal data.  in detecting both known and zero-day attacks without requiring a labeled dataset.
%These methods benefit over supervised ML models by generalizing well to under-represented attack classes or zero day attacks. 
These ND solutions can effectively identify attacks by analyzing purely normal data, provided that the attacks exhibit substantial deviations from normal behavior \cite{verkerken2022towards}. 
%This approach is effective provided that the attack exhibits substantial deviations from normal behavior \cite{verkerken2022towards}. 
However, it has been shown that ND algorithms such as Isolation Forest and Local Outlier Factor
result in lower prediction performance under changing environments, where they suffer from issues like \textit{catastrophic forgetting} \cite{Faber_2024}. 
%Specifically showing that methods such as Isolation Forest (IF), Local Outlier Factor (LOF), One-Class Support Vector Machine (OC-SVM), and Variational Autorncoder (VAE) all suffer from catastrophic forgetting, and 
This issue can be addressed by leveraging continual learning strategies, hence motivating continual novelty detection methods for IDS. 

To address the challenges of evolving data streams and lack of supervision, we propose \textit{\Design{}}, a continual novelty detection approach for ML-based intrusion detection (Fig.~\ref{figure:model_diagram}). To the best of our knowledge, we are the first to propose continual ND for intrusion detection. %Through a CL data preparation phase, we split the data into normal data, training experiences, and test experiences.
\Design{} consists of two critical components: a continual feature extractor (CFE) and a novelty detector based on principal component analysis (PCA) reconstruction. We design a novel continual ND loss to learn representations of the data stream, enabling the CFE to update its representations in a streaming environment with zero attack labels. %, allowing \Design{} to adapt to the changing nature of the input data. 
PCA reconstruction error is then used to classify test samples as either attack or normal data based on thresholding. By fitting PCA on normal data, \Design{} is trained without any labeled attack data, enabling it to detect previously unknown zero-day attacks. Our results show that on realistic intrusion datasets, \Design{} achieves up to 6.1$\times$ F-score improvement over the SOTA unsupervised continual learning algorithm.

% Then our model is deployed into a continual learning  environment where the attacks are periodically introduced through new experiences. All data within these experiences are unsupervised, necessitating our model to create a general representation of attack/normal data that can generalize to zero day attacks. We propose a new problem formulation for unsupervised continual learning for intrusion detection systems. Fig.~\ref{figure:data_flow} shows the data flow of this problem formulation. The model under-goes an initialization phase on only normal data to initially learn the normal activity. This normal data is supervised, however we believe it to be realistic to have access to normal data before deployment. Then the model is tested under the "deployment" phase which is meant to simulate the model under real-life conditions. In this phase there are multiple non-iid experiences where normal and attack data distribution shift overtime. Specifically the normal data undergoes a distribution shift between experiences, and the attack data contains different attack types.   

%Our contributions can be summarized as follows \og{Please provide some framework details here} \sean{More than described above?}: 
%\begin{itemize}
%    \item A novel problem formulation for unsupervised CL for intrusion detection.
%    \item An \underline{u}nsupervised \underline{co}ntinual \underline{n}ovelty detection algorithm for \underline{i}ntrusion \underline{d}etection \underline{s}ystems, coined \textit{\Design{}}
%\end{itemize}

% There has been work done in unsupervised continual learning that could be applied to intrusion detection systems.  Previous analysis \cite{prasath2022} makes it clear that IDS must utilize continual learning because they are deployed in an environment where there is a distribution shift over time. But continually labeling new data while the model is deployed takes human labor. This motivates using an unsupervised CL strategy.

% However the IDS application introduces the complexity of a large class imbalance that must be handled in an unsupervised manner. This cannot simply be solved with over-sampling/under-sampling as this requires class labels and therefore human intervention. This necessitates the need for a new model to handle this class imbalance for long-term deployment in a human-free way.

% In addition, \cite{ashfahani2023adcn} shows some promising results (depending on the dataset) of a forward transfer effect of unsupervised continual learning. Forward transfer measures the model’s performance on future data, and for some datasets analyzed in \cite{ashfahani2023adcn} this forward transfer is significantly positive. This could help handle zero-day attacks. 

% \cite{Faber_2024} provide motivation for the necessity of continual learning in anomaly detection. They also provide a framework for generating a shifting normal class, that may not be present in other work. 