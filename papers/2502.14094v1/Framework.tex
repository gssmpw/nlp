Fig.~\ref{figure:model_diagram} illustrates our continual novelty detection-based intrusion detection (\Design{}) framework. We first apply a continual learning data preparation phase, where we divide the intrusion data into normal data, training experiences, and test experiences. Our framework consists of two main components: a continual feature extractor (CFE) and principal component analysis (PCA)-based novelty detector. The CFE creates a representation of the data that is used to distinguish normal and attack data by the novelty detector. The CFE allows the model to learn new feature representations overtime, so that it can easily adapt as new attacks are introduced through the data stream. CFE is trained through our continual novelty detection loss function, to continually learn from the input stream without forgetting. The next component, PCA reconstruction, provides an anomaly score on the feature output from the feature extractor. PCA is trained purely on normal data, therefore it can generalize well to unseen attacks. Finally we apply a threshold, $\tau$, such that if the anomaly score is greater than $\tau$, we classify that data as an attack. Overall, our learning framework does not require any labeled attack data.

\subsection{Continual Learning (CL) Data Preparation}
\label{section:data_preparation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}
%    \centering
%    \includegraphics[width=\linewidth]{figures/data_breakdown.pdf}
%    \caption{CL data preparation flow diagram}
%    \label{figure:data_flow}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We assume a given dataset contains attack data $A$, normal (benign) data $N$, and various attack types $C$. 
%The goal of our data preparation is to modify the given dataset to replicate the flow demonstrated in Fig.~\ref{figure:data_flow}. 
To begin our data preparation, we remove 10\% of the normal data, and save this as clean normal data $N_c$ to train PCA novelty detector. For the remaining data, we split it across an arbitrary number of experiences $m$. We create a set of experiences $E$, such that each individual experience is $(E_0, E_1,...E_{m})$. Each experience contains a portion of the remaining normal data, of size $\frac{0.9 *|N|}{m}$. The attacks are distributed such that each experience contains $\frac{|C|}{m}$ different attack classes. Therefore, each experience contains some number of \textit{unique} attacks to that experience. This allows us to test on zero-day attacks through future experiences, and seen attacks through current or past experiences. Each experience $E_i$ is split into training and testing set. The training split contains only $X_{train}$ data points, meaning it does not include any labels. The test data contains $\{X_{test},Y_{test}\}$ where $Y_{test} \in \{0,1\}$, where 0 means normal, and 1 means attack data. For each experience $E_i$, we utilize the training set $X_{train}^i$ and $N_c$ to train \Design{}. We then evaluate the model using the test points $\{X_{test},Y_{test}\}$. This setup is designed to represent a realistic intrusion detection scenario, where attacks are entirely unknown before deployment into a continual learning environment. In our framework, the only known data is $N$, while all attack data is unlabeled. With this data setup, we can assess model's performance across various attack scenarios. Specifically, we can simulate the model's response to zero-day attacks as well as known attacks.

\subsection{Proposed Algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}
    \caption{\Design{} Algorithm (Training and Test)}
    \label{alg:train_test}
    \begin{algorithmic}[1]
    \Require $E$ - Experience Set; $N_c$ - Subset of Clean Normal Data; $CFE$ - Continual Feature Extractor; $ND$ - PCA Novelty Detector
    \For {$i \leftarrow 1$ \textbf{to} $|E|$}  % Iterate through each element
      \State Get $X_{\text{train}}$ from experience data $E_i$
      \State Fit $CFE$ to training data $X_{\text{train}}$
      \State Encode $N_c$ by passing it through $CFE$
      \State Fit $ND$ to encoded $N_c$
      \State Get $X_{\text{test}}, Y_{\text{test}}$ from all experiences within $E$
      \State Encode $X_{\text{test}}$ by passing it through $CFE$
      \State Use $ND$ to compute anomaly score $S_{\text{test}}$ on test data
      \State Compute threshold $\tau$ based on thresholding method
      \State Compute predictions such that $Y_{\text{pred}} = (S_{\text{test}} > \tau$)
      \State Compute evaluation metrics based on $Y_{\text{pred}}, Y_{\text{test}}$
    \EndFor
    \end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Algorithm~\ref{alg:train_test} depicts the proposed \Design{} algorithm, including the training and test steps. The training flow follows three main steps: (i) train the CFE, (ii) encode $N_c$ into features, and (iii) train PCA-based novelty detector on the encoded $N_c$ data. Each of these steps is performed at every training experience. For step (i), the CFE is trained on $X_{train}$ using the loss function from Equation~\ref{equation:final_loss}. For step (ii), the subset of normal data $N_c$ is encoded by passing it through the trained CFE, where we encode the entire set. Ultimately, in step (iii), we fit the PCA novelty detection model to this encoded normal data. This completes the \Design{} training, and we then proceed to evaluate on the test experiences. At the end of each training experience, we evaluate on the test set of all experiences. Therefore, we evaluate model performance on unseen attacks (future experiences) and seen attacks (past experiences). When evaluating a batch of testing data, we encode all points from $X_{test}$ with CFE. Then use PCA reconstruction to get an anomaly score $S_{\text{test}}$ for each point based on the reconstruction loss. Next, we leverage widely used Best-F \cite{su2019robust} to select a threshold $\tau$. Ultimately, all anomaly scores greater than $\tau$ are classified as attack while all scores less than or equal to $\tau$ are classified as normal, resulting in the CND-IDS predictions $Y_{\text{pred}}$. We ultimately compute our evaluation metrics by comparing $Y_{\text{pred}}$ with the true labels $Y_{\text{test}}$.   
%Next, we present the components of our \Design{} framework. 

\subsection{Continual Feature Extractor (CFE)}
CFE is an autoencoder (AE)-based model that leverages Multi-Layer Perceptron (MLP) as both the encoder and decoder. %The encoder optimizes 3 separate loss functions. 
Our continual novelty detection loss ($L_{CND}$) consists of a novel cluster separation loss ($L_{CS}$), a reconstruction loss ($L_{R}$), and a continual learning loss ($L_{CL}$): 
%$L_{CND}$ is formulated as follows:

\begin{equation}
    \label{equation:final_loss}
    L_{CND} = L_{CS} + \lambda_R L_R + \lambda_{CL} L_{CL}
\end{equation}

where $\lambda_R \in [0,1]$ and $\lambda_{CL} \in [0,1]$ are hyper-parameters controlling the strength of the reconstruction loss and the continual learning loss respectively. 

\textbf{Cluster Separation Loss:} We design a novel cluster separation loss $L_{CS}$ to enhance the performance of our PCA-based novelty detector by increasing the separation between normal and anomalous data points in feature space. To achieve this, we leverage the clean normal data $N_c$ (which is also used to train the PCA model). Using K-Means clustering \cite{kmeans2022}, we identify which points in $X_{train}$ are most similar to $N_c$ and then push these points apart in feature space. 
%This separation process helps the model better distinguish between normal and anomalous data. 
%The introduction of $L_{CS}$ is a novel contribution of this work.
Specifically, $L_{CS}$ leverages K-Means clustering to assign pseudo-labels to all points in $X_{train}$. Then it utilizes triplet margin loss\cite{schroff2015facenet} to maximize the Euclidean distance between the different pseudo labels. Calculating the $L_{CS}$ pseudo-labels involves the following steps: 1) Fit K-Means clustering to all points in $X_{train}$; 2) Find the cluster labels of all $N_c$ data points; 3) Create the set of "normal data" clusters $CL_N$, where each cluster contains at least one point from $N_c$; 4) Assign class 0 to points in $X_{train}$ if their associated cluster is in $CL_N$, and class 1 otherwise.
In summary, after fitting K-Means to $X_{train}$, we identify the clusters associated with $N_c$. If a cluster contains any point from $N_c$, all points in that cluster are assigned to class 0; otherwise, they are assigned to class 1. This effectively splits the data into two, where 0 would represent normal pseudo-label, and 1 would represent anomalous pseudo-label

After assigning the pseudo-labels, the final loss is computed using the widely adopted triplet margin loss \cite{schroff2015facenet}, defined as:
\begin{equation}
    L_{CS} = \max\left( \Delta_{ap} - \Delta_{an} + m, 0 \right)
\end{equation} where $\Delta_{ap}$ represents the Euclidean distance between an anchor point and a positive point (a point of the same class), and $\Delta_{an}$ is the Euclidean distance between the anchor and a negative point (a point from a different class). The term $m > 0$ is a hyper-parameter that specifies the desired margin between positive and negative points.

\textbf{Reconstruction Loss:} The reconstruction loss ensures that the features embedded by the encoder retain significant information from the original data. We found that this approach helps the PCA extractor better generalize to future and past experiences by forcing the model to learn encodings that align more closely with the original data. The reconstruction loss is the mean squared error (MSE) between the original input and the reconstructed output of the decoder. Let $h$ be the encoded feature of point $x$. Then $L_R = MSE(\text{decoder}(h) , x)$.

\textbf{Continual Learning Loss:} Our solution to catastrophic forgetting is employing a latent-based regularization loss, $L_{CL}$ \cite{ashfahani2023unsupervised}. This loss ensures that as the model learns new information, it retains knowledge from past experiences.  $L_{CL}$ can be formulated as: $
    L_{CL} = \sum_{i < c}^{c} MSE(h^{c}, h^{i}) $
where $c$ represents  the current experience, and \textbf{$h^{j}$}  is the encoded embedding of input $x$ at experience $j$. The loss is computed by summing the MSE between the current embedding (${h^c}$) and all previous embeddings $h^{i}$ where $i < c$. This ensures that the current embedding is still similar to the previous embedding, thereby preventing catastrophic forgetting. To calculate past embedding, we pass the current data point $x$ into a past version of the model. This requires the model to save its state between experiences but does not require it to save any data, which can significantly reduce storage overhead.
\subsection{PCA-based Novelty Detection}
Inspired by \cite{rios2022incdfm}, we create a PCA-based novelty detection approach. Let $\textbf{h}$ denote the output feature from our feature extractor. We utilize principal component analysis transformation $\textbf{T}$ to map the input feature from a high dimensional space to low dimensional space $\textbf{T} : \textbf{h} \rightarrow \textbf{l}$. We then utilize the feature reconstruction error ($FRE$) as the anomaly score: $FRE = \norm{\textbf{h} - \textbf{T}^{-1}(\textbf{l})} ^2$, where $\textbf{T}^{-1}$ is the inverse PCA transform. The anomaly score is therefore the reconstruction loss from this method. We train the PCA transformation on the subset of normal data $N_c$ after it is encoded by the CFE.  