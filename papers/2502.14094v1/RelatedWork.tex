\textbf{Intrusion Detection Systems:} %Can be shortened
%Due to increased inter-connectivity and resource constrained devices, IIoT is highly susceptible to cyber attacks such as denial of service, eavesdropping, and man-in-the-middle \cite{lezzi2018cybersecurity}. 
%An adversary can gain access to an entire IIoT system by exploiting its vulnerable assets such as application software, industrial communication protocols, and smart devices \cite{wu2018cybersecurity}. 
%In 2019, manufacturing organizations in Asia Pacific experienced average losses of \$10.7 million per data breach \cite{microsoft2019}. %There are advanced security solutions in traditional IT systems, yet these cannot be directly used in IIoT systems 
%Traditional IT security solutions cannot be directly applied to IIoT due to its limited power, constrained functionality, and lightweight network protocols \cite{gungor2024roldef}. %As a potential security measure for IIoT systems, 
%Anomaly-based intrusion detection systems (AIDS) offer potential security by identifying deviations from normal behavior through statistical-based, knowledge-based, and machine learning-based methods \cite{khraisat2019survey}.
Intrusion Detection Systems (IDS) fall into two main categories: Signature-based and Anomaly-based IDS. Signature-based IDS identify attacks by matching network data to known attack patterns. In contrast, Anomaly-based IDS use machine learning methods to analyze statistical properties of network data \cite{gupta2023surveyIDS}. Machine learning-based IDS (ML-IDS), a popular form of Anomaly-based IDS, use historical data to train models, enhancing accuracy and reducing the need for expert knowledge \cite{gungor2024rigorous}. The literature proposes various ML models, including supervised models such as support vector machine, random forest, deep neural networks \cite{liu2019machine}, and unsupervised models like isolation forest, autoencoder, and principal component analysis \cite{verkerken2022towards}.
%Although AIDS can detect zero-day attacks, it suffers from high false positive rate since anomalies can be recognized as new normal activities rather than intrusions. To address this problem, we propose a novel unsupervised continual learning-based AIDS approach. 

\textbf{Continual Learning for Intrusion Detection:} Current ML-IDS solutions are often built on the premise that all data are sampled \textit{i.i.d.} (independent and identically distributed) \cite{verwimp2023continual}, making them vulnerable to performance degradation when data distributions shift. %Under shifting data distribution (due to changes in system architecture and charac the model's prediction performance could deteriorate.
%One possible solution is to periodically retrain these models from scratch, yet this might be infeasible due to high computational and memory costs, such as those encountered in resource-constrained edge devices, or due to privacy concerns \cite{de2021continual}. As a better alternative, 
Continual Learning (CL) seeks to train ML models to acquire new information while minimizing the loss of previously learned knowledge. %CL addresses this challenge by employing techniques such as regularization, replay memory, and architectural changes \cite{hadsell2020embracing}.  Since IDS are deployed in environments with evolving systems and emerging attacks, they face shifting data distributions. 
Prasath et al. \cite{prasath2022analysis} highlight that intrusion datasets exhibit these shifting distributions, underscoring the need for CL-capable IDS that can autonomously adapt to the evolving characteristics of the data.
%CL solutions have been mostly used in computer vision \cite{qu2021recent}, and natural language processing \cite{biesialska2020continual}, 
Few studies have recently adopted CL for intrusion detection. Kozik et al. \cite{kozik2019balanced} extend efficient lifelong learning algorithm \cite{ruvolo2013ella} to detect cyber attacks and address the data imbalance problem. %Their experiments provide 80\% average detection ratio and less then 1\% of false positives.
%Karn et al. \cite{karn2021learning} propose a unified framework to compare four different progressive learning approaches from the cloud cyber security domain. %Their evaluation on different datasets showed that progressive learning can provide a structured framework for automating network threat detection.
%Prasath et al. \cite{prasath2022analysis} propose an eight-stage statistics and ML guided framework to analyze data drift and show that CL approaches improve accuracy and reduce false positive rates. %After quantifying the changes, they utilize three different CL approaches which showed improved accuracy and lower FPR rates. 
%Kumar et al. \cite{amalapuram2022continual} apply Elastic Weight Consolidation and Gradient Episodic Memory CL algorithms on CICIDS and KDD Cup datasets. In their follow-up study \cite{kumar2023augmented}, they extend a well-known memory-based CL method (class balancing reservoir sampling) and propose a novel approach (perturbation assistance for parameter approximation) for CL scalability. Their results provide more efficient and effective CL for intrusion detection. Doroud et al. \cite{doroud2023ids} implemented Fuzzy Bounded Twin Support Vector Machine as a lifelong-learning AIDS solution. The comparison with SOTA SIDS method (Snort) showed the superiority of their approach. Ultimately, Oikonomou et al. \cite{oikonomou2023multi} compare twelve different CL algorithms in terms of their efficiency in correctly detecting and classifying malicious traffic. Their analysis showed that memory-based CL methods perform better in terms of accuracy and false alarm predictions. 
Kumar et al.\cite{amalapuram2022continual} applied Elastic Weight Consolidation and Gradient Episodic Memory CL algorithms. In a follow-up study \cite{kumar2023augmented}, they extend a memory-based CL method and proposed a novel approach (perturbation assistance for parameter approximation), improving CL scalability. Nevertheless, all of these studies leverage labeled attack data to devise their CL solutions, which may not be feasible in IDS due to the difficulty and expense of obtaining such labeled data.     
% Doroud et al. \cite{doroud2023ids} introduced a Fuzzy Bounded Twin Support Vector Machine as a CL solution for IDS. Oikonomou et al.
%\cite{oikonomou2023multi} compared twelve CL algorithms, finding memory-based methods more accurate with fewer false alarms. 
   

% \subsection{Continual Novelty Detection}
\textbf{Continual Novelty Detection:} %In the literature, 
Continual Novelty Detection (CND) primarily addresses detecting distribution shifts after ML model deployment. To illustrate, Kim et al. \cite{kim2023openworld} highlight how ND combined with CL is necessary for realistic class incremental learning. 
%Jingbo et al. \cite{sun2021gradientbasednoveltydetectionboosted} combine a gradient-based ND algorithm with CL strategies to detect and teach new data to a ML model. 
Aljundi et al. \cite{aljundi2022continual} investigate CND for detecting data outside the current model's knowledge. Finally, Rios et al. \cite{rios2022incdfm} propose a novel CND framework for detecting new data and incorporating it into the current ML model's knowledge. 
These studies focus on using ND to identify data outside the training set and integrate it into the ML model via CL strategies. However, Faber et al.\cite{Faber_2024} demonstrate the performance decline in ND-algorithms themselves under continual learning settings. 
%something not addressed in previous papers. 
Given the constantly changing nature of attacks, it is necessary for ML-IDS systems to continually adapt without labels, which motivates our work. %In this work, we create a novel continual novelty detection algorithm to adapt the novelty detector to changing data distributions. 
To the best of our knowledge, we are the first to propose continual novelty detection for ML-based intrusion detection.  


%Traditionally, many CND papers focus on utilizing ND to detect when distribution shifts during model deployment \cite{kim2023openworldcontinuallearningunifying,sun2021gradientbasednoveltydetectionboosted, aljundi2022continual}. However these methods do not incorporate continual learning methods into the novelty detector itself. 


%Continual Novelty Detection (CND) aims to develop a novelty detection model that can identify outliers even as the normal or novel data undergo distribution shifts. Faber et al. \cite{Faber_2024} demonstrate the performance decline in novelty detection algorithms under continual learning settings and highlight how continual learning strategies can help reduce this decline. Aljundi et al. \cite{aljundi2022continual} investigate continual novelty detection for detecting data outside the current model's knowledge. To the authors best knowledge, there are no continual ND specific methods that can be applied to IDS without attack labels. 

% Continual Novelty Detection aims to detect out-of-distribution (OOD) data while combining a distribution shift. Gyuhak et al. \cite{kim2023openworldcontinuallearningunifying} show how novelty 


%Gyuhak et al. \cite{kim2023openworldcontinuallearningunifying} highlight how novelty detection can be used to identify when a distribution shift occurs. Jingbo et al. \cite{sun2021gradientbasednoveltydetectionboosted} combine a gradient-based ND algorithm with CL strategies to detect and teach new data to a ML model. Aljundi et al. \cite{aljundi2022continual} investigate CND for detecting data outside the current model's knowledge. However, these papers focus on ND for detecting test data outside of the model's knowledge. 

 
% Faber et al. \cite{Faber_2024} demonstrate the performance decline in novelty detection algorithms under continual learning settings and highlight how continual learning strategies can help reduce this decline. %\cite{sun2021gradientbasednoveltydetectionboosted}

% Aljundi et al. \cite{aljundi2022continual} investigate continual novelty detection for detecting data outside the current model's knowledge.
%However, unsupervised continual learning models can be applied to this problem domain. Unsupervised continual learning research has mainly been done for computer vision, heavily relying upon image specific contrastive learning. Therefore, state-of-the-art contrastive learning-based methods such as LUMP \cite{madaan2022representational}, SCALE \cite{yu2023scale}, CaSSLE \cite{fini2022self}, and UCAD \cite{liu2024unsupervised} cannot be applied to IIoT datasets. One exception is Autonomous Deep Clustering Network (ADCN) proposed by Ashfahani and Pratama \cite{ashfahani2023unsupervised}. ADCN uses Stacked Autoencoders (SAEs) to encode the input data into a feature representation. After the SAEs encode the input data, the data is clustered through a self-clustering method. These clusters are assigned labels based upon their similarity to a small selection of labeled data. Nevertheless, ADCN requires a small amount of labeled data to perform classification. In the context of IDS, this can lead to over fitting to the labeled data and poor generalization to zero-day attacks. In our study, we modify the evolving SAEs from ADCN as a continual feature extractor. Instead of clustering the output and labeling these clusters, we use novelty detection to classify the extracted features as normal or attack data.

% \subsection{Unsupervised Continual Learning}

% Unsupervised continual learning (UCL) has primarily been used in computer vision. Ashfahani and Pratama \cite{ashfahani2023unsupervised} aim to solve unsupervised continual learning in a streaming environment. They develop a novel unsupervised continual learning strategy called Autonomous Deep Clustering Network (ADCN). ADCN uses Stacked Autoencoders (SAEs) to encode the input data into a feature representation. After the SAEs encode the input data, the data is clustered through a self-clustering method. These clusters are assigned labels based upon their similarity to a small selection of labeled data. Nevertheless, ADCN requires a small amount of labeled data to perform classification. In the context of IDS, this can lead to overfitting to the labeled data and poor generalization to zero-day attacks. In our study, we modify the evolving SAEs from ADCN as a continual feature extractor. Instead of clustering the output and labeling these clusters, we use novelty detection to classify the extracted features as normal or attack data. Apart from ADCN, Yu et al. \cite{yu2023scale} propose SCALE, a self-supervised online lifelong learning algorithm that performs unsupervised feature extraction. It shows SOTA performance on classifying images from unsupervised representations. Madaan et al. \cite{madaan2022representational} propose LUMP, which interpolates between the current task and previous tasks to alleviate catastrophic forgetting. Liu et al. \cite{liu2024unsupervised} propose UCAD, an unsupervised continual anomaly detection algorithm to detect anomalies within different classes of images. Taufique et al. \cite{taufique2022uclgv} apply UCL techniques to gradually varying domains, showing success on generalizing these methods. Finally, Fini et al. \cite{fini2022self} propose CaSSLE, showing that self-supervised models are inherently better suited for continual learning. Notably, SCALE, LUMP, UCAD, and CaSSLE all rely on image augmentations to create positive/negative image samples for contrastive learning which is not directly applicable to intrusion detection. \textbf{To the best of our knowledge, no prior work has applied or proposed a novel unsupervised CL method for intrusion detection.} 
% %Intrusion detection can greatly benefit from unsupervised CL, as it enables IDS to adapt to distribution shifts inherent in IIoT security without requiring human intervention.