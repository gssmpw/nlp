\section{Related Work}
\label{sec:related}
\paratitle{LLMs in Spatial-temporal Tasks}
Considerable efforts have been dedicated to using LLMs to improve the performance of spatial-temporal tasks**Chen, "GeoGPT: A Large-Scale Geospatial Knowledge Graph"**. For instance, GeoGPT**Chen et al., "GeoGPT: A Large-Scale Geospatial Knowledge Graph"** introduced an LLM-based tool capable of automating the processing of geographic data, but it does not delve into extracting detailed information about locations. GEOLLM**Li et al., "GEOLLM: A Geospatial Language Model for Location-Based Queries"** designed prompts that include coordinates, address, and surrounding buildings, but it can only address simple questions in a Q\&A format and are unable to handle complex tasks like POI recommendation. Besides, they fail to fully extract the semantic information of POIs.
Some researchers have used LLMs as backbones to tackle complex real-world tasks. For example, GATGPT**Wang et al., "Graph Attention-based Geospatial Temporal Graph Neural Network for Traffic Speed Prediction"** input spatial-temporal features into a frozen LLM to predict traffic speeds, while ST-LLM**Liu et al., "Spatial-Temporal Language Model for Traffic Flow Forecasting"** used a partially frozen LLM to forecast traffic flow. However, these methods are designed for specific individual problems and cannot be applied across multiple tasks.
To solve these limitations, we designed three types of special prompts to extract the semantic information of POIs from LLMs effectively.

\paratitle{POI Representation with Semantic Information}
POI representation aims to turn each POI into a vector that can be utilized in various downstream tasks like traffic forecasting tasks**Zhang et al., "Traffic Forecasting using POI Embeddings"** and trajectory tasks**Wang, "Trajectory Prediction using POI-based Graph Neural Network"**. Most existing methods like **Chen et al., "POI Representation using Textual Features"** leverage textual features typically using one-hot code to encode POI categories and then concatenate them with the embedding vectors. For data types like check-in content,**Li, "Check-in Content Modeling using POI-Word Relationship Graph"** model the similarity between POIs by constructing a POI-Word relationship graph, while **Wang et al., "POI Embeddings using Word2Vec Method"** draws inspiration from Word2Vec method, simultaneously training word vectors and POI vectors. However, these methods often fall short in preserving semantic information and achieving a more comprehensive integration during the fusion process.
To address this issue, we designed three modules in the Embedding Enhancement to improve the preservation and integration of semantic information in the POI embedding.