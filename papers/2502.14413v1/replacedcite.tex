\section{Related Work}
\label{RelatedWork}
\paragraph{Post-training Structured Pruning of LLMs.}
Structured pruning ____ offers advantages such as hardware-friendly sparsity patterns and reduced memory footprint. Traditionally, structured pruning methods required retraining the model, which was effective for smaller networks ____. However, when it comes to LLMs, retraining becomes impractical due to the enormous computational resources and time required ____. This challenge has led to the development of post-training pruning techniques specifically tailored for LLMs. Post-training pruning aims to reduce model size and inference time without the need for extensive retraining ____. However, existing post-training structured pruning techniques can lead to a sharp drop in the accuracy of LLMs ____. In this work, we found that the layer-wise pruning rate configuration has a significant impact on the accuracy of post-training structured pruning for LLMs. Through carefully searched layer-wise pruning rates, we can greatly improve the accuracy of existing post-training structured pruning LLMs.

\paragraph{LLMs for Optimization.}
In recent years, the capabilities of LLMs have significantly improved ____. People can now use LLMs to help solve a wide range of problems, including optimization tasks. For example, LLMs have been employed in heuristic algorithm design ____, prompt optimization ____, solving black-box optimization problems ____, and neural architecture search ____. LLMs have demonstrated powerful understanding and reasoning capabilities ____ in the aforementioned optimization domains. Naturally, this leads us to consider whether LLMs can be used to optimize the model pruning problem, specifically by having LLMs design an excellent pruning model. Due to the extensive training of LLMs on massive amounts of data, they encompass a wide range of domain knowledge, enabling them to integrate knowledge from multiple related fields ____ and thereby propose more comprehensive and effective pruning strategies.

\paragraph{LLMs meet Evolutionary Algorithms.}
Evolutionary algorithms are a class of optimization algorithms that simulate biological evolutionary processes, solving complex optimization problems by mimicking mechanisms such as natural selection, inheritance, and mutation ____. The integration of evolutionary computation into prompt engineering for LLMs has shown great potential in improving performance across multiple domains. For example, it has been applied to code generation ____, text generation ____, and heuristic algorithm design ____. The success in these areas have inspired our idea to apply the combination of evolutionary algorithms and LLMs to automated model pruning. By allowing LLMs to perform the evolutionary search process, we anticipate gradually optimizing pruning strategies through iterations, thereby effectively enhancing the accuracy of existing pruning methods. This approach not only fully utilizes the powerful reasoning capabilities of LLMs ____ but also leverages the advantage of evolutionary algorithms in finding solution within complex search spaces ____, providing a novel perspective for addressing the challenging problem of model pruning.