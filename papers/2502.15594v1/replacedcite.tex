\section{Related Work}
\textbf{Jailbreak Attacks}\quad
Jailbreak attacks aim to bypass alignment or safeguards, forcing LLMs to generate inappropriate content. Early jailbreak attacks ____ rely on manually crafted adversarial prompts, which primarily exploit objective competition and mismatched generalization to achieve jailbreaks. Subsequent optimization-based attacks ____ introduce automated adversarial prompt optimization by leveraging the internal states of LLMs, significantly improving both the success rate and efficiency of jailbreaks. Recent jailbreak attacks ____ iteratively rewrite and refine adversarial prompts using one or multiple LLMs, further exposing security vulnerabilities in LLMs.
% More recent jailbreak attacks harnessing the powerful capabilities of LLMs to facilitate jailbreaks ____. LLM-based attacks iteratively rewrite and refine adversarial prompts using one or multiple LLMs ____, further exposing security vulnerabilities in large language models.
\vspace{0.2\baselineskip}
\\ \textbf{Jailbreak Defenses}\quad 
To address the challenges posed by jailbreak attacks, numerous defense methods have been proposed ____. Detection-based approaches identify adversarial prompts by computing perplexity ____ or randomly deleting parts of the input ____. Some methods prompt the LLM to perform self-checking through instructions ____ or context ____. Decoding-based defenses ____ focus on analyzing decoding probabilities under different conditions and formulating decoding strategies to ensure safer outputs. Additionally, certain approaches ____ edit specific model parameters to make LLMs forget harmful knowledge. A more controllable and efficient class of defenses ____ involves manipulating representations to mitigate jailbreak attacks without modifying model parameters or adding decoding overhead. 
% This class of defenses does not require modifying model parameters or adding decoding overhead.
\vspace{0.2\baselineskip}
\\ \textbf{Representation Engineering for Safety}\quad     % to check
% \textcolor{blue}{Representation engineering is associated with adjusting the representation of individual layers during inference to modify the behavior of the LLMs.} 
Many studies have employed representation engineering techniques ____ to investigate or enhance the safety of LLMs. ____ and ____ analyze the mechanisms of jailbreak and refusal from a representation perspective, respectively. 
____ improve the robustness of LLMs by strengthening the safety patterns they recognize.
____ introduce a learnable safety prompt that aims to increase the separation between harmful and harmless query representations along the refusal direction. 
% However, this method is not specifically designed to defend against jailbreak attacks.
____ add a difference vector to query representations to guide the LLM toward rejecting malicious instructions, while ____ mitigate jailbreak attacks by constraining activations within a safe boundary. 
A major drawback of these two approaches is that their interventions cannot be automatically optimized. This means that when the intervention is applied to all query representations, the choice of intervention strength becomes highly sensitive.   
In contrast, our method adopts a parameterized intervention, which adaptively identifies and adjusts jailbreak-related representations regardless of manually tuning the intervention strength.