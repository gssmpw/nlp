@INPROCEEDINGS{10160439,
  author={Myers, Vivek and Bıyık, Erdem and Sadigh, Dorsa},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Active Reward Learning from Online Preferences}, 
  year={2023},
  volume={},
  number={},
  pages={7511-7518},
  keywords={Adaptation models;Codes;Automation;Reliability;Robots;Videos},
  doi={10.1109/ICRA48891.2023.10160439}}

@inproceedings{Sadigh2017ActivePL,
  title={Active Preference-Based Learning of Reward Functions},
  author={Dorsa Sadigh and Anca D. Dragan and S. Shankar Sastry and Sanjit A. Seshia},
  booktitle={Robotics: Science and Systems},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:12226563}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{akrour2012april,
  title={April: Active preference learning-based reinforcement learning},
  author={Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\`e}le},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings, Part II 23},
  pages={116--131},
  year={2012},
  organization={Springer}
}

@inproceedings{akrour2014programming,
  title={Programming by feedback},
  author={Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\`e}le and Souplet, Jean-Christophe},
  booktitle={International Conference on Machine Learning},
  volume={32},
  pages={1503--1511},
  year={2014},
  organization={JMLR. org}
}

@article{amid2019robust,
  title={Robust bi-tempered logistic loss based on bregman divergences},
  author={Amid, Ehsan and Warmuth, Manfred KK and Anil, Rohan and Koren, Tomer},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38176--38189},
  year={2022}
}

@inproceedings{biyik2018batch,
  title={Batch active preference-based learning of reward functions},
  author={Biyik, Erdem and Sadigh, Dorsa},
  booktitle={Conference on robot learning},
  pages={519--528},
  year={2018},
  organization={PMLR}
}

@article{biyik2020active,
  title={Active preference-based gaussian process regression for reward learning},
  author={B{\i}y{\i}k, Erdem and Huynh, Nicolas and Kochenderfer, Mykel J and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2005.02575},
  year={2020}
}

@article{biyik2024batch,
  title={Batch active learning of reward functions from human preferences},
  author={Biyik, Erdem and Anari, Nima and Sadigh, Dorsa},
  journal={ACM Transactions on Human-Robot Interaction},
  volume={13},
  number={2},
  pages={1--27},
  year={2024},
  publisher={ACM New York, NY}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{cheng2024rime,
  title={RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences},
  author={Cheng, Jie and Xiong, Gang and Dai, Xingyuan and Miao, Qinghai and Lv, Yisheng and Wang, Fei-Yue},
  journal={arXiv preprint arXiv:2402.17257},
  year={2024}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{daniel2014active,
  title={Active Reward Learning},
  author={Daniel, Christian and Viering, Malte and Metz, Jan and Kroemer, Oliver and Peters, Jan},
  booktitle={Robotics: Science and systems},
  volume={98},
  year={2014}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{hejna2023contrastive,
  title={Contrastive prefence learning: Learning from human feedback without rl},
  author={Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W Bradley and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2310.13639},
  year={2023}
}

@inproceedings{hejna2023few,
  title={Few-shot preference learning for human-in-the-loop rl},
  author={Hejna III, Donald Joseph and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={2014--2025},
  year={2023},
  organization={PMLR}
}

@article{heo2025mixing,
  title={Mixing corrupted preferences for robust and feedback-efficient preference-based reinforcement learning},
  author={Heo, Jongkook and Lee, Young Jae and Kim, Jaehoon and Kwak, Min Gu and Park, Young Joon and Kim, Seoung Bum},
  journal={Knowledge-Based Systems},
  volume={309},
  pages={112824},
  year={2025},
  publisher={Elsevier}
}

@article{houlsby2011bayesian,
  title={Bayesian active learning for classification and preference learning},
  author={Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  journal={arXiv preprint arXiv:1112.5745},
  year={2011}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International conference on machine learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{jin2022learning,
  title={Learning from human directional corrections},
  author={Jin, Wanxin and Murphey, Todd D and Lu, Zehui and Mou, Shaoshuai},
  journal={IEEE Transactions on Robotics},
  volume={39},
  number={1},
  pages={625--644},
  year={2022},
  publisher={IEEE}
}

@inproceedings{lee2019robust,
  title={Robust inference via generative classifiers for handling noisy labels},
  author={Lee, Kimin and Yun, Sukmin and Lee, Kibok and Lee, Honglak and Li, Bo and Shin, Jinwoo},
  booktitle={International conference on machine learning},
  pages={3763--3772},
  year={2019},
  organization={PMLR}
}

@article{lee2021b,
  title={B-pref: Benchmarking preference-based reinforcement learning},
  author={Lee, Kimin and Smith, Laura and Dragan, Anca and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2111.03026},
  year={2021}
}

@article{liang2022reward,
  title={Reward uncertainty for exploration in preference-based reinforcement learning},
  author={Liang, Xinran and Shu, Katherine and Lee, Kimin and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2205.12401},
  year={2022}
}

@article{liu2022meta,
  title={Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning},
  author={Liu, Runze and Bai, Fengshuo and Du, Yali and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22270--22284},
  year={2022}
}

@inproceedings{lukasik2020does,
  title={Does label smoothing mitigate label noise?},
  author={Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv},
  booktitle={International Conference on Machine Learning},
  pages={6448--6458},
  year={2020},
  organization={PMLR}
}

@inproceedings{ma2020normalized,
  title={Normalized loss functions for deep learning with noisy labels},
  author={Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James},
  booktitle={International conference on machine learning},
  pages={6543--6553},
  year={2020},
  organization={PMLR}
}

@article{park2022surf,
  title={SURF: Semi-supervised reward learning with data augmentation for feedback-efficient preference-based reinforcement learning},
  author={Park, Jongjin and Seo, Younggyo and Shin, Jinwoo and Lee, Honglak and Abbeel, Pieter and Lee, Kimin},
  journal={arXiv preprint arXiv:2203.10050},
  year={2022}
}

@InProceedings{pmlr-v139-lee21i,
  title = 	 {PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training},
  author =       {Lee, Kimin and Smith, Laura M and Abbeel, Pieter},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6152--6163},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@InProceedings{pmlr-v164-myers22a,
  title = 	 {Learning Multimodal Rewards from Rankings},
  author =       {Myers, Vivek and Biyik, Erdem and Anari, Nima and Sadigh, Dorsa},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {342--352},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{song2022learning,
  title={Learning from noisy labels with deep neural networks: A survey},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
  journal={IEEE transactions on neural networks and learning systems},
  volume={34},
  number={11},
  pages={8135--8153},
  year={2022},
  publisher={IEEE}
}

@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017}
}

@article{xie2024safe,
  title={Safe MPC Alignment with Human Directional Feedback},
  author={Xie, Zhixian and Zhang, Wenlong and Ren, Yi and Wang, Zhaoran and Pappas, George J and Jin, Wanxin},
  journal={arXiv preprint arXiv:2407.04216},
  year={2024}
}

@article{xue2023reinforcement,
  title={Reinforcement learning from diverse human preferences},
  author={Xue, Wanqi and An, Bo and Yan, Shuicheng and Xu, Zhongwen},
  journal={arXiv preprint arXiv:2301.11774},
  year={2023}
}

@article{yao2018deep,
  title={Deep learning from noisy image labels with quality embedding},
  author={Yao, Jiangchao and Wang, Jiajie and Tsang, Ivor W and Zhang, Ya and Sun, Jun and Zhang, Chengqi and Zhang, Rui},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={4},
  pages={1909--1922},
  year={2018},
  publisher={IEEE}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@inproceedings{zhou2020robust,
  title={Robust curriculum learning: from clean label detection to noisy label self-correction},
  author={Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{zucker2010optimization,
  title={An optimization approach to rough terrain locomotion},
  author={Zucker, Matt and Bagnell, J Andrew and Atkeson, Christopher G and Kuffner, James},
  booktitle={2010 IEEE International Conference on Robotics and Automation},
  pages={3589--3595},
  year={2010},
  organization={IEEE}
}

