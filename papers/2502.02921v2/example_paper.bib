@article{biyik2024batch,
  title={Batch active learning of reward functions from human preferences},
  author={Biyik, Erdem and Anari, Nima and Sadigh, Dorsa},
  journal={ACM Transactions on Human-Robot Interaction},
  volume={13},
  number={2},
  pages={1--27},
  year={2024},
  publisher={ACM New York, NY}
}

@article{shivaswamy2015coactive,
  title={Coactive learning},
  author={Shivaswamy, Pannaga and Joachims, Thorsten},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={1--40},
  year={2015}
}


@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@inproceedings{qi2023hand,
  title={In-hand object rotation via rapid motor adaptation},
  author={Qi, Haozhi and Kumar, Ashish and Calandra, Roberto and Ma, Yi and Malik, Jitendra},
  booktitle={Conference on Robot Learning},
  pages={1722--1732},
  year={2023},
  organization={PMLR}
}

@inproceedings{handa2023dextreme,
  title={Dextreme: Transfer of agile in-hand manipulation from simulation to reality},
  author={Handa, Ankur and Allshire, Arthur and Makoviychuk, Viktor and Petrenko, Aleksei and Singh, Ritvik and Liu, Jingzhou and Makoviichuk, Denys and Van Wyk, Karl and Zhurkevich, Alexander and Sundaralingam, Balakumar and others},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5977--5984},
  year={2023},
  organization={IEEE}
}

@article{yin2023rotating,
  title={Rotating without seeing: Towards in-hand dexterity through touch},
  author={Yin, Zhao-Heng and Huang, Binghao and Qin, Yuzhe and Chen, Qifeng and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2303.10880},
  year={2023}
}

@article{radosavovic2024real,
  title={Real-world humanoid locomotion with reinforcement learning},
  author={Radosavovic, Ilija and Xiao, Tete and Zhang, Bike and Darrell, Trevor and Malik, Jitendra and Sreenath, Koushil},
  journal={Science Robotics},
  volume={9},
  number={89},
  pages={eadi9579},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{tsounis2020deepgait,
  title={Deepgait: Planning and control of quadrupedal gaits using deep reinforcement learning},
  author={Tsounis, Vassilios and Alge, Mitja and Lee, Joonho and Farshidian, Farbod and Hutter, Marco},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={3699--3706},
  year={2020},
  publisher={IEEE}
}

@article{hoeller2024anymal,
  title={Anymal parkour: Learning agile navigation for quadrupedal robots},
  author={Hoeller, David and Rudin, Nikita and Sako, Dhionis and Hutter, Marco},
  journal={Science Robotics},
  volume={9},
  number={88},
  pages={eadi7566},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{casper2023open,
  title={Open problems and fundamental limitations of reinforcement learning from human feedback},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}
@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017}
}
@inproceedings{akrour2012april,
  title={April: Active preference learning-based reinforcement learning},
  author={Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\`e}le},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings, Part II 23},
  pages={116--131},
  year={2012},
  organization={Springer}
}

@inproceedings{akrour2014programming,
  title={Programming by feedback},
  author={Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\`e}le and Souplet, Jean-Christophe},
  booktitle={International Conference on Machine Learning},
  volume={32},
  pages={1503--1511},
  year={2014},
  organization={JMLR. org}
}

@inproceedings{zucker2010optimization,
  title={An optimization approach to rough terrain locomotion},
  author={Zucker, Matt and Bagnell, J Andrew and Atkeson, Christopher G and Kuffner, James},
  booktitle={2010 IEEE International Conference on Robotics and Automation},
  pages={3589--3595},
  year={2010},
  organization={IEEE}
}

@article{daniel2015active,
  title={Active reward learning with a novel acquisition function},
  author={Daniel, Christian and Kroemer, Oliver and Viering, Malte and Metz, Jan and Peters, Jan},
  journal={Autonomous Robots},
  volume={39},
  pages={389--405},
  year={2015},
  publisher={Springer}
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38176--38189},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{daniel2014active,
  title={Active Reward Learning},
  author={Daniel, Christian and Viering, Malte and Metz, Jan and Kroemer, Oliver and Peters, Jan},
  booktitle={Robotics: Science and systems},
  volume={98},
  year={2014}
}



@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{Sadigh2017ActivePL,
  title={Active Preference-Based Learning of Reward Functions},
  author={Dorsa Sadigh and Anca D. Dragan and S. Shankar Sastry and Sanjit A. Seshia},
  booktitle={Robotics: Science and Systems},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:12226563}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@InProceedings{pmlr-v139-lee21i,
  title = 	 {PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training},
  author =       {Lee, Kimin and Smith, Laura M and Abbeel, Pieter},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6152--6163},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@inproceedings{hejna2023few,
  title={Few-shot preference learning for human-in-the-loop rl},
  author={Hejna III, Donald Joseph and Sadigh, Dorsa},
  booktitle={Conference on Robot Learning},
  pages={2014--2025},
  year={2023},
  organization={PMLR}
}

@INPROCEEDINGS{10160439,
  author={Myers, Vivek and Bıyık, Erdem and Sadigh, Dorsa},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Active Reward Learning from Online Preferences}, 
  year={2023},
  volume={},
  number={},
  pages={7511-7518},
  keywords={Adaptation models;Codes;Automation;Reliability;Robots;Videos},
  doi={10.1109/ICRA48891.2023.10160439}}

@article{hejna2023contrastive,
  title={Contrastive prefence learning: Learning from human feedback without rl},
  author={Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W Bradley and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2310.13639},
  year={2023}
}


@InProceedings{pmlr-v164-myers22a,
  title = 	 {Learning Multimodal Rewards from Rankings},
  author =       {Myers, Vivek and Biyik, Erdem and Anari, Nima and Sadigh, Dorsa},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {342--352},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
}

@article{park2022surf,
  title={SURF: Semi-supervised reward learning with data augmentation for feedback-efficient preference-based reinforcement learning},
  author={Park, Jongjin and Seo, Younggyo and Shin, Jinwoo and Lee, Honglak and Abbeel, Pieter and Lee, Kimin},
  journal={arXiv preprint arXiv:2203.10050},
  year={2022}
}

@article{liang2022reward,
  title={Reward uncertainty for exploration in preference-based reinforcement learning},
  author={Liang, Xinran and Shu, Katherine and Lee, Kimin and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2205.12401},
  year={2022}
}

@article{liu2022meta,
  title={Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning},
  author={Liu, Runze and Bai, Fengshuo and Du, Yali and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22270--22284},
  year={2022}
}

@inproceedings{liu2023efficient,
  title={Efficient preference-based reinforcement learning using learned dynamics models},
  author={Liu, Yi and Datta, Gaurav and Novoseller, Ellen and Brown, Daniel S},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2921--2928},
  year={2023},
  organization={IEEE}
}

@article{lee2021b,
  title={B-pref: Benchmarking preference-based reinforcement learning},
  author={Lee, Kimin and Smith, Laura and Dragan, Anca and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2111.03026},
  year={2021}
}

@article{song2022learning,
  title={Learning from noisy labels with deep neural networks: A survey},
  author={Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
  journal={IEEE transactions on neural networks and learning systems},
  volume={34},
  number={11},
  pages={8135--8153},
  year={2022},
  publisher={IEEE}
}

@article{yao2018deep,
  title={Deep learning from noisy image labels with quality embedding},
  author={Yao, Jiangchao and Wang, Jiajie and Tsang, Ivor W and Zhang, Ya and Sun, Jun and Zhang, Chengqi and Zhang, Rui},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={4},
  pages={1909--1922},
  year={2018},
  publisher={IEEE}
}

@inproceedings{lee2019robust,
  title={Robust inference via generative classifiers for handling noisy labels},
  author={Lee, Kimin and Yun, Sukmin and Lee, Kibok and Lee, Honglak and Li, Bo and Shin, Jinwoo},
  booktitle={International conference on machine learning},
  pages={3763--3772},
  year={2019},
  organization={PMLR}
}

@inproceedings{lukasik2020does,
  title={Does label smoothing mitigate label noise?},
  author={Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv},
  booktitle={International Conference on Machine Learning},
  pages={6448--6458},
  year={2020},
  organization={PMLR}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@article{amid2019robust,
  title={Robust bi-tempered logistic loss based on bregman divergences},
  author={Amid, Ehsan and Warmuth, Manfred KK and Anil, Rohan and Koren, Tomer},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{ma2020normalized,
  title={Normalized loss functions for deep learning with noisy labels},
  author={Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James},
  booktitle={International conference on machine learning},
  pages={6543--6553},
  year={2020},
  organization={PMLR}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International conference on machine learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@inproceedings{zhou2020robust,
  title={Robust curriculum learning: from clean label detection to noisy label self-correction},
  author={Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{xue2023reinforcement,
  title={Reinforcement learning from diverse human preferences},
  author={Xue, Wanqi and An, Bo and Yan, Shuicheng and Xu, Zhongwen},
  journal={arXiv preprint arXiv:2301.11774},
  year={2023}
}

@article{heo2025mixing,
  title={Mixing corrupted preferences for robust and feedback-efficient preference-based reinforcement learning},
  author={Heo, Jongkook and Lee, Young Jae and Kim, Jaehoon and Kwak, Min Gu and Park, Young Joon and Kim, Seoung Bum},
  journal={Knowledge-Based Systems},
  volume={309},
  pages={112824},
  year={2025},
  publisher={Elsevier}
}

@article{cheng2024rime,
  title={RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences},
  author={Cheng, Jie and Xiong, Gang and Dai, Xingyuan and Miao, Qinghai and Lv, Yisheng and Wang, Fei-Yue},
  journal={arXiv preprint arXiv:2402.17257},
  year={2024}
}

@article{williams2015model,
  title={Model predictive path integral control using covariance variable importance sampling},
  author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos},
  journal={arXiv preprint arXiv:1509.01149},
  year={2015}
}

@inproceedings{todorov2012mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE},
  doi={10.1109/IROS.2012.6386109}
}

@book{ActiveBook,
author = {Settles, Burr},
title = {Active Learning},
year = {2012},
isbn = {1608457257},
publisher = {Morgan \& Claypool Publishers},
abstract = {The key idea behind active learning is that a machine learning algorithm can perform better with less training if it is allowed to choose the data from which it learns. An active learner may pose "queries," usually in the form of unlabeled data instances to be labeled by an "oracle" (e.g., a human annotator) that already understands the nature of the problem. This sort of approach is well-motivated in many modern machine learning and data mining applications, where unlabeled data may be abundant or easy to come by, but training labels are difficult, time-consuming, or expensive to obtain. This book is a general introduction to active learning. It outlines several scenarios in which queries might be formulated, and details many query selection algorithms which have been organized into four broad categories, or "query selection frameworks." We also touch on some of the theoretical foundations of active learning, and conclude with an overview of the strengths and weaknesses of these approaches in practice, including a summary of ongoing work to address these open challenges and opportunities.}
}

@article{vapnik1998statistical,
  title={Statistical learning theory},
  author={Vapnik, Vladimir},
  journal={John Wiley \& Sons google schola},
  volume={2},
  pages={831--842},
  year={1998}
}

@article{houlsby2011bayesian,
  title={Bayesian active learning for classification and preference learning},
  author={Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  journal={arXiv preprint arXiv:1112.5745},
  year={2011}
}

@article{biyik2020active,
  title={Active preference-based gaussian process regression for reward learning},
  author={B{\i}y{\i}k, Erdem and Huynh, Nicolas and Kochenderfer, Mykel J and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2005.02575},
  year={2020}
}

@inproceedings{biyik2018batch,
  title={Batch active preference-based learning of reward functions},
  author={Biyik, Erdem and Sadigh, Dorsa},
  booktitle={Conference on robot learning},
  pages={519--528},
  year={2018},
  organization={PMLR}
}

@article{jin2022learning,
  title={Learning from human directional corrections},
  author={Jin, Wanxin and Murphey, Todd D and Lu, Zehui and Mou, Shaoshuai},
  journal={IEEE Transactions on Robotics},
  volume={39},
  number={1},
  pages={625--644},
  year={2022},
  publisher={IEEE}
}

@article{xie2024safe,
  title={Safe MPC Alignment with Human Directional Feedback},
  author={Xie, Zhixian and Zhang, Wenlong and Ren, Yi and Wang, Zhaoran and Pappas, George J and Jin, Wanxin},
  journal={arXiv preprint arXiv:2407.04216},
  year={2024}
}

@inproceedings{hanneke2007bound,
  title={A bound on the label complexity of agnostic active learning},
  author={Hanneke, Steve},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={353--360},
  year={2007}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{howell2022,
  title={{Predictive Sampling: Real-time Behaviour Synthesis with MuJoCo}},
  author={Howell, Taylor and Gileadi, Nimrod and Tunyasuvunakool, Saran and Zakka, Kevin and Erez, Tom and Tassa, Yuval},
  archivePrefix={arXiv},
  eprint={2212.00541},
  primaryClass={cs.RO},
  url={https://arxiv.org/abs/2212.00541},
  doi={10.48550/arXiv.2212.00541},
  year={2022},
  month={dec}
}