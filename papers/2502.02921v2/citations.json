[
  {
    "index": 0,
    "papers": [
      {
        "key": "wirth2017survey",
        "author": "Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\\\"u}rnkranz, Johannes",
        "title": "A survey of preference-based reinforcement learning methods"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zucker2010optimization",
        "author": "Zucker, Matt and Bagnell, J Andrew and Atkeson, Christopher G and Kuffner, James",
        "title": "An optimization approach to rough terrain locomotion"
      },
      {
        "key": "akrour2012april",
        "author": "Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\\`e}le",
        "title": "April: Active preference learning-based reinforcement learning"
      },
      {
        "key": "akrour2014programming",
        "author": "Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\\`e}le and Souplet, Jean-Christophe",
        "title": "Programming by feedback"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "christiano2017deep",
        "author": "Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario",
        "title": "Deep reinforcement learning from human preferences"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "bakker2022fine",
        "author": "Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others",
        "title": "Fine-tuning language models to find agreement among humans with diverse preferences"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bradley1952rank",
        "author": "Bradley, Ralph Allan and Terry, Milton E",
        "title": "Rank analysis of incomplete block designs: I. The method of paired comparisons"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal policy optimization algorithms"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "haarnoja2018soft",
        "author": "Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey",
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "hejna2023few",
        "author": "Hejna III, Donald Joseph and Sadigh, Dorsa",
        "title": "Few-shot preference learning for human-in-the-loop rl"
      },
      {
        "key": "hejna2023contrastive",
        "author": "Hejna, Joey and Rafailov, Rafael and Sikchi, Harshit and Finn, Chelsea and Niekum, Scott and Knox, W Bradley and Sadigh, Dorsa",
        "title": "Contrastive prefence learning: Learning from human feedback without rl"
      },
      {
        "key": "pmlr-v164-myers22a",
        "author": "Myers, Vivek and Biyik, Erdem and Anari, Nima and Sadigh, Dorsa",
        "title": "Learning Multimodal Rewards from Rankings"
      },
      {
        "key": "10160439",
        "author": "Myers, Vivek and B\u0131y\u0131k, Erdem and Sadigh, Dorsa",
        "title": "Active Reward Learning from Online Preferences"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "pmlr-v139-lee21i",
        "author": "Lee, Kimin and Smith, Laura M and Abbeel, Pieter",
        "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "park2022surf",
        "author": "Park, Jongjin and Seo, Younggyo and Shin, Jinwoo and Lee, Honglak and Abbeel, Pieter and Lee, Kimin",
        "title": "SURF: Semi-supervised reward learning with data augmentation for feedback-efficient preference-based reinforcement learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "liang2022reward",
        "author": "Liang, Xinran and Shu, Katherine and Lee, Kimin and Abbeel, Pieter",
        "title": "Reward uncertainty for exploration in preference-based reinforcement learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "liu2022meta",
        "author": "Liu, Runze and Bai, Fengshuo and Du, Yali and Yang, Yaodong",
        "title": "Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "lee2021b",
        "author": "Lee, Kimin and Smith, Laura and Dragan, Anca and Abbeel, Pieter",
        "title": "B-pref: Benchmarking preference-based reinforcement learning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "song2022learning",
        "author": "Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil",
        "title": "Learning from noisy labels with deep neural networks: A survey"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "yao2018deep",
        "author": "Yao, Jiangchao and Wang, Jiajie and Tsang, Ivor W and Zhang, Ya and Sun, Jun and Zhang, Chengqi and Zhang, Rui",
        "title": "Deep learning from noisy image labels with quality embedding"
      },
      {
        "key": "lee2019robust",
        "author": "Lee, Kimin and Yun, Sukmin and Lee, Kibok and Lee, Honglak and Li, Bo and Shin, Jinwoo",
        "title": "Robust inference via generative classifiers for handling noisy labels"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lukasik2020does",
        "author": "Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv",
        "title": "Does label smoothing mitigate label noise?"
      },
      {
        "key": "zhang2017mixup",
        "author": "Zhang, Hongyi",
        "title": "mixup: Beyond empirical risk minimization"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "amid2019robust",
        "author": "Amid, Ehsan and Warmuth, Manfred KK and Anil, Rohan and Koren, Tomer",
        "title": "Robust bi-tempered logistic loss based on bregman divergences"
      },
      {
        "key": "ma2020normalized",
        "author": "Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James",
        "title": "Normalized loss functions for deep learning with noisy labels"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "jiang2018mentornet",
        "author": "Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li",
        "title": "Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels"
      },
      {
        "key": "zhou2020robust",
        "author": "Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff",
        "title": "Robust curriculum learning: from clean label detection to noisy label self-correction"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yao2018deep",
        "author": "Yao, Jiangchao and Wang, Jiajie and Tsang, Ivor W and Zhang, Ya and Sun, Jun and Zhang, Chengqi and Zhang, Rui",
        "title": "Deep learning from noisy image labels with quality embedding"
      },
      {
        "key": "lee2019robust",
        "author": "Lee, Kimin and Yun, Sukmin and Lee, Kibok and Lee, Honglak and Li, Bo and Shin, Jinwoo",
        "title": "Robust inference via generative classifiers for handling noisy labels"
      },
      {
        "key": "lukasik2020does",
        "author": "Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv",
        "title": "Does label smoothing mitigate label noise?"
      },
      {
        "key": "zhang2017mixup",
        "author": "Zhang, Hongyi",
        "title": "mixup: Beyond empirical risk minimization"
      },
      {
        "key": "amid2019robust",
        "author": "Amid, Ehsan and Warmuth, Manfred KK and Anil, Rohan and Koren, Tomer",
        "title": "Robust bi-tempered logistic loss based on bregman divergences"
      },
      {
        "key": "ma2020normalized",
        "author": "Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James",
        "title": "Normalized loss functions for deep learning with noisy labels"
      },
      {
        "key": "jiang2018mentornet",
        "author": "Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li",
        "title": "Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels"
      },
      {
        "key": "zhou2020robust",
        "author": "Zhou, Tianyi and Wang, Shengjie and Bilmes, Jeff",
        "title": "Robust curriculum learning: from clean label detection to noisy label self-correction"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "xue2023reinforcement",
        "author": "Xue, Wanqi and An, Bo and Yan, Shuicheng and Xu, Zhongwen",
        "title": "Reinforcement learning from diverse human preferences"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "cheng2024rime",
        "author": "Cheng, Jie and Xiong, Gang and Dai, Xingyuan and Miao, Qinghai and Lv, Yisheng and Wang, Fei-Yue",
        "title": "RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "heo2025mixing",
        "author": "Heo, Jongkook and Lee, Young Jae and Kim, Jaehoon and Kwak, Min Gu and Park, Young Joon and Kim, Seoung Bum",
        "title": "Mixing corrupted preferences for robust and feedback-efficient preference-based reinforcement learning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhang2017mixup",
        "author": "Zhang, Hongyi",
        "title": "mixup: Beyond empirical risk minimization"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "daniel2014active",
        "author": "Daniel, Christian and Viering, Malte and Metz, Jan and Kroemer, Oliver and Peters, Jan",
        "title": "Active Reward Learning"
      },
      {
        "key": "biyik2018batch",
        "author": "Biyik, Erdem and Sadigh, Dorsa",
        "title": "Batch active preference-based learning of reward functions"
      },
      {
        "key": "Sadigh2017ActivePL",
        "author": "Dorsa Sadigh and Anca D. Dragan and S. Shankar Sastry and Sanjit A. Seshia",
        "title": "Active Preference-Based Learning of Reward Functions"
      },
      {
        "key": "biyik2020active",
        "author": "B{\\i}y{\\i}k, Erdem and Huynh, Nicolas and Kochenderfer, Mykel J and Sadigh, Dorsa",
        "title": "Active preference-based gaussian process regression for reward learning"
      },
      {
        "key": "houlsby2011bayesian",
        "author": "Houlsby, Neil and Husz{\\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\\'a}t{\\'e}",
        "title": "Bayesian active learning for classification and preference learning"
      },
      {
        "key": "biyik2024batch",
        "author": "Biyik, Erdem and Anari, Nima and Sadigh, Dorsa",
        "title": "Batch active learning of reward functions from human preferences"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "Sadigh2017ActivePL",
        "author": "Dorsa Sadigh and Anca D. Dragan and S. Shankar Sastry and Sanjit A. Seshia",
        "title": "Active Preference-Based Learning of Reward Functions"
      },
      {
        "key": "biyik2018batch",
        "author": "Biyik, Erdem and Sadigh, Dorsa",
        "title": "Batch active preference-based learning of reward functions"
      },
      {
        "key": "biyik2024batch",
        "author": "Biyik, Erdem and Anari, Nima and Sadigh, Dorsa",
        "title": "Batch active learning of reward functions from human preferences"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "jin2022learning",
        "author": "Jin, Wanxin and Murphey, Todd D and Lu, Zehui and Mou, Shaoshuai",
        "title": "Learning from human directional corrections"
      },
      {
        "key": "xie2024safe",
        "author": "Xie, Zhixian and Zhang, Wenlong and Ren, Yi and Wang, Zhaoran and Pappas, George J and Jin, Wanxin",
        "title": "Safe MPC Alignment with Human Directional Feedback"
      }
    ]
  }
]