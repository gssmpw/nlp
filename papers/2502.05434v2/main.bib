@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{pacchiano2021dueling,
  title={Dueling rl: reinforcement learning with trajectory preferences},
  author={Pacchiano, Aldo and Saha, Aadirupa and Lee, Jonathan},
  journal={arXiv preprint arXiv:2111.04850},
  year={2021}
}

@article{sekhari2024contextual,
  title={Contextual bandits and imitation learning with preference-based active queries},
  author={Sekhari, Ayush and Sridharan, Karthik and Sun, Wen and Wu, Runzhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{furnkranz2012preference,
  title={Preference-based reinforcement learning: a formal framework and a policy iteration algorithm},
  author={F{\"u}rnkranz, Johannes and H{\"u}llermeier, Eyke and Cheng, Weiwei and Park, Sang-Hyeun},
  journal={Machine learning},
  volume={89},
  pages={123--156},
  year={2012},
  publisher={Springer}
}

@inproceedings{chen2022human,
  title={Human-in-the-loop: Provably efficient preference-based reinforcement learning with general function approximation},
  author={Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={3773--3793},
  year={2022},
  organization={PMLR}
}

@inproceedings{taranovic2022adversarial,
  title={Adversarial imitation learning with preferences},
  author={Taranovic, Aleksandar and Kupcsik, Andras Gabor and Freymuth, Niklas and Neumann, Gerhard},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{xu2020preference,
  title={Preference-based reinforcement learning with finite-time guarantees},
  author={Xu, Yichong and Wang, Ruosong and Yang, Lin and Singh, Aarti and Dubrawski, Artur},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18784--18794},
  year={2020}
}

@article{busa2014preference,
  title={Preference-based reinforcement learning: evolutionary direct policy search using a preference-based racing algorithm},
  author={Busa-Fekete, R{\'o}bert and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Weng, Paul and Cheng, Weiwei and H{\"u}llermeier, Eyke},
  journal={Machine learning},
  volume={97},
  pages={327--351},
  year={2014},
  publisher={Springer}
}

@article{ji2024reinforcement,
  title={Reinforcement learning from human feedback with active queries},
  author={Ji, Kaixuan and He, Jiafan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2402.09401},
  year={2024}
}

@article{li2024feel,
  title={Feel-Good Thompson Sampling for Contextual Dueling Bandits},
  author={Li, Xuheng and Zhao, Heyang and Gu, Quanquan},
  journal={arXiv preprint arXiv:2404.06013},
  year={2024}
}

@article{saha2021optimal,
  title={Optimal algorithms for stochastic contextual preference bandits},
  author={Saha, Aadirupa},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={30050--30062},
  year={2021}
}

@article{wu2023making,
  title={Making rl with preference-based feedback efficient via randomization},
  author={Wu, Runzhe and Sun, Wen},
  journal={arXiv preprint arXiv:2310.14554},
  year={2023}
}

@article{russo2014learning,
  title={Learning to optimize via information-directed sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{russo2016information,
  title={An information-theoretic analysis of thompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={68},
  pages={1--30},
  year={2016}
}

@article{dong2018information,
  title={An information-theoretic analysis for thompson sampling with many actions},
  author={Dong, Shi and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{bubeck2020first,
  title={First-order bayesian regret analysis of thompson sampling},
  author={Bubeck, S{\'e}bastien and Sellke, Mark},
  booktitle={Algorithmic Learning Theory},
  pages={196--233},
  year={2020},
  organization={PMLR}
}
@inproceedings{liu2018information,
  title={Information directed sampling for stochastic bandits with graph feedback},
  author={Liu, Fang and Buccapatnam, Swapna and Shroff, Ness},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{kirschner2021asymptotically,
  title={Asymptotically optimal information-directed sampling},
  author={Kirschner, Johannes and Lattimore, Tor and Vernade, Claire and Szepesv{\'a}ri, Csaba},
  booktitle={Conference on Learning Theory},
  pages={2777--2821},
  year={2021},
  organization={PMLR}
}

@inproceedings{hao2022contextual,
  title={Contextual information-directed sampling},
  author={Hao, Botao and Lattimore, Tor and Qin, Chao},
  booktitle={International Conference on Machine Learning},
  pages={8446--8464},
  year={2022},
  organization={PMLR}
}

@article{hao2022regret,
  title={Regret bounds for information-directed reinforcement learning},
  author={Hao, Botao and Lattimore, Tor},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={28575--28587},
  year={2022}
}
@article{moradipari2023improved,
  title={Improved Bayesian regret bounds for thompson sampling in reinforcement learning},
  author={Moradipari, Ahmadreza and Pedramfar, Mohammad and Shokrian Zini, Modjtaba and Aggarwal, Vaneet},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={23557--23569},
  year={2023}
}





@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@inproceedings{zhu2023principled,
  title={Principled reinforcement learning with human feedback from pairwise or k-wise comparisons},
  author={Zhu, Banghua and Jordan, Michael and Jiao, Jiantao},
  booktitle={International Conference on Machine Learning},
  pages={43037--43067},
  year={2023},
  organization={PMLR}
}

@article{xie2024exploratorypreferenceoptimizationharnessing,
  title={Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF},
  author={Xie, Tengyang and Foster, Dylan J and Krishnamurthy, Akshay and Rosset, Corby and Awadallah, Ahmed and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2405.21046},
  year={2024}
}

@article{tossou2019nearoptimaloptimisticreinforcementlearning,
  title={Near-optimal optimistic reinforcement learning using empirical bernstein inequalities},
  author={Tossou, Aristide and Basu, Debabrota and Dimitrakakis, Christos},
  journal={arXiv preprint arXiv:1905.12425},
  year={2019}
}

@article{ye2024theoretical,
  title={A theoretical analysis of nash learning from human feedback under general kl-regularized preference},
  author={Ye, Chenlu and Xiong, Wei and Zhang, Yuheng and Jiang, Nan and Zhang, Tong},
  journal={arXiv preprint arXiv:2402.07314},
  year={2024}
}

@article{zhang2024provablyefficientinformationdirectedsampling,
  title={Provably Efficient Information-Directed Sampling Algorithms for Multi-Agent Reinforcement Learning},
  author={Zhang, Qiaosheng and Bai, Chenjia and Hu, Shuyue and Wang, Zhen and Li, Xuelong},
  journal={arXiv preprint arXiv:2404.19292},
  year={2024}
}

@inproceedings{kirschner2018informationdirectedsamplingbandits,
  title={Information directed sampling and bandits with heteroscedastic noise},
  author={Kirschner, Johannes and Krause, Andreas},
  booktitle={Conference On Learning Theory},
  pages={358--384},
  year={2018},
  organization={PMLR}
}

@article{hao2021information,
  title={Information directed sampling for sparse linear bandits},
  author={Hao, Botao and Lattimore, Tor and Deng, Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16738--16750},
  year={2021}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@book{ghosal2017fundamentals,
  title={Fundamentals of nonparametric Bayesian inference},
  author={Ghosal, Subhashis and van der Vaart, Aad W},
  volume={44},
  year={2017},
  publisher={Cambridge University Press}
}
@inproceedings{saha2023dueling,
  title={Dueling rl: Reinforcement learning with trajectory preferences},
  author={Saha, Aadirupa and Pacchiano, Aldo and Lee, Jonathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6263--6289},
  year={2023},
  organization={PMLR}
}


@inproceedings{bai2025online,
  title={Online Preference Alignment for Language Models via Count-based Exploration},
  author={Bai, Chenjia and Zhang, Yang and Qiu, Shuang and Zhang, Qiaosheng and Xu, Kang and Li, Xuelong},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{zhang2024provably,
  title={Provably Efficient Information-Directed Sampling Algorithms for Multi-Agent Reinforcement Learning},
  author={Zhang, Qiaosheng and Bai, Chenjia and Hu, Shuyue and Wang, Zhen and Li, Xuelong},
  journal={arXiv preprint arXiv:2404.19292},
  year={2024}
}

