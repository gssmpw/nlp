\section{Introduction}
\label{sec:intro}

Point cloud-based 3D object detection is revolutionizing a wide range of applications, significantly enhancing capabilities in fields such as autonomous driving~\cite{fernandesPointcloudBased3D2021a, mao3DObjectDetection2023a, zengRT3DRealTime3D2018} and 3D scene perception~\cite{wisultschew3DLIDARBasedObject2021, benedek3DPeopleSurveillance2014, 3DSurveillance, blanch2024lidar}. Due to the conflict between computationally intensive deep learning-based 3D object detectors and the limited computational resources of edge devices, it is promising to stream or archive point clouds to compute-capable platforms for further analytics~\cite{lianides20223d, mclean2022towards} or model optimization~\cite{yang2023online, shaheen2022continual}. However, the large volumes of point cloud data generated by sensors pose significant challenges for networking and storage.

% for collaborative sensing\needsref{}, edge-assisted object detection\needsref{}, or online model optimization\needsref{}.

\begin{figure}[ht]
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{-0.2cm}
  \centering
    % \fbox{\rule{0pt}{6cm} \rule{0.9\linewidth}{0pt}}
    \includegraphics[width=\linewidth]{figs/teaser.pdf}
  \caption{The first row demonstrates the accuracy improvement of 3D object detection after applying RoI encoding (objects detected are colored in green). The second row shows the accuracy-bitrate trade-off curve of \methodname{} and VPCC when supporting CenterPoint~\cite{yin2021center} and BEVFusion-Lidar~\cite{liu2023bevfusion}.\protect\footnote{}}
  \label{fig-intro-showcase}
\vspace{-0.4cm}
\end{figure}
\footnotetext{Results in the first row are encoded with nuScenes~\cite{caesarnuScenesMultimodalDataset2020} dataset, RoI QP $\roiqp=20$, background QP $\backqp=45$, CenterPoint~\cite{yin2021center} as the back-end 3D object detector. Settings of results in the second row follow Fig.~\ref{fig-metric-illus}. Details about RoI encoding can be found in ~\cref{sec-roi-encoder}.}

\begin{figure*}[t]
\setlength{\abovecaptionskip}{0.2cm}
\setlength{\belowcaptionskip}{-0.2cm}
  \centering
    % \fbox{\rule{0pt}{5cm} \rule{\linewidth}{0pt}}
    \includegraphics[width=\linewidth]{figs/system.pdf}
  \caption{Overview of \methodname{}.}
  \label{fig-system-diagram}
% \vspace{-0.2cm}
\end{figure*}


The moving picture experts group's (MPEG) video-based point cloud compression (VPCC)~\cite{graziosi2021video} standard is a promising solution to point cloud sequence compression. VPCC projects a sequence of 3D point clouds into 2D depth and color images, and leverages mature video codecs such as H.264~\cite{wiegand2003overview}, which is widely supported by existing hardware, to remove temporal redundancy and compress the volume~\cite{graziosiOverviewOngoingPoint2020}. Typically, VPCC does not prioritize different spatial regions and applies a constant compression quality within a point cloud, which is aligned with visual quality metrics such as Point-to-Point (P2P) PSNR~\cite{mekuriaPerformanceAssessmentPoint2017} and Point-to-Plane (P2C) PSNR~\cite{tianGeometricDistortionMetrics2017a}.

However, this quality assignment scheme poses significant limitations in applications where some spatial regions, i.e., regions of interest (RoIs), demand higher fidelity. 
For instance, in driving scenes, regions containing the potential objects are crucial for 3D object detectors~\cite{qi2018frustum,paigwar2021frustum}, while the ground plane is less interested~\cite{himmelsbachFastSegmentation3D2010, leePatchworkFastRobust2022}. The uniform application of compression may result in the loss of critical details in RoIs, potentially compromising the functionality of 3D object detectors. 
To better understand this dilemma, Fig.~\ref{fig-intro-showcase} demonstrates the bitrate-accuracy curve of VPCC when applying VPCC on nuScenes dataset~\cite{caesarnuScenesMultimodalDataset2020}. As shown, VPCC experiences a poor trade-off between bitrate reduction and 3D object detection accuracy.

To this end, we propose \methodname{}, a RoI-based point cloud sequence compression method. Specifically, we enhance VPCC to support RoI encoding and design a lightweight detector to locate RoIs efficiently. As shown in Fig.~\ref{fig-intro-showcase}, with the aid of RoI encoding, our method significantly improves the accuracy of 3D object detectors. 

% The right part of Fig.~\ref{fig-intro-showcase} shows that VPCC is ignorant of the RoI. Points containing the potential objects suffer from large distortion. 

% To implement 3D RoI encoding, the key challenge is detecting RoI with low computational complexity. We observe that, the rate-accuracy trade-off is less sensitive on RoI prediciton's precision than its recall, as shown in Fig.~\ref{fig-intro-showcase}. This observation gives us chances to use rough 3D object detection results as RoI predictions. 

The contributions of this work are as follows:

\begin{itemize}
  \item To our knowledge, this is the first study that highlights and addresses the poor bitrate-accuracy trade-off of VPCC when it supports 3D object detection.
  \item We enhance VPCC to support RoI-based encoding to allow spatially non-uniform quality assignment. 
  \item We design an efficient RoI detector to locate critical regions potentially containing objects. 
  \item We evaluate \methodname{} on the nuScenes dataset. Experimental results show that \methodname{} achieves a better bitrate-accuracy trade-off than vanilla VPCC.
\end{itemize}



% \begin{figure*}
%   \centering
%   \begin{subfigure}{0.68\linewidth}
%     \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
%     \caption{An example of a subfigure.}
%     \label{fig:short-a}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}{0.28\linewidth}
%     \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
%     \caption{Another example of a subfigure.}
%     \label{fig:short-b}
%   \end{subfigure}
%   \caption{Example of a short caption, which should be centered.}
%   \label{fig:short}
% \end{figure*}
