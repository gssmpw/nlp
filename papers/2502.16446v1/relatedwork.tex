\section{Related Work}
Previous GAN-based models for SMILES sequence generation include SeqGAN and ORGAN. These foundational approaches were later extended with downstream networks such as ORGANIC\cite{Sanchez-Lengeling2017}, RANC\cite{Putin2018a} and ATNC\cite{Putin2018b}, which tailored the generative process to specific application objectives. %The primary goal of these methods has been to minimize various types of divergences between real and generated distributions. However, their discriminators are typically trained from scratch without leveraging pre-trained networks, making them prone to overfitting on the training set and harder to converge, especially when working with small datasets. Additionally, the average length and distribution of input molecular sequences significantly influence training outcomes, further complicating the optimization process.

Since the introduction of GANs\cite{Goodfellow2020}, advancements in architectures\cite{Radford2015,Odena2016,Karras2018,Karras2021,Huang2025}, training strategies\cite{Karras2017}, and objective functions\cite{Durugkar2016,Arjovsky2017,Albuquerque2019,Kumari2021} have led to significant progress. Despite their success in image-based tasks, many methods have not yet been applied to GANs for sequence generation. In this work, we integrate these advancements including ACGAN, pre-trained discriminators, and WGAN objective function into a sequence-generation GAN framework, with a particular focus on molecular sequence generation.%For example, ACGAN is a classic model in computer vision, demonstrating improved image generation quality by incorporating auxiliary label information. Pre-trained discriminators have also proven effective in GAN frameworks, enabling high-quality image generation with minimal training data. Despite their success in image-based tasks, these methods have yet to be applied to GANs for sequence generation. WGANs, which utilize the Wasserstein distance as the objective function, address critical issues like mode collapse and have been applied in ORGAN to improve generative stability. 

Molecules, due to their structured nature and extensive prior knowledge, are particularly well-suited for transfer learning. Descriptor-generation tools like RDKit\cite{rdkit} and OpenBabel\cite{O'Boyle2011} allow for the extraction of rich molecular features, which can be effectively transferred to unseen tasks, datasets, and domains. In our work, we leverage these transferable molecular property representations for unsupervised model training, enabling the generation of high-quality SMILES strings even with limited training data.

GANs can amplify data to address data scarcity issue in molecule predicting task\cite{arigye2020}, outperforming traditional methods like Synthetic Minority Oversampling Technique (SMOTE). At present, data enhancement methods have not been used to generate molecules in GANs. For highly imbalanced datasets, we employ over-sampling to enrich minority classes.