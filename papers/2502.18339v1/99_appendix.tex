\clearpage

\section{Related Work}
\label{app:sec:related_work}

The evaluation of language models has a rich and constantly evolving history. Human evaluations have long been considered the gold standard \citep{gatt2018survey,van2019best,celikyilmaz2020evaluation,roller2020opendomainconversationalagentscurrent,van2021human}, despite serious objections raised regarding the collection, analysis, and interpretation of human evaluation scores \citep{novikova2018rankme,howcroft2020twenty, bowman2021fixbenchmarkingnaturallanguage,karpinska2021perilsusingmechanicalturk, clark2021all,smith2022humanevaluationconversationsopen, gehrmann2023repairing,finch2023dontforgetabcsevaluating}. Many classic NLP benchmark metrics, such as BLEU \citep{papineni2002bleu}, NIST \citep{doddington2002nist}, ROUGE \citep{lin2004rouge}, and METEOR \citep{banerjee2005meteor}, were introduced on the premise that they correlate with human judgments. However, subsequent studies revealed that the relationship between automated metrics and human evaluations is often complex and not straightforward \citep{liu2016hownot, novikova2017we, reiter2018structured, karpinska2021perilsusingmechanicalturk}. Another prominent class of evaluation methods are based on machine learning models, e.g., word mover distance \citep{kusner2015word} and BERT-Score \citep{zhang2019bertscore} that have since evolved into using chat LMs themselves as evaluators \citep{wang2023chatgpt,zheng2024judging, chiang2023largelanguagemodelsalternative,chan2023chatevalbetterllmbasedevaluators,bavaresco2024llms,fu2024gptscore}, albeit with limitations, e.g., \citep{dorner2024limits,szymanski2024limitationsllmasajudgeapproachevaluating, thakur2024judging}.

The earliest investigations into the general relationship between NLP benchmark scores and human evaluations date back to \citet{bangalore2000evaluation}, \citet{belz2006comparing}, and \citet{liu2016hownot}. In the context of natural language generation, \citet{clinciu2021study} found that embedding-based automated metrics (e.g., BERT-Score \citep{zhang2019bertscore} and BLEURT \citet{sellam2020bleurt}) correlate more strongly with human judgments compared to word-overlap metrics (e.g., ROUGE \citep{lin2004rouge} and BLEU \citep{papineni2002bleu}). In the domain of natural language inference, \citet{schuff2021does} found that automated metrics do not appear to correlate with human judgment scores. However, the majority of these works predate the current era of chat LMs, which exhibit significantly more advanced capabilities compared to their predecessors. This new era motivates our work to investigate the relationship between NLP benchmarks and human evaluations when evaluating chat LMs.

\section{Experimental Methodology: Data and Analyses}
\label{app:sec:experimental_methodology}

\subsection{Data: Natural Language Processing (NLP) Benchmark Scores}
\label{app:sec:experimental_methodology:nlp_benchmarks}

We chose which NLP benchmarks to include based largely on which frontier AI models were reporting performance scores on. Llama 1 \citep{touvron2023llama1} and Llama 2 \citep{touvron2023llama2} were our primary guides, as were Gemini 1 and Gemini 1.5 \citep{team2023gemini, reid2024gemini}, Claude 3 \citep{anthropic2023claude3}, and Mistral \citep{jiang2023mistral}.
We evaluated the 4 Llama 2 Chat models following the same evaluation processes reported in the Llama 2 paper \citep{touvron2023llama2}.
This included matching the prompt formatting, automated metric scoring and (when appropriate) few-shot prompting and chain-of-thought prompting.
% Different benchmarks are reported under zero and few-shot prompting.
After evaluating the four Chat Llama 2 models on these NLP benchmarks and evaluation processes, we obtained 160 scores per model for our analyses.

\begin{figure*}[t!]
    \centering
    % https://www.overleaf.com/learn/latex/Using_colors_in_LaTeX
    \includegraphics[width=0.9\textwidth]{figures/schematics/human_eval_taxonomy.pdf}
    \caption{\textbf{Human Evaluations: Taxonomy of Single-Turn and Multi-Turn Conversations.} Single-turn and multi-turn prompts were created in a hierarchical taxonomy of 9 areas (blue), categories (green) and subcategories (yellow). Paid human annotators then rated Chat Llama 2 generations against ChatGPT generations by paid human annotators on a 7 point Likert scale \citep{likert1932technique}.}
    \label{fig:human_eval_prompt_taxonomy}
\end{figure*}


\begin{longtable}{|c|c|c|c|c|}
    \caption{\textbf{Natural Language Processing Datasets and Evaluation Processes.} In this work, we used the above well-established NLP datasets and evaluation processes. ``cot" means Chain-of-Thought prompting \citep{cobbe2021training, wei2022chain}. ``Gen" refers generations per evaluation. For more information, please see Section \ref{sec:methods} and Appendix \ref{app:sec:experimental_methodology}.}
    \label{app:tab:all_benchmarks_tasks}\\
    \hline
    Benchmark & Subset & Metric & Shots & Additional\\
    \hline
    \endfirsthead
    \multicolumn{5}{c}%
    {{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
    \hline
    Benchmark & Subset & Metric & Shots & Additional \\
    \hline
    \endhead
    AGI & aqua\_rat & Acc Char & 5 & -- \\
    AGI & gaokao\_biology & Acc Char & 5 & -- \\
    AGI & gaokao\_chemistry & Acc Char & 5 & -- \\
    AGI & gaokao\_chinese & Acc Char & 5 & -- \\
    AGI & gaokao\_english & Acc Char & 5 & -- \\
    AGI & gaokao\_geography & Acc Char & 5 & -- \\
    AGI & gaokao\_history & Acc Char & 5 & -- \\
    AGI & gaokao\_mathcloze & Exact Match & 5 & -- \\
    AGI & gaokao\_mathqa & Acc Char & 5 & -- \\
    AGI & gaokao\_physics & Acc Char & 5 & -- \\
    AGI & jec\_qa\_ca & Acc Char & 5 & -- \\
    AGI & jec\_qa\_kd & Acc Char & 5 & -- \\
    AGI & logiqa\_en & Acc Char & 3 & -- \\
    AGI & logiqa\_zh & Acc Char & 3 & -- \\
    AGI & lsat\_ar & Acc Char & 3 & -- \\
    AGI & lsat\_lr & Acc Char & 3 & -- \\
    AGI & lsat\_rc & Acc Char & 3 & -- \\
    AGI & sat\_math & Acc Char & 5 & -- \\
    ARC & Challenge & Acc Char & 0 & -- \\
    ARC & Easy & Acc Char & 0 & -- \\
    BBH & boolean\_expressions & Exact Match & 0 & -- \\
    BBH & causal\_judgement & Exact Match & 0 & -- \\
    BBH & date\_understanding & Exact Match & 0 & -- \\
    BBH & disambiguation\_qa & Exact Match & 0 & -- \\
    BBH & dyck\_languages & Exact Match & 0 & -- \\
    BBH & formal\_fallacies & Exact Match & 0 & -- \\
    BBH & geometric\_shapes & Exact Match & 0 & -- \\
    BBH & hyperbaton & Exact Match & 0 & -- \\
    BBH & logical\_deduction\_3\_objects & Exact Match & 0 & -- \\
    BBH & logical\_deduction\_5\_objects & Exact Match & 0 & -- \\
    BBH & logical\_deduction\_7\_objects & Exact Match & 0 & -- \\
    BBH & movie\_recommendation & Exact Match & 0 & -- \\
    BBH & multistep\_arithmetic\_two & Exact Match & 0 & -- \\
    BBH & navigate & Exact Match & 0 & -- \\
    BBH & object\_counting & Exact Match & 0 & -- \\
    BBH & penguins\_in\_a\_table & Exact Match & 0 & -- \\
    BBH & reasoning\_about\_colored\_objects & Exact Match & 0 & -- \\
    BBH & ruin\_names & Exact Match & 0 & -- \\
    BBH & salient\_translation\_error\_detection & Exact Match & 0 & -- \\
    BBH & snarks & Exact Match & 0 & -- \\
    BBH & sports\_understanding & Exact Match & 0 & -- \\
    BBH & temporal\_sequences & Exact Match & 0 & -- \\
    BBH & tracking\_shuffled\_objects\_3 & Exact Match & 0 & -- \\
    BBH & tracking\_shuffled\_objects\_5 & Exact Match & 0 & -- \\
    BBH & tracking\_shuffled\_objects\_7 & Exact Match & 0 & -- \\
    BBH & web\_of\_lies & Exact Match & 0 & -- \\
    BBH & word\_sorting & Exact Match & 0 & -- \\
    BoolQ & -- & Acc Token & 0 & -- \\
    CommonSenseQA & -- & Acc Char & 7 & -- \\
    COPA & -- & Acc Char & ? & -- \\
    DROP & -- & Exact Match & 0 & -- \\
    DROP & -- & F1 & 0 & -- \\
    ETHOS & -- & Acc Char & 0 & -- \\
    GSM8K & -- & Exact Match & 0 & 100 Gen \\
    GSM8K & -- & F1 & 0 & 100 Gen \\
    GSM8K & -- & Exct Mtch maj1@100 & 0 & 100 Gen \\
    GSM8K & -- & F1 maj1@100 & 0 & 100 Gen \\
    HellaSwag & -- & Acc Char & ? & -- \\
    Human Eval & -- & pass@1 & 0 & 1 Gen \\
    Human Eval & -- & pass@1 & 0 & 200 Gen \\
    Human Eval & -- & pass@100 & 0 & 200 Gen \\
    Inverse Scaling & hindsight\_neglect & Exact Match & 0 & -- \\
    Inverse Scaling & into\_the\_unknown & Exact Match & 0 & -- \\
    Inverse Scaling & memo\_trap & Exact Match & 0 & -- \\
    Inverse Scaling & modus\_tollens & Exact Match & 0 & -- \\
    Inverse Scaling & neqa & Exact Match & 0 & -- \\
    Inverse Scaling & pattern\_matching\_suppression & Exact Match & 0 & -- \\
    Inverse Scaling & redefine & Exact Match & 0 & -- \\
    Inverse Scaling & repetitive\_algebra & Exact Match & 0 & -- \\
    Inverse Scaling & resisting\_correction & Exact Match & 0 & -- \\
    Inverse Scaling & sig\_figs & Exact Match & 0 & -- \\
    Kth Sentence & 128 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 256 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 512 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 1024 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 1536 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 2048 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 4096 & ROUGE-2 & 0 & -- \\
    Kth Sentence & 8192 & ROUGE-2 & 0 & -- \\
    MBPP & -- & pass@1 & 3 & 80 Gen \\
    MBPP & -- & pass@80 & 3 & 80 Gen \\
    MMLU & abstract\_algebra & Acc Char & 5 & -- \\
    MMLU & anatomy & Acc Char & 5 & -- \\
    MMLU & astronomy & Acc Char & 5 & -- \\
    MMLU & business\_ethics & Acc Char & 5 & -- \\
    MMLU & clinical\_knowledge & Acc Char & 5 & -- \\
    MMLU & college\_biology & Acc Char & 5 & -- \\
    MMLU & college\_chemistry & Acc Char & 5 & -- \\
    MMLU & college\_computer\_science & Acc Char & 5 & -- \\
    MMLU & college\_mathematics & Acc Char & 5 & -- \\
    MMLU & college\_medicine & Acc Char & 5 & -- \\
    MMLU & college\_physics & Acc Char & 5 & -- \\
    MMLU & computer\_security & Acc Char & 5 & -- \\
    MMLU & conceptual\_physics & Acc Char & 5 & -- \\
    MMLU & econometrics & Acc Char & 5 & -- \\
    MMLU & electrical\_engineering & Acc Char & 5 & -- \\
    MMLU & elementary\_mathematics & Acc Char & 5 & -- \\
    MMLU & formal\_logic & Acc Char & 5 & -- \\
    MMLU & global\_facts & Acc Char & 5 & -- \\
    MMLU & high\_school\_biology & Acc Char & 5 & -- \\
    MMLU & high\_school\_chemistry & Acc Char & 5 & -- \\
    MMLU & high\_school\_computer\_science & Acc Char & 5 & -- \\
    MMLU & high\_school\_european\_history & Acc Char & 5 & -- \\
    MMLU & high\_school\_geography & Acc Char & 5 & -- \\
    MMLU & high\_school\_government\_and\_politics & Acc Char & 5 & -- \\
    MMLU & high\_school\_macroeconomics & Acc Char & 5 & -- \\
    MMLU & high\_school\_mathematics & Acc Char & 5 & -- \\
    MMLU & high\_school\_microeconomics & Acc Char & 5 & -- \\
    MMLU & high\_school\_physics & Acc Char & 5 & -- \\
    MMLU & high\_school\_psychology & Acc Char & 5 & -- \\
    MMLU & high\_school\_statistics & Acc Char & 5 & -- \\
    MMLU & high\_school\_us\_history & Acc Char & 5 & -- \\
    MMLU & high\_school\_world\_history & Acc Char & 5 & -- \\
    MMLU & human\_aging & Acc Char & 5 & -- \\
    MMLU & human\_sexuality & Acc Char & 5 & -- \\
    MMLU & international\_law & Acc Char & 5 & -- \\
    MMLU & jurisprudence & Acc Char & 5 & -- \\
    MMLU & logical\_fallacies & Acc Char & 5 & -- \\
    MMLU & machine\_learning & Acc Char & 5 & -- \\
    MMLU & management & Acc Char & 5 & -- \\
    MMLU & marketing & Acc Char & 5 & -- \\
    MMLU & medical Genetics & Acc Char & 5 & -- \\
    MMLU & miscellaneous & Acc Char & 5 & -- \\
    MMLU & moral\_disputes & Acc Char & 5 & -- \\
    MMLU & moral\_scenarios & Acc Char & 5 & -- \\
    MMLU & nutrition & Acc Char & 5 & -- \\
    MMLU & philosophy & Acc Char & 5 & -- \\
    MMLU & prehistory & Acc Char & 5 & -- \\
    MMLU & professional\_accounting & Acc Char & 5 & -- \\
    MMLU & professional\_law & Acc Char & 5 & -- \\
    MMLU & professional\_medicine & Acc Char & 5 & -- \\
    MMLU & professional\_psychology & Acc Char & 5 & -- \\
    MMLU & public\_relations & Acc Char & 5 & -- \\
    MMLU & security\_studies & Acc Char & 5 & -- \\
    MMLU & sociology & Acc Char & 5 & -- \\
    MMLU & us\_foreign\_policy & Acc Char & 5 & -- \\
    MMLU & virology & Acc Char & 5 & -- \\
    MMLU & world\_religions & Acc Char & 5 & -- \\
    NaturalQuestions & -- & Exact Match & 0 & -- \\
    OpenBookQA & -- & Acc Completion & 0 & -- \\
    PIQA & -- & Acc Char & 0 & -- \\
    QuAC & -- & F1 & 0 & -- \\
    RACE & High School & Acc Char & 0 & -- \\
    RACE & Middle School & Acc Char & 0 & -- \\
    SIQA & -- & Acc Char & 0 & -- \\
    SQuAD & -- & Exact Match & 0 & -- \\
    SciBench & atkins & Fuzzy Match & 0 & -- \\
    SciBench & calculus & Fuzzy Match & 0 & -- \\
    SciBench & chemmc & Fuzzy Match & 0 & -- \\
    SciBench & class & Fuzzy Match & 0 & -- \\
    SciBench & diff & Fuzzy Match & 0 & -- \\
    SciBench & fund & Fuzzy Match & 0 & -- \\
    SciBench & matter & Fuzzy Match & 0 & -- \\
    SciBench & quan & Fuzzy Match & 0 & -- \\
    SciBench & stat & Fuzzy Match & 0 & -- \\
    SciBench & thermo & Fuzzy Match & 0 & -- \\
    TLDR & -- & ROUGE-2 & 0 & -- \\
    TLDR & -- & ROUGE-L & 0 & -- \\
    TriviaQA & -- & Exact Match & 0 & -- \\
    WinoGrande & -- & Acc Char & 0 & -- \\
    Xsum & -- & ROUGE-2 & 1 & -- \\
    \hline
\end{longtable}


\subsection{Data: Human Evaluation Scores}
\label{app:sec:experimental_methodology:human_evals}

Human data annotators were hired to evaluate outputs of chat language models (LMs) in single-turn and multi-turn conversations using a Likert scale \citep{likert1932technique} from 1 to 7. The conversations were constructed within our taxonomy of areas-categories-subcategories (Sec. \ref{sec:methods}; Fig. \ref{fig:human_eval_prompt_taxonomy}). Each conversation was evaluated by at least three unique humans for a combined total of 2104 unique human annotators. Our human annotators scored 11291 single-turn conversations and 2081 multi-turn conversations.


\begin{longtable}{|l|l|l|}
\caption{\textbf{Human Evaluation Areas, Categories, and Subcategories.}}
\label{tab:categories}\\
\hline
\textbf{Area} & \textbf{Category} & \textbf{Subcategory}\\
\hline
\endfirsthead
\multicolumn{3}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}}\\
\hline
\textbf{Area} & \textbf{Category} & \textbf{Subcategory}\\
\hline
\endhead
Dialogue & Adversarial Dishonesty & Adversarial Dishonesty \\
Dialogue & Adversarial Harmfulness & Adversarial Harmfulness \\
Dialogue & Advice & Casual advice \& recommendations \\
Dialogue & Advice & Personal \& interpersonal relationships \\
Dialogue & Brainstorming & Brainstorming \\
Dialogue & Classification & Classification \\
Dialogue & Closed QA & Closed QA \\
Dialogue & Code & Code \\
Dialogue & Conversational / Entertainment & Conversational / Entertainment \\
Dialogue & Conversational/Entertainment & Conversational/Entertainment \\
Dialogue & Dialogue & Dialogue \\
Dialogue & Extraction & Extraction \\
Dialogue & Factual Questions & Factual Questions \\
Dialogue & Identity / Personas & Famous historical personalities \\
Dialogue & Identity / Personas & Fictional characters \\
Dialogue & Identity / Personas & No character (it's just an AI) \\
Dialogue & Identity / Personas & Public figures \\
Dialogue & Identity / Personas & Synthetic (made up) characters \\
Dialogue & Language Assistance & Language Assistance \\
Dialogue & Math & Math \\
Dialogue & Mathematical Reasoning & Mathematical Reasoning \\
Dialogue & Open QA & Open QA \\
Dialogue & Procedural Questions & Procedural Questions \\
Dialogue & Reasoning (math / problem-solving) & Reasoning (math / problem-solving) \\
Dialogue & Recommendations / Brainstorming & Recommendations / Brainstorming \\
Dialogue & Rewriting & Rewriting \\
Dialogue & Safety & Safety \\
Dialogue & Summarization & Summarization \\
Dialogue & Writing & Writing \\
Dialogue & Writing \& Content Creation & Writing \& Content Creation \\
Factual Questions & Cultural \& social topics & Arts \& literature \\
Factual Questions & Cultural \& social topics & History \& traditions \\
Factual Questions & Cultural \& social topics & Popular culture \& media \\
Factual Questions & Cultural \& social topics & Religion \& spirituality \\
Factual Questions & Cultural \& social topics & Social issues \& current events \\
Language assistance & Grammar, spelling, \& vocabulary & English slang \\
Language assistance & Grammar, spelling, \& vocabulary & Grammar \& syntax \\
Language assistance & Grammar, spelling, \& vocabulary & Language conventions \& style \\
Language assistance & Grammar, spelling, \& vocabulary & Spelling \& orthography \\
Language assistance & Grammar, spelling, \& vocabulary & Vocabulary \& word choice \\
Recommendations & Entertainment suggestions & Books, authors, \& genres \\
Recommendations & Entertainment suggestions & Games, apps, \& digital content \\
Recommendations & Entertainment suggestions & Movies, TV shows, \& streaming content \\
Recommendations & Entertainment suggestions & Music, songs, \& artists \\
Recommendations & Personal \& professional development & Health, wellness, \& self-improvement tips \\
Recommendations & Personal \& professional development & Job search \& career advice \\
Recommendations & Personal \& professional development & Networking \& mentorship opportunities \\
Recommendations & Personal \& professional development & Skill-building resources \& courses \\
Writing \& content creation & Creative writing & Articles \& reviews \\
Writing \& content creation & Creative writing & Fictional stories \& narrative \\
Writing \& content creation & Creative writing & In-the-style-of writing \\
Writing \& content creation & Creative writing & Poetry \& songwriting \\
Writing \& content creation & Creative writing & Social media posts \\
Writing \& content creation & Summarization \& editing & Content restructuring \& organization \\
Writing \& content creation & Summarization \& editing & Proofreading \\
Writing \& content creation & Summarization \& editing & Style \& tone adjustments \\
\hline
\end{longtable}
% \subsection{Analyses: Correlations}

% \subsection{Analyses: Community Detection}

\subsection{Analyses: Linear Regression}
\label{app:sec:generalization_of_overparameterized_models}

Due to space limitations in the main text, we defered citations regarding generalization of overparameterized models to here. For a nonexhaustive list, please see \citet{vallet1989hebb,krogh1991simple,geman1992neural,krogh1992generalization,opper1995statistical,duin2000classifiers, spigler2018jamming, belkin2019reconciling, bartlett2020benign, belkin2020twomodels, nakkiran2021deep, poggio2019double, advani2020high, liang2020just, adlam2020understanding, rocks2022memorizing, rocks2021geometry, rocks2022bias, mei2022generalization, hastie2022surprises, bach2023highdimensional,schaeffer2023double, schaeffer2023divergence, curth2024u, schaeffer2024doubledescentdemystified}.

\clearpage
\section{Statistics of Human Evaluations}

As exploratory data analysis, we calculated and examined basic statistics of the human evaluations. Fig. \ref{app:fig:human_evaluations_number_of_turns_per_annotated_sample} showcases how many turns (i.e., back and forth messages) are in each sample evaluated by human annotators (left)  and how many human annotators evaluated each sample (right). Fig. \ref{app:fig:human_annotator_scores_mean_std_dev_ecdfs} shows the empirical cumulative distributions functions of the average of human annotators' scores per datum (left) and the standard deviation of human annotators' scores per datum (right). Fig. \ref{app:fig:human_annotator_scores_means_vs_std_dev_scatter_and_kde} visualizes the joint distribution of means and standard deviations of human annotators' scores per datum as both a scatterplot (left) and a kernel density estimate (right).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.48\linewidth]{figures/appendix/human_evals/num_turns_for_human_evals_hist.pdf}%
    \includegraphics[width=0.48\linewidth]{figures/appendix/human_evals/num_annotators_per_sample_hist.pdf}
    \caption{\textbf{Statistics of Human-Evaluated Data.} Left: Number of turns per datum. Right: Number of human annotators per human-evaluated datum.}
    \label{app:fig:human_evaluations_number_of_turns_per_annotated_sample}
\end{figure}


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.48\linewidth]{figures/appendix/human_evals/human_annotators_mean_ecdf.pdf}%
    \includegraphics[width=0.48\linewidth]{figures/appendix/human_evals/human_annotators_std_dev_ecdf.pdf}
    \caption{\textbf{Empirical Cumulative Distribution Functions of Human Annotators' Scores.} Left: Average of human annotators' score per annotated sample. Right: Human annotators' standard deviation per annotated sample. }
    \label{app:fig:human_annotator_scores_mean_std_dev_ecdfs}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.53\linewidth]{figures/appendix/human_evals/human_annotators_mean_vs_std_dev_scatter.pdf}%
    \includegraphics[width=0.45\linewidth]{figures/appendix/human_evals/human_annotators_mean_vs_std_dev_kde.pdf}
    \caption{\textbf{Joint Distribution of Human Annotators' Average Scores per Datum vs Standard Deviation per Datum.} Left: Scatterplot. Right: Kernel Density Estimate.}
    \label{app:fig:human_annotator_scores_means_vs_std_dev_scatter_and_kde}
\end{figure}

\clearpage
\section{Correlation Metrics Are Themselves Highly Correlated}
\label{app:sec:comparison_of_correlation_methods}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{figures/correlations/corr_between_human_and_academic_all_methods.pdf}
    \caption{\textbf{Correlation of Academic-Human Evaluation Correlations Under Different Correlation Metrics}. For each pair of human evaluation (area and category) and NLP benchmark (benchmark and subset), we computed the correlation between scores under one of 3 correlation metrics: Pearson, Spearman and Kendall. We then looked at how correlated the correlation scores under the 3 correlation metrics are. In general, all 3 are correlation metrics yield correlated scores. This demonstrates that the choice of correlation metric is relatively less important.}
    \label{app:fig:correlation_couplings}
\end{figure}

\clearpage
\section{Correlation Matrices Between Human Evaluations and NLP Benchmarks and Their Singular Value Decompositions}
\label{app:sec:full_correlation_matrices}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/appendix/correlations/singular_value_spectra_of_correlation_matrices.pdf}
    \caption{\textbf{Spectra of Human Evaluation-NLP Benchmark Correlation Matrices}. Because the correlation matrices are computed over four Chat Llama 2 models, the maximum matrix rank is 4. Howeer, both Pearson and Spearman correlation matrices have only 3 non-zero singular values.}
    \label{app:fig:academic_human_singular_value_spectra}
\end{figure}

\clearpage



\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/correlations/singular_modes_correlation=Pearson.pdf}
    \caption{\textbf{Pearson Correlation Matrix between Human Evaluations and NLP Benchmarks.} The Pearson correlation matrix has 3 non-zero singular values, with corresponding modes shown in the last 3 rows.}
    \label{app:fig:pearson_correlation}
\end{figure}

The first component of the Pearson correlation matrix divides the human evaluations and NLP benchmarks into 3 groups (Fig. \ref{fig:corr:singular_modes}B): one group that is broadly uncorrelated, and two unequally-sized groups that are self-correlated and mutually anti-correlated. The \textit{uncorrelated group} consists of human evaluations Dialogue:Code and Dialogue:Language Assistance, as well as NLP benchmarks Kth-sentence, TLDR, SciBench's Atkins and Differential Equations, MMLU's College Math and BBH's Formal Fallacies. The \textit{smaller self-correlated group} consists of Dialogue:Adversarial Dishonesty and Safety:Harmlessness as well as ETHOS (a hate speech detection benchmark), Inverse Scaling NEQA (a negation question-answering benchmark) and AGI Gaokao Chemistry, whereas the \textit{larger self-correlated group} consists of almost all other human evaluations and NLP benchmarks. This is more clearly visually displayed in the Spearman correlation matrix (App. Fig. \ref{app:fig:spearman_correlation}).

% Recalling that the second component of any SVD adds a \textit{correction} to the first component, we can understand the second component of the Pearson correlation matrix (Fig. \ref{fig:corr:singular_modes}C) as identifying which human evaluations and NLP benchmarks were under correlated than the first 

\clearpage


\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/correlations/singular_modes_correlation=Spearman.pdf}
    \caption{\textbf{Spearman Correlation Matrix between Human Evaluations and NLP Benchmarks.} The Spearman correlation matrix also has 3 non-zero singular values, with corresponding modes shown in the last 3 rows.}
    \label{app:fig:spearman_correlation}
\end{figure}

\clearpage

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/correlations/singular_modes_correlation=Kendall.pdf}
    \caption{\textbf{Kendall Correlation Matrix between Human Evaluations and NLP Benchmarks.} The Kendall correlation matrix has four non-zero singular values, with corresponding modes shown in the last four rows.}
    \label{app:fig:kendall_correlation}
\end{figure}


\clearpage
\section{Empirical Scaling Behavior of Human Evaluations and NLP Benchmarks}
\label{app:empirical_scaling_behavior}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/appendix/empirical_scaling_behavior/human_scores_vs_compute_by_human_dataset_eval_process.pdf}
    \caption{\textbf{Empirical Scaling Behavior of Human Evaluations with Increasing Compute.}}
    \label{app:fig:human_eval_vs_compute}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/appendix/empirical_scaling_behavior/academic_scores_vs_compute_by_human_dataset_eval_process.pdf}
    \caption{\textbf{Empirical Scaling Behavior of NLP Benchmarks with Increasing Compute.}}
    \label{app:fig:nlp_benchmark_vs_compute}
\end{figure}

\clearpage
\section{Coefficients of Leave-One-Out Cross-Validated Linear Regressions}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{figures/regressions/academic_dataset_and_eval_process_vs_coefficient_by_human_dataset_and_eval_process_lineplot.pdf}
    \caption{\textbf{Linear Coefficients of NLP Benchmarks in Predicting Human Evaluations.} For each human evaluation area, category and subcategory, we visualize the learned linear parameters per NLP benchmark averaged over the 4-fold leave-one-out cross validation process. For interpretation of results, see Sec. \ref{sec:predictions}.}
    \label{app:fig:linear_regression_coefficients}
\end{figure}
