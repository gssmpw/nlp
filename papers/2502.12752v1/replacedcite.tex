\section{Related Work}
\subsection{Feed-Forward Novel View Synthesis}
A significant number of attempts are devoted to synthesizing novel views from single/sparse observations in a feed-forward manner. Due to the limited input information, early works usually adopt depth estimation methods to model scene geometry and then utilize inpainting approaches for content synthesis____. To generate realistic novel views, several techniques are developed, including GAN-based inpainting____, VQ-VAE outpainter____, and implicit 3D transformer____. Recently, novel scene representations are proposed to achieve high-quality view synthesis. For instance, pixelNeRF combines convolutional networks with NeRF representation to render novel views from two images____. Meanwhile, layer-based representations, \eg, multi-plane images (MPI)____ and layered depth images (LDI)____, are exploited for efficient rendering.
However, since previous feed-forward NVS methods are mainly designed for specific domains, they often suffer from performance drops in complex scenes due to the limited model capability.

\subsection{Diffusion-Based Novel View Synthesis} 
Diffusion models have demonstrated exceptional performance in generating realistic images and videos____, reflecting a profound understanding of the 3D world.
To utilize the diffusion prior for novel view synthesis, previous attempts develop conditional diffusion frameworks, \eg, 3D feature-conditioned diffusion____ and viewpoint-conditioned diffusion____, to generate novel views for simple inputs like 3D objects____. Considering complex real-world scenes, multi-view diffusion models are often employed to synthesize high-quality novel views, which are then used to generate 3D scenes (\eg, 3D Gaussians) for novel view rendering____. Based on this, ZeroNVS combines diverse training datasets to acquire zero-shot NVS performance____, and Cat3D designs an efficient parallel sampling strategy for fast generation of 3D-consistent images____. In addition, GenWarp exploits the diffusion prior to achieve semantic-preserving warping____. Recent works also explore the potential of video diffusion models for novel view synthesis. For instance, ViewCrafter constructs a point-conditioned video diffusion model to iteratively complete the point cloud for consistent view rendering____, and StereoCrafter proposes a tiled processing strategy to generate stereoscopic videos with video diffusion models____. While diffusion-based NVS approaches excel at synthesizing realistic novel views, the generative nature of diffusion models often introduces hallucinated content (\eg, Fig.~\ref{fig:main-teaser}), leading to inconsistent texture across different viewpoints.


\subsection{Splatting-Based Novel View Synthesis}
Splatting-based NVS approaches are typically trained in a regression manner with pixel-level or feature-level constraints____. As a result, they often preserve better textures compared to diffusion-based methods. Previous study employs depth-based warping to achieve real-time novel view rendering____. With the rapid advancement of 3DGS techniques____, a considerable amount of attention has been drawn to feed-forward Gaussian splatting methods. The pioneer work pixelSplat estimates Gaussian parameters from neural networks and dense probability distributions, achieving efficient novel view synthesis with a pair of images____. Following this, several techniques are developed for improved performance and efficiency, including cost volume encoding____ and depth-aware transformer____. Recent method DepthSplat integrates monocular features from depth models and achieves better geometry in the estimated 3D Gaussians____. Instead of utilizing multi-view cues, another line of work focuses on predicting Gaussian parameters from a single image. Splatter Image obtains 3D Gaussian parameters from pure image features____, and Flash3D employs zero-shot depth models for generalizable single-view NVS____. 
However, due to the challenges of estimating accurate geometry from limited observations, existing splatting-based methods often suffer from splatting errors, resulting in novel views with distorted geometry (\eg, Fig.~\ref{fig:main-teaser}). By contrast, our \method\ leverages the geometric priors of diffusion models to correct splatting errors, achieving geometry-consistent and high-fidelity novel view synthesis.


\input{figs/main/fig-diff}
\input{figs/main/fig-alignsyn}