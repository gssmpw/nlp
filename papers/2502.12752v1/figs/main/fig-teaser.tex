\def\imgWidth{0.238\textwidth} %
\def\scc{(-1.9,-1.4)}
\def\rebigone{(2.1, -0.8)} %
\def\reone{(-1.45,0.42)} %
\def\scc{(-2,-1.2)}

\def\ssmag{3}

\begin{teaserfigure}
    \centering
    \tikzstyle{img} = [rectangle, minimum width=\imgWidth, draw=black]
\centering
\begin{subfigure}{\textwidth}
\centering
    \includegraphics[width=\textwidth, trim=0 0 0 0, clip]{imgs/main/img-teaser.png}
    \end{subfigure}
    \caption{\textbf{Performance comparison.} Diffusion-based methods, \eg, ViewCrafter, usually hallucinate contents that are inconsistent with the input view. Splatting-based approaches, \eg, DepthSplat, often suffer from distorted geometry due to splatting errors. By contrast, our method produces novel views with consistent geometry and high-fidelity texture, achieving significantly better performance than previous arts on different tasks. Note that our model is trained only on the single-view novel view synthesis and is directly applied to the other tasks, showing promising cross-domain and cross-task performance.}
    \label{fig:main-teaser}
\end{teaserfigure}













