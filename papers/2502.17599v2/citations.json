[
  {
    "index": 0,
    "papers": [
      {
        "key": "wan2023efficient",
        "author": "Wan, Zhongwei and Wang, Xin and Liu, Che and Alam, Samiul and Zheng, Yu and Liu, Jiachen and Qu, Zhongnan and Yan, Shen and Zhu, Yi and Zhang, Quanlu and others",
        "title": "Efficient large language models: A survey"
      },
      {
        "key": "liu2024contemporary",
        "author": "Liu, Dong",
        "title": "Contemporary model compression on large language models inference"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Xiao2023EfficientSL",
        "author": "Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis",
        "title": "Efficient Streaming Language Models with Attention Sinks"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2024h2o",
        "author": "Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\\'e}, Christopher and Barrett, Clark and others",
        "title": "H2o: Heavy-hitter oracle for efficient generative inference of large language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Li2024SnapKVLK",
        "author": "Yuhong Li and Yingbing Huang and Bowen Yang and Bharat Venkitesh and Acyr F. Locatelli and Hanchen Ye and Tianle Cai and Patrick Lewis and Deming Chen",
        "title": "SnapKV: LLM Knows What You are Looking for Before Generation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "xiong2025parallelcomp",
        "author": "Xiong, Jing and Shen, Jianghan and Zheng, Chuanyang and Wan, Zhongwei and Zhao, Chenyang and Yang, Chiwun and Ye, Fanghua and Yang, Hongxia and Kong, Lingpeng and Wong, Ngai",
        "title": "ParallelComp: Parallel Long-Context Compressor for Length Extrapolation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xiong2024uncomp",
        "author": "Xiong, Jing and Shen, Jianghan and Ye, Fanghua and Tao, Chaofan and Wan, Zhongwei and Lu, Jianqiao and Wu, Xun and Zheng, Chuanyang and Guo, Zhijiang and Kong, Lingpeng and others",
        "title": "UNComp: Uncertainty-Aware Long-Context Compressor for Efficient Large Language Model Inference"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Zhang2024CaMCM",
        "author": "Yuxin Zhang and Yuxuan Du and Gen Luo and Yunshan Zhong and Zhenyu Zhang and Shiwei Liu and Rongrong Ji",
        "title": "CaM: Cache Merging for Memory-efficient LLMs Inference"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wan2024d2o",
        "author": "Wan, Zhongwei and Wu, Xinjian and Zhang, Yu and Xin, Yi and Tao, Chaofan and Zhu, Zhihong and Wang, Xin and Luo, Siqi and Xiong, Jing and Zhang, Mi",
        "title": "D2O: Dynamic Discriminative Operations for Efficient Generative Inference of Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhang2024pyramidkv",
        "author": "Zhang, Yichi and Gao, Bofei and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and Xiao, Wen and others",
        "title": "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2024kivi",
        "author": "Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia",
        "title": "KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kang2024gear",
        "author": "Kang, Hao and Zhang, Qingru and Kundu, Souvik and Jeong, Geonhwa and Liu, Zaoxing and Krishna, Tushar and Zhao, Tuo",
        "title": "GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wan2024look",
        "author": "Wan, Zhongwei and Wu, Ziang and Liu, Che and Huang, Jinfa and Zhu, Zhihong and Jin, Peng and Wang, Longyue and Yuan, Li",
        "title": "Look-m: Look-once optimization in kv cache for efficient multimodal long-context inference"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chu2024mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others",
        "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Shang2024LLaVAPruMergeAT",
        "author": "Yuzhang Shang and Mu Cai and Bingxin Xu and Yong Jae Lee and Yan Yan",
        "title": "LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Cao2024MADTPMA",
        "author": "Jianjian Cao and Peng Ye and Shengze Li and Chong Yu and Yansong Tang and Jiwen Lu and Tao Chen",
        "title": "MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "Chen2024AnII",
        "author": "Liang Chen and Haozhe Zhao and Tianyu Liu and Shuai Bai and Junyang Lin and Chang Zhou and Baobao Chang",
        "title": "An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "chu2024mobilevlm",
        "author": "Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others",
        "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "Shang2024LLaVAPruMergeAT",
        "author": "Yuzhang Shang and Mu Cai and Bingxin Xu and Yong Jae Lee and Yan Yan",
        "title": "LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "Cao2024MADTPMA",
        "author": "Jianjian Cao and Peng Ye and Shengze Li and Chong Yu and Yansong Tang and Jiwen Lu and Tao Chen",
        "title": "MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "Chen2024AnII",
        "author": "Liang Chen and Haozhe Zhao and Tianyu Liu and Shuai Bai and Junyang Lin and Chang Zhou and Baobao Chang",
        "title": "An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "liu2024world",
        "author": "Liu, Hao and Yan, Wilson and Zaharia, Matei and Abbeel, Pieter",
        "title": "World model on million-length video and language with blockwise ringattention"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "zhang2024long",
        "author": "Zhang, Peiyuan and Zhang, Kaichen and Li, Bo and Zeng, Guangtao and Yang, Jingkang and Zhang, Yuanhan and Wang, Ziyue and Tan, Haoran and Li, Chunyuan and Liu, Ziwei",
        "title": "Long context transfer from language to vision"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2024longllava",
        "author": "Wang, Xidong and Song, Dingjie and Chen, Shunian and Zhang, Chen and Wang, Benyou",
        "title": "LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "shu2024video",
        "author": "Shu, Yan and Zhang, Peitian and Liu, Zheng and Qin, Minghao and Zhou, Junjie and Huang, Tiejun and Zhao, Bo",
        "title": "Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding"
      }
    ]
  }
]