\section{Introduction}

The great advancements in language models have led to the integration of image encoding and understanding capabilities \cite{achiam2023gpt,lu2024deepseekvl, Qwen2-VL}, significantly enhancing the performance of a series of pre-trained  Visual Large Language Models (VLLMs) in tasks involving Visual Question Answering (VQA). Despite these advancements, akin to text Large Language Models (LLMs) \cite{touvron2023llama, workshop2022bloom, zhang2024exploring}, VLLMs remain constrained by the boundaries of their knowledge \cite{lin-byrne-2022-retrieval}. As a result, their ability to accurately respond to content outside the model's knowledge scope, such as knowledge-intensive questions, real-time news, and queries with dynamic answers, is considerably limited. 

\begin{figure}[tb]
\centering
\includegraphics[width=0.87\linewidth]{figs/outline.pdf}
\caption{VLLMs Knowledge Boundary concept. The black part represents all the knowledge humans have explored, and the orange and green parts represent knowledge possessed by VLLMs and knowledge that can be retrieved from external sources respectively. They overlap in some areas and the boundary between them remains unclear. The overall knowledge boundary of VLLMs can be differentiated into two parts that overlap with knowledge between RAG and world knowledge. Our method aims to identify both, and we conduct experiments to validate the potential VQA performance improvements using RAG.}
\label{outline}
\end{figure}

Some works study the knowledge boundary of text LLMs \cite{li2025refine, cheng2024can, zhang2024exploring, ren2023investigating} via prompt-based or SFT-based methods.
As of yet, there has been little research on the methodology for determining the knowledge boundaries of VLLMs. In practical applications, to answer VQA queries outside its knowledge scope, indiscriminately employing Retrieval Augmented Generation (RAG) techniques is often a viable solution. 
Although this approach has been proven to enhance the (V)LLMs' performance \cite{wang2021improving, lewis2020retrieval, chen-etal-2017-reading}, the comprehensive reliance on retrieval methods incurs significant latency due to the retrieval steps and the introduction of excessively long inputs \cite{chevalier2023adapting, zhang2024longcontextcompressionactivation, chen-etal-2024-improving-retrieval}.

To mitigate the dependence on retrieval for answering questions and simultaneously maintain, or improve, the performance benefits provided by retrieval, we aim to develop a method that can depict the knowledge boundary of a VLLM. 
In this paper, we employ a method with two variants to delineate the knowledge boundaries of a VLLM by fine-tuning a VLLM on data constructed based on sampling the responses of the VLLM. 


With the ability to depict the knowledge boundary of a VLLM, we then adopt RAG techniques to validate the accuracy of the identified boundary in various held-out datasets. 
We conduct experiments using a variety of VQA datasets, including three knowledge-intensive datasets, two non-knowledge-intensive datasets, and one mixed dataset. After determining whether a query falls within the knowledge boundary, we use RAG to assess the potential improvements the retrieved information provides to the queries falling out of the knowledge boundary. Our experimental results reveal that on a mixed dataset, which contains both non-knowledge-intensive and knowledge-intensive queries simulating real situations, our method outperforms the indiscriminative use of RAG (denoted ``All RAG'') and prompt-based baseline with 50.67\% retrieval reduction. The fine-tuned knowledge boundary model lowers the retrieving ratio on less knowledge-intensive data and obtains close or even better performance compared to the ``All RAG'' setting. 
% \textcolor{blue}{Besides, we show that the fine-tuned boundary VLLM could also be applied to other series of VLLMs as a plugin.}
Besides, we show that the fine-tuned VLLM for boundary identification for one VLLM can be used as a surrogate boundary identifier for other VLLMs.

To sum up, our contributions are as follows:
\begin{enumerate}[leftmargin=*,noitemsep, topsep=1pt]
    \item We propose a method with two variants that detects the knowledge boundary of a VLLM.
    \item Experimental results show that we maintain, or even improve, the performance of the VLLM on various types of data while lowering the ratio of using RAG, and our method outperforms the ``All RAG'' setting and other baselines on a dataset simulating real situations.
    \item We show that the knowledge boundary for one VLLM can be used as a surrogate boundary for other VLLMs, to reduce retrieval while maintaining or improving the performance.
\end{enumerate}


