\section{Related Work}
\label{sec:related work}

Early work on NF segmentation relied on semi-automated techniques. In 2004, Solomon \textit{et al.} \cite{solomon_automated_2004} introduced a thresholding-based method with manual initialization, which was prone to errors in iso-intense regions. 

In 2012, Weizman \textit{et al.} \cite{weizman_interactive_2012} proposed a method with manual initialization, followed by a segmentation based on tumor connectivity. It struggled with intensity similarities between PNFs and healthy tissues. A refinement in 2013 utilized a histogram-based tool requiring minimal user input \cite{weizman_pnist_2014}; however, it showed lower accuracy for small-volume tumors and diffusion of segmentation into high-signal-intensity structures adjacent to tumors.

A shift towards deep learning (DL) in NF segmentation was marked by Wu \textit{et al.} in 2020 \cite{wu_deep_2020}, who introduced the Deep Parametric Active Contour Model (Deep-PAC). It combined active contour models with DL features. Deep-PAC demonstrated superior performance over Fully Convolutional Networks (FCN) and U-Net. However, it required manual initialization and was computationally intensive. 

Advancements in fully automated methods were demonstrated by Ho \textit{et al.} in 2020 \cite{ho_image_2020}. They developed a multi-spectral neural network classifier that utilized diffusion-weighted imaging data. Although this method reduced intra- and inter-observer variability, it struggled with misclassifying normal anatomy as pathological. 

In 2021, Zhang \textit{et al.} \cite{zhang_dins_2022} proposed Deep Interactive Networks (DINs), using an Exponential Distance Transform to convert user interactions into guide maps. Compared to 3D U-Net and nnU-Net, DINs achieved significantly higher DSC, though it required user interaction.

In 2022, Wu \textit{et al.} introduced a Deep Hybrid Contextual Feature Network, integrated with a Multi-Gradient Active Contour model \cite{wu_dh-gac_2022}. The method consistently outperformed both U-Net and FCN, but it faced challenges due to intensity inhomogeneity and fuzzy boundaries, in addition to numerical instabilities during contour evolution. 

Despite progress in NF segmentation, existing methods remain sensitive to tumor appearance variability, are often restricted to 2D operations, or are limited to segmenting only a few tumors within a region of interest. Our approach addresses these limitations by integrating anatomical knowledge and radiomics in a fully automated multistage pipeline.