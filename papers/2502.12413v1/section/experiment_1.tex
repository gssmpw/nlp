\section{Experiments}


% \jq{graph more baseline: (gin, gcn, xgnn) erm, irm, vrex, ciga, refer to ciga}

% \jq{cv datasets: cmnist, gray cmnist, domainbed; baseline: erm, irm, vrex, scl }

% \jq{ablation study: 1) without random mask, without projector, without ucl,  how's it going. 2) different data augmentation methods}
We evaluate \ours and compare with IL methods on a range of tasks requiring OOD generalization. 
\ours provides generalization benefits and outperforms IL methods on a wide range of
tasks, including: 1) Colored MNIST (CMNIST) dataset, 2) graph dataset such as the synthetic Spurious-Motif dataset and drug discovery, 3) natural language datasets \jq{xx}.

\subsection{computer vision}
\input{tables/cmnist_test}
\zzx{need to be done, choose the appropriate settings and then add the contrastive loss as \ours}
\paragraph{Datasets.} We conduct a comprehensive evaluation of various methods across seven well-known domain generalization benchmarks, including the synthetic datasets ColoredMNIST \citep{irmv1} and RotatedMNIST \citep{rmnist}, as well as real multi-domain image classification datasets: VLCS \citep{vlcs}, PACS \citep{pacs}, OfficeHome \citep{officehome}, TerraIncognita \citep{TerraIncognita}, and DomainNet \citep{domainnet}. To ensure a fair comparison, we adopt the training and evaluation protocols established in DomainBed \citep{domainbed}, which encompass dataset splits, training iterations, and model selection criteria.

\paragraph{Baselines.} We conducted a thorough comparison of \ours, ERM, and various invariant learning algorithms, including causal methods that focus on learning invariance (IRM, VREx, EQRM), distributional robustness methods (GroupDRO), gradient matching techniques (Fish, Fishr), representation distribution matching methods (MMD, CORAL), and other variants (Mixup, MLDG).

% 这一段可以参考 domainbed 的论文来写 https://arxiv.org/pdf/2007.01434
\paragraph{Settings.} In line with the DomainBed setting, we fine-tune the pretrained ResNet-50 \citep{resnet} across all datasets. However, for Rotated MNIST and Colored MNIST, we opt for a smaller CNN architecture instead. To ensure a fair comparison, the methods are evaluated under identical conditions, including limiting hyperparameter configurations, using fixed backbone options, and applying consistent data augmentation techniques. Due to limited computational resources and the large search space, we restrict the random search experiments for hyperparameters to $x$ trials in order to optimize hyperparameters for each domain. 

\paragraph{Evaluation.} After carefully examining the model selection criteria proposed by \cite{domainbed}, we adopt $criteria$ for our experiments. \zzx{[which and why ?]} For the optimal parameters obtained through the sweep for each domain, we report the average and standard error of the results from $y$ runs with different random initializations.


\paragraph{Results.}
% 需要确定实验的setting，和评估策略：
    % - training-domain validation (all training models are pooled and a fraction of each of them is used as validation set)
    % - leave-one domain-out cross-validation (cross validation is performed using a different domain as validation, and the best models is retrained on all training domains)
    % - test domain validation set (a fraction of the test domain is used as validation set)

% Our evaluation uses a leave-one-domain-out approach, where each model is trained on all domains except one and tested on the excluded domain. The final model is selected based on its combined accuracy across all validation sets for the training domains.


% We validated our method on two synthetic datasets built on the MNIST handwritten digit classification dataset: , following the Domainbed setup. 
% \begin{itemize} 
%     \item \textbf{ColoredMNIST} contains 3 domains: \{+90\%, +80\%, --90\%\} with two labels. The percentages indicate the degree of correlation between color and label, with this correlation strength varying across different domains. The dataset comprises 70,000 images with a resolution of 2×28×28 and has 2 classes. 
%     \item \textbf{RotatedMNIST} consists of 6 domains: \{0, 15, 30, 45, 60, 75\} created by 15\% rotations ranging from 0 to 90 degrees. It includes 70,000 images with a resolution of 1×28×28 and has 10 classes. 
% \end{itemize}

% 这里有两个实验，感觉不太好说清楚逻辑诶
% \paragraph{Baselines.} We conducted comparative tests by applying \ours to ERM and traditional invariant learning methods such as IRM and VREx. We used ResNet as the backbone network, and the results are presented in Tables X and Y. More details can be found in the appendix.

% First, on the Colored MNIST dataset, we tested whether the model learned to ignore color by reversing this correlation during testing. In brief, if the model solely relies on color, it would achieve an accuracy of 10\% in testing, while a perfect "oracle" model that predicts shape accurately would achieve 75\%. We strictly followed the IRM implementation, applying \ours to existing methods (ERM, IRM, VREx, and Fishr). The multi-layer perceptron (MLP) and existing hyperparameters remained unchanged, and we added a two-layer nonlinear layer as a projection. The \ours loss weight was explored across \{0.01, 0.05, 0.1, 0.2\}, and the projection mask ratio varied over \{30\%, 50\%, 70\%\}, selecting the best results for comparison. All experiments are repeated with $5$ different random seeds of $\{1,2,3,4,5\}$. The mean and standard deviation of the accuracy rate are reported from the $5$ runs. The outcomes are presented in Table \ref{tab:cmnist}.

% Then, we conducted comparative tests by applying \ours to ERM and traditional invariant learning methods such as IRM and VREx. We used ResNet as the backbone network, and the results are presented in Tables X and Y. More details can be found in the appendix.


% dataset: ColorMINIST, grayMINIST, 



\subsection{graph}

\paragraph{Datasets.} For our experiments on graphs, we employed one synthetic dataset along with eight realistic datasets, including the Spurious-Motif datasets from \cite{dir}. These datasets consist of three graph classes, each with a designated subgraph serving as the ground-truth explanation, along with spurious correlations between the remaining graph components and the labels in the training data. The degree of these correlations is controlled by the parameter \( b \), with values of \( 0.33, 0.6, \) and \( 0.9 \). Furthermore, to examine our method in real-world scenarios characterized by more complex relationships and distribution shifts, we incorporated the DrugOOD dataset from AI-aided Drug Discovery, which includes Assay, Scaffold, and Size splits from the EC50 category (denoted as EC50-*) and the Ki category (denoted as Ki-*). Additionally, we included tests on the CMNIST-sp dataset, which consists of superpixel graphs derived from the ColoredMNIST dataset using the algorithm from \cite{understand_att}, featuring distribution shifts in node attributes and graph size, as well as on the sentiment analysis dataset Graph-SST2, which is formed by converting each text sequence from SST2 into a graph. More details can be found in Appendix x.x
\input{tables/spmotif}
\input{tables/drugood}
% Additionally, we converted the ColoredMNIST dataset from IRM [4] using Knyazev et al.'s algorithm [46] to introduce attribute shifts, and we split the Graph-SST dataset [122] to inject degree biases.

% For experiments, we employed one synthetic and eight realistic datasets, one comprising comprehensive topological structure information and the other focusing on the challenging real-world task of AI-aided drug affinity prediction.
% \begin{itemize}
%     \item \textbf{Spurious-Motif} is a synthetic dataset with three graph classes proposed by \cite{dir}. Each class contains a particular subgraph that can be regarded as the ground-truth explanation. Some spurious correlation between the rest graph components (other than the motifs) and the labels also exists in the training data. The degree of such correlation is controlled by b, and we include datasets with b = 0.33, 0.6 and 0.9.
%     \item \textbf{DrugOOD} is a systematic OOD benchmark for AI-aided drug discovery proposed by \cite{drugood}. The datasets focus on the task
%     of drug targeted binding affinity prediction for both macro-molecule and small-molecule. The DrugOOD datasets include splits using Assay, Scaffold, and Size from the EC50 category (denoted as EC50-*) and the Ki category (denoted as Ki-*).
%     \item \textbf{CMNIST-sp} is a graph classification dataset that contains distribution shifts in node attributes and graph size. Each image in ColoredMNIST is converted to a superpixel graph using the algorithm from \cite{understand_att}. Nodes with nonzero pixel values provide ground-truth explanations.
%     \item \textbf{Graph-SST2} is a sentiment analysis dataset, where each text sequence in SST2 is converted to a graph. Following the splits in \cite{dir}, this dataset contains degree shifts and no ground-truth explanation labels.
% \end{itemize}

\paragraph{Baselines.} We compared \ours with the current state-of-the-art Causality Inspired Invariant Graph Learning approaches, such as CIGA \citep{ciga}. Additionally, we conducted a comprehensive evaluation of \ours against Vanilla GNN and other SOTA interpretable GNN invariant learning methods, including GIB \citep{gib} and DIR \citep{dir}, to assess the effectiveness of the optimization objective in \ours. We also contrasted our method with SOTA out-of-distribution (OOD) objectives, such as IRM \citep{irmv1}, v-Rex \citep{v-rex}, and IB-IRM \citep{ib-irm}, using random environment partitions as described in [23]. Furthermore, we compared CIGA with EIIL \citep{eiil}, CNC and CNCP \citep{cnc}, all of which do not require environment labels. Notably, both CNC and CNCP utilize contrastive sampling strategies to address subpopulation shifts.

\paragraph{Evaluation.} Following the CIGA setting \citep{ciga}, we report classification accuracy for the Spurious-Motif, CMNIST-sp, and Graph-SST2 datasets, and ROC-AUC for the DrugOOD datasets. The evaluation is conducted five times with different random seeds (\{1, 2, 3, 4, 5\}), selecting models based on validation performance. Finally, we present the mean and standard deviation for each corresponding metric.

\paragraph{Settings.} For the DrugOOD, CMNIST-sp, and Graph-SST2 datasets, we utilized the GNN backbone GCN \citep{gcn}, while employing both GCN and GIN \citep{gin} with sum pooling to enhance expressive power for the Spurious-Motif datasets. Additionally, we incorporated XGNN, an interpretable GNN commonly used in graph OOD models, to extract the invariant subgraph \( G_c \) \citep{dir,gil,ciga}. More implementation details can be found in Appendix x.x.

\zzx{wired result, maybe is not reliable. compared with ciga's baseline, the erm, dir, irm and some other results had a big difference on cmnist-sp dataset}

\paragraph{Results.} The results are demonstrated in Table \ref{tab:main_table} and \ref{tab:spmotif}. 

As shown in Table \ref{tab:main_table}, \ours demonstrates better generalization ability than all baseline models on real-world datasets. 
% Specifically, in the MNIST-sp dataset, \ours surpasses CIGA by (19.80\% not sure) when using the GCN backbone. Additionally, in the ki-scaffold dataset, CIGA performs worse than ERM, while \ours achieves higher performance, confirming the effectiveness and robustness of \ours.

Then, Table \ref{tab:spmotif} shows that \ours significantly outperforms Vanilla GNN and the graph invariant learning method CIGA on the Spurious-Motif datasets (under GCN, GIN, and XGNN settings). Moreover, as the spurious bias increases, DivGIL's performance remains stable, while the baseline models tend to fail. For example, in the SPMotif-0.60 dataset, DivGIL improves performance from 65.45\% to 70.03\%, and in the SPMotif-0.90 dataset, from 59.64\% to 66.85\%.



% % We thoroughly compare \ours with Vallina GNN and Causality Inspired Invariant Graph Learning ( e.g. CIGA \citep{ciga} ).
% We adopted GNN backbone GCN \citep{gcn} and GIN \citep{gin}, selecting the sum pooling for better expressive power. 
% % In addition to the XGNN which is an interpretable GNN used in many graph OOD models to extract the invariant subgraph $G_c$~\citep{dir,gil,ciga}, we also include standard GNN to demonstrate our discussion in Sec \ref{sec: gil understand} and answer RQ3.
% In addition to the XGNN which is an interpretable GNN used in many graph OOD models to extract the invariant subgraph $G_c$~\citep{dir,gil,ciga}, we also include standard GNN to demonstrate our discussion in answer RQ3.
% The results are demonstrated in Table \ref{tab:main_table} and \ref{tab:spmotif}. 
% We describe more details in appendix.




% \input{iclr2024/tables/oversmoothing}
% \ref{tab:main_table}

% dataset
% baseline ( related baseline)
% setting: para
% results


\subsection{Natural language processing}
\input{tables/NLI}
