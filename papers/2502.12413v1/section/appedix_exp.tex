\section{Datasets}
\subsection{CMNIST}
Colored MNIST is a binary digit classification dataset introduced in IRM (\cite{irmv1}). Compared to the traditional
MNIST, it has 2 main differences. 
First, 0-4 and 5-9 digits are each collapsed into a single class, with a
25\% chance of label flipping. 
Second, digits are either colored red or green, with a strong correlation between label and
color in training. 
However, this correlation is reversed at test time. 
Specifically, in training, the model has access to two
domains E = $\{90\%, 80\%\}$: in the first domain, green digits have a 90\% chance of being in 5-9; in the second, this chance goes down to 80\%. 
In test, green digits have a 10\% chance of being in 5-9. Due to this modification in correlation, a model
should ideally ignore the color information and only rely on the digitsâ€™ shape: this would obtain a 75\% test accuracy.


\subsection{NLI}
The natural language inference (NLI) task involves determining the logical relationship between pairs of sentences, typically categorized as entailment, contradiction, or neutral.
In this task, a model is presented with a premise sentence and a hypothesis sentence, and it must infer how the hypothesis relates to the premise as seen in Table~\ref{tab: app_snli} and Table~\ref{tab: app_mnli}. 
NLI is crucial in natural language understanding as it tests a model's ability to comprehend and reason about language, making it a fundamental benchmark for evaluating the performance of language models and their ability to capture semantic relationships and contextual information within the text.

We provide more details about the motivation and construction method of the datasets used in our experiments. Statistics of the datasets are presented in Table~\ref{tab:app_nli}.
We use about 8,000 examples in the train set from the SNLI~\cite{SNLI}, from the Image Captions from the Flickr30k Corpus domains.
We selected 1,000 examples from the validation-matched set of the MNLI dataset~\citep{MNLI}, sourced from the Fiction, Government, Slate, Telephone, and Travel domains. Additionally, we chose another 1,000 examples from the validation-matched set of the MNLI dataset, taken from the 9/11, Face-to-Face, Letters, OUP, and Verbatim domains, to form our out-of-domain (OOD) test set.
Examples of SNLI and MNLI are shown in Table~\ref{tab: app_snli} and Table~\ref{tab: app_mnli}.

\begin{table}[ht]
\centering
\caption{Statistics of our constructed OOD NLI Dataset.}
\label{tab:app_nli}
\resizebox{\textwidth}{!}{
\begin{tabular}{lccl m{0.4\textwidth} c}
\toprule
\textbf{Split} & \textbf{Genre} & \textbf{Examples} & \textbf{Partition} & \textbf{Data Domain} & \textbf{Metrics} \\
\midrule
\multirow{1}{*}{Train set} & SNLI & 7992 & train & \textsc{Image Captions from the Flickr30k Corpus} & ACC \\
\hline
\multirow{3}{*}{Test set} & SNLI & 991 & validation & \textsc{Image Captions from the Flickr30k Corpus} & ACC \\
    & \multirow{2}{*}{MNLI} & 1000 & validation-matched & \textsc{Fiction, Government, Slate, Telephone, Travel} & ACC \\
    & & 1000 & validation-mismatched & \textsc{9/11, Face-to-Face, Letters, OUP, Verbatim} & ACC \\
\bottomrule
\end{tabular}
}
\end{table}


\begin{table}[t]
\centering
\caption{NLI dataset samples from SNLI (IID).}
\label{tab: app_snli}
\resizebox{\textwidth}{!}{
\begin{tabular}{m{0.6\textwidth} m{0.3\textwidth} c}
\toprule
Premise & Hypothesis & Label \\
\toprule
\vfill Two men holding their mouths open. \vfill & \vfill Two men with mouths agape. \vfill & \textsc{entailment} \\
\vfill Trying very hard not to blend any of the yellow paint into the white. \vfill & \vfill Someone is painting a house. \vfill & \textsc{neutral} \\
\vfill A man on a small 4 wheeled vehicle is flying through the air. \vfill & \vfill The man is on a bike. \vfill & \textsc{contradiction} \\
\vfill Two power walkers walking beside one another in a race. \vfill & \vfill Two people in a park walking \vfill & \textsc{neutral} \\
\vfill Women standing at a podium with a crowd and building in the background. & \vfill woman stands at podium & \textsc{entailment} \\
\bottomrule
\end{tabular}
}
\end{table}


\begin{table}[t]
\centering
\caption{MNLI dataset samples from the validation-matched (above) and validation-mismatched (below) subsets (OOD).}
\label{tab: app_mnli}
\resizebox{\textwidth}{!}{
\begin{tabular}{m{0.5\textwidth} m{0.4\textwidth} c}
\toprule
Premise & Hypothesis & Label \\
\toprule
\vfill pretty good newspaper uh-huh \vfill & \vfill I think this is a decent newspaper. \vfill & \textsc{entailment} \\
\vfill Massive tidal waves swept over Crete, and other parts of the Mediterranean, smashing buildings and drowning many thousands of people. \vfill & \vfill The waves came with no warning to the inhabitants. \vfill & \textsc{neutral} \\
\vfill For such a governmentwide review, an entrance conference is generally held with applicable central agencies, such as the Office of Management and Budget (OMB) or the Office of Personnel Management. & \vfill An entrance conference is held with specialized agencies.  & \textsc{contradiction} \\
\midrule
\vfill As Figure 6.6 shows, the safety stock needed to achieve a given customer service level is proportional to the standard deviation of the demand forecast. \vfill & \vfill Figure 6.6 shows the safety stock needed to achieve a given customer service level. \vfill & \textsc{entailment} \\
\vfill Some of Bin Ladin's close comrades were more peers than subordinates. \vfill & \vfill There were three people who could be considered peers of Bin Ladin. \vfill & \textsc{neutral} \\
\vfill Nothing except knowing that you are helping to protect the Earth's precious natural resources. & \vfill Everything, except knowing that you are helping to protect Earth's natural resources. & \textsc{contradiction} \\
\bottomrule
\end{tabular}
}
\end{table}



\subsection{Graph}
We provide more details about the motivation and construction method of the datasets used in our experiments. Statistics of the datasets are presented in Table~\ref{tab: app_graph_data}.
\paragraph{Spurious-Motif}
We construct 3-class synthetic datasets based on BAMotif following~\cite{dir}, where the model needs to tell which one of three motifs (House, Cycle, Crane) the graph contains. 
For each dataset, we generate 3,000 graphs for each class in the training set, and 1,000 graphs for each class in the validation set and testing set, respectively.
We introduce the bias based on FIIF, where the motif and one of the three base graphs (Tree, Ladder, Wheel) are artificially
(spuriously) correlated with a probability of various biases, and equally correlated with the other two. 
Specifically, given a predefined bias b, the probability of a specific motif (e.g., House) and a
specific base graph (Tree) will co-occur is $b$ while for the others is $(1-b)/2$ (e.g., House-Ladder, House-Wheel). 
We use random node features in order to study the influences of structure level shifts. 

\paragraph{CMNIST-sp} To study the effects of PIIF shifts, we select the ColoredMNIST dataset created
in~\cite{irmv1}. 
We convert the ColoredMNIST into graphs using the superpixel algorithm introduced
by~\cite{understand_att} .

\paragraph{Graph-SST2}
Inspired by the data splits generation for studying distribution shifts on graph sizes, we
split the data curated from sentiment graph data [84], that converts sentiment sentence classification
datasets Graph-SST2~\citep{graph-sst2} into graphs, where node features are generated using BERT~\citep{bert} and the edges are parsed by~\cite{biaffine}. 
Our splits are created according to the averaged degrees of each graph. 
Specifically, we assign the graphs as follows: Those that have smaller or equal to 50-th percentile while smaller than 80-th percentile are assigned to the validation set, and the left are
assigned to test set.

\paragraph{DrugOOD datasets}To evaluate the OOD performance in realistic scenarios with realistic
distribution shifts, we also include three datasets from DrugOOD benchmark~\citep{drugood}. 
DrugOOD is a systematic OOD benchmark for AI-aided drug discovery, focusing on the task
of drug target binding affinity prediction for both macromolecule (protein target) and smallmolecule (drug compound). 
The molecule data and the notations are curated from realistic ChEMBL database~\citep{chembl}. Complicated distribution shifts can happen on different assays, scaffolds and molecule sizes. 
In particular, we select DrugOOD-lbap-core-ec50-assay,
DrugOOD-lbap-core-ec50-scaffold, DrugOOD-lbap-core-ec50-size,
DrugOOD-lbap-core-ki-assay, DrugOOD-lbap-core-ki-scaffold, and
DrugOOD-lbap-core-ki-size, from the task of Ligand Based Affinity Prediction which
uses ic50 measurement type and contains core level annotation noises. 
We directly use the data
files provided by~\cite{drugood}. 
% For more details, we refer interested readers to \cite{drugood}.

\begin{table}[ht]
\centering
\caption{Graph dataset details. The number of nodes and edges are respectively taking average among all graphs.}
\label{tab: app_graph_data}
\begin{tabular}{l *{7}{c}}
\toprule
Dataset & Training & Validation & Testing & Classes & Nodes & Edges & Metrics \\
\midrule
SPMOTIF & 9,000 & 3,000 & 3,000 & 3 & 44.96 & 65.67 & ACC \\
CMNIST-SP & 40,000 & 5,000 & 15,000 & 2 & 56.90 & 373.85 & ACC \\
Graph-SST2 & 24,881 & 7,004 & 12,893 & 2 & 10.20 & 18.40 & ACC \\
EC50-Assay & 4,978 & 2,761 & 2,725 & 2 & 40.89 & 87.18 & ROC-AUC \\
EC50-Scaffold & 2,743 & 2,723 & 2,762 & 2 & 35.54 & 75.56 & ROC-AUC \\
EC50-Size & 5,189 & 2,495 & 2,505 & 2 & 35.12 & 75.30 & ROC-AUC \\
Ki-Assay & 8,490 & 4,741 & 4,720 & 2 & 32.66 & 71.38 & ROC-AUC \\
Ki-Scaffold & 5,389 & 4,805 & 4,463 & 2 & 29.96 & 65.11 & ROC-AUC \\
Ki-Size & 8,605 & 4,486 & 4,558 & 2 & 30.35 & 66.49 & ROC-AUC \\
\bottomrule
\end{tabular}
\end{table}

\section{Implement Details}
During the experiments, we do not tune the hyperparameters exhaustively while following the
common recipes for optimizing the models. Details are as follows.
We will publish our code when the paper is accepted.

\subsection{CMNIST Implements}
In the experimental setup in Section~\ref{sec: exp cmnist}, the network is a 3 layers MLP with ReLu activation, optimized with Adam (\cite{adam}). 
IRM selected the following hyperparameters by random search over 50 trials: hidden dimension of 390, l2 regularizer weight of 0.00110794568, learning rate of 0.0004898536566546834, penalty anneal iters (or warmup iter) of 190, penalty weight ($\lambda$) of 91257.18613115903, 501 epochs and batch size 25,000 (half of the dataset size). 
For the implementation of the invariant losses(IRM, VREx and Fishr), we strictly keep the same hyperparameters values in our implementation and the code is almost unchanged from
\url{https://github.com/alexrame/fishr}.
To account for the varying degrees of over-invariance introduced by different IL methods, we performed a straightforward search over \(\beta\) values of \{0.01, 0.05, 0.1, 0.2\} and projection mask probabilities of \{0.3, 0.5, 0.7\}, while keeping the random augmentation mask probability fixed at 0.2.

\subsection{NLI Implements}
We employed a pretrained GPT-2 model with a randomly initialized classification head. 
We set the maximum token length to 64 and trained the model for 5 epochs using the AdamW optimizer. The learning rate was configured at 2e-5, with a weight decay of 0.01 and a linear learning rate scheduler. 
We used a training batch size of 32.
To optimize our model, we explored various combinations of the invariant loss and unsupervised loss weights for \( \lambda \) and \( \beta \), choosing the best from the \{0, 0.1, 0.3, 0.5, 0.7, 1.0\} according to the validation set.
Additionally, we fixed the projection mask probability at 0.7 and reported the results for the best-performing configuration.

\subsection{Graph Implements}
For a fair comparison, \ours uses the same GNN architecture for GNN encoders as the baseline methods. We use the GCN backbone and the sum pooling in Table~\ref{tab:main_table}.
By default, we fix the temperature to be 1 in the unsupervised contrastive loss, and merely search the penalty weight of the contrastive loss from $\{0.1, 0.2, 0.5, 1, 2\}$ according to the validation performances. 
We select the best of the random mask percentage $p$ from the $\{0.2,0.3,0.5,0.7\}$ according to the validation performances.
For the implementation of graph data augmentation, we use the tool from~\cite{graphCL}. 
We select the best percentage $p_2$ of node dropping, edge removing, and subgraph extraction from the $\{0.05, 0.1, 0.15, 0.2\}$ according to the validation performances to create the positive pair and keep $p_1=0$ representing the sample itself. 
For the implementation of our baselines, we take the code almost unchanged from
\url{https://github.com/LFhase/CIGA}.
% \subsection{Discussion on Invariant Loss}
% \label{sec: diss il loss}
% Many IL methods aim to limit the changes of the model, ensuring consistent adjustment rates across all environments~\cite{irmv1,v-rex, fishr, cnc}.
% For example, IRMv1 employs a gradient-based penalty $\mathcal{L}_{il}$ as follows:
% \(
%  \mathcal{L}_{irm}= \Sigma_{s \in \epsilon_{tr}} \| \triangledown_{w | w=1.0} \mathcal{L}_{pred}^s(f)\|\,.
% \)
% Vrex takes the variance of the loss across different environments as the penalty loss as
% \( \mathcal{L}_{vrex}= Var(\mathcal{L}_{pred}^1(f),\mathcal{L}_{pred}^2(f),\cdots,\mathcal{L}_{pred}^n(f))\). 
% To get rid of the environment labels, other methods also adopt the loss of supervised contrastive learning as $\mathcal{L}_{il}$, like CNC~\cite{cnc} and CIGA~\cite{ciga}, using different heuristic strategies to choose the positive and negative samples.
\section{More Ablation Study}
\tmlr{\subsection{Abltions on Random Masking}}

\tmlr{We introduced a random masking mechanism to overcome the issue of over-invariance, which differs from the traditional dropout method. Unlike dropout, which randomly drops out dimensions independently, we observed that features tend to diversify in the earlier dimensions and become more invariant in the later dimensions. Therefore, we promote the diversity of characteristics by setting the first p dimensions of the contrastive learning feature space to 0. This approach not only alleviates the over-invariance problem but also enhances flexibility in specific dimensions of the feature space.}

\tmlr{
To validate the effectiveness of this mechanism, we conducted ablation experiments on the CMNIST dataset. The experimental results showed that the model using the random masking method outperforms the model using traditional dropout in terms of out-of-distribution generalization. As shown in Table~\ref{tab:dropout_ablation}, the random masking mechanism improves the robustness of the model, particularly in the face of complex data distributions, effectively mitigating over-invariance and improving the overall performance of the model.}

\begin{table}[ht]
    \centering
    \caption{Comparison of Random Masking and Dropout on the CMNIST Dataset.}
    \label{tab:dropout_ablation}
    \begin{tabular}{lcc}
    \hline
    \textbf{Method} & \textbf{Train} & \textbf{Test} \\
    \hline
    IRM & 71.47 $\pm$ 1.18 & 65.30 $\pm$ 1.09 \\
    \rowcolor{gray!5}+ \ours(dropout) & 70.65 $\pm$ 0.54 & 66.19 $\pm$ 1.78 \\
    \rowcolor{gray!15}+ \ours(random masking) & 70.93 $\pm$ 0.29 & 66.40 $\pm$ 1.39 \\
    \hline
    VERx & 72.14 $\pm$ 1.49 & 67.05 $\pm$ 0.84 \\
    \rowcolor{gray!5}+ \ours(dropout) & 72.54 $\pm$ 1.72 & 66.73 $\pm$ 1.34 \\
    \rowcolor{gray!15}+ \ours(random masking) & 72.67 $\pm$ 0.93 & 67.50 $\pm$ 1.45 \\
    \hline
    Fishr & 71.34 $\pm$ 1.27 & 69.18 $\pm$ 0.80 \\
    \rowcolor{gray!5}+ \ours(dropout) & 71.36 $\pm$ 1.41 & 69.20 $\pm$ 0.77 \\
    \rowcolor{gray!15}+ \ours(random masking) & 71.27 $\pm$ 1.36 & 69.25 $\pm$ 0.81 \\
    \hline
    \end{tabular}
\end{table}

\tmlr{\subsection{Interpretation Visualization of Over-invariance on Graph}
\label{sec:interpret_visualize_appdx}
To demonstrate the over-invariance issue on the real datasets, we use the interpretable GNN architecture (XGNN) to extract $G_c$, it brings an additional demonstration that over-invariance risk occurs in the real-graph datasets, which may facilitate human understanding in practice.
}


\tmlr{
 We provide some visualizations of invariant subgraphs learned by~\cite{ciga}.
 First, we illustrate the examples in SPMotif under the biases of $0.6$ and $0.9$ shown in Figure~\ref{fig:spmotif_b6_appdx} and Figure~\ref{fig:spmotif_b9_appdx}.
 We use pink to color the ground truth nodes in $G_c$, and denote the relative attention strength with edge color intensities.
We also provide some interpretation visualization examples in DrugOOD datasets shown in Figure~\ref{fig:assay_viz_act_appdx} to Figure~\ref{fig:assay_viz_inact_appdx}.
We use the edge color intensities to denote the attention of models that pay to the corresponding edge.
}

\tmlr{We have two observations based on the above visualization examples. 1) Invariant learning methods tend to extract the subgraph of the ground truth invariant subgraph(Figure~\ref{fig:spmotif_b6_appdx},~\ref{fig:spmotif_b9_appdx},~\ref{fig:assay_viz_act_appdx},~\ref{fig:assay_viz_inact_appdx}), thus verifying the over-invariance issue. 2) When confronted with multiple invariant subgraphs (Figure~\ref{fig:assay_viz_act_appdx},~\ref{fig:assay_viz_inact_appdx}), these learning methods usually focus on only one of them rather than considering all the invariant subgraphs. 
In the fields of computer vision and natural language processing, we do not visualize them here due to the ambiguous definitions and interpretations of invariance and spurious effects.
The above two observations aligned with our synthetics experiments in Figure~\ref{fig:over_invariance} measured by the strength.   }

% Some interesting patterns can be found in the molecules shared with the same label, which could provide insights to the domain experts when developing new drugs. We believe that, because of its superior OOD generalization performance on graphs, $G_c$ can have high potential to push forward the developments of AI-Assisted Drug Discovery, and enrich the AI tools for facilitating the fundamental practice of science in the future.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif6_568_label0.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif6_1302_label1.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif6_2153_label2.pdf}
    \end{subfigure}
    \caption{Over-invariance visualizations of examples from SPMotif-Struc under bias$=0.6$ (\cite{ciga}).}
    \label{fig:spmotif_b6_appdx}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif9_118_label0.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif9_2385_label1.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/SPMotif9_5186_label2.pdf}
    \end{subfigure}
    \caption{Over-invariance visualizations of examples from SPMotif-Struc under bias$=0.9$ (\cite{ciga}).}
    \label{fig:spmotif_b9_appdx}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_4802_label1.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_3149_label1.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_2131_label1.pdf}
    \end{subfigure}
    \caption{Over-invariance visualizations of activate examples ($y=1$) from DrugOOD-Assay (\cite{ciga}).}
    \label{fig:assay_viz_act_appdx}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_13430_label0.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_7387_label0.pdf}
    \end{subfigure}
    \begin{subfigure}{0.31\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/drugood_lbap_core_ec50_assay_5256_label0.pdf}
    \end{subfigure}
    \caption{Over-invariance visualizations of inactivate examples ($y=0$) from DrugOOD-Assay (\cite{ciga}).}
    \label{fig:assay_viz_inact_appdx}
\end{figure}

\section{Software and Hardware}
We implement our methods with PyTorch~\citep{pytorch} and PyTorch Geometric~\citep{pytorch_geometric}. We ran our experiments
on Linux Servers installed with 3090 graphics cards and CUDA 10.2.

% \section{Theorem}

% \begin{proposition}[Informal]
% % Define the linear model as $f_{\mathbf{\Theta}}=\mathbf{Wx}+\mathbf{b}$, where $\mathbf{\Theta} $ as the concatenated parameter $[\mathbf{W}\ \mathbf{b}]$.
% % Let \( \mathbf{\Theta}^{*} = [\mathbf{W}^{*}, \mathbf{b}^{*}] \) be the minimizer of the invariant loss \( L_{il} \) as follows: 
% % \[\mathbf{\Theta}^{*} \in \arg\min_{\mathbf{\Theta}} L_{il}(\mathbf{\Theta}).\]
% With high probability, there exists a subset of the invariant data \( x_c \), denoted as the over-invariant data \(o_c\), where the strength of the rest part of the invariant data $(x_c \backslash o_c)$ is 0: 
% \[\text{strength} (x_c \backslash o_c) = ||{\Phi}^{*} (x_c \backslash o_c) ||_2 = 0.\]
% Thus, \textbf{over-invariance} occurs at test time.

% \end{proposition}

% \begin{proposition}[Informal]
% Define the linear model as $f_{\mathbf{\Theta}}=\mathbf{Wx}+\mathbf{b}$, where $\mathbf{\Theta} $ as the concatenated parameter $[\mathbf{W}\ \mathbf{b}]$.
% Let \( \mathbf{\Theta}^{*} = [\mathbf{W}^{*}, \mathbf{b}^{*}] \) be the minimizer of \ours in~\eqref{eq: diverse_loss}.
% For any subset of the invariant data \( x_c \), denoted as \(o_s\), the strength of the rest part of the invariant data $(x_c \backslash s_c)$ will not be 0: 
% \[\text{strength} (x_c \backslash o_s) = ||{\Phi}^{*} (x_c \backslash o_s) ||_2 \neq 0, \,  o_s \subset x_c.\]
% Thus, \ours mitigates the \textbf{over-invariance} issue at test time.

% \end{proposition}

