\section{Introduction}
% ood
% Modern machine learning methodologies have demonstrated their superior proficiency across various domains such as natural language processing, computer vision, graph neural networks, etc. 
% these techniques
Modern machine learning methods have \tmlr{achieved great success} across various domains such as natural language processing, computer vision, and graph neural networks~\citep{gcn,bert,gin}.
However, these methods heavily rely on the assumption that training and testing data come from \tmlr{the independent and identically distribution(I.I.Dassumption)}~\citep{liu2023outofdistribution, peters2016casual}.
% , which is often violated in the real world.
When faced with out-of-distribution (OOD) data, almost all of these methods
generalize poorly since they are prone to inherit data biases from the train set as shortcuts~\citep{wilds,domainbed,good_bench,drugood,xie2024enhancing}.
% \cqg{There lacks smooth logical connections of those two sub-sentence.}.
% However, it often violated in real world scenarios~\cite{wilds, drugood}.
% However, when confronted with out-of-distribution (OOD) data, which is common in real scenarios~\cite{wilds, drugood}, these methods often exhibit poor generalization performance due to inheriting data biases as shortcut.
% invariant
% , which aims to learn prediction mechanisms that are strictly stable given multiple environments

A canonical method for the OOD generalization is invariant learning (IL) based on the invariant principle from causality~\citep{irmv1,ib-irm,inv_principle,v-rex,yao2024empowering,chen2024interpretable,wang2024sober,xu2025brainood}.
As seen in Figure~\ref{fig:scm}, the basic assumption of IL is that each data is determined by the invariant feature $Z^c$ and the spurious feature $Z^s$ and only learning the invariant features can achieve the success of OOD generalization. 
% (only related to the labels)
Specially, the two variables are unobservable and the invariant one is stable across environments ($Z^c\perp S | C $) while the spurious one changes with environments (S).
The key challenge of IL is how to learn the invariant features while alleviating the spurious features.
% To extract the invariant one from the original features, 
To achieve this goal, various IL methods add regularization to the original Empirical Risk Minimization (ERM) loss, 
% such as gradients-induced series: 
for example, IRMv1, VREx, and Fishr~\citep{v-rex,fishr} introduce gradients-induced losses and EIIL, EILLS, and CIGA ~\citep{eiil,Fan2023EnvironmentIL,ciga} adapt the environment-induced penalties.
% series: 
% \cqg{It is unusual to introduce related works like this. Maybe like "There are two main streams of works. xxx xxx introduce gradients-induced loss...."}.
Others~\citep{inv_principle,ib-irm,dir,groupdro} apply complex invariant strategies during the training process to extract invariance.
% Recent works~\citep{lin2023spurious,xie2024enhancing} also reveal that % not only focusing on the invariant features but instead 
% learning the useful spurious features from different train environments can also enhance the OOD generalization performance in the test set, although the underlying reasons remain unclear.
% % \cqg{invariant feature?} 
% % However, they 
% This phenomenon leads us to rethink the following question:
% \begin{center}
%     \textit{Is the invariant learning objective really suitable for out-of-distribution generalization?}
% \end{center}
% \begin{figure}[t]
% 	\centering	\includegraphics[width=0.25\textwidth]{tmlr-style-file-main/images/spurious_and_invariant_feature.png}
% 	\caption{Structural causal model of invariant and spurious features.}
% 	\label{fig:scm}
% \end{figure}

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.24\textwidth}
        \centering
\includegraphics[width=\linewidth]{images/spurious_and_invariant_feature.png}
	\caption{Structural causal model.}
	\label{fig:scm}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.73\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/divil-graph.pdf}
        \caption{Illustration of the over-invariance issue in the graph field.}
        \label{fig:over-invariance illu}
    \end{subfigure}
    \caption{(a) shows the structural causal model of invariant and spurious features in relation to the invariance and the environments. (b) shows the over-invariance issue in the graph field. Each graph $G$ consists of the invariant subgraph $G_c$ (star, house) and the spurious subgraph $G_s$ (wheel, tree). Previous IL methods alleviate spurious subgraphs while sacrificing important details of invariant subgraphs (The circle is the invariant subgraph $\hat{G}_c$ identified by the model.), causing the over-invariance issue.
    % \cqg{From my perspective, it will be clearer to only encircle part of the invariance feature than to also encircle the environment feature.}
    }
    \label{fig:twosubs}
\end{figure}

% To answer this question, our analysis focuses on two cornerstone invariant learning techniques, IRM~\cite{irmv1} and VREx~\cite{v-rex}.
% over-invariant
% To answer this question, we need to delve deeply into the gap between the theoretically invariant principle and the practical invariant learning methods. 
% The key of the invariant principle is the featurizer $w$ which requires $w$ is Bayes Optimal across all environments $e$.
% Surprisingly, we found a \textit{over-invariance phenomenon}: the models trained on the IL loss easily collapse the invariant feature while mitigating spurious correlations. \jq{figure}
% we find that applying the invariance constraints to representation learning in order to prevent any spurious feature learning can easily lead to a too conservative representation, namely .
% We find that invariant learning mitigates spurious correlations but may easily collapse the invariant feature.
% To answer this question, we need to rethink the definition of the invariant features. 
% \cqg{I think you should add these definition-like related work before you introduce the question.}
% Invariant risk minimization (IRM)~\cite{irmv1} first defines 
However, the rigorous invariance definition~\citep{irmv1} must (1) be Bayesian optimal across all environments and (2) completely abandon the spurious feature, which gives a strong restriction to the representation learning.
Despite improvement in performance on the test set, most IL methods perform poorly compared to ERM on the train set~\citep{eiil,irm_aistats,v-rex}.
Furthermore, extracting invariant features requires the train data from different environments which are often artificially divided or typically absent in real-world scenarios.
% \cqg{What does IRM mean?} 
Some studies~\citep{zin,kamath2021does} have proved that in cases with insufficient environments in the train set, IL fails to distinguish the invariance and the spurious correlation.
This reveals two critical dilemmas of IL to capture the invariance: while beneficial for OOD generalization, its over-regularization limits the representation and requires an infinite number of diverse environments.
% \cqg{It looks hard to understand} 

In this paper,  
% by the models (fig \ref{fig:over_invariance}).
we highlight that during the pursuit of invariance, current IL methods tend to use fewer features to avoid any risk of violating invariance, referred to as the \textit{over-invariance}.
Figure~\ref{fig:over-invariance illu} demonstrates an example of over-invariance in the graph field where IL predicts the label only by the small subgraph of the invariant subgraph $G_c$ and ignores other part of the graph.
However, this may come at the cost of losing enough details and diversity of the invariant feature despite alleviating the spurious correlation, which also degrades the out-of-distribution generalization.
Furthermore, we rigorously define the over-invariance and conduct simulation experiments on two classic IL methods, IRM~\citep{irmv1} and VREx~\citep{v-rex}, verifying the existence of the over-invariance.
% In this paper, we first present  that applying the constraints from IL in order to prevent the spurious feature can easily lead to the more conservative invariant features.
% We give the definition of the over-invaraint features and conduct the simulation experiments on two cornerstone IL techniques, IRM~\cite{irmv1} and VREx~\cite{v-rex} in Section~\ref{sec: understand}.
% Therefore, release the constrains 
% methods/experiments

Built upon our observation, we propose a simple and novel method\oursfull (\ours) with a focus on promoting richer and more diverse invariance. 
Since the quality of the invariant feature plays an essential role in IL, we consider striking a balance between the strong regularizers to alleviate spurious correlations and the detailed capture of the invariant features.
% Inspired by the contrastive learning~\cite{DC_leCun}, 
%  principle that utilizes both invariance and diversity objectives for balanced representation learning~\cite{DC_leCun}, we also incorporate it into invariant learning methods with a particular focus on resolving over-invariance. 
% Specifically,
We combine invariant penalties and unsupervised contrastive learning (UCL) with random data augmentation to extract domain-wise and sample-wise features, eliminating the reliance on the environments.
% \cqg{what's this propose for the paper motivation?}
% Meanwhile, to overcome the loss of information in the diversity of invariant feature extraction step, we propose to utilize the full graph to retain the most information, and find that it delivers better performance in general. 
% from the contrastive learning literature 
Meanwhile, we mask the front part of the UCL feature as zero to reduce overfitting to spurious shortcuts~\citep{DC_leCun}.
% , promoting diversity when learning domain-wise feature invariance.
% \cqg{I think we should not talk about the verb like borrow inspire. $\rightarrow$ We do what for how.}. 
% Overall, we name our method \oursfull (\ours) \cqg{Put it into first before module introduction for better overall scaning} with a focus on 
We evaluate \ours on an extensive set of $12$ benchmark datasets across natural language, computer vision, and graph domains with various distribution shifts, including a challenging setting from AI-aided drug discovery~\citep{drugood}. 
We demonstrate that \ours can significantly enhance the performance of invariant learning methods, thereby reinforcing our insight of the over-invariance issue in invariant learning.
% Meanwhile, we also validate that \ours~ can also help alleviate the over-invariance issue while maintaining the spurious feature alleviation, 
Our main contributions are:
\begin{itemize}
    \item We discover and theoretically define the over-invariance phenomenon,  \textit{i.e.,} the loss of important details in invariance when alleviating the spurious features, which exists in almost all of the previous IL methods. 
    \item We propose \oursfull (\ours), combining both invariant constraints and unsupervised contrastive learning with randomly masking mechanism to promote richer and more diverse invariance.
    % \item We propose the the diverse invariance learning (\ours) combining the self-supervised and supervised contrastive learning to enhance the invariant feature diversity.  
    \item Experiments conducted on 12 benchmarks, 4 different invariant learning methods across 3 modalities (graphs, vision, and natural language) demonstrate that \tmlr{\ours~effectively enhances the out-of-distribution generalization performance, verifying the over-invariance insight.}
    % \item Experiments show that our proposed methods improve the OOD performance on xx datasets across various domains.
\end{itemize}