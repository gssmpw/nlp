[
  {
    "index": 0,
    "papers": [
      {
        "key": "kaplan2020scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhai2022scaling",
        "author": "Xiaohua Zhai and\nAlexander Kolesnikov and\nNeil Houlsby and\nLucas Beyer",
        "title": "Scaling Vision Transformers"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ma2024scaling",
        "author": "Ma, Qian and Mao, Haitao and Liu, Jingzhe and Zhang, Zhehua and Feng, Chunlin and Song, Yu and Shao, Yihan and Ma, Yao",
        "title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "alabdulmohsin2022scaling",
        "author": "Alabdulmohsin, Ibrahim M and Neyshabur, Behnam and Zhai, Xiaohua",
        "title": "Revisiting Neural Scaling Laws in Language and Vision"
      },
      {
        "key": "henighan2020scaling",
        "author": "Henighan, Tom and Kaplan, Jared and Katz, Maxwell and Levskaya, Anselm and McCandlish, Sam and Stuhlmuller, Andreas and Gray, Scott and Amodei, Dario",
        "title": "Scaling laws for autoregressive generative modeling"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hernandez2021scaling",
        "author": "Hernandez, Danny and Kaplan, Jared and Henighan, Tom and McCandlish, Sam",
        "title": "Scaling laws for transfer"
      },
      {
        "key": "tay2021scale",
        "author": "Yi Tay and\nMostafa Dehghani and\nJinfeng Rao and\nWilliam Fedus and\nSamira Abnar and\nHyung Won Chung and\nSharan Narang and\nDani Yogatama and\nAshish Vaswani and\nDonald Metzler",
        "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "tao2024scaling",
        "author": "Tao, Chaofan and Liu, Qian and Dou, Longxu and Muennighoff, Niklas and Wan, Zhongwei and Luo, Ping and Lin, Min and Wong, Ngai",
        "title": "Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "shao2024scaling",
        "author": "Shao, Rulin and He, Jacqueline and Asai, Akari and Shi, Weijia and Dettmers, Tim and Min, Sewon and Zettlemoyer, Luke and Koh, Pang Wei",
        "title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lingle2024hyperparameters",
        "author": "Lingle, Lucas",
        "title": "A Large-Scale Exploration of $\\mu$-Transfer"
      },
      {
        "key": "yang2022hyperparameters",
        "author": "Yang, Greg and Hu, Edward J and Babuschkin, Igor and Sidor, Szymon and Liu, Xiaodong and Farhi, David and Ryder, Nick and Pachocki, Jakub and Chen, Weizhu and Gao, Jianfeng",
        "title": "Tensor programs v: Tuning large neural networks via zero-shot hyperparameter transfer"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wei2022emergent",
        "author": "Wei, Jason and Tay, Yi and Bommasani, Rishi and others",
        "title": "Emergent abilities of large language models"
      },
      {
        "key": "schaeffer2024emergent",
        "author": "Rylan Schaeffer and\nBrando Miranda and\nSanmi Koyejo",
        "title": "Are Emergent Abilities of Large Language Models a Mirage?"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen2024scaling",
        "author": "Chen, Yangyi and Huang, Binxuan and Gao, Yifan and Wang, Zhengyang and Yang, Jingfeng and Ji, Heng",
        "title": "Scaling Laws for Predicting Downstream Performance in LLMs"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "hu2023predicting",
        "author": "Hu, Shengding and Liu, Xin and Han, Xu and Zhang, Xinrong and He, Chaoqun and Zhao, Weilin and Lin, Yankai and Ding, Ning and Ou, Zebin and Zeng, Guoyang and others",
        "title": "Predicting Emergent Abilities with Infinite Resolution Evaluation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2024scaling",
        "author": "Chen, Yangyi and Huang, Binxuan and Gao, Yifan and Wang, Zhengyang and Yang, Jingfeng and Ji, Heng",
        "title": "Scaling Laws for Predicting Downstream Performance in LLMs"
      },
      {
        "key": "gadre2024language",
        "author": "Gadre, Samir Yitzhak and Smyrnis, Georgios and Shankar, Vaishaal and Gururangan, Suchin and Wortsman, Mitchell and Shao, Rulin and Mercat, Jean and Fang, Alex and Li, Jeffrey and Keh, Sedrick and others",
        "title": "Language models scale reliably with over-training and on downstream tasks"
      },
      {
        "key": "du2024understanding",
        "author": "Du, Zhengxiao and Zeng, Aohan and Dong, Yuxiao and Tang, Jie",
        "title": "Understanding emergent abilities of language models from the loss perspective"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "xiao2024densing",
        "author": "Xiao, Chaojun and Cai, Jie and Zhao, Weilin and Zeng, Guoyang and Han, Xu and Liu, Zhiyuan and Sun, Maosong",
        "title": "Densing Law of LLMs"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "hu2023predicting",
        "author": "Hu, Shengding and Liu, Xin and Han, Xu and Zhang, Xinrong and He, Chaoqun and Zhao, Weilin and Lin, Yankai and Ding, Ning and Ou, Zebin and Zeng, Guoyang and others",
        "title": "Predicting Emergent Abilities with Infinite Resolution Evaluation"
      },
      {
        "key": "owen2024predictable",
        "author": "Owen, David",
        "title": "How predictable is language model benchmark performance?"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "hu2023predicting",
        "author": "Hu, Shengding and Liu, Xin and Han, Xu and Zhang, Xinrong and He, Chaoqun and Zhao, Weilin and Lin, Yankai and Ding, Ning and Ou, Zebin and Zeng, Guoyang and others",
        "title": "Predicting Emergent Abilities with Infinite Resolution Evaluation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "xiao2024densing",
        "author": "Xiao, Chaojun and Cai, Jie and Zhao, Weilin and Zeng, Guoyang and Han, Xu and Liu, Zhiyuan and Sun, Maosong",
        "title": "Densing Law of LLMs"
      }
    ]
  }
]