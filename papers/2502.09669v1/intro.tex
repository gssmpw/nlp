Volume data representation is a long-standing theme for scientific computing and visualization. 
Recently, researchers have explored using {\em implicit neural representation} (INR)~\cite{Sitzmann-SIREN-NeurIPS20} for volume data representation~\cite{Lu-neurcomp, Han-TVCG23, Tang-CG24, Tang-PVIS24}.
Using an architecture of {\em multilayer perception} (MLP), INR maps spatial coordinates to corresponding voxel values for volume fitting and stores the parameters of the MLP to represent the underlying volume.
In this context, INR offers three advantages. 
First, the model size of a fully connected network is usually much smaller than the original volume, implying that INR can achieve highly compressive results.
Second, INR can be naturally embedded into the volume rendering pipeline. A renderer can directly access the voxel values along a ray by inferring the trained network, eliminating the need to decode the entire volume beforehand.
Third, once trained, an INR can achieve arbitrary-scale interpolation without accessing the original data, significantly enhancing the convenience of post-hoc analysis.

Despite its effectiveness, the current INR network parameters optimized on one volume are not generalizable enough to be adapted to other unseen volumes.
When users represent new simulation volume data using INR, the parameters of the trained INR cannot be directly reused to accelerate training on other volumes, which leads to inefficient encoding for time-varying or ensemble datasets.
Inspired by {\em meta-learning} in neural networks~\cite{Hospedales-TPMAI22}, we propose Meta-INR, a pretraining strategy for INR that only uses partial observation of a volumetric dataset but enables rapid adaptation to unseen volumes with similar structures in a few gradient steps. 

The contributions of our work are as follows. 
First, we are the first to apply meta-learning techniques to volume data representation. 
We demonstrate that Meta-INR, pretrained using no more than 1\% of data samples, can adapt to unseen similar volumes efficiently. 
Our method reduces the computational overhead of encoding new volumes by leveraging meta-learned priors, leading to significantly faster encoding than training from scratch. 
Second, we show that the parameters of adapted INRs exhibit enhanced interpretability, making them useful for simulation parameter analysis and representative timestep selection tasks.
Finally, we evaluate Meta-INR on various datasets by comparing its performance with other training strategies.