%--------------------------------------
\begin{table}[htb]
\caption{Experimented datasets and their respective settings.}
%\vspace{-0.05in}
\centering
{\scriptsize
%\resizebox{\columnwidth}{!}{
\begin{tabular}{c|ccc}
  & dimension & \# of timesteps     \\ 
 dataset & (x$\times$y$\times$z) & or ensembles    \\ \hline
 earthquake &  256$\times$256$\times$96  &  598\\ 
 half-cylinder~\cite{Rojo-TVCG19} &  640$\times$240$\times$80  &  20\\ 
 ionization~\cite{Whalen-TAJ08} & 600$\times$248$\times$248  &    30\\
 Tangaroa~\cite{Popinet-JAOT04} & 300$\times$180$\times$120 &   30\\
 vortex~\cite{silver1997tracking} & 128$\times$128$\times$128 &   15 \\
 Nyx~\cite{Almgren-AJ13}        & 256$\times$256$\times$256 & 209
\end{tabular}
}
\label{tab:datasets}
\end{table}
%--------------------------------------
 
%--------------------------------------
\begin{table}[!htb]
\caption{Average PSNR (dB), LPIPS, CD values across all timesteps, and overall encoding time (ET), pretraining time (PT), and total time (TT) for encoding different time-varying datasets. ``p.t." stands for pretrained. The chosen isovalues for computing CD are $0.0$, $-0.6$, $-0.8$, and $-0.2$, respectively. `s', `m', and `h' denote seconds, minutes, and hours. The best metric values are shown in bold.}
%\vspace{-0.05in}
\centering
{\scriptsize
%\resizebox{6in}{!}{
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|c|ccc|ccc}
dataset		&method & PSNR$\uparrow$ & LPIPS$\downarrow$ & CD$\downarrow$& ET &  PT & TT\\ \hline
\multirow{3}{*}{\shortstack{half-cylinder}}% \\ ($v = 0.0$)}}
&SIREN& 48.89&	0.0729& 0.5081& 4h 28m& --- &4h 28m\\ 
&p.t.\ SIREN& 35.87&	0.1113& 2.6655& 42m 19s&2h 39m&3h 21m\\ 
&Meta-INR& \textbf{55.92}&	\textbf{0.0705}& \textbf{0.2989}& 43m 45s&2h 14m&2h 58m\\  \hline
\multirow{3}{*}{\shortstack{ionitzation}}% \\ ($v = -0.6$)}}
&SIREN& 48.43&	0.0591& 0.5534& 21h 7m& --- &21h 7m\\ 
&p.t.\ SIREN& 40.67&	0.1189& 1.6666& 3h 21m&11h 51m&15h 12m\\ 
&Meta-INR& \textbf{51.30}&	\textbf{0.0576}&\textbf{ 0.4622}& 3h 15m&11h 28m&14h 43m\\ \hline
\multirow{3}{*}{\shortstack{Tangaroa}}% \\ ($v = -0.8$)}}
&SIREN& 43.22&	0.1989& 1.3144& 3h 29m& --- &3h 29m\\ 
&p.t.\ SIREN& 40.46&	0.3387& 16.075& 33m 23s&2h 10m &2h 43m\\ 
&Meta-INR& \textbf{48.68}&	\textbf{0.1969}&\textbf{ 0.5499}& 33m 59s&2h 7m &2h 41m\\ \hline
\multirow{3}{*}{\shortstack{vortex}}% \\ ($v = -0.2$)}}
&SIREN& 46.06&	0.0358& 0.2484& 24m 22s& --- &24m 22s\\ 
&p.t.\ SIREN& 26.22&	0.2541& 2.0146& 5m 17s&22m 49s &28m 06s\\ 
&Meta-INR& \textbf{48.19}&	\textbf{0.0294}& \textbf{0.2029}& 5m 10s&18m 44s &23m 54s\\ 
\end{tabular}
}
}
\label{tab:baseline-metrics}
\end{table}
%--------------------------------------

%--------------------------------------
\begin{figure}[!htb]
 \begin{center}
 $\begin{array}{c@{\hspace{0.025in}}c@{\hspace{0.025in}}c@{\hspace{0.025in}}c}
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/half-cylinder/INR100.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/half-cylinder/Baseline.jpg}&
  \includegraphics[width=0.23\linewidth]{figures/drawings/volume/half-cylinder/MetaINR.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/half-cylinder/GT.jpg} \\
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/ionization/INR100.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/ionization/Baseline.jpg}&
  \includegraphics[width=0.23\linewidth]{figures/drawings/volume/ionization/MetaINR.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/ionization/GT.jpg} \\
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/tangaroa/INR100.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/tangaroa/Baseline.jpg}&
  \includegraphics[width=0.23\linewidth]{figures/drawings/volume/tangaroa/MetaINR.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/tangaroa/GT.jpg} \\
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/vorts/INR100.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/vorts/Baseline.jpg}&
  \includegraphics[width=0.23\linewidth]{figures/drawings/volume/vorts/MetaINR.jpg}&
 \includegraphics[width=0.23\linewidth]{figures/drawings/volume/vorts/GT.jpg} \\
\mbox{\footnotesize SIREN} & \mbox{\footnotesize p.t.\ SIREN} & \mbox{\footnotesize Meta-INR} &\mbox{\footnotesize GT}
\end{array}$
\end{center}
\vspace{-.25in} 
\caption{Comparing different methods on volume rendering results. Top to bottom: half-cylinder, ionization, Tangaroa, and vortex.} 
\label{fig:time-varying-vol}
\end{figure}
%--------------------------------------


%--------------------------------------
\begin{figure}[t]
 \begin{center}
 $\begin{array}{c@{\hspace{0.025in}}c@{\hspace{0.025in}}c@{\hspace{0.025in}}c}
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/half-cylinder-INR100.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/half-cylinder-Baseline.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/half-cylinder-MetaINR.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/half-cylinder-GT.png} \\
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/ionization-INR100.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/ionization-Baseline.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/ionization-MetaINR.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/ionization-GT.png} \\
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/tangaroa-INR100.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/tangaroa-Baseline.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/tangaroa-MetaINR.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/tangaroa-GT.png} \\
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/vorts-INR100.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/vorts-Baseline.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/vorts-MetaINR.png}&
\includegraphics[width=0.23\linewidth]{figures/drawings/isosurface/figure/vorts-GT.png} \\
\mbox{\footnotesize SIREN} & \mbox{\footnotesize p.t.\ SIREN} & \mbox{\footnotesize Meta-INR} &\mbox{\footnotesize GT}
\end{array}$
\end{center}
\vspace{-.25in} 
\caption{Comparing different methods on isosurface rendering results. Top to bottom: half-cylinder, ionization, Tangaroa, and vortex. The chosen isovalues are reported in Table~\ref{tab:baseline-metrics}.} 
\label{fig:time-varying-iso}
\end{figure}
%--------------------------------------



%--------------------------------------
\begin{figure*}[!ht]
\begin{center}
$\begin{array}{c@{\hspace{0.25in}}c@{\hspace{0.25in}}c}
\includegraphics[height=1.6in]{figures/drawings/TSNE/INR.png} &
\includegraphics[height=1.6in]{figures/drawings/TSNE/Earthquake-Mix.png} &
\includegraphics[height=1.6in]{figures/drawings/TSNE/MetaINR.png} \\
\mbox{\footnotesize (a) SIREN~\cite{Sitzmann-SIREN-NeurIPS20}} & \mbox{\footnotesize (b) autoencoder~\cite{Porter-VISSP19}} &
\mbox{\footnotesize (c) Meta-INR} 
\end{array}$
\end{center}
\vspace{-.25in}
\caption{t-SNE projections using parameters from different methods trained on the time-varying earthquake dataset, where selected timesteps are marked on the timeline on the left. SIREN's model parameters are not interpretable and fail to establish a correlation between timesteps. Volume rendering images are shown adjacent to selected timesteps for autoencoder and Meta-INR. 
% \hot{for (a) and (c), draw the curve first before drawing the points and labels. Shift the timeline for (c) a bit to the left, use the same height.}
}
\label{fig:timestep-selection}
\end{figure*}
%--------------------------------------

%--------------------------------------
\begin{figure*}[!htb]
\centering
\begin{center}
$\begin{array}{c@{\hspace{0.25in}}c@{\hspace{0.25in}}c@{\hspace{0.25in}}c}
\includegraphics[width=0.215\linewidth]{figures/h_0_550000_crop.png} &
\includegraphics[width=0.215\linewidth]{figures/h_0_700000_crop.png} &
\includegraphics[width=0.215\linewidth]{figures/OmM_0_120000_crop.png} &
\includegraphics[width=0.215\linewidth]{figures/OmM_0_155000_crop.png} \\
\mbox{\footnotesize (a) $h_0=550,000$} & \mbox{\footnotesize (b) $h_0=700,000$} &
\mbox{\footnotesize (c) $OmM_0=120,000$} & \mbox{\footnotesize (d) $OmM_0=155,000$} 
\end{array}$
\end{center}
\vspace{-.25in}
\caption{t-SNE projections of Meta-INR models trained on the ensemble Nyx dataset where each point represents a volume. Volumes with $h_0$ or $OmM_0$ matching the specified values are highlighted in light blue.}
\label{fig:multi-variate}
\end{figure*}
%--------------------------------------

\vspace{-0.1in}
\section{Results and discussion}

\subsection{Datasets, Training, Baselines, and Metrics}

{\bf Datasets and network training.}
Table~\ref{tab:datasets} lists the datasets used to evaluate Meta-INR. 
In particular, we utilize the time-varying datasets, including the half-cylinder, ionization, Tangaroa, and vortex datasets, to evaluate the reconstruction accuracy of the Meta-INR compared with other baseline methods.
The time-varying earthquake dataset is leveraged to showcase the interpretability of the parameters of adapted INRs under t-SNE projection.
We demonstrate the ability of Meta-INR on simulation parameter analysis using the ensemble Nyx dataset with three simulation parameters: $h_0$, $OmM_0$, and $OmB_0$.
Meta-INR uses a seven-layer SIREN model~\cite{Sitzmann-SIREN-NeurIPS20} as its network backbone, with a hidden layer dimension of 256.
It is trained across all experiments with 500 outer steps and sets the number of inner-loop steps $K=16$.
We set both inner and outer loop learning rates $\alpha$ and $\beta$ to 0.0001 during meta-pretraining and 0.00001 during volume-specific finetuning. 
Both stages optimize the parameters with a batch size of 50,000 coordinate-value pairs for each iteration.

{\bf Baselines.} We compare Meta-INR with two baseline strategies:
\begin{myitemize}
\vspace{-0.05in}
    \item SIREN~\cite{Sitzmann-SIREN-NeurIPS20} is the backbone network architecture of Meta-INR. Here, SIREN as a baseline method means training each INR network independently for each volume from scratch.
    \item Pretrained SIREN is a vanilla pretraining baseline method that optimizes the initial parameters on the same subsampled dataset without leveraging meta-learning techniques (i.e., no inner-loop updating). After pretraining, we finetune the learned initial parameters using the same number of adaptation steps as the Meta-INR for fair comparisons.

\vspace{-0.05in}
\end{myitemize}

{\bf Evaluation metrics.}
We use three metrics to evaluate the reconstruction accuracy of Meta-INR and baseline methods. 
We utilize \textit{peak signal-to-noise ratio} (PSNR) to measure the volume reconstruction accuracy, and \textit{learned perceptual image patch similarity} (LPIPS) to evaluate rendered image qualities for volumes reconstructed by different methods. \textit{Chamfer distance} (CD) is used to assess similarity at the surface level by calculating the average distance of isosurfaces. 

\vspace{-0.05in}
\subsection{Time-Varying Data Representation}
\label{subsec:tvdr}

Time-varying data representation directly evaluates the effectiveness of Meta-INR in speeding up model training and improving reconstruction fidelity. We consider all methods on four datasets with various dimensions, as seen in Table~\ref{tab:datasets}. 

{\bf Quantitative comparison.}
In Table~\ref{fig:time-varying-iso}, we report quantitative results of all different methods. 
Meta-INR performs the best across the three quality metrics for all datasets. 
Although SIREN achieves decent quality, sometimes comparable to Meta-INR, the need to retrain a model from scratch for each volume implies that a significant encoding time is required for the model to converge. 
For Meta-INR, despite the model taking the majority of total time for meta-pretraining, only a few adaptation steps are needed for encoding, saving considerable time compared to SIREN.
In particular, the encoding time of adapted INRs is 5.87$\times$ faster on average across all datasets than SIREN, which trains each INR from scratch. 
Pretrained SIREN performs the worst in terms of the three quality metrics as it fails to capture the intrinsic patterns from partial observation of volumetric datasets and struggles to converge efficiently during encoding.
Through diverse evaluation across multiple datasets varying in size and complexity, we found Meta-INR to be highly adaptable. Meta-INR's generalizability stems from its meta-learning framework, which uses inner loop adaptation during meta-pretraining that mimics the finetuning process, forcing parameters into a region where a small number of gradient steps can minimize task-specific loss. This design ensures the prior captures shared structural patterns while remaining sensitive to volume-specific variations. 
%\hot{Need to briefly discuss training time across three methods.}
%(6.13+6.497+6.147+4.72)/4=5.87


{\bf Qualitative comparison.} 
In Figures~\ref{fig:time-varying-vol}~and~\ref{fig:time-varying-iso}, we compare the volume and isosurface rendering results for different methods. 
A pixel-wise difference image is also provided on the bottom left to show the differences between each method and the GT.
Pretrained SIREN performs the worst among all three methods, showing significant deviations from the GT. In many cases, it demonstrates block-like artifacts. 
%
Both SIREN and Meta-INR demonstrate excellent visual fidelity for the reconstructed volumes. Although they perform similar results in simple datasets such as vortex, Meta-INR can achieve significantly higher accuracy for complex ones with many details, such as Tangaroa. This is because such details are already captured in the meta-model, which serves as the prior for quick adaptation. Then, during volume-specific finetuning, only slight parameter adaptation is needed.

\vspace{-0.05in}
\subsection{Representative Timestep Selection}

We showcase the interpretability of Meta-INR by analyzing its ability on the representative timestep selection task of the earthquake dataset. 
Porter et al.\ \cite{Porter-VISSP19} demonstrated the effectiveness of deep learning techniques for selecting representative timesteps.
In our scenario, an INR network trained on one specific volume can also be considered an alternative representation of that volume.
However, as shown in Figure~\ref{fig:timestep-selection}, when we use t-SNE~\cite{t-SNE} to project the learned parameters of each SIREN at each timestep to a 2D space and connect the points in the order of timesteps, the resulting projection view is meaningless and offers no interpretability. 
This is because of significantly increased noise and randomness in training, which leads to models finding drastically different local minima. In contrast, Meta-INR's volume-specific finetuning starts with a common prior, eliminating most noise and focusing on each volume's differences.
In particular, the connected points of SIREN across different timesteps lack continuity, resulting in numerous sharp turnings. 
As SIREN encodes volumes at each timestep independently from scratch, their parameter representations fail to capture a smooth transition of the dataset along the time dimension.
%
Unlike SIREN, the connected points are meaningful and smooth when leveraging t-SNE to project the parameters of adapted INRs finetuned on each timestep.
We select representative timesteps following~\cite{Porter-VISSP19} and observe reasonable results.
Moreover, we can see that the connected points of Meta-INR are smoother than the results obtained by~\cite{Porter-VISSP19} using an autoencoder.
This difference arises from the need to downsample the data before training the autoencoder. 
Unlike Meta-INR, the network architecture of the autoencoder is constrained by volume dimensions and cannot directly process high-resolution volumetric data.
Therefore, the connected points for the projections of the autoencoder are less smooth due to the noise introduced from downsampling.

\vspace{-0.05in}
\subsection{Simulation Parameter Analysis}
\label{subsec:spa}

When analyzing ensemble datasets, it is often insightful to see how changes in each parameter affect the simulation. 
Meta-INR can aid in this process by effectively visualizing the relative differences between each volume via t-SNE projection. We apply Meta-INR to the Nyx dataset with three simulation parameters, $h_0$, $OmM_0$, and $OmB_0$. Similar to the time-varying datasets, we perform meta-pretraining on the subsampled Nyx dataset, which is downsampled along the spatial and ensemble dimensions, and then conduct volume-specific finetuning to fit all volumes corresponding to different simulation parameters. In Figure~\ref{fig:multi-variate}, we visualize the pattern in model parameters using t-SNE and mark t-SNE projections sharing the same parameter values. 
%
In (a) and (b), we highlight all projections with $h_0$ equal to 550,000 and 700,000, respectively. We can see that $h_0=550,000$ corresponds to projections centralized on the left side, and the projections of $h_0=700,000$ are centralized at the bottom of the plot.
%
Similarly, in (c) and (d), which mark projections with $OmM_0$ equal  120,000 and 155,000, respectively, we observe that $OmM_0=120,000$ corresponds to projections located at the outer region of the plot. On the other hand, $OmM_0=155,000$ corresponds to projections close to the inner region.
These results show that the parameters of adapted INRs assimilate information about the simulation parameters during the encoding process.
