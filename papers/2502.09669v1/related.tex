\vspace{-0.075in}
\section{Related Work}
\vspace{-0.025in}

{\bf INR for scientific visualization.}
Using deep learning techniques for data representation~\cite{Wang-DL4SciVis} has been extensively studied recently. 
One solution uses INR, which inputs spatial coordinates and outputs corresponding voxel values to achieve the generation and reduction of scientific data. 
Typically, INR leverages the MLP architecture to represent volumetric data.
For example, Lu et al.\ \cite{Lu-neurcomp} compressed a single scalar field by optimizing an INR with weight quantization.
Han and Wang~\cite{Han-TVCG23} proposed CoordNet, a coordinate-based network to tackle diverse data and visualization generation tasks.
Tang and Wang~\cite{Tang-CG24} presented STSR-INR, leveraging an INR to generate simultaneous spatiotemporal super-resolution for time-varying multivariate volumetric data.
Han et al.\ \cite{Han-KD-INR} proposed KD-INR to handle large-scale time-varying volumetric data compression when volumes are only sequentially accessible during training.
Tang and Wang~\cite{Tang-PVIS24} designed ECNR to achieve efficient time-varying data compression by combining INR with the Laplacian pyramid for multiscale fitting.
Li and Shen~\cite{Li-TVCG24} leveraged Gaussian distribution to model the probability distribution of an INR network to achieve efficient isosurface extraction.

Besides the vanilla MLP architecture, multiple works integrate grid parameters into INR to achieve efficient encoding and rendering.
%For instance, 
Weiss et al.\ \cite{Weiss-CGF22} implemented fV-SRN, achieving significant rendering speed gain over~\cite{Lu-neurcomp} using a volumetric latent grid.
Wurster et al.\ \cite{Wurster-TVCG24} proposed APMGSRN, which uses multiple spatially adaptive feature grids to represent a large volume.
Xiong et al.\ \cite{Xiong-TVCG24} designed MDSRN to simultaneously reconstruct the data and assess the reconstruction quality in one INR network.
Tang and Wang~\cite{Tang-VIS24} developed StyleRF-VolVis, leveraging a grid-based encoding INR to represent a volume rendering scene that supports various editings.
Yao et al.\ \cite{Yao-PVIS25} proposed ViSNeRF, utilizing a multidimensional INR representation for visualization synthesis of dynamic scenes, including changes of transfer functions, isovalues, timesteps, or simulation parameters. 
Gu et al.\ \cite{Gu-CG23} and Lu et al.\ \cite{YF-Lu-VISSP24} presented NeRVI and FCNR, respectively, utilizing INRs for the effective compression of a large collection of visualization images. 
%
Unlike existing works that mainly focus on network architecture design, this paper aims to develop a pretraining strategy for optimizing the initial parameters of an INR network to enhance the representation generalizability.

{\bf Meta-learning.}
Meta-learning is a deep learning technique primarily aiming for few-shot learning~\cite{Song-ACM23}.
Numerous recent studies have explored using it to optimize the initialization of neural networks, enabling them to adapt to new tasks with just a few steps of gradient descent.
For instance, 
Sitzmann et al.\ \cite{Sitzmann-MetaSDF-NeurIPS20} leveraged meta-learners to generalize INR across shapes.
Tancik et al.\ \cite{Tancik-CVPR21} employed meta-learning to initialize INR network parameters according to the underlying class of represented signals.
Emilien et al.\ \cite{Emilien-TMLR} proposed COIN++, a neural compression framework that supports encoding various data modalities with a meta-learned base network.
Similar to these works, we develop Meta-INR based on existing meta-learning algorithms~\cite{Finn-ICML17, Nichol-arXiv18}.
However, we focus on applying meta-learning in INR for volume data representation, setting it apart from existing studies.
