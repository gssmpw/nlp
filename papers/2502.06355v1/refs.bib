@inproceedings{transformer_model,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{gpt3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{vatt,
      title={VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text}, 
      author={Hassan Akbari and Liangzhe Yuan and Rui Qian and Wei-Hong Chuang and Shih-Fu Chang and Yin Cui and Boqing Gong},
      year={2021},
      eprint={2104.11178},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{clip,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imagebind,
    title={ImageBind: One Embedding Space To Bind Them All},
    author={Rohit Girdhar and Alaaeldin El-Nouby and Zhuang Liu and Mannat Singh and Kalyan Vasudev Alwala and Armand Joulin and Ishan Misra},
    year={2023},
    eprint={2305.05665},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}


@InProceedings{fl,
  title = 	 {{Communication-Efficient Learning of Deep Networks from Decentralized Data}},
  author = 	 {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1273--1282},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/mcmahan17a.html},
  abstract = 	 {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.  We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.  We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent. }
}

@misc{sl,
      title={Distributed learning of deep neural network over multiple agents}, 
      author={Otkrist Gupta and Ramesh Raskar},
      year={2018},
      eprint={1810.06060},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{splitfed,
      title={SplitFed: When Federated Learning Meets Split Learning}, 
      author={Chandra Thapa and M. A. P. Chamikara and Seyit Camtepe and Lichao Sun},
      year={2022},
      eprint={2004.12088},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sglr,
      title={Server-Side Local Gradient Averaging and Learning Rate Acceleration for Scalable Split Learning}, 
      author={Shraman Pal and Mansi Uniyal and Jihong Park and Praneeth Vepakomma and Ramesh Raskar and Mehdi Bennis and Moongu Jeon and Jinho Choi},
      year={2021},
      eprint={2112.05929},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{sasl,
  author={Lyu, Xinchen and Liu, Shuhan and Liu, Junlin and Ren, Chenshan},
  journal={IEEE Internet of Things Magazine}, 
  title={Scalable Aggregated Split Learning for Data-Driven Edge Intelligence on Internet-of-Things}, 
  year={2023},
  volume={6},
  number={4},
  pages={124-129},
  keywords={Training;Performance evaluation;Backpropagation;Data privacy;Computational modeling;Computational efficiency;Internet of Things},
  doi={10.1109/IOTM.001.2300053}}

@article{ViT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{InfoNCE,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={631--648},
  year={2018}
}

@article{ViT-LENS,
  title={Vit-lens: Towards omni-modal representations},
  author={Lei, Weixian and Ge, Yixiao and Zhang, Jianfeng and Sun, Dylan and Yi, Kun and Shan, Ying and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2308.10185},
  year={2023}
}

@article{meta-transformer,
  title={Meta-transformer: A unified framework for multimodal learning},
  author={Zhang, Yiyuan and Gong, Kaixiong and Zhang, Kaipeng and Li, Hongsheng and Qiao, Yu and Ouyang, Wanli and Yue, Xiangyu},
  journal={arXiv preprint arXiv:2307.10802},
  year={2023}
}

@inproceedings{LAION-2B,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{multimodal-federated-learning__a-survey,
  title={Multimodal federated learning: A survey},
  author={Che, Liwei and Wang, Jiaqi and Zhou, Yao and Ma, Fenglong},
  journal={Sensors},
  volume={23},
  number={15},
  pages={6986},
  year={2023},
  publisher={MDPI}
}

@article{distributed-learning-in-the-IoT-edge-cloud-continuum,
  title={Distributed Learning in the IoT--Edge--Cloud Continuum},
  author={Arzovs, Audris and Judvaitis, Janis and Nesenbergs, Krisjanis and Selavo, Leo},
  journal={Machine Learning and Knowledge Extraction},
  volume={6},
  number={1},
  pages={283--315},
  year={2024},
  publisher={MDPI}
}

@article{advancements-of-fl-towards-privacy-preservation_from-fl-to-sl,
  title={Advancements of federated learning towards privacy preservation: from federated learning to split learning},
  author={Thapa, Chandra and Chamikara, Mahawaga Arachchige Pathum and Camtepe, Seyit A},
  journal={Federated Learning Systems: Towards Next-Generation AI},
  pages={79--109},
  year={2021},
  publisher={Springer}
}

@article{combined-federated-and-sl-in-edge-computing-for-uniquitous,
  title={Combined federated and split learning in edge computing for ubiquitous intelligence in internet of things: State-of-the-art and future directions},
  author={Duan, Qiang and Hu, Shijing and Deng, Ruijun and Lu, Zhihui},
  journal={Sensors},
  volume={22},
  number={16},
  pages={5983},
  year={2022},
  publisher={MDPI}
}

@article{sl-in-6g-networks,
  title={Split learning in 6g edge networks},
  author={Lin, Zheng and Qu, Guanqiao and Chen, Xianhao and Huang, Kaibin},
  journal={arXiv preprint arXiv:2306.12194},
  year={2023}
}

@inproceedings{privacy-sensitive-psl,
  title={Privacy-sensitive parallel split learning},
  author={Jeon, Joohyung and Kim, Joongheon},
  booktitle={2020 International Conference on Information Networking (ICOIN)},
  pages={7--9},
  year={2020},
  organization={IEEE}
}

@article{mhsl,
  title={Splitfed learning without client-side synchronization: Analyzing client-side split network portion size to overall performance},
  author={Joshi, Praveen and Thapa, Chandra and Camtepe, Seyit and Hasanuzzamana, Mohammed and Scully, Ted and Afli, Haithem},
  journal={arXiv preprint arXiv:2109.09246},
  year={2021}
}

@inproceedings{LocalSplitFed,
  title={Accelerating federated learning with split learning on locally generated losses},
  author={Han, Dong-Jun and Bhatti, Hasnain Irshad and Lee, Jungmoon and Moon, Jaekyun},
  booktitle={ICML 2021 workshop on federated learning for user privacy and data confidentiality. ICML Board},
  year={2021}
}

@inproceedings{CSFL,
  title={Efficient Federated Learning Method for Cloud-Edge Network Communication},
  author={Duan, Jing and Duan, Jie and Wan, Xuefeng and Li, Yang},
  booktitle={2023 5th International Conference on Communications, Information System and Computer Engineering (CISCE)},
  pages={118--121},
  year={2023},
  organization={IEEE}
}

@inproceedings{CSE-FSL,
  title={Communication and storage efficient federated split learning},
  author={Mu, Yujia and Shen, Cong},
  booktitle={ICC 2023-IEEE International Conference on Communications},
  pages={2976--2981},
  year={2023},
  organization={IEEE}
}

@article{AdaSplit,
  title={Adasplit: Adaptive trade-offs for resource-constrained distributed deep learning},
  author={Chopra, Ayush and Sahu, Surya Kant and Singh, Abhishek and Java, Abhinav and Vepakomma, Praneeth and Sharma, Vivek and Raskar, Ramesh},
  journal={arXiv preprint arXiv:2112.01637},
  year={2021}
}

@inproceedings{LocFedMix-SL,
  title={Locfedmix-sl: Localize, federate, and mix for improved scalability, convergence, and latency in split learning},
  author={Oh, Seungeun and Park, Jihong and Vepakomma, Praneeth and Baek, Sihun and Raskar, Ramesh and Bennis, Mehdi and Kim, Seong-Lyun},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={3347--3357},
  year={2022}
}

@article{Mix2SFL,
  title={Mix2SFL: Two-Way Mixup for Scalable, Accurate, and Communication-Efficient Split Federated Learning},
  author={Oh, Seungeun and Nam, Hyelin and Park, Jihong and Vepakomma, Praneeth and Raskar, Ramesh and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={IEEE Transactions on Big Data},
  year={2023},
  publisher={IEEE}
}

@article{EPSL,
  title={Efficient parallel split learning over resource-constrained wireless edge networks},
  author={Lin, Zheng and Zhu, Guangyu and Deng, Yiqin and Chen, Xianhao and Gao, Yue and Huang, Kaibin and Fang, Yuguang},
  journal={IEEE Transactions on Mobile Computing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{PFSL,
  title={PFSL: Personalized \& Fair Split Learning with Data \& Label Privacy for thin clients},
  author={Wadhwa, Manas and Gupta, Gagan Raj and Sahu, Ashutosh and Saini, Rahul and Mittal, Vidhi},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
  pages={377--390},
  year={2023},
  organization={IEEE}
}

@article{MP-SL,
  title={MP-SL: Multihop Parallel Split Learning},
  author={Tirana, Joana and Lalis, Spyros and Chatzopoulos, Dimitris},
  journal={arXiv preprint arXiv:2402.00208},
  year={2024}
}

@inproceedings{BiCSL,
  title={Bidirectional Contrastive Split Learning for Visual Question Answering},
  author={Sun, Yuwei and Ochiai, Hideya},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21602--21609},
  year={2024}
}

@article{FedCLIP,
  title={Fedclip: Fast generalization and personalization for clip in federated learning},
  author={Lu, Wang and Hu, Xixu and Wang, Jindong and Xie, Xing},
  journal={arXiv preprint arXiv:2302.13485},
  year={2023}
}

@article{Shuffled-Transformer,
  title={Shuffled transformer for privacy-preserving split learning},
  author={Xu, Hengyuan and Xiang, Liyao and Ye, Hangyu and Yao, Dixi and Chu, Pengzhi and Li, Baochun},
  journal={arXiv preprint arXiv:2304.07735},
  year={2023}
}

@article{MaskSL,
  title={Privacy-preserving split learning for large-scaled vision pre-training},
  author={Wang, Zhousheng and Yang, Geng and Dai, Hua and Rong, Chunming},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={18},
  pages={1539--1553},
  year={2023},
  publisher={IEEE}
}

@article{SAP,
  title={A Split-and-Privatize Framework for Large Language Model Fine-Tuning},
  author={Shen, Xicong and Liu, Yang and Liu, Huiqi and Hong, Jue and Duan, Bing and Huang, Zirui and Mao, Yunlong and Wu, Ye and Wu, Di},
  journal={arXiv preprint arXiv:2312.15603},
  year={2023}
}

@inproceedings{DP,
  title={Differential privacy: A survey of results},
  author={Dwork, Cynthia},
  booktitle={International conference on theory and applications of models of computation},
  pages={1--19},
  year={2008},
  organization={Springer}
}

@article{CutMixSL,
  title={Visual transformer meets cutmix for improved accuracy, communication efficiency, and data privacy in split learning},
  author={Baek, Sihun and Park, Jihong and Vepakomma, Praneeth and Raskar, Ramesh and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={arXiv preprint arXiv:2207.00234},
  year={2022}
}

@article{DP-CutMixSL,
  title={Differentially private cutmix for split learning with vision transformer},
  author={Oh, Seungeun and Park, Jihong and Baek, Sihun and Nam, Hyelin and Vepakomma, Praneeth and Raskar, Ramesh and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={arXiv preprint arXiv:2210.15986},
  year={2022}
}

@article{FedBone,
  title={Fedbone: Towards large-scale federated multi-task learning},
  author={Chen, Yiqiang and Zhang, Teng and Jiang, Xinlong and Chen, Qian and Gao, Chenlong and Huang, Wuliang},
  journal={arXiv preprint arXiv:2306.17465},
  year={2023}
}

@article{FeSTA,
  title={Federated split vision transformer for COVID-19 CXR diagnosis using task-agnostic training},
  author={Park, Sangjoon and Kim, Gwanghyun and Kim, Jeongsol and Kim, Boah and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2111.01338},
  year={2021}
}

@article{p-FeSTA,
  title={Multi-task distributed learning using vision transformer with random patch permutation},
  author={Park, Sangjoon and Ye, Jong Chul},
  journal={IEEE Transactions on Medical Imaging},
  year={2022},
  publisher={IEEE}
}

@inproceedings{FeSViBS,
  title={FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling},
  author={Almalik, Faris and Alkhunaizi, Naif and Almakky, Ibrahim and Nandakumar, Karthik},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={350--360},
  year={2023},
  organization={Springer}
}

@inproceedings{FedSIS,
  title={FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection},
  author={Alkhunaizi, Naif and Srivatsan, Koushik and Almalik, Faris and Almakky, Ibrahim and Nandakumar, Karthik},
  booktitle={2023 IEEE International Joint Conference on Biometrics (IJCB)},
  pages={1--11},
  year={2023},
  organization={IEEE}
}

@article{BERT,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{FedBERT,
  title={Fedbert: When federated learning meets pre-training},
  author={Tian, Yuanyishu and Wan, Yao and Lyu, Lingjuan and Yao, Dezhong and Jin, Hai and Sun, Lichao},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={13},
  number={4},
  pages={1--26},
  year={2022},
  publisher={ACM New York, NY}
}

@article{Fed-urlBERT,
  title={Fed-urlBERT: Client-side Lightweight Federated Transformers for URL Threat Analysis},
  author={Li, Yujie and Wang, Yanbin and Xu, Haitao and Guo, Zhenhao and Zhang, Fan and Liu, Ruitong and Ma, Wenrui},
  journal={arXiv preprint arXiv:2312.03636},
  year={2023}
}

@article{VQA-fusion-techniques,
  title={Cross-Attention Based Text-Image Transformer for Visual Question Answering},
  author={Rezapour, Mahdi}
}

@inproceedings{FedMultimodal,
  title={Fedmultimodal: A benchmark for multimodal federated learning},
  author={Feng, Tiantian and Bose, Digbalay and Zhang, Tuo and Hebbar, Rajat and Ramakrishna, Anil and Gupta, Rahul and Zhang, Mi and Avestimehr, Salman and Narayanan, Shrikanth},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4035--4045},
  year={2023}
}

@article{SLPerf,
  title={SLPerf: a Unified Framework for Benchmarking Split Learning},
  author={Zhou, Tianchen and Hu, Zhanyi and Wu, Bingzhe and Chen, Cen},
  journal={arXiv preprint arXiv:2304.01502},
  year={2023}
}

@article{BEiT-3,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@inproceedings{OFA,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@article{VLMO,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}

% ============================== Datasets ==============================
@inproceedings{ScanNet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@article{MHAiR,
  title={MHAiR: A Dataset of Audio-Image Representations for Multimodal Human Actions},
  author={Shaikh, Muhammad Bilal and Chai, Douglas and Islam, Syed Mohammed Shamsul and Akhtar, Naveed},
  journal={Data},
  volume={9},
  number={2},
  pages={21},
  year={2024},
  publisher={MDPI}
}

@inproceedings{MetaAudioVisualSegmentation,
  title={Audio--visual segmentation},
  author={Zhou, Jinxing and Wang, Jianyuan and Zhang, Jiayi and Sun, Weixuan and Zhang, Jing and Birchfield, Stan and Guo, Dan and Kong, Lingpeng and Wang, Meng and Zhong, Yiran},
  booktitle={European Conference on Computer Vision},
  pages={386--403},
  year={2022},
  organization={Springer}
}

@article{MELD,
  title={Meld: A multimodal multi-party dataset for emotion recognition in conversations},
  author={Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},
  journal={arXiv preprint arXiv:1810.02508},
  year={2018}
}

@article{Crema-D,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  journal={IEEE transactions on affective computing},
  volume={5},
  number={4},
  pages={377--390},
  year={2014},
  publisher={IEEE}
}

@article{Fakeddit,
  author       = {Kai Nakamura and
                  Sharon Levy and
                  William Yang Wang},
  title        = {r/Fakeddit: {A} New Multimodal Benchmark Dataset for Fine-grained
                  Fake News Detection},
  journal      = {CoRR},
  volume       = {abs/1911.03854},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.03854},
  eprinttype    = {arXiv},
  eprint       = {1911.03854},
  timestamp    = {Sun, 01 Dec 2019 20:31:34 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-03854.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{FakeNewsNet,
  title={Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media},
  author={Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  journal={Big data},
  volume={8},
  number={3},
  pages={171--188},
  year={2020},
  publisher={Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…}
}

@inproceedings{COCO,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{Flickr30K,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2641--2649},
  year={2015}
}

@InProceedings{T4SA,
    author = {Vadicamo, Lucia and Carrara, Fabio and Cimino, Andrea and Cresci, Stefano and Dell'Orletta, Felice and Falchi, Fabrizio and Tesconi, Maurizio},
    title = {Cross-Media Learning for Image Sentiment Analysis in the Wild},
    booktitle = {2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},
    pages={308-317}, 
    doi={10.1109/ICCVW.2017.45}, 
    month = {Oct},
    year = {2017}
}

@inproceedings{MVSA,
author   = {Teng Niu and Shiai Zhu and Lei Pang and Abdulmotaleb El{-}Saddik},
title     = {Sentiment Analysis on Multi-View Social Data},
booktitle = {MultiMedia Modeling},
pages     = {15–27},
year     = {2016},
}

@article{TableQuestions,
  title={Compositional semantic parsing on semi-structured tables},
  author={Pasupat, Panupong and Liang, Percy},
  journal={arXiv preprint arXiv:1508.00305},
  year={2015}
}

@inproceedings{e-SNLI-VE,
  title={e-vil: A dataset and benchmark for natural language explanations in vision-language tasks},
  author={Kayser, Maxime and Camburu, Oana-Maria and Salewski, Leonard and Emde, Cornelius and Do, Virginie and Akata, Zeynep and Lukasiewicz, Thomas},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1244--1254},
  year={2021}
}

@article{SNLI-VE,
  title={Visual entailment: A novel task for fine-grained image understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint arXiv:1901.06706},
  year={2019}
}

@article{VSR,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{Clotho,
  title={Freesound technical demo},
  author={Font, Frederic and Roma, Gerard and Serra, Xavier},
  booktitle={Proceedings of the 21st ACM international conference on Multimedia},
  pages={411--412},
  year={2013}
}

@inproceedings{AudioCaps,
  title={Audiocaps: Generating captions for audios in the wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={119--132},
  year={2019}
}

@inproceedings{ActivityNet-QA,
  title={Activitynet-qa: A dataset for understanding complex web videos via question answering},
  author={Yu, Zhou and Xu, Dejing and Yu, Jun and Yu, Ting and Zhao, Zhou and Zhuang, Yueting and Tao, Dacheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={9127--9134},
  year={2019}
}

@inproceedings{VQAv2,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{DAQUAR,
  title={A multi-world approach to question answering about real-world scenes based on uncertain input},
  author={Malinowski, Mateusz and Fritz, Mario},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{COCO-QA,
  title={Exploring models and data for image question answering},
  author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{Genome,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{TextVQA,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}

@inproceedings{NLVR,
  title={A corpus of natural language for visual reasoning},
  author={Suhr, Alane and Lewis, Mike and Yeh, James and Artzi, Yoav},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={217--223},
  year={2017}
}

@inproceedings{SHAPES,
  title={Neural module networks},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={39--48},
  year={2016}
}

@article{UCF101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@article{MiT,
  title={Moments in time dataset: one million videos for event understanding},
  author={Monfort, Mathew and Andonian, Alex and Zhou, Bolei and Ramakrishnan, Kandan and Bargal, Sarah Adel and Yan, Tom and Brown, Lisa and Fan, Quanfu and Gutfreund, Dan and Vondrick, Carl and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={2},
  pages={502--508},
  year={2019},
  publisher={IEEE}
}





@article{AST,
  title={Ast: Audio spectrogram transformer},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  journal={arXiv preprint arXiv:2104.01778},
  year={2021}
}


@inproceedings{karpathy_split,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@inproceedings{kinetics-sound,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={609--617},
  year={2017}
}

@misc{ONE_PEACE,
      title={ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities}, 
      author={Peng Wang and Shijie Wang and Junyang Lin and Shuai Bai and Xiaohuan Zhou and Jingren Zhou and Xinggang Wang and Chang Zhou},
      year={2023},
      eprint={2305.11172},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.11172}, 
}

@misc{li2021federatedlearningnoniiddata,
      title={Federated Learning on Non-IID Data Silos: An Experimental Study}, 
      author={Qinbin Li and Yiqun Diao and Quan Chen and Bingsheng He},
      year={2021},
      eprint={2102.02079},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.02079}, 
}

@inproceedings{Bonaventura_2024,
   title={The IoT Breaches Your Household Again},
   url={http://dx.doi.org/10.5220/0012767700003767},
   DOI={10.5220/0012767700003767},
   booktitle={Proceedings of the 21st International Conference on Security and Cryptography},
   publisher={SCITEPRESS - Science and Technology Publications},
   author={Bonaventura, Davide and Esposito, Sergio and Bella, Giampaolo},
   year={2024},
   pages={475–482} }


@INPROCEEDINGS{10605435,
  author={Ghosh, Bishwamittra and Wang, Yuan and Fu, Huazhu and Wei, Qingsong and Liu, Yong and Goh, Rick Siow Mong},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Split Learning of Multi-Modal Medical Image Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1326-1331},
  keywords={Training;Image coding;Computational modeling;Pipelines;Collaboration;Machine learning;Data models;Split-learning;Multi-modal Classification;Multi-label Classification;Privacy-preserving Machine Learning},
  doi={10.1109/CAI59869.2024.00235}
}


@misc{duan2022multimodalalignmentusingrepresentation,
      title={Multi-modal Alignment using Representation Codebook}, 
      author={Jiali Duan and Liqun Chen and Son Tran and Jinyu Yang and Yi Xu and Belinda Zeng and Trishul Chilimbi},
      year={2022},
      eprint={2203.00048},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.00048}, 
}

@article{MACKIEWICZ1993303,
title = {Principal components analysis (PCA)},
journal = {Computers & Geosciences},
volume = {19},
number = {3},
pages = {303-342},
year = {1993},
issn = {0098-3004},
doi = {https://doi.org/10.1016/0098-3004(93)90090-R},
url = {https://www.sciencedirect.com/science/article/pii/009830049390090R},
author = {Andrzej Maćkiewicz and Waldemar Ratajczak},
keywords = {Principal Components Analysis, Variance-covariance matrix, Coefficients of determination, Eigenvalues, Eigenvectors, Correlation matrix, Bartlett's statistics, FORTRAN 77},
}