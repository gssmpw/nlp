% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").



@misc{lin2022truthfulqameasuringmodelsmimic,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@misc{christiano2023deepreinforcementlearninghuman,
      title={Deep reinforcement learning from human preferences}, 
      author={Paul Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
      year={2023},
      eprint={1706.03741},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.03741}, 
}

@misc{sharma2023understandingsycophancylanguagemodels,
      title={Towards Understanding Sycophancy in Language Models}, 
      author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Newton Cheng and Esin Durmus and Zac Hatfield-Dodds and Scott R. Johnston and Shauna Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
      year={2023},
      eprint={2310.13548},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.13548}, 
}

@misc{cotra2021Whyaialignmentcouldbehardwithmoderndeeplearning,  title={Why ai alignment could be hard with modern
deep learning}, 
author={
    Ajeya Cotra}, 
year={2021},
archivePrefix={Cold Takes},
url={https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/}
}



@misc{miehling2024languagemodelsdialogueconversational,
      title={Language Models in Dialogue: Conversational Maxims for Human-AI Interactions}, 
      author={Erik Miehling and Manish Nagireddy and Prasanna Sattigeri and Elizabeth M. Daly and David Piorkowski and John T. Richards},
      year={2024},
      eprint={2403.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.15115}, 
}
@inproceedings{Zheng_2022, series={CHI ’22},
   title={UX Research on Conversational Human-AI Interaction: A Literature Review of the ACM Digital Library},
   url={http://dx.doi.org/10.1145/3491102.3501855},
   DOI={10.1145/3491102.3501855},
   booktitle={CHI Conference on Human Factors in Computing Systems},
   publisher={ACM},
   author={Zheng, Qingxiao and Tang, Yiliu and Liu, Yiren and Liu, Weizi and Huang, Yun},
   year={2022},
   month=apr, collection={CHI ’22} }

@misc{yang2024largelanguagemodelsoptimizers,
      title={Large Language Models as Optimizers}, 
      author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le and Denny Zhou and Xinyun Chen},
      year={2024},
      eprint={2309.03409},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.03409}, 
}

@misc{laban2024surechallengingllmsleads,
      title={Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment}, 
      author={Philippe Laban and Lidiya Murakhovs'ka and Caiming Xiong and Chien-Sheng Wu},
      year={2024},
      eprint={2311.08596},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08596}, 
}

@misc{wei2024simplesyntheticdatareduces,
      title={Simple synthetic data reduces sycophancy in large language models}, 
      author={Jerry Wei and Da Huang and Yifeng Lu and Denny Zhou and Quoc V. Le},
      year={2024},
      eprint={2308.03958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.03958}, 
}


@misc{malmqvist2024sycophancylargelanguagemodels,
      title={Sycophancy in Large Language Models: Causes and Mitigations}, 
      author={Lars Malmqvist},
      year={2024},
      eprint={2411.15287},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15287}, 
}

@misc{sirdeshmukh2025multichallengerealisticmultiturnconversation,
      title={MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs}, 
      author={Ved Sirdeshmukh and Kaustubh Deshpande and Johannes Mols and Lifeng Jin and Ed-Yeremai Cardona and Dean Lee and Jeremy Kritz and Willow Primack and Summer Yue and Chen Xing},
      year={2025},
      eprint={2501.17399},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.17399}, 
}

@article{wang2024mmlu,
  title={Mmlu-pro: A more robust and challenging multi-task language understanding benchmark},
  author={Wang, Yubo and Ma, Xueguang and Zhang, Ge and Ni, Yuansheng and Chandra, Abhranil and Guo, Shiguang and Ren, Weiming and Arulraj, Aaran and He, Xuan and Jiang, Ziyan and others},
  journal={arXiv preprint arXiv:2406.01574},
  year={2024}
}

@article{hendryckstest2021,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}


@misc{wang2024mintevaluatingllmsmultiturn,
      title={MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback}, 
      author={Xingyao Wang and Zihan Wang and Jiateng Liu and Yangyi Chen and Lifan Yuan and Hao Peng and Heng Ji},
      year={2024},
      eprint={2309.10691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.10691}, 
}

@misc{nirman2024foolmefoolme,
      title={Fool Me, Fool Me: User Attitudes Toward LLM Falsehoods}, 
      author={Diana Bar-Or Nirman and Ariel Weizman and Amos Azaria},
      year={2024},
      eprint={2412.11625},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11625}, 
}

@misc{shaikh2024cbevalframeworkevaluatinginterpreting,
      title={CBEval: A framework for evaluating and interpreting cognitive biases in LLMs}, 
      author={Ammar Shaikh and Raj Abhijit Dandekar and Sreedath Panat and Rajat Dandekar},
      year={2024},
      eprint={2412.03605},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03605}, 
}


@misc{lou2024anchoringbiaslargelanguage,
      title={Anchoring Bias in Large Language Models: An Experimental Study}, 
      author={Jiaxu Lou and Yifan Sun},
      year={2024},
      eprint={2412.06593},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.06593}, 
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

AI Anthropic. 2024a. The claude 3 model family: Opus,
sonnet, haiku. Claude-3 Model Card.

@misc{anthropicclaude3model, 
    title={The Claude 3 Model Family: Opus, Sonnet, Haiku}, 
    author={Anthropic}, 
    year={2024},
    url={https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf}
}
@misc{openaigpt4omini,
    title={GPT-4o mini: advancing cost-efficient intelligence}, 
    author={OpenAI}, 
    year={2024}, 
    url={https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}
}

@misc{ou2024dialogbenchevaluatingllmshumanlike,
      title={DialogBench: Evaluating LLMs as Human-like Dialogue Systems}, 
      author={Jiao Ou and Junda Lu and Che Liu and Yihong Tang and Fuzheng Zhang and Di Zhang and Kun Gai},
      year={2024},
      eprint={2311.01677},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.01677}, 
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Meta},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{rrv2024chaoskeywordsexposinglarge,
      title={Chaos with Keywords: Exposing Large Language Models Sycophantic Hallucination to Misleading Keywords and Evaluating Defense Strategies}, 
      author={Aswin RRV and Nemika Tyagi and Md Nayem Uddin and Neeraj Varshney and Chitta Baral},
      year={2024},
      eprint={2406.03827},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03827}, 
}@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}