\begin{abstract}

We present a method leveraging extreme learning machine (ELM) type
randomized neural networks (NNs) for learning the exact time integration
algorithm for initial value problems. The exact time integration
algorithm for non-autonomous (including autonomous) systems
can be represented by an algorithmic function in higher dimensions,
which satisfies an associated system of partial differential equations with
corresponding boundary conditions.
Our method learns the algorithmic function by solving this associated system
using ELM with a physics informed approach.
The trained ELM network serves as the learned algorithm and can be
used to solve the initial value problem with arbitrary initial data
or arbitrary step sizes from some domain.
When the right hand side of the non-autonomous system exhibits a
periodicity with respect to any of its arguments, while 
the solution itself to the problem is not periodic, we show that in this case
the algorithmic function is either periodic, or when it is not,
satisfies a well-defined relation for different periods.
This property can greatly simplify the network training for algorithm
learning  in many problems.
We consider explicit and implicit NN formulations, leading to
explicit and implicit time integration algorithms, and discuss
how to train the ELM network by the nonlinear least squares method.
Extensive numerical experiments with benchmark problems,
including non-stiff, stiff and chaotic systems, show that the learned NN
algorithm produces highly accurate solutions in long-time simulations,
with its time-marching errors decreasing nearly exponentially with increasing
degrees of freedom  in the neural
network. We compare extensively the computational performance (time-marching accuracy
vs.~time-marching cost) between the current NN algorithm and
the leading traditional time integration algorithms. The learned NN
algorithm is computationally competitive, markedly outperforming
the traditional algorithms in many problems.



\end{abstract}
