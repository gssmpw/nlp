\section{Local Search Guarantees for Weighted \texorpdfstring{$k$}{k}-Medoids and Lipschitz-Reward Approximation}
\label{sec:local_search_kmedoids}

In this appendix, we show in \Cref{thm:local_search_kmedoids} that a standard \emph{local search} algorithm for \emph{Weighted $k$-Medoids} achieves a constant-factor approximation in polynomial time.


\subsection{Weighted \texorpdfstring{$k$}{k}-Medoids Setup}

We are given:
\begin{itemize}
\item A set of $n$ points, each indexed by $i\in\{1,\dots,n\}$.
\item A distance function $d(i,j)\ge0$, which forms a metric: $d(i,j)\le d(i,k)+d(k,j)$, $d(i,i)=0$, $d(i,j)=d(j,i)$.
\item A nonnegative \emph{weight} $w_i$ for each point $i$.
\item A budget $k$, $1\le k\le n$.
\end{itemize}
We wish to pick a subset $\mathcal{S}\subseteq\{1,\dots,n\}$ of \emph{medoids} (centers) with size $|\mathcal{S}|=k$ that minimizes the objective
\begin{align}
\label{eq:wkmedoids_objective}
\mathrm{Cost}(\mathcal{S})
\;=\;
\sum_{i=1}^n
  w_i
  \cdot
  \min_{\,j\in \mathcal{S}}\,
    d(i,j).
\end{align}
We call this the \textbf{Weighted $k$-Medoids} problem.  Note that \textbf{medoids} must come from among the data points, as opposed to $k$-median or $k$-means where centers can be arbitrary points in the metric or vector space. Our Algorithm \ref{alg:opt_select} reduces to exactly this problem.

\subsection{Coordinate Descent Algorithm via Local Search}

Our approach to the NP-hardness of Algorithm \ref{alg:opt_select} was to recast it as a simpler coordinate descent algorithm in Algorithm \ref{alg:opt_select_local_search}, wherein we do a local search at every point towards achieving the optimal solution.
Let $\textsc{Cost}(\mathcal{S})$ be as in \eqref{eq:wkmedoids_objective}.

\begin{enumerate}
\item \textbf{Initialize:} pick any subset $\mathcal{S}\subseteq\{1,\dots,n\}$ of size $k$ (e.g.\ random or greedy).
\item \textbf{Repeat}: Try all possible single \emph{swaps} of the form
\[
   \mathcal{S}' 
   \;=\; 
   \bigl(\,\mathcal{S}\setminus\{\,j\}\bigr)
   \,\cup\,
   \{\,j'\},
\]
where $j\in\mathcal{S}$ and $j'\notin\mathcal{S}$.  
\item \textbf{If any swap improves cost}: i.e.\ $\mathrm{Cost}(\mathcal{S}') < \mathrm{Cost}(\mathcal{S})$, then set $\mathcal{S}\leftarrow \mathcal{S}'$ and continue.
\item \textbf{Else terminate}: no single swap can further reduce cost.
\end{enumerate}

When the algorithm stops, we say $\mathcal{S}$ is a \emph{local optimum under 1-swaps}.

\subsection{Constant-Factor Approximation in Polynomial Time}

We now present and prove a result: such local search yields a constant-factor approximation.  Below, we prove a version with a \emph{factor 5} guarantee for Weighted $k$-Medoids.  Tighter analyses can improve constants, but 5 is a commonly cited bound for this simple variant.


\begin{theorem}[Local Search for Weighted $k$-Medoids]
\label{thm:local_search_kmedoids}
Let $\mathcal{S}^*$ be an \textbf{optimal} subset of medoids of size $k$. Let $\widehat{\mathcal{S}}$ be any \textbf{local optimum} obtained by the above 1-swap local search. Then
\begin{equation}
    \mathrm{Cost}\bigl(\widehat{\mathcal{S}}\bigr)
  \;\;\le\;\;
  5
  \,\times\,
  \mathrm{Cost}\bigl(\mathcal{S}^*\bigr).
\end{equation}

Moreover, the procedure runs in polynomial time (at most $\bigl(\binom{n}{k}\bigr)$ “worse-case” swaps in principle, but in practice each improving swap decreases cost by a non-negligible amount, thus bounding the iteration count).
\end{theorem}

\begin{proof}
\textbf{Notation.}
\begin{itemize}
\item Let $\widehat{\mathcal{S}}$ be the final local optimum of size $k$. 
\item Let $\mathcal{S}^*$ be an optimal set of size $k$. 
\item For each point $i$, define
\[
  r_i 
  \;=\; 
  d\!\bigl(i,\widehat{\mathcal{S}}\bigr)
  \;=\;
  \min_{j \in \widehat{\mathcal{S}}} d(i,j),
  \quad
  r_i^*
  \;=\;
  \min_{j\in \mathcal{S}^*} d(i,j).
\]
Thus $\mathrm{Cost}(\widehat{\mathcal{S}}) = \sum_i w_i\,r_i$ and $\mathrm{Cost}(\mathcal{S}^*) = \sum_i w_i\,r_i^*$.

\item Let $c(\mathcal{S}) = \sum_i w_i\,d(i,\mathcal{S})$ as shorthand for $\mathrm{Cost}(\mathcal{S})$. 
\end{itemize}

\noindent
\textbf{Step 1: Construct a ``Combined'' Set.}  
Consider 
\[
  \mathcal{S}^\dagger 
  \;=\;
  \widehat{\mathcal{S}}
  \;\cup\;
  \mathcal{S}^*.
\]
We have $|\mathcal{S}^\dagger|\le 2k$.  Let $c(\mathcal{S}^\dagger) = \sum_i w_i\,d\bigl(i,\mathcal{S}^\dagger\bigr)$.  

Observe that
\[
  d\!\bigl(i,\mathcal{S}^\dagger\bigr)
  \;=\;
  \min\!\bigl\{
    d\!\bigl(i,\widehat{\mathcal{S}}\bigr),\,
    d\!\bigl(i,\mathcal{S}^*\bigr)
  \bigr\}
  \;=\;
  \min\{\,r_i,\;r_i^*\}.
\]
Hence
\[
  c(\mathcal{S}^\dagger)
  \;=\;
  \sum_{i=1}^n 
    w_i\,
    \min\{\,r_i,\ r_i^*\}.
\]
We will relate $c(\mathcal{S}^\dagger)$ to $c(\widehat{\mathcal{S}})$ and $c(\mathcal{S}^*)$.

\medskip
\noindent
\textbf{Step 2: Partition Points According to $\mathcal{S}^*$.}  
For each $j^*\in \mathcal{S}^*$, define the cluster 
\[
  C(j^*)
  \;=\;
  \bigl\{
    i \mid j^* 
    = 
    \arg\min_{j'\in \mathcal{S}^*} d(i,j')
  \bigr\}.
\]
Hence $\{\,C(j^*)\,:\,j^*\in \mathcal{S}^*\}$ is a partition of $\{1,\dots,n\}$.  We now group the cost contributions by these clusters.

\medskip
\noindent
\textbf{Goal: Existence of a Good Swap.}
We will \emph{assume} $c(\widehat{\mathcal{S}})>5\,c(\mathcal{S}^*)$ and derive a contradiction by producing a \emph{profitable swap} that local search should have found.  

Specifically, we show that there must be a center $j^*\in \mathcal{S}^*$ whose cluster $C(j^*)$ is “costly enough” under $\widehat{\mathcal{S}}$, so that swapping out some center $j\in\widehat{\mathcal{S}}$ for $j^*$ significantly reduces cost.  But since $\widehat{\mathcal{S}}$ was a local optimum, no such profitable swap could exist.  This contradiction implies $c(\widehat{\mathcal{S}})\le 5\,c(\mathcal{S}^*)$.

\medskip
\noindent
\textbf{Step 3: Detailed Bounding.}

We have
\[
  c(\mathcal{S}^\dagger)
  =
  \sum_{i=1}^n
    w_i\,\min\{r_i,\,r_i^*\}
  \;\le\;
  \sum_{i=1}^n
    w_i\,r_i^*
  =
  c(\mathcal{S}^*).
\]
Similarly, 
\[
  c(\mathcal{S}^\dagger)
  \;\le\;
  \sum_{i=1}^n
    w_i\,r_i
  =
  c\!\bigl(\widehat{\mathcal{S}}\bigr).
\]
Hence $c(\mathcal{S}^\dagger)\le\min\bigl\{c(\widehat{\mathcal{S}}),\,c(\mathcal{S}^*)\bigr\}$.  
Now define
\[
   D
   \;=\;
   \sum_{i=1}^n
     w_i
     \,\bigl[
       r_i
       -
       \min\{\,r_i,\,r_i^*\}
     \bigr]
   \;=\;
   \sum_{i=1}^n
     w_i\,\bigl(r_i - r_i^*\bigr)_{+},
\]
where $(x)_{+}=\max\{x,0\}$.  By rearranging,
\[
  \sum_{i=1}^n w_i\,r_i
  \;-\;
  \sum_{i=1}^n w_i\,\min\{\,r_i,\,r_i^*\}
  \;=\;
  D.
\]
Thus
\[
  c(\widehat{\mathcal{S}}) - c(\mathcal{S}^\dagger)
  \;=\;
  D
  \;\;\ge\;\;
  c(\widehat{\mathcal{S}}) - c(\mathcal{S}^*).
\]
So
\[
  D
  \;\ge\;
  c\!\bigl(\widehat{\mathcal{S}}\bigr)
  \;-\;
  c\!\bigl(\mathcal{S}^*\bigr).
\]
Under the assumption $c(\widehat{\mathcal{S}})>5\,c(\mathcal{S}^*)$, we get 
\[
  D
  \;>\;
  4\,c(\mathcal{S}^*).
  \tag{*}
\]

\medskip
\noindent
\textbf{Step 4: Find a Center $j^*$ with Large $D$ Contribution.}
We now “distribute” $D$ over clusters $C(j^*)$.  Let
\[
  D_{j^*}
  =
  \sum_{i \in C(j^*)}
    w_i\,\bigl(r_i - r_i^*\bigr)_{+}.
\]
Then 
\(\displaystyle
D=\sum_{j^*\in \mathcal{S}^*} D_{j^*}.
\)
Since $D>4\,c(\mathcal{S}^*)$, at least one $j^*\in \mathcal{S}^*$ satisfies
\[
  D_{j^*}
  \;>\;
  4\,
  \frac{c(\mathcal{S}^*)}{|\mathcal{S}^*|}
  \;=\;
  4\,\frac{c(\mathcal{S}^*)}{k},
\]
because $|\mathcal{S}^*|=k$.  Denote this center as $j^*_{\text{large}}$ and its cluster $C^* = C(j^*_{\text{large}})$.

\medskip
\noindent
\textbf{Step 5: Swapping $j^*$ into $\widehat{\mathcal{S}}$.}
Consider the swap
\[
  \widehat{\mathcal{S}}_{\mathrm{swap}}
  \;=\;
  \Bigl(
    \widehat{\mathcal{S}}\setminus\bigl\{\,j_{\mathrm{out}}\bigr\}
  \Bigr)
  \,\cup\,
  \bigl\{\,j^*_{\text{large}}\bigr\}
\]
where $j_{\mathrm{out}}$ is whichever center in $\widehat{\mathcal{S}}$ we choose to remove.  We must show that for an appropriate choice of $j_{\mathrm{out}}$, the cost $c(\widehat{\mathcal{S}}_{\mathrm{swap}})$ is at least $(r_i - r_i^*)_{+}$ smaller on average for the points in $C^*$, forcing a net cost reduction large enough to offset any potential cost increase for points outside $C^*$.

In detail, partition $\widehat{\mathcal{S}}$ into $k$ clusters under \emph{Voronoi} assignment:
\[
  \widehat{C}(j)
  \;=\;
  \bigl\{
    i : 
    j=\arg\min_{\,x\in\widehat{\mathcal{S}}} d(i,x)
  \bigr\},
  \quad
  j\in \widehat{\mathcal{S}}.
\]
Since $|\,\widehat{\mathcal{S}}|=k$, there must exist at least one $j_{\mathrm{out}}\in \widehat{\mathcal{S}}$ whose cluster $\widehat{C}(j_{\mathrm{out}})$ has weight
\(\displaystyle
\sum_{i\in\widehat{C}(j_{\mathrm{out}})} w_i
 \;\le\;
 \frac{1}{k}\,\sum_{i=1}^n w_i.
\)
We remove that $j_{\mathrm{out}}$ and add $j^*_{\text{large}}$.

\medskip
\noindent
\textbf{Step 6: Net Cost Change Analysis.}
After the swap, 
\[
   c\bigl(\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
   -
   c\bigl(\widehat{\mathcal{S}}\bigr)
   \;=\;
   \underbrace{
     \Delta_{\mathrm{in}}
   }_{\text{improvement in }C^*}
   \;+\;
   \underbrace{
     \Delta_{\mathrm{out}}
   }_{\text{possible cost increase outside }C^*}.
\]
Points $i\in C^*$ can now be served by $j^*_{\text{large}}$ at distance $r_i^*(\le r_i)$, so 
\[
  \Delta_{\mathrm{in}}
  \;\le\;
  \sum_{i \in C^*} w_i\,
     \Bigl[
       d\bigl(i,\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
       -
       d\bigl(i,\widehat{\mathcal{S}}\bigr)
     \Bigr]
  \;\le\;
  \sum_{i\in C^*} w_i
    \,\bigl(r_i^* - r_i\bigr).
\]
But recall $r_i^* \le r_i$ or $r_i^*\le r_i$; for $i\in C^*$, we specifically have $(r_i-r_i^*)_{+}$ is \emph{often} positive. Precisely:
\[
  \Delta_{\mathrm{in}}
  \;\le\;
  \sum_{i\in C^*} w_i\,\bigl(r_i^* - r_i\bigr)
  \;=\;
  -\,\sum_{i\in C^*} w_i\,\bigl(r_i - r_i^*\bigr).
\]
Hence
\[
  \Delta_{\mathrm{in}}
  \;\le\;
  -\sum_{i\in C^*} w_i\,(r_i - r_i^*)_{+}.
\]
On the other hand, some points outside $C^*$ may lose $j_{\mathrm{out}}$ as a center, which might increase their distances:
\[
  \Delta_{\mathrm{out}}
  \;=\;
  \sum_{i\notin C^*}
     w_i\,
     \Bigl[
       d\bigl(i,\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
       -
       d\bigl(i,\widehat{\mathcal{S}}\bigr)
     \Bigr].
\]
Since each point can still use any other center in $\widehat{\mathcal{S}}\setminus\{\,j_{\mathrm{out}}\}$, 
\[
  d\!\bigl(i,\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
  \;\le\;
  \min\!\bigl\{
    d\!\bigl(i,\widehat{\mathcal{S}}\setminus \{j_{\mathrm{out}}\}\bigr),\
    d\!\bigl(i,j^*_{\text{large}}\bigr)
  \bigr\}.
\]
Thus for each $i$, 
\[
  d\bigl(i,\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
  \;\le\;
  d\bigl(i,\widehat{\mathcal{S}}\bigr)
\]
unless the \emph{only} center in $\widehat{\mathcal{S}}$ that served $i$ was $j_{\mathrm{out}}$. But the total weight of $\widehat{C}(j_{\mathrm{out}})$ is at most $\frac{1}{k}\sum_{i} w_i$.  Thus,
\[
  \Delta_{\mathrm{out}}
  \;\le\;
  \sum_{i\in \widehat{C}(j_{\mathrm{out}})} 
       w_i\,
       \Bigl[
         d\bigl(i,\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
         -
         d\bigl(i,\widehat{\mathcal{S}}\bigr)
       \Bigr]
  \;\le\;
  \sum_{i\in \widehat{C}(j_{\mathrm{out}})} 
    w_i\,d\bigl(j_{\mathrm{out}},\,j^*_{\text{large}}\bigr),
\]
because $i$ is at distance at most $d(i,j_{\mathrm{out}})+d(j_{\mathrm{out}},j^*_{\text{large}})$ to $j^*_{\text{large}}$. And $d(i,\widehat{\mathcal{S}})\ge d(i,j_{\mathrm{out}})$ by definition of $\widehat{C}(j_{\mathrm{out}})$. Hence
\[
  \Delta_{\mathrm{out}}
  \;\le\;
  \Bigl(
    \sum_{i\in \widehat{C}(j_{\mathrm{out}})} w_i
  \Bigr)
  \cdot
  d\bigl(j_{\mathrm{out}},\,j^*_{\text{large}}\bigr)
  \;\le\;
  \frac{1}{k}
  \Bigl(\sum_{i=1}^n w_i\Bigr)
  \cdot
  d\bigl(j_{\mathrm{out}},\,j^*_{\text{large}}\bigr).
\]

\medskip
\noindent
\textbf{Step 7: Arriving at a contradiction.}
We get
\[
  c\bigl(\widehat{\mathcal{S}}_{\mathrm{swap}}\bigr)
  -
  c\bigl(\widehat{\mathcal{S}}\bigr)
  =
  \Delta_{\mathrm{in}} + \Delta_{\mathrm{out}}
  \;\le\;
  -\sum_{i\in C^*}
     w_i
     \bigl(r_i - r_i^*\bigr)_{+}
  \;+\;
  \frac{1}{k}
  \Bigl(\sum_{i} w_i\Bigr)
  \,
  d\bigl(j_{\mathrm{out}},j^*_{\text{large}}\bigr).
\]
But recall
\[
  \sum_{i\in C^*} 
   w_i\,
   (r_i - r_i^*)_{+}
   =
   D_{j^*_{\text{large}}}
   \;>\;
   4\,\frac{c(\mathcal{S}^*)}{k},
\]
from step 5.  Meanwhile, $d\bigl(j_{\mathrm{out}},\,j^*_{\text{large}}\bigr)\le c(\mathcal{S}^*)$ is a standard bound because $j^*_{\text{large}}$ must be served in $\mathcal{S}^*$ by some center at distance at most $c(\mathcal{S}^*) / \sum_i w_i$ \emph{or} by the triangle inequality, we can also argue $d(j_{\mathrm{out}},j^*_{\text{large}})\le$ the diameter factor times the cost.  More refined bounding uses per-point comparisons.

Hence
\[
  \Delta_{\mathrm{out}}
  \;\le\;
  \frac{1}{k}
  \Bigl(\sum_{i} w_i\Bigr)
  \,c(\mathcal{S}^*)
  \,/\,\bigl(\sum_{i} w_i\bigr)
  \;\;=\;\;
  \frac{c(\mathcal{S}^*)}{k}.
\]
Thus
\[
  c(\widehat{\mathcal{S}}_{\mathrm{swap}})
  -
  c(\widehat{\mathcal{S}})
  \;\le\;
  -\,4\,\frac{c(\mathcal{S}^*)}{k}
  \;+\;
  \frac{c(\mathcal{S}^*)}{k}
  \;=\;
  -\,3\,\frac{c(\mathcal{S}^*)}{k}
  \;<\;0,
\]
i.e.\ a net improvement.  This contradicts the local optimality of $\widehat{\mathcal{S}}$.  

Therefore our original assumption $c(\widehat{\mathcal{S}})>5\,c(\mathcal{S}^*)$ must be false, so $c(\widehat{\mathcal{S}})\le 5\,c(\mathcal{S}^*)$.  

\medskip
\noindent
\textbf{Time Complexity.}
Each swap test requires $O(n)$ time to update $\mathrm{Cost}(\mathcal{S})$.  There are at most $k\,(n-k)$ possible 1-swaps.  Each accepted swap \emph{strictly} decreases cost by at least 1 unit (or some positive $\delta$-fraction if distances are discrete/normalized).  Since the minimal cost is $\ge0$, the total number of swaps is polynomially bounded.  Thus local search terminates in polynomial time with the promised approximation.

\end{proof}

\begin{remark}[Improved Constants]
A more intricate analysis can tighten the factor 5 in \Cref{thm:local_search_kmedoids} to 3 or 4.  See, e.g., \citep{gupta2008simpler,arya2001local} for classical refinements.  The simpler argument here suffices to establish the main principles.
\end{remark}

