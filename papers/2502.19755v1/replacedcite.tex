\section{Background and Related Work}
\label{sec:related}
In this section, we give an overview of the fields of OOD detection and adversarial machine learning, highlighting techniques relevant to our approach. We then review adversarial OOD detection and describe a number of prior robust OOD detection methods.

\subsection{Out-of-Distribution Detection}

The task of out-of-distribution (OOD) detection involves distinguishing between inputs drawn from the training distribution (in-distribution or ID samples) and those drawn from other distributions (out-of-distribution or OOD samples) ____. Many approaches have been proposed to perform this task, including score-based approaches where a higher score is more indicative of an OOD sample. Broadly, score-based approaches can be broken down into confidence based ____, energy based ____ and deriving from a learned discriminator ____. Other methods focus on measuring distance between samples in normal ____ and hyper-spherical embedding spaces ____.
Another line of work has explored giving models access to outlier samples from an 
auxiliary training set $\mathcal{D}_{\text{oe}}$ ____. This method, called outlier exposure, works by training on the following objective:
\begin{equation}
    \mathcal{L}_{\text{OE}} = \mathbb{E}_{(\bm{x},y) \sim \mathcal{D}_{\text{in}}} [\text{CE}(f_\theta(\bm{x}), y)] + \lambda \cdot \mathbb{E}_{\bm{x}' \sim \mathcal{D}_{\text{oe}}} [\text{KL} (f_\theta(\bm{x}') , \mathcal{U})]
    \label{eq:outlier_exposure}
\end{equation}
where the standard cross-entropy (CE) loss term is paired with a KL divergence term that pushes output on OE samples towards the uniform distribution. Recent work has also explored generating synthetic outliers ____ and using large pre-trained image-text models ____ to improve performance.

\subsection{Adversarial Attacks and Defences} \label{sec:advml}
Adversarial attacks are small, often imperceptible modifications to inputs to a model that change the class label that the model assigns to the input  ____. The field of adversarial machine learning is concerned both with developing new methods of attack as well as techniques to produce robust models that perform better under these attacks.

\textbf{Adversarial Attacks:} An adversarial example for an image $\bm{x}$ with class label $y$ is defined as $\bm{x}' = \bm{x} + \bm{\delta}$, where $\bm{\delta}$ is a perturbation that satisfies some constraint designed to ensure its imperceptibility to humans, usually that the $\ell_p$ norm of delta $||\bm{\delta}||_p$ is less than some $\epsilon$. We denote the set of such allowable perturbations $\mathcal{S}$. Perturbations are usually constructed to maximise the loss function $\text{CE}(f_\theta(\bm{x}+\bm{\delta}), y)$, thus lowering classification accuracy. 

Projected gradient descent (PGD) ____ is a common method used to produce adversarial perturbations. It constructs $\bm{\delta}$ by making a number of additive gradient steps of size $\alpha$ in the direction of maximum loss:
\begin{equation}
\bm{\delta}^{(t+1)}_{\text{PGD}} = \Pi_{\mathcal{S}} \bigl( \bm{\delta}^{(t)}_\text{PGD} + \alpha \cdot \text{sign}(\nabla_{\bm{x}} \text{CE}(f_\theta(\bm{x} + \bm{\delta}^{(t)}_{\text{PGD}}), y) \bigr)
\label{eq:pgd_delta}
\end{equation}
where $\Pi_{\mathcal{S}}$ denotes projection onto the set of allowed perturbations $\mathcal{S}$.

AutoAttack ____ is a more recent, stronger method that comprises four independent attacks and is widely considered to provide a more reliable estimate of robustness against various types of adversaries.

\textbf{Adversarial Defences:} In parallel to the development of adversarial attacks, many works have proposed methods to produce \textit{adversarially robust} classifiers ____. This task has proven difficult, with all methods that are effective in increasing robust accuracy resulting in significant reductions in clean accuracy ____. As such, a primary focus of research in this area has been to optimise the trade-off between robust accuracy and clean accuracy. An early work that achieves robustness to various attacks is standard adversarial training (SAT) ____. This method treats training as a min-max game, optimising the normal cross-entropy objective in the presence of a simulated adversary. Specifically, AT aims to minimise: 
\begin{equation}
\mathcal{L}_{\text{AT}} = 
\mathbb{E}_{(\bm{x},y)\sim\mathcal{D}} \bigl[ \max_{\bm{\delta} \in \mathcal{S}} \text{CE}(f_\theta(\bm{x} + \bm{\delta}), y) \bigr]
\label{eq:madry_at}
\end{equation}
where the inner maximisation is approximated using a PGD attack. ____ leverage a better theoretical understanding of the trade-off between clean and robust accuracy to develop TRADES, an improvement on SAT. TRADES has separate terms for clean accuracy and robustness, using a hyperparameter $\beta$ to control their relative importance:
\begin{equation}
\begin{split}
\mathcal{L}_{\text{TRADES}} &= 
\mathbb{E}_{(\bm{x},y)\sim\mathcal{D}} \bigl[ \text{CE}(f_\theta(\bm{x}), y) \\
&+ \beta \cdot \max_{\bm{\delta} \in \mathcal{S}} \text{KL} (f_\theta(\bm{x}) , f_\theta(\bm{x} + \bm{\delta})) \bigr]
\label{eq:trades}
\end{split}
\end{equation}

Helper Adversarial Training (HAT) ____ is a more recent method that attempts to further improve the clean/robust trade-off by reducing the excessive decision boundary margin that is introduced by existing adversarial training methods. It works by defining a helper example $\Tilde{\bm{x}} = \bm{x} + 2 \bm{\delta}$ and helper label $\Tilde{y} = \argmax f_{std}(\bm{x}+\bm{\delta})$ where $f_{std}$ is a standard (non-robust) model. We can then optimise the following objective: 
\begin{equation}
\begin{split}
\mathcal{L}_{\text{HAT}} &= 
\mathbb{E}_{(\bm{x},y)\sim\mathcal{D}} \bigl[ \text{CE}(f_\theta(\bm{x}), y) \\
&+ \beta \cdot \max_{\bm{\delta} \in \mathcal{S}} \text{KL} (f_\theta(\bm{x}) , f_\theta(\bm{x} + \bm{\delta})) \\
&+ \gamma \cdot \text{CE}(f_\theta(\Tilde{\bm{x}}), \Tilde{y}) \bigr]
\label{eq:hat}
\end{split}
\end{equation}

This has the effect of encouraging the model to be invariant in its output to attacks of the specified strength $\epsilon$, but less so beyond that. HAT is shown to improve the trade off between clean and robust accuracy compared to TRADES, while achieving a similar robust accuracy ____. Recently, other works have explored mixing standard and robust model output ____ and incorporating extra data from pseudo-labelling ____ or diffusion models ____ to achieve better results.

\subsection{Adversarial OOD Detection} \label{sec:advood}
Though not as well studied as the problems of (clean) OOD detection and (classification) adversarial robustness, the field of adversarial OOD detection has received meaningful attention in recent years ____.

Unlike \textit{classification} attacks in which the adversary aims to induce misclassification, detection attacks instead try to fool the detection module of a network. These attacks can naturally be separated into two types: \textbf{ID$\rightarrow$OOD} attacks which modify ID samples in an attempt to have the detector erroneously flag them as OOD, and \textbf{OOD$\rightarrow$ID} attacks which modify OOD samples to evade detection by the model. For clarity, we give a schematic diagram of each of these attacks in Figure \ref{fig:attack_vis}. We can also consider performing OOD detection when both of these attacks occur at the same time, which as noted by ____ is a strictly harder setting as the perturbation budget is effectively doubled. As approaches to OOD detection vary, the exact method used by the adversary also needs to change to produce a strong attack. When using the baseline method of MSP for example, it is desirable for the model's output to have a high entropy (uniform) distribution on OOD samples and a low entropy (peaked) distribution on ID samples. Correspondingly, OOD$\rightarrow$ID and ID$\rightarrow$OOD attacks for this method aim to increase/decrease the divergence between the model's output distribution and the uniform distribution, respectively. Details for other methods are given in Appendix \ref{apdx:detection_attacks}.

\subsection{Prior Robust OOD Detection Works}

ACET ____ is one of the first methods to tackle the problem of robust OOD detection, training jointly on standard CE loss and an (attacked) OE objective: 
\begin{equation}
\begin{split}
    \mathcal{L}_{\text{ACET}} &= 
    \mathbb{E}_{(\bm{x},y) \sim \mathcal{D}_{\text{in}}} \bigl[\text{CE}(f_\theta(\bm{x}), y)\bigr] \\
    &+ \lambda \cdot \mathbb{E}_{\bm{x}' \sim \mathcal{D}_{\text{oe}}} \bigl[\max_{\bm{\delta} \in \mathcal{S}}\text{CE}(f_\theta(\bm{x}'+\bm{\delta}), \mathcal{U})\bigr]
    \label{eq:ACET}
\end{split}
\end{equation}
where an OOD$\rightarrow$ID attack is performed using PGD to find $\bm{\delta}$. ATOM ____ takes a somewhat similar approach, training a classification model with $K+1$ classes, where a positive detection is made when $\textsc{SoftMax}(f_\theta(\bm{x}))_{K+1} \geq \gamma$ for some threshold $\gamma$. Training utilises a supplementary OE dataset where a subset of the samples are attacked to push them closer to the detection decision boundary. Both ACET and ATOM only consider robustness on OOD samples, leaving them vulnerable to ID$\rightarrow$OOD attacks. ALOE ____ and RATIO\footnote{Both ALOE and RATIO optimise the same objective function, but consider the case of the $\ell_\infty$ and $\ell_2$ norm respectively. In our comparisons we use ALOE as we also focus on the $\ell_\infty$ norm.} ____ seek to rectify this issue, attacking both the ID and OE datasets during training. This amounts to optimising the following objective, where $\lambda$ is a hyperparameter controlling the relative importance of the OE term: 
\begin{equation}
\begin{split}
    \mathcal{L}_{\text{ALOE}} &= 
    \mathbb{E}_{(\bm{x},y) \sim \mathcal{D}_{\text{in}}} \bigl[\max_{\bm{\delta} \in \mathcal{S}}\text{CE}(f_\theta(\bm{x}+\bm{\delta}), y)\bigr] \\
    &+ \lambda \cdot \mathbb{E}_{\bm{x}' \sim \mathcal{D}_{\text{oe}}} \bigl[\max_{\bm{\delta} \in \mathcal{S}}\text{CE}(f_\theta(\bm{x}'+\bm{\delta}), \mathcal{U})\bigr]
    \label{eq:aloe}
\end{split}
\end{equation}

Another method aiming at both ID and OOD robustness is OSAD ____ which trains an encoder with dual-attentive feature-denoising layers and uses the representations it produces as input to a classification head. This is paired with an OpenMax ____ layer for OOD detection. Further, Adversarially Trained Discriminator (ATD) ____ is a recent method that utilises a pre-trained robust classification model for feature extraction and trains a discriminator to perform OOD detection on these features. It additionally uses an OE dataset and a generator (trained in tandem with the discriminator) to gain exposure to a diverse distribution of outliers during training. 

Other recent works have explored certified OOD detection ____, robust one class classification ____ and the use of pre-trained image-text models to supplement OE data ____.

%%%%%%%%% METHODOLOGY