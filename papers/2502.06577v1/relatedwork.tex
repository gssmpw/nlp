\section{Related Work}
\label{sec:related-work}

Recent research has explored the integration of causality and multi-armed bandit (MAB) frameworks.
As mentioned in \Cref{sec:introduction}, \citet{lattimore2016bandits} introduced the original causal bandit problems, which involve hard interventions in causal models.
Subsequent works \citep{rajat2017identifying, yabe2018causal, lu2020regret, nair2021budgeted,sawarni2023learning,maiti2022causal,feng2023combinatorial} proposed algorithms for variants of causal bandits with both hard and soft interventions, budget constraints, and unobserved confounders, all under specific assumptions, such as binary variables, simple graphs, or known post-intervention distributions.
Note that we do not make such assumptions.

Recent works in ``contextual causal bandits'' address interventions that account for context, bearing a superficial resemblance to our problem.
However, our problem remains distinct.
In \Citet{madhavan2024contextual}, the term "contexts" is used in a very different way, actually referring to different graphs as opposed to different variable values.
\Citet{subramanian2022contextual,subramanian2024causal} tackle the scenario in which an intervention is performed, with knowledge of a given set of context variables, on a \emph{pre-chosen} variable $X$ that has an edge into $Y$ (and no other outgoing edges).
This approach can be understood as selecting a conditional intervention for a predefined node from a very simple graph.
In contrast, in our setting we need to choose what variable to intervene on to begin with, and there are no restrictions on the causal graph.

All of the works described above proposed algorithms which aim at accelerating learning by utilizing knowledge of the causal model.
As explained in \Cref{sec:introduction}, this contrasts with the work by \citet{lee2018structural,lee2019structural}, which, just like our work, uses knowledge of the causal graph to find a minimal search space (over the nodes) for causal bandits.
While they focus on multi-node, hard interventions, we focus on single-node, conditional interventions.

The work of \Citet{lee2020characterizing} presents an interesting connection to our work.
Given a causal graph, they study the sets of pairs $(\mathrm{node}, \mathrm{context(node)})$ (referred to as ``scopes'') that may correspond to an optimal (multi-node) intervention policy where each node $X$ in a scope is intervened on according to a policy $\pi_{X}(X \mid \mathrm{context(X)})$.
This is a challenging problem, and they do not provide a full characterization of these optimal scopes, instead deriving a set of rules that can be used to compare certain pairs of scopes.
In this paper, we instead assume that the practitioner knows the appropriate conditioning set $\condset_{X}$ (context) to use and impose only minimal restrictions on what $\condset_{X}$ can be, focusing instead on choosing the nodes that can yield the best results.
While \citet{lee2020characterizing} consider multi-node interventions, it would be interesting in future work to adapt their ideas to the single-node case to identify the smallest $\condset_{X}$ sets for which the best policy can still be found.
Such an approach
could further accelerate learning by MAB algorithms.