\section{Introduction}
\label{sec:introduction}
\noindent
Amongst different design focuses, 5G standards have specifically addressed low-latency requirements to  cater safety-critical and mission-critical applications~\cite{2020_comst_5G_latency}. Industrial automation within Industry 4.0 is an example of new perspectives that are triggered by such a new capability. To reach low-latency targets, the 5G New Radio (NR) standard has defined the Ultra-Reliable Low Latency Communication (URLLC), which allows for reaching a few ms one-way latency with small radio frames~\cite{2021_access_urllc}. Furthermore, to improve the end-to-end latency, the 5G architecture has integrated distributed cloud infrastructures enabled by the ETSI standard for Multi-access Edge Computing (MEC)~\cite{MEC003}, which brings compute, storage and network resources next to the end-user devices. Indeed, processing data at the networkâ€™s edge instead of transferring it to remote cloud data centres is beneficial not only to reduce bandwidth requirements and access times but also to increase the ability of the network providers to satisfy the needs of complex real-time applications~\cite{2018_comst_mec_iot,2021_jnca_edge}.  

Another important pillar of the 5G standards is the network slice concept that allows sharing the same 5G infrastructure amongst multiple service providers. This aims at improving network flexibility and service customisation and, in the end, maximising 5G operator revenue. There are several definition of a network slice~\cite{NFV028,NFV012,NGMN028,3GPPTR28801,IETFFarrel}. However, all have agreed that a (network) slice is a logical network composed of dedicated and shared network resources providing specific network capabilities and characteristics. One of the key features of network slicing is isolation between (network) slice instances at different levels, namely at the data plane, the control plane and the management plane. Furthermore, a network slice needs to span not only over different architectural levels but also over different technological domains (e.g., access, core and transport networks). Therefore, the definition of end-to-end (E2E) network slicing frameworks that seamlessly interconnect different slice segments (or slice subnets in 5G terminology) is an open research challenge~\cite{ZSM003}. Furthermore, as latency should be managed end-to-end, there is a clear need to establish and manage an E2E network slice including the MEC~\cite{MEC024}. The most mature proposal to enable the instantiation of a network slice embedding MEC components is the MEC-in-NFV architecture~\cite{MEC003}, which proposes to use Network Function Virtualisation (NFV) technologies to virtualise MEC applications and MEC management entities. Recently, a few research works have attempted to extend the MEC-in-NFV orchestration architecture to allow not only multiple tenants (namely MEC applications) to co-exist in the same network slice but also the sharing of multiple network slices with the same tenant~\cite{Cominardi2020,2020_MNET_MEC_subslice}. However, those proposals implicitly assume that only an end customer (e.g., a UE requesting a specific service) can be a tenant of a MEC platform. On the contrary, in this study, we advocate a more articulated multi-tenancy model in which an operator of a MEC infrastructure (we call it MEC Owner) interacts with the 5G system and offers virtualised MEC environments to multiple tenants (we call them MEC Customers). Then, a MEC Customer acts as an application service provider towards its end users. This architectural design has multiple benefits. First, it allows the deployment of MEC environments that are dedicated (and optimised) to specific application domains. For instance, a MEC Customer can offer specialised services to car manufacturers that want to deploy automotive applications. In contrast, another MEC Customer can offer specialised services to law enforcement agencies in a city that want to deploy video analytics applications (e.g. traffic monitoring, crowd control). However, both MEC Customers can share the same MEC infrastructure deployed by a MEC Owner in a given city. Second, this architecture facilitates a clear distinction between management roles and businesses responsibilities of different stakeholders, as the orchestration of edge-related resources is clearly separated from the orchestration of network-related resources. We argue that this is an important improvement over existing proposals that normally delegate the management and orchestration of application components to the orchestrator already contained within an NFV architecture, as in~\cite{Cominardi2020}. To some extent, this is equivalent to moving from a sliced MEC management platform to a fully \textit{sliced MEC orchestration} capability. Finally, our proposal also permits to clearly distinguish responsibilities in terms of contribution to application latency budget, as the MEC Owner is essentially responsible for the network latency in the edge platform, while the MEC Customer is essentially responsible for data processing and storage latencies.

This paper achieves the above goals through a fourfold contribution. First, we introduce the new concepts of Application Slice (APS) and Application Service (AS), which allows for better distinguishing between the management and orchestration of application and network services. Second, we propose an end-to-end slice architecture together with the related operational and business roles, which spans over all the domains of an end-to-end application service. This architecture design allows for considering all processing and storage latencies, especially those within the MEC. Third, we propose an overall management architecture that allows the life-cycle management of such end-to-end slices, following two distinct deployment models. We also show how this general management architecture can be instantiated into a multi-tenant MEC infrastructure with two layers of virtualisation and orchestration, which is enabled by emerging nested virtualisation capabilities~\cite{MEC024}. Fourth, we propose a preliminary implementation of the described architecture focusing on the MEC domain and the MEC Customer orchestrator. We also show experimental results to validate the feasibility of our design approach and its ability to support performance isolation between deployed application slices.  

The rest of this paper is organised as follows. Section~\ref{sec:background} provides background information about the network slicing concept, the 3GPP slice management architecture and the MEC standard. Section~\ref{sec:app_slice} presents our proposed end-to-end application slice management architecture and how it can be instantiated in the context of MEC and 5G systems. Section~\ref{sec:implementation} describes our proof-of-concept implementation and Section~\ref{sec:evaluation} shows experimental results. Finally, we conclude with section~\ref{sec:conclusions} where we provide some hints on our future works. 

%This paper is focusing on slicing within the MEC with regards to latency perspective. It proposes to split the MEC slice into two different slice subnets: a pure network slice subnet which supports a MEC network slice and an application slice subnet which supports a MEC application slice. The reason for this dichotomy is that the two slices are of different characteristics. While the MEC network slice can support 3GPP-defined Communication Services (CSes) \cite{3GPPTS28530} built from Network Functions (NFs) and Virtual Network Functions (VNFs) \cite{NFV003} with CS Service Level Agreement framework (SLA), MEC application slice essentially supports Application Services (ASes) similarly built from applications and from what we call in this document as Application Component Functions (ACFs) and with SLA framework very much application oriented (e.g. data backup service). 

%The notion of MEC application slice allows for isolating cloud resources assigned to a particular MEC application in order to meet this application processing latency budget. This could be performed at the granularity of MEC application.

%In terms of operation, we advocate for a multi-tenant MEC architecture with two main types of actors. The first one who owns the MEC hardware infrastructure is called the MEC Owner. He/she is responsible to manage MEC network slices while interacting with the 5G system to synchronise in terms of forwarding rules. Within such a partitioned MEC infrastructure, a MEC Customer is assigned a dedicated network slice. The MEC Customer is responsible to manage the MEC application slices. Thus, each actor is responsible for part of the MEC latency budget, the MEC Owner essentially network latency and the MEC Customer essentially processing and storage latency.

%MEC-architecture
%Moreover, MEC resources are managed by two different types of actors: the MEC infrastructure owner and the MEC customer. Generally speaking, the MEC owner is likely to manage the MEC network slice while the MEC customer is to manage the MEC application slice. In this paper, we particularly focus on cases where the MEC customer is offered at least means to orchestrate cloud resources either at the VM level (e.g. access to OpenStack API) or at the container level (e.g. access to Kubernetes API) to meet latency constraints. In the case where the MEC customer only subscribes for a SaaS, the MEC owner is responsible for the management and the orchestration of both the MEC network slice and the MEC application slice. However, the latter case does not present the interesting issues related to multi-actor interaction in terms of end-to-end latency management.