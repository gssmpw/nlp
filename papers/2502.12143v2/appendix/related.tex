\section{Related Work}

\subsection{Chain-of-Thought}

Early research on CoT primarily focused on short CoT, where models produce succinct reasoning paths to reach a solution \citep{lambert2025tulu3pushingfrontiers, longpre2023flancollectiondesigningdata, wei2023chainofthoughtpromptingelicitsreasoning, yu2024metamathbootstrapmathematicalquestions}.
Recently, researchers have turned to long CoT prompting, which encourages the generation of extended and detailed reasoning chains 
\citep{DeepSeekAI2025DeepseekR1, hou2025advancinglanguagemodelreasoning, kimi2025k15, sky_t1_2025, openai2024learning, tinyzero, zeng2025simplerl}. 
The model systematically explores multiple paths (branching) and reverts to earlier points if a particular path proves wrong (backtracking). Although several studies have investigated methods such as distillation and reinforcement learning to integrate long CoT capabilities into LLMs, these efforts have predominantly concentrated on large models. In contrast, our work specifically targets the challenges associated with training smaller models.


\subsection{Synthetic Reasoning Data}
Although human-crafted reasoning datasets have been used to enhance LLM reasoning capabilities \cite{hendrycks2021measuringmathematicalproblemsolving, numina_math_datasets}, their development is both time-consuming and labor-intensive. 
% As a promising alternative, synthetic dataset generation has gained significant attention.
Recent advancements have streamlined this process by generating instructions or responses directly from LLMs \citep{hui2024smallerlanguagemodelsbetter, toshniwal2024openmathinstruct2acceleratingaimath, xu2024magpiealignmentdatasynthesis, yue2023mammothbuildingmathgeneralist, zhang2025bestinstructiontuningdatafit} or extracting data directly from web \citep{paster2023openwebmathopendatasethighquality, yue2024mammoth2scalinginstructionsweb}, yielding more detailed and diverse chain-of-thought reasoning pathways. Recent study has investigated the impact of various response generators \citep{kim2024evaluatinglanguagemodelssynthetic}, suggesting that in the domains of instruction following and reasoning, responses from stronger teacher models do not necessarily produce the most effective learning effects for student models. However, these investigations have not recognized student model size as a critical factor influencing this phenomenon, nor have they performed the more attribution and mitigation analyses as in this paper.
