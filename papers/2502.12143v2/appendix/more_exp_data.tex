\section{More Experiments Results}
\label{appendix: More Experiments}
In this section we present additional experiment results of long CoT gap and large teacher CoT gap.
\subsection{Long CoT Gap: Additional Results}
Table \ref{tab:full_performance_lg} shows the detailed performance scores and gap of each benchmark for different student models fine-tuned on long CoT and short CoT.
\texttt{QwQ-32B-Preview} is chosen to generate long CoT and awhile \texttt{Qwen-2.5-32B-Instruct} is chosen to generate short CoT. We observe that small student models tend to benefit more from short CoT, while large student models gain greater advantages from long CoT. 
\input{tables/long_CoT_full_table}
\subsection{Large Teacher CoT Gap: Additional Results}
Table \ref{tab:lmp-full_comparison} shows the detailed performance scores and gap of each benchmark for different student models distilled from large teacher and small teacher.
We summarize the performance of 10 student models from the Llama and Qwen families across various model sizes. \texttt{Qwen-2.5-72B-Instruct} is chosen as the large teacher while \texttt{Qwen-2.5-3B-Instruct} is chosen as the small teacher. The results are shown in Table \ref{tab:lmp-full_comparison}. Our findings indicate that small student models may experience degraded performance when distilled from a large teacher compared to a small teacher, whereas larger student models benefit more from distilling a large teacher.

Table \ref{tab:lmp_comparison2} shows more experiment results for teacher models in different model families, including \texttt{Gemma-27B-it} vs \texttt{Gemma-9B-it} and \texttt{Llama3.1-72B-Instruct} vs \texttt{Llama3.1-8B-Instruct}. 

\input{tables/strong_model_CoT_full_table}
\input{tables/lmp_more_teachers}