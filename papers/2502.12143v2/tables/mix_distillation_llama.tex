\begin{table*}[ht]
    \small
    \centering
    \caption{Our proposed \textbf{Mix Distillation} method outperforms the baseline models across most metrics. We use Llama3.2-3B-Instruct as the student model and MATH training dataset (7.5k) as the training set. We distill different teacher models to generate responses as the baseline. Our proposed Mix-Long combines long CoT data and normal CoT data in a 0.2:0.8 ratio, while Mix-Large combines strong model response and weak model response with the same proportion. Experimental results demonstrate that both Mix-Long and Mix-Large surpass baselines in most evaluation metrics.}
    \label{tab:performance2}
    \resizebox{0.9\textwidth}{!}{%
    \begin{tabular}{l c c c c c c}
        \toprule
        Distillation Method & MATH  & AMC   & GSM8k   & \makecell{Olympiad \\ Bench} & AIME    &Average  \\
        \midrule
        QwQ-32B (Long CoT)       & 0.487  & 0.175  & 0.751   & \underline{0.176}  & \underline{0.033}  &0.325  \\
        Qwen2.5-32B (Normal CoT)     & 0.509  & 0.150  & 0.775   & \textbf{0.187} & \underline{0.033}  &0.331  \\
        Qwen2.5-72B (Strong Model Response)   & 0.474  & \textbf{0.250}  & 0.712   & 0.169  & \underline{0.033}  &0.328  \\
        Qwen2.5-3B (Weak Model Response)    & 0.479  & 0.175  & 0.741   & 0.164  & \underline{0.033}  &0.312  \\
        Deepseek-R1-32B (Long CoT)         & 0.485  & 0.175  & \underline{0.777}  & 0.161  & \textbf{0.067}   & 0.333  \\
        \midrule
        \multicolumn{1}{l}{\textit{Ours}} & & & & & & \\
        Mix-Long       & \textbf{0.530}  & \underline{0.225}  & \textbf{0.794}  & 0.172 & \underline{0.033}  &\textbf{0.351}  \\
        Mix-Large     & \underline{0.518}  & \textbf{0.250}  & 0.763   & 0.172 & \underline{0.033}  & \underline{0.347}  \\
        \bottomrule
    \end{tabular}%
    }

        
\end{table*}
