
\begin{table*}[htbp]
  \centering
  \resizebox{1\textwidth}{!}{%
  \begin{tabular}{l*{5}{ccc}c}
    \toprule
    & \multicolumn{3}{c}{MATH} 
    & \multicolumn{3}{c}{GSM8k} 
    & \multicolumn{3}{c}{AIME} 
    & \multicolumn{3}{c}{AMC} 
    & \multicolumn{3}{c}{Olympiad} 
    & \multicolumn{1}{c}{\makecell{Average \\ $\Delta_{\rm Strong}$}} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
    Model 
    & $P_{\rm Strong}$ & $P_{\rm Weak}$ & $\Delta_{\rm Strong}$ 
    & $P_{\rm Strong}$ & $P_{\rm Weak}$ & $\Delta_{\rm Strong}$ 
    & $P_{\rm Strong}$ & $P_{\rm Weak}$ & $\Delta_{\rm Strong}$ 
    & $P_{\rm Strong}$ & $P_{\rm Weak}$ & $\Delta_{\rm Strong}$ 
    & $P_{\rm Strong}$ & $P_{\rm Weak}$ & $\Delta_{\rm Strong}$ 
    & \\ 
    \midrule
    Llama-3.2-1B      & 29.8   & 29.6   & \cellcolor{green!2}{0.160} 
                      & 44.4   & 47.5   & \cellcolor{red!32}{-3.18} 
                      & 0.00   & 0.00   & \cellcolor{white}{0.00} 
                      & 2.50   & 7.50   & \cellcolor{red!50}{-5.00} 
                      & 6.07   & 7.70   & \cellcolor{red!16}{-1.63} 
                      & \cellcolor{red!19}{-1.93} \\
    Llama-3.2-3B      & 47.4   & 47.9   & \cellcolor{red!5}{-0.500} 
                      & 71.2   & 74.1   & \cellcolor{red!29}{-2.88} 
                      & 3.33   & 0.00   & \cellcolor{green!33}{3.33} 
                      & 25.0   & 17.5   & \cellcolor{green!75}{7.50} 
                      & 16.9   & 16.4   & \cellcolor{green!4}{0.445} 
                      & \cellcolor{green!16}{1.58} \\
    Llama-3.2-8B      & 37.6   & 37.6   & \cellcolor{red!1}{-0.040} 
                      & 67.0   & 69.2   & \cellcolor{red!22}{-2.20} 
                      & 6.67   & 0.00   & \cellcolor{green!67}{6.67} 
                      & 7.50   & 7.50   & \cellcolor{white}{0.00} 
                      & 9.19   & 11.0   & \cellcolor{red!18}{-1.78} 
                      & \cellcolor{green!5}{0.530} \\
    Llama-3.2-70B     & 74.5   & 72.2   & \cellcolor{green!23}{2.28} 
                      & 92.0   & 92.2   & \cellcolor{red!2}{-0.152} 
                      & 16.7   & 16.7   & \cellcolor{white}{0.00} 
                      & 67.5   & 50.0   & \cellcolor{green!100}{17.5} 
                      & 37.3   & 35.7   & \cellcolor{green!16}{1.63} 
                      & \cellcolor{green!43}{4.25} \\
    \midrule
    Qwen2.5-0.5B      & 30.0   & 31.0   & \cellcolor{red!9}{-0.920} 
                      & 43.1   & 45.4   & \cellcolor{red!24}{-2.35} 
                      & 0.00   & 0.00   & \cellcolor{white}{0.00} 
                      & 5.00   & 17.5   & \cellcolor{red!100}{-12.5} 
                      & 6.52   & 8.30   & \cellcolor{red!18}{-1.78} 
                      & \cellcolor{red!35}{-3.51} \\
    Qwen2.5-1.5B      & 50.3   & 50.7   & \cellcolor{red!4}{-0.440} 
                      & 70.6   & 71.0   & \cellcolor{red!5}{-0.455} 
                      & 0.00   & 3.33   & \cellcolor{red!33}{-3.33} 
                      & 22.5   & 20.0   & \cellcolor{green!25}{2.50} 
                      & 17.8   & 20.0   & \cellcolor{red!22}{-2.22} 
                      & \cellcolor{red!8}{-0.790} \\
    Qwen2.5-3B        & 57.5   & 60.3   & \cellcolor{red!28}{-2.82} 
                      & 79.9   & 79.5   & \cellcolor{green!4}{0.379} 
                      & 0.00   & 3.33   & \cellcolor{red!33}{-3.33} 
                      & 35.0   & 27.5   & \cellcolor{green!75}{7.50} 
                      & 25.9   & 26.4   & \cellcolor{red!4}{-0.444} 
                      & \cellcolor{green!3}{0.256} \\
    Qwen2.5-7B        & 71.3   & 63.6   & \cellcolor{green!77}{7.66} 
                      & 87.8   & 84.1   & \cellcolor{green!37}{3.72} 
                      & 6.67   & 0.00   & \cellcolor{green!67}{6.67} 
                      & 40.0   & 35.0   & \cellcolor{green!50}{5.00} 
                      & 38.8   & 29.0   & \cellcolor{green!98}{9.78} 
                      & \cellcolor{green!66}{6.56} \\
    Qwen2.5-14B       & 76.4   & 72.8   & \cellcolor{green!37}{3.66} 
                      & 93.1   & 89.6   & \cellcolor{green!35}{3.49} 
                      & 6.67   & 3.33   & \cellcolor{green!33}{3.33} 
                      & 47.5   & 45.0   & \cellcolor{green!25}{2.50} 
                      & 41.0   & 39.0   & \cellcolor{green!21}{2.07} 
                      & \cellcolor{green!30}{3.01} \\
    Qwen2.5-32B       & 80.5   & 76.8   & \cellcolor{green!37}{3.72} 
                      & 92.2   & 92.7   & \cellcolor{red!5}{-0.531} 
                      & 20.0   & 3.33   & \cellcolor{green!100}{16.7} 
                      & 57.5   & 50.0   & \cellcolor{green!75}{7.50} 
                      & 47.4   & 42.4   & \cellcolor{green!50}{5.04} 
                      & \cellcolor{green!65}{6.48} \\
    \bottomrule
  \end{tabular}
  }


\caption{This table summarizes the performance of models in Llama and Qwen families fine-tuned with large teacher CoT and small teacher CoT when evaluated on MATH, GSM8K, AIME, AMC, and OlympiadBench. \texttt{Qwen-2.5-72B-Instruct} is chosen as the large teacher while \texttt{Qwen-2.5-3B-Instruct} is chosen as the small teacher. We observe that small student models may experience degraded performance when distilled from a large teacher compared to a small teacher, whereas larger student models benefit more from the distilling a large teacher.}
\label{tab:lmp-full_comparison}
\end{table*}
