\section{Conclusion and Future Work}
In this paper, we show that long CoT data and large model responses were not uniformly beneficial for small student models. We found that small models may perform better when fine-tuned with short CoT and small model CoT.
We termed this challenge as the Small Model Learnability Gap.
The reason behind it may be that small student models excel on data that closely match their inherent distribution but struggle with significant distribution shifts.  
To bridge the gap, we introduced Mix Distillation, including Mix-Long, which combined long CoT and short CoT data in a ratio, and Mix-Large, which integrated large and small teacher CoT. 
Experimental results showed that both Mix-Long and Mix-Large outperform baselines across most evaluation metrics, which implied mix distillation outperforms training on a single data distribution. This paper provided practical insights for optimizing post-training strategies to enhance small language model reasoning capability.

We will explore several promising directions as future work. First, we will refine mix distillation by optimally combining diverse data sources and proposing more fine-grained mixing algorithms to boost reasoning capabilities. Second, we propose to study how strong reasoning teachers can generate data that is better suited for tuning small student models, thereby facilitating more effective knowledge transfer. Third, we will conduct further theoretical and model interpolability studies on the small model learnability gap. Lastly, we will investigate which SFT methods yield the best initial policies for subsequent RL procedure, ultimately enhancing overall model performance.


\section*{Acknowledgment}


This work is partially supported by the Air Force Office of Scientific Research (AFOSR) under grant FA9550-23-1-0208, the Office of Naval Research (ONR) under grant N0014-23-1-2386, and the National Science Foundation (NSF) AI Institute for Agent-based Cyber Threat Intelligence and Operation (ACTION) under grant IIS 2229876.


This work is supported in part by funds provided by the National Science Foundation, Department of Homeland Security, and IBM. 
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the NSF or its federal agency and industry partners.
