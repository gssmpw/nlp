Single-source domain generalization (SDG) in medical image segmentation remains a significant challenge, particularly for images with varying color distributions and qualities. 
Previous approaches often struggle when models trained on high-quality images fail to generalize to low-quality test images due to these color and quality shifts. 
In this work, we propose two novel techniques to enhance generalization: dynamic color image normalization (DCIN) module and color-quality generalization (CQG) loss. 
The DCIN dynamically normalizes the color of test images using two reference image selection strategies. 
Specifically, the DCIN utilizes a global reference image selection (GRIS), which finds a universal reference image, and a local reference image selection (LRIS), which selects a semantically similar reference image per test sample. 
Additionally, CQG loss enforces invariance to color and quality variations by ensuring consistent segmentation predictions across transformed image pairs. 
Experimental results show that our proposals significantly improve segmentation performance over the baseline on two target domain datasets, despite being trained solely on a single source domain. 
Notably, our model achieved up to a 32.3-point increase in Dice score compared to the baseline, consistently producing robust and usable results even under substantial domain shifts. 
% Notably, our full DCIN pipeline (GRIS + LRIS) achieves superior generalization compared to existing methods, including those using human-expert-selected references. 
Our work contributes to the development of more robust medical image segmentation models that generalize across unseen domains.
The implementation code is available at \url{https://github.com/RaviShah1/DCIN-CQG}.
