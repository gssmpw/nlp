Accurate segmentation of medical images is crucial for computer-aided diagnosis, healthcare systems, and clinical research. 
In recent years, with the rapid development of deep learning techniques, the performance of medical image segmentation tasks has been significantly improved \cite{qureshi2023medical, azad2024medical}. 
However, these deep learning-based models tend to perform well when trained and tested on datasets from a single domain but perform poorly when faced with data from different domains, which is known as the domain shift problem. 
To improve the generalization of these models on new test cases, we could use larger datasets that include a diverse range of high-quality images. 
However, obtaining such extensive medical datasets is very challenging, primarily due to the obstacles in data collection and sharing, as well as the high expenses associated with labeling. 

One solution to the problem of domain shift is to use unsupervised domain adaptation (UDA) techniques. 
In the UDA setting, segmentation models are trained on labeled data from a source domain, as well as unlabeled data from the target domain, in order to better generalize to the target domain \cite{guan2021domain, kumari2024deep}. 
However, a drawback of this method is that the target domain must be known in advance, which may not be possible in medical applications. 
Additionally, if the target domain changes, a new model would need to be re-trained, which can be difficult or impossible to accomplish in real-world scenarios. 

Another potential approach for overcoming the above issue is to employ domain generalization (DA) methods \cite{matta2024systematic, yoon2024domain}. 
These methods are designed to improve generalization by training only from labeled source domains without accessing data from unseen target domains. 
The DA methods could be divided into two categories: multi-source domain generalization (MDG) and single-source domain generalization (SDG). 
The former, MDG methods, normally require training on two or more labeled source domains. 
However, as previously noted, this is problematic due to the limited availability of medical images from various domains in real-world settings. 
On the other hand, the SDG methods are known to be more practical as these methods use training data from only one source domain but generalize it to unseen target data from multiple domains. 
Through these SDG methods, significant improvements in performance have been observed in the medical image segmentation tasks \cite{su2023rethinking,hu2023devil,yang2024single,liu2024universal,jiang2025structure}. 
% Fig. 1
\input{figures/tex_files/Fig_1}

Despite achieving promising results, they largely rely on the assumption of minimal domain distribution shifts. 
In practice, large domain shifts, particularly with color medical images, can lead to a noticeable decline in the performance of SDG segmentation models. 
Fig. \ref{fig:fig_1} depicts instances of failure from a throat segmentation model which was trained on high-quality (HQ) color throat images captured from a professional camera but tested on low-quality (LQ) images acquired from other camera models. 
While performing well on the HQ domain (first row), the model was unable to capture semantic information from other domains (second to last rows). 
In practice, failure cases are more likely to occur since LQ color medical images (e.g., low-resolution, noise, etc.,) such as endoscopic throat images are often obtained with very complex degradations during the acquisition process \cite{cap2025practical}. 
As we experienced, this decline in segmentation performance is mainly due to the differences in color between domains. In addition, previous studies have shown that the decisions of deep networks are greatly influenced by the color differences between datasets \cite{afifi2019else,de2021impact}. 
Therefore, we believe the implementation of advanced techniques for color distribution alignment has the potential to improve the segmentation performance. 

Color normalization is a common technique to mitigate the effects of domain shift in medical imaging \cite{macenko2009method, vahadane2016structure}. 
However, from our observations, segmentation results vary depending on the chosen reference images, making the selection of suitable reference images for testing a challenging task. 
While expert-selected reference images may provide guidance, this process remains highly subjective and dependent on individual judgment. 
In this work, we first propose a dynamic color image normalization (DCIN) method that dynamically selects suitable reference images from the training data and transfers the color distribution of test images to match that of the reference image. 
We show that the performance of segmentation models is better when using our DCIN module compared to expert reference image selection. 

To further enhance the robustness of the segmentation models, we introduce a training objective function called color-quality generalization (CQG) as our second proposal. 
The CQG loss is a contrastive-based loss with the idea that an image in different color and quality conditions should have the same segmentation outputs. 
These two proposals effectively mitigate the issue of large domain shifts and significantly improve the performance of SDG segmentation models. 
Experiments demonstrate that our proposed method results in large increases in DICE scores across all segmentation models on two other domain datasets, with a maximum improvement of 32.3 points over the baseline. 
Moreover, our method is model agnostic which can be adapted to any SGD color image segmentation model.  
% Fig. 2
\input{figures/tex_files/Fig_2}