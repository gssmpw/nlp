%\documentclass[a4paper,onecolumn,11pt,unpublished]{quantumarticle}
%\pdfoutput=1
%\usepackage{lipsum}


\documentclass[
    aps,
    pra,
    longbibliography,
    % a4paper,
    superscriptaddress,amsmath,amssymb,amsfonts, 
    tightenlines,
    twocolumn,
    % 10pt
    ]{revtex4-2} 

    
    
\usepackage[utf8]{inputenc}  %Input what you want e.g., Ã©, Å, a, ÃŒ
\usepackage[T1]{fontenc}     %Output what you want e.g., Ã©, Å, a, ÃŒ
\usepackage[english]{babel}  %Do hyphenation according to british english


%\usepackage[sc,osf]{mathpazo}\linespread{1.05}  %Palatino font
  % URL font that go well wtih palatino
%\usepackage[scaled=1.03]{inconsolata} %Monospace font
%\usepackage{hyperref}  %Hyperlinks (pink, green, blue)
\usepackage[colorlinks = true, linkcolor=teal, citecolor=teal, urlcolor  = teal]{hyperref}


\usepackage{graphicx} % Package to insert external figures
\usepackage[babel]{microtype}  %Improves text justification
\usepackage{amsmath,amssymb,amsthm,bm,amsfonts,mathrsfs,bbm} %Useful math packages
\usepackage{setspace}
\usepackage{times}
\usepackage{braket}
\usepackage[bottom]{footmisc}
\usepackage{blochsphere}
\usepackage{pgfplots}
\usepackage{amsthm}
%\usepackage{subcaption}
% Do not use, this clashes with other packages


\pgfplotsset{compat=1.17}
\usetikzlibrary{calc,3d,shapes, pgfplots.external, intersections}
\usepackage{algorithm}
\usepackage{physics}
% \usepackage[noend]{algpseudocode}
\usepackage[noend]{algorithmic}
\usepackage{eqparbox}
\renewcommand\algorithmiccomment[1]{%
  \hfill\#\ \eqparbox{COMMENT}{#1}%
}
%\usepackage{physics}
%\usepackage{subfig}
\usepackage{tikz}
\usepackage{mathtools}
%\usepackage{mathabx}
\usetikzlibrary{arrows.meta}
\usepackage{csquotes}
\renewcommand{\qedsymbol}{\rule{0.7em}{0.7em}}
%\renewcommand{\qedsymbol}{$\blacksquare$}
\usepackage{xspace}  %Useful to add space in macros
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{amsmath}
%\usepackage[shortlabels]{enumitem}
% \captionsetup{style=base}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\je}[1]{{\color{cyan}\textbf{JE:  #1}}}
\newcommand{\yw}[1]{{\color{violet}\textbf{YW:  #1}}}
\newcommand{\roxie}[1]{{\color{blue}\textbf{roxie:  #1}}}

\newtheorem{theorem}{Theorem}


\newtheoremstyle{note}% <name>
{3pt}% <Space above>
{3pt}% <Space below>
{}% <Body font>
{}% <Indent amount>
{\itshape}% <Theorem head font>
{:}% <Punctuation after theorem head>
{.5em}% <Space after theorem headi>
{}% <Theorem head spec (can be left empty, meaning `normal')>


\newtheorem{acknowledgement}[theorem]{Acknowledgement}

\newcommand{\Lagr}{\mathcal{L}}
\def\bracket#1#2{{\langle#1|#2\rangle}}
\def\expect#1{{\langle#1\rangle}}
\def\e{{\rm e}}
\def\proj{{\hat{\cal P}}}

\def\H{{\hat H}}
\def\Htot{{\bf \hat H}}
\def\Hint{{\hat H}_{\rm int}}
\def\Hbint{{\bf \hat H}_{\rm int}}
\def\L{{\hat L}}
\def\Ldag{{\hat L}^\dagger}
\def\U{{\hat U}}
\def\Udag{{\hat U}^\dagger}
\def\field{{\hat\phi}}
\def\conj{{\hat p}}
\def\P{{\hat{\vec P}}}
\def\Op{{\hat O}}


\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand\id{\leavevmode\hbox{\small1\kern-3.3pt\normalsize1}}


\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\bst}{\bs{\theta}}
\newcommand{\bsy}{\bs{y}}
\newcommand{\bsx}{\bs{x}}
\newcommand{\bsz}{\bs{0}}
\newcommand{\bse}{\bs{e}}
\newcommand{\lV}{\left\Vert}
\newcommand{\rV}{\right\Vert}
\newcommand{\cH}{{\cal H}}
\newcommand{\al}{\hat{\alpha}}
\newcommand{\be}{\hat{\beta}}
\newcommand{\tet}{\vartheta}
\newcommand{\fii}{\varphi}
\newcommand{\M}{{_{(M)}}}
\newcommand{\vt}{\widetilde{v}\, }
\newcommand{\alphas}{{\al_1, \dots\, ,\al_N}}
\newcommand{\mus}{{\mu_1, \dots\, ,\mu_N}}
\newcommand{\betas}{{\be_1 \be_2 \dots \be_N}}
\newcommand{\mbbC}{\mathbb{C}}
\newcommand{\mbbR}{\mathbb{R}}
\newcommand{\x}{{\bf x}}
\newcommand{\xp}{{\bf x'}}
\newcommand{\y}{{\bf y}}
\newcommand{\p}{{\bf p}}
\newcommand{\q}{{\bf q}}
\newcommand{\hq}{\hat{q}}
\newcommand{\hp}{\hat{p}}
\newcommand{\hrho}{\hat{\rho}}
\newcommand{\ha}{\hat{a}}
\newcommand{\had}{\hat{a}^\dagger}
\newcommand{\kk}{{\bf k}}
\newcommand{\kp}{{\bf k'}}
\newcommand{\rr}{{\bf r}}
\newcommand{\s}{{\bf s}}
\newcommand{\z}{{\bf z}}
\newcommand{\A}{{\bf \al}}
\newcommand{\sqd}{\frac{1}{\sqrt{2}}}
%\newcommand{\tr}{\mbox{Tr}}
\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{assumption}{Assumption}

\definecolor{jens}{rgb}{0.1,0.4,0.6}

\newcommand{\newtext}[1]{{\textcolor{black}{#1}}}

\newcommand\DSD[1]{{\color{blue} \bf DSD: #1}}
\newcommand\DP[1]{{\color{red} \bf DP: #1}}

\newcommand\JPL[1]{{\color{red} \bf JPL: #1}}



\usepackage{pdfpages}
\usepackage{pgffor}
\makeatletter
\AtBeginDocument{\let\LS@rot\@undefined}
\makeatother

\begin{document}

\title{Towards efficient quantum algorithms for diffusion probability models}

\author{Yunfei Wang}
% \email{yunfeizl@umd.edu}
\email{Equal contribution}
\affiliation{Joint Center for Quantum Information and Computer Science, NIST/University of Maryland, College Park, MD 20742, USA}
\affiliation{Maryland Center for Fundamental Physics, Department of Physics, University of Maryland, College Park, MD 20742, USA}

\author{Ruoxi Jiang}
% \email{roxie62@uchicago.edu}
\email{Equal contribution}
\affiliation{Department of Computer Science, University of Chicago Chicago, IL 60637}

\author{Yingda Fan}
% \email{yif47@pitt.edu}
\affiliation{Department of Computer Science, The University of Pittsburgh, Pittsburgh, PA 15260, USA}

\author{Xiaowei Jia}
%\email{xiaowei@pitt.edu}
\affiliation{Department of Computer Science, The University of Pittsburgh, Pittsburgh, PA 15260, USA}

\author{Jens Eisert}
\email{jense@zedat.fu-berlin.de}
\affiliation{Dahlem Center for Complex Quantum Systems, Freie Universit{\"a}t Berlin, 14195 Berlin, Germany}

\author{Junyu Liu}
\email{junyuliu@pitt.edu}
\affiliation{Department of Computer Science, The University of Pittsburgh, Pittsburgh, PA 15260, USA}

\author{Jin-Peng Liu}
\email{liujinpeng@tsinghua.edu.cn}
\affiliation{Yau Mathematical Sciences Center and Department of Mathematics, Tsinghua University, Beijing 100084, China}
\affiliation{Yanqi Lake Beijing Institute of Mathematical Sciences and Applications, Beijing 100407, China}

\maketitle


%\je{I would prefer `quantum algorithms' over `quantum ODE solvers', as it can be a bit unfortunate to have abbreviations in titles.}
%\JPL{Sure, let's still use ``towards efficient quantum algorithms for diffusion probability models''. I am also okay with ``towards efficient quantum solvers for diffusion probability models''}

%\je{Wonderful to see how the paper develops.}

%$*$: Equal contribution.
%\\
%\\

{\bf A diffusion probabilistic model (DPM) is a generative model renowned for its ability to produce high-quality outputs in tasks such as image and audio generation. However, training DPMs on large, high-dimensional datasets—such as high-resolution images or audio—incurs significant computational, energy, and hardware costs. In this work, we introduce efficient quantum algorithms for implementing DPMs through various quantum ODE solvers. These algorithms highlight the potential of quantum Carleman linearization for diverse mathematical structures, leveraging state-of-the-art quantum linear system solvers (QLSS) or linear combination of Hamiltonian simulations (LCHS). Specifically, we focus on two approaches: DPM-solver-$k$ which employs exact $k$-th order derivatives to compute a polynomial approximation of $\epsilon_\theta(x_\lambda,\lambda)$; and UniPC which uses finite difference of $\epsilon_\theta(x_\lambda,\lambda)$ at different points $(x_{s_m}, \lambda_{s_m})$ to approximate higher-order derivatives. As such, this work represents one of the most direct and pragmatic applications of quantum algorithms to large-scale machine learning models, 
%marking a significant milestone 
presumably talking substantial steps towards
%in 
demonstrating the practical utility of quantum computing.}


%\tableofcontents
\section{{Introduction}}\label{sec:introduction}

Diffusion models, in the 
context of machine learning and, more specifically, deep learning, represent a class of generative models that have garnered significant attention for their novel approach to modeling complex data distributions
\cite{DiffusionModels1,DiffusionModels2,DiffusionModels3,DiffusionModels3,ho2020denoising}. Unlike traditional models
of machine learning, which often rely on explicit likelihood estimation or adversarial training, diffusion models generate data through a gradual, iterative process inspired by the physical concept of diffusion. They 
work by initially introducing noise a data points and then learning how 
to reverse this process, 
effectively denoising the data step-by-step. This framework allows them to generate high-quality samples, often rivaling or surpassing the performance of other generative models, such as \emph{generative adversarial networks} (GANs) \cite{GANS} and \emph{variational autoencoders} (VAEs) \cite{VAE}. The appeal of diffusion models lies in their stability during training and their ability to model intricate, high-dimensional data distributions without requiring complex adversarial setups or delicate balancing of training dynamics. 
\emph{Diffusion probabilistic models} 
(DPM), as we call them, are families of generative
model renowned for their ability to produce high-quality out-
puts in complex tasks such as 
image and audio generation. 

Turning to quantum approaches, quantum computing is widely regarded as one of the most promising alternatives to von Neumann architectures in the post-Moore era \cite{preskill1998lecture}. By leveraging unique quantum features such as superposition and entanglement, quantum computing is anticipated to surpass classical counterparts in specific tasks. These include factoring \cite{shor1999polynomial}, database search \cite{grover1996fast}, simulating complex quantum systems \cite{lloyd1996universal}, sampling \cite{SupremacyReview}, and solving problems in linear algebra \cite{Wang_2024,Harrow_2009}.
Although we are currently still in what can be 
called the \emph{noisy intermediate-scale quantum} (NISQ) era, the concept of a \textit{megaquop machine} offers a vision of a future where quantum computing achieves remarkable reliability and scalability. 
Such a machine, with an error rate per logical gate on the order 
of $10^{-6}$, would surpass the limitations of classical, NISQ, or analog quantum devices. It would have the capacity to execute quantum circuits involving around $100$ logical qubits and 
a circuit depth of 
approximately $10,000$—capabilities far beyond the reach of 
current technology.  
%\je{Moved here from the appendix and deleted there to remove redundancy.}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=1\linewidth]{BigDiffusionModelFigure2.png}
    \caption{
    Sketch of classical (1.) \emph{diffusion probability 
    models} (DPM) and the 
    quantum algorithms proposed here for quantum analogs 
    (2.-4.). We pursue two approaches: 
   This is on 
   the one hand Carlemann linearization for DPM solvers (2.), on the other 
    Carleman linearization for UniPC
    (3.). For both approaches, quantum ODE 
    solvers are
    instrumental in the step before measurement. 
    QLSS stands for \emph{quantum linear system solvers}, LCHS for \emph{linear combination of Hamiltonian simulation}.
   % \je{Please refine.}
   % \JPL{ Not sure whether we should introduce the full words of UniPC and QLSS/LCHS here or not.}
    } 
    \label{fig:BigFigure}
\end{figure*}


In the light of these observations, it is not surprising that  recent years have seen a surge of interest in exploring how quantum algorithms might enhance machine learning tasks, whether in terms of sample complexity, computational complexity, or generalization \cite{biamonte2017quantum,RevModPhys.91.045002,McClean_2016,Wang_2024}.
Indeed, This interest is well motivated by the fact that, for certain structured models, quantum algorithms are proven to vastly outperform their classical counterparts. In fact, rigorous separations have been demonstrated for specific PAC learning problems \cite{PACLearning,DensityModelling,TemmeML}. 
Even constant-depth quantum circuits have been shown to offer advantages over suitably constrained classical circuits \cite{ShortCircuitsLearning}. 
These insights provide strong motivation for the rapidly evolving field of quantum machine learning and give impetus for the thought that quantum computers may well offer computational advantages.

That said, quantum computers excel at tackling highly 
structured problems, while many common machine learning challenges involve highly unstructured data. In the light of this, it remains to 
an extent unclear what practical advantages quantum computers 
might offer for addressing machine learning tasks. Furthermore, it is still uncertain whether proving separations will be the 
most 
effective or even the best approach for advancing the field \cite{PRXQuantum.3.030101}.
For variational approaches \cite{McClean_2016}, 
while being exciting and promising,
no rigorous guarantees and separations of quantum 
over
classical approaches are known yet.
To date, it seems fair to say that  are lacking a framework for devising end-to-end applications of quantum computers for industrially relevant machine learning tasks \cite{Myths}.

In this work, 
we take out-of-the-box steps to establish a fresh avenue towards showing the utility of quantum computers in machine learning tasks.
Concretely, we present novel and efficient quantum algorithms designed for implementing \emph{differential path models} (DPMs) through a variety of quantum \emph{ordinary differential equation} (ODE) solvers. 
Our algorithms showcase the potential of quantum 
Carleman linearization in 
tackling a 
broad range of mathematical structures and problems, leveraging some of the latest advancements in \emph{quantum linear system solvers} 
(QLSS) or \emph{linear combination of Hamiltonian simulation} (LCHS). Specifically, we explore two distinctly
different but related approaches: the DPM-solver-$k$, which utilizes exact $k$-th order derivatives to compute a polynomial approximation of $\epsilon_\theta(x_\lambda, \lambda)$, and UniPC, which approximates higher-order derivatives by employing finite differences of $\epsilon_\theta(x_\lambda, \lambda)$ at multiple points $(x_{s_m}, \lambda_{s_m})$. Furthermore, this 
work represents one of the most direct and pragmatic applications of quantum algorithms to large-scale machine learning models, highlighting a key milestone in demonstrating the tangible benefits and practical utility of quantum computing in real-world tasks. We provide both rigorous statements and numerical results.
While this result may not yet be a full
end-to-end application, by
bridging the gap between theoretical quantum algorithms and their application to complex computational models, we take a significant step, so we think, toward realizing the power of quantum technologies for solving real-world problems in machine learning and beyond. %\je{I am on it. Let us keep the original draft as the supplement.}


\section{{Results}}\label{sec:results}

In this section, we lay out our specific results, both concerning rigorous statements that heuristic numerical statements that are meant to provide further evidence for the functioning of the approach. Substantial more detail on all steps will be presented in the supplemental material.
We will now explain what 
steps we take towards
establishing a fresh direction for demonstrating the utility of quantum computers in machine learning tasks. Specifically, we present novel and efficient quantum algorithms for implementing \emph{diffusion probabilistic models} (DPMs) using a variety of \emph{ordinary differential equation} (ODE) solvers. These algorithms leverage recent advancements in \emph{quantum ODE solvers} and highlight the potential of quantum Carleman linearization for addressing a broad range of mathematical structures and challenges.
Our exploration focuses on two distinct approaches.
\begin{itemize}
    \item DPM-solver-$k$: Utilizes exact $k$-th order derivatives to compute a polynomial approximation of $\epsilon_\theta(x_\lambda, \lambda)$.
    \item UniPC-$p$: Approximates higher-order derivatives by employing finite differences of $\epsilon_\theta(x_\lambda, \lambda)$ at different points $(x_{s_m}, \lambda_{s_m})$.
\end{itemize}
These algorithms underscore the 
potential of quantum Carleman linearization in addressing diverse mathematical structures. Moreover, as we advance toward the era of megaquop machines, this work stands out as one of the most direct and practical applications of quantum algorithms to large-scale machine learning models. It marks, so we hope, a significant milestone in showcasing the tangible utility of quantum computing in real-world applications. 
% \je{Altered and moved here from the appendix.}

\subsection{{Embedding classical neural networks}}

In the center of DPMs in the classical realm are ordinary differential equations capturing diffusion processes. On the highest level, they are defined by a \emph{forward process}, the reverse or \emph{backward} process, and the \emph{sampling procedure}.
%\je{Added this.}
In this work, the core aim is to establish quantum algorithms for quantum analogs of such models. Since quantum mechanics is intrinsically linear, much of the work will circle around embedding the problem in the appropriate fashion.
In this section, we present a brief heuristic overview of how to solve the diffusion ODE
%In this section, we provide a heuristic and short description of how to solve the diffusion ODE
\begin{equation}
    \frac{\mathrm{d} x_t}{\mathrm{d} t} = f(t) x_t + \frac{g^2(t)}{2\sigma_t} \epsilon_{\theta}(x_t,t), \qquad x_T \sim q_T(x_T),
\label{eq:diffusion-ODE}
\end{equation}
leveraging an instance of a quantum ODE solver based on both the DPM-solver \cite{lu2022dpm,lu2022dpm++} and UniPC \cite{zhao2024unipc}.
%\je{Started here by introducing a bit more. Please edit and change if appropriate.}

\subsubsection{{Carleman linearization for DPM-solvers}}
% \yw{Reproduced here from the appendix. A brief intro to DPM-solver and UniPC before linearizing it and an outline of the proposed quantum algorithms.}
%\je{I am shortening and explaining better.}
% \yw{Great! I removed the quantum algorithm part and put them collectively in the quantum ODE solver section.}
% \je{I am removing my earlier comments, to see what we still need to do.}
%DPM-solver series are the currently most popular diffusion ODE solvers.
%Given an initial value 
We here outline the core ideas of the linearization and embedding -- details can be found in the supplemental material, also shown in Fig.\ \ref{fig:BigFigure}.
The DPM-solver series are currently the most widely used solvers for diffusion ODEs. Given an initial value $x_s$, 
the solution $x_t$ of the diffusion ODE w.r.t.\ 
the noise prediction model Eq.~(\ref{eq:diffusion-ODE}) for $t \in (0,s)$ is given by
\begin{equation}
    \frac{x_t}{\alpha_t} = \frac{x_s}{\alpha_s} - \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \epsilon_{\theta}(x_{\lambda},\lambda) \mathrm{d} \lambda.
\label{eq:diffusion-ODE-exact}
\end{equation}
In this expression $\lambda \coloneqq \log(\alpha_t/\sigma_t)$ is what is called the log-SNR variable. For a given a set of time steps  
$\{t_i\}_{i=0}^M$ with $t_0 = T$ and $t_M = 0$, with $h_i = \lambda_{t_i} - \lambda_{t_{i-1}}$, one makes use of the $(k-1)$-st-order Taylor approximation in order to develop
what is called the DPM-solver-$k$ in Ref.~\cite{lu2022dpm}. This actually takes the form
\begin{equation}\label{eq:DPM-solver-k}
    \begin{split}
        x_{t_i} &= \frac{\alpha_{t_i}}{\alpha_{t_{i-1}}}  x_{t_{i-1}}
        - \alpha_{t_i} \sum_{n=0}^{k-1} \epsilon^{(n)}_{\theta}(x_{\lambda_{t_{i-1}}},\lambda_{t_{i-1}})\\
        & \times \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \frac{(\lambda - \lambda_{t_{i-1}})^n}{n!} \mathrm{d} \lambda  + O(h_i^{k+1}),
    \end{split}
\end{equation}
where $\epsilon^{(n)}_{\theta}(x_{\lambda_{t_{i-1}}},\lambda_{t_{i-1}})$ is the $n$-th derivative. 
The integral in the final line can 
be computed analytically in this case. In the same way, a polynomial expansion on the data prediction model $x_{\theta}(x_{\lambda},\lambda)$ gives rise to what is called the DPM-solver++~\cite{lu2022dpm++}. However, 
as mentioned before, 
the intrinsic linearity of quantum mechanics renders a direct implementation of non-linear ODE schemes inapplicable,
so that one has to 
resort to an instance of
Carleman or 
Koopman linearization and embedding of 
the diffusion ODE. In 
what follows, we discuss the logic and structure of the proposed quantum algorithm.
%\je{Have reformulated the paragraph.}
\begin{itemize}
    \item In a first step, we express $\epsilon_{\theta}(x_{\lambda},\lambda)$ and its higher-order derivatives as a polynomial expansion in $x_{\lambda}$. Building on this, we derive a forward iteration $x_{t_i} = \operatorname{poly}(x_{t_{i-1}})$. 
    
    \item For this still being a non-linear expression, we employ 
     \textit{Carleman linearization} to transform it into a linear system, so that a quantum algorithm can be devised.

    \item For this, we define $y_{j}(\lambda) \approx x^j_{\lambda}$ for $j = 1, \dots, N$. As the Carleman linearization transforms a non-linear differential equation into an infinite-dimensional system of linear differential equations, we truncate it at step $N$, with the initial condition $y_j(\lambda_{t_{i-1}}) = x^j_{\lambda_{t_{i-1}}}$.

    \item Setting $Y = (y_1, \ldots, y_N)$, we then derive a linear iteration of the form 
    \begin{equation} \label{LinearizedSystemDPM}
        \begin{split}
            \delta \hat{Y} & = \hat{Y}(t_{i}) - \hat{Y}(t_{i-1}) = A \hat{Y}(t_{i-1}) + b~,\\
            & \text{ for }\quad \hat{y}_1(t_M) = \hat{y}_1(0) = x_{\mathrm{in}}(0)~,
        \end{split}
    \end{equation}
    based on Eq.~(\ref{eq:DPM-solver-k}), introducing a matrix $A$, which is the \textit{quantum Carleman matrix} 
    (QCM) associated with the DPM-solver.

    % \item Once the linear iteration equations has been established, one can construct a system of linear equations 
    % for every time step,
    % %$\{t_i\}_{i=0}^M$ with $t_0 = T$ and $t_M = 0$, 
    % and apply \emph{quantum linear system solvers} (QLSS) to compute $(Y(\lambda_{t_0}), \ldots, Y(\lambda_{t_M}))$ and measure the amplitude proportional to $y_1(t_M) = y_1(0) = x(0)$. \JPL{Yunfei: please introduce the alternative approach: LCHS, which can avoid QLSS}
\end{itemize}
%\je{I have reformulated this to remove redundancy and slightly shortened it.}
% \JPL{Yunfei: Besides QLSS, 
% also mention LCHS here?}
% \je{Good point. 
% The same applies to the discussion below.}
% \yw{I put all quantum algorithm discussions in the next section, such that it fits the section title better.}
% \JPL{I suggest deleting the matrix block structure (QLSS is not the only way).}
Eq.~(\ref{LinearizedSystemDPM}) embodies
 $M+1$ iterations in total ranging from $t_0 = T$ to $t_M = 0$. Here, $X_{\text{in}} = X(0)$ is specified by the initial vector. This
 expression, distinctly departing from that of 
 Ref.~\cite{Liu:2023coc}, has been designed to reconstruct the original data $x_0$ from $x_t$ through a \textit{backward} denoising diffusion process, contrasting with the forward progression typically seen in a (stochastic) gradient descent algorithm during the training process. %\je{ ted.}


\subsubsection{{Carleman linearization for UniPC}}

Complementing the above methodology, in this subsection, we design
a reading of a quantum Carleman algorithm suitable for the known 
alternative technique to solve the diffusion ODE referred to as UniPC. This includes both the predictor (UniP-p) and the corrector (UniC-p), defined as
\begin{equation}
    \begin{split}
        x_{s_p} = \frac{\alpha_{s_p}}{\alpha_{s_0}}x_{s_0} & - \sigma_{s_p} (e^{h_i} - 1) \epsilon_{\theta}(x_{s_0},\lambda_{s_0})\\
        & - \sigma_{s_p}B(h_i) \sum_{m=1}^{p-1} \frac{a_m}{r_m} D_m,
    \end{split}
\label{eq:UniP--p}
\end{equation}
and as
\begin{equation}
    \begin{split}
        x^c_{s_p} = \frac{\alpha_{s_p}}{\alpha_{s_0}}x^c_{s_0}& - \sigma_{s_p} (e^{h_i} - 1) \epsilon_{\theta}(x_{s_0},\lambda_{s_0})\\
        & - \sigma_{s_p}B(h_i) \sum_{m=1}^p \frac{a_m}{r_m} D_m.
    \end{split}
\label{eq:UniC--p}
\end{equation}
Here, we have encountered the interpolation time steps $s_m = h_ir_m + \lambda_{t_{i-1}}$, where $m = 1, 2, \dots, p$, and the finite difference $D_m = \epsilon_{\theta}(x_{s_m},\lambda_{s_m}) - \epsilon_{\theta}(x_{s_0},\lambda_{s_0})$. 
Note that
in this expression $s_0 = \lambda_{t_{i-1}}$, and $s_p = \lambda_{t_i}$.
%\je{Reformulated.}
Again, we outline the logic and structure of the proposed quantum algorithm.
\begin{itemize}
    \item In a first step, as before, we rewrite the denoising function $\epsilon_{\theta}(x_{\lambda},\lambda)$ in terms of a polynomial expansion in $x_\lambda$
    % \begin{equation} \label{UniPCTaylorExpansion}
    %     \epsilon_{\theta}(x_{\lambda},\lambda) = \sum_{j=0}^J \frac{a_j}{j!} x^j_{\lambda}
    % \end{equation}
    up to order $J$, 
    with the coefficients $a_j$ contains $\lambda$. 

    \item In a next step, we can express $\epsilon_{\theta}(x_{\lambda},\lambda)$ at different points as a polynomial of $x_{\lambda}$, and derive a multi-step 
    forward iteration for UniP given by $x_{s_p} = \operatorname{poly}(x_{s_0}) + \operatorname{poly}(x_{s_1}) + \cdots + \operatorname{poly}(x_{s_{p-1}})$. For UniC, this is $x^c_{s_p} = x^c_{s_0} + \operatorname{poly}(x_{s_0}) + \operatorname{poly}(x_{s_1}) + \cdots + \operatorname{poly}(x_{s_p})$.

    \item Similarly as before, we use \textit{Carleman linearization} in 
    this 
    step and truncate the system at $N$. We denote $y_j(\lambda) \approx x^j_{\lambda}(\lambda)$, $z_j(\lambda) \approx (x^c)^j_{\lambda}(\lambda)$ for $j = 1, \dots, N$, with the initial condition $y_1(s_0) = x_{\lambda}(s_0)$, $z_1(s_0) = (x^c)_{\lambda}(s_0)$. 

    \item In terms of $Y = (y_1, \ldots, y_N)$, and $Z = (z_1, \ldots, z_N)$, we can build on Eq.~(\ref{eq:UniP--p}) and Eq.~(\ref{eq:UniC--p}) 
    to derive a multi-step linear iteration (predictor) expression 
    given by \begin{equation}\label{LinearDifferenceEqnUniP}
        \begin{split}
            \delta Y(t_{i}) =~& A^{(0)} Y^{(0)}(t_{i}) + b^{(0)}\\
            & + A^{(1)} Y^{(1)}(t_{i}) + b^{(1)}\\
            & + \ldots + A^{(p-1)} Y^{(p-1)}(t_{i}) + b^{(p-1)}~,
         \end{split}
    \end{equation}
    with Carleman matrices $A^{(0)}, \dots, A^{(p-1)}$ for all 
    interpolation 
    steps. 
    The corrector, reflecting the other linear iteration
    % \je{the denoising and the corrector are the same in this nomenclature}, 
    takes the form
    \begin{equation} \label{eq:UniPCDifferenceEquation}
        \begin{split}
            \delta Z(t_i) = B Z(t_{i}) & + A^{(0)_c} Y^{(0)}(t_{i}) + b^{(0)_c}\\
            & + A^{(1)_c} Y^{(1)}(t_{i}) + b^{(1)_c}\\
            & + \ldots + A^{(p)_c} Y^{(p)}(t_{i}) + b^{(p)_c}~,
        \end{split}
    \end{equation} 
    with Carleman matrices $B, A^{(0)_c}, \dots, A^{(p)_c}$.

    % \item At all times $\{t_i\}_{i=0}^M$ with $t_0 = T$ and $t_M = 0$, we 
    % can construct a system of linear equations and apply an instance of a \emph{quantum linear system solver} (QLSS) to obtain $(Y(\lambda_{t_0}), \ldots, Y(\lambda_{t_M}))$ and $(Z(\lambda_{t_0}), \ldots, Z(\lambda_{t_M}))$. We then measure the amplitude proportion to (the corrected) $z_1(t_M) = z_1(0) = x^c(0)$.
\end{itemize}
%\je{Reformulated and slightly shortened.}
% The entire iteration schemes can be encapsulated as 
% \begin{equation}\label{UniPCLinearSys}
%     \boldsymbol{\mathsf{M}^c} \boldsymbol{\mathsf{Z}} = \boldsymbol{\mathsf{b}^c}~,
% \end{equation}
% where $\boldsymbol{\mathsf{Z}}$ collects all of the $Z(t_i)$ and $Y(t_i)$, and $\boldsymbol{\mathsf{M}^c}$ is defined accordingly. 
% \JPL{Yunfei:simularly, besides QLSS, also mention LCHS here?}
% \yw{Similarly, I put discussions in the next section.}
% \JPL{Similarly, I suggest deleting  $\boldsymbol{\mathsf{M}^c} \boldsymbol{\mathsf{Z}} = \boldsymbol{\mathsf{b}^c}$.}
% The explicit forms are provided in the supplementary materials.
% %
It is important to stress that 
the Carleman linearization approach %for UniPC 
introduced here represents a novel Carleman predictor-corrector %numerical 
scheme. This approach differs from both the 
DPM-solver framework described in the previous section and the approach taken in Ref.~\cite{Liu:2023coc}. A defining feature of the quantum Carleman algorithm for UniPC is the generation of a unique \emph{quantum Carleman matrix} (QCM) for each interpolation time step $s_m$ that we think is also interesting as an innovative step in its own right.
%\je{Reformulated.}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.98\linewidth]{BigDPMFigure.jpg}
    \caption{Results of numerical experiments.
    1. \textit{Spectrum dynamics of the reverse diffusion process on ImageNet-100.}
Using the DPM-Solver \citep{lu2022dpm}, we show the eigenvalue trajectories of the Jacobian 
$\mathbf{J}(t)$ for dimensions $d=1024,4096$, and $16384$, each representing image generation at a different resolution, ranging from coarse to fine-grained. Across all three cases, the eigenvalues start positive and progressively develop a larger spectral gap with extremely positive values, highlighting the system’s consistent dissipative behavior.
2. \textit{Dissipative measure of the reverse diffusion process on ImageNet-100.}
The shaded area represents the [25th, 75th] percentile of the statistics. Across three models with $d=$ 1024, 4096, and 16384, $P(t)$ consistently decreases with $t$.
    } 
    \label{fig:BigFigure2}
\end{figure*}

\subsection{{End-to-end quantum ODE solver}}
% \yw{Summarized from the supplementary material. Highlights the state-of-the-art QLSS, the derivation of two theorems, and briefly addresses uploading and downloading challenges.}
% \JPL{Yunfei: Also need to introduce LCHS as an alternative method without using QLSS}

% \yw{I have added a brief discussion given that we are limited with the space. I have included a more detailed discussion in the appendix. I also changed the name of that section to quantum ODE solver.}
% \JPL{It looks generally good. Also be careful about the statements in the previous subsections.}
% \yw{The previous section focuses on linearizing classical neural network. So I think it is appropriate to include quantum algorithms that applies to both cases in this section collectively. I removed all quantum algorithm discussion in previous sections, both QLSS and LCHS.}

% \yw{I have relocated the discussion on QLSS entirely to this section to present both methods, QLSS and LCHS, on equal footing. Additionally, I have temporarily removed most comments to assess the available space for the experimental results and the discussion section.} \je{This is wonderful idea, well done.}

With the foundational elements established, there are two distinct approaches to solving the resulting linear ODEs. The first approach leverages the advanced capabilities of the \emph{quantum linear system solver} (QLSS), while the second utilizes the \emph{linear combination of Hamiltonian simulation} (LCHS) algorithm. We will begin by exploring the application of QLSS and subsequently discuss the LCHS method.

To make use of QLSS, we need to massage the iteration ODEs into a single vector equation, as has been  done in Ref.~\cite{Liu:2023coc}. 
We look at the DPM-solver first, the entire
iteration scheme established in Eq.~(\ref{LinearizedSystemDPM}) can be captured in a vector equation 
\begin{equation}\label{LinearSystemDPMSolver}
    M \boldsymbol{Y} = \boldsymbol{b}~
\end{equation}
that collects $Y(t_i)$ at all time steps in order to form a single big vector $\boldsymbol{Y} = (Y(t_0), Y(t_1), \dots, Y(t_M))$. Similarly, the UniPC system can also be captured in a single vector equation as
\begin{equation}\label{UniPCLinearSys}
    \boldsymbol{\mathsf{M}^c} \boldsymbol{\mathsf{Z}} = \boldsymbol{\mathsf{b}^c}~,
\end{equation}
where $\boldsymbol{\mathsf{Z}}$ collects all of the $Z(t_i)$. The explicit forms of Eq.~(\ref{LinearSystemDPMSolver}) and Eq.~(\ref{UniPCLinearSys}) are provided in the supplementary 
material.

We are 
now in the position to invoke 
and discuss an instance of a \emph{quantum linear system solver} (QLSS) to efficiently solve the 
resulting differential equations. QLSS have technically advanced significantly since the introduction of the original \emph{Harrow-Hassidim-Lloyd} (HHL) algorithm proposed in 2008, which has achieved a complexity of $\mathcal{O}(\operatorname{poly}(\kappa, 1/\epsilon))$ for solving sparse linear systems, where $\kappa>0$ is the condition number and $\epsilon>0$ is the desired accuracy \cite{Harrow_2009}. Subsequent developments, including Ambainis' \emph{variable-time amplitude amplification} (VTAA) and linear combination of quantum walks,
have improved the scaling to $\mathcal{O}(\kappa \log(1/\epsilon))$ \cite{ambainis2010variable, Childs_2017}. These algorithms utilize matrix ($\mathcal{O}_M$) and state preparation ($\mathcal{O}_{\boldsymbol{b}}$) oracles, with $\mathcal{O}_{\boldsymbol{b}}$ often incurring lower costs 
in practice \cite{low2024QLAOptimal}. Further recently introduced techniques, such as kernel reflection and adiabatic evolution, have further optimized 
the query complexities, achieving near-optimal bounds for both $\mathcal{O}_M$ and $\mathcal{O}_{\boldsymbol{b}}$ \cite{costa2021optimal, dalzell2024shortcut}. These advancements are particularly relevant for sparse systems like those arising in the Carleman method, where the matrix sparsity $s_M$ and the success probability $p_{\text{succ}}$ significantly influence the overall complexity \cite{Gily_n_2019}. 
%\je{Reformulated and shortened.}

Going further, 
and building on the
theorems and quantum algorithms discussed 
and introduced in Refs.~\cite{Liu:2023coc,costa2021optimal,dalzell2024shortcut,low2024QLAOptimal}, we derive the formal version of Theorem \ref{DPMsolverComplexityTheorem} and Theorem \ref{UniPCComplexityTheorem} presented in the next section, which establish the gate complexity bounds for the quantum Carleman algorithm (for the formal version of these theorems, we refer to the supplementary material). These results integrate advancements in quantum linear system solvers, particularly leveraging the state-of-the-art methods for efficient matrix block encoding, initial state preparation, and sparsity-aware optimization, ensuring a comprehensive understanding of the computational costs associated with solving such systems.

Besides the QLSS approach, the \emph{linear combination of Hamiltonian simulation} (LCHS) strategy \cite{An_2023,an2023quantum} provides an alternative method for solving the linear ODEs in Eqs.~(\ref{LinearSystemDPMSolver}) and (\ref{UniPCLinearSys}) by representing the solution to the homogeneous equation as a linear combination of Hamiltonian simulations. When a source term (e.g., $\boldsymbol{\mathsf{b}^c}$ in Eq.~(\ref{UniPCLinearSys}) and the right-hand side of Eq.~(\ref{LinearSystemDPMSolver})) is present, Duhamel's principle 
can be applied \cite{An_2023}. LCHS achieves gate efficiency by combining \emph{linear combinations of unitaries} (LCU) \cite{Childs2012Hamiltonian} with existing 
Hamiltonian simulation techniques. The method involves truncating the infinite integral to a finite interval $[-K,K]$ and discretizing it using the  $M + 1$ grid points. Compared to the standard QLSS approach, LCHS directly implements the time evolution operator, significantly reducing the number of state preparation oracles required.

At last, we address briefly the challenges of uploading and downloading data for our quantum algorithms, as this aspect is sometimes underappreciated. By leveraging sparsity in both data representation and training, our framework \emph{avoids} the need for \emph{quantum random access memory}  (QRAM) \cite{Liu:2023coc}, thus enhancing scalability and practicality while minimizing classical-to-quantum communication overhead \cite{hann2019hardware, Matteo_2020, Hann_2021, Wang:2023oon}. 
%
The downloading problem is actually more challenging than uploading, as it involves performing state tomography \cite{BenchmarkingReview} on the resulting quantum states from our quantum algorithms \cite{aaronson2018shadowtomography,Huang_2020,Wang_2024}. We focus on tomographic recovery in sparse training on sparse vectors and QCM matrices from the DPM architecture, which is similar to the structure presented in Ref.~\cite{Liu:2023coc}. The recovery process identifies $r$-sparse computational basis vectors and reconstructs the state using a modified \emph{classical shadow estimation} scheme with $n$-qubit Clifford circuits \cite{Huang_2020,ShallowShadows,BenchmarkingReview}, requiring $\mathcal{O}(r \log r)$ measurements only. %\je{Reformulated}

\subsection{{Theorems}}

The above scheme give rise to practical quantum algorithms for a fault tolerant quantum computer.
In this section, we will lay out the informally formulated main theorems that are established in this work. Details can be found in the supplementary material. 
% \yw{Moved up here from the appendix. I have made these simpler and informal.}
% \je{Wonderful. But I move the theorems one section down and explain the linearization in a bit more detail, ok?}
% \yw{Sure, thanks.}

\begin{theorem}[Informal complexity of the DPM-solver] \label{DPMsolverComplexityTheorem}
    For a DPM-solver with a denoising function expanded up to the $J$-th order Taylor approximation and truncated at $N$, the system of linear equations $M \boldsymbol{Y} = \boldsymbol{b}$ can be solved using a quantum algorithm. If $M$ is sparse and block-encoded efficiently, the quantum state proportional to the solution vector can be prepared with query complexity scaling as
    \begin{equation}
        \mathcal{O}(J \kappa \cdot \mathrm{polylog}(N/\epsilon))~,
    \end{equation}
    where $\kappa>0$ is an upper bound on the condition number of $M$. The algorithm achieves a success probability $p_{\text{succ}}$ greater than $1/2$ and accuracy $\epsilon>0$.

    Assuming the output weight vectors are \( r \)-sparse with \( m \coloneqq \log_2(N) \), the tomographic cost for transferring quantum states to classical devices is \( \mathcal{O}(m^2 r^3 /\epsilon^2) \), ignoring logarithmic factors. The algorithm excludes the state preparation cost, which remains efficient for sparse training.
\end{theorem}

The next statement summarizes the sample complexity of the second approach taken.

\begin{theorem}[Informal complexity of the UniPC-$p$ framework]\label{UniPCComplexityTheorem}
    For the UniPC-$p$ framework used in fast sampling of DPMs, a system of linear equations $\boldsymbol{\mathsf{M}^c} \boldsymbol{\mathsf{Z}} = \boldsymbol{\mathsf{b}^c}$ can be formulated and solved using a quantum algorithm. If $\boldsymbol{\mathsf{M}^c}$ is sparse and efficiently block-encoded, the quantum state proportional to the solution can be prepared with query complexity 
    \begin{equation}
        \mathcal{O}(p J \kappa \cdot \mathrm{polylog}(N/\epsilon))~,
    \end{equation}
    where $\kappa>0$ bounds the condition number of $\boldsymbol{\mathsf{M}^c}$. The algorithm achieves a success probability $p_{\text{succ}}$ greater than $1/2$ and accuracy $\epsilon>0$.

    Assuming the output weight vectors are \( r \)-sparse with \( m \coloneqq \log_2(N) \), the tomographic cost for transferring quantum states to classical devices is \( \mathcal{O}(m^2 r^3 /\epsilon^2) \), ignoring logarithmic factors. The algorithm excludes the state preparation cost, which remains efficient for sparse training.
\end{theorem}
These statements ensure that the quantum algorithms are efficiently implementable on a fault tolerant quantum computer.
%\je{Reformulated.}

% \JPL{Yunfei: also need to add state preparation and quantum tomography theorems (see our previous NC paper)}
% \yw{I discussed quantum tomography in the last paragraph of last section. I have added the tomography part to our theorems here also in brief terms.}
% \JPL{I see. Need to highlight it. For instance, we can call our algorithm as an end-to-end quantum ODE solver.}

\subsection{{Numerical analysis and experiments}}\label{sec:experiments}

Above, we present present performance guarantees of the quantum algorithms
introduced. It is a core contribution of this work, however, to also make the 
point that the approach taken is reasonably applicable to real-world data.
This is a valuable contribution, as the proven separations for machine learning
problems are for highly structured and artificial data \cite{PACLearning,DensityModelling,TemmeML}. In this section, we perform
extensive numerical experiments to show that for real-world
datasets, the conditions of the above theorems are commonly satisfied for natural data
and that the processes considered are sufficiently diffusive in a precise
sense. 

%While we present performance guarantees of the quantum algorithms above, we augment our results by a numerical analysis that is aimed at providing further evidence for the functioning of the schemes.
%
\input{experiments}

\section{{Discussion}}\label{sec:concoutlook}

In this work, we have taken steps towards identifying practical applications of quantum computers in realistic machine learning tasks, by formulating meaningful analogs of diffusion probabilistic models that constitute an increasingly important family of classical generative models, producing high quality outputs. 
We build on and further develop tools of quantum solvers for ordinary differential equations to make progress in presenting 
quantum algorithms for quantum analogs of DPMs.
Our work showcases the potential of quantum Carleman linearization for a wide range of mathematical structures, utilizing cutting-edge quantum linear system solvers and linear combination of Hamiltonian simulations. We explain the respective features of the two approaches taken. For our rigorous results, we present performance guarantees, while we offer also results of numerical experiments to provide further evidence for the functioning of the approach.


At a broader level, we aim for our work to help address a key bottleneck in exploring the potential of quantum computing in machine learning. While quantum computers have demonstrated advantages for certain highly structured problems, there is a prevailing view that they may offer limited benefits for tasks in machine learning, which typically involve less structured data and more noise
\cite{PRXQuantum.3.030101}. This work, suggests, however, that there may be significant potential for quantum computers in performing inference tasks or generative tasks of this nature. Considering that inference costs might be more than training costs in many machine learning applications, our proposed approach could pave the way for a practical example of quantum advantage in machine learning industry, while also providing a pathway to making quantum computers more useful for solving industrially relevant problems.\\
%\je{Added this.}

\section*{{Acknowledgements}}\label{sec:ack}


%\je{To be completed.}
J.~E.~has been supported by the BMBF (Hybrid++, DAQC, QSolid), the QuantERA (HQCC),
the BMWK (EniQmA), the DFG (CRC 183), the Quantum Flagship (PasQuans2, Millenion), the Munich Quantum Valley, 
Berlin Quantum, and the European Research Council (DebuQC). 
J.-P.~L.~acknowledges support from Tsinghua University and Beijing Institute of Mathematical Sciences and Applications.

\pagebreak
\clearpage
\foreach \x in {1,...,\the\pdflastximagepages}
{
	\clearpage
	\includepdf[pages={\x,{}}]{appendixDPM.pdf}
}


%\input{appendixDPM.pdf}

%\bibliography{reference}

%apsrev4-2.bst 2019-01-14 (MD) hand-edited version of apsrev4-1.bst
%Control: key (0)
%Control: author (8) initials jnrlst
%Control: editor formatted (1) identically to author
%Control: production of article title (0) allowed
%Control: page (0) single
%Control: year (1) truncated
%Control: production of eprint (0) enabled
\begin{thebibliography}{46}%
\makeatletter
\providecommand \@ifxundefined [1]{%
 \@ifx{#1\undefined}
}%
\providecommand \@ifnum [1]{%
 \ifnum #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \@ifx [1]{%
 \ifx #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \natexlab [1]{#1}%
\providecommand \enquote  [1]{``#1''}%
\providecommand \bibnamefont  [1]{#1}%
\providecommand \bibfnamefont [1]{#1}%
\providecommand \citenamefont [1]{#1}%
\providecommand \href@noop [0]{\@secondoftwo}%
\providecommand \href [0]{\begingroup \@sanitize@url \@href}%
\providecommand \@href[1]{\@@startlink{#1}\@@href}%
\providecommand \@@href[1]{\endgroup#1\@@endlink}%
\providecommand \@sanitize@url [0]{\catcode `\\12\catcode `\$12\catcode
  `\&12\catcode `\#12\catcode `\^12\catcode `\_12\catcode `\%12\relax}%
\providecommand \@@startlink[1]{}%
\providecommand \@@endlink[0]{}%
\providecommand \url  [0]{\begingroup\@sanitize@url \@url }%
\providecommand \@url [1]{\endgroup\@href {#1}{\urlprefix }}%
\providecommand \urlprefix  [0]{URL }%
\providecommand \Eprint [0]{\href }%
\providecommand \doibase [0]{https://doi.org/}%
\providecommand \selectlanguage [0]{\@gobble}%
\providecommand \bibinfo  [0]{\@secondoftwo}%
\providecommand \bibfield  [0]{\@secondoftwo}%
\providecommand \translation [1]{[#1]}%
\providecommand \BibitemOpen [0]{}%
\providecommand \bibitemStop [0]{}%
\providecommand \bibitemNoStop [0]{.\EOS\space}%
\providecommand \EOS [0]{\spacefactor3000\relax}%
\providecommand \BibitemShut  [1]{\csname bibitem#1\endcsname}%
\let\auto@bib@innerbib\@empty
%</preamble>
\bibitem [{\citenamefont {Chang}\ \emph {et~al.}(2023)\citenamefont {Chang},
  \citenamefont {Koulieris},\ and\ \citenamefont {Shum}}]{DiffusionModels1}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont
  {Chang}}, \bibinfo {author} {\bibfnamefont {G.~A.}\ \bibnamefont
  {Koulieris}},\ and\ \bibinfo {author} {\bibfnamefont {H.~P.~H.}\ \bibnamefont
  {Shum}},\ }\href {https://arxiv.org/abs/2306.04542} {\bibinfo {title} {On the
  design fundamentals of diffusion models: A survey}} (\bibinfo {year}
  {2023}),\ \Eprint {https://arxiv.org/abs/2306.04542} {arXiv:2306.04542}
  \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Croitoru}\ \emph {et~al.}(2023)\citenamefont
  {Croitoru}, \citenamefont {Hondru}, \citenamefont {Ionescu},\ and\
  \citenamefont {Shah}}]{DiffusionModels2}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.-A.}\ \bibnamefont
  {Croitoru}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {Hondru}},
  \bibinfo {author} {\bibfnamefont {R.~T.}\ \bibnamefont {Ionescu}},\ and\
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Shah}},\ }\bibfield
  {title} {\bibinfo {title} {Diffusion models in vision: A survey},\ }\href
  {https://doi.org/10.1109/tpami.2023.3261988} {\bibfield  {journal} {\bibinfo
  {journal} {IEEE Trans. Patt. Ana. Mach. Intel.}\ }\textbf {\bibinfo {volume}
  {45}},\ \bibinfo {pages} {10850–10869} (\bibinfo {year}
  {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Song}\ \emph {et~al.}(2021)\citenamefont {Song},
  \citenamefont {Sohl-Dickstein}, \citenamefont {Kingma}, \citenamefont
  {Kumar}, \citenamefont {Ermon},\ and\ \citenamefont
  {Poole}}]{DiffusionModels3}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Song}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Sohl-Dickstein}}, \bibinfo {author} {\bibfnamefont {D.~P.}\ \bibnamefont
  {Kingma}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Kumar}},
  \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Ermon}},\ and\ \bibinfo
  {author} {\bibfnamefont {B.}~\bibnamefont {Poole}},\ }\href
  {https://arxiv.org/abs/2011.13456} {\bibinfo {title} {Score-based generative
  modeling through stochastic differential equations}} (\bibinfo {year}
  {2021}),\ \Eprint {https://arxiv.org/abs/2011.13456} {arXiv:2011.13456}
  \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ho}\ \emph {et~al.}(2020)\citenamefont {Ho},
  \citenamefont {Jain},\ and\ \citenamefont {Abbeel}}]{ho2020denoising}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Ho}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Jain}},\ and\
  \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Abbeel}},\ }\href
  {https://arxiv.org/abs/2006.11239} {\bibinfo {title} {Denoising diffusion
  probabilistic models}} (\bibinfo {year} {2020}),\ \Eprint
  {https://arxiv.org/abs/2006.11239} {arXiv:2006.11239 [cs.LG]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Creswell}\ \emph {et~al.}(2017)\citenamefont
  {Creswell}, \citenamefont {White}, \citenamefont {Dumoulin},\ and\
  \citenamefont {Arulkumaran}}]{GANS}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Creswell}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {White}},
  \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {Dumoulin}},\ and\
  \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {Arulkumaran}},\
  }\bibfield  {title} {\bibinfo {title} {Generative adversarial networks: An
  overview},\ }\href {https://doi.org/10.1109/MSP.2017.2765202} {\bibfield
  {journal} {\bibinfo  {journal} {IEEE Sig. Proc. Mag.}\ }\textbf {\bibinfo
  {volume} {35}},\ \bibinfo {pages} {53} (\bibinfo {year} {2017})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Kingma}\ and\ \citenamefont {Welling}(2019)}]{VAE}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~P.}\ \bibnamefont
  {Kingma}}\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Welling}},\ }\bibfield  {title} {\bibinfo {title} {An introduction to
  variational autoencoders},\ }\href {https://doi.org/10.1561/2200000056}
  {\bibfield  {journal} {\bibinfo  {journal} {Found. Trends Mach. Learn.}\
  }\textbf {\bibinfo {volume} {12}},\ \bibinfo {pages} {307–392} (\bibinfo
  {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Preskill}(1998)}]{preskill1998lecture}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Preskill}},\ }\bibfield  {title} {\bibinfo {title} {Lecture notes for
  physics 229: Quantum information and computation},\ }\href
  {https://www.preskill.caltech.edu/ph229} {\bibfield  {journal} {\bibinfo
  {journal} {California Institute of Technology}\ }\textbf {\bibinfo {volume}
  {16}},\ \bibinfo {pages} {1} (\bibinfo {year} {1998})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Shor}(1999)}]{shor1999polynomial}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.~W.}\ \bibnamefont
  {Shor}},\ }\bibfield  {title} {\bibinfo {title} {Polynomial-time algorithms
  for prime factorization and discrete logarithms on a quantum computer},\
  }\href {https://doi.org/10.1137/S0036144598347011} {\bibfield  {journal}
  {\bibinfo  {journal} {SIAM Rev.}\ }\textbf {\bibinfo {volume} {41}},\
  \bibinfo {pages} {303} (\bibinfo {year} {1999})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Grover}(1996)}]{grover1996fast}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.~K.}\ \bibnamefont
  {Grover}},\ }\bibfield  {title} {\bibinfo {title} {A fast quantum mechanical
  algorithm for database search},\ }in\ \href@noop {} {\emph {\bibinfo
  {booktitle} {Proceedings of the twenty-eighth annual ACM symposium on Theory
  of computing}}}\ (\bibinfo {year} {1996})\ pp.\ \bibinfo {pages} {212--219},\
  \bibinfo {note}
  {\href{https://arxiv.org/abs/quant-ph/9605043}{arXiv:quant-ph/9605043}}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Lloyd}(1996)}]{lloyd1996universal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Lloyd}},\ }\bibfield  {title} {\bibinfo {title} {Universal quantum
  simulators},\ }\href {https://doi.org/10.1126/science.273.5278.1073}
  {\bibfield  {journal} {\bibinfo  {journal} {Science}\ }\textbf {\bibinfo
  {volume} {273}},\ \bibinfo {pages} {1073} (\bibinfo {year}
  {1996})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hangleiter}\ and\ \citenamefont
  {Eisert}(2023)}]{SupremacyReview}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Hangleiter}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Eisert}},\ }\bibfield  {title} {\bibinfo {title} {Computational advantage of
  quantum random sampling},\ }\href
  {https://doi.org/10.1103/RevModPhys.95.035001} {\bibfield  {journal}
  {\bibinfo  {journal} {Rev. Mod. Phys.}\ }\textbf {\bibinfo {volume} {95}},\
  \bibinfo {pages} {035001} (\bibinfo {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Wang}\ and\ \citenamefont {Liu}(2024)}]{Wang_2024}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Wang}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Liu}},\
  }\bibfield  {title} {\bibinfo {title} {{A comprehensive review of quantum
  machine learning: from NISQ to fault tolerance}},\ }\href
  {https://doi.org/10.1088/1361-6633/ad7f69} {\bibfield  {journal} {\bibinfo
  {journal} {Rep. Prog. Phys.}\ }\textbf {\bibinfo {volume} {87}},\ \bibinfo
  {pages} {116402} (\bibinfo {year} {2024})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Harrow}\ \emph {et~al.}(2009)\citenamefont {Harrow},
  \citenamefont {Hassidim},\ and\ \citenamefont {Lloyd}}]{Harrow_2009}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~W.}\ \bibnamefont
  {Harrow}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Hassidim}},\
  and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Lloyd}},\ }\bibfield
   {title} {\bibinfo {title} {Quantum algorithm for linear systems of
  equations},\ }\href {https://doi.org/10.1103/physrevlett.103.150502}
  {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. Lett.}\ }\textbf
  {\bibinfo {volume} {103}},\ \bibinfo {pages} {150502} (\bibinfo {year}
  {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Biamonte}\ \emph {et~al.}(2017)\citenamefont
  {Biamonte}, \citenamefont {Wittek}, \citenamefont {Pancotti}, \citenamefont
  {Rebentrost}, \citenamefont {Wiebe},\ and\ \citenamefont
  {Lloyd}}]{biamonte2017quantum}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Biamonte}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Wittek}},
  \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Pancotti}}, \bibinfo
  {author} {\bibfnamefont {P.}~\bibnamefont {Rebentrost}}, \bibinfo {author}
  {\bibfnamefont {N.}~\bibnamefont {Wiebe}},\ and\ \bibinfo {author}
  {\bibfnamefont {S.}~\bibnamefont {Lloyd}},\ }\bibfield  {title} {\bibinfo
  {title} {Quantum machine learning},\ }\href
  {https://doi.org/10.1038/nature23474} {\bibfield  {journal} {\bibinfo
  {journal} {Nature}\ }\textbf {\bibinfo {volume} {549}},\ \bibinfo {pages}
  {195} (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Carleo}\ \emph {et~al.}(2019)\citenamefont {Carleo},
  \citenamefont {Cirac}, \citenamefont {Cranmer}, \citenamefont {Daudet},
  \citenamefont {Schuld}, \citenamefont {Tishby}, \citenamefont
  {Vogt-Maranto},\ and\ \citenamefont {Zdeborov\'a}}]{RevModPhys.91.045002}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont
  {Carleo}}, \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {Cirac}},
  \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {Cranmer}}, \bibinfo
  {author} {\bibfnamefont {L.}~\bibnamefont {Daudet}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {Schuld}}, \bibinfo {author} {\bibfnamefont
  {N.}~\bibnamefont {Tishby}}, \bibinfo {author} {\bibfnamefont
  {L.}~\bibnamefont {Vogt-Maranto}},\ and\ \bibinfo {author} {\bibfnamefont
  {L.}~\bibnamefont {Zdeborov\'a}},\ }\bibfield  {title} {\bibinfo {title}
  {Machine learning and the physical sciences},\ }\href
  {https://doi.org/10.1103/RevModPhys.91.045002} {\bibfield  {journal}
  {\bibinfo  {journal} {Rev. Mod. Phys.}\ }\textbf {\bibinfo {volume} {91}},\
  \bibinfo {pages} {045002} (\bibinfo {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {McClean}\ \emph {et~al.}(2016)\citenamefont
  {McClean}, \citenamefont {Romero}, \citenamefont {Babbush},\ and\
  \citenamefont {Aspuru-Guzik}}]{McClean_2016}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~R.}\ \bibnamefont
  {McClean}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Romero}},
  \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Babbush}},\ and\ \bibinfo
  {author} {\bibfnamefont {A.}~\bibnamefont {Aspuru-Guzik}},\ }\bibfield
  {title} {\bibinfo {title} {The theory of variational hybrid quantum-classical
  algorithms},\ }\href {https://doi.org/10.1088/1367-2630/18/2/023023}
  {\bibfield  {journal} {\bibinfo  {journal} {New J. Phys.}\ }\textbf {\bibinfo
  {volume} {18}},\ \bibinfo {pages} {023023} (\bibinfo {year}
  {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Sweke}\ \emph {et~al.}(2021)\citenamefont {Sweke},
  \citenamefont {Seifert}, \citenamefont {Hangleiter},\ and\ \citenamefont
  {Eisert}}]{PACLearning}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Sweke}}, \bibinfo {author} {\bibfnamefont {J.-P.}\ \bibnamefont {Seifert}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Hangleiter}},\ and\
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Eisert}},\ }\bibfield
  {title} {\bibinfo {title} {On the quantum versus classical learnability of
  discrete distributions},\ }\href {https://doi.org/10.22331/q-2021-03-23-417}
  {\bibfield  {journal} {\bibinfo  {journal} {Quantum}\ }\textbf {\bibinfo
  {volume} {5}},\ \bibinfo {pages} {417} (\bibinfo {year} {2021})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Pirnay}\ \emph {et~al.}(2023)\citenamefont {Pirnay},
  \citenamefont {Sweke}, \citenamefont {Eisert},\ and\ \citenamefont
  {Seifert}}]{DensityModelling}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Pirnay}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Sweke}},
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Eisert}},\ and\ \bibinfo
  {author} {\bibfnamefont {J.-P.}\ \bibnamefont {Seifert}},\ }\bibfield
  {title} {\bibinfo {title} {A super-polynomial quantum-classical separation
  for density modelling},\ }\href {https://doi.org/10.1103/PhysRevA.107.042416}
  {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. A}\ }\textbf {\bibinfo
  {volume} {107}},\ \bibinfo {pages} {042416} (\bibinfo {year}
  {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Liu}\ \emph {et~al.}(2021)\citenamefont {Liu},
  \citenamefont {Arunachalam},\ and\ \citenamefont {Temme}}]{TemmeML}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Liu}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Arunachalam}},\
  and\ \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {Temme}},\ }\bibfield
   {title} {\bibinfo {title} {A rigorous and robust quantum speed-up in
  supervised machine learning},\ }\href
  {https://doi.org/10.1038/s41567-021-01287-z} {\bibfield  {journal} {\bibinfo
  {journal} {Nature Phys.}\ }\textbf {\bibinfo {volume} {17}},\ \bibinfo
  {pages} {1013} (\bibinfo {year} {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pirnay}\ \emph {et~al.}(2024)\citenamefont {Pirnay},
  \citenamefont {Jerbi}, \citenamefont {Seifert},\ and\ \citenamefont
  {Eisert}}]{ShortCircuitsLearning}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Pirnay}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Jerbi}},
  \bibinfo {author} {\bibfnamefont {J.~P.}\ \bibnamefont {Seifert}},\ and\
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Eisert}},\ }\href
  {https://arxiv.org/abs/2411.15548} {\bibinfo {title} {An unconditional
  distribution learning advantage with shallow quantum circuits}} (\bibinfo
  {year} {2024}),\ \Eprint {https://arxiv.org/abs/2411.15548}
  {arXiv:2411.15548} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Schuld}\ and\ \citenamefont
  {Killoran}(2022)}]{PRXQuantum.3.030101}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Schuld}}\ and\ \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Killoran}},\ }\bibfield  {title} {\bibinfo {title} {Is quantum advantage the
  right goal for quantum machine learning?},\ }\href
  {https://doi.org/10.1103/PRXQuantum.3.030101} {\bibfield  {journal} {\bibinfo
   {journal} {PRX Quantum}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo {pages}
  {030101} (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Zimborás}\ \emph {et~al.}(2025)\citenamefont
  {Zimborás}, \citenamefont {Koczor}, \citenamefont {Holmes}, \citenamefont
  {Borrelli}, \citenamefont {Gilyén}, \citenamefont {Huang}, \citenamefont
  {Cai}, \citenamefont {Acín}, \citenamefont {Aolita}, \citenamefont {Banchi},
  \citenamefont {Brandão}, \citenamefont {Cavalcanti}, \citenamefont {Cubitt},
  \citenamefont {Filippov}, \citenamefont {García-Pérez}, \citenamefont
  {Goold}, \citenamefont {Kálmán}, \citenamefont {Kyoseva}, \citenamefont
  {Rossi}, \citenamefont {Sokolov}, \citenamefont {Tavernelli},\ and\
  \citenamefont {Maniscalco}}]{Myths}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont
  {Zimborás}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Koczor}},
  \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Holmes}}, \bibinfo
  {author} {\bibfnamefont {E.-M.}\ \bibnamefont {Borrelli}}, \bibinfo {author}
  {\bibfnamefont {A.}~\bibnamefont {Gilyén}}, \bibinfo {author} {\bibfnamefont
  {H.-Y.}\ \bibnamefont {Huang}}, \bibinfo {author} {\bibfnamefont
  {Z.}~\bibnamefont {Cai}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Acín}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Aolita}},
  \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Banchi}}, \bibinfo
  {author} {\bibfnamefont {F.~G. S.~L.}\ \bibnamefont {Brandão}}, \bibinfo
  {author} {\bibfnamefont {D.}~\bibnamefont {Cavalcanti}}, \bibinfo {author}
  {\bibfnamefont {T.}~\bibnamefont {Cubitt}}, \bibinfo {author} {\bibfnamefont
  {S.~N.}\ \bibnamefont {Filippov}}, \bibinfo {author} {\bibfnamefont
  {G.}~\bibnamefont {García-Pérez}}, \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Goold}}, \bibinfo {author} {\bibfnamefont
  {O.}~\bibnamefont {Kálmán}}, \bibinfo {author} {\bibfnamefont
  {E.}~\bibnamefont {Kyoseva}}, \bibinfo {author} {\bibfnamefont {M.~A.~C.}\
  \bibnamefont {Rossi}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Sokolov}}, \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont
  {Tavernelli}},\ and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Maniscalco}},\ }\href {https://arxiv.org/abs/2501.05694} {\bibinfo {title}
  {Myths around quantum computation before full fault tolerance: What no-go
  theorems rule out and what they don't}} (\bibinfo {year} {2025}),\ \Eprint
  {https://arxiv.org/abs/2501.05694} {arXiv:2501.05694 [quant-ph]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Lu}\ \emph {et~al.}(2022)\citenamefont {Lu},
  \citenamefont {Zhou}, \citenamefont {Bao}, \citenamefont {Chen},
  \citenamefont {Li},\ and\ \citenamefont {Zhu}}]{lu2022dpm}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Lu}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Zhou}}, \bibinfo
  {author} {\bibfnamefont {F.}~\bibnamefont {Bao}}, \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Chen}}, \bibinfo {author} {\bibfnamefont
  {C.}~\bibnamefont {Li}},\ and\ \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Zhu}},\ }\bibfield  {title} {\bibinfo {title}
  {{DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in
  around 10 steps}},\ }\href {https://doi.org/10.48550/arXiv.2206.00927}
  {\bibfield  {journal} {\bibinfo  {journal} {Adv. Neur. Inf. Proc. Sys.
  (NeurIPS)}\ }\textbf {\bibinfo {volume} {35}},\ \bibinfo {pages} {5775}
  (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lu}\ \emph {et~al.}(2023)\citenamefont {Lu},
  \citenamefont {Zhou}, \citenamefont {Bao}, \citenamefont {Chen},
  \citenamefont {Li},\ and\ \citenamefont {Zhu}}]{lu2022dpm++}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Lu}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Zhou}}, \bibinfo
  {author} {\bibfnamefont {F.}~\bibnamefont {Bao}}, \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Chen}}, \bibinfo {author} {\bibfnamefont
  {C.}~\bibnamefont {Li}},\ and\ \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Zhu}},\ }\href {https://arxiv.org/abs/2211.01095}
  {\bibinfo {title} {{DPM-Solver++: Fast solver for guided sampling of
  diffusion probabilistic models}}} (\bibinfo {year} {2023}),\ \Eprint
  {https://arxiv.org/abs/2211.01095} {arXiv:2211.01095 [cs.LG]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Zhao}\ \emph {et~al.}(2024)\citenamefont {Zhao},
  \citenamefont {Bai}, \citenamefont {Rao}, \citenamefont {Zhou},\ and\
  \citenamefont {Lu}}]{zhao2024unipc}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.}~\bibnamefont
  {Zhao}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Bai}}, \bibinfo
  {author} {\bibfnamefont {Y.}~\bibnamefont {Rao}}, \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Zhou}},\ and\ \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Lu}},\ }\bibfield  {title} {\bibinfo
  {title} {{UniPC: A unified predictor-corrector framework for fast sampling of
  diffusion models}},\ }\href {https://doi.org/10.48550/arXiv.2302.04867}
  {\bibfield  {journal} {\bibinfo  {journal} {Adv. Neur. Inf. Proc. Sys.
  (NeurIPS)}\ }\textbf {\bibinfo {volume} {36}},\ \bibinfo {pages} {49842}
  (\bibinfo {year} {2024})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Liu}\ \emph {et~al.}(2024)\citenamefont {Liu},
  \citenamefont {Liu}, \citenamefont {Liu}, \citenamefont {Ye}, \citenamefont
  {Wang}, \citenamefont {Alexeev}, \citenamefont {Eisert},\ and\ \citenamefont
  {Jiang}}]{Liu:2023coc}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Liu}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Liu}}, \bibinfo
  {author} {\bibfnamefont {J.-P.}\ \bibnamefont {Liu}}, \bibinfo {author}
  {\bibfnamefont {Z.}~\bibnamefont {Ye}}, \bibinfo {author} {\bibfnamefont
  {Y.}~\bibnamefont {Wang}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Alexeev}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Eisert}},\
  and\ \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Jiang}},\ }\bibfield
   {title} {\bibinfo {title} {{Towards provably efficient quantum algorithms
  for large-scale machine-learning models}},\ }\href
  {https://doi.org/10.1038/s41467-023-43957-x} {\bibfield  {journal} {\bibinfo
  {journal} {Nature Comm.}\ }\textbf {\bibinfo {volume} {15}},\ \bibinfo
  {pages} {434} (\bibinfo {year} {2024})},\ \Eprint
  {https://arxiv.org/abs/2303.03428} {arXiv:2303.03428} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ambainis}(2010)}]{ambainis2010variable}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Ambainis}},\ }\href {https://arxiv.org/abs/1010.4458} {\bibinfo {title}
  {Variable time amplitude amplification and a faster quantum algorithm for
  solving systems of linear equations}} (\bibinfo {year} {2010}),\ \Eprint
  {https://arxiv.org/abs/1010.4458} {arXiv:1010.4458 [quant-ph]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Childs}\ \emph {et~al.}(2017)\citenamefont {Childs},
  \citenamefont {Kothari},\ and\ \citenamefont {Somma}}]{Childs_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~M.}\ \bibnamefont
  {Childs}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Kothari}},\
  and\ \bibinfo {author} {\bibfnamefont {R.~D.}\ \bibnamefont {Somma}},\
  }\bibfield  {title} {\bibinfo {title} {Quantum algorithm for systems of
  linear equations with exponentially improved dependence on precision},\
  }\href {https://doi.org/10.1137/16m1087072} {\bibfield  {journal} {\bibinfo
  {journal} {SIAM J. Comp.}\ }\textbf {\bibinfo {volume} {46}},\ \bibinfo
  {pages} {1920–1950} (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Low}\ and\ \citenamefont
  {Su}(2024)}]{low2024QLAOptimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.~H.}\ \bibnamefont
  {Low}}\ and\ \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Su}},\
  }\href {https://arxiv.org/abs/2410.18178} {\bibinfo {title} {Quantum linear
  system algorithm with optimal queries to initial state preparation}}
  (\bibinfo {year} {2024}),\ \Eprint {https://arxiv.org/abs/2410.18178}
  {arXiv:2410.18178 [quant-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Costa}\ \emph {et~al.}(2021)\citenamefont {Costa},
  \citenamefont {An}, \citenamefont {Sanders}, \citenamefont {Su},
  \citenamefont {Babbush},\ and\ \citenamefont {Berry}}]{costa2021optimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.~C.~S.}\
  \bibnamefont {Costa}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {An}}, \bibinfo {author} {\bibfnamefont {Y.~R.}\ \bibnamefont {Sanders}},
  \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Su}}, \bibinfo {author}
  {\bibfnamefont {R.}~\bibnamefont {Babbush}},\ and\ \bibinfo {author}
  {\bibfnamefont {D.~W.}\ \bibnamefont {Berry}},\ }\href
  {https://arxiv.org/abs/2111.08152} {\bibinfo {title} {Optimal scaling quantum
  linear systems solver via discrete adiabatic theorem}} (\bibinfo {year}
  {2021}),\ \Eprint {https://arxiv.org/abs/2111.08152} {arXiv:2111.08152
  [quant-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Dalzell}(2024)}]{dalzell2024shortcut}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~M.}\ \bibnamefont
  {Dalzell}},\ }\href {https://arxiv.org/abs/2406.12086} {\bibinfo {title} {A
  shortcut to an optimal quantum linear system solver}} (\bibinfo {year}
  {2024}),\ \Eprint {https://arxiv.org/abs/2406.12086} {arXiv:2406.12086
  [quant-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gilyén}\ \emph {et~al.}(2019)\citenamefont
  {Gilyén}, \citenamefont {Su}, \citenamefont {Low},\ and\ \citenamefont
  {Wiebe}}]{Gily_n_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Gilyén}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Su}},
  \bibinfo {author} {\bibfnamefont {G.~H.}\ \bibnamefont {Low}},\ and\ \bibinfo
  {author} {\bibfnamefont {N.}~\bibnamefont {Wiebe}},\ }\bibfield  {title}
  {\bibinfo {title} {Quantum singular value transformation and beyond:
  exponential improvements for quantum matrix arithmetics},\ }in\ \href
  {https://doi.org/10.1145/3313276.3316366} {\emph {\bibinfo {booktitle}
  {Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of
  Computing}}},\ \bibinfo {series and number} {STOC ’19}\ (\bibinfo
  {publisher} {ACM},\ \bibinfo {year} {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {An}\ \emph {et~al.}(2023{\natexlab{a}})\citenamefont
  {An}, \citenamefont {Liu},\ and\ \citenamefont {Lin}}]{An_2023}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {An}}, \bibinfo {author} {\bibfnamefont {J.-P.}\ \bibnamefont {Liu}},\ and\
  \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Lin}},\ }\bibfield
  {title} {\bibinfo {title} {{Linear combination of Hamiltonian simulation for
  nonunitary dynamics with optimal state preparation cost}},\ }\href
  {https://doi.org/10.1103/physrevlett.131.150603} {\bibfield  {journal}
  {\bibinfo  {journal} {Phys. Rev. Lett.}\ }\textbf {\bibinfo {volume} {131}},\
  \bibinfo {pages} {150603} (\bibinfo {year} {2023}{\natexlab{a}})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {An}\ \emph {et~al.}(2023{\natexlab{b}})\citenamefont
  {An}, \citenamefont {Childs},\ and\ \citenamefont {Lin}}]{an2023quantum}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {An}}, \bibinfo {author} {\bibfnamefont {A.~M.}\ \bibnamefont {Childs}},\
  and\ \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Lin}},\ }\href
  {https://arxiv.org/abs/2312.03916} {\bibinfo {title} {Quantum algorithm for
  linear non-unitary dynamics with near-optimal dependence on all parameters}}
  (\bibinfo {year} {2023}{\natexlab{b}}),\ \Eprint
  {https://arxiv.org/abs/2312.03916} {arXiv:2312.03916 [quant-ph]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Andrew M.~Childs}(2012)}]{Childs2012Hamiltonian}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {N.~W.}\ \bibnamefont
  {Andrew M.~Childs}},\ }\bibfield  {title} {\bibinfo {title} {Hamiltonian
  simulation using linear combinations of unitary operations},\ }\href
  {https://doi.org/10.26421/qic12.11-12} {\bibfield  {journal} {\bibinfo
  {journal} {Quant. Inf. Comp.}\ }\textbf {\bibinfo {volume} {12}},\ \bibinfo
  {pages} {0901} (\bibinfo {year} {2012})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hann}\ \emph {et~al.}(2019)\citenamefont {Hann},
  \citenamefont {Zou}, \citenamefont {Zhang}, \citenamefont {Chu},
  \citenamefont {Schoelkopf}, \citenamefont {Girvin},\ and\ \citenamefont
  {Jiang}}]{hann2019hardware}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.~T.}\ \bibnamefont
  {Hann}}, \bibinfo {author} {\bibfnamefont {C.-L.}\ \bibnamefont {Zou}},
  \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Zhang}}, \bibinfo
  {author} {\bibfnamefont {Y.}~\bibnamefont {Chu}}, \bibinfo {author}
  {\bibfnamefont {R.~J.}\ \bibnamefont {Schoelkopf}}, \bibinfo {author}
  {\bibfnamefont {S.~M.}\ \bibnamefont {Girvin}},\ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Jiang}},\ }\bibfield  {title} {\bibinfo
  {title} {Hardware-efficient quantum random access memory with hybrid quantum
  acoustic systems},\ }\href {https://doi.org/10.1103/PhysRevLett.123.250501}
  {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. Lett.}\ }\textbf
  {\bibinfo {volume} {123}},\ \bibinfo {pages} {250501} (\bibinfo {year}
  {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Matteo}\ \emph {et~al.}(2020)\citenamefont {Matteo},
  \citenamefont {Gheorghiu},\ and\ \citenamefont {Mosca}}]{Matteo_2020}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {O.~D.}\ \bibnamefont
  {Matteo}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {Gheorghiu}},\
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Mosca}},\ }\bibfield
   {title} {\bibinfo {title} {Fault-tolerant resource estimation of quantum
  random-access memories},\ }\href {https://doi.org/10.1109/tqe.2020.2965803}
  {\bibfield  {journal} {\bibinfo  {journal} {IEEE Trans. Quant. Eng.}\
  }\textbf {\bibinfo {volume} {1}},\ \bibinfo {pages} {1–13} (\bibinfo {year}
  {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hann}\ \emph {et~al.}(2021)\citenamefont {Hann},
  \citenamefont {Lee}, \citenamefont {Girvin},\ and\ \citenamefont
  {Jiang}}]{Hann_2021}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.~T.}\ \bibnamefont
  {Hann}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Lee}}, \bibinfo
  {author} {\bibfnamefont {S.}~\bibnamefont {Girvin}},\ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Jiang}},\ }\bibfield  {title} {\bibinfo
  {title} {Resilience of quantum random access memory to generic noise},\
  }\href {https://doi.org/10.1103/prxquantum.2.020311} {\bibfield  {journal}
  {\bibinfo  {journal} {PRX Quantum}\ }\textbf {\bibinfo {volume} {2}},\
  \bibinfo {pages} {020311} (\bibinfo {year} {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Wang}\ \emph {et~al.}(2024)\citenamefont {Wang},
  \citenamefont {Alexeev}, \citenamefont {Jiang}, \citenamefont {Chong},\ and\
  \citenamefont {Liu}}]{Wang:2023oon}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Wang}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Alexeev}},
  \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Jiang}}, \bibinfo
  {author} {\bibfnamefont {F.~T.}\ \bibnamefont {Chong}},\ and\ \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Liu}},\ }\bibfield  {title}
  {\bibinfo {title} {{Fundamental causal bounds of quantum random access
  memories}},\ }\href {https://doi.org/10.1038/s41534-024-00848-3} {\bibfield
  {journal} {\bibinfo  {journal} {npj Quant. Inf.}\ }\textbf {\bibinfo {volume}
  {10}},\ \bibinfo {pages} {71} (\bibinfo {year} {2024})},\ \Eprint
  {https://arxiv.org/abs/2307.13460} {arXiv:2307.13460 [quant-ph]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Eisert}\ \emph {et~al.}(2020)\citenamefont {Eisert},
  \citenamefont {Hangleiter}, \citenamefont {Walk}, \citenamefont {Roth},
  \citenamefont {Markham}, \citenamefont {Parekh}, \citenamefont {Chabaud},\
  and\ \citenamefont {Kashefi}}]{BenchmarkingReview}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Eisert}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Hangleiter}},
  \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Walk}}, \bibinfo {author}
  {\bibfnamefont {I.}~\bibnamefont {Roth}}, \bibinfo {author} {\bibfnamefont
  {D.}~\bibnamefont {Markham}}, \bibinfo {author} {\bibfnamefont
  {R.}~\bibnamefont {Parekh}}, \bibinfo {author} {\bibfnamefont
  {U.}~\bibnamefont {Chabaud}},\ and\ \bibinfo {author} {\bibfnamefont
  {E.}~\bibnamefont {Kashefi}},\ }\bibfield  {title} {\bibinfo {title} {Quantum
  certification and benchmarking},\ }\href
  {https://doi.org/10.1038/s42254-020-0186-4} {\bibfield  {journal} {\bibinfo
  {journal} {Nature Rev. Phys.}\ }\textbf {\bibinfo {volume} {2}},\ \bibinfo
  {pages} {382} (\bibinfo {year} {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Aaronson}(2018)}]{aaronson2018shadowtomography}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Aaronson}},\ }\href {https://arxiv.org/abs/1711.01053} {\bibinfo {title}
  {Shadow tomography of quantum states}} (\bibinfo {year} {2018}),\ \Eprint
  {https://arxiv.org/abs/1711.01053} {arXiv:1711.01053 [quant-ph]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Huang}\ \emph {et~al.}(2020)\citenamefont {Huang},
  \citenamefont {Kueng},\ and\ \citenamefont {Preskill}}]{Huang_2020}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.-Y.}\ \bibnamefont
  {Huang}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Kueng}},\ and\
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Preskill}},\ }\bibfield
  {title} {\bibinfo {title} {Predicting many properties of a quantum system
  from very few measurements},\ }\href
  {https://doi.org/10.1038/s41567-020-0932-7} {\bibfield  {journal} {\bibinfo
  {journal} {Nature Phys.}\ }\textbf {\bibinfo {volume} {16}},\ \bibinfo
  {pages} {1050–1057} (\bibinfo {year} {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bertoni}\ \emph {et~al.}(2024)\citenamefont
  {Bertoni}, \citenamefont {Haferkamp}, \citenamefont {Hinsche}, \citenamefont
  {Ioannou}, \citenamefont {Eisert},\ and\ \citenamefont
  {Pashayan}}]{ShallowShadows}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Bertoni}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Haferkamp}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Hinsche}}, \bibinfo
  {author} {\bibfnamefont {M.}~\bibnamefont {Ioannou}}, \bibinfo {author}
  {\bibfnamefont {J.}~\bibnamefont {Eisert}},\ and\ \bibinfo {author}
  {\bibfnamefont {H.}~\bibnamefont {Pashayan}},\ }\bibfield  {title} {\bibinfo
  {title} {{Shallow shadows: Expectation estimation using low-depth random
  Clifford circuits}},\ }\href {https://doi.org/10.1103/PhysRevLett.133.020602}
  {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. Lett.}\ }\textbf
  {\bibinfo {volume} {133}},\ \bibinfo {pages} {020602} (\bibinfo {year}
  {2024})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bao}\ \emph {et~al.}(2023)\citenamefont {Bao},
  \citenamefont {Nie}, \citenamefont {Xue}, \citenamefont {Cao}, \citenamefont
  {Li}, \citenamefont {Su},\ and\ \citenamefont {Zhu}}]{bao2022all}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Bao}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Nie}}, \bibinfo
  {author} {\bibfnamefont {K.}~\bibnamefont {Xue}}, \bibinfo {author}
  {\bibfnamefont {Y.}~\bibnamefont {Cao}}, \bibinfo {author} {\bibfnamefont
  {C.}~\bibnamefont {Li}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Su}},\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Zhu}},\
  }\bibfield  {title} {\bibinfo {title} {All are worth words: A vit backbone
  for diffusion models},\ }in\ \href@noop {} {\emph {\bibinfo {booktitle}
  {CVPR}}}\ (\bibinfo {year} {2023})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Rombach}\ \emph {et~al.}(2021)\citenamefont
  {Rombach}, \citenamefont {Blattmann}, \citenamefont {Lorenz}, \citenamefont
  {Esser},\ and\ \citenamefont {Ommer}}]{rombach2021highresolution}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Rombach}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Blattmann}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Lorenz}}, \bibinfo
  {author} {\bibfnamefont {P.}~\bibnamefont {Esser}},\ and\ \bibinfo {author}
  {\bibfnamefont {B.}~\bibnamefont {Ommer}},\ }\href@noop {} {\bibinfo {title}
  {High-resolution image synthesis with latent diffusion models}} (\bibinfo
  {year} {2021}),\ \Eprint {https://arxiv.org/abs/2112.10752} {arXiv:2112.10752
  [cs.CV]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Deng}\ \emph {et~al.}(2009)\citenamefont {Deng},
  \citenamefont {Dong}, \citenamefont {Socher}, \citenamefont {Li},
  \citenamefont {Li},\ and\ \citenamefont {Fei-Fei}}]{deng2009imagenet}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Deng}}, \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {Dong}}, \bibinfo
  {author} {\bibfnamefont {R.}~\bibnamefont {Socher}}, \bibinfo {author}
  {\bibfnamefont {L.-J.}\ \bibnamefont {Li}}, \bibinfo {author} {\bibfnamefont
  {K.}~\bibnamefont {Li}},\ and\ \bibinfo {author} {\bibfnamefont
  {L.}~\bibnamefont {Fei-Fei}},\ }\bibfield  {title} {\bibinfo {title}
  {Imagenet: A large-scale hierarchical image database},\ }in\ \href@noop {}
  {\emph {\bibinfo {booktitle} {2009 IEEE conference on computer vision and
  pattern recognition}}}\ (\bibinfo {organization} {Ieee},\ \bibinfo {year}
  {2009})\ pp.\ \bibinfo {pages} {248--255}\BibitemShut {NoStop}%
\end{thebibliography}%


\end{document}
