@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@inproceedings{brown2020language,
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	booktitle = {Conference on {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	year = {2020},
	pages = {},
	organization = {},
	title = {Language {Models} are {Few}-{Shot} {Learners}.},
	volume = {},
}

@article{dong2024xgrammar,
  title={Xgrammar: Flexible and efficient structured generation engine for large language models},
  author={Dong, Yixin and Ruan, Charlie F and Cai, Yaxing and Lai, Ruihang and Xu, Ziyi and Zhao, Yilong and Chen, Tianqi},
  journal={arXiv preprint arXiv:2411.15100},
  year={2024}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{he2024complex,
  title={From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models},
  author={He, Qianyu and Zeng, Jie and He, Qianxi and Liang, Jiaqing and Xiao, Yanghua},
  journal={arXiv preprint arXiv:2404.15846},
  year={2024}
}

@article{hong2024orpo,
  title={Orpo: Monolithic preference optimization without reference model},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  journal={arXiv preprint arXiv:2403.07691},
  volume={2},
  number={4},
  pages={5},
  year={2024}
}

@article{ifeval,
	author = {Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
	journal = {arXiv},
	year = {2023},
	pages = {},
	publisher = {},
	title = {Instruction-{Following} {Evaluation} for {Large} {Language} {Models}},
	volume = {abs/2311.07911},
}

@article{jain2023bring,
  title={Bring your own data! self-supervised evaluation for large language models},
  author={Jain, Neel and Saifullah, Khalid and Wen, Yuxin and Kirchenbauer, John and Shu, Manli and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2306.13651},
  year={2023}
}

@article{jiang2023followbench,
  title={Followbench: A multi-level fine-grained constraints following benchmark for large language models},
  author={Jiang, Yuxin and Wang, Yufei and Zeng, Xingshan and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Shang, Lifeng and Jiang, Xin and Liu, Qun and Wang, Wei},
  journal={arXiv preprint arXiv:2310.20410},
  year={2023}
}

@article{jiang2023preference,
  title={Preference as Reward, Maximum Preference Optimization with Importance Sampling},
  author={Jiang, Zaifan and Huang, Xing and Wei, Chao},
  journal={arXiv preprint arXiv:2312.16430},
  year={2023}
}

@misc{jsonformer2023,
  title = {jsonformer - GitHub Repository},
  author = {{1rgs}},
  year = {2023},
  url = {https://github.com/1rgs/jsonformer}
}

@article{liu2303g,
  title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment (2023)},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={URL http://arxiv. org/abs/2303.16634},
  year={2023}
}

@misc{lmql2023,
  title = {LMQL - GitHub Repository},
  author = {{ETH SRI}},
  year = {2023},
  url = {https://github.com/eth-sri/lmql}
}

@article{meng2024simpo,
  title={SimPO: Simple Preference Optimization with a Reference-Free Reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}

@misc{openai2023structured,
  title = {Introducing Structured Outputs in the API},
  author = {{OpenAI}},
  year = {2023},
  url = {https://openai.com/index/introducing-structured-outputs-in-the-api}
}

@misc{outlines2023,
  title = {Outlines - GitHub Repository},
  author = {{Outlines Development Team}},
  year = {2023},
  url = {https://github.com/outlines-dev/outlines}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{qin2024infobench,
      title={InFoBench: Evaluating Instruction Following Ability in Large Language Models}, 
      author={Yiwei Qin and Kaiqiang Song and Yebowen Hu and Wenlin Yao and Sangwoo Cho and Xiaoyang Wang and Xuansheng Wu and Fei Liu and Pengfei Liu and Dong Yu},
      year={2024},
      eprint={2401.03601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sun2024conifer,
  title={Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models},
  author={Haoran Sun and Lixin Liu and Junjie Li and Fengyu Wang and Baohua Dong and Ran Lin and Ruohui Huang},
  journal={arxiv preprint arXiv:2404.02823},
  year={2024},
  url={https://arxiv.org/abs/2404.02823}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{wang2023pandalm,
  title={Pandalm: An automatic evaluation benchmark for llm instruction tuning optimization},
  author={Wang, Yidong and Yu, Zhuohao and Zeng, Zhengran and Yang, Linyi and Wang, Cunxiang and Chen, Hao and Jiang, Chaoya and Xie, Rui and Wang, Jindong and Xie, Xing and others},
  journal={arXiv preprint arXiv:2306.05087},
  year={2023}
}

@article{xia2024fofo,
  title={FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability},
  author={Xia, Congying and Xing, Chen and Du, Jiangshu and Yang, Xinyi and Feng, Yihao and Xu, Ran and Yin, Wenpeng and Xiong, Caiming},
  journal={arXiv preprint arXiv:2402.18667},
  year={2024}
}

@inproceedings{xu2023wizardlm,
  title={WizardLM: Empowering large pre-trained language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Lin, Qingwei and Jiang, Daxin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

