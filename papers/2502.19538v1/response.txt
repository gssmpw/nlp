\section{Related Work}
Multi-language interoperation between probabilistic programming languages builds
on a wide body of work spanning the programming language and the machine
learning communities. We situate our research in four categories: heterogeneous inference, programmable inference,
multi-language semantics, and the monadic semantics of probabilistic programming
languages.

\newcounter{relwork}
\setcounter{relwork}{1}
\newcommand{\relworksection}[1]{\vspace{0.5em}\noindent\textit{5.\therelwork{}\phantom{sp}\addtocounter{relwork}{1}~#1}}

\relworksection{Heterogeneous inference in probabilistic programming languages.}
There are existing probabilistic programming languages and systems that enable
users to blend different kinds of inference algorithms when performing inference
on a single probabilistic program. Particularly relevant are approaches that
leverage \emph{Rao-Blackwellization} in order to combine exact and approximate
inference strategies into a single system. Within this vein,
Goodman et al., "Probabilistic Model-Based Methods for Combinatorial Optimization"__
introduced \emph{semi-symbolic
	inference}, where the idea is to perform exact marginalization over
distributions whose posteriors can be determined to have some closed-form
solution. Other works that use variations of Rao-Blackwellization
__all seek to explicitly marginalize out
portions of the distribution by using closed-form exact posteriors when
feasible. The main difference between these approaches to Rao-Blackwellization
and our proposed approach is that these systems do not expose \emph{separate
	languages} that correspond to different phases of the inference algorithm: they
provide a single unified syntax in which the user programs. As a consequence,
they all rely on (semi-)automated means of automatically discovering which portions can
be feasibly Rao-Blackwellized; this process can be difficult to control and lead
to unpredictable performance. Our multi-language approach
has the following benefits: (1) predictable and interpretable performance due to the explicit
choice of inference algorithm that is exposed to the user; and (2) amenability to
modular formalization, since we can verify the correctness of each inference
strategy and verify the correctness of their composition on the boundary. %
We hope to incorporate the interesting ideas of these related works into \multippl{},
in particular closed-form approaches to exact marginalization of continuous distributions.

There is a broad literature on heterogeneous inference that we hope to
eventually draw on to build a richer vocabulary of sub-languages to add to
\multippl{}. __described an approach to
collapsed approximate inference that dynamically blends exact inference via
knowledge compilation and approximate inference via sampling; we are curious if
this can be integrated with our system. We also look towards incorporating more
stateful inference algorithms such as Markov-Chain Monte Carlo into
\multippl{}, and aim to investigate this in future work.

\relworksection{Programmable inference.}
Programmable inference (or inference (meta-)programming)
provide probabilistic programmers with a meta-language for defining new inference algorithms within a single
PPL by offering language primitives that give direct access to the inference
runtime___. %
__ provides a black-box
interface to underlying inference algorithms alongside combinators to operate on
these interfaces, __ designs a domain specific language (DSL) for inference which produces
correct-by-construction importance weights.

We see programmable inference as a viable means of designing new inference
algorithms which we can incorporate into a multi-language. Furthermore, a
multi-language setting can offer inference programmers the ability to abstract
away the nuances of the inference process, lowering the barrier to entry for
this type of development. One common thread through much of the work on
inference programming is core primitives which encapsulate the building blocks
for inference algorithms including resample-move sequential Monte Carlo,
variational inference, many other Markov chain Monte Carlo methods. These primitives
could be designed formally as DSLs, which would be a great addition to a
multi-language and something we look forward to developing in future work.


\relworksection{Nested inference.}%
~Nested inference enriches a probabilistic programming language with a
first-class \texttt{infer} or \texttt{normalize} construct that enables the
programmer to query for the probability of an event inside their probabilistic
programs__.
Nested inference is a useful programming construct that enables a variety of new
applications, such as in cognitive science where one agent may wish to reason
about the intent of another__.
Nested inference is similar in spirit to our multi-language approach in that it
gives the programmer control over when inference is performed
on their program and what inference algorithm is used.
A key difference between nested inference and our multi-language approach is
that the former provides access to the inference result
whereas MultiPPL's boundary forms do not. This difference is essential.
In our view, there is the following analogy to non-probabilistic programming:
performing nested inference is like invoking a compiler and inspecting the
resulting binary, whereas performing multi-language inference is like
interoperating through an FFI.
In the non-probabilistic setting, these two situations require distinct semantic models ---
compare, for example, formal models of introspection and dynamic code generation__ with formal models of FFI-based interoperability__ ---
and we believe the same is likely true of our probabilistic setting.

In the future, it would be interesting to consider integrating nested
inference within a multi-language setting and exploring the consequences
of this new feature on language interoperation.
It would also be quite interesting to investigate whether our multi-language inference
strategy could be compiled to, or expressed in terms of, rich nested inference constructs.
A preliminary analysis reveals a number of basic differences between \multippl{}'s
inference strategy and standard models of nested inference, so such a compilation scheme
would likely require significant modifications to nested inference --- for a detailed technical
discussion, see \cref{app:sec:comparison-with-nested-inference}.




\relworksection{Multi-language semantics.} Today, it is often the case that
probabilistic programming languages are embedded in a host, non-probabilistic
language__.
However, these PPLs assume their host semantics will not interfere with the
semantics of the PPL's inference process. This work is the first of its kind to
build on top of multi-language semantics to reason about inference algorithms.

Multi-language semantics, while new to the domain of probabilistic programming,
has had a large impact on the broader programming language community. They play
a fundamental role in reasoning about
interoperation__, gradual
typing__, and
compositional compiler verification___. There are two
styles of calculi which represent the current approaches to multi-language
interoperation. These are the \emph{multi-languages} approach from
__and the a more fine-grained approach by
__ using a \emph{gradually typed lambda calculus}.

__ takes a traditional programming language
approach to the gradual typing of PPLs and defines a gradually typed
probabilistic lambda calculus which allows a user to migrate a PPL from an
untyped- to typed- language --- a nontrivial task involving a probabilistic
coupling argument for soundness. In contrast, our work centers on how
multi-languages can help the interoperation of inference algorithms across
semantic domains.

__ establishes, informally, a common interface
for PPLs to interact with scientific simulators across language boundaries. In
this work, the semantics of the simulator is a black-box distribution defined in
some language, which may or may not be probabilistic, and a separate PPL may
interact with the simulator during the inference process. While
__ works across language boundaries, they do not
reason about interoperation --- they only involve
one inference algorithm --- and they do not provide any soundness guarantees.
That said, __ demonstrates a simple boundary allowing for rapid
integration of many practical probabilistic programming languages, something we
also strive for.


\relworksection{Monadic semantics of PPLs.}
Numerous monads have been developed
for use as semantic domains
that capture the various notions of computation
used in probabilistic inference.
The fundamental building block for each of these models is the
probability monad $\giry$, along with its generalizations
to monads of subdistributions and measures__.
Using this probability monad to give semantics to probabilistic programs
goes back to at least
__, who further build on this basic idea by providing a model of exact inference via knowledge compilation
in terms of stateful manipulation of finite conditional
probability spaces and random variables.
Our semantics of \multippl{}
builds on this line of
work in giving monadic semantics to probabilistic computations