\section{Conclusion}
In this work, we propose a simple yet effective weighted fine-tuning approach that directs the model's attention towards regions with significant transfer risk, tailored to the medical semantic segmentation problem. Specifically, we introduce a pixel-level transferability-guided transfer risk map, which quantifies the transfer hardness for each pixel and the potential risks of negative transfer associated with them. During the fine-tuning phase, we calculate weighted loss values across all pixels and average them exclusively over the foreground pixels. Extensive experiments demonstrate that our proposed fine-tuning method achieves significantly enhanced performance when transferring knowledge between distinct modalities and tasks, indicating that it indeed avoids negative transfer from diverse modalities and tasks while learning beneficial knowledge for segmentation across multiple modalities and tasks. The simplicity of the proposed method also makes it easy to integrate into more advanced architectures such as vision transformer, and more sophisticated transfer learning paradigms. 
