\section{Related Works}
\subsection{AI-Assisted Counseling Psychotherapy}
In the field of mental health, face-to-face campus counseling and mental health services are considered effective solutions to support students' increasing needs for mental health services \citep{zabek2023roles}. With the rise of AI, researchers have explored the adaptation of AI in psychotherapy activities. For example, machine learning techniques have been used in mental health tools and the research covered a variety of topics, including counselor adaptability and effectiveness \citep{perez2019makes}, the distinction between personalized and standardized counseling language \citep{althoff2016large}, shifts in psychological perspectives and topic adherence \citep{althoff2016large,wadden2021effect}, therapeutic interventions \citep{lee2019identifying}, empathy expression \citep{sharma2020computational}, transformative moments \citep{pruksachatkun2019moments}, counseling approaches \citep{perez2022pair,shah2022modeling}, and conversational involvement \citep{sharma2020engagement}. AI systems can analyze various types of behavioral data such as video, audio, and text from therapy sessions. This allows clinicians to receive immediate insight and feedback without relying on patients to complete extra self-report measures. Studies have shown that AI systems can accurately predict patient-reported alliance and symptom ratings based on behavioral markers extracted from video recordings of psychotherapy sessions. Verbal features \citep{aafjes2020language,vail2022toward,goldberg2020machine}, body and facial movements \citep{cohen2021nonverbal}, have all been considered as directly associated with self-reported measures of the working alliance.

Recently, impressed by the outstanding performance of LLM in many fields \citep{wang2024evaluating,kung2023performance,petridis2023anglekindling}, some studies tried to develop LLM-based tools to participate in traditional face-to-face psychotherapy. Particularly, in addition to classic functions like emotion recognition \citep{muller2024recognizing} and information retrieval \citep{stade2024large}, other advanced functions (e.g., LLM-based tools for counseling psychotherapists supervision \citep{li2024automatic}, conversational topic recommendation in counseling \citep{gunal2024conversational}, psychotherapists training \citep{wang2024patient}) are emerging.

%Specifically, by analyzing various types of behavioral data such as video, audio, and text from each therapy session, AI systems can automatically assess the level of rapport and symptoms, providing clinicians with immediate insight and feedback without relying on patients to complete additional self-report measures. Studies have shown that AI systems can make accurate predictions of patient-reported alliance and symptom ratings based on behavioral markers extracted from video recordings of psychotherapy sessions. Verbal features \citep{aafjes2020language,vail2022toward,goldberg2020machine}, body and facial movements \citep{cohen2021nonverbal} have all been directly linked to self-reported measures of the working alliance. Combining audio, video, and text features may further improve performance \citep{aafjes2024feasibility}. Moreover, AI-powered systems have been designed to enhance the capabilities of mental health professionals. For instance, Tanana et al. \citep{tanana2019development} introduced a machine learning system for counselor training. In a similar vein, Sharma et al. \citep{sharma2021towards,sharma2023human} created a system based on GPT-2 and reinforcement learning to provide empathy-centered feedback to novice online peer supporters. Recently, impressed by the outstanding performance of LLM in many fields \citep{wang2024evaluating,kung2023performance,petridis2023anglekindling}, some studies tried to develop LLM-based tools to participate in traditional face-to-face psychotherapy. Particularly, exclude classic functions (e.g., emotion recognition \citep{muller2024recognizing}, information retrieval \citep{stade2024large}), other functions like LLM-based tools for counseling psychotherapists supervision \citep{li2024automatic}, conversational topic recommendation in counseling \citep{gunal2024conversational}, psychotherapists training \citep{wang2024patient} are emerging.

However, although a small number of studies \citep{grodniewicz2023waiting, haber2024artificial} have mentioned the challenges of integrating large language models into traditional counseling modes, to the best of our knowledge, there is still a lack of user-centered (human psychotherapists and clients) research evaluating the current LLMs from the perspective of treating LLMs as supportive artificial intelligence systems in the context of human-computer interaction.

\subsection{Autonomous Psychotherapy by Conversational AI}


Given the advantages like ease of accessibility, and personalized service \citep{habicht2024closing}, researchers have also delved into developing virtual assistants and chatbots for autonomous health support \citep{richards2023principlist,nicol2022chatbot} and counseling services \citep{srivastava2023response}. Functionally, such AI systems can also be broadly classified into two categories. The first category provides daily counseling or chat services, including listening, empathy and reassurance, simulating the role of a friend or experienced elder \citep{xu2022survey,valtolina2021design}. For example, some studies \citep{harilal2020caro, kornfield2022meeting} tried to propose a digital tool for people with self-managing mental health concerns, and SERMO for emotion regulation \citep{denecke2020mental}. Meyerhoff et. al \citep{meyerhoff2022meeting} studied changes in the behavior of young people with depression who sought help from the community online, and provided recommendations for the corresponding design of future digital mental health tools. Other business products include OneRemission\footnote{https://keenethics.com/project-one-remission}, and Woebot\footnote{https://woebothealth.com/}. However, this type of chatbot still cannot replace professional psychotherapy services.

Another type of chatbot aims to mimic human therapists to replace them in existing counseling psychotherapy. However, numerous studies have expressed skepticism about the capability of this type of chatbot \citep{xu2022survey,brown2021ai}. Particularly, before 2023, most mental health chatbots were based only on traditional NLP techniques \citep{laranjo2018conversational}. The lack of visual information may lead to lower user engagement and a poor understanding of the user's current state due to the absence of facial emotion and movement analysis \citep{miner2019key}. 

With the development of AI, the incorporation of cognitive mechanisms has significantly enhanced the capabilities of LLMs \citep{binz2023turning}, which demonstrate emergent behaviors reminiscent of complex physical systems \citep{wei2022emergent}. Currently, based on the rapid development of LLM technology and its surprising capabilities, more and more works \citep{nie2024llm,chiu2024computational} have begun to target the second type of autonomous psychotherapeutic agent. However, despite the fast development of LLM after 2023, concerns about the capabilities of LLM-based chatbots \citep{grodniewicz2023waiting,floridi2023ai} still existed, though some have claimed that properly prompted LLMs are capable of complex reasoning \citep{wei2022chain} and even exhibit capabilities similar to psychologists \citep{ullman2023large}. One significant research gap for the adoption of the LLM into psychotherapy is that, rapid technology iteration does not necessarily lead to wide adoption, and the views of human participants as stakeholders in the different types of LLM-based autonomous psychotherapeutic agents are still missing from the extant literature in terms of more extensive discussions and analyses.
%As mentioned before, psychotherapy has traditionally been defined as a relationship between two individuals. 




%\subsection{Large Language Model Technology}