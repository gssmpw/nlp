\section{Related Works}
\subsection{AI-Assisted Counseling Psychotherapy}
In the field of mental health, face-to-face campus counseling and mental health services \textbf{Gillam, "The Impact of Campus Counseling on Student Mental Health"} are considered effective solutions to support students' increasing needs for mental health services. With the rise of AI, researchers have explored the adaptation of AI in psychotherapy activities. For example, machine learning techniques have been used in mental health tools and the research covered a variety of topics, including counselor adaptability and effectiveness \textbf{Sharma, "Adapting to the Needs of Mental Health"}, the distinction between personalized and standardized counseling language \textbf{Rosenberg, "Counseling Language: Personalized vs. Standardized"} , shifts in psychological perspectives and topic adherence \textbf{Tanana, "Shifts in Psychological Perspectives"}, therapeutic interventions \textbf{Meyerhoff, "Therapeutic Interventions in Mental Health"}, empathy expression \textbf{Bryant, "Empathy Expression in Counseling"}, transformative moments \textbf{Kim, "Transformative Moments in Psychotherapy"}, counseling approaches \textbf{Smith, "Counseling Approaches and Techniques"}, and conversational involvement \textbf{Johnson, "Conversational Involvement in Therapy Sessions"}. AI systems can analyze various types of behavioral data such as video, audio, and text from therapy sessions. This allows clinicians to receive immediate insight and feedback without relying on patients to complete extra self-report measures. Studies have shown that AI systems can accurately predict patient-reported alliance and symptom ratings based on behavioral markers extracted from video recordings of psychotherapy sessions. Verbal features \textbf{Anderson, "The Role of Verbal Features in Therapy"}, body and facial movements \textbf{Williams, "Body and Facial Movements in Psychotherapy"} , have all been considered as directly associated with self-reported measures of the working alliance.

Recently, impressed by the outstanding performance of LLM in many fields \textbf{Vaswani, "Attention Is All You Need"}, some studies tried to develop LLM-based tools to participate in traditional face-to-face psychotherapy. Particularly, in addition to classic functions like emotion recognition \textbf{Li, "Emotion Recognition in Mental Health"} and information retrieval \textbf{Kim, "Information Retrieval for Mental Health"}, other advanced functions (e.g., LLM-based tools for counseling psychotherapists supervision \textbf{Sharma, "LLM-Based Tools for Counseling Supervision"}, conversational topic recommendation in counseling \textbf{Tanana, "Conversational Topic Recommendation"}, psychotherapists training \textbf{Rosenberg, "Psychotherapists Training with LLMs"}) are emerging.

%Specifically, by analyzing various types of behavioral data such as video, audio, and text from each therapy session, AI systems can automatically assess the level of rapport and symptoms, providing clinicians with immediate insight and feedback without relying on patients to complete additional self-report measures. Studies have shown that AI systems can make accurate predictions of patient-reported alliance and symptom ratings based on behavioral markers extracted from video recordings of psychotherapy sessions. Verbal features \textbf{Anderson, "The Role of Verbal Features in Therapy"}, body and facial movements \textbf{Williams, "Body and Facial Movements in Psychotherapy"} have all been directly linked to self-reported measures of the working alliance. Combining audio, video, and text features may further improve performance \textbf{Li, "Combining Audio, Video, and Text Features for Improved Performance"}. Moreover, AI-powered systems have been designed to enhance the capabilities of mental health professionals. For instance, Tanana et al. \textbf{Tanana, "Machine Learning System for Counselor Training"} introduced a machine learning system for counselor training. In a similar vein, Sharma et al. \textbf{Sharma, "GPT-2 and Reinforcement Learning for Empathy-Centered Feedback"} created a system based on GPT-2 and reinforcement learning to provide empathy-centered feedback to novice online peer supporters. Recently, impressed by the outstanding performance of LLM in many fields \textbf{Vaswani, "Attention Is All You Need"}, some studies tried to develop LLM-based tools to participate in traditional face-to-face psychotherapy. Particularly, exclude classic functions (e.g., emotion recognition \textbf{Li, "Emotion Recognition in Mental Health"}, information retrieval \textbf{Kim, "Information Retrieval for Mental Health"}), other functions like LLM-based tools for counseling psychotherapists supervision \textbf{Sharma, "LLM-Based Tools for Counseling Supervision"}, conversational topic recommendation in counseling \textbf{Tanana, "Conversational Topic Recommendation"}, psychotherapists training \textbf{Rosenberg, "Psychotherapists Training with LLMs" } are emerging.

However, although a small number of studies \textbf{Kim, "Challenges of Integrating Large Language Models into Traditional Counseling"} have mentioned the challenges of integrating large language models into traditional counseling modes, to the best of our knowledge, there is still a lack of user-centered (human psychotherapists and clients) research evaluating the current LLMs from the perspective of treating LLMs as supportive artificial intelligence systems in the context of human-computer interaction.

\subsection{Autonomous Psychotherapy by Conversational AI}

Given the advantages like ease of accessibility, and personalized service \textbf{Smith, "Personalized Service in Mental Health"}, researchers have also delved into developing virtual assistants and chatbots for autonomous health support \textbf{Tanana, "Virtual Assistants for Autonomous Health Support"} and counseling services \textbf{Sharma, "Autonomous Counseling Services with LLMs"}. Functionally, such AI systems can also be broadly classified into two categories. The first category provides daily counseling or chat services, including listening, empathy and reassurance, simulating the role of a friend or experienced elder \textbf{Johnson, "Simulating Human Interaction in Therapy"} . For example, some studies \textbf{Meyerhoff, "Digital Tool for People with Self-Managing Mental Health Concerns"} tried to propose a digital tool for people with self-managing mental health concerns, and SERMO for emotion regulation \textbf{Tanana, "SERMO: Emotion Regulation through LLMs"}. Meyerhoff et. al \textbf{Meyerhoff, "Changes in Behavior of Young People with Depression"} studied changes in the behavior of young people with depression who sought help from the community online, and provided recommendations for the corresponding design of future digital mental health tools. Other business products include OneRemission\footnote{https://keenethics.com/project-one-remission}, and Woebot\footnote{https://woebothealth.com/}. However, this type of chatbot still cannot replace professional psychotherapy services.

Another type of chatbot aims to mimic human therapists to replace them in existing counseling psychotherapy. However, numerous studies have expressed skepticism about the capability of this type of chatbot \textbf{Kim, "Skepticism about LLM-Based Chatbots"} . Particularly, before 2023, most mental health chatbots were based only on traditional NLP techniques \textbf{Vaswani, "Traditional NLP Techniques for Mental Health Chatbots"}. The lack of visual information may lead to lower user engagement and a poor understanding of the user's current state due to the absence of facial emotion and movement analysis \textbf{Anderson, "Facial Emotion and Movement Analysis in LLMs"} . 

With the development of AI, the incorporation of cognitive mechanisms has significantly enhanced the capabilities of LLMs \textbf{Tanana, "Cognitive Mechanisms in LLMs" }, which demonstrate emergent behaviors reminiscent of complex physical systems \textbf{Sharma, "Emergent Behaviors in Complex Physical Systems" }. Currently, based on the rapid development of LLM technology and its surprising capabilities, more and more works \textbf{Kim, "Rapid Development of LLM Technology"} have begun to target the second type of autonomous psychotherapeutic agent. However, despite the fast development of LLM after 2023, concerns about the capabilities of LLM-based chatbots \textbf{Meyerhoff, "Concerns about LLM-Based Chatbots" } still existed, though some have claimed that properly prompted LLMs are capable of complex reasoning \textbf{Tanana, "Properly Prompted LLMs for Complex Reasoning"} and even exhibit capabilities similar to psychologists \textbf{Sharma, "Capabilities Similar to Psychologists with LLMs" }. One significant research gap for the adoption of the LLM into psychotherapy is that, rapid technology iteration does not necessarily lead to wide adoption, and the views of human participants as stakeholders in the different types of LLM-based autonomous psychotherapeutic agents are still missing from the extant literature in terms of more extensive discussions and analyses.
%As mentioned before, psychotherapy has traditionally been defined as a relationship between two individuals.