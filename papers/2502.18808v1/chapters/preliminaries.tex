\section{Preliminaries}
\subsection{Implicit Loss in Neural ODE}
The flow-based generative models uses invertible function $f:\mathbb{R}^D \rightarrow \mathbb{R}^D$ to map points from prior to data distribution~\citep{density_real_NVP, dinh2014nice}. 
Given a latent variable $\mathbf{z}\sim q(\mathbf{z})$, the parameterized model $p_\theta(x)$ can be evaluated as:
\begin{equation}\label{eq: change_of_variables}
    \log p_\theta(\mathbf{x}) = \log q(\mathbf{z}) - \log \det \left| \frac{\partial f(\mathbf{z})}{\partial \mathbf{z}} \right|
\end{equation}
where $\partial f(\mathbf{z}) / \partial \mathbf{z}$ is the Jacobian of $f$.
To avoid $\mathcal{O}(D^3)$ cost in determinant computation, 
\citet{neural_ode} presented continuous normalizing flows, mapping the reverse process through ordinary differential equations (ODEs) defined by the parameterized function $f(\mathbf{z}(t),t;\theta)$. Following 
~\citet{neural_ode}, 
Equation \ref{eq: change_of_variables} can be re-formulated in integral form:
\begin{equation}\label{eq: ode_likelihood}
    \log p_\theta(\mathbf{z}(t_1)) = \log q(\mathbf{z}(t_0)) - \int_{t_0}^{t_1} \mathrm{Tr} \left( \frac{\partial f}{\partial \mathbf{z}(t)} \right) \, dt.
\end{equation}
where $\mathbf{z}(t_0) = \mathbf{z_0}$ is sampled from a  initial distribution $q(\mathbf{z_0})$ and $\mathbf{z}(t_1) = \mathbf{x}$ denotes the observed samples. 

\subsection{Hutchinson Trace Estimator}\label{sec: Hutchinson}
Given a jacobian matrix $\mathbf{A} \in \mathbb{R}^{D \times D}$, the exact trace $\mathrm{Tr}(\mathbf{A})$ requires computing the full Jacobian matrix,
which is prohibitive in practice when $D$ increases.
Fortunately, the Hutchinson trace estimator~\citep{Hutchinson89} is a computational technique used to approximate the trace of a large matrix efficiently. 
The method first involves generating random vector $\mathbf{v}_i \in \mathbb{R}^D$, and then computes the product $\mathbf{v}_i^\top \mathbf{A} \mathbf{v}_i$ for each vector. 
Thus, we can get an unbiased estimate of the trace:
\begin{equation}\label{eq: hutchinson_unbaised}
    \mathrm{Tr}(\mathbf{A}) = \E_{p(\mathbf{v})}[\mathbf{v}^\top\mathbf{A}\mathbf{v}]
\end{equation}
for all random variable satisfied $\E_{p(\mathbf{v})}[\mathbf{v}^\top\mathbf{v}] = I$. 
Therefore, the trace can be estimated by Monte Carlo using Hutchinson's trace estimator~\citep{Hutchinson89}:
\begin{equation}\label{eq: hutchinson}
    \mathrm{Tr}(\mathbf{A}) \approx \frac{1}{m} \sum_{i=1}^{m} \mathbf{v}_i^\top \mathbf{A} \mathbf{v}_i=:H_m(\mathbf{A}),
\end{equation}
where each $\mathbf{v}_i$ are $i.i.d.$ samples from $p(\mathbf{v})$, typically from a Gaussian distribution~\citep{Hutchinson89}. 
$m$ denotes the number of matrix-vector multiplication queries~\citep{avron2011matrixvector1, roosta2015matrixvector2}.
Leveraging the Hutchinson estimator, \citet{FFJORD} proposed FFJORD, a normalizing flow model trained with a free-form Jacobian, which extends the potential for training divergence-based likelihood in generative modeling~\citep{FFJORD,song2020sliced, forward_backward_SDE}.

\subsection{Likelihood Training of Schrödinger Bridge Models}\label{sec: fb-sde}
The dynamic Schrödinger bridge (SB) problem is defined as solving:
\begin{equation}
    \min_{\mathbf{Q} \in \mathcal{P}(p_{\text{data}}, p_{\text{prior}})} D_{KL}(\mathbf{Q} \parallel \mathbf{P}),
\end{equation}
where ${\mathbf{Q} \in \mathcal{P}(p_{\text{data}}, p_{\text{prior}})}$ denotes a set of \textit{path measures} with marginals probability density $p_{\text{data}}$ and $p_{\text{prior}}$ at $t=0$ and $t=T$, respectively. $\mathcal{P}$ is a prior measure typically defined via Brownian motion.
To solve the SB problem, \citet{forward_backward_SDE} proposed divergence-based likelihood training of Forward-Backward Stochastic Differential Equations (FB-SDE), a framework transforms the optimality condition of SB into a set of SDEs:
% a framework transforming the optimality condition of SB into a set of SDEs:
\begin{align}
\scalebox{0.95}{$
    \mathrm{d}\mathbf{x}_t = \left[f(\mathbf{x}_t, t) + \beta_t \nabla_{\mathbf{x}} \log \overrightarrow{\psi}_t(\mathbf{x}_t, t)\right]\mathrm{d}t + \sqrt{\beta_t}\mathrm{d}\mathbf{w}_t $}\tag{6a}\label{eq: fb-sde-b}\\
    \scalebox{0.95}{$
    \mathrm{d}\mathbf{x}_t = \left[f(\mathbf{x}_t, t) - \beta_t \nabla_{\mathbf{x}} \log \overleftarrow{\varphi}_t(\mathbf{x}_t, t)\right]
    \mathrm{d}t + \sqrt{\beta_t}\mathrm{d}\mathbf{w}_t $}\tag{6b}\label{eq: fb-sde-f}
\end{align}
where $f(\cdot, t):\R^d\rightarrow\R^d$ and $\beta_t$ denote the vector field and time-varying scalar; $\mathbf{x}_0 \sim p_{\text{data}}$ and $\mathbf{x}_0 \sim p_{\text{prior}}$. 
$\nabla_{\mathbf{x}} \log \overleftarrow{\psi}_t(\mathbf{x}_t, t)$ and $\nabla_{\mathbf{x}} \log \overrightarrow{\varphi}_t(\mathbf{x}_t, t)$ are the optimal forward and backward drifts for SB.
$\mathbf{w}_t$ is standard Wiener process.
Given the models $\overleftarrow{z}_t^\theta$ and $\overrightarrow{z}_t^\phi$, we can learn the forward and backward policies $\overleftarrow{z}_t = \sqrt{\beta_t}\nabla_{\mathbf{x}} \log \overleftarrow{\psi}_t$ and $\overrightarrow{z}_t = \sqrt{\beta_t}\nabla_{\mathbf{x}} \log \overleftarrow{\varphi}_t$, respectively. 
We list two simplified divergence-based objectives of SB model in an alternate training scheme:
\begin{align}
\scalebox{0.85}{$
    \Tilde{\mathcal{L}}_{SB}(\mathbf{x}_0) = - \int_{0}^{T}\E_{\mathbf{x}_t\sim \ref{eq: fb-sde-b}}\left[ \frac{1}{2}\|\overrightarrow{z}_t^\phi\|^2 + \sqrt{\beta_t}\nabla_{\mathbf{x}} \cdot\overrightarrow{z}_t^\phi + \overleftarrow{z}_t^\top\overrightarrow{z}_t^\phi\right] \mathrm{d}t
    $} \tag{7a}\label{eq: fb-sde-train-b}\\
\scalebox{0.85}{$
    \Tilde{\mathcal{L}}_{SB}(\mathbf{x}_T) = - \int_{0}^{T}\E_{\mathbf{x}_t\sim \ref{eq: fb-sde-f}}\left[ \frac{1}{2}\|\overleftarrow{z}_t^\theta\|^2 + \sqrt{\beta_t}\nabla_{\mathbf{x}} \cdot\overleftarrow{z}_t^\theta + \overrightarrow{z}_t^\top\overleftarrow{z}_t^\theta\right] \mathrm{d}t 
$}\tag{7b}\label{eq: fb-sde-train-f}
\end{align}
where the divergence terms in Equation \ref{eq: fb-sde-train-b} and Equation \ref{eq: fb-sde-train-f} can be approximated by Hutchinson estimator \citep{Hutchinson89}.
% introduced in \Cref{sec: Hutchinson}. 
The divergence-based likelihood training paradigm enables the Schrödinger bridge model to use the forward policy $\overleftarrow{z}_t$ to build the optimal path governing samples towards $p_{\text{prior}}$ with optimal transport guarantee.
This addressed the weak transport properties in SGM and enriches its architecture by introducing the nonlinear drifts into the learning process under the guarantee of optimal transport. 








