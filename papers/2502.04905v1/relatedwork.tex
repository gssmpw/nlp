\section{Related Work}
\vspace*{-1mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Static analysis.} RacerX \cite{racerx} is a static analyser for C
based primarily on a lockset analysis. The tool implements many heuristics to
deal with analysis mistakes and has been successfully used to find bugs in the
kernels of several operating systems. Compared to our approach, RacerX uses only
a very simple pointer analysis for the representation of locks.
RacerD~\cite{racerd} is a compositional analyser implemented in the Infer
framework. It provides scalability by analysing each function only once. Unlike
us, RacerD targets Java programs with structural locking, assuming that all
locking operations are balanced. \otwo \cite{o2} is another static checker
building on the notion of origins unifying threads and events. The approach was
implemented for C, C++, and Java/Android; and used to find many previously
unknown bugs in real-world code. However, as we show in our experiments, it can
still miss many data races in smaller but real-world programs.

On the other side, there are tools focused on soundness, rather than race
detection. Goblint \cite{goblint} and Astr√©e~\cite{astree2,astree1} rely on a
thread-modular abstract interpretation to soundly over-approximate thread
behaviour. The work \cite{goblint} further proposes a way to handle common
locking schemes in Linux driver devices. In our approach, we are not interested
in the analysis of multithreaded programs in general and we can consequently
afford more drastic approximations that seem to be sufficient for data race
detection.  We also focus on under-approximation to detect bugs.

As an alternative to static data race detection, various approaches based on
\emph{testing} and \emph{dynamic analysis} can be used. A big challenge for
these approaches is the fact that errors like data races can manifest in very
rare behaviours only, which are difficult to catch, even through many repeated
test runs. Coverage of such rare behaviours can be improved using approaches
such as \emph{systematic testing}~\cite{schedspec12} or \emph{noise-based
testing}~\cite{contestframework03,noise15}. Another way is to use
\emph{extrapolating dynamic checkers}, such
as~\cite{Eraser,goldilocks07,fasttrack09}, which can report warnings about
possible errors even if those are not seen in the testing runs, based on
spotting their symptoms. However, even though such checkers have proven quite
useful in practice, they can, of course, still miss rarely occuring errors.
Moreover, monitoring a run of large software through such checkers may be quite
expensive too. 

% Combining static and dynamic analysis may then leverage advantages of both
% approaches, allowing static analysis to be more focused and hence more
% efficient~\cite{noise15,bigfoot17}.

%!!!!!!!!!!!!!!!!!!!!!!!
\enlargethispage{6mm}
%!!!!!!!!!!!!!!!!!!!!!!!

Approaches based on \emph{model checking}, i.e., exhaustive state-space
exploration, can guarantee the discovery of all potentially present errors --
either in general or at least up to some bound, often given in the number of
context switches. However, so far, the scalability of these techniques is not
sufficient to handle large industrial code, even when combined with methods such
as \emph{sequentialisation}~\cite{lal-reps-08,lazy-seq-16} and others used in
the newest tools such as Deagle~\cite{deagle}. Indeed, this shows up in our
experiments too.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace*{-3mm}