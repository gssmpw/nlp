\section{Conclusion}
We accelerate video diffusion transformers by exploiting sparse attention. We reveal that attention heads have inherent sparsity patterns and we classify them into spatial head and temporal head. We proposed Sparse VideoGen (SVG), a training-free method to utilize these sparsity patterns for end-to-end efficiency boosts, including an efficient online profiling algorithm and an efficient inference system. On representative open video diffusion transformers (CogVideoX-v1.5 and HunyuanVideo), SVG demonstrates prominent end-to-end speedup without losing quality. 



\section*{Impact Statement}
This paper presents work that aims to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.

\section*{Acknowledgment}
We thank Guangxuan Xiao and Zihao Ye for the visualizations and kernel designs.