\section{TrustRAG Library}
TrustRAG is a configurable and modular Retrieval-Augmented Generation (RAG) framework designed for "reliable input and trustworthy output." It consists of key components such as document parsing, text chunking, query optimization, retrieval ranking, content compression, model generation, and answer citation. This section highlights its innovations in semantic enhancement, usefulness enhancement, and citation enhancement.

\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{figures/TrustRAG_Library.pdf}
\caption{An overview of the TrustRAG framework.}
\label{fig:trustrag_overview}
\end{figure}

% \input{figures/library_dir}

\subsection{Semantic-Enhanced Indexing}
Existing text chunking methods, while efficient, often lead to significant semantic loss, particularly when handling long or complex documents~\cite{sarthi2024raptor}. Simple character-based or paragraph-based splitting can disrupt contextual coherence, making it difficult for downstream retrieval and generation tasks to fully utilize the semantic information embedded in the text. 

To address this issue, TrustRAG introduces the \textit{semantic-enhanced chunking} to improve the semantic integrity and coherence for each chunk. Specifically, we firstly take the \ac{LLM} to apply co-reference resolution for each document, which resolves ambiguities caused by pronouns or incomplete references. For instance, when a pronoun like "it" appears in a sentence, the system identifies its antecedent and restores the missing context, thereby enhancing the semantic completeness of the text. This process not only recovers lost semantic information but also provides more accurate contextual support for subsequent generation tasks.
Moreover, we standardize the time fields in the document by converting the relative time references into standardize date formats based on the document publication date. For example, if the document's publication date is ``2025-02-18'', terms like ``yesterday'' and ``last Friday'' will be converted to ``2025-02-17'' and ``2025-02-14'', respectively. 
%To address this issue, TrustRAG introduces \textbf{context decontextualization}, a technique that ensures semantic integrity and coherence in text chunks. By leveraging coreference resolution and semantic completion techniques, TrustRAG resolves ambiguities caused by pronouns or incomplete references. For instance, when a pronoun like "it" appears in a sentence, the system identifies its antecedent and restores the missing context, thereby enhancing the semantic completeness of the text. 
This process not only recovers lost semantic information but also provides more accurate contextual support for subsequent generation tasks. The implementation of this feature can be found in \texttt{trustrag/modules/refiner/decontextualizer.py}.

Furthermore, TrustRAG supports advanced semantic segmentation techniques that dynamically identify semantic boundaries using embedding technologies and large language models (LLMs). Unlike static chunking methods, these techniques allow the system to adaptively split text based on its semantic structure, ensuring higher-quality chunks that preserve contextual coherence. The code is available in \texttt{trustrag/modules/chunks/semantic\_chunk.py}. These innovations improve the quality of text indexing, laying a solid foundation for reliable retrieval and generation.

\subsection{Utility-Enhanced Retrieval}
In conventional RAG systems, the relevance of retrieved documents is often determined solely by vector similarity. However, high similarity does not always translate to usefulness for the generation task. In some cases, even irrelevant documents may inadvertently improve system accuracy, highlighting the need for more intelligent mechanisms to evaluate the utility of retrieved results~\cite{cuconasu2024power}.
TrustRAG addresses this limitation by introducing two key innovations: \textbf{usefulness judgement} and \textbf{fine-grained evidence extraction}.
\begin{itemize}
    \item \textbf{Usefulness Judgement:} TrustRAG employs large language models (LLMs) as discriminators to assess the utility of retrieved documents. Through carefully designed prompts, the system evaluates the relevance of each document to the user's query and the generation task. This evaluation goes beyond surface-level similarity, incorporating deeper contextual understanding to ensure that only the most useful documents are selected. See \texttt{trustrag/modules/judger/llm\_judger.py}.
    
    \item \textbf{Fine-Grained Evidence Extraction:} After identifying useful documents, TrustRAG extracts the most relevant sentences through fine-grained evidence extraction. This process leverages model distillation techniques to reduce computational costs while maintaining high accuracy and relevance. By focusing on the most pertinent information, the system ensures that the generation task receives high-quality inputs. See \texttt{trustrag/modules/refiner/compressor.py}.
\end{itemize}
These enhancements enable TrustRAG to prioritize truly useful information, improving the overall quality and reliability of the retrieval process.

\subsection{Attribution-Enhanced Generation}
The credibility and traceability of generated answers are critical for trustworthiness in RAG systems. Traditional approaches rely heavily on direct reasoning by large models, which can be slow and prone to inaccuracies in citations. Additionally, fine-tuning models to improve citation accuracy may compromise their performance on other tasks, limiting practical applicability.

TrustRAG overcomes these challenges through two key innovations: \textbf{post-generation citation} and \textbf{citation grouping with cross-referencing}.
\begin{itemize}
    \item \textbf{Post-Generation Citation:} Instead of embedding citations during the generation process, TrustRAG matches the generated answers with retrieved reference materials afterward. This approach ensures higher citation accuracy while significantly accelerating the generation process. See \texttt{trustrag/mod
    ules/citation/match\_citation.py}.
    
    \item \textbf{Citation Grouping and Cross-Referencing:} To enhance traceability, TrustRAG organizes citations into logical groups, providing users with clearer reference sources. Furthermore, the system supports cross-referencing, allowing it to establish connections between different citations. This feature not only improves the clarity of references but also strengthens the credibility of the generated answers. See \texttt{trustrag/modules/
    citation/source\_citation.py}.
\end{itemize}
These innovations ensure that TrustRAG delivers both accurate and traceable answers, addressing key limitations of traditional RAG systems.

\begin{figure*}[!t]
\centering
\includegraphics[scale=0.6]{./figures/demo.png}
\caption{Example usage of TrustRAG on Excerpt-based Questions}
\label{fig:demo}
\end{figure*}

\subsection{Additional Modules}
Beyond the three core enhancements, TrustRAG offers a rich set of modular functionalities, each designed to support specific aspects of the RAG pipeline:
\begin{itemize}
    \item \textbf{Document Parsing:} TrustRAG supports efficient parsing of multiple file formats, including PDF, Word, and HTML, with robust cross-language capabilities. This module ensures high parsing success rates and seamless integration with multilingual content. See \texttt{trustrag/modules/document} for implementation details.
    
    \item \textbf{Text Chunking:} From basic to advanced chunking methods, this module ensures semantic consistency and coherence in text segmentation. See \texttt{trustrag/modules/chunks}.
    
    \item \textbf{Query Optimization:} TrustRAG enhances query accuracy and efficiency through techniques such as query expansion, decomposition, disambiguation, and abstraction. These methods help refine user queries, improving the quality of retrieval results. See \texttt{trustrag/mod
    ules/rewriter}.
    
    \item \textbf{Retrieval Ranking:} By employing multi-path retrieval and fusion-based re-ranking, TrustRAG ensures high relevance and reliability in retrieval results. See \texttt{trustrag/modules/
    reranker}.
    
    \item \textbf{Content Compression:} This module extracts high-value information from large volumes of retrieved content using usefulness evaluation and semantic enhancement techniques. See \texttt{trustrag/modules/refiner}.
    
    \item \textbf{Model Generation:} TrustRAG supports flexible invocation of various large language models, providing efficient inference and indexing management capabilities. See \texttt{trustrag/
    modules/generator}.
\end{itemize}

Through these comprehensive innovations, TrustRAG significantly enhances the reliability and trustworthiness of RAG systems. Its modular and configurable design empowers users to tailor the framework to diverse application scenarios, delivering high-quality and trustworthy outputs across a wide range of use cases.


