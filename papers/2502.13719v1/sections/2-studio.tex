

\section{System Overview}
The architecture of the system is shown in the Figure \ref{fig:architecture}. The system consists of two major components, namely the TrustRAG library and the TrustRAG studio. 

The library functions as the system's back-end, offering a comprehensive set of features for all stages of the \ac{RAG} pipeline. Its capabilities are structured into three modular components: the offline indexing module, the retrieval module, and the generation module.
First, the offline indexing module provide rich parsing functions for different kinds of files (e.g., PDF, Word, Excel, JSON) and converts chunked content into embeddings. 
Second, the retrieval module operates in three stages: query processing, retrieval, and utility assessment. 
Finally, the generation module also follows a three-stage process, comprising basic generation, citation integration, and post-processing.

The studio serves as the system's front-end, offering a user-friendly GUI built on the TrustRAG library. It features two main panels: \textbf{the knowledge manage panel} and \textbf{the conversation manage panel}. In the knowledge manage panel, users can upload their own documents, configure processing options, and select the indexing method. In the conversation manage panel, users can choose search method and the \ac{LLM} for each conversation. Additionally, the studio visualize the intermediate ``thinking'' process of the TrustRAG, including query understanding, document selection, answer reasoning, and sentence citation, to enhance reliability and transparency. 
%The Studio serves as the system's front-end, offering a user-friendly GUI built on the TrustRAG library. It features two main panels: the Knowledge Management Panel and the Conversation Management Panel.








 
 %provides a user-friendly GUI so that ordinary users can lean, practice, and develop neural text matching models easily. It contains three unified API for user accessing
 
%All components in the architecture are stand-alone and interact with each other via HTTP API. For example, any search engine can be added to our system with minimal effort. This design also adds flexibility to these components and permits their use in different applications. For instance, the platform server was also used in the TREC 2017 RTS track evaluation for collecting judgments of tweets from the assessors [6]. The CAL component also has a command line interface through which various simulation experiments can be conducted.

%The platform server is built using Django, a Python web framework. CAL and Search are written in C++. The source code is publicly available.