\section{Introduction}
Large Language Models (LLMs) have made significant strides across various tasks, including code generation, knowledge-based question answering, and complex reasoning~\citep{zhao2023survey, chang2023survey, pan2023preliminary, qin2024large}. Unlike earlier models that showed incremental improvements, LLMs exhibit emergent capabilities that fundamentally reshape problem-solving. At the core of these capabilities are two critical mechanisms: In-Context Learning (ICL)~\citep{brown2020language,dong2022survey,qin2024what} and chain-of-Thought (CoT) reasoning~\citep{nye2022show,wei2022chain,chen2024unlocking}, enabling LLMs to adapt dynamically to new challenges and achieve human-comparable learning and reasoning~\citep{brown2020language,openai2022gpt35,achiam2023gpt}. Specifically, ICL triggers LLMs to generalize information based on task-specific context provided in the input, without requiring parameter updates. In parallel, CoT reasoning allows LLMs to approach complex problems stepwise, enhancing both performance and interpretability. Together, these mechanisms empower LLMs to serve as versatile problem solvers in critical fields such as healthcare and education~\citep{harrer2023attention,nazi2024large,kasneci2023chatgpt,kung2023performance}.

Despite their transformative potential, the mechanism of LLMs’ emergent capabilities remains poorly understood. Current research on ICL has uncovered preliminary evidence of how models encode and process contextual information, with studies suggesting latent representations that approximate forms of task-specific meta-learning~\citep{wang-etal-2023-label, von2023transformers} or topic models~\citep{wang2023large}.
Similarly, CoT research has begun to map the reasoning pathways LLMs employ, providing insights into their demonstration alignment with human cognitive heuristics~\citep{madaan2023makes, wang2023towards}. Others seek to interpret emergent behaviors using macroscopic mathematical models based on experimental analysis~\citep{feng2024towards, chen2024unlocking}.
In practice, ICL and CoT are often integrated, allowing models to adapt to context and solve problems step-by-step~\citep{kojima2022large, hu2023tree, qin2023cross, zhuang2023through, chen-etal-2024-m3cot}. To put it figuratively, combining ICL and CoT is like planting a tree: ICL provides the rich ``soil'' in which the model can absorb and integrate contextual knowledge, while CoT guides its ``branches'' to grow step by step in a clear, structured direction. Together, they create a natural, human-like reasoning process that’s both flexible and transparent, enabling models to tackle complex tasks with greater depth and precision.
Unfortunately, in the current literature, a unified understanding of the combined effect of ICL and CoT remains limited, which seriously affects correct performance interpretation and controllable result prediction and further constrains the development of principled methodologies for LLM design and deployment.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{figure/main_2.pdf}
    \caption{\textbf{Glossary of Terms and Schematic of Electronic Circuit Model (\modelname{}).}\\
    In-Context Learning (ICL) is conceptualized as a (Semantic) Magnetic Field. Demonstrations in ICL effectively provide an additional voltage by applying a magnetic field change aligned with the input query direction. Chain-of-Thought (CoT) process is analogized as series resistors in circuit, where the reasoning difficulty in CoT are divided into a sequence of sub-difficulties, analogous to resistors in a circuit that collectively increase overall resistor. Building on this, we introduce the concept of model inherent capabilities, represented as the power supply of the circuit to provide basic voltage. Model performance can then be quantified as the circuit's output power, enabling more precise predictions of empirical accuracy. In addition, in this article, ``strength'' denotes the value of semantic magnetic fields, ``resistance'' denotes the value of resistor, and ``voltage'' denotes the value of power supply.\vspace{-5pt}
    }
    \label{fig:main}
\end{figure}

To bridge this gap, we introduce the Electronic Circuit model (\modelname{}), a unified theoretical paradigm that reimagines model performance through the lens of physical circuit systems. Specifically, as shown in Figure~\ref{fig:main}, we try to conceptualize ICL capabilities as semantic magnetic fields, driving additional voltage gains that correspond to enhanced information absorption, while CoT challenges are modeled as series resistors, introducing predictable constraints akin to circuit losses. Based on these hypotheses, we discover Faraday's Law of ICL and Ohm's Law of CoT in LLMs' reasoning process.
By rigorously aligning theoretical circuit power predictions with empirical accuracy results across 3 prompting strategies, 4 task categories, and 13 different LLMs.
The \modelname{} successfully establishes a unified quantitative paradigm for predicting and optimizing the behavior of LLMs.

Moreover, based on the introduction of \modelname{}, we further explain over 10 existing prompt optimization strategies from the perspective of optimizing the magnetic field and optimizing the resistors. And given these perspectives, some phenomena that have not been successfully explained by previous works and more excellent prompt strategies are discovered based on \modelname{}.
Notably, our results show that combined with these approaches has achieved breakthroughs in complex domains: LLMs guided by \modelname{}-optimized strategies have outperformed over 80\% of human competitors in the International Olympiad in Informatics and the International Mathematical Olympiad. Furthermore, in subjective and exploratory contexts such as academic research development, \modelname{}-optimized strategies have driven significant gains, achieving a minimum 10\% improvement in overall human scores.


In summary, our contributions are as follows:
\begin{itemize}[leftmargin=4ex]
    \item To the best of our knowledge, we are taking the first meaningful step to introduce the Electronic Circuit Model (\modelname{}), effectively offering a unified theoretical paradigm to reformulate model performance through the lens of circuit systems.
    \item In this framework, we discover Faraday's Law of ICL and Ohm's Law of CoT in LLMs' reasoning, and further utilize \modelname{} to effectively predict the empirical accuracy and explain the effectiveness of 10 existing strategies from the view of optimizing the magnetic field and optimizing the resistor.
    \item We utilize \modelname{} to explain some open phenomena and to propose more excellent prompt strategies based on \modelname{}. Combined with these approaches, we have achieved breakthroughs in mathematical and code competition and academic research development scenarios. Further, we empirically demonstrate that applying ECM-driven optimizations to LLMs leads to substantial performance gains.
\end{itemize}