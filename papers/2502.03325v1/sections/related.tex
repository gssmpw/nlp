\section{Related Work}\vspace{-5pt}
In this section, we review recent literature related to Chain-of-Thought (CoT) prompting, focusing on theoretical and empirical investigations.
\citet{madaan-etal-2023-makes,wang-etal-2023-towards,saparov2023language,he2023solving,zhang2024pattern,wang2024rethinking} and \citet{prystawski2024think} qualitatively show that the LLMs learn the reasoning chain based on the demonstrations in the context.
Besides, \citet{lampinen-etal-2022-language} and \citet{tan-2023-causal} find a causal link between generated intermediate steps and the final answers during a series of qualitative experiments. \citet{wang2023large,hanna2024does} and \citet{dutta2024think} study neural substructure within the LLM, embodying CoT reasoning from a white-box mechanism perspective, demonstrating that the LLM deploys multiple parallel answer generation paths in internal of the LLMs.

Recently, a large amount of work has demonstrated the upper-bounds and limitations of LLM in various CoT tasks~\citep{qin2023cross,imani2023mathprompter,huang2024far,sprague2024musr}.
\citet{bi2024program} investigate these bounds on planning capability in code generation by training LLM on CoT samples of varying difficulties. Their findings suggest that LLMs have a limited capacity to learn or manage tasks exceeding a certain complexity threshold.
Further understanding of the CoT upper-bound, \citet{merrill2023expressive,li2023chain} and \citet{feng2024towards} analyze single-step arithmetic capability, which suggests an upper bound on model performance related to input length in single-step reasoning processes.


Despite advancements in CoT explanation for LLMs, significant challenges remain, including the absence of quantifiable metrics for CoT's upper-bounds and the deficiency in optimization guidelines. To tackle this, we propose a reasoning granularity framework designed to systematically quantify and optimize various CoT approaches. This framework offers a transferable and user-friendly methodology to enhance model performance from a mechanistic perspective. We anticipate that it will furnish systematic insights for ongoing research and inform future developments in the field.\vspace{-5pt}