\section{Introduction}


Advances in machine learning have significantly enhanced the detection and classification of malicious software, achieving notable success across various domains such as Windows executables~\cite{malwareguard, transcendingtranscend, chen2023continuous}, PDFs~\cite{maiorca2012pattern}, and Android applications~\cite{arp2014drebin, cade}. Traditional models, trained on static datasets, are typically expected to perform well on new data under the assumption of a constant data distribution. However, in reality, both malicious (\emph{malware}) and benign (\emph{goodware}) software evolve continuously, necessitating regular model updates to adapt to changes in data distribution and maintain effectiveness. For example, the AV-TEST Institute reports approximately 450,000 new malware samples daily~\cite{av-test}, while VirusTotal processes over one million unique submissions each day~\cite{virustotal}. This scale creates immense challenges in training and even storing all the samples being identified.

Training a malware classification model solely on new data can lead to \emph{catastrophic forgetting}~\cite{french1999catastrophic, robins1995catastrophic}, where previously learned information is lost, resulting in misclassification of benign software or allowing attackers to evade detection with older malware strains, known as {\em Retrograde Malware Attacks (RMA)} (see Section~\ref{sec:threat_model}). %Our analysis shows that catastrophic forgetting can be observed in both classical ML-based (e.g., LightGBM) and Neural Network-based (e.g., MLP) malware detection systems. 
As such, anti-virus vendors must deal with difficult trade-offs: (i) removing older samples from the training set, risking exposure to revived older malware; (ii) ignoring newer samples, risking failure to detect emerging trends; (iii) reducing the frequency of retraining, compromising accuracy during intervals between updates; or (iv) incurring significant effort and cost to frequently retrain on the entire dataset. These challenges highlight the need for agile and adaptive malware classification techniques capable of learning incrementally and responding to the dynamic malware landscape.

Continual learning (CL) provides a promising solution to this problem by enabling models to adapt to new data without requiring the retention of large datasets or frequent retraining~\cite{malcl,wangunified, tamil, BIR, icarl, aljundi2019gradient}. By addressing catastrophic forgetting, CL techniques ensure that models remain effective and efficient in the face of evolving malware distributions. While designs for CL have been extensively studied in the context of computer vision~\cite{gr,hsu2018re,BIR}, there are very few such studies in the malware classification domain~\cite{continual-learning-malware, malcl}. Rahman et al.~\cite{continual-learning-malware} observed that CL techniques originally developed for computer vision problems fail to deliver acceptable performance in malware classification, due in part to the strong semantics of malware features and the high level of diversity found in the  malware ecosystem. 



In this study, we first delve into the complexities of malware data distributions using the EMBER dataset~\cite{ember} of Windows malware and goodware. Our analysis highlights the diversity in malware, both between and even within \emph{families}, or groups of related malware. Leveraging this insight, we devise \system\ -- $\underline{M}$alware $\underline{A}$nalysis with $\underline{D}$iversity-$\underline{A}$ware $\underline{R}$eplay, a replay-based continual learning strategy that accounts for diversity and achieves improved malware classification performance. In particular, \system\ replays a mix of representative samples and novel samples (i.e., outliers) to enhance the model's ability to retain knowledge and identify new malware variants despite memory constraints. Our techniques employ Isolation Forests (IF)~\cite{if} to identify critical novel samples, either directly through the raw feature vectors (\system), or through the use of model activations for a more compact representation (MADAR$^\theta$). For both of these approaches, we also consider two mechanisms to control how the number of replay samples is chosen, which refer to as Ratio and Uniform strategies.



We evaluate these techniques with comprehensive experiments on two large-scale datasets across three CL scenarios representative of real-world malware analysis tasks, covering domain incremental learning (Domain-IL), class incremental learning (Class-IL), and task incremental learning (Task-IL). These datasets include the well-known EMBER dataset~\cite{ember}, containing one million examples of Windows executables, and a new benchmark dataset of Android malware from the AndroZoo repository~\cite{AndroZoo} specifically created to explore CL scenarios. Our experimental results on these datasets confirm that \system\ is indeed effective and much better than prior state-of-the-art CL methods in the face of realistic malware data distribution shifts.

In summary, the contributions of this study are:
\begin{itemize}
    \item We provide an exploratory analysis of the diversity of malware distributions and show how it creates unique challenges for continuous learning.

    \item We develop a large-scale, realistic Android malware benchmark dataset covering all three CL scenarios -- Domain-IL, Class-IL, and Task-IL.
    
    \item In Domain-IL scenarios, we show that \system\ performs much better than prior CL techniques. On the AndroZoo dataset, for example, \system\ comes within 0.4\% average accuracy of the  retraining baseline using just 50K training samples versus 680K for full retraining.
    

    \item \system\ is also effective in Class-IL scenarios, where it consistently outperforms all prior methods over a wide range of budgets. With a budget of 20K training samples on EMBER, \system\ gets an average accuracy of $85.8\%$ versus $66.8\%$ for the best method from prior work.
    
    \item For Task-IL, \system\ outperforms all prior methods across all memory budget configurations for both the EMBER and AndroZoo datasets. For example, in the AndroZoo dataset, the \system-U variant of MADAR achieves an average accuracy of 98.7\% (within 0.1\% of full retrain) with a budget of only 20K replay samples (versus approximately 250K for full retrain).
    
\end{itemize}

Through these contributions, this study stands as a significant advancement in continual learning for malware classification, highlighting the importance of understanding the domain distribution to effectively combat catastrophic forgetting. 




