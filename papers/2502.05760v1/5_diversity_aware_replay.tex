
\section{Diversity-Aware Replay}
\label{divreplay}

Here, we introduce the our proposed continual learning (CL) framework for malware classification with two diversity-aware replay variants: MADAR and MADAR$^\theta$. MADAR operates on the basis of the raw-feature space and MADAR$^\theta$ operates on the basis of the model's weights-space of raw-features. 



\subsection{MADAR}
\label{subsec:ifs}

% GRS is implicitly designed on the assumption that important information for training is distributed evenly across the dataset. We instead aim to sample intelligently to capture key information while avoiding unnecessary redundancy. Building on the dataset analysis in Section~\ref{sec:exploratoryAnalysis}, we postulate that stratified sampling, where replay samples are chosen based on their representation in malware families, might better preserve the model's stability than random sampling. Moreover, we also seek to capture the diversity \emph{within} the malware family data distribution. This entails incorporating both \emph{representative} samples that are close to the centroid and \emph{discriminative} samples that lie further from the centroid into the replay sample pool. To this end, we conjecture that a technique for identifying outliers within a distribution could effectively pinpoint the most discriminative samples, while a random subset of non-outliers would address a variety of representative samples without excess redundancy.

% GRS assumes even distribution of important information across the dataset, while we propose intelligent stratified sampling.

Building on the exploratory analysis in Section~\ref{sec:exploratoryAnalysis}, we postulate that stratified sampling, where replay samples are chosen based on their representation in malware families, may better preserve the model's stability versus random sampling as used in GRS. Moreover, we also seek to capture the diversity \emph{within} each family's data distribution. 
%As such, our proposed techniques are designed to provide replay samples from each individual malware family distribution by choosing 
We do this by selecting a balance between \emph{representative samples} that are close to each other and \emph{anomalous samples} that are separated. 
%In particular, the samples that may form a cluster can be termed as the representative samples of the cluster and the samples that do not necessarily form a cluster or the samples which are farther away from the formed cluster can be termed as the outliers in this context. It is important for a malware classifier to not forget these outliers because these outliers are still crucial as they maybe very few in number and may have less overlap in the code compared to other samples of a particular family. 
While any single anomalous sample is not as important to learn and remember as a single representative sample, a collection of anomalous samples helps to track the diversity within a class.
%And forgetting these samples may increase {false negatives}. As such, our techniques preserve representation of the similar samples and outlier samples to retain the inner diversity of a family.
% We capture diversity within malware families by including representative samples near the centroid and discriminative samples farther away. Outlier identification helps pinpoint discriminative samples, while a random subset of non-outliers provides representative diversity without redundancy.


% {\em Isolation Forests (IF)}\cite{if} are an efficient approach to finding outliers in high-dimensional data like our malware dataset. IF employs decision trees to randomly select a feature and split value, producing shorter paths for anomalous data points and distinguishing them from the rest of the data. This approach stems from the intuition that anomalous data points are few, distinct, and easy to isolate. In IF, data samples are partitioned by randomly selecting a feature $f$ and recursively splitting the samples until they are completely isolated from one another. The resulting path lengths are used to rank each sample based on their degree of anomaly, yielding anomaly scores that can be used to pinpoint outliers. An important parameter of IF is the contamination rate $C_{r}$, $0 \leq C_{r} \leq 0.5$ -- the anticipated fraction of outlier samples in the distribution. After experimenting with $C_{r} \in \{0.1, .., 0.5\}$, we observe that $C_{r} = 0.1$ was the best, and we thus use $C_{r} = 0.1$ in all of our experiments.

{\em Isolation Forest (IF)}~\cite{if} is a technique for identifying outliers in high-dimensional data. IF uses decision trees to isolate anomalous data points based on the intuition that outliers are distinct and easy to separate from the rest of the data. An important parameter in IF is the contamination rate $C_{r}$, which represents the expected fraction of outliers in the data. We found that $C_{r} = 0.1$ works best and used it in all our experiments. The algorithm for \system\ in the Domain-IL setting is provided in Algorithm~\ref{alg:IFS}. The algorithm for \system\ in the Class-IL and Task-IL settings is provided in Algorithm~\ref{alg:IFS_Class_Task_IL}. 


\input{algo/algo_MADAR_DIL}



% In IFS, presented in Algorithm~\ref{alg:IFS}, goodware and malware samples are treated separately, and malware samples are further selected based on families. We present IFS using Domain-IL for simplicity, and Class-IL follows the similar procedure. IFS initializes a global data pool $\mathcal{P}$ to preserve all the goodware samples and malware samples based on their family; and a dictionary $\mathcal{D}$ to preserve the name of family and the associated frequencies of malware samples till the current task.

% For any subsequent task, IFS separates goodware $X_{good}$ and malware $X_{mal}$ from $\mathcal{P}$. Afterwards, it allocates malware $\beta_M$ and goodware $\beta_G$ budgets from the memory budget $\beta$ based on a given split ratio of $\gamma$. If the dataset is relatively balanced in terms of goodware and malware which it is for EMBER, we can simply use $\gamma \in \{50:50\}$, however, if the dataset is not balanced which it is for AZ datasets, we can use a tuned $\gamma$. For AZ dataset, we use $\gamma \in \{90:10\}$. 

% In IFS, detailed in Algorithm~\ref{alg:IFS}, goodware and malware are processed separately, with malware further categorized by family.

\subsubsection*{\bf Procedure}
We now describe \system using the framework of Domain-IL; the process is similar for Class-IL and Task-IL. 
%\system processes goodware and malware separately, further categorizing malware by family. 
The procedure begins by initializing a global data pool $\mathcal{P}$, containing both goodware and malware samples, and a dictionary $\mathcal{D}$ that tracks malware families and their frequencies in the data up to the current task.

For each new task $c$, \system divides the data into goodware ($X_{good}$) and malware ($X_{mal}$) subsets from $\mathcal{P}$, allocating memory budgets $\beta_M$ for malware and $\beta_G$ for goodware from the total memory budget $\beta$, based on a split ratio $\gamma$:
\begin{equation}
    \beta_G = \gamma \cdot \beta, \quad  \beta_M = (1 - \gamma) \cdot \beta. %\nonumber
\end{equation}
For balanced datasets like EMBER, $\gamma = 0.5$ ensures an equal split between malware and goodware. For an imbalanced dataset, it is better to tune $\gamma$. Our Android malware (AZ) datasets, for example, have a 9:1 ratio of goodware to malware, so we use $\gamma=0.9$.

Before training for a new task, \system incrementally trains the classifier using a combination of new samples from the current task and replay samples from previous tasks. The replay samples include both goodware ($R_{good} \subset X_{good}$) and malware ($R_{mal} \subset X_{mal}$), with $R_{mal}$ sampled from specific malware families rather than randomly from all of $X_{mal}$.

For each family $f$, we set its \emph{family budget} $\mathcal{B}_f$---
the number of samples to select from $f$---using two sub-sampling variants: \emph{Ratio budgeting} and \emph{Uniform budgeting}. 


\begin{smitemize}
    \item \textbf{Ratio Budgeting:} Select the number of samples from a family $f$ proportional to that family's representation in the dataset. The family budget $\mathcal{B}_f$ is
    $\mathcal{B}_f = \frac{|X_{f}|}{|X_{mal}|} \cdot \beta_M$,
%    \begin{equation}
 %       \mathcal{B}_f = \frac{|X_{f}|}{|X_{mal}|} \cdot \beta_M
 %   \end{equation}
    %
    where $|X_{f}|$ is the number of samples in family $f$, and $|X_{mal}|$ is the total number of malware samples. This strategy may be more suitable in binary classification, as it provides proportional representation of the malware families for training on the malicious class.
    
    \item \textbf{Uniform Budgeting:} In this method, the memory budget $\beta_M$ is uniformly distributed across all malware families:
    %\begin{equation}
        $\mathcal{B}_f = \frac{\beta_M}{|\mathcal{F}|}$,
    %\end{equation}
    where $|\mathcal{F}|$ is the total number of malware families. 
    Compared with Ratio budgeting, Uniform budgeting may work well for multi-class classification to determine which family a sample belongs to, as it ensures better class balance.
\end{smitemize}

Within each family $f$, we further split the family budget $\mathcal{B}_f$ into two parts: representative samples $S_f$ and anomalous samples $A_f$, using IF, controlled by a split parameter $\alpha$:
\begin{equation}
    |S_f| = \alpha \cdot \mathcal{B}_f, \quad |A_f| = (1 - \alpha) \cdot \mathcal{B}_f %\nonumber 
\end{equation}
%Our experiments reveal that an even split, $\alpha = 0.5$, of representative and anomalous samples provides the optimal performance. 
%
We found empirically that a balanced split ($\alpha = 0.5$) between representative and anomalous samples provides optimal performance. In this setup, the model learns equally the core class characteristics from representative samples %($|S_f| = \alpha \cdot \mathcal{B}_f$) 
and less common variations from anomalous samples. 
%($|A_f| = (1 - \alpha) \cdot \mathcal{B}_f$), 
%allowing it to generalize well and handle edge cases equally well.
%without overemphasizing one type at the expense of the other. 
%We see no reason to expect that this setting would favor a highly imbalanced split in either direction.

The malware replay set $R_{mal}$ is then constructed by combining the representative and anomalous samples from all malware families: 
\begin{equation}
    R_{mal} = \bigcup_{f \in F} \{ S_f \cup A_f \}. %\nonumber 
\end{equation}
The total replay set consists of both goodware and malware replay samples, which are then concatenated with the new task samples
%The number of goodware samples in the replay set is chosen such that \(|R_{good}| = \beta_G \). 
%The replay samples and the new task samples are concatenated 
to form the training set for the current task $c$.
%$R = R_{good} \cup $
%\begin{equation}
%    X_{train} = X_c \cup X_{replay}, \quad Y_{train} = Y_c \cup Y_{replay}
%\end{equation}
After training, the data pool $\mathcal{P}$ is updated with the new task samples, \(\mathcal{P} \leftarrow \mathcal{P} \cup \{X_c, Y_c\}\), and the malware family dictionary $\mathcal{D}$ is updated to reflect the new frequencies of malware families in $X_{mal}$: \(\mathcal{D} \leftarrow \mathcal{D} + freq(X_{mal})\).



\input{algo/algo_MADAR_CIL_TIL}



\subsection{MADAR$^\theta$}
\label{subsec:aws}





While Isolation Forest (IF) outperforms other distance-based anomaly detection techniques on high-dimensional data, it struggles with correlated features~\cite{puggini2018enhanced}. Let \( \mathbf{X} \in \mathbb{R}^D \) represent the input data, where \( D \) is the feature dimension. For example, the EMBER dataset has \( D = 2381 \), while the AZ datasets have \( D = 1789 \) for AZ-Domain and \( D = 2439 \) for AZ-Class, respectively. Instead of applying dimensionality reduction techniques such as PCA, we propose leveraging a neural network \( \mathcal{M} \) to generate compact feature representations \( \mathbf{Z} \in \mathbb{R}^d \), where \( d \ll D \). This approach is particularly advantageous in continual learning contexts, as it complements ongoing model development and adapts to evolving tasks~\cite{hayes2020remind,ostapenko2022foundational}.

To address these, we introduce MADAR$^\theta$, a variant of MADAR that leverages learned representations from a trained model \( \mathcal{M} \) to identify both representative and diverse samples effectively. 
%The MADAR$^\theta$ algorithm is provided in Appendix~\ref{append:awsAlgo}. 
For an input sample \( \mathbf{x} \), the model \( \mathcal{M} \) computes activations \( \mathcal{W}(\mathbf{x}) \), representing its internal state. Specifically, for a set of inputs \( \mathbf{X}_f \) belonging to a family \( f \), MADAR$^\theta$ extracts activations:
\begin{equation}
\Theta^\mathcal{L}(\mathbf{X}_f) = \{ \mathcal{W}^\mathcal{L}(\mathbf{x}) : \mathbf{x} \in \mathbf{X}_f \}, \quad \text{where} \quad \Theta^\mathcal{L}(\mathbf{X}_f) \in \mathbb{R}^d,
\end{equation}
from a chosen layer \( \mathcal{L} \) of the model.

These activations are analyzed using the Isolation Forest (IF) algorithm to identify anomalous activations \( \mathcal{A}_w \subseteq \Theta^\mathcal{L}(\mathbf{X}_f) \). The corresponding anomalous samples in the original input space are denoted as:
\begin{equation}
A_f = \{ \mathbf{x} \in \mathbf{X}_f : \mathcal{W}^\mathcal{L}(\mathbf{x}) \in \mathcal{A}_w \}.
\end{equation}
Non-anomalous samples are similarly sampled to form the set \( S_f \), ensuring a balanced and representative replay set:
\begin{equation}
S_f = \{ \mathbf{x} \in \mathbf{X}_f : \mathcal{W}^\mathcal{L}(\mathbf{x}) \notin \mathcal{A}_w \}.
\end{equation}

The replay samples \( A_f \cup S_f \) are then used in subsequent training episodes to maintain knowledge retention and mitigate catastrophic forgetting.

\paragraphX{Selection of the Layer \( \mathcal{L} \).}
The choice of \( \mathcal{L} \) is critical in MADAR$^\theta$ to ensure that feature representations are captured without interference from the model's final classification stage. Empirical testing revealed that the penultimate layers, denoted as \texttt{act4} for the EMBER dataset and \texttt{act5} for the AZ datasets, provide optimal results such that $\mathcal{L}_{\text{EMBER}} = \texttt{act4}, \quad \mathcal{L}_{\text{AZ}} = \texttt{act5}.$

% \begin{equation}
% \mathcal{L}_{\text{EMBER}} = \texttt{act4}, \quad \mathcal{L}_{\text{AZ}} = \texttt{act5}.
% \end{equation}

\paragraphX{Adaptation of Batch Normalization.}
During the forward pass, batch normalization is omitted in MADAR$^\theta$ to preserve the diversity of the activation distributions. While batch normalization typically stabilizes learning and improves generalization, it can homogenize activations, reducing the diversity essential for identifying anomalies. This adaptation enhances the performance of MADAR$^\theta$, as confirmed by empirical results.


% \begin{equation}
% \Theta^\mathcal{L}(\mathbf{X}_f) = \text{ForwardPass}(\mathbf{X}_f, \text{BatchNorm=False}).
% \end{equation}




\paragraphX{Efficiency of MADAR$^\theta$.}
MADAR$^\theta$ is computationally efficient compared to MADAR applied directly to the input space. The hidden layers \texttt{act4} and \texttt{act5} have \( d = 128 \), significantly reducing the dimensionality from \( D \). As a result, MADAR$^\theta$ offers reduced computational complexity.

% \begin{equation}
% \text{Time Complexity of IF} \propto \mathcal{O}(d \log n),
% \end{equation}
% where \( n \) is the number of samples. This efficiency further underscores the practicality of MADAR$^\theta$ for continual learning scenarios.






% While IF works better than other distance-based anomaly detection techniques on high-dimensional data, it can struggle with correlated features~\cite{puggini2018enhanced}. The EMBER dataset has 2,381 features, and while the AZ datasets have 1,789 and 2,439 features for AZ-Domain and AZ-Class, respectively. Instead of applying dimensionality reduction, leveraging the neural network to generate a more compact feature representation could be a beneficial approach, especially in continual-learning contexts where it complements ongoing model development efforts~\cite{hayes2020remind,ostapenko2022foundational}. 

% As such, we introduce MADAR$^\theta$ which is based on anomalous weights, a variant of MADAR that leverages learned representations from a trained model, $\mathcal{M}$, to more effectively identify both representative and diverse samples. 
% %A schematic representation of AWS is depicted in Figure~\ref{fig:madar-aws}. 
% By inputting a sample $\mathcal{X}$ into $\mathcal{M}$, we obtain activations $\mathcal{W}$ reflecting the sample's internal state. For inputs $X_{f}$ from family $f$, MADAR$^\theta$ extracts activations $\Theta^{L}{X_{f}} \in \mathbb{R}^{D}$ from a chosen layer $\mathcal{L}$. These activations are then analyzed with the Isolation Forest (IF) algorithm to pinpoint anomalous activations, $\mathcal{A}_{w}$. MADAR$^\theta$ then maps these anomalies back to the original input space of $X_{f}$ to select the anomalous samples $A_f$. Non-anomalous samples are similarly sampled to form $S_f$. Aside from these steps, MADAR$^\theta$ proceeds similarly to MADAR. 

% In selecting the layer $\mathcal{L}$ for MADAR$^\theta$, we aim to capture feature representations while avoiding the model's final classification stage. Testing various layers revealed that the penultimate layers, \texttt{act4} for EMBER and \texttt{act5} for AZ, yield the best results. Thus, we utilized these layers for the remainder of our study. We also adapted the MADAR$^\theta$ algorithm by omitting batch normalization during the forward pass. Although batch normalization generally stabilizes learning and improves model generalization by normalizing input layers, in the MADAR$^\theta$ context, it can diminish the activation distribution diversity we seek to maintain. Our tests confirmed that excluding batch normalization enhances MADAR$^\theta$'s performance.

% Besides enhancing replay sample selection, MADAR$^\theta$ is also more efficient than IFS. The \texttt{act4} and \texttt{act5} hidden layers have just 128 dimensions each, considerably less than the original feature dimensions. The IF algorithm thus operates more quickly in this reduced dimension space.

