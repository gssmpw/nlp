
%\section{Training and Model Details}

% \subsection{Training Protocols}

% In continual learning, models sequentially learn tasks $t_1, t_2, ..., t_T$, each with its distinct data distribution $p(x,y|t_i)$. The goal is to adapt to new tasks while maintaining classification ability on older ones. CL uses three types of parameters: shared parameters ($\theta_{s}$) across all tasks, old task-specific parameters ($\theta_{0}$), and new task-specific parameters ($\theta_{n}$). The {\em Joint} training method, considered the performance benchmark, optimizes all these parameters simultaneously but requires extensive resources as it needs access to all past and present data during training.

% In contrast, CL training strives to optimize and update $\theta_{s}$ and $\theta_{n}$, while maintaining $\theta_{0}$ in a relatively fixed state, for each new task. Updating any of the shared weights $\theta_{s}$, however, risks confusing the classifier when faced with older data, as those classification decisions depend on not only $\theta_{0}$, but also $\theta_{s}$. CL training typically boasts significantly faster speed and far less storage requirements than {\em Joint} training, thus permitting more frequent model retraining to adapt to evolving data distributions or other requirements.




\if 0
\subsection{Model Selection and Implementation}
\label{sec:modelSelectionTraining}

We utilize a similar multi-layer perceptron (MLP) model for malware classification as used in~\cite{continual-learning-malware} for the experiments with EMBER dataset. For the experiments with Android APK file, we develop a new MLP model which has five fully-connected layers. For our Android malware model, we use Adam optimizer with learning rate $0.001$ along with batch normalization and dropout regularization. For the AZ dataset, we developed a new MLP model with five fully-connected layers, largely inspired by the MLP used for EMBER. This Android-specific model utilizes the Adam optimizer with a learning rate of $0.001$, and incorporates batch normalization and dropout for regularization. 
We train the models sequentially, treating each task and its associated data as separate entities and the model uses either data from the current task or a combination of the data from previous task and current task during training. The choice is contingent upon the particular method being employed. Depending on the experiment, we use either binary or multi-class cross-entropy loss.

The implementation of the output layer varies between Class-IL and Domain-IL scenarios. In Class-IL, the output layer comprises distinct units for each class that needs to be learned, with all units corresponding to classes encountered up to that point being active. Class-IL begins with an initial set of 50 classes in the first task and progressively adds five more classes in each of the remaining 10 tasks for both EMBER and AZ datasets. In contrast, Domain-IL operates as a series of binary classification tasks over 12 months for EMBER, and over 9 years for the AZ dataset, with two active units in each case: malware and benign. In Domain-IL, both output units are always active, as the task remains binary classification, with only the data distribution changing over time.


The experiments are conducted with a focus on reproducibility and robustness. Each set of experiments is performed around 10 times, with different random parameter initializations. This approach ensures that the results are not skewed by any particular initial configuration and provides a more reliable assessment of the algorithm's performance across varying conditions.

\fi

