\subsection{Problem Formulation}

% We begin by formulating the problem of dynamic benchmarking for LLMs.
A dynamic benchmark is defined as  
$
\small
\mathcal{B}_{\text{dynamic}} = (\mathcal{D}, T(\cdot)), \quad 
\mathcal{D} = (\mathcal{X}, \mathcal{Y}, \mathcal{S}(\cdot))
$
where \( \mathcal{D} \) represents the static benchmark dataset. 
% consisting of input prompts \( \mathcal{X} \), expected outputs \( \mathcal{Y} \), and a scoring function \( \mathcal{S}(\cdot) \) that evaluates the quality of an LLM's outputs by comparing them against \( \mathcal{Y} \). 
The transformation function \( T(\cdot) \) modifies the data set during the benchmarking to avoid possible data contamination.
The dynamic dataset for the evaluation of an LLM can then be expressed as
$
\small
        \mathcal{D}_t = T_t(\mathcal{D}),  \quad
        \forall t \in \{1, \dots, N\}
$
where \( \mathcal{D}_t \) represents the evaluation data set at the timestamp \( t \), and \( N\) is the total timestamp number, which could be finite or infinite. % \ie $N= \infty$.
If the seed dataset $\mathcal{D}$ is empty, the dynamic benchmarking dataset will be created from scratch.

