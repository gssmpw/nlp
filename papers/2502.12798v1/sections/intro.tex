\section{Introduction}
\label{chap: intro}
Multi-armed bandits (MABs) are a cornerstone of machine learning.
In this framework, a learner makes decisions sequentially, choosing an arm (i.e., an action) and subsequently receiving a reward in each round.
Central to MABs is the dilemma of exploiting known arms with historically high rewards and exploring lesser-known arms that could yield even higher rewards.
The literature includes diverse variants of the problem, including contextual bandits~\cite{chu2011contextual, slivkins2011contextual}, dueling bandits~\cite{yue2012k, cohen2021dueling}, non-stationary bandits~\cite{besbes2014stochastic, levine2017rotting}, and Lipschitz bandits~\cite{kleinberg2008multi}.
The main challenge in these works is to overcome reward uncertainty, compared to ideal scenarios with complete information.


However, with the widespread commercial deployment of explore-and-exploit systems, concerns have expanded beyond mere reward uncertainty to encompass broader societal and fairness issues.
Recent research considers facets of fairness, such as regulatory requirements \cite{patil2021achieving, bahar2020fiduciary,ron2021corporate}, fairness of exposure~\cite{ wang2021fairness, liu2017calibrated}, and meritocratic fairness \cite{joseph2016fairness}. While much of this work has tackled fairness from the perspective of the ``arms,'' user-centric fairness remains relatively underexplored. In particular, the concept of \textit{envy}, a well-established theme in fair division literature~\cite{moulin2004fair,procaccia2013cake}, has been somewhat overlooked in this context (see notable exceptions in Subsection~\ref{sec: rw}). This is especially important because perceived unfairness, as captured by envy, can significantly affect user satisfaction and the overall trustworthiness of the system.

%In this work, we take the first steps toward examining envy within explore-and-exploit systems by modeling two key behaviors that are characteristic of real-world, user-centric applications:
%In this work, we contribute to the growing body of work on envy within explore-and-exploit systems. We model two key behaviors that are characteristic of real-world, user-centric applications:
In this work, we contribute to the research on envy within explore-and-exploit systems by modeling two key behaviors that characterize real-world, user-centric applications:
\begin{enumerate}[wide, labelwidth=0pt, labelindent=0pt]
    \item \textit{Recurring users}: Rather than being one-time visitors, users often return to the system repeatedly. For example, navigation apps experience periodic engagement as users rely on them regularly.
    \item \textit{Reward consistency}: Although rewards may fluctuate stochastically, they tend to remain stable over specific periods. For instance, the quality of a restaurant’s daily special is generally consistent throughout the day, and travel times on a frequently used route remain largely unchanged over short intervals.
\end{enumerate}
These assumptions introduce nuances in the user experience that foster envy. Due to the dynamics of exploration, some users may explore more frequently and consequently receive lower rewards. This discrepancy in user experience can lead to reluctance to engage with the system or follow its recommendations.


\subsection{Our Contribution}
\label{sec: contribution}
Our contribution is two-fold. Conceptually, we advance the understanding of envy dynamics in explore-and-exploit systems using a stylized model. Our framework encompasses $N$ homogeneous agents, $K$ arms and $T$ \emph{rounds}. Each round comprises multiple \emph{sessions}, wherein distinct agents interact with the system. During each session, the algorithm selects an arm on behalf of the corresponding agent. We assume that arm rewards are independently sampled in every round but are \emph{consistent} across all sessions within a given round. Within this framework, algorithms typically aim to optimize an aggregate performance metric---such as maximizing social welfare, enhancing risk-adjusted outcomes, or minimizing cumulative regret. Consequently, each round involves both exploration---unveiling rewards for the current session---and exploitation, wherein past session information is leveraged to benefit subsequent agents. 

In this context, agents participating in earlier sessions explore more frequently, while agents arriving later benefit from the information gathered by their predecessors.
This gives rise \emph{envy}, defined as the maximal disparity in cumulative rewards among agents. As expected, the manner in which agents enter a round plays a pivotal role in influencing envy.
We formalize this arrival process as an \emph{arrival function}, which dictates the sequence of agent arrivals within a round. We propose three arrival functions: Uniform, denoted as $\uniord$, which uniformly determines the order of agent arrival for each round; nudged arrival, denoted as $\sugord$, allowing the system to influence the order of arrival, potentially mitigating envy across successive rounds; and adversarial arrival, denoted as $\advord$, establishing a worst-case scenario for agent arrival order from an envy perspective.

Our second contribution is technical: We characterize the envy of \emph{anonymous} algorithms, i.e., invariant under any permutation of the agent order. Focusing on such algorithms is justified since agents have homogeneous preferences, and their identities are irrelevant for optimizing any aggregated metric. For the uniform arrival $\uniord$, Section~\ref{sec:uniform} establishes an upper bound of $O\Big(\sqrt{\ln{(N)} \sum^{T}_{t=1}{\var{\dift}} }\Big)$, where $\Delta^t$ is the average reward discrepancy in round $t$ and $N$ is the number of agents. Crucially, $\Delta^t$ depends on both the algorithm at hand and the reward distributions. Under mild assumptions, this bound becomes $O( \sqrt{\nicefrac{TK\ln(N)}{N}})$. We also prove an (almost) matching lower bound of $\Omega\Big(\sqrt{\sum^{T}_{t=1}{\var{\dift}} }\Big)$. 

For the nudged arrival $\sugord$, Section~\ref{sec:nudge} derives an upper bound of $O(\nicefrac{N}{\delta})$, where $\delta \in (0,1)$ measures the degree to which the system can influence the arrival order. Surprisingly, this bound only depends on the number of agents but not the number of rounds $T$. We further establish a tight linear bound of $\Theta(T)$ for the adversarial arrival, with constants hidden in the bound depending on the specific instance. Our core techniques heavily rely on martingale and excursion theory, enabling the analysis of (possibly dependent) reward discrepancies. 

While our primary aim is to understand and characterize the envy generated by any arbitrary algorithm, we also take initial steps toward balancing social welfare and envy. In Section~\ref{sec:extensions}, we focus on uniform rewards and introduce an algorithm that can attain any point on the efficiency-fairness Pareto frontier. Formally, it receives a positive number $C \in \mathbb R_{+}$, and ensures that envy would not grow beyond $C$ almost surely. We show that for $C=1$, namely, an envy of at most 1,  our algorithm is able to gain almost half of the additional welfare compared to a no-envy algorithm.

\subsection{Related Work}
\label{sec: rw}
From the economic perspective, there has been extensive research in the realm of fairness~\cite{conitzer2017fair, Kahneman86, shapley_shubik_1954, dubey1975uniqueness,shapley1974cores, shapley1971cores}. Envy-freeness is a central concept in the fair division and allocation literature, for instance, in cake-cutting~\cite{Steven95,aziz2016discrete,cohler2011optimal}. Envy-freeness refers to a situation where no individual envies the allocation of another. 
%One of the primary tensions of envy is that while guaranteeing \textit{ex-ante} fairness through randomness may seem feasible, it might lead to \textit{ex-post} unfairness under any realization~\cite{chen2017ignorance, bestofbothworlds,apportionment2022}. For instance, flipping a fair coin and distributing one million USD to one of two agents seems ex-ante envy-free but never achieves ex-post envy-freeness. Our analysis navigates both these terrains: We investigate both expected envy (referring to ex-ante envy) and high-probability envy (pertaining to ex-post envy).
%A significant tension associated with envy is its relationship with efficiency (see, e.g., the overview of results in \cite{Arnsperger94}).
%There is a growing body of research on \emph{dynamic fair allocation} \cite{hassanzadeh2023sequential, benade2018make,kash2014no,zeng2020tradeoffs,sinclair2022sequential}, exemplified by food bank operations, hones in on this fairness-efficiency balance. Our work addresses this tension as well and suggests solutions to tackle it.
Building on this foundation, a growing body of research on \emph{dynamic fair allocation} \cite{hassanzadeh2023sequential, benade2018make,kash2014no,zeng2020tradeoffs,sinclair2022sequential}, exemplified by applications such as food bank operations, explores ways for allocating resources dynamically. %Our work aligns with this literature, focusing on dynamic allocation mechanisms.

Within this literature, \citet{benade2018make} is the work most related to ours. The authors model the dynamic fair division of $T$ indivisible goods that arrive online and must be immediately allocated to exactly $n$ heterogeneous agents who assign a value in $[0,1]$ to each item. Their goal is to design allocation algorithms that minimize the maximum envy at time $T$, where envy is defined as the largest difference between any agent's overall value for items allocated to another agent and her own. They design an efficient algorithm with an envy of $\tilde O(\sqrt{T})$, and show that this guarantee is asymptotically optimal. Despite the many alignments in the underlying mathematical framework and results, there are significant distinctions between the work of \citet{benade2018make} and our work.  

First and foremost, while envy in \citet{benade2018make} arises from heterogeneous valuations among agents, our model involves homogeneous agents. To emphasize this point, in the model of  \citet{benade2018make}, if agents were homogeneous, then simply allocating each item to the agent with the lowest cumulative reward would yield an envy of at most one and not $\tilde O(\sqrt{T})$. Second, in our work, envy is generated due to arrival order rather than solely by allocation decisions like \citet{benade2018make}. In our setting, the same arm (or resource) can be assigned to several agents, with its utility being revealed only after it is pulled for the first agent; thus, envy emerges from the inherent explore-and-exploit tradeoffs. Third, while \citet{benade2018make} aim \emph{to design} fair algorithms, we focus on \emph{measuring} envy under virtually any algorithm and different arrival order mechanisms. Indeed, in our work, the decision-making algorithm could operate optimistically like UCB~\cite{auer2002finite}, follow Thompson sampling~\cite{agrawal2012analysis}, or leverage deep learning techniques to learn reward distribution over time. %These fundamental differences motivate our investigation into the interplay between exploration, exploitation, and fairness in recommendation systems.


From the machine learning perspective, fairness has attracted increasing interest over the past decade (see, e.g., \cite{Mehrabi19,caton2020fairness,pessach2022review} for recent surveys).
Within the domain of fair classification~\cite{Kleinberg16}, several works apply a fair division lens to evaluate the equity of predicted classes relative to protected attributes~\cite{Hossain20-2, ben2021protecting}. Some works consider fairness in MABs but overlook multi-agent complexities~\cite{wang2021fairness,liu2017calibrated}, and other works consider multi-agent MABs but sidestep fairness considerations~\cite{chakraborty2017coordinated,bargiacchi2018learning}. 

A work that is similar to ours is \citet{Hossain20} and its extensions~\cite{jones2023efficient}.
The authors introduce a multi-agent MABs model, in which a pull of an arm simultaneously serves multiple agents.
The objective of \cite{Hossain20} is minimizing regret with respect to the \textit{Nash social welfare}, a celebrated concept in the economic literature~\cite{kaneko1979nash}. Despite apparent parallels, our work and \cite{Hossain20} differ fundamentally.
For instance, while they assume a single arm is pulled each round to serve all agents, we permit different agents to pull different arms within a round.
Moreover, our model captures intra-round information exploitation due to the consistency of rewards, an angle that they do not model.
Their emphasis is on the Nash product as an objective, known for its envy-freeness properties (EF1)~\cite{caragiannis2019unreasonable}. We, on the other hand, aim to measure the envy induced by any anonymous algorithm.

Another pertinent line of work involves incentivizing exploration~\cite{Kremer14,bahar2020fiduciary,frazier2014incentivizing, Mansour15,simchowitz2024exploration}.
In the framework proposed by~\cite{Kremer14}, algorithms can suggest which arms agents should pull. However, agents are strategic and might opt not to follow the algorithm's recommendation, particularly when it comes to exploration.
This necessitates the design of incentive-compatible mechanisms~\cite{Roughgarden10}. Interestingly, this reluctance to embrace exploration is also central to our work because exploration inherently induces envy. Nevertheless, our approach diverges; we assume agents are non-strategic and the algorithm is in charge of arm-pulling, treating envy as a quantifiable undesired outcome.


Finally, while this work focuses on analyzing envy dynamics for arbitrary algorithms, designing socially optimal algorithms under our model is nontrivial. Because rewards remain constant for extended periods, the problem shares many characteristics with the Pandora’s Box framework \cite{weitzman1978optimal,boodaghians2020pandora,berger2023pandora,amanatidis2024pandora} and prophet inequalities \cite{agrawal2020optimal,brustle2024competition}. We expand on these connections in Section~\ref{sec:discussion}.

% the problem of finding an optimal arm in each round and the lines of research of 
% Pandora's box'' problem~\cite{weitzman1978optimal} and

% . There are different and challenging variations of the ``Pandora's box'' \cite{agrawal2020optimal, boodaghians2020pandora, berger2023pandora} problem for which different solutions have been proposed.
% These works might assist in finding an optimal algorithm.
% For example, \citet{berger2023pandora} offers a variation of the classical Pandora's box problem with combinatorial opening costs. That is, each set of boxes has a total cost, and the cost of opening each box depends on the number of boxes that have been opened so far. As we show later in the work, tools that have been developed for Pandora's box are largely futile for our problem, besides some degenerate cases. 

% \cite{boodaghians2020pandora}
% \cite{amanatidis2024pandora} - pandora's box over time
% \cite{fu2023pandora} without inspection