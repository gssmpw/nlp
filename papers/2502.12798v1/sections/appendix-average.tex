\section{Average Envy}
\label{sec: avg envy}
In this section, we examine another way to define envy: The average reward disparity between the agents. We define the \emph{average envy}, denoted $\envavg^T$, as 
\[
\envavg^T = \frac{1}{\binom{N}{2}}\sum_{1\leq i<j\leq N}{\abs{\env_{i,j}^T}}.
\]
For the special cases of $N=2$ agents, the definition of maximal envy $\env$ and average envy $\envavg$ coincide. 


Since $\envavg^t \leq \env^t$ for all $t$  almost surely, any upper bound on the maximal envy can be applied to the average envy. Particularly, Theorem~\ref{thm: uni upper-bound} provides an immediate upper bound on $\E{\envavg^T}$ of $O\left(\sqrt{\ln (N) \sum^T_{t=1} \var{\dift}} \right)$. Using a slightly more careful analysis, we can eliminate the $\sqrt{\ln{(N)}}$ factor.
\begin{proposition}\label{prop: avg upper-bound}
When executing any algorithm, it holds that
\[\E{\max_{1\leq t \leq T} \envavg^t (\uniord)} \leq 2\sqrt{\ln{(N)} \sum^{T}_{t=1}{\var{\dift}} }.\]
\end{proposition}
\begin{proof}[Proof of Proposition~\ref{prop: avg upper-bound}]
Much like the proof of Theorem~\ref{thm: uni upper-bound}, this proof is based on the fact that $\dift$ are subgaussian random variables. From the linearity of expectation, we get
\begin{align}\label{avg 1}
\E{\max_{1\leq t \leq T} \envavg^t } &=
\E{\max_{1\leq t \leq T} \frac{1}{\binom{N}{2}}\sum_{1\leq i<j\leq N}{\abs{\env_{i,j}^t}}} 
\leq \E{\frac{1}{\binom{N}{2}}\sum_{1\leq i<j\leq N}{\max_{1\leq t \leq T} 
 \abs{\env_{i,j}^t}}} \nonumber\\
&=\frac{1}{\binom{N}{2}}\sum_{1\leq i<j\leq N}\E{\max_{1\leq t \leq T}  \abs{\sum^t_{\tau=1}{\adif{i}{j}^\tau}} }.
\end{align}
For every pair of agents $i,j \in [N]$, it holds that
\begin{align}\label{avg 2}
\E{\max_{1\leq t \leq T}  \abs{\sum^t_{\tau=1}{\adif{i}{j}^\tau}} } =
\E{\max_{1\leq t \leq T, \sigma\in \{-1,1\}}\left\{\sigma\sum^t_{\tau=1}{\adif{i}{j}^\tau}\right\}} \leq
\sqrt{2\ln{(2)}\sum^T_{t=1}{\var{\dift}}},
\end{align}
where the last inequality is due to Proposition~\ref{prop:envy is good SG} and Claim~\ref{claim: sg max}. By combining Inequalities~\eqref{avg 1} and \eqref{avg 2} we can conclude that
\begin{align*}
\E{\max_{1\leq t \leq T} \envavg^t } \leq
\frac{1}{\binom{N}{2}}\sum_{1\leq i<j\leq N}{\sqrt{2\ln{(2)}\sum^T_{t=1}{\var{\dift}}}} =
\sqrt{2\ln{(2)}\sum^T_{t=1}{\var{\dift}}},
\end{align*}
which concludes the proof of Proposition~\ref{prop: avg upper-bound}. 
\end{proof}
Next, we craft a lower bound for the average envy.
\begin{proposition}\label{prop: mp avg lower-bound}
    For a large enough $T$, a sufficiently random execution with a symmetric, memory-free algorithm yields
    \[\E{\envavg^T} \geq c\sqrt{ \sum^{T}_{t=1}{\var{\dif^t}}},\]
    where $c> 0$ is a global constant.    
\end{proposition}


\begin{proof}[Proof of Proposition~\ref{prop: mp avg lower-bound}]
The proof of Proposition~\ref{prop: mp avg lower-bound} is almost identical to the proof of Theorem~\ref{thm: uni lower-bound}. In that proof, we bounded the (maximal) envy from below using the envy between a specific couple of agents.
Since, the algorithm is symmetric, the bound we showed is valid for every two agents;
thus, for every $i,j$ it holds that
\begin{align*}
\E{\env_{i,j}^T} \geq \frac{A_1}{2}\sqrt{ \sum^{T}_{t=1}{\var{\dif^t}} },
\end{align*}
where $A_1$ is the constant from Theorem~\ref{thm:BDG}. Using linearity of expectation, we get
\begin{align*}
\E{\envavg^T} & =
\E{\frac{1}{\binom{N}{2}}\sum_{i,j \in [N]^2}{\env_{i,j}^T}} =
\frac{1}{\binom{N}{2}}\sum_{i,j \in [N]^2}{\E{\env_{i,j}^T}}
\geq
\frac{1}{\binom{N}{2}}\sum_{i,j \in [N]^2} {\frac{A_1}{2}\sqrt{ \sum^{T}_{t=1}{\var{\dif^t}} }}
\\&=
\frac{A_1}{2}\sqrt{ \sum^{T}_{t=1}{\var{\dif^t}} }.
\end{align*}
This concludes the proof of Proposition~\ref{prop: mp avg lower-bound}.
\end{proof}
We finalize this section by mentioning that the upper bound on nudged arrival and maximal envy holds trivially for the average envy due to the fact that $\envavg^t \leq \env^t$ for all $t$  almost surely. Future work could seek a tighter bound for the average envy.

