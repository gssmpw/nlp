% !TeX root = main.tex 
%!TEX root = main.tex

\section{Introduction}\label{sec:intro}

Let $G=(V,E)$ be any $n$-vertex graph with maximum degree $\Delta$. A basic graph theory fact is that vertices of $G$ can be colored with $\Delta+1$ colors such that no edge is monochromatic. This can be done using 
a textbook greedy algorithm: iterate over vertices of $G$ in any arbitrary order and for each vertex greedily find a color that has not been used in its neighborhood, which is guaranteed to exist by the pigeonhole principle. 
This algorithm is quite simple and efficient as it runs in linear time and space. But, can we design even more efficient algorithms? 

Assadi, Chen, and Khanna~\cite{AssadiCK19} addressed this question by designing various \emph{sublinear} algorithms for the $(\Delta+1)$ vertex coloring problem. These are algorithms whose resource requirements 
are significantly smaller than their input. Some canonical examples include $(a)$ \emph{graph streaming} algorithms~\cite{FeigenbaumKMSZ04} that process graphs by making one pass 
over their edges and using a limited space; $(b)$ \emph{sublinear time} algorithms~\cite{ChazelleRT01} that process graphs by 
querying its adjacency list/matrix and using limited \emph{time}; or $(c)$ \emph{Massively Parallel Computation (MPC)} algorithms~\cite{KarloffSV10} that process graphs 
in synchronous rounds and a distributed manner over machines with limited \emph{communication} (see~\Cref{sec:sublinear} for definitions). 

The key contribution of~\cite{AssadiCK19} was proving the following (purely combinatorial) theorem about $(\Delta+1)$ coloring, termed the \textbf{palette sparsification theorem (PST)}. 

\begin{theorem}[\textbf{Palette Sparsification Theorem (PST)}~\cite{AssadiCK19}]\label{thm:pst}
	For any graph $G=(V,E)$ with maximum degree $\Delta$, if we sample $O(\log{n})$ colors $L(v)$ for each vertex $v \in V$ independently and uniformly at random
	from the  colors $\set{1,2,\ldots,\Delta+1}$, then, with high probability, $G$ can be colored so that every vertex $v$ chooses its color from its own list $L(v)$. 
\end{theorem}

The authors in \cite{AssadiCK19} used PST to design sublinear algorithms in all the aforementioned models using the following ``sparsifying'' nature of this result: Firstly, it is easy to see that to color $G$ from the sampled 
lists, we can ignore all edges $(u,v) \in E$ where $L(u) \cap L(v) = \emptyset$ since they do not create any conflict under any possible coloring. Secondly, for any edge $(u,v) \in E$, the probability that it still remains conflicting---the probability that two independently chosen $O(\log{n})$-lists from $(\Delta+1)$ colors intersect---is $O(\log^2\!{(n)}/\Delta)$. Combining these with the upper bound of $n\Delta/2$ 
on the number of edges in $G$ implies that in expectation (and even with high probability) there are only $O(n\log^2\!{(n)})$  ``important'' edges that the algorithm should consider. 
The sublinear algorithms can now 
be obtained from this in a simple way\footnote{For instance, for a streaming algorithm, first sample all the $O(n\log{n})$ colors, and during the stream whenever an edge arrives, see if it is an important edge and if so store it. 
At the end, use~\Cref{thm:pst} to color the graph using these stored edges. This leads to a single-pass streaming algorithm with $O(n\log^2\!{(n)})$ space for $(\Delta+1)$ coloring.}.

Since its introduction~\cite{AssadiCK19}, PST and its variants and generalizations have been studied in sublinear algorithms~\cite{ChangFGUZ19,BeraCG20,AssadiKM22,ChakrabartiGS22,AssadiCGS23}, distributed computing~\cite{FischerHM23,FlinGHKN23,HalldorssonKNT22}, and discrete mathematics~\cite{AlonA20,AndersonBD22,KahnK23,KahnK24,HefetzK24}. 

Despite its long list of applications, and perhaps even due to its generality, PST suffers from two drawbacks. Firstly, the proof of PST is considerably complicated and technical; it goes through 
the so-called sparse-dense decomposition of graphs due to~\cite{Reed98} (and the variant proved in~\cite{AssadiCK19} itself, building on~\cite{HarrisSS16}), and then a detailed three-phase approach
for coloring each part in the decomposition differently using various probabilistic and random graph theory arguments\footnote{All known proofs of PST for $(\Delta+1)$ coloring (or so-called $(\deg+1)$-(list) 
coloring)~\cite{AssadiCK19,AlonA20,HalldorssonKNT22,KahnK23,FlinGHKN24} follow this decomposition plus three-phase approach and it was even pointed out in~\cite{KahnK23} that: ``something of this type [...] seems more or less
unavoidable''.}. Secondly, PST, as stated, is a purely combinatorial theorem and not an algorithmic one, and thus
to obtain the coloring of $G$, one needs to run a rather complicated and non-greedy post-processing algorithm to find the coloring of $G$ from the sampled lists (given also the decomposition of the graph; see~\cite{AssadiCK19} for more details). 

\paragraph{Our contribution.} We show that introducing a simple \emph{asymmetry} in the definition of PST leads to the same colorability guarantee but this time using a much simpler proof and algorithm. 

\begin{result}
\textbf{Asymmetric Palette Sparsification Theorem (APST).}
	For any graph $G=(V,E)$ with maximum degree $\Delta$, there is a distribution on list-sizes $\ell: V \rightarrow \IN$ (depending only on vertices $V$ and \underline{not} edges $E$) 
	such that an \underline{average} list size is deterministically $O(\log^2\!{(n)})$ and the following holds. With high probability, 
	if we sample $\ell(v)$ colors $L(v)$ for each vertex $v \in V$ independently and uniformly at random
	from colors $\set{1,2,\ldots,\Delta+1}$, then, with high probability, the greedy coloring algorithm that processes vertices in the increasing order of list-sizes finds a proper coloring of $G$ by coloring 
	each $v$ from its own list $L(v)$. 
\end{result}

The benefit of our APST compared to the original PST of~\cite{AssadiCK19} (and all its other alternative variants in~\cite{AlonA20,HalldorssonKNT22,KahnK23,FlinGHKN24}) is twofold: it admits a 
\emph{significantly} simpler proof, while also allowing for coloring from the sampled list using the standard greedy algorithm itself. At the same time, it is also weaker than the original PST 
on two fronts: it requires $O(\log^2\!{(n)})$ list sizes per vertex as opposed to $O(\log{n})$ (which is similar to~\cite{HalldorssonKNT22,FlinGHKN24}) but much more importantly, it allows the vertices to have much larger 
list sizes in the worst-case and only bounds the \emph{average} list sizes (this is different than all prior work on PST, and was inspired by the recent work of~\cite{FlinM24} on the communication complexity of $(\Delta+1)$ coloring). We note that asymmetric list sizes are \emph{necessary} if we like to color the graph \emph{greedily} from the sampled colors\footnote{Consider 
coloring a $(\Delta+1)$-clique. When coloring the last vertex $v$ of the clique in the greedy algorithm, there is only one color that can be assigned to $v$ but to ensure this color is sampled by $v$ even with a constant probability, we need $L(v)$ to have 
size $\Omega(\Delta)$. Our APST addresses this by allowing vertices that are colored later in the greedy algorithm to also sample more colors, while earlier vertices need to stick with smaller list sizes.}. 

Finally, APST allows for recovering the same type of sublinear algorithms as in~\cite{AssadiCK19} with only an extra $\poly\!\log\!{(n)}$ overhead in their resources. 
In particular, we obtain the following sublinear algorithms for $(\Delta+1)$ vertex coloring: 
\begin{itemize}
	\item A randomized \textbf{graph streaming} algorithm with $\Ot(n)$ space\footnote{Throughout, we use $\Ot(f) := O(f \cdot \poly\log{(f)})$ to suppress polylog factors.} and a single pass over the input.  
	\item A randomized \textbf{sublinear time} algorithm with $\Ot(n^{1.5})$ time, given (non-adaptive) query access to both adjacency list and matrix of the input (also called the general query model). 
	\item A randomized \textbf{MPC} algorithm with $\Ot(n)$ memory per machine and $O(1)$ rounds. 
\end{itemize}
The number of passes in the streaming algorithms as well as the rounds in the MPC one are clearly optimal. It was also proven in~\cite{AssadiCK19} that 
the runtime of the sublinear time algorithm and the space of the streaming algorithm are nearly optimal up to $\poly\!\log{(n)}$ factors (for the streaming algorithm, storing the coloring itself requires this much space anyway). 
These constitute the simplest known sublinear algorithms for $(\Delta+1)$ vertex coloring.\footnote{To our knowledge, no other streaming nor sublinear time algorithms beside~\cite{AssadiCK19} have been developed for this problem but for MPC algorithms,~\cite{ChangFGUZ19,CzumajDP21} have subsequently presented other algorithms for this problem.} 

In conclusion, we find our APST as a more ``algorithmic friendly'' version of PST that still allows for recovering nearly optimal sublinear algorithms for $(\Delta+1)$ coloring. In addition, we hope its proof 
can act as a gentle warmup and introduction to the original PST itself. 

Finally, in~\Cref{sec:warm-up}, we also present an even simpler sublinear \emph{time} algorithm for $(\Delta+1)$ coloring whose proof
is inspired by our APST but does not directly uses it. While qualitatively weaker, the benefit of this algorithm is that it is entirely self-contained and only requires elementary probabilistic arguments (not even concentration inequalities), and 
thus can be even more ``classroom friendly'' than the algorithms obtained from our APST. 

