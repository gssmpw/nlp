% !TeX root = main.tex 
%!TEX root = main.tex

\newcommand{\LL}{\ensuremath{\mathcal{L}}}



\section{Sublinear Algorithms from Asymmetric Palette Sparsification}\label{sec:asymmetric} 

We now show how our asymmetric palette sparsification theorem in~\Cref{thm:apst} can be used to obtain sublinear algorithms for $(\Delta+1)$ vertex coloring. These algorithms are more or less identical 
to the (exponential-time) sublinear algorithms of~\cite{AssadiCK19} from their original palette sparsification theorem and we claim no novelty in this part\footnote{We do note that however, the time-efficient algorithms of~\cite{AssadiCK19} are considerably more complex. They first need to find a so-called sparse-dense decomposition of the input graph via sublinear algorithms. Then, this decomposition is used to color the final graph from the sampled colors using an algorithmic version of the proof of their palette sparsification theorem which in particular requires a highly non-greedy and not-so-simple approach.}. Instead, we merely point out how the ``asymmetry'' in list-sizes in~\Cref{thm:apst} 
does not weaken the performance of the resulting sublinear algorithms beyond some $\polylog{(n)}$-factors, but instead leads to much simpler post-processing algorithms for finding the coloring of the graph from the sampled lists. 

\begin{theorem}\label{thm:sublinear}
	There exist randomized sublinear algorithms that given any graph $G=(V,E)$ with maximum degree $\Delta$ with high probability output a $(\Delta+1)$ vertex coloring of $G$ using: 
	\begin{itemize}
		\item \emph{\textbf{Graph streaming:}} a single pass over the edges of $G$ in any order and $\Ot(n)$ space; 
		\item \emph{\textbf{Sublinear time:}} $\Ot(n^{1.5})$ time and non-adaptive queries to adjacency list and matrix of $G$;
		\item \emph{\textbf{Massively parallel computation (MPC):}} $O(1)$ rounds with machines of $\Ot(n)$ memory.  
	\end{itemize}
\end{theorem}

As stated earlier, the proof of~\Cref{thm:sublinear} follows the same exact strategy as the (exponential-time) sublinear algorithms of~\cite{AssadiCK19}. To do so, we need the following definition. 

\paragraph{Conflict graphs.} Let $G=(V,E)$ be any graph with maximum degree $\Delta$ and $\LL := \set{L(v) \mid v \in V}$ be a set of lists of colors sampled for vertices of $G$ according to the distribution of~\Cref{thm:apst}. 
We define the \textbf{conflict graph} $G_\LL = (V, E_{\LL})$ of $G$ and $\LL$ as the spanning subgraph of $G$ consisting of all edges $(u,v) \in E$ such that the sampled lists $L(u)$ and $L(v)$ intersect with each other. 

The following observation allows us to use conflict graphs in our sublinear algorithms as a proxy to the original graph $G$. 

\begin{observation}\label{obs:conflict-graph-use}
	The greedy algorithm in~\Cref{thm:apst} outputs the same exact coloring when run over the conflict graph $G_{\LL}$ instead of the original graph $G$. 
\end{observation}
\begin{proof}
	The only edges that affect the greedy algorithm of~\Cref{thm:apst} are edges $(u,v) \in E$ such that $L(u) \cap L(v)$ is non-empty. These edges are identical in $G$ and $G_{\LL}$. 
\end{proof}

The following easy claim also allows us to bound the size of the conflict graphs. 

\begin{claim}\label{clm:conflict-graph-size}
	The list of colors $\LL$ consists of $O(n\log^2{n})$ colors deterministically and the expected number of edges in $G_\LL=(V,E_{\LL})$ is $\Exp\card{E_{\LL}} = O(n\log^4{n})$. 
\end{claim}
\begin{proof}
	By the list sizes property of \Cref{thm:apst}, we already know that  $\LL$ consists of $O(n\log^2{n})$ colors deterministically. For the second part, for any edge $(u,v)$, we have, 
	\[
		\Pr\paren{\text{$(u,v)$ is in $E_{\LL}$}} \leq \Exp_{\ell(u),\ell(v)}\bracket{\Pr\paren{L(u) \cap L(v) \neq \emptyset \mid \ell(u),\ell(v)}} \leq \expect{\frac{\ell(u) \cdot \ell(v)}{\Delta+1}} = \frac{O(\log^4{(n)})}{\Delta},
	\]
	where the first inequality is by the law of conditional expectation (by conditioning on list-sizes first), the second is by union bound, and the third is by the list-size properties of~\Cref{thm:apst}. Since the total
	number of edges in $G$ is at most $n\Delta/2$, we can conclude the proof. 	
\end{proof}

We now prove~\Cref{thm:sublinear} for each family of sublinear algorithms separately. In the following, we prove the resource guarantees of the algorithms only in expectation instead of deterministically. However, using the standard trick of running $O(\log{n})$ copies of the algorithm in parallel, terminating any copy that uses more than twice the expected resources, and returning the answer of any of the remaining ones, we obtain the desired
algorithms in~\Cref{thm:sublinear} as well (this reduction only increases space/query/memory of algorithms with an $O(\log{n})$ multiplicative factor and the error probability with a $1/\poly(n)$ additive factor). 

\paragraph{Graph streaming.} At the beginning of the stream, sample the colors $\LL$ using~\Cref{thm:apst} and during the stream, only store the edges that belong to $G_{\LL}$. In the end, 
run the greedy algorithm on $G_{\LL}$ and return the coloring.~\Cref{thm:apst} ensures that with high probability $G$ is (list-)colorable from the sampled lists which leads to a $(\Delta+1)$ coloring of the entire graph. 
\Cref{obs:conflict-graph-use} ensures that we only need to work with $G_{\LL}$ at the end of the stream and not all of $G$, and~\Cref{clm:conflict-graph-size} bounds the space of the algorithm with $\Ot(n)$ space in expectation. 

We can implement this algorithm in dynamic streams also by recovering the conflict graph using a sparse recovery sketch instead of explicitly storing each of its edges in the stream. See~\cite{AhnGM12} for more on dynamic streams. 

\paragraph{Sublinear time.} Sample the colors $\LL$ using~\Cref{thm:apst} and query the edges between \emph{all} pairs of vertices $u \neq v \in V$ with $L(u) \cap L(v)$ being non-empty to find the edges of $G_{\LL}$. The same analysis as in~\Cref{clm:conflict-graph-size}
applied to the ${{n}\choose{2}}$ vertex-pairs (instead of $\leq n\Delta/2$ edges), ensures that the expected number of queries is $\Ot(n^2/\Delta)$. We can then color $G_{\LL}$ using the greedy algorithm in $\Ot(n)$ time. The correctness follows 
from~\Cref{thm:apst} and \Cref{obs:conflict-graph-use} as before. This algorithm only requires adjacency matrix access to $G$ and we run it when $\Delta \geq \sqrt{n}$ to obtain $\Ot(n\sqrt{n})$ time/query algorithm. When $\Delta \leq \sqrt{n}$, we instead run the standard greedy algorithm using $O(n\Delta) = \Ot(n\sqrt{n})$ 
time and queries to the adjacency list of $G$ instead. 

\paragraph{MPC.} The algorithm is almost identical to the semi-streaming one. Suppose we have access to public randomness. Then, we can sample the lists $\LL$ publicly, and each machine that has an 
edge in $G_{\LL}$ can send it to a designated machine. This way, a single machine receives all of $G_{\LL}$ and can color it greedily. The correctness follows from~\Cref{thm:apst} and~\Cref{obs:conflict-graph-use} and the memory needed for this designated machine will be $\Ot(n)$ in expectation by~\Cref{clm:conflict-graph-size}. 
Finally, we can remove the public randomness by having one machine do the sampling first on its own and share it with all the remaining machines in $O(1)$ rounds using the standard MPC primitives of search and sort. 


 