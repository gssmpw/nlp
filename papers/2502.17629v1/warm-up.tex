% !TeX root = main.tex 
%!TEX root = main.tex


\clearpage

\appendix
\section{Appendix: A Self-contained Sublinear Time Algorithm}\label{sec:warm-up}

In addition to our main result, we also first present a very simple sublinear time algorithm for $(\Delta+1)$ coloring in the following theorem. This algorithm has recently and independently been discovered in~\cite{ferber2025improved} 
and has also appeared as part of lecture notes for different courses~\cite{Lec24,Lec25,HW} at this point. Finally, this algorithm can also be seen as a simple adjustment to the sublinear time $(\Delta+o(\Delta))$ coloring algorithm of~\cite{MorrisS21}. 


\begin{theorem}\label{thm:warm-up}
	There is a randomized algorithm that given any graph $G$ with maximum degree $\Delta$ via adjacency list and matrix access, 
	outputs a $(\Delta+1)$ coloring of $G$ in  $O(n \cdot \sqrt{n\log{n}})$ expected time. 
\end{theorem}

We note that unlike our sublinear time algorithm in~\Cref{thm:sublinear} which was \emph{non-adaptive}, namely, made all its queries in advance before seeing the answer to them, the current algorithm is adaptive and needs to 
receive the answer to each query before deciding its next query. 

The algorithm in~\Cref{thm:warm-up} is quite similar to the standard greedy algorithm for $(\Delta+1)$ coloring. It iterates over the vertices
and color each one greedily by finding a color not used in the neighbors' of this vertex yet (which exists by pigeonhole principle). However, unlike the greedy algorithm, $(i)$ it crucially needs to iterate
over the vertices in a random order, and, $(ii)$ instead of 
iterating over the neighbors of the current vertex to find an available color, it samples a color randomly for this vertex and then iterates over all vertices with this color to make sure they are not neighbor to the current vertex. 
Formally, the algorithm is as follows. 

\begin{Algorithm}\label{alg:warmup}
	An (adaptive) sublinear time algorithm for $(\Delta+1)$ vertex coloring. 
	
	\begin{enumerate}
		\item Let $C_1,C_2,\ldots,C_{\Delta+1}$ be the \textbf{color classes} to be output at the end, initially set to empty. 
		\item Pick a permutation $\pi$ of vertices in $V$ uniformly at random.
		\item For $v \in V$ in the order of the permutation $\pi$: 
		\begin{enumerate}
			\item\label{line:reset} Sample $c \in [\Delta+1]$ uniformly at random. 
			\item For every vertex $u \in C_c$, check if $(u,v)$ is an edge in $G$; if \emph{Yes}, restart from Line~\eqref{line:reset}. 
			\item If the algorithm reaches this step, color the vertex $v$ with $c$ and add $v$ to $C_c$. 
		\end{enumerate}
	\end{enumerate}
	
\end{Algorithm}

It is easy to see that this algorithm never outputs a wrong coloring (namely, if it ever terminates, its answer is always correct). Any new vertex colored does not create a conflict with previously colored vertices (given the algorithm explicitly checks to not color $v$ with a color $c$ if one of its neighbors is already colored $c$) and thus at the end, there cannot be any monochromatic edge in the graph. The interesting part of the analysis is to show that the algorithm terminates quickly enough, which is captured by the following lemma. 

\begin{lemma}\label{lem:warmup-runtime}
	For any input graph $G=(V,E)$, the expected runtime of~\Cref{alg:warmup} is 
	\[
	O(\frac{n^2}{\Delta} \cdot \log{\Delta}) ~\text{time}. 
	\] 
\end{lemma}

\noindent
To continue, we need to set up some notation.  For any vertex $v \in V$, we define the random variable $X_v$ as the number of $(u,v)$ queries checked by the algorithm in the for-loop of coloring $v$. Additionally, for any $v \in V$ and permutation $\pi$ picked over $V$, define $\Nback{v}$ as the neighbors $u$ of $v$ with $\pi(u) < \pi(v)$, namely, the ones that are colored \emph{before} $v$ by Algorithm~\Cref{alg:warmup}. Let $\degback{v}:= \card{\Nback{v}}$. We start with the basic observation that the runtime of~\Cref{alg:warmup} can be stated in terms of the variables $\set{X_v}_{v \in V}$. 

\begin{observation}\label{obs:warmup-Xv}
	The expected runtime of~\Cref{alg:warmup} is $O(\sum_{v \in V} \expect{X_v})$. 
\end{observation}
\begin{proof}
	By definition, $X_v$ is the number of queries checked in the for-loop of coloring $v$. The algorithm repeats this for-loop for all $v \in V$, so the expected runtime is the number of all queries checked in this algorithm which is proportional to $\expect{\sum_{v\in V} X_v}$. Applying linearity of expectation concludes the proof. 
\end{proof}

Our task is now to bound each of $\expect{X_v}$ for $v \in V$ to bound the runtime of the algorithm using~\Cref{obs:warmup-Xv}. 

\begin{lemma}\label{lem:warmup-Xv-bound}
	For any vertex $v \in V$ and any choice of the permutation $\pi$:  
	\[
	\expect{X_v \mid \pi} \leq \frac{n}{\Delta+1-\degback{v}}.
	\]
\end{lemma}

To prove~\Cref{lem:warmup-Xv-bound}, we first need the following claim. 

\begin{claim}\label{clm:warmup-Xv-step}
	Fix any vertex $v \in V$, any choice of the permutation $\pi$, and any assignment of colors $C(u_1),C(u_2),\ldots$ by~\Cref{alg:warmup} to all vertices that appear before $v$ in $\pi$. 
	Then, 
	\[
	\expect{X_v\mid \pi} = \frac{\expect{\card{C_c}\mid \pi}}{\Pr\paren{\text{$c$ does not appear in $\Nback{v}$} \mid \pi, C(u_1),C(u_2),\ldots}},
	\]
	where in the RHS, both the expectation and the probability are taken with respect to a color $c$ chosen uniformly at random from $[\Delta+1]$. 
\end{claim}
\begin{proof}
	Define the colors $B(v)$ as the set of colors that appear in $\Nback{v}$, that is 
	\[
	B(v) := \set{c \in [\Delta+1] \mid  \text{there exists $u\in\Nback{v}$ with $c(u)=c$}}.
	\]
	
	For every color $c$, if $c$ is in $B(v)$ then $v$ cannot be colored by $c$, and otherwise it can. The probability of picking each color $c$ is $1/(\Delta +1)$. 
	For $c \notin B(v)$, the number of needed queries before coloring $v$ is $\card{C_c}$. 
	For $c \in B(v)$, the algorithm first needs to check up to $\card{C_c}$ queries to know this color is not available to $v$, and then it simply needs to repeat the same exact process.
	As such, 
	\[
	\expect{X_v\mid \pi}  = \sum_{c \notin B(v)} \frac{1}{\Delta+1}\card{C_{c}} + \sum_{c \in B(v)} \frac{1}{\Delta+1}(\card{C_{c}}+ \expect{X_v\mid \pi} ) = \expect{\card{C_c}\mid \pi} + \frac{\card{B(v)}}{\Delta +1} \cdot \expect{X_v\mid \pi}.
	\]
	
	We can also define the probability of $c$ not appearing in $\Nback{v}$ in terms of  $\card{B(v)}$ as below:
	
	\[
	\Pr\paren{\text{$c$ does not appear in $\Nback{v}$} \mid \pi, C(u_1),C(u_2),\ldots} = 1 - \frac{\card{B(v)}}{\Delta+1}. 
	\]
	
	By solving the recursive equation above, we will get that
	\[
	\expect{X_v\mid \pi} =\frac{\expect{\card{C_c}\mid \pi}}{\Pr\paren{\text{$c$ does not appear in $\Nback{v}$} \mid \pi, C(u_1),C(u_2),\ldots}}. \Qed{clm:warmup-Xv-step}
	\]
	
\end{proof}

Using~\Cref{clm:warmup-Xv-step}, we can conclude the proof of~\Cref{lem:warmup-Xv-bound}. 
\begin{proof}[Proof of~\Cref{lem:warmup-Xv-bound}]
	Each color $c' \in [\Delta+1]$ is chosen with probability $1/(\Delta+1)$ in Line~\eqref{line:reset} of the algorithm. Thus, 
	\[
	\expect{\card{C_c} \mid \pi} = \sum_{c'\in [\Delta +1]}{\Pr\paren{c=c' \mid \pi}\cdot \card{C_{c'}} } \leq \frac{n}{\Delta +1}, 
	\]
	as the sets $\set{C_{c'} \mid c' \in [\Delta+1]}$ are disjoint and partition the already-colored vertices which are at most $n$ vertices. 
	At this point, at most $\degback{v}$ colors have been used in the neighborhood of $v$ and thus cannot be used to color $v$. As such,
	\[
	\Pr\paren{\text{$c$ does not appear in $\Nback{v}$} \mid \pi, C(u_1),C(u_2),\ldots} \geq 1-\frac{\degback{v}}{\Delta +1}.
	\]
	Using~\Cref{clm:warmup-Xv-step} and the above bounds, we conclude
	\begin{align*}
		\expect{X_v \mid \pi } &= \frac{\expect{\card{C_c} \mid \pi}}{\Pr\paren{\text{$c$ does not appear in $\Nback{v}$} \mid \pi, C(u_1),C(u_2),\ldots}} \\
		&\leq \frac{n}{\Delta +1 -\degback{v}}.\Qed{lem:warmup-Xv-bound}
	\end{align*}
	
\end{proof}

By~\Cref{lem:warmup-Xv-bound} (and~\Cref{obs:warmup-Xv}), for any choice of the permutation $\pi$ in~\Cref{alg:warmup},  
\begin{align}
	\expect{\text{runtime of~\Cref{alg:warmup}} \mid \pi} = O(1) \cdot \sum_{v \in V} \frac{n}{\Delta+1-\degback{v}}.  \label{eq:warmup-suffices}
\end{align}

We now consider the randomness of  $\pi$ to bound the RHS above in expectation over $\pi$. 
\begin{lemma}\label{lem:warmup-RHS-suffices}
	We have, 
	\[
	\Exp_{\pi}\bracket{\sum_{v \in V} \frac{n}{\Delta+1-\degback{v}}} = O(\frac{n^2}{\Delta} \cdot \log{\Delta}).
	\] 
\end{lemma}
\begin{proof}
	Using the linearity of expectation, we have
	\[
	\Exp_{\pi}\bracket{\sum_{v \in V} \frac{n}{\Delta+1-\degback{v}}} =n \cdot \sum_{v\in V} \Exp_{\pi}\bracket{\frac{1}{\Delta+1-\degback{v}}}.
	\]
	
	For each permutation $\pi$, $\degback{v}$ depends on $v$'s relative position in the permutation $\pi$ with respect to its neighbors and it can vary from $0$ to $\deg(v)$. Each of these positions happens with the same probability ${1}/({\deg(v)+1})$. 
	Hence, for every vertex $v\in V$,
	\begin{align*}
		\Exp_{\pi}\bracket{\frac{1}{\Delta+1-\degback{v}}} &= \sum_{d=0}^{\deg(v)}\frac{1}{\deg(v)+1}\cdot \frac{1}{\Delta +1-d} \leq \sum_{d=0}^{\Delta}\frac{1}{\Delta+1}\cdot \frac{1}{\Delta +1-d} = O(\frac{\log{\Delta}}{\Delta}),
	\end{align*}
	where the inequality holds because if we let $A := \set{n/(\Delta + 1 - d)}_{d=0}^{\Delta}$, then, in the LHS, we are taking the average of the smallest $\deg(v) + 1$ numbers in $A$, whereas in the RHS we are taking the average of all of $A$.
	Plugging in this bound in the equation above concludes the proof. 
\end{proof}

\Cref{lem:warmup-runtime} now follows immediately from \Cref{eq:warmup-suffices} and \Cref{lem:warmup-RHS-suffices}. We can now use this to wrap up the proof of~\Cref{thm:warm-up}. 

\begin{proof}[Proof of~\Cref{thm:warm-up}]
	
	First, we consider the case $\Delta \geq \sqrt{n\log n}$.  In this case, we use \Cref{alg:warmup}, which relies on the adjacency matrix to access the input graph.
	By~\Cref{lem:warmup-runtime} we know that this algorithm has expected runtime $O(\frac{n^2}{\Delta} \cdot \log{\Delta})$ which is $O(n\sqrt{n\cdot \log(n)})$ by the lower bound on $\Delta$.
	
	
	If $\Delta < \sqrt{n\log n}$ we can use the standard deterministic greedy algorithm for vertex coloring which has linear runtime of $O(n\Delta)$. This algorithm uses an adjacency list to access the graph. 
	This is again $O(n\sqrt{n\log{n}})$ by the upper bound on $\Delta$ in this case, concluding the proof.
\end{proof}

