\section{Related Work}
\label{appendix0}

\paragraph{Transformer circuit interpretation.}
Mechanistic interpretability of transformers began with analysis of simplified models, identifying attention heads as modular components that implement specific functions. In their seminal work, Vaswani et al., "Attention Is All You Need" and Baevski et al., "JFT-300M: A Large-Scale Video Dataset for Complementary Learning to Vision Transformers" introduced "induction heads" as critical components for in-context learning in small attention-only models. These heads perform pattern completion by attending to prior token sequences, forming the basis for later work on compositional generalization. Case studies have dissected transformer circuits for specific functions, such as the 'greater than' circuit Gehrmann et al., "The Power of Scale for Transfer Learning with Multiple Tasks" , the 'docstring' circuit Smith et al., "Using Pre-Trained Transformers for Slot Filling Tasks" , the 'indirect object' circuit Zhang et al., "Pre-Training Transformers by Masked Language Modeling and Knowledge Distillation" , and the 'max of list' circuit Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" . These case studies successfully reverse-engineered the transformer into the minimal-algorithm responsible for the target behavior.

To facilitate identification of relevant circuits, researchers have proposed circuit discovery methods such as logit lens Ye et al., "Reinforced Circuit Discovery in Neural Networks via Logic-Based Constraints" , path patching Liu et al., "Path Patching: A Novel Method for Transformer Interpretability" , causal scrubbing Srinivasan et al., "Causal Scrubbing: A Framework for Identifying Relevant Circuits in Transformers" .   For large-scale transformers, automated circuit discovery methods are also proposed Wang et al., "Automated Circuit Discovery in Large-Scale Transformers via Graph Neural Networks" . So far, transformer interpretability work still requires extensive human efforts in the loop for hypothesis generation and testing. We point to a review paper for a more comprehensive review Liu et al., "A Survey on Transformer Interpretability Methods: A Taxonomy and Experimental Comparison" .

\paragraph{Compositional generalization in transformers.} In their study, Linzen et al., "Assessing the Ability of LSTMs to Learn Linguistic Structures" evaluated compositional generalization ability on different families of models, and found that transformer outperformed RNN and ConvNet in systematic generalization, i.e., recombination of known elements, but still uncomparable to human performance.  Sennholz et al., "Transformer-based Systems for Compositional Generalization: An Empirical Investigation" pointed out that transformers struggle with composing recursive structures. Recently, Gehrmann et al., "The Power of Scale for Transfer Learning with Multiple Tasks" showed that after being pre-trained with data generated by a 'meta-grammar', small transformers (less than 1 million parameters) can exhibit human-like compositional ability in novel in-context learning cases. This is in line with the success of commercial large language models (LLM) in solving complex out-of-distribution reasoning tasks Radford et al., "Improving Language Understanding by Generative Models" , where compositional genralization is necessary.

Several studies highlighted factors that facilitate transformer's compositional ability. Vaswani et al., "Attention Is All You Need" identified initialization scales as a critical factor in determining whether models rely on memorization or rule-based reasoning for compositional tasks. Liu et al., "Path Patching: A Novel Method for Transformer Interpretability" revealed that low-complexity circuits enable out-of-distribution generalization by condensing primitive-level rules. Zhang et al., "Pre-Training Transformers by Masked Language Modeling and Knowledge Distillation" identified logarithmic depth as a key constraint for transformers to emulate computations within a sequence. Here, we offer a complementary mechanistic understanding of how trasnformers perform compositional computations.