[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhou2022responsive",
        "author": "Zhou, Mohan and Bai, Yalong and Zhang, Wei and Yao, Ting and Zhao, Tiejun and Mei, Tao",
        "title": "Responsive listening head generation: a benchmark dataset and baseline"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ng2022learning",
        "author": "Ng, Evonne and Joo, Hanbyul and Hu, Liwen and Li, Hao and Darrell, Trevor and Kanazawa, Angjoo and Ginosar, Shiry",
        "title": "Learning to listen: Modeling non-deterministic dyadic facial motion"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "song2023emotional",
        "author": "Song, Luchuan and Yin, Guojun and Jin, Zhenchao and Dong, Xiaoyi and Xu, Chenliang",
        "title": "Emotional listener portrait: Neural listener head generation with emotion"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ng2023can",
        "author": "Ng, Evonne and Subramanian, Sanjay and Klein, Dan and Kanazawa, Angjoo and Darrell, Trevor and Ginosar, Shiry",
        "title": "Can Language Models Learn to Listen?"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ng2022learning",
        "author": "Ng, Evonne and Joo, Hanbyul and Hu, Liwen and Li, Hao and Darrell, Trevor and Kanazawa, Angjoo and Ginosar, Shiry",
        "title": "Learning to listen: Modeling non-deterministic dyadic facial motion"
      },
      {
        "key": "ng2023can",
        "author": "Ng, Evonne and Subramanian, Sanjay and Klein, Dan and Kanazawa, Angjoo and Darrell, Trevor and Ginosar, Shiry",
        "title": "Can Language Models Learn to Listen?"
      },
      {
        "key": "zhou2022responsive",
        "author": "Zhou, Mohan and Bai, Yalong and Zhang, Wei and Yao, Ting and Zhao, Tiejun and Mei, Tao",
        "title": "Responsive listening head generation: a benchmark dataset and baseline"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "sohl2015deep",
        "author": "Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya",
        "title": "Deep unsupervised learning using nonequilibrium thermodynamics"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      },
      {
        "key": "ho2022cascaded",
        "author": "Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim",
        "title": "Cascaded diffusion models for high fidelity image generation"
      },
      {
        "key": "epstein2023diffusion",
        "author": "Epstein, Dave and Jabri, Allan and Poole, Ben and Efros, Alexei and Holynski, Aleksander",
        "title": "Diffusion self-guidance for controllable image generation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kong2020diffwave",
        "author": "Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan",
        "title": "Diffwave: A versatile diffusion model for audio synthesis"
      },
      {
        "key": "gong2022diffuseq",
        "author": "Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, LingPeng",
        "title": "Diffuseq: Sequence to sequence text generation with diffusion models"
      },
      {
        "key": "ho2022imagen",
        "author": "Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others",
        "title": "Imagen video: High definition video generation with diffusion models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hoogeboom2021argmax",
        "author": "Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\\'e}, Patrick and Welling, Max",
        "title": "Argmax flows and multinomial diffusion: Learning categorical distributions"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gu2022vector",
        "author": "Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining",
        "title": "Vector quantized diffusion model for text-to-image synthesis"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "yang2023diffsound",
        "author": "Yang, Dongchao and Yu, Jianwei and Wang, Helin and Wang, Wen and Weng, Chao and Zou, Yuexian and Yu, Dong",
        "title": "Diffsound: Discrete diffusion model for text-to-sound generation"
      },
      {
        "key": "li2023generalized",
        "author": "Li, Yuhan and Dou, Yishun and Chen, Xuanhong and Ni, Bingbing and Sun, Yilin and Liu, Yutian and Wang, Fuzhen",
        "title": "Generalized deep 3d shape prior via part-discretized diffusion process"
      },
      {
        "key": "han2024clip",
        "author": "Han, Seungdae and Kim, Joohee",
        "title": "CLIP-VQDiffusion: Langauge Free Training of Text To Image generation using CLIP and vector quantized diffusion model"
      }
    ]
  }
]