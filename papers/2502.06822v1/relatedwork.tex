\section{Related Work}
\subsection{Listener Head Generation}
VICO~\cite{zhou2022responsive} 
proposes the LSTM-based model which generates the listener's responsive reactions based on the speaker's facial and audio information.
L2L~\cite{ng2022learning} points out the non-deterministic properties of the listener's reaction. They propose using a codebook to represent the listener's reaction.
ELP~\cite{song2023emotional} proposes using multiple codebooks based on the estimated emotion from the speaker.
LM-Listener~\cite{ng2023can} utilizes the large language model to generate the listener's reaction only using the text information of the speaker. 
Most of the existing listener head generation models~\cite{ng2022learning, ng2023can, zhou2022responsive} utilize the autoregressive approach. However, this approach has drawbacks such as accumulated error problems, so we propose the DiffListener to solve this limitation in non-autoregressive manner.

\subsection{Diffusion Model}
The denoising diffusion probabilistic model~\cite{sohl2015deep} has shown strong performance not only in the image generation~\cite{ho2020denoising,ho2022cascaded,epstein2023diffusion}
but also in the other various generation tasks~\cite{kong2020diffwave,gong2022diffuseq, ho2022imagen}. 
The Argmax Flow~\cite{hoogeboom2021argmax} extends the diffusion model to categorical random variables with transition matrices. 
The VQ-Diffusion~\cite{gu2022vector} improves the discrete diffusion and applies it to the image generation task, which has also been applied in various tasks \cite{yang2023diffsound,li2023generalized,han2024clip}. To the best of our knowledge, this is the first time discrete diffusion is applied to the listener generation task.