

\section{Experiments}
\paragraph{Backbones}
We evaluate \textbf{twelve} mainstreaming LLMs,
the complete list of models is in App.~\ref{app:backbone_list}.
\subsection{Main Results}
Table~\ref{tab:qa-results} and Figure~\ref{tab:qa-results} present the experimental results of QA and Ito's Guessing Game, respectively.
We observe the following empirical findings:
\textbf{(I)} The more entities considered, the worse the performance, and Time Interval Calculation (TIC) is the most challenging task.
The former requires identifying the temporal information of multiple entities, while the latter demands a more precise assessment of specific timestamps.
\textbf{(II)} CoT can enhance performance, however, when the LLM is very small or the context is excessively long, it can even negatively impact temporal reasoning tasks.
This aligns with the conclusions of work~\cite{chu-etal-2024-timebench} and may be attributed to the knowledge sensitivity inherent in temporal reasoning.
\textbf{(III)} InternLM2.5 demonstrates strong performance among small open-source models, which may be attributed to the quality and composition of its training data.
\textbf{(IV)} The reasoning model demonstrates remarkably strong performance.
\textbf{(V)} Temporal alignment is highly challenging, and even powerful model GPT-4o fail to exceed 40 on the Pass@8 metric.
\textbf{(VI)} Small LLMs cannot align entities across different dimensions, and the Pass@$K$ performance for LLMs smaller than 32B does not exceed 10.

\subsection{Analysis}
\paragraph{The shorter the time interval between the entities, the greater the difficulty.}
As illustrated in Figure~\ref{fig:acc_span}, we evaluate performance across various models based on entity inter-dynastic intervals.
For example, an interval of 1 indicates adjacent dynasties, while an interval of 0 represents the same dynasty. 
As the interval decreases, performance declines.
This is because reasoning in QA tasks requires a clear understanding of the temporal relationships between entities, with closer intervals demanding more precise examination.


\begin{figure}[t]
    \centering
\includegraphics[width=0.40\textwidth]{figs/openbook.pdf}
    \caption{Performance in the close-book and open-book settings. Detailed results can be found in App.~\ref{app:openbook}.
    }
    \label{fig:openbook}
\end{figure}

\paragraph{In the open-book setting, temporal reasoning performance can be moderately improved.}
To obtain more precise temporal information about entities, we can leverage search engines to retrieve relevant information from the web, enhancing the specificity of entity details~\cite{wu2025webwalker}.
In the open-book setting, we use the titles and snippets of the Top-10 webpages retrieved via \texttt{Google} search as retrieval-augmented information.
As shown in Figure~\ref{fig:openbook}, it can be observed that performance improves after incorporating the retrieved content, except for Qwen2.5-7B, possibly due to its weaker longe contextual understanding.
