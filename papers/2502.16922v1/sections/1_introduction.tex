\section{Introduction}
\begin{quote}
``究天人之际，通古今之变。''\\
\hspace*{\fill}--- 司马迁《史记·报任安书》
\end{quote}
Understanding time is fundamental to human cognition and plays a pivotal role in shaping our perception and interaction with the world~\cite{islakoglu2025chronosense}.
Recently, Large Language Models (LLMs)have shown promising abilities in temporal reasoning~\citep{chu-etal-2024-timebench,su-etal-2024-living}.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{figs/ctm_overview.pdf}
    \caption{A QA pair from a script error correction task and an instance of the Timeline Ito Game with a ``\textit{fruit size}'' theme from CTM.
    \protect\footnotemark
    }
    \label{fig:intro}
\end{figure}
\footnotetext{The English translation is presented in App.~\ref{app:tran_qa}.
}
Previous benchmarks, which rely on rule-based constructed methods, lack contextualization and involve a limited number of entities in temporal relation evaluation.
The core principle in assessing temporal reasoning lies in evaluating whether the model has a clear understanding of the event time within a temporal coordinate system. 
Compared to other temporal coordinate systems, the Chinese dynastic chronology spans a significantly longer historical scope and encompasses a broader range of culturally-grounded and historical knowledge~\citep{sun-etal-2024-benchmarking-chinese, li-etal-2024-foodieqa, yuan2024cultural, lu2024benchmarking}.
It serves as a well-suitable background for temporal reasoning, as real-world applications can be found in various media, including films, short dramas, and novel writing, all of which rely on it.

\begin{table*}[t]
\small
\centering
\caption{\textbf{Comparison} between CTM and other benchmarks.
Detailed discussion is presented in Appendix~\ref{app:rw}.}
\resizebox{1.8\columnwidth}{!}{%
\begin{tabular}{@{}c|c|c|c|c|c|c@{}}
\toprule
& \textbf{Language}  & \textbf{Construction} & \textbf{Time Scope} & \textbf{Contextualization} & \textbf{Temporal Alignment}
& \textbf{Complex Aspects}\\
\toprule
\textsc{TimeQA}~\shortcite{chen2021a} & En & Rule-based & 1367--2018 & \no & \no & \no\\
\textsc{TempLAMA}~\shortcite{dhingra-etal-2022-time} & En & Rule-based & 2010--2020 & \no & \no & \no\\
\textsc{TempReason}~\shortcite{tan-etal-2023-towards} & En & Rule-based & 634--2023 & \no & \no & \no\\
\textsc{SituatedGen}~\shortcite{zhang2023situatedgen} & En & LLM-based & - & \yes & \no & \yes \\
\textsc{CoTemp\-QA}~\shortcite{su-etal-2024-living}  & En & Rule-based & - & \no & \no & \no\\
\textsc{TimeBench}~\shortcite{chu-etal-2024-timebench}  & En & - & - & \yes & \no & \yes\\
\textsc{TRAM}~\shortcite{wang-zhao-2024-tram} & En & Rule-based & - & \yes & \no & \yes\\
\textsc{ChronoSense}~\shortcite{islakoglu2025chronosense}  & En & Rule-based & - & \no & \no & \no\\
\textbf{CTM}  & Zh & LLM-based & -2100--1912 & \yes & \yes & \yes\\
\bottomrule 
\end{tabular}
}
\label{table:comparsion}
\end{table*}


Therefore, we introduce \textbf{C}hinese \textbf{T}i\textbf{m}e Reasoning (\textbf{CTM}) benchmark in this study.
The comparison between CTM and other benchmarks is shown in Table~\ref{table:comparsion}.
\textbf{CTM} focuses on contextualization, cross-entity relationships, and pair-wise temporal alignment capability.
As shown in Figure~\ref{fig:intro}, answering this question requires a clear temporal understanding of four entities, ``李白'' (701 to 762), ``白居易'' (772 to 826), ``古琴'' (Since ``Pre-Qin''), and ``辣椒'' (Since ``Ming'').
In addition, we develop the Timeline Ito Game to evaluate the LLM's ability to align entities across temporal and other dimensions, requiring pairwise order perception of different entities.
The CTM benchmark is built upon a curated and authoritative Chinese cultural entity repository, which encompasses over 4,700 entities, spanning from figures, places, allusions, ingredients, and intangible cultural heritage.

We evaluate the performance of the CTM benchmark using various mainstream LLMs, including both closed-source and open-sourced from diverse perspectives.
We conduct experiments under both zero-shot and chain-of-thought (CoT) settings~\cite{wei2022chain}, respectively.
Further analysis shows the challenge of CTM and 
provides empirical insights into enhancing LLMs' temporal reasoning abilities and alignment across Chinese dynasties.

The contributions of this work are as follows: 1). We construct an interesting and challenging benchmark CTM, comprising \textbf{8,750} QA pairs and \textbf{60} instances of Timeline Ito Games.
2). We conduct extensive empirical experiments with various LLMs, which show that the proposed tasks are challenging.
3). Analysis of the experiments further reveals potential directions for addressing temporal reasoning tasks.