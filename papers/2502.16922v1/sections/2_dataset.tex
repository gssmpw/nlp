\section{CTM Dataset}

\subsection{Task Definition}
\begin{table*}[t]
\centering
\caption{ 
\textbf{Main results on QA tasks} within CTM benchmark.
The best results among all backbones are \textbf{bolded}, and the second-best results are \underline{underlined}.
}
\small
\setlength\tabcolsep{2pt}
\resizebox{0.90\textwidth}{!}{%

\begin{tabular}{l|ccccc|ccccccc|c}
\toprule

\multicolumn{1}{c|}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{5}{c|}{\textbf{Cross Temp Count}} & \multicolumn{7}{c|}{\textbf{Question Type}} & \multicolumn{1}{c}{\multirow{3}{*}{\textbf{Avg.}}} \\
\cmidrule{2-13}
 & $=1$ (EDD) & $=2$ & $=3$ & $\geq 4$ & $\geq 4_{L}$ (LSEC) & PJ & TOU & RR & SEC & EEU & TIC & TES\\
\midrule
\multicolumn{14}{c}{\cellcolor{uclablue} \textbf{\textit{Closed-Sourced LLMs}}} \\
\midrule
GPT-4o & 56.52 & 51.12 & 44.76 & 26.10 & 53.60
& 58.64 & 38.42 & 57.26 & 36.15 & 40.58 & 15.36 & 59.31 & 48.08\\
\addMethod{CoT} & \underline{67.40}\tiny\textcolor{red}{+10.88} & \underline{58.08}\tiny\textcolor{red}{+6.96} & 49.24\tiny\textcolor{red}{+4.48} & 29.60\tiny\textcolor{red}{+3.50} & 31.60\tiny\textcolor[HTML]{206546}{-22.0}
& \underline{64.10}\tiny\textcolor{red}{+5.46} & \underline{44.71}\tiny\textcolor{red}{+6.29} & \underline{59.62}\tiny\textcolor{red}{+2.36} & \underline{47.09}\tiny\textcolor{red}{+10.94} & 44.06\tiny\textcolor{red}{+3.48} & \underline{17.70}\tiny\textcolor{red}{+2.34} & \underline{61.68}\tiny\textcolor{red}{+2.37}
& \underline{54.21}\tiny\textcolor{red}{+6.13}\\

\arrayrulecolor{black!20}\midrule
Qwen-max & 60.48 & 53.12 & \underline{50.54} & 30.80 & \underline{62.00}
& \textbf{64.39} & 42.55 & 59.10 & 40.71 & \underline{46.38} & \textbf{20.87} & 60.22 & 52.27\\
\addMethod{CoT} & \textbf{69.56}\tiny\textcolor{red}{+9.08} & \textbf{59.32}\tiny\textcolor{red}{+6.20} & \textbf{54.48}\tiny\textcolor{red}{+3.94} & \underline{31.90}\tiny\textcolor{red}{+1.10} & 39.60\tiny\textcolor[HTML]{206546}{-22.40}
& 63.29\tiny\textcolor{red}{-1.10} & \textbf{48.58}\tiny\textcolor{red}{+6.03} & \textbf{63.75}\tiny\textcolor{red}{+4.65} & \textbf{55.77}\tiny\textcolor{red}{+15.06} & \textbf{53.91}\tiny\textcolor{red}{+7.53} & 15.19\tiny\textcolor{red}{-5.68} & \textbf{63.14}\tiny\textcolor{red}{+2.92} & \textbf{57.24}\tiny\textcolor{red}{+4.97} \\

\arrayrulecolor{black!20}\midrule
\rowcolor{mycell}
o1-preview & 52.80 & 46.56 & 49.64 & \textbf{32.70} & \textbf{67.20}
& 58.28 & 44.28 & 53.01 & 43.16 & 40.87 & 11.02 & 56.02 & 48.24\\

\arrayrulecolor{black}\midrule
\multicolumn{14}{c}{\cellcolor{uclagold} \textbf{\textit{Open-Sourced LLMs}}} \\
\midrule
LLaMA3.1$_{\text{8b}}$ & 33.04 & 16.86 & 15.60 & 9.10 & 10.80
& 19.66 & 12.95 & 18.65 & 7.37 & 0.87 & 2.01 & 37.04 & 20.14\\
\addMethod{CoT} & 35.05\tiny\textcolor{red}{+2.01} & 26.44\tiny\textcolor{red}{+9.58} & 19.96\tiny\textcolor{red}{+4.36} & 10.70\tiny\textcolor{red}{+1.60} & 12.40\tiny\textcolor{red}{+1.60}
& 26.48\tiny\textcolor{red}{+6.82} & 19.55\tiny\textcolor{red}{+6.60} & 23.20\tiny\textcolor{red}{+4.55} & 20.02\tiny\textcolor{red}{+12.65} & 15.70\tiny\textcolor{red}{+14.83} & 5.51\tiny\textcolor{red}{+3.50} & 34.37\tiny\textcolor[HTML]{206546}{-2.67} & 24.91\tiny\textcolor{red}{+4.77} \\

\arrayrulecolor{black!20}\midrule
ChatGLM3$_{\text{6b}}$ & 38.40 & 21.60 & 16.04 & 5.80 & 4.80
& 21.40 & 12.28 & 22.67 & 12.25 & 12.75 & 1.84 & 35.58
& 22.52\\
\addMethod{CoT} & 37.24\tiny\textcolor[HTML]{206546}{-1.16} & 22.72\tiny\textcolor{red}{+1.12} & 15.28\tiny\textcolor[HTML]{206546}{-0.76} & 8.20\tiny\textcolor{red}{+2.40} & 4.00\tiny\textcolor[HTML]{206546}{-0.80}
& 20.32\tiny\textcolor[HTML]{206546}{-1.08} & 15.92\tiny\textcolor{red}{+3.64} & 20.12\tiny\textcolor[HTML]{206546}{-2.55} & 14.98\tiny\textcolor{red}{+2.73} & 16.52\tiny\textcolor{red}{+3.77} & 3.01\tiny\textcolor{red}{+1.17} & 29.74\tiny\textcolor[HTML]{206546}{-5.84} 
& 22.61\tiny\textcolor{red}{+0.09} \\

\arrayrulecolor{black!20}\midrule
InternLM2.5$_{\text{7b}}$ & 60.64 & 47.32 & 39.36 & 21.60 & 42.00
& 51.39 & 30.16 & 48.64 & 45.78 & 42.61 & 11.19 & 50.18 
& 45.75\\
\addMethod{CoT} & 61.44\tiny\textcolor{red}{+0.80} & 51.40\tiny\textcolor{red}{+4.08} & 39.36\tiny\textcolor{red}{+0.00} & 20.20\tiny\textcolor[HTML]{206546}{-1.40} & 38.00\tiny\textcolor[HTML]{206546}{-4.00}
& 51.70\tiny\textcolor{red}{+0.31} & 31.45\tiny\textcolor{red}{+1.29} & 49.47\tiny\textcolor{red}{+0.83} & \underline{52.86}\tiny\textcolor{red}{+7.08} & 44.19\tiny\textcolor{red}{+1.58} & 11.52\tiny\textcolor{red}{+0.33} & 48.54\tiny\textcolor[HTML]{206546}{-1.64}
& 46.90\tiny\textcolor{red}{+1.15} \\

\arrayrulecolor{black!20}\midrule
Qwen2.5$_{\text{7b}}$ & 51.80 & 39.88 & 35.96 & 12.40 & 30.00
& 46.28 & 26.38 & 46.28 & 24.14 & 36.23 & 7.35 & 52.01 
& 38.76\\
\addMethod{CoT} & 59.96\tiny\textcolor{red}{+8.16} & 47.60\tiny\textcolor{red}{+7.72} & 36.64\tiny\textcolor{red}{+0.68} & 18.30\tiny\textcolor{red}{+5.90} & 30.80\tiny\textcolor{red}{+0.80}
& 52.46\tiny\textcolor{red}{+6.18} & 29.95\tiny\textcolor{red}{+3.57} & 52.18\tiny\textcolor{red}{+5.90} & 34.13\tiny\textcolor{red}{+9.99} & 40.58\tiny\textcolor{red}{+4.35} & 8.18\tiny\textcolor{red}{+0.83} & 49.64\tiny\textcolor{red}{-2.37} & 44.22\tiny\textcolor{red}{+5.46} \\

\arrayrulecolor{black!20}\midrule
Qwen2.5$_{\text{14b}}$ & 54.36 & 51.16 & 42.56 & 23.80 & 42.00 
& 57.44 & 36.86 & 51.83 & 36.90 & 39.07 & 18.26 & 58.58 
& 46.32\\
\addMethod{CoT} & 57.92\tiny\textcolor{red}{+3.56} & 45.44\tiny\textcolor[HTML]{206546}{-5.72} & 41.24\tiny\textcolor[HTML]{206546}{-1.32} & 22.50\tiny\textcolor[HTML]{206546}{-1.30} & 30.80\tiny\textcolor[HTML]{206546}{-11.20} & 
52.73\tiny\textcolor[HTML]{206546}{-4.71} & 34.36\tiny\textcolor[HTML]{206546}{-2.50} & 46.52\tiny\textcolor[HTML]{206546}{-5.31} & 42.57\tiny\textcolor{red}{+5.67} & 36.81\tiny\textcolor[HTML]{206546}{-2.26} & 10.02\tiny\textcolor[HTML]{206546}{-8.24} & 51.82\tiny\textcolor[HTML]{206546}{-6.76} & 
44.89\tiny\textcolor[HTML]{206546}{-1.43} \\

\arrayrulecolor{black!20}\midrule
Qwen2.5$_{\text{32b}}$ & 56.28 & 52.78 & 46.24 & 26.90 & 46.40
& 60.66 & 38.54 & 56.79 & 39.12 & 43.77 & 20.10 & 60.04 & 48.83\\
\addMethod{CoT} & 60.80\tiny\textcolor{red}{+4.52} & 49.32\tiny\textcolor[HTML]{206546}{-3.46} & 45.32\tiny\textcolor[HTML]{206546}{-0.92} & 24.80\tiny\textcolor[HTML]{206546}{-2.10} & 31.20\tiny\textcolor[HTML]{206546}{-15.20} & 
50.67\tiny\textcolor[HTML]{206546}{-9.99} & 40.65\tiny\textcolor{red}{+2.11} & 51.12\tiny\textcolor[HTML]{206546}{-5.67} & 43.40\tiny\textcolor{red}{+4.28} & 40.29\tiny\textcolor[HTML]{206546}{-3.48} & 17.03\tiny\textcolor[HTML]{206546}{-3.07} & 57.12\tiny\textcolor[HTML]{206546}{-2.92} 
& 48.14\tiny\textcolor[HTML]{206546}{-0.69} \\

\arrayrulecolor{black!20}\midrule
Qwen2.5$_{\text{72b}}$ & 58.20 & 48.76 & 46.84 & 31.30 & \underline{60.80} 
& 61.38 & 40.77 & 54.31 & 36.62 & 42.03 & 11.52 & \underline{62.23} & 49.30\\
\addMethod{CoT} & \underline{69.00}\tiny\textcolor{red}{+10.80} & \underline{57.24}\tiny\textcolor{red}{+8.48} & \underline{49.88}\tiny\textcolor{red}{+3.04} & \underline{32.50}\tiny\textcolor{red}{+1.20} & 46.00\tiny\textcolor[HTML]{206546}{-14.80}
& \underline{61.50}\tiny\textcolor{red}{+0.12} & \underline{45.01}\tiny\textcolor{red}{+4.24} & \underline{61.51}\tiny\textcolor{red}{+7.20} & 50.18\tiny\textcolor{red}{+13.56} & \underline{49.86}\tiny\textcolor{red}{+7.83} & \underline{17.53}\tiny\textcolor{red}{+6.01} & 59.85\tiny\textcolor[HTML]{206546}{-2.38} & \underline{55.39}\tiny\textcolor{red}{+6.09} \\

\arrayrulecolor{black!20}\midrule
\rowcolor{mycell}
Deepseek-R1 & \textbf{70.84} & \textbf{67.12} & \textbf{60.64} & \textbf{45.50} & \textbf{72.40}
& \textbf{76.63} & \textbf{58.17} & \textbf{67.30} & \textbf{59.69} & \textbf{61.16} & \textbf{24.37} & \textbf{67.70} & \textbf{64.02}\\

\arrayrulecolor{black}\bottomrule
\end{tabular}
}
\label{tab:qa-results}
\end{table*}

\paragraph{Question-Answering} 
We design the below eight challenging tasks using the Question-Answering format:
\textbf{\textit{(i)}} \textit{Entity-based Dynasty Determination} (\textbf{EDD}): infer the historical dynasty of a given entity based on contextual information.
\textbf{\textit{(ii)}} \textit{Plausibility Judgment} (\textbf{PJ}): assess whether a described historical scenario is plausible by reasoning about temporal and factual consistency.
\textbf{\textit{(iii)}} \textit{Temporal Order Understanding} (\textbf{TOU}): understand and compare the chronological order of historical events or figures.
\textbf{\textit{(iv)}} \textit{Relation Reasoning} (\textbf{RR}): reason about the historical relationships between entities, such as their spatial, temporal, or functional connections.
\textbf{\textit{(v)}} \textit{Script Error Correction} (\textbf{SEC}): identify and correct historical inaccuracies in visual or textual narratives.
\textbf{\textit{(v)}} \textit{Entity Evolution Understanding} (\textbf{EEU}): track and understand the evolution of entity names or attributes across different historical periods.
\textbf{\textit{(vi)}} \textit{Time Interval Calculation} (\textbf{TIC}): calculate the temporal gap between historical entities or events.
\textbf{\textit{(vii)}} \textit{Temporal Entity Selection} (\textbf{TES}): select the correct historical entity based on temporal and contextual constraints.
\textbf{\textit{viii}} \textit{Long Script Error Correction} (\textbf{LSEC}): identify and correct complex historical inaccuracies in long narratives by reasoning across extended contexts.
The key aspect of these task designs is to examine LLM’s ability to accurately \textbf{perceive and reason} about temporal relationships in a structured manner.\footnote{Each task's examples are presented in App.~\ref{app:qa-case}.}


\paragraph{Timeline Ito Game}
Our developed Timeline Ito Game is a collaborative reasoning game where agents infer the chronological order of historical entities within a dynasty timeline using thematic metaphors.
As shown in Figure~\ref{fig:intro}, the rules can be divided into the following steps:
\begin{itemize}
    \item \textbf{Step1: Describe Card}: Agents describe their assigned historical entity using a given theme without explicit temporal references.
    \item \textbf{Step2: Infer Rank}: Agents collaboratively deduce their relative positions in the timeline based on shared contexts.
    \item \textbf{Step3: Determine Order}: Each Agent sequentially predicts their position in the timeline relative to the others, and the team’s final order is based on these individual predictions.
\end{itemize}
The game ends when the team’s predicted order matches the true chronological sequence or when the maximum number of rounds, $K$, is reached.\footnote{We present a running case in App.~\ref{app:ito-case}.}
% If incorrect, a new theme is introduced, and the game continues to the next round.
% We present a running case in Appendix~\ref{app:ito-case} to enhance the understanding of the rules of this game.
% Through the developed rules, we can evaluate the temporal alignment capability of LLMs.

\subsection{Data Collection}
% To make the annotation process cost-efficient and
% accurate, we employ a two-stage funnel annotation
% strategy, combining LLM-based and human annotation. 
% In the first stage, GPT-4o~\citep{},
% performs initial annotations, followed by a second stage, where crowd-sourced human annotators conduct quality control. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.36\textwidth]{figs/sta.pdf}
    \caption{Statistic of CTM.
    }
    \label{fig:sta}
    \vspace{-5mm}
\end{figure}

\paragraph{Source}
We construct a comprehensive entity information repository by collecting diverse data from multiple authoritative sources, \textit{e.g.}, \texttt{Gushiwen}
% \footnote{\url{https://www.gushiwen.cn/}}
, \texttt{CBDB}
% \footnote{\url{https://projects.iq.harvard.edu/chinesecbdb}}
, \texttt{CHGIS}
% \footnote{\url{https://gis.harvard.edu/china-historical-gis}}
, \texttt{Wikipedia}
% \footnote{\url{https://zh.wikipedia.org/wiki/}}
, and 
\texttt{Ihchina}
% \footnote{\url{https://www.ihchina.cn/}}
.
The historical dynasties are simplified into ten major periods based on \texttt{Allhistory} and \texttt{CHINA—Timeline of Historical Periods}, 
specifically: ``先秦'', ``汉'', ``六朝'', ``隋'', ``唐'', ``五代'', ``宋'', ``元'',  ``明', ``清''.
The entity repository contains 1,652 figures (with attributes such as birth address, birth year, death year, and associated books or sentences), 2,907 places (including 990 primary administrative regions and 1,917 subordinate localities), 93 allusions, 49 ingredients, and 44 intangible cultural heritage items.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.38\textwidth]{figs/acc_ito_game.pdf}
    \caption{Average performance of Ito's Guessing Game. Detailed results can be found in Appendix~\ref{app:ito_acc}.
    }
    \label{fig:ito}
    \vspace{-5mm}
\end{figure}

\paragraph{Annotation Process}
The annotation process is structured into three key steps to ensure systematic and high-quality data generation:
\textbf{seed prompt creation}, \textbf{entity-aware data generation}, and \textbf{validation and quality control}.\footnote{The details of each step are provided in the App.~\ref{app:anno}.}
The process systematically generates annotated data while aligning with the repository's structured knowledge.
The statistics of CTM on the task are shown in Figure~\ref{fig:sta}.



\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figs/span_direct.pdf}
    \caption{Accuracy across entity inter-dynastic intervals under direct prompting setting. 
    The detailed results are shown in Figure~\ref{fig:acc_span_cot}, Figure~\ref{fig:line_direct} and Figure~\ref{fig:line_cot}.
    }
    \label{fig:acc_span}
\end{figure*}

\subsection{Evaluation}
We use the \textbf{accuracy} metric to evaluate the QA tasks while \textbf{Pass@$K$} is used to evaluate Ito's Guessing Game.
Due to the varying lengths of LLM-generated
text, it is challenging to perform exact match evaluation.
We use GPT-4o as the evaluator\footnote{The prompt for the evaluator is provided in Appendix~\ref{app:prompt}.}, which determines the correctness of responses by comparing the prediction with the ground truth using the CoT~\cite{wei2022chain}.
Pass@$K$ measures whether the sequential alignment is achieved within $K$ attempts, we set $K$ to 3 and 8.

