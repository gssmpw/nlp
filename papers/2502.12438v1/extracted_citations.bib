@article{CRNN_HSMM,
  title="{Audio-to-score singing transcription based on a CRNN-HSMM hybrid model}",
  author={Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Yoshii, Kazuyoshi},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={10},
  pages={e7},
  year={2021},
  publisher={Cambridge University Press}
}

@inproceedings{adt,
  title={Automatic Drum Transcription Using the Student-Teacher Learning Paradigm with Unlabeled Music Data},
  author={Chih-Wei Wu and Alexander Lerch},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2017},
}

@article{altamt,
  title={Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing},
  author={Gu, Xiangming and Ou, Longshen and Zeng, Wei and Zhang, Jianan and Wong, Nicholas and Wang, Ye},
  journal={ACM Transactions on Multimedia Computing, Communications and Applications},
  volume={20},
  number={7},
  pages={1--29},
  year={2024},
  publisher={ACM New York, NY}
}

@article{av-hubert,
  title={Learning audio-visual speech representation by masked multimodal cluster prediction},
  author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2201.02184},
  year={2022}
}

@article{av-svt,
  title={Deep audio-visual singing voice transcription based on self-supervised learning models},
  author={Gu, Xiangming and Zeng, Wei and Zhang, Jianan and Ou, Longshen and Wang, Ye},
  journal={arXiv preprint arXiv:2304.12082},
  year={2023}
}

@inproceedings{beat_attention,
  title={End-to-end melody note transcription based on a beat-synchronous attention mechanism},
  author={Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Yoshii, Kazuyoshi},
  booktitle={2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  pages={26--30},
  year={2019},
  organization={IEEE}
}

@article{cs2s,
  title={Music transcription with convolutional sequence-to-sequence models},
  author={Ullrich, Karen and van der Wel, Eelco},
  year={2018}
}

@inproceedings{ctc,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@article{ctc_note,
  title={Training a Singing Transcription Model Using Connectionist Temporal Classification Loss and Cross-Entropy Loss},
  author={Wang, Jun-You and Jang, Jyh-Shing Roger},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={383--396},
  year={2022},
  publisher={IEEE}
}

@inproceedings{ctc_score1,
  title="{Audio-to-score singing transcription based on joint estimation of pitches, onsets, and metrical positions with tatum-level CTC loss}",
  author={Deng, Tengyu and Nakamura, Eita and Yoshii, Kazuyoshi},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={583--590},
  year={2023},
  organization={IEEE}
}

@article{ctc_score2,
  title="{End-to-end singing transcription based on CTC and HSMM decoding with a refined score representation}",
  author={Deng, Tengyu and Nakamura, Eita and Nishikimi, Ryo and Yoshii, Kazuyoshi and others},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={13},
  number={5},
  year={2024},
  publisher={Now Publishers, Inc.}
}

@article{jdc,
  title={Joint detection and classification of singing voice melody using convolutional recurrent neural networks},
  author={Kum, Sangeun and Nam, Juhan},
  journal={Applied Sciences},
  volume={9},
  number={7},
  pages={1324},
  year={2019},
  publisher={MDPI}
}

@inproceedings{jdc_note,
  title={Pseudo-label transfer from frame-level to note-level in a teacher-student framework for singing transcription from polyphonic music},
  author={Kum, Sangeun and Lee, Jongpil and Kim, Keunhyoung Luke and Kim, Taehyoung and Nam, Juhan},
  booktitle={2022 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={796--800},
  year={2022},
  organization={IEEE}
}

@article{jong,
  title={Note-level singing melody transcription with transformers},
  author={Park, Jonggwon and Choi, Kyoyun and Oh, Seola and Kim, Leekyung and Park, Jonghun},
  journal={Intelligent Data Analysis},
  volume={27},
  number={6},
  pages={1853--1871},
  year={2023},
  publisher={IOS Press}
}

@article{jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@article{musicyolo,
  title="{MusicYOLO: A vision-based framework for automatic singing transcription}",
  author={Wang, Xianke and Tian, Bowen and Yang, Weiming and Xu, Wei and Cheng, Wenqing},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={229--241},
  year={2022},
  publisher={IEEE}
}

@article{nakamura_rhythm,
  title="{Rhythm transcription of polyphonic piano music based on merged-output HMM for multiple voices}",
  author={Nakamura, Eita and Yoshii, Kazuyoshi and Sagayama, Shigeki},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={4},
  pages={794--806},
  year={2017},
  publisher={IEEE}
}

@inproceedings{notation1,
  title={Towards end-to-end polyphonic music transcription: Transforming music audio directly to a score},
  author={Carvalho, Ralf Gunter Correa and Smaragdis, Paris},
  booktitle={2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  pages={151--155},
  year={2017},
  organization={IEEE}
}

@inproceedings{notation2,
  title={An End-to-end Framework for Audio-to-Score Music Transcription on Monophonic Excerpts},
  author={Miguel A. Rom{\'a}n and A. Pertusa and Jorge Calvo-Zaragoza},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2018},
}

@inproceedings{notation3,
  title={A holistic approach to polyphonic music transcription with neural networks},
  author={Rom{\'a}n, Miguel A and Pertusa, Antonio and Calvo-Zaragoza, Jorge},
  booktitle={Proceedings of the 20th International Society for Music Information Retrieval Conference},
  year={2019}
}

@article{quantization,
  title={Rhythm quantization for transcription},
  author={Cemgil, Ali Taylan and Desain, Peter and Kappen, Bert},
  journal={Computer Music Journal},
  volume={24},
  number={2},
  pages={60--76},
  year={2000},
  publisher={JSTOR}
}

@inproceedings{rosvot,
  title={Robust Singing Voice Transcription Serves Synthesis},
  author={Ruiqi Li and Yu Zhang and Yongqi Wang and Zhiqing Hong and Rongjie Huang and Zhou Zhao},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2024},
  pages={9751--9766},
  publisher = "Association for Computational Linguistics",
}

@phdthesis{s2s_amt,
  title={Automatic music transcription using sequence to sequence learning},
  author={Awiszus, B Sc Maximilian},
  year={2019},
  school={Masterâ€™s thesis, Karlsruhe Institute of Technology}
}

@inproceedings{s2s_asr,
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4960--4964},
  year={2016},
  organization={IEEE}
}

@article{seq2seq,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{spleeter,
  title={Spleeter: a fast and efficient music source separation tool with pre-trained models},
  author={Hennequin, Romain and Khlif, Anis and Voituret, Felix and Moussallam, Manuel},
  journal={Journal of Open Source Software},
  volume={5},
  number={50},
  pages={2154},
  year={2020}
}

@inproceedings{ssl_vocal,
  title={Semi-supervised Learning Using Teacher-student Models for Vocal Melody Extraction},
  author={Keum, Sagneun and Lin, Jing-Hua and Su, Li and Nam, Juhan},
  booktitle={The 21th International Society for Music Information Retrieval Conference (ISMIR)},
  year={2020},
}

@inproceedings{st500,
  title={On the preparation and validation of a large-scale dataset of singing transcription},
  author={Wang, Jun-You and Jang, Jyh-Shing Roger},
  booktitle={2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={276--280},
  year={2021},
  organization={IEEE}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{vat,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE}
}

@inproceedings{vocano,
	title={{VOCANO}: A Note Transcription Framework For Singing Voice In Polyphonic Music},
	author={Hsu, Jui-Yang and Su, Li},
	booktitle={Proc. International Society of Music Information Retrieval Conference (ISMIR)},
	year={2021}
}

@article{wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@inproceedings{weakly_attention,
  title={Automatic singing transcription based on encoder-decoder recurrent neural networks with a weakly-supervised attention mechanism},
  author={Nishikimi, Ryo and Nakamura, Eita and Fukayama, Satoru and Goto, Masataka and Yoshii, Kazuyoshi},
  booktitle={2019 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={161--165},
  year={2019},
  organization={IEEE}
}

