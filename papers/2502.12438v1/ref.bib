@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLdash_repeated_names= "no",
}

@inproceedings{st500,
  title={On the preparation and validation of a large-scale dataset of singing transcription},
  author={Wang, Jun-You and Jang, Jyh-Shing Roger},
  booktitle={2021 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={276--280},
  year={2021},
  organization={IEEE}
}

@inproceedings{ef_net,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{dali,
  title="{DALI: A large dataset of synchronized audio, lyrics and notes, automatically created using teacher-student machine learning paradigm}",
  author={Meseguer-Brocal, Gabriel and Cohen-Hadria, Alice and Peeters, Geoffroy},
  booktitle={19th International Society for Music Information Retrieval Conference},
  year={2018}
}

@inproceedings{hsd,
  title="{HSD: A hierarchical singing annotation dataset}",
  author={Fu, Xiao and Yuan, Xin and Hu, Jinglu},
  booktitle={2022 IEEE International Symposium on Multimedia (ISM)},
  pages={245--246},
  year={2022},
  organization={IEEE}
}

@inproceedings{rwc,
  title="{AIST Annotation for the RWC Music Database.}",
  author={Goto, Masataka and others},
  booktitle={Proceedings of the 7th International Conference on Music Information Retrieval},
  pages={359--360},
  year={2006},
}

@article{musicyolo,
  title="{MusicYOLO: A vision-based framework for automatic singing transcription}",
  author={Wang, Xianke and Tian, Bowen and Yang, Weiming and Xu, Wei and Cheng, Wenqing},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={229--241},
  year={2022},
  publisher={IEEE}
}

@article{yolox,
  title="{YOLOX: Exceeding YOLO series in 2021}",
  author={Ge, Zheng and Liu, Songtao and Wang, Feng and Li, Zeming and Sun, Jian},
  journal={arXiv preprint arXiv:2107.08430},
  year={2021}
}

@inproceedings{pyin,
  title={pYIN: A fundamental frequency estimator using probabilistic threshold distributions},
  author={Mauch, Matthias and Dixon, Simon},
  booktitle={2014 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={659--663},
  year={2014},
  organization={IEEE}
}

@inproceedings{notation1,
  title={Towards end-to-end polyphonic music transcription: Transforming music audio directly to a score},
  author={Carvalho, Ralf Gunter Correa and Smaragdis, Paris},
  booktitle={2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  pages={151--155},
  year={2017},
  organization={IEEE}
}

@inproceedings{notation2,
  title={An End-to-end Framework for Audio-to-Score Music Transcription on Monophonic Excerpts},
  author={Miguel A. Rom{\'a}n and A. Pertusa and Jorge Calvo-Zaragoza},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2018},
}

@inproceedings{notation3,
  title={A holistic approach to polyphonic music transcription with neural networks},
  author={Rom{\'a}n, Miguel A and Pertusa, Antonio and Calvo-Zaragoza, Jorge},
  booktitle={Proceedings of the 20th International Society for Music Information Retrieval Conference},
  year={2019}
}

@inproceedings{beat_attention,
  title={End-to-end melody note transcription based on a beat-synchronous attention mechanism},
  author={Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Yoshii, Kazuyoshi},
  booktitle={2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  pages={26--30},
  year={2019},
  organization={IEEE}
}

@inproceedings{weakly_attention,
  title={Automatic singing transcription based on encoder-decoder recurrent neural networks with a weakly-supervised attention mechanism},
  author={Nishikimi, Ryo and Nakamura, Eita and Fukayama, Satoru and Goto, Masataka and Yoshii, Kazuyoshi},
  booktitle={2019 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={161--165},
  year={2019},
  organization={IEEE}
}

@article{quantization,
  title={Rhythm quantization for transcription},
  author={Cemgil, Ali Taylan and Desain, Peter and Kappen, Bert},
  journal={Computer Music Journal},
  volume={24},
  number={2},
  pages={60--76},
  year={2000},
  publisher={JSTOR}
}

@inproceedings{midi_to_score,
  title={A parse-based framework for coupled rhythm quantization and score structuring},
  author={Foscarin, Francesco and Jacquemard, Florent and Rigaux, Philippe and Sakai, Masahiko},
  booktitle={Mathematics and Computation in Music: 7th International Conference, MCM 2019, Madrid, Spain, June 18--21, 2019, Proceedings 7},
  pages={248--260},
  year={2019},
  organization={Springer}
}

@article{ismir2014,
  title={Evaluation framework for automatic singing transcription},
  author={Molina, Emilio and Barbancho-Perez, Ana Maria and Tardon-Garcia, Lorenzo Jose and Barbancho-Perez, Isabel and others},
  year={2014}
}

@article{overview,
  title={Automatic music transcription: An overview},
  author={Benetos, Emmanouil and Dixon, Simon and Duan, Zhiyao and Ewert, Sebastian},
  journal={IEEE Signal Processing Magazine},
  volume={36},
  number={1},
  pages={20--30},
  year={2018},
  publisher={IEEE}
}

@inproceedings{cycliclr,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={2017 IEEE winter conference on applications of computer vision (WACV)},
  pages={464--472},
  year={2017},
  organization={IEEE}
}

@article{omnizart,
  title={Omnizart: A general toolbox for automatic music transcription},
  author={Wu, Yu-Te and Luo, Yin-Jyun and Chen, Tsung-Ping and Wei, I and Hsu, Jui-Yang and Chuang, Yi-Chin and Su, Li and others},
  journal={arXiv preprint arXiv:2106.00497},
  year={2021}
}

@inproceedings{patch_cnn,
  title={Vocal melody extraction using patch-based CNN},
  author={Su, Li},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={371--375},
  year={2018},
  organization={IEEE}
}

@inproceedings{vocano,
	title={{VOCANO}: A Note Transcription Framework For Singing Voice In Polyphonic Music},
	author={Hsu, Jui-Yang and Su, Li},
	booktitle={Proc. International Society of Music Information Retrieval Conference (ISMIR)},
	year={2021}
}

@article{shakedrop,
  title={Shakedrop regularization for deep residual learning},
  author={Yamada, Yoshihiro and Iwamura, Masakazu and Akiba, Takuya and Kise, Koichi},
  journal={IEEE Access},
  volume={7},
  pages={186126--186136},
  year={2019},
  publisher={IEEE}
}

@inproceedings{pyramid,
  title={Deep pyramidal residual networks},
  author={Han, Dongyoon and Kim, Jiwhan and Kim, Junmo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5927--5935},
  year={2017}
}

@article{vat,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE}
}

@inproceedings{reconvat,
  title="{ReconVAT: A semi-supervised automatic music transcription framework for low-resource real-world data}",
  author={Cheuk, Kin Wai and Herremans, Dorien and Su, Li},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={3918--3926},
  year={2021}
}

@article{ctc_note,
  title={Training a Singing Transcription Model Using Connectionist Temporal Classification Loss and Cross-Entropy Loss},
  author={Wang, Jun-You and Jang, Jyh-Shing Roger},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={383--396},
  year={2022},
  publisher={IEEE}
}

@inproceedings{ssl_vocal,
  title={Semi-supervised Learning Using Teacher-student Models for Vocal Melody Extraction},
  author={Keum, Sagneun and Lin, Jing-Hua and Su, Li and Nam, Juhan},
  booktitle={The 21th International Society for Music Information Retrieval Conference (ISMIR)},
  year={2020},
}

@inproceedings{adt,
  title={Automatic Drum Transcription Using the Student-Teacher Learning Paradigm with Unlabeled Music Data},
  author={Chih-Wei Wu and Alexander Lerch},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2017},
}

@article{jdc,
  title={Joint detection and classification of singing voice melody using convolutional recurrent neural networks},
  author={Kum, Sangeun and Nam, Juhan},
  journal={Applied Sciences},
  volume={9},
  number={7},
  pages={1324},
  year={2019},
  publisher={MDPI}
}

@article{jukebox,
  title={Jukebox: A generative model for music},
  author={Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2005.00341},
  year={2020}
}

@misc{sheetsage,
  author       = {Donahue, Chris and Liang, Percy},
title="{Sheet Sage: Lead sheets from music audio}",
  note = {{L}ate Breaking Demo in the 22nd International Society for Music Information Retrieval Conference, {ISMIR}},
  year      = {2021},
}

@article{melody_jukebox,
  title={Melody transcription via generative pre-training},
  author={Donahue, Chris and Thickstun, John and Liang, Percy},
  journal={arXiv preprint arXiv:2212.01884},
  year={2022}
}

@article{castellon,
  title={Codified audio language modeling learns useful representations for music information retrieval},
  author={Castellon, Rodrigo and Donahue, Chris and Liang, Percy},
  journal={arXiv preprint arXiv:2107.05677},
  year={2021}
}


@inproceedings{jdc_note,
  title={Pseudo-label transfer from frame-level to note-level in a teacher-student framework for singing transcription from polyphonic music},
  author={Kum, Sangeun and Lee, Jongpil and Kim, Keunhyoung Luke and Kim, Taehyoung and Nam, Juhan},
  booktitle={2022 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={796--800},
  year={2022},
  organization={IEEE}
}

@inproceedings{mir_eval,
  title="{mir\_eval: A transparent implementation of common MIR metrics.}",
  author={Raffel, Colin and McFee, Brian and Humphrey, Eric J and Salamon, Justin and Nieto, Oriol and Liang, Dawen and Ellis, Daniel PW and Raffel, C Colin},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2014}
}

@inproceedings{phoneme,
  title={A Phoneme-Informed Neural Network Model For Note-Level Singing Transcription},
  author={Yong, Sangeon and Su, Li and Nam, Juhan},
  booktitle={2023 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}


@inproceedings{s2s_piano,
  title={Sequence-to-Sequence Piano Transcription with Transformers},
  author={Curtis Hawthorne and Ian Simon and Rigel Swavely and Ethan Manilow and Jesse Engel},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2021}
}

@inproceedings{mt3,
  title="{MT3: Multi-task multitrack music transcription}",
  author={Gardner, Joshua P and Simon, Ian and Manilow, Ethan and Hawthorne, Curtis and Engel, Jesse},
  booktitle={International Conference on Learning Representations},
  year={2021} 
}

@article{seq2seq,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{s2s_asr,
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4960--4964},
  year={2016},
  organization={IEEE}
}

@article{s2s_mt,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}

@phdthesis{s2s_amt,
  title={Automatic music transcription using sequence to sequence learning},
  author={Awiszus, B Sc Maximilian},
  year={2019},
  school={Master’s thesis, Karlsruhe Institute of Technology}
}

@article{cs2s,
  title={Music transcription with convolutional sequence-to-sequence models},
  author={Ullrich, Karen and van der Wel, Eelco},
  year={2018}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{aug_audio,
  title={Deep convolutional neural networks and data augmentation for environmental sound classification},
  author={Salamon, Justin and Bello, Juan Pablo},
  journal={IEEE Signal processing letters},
  volume={24},
  number={3},
  pages={279--283},
  year={2017},
  publisher={IEEE}
}

@inproceedings{aug_music,
  title={Exploring data augmentation to improve music genre classification with convnets},
  author={Aguiar, Rafael L and Costa, Yandre MG and Silla, Carlos N},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}

@article{spleeter,
  title={Spleeter: a fast and efficient music source separation tool with pre-trained models},
  author={Hennequin, Romain and Khlif, Anis and Voituret, Felix and Moussallam, Manuel},
  journal={Journal of Open Source Software},
  volume={5},
  number={50},
  pages={2154},
  year={2020}
}

@article{demucs,
  title={Music source separation in the waveform domain},
  author={D{\'e}fossez, Alexandre and Usunier, Nicolas and Bottou, L{\'e}on and Bach, Francis},
  journal={arXiv preprint arXiv:1911.13254},
  year={2019}
}

@inproceedings{integrating,
  title={Towards complete polyphonic music transcription: Integrating multi-pitch detection and rhythm quantization},
  author={Nakamura, Eita and Benetos, Emmanouil and Yoshii, Kazuyoshi and Dixon, Simon},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={101--105},
  year={2018},
  organization={IEEE}
}

@article{CRNN_HSMM,
  title="{Audio-to-score singing transcription based on a CRNN-HSMM hybrid model}",
  author={Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Yoshii, Kazuyoshi},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={10},
  pages={e7},
  year={2021},
  publisher={Cambridge University Press}
}

@inproceedings{madmom_python,
  title="{madmom: A new Python audio and music signal processing library}",
  author={B{\"o}ck, Sebastian and Korzeniowski, Filip and Schl{\"u}ter, Jan and Krebs, Florian and Widmer, Gerhard},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={1174--1178},
  year={2016}
}

@inproceedings{madmom_model,
  title={Joint Beat and Downbeat Tracking with Recurrent Neural Networks},
  author={Sebastian B{\"o}ck and Florian Krebs and Gerhard Widmer},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2016},
}

@inproceedings{beat-transformer,
  title={Beat Transformer: Demixed Beat and Downbeat Tracking with Dilated Self-Attention},
  author={Zhao, Jingwei and Xia, Gus and Wang, Ye},
  booktitle={Proc. International Society of Music Information Retrieval Conference (ISMIR)},
  year={2022}
}

@inproceedings{lilypond,
  title={LilyPond, a system for automated music engraving},
  author={Nienhuys, Han-Wen and Nieuwenhuizen, Jan},
  booktitle={Proceedings of the XIV Colloquium on Musical Informatics (XIV CIM 2003)},
  volume={1},
  pages={167--171},
  year={2003},
  organization={Citeseer}
}


@article{jong,
  title={Note-level singing melody transcription with transformers},
  author={Park, Jonggwon and Choi, Kyoyun and Oh, Seola and Kim, Leekyung and Park, Jonghun},
  journal={Intelligent Data Analysis},
  volume={27},
  number={6},
  pages={1853--1871},
  year={2023},
  publisher={IOS Press}
}


@inproceedings{old_notation,
  title={Automatic Generation of Lead Sheets from Polyphonic Music Signals.},
  author={Weil, Jan and Sikora, Thomas and Durrieu, Jean-Louis and Richard, Ga{\"e}l},
  booktitle={ISMIR},
  pages={603--608},
  year={2009}
}

@article{benetos2015,
  title={An efficient temporally-constrained probabilistic model for multiple-instrument music transcription},
  author={Benetos, Emmanouil and Weyde, Tillman and others},
  year={2015},
  publisher={International Society for Music Information Retrieval}
}

@article{nakamura_rhythm,
  title="{Rhythm transcription of polyphonic piano music based on merged-output HMM for multiple voices}",
  author={Nakamura, Eita and Yoshii, Kazuyoshi and Sagayama, Shigeki},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={4},
  pages={794--806},
  year={2017},
  publisher={IEEE}
}

@inproceedings{ctc,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@incollection{kern,
  title={Humdrum and Kern: Selective feature encoding},
  author={Huron, David},
  booktitle={Beyond MIDI: The handbook of musical codes},
  pages={375--401},
  year={1997}
}

@article{mcnab1995,
  title={Signal processing for melody transcription},
  author={McNab, Rodger J and Smith, Lloyd A and Witten, Ian H},
  year={1995},
  publisher={University of Waikato, Department of Computer Science}
}

@inproceedings{auditory_transcription,
  title={An Auditory Model Based Transcriber of Singing Sequences.},
  author={Clarisse, LP and Martens, Jean-Pierre and Lesaffre, Micheline and De Baets, Bernard and De Meyer, Hans E and Leman, Marc},
  booktitle={ISMIR},
  year={2002}
}

@article{auditory_model,
  title={On the importance of time-a temporal representation of sound},
  author={Slaney, Malcolm and Lyon, Richard F},
  journal={Visual representations of speech signals},
  volume={95116},
  year={1993},
  publisher={Citeseer}
}

@inproceedings{ryyn,
  title={Transcription of the Singing Melody in Polyphonic Music.},
  author={Ryyn{\"a}nen, Matti and Klapuri, Anssi},
  booktitle={ISMIR},
  pages={222--227},
  year={2006}
}

@article{tonas,
  title={Towards computer-assisted flamenco transcription: An experimental comparison of automatic transcription algorithms as applied to a cappella singing},
  author={G{\'o}mez, Emilia and Bonada, Jordi},
  journal={Computer Music Journal},
  volume={37},
  number={2},
  pages={73--90},
  year={2013},
  publisher={MIT Press}
}

@inproceedings{note_dnn,
  title={Singing Voice Melody Transcription Using Deep Neural Networks.},
  author={Rigaud, Fran{\c{c}}ois and Radenen, Mathieu},
  booktitle={ISMIR},
  pages={737--743},
  year={2016}
}

@article{nlp_token,
  title={Unified language model pre-training for natural language understanding and generation},
  author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun and others},
  booktitle={Workshop on challenges in representation learning, ICML},
  volume={3},
  number={2},
  pages={896},
  year={2013},
  organization={Atlanta}
}

@article{musicxml,
  title="{MusicXML for notation and analysis}",
  author={Good, Michael},
  journal={The virtual score: representation, retrieval, restoration},
  volume={12},
  number={113--124},
  pages={160},
  year={2001},
  publisher={MIT Press, Cambridge, MA}
}

@misc{musescore,
	author = {},
	title = "{MuseScore 4.1.1}",
	howpublished = {\url{https://musescore.org/}},
	note = {[Accessed 16-11-2023]},
}

@misc{anthemscore,
	author = {Lunaverus},
	title = "{AnthemScore 4.17.4}",
	howpublished = {\url{https://www.lunaverus.com}},
	note = {[Accessed 16-11-2023]},
}

@inproceedings{a2s-eu,
  title="{Learning frame similarity using Siamese networks for audio-to-score alignment}",
  author={Agrawal, Ruchit and Dixon, Simon},
  booktitle={2020 28th European Signal Processing Conference (EUSIPCO)},
  pages={141--145},
  year={2021},
  organization={IEEE}
}

@inproceedings{a2s-ie,
  title={Audio-to-score alignment using deep automatic music transcription},
  author={Simonetta, Federico and Ntalampiras, Stavros and Avanzini, Federico},
  booktitle={2021 IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@inproceedings{eval_prf,
  title="{Evaluation of multiple-F0 estimation and tracking systems.}",
  author={Bay, Mert and Ehmann, Andreas F and Downie, J Stephen},
  booktitle={10th International Society for Music Information Retrieval Conference, ISMIR 2009},
  pages={315--320},
  year={2009}
}

@book{f0,
  title={Music in theory and practice vol. 2},
  author={Benward, Bruce},
  year={2018},
  publisher={London, United States: McGraw Hill Higher Education}
}

@article{klapuri,
  title={Signal processing methods for music transcription},
  author={Klapuri, Anssi and Davy, Manuel},
  year={2007},
  publisher={Springer Science \& Business Media}
}

@article{f0_eval,
  title={Melody transcription from music audio: Approaches and evaluation},
  author={Poliner, Graham E and Ellis, Daniel PW and Ehmann, Andreas F and G{\'o}mez, Emilia and Streich, Sebastian and Ong, Beesuan},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={15},
  number={4},
  pages={1247--1256},
  year={2007},
  publisher={IEEE}
}

@inproceedings{leven,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle={Soviet physics doklady},
  volume={10},
  number={8},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}

@inproceedings{ctc_score1,
  title="{Audio-to-score singing transcription based on joint estimation of pitches, onsets, and metrical positions with tatum-level CTC loss}",
  author={Deng, Tengyu and Nakamura, Eita and Yoshii, Kazuyoshi},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={583--590},
  year={2023},
  organization={IEEE}
}

@article{ctc_score2,
  title="{End-to-end singing transcription based on CTC and HSMM decoding with a refined score representation}",
  author={Deng, Tengyu and Nakamura, Eita and Nishikimi, Ryo and Yoshii, Kazuyoshi and others},
  journal={APSIPA Transactions on Signal and Information Processing},
  volume={13},
  number={5},
  year={2024},
  publisher={Now Publishers, Inc.}
}

@inproceedings{rosvot,
  title={Robust Singing Voice Transcription Serves Synthesis},
  author={Ruiqi Li and Yu Zhang and Yongqi Wang and Zhiqing Hong and Rongjie Huang and Zhou Zhao},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2024},
  pages={9751--9766},
  publisher = "Association for Computational Linguistics",
}

@article{altamt,
  title={Automatic Lyric Transcription and Automatic Music Transcription from Multimodal Singing},
  author={Gu, Xiangming and Ou, Longshen and Zeng, Wei and Zhang, Jianan and Wong, Nicholas and Wang, Ye},
  journal={ACM Transactions on Multimedia Computing, Communications and Applications},
  volume={20},
  number={7},
  pages={1--29},
  year={2024},
  publisher={ACM New York, NY}
}

@article{av-svt,
  title={Deep audio-visual singing voice transcription based on self-supervised learning models},
  author={Gu, Xiangming and Zeng, Wei and Zhang, Jianan and Ou, Longshen and Wang, Ye},
  journal={arXiv preprint arXiv:2304.12082},
  year={2023}
}

@article{av-hubert,
  title={Learning audio-visual speech representation by masked multimodal cluster prediction},
  author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2201.02184},
  year={2022}
}

@article{wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}