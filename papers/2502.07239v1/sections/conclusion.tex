\section{Conclusion}
\label{sec:conclusion}

\vspace{-0.2cm}

We present \textbf{Contextual Gesture}, a framework for generating realistic co-speech gesture videos.
To ensure the gestures cohere well with speech, we propose speech-content aware gesture motion representation though knowledge distillation from the gesture-speech aligned features.
%
Our structural-aware image generation module improves the transformation of latent motions into realistic animations for large-scale body motions.
%
We hope this work encourage further exploration of the relationship between gesture patterns and speech context for more compelling gesture video generations in the future.



\section{Impact Statements}
\vspace{-0.2cm}
This work focuses on generating co-speech gesture videos, highlighting both its potential and ethical concerns, particularly the risk of misuse for creating deepfakes or fabricated events involving public figures. While itâ€™s impossible to fully eliminate such risks, the research provides a technical analysis of gesture video synthesis, emphasizing its capabilities and limitations. To mitigate misuse, we recommend practices like watermarking videos and using detection tools for synthetic content to promote responsible and ethical use of the technology.



