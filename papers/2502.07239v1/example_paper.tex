%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2024}


% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}




\usepackage{hyperref}
\usepackage{url}
\usepackage[capitalize]{cleveref}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{amsmath,amssymb,amsfonts,amsthm,dsfont,pifont,bm,bbm,mathrsfs,mathtools,nicefrac}
\usepackage{wrapfig}



\input{notation}

% \setlength{\abovedisplayskip}{20pt} % space above the equation
% \setlength{\belowdisplayskip}{20pt} % space below the equation

\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\andy}[1]{\textcolor{magenta}{Andy: #1}}
\newcommand{\pablo}[1]{\textcolor{blue}{Pablo: #1}}
\newcommand{\kyle}[1]{\textcolor{purple}{Kyle: #1}}
\newcommand{\hk}[1]{\textcolor{green}{HK: #1}}
\newcommand{\ari}[1]{\textcolor{orange}{Ari: #1}}

\newcommand{\red}[1]{\textcolor{red}{#1}}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\newcommand{\numColumns}{3}
\newcommand{\columnSpacing}{0.25em}


\def\hlinew#1{%
  \noalign{\ifnum0=`}\fi\hrule \@height #1 \futurelet
   \reserved@a\@xhline}


\usepackage{colortbl}

\definecolor{gtgray}{gray}{0.97}
\definecolor{mygray}{gray}{.88}

\definecolor{gray1}{gray}{.90}
\definecolor{gray2}{gray}{.92}
\definecolor{gray3}{gray}{.94}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{}

\begin{document}




\twocolumn[
\icmltitle{Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation}


\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Pinxin Liu}{sch1}
\icmlauthor{Pengfei Zhang}{sch2}
\icmlauthor{Hyeongwoo Kim}{sch3}
\icmlauthor{Pablo Garrido}{comp}
\icmlauthor{Ari Sharpio}{comp}
\icmlauthor{Kyle Olszewski}{comp}

\end{icmlauthorlist}

\icmlaffiliation{sch1}{University of Rochester, USA}
\icmlaffiliation{sch2}{University of California Irvine, USA}
\icmlaffiliation{sch3}{ Imperial College, London, UK}
\icmlaffiliation{comp}{Flaswless AI, USA}

% \icmlcorrespondingauthor{Pinxin Liu}{pliu23@u.rochester.edu}
\icmlcorrespondingauthor{Kyle Olszewski}{kyle.olszewski@flawlessai.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in



{\renewcommand\twocolumn[1][]{#1}%
\begin{center}
    \vspace{-1.7em}
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=0.9\textwidth]{figs/teaser-icml.pdf}
    \vspace{-0.8em}
    \captionof{figure}{Contextual Gesture achieves various fine-grained control over video-level gesture motion. \textbf{Left}: We can generate 30s to 1 min speech conditioned gesture videos. \textbf{Mid}: We modify the gestures for intermediate frames of a video by providing a new audio segment. \textbf{Right}: Different people present the same gesture patterns for a given audio.}
    \label{fig:intro}
    \vspace{0.3em}
\end{center}}

]

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{} % otherwise use the standard text.



\begin{abstract}
Co-speech gesture generation is crucial for creating lifelike avatars and enhancing human-computer interactions by synchronizing gestures with speech. Despite recent advancements, existing methods struggle with accurately identifying the rhythmic or semantic triggers from audio for generating contextualized gesture patterns and achieving pixel-level realism. To address these challenges, we introduce Contextual Gesture, a framework that improves co-speech gesture video generation through three innovative components: (1) a chronological speech-gesture alignment that temporally connects two modalities, (2) a contextualized gesture tokenization that incorporate speech context into motion pattern representation through distillation, and (3) a structure-aware refinement module that employs edge connection to link gesture keypoints to improve video generation. Our extensive experiments demonstrate that Contextual Gesture not only produces realistic and speech-aligned gesture videos but also supports long-sequence generation and video gesture editing applications, shown in Fig.~\ref{fig:intro} Project Page: {\small\url{https://andypinxinliu.github.io/Contextual-Gesture/}}.
\end{abstract}

\input{sections/introduction.tex}

\input{sections/related_works.tex}

\input{sections/method.tex}

\input{sections/experiment.tex}
        
\input{sections/conclusion.tex}



\bibliography{example_paper}
\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\input{sections/appendix.tex}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
