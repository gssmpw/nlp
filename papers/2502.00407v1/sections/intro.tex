% !TEX root =  ../main.tex


\section{Introduction}\label{sec:intro}
\begin{figure}[t]
    \centering
    \scalebox{.9}{
    \begin{tcolorbox}[
    colback=white,
    colframe=black,
    boxrule=0.8pt,
    before=\par\smallskip\centering,
    after=\par\smallskip,
]
\textbf{The Semantic Embedding Principle (SEP)}
\\[1ex]
\textit{
%Causal Abstractions must preserve the causal knowledge of the high-level model when embedded in the low-level, ensuring perfect knowledge reconstruction from the high-level viewpoint.
Causal Abstractions must preserve high-level causal knowledge when embedded in the low-level.
}
\end{tcolorbox}
}
    \begin{tikzpicture}[scale=.9]
% Manifold ll
\draw[smooth cycle, tension=0.4, fill=mypurple, opacity=0.1] 
    plot coordinates{(2,1.0) (-2.5,-0.3) (2,-1.5) (6,0.3)}; 

\draw[smooth cycle, fill=mypurple, opacity=0.3]
    plot coordinates {(4.2, -0.3) (3.7, 0.6) (2.5, 0.9) (1.7, 0.6) (1.0, 0.6) (1.0, -0.3) (1.6, -0.6) (2.2, -0.8)};

\draw[smooth cycle, fill=mypurple, opacity=.5] 
    plot coordinates {(3.5, 0.0) (3.2, 0.4) (2.0, 0.5) (1.6, 0.3) (1.6, 0.0) (2.0, -0.4) (3.0, -0.5)};

\node[black] at (5.2,0.2) {\textbf{\large $\reall^\ell$}};
% Bold text brought to the front
\node[black] at (2.5,0.1) {\textbf{\large $\varphi^{\V^\top}_{\#}(\chi^h)$}};
\node[black] at (3.9,-0.1) {\textbf{\large $\chi^\ell$}};


% Manifold M'
\draw[smooth cycle, tension=0.4, fill=cyan, opacity=0.1]
    plot coordinates{(2,-2.5) (-1.5,-4) (3.5,-5) (5,-3)}; 

\draw[smooth cycle, fill=cyan, opacity=0.5]
    plot coordinates {(-0.7,-4.0) (-0.2,-3.3) (0.5,-3.2) (1.1,-3.9) (0.8,-4.3)}; 

\draw[smooth cycle, fill=cyan, opacity=0.5]
    plot coordinates {(4,-4.5) (4.5,-3.5) (4,-3.2) (2.5,-3.2) (2,-3.7) (2.2,-4.2)};

\node[black] at (4.7,-3.1) {\textbf{\large $\reall^h$}};
\node[black] at (0.2,-3.7) {\textbf{\large $\chi^h$}};
\node[black] at (3.3,-3.8) {\textbf{\large $\varphi^{\V \circ \V^\top}_{\#}(\chi^h)$}};


% Replace Stiefel Manifold with the Paraboloid
\begin{axis}[
    at={(-2.3cm,-2.9cm)},       % Adjust position
    width=5.5cm,                % Set width
    height=3.5cm,               % Set height
    view={45}{30},              % Adjust viewing angle
    hide axis,                  % Hide axes for a clean look
]

% Plot a solid-coloured inverted paraboloid
\addplot3[
    surf,                       % Use surf for the 3D surface
    domain=-2:2,                % Domain for x-axis
    domain y=-2:2,              % Domain for y-axis
    samples=10,                 % Resolution for smoothness
    shader=flat,                % Disable gradients
    draw=none,                  % Disable gridlines and wireframe
    fill=orange,              % Solid fill colour
    opacity=0.3,                % Transparency
]
{-0.1*(x^2 + y^2)};             % Paraboloid equation

\end{axis}

%Label for Stiefel Manifold
\node[black] at (-1.6,-2.6) {$\text{St}(\ell,h)$};
\node[black] at (-.34,-1.15) {\large \textcolor{red}{\V}};
\node[black] at (-.34,-1.47) {\large \textcolor{red}{\textbullet}};

%to[bend left=10] node[midway, above=4mm] 

\draw[->, draw=teal, dotted, line width=1pt] (3.5,-0.2) to[bend left=25] node[midway, right]{{\large $\V^\top$} $\in \reall^{h \times \ell}$} (3.5,-3.3);

\draw[->, draw=olive, dotted, line width=1pt] (0.2,-4.0) to[bend right=55] node[midway, above]{$\mathrm{Id}_{\chi^h}$} (3.0,-4.1);

\draw[-, draw=teal, dotted, line width=1pt] (0.0,-3.6)  to[bend left=15] node[midway, left]{} (-0.3,-2.4);

\draw[->, draw=teal, dotted, line width=1pt] (-0.2,-1.4)  to[bend left=25] node[midway, left]{} (1.6,0.0);

\end{tikzpicture}
    \caption{
    %Illustration of the semantic embedding principle for linear causal abstractions.
    Pictorial representation of SEP for linear CA.
    A linear map \V belonging to the Stiefel manifold embeds a high-level causal knowledge \measurehigh into a low-level one, viz. \measurelow, identifying an embedded causal knowledge $\varphi_{\#}^{\V^\top}(\chi^h)$.
    % Then, a linear CA $\V^\top$ abstracts \measurelow, yielding only the projection $\varphi_{\#}^{\V \circ \V^\top}(\chi^h)$ of the embedded causal knowledge identical to \measurehigh.
    Then, a linear CA $\V^\top$ abstracts $\varphi_{\#}^{\V^\top}(\chi^h)$, yielding a causal knowledge identical to \measurehigh.
    % In linear CA, $\V^\top$ must belong to the Stiefel manifold $\stiefel{\ell}{h}$. This means that embedding a high-level distribution $\chi^h$ into $\mathbb{R}^\ell$ via $\V$, and then abstracting back into $\mathbb{R}^h$ via $\V^\top$ preserves all the information. In other words, composing $\V \circ \V^\top$ and taking the pushforward $\varphi^{\V \circ \V^\top}(\chi^\ell)$ returns a distribution identical to $\chi^\ell$. 
    Notice that the arrow $\mathrm{Id}_{\chi^h}$ underlines that commutativity holds only in one direction, that is, SEP does not imply $\varphi^{\V^\top \circ \V}(\chi^\ell) = \chi^\ell$.
    }
    \label{fig:fig1}
\end{figure}

%Motivation
\emph{Causal modeling and reasoning} are key to trustworthy and responsible AI \cite{ganguly2023review,rawal2024causality,qi2024causal}. 
\emph{Structural causal models} (SCMs) provide a widely adopted framework for causal reasoning \cite{pearl2009causality}. While canonical causal theory focuses on a single SCM, scientific research often requires multiple representations of the same system at different levels of resolution. 
For example, biological processes can be studied at the molecular level (e.g., gene expression), cellular level (e.g., metabolic pathways), or organism level (e.g., physiological responses), each offering a different view 
%yet interconnected abstraction 
of the same underlying system. \emph{Causal abstraction} (CA) theory \cite{rubenstein2017causal,beckers2019abstracting} formalizes mappings between SCMs at different abstraction levels, enforcing rigorous \emph{consistency} requirements.
This makes CA a powerful tool for transitioning between resolutions, synthesizing causal evidence, and selecting the most parsimonious representation for a given task.
However, CAs are unknown in practice, underscoring the need for advancing CA learning from data \cite{zennaro2023jointly}.

\spara{Related works.}
Seminal works on CA have focused on defining and assessing given CA maps \cite{rubenstein2017causal,beckers2019abstracting}. 
Our approach builds on the \abst-abstraction category-theoretic framework introduced by \cite{rischel2020category}, which neatly 
%As we will demonstrate, the \abst-abstraction is well-suited to our context, as it 
separates the structural and functional components of the CA. From a learning perspective, several methods have been proposed which rely on restrictive assumptions.
\black{In our work, we transform them into \emph{non-assumptions} (NA).}
\cite{zennaro2023jointly} addresses the learning problem under \hypertarget{NA1}{(NA1)} complete specification of SCMs, which, in reality, is rarely available. 
\cite{felekis2024causal} assumes \hypertarget{(NA2)}{(NA2)} knowledge of causal DAGs, which are often unknown in many applications.
\cite{dyer2024a} relies on the \hypertarget{NA3}{(NA3)} availability of interventional data, which may be infeasible or unethical to obtain.
\cite{kekic2023targeted,massidda2024learningcausalabstractionslinear} make 
\hypertarget{(NA4)}{(NA4)} functional assumptions on the SCMs, such as linearity. \cite{massidda2024learningcausalabstractionslinear} implicitly assumes \hypertarget{(NA5)}{(NA5)} alignment between data generated by two models, which requires tight coordination in sample collection. \black{Conversely,} we work under the realistic and pragmatic assumption that \hypertarget{(A1)}{(A1)} \emph{at least partial prior knowledge of the structure of a CA is available}.
\hyperlink{(A1)}{(A1)} is met in different application domains, such as neuroscience.
For instance, consider the learning of a CA between two brain SCMs, the first referring to some brain region of interest (ROIs), the second to the brain lobes.
A map between ROIs and brain lobes is implicitly defined by the location of ROIs, and so it would be natural to try to exploit such prior knowledge when learning the CA.
\black{Finally, we build on top of different continuous optimization frameworks, working in both the Euclidean and Riemannian spaces.
Specifically, when dealing with a nonsmooth Riemannian problem, we leverage the \emph{manifold alternating direction method of multipliers} (MADMM, \citealp{kovnatsky2016madmm}) and the \emph{manifold proximal gradient} (ManPG, \citealp{chen2020}).
They are the Riemannian counterparts of the ADMM \cite{boyd2011distributed} and PG \cite{parikh2014proximal}.
Additionally, when dealing with a smooth, constrained, Riemannian problem, our solution combines the \emph{splitting of ortogonality constraints} (SOC, \citealp{lai2014splitting}), the ADMM, and the \emph{successive convex approximation} (SCA, \citealp{nedic2018parallel}) methods.}

\spara{Contributions.} \emph{First}, we introduce the \emph{semantic embedding principle} (SEP) for CA, informally stating that in a well-behaved CA, embedding the high-level (coarser) causal knowledge into the low-level (finer) one and then abstracting it back enables perfect reconstruction of the high-level causal knowledge.
\emph{Second}, to formalize SEP categorically, we present an alternative category-theoretic framework for CA, which allows us to focus on the semantic layer of an SCM. 
%Accordingly, we reinterpret the \abst-abstraction within our mathematical framework.
\emph{Third}, we formulate a general CA learning problem based on SEP and \hyperlink{(A1)}{(A1)}.
\emph{Fourth}, we tackle the linear CA case, showing that SEP naturally links the linear CA to the geometry of the Stiefel manifold, shaping the learning process as a Riemannian optimization problem.
As an application, we consider the Gaussian setting with the Kullback-Liebler (KL) divergence as a measure of alignment between
the low- and high-level SCMs.
\emph{Fifth}, we formalize and solve nonsmooth and smooth learning problems for linear CAs in this setting. For the former, we present the LinSEPAL-ADMM and LinSEPAL-PG methods; for the latter, the CLinSEPAL one.
Our experiments on synthetic and brain data, across different levels of prior knowledge, confirm good performance of the proposed methods.

\emph{Our work is a first step to bridging the gap between CA learning methods and real-world applications.}