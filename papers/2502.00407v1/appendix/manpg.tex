% !TEX root =  ../main.tex
\section{LinSEPAL-PG}\label{app:ManPG}
This method is based upon the \text{manifold proximal gradient} \citeSupp{chen2020Supp} framework, which generalizes the \emph{proximal gradient} framework defined in the Euclidean space to the Stiefel manifold.
Following \citeSupp{chen2020Supp}, denoting by $\V^k$ the iterate at the step $k$, the updates recursion for solving \eqref{eq:minKL} reads as
\begin{equation}\label{eq:ManPG_app}
    \begin{aligned}
        \G^k &= \argmin_{\G \in \tangentspace{\V^k}{\stiefel{\ell}{h}}} \quad \Eprod{\Egrad{}{f\left(\V^k\right)}}{\G}{} + \frac{1}{2\rho} \frob{\G}^2 + \lambda \norm{\D \odot \left(\V^k + \G\right)}_1 \, ,\\
        \V^{k+1} &= \Retr{}{\V^k}{\G^k} \,.
    \end{aligned}
    \tag{R2}
\end{equation}
In \eqref{eq:ManPG_app}, the first update is the proximal mapping providing a proximal gradient direction $\G^k$ onto the tangent space to the Stiefel manifold, using the first-order approximation of the objective around the $k$-th estimate.
The second is the update for $\V^{k+1}$, which exploits the canonical retraction (cf. \cref{eq:stiefel_retractions}) technique for projecting back $\V^k + \G^k$ from the tangent space to the manifold.
Global convergence of the ManPG method has been established in \citeSupp{chen2020Supp}.

\spara{Solution for $\G^k$.}
\citet{chen2020} shows that the first update can be efficiently solved using the regularized semi-smooth Newton method in \citeSupp{xiao2018regularizedSupp}.
Specifically, according to \Cref{eq:Stiefel_t_space}, the feasible set $\tangentspace{\V^k}{\stiefel{\ell}{h}}$ translates into a linear constraint.
By defining $\linearop{\mathcal{A}^k}{\G} \coloneqq \G^\top \V^k + \V^{k^\top} \G$, the update is
\begin{equation}\label{eq:ManPGU1}
    \begin{aligned}
        \G^k = \argmin_{\G \in \reall^{\ell \times h}} &\quad \Eprod{\Egrad{}{f\left(\V^k\right)}}{\G}{} + \frac{1}{2\rho} \frob{\G}^2 + \lambda \norm{\D \odot \left(\V^k + \G\right)}_1 \, ,\\
        \textrm{subject to} &\quad \linearop{\mathcal{A}^k}{\G} = \zeros_{h \times h}\,.
    \end{aligned}
\end{equation}

However, following the rationale in \citeSupp{si2024riemannianSupp}, we can force $\G^k \in \tangentspace{\V^k}{\stiefel{\ell}{h}}$ by exploiting the basis $\basisN{\V^k}$ of the normal space to the manifold, namely $\normalspace{\V^k}{\stiefel{\ell}{h}}$.
To find such $\basisN{\V^k}$, recall the explicit form of \normalspace{\V}{\stiefel{\ell}{h}} in \Cref{eq:explicit_normal_space}.

The basis of \sym{h}, having dimension $s=h (h+1)/2$, is 
\begin{equation}\label{eq:basis_sym}
    \mathcal{E} \coloneqq \{ \mathbf{E}_{ij} \in \{0,1\}^{h \times h} \, \mid \, \mathbf{E}_{ij} \text{ has } e_{ij}=e_{ji}=1, \, 0 \text{ elsewhere}, \, 1\leq i \leq j \leq h\}\,.
\end{equation}
It follows from \Cref{eq:explicit_normal_space,eq:basis_sym} that
\begin{equation}\label{eq:basis_nvk}
    \basisN{\V^k} \coloneqq \{ \basisNelement{k}_{ij}=\V^k \mathbf{E}_{ij}, \, 1\leq i \leq j \leq h\}\,.
\end{equation}
At this point, the membership to $\tangentspace{\V^k}{\stiefel{\ell}{h}}$ can be expressed as 
\begin{equation}
    \Eprod{\basisNelement{k}_{ij}}{\mathbf{G}}{}=0, \quad \forall 1\leq i \leq j \leq h\,. 
\end{equation}

Hence, \eqref{eq:ManPGU1} reads as
\begin{equation}\label{eq:ManPGU1n}
    \begin{aligned}        
        \G^k = \argmin_{\G \in \reall^{\ell \times h}} &\quad \Eprod{\Egrad{}{f\left(\V^k\right)}}{\G}{} + \frac{1}{2\rho} \frob{\G}^2 + \lambda \norm{\D \odot \left(\V^k + \G\right)}_1 \, ,\\
        \textrm{subject to} &\quad \Eprod{\basisNelement{k}_{ij}}{\mathbf{G}}{}=0, \quad \forall\, 1\leq i \leq j \leq h\,.
    \end{aligned}
\end{equation}

Consider $h\left(\V^k + \G\right)=\norm{\D \odot \left(\V^k + \G\right)}_1$ and $\reall^{s} \ni \boldsymbol{\mu}=[\mu_{11}, \mu_{12}, \ldots, \mu_{ij},\dots, \mu_{hh}]$, with $1\leq i \leq j \leq h$.
The Lagrangian for \eqref{eq:ManPGU1n} is
\begin{equation}\label{eq:ManPGU1n_Lagr}
    L_\rho \left(\G, \boldsymbol{\mu} \right) = \Eprod{\Egrad{}{f\left(\V^k\right)}}{\G}{} + \frac{1}{2\rho} \frob{\G}^2 + \lambda \, h\left(\V^k + \G\right) - \sum_{1\leq i \leq j \leq h}\mu_{ij} \Eprod{\basisNelement{k}_{ij}}{\mathbf{G}}{}\,.
\end{equation}
Let us define now the matrix $\reall^{s \times \ell h} \ni \mathbf{B}^k \coloneqq [\myvec{\basisNelement{k}_{11}}, \myvec{\basisNelement{k}_{12}}, \ldots, \myvec{\basisNelement{k}_{hh}}]^\top$, where $\myvec{\basisNelement{k}_{ij}} \in \reall^{\ell h}$.
We can compactly express the $s$ equality constraints as
\begin{equation}\label{eq:compact_eq_constraint}
    \mathbf{B}^k\myvec{\G}=\zeros_{s}\,.
\end{equation}

Thus, the Karush-Kuhn-Tacker (KKT) conditions of \Cref{eq:ManPGU1} reads as
\begin{equation}\label{eq:ManPGU1_KKT}
    \text{\emph{(i)}}\; \zeros_{l \times h} \in \Esubgrad{\G}{L_{\rho}\left(\G, \boldsymbol{\mu} \right)}\,, \quad \text{and} \quad \text{\emph{(ii)}}\; \mathbf{B}^k\myvec{\G}=\zeros_{s}\,.
\end{equation}

From the stationarity condition we get
\begin{equation}\label{eq:ManPGU1_stationarity}
    \begin{aligned}
        \zeros_{l \times h} \in \G + \rho \left(\Egrad{}{f\left(\V^k\right)} - \sum_{1\leq i\leq j\leq h} \mu_{ij} \basisNelement{k}_{ij} \right) + \lambda \, \rho \,\Esubgrad{\G}{h\left(\V^k + \G\right)}\,.
    \end{aligned}
\end{equation}

At this point, recalling the inclusion property of proximal operators, viz. $\mathbf{P} = \mathrm{prox}_g(\mathbf{B}) \iff \mathbf{B}-\mathbf{P} \in \Esubgrad{}{g(\mathbf{P})}$, we have
\begin{equation}\label{eq:ManPGU1_stationarity_prox}
    \begin{aligned}
        \zeros_{l \times h} \in \underbrace{\V^k + \G}_{\mathbf{P}} - \underbrace{\left( \V^k - \rho \left(\Egrad{}{f\left(\V^k\right)} - \sum_{1\leq i\leq j\leq h} \mu_{ij} \basisNelement{k}_{ij} \right) \right)}_{\mathbf{B}(\boldsymbol{\mu})} + \lambda\, \rho \, \Esubgrad{\G}{h\underbrace{\left(\V^k + \G\right)}_{\mathbf{P}}}\,;
    \end{aligned}
\end{equation}

from which we get
\begin{equation}\label{eq:ManPGU1_stationarity_solved}
    \G(\boldsymbol{\mu}) = \mathrm{prox}_{\lambda \, \rho\, h(\cdot) } \left(\mathbf{B}\left(\boldsymbol{\mu}\right)\right) - \V^k\,.
\end{equation}

At this point, $\mathrm{prox}_{\lambda \, \rho\, h(\cdot) }$ can be computed element-wise as
\begin{equation}\label{eq:ManPGU1_stationarity_prox_solved}
    \mathrm{prox}_{\lambda \, \rho\, h(\cdot) } \left(b_{ij}\left(\boldsymbol{\mu}\right)\right) = \begin{cases}
        b_{ij}(\boldsymbol{\mu})\,, &\quad \text{if } d_{ij}=0\,, \\
        \mathcal{S}_{\lambda \, \rho}(b_{ij}(\boldsymbol{\mu}))\,, &\quad \text{otherwise}\,.
    \end{cases}
\end{equation}

Substituting \Cref{eq:ManPGU1_stationarity_solved} into \Cref{eq:ManPGU1_KKT}, we have 
\begin{equation}\label{eq:ManPGLambda_G}
    \mathbf{B}^k\myvec{\G(\boldsymbol{\mu})}=\zeros_{s}\,.
\end{equation}

Here the $r$-th entry of $\myvec{\G(\boldsymbol{\mu})}$ corresponds to the entry of $\G(\boldsymbol{\mu})$ at row $ u=(r-1) \,\mathrm{mod}\, \ell + 1$, and column $v=\lfloor{(r-1) / \ell\rfloor} + 1$ , $r \in [\ell h]$. 

At this point, we can use the regularized semi-smooth Newton method \citeSupp{xiao2018regularizedSupp} to solve \Cref{eq:ManPGLambda_G}.
Our target function is
\begin{equation}\label{eq:regNF}
    F(\boldsymbol{\mu})=\mathbf{B}^k\myvec{\G(\boldsymbol{\mu})} \, :\, \reall^s \rightarrow \reall^s. 
\end{equation}
By the chain rule of calculus, using \Cref{eq:ManPGU1_stationarity_solved}, the generalized Jacobian matrix is 
\begin{equation}\label{eq:genJ}
    \begin{aligned}
        \reall^{s \times s} \ni \mathbf{J} &= \pdv{F(\boldsymbol{\mu})}{\myvec{\G(\boldsymbol{\mu})}}\cdot \pdv{\myvec{\G(\boldsymbol{\mu})}}{\boldsymbol{\mu}} \\
        &= \mathbf{B}^k \pdv{\prox_{\lambda\, \rho\, h(\cdot)}\left(\myvec{\mathbf{B}(\boldsymbol{\mu})}\right)}{\myvec{\mathbf{B}(\boldsymbol{\mu})}}\cdot\pdv{\myvec{\mathbf{B}(\boldsymbol{\mu})}}{\boldsymbol{\mu}}\,.
    \end{aligned}
\end{equation}
The proximal-related term is a diagonal matrix $\mathbf{M} \in \reall^{\ell h \times \ell h}$, where
\begin{equation}\label{eq:Jfirst}
    m_{rr} = \begin{cases}
        1\,,\quad \text{if } \myvec{\D}_{r} = 0 \text{ or } \left(\myvec{\D}_{r} = 1 \text{ and }\abs{b_{r}}-\lambda \rho >0\right)\,. \\
        0\,, \quad \text{otherwise}.
    \end{cases}
\end{equation}
Additionally, starting from
\begin{equation}
    \begin{aligned}
        b_r(\boldsymbol{\mu}) &= \myvec{\V^k - \rho\left( \Egrad{}{f(\V^k)} - \sum_{1 \leq i \leq j \leq h} \mu_{ij} \left[\B_{ij}^k \right]_{uv} \right) } \\
        &= \myvec{\V^k - \rho\left( \Egrad{}{f(\V^k)} - \mathbf{b}_{uv}^{k^\top} \boldsymbol{\mu} \right)}\,.        
    \end{aligned}
\end{equation}

Hence, we get 
\begin{equation}\label{eq:Jsecond}
    \reall^{s} \ni \pdv{b_r(\boldsymbol{\mu})}{\boldsymbol{\mu}}=\mathbf{b}_{uv}^{k}\,.
\end{equation}

Consequently, starting from \Cref{eq:genJ}, using \Cref{eq:Jfirst,eq:Jsecond}, we finally have
\begin{equation}\label{eq:genJ_explicit}
    \mathbf{J} = \mathbf{B}^k \mathbf{M} \mathbf{C}, 
    \quad \text{ with } \reall^{\ell h \times s} \ni \mathbf{C}=\begin{pmatrix}
        \mathbf{b}_{11}^{k^\top}\\
        \mathbf{b}_{21}^{k^\top}\\
        \vdots \\
        \mathbf{b}_{\ell h}^{k^\top}  
    \end{pmatrix}\,. 
\end{equation}

Following \citeSupp{xiao2018regularizedSupp}, denoting with $\nu^k=\alpha^k\norm{F^k}_2, \, \alpha^k \in \reall^+$, we define
\begin{equation}\label{eq:regN1}
    r^k \coloneqq \left( \mathbf{J}^{k-1} + \nu^{k-1} \identity_s \right) \mathbf{d}^{k} + F^{k-1}\,.
\end{equation}

At each iteration we want to find the step $\mathbf{d}^k$ by solving \Cref{eq:regN1} inexactly, such that
\begin{equation}
    \norm{r^k}_2 \leq \tau \min{\left(1, \alpha^{k-1} \norm{F^{k-1}}_2 \norm{\mathbf{d}^k}_2\right)}\,, \quad \tau \in (0,1)\,;
\end{equation}
obtaining a trial point
\begin{equation}\label{eq:regN_trial}
    \mathbf{u}^k = \boldsymbol{\mu}^{k-1} + \mathbf{d}^k\,.
\end{equation}

Let $\beta^0=\norm{F(\boldsymbol{\mu}^0)}_2$ and $\gamma \in (0,1)$.
If $\norm{F(\mathbf{u}^k)}_2\leq \gamma \beta^{k-1}$ then we set
\begin{equation}\label{eq:Newton_step}
    \boldsymbol{\mu}^{k} = \mathbf{u}^k\,, \; \beta^{k}=\norm{F(\mathbf{u}^k)}_2\,, \; \text{ and } \alpha^{k}=\alpha^{k-1}\,. \quad \text{[Newton step]}
\end{equation}

Otherwise, let 
\begin{equation}\label{eq:safeguard_ratio}
    \xi^k = \frac{- F(\mathbf{u}^k)^\top \mathbf{d}^k}{\norm{\mathbf{d^k}}_2^2}\, . 
\end{equation}

Select $0<\phi_1\leq\phi_2<1$ and $1<\psi_1<\psi_2$.
Hence, we make a safeguard step as follows
\begin{equation}\label{eq:safeguard_step}
    \boldsymbol{\mu}^{k} = \begin{cases}
        \mathbf{v}^k\,, &\quad \text{ if } \xi^k \geq \phi_1 \text{ and } \norm{F(\mathbf{v}^k)}_2 \leq \norm{F(\boldsymbol{\mu}^{k-1})}_2, \;  \text{[projection step]} \\
        \mathbf{w}^k\,, &\quad \text{ if } \xi^k \geq \phi_1 \text{ and } \norm{F(\mathbf{v}^k)}_2 > \norm{F(\boldsymbol{\mu}^{k-1})}_2, \;  \text{[fixed-point step]} \\
        \boldsymbol{\mu}^{k-1}\,, &\quad \text{ if } \xi^k < \phi_1, \; \text{unsuccessful step}
    \end{cases}
\end{equation}
where
\begin{equation}
    \mathbf{v}^k = \boldsymbol{\mu}^{k-1} - \frac{F(\mathbf{u}^k)^\top (\boldsymbol{\mu}^{k-1} - \mathbf{u}^k)}{\norm{F(\mathbf{u}^k)}_2} F(\mathbf{u}^k), \; \mathbf{w}^k=\boldsymbol{\mu}^{k-1} - \delta F(\boldsymbol{\mu}^k), \; \delta \in \left(0, \frac{1}{\omega}\right)\,;
\end{equation}

where $\omega \in (0,1]$. 
Finally, denoting $\reall^+ \ni \Bar{\alpha} \approx 0$, the parameters $\beta^{k+1}$ and $\alpha^{k+1}$ are updated as
\begin{equation}
    \beta^{k}=\beta^{k-1}, \quad \alpha^{k} \in \begin{cases}
        (\Bar{\alpha}, \alpha^{k-1})\,, &\quad \text{if } \xi^k \geq \phi_2,\\
        [\alpha^{k-1}, \psi_1\alpha^{k-1}]\,, &\quad \text{if } \phi_1 \leq \xi^k < \phi_2,\\
        (\psi_1\alpha^{k-1}, \psi_2\alpha^{k-1}]\,, &\quad \text{otherwise.}\\
    \end{cases}
\end{equation}

At this point, we set $\G^k=\G^k(\boldsymbol{\mu}^k)$ according to \Cref{eq:ManPGU1_stationarity_solved}.

\spara{Solution for $\mathbf{V}^{k+1}$.}
Given $\V^k + \G^k \in \tangentspace{\V^k}{\stiefel{\ell}{h}}$, we have to project the point onto the manifold.
This can be accomplished via the canonical retractions in \Cref{eq:stiefel_retractions}.
However, as suggested in \citeSupp{chen2020Supp}, our LinSEPAL-PG implementation performs an Armijo line-search procedure to determine the stepsize $a$.
Hence, the update is
\begin{equation}\label{eq:updateV_linsepalpg}
    \V^{k+1}=\Retr{\mathrm{QR}}{\V^k}{a\G^k}\,.
\end{equation}

\spara{Stopping criteria.}
Empirical convergence of the LinSEPAL-PG algorithm is established either when a maximum number of iterations $K$ is reached, or when the $\KL{\V^{k+1}}$ is below a certain threshold $\tau^{\mathrm{KL}}\approx 0$.
The LinSEPAL-PG algorithm is summarized in \cref{alg:linsepal_pg}.

\begin{algorithm}[H]
\caption{LinSEPAL-PG}
\label{alg:linsepal_pg}
\begin{algorithmic}[1]
\STATE \textbf{Input:} $\covlow$, $\covhigh$, $\D$, $\lambda$, $\rho$, $\gamma \in (0,\,1)$, $\tau^{\mathrm{KL}}$, $K$
\STATE Initialize: $\V^0 \in \stiefel{\ell}{h}$, $\Y^0 \in \rmatdim$, $\scaledU^0 \in \rmatdim$
\REPEAT
    \STATE $\G^{k} \gets \text{Solve \cref{eq:ManPGU1n} via the regularized semi-smooth Newton method}$ 
    \STATE $a \gets 1$
    \REPEAT
        \STATE $a = \gamma a$
        \STATE $\bar{\V} = \;\Retr{\mathrm{QR}}{\V^k}{a\,\G^k}$
    \UNTIL{$\KL{\bar{\V}} > \KL{\V^k} - \frac{a \frob{\G^k}^2}{2\rho}$}
    \STATE $\V^{k+1} \gets \bar{\V}$
\UNTIL{$k>K$ or $\KL{\V^{k+1}}<\tau^{\mathrm{KL}}$}
\STATE \textbf{Output:} $\V$
\end{algorithmic}
\end{algorithm} 