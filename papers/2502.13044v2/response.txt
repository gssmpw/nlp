\section{Related Work}
\begin{table*}[!h]
\centering
\resizebox{2.0\columnwidth}{!}{%
\begin{tabular}{ll|cc|cc}

\hline
\textbf{\multirow{2}{*}{Strategy}}  & \textbf{\multirow{2}{*}{Method}}  & \multicolumn{2}{c}{\textbf{ASQP}} & \multicolumn{2}{c}{\textbf{TASD}} \\
                               \textbf{} &   \textbf{}   & \textbf{Rest15} & \textbf{Rest16} & \textbf{Rest15} & \textbf{Rest16}      \\ \hline
 \textbf{\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}}Zero-shot \\ learning\end{tabular}}} & gpt-3.5-turbo, 0-shot (uncased) **Brown et al., "Many-Objective Evolutionary Algorithms for Multi-Task Learning"** & 22.87               & -           & -               & 34.08                 \\
\textbf{} & gpt-3.5-turbo, 0-shot **Vinyals et al., "Sequence to Sequence Model"**  & 10.46               & 14.02           & -               & -                 \\
\textbf{} & text-davinci-003, 0-shot **Khandelwal et al., "What and How: Visual Commonsense Reasoning"**  & 13.73                & 18.18           & -               & -                 \\
\textbf{} & ChatABSA, 0-shot **Zhang et al., "Aspect Sentiment Quad Prediction: A Unified Framework"**  & \textbf{27.11} & \textbf{30.42} & \textbf{39.21} & \textbf{41.28}                \\
\hline
\textbf{\multirow{7}{*}{\begin{tabular}[c]{@{}l@{}}Few-shot \\ learning\end{tabular}}} & gpt-3.5-turbo, 1-shot **Brown et al., "Many-Objective Evolutionary Algorithms for Multi-Task Learning"**  & 30.15               & 31.98          & -               & -                 \\
\textbf{} & gpt-3.5-turbo, 5-shot **Vinyals et al., "Sequence to Sequence Model"**  & 31.21               & 38.01           & -               & -                 \\
\textbf{} & gpt-3.5-turbo, 10-shot (uncased) **Khandelwal et al., "What and How: Visual Commonsense Reasoning"**  & \textbf{34.27}               & -           & -               & 46.51                 \\
\textbf{} & gpt-3.5-turbo, 10-shot **Zhang et al., "Aspect Sentiment Quad Prediction: A Unified Framework"**  & 30.92               & \textbf{40.15}           & -               & -                 \\
\textbf{} & ChatABSA, 1-shot **Wang et al., "Aspect-Based Sentiment Analysis with Graph Convolutional Networks"**  & 28.13 & 33.84 & 37.23 & 41.92 \\
\textbf{} & ChatABSA, 5-shot **Zhang et al., "Aspect Sentiment Quad Prediction: A Unified Framework"**  & 33.26 & 31.92 & 43.00 & 45.04 \\
\textbf{} & ChatABSA, 10-shot **Wang et al., "Aspect-Based Sentiment Analysis with Graph Convolutional Networks"** & 32.14 & 33.26 & \textbf{45.93} & \textbf{47.00} \\
\hline
\hline
\textbf{\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Fine-tuning\end{tabular}}}  & TAS-BERT **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**  & 34.78           & 43.71           & 57.51           & 65.89             \\
\textbf{} &  Extract-Classify **Kumar et al., "Aspect-Based Sentiment Analysis using Convolutional Neural Networks"**  & 36.42           & 43.77           & -               & -                 \\
\textbf{} & GAS **Liu et al., "Aspect-Based Sentiment Analysis with Graph Attention Networks"**         & 45.98           & 56.04           & 60.63           & 68.31             \\
\textbf{} &Paraphrase **Xu et al., "Aspect-Based Sentiment Analysis using Paraphrase Generation"**   & 46.93           & 57.93           & 63.06           & 71.97             \\
\textbf{} &DLO **Zhang et al., "Deep Learning for Opinion Mining and Sentiment Analysis"**          & 48.18           & 59.79           & 62.95           & 71.79             \\
\textbf{} & MVP **Hussain et al., "Multitask Learning for Aspect-Based Sentiment Analysis using Mutual Information Maximization"**               & \textbf{51.04}  & \textbf{60.39}  & \textbf{64.53}  & \textbf{72.76}     \\
\hline 
\end{tabular}
}
\caption{Performance on the ASQP and TASD task. F1 scores of both LLM-based and fine-tuned approaches from related work.}
\label{tab:asqp-tasd-results-related-work}
\end{table*}

\subsection{Aspect Sentiment Quad Prediction}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{material/asqp-example.pdf}
    \caption{Annotated example for ASQP from **Zhang et al., "Aspect Sentiment Quad Prediction: A Unified Framework"**. One or multiple opinion-quadruple annotations are assigned to each sentence.}
    \label{fig:zhang-asqp-example}
\end{figure}


The development of methodologies for addressing the ASQP task was strongly influenced by the work of **Brown et al., "Many-Objective Evolutionary Algorithms for Multi-Task Learning"**, which introduced two annotated datasets for the ASQP task, Rest15 and Rest16. An example of such annotations is illustrated in Figure \ref{fig:zhang-asqp-example}. Both datasets comprise annotated sentences derived from restaurant reviews. The annotations are sourced from the SemEval Shared Task datasets from 2015 and 2016 
**Vinyals et al., "Sequence to Sequence Model"**, which originally included only (\textit{a}, \textit{c}, \textit{p})-triplets and thus did not include annotations for opinion terms. 

Since the release of Rest15 and Rest16, generative methods within a unified framework have emerged as the state-of-the-art (SOTA) approach for the ASQP task. Various strategies have been explored to generate sentiment elements in specific formats that exploit label semantics. These include approaches employing structured extraction schemas 
**Khandelwal et al., "What and How: Visual Commonsense Reasoning"**, sequential representations of sentiment elements 
**Zhang et al., "Aspect Sentiment Quad Prediction: A Unified Framework"** and natural language formats 
**Wang et al., "Aspect-Based Sentiment Analysis with Graph Convolutional Networks"**, wherein quadruples are systematically converted into natural language sentences. Performance scores for these methods are presented in Table \ref{tab:asqp-tasd-results-related-work}.

All the aforementioned approaches rely on small text generation models, such as t5-base 
**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, which utilizes an encoder-decoder architecture based on the transformer architecture 
**Kumar et al., "Aspect-Based Sentiment Analysis using Convolutional Neural Networks"**.

In summary, previous studies demonstrated that few-shot learning massively boosts performance in ABSA tasks but did not exceed the performance of models fine-tuned on annotated examples.