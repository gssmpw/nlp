\section*{Limitations}

This study evaluated the performance of LLMs on ASQP tasks across a broad selection of datasets, few-shot settings, and LLM configurations. However, a limitation of this work is the selection of employed LLMs. We only employed LLMs comprising 9 or 27 billion parameters. Bigger-sized models such as Llama-3-70B \citep{dubey2024llama} or commercial models were not considered due to their prohibitive computational and financial costs. In order to evaluate each setting for a considered LLM, we executed a total of 171,360 prompts. Due to the amount of tokens in each prompt, the associated cost implications are substantial: about 191 hours (8 days) for Gemma-2-27B and 120 hours (5 days) for Gemma-2-9B. Hence, the time would further increase with an even bigger LLM in terms of parameter size. For commercial models such as GPT-4, executing all prompts would result in massive costs.

Finally, we must highlight the issue of potential data contamination, as it is the case for the previous studies introduced in the related work section. Meaning, it cannot be ruled out that the publicly available annotated datasets used in this study (except for FlightABSA) were included in the training data for both Gemma-2-9B and Gemma-2-27B.

\section*{Ethics Statement}

All results and code used in this study are publicly available. The dataset we introduced, FlightABSA, is available upon request. We want to prevent the annotated dataset from being available online and then being inadvertently collected for pre-training LLMs.