\section{Introduction}

Transformer-based large language models (LLMs) have gained significant attention due to their capability to address a broad spectrum of natural language processing (NLP) tasks, such as text summarization, translation, reading comprehension and text classification \citep{brown2020language,dubey2024llama}. Noteworthy LLMs include Llama-3.1 \citep{dubey2024llama}, Gemma-2 \citep{team2024gemma}, and Mixtral \citep{jiang2024mixtral}, which are accessible in various parameter sizes with open model weights and commercial models like GPT-4 \citep{achiam2023gpt} and Claude 3 \citep{anthropic2024claude}.

Previous research explored zero- and few-shot scenarios in which the LLM generates outputs with either none or only a few labelled examples provided in the prompt \cite{gou2023mvp, zhang2024sentiment}. This eliminates the need for supervised model training, such as for small language models\footnote{There is no universally accepted definition for categorizing language models as small or large. As handled by \citet{zhang2024sentiment}, models with fewer than 1 billion parameters are considered small, while those with 1 billion or more parameters are classified as large.} (SLMs) using annotated datasets \citep{wang2023large}. This approach is particularly appealing because data annotation is often deemed complex and expensive, both in terms of time or financial cost, thereby complicating the development of text classification solutions tailored to specific tasks \citep{fehle2023absa,gretz2023zero,li2023data}.

An extensively studied task in NLP where manual annotations pose significant challenges is aspect-based sentiment analysis (ABSA) \citep{zhang2022survey}. This task facilitates the understanding of customer opinions expressed in reviews or feedback \citep{pontiki2014semeval}. Unlike traditional sentiment classification, which assigns a single sentiment label (commonly positive, negative, or neutral) to an entire text document, ABSA requires annotators to identify all aspects within the text and determine the sentiment associated with each one \citep{zhang2022survey}.

A prominent subtask of ABSA is aspect sentiment quad prediction (ASQP), which provides exceptionally detailed insights into the author's opinions by identifying four sentiment elements for each opinion: aspect term (\textit{a}), aspect category (\textit{c}), sentiment polarity (\textit{p}) and opinion term (\textit{o}) \citep{zhang2021aspect}. Consequently, the annotation process for training examples is highly demanding, particularly when multiple opinions need to be annotated within a single text.

Previous research has predominantly concentrated on 0- to 10-shot learning, exclusively utilizing the English-language restaurant domain datasets Rest15 and Rest16 introduced by \citet{zhang2021aspect}. 

In this study, we extend the analysis to include up to 50 few-shot examples and evaluate the approach on a diverse series of five datasets. The datasets utilized in this work include Rest15 and Rest16, introduced by \citet{zhang2021towards} and we incorporate the OATS dataset by \citet{chebolu2024oats}, which consists of hotel reviews from TripAdvisor and online learning reviews collected from Coursera. Finally, we introduce a novel ASQP dataset, comprising annotated sentences from airline reviews, which is published as part of this work.

We considered the following research questions:

\begin{description}
  \item \textbf{RQ1:} How does varying the number of few-shot examples (from 0 to 50) impact performance on the ASQP task?
  \item \textbf{RQ2:} How do LLMs perform on the ASQP task compared to SLMs trained on annotated examples? 
  \item \textbf{RQ3:} Does self-consistency (SC) prompting \citep{wang2022self}, where multiple outputs are generated from the same prompt and the most consistent response is selected, improve performance on the ASQP task?
\end{description}

We employed Google's Gemma-2-27B \citep{team2024gemma} and report the performance for the smaller-sized Gemma-2-9B. In addition, we report the LLMs' performance on the target aspect sentiment detection (TASD) task, which focuses on the identification of (\textit{a}, \textit{c}, \textit{p})-triplets. All code and results of this study is publicly available on GitHub\footnote{\url{https://anonymous.4open.science/r/llm-absa-quad-zero}}.

