%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
\documentclass[10pt,twocolumn,twoside]{IEEEtran}   % Comment this line out

\IEEEoverridecommandlockouts                       % This command is only
% needed if you want to
% use the \thanks command
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org

\input{preamble/common}
\usepackage[capitalise]{cleveref}
\newcommand{\news}{\color{blue}}

\pagenumbering{arabic}

\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

\title{\LARGE \bf
 %Distributed Task Assignment for Cyber-Physical Security in Multi-Agent Systems
 Distributed Online Task Assignment via Inexact ADMM for unplanned online tasks and its Applications to Security}
 %with Applications to Cyber-Physical Security}
% with Applications to Introspection Monitoring}
\author{Ziqi Yang and Roberto Tron \IEEEmembership{Member, IEEE} 
\thanks{This project is supported by the National Science Foundation grant "CPS: Medium: Collaborative Research: Multiagent Physical Cognition and Control Synthesis Against Cyber Attacks" (Award number 1932162).}
\thanks{Ziqi Yang is with the Department of Systems Engineering,
Boston University, Boston, MA 02215 USA (e-mail: zy259@bu.edu).
}
\thanks{Roberto Tron is with the Faculty of Mechanical Engineering and Systems Engineering, Boston University, Boston, MA 02215 USA (e-mail:tron@bu.edu).}}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
    In multi-robot system (MRS) applications, efficient task assignment is essential not only for coordinating agents and ensuring mission success but also for maintaining overall system security. In this work, we first propose an optimization-based distributed task assignment algorithm that dynamically assigns mandatory security-critical tasks and optional tasks among teams. Leveraging an inexact Alternating Direction Method of Multipliers (ADMM)-based approach, we decompose the task assignment problem into separable and non-separable subproblems. The non-separable subproblems are transformed into an inexact ADMM update by projected gradient descent, which can be performed through several communication steps within the team. 
    
    In the second part of this paper, we formulate a comprehensive framework that enables MRS under plan-deviation attacks to handle online tasks without compromising security. The process begins with a security analysis that determines whether an online task can be executed securely by a robot and, if so, the required time and location for the robot to rejoin the team. Next, the proposed task assignment algorithm is used to allocate security-related tasks and verified online tasks. Finally, task fulfillment is managed using a Control Lyapunov Function (CLF)-based controller, while security enforcement is ensured through a Control Barrier Function (CBF)-based security filter. Through simulations, we demonstrate that the proposed framework allows MRS to effectively respond to unplanned online tasks while maintaining security guarantees.
\end{abstract}
\begin{IEEEkeywords}
    Multi-robot system, distributed task assignment, optimization, cyber-physical security
  \end{IEEEkeywords}
  

\section{Introduction}\label{sec:introduction}
Effective team division is a common and valuable approach in multi-robot system (MRS) applications, particularly for coordinating tasks across large, dynamic environments. By forming sub-teams, MRS can enhance coordination, scalability, and task efficiency, enabling better coverage, redundancy, and adaptability. In security scenarios, such as patrolling, surveillance, and co-observation\cite{pajares2015overview,wardega2019resilience,julian2012distributed}, the sub-team structure offers distinct advantages over individual robot deployments by allowing tasks to be distributed more effectively within and across teams. Additionally, the flexible nature of MRS expends the integration of security measures into non-security tasks by augmenting additional application-specific objectives (e.g., map exploration) with co-observation plans (see, e.g., our previous work in \cite{wardega2019resilience} for details). This approach not only improves overall task performance but also enables the efficient monitoring of sensitive areas, detection of anomalies, and timely response to threats. 

These security applications often require teams to follow pre-defined trajectories, visit key checkpoints, and collaborate or co-observe with other teams to detect intrusions or suspicious activity. In practice, however, there might be situations that cannot be planned for ahead of time (e.g., visiting unexpected targets of interest). These online events will unavoidably lead to conflicts with the security spatio-temporal requirements (e.g., reaching an unexpected target might lead to missing a checkpoint). A complete optimal replan in such cases might be unfeasible, due to high-dimensional computations or security considerations. To take advantage of the redundancy provided by MRS and sub-teams, we propose to handle these \emph{online tasks} through an online task assignment that optimizes the use of the additional robots. The task assignment algorithm ensures that some robots will always fulfill the original plan and maintain the security requirements so that others can be assigned to handle online tasks. This requires the system to optimally assign tasks according to predefined priorities (pre-planned tasks versus online tasks)~\cite{khamis2015multi}. 

Traditionally, multi-agent task assignment problems can be addressed using either distributed or centralized approaches~\cite{chakraa2023optimization}. Centralized approaches require individual agent's information to be communicated to a central agent or server, which generates a plan for the entire system. By taking into account the capabilities and limitations of all agents and tasks, the central planner is able to optimize the overall system performance \cite{prasad2020,coltin2010mobile,liu2012centralized,jin2003cooperative}. However, the centralized method sacrifices robustness and scalability, exposing the system to risks of failures at the central entity and limiting the range to where centralized communications are possible.

Decentralized approaches, on the other hand, rely on local communications between agents, and offer resilience to a single point of failure, as well as scalability in team size and mission range. Common methods include local search algorithm~\cite{lee2014ad}, bio-inspired methods~\cite{jevtic2011distributed}, consensus-based algorithms~\cite{alighanbari2005decentralized,dionne2007multi}, auction algorithms~\cite{quinton2023market,cao2012overview}, game theory-based algorithms~\cite{Xu2024}, just to name a few. Consensus usually relies on local communication to converge to a common value\cite{alighanbari2005decentralized,dionne2007multi}. However, these methods cannot guarantee a conflict-free solution. On the other hand, auction algorithms with conflict-free capability are not robust to distributed network topologies, which may not cope with multiple tasks~\cite{sariel2005real,Bai2023}. Some approaches provide improvements for the latter case, e.g., by running sequential auctions \cite{sariel2005real,sujit2007distributed}, or incorporating consensus methods \cite{choi2009consensus}. In any case, however, it is not clear that existing consensus- or auction-based methods can be applied to our application, which requires real-time adaptability and robustness to dynamic changes in order to maintain security.

In this paper, we present a distributed task assignment algorithm to manage tasks with different priorities. The task assignment is formulated as an optimization problem, where task priorities are incorporated as constraints. We first demonstrate that when the number of tasks matches the number of robots, the problem can be solved in a distributed manner using a projected gradient descent variation of the inexact Alternating Direction Method of Multipliers (ADMM). As shown in \cite{ma2016alternating,chang2014multi}, the use of the inexact gradient-based updates in each ADMM step significantly reduces complexity while still ensuring convergence. With this approach, we divide the task assignment problem into separable and non-separable ADMM blocks. The separable block can be solved individually by each robot; by applying a projected gradient descent method in the ADMM update, the non-separable subproblems can also be solved in a distributed manner through communication between connected robots. In addition, we introduce the concepts of \emph{shadow agents} and \emph{secondary trajectory tasks} to address scenarios where the number of tasks is different from the number of available agents.

We test our task assignment algorithm in a co-observation-secured application, building on previous work in the area~\cite{yangmulti,wardega2019resilience}. \emph{Co-observations} serve as an additional security layer for non-security tasks, which utilize the physical sensing capabilities of robots to perform mutual observations within the MRS system. This technique aims to mitigate the risks posted by \emph{physical masquerade attacks}, where compromised robots are taken over by attackers, masquerading as legitimate robots, to gain unauthorized access to forbidden areas. As shown in~\cite{yang2021multi}, adversarial robots can be detected even without knowing the attacker's model by incorporating proper \emph{reachability} constraints and co-observation schedule into the trajectory plan~\cite{yangmulti,wardega2019resilience}. To extend this security framework to handle unplanned online tasks, we propose an online control framework that integrates co-observation and reachability constraints while ensuring safe task execution. The framework consists of three key components: 
\begin{itemize}
    \item \emph{Regroup time calculation module} that evaluates whether an unplanned task can be safely executed while maintaining security guarantees;
    \item \emph{Distributed task assignment algorithm} that dynamically allocates robots to both trajectory and online tasks without compromising co-observation security;
    \item \emph{Online control scheme} that trajectory tracking and online task fulfillment are formulated as Control Lyapunov Function (CLF) constraints. Security conditions are transformed into Signal Temporal Logic (STL) requirements and enforced using a Control Barrier Function (CBF)-STL-based security filter, ensuring real-time adherence to both spatial and timing constraints. 
\end{itemize}
 This framework allows robots to respond to unplanned events while preserving security guarantees, as detailed in~\cref{fig:Flowchart}.


\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth, trim = 5.2cm 10.5cm 3.3cm 4cm, clip]{BlockDiag.pdf}
    \caption{Strategies for co-observation-secured sub-teams encountering online tasks}\label{fig:Flowchart}
\end{figure}

The main contributions of this paper are as follows:
\begin{enumerate}
      \item We present a computationally inexpensive distributed online task assignment algorithm that can handle different priority constraints, such as ensuring the completion of pre-planned tasks while accommodating online tasks. This algorithm leverages an inexact ADMM to solve the task assignment problem in a distributed manner. Compared to existing optimization-based approaches~\cite{chakraa2023optimization}, our method is more scalable for the types of problems discussed in this paper.
     \item We demonstrate the applicability of the task assignment algorithm through a co-observation-secured multi-robot map exploration task. Our task assignment algorithm allows a team of robots with security-critical plans to efficiently handle online tasks without compromising security. The strategy contains three components: the decision-making process for secure deviations and regroups for online tasks, the distributed task assignment algorithm, and CLF and CBF based control framework~\cite{lindemann2018control,article09} to guide robots to meet their spatio-temporal schedule. 
\end{enumerate}

The organization of this paper is as follows. \Cref{sec:preliminary} introduces necessary definitions and preliminaries for task assignment problems. \Cref{sec:task_assignment} presents the distributed task assignment algorithm in detail. \Cref{sec:application} presents a co-observation-secured application. In this application, the capability to deal with online tasks is demonstrated using the proposed algorithm combined with additional decision-making processes and control methods. \Cref{sec:simulation} presents the simulation results. \Cref{sec:Conclusion} concludes this paper.
%Overall, our paper presents several novel contributions that enable a flexible and securied solution dealing with unplanned online tasks in systems with spatio-temporal constraints.


\section{Definitions and Preliminaries}\label{sec:preliminary}
\subsection{Pre-planned MRS trajectory and sub-teams}
We consider a multi-robot system with $N>1$ robots in a $m$ dimensional workspace, where a partition $\cI=\bigcup_p \cI_p$ is defined to separate the system into $N_p$ \emph{sub-team}s. A planner~\cite{yang2021multi} is used to generate reference paths that can satisfy the security requirements like co-observation schedule while optimizing some high-level objectives (e.g., the accuracy of the map)~\cite{yang2021multi}. The planner provides $N_P<N$ trajectories $\{\vq_p\}_{p=1}^{N_p}$ for each sub-team $\cI_p$ that consist of reference waypoints $\vq_p = [q_{p1},\dots,q_{pT}]$ where $q_{ij}\in\real{m}$ is the reference waypoint of team $i$ in a $m$ dimensional state space, $T$ is the time horizon. Robots in the same sub-team $\cI_p$ share the same nominal trajectory $\vq_p$ and treat the trajectory following as their \emph{primary task}. Each sub-team performs the task assignment individually. For simplicity, in the rest of this paper, we only consider states of members in one sub-team instead of the whole MRS system. The state $x_{\cA_i}\in \real{m}$ represents the current position of the $i$-th robot $\cA_i$ in sub-team.

\subsection{Communication graph}
We assume that agents in the same sub-team $p$ can securely exchange information according to an undirected communication graph $G_p$. To each graph is associated a \emph{Laplacian matrix} $L_p$ defined as follows.
\begin{definition}\label{def:laplacian_matrix} Let $A$ be the adjacency matrix of a symmetric network. Let $D=\diag(A\vct{1})$. Thus, the Laplacian matrix is defined as $L=D-A$.~\cite{chung1997spectral}
\end{definition}
Assuming that the network graph is always connected and symmetric, we have the following:
\begin{lemma}\label{lemma:laplacian properties}
$L\vct{1}=0$ and $L\succ 0$.
\end{lemma}
Let $\alpha=\stack(\{\alpha_i\})$ be a vector of scalar states at each node. The following observation is used further below to identify computations that can be implemented in a distributed manner.
\begin{lemma}
    The computation of $L\alpha$ can be done in a distributed way: each agent $i$ only needs to know $\alpha_i$ and exchange a single round of communication with its neighbors $N_i$.
\end{lemma}
\begin{proof}
    Given the definition of $L$, for an individual agent, the operation can be written as $[L\alpha]_i=\sum_{\in N_i} (\alpha_j-\alpha_i)$, hence the claim.
\end{proof}


% \section{Problem overview and proposed solutions}\label{sec:problem_overview}

\section{Distributed task assignment protocol}\label{sec:task_assignment}
In this section, we formulate the task assignment problem and solve it in a distributed manner using an inexact ADMM-based approach. The problem involves two types of assignable tasks.

\begin{description}
\item[\emph{Trajectory task $P$}]: This task corresponds to the original pre-planned mission trajectory, with designated locations and pre-determined times for the agents to reach. The trajectory task is fulfilled by following the nominal trajectory $q_p$ given to the sub-team. These tasks have the highest priority and are required to have at least one agent in each sub-team always assigned to them. 
\item[\emph{Online tasks $\{O_j\}$}]: These are tasks that are not known at planning time. An online task $j$ appears at a certain time $t_{O_j}$ at a location $q_{O_j}$ (\cref{fig:Example_case_task_appear}), and it is satisfied when a robot reaches a small neighborhood of $q_{O_j}$. We consider that an online task is optional, and may be unsatisfied if there are no available agents, or if the overall security requirements cannot be maintained.
\end{description}

Inside the sub-team, each robot is either assigned to the trajectory task $P$, or to an online task $O_j$. We introduce a matrix of \emph{splitting coefficients} $ \pmb\alpha_{\cA} =[\alpha_{i,j}]$, which are functions of time, and where each element $\alpha_{i,j}=1$ represents the assignment of agent $i$ to task $j$. We formally define the main task assignment problem via the following Linear Program:
\begin{subequations}\label{eq:original_problem}
\begin{align}
    \min_{\alpha} &-\trace(\pmb W_{\cA}\transpose \pmb\alpha_{\cA}),\\
    \subjectto & \sum_{j} \alpha_{ij}=1, \label{eq:agent total}\\
    &\sum_i \alpha_{iP}= 1, \label{eq:primary task}\\
    &\sum_i \alpha_{ij}\leq 1, \label{eq:optional tasks}  \quad \textrm{for}\quad j\neq P\\
    & 0\leq \alpha_{ij} \leq1, 
\end{align}
\end{subequations}
where $\pmb W_{\cA}, \pmb\alpha_A \in\real{\abs{\cA}\times \abs{\cT}}$ is a matrix of weights, $j\in\cT$ $i\in \cA$, $\cT \subseteq P \union \{O_j\}$ is the set of trajectory and online tasks, and $\cA$ is the set of agents. 
The rationale behind the constraints is as follows:
\begin{description}
\item[\eqref{eq:agent total}] ensures that each agent is assigned to exactly one task. This is a local constraint that is easy to handle through a local step of ADMM.
\item[\eqref{eq:primary task}] ensures that the trajectory task is always assigned exactly once.
\item[\eqref{eq:optional tasks}] ensures that online tasks do not get assigned to more than one agent. When $\abs{\cA} = \abs{\cT}$, this constraint can be written as $\sum_i a_{ij} = 1$
\end{description}
Each entry $\pmb W_{\cA} = [w_{ij}]$ represents the weight for task $j$ and $\cA_i$; $w_{ij}$ is determined from the current state (location) $x_{\cA_i}$ of agent $i$ as follows:%. The weight for trajectory tasks and online tasks are designed as:
\begin{description}
    \item[Trajectory task $P$]: 
    \begin{equation}\label{eq:trajectory_task_weight}
    w_{\cA P}(x_{\cA_i})=(d( q_t,x_{\cA_i})+\epsilon)\inverse, 
    \end{equation} where $\epsilon$ is a perturbation term to avoid singularity. The weight of the trajectory task is formulated as the distance between the current location $x_{\cA_i}$ and reference waypoint $ q_t$ at next time step.
    \item[Online tasks $\{O_1,O_2,\ldots\}$]:
    \begin{equation}
        w_{\cA O_j}(x_{\cA_i})=(d(q_{O_j},x_{\cA_i})+\epsilon)\inverse.
    \end{equation} 
    Weight of the online task $O_j$ is formulated as the distance between the current location $x_{\cA_i}$ and task location $q_{O_j}$.
\end{description}
Notice that, in all cases, the weights satisfy the property $w_{ij}\leq \epsilon\inverse$.

Our goal is to compute the coefficients $\vct{\alpha}$ in a distributed manner.
 We first show a distributed solution for problem \eqref{eq:original_problem} when we have an equal number of agents and tasks ($\abs{\cA} = \abs{\cT}$); we extend the solution for other cases ($\abs{\cA} \neq \abs{\cT}$) in later sections.
 

\subsection{Distributed optimization problem formulation for the square case ($\abs{\cA} = \abs{\cT}$)}\label{sec:square_case}

When the number of agents and tasks (including both trajectory and online) is the same, i.e.,  $\abs{\cA} = \abs{\cT}$, the problem can be written in matrix form (dropping the subscript $\cA$ to simplify the notation) as:
\begin{subequations}\label{eq:nXn_problem}
\begin{align}
    \min_{0\leq \pmb\alpha \leq 1} &-\sum_i (\vw_i\transpose \pmb\alpha_i)\\
    \subjectto & \pmb\alpha \vct{1}=\vct{1} \label{eq:all_task_assigned}\\
    & \vct{1}\transpose \underbrace{\pmb\alpha_{\vct{e}_j}}_{\pmb\alpha_j}= 1 \quad
\forall j\in \cT
\end{align}
\end{subequations}
where $\pmb\alpha_j\defeq\pmb\alpha_{\vct{e}_j}$ is the $j$-th columns of $\pmb\alpha$, and $\pmb\alpha_i$ is the $i$-th row of $\pmb\alpha$.

Our strategy is to rewrite the problem in a separable form and introduce distributed computations for parts that involve constraints over all the agents. Following the ADMM framework \cite{Boyd2011}, we separate the problem in two parts:
\begin{subequations}\label{eq:square-problem}
\begin{align}
\min_{0\leq \pmb\alpha \leq 1}  & \sum_i f_i(\pmb\alpha_i) + g(\vz)\\
\subjectto & \pmb\alpha = \vz
\end{align}
\end{subequations}
where
\begin{align}
&f_i(\pmb\alpha_i) = - \vw_{i}\transpose \pmb\alpha_{i} \label{eq:individual_problem}\\
&\textrm{dom}f = \{ \pmb\alpha_{i}| \pmb\alpha_{i}\transpose\vct{1}=1,  0\leq \pmb\alpha \leq 1\} \label{eq:individual_constraint}
\end{align}
\begin{equation}\label{eq:consensus_problem}
	g(\vz)=\begin{cases}
	0 & \textrm{ if } \vz\transpose \vec{1} = \vec{1}\\
	-\inf & \textrm{ otherwise.}
	\end{cases}
\end{equation}

The Lagrangian of the problem can be written as: 
\begin{equation}
	\cL(\pmb\alpha,\vz,\vu) = \sum_i f_i(\pmb\alpha_i) + g(\vz) + (\rho/2) \norm{\pmb\alpha-\vz+\vu}_2^2
\end{equation}

To deal with the non-separable constraint (\ref{eq:agent total}) and separable constraints \eqref{eq:primary task} and \eqref{eq:optional tasks}, we rewrite them in the form of \eqref{eq:individual_constraint}, \eqref{eq:consensus_problem}. The local constraint (\ref{eq:individual_constraint}), which is the replacement of (\ref{eq:agent total}), enforces that each agent is assigned exactly to a single task in $\cT$. 
The separable constraint (\ref{eq:consensus_problem}) replaces \eqref{eq:primary task} and \eqref{eq:optional tasks} which enforces that each task is assigned to exactly one agent.

The ADMM framework then proceeds with iterations through the following steps:
\begin{enumerate}
	\item $\pmb\alpha$-update:
	\begin{equation}
	\begin{aligned}
	\pmb\alpha \gets \argmin_{\pmb\alpha} &-\sum_{i=1}^n \vw_{i} \pmb\alpha_{i}\transpose + (\rho/2) \norm{\pmb\alpha-\vz^k+\vu^k}_2^2\\
	\subjectto &\pmb\alpha\transpose\vec{1}=1\\
	&\vec{0}\leq\pmb\alpha\leq\vec{1}
	\end{aligned}
	\end{equation}
	The optimization problem is separable, and the local objective for agent $i$ can be written as a QP problem:
	\begin{equation}
	\begin{aligned}
	\min_{\pmb\alpha_{i}} & \quad \frac{1}{2}\pmb\alpha_{i}\transpose \pmb\alpha_{i} + (-\vz_i^k+\vu_i^k-\frac{\vw_{i}}{\rho})\transpose\pmb\alpha_{i}\\
	\subjectto &\quad \vct{1}\transpose\pmb\alpha_i=1\\
	&\quad \vec{0}\leq\pmb\alpha\leq\vec{1}.
	\end{aligned}
	\end{equation}
	Each agent can compute its part of the solution independently.
	
    \item $\vz$-update:
	\begin{equation}\label{eq:z_update}
	 \vz \gets \argmin_{\vz\transpose \vct{1} = \vct{1}} \sum_{j= 1}^m\frac{1}{2}\norm{\vz-(\pmb{\alpha}^{k+1}+\vu^k)}^2
	\end{equation}
	
	This problem is separable over $\vz_j$, the columns of $z$, i.e., over tasks. Each sub-problem (i.e., the solution for  task $j$) can be formulated as:
	\begin{subequations}\label{eq:z_update_reform}
	\begin{align}
	\min & \frac{1}{2}\norm{\vz_j-\pmb\alpha_j^{k+1}-\vu_j^k}^2\label{eq:z_update_reform_obj}\\
	\subjectto & \vct{1}\transpose\vz_j=1\label{eq:z_update_reform_constraint}
	\end{align}
	\end{subequations}
	where $\vz_j$, $\pmb\alpha_j$ and $\vu_j$ are all $j$th column of the corresponding matrices.
	The objective can be written as $\sum_i (\vz_{ij}-\pmb\alpha_{ij}-\vu_{ij})^2$, which is separable over agents, but the constraint is not, so we cannot directly solve this step in a distributed way. However, we show in Section \ref{sec:distributed_computation_of_z} that this can be solved using \emph{projected gradient descent}.
\item $\vu$-update:
\begin{equation}
\vu_i \gets \vu_i^k + \pmb\alpha_i^{k+1} - \vz_i^{k+1}
\end{equation}
Each multiplier $\vu$ update only needs information that is local to the node, so this step can be executed independently at each node. 
\end{enumerate}

\subsection{Distributed $\vz$-update}\label{sec:distributed_computation_of_z}
This subsection introduces the implement how the proximal update helps to solve~\eqref{eq:z_update} in a distributed fashion. When the communication graph $G_p$ is connected,~\eqref{eq:z_update_reform} can be approximately solved using a distributed projected gradient descent, where each robot requires only information from its neighbors.


% \rtron{This Lemma is a subset of the theory of [19]}
% \begin{lemma}[Projected gradient descent]\label{remark:Projected_gradient}
% 	Let $\Omega$ be a convex set of constraints on a state vector $y$ and let $f$ be a convex function that needs to be minimized. The  iteration $y[k+1]=\proj_\Omega(y[k]-\epsilon \Gamma \grad_y f(y[k]))$ converges to the constrained minimum for $\Gamma\succ 0$. 
% \end{lemma}
% See \cite{bertsekas2000gradient} for a proof.

\begin{lemma}\label{lemma:keep_constraint_valid}
The iterations $y[k+1]=y[k]+Lv[k]$ satisfy $\vct{1}y[k]=\vct{1}\transpose y[0]$ for all $k$. 
\end{lemma}
\begin{proof} Using the properties of the Laplacian matrix in Lemma \ref{lemma:laplacian properties}, we have the following invariant:
$\vct{1}\transpose y[k+1]=\vct{1}\transpose y[k]+\vct{1}\transpose Lv[k]=\vct{1}\transpose y[k]$, from which the claim follows.
\end{proof}

The \emph{gradient} of problem (\ref{eq:z_update_reform}) can be computed in a distributed manner, we simply have
$\grad_{\vz_j}\cL=(\vz_j^k-\pmb\alpha_j^{k+1}-\vu_j^k)$.

Thus, by iterating 
\begin{multline}\label{eq:z_update_distributed}
\vz_j[k'+1]=\vz_j[k']-\varepsilon L\grad_{\vz_j} \cL\\
=\vz_j[k']-\varepsilon L (\vz_j[k']-\pmb\alpha_j^{k+1}-\vu_j^k)\\
=(I-\varepsilon L)\vz_j[k']+\varepsilon L(\pmb\alpha_j^{k+1}+\vu_j^k)
\end{multline}
we show that
\begin{itemize}
	\item $\vz[k']$ converges to the desired solution of \eqref{eq:z_update};
	\item Each step is distributed.
\end{itemize}

The update for each node can be written as the sum of contributions over its neighbors. Note that for any state vector $v$, from the definition of Laplacian in~\cref{def:laplacian_matrix}, we have
\begin{equation}\label{eq:Lv}
L\vv=(D-A)\vv=D\vv-A\vv;
\end{equation}
Considering only the $i$-th entry, the righthand side of \eqref{eq:Lv} becomes
\begin{equation}
d_iv_i-\sum_{j:\ijE} a_{ij} v_j,
\end{equation}
where $d_i=\sum_{j:\ijE} a_{ij}$, and we can write \eqref{eq:z_update_distributed} for each agent as 
\begin{multline}
\label{eq:z_update_distributed_agent}
\vz_j[k'+1]=\vz_j[k']+\\
\varepsilon\sum_{\ijE}\bigl(\vz_j[k']-2(\vz_j[k']-\pmb\alpha_j[k]-\vu_j[k])\bigr) 
\end{multline}
Note the different time index for $\pmb\alpha_j$ and $\vu_j$ ($k$ instead of $k'$): this is because $\pmb\alpha_i$ and $\vu_i$ are constant while we update the $\vz_i$'s. 

In \cref{app:proof}, we show that a single iteration of~\eqref{eq:z_update_distributed} is enough to guarantee $z$ converge to its optimal value. While in practice, we empirically found that~\eqref{eq:z_update_distributed} can be repeated multiple times to accelerate convergence. The number of iterations for~\eqref{eq:z_update_distributed} is then a trade-off between computation time and communication overhead. For instance, simulations in~\cref{sec:simulation} show that five iterations of the $z$-update represent an effective balance in the particular setting considered.

%we only run a few iterations of \eqref{eq:z_update_distributed} in each ADMM iteration (5 iterations in simulation \ref{sec:simulation}). Although \eqref{eq:z_update_reform_obj} decreases monotonically with each iteration, the impact of an inexact solution on the ADMM will not be discussed in this paper.

\subsection{Shadow agents and secondary trajectory tasks}
The distributed solution of problem~\eqref{eq:nXn_problem} is based on \cref{lemma:keep_constraint_valid} which requires that $\pmb\alpha$ is a square matrix and $\vct{1}\transpose \pmb \alpha = \vct{1}$. 
This cannot be the case when the number of robots and tasks are not equal (i.e. $\abs{\cA} \neq \abs{\cT}$). 
For these cases, we introduce the concepts of \emph{secondary trajectory task} (when $\abs{\cA}>\abs{\cT}$) and \emph{shadow agent} (when $\abs{\cA}<\abs{\cT}$), which allow us to reformulate the general assignment problem \eqref{eq:original_problem} to square case introduced in \cref{sec:square_case}. %\ref{eq:nXn_problem} for a easier distributed computation.

\subsubsection{Secondary trajectory tasks}

For cases where the number of agents is larger than the number of tasks (i.e. $\abs{\cA} > \abs{\cT}$), we introduce \emph{secondary trajectory tasks} $P'=\bigcup_j P'_j$, where $\abs{P'} = \abs{\cA} - \abs{\cT}$, to capture the marginal gains of having more than one agent following the planned trajectory. The modified weight matrix is denoted as $\tilde{\pmb W}$.

To ensure correctness, the weight for $P'$ should be lower than all the weights of the online tasks, as well as the trajectory task $P$; specifically, we propose $w_{iP'_j}(x_{\cA_i})=(d(P,x_{\cA_i})+\epsilon')\inverse$, where $\epsilon'\gg\epsilon$, and $\epsilon'$ is significantly larger than the maximimum distance between any agent and objective targets (i.e. $\epsilon \gg \max_{\forall O,\forall x}d(O,x)$).
\begin{proposition}
    The introduction of $P'$ will not alter the assignment of $P$ and $O$ in the original problem.
    % Agents in $\cA$ will be assigned to $P'$ only if all tasks in $P$ and $O$ are taken.
\end{proposition}
\begin{proof}
    Let $\pmb W, \pmb \alpha_o$ be the weights and optimal solution for the rectangular problem~\eqref{eq:original_problem}, and $\tilde{\pmb W},\tilde{\pmb\alpha}$ be the set of weights and optimal solution for the square problem~\eqref{eq:nXn_problem}. Note that $W$ is a subset of the entries of $\tilde{\pmb W}$. Let $\tilde{\pmb \alpha}_o$ be the result $\pmb \alpha_o$ extended in a way such that the unassigned agents are assigned to $P'$; note that $\pmb \alpha_o$ is a subset of $\tilde{\pmb \alpha}_o$.

    To prove the claim, we want to prove that $\tilde{\pmb \alpha}=\tilde{\pmb \alpha}_o$.
    Then, by way of contradiction, assume that there exist a solution of $\tilde{\pmb \alpha}\neq \tilde{\pmb \alpha}_o$ that gives a better cost, i.e., 
    \begin{equation}
        \trace(\tilde{\pmb W}\transpose\tilde{\pmb \alpha})>\trace(\tilde{\pmb W}\transpose\tilde{\pmb \alpha}_o)\label{eq:assumption for contradiction}
    \end{equation}
    and the two solutions differ from each other only by two agents: $\cA_1$ is unassigned in $\alpha_o$, but is assigned to $P$ in $\tilde{\alpha}$; conversely, $\cA_2$ is assigned to $P$ in $\alpha_o$, but is assigned to $P'_1$ in $\tilde{\alpha}$. This yields:
    % Take the difference between the two costs, 
    % \begin{equation} \label{eq:cost difference}
    %     \trace(\tilde{W}\transpose\tilde{\alpha})-\trace(\tilde{W}\transpose\alpha_o), 
    % \end{equation}
    \begin{multline}\label{eq:counterproof2}
        \trace(\tilde{\pmb W}\transpose \tilde{\pmb\alpha})\geq tr(\tilde{\pmb W}\transpose \tilde{\pmb\alpha}_o) \Longrightarrow \\  (w_{P}(x_{\cA_1})+w_{P'_1}(x_{\cA_2}))\geq(w_{P'_1}(x_{\cA_1})+w_{P}(x_{\cA_2})).
    \end{multline}

   However, from the fact that $\alpha$ is optimal for problem~\eqref{eq:original_problem}, $w_{P}(x_{\cA_1}) < w_{P}(x_{\cA_2})$; and from the assumption of $\epsilon\gg\epsilon$, $w_{P'_1}(x_{\cA_1})$ and $w_{P'_1}(x_{\cA_2})$ are sufficiently small and do not alter this inequality. This leads to a contradiction for~\eqref{eq:counterproof2}, hence $\alpha'=\tilde{\alpha}$ and the claim is proven.  Similarly, since the weights of secondary trajectory tasks are sufficiently small, any case involving an alteration in the assignment of $O_n$ or changes to more than one pair of assignments will contradict the optimality of problem~\eqref{eq:original_problem}.
\end{proof}
\subsubsection{Shadow agent}
For cases where the number of agents is smaller than the number of tasks (i.e. $\abs{\cA} < \abs{\cT}$), we introduce a set of \emph{shadow} agents $\cS^{\cA_i}=\bigcup_l \cS^{\cA_i}_{l}$, where $\abs{\cS^{\cA_i}} = \abs{\cT}-\abs{\cA}$ and $\cS^{\cA_i}_{l}$ are virtual replicas of $\cA_i$ that are considered to have the same location and graph connectivity as $\cA_i$ (communications and computations are handled by the physical $\cA_i$). All the agents in $\cS^{\cA_i}$ can always communicate with physical agent $\cA_i$, and vice versa. If $\cA_i$ is connected with another physical agent $\cA_j$, then all the agents in $\cS^{\cA_i}_{i}$ can communicate with $\cA_j$. There might be more than one shadow agent for a single physical agent.

Assigning tasks to shadow agents means that the corresponding tasks are abandoned, and will not be performed by an actual agent. For simplicity, we let $\cS_l$ denote $\cS_l^{\cA_i}$. We define the weights of the shadow agents as 
\begin{description}
	\item[Trajectory task $P$]: $w_{SP}(x_{\cS_{l}})=-M$, where $M>2\epsilon\inverse$. Effectively, this implies that it is never advantageous, from the optimization perspective, to assign a shadow agent to the trajectory task.
	\item[Online tasks$\{O_j\}$]  $w_{SO_j}(x_{\cS_{l}})=-(d(O_j,x_{\cS_{l}})+\epsilon)\inverse$ This implies that assigning tasks to shadow agents (i.e., abandoning the tasks), from the optimization perspective, is never encouraged; moreover, farther tasks are more likely to be abandoned.
\end{description}

We now show that solving the problem with \emph{shadow agent}s is equivalent to solving it without. Since constraint~\eqref{eq:all_task_assigned} only ensures that there exists an agent $\cA$ (among regular agents $\cA$ or shadow agents $\cA_S$) that is assigned to $P$; we want to show that $a\in \cA$. 

\begin{proposition}
    Agents in $\cA_S$ will never be assigned to $P$ if $M>2\epsilon\inverse$.
\end{proposition}
\begin{proof}    
   By way of contradiction, assume $\pmb\alpha$ be an optimal solution where $\cS_{l}$ is assigned to $P$ with weight $w_{SP}(x_{\cS_{l}})=-M$. Correspondingly, the real agent $\cA_{i}$ corresponding to $\cS_{l}$ is assigned with an online tasks $O_j$, with weight $0<w_{\cA O_j}(x_{\cA_i})\leq \epsilon\inverse$. Consider a different solution $\tilde{\pmb{\alpha}}$, where $\cS_{l}$ is assigned to $O_j$ with weight $w_{SO_j}(x_{\cS_l})=w_{\cA O_j}(x_{\cA_i})$ and $\cA_{i}$ is assigned to $P$ with weight $w_{AP}(x_{\cA_i})$. Then we have
    \begin{multline}
        \trace(W\transpose \tilde{\pmb\alpha})-\trace(W\transpose\pmb\alpha) \\ 
        =w_{AP}(x_{\cA_i})-w_{SO_j}(x_{\cS_l})-(-M+w_{\cA O_j}(x_{\cA_i}))\\    
        =(M+w_{AP}(x_{\cA_i}))-2w_{\cA O_j}(x_{\cA_i}) \geq M-2\epsilon\inverse.
    \end{multline}
    Since $M>2\epsilon\inverse$, $\trace(W\transpose \pmb\alpha')-\trace(W\transpose\pmb\alpha)>0$, hence $\pmb\alpha$ is not optimal, leading to the contradiction. 
\end{proof}

\section{Online tasks in Co-observation secured map exploration task}\label{sec:application}
In this section, we apply the proposed task assignment algorithm within the co-observation-secured application introduced earlier in~\cref{sec:introduction}. This application builds on previous work in the field \cite{yangmulti,wardega2019resilience} to mitigate risks posed by physical masquerade attacks in multi-robot systems (MRS). Our solution incorporates co-observation and reachability constraints to ensure security while allowing robots to handle both pre-planned and online tasks. As illustrated in~\cref{fig:Flowchart}, the strategy is structured into three main sections:
\begin{figure*}[h]
	\centering
    %  \subfloat[Initial plan \label{fig:Example_case_init}]{\includegraphics[width=0.25\linewidth]{Figs/Example/Gridworld_example_0.png}}\hspace{1cm}
    \subfloat[Online tasks appear\label{fig:Example_case_task_appear}]{\includegraphics[width=0.28\linewidth]{Figs/Grid_world_example_1}}
    \subfloat[Online task 1 assigned\label{fig:Example_case_task_assigned}]{\includegraphics[width=0.28\linewidth]{Figs/Grid_world_example_2}}
    \subfloat[Co-observation\label{fig:Example_case_co-observation}]{\includegraphics[width=0.28\linewidth]{Figs/Grid_world_example_3}}
    % \subfloat[Regroup and continue\label{fig:Example_case_regroup}]{\includegraphics[width=0.24\linewidth]{Figs/Example/Grid world example 4.png}}
    \caption{ Online task 1 and 2 appear during the mission. (\ref{fig:Example_case_task_appear}) Green team only have no extra robot available to assign online task 2 with. The latest regroup time for black team do not allow a secure deviation for available online tasks. Thus, no task is assigned. (\ref{fig:Example_case_task_assigned},\ref{fig:Example_case_co-observation}) A safe regroup time is found for black team to fulfill online task 1, one robot got assigned with trajectory task for co-observation with green team. The other robot deviated for online task 1 is required to regroup at the pre-defined regroup time and location, and co-observe with the robot with trajectory task. }\label{fig:5_Example_set}
    \label{fig:Simulation-results}
\end{figure*}

\begin{itemize}
    \item \textbf{Regroup Time Calculation:} Determine whether an unassigned online task can be fulfilled while still satisfying a security condition given by \emph{reachability ellipsoid}; if this is possible, it computes the latest regroup time; this is illustrated in \cref{sec:regroup_computation}.
    \item \textbf{Task Assignment Algorithm} Apply the algorithm introduced in~\cref{sec:task_assignment} to find assignments of agents to trajectory and online tasks via distributed computations. % is implemented to ensure co-observation by assigning trajectory tasks and securely distributing online tasks among available robots.
    \cref{sec:task-assignment-security} discusses the reasons why solutions to the assignment never break the security guarantees given by co-observations.
    \item \textbf{Online Control Scheme} Use the \emph{CLF-QP} algorithm to compute reference control inputs and use CBF for \emph{Signal Temporal Logic (STL)} tasks as a security filter to guarantee the security of the system. 

    This part transforms the time and locations produced by the online assignment into \emph{spatial constraints} (follow a trajectory, or reach a given location) and \emph{timing constraints} (to avoid missing co-observation times).
    These constraints and their application to the real-time control of agents, are discussed in \cref{sec:control-design}
\end{itemize}
In this section, we first introduce the preliminaries in~\cref{sec:definition}; then the regroup time calculation is introduced in~\cref{sec:regroup_computation}; the CBF-CLF based online control scheme is introduced in~\cref{sec:CBF}.
\subsection{Preliminaries for co-observation-secured planning}\label{sec:definition}
In this section, we define the potential attacks faced by the MRS in the applied scenario and introduce the corresponding security requirements considered in the path planning phase. These requirements are then integrated into the online control problem in later sections to ensure the secure execution of unplanned online tasks.

\subsubsection{Forbidden region}
As part of our scenario, we assume that the environment contains \emph{forbidden regions} $\cF = \bigcup_k \cF_k$ in which none of the robots should enter (e.g. because they contain sensitive information or human operators). Forbidden region are modeled as convex polygons (shown as the red rectangle in~\cref{fig:5_Example_set}; one can use multiple, possibly overlapping, polygons for non-convex regions).

\subsubsection{Plan-deviation attacks}\label{app:attack-model}
We consider \emph{plan-deviation attacks} as introduced by~\cite{wardega2019resilience} to model potential threats to multi-agent systems. Specifically, we assume that a robot in the system has been compromised by an attacker who intends to violate the security constraints by entering forbidden areas undetected.
The attacker has full knowledge of the motion plan and aims to masquerade the compromised robot as a legitimate one.
The attacker intends to let the compromised robot perform deviations from the nominal plan and seek access to forbidden areas. 
We refer to these malicious deviations as plan-deviation attacks. An undetected plan-deviation occurs when a compromised robot deviates from the motion plan while providing a false self-report to the system about its location. Under our model, we consider such deviations to go undetected by the system as long as the self-reports of all other robots remain unchanged.

\subsubsection{Co-observation schedule}\label{sec:coobservation_intro}
The self-reports within the MRS is no longer reliable considering the potential of plan-deviation attacks. In previous works~\cite{wardega2019resilience,yang2021multi}, we proposed to leverage onboard sensing capabilities to integrate a mutual observation plan into the multi-agent trajectory. 
We assume that we are given a \emph{co-observation schedule}, a sequence of waypoints where two or more sub-teams of robots are required to meet (shown as dotted robots in~\cref{fig:5_Example_set}) such that, for each sub-team, any faulty or attacking agent breaching security specifications (i.e. in this case, trespassing forbidden region) would inevitably violate the plan, ensuring their actions are detectable. 

\subsubsection{Reachability region}
 Paired with the co-observation schedule, we introduced the concept of the \emph{reachability region} to analyze whether a compromised robot could reach any forbidden area between scheduled co-observation locations. The reachability region is defined as the set of all points in the free configuration space that a robot can feasibly reach while traveling from one co-observation location to the next one within the given time interval. For simplicity, this analysis assumes a robot with a first-order integrator model and a maximum velocity cap $v_{max}$, allowing us to over-approximate the reachability region by a \emph{reachability ellipsoid}.

\begin{definition}\label{sec:ellipsoidal definition}
    Consider a robot $i$ starting from $q_{1}$ at time $t_1$ and reaching $q_{2}$ at time $t_2$. The \textbf{reachability ellipsoid $\cE$} is defined as the region $\cE^{q_2}_{q_1} = \mathcal{E}(q_1,q_2,t_{1},t_{2})=\{\tilde{q}\in\mathbb{R}^n: d(q_1,\tilde{q})+d(\tilde{q},q_2)<2a\}$, where $a=\frac{v_{max}}{2}(t_2-t_1)$, and $d(\cdot,\cdot)$ denotes the Euclidean distance between two points.
\end{definition}

 If the reachability region does not intersect with any forbidden regions $\cE^{q_2}_{q_1}  \cap \cF = \emptyset$, it can be guaranteed that the robot starting at $(q_1,t_1)$ is unable to reach $(q_2,t_2)$ if it trespassed any forbidden region. 
    
Accordingly, we can provide a formal security guarantee against plan-deviation attacks for a multi-agent trajectory.
\begin{definition}\label{rmk:revised-security}
A multi-robot trajectory is secured against plan-deviation attacks if there exists a co-observation plan such that the reachability region between each consecutive co-observation does not intersect with any forbidden regions.
\end{definition}

\subsection{Regroup time Computation}\label{sec:regroup_computation}
When addressing unplanned tasks that require deviations from the planned trajectory, robots must ensure that these deviations do not compromise security.
We leverage the concepts of co-observation schedules and reachability regions to pose constraints on robots deviating and rejoining teams, as made rigorous in the following definition.
\begin{definition}
    A deviation for robot $\cA_i$ in team $\cA$, deviating from the trajectory at $(x_1, t_1)$, and rejoining it at $(x_2, t_2)$, is secured if the following conditions are met: \begin{enumerate}
    \item At least one other robot in the team $\cA$ remains on the planned trajectory between $t_1$ and $t_2$.
    \item The reachability region between $(x_1, t_1)$ and $(x_2, t_2)$  does not intersect any forbidden regions, i.e.,  $\cE^{x_2}_{x_2} \cap \mathcal{F} = \emptyset$.
    \end{enumerate}
\end{definition}

It becomes apparent from the definition that, at every step of a trajectory, an agent is free to deviate if it can rejoin its team quickly enough. We therefore introduce the following.
\begin{definition} 
    The \textbf{latest secured regroup time} for a deviation at $(x_1, t_1)$ is defined as the largest time $t_2\in [t_1,T]$ such that rejoining at $(x_2,t_2)$ can secure this deviation.
\end{definition}

To avoid complex online computation, we propose to map each waypoint $q_t$ with its latest secured regroup time $t^r_{q_t}$.%; this mapping is formalized below.
\begin{definition} 
    The \textbf{latest regroup time lookup table} $\{(q_t ,t^r_{q_t})\}^T_{t=1}$ maps each waypoint $q_t$ on the planned trajectory $\{\vq_p\}$ to its latest secured regroup time $t^r_{q_t}$.
\end{definition}

The lookup table can be built by applying \cref{alg:lookup_table} for each one of the $N_p$ reference trajectories.
\begin{algorithm}
    \caption{Lookup Table construction for sub-team $N_p$}
    \label{alg:lookup_table}
    \begin{algorithmic}[1]
    \Require Planned trajectory $\{\mathbf{q}_p\}$, forbidden regions $\mathcal{F}$
    \State \textbf{Initialization:} Lookup table $\mathcal{L}$
    
    \For{$i = 1$ to $T$} 
        \State $q_1 \gets q_i \in \{\mathbf{q}_p\}$
        \State $j \gets i+1$, $q_2 \gets q_j \in \{\mathbf{q}_p\}$
        \While{Section $(q_i,q_j)$ is secured ($\cE^{q_2}_{q_1} \cap \cF = \emptyset$) }
            \State $j \gets j+1$, $q_2  \gets q_j \in \{\mathbf{q}_p\}$
        \EndWhile
        \State $t_r \gets j-1$
        \State Store $\{(q_i, t_r)\}$ in $\mathcal{L}$
    \EndFor
    \end{algorithmic}
\end{algorithm}

The lookup table is used when an online task $O^n_j$ appears or remains unassigned in a previous time step. Agents check for the latest safe regroup time $t_r$ for the next timestep $t$: if $d(p_t,x_{O^n_j})+d(p_{t_r},x_{O^n_j})>v_{max}(t_r-t)$, $O^n_j$ is outside the reachability region $\cE_t^{t_r}$; thus, deviation for $O^n_j$ can not be secured, $O^n_j$ will not be assigned (\cref{fig:Example_case_task_appear}). Otherwise, $O^n_j$ is passed to the task assignment algorithm (\cref{fig:Example_case_task_assigned}).

Since the lookup table is precomputed and stored locally on each robot, once a task is assigned, all agents (both deviating and non-deviating) will be aware of the regroup time without explicit communications. 
% This ensures that attackers cannot modify the time (unless the entire sub-team is compromised).

\subsection{Online task assignment problem}\label{sec:task-assignment-security}
As shown in~\cref{fig:Flowchart}, after determined the secured regroup time, available tasks are updated and passed to the task assignment algorithm introduced in~\cref{sec:task_assignment}. The priorities in the assignment ensure that at least one agent will satisfy the trajectory task $P$ to fulfill the co-observation schedule, while the extra robots are assigned to available online tasks $O_j$ (\cref{fig:Example_case_co-observation}). 

Note that the overall security is maintained, and none of the robots will be able to reach the forbidden zones because:
    \begin{itemize}
    \item For the robots assigned to trajectory tasks $P$, this type of deviation would imply breaking the constraints imposed by the co-observation schedule.
    \item For the robots assigned to the online tasks $O_j$, this type of deviation would cause them to miss the implicit co-observation constraints with the rest of the team at the regroup location and time.
\end{itemize}

\subsection{Online Control Scheme}\label{sec:CBF}
The reference trajectories and co-observation requirements are defined in terms of waypoints in discrete time. To enable execution in continuous time for real-world scenarios, we propose an online control framework for each individual robot. In this framework, robots assigned to trajectory and secondary trajectory tasks follow their predefined secure paths, while robots assigned to online tasks move toward the task location, complete the task, and then return to the reference trajectory. Additionally, to maintain security, the framework ensures that robots following trajectory tasks reach their designated co-observation locations within the required time, while robots performing online tasks must return to their trajectory and rejoin the group before the regroup time.

\subsubsection{Robot dynamics}
Consider robots with an affine-input dynamical system
\begin{equation}
\dot{x}=f(x)+g(x)u
\end{equation}
with $f$ and $g \neq 0$ locally Lipschitz continuous, $x \in \mathbb{R}^m$ represents the location of the robot and $u \in U \subset \mathbb{R}^{n}$ is the control input.

\subsubsection{Navigation and timing control constraints via CBF and CLF functions}
% In this application, we use CLF as navigation constraints to ensure that: \begin{itemize}
%     \item Robots assigned trajectory and secondary trajectory tasks follow their predefined secure trajectories;
%     \item Robots assigned to online tasks move toward the task location, complete the task, and then return to the reference trajectory.
% \end{itemize}

% And we use CBF timing constraints as security filters to ensure that: \begin{itemize}
%     \item Robots with trajectory tasks reach their co-observation locations within the required time; 
%     \item Robots with online tasks return to their trajectory and rejoin the group before the regroup time. 
% \end{itemize}
All assignments and security requirements can be represented as navigation and timing control constraints, which are formulated via CBF and CLF functions. The definitions of these functions are provided below.

Given a set $\mathcal{C}$ defined as $\cC=\{x\in\real{m},t\in\real{}_{\geq 0}:h(x,t)\geq 0\}$ for a continuously differentiable function $h(x):\mathbb{R}^{m}\times\real{}_{\geq 0} \rightarrow \mathbb{R}$. The function $h$ is called a \emph{CBF}, if there exists a class $\mathcal{K}$ function $\beta $ such that 
\begin{equation}\label{eq:CBF_constraint}
\sup_{u \in U} \frac{\partial h(x,t)}{\partial x}(f(x)+g(x)u)+\frac{\partial h(x,t)}{\partial t} +\beta(h(x,t)) \geq 0.
\end{equation}
In the following content, we denote $\frac{\partial h(x,t)}{\partial x}(f(x)+g(x)u)+\frac{\partial h(x,t)}{\partial t}$ as $\dot{h}(x,t)$ for simplicity. Controllers satisfying the CBF constraint~\eqref{eq:CBF_constraint} ensure that the set $\cC$ remains \emph{forward invariant}. This means that if the initial state satisfies $x(0)\in \cC$, the state remains in $x(t)\in \cC, \forall t>0$.

In this application, we use CBF timing constraints as security filters to ensure that: \begin{itemize}
    \item Robots with trajectory tasks reach their co-observation locations within the required time; 
    \item Robots with online tasks return to their trajectory and rejoin the group before the regroup time. 
\end{itemize}

Similarly, consider a continuously differentiable positive definite function $V : \real{m}\rightarrow \real{}$. $V$ is called a \emph{CLF} if there exist a class $\cK$ function $\gamma$, such that:
\begin{equation}
    \inf_{u\in U} [L_f V(x) + L_g V(x)u + \gamma(V(x))] \leq 0.
\end{equation}
% Controllers satisfying the CLF constraint~\eqref{eq:CBF_constraint} ensure the stability of the system.
In this application, we use CLF as navigation constraints to ensure that: \begin{itemize}
    \item Robots assigned trajectory and secondary trajectory tasks follow their predefined secure trajectories;
    \item Robots assigned to online tasks move toward the task location, complete the task, and then return to the reference trajectory.
\end{itemize}

\subsubsection{CLF functions for navigation}
We define the CLF as $V_t(x) = d(x,q_i)$ for trajectory task and secondary trajectory tasks, where $q_i \in \vq$ is the planned waypoint for the next timestep. Since the reference trajectory is in discrete time, $V_t$ remain the same for $t\in [i-1,i)$, and switch for the next reference point $V_t(x) = d(x,q_{i+1})$ for $t\in[i,i+1)$. And $V_{O_j}(x) = d(x,x_{O_j})$ is the candidate CLF for online tasks. 

\subsubsection{CBF functions via STL}
% \subsubsection{Signal Temporal Logic (STL)}
Both trajectory and online task security requirements are enforced through co-observations at specific times and locations. For trajectory tasks, co-observations occur between sub-teams based on the co-observation schedule. For online tasks, they occur within a sub-team, ensuring the returning robot is observed at the regroup time along the reference trajectory. This also adds additional co-observation requirements for the trajectory task robot. For online control, we use STL to formally encode these tasks with strict deadlines, ensuring their satisfaction through Control Barrier Functions (CBFs)~\cite{lindemann2018control}.

A predicate $\mu$ is derived from evaluating a function $h:\real{m}\rightarrow \real{}$ as:
\begin{equation*}
    h(x)\coloneqq \begin{cases}
        \text{True}& \text{if } h(x)\geq 0, \\
        \text{False} & \text{if } h(x) <0.
    \end{cases}
\end{equation*}
The STL syntax defines a formula as:
\begin{equation*}
    \phi ::= \text{True} | \mu | \neg \phi | \phi_1 \wedge \phi_2 | \phi_1 \textbf{U}_{[t_1,t_2]} \phi_2,
\end{equation*}
where $\phi_1$ and $\phi_2$ are STL formulas and $t_1,t_2\in\real{}_\geq0$ with $t_2>t_1$. Notice that $\textbf{F}_{[t_1,t_2]}\phi$ and $\textbf{G}_{[t_1,t_2]}\phi$ can be defined in terms of $\textbf{U}$, thus are omitted in this formula.

In this paper, we consider the following STL fragment:
\begin{align}
    &\psi ::= True | \mu | \neg \mu | \psi_1 \wedge \psi_2 ,\\
    &\phi ::= G_{[a,b]} \psi | F_{[a,b]} \psi | \psi_1 U_{[a,b]} \psi_2 | \phi_1 \wedge \phi_2,
\end{align}
where $\psi$ defines state-based conditions that involve only Boolean logic with $\psi_1$ and $\psi_2$ are formulas of $\psi$. While $\phi$ defines temporal properties that are built from class $\psi$, and $\phi_1$ and $\phi_2$ are formulas of the temporal operators.

To better handle these requirements via CBF, we model each individual requirement, i.e. co-observation at location $q$ at time $c$, using STL formulas. The formula $\phi_i$ is defined as:
\begin{equation}
\phi_i := \phi_{i1} \wedge \phi_{i2},
\end{equation}
 where:
 \begin{itemize}
    \item $\phi_1 := F_{[0,c]} \psi$ to ensure that the robot maintains the capability of  reaching the scheduled co-observation location on time,
    \item and $\phi_2 := G_{[c,c]} \psi$ to ensure that the robot arrives at co-observation exactly at the scheduled time,
    \item $\psi := (d(x,q)\leq r_1) \wedge (d(x,x')\leq r_2)$, where $d:\real{m}\times\real{m}\rightarrow \real{}$, as the Euclidean distance between locations, i.e. $d(x_1,x_2) = \norm{x_1-x_2}_2^2$. $x'$ being the location of the other robot for the co-observation and $r_1$, $r_2$ being the maximum offset allowed.
 \end{itemize}
Since the co-observation locations are fixed, we omitted the term $\norm{x-x'}\leq r_2$ for simplicity. Multiple co-observation requirements are combined through conjunctions, for example, $\phi = \phi_1 \wedge \phi_2 \wedge \phi_3$.

\subsubsection{Controller framework}\label{sec:control-design}
For implementation, the CLF-based controller is used to apply the trajectory tracking and online task target tracking requirements. 
On the other hand, the CBF-based security filter is used to apply security-related requirements. Using the CBF design method for STL tasks introduced in~\cite{lindemann2018control}, we design the CBF for simple temporal operators. Consider formula $F_{[a,b]} d(x,q)\leq r$, the candidate CBF is designed as:
\begin{equation}
    h(x,t) =\gamma_1(t) + \frac{r - d(x,q)}{v_{max}},
\end{equation}
where $v_{max}$ is the maximum speed for robot
\begin{equation}
    \gamma_1(t) = -\frac{a}{b}t+a.
\end{equation}

For formula $G_{[a,b]} d(x,q)\leq r$, the candidate CBF is designed as:
\begin{equation}
    h(x,t) =\gamma_2(t) + r - d(x,q),
\end{equation}
with 
\begin{equation}
    \gamma_2(t) = \mu e^{-\epsilon t} - \sigma,
\end{equation}
where $\epsilon$ is the decay rate to be designed, $r_1$  is a sufficiently small offset variable that ensures the function $\gamma_2(t)\leq 0$ for all $t\in [a,b]$, and $\mu= r_1 e^{\epsilon a}$. 

For conjunctions $\phi_1 \wedge \phi_2$, the candidate CBF is designed as follows:
\begin{equation}
    h(x,t) = -ln(e^{-h_1(x,t)} + e^{-h_2(x,t)}),
\end{equation}
where $h_1$ and $h_2$ are candidate CBF for $\phi_1$ and $\phi_2$ respectively.

To avoid conservatism and potential conflicts arising from multiple constraints, we focus solely on the CBF for the next scheduled co-observation and regroup co-observation. Once a co-observation is fulfilled, the corresponding CBF is deactivated.

We then propose to first solve the following local constrained optimization problem to get the optimal reference control law $u_{ref}$, for robot $i$, we have
\begin{equation}
\begin{aligned}
u_{ref}=&\argmin_{u_i\in U}&& u\transpose Q u \\
        & s.t.&& L_f V_t(x) + L_g V_t(x)u + \gamma(V(x))\\ 
        &    && \qquad \qquad \leq (1-\alpha_{iP}+\sum_j \alpha_{iP'_j})\cM \\
        &     && L_f V_{O_j}(x) + L_g V_{O_j}(x)u + \gamma(V(x))\\
        &     && \qquad \qquad \leq (1-\alpha_{iO_j})\cM, \quad \forall \{O_j\}.
 \end{aligned}
\end{equation}
where $Q\in\real{n\times n}$ is a positive semi-definite weight matrix, and $\alpha_{i,P}$, $\alpha_{i,P'}$ and $\alpha_{i,O_j}$ are the assignment coefficient of robot $i$ for trajectory tasks, secondary trajectory task and online tasks respectively. Since the assignment algorithm in \cref{sec:task_assignment} requires multiple iterations for convergence, the assignment result $\alpha_{ij}$ isn't always strictly $0$ or $1$.  To manage constraint prioritization, we introduce a sufficiently large penalty constant $\cM$, which is combined with the assignment coefficients. When $\alpha_{ij}$ is close to 1, the right-hand sides of the constraints approach $0$, giving higher priority to the corresponding CLF. Conversely, when $\alpha_{ij}$ approaches $0$, the CLF has lower priority. 

Then we use CBF as a security filter:
\begin{subequations}
    \begin{align}
        \min_{u\in U} & \quad (u-u_{ref})\transpose (u-u_{ref})&\\
        s.t. & \dot{h}_{O_j}(x,t) + \beta_T(h_{O_j}(x,t))\geq -(1-\alpha_{iO_j})\cM, \quad \forall \{O_j\} \\
            & \dot{h}_{P}(x,t) + \beta_T(h_{P}(x,t))\geq -(1-\alpha_{iP})\cM \\
            &\dot{h}_{O_j}(x,t) + \beta_T(h_{O_j}(x,t))\geq -(1-\alpha_{iP})\cM \\
            & L_f h_c(x) + L_g h_c(x)u + \beta_c(h_c(x))\geq 0, 
    \end{align}
\end{subequations}
where $h_{O_j}$ is the candidate CBF for regroup co-observation associated with online task $O_j$, $h_{P}$ is the candidate CBF for the next scheduled co-observation, and $h_c$ represents CBF for collision avoidance and other time-invariant safety requirements~\cite{Li2017CBF}.

By using the two-step approach above (computation of the reference, followed by a security filter), the CLF constraints are relaxed while prioritizing the CBF constraints to maintain security. For example, when a robot gets blocked while executing an online task and a detour will cause it to miss the regroup co-observation, the robot prioritizes the regroup and abandons the online task.

\section{Simulation}\label{sec:simulation}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth,trim = 1cm 1cm 1cm 1cm, clip]{Figs/OfflineMaping_v2}
    \caption{Secured 3-team reference path generated offline, region 1 is a forbidden region and region 2 is an obstacle.}\label{fig:PrePlanedPath}
\end{figure}

\begin{figure*}[h]
    \centering
    % \subfloat[Pre-generated reference trajectory for three sub-teams.\label{fig:PrePlanedPath}]{\includegraphics[width=0.4\linewidth,trim = 1cm 1cm 1cm 1cm, clip]{Figs/OfflineMaping_v2}}
    % \quad
    \subfloat[Time $t=12$. Agent 1 has been assigned to online task 1 while agent 2 and 3 follow the trajectory. \label{fig:t=12}]{\includegraphics[width=0.3\linewidth,trim = 1cm 1cm 1cm 1cm, clip]{Figs/t12_v2}}
    \quad
    \subfloat[Time $t=20$. Agent 1 gets back to the trajectory and agent 2 has been assigned to online task 2. \label{fig:t=20}]{\includegraphics[width=0.3\linewidth,trim = 1cm 1cm 1cm 1cm, clip]{Figs/t20_v2}}
    \quad
    \subfloat[Runtime simulation with online tasks appear during the mission. \label{fig:OnlineFullpath}]{\includegraphics[width=0.3\linewidth,trim = 1cm 1cm 1cm 1cm, clip]{Figs/OnlineControlResult_v2}}
    \caption{ 3 robots form blue sub-team (following the blue trajectory) in \cref{fig:PrePlanedPath} to deal with online tasks. Sign $\ast$ indicating fulfilled security-verified online tasks, and sign $\times$ indicating unassigned online tasks.}
\end{figure*}
    
In this section, the proposed strategy is tested using a map exploration secured with a co-observation schedule for three sub-teams. We assume that the environment is a square region with the coordinate origin $(0,0)$ located in the bottom-left corner and the edge length of $8$ units. In the test area, \emph{zone 1} is an obstacle and \emph{zone 2} is a forbidden area. All robots are set to have a maximum velocity of $0.5m/s$ with a total task time of $20s$. The reference trajectory is generated using the method in \cite{yang2021multi} alongside a co-observation plan: team $1$ and $2$ meet at time $8$ and $14$, while team $2$ and $3$ meet at time $18$. The reference trajectory and the environment setup are shown in~\cref{fig:PrePlanedPath}.

In real-time simulation, group $1$ has three robots in the sub-team while group $2$ and $3$ have one. We will focus on the task assignment performance and deadline setup for group 1. 

During the task period, two out of four \emph{online} tasks appeared have been fulfilled. When the mission first began, there were no \emph{online} tasks, and all agents were performing the trajectory task. When \emph{online} task $2$ appears and a secured regroup time was found at $t=24$ (as shown in~\cref{fig:t=12}), agent 1 was assigned with \emph{online} task 1. Meanwhile, agent 1 set up a deadline CBF to guarantee the return to reference trajectory before the \emph{regroup} time. 

When \emph{online} task 1 and 3 appear and are sent to the assignment algorithm later (as shown in~\cref{fig:t=20}), \emph{online} task 1 is assigned to agent 2, while task 3 is assigned to a shadow agent due to an insufficient number of agents (agent 3 was assigned to \emph{trajectory} task and agent 1 was still working on getting back to the reference trajectory). Online task 4 is never sent to the assignment process because it is always outside the secure reachability regions. 

During the entire task process, agent 3 strictly follows the trajectory and the co-observation schedule to vouch for the security of the team. The final result is shown in~\cref{fig:OnlineFullpath}. Both the task and co-observation had been satisfied, and when agents separate, they successfully return to the reference trajectory before the \emph{regroup} deadline.

\section{Conclusion and Future Work}\label{sec:Conclusion}
We proposed a distributed task assignment algorithm that dynamically allocates robots with different priorities. Using an inexact ADMM-based approach, the problem is decomposed into separable and non-separable subproblems, with the latter solved via projected gradient descent through local communication. This distributed formulation enables efficient coordination of security-related high-priority tasks and unplanned optional online tasks. We integrated this algorithm into a comprehensive framework that enables MRS to safely handle unplanned \emph{online} tasks, validated through real-time simulation. The proposed approach consists of a security analysis to determine whether an online task can be executed securely and, if so, the required time and location for the robot fulfilling it to return to the team. It also includes the distributed task assignment algorithm and an online controller that fulfills the assigned tasks while using a CBF-STL-based security filter to enforce security requirements.

In the future, we plan to investigate the effects of network topology changes during task execution. For instance, team composition may vary as robots join other sub-teams or move out of communication range while completing online tasks. We will further analyze the impact of these changes to ensure our approach remains robust and effective across different scenarios. Another future direction is the application of our algorithm to heterogeneous MRS. While robots can incorporate their specialization through local constraints, the current algorithm struggles with handling abandoned tasks when there are insufficient specialized robots to fulfill them. This limitation arises because the algorithm requires inserting shadow agents in advance. Addressing this challenge will be a key focus of our future work.

\appendix
\subsection{Proof of Distributed $\vz$-update}\label{app:proof}
First we consider the convergence of single iteration for \eqref{eq:z_update_distributed}. Single iteration of \eqref{eq:z_update_distributed} can transform \eqref{eq:z_update} into a Proximal Gradient step as:
\begin{equation}\label{eq:apgm}
    z^{k+1} \leftarrow \argmin_z g(z) + \frac{1}{\epsilon} \norm{z-(z^k - \epsilon\grad_{\vz_j}\cL)}.
\end{equation}
According to \cite{ma2016alternating}, for the optimization problem \eqref{eq:square-problem} (let $f(\alpha) = \sum_i f_i(\pmb\alpha_i)$ for simplicity),
% , for an optimization problem:
% \begin{equation}
%     \begin{aligned}
%         \min_{x,z} & f(x) + g(z) \\
%         \subjectto & Ax + Bz = b,
%     \end{aligned}
% \end{equation}
update step of variable $z$ with a step size of $\tau$ via:
\begin{multline}
    z^{k+1}:=\argmin_z g(z) +\\
     \frac{\rho}{2\tau}\norm{z-\left(z^k+\tau(x^{k+1}-z^k+u^k)\right)}_2^2.
\end{multline}
renders that:
\begin{equation}\label{eq:partialKKT}
    0\in  \partial g(z^{k+1}) + \frac{\rho}{\tau} (z^{k+1}-z^{k}) + \rho \transpose (z^{k+1}-z^k-u^{k+1}).
\end{equation}
Using the fact that $\partial g$ is a monotonic operator, \eqref{eq:partialKKT} can combined with the KKT condition $0\in \partial g(z^*)+ u^*$ to derive the condition:
% \begin{equation}
%     0\in \partial g(z^*)+B\transpose u^*, 
% \end{equation}
\begin{multline}\label{eq:z_update_trand}
    (z^{k+1}-z^*)\big((\frac{1}{\tau}(z^k-z^{k+1})-\\
    (z^k-z^{k+1})-(u^{k+1}-u^*))\big)\geq 0.
\end{multline}
And since regular $\alpha$-update for ADMM is used, which renders:
\begin{equation}
    0 \in \partial f(\alpha^{k+1}) + \rho (u^{k+1}-z^k+z^{k+1}).
\end{equation}
Similarly, combined with KKT condition $0\in \partial f(\alpha^*) -  \alpha^*$ yields:
\begin{equation}\label{eq:x_update_trand}
    (\alpha^{k+1}-\alpha^{k})\transpose ( (u^{k+1}-u^*)+(z^{k+1}-z^k))\geq 0.
\end{equation}
Combine \eqref{eq:z_update_trand} and \eqref{eq:x_update_trand} considering the fact that $\alpha^* =z^* $ and $u^{k+1}= u^k+\alpha^{k+1}-z^{k+1}$, we get:
\begin{multline}
    \frac{1}{\tau}(z^{k+1}-z^*)\transpose(z^k-z^{k+1}) + (u^k-u^{k+1})\transpose (z^k-z^{k+1}) \\+ (u^{k+1}-u^*)\transpose(u^k-u^{k+1})\geq 0
\end{multline}
Considering having $y^k=\bmat{\frac{1}{\sqrt{\tau}} z^k \\ u^k}$, and $y^* = \bmat{\frac{1}{\sqrt{\tau}} z^* \\u^*}$, we can rewrite this inequality as:
\begin{multline}
 (y^{k+1}-y^{*})\transpose (y^k-y^{k+1})\\
 =  (y^{k}-y^{*})\transpose (y^k-y^{k+1}) - \norm{y^k-y^{k+1}}_2^2\\
 \geq -(u^k-u^{k+1})\transpose (z^k-z^{k+1})
\end{multline}
which implies
\begin{multline}\label{eq:update2optimal}
    \norm{y^k-y^*}^2_2-\norm{y^{k+1}-y^*}^2_2 \\
    = 2(y^{k}-y^{*})\transpose (y^k-y^{k+1}) - \norm{y^k-y^{k+1}}^2_2 \\
    \geq  \norm{y^k-y^{k+1}}^2_2-2(u^k-u^{k+1})\transpose (z^k-z^{k+1})
\end{multline}
Set $\xi = \frac{1}{2}+\frac{\tau}{2}$, and $\tau<\xi<1$, using the Cauchy-Schwartz inequality, we can get
\begin{multline}
-2(u^k-u^{k+1})\transpose (z^k-z^{k+1}) \\\geq -\xi \norm{u^k-u^{k+1}}^2_2 - \frac{1}{\xi}\norm{z^k-z^{k+1}}^2_2
\end{multline}
making \eqref{eq:update2optimal}
\begin{multline}\label{eq:convergence}
    \norm{y^k-y^*}^2_2-\norm{y^{k+1}-y^*}^2_2 \\
    \geq  (1-\xi) \norm{u^k-u^{k+1}}^2_2 + (\frac{1}{\tau}-\frac{1}{\xi})\norm{z^k-z^{k+1}}^2_2\\
    \geq \eta \norm{y^k-y^{k+1}}
\end{multline}
where $\eta = \min\{ (1-\xi), (\frac{1}{\tau}-\frac{1}{\xi})\}$.
From \eqref{eq:convergence}, it can be implied that $\norm{y^k-y^{k+1}}^2_2\rightarrow 0$, and $\norm{y^k-y^*}^2_2$ is monotonically non-increasing and thus converges. Thus, if the proximal gradient step $\epsilon < 1$, $z^k$ provided by \eqref{eq:z_update_distributed_agent} will converge to optimal solution $z^*$.
{\small
\bibliographystyle{IEEEtran}
\bibliography{ADMM_planning,ACC,task_assignment}
}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figs/ProfilePhoto.jpg}}]{Ziqi Yang} received the B.S. degree in Automation from Harbin Institute of Technology, Harbin, China in 2015, the M.Eng. degree in Electrical and Computer Engineering from Cornell University, Ithaca, NY, USA in 2017, and the Ph.D degree in Systems Engineering from Boston University, Brookline, MA, USA in 2023. He is currently a Research Fellow at the School of Electrical and Electronic Engineering at Nanyang Technological University.
% His current research interests include nonlinear control, planning and optimization, with an emphasis on system safety and security.
%     \end{IEEEbiography}
%     \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figs/Tron_bio.png}}]{Roberto Tron}
%         received the B.Sc. degree in 2004
%         and the M.Sc. degree (highest honors) in 2007 both in telecommunication engineering from the Politecnico di Torino, Turin, Italy, the Diplome dEngenieur from the Eurecom Institute, Biot, France, and the DEA degree from the Universit de Nice Sophia-Antipolis, Nice, France in 2006, and the Ph.D. degree in electrical and computer engineering from The Johns Hopkins University, Baltimore, MD, USA, in 2012. He was a Postdoctoral Researcher with the GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA, until 2015. He is an Associate Professor of Mechanical Engineering and System Engineering with Boston University, Boston, MA, USA. His research interests include the intersection of automatic control, robotics, and computer vision,  with a particular interest in applications of Riemannian geometry and linear programming in problems involving distributed teams of agents, or geometrical and spatio-temporal constraints. Dr. Tron was recognized at the IEEE Conference on Decision and Control with the General Chairs Interactive Presentation Recognition Award, in 2009, the Best Student Paper Runner-up in 2011, and the Best Student Paper Award in 2012.
%     \end{IEEEbiography}

\end{document}
