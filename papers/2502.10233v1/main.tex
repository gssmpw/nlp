% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{xcolor}
\usepackage{bm}

\usepackage{mathtools}
\usepackage{esvect}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{rotating}
\usepackage{subcaption} % For subfigures
\usepackage{threeparttable}
\usepackage{calc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{setspace}  % Package to control line spacing
\usepackage{bbm}
% for tables
\usepackage{colortbl}
\aboverulesep=0pt
\belowrulesep=0.20pt
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:

\usepackage[hidelinks]{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\usepackage{cleveref}

\newcommand{\SetOfLocationsIncludePickItem}[1]{\mathcal{V}_{\!#1}^\text{S}}
\newcommand{\SetOfSKUs}{\mathcal{P}}
\newcommand{\SetOfAllNodes}%{\mathcal{V}^{\text{L}}}
{\mathcal{V}}
\newcommand{\SetOfPackingStations}{\mathcal{V}^{\text{D}}}
\newcommand{\SetOfStorageLocations}{\mathcal{V}^{\text{S}}}
\newcommand{\NumTours}{\mathcal{B}}
\newcommand{\SetOfShelves}{\mathcal{V}^{\text{R}}}
\newcommand{\SetOfAgents}{\mathcal{M}}

\newcommand{\logits}{L}
\newcommand{\curragent}[1]{{\Omega_{#1}}}
\newcommand{\PermOverL}{{\Omega(\logits)}}


\newcommand{\finalNodeEmb}[1]{\bm{h}^{L}_{#1}}
\newcommand{\shelfPolicy}{g^{\mathcal{V}}_{\theta}}
\newcommand{\SKUPolicy}{g^{\mathcal{P}}_{\theta}}
\newcommand{\subActionSpace}{\mathcal{A}_d}
\newcommand{\numagents}{{M}}
\newcommand{\agentidx}{{m}}

\newcommand{\embdim}{{D}}


\begin{document}
\vspace{-2cm}
\title{Learning to Solve the Min-Max \\ Mixed-Shelves Picker-Routing Problem \\ via Hierarchical and Parallel Decoding}
\authorrunning{Luttmann, Xie}
\titlerunning{Hierarchical and Parallel Decoding for Picker-Routing}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%

%
\author{Laurin Luttmann\inst{1} \and
Lin Xie\inst{2}}
%

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Leuphana University, LÃ¼neburg, Germany \and
Brandenburg University of Technology, Cottbus, Germany}
%

\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The Mixed-Shelves Picker Routing Problem (MSPRP) is a fundamental challenge in warehouse logistics, where pickers must navigate a mixed-shelves environment to retrieve SKUs efficiently. Traditional heuristics and optimization-based approaches struggle with scalability, while recent machine learning methods often rely on sequential decision-making, leading to high solution latency and suboptimal agent coordination. In this work, we propose a novel hierarchical and parallel decoding approach for solving the min-max variant of the MSPRP via multi-agent reinforcement learning. While our approach generates a joint distribution over agent actions, allowing for fast decoding and effective picker coordination, our method introduces a sequential action selection to avoid conflicts in the multi-dimensional action space. Experiments show state-of-the-art performance in both solution quality and inference speed, particularly for large-scale and out-of-distribution instances. Our code is publicly available at \url{http://github.com/LTluttmann/marl4msprp}


\keywords{Picker Routing \and Mixed-Shelves Warehouses \and Neural Combinatorial Optimization \and Multi-Agent Reinforcement Learning}
\end{abstract}
%
%
%
\section{Introduction}
Order picking, the process of retrieving items from a warehouse to fulfill customer orders, is one of the most labor-intensive and time-consuming operations in warehouse logistics, accounting for up to 65\% of total operating costs \cite{de2007design}. In conventional picker-to-parts warehouses, most of a picker's time is spent traveling between the shelves of the storage area \cite{Tompkins2010}. To reduce travel time, mixed-shelves storage strategies have gained traction in recent years (see \cite{Boysen2017}, \cite{weidingerPickerRoutingMixedshelves2019}, \cite{xie2021introducing}, \cite{xie2023formulating}, and \cite{luttmann2024neural}). Unlike traditional warehouse layouts that allocate a single storage position per Stock-Keeping Unit (SKU), mixed-shelves storage distributes SKUs to multiple shelves of the storage area, potentially decreasing travel distances and improving overall efficiency.

This mixed-shelves approach gives rise to the Mixed-Shelves Picker Routing Problem (MSPRP), which focuses on determining optimal routes for pickers while considering the unique constraints of mixed-shelves warehouses and operations. Despite its practical significance, research on solving the MSPRP remains limited. Existing approaches primarily rely on classical heuristics such as variable neighborhood search \cite{xie2023formulating} and Tabu search \cite{danielsModelWarehouseOrder1998}. While these methods can produce high-quality solutions, they are computationally expensive which makes them impractical for large-scale or real-time applications.
Neural combinatorial optimization (NCO) has emerged as a promising alternative, offering faster solution generation while maintaining high solution quality across various routing problems. However, current NCO applications to the MSPRP are limited to single-picker scenarios that focus on minimizing total travel distance. This represents a significant gap in addressing real-world warehouse operations, where multiple pickers typically work simultaneously and minimizing the longest tour (i.e., the route of the most time-consuming picker) is more critical for maintaining efficient operations. To bridge this gap, we propose a novel NCO approach that integrates hierarchical and parallel decoding to efficiently solve the min-max variant of the MSPRP. Our main contributions are as follows:

\begin{itemize}
    \item We formulate the MSPRP as a cooperative multi-agent problem, aiming to balance workloads among pickers rather than minimizing the total distance.
    \item A Hierarchical and Parallel Decoding framework enables efficient picker coordination in complex multi-dimensional action spaces.
    \item A Sequential Action Selection strategy supports the parallel decoding step by avoiding conflicts while exhibiting strong generalization performance    
    \item We demonstrate state-of-the-art performance in terms of both solution quality and computational efficiency, particularly for large problem instances.
\end{itemize}

\section{Related Work}
\label{subsec:relwork}

\input{chapters/related_works}

\section{Problem Formulation}
\label{sec:mathmod}

\input{chapters/problem_description}


\section{Method}

% TODOS:

% \textcolor{red}{
% \begin{itemize}
%     \item check notation $\bm{a}$ and $\tau$ (Tau is route, a is solution / all actions)
%     \item describe ranking-based positional encoding 
%     \item remove mha formulas from agent encoder
%     \item perform permutation test w/o communication layer
% \end{itemize}
% }
This section introduces our Multi-Agent Hierarchical Attention Model (MAHAM) -- an extension of the Hierarchical Attention Model (HAM) architecture \cite{luttmann2024neural} -- designed to address the multi-picker min-max variant of the MSPRP. In NCO, the sequential nature of the MDP underlying the CO problem often leads to the adoption of autoregressive (AR) models, which implement a sequential solution generation via an encoder-decoder network, formally represented as:\footnote{henceforth, we use the current problem state $s_t$ instead of the problem instance $x$ and the previous actions $\bm{a}_{1:t-1}$ to condition the models}
\begin{align}
\label{eq:autoregressive_encoding_decoding}
p_\theta(\bm{a}|x) &= \prod_{t=1}^{T} g_\theta(a_{t} | x, \bm{a}_{1:t-1}, H_t) \cdot f_\theta(H_t | x, \bm{a}_{1:t-1})
\end{align}
where $f_\theta$ represents the encoder network, used to construct a hidden representation of the problem instance $x$ given the actions taken so far and $g_\theta$ the decoder, that selects actions based on the problem encoding and its current state. 

MAHAM follows this approach, however the presence of multiple agents and a composite action space $\mathcal{A} \equiv \mathcal{V} \times \mathcal{P}$ introduce special needs which we carefully address with our architecture in \Cref{fig:maham}. While existing approaches tackle multi-agent problems by sequentially generating solutions for one agent after another \cite{son2024equity} or using a separate decoder $\pi_\theta^m$ per agent \cite{zong2022mapdp}, MAHAM poses a shared policy which constructs multiple picker routes in parallel through 1.) a separate agent encoder and 2.) a parallel decoding with sequential action selection scheme.  
% \begin{align}


\subsection{Encoder}


\input{chapters/encoder}


\subsection{Parallel and Hierarchical Decoder}

\input{chapters/decoder}


\subsection{Learning Method}

\input{chapters/training}

\section{Experiments}

\input{chapters/experiments}


% \begin{itemize}
%     \item maham vs gurobi, ham and et
%     \item ablation studies: 
%     \begin{itemize}
%         \item compare action selection strategy with agents selecting actions in random order
%         \item compare SL with REINFORCE
%         \item Agent Context Encoder
%         \item MatNet with parameter sharing etc
%     \end{itemize}
%     \item more or less agents then required tours (benchmark against what?)
%     \item extension to multiple depots with balanced packing stations?
%     \item softmax per agent of over all agent-action combinations
% \end{itemize}



\section{Conclusion and Future Work}
In this work, we introduced the first neural solver for the min-max Mixed-Shelves Picker Routing Problem. The core of our approach is the integration of a hierarchical and parallel decoding mechanism capable of efficiently constructing solutions over complex, multi-dimensional action spaces, such as those found in min-max MSPRP. While previous methods relied on sequential solution construction or parallel decision-making prone to conflicts, our approach achieves efficient and effective agent coordination, enabled by a novel Sequential Action Selection algorithm.

Our extensive experimental results, including traditional as well as neural solvers, demonstrate the superiority of MAHAM in both solution quality and inference speed, particularly for large-scale problem instances. These findings highlight the capabilities of neural solvers and prove them as a strong alternative to hand-crafted heuristics.

Future research directions include extending this approach to more dynamic warehouse environments with real-time demand fluctuations and exploring hybrid methods that integrate learning-based techniques with optimization heuristics for further performance improvements. Additionally, our framework could be adapted to other multi-agent combinatorial optimization problems beyond warehouse logistics, such as fleet routing and robotic task allocation.


\bibliographystyle{splncs04}
\bibliography{bib.bib}

\input{chapters/appendix}

\end{document}
