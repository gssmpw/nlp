
\label{sec:exp}

We study the effectiveness of MAHAM in solving the min-max MSPRP by comparing it with both traditional OR solvers as well as other multi-agent neural solvers. First, we use the exact solver Gurobi with two different time budgets (10 minutes and one hour) to solve a single instance from the test set. Further, due to the absence of (meta-)heuristics for the min-max variant of the MSPRP, we implement a greedy heuristic as a simple baseline. To compare MAHAM with other learning-based methods, we include HAM \cite{luttmann2024neural}, 2d-Ptr \cite{liu20242d}, Equity Transformer \cite{son2024equity}, and PARCO \cite{berto2024parco} in the experiments.  We describe all baseline solvers in \Cref{appendix:baselines}. 




\subsection{Comparison with Baselines}
\input{tables/luttmann_instances}
We present the main empirical results, comparing MAHAM against all baselines mentioned above, in \Cref{tab:main}, reporting the average objective function values (Obj.), gaps to the best-known solutions, and inference times for solving a single instance from the test set of the respective instance type. For training and evaluating MAHAM, we use the same instance types and instance generation method as described in \cite{luttmann2024neural}. Specifically, we use three different warehouse layouts, with 10, 25, and 40 shelves and vary the number of SKUs per layout type. We describe the generation of instances in detail in \Cref{appendix:instance}. For neural baselines, we evaluate the performance using 1280 sampled solutions and reporting the objective value of the best one. 

MAHAM consistently outperforms other neural baselines in terms of solution quality and speed, with margins growing with the size of the problem instance. Also, MAHAM is on-par with the Gurobi solver on small instances and even outperforms it on larger instances, where no optimal solutions were found in the given time bounds.


\subsection{Large Scale Generalization}
\input{tables/large_scale}

We further evaluate the generalization performance of MAHAM on large-scale instances of the MSPRP that were not seen during training. The ability to generalize to larger instances is crucial for any NCO algorithm to make it applicable to dynamic real-world scenarios. We evaluate MAHAM against a purely autoregressive approach (2d-Ptr), PARCO as an alternative parallel decoding model, and the Greedy heuristic. Gurobi is not included in the evaluation as it can not find solutions to any of the large instances with a time budget of one hour per instance. The results are shown in \Cref{table:large_scale_generalization}, where MAHAM consistently outperforms other methods while also being significantly faster. Most notable is the large performance gap compared to PARCO, which achieves competitive results in in-distribution testing, but seems to generalize worse to larger instances.

\subsection{Ablation Studies}

\paragraph{Picker Ranking and Coordination:}
A key aspect of MAHAM is the Sequential Action Selection. The quality of the solution generated by the autoregressive policy defined in \Cref{eq:maham} and the action selection function $\psi$ defined by \Cref{alg:seq-action-selection} strongly depends on the order $\PermOverL$ in which pickers perform actions. In order to validate that the model is able to learn good agent rankings, i.e., by assigning higher logits to those agents that should have priority, we compare the (\textit{learned}) agent priority of \Cref{eq:maham} with a model that iterates over the set of agents in the order of their index $m$ (\textit{index}) as well as a model that determines the order $\Omega$ randomly (\textit{random}). 

Moreover, MAHAM utilizes a separate agent encoder that enables effective agent coordination when computing the joint action logits in the decoders. The idea of utilizing an agent encoder for multi-agent problems itself is not novel, but has already been applied in the Equity Transformer \cite{son2024equity}, the 2d-Ptr \cite{liu20242d}, and PARCO \cite{berto2024parco}. However, in this work we fuse the agent encoder with a novel rank-dependent positional encoding followed by a multi-head self-attention layer. This enables effective communication between the agents based on their current utilization and ultimately enables the model to come up with optimal rankings. 

\Cref{fig:ranking} summarizes the results of an ablation study testing the effectiveness of the proposed components in our MAHAM architecture. The full model with learned rankings and rank-dependent positional encodings (PE) performs significantly better than the models relying on an index-based or random order, and also achieves better solutions than MAHAM without the positional encoding.

\paragraph{Encoder Parameter Sharing:} MAHAM introduces an efficient way to incorporate message-passing over different types of nodes in a heterogeneous graph. Through the parameter sharing (PS) approach described in \Cref{sec:encoder}, the MAHAM encoder saves roughly 20\% in size, allowing it to process larger instances faster. In addition, parameter sharing acts as regularization, improving the generalization of the trained model. We compare MAHAM with and without parameter sharing in the cross-attention layer of the encoder on out-of-distribution instances in \cref{table:large_scale_generalization}. Parameter sharing consistently results in better solutions in less time.  

\begin{figure}[h]
    \centering
    \scalebox{0.95}{ % Adjust the scaling factor as needed
        \begin{minipage}{\textwidth}
            \centering
            \begin{subfigure}[b]{0.435\textwidth}
                \centering
                \includegraphics[width=\textwidth]{figures/ranking.pdf}
                \vspace{-6mm}
                \caption{}
                \label{fig:ranking}
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{figures/avg_steps.pdf}
                \vspace{-6mm}
                \caption{}
                \label{fig:runtime}
            \end{subfigure}
        \end{minipage}
    }
    \caption{\footnotesize Solution quality of MAHAM on MSPRP instances for different ranking strategies (left) and MAHAM efficiency in comparison to the 2d-Ptr and PARCO (right)}
    \label{fig:both}
\end{figure}
\vspace{-5mm}
%
% \begin{figure}[h]
%     \centering
%     \begin{subfigure}[b]{0.46\textwidth} % Adjust width as needed
%         \centering
%         \includegraphics[width=\textwidth]{figures/ranking.pdf} % Replace with your image file
%         \label{fig:ranking}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.53\textwidth} % Adjust width as needed
%         \centering
%         \includegraphics[width=\textwidth]{figures/avg_steps.pdf} % Replace with your image file
%         \label{fig:runtime}
%     \end{subfigure}
%     \caption{\footnotesize Solution quality of MAHAM on MSPRP25 instances with different ranking strategies (left). The right plot shows the efficiency of MAHAM in comparison to the 2d-Ptr and PARCO. Most notably, MAHAM requires also less decoding steps than PARCO, which employs parallel decoding similar to MAHAM.}
%     \label{fig:both}
% \end{figure}
%
\subsection{Runtime Comparison}
We study the efficiency of MAHAM by comparing it to the 2d-Ptr -- acting as a purely autoregressive neural baseline -- and PARCO, another parallel solution construction approach. The results are shown in \Cref{fig:runtime}. While the 2d-Ptr requires much more decoding steps to construct a solution, resulting in longer training times, MAHAM also needs less construction steps and is quicker to train than PARCO. This can be attributed to our Sequential Action Selection approach, which effectively avoids conflicts through adaptive masking. In PARCO on the other hand, agents may select the same shelf/SKU in the same decoding step, resulting in a conflict and consequently in one or more agents doing nothing in the respective stage. 