
\subsubsection{Mixed-shelves Picker Routing.}
Various heuristics have been developed to address the MSPRP, including construction and improvement methods \cite{weidingerPickerRoutingRectangular2018,weidingerPickerRoutingMixedshelves2019} and a variable neighborhood search approach \cite{xie2023formulating}. However, these methods often require minutes of computation, which can be impractical for fast-paced operations.
Only one neural learning approach has been proposed for the MSPRP, modeling it as a heterogeneous graph to optimize selection and routing for a single picker \cite{luttmann2024neural}. In practice, multiple pickers operate simultaneously, shifting the focus towards minimizing overall completion time instead of total travel distance. We thus explore a min-max variant of the MSPRP, aiming to balance travel distances among pickers. 
\vspace{-5mm}

\subsubsection{Neural Combinatorial Optimization.} While early work in the NCO field focus on problems involving a single agent like in the traveling salesman problem  \cite{vinyals2015pointer,kool2018attention,kwon2020pomo,kwon2021matrix}, recently more attention has been given to more complex, multi-agent variants of routing problems. Building on \cite{kool2018attention}, the Equity Transformer \cite{son2024equity} and 2d-Ptr \cite{liu20242d} introduce attention-based policies for multi-agent min-max routing. However, these models can be seen as purely autoregressive approaches, constructing solutions for one agent at a time, thus neglecting potential agent coordination and exhibiting high generation latency for large problems with many agents. PARCO \cite{berto2024parco} aims to address these shortcomings by introducing parallel solution construction, using a Priority-based Conflict handler to avoid infeasible solutions when performing actions for multiple agents simultaneously. 

In this work, we combine the hierarchical decoder of \cite{luttmann2024neural}, designed for the integrated selection and routing in MSPRP, as well as parallel solution construction similar to \cite{berto2024parco}, to learn high quality solutions for the min-max MSPRP. To effectively avoid conflicts during hierarchical solution construction, we combine a Parallel Pointer Mechanism with a Sequential Action Selection algorithm.