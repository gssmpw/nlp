\section{Video Latent Flow Matching} \label{sec:vlfm}

In this section, we propose Video Latent Flow Matching (VLFM) in response to the main problem in Section~\ref{sub:problem_def}. Especially, we briefly review the HiPPO (high-order polynomial projection operators) framework \cite{gde+20} in Section~\ref{sub:hippo}. We state the derivation of our VLFM based on the popular flow matching approach \cite{lcb+22} in Section~\ref{sub:vlfm}. Finally, we define the training objective of the VLFM for efficient video modeling in Section~\ref{sub:training_objective}.


\subsection{HiPPO Framework and LegS State Space Model}\label{sub:hippo}

Given an input function $f(t) \in \R$ for $t \ge 0$, we use $f_{\leq t}$ to denote the cumulative history of $f(t)$ for every time $t \ge 0$. We choose integer $s \ge 1$ as the order of approximation. Then, any $s$-dimensional subspace ${\cal G}$ of this function space is a suitable candidate for the approximation. Given a time-varying measure family $p(t)$ supported on $(-\infty, t)$, a sequence of basis functions ${\cal G} = {\rm span}\{ g_{i}(t) \}_{i=1}^s$. HiPPO \cite{gde+20} defines an operator that maps $f$ to the optimal projection coefficients $c: \R_{\ge 0} \rightarrow \R^s$, such that:
\begin{align*}
    g(t) := & ~ \arg \min_{g \in {\cal G}} \| f_{\leq t} -  g \|_{p(t)}, \\
    g(t) = & ~ \sum_{i=1}^s c_i(t) \cdot g_i(t).
\end{align*}
We focus on the case where the coefficients $c(t)$ have the form of a linear ODE satisfying $\nabla c(t) = A(t) c(t) + B(t) f(t)$ for some $A(t) \in \R^{s \times s}$ and $B(t) \in \R^{s \times 1}$. This equation is now also known as the state space model (SSM) in many works \cite{kds+15,aia+22,gd23,dg24,zlz+24,xyy+24,mlw24,rx24,sld+24}.

{\bf Discrete HiPPO-LegS.} The setting of HiPPO-LegS defines the update rule of SSM and the discrete version of $A$ and $B$ matrices, which are $c_{\tau + 1} = (I_s - \frac{A}{\tau}) c_\tau + \frac{1}{\tau} B f_\tau$ and:
\begin{align*}
    A_{i_1, i_2} & ~ = \begin{cases}
        \sqrt{(2i_1 + 1)(2i_2 + 1)}, & \text{if $i_1 > i_2$} \\
        i_1 + 1, & \text{if $i_1 = i_2$} \\
        0, & \text{if $i_1 < i_2$}
    \end{cases}, \\
    B_{i_1} & ~ = \sqrt{2i_1 + 1}, \forall i_1, i_2 \in [s].
\end{align*}

\subsection{Conditional Video Latent Flow}\label{sub:vlfm}


Here we emphasize the core idea of VLFM is to approximate a continuous video distribution from limited discrete video frames data utilizing the optimal high-order polynomial approximation. 

Given a video-caption distribution ${\cal V}_c$, then for any video-caption data pair $(V, c) \sim {\cal V}_c$, we obtain the data $\wt{u}_\tau \in \R^d, \forall \tau \in [N]$ via Eq.~\eqref{eq:u_tau:informal}.
We aim to define a time-dependent flow $\psi_t(\wt{u})$ that takes inputs $\wt{u}$ and time $t$, and could match $\widehat{u}_\tau$ for all time $\tau \in [N]$. Since $\widehat{u}$ is discrete, HiPPO-LegS will be the best solution to approximate the continuous data. We define the \emph{Video Latent Flow} as:
\begin{align}\label{eq:psi}
    \psi_t(\wt{u}) := \sigma_t( \wt{u} ) \cdot z + \mu_t(\wt{u}) \in \R^d,
\end{align}
where $t \in [0,T]$ and $z \sim \mathcal{N}(0, I_d)$, $\sigma: [0, T] \times \R^{N \times d} \rightarrow \R_{> 0}$ denotes the time-dependent standard deviation, where $\sigma_0 ( \wt{u} ) = 1$, and $\sigma_{\frac{T}{N} \cdot \tau}( \wt{u} ) = \sigma_{\min}$, for all $\tau \in [N]$ ; $\mu: [0, T] \times \R^{N \times d} \rightarrow \R^d$ denotes the time-dependent mean of Gaussian distribution, where $\mu_0(\wt{u}) = {\bf 0}_d$, $\mu_{\frac{T}{N} \cdot \tau}(\wt{u}) = \wt{u}_\tau,$ for all $\tau \in [N]$.

Especially, we define:
\begin{align*}
    \mu_t(\wt{u} ) := & ~  H_N g(t), \\
    H_{\tau + 1} := & ~ H_{\tau} (I_s - \frac{1}{\tau} A)^\top + \frac{1}{\tau} \wt{u}_\tau B^\top,
\end{align*}
where $g(t) := [\sqrt{\frac{1}{2}} P_0(t), \sqrt{\frac{3}{2}} P_1(t), \cdots, \sqrt{\frac{2s-1}{2}} P_{s-1}(t)]^\top $ $\in \R^{s}$, $P_i(t), \forall i \in [s]$ is Legendre polynomials. We initialize $H_0 := {\bf 0}_{d \times s}$.

Besides, having a large scalar $\alpha > 0$, we give:
\begin{align*}
    \sigma_t(\wt{u}) := (1 - \sigma_{\min}) \cdot [\sin^2( \pi \frac{N}{T} t ) +  \exp(-\alpha t) ] + \sigma_{\min}.
\end{align*}

\subsection{Training Objective}\label{sub:training_objective}

Here we define a model function $F_\theta: \R^d \times \R^\ell \times [0, T] \rightarrow \R^d$ with parameters $\theta$ to learn the conditional video latent flow $\psi_t(\wt{u})$ defined in Eq.~\eqref{eq:psi}. This function takes inputs of flow and time to predict the vector field. The training objective is based on the Flow Matching framework \cite{lcb+22}, which aims to minimize the distance between the model's prediction and the true derivative of the flow.

The training objective of VLFM is defined as the expectation of the square $\ell_2$ norm of the difference, which is:
\begin{align*}
    {\cal L}(\theta) := \E_{z, t, (V, c)}[\| F_\theta( \psi_t(\wt{u}), c, t ) - \frac{\d }{\d t} \psi_t(\wt{u}) \|_2^2],
\end{align*}
where $z \sim \mathcal{N}(0, I_d)$,  $t \sim {\sf Uniform}[0, T]$ and $(V, c) \sim {\cal V}_c$. By minimizing this objective, the model learns to approximate the vector field that transports the initial noise distribution to the distribution of video latent patches. Formally, we solve: $\min_{\theta} {\cal L}(\theta)$. 

{\bf Close-form solution.} Furthermore, the close-form solution could be easily obtained as follows:
\begin{theorem}
    The minimum solution for function $F_\theta$ that takes $z \sim N(0, I_d)$ and $t \sim {\sf Uniform}[0, T]$ is:
    \begin{align*}
        F_\theta(z, c, t) = \frac{\sigma_t'(\wt{u})}{\sigma_t(\wt{u})} (z - \mu_t(\wt{u})) + \mu_t'(\wt{u}).
    \end{align*}
\end{theorem}

\begin{proof}
    This proof follows from Theorem 3 in \cite{lcb+22}.
\end{proof}

