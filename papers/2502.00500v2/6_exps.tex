\begin{figure*}[!ht]
\begin{center}
\centering
    \subfloat[{\it Video caption: A green turtle swimming under the sea.}]{
    \includegraphics[width=0.95\textwidth]{gen/turtle}} \\
    \subfloat[{\it Video caption: Viewing countless sunflowers in a field from top.}]{
    \includegraphics[width=0.95\textwidth]{gen/sunflower}}
\end{center}
\caption{Generated videos with different frame rates $\{8, 12, 16\}$. }
\label{fig:gen}
\ifdefined\isarxiv
\else
\vspace{-3mm}
\fi
\end{figure*}

\begin{figure*}[!ht]
\begin{center}
\centering
    \subfloat{
    \includegraphics[width=0.95\textwidth]{inter/lion}} \\
    \subfloat{
    \includegraphics[width=0.95\textwidth]{inter/aurora}} \\
    \subfloat{
    \includegraphics[width=0.95\textwidth]{extra/cloud}} \\
\end{center}
\caption{Interpolation and Extrapolation of VLFM.}
\label{fig:inter_extra}
\ifdefined\isarxiv
\else
\vspace{-2mm}
\fi
\end{figure*}

\section{Experiments}\label{sec:exp}

In this section, we conduct experiments to evaluate the effectiveness of our approach. We first introduce our experimental setups in Section~\ref{sub:exp_setup}. Then, we demonstrate text-to-video generation using VLFM and VLFM's capability of generating videos in arbitrary frame rate in Section~\ref{sub:exp_gen}. Furthermore, we showcase the strong performance of interpolation and extrapolation of VLFM in Section~\ref{sub:exp_inter_extra}. We also perform an ablation study to discuss the importance of the flow matching algorithm in Section~\ref{sub:exp_ablation}.

\subsection{Setup} \label{sub:exp_setup}

In our experiments, we apply Stable Diffusion v1.5 \cite{rbl+22} with DDIM scheduler \cite{sme20} as the visual decoder. Then, we use a DiT-XL-2 \cite{px23} as the backbone for the Flow Matching algorithm \cite{lcb+22,lgl22}, and the choice of hyper-parameters of $\sigma_t(\wt{u})$ is given by $\sigma_{\rm min} = 0.01$ and $\alpha = 10$. We optimize the DiT using Grams optimizer \cite{cls24}. We sample and combine 7 data resources for comprehensive training and validation of our method. They are:
OpenVid-1M \cite{nxz+24},
UCF-101 \cite{szs12},
Kinetics-400 \cite{kcs+17},
YouTube-8M \cite{akl+16},
InternVid \cite{whl+23},
MiraData \cite{jgz+24}, and
Pixabay \cite{pixabay}. 

\ifdefined\isarxiv
\else
\vspace{-4mm}
\fi

\subsection{Text-to-Video Generation with Arbitrary Frame Rate} \label{sub:exp_gen}

In this section, we recover several videos with different frame rates using VLFM with given video captions in the training dataset. We extract $T= 0.5$ for demonstrations as Figure~\ref{fig:gen}. In detail, we choose three frame rates for generation $\{8, 12, 16\}$. As shown, our VLFM performs fairly on text-to-video generation while it requires very small resource that is equivalent to training a new flow matching text-to-image video, which ensures its efficiency. Moreover, we give more results that are generated by VLFM in Appendix~\ref{sec:app:more_1} and \ref{sec:app:more_2}.
\ifdefined\isarxiv
\else
\vspace{-3mm}
\fi

\subsection{Interpolation and Extrapolation} \label{sub:exp_inter_extra}

In this section, we test the interpolation and extrapolation of VLFM. For the interpolation experiment, the model is trained with 24 FPS and evaluated to generate video with 48 FPS. For the extrapolation, the model is trained with the first video with $T = 2$ and evaluated to generate the whole video with $T = 8$. Referring the results in Figure~\ref{fig:inter_extra}, this demonstrates the strong performance of our VLFM under our mathematical guarantee of the error bound and its effectiveness.

\subsection{Ablation Study} \label{sub:exp_ablation}

In this section, we compared training VLFM with the Flow Matching algorithm and directly used DiT to predict the latent patches to showcase the importance of utilizing flow matching in our VLFM. We compare VLFM with and without flow matching by training the model with 1000 steps and compare the PSNR (peak signal-to-noise ratio) before and after training for video recovery with given captions in the training dataset. We state the results in Table~\ref{tab:ablation}. Denote ${\rm MSE}(x,y)$ as the mean squared error function, the computation of the metric PSNR is given by ($x,y \in \R^{r\times r}$):
\ifdefined\isarxiv
\else
\vspace{-3mm}
\fi
\begin{align*}
    {\rm PSNR}(x,y) := 10 \log_{10}(\frac{r^2}{{\rm MSE}(x,y)}), 
\end{align*}
\ifdefined\isarxiv
\else
\vspace{-3mm}
\fi

\begin{table}[!ht]
\ifdefined\isarxiv
\else
\vspace{-2mm}
\fi
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{r | c c}
    \toprule
    Algorithm & Initial PSNR$\uparrow$ & Final PSNR$\uparrow$ \\
    \midrule
    Flow Matching & {\bf 57.20} & {\bf 61.18} \\
    Direct Predicting & 9.81 & 53.77 \\
    \bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\caption{PSNR comparison (the greater, the better) of Flow Matching and direct generation from DiT. We boldface the better scores.}
\label{tab:ablation}
\ifdefined\isarxiv
\else
\vspace{-4mm}
\fi

\end{table}