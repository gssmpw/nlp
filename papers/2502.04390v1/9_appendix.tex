%\parttoc % Insert the appendix TOC
\section*{Appendix}

We now report extended material concerning the extended related work (Appendix \ref{app:related}), the extraction of historical activations and gradients (Appendix \ref{app:notation:extraction}),  as well as detailed results on dissonance awareness (Appendix \ref{app:dissonance}), non-dissonant updates (Appendix \ref{app:update}) and dissonant updates (Appendix \ref{app:dissonant}).

% Table of contents for the appendixn

\section{Extended Related work}\label{app:related}
\input{appendix/appendix_related_work}

\section{Extraction of historical activations and gradients}\label{app:notation:extraction}
We here detail our procedure for the extraction of activations and gradients. Source code is also available at \url{https://github.com/bendiogene/ConflictAwareLLM/} for ultimate level of details and reproducibility purposes. 

\input{appendix/extended_problem_definition}


\section{Dissonance awareness}\label{app:dissonance}

\subsection{Augmenting the COUNTERFACT Dataset with Novel facts}
\label{appendix:unknown_facts_prompt}

To generate unknown facts to augment the Counterfact dataset, we used GPT-3.5 with a prompt as follows:

\begin{lstlisting}[language=,frame=single]
Starting from this list of facts, can you create one data entry for each that concerns imaginary names and characters if necessary, while following the same logic.

For example, Danielle Darrieux's mother tongue is French => Becomes Machin De Machine's mother tongue is Kurdi (or Kinduli).

Edwin of Northumbria's religious values strongly emphasize Christianity => Hamed Habib's religious values strongly emphasize Atheism (or Peace or..)

Try to make the old and new as far as possible from each other (e.g., Kurdi is far from French, Kinduli is an imaginary language, etc.), while keeping some logic.

Write in JSON format, please (easy to parse):

- Danielle Darrieux's mother tongue is French
- Edwin of Northumbria's religious values strongly emphasize Christianity
- Toko Yasuda produces the most amazing music on the guitar
- One can get to Autonomous University of Madrid by navigating Spain
- Thomas Joannes Stieltjes was born in Dutch
- Anaal Nathrakh originated from Birmingham
\end{lstlisting}

\paragraph{Example Generated Transformations:}

\begin{itemize}
    \item Original: \emph{``Toko Yasuda produces the most amazing music on the guitar.''}

    Transformed: \emph{``Zara Zorin produces the most amazing music on the theremin.''}
    \item Original: \emph{``One can get to Autonomous University of Madrid by navigating Spain.''}

    Transformed: \emph{``One can reach the Floating Academia of Zephyria by navigating through the Cloud Realms.''}
    \item Original: \emph{``Thomas Joannes Stieltjes was born in Dutch.''}

    Transformed: \emph{``Lorien Ilithar was born amidst the Elvish.''}
\end{itemize}

These transformations help create novel facts unlikely to be known by the model, enabling us to evaluate its ability to handle unknown information effectively.


\subsection{Ablation study of classifier performance}
We further report for the interested reader the results of an ablation study of the dissonance awareness classifier, evaluating its performance under different scenarios (fine-tuned vs. pre-trained models), feature sets (A, G, A+G), normalization strategies (None, Layer, Historical), and classifiers (Random Forests (RF) and Support Vector Machines (SVM)).

Table~\ref{tab:classification_results_appendix} presents a comprehensive set of classification results, including average accuracy and F1 scores (with standard deviations) across different settings. The best results for each classifier are denoted with a $\star$ and reported earlier in Table~\ref{tab:classification_results} in the main paper.


\input{appendix/table-classification-results-appendix}

\subsection{Explanation of feature importance}\label{app:feature:importance}
To further understand the discriminative power of different features, we analyzed the feature importance scores derived from the RF classifier.

First, as earlier mentioned in Fig.\ref{fig:feature_importance} in the main paper, gradient-based features are substantially more important than activation-based features. This suggests that fine-tuning leads to more discriminative gradients, possibly due to the model overfitting on the known facts, resulting in near-zero gradients for known facts and higher gradients for novel or conflicting facts. In contrast, for the pre-trained model, both activation and gradient features contribute significantly, indicating that combining internal representations and learning dynamics is beneficial for classification.

Complementary to Fig.\ref{fig:feature_importance}, block importance reported in Fig.~\ref{fig:block_importance} reveals that, in the pre-trained model all transformer blocks tend to contribute relatively equally to the classification task, with the last layers contributing less. The finetuned model, on the other hand shows a slightly different tendency where the earlier layers contribute less. More work is clearly needed to understand such differences. This paper focuses only on feasibility of the entire cognitive-dissonance approach, leaving more elaborate evaluations for future work.

\input{appendix/figure-explanation-feature-importance}

\subsection{Location of stubborn neurons}
We also report the distribution of stubborn neurons across the transformer blocks in GPT-2 XL. Figures~\ref{fig:stubborn_8000} and~\ref{fig:stubborn_2000} show histograms of the number of stubborn neurons identified in each block for thresholds of 8,000 and 2,000 neurons, respectively.

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl/experiment2_1_xl_stubborn_neurons_stubborn_neurons_histogram_8000.pdf}
        \subcaption{Histogram of stubborn neurons ($t=8000$ neurons) across transformer blocks}
        \label{fig:stubborn_8000}
    \end{subfigure}
    %\hfill
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl/experiment2_1_xl_stubborn_neurons_stubborn_neurons_histogram_2000.pdf}
        \subcaption{Histogram of stubborn neurons ($t=2000$ neurons) across transformer blocks}
        \label{fig:stubborn_2000}
    \end{subfigure}
    
    \caption{Distribution of stubborn neurons across GPT2-XL transformer blocks for different neuron thresholds to define stubbornness. (a) shows the distribution for $t=8000$ neurons, while (b) corresponds to $t=2000$ neurons.}
    \label{fig:stubborn_neurons_distribution}
\end{figure}

%\zbh{/home/sclemente/project/epmem\_edit/analysis/plots\_exp\_2\_1\_xl.ipynb}}
Our analysis indicates that stubborn neurons are not uniformly distributed throughout the network. Instead, they curiousy tend to be concentrated in certain blocks, particularly in the first block and in certain middle layers of the transformer. This might suggest that these layers play a more significant role in encoding and retaining knowledge during training. 
Interestingly,  \(\text{Attn}_{\text{c\_attn}}\) concentrates much more of the stubborn neurons overall, with the exception of the first block where \(\text{Attn}_{\text{c\_proj}}\) has a substantially higher share of stubborn neurons.
The results are similar for both thresholds.

Overall, understanding the distribution of stubborn neurons can inform targeted update strategies by identifying which parts of the network are more critical for preserving existing knowledge.

%\clearpage
%--------------------------------------------------
%--------------------------------------------------

\subsection{Using model output (instead of internal state) as features for dissonance awareness}\label{app:diss:aware:prob}
\input{appendix/additional_classifier_experiment}

\section{{\color{customgreen}Non-dissonant} updates}\label{app:update}

\subsection{Similarities with Lottery ticket}\label{app:lottey}

To assess the hypothesis that certain subnetworks within the language model are more conducive to integrating new information—a notion earlier named the lottery ticket hypothesis~\citep{frankle2018lottery}—we designed an experiment to confirm this effect. 

We first trained a model on 10,000 disjoint facts (referred to as Facts H) and identified the most active candidate neurons during this process, which we term \emph{Lottery Ticket Neurons}. These neurons should form a preferred subnetwork for representing Facts H. Next, we started from a \textit{fresh model} and trained on a new set of novel facts (Facts A), which are different from H, restricting updates to three distinct groups of neurons:

\begin{enumerate}
    \item \textbf{Lottery Ticket Neurons}: Neurons highly active during the initial training on Facts H.
    \item \textbf{Non-Lottery Neurons}: Neurons underutilized during the initial training on Facts H.
    \item \textbf{Random Neurons}: Neurons selected randomly from the entire network.
\end{enumerate}

Figure~\ref{fig:lottery} shows the accuracy of acquiring new knowledge when using each of these strategies, with the number of neurons varying from 2,000 to 20,000. Using the Lottery Ticket Neurons led to significantly better performance, reaching nearly 100\% accuracy at 8,000 neurons, compared to around 40\% for the Non-Lottery Neurons. The Random Neurons strategy also performed relatively well, interestingly suggesting that capturing even a few ``anchor'' neurons from the preferred subnetwork is sufficient to achieve good performance.

\begin{figure}
    \centering
    \includegraphics[width=0.48\textwidth]{./figures/3_incremental_update/experiment_2_2/experiment_2_2_1000_neuron_update_strategies_new_knowledge.pdf}
    \caption{Lottery ticket}\label{fig:lottery}
\end{figure}


These results support the existence of preferred subnetworks within the model that are particularly effective for learning new information. Leveraging these subnetworks can enhance the efficiency of knowledge integration while preserving existing knowledge, an aspect that our candidate and specific strategies are already exploiting.

\subsection{Hyperparameter selection: learning rate and batch size for GPT2-XL}\label{app:gptxl:search}
In our experiments, the first step is to conduct a hyperparameter search to determine the optimal learning rates and batch sizes for fine-tuning the model on our facts. Table~\ref{tab:lr:search} presents the performance of  GPT2-XL on old and new knowledge across various learning rates and batch sizes.
\textit{Note that this optimal learning rate for full finetuning might turn out not enough for our targeted updates, since they use, by design, a smaller number of neurons. 
}
\input{appendix/table-learning-rate}


\subsection{Comprehensive Analysis of GPT2-XL {\color{customgreen}non-dissonant} Updates}\label{app:gpt2xl:noconflict}


\begin{figure*}[ht!]
    \centering
    \captionsetup{font=small} % Reduce caption font size
    \begin{tabular}{@{}c@{} c@{}} % Remove extra space between columns
           \multicolumn{2}{c}{\textbf{The best LR for full FT is not enough to learn with targeted updates:}} \\
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240913_013018_bestLR_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:bestLR_old:xl}
        \end{subfigure} &
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240913_013018_bestLR_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:bestLR_new:xl}
        \end{subfigure} \\
        %\vspace{0.1cm} \\

        % Impact of Learning Rate: 10X Higher Learning Rate
        % \multicolumn{2}{c}{\textbf{Impact of Learning Rate: 10X Higher Learning Rate}} \\
        \multicolumn{2}{c}{\textbf{Increasing the LR (here 10X higher) helps:}} \\
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240912_203810_10xLR_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:10xLR_old:xl}
        \end{subfigure} &
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240912_203810_10xLR_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:10xLR_new:xl}
        \end{subfigure} \\
        %\vspace{0.1cm} \\

        % % Impact of Update Sparsity: 10X More Neurons
        % \multicolumn{2}{c}{\textbf{Impact of Update Sparsity: 10X More Neurons}} \\
         % Impact of Update Sparsity: 10X More Neurons
        \multicolumn{2}{c}{\textbf{Giving more space (here 10X more neurons) also helps targetted updates:}} \\
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240911_181551_bestLR_10XNeurons_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:10XNeurons_old:xl}
        \end{subfigure} &
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240911_181551_bestLR_10XNeurons_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:10XNeurons_new:xl}
        \end{subfigure} \\
        %\vspace{0.1cm} \\

        % Impact of Training Duration: 50 Epochs (10X More)
        \multicolumn{2}{c}{\textbf{Finally, training longer (here 50 Epochs) yielded the most stable results:}} \\
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240912_150705epochs50s_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:epochs50s_old}
        \end{subfigure} &
        \begin{subfigure}[b]{0.34\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/3_incremental_update/experiment2_1_xl_update/experiment_2_1_with_B_20240912_150705epochs50s_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:epochs50s_new}
        \end{subfigure} \\
    \end{tabular}
    \caption{\textbf{{\color{customgreen}Non-Dissonant} updates with GPT2-XL} under various conditions. Overall the same trends as GPT2-small are confirmed: targeting stubborn neurons destroys old knowledge more and plastic neurons need more space or time to learn.}
    \label{fig:gpt2xl:full:non-conflict}
\end{figure*}


Figure~\ref{fig:gpt2xl:full:non-conflict} presents the accuracy of GPT-2 XL on old and new knowledge under various neuron update strategies and experimental conditions. We explored different configurations to understand how the model's larger capacity affects knowledge integration.


Our results reveal distinct scaling behaviors compared to GPT-2 small. 
With the optimal learning rate for GPT-2 XL (Figures~\ref{fig:bestLR_old:xl},~\ref{fig:bestLR_new:xl}), we observe improved new knowledge acquisition while still preserving old knowledge. This means that although our carefully picked learning rate allows for efficient learning with full finetuning, learning with fewer neurons (as per our targetted strategies) seems harder than it was for GPT-2 small. 

Increasing the learning rate by 10x (Figures~\ref{fig:10xLR_old:xl},~\ref{fig:10xLR_new:xl}) or allocating 10x more neurons (Figures~\ref{fig:10XNeurons_old:xl},~\ref{fig:10XNeurons_new:xl}) confirms that GPT-2 XL requires either higher learning rates or more extensive parameter updates compared to GPT-2 small to achieve effective learning with our targeted strategies. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/3_incremental_update/mosaic_all/pareto_mosaic_GPT2-small_GPT2-XL_10x_neurons_GPT2-XL_GPT2-XL_10x_LR_GPT2-XL_50_Epochs.pdf}
		
    \caption{\textbf{{\color{customgreen}Non-Dissonant} updates with GPT2-XL compared to small, a different visualization.} Scatter plot of old (x) vs new (y) knowledge during {\color{customgreen}non-dissonant} updates. Same conditions as in Fig.~\ref{fig:gpt2xl:full:non-conflict}. We can see clearly how in all cases, the accuracy on previous knowledge remains high. The lottery-ticket effect is also visible where free neurons struggle to efficient pack novel facts.}
    \label{fig:pareto_mosaic_combined}
\end{figure}



Similarly, extended training duration (50 epochs, Figures~\ref{fig:epochs50s_old},~\ref{fig:epochs50s_new}) allows the model to better integrate new knowledge while preserving old information, indicating that longer training can also help overcome the limitations of sparse updates in larger models. Figure~\ref{fig:pareto_mosaic_combined} summarizes these trade-offs across all configurations, highlighting how different hyperparameter choices affect the balance between preserving old knowledge and acquiring new information.

Finally, note that while GPT-2 XL's larger capacity naturally reduces interference with our tracked facts during non-dissonant updates, this improved performance is ``deceptive'' and should be interpreted cautiously: \textit{we cannot measure potential effects on other pre-trained knowledge beyond our tracked facts}. 

\textit{These results highlight the methodological challenges in studying knowledge updates in larger models:  their increased capacity can mask interference with tracked facts,  making it harder to fully measure the impact of updates on the model's broader knowledge.} This underscores the importance of controlled experimental settings when studying fundamental properties of knowledge updating in neural networks.

% Our results indicate that, unlike GPT-2 small, GPT-2 XL generally preserves old knowledge across all strategies, but struggles to integrate new knowledge effectively. Increasing the learning rate or the number of neurons allocated for updates improves the model's ability to learn new information but may lead to more degradation of existing knowledge. Extending the training duration also allows the model to pack more knowledge into fewer neurons while better preserving old knowledge.

% These findings suggest that the principles observed in smaller models apply to larger models like GPT-2 XL, though the effects may be less pronounced due to the increased capacity. Adjusting hyperparameters such as the learning rate, number of neurons, and training duration is crucial when scaling up to larger models.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{{\color{customred}Dissonant} updates}\label{app:dissonant}

\subsection{Impact of number of conflicting facts}\label{app:diss:nfacts}
We examined the effect of varying the number of conflicting facts introduced during {\color{customred}Dissonant} updates. Figure~\ref{fig:additional_results} shows the performance metrics of GPT-2 small when editing 10, 100, and 1,000 facts, respectively.

Our findings show that as the number of conflicting facts increases, the impact on old knowledge retention becomes more pronounced, with all strategies experiencing significant degradation. The ability to learn new conflicting knowledge improves slightly with more facts, but overall performance remains suboptimal. The plastic and random neuron strategies tend to preserve old knowledge when editing a small number of facts (e.g., 10 facts), but their effectiveness diminishes as more conflicting information is introduced. Interestingly, the opposite effect is observed for new knowledge, where adding more facts seems to make it easier to learn new knowledge, for all strategies.
\begin{figure}[h]
    \centering
    \captionsetup{font=small} % Optional: Reduce caption font size for better fit
    \begin{tabular}{@{}c c c@{}}
        % -------------------------------
        % Row 1: Generalization
        \multicolumn{3}{c}{\textbf{Generalization}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_10_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{10 Facts}
            \label{fig:gen_10}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_100_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{100 Facts}
            \label{fig:gen_100}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{1000 Facts}
            \label{fig:gen_1000}
        \end{subfigure} \\
        \vspace{0.3cm} \\

        % -------------------------------
        % Row 2: Accuracy on New Knowledge
        \multicolumn{3}{c}{\textbf{Accuracy on New Knowledge}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_10_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{10 Facts}
            \label{fig:acc_new_10}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_100_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{100 Facts}
            \label{fig:acc_new_100}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_new_knowledge.pdf} % Added .pdf extension
            \subcaption{1000 Facts}
            \label{fig:acc_new_1000}
        \end{subfigure} \\
        \vspace{0.3cm} \\

        % -------------------------------
        % Row 3: Accuracy on Old Knowledge
        \multicolumn{3}{c}{\textbf{Accuracy on Old Knowledge}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_10_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{10 Facts}
            \label{fig:acc_old_10}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_100_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{100 Facts}
            \label{fig:acc_old_100}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{1000 Facts}
            \label{fig:acc_old_1000}
        \end{subfigure} \\
    \end{tabular}
    \caption{\textbf{{\color{customred}Dissonant} updates with GPT2-small - impact of the number of conflicting facts}. Each row represents a distinct metric: accuracy on the \textbf{Generalization} side dataset (paraphrased versions of the new facts), accuracy on \textbf{New Knowledge}, and Accuracy on \textbf{Old Knowledge}. Within each row, the subplots correspond to the number of conflicting facts introduced (\textbf{10 Facts}, \textbf{100 Facts}, and \textbf{1000 Facts}).}
    \label{fig:additional_results}
\end{figure}


\subsection{Comparative performance of Editing methods}\label{app:rome:memit}
Our primary focus in this work is \textit{not} on developing new model editing techniques. Most existing editing techniques focus on altering existing associations, and are hence by our definition dissonant by design. Our empirical findings in this work suggest another parallel path in which editing is abandoned in favor of non-dissonant variations where old knowledge is kept and contextualized

However, to have an idea on how existing editing methods perform compared to our targeted strategies, we leverage \texttt{EasyEdit}~\citep{wang2023easyedit} to benchmark two state-of-the-art model editing methods, ROME~\citep{Meng2022} and MEMIT~\citep{Meng2022a}, under our same multi-fact experimental conditions . 

Table~\ref{tab:comparison:sumary:editing} summarizes the performance of different strategies and editing methods. Some of our targeted update strategies obtain a higher harmonic mean compared to ROME and MEMIT. But the higher harmonic mean must not hide that the approaches are not directly comparable since they explore different regions of the pareto front, balancing new knowledge acquisition and old knowledge retention, as self-explained with colors and rankings in the table. 
\input{table3_comparison_gradient_v2}


\subsection{More detailed figures for specific numbers of neurons}\label{app:dissonant:numbers}
Tables~\ref{tab:neuron_editing_20000}, Figs.~\ref{tab:neuron_editing_8000}, and \ref{tab:neuron_editing_4000} provide detailed performance metrics for different neuron thresholds (20k, 8k, and 4k neurons, respectively) when editing 1,000, 100 and 10, conflicting facts using various strategies.

\begin{table}[h!]
\centering
\caption{Neuron Editing Results for N=20,000 Neurons}
\label{tab:neuron_editing_20000}
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
\textbf{Samples} & \textbf{Strategy}          & \textbf{Accuracy A} & \textbf{Accuracy NOT(B)} & \textbf{Accuracy GEN} & \textbf{Harmonic Mean} \\
\midrule
\multirow{7}{*}{10} 
 &Full Finetune                      & 0.107 (0.082)       & 1.000 (0.000)             & 0.576 (0.117)         & 0.222 (0.116)           \\
 & Specific             & 0.491 (0.137)       & 1.000 (0.000)             & 0.604 (0.126)         & 0.621 (0.109)           \\
 & Plastic           & 0.735 (0.105)       & 0.752 (0.175)             & 0.220 (0.183)         & 0.434 (0.185)           \\
% & Plastic (new)          & 0.794 (0.093)       & 0.732 (0.176)             & 0.204 (0.169)         & 0.424 (0.201)           \\
 & Stubborn           & 0.449 (0.109)       & 1.000 (0.000)             & 0.616 (0.091)         & 0.606 (0.084)           \\
 & Candidate          & 0.430 (0.134)       & 1.000 (0.000)             & 0.656 (0.125)         & 0.597 (0.116)           \\
 & Random              & 0.688 (0.107)       & 0.944 (0.083)             & 0.448 (0.212)         & 0.579 (0.222)           \\
\midrule
\multirow{7}{*}{100} 
 &Full Finetune                      & 0.238 (0.019)       & 0.998 (0.003)             & 0.434 (0.089)         & 0.398 (0.041)           \\
 & Specific             & 0.412 (0.046)       & 0.988 (0.005)             & 0.330 (0.054)         & 0.460 (0.046)           \\
 & Plastic           & 0.317 (0.052)       & 0.586 (0.048)             & 0.128 (0.028)         & 0.233 (0.035)           \\
%& Plastic (new)          & 0.301 (0.044)       & 0.649 (0.062)             & 0.146 (0.032)         & 0.252 (0.037)           \\
 & Stubborn           & 0.435 (0.043)       & 0.999 (0.002)             & 0.427 (0.085)         & 0.528 (0.057)           \\
 & Candidate          & 0.463 (0.032)       & 0.999 (0.002)             & 0.447 (0.083)         & 0.552 (0.052)           \\
 & Random              & 0.474 (0.035)       & 0.874 (0.048)             & 0.292 (0.048)         & 0.444 (0.036)           \\
\midrule
\multirow{7}{*}{1000} 
 &Full Finetune                      & 0.182 (0.007)       & 0.991 (0.009)             & 0.442 (0.053)         & 0.341 (0.016)           \\
 & Specific             & 0.188 (0.033)       & 0.995 (0.002)             & 0.257 (0.025)         & 0.292 (0.035)           \\
 & Plastic           & 0.077 (0.021)       & 0.996 (0.002)             & 0.224 (0.018)         & 0.160 (0.027)           \\
 %& Plastic (new)          & 0.078 (0.010)       & 0.996 (0.002)             & 0.247 (0.014)         & 0.168 (0.015)           \\
 & Stubborn           & 0.185 (0.010)       & 0.992 (0.005)             & 0.327 (0.013)         & 0.317 (0.012)           \\
 & Candidate          & 0.172 (0.018)       & 0.996 (0.001)             & 0.369 (0.043)         & 0.314 (0.028)           \\
 & Random              & 0.235 (0.029)       & 0.995 (0.003)             & 0.300 (0.053)         & 0.347 (0.041)           \\
\bottomrule
\end{tabular}
}
\end{table}


\begin{table}[h!]
\centering
\caption{Neuron Editing Results for N=8,000 Neurons}
\label{tab:neuron_editing_8000}
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
\textbf{Samples} & \textbf{Strategy} & \textbf{Accuracy A} & \textbf{Accuracy NOT(B)} & \textbf{Accuracy GEN} & \textbf{Harmonic Mean} \\
\midrule
\multirow{7}{*}{10} 
 & Full Finetune     & 0.107 (0.082) & 1.000 (0.000) & 0.576 (0.117) & 0.222 (0.116) \\ 
 & Specific         & 0.638 (0.138) & 0.964 (0.039) & 0.512 (0.238) & 0.600 (0.183) \\ 
 & Plastic        & 0.909 (0.039) & 0.020 (0.040) & 0.000 (0.000) & 0.0 \\ 
 %& Plastic (New)       & 0.936 (0.029) & 0.000 (0.000) & 0.000 (0.000) & 0.0 \\ 
 & Stubborn        & 0.622 (0.110) & 0.972 (0.030) & 0.544 (0.169) & 0.643 (0.103) \\ 
 & Candidate       & 0.596 (0.106) & 0.988 (0.024) & 0.644 (0.128) & 0.690 (0.058) \\ 
 & Random          & 0.827 (0.083) & 0.380 (0.132) & 0.092 (0.094) & 0.277 (0.098) \\ 
\midrule
\multirow{7}{*}{100} 
 &Full Finetune                  & 0.238 (0.019) & 0.998 (0.003) & 0.434 (0.089) & 0.398 (0.041) \\ 
 & Specific         & 0.531 (0.030) & 0.760 (0.063) & 0.263 (0.027) & 0.426 (0.024) \\ 
 & Plastic        & 0.433 (0.029) & 0.059 (0.014) & 0.028 (0.017) & 0.052 (0.025) \\ 
% & Plastic (New)       & 0.553 (0.056) & 0.033 (0.011) & 0.016 (0.010) & 0.028 (0.012) \\ 
 & Stubborn        & 0.530 (0.054) & 0.936 (0.048) & 0.398 (0.064) & 0.547 (0.063) \\ 
 & Candidate       & 0.542 (0.035) & 0.969 (0.033) & 0.462 (0.081) & 0.591 (0.054) \\ 
 & Random          & 0.508 (0.019) & 0.193 (0.038) & 0.065 (0.025) & 0.131 (0.039) \\ 
\midrule
\multirow{7}{*}{1000} 
 &Full Finetune                  & 0.182 (0.007) & 0.991 (0.009) & 0.442 (0.053) & 0.341 (0.016) \\ 
 & Specific         & 0.240 (0.017) & 0.993 (0.003) & 0.287 (0.039) & 0.345 (0.028) \\ 
 & Plastic        & 0.218 (0.024) & 0.283 (0.026) & 0.070 (0.010) & 0.133 (0.013) \\ 
 %& Plastic (New)       & 0.266 (0.034) & 0.247 (0.028) & 0.060 (0.011) & 0.122 (0.017) \\ 
 & Stubborn        & 0.200 (0.007) & 0.995 (0.001) & 0.317 (0.024) & 0.327 (0.006) \\ 
 & Candidate       & 0.199 (0.014) & 0.996 (0.002) & 0.380 (0.041) & 0.345 (0.014) \\ 
 & Random          & 0.159 (0.032) & 0.784 (0.091) & 0.102 (0.014) & 0.169 (0.010) \\ \bottomrule
\end{tabular}
}
\end{table}

% \begin{table}[h!]
% \centering
% \caption{Neuron Editing Results for N=6,000 Neurons}
% \label{tab:neuron_editing_6000}
% \resizebox{0.7\textwidth}{!}{%
% \begin{tabular}{cccccc}
% \toprule
% \textbf{Samples} & \textbf{Strategy} & \textbf{Accuracy A} & \textbf{Accuracy NOT(B)} & \textbf{Accuracy GEN} & \textbf{Harmonic Mean} \\
% \midrule
% \multirow{7}{*}{10} \\ 
%  &Full Finetune                  & 0.107 (0.082) & 1.000 (0.000) & 0.576 (0.117) & 0.222 (0.116) \\ 
%  & Specific         & 0.663 (0.117) & 0.800 (0.111) & 0.436 (0.204) & 0.545 (0.164) \\ 
%  & Plastic        & 0.941 (0.031) & 0.004 (0.008) & 0.000 (0.000) & 0.0 \\ 
% % & Plastic (New)       & 0.963 (0.018) & 0.000 (0.000) & 0.000 (0.000) & 0.0 \\ 
%  & Stubborn        & 0.641 (0.083) & 0.868 (0.057) & 0.404 (0.160) & 0.548 (0.111) \\ 
%  & Candidate       & 0.604 (0.115) & 0.956 (0.043) & 0.552 (0.134) & 0.642 (0.057) \\ 
%  & Random          & 0.898 (0.059) & 0.120 (0.126) & 0.000 (0.000) & 0.0 \\ 
% \midrule
% \multirow{7}{*}{100} \\ 
%  &Full Finetune                  & 0.238 (0.019) & 0.998 (0.003) & 0.434 (0.089) & 0.398 (0.041) \\ 
%  & Specific         & 0.552 (0.014) & 0.573 (0.064) & 0.200 (0.025) & 0.347 (0.020) \\ 
%  & Plastic        & 0.627 (0.051) & 0.010 (0.005) & 0.011 (0.011) & 0.020 (0.004) \\ 
% % & Plastic (New)       & 0.733 (0.036) & 0.002 (0.002) & 0.002 (0.004) & 0.005 (0.000) \\ 
%  & Stubborn        & 0.558 (0.050) & 0.850 (0.091) & 0.371 (0.063) & 0.527 (0.062) \\ 
%  & Candidate       & 0.569 (0.031) & 0.925 (0.091) & 0.436 (0.095) & 0.580 (0.075) \\ 
%  & Random          & 0.497 (0.047) & 0.077 (0.029) & 0.040 (0.030) & 0.071 (0.041) \\ 
% \midrule
% \multirow{7}{*}{1000} \\ 
%  &Full Finetune                  & 0.182 (0.007) & 0.991 (0.009) & 0.442 (0.053) & 0.341 (0.016) \\ 
%  & Specific         & 0.230 (0.012) & 0.992 (0.006) & 0.297 (0.052) & 0.342 (0.030) \\ 
%  & Plastic        & 0.270 (0.054) & 0.196 (0.022) & 0.057 (0.010) & 0.112 (0.014) \\ 
%  %& Plastic (New)       & 0.316 (0.066) & 0.165 (0.028) & 0.051 (0.009) & 0.102 (0.014) \\ 
%  & Stubborn        & 0.200 (0.018) & 0.993 (0.005) & 0.315 (0.043) & 0.325 (0.029) \\ 
%  & Candidate       & 0.185 (0.026) & 0.997 (0.002) & 0.357 (0.048) & 0.322 (0.026) \\ 
%  & Random          & 0.194 (0.026) & 0.663 (0.072) & 0.088 (0.008) & 0.165 (0.014) \\ \bottomrule
% \end{tabular}
% }
% \end{table}

\begin{table}[h!]
\centering
\caption{Neuron Editing Results for N=4,000 Neurons}
\label{tab:neuron_editing_4000}
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
\textbf{Samples} & \textbf{Strategy} & \textbf{Accuracy A} & \textbf{Accuracy NOT(B)} & \textbf{Accuracy GEN} & \textbf{Harmonic Mean} \\
\midrule
\multirow{7}{*}{10} \\ 
 &Full Finetune                  & 0.107 (0.082) & 1.000 (0.000) & 0.576 (0.117) & 0.222 (0.116) \\ 
 & Specific         & 0.673 (0.101) & 0.656 (0.168) & 0.264 (0.208) & 0.385 (0.182) \\ 
 & Plastic        & 0.965 (0.021) & 0.000 (0.000) & 0.000 (0.000) & 0.0 \\ 
 %& Plastic (New)       & 0.981 (0.010) & 0.000 (0.000) & 0.000 (0.000) & 0.0 \\ 
 & Stubborn        & 0.635 (0.062) & 0.764 (0.087) & 0.352 (0.115) & 0.506 (0.101) \\ 
 & Candidate       & 0.603 (0.101) & 0.864 (0.126) & 0.512 (0.106) & 0.613 (0.065) \\ 
 & Random          & 0.863 (0.066) & 0.144 (0.113) & 0.044 (0.062) & 0.169 (0.050) \\ 
\midrule
\multirow{7}{*}{100} \\ 
 &Full Finetune                  & 0.238 (0.019) & 0.998 (0.003) & 0.434 (0.089) & 0.398 (0.041) \\ 
 & Specific         & 0.553 (0.023) & 0.408 (0.040) & 0.137 (0.022) & 0.258 (0.029) \\ 
 & Plastic        & 0.760 (0.054) & 0.000 (0.000) & 0.003 (0.003) & 0.0 \\ 
 %& Plastic (New)       & 0.854 (0.024) & 0.000 (0.000) & 0.000 (0.000) & 0.0 \\ 
 & Stubborn        & 0.565 (0.060) & 0.705 (0.143) & 0.303 (0.077) & 0.460 (0.092) \\ 
 & Candidate       & 0.573 (0.041) & 0.852 (0.124) & 0.400 (0.102) & 0.548 (0.093) \\ 
 & Random          & 0.487 (0.043) & 0.090 (0.018) & 0.045 (0.023) & 0.082 (0.030) \\ 
\midrule
\multirow{7}{*}{1000} \\ 
 &Full Finetune                  & 0.182 (0.007) & 0.991 (0.009) & 0.442 (0.053) & 0.341 (0.016) \\ 
 & Specific         & 0.235 (0.008) & 0.976 (0.012) & 0.265 (0.041) & 0.329 (0.025) \\ 
 & Plastic        & 0.348 (0.049) & 0.125 (0.021) & 0.047 (0.006) & 0.093 (0.009) \\ 
 %& Plastic (New)       & 0.456 (0.097) & 0.080 (0.019) & 0.034 (0.007) & 0.067 (0.012) \\ 
 & Stubborn        & 0.203 (0.013) & 0.989 (0.006) & 0.315 (0.031) & 0.329 (0.016) \\ 
 & Candidate       & 0.184 (0.013) & 0.996 (0.001) & 0.370 (0.045) & 0.327 (0.025) \\ 
 & Random          & 0.254 (0.049) & 0.400 (0.085) & 0.072 (0.006) & 0.146 (0.010) \\ \bottomrule
\end{tabular}
}
\end{table}

% FT NOT-B                 
% & C-FT NOT-B (spec)         
% & C-FT NOT-B (free_A)      
% & C-FT NOT-B (free_B)      
% & C-FT NOT-B (busy_A)      
% & C-FT NOT-B (busy_B)      
% & C-FT NOT-B (rnd)  
%  &Full Finetune       
% & Plastic (old)          
% & Plastic (new) => removed because confusing.         
% & Stubborn (old)         
% & Candidate          
% & Random        

The results show that changing the number of neurons allocated for updates does not necessarily improve or degrade performance in the dissonant update scenario. In all cases, the model struggles to retain old knowledge while learning new conflicting information. The candidate and specific neuron strategies are consistently and significantly better than state of the art solutions, offering a slight advantage. However, they are still unable to effectively mitigate the destructive effects of dissonant updates, further motivating the neeed for both (i) dissonance awareness and (ii) proper conflict resolution.

\subsection{Scaling to GPT2-XL}\label{app:diss:xl}
We extended our dissonant update experiments to GPT-2 XL to examine whether our observations about knowledge conflicts persist in larger models.

Figure~\ref{fig:knowledge_editing_performance} examines GPT2-XL's behavior when updating 1,000 conflicting facts using the optimal learning rate, as determined by our hyperparameter search. We compare three configurations: GPT-2 small (2,000 to 20,000 neurons) shown previously, GPT2-XL with the same range, and GPT2-XL with ten times more neurons (20,000 to 200,000). The latter was shown effective in packing new knowledge compared to (2000 to 20000) range in non-dissonant updates.

% %\subsection{Impact of Neurons under Best Learning Rate}\label{app:xl:neurons:10}
% Finally, we conduct also additional experiments using the optimal learning rate for GPT-2 XL, as determined in our hyperparameter search. Figure~\ref{fig:knowledge_editing_performance} compares the performance of GPT-2 small and GPT-2 XL when updating 1,000 conflicting facts, varying the number of neurons from 2,000 to 20,000 for GPT-2 small and from 20,000 to 200,000 for GPT-2 XL.

\begin{figure}[h]
    \centering
    \captionsetup{font=small}
    \begin{tabular}{@{}c c c@{}}
        \multicolumn{3}{c}{} \\
        \textbf{Old Knowledge} & \textbf{New Knowledge} & \textbf{Generalization} \\

       % Row 1: GPT2-XL from 2k to 20k neurons
        \multicolumn{3}{c}{\textit{GPT2-small from 2k to 20k neurons}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:same_old}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_new_knowledge}
            \subcaption{New Knowledge}
            \label{fig:same_new}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1/experiment_3_1_2000_1000_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{Generalization}
            \label{fig:same_gen}
        \end{subfigure} \\
        \vspace{0.3cm} \\

        % Row 1: GPT2-XL from 2k to 20k neurons
        \multicolumn{3}{c}{\textit{GPT2-XL from 2k to 20k neurons}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_135003_2000_1000_10_small_lr_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:same_old_xl}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_135003_2000_1000_10_small_lr_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:same_new_xl}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_135003_2000_1000_10_small_lr_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{Generalization}
            \label{fig:same_gen_xl}
        \end{subfigure} \\
        \vspace{0.3cm} \\
    
        % Row 2: GPT2-XL from 20k to 200k neurons
        \multicolumn{3}{c}{\textit{GPT2-XL with 10X more neurons}} \\
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_085748_20000_1000_10_small_lr_neuron_update_strategies_old_knowledge.pdf}
            \subcaption{Old Knowledge}
            \label{fig:10x_old}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_085748_20000_1000_10_small_lr_neuron_update_strategies_new_knowledge.pdf}
            \subcaption{New Knowledge}
            \label{fig:10x_new}
        \end{subfigure} &
        \begin{subfigure}[b]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_085748_20000_1000_10_small_lr_neuron_update_strategies_general_knowledge.pdf}
            \subcaption{Generalization}
            \label{fig:10x_gen}
        \end{subfigure} \\
    \end{tabular}
    \caption{\textbf{ {\color{customred}Dissonant} updates with GPT2-XL: whether the model learns new knowledge or not, old knowledge is severely destroyed regardless of the strategy} Experiments with 1000 facts using the best learning rate we found for Full Finetuning.}
    \label{fig:knowledge_editing_performance}
\end{figure}

First, while GPT2-XL still requires more neurons than GPT-2 small to effectively learn new conflicting knowledge, as seen earlier, the key finding concerns old knowledge retention: regardless of model size or neuron allocation, we observe significant degradation of old, unrelated knowledge across all strategies. 

Interestingly, this degradation persists even when using fewer neurons and when the model fails to effectively learn the new conflicting information (2k to 20k). These results strongly suggest that the destructive impact of conflicting updates on existing knowledge is a fundamental property that remains present in larger models.


% Even with the best learning rate, GPT-2 XL fails to learn the new conflicting knowledge effectively and continues to experience significant degradation in old knowledge retention. These findings further confirm the challenges associated with learning dissonant updates, even when using less packed  larger models. Our various experiments suggest that adjusting hyperparameters alone is not sufficient to mitigate the destructive effects of conflicting information.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{comment}
% app:xl:new, app:xl:gen, app:xl:old
% \subsubsection{New Knowledge Acquisition}\label{app:xl:new}

% Figures~\ref{fig:same_10_new}, \ref{fig:same_100_new}, and \ref{fig:same_1000_new} illustrate the performance on conflicting knowledge acquisition when introducing 10, 100, and 1,000 conflicting facts. First, using the same hyperparameters as GPT-2 small, GPT-2 XL achieves less than 10\% accuracy in acquiring new conflicting knowledge - a stark contrast with the non-dissonant case where it reached up to 40\% accuracy under similar conditions (Fig.~\ref{fig:sameLR_new:xl}). Interestingly, in this case, and in contrast with the non-dissonant case, performance remains poor even when allocating 10 times more neurons (Figures~\ref{fig:10x_10_new}, \ref{fig:10x_100_new}, and \ref{fig:10x_1000_new}).

% \begin{figure}[h]
%     \centering
%     \captionsetup{font=small} % Optional: Adjust caption font size
%     \begin{tabular}{@{}c c c@{}}
%         \multicolumn{3}{c}{\textbf{New Knowledge Acquisition}} \\
%         \textbf{10 Facts} & \textbf{100 Facts} & \textbf{1000 Facts} \\
        
%         % Row 1: Same Condition as GPT2-small
%         \multicolumn{3}{c}{\textit{GPT2-XL under the same conditions as GPT2-small}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_2000_10_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:same_10_new}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_094011_2000_100_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:same_100_new}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_000646_2000_1000_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:same_1000_new}
%         \end{subfigure} \\
%         \vspace{0.3cm} \\
        
%         % Row 2: 10X Neurons
%         \multicolumn{3}{c}{\textit{GPT2-XL with 10X more neurons}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20000_10_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:10x_10_new}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_044940_20000_100_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:10x_100_new}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240718_160529_20000_1000_neuron_update_strategies_new_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:10x_1000_new}
%         \end{subfigure} \\
%     \end{tabular}
%     \caption{New Knowledge Acquisition of GPT2-XL across different experimental conditions and numbers of conflicting facts.}
%     \label{fig:new_knowledge_acquisition}
% \end{figure}

% However, as we will see later, despite being unable to properly learn new conflicting knowledge, the performance on old unrelated knowledge still considerably degrades.

% \subsubsection{Generalization Performance}\label{app:xl:gen}

% Figures~\ref{fig:same_10_gen}, \ref{fig:same_100_gen}, and \ref{fig:same_1000_gen} show the generalization performance of GPT-2 XL in the dissonant update scenario. 
% The models overall fail to generalize effectively to paraphrased versions of the new conflicting facts, even when more neurons are allocated (Figures~\ref{fig:10x_10_gen}, \ref{fig:10x_100_gen}, and \ref{fig:10x_1000_gen}).

% \begin{figure}[h]
%     \centering
%     \captionsetup{font=small} % Optional: Adjust caption font size
%     \begin{tabular}{@{}c c c@{}}
%         \multicolumn{3}{c}{\textbf{Generalization Performance}} \\
%         \textbf{10 Facts} & \textbf{100 Facts} & \textbf{1000 Facts} \\
        
%         % Row 1: Same Condition as GPT2-small
%         \multicolumn{3}{c}{\textit{GPT2-XL under the same conditions as GPT2-small}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_2000_10_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:same_10_gen}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_094011_2000_100_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:same_100_gen}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_000646_2000_1000_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:same_1000_gen}
%         \end{subfigure} \\
%         \vspace{0.3cm} \\
    
%         % Row 2: 10X Neurons
%         \multicolumn{3}{c}{\textit{GPT2-XL with 10X more neurons}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20000_10_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:10x_10_gen}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_044940_20000_100_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:10x_100_gen}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240718_160529_20000_1000_neuron_update_strategies_general_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:10x_1000_gen}
%         \end{subfigure} \\
%     \end{tabular}
%     \caption{Generalization Performance of GPT2-XL across different experimental conditions and numbers of conflicting facts. Note that y axes do not have the same scale. Indeed, finetuning performs much better in the case of 10 facts, compared to 100 or 1000 facts.}
%     \label{fig:generalization_performance}
% \end{figure}

% % \include{appendix/gpt2-large-dissonant}
% \subsubsection{Unrelated Old Knowledge Retention}\label{app:xl:old}

% Figures~\ref{fig:same_10_old}, \ref{fig:same_100_old}, and \ref{fig:same_1000_old} depict the retention of old knowledge following dissonant updates. Even when not effectively learning the new conflicting knowledge, GPT-2 XL experiences significant degradation in old knowledge accuracy, particularly when updating larger numbers of conflicting facts. Allocating more neurons exacerbates this effect (Figures~\ref{fig:10x_10_old}, \ref{fig:10x_100_old}, and \ref{fig:10x_1000_old}).


% \begin{figure}[h]
%     \centering
%     \captionsetup{font=small} % Optional: Adjust caption font size
%     \begin{tabular}{@{}c c c@{}}
%         \multicolumn{3}{c}{\textbf{Old Knowledge Retention}} \\
%         \textbf{10 Facts} & \textbf{100 Facts} & \textbf{1000 Facts} \\
        
%         % Row 1: Same Condition as GPT2-small
%         \multicolumn{3}{c}{\textit{GPT2-XL under the same conditions as GPT2-small}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_2000_10_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:same_10_old}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_094011_2000_100_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:same_100_old}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_000646_2000_1000_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:same_1000_old}
%         \end{subfigure} \\
%         \vspace{0.3cm} \\
        
%         % Row 2: 10X Neurons
%         \multicolumn{3}{c}{\textit{GPT2-XL with 10X more neurons}} \\
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20000_10_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{10 Facts}
%             \label{fig:10x_10_old}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240719_044940_20000_100_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{100 Facts}
%             \label{fig:10x_100_old}
%         \end{subfigure} &
%         \begin{subfigure}[b]{0.3\textwidth}
%             \centering
%             \includegraphics[width=\textwidth]{./figures/4_editing/experiment3_1_xl/experiment_3_1_20240718_160529_20000_1000_neuron_update_strategies_old_knowledge.pdf}
%             \subcaption{1000 Facts}
%             \label{fig:10x_1000_old}
%         \end{subfigure} \\
%     \end{tabular}
%     \caption{Old Knowledge Retention of GPT2-XL across different experimental conditions and numbers of conflicting facts.}
%     \label{fig:old_knowledge_retention}
% \end{figure}
% \end{comment}















%\section{Extended related work}\label{app:related}
%\input{appendix/appendix_related_work}

% \subsection{Impact of learning rate on packing and forgetting knowledge}\label{app:nondiss:packing:lr}
% \zbh{I wrote it but may be too straightforward}
% We investigated the impact of different learning rates on the model's ability to integrate new knowledge and retain old knowledge. Figure~\ref{fig:lr_impact_appendix} shows the accuracy of GPT-2 XL on old and new knowledge for various learning rates, ranging from $4 \times 10^{-5}$ to $1 \times 10^{-2}$, under different neuron update strategies.
% \include{appendix/ablation-learning-rate}

% Our findings indicate that starting from a learning rate of $1.6 \times 10^{-4}$, there is a collapse in performance for both old and new knowledge. The tendencies observed throughout the work are also observed here. Targeting plastic neurons helps preserve old knowledge but struggles to learn new information effectively. Conversely, updating stubborn neurons leads to better acquisition of new knowledge but results in more degradation of old knowledge. These observations highlight the importance of selecting an appropriate learning rate to balance knowledge integration and retention.


% \section{Will likely not Keep}
% \subsection{ROME performance across folds}
% \begin{table}[h]
% \centering
% \caption{ROME Results for Different Sample Sizes and Layers (GPT2-small) \zbh{Not sure to keep, putting here right now}}
% \label{tab:rome_results}
% %\resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccc}
% \toprule
% \textbf{Samples} & \textbf{Run} & \textbf{Old (Locality)} & \textbf{New (Reliability)} & \textbf{Generalization} \\
% \midrule
% \multirow{5}{*}{10} 
%  & 0   & 0.952 & 0.200 & 0.000 \\
%  & 1   & 0.745 & 0.300 & 0.300 \\
%  & 2    & 0.908 & 0.500 & 0.400 \\
%  & 3  & 0.948 & 0.000 & 0.000 \\
%  & 4 & 0.903 & 0.200 & 0.200 \\
% \midrule
% \multirow{5}{*}{100}
%  & 0   & 0.435 & 0.350 & 0.180 \\
%  & 1   & 0.470 & 0.350 & 0.140 \\
%  & 2    & 0.554 & 0.230 & 0.140 \\
%  & 3  & 0.258 & 0.260 & 0.100 \\
%  & 4 & 0.437 & 0.310 & 0.190 \\
% \midrule
% \multirow{5}{*}{1000}
%  & 0   & 0.0261 & 0.0015 & 0.005 \\
%  & 1   & 0.1906 & 0.1930 & 0.083 \\
%  & 2    & 0.1808 & 0.2000 & 0.084 \\
%  & 3  & 0.1756 & 0.1670 & 0.076 \\
%  & 4 & 0.1870 & 0.2400 & 0.085 \\
% \bottomrule
% \end{tabular}
% %}
% \end{table}

% \subsection{MEMIT performance across folds}

% \begin{table}[h]
% \centering
% \caption{MEMIT Results for Different Sample Sizes and Layers (GPT2-small). \zbh{Not sure to keep, putting here right now}}
% \label{tab:memit_results}
% %\resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccc}
% \toprule
% \textbf{Samples} & \textbf{Run} & \textbf{Old (Locality)} & \textbf{New (Reliability)} & \textbf{Generalization} \\
% \midrule
% \multirow{5}{*}{10} 
%  & 0   & 0.998 & 0.000 & 0.000 \\
%  & 1   & 0.996 & 0.000 & 0.000 \\
%  & 2    & 0.997 & 0.000 & 0.000 \\
%  & 3  & 0.997 & 0.000 & 0.000 \\
%  & 4 & 0.820 & 0.000 & 0.000 \\
% \midrule
% \multirow{5}{*}{100}
%  & 0  & 0.974 & 0.010 & 0.010 \\
%  & 1  & 0.982 & 0.000 & 0.010 \\
%  & 2  & 0.977 & 0.000 & 0.020 \\
%  & 3  & 0.965 & 0.010 & 0.000 \\
%  & 4  & 0.984 & 0.000 & 0.010 \\
% \midrule
% \multirow{5}{*}{1000}
%  & 0  & 0.624 & 0.202 & 0.110 \\
%  & 1  & 0.623 & 0.204 & 0.113 \\
%  & 2  & 0.717 & 0.120 & 0.077 \\
%  & 3  & 0.633 & 0.197 & 0.089 \\
%  & 4  & 0.427 & 0.268 & 0.111 \\
% \bottomrule
% \end{tabular}
% %}
% \end{table}

% \subsection{GPT2XL comparisons}
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\textwidth]{figures/3_incremental_update/mosaic_all/pareto_mosaic_GPT2-small_GPT2-XL 10x LR.pdf}
%     \caption{Scatter plot of old (x) vs new (y) knowledge during incremental updates with new knowledge for different strategies and scopes (N). GPT2-small (top row) and GPT2-XL (bottom row) with 10x learning rate.  \zbh{Not sure to keep, putting here right now}}
%     \label{fig:pareto_mosaic_10x_lr}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\textwidth]{figures/3_incremental_update/mosaic_all/pareto_mosaic_GPT2-small_GPT2-XL 10x neurons.pdf}
%     \caption{Scatter plot of old (x) vs new (y) knowledge during incremental updates with new knowledge for different strategies and scopes (N). GPT2-small (top row) and GPT2-XL (bottom row) with 10x neurons.\zbh{Not sure to keep, putting here right now}}
%     \label{fig:pareto_mosaic_10x_neurons}
% \end{figure}

% \subsection{Comparison with editing methods using Easyedit}\label{app:editing:numbers}
% As mentioned in the main paper, we leverage the easyEdit package to compare two keys state of the art methods, for which we report the full results below.

% \begin{table}[h]
% \centering
% \caption{ROME Results for Different Fact sample Sizes (mean(std) over 5 folds of facts).}
% \label{tab:rome_results_mean_std}
% %\resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccc}
% \toprule
% \textbf{Samples} & \textbf{Old (Locality)} & \textbf{New (Reliability)} & \textbf{Generalization} & \textbf{Harmonic Mean} \\
% \midrule
% 10   & 0.891 (0.085) & 0.240 (0.182) & 0.180 (0.179) & 0.236 (0.235) \\
% 100  & 0.431 (0.108) & 0.300 (0.054) & 0.150 (0.036) & 0.24 (0.045) \\
% 1000 & 0.152 (0.071) & 0.160 (0.093) & 0.067 (0.035) &  0.106 (0.058) \\
% \bottomrule
% \end{tabular}
% %}
% \end{table}

% \begin{table}[h]
% \centering
% \caption{MEMIT Results for Different Fact Sample Sizes (mean(std) over 5 folds of facts).}
% \label{tab:memit_results_mean_std}
% %\resizebox{\textwidth}{!}{%
% \begin{tabular}{ccccc}
% \toprule
% \textbf{Samples} & \textbf{Old (Locality)} & \textbf{New (Reliability)} & \textbf{Generalization} & \textbf{Harmonic Mean} \\\\
% \midrule
% 10    & 0.962 (0.079) & 0.000 (0.000) & 0.000 (0.000) & 0.000 (0.000)\\
% 100   & 0.976 (0.008) & 0.004 (0.005) & 0.010 (0.007) & 0.003 (0.007)\\
% 1000  & 0.605 (0.107) & 0.198 (0.053) & 0.100 (0.016) & 0.177 (0.028) \\
% \bottomrule
% \end{tabular}\caption{MEMIT}
% %}
% \end{table}


% Extra to add eventually? 
% \ref{fig:bestLR_old:xl} \ref{fig:bestLR_old:xl}
% Using the best LR allows as expected to learn all the new facts with 100\% accuracy while almost preserving the old knowledge. However, all the strategies fail to learn all the new facts up to 20,000 neurons; but still with the same trend as before: the candidate and the specific are by far more efficient in learning new facts compared to the neurons from the free plastic space, confirming again the existence of preferred subnetworks for learning following the lottery ticket hypothesis.
% The figure shows that using the same aggressive LR as GPT2-small (Fig.~\ref{fig:sameLR_old:xl} Fig.~\ref{fig:sameLR_new:xl} does not work as expetd to learn the new knowledge even in the case of finetuning, but results also destructing the old knowledge (50\% accuracy). 

% \ref{fig:10xLR_old:xl} \ref{fig:10xLR_new:xl}
% Next, using 10X learning rates, allows us to see on GPT2XL similar effects to those of gpt2small
% with: the specific strategy providing the best trade-off, candidate and stubborn killing more old knowledge while learning wll. The specific strategy is again the best. The free strategy here is still unable to learn even when given 20,000 neurons (less than 50\% accuracy, compared to the candidate and soecific and busy which reach 100\% at this high number of neurons).
% This suggests again that using preferred networks allows to pack knowledge in few neurons compared to using the entire space, where everything needs to be ``learned from scratch''.

% \ref{fig:10XNeurons_old:xl} \ref{fig:10XNeurons_new:xl}
% The case of 10X more neurons, allowing more space. Here, we observe the cloest results to GPT2small: Adding new knowledge starts to slightly destroy old knowledge, even when using our strategies. And finally, Free neurons have more space to learn. 
% \ref{fig:epochs50s_new} \ref{fig:epochs50s_new}
% Finally, and as expected, when given 10 times more time to train, the free strategy also manages to pack knowlege more efficiently in fewer neurons, but the smae findings as earlier hold for the remaining strategies. However, this regime (which is way slower than fintuning in learning the new knowledge, remember we decided to pick the number of epochs based on the finetuning performance, see Fig.\ref{tab:lr:search} where 5 epochs where enough for GPT2XL) seems to offer a small advantage compared to the best LR case: it is possible, if we wait enough (train more) to pack more knowledge in less neurons, while better preserving old knowledge (100\% accuracy against 99\% only with best LR)). But again, the effects are not enough visible in our GPT2XL toy case, but we expect them to be big in more real settings where models are more packed and knowledge collisions are more likely.   
