\section{Related Work}
In this section, we focus on machine learning-based interatomic potentials and provide related works in conventional computation methods in Appendix~\ref{app:related_traditional}.


Recent advances in materials property prediction models____ and the availability of high-quality materials dynamics datasets____ generated using DFT-based algorithms have facilitated the development of materials foundation models capable of predicting energy, force, and stress. Among these models, purely invariant designs, such as M3GNet____, CHGNet____, Orb____, and EScAIP____, are computationally efficient, but typically do not perform as well, particularly for predicting higher order tensors such as force and stress. While some invariant models such as Orb____, and EScAIP____ are able to achieve competitive performance on benchmarks, this does not not necessarily translate to downstream tasks, as shown in Sec. \ref{sec:HEA}. In contrast, equivariant designs, including MACE____, SevenNet____, and EquiformerV2____, respect physical constraints like equivariance. However, they are computationally expensive due to the extensive use of tensor product operations, which limits their scalability. Additionally, some equivariant models still do not obey other important physical laws, undermining their performance on realistic material system simulations as seen in Sec. \ref{section:experiments}.

Different from these prior foundation models, our proposed HIENet detailed in Sec.~\ref{sec:HIENet} satisfies all key physical constraints while combining the scalability and efficiency of invariant designs with the robustness and symmetry-capturing capabilities of equivariant designs. This novel integration offers a promising direction for the next generation of materials foundation model design.