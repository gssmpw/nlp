\section{Background}
\label{background}

In this section, we provide an overview of adversarial attacks in machine learning, focusing on their implications for traffic sign classification systems. We also introduce the LISA dataset, a widely used benchmark for U.S. traffic sign recognition, and discuss LISA-CNN, the convolutional neural network model used in this work as a victim classifier.

\subsection{Adversarial Attacks}

Adversarial attacks exploit the vulnerabilities of deep neural networks (DNNs) by introducing small, carefully crafted perturbations to input data, causing the model to misclassify objects while remaining undetectable to human observers~\cite{szegedy2013intriguing, goodfellow2014explaining}. Other attacks have explored adding larger perturbations, which are ignored by humans, but confuse machine learning models~\cite{eykholt2018robust, zhong2022shadows}.
Adversarial attacks can be broadly categorized into digital attacks, where perturbations are applied directly to input images, and physical attacks, where adversarial modifications are introduced into real-world environments. 

Among digital attacks, early attack methods, such as the Fast Gradient Sign Method (FGSM)\cite{goodfellow2014explaining} and Projected Gradient Descent (PGD)\cite{madry2017towards}, rely on perturbing individual images to fool a model. More advanced approaches, like universal adversarial perturbations (UAPs), generate a single perturbation that generalizes across multiple inputs, making attacks more practical for real-world scenarios~\cite{moosavi2017universal}.

Among physical attacks, recent studies have shown that physical adversarial attacks pose a significant challenge to vision-based models. Attacks using stickers, shadows, and light-based manipulations have successfully deceived traffic sign classifiers by subtly altering key regions of an image without requiring direct access to the model~\cite{eykholt2018robust, zhong2022shadows, hsiao2024natural}. Attacks using leaves have also been used to mislead traffic sign classifiers as well~\cite{etim2024fallleafadversarialattack}. These attacks highlight the importance of understanding adversarial vulnerabilities beyond digital spaces and accounting for real-world environmental factors that may compromise model robustness.


\begin{figure*}[th!]
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
\includegraphics[width=2.2cm]{plots/base_images_resized/stop.png}
        \caption{\footnotesize \centering Stop \newline Test Image}
        \label{fig:stop_image}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/base_images_resized/yield.png}
        \caption{\footnotesize \centering Yield\newline Test Image}
    \label{fig:yield_image}
    \end{subfigure}
    \hfill
     \begin{subfigure}[b]{0.19\textwidth}
        \centering
    \includegraphics[width=2.2cm]{plots/base_images_resized/pedestrian.png}
        \caption{\footnotesize \centering Ped. Crossing\newline Test Image}
    \label{fig:pedestrian_image}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/base_images_resized/merge.png}
        \caption{\footnotesize \centering Merge\newline Test Image}
    \label{fig:merge_image}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/base_images_resized/right.png}
        \caption{\footnotesize \centering Turn Right\newline Test Image}
    \label{fig:right_image}
    \end{subfigure}
    \hfill
    \caption{Street View test images used in evaluation of the attacks.}
    \label{fig:Test_Images}
\end{figure*}

\begin{figure*}[th!]
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
\includegraphics[width=2.2cm]{plots/output_masks_resized/stop_output_mask.png}
        \caption{\footnotesize \centering Stop\newline Output Mask}
        \label{fig:stop_output_mask}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/output_masks_resized/yield_output_mask.png}
        \caption{\footnotesize \centering Yield\newline Output Mask}
    \label{fig:yield_output_mask}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
    \includegraphics[width=2.2cm]{plots/output_masks_resized/pedestrian_output_mask.png}
        \caption{\footnotesize \centering Ped. Crossing\newline Output Mask}
    \label{fig:pedestrian_output_mask}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/output_masks_resized/merge_output_mask.png}
        \caption{\footnotesize \centering Merge\newline Output Mask}
    \label{fig:merge_output_mask}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=2.2cm]{plots/output_masks_resized/right_output_mask.png}
        \caption{\footnotesize \centering Turn Right\newline Output Mask}
    \label{fig:right_output_mask}
    \end{subfigure}
    \hfill
    \caption{Street View test image masks used in placing snowball patches.}
     \label{fig:Output Masks}
\end{figure*}

% Snowball images
\begin{figure*}[th!]
    \centering
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \includegraphics[width=\linewidth]{plots/snowball_images/chatgpt/snowball_1.png}
        \caption{\footnotesize \centering Snowball 1}
        \label{fig:snowball_1}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \includegraphics[width=\linewidth]{plots/snowball_images/chatgpt/snowball_2.png}
        \caption{\footnotesize \centering Snowball 2}
        \label{fig:snowball_2}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \includegraphics[width=\linewidth]{plots/snowball_images/chatgpt/snowball_3.png}
        \caption{\footnotesize \centering Snowball 3}
        \label{fig:snowball_3}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
       \includegraphics[width=\linewidth]{plots/snowball_images/adobe_firefly_image_3/snowball_4.png}
        \caption{\footnotesize \centering Snowball 4}
        \label{fig:snowball_4}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \includegraphics[width=\linewidth]{plots/snowball_images/adobe_firefly_image_3/snowball_5.png}
        \caption{\footnotesize \centering Snowball 5}
        \label{fig:snowball_5}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
        \includegraphics[width=\linewidth]{plots/snowball_images/adobe_firefly_image_3/snowball_6.png}
        \caption{\footnotesize \centering Snowball 6}
        \label{fig:snowball_6}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
       \includegraphics[width=\linewidth]{plots/snowball_images/midjourney/snowball_7.png}
        \caption{\footnotesize \centering Snowball 7}
        \label{fig:snowball_7}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
       \includegraphics[width=\linewidth]{plots/snowball_images/midjourney/snowball_8.png}
        \caption{\footnotesize \centering Snowball 8}
        \label{fig:snowball_8}
    \end{subfigure}
    \begin{subfigure}[b]{0.1\textwidth}
        \centering
       \includegraphics[width=\linewidth]{plots/snowball_images/midjourney/snowball_9.png}
        \caption{\footnotesize \centering Snowball 9}
        \label{fig:snowball_9}
    \end{subfigure}
\caption{Generated snowball patches used for testing.}
\label{fig:snowball_adversarial_image}
\end{figure*}


\subsection{LISA Dataset}

The LISA (Laboratory for Intelligent and Safe Automobiles) dataset is a widely used benchmark for traffic sign classification, containing images of 47 different U.S. traffic signs collected under varying environmental conditions, lighting, and viewpoints~\cite{lisa}. However, due to class imbalances, prior research has often focused on the 16 most frequently occurring traffic signs, improving model performance by ensuring sufficient training data for each class~\cite{hsiao2024natural}. The dataset is commonly used to evaluate the robustness of machine learning models deployed in various autonomous driving systems.

\subsection{Street View Street Signs}

% \hl{FIXME explan Street View and the street view signs you use}
This work evaluates attacks using images sourced from Google Street View~\cite{googleExploreStreet}, which provides real-world depictions of street signs in various environments. By modifying these images, we can assess the effectiveness of attacks in a setting that closely resembles real-world conditions without physically altering street signs. This approach ensures that evaluations remain safe, ethical, and reflective of real-world adversarial scenarios.

Additionally, it is important to note that the LISA-CNN model was not trained on Street View images. Instead, it was trained on the LISA dataset, which consists of traffic sign images collected in controlled settings. The use of Street View images for testing ensures a clear separation between training and evaluation data, reducing the risk of overfitting and making the results more representative of real-world scenarios.

\subsection{LISA-CNN}

LISA-CNN is a convolutional neural network designed for traffic sign classification using the LISA dataset. The architecture consists of three convolutional layers followed by fully connected layers, trained to recognize traffic signs under diverse real-world conditions~\cite{eykholt2018robust}. The model has demonstrated high accuracy in detecting and classifying traffic signs, making it a suitable victim model for studying adversarial vulnerabilities.

In this work, we employ LISA-CNN to evaluate the effectiveness of the Snowball Adversarial Attack. The model processes real-world traffic sign images, allowing us to assess how snow-based perturbations impact recognition accuracy. By systematically analyzing the attackâ€™s effectiveness, we provide insights into how naturally occurring occlusions, such as snowfall, can degrade the performance of machine learning models used in self-driving cars and other autonomous driving~systems.