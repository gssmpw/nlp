\section{Related Works}
\label{sec:related}


\textbf{Deep generative models with GA.} Several studies explore combining GAs and deep generative models, particularly in chemical domains. One direction is that utilizing expert-designed GA to improve the generative models' outcome. ____ and ____ employ Graph GA ____ whose crossover and mutation are designed to guarantee the validity in chemical space, to refine the generated molecules. 
Conversely, some researches suggest to incorporate neural models to enhance or design GAs.s
Notably, in SynNet ____, the neural policy construct offspring conditioned on molecule embedding from the parent, allowing exploiting the generative capability from the deep model similar to our works. However, to ensure the plausibility, SynNet employs domain-specific reaction rules in the subsequent synthesis planning. 
____ utilizes the generative model to refine the molecules obtained by Graph GA to more synthesizable ones. In Reinforced Genetic Algorithm ____, the neural models guides the crossover and mutation process with a protein target structure embedding to overcome a random-work exploration with predefined rules.

More broadly, there is a growing trend that leverages large language models (LLMs) as a black-box operator within GAs, where parent samples are directly fed into LLM to obtain new samples. These LLM-based GAs have been studied in various domains, including prompt optimization ____, molecular design ____, and code generations ____. However, a primary challenge is the reliance on hand-crafted prompt engineering, and many approaches continue to employ problem-specific rules along with the LLM-based operator ____.



\textbf{Test-time search for enhanced inference. } Recent work in large language models (LLMs) ____ demonstrates that dedicating additional computation at test time can greatly improve outputs (see ____ for an overview).
Meanwhile, in combinatorial optimization (CO), its mathematically rigorous algorithmic foundations have inspired a line of research integrating traditional algorithms into test-time search within deep learning. For instance, ____ employ restricted dynamic programming guided by a graph neural network (GNN) that predicts a solution heatmap in routing problems. Meanwhile, ____ and ____ use a predicted edge heatmap in ant colony optimization (ACO) for broader CO applications. ____ propose a new greedy decoding-based search that randomly destroys the generated solutions and reconstructs solutions. Although effective, this method relies on handcrafted rules for destruction.
In addition to external algorithmic integrations, there exist a range of self-improvement approaches, such as beam search ____, sampling (also called \textit{best-of-N}) ____, and Monte Carlo Tree Search ____, and active searches ____ are also employed for refining solutions at test time.

% In deep learning for CO, various test-time search techniques have emerged. ____ and ____ utilize beam search, and ____ extends this to a simulation-guided beam search. 
% Another line of research integrates traditional algorithms (e.g., dynamic programming algorithm ____ and ant colony optimization ____) or problem-specifically designed search algorithms ____.
% Additionally, several studies employ active search approaches to fine-tune a pretrained policy, either via policy exploration ____, greedy rollouts ____, or meta-learning ____.