\section{Related Work}
\label{sec:relatedwork}

\paragraph{Collaborative Object Detection} Collaborative object detection, in which multiple agents collectively perceive a scene via communication, is able to address several dilemmas in individual object detection~\cite{li2022v2x,cai2022analyzing}. Compared to individual detection, multi-agent collaboration introduces more viewpoints to solve the long-range data sparsity and severe occlusions.
% Compared to individual detection, multi-agent collaboration introduces more viewpoints to solve the long-range data sparsity stemming from the restricted sensing capability and to mitigate the influence of severe occlusion in dense traffic scenarios. 
The pioneer collaborative detectors employ early collaboration which shares raw data~\cite{Chen2019CooperCP} or late collaboration which shares output bounding boxes~\cite{arnold2020cooperative}. To further improve the performance-bandwidth trade-off, recent research proposes intermediate collaboration which shares intermediate feature representations from a neural network. Various intermediate collaboration strategies have been developed such as neural message passing~\cite{wang2020v2vnet}, knowledge distillation~\cite{li2021learning}, and attention~\cite{xu2022v2x,xu2022bridging}. However, existing works only focus on improving the performance of collaborative detection, no existing work investigates uncertainty quantification of collaborative object detection. 
% To the best of our knowledge, we make the first attempt to quantify uncertainty in collaborative object detection. 
%\songyang{However, the above works only focus on improving the performance of collaborative detection without considering the uncertainties of the detection results. }

\paragraph{Uncertainty Quantification on Object Detection} 
Different types of uncertainty quantification methods for object detection have been proposed. For epistemic uncertainty, the Monte-Carlo dropout method utilizes the dropout-based neural network training to perform approximated inference in Bayesian neural networks~\cite{miller2018dropout}. The deep ensembles method estimates probability distribution by an ensemble of networks with the same architecture and different parameters~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. Both methods require multiple runs of inference, which makes them infeasible for real-time critical tasks with high computational costs such as collaborative objection detection. Moreover, they do not consider time series properties in the dataset, which is one important characteristic of the autonomous driving dataset. In contrast, our uncertainty quantification method overcomes these problems by tailoring a moving block bootstrap~\cite{lahiri1999theoretical} (MBB, an effective algorithm for time series analysis) algorithm and quantifies the uncertainty of collaborative object detection in one inference pass.

The direct modeling (DM) method is designed to estimate aleatoric uncertainty. The main steps of DM are~\cite{feng2021review}: a) select one object detector; b) set a certainty probability distribution on outputs of the detector and design the corresponding loss function; c) add extra regression layers to predict the covariance; d) train the modified detector. The work~\cite{he2019bounding} proposes the DM method for image object detection, which assumes that the distribution of each bounding box variable is a single-variate Gaussian distribution and introduces one additional layer to estimate the variance of the bounding box. \cite{he2020deep} proposes the DM method with a high dimensional multivariate Gaussian distribution. DM methods for point cloud object detection~\cite{meyer2020learning,meyer2019lasernet} have been proposed. Methods with both DM and MC dropout to estimate aleatoric and epistemic uncertainties in object detection have also been investigated~\cite{kendall2017uncertainties,feng2019leveraging,feng2018towards}. 

All the above works only focus on individual object detection. How to quantify the aleatoric and epistemic uncertainties in collaborative object detection remains challenging. In our work, we tailor an MBB-based algorithm process to estimate both aleatoric and epistemic uncertainties of collaborative object detection, with an independent multivariate Gaussian distribution assumption for each corner of the bounding box to represent the uncertainty.
%In our work, we tailor a DM method to estimate the aleatoric uncertainty of collaborative object detection with a multivariate Gaussian distribution assumption for the output coordinate of each corner, and integrate DM with MBB-based algorithm process to estimate both aleatoric and epistemic uncertainties of collaborative object detection.  % estimates  . However, our work estimates both uncertainties for collaborative object detection. Though Direct Modeling (DM) has been widely used to quantify aleatoric uncertainty for single-view autonomous vehicles, 




%\comment{
%1. unrelated part, dropout and ensembles
%2. The closest works for ours are direct modeling and bootstrap (estimate the tempor-based dataset).}It assumes a certain probability distribution on the outputs, uses network layers to directly predict parameters of the distribution, and uses the Kullback-Leibler divergence between the predictive probability distribution and the groud-truth distribution as the loss function for training.