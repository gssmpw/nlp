\section{Related Work}
\label{sec:relatedwork}


% motion prediction: Kalman Filter~\cite{zhang2021bytetrack, cao2022observation}

% \cite{cao2022observation} shows that MOT is sensitive to state uncertainty.

% Association: Hungarian method, similarity metric (iou)

\paragraph{Collaborative Object Detection (COD)}\label{subsec:cod}
Collaborative Object Detection (COD) surpasses traditional Single-Agent Object Detection (SOD) by harnessing information from multiple agents or sensors, elevating detection accuracy \cite{li2022v2x, xu2022opencood, cai2022analyzing} and mitigating uncertainty \cite{Su2022uncertainty}. Multi-camera object detection (MOD) \cite{jiang2023polarformer} methods use strategically positioned cameras of a single agent to improve performance~\cite{jiang2023polarformer}. In complex scenarios such as low-light conditions, occlusions, and adverse weather, COD outperforms MOD for sharing complementary information by communication between multiple agents~\cite{hu2022where2comm}. Its dynamic integration of insights from various sources enables effective adaptation to changing environments and scene dynamics. Hence, COD harmonizes viewpoints and enables innovative occlusion handling. Moreover, COD extends coverage and precision, with well-designed orchestration to avert redundancy or misalignment~\cite{li2022v2x}. In summary, COD redefines object detection, leveraging collaboration to tackle challenges and chart the future of detection~\cite{xu2022v2x}. 
In this study, we want to show that even though object detection performance has already improved, uncertainty propagation from an advanced model such as COD is still important to enhance the overall performance of subsequent modules.
%Here, the reason that we focus on the uncertainty propagation from COD is that COD has better performance than SOD and MOD and we want to prove that the uncertainty propagation from such a well-performance model can still improve the performance of later modules.
%Prevailing studies have predominantly focused on enhancing the performance of COD. Regrettably, none have delved into the exploration of the uncertainty propagation from COD to subsequent modules.

%\textcolor{blue}{CD: The whole paragraph being bold seems a bit strange}
\paragraph{Uncertainty Quantification and Propagation}\label{subsec:uq}

Uncertainty Quantification (UQ) is vital for the collaborative perception of safety-critical systems such as robots~\cite{rss19, perceptionCBF_corl21} and connected and autonomous vehicles~\cite{han2022solution, han2022stable, he2023robust}. 
%While it seems plausible that the incorporation of uncertainty for each detected object could benefit subsequent modules in self-driving tasks, such as trajectory prediction~\cite{boris2022propagating} and motion planning~\cite{mpUncertain_icra14}, there is no research about how to leverage uncertainty quantification from collaborative object detection (COD) to improve the tracking performance yet. Several methods for uncertainty quantification in OD have been proposed. The Monte-Carlo dropout method involves training neural networks using dropout to perform approximate inference in Bayesian neural networks~\cite{miller2018dropout}. The deep ensembles method estimates the probability distribution by ensembling multiple networks with the same architecture but different parameters~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. Despite their effectiveness, both Monte-Carlo dropout and deep ensembles methods require multiple runs of inference, which can be computationally costly and time-consuming. This limitation makes them less suitable for real-time critical tasks that demand low-latency, such as collaborative object detection.
In self-driving tasks, UQ from COD could improve trajectory prediction~\cite{boris2022propagating} and motion planning~\cite{mpUncertain_icra14}. However, there is no research on how to leverage COD uncertainty to enhance tracking performance. Several methods for UQ in object detection (OD) require multiple inference runs, not designed for real-time tasks like COD, such as Monte-Carlo dropout~\cite{miller2018dropout} and deep ensemble~\cite{lakshminarayanan2017simple,lyu2020probabilistic}. %ovadia2019can
%The Monte-Carlo dropout method involves using dropout-based neural network training to perform approximate inference in Bayesian neural networks~\cite{miller2018dropout}. The deep ensembles method estimates the probability distribution through an ensemble of networks with the same architecture but different parameters~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. 

%However, both methods require multiple runs of inference, making them infeasible for real-time critical tasks with high computational costs, such as collaborative object detection.


 %method is designed to estimate uncertainty and involves selecting an object detector, a loss function and a certainty probability distribution on the outputs, adding extra regression layers to predict the uncertainty, and training the modified detector. 
% For instance, the DM method for image object detection~\cite{he2019bounding} assumes that the distribution of each bounding box variable is a single-variate Gaussian distribution and introduces one additional layer to estimate the variance of the bounding box. Additionally, \cite{he2020deep} proposed the DM method with a high-dimensional multivariate Gaussian distribution. 
Direct modeling (DM)~\cite{feng2021review} methods for OD have been proposed~\cite{Su2022uncertainty, meyer2020learning}. DM is promising for real-time computer vision tasks, as only requires a single inference pass. However, DM lacks rigorous UQ as the model may easily overfit the training dataset. The work in~\cite{Su2022uncertainty} proposes the bootstrap calibrated DM method for COD. However, the bounding box definition it presented, which relies on corner coordinates, is not congruent with tracking algorithms. Conformal prediction (CP)~\cite{angelopoulos2021gentle} is a statistical method that converts any heuristic notion of uncertainty (e.g. standard deviation estimations) into rigorous UQ. To rigorously quantify the uncertainty in COD and propagate the uncertainty to MOT, our MOT-CUP framework leverages CP to calibrate the uncertainty estimation from DM.

%\hl{The work in}~\cite{Su2022uncertainty} \hl{introduces a distinct Double-M Quantification method, concentrating on uncertainty quantification for COD, which has a different task from ours. Further, it is essential to note that the bounding box definition presented in}~\cite{Su2022uncertainty}\hl{ relies on corner coordinates, a representation that may not be congruent with tracking algorithms such as SORT and ByteTrack. The application of its uncertainty quantification method to our uncertainty propagation task is not feasible.}


% Methods with both DM and MC dropout to estimate aleatoric and epistemic uncertainties in object detection have also been investigated~\cite{kendall2017uncertainties,feng2019leveraging,feng2018towards}. 

% Uncertainty propagation~\cite{boris2022propagating}, conformal prediction, uncertain quantification in MOT of single robot perception
\paragraph{Multiple Object Tracking (MOT)}\label{subsec:mot}

Several recent MOT algorithms~\cite{zhang2021bytetrack,cao2022observation,wojke2017simple,choi2015near,zhou2020tracking} use motion models based on Bayesian estimation~\cite{lehmann2006theory} to predict states by maximizing the posterior estimation. Kalman Filter (KF)~\cite{kalman1960contributions}, a widely used motion model, operates as a recursive Bayes filter that follows a standard predict-update cycle. 
% The KF assumes that the true state is an unobserved Markov process, while measurements are observations of a hidden Markov model~\cite{rabiner1986introduction}. 
%However, because the KF is limited by its linear motion assumption, subsequent works, such as the Extended KF~\cite{smith1962application} and Unscented KF~\cite{julier1997new}, were developed to handle nonlinear motion by using first-order and third-order Taylor approximation, respectively. 
Current KF-based algorithms typically use a fixed measured uncertainty for all detections without considering rigorously estimated uncertainty to improve the prediction accuracy. In contrast, we propose a rigorous UQ of the COD process based on CP, and integrating it into KF for enhanced accuracy and uncertainty estimation of output.

Data association is a crucial step of MOT, which involves computing the similarity between tracklets and detected objects and utilizing various strategies to match them based on their similarity. 
% The SORT algorithm~\cite{bewley2016simple} takes a straightforward approach to combine location and motion cues. 
The SORT algorithm~\cite{bewley2016simple} uses the Intersection over Union (IoU) between predicted and detected boxes to determine their similarity. This approach has proven to be highly competitive on a variety of MOT benchmarks, and serves as a strong baseline for more sophisticated tracking methods.
%In contrast, recent methods~\cite{sun2020transtrack,wu2021track,zhou2020tracking} employ networks to learn object motions and achieve more robust results, especially in cases of large camera motion or low frame rates. 
With the similarity, matching strategies assign identities to the objects. This can be achieved through the Hungarian Algorithm~\cite{kuhn1955hungarian} or greedy assignment~\cite{zhou2020tracking}. 
%SORT~\cite{bewley2016simple} matches the detection boxes to the tracklets in a single matching step. 
% DeepSort~\cite{wojke2017simple} proposes appearance features obtained from a pre-trained convolutional neural network as the similarity which is only suitable for images.
ByteTrack~\cite{zhang2021bytetrack} utilizes similarities between the low-quality detections and tracklets to recover accurate object identities,  improving data association performance.
However, using IoU distance as a similarity metric may not be appropriate for low-quality detections as explained in Fig.~\ref{fig:teaser}. 
The Mahalanobis distance is also a widely used similarity score by quantifying the dissimilarity between the detected objects and the distributions of tracklets from the KF model~\cite{bertozzi2004pedestrian}. Nonetheless, substantial uncertainty could result in minimal distances, leading to erroneous matching~\cite{altendorfer2016association,wojke2017simple}. 
%\hl{Appearance similarity is measured by the cosine similarity of the Re-ID features which is extracted by a stand-alone Re-ID model}~\cite{wojke2017simple}. \hl{However, the presence of multiple objects sharing similar appearances can lead to identity switches or mismatches and it is not suitable to point cloud data}~\cite{bai2022re}.
The work in \cite{altendorfer2016association} proposes the association log-likelihood distance to overcome this problem by computing the logarithmized association probability.
Unlike conventional similarity scores, we propose the Negative Log Likelihood (NLL) similarity score, which computes the NLL between the detected distribution of the objects and the mean of the tracklets to focus on the distribution of detections. So it can ignore the large uncertainty and facilitate more accurate associations for low-quality detections.

%Therefore, we propose a new association metric, Negative Log Likelihood (NLL), that is more informative in such situations, to better match low-quality detections and improve the tracking result in accuracy and uncertainty.


