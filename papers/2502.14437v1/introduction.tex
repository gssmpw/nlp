%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Introduction to NLG}
\label{intro} % Always give a unique label

This book gives my perspective on Natural Language Generation (NLG), that is using artificial intelligence (AI) techniques to produce texts in English and other human languages; it draws on
my decades of experience in the field.  I wrote a book (with Robert Dale) on NLG in 2000 \cite{reiterdale2000}, when I had limited experience building NLG systems.  Over the past 25 years I have gained a lot more experience building systems, and this book largely reflects the issues and challenges I faced; most of the examples come from systems I have worked on.  It draws on my experiences at the company Arria NLG (which evolved from a spinout company, Data2text, which I co-founded in 2009) as well as my academic research at the University of Aberdeen.

This book is intended to help students, developers, and researchers understand the fundamental concepts of NLG.  It is not intended to be an up-to-date guide to the latest language model technologies, research papers and commercial offerings.
In particular, the book discusses technology only at a high level because technology changes very fast, hence detailed material on technology would quickly become out of date.  The book's main focus is on fundamental aspects of NLG which change more slowly than technology, including component tasks of NLG, requirements of NLG systems, evaluation, safety and testing, and applications. These topics are essential for success (at least in my experience) but are less often discussed than technology; I hope this book can help readers understand these aspects of NLG.

The book focuses on systems which generate output texts that describe, summarise, explain, etc. the system's input data.  In other words, from the perspective of generative AI systems such as ChatGPT\index{ChatGPT} and Google Gemini\index{Gemini}, it focuses on applications where an input is transformed into an output (see examples later in this chapter), not applications where the user asks a question and the system synthesises an answer from Internet sources


\section{What is Natural Language Generation}
\label{sec:IntroWhatIsNLG}

Natural Language Generation (NLG) systems use artificial intelligence and natural language processing techniques within software systems that generate texts in human languages such as English, Chinese, and Arabic.  In other words, NLG is the science of AI systems that can write. As such it is related to (but not the same as) Natural Language Understanding\index{natural language understanding} (NLU), which is the science of AI systems that can read and extract meanings from human-written texts.

Natural language generation has recently become more prominent because of the success of ChatGPT\index{ChatGPT} and other generative language models, but the field has been around for decades.   AI and NLP techniques such as machine learning and language models are widely used, but they do not tell the whole story.  NLG researchers and developers should understand (Figure~\ref{fig:nlgskills}):
\begin{itemize}
\item \emph{AI and NLP techniques}: technology used to generate texts.
\item \emph{Human-computer-interaction (HCI)\index{HCI}}: how NLG systems can effectively interact with users.
\item \emph{Linguistics\index{linguistics} and psychology\index{psychology}}: how to best use language to communicate with users.
\item \emph{Software engineering\index{software engineering}:} how to build real-world usable software systems.
\item \emph{Domain knowledge\index{domain!knowledge}}: what is important in the target domain, and how it should be communicated.
\end{itemize}

\personal{I have found that research is much more rewarding if it takes the larger context into consideration.  Certainly in my own career I have enjoyed learning about the above areas and collaborating with all sorts of people, ranging from HCI\index{HCI} and usability\index{usability} experts to domain experts\index{domain!experts} in offshore oil platforms\index{oil industry}.   Many of my most influential research papers have benefitted from collaborations with and insights from HCI\index{HCI} experts \cite{knoll-etal-2022-user}, psychologists\index{psychology} and linguists\index{linguists} \cite{mckinlay2010design}, software engineers\index{software engineering} \cite{reiter-2017-commercial}, and domain experts\index{domain!experts} \cite{PORTET2009789}.}


\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.5]{nlgskills.pdf}
\caption{Skills needed for NLG}
\lineacross
\label{fig:nlgskills}       
\end{figure}

From a practical perspective, NLG is used in many different contexts.  My focus in this book is on systems which generate texts which describe, explain, summarise (etc.) an input to the system.   The input can be numbers, in which case the NLG system is a \emph{data-to-text}\index{data-to-text} system (see example in Section~\ref{ArriaWeatherExample}); the input can also be words, in which case the NLG system is a \emph{text-to-text}\index{text-to-text} system (see example im Section~\ref{IntroConsultationSummary}).
Machine translation\index{machine translation} (MT) is sometimes considered to be a type of NLG, and I will occasionally refer to MT, especially when discussing evaluation.  However, readers interested in MT should look at a specialised book such as Koehn's \emph{Neural Machine Translation} \cite{koehn2020}.   I also will not discuss writing assistants\index{writing assistants} (sentence completion, grammar improvements, etc) or tools for generating fictional content\index{fiction generation}.
I discuss using generative language models to produce text, but I do not discuss other capabilities of these models such as language understanding and image generation\index{image generation}.



\section{Example: Weather Forecast (\emph{Data-to-Text})}\label{ArriaWeatherExample}
One of the earliest use cases for NLG was generating textual weather forecasts\index{weather forecasts} from numerical weather predictions.  The numerical weather predictions are produced by atmosphere simulations and give predicted weather parameters (e.g., wind speed, precipitation) at different points and times.  The NLG system takes this information and produces a textual forecast which summarises in words how the weather will develop.
As described below, using NLG to produce forecasts makes it easier to produce specialised forecasts from the same numerical weather prediction data; for example forecasts for different locations or for different types of users.

Many NLG weather forecast systems have been developed over the years, with the first production system entering operational usage in 1992 \cite{Goldberg1994} (Figure~\ref{fig:FoG}).  More recently there has been considerable interest in using neural NLG techniques to allow dialogue systems to respond to weather queries (Section~\ref{sec:Facebookweather}).

Forecast generation is a type of \emph{data-to-text}\index{data-to-text} NLG, that is a system which generates text that summarises a numeric (or symbolic) data set.  In this case, the input data is a large set of numbers which describe wind speed, precipitation, etc.; symbols are used to describe some weather parameters such as wind direction (E, NE, N, NW, etc).   For some types of weather forecasts, the input data set can consist of millions of numbers and symbols \cite{turner-etal-2009-generating}.  The NLG system \scare{digests} and analyses this data, and generates a text which summarises key facts and insights for the user.

Because NLG researchers have worked on generating weather forecasts for over 30 years, it is a good domain to understand NLG issues and technologies, and this book will refer to weather forecast generation in many places.

\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.6, trim = {0.5cm 0 1cm 0},clip]{arriamet}
\caption{Weather forecast from Arria system; Figure 1 from \cite{sripada-etal-2014-case}}
\label{fig:ArriaMet}      
\lineacross 
\end{figure}

\subsection{Use Case: Point weather forecasts for general public}\label{sec:Arriaweather}
My company, Arria\index{Arria}, developed a simple forecast generator for the UK Met Office \cite{sripada-etal-2014-case} in 2014.   It is by no means the most sophisticated NLG system in this space, but it does illustrate weather forecast generation and data-to-text NLG.  The Arria system is not being used at the time of writing, but rule-based techniques are still widely used to produce simple weather forecasts.

This system generates a \emph{point forecast}, that is a weather forecast for a particular location over a time period (such as Heathrow airport in London). \emph{Area forecasts}, in contrast, describe the weather over a region (such as Scotland); NLG systems which generate area forecasts (such as \cite{turner-etal-2009-generating}) tend to be considerably more complex than systems which generate point forecasts.

The Arria system  produced \emph{public forecasts}, that is forecasts which are intended for the general public.  There are also of course many specialised forecasts, for farmers, pilots, sailors, etc; these emphasise different types of information (for example, aviation forecasts describe wind speeds at different altitudes; public forecasts do not). They also often used specialised terminology\index{terminology} (for example, marine forecasts use the verb \lingform{backing} to describe a counter-clockwise change in wind direction).

The commercial goal of the Arria system was to produce weather forecasts for 5,000 different locations; this would be a daunting task for human forecasters.   In general the benefits of NLG are often in allowing large numbers of specialised texts to be produced, so that users can receive texts which are specific to their needs, instead of generic texts.  In other words, an Aberdeen-specific forecast is of more use to me than UK-wide forecast, but producing textual forecasts for the thousands of towns and villages in the UK is difficult without automation.

Figure~\ref{fig:ArriaMet} shows an example public forecast produced by the Arria system for London's Heathrow Airport, and some of the data used to produce this forecast.  The forecast itself is 
\begin{quotation}
Sunshine from mid-morning and into the afternoon.  Staying dry, but becoming cloudier from early evening and into Thursday.   It is likely to feel milder than on Tuesday with a maximum temperature during the afternoon in the region of 11C and a minimum temperature overnight of around 6C.  Light winds throughout.
\end{quotation}

The data used to produce the forecast (ie, the output of the numerical weather model) is a table which shows the values of different weather parameters at different times, for this location.  Part of the table is shown beneath the forecast in the Figure~\ref{fig:ArriaMet}, for example the Temperature at 0000 is 4C.

\subsection{Technology: Rule-based NLG\index{rule-based NLG}}\label{sec:d2tpipeline}

The Arria system uses rules to generate the text (not machine learning).  Details are not given in  \cite{sripada-etal-2014-case}, but in rough terms the rules do the following
\begin{itemize}
\item \emph{Stage 1: Find patterns in data (signal analysis\index{signal analysis}).}  For example, the probability of precipitation is very low (less than 5\%) for the entire period.
\item \emph{Stage 2: Generate insights (data interpretation\index{data interpretation}).}  For example, this will be a dry day.  Insights depend on what the user is interested in.  
For instance, as mentioned above, an aviation forecast will describe wind speed at different altitudes, since this this very important to pilots.  In contrast, a public forecast probably will only describe wind speed at ground level, since this is all the general public cares about.
\item \emph{Stage 3: Decide which insights to present, how they are ordered, and how they are related to each other (document planning\index{document planning}).}  For example, adding a contrast link (expressed as \lingform{but}) between the low-precipitation insight and the insight that cloud cover increases.
\item \emph{Stage 4: Decide how to express insights linguistically, in a stylistically appropriate manner (microplanning\index{microplanning}).} For example, deciding to use the gerund phrase \lingform{staying dry} to communicate the low-precipitation insight.
\item \emph{Stage 5: Generate grammatically correct text (surface realisation\index{surface realisation}).}  For example, capitalising \lingform{Staying} since it is the first word of the sentence.
\end{itemize}
All data-to-text\index{data-to-text} systems must perform the above types of processing in some fashion.  That is, they must find patterns in the data, generate insights which are useful to the user, order and link insights, express insights as words, and deal with grammatical details.  The Arria system does these steps explicitly, using rules.

At the other extreme, a neural model can be trained to go from input data to output text in a single step; but this model would still need to make decisions about patterns, insights, document structure, linguistic expression, and grammar conformance, even if these decisions are buried in a neural network instead of expressed explicitly as rules.  Another approach is to mix technologies, for example to use algorithms and rules to find patterns and generate insights, and a neural model to select and express insights in grammatically correct text.

\subsection{Evaluation}
The Arria system was evaluated by putting it onto a website used by the Met Office to test new technologies, and asking users to rate the usefulness\index{utility} and desirability of the forecasts; this is an example of a \emph{human evaluation based on ratings\index{rating}} (Section~\ref{sec:humanevalrankings}).
Users who submitted ratings were overall very positive, however we need to keep in mind that people who looked at the Met Office \scare{new technology} site may not be representative of Met Office users more generally.
User ratings are often used to evaluate NLG systems, but its considered best practice to try to get a diverse and representative set of users to do this.

This and other points related to evaluation of NLG systems are discussed in detail in Chapter~\ref{evaluation}.

\section{Example: Summarising Consultations (\emph{Text-to-Text})}\label{IntroConsultationSummary}
Weather forecasts are an example of data-to-text NLG, where the input to the NLG system is structured data.   In contrast, \emph{text-to-text}\index{text-to-text} NLG systems generate texts from other texts.   One example is \emph{summarisation}\index{summarisation} systems, which generate texts which summarise input texts.

A concrete example is generating texts which summarise consultations between professionals and their clients.
Such summaries are often useful as a record of what was discussed and decided; in some contexts they are legally required.

\subsection{Use Case: Generating Summaries of Doctor-Patient Consultations}

\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.75]{NoteGenerator}
\caption{Example of Note Generator; Figure 1 from \cite{knoll-etal-2022-user}}
\label{fig:NoteGenerator}       
\lineacross
\end{figure}

Babylon, a UK digital health company, developed the Note Generator\index{Note Generator} system \cite{knoll-etal-2022-user} which generated summaries of  doctor\index{doctors}-patient consultations\index{consultations}.  In the UK and many other countries, whenever a doctor talks to a patient, a summary of this consultation needs to be added to the patient's medical record.  In the past these summaries were written manually, either by the doctor or by a medical scribe who listens to a recording of the consultation.   Interest is growing in automating at least part of the process of summarising a consultation.

Two goals of the Babylon Note Generator system are (A) reduce the amount of manual effort required to create the summary and (B) enable doctors to focus on the patient on the consultation without the distraction of taking notes \cite{knoll-etal-2022-user}.
Note Generator is no longer used\footnote{Babylon unfortunately went bankrupt in 2023}, but similar systems are being developed and used by other healthcare companies at the time of writing, such as Abridge\footnote{\url{https://www.abridge.com/}}.  

A simple example is shown in Figure~\ref{fig:NoteGenerator}.   The consultation is recorded and transcribed by a speech-to-text system; a short extract of a transcript is shown in the Transcript box in Figure~\ref{fig:NoteGenerator}.   The NLG system then produces a summary of the transcript for the patient record (shown in the Note box in Figure~\ref{fig:NoteGenerator}); this communicates key medical information in standardised medical language.  The summary is shown to the doctor, who can edit\index{post-editing} it to add missing information, correct mistakes, etc. before the summary is added to the patient record.


Of course some consultations are more difficult than others; for example it is difficult to write up a consultation when the doctor suspects that the patient may not be telling the truth.  Note Generator focuses on summarising straightforward consultations (which are the majority); doctors still need to manually write notes for difficult cases, especially if information needs to be added beyond what was said in the consultation.  This is common in NLG and indeed AI; the NLG system helps the user with \scare{straightforward} cases, but provides less assistance in more complex, unusual, or novel situations.

\subsection{Technology}\label{sec:notegentech}
The Note Generator system uses \emph{neural language models}\index{language models} to generate the summaries.  A neural language model essentially is a machine learning system which is trained on (input, output) pairs to perform a task.  For the Note Generator, the developers started with a standard model used for summarisation (BART\index{BART} \cite{lewis-etal-2020-bart}) which had been trained on almost 300,000 pairs of news articles and their summaries.  Of course summaries of medical consultations are very different from summaries of news articles, so the developers adapted the model by \emph{fine-tuning}\index{fine-tuning} it on 10,000 examples of previous doctor-patient consultations  which had already been manually summarised and entered into Babylon's patient record system.  This is a common strategy in neural NLG; we train a model on a large data set which is only loosely related to the application, and then use a smaller data set to adapt the model to the target domain and application.

From a summarisation perspective, one unusual aspect of Note Generator was that doctors wanted summaries to be generated incrementally, so that at any point in time there was a summary of the consultation so far \cite{knoll-etal-2022-user}; this is an example of a human-computer interaction constraint (Figure~\ref{fig:nlgskills}).  Previous summarisation systems generated a complete summary from a complete input document, so the team essentially trained the model to generate incremental additions to an existing summary.   The model always added content to the summary, it never changed what the doctors had already seen.  This was novel technology (the team applied for a patent) and shows how taking HCI\index{HCI} considerations seriously can lead to new NLG technology.

\subsection{Evaluation}
The Note Generator System was evaluated in a number of different ways \cite{knoll-etal-2022-user,moramarco-etal-2022-human,moramarcophd}:
\begin{itemize}
\item \emph{Automatic metrics\index{metrics}}: the system was run on a \emph{test set} of historical consultations (which had not been used to train or fine-tune the model), and several different metrics (algorithms) were used to assess how similar the system's output was to the manually-written summary in the historical report.  This is a very common type of evaluation in NLP, which is discussed in Section~\ref{sec:automaticevaluation}.  Such evaluations are easy to do but unfortunately are not always meaningful.  In this case, the scores returned by the metrics were not  good predictors of actual utility \cite{moramarco-etal-2022-human}.
\item \emph{Error analysis\index{error analysis}:} The team asked doctors to find mistakes in the generated summaries, such as incorrect statements, omitted content, and misleading statements.   This information was very useful in itself for understanding where the system worked well and where it did not, and it also was a good predictor of utility.   Evaluations via error analysis are discussed in Section~\ref{sec:humanevalannotations}.
%They are relatively unusual at the time of writing, but they are becoming more common \cite{thomson-reiter-2020-gold}.
\item \emph{Post-edit\index{post-editing} time:} The team asked doctors to edit summaries and fix mistakes, and timed how long this took; post-editing time is one the most important KPI (Key Performance Indicator) for real-world success.  Not surprisingly, the time taken to post-edit was correlated with the number of errors.  This is an example of a \emph{task-based} evaluation\index{task-based evaluation}, where we measure the impact on NLG system has on human task performance; such evaluations are discussed in Section~\ref{sec:humantaskeval}.
\item \emph{Real-world utility\index{utility}:} Last but certainly not least, after the system was deployed and used in real consultations, the team measured how long it took doctors to post-edit notes in real consultations, and how this compared to the time needed to write notes manually before the system was deployed.  They also assessed the number of errors\index{errors} in post-edited Note Generator summaries (from real consultations), and compared this to the number of errors in manually-written summaries. Evaluations of real-world utility and impact\index{impact} are discussed in Section~\ref{sec:impactevaluation}.
\end{itemize}

Using a broad mix of evaluation techniques is good practice, and gives us a better perspective on how well a system is performing.



\section{Technologies}
The first part of this book discusses technologies used to build NLG systems.  Because NLG technology is changing very fast, the discussion is high-level and conceptual; readers interested in details of the latest research paper or commercial product should look at other sources for this information.

\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.5]{nlgtech.pdf}
\caption{Scalability and controllability of different NLG technologies.}
\label{fig:nlgtech}       
\lineacross
\end{figure}

At the most basic level, there are two ways of building NLG functionality: we can write  \emph{rules} and code which execute NLG algorithms, or we can use \emph{machine-learning} models (usually based on neural deep-learning\index{deep learning} technology), which may be trained or fine-tuned on the application domain.  In very crude terms, these technologies involve different trade-offs between the following (Figure~\ref{fig:nlgtech}):
\begin{itemize}
\item \emph{Scalability\index{scalability}:} How much effort is required to build a large-scale NLG system which produces sensible output texts for a wide variety of inputs?
\item \emph{Controllability\index{controllability}:} Can developers and users precisely control what the NLG system does?  A related criteris is \emph{Transparency}\index{transparency}; do developers and users understand how and why the NLG system produces a text?
\end{itemize}
Rule-based NLG\index{rule-based NLG} systems are very controllable and transparent, but large-scale wide-coverage NLG systems may require thousands of rules; creating these rules is expensive and time-consuming.  Neural NLG systems, in contrast, are black boxes which are difficult to control and not transparent, but building such systems can be relatively cheap and quick if appropriate training data\index{training data} is available.

Of course this is a very over-simplified comparison!  For example, software engineering\index{software engineering} tells us that most of the lifecycle costs\index{cost} of a successful software product are in maintenance\index{maintenance}, not initial development, and we do not have a good understanding of how the cost of maintaining a rule-based system compare to the cost of maintaining a neural system.  Maintenance of NLG systems is discussed in Section~\ref{sec:impactevaluation}.


\subsection{Rule-based NLG\index{rule-based NLG}}
Chapter~\ref{rules} looks at rule-based NLG systems, which execute specific algorithms to analyse data, extract insights, choose the content of generated texts, choose words and syntactic structures, and generate linguistically correct output texts (an example was given in Section~\ref{sec:d2tpipeline}).  The chapter focuses on data-to-text\index{data-to-text} because rule-based approaches are rarely used in text-to-text\index{text-to-text} applications.  Rule-based systems often use a modularised \emph{pipeline}\index{pipeline} architecture (Section~\ref{sec:pipeline}), where different modules are used for each of  these tasks (e.g., pattern detection is done by a module specialising in this task), and these modules are usually run sequentially (ie, all pattern detection is done, then all insight generation is done, etc).  Often there is a core set of libraries\index{libraries} and modules which encodes key analytics\index{analytics} and linguistic\index{linguistics} processing algorithms, which is supplemented with a layer of rules that encode domain knowledge\index{domain!knowledge} for a specific application.  

From a high-level perspective, rule-based systems have the advantage of being precise and modifiable; if the system is not doing what the user wants, developers can modify the rules to match user needs.   They are also transparent, auditable\index{auditable}, and can be tested\index{testing} using software engineering techniques; this is important in many commercial contexts, especially in contexts where companies are legally liable\index{liability} if an NLG system makes a mistake.  Finally, rule-based systems are  good at integrating analytics (insight generation) and linguistic (insight expression) reasoning, and in incorporating domain/genre\index{genre} knowledge into both types of reasoning. Their main disadvantage is that writing rules is time-consuming (and can require specialised domain knowledge), especially for systems which have broad or changing use cases\index{use cases}.

For these reasons, rule-based systems work well for business-oriented data-to-text NLG systems in focused domains and use cases where the output needs to be accurate\index{accuracy}.

\subsection{Machine learning and neural models}\label{sec:finetune}
Chapter~\ref{neuralnlg} discusses how \emph{machine learning}, especially \emph{neural deep learning\index{deep learning}} technology, can be used to create models\index{models} which produce texts. This often requires collecting a training set (sometimes called \emph{corpus}\index{corpus}) of example input-output pairs, and using this to create a model for the task; the model essentially learns from the corpus how to map system inputs into textual outputs.

Training a high-quality language model from scratch requires a lot of training data\index{training data}, typically at least a billion tokens (words).  Most NLG applications do not have this much training data available; for example only 10,000 input-output pairs (consultation transcript and corresponding human-written summaries) were available to train Note Generator\index{Note Generator} (Section~\ref{IntroConsultationSummary}).  Fortunately, we can also build good models by \emph{fine-tuning} general-purpose \emph{large language models (LLMs)}\index{large language models} (these are sometimes called \emph{foundation} models\index{models!foundation}).  In other words, we can take a large generic model such as BART\index{BART} \cite{lewis-etal-2020-bart} or T5\index{T5} \cite{raffel2020exploring} which has been trained on billions of tokens of generic Internet material, and then adapt the model to a specific task using a smaller corpus of actual input-output pairs for this task.  This was the approach used in Note Generator; the 10,000 pairs of transcripts and corresponding human-written summaries were not sufficient to train a good model from scratch, but they were sufficient to fine-tune a large generic model (BART).

Some LLMs, such as ChatGPT\index{ChatGPT}, can be used without training or fine-tuning corpora, by simply asking the model (via a \emph{prompt}\index{prompt}) to generate a text.  For example, in order to summarise a text, we could give ChatGPT a prompt which says something like \lingform{Summarise the following text}, followed by the text to be summarised (Fig~\ref{fig:chatgpt1}).  In this example the summary is not very good (almost as long as the original text), but it was generated without needing any application-specific or domain-specific training or fine-tuning!   We can optionally include a small number of examples (5 or 10, not 10,000) in the prompt in order to give the model some guidance as to what we are looking for; we can also use \emph{prompt engineering}\index{prompt!engineering} to tune the wording of the prompt in order to get a more appropriate result.

\begin{figure}
\lineacross\\
\textbf{Prompt: (input to ChatGPT)}\\
Summarise the following text:\\
I think journals do a much better job than conferences at reviewing papers. This year I got a good perspective on this issue, because I was both an Action editor at TACL (Transactions of the ACL), which is a leading NLP journal; and a Senior Area Chair for the ACL conference, which is a leading NLP conference. The experience reinforced my belief that reviewing is better at journals, and I summarise some of my observations below.\\
\\
\textbf{Result: (from ChatGPT)}\\
The author believes that journals are more effective than conferences when it comes to reviewing papers. Their perspective on this matter was strengthened by their dual role as an Action editor at TACL, a reputable NLP journal, and a Senior Area Chair for the ACL conference, a prominent NLP conference. Based on their experience, they summarize their observations supporting the superiority of journal reviews.

\caption{Using a large language model (ChatGPT) for NLG}
\label{fig:chatgpt1}       
\lineacross
\end{figure}

From a high-level perspective, the great advantage of ML approaches is that they can be used to build wide-coverage NLG systems, without needing to write a large number of rules.  Neural NLG systems are also very good at generating readable\index{readability} and fluent\index{fluency} texts.  A substantial amount of training data is needed to fine-tune models (and much more data to train models from scratch), but we do not need training data if we can simply prompt an existing model to do the task (as in Figure~\ref{fig:chatgpt1}). 

On the other hand, neural NLG systems are difficult to control\index{controllability}; for example if the user wants the output texts to be modified in specific ways, this is not  straightforward with neural models. Sometimes this can be done by modifying a prompt, but this is not always sufficient.  Another major problem is that neural models can generate texts which are factually inaccurate\index{accuracy} or otherwise have inappropriate\index{appropriateness} content.  A related point is that software testing\index{testing}  and quality assurance (Section~\ref{sec:testingnlg}) of neural systems is challenging, since they are not transparent and understandable.   For this reason, neural NLG is often used in \emph{human-in-the-loop}\index{human-in-loop} workflows (Section~\ref{sec:workflow}), where a person checks and fixes the model's output (as is the case with  Note Generator), at least in contexts where accuracy is very important.  However human-in-the-loop may not be necessary in contexts where accuracy is not of paramount importance, such as generating fiction or advertising material.






\subsection{Combining rules and ML}
It is of course possible to build NLG systems which combine rule-based processing and machine learning.  One approach is to use a pipeline\index{pipeline} architecture, but have some of the processing within modules done by neural systems \cite{castro-ferreira-etal-2019-neural}.   For example, we can use rules where precision and accuracy\index{accuracy} are very important (selecting key insights to communicate?), and neural techniques where fluency\index{fluency} is very important (choosing syntactic structures of sentences?).

A variant of this is to generate an initial draft text using rules, which is guaranteed to have the right content (insights) but may not be very readable, and use a language model\index{language models} to rewrite the text to make it more fluent and readable \cite{kale-rastogi-2020-template}.

Another approach is to build two systems, one neural and one rule-based, run both, and use a selection module to decide which of the two outputs to use.  For example, the selection module could test the text produced by the neural system for accuracy errors, and use the neural text if none were detected and the rule-based text otherwise \cite{heidari-etal-2021-getting}.




\section{Effectiveness}
The second part of this book looks at the usefulness and effectiveness of NLG systems. It starts by looking at \emph{requirements}, in other words what NLG systems need to do in order to be useful.  It then looks at \emph{evaluation}, i.e. measuring how well NLG systems meet important quality criteria (as determined by requirements).  It concludes by looking at \emph{safety and testing}, which focus on whether the system behaves unacceptably in a few cases even if it is fine in most cases.

\subsection{Requirements}\index{requirements}
Chapter~\ref{requirements} looks at requirements for NLG systems; what do real-world users want NLG systems to do?  Where does NLG \scare{add value} in real-world use cases\index{use cases}, and how does it impact workflows?   What specific NLG capabilities are needed by users?

Questions like the above are often ignored by academic researchers, but they are very important for real-world success.  Just as with other types of software, an NLG system is not going to succeed if we do not understand user requirements and more generally how users will react to the NLG system.  Some of the key requirements issues discussed in Chapter~\ref{requirements} are:

\begin{itemize}
\item \emph{Quality Criteria:}\index{quality criteria} What are the text (and system) characteristics which may be important to users and other stakeholders\index{stakeholders}, and which of these matter most in different contexts?  For example, when is accuracy\index{accuracy} more important than readability\index{readability}?  Also, are users only interested in average text quality, or do they need a guarantee that all texts will meet a minimum quality threshold?
\item \emph{Workflows:}\index{workflow}   While some NLG systems operate without human supervision, many NLG systems collaborate with humans and as such are integrated with human workflows.   What are different \scare{human-in-the-loop}\index{human-in-loop} workflows and when do they make sense?
\item \emph{Text and Graphics:}\index{graphics} Computer systems can communicate information and otherwise interact with users using visualisations and interactive data graphics as well as text.  When is text the best interaction and communication modality?  How should NLG texts should be combined and integrated with visualisations\index{visualisations}?
\item \emph{Understanding Requirements:}  How do NLG developers work with users and other stakeholders in order to understand their needs?  Many techniques for requirements acquisition\index{requirements!acquisition} have been developed in other parts of computing science, how can we adapt these to work for NLG \cite{knoll-etal-2022-user}?
\end{itemize}


\subsection{Evaluation}
Chapter~\ref{evaluation} discusses evaluation of NLG systems.
From a scientific perspective, we need to be able to evaluate NLG models, algorithms, and systems, in order to understand how they compare to previous work and also where further work is needed.  

Scientific evaluation is essentially hypothesis testing\index{hypothesis testing}.  In very general terms, we can evaluate NLG systems by asking people to examine or use generated texts (\emph{human evaluation})\index{human evaluation}, by using \emph{automatic metrics}\index{metrics} (algorithms) to assess the quality of texts, or by assessing the system's real-world impact\index{impact} when deployed (\emph{impact evaluation}).   For all types of evaluation, a key question is how meaningful it is, and in particular whether the evaluation is a good predictor of real-world utility\index{utility}.

There are many kinds of human evaluation.   The most expensive, and usually the most meaningful, are \emph{task-based evaluations}\index{task-based evaluation}.  Such evaluations involve asking domain experts\index{domain!experts} to perform a task using the generated text, such as asking doctors\index{doctors} to decide on a medical intervention for a patient after reading an NLG summary of the patient's status \cite{PORTET2009789}.  A more common approach (which not coincidentally is considerably cheaper and quicker) is to ask non-expert subjects to read generated texts and either rate\index{rating} them on quality factors such as accuracy and readability, or rank\index{ranking} (order) texts based on a quality factor.  Such studies need to be carefully designed in order to be meaningful \cite{VANDERLEE2021101151}.  Another approach to human evaluation is to ask subjects to annotate errors and other problems in generated texts; this is often more meaningful than rating-based evaluation, but can also be more expensive.

Metric (algorithmic) evaluations are usually much cheaper and faster than human evaluation; because of this, metric evaluations can be done more frequently and on a larger scale than human evaluation (a typical academic human evaluation may look at one hundred texts; a metric evaluation can look at many thousands or even millions of texts).   At the time of writing, most metric evaluation is \emph{reference-based}, that is generated texts are algorithmically compared against human-written \scare{gold standard} \emph{reference} texts\index{reference texts}.   Numerous such metrics have been designed, and they are usually \emph{validated} by seeing how well they correlate with high-quality human evaluations.  Correlation may depend on factors such as text quality; for example a metric may correlate well with human evaluations of low-quality NLG texts but not of high-quality NLG texts.  There are also \emph{no-reference} metrics which assess the linguistic quality of a text in isolation, including well established formulas such as Flesch-Kincaid scores. Interest is growing in using large language models\index{large language models} such as GPT to evaluate texts (both with and without references), this seems to work well in many contexts.

Impact evaluation is perhaps the hardest to carry out, not least because evaluating a system in production\index{production} usage may raise ethical\index{ethics} issues; for example if we evaluate a medical decision support system in real clinical usage, we need to show beforehand that the system will not damage patient care.  The most rigorous impact evaluation is to conduct a \emph{comparison experiment}\index{comparison experiment} where some people use the NLG system and others use an alternative system, and compare outcomes; this is related to \emph{A/B Testing}\index{A/B testing}.  An alternative is a \emph{historical comparison}\index{historical comparison} where an NLG system is deployed to a set of users, and \emph{Key Performance Indicators (KPIs)} are compared before and after the system is introduced.




\subsection{Safety\index{safety}, Testing\index{testing}, and Maintenance\index{maintenance}}
Developers of real-world NLG systems need to ensure that their systems are safe (never harm users), properly tested from a software perspective (including edge cases\index{edge cases}), and maintained as the world and user needs\index{user needs} evolve.
Chapter~\ref{safetytesting} looks at these issues.

There are many aspects of \emph{safety}.  NLG systems should not generate texts which include profanity, racist language, or other socially unacceptable language.  They should not encourage users to do harmful activities such as self-harm, suicide, or killing someone \cite{bbc:chatbotkillqueen};  they should not give misleading advice or information which could harm the user more generally (including poor medical advice \cite{Bickmore:jmir18}); they should not make the user feel stressed or depressed \cite{balloccu2024ask}; and they should not divulge sensitive data to unauthorised users.   Furthermore, such behaviour should \emph{never} happen.   In other words, we should design NLG systems that never exhibit the above behaviour under any circumstances.  This is a very important but also very difficult challenge, especially for NLG systems which use neural models (whether trained, fine-tuned, or prompted).

Like other software systems, NLG systems need to be \emph{tested} before they are deployed and released to customers, in order to ensure that the system is robust\index{robustness} and that generated texts are of acceptable quality.  Of course classic software engineering\index{software engineering} techniques can be used for NLG testing, but NLG has the additional challenge that there are usually many ways to express information in words, so it is difficult to create \emph{test cases}\index{test cases} which pair an input with a specific target output (because there may be other outputs which are just as good).  A related issue is that many NLG systems are \emph{stochastic}\index{stochastic} which means that they can produce different outputs from the same input on different runs; this also makes it harder to use standard software testing techniques

Last but not least, \emph{maintaining} NLG systems can be challenging.  Software engineering tells us that most of the lifecycle cost of a software system is in maintaining the software, including adapting it to changing data sources and user needs as well as fixing bugs\index{bugs}.   Unfortunately, very little is known about maintaining NLG software, especially neural systems.  Maintaining rule-based NLG is probably similar to maintaining programmatic code, but maintaining a system which is trained on data offers additional challenges.

One such challenge is adapting neural NLG systems as the world changes (what is sometimes called \emph{domain shift}\index{domain!shift}).  For example, suppose a new medication is introduced which is very effective at treating cancer, and we want a medical NLG system to consider this medication in its recommendations.  Since the medication is new, we will not have a corpus of training data to update the system.  Strickland \cite{strickland2019ibm} points out that such cases were very challenging for the IBM Watson\index{IBM Watson} question-answering system.

\section{Use Cases\index{use cases} and Applications\index{applications}}
The final part of this book (Chapter~\ref{applications}) describes some NLG use cases and applications,  The chapter first introduces general guidelines for successful applications, and then discusses four specific domains: journalism\index{journalism}, business intelligence\index{business intelligence},summarisation\index{summarisation} and health\index{health}.

NLG is being used in a huge range of different applications.  It is not possible to make general statements which apply to all of these, except perhaps that the necessary input data must be available,
but in most cases successful NLG applications have the following characteristics:
\begin{itemize}
\item \emph{Scalability\index{scalability} and configurability\index{configurability}:} The NLG system is used to generate a large number of texts for a large number of users.  This usually means that the system is configurable to some degree, so that users can customise it for their requirements, data sources, etc.
\item \emph{Acuracy\index{accuracy} and utility\index{utility}:} The NLG system reliably  generates high-quality useful and accurate texts.  Even a small number of low-quality outputs can reduce users' trust in the system.
\item \emph{Acceptability\index{acceptability}:} Users accept and want to use the NLG system; they do not, for example, see it as a threat to their jobs.
\item \emph{Benefits\index{benefits}:} The system must provide significant benefits to its users, which exceeds its cost and offer a good return on investment\index{return on investment}.  This is not always needed in the short term if investment capital is available, but it is crucial for long-term success.
\end{itemize}

Looking at specific application domains, NLG can be used in \emph{journalism}\index{journalism} to automatically write some types of articles in newspapers and other media.  Figure~\ref{fig:bbcelectionIntro} shows a simple example of this, which is a BBC news article about the 2019 UK general election in a specific constituency.  This was generated automatically using technology from Arria\index{Arria} (my company).   Like most such generated articles, the BBC\index{BBC} election reports were checked by human journalists before they were released to the public.  The advantage of using NLG in this case was largely speed; old news is stale news, and using NLG to produce these articles meant they could be released the morning after the election, which would not have been possible if the articles had been manually written.

\begin{figure}
\lineacross{}
Florence Eshalomi has been elected MP for Vauxhall, meaning that the Labour Party holds the seat with a decreased majority.

The new MP beat Liberal Democrat Sarah Lewis by 19,612 votes. This was fewer than Kate Hoey's 20,250-vote majority in the 2017 general election.

Sarah Bool of the Conservative Party came third and the Green Party's Jacqueline Bond came fourth.

Voter turnout was down by 3.5 percentage points since the last general election.

More than 56,000 people, 63.5\% of those eligible to vote, went to polling stations across the area on Thursday, in the first December general election since 1923.

Three of the six candidates, Jacqueline Bond (Green), Andrew McGuinness (The Brexit Party) and Salah Faissal (independent) lost their Â£500 deposits after failing to win 5\% of the vote.

\textbf{\textit{This story about Vauxhall was created using some automation.}}

\caption{Example story from BBC election reporter, from \url{https://www.bbc.co.uk/news/technology-50779761}}
\label{fig:bbcelectionIntro}
\lineacross
\end{figure}

NLG can also be used to explain and summarise data in a \emph{Business Intelligence (BI)} context, including data about sales, profits, inventories, customers, suppliers, employees, etc.   At the time of writing, most BI data is communicated graphically\index{graphics} using BI tools such as Tableau, but some types of insights are best communicated in words instead of data visualisations\index{visualisations}.  BI NLG systems can be very scalable\index{scalability}: almost every business in the world is interested in sales, profits, etc.

Another long-standing use case of NLG is summarising textual information.  Note Generator (Section~\ref{IntroConsultationSummary}) summarised doctor-patient consultations; NLG systems can also summarise emails, legal documents, news articles, product reviews, and  many other types of documents.

Finally (at least in this chapter), NLG can be used in \emph{medicine and healthcare}\index{health}.  A large number of medical applications of NLG have been explored in the academic literature over the years, including
\begin{itemize}
\item \emph{reporting\index{reporting}:} tools that help clinicians create medical documents, such as Note Generator (Section~\ref{IntroConsultationSummary}).
\item \emph{behaviour change\index{behaviour change}:} tools to encourage healthier behaviour in smoking \cite{REITER200341}, diet \cite{balloccu-reiter-2022-comparing}, etc.
\item \emph{patient information\index{patient information}:} tools that explain medical information and patient data to patients \cite{mahamood-reiter-2011-generating}.
\item \emph{clinical decision support\index{decision support} tools:} tools that help clinicians decide on appropriate medical interventions for patients \cite{PORTET2009789}.
\end{itemize}
The commercial NLG community has explored additional opportunities, such as business intelligence for health organisations.

Although there are many exciting opportunities in using NLG in healthcare, it can be difficult to deploy NLG (and indeed AI) solutions in medicine.  This is partially because of understandable safety\index{safety} concerns (we cannot take the risk that an NLG system could damage the quality of care), and also partially because the huge diversity of the healthcare sector (especially if we look worldwide) makes it difficult to build scalable\index{scalability} solutions.  In other words, we can build NLG solutions that help one hospital, but it is difficult to build solutions that help hundreds of hospitals because there is little standardisation between hospitals in IT systems, equipment, clinical procedures, administrative processes, etc.

\section{Ethics}\index{ethics}
NLG systems need to behave \emph{ethically}.  In other words, NLG systems need to act in a manner which is acceptable to society\index{society} and does not harm users or third parties.  

AI ethics is a very broad area, which of course goes well beyond NLG; I will just mention a few issues here.
One is \emph{accessibility\index{accessibility} across languages and communities}.  In particular, much better NLG technology and resources are available in widely-spoken world languages (such as English, German, and Mandarin) than in \emph{under-resourced}\index{under-resourced languages} languages  such as Scottish Gaelic, Maltese, and isiZulu; this may encourage speakers of these languages to make more use of English.  Also some communities (such as gypsies and travellers in the UK) are under-represented\index{under-represented communities} in the corpora\index{corpus} used to train large language models\index{large language models}; applications developed for such models may therefore not work well for members of these communities.  From a technology perspective, it would be good to have more work on NLG in under-resourced languages and for under-represented communities.

Another issue is \emph{bias}\index{bias}.  For example, an NLG system may generate texts which use male pronouns to refer to doctors and female pronouns to refer to nurses; this can support and reinforce gender stereotypes\index{gender stereotypes}.  Such biases can manifest in more subtle ways as well \cite{ciora-etal-2021-examining}.   Unfortunately it can be difficult for developers to detect such issues, especially if they are not in the biased-against group.  For this reason it is useful to get a diverse set of users, with different demographics and background, to check NLG texts for bias.

 \emph{Unethical use cases} can also be a problem, such as generating fake new\index{news!fake} or misinformation\index{misinformation} which is intended to stop people from voting.  Of course working explicitly on such applications is unethical.  A trickier case is developing technology which can be applied to both ethical and unethical use cases, such as techniques for generating persuasive\index{persuasion} texts.  It is hard to give crisp guidelines about \scare{dual-use} technology, but I encourage developers to think about this issue and decide what they personally are comfortable with.

\emph{Theft of intellectual property}\index{intellectual property} can be a concern with neural NLG systems based on large language models.  If an NLG system simply regurgitates (in whole or in part) what a person has written, then the human author needs to be acknowledged.  If the original human-written text was not licensed for general reuse (for example with a Creative Commons\footnote{\url{https://creativecommons.org/}}\index{Creative Commons} license), then it can only be reused with permission from the human author, who may expect some compensation.

Another issue is \emph{job losses}\index{job losses}.  Like other AI and IT technologies, NLG can lead to jobs being automated; for example we may need fewer weather forecasters if NLG is used to generate weather forecasts\index{weather forecasts}.  Automation can also make jobs less interesting and rewarding; for example journalists\index{journalism} may be told to check and fix up AI-written articles (Section~\ref{journalism}), instead of writing articles themselves.   Again there is no easy answer to this problem; if we had refused in the past to adapt technology that automated jobs, then we would still be living in an agrarian society where 90\% of people worked on farms.  As above, I encourage developers to think about this issue and decide what they personally are comfortable with.

Last but not least,  NLG researchers and developers need to ensure that experiments used to evaluate NLG systems are ethical and cannot harm experimental subjects or third parties; this is discussed in Section~\ref{sec:researchethics}.

There are grey areas.  For example, in general it is not ethical for NLG systems to lie\index{lies}.  However an NLG system which informs relatives about the state of a sick baby may wish to be economical with the truth when communicating with an elderly great-grandmother who could have a heart attack if she hears bad news \cite{vanDeemterLying}.




\section{A Very Short History of NLG}

\subsection{Early history}

Speculation about algorithmic and mechanical generation of texts dates back at least to the seventeenth century \cite{peter1677artificial}.
The earliest work on rule-based NLG\index{rule-based NLG} as described in this book was done in the 1960s, in the context of building machine translation\index{machine translation} systems.  Whereas modern MT systems use neural models to directly create a target-language output from a source-language input, early MT systems usually analysed the source language input into an intermediate structure, made changes to the structure to suit the target language, and then generated text in the target language from the intermediate structure.  This last step was essentially NLG, and researchers working on this were the first researchers who attempted to dynamically construct sentences using natural language technologies \cite{sakai-nagao-1965-sentence}.

The 1970s saw the first PhD theses on NLG which were not connected to Machine Translation.  For example, Goldmans' PhD thesis developed techniques for generating texts from conceptual dependency models \cite{goldman:phd}, and Davey's PhD looked at generating summaries of tic-tac-toe games \cite{davey:PhD}.

The 1980s saw a lot more research activity in NLG, including the first work on data-to-text \cite{kukich-1983-design} (Figure~\ref{fig:kukich-stock}), and developments of text summarisation technology \cite{Marsh1984}. There also was a movement towards separating NLG into component tasks, and in particular separating content decisions (\emph{what to say}) from linguistic decisions (\emph{how to say}).  The NLG community also developed more of an identity, with the founding of the ACL Special Interest Group in Generation (SIGGEN).  The first International Workshop on Natural Language Generation was held in 1983.  Researchers also began looking at NLG applications, for example in weather forecasts\index{weather forecasts} \cite{kittredge-etal-1988-multi}.

\subsection{1990-2014}
Research interest in NLG grew in the 1990s, with researchers investigating a broad range of topics including generating texts in multiple languages,  integrating text and graphics\index{graphics}, and generating different texts for different users.   The first shared tasks appeared in text summarisation, such as SUMMAC \cite{mani-etal-1999-tipster}.   Software libraries\index{libraries} for doing NLG tasks were released \cite{elhadad-robin-1996-overview}, so researchers did not need to build everything from scratch.

In the late 1990s, researchers started looking at data-driven techniques for NLG, including ngram models, statistical models, and machine learning (the systems mentioned above all used rules or algorithmic code).  This was successful in text summarisation \cite{radev-etal-2002-introduction}, but less successful in data-to-text systems.

Evaluation also grew in importance, and researchers experimented with a wide range of techniques, ranging from simple metrics\index{metrics} such as BLEU\index{BLEU} \cite{papineni-etal-2002-bleu} and ROUGE\index{ROUGE} \cite{lin-2004-rouge} to large-scale task-based evaluations\index{task-based evaluation} with real users \cite{REITER200341,mani2002summac}.   The first meta-evaluation studies were done to see how well different types of evaluation agreed with each other \cite{reiter-belz-2009-investigation}.

From a commercial perspective, this period had an exciting start, when CoGenTex\index{CoGenTex} (the first-ever specialist NLG company) operationally deployed the FoG\index{FoG} weather forecast system in 1992 \cite{Goldberg1994} (Fig~\ref{fig:FoG}).  However commercial NLG did not really begin to take off until the latter part of this period, when several specialist NLG companies were founded, including my company Data2Text\index{Data2Text} (which was bought by Arria\index{Arria}), Ax Semantics\index{Ax Semantics}, and Narrative Science\index{Narrative Science}.

\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.75]{fog-output}
\caption{FoG, the first-ever commercial NLG system, which went live in 1992. From cogentex.com (website is now defunct).}
\label{fig:FoG}       
\lineacross
\end{figure}

\subsection{2015-2024}
This period is very recent, so it is difficult to give a historical perspective, but around 2015 neural deep-learning\index{deep learning} technology started being used in NLP and NLG.  Researchers had in fact been exploring using neural techniques in NLG since the 1980s \cite{kukich1987phrases}, but such work had limited impact before deep learning  became popular.  Deep learning neural approaches were very successful in academic circles, and by 2020 this technology dominated academic NLP conferences and journals.  Conferences also grew in size; 320 papers were presented at the Association for Computational Linguistic conference in 2015, while over 1000 papers were presented at this conference in 2023.   Perhaps because of this growth, many exciting new uses for language generation technology were explored, such as image captioning\index{image captioning} (image-to-text).   There was also a strong and welcome trend towards making code and datasets publicly available for other researchers.  In 2022 the ChatGPT\index{ChatGPT} system was introduced, and the research community started focusing more on using prompted LLMs to generate texts

One consequence of the dominance of neural technology was that different types of NLG systems became more likely to use the same technology.  For example, the 2014 Arria weather system (Section~\ref{ArriaWeatherExample}) used completely different technology than 2022 Note Generator (Section~\ref{IntroConsultationSummary}).  However both Note Generator and Facebook's 2021 weather system \cite{heidari-etal-2021-getting} (Section~\ref{sec:Facebookweather}) were based on fine-tuning and adapting the BART\index{BART} language model \cite{lewis-etal-2020-bart}.

The commercial NLG world is changing extremely quickly at the time of writing.  Companies initially were slower to adapt neural techniques than academics, because of concerns over accuracy\index{accuracy}, quality assurance and testing\index{testing}, controllability\index{controllability}, and maintainability\index{maintenance}.    However, since the introduction of ChatGPT there is huge interest in using prompted models to generate text in commercial applications.  It is too soon to say where such models will prove successful in real-world usage, and where concerns about accuracy, quality, etc will motivate the continued use of
rule-based or programmatic approaches

\subsection{My personal NLG journey}
On a personal note, I got my PhD thesis in 1990, from Harvard, on the topic \emph{Generating Appropriate Natural Language Object Descriptions} \cite{reiter:phd}.  The most important part of my thesis was work on generating \emph{referring expressions}\index{referring expressions} for entities.  After my PhD, I further developed my ideas on this topic while doing a post-doc at the University of Edinburgh.  I worked with Robert Dale, who was also interested in this area \cite{DALE1995233}.  In 2000 Robert and I published the first ever book dedicated to NLG, \emph{Building Natural Language Generation Systems} \cite{reiterdale2000}.

In 1995, after spending a few years at CoGenTex\index{CoGenTex} (which developed the Fog\index{FoG} system, Fig~\ref{fig:FoG}), I moved to the University of Aberdeen.  Around 2000 I started focusing on data-to-text\index{data-to-text}, working on projects such as SumTime (generating weather forecasts\index{weather forecasts}) \cite{REITER2005137} and Babytalk (generating summaries of electronic patient records) \cite{PORTET2009789}.  One of my papers, on the architecture of data-to-text systems \cite{reiter-2007-architecture} was given a Test-of-Time award by the INLG conference as the most influential paper published in any INLG conference before 2022.

In 2009 I founded a company, Data2Text\index{Data2Text}, to commercialise data-to-text, and by 2012 I was spending almost all of my time at the company (which was bought by Arria\index{Arria} in 2013).  It was very exciting; we did a lot of work for the oil industry\index{oil industry}, and I really enjoyed working with engineers\index{engineers} and exploring how NLG could help them.

Around 2017 I started to re-engage with academic life, and by 2023 I was once again a full-time academic.  My research interests focused on evaluation, especially human evaluation\index{human evaluation} (e.g., \cite{reiter-2018-bleu,thomson-csl23,belz-etal-2023-missing,wu-etal-2023-experts,thomson-cl24}); this partially arose from my frustration at the poor-quality evaluations that dominated early work in neural NLG, which meant that much of this work was scientifically meaningless.  Evaluation quality has improved since 2017, but unfortunately many evaluations published in the academic literature are still of disappointing quality and/or difficult to reproduce.

\section{Resources and Further Reading}
Numerous surveys of NLG have been published in the academic literature, but most focus on technology and quickly become out of date.  Likewise many textbooks on natural language processing include sections on NLG, but the focus is almost always on technology.  Since technology evolves so rapidly, I do not give recommended sources here, but instead encourage readers to find up-to-date sources.   There are also of course many commercial white papers on NLG, but these usually do not provide a balanced scientific view of the field.

Two surveys which go beyond technology are Gatt and Krahmer (2018) \cite{gatt2018survey}, who take a broad perspective on NLG, and Gehrmann et al (2023) \cite{GehrmannEvaluation}, who focus on NLG evaluation.

The Special Interest Group on Natural Language Generation (SIGGEN) (\url{https://siggen-acl.github.io/}) of the Association for Computational Linguistics (ACL) organises academic conferences and other events about NLG topics, including the annual International Natural Language Generation (INLG) conference.

The \emph{ACL Anthology} (\url{https://aclanthology.org/}) contains free downloadable copies of all papers published at conferences and journals sponsored by the Association for Computational Linguistics (and a number of non-ACL venues as well), including SIGGEN events such as INLG (\url{https://aclanthology.org/sigs/siggen/}).  The Anthology is not always easy to search, but if you know what you are looking for, it is a great resource (and one that I personally use all the time).

Huggingface\index{Huggingface} (\url{https://huggingface.co/}) is an excellent source for datasets and code libraries, especially for neural NLG.  Popular Huggingface resources are often well documented and supported.

For further reading on topics discussed elsewhere in this book, please consult the relevant chapter.  For example, further reading on applications of NLG is available in Section~\ref{sec:furtherApplications}.

The ACL maintains a good bibliography of papers specifically about ethics in Natural Language Processing, see \url{https://github.com/acl-org/ethics-reading-list}.  The only paper I am aware of which is specifically about ethics in NLG is Smiley et al \cite{smiley-etal-2017-say}.

Little has been published specifically about the history of NLG.  However I gave a talk about this, which is available on YouTube at \url{https://www.youtube.com/watch?v=SEw47Y_ZN8Q}.








