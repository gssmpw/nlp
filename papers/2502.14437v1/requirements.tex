%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Requirements}
\label{requirements} % Always give a unique label


One of the most important questions in applied NLG is user requirements\index{requirements}; what do real-world users and other stakeholders want NLG systems to do?  AI systems are only useful if they do what users want them to do \cite{stangle:blindimages}.

Of course requirements depend on the use case\index{use cases}, which is discussed in Chapter~\ref{applications}.  There is a large literature on requirements in the general software engineering\index{software engineering} literature, which NLG system builders should be familiar with.

At the simplest level, requirements analysis\index{requirements!analysis} is about understanding what texts the NLG system should generate from different inputs in different contexts; what is their content, and how is this content expressed. The first step in this process is to explore high level issues such as:
\begin{itemize}
\item \emph{Quality Criteria}\index{quality criteria} (Sections~\ref{req-criteria} and \ref{system-req-criteria}):  What aspects of quality are important to the users?  Are they more interested in readability\index{readability} or in accuracy\index{accuracy}? Does worst-case\index{worst-case} performance matter as well as average-case? How important are non-functional aspects such as time needed to generate a text?  \emph{Different quality criteria are important in different use cases and contexts}; for example accuracy is not important when generating fiction, but it is very important when generating texts that support medical decision-making.
\item \emph{Workflow}\index{workflow} (Section~\ref{sec:workflow}): NLG systems can be used in many different \emph{workflows}.  In particular, they can be used fully automatically (with no human involvement); with a human checking and \emph{post-editing}\index{post-editing} the NLG output texts before they are released; or to create draft material which human writers can use if they wish.  Each of these workflows has associated requirements.  For example, NLG systems used in a context with human checking and post-editing do not need to generate perfect texts, but they must be integrated into a user interface which makes human post-editing as easy as possible.
\item \emph{Text and Graphics}\index{graphics} (Section~\ref{sec:textgraphics}): A key question from a requirements perspective is where users want to see information communicated in words, and where they would prefer that information be communicated visually, for example using information graphics\index{graphics!information}.  Often the best strategy from the users perspective is to use a mixture of text and graphics to communicate information.
\end{itemize}

Various methodologies can be used to understand the requirements of an NLG system.
\emph{User studies}\index{user studies} (Section~\ref{sec:userstudies}) are often a good way for developers to develop a high-level understanding of the above issues.
A useful technique for understanding at a more detailed level what content the NLG system should communicate in different contexts, and how this should be expressed linguistically,  is \emph{manual corpus analysis}\index{corpus!manual analysis} (Section~\ref{sec:manualcorpus}), where a (relatively small) set of human-written \emph{target texts}\index{target texts} is manually annotated for content and aspects of linguistic style.


\begin{figure}
\lineacross\\
\emph{Key text-level quality criteria}

\textbf{Readability:} Is a text easy to read and understand?

\textbf{Accuracy:} Is the information in a text accurate and correct?

\textbf{Content:} Does the text include the most important and relevant insights for the user?

\textbf{Utility:} Does the text help the user?\\

\emph{Key system-level quality criteria:}

\textbf{Non-functional:} Does the system generate texts quickly and cheaply?

\textbf{Variation:} Is different wording used in different texts (if this is desirable)?

\textbf{Average and worst case:} Do \emph{all} texts meet minimal expected quality criteria?
\caption{Selected quality criteria for NLG}\label{fig:qualitycriteria}
\lineacross
\end{figure}

\section{Quality Criteria: Texts}\label{req-criteria}\index{quality criteria}

Many different \emph{quality criteria} \cite{belz-etal-2020-disentangling} can be used to assess the usefulness and appropriateness of an NLG system.   Chapter~\ref{evaluation} examines evaluation techniques, here the focus is on what some of these criterion are, and how their importance differs in different contexts.   This section looks at text-level quality criteria, Section~\ref{system-req-criteria} looks at system-level criteria.

Many quality criteria have been discussed in the literature \cite{howcroft-etal-2020-twenty,belz-etal-2020-disentangling}.  This book will focus on the criteria listed in Figure~\ref{fig:qualitycriteria}, and illustrate these using the example shown in Figure~\ref{fig:quality-example}; this shows a simple weather forecast produced by ChatGPT from basic weather data.

\personal{The quality criteria in Figure~\ref{fig:qualitycriteria} are the criteria which I personally have used most often in NLG projects. There are additional criteria which can be important in some use cases, such as emotional appropriateness (Section~\ref{sec:upsetting}).}

\begin{table}

\begin{tabular}{|r|r|r|r|}
\hline
time & wind speed & precipitation & temperature\\ \hline
0 & 10 & 0 & 6 \\ \hline
3 & 11 & 0 & 6 \\ \hline
6 & 12 & 0 & 7 \\ \hline
9 & 9 & 0 & 8 \\ \hline
12 & 10 & 0 & 12 \\ \hline
15 & 12 & 0 & 15 \\ \hline
18 & 9 & 0 & 12 \\ \hline
21 & 9 & 0 & 10 \\ \hline
\end{tabular}
\caption{Example weather data for a specific location over one day, at 3-hourly periods}\label{tab:quality-example-data}
\end{table}

\begin{figure}
\emph{Output of ChatGPT:}\\
\lingformquote{Here's a short weather forecast based on the provided data:}\\

\lingformquote{Expect a day with changing wind speeds and temperatures. The wind will range from 9 km/h to 12 km/h throughout the day, occasionally gusting higher. The temperature will start at 6°C and gradually increase to 15°C in the afternoon before dropping to 10°C in the evening.}\\

\lingformquote{There is no precipitation expected, so it will be a dry day.}\\

\lingformquote{In summary, anticipate a mix of wind speeds, with temperatures ranging from 6°C to 15°C, and no rainfall.}\\
\caption{Example text produced from weather data (Table~\ref{tab:quality-example-data})}\label{fig:quality-example}
\lineacross
\end{figure}

\subsection{Readability\index{readability} and Fluency\index{fluency}}\label{sec:fluency}
One fundamental criteria for NLG systems is that their output texts are easy for people to read.    In the research literature, this is sometimes called \emph{fluency} or \emph{clarity}\index{clarity} as well as \emph{readability}; unfortunately terminology in the research literature is not standardised \cite{howcroft-etal-2020-twenty}.  From a theoretical perspective, we can distinguish between \emph{Readability} (users can quickly read a text and understand its content) and \emph{Fluency} (users subjectively think that a text is fluent and well-written), but in this book we will treat these as being different aspects of an underlying assessment of linguistic quality.

For example, readers may judge that the text in Figure~\ref{fig:quality-example} is reasonable but not excellent from a readability and fluency perspective.  Most readers can read and understand the text, but it could be shortened and simplified (which would improve reading time), for example by dropping \lingform{There is no precipitation expected} and simply saying that this will be a dry day.

An example of an incoherent text produced by an NLG system in the sports domain is \cite{thomson-reiter-2020-gold}:
\begin{quotation}
\lingformquote{Markieff Morris also had a nice game
off the bench, as he scored 20 points and
swatted away late in the fourth quarter
to give the Suns a commanding Game 1
loss to give the Suns a 118-0 record in the
Eastern Conference’s first playoff series
with at least the Eastern Conference win
in Game 5.}
\end{quotation}

Poor readability is usually unacceptable; if the user cannot read the text, it is not useful.   However, the importance of high readability (very well written text) vs medium readability (as in Figure~\ref{fig:quality-example}) depends on the use case.   In particular, many texts targeted towards professionals, including financial reports, legal\index{legal} documents, and medical\index{health} summaries, need to be understandable and have appropriate content (see below), but users may not insist on very high levels of readability.  On the other hand, high readability can be important in texts intended for the general public, especially if the target audience includes people who are non-native speakers\index{non-native speakers} or have limited levels of literacy\index{literacy}.

\subsection{Accuracy}\label{sec:qualityaccuracy}\index{accuracy}
Another fundamental criteria for NLG systems is \emph{accuracy}; is the information in the text factually correct?  Again different names can be used, such as \emph{fidelity}\index{fidelity}.    Another way of expressing this criteria is minimising \emph{hallucinations}\index{hallucinations}, that is statements which are not correct.

At the time of writing, a lot of attention is being paid to accuracy problems in texts produced by large  language models\index{large language models} and other neural NLG systems.  It is rare for such systems to generate incoherent texts with poor readability, but unfortunately they can still sometimes generate texts with serious accuracy problems.

If we look at Figure~\ref{fig:quality-example}, it is mostly correct but there are some accuracy problems:
\begin{itemize}
\item The text says that wind speeds are in \lingform{km/h}, but this is not stated in the input.  In fact, these speeds are in \lingform{mph}.   Hallucinating units of measure is not good practice.  If the system does not know the units of measure, it should not guess them, and instead simply say \lingform{the wind will range from 9 to 12} (etc.).
\item The text states there will be \lingform{changing wind speeds}.  In fact, a wind speed range of 9-12 over 24 hours is pretty stable. 
\end{itemize}
A wider range of problems would probably be seen if the input data was noisy in the sense discussed in Section~\ref{sec:noise}.

\begin{figure}
\lineacross\\
Types of accuracy:
\begin{itemize}
\item Accurate with respect to \emph{input data} vs. accurate with respect to \emph{real world}.
\item \emph{Semantic} (literal) accuracy vs. \emph{pragmatic} (inferential) accuracy.
\item \emph{Critical} information correct vs \emph{all} information correct.
\end{itemize}
\caption{Types of accuracy}\label{fig:accuracytype}
\lineacross
\end{figure}

Accuracy can be formalised in many ways (Figure~\ref{fig:accuracytype}).  One issue is whether output texts should be accurate with regard to their \emph{input data}, or accurate with regard to the \emph{real world}.   For example, the text in Figure~\ref{fig:quality-example} states that temperatures are in Centigrade (\lingform{°C}); this happens to be true but is not stated in the input data.
 If we are assessing accuracy against input data, this would be regarded as an inappropriate \emph{hallucination}; however it would be fine if we assessed accuracy against the real-world.

Sometimes the term \emph{extrinsic hallucination}\index{hallucinations!extrinsic} is used for cases where extra information is added to the text, beyond what is in the input data.  \emph{Intrinsic hallucinations}\index{hallucinations!intrinsic} are statements that contradict the input data.

Another issue is \emph{semantic}\index{semantics} (literal) accuracy compared to \emph{pragmatic}\index{pragmatics} (inferential) accuracy.  For example, in a sports context, assume that in a football match between Aberdeen and Dundee, Bojan Miovski scores 2 goals for Aberdeen and Glenn Middleton scores one goal for Dundee.  Consider the statement

\begin{quotation}
\lingform{Miovskoi scored 2 goals for Aberdeen, and Middleton scored one goal.}
\end{quotation}

This is literally correct, but it implies that Middleton also played for Aberdeen, which is incorrect.  Again we can define accuracy only based on semantic correctness, or we can define it to also include pragmatic correctness.

Of course, different accuracy errors will have different impacts, and sometimes it is useful to distinguish between \emph{critical}\index{errors!critical} and \emph{non-critical} factual errors. For example, when summarising a doctor-patient consultation (Section~\ref{IntroConsultationSummary}) \cite{moramarco-etal-2022-human}, it is essential to accurately record information which impacts clinical care.  Therefore \lingform{the patient is vomiting} is a critical error if this statement is incorrect (ie, the patient is not vomiting), since this may change decisions about appropriate medical interventions.  However, accurately recording information about family members is less likely to impact clinical care; hence \lingform{the patient's wife is vomiting} may be considered a non-critical error if this statement is incorrect (ie, the patient's wife is not vomiting).  Of course the definition of critical and non-critical depends on the use case.  More categories are possible; for example Freitag et al \cite{FreitagMQM} classify errors as \emph{Major}, \emph{Minor}, or \emph{Neutral}.

The importance of accuracy depends on the use case (Chapter~\ref{applications}).  It is of paramount importance in many medical\index{health} applications, where critical errors in particular are unacceptable, and in general it is very important that texts be semantically correct and also pragmatically correct (not lead to false inferences).  In legal\index{legal} contexts, semantic accuracy is very important, but pragmatic (inferential) accuracy is sometimes less critical.  At the other extreme, accuracy is irrelevant for fiction-generation\index{fiction generation} systems.  Journalism\index{journalism} is an interesting case, where gross inaccuracy is unacceptable, but limited factual errors may be tolerated in some cases; Thomson et al \cite{thomson-csl23} found 1.5 factual errors (on average) in human-written summaries of basketball games.

\subsection{Content}\label{sec:omissionscriteria}\index{content}
In addition to being accurate, it is usually important for the content of a generated text to contain the key insights\index{insights} and information that the user needs to know.   A related concept is minimising \emph{omissions}\index{omissions}, where key information is not present in a text.

Content and omissions are harder to pin down than readability and accuracy, in part because they depend on the use case and target audience.  Readability and accuracy can be defined in a general manner that is somewhat domain-independent (although their importance depends on the use case).  However we cannot specify what content is appropriate independent of the use case\index{use cases}.

For example, if we look at the text in Figure~\ref{fig:quality-example}, its probably fine from a content appropriateness perspective for a forecast aimed at the general public.   However, it would not  be appropriate for a forecast for offshore oil rigs, because it omits detailed information about wind speeds.  Some oil-rig maintenance procedures can only be done if the wind speed is less than 10, and the Figure~\ref{fig:quality-example} text does not specify when wind speeds are greater than or less than 10.

From a content perspective, the simplest situation is when all of the information in the system's input needs to be communicated in the generated text, and hence any input information which is not communicated is a content error.  This was the case in the E2E\index{E2E} challenge \cite{DUSEK2020123}, for example, where the systems input was a small number of features (about a restaurant), and the generated texts was supposed to include all of these features.  However this is unusual, usually NLG systems produce texts which summarise their input data in some fashion.  Certainly a data-to-text system whose input data is large (thousands or even millions of numbers \cite{turner-etal-2009-generating}) must summarise, it cannot explicitly communicate this amount of information in a readable text of realistic size.

When a system does summarise its data, its texts have appropriate content when they include the key insights and messages for the target user and use case.  Sometime the key insights from a content perspective are the same as the ones which can give rise to critical accuracy\index{accuracy} errors (Section~\ref{sec:qualityaccuracy}).
For example, if we know that  \lingform{The patient is vomiting} is a critical error if it is incorrect, it is likely that omitting this statement (if it is true) will be a content error.


\subsection{Utility}\label{req-utility}\index{utility}
Perhaps the most important quality criteria, but also the hardest to define and measure, is utility.  Is the generated text effective in helping the user or otherwise fulfilling its communicative goal?   Utility of course is completely dependent on the use case\index{use cases} and target audience, even more so than omissions and content quality.

For example, Gkatzia et al \cite{gkatzia-etal-2016-natural} analyse and evaluate NLG weather forecasts\index{weather forecasts} for the specific task of helping outdoors ice cream vendors decide when to sell ice cream (Section~\ref{sec:gkatziaweather}).  They most important weather parameter in this context is usually rain (very few people buy ice cream from an outdoors vendor if it is raining); temperature can also play a role.   The utility of the text in Figure~\ref{fig:quality-example} can be assessed in this use case; its probably pretty good, since the key information about rain and temperature is clearly stated.  On the other hand, the utility of this forecast would probably be poor for offshore oil rigs (as discussed in Section~\ref{sec:omissionscriteria}).

Many NLG systems are deployed in \emph{human-in-loop}\index{human-in-loop} workflows where  a person checks and edits NLG texts before they are sent to end users (Section~\ref{sec:humanchecking}).  In such cases, \emph{post-edit time}\index{post-editing!time} (the amount of time that people need to check and edit the NLG texts) is often closely linked to utility; the value of the system is lower if people need to spend a lot of time checking its output texts.  Of course, post-edit time depends on user-interface and workflow as well as the generated texts.  It also is variable across users, with some people doing considerably more edits than others \cite{sripada-etal-2005-evaluation}.

We also need to keep in mind that real-world utility can depend on non-technical factors.  For example,  Babytalk\index{Babytalk} BT-Family system (Section~\ref{sec:babytalk}) generated summaries for parents of the status of a baby in a hospital neonatal ICU \cite{mahamood-reiter-2011-generating,mahamood-reiter-2012-working}. The system was deployed and used by parents.  When we asked them about utility, they said it would be much more useful if the summaries could be put on the Internet, especially since in many cases one parent was staying at home with other children while the other parent was spending a lot of time with the sick baby in the hospital.  Unfortunately, the hospital's IT security\index{security} policy prohibited doing this.  Hence BT-Family's utility was reduced by real-world factors which had nothing to do with NLG.

\section{Quality Criteria: Systems}\label{system-req-criteria}\index{quality criteria}
Most work on quality criteria has focused on the quality of texts produced by NLG systems, but there are also important criteria at the \emph{system} level.

\subsection{Non-functional requirements}
In many cases \emph{non-functional} requirements\index{requirements!non-functional} are important, such as the amount of time required to produce a generated text\index{compute!speed}.   In interactive systems such as chatbots, the general rule is that the computer system should respond within one second \cite{nielsen1994usability}, and sometimes this can be challenging for systems based on large neural language models.

For example, it took an early version of ChatGPT (GPT 3.5) around 1 second to produce the text shown in Figure~\ref{fig:quality-example} (later versions are considerably faster).  In an interactive chatbot context, 1 second may be acceptable (although it is not great); 5 seconds would not be acceptable.

A related issue is compute resources\index{compute!resources} and costs\index{compute!cost}.  Running a large language model can require sizeable compute resources, and such resources may not be available locally, for example if the NLG application needs to run on a phone in airplane mode (no internet access).  The situation is easier if the NLG application can access compute resources on the cloud, but such resources must be paid for, and there will be limits to acceptable expenditure.  In late 2023 generating the Figure~\ref{fig:quality-example} text using GPT4 cost around US\$0.01, which would probably be too expensive for a weather app that relies on advertising for income.

Privacy\index{privacy} and security\index{security} are also very important in many commercial contexts.  In particular, some companies will not use cloud-based services for processing sensitive data because of privacy and security concerns, and insist that all processing be done internally.

\subsection{Consistency and Variation}\label{sec:variation}\index{consistency}\index{variation}
In many use cases\index{use cases}, users want texts to be \emph{consistent} and always express information in the same way.  In medicine\index{health}, for example, texts describing clinical phenomena should be precise and use standard medical terminologies\index{terminology}, in order to minimise the chances that the text is misunderstood.   This is especially important when texts may be read by non-native speakers\index{non-native speakers} with variable levels of literacy \cite{reiter1995automatic}.

However, there are also use cases where users want to see \emph{variation} in texts, where the same information is expressed differently on different occasions.  This is especially important in contexts where readers see many texts produced by the NLG system, such as journalism\index{journalism}, sports reporting and weather forecasts\index{weather forecasts}.  Readers will get bored if they see the same language repeated in media stories \cite{diakopoulos2019automating}.  Figure~\ref{fig:variation} shows some possible variations of the last sentence in  Figure~\ref{fig:quality-example}, where the same content is expressed using:
\begin{itemize}
\item different words (e.g., \lingform{no rainfall} vs. \lingform{dry})
\item different ordering of phrases (e.g., start with wind speed information or start with precipitation information)
\item different semantic structures (e.g., whether reader is told something will happen, or told to expect that something will happen)
\end{itemize}

\begin{figure}
\lineacross\\
A few variations of a sentence in a weather forecast: 
\begin{itemize}
\item \emph{Original}:~\lingformquote{In summary, anticipate a mix of wind speeds, with temperatures ranging from 6°C to 15°C, and no rainfall}
\item \emph{Variation 1}:~\lingformquote{In summary, expect a mix of wind speeds, no rainfall, and temperatures ranging from 6°C to 15°C.}
\item \emph{Variation 2}:~\lingformquote{In short, the day should be dry with temperatures between 6°C to 15°C and a mix of wind speeds.}
\end{itemize}
\caption{Variations of the last sentence in Figure~\ref{fig:quality-example}; content is the same, but it is expressed differently}
\label{fig:variation}
\lineacross
\end{figure}

Sometimes users care about both consistency and variation; for example in a weather forecast context they may want consistency in content words such as \lingform{dry}, but variation in other types of words such as connectives (e.g., alternating between \lingform{but} and \lingform{however}).

It is dangerous to generalise about use cases, but overall consistency is more likely to be important for NLG systems that generate texts for professionals, while variation is most likely to be important in systems that generate texts for consumers or the general public.  Of course there are exceptions!

\subsection{Average vs Worst-Case}\label{sec:req-worstcase}\index{worst-case}
Another system-level issue is the distribution of quality criteria\index{quality criteria} across generated texts.  Usually different texts generated by an NLG system have different individual ratings on quality criteria.  For example, if we look at accuracy, perhaps a few texts will have no errors\index{errors}, some will have one error, some will have two errors, and a few will have three or more errors.  If we want to compute quality criteria for \emph{systems} instead of individual texts, then we have to decide how to map a distribution of text-level quality scores onto a single system-level quality score.  In principle we could report the distribution of text-level scores, but this is rare.

If we want to report a single number which aggregates the distribution, the most common choice is the mean (average) value of the criteria across a set of texts; this is \emph{average-case performance}. However, in some cases (especially when safety is important, see Section~\ref{sec:safety}) it is essential that \emph{all} texts generated by a system have acceptable quality; in such cases we report the minimum value of the criteria across the set of generated texts (\emph{worst-case performance}).  An example is shown in Table~\ref{fig:averageworst}.

If average readability is most important in this use case, we should report the mean readability of the generated texts (8).  However, if the key requirement is that all texts achieve a minimum readability level, then we should report the minimum readability score (4).  In some use cases we may want to report both, for example if we want a high average readability score but also a guarantee that all texts achieve a minimum readability level (eg, not be incomprehensible).

\begin{table}
\lineacross\\
\begin{tabular}{|l|r|} \hline
Generated text & Readability (0-10) \\ \hline
\lingformquote{Tomorrow should be dry with temperatures between 6°C to 15°C.} & 9 \\ \hline
\lingformquote{Tomorrow will be a dry day, with moderate temperatures.} & 9 \\ \hline
\lingformquote{Tomorrow will be a moderate day with dry temperatures.} & 4 \\ \hline
\lingformquote{Tomorrow will be a really nice day.} & 10 \\ \hline
\end{tabular}

\blankline
Average (mean) readability: 8 \\
Worst-case (minimum) readability: 4 \\
\caption{Average and worse case ratings of a set of texts.}\label{fig:averageworst}
\lineacross
\end{table}

\section{Workflow}~\label{sec:workflow}\index{workflow}\index{integration}
Another key aspect of requirements is how the NLG system fits into overall \emph{workflows}.  In particular, it is useful to distinguish between \emph{fully automatic NLG}, \emph{NLG with human checking\index{human checking} and post-editing\index{post-editing}}, and \emph{humans creating a document from an NLG draft}.

A related concept is \emph{integration}\index{integration}, that is connecting the NLG system to input data sources and output document delivery mechanisms.  This is very important for production systems; in commercial NLG projects, a sizeable chunk of engineering effort is often spent on integration.  However, since integration issues for NLG systems are similar to integration issues for other types of software systems, I will not discuss them here.

\subsection{Fully automatic NLG}
A fully automatic NLG system produces a narrative with no human involvement (other than humans reading the generated narrative).

At the time of writing, there is limited use of fully automatic NLG systems in professional contexts, in part because of the fear that some of the NLG texts may be incorrect.  In other words, with regard to quality criteria (Section~\ref{req-criteria}), there is a fear that worst-case\index{worst-case} readability, accuracy, and/or content appropriateness will not be acceptable; i.e., in a few cases the generated texts will be difficult to read, inaccurate, or missing key information.  In safety-critical\index{safety} or high-value contexts, this is not acceptable.   Of course, there are use cases\index{use cases}, perhaps especially in consumer-oriented contexts, where a small number of mistakes are perhaps acceptable, and fully automatic NLG systems can be used in such contexts.

The weather  system  \cite{arun-etal-2020-best}  described in Section~\ref{sec:Facebookweather} is an example of such a system.  While some specialised types of weather forecasts\index{weather forecasts} (such as aviation forecasts) are safety critical, forecasts for the general public usually do not kill people if they are wrong.  Also, weather forecasts by their nature are approximate and sometimes incorrect because they are \emph{forecasts} (the result of a numerical model which simulates how the atmosphere will change in order to predict weather parameters over time), so users know that they cannot be 100\% trusted even ignoring NLG issues.

\subsection{Human checking\index{human checking} and editing}\label{sec:humanchecking}
In NLG systems used by professionals (doctors, accountants, engineers, etc.), it is more common to see workflows where a person checks the output of the NLG system and fixes (\emph{post-edits})\index{post-editing} the text if necessary.  This is the certainly the case with systems that generate medical\index{health} documents such as consultation summaries \cite{knoll-etal-2022-user} (Section~\ref{sec:medicalreporting}), and its also true of most NLG systems which are used to generate journalistic\index{journalism} content \cite{diakopoulos2019automating} (Section~\ref{journalism}).

 In the weather domain, the forecasts\index{weather forecasts} produced by SumTime\index{SumTime} were checked and edited by human forecasters \cite{sripada-etal-2005-evaluation} before they were sent to clients.  This is partially because these were specialist forecasts for people operating off-shore oil rigs, so accuracy requirements were higher than for public forecasts (Section~\ref{ArriaWeatherExample}).  Figure~\ref{fig:sumtimepostedit} shows an example of how a SumTime text describing the wind was edited by a human forecaster before being released to clients.  

\begin{figure}
\lineacross\\
\emph{Original SumTime wind text:}  \lingformquote{SW 20-25 backing SSW 28-33 by midday, then gradually increasing 34-39 by midnight.}\\
\emph{Human-edited version of above text:} \lingformquote{SW 22-27 gradually increasing SSW 34-39.}\\
\caption{Example of post-editing a SumTime wind text, from \cite{sripada-etal-2005-evaluation}.  Human has changed \lingform{20-25} to \lingform{22-27}, dropped the phrase \lingform{backing SSW 28-33 by midday}, and also dropped \lingform{then} and \lingform{by midnight}.}
\label{fig:sumtimepostedit}
\lineacross
\end{figure}

Sripada et al \cite{sripada-etal-2005-evaluation} analysed a corpus of such edits to SumTime forecasts (real edits made during operational usage of the system), and discovered that there was a considerable difference in the amount of post-editing done by different forecasters. This is partially because some forecasters are fussier than others, but also because some forecasters insisted on editing texts into their personal preferred style.   If consistency is important, editors should be given clear guidelines\index{guidelines} on what should be fixed, ideally supported by training.

Post-editing also of course is influenced by the editing user-interface\index{user interface} and by how it fits into the editors overall workflow \cite{knoll-etal-2022-user}.   A good post-edit UI can make post-editing much quicker, and also can help editors conform to instructions.

The result of a workflow where human experts post-edit NLG outputs can be excellent.  Moramarco \cite{moramarcophd} showed that for the task of writing summaries of doctor-patient consultations, texts produced by asking clinicians to post-edit summaries produced by Note Generator (Section~\ref{IntroConsultationSummary}) seemed to be slightly \emph{more} accurate (on average) than texts produced by the same clinicians using a completely manual workflow.

We can also use machine-learning techniques to learn from post edits and refine our models so that they make fewer mistakes in the future.  This is sometimes called \emph{automatic post editing}\index{post-editing!automatic} \cite{do2021review}.

There has been extensive work on post-editing in machine translation\index{machine translation}. Indeed, there is even an ISO standard about this (ISO 18587:2017).

\subsection{Creating drafts for human writers}\label{draftworkflow}
Finally, NLG systems can be used to generate draft documents which human writers can use when they create documents.  For example, an NLG system may generate a financial report which is \scare{mined} for content by a human analyst; ie, the human analyst does not try to fix the entire NLG narrative, instead he or she extracts useful chunks from the NLG narrative and includes them in the document he or she is writing.  As with post-editing, different authors use drafts in different ways, and the user interface is very important.

The division between \scare{human checking and post-editing} and \scare{creating drafts} is fuzzy, but in general in the first case the NLG system is the main author, assisted by the human, whereas in the second case the human author is the main author, assisted by the NLG system.  In principal, usage of NLG in a use case can evolve, perhaps starting with the system creating drafts, then moving to a \scare{human checking} workflow, and ending with fully automatic NLG with no human involvement.


\section{Text and Graphics}\label{sec:textgraphics}\index{graphics}
Visualisations\index{visualisations}, images, and graphics can be used to communicate numerical data, and in many use cases can be an alternative or supplement to texts produced by data-to-text NLG systems.  For example:
\begin{itemize}
\item \emph{Financial and medical information} can be presented using words, informations graphics, or both.
\item \emph{Persuasive content} (eg, to encourage safer driving) can be presented using words, graphics/images, or both.
\item \emph{Instructions} (such as directions for getting from A to B) can be presented using words, maps\index{maps}, or both
\end{itemize}
Hence when building an app which communicates information to a user, developers may need to decide whether to use words (NLG), some form of graphic, or a combination of both.

Sometimes the choice is dictated by pragmatic reasons.  For example, a voice assistant which communicates over a telephone landline cannot show images, so it must rely on words. Similarly systems for blind people emphasise words; it is possible in theory to communicate graphically using Braille displays, but this is expensive and usually avoided.   On the other hand, use cases which require information to be understandable to speakers of many different languages (such as many DIY instructions) avoid words and use pictures instead.  Summaries of textual documents are also usually done with words; pictorial summaries are possible but unusual.

In many use cases, however, we have a choice between words and pictures, and hence need to decide which of these is most suitable for the use case\index{use cases} and target audience; this is an important aspect of understanding client requirements.

\subsection{Decision Support}\label{sec:gkatziaweather}\index{decision support}
One use of data-to-text NLG is \emph{decision support}, that is presenting information to people to help them make decisions.  A few studies have looked at the relative effectiveness of text and graphics in this area.


\begin{figure}
\includegraphics[scale  = 0.5]{gkatzia2}
\caption{Simple weather forcast (text and graphics); courtesy of Dmitra Gkatzia}
\label{fig:GkatziaWeather}       
\end{figure}

Gkatzia et al \cite{gkatzia-etal-2016-natural} present an interesting study of this issue in the context of simple weather forecasts\index{weather forecasts}.  Fig~\ref{fig:GkatziaWeather} shows an example of the kind of forecast they examined; this example shows both images and words.  They also had an images-only condition (no words) and a words-only condition (no images).   They ran an experiment where they showed people either the words+graphics forecasts, the graphics-only forecast, or the words-only forecast, and asked them to make a weather-related decision.  They found that the best decisions were made from words+graphics, and words-only forecasts were more effective (as decision aids) than graphics-only forecasts.

Gkatzia et al looked at a context where ordinary people were making a decision based on fairly simple data.   The Babytalk BT45\index{Babytalk!BT45} systems \cite{PORTET2009789} generated texts which were intended to support clinical decision making, and studies were done of the text-vs-graphics issue in this context, where medical professionals examine clinical data and then make decisions based on this data.
Law et al \cite{law2005comparison} compared the effectiveness of presenting clinical data to clinicians via data visualisations or
(human-written) textual summaries of data, and found that clinicians\index{doctors} who saw the human-written text summaries made better decisions.   Van de Meulen et al \cite{van2010graph} presented clinical data as either (A) data visualisations, (B) computer generated (NLG) textual summaries, or (C) human-written textual summaries, and found that doctors who saw the human-written textual summaries  again made the best decisions.  There was little difference overall in the quality of decisions made by doctors who saw the data visualisations and doctors who saw the computer-generated NLG texts.  However  in some scenarios the visualisations led to better decisions and in others the NLG texts led to better decisions.  This suggests that the best strategy is to combine the two, which matches what Gkatzia et al found.  

Of course, all of these experiments were done based on specific visualisations and NLG summaries; it is possible that different results woud have been seen with different visualisations and/or NLG summaries.  But it is plausible that a combined text+graphics presentation of information is usually best, not least because we know that which presentation is best depends on the scenario and also on the user (e.g., verbal vs visual thinker); hence a combined \scare{multi-modal}\index{multi-modal} presentation will be more robust across scenarios and users. 


\subsection{Other Use Cases}
Balloccu and Reiter \cite{balloccu-reiter-2022-comparing} looked at graphical vs text+graphics presentation of dietary information in an app which gave people feedback about their diet.  They found that users had better understanding of the dietary data when it was presented using a mixture of text and graphics.

McKeown et al \cite{MCKEOWN199895} look at a number of use cases, including generating maintenance instructions and generating briefs which summarise a patient's status after an operation.  They again suggest that the best strategy is to mix text and graphics.

\subsection{Combining Text and Graphics}
The above papers suggest that a multi-modal\index{multi-modal} presentation of information, combining text and graphics, is usually the most effective.  Of course this raises the question of how to best combine text and graphics.

The simplest approach is to generate the text and graphics independently, so that the user sees text and graphical summaries of the data; this approach was used by Gkatzia et al \cite{gkatzia-etal-2016-natural} (Figure~\ref{fig:GkatziaWeather}).  It allows users to focus on whichever media (text or graphics) works best for them in their current context; also if they struggle to understand something which is presented graphically, they can look at the text, and vice-versa.

It is also possible to present different kinds of information in the two media. For example, we can use the textual descriptions to describe what-if analyses, causal links, background information, and other things that are difficult to describe in graphs, while using the graphs to communicate raw numerical data (which is awkward to do in words).  This approach is common in business intelligence\index{business intelligence} (Section~\ref{sec:bi}), and there are a number of commercial tools which essentially explain business data (such as sale and profits) using a mixture of graphs and words; sometimes the textual information is intended to expand and/or clarify the data visualisations\index{visualisations} \cite{mahamood-etal-2014-generating}.
In interactive chatbot\index{chatbot} contexts (such as Balloccu and Reiter \cite{balloccu-reiter-2022-comparing}), the user may be able to explicitly request textual or graphical presentations of data.   We might describe this approach as \emph{loose coupling}; the text and graphics communicate different information, but they can be examined independently.  In other words, the textual component makes sense even without the graphical component, and vice-versa.

\begin{figure}
\includegraphics[scale  = 0.8]{saferdriver_full}
\caption{Combining text and graphics in SaferDriver\index{SaferDriver}; courtesy of Daniel Braun}
\label{fig:saferdrivermultimodal}       
\end{figure}

A nice example of this from a research system is SaferDriver\index{SaferDriver} \cite{braun_reiter_siddharthan_2018}, which generated feedback reports for drivers about speeding and other unsafe driving behaviour, based on GPS data.  As shown in Figure~\ref{fig:saferdrivermultimodal}, SaferDriver used NLG texts to give summary information, key insights, and encouragement/praise, but it used a map\index{maps} to show detailed driving data.

In the 1990s there were a number of research projects which looked at close integration of text and graphics, where the text component did not make sense without the graphical component, and vice-versa.   Much of this work focused on instruction giving \cite{feiner1991automating,wahlster1993plan,MCKEOWN199895}; I summarise some of it in Chapter 7 of my 2000 book \cite{reiterdale2000}.   This approach is less common in recent work.

\section{Requirements acquisition}\index{requirements!analysis}
Since requirements are very important, a key question is how developers and system builders can understand user requirements.  There is of course a large literature in the software engineering community on requirements acquisition for building software systems (for example, Wiegers and Beatty \cite{wiegers2013software}), most of which is applicable to building NLG systems.  There is also some work explicitly on understanding requirements for NLG.



\subsection{User studies}\label{sec:userstudies}\index{user studies}
A very useful technique for understanding requirements is to conduct \emph{user studies}.  This is a powerful technique which is widely used in software engineering and interface design.

Knoll et al \cite{knoll-etal-2022-user} describe a set of user studies they performed in order to understand requirements for Note Generator\index{Note Generator} (Section~\ref{IntroConsultationSummary}), a system which summarised doctor-patient consultations.  They divide the process into several stages (Figure~\ref{fig:userstudies})

\begin{figure}
\includegraphics[scale  = 1]{userstudies.pdf}
\caption{User studies process, inspired by Knoll et al \cite{knoll-etal-2022-user}}
\label{fig:userstudies}       
\end{figure}

\emph{Step 1: Analysis of how humans currently do the task.} If an NLG system is (semi-)automating a task which is currrently done manually, then the first step is understanding how humans currently perform the task.  Knoll et al conducted one-hour semi-structured interviews\index{semi-structured interviews} with seven clinicians in order to understand how they manually did the task, where they needed help, and what the difficult cases were; they also created several \emph{personas}\index{personas} based on the people they interviewed.

The difficult cases (for writing up doctor-patient consultations) included cases where patients were not truthful\index{lies} or exaggerated symptoms, cases where patients had multiple problems, and cases where patient's non-verbal behaviour communicated important information.  In general understanding hard cases is essential in requirements analysis; developers need to ensure that they have a strategy for dealing with hard cases (which could be reverting to human authorship).

\emph{Stage 2: Mockups.}\index{mockups}  Once developers have an idea what an NLG system will do, the next step is to get feedback from users and stakeholders\index{stakeholders} to verify that this functionality is useful and meets user/stakeholder needs.  A common practice in interface design, which Knoll et al use, is mockups;  they show users simple mockups of systems, and used this to get feedback on what interface and functionality is best.  Showing mockups is cheap and can be done very early in the system-building process.

Amongst other things, Knoll et al discovered that users (doctors) wanted the consultation summary to be generated and updated in real-time, as the doctor and patient spoke.  In other words, doctors wanted to see a summary of the consultation as it progressed, not just at the end.  This had an impact on the technology used in the final system.

\emph{Stage 3: Wizard of Oz.}\index{Wizard of Oz} Knoll et al then built a \emph{Wizard of Oz} system, where users thought they were interacting with the NLG system, but in fact the summaries were produced by a human \emph{Wizard}, who wrote the texts which the users thought were produced by the NLG system.  This is again a common technique in interface design.  It is a great way to get feedback on a proposed app (does it meet user needs?) at an early stage, before the app is built.

In this case, the Wizard of Oz study showed that different users used the system in different ways.  For example, some users essentially used a post-editing workflow (Section~\ref{sec:humanchecking}), that is they updated the computer-generated summary.  Other users used a drafting workflow (Section~\ref{draftworkflow}), that is they wrote their own summary, and copied over material from the computer-generated summary where it was helpful.


\emph{Stage 4: Live beta test.}\index{beta test} The final user-study stage was to deploy the complete NLG summarisation material in a limited test with a small number of clinicians, and monitor how clinicians used it and what the problems are.  This is similar to \emph{alpha} or \emph{beta} tests in classical software development.

Amongst other things, the beta test showed the doctors did \emph{not} generally use the NLG system in difficult consultations of the sort described above; in such cases they reverted to manual note writing.  This suggests that it is acceptable (but of course not ideal) for the  system to focus on handling \scare{easy} cases well.

\emph{Production usage.}\index{production} Once the above stages are completed and the system has been updated based on feedback and observation, it is time to start the process of deploying the system in full production usage!   Moramarco \cite{moramarcophd} describes the production deployment of Note Generator.
\newline
\newline
Of course there are other techniques which can be used in user studies, beyond those discussed in Knoll et al.  For example in other projects we have used focus groups to help us understand what users wanted \cite{sun2024}.


\subsection{Manual Corpus Analysis}\label{sec:manualcorpus}\index{corpus!manual analysis}
User studies focus on what users want and need, and are usually the best technique for high-level requirements analysis.  It can also be useful, especially when building rule-based NLG systems, to try to elicit detailed requirements by manually analysing a small set of high-quality input-output pars. This process is called \emph{manual corpus analysis} \cite{reiterdale2000}.

This process is as follows:
\begin{enumerate}
\item Obtain a small \emph{corpus}\index{corpus} of system inputs (typically 10-20 texts, ideally as varied as possible) and high-quality outputs for these inputs.  These outputs are called \emph{target texts}\index{target texts} and are usually written by a human domain expert.
%Small in this context often means 10-20 texts.
\item Ask other people (not the domain experts\index{domain!experts} who wrote the texts) to annotate the target texts to indicate where information comes from.  Figure~\ref{figure:manualannotation} shows a simple annotation scheme which was worked well for me on many occasions.
\item Update the target texts to remove information and insights which cannot realistically be included in the generated text; note that this judgement partially depends on the NLG technology which will be used.
\item Analyse the annotations of the remaining material in the target texts in order to understand what content and wording is needed and how it might be produced.
\item Repeat above if necessary.
\end{enumerate}
An example of an annotated target text is shown in Figure~\ref{fig-corpus-annotate}.


\begin{figure}
\lineacross\\
Sentences (or in some case phrases) are annotated with one of the following categories:\\

\textbf{Static:} Always present, does not change. An example is the sentence \lingform{Remember that past performance is not indicative of future results} in Figure~\ref{fig-corpus-annotate}; this is a boilerplate fixed sentence which needs to be present for legal reasons, and never changes.\\

\textbf{Data:} Directly communicates part of the input data. An example from Figure~\ref{fig-corpus-annotate} is the sentence \lingform{The FTSE rose by 20 points yesterday}; this directly communicates basic stock market data.\\

\textbf{Insight:} Communicates insights derived from the input data. An example from Figure~\ref{fig-corpus-annotate} is the sentence \lingform{The rise was largely driven by an increasing values of energy-related stocks}; this is the result of a key-drivers-and-offset analysis of the stock market data.\\

\textbf{Background:} Communicate background information which is available on the Internet or within a language model. An example from Figure~\ref{fig-corpus-annotate} is the sentence \lingform{Crude oil prices are increasing rapidly}; this is not in the stock market data but is related information which can be obtained from the Internet.\\

\textbf{Unavailable:} Communicates information which is not available to the system. An example from Figure~\ref{fig-corpus-annotate} is the sentence \lingform{Investors who bet on oil companies are very happy}; this is a plausible guess, but the system does not have access to the emotional state of millions of investors.\\

\caption{Simple annotation scheme for manual corpus analysis}\label{figure:manualannotation}
\lineacross

\lingformquote{The FTSE rose by 20 points yesterday.} \emph{(Data)}\\
\lingformquote{The rise was largely driven by an increasing values of energy-related stocks.} \emph{(Insight)}\\
\lingformquote{Crude oil prices are increasing rapidly.} \emph{(Background)}\\
\lingformquote{Investors who bet on oil companies are very happy!} \emph{(Unavailable)}\\
\lingformquote{Remember that past performance is not indicative of future results.}  \emph{(Static)}
\caption{Example of annotated human-written text using the annotation scheme of Figure~\ref{figure:manualannotation}.  The system's input data is stock market share prices.}\label{fig-corpus-annotate}
\lineacross
\end{figure}


Part of this exercise is examining Insight and Background texts and deciding whether any of these are unrealistic to produce; for example the Background text in Figure~\ref{fig-corpus-annotate} can only be generated if the system has access to data about oil prices (ie, it has access to commodity prices as well as share prices).  Developers also need to consider whether Unavailable texts should be dropped; for example the Unavailable text in Figure~\ref{fig-corpus-annotate} is essentially a bit of journalistic colour which might be acceptable in general media stories, but probably should not be included in financial updates aimed at professional investors (who might indeed complain that they are not feeling very happy, because they expected a larger increase in stock prices).

Developers may wish to change target texts based on the corpus analysis.  Of course, any changes should be
discussed with clients and users; it is also often useful to discuss them with the domain experts who wrote the target texts if this is possible.  Some changes are minor and have little impact on users, but others may significantly decrease the utility of the NLG system.   When developers have agreed on a set of target texts with the client, this becomes an important resource in defining what the NLG system should do.

Once such changes have been made and the the target text corpus is finalised, developers can analyse it in order to better understand the type of content that will be included in generated texts, and also how it is expressed linguistically.  This analysis is very useful when building rule-based NLG\index{rule-based NLG} systems, and can directly lead to an initial set of rules.

For neural NLG, the context analysis is  useful as a way of understanding what information and reasoning is needed to generate context, which helps specify input sources and prompts.  The language/expression analysis can identify whether text needs to be in a specific genre\index{genre} such as \scare{weatherese} or \scare{legalese}.


\subsubsection{Issues and Limitations}

One limitation of manual corpus analysis is that it generally does \emph{not} have good coverage of  boundary or \scare{edge} cases\index{edge cases}, because there are usually hundreds or thousands of such cases.  We can train a machine learning model on tens of thousands of texts, but we cannot realistically do manual corpus analysis on tens of thousands of texts!  If we are building a rule-based NLG system, one approach is to identify edge cases and then explicitly ask domain experts how they should be handled..

Another limitation which is inherent in analysing human-written texts is that different human writers will write different texts, even if they are given the same input data. So a text written by author A may include different Insight statements, different Background statements, etc. compared to a text written by author B.   One strategy is to analyse texts written by several experienced domain experts, in order to get good coverage of what content experts think could be included in a text.

A related issue is that some human-written texts may not be very good.  It is very appealing to get the corpus texts from real-world texts written by professionals.  However sometimes such texts are written by less experienced domain experts working under intense time pressure, which reduces their quality.  This is certainly true of production weather forecasts\index{weather forecasts}; a weather forecast written by an experienced forecaster with plenty of time is not the same as a weather forecast which is quickly produced by a novice forecaster who is struggling to write a large number of forecasts in a short amount of time.  If text quality is a concern, it may be useful to ask an experienced domain expert (eg, forecaster) to check corpus texts and remove low-quality ones.

Last but not least, the above process requires cooperation and support from domain experts, but sometimes they are hostile to the AI/NLG initiatives because they see them as a threat to their jobs.   This is a \emph{change management}\index{change management} issue (Section~\ref{sec:acceptability}), not a technical one, and will require sensitivity and addressing the concerns of the individuals who are supposed to be supporting the project.


\subsection{Stakeholders}\label{sec:reqstakeholders}\index{stakeholders}
When working with people to understand requirements, it is important to talk to \emph{stakeholders} as well as direct users.  For example, a system which summarises doctor-patient consultations (Section~\ref{sec:userstudies}) must be acceptable to the doctors\index{doctors} who will use it!  But it must also be acceptable to managers\index{managers} who look at the \scare{big picture} impact of the system, and to legal\index{legal} and risk\index{risk} management specialists who assess the likelihood and damage (reputational as well as financial) if anything goes wrong.  Many medical systems also need to be acceptable to regulators\index{regulator} and patients.

It is important when analysing requirements to work with all types of stakeholders if possible.  For example, a doctor may not care how much an NLG system costs, but a manager certainly will!  Likewise doctors and managers may not be able to estimate risks of successful lawsuits if something goes wrong, specialists need to be consulted about this.

\personal{I have seen a number of NLG projects where success has been limited because not all stakeholders were consulted.  The most common problem has been failure to consult users; managers think a certain type of NLG system will be useful and buy it, without considering whether end users actually want this functionality.  I have also seen failures where users were consulted but management was not; we ended up building systems which users loved, but managers decided were not cost-effective.}

\section{Further reading}
There are many textbooks and other sources about software requirements in the general software engineering\index{software engineering} literature (eg, \cite{wiegers2013software}).  Indeed, getting requirements wrong is a leading cause of many IT disasters, where an expensive IT system turns out to be useless in practice.  A good example is the £10B NHS Connecting for Health programme, probably the biggest IT failure in the UK public sector (\url{https://en.wikipedia.org/wiki/NHS\_Connecting\_for\_Health}).

Strickland's excellent retrospective \cite{strickland2019ibm} on the failure of IBM Watson\index{IBM Watson} in healthcare identifies many problems which essentially are due to poor understanding of what real-world users wanted the system to do.

I am not aware of textbooks or research papers specifically on requirements for natural language generation, but application-oriented books and papers which target specific NLG use cases often mention requirements.  An excellent example which includes generalisable insights is Diakpopoulus's book \cite{diakopoulos2019automating} on automatic journalism\index{journalism}.  

A lot has been written in the general AI literature about human-AI interaction and workflows\index{workflow}; one recent survey is Mosqueira-Rey et al \cite{mosqueira2023human}.  Amershi et al \cite{amershi2019guidelines} give guidelines from HCI (human-computer interaction)\index{HCI} perspective on human-AI interaction.  O'Brien \cite{o2022deal} discusses post-editing in machine translation.  Diakopolus et al \cite{diakopoulos2024} survey workflows for using language models in journalism.
Unfortunately I am not aware of papers specifically on post-editing\index{post-editing} and other workflows in NLG, other than the ones cited above in Section~\ref{sec:workflow}.  There are numerous blogs and white papers about human-AI interaction from commercial AI companies; as always with commercial material, these are often very well written but may not be completely objective.

An increasing number of papers are being published which explore different quality criteria\index{quality criteria} for NLG, but I recommend that readers interested in this topic start with Howcroft et al \cite{howcroft-etal-2020-twenty} and Belz et al \cite{belz-etal-2020-disentangling}.  Gehrmann et al \cite{GehrmannEvaluation} is primarily a survey of NLG evaluation, but also has some good insights about quality criteria.

My 2000 book \cite{reiterdale2000} includes a fair amount of material on text and graphics\index{graphics}.  Much of this is out of date, but I think the discussion of basic issues and concepts is still relevant today.  In 2024, the best work on combining NLG and information graphics is often done commercially, by companies (such as Arria, my company) which develop solutions which combine these in real use cases.  One example of a system which Arria helped developed is described in Section~\ref{sec:covid} of this book.

For requirements acquisition\index{requirements!acquisition}, Knoll et al \cite{knoll-etal-2022-user} is the only paper I am aware of which explicitly examines requirements acquisition processes for NLG.  There are of course many general textbooks about software requirements (as above), which discuss requirements acquisition.  Textbooks about interaction and UI design in HCI (eg, Rogers et al \cite{interactiondesign}) can also be useful.



