%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Applications}
\label{applications} % Always give a unique label

\abstract*{NLG is not just an academic discipline, it is also a technology which can be used to build useful applications which help people.  This chapter discusses some fundamental issues (such as scalability), and then looks in more detail at four areas which NLG has been used commercially for many years: journalism, business intelligence, summarisation, and medicine.  Lessons from these long-standing NLG use cases can be applied to newer applications of NLG.}

NLG is being used in many real-world contexts.   Indeed, the usage of NLG is evolving extremely rapidly, with new use cases\index{use cases} appearing every month.  What is possible to accomplish in specific use cases is also changing fast, as better technology opens up new possibilities.

As always with this book, I will focus on fundamentals, not the latest developments.  I will first discuss generic issues in applying NLG to real-world use cases.  Then I will look at several  long-standing use cases of NLG: journalism, business intelligence,  summarisation, and healthcare.

\section{Key Attributes of Successful NLG Applications}

\subsection{Volume and Scalability}\label{sec:scalability}\index{volume}\index{scalability}
NLG systems generally need to generate a large number of texts in order to be cost-effective from a commercial perspective; this is related to return on investment\index{return on investment} (Section~\ref{sec:ROI}).  For example, suppose an NLG system generates a daily summary of the London stock market (on weekdays, not weekends), and that it would take a
journalist\index{journalism} one hour to write such a summary manually.  If the journalist is paid £20 per hour, this means the system saves £20*52*5 = £5200 per year.  The cost\index{cost} of building and maintaining the NLG is likely to be considerably higher than this!   On the other hand, if the system generates 60 stock market summaries each weekday (one summary for each of the 60 largest global stock markets),  then it saves £312K per year, which is more likely to be commercially viable.

It is for this reason that successful commercial NLG systems tend to focus on high-volume use cases, such as generating large numbers of local news stories, business intelligence reports, or email summaries.  For example, in sports reporting, it probably makes more commercial sense to use NLG to produce a large number of stories about local teams, instead of a small number of stories about world-leading teams.

NLG systerms built around prompted models\index{models!prompted} can be considerably cheaper to create than systems built using rules or by training or fine-tuning models.  However, if the goal is to create a product (as opposed to an in-house tool that customers do not see), then even if coding costs are massively reduced, there still will be substantial costs for requirements analysis (Chapter~\ref{requirements}), evaluation (Chapter~\ref{evaluation}), testing (Section~\ref{sec:testingnlg}), and maintenance (Section~\ref{sec:maintenance}). Plus of course commercial costs such as marketing.  So again volume makes commercial sense.

Of course NLG can be justified in other ways as well, for example the BBC Election Reporter\index{BBC Election Reporter} (Section~\ref{sec:bbcelection}) was justified on the basis of speed (need to get lots of election-results stories written quickly) as well as volume.  But even here, the system only made sense for generating hundreds of stories about local election results, it would not have been a viable solution to producing a small number of stories about national results.

A related concept is \emph{scalability}\index{scalability}; NLG systems should be usable in many contexts.  In healthcare, for example, there is limited commercial value in an NLG system which only works in one hospital, such as Babytalk\index{Babytalk} (Section~\ref{sec:nlgbenefits}).  We want systems which can be deployed in many hospitals and hence will work with different systems, sensors, equipment, clinical procedures, and  administrative procedures.

Of course, the difficulty of scalability depends on the use case.  For example, Business Intelligence\index{business intelligence} use cases are often scalable and generalisable at least to some degree, in part because the underlying processes and data are often similar in different companies.

\personal{I once worked a research project whose goal was to help non-verbal children\index{children} create stories about their school days for their parents \cite{black-hwst12,TintarevHWST}.  We worked with a small number of children and achieved good success with them, but it was clear that our solutions would not work for many other non-verbal children.  Children who cannot speak are very different from each other; different levels and types of cognitive impairment, different physical problems, different backgrounds and attitudes, etc.  In short we cold build bespoke solutions for individual children, but not scalable solutions which worked for a large number of non-verbal children.}



\subsection{Data Availability}\index{data availability}
We cannot build a data-to-text\index{data-to-text} NLG system unless we have access to the data that the system is describing or summarising; if we are building a neural NLG system which is trained or fine-tuned, we also need access to training data\index{training data}.  Data should also be of high-quality.  These issues can constrain where commercial NLG makes sense.

For example, a limitation on some NLG systems used in sports reporting is that they do not have access to visual data.   A human journalist\index{journalism} who observes a game will add phrases such as \lingform{Jones was in tears after missing a shot} or \lingform{Brown jumped for joy after scoring}, this human-interest content makes stories more interesting to readers.  But an NLG system cannot do this if it has access to scores and player performance data but not camera-feeds of players faces.

\subsection{Accuracy}\index{accuracy}
Neural NLG systems make mistakes\index{errors} (Section~\ref{sec:qualityaccuracy}).  Mistakes are more tolerable in some use cases than in others.  We can sometimes estimate the number of acceptable mistakes in a use case by analysing mistakes in texts written by people.
For example, Thomson et al \cite{thomson-csl23} found an average of 1.5 factual errors in human-written sports stories.  So 1.5 mistakes may be acceptable (although of course not desirable) in a sports story;  it would not be acceptable in medical reporting.

In many contexts the best way to produce accurate texts is for humans and NLG systems to work together, for example by asking human writers to edit\index{post-editing} the output of NLG systems (Section~\ref{sec:humanchecking}).  If done well, this process can produce texts which are more accurate than texts produced just by humans (because the NLG system will not make human-like errors like copying the wrong number) or just by NLG systems (because the humans will not hallucinate untrue information).

On the other hand, human checking and editing of NLG outputs must be done well in order to be effective. For example, CNET published a number of articles produced by an NLG system, which had been checked by human editors, which  nevertheless had serious and potentially harmful mistakes, such as giving inaccurate advice about personal finance.\footnote{\url{https://edition.cnn.com/2023/01/25/tech/cnet-ai-tool-news-stories/index.html}}

Accuracy is especially important if there are safety\index{safety} concerns (Section~\ref{sec:safety}); Section~\ref{sec:medical-safety} discusses safety concerns in medical applications of NLG.



\subsection{Maintainability and Adaptability}\index{maintenance}\index{adaptability}
As discussed in Section~\ref{sec:maintenance}, real-world NLG systems must be maintained and adopted as the domain and user needs change.  In healthcare\index{health}, for example, if medical advice is updated due to new research, NLG systems should adapt their output accordingly.  Unfortunately, this is not always easy to achieve in practice (Section~\ref{sec:datedinfo}); Strickland \cite{strickland2019ibm} points out that this was a major problem with the IBM Watson\index{IBM Watson} health systems.

Of course change is faster in some domains than in others; NLG weather forecast generators, for example, may evolve less quickly than medical NLG systems.  Hence the maintenance burden is different in different applications.  Application builders should estimate likely maintenance costs for their system, as well as development costs.


A related problem is that NLG systems should be able to adapt their output to local circumstances.  Figure~\ref{fig:chatgptlocal} shows an example of an adaptation failure; ChatGPT\index{ChatGPT} responds to a query with information which makes sense in the US but not in the UK, since UK patients generally do not have health insurance and do not need to deal with insurance providers.  Perhaps ChatGPT thought that \lingform{Aberdeen} referred to an American town, but this is odd because Aberdeen, UK is ten times bigger than any of the American Aberdeen's.


\begin{figure}
\lineacross\\
\emph{User}: I live in Aberdeen and want to see a respiratory health doctor, what should I do?\\

\emph{ChatGPT}:
If you're in Aberdeen and you're looking to see a respiratory health doctor, here are steps you can take:\\

\begin{enumerate}
\item Contact Your Primary Care Physician:\\

Start by reaching out to your primary care doctor or general practitioner. They can assess your symptoms, provide initial care, and refer you to a specialist if needed.\\

\item Insurance Coverage Check:\\

Check with your health insurance provider to understand your coverage and whether you need a referral to see a specialist.\\

\item Specialist Referral:\\

If your primary care doctor determines that you need to see a respiratory health specialist, they can provide you with a referral. This referral may be necessary for insurance purposes.\\

\item \emph{etc}
\end{enumerate}
\caption{ChatGPT advice is not appropriate for Aberdeen, UK, because the UK does not have an insurance-based health system}\label{fig:chatgptlocal}
\lineacross
\end{figure}


\subsection{Acceptability and Trust}\label{sec:acceptability}\index{acceptability}\index{trust}
NLG systems will only be used if people trust and accept them.  This is partially a \emph{change management}\index{change management} issue, and it is useful to be aware of the literature on managing and enabling organisational change, including introducing new technologies\footnote{\url{https://en.wikipedia.org/wiki/Change\_management}}.

For example, it is difficult to get hospitals and doctors\index{doctors} to use machine learning models for medical diagnosis; doctors see diagnosis as a core part of their job which they do not want to be automated, and hospitals do not see diagnosis as a major \scare{pain point}\index{pain point} which needs to be automated \cite{strickland2019ibm}.
Paul Meehl \cite{meehl1954clinical} showed in 1954 that simple regression models could do some medical diagnosis tasks better than the average doctor; however Meehl's models were never used.  Strickland analysed the failure of IBM's Watson\index{IBM Watson} health system \cite{strickland2019ibm}, and highlighted factors such as poor fit to clinical workflows\index{workflow}, and lack of understanding of requirements\index{requirements}, that is what doctors and hospitals actually wanted help with.

\personal{Many years ago, the Scottish AI pioneer Rob Milne (now sadly deceased) told me that the most successful AI applications were those that targeted \scare{peripheral} tasks, i.e. tasks that users saw as annoying distractions. It was much harder to build a successful AI application for a core task, i.e. a task that the user saw as a central aspect of his job and perhaps identity.  Diagnosis is  a core task for doctors.}



With regard to trust, domain experts may have more trust in simple models which they feel they understand, compared to black-box neural models.  This is not irrational if we consider that black-box models reflect their training data\index{training data}, which may be biased and noisy.  For example, a doctor may be concerned that a neural LLM used in a patient information system may in some cases repeat inappropriate content from the Internet (Section~\ref{sec:medical-safety}).  There is no way for a doctor to check the black-box LLM to see if this may happen, he needs to trust the system not to do this.

Another issue is that doctors often have additional information (for example visual observation of the patient) which is not available to the NLG system.  It is easier for doctors to assess the impact of this information if they understand how the NLG system works.

My experience (and that of other people working in applied NLG) is that trust is easily lost; even a single mistake can lead to users distrusting an NLG system and refusing to use it.


\subsection{Conforming to genre and sublanguage}\index{genre}\index{sublanguage}
In some applications, texts must be written in a way which conforms to a \emph{sublanguage} \cite{kittredge1982sublanguage}.  That is they need to use words and syntactic structures which are expected in the target domain\index{domain} and genre.

For example, the SumTime\index{SumTime} system generated marine weather forecasts\index{weather forecasts} \cite{REITER2005137}.  An example is shown in Figure~\ref{sumtime-sublanguage}.  Note that this sentence is \emph{not} a grammatically correct sentence according to the normal rules of English grammar; for example it does not have a correctly inflected clausal verb.  It does however fit the rules of the marine-forecast sublanguage, so it is perfectly acceptable.

\begin{figure}
\lineacross\\
W 10–15 backing SW by mid afternoon and S 13–18 by midnight.
\caption{Extract from SumTime forecast, in appropriate sublanguage}\label{sumtime-sublanguage}
\lineacross
\end{figure}

Similarly, texts intended for clinicians and medical professionals should use appropriate medical terminology\index{terminology} and language.  
Indeed, Moramarco et al's \cite{moramarco-etal-2022-human} evaluation of Note Generator\index{Note Generator} (Section~\ref{sec:NoteGenerator2}) identified several cases where inappropriate acronyms were used, and classified these as errors.

Precision terminology is also very important in  some cases.  For example, \lingform{bad headache} and \lingform{migraine} are sometimes used interchangeably by patients, but to doctors they have different meanings.

\personal{Patients may want to see some medical terminology, even if they do not fully understand it.  For example, in our Babytalk\index{Babytalk!BT-Family} system for parents (Section~\ref{sec:babytalk}), we initially tried to remove medical terminology.  However,  some parents didn't like this and said that we were \scare{dumbing down} texts and patronising them, so we put some medical terminology back into the parent reports, even though in some cases this made them harder to understand.}


\section{Journalism}\label{journalism}\index{journalism}

One of the oldest use cases for NLG is journalism and media, that is using NLG to produce stories for newspapers and web sites.  Typically data-to-text NLG is used for \emph{data journalism}\index{journalism!data} where an article is largely based on data of some kind; for example financial stories that summarise financial data, or sports stories that summarise what happened in a sports match based on match data.  This is sometimes called \emph{automatic journalism}\index{journalism!automatic} or \emph{robo-journalism}.

Diakopoulos \cite{diakopoulos2019automating} presents a detailed summary of \scare{Automated Content Production} in  journalism up to 2019.  In this period, the focus was on using relatively simple rule-based NLG\index{rule-based NLG} techniques (sometimes just templates) to generate drafts of relatively short and straightforward articles; these articles were post-edited by journalists (Section~\ref{sec:humanchecking}) before they were released. 

Large language model\index{large language models} technology (which appeared after 2019) allows more complex articles to be generated.  At the time of writing, there is a lot of excitement about using ChatGPT and other large language models in journalism; they should expand the power of automatic journalism by semi-automating production of more types of stories.  Perhaps the technology will also enable the development of new types of news media, such as dialogue systems for news (where users can ask questions about news stories).


\subsection{Example: BBC Election Reporter}\label{sec:bbcelection}\index{BBC Election Reporter}
A perhaps typical example of using relatively simple rule-based NLG techniques to produce media articles is the BBC's election reporter system, which generated short reports about election results in individual constituencies in the 2019 UK general election\footnote{\url{https://www.bbc.co.uk/news/technology-50779761}}.   An example is show in Figure~\ref{fig:bbcelection}.  Stories for constituencies in Wales were produced in Welsh\index{Welsh} as well as English.  Stories were checked\index{post-editing} by human journalists before they were released; in a few cases the journalists added additional content, generally deeper analysis of results in key races.

\begin{figure}
\lineacross\\
Florence Eshalomi has been elected MP for Vauxhall, meaning that the Labour Party holds the seat with a decreased majority.

The new MP beat Liberal Democrat Sarah Lewis by 19,612 votes. This was fewer than Kate Hoey's 20,250-vote majority in the 2017 general election.

Sarah Bool of the Conservative Party came third and the Green Party's Jacqueline Bond came fourth.

Voter turnout was down by 3.5 percentage points since the last general election.

More than 56,000 people, 63.5\% of those eligible to vote, went to polling stations across the area on Thursday, in the first December general election since 1923.

Three of the six candidates, Jacqueline Bond (Green), Andrew McGuinness (The Brexit Party) and Salah Faissal (independent) lost their £500 deposits after failing to win 5\% of the vote.

\textbf{\textit{This story about Vauxhall was created using some automation.}}

\caption{Example story from BBC election reporter, from \url{https://www.bbc.co.uk/news/technology-50779761}}
\label{fig:bbcelection}
\lineacross
\end{figure}

The rationale for this project is that the BBC can report election results overall, but it cannot manually produce 650 stories about individual MP races in the required time frame (readers expect to see these stories the morning after the election, not several days later).     The focus on fast production of a large number of news stories, with human oversight and editing, is common in automatic journalism.

This project used Arria\index{Arria} NLG Studio, which is a commercial tool for building rule-based NLG\index{rule-based NLG}.  Implementation details are not publicly available, but interested readers may wish to look at Valteri \cite{leppanen-etal-2017-data,Melin18}, which is an election reporting system built by an academic research group that also used rule-based NLG.

\subsection{Types of news}
\subsubsection{General news}\index{news!general}
A number of NLG systems have been used to produce general news articles  \cite{diakopoulos2019automating}, using an approach similar, at least at a conceptual level, to the BBC election reporter (Section~\ref{sec:bbcelection}).  For example, Radar\footnote{\url{https://pa.media/radar/}}\index{Radar} used Arria\index{Arria} NLG Studio to generate a large number of localised articles from data sets about politics, crime, health, traffic, and so forth.  For instance, the Radar system would ingest a UK-wide dataset about obesity rates, extract the relevant information for a particular town or city (such as Aberdeen), and then generate a story based on this data (ie, obesity in Aberdeen).  This story would be sold to a local newspaper, which would release it, possibly after being edited by a journalist to add more local content and context.

The advantage of this approach for journalists is that it made it much easier for local newspapers, which often were short-staffed and lacked journalists with domain expertise, to publish data-based articles on health, crime, etc.  A large national newspaper such as \emph{New York Times} or \emph{Guardian} will have in-house teams of specialist data journalists, but small local newspapers cannot afford this.

Large language models\index{large language models} such as ChatGPT may have a large impact in this area; technology and use cases are evolving very rapidly at the time of writing.

\subsubsection{Sports Reporting}\index{news!sports}
One of the most active areas of NLG in media is sports reporting.   Modern sporting events are often monitored by sensors which produce large amounts of data; there is also often a large amount of historical data about the players and teams involved in the match. This data can be used by NLG systems to generate many kinds of articles, including live updates during a match, post-match game descriptions, and pre-match summaries of the teams involved. Articles can be targeted towards different audiences, such as the general public, fans of one of the teams, or people placing bets; they can be delivered on social media, websites, and indeed printed stories.  NLG technology can also be used to generate reports from sports data for coaches and talent scouts.

Sports stories are an area where \emph{variation}\index{variation} (Section~\ref{sec:variation}) is very important.  Sports fans read lots of sports stories, and it is essential that these stories use different words and sentences (even when conveying similar information), otherwise readers will get bored and may stop reading the stories.  Certainly in the sports NLG projects I have been involved in, considerable effort was put into supporting extensive variation.

Anyways, the richness of data and use cases makes this an exciting area for NLG.   It is also an area where there is a lot of interest in using neural NLG techniques.  In part this is because from a quality-factor perspective (Section~\ref{req-criteria}), its is essential that sports stories be well-written and engaging.  Errors\index{errors} (such as hallucination) are of course not desirable but may have less impact than in safety-criticial contexts such as clinical decision support. An error in a story about a children's basketball game is not going to kill anyone!


\subsubsection{Financial News}\index{news!financial}

\begin{figure}
\lineacross\\
After climbing steadily through most of the morning, the stock market was pushed downhill late in the day. Stock prices posted a small loss, with the indexes turning in a mixed showing yesterday in brisk trading.

The Dow Jones average of 30 industrials surrendered a 16.28 gain at 4pm and declined slightly , finishing the day at 1083.61, off 0.18 points.

\caption{Stock market story from world's first data-to-text system \cite{kukich-1983-design}}
\label{fig:kukich-stock}
\lineacross
\end{figure}

There is also a lot of interest in in using NLG in financial journalism.  Investors and business people more generally are very interested in knowing what is happening in companies of interest to them.  There are thousands of companies listed on the London Stock Exchange, New York Stock Exchange, NASDAQ, etc, and it is difficult for human journalists to write stories about business developments in such a large number of companies.  But since basic data about listed companies is available from the stock markets\index{stock markets} themselves and also from relevant regulators\index{regulator}, NLG technology can be used to generate large numbers of stories about these companies, as well as stories about stock market performance.

Indeed, the very first work on data-to-text NLG, by Karen Kukich in 1983 \cite{kukich-1983-design}, was on generating summaries of stock market activity.  A simple example from Kukich's system is shown in Figure~\ref{fig:kukich-stock}.  Of course modern financial reporting NLG systems generate much more sophisticated texts about a wide range of financial stories (not just stock market updates), but the core concept is the same; the system takes financial data as input and produces a story about this data as output.

As with sports, a key issue is data availability\index{data availability}.  Generated stories are richer when the NLG system has access to more data about companies and markets, perhaps including data extracted from free-text documents using natural language understanding techniques. 
%In 2024 financial information companies such as Bloomberg\index{Bloomberg} use NLG to create routine financial stories.  However. t

From a quality factor perspective, financial stories should of course to be well-written and varied\index{variation}, like all news stories.  They also must be accurate, because investors may make decisions based in part on news stories.  Accuracy\index{accuracy} in financial news is perhaps not as important as in medical decision support, but it is considerably more important than accuracy in sports reporting.

From a technology perspective, at the time of writing many financial news generators use rule-based techniques, but there is huge interest in generating financial stories using machine learning and neural techniques. However, it is worth noting that Thomson-Reuters\index{Thomson-Reuters} generated financial stories for a number of years using a very interesting machine learning approach (essentially ML techniques were used to learn and select templates\index{templates} \cite{kondadadi-etal-2013-statistical}), but then withdrew this system, I suspect in part because journalists wanted more explicit control over the content of generated stories.  In short, this particular ML NLG system was not acceptable to journalists in real-world usage (Section~\ref{sec:acceptability}).  Of course other ML techniques may be more successful, but acceptability\index{acceptability} can only be assessed when the system is in production\index{production} real-world usage by many journalists.

\subsection{Fake News}\index{news!fake}
Neural NLG systems make mistakes.  Reputable journalists and media organisations will of course do their best to detect and minimise mistakes.  However, there also are malicious and unscrupulous agents who deliberately use NLG to to produce stories which are not true.   Large language models\index{large language models} unfortunately can be very good at producing \scare{fake news} \cite{solaiman2019release}.

A lot of fake news is simply designed to attract readers and hence get money from advertisers.  Of course some media outlets have printed fake stories about alien abductions and the like for decades, without any use of AI and NLG! But creating plausible-sounding stories about visits from little green men is easier and quicker with NLG.

More damaging is using AI to create fake material which people pay money to read.  For example, at the time of writing there is a lot of concern about people buying useless AI-written travel guides\footnote{\url{https://www.nytimes.com/2023/08/05/travel/amazon-guidebooks-artificial-intelligence.html}}.

Perhaps most damaging is fake news which tries to influence people.  In the last three months of the 2016 US Presidential election, fake news got more engagement in Facebook than genuine news\footnote{\url{https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook}}.  These articles were presumably written by humans, not NLG systems.  It is not clear to what degree NLG systems are currently being used to generate fake news for such purposes, but this is a major safety concern at the societal level \cite{distsafety}.

\section{Business Intelligence}\label{sec:bi}\index{business intelligence}
Another long-standing use case of NLG is Business Intelligence (BI)\footnote{\url{https://en.wikipedia.org/wiki/Business\_intelligence}}. BI tools help people understand data about their organisation (business, charity, government, etc).  Amongst other things, this includes data about:
\begin{itemize}
\item Sales, profits, losses;
\item Employees;
\item Budgets;
\item Inventories and logistics;
\item etc.
\end{itemize}
For example, a BI tool could help an organisation understand that most of its sales growth is in Asia, turnover in IT staff is growing rapidly, its inventory of laptops is too large, etc.  This in turn helps managers and other decision makers make good decisions.

Most commercial BI tools, such as Tableau\index{Tableau} and PowerBI\index{PowerBI}, focus on graphical\index{graphics} presentation of data.  However, in some cases textual presentation of data is better (Section~\ref{sec:textgraphics}), not least because it can include analyses and background information to supplement the data.

From a commercial perspective, one of the big advantages of BI as a use case is thats it is often scalable (Section~\ref{sec:scalability}).  Whereas medical NLG systems often need to be tailored for specific hospitals, and journalism NLG systems need to be adapted for specific local markets, all organisations have budgets and employees, and most have sales and inventories.  Furthermore, the data about budgets, employees, sales, and inventories is often held in databases or spreadsheets, many of which have a similar structure in part because of the requirements of tax and regulatory\index{regulator} authorities.  Hence it is possible to build somewhat generic NLG BI systems which can be sold to many customers.
 
 \subsection{Example: Covid Reporter}\label{sec:covid}\index{Covid Reporter}
 
 \begin{figure}
 \lineacross\\
\includegraphics[scale  = 0.75]{covidBI}
NLG text in above screenshot (replicated for clarity):\\
As of Sunday 17th May 2020, there are at least \textbf{4,364,603 confirmed cases} of COVID-19 worldwide. So far, \textbf{283,911 deaths} have been recorded as a result of the virus. The number of cases reported in the United States is increasing to a rate of \textbf{0.01\%}, while Russia is starting to slow down, having a rate of \textbf{-0.08\%}, compared to its average rate of\textbf{ -0.07\%} over the previous week.
\caption{Business Intelligence about Covid-19. Taken from \url{https://www.tibco.com/covid19} .  This page no longer exists, it was removed when the pandemic ended.}
\label{fig:covidBI}       
\lineacross
\end{figure}

A simple example is shown in Figure~\ref{fig:covidBI}.  This system was created by Tibco and Arria\index{Arria} to provide information to the  public about the status of the Covid-19 pandemic, using business intelligence techniques.  The full system includes many information displays; the one show in Figure~\ref{fig:covidBI} gives summary information about the presence of Covid-19\index{Covid pandemic}.  It uses an NLG-generated texts to give a high-level summary, a map to show distribution of Covid-19 in different countries, and a table to give more detailed information about badly affected countries.   This\scare{multi-modal}\index{multi-modal} combination of text and graphics is typical, and allows each media to be used to communicate the type of information it is best suited for.

\section{Summarisation}\index{summarisation}
Another long-standing use of NLG is summarising documents.  Indeed, summarisation predates NLG, with some initial work in this area done in the 1950s \cite{Luhn1957} focusing on statistical techniques for  identifying key material in a document,

There are two general approaches to summarisation.  \emph{Extractive summarisation}\index{summarisation!extractive} identifies key sentences and builds a summary from these, while \emph{abstractive summarisation}\index{summarisation!abstractive} creates new sentences to summarise information.  A simple example is shown in Figure~\ref{fig:extractiveabstractive}, which show shows possible extractive and abstractive summaries of an Aberdeen weather forecast\index{weather forecasts}.  The extractive one is simply the first sentence in the text, while the abstractive summary integrates information from several source sentences into the summary sentence.

\begin{figure}
\lineacross\\
\emph{Source text (weather forecast for Aberdeen):}\\
A mix of brighter spells and showers. Best of the brightness in the morning, particularly across Moray and western Aberdeenshire. Showers isolated early before building through the afternoon. Winds light. Maximum temperature 8 °C.\\

\emph{Extractive summary:}\\
A mix of brighter spells and showers. \\

\emph{Abstractive summary:}\\
A mild day with a mix of brighter spells (especially in the morning) and showers. \\

\caption{Extractive and abstractive summaries of a weather forecast}
\label{fig:extractiveabstractive}
\lineacross\\
\end{figure}

Another key distinction is between \emph{single-document summaries}  (where one document is summarised, as in the example in Figure~\ref{fig:extractiveabstractive}) and \emph{multiple-document summaries} (where multiple documents are summarised, for example a summary of a set of news articles).  The latter are often more useful, especially in contexts (such as summarising reviews or email chains) when the reader wants to quickly get an understanding of a set of documents.

There are many uses of summarisation, including:
\begin{itemize}
\item \emph{Meeting summaries:}  The Note Generator\index{Note Generator} system (Section~\ref{sec:NoteGenerator2}) is an example of a system that generates summaries of meetings.  There are many other tools in this space, which generate different types of summaries (key points, action items, etc.) of meetings.  Rennard et al \cite{rennard23} survey research in this area.
\item \emph{Email summaries:}  Likewise there are many tools which summarise email messages (individually or collectively), in order to help people manage overflowing inboxes; for example Microsoft Copilot in Outlook summarises email threads.
\item \emph{News summaries:}  Extensive research has been done on summarising news articles, initially driven by the desire of intelligence agencies to help analysts quickly identify key information \cite{mani2002summac}.  Recent work in this area has also looked at summarising social media.
\item \emph{Review summaries:} There also is a lot of interest in summarising product reviews, in this case it is essential that the summary cover a set of reviews (a summary of one review is less useful).  Amazon provides summaries of reviews in its ecommerce site.
\end{itemize}
At the time of writing, summarisation is usually done using large language models\index{large language models}.

\subsection{Example: Summarising emails with Google Bard}\index{Bard}
Google Bard is one of many systems that can summarise emails, including chains and sets of emails as well as single emails.  I show a simple Bard example in Figure~\ref{fig:bardemail}.  In this case, Bard has found the relevant email (which is pretty straightforward), extracted key information from the email which is relevant to my question, and created a sentence which communicates this information.  This is an example of generating an abstractive summary\index{summarisation!abstractive} of a single document.

\begin{figure}
\lineacross\\
\emph{Question to Bard:}\\
Check my emails, what is the next book in my bookclub\\

\emph{Response from Bard:}\\
The next book for the AJSCC book club is Odessa Stories by Isaac Babel. The meeting will be on Thursday, January 18th, 2024 at 8pm on Zoom.\\

\emph{Source email:}\\
\textbf{Subject}: dates of next few meetings for AJSCC book club\\
We had a wonderful evening of discussion around Susan's book choice!  Lovely to have so many of us participating.  Here are full details of our next two books for January and March\\


date:           Thursday 18th January 2024\\
time:            8.00pm\\
location:      Zoom\\
book:          Odessa Stories\\
author:        Isaac Babel\\
publisher:    Pushkin Collection\\
published:   2016\\
ISBN:          978-1782271666\\
chosen by:  Ehud\\

\emph{additional email content not shown}


\caption{Example of Bard summarising an email}
\label{fig:bardemail}
\lineacross\\
\end{figure}


\section{Medical applications}

For most of my career, I have been very interested in applications of NLG to healthcare\index{health}.  In principle, we can use NLG in all sorts of ways to help clinicians\index{doctors} and patients, including automated reporting (save doctor's time and perhaps reduce errors), clinical decision support (help clinicians make good decisions and avoid mistakes), patient information (keep patients informed and help them make appropriate decisions), and behaviour change (encourage patients to adopt healthier behaviours).  Success in this area would have huge impact, both financially (according to WHO, healthcare is over 10\% of the world's economy) and (more importantly) on people's lives.   Indeed, when I was asked to write a long-term vision for my research in the early 2000s, I said that I wanted to use NLG to help patients live healthier lives.

However, healthcare is also a very challenging area to work in, especially if our goal is real-world impact\index{impact} instead of academic papers.  In the early 1990s, a colleague told me that the challenge with AI generally in healthcare was building scalable\index{scalability} robust solutions which doctors and health organisations would adopt.  Building a system that works well on one data set or in one hospital is much easier than building a system which can be widely used; and building a widely-usable system is much easier than getting health organisations and professions to actually use the system (Section~\ref{sec:acceptability}).

In medicine, it is also the case that mistakes can hurt or even kill people; for this reason, we need to be careful when using neural language models.  Indeed, the terms of use of the BLOOM\index{BLOOM} language model explicitly prohibit using BLOOM \scare{to provide medical advice and medical results interpretation}\footnote{\url{https://huggingface.co/spaces/bigscience/license}}.

In short, NLG applications in healthcare have huge potential, but we must also keep in mind that it is difficult to deploy NLG technology on a large scale in healthcare, even if the technology is safe and effective.


\subsection{Use case: Reporting}\label{sec:medicalreporting}\index{reporting}
Many clinicians are most excited by NLG systems that automate or otherwise support reporting tasks.  Doctors\index{doctors} are expected to write large numbers of reports and documents, and this takes up a considerable amount of their time.  Most doctors see this as a peripheral task (Section~\ref{sec:acceptability}); it needs to be done but they welcome innovations which reduce the amount of time they spend on writing documents. Diagnosis, in contrast, is a core task, where automation is resisted; Strickland \cite{strickland2019ibm} discusses a related point.  Hence, from a change management\index{change management} perspectrive (Section~\ref{sec:acceptability}), many clinician welcome AI support for reporting, but not for diagnosis.

In other words, doctors will probably be receptive to \scare{We will use AI to automate paperwork so that you have more time for careful decision-making}.  However, they may not be receptive to \scare{We will use AI to automate decision-making so that you have more time to carefully complete your paperwork}.

From a commercial evaluation perspective, the benefits of report automation (time saved by doctors) are also relatively straightforward to measure. Changes in patient outcomes can be harder to measure; for example, if we are interested in survival rate 5 years after treatment, we will have to wait five years to get this information.

From a scalability\index{scalability} perspective (Section~\ref{sec:scalability}), reporting practices differ in different healthcare organisations, which means that reporting systems are often specific to individual hospitals or even hospital units.  An exception is regulatory reporting, which of course is standardised to the requirements of the regulator; for example I have seen commercial work on using NLG to generate clinical safety reports (on pharmaceuticals) for regulatory agencies.

\subsubsection{Example: Summarising consultations}\label{sec:NoteGenerator2}\index{summarisation}\index{consultations}
An example of an NLG system used for medical reporting is Note Generator\index{Note Generator} (described in Section~\ref{IntroConsultationSummary}). It generates a summary of a doctor-patient consultation, which is entered into the patient's medical record after being checked and edited by a doctor.  An extract from Note Generator was shown in Figure~\ref{fig:NoteGenerator};  I repeat this in Figure~\ref{fig:NoteGenerator2} for convenience.

Manually writing a summary of a doctor-patient consultation can take 2-3 minutes, which is a sizeable chunk of the ten minutes allocated to consultations with general practitioners (GPs) in the UK.  Partially automating this task gives doctors more time to interact with patients, which they welcome.  Moramarco \cite{moramarcophd} analysed real-world usage of Note Generator (Section~\ref{sec:historicalcomparisons}) and
reported that doctor using Note Generator (ie, post-editing a Note Generator summary) could generate a summary in 9\% less time compared to manually writing summaries from scratch.
Summaries produced by post-editing\index{post-editing} Note Generator drafts were also more accurate\index{accuracy} and contained fewer errors\index{errors} than manually written summaries. 

\begin{figure}
\lineacross\\
\includegraphics[scale  = 0.75]{NoteGenerator}
\caption{Example of Note Generation; this is the same as Figure~\ref{fig:NoteGenerator}}
\label{fig:NoteGenerator2}     
\lineacross  
\end{figure}




\subsection{Use case: Patient information and behaviour change}\index{patient information}\index{behaviour change}
It is a truism in medicine that the best way to improve most people's health is to change their behaviour.  This includes adopting healthier life styles (diet, exercise, smoking, etc), correctly complying with medical instructions (e.g., take medication correctly), and contacting healthcare personnel when appropriate.    Indeed, it is hard to see how healthcare systems can cope with increasingly elderly populations unless people look after themselves better.

Also, modern medicine expects patients to make informed decisions about their healthcare, and informed decisions are only possible if patients understand benefits and risks\index{risk}.  This is difficult for many people, especially if probabilities are involved; many people have a weak understanding of risk and probabilities (Section~\ref{sec:riskcommunication}).

Hence there is a lot of potential in building NLG systems that directly interact with patients in order to educate people about health consequences of their behaviour, encourage behaviour change,
and/or explain important information.   I personally think that this is an area of medicine where NLG could potentially make very important contributions.

A general rule is that we can help and encourage people to do things they would like to do, but its very hard to change intentions.  For example,  looking at smoking cessation, we can give suggestions to people who want to stop smoking about how to achieve this goal; its much harder to try to convince committed smokers to stop smoking.  Similarly we can support people who want to make informed decisions by giving them appropriate information, but giving information isn't going to do much good if the patient wants to delegate all decisions to his or her doctor.

Behaviour change is difficult even for people who want to change, especially on a long-term basis.  For example, most adult smokers in the UK want to stop smoking, but quitting is still very hard.  Similarly most overweight and obese people would like to lose weight, and may achieve this temporarily (e.g. by following a diet), but find it harder to lose weight on a sustained long-term basis.

In part for the above reasons, it is very useful for NLG systems (and indeed AI systems more generally) in this space to be integrated into the broader healthcare system, so that they are just one of many tools which people can use to help them change their behaviour.  Unfortunately, differences between healthcare systems can make this difficult.

\subsubsection{Example: encouraging smoking cessation}\label{sec:stop2}
The STOP\index{STOP} system (described in Section~\ref{sec:stopsmoking}) generated personalised smoking-cessation advice for smokers, based on their answers to a smoking questionnaire.   An extract from STOP was shown in Figure~\ref{fig:stopleaflet}; I repeat this in Figure~\ref{fig:stopleaflet2} for convenience.

\begin{figure}
\lineacross\\
\textbf{Dear Ms Cameron}
\blankline\\
Thank you for taking the trouble to return the smoking questionnaire that we sent you.  It appears from your answers that although you're not planning to stop smoking in the near future, you would like to stop if it was easy.  You think it would be difficult to stop because \emph{smoking helps you cope with stress}, \emph{it is something to do when you are bored}, and \emph{smoking stops you putting on weight}.  However, you have reasons to be confident of success if you did try to stop, and there are ways of coping with the difficulties.\\
%\includegraphics[scale  = 0.8,trim={0 9cm 14cm 0},clip]{images/tailor2.pdf}
\caption{Part of a STOP leaflet; this is the same as Figure~\ref{fig:stopleaflet}}\label{fig:stopleaflet2}
\lineacross
\end{figure}

Unfortunately, a randomised controlled clinical trial showed that the STOP system was not effective, i.e. people who received a fixed letter about smoking-cessation (not produced by an NLG system) were at least as likely to stop smoking as people who received a letter produced by STOP \cite{Lennox1396,REITER200341}.

\subsubsection{Communicating risks and probabilities}\label{sec:riskcommunication}\index{risk}\index{probability}
It is often necessary in patient information systems to communicate risks and probabilities.  Unfortunately many patients in the UK. US, and elsewhere have limited numeracy\index{numeracy} skills and may not understand numbers, so risk should be communicated to them in other ways, such as with words.

Some of the challenges in communicating risk linguistically are described by Berry \cite{berry2006health,berry2004ebook,berry2011}; see also Hommes et al \cite{hommes-etal-2019-personalized}.  For example:
\begin{itemize}
\item Different people interpret descriptors such as \lingform{likely} and \lingform{common} in different ways.
\item It matters how risk is framed (risk of success vs risk of failure).
\item Is risk communicated in absolute or relative terms (\lingform{this procedure has a 5\% chance of success} vs. \lingform{this procedure has a 50\% higher chance of success than the alternative})?
\end{itemize}
Even more complexity arises if we wish to communicate the reliability of a risk, e.g. \lingform{the model says you have a 10\% chance of developing lung cancer, however the risk may be higher because the model has ignored the fact that  both of your parents died of lung cancer} \cite{sivaprasad-reiter-2024-linguistically}.

Unfortunately, while there is a large general literature on risk communication, I am not aware of much research in the NLG community on communicating risk in a way which takes these issues into account.

\subsection{Use case: Clinical decision support}\index{decision support}
NLG systems can summarise information and help doctors\index{doctors} make decisions.  This is an appealing concept in principle, but success is difficult, in part  because of the issues mentioned in Section~\ref{sec:medicalreporting}.  Doctors enjoy decision making and generally are pretty good at it;  they also have access to additional information sources not available to the NLG system (eg, observing and talking to the patient). So help is often neither wanted nor needed \cite{strickland2019ibm}.  

Safety\index{safety} issues (Section~\ref{sec:safety}) are very important in this area; mistakes could cost lives and also could lead to massive lawsuits.  Trust\index{trust} is  paramount; if doctors don't trust an NLG system (and even a single mistake can destroy trust), they will not use it.  Adding explanations, if done well, could enhance trust.

\personal{Many years ago I was very excited by using NLG as a decision support tool, by summarising key information for clinicians.  Looking back at this now, I think this may be possible technically, but getting clinicians to use such a system would be very hard.  Adoption will probably be significantly easier for systems focusing on the other use cases discussed here (reporting, behaviour change, business intelligence).}


\subsubsection{Example: ICU decision support}\label{sec:babytalk2}
Babytalk\index{Babytalk} (described in Section~\ref{sec:babytalk}) generated decision-support material, nursing shift handover reports, and parent reports for babies in a neonatal intensive care unit, using information extracted from the baby's electronic patient record.  An extract from the Babytalk systems was shown in Figure~\ref{fig:BabytalkOutputs};  I repeat the extract from the Babytalk decision-support system in Figure~\ref{fig:BabytalkOutputs2} for convenience.

\begin{figure}
\lineacross\\
\emph{Example BT45 output (extract)}:\\
By 11:00 the baby had been hand-bagged a number of times causing 2 successive bradycardias. She was successfully re-intubated after 2 attempts. The baby was sucked out twice. At 11:02 FIO2 was raised to 79\%.\\

\caption{Example outputs from Babytalk BT45\index{Babytalk!BT45} decision-support system; this is the same as shown in Figure~\ref{fig:BabytalkOutputs}}
\label{fig:BabytalkOutputs2}
\lineacross
\end{figure}

\subsection{Medical business intelligence use cases}\label{sec:medicalbi}\index{business intelligence}
Of course medicine is a huge area, and there are many other ways we can use NLG in healthcare.  In particular, NLG can be used in many healthcare contexts to provide business intelligence (BI) (Section~\ref{sec:bi}) which supports non-clinical processes such as logistics and quality control.

For example, we can use NLG BI to support logistics\index{logistics}, and help insure that equipment, medication, blood supplies, ambulances, etc are in the right place.  I am not aware of research projects in this space, but I have seen some commercial uses of NLG that support BI in healthcare.  A medical colleague once told me that she thought logistics was the best place to apply AI in healthcare, since it is extremely important, and generally raises fewer concerns about safety, acceptability to clinicians, etc.

Another use of NLG+BI is to provide quality-of-service information on healthcare, either to patients (summarising quality and outcome data about a hospital) or to doctors (summarising how well they are doing at reaching various quality targets).  Management can also use NLG+BI to analyse efficiency and outcome data.  Again I'm not aware of research projects in this area, it seems mostly of interest to the commercial NLG world.

Last but not least, we can use NLG+BI to summarise and explain public health data, especially in local areas where public health officials may lack data analysis expertise.  I've seen discussions about this but not actual projects, which is a shame.

\subsection{Safety}\label{sec:medical-safety}\index{safety}
Safety (Section~\ref{sec:safety}) is obviously very important in medical applications, especially since incorrect medical information or advice could injure or kill people.  Hallucinations\index{hallucinations} are unacceptable in texts that impact medical care, as are omissions\index{omissions} of key information.  Singhai et al \cite{singhal2023large} present a formal evaluation of a medical language model, MedPaLM\index{MedPaLM}; Tamayo-Sarver \cite{TamayoBlog} describes some of the failings he has encountered when trying to apply ChatGPT\index{ChatGPT} to real-world medical situations.  Readers should keep in mind that humans as well as AI systems make mistakes, and a workflow\index{workflow} which combines human and AI can make fewer mistakes (Section~\ref{sec:NoteGenerator2}) and hence perhaps be safer, than a workflow that uses just humans (or just AI systems).

When systems are interacting with patients, it is also essential to minimise adverse emotional\index{emotion} effects.  Of course discussing medical details and options can be inherently depressing for patients \cite{van2024potential}, but systems should not unnecessarily make people feel depressed, inadequate, etc.
As discussed in Section~\ref{sec:upsetting}, Balloccu \cite{balloccuphd} asked domain experts to analyse texts produced by ChatGPT to response to dietary struggles, and he found many cases responses were factually correct but inappropriate and indeed unsafe because of their potential emotional impact.


Balloccu's domain experts also expressed a general concern ChatGPT seemed to largely be trained on texts
from internet forums which were not written by healthcare professionals.

Other medical professionals have made similar comments to me about the outputs of large language models\index{large language models}; the text was correct but not an appropriate thing to say to a patient.  In general, they feel that health information should come from reputable medical sources, and are concerned that Internet-trained LLMs may rely on sources that are not quality-controlled, such as Reddit\index{Reddit} forums.  Certainly in my own personal experience, advice from well-meaning lay people such as friends and family (as opposed to advise from health professionals) has often been insensitive to emotional issues.

\section{Further Reading}\label{sec:furtherApplications}
The usage of NLG in real-world applications is evolving and changing very rapidly.  There are numerous commercial websites which proclaim the wonders of specific NLG products, as well as numerous consulting firms who offer advice and analysis on NLG applications.  This material is usually very well written and presented, but of course is intended to further the author's commercial objectives.  It also tends to emphasise case studies, demos, and stories instead of rigorous evaluation.

Diakopoulos et al \cite{diakopoulos2024} is an excellent survey of how large language models and NLG are being used by journalists in 2024.  While this is about journalism\index{journalism}, many of the insights about use cases, workflows, ethics, etc. are generic and apply to other applications as well; I highly recommend this survey to anyone developing NLG applications. Diakopoulos also wrote a book in 2019 on \scare{Automating the newsroom} \cite{diakopoulos2019automating}, and helps run a website on NLG in journalism (\url{https://generative-ai-newsroom.com/}); both of these are also excellent sources.

Anyone interested in using NLG or indeed any form of AI in healthcare\index{health} should read Strickland's excellent retrospective on why IBM's Watson\index{IBM Watson} system was not successful in healthcare \cite{strickland2019ibm}; I would love to see more such retrospectives!
Hüske-Kraus's 2003 survey of NLG in clinical medicine in 2003 \cite{huske2003text} is still useful;  technology has changed radically since then, but many of the broader issues have not.

Dale occasionally writes insightful articles about commercial NLG, such as \cite{Dale_2023}.

My personal blog includes many blogs about applications of NLG and the issues raised in this chapter, including:
\begin{itemize}
\item \emph{Change management}: \url{https://ehudreiter.com/2020/01/27/ai-professionals-also-focus-on-change-management/}
\item \emph{BBC Election Reporter} (Section~\ref{sec:bbcelection}: \url{https://ehudreiter.com/2019/12/23/election-results-lessons-from-a-real-world-nlg-system/}
\item \emph{Challenges in medical NLG}: \url{https://ehudreiter.com/2021/06/21/pain-points-in-health-nlg/}
\item \emph{Covid reporter} (Section~\ref{sec:covid}): \url{https://ehudreiter.com/2020/05/21/adding-narrative-to-a-covid-dashboard/}
\item \emph{Sports NLG}: \url{https://ehudreiter.com/2022/03/21/sports-nlg-commercial-vs-academic-perspective/}
\end{itemize}
I have written many other blogs about NLG applications which readers may find useful.





