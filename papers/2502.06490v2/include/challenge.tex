\vspace{-0.05in}
\section{Challenges and Future Directions}
% \vspace{-0.03in}
\label{sec:challenge}

% As highlighted in the preceding sections of this review, discrete speech tokens have emerged as a thriving and central research direction in the era of speech LLMs.
Current discrete speech tokens still exhibit certain limitations and challenges that need to be addressed.
In this section, we summarize the existing challenges in this field and outline the corresponding future directions.

\vspace{0.05in}
\subsubsection{Low-Bitrate Tokens}
% Not only is reducing the bitrate desirable for compression and transmission, but it also eases the downstream modeling burden.
For bitrates of tokens, factors $Q$ (number of quantizers) and $F$ (frame rate) play a more important role than $V$ (vocabulary size).
% For $Q$, there have been efforts to construct single-codebook acoustic tokens~\cite{singlecodec,ji2024wavtokenizer,xin2024bigcodec,wu2024ts3codectransformerbasedsimplestreaming} and lower the bitrate to $\le 0.3$kbps~\cite{singlecodec,liu2024semanticodec,guo2024lscodec}.
Using only a single codebook is very beneficial for language modeling, since speech can be truly regarded as another ``natural language'' then.
However, there is usually a noticeable degradation in reconstruction performance in these tokens.
A critical problem lies in how to better utilize the highly-compact discrete VQ representation space.
For $F$, the frame rates of most tokens are still much greater than text sequences, which can significantly influence the syntactic and semantic modeling capability of language models~\cite{wang2024whyspeech}.
% , even if some attempt to lower the frame rate down to $\le 12.5$Hz~\cite{kyutai2024moshi,zeng2024scaling}.
% As pointed out in \cite{wang2024whyspeech}, the difference in sequence lengths between phoneme and speech tokens significantly influences the syntactic and semantic modeling capabilities of language models trained on these two modalities.
% It is thus important to further shorten the sequence length of speech tokens.
However, reducing the frame rate of tokens may also lead to decreased intelligibility in reconstructed speech.
A lower $V$ is also desirable for language modeling and length reduction by BPE.
% When considering legnth reduction using BPE, a lower $V$
% As for the vocabulary size $V$, it will not significantly impact the bitrate or downstream modeling generally, provided that it is not excessively large.

For acoustic tokens, it remains an open problem what the lower bound of bitrate and the frame rate $F$ are, and how to reach them.
More powerful network architectures or advanced VQ strategies should be helpful, and reducing temporal redundancy by disentangling global information is also a promising solution.

\vspace{0.05in}
\subsubsection{Streaming Ability and Efficiency}
Real-time applications require tokens to be stream-able both in encoding and decoding.
% , i.e. the token encoder and decoder must be able to produce outputs using only prior inputs or within a fixed chunk size.
% Streaming ability means encoding or decoding tokens in real time, or with minimal latency, once sufficient data is received.
% This means . 
For most CNN-based acoustic tokens, achieving this is easy due to their fixed receptive fields.
For acoustic tokens with Transformer blocks, an attention mask is necessary.
However, most SSL models employ a non-causal Transformer architecture, which makes semantic tokens derived from these models unsuitable for real-time tokenization.
% Since these tokens are frequently designed as targets for language modeling, the token vocoder for them should also be stream-able.
It remains unclear how much performance degradation would result from transitioning to causal architectures in both SSL models and token vocoders.

Streaming ability also poses a requirement for model efficiency.
Currently, larger acoustic token models are reported to achieve better performance with lower bitrates~\cite{xin2024bigcodec,parker2024scalingtransformerslowbitratehighquality}, but at a cost of efficiency.
In addition to reducing the bitrate of the tokenized codes, the efficiency of tokenizers must also be balanced for real-time applications.

\vspace{0.05in}
\subsubsection{Disentanglement in Acoustic Tokens}
Whether disentanglement should be incorporated into acoustic tokens depends on the specific application.
If reconstruction is the major objective, disentanglement may not be necessary.
However, disentanglement can help reduce the bitrate in time-varying tokens, ensure anonymity during transmission, reduce downstream modeling complexity, and achieve independent control of difference voice properties.
% For downstream modeling tasks, factorizing the encoded information is desirable for reducing modeling complexity and achieving independent control of different voice properties in generative tasks.
There are currently only limited efforts on decoupled acoustic tokens, and the decoupling effect is still suboptimal or causing a negative impact on reconstruction quality.
% , e.g. VC performance is lower than state-of-the-art VC models
More advanced techniques for information decoupling should be considered in the future.

\vspace{0.05in}
\subsubsection{Variable Frame Rate Tokens}
Current speech tokens are usually designed at a fixed temporal rate, while the underlying linguistic units in speech are highly variable-rate.
% This can be an important insight, as discrete tokens will have a better alignment and relation with texts then.
This can offer an important insight and potential of further reducing the bitrate, and more importantly, closing the gap between speech tokens and natural language units for downstream tasks.
% with inductive bias in tokens that more resembles units in a natural language.
So far, only semantic tokens have explored varying temporal rates, but with a complicated algorithm or iterative training process~\cite{baade2024syllablelm, cho2024sylber}.
More explorations need to be taken on variable frame rate acoustic tokens and the benefit of these variable frame rate tokens in practice.
% Is it possible for acoustic tokens to vary the frame rate as well?

\vspace{0.05in}
\subsubsection{Combining Acoustic and Semantic Tokens}
% It is widely acknowledged, and also shown in this review, that acoustic tokens emphasize  preserving the acoustic details of speech, whereas semantic tokens often discard them.
Given the distinct properties of acoustic and semantic tokens, a natural question arises: 
% Does there exist a representation space that is both acoustic and semantic? 
Can a representation space contain rich speech understanding capabilities while also reconstructing acoustic details at a decent level?
It is promising to incorporating semantic information from SSL models to enhance the reconstruction and downstream modeling performance of acoustic tokens~\cite{zhang2024speechtokenizer,ye2024codec,liu2024semanticodec}.
This approach should be further optimized to achieve lower bitrates and even a single codebook.

\vspace{0.05in}
\subsubsection{Paralinguistics in Semantic Tokens}
While speaker information is generally considered irrelevant for semantic content, prosody serves as a crucial component of paralinguistic information.
Semantic tokens derived through simple clustering methods are likely to discard both speaker information and prosody, harming downstream models' ability to handle rich emotions, tones, singing voices, and non-verbal vocalizations that convey semantic meaning.
This problem can be partially mitigated by certain VQ approaches that encode more information from SSL features~\cite{huang2023repcodec,shi24h_interspeech,mousavi2024should}, but at a cost of more codebooks and higher bitrates.
Supervised tokenization could also be considered for directly guiding tokens toward paralinguistic information. 
However, current supervised tokens rely solely on ASR, which is insufficient for preserving prosody.

\vspace{0.05in}
\subsubsection{Noise Preservation vs. Noise Robustness}
Similar to disentanglement in acoustic tokens, the inclusion or exclusion of background noise and channel effects in the tokens also depends on the specific application.
Most acoustic tokens are designed to capture noise, but their performance across various types of noise and channel effects remains unclear.
This issue extends beyond speech and relates to the broader scope of neural \textit{audio} codecs.
On the other hand, denoising~\cite{zeghidour2021soundstream} is also an interesting application of acoustic tokens that leverages the limited VQ space.
If noise is considered undesirable in tokens, such as semantic tokens, then the robustness against various types of signal perturbations needs to be investigated.

\vspace{0.05in}
\subsubsection{Timbre Control in Token Vocoders}
For semantic tokens and speaker-decoupled acoustic tokens, token vocoders should be responsible for controlling speaker timbre.
Currently, both GAN-based token-to-wav vocoders~\cite{guo2024vec2wav} and flow matching-based token-to-mel models~\cite{du2024cosyvoice} have demonstrated strong timbre control capabilities. 
It remains an open question whether the upper bound of the former method can be improved by training on large-scale datasets, as is done with the latter.
Also, the timbre controllability of in-the-wild reference prompts with various acoustic conditions should be further investigated.
% However, as the former is usually trained on a large scale of data, 

\vspace{0.05in}
\subsubsection{Adaptivity}
The diverse application scenarios range from transmission to various speech processing tasks and speech LLMs.
It is challenging to develop a single speech tokenizer that meets all the requirements of these scenarios.
However, adaptivity remains a desirable property, where the tokenizer is expected to adapt to different scenarios given a task prompt or a few data examples.
% For instance, an adaptive tokenizer is allowed to underperform on speech with unseen accents, languages, or acoustic backgrounds, but it should have the capability to quickly adapt to these new scenarios.
% Another example is that an acoustic tokenizer can determine whether to preserve or remove speaker timbre, or adjust the temporal rate and granularity, based on an external control signal.
If such tokens exist and the aforementioned challenges are well addressed, then we may be close to achieving a universal speech tokenizer.

\vspace{-0.07in}
\section{Conclusion}
% \vspace{-0.05in}
Recently, discrete speech tokens have emerged as a rapidly evolving field and a core research direction in the speech LLM era. These tokens encode acoustic or semantic information into a compact discrete representation space, catalyzing the fusion of LLMs and speech processing.
% , particularly speech generation and spoken language modeling. 
% The taxonomy of discrete speech tokens begins with the division of acoustic and semantic tokens.
Existing discrete speech tokens show rich diversity in model architecture and optimization objectives.
In this review, we provide a comprehensive introduction to representative categories of discrete speech tokens, summarizing their motivations and limitations. 
We conduct a unified analysis of reconstruction and voice conversion across different token types to highlight their unique characteristics. 
We also review efforts to apply discrete tokens to speech processing tasks, including spoken language understanding, speech generation, and spoken language modeling. 
Finally, we explore future directions for discrete speech tokenization methods. 
% Despite significant progress, substantial development remains ahead. 
We hope this review lays a solid foundation for future research in speech technology.
