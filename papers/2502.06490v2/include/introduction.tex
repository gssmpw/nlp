\section{Introduction}
% \IEEEPARstart{T}{his} file is intended to serve as a ``sample article file''

% \IEEEPARstart{S}{peech} is a long sequence: one second of 24kHz PCM16 speech waveform segment needs 384,000 bits to store in a computer.
% Such form of speech makes storage and transmission very costly and inconvenient.
% % , while the underlying text sentence is usually magnitudes 
% To mitigate this problem, compression is a necessary procedure in many speech processing practices, whether lossless or lossy.
% \textbf{Speech codecs} are such compression techniques for speech, whose primary goal is:

% \begin{center}
% {\textit{To compress long speech waveforms into short discrete bit streams, to decrease the bitrate for storage or transmission. If the compression is lossy, then optimize the reconstruction quality under a limited bitrate budget.}}
% \end{center}

\IEEEPARstart{T}{he} rapid advancement of large language models (LLMs) in natural language processing has revolutionized speech generation tasks~\cite{cui2024recent,ji2024wavchat}, with speech being tokenized and modeled using decoder-only Transformers~\cite{transformer}. 
Efforts starting from GSLM~\cite{lakhotia2021generative} and AudioLM~\cite{borsos2023audiolm} aim to develop text-free spoken LLMs, akin to how current LLM-powered chatbots enable text-based interactions. 
Other works, including VALL-E~\cite{valle} and VioLA~\cite{wang2024viola}, extend this approach to conditional speech generation tasks, such as zero-shot text-to-speech and speech translation.
However, this paradigm requires data to be tokenized, as LLMs typically process discrete data only. 
Textual tokens naturally meet this requirement because they are designed as discrete units separated by clear boundaries, whereas raw speech signals are continuous and boundary-less. 
Therefore, a necessary step before applying speech data to LLM is the \textbf{tokenization of speech}, whose goal is:

\begin{center}
    \textit{To convert long speech waveforms into short discrete tokens for downstream tasks. These tokens should be compatible with the underlying textual representations, especially for language modeling approaches targeted at speech.}
\end{center}

\begin{figure}
    \centering
    \includegraphics[width=0.99\linewidth]{figs/teaser.png}
    \caption{Diagram of discrete speech tokenization process and speech token-based downstream applications.}
    \label{fig:diagram}
    \vspace{-0.2in}
\end{figure}


% Fortunately, the aforementioned speech codecs are naturally discrete, thus they can also be regarded as a form of discrete speech tokens.
% Compared to continuous speech representations such as mel-spectrum, such discrete representations of speech are much more compact, which benefit downstream modeling tasks with various advantages.
% Starting from GSLM~\cite{lakhotia2021generative}, AudioLM~\cite{borsos2023audiolm} and VALL-E~\cite{valle}, researchers have realized that discretized speech tokens are very suitable for spoken language modeling and speech synthesis.
As a result, significant efforts have been directed towards developing efficient and powerful speech tokenization methods. Generally, these methods are based on two distinct principles, giving rise to two types of speech tokens: \textit{acoustic tokens} and \textit{semantic tokens}.
% The previous two goals have sparked two branches of discrete speech tokens, the \textit{acoustic tokens} and the \textit{semantic} tokens, respectively~\cite{borsos2023audiolm,kharitonov2023speak,yang2024towards}.
Acoustic tokens are derived from neural codecs designed to encode speech at a low bitrate while preserving as much information as possible. In contrast, semantic tokens originate from speech self-supervised learning (SSL)~\cite{mohamed2022self}, which aims to learn a more phonetic or semantic representation space, making it easier for speech recognition.
These two nearly independent lines of research magically intersect in the context of language modeling for speech.
Now, there are also efforts that try to design a speech tokenizer that accomplishes the two objectives simultaneously~\cite{zhang2024speechtokenizer,kyutai2024moshi}.
% So far, discrete speech tokens have been widely adopted in various speech processing tasks.
% Even if not in the decoder-only Transformer-based language modeling paradigm, discrete speech tokens have still proven to have advantages in some tasks~\cite{VQTTS,chang23b_interspeech,chang2024exploring}.
% As the LLM-based end-to-end spoken dialogue systems are being researched with increasing depth today, discrete speech tokens, no matter acoustic or semantic, are playing an important role as the inputs or outputs of such systems~\cite{ji2024wavchat}.
Consequently, speech tokenization has become a core problem of speech processing under the new paradigm, with versatile downstream applications, as shown in Fig.\ref{fig:diagram}.

% Xie et al.~\cite{xie2024towards} centers on tokens that are used in existing controllable TTS models.
Despite the rapid development and numerous recent works, a comprehensive taxonomy of methodologies in discrete speech tokens has not been clearly constructed. 
Existing reviews~\cite{mohamed2022self,anees2024speech,wu2024towards,cui2024recent,kim2024neural,ji2024wavchat} in this field overlook the diverse categories and methodologies in both acoustic and semantic tokens.
% Mohamed et al.~\cite{mohamed2022self} mentions some SSL models that produce discrete representations in the context of speech SSL.
% Mohamed et al.~\cite{anees2024speech} covers multiple traditional methods in speech coding for transmission and storage.
For example, \cite{cui2024recent,ji2024wavchat} focus primarily on methods in spoken language modeling, providing only brief descriptions of some speech tokens used in existing models.
The taxonomy of neural audio codecs has been summarized in \cite{wu2024towards,du2025codecfake}, but the realm of semantic tokens is still overlooked.
% Wu et al.~\cite{wu2024towards} introduces several neural audio codecs but largely ignores the realm of semantic tokens.
% Cui et al.~\cite{cui2024recent} also includes some semantic tokens and ``mixed objective'' tokens besides acoustic tokens.
% Kim et al.~\cite{kim2024neural} focuses on reviewing and discussing the integration of model-based and data-driven approaches in specific neural audio and speech codecs.
% WavChat~\cite{ji2024wavchat} introduces some tokens that are adopted in existing speech dialogue models.
% Xie et al.~\cite{xie2024towards} centers on tokens that are used in existing controllable TTS models.
% In this review, we give a detailed review of the ideas, methods and characteristics of different kinds of discrete speech tokens themselves, together with their applications in spoken language understanding (SLU), speech generation and spoken dialogue models.
In this review, we provide a comprehensive overview of the concepts, methods, and characteristics of various types of discrete speech tokens, with their applications in spoken language understanding, speech generation, and spoken dialogue models.
We hope that through this review, the community can have a clear understanding of the current development and key technologies of discrete speech tokens, so as to promote further research in the future.

% \textcolor{red}{TODO: Should have a figure to visualize the token-based speech processing paradigm in high-level.}

Our contributions are summarized as follows:
\begin{itemize}
    \item This review is the first to focus specifically on discrete speech tokens with sufficient depth in the LLM era.
    \item We construct a comprehensive taxonomy of current research on discrete speech tokens and meticulously review the motivation, representative approaches, and challenges in each sub-category.
    \item We provide a unified comparison of different types of discrete speech tokens in terms of reconstruction and voice conversion performance, covering both acoustic and semantic tokens.
    \item We summarize the current challenges and potential future directions for discrete speech tokens, including decoupled and variable frame rate tokens.
\end{itemize}

The structure of this review is shown in Fig.\ref{fig: Taxonomy}.
% We will first briefly introduce the technical pre-requisites of discrete speech tokens in Section \ref{sec:prereq}.
Following \cite{borsos2023audiolm,kharitonov2023speak,yang2024towards}, we classify discrete speech tokens into acoustic and semantic tokens based on their principles.
We will characterize the two types of tokens both by conceptual descriptions and unified experimental comparisons.
% , and identity potential challenges and future outlooks.
% , and introduce common token sequence compression methods in Section \ref{sec:dedup-bpe}.
% Some variable-rate discrete representation learning and unit discovery methods will be briefly covered in Section \ref{sec:variable-rate}.
% In Section \ref{sec:analysis}, we summarize the existing benchmarks and analyses of discrete speech tokens, and conduct a comparison of all kinds of tokens on their reconstruction and voice conversion performance. 
% This helps understand the different characteristics of each kind of tokens.
% Section \ref{sec:application} briefly presents several downstream application paradigms of discrete speech tokens besides compression and transmission.
% Section \ref{sec:challenge} concludes the current challenges and outlook for the future development of discrete speech tokens.
