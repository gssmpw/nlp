\section{Dataset Statistics}\label{apppendix:statistic}
The FoREST dataset statistic is provided in the Table~\ref{tab:data_statistic}.

\begin{table*}[t!]
    \centering
    \small
    \begin{tabular}{|c|c|c||c|c|c|}
        \hline
         Case & A-Split & A-Split for T2I & FoR class & C-Spilt & C-split for T2I\\
         \hline
         Cow Case & 792 & 3168 & External Relative & 1528 & 4288\\
         Box Case & 120 & 120 & External Intrinsic & 920 & 3680\\
         Car Case & 128 & 512 & Internal Intrinsic & 128 & 0\\
         Pen Case & 488 & 488 & Internal Relative & 248 & 0\\
         \hline
         Total & 1528 & 4288 & Total & 2824 & 7968 \\
         \hline
    \end{tabular}
    \caption{Dataset Statistic of FoREST dataset. }
    \label{tab:data_statistic}
\end{table*}


\section{Details Creation of FoREST dataset}\label{appendix:dataset_creation}
We define the nine categories of objects selected in our dataset as indicated below in Table~\ref{tab:selected object}. We select sets of locatum and relatum based on the properties of each class to cover four cases of frame of reference defined in Section~\ref{sec:FoR_Relatum_scenario}. Notice that we also consider the appropriateness of the container; for example, the car should not contain the bus.

Based on the selected locatum and relatum. To create an A-split spatial expression, we substitute the actual locatum and relatum objects in the Spatial Relation template. After obtaining the A-split contexts, we create their counterparts using the perspective/topology clauses to make the counterparts in C-spilt. Then, we obtain the I-A and I-C split by applying the directional template to the first occurrence of relatum when it has intrinsic directions. The directional templates are "that is facing towards," "that is facing backward," "that is facing to the left," and "that is facing to the right." All the templates are in the Table~\ref{tab:templates}.
We then construct the scene configuration from each modified spatial expression and send it to the simulator developed using Unity3D. 
Eventually, the simulator produces four visualization images for each scene configuration. 

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{|c|c|c|c|}
    \hline
        Category &  Object & Intrinsic Direction & Container \\
        \hline
        small object without intrinsic directions & umbrella, bag, suitcase, fire hydrant & \xmark & \xmark \\
        \hline
        bog object with intrinsic directions & bench, chair & \checkmark &  \xmark \\ 
        \hline
        big object without intrinsic direction & water tank & \xmark & \xmark \\
        \hline
        container & box, container & \xmark & \checkmark \\
        \hline
        small animal & chicken, dog, cat & \checkmark & \xmark \\
        \hline
        big animal & deer, horse, cow, sheep & \checkmark & \xmark \\
        \hline
        small vehicle & bicycle & \checkmark & \xmark \\
        \hline
        big vehicle & bus, car & \checkmark & \checkmark \\
        \hline
        tree & tree & \xmark & \xmark \\
        \hline
    \end{tabular}
    \caption{All selected objects with two properties: intrinsic direction, affordance of being container}
    \label{tab:selected object}
\end{table*}

\subsection{Simulation Details}
The simulation starts with randomly placing the relatum into the scene with the orientation based on the given scene configuration. 
We randomly select the orientation by given scene configuration, [-40, 40] for front, [40, 140] for left, [140, 220] for back, and [220, 320] for right. Then, we create the locatum from the relatum position and move it in the spatial relation provided. If the frame of reference is relative, we move the locatum based on the camera's orientation. Otherwise, we move it from the relatum's orientation. Then, we check the camera's visibility of both objects. If one of them is not visible, we repeat the process of generating the relatum until the correct placement is achieved. After getting the proper placement, we randomly choose the background from 6 backgrounds. Eventually, we repeat the procedures four times for one configuration. 

\subsection{Object Models and Background}
For the object models and background, we find it from the unity assert store\footnote{https://assetstore.unity.com}. All of them are free and available for download. All of the 3D models used are shown in Figure~\ref{fig:3D_model}.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{Figures/all_3d_model.png}
    \caption{All 3d models used to generate visualizations for FoREST.}
    \label{fig:3D_model}
\end{figure*}

\begin{table*}[t]
    \centering
    \tiny
    \begin{tabular}{|c|c|} 
    \hline
        &   \{locatum\} is in front of \{relatum\} \\
         &  \{locatum\} is on the left of \{relatum\} \\
           &  \{locatum\} is to the left of \{relatum\}\\ 
        Spatial Relation Templates &  \{locatum\} is behind of \{relatum\} \\
           &  \{locatum\} is back of \{relatum\} \\
          &  \{locatum\} is on the right of \{relatum\} \\
          &   \{locatum\} is to the right of \{relatum\} \\
         \hline
         &  within \{relatum\} \\ 
         Topology Templates &  and inside \{relatum\} \\ 
         &  and outside of \{relatum\} \\ 
         \hline
         & from \{relatum\}'s view \\ 
         & relative to \{relatum\} \\ 
         Perspective Templates & from \{relatum\}'s perspective\\ 
         & from my perspective \\ 
          & from my point of view \\ 
           & relative to observer \\ 
         \hline
          &  \{relatum\} facing toward that camera\\ 
         Orientation Templates &  \{relatum\}is facing away from the camera. \\ 
          &  \{relatum\} facing left relative to the camera\\ 
           &  \{relatum\} facing right relative to the camera \\ 
         \hline
         & In the camera view, how is \{locatum\} positioned in relation to \{relatum\}? \\
        &  Based on the camera perspective, where is the \{locatum\} from the \{relatum\}'s position? \\ 
         Question Templates &  From the camera perspective, what is the relation of the\{locatum\} to the \{relatum\}?\\ 
          &  Looking through the camera perspective, how does \{locatum\} appear to be oriented relative to \{relatum\}'s position?\\ 
           &  Based on the camera angle, where is \{locatum\} located with respect to \{relatum\}'s location? \\ 
         \hline
    \end{tabular}
    \caption{All templates used to create FoREST dataset.}
    \label{tab:templates}
\end{table*}


\subsection{Textual templates}\label{appendix:textual_template}
All the templates used to create FoREST are given in Table~\ref{tab:templates}.



\section{VISOR {uncond} Score}\label{appendix:Visor_uncond}

VISOR$_{uncond}$ provides the overall spatial relation score, including images with object generation errors. Since it is less focused on evaluating spatial interpretation than VISOR$_{cond}$, which assesses explicitly the text-to-image model's spatial reasoning, we report VISOR$_{uncond}$ results here in the Table~\ref{tab:VISOR_uncode} rather than in the main paper. The results are similar to the pattern observed in VISOR$_{uncond}$ that the based models(SD-1.5 and SD-2.1) perform better in the relative frame of reference, while the layout-to-image models, i.e., GLIGEN, are better in the intrinsic frame of reference.

\begin{table*}[t!]
    \centering
    \small
    % \begin{adjustbox}{width=\columnwidth -0mm, center}
    \begin{tabular}{|l | c c | c | c c | c |}
    \hline
         & \multicolumn{6}{c|}{VISOR(\%)} \\ \cline{2-7}
        Model & uncond (I) & uncond (R) & uncond (avg) & uncond (I) & uncond (R) & uncond (avg) \\
        \hline
         & \multicolumn{3}{|c|}{ A-Split } & \multicolumn{3}{|c|}{ C-Split }  \\ \hline
        SD-1.5 & $ 45.43$  & $33.22$ & $ 43.51$ &  $ 35.06$  & $ 35.68$ & $ 35.40$ \\
        SD-2.1 & $\mathbf{62.87}$  & $ 43.90$ & $\mathbf{59.89}$ & $\mathbf{45.98}$  & $ 46.59$ & $\mathbf{46.31}$ \\
        \hline
        Llama3-8B + GLIGEN & $ 46.74$  & $ 38.16$ & $ 45.39$ & $ 33.98$  & $ 39.36$ & $ 36.89$ \\
        Llama3-70B + GLIGEN & $ 54.33$  & $ 46.89$ & $ 53.17$ & $ 38.04$  & $ 46.04$ & $ 42.37$ \\
        Llama3-8B + SG + GLIGEN (Our) & $ 51.83$  & $ 43.24$ & $ 50.48$ & $ 36.28$  & $ 44.43$ & $ 40.70$ \\
        Llama3-70B + SG + GLIGEN (Our) & $ 58.92$  & $\mathbf{47.44}$ & $ 57.12$ & $ 38.23$  & $\mathbf{48.62}$ & $ 43.86$ \\
        \hline
    \end{tabular}
    \caption{VISOR$_{uncond}$ score on the A-Split and C-Split where $I$ refer to the Cow Case and Car Case where relatum has intrinsic directions, and $R$ refer to the Box Case and Pen case where relatum lacks intrinsic directions, $avg$  is mirco-average of $I$ and $R$. cond and uncond are explained in Section~\ref{sec:evaluation_setting}.}
    \label{tab:VISOR_uncode}
\end{table*}


\section{Analyze the improvements in SG-prompting for T2I.} \label{appedix:anaylize_SG_improment_t2i}
\begin{table}[t]
    \small
    \centering
    \begin{tabular}{|l|c|c|c|}
         \hline
         Model & Layout & Layout$_{cond}$  \\
         \hline
          Llama3-8B  & $85.26$ & $88.84$\\
          Llama3-8B + SG  & $85.04$ & $88.86$  \\
          Llama3-70B  & $88.47$ & $93.16$ \\
          Llama3-70B + SG & $91.95$ & $95.45$ \\
          \hline
    \end{tabular}
    \caption{Layout accuracy where spatial relations are left or right relative to the camera. Layout is evaluated for all generated layouts in I-C split while Layout$_{cond}$ uses the same testing examples as VISOR$_{cond}$.}
    \label{tab:layout_results}
\end{table}


To further explain improvements of SG-prompting in T2I task, we assess the generated bounding boxes
in the I-C split for left and right relations relative to the camera since these can be evaluated using only bounding boxes without depth information.
As seen is Table~\ref{tab:layout_results}, our SG prompting improved 
Llama3-70B's by $3.48\%$, while Llama3-8B saw a slight decrease of $0.22\%$. 
This evaluation was conducted on all generated layouts from the I-C split, which differs from the evaluation subset of images used for VISOR$_{cond}$ in Table~\ref{tab:I_split}. 
We report the layout$_{cond}$ score for a consistent evaluation in the same table. Layout$_{cond}$ shows that Llama3-8B improves within the same evaluation subset with VISOR$_{cond}$.
Overall, by incorporating FoR information through SG layout diffusion, Llama3 generates better spatial configurations, enhancing image generation performance.



% \section{\iclr{Qualitative Examples of Failure Cases of CoT and SG}}\label{appendix:false_examples}


% \subsection{CoT Incorrect but Resolved by using SG}

% \begin{itemize}
% \item \textbf{Context} : A cat is inside and on the left of a car from the car's perspective

% \textbf{CoT} : Explanation: Cat is inside of the car, and the car has the intrinsic direction. However, the left of the car is referring to the car's perspective rather than the intrinsic direction of the car. Answer: internal relative.

% \textbf{SG} : Explanation: Topological: cat is inside of the car. Distance: cat should be in the same location with the car from the context. Direction: The car which is the relative object has the direction, and cat is on the left side of the car. Answer: internal intrinsic.

% \textbf{label} : internal intrinsic

% \item \textbf{Context} : A container is on the right of a dog from the dog's perspective

% \textbf{CoT} : Explanation: Based on the context, dog does not contain the container. The dog has the direction; however, the right of a dog referring to the dog's perspective rather than intrinsic direction of the dog. Answer: external relative.

% \textbf{SG} : Explanation: Topological: container is not inside of the dog. Distance: container may has some distance from dog according to the context. Direction: Dog has the direction and the context right relation is referred from dog's perspective that a container is on the right side of the dog's facing orientation. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A water tank is on the left of a cow from the cow's perspective

% \textbf{CoT} : Explanation: Based on the context, cow does not contain the water tank. The cow has the direction; however, the left of a water tank referring to the cow's perspective rather than cow's intrinsic direction. Answer: external relative.

% \textbf{SG} : Explanation: Topological: water tank is not inside of the cow. Distance: water tank may has some distance from cow according to the context. Direction: The cow which is the relative object has the direction, and water tank is on the left side of the cow. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A bicycle is in front of a container inside the container

% \textbf{CoT} : Explanation: The bicycle is contained within the container, fulfilling the first condition for internal frames of reference. However, since the bicycle is also described as being 'in front' of another object (another container), this implies a spatial relationship that is dependent on the container's intrinsic direction. But due to thembiguity of having two containers mentioned, and assuming the second 'container' is a typo or misstatement, we interpret it as a single container scenario. As such, the spatial relation is intrinsic to the container itself, not relative to an external observer or another entity. Answer: internal intrinsic. 

% However, the context provided contains a potential error or ambiguity ("inside the container"), which could alter the interpretation if clarified. Assuming there was meant to be only one container, thebove categorization holds. If there were indeed two distinct containers, further clarification would be needed to accurately categorize the spatial relation.

% \textbf{SG} : Explanation: Topological: bicycle is inside of the container. Distance: bicycle should be in the same location with the container from the context. Direction: Container doesn't have the direction and context refere from observer perspective for bicycle is in the front of the container. Answer: internal relative. However, there seems to be a contradiction in the statement as it says the bicycle is both inside and in front of the container. For the purpose of categorization, we will assume that the intended meaning was that the bicycle is inside the container and positioned towards the front end of it.

% \textbf{label} : internal relative

% \item \textbf{Context} : A tree is on the left of a box inside the box

% \textbf{CoT} : Explanation: Based on the context, box does not contain the tree. However, it seems there might be a mistake in the sentence as it mentions 'inside the box' twice. Assuming the intention was to describe the tree's position relative to the box without specifying a container for the tree, we can interpret this as the tree being positioned relative to the box without being contained within it. Since the box does not have an intrinsic direction, the reference to 'left' is relative to an external observer's perspective. Answer: external relative.

% \textbf{SG} : This context seems to have a logical inconsistency as a tree cannot be inside a box. However, assuming this was intended to describe two separate spatial relations, we can interpret it as follows:

% Explanation: Topological: tree is not inside of the box. Distance: tree may have some distance from the box according to the context. Direction: the box does not have a facing orientation, so the tree being on the left is referred from the observer's perspective. Answer: external relative for the relation between the tree and the box.

% However, the second part of the sentence "inside the box" does not provide enough information to determine a spatial relation between entities. It appears to be incomplete or incorrectly phrased. If you meant to say "A tree is on the left of a box inside a room," then the relation between the tree and the box would still be external relative, while the relation of the box being inside the room would be internal relative.

% \textbf{label} : internal relative

% \item \textbf{Context} : A deer is outside and on the left of a bus relative to the bus

% \textbf{CoT} : Explanation: The bus has the front/back direction. However, the left of the bus is not referring to the bus's intrinsic direction, but rather to an observer's perspective. Answer: external relative.

% \textbf{SG} : Explanation: Topological: deer is outside of the bus. Distance: deer may be little bit far from the left of the bus from the context. Direction: The bus which is the relative object has the direction and deer is actually on the left side of the bus. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A bicycle is behind a fire hydrant

% \textbf{CoT} : Explanation: Based on the context, fire hydrant does not contain the bicycle. Fire hydrant does not have intrinsic direction, so the behind relation is based on the observer's perspective. However, since there is no explicit mention of an observer or reference point, we can consider it as an external intrinsic relation where the observer's perspective is implied. Answer: external intrinsic.

% \textbf{SG} : Explanation: Topological: bicycle is not inside of the fire hydrant. Distance: bicycle may have some distance from the fire hydrant according to the context. Direction: Fire hydrant does not have a facing orientation, so the spatial relation is not relative to its intrinsic direction. Instead, it is described from an external perspective. Answer: external relative.

% \textbf{label} : external relative

% \item \textbf{Context} : A box is behind a chicken relative to the chicken

% \textbf{CoT} : Explanation: The chicken has no intrinsic direction, so the 'behind' relation is based on the perspective of the chicken itself, not its intrinsic orientation. Answer: external relative. Note that this could potentially be seen as external intrinsic if we assume that the chicken has a front-back orientation, but since chickens do not typically have a fixed or understood front-back orientation like humans or cars do, it is more likely to be considered external relative.

% \textbf{SG} : Explanation: Topological: box is not inside of the chicken. Distance: box may be little bit far from the chicken from the context. Direction: The chicken which is the relative object has the direction and box is actually behind the chicken. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A car is in front of a deer from the deer's perspective

% \textbf{CoT} : Explanation: Based on the context, deer does not contain the car. The deer has the direction; however, the front of a deer referring to the deer's perspective rather than intrinsic direction of deer. Answer: external relative.

% \textbf{SG} : Explanation: Topological: car is not inside of the deer. Distance: car may has some distance from deer according to the context. Direction: The deer which is the relative object has the direction, and car is in front of the deer. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : An umbrella is on the left of a chicken from the chicken's perspective

% \textbf{CoT} : Explanation: Based on the context, chicken does not contain the umbrella. The chicken has the direction; however, the left of a chicken referring to the chicken's perspective rather than intrinsic direction of the chicken. Answer: external intrinsic. Note that this sentence is ambiguous because it can be interpreted as external relative if the left is referring to the observer's perspective. However, given the context provided, it is more likely to be interpreted as external intrinsic.

% \textbf{SG} : Explanation: Topological: umbrella is not inside of the chicken. Distance: umbrella may has some distance from chicken according to the context. Direction: The context left relation is referred from the chicken's perspective that an umbrella is on the left side of the chicken's facing orientation. Answer: external intrinsic.

% \textbf{label} : external intrinsic

% \end{itemize}

% \subsubsection{Failure Case of SG}

% \begin{itemize}
%     \item \textbf{Context} : A bus is on the right of a chair from the chair's perspective

% \textbf{SG} : Explanation: Topological: bus is not inside of the chair. Distance: bus may has some distance from chair according to the context. Direction: Even though the chair does not have a facing orientation, the perspective is given as the chair's, making this a case of an object being described relative to another object's perspective. Answer: external intrinsic. However, usually chairs do not have a defined facing direction, so typically this would fall under external relative. But given the instruction to consider the chair's perspective, it can be seen as an exception to the rule, aligning more closely with external intrinsic in this specific context.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A tree is on the left of a box inside the box

% \textbf{SG} : This context seems to have a logical inconsistency as a tree cannot be inside a box. However, assuming this was intended to mean 'A tree is on the left of a box inside a room', the categorization would be:

% Explanation: Topological: tree is not inside of the box. Distance: tree may have some distance from the box according to the context. Direction: The context left relation is referred from observer's perspective that a tree is on the left side of the box location. Answer: external relative. 

% If the original context was correct, it would fall under none of these categories due to the physical impossibility of the scenario described.

% \textbf{label} : internal relative

% \item \textbf{Context} : A cow is in front of a bench relative to the bench

% \textbf{SG} : Explanation: Topological: cow is not inside of the bench. Distance: cow may has some distance from bench according to the context. Direction: Bench doesn't have the direction and context refere from observer perspective for cow is in the front of the bench. Answer: external relative. But if we consider that 'in front of' refers to the bench's intrinsic direction, then it would fall under external intrinsic. However, benches typically do not have a defined facing direction, so this is less common.

% \textbf{label} : external intrinsic

% \item \textbf{Context} : A dog is on the left of a box within the box

% \textbf{SG} : Explanation: Topological: dog is not inside of the box. Distance: dog may has some distance from box according to the context. Direction: Even if box has direction, the context left relation is referred from observer's perspective that a dog is on the left side of the box location. However, since the dog is not contained by the box, this does not fall under internal intrinsic or internal relative. Answer: external relative. Note that the phrase "within the box" seems redundant and does not change the frame of reference.

% \textbf{label} : internal relative

% \end{itemize}

\section{Frame of Reference Identification}\label{appendix:FoRIdentification}

We evaluate the LLMs' performance in recognizing the FoR classes from given spatial expressions. 
The LLMs receive spatial expression, denoted as $T$, and output one FoR class, $FoR$, from the valid set of FoR classes, $For \in $ \{external relative, external intrinsic, internal intrinsic, internal relative\}. All in-context learning examples are in the Appendix~\ref{appendix:in-context}.

\subsection{Experimental Setting}
\noindent\textbf{Zero-shot model.} We follow the regular setting of \textit{zero-shot} prompting. 
We only provide instruction to LLM with spatial context. 
The instruction prompt briefly explains each class of the FoR and candidate answers for the LLM. We called the LLM with the instruction prompt and $T$ to find $F$.

\noindent\textbf{Few-shot model.} We manually craft four spatial expressions for each FoR class. 
To avoid creating bias, each spatial expression is ensured to fit in only one FoR class. These expressions serve as examples of our \textit{few-shot}setting.
We provide these examples in addition to the instruction as a part of the prompt, followed by $T$ and query $F$ from the LLM.

\noindent\textbf{Chain-of-Thought (CoT) model.}
To create CoT~\citep{wei2023chainofthoughtpromptingelicitsreasoning} examples, we modify the prompt to require reasoning before answering.
Then, we manually crafted reasoning explanations with the necessary information for each example used in few-shot.
Finally, we call the LLMs, adding modified instructions to updated examples, followed by $T$ and query $F$. 

\noindent\textbf{Spatial-Guided Prompting (SG) model.}
We hypothesize that the general spatial relation types defined in Section~\ref{sec:primitives} can provide meaningful information for recognizing FoR classes. For instance, a topological relation, such as ``inside," is intuitively associated with an internal FoR.
Therefore, we propose Spatial-Guided Prompting to direct the model in identifying the type of relations before querying $F$. 
We revise the prompting instruction to guide the model in considering these three aspects. 
Then, we manually explain these three aspects.
We specify the relation's origin from the context for direction relations, such as "the left direction is relative to the observer."
We hypothesize that this information helps the model distinguish between intrinsic and relative FoR.
Next, we specify whether the locatum is inside or outside the relatum for topological relations. 
This information should help distinguish between internal and external FoR classes.
Lastly, we provide the potential quantitative distance, e.g., far. This quantitative distance further encourages identifying the correct topological and directional relations. 
Eventually, we insert these new explanations in examples and call the model with the updated instructions followed by $T$ to query $F$.

\subsection{Evaluation Metrics}
We report the accuracy of the model on the multi-class classification task. Note that the expressions in A-split can have multiple correct answers. Therefore, we consider the prediction correct when it is in one of the valid FoR classes for the given spatial expression. 

\begin{table}[t]
    \tiny
    \centering
    \begin{tabular}{|l|c | c|c|c|}
    \hline
    \textbf{Model} & \multicolumn{2}{c|}{inherently clear} & \multicolumn{2}{c|}{require template} \\ \cline{2-5}
     & CoT & SG & {CoT} & {SG} \\ 
    \hline
    Llama3-70B  & 19.84 & 44.64 \improve{24.80} & 76.72 & 87.39 \improve{10.67}\\
    Qwen2-72B & 58.20 & 84.22 \improve{26.02} & 88.36 & 93.86 \improve{10.67} \\
    GPT-4o & 12.50 & 29.17 \improve{16.67} & 87.73 & 90.74 \improve{3.01}  \\
    \hline
    \end{tabular}
    \caption{The comparison between CoT and SG prompting in C-split separated by inherently clear / required template to be clear.}
    \label{tab:model_performance}
\end{table}



\begin{table*}[t]
    \tiny
    \centering
    \begin{tabular}{| l | c | c c c c | c|}
        \hline
        & A-split & \multicolumn{5}{|c|}{C-Split} \\ \cline{3-7}
         Model &  & ER-C-Split & EC-Split & IC-Split & IR-C-Split & Avg. \\
         \hline
         Gemma2-9B (0-shot) & $94.17$ & $\mathbf{94.24}$ & $35.98$ & $53.91$ & $57.66$  & $60.45$\\
          Gemma2-9B (4-shot) & $59.58$  & $55.89$\worse{38.34} & $72.61$\improve{36.63} & $74.22$\improve{20.31} & $54.44$\worse{3.23} & $64.29$\improve{3.84}\\
         Gemma2-9B (CoT) & $60.49$  & $60.49$\worse{33.74} & $60.54$\improve{24.57} & $87.50$\improve{33.59} & $54.03$\worse{3.63} & $65.64$\improve{5.20}\\
          Gemma2-9B (SG)(Our) & $72.67$ & $65.87$\worse{28.37} & $65.54$\improve{29.57} & $53.12$\worse{0.78} & $\mathbf{95.97}$\improve{38.31} & $70.13$\improve{9.68}\\
         \hline
         llama3-8B (0-shot) & $60.21$ & $32.20$ & $90.11$ & $75.78$ & $0.00$ & $49.52$\\
         llama3-8B (4-shot) & $60.14$ & $47.77$\improve{15.58} & $54.35$\worse{35.76} & $100.00$\improve{24.22} & $41.13$\improve{41.13} & $60.81$\improve{11.29}\\
         llama3-8B (CoT) & $61.32$ & $61.06$\improve{28.86} & $97.28$\improve{7.17} & $100.00$\improve{24.22} & $36.29$\improve{36.29} & $73.66$\improve{24.14}\\
         llama3-8B (SG) (Our) & $62.95$ & $63.29$\improve{31.09} & $94.57$\improve{4.46} & $100.00$\improve{24.22} & $43.55$\improve{43.55} & $75.35$\improve{25.83}\\

         \hline
         llama3-70B (0-shot) & $84.23$ & $74.08$ & $9.57$ & $92.19$ & $68.55$ & $61.10$\\
         llama3-70B (4-shot) & $78.47$ & $81.81$\improve{7.72} & $64.89$\improve{55.33} & $100.00$\improve{7.81} & $75.81$\improve{7.26} & $80.63$\improve{19.53}\\
         llama3-70B (CoT) & $69.11$ & $72.05$\worse{2.03} & $97.07$\improve{87.50} & $100.00$\improve{7.81} & $79.44$\improve{10.89} & $87.14$\improve{26.04}\\
         llama3-70B (SG) (Our) & $76.50$ & $78.21$\improve{4.12} & $97.61$\improve{88.04} & $100.00$\improve{7.81} & $72.18$\improve{3.63} & $87.00$\improve{25.90}\\
        % llama3-70B (0-shot) & $77.33$  & $35.04$ & $32.39$ & $57.81$ & $53.23$ & $44.62$\\
        %  llama3-70B (4-shot) & $59.78$ & $59.78$\improve{24.74} & $66.52$\improve{34.13} & $77.34$\improve{19.53} & $51.61$\worse{1.61} & $63.81$\improve{19.20}\\
        %  llama3-70B (CoT) & $66.00$  & $68.01$\improve{32.97} & $65.65$\improve{33.26} & $91.41$\improve{33.59} & $58.47$\improve{5.24} & $70.88$\improve{26.27}\\
        %  llama3-70B (SG) (Our) & $74.94$  & $78.17$\improve{43.13} & $70.87$\improve{38.48} & $100.00$\improve{42.19} & $84.27$\improve{31.05} & $83.33$\improve{38.71}\\
         \hline
         Qwen2-7B (0-shot) & $83.64$ & $79.97$ & $59.24$ & $77.34$ & $40.73$ & $64.32$\\
        Qwen2-7B (4-shot) & $61.12$ & $50.52$\worse{29.45} & $65.76$\improve{6.52} & $93.75$\improve{16.41} & $56.05$\improve{15.32} & $66.52$\improve{2.20}\\
        Qwen2-7B (CoT) & $72.12$ & $70.81$\worse{9.16} & $63.80$\improve{4.57} & $99.22$\improve{21.88} & $51.61$\improve{10.89} & $71.36$\improve{7.04}\\
        Qwen2-7B (SG) & $70.61$ & $68.00$\worse{11.98} & $71.20$\improve{11.96} & $88.28$\improve{10.94} & $57.26$\improve{16.53} & $71.18$\improve{6.86}\\
        \hline
        Qwen2-72B (0-shot)& $64.46$ & $62.70$ & $100.00$ & $100.00$ & $39.11$ & $75.45$\\
        Qwen2-72B (4-shot)& $79.12$ & $78.73$\improve{16.03} & $99.35$\worse{0.65} & $87.50$\worse{12.50} & $87.10$\improve{47.98} & $88.17$\improve{12.72}\\
        Qwen2-72B (CoT)& $88.54$ & $88.87$\improve{26.18} & $89.57$\worse{10.43} & $93.75$\worse{6.25} & $83.47$\improve{44.35} & $88.91$\improve{13.46}\\
        Qwen2-72B (SG)& $90.51$ & $90.18$\improve{27.49} & $93.26$\worse{6.74} & $98.44$\worse{1.56} & $85.08$\improve{45.97} & $91.74$\improve{16.29}\\
        \hline
         GPT3.5 (0-shot) & $83.11$ & $88.15$ & $17.50$ & $70.31$ & $41.13$ & $54.27$\\
         GPT3.5 (4-shot) & $61.25$  & $48.95$\worse{39.20} & $62.72$\improve{45.22} & $100.00$\improve{29.69} & $28.63$\worse{12.50} & $60.07$\improve{5.80}\\

         GPT3.5 (CoT) & $66.55$ & $66.62$\worse{21.53} & $96.85$\improve{79.35} & $100.00$\improve{29.69} & $50.81$\improve{9.68} & $78.57$\improve{24.30}\\
         GPT3.5 (SG) (Our) & $70.61$  & $73.30$\worse{14.86} & $92.93$\improve{75.43} & $99.22$\improve{28.91} & $49.19$\improve{8.06} & $78.66$\improve{24.39}\\
         \hline
         GPT4o (0-shot) & $73.82$  & $71.27$ & $98.80$ & $100.00$ & $70.56$ & $85.16$\\
         GPT4o (4-shot) & $66.23$  & $67.87$\worse{3.40} & $98.70$\worse{0.11} & $100.00$\improve{0.00} & $78.63$\improve{8.06} & $86.30$\improve{1.14}\\
         GPT4o (CoT) & $72.44$  & $72.77$\improve{1.51} & $100.00$\improve{1.20} & $100.00$\improve{0.00} & $73.79$\improve{3.23} & $86.64$\improve{1.48}\\
         GPT4o (SG) (Our) & $76.44$ & $74.67$\improve{3.40} & $97.72$\worse{1.09} & $100.00$\improve{0.00} & $68.55$\worse{2.02} & $85.23$\improve{0.08}\\
         \hline
    \end{tabular}
    \caption{Accuracy results report from FoR Identification with LLMs. The correct prediction is one of the valid FoR classes for the given spatial expression. All FoR classes are external relative (ER), external intrinsic (EI), internal intrinsic (II), and internal relative (IR).}
    \label{tab:text_experiment}
\end{table*}




\begin{figure*}[t]
    \centering
    \begin{subfigure}[ht]{0.4\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth, trim={0 0 0 2cm}]{Figures/A_cow_case.png}
        \caption{Results of Cow Case in A-Split. 
        % Valid predictions are external intrinsic and external relative.
        }
    \end{subfigure}%
    ~ 
    \begin{subfigure}[ht]{0.4\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth, trim={0 0 0 2cm}]{Figures/A_car_case.png}
        \caption{Results of Car Case in A-Split. 
        % All FoRs are valid predictions of this case.
        }
    \end{subfigure}
    
    \vskip\baselineskip
    
    \begin{subfigure}[ht]{0.4\textwidth}   
        \centering 
        \includegraphics[width=0.8\textwidth, trim={0 0 0 1cm}]{Figures/A_box_case.png}
        \caption{Results of Box Case in A-Split. 
        % The correct predictions are external relative and internal relative.
        }    
    \end{subfigure}
        ~
    \begin{subfigure}[ht]{0.4\textwidth}   
        \centering 
        \includegraphics[width=0.8\textwidth, trim={0 0 0 1cm}]{Figures/A_pen_case.png}
        \caption{Results of Pen Case in A-Split. 
        % The only applicable FoR is external relative.
        }  
    \end{subfigure}
    \caption{Red shows the wrong FoR identifications, and green shows the correct ones. The dark color is for relative FoRs, while the light color is for intrinsic FoRs. The round shape is for the external FoRs, while the square is for internal FoRs. The depth of the plots shows the four FoRs, i.e., \textit{external relative, external intrinsic, internal intrinsic, and internal relative}, \textbf{from front to back}.}
    \label{fig:cow_car_case}
\end{figure*}


\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=0.88\textwidth, trim={0 0 0 0}]{Figures/A_cow_case_s.png}
        \caption{Results of Cow Case in A-Split. 
        % Valid predictions are external intrinsic and external relative.
        }
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=0.88\textwidth, trim={0 0 0 0}]{Figures/A_car_case_s.png}
        \caption{Results of Car Case in A-Split. 
        % All FoRs are valid predictions of this case.
        }
    \end{subfigure}
    
    \vskip\baselineskip
    
    \begin{subfigure}[t]{0.4\textwidth}   
        \centering 
        \includegraphics[width=0.88\textwidth, trim={0 0 0 0}]{Figures/A_box_case_s.png}
        \caption{Results of Box Case in A-Split. 
        % The correct predictions are external relative and internal relative.
        }    
    \end{subfigure}
        ~
    \begin{subfigure}[t]{0.4\textwidth}   
        \centering 
        \includegraphics[width=0.88\textwidth, trim={0 0 0 0}]{Figures/A_pen_case_s.png}
        \caption{Results of Pen Case in A-Split. 
        % The only applicable FoR is external relative.
        }  
    \end{subfigure}
    \caption{Red shows the wrong FoR identifications, and green shows the correct ones. The dark color is for relative FoRs, while the light color is for intrinsic FoRs. The round shape is for the external FoRs, while the square is for internal FoRs. The depth of the plots shows the four FoRs, i.e., external relative, external intrinsic, internal intrinsic, and internal relative, from front to back. This plot is the result of the rest of LLMs.}
    \label{fig:cow_car_case2}
\end{figure*}

\subsection{Results}

\subsubsection{FoR Inherently Bias in LLMs} 
\noindent\textbf{C-spilt.}
The \textit{zero-shot} setting reflects the LLMs' inherent bias in identifying FoR.
Table~\ref{tab:text_experiment} presents the accuracy for each FoR class in C-split, where sentences explicitly include information about topology and perspectives.
We found that some models strongly prefer specific FoR classes.
Notably, Gemme2-9B achieves a near-perfect accuracy on external relative FoR but performs poorly on other classes, especially external intrinsic, indicating a notable bias towards external relative. 
In contrast, GPT4o and Qwen2-72B perform exceptionally in both intrinsic FoR classes. However, they perform poorly in the relative FoRs.

\noindent\textbf{A-spilt.}
We examine the FoR bias in the A-split.
Based on the results in Table~\ref{tab:text_experiment}, we plotted the top-3 models' results (Gemma2-9B, Llama3-70B, and GPT4o) for a more precise analysis in Figures~\ref{fig:cow_car_case}. 
The plots show the frequencies of each FoR category. 
According to the plot, Gemma and GPT have strong biases toward external relative and external intrinsic, respectively. 
This bias helps Gemma2 perform well in the A-split since all spatial expressions can be interpreted as external relative. 
However, GPT4o's bias leads to errors when intrinsic FoRs aren't valid, as in the Box and Pen cases (see plots (c) and (d)).
Llama3 exhibits different behavior, showing a bias based on the relatum’s properties, specifically the relatum's affordance as a container.
In cases where relatum cannot serve as containers, i.e., Cow and Pen cases, Llama3 favors external relative. 
Conversely, Llama3 tends to favor external intrinsic when the relatum has the potential to be a container.

\subsubsection{Behavior with ICL variations}\label{sec:result_A_ICL}

\noindent\textbf{C-spilt.}
We evaluate the models’ behavior under various in-context learning (ICL) methods.
As observed in Table~\ref{tab:text_experiment}, the \textit{few-shot} method improves the performance of the \textit{zero-shot} method across multiple LLMs by reducing their original bias toward specific classes. 
Reducing the bias, however, lowers the performance in some cases, such as the performance of Gemma 2 in ER class.
One noteworthy observation is that while the \textit{CoT} prompting generally improves performance in larger LLMs, it is counterproductive in smaller models for some FoR classes. 
This suggests that the smaller models have difficulty inferring FoR from the longer context. 
This negative effect also appears in SG prompting, which uses longer explanations.
Despite performance degradation in particular classes of small models, SG prompting performs exceptionally well across various models and achieves outstanding performance with Qwen2-72B. 
We further investigate the performance of CoT and SG prompting. 
As shown in Table~\ref{tab:model_performance}, CoT exhibits a substantial difference in performance between contexts with inherently clear FoR and contexts requiring the template to clarify FoR ambiguity.
This implies that CoT heavily relies on the specific template to identify FoR classes. 
In contrast, SG prompting demonstrates a smaller gap between these two scenarios and significantly enhances performance over CoT in inherently clear FoR contexts.  
Therefore, guiding the model to provide characteristics regarding topological, distance, and directional types of relations improves FoR comprehension.

\noindent\textbf{A-spilt.}
We use the same Figure~\ref{fig:cow_car_case} to observe the behavior when applying ICL. 
The A-split shows minimal improvement with ICL variations, though some notable changes are observed.
With \textit{few-shot}, all models show a strong bias toward external intrinsic FoR, even when the relatum lacks intrinsic directions, i.e., Box and Pen cases. 
This bias appears even in Gemma2-9B, which usually behaves differently. 
This suggests that the models pick up biases from the examples despite efforts to avoid such patterns.
However, \textit{CoT} reduces some bias, leading LLMs to revisit relative, which is generally valid across scenarios. 
In Gemma2, the model predicts relative FoR where the relatum has intrinsic directions, i.e., Cow and Car cases.
Llama3 behaves similarly in cases where the relatum cannot act as a container, i.e., Cow and Pen cases.
GPT4o, however, does not depend on the relatum's properties and shows slight improvements across all cases.
Unlike \textit{CoT}, our SG prompting is effective in all scenarios.
It significantly reduces biases while following a similar pattern to \textit{CoT}. 
Specifically, SG prompting increases external relative predictions for Car and Cow in Gemma2-9B, and for Cow and Pen in Llama3-70B.
Nevertheless, GPT4o shows only a slight bias reduction.
However, Our proposed method improves the overall performance of most models, as shown in Table~\ref{tab:text_experiment}. 
The Llama3-70B behaviors are also seen in LLama3-8B and GPT3.5. 
The plots for LLama3-8B and GPT3.5 are in Figure~\ref{fig:cow_car_case2}.

\subsubsection{Experiment with different temperatures}
We conducted additional experiments to further investigate the impact of temperature on the biased interpretation of the model in the A-split of our dataset.
As presented in Table~\ref{tab:temp_table}, comparing distinct temperatures (0 and 1) revealed a shift in the distribution. The frequencies of the classes experienced a change of up to 10\%.
However, the magnitude of this change is relatively minor, and the relative preferences for most categories remained unchanged.
Specifically, the model exhibited the highest frequency responses for the cow, car, and pen cases, even with higher frequencies in certain settings. Consequently, a high temperature does not substantially alter the diversity of LLMs’ responses to this task, which is an intriguing finding.

\begin{table*}[t]
    \tiny
    \centering
    \begin{tabular}{|l|c c |c c| c c | c c |}
    \hline
    Model & \multicolumn{2}{|c|}{ER} & \multicolumn{2}{|c|}{EI} & \multicolumn{2}{|c|}{II} & \multicolumn{2}{|c|}{IR} \\
    & temp-0 & temp-1 & temp-0 & temp-1 & temp-0 & temp-1 & temp-0 & temp-1 \\
    \hline
    \multicolumn{9}{| l |}{Cow Case} \\
    \hline
     0-shot   & 75.38 &  87.12 & 23.86 & 12.50 & 0.76 & 0.13 & 0.00 & 0.25\\ 
     4-shot   & 0.00 &  15.66 & 100.00 & 84.34 & 0.00 & 0.00 & 0.00 & 0.00\\
     CoT & 31.82 & 49.87 & 68.18 & 49.87 & 0.00 & 0.13 & 0.00 & 0.13 \\
     SG & 51.39 & 70.45 & 48.61 & 29.42 & 0.00 & 0.00 & 0.00 & 0.13\\
     \hline
     \multicolumn{9}{| l |}{Box Case} \\
     \hline
     0-shot   & 22.50 &  41.67 & 77.50 & 58.33 & 0.00 & 0.13 & 0.00 & 0.25\\ 
     4-shot   & 0.00 &  0.00 & 100.00 & 100.00 & 0.00 & 0.00 & 0.00 & 0.00\\
     CoT & 0.00 &  5.83 & 100.00 & 94.17 & 0.00 & 0.00 & 0.00 & 0.00\\
     SG & 11.67 &  33.33 & 88.33 & 66.67 & 0.00 & 0.00 & 0.00 & 0.00\\
     \hline
     \multicolumn{9}{| l |}{Car Case} \\
     \hline
     0-shot   & 55.20 & 68.24 & 49.01 & 31.15 & 0.79 & 0.61 & 0.00 & 0.00\\ 
     4-shot   & 0.60 &  5.94 & 99.40 & 94.06 & 0.00 & 0.00 & 0.00 & 0.00\\
     CoT & 19.64 &  38.52 & 80.16 & 61.27 & 0.20 & 0.20 & 0.00 & 0.00\\
     SG & 44.25 &  56.97 & 55.75 & 43.03 & 0.00 & 0.00 & 0.00 & 0.00\\
     \hline
     \multicolumn{9}{| l |}{Pen Case} \\
     \hline
     0-shot   & 90.62 & 96.88 & 9.38 & 3.12 & 0.00 & 0.61 & 0.00 & 0.00\\ 
     4-shot   & 0.00  &  7.03 & 100.00 & 92.97 & 0.00 & 0.00 & 0.00 & 0.00\\
     CoT & 17.19 &  28.91 & 82.81 & 71.09 & 0.20 & 0.20 & 0.00 & 0.00\\
     SG & 48.31 &  57.81 & 54.69 & 42.19 & 0.00 & 0.00 & 0.00 & 0.00\\
     \hline
    \end{tabular}
    \caption{The results between two different temperatures of Llam3-70B on the A-spilt of FoREST. The number shows the percentage frequency of responses from the model.}
    \label{tab:temp_table}
\end{table*}

\section{In-context learning}\label{appendix:in-context}
\subsection{FoR Identification}
We provide the prompting for each in-context learning. The prompting for \textit{zero-shot} and \textit{few-shot} is provided in Listing~\ref{lst:base_instruction}. The instruction answer for these two in-context learning is ``Answer only the category without any explanation. The answer should be in the form of \{Answer: Category.\}"

For the Chain of Thought (CoT), we only modified the instruction answer to ``Answer only the category with an explanation. The answer should be in the form of \{Explanation: Explanation Answer: Category.\}" 
Similarly to CoT, we only modified the instruction answer to ``Answer only the category with an explanation regarding topological, distance, and direction aspects. The answer should be in the form of \{Explanation: Explanation Answer: Category.\}", respectively. The example responses are provided in Listing~\ref{lst:example_answer} for Spatial Guided prompting.

\begin{lstlisting}[caption={Prompt for finding the frame of reference class of given context.}, label={lst:base_instruction}]
# Instruction to find frame of reference class of given context
"""
Instruction: 
You specialize in language and spatial relations, specifically in the frame of context (multiple perspectives in the spatial relation). Identify the frame of reference category given the following context. There are four classes of the frame of reference (external intrinsic, internal intrinsic, external relative, internal relative). Note that the intrinsic direction refers to whether the model has the front/back by itself. (Example: a bird, human. Counter Example: a ball, a box). "

External intrinsic. The spatial description of an entity A relative to another entity B, where (1) A is not contained by B, (2) the spatial relation is based on B's facing orientation (intrinsic direction) if B has one.

Internal intrinsic. The spatial description of an entity A relative to another entity B, where (1) A is contained by B, (2) the spatial relation is based on B's facing orientation (intrinsic direction) if B has one.

External relative. The spatial description of an entity A relative to another entity B, where (1) A is not contained by B, (2) The spatial relation is relative to entity C, where C is not involved in the spatial relation and only provides the perspective. An example of C is the camera.

Internal relative. The spatial description of an entity A relative to another entity B, where (1) A is contained by B, (2) The spatial relation is relative to entity C, where C is not involved in the spatial relation and only provides the perspective. An example of C is the camera.

{Instruction answer}
# Normal Instruction answer: Find the frame of reference category without any explanations. The answer should be in the form of Answer: Category.
# COT Instruction answer: Find the frame of reference category with an explanation. The answer should be in the form of Explanation: Explanation. Answer: Category.
# SG Instruction answer: Find the frame of reference category with an explanation. Additionally, include three more explanations relating to topology, distance, and direction from the given context. The answer should be in the form of \"Explanation: Explanation. Topology: Explanation. Distance: Explanation. Direction: Explanation. Answer: Category.

Context: {spatial exprssion}
"""

\end{lstlisting}

\begin{lstlisting}[caption={Spatial expression examples using for few-shots, Chain-of-Thought (CoT), and Spatial Guide (SG) prompting}, label={lst:example_answerQA}]
## These are four examples used in few-shot, CoT, and SG
# Example 1: The bird is outside the car and in front of the car relative to the car.
# Few-shot response: Answer: external intrinsic
# CoT response: Explanation: The car does not contain the bird, and the spatial relation is relative to the car's facing orientation. The intrinsic direction of the car is relevant in this context, as the description \"in front of\" implies a direction relative to the sheep's front or back. Answer: external intrinsic.
# SG response: Explanation: The car does not contain the bird, and the spatial relation is relative to the car's facing orientation. The intrinsic direction of the car is relevant in this context, as the description \"in front of\" implies a direction relative to the sheep's front or back. Topology: The bird is outside the car. Distance: There is little distance between the bird and the car. Direction: The bird is in the front direction of the car (entity B). Answer: external intrinsic.

# Example 2: The bird is inside of the car and left of the car from the car's perspective.
# Few-shot response: Answer: internal intrinsic
# CoT response: Explanation: In this scenario, the bird is contained within the car, meaning it is an internal relationship. Additionally, the description specifies the bird's position relative to the car, indicating that the spatial relation is relative to the car itself, considering its intrinsic direction. Answer: internal intrinsic.
# SG response:  Explanation: In this scenario, the bird is contained within the car, meaning it is an internal relationship. Additionally, the description specifies the bird's position relative to the car, indicating that the spatial relation is relative to the car itself, considering its intrinsic direction. Topological: The bird is inside the car. Distance: The bird is in the same location as the car. Direction: The bird is in the left direction of the car (entity B). Answer: internal intrinsic.

# Example 3: The box is inside and at the back of the room.
# Few-shot response: Answer: internal relative
# CoT response: Explanation: In this context, the box (entity A) is described as inside the room (entity B), fulfilling the first condition for an internal frame of reference. However, the spatial relation given (\" at the back\") cannot originate from the room since the room does not have intrinsic direction, implying it is relative to an external observer or reference point (C), such as a camera or a person viewing the scene. Answer: internal relative
# SG response:  Explanation: In this context, the box (entity A) is described as inside the room (entity B), fulfilling the first condition for an internal frame of reference. However, the spatial relation given (\" at the back\") cannot originate from the room since the room does not have intrinsic direction, implying it is relative to an external observer or reference point (C), such as a camera or a person viewing the scene. Topological: The box is inside the room. Distance: The box is in the same location as the room. Direction: From the observer's perspective, the box is located at the back of the room. Answer: internal relative

# Example 4: A phone is on the left of a tablet from my perspective.
# Few-shot response: Answer: external relative
# CoT response: Explanation: In this context, the spatial relation is described from the perspective of an observer (C) who is not involved in the spatial relation. The phone (A) is not contained by the tablet (B), and the spatial relation \"left of\" is relative to the observer's perspective, not the tablet's facing orientation. Answer: external relative.
# SG response:  Explanation: In this context, the spatial relation is described from the perspective of an observer (C) who is not involved in the spatial relation. The phone (A) is not contained by the tablet (B), and the spatial relation \"left of\" is relative to the observer's perspective, not the tablet's facing orientation. Topological: The phone is not contained by the tablet. Distance: There is some distance between the phone and the tablet. Direction: From the observer's perspective, the phone is located to the left of the tablet. Answer: external relative.
\end{lstlisting}

\subsection{Question Answering Example}\label{appendix:QA_example}


\begin{lstlisting}[caption={Spatial expression examples using for few-shots, Chain-of-Thought (CoT), and Spatial Guide (SG) prompting for question-answering.}, label={lst:example_answerQA}]
'''
#Context: The bird is outside the car and in front of the car relative to the car. The car is facing toward the camera. 
#Question: Based on the camera's perspective, where is the bird from the car position in the scene? 
#SG information (used in SG + CoT): Frame of reference Explanation: The car does not contain the bird, and the spatial relation is relative to the car's facing orientation. The intrinsic direction of the car is relevant in this context, as the description \"in front of\" implies a direction relative to the sheep's front or back. Topology: The bird is outside the car. Distance: There is little distance between the bird and the car. Direction: The bird is in the front direction of the car (entity B). Frame of reference: external intrinsic.
#Normal response: Answer: front
#CoT / (SG + COT) response:Explanation: Based on the context, the bird's position is in the front direction of the car. The car is facing toward the camera. Then, the car's front direction is the camera's front direction. Therefore, the bird's position is in front of the car's position from the camera's perspective. Answer: front

#Context: The bird is inside the car and left of the car from the car's perspective. The car is facing to the right relative to the camera.  #Question: Based on the camera's perspective, where is the bird from the car's position?
#SG information (used in SG + CoT):  Frame of reference Explanation: In this scenario, the bird is contained within the car, meaning it is an internal relationship. Additionally, the description specifies the bird's position relative to the car, indicating that the spatial relation is relative to the car itself, considering its intrinsic direction. Topological: The bird is inside the car. Distance: The bird is in the same location as the car. Direction: The bird is in the left direction of the car (entity B). Frame of reference: internal intrinsic.
#Normal response: Answer: back
#CoT / (SG + COT) response: Explanation: Based on the context, the bird's position is in the left direction of the car. The car is facing to the right. Then, the car's left direction is the camera's back direction. Therefore, the bird's position is to the back of the car's position from the camera's perspective. Answer: back

Context: The box is inside and to the right of the room from the observer's perspective. 
Question: From the observer's perspective, what is the spatial relation of the box to the room? 
#SG information (used in SG + CoT): Frame of reference Explanation: In this context, the box (entity A) is described as inside the room (entity B), fulfilling the first condition for an internal frame of reference. However, the spatial relation given (\" at the back\") cannot originate from the room since the room does not have intrinsic direction, implying it is relative to an external observer or reference point (C), such as a camera or a person viewing the scene. Topological: The box is inside the room. Distance: The box is in the same location as the room. Direction: From the observer's perspective, the box is located at the back of the room. Frame of reference: internal relative.
#Normal response: Answer: right
#CoT / (SG + COT) response: Explanation: Based on the context, the box is to the right of the room from the camera's direction. Therefore, the box's position is to the right of the room's position from the observer's perspective. Answer: right

Context: A phone is to the left of a tablet from my perspective. The tablet is facing to the right. Question: From my perspective, what is the spatial relation of the phone to the tablet?
#SG information (used in SG + CoT): Frame of Reference Explanation: In this context, the spatial relation is described from the perspective of an observer (C) who is not involved in the spatial relation. The phone (A) is not contained by the tablet (B), and the spatial relation \"left of\" is relative to the observer's perspective, not the tablet's facing orientation. Topological: The phone is not contained by the tablet. Distance: There is some distance between the phone and the tablet. Direction: From the observer's perspective, the phone is located to the left of the tablet. Frame of Reference: external relative.
#Normal response: Answer: left
#CoT / (SG + COT) response: Explanation: Based on the context, the phone is to the left of the tablet from my perspective. The direction of the tablet is not relevant in this context since the left relation is from my perspective. Therefore, from my perspective, the phone is to the left of the tablet. Answer: left
'''
\end{lstlisting}

\subsection{Text to Layout}
\begin{lstlisting}[caption={Prompt for generating bounding coordinates to use as the layout for layout-to-image models.}, label={lst:example_answer}]
    # Instruction for generating bounding box
"""
Your task is to generate the bounding boxes of objects mentioned in the caption.
The image is size 512x512. The bounding box should be in the format of (x, y, width, height). Please considering the frame of reference of caption and direction of reference object if possible. If needed, you can make the reasonable guess.
"""
\end{lstlisting}







 