[
  {
    "index": 0,
    "papers": [
      {
        "key": "pryzant2023automatic",
        "author": "Pryzant, Reid and Iter, Dan and Li, Jerry and Lee, Yin Tat and Zhu, Chenguang and Zeng, Michael",
        "title": "Automatic prompt optimization with\" gradient descent\" and beam search"
      },
      {
        "key": "li2024promptist",
        "author": "Li, WeiJie and Wang, Jin and Zhang, Xuejie",
        "title": "PROMPTIST: Automated Prompt Optimization for Text-to-Image Synthesis"
      },
      {
        "key": "kepel2024autonomous",
        "author": "Kepel, Daan and Valogianni, Konstantina",
        "title": "Autonomous prompt engineering in large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "shinn2023reflexion",
        "author": "Shinn, Noah and Cassano, Federico and Berman, Edward and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu",
        "title": "Reflexion: Language Agents with Verbal Reinforcement Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "nori2023generalist",
        "author": "Harsha Nori and Yin Tat Lee and Sheng Zhang and Dean Carignan and Richard Edgar and Nicolo Fusi and Nicholas King and Jonathan Larson and Yuanzhi Li and Weishung Liu and Renqian Luo and Scott Mayer McKinney and Robert Osazuwa Ness and Hoifung Poon and Tao Qin and Naoto Usuyama and Chris White and Eric Horvitz",
        "title": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "nori2023generalist",
        "author": "Harsha Nori and Yin Tat Lee and Sheng Zhang and Dean Carignan and Richard Edgar and Nicolo Fusi and Nicholas King and Jonathan Larson and Yuanzhi Li and Weishung Liu and Renqian Luo and Scott Mayer McKinney and Robert Osazuwa Ness and Hoifung Poon and Tao Qin and Naoto Usuyama and Chris White and Eric Horvitz",
        "title": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "khattab2023dspy",
        "author": "Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and others",
        "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "maharjan2024openmedlm",
        "author": "Maharjan, Jaya and Garikipati, Anusha and Singh, N. P. and others",
        "title": "OpenMedLM: Prompt Engineering Can Out-Perform Fine-Tuning in Medical Question-Answering with Open-Source Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "01ai2024yi",
        "author": "{01.AI}",
        "title": "Yi: Open Foundation Models by 01.AI"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "pal2022medmcqa",
        "author": "Pal, Ankit and et al",
        "title": "MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yuksekgonul2024textgrad",
        "author": "Yuksekgonul, Mert and Bianchi, Federico and Boen, Joseph and Liu, Sheng and Huang, Zhi and Guestrin, Carlos and Zou, James",
        "title": "TextGrad: Automatic \"Differentiation\" via Text"
      }
    ]
  }
]