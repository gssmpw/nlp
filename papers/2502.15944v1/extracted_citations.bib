@article{01ai2024yi,
  author = {{01.AI}},
  title = {Yi: Open Foundation Models by 01.AI},
  journal = {arXiv preprint arXiv:2403.04652},
  year = {2024},
  month = {mar},
  eprint = {2403.04652},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG}
}

@article{kepel2024autonomous,
  title={Autonomous prompt engineering in large language models},
  author={Kepel, Daan and Valogianni, Konstantina},
  journal={arXiv preprint arXiv:2407.11000},
  year={2024}
}

@article{khattab2023dspy,
  title={DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023},
  doi={10.48550/arXiv.2310.03714}
}

@inproceedings{li2024promptist,
  title={PROMPTIST: Automated Prompt Optimization for Text-to-Image Synthesis},
  author={Li, WeiJie and Wang, Jin and Zhang, Xuejie},
  booktitle={CCF International Conference on Natural Language Processing and Chinese Computing},
  pages={295--306},
  year={2024},
  organization={Springer}
}

@article{maharjan2024openmedlm,
  title={OpenMedLM: Prompt Engineering Can Out-Perform Fine-Tuning in Medical Question-Answering with Open-Source Large Language Models},
  author={Maharjan, Jaya and Garikipati, Anusha and Singh, N. P. and others},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={14156},
  year={2024},
  doi={10.1038/s41598-024-64827-6}
}

@article{nori2023generalist,
  author    = {Harsha Nori and Yin Tat Lee and Sheng Zhang and Dean Carignan and Richard Edgar and Nicolo Fusi and Nicholas King and Jonathan Larson and Yuanzhi Li and Weishung Liu and Renqian Luo and Scott Mayer McKinney and Robert Osazuwa Ness and Hoifung Poon and Tao Qin and Naoto Usuyama and Chris White and Eric Horvitz},
  title     = {Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine},
  journal   = {Microsoft Research},
  year      = {2023},
  url       = {https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/}
}

@article{pal2022medmcqa,
  title={MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author={Pal, Ankit and et al},
  journal={arXiv preprint arXiv:2203.14371},
  year={2022},
  eprint={2203.14371},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@article{pryzant2023automatic,
  title={Automatic prompt optimization with" gradient descent" and beam search},
  author={Pryzant, Reid and Iter, Dan and Li, Jerry and Lee, Yin Tat and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2305.03495},
  year={2023}
}

@article{shinn2023reflexion,
  title={Reflexion: Language Agents with Verbal Reinforcement Learning},
  author={Shinn, Noah and Cassano, Federico and Berman, Edward and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023},
  url={https://doi.org/10.48550/arXiv.2303.11366}
}

@article{yuksekgonul2024textgrad,
  title={TextGrad: Automatic "Differentiation" via Text},
  author={Yuksekgonul, Mert and Bianchi, Federico and Boen, Joseph and Liu, Sheng and Huang, Zhi and Guestrin, Carlos and Zou, James},
  journal={arXiv preprint arXiv:2406.07496},
  year={2024},
  url={https://doi.org/10.48550/arXiv.2406.07496}
}

