\section{Experiments}
\subsection{Experiment dataset} 
\noindent\textbf{Training dataset.} We adopt a large-scaled synthetic dataset GSO~\cite{suresh2023midastouch, labbe2022megapose} to train our model. The synthetic GSO dataset consists of 1000 3D objects and 1 million synthetic RGB-D images with randomly placed objects.

\noindent\textbf{Test dataset.} 
To test the performance in object pose estimation in real-world bin-picking scenes, we adopt the large real-world bin-picking dataset ROBI~\cite{robi} as our test dataset for evaluation. 
This dataset contains seven reflective and texture-less metal objects made from different materials and includes 14 bin-picking test scenes.
These scenes are specifically designed to represent the most challenging scenarios in bin-picking tasks, with up to 38 target instances stacked in a bin.
For each scene, an RGB-D camera captures images from multiple viewpoints, resulting in a total of 1,218 test images with over 20,000 object instances in various poses.

\subsection{Implement details} 
\noindent\textbf{Loss function.} We follow ZeroPose~\cite{chen2023zeropose} and select the overlap-aware circle loss~\cite{qin2023geotransformer}, to optimize the learning PAC on superpoints and negative log-likelihood loss to optimize the learning PAC on points. To enhance correspondence learning in stacked modules, we also optimize the intermediate layer correspondence as an additional loss.

\vspace{1mm}
\noindent\textbf{Model architecture.}
\note{For fairly compared with the baseline model~\cite{chen2023zeropose}, we keep the same network layers $N=3$ in both superpoints and point correspondence learning.
As early experiments and visualization in Fig.~\ref{fig:vis_layers}, the correspondence can effectively converge with three times alternate refinement.
}

\vspace{1mm}
\noindent\textbf{Correspondences selection.}
\note{We select the superpoint pairs with the top $K=256$ feature similarities as the superpoint correspondences. For point correspondences, we adopt the hypothesis-and-verify approach~\cite{qin2023geotransformer} to estimate the correspondences. This method separately estimates the point correspondences within each superpoint pair to generate pose hypotheses. By transforming all CAD points using these pose hypotheses, point pairs with close distances are considered as the point correspondence. Point correspondences having the largest number in hypotheses are chosen in the final.
}

% 
\subsection{Evaluation metrics} 
We follow \cite{st6deccv, MVBPICRA, dcnet} to select the common average recall (AR) of the ADD(-S) metric~\cite{add} to evaluate the pose estimation performance. This metric evaluates the average point cloud distance between the CAD model transformed by the predicted pose and the ground-truth pose whether smaller than 10\% of the object diameter. 

\input{tables/abalation_pe}
\begin{figure}[t!]
    \centering
    \includegraphics[width=0.49 \textwidth]{figures/fig3.jpg}
    \caption{Visualizations of correspondences in layers.}
    \label{fig:vis_layers}
    \vspace{-3mm}
\end{figure}

\subsection{Comparison with state-of-the-art methods}
\noindent\textbf{Quantitative results.}
We compared our model with the baseline ZeroPose~\cite{chen2023zeropose}, and the state-of-the-art zero-shot 6D pose estimation method SAM6D~\cite{sam6d}.
Besides, we also compare with object-specific methods, which need days to generate synthetic data of test objects and retrain the model.
As shown in Table~\ref{tab:robi}, our method outperforms state-of-the-art zero-shot pose estimation methods. Compared with the baseline, it achieves an improvement of 16.4\% in average recall of correct poses.
\noteb{In comparison to object-specific models that have been trained on the test objects, our ZeroBP without seeing these objects during training achieves remarkable performance. While there is still a performance gap, our ZeroBP showcases great potential to narrow the gap.} This generalization capability makes our method a promising alternative to object-specific approaches in real-world bin-picking tasks with faster deployment time and lower deployment cost.

\vspace{1mm}
\noindent\textbf{Qualitative results.}
Fig.~\ref{fig:vis_robi} visualize the 6D pose estimation results of the baseline ZeroPose~\cite{chen2023zeropose} and our method.
For evaluation, we reproject objects into the scene image by the estimated poses and visualize the masks in the top part and the depth error in the bottom part.
To mitigate the impact of potential bias introduced by different segmentation results, we adopt ground truth segmentation results for fair comparison.
As shown in Fig.~\ref{fig:vis_robi}, ZeroPose often leads to significant pose estimation errors in bin-picking objects due to the mismatching in ambiguous regions. Our learning-based PAC method effectively addresses mismatching issues, improving the accuracy of pose estimation.




\subsection{Ablation studies}
We perform ablation studies to analyze our positional encoding strategies and network design. Following~\cite{gcpose}, we conduct the experiments using ground truth masks to eliminate the impact of potential bias in segmentation masks.


\vspace{1mm}
\noindent\textbf{Positional encoding strategies.}
As presented in Tab.~\ref{tab:aba1_pe_methods}, we compare different positional encoding strategies for cross-attention. 
%
\note{We first select vanilla 3D coordinate positional encoding in cross-attention to distinguish ambiguous regions, which results in a 10.9\% performance gain, demonstrating the effectiveness of positional encoding in heterogeneous feature cross-attention.
The alternate refinement can refine the coordinates and provide an additional 2\% performance improvement.
Benefiting from the natural angle constraint in vector multiplication, the proposed directional vector positional encoding shows the highest AR score 55.7\% and 19.3\% performance gain, demonstrating its effectiveness.}

\vspace{1mm}
\noindent\textbf{Network design.}
As presented in Tab.~\ref{tab:aba_scale}, we compare the pose estimation precision, network parameter size, and runtime at each instance when integrating learning PAC on superpoints and points.
After separately conducting learning PAC on superpoints and points, the AR scores respectively increased by 13.8\% and 8.4\%. When combined together, the AR further improved showing a 19.5\% performance gain.
Notably, the learning-based PAC introduces only a few linear layers for positional embedding, resulting in minimal impact on network speed and parameter size.

\vspace{1mm}
\noindent\textbf{Correspondence alternate refinement in layers.}
\note{Fig.~\ref{fig:vis_layers} shows the visualizations of superpoint correspondences across different layers. 
With the alternate refinement with layers, there is a clear improvement in the precision of the correspondences, starting from 43\% to 100\%. 
The initial correspondences from backbone features show many mismatches within ambiguity regions, indicated by the red lines. With alternate refinement in layers by proposed learning PAC, the number of correct correspondences (green lines) improves significantly, demonstrating its effectiveness.}

\section{Conclusion}
\label{sec:conclusion}
The paper introduces a zero-shot 6D pose estimation method for bin-picking, which learns robust position-aware correspondence between the scene instance and the CAD model to alleviate mismatch in ambiguous regions of textureless bin-picking workpieces.
Thanks to the robust position-aware correspondences, our method offers promising performance in bin-picking scene object pose estimation and strong generalization capability, highlighting its significant potential for more bin-picking applications.  
