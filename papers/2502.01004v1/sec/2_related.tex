
\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.975 \textwidth]{figures/fig2v5.jpg}
    \caption{Overview of learning Position-Aware Correspondence (PAC) for zero-shot 6D pose estimation in bin-picking. \noteb{We introduce the globally positional encoding and position-aware cross-attention modules to learn robust PAC, alleviating the mismatch issue in textureless bin-picking workpieces. Overall, we adopt a coarse-to-fine strategy to establish the correspondence from superpoints to points.}}
    \label{fig:overall_framwork}
    \vspace{-2mm}
\end{figure*}

\vspace{-1mm}
\section{Related Work}
\label{sec:related work}
\subsection{Object-specific 6D pose estimation models in bin-picking}
Compared with the general household object pose estimation, the bin-picking objects are often manufactured workpieces, which lack sufficient texture and stacking in a bin.
To estimate their poses, existing methods~\cite{kleeberger2020single, aae,dcnet,mpaae,miretr, MVBPICRA, uni6dv2, chen2023geo6d, pprnet} usually prepare training data for training an object-specific model for pose estimation.
However, these training data are expensive to prepare and annotate 6D poses.
To solve that, current methods~\cite{st6deccv, ST6DICRA} introduce a domain adaptation strategy, named sim2real. This sim2real strategy enables the model training on the synthetic images of target objects and uses the real-world unannotated images for fine-tuning in a self-supervised manner. However, although it reduces the deployment cost in data preparation, the model still has an expensive deployment in training the model when an unseen object coming.
Such an expensive and time-consuming deployment process limits the practical application of these approaches.
\subsection{Zero-shot 6D pose estimation models}
Recent works~\cite{chen2023zeropose, sam6d, nguyen2024gigapose, ornek2023foundpose, FoundationPose, shugurov2022cvpr:osop, gcpose, ausserlechner2023zs6d, park2020latentfusion} demonstrate the strong generalization capability for zero-shot 6D pose estimation in household objects and scenes.
After the pertaining on the seen objects, the zero-shot model can generalize to novel unseen objects without retraining the model.
%
These methods~\cite{chen2023zeropose,sam6d, nguyen2024gigapose, ornek2023foundpose, shugurov2022cvpr:osop} estimate the pose by matching the visual features in objects from the scene image and the template images rendered from the CAD model. 
For the manufactured target objects in bin-picking, which lack sufficient texture and contain ambiguous local regions with the same structure and appearance, these zero-shot methods usually suffer from mismatching and fail to estimate the pose accurately. Therefore, existing zero-shot methods still cannot be effectively applied to the bin-picking task.


\subsection{Positional encoding}
Positional encoding is a crucial component in feature extraction and interaction networks~\cite{vaswani2017attention, liu2022petr, pointnet, pointnet++, qin2023geotransformer}. It embeds positional information into features, allowing for feature attention with positional constraints. However, the existing positional encoding strategies are typically designed for the homogeneous source input. When processing heterogeneous source feature attention, they primarily rely on feature similarity without incorporating positional encoding. 
This makes the attention mechanism unreliable in features with insufficient discriminative, ultimately leading to a failure in estimating correct correspondence through feature matching.