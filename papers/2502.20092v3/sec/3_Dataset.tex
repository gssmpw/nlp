\section{WalnutData Construction}
\begin{table*}
	\caption{The detailed data of the walnut sample plots in this study. A total of 8 sample plots were selected, all of which are located in Yangbi County, Dali Bai Autonomous Prefecture, Yunnan Province, China. The shooting dates are between July 18 and September 14, 2024. In order to capture the changes in lighting conditions, the shooting time was chosen between 9:00 and 19:00. At the same time, in order to minimize the impact on the quality of the images collected by the sensor as much as possible, we set the flight altitude between 12 and 30 meters.}
	\label{tab:Table_3}
	\centering
	\begin{tabular}{lcccccccc}
		\toprule
		\multirow{2}{*}{Sample Number} & \multirow{2}{*}{Altitude Range (m)} & \multicolumn{2}{c}{Geographical Coordinates} & \multirow{2}{*}{Flight Altitude (m)} & \multirow{2}{*}{GSD (cm/pixel)} & \multirow{2}{*}{Date} & \multirow{2}{*}{Time} & \multirow{2}{*}{Images} \\
		\cmidrule(lr){3-4}
		& & E & N & & & & & \\
		\midrule
		1 & 2031.48-2033.77 & 100°0'25.600" & 25°40'9.077" & 25 & 0.31 & 2024/7/18 & 9:49 & 251 \\
		2 & 2062.44-2068.22 & 100°1'37.681" & 25°40'47.933" & 12 & 0.15 & 2024/7/18 & 11:20 & 3703 \\
		3 & 1871.56-1882.45 & 100°1'29.779" & 25°36'37.303" & 15 & 0.19 & 2024/8/31 & 10:54 & 828 \\
		4 & 1905.41-1905.47 & 100°1'14.148" & 25°36'54.632" & 20 & 0.25 & 2024/8/30 & 18:25 & 656 \\
		5 & 2339.12-2339.73 & 99°52'6.610" & 25°36'28.995" & 25 & 0.31 & 2024/7/20 & 16:03 & 691 \\
		6 & 2092.40-2096.17 & 99°48'29.425" & 25°38'15.829" & 20 & 0.25 & 2024/9/1 & 10:00 & 1503 \\
		7 & 2131.30-2131.38 & 100°1'53.728" & 25°40'18.837" & 30 & 0.38 & 2024/9/13 & 10:05 & 236 \\
		8 & 2045.32-2064.72 & 100°1'43.099" & 25°40'8.263" & 30 & 0.38 & 2024/9/14 & 11:04 & 1531 \\
		\bottomrule
	\end{tabular}
\end{table*}

\subsection{Data Collection}
We carried out data collection on 8 walnut sample plots between July 18 and September 14, 2024. These sample plots are all located in Yangbi County, Dali Bai Autonomous Prefecture, Yunnan Province, China. In addition, in order to capture the changes in lighting conditions, we conducted the shooting between 9:00 and 19:00. The data collection equipment used uniformly was a DJI Matrice 300 RTK UAV and a Zenmuse P1 (35mm F2.8) lens. The UAV took photos from a top-down angle (-90°) along the pre-planned flight path throughout the process, and the flight path fully covered the scope of each sample plot. To reduce the impact of too high a flight altitude and too fast camera movement on the imaging quality, and while ensuring flight safety, we set the flight speed between 1-3 m/s and the flight altitude between 12-30 m. The information of the walnut sample plots selected in this study is shown in Table~\ref{tab:Table_3}.

Finally, we set the overlap rate of the UAV flight paths to be all above 70\%. A total of 9,399 images were collected from the 8 walnut sample plots. 
\subsection{Dataset Construction}
Setting the overlap rate of the flight paths above 70\% can ensure that certain contents will not be missed during shooting. However, this will cause the UAV to capture similar areas during the data collection task, resulting in the situation where the same walnut tree appears in multiple aerial images. In order to avoid a large amount of duplicate content in the final dataset, we organized multiple members to carefully screen the aerial images of each walnut sample plot at the same time, so as to achieve the situation where there are almost no overlapping areas in the selected images.

Since the resolution of the UAV aerial images (8,192×5,460 pixels) is too large, which is not conducive to the training of the model, in this study, the selected original images were all cut with a step size of 512. The resolution of the cut images is 1,024×1,024 pixels. After the processing of the above steps, the dataset of this study was finally formed, with a total of 30,240 images.

\subsection{Data Annotation}
In this study, four label categories were defined: A1 (frontal light without occlusion), A2 (backlight without occlusion), B1 (frontal light with occlusion), and B2 (backlight with occlusion). The Labelme annotation tool was used to manually annotate the dataset, and the annotation format is bounding box. During this work process, we organized multiple members to spend about 3 months on data annotation, and finally obtained 24,673 labels.

\subsection{Dataset Split}
According to the way accepted by the current mainstream object detection models, we divided the dataset into a Train, a Val, and a Test. The ratio of the Train, the Val, and the Test is 7:2:1, with 21,167 images, 6,048 images, and 3,025 images respectively. In addition, in the arrangement of the distribution of the number of categories, we tried our best to ensure the similarity and balance of the distribution. The distribution information of category instances after the dataset partition is shown in Fig.~\ref{fig:Instance Distribution Information after Dataset Division}. We will release the Train and the Val containing label annotations. At the same time, the Test will also be provided to researchers for evaluating their own models, but the label annotations of the Test images will not be provided.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.9\linewidth]{Fig/Instance_Distribution_Information_after_Dataset_Division.pdf}
	\caption{The proportion information of the number of instances in each category after the dataset is partitioned. The proportions of the numbers of A1, B1, B2, and A2 instances are similar in the Train, the Val, and the Test respectively.}
	\label{fig:Instance Distribution Information after Dataset Division}
	%\vspace{-5pt}
\end{figure}
\subsection{Dataset Analysis}
We have counted the number of instances and the average number of instances in WalnutData (Table~\ref{tab:Table_4}). The average number of targets per image in the Training, the Val, and the Test is approximately 23.353.

\setlength{\tabcolsep}{8pt} 
\begin{table}[htbp]
	\centering
	\caption{The distribution of the number of instances in WalnutData and the average number of bounding boxes per image. BBox is the abbreviation of Bounding Box, and Avg. BBox quantity represents the average number of bounding boxes per image.}
	\label{tab:Table_4}
	\begin{tabular}{lccc}
		\toprule
		Name & Image quantity & BBox quantity & Avg. BBox quantity \\
		\midrule
		Train & 21,167 & 495,812 & 23.424 \\
		Val & 6,048 & 139,255 & 23.025 \\
		Test & 3,025 & 71,141 & 23.518 \\
		\bottomrule
	\end{tabular}
\end{table}

We analyzed the lighting conditions of the green walnut fruits in WalnutData. Since the lighting conditions of the non-target backgrounds around the green walnut fruits are almost similar, we first extracted the pixels of the images within the instance rectangular boxes. Then, we converted the RGB images into grayscale images and calculated the average grayscale value to analyze the lighting intensity received by the green walnut fruits. The distribution of the average grayscale values of each instance in the Train, the Val, and the Test is shown in Fig.~\ref{fig:Grayscale value information}. The average grayscale values of the Train, the Val, and the Test are 107.316, 108.048, and 107.544 respectively. The proportions of values lower than the intermediate grayscale value of 127.5 are 76.31\%, 75.59\%, and 75.81\% respectively. This indicates that most of the green walnuts in WalnutData are in backlight conditions or are shaded by leaves in relatively dark places. 

\begin{figure}
	\centering
	\includegraphics[width=1.05\linewidth]{Fig/Grayscale_value_information.pdf}
	
	\caption{The distribution of the average grayscale values of each instance in the Train, the Val, and the Test. (a), (b), and (c) are the statistics of the grayscale values of each instance in the Train, the Val, and the Test respectively. Among them, 76.31\%, 75.59\%, and 75.81\% of the instances in the Train, the Val, and the Test respectively have grayscale values lower than the median grayscale value (127.5), indicating that more than half of the green walnuts in WalnutData receive less light. }
	\label{fig:Grayscale value information}
	%\vspace{-5pt}
\end{figure}

In addition, according to the definition of large (pixel\textgreater96), medium (96\textgreater pixel\textgreater32), and small (32\textgreater pixel) targets in the COCO dataset~\cite{lin2014microsoft}, we counted the quantity distribution of large, medium, and small targets in WalnutData (Table~\ref{tab:Table_5}). In WalnutData, the proportion of medium and small targets is higher, which is in line with the morphological characteristics of green walnut fruits from the perspective of a UAV. Therefore, the model trained on WalnutData can better adapt to the distribution of target sizes in practical application scenarios. 

\setlength{\tabcolsep}{15pt} 
\begin{table}[htbp]
	\centering
	\caption{Quantity distribution of large, medium and small targets in WalnutData.}
	\label{tab:Table_5}
	\begin{tabular}{lccc}
		\toprule
		Name & Large & Medium & Small \\
		\midrule
		Train & 526 & 211,669 & 283,617 \\
		Val & 175 & 59,371 & 79,709 \\
		Test & 74 & 30,047 & 41,020 \\
		\bottomrule
	\end{tabular}
\end{table}



