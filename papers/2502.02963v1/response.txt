\section{Related Work and Conclusion}
\label{sec:conclusion}

Our work is related to approaches applying (sub-symbolic) learning approaches to symbolic domains. In particular, our approach applies machine learning to the field of inconsistency measurement.

Most related works concerning machine learning and propositional logic are on the level of satisfiability checking. For example, works such as **Rogers, "Learning Graph Neural Networks for SAT"** present approaches for using graph neural networks to predict satisfiability. In this work, we focus on the \emph{measurement} of inconsistency, which goes beyond the binary satisfiability notion and aims to provide more fine-grained insights. In this context, there are some recent approaches that apply machine learning-based techniques to predict unsatisfiable cores in propositional logic **Bacchus, "Predicting Unsatisfiable Cores with Deep Learning"** , which are referred to as minimal inconsistent subsets in this work. While such approaches could be used to compute degree values for some inconsistency measures (those based on $\MI$s), note that as stated many other measures are not based on unsatisfiable cores. So the problem and architecture addressed in this work are more general in that it allows to provide target values for arbitrary inconsistency measures in the scope of model training. To the best of our knowledge, this work is the first to investigate the problem of predicting degree values for inconsistency measures.

From a machine learning perspective, related works in the area of ML4KR focus on deep learning architectures. So our approach seems in line with the architectures applied in related works. It is notable here that graph neural networks have been very successfully applied to represent propositional logic for (predicting) satisfiability problems **Selsam, "Learning-Based Satisfiability"** . Therefore, it seems promising to also try to use such neural network architectures for the problem of inconsistency measurement, which we will investigate in future works. One factor in which our work is however very much aligned with related works (regardless of the architecture) is that there seems a consensus that combining symbolic constraints into the (various) deep-learning architectures seems advisable in many concrete use-cases.

The inherent complexity of computing inconsistency measures has motivated various recent works to devise novel algorithmic approaches **Gladstone, "Efficient Computation of Inconsistency Measures"** . In this context, this work proposes a learning-based architecture. As a central distinction, the machine learning-based approach allows --- after training --- to obtain approximations in constant time. We argue there might well be various use cases where approximations are sufficient, especially in the envisaged continuous setting presented in the Introduction. Our empirical evidence shows that we could reach a clear break-even point as to where the machine learning-based approach (including training) can be performed in a faster time than with a conventional solver (see Figure \ref{fig:runtimes}).% Furthermore, the MAE values of the best-performing models indicated average deviations from the ground truth of around .2-.5, which, given target value ranges that can be expected from the measures, may well provide useful approximations.

For our concrete approach, we applied a binary encoding for representing knowledge bases. In the case of larger knowledge bases, this might lead to large feature vectors. From Section~\ref{sec:scalability} (Scalability), we could not identify any inherent technical difficulties in handling larger feature vectors. Still, in future work, we aim to investigate additional means for feature reduction that would allow us to reduce vector dimensionality. Also, different encoding forms, such as encoding knowledge with some form of abstraction, or graph neural networks, could be investigated.

%A further focus of this work was also the integration of symbolic constraints derived from various measure properties. %While the focus of this work was to investigate the general idea of integrating constraints (as well as different mechanisms for the integration), 
%In our setting, computing flags were constant, but intuitively, there could be flags that are more difficult to encode. So the actual computational costs of computing these should be carefully taken into consideration. 
%The same applies to the concrete form of constraint integration: The design of the constraint integration is also an important factor next to the domain knowledge itself.

Finally, while the problem investigated in this work was framed as a regression problem, a related interesting problem could be to classify two knowledge bases in which one is more inconsistent than the other. While this will not offer granular insights as in this work, there could still exist use cases where this insight would be useful, and it might be solvable with a simpler classification setup. 

In general, it seems the areas of machine learning and inconsistency measurement can be well aligned and may provide further opportunities for future work.