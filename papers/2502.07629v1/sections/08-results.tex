\section{Results}
Here we report on the study results.
Across both experiments, we recorded 1706 gestures from the 14 participants.

\subsection{Time}
\label{ssec:time}
In Experiment 1 we asked participants to repeatedly perform spread and pinch gestures to generate and remove text.
The mean time to complete this task (i.e. performing all gestures), was 16.38\,s when no visualisation was used, \secs{16.30} for Lines and \secs{14.41} for Bubbles.
These differences were significant as follows (\cref{tab:sig_tests}, row 1): 
\revision{With Bubbles,} participants completed the tasks significantly faster than with Lines (-\secs{1.76}) or without a visualisation (-\secs{2.62}).
\cref{fig:exp1_times} shows each subtask as a box blot.


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/task_completion_exp1.pdf}
    \caption{Task completion times for all subtasks in Experiment 1, segmented by visualisation condition (NoVis, Line, and Bubbles). Each subtask is represented along the x-axis, with the y-axis showing the completion time in seconds. Box plots display the completion times for each visualisation condition, with individual data points plotted as dots.}
    \Description{This figure shows a box plot illustrating task completion times across different tasks, subtasks, and visualisation conditions from Experiment 1. The x-axis represents the task and subtask combinations, while the y-axis shows completion time in seconds. Each subtask is labelled along the x-axis (e.g., extend - incomplete sentence, extend - 1 sentence, etc.), representing various tasks the participants completed during the study. The y-axis measures the time taken to complete each task, ranging from 0 to 70 seconds. Three colours represent the different visualisation conditions: Red represents NoVis, Green represents Lines visualisation, Blue represents Bubbles. Each box plot indicates the distribution of completion times for each visualisation across the different subtasks. Individual data points are plotted as dots to provide a clearer view of task variability.}
    \label{fig:exp1_times}
\end{figure*}

\revision{In Experiment 2}, with a mean completion time of \secs{56.35}, Bubbles was twice as fast as the chatbot UI, which took people \secs{134.86}.
This difference is significant (\cref{tab:sig_tests}, row 2).

The mean execution time of one extend gesture was \secs{5.23} for NoVis, \secs{4.59} for Lines, and \secs{3.88} for Bubbles.
Gestures to remove text took an average of \secs{2.73} for NoVis, \secs{2.59} for Lines, and \secs{2.52} for Bubbles.
\revision{See \cref{tab:time} for more details.}


\begin{table}[t]
\footnotesize
\centering
\begin{tabular}{llccc}
\toprule
\textbf{Task} & \textbf{Variable} & \textbf{Time} & \textbf{SD} & \textbf{Median} \\
\midrule
\multicolumn{5}{c}{\textbf{Experiment 1 - Visualisation}} \medskip\\
Overall & No Vis & 16.38 & 11.80 & 12.95 \\
 & Lines & 16.30 & 12.36 & 12.16 \\
 & Bubbles & 14.41 & 8.96 & 11.53 \medskip\\
Extend & No Vis & 18.48 & 11.53 & 13.89 \\
 & Lines & 17.16 & 12.22 & 13.24 \\
 & Bubbles & 15.58 & 8.91 & 12.87 \medskip\\
Shorten & No Vis & 12.27 & 9.87 & 9.52 \\
 & Lines & 12.79 & 10.36 & 9.78 \\
 & Bubbles & 12.02 & 8.54 & 9.24 \medskip\\
Combination & No Vis & 31.48 & 14.26 & 29.60 \\
 & Lines & 33.18 & 14.44 & 30.76 \\
 & Bubbles & 25.12 & 12.04 & 23.03 \medskip\\
\midrule
\multicolumn{5}{c}{\textbf{Experiment 2 - Interaction}} \medskip\\
Combined Task & Gesture & 56.35 & 30.87 & 51.03 \\
 & CUI & 134.86 & 58.05 & 125.94 \medskip\\
\midrule
\multicolumn{5}{c}{\textbf{Gesture Execution Time}} \medskip\\
Extend & No Vis & 5.23 & 3.13 & 4.71 \\
 & Lines & 4.59 & 2.45 & 4.33 \\
 & Bubbles & 3.88 & 2.20 & 3.61 \medskip\\
Shorten & No Vis & 2.73 & 1.45 & 2.22 \\
 & Lines & 2.59 & 1.51 & 2.00 \\
 & Bubbles & 2.52 & 0.87 & 2.41 \\
\bottomrule
\end{tabular}
\caption{Times measured in the study.}
\Description{This table gives an overview of the task times during the user study.}
\label{tab:time}
\end{table}








\subsection{\revision{Use of Space}}
The average finger distance when generating one sentence with the spread gesture was 229 pixel or 38.1\,mm. %
The average with the pinch gesture was 130 pixel or 21.6\,mm. %
\cref{fig:finger_kde} shows \revision{the finger locations.}
Participants used 1.88 (SD 1.77, median 1) subgestures (defined as taking the fingers off the screen to readjust) to complete one sentence, 1.73 (SD 1.35, median 1.0) to add a full sentence, and 3.89 (SD 2.70, median 3) to add three.
Similarly, they used 2.30 (SD 2.55, median 2) subgestures to remove one incomplete sentence, 1.38 (SD 0.64, median 1) to remove one sentence, and 2.92 (SD 1.68, median 2) to remove three.

\begin{figure}[t]
    \centering
    \includegraphics[height=7cm]{figures/finger_movement_overall_new}
    \caption{Density plot of all finger positions that were logged during the user study.}
    \Description{This figure is a Kernel Density Estimate (KDE) plot, visualising the density of all finger positions during gesture movements in the user study. The plot contains two density regions, each representing the positions of the first and second fingers during gesture input. The blue contour represents the distribution of the first finger’s touch positions, which are concentrated in the upper-left portion of the plot, around the coordinates (100, 150) in X and Y pixels, respectively. The orange contour indicates the density of the second finger’s positions, which are located in the lower-right part of the plot, around the coordinates (250, 500).The X-axis represents the horizontal position of the touches in pixels, and the Y-axis represents the vertical position. Darker areas within each density region indicate where finger positions are more concentrated during the gestures.}
    \label{fig:finger_kde}
\end{figure}


\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/distance_avg_all_versions_just_lines}
    \caption{The progression of normalized distance (relative to the target) over time for the visualisations in Experiment 1. The dashed red line represents the target distance, which is defined as the distance the fingers needed to be moved apart to create the intended amount of text. The pink, green, and blue lines represent the average distance at each point in time for \visnone{}, \visline{}, and \visbubble, respectively. The thickness of the lines indicates the number of samples included. Individual traces are displayed in light background lines.}
    \Description{This line graph illustrates how the distance between fingers, normalized relative to a target value, changes over time under different visual conditions tested in Experiment 1. The x-axis represents time in arbitrary units, while the y-axis represents normalized distance (relative to a target value of 1.0). A dashed red line indicates the target distance, which corresponds to the ideal finger movement required to achieve the desired text change. Three average distance lines are drawn: a pink line for the NoVis condition, a green line for the Lines condition, and a blue line for the Bubbles condition. The thickness of the lines indicate the number of samples included, which decreases gradually. Numerous faint individual traces are shown in the background, representing the variations in gesture distances for different trials under each condition. The lines for Bubbles reaches the dashed red line the fastest. NoVis reaches this target line the latest and overshoots.}
    \label{fig:normdist_time_all_avg}
\end{figure}

\subsection{Anatomy of Touch Gesture Text Generation}



\revision{To initiate the gestures, participants placed one finger at either the end or middle of a sentence, with the second finger positioned closer for the \spread{} gesture (280 px on average, SD 77.5, median 274) than for the \pinch{} gesture (343 px on average, SD 70.5, median 351). Also see \cref{fig:first_touches} in \cref{sec:appendix_figs}.}


An analysis inspired by human pointing dynamics \cite{mouse_mueller2017} \revision{revealed} distinct phases during the \spread{} gesture (\cref{fig:normdist_time_all_avg}): %
Participants rapidly spread their fingers to generate text, \revision{with 80\% of the target distance (where the task was completed) covered in the first half of the movement time.}
Afterward, the movement slowed down as the text approached the intended length.



Without visual feedback, participants often overshot the intended text length, going beyond the distance needed to complete the task.
This overshooting was less prominent with the Lines visualisation and entirely absent with Bubbles, as shown in \cref{fig:overshoot}. 

For Bubbles, the target was approached with a more consistent velocity.
Note that in \cref{fig:overshoot}, both the distance to the target and the time have been normalized\revision{, making the} curve for Bubbles appear to show a delayed target reach compared to the others. 
However, in absolute terms, Bubbles \revision{achieved} the shortest execution time, as detailed in \cref{ssec:time} and \cref{fig:normdist_time_all_avg}.

Finally, regarding hand postures, many participants intuitively used both thumbs for the gestures, though some adjusted their technique depending on the text's position, switching between thumbs and index fingers. 

\begin{figure*}[t]
     \centering
     \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{figures/distance_normalized_time_all_versions_scaled.pdf}
        \caption{The complete average movement to generate the targeted amount of text with the \spread{} gesture as a function of distance (relative to the target text length) over normalised time.}
        \label{fig:overshoot1} 
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[width=0.9555\linewidth]{figures/distance_normalized_time_all_versions_zoomed.pdf}
        \caption{The movement from (a) zoomed in on the end of the movement. At around 80\% of the total movement time a visible overshoot occurs for both \visnone and \visline.}
        \label{fig:overshoot2}
     \end{subfigure}
     \caption{The average movement to generate the target amount of text with \spread{} gives insights into how this gesture was executed. The distance is normalised relative to the targeted amount of text (red dashed line) and the normalized time. Points above y=1 indicate an overshoot, where more text was being generated than intended. We obtain this intention directly from users, as they had to confirm the text length modification after performing the gesture.}
     \Description{This figure contains two line graphs comparing the performance of different visualisation conditions ('NoVis', 'Lines', and 'Bubbles') while using the \spread{} gesture to generate text. Left graph (a): This graph plots the complete average movement required to generate the targeted text length as a function of normalized distance (relative to the target text length) over normalized time. The x-axis represents normalized time (0.0 to 1.0), and the y-axis represents normalized distance (relative to the target distance of 1.0). The three visualisation conditions ('NoVis', 'Lines', and 'Bubbles') are compared, with each shown as a distinct line. The target distance is represented by a red dashed line, while the other lines show the performance of each condition. The graph demonstrates how each condition approaches the target distance over time. Right graph (b): This graph zooms in on the final portion of the movement, focusing on the last 20\% of the total movement time. The same three conditions ('NoVis', 'Lines', and 'Bubbles') are plotted, showing the movement beyond 0.70 normalized time. Around 80\% of the total movement time, a visible overshoot occurs in both 'NoVis' and 'Lines' conditions, where the lines exceed the target distance.}
     \label{fig:overshoot}
\end{figure*}






\subsection{Perception of Visualisation Techniques (Experiment 1)}
\label{sec:perception_exp1}
After each condition in Experiment 1, participants rated the system's usability with the SUS questionnaire, their perceived workload using the NASA-TLX, and nine additional 5-point Likert items.

These results show that Bubbles achieved the highest usability rating of 85.54, indicating ``excellent'' usability, whereas Lines achieved a ``good'' score of 76.96, and NoVis performed significantly (\cref{tab:sig_tests}, row 3) worse than both with an ``OK'' score of 63.46 \cite{susBangor2009}.
Similarly, participants perceived the lowest workload using Bubbles with a NASA-TLX Raw score of 1.976, followed by 2.154 for Lines, and 2.794 for NoVis, which was significantly higher than both visualisations (\cref{tab:sig_tests}, row 5).

Further Likert items in Experiment 1 (see \cref{fig:own_likert_exp1}) overall indicate that participants perceived their interaction with the system as fast and without delays, regardless of the visualisation.
Comparatively, NoVis was clearly rated the lowest across all items.
While this is expected for questions regarding the support offered by visual representations, it is worth noting that both Lines and Bubbles also %
considerably increased participants' enjoyment of the system.
Comparing Bubbles and Lines, Bubbles was rated higher across all items, except for participants' perceived level of control over text length, where both visualisations were rated equally high. 

\begin{figure*}
    \centering
    \includegraphics[width=.65\linewidth]{figures/exp1_likert_comparison.pdf}
    \caption{Likert results on participants' perception of interaction with our prototype and the visual presentations, rated after each condition in Experiment 1. These rating overall indicate that participants felt that their interaction with the system was fast and without delays, regardless of the visualisation technique, but comparatively, NoVis was clearly rated the lowest across all items.}
    \Description{This figure shows divergent bar charts for the Likert results on participants' perception of interaction with our prototype and the visual presentations, rated after each condition in Experiment 1. These rating overall indicate that participants felt that their interaction with the system was fast and without delays, regardless of the visualisation technique, but comparatively, NoVis was clearly rated the lowest across all items.}
    \label{fig:own_likert_exp1}
\end{figure*}


\subsection{Perception of Interaction (Experiment 2)}
\label{sec:perception_exp2}
In Experiment 2, participants rated the system's usability significantly higher (\cref{tab:sig_tests}, row 4) for the touch gestures (81, ``good'') compared to using the CUI designed to mimic ChatGPT (52.5, ``OK'').
Similarly, their perceived workload was significantly (\cref{tab:sig_tests}, row 6) lower when using touch gestures (2.060) compared to using ChatGPT (3.153). %

This trend is further reflected in the nine Likert-items for Experiment 2 (see \cref{fig:own_likert_exp2}), which participants rated after each condition.
Our gesture-based interaction approach scored higher than the ChatGPT-like CUI across all items.

\begin{figure*}
    \centering
    \includegraphics[width=.65\linewidth]{figures/exp2_likert_comparison.pdf}
    \caption{Likert results on participants' perception of interaction with our touch-based prototype compared to our CUI implementation, rated after each condition in Experiment 2. Most participants rated almost all items overwhelmingly positive when using our approach.}
    \Description{This figure shows divergent bar charts for the likert results on participants' perception of interaction with our touch-based prototype compared to our CUI implementation, rated after each condition in Experiment 2. Most participants rated almost all items overwhelmingly positive when using our approach. Only for the item that asked participants whether they felt like the author of the text, while still rating our mode higher, the responses were more mixed.}
    \label{fig:own_likert_exp2}
\end{figure*}


\subsection{Subjective Feedback}
\label{sec:ss_interview_perception}
After both experiments, participants rated four Likert items on their overall experience with the gestures.

All but one ``neutral'' participant agreed (7) or strongly agreed (6), that ``the gesture controls felt intuitive.''
Similar, all but one ``neutral'' participant agreed (5) and strongly agreed (8), that ``the gesture controls felt natural''.
They ``would use this gesture-based text control of text generation feature in [their] daily tasks'' (4 ``neutral'', 8 ``agree'', 2 ``strongly agree'') and ``would recommend this gesture-based text control feature to others'' (1 ``neutral'', 3 ``agree'', 10 ``strongly agree'').
No one disagreed with any of these statements.


As the last part, we conducted semi-structured interviews. %
All but one participant %
picked Bubbles as their favourite, explicitly confirming the bigger picture observed in the preceding sections.




When asked about challenges, six participants reported no issues, one mentioned occlusion, and seven said they sometimes struggled to select the intended sentence. 
\revision{Difficulties include ``fat finger'' issues on the smaller screen (some were accustomed to larger devices), misunderstanding the interaction pattern (placing the cursor instead of tapping the sentence), and lack of individual adjustments for visual feedback delay and touch target offset. %
}
However, P8 added, ``you'd get into it over time''\revision{, which we also observed in other participants as the study progressed}.

\revision{Participants’ feedback on what they liked most about using gesture controls emphasized its intuitive, ``extremely smooth'' (P14) and natural feel.
They preferred the Bubbles visualisation for its clear separation of words, sentences, and deletions.}
In \cref{sec:perception_exp2}, we reported mixed feelings about authorship (\cref{fig:own_likert_exp2}). 
However, when reminded about the long-press feature in the interviews, 
\revision{11 out of 14 participants said this would enhance their sense of authorship.}

Multiple participants also noted that the visualisation effectively managed latency, with P7 remarking that they had ``hardly any feeling of latency''. %
The interaction as a whole -- but especially with Bubbles -- was described as satisfying, with P13 noting, ``It was simply fun to watch!''







