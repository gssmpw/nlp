\documentclass[sigconf]{acmart}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage[capitalize, noabbrev]{cleveref}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{siunitx}
\usepackage{enumitem}
\usepackage{calc}
\usepackage{listings}
\usepackage{float}
\lstset{
basicstyle=\small\ttfamily,
columns=flexible,
breaklines=true
}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\setcopyright{acmlicensed}
\copyrightyear{2025} 
\acmYear{2025} 
\setcopyright{cc}
\setcctype{by}
\acmConference[CHI '25]{CHI Conference on Human Factors in Computing Systems}{April 26-May 1, 2025}{Yokohama, Japan}
\acmBooktitle{CHI Conference on Human Factors in Computing Systems (CHI '25), April 26-May 1, 2025, Yokohama, Japan}\acmDOI{10.1145/3706598.3713554}
\acmISBN{979-8-4007-1394-1/25/04}






\begin{document}

\title{Exploring Mobile Touch Interaction with Large Language Models}

\author{Tim Zindulka}
\email{tim.zindulka@uni-bayreuth.de}
\orcid{0009-0009-1972-351X}
\affiliation{%
  \institution{University of Bayreuth}
  \city{Bayreuth}
  \country{Germany}
}

\author{Jannek Sekowski}
\email{jannek.sekowski@uni-bayreuth.de}
\orcid{0009-0006-3324-7837}
\affiliation{%
  \institution{University of Bayreuth}
  \city{Bayreuth}
  \country{Germany}
}

\author{Florian Lehmann}
\email{florian.lehmann@uni-bayreuth.de}
\orcid{0000-0003-0201-867X}
\affiliation{%
  \institution{University of Bayreuth}
  \city{Bayreuth}
  \country{Germany}
}

\author{Daniel Buschek}
\email{daniel.buschek@uni-bayreuth.de}
\orcid{0000-0002-0013-715X}
\affiliation{%
  \institution{University of Bayreuth}
  \city{Bayreuth}
  \country{Germany}
}

\renewcommand{\shortauthors}{Zindulka et al.}

\definecolor{TimsColor}{rgb}{0.1,0.5,0.8}
\newcommand{\tim}[1]{\textsf{\textbf{\textcolor{TimsColor}{[Tim: #1]}}}}
\definecolor{JanneksColor}{rgb}{0.5,0.8,0.5}
\newcommand{\jannek}[1]{\textsf{\textbf{\textcolor{JanneksColor}{[Sven: #1]}}}}
\definecolor{FlosColor}{rgb}{0.9,0.1,0.8}
\newcommand{\flo}[1]{\textsf{\textbf{\textcolor{FlosColor}{[Flo: #1]}}}}
\definecolor{DanielsColor}{rgb}{0.9,0.6,0.1}
\newcommand{\daniel}[1]{\textsf{\textbf{\textcolor{DanielsColor}{[Daniel: #1]}}}}


\newcommand{\minsec}[2]{\SI{#1}{\minute} \SI{#2}{\second}}
\newcommand{\mins}[1]{\SI{#1}{\minute}}
\newcommand{\secs}[1]{\SI{#1}{\second}}
\newcommand{\pct}[1]{\ifnum\pdfstrcmp{#1}{X}=0
        X\% 
    \else\SI{#1}{\percent}\fi
}
\newcommand{\lbparagraph}[1]{\paragraph{#1}\mbox{}\\}



\newcommand{\lmmci}[5]{$\beta$=#1, SE=#2, CI$_{95\%}$=[#3, #4], p#5}
\newcommand{\posthoc}[2]{#1, p#2}

\definecolor{deemphColor}{rgb}{0.4,0.4,0.4}
\newcommand{\deemph}[1]{\textcolor{deemphColor}{#1}}

\newcommand{\pinch}{pinch-to-shorten}
\newcommand{\Pinch}{Pinch-to-shorten}
\newcommand{\spread}{spread-to-generate}
\newcommand{\Spread}{Spread-to-generate}
\newcommand{\visbubble}{Bubbles}
\newcommand{\visline}{Lines}
\newcommand{\visnone}{NoVis}
\newcommand{\modeours}{Gestures}
\newcommand{\modegpt}{ChatGPT}


\newcommand\revision[1]{\textcolor{black}{#1}}


\begin{abstract}
Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. 
In this paper, we propose to control the LLM via touch gestures performed directly on the text.
We first chart a design space that covers fundamental touch input and text transformations.
In this space, we then concretely explore two control mappings: \spread{} and \pinch{}, with visual feedback loops.
We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. 
The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. 
This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.
\end{abstract}



\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10011748</concept_id>
       <concept_desc>Human-centered computing~Empirical studies in HCI</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003128.10011753</concept_id>
       <concept_desc>Human-centered computing~Text input</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178.10010179</concept_id>
       <concept_desc>Computing methodologies~Natural language processing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Empirical studies in HCI}
\ccsdesc[500]{Human-centered computing~Text input}
\ccsdesc[500]{Computing methodologies~Natural language processing}



\keywords{Writing assistance, Large language models, Human-AI interaction, Mobile interaction, Touch interaction, Direct manipulation}


\begin{teaserfigure}
  \centering
  \includegraphics[width=\textwidth]{figures/teaser}
  \caption{Our \textit{\spread} touch gesture for controlling generative AI on mobile devices. Touches are marked in orange. \textit{(1)} Placing two fingers on the screen sets the cursor (red) to the end of the sentence at the first touch (here: top touch). \textit{(2-3)} Spreading the two fingers fades in blue ``word bubbles'', which indicate estimates of length and number of words to be generated. In the background, an LLM generates text and streams it to the UI, where it is inserted into empty bubbles as it becomes available. \textit{(4)} Reaching the end of a sentence turns the word bubbles into one green sentence bubble. Further spreading the fingers starts generating another sentence. \textit{(5)} A confirmation widget is shown when lifting the fingers. Tapping the check mark accepts the generated text for \textit{(6)} the final result.}
  \label{fig:teaser}
  \Description{This figure shows six stages of the '\spread' gesture for controlling a generative AI system on mobile devices. The gesture is used to generate and insert text into a passage, and key touch points are highlighted in orange circles. Panel 1: The user places two fingers on the screen, and the cursor (shown in red) is positioned at the end of the sentence, where text generation will begin. Panel 2: As the user begins spreading their fingers apart, blue 'word bubbles' start appearing between the cursor and the point of finger contact. These bubbles represent placeholders for the AI-generated words that will be inserted into the sentence. Panel 3: As the spreading gesture continues, more 'word bubbles' are generated, reflecting additional text the AI will insert. The bubbles indicate the length and number of words that are likely to be generated. Panel 4: Once the AI has completed generating text for the current sentence, all the blue 'word bubbles' turn into a single green sentence bubble. This indicates that the AI has fully generated the sentence. Panel 5: A confirmation widget appears in the bottom right corner with a checkmark and 'X' button after the user lifts their fingers. This allows the user to either accept or reject the generated text. Panel 6: The user taps the checkmark to confirm and accept the AI-generated text, which is then finalized and inserted into the document. Each panel shows the progression of the gesture, from starting the text generation process to confirming the final result.}
\end{teaserfigure}



\maketitle

\input{sections/01-introduction}
\input{sections/02b-related_work_v2}
\input{sections/04-design_space}
\input{sections/06-implementation}
\input{sections/07-user_study}
\input{sections/08-results}
\input{sections/09-discussion}
\input{sections/10-conclusion}



\begin{acks}
Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- 525037874.
This project is funded by the Bavarian State Ministry of Science and the Arts and coordinated by the Bavarian Research Institute for Digital Transformation (bidt).
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}


\appendix

\input{sections/11-appendix}

\end{document}
