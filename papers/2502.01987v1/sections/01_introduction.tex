\section{INTRODUCTION}
Learning-based systems enable autonomous navigation in complex structured and unstructured environments where classical methods have strugled~\cite{frey2023fast, guastella2021learning}, for example, in densely vegetated environments. However, methods relying on modern learning techniques can suffer from decreasing performance when encountering previously unseen elements in the environment, resulting in unsafe behaviour or catastrophic failure. 
%
Many modern approaches rely on supervised data to adapt or finetune learnt models to a novel environment, to a different robotic platform or sensor configuration. This commonly requires the collection and hand-labelling of data, which is expensive and time-consuming. Hence, adapting a system to every new environment can be prohibitively expensive in terms of both time and cost. For industry applications, this presents a severe practical barrier to adopting and deploying autonomous systems in various scenarios.
%
Consequently, the ability of a pre-trained model to adapt to a new domain or, in extreme cases, the ability to train a new model in a self-supervised fashion directly in a novel environment is highly desirable. It may even be necessary to enable widespread deployment and adaptation of autonomous systems. Further, depending on the application, time constraints can be critical. For example, an autonomous agent intended to fight bushfires would not have time to be re-trained for each deployment location. The key factors here are the time and effort to deploy in a novel environment.

The issue of high variation and change is particularly relevant for densely vegetated environments. These environments can exhibit significant and rapid changes due to weather,  rapid plant growth, seasons or day/night cycle.  Additionally, there is a considerable variation within the flora depending on the location and the macro-climate, e.g. sun vs shade side of a hill. In essence, there can be a high amount of variability and sudden changes in the environment on a small spatial and temporal scale, as was also reported in field experiments~\cite{bradley2015scene, frey2023fast}. Hence, the ability to adapt to the environment is essential to enable robust deployment of autonomous agents in natural environments.

The recent literature on online adaptation for robotic navigation in unstructured and complex environments relies on image modalities. Images are typically labelled using self-supervised approaches, where experience (e.g. traversal, realised speed vs. actual speed, IMU signals) is associated with the image~\cite{frey2023fast, bae2023self, wellhausen2019where, kahn2020badgr}. 
% 
The robot's experience of traversing a patch or a volume of terrain is used to associate proprioceptive sensor readings and robot state with exteroceptive sensor measurements or spatial representation. This fusion allows for the generation of self-supervised labelled data with a traversability metric or surrogate. More recent work includes geometric measurements, such as point clouds or height maps, to assist in the projection or as an additional feature for a neural network~\cite{li2023seeing, frey2024roadrunner}. However, the mentioned method solely relies on the image modality to discriminate the environment, which is prone to catastrophic failures to environmental conditions, e.g. light changes or inability to navigate due to occlusions.
% 
Commonly, non-traversable examples are not captured during data collection to avoid the risk of damaging the robot. Instead, surrogate metrics are defined for non-traversable elements. This has been shown to lead to desirable behaviours or navigation strategies that may implicitly emerge~\cite{frey2023fast}, but may not capture the actual traversability capability of the robotic system. These methods are similar to self-supervised learning approaches that use post-processed data but require additional considerations to be deployed online.

% In the case of online adaptation or continual learning, this can identify the requirement to learn/adapt to a new environment (out of distribution detection) and stop when sufficient performance has been achieved. Both of these questions are an ongoing topic of research~\cite{lee2024learning}. Further, allowing an autonomous system to explore an environment with many out-of-distribution elements can be risky and result in damaging the platform or the sensors due to actual collisions with dense elements of the environments. A human operator can guide the robot in novel environments and guide the system to gather self-supervised data rapidly whilst minimising the risk of catastrophic failure.

This work proposes a novel online adaptive TE method that allows the robot to adapt to previously-unseen densely vegetated environments and enables safe navigation. The method can be trained in real-time, in situ, on the platform, with the help of a human operator guiding the robot to experience the environment. The proposed method leverages 3D probabilistic voxel maps, which are robust against single erroneous sensor readings and occlusions. Further,  an incremental data fusion scheme combines lidar measurements and robot experience into a graph-based data structure. This approach allows to retain and update temporarily evolving voxel distribution whilst minimising the computational load. This method differentiates itself from other recent works in this area, as it is a pure lidar-based geometric method achieving online \ac{TE} in vegetated environments. It provides insights when dealing with multi-distribution probabilistic voxel-based maps in the online learning domain, which have not been presented anywhere else. Further, the proposed method does not require an ``expert operator''  with significant technical knowledge to adapt a robotic system to a novel environment.

The proposed online adaptive forest traversability estimation allows the operator to quickly adapt an existing model to a new environment. The contributions of this paper are as follows: 
\begin{itemize}
 \item we present a novel online adaptive traversability estimation method that can adapt to novel/unseen environments during deployment,
 \item we propose a data graph strategy to capture and maintain a graph of the environment in a sparse form, allowing for the generation of high-quality data whilst the robot operates,
 \item we demonstrate that online adaptation can be achieved solely with self-supervised data whilst running on a robot in real-time and validate this with a model trained online for point-to-point navigation,
 \item we provide a detailed evaluation of \ac{TE} model performance based on a variety of training or adaptation schemes and network architectures, resulting in recommendations of strategies that should be used depending on the constraints,
 \item we present an extensive field test using point-to-point navigation for six different methods and models trained with different data and approaches, allowing us to gather further insight into the benefits and limitations of this approach. 
\end{itemize}

This work differs from other contributions in the field by using only lidar and a temporally evolving 3D probabilistic voxel map rather than imaging modalities~\cite{frey2023fast, yoon2024adaptive}. Further, this method allows the robot to experience the failure state of learning actual terrain traversability rather than a surrogate measure and generate accurate \ac{lfe} data. In addition, this work releases open-source codebases and additional videos on the project website~\footnote{ \href{https://fabioruetz.github.io/foresttrav_aol.github.io}{Project Website: https://fabioruetz.github.io/foresttrav\_aol.github.io}} ~\footnote{ \href{https://github.com/csiro-robotics/foresttrav}{Github: https://github.com/csiro-robotics/foresttrav }}.

