\section{DISCUSSION}
\label{sec:discussion}
The online adaptation demonstrated on the real-world data set showed that thanks to our proposed method, it is feasible to train and adapt a model online and deploy it in a vegetated environment for safe navigation. This is a significant finding since, currently, there are no comparable online~\ac{TE} adaptation methods for robotic navigation in vegetated environments using probabilistic voxel representations. Further, we demonstrated the method can achieve high performance, comparable to the results obtained in state of the art using offline data~\cite{ruetz2024foresttrav}. 

Further, the presented results on online adaptation provided insights and recommendations for practical applications for deploying robots using deep learning systems and probabilistic voxel representations. The performance-determining factors are the quality and quantity of available data. Depending on time, cost and performance constraints, there are different recommendations. For a long-term deployment in a given area, the traditional hand-labelling approach provides the best performance at a high upfront cost and with the most generalisation. 

However, the results from the experiments also suggest that highly accurate models can be trained with data solely collected from the robot's experience. Multiple data collection runs may be required, and for the presented system and methods, this can be achieved within hours. However, as in the case with the ForestTrav DENSE case, the model may be only valid for a short time and may not generalise as well to changing sensor or environmental changes.

The online adaptation on the robot could be reduced to \qty{\sim 8}{\minute} for our system running on a \qty{25}{\watt} GPU, with a previous model at the reduction of MCC score from 0.74 to 0.63 for our in-situ online adaptation experiment, see Subsection~\ref{subsec:online_odap}. Comparing the adaptive online method score with results from Table~\ref{tab:tab_offline_ft}, the online approach is not as accurate as the \ac{lfe_hl} methods. However, the online experiment~\ref{subsec:online_odap} resulted in a model as accurate, both MCC of 0.63, as the models trained only~\ac{lfe} the available time, specific task and accuracy requirements will dictate what method is appropriate.

The main difference between the pure \ac{lfe} data set (post-processed data) and the online adaptation data set is the information quality of the voxel map. Again, understanding the completeness of the environment and how well the voxel-wise distributions have converged is desirable, but it is a current limitation. Using offline processing allows us to store intermediate steps, and introspection is currently not possible when computing online. Further, the proposed models require, in comparison to image methods, little high-quality data to perform well (see Table~\ref{tab:offline_base}). This indicates that the quality and variety of the data are more significant than the necessary quantity of data. The experiment using the online collected data showed that high-performance models could be trained. However, there must be sufficient and diverse data. 


% Generalisation of the data to the different environments
A key benefit of this method is its generalisation over starkly different environments. The results indicate that the more complex environments share many baseline similarities with structured environments, such as the industrial set, but include many more complex elements (e.g. grass, bushes). However, some baseline static constraints will still apply, e.g. an agent cannot drive up to steep slopes or cannot overcome large elements. Other online, adaptive vision-based systems have reported significant performance degradation within small location changes of the ``same'' environment, noting this is common and expected for vision modalities~\cite{frey2023fast}.  

Whilst our method generalises over different environments, in our online navigation experiment, we see a qualitative performance degradation of the model trained on the ForestTrav data set. Firstly, the test environment has experienced significant growth since the original data set~\cite{ruetz2024foresttrav} was collected, changing the environment substantially. The presented online adaptive model, ForestTrav AOL, generated its training data in the changed environment, highlighting the need for adaptive methods. Secondly, a different sensor pack was used during testing, changing the characteristics of some of the sensor modalities, leading to significant degradation of the model trained on the industrial setting in the forest environment.  


% The performance difference of the models in Subsections~\ref{ch7:res_online_adaptation}

% Elements that are not discussed in this paper include detecting when the model is not performing well and how to evaluate an online trained model. Since cross-entropy is a proper scoring metric, the resulting loss should give a broad indication of how well the system is performing. However, this relies on the quality of the data gathered through robot experience. 
% % 
% Another point of interest is the question of the data quality or map quality. This can either mean the current map as a whole or the generated self-labelled patches. The graph structure allows for the maintenance of a sparse representation, but the question of which data should be added or overwritten could be addressed with a more nuanced understanding. Further, the addition of older data or rarely occurring elements may be desirable and not realised in the current form.
% % 
% Further, some nodes will contain redundant information and examples. For long-term deployment, one would want to minimise the redundant data and prioritise difficult examples. 
% % 
% Additionally, a form of anomaly detection or out-of-distribution detection would allow the system to understand when previously unseen environments or elements are encountered. This could allow us to determine when to start or stop an online adaptation cycle, e.g. when the number of unknown elements reaches a lower bound. The practicality of this approach is an open question. 

\section{CONCLUSION}
This work introduced a novel online TE adaptation method that allows a robot to adapt to its environment in situ. In human-robot collaboration, the robot experiences the environment and can build high-quality training data on the fly using a graph-based representation \ac{ograph}. We explored the lidar-only TE estimation model for online adaptation to a novel environment. We demonstrated the feasibility of adapting a model online. The proposed methods and \ac{ograph} allow the model's training in situ whilst aided by a human operator. We demonstrated that the adapted model allowed for point-to-point navigation in challenging environments. The online-trained model with an \ac{mcc} score of 0.63 allows the robot to navigate complex environments and shows comparable performance to the model trained on offline data in our previous publication~\cite{ruetz2024foresttrav}.

We compare the benefits of online adaptation versus more classical, offline approaches using hand-labelled data or self-supervised data, allowing potential future users to make an informed decision about which method to choose.  ForestTrav, using the combination of hand and self-supervised data, has been shown to generalise well to novel environments and environmental changes.  However, the presented online adaptive method has significant practical use benefits given time constraints. Generating training data and a trained model in less than \qty{8}{\minute} in situ is much faster than post-processing and hand-labelling data. Lastly, since there is limited literature on online learning with 3D probabilistic voxel on robotic platforms in situ, this work provides valuable insights and highlights further challenges and open research areas.

% Limitations and future work
 Current limitations include ensuring that the training data is unique and expressive. The longer an adaptation lasts, the more similar data will likely be accumulated. The increase in duplicate data reduces the training signal of corner cases due to the low number of samples. Hence, understanding what is poorly observed vs out-of-distribution or novel data would be an interesting avenue of future work. In an ideal case, this could be presented to the operator in real-time to collect relevant information and allow the model to adapt faster. Furthermore, parallel training of models has yet to be explored. Simultaneously, adapting multiple models would be desirable to enable the use of an ensemble. Lastly, a method to evaluate the model online during deployment, either fully trained or adapted, would be desirable.