
\section{Limitations}

Despite exhibiting state-of-the-art performance in material transfer, our method still suffers from a few limitations that we illustrate in ~\cref{fig:limitations}. A challenging case for us is surfaces pointing downwards or exhibiting high-frequency normals, both of which do not appear in our dataset and could benefit from a more extensive training set. Another challenge comes from thin or small objects that are difficult to process due to the diffusion model resolution and the downsizing of the input mask when working in latent space, effectively eroding the masked area. Finally, as we rely on normals and irradiance as inputs, our method is negatively impacted when they are poorly estimated. However, this is mitigated by the rapid progress in intrinsic image decomposition from which we directly benefit. 



\section{Conclusion}

We present ~\method{}, a method for material transfer from flat textures to images without requiring complex 3D understanding or UV mapping. Our approach naturally harmonizes the transferred material with the target image illumination, leveraging the available irradiance information. We demonstrate material transfer in real photographs with control over the scale and hue, making it easier to adapt the new material to the target scene. We believe our approach provides a more practical tool for artists to edit images and explore possible material variations, for example in the context of architecture visualization and interior design. 

\newparagraph{Acknowledgments.} This research was funded by the French Agence Nationale de la Recherche (ANR) with the project SIGHT (ANR-20-CE23-0016) and performed with HPC resources from GENCI-IDRIS (Grants AD011014389R1 and AD011012808R3). 