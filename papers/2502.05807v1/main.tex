%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{tcolorbox}
\usepackage{enumerate}
\usepackage{stfloats}
\usepackage{multirow}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{caption}
\usepackage{listings}
\usepackage[thicklines]{cancel}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    xleftmargin=1em,
    xrightmargin=1em,
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\renewcommand{\algorithmiccomment}[1]{\hfill\textit{\textcolor{gray}{#1}}}

\definecolor{customblue}{RGB}{31,119,180} % C0-like blue from Matplotlib

\usepackage{pifont}
\newcommand{\cmark}{ \textcolor{green!60!black}{\ding{51}} }
\newcommand{\xmark}{ \textcolor{red!60!black}{\ding{55}} }


% shorthands
\def\x0{\mathbf{x}_0}
\def\xt{\mathbf{x}_t}
\def\xT{\mathbf{x}_T}
\def\ut{\mathbf{u}_t}

\usepackage{tikz}

\newcommand{\highlight}[1]{%
    \tikz[baseline=(X.base)] \node[fill=customblue!20, rounded corners=2pt, text opacity=1, fill opacity=0.8, inner sep=2pt] (X) {#1};%
}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
%\usepackage{hyperref}
\usepackage[colorlinks=true,citecolor=blue!70!green,linkcolor=red!80!black]{hyperref}
%\def\equationautorefname~#1\null{(#1)\null} 
\def\equationautorefname~#1\null{equation (#1)\null}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage[nohyperref]{icml2024}


% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{prop}{Proposition}
\newtheorem{corollary}{Corollary}
\newcommand{\lemmaautorefname}{Lemma}
\newcommand{\corollaryautorefname}{Corollary}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% Abbreviations for mathematical expressions
\input{math_commands}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Density guidance}

\begin{document}

\twocolumn[
%\icmltitle{Density-Guided Sampling in Flow Models:\\Detail-Aware Image Generation}

\icmltitle{Devil is in the Details: Density Guidance \\for Detail-Aware Generation with Flow Models}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Rafał Karczewski}{aalto}
\icmlauthor{Markus Heinonen}{aalto}
\icmlauthor{Vikas Garg}{aalto,yaiyai}
\end{icmlauthorlist}

\icmlaffiliation{aalto}{Department of Computer Science, Aalto University, Finland}
\icmlaffiliation{yaiyai}{YaiYai Ltd}

\icmlcorrespondingauthor{Rafał Karczewski}{rafal.karczewski@aalto.fi}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Diffusion models have emerged as a powerful class of generative models, capable of producing high-quality images by mapping noise to a data distribution. However, recent findings suggest that image likelihood does not align with perceptual quality: high-likelihood samples tend to be smooth, while lower-likelihood ones are more detailed. Controlling sample density is thus crucial for balancing realism and detail. In this paper, we analyze an existing technique, Prior Guidance, which scales the latent code to influence image detail. We introduce score alignment, a condition that explains why this method works and show that it can be tractably checked for any continuous normalizing flow model. We then propose Density Guidance, a principled modification of the generative ODE that enables exact log-density control during sampling. Finally, we extend Density Guidance to stochastic sampling, ensuring precise log-density control while allowing controlled variation in structure or fine details. Our experiments demonstrate that these techniques provide fine-grained control over image detail without compromising sample quality.
\end{abstract}

\section{Introduction}\label{sec:intro}

Diffusion models are a family of generative models that learn to map noise to a data distribution $p_0$, which allows realistic image sampling \citep{ho2020denoising,song2021scorebased,song2021denoising,vahdat2021scorebased}. In the quest towards high-fidelity sampling it is natural to ask whether perceptual quality of images aligns with their likelihood $p_0(\vx)$ \citep{karczewski2024diffusion}? 

Remarkably, the density $p_0$ correlates \emph{negatively} with the amount of detail: within the \emph{typical samples} \citep{nalisnick2020detecting} $\vx \sim p_0$ higher-density images tend to lack detail and be smooth, while lower-density images tend to be richly textured and detailed \citep{sehwag2022generating} (See \autoref{fig:forest}). Outside the typical samples, extremely low density leads to broken images \citep{karras2024guiding}, while extremely high density strips detail to the point of resembling sketch drawings or blurs \citep{karczewski2024diffusion}. 

\begin{figure}[t!]
    \centering
    % \includegraphics[width=\columnwidth]{figures/img3.png}
%    \includegraphics[width=\columnwidth]{figures/dg-fig1.png}
    \includegraphics[width=\columnwidth]{figures/dg-fig1.jpg}
    \caption{\textbf{Density guidance controls the amount of detail.} Images sampled from the same condition and latent code with different strengths of guidance. Top: StableDiffusion v2.1 \citep{rombach2021highresolution}. Bottom: EDM2 \citep{karras2024analyzing}.}
    \label{fig:forest}
\end{figure}

Somewhat surprisingly the common sampling strategies in flow models do not optimise for sample density \citep{karras2022elucidating}. Recently, \citet{karczewski2024diffusion} proposed a seminal approach towards controlling the sample density by biasing the sampling towards the extremely high likelihood regions of $p(\vx_0|\vx_t)$, and demonstrated that these correspond to unrealistic images. Their work is limited in three ways. The approach is only derived for SDE models with linear drift. The exact procedure is not tractable so the authors resort to approximations in practice. Finally, it only allows targeting the highest possible likelihoods, which do not produce realistic images.
This highlights the need for a more general approach that allows fine-grained control over sample density while preserving realism.

In this paper, we build upon prior observations that scaling the latent code affects image detail \citep{song2021scorebased}.
We refer to this method as \emph{Prior Guidance} and we provide a theoretical explanation for this phenomenon by introducing \emph{score alignment}, a condition under which Prior Guidance provably increases or decreases log-density.
We show that this condition often holds in practice.
% , and we derive precise limits on the latent code norm to prevent deviations from the data manifold.

Beyond this analysis, we introduce \emph{Density Guidance}, a novel procedure that allows explicit control over the log-density of generated samples.
Assuming knowledge of the score function, we derive an alternative ODE that guarantees the log-density of the trajectory evolves exactly as specified.
Empirically, we show that this method achieves similar results to Prior Guidance.

Finally, we extend Density Guidance to incorporate stochastic sampling.
This enables precise control over the log-density of generated samples even when randomness is introduced.
By injecting noise at different stages of the generation process, we can selectively influence variations in high-level structure (e.g., shape and composition) or fine-grained details.
Our experiments demonstrate that this stochastic extension allows for enhanced diversity while preserving control over the desired level of detail.

% In this paper we address all three issues by introducing rigorous \emph{density guidance}, which can precisely control the desired sample density. The density guidance (i) works for any continuous-time generative model, (ii) %is tractable and efficient, 
% can require zero extra cost, 
% (iii) requires no extra training, (iv) allows sampling points with arbitrary likelihood $p_0(\vx)=c$. In practise this results in \emph{detail-aware generation} where we can choose the amount of secondary details in the sampled image, with no apparent degradation of image quality (See \autoref{fig:forest}). 

In summary, in this paper we
\begin{itemize}
\item introduce \emph{Score Alignment}, a condition that explains how latent code scaling affects image detail and can be tractably checked for any CNF model - \autoref{sec:scaling};
\item derive a modification of the generative ODE that enables exact log-density control during sampling - \emph{Density Guidance} \autoref{sec:dgs};
\item extend Density Guidance to stochastic sampling, retaining exact log-density control while allowing controlled variation in structure or details - \autoref{sec:sold}.
\end{itemize}

% \autoref{tab:contrib} summarises our contributions.


% \begin{table*}[t]
% \centering
% \caption{Our contributions.}
% \resizebox{\linewidth}{!}{
% \begin{tabular}{lcccccc}
% \toprule
%        &         &         & \multicolumn{2}{c}{Sample images} &   & \\ 
% \cmidrule(lr){4-5}
% Method & Section & Sampler & semantics & details & $\log p_t$ control & Cost \\ 
% \midrule
% %PF-ODE, revSDE & \citet{song2021scorebased} & & & \xmark \\
% %Temperature scaling & \citet{song2021scorebased} & PF-ODE & & relative \\
% %Low-density sampling & \citet{sehwag2022generating} & LD & & low density \\
% %Mode seeking & \citet{karczewski2024diffusion} & HP-ODE & constant & modes \\
% %\cmidrule(lr){1-5}
% Prior Guidance & \autoref{sec:scaling} & Probability-Flow ODE & $\approx$ constant & varying & monotonic & Free \\
% Density Guidance & \autoref{sec:dgs} & Density-Guided ODE & $\approx$ constant & varying & precise, or quantile $q$ & Free \\
% Stochastic Density Guidance & \autoref{sec:sold} & Density-Guided SDE & varying & $\approx$ constant & precise, or quantile $q$ & \textcolor{red}{TODO} \\
% \bottomrule
% \end{tabular}
% }
% \label{tab:contrib}
% \end{table*}

\section{Background}\label{sec:background}

\begin{figure*}[ht]
    \centering    \includegraphics[width=0.95\textwidth]{figures/vfa_figure_sa_highlight.png}
    \caption{\textbf{Prior Guidance and Score Alignment (SA).} Prior guidance works by moving \( \vx_T \) (noise) in the direction of \( \textcolor[HTML]{ED1C24}{\nabla \log p_T(\vx_T)} \) and decoding to \( \vx_0 \) (image). The purpose of this is to increase or decrease \( \log p_0(\vx_0) \), which is inversely related to the level of detail in \( \vx_0 \). SA is a condition that ensures prior guidance is effective by requiring the alignment of score vectors across time steps. \textcolor[HTML]{ED1C24}{Red arrows} represent tangents to the curves: \( \nabla \log p_T(\vx_T) \) is the tangent to the left curve at \( \vx_T \), and its push-forward via \( \frac{\partial \vx_0}{\partial \vx_T} \) is the tangent to the decoded curve at \( \vx_0 \). SA states that the transformed \textcolor[HTML]{ED1C24}{tangent vector} must align with \( \textcolor[HTML]{27AAE1}{\nabla \log p_0(\vx_0)} \) such that the angle \( \alpha \leq 90^\circ \) (non-negative dot product).
}
    \label{fig:vfa-vis}
\end{figure*}

%We present diffusion models as differential equations, which unifies the major families of score-based diffusion \citep{song2021scorebased}, denoising probabilistic models \citep{ho2020denoising}, and flow matching \citep{lipman2023flow} (For discussion, see \citet{kingma2021variational,luo2022understanding}).

Let $\vx \in \R^D$. We assume spatial gradient $\nabla = (\frac{\partial}{\partial x_1}, \ldots, \frac{\partial}{\partial x_D})^T \in \R^D$, divergence $\div = \sum_d \frac{\partial}{\partial x_d} \in \R$, and Laplacian $\Delta = \sum_d \frac{\partial^2}{\partial x_d^2} \in \R$ operators. We assume continuous time $t \in [0,T]$ between data $p_0$ and noise $p_T$.

\subsection{Continuous normalizing flows}

Continuous normalizing flows (CNFs) \citep{chen2018neural} are probabilistic models specified by a tractable prior distribution $p_T$ at terminal time $T$ and an ordinary differential equation (ODE)
\begin{equation}\label{eq:ode}
    d\vx_t = \vu_t(\vx_t)dt, 
\end{equation}
which samples by integrating %where we sample by solving \autoref{eq:ode} 
from $\vx_T \sim p_T$ at $t=T$ to $t=0$ by following the time-varying vector field $\vu_t : \R^D \mapsto \R^D$ with a solution
\begin{align} \label{eq:odesol}
    \vx_t := \vx_t(\vx_T) &= \vx_T + \int_{T}^{t} \vu_\tau(\vx_\tau) d\tau.
\end{align}
The flow family encompasses many popular generative frameworks, including diffusion/score-based models \citep{song2021scorebased}, flow matching \citep{lipman2023flow, tong2024improving}, rectified flows \citep{liu2023flow}, stochastic interpolants \citep{albergo2023building}, consistency models \citep{pmlr-v202-song23a}, and the denoising probabilistic models at continuous limit \citep{kingma2021variational}: the vector field $\vu_t$ is the denoiser. \nocite{zhi2021learning}

In a CNF we can evaluate the log-likelihood of a sample moving in \autoref{eq:ode} with tractable density evolution
%evolution of a given sample $\vx_t$ moving under \autoref{eq:ode} evolves by
%is performed with the instantaneous change of variables formula \citep{chen2018neural}, which states that for a sample evolving according to \autoref{eq:ode} we know the evolution of marginal log-density is given by
\begin{equation}\label{eq:insta-change-of-variables}
    \frac{d \log p_t(\vx_t)}{dt} = -\div \vu_t(\vx_t), %= \nabla^T \vu_t(\vx_t) =
    %\sum_{d=1}^D \frac{\partial [\vu_t(\vx_t)]_d}{\partial x_d},
\end{equation}
where $p_t$ is the marginal density of a process defined by \autoref{eq:ode}. 
\citet{karczewski2024diffusion} generalized this formula to enable tracking of the same marginal $p_t$ for a sample following a \emph{different} direction $d\vx_t = \tilde{\vu}_t(\vx_t)dt$ as
\begin{align}\label{eq:gen-insta-change}
        \frac{d \log p_t(\vx_t)}{dt} &= - \div \vu_t(\vx_t) \\
        & \quad \:\:\: + \nabla \log p_t(\vx_t)^T \Big(\tilde{\vu}_t(\vx_t) - \vu_t(\vx_t)\Big) \notag.
\end{align}
At $\tilde{\vu}_t = \vu_t$, this reduces back to \autoref{eq:insta-change-of-variables}. See \autoref{app:cnf} for detailed derivations.
%For instance, in classifier-free guidance (CFG) the vector field overemphasises the score \citep{karras2024guiding} with $\tilde{\vu} = w \vu$ for $w > 1$. %, but without tracking the density change.


%Furthermore, \citet{karczewski2024diffusion} generalized this formula to enable tracking the marginal density of a sample following an \emph{arbitrary} ODE $d\vtx_t=\Tilde\vu_t(\vtx_t)dt$ as long as have access to the score function $\nabla \log p_t(\vx)$:
%\begin{align}\label{eq:gen-insta-change}
%        \frac{d \log p_t(\vtx_t)}{dt} = - \div(\vu_t(\vtx_t)) + \nabla \log p_t(\vtx_t)^T (\Tilde\vu_t(\vtx_t) - \vu_t(\vtx_t))
%\end{align}

\subsection{Diffusion models}

A notable case of flow models are diffusion models given by a forward process $p_t(\vx_t|\vx_0)=\mathcal{N}(\alpha_t\vx_0,\sigma_t\mI_D)$, or equivalently, by a stochastic differential equation (SDE)
\begin{equation}\label{eq:sde}
    d\vx_t = f(t)\vx_tdt + g(t)d\rW_t
\end{equation}
with drift $f(t)=\frac{d \log \alpha_t}{dt}$, diffusion $g^2(t)=2\sigma_t^2 \frac{d \log \frac{\sigma_t}{\alpha_t}}{dt}$, and Wiener process $\rW_t$.
% The reverse SDE 
% \begin{equation}\label{eq:rev-sde}
%     d\vx_t = \Big(f(t)\vx_t - g^2(t) \nabla \log p_t(\vx_t) \Big) dt + g(t)d\overline{\rW}_t,
% \end{equation}
% shares marginals $p_t$ with the forward.
A CNF with drift 
\begin{align} \label{eq:pf-ode}
    \vu_t^\textsc{pf-ode}(\vx_t) = f(t)\vx_t - \frac{1}{2} g^2(t)\underbrace{\nabla \log p_t(\vx_t)}_{\text{score}}
\end{align}
shares marginals $p_t$ with \autoref{eq:sde} when $p_T$ are shared \citep{song2021scorebased}. This Probability-Flow ODE (PF-ODE) is an efficient, deterministic, sampler in diffusion models.

\subsection{Stochastic sampling and likelihood}

\citet{eijkelboom2024variational} pointed out that any CNF can be cast as an SDE model via the score function $\nabla \log p_t(\vx)$:\footnote{In \citet{eijkelboom2024variational}, the drift is: $\vu_t(\vx_t) + \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)$. This is caused by different conventions. We follow the diffusion literature \citep{song2021scorebased}, where time flows backward, i.e. $dt<0$ and the Wiener process runs in reverse during sampling. In \citet{eijkelboom2024variational} sampling is from $t=0$ to $t=1$ and $dt>0$.}
\begin{equation}\label{eq:fm-sde}
    d\vx_t = \Big(\vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)\Big) dt + \varphi(t) d\overline{\rW}_t,
\end{equation}
where $\overline{\rW}$ is the Wiener process going backward in time and the process defined by \autoref{eq:fm-sde} shares marginals with \autoref{eq:ode} for any choice of the variance term $\varphi$ as long as they share $p_T$. \citet{karczewski2024diffusion} demonstrated that for SDE models one can also track the evolution of marginal
\begin{align}\label{eq:log-density-sde}
    d \log p_t(\vx_t) &= F(t, \vx_t)dt + \varphi(t)\nabla \log p_t(\vx_t)^Td\overline{\rW}_t,
\end{align}
where
\begin{equation}
\begin{split}
    F(t, \vx) =& -\div \vu_t(\vx)  - \frac{1}{2}\varphi^2(t)\Delta \log p_t(\vx) \\
    & \quad - \frac{1}{2}\varphi^2(t) \| \nabla \log p_t(\vx) \|^2.
\end{split}
\end{equation}

\subsection{Neural network approximations}
In all our experiments, we assume access to pre-trained neural networks to approximate $\mathbf{u}_t$ and $\nabla \log p_t$. When estimating Jacobian-vector products such as $\frac{\partial \vu_t}{\partial \vx}\vv$, we leverage automatic differentiation to compute these efficiently with a single network pass.
To estimate divergence, such as $\Delta \log p_t(\vx) = \div \nabla \log p_t(\vx)$, we use the Hutchinson’s trick \citep{hutchinson1989stochastic,grathwohl2018ffjord} using a single Rademacher test vector.



\section{Scaling the latent code -- when and why?}\label{sec:scaling}

In this section we evaluate whether the simple latent rescaling approach of \citet{song2021scorebased} is sufficient to control for sample density, and demonstrate its shortcomings.

\citet{song2021scorebased} observed that scaling the latent noise $\vx_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ down with $\beta < 1$ monotonically decreases the amount of detail in the decoded images $\vx_0^\textsc{pf-ode}(\beta \vx_T)$, while preserving the image semantics (See \autoref{fig:vfa-vis}).
Interestingly, \citet{karczewski2024diffusion} recently showed that the log-density $\log p_0(\vx_0)$ assigned by a diffusion model correlates with the amount of detail in the generated image.
%Most diffusion models use a Gaussian prior $p_T = \mathcal{N}(0, \sigma_T^2 \mI_D)$, whose score $\nabla \log p_T(\vx_T) = -\frac{\vx_T}{\sigma_T^2}$ simply reduces the latent norm towards zero. Thus scaling at $t=T$ is equivalent to minimizing (or maximizing) $\log p_T$. % by following its gradient.
Most diffusion models use a Gaussian noise $p_T = \mathcal{N}(\mathbf{0}, \mI_D)$, whose score $\nabla \log p_T(\vx_T) = -\vx_T$ simply reduces the latent norm towards zero. Thus (down)scaling at $t=T$ is equivalent to maximizing $\log p_T$. % by following its gradient.

These two observations suggest a simple hypothesis: 
\begin{tcolorbox}[colback=orange!10!white,colframe=orange!75!black]
\textbf{Prior guidance}: To increase (decrease) $\log p_0(\vx_0)$, it suffices to move $\vx_T$ in the positive (negative) direction of $\nabla \log p_T(\vx_T)$, and then decode.
\end{tcolorbox}

We are interested in studying whether (steepest) $\log p_T$ increase in latent $\vx_T$ leads to a monotonic increase in $\log p_0$ of the decoding $\vx_0(\vx_T)$ \autoref{eq:odesol}. To formalise this notion, we assume a latent curve $c : [0,1] \to \R^D$ at $t=T$, whose tangent is given by the score $c'(s) = \nabla \log p_T(c(s))$. A monotonic curve decoding has
\begin{align}
    \frac{d}{ds} \log p_0\Big(\vx_0\big(c(s)\big)\Big) \geq 0, \qquad \forall s,
\end{align}
which is equivalent to \emph{Score Alignment} (\autoref{app:vfa}):
\begin{equation}\label{eq:vfa}
    \mathrm{SA:} \quad \underbrace{\nabla \log p_0(\vx_0)^T}_{\text{decoding score}} \underbrace{ \frac{\partial \vx_0}{\partial \vx_T} \nabla \log p_T(\vx_T)}_{\text{push-forward score } \vv_0 \in \R^D} \ge 0,
\end{equation}
for all $\vx_T \in \R^D$, where $\vv_t(\vx_T)\coloneqq \frac{\partial \vx_t}{\partial \vx_T} \nabla \log p_T(\vx_T)$.
In \autoref{app:vfa} we show that \autoref{eq:vfa} always holds when $\vu_t$ is linear in $\vx$, as in trivial diffusion models. We also show that it does not hold in general by providing a counterexample.
See \autoref{fig:vfa-vis} for a visualisation.

To evaluate the SA \autoref{eq:vfa} we need to solve for $\vv_0$. We use sensitivity equations (i.e. forward differentiation) %we denote $\vv_t=D_\vx \phi(T, t)(\vx_T) \nabla \log p_T(\vx_T)$ and
%we leverage the sensitivity equation \citep{pontryagin,diehl2011numerical}:
\begin{equation}\label{eq:sensitivity}
    d\begin{bmatrix}
        \vx_t \\ \vv_t
    \end{bmatrix} = \begin{bmatrix}
        \vu_t(\vx_t) \\
        \frac{\partial \vu_t(\vx_t)}{\partial \vx} \vv_t
    \end{bmatrix}dt,
\end{equation}
with $\vv_T \coloneqq \nabla \log p_T(\vx_T)$ to describe the $\vv_t$ evolution, and specifically, to solve $\vv_0(\vv_T)$ \citep{baydin2018automatic}.

\begin{figure}[htb]
    \centering\includegraphics[width=0.99\linewidth]{figures/dot-product-empirical.png}
    \caption{\textbf{Nearly all $\vx_T$ satisfy the positive score alignment of \autoref{eq:vfa} across models and datasets.}}
    \label{fig:dot-product}
\end{figure}

\paragraph{Empirical demonstration}
To empirically verify whether SA holds, one can sample a large batch of $\vx_T \sim p_T$ and solve \autoref{eq:sensitivity} from $t=T$ to $t=0$\footnote{In practice, we solve until $t=\varepsilon$ for small $\varepsilon > 0$.} and check whether $\vv_0^T\nabla \log p_0(\vx_0) \geq 0$.
We demonstrate this on two models, a VP-SDE model trained on CIFAR-10 \citep{karczewski2024diffusion}, and EDM2, a conditional latent diffusion trained on ImageNet512 \citep{karras2024analyzing}.
We find that for CIFAR 97\% of the latent codes satisfy the equation and 100\% for EDM2 (\autoref{fig:dot-product}).
This shows that, in most cases, scaling the latent code $\vx_T$ impacts $\nabla \log p_0(\vx_0)$ monotonically, and thus explains the visual effect of low-level feature manipulation (\autoref{fig:forest}).
See \autoref{app:scaling-samples} for more samples.

\paragraph{Log-density vs FLIPD} \citet{kamkari2024geometric} recently proposed $\mathrm{FLIPD}$ - a method for measuring local intrinsic dimension and argued that it correlates strongly with the amount of detail (or information) in the image as measured by the size of PNG compression of the decoded image $\mathrm{PNG}(\vx_0)$.
In \autoref{fig:logp-vs-flipd} we show on a high resolution latent diffusion model EDM2 \citep{karras2024analyzing} that $-\log p_t(\vx_t)$ correlates with $\mathrm{PNG}(\vx_0)$ more strongly, reaching a maximum of 84\%, compared to 29\% achieved by $\mathrm{FLIPD}$.
Furthermore, we observed that the correlation of $-\log p_t(\vx_t)$ with $\mathrm{PNG}(\vx_0)$ is the strongest not for $t \approx 0$, but rather $t \approx 0.6$ corresponding to $\log\mathrm{SNR}(t)=\log\frac{\alpha_t^2}{\sigma_t^2}=1$.
This suggests that for detail manipulation with Prior Guidance, verification of the SA condition \autoref{eq:vfa} should be done up to this value of $t$ rather than $t=0$.

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/logp-vs-flipd-correlation.png}
    \caption{\textbf{Negative $\log p_t(\vx_t)$ correlates well with image compression size}, while the recently proposed intrinsic dimensionality measure FLIPD \citep{kamkari2024geometric} correlates weakly. Experiment performed for a latent diffusion model EDM2 trained on ImageNet $512 \times 512$ resolution \citep{karras2024analyzing}.}
    \label{fig:logp-vs-flipd}
\end{figure}
\paragraph{What if score is unknown?}
To verify SA, one needs to solve \autoref{eq:sensitivity} and estimate $\nabla \log p_0(\vx_0)$.
The latter is straightforward for diffusion models, but not in the general case of \autoref{eq:ode}.
Remarkably, it is also possible to evaluate $\vv_0^T \nabla \log p_0(\vx_0)$ for any flow model without estimating the score itself.
Concretely, in \autoref{app:vfa}, we show that for $\omega_t\coloneq \vv_t^T \nabla \log p_t(\vx_t)$,  $\frac{d}{dt} \omega_t = -\div (\frac{\partial \vu_t}{\partial \vx}(\vx_t)\vv_t)$.
Therefore, in absence of the score function, one can estimate $\omega_0$ by augmenting \autoref{eq:sensitivity} with $\dot{\omega}_t$ initialized at $\omega_T = \| \nabla \log p_T(\vx_T)\|^2$:
\begin{equation}\label{eq:aug-sensitivity}
    d\begin{bmatrix}
        \vx_t \\ \vv_t \\ \omega_t
    \end{bmatrix} = \begin{bmatrix}
        \vu_t(\vx_t) \\
        \frac{\partial \vu_t(\vx_t)}{\partial \vx} \vv_t \\
        -\div\big(\frac{\partial \vu_t(\vx_t)}{\partial \vx} \vv_t\big)
    \end{bmatrix}dt.
\end{equation}
In \autoref{fig:vfa-verification} we present the SA verification algorithm.
To empirically validate \autoref{eq:aug-sensitivity}, we used a VP-SDE CIFAR-10 diffusion model  \citep{karczewski2024diffusion}, sampled 256 latent codes $\vx_T$ and solved \autoref{eq:aug-sensitivity} from $t=T$ to $t$ corresponding to $\log\mathrm{SNR}(t)=1$.
This is a score-based model and thus we can compare the ground truth $\vv_t^T\nabla \log p_t(\vx_t)$ with the estimated $\omega_t$.
We found that their correlation was at 98.8\%.
See \autoref{fig:omega-vs-prod-cifar}.

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/cifar-omega-sa.png}
    \caption{\textbf{The augmented sensitivity equations of \autoref{eq:aug-sensitivity} accurately tracks the score alignment (SA).}}
    \label{fig:omega-vs-prod-cifar}
\end{figure}

\section{Density Guided Sampling}\label{sec:dgs}

\begin{figure}
\centering
        \begin{algorithm}[H]
            \caption{Score Alignment verification}
            \begin{algorithmic}[1]
                \STATE \textbf{input:} Flow $\vu_t$, latent $\vx_T \in \R^D$, step size $dt>0$
                \STATE \textbf{initialize} $\vv_T = \nabla \log p_T(\vx_T)$, $t=T$, \highlight{$\omega_T=\|\vv_T\|^2$}
                \WHILE{$t > 0$}
                    \STATE $d\vx \gets \vu_t(\vx_t)$ 
                    \STATE $d\vv \gets \mathrm{JVP}(\vu_t, \vx_t, \vv_t)$
                    \STATE \highlight{$\veps \gets \mathrm{Uniform}\{-1, 1\}^D$}\COMMENT{Rademacher variables}
                    \STATE \highlight{$d\omega \gets  - \veps^T \mathrm{JVP}(d\vv, \vx_t, \veps)$}\COMMENT{Hutchinson's trick}
                    \STATE $\vx_t \gets \vx_t - dt \cdot d\vx$
                    \STATE $\vv_t \gets \vv_t - dt \cdot d\vv$
                    \STATE \highlight{$\omega_t \gets \omega_t - dt \cdot d\omega$}
                    \STATE $t \gets t - dt$
                \ENDWHILE
                \IF{$\nabla \log p_0(\vx_0)$ known}
                    \STATE \textbf{return} $\nabla \log p_0(\vx_0)^T \vv_0$
                \ELSE 
                    \STATE \highlight{\textbf{return} $\omega_0$}
                \ENDIF
            \end{algorithmic}
        \end{algorithm}
        \caption{%
    \textbf{Score Alignment Verification.} When the score $\nabla \log p_0$ is known, \autoref{eq:sensitivity} applies, and the \highlight{highlighted steps} (corresponding to \autoref{eq:aug-sensitivity}) can be omitted. We provide JAX implementation in \autoref{lst:jax_score_alignment}.}
    \label{fig:vfa-verification}
\end{figure}

In \autoref{sec:scaling} we discussed ways to determine whether scaling the latent code corresponds to changing $\log p_0(\vx_0)$.
In particular, we showed that the necessary SA condition \autoref{eq:vfa} does not always hold. Furthermore, the prior guidance does \emph{not} allow choosing the desired sample log-density.

We now present an approach for sampling $\vx_0$ with explicit control of $\log p_0(\vx_0)$. 
Suppose that we require an instantaneous density changes over time,
\begin{equation}\label{eq:log-density-evolution}
    \hspace{-10mm} \text{constraint:} \qquad \frac{d \log p_t(\vx_t)}{dt} = b_t(\vx_t) \quad \in \R
\end{equation}
for a predetermined $b_t$. To achieve this, we choose a new ODE $d\vx_t = \tilde{\vu}_t dt$, such that its density change from \autoref{eq:gen-insta-change} satisfies
\begin{equation}\label{eq:steering_general_ode}
        b_t(\vx_t) = \nabla \log p_t(\vx_t)^T \Big( \Tilde\vu_t(\vx_t) - \vu_t(\vx_t)\Big) - \div \vu_t(\vx_t).
\end{equation}
Whenever $\nabla \log p_t(\vx_t) \neq \mathbf{0}$, \autoref{eq:steering_general_ode} has multiple solutions of $\tilde\vu$ for any $b_t$.
We choose $\tilde\vu$ that is closest to $\vu$, which uniquely gives (See \autoref{app:steering-deriv})
\begin{equation}\label{eq:steering-unique-ode}
    \Tilde\vu_t(\vx) = \vu_t(\vx) + \underbrace{\frac{\div \vu_t(\vx) + b_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}}_{\text{score bias } s_b(\vx)} \nabla \log p_t(\vx).
\end{equation}
\begin{tcolorbox}[colback=orange!10!white, colframe=orange!75!black]
\textbf{Density guidance:} \autoref{eq:steering-unique-ode} steers the sample away from the original trajectory towards desired likelihood.
\end{tcolorbox}
When $b_t = -\div \vu_t$, we reduce to the canonical sampler $\Tilde\vu_t =\vu_t$.
Since using \autoref{eq:steering-unique-ode} requires knowing the score function, we assume from this point on that $\vu_t$ is given by the PF-ODE of a diffusion \autoref{eq:pf-ode}, which is transformed by \autoref{eq:steering-unique-ode} into
\begin{align} \label{eq:pg-ode}
    \Tilde\vu_t(\vx_t) = f(t)\vx_t + \left( s_b(\vx_t) - \frac{1}{2} g^2(t) \right)\nabla \log p_t(\vx_t),
\end{align}
which can readily be used for sampling for any $b$.

The question is: How to choose $b_t$? Notably, we cannot simply push $b_t$ to be arbitrarily high or low, since it will fall off the diffusion manifold, leading to nonsense decodings.

\subsection{Explicit quantile matching}

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/cifar_typical_logp.png}
    \caption{Quantiles and typical values of $\log p_t(\vx_t)$ for a diffusion model trained on CIFAR10.}
    \label{fig:cifar-quantiles}
\end{figure}

Suppose that we want $\vx_0$ to have a pre-defined value of log-density $\log p_0(\vx_0) = c \in \R$, which is equivalent to
\begin{equation}\label{eq:int-cond}
    \int_0^T b_t(\vx_t)dt = \log p_T(\vx_T) - c.
\end{equation}
If this holds for $b$, the \autoref{eq:steering-unique-ode} will generate a sample $\vx_0$ with the log-density $c$.
However, not all choices of $b$ are equally good.
In practice, $\vu$ and $\nabla \log p_t$ are approximated with neural networks, and their predictions are only accurate when $\vx_t$ is in the typical region of $p_t$ \citep{nalisnick2020detecting}.


Suppose that the target value $c$ is the $q$'th quantile of $\log p_0$, where $q \in [0,1]$.
A simple strategy is to choose $b_t$ such that the sample $\vx_t$ remains on the same quantile $q$ over all times $t$ and $p_t$.
Let $\phi_t(q)$ denote the $q$-th quantile of $\log p_t$.
Then
\begin{equation}
    \log p_t(\vx_t) = \log p_T(\vx_T) - \int_t^T b_\tau(\vx_\tau)d\tau = \phi_t(q),
\end{equation}
which is satisfied for $b_t(\vx) \coloneq \frac{d}{dt} \phi_t(q)$. The quantile function $\phi_t(q)$ can be estimated by sampling $K$ independent samples $\vx_T \sim p_T$, estimating $\log p_t(\vx_t)$ with \autoref{eq:insta-change-of-variables} and finding empirical quantiles for target values of $q$.
We visualize $\phi_t(0.99)$ and $\phi_t(0.01)$ in \autoref{fig:cifar-quantiles} estimated for a Variance-Preserving (VP) SDE diffusion model with linear log-$\mathrm{SNR}$ schedule trained on CIFAR10.

\begin{figure}
    \centering
    \includegraphics[width=0.99\linewidth]{figures/classes_densities.jpg}
    \caption{\textbf{Different classes have different likelihoods.} Left: Distributions of log-likelihoods of 16 randomly selected classes from ImageNet. Right: Distributions of log-likelihoods for ``fox" and ``whistle" differ significantly.}
    \label{fig:class-densities}
\end{figure}

\subsection{Implicit quantile matching}

A considerable drawback of explicit quantile matching is the need to estimate $\phi_t$.
This becomes especially problematic for conditional generation, where the distribution of $\log p_t$ can differ significantly for different classes (\autoref{fig:class-densities}).
For applications such as text-to-image, this would require estimating the distribution of $\log p_t$ for every possible text prompt, which is not feasible.

\begin{figure*}[bt]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/deterministic_steering_edm2_samples.jpg}
    \caption{\textbf{Density Guidance controls the amount of detail.} Samples generated with \autoref{eq:dgs} using the EDM2 model \citep{karras2024analyzing}.}
    \label{fig:deterministic-steering}
\end{figure*}

The \autoref{eq:steering_general_ode} gives a recipe for altering the flow based on how we want $\log p_t(\vx_t)$ to evolve.
However, the challenge is to determine what are the \emph{reasonable} values of $b_t$ so that $\log p_t$ does not deviate from what is typical.
We tackle this problem by analyzing the stochastic view of CNFs.
Specifically, for $\vx_t \sim p_t$, \autoref{eq:fm-sde} says that when evaluating $\vx_{t-dt}$, we can add random noise and stay within the typical region of $p_{t-dt}$ as long as we correct for it by subtracting the score from the drift.
Furthermore, \autoref{eq:log-density-sde} says how $\log p_t$ changes under this stochastic evolution.

Concretely, the \emph{average} change in log-density, when adding noise of strength $\varphi(t)$ is given by
\begin{equation}\label{eq:typical-log-p}
    \E\big[ d \log p_t(\vx_t)\big] = - \left(\div \vu_t(\vx_t) + \frac{1}{2}\varphi^2(t) h(\vx_t) \right) dt,
\end{equation}
where $h(\vx)=\Delta \log p_t(\vx) + \| \nabla \log p_t(\vx)\|^2 \in \R$.
Interestingly, in \autoref{app:asymptotic}, we empirically (and theoretically in simplified cases) show that in diffusion models $\frac{\sigma_t^2 h(\vx_t)}{\sqrt{2D}}$ approximately follows $\mathcal{N}(0, 1)$ when $\vx_t \sim p_t$ and dimension $D$ is high.
A reasonable choice is then
\begin{equation}
    b_t(\vx) = -\div \vu_t(\vx) - \frac{1}{2}\varphi^2(t) \frac{\sqrt{2D}}{\sigma_t^2} \Phi^{-1}(q),
\end{equation}
where $\Phi$ is the cumulative distribution function of $\mathcal{N}(0, 1)$ and $q$ is the desired quantile.
We found that choosing $\varphi$ to match the diffusion strength in \autoref{eq:sde}, i.e. $\varphi\equiv g$ works well in practice.
Thus, in our experiments we use
\begin{equation}\label{eq:b-quantile}
    b^q_t(\vx) = -\div \vu_t(\vx) - \frac{1}{2}g^2(t) \frac{\sqrt{2D}}{\sigma_t^2} \Phi^{-1}(q).
\end{equation}
After plugging this definition of $b$ to \autoref{eq:steering-unique-ode}, we get
\begin{equation}\label{eq:dgs}
\vu^\textsc{dg-ode}_t(\vx_t) = f(t)\vx_t - \frac{1}{2}g^2(t)\eta_t(\vx_t)\nabla \log p_t(\vx_t),
\end{equation}
which is equivalent to simply rescaling the score by
\begin{equation}\label{eq:quantile-score-scaling}
\eta_t(\vx)=1 + \frac{\sqrt{2D}\Phi^{-1}(q)}{\| \sigma_t \nabla \log p_t(\vx) \|^2}.
\end{equation}
We call \autoref{eq:dgs} \emph{Density-Guided Sampling} (DGS).
Importantly, DGS comes at no extra cost since the score is evaluated at each sampling step anyway.
Note that, as shown in \autoref{fig:logp-vs-flipd}, the correlation of $\log p_t(\vx_t)$ with image detail is the strongest for $t^* \approx \log \mathrm{SNR}^{-1}(1)$ and thus in our experiments we only use guidance in the $[T, t^*]$ interval.
In \autoref{fig:deterministic-steering} we show samples generated with DGS with different values of $q$.
Interestingly, the samples are perceptually very similar to those from Prior Guidance (\autoref{app:scaling-samples}).
\paragraph{Conditional generation}
Whenever a conditional score function $\nabla \log p_t(\vx | \mathrm{cond} )$ is available, where $\mathrm{cond}$ can be any condition (class, text, etc.), one need only replace the score function with the conditional one in \autoref{eq:dgs}.

\begin{figure*}[bt]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/stochastic_steering_edm2_samples.jpg}
    \caption{\textbf{Stochastic density guidance increases variation in generated samples whilst maintaining the desired level of detail.} Samples generated with \autoref{eq:stochastic-steering}. Adding stochasticity early in the sampling process changes high-level features, whereas adding noise later, only affects lower-level detail.}
    \label{fig:stochastic-steering}
\end{figure*}

\section{Stochastic density guidance}\label{sec:sold}

In previous sections we discussed two methods for controlling $\log p_0(\vx_0)$ during ODE sampling of form \autoref{eq:ode}.
However, it has been reported that adding stochasticity during sampling can improve sample quality \citep{song2021scorebased, karras2022elucidating}.
Neither of the previously discussed methods supports stochastic sampling. Recently \citet{karczewski2024diffusion} lifted the first roadblock towards this by showing how to \emph{evaluate} $\log p_0(\vx_0)$ for an SDE. We now ask: Is it possible to also \emph{control} $\log p_0(\vx_0)$ during stochastic sampling?

Recall a stochastic CNF sampler with noise strength $\varphi$:
\begin{equation}\tag{\ref{eq:fm-sde}}
d\vx_t = \Big(\vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)\Big) dt + \varphi(t) d\overline{\rW}_t.
\end{equation}
In \autoref{app:sold}, we show that, similarly to density guidance \autoref{eq:dgs}, it can be altered to enforce the desired evolution of log-density over time.
Specifically, suppose that $\vu_t=\vu_t^{\textsc{PF-ODE}}$ and that we require $\frac{d \log p_t(\vx_t)}{dt} = b_t(\vx_t)$ for $b$ defined in \autoref{eq:b-quantile}. 
Then, the stochastic process
\begin{equation}\label{eq:stochastic-steering}
d \vx_t =\vu_t^\textsc{dg-sde}(\vx_t)dt + \varphi(t)P_t(\vx_t)d\overline{\rW}_t
\end{equation}
\emph{approximately} satisfies $\frac{d \log p_t(\vx_t)}{dt} = b_t(\vx_t)$, where
\begin{align}
\vu^\textsc{dg-sde}_t(\vx) &= \vu^\textsc{dg-ode}_t(\vx) \\
 & + \underbrace{\frac{1}{2}\varphi^2(t)\frac{\Delta \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}\nabla \log p_t(\vx)}_{\text{correction for added stochasticity}}
\end{align}
and
\begin{equation}
\hspace{-1.5mm} P_t(\vx) = \mI_D - \left(\frac{\nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|}\right) \hspace{-1mm} \left(\frac{\nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|}\right)^T
\end{equation}
is the ``score-orthogonal" projection, which ensures that the $\log p_t(\vx_t)$ changes deterministically even though $\vx_t$ is stochastic.
In \autoref{app:sold} we provide the formula \autoref{eq:general-sde-steering} of the SDE drfit that \emph{exactly} achieves $d \log p_t(\vx_t)=b_t(\vx_t)dt$ for any choice of $b_t$ and $\vu_t$, which we omit here for presentation clarity.

The \autoref{eq:stochastic-steering} allows increasing variation in the samples by injecting noise to DGS \autoref{eq:dgs} whilst maintaining the desired evolution of the log-density.
Furthermore, since it is known that diffusion models first generate high-level features and then the details \citep{ho2020denoising, deja2022analyzing, wang2023diffusion}, DGS can be combined with stochasticity by introducing noise at specific stages of the generation process, allowing for controlled variation in either high- or low-level features while preserving the desired level of detail.
We demonstrate this approach in \autoref{fig:stochastic-steering}.

\section{Related Work}\label{sec:related-work}

\citet{sehwag2022generating} proposed a method for generating samples from low-density regions of diffusion models. However, due to the intractability of likelihood in diffusion models, their approach relies on approximations. Subsequent work by \citet{karczewski2024diffusion} demonstrated that likelihood is, in fact, tractable even in stochastic diffusion models, challenging the need for such approximations. Building on this, our proposed methods provide explicit likelihood control for both deterministic sampling—via Prior Guidance (\autoref{sec:scaling}) and Density Guidance (\autoref{sec:dgs})—and stochastic sampling through Stochastic Density Guidance (\autoref{sec:sold}).

\citet{song2021scorebased} observed that scaling the latent code alters the amount of detail in deterministically generated images.
While this phenomenon has been widely acknowledged, we provide a rigorous analysis (\autoref{sec:scaling}) and prove that it is a direct consequence of Score Alignment \autoref{eq:vfa}, which guarantees that scaling leads to a monotonic change in the likelihood of the generated image, $\log p_0(\vx_0)$.
Furthermore, we introduce tractable numerical tools (\autoref{fig:vfa-verification}) that can verify whether any given CNF model (not necessarily score-based) exhibits this behavior.

\citet{karras2024guiding} proposed auto-guidance as a method for improving sample quality by targeting high-density regions. However, \citet{karczewski2024diffusion} found that the highest-density regions in diffusion models contain cartoon-like or blurry images, which raises concerns about the effectiveness of purely maximizing likelihood. In contrast, we introduce multiple cost-free methods for explicitly controlling the likelihood of generated samples. Additionally, while \citet{karras2024guiding} observed that scaling the score function leads to oversimplified images, we demonstrate that DGS \autoref{eq:dgs} enables effective control over image detail—both increasing and decreasing it—when the scaling is adapted both temporally and spatially \autoref{eq:quantile-score-scaling}.

\citet{yu2023scalable} introduced Riemannian Langevin Dynamics, an SDE with a non-diagonal diffusion matrix, similar in structure to our Stochastic Density Guidance (\autoref{sec:sold}). However, a key distinction is that our diffusion matrix is a projection onto the orthogonal complement of the subspace spanned by the score function. As a result, it is not positive definite and cannot serve as a Riemannian metric tensor, making our approach fundamentally different in its mathematical formulation and behavior.

Recently, \citet{kamkari2024geometric} proposed a method for measuring local intrinsic dimension, which, in the case of images, corresponds to the amount of detail present. However, we show that negative $\log p$ is a more effective measure of image detail and provide empirical comparisons in \autoref{fig:logp-vs-flipd}. Moreover, while \citet{kamkari2024geometric} focus on measuring image detail, our methods enable direct manipulation of it, allowing for finer control over generative model outputs.

\section{Conclusion}\label{sec:conclusion}

In this paper, we introduced methods for controlling sample density in flow models, enabling manipulation of image detail through likelihood-guided sampling. We provided a theoretical explanation of latent code scaling by introducing score alignment, a condition that can be tractably checked for any CNF model. Building on this, we derived Density Guidance, a principled modification of the generative ODE that allows for exact log-density control during sampling. Finally, we extended this approach to stochastic sampling, demonstrating that it retains precise detail control while allowing controlled variation in image structure and detail. Our findings deepen the understanding of likelihood in flow models and provide practical tools for better sample control. 

\section{Impact Statement}\label{sec:impact}
This paper presents work that advances the understanding and controllability of sample density in diffusion-based generative models. By introducing techniques for precise log-density control, our work contributes to improved interpretability and fine-grained control over image generation. While these advancements could enhance applications in creative and scientific domains, they also raise considerations around synthetic media generation and potential misuse. However, our contributions primarily aim at improving theoretical understanding and control in generative modeling, without introducing new ethical risks beyond those already associated with generative AI.

% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}


\bibliography{refs}
\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Auxiliary results}\label{app:aux}
\subsection{Constrained optimization}\label{app:constr}
In multiple sections, we will be solving constrained optimization problems, which can be written in the following way.
Suppose $\vv \in \R^D$, $\vv \neq \mathbf{0}$, any $\vy \in \R^D$ and $a \in \R$.
The problem we will encounter is
\begin{equation}\label{eq:constrained-opt}
\begin{split}
    &\min_{\vx \in \R^D}\frac{1}{2}\| \vx - \vy\|^2 \\
    &\text{s.t.} \quad \vx^T\vv = a.
\end{split}
\end{equation}
We solve this by introducing the Lagrangian $\mathcal{L}(\vx, \lambda)=\frac{1}{2}\| \vx - \vy\|^2 + \lambda (\vx^T\vv - a)$ for $\lambda \in \R$.
By setting $\frac{\partial \mathcal{L}}{\partial \vx}=\mathbf{0}$, we get
\begin{equation}
\vx - \vy + \lambda \vv = 0 \Rightarrow \vx = \vy - \lambda \vv.
\end{equation}
To find $\lambda$ we substitute for $\vx$ in the constraint and find
\begin{equation}
\vy^T\vv - \lambda \| \vv \|^2 = a \Rightarrow \lambda = \frac{\vy^T\vv - a}{\| \vv \|^2}.
\end{equation}
Combining the two, we get that the solution is given by
\begin{equation}
\vx = \vy + \frac{a - \vv^T\vy}{\| \vv \|^2}\vv.
\end{equation}
\subsection{Divergence-gradient identity}\label{app:div-id}
We will make use of an identity connecting the gradient of the divergence with the divergence of a Jacobian vector product.
\begin{lemma}
Let $f: \R^D \to \R^D$  with continuous 2-nd order derivatives and $\vv \in \R$.
Define $g(\vx) \coloneqq \div f(\vx) = \sum_{i=1}^D \frac{\partial f^i}{\partial x_i}(\vx)$ and $G(\vx) \coloneqq \frac{\partial f}{\partial \vx}(\vx)\vv$.
Then $g:\R^D \to \R$ is a scalar function and $G:\R^D \to \R^D$ is a vector function satisfying
\begin{equation}
\nabla g(\vx)^T\vv = \div G(\vx).
\end{equation}
Equivalently, we write it as
\begin{equation}\label{eq:div-identity}
\left( \nabla \div f(\vx)\right)^T\vv = \div \left( \frac{\partial f}{\partial \vx}(\vx)\vv \right)
\end{equation}
\end{lemma}
\begin{proof}
\begin{align*}
\nabla g(\vx)^T\vv &= \sum_{j=1}^D \frac{\partial g}{\partial x_j}(\vx) v_j = \sum_{j=1}^D \frac{\partial }{\partial x_j} \left( \sum_{i=1}^D \frac{\partial f^i}{\partial x_i}(\vx)\right)v_j = \sum_{i=1}^D \frac{\partial }{\partial x_i} \left(\sum_{j=1}^D \frac{\partial f^i}{\partial x_j}v_j \right) = \sum_{i=1}^D \frac{\partial }{\partial x_i} \left(\frac{\partial f}{\partial \vx}(\vx)\vv \right)_i \\
& = \sum_{i=1}^D \frac{\partial }{\partial x_i} G^i(\vx) = \div G(\vx).
\end{align*}
\end{proof}
\subsection{Optimality of projection}\label{app:proj-opt}
In \autoref{app:sold} we will be interested in finding a linear operator $\mA \in \R^{D \times D}$ satisfying $\mA\vv=\mathbf{0}$ for some $\vv$, so that the distance between $\mA$ and the identity $\mI_D$ is minimal.
The following lemma provides a solution.
\begin{lemma}\label{lem:proj-opt}
Let $\mathbf{0} \neq \vv \in \R^D$.
The solution of
\begin{equation}
\begin{split}
&\min_{\mA \in \R^{D \times D}} \|\mA - \mI_D\| \\
& \text{s.t. } \mA\vv=\mathbf{0},
\end{split}
\end{equation}
where $\| \cdot  \|$ can be either the spectral or Frobenius norm, is given by the projection matrix
\begin{equation}
\mA^{\textsc{opt}} = \mP = \mI_D - \left( \frac{\vv}{\|\vv\|} \right)\left( \frac{\vv}{\|\vv\|} \right)^T.
\end{equation}
\end{lemma}
\begin{proof}
First note that for any $\mA \in \R^{D \times D}$ satisfying $\mA\vv=\mathbf{0}$, we have
\begin{equation}
\| \mA - \mI_D \|_F \geq \| \mA - \mI_D\|_2 = \max_{\vw \neq 0} \left| \frac{\vw^T (\mA - \mI_D) \vw}{\|\vw\|^2} \right| \geq \left| \frac{\vv^T (\mA - \mI_D) \vv}{\|\vv\|^2} \right| = \left| \frac{\vv^T (0 - \vv)}{\|\vv\|^2} \right| = \frac{\vv^T \vv}{\|\vv\|^2} = 1.
\end{equation}
On the other hand $\mP - \mI_D = \left( \frac{\vv}{\|\vv\|} \right)\left( \frac{\vv}{\|\vv\|} \right)^T$, which has only a single non-zero eigenvalue $\lambda = 1$ and thus
\begin{equation}
\| \mP - \mI_D \|_F = \| \mP - \mI_D\|_2 = 1
\end{equation}
and
\begin{equation}
\mP\vv = \vv - \frac{\vv^T\vv}{\| \vv\|^2} \vv = \mathbf{0}.
\end{equation}
Therefore $\mA = \mP$ satisfies $\mA\vv=\mathbf{0}$ and minimizes both $\| \mA - \mI_D\|_2$ and $\| \mA - \mI_D\|_F$.
\end{proof}
\section{Derivation of CNF density evolutions}\label{app:cnf}

We reproduce the continuous-time normaling flow (CNF) density evolution of \citet{chen2018neural},
\begin{align}
    \frac{d\log p_t(\vx_t)}{dt} &= -\operatorname{div} \vu_t(\vx_t),
\end{align}
and the generalised CNF density evolution of \citet{karczewski2024diffusion},
\begin{align}
    \frac{d\log p_t(\vx_t)}{dt} &= -\operatorname{div} \vu_t(\vx_t) + \nabla \log p_t(\vx_t)^T (\tilde\vu_t(\vx_t) - \vu_t(\vx_t)),
\end{align}
with a unified derivation.

We assume a time-dependent particle $\vx_t \in \R^D$ evolving through continuous time $t \in \R$ governed by an ordinary differential equation (ODE)
\begin{align}
    \frac{d\vx_t}{dt} &= \vu_t(\vx_t),
\end{align}
where $\vu_t(\vx) : \R \times \R^D \mapsto \R^D$ is a time-dependent vector field that maps any state vector $\vx$ to its time derivative vector $\vu_t(\vx_t)$.

\paragraph{CNF density evolution}
We are interested in the time evolution of the spatiotemporal log-likelihood $\log p_t(\vx_t)$ for particles evolving under the ODE. 
We write the log density total derivative wrt time by using the chain rule
\begin{align}
    \frac{d \log p_t(\vx_t)}{dt} &= \frac{1}{p_t(\vx_t)} \frac{d p_t(\vx_t)}{dt} \\
    &= \frac{1}{p_t(\vx_t)} \left( \frac{\partial p_t(\vx_t)}{\partial t} + \frac{\partial p_t(\vx_t) }{\partial \vx} \cdot \frac{d \vx_t }{d t} \right),
\end{align}
which describes the density evolution of a particle moving under a flow.
We assume that the ODE is a continuous-time normalizing flow, where the density is conserved over time. This is described by the continuity equation \citep{finlay2020learning,xu2024normalizing}
\begin{align}\label{eq:cont-eq}
    \frac{\partial p_t(\vx_t)}{\partial t} + \nabla \cdot \Big(p_t(\vx_t) \vu_t(\vx_t)\Big) = 0,
\end{align}
which describes the change in particle density as a result of a vector field $\vu_t$ transporting the particles, at location $\vx$. By substitution we obtain
\begin{align}
    \frac{d \log p_t(\vx_t)}{dt} &= \frac{1}{p_t(\vx_t)} \Big( -\nabla \cdot (p_t(\vx_t) \vu_t(\vx_t)) + \nabla p_t(\vx_t) \cdot \vu_t(\vx_t) \Big) \\
    &= \frac{1}{p_t(\vx_t)} \Big( - p_t(\vx_t) \nabla \cdot \vu_t(\vx_t) - \nabla p_t(\vx_t) \cdot \vu_t(\vx_t) + \nabla p_t(\vx_t) \cdot \vu_t(\vx_t) \Big) \\
    &= - \frac{1}{p_t(\vx_t)} p_t(\vx_t) \nabla \cdot \vu_t(\vx_t) \\
    &= - \nabla \cdot \vu_t(\vx_t) \\
    &= - \operatorname{div} \vu_t(\vx_t).
\end{align}

\paragraph{Generalised CNF density evolution}
Next, we derive the evolution of log-density $\log p_t$ of a particle that is moving in some non-canonical direction, ie. $\dot{\vx}_t = \tilde{\vu}_t(\vx_t) \not = \vu_t(\vx_t)$. Notably, the continuity equation remains with the $\vu_t$ as we are describing the particle density in the marginal induced by the original transport $\vu_t$. We obtain 
\begin{align}
    \frac{d \log p_t(\vx_t)}{dt} &= \frac{1}{p_t(\vx_t)} \left( -\nabla \cdot \Big(p_t(\vx_t) \vu_t(\vx_t)\Big) + \nabla p_t(\vx_t) \cdot \tilde\vu_t(\vx_t) \right) \\
    &= \frac{1}{p_t(\vx_t)} \Big( - p_t(\vx_t) \nabla \cdot \vu_t(\vx_t) - \nabla p_t(\vx_t) \cdot \vu_t(\vx_t) + \nabla p_t(\vx_t) \cdot \tilde\vu_t(\vx_t) \Big) \\
    &= \frac{1}{p_t(\vx_t)} \Big( - p_t(\vx_t) \nabla \cdot \vu_t(\vx_t) + \nabla p_t(\vx_t) \cdot \Big( \tilde\vu_t(\vx_t) - \vu_t(\vx_t)\Big) \Big) \\
    &= - \nabla \cdot \vu_t(\vx_t) + \frac{1}{p_t(\vx_t)} \nabla p_t(\vx_t) \cdot \Big( \tilde\vu_t(\vx_t) - \vu_t(\vx_t)\Big) \\
    &= - \operatorname{div} \vu_t(\vx_t) +  \nabla \log p_t(\vx_t) \cdot \Big( \tilde\vu_t(\vx_t) - \vu_t(\vx_t)\Big),
\end{align}
which is the generalised instantaneous change of density.

\section{Derivation of Score Alignment}\label{app:vfa}

In this section, we prove the Score Alignment condition, a necessary and sufficient condition for prior guidance to be effective in controlling $\log p_0$.
Formally, assume a latent curve $c : [0, 1] \to \R^D$ following the score at $t=T$, $c'(s)=\nabla \log p_T(\vx_0(c(s)))$. In a Gaussian prior $p_T$ the curve becomes a line of scaled latents $\vx_T$. 
The $\log p_0$ is monotonic on the decoded curve when
\begin{equation}\label{eq:monotonocity}
\frac{d}{ds} \log p_0(\vx_0(c(s))) \geq 0, \qquad \forall s \in (0, 1).
\end{equation}
The chain rule gives the derivative
\begin{align}
\frac{d}{ds} \log p_0(\vx_0(c(s))) &= \nabla \log p_0(\vx_0(c(s)))^T \frac{d}{ds} \vx_0(c(s)) \\
&= \nabla \log p_0(\vx_0(c(s)))^T \frac{\partial \vx_0}{\partial \vx_T}(c(s))c'(s) \\
&= \nabla \log p_0(\vx_0(c(s)))^T \frac{\partial \vx_0}{\partial \vx_T}(c(s))\nabla \log p_T(c(s))
\end{align}
Therefore, for \autoref{eq:monotonocity} to hold for a curve passing through some arbitrary $\vx_T \in \R^D$ at some point $s \in (0, 1)$ it must hold
\begin{equation}\label{eq:vfa-app}
\nabla \log p_0(\vx_0(\vx_T))^T \frac{\partial \vx_0}{\partial \vx_T}(\vx_T)\nabla \log p_T(\vx_T) \geq 0,
\end{equation}
where in \autoref{eq:vfa} we omit the $\vx_T$ in the parentheses for brevity. 

\subsection{Score alignment time evolution}\label{app:sa-alt}

In this subsection, we derive \autoref{eq:aug-sensitivity}, i.e. how the SA condition can be checked without knowing $\nabla \log p_t$ for $t < T$.
Let $c$ be a latent curve following the score and passing through $\vx_T$, i.e. $c: (-\varepsilon, \varepsilon) \to \R^D$, $c'(s) = \nabla \log p_T(c(s))$ and $c(0)=\vx_T$.
Define
\begin{equation}
\psi(t, s) \coloneqq \log p_t(\vx_t(c(s))) \: \text{for } t \in [0, T], \ s \in (-\varepsilon, \varepsilon).
\end{equation}
The SA condition at $\vx_T$ (\autoref{eq:vfa-app}) is given by
\begin{equation}\label{eq:psi-vfa}
\frac{\partial \psi}{\partial s}(0, 0) = \nabla \log p_0(\vx_0(\vx_T))^T \frac{\partial \vx_0}{\partial \vx_T}(\vx_T)\nabla \log p_T(\vx_T).
\end{equation}
Note that
\begin{equation}
\frac{\partial \psi}{\partial s}(T, 0) =  \frac{d}{ds} \log p_T(c(s)) \bigg\rvert_{s=0}= \nabla \log p_T(c(s))^T c'(s) \bigg\rvert_{s=0} = \| \nabla \log p_T(\vx_T) \|^2.
\end{equation}
Therefore \autoref{eq:psi-vfa} can be equivalently written as 
\begin{equation}\label{eq:psi-int}
\frac{\partial \psi}{\partial s}(0,0) = \frac{\partial \psi}{\partial s}(T,0) + \left( \frac{\partial \psi}{\partial s}(0,0) - \frac{\partial \psi}{\partial s}(T,0)\right) = \| \nabla \log p_T(\vx_T) \|^2 + \int_T^0 \frac{\partial^2 \psi}{\partial t \partial s}(t, 0)dt,
\end{equation}
where we applied the fundamental theorem of calculus.
We arrived at a seemingly more complex formula.
However, we can now swap the order of the derivatives (assuming that $\log p \in \mathcal{C}^2(\R \times \R^D)$ and $\vu \in \mathcal{C}^1(\R \times \R^D)$):
\begin{equation}
\frac{\partial^2 \psi}{\partial t \partial s}(t, s) = \frac{\partial^2 \psi}{\partial s \partial t}(t, s) = \frac{\partial }{\partial s} \left( \frac{\partial \psi}{\partial t}(t, s) \right).
\end{equation}
$\frac{\partial \psi}{\partial t}$ is given by \autoref{eq:insta-change-of-variables}:
\begin{equation}
\frac{\partial \psi}{\partial t}(t, s) = \frac{d}{dt} \log p_t(\vx_t(c(s))) = -\div \vu_t(\vx_t(c(s)))
\end{equation}
and by the chain rule and denoting $\nabla \div \vu_t$ the gradient of the scalar function $\vx \mapsto \div \vu_t (\vx)$:
\begin{align}
\frac{\partial^2 \psi}{\partial s \partial t}(t, s) &= \frac{d}{ds} -\div \vu_t(\vx_t(c(s))) \\
&= - \left(\nabla \div \vu_t(\vx_t(c(s)))\right)^T \frac{d}{ds} (\vx_t(c(s)) \\
&= - \left(\nabla \div \vu_t(\vx_t(c(s))) \right)^T \frac{\partial \vx_t}{\partial \vx_0}(c(s)) c'(s) \\
&= - \left(\nabla \div \vu_t(\vx_t(c(s))) \right)^T \frac{\partial \vx_t}{\partial \vx_0}(c(s)) \nabla \log p_T(c(s)).
\end{align}
After setting $s=0$ we get
\begin{align}
\frac{\partial^2 \psi}{\partial s \partial t}(t, 0) &= -\left(\nabla \div \vu_t(\vx_t(\vx_T)) \right)^T \underbrace{\frac{\partial \vx_t}{\partial \vx_0}(\vx_T) \nabla \log p_T(\vx_T)}_{=\vv_t(\vx_T)} \\
&= -\left(\nabla \div \vu_t(\vx_t(\vx_T)) \right)^T \vv_t(\vx_T) \\
&\stackrel{(\ref{eq:div-identity})}{=} -\div \left( \frac{\partial \vu_t}{\partial \vx}(\vx_t)\vv_t \right),
\end{align}
where $\vx_t=\vx_t(\vx_T)$ and $\vv_t = \vv_t(\vx_T)$.
After plugging into \autoref{eq:psi-int}:
\begin{equation}
\frac{\partial \psi}{\partial s}(0, 0) = \| \nabla \log p_T(\vx_T) \|^2 + \int_T^0 -\div \left( \frac{\partial \vu_t}{\partial \vx}(\vx_t)\vv_t \right) dt
\end{equation}
which after plugging into \autoref{eq:psi-vfa} becomes
\begin{equation}\label{eq:omega_def}
\nabla \log p_0(\vx_0)^T \frac{\partial \vx_0}{\partial \vx_T}\nabla \log p_T(\vx_T) = \| \nabla \log p_T(\vx_T) \|^2 + \int_T^0 -\div \left( \frac{\partial \vu_t}{\partial \vx}(\vx_t)\vv_t \right) dt
\end{equation}
and crucially, the score function for $t<T$ does not appear in the RHS, which can be estimated purely from derivatives of $\vu_t$.

\subsection{Score alignment holds in linear models}\label{app:sa-linear}
In this subsection, we show that the score alignment \autoref{eq:vfa} holds whenever $\vu_t(\vx_t)$ is linear in $\vx$.
Such models are for example linear-drift diffusion models with Gaussian data distribution $p_0$.
Score alignment is then an immediate consequence of \autoref{eq:omega_def}.
Specifically, when $\vu_t$ is linear in $\vx$, then $\frac{\partial \vu_t}{\partial \vx}\vv_t$ does not depend on $\vx$ and thus
\begin{equation}
\div \left( \frac{\partial \vu_t}{\partial \vx}\vv_t \right) = 0
\end{equation}
and 
\begin{equation}
\nabla \log p_0(\vx_0)^T \frac{\partial \vx_0}{\partial \vx_T}\nabla \log p_T(\vx_T) = \| \nabla \log p_T(\vx_T) \|^2 + \int_T^0 0dt = \| \nabla \log p_T(\vx_T) \|^2 \geq 0.
\end{equation}

\subsection{SA does not always hold}
We provide a simple example, for which the Score Alignment condition fails and thus Prior Guidance does not lead to monotonic changes in $\log p_0(\vx_0)$.
We study a 2-dimensional Gaussian mixture distribution with three components: $p_0 = \frac{1}{3}\sum_{i=1}^3 \mathcal{N}(\mu_i, 0.005 \mI_2)$, where $\mu_1 = [-0.3502, -0.6207]^T$, $\mu_2=[-0.4828,  1.0680]^T$ and $\mu_3 = [-0.7789,  0.7565]^T$ ($\mu_i$ we randomly chosen).

We found two latent codes $\mathbf{z}_1 = [1.3166, -0.2252]^T$ and $\mathbf{z}_2 = [-0.1504, -0.2165]^T$ exhibiting inconsistent behaviour.
Specifically, when $\vx_T = \sigma_T \mathbf{z}_1$, scaling up by 1.22 \emph{decreases} $\log p_0(\vx_0)$, while for $\vx_T =  \sigma_T \mathbf{z}_2$ the same scaling \emph{increases} $\log p_0(\vx_0)$.
We visualize this in \autoref{fig:gm-sa-failure} with solid lines corresponding to decoding $\vx_T$ and the dashed lines the decodings of $1.22 \vx_T$.
This behavior was consistent regardless of which SDE was used.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/gaussian_mixture_sa_failure.jpg}
    \caption{\textbf{Prior Guidance is ineffective due to unsatisfied SA condition.} For some latent codes: $\vx_T=\sigma_T \mathbf{z}_1$ scaling the latent code by $1.22$ increases $\log p_0(\vx_0)$, while for others the same scaling leads to a decrease in $\log p_0(\vx_0)$ ($\vx_T=\sigma_T \mathbf{z}_1$). It can be seen that the blue lines cross, while orange do not. The same behavior was observed regardless of which SDE was used.}
    \label{fig:gm-sa-failure}
\end{figure}

\section{Derivation of likelihood steering}\label{app:steering-deriv}

In this section we derive \autoref{eq:steering-unique-ode}. From \autoref{eq:steering_general_ode}, we see that if $\vx_t$ is following a trajectory given by $d\vx_t=\Tilde\vu_t(\vx_t)dt$, then
\begin{align} \label{eq:evolution-v-condition}
    \frac{d \log p_t(\vx_t)}{dt} = b_t(\vx_t) \quad &\Leftrightarrow \quad  \nabla \log p_t(\vx_t)^T( \Tilde\vu_t(\vx_t) - \vu_t(\vx_t)) = b_t(\vx_t) + \div \vu_t(\vx_t) \\
    &\Leftrightarrow \quad  \tilde \vu_t(\vx_t)^T \nabla \log p_t(\vx_t) = b_t(\vx_t) + \div \vu_t(\vx_t) + \vu_t(\vx_t)^T \nabla \log p_t(\vx_t)
\end{align}
Whenever $\nabla \log p_t(\vx_t) = \mathbf{0}$, then RHS is satisfied only when $b_t(\vx_t)=-\div \vu_t(\vx_t)$. In other words, when the score function vanishes, the infinitesimal change in $\log p_t(\vx_t)$ is the same and equal to $-\div \vu_t(\vx_t)$ regardless of the choice of $\Tilde\vu_t$.

Assume now that $\nabla \log p_t(\vx_t) \neq \mathbf{0}$. For fixed $(t, \vx_t)$, we can treat the condition in \autoref{eq:evolution-v-condition} as a linear equation with $\vw \coloneqq \Tilde \vu_t(\vx_t)$ being the unknown quantity we want to solve for. It is a single equation with $D$ variables (dimensionality of $\vw$), i.e. it does not have a unique solution. Out of all possible solutions, we can choose a one, which satisfies additional criteria. Specifically, we choose a solution, which diverges from the original trajectory $\vu_t(\vx_t)$ the least. We therefore solve the following constrained optimization problem
\begin{equation}\label{eq:v-constrained-opt}
\begin{split}
    &\min_{\vw \in \R^D}\frac{1}{2}\| \vw - \vu_t(\vx_t)\|^2 \\
    \text{s.t.} \quad & \vw^T \nabla \log p_t(\vx_t) = b_t(\vx_t) + \div \vu_t(\vx_t) + \vu_t(\vx_t)^T \nabla \log p_t(\vx_t),
\end{split}
\end{equation}
which is treated in \autoref{app:constr}. The solution is
\begin{align}
    \vw &= \vu_t(\vx_t) + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) + \vu_t(\vx_t)^T \nabla \log p_t(\vx_t) - \nabla \log p_t(\vx_t)^T \vu_t(\vx_t) }{\| \nabla \log p_t(\vx_t)\|^2} \nabla \log p_t(\vx_t) \\
    &= \vu_t(\vx_t) + \frac{b_t(\vx_t) + \div \vu_t(\vx_t)}{ \| \nabla \log p_t(\vx_t)\|^2 }\nabla \log p_t(\vx_t),
\end{align}
which matches \autoref{eq:steering-unique-ode}.

\section{Asymptotic behaviour of $\Delta \log p (\vx) + \| \nabla \log p_t(\vx) \|^2$}\label{app:asymptotic}
In this section, we discuss an observation that proved useful in determining \emph{typical} values $\frac{d \log p_t(\vx_t)}{dt}$ in diffusion models. Specifically, we observed that for some distributions $p_0$ after diffusing into $p_t$ via the forward process $p(\vx_t|\vx_0)=\mathcal{N}(\alpha_t\vx_0,\sigma_t^2\mI_D)$, the following holds
\begin{equation}\label{eq:normality}
    h(\vx) = \frac{\sigma_t^2\left(\Delta \log p_t(\vx) + \| \nabla \log p_t(\vx)\|^2\right)}{\sqrt{2D}} \xrightarrow[D \to \infty]{d} \mathcal{N}(0, 1),
\end{equation}
where $D$ denotes the dimension of the distribution $p_t$ and ``$\stackrel{d}{\to}$" denotes convergence in distribution.
\subsection{Single data point}
We begin by showing \autoref{eq:normality} for the simplest possible case, where $p_0=\delta_{\vx_0}$. In that case $p_t=\mathcal{N}(\alpha_t\vx_0,\sigma_t^2 \mI_D)$ and
\begin{align*}
    & \nabla \log p_t(\vx) = \frac{\alpha_t\vx_0 - \vx}{\sigma_t^2} \\
    & \Delta \log p_t(\vx) = -\frac{D}{\sigma_t^2}.
\end{align*}
Since $\vx = \alpha_t \vx_0 + \sigma_t \veps$ for $\veps \sim \mathcal{N}(\mathbf{0}, \mI_D)$ and our expression becomes
\begin{equation}\label{eq:clt-chi}
    h(\vx) = \frac{\sigma_t^2\left(-\frac{D}{\sigma_t^2} + \frac{1}{\sigma_t^2}\|\veps \|^2\right)}{\sqrt{2D}} = \frac{\sum_j (\varepsilon_j^2 - 1)}{\sqrt{2D}}.
\end{equation}
Since $\{\varepsilon_j^2\}_j$ are i.i.d. random variables with $\chi^2_1$ distribution, we have that $\mathbb{E}[\varepsilon_j^2]=1$, $\mathrm{Var}[\varepsilon_j^2]=2$, and the claim follows from the central limit theorem.
\subsection{Non-isotropic Gaussian distribution}
When $p_t$ is Gaussian, but with non-diagonal covariance an analogous result holds when the covariance matrix satisfies some additional conditions. We begin with a useful lemma.
\begin{lemma}[Quadratic CLT \citep{deJong1987}]\label{lem:quadratic-clt}
    Suppose $A=[a_{ij}] \in \R^{D \times D}$ is a real symmetric matrix with eigenvalues $\lambda_1, \dots, \lambda_D$. Let $\{\varepsilon_j\}_{j=1\dots D}$ be independent variables such that $\varepsilon_j \sim \mathcal{N}(0, 1)$.

    If 
    \begin{equation}
        \lim_{D \to \infty} 
        \frac{\max_{j\leq D}\lambda_j^2
        }{\sum_{j\leq D}\lambda_j^2}=0,
    \end{equation}
    then
    \begin{equation}
        \frac{\veps^TA\veps - \mathrm{Tr}(A)}{\sqrt{2}\|A\|_F} \xrightarrow[D \to \infty]{d} \mathcal{N}(0, 1).
    \end{equation}
\end{lemma}

Let $p_t=\mathcal{N}(\mathbf{\mu},\Sigma)$ for $\Sigma$ satisfying the following conditions. Denoting $\Sigma=LL^T$, and $\Tilde\Sigma=L^{-1}(L^T)^{-1}$ with $\lambda_1, \dots, \lambda_D$ eigenvalues of $\Tilde \Sigma$, we assume
\begin{equation}
\lim_{D \to \infty}\frac{\max_{j\leq D}\lambda_j^2}{\sum_{j\leq D}\lambda_j^2}=0
\end{equation}
Note that for $\Sigma=\sigma_t^2\mI_D$, we have $\Tilde\Sigma=\frac{1}{\sigma_t^2}\mI_D$, $\lambda_k = \frac{1}{\sigma_t^2}$, and all the above conditions becomes $\lim_{D \to \infty}\frac{1}{D}=0$, which of course holds. Then
\begin{equation}
    h(\vx) = \frac{\Delta \log p_t(\vx) + \| \nabla \log p_t(\vx) \|^2}{\sqrt{2}\|\nabla^2 \log p_t(\vx)\|_F} \xrightarrow[D \to \infty]{d} \mathcal{N}(0, 1).
\end{equation}

For $\vx \sim \mathcal{N}(\mathbf{\mu}, \Sigma)$, we can represent $\vx = \mu + L\veps$ for $\Sigma=LL^T$ and $\veps \sim \mathcal{N}(\mathbf{0}, \mI_D)$. In this case, we have
\begin{align*}
    & \nabla \log p_t(\vx)=\Sigma^{-1}(\mu - \vx)=-(L^T)^{-1}\veps \\
    & \nabla^2 \log p_t(\vx) = -\Sigma^{-1} \\
    & \Delta \log p_t(\vx) = -\mathrm{Tr}(\Sigma^{-1}).
\end{align*}
Note that $\| \nabla \log p_t(\vx)\|^2=\veps^T \Tilde{\Sigma}\veps$, where $\Tilde\Sigma = L^{-1}(L^T)^{-1}$. Since $\Sigma^{-1}=(L^T)^{-1}L^{-1}$ and $\mathrm{Tr}(AB)=\mathrm{Tr}(BA)$, we have $\Delta \log p_t(\vx)=-\mathrm{Tr}(\Tilde \Sigma)$ and $\| \Tilde\Sigma \|_F=\| \Sigma^{-1} \|_F=\| \nabla^2 \log p_t(\vx) \|_F$
We can now write
\begin{equation}
    h(\vx) = \frac{\Delta \log p_t(\vx) + \| \nabla \log p_t(\vx) \|^2}{\sqrt{2}\|\nabla^2 \log p_t(\vx)\|_F} = \frac{\veps^T \Tilde{\Sigma}\veps - \mathrm{Tr}(\Tilde \Sigma)}{\sqrt{2}\| \Tilde\Sigma \|_F} \xrightarrow[D \to \infty]{d} \mathcal{N}(0, 1)
\end{equation}
from \autoref{lem:quadratic-clt}.
\subsection{Gaussian Mixture}
Usually, the distributions we are interested in can be represented as $p_0=\frac{1}{K}\sum_{k=1}^K \delta_{\vx_k}$, where $\{\vx_k \}_k \subset \R^D$ is the data set.
We show that in this case \autoref{eq:normality} also holds.
In that case, $p_t=\frac{1}{K}\sum_{k=1}^K \mathcal{N}(\mu_k, \sigma_t^2\mI_D$), where $\mu_k = \alpha_t\vx_k$. We will use the following identity, which holds for any $p(\vx)$:
\begin{equation}
    \Delta \log p(\vx) + \| \nabla \log p(\vx) \| ^2 = \frac{\Delta p(\vx)}{p(\vx)}.
\end{equation}
In the Gaussian mixture case (denoting $p_k = \mathcal{N}(\mu_k,\sigma_t^2\mI_D)$, we have
\begin{equation*}
    \frac{\partial}{\partial x^i} p_t(\vx) = \frac{1}{K}\sum_k p_k(\vx)\frac{\mu_k^i - x^i}{\sigma_t^2} = \frac{1}{K\sigma_t^2}\sum_k p_k(\vx)(\mu_k^i - x^i)
\end{equation*}
and
\begin{equation*}
     \frac{\partial^2}{\partial (x^i)^2}p_t(\vx) = \frac{1}{K\sigma_t^2}\sum_k \frac{\partial}{\partial x^i}p_k(\vx)(\mu_k^i - x^i) - \frac{1}{\sigma_t^2}p_t(\vx) = \frac{1}{K\sigma_t^4}\sum_k p_k(\vx) (\mu_k^i - x^i)^2 - \frac{1}{\sigma_t^2}p_t(\vx).
\end{equation*}
Therefore, we have
\begin{equation}\label{eq:gaussian_mixture_normality}
h(\vx) = \frac{\sigma_t^2 \left( \Delta \log p_t(\vx) + \| \nabla \log p_t(\vx) \|^2 \right)}{\sqrt{2D}} = \frac{\sigma_t^2 \Delta p_t(\vx)}{p_t(\vx)\sqrt{2D}} = \frac{\sum_k w_k(\vx) \| \frac{\vx - \mu_k}{\sigma_t} \|^2 - D}{\sqrt{2D}},
\end{equation}
where $w_k(\vx) \coloneqq \frac{p_k(\vx)}{p(\vx)}$.
In \autoref{thm:gaussian_mixture_asymptotics} we show that $h(\vx) \xrightarrow{d}N(0,1)$.
We additionally verify this hypothesis numerically. Specifically, we set the number of components to $K=128$ and sample $\{ \mu_k\}$ from $\mathcal{N}(\mathbf{0}, \sigma_t^2\mI_D)$. We then sample $N=16384$ samples $\vx_j \sim p_t(\vx)$ and evaluate corresponding values of $h(\vx)$ with \autoref{eq:gaussian_mixture_normality}. We repeat this experiment for three values of $\sigma_t \in \{0.5, 1, 10\}$. To test whether the distribution of $h(\vx)$ approaches $\mathcal{N}(0, 1)$ for larger $D$, we repeat this experiment for $D = 2^m$ for $m=6, 7, \dots, 12$ and evaluate the p-value of a normality test on $h(\vx)$
\footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html}}. We see that for $D$ greater than $\approx 1000$, the distribution of $h(\vx)$ is close to $\mathcal{N}(0, 1)$ as evidenced by p-value being greater than the commonly used significance threshold $\alpha=0.05$. Please see \autoref{fig:gaussian_mixture_normality}.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/gaussian_mixture_p_value.jpg}
    \caption{\textbf{$h(\vx)$ approaches $\mathcal{N}(0, 1)$ for larger $D$}.}
    \label{fig:gaussian_mixture_normality}
\end{figure}
\subsection{Image data}
In this section we study $p_0$ being CIFAR-10 image data distribution and $\nabla \log p_t(\vx)$ being approximated with a neural network. Specifically, we uniformly sample different times $t \in (0, T]$ and corresponding noisy samples $\vx_t \sim p_t(\vx)$. Then, we estimate $\nabla \log p_t(\vx)$ using a model and $\Delta \log p_t(\vx) \approx \div \nabla \log p_t(\vx)$ using the Hutchinson's trick. Finally, we plot $\Phi^{-1}(h(\vx_t))$ for $h(\vx_t)$ estimated using \autoref{eq:normality}, where $\Phi$ is the cumulative density function of $\mathcal{N}(0, 1)$. If $h(\vx_t) \sim \mathcal{N}(0, 1)$, then $\Phi^{-1}(h(\vx_t)) \sim \mathcal{U}(0, 1)$ for all $t \in (0, T]$. Indeed, this is precisely the observed behaviour for two different choices of the forward process: $\alpha_t^2 + \sigma_t^2=1$ (VP-SDE) and $\alpha_t + \sigma_t=1$ (CFM) confirming that this finding also holds for high dimensional image data. See \autoref{fig:cifar-normality}.
\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{figures/normality_cifar.png}
    \caption{\textbf{$h(\vx_t)$ approximately follows $\mathcal{N}(0, 1)$ for various definitions of the diffusion process.}}
    \label{fig:cifar-normality}
\end{figure}

\section{Stochastic density guidance}\label{app:sold}
In this section, we derive the stochastic density guidance method.
A central tool in this section is Itô's lemma \citep{ito1951formula}, a generalization of the total derivative to stochastic processes.
\begin{lemma}[Itô's Lemma]\label{lem:ito}
    Let $d\vx_t = \mathbf{\mu}(t, \vx_t)dt + \mG(t, \vx_t)d\rW_t$ be a $D$-dimensional Itô process with $\mu : \R \times \R^D \to \R^D$, $\mG : \R \times \R^D \to \R^{D \times D}$ and $\rW$ the Wiener process in $\R^D$. For a smooth function $h : \R \times \R^D \to \R$, it holds that $h(t, \vx_t)$ is also an Itô process with the following dynamics
    \begin{equation}
    \begin{split}
        d h(t, \vx_t) =& \Big(\frac{\partial h}{\partial t}(t, \vx_t) + \mathbf{\mu}(t, \vx_t)^T \frac{\partial h}{\partial \vx}(t, \vx_t) + \frac{1}{2}\mathrm{Tr}\Big(\mG(t, \vx_t)^T \nabla^2 h(t, \vx_t) \mG(t, \vx_t) \Big) \Big)dt \\
        & + \frac{\partial h}{\partial \vx}(t, \vx_t)^T \mG(t, \vx_t)d\rW_t,
        \end{split}
    \end{equation}
    where $\nabla^2 h$ is the Hessian matrix of $h$ w.r.t $\vx$. In the case when $\mG(t, \vx)=\varphi(t)\mI_D$, the dynamics simplify to
    \begin{equation}
        d h(t, \vx_t) = \Big(\frac{\partial h}{\partial t}(t, \vx_t) + \mathbf{\mu}(t, \vx_t)^T \frac{\partial h}{\partial \vx}(t, \vx_t) + \frac{1}{2}\varphi^2(t)\Delta_\vx h(t, \vx_t) \Big)ds  + \varphi(t)\frac{\partial h}{\partial \vx}(t, \vx_t)^T d\rW_t
    \end{equation}
\end{lemma}
In contrast to the total derivative for deterministic processes, the forward and reverse-time dynamics are not the same for stochastic processes.
We now prove the reverse-time Itô's lemma, which will be useful in our derivation as our convention is that sampling happens backward in time, from $t=T$ to $t=0$.
\begin{corollary}[Reverse-time Itô's lemma]\label{cor:rev-ito}
Let $d\vx_t = \mathbf{\mu}(t, \vx_t)dt + \mG(t, \vx_t)d\overline{\rW}_t$, $dt<0$,  $\overline{\rW}$ the Wiener process running backwards in time from $t=T$ to $t=0$ and $\mu$ and $G$ are as in \autoref{lem:ito}. Then
    \begin{equation}
    \begin{split}
        d h(t, \vx_t) =& \Big(\frac{\partial h}{\partial t}(t, \vx_t) + \mathbf{\mu}(t, \vx_t)^T \frac{\partial h}{\partial \vx}(t, \vx_t) \textcolor[HTML]{318CE7}{-} \frac{1}{2}\mathrm{Tr}\left(\mG(t, \vx_t)^T \nabla^2 h(t, \vx_t) \mG(t, \vx_t) \right) \Big)dt \\
        & + \frac{\partial h}{\partial \vx}(t, \vx_t)^T \mG(t, \vx_t)\textcolor[HTML]{318CE7}{d\overline{\rW}_t},
        \end{split}
    \end{equation}
with the modifications coming from time-reversal highlighted in \textcolor[HTML]{318CE7}{blue}.    
\end{corollary}
\begin{proof}
Let $s=T-t$. Since $ds=-dt$, the dynamics of $\vx$ can be equivalently written as \citep{dockhorn2022scorebased}:
\begin{equation}
d\vx_s = -\mathbf{\mu}(T-s, \vx_s)ds + \mG(T-s, \vx_s)d\rW_s
\end{equation}
for the standard Wiener process $\rW$ and $ds>0$. Now let $\Tilde h(s, \vx) \coloneqq h(T-s, \vx)$.
Applying Itô's lemma to $\Tilde h$ yields
    \begin{equation}
    \begin{split}
        d \Tilde h(s, \vx_s) =& \Big(\frac{\partial \Tilde h}{\partial s}(s, \vx_s) - \mathbf{\mu}(T - s, \vx_s)^T \frac{\partial \Tilde h}{\partial \vx}(s, \vx_s) + \frac{1}{2}\mathrm{Tr}\left(\mG(T - s, \vx_s)^T \nabla^2 \Tilde h(s, \vx_s) \mG(T - s, \vx_s) \right) \Big)ds \\
        & + \frac{\partial \Tilde h}{\partial \vx}(s, \vx_s)^T \mG(T - s, \vx_s)d\rW_s \\
        = & \Big(-\frac{\partial  h}{\partial t}(T - s, \vx_s) - \mathbf{\mu}(T - s, \vx_s)^T \frac{\partial h}{\partial \vx}(T - s, \vx_s) + \frac{1}{2}\mathrm{Tr}\left(\mG(T - s, \vx_s)^T \nabla^2 h(T - s, \vx_s) \mG(T - s, \vx_s) \right) \Big)ds \\
        & + \frac{\partial h}{\partial \vx}(T - s, \vx_s)^T \mG(T - s, \vx_s)d\rW_s.
        \end{split}
    \end{equation}
The claim follows from switching back to running backward in time $t \gets T-s$
\end{proof}
Recall \autoref{eq:fm-sde} which describes stochastic sampling from a CNF model
\begin{equation}\tag{\ref{eq:fm-sde}}
    d\vx_t = \Big(\vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)\Big) dt + \varphi(t) d\overline{\rW}_t
\end{equation}
for which, we know how the log-density evolves (\autoref{eq:log-density-sde}):
\begin{equation}\tag{\ref{eq:log-density-sde}}
d \log p_t(\vx_t) = \left( -\div \vu_t(\vx) - \frac{1}{2}\varphi^2(t) \left(\Delta \log p_t(\vx)
     + \frac{1}{2}\varphi^2(t) \| \nabla \log p_t(\vx) \|^2\right)\right)dt + \varphi(t)\nabla \log p_t(\vx_t)^Td\overline{\rW}_t.
\end{equation}
We now ask: how can modify the stochastic dynamics (\autoref{eq:fm-sde}) so that
\begin{equation}\label{eq:b-sde-cond}
d \log p_t(\vx_t) = b_t(\vx_t)
\end{equation}
for some given $b_t$.
Suppose that $\vx$ is following
\begin{equation}\label{eq:stochastic-dynamics}
d\vx_t = \Tilde\vu_t( \vx_t)dt + \mG(t, \vx_t)d\overline{\rW}_t
\end{equation}
for some $\Tilde \vu$ and $\mG$.
To evaluate the change log-density we will use \autoref{cor:rev-ito} applied to $h(t, \vx) = \log p_t(\vx)$:
    \begin{equation}\label{eq:stochastic-dlogp}
    \begin{split}
        d \log p_t(\vx_t) =& \Big(\frac{\partial \log p_t}{\partial t}(\vx_t) + \Tilde\vu_t( \vx_t)^T \nabla \log p_t(\vx_t) -  \frac{1}{2}\mathrm{Tr}\left(\mG(t, \vx_t)^T \nabla^2 \log p_t(\vx_t) \mG(t, \vx_t) \right) \Big)dt \\
        & + \nabla \log p_t(\vx_t)^T \mG(t, \vx_t)d\overline{\rW}_t.
        \end{split}
    \end{equation}
Since we assumed that $d \log p_t(\vx_t)=b_t(\vx_t)dt$, the stochastic component of $d \log p_t(\vx_t)$ must vanish, i.e. $\nabla \log p_t(\vx)^T\mG(t, \vx) = \mathbf{0}$.
There are many $\mG$ that satisfy this condition including a trivial $\mG \equiv \mathbf{0}$.
However, standard stochastic sampling (\autoref{eq:fm-sde}) assumes isotropic noise, i.e. $\mG(t, \vx) = \varphi(t)\mI_D$ and we want to match that as closely as possible.
An optimal solution (\autoref{lem:proj-opt}) to this problem is the projection $\mG(t, \vx) = \varphi(t)\mP_t(\vx)$ for:
\begin{equation}
\mP_t(\vx)= \mI_D - \left(\frac{\nabla \log p_t(\vx)}{\|\nabla \log p_t(\vx)\|}\right)\left(\frac{\nabla \log p_t(\vx)}{\|\nabla \log p_t(\vx)\|}\right)^T.
\end{equation}
Clearly $\mP_t(\vx)^T=\mP_t(\vx)$. Furthermore, since $\mP_t$ is a projection matrix, it also holds that $\mP_t(\vx)\mP_t(\vx)=\mP_t(\vx)$.
Now we can plug this into \autoref{eq:stochastic-dlogp} and we obtain
\begin{equation}
d \log p_t(\vx_t) = \Big(\frac{\partial \log p_t}{\partial t}(\vx_t) + \Tilde\vu_t(\vx_t)^T \nabla \log p_t(\vx_t) -  \frac{1}{2}\varphi^2(t)\mathrm{Tr}\left(\mP_t(\vx_t)^T \nabla^2 \log p_t(\vx_t) \mP_t(\vx_t) \right) \Big)dt.
\end{equation}
Using the symmetry and idempotency of $P_t$, and properties of the trace (linearity and $\mathrm{Tr}(AB) = \mathrm{Tr}(BA)$), we have
\begin{align}
\mathrm{Tr}\left(\mP_t(\vx)^T \nabla^2 \log p_t(\vx) \mP_t(\vx) \right) &= \mathrm{Tr}\left(\mP_t(\vx) \nabla^2 \log p_t(\vx)\right) \\
& = \mathrm{Tr}\left( \nabla^2 \log p_t(\vx) \right) - \frac{1}{\| \nabla \log p_t(\vx) \|^2}\mathrm{Tr}\left( \nabla \log p_t(\vx)  \nabla\log p_t(\vx)^T \nabla^2 \log p_t(\vx) \right) \\
&= \Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}.
\end{align}
Furthermore, from \autoref{eq:cont-eq}, we have
\begin{equation}
\frac{\partial \log p_t}{\partial t}(\vx) = -\div \vu_t(\vx) - \nabla \log p_t(\vx)^T \vu_t(\vx).
\end{equation}
Combining these, we get
\begin{equation}\label{eq:mu-constraint}
\begin{split}
b_t(\vx_t)=\frac{d \log p_t(\vx_t)}{dt} =&
  -\div \vu_t(\vx_t) + \nabla \log p_t(\vx_t)^T (\Tilde \vu_t(\vx_t) - \vu_t(\vx_t)) \\
  & -  \frac{1}{2}\varphi^2(t)\left( \Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}\right).
 \end{split}
\end{equation}
Any $\Tilde\vu_t(\vx)$ satisfying \autoref{eq:mu-constraint} guarantees the desired evolution of log-density.
However, we wish to minimize the discrepancy from the new drift $\Tilde\vu_t(\vx_t)$ and the one from \autoref{eq:fm-sde}, which guarantees sampling from the correct distribution: $\vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)$.
Therefore, we solve the constrained optimization problem:
\begin{equation}
\begin{split}
    &\min_{\Tilde \vu \in \R^D}\frac{1}{2}\| \Tilde \vu - \vu_t(\vx_t) + \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)\|^2 \\
    \text{s.t.} \quad & \Tilde \vu \text{ is a solution of \autoref{eq:mu-constraint}}.
\end{split}
\end{equation}
This is a problem setting discussed and solved in \autoref{app:constr} with
\begin{equation}
\begin{cases}
\vx &= \Tilde \vu \\
\vy & = \vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t) \\
\vv & = \nabla \log p_t(\vx_t) \\
a & = b_t(\vx_t) + \div \vu_t(\vx_t) + \vu_t(\vx_t)^T\nabla \log p_t(\vx_t) + \frac{1}{2}\varphi^2(t)\left( \Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2} \right)
\end{cases}
\end{equation}
After substituting 
\begin{align}
    \Tilde\vu_t(\vx_t) &= \vy + \frac{a - \vv^T\vy}{\|\vv\|^2}\vv  \\
    &= \vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t) \\
    &\quad + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) + \color{red}\cancel{\color{black}\vu_t(\vx_t)^T\nabla \log p_t(\vx_t)}\color{black} -\nabla \log p_t(\vx_t)^T (\color{red}\cancel{\color{black}\vu_t(\vx_t)}\color{black}  - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)) }{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) \\
    &\quad + \frac{1}{2}\varphi^2(t)\frac{\Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}}{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) \\
    &= \vu_t(\vx_t) - \frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t) + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) + \frac{1}{2}\varphi^2(t)  \|\nabla \log p_t(\vx_t)\|^2 }{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) \\
    &\quad + \frac{1}{2}\varphi^2(t)\frac{\Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2} }{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) \\
    &= \vu_t(\vx_t) - \color{red}\cancel{\color{black}\frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)}\color{black} + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) }{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) +\color{red}\cancel{\color{black}\frac{1}{2}\varphi^2(t)\nabla \log p_t(\vx_t)}\color{black}  \\
    &\quad + \frac{1}{2}\varphi^2(t)\frac{\Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2} }{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t) \\
    &= \vu_t(\vx_t) + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) + \frac{1}{2}\varphi^2(t) \left( \Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2} \right)}{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t).
\end{align}
The solution is 
\begin{equation}\label{eq:general-sde-steering}
\Tilde\vu_t(\vx_t) = \vu_t(\vx_t) + \frac{b_t(\vx_t) + \div \vu_t(\vx_t) + \frac{1}{2}\varphi^2(t) \left( \Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2} \right)}{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t),
\end{equation}
which exactly matches \autoref{eq:steering_general_ode} when $\varphi \equiv 0$ as expected.
Now suppose that $\vu_t = \vu_t^{\textsc{pf-ode}}$ and $b$ is defined as in \autoref{eq:b-quantile}.
\begin{equation}\tag{\ref{eq:b-quantile}}
b^q_t(\vx) = -\div \vu_t(\vx) - \frac{1}{2}g^2(t) \frac{\sqrt{2D}}{\sigma_t^2} \Phi^{-1}(q).
\end{equation}
Then the drift becomes
\begin{equation}
\Tilde\vu_t(\vx) = \vu^\textsc{dg-ode}_t(\vx) + \frac{1}{2}\varphi^2(t) \frac{\Delta \log p_t(\vx) - \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}}{\|\nabla \log p_t(\vx_t)\|^2}\nabla \log p_t(\vx_t).
\end{equation}
\paragraph{Practical approximation} The Laplacian, $\Delta \log p_t(\vx)$, is given by the trace of the Hessian $\nabla^2 \log p_t(\vx)$, which corresponds to the sum of its eigenvalues. In contrast, 
\begin{equation*}
\mathcal{R}(\nabla^2 \log p_t(\vx), \nabla \log p_t(\vx)) = \frac{\nabla \log p_t(\vx)^T \nabla^2 \log p_t(\vx) \nabla \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}
\end{equation*}
represents the Rayleigh quotient of the Hessian evaluated at $\nabla \log p_t(x)$. This quantity is bounded in absolute value by the largest absolute eigenvalue of the Hessian, i.e., its spectral norm. Intuitively, when the eigenvalues of the Hessian are relatively uniform—such as when it is close to a scaled identity matrix—the Laplacian scales linearly with the dimension, whereas the Rayleigh quotient remains bounded by a constant. This suggests that in high-dimensional settings, the Laplacian dominates.

Empirically, we verified this intuition by estimating both quantities on real data.
Specifically, we used a VP-SDE model trained on CIFAR-10 ($32 \times 32$ resolution, $D=3072$) \citep{karczewski2024diffusion} and a VE-SDE model trained on ImageNet ($64 \times 64$ resolution, $D=12288$) \citep{karras2022elucidating} and sampled uniformly values of $t \in [0, T]$ and corresponding $\vx_t \sim p_t$ (used 8192 and 16384 samples respectively) and found that the ratio was negligibly small in practice
\begin{equation*}
\left|\frac{\mathcal{R}(\nabla^2 \log p_t(\vx_t), \nabla \log p_t(\vx_t))}{\Delta \log p_t(\vx_t)}\right| \approx \begin{cases}\text{0.0003 \textcolor{gray}{± 0.00006}} & \text{ for CIFAR-10}\\
\text{0.00006 \textcolor{gray}{± 0.00003}} & \text{ for ImageNet64}
\end{cases}
\end{equation*}
This confirms that $\mathcal{R}(\nabla^2 \log p_t(\vx), \nabla \log p_t(\vx))$ is negligible in practice.
Therefore, in practice, we use
\begin{equation}
\vu^\textsc{dg-sde}_t(\vx) \coloneqq \vu^\textsc{dg-ode}_t(\vx) + \underbrace{\frac{1}{2}\varphi^2(t)\frac{\Delta \log p_t(\vx)}{\| \nabla \log p_t(\vx) \|^2}\nabla \log p_t(\vx)}_{\text{correction for added stochasticity}}.
\end{equation}

\newpage
\section{JAX implementation of Score Alignment verification}\label{app:sa-jax}
\begin{lstlisting}[language=Python, caption=JAX Implementation of Score Alignment Verification, label=lst:jax_score_alignment]
import jax
import jax.random as jr
import jax.numpy as jnp

def aug_drift(u, x, v, t, key):
    model_key, eps_key = jr.split(key, 2)
    eps = jr.rademacher(eps_key, (x.size,), dtype=jnp.float32)
    def u(x_):
        return u(t, x_.reshape(x.shape), key=model_key).flatten()
    def du_dv(x_):
        u_pred, du_dv_pred = jax.jvp(u, (x_,), (v,))
        return u_pred.reshape(x.shape), du_dv_pred
    return du_dv(x.flatten())

def aug_drift_w_omega(u, x, v, t, key):
    model_key, eps_key = jr.split(key, 2)
    eps = jr.rademacher(eps_key, (x.size,), dtype=jnp.float32)
    def u(x_):
        return u(t, x_.reshape(x.shape), key=model_key).flatten()
    def du_dv(x_):
        u_pred, du_dv_pred = jax.jvp(u, (x_,), (v,))
        return du_dv_pred, u_pred.reshape(x.shape)
    def div_du_dv(x_):
        du_dv_pred, du_dv_eps, u_pred = jax.jvp(du_dv, (x_,), (eps,), has_aux=True)
        return u_pred, du_dv_pred, -jnp.sum(eps * du_dv_eps)
    return div_du_dv(x.flatten())

def score_alignment_verification(u, x_T, v_T, T, dt, key, eps=1e-2, use_omega=False):
    t = T
    x = x_T
    v = v_T
    omega = jnp.sum(v_T **2) if use_omega else None
    while t > eps:
        key, subkey = jr.split(key)
        if use_omega:
            dx, dv, domega = aug_drift_w_omega(u, x, v, t, subkey)
            omega -= dt * domega
        else:
            dx, dv = aug_drift(u, x, v, t, subkey)
        x -= dt * dx
        v -= dt * dv
        t -= dt
    if use_omega:
        return omega
    else:
        return jnp.dot(v, score_fn(eps, x, key)) # Assuming score_fn is known
\end{lstlisting}

\section{Prior Guidance samples}\label{app:scaling-samples}
In \autoref{fig:scaling-samples} we show samples generated with the EDM2 ImageNet $512 \times 512$ model \citep{karras2024analyzing}.
Specifically, we randomly sampled a latent code $\vx_T = \sigma_T \veps$ for $\veps \sim \mathcal{N}(\mathbf{0}, \mI_D)$ and scaled it to have specific values of the norm.
Since $\log p_T(\vx_T) = C - \frac{1}{2}\|\veps\|^2$ and $\|\veps\|^2 \sim \chi^2(D)$, we choose the values of the target squared norm to be quantiles of $\chi^2(D)$ for $q \in [0.001, 0.999]$ for $\vx_T$ to remain in the typical region of $p_T$.
Higher values of $q$ mean higher norm, i.e. lower $\log p_T(\vx_T)$, and are thus decoding produces more detailed images.

Given that the Score Alignment holds for the EDM2 model (\autoref{fig:dot-product}), we can see that scaling the latent code (Prior Guidance) is effective in controlling $\log p_0(\vx_0)$ and thus the image detail.
We additionally include samples for StableDiffusion v2.1 \citep{rombach2021highresolution} in \autoref{fig:scaling-stable-diffusion}.
\begin{figure}[b]
    \centering
    \includegraphics[width=1\linewidth]{figures/scaling_edm2_samples.jpg}
    \caption{\textbf{Prior Guidance controls the detail when Score Alignment holds.} Samples generated with the EDM2 latent diffusion model \citep{karras2024analyzing} for different values of quantiles $q$ for the $\chi^2$ distribution. See \autoref{app:scaling-samples} for details.}
    \label{fig:scaling-samples}
\end{figure}

\begin{figure}[t]
    \centering
\includegraphics[width=1\linewidth]{figures/scaling_stable_diffusion_samples.jpg}
    \caption{Samples with Prior Guidance on StableDiffusion v2.1 \citep{rombach2021highresolution}}
    \label{fig:scaling-stable-diffusion}
\end{figure}

\section{Gaussian Mixture asymptotics}
\begin{lemma}\label{lem:gm-1}
    Let $f:\R\to\R, \:f(x)=\exp(-\frac{1}{2}x)x$. Then for all $x \in \R$
    \begin{equation}
        f(x) \leq 1
    \end{equation}
\end{lemma}
\begin{proof}
    \begin{equation*}
        f'(x) = -\frac{1}{2}\exp\left(-\frac{1}{2}x\right)x + \exp\left(-\frac{1}{2}x\right)=\exp\left(-\frac{1}{2}x\right)\left(1 - \frac{1}{2}x\right).
    \end{equation*}
    $f'(x) > 0$ for $x<2$ and $f'(x) < 0$ for $x > 2$. Therefore for all $x \in \R$
    \begin{equation*}
        f(x) \leq f(2) = \exp(-1)2 = \frac{2}{e} < 1.
    \end{equation*}
\end{proof}
\begin{lemma}\label{lem:gm-2}
    For any $a>0$ and $x>0$
    \begin{equation}
        \left(\frac{a}{x}+x\right)^2 \geq 4a.
    \end{equation}
\end{lemma}
\begin{proof}
\begin{equation*}
    0 \leq \left( \frac{a}{x}-x \right)^2 = \frac{a^2}{x^2}-2a+x^2 = \left( \frac{a}{x}+x \right)^2 -4a
\end{equation*}
\end{proof}
\begin{theorem}
\label{thm:gaussian_mixture_asymptotics}
Let $X\in \mathbb{R}^D$ be drawn from a mixture of $K$ Gaussian components:
\begin{equation}
  \Pr(Y=k)=\pi_k,\quad
  X\mid(Y=k)\sim\mathcal{N}(\mu_k,\sigma^2 I_D),
\end{equation}
where $\mu_j \neq \mu_i$ for $i \neq j$ (note that this assumption is not restrictive, because when different components share the mean, the mixture can be rewritten with distinct $\mu$ and updated $\pi$). Define
\begin{equation}
  h(X)
  =
  \frac{1}{\sqrt{2D}}\left[\sum_{j=1}^K w_j(X)\frac{\|X-\mu_j\|^2}{\sigma^2} 
    - D\right],
\end{equation}
where
\begin{equation}
  w_j(x)
  =
  \frac{\pi_j\exp\left[-\frac1{2\sigma^2}\|x-\mu_j\|^2\right]}{
        \sum_{m=1}^K \pi_m\exp\left[-\frac1{2\sigma^2}\|x-\mu_m\|^2\right]}.
\end{equation}
Then $h(X)\xrightarrow{d}N(0,1)$ as $D\to\infty$.
\end{theorem}

\begin{proof}
\textbf{Step 1: It suffices to show $h(X)\mid(Y=k)\to N(0,1)$.}  
Indeed,
\[
  \varphi_{h(X)}(t)=\mathbb{E}\left[e^{ith(X)}\right]
  =\sum_{k=1}^K
  \pi_k\mathbb{E}\left[e^{ith(X)}\mid Y=k\right]=\sum_{k=1}^K
  \pi_k\varphi_{h(X)|Y=k}(t).
\]
Thus if each conditional law converges to $N(0,1)$ (point-wise convergence of characteristic functions), so does the unconditional mixture.

\noindent
\textbf{Step 2: Rewrite $X=\mu_k+\sigma\veps$.}  
Conditioning on $Y=k$, we have $X=\mu_k+\sigma\veps$, $\veps\sim\mathcal{N}(\mathbf{0},\mI_D)$.  Thus
\[
  \frac{\|X-\mu_k\|^2}{\sigma^2}
  = \|\veps\|^2
  \sim\chi^2_D,\quad
  \frac{\|\veps\|^2 -D}{\sqrt{2D}}
  \xrightarrow{d}N(0,1)
\]
% as in \autoref{eq:clt-chi}.

\noindent
\textbf{Step 3: Define remainder $\mathcal{R}_D$.}  
Set
\[
  \sum_{j=1}^K w_j(X)\frac{\|X-\mu_j\|^2}{\sigma^2}
  =
  \|\veps\|^2 +\mathcal{R}_D,
\]
so
\[
  h(X)
  =
  \frac{\|\veps\|^2 -D}{\sqrt{2D}}
  +
  \frac{\mathcal{R}_D}{\sqrt{2D}}.
\]
Using Slutsky's theorem, it suffices to show $\mathcal{R}_D/\sqrt{2D}\xrightarrow{d} 0$, which is a weaker condition than convergence in probability.
\textbf{It thus suffices to show}
\begin{equation}
 \frac{\mathcal{R}_D}{\sqrt{2D}}\xrightarrow{\mathbb{P}}0   
 \end{equation}
\noindent
\textbf{Step 4: Showing $\mathcal{R}_D/\sqrt{2D} \xrightarrow[]{\mathbb{P}}0$.}  
Let 
\[
  \Delta_{j,k}
  := \frac{\mu_k-\mu_j}{\sigma} \neq \mathbf{0}.
\]
Note
\[
  \frac{\|X-\mu_j\|^2}{\sigma^2}
  = \|\veps + \Delta_{j,k}\|^2
  = \|\veps\|^2 + 2\veps^T\Delta_{j,k} + \|\Delta_{j,k}\|^2 = \|\veps\|^2 + b_j
\]
for $b_j = 2\veps^T\Delta_{j,k} + \|\Delta_{j,k}\|^2$ and $b_k=0$ since $\Delta_{k,k}=0$.
Hence
\[
  \mathcal{R}_D
  = \sum_{j=1}^K w_j(X)\left[2\veps^T\Delta_{j,k} + \|\Delta_{j,k}\|^2\right] = \sum_{j\neq k} w_j(X)b_j. 
\]
Also:
\[
  w_j(X)
  =
  \frac{\pi_j\exp\left[-\frac1{2\sigma^2}\|x-\mu_j\|^2\right]}{
        \sum_{m=1}^K\pi_m \exp\left[-\frac1{2\sigma^2}\|x-\mu_m\|^2\right]} = \frac{\pi_j\exp\left[-\frac1{2}(\|\veps\|^2 + b_j)\right]}{
        \sum_{m=1}^K \pi_m\exp\left[-\frac1{2}(\|\veps\|^2 + b_m)\right]}=\frac{\pi_j\exp(-\frac{1}{2}b_j)}{
        \sum_{m=1}^K \pi_m\exp(-\frac{1}{2}b_m)}.
\]
Then
\[
\mathcal{R}_D = \frac{\sum_{j \neq k}\pi_j\exp(-\frac{1}{2}b_j)b_j}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)}.
\]
We will now separate the sum in the numerator of $\mathcal{R}_D$ into positive and negative $b_j$. Define $J^+ = \{ j \neq k | b_j \geq 0 \}$ and $J^-=  \{ j \neq k | b_j < 0 \}$:
\[
\mathcal{R}_D = \frac{\sum_{j \in J^+}\pi_j\exp(-\frac{1}{2}b_j)b_j}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)} + \frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)b_j}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)}.
\]
From \autoref{lem:gm-1}, $\exp(-\frac{1}{2}b_j)b_j\leq 1$ and thus $\sum_{j \in J^+}\pi_j\exp(-\frac{1}{2}b_j)b_j \leq 1$.
Therefore (note shrinking denominators to achieve upper bounds):
\begin{align*}
    \left| \mathcal{R}_D \right| & \leq \left|\frac{\sum_{j \in J^+}\pi_j\exp(-\frac{1}{2}b_j)b_j}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)}\right| + \left|\frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)b_j}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)}\right| \\
    & \leq \frac{1}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)} + \frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)|b_j|}{\pi_k + \sum_{m \neq k}\pi_m\exp(-\frac{1}{2}b_m)} \\
    & \leq \frac{1}{\pi_k} + \frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)|b_j|}{\pi_k + \sum_{m \in J^-}\pi_m\exp(-\frac{1}{2}b_m)} \\
    & \leq \frac{1}{\pi_k} + \frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)|b_j|}{\pi_k + \sum_{m \in J^-}\pi_m\exp(-\frac{1}{2}b_m)} = \frac{1}{\pi_k} + \sum_{j \in J^-}\Tilde w_j |b_j|,
\end{align*}
where $\Tilde w_j = \frac{\pi_j\exp(-\frac{1}{2}b_j)}{\pi_k + \sum_{m \in J^- }\pi_m\exp(-\frac{1}{2}b_m)}$ and $\sum_{j \in J^-}\Tilde w_j = \frac{\sum_{j \in J^-}\pi_j\exp(-\frac{1}{2}b_j)}{\pi_k + \sum_{m \in J^-}\pi_m\exp(-\frac{1}{2}b_m)} \leq 1$. Thus
\[
\sum_{j \in J^-}\Tilde w_j |b_j| \leq \sum_{j \in J^-}\Tilde w_j \max_{j \in J^-}|b_j| \leq \max_{j \in J^-}|b_j| = \max(-\min_{j \neq k} b_j, 0),
\]
where the last equality comes from the definition of $J^-$. In summary
\[
|\mathcal{R}_D| \leq \frac{1}{\pi_k} + \max(-\min_{j \neq k} b_j, 0).
\]
Now, for any $\delta >0 $:
\[
\Pr\left(\frac{|\mathcal{R}_D|}{\sqrt{2D}} > \delta\right) = \Pr\left(|\mathcal{R}_D| > \delta\sqrt{2D}\right) \leq \Pr\left( \max(-\min_{j \neq k} b_j, 0) > \delta\sqrt{2D} - \frac{1}{\pi_k} \right).
\]
Now choose $D$ large enough so that $a = \delta\sqrt{2D} - \frac{1}{\pi_k} > 0$.
Then
\[
\Pr\left( \max(-\min_{j \neq k} b_j, 0) > a \right) = \Pr\left( \exists_{j \neq k} \: b_j < -a\right) \leq \sum_{j\neq k} \Pr\left( b_j < -a \right).
\]
Now plugging in the definition of $b_j$ and using the fact that $Z = \frac{\veps^T \Delta_{k, j}}{\| \Delta_{k,j}\|} \sim \mathcal{N}(0, 1)$.
\[
\Pr\left( b_j < -a \right) = \Pr\left( 2\veps^T\Delta_{j,k} + \|\Delta_{j,k}\|^2 < -a \right) = \Pr\left( Z < -\frac{1}{2} \left( \frac{a}{\|\Delta_{j,k}\|} + \| \Delta_{j,k} \| \right)\right).
\]
And using the standard Gaussian tail bound $\Pr(Z<-t) = \Pr(Z>t) \leq \exp(-\frac{1}{2}t^2)$ for $t>0$:
\[
\Pr\left( b_j < -a \right) \leq \exp\left(-\frac{1}{8}\left(\frac{a}{\|\Delta_{j,k}\|} + \| \Delta_{j,k} \|\right)^2\right) \leq \exp\left(-\frac{1}{2}a\right),
\]
where the last inequality comes from \autoref{lem:gm-2}. Therefore
\begin{equation*}
    \Pr\left(\frac{|\mathcal{R}_D|}{\sqrt{2D}} > \delta\right) \leq \sum_{j \neq k} \Pr(b_j < -a) \leq\sum_{j\neq k}\exp\left(-\frac{1}{2}a\right) = (K-1)\exp\left(-\frac{1}{2}\left( \delta\sqrt{2D} - \frac{1}{\pi_k} \right)\right) \xrightarrow[D \to \infty]{}0
\end{equation*}
We have shown that for all $\delta >0 $
\begin{equation}
    \lim_{D \to \infty }\Pr\left( \left| \frac{\mathcal{R}_D}{\sqrt{2D}} \right| > \delta \right)= 0,
\end{equation}
which means
\[
\frac{\mathcal{R}_D}{\sqrt{2D}} \xrightarrow[D \to \infty]{\mathbb{P}} 0.
\]
\end{proof}
\end{document}
