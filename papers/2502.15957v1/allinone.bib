
@InProceedings{	  vaswani2017attention,
  title		= {Attention is all you need},
  author	= {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
		  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
		  Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle	= {Advances in neural information processing systems},
  pages		= {5998--6008},
  year		= {2017}
}

@Article{	  yuan2021bartscore,
  title		= {Bartscore: Evaluating generated text as text generation},
  author	= {Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {34},
  year		= {2021}
}

@InProceedings{	  loshchilov2018decoupled,
  title		= {Decoupled Weight Decay Regularization},
  author	= {Loshchilov, Ilya and Hutter, Frank},
  booktitle	= {International Conference on Learning Representations},
  year		= {2018}
}

@Misc{		  chatgpt,
  author	= {OpenAI},
  title		= {Chatgpt: Optimizing language models for dialogue},
  year		= 2022,
  url		= {https://openai.com/blog/chatgpt/}
}

@InProceedings{	  ouyang2022training,
  title		= {Training language models to follow instructions with human
		  feedback},
  author	= {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida,
		  Diogo and Wainwright, Carroll and Mishkin, Pamela and
		  Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and
		  Gray, Alex and others},
  booktitle	= {Advances in Neural Information Processing Systems},
  year		= {2022}
}

@Article{	  achiam2023gpt,
  title		= {Gpt-4 technical report},
  author	= {Achiam, Josh and Adler, Steven and Agarwal, Sandhini and
		  Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni
		  and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam
		  and Anadkat, Shyamal and others},
  journal	= {arXiv preprint arXiv:2303.08774},
  year		= {2023}
}

@Article{	  suzgun2024meta,
  title		= {Meta-Prompting: Enhancing Language Models with
		  Task-Agnostic Scaffolding},
  author	= {Suzgun, Mirac and Kalai, Adam Tauman},
  journal	= {arXiv preprint arXiv:2401.12954},
  year		= {2024}
}

@Article{	  guo2023close,
  title		= {How close is chatgpt to human experts? comparison corpus,
		  evaluation, and detection},
  author	= {Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang,
		  Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and
		  Wu, Yupeng},
  journal	= {arXiv preprint arXiv:2301.07597},
  year		= {2023}
}

@Article{	  srivastava2023beyond,
  title		= {Beyond the Imitation Game: Quantifying and extrapolating
		  the capabilities of language models},
  author	= {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek
		  and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam
		  and Brown, Adam R and Santoro, Adam and Gupta, Aditya and
		  Garriga-Alonso, Adri{\`a} and others},
  journal	= {Transactions on Machine Learning Research},
  year		= {2023}
}

@Article{	  raffel2020exploring,
  title		= {Exploring the Limits of Transfer Learning with a Unified
		  Text-to-Text Transformer},
  author	= {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee,
		  Katherine and Narang, Sharan and Matena, Michael and Zhou,
		  Yanqi and Li, Wei and Liu, Peter J},
  journal	= {Journal of Machine Learning Research},
  volume	= {21},
  pages		= {1--67},
  year		= {2020}
}

@Article{	  liang2022holistic,
  title		= {Holistic evaluation of language models},
  author	= {Liang, Percy and Bommasani, Rishi and Lee, Tony and
		  Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro
		  and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and
		  Kumar, Ananya and others},
  journal	= {arXiv preprint arXiv:2211.09110},
  year		= {2022}
}

@Article{	  dubey2024llama,
  title		= {The llama 3 herd of models},
  author	= {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav
		  and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha
		  and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan,
		  Angela and others},
  journal	= {arXiv preprint arXiv:2407.21783},
  year		= {2024}
}

@Article{	  team2023gemini,
  title		= {Gemini: a family of highly capable multimodal models},
  author	= {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and
		  Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and
		  Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and
		  Hauth, Anja and others},
  journal	= {arXiv preprint arXiv:2312.11805},
  year		= {2023}
}

@Article{	  hong2023metagpt,
  title		= {Metagpt: Meta programming for multi-agent collaborative
		  framework},
  author	= {Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng,
		  Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and
		  Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and
		  others},
  journal	= {arXiv preprint arXiv:2308.00352},
  year		= {2023}
}

@Article{	  wang2023voyager,
  title		= {Voyager: An open-ended embodied agent with large language
		  models},
  author	= {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and
		  Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan,
		  Linxi and Anandkumar, Anima},
  journal	= {arXiv preprint arXiv:2305.16291},
  year		= {2023}
}

@Article{	  wang2023jarvis,
  title		= {Jarvis-1: Open-world multi-task agents with
		  memory-augmented multimodal language models},
  author	= {Wang, Zihao and Cai, Shaofei and Liu, Anji and Jin,
		  Yonggang and Hou, Jinbing and Zhang, Bowei and Lin, Haowei
		  and He, Zhaofeng and Zheng, Zilong and Yang, Yaodong and
		  others},
  journal	= {arXiv preprint arXiv:2311.05997},
  year		= {2023}
}

@Article{	  tao2024survey,
  title		= {A survey on self-evolution of large language models},
  author	= {Tao, Zhengwei and Lin, Ting-En and Chen, Xiancai and Li,
		  Hangyu and Wu, Yuchuan and Li, Yongbin and Jin, Zhi and
		  Huang, Fei and Tao, Dacheng and Zhou, Jingren},
  journal	= {arXiv preprint arXiv:2404.14387},
  year		= {2024}
}

@Article{	  wu2024copilot,
  title		= {Os-copilot: Towards generalist computer agents with
		  self-improvement},
  author	= {Wu, Zhiyong and Han, Chengcheng and Ding, Zichen and Weng,
		  Zhenmin and Liu, Zhoumianze and Yao, Shunyu and Yu, Tao and
		  Kong, Lingpeng},
  journal	= {arXiv preprint arXiv:2402.07456},
  year		= {2024}
}

@Article{	  maharana2024evaluating,
  title		= {Evaluating very long-term conversational memory of llm
		  agents},
  author	= {Maharana, Adyasha and Lee, Dong-Ho and Tulyakov, Sergey
		  and Bansal, Mohit and Barbieri, Francesco and Fang, Yuwei},
  journal	= {arXiv preprint arXiv:2402.17753},
  year		= {2024}
}

@Article{	  wang2024self,
  title		= {Self-Updatable Large Language Models with Parameter
		  Integration},
  author	= {Wang, Yu and Liu, Xinshuang and Chen, Xiusi and O'Brien,
		  Sean and Wu, Junda and McAuley, Julian},
  journal	= {arXiv preprint arXiv:2410.00487},
  year		= {2024}
}

@Article{	  choi2022prompt,
  title		= {Prompt injection: Parameterization of fixed inputs},
  author	= {Choi, Eunbi and Jo, Yongrae and Jang, Joel and Seo,
		  Minjoon},
  journal	= {arXiv preprint arXiv:2206.11349},
  year		= {2022}
}

@Article{	  bulatov2022recurrent,
  title		= {Recurrent memory transformer},
  author	= {Bulatov, Aydar and Kuratov, Yury and Burtsev, Mikhail},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {35},
  pages		= {11079--11091},
  year		= {2022}
}

@Article{	  he2024camelot,
  title		= {CAMELoT: Towards Large Language Models with Training-Free
		  Consolidated Associative Memory},
  author	= {He, Zexue and Karlinsky, Leonid and Kim, Donghyun and
		  McAuley, Julian and Krotov, Dmitry and Feris, Rogerio},
  journal	= {arXiv preprint arXiv:2402.13449},
  year		= {2024}
}

@InProceedings{	  wang2024memoryllm,
  author	= {Wang, Yu and Gao, Yifan and Chen, Xiusi and Jiang, Haoming
		  and Li, Shiyang and Yang, Jingfeng and Yin, Qingyu and Li,
		  Zheng and Li, Xian and Yin, Bing and Shang, Jingbo and
		  McAuley, Julian},
  title		= {MEMORYLLM: towards self-updatable large language models},
  year		= {2024},
  publisher	= {JMLR.org},
  booktitle	= {Proceedings of the 41st International Conference on
		  Machine Learning},
  articleno	= {2065},
  numpages	= {14},
  location	= {Vienna, Austria},
  series	= {ICML'24}
}

@Article{	  behrouz2024titans,
  title		= {Titans: Learning to Memorize at Test Time},
  author	= {Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
  journal	= {arXiv preprint arXiv:2501.00663},
  year		= {2024}
}

@InProceedings{	  zhong2024memorybank,
  title		= {Memorybank: Enhancing large language models with long-term
		  memory},
  author	= {Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Ye, He
		  and Wang, Yanlin},
  booktitle	= {Proceedings of the AAAI Conference on Artificial
		  Intelligence},
  volume	= {38},
  pages		= {19724--19731},
  year		= {2024}
}

@Article{	  hu2024hiagent,
  title		= {Hiagent: Hierarchical working memory management for
		  solving long-horizon agent tasks with large language
		  model},
  author	= {Hu, Mengkang and Chen, Tianxing and Chen, Qiguang and Mu,
		  Yao and Shao, Wenqi and Luo, Ping},
  journal	= {arXiv preprint arXiv:2408.09559},
  year		= {2024}
}

@Article{	  li2024banishing,
  title		= {Banishing LLM hallucinations requires rethinking
		  generalization},
  author	= {Li, Johnny and Consul, Saksham and Zhou, Eda and Wong,
		  James and Farooqui, Naila and Ye, Yuxin and Manohar,
		  Nithyashree and Wei, Zhuxiaona and Wu, Tian and Echols, Ben
		  and others},
  journal	= {arXiv preprint arXiv:2406.17642},
  year		= {2024}
}

@Article{	  qian2024memorag,
  title		= {Memorag: Moving towards next-gen rag via memory-inspired
		  knowledge discovery},
  author	= {Qian, Hongjin and Zhang, Peitian and Liu, Zheng and Mao,
		  Kelong and Dou, Zhicheng},
  journal	= {arXiv preprint arXiv:2409.05591},
  year		= {2024}
}

@Article{	  padmanabhan2024propagating,
  title		= {Propagating knowledge updates to lms through
		  distillation},
  author	= {Padmanabhan, Shankar and Onoe, Yasumasa and Zhang, Michael
		  and Durrett, Greg and Choi, Eunsol},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {36},
  year		= {2024}
}

@InProceedings{	  tack2024online,
  title		= {Online Adaptation of Language Models with a Memory of
		  Amortized Contexts},
  author	= {Jihoon Tack and Jaehyung Kim and Eric Mitchell and Jinwoo
		  Shin and Yee Whye Teh and Jonathan Richard Schwarz},
  booktitle	= {The Thirty-eighth Annual Conference on Neural Information
		  Processing Systems},
  year		= {2024},
  url		= {https://openreview.net/forum?id=RIfgKCknTu}
}

@Article{	  zaheer2020big,
  title		= {Big bird: Transformers for longer sequences},
  author	= {Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar
		  Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon,
		  Santiago and Pham, Philip and Ravula, Anirudh and Wang,
		  Qifan and Yang, Li and others},
  journal	= {Advances in neural information processing systems},
  volume	= {33},
  pages		= {17283--17297},
  year		= {2020}
}

@Article{	  beltagy2020longformer,
  title		= {Longformer: The long-document transformer},
  author	= {Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal	= {arXiv preprint arXiv:2004.05150},
  year		= {2020}
}

@Article{	  chen2024melodi,
  title		= {MELODI: Exploring Memory Compression for Long Contexts},
  author	= {Chen, Yinpeng and Hutchins, DeLesley and Jansen, Aren and
		  Zhmoginov, Andrey and Racz, David and Andersen, Jesper},
  journal	= {arXiv preprint arXiv:2410.03156},
  year		= {2024}
}

@Article{	  liu2021p,
  title		= {P-tuning v2: Prompt tuning can be comparable to
		  fine-tuning universally across scales and tasks},
  author	= {Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng
		  Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal	= {arXiv preprint arXiv:2110.07602},
  year		= {2021}
}

@Article{	  an2024does,
  title		= {Why Does the Effective Context Length of LLMs Fall
		  Short?},
  author	= {An, Chenxin and Zhang, Jun and Zhong, Ming and Li, Lei and
		  Gong, Shansan and Luo, Yao and Xu, Jingjing and Kong,
		  Lingpeng},
  journal	= {arXiv preprint arXiv:2410.18745},
  year		= {2024}
}

@Article{	  ge2023context,
  title		= {In-context autoencoder for context compression in a large
		  language model},
  author	= {Ge, Tao and Hu, Jing and Wang, Lei and Wang, Xun and Chen,
		  Si-Qing and Wei, Furu},
  journal	= {arXiv preprint arXiv:2307.06945},
  year		= {2023}
}

@Article{	  mu2024learning,
  title		= {Learning to compress prompts with gist tokens},
  author	= {Mu, Jesse and Li, Xiang and Goodman, Noah},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {36},
  year		= {2024}
}

@Article{	  liao2024make,
  title		= {Make pre-trained model reversible: From parameter to
		  memory efficient fine-tuning},
  author	= {Liao, Baohao and Tan, Shaomu and Monz, Christof},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {36},
  year		= {2024}
}

@InProceedings{	  houlsby2019parameter,
  title		= {Parameter-efficient transfer learning for NLP},
  author	= {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski,
		  Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin
		  and Gesmundo, Andrea and Attariyan, Mona and Gelly,
		  Sylvain},
  booktitle	= {International conference on machine learning},
  pages		= {2790--2799},
  year		= {2019},
  organization	= {PMLR}
}

@Article{	  hu2021lora,
  title		= {Lora: Low-rank adaptation of large language models},
  author	= {Hu, Edward J and Shen, Yelong and Wallis, Phillip and
		  Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang,
		  Lu and Chen, Weizhu},
  journal	= {arXiv preprint arXiv:2106.09685},
  year		= {2021}
}

@InProceedings{	  he2016dual,
  title		= {Dual learning for machine translation},
  author	= {He, Di and Xia, Yingce and Qin, Tao and Wang, Liwei and
		  Yu, Nenghai and Liu, Tie-Yan and Ma, Wei-Ying},
  booktitle	= {Proceedings of the 30th International Conference on Neural
		  Information Processing Systems},
  pages		= {820--828},
  year		= {2016}
}

@Article{	  zheng2021duplex,
  title		= {Duplex sequence-to-sequence learning for reversible
		  machine translation},
  author	= {Zheng, Zaixiang and Zhou, Hao and Huang, Shujian and Chen,
		  Jiajun and Xu, Jingjing and Li, Lei},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {34},
  pages		= {21070--21084},
  year		= {2021}
}

@Article{	  dinh2014nice,
  title		= {Nice: Non-linear independent components estimation},
  author	= {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  journal	= {arXiv preprint arXiv:1410.8516},
  year		= {2014}
}

@InProceedings{	  dinh2022density,
  title		= {Density estimation using Real NVP},
  author	= {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio,
		  Samy},
  booktitle	= {International Conference on Learning Representations},
  year		= {2022}
}

@Article{	  qin2025ui,
  title		= {UI-TARS: Pioneering Automated GUI Interaction with Native
		  Agents},
  author	= {Qin, Yujia and Ye, Yining and Fang, Junjie and Wang,
		  Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda
		  and Li, Jiahao and Li, Yunxin and Huang, Shijue and
		  others},
  journal	= {arXiv preprint arXiv:2501.12326},
  year		= {2025}
}

@InProceedings{	  zheng2024towards,
  title		= {Towards learning a generalist model for embodied
		  navigation},
  author	= {Zheng, Duo and Huang, Shijia and Zhao, Lin and Zhong, Yiwu
		  and Wang, Liwei},
  booktitle	= {Proceedings of the IEEE/CVF Conference on Computer Vision
		  and Pattern Recognition},
  pages		= {13624--13634},
  year		= {2024}
}

@Article{	  sumers2023cognitive,
  title		= {Cognitive architectures for language agents},
  author	= {Sumers, Theodore R and Yao, Shunyu and Narasimhan, Karthik
		  and Griffiths, Thomas L},
  journal	= {arXiv preprint arXiv:2309.02427},
  year		= {2023}
}

@Article{	  zhu2024knowagent,
  title		= {Knowagent: Knowledge-augmented planning for llm-based
		  agents},
  author	= {Zhu, Yuqi and Qiao, Shuofei and Ou, Yixin and Deng, Shumin
		  and Zhang, Ningyu and Lyu, Shiwei and Shen, Yue and Liang,
		  Lei and Gu, Jinjie and Chen, Huajun},
  journal	= {arXiv preprint arXiv:2403.03101},
  year		= {2024}
}

@Article{	  kagaya2024rap,
  title		= {Rap: Retrieval-augmented planning with contextual memory
		  for multimodal llm agents},
  author	= {Kagaya, Tomoyuki and Yuan, Thong Jing and Lou, Yuxuan and
		  Karlekar, Jayashree and Pranata, Sugiri and Kinose, Akira
		  and Oguri, Koki and Wick, Felix and You, Yang},
  journal	= {arXiv preprint arXiv:2402.03610},
  year		= {2024}
}

@Article{	  jing2024large,
  title		= {When large language models meet vector databases: A
		  survey},
  author	= {Jing, Zhi and Su, Yongye and Han, Yikun and Yuan, Bo and
		  Xu, Haiyun and Liu, Chunjiang and Chen, Kehai and Zhang,
		  Min},
  journal	= {arXiv preprint arXiv:2402.01763},
  year		= {2024}
}

@Article{	  liu2024retrievalattention,
  title		= {Retrievalattention: Accelerating long-context llm
		  inference via vector retrieval},
  author	= {Liu, Di and Chen, Meng and Lu, Baotong and Jiang, Huiqiang
		  and Han, Zhenhua and Zhang, Qianxi and Chen, Qi and Zhang,
		  Chengruidong and Ding, Bailu and Zhang, Kai and others},
  journal	= {arXiv preprint arXiv:2409.10516},
  year		= {2024}
}

@Article{	  huang2023transformer,
  title		= {Transformer-patcher: One mistake worth one neuron},
  author	= {Huang, Zeyu and Shen, Yikang and Zhang, Xiaofeng and Zhou,
		  Jie and Rong, Wenge and Xiong, Zhang},
  journal	= {arXiv preprint arXiv:2301.09785},
  year		= {2023}
}

@Article{	  wang2024large,
  title		= {Large Scale Knowledge Washing},
  author	= {Wang, Yu and Wu, Ruihan and He, Zexue and Chen, Xiusi and
		  McAuley, Julian},
  journal	= {arXiv preprint arXiv:2405.16720},
  year		= {2024}
}

@Article{	  xu2023recomp,
  title		= {Recomp: Improving retrieval-augmented lms with compression
		  and selective augmentation},
  author	= {Xu, Fangyuan and Shi, Weijia and Choi, Eunsol},
  journal	= {arXiv preprint arXiv:2310.04408},
  year		= {2023}
}

@Article{	  yoon2024compact,
  title		= {Compact: Compressing retrieved documents actively for
		  question answering},
  author	= {Yoon, Chanwoong and Lee, Taewhoo and Hwang, Hyeon and
		  Jeong, Minbyul and Kang, Jaewoo},
  journal	= {arXiv preprint arXiv:2407.09014},
  year		= {2024}
}

@Article{	  nogueira2019document,
  title		= {Document expansion by query prediction},
  author	= {Nogueira, Rodrigo and Yang, Wei and Lin, Jimmy and Cho,
		  Kyunghyun},
  journal	= {arXiv preprint arXiv:1904.08375},
  year		= {2019}
}

@Article{	  zhu2024eventsum,
  title		= {EventSum: A Large-Scale Event-Centric Summarization
		  Dataset for Chinese Multi-News Documents},
  author	= {Zhu, Mengna and Zeng, Kaisheng and Wang, Mao and Xiao,
		  Kaiming and Hou, Lei and Huang, Hongbin and Li, Juanzi},
  journal	= {arXiv preprint arXiv:2412.11814},
  year		= {2024}
}

@Article{	  sukhbaatar2019augmenting,
  title		= {Augmenting self-attention with persistent memory},
  author	= {Sukhbaatar, Sainbayar and Grave, Edouard and Lample,
		  Guillaume and Jegou, Herve and Joulin, Armand},
  journal	= {arXiv preprint arXiv:1907.01470},
  year		= {2019}
}

@Article{	  zancato2024b,
  title		= {B'MOJO: Hybrid State Space Realizations of Foundation
		  Models with Eidetic and Fading Memory},
  author	= {Zancato, Luca and Seshadri, Arjun and Dukler, Yonatan and
		  Golatkar, Aditya and Shen, Yantao and Bowman, Benjamin and
		  Trager, Matthew and Achille, Alessandro and Soatto,
		  Stefano},
  journal	= {arXiv preprint arXiv:2407.06324},
  year		= {2024}
}

@Article{	  graves2014neural,
  title		= {Neural Turing Machines},
  author	= {Graves, Alex},
  journal	= {arXiv preprint arXiv:1410.5401},
  year		= {2014}
}

@Article{	  ramsauer2020hopfield,
  title		= {Hopfield networks is all you need},
  author	= {Ramsauer, Hubert and Sch{\"a}fl, Bernhard and Lehner,
		  Johannes and Seidl, Philipp and Widrich, Michael and Adler,
		  Thomas and Gruber, Lukas and Holzleitner, Markus and
		  Pavlovi{\'c}, Milena and Sandve, Geir Kjetil and others},
  journal	= {arXiv preprint arXiv:2008.02217},
  year		= {2020}
}

@Article{	  dai2019transformer,
  title		= {Transformer-xl: Attentive language models beyond a
		  fixed-length context},
  author	= {Dai, Zihang},
  journal	= {arXiv preprint arXiv:1901.02860},
  year		= {2019}
}

@Article{	  he2024mixture,
  title		= {Mixture of a million experts},
  author	= {He, Xu Owen},
  journal	= {arXiv preprint arXiv:2407.04153},
  year		= {2024}
}

@Article{	  sun2024learning,
  title		= {Learning to (learn at test time): Rnns with expressive
		  hidden states},
  author	= {Sun, Yu and Li, Xinhao and Dalal, Karan and Xu, Jiarui and
		  Vikram, Arjun and Zhang, Genghan and Dubois, Yann and Chen,
		  Xinlei and Wang, Xiaolong and Koyejo, Sanmi and others},
  journal	= {arXiv preprint arXiv:2407.04620},
  year		= {2024}
}

@Article{	  li2024prompt,
  title		= {Prompt compression for large language models: A survey},
  author	= {Li, Zongqian and Liu, Yinhong and Su, Yixuan and Collier,
		  Nigel},
  journal	= {arXiv preprint arXiv:2410.12388},
  year		= {2024}
}

@Article{	  deletang2023language,
  title		= {Language modeling is compression},
  author	= {Del{\'e}tang, Gr{\'e}goire and Ruoss, Anian and Duquenne,
		  Paul-Ambroise and Catt, Elliot and Genewein, Tim and
		  Mattern, Christopher and Grau-Moya, Jordi and Wenliang, Li
		  Kevin and Aitchison, Matthew and Orseau, Laurent and others},
  journal	= {arXiv preprint arXiv:2309.10668},
  year		= {2023}
}

@Article{	  rissanen1976generalized,
  title		= {Generalized Kraft inequality and arithmetic coding},
  author	= {Rissanen, Jorma J},
  journal	= {IBM Journal of research and development},
  volume	= {20},
  number	= {3},
  pages		= {198--203},
  year		= {1976},
  publisher	= {IBM}
}

@PhDThesis{	  pasco1976source,
  title		= {Source coding algorithms for fast data compression},
  author	= {Pasco, Richard Clark},
  year		= {1976},
  school	= {Stanford University CA}
}

@Article{	  yang2024text,
  title		= {Memory$^3$: Language Modeling with Explicit Memory},
  author	= {Yang, Hongkang and Lin, Zehao and Wang, Wenjin and Wu, Hao
		  and Li, Zhiyu and Tang, Bo and Wei, Wenqiang and Wang,
		  Jinbo and Tang, Zeyun and Song, Shichao and others},
  journal	= {arXiv preprint arXiv:2407.01178},
  year		= {2024}
}

@Article{	  gao2024memory,
  title		= {Memory Sharing for Large Language Model based Agents},
  author	= {Gao, Hang and Zhang, Yongfeng},
  journal	= {arXiv preprint arXiv:2404.09982},
  year		= {2024}
}

@Article{	  farahani2024deciphering,
  title		= {Deciphering the Interplay of Parametric and Non-parametric
		  Memory in Retrieval-augmented Language Models},
  author	= {Farahani, Mehrdad and Johansson, Richard},
  journal	= {arXiv preprint arXiv:2410.05162},
  year		= {2024}
}

@Article{	  rae2019compressive,
  title		= {Compressive transformers for long-range sequence
		  modelling},
  author	= {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M
		  and Lillicrap, Timothy P},
  journal	= {arXiv preprint arXiv:1911.05507},
  year		= {2019}
}

@Article{	  gao2020pile,
  title		= {The pile: An 800gb dataset of diverse text for language
		  modeling},
  author	= {Gao, Leo and Biderman, Stella and Black, Sid and Golding,
		  Laurence and Hoppe, Travis and Foster, Charles and Phang,
		  Jason and He, Horace and Thite, Anish and Nabeshima, Noa
		  and others},
  journal	= {arXiv preprint arXiv:2101.00027},
  year		= {2020}
}

@Article{	  zhang2024survey,
  title		= {A survey on the memory mechanism of large language model
		  based agents},
  author	= {Zhang, Zeyu and Bo, Xiaohe and Ma, Chen and Li, Rui and
		  Chen, Xu and Dai, Quanyu and Zhu, Jieming and Dong, Zhenhua
		  and Wen, Ji-Rong},
  journal	= {arXiv preprint arXiv:2404.13501},
  year		= {2024}
}

@Article{	  paszke2019pytorch,
  title		= {Pytorch: An imperative style, high-performance deep
		  learning library},
  author	= {Paszke, Adam and Gross, Sam and Massa, Francisco and
		  Lerer, Adam and Bradbury, James and Chanan, Gregory and
		  Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and
		  Antiga, Luca and others},
  journal	= {Advances in neural information processing systems},
  volume	= {32},
  year		= {2019}
}

@Article{	  wang2024oscar,
  title		= {Oscar: Operating system control via state-aware reasoning
		  and re-planning},
  author	= {Wang, Xiaoqiang and Liu, Bang},
  journal	= {arXiv preprint arXiv:2410.18963},
  year		= {2024}
}

@InProceedings{	  sun-etal-2024-enhancing-agent,
  title		= "Enhancing Agent Learning through World Dynamics Modeling",
  author	= "Sun, Zhiyuan and Shi, Haochen and C{\^o}t{\'e},
		  Marc-Alexandre and Berseth, Glen and Yuan, Xingdi and Liu,
		  Bang",
  editor	= "Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung",
  booktitle	= "Findings of the Association for Computational Linguistics:
		  EMNLP 2024",
  month		= nov,
  year		= "2024",
  address	= "Miami, Florida, USA",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.findings-emnlp.202/",
  doi		= "10.18653/v1/2024.findings-emnlp.202",
  pages		= "3534--3568"
}

@InProceedings{	  gangadhar-stratos-2024-model,
  title		= "Model Editing by Standard Fine-Tuning",
  author	= "Gangadhar, Govind Krishnan and Stratos, Karl",
  editor	= "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
  booktitle	= "Findings of the Association for Computational Linguistics:
		  ACL 2024",
  month		= aug,
  year		= "2024",
  address	= "Bangkok, Thailand",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.findings-acl.352/",
  doi		= "10.18653/v1/2024.findings-acl.352",
  pages		= "5907--5913"
}

@InProceedings{	  wang-etal-2024-fac2e,
  title		= "{FAC}$^2${E}: Better Understanding Large Language Model
		  Capabilities by Dissociating Language and Cognition",
  author	= "Wang, Xiaoqiang and Wu, Lingfei and Ma, Tengfei and Liu,
		  Bang",
  editor	= "Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung",
  booktitle	= "Proceedings of the 2024 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= nov,
  year		= "2024",
  address	= "Miami, Florida, USA",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.emnlp-main.734/",
  doi		= "10.18653/v1/2024.emnlp-main.734",
  pages		= "13228--13243"
}

@InProceedings{	  yin-etal-2024-explicit,
  title		= "Explicit Memory Learning with Expectation Maximization",
  author	= "Yin, Zhangyue and Sun, Qiushi and Guo, Qipeng and Zeng,
		  Zhiyuan and Cheng, Qinyuan and Qiu, Xipeng and Huang,
		  Xuanjing",
  editor	= "Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung",
  booktitle	= "Proceedings of the 2024 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= nov,
  year		= "2024",
  address	= "Miami, Florida, USA",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.emnlp-main.927/",
  doi		= "10.18653/v1/2024.emnlp-main.927",
  pages		= "16618--16635"
}

@InProceedings{	  yoon-etal-2024-compact,
  title		= "{C}omp{A}ct: Compressing Retrieved Documents Actively for
		  Question Answering",
  author	= "Yoon, Chanwoong and Lee, Taewhoo and Hwang, Hyeon and
		  Jeong, Minbyul and Kang, Jaewoo",
  editor	= "Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung",
  booktitle	= "Proceedings of the 2024 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= nov,
  year		= "2024",
  address	= "Miami, Florida, USA",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.emnlp-main.1194/",
  doi		= "10.18653/v1/2024.emnlp-main.1194",
  pages		= "21424--21439"
}

@InProceedings{	  jiang-etal-2024-longllmlingua,
  title		= "{L}ong{LLML}ingua: Accelerating and Enhancing {LLM}s in
		  Long Context Scenarios via Prompt Compression",
  author	= "Jiang, Huiqiang and Wu, Qianhui and Luo, Xufang and Li,
		  Dongsheng and Lin, Chin-Yew and Yang, Yuqing and Qiu, Lili",
  editor	= "Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek",
  booktitle	= "Proceedings of the 62nd Annual Meeting of the Association
		  for Computational Linguistics (Volume 1: Long Papers)",
  month		= aug,
  year		= "2024",
  address	= "Bangkok, Thailand",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2024.acl-long.91/",
  doi		= "10.18653/v1/2024.acl-long.91",
  pages		= "1658--1677"
}

@InProceedings{	  wu-2023-duplex,
  title		= "Duplex Diffusion Models Improve Speech-to-Speech
		  Translation",
  author	= "Wu, Xianchao",
  editor	= "Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki",
  booktitle	= "Findings of the Association for Computational Linguistics:
		  ACL 2023",
  month		= jul,
  year		= "2023",
  address	= "Toronto, Canada",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.findings-acl.509/",
  doi		= "10.18653/v1/2023.findings-acl.509",
  pages		= "8035--8047"
}

@InProceedings{	  w-etal-2023-query,
  title		= "Query-as-context Pre-training for Dense Passage Retrieval",
  author	= "W, Xing and Ma, Guangyuan and Qian, Wanhui and Lin, Zijia
		  and Hu, Songlin",
  editor	= "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle	= "Proceedings of the 2023 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= dec,
  year		= "2023",
  address	= "Singapore",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.emnlp-main.118/",
  doi		= "10.18653/v1/2023.emnlp-main.118",
  pages		= "1906--1916"
}

@InProceedings{	  chevalier-etal-2023-adapting,
  title		= "Adapting Language Models to Compress Contexts",
  author	= "Chevalier, Alexis and Wettig, Alexander and Ajith, Anirudh
		  and Chen, Danqi",
  editor	= "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle	= "Proceedings of the 2023 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= dec,
  year		= "2023",
  address	= "Singapore",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.emnlp-main.232/",
  doi		= "10.18653/v1/2023.emnlp-main.232",
  pages		= "3829--3846"
}

@InProceedings{	  li-etal-2023-compressing,
  title		= "Compressing Context to Enhance Inference Efficiency of
		  Large Language Models",
  author	= "Li, Yucheng and Dong, Bo and Guerin, Frank and Lin,
		  Chenghua",
  editor	= "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle	= "Proceedings of the 2023 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= dec,
  year		= "2023",
  address	= "Singapore",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.emnlp-main.391/",
  doi		= "10.18653/v1/2023.emnlp-main.391",
  pages		= "6342--6353"
}

@InProceedings{	  jiang-etal-2023-llmlingua,
  title		= "{LLML}ingua: Compressing Prompts for Accelerated Inference
		  of Large Language Models",
  author	= "Jiang, Huiqiang and Wu, Qianhui and Lin, Chin-Yew and
		  Yang, Yuqing and Qiu, Lili",
  editor	= "Bouamor, Houda and Pino, Juan and Bali, Kalika",
  booktitle	= "Proceedings of the 2023 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= dec,
  year		= "2023",
  address	= "Singapore",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.emnlp-main.825/",
  doi		= "10.18653/v1/2023.emnlp-main.825",
  pages		= "13358--13376"
}

@InProceedings{	  mallen-etal-2023-trust,
  title		= "When Not to Trust Language Models: Investigating
		  Effectiveness of Parametric and Non-Parametric Memories",
  author	= "Mallen, Alex and Asai, Akari and Zhong, Victor and Das,
		  Rajarshi and Khashabi, Daniel and Hajishirzi, Hannaneh",
  editor	= "Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki",
  booktitle	= "Proceedings of the 61st Annual Meeting of the Association
		  for Computational Linguistics (Volume 1: Long Papers)",
  month		= jul,
  year		= "2023",
  address	= "Toronto, Canada",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2023.acl-long.546/",
  doi		= "10.18653/v1/2023.acl-long.546",
  pages		= "9802--9822"
}

@InProceedings{	  zhong-etal-2022-unsupervised,
  title		= "Unsupervised Multi-Granularity Summarization",
  author	= "Zhong, Ming and Liu, Yang and Ge, Suyu and Mao, Yuning and
		  Jiao, Yizhu and Zhang, Xingxing and Xu, Yichong and Zhu,
		  Chenguang and Zeng, Michael and Han, Jiawei",
  editor	= "Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue",
  booktitle	= "Findings of the Association for Computational Linguistics:
		  EMNLP 2022",
  month		= dec,
  year		= "2022",
  address	= "Abu Dhabi, United Arab Emirates",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2022.findings-emnlp.366/",
  doi		= "10.18653/v1/2022.findings-emnlp.366",
  pages		= "4980--4995"
}

@InProceedings{	  gao-callan-2022-unsupervised,
  title		= "Unsupervised Corpus Aware Language Model Pre-training for
		  Dense Passage Retrieval",
  author	= "Gao, Luyu and Callan, Jamie",
  editor	= "Muresan, Smaranda and Nakov, Preslav and Villavicencio,
		  Aline",
  booktitle	= "Proceedings of the 60th Annual Meeting of the Association
		  for Computational Linguistics (Volume 1: Long Papers)",
  month		= may,
  year		= "2022",
  address	= "Dublin, Ireland",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2022.acl-long.203/",
  doi		= "10.18653/v1/2022.acl-long.203",
  pages		= "2843--2853"
}

@InProceedings{	  huang-etal-2021-efficient,
  title		= "Efficient Attentions for Long Document Summarization",
  author	= "Huang, Luyang and Cao, Shuyang and Parulian, Nikolaus and
		  Ji, Heng and Wang, Lu",
  editor	= "Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer,
		  Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard,
		  Steven and Cotterell, Ryan and Chakraborty, Tanmoy and
		  Zhou, Yichao",
  booktitle	= "Proceedings of the 2021 Conference of the North American
		  Chapter of the Association for Computational Linguistics:
		  Human Language Technologies",
  month		= jun,
  year		= "2021",
  address	= "Online",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2021.naacl-main.112/",
  doi		= "10.18653/v1/2021.naacl-main.112",
  pages		= "1419--1436"
}

@InProceedings{	  dasigi-etal-2021-dataset,
  title		= "A Dataset of Information-Seeking Questions and Answers
		  Anchored in Research Papers",
  author	= "Dasigi, Pradeep and Lo, Kyle and Beltagy, Iz and Cohan,
		  Arman and Smith, Noah A. and Gardner, Matt",
  editor	= "Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer,
		  Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard,
		  Steven and Cotterell, Ryan and Chakraborty, Tanmoy and
		  Zhou, Yichao",
  booktitle	= "Proceedings of the 2021 Conference of the North American
		  Chapter of the Association for Computational Linguistics:
		  Human Language Technologies",
  month		= jun,
  year		= "2021",
  address	= "Online",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2021.naacl-main.365/",
  doi		= "10.18653/v1/2021.naacl-main.365",
  pages		= "4599--4610"
}

@InProceedings{	  lester-etal-2021-power,
  title		= "The Power of Scale for Parameter-Efficient Prompt Tuning",
  author	= "Lester, Brian and Al-Rfou, Rami and Constant, Noah",
  editor	= "Moens, Marie-Francine and Huang, Xuanjing and Specia,
		  Lucia and Yih, Scott Wen-tau",
  booktitle	= "Proceedings of the 2021 Conference on Empirical Methods in
		  Natural Language Processing",
  month		= nov,
  year		= "2021",
  address	= "Online and Punta Cana, Dominican Republic",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2021.emnlp-main.243/",
  doi		= "10.18653/v1/2021.emnlp-main.243",
  pages		= "3045--3059"
}

@InProceedings{	  li-liang-2021-prefix,
  title		= "Prefix-Tuning: Optimizing Continuous Prompts for
		  Generation",
  author	= "Li, Xiang Lisa and Liang, Percy",
  editor	= "Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli,
		  Roberto",
  booktitle	= "Proceedings of the 59th Annual Meeting of the Association
		  for Computational Linguistics and the 11th International
		  Joint Conference on Natural Language Processing (Volume 1:
		  Long Papers)",
  month		= aug,
  year		= "2021",
  address	= "Online",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2021.acl-long.353/",
  doi		= "10.18653/v1/2021.acl-long.353",
  pages		= "4582--4597"
}

@InProceedings{	  wolf-etal-2020-transformers,
  title		= "Transformers: State-of-the-Art Natural Language
		  Processing",
  author	= "Wolf, Thomas and Debut, Lysandre and Sanh, Victor and
		  Chaumond, Julien and Delangue, Clement and Moi, Anthony and
		  Cistac, Pierric and Rault, Tim and Louf, Remi and
		  Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and
		  von Platen, Patrick and Ma, Clara and Jernite, Yacine and
		  Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger,
		  Sylvain and Drame, Mariama and Lhoest, Quentin and Rush,
		  Alexander",
  editor	= "Liu, Qun and Schlangen, David",
  booktitle	= "Proceedings of the 2020 Conference on Empirical Methods in
		  Natural Language Processing: System Demonstrations",
  month		= oct,
  year		= "2020",
  address	= "Online",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2020.emnlp-demos.6/",
  doi		= "10.18653/v1/2020.emnlp-demos.6",
  pages		= "38--45"
}

@InProceedings{	  lo-etal-2020-s2orc,
  title		= "{S}2{ORC}: The Semantic Scholar Open Research Corpus",
  author	= "Lo, Kyle and Wang, Lucy Lu and Neumann, Mark and Kinney,
		  Rodney and Weld, Daniel",
  editor	= "Jurafsky, Dan and Chai, Joyce and Schluter, Natalie and
		  Tetreault, Joel",
  booktitle	= "Proceedings of the 58th Annual Meeting of the Association
		  for Computational Linguistics",
  month		= jul,
  year		= "2020",
  address	= "Online",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/2020.acl-main.447/",
  doi		= "10.18653/v1/2020.acl-main.447",
  pages		= "4969--4983"
}

@InProceedings{	  fabbri-etal-2019-multi,
  title		= "Multi-News: A Large-Scale Multi-Document Summarization
		  Dataset and Abstractive Hierarchical Model",
  author	= "Fabbri, Alexander and Li, Irene and She, Tianwei and Li,
		  Suyi and Radev, Dragomir",
  editor	= "Korhonen, Anna and Traum, David and M{\`a}rquez,
		  Llu{\'i}s",
  booktitle	= "Proceedings of the 57th Annual Meeting of the Association
		  for Computational Linguistics",
  month		= jul,
  year		= "2019",
  address	= "Florence, Italy",
  publisher	= "Association for Computational Linguistics",
  url		= "https://aclanthology.org/P19-1102/",
  doi		= "10.18653/v1/P19-1102",
  pages		= "1074--1084"
}

@Article{	  kocisky-etal-2018-narrativeqa,
  title		= "The {N}arrative{QA} Reading Comprehension Challenge",
  author	= "Ko{\v{c}}isk{\'y}, Tom{\'a}{\v{s}} and Schwarz, Jonathan
		  and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz
		  and Melis, G{\'a}bor and Grefenstette, Edward",
  editor	= "Lee, Lillian and Johnson, Mark and Toutanova, Kristina and
		  Roark, Brian",
  journal	= "Transactions of the Association for Computational
		  Linguistics",
  volume	= "6",
  year		= "2018",
  address	= "Cambridge, MA",
  publisher	= "MIT Press",
  url		= "https://aclanthology.org/Q18-1023/",
  doi		= "10.1162/tacl_a_00023",
  pages		= "317--328"
}
