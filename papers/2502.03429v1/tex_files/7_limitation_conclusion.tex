\section{Conclusion}
\label{sec:limitation_conclusion}

\paragraph{Conclusion}
We examined demographic bias (e.g., gender, race) in unified multimodal large language models (U-MLLMs). We proposed a balanced preference optimization framework that combines supervised finetuning with a preference deviation penalty. Our experiments show that this method effectively reduces bias while maintaining high image quality and semantic fidelity. Moreover, our analysis of understanding versus generation bias underscores the importance of addressing \emph{both} visual reasoning and token-level preference shaping for comprehensive alignment. We hope these findings will guide future work toward building multimodal models with stronger fairness guarantees. Our work also have some limitation as illustrated in \autoref{sec:limitation}.


\paragraph{Impact Statement.}
Our work addresses the challenge of demographic bias in unified multimodal language models, aiming to ensure fair image generation for different demographic groups. Our methods can help mitigate harmful stereotypes and minimize the risk of reinforcing inequalities in automatically generated content. We believe ongoing work from researchers, policymakers, and the communities represented is important to maximize the societal benefits of debiasing techniques while maintaining transparency and fairness in machine learning systems. 

