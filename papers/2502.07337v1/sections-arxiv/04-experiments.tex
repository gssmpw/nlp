
\begin{table}[t]
\centering
\caption{Comparison of neural samplers on GMM-40, MW-32, and DW-4 energy functions, with mean and standard deviation based on five evaluations using different random seeds.}
\vspace{-2mm}
\label{tab:main_results}
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccc}
\toprule
Energy $\rightarrow$ & \multicolumn{2}{c}{GMM-40 ($d = 2$)} & \multicolumn{2}{c}{MW-32 ($d = 32$)} & \multicolumn{3}{c}{DW-4 ($d = 8$)} \\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-8}
 Method $\downarrow$ & $\mathcal{E}$-$\mathcal{W}_2$ & $\mathcal{X}$-TV & $\mathcal{E}$-TV & $\mathcal{X}$-$\mathcal{W}_2$ & $\mathcal{E}$-$\mathcal{W}_2$ & $\mathcal{E}$-TV & $\mathcal{D}$-TV \\
\midrule
FAB \citep{midgley2022flow} & 
$8.89\text{\scalebox{0.7}{$\pm 2.20$}}$ & $0.84\text{\scalebox{0.7}{$\pm 0.19$}}$ & $0.25\text{\scalebox{0.7}{$\pm 0.01$}}$ & $5.78\text{\scalebox{0.7}{$\pm 0.02$}}$ & $0.64\text{\scalebox{0.7}{$\pm 0.20$}}$ & $0.22\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.09\text{\scalebox{0.7}{$\pm 0.01$}}$\\
iDEM \citep{AkhoundSadegh2024IteratedDE} & 
$1.27\text{\scalebox{0.7}{$\pm 0.21$}}$ & $0.83\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.63\text{\scalebox{0.7}{$\pm 0.15$}}$ & $8.18\text{\scalebox{0.7}{$\pm 0.04$}}$ & $0.19\text{\scalebox{0.7}{$\pm 0.05$}}$ & $0.21\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.10\text{\scalebox{0.7}{$\pm 0.01$}}$\\
LFIS \citep{tian2024liouville} & 
$0.27\text{\scalebox{0.7}{$\pm 0.21$}}$ & $0.84\text{\scalebox{0.7}{$\pm 0.01$}}$ &
$\infty$ & $8.89\text{\scalebox{0.7}{$\pm 0.03$}}$  & $6.06\text{\scalebox{0.7}{$\pm 1.05$}}$ & $0.66\text{\scalebox{0.7}{$\pm 0.02$}}$ & $0.29\text{\scalebox{0.7}{$\pm 0.01$}}$\\
\midrule
\ours-128 (ours) & 
$0.46\text{\scalebox{0.7}{$\pm 0.14$}}$ & $0.67\text{\scalebox{0.7}{$\pm 0.00$}}$ & $0.16\text{\scalebox{0.7}{$\pm 0.00$}}$ & $6.17\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.44\text{\scalebox{0.7}{$\pm 0.03$}}$ & $0.10\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.07\text{\scalebox{0.7}{$\pm 0.01$}}$\\
\ours-64 (ours) & 
$1.32\text{\scalebox{0.7}{$\pm 0.29$}}$ & $0.69\text{\scalebox{0.7}{$\pm 0.01$}}$ &
$0.18\text{\scalebox{0.7}{$\pm 0.00$}}$ & $6.34\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.98\text{\scalebox{0.7}{$\pm 0.16$}}$ & $0.13\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.11\text{\scalebox{0.7}{$\pm 0.01$}}$\\
\ours-32 (ours) & 
$4.38\text{\scalebox{0.7}{$\pm 1.14$}}$ & $0.72\text{\scalebox{0.7}{$\pm 0.01$}}$ &
$0.49\text{\scalebox{0.7}{$\pm 0.01$}}$ & $9.05\text{\scalebox{0.7}{$\pm 0.01$}}$ & $14.97\text{\scalebox{0.7}{$\pm 0.82$}}$ & $0.41\text{\scalebox{0.7}{$\pm 0.01$}}$ & $0.28\text{\scalebox{0.7}{$\pm 0.01$}}$\\
\bottomrule
\end{tabular}
}
\end{table}


\begin{figure}[!t]
\vspace{-5mm}
    \centering
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/gmm/data_samples.png}
        Ground Truth
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/gmm/fab_samples.png}
        FAB
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/gmm/idem_samples.png}
        iDEM
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/gmm/lfis_samples.png}
        LFIS
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/gmm/nfs_samples.png}
        \ours (ours)
    \end{minipage}
    \vspace{-2mm}
    \caption{Samples of GMM-40, with contour lines representing the ground truth distribution.}
    \label{fig:gmm-visualised}
\end{figure}

\begin{figure}[!t]
    \vspace{-4mm}
    \centering
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/mw-32/data_samples.png}
        Ground Truth
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/mw-32/fab_samples.png}
        FAB
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/mw-32/idem_samples.png}
        iDEM
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/mw-32/lfis_samples.png}
        LFIS
    \end{minipage}
    \begin{minipage}[t]{0.195\linewidth}
        \centering
        \includegraphics[width=1.\linewidth]{figures/samples/mw-32/nfs_samples.png}
        \ours (ours)
    \end{minipage}
    \vspace{-2mm}
    \caption{2D marginal samples from the 1st and 3rd dimensions of MW-32.}
    \vspace{-4mm}
    \label{fig:mw32-visualised}
\end{figure}

\section{Experiments}
We evaluate our method against baselines on three distinct energy functions: i) a 2-dimensional Gaussian Mixture Model with 40 components (GMM-40), ii) a 32-dimensional many-well (MW-32) distribution, and iii) an 8-dimensional 4-particle double-well (DW-4) potential. Experimental details and additional results are provided in \cref{sec:sppendix_exp_details,sec:appendix_add_exp_results}.

\textbf{Baselines.} We compare against three recent methods: Flow Annealed Importance Sampling Bootstrap (FAB) \citep{midgley2022flow}, Iterated Denoising Energy Matching (iDEM) \citep{AkhoundSadegh2024IteratedDE} with $1000$ sampling steps, and Liouville Flow Importance Sampling (LFIS) \citep{tian2024liouville} with $256$ sampling steps.
We denote the proposed method with $M$ sampling steps as \ours-$M$.

\begin{wrapfigure}{r}{0.54\linewidth}
    \centering
    \vspace{-4mm}
    \includegraphics[width=.53\textwidth]{figures/samples/dw-4/dw4_hist.png}
    \vspace{-2mm}
    \caption{Histogram of interatomic distance and sample energy on DW-4.}
    \label{fig:dw4-hist}
    \vspace{-5mm}
\end{wrapfigure}
\textbf{Results and Discussion.} 
\cref{tab:main_results} presents a comparison of our method with baselines across various metrics, showing that \ours outperforms better in most cases. Specifically, compared to LFIS, the method most similar to ours in learning velocity and estimating $\partial_t \log Z_t$ via importance sampling, \ours exhibits superior performance. This highlights the effectiveness of our variance reduction techniques through SMC and control variates. 
When compared to iDEM, the current SOTA diffusion-based sampler, \ours surpasses iDEM on GMM-40 and MW-32, achieving comparable performance on DW-4. Notably, \ours achieves this with significantly fewer sampling steps than iDEM, further emphasizing its superiority.
We visualize the generated GMM-40 samples in \cref{fig:gmm-visualised}, where \ours is the only method that captures both the diversity and sharpness of the modes. 
MW-32 samples are shown in \cref{fig:mw32-visualised}, where LFIS and iDEM fail to accurately model the position and weight of modes, while FAB and \ours excel at both.
Moreover, we also visualize histograms for sample energy and interatomic distance in \cref{fig:dw4-hist}. As shown, \ours achieves competitive performance with both FAB and iDEM, and notably outperforms LFIS.
For additional experimental results, please refer to \cref{sec:appendix_add_exp_results}.
