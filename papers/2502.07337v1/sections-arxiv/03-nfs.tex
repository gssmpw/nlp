\section{Neural Flow Sampler}
To learn a model-based velocity $v_t (x; \theta)$, parametrised by $\theta$, we first define the probability path $p_t$. Specifically, given a tractable base distribution $\eta$, the path is constructed using annealing interpolation as $p_t \propto \rho^t \eta^{1-t} =: \tilde{p}_t$. The velocity can then be learned by minimizing the following loss
\begin{align} \label{eq:nfs_loss}
    \mathcal{L}(\theta) \!=\! \E_{q(x),w(t)}  \delta_t^2(x;v_t(\cdot;\theta)), \quad \delta_t(x;v_t) \!\triangleq\! \partial_t \log p_t (x) \!+\! \nabla_x \cdot v_t (x) \!+\! v_t (x) \cdot \nabla_x \log p_t (x),
\end{align}
where $q(x)$ is any distribution has the same support of the target $\pi$ and $w(t)$ denotes the time schedule distribution.
This objective, initially proposed by \cite{tian2024liouville}, poses several challenges. First, computing the divergence $\nabla_x \cdot v_t (x)$ can be prohibitive in high-dimension; however, this issue can be mitigated using the Hutchinson estimator \citep{hutchinson1989stochastic}. More critically, the time derivative introduces additional complexity, as it involves $\partial_t \log p_t (x) = \partial_t \log \tilde{p}_t (x) - \partial_t \log Z_t$ with $Z_t = \int  \tilde{p}_t (x) \dif x$, which is intractable. 
\cite{tian2024liouville} estimate it using importance sampling $\partial_t \log Z_t \approx \sum_k \frac{w_k}{\sum_k w_k} \partial_t \log \tilde{p}_t (x_t^{(k)})$, where $x_t^{(k)} \sim p_t (x;\theta)$ denotes the sample generated by the velocity $v_t (x;\theta)$ at time $t$, and $\log w_t = \int_0^t \delta_s (x_s;v_s(\cdot;\theta)) \dif s$ (see \cref{sec:appendix_is} for details).
However, importance sampling can suffer from high variance if the proposal $p_t (x;\theta)$ differs significantly from the target $p_t (x)$, leading to a low effective sample size.
In the following, we propose a velocity-driven method to estimate the intractable time derivatives $\partial_t \log Z_t$.

\subsection{Velocity-Driven Sequential Monte Carlo Estimation}
As discussed before, even though importance sampling provides a simple way to approximate the intractable time derivatives, it often suffers from high variance.
To alleviate this issue, we propose to apply Sequential Monte Carlo (SMC), together with a velocity-driven transition kernel.
Considering discrete-time steps $0=t_0 < \dots < t_M = 1$,
The key ingredients of SMC are proposals $\{\mathcal{F}_{t_m} (x_{t_{m+1}} | x_{t_m})\}_{m=0}^{M-1}$ and weighting functions $\{w_{t_m}\}_{m=0}^M$. At the initial step, one draws $K$ particles of $x_{t_0}^{(k)} \sim p_{t_0}$ and set $w_{t_0}^{(k)} = p_{t_0} (x_{t_0}^{(k)})$, and sequentially repeats the following steps for $m=1,\dots,M$: i) \textit{resample} $\{x_{t_{m-1}}^{(k)}\}_{k=1}^K \sim \mathrm{Systematic}(\{x_{t_{m-1}}^{(k)}\}_{k=1}^K; \{w_{t_{m-1}}^{(k)}\}_{k=1}^K)$; ii) \textit{propose} $x_{t_m}^{(k)} \sim \mathcal{F}_{t_{m-1}}(x_{t_m} | x_{t_{m-1}})$ for $k=1,\dots,K$; and iii) \textit{weight} $w_t^{(k)} = \tilde{p}_{t_m}(x_{t_m}^{(k)}) / \tilde{p}_{t_{m-1}}(x_{t_m}^{(k)})$ for $k=1,\dots,K$.  
The time derivatives at time step $t$ can therefore be estimated via $\partial_t \log Z_t \approx \sum_k \frac{w_t^{(k)}}{\sum_k w_t^{(k)}} \partial_t \log \tilde{p}_t (x_t^{(k)})$ (see \cref{sec:appendix-smc} for details). This approximation becomes arbitrarily accurate in the limit as much as particles are used \cite[Proposition 11.4]{chopin2020introduction}.

The choice of the proposal in SMC is critical as a poor proposal can lead to trajectories that quickly collapse onto a single ancestor, reducing particle diversity and effectiveness. To address this issue,  we propose incorporating Markov Chain Monte Carlo (MCMC) steps into the SMC framework \citep{van2000unscented}. To further enhance MCMC convergence, we integrate it with a trainable velocity model. Specifically, the transition kernel $\mathcal{F}_{t_m} (x_{t_{m+1}} | x_{t_m})$ comprises two steps i) \textit{velocity move} with an Euler update $\hat{x}_{t_{m+1}} \!\!\!\leftarrow\! x_{t_m} \!\!+ v_{t_m}(x_{t_m}; \theta) (t_{m+1}\!-t_m)$ to provide a better initialisation; and ii) \textit{MCMC move} with a HMC \citep{neal2012mcmc} refinement $x_{t_{m+1}} \!\sim\! \mathrm{HMC}(\hat{x}_{t_{m+1}})$ to ensure consistency with the target distribution.
This velocity-driven MCMC kernel operates in a bootstrap manner, with the velocity move offering an informed initialisation that improves the efficiency of the subsequent MCMC step. As training progresses, the velocity model becomes increasingly accurate, generating high-quality proposals that reduce the corrections required during the MCMC step. This synergy between the velocity move and the MCMC refinement not only accelerates convergence but also preserves particle diversity, making the approach robust in high-dimensional or complex settings.

\textbf{Further Variance Reduction with Control Variates.}
To further reduce the variance, a key observation is that for any given velocity $v_t$, the following identity holds
\begin{align} \label{eq:partial_logZ_fpi}
    \!\!\!\!\!\partial_t \log Z_t \!\!=\!\! \argmin_{c_t} \!\E_{p_t} (\xi_t(x;v_t) \!-\! c_t)^2, \xi_t(x;v_t) \!\triangleq\! \partial_t \log \tilde{p}_t (x) \!+\! \nabla_x \!\cdot\! v_t (x) \!+\! v_t (x) \!\cdot\! \nabla_x \log p_t (x).
\end{align}
\begin{wrapfigure}{r}{0.42\linewidth}
    \centering
    \vspace{-4mm}
    \includegraphics[width=.39\textwidth]{figures/training/std_dt_logZt_plot.png}
    \vspace{-2mm}
    \caption{Standard deviation of the estimation of $\partial_t \log Z_t$.}
    \label{fig:std_dt_logZt}
    \vspace{-4mm}
\end{wrapfigure}
See \cref{sec:appendix-proof_partial_logZ} for proof. Thus, one can calculate the optimal $c_t$ via $\partial_t \log Z_t = \E_{p_t} \xi_t (x;v_t)$, which can be approximated using Monte Carlo estimation. Empirically, we observe that \cref{eq:partial_logZ_fpi} achieves lower variance compared to the approximation $\partial_t \log Z_t = \E_{p_t} \partial_t \log \tilde{p}_t (x)$, and it sometimes leads to better optimisation. We visualize the comparison of the standard deviation of the two estimation methods in \cref{fig:std_dt_logZt}, with the corresponding loss plots deferred to \cref{fig:loss}.
In \cref{sec:appendix-control-variates}, we provide a control variate perspective to explain this observation. Therefore, when combined with SMC, the time derivatives can be estimated as $\partial_t \log Z_t \approx \sum_k \frac{w_t^{(k)}}{\sum_k w_t^{(k)}} \xi_t (x_t^{(k)}; v_t)$.
To summarize, the velocity can then be learned by iterating the following steps i) $\theta \!\leftarrow\! \argmin_\theta \!\int_0^1 \E_{p_t} (\xi_t(x;v_t(x;\theta)) \!-\! c_t)^2 \dif t$; ii) $c_t \leftarrow \E_{p_t} \xi_t (x; v_t(x;\theta))$. 
Notably, \cite{mate2023learning} propose a similar method, where $c_t$ is parametrised as a neural network and trained using stochastic gradient descent by optimising objective in \cref{eq:partial_logZ_fpi}, rather than using SMC in conjunction with control variates.


\subsection{Neural Flow Shortcut Sampler}
With the time derivative estimator established in the previous sections, the velocity can be learned by minimizing the loss defined in \cref{eq:nfs_loss}. However, during sampling, small step sizes are required to control discretization error, resulting in high computational costs. To address this, we draw inspiration from the recent success of shortcut models \citep{frans2024one} and introduce an additional shortcut regularization to alleviate this issue.
The basic idea is to parameterise a shortcut model $s_t (x_t, d;\theta)$ to account for the future curvature, such that $x_{t+d} = x_t + s_t (x_t, d; \theta)d$. To this end, one can regularise the shortcut model to ensure that $s_t (x_t, 2d;\theta) = s_t (x_t, d;\theta)/2 + s_{t+d} (x_{t+d}, d;\theta)/2 =: s_{\text{target}}, \forall d,t$, which leads to the final objective
\begin{align} \label{eq:loss-nfs2}
    \mathcal{L}(\theta) = \E_{q(x), w(t)} \left[ \delta_t^2(x; s_t(\cdot, 0;\theta)) + \E_{p(d)} \lVert s_t(x, 2d;\theta) - s_{\text{target}} \rVert_2^2 \right].
\end{align}
We refer to the proposed methods as neural flow shortcut samplers (\ours), using $128$ sampling steps by default unless specified otherwise.
The training and sampling procedures are summarized in \cref{alg:nfs_training,alg:nfs_sampling}, respectively.