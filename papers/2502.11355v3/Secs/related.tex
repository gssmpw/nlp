\section{Related Work}

\noindent\textbf{Safety of Autonomous Agent.}
Autonomous LLM agents are considered key to achieving artificial general intelligence (AGI)~\citep{bengio2023managing, morris2023levels, wang2024survey}. Recent studies show that as LLMs are prone to safety risks~\citep{bengio2025superintelligent}, such as hallucinations~\citep{ji2023survey, rawte2023survey}, scheming~\citep{meinke2024frontier, jaech2024openai, ord2024case, greenblatt2024alignment, balesni2024towards} and deceptions~\citep{scheurer2024large, park2024ai, su2024ai}. \citet{phuong2024evaluating} explores the correlation between model sophistication and scheming or deception. In contrast to prior work, we focus on catastrophic risks by autonomous agents. The most closely related work is~\citet{rivera2024escalation}, which assesses escalation risks between countries via agents making diplomatic and military decisions. Works on non-autonomous safety risks, particularly in tool agents~\citep{zhan2024injecagent, ye2024toolsword, zhang2024agent}, fall outside our scope.

\noindent\textbf{CBRN Risks in AI.}
The extreme dangers of CBRN risks in AI have drawn considerable attention~\citep{lohn2018might, koessler2024risk, christodorescu2024securing,jaech2024openai, anthropic2024rsp, phuong2024evaluating,biden2023executive, dhs2024cbrnai}. Previous work mainly focuses on CBRN knowledge learned by LLMs, which may be maliciously exploited~\citep{urbina2022dual, anwar2024foundational, guest2024operational}. For example, \citet{li2024wmdp} propose the WMDP benchmark to assess LLMs' hazardous knowledge in weapons of mass destruction security. In contrast, our research examines CBRN risks arising from the \emph{decision-making} process of autonomous agents.

\noindent\textbf{LLM Agent-based Simulation.}
Agent-based simulation has long been used to model diverse systems~\citep{epstein1996growing, macal2009agent}. Recently, \citet{park2023generative} use LLM agents to simulate social interactions, with research extending to areas like daily activities~\citep{wang2024simulating}, governance~\citep{piatti2024cooperate}, social norms~\citep{ren2024emergence}, and harmful information spread~\citep{ju2024flooding}. Studies also explore decision-making in voting~\citep{yang2024llm} and financial trading~\citep{yu2024fincon}, as well as how biases~\citep{schmidgall2024agentclinic, bai2024fairmonitor} and prosocial irrationality~\citep{liu2024exploring} affect decisions. Our research uniquely simulates LLM agents' decision-making on \emph{catastrophic risks} and the \emph{driving factors} behind their decisions.
