\section{Details on Main Experiment Setups}
\label{sec:experimental-details}

\subsection{Evaluation Configuration}

We directly employ the exact prompts provided in \autoref{sec:method-info}. The default configurations for two of the tunable components, effectiveness and consequence, can be found in \autoref{fig:pauto-war} and \autoref{fig:pauto-lab}. Note that the default descriptions used in the main experiments are distinct from the three-level tunable configurations (ranging from low to high) discussed in \autoref{subsec:Tunable} and our extended experiments on decision-making factors (\autoref{subsec:influencing-factors}).

\subsection{Commercial (API-based) Models}

The model versions of OpenAI's LLMs used in our experiments are as follows:
\begin{itemize}
\item GPT-4-Turbo: \texttt{gpt-4-turbo-2024-04-09}
\item GPT-4o: \texttt{gpt-4o-2024-08-06}
\item GPT-4o-mini: \texttt{gpt-4o-mini-0718}
\item OpenAI o1: \texttt{o1-2024-12-17}
\item OpenAI o1-mini: \texttt{o1-mini-2024-09-12}
\item OpenAI o3-mini: \texttt{o3-mini-2025-01-31}
\end{itemize}

The API version of GPT-4 series models is \texttt{2024-08-01-preview} and \texttt{2024-12-01-preview} for all others. OpenAI o1/o3 series reasoning models require an additional parameter called \texttt{reasoning\_effort}\footnote{\url{https://platform.openai.com/docs/guides/reasoning\#reasoning-effort}}, we use the default parameters, which is \texttt{medium}. 

For setting the system prompt of the LLM agent (see \autoref{sec:method-info} for details), we use \texttt{system message}s for all models except for the OpenAI o1/o3 series reasoning models. For the OpenAI o1 and o3-mini models, we use \texttt{developer message}s, as \texttt{system message}s cannot be configured by users\footnote{Later, OpenAI stated that \texttt{developer message}s now function identically to the original system prompt, see \url{https://platform.openai.com/docs/guides/text-generation\#messages-and-roles}.}. For the o1-mini model, which does not accept system or developer messages, or messages with higher hierarchical levels \cite{chainofcommand}, we opt for a standard user prompt.

\subsection{Open-source Models}

For all open-source models, we perform all experiments using full-precision (FP32) computation. All models are served on two servers: one equipped with 8 NVIDIA A100 GPUs, the other equipped with 8 NVIDIA GeForce RTX 4090 GPUs.

\subsection{Claude-3.5-Sonnet in \war{}}
\label{subsec:exmples-rejecting-simulation}

In our experiments, Claude-3.5-Sonnet is the only model that consistently refuses to act as an autonomous agent in \war{}-related scenarios. Our tests show that its refusal rate in \war{} exceeds $95\%$, all other models have a refusal rate of $0\%$. As a result, simulation is not possible for Claude-3.5-Sonnet in \war{}.

Some reasons cited by Claude-3.5-Sonnet for refusing to engage in \war{}-related scenarios are listed in \autoref{tab:claude-rejection}. These responses reflect the model's strong focus on harm \avoidance{}, likely influenced by its general safety alignment. It is also possible that it has undergone task-specific alignment tuning for \war{}-related simulations. While this approach is understandable in high-stakes contexts, it may not align with users' expectations for LLM agents in other use cases, where a more flexible response is often desired.


\input{Tabs/claude-rejection}












