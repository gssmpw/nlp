\section{Related works}
\label{sec:related_works}

\subsection{Research for perceptual music similarity}
Several studies have been conducted on perceptual music similarity~\cite{McAdams2001, Eerola2001, Berenzwei2003, Novello2006, Mullensiefen2007, Typke2005, Novello2011, Volk2012}. In the previous study~\cite{Ellis2002}, the authors asked subjects to evaluate the similarity between artists in popular music and collected 22,000 answers. They also conducted expert evaluations and analyzed the relationship between acoustic features and perceptual music similarity~\cite{Berenzwei2003}. Novello et al.~\cite{Novello2006} have analyzed the results of the similarity evaluation experiment for popular music in terms of consistency across subjects and so on. They have also researched the important factors underlying perceptual music similarity~\cite{Novello2011}. 
\par
%The evaluations obtained in these studies are for the musical piece; no evaluation experiment has been conducted based on each instrumental part composing the musical piece.
These studies do not involve experiments where each individual instrumental part that composes a musical piece is listened to separately.


\subsection{Instrumental-part-based similarity learning}
\label{disent}
We have proposed a method to compute similarities focusing on each instrumental part with a single network that takes music tracks (i.e. mixed sounds) as input~\cite{has2023}. We have designed a similarity embedding space with disentangled subspaces for each instrument using Conditional Similarity Networks (CSNs)~\cite{CSN}.
\par
To disentangle the embedding space, a mask is applied to all dimensions except for the dimension corresponding to the notion to be considered in the triplet loss calculation. The network is given by function $f(\cdot)$, and $m_c$ is a mask that activates only the dimension corresponding to the condition $c$. The masked distance function between two samples $x_i$ and $x_j$ is given by
\begin {align}
\label{CSNtriplet}
d(x_i,x_j;m_c)=\parallel f(x_i)m_c-f(x_j)m_c\parallel_2.
\vspace{-24pt}
\end{align}
Letting $x_i^{(a)}$, $x_i^{(p)}$, and $x_i^{(n)}$ denote the $i$-th anchor, positive sample, and negative sample, respectively, $M$ denote the margin, the triplet loss can be written as follows.
\begin {align}
 &\mathcal{L}_T(x^{(a)},x^{(p)},x^{(n)},c)=\notag \\
 &\max\{0,d(x^{(a)},x^{(p)};m_c)-d(x^{(a)},x^{(n)};m_c)+M\}
\end{align}
\vspace{-24pt}
\\

 We have designed an embedding space whose subspaces are disentangled by the five instruments with condition $c$ where $c=0, 1, 2, 3, 4$ represent drums, bass, piano, guitar, and others, respectively. Let $D$ be the number of dimensions of subspace assigned for one instrument, and the subspace assigned to condition $c$ are as $f[cD:(c+1)D-1]$. The following formula defines the $m_c$ as a mask that leaves the subspace corresponding to each condition $c$ and sets the other dimensions to 0. 
\begin {align}
m_{ck} = \left\{
\begin{array}{ll}
1, & (cD\leqq k<(c+1)D)\\
0, & (\mbox{otherwise}).
\end{array}
\right.
\vspace{-8pt}
\end{align}

A triplet sampling method suitable for this method needs to satisfy a requirement: when learning a subspace corresponding to an instrument, an anchor and a positive sample are similar, and the anchor and a negative sample are dissimilar focusing on that instrument. To satisfy this requirement without using manual labels, for example in sampling for drums subspace, we have defined that music tracks that contain different time segments of the same drum sound are similar, and those that contain segments from different drum sounds are dissimilar. We have proposed the use of pseudo musical pieces and have shown that this method can improve the modelâ€™s performance.