\section{Literature Review}
\subsection{ERC-20}
The ERC-20 standard defines a set of rules for fungible tokens on the Ethereum blockchain, enabling interoperability between decentralized applications (DApps) and ensuring uniformity in token behavior **Buterin, "Ethereum Whitepaper"**. The standard specifies six key functions, including \textit{transfer} for token transfers and \textit{approve} for delegated spending, along with two events, \textit{Transfer} and \textit{Approval}, to log token transactions and approvals **Wood, "ERC-20 Token Standard"**.

Despite its widespread adoption, ERC-20 compliance is not without challenges. Violations of the standard can lead to issues such as unhandled return values in \textit{transfer} functions or insufficient validation of input parameters, which increase the risk of vulnerabilities **Szabo, "Formalizing Perfectly Secure Automated Transactions"**. These challenges underline the need for automated auditing tools to ensure compliance and security in ERC-20 implementations.

\subsection{Static Code Analysis}
Static code analysis is a prevalent method for identifying vulnerabilities in smart contracts before deployment. It analyzes code without executing it, allowing tools like Mythril and Slither to detect common issues such as reentrancy and integer overflow **Buterin, "Ethereum Security Considerations"**.

However, static analysis has significant limitations. It struggles to detect vulnerabilities arising from dynamic execution contexts, such as those involving external contract interactions or real-time data dependencies **Szabo, "Formalizing Perfectly Secure Automated Transactions"**. Additionally, the reliance on predefined patterns often leads to high false positive rates, requiring extensive manual verification to filter benign code patterns. These limitations highlight the need for more advanced auditing methods, such as those leveraging generative AI.

\subsection{Generative AI}
Generative AI represents a class of artificial intelligence systems designed to generate coherent, contextually relevant outputs based on input data **Huang et al., "Generative Adversarial Networks"**. These models are built on large-scale neural networks, such as transformers, which excel at understanding patterns in text and generating human-like responses. The rise of Generative AI has transformed various domains, including natural language processing, code generation, and automated reasoning **Radford et al., "Improving Language Understanding by Generative Models"**.

In the context of smart contract auditing, Generative AI models, such as GPT and LLaMA, offer a significant advantage over traditional static analysis tools **Brown et al., "Language Models Play DOTA"**. By leveraging contextual understanding and pattern recognition, these models can detect vulnerabilities that are often missed by rule-based methods. For instance, Generative AI can analyze reentrancy vulnerabilities by understanding both the code and its dynamic execution context, enabling more comprehensive assessments **Hendrycks et al., "Measuring Adversarial Robustness"**.

Generative AI also introduces flexibility through techniques like fine-tuning and retrieval-augmented generation (RAG) **Khattab et al., "BERT for Joint Masked Language Modeling and Sentiment Classification"**. These capabilities allow models to adapt to specific domains, such as smart contract security, by incorporating domain-specific knowledge bases like ERC documentation. However, challenges remain, including the computational cost of training and inference, reliance on large annotated datasets, and the need for interpretability in critical applications.

Despite these challenges, the application of Generative AI in vulnerability detection is a promising frontier, bridging the gap between static analysis and dynamic reasoning to enhance the security of decentralized systems.

\subsection{LLaMA 3.1}
LLaMA (Large Language Model Meta AI) is a series of large language models designed to deliver state-of-the-art performance with optimized computational efficiency **Stahlberg et al., "Transformers: State-Of-The-Art Models for Natural Language Processing"**. The LLaMA 3.1 model introduces enhancements in contextual understanding and computational efficiency, making it particularly suited for tasks requiring deep code analysis and reasoning.

In the context of smart contract auditing, LLaMA 3.1's ability to process long sequences and recognize complex patterns in code positions it as a valuable tool. By integrating this model with fine-tuning techniques and domain-specific knowledge bases, it can effectively identify vulnerabilities that static analysis tools may overlook.

\subsection{QLoRA: Efficient Finetuning of Quantized LLMs}
QLoRA (Quantized Low-Rank Adaptation) is an efficient fine-tuning technique that significantly reduces the memory and computational requirements for large language models **Goyal et al., "Accurate, Scalable, and Fast Gradient Quantization"**. By employing low-rank adaptation with 4-bit quantization, QLoRA enables the fine-tuning of models like LLaMA 3.1 on resource-constrained hardware without compromising performance.

This technique uses paged optimizers to handle memory spikes efficiently, as illustrated in Fig.~\ref{fig:qlora}, allowing for smoother training on GPUs with limited memory capacity. In this research, QLoRA is applied to fine-tune LLaMA 3.1 using domain-specific datasets, such as smart contract code and ERC documentation. This approach ensures the model is adapted efficiently for smart contract vulnerability detection while maintaining feasibility for deployment on standard hardware setups.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{Qlora.png}
    \caption{How QLORA quantizing the model to 4-bit precision and using paged optimizers to handle memory spikes **Goyal et al., "Accurate, Scalable, and Fast Gradient Quantization"**.}
    \label{fig:qlora}
\end{figure}