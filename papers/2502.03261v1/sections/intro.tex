\section{Introduction}
\label{sec:intro}

% Consider a prediction task: Let $(X, Y)$ be a random pair that takes a value in the space $\cZ \triangleq \cX \times \cY$ with a joint distribution $P$. We consider $X \in \cX \subset \reals^d $ as covariates and $Y \in \cY$ as the response, and given $X$ we want to predict $Y$ as a function of $X$.  Although the standard approach would be to learn a prediction model $f: \cX \to \cY$ from $\cD$ using statistical learning methods, learning such $f$ is often very challenging due to the requirement of a large sample size and computing resources. 


Consider a standard prediction task: for an $(X, Y) \in \cX \times \cY$ drawn from the distribution $P$ we want to predict $Y$ using $X$, where $\cX \subset \reals^d$ is the covariates space and $\cY$ is the response space. For the prediction task, we want to learn a predictor $f : \cX \to \cY$ such that, given a new $(X, Y) \sim P$, the error in predicting $Y$ as $f(X)$ is as small as possible. To learn such $f$, we have a dataset $\cD_n = \{(X_i, Y_i)\}_{i = 1}^n \subset \cX \times \cY$ of size $n$ drawn \emph{i.i.d.} from the distribution $P$, and a standard statistical technique is to estimate $f$ by minimizing an empirical risk calculated with $\cD_n$. 
In this paper, we are particularly interested in prediction tasks in which learning $f$ in such a manner is very challenging or even impossible due to the requirements of a large sample size and computing resources. Instead, we have access to a collection of pre-trained models $f_1, \dots, f_M: \cX \to \cY$ that may aid our prediction task, and for a new $X$ we want to pick the ``best capable'' model for prediction.  


As a motivating example, consider the task of building a question and answering (Q\&A) system, \ie\ we want to learn a large language model (LLM) for text generation, which, given a question, generates the correct answer. As is well known by now, training such models from scratch is notoriously difficult in terms of their required data and computation resources, and is certainly outside of the capacity of an everyday researcher. As a more feasible approach, we turn to the Internet, where a collections of pre-trained LLMs are readily available for our use. Rather than training an LLM from scratch, we pick the ``best capable'' model to answer a question.


% But LLMs come in a wide variety of LLMs exist; in terms of their \emph{sizes}, which can range in size from one billion to hundreds of billions of parameters; \emph{expertise}, based on the dataset on which it has been trained, \eg text, math or science Q\&A, as well as \emph{costs} to obtain a prediction.
% Broadly speaking, larger models tend to be more capable but
% come at a higher cost, while smaller models tend to be less capable but cheaper to serve.
% Thus, a learner is presented with the problem of choice: given a new question, which LLM is best suited? 


There is a wide variety of LLMs available in the Internet --- their \emph{sizes} range from less than a billion to hundreds of billion of parameters; they may have a diverse \emph{expertise} based on their training datasets, \eg\ reasoning, math or coding Q\&A's; as well as their \emph{costs} of prediction might also be different. Broadly speaking, larger models (\eg\ GPT4) tend to be more capable but
come at a higher cost, while smaller models tend to be less capable but are cheaper to serve. 
In terms of model capability, we focus on the two following metrics: 
\begin{itemize}
    \item {\bf Prediction error:} we have a prediction loss function $\ell$ such that the error in predicting a response $Y$  as $f_m(X)$ from the $m$-th model is $\ell\{Y, f_m(X)\} \in \reals$. We want to pick the model with the smallest prediction error. 
    \item {\bf Prediction cost:} together with a pre-trained model $f_m$, we also have a cost function $\kappa_m: \cX \to \reals$ that, given an input $X$, quantifies the cost of obtaining the prediction $f_m(X)$ as $\kappa_m(X)$. Usually, the prediction cost for an LLM is related to factors such as the sizes of models, input tokens, etc. 
\end{itemize}
Intuitively, we would like to use a more expensive model like GPT4 for a question that is difficult to answer. On the other hand, a smaller model with less prediction cost might be sufficient for a question that is easy to answer. Thus, we want to find the LLM that can correctly answer a question at the cheapest prediction cost. 

% Thus, we have a problem of choice: \emph{given a new question, which LLM is best suited to answer it?} 



The task of picking the best prediction model is called \emph{routing} and has attracted a growing interest in the LLM community \citep{lu2023routing,wang2023fusing}, due to it's capability of harnessing the complementary expertise of a heterogeneous class of LLMs to achieve better performance at a reduced prediction cost. 
% To formally introduce the problem, assume that we have access to $M$ pre-trained models $f_1, \dots, f_M: \cX \to \cY$ and given a new $X\in \cX$ we need to pick the ``best capable'' one to predict $Y$. 
In this paper, we consider routing with two metrics, namely prediction error and cost, but our framework can also be extended to more than two metrics (\cf\ Section \ref{sec:general-multi-obj}). As hinted before, the two metrics are often at odds with each other: a larger model will have a smaller prediction error, but at a higher cost, whereas a smaller model will have a lower prediction cost but a higher prediction error. This is a well-known issue in most multi-objective learning problems and in such scenarios it is often standard to consider a ``trade-off'' between the prediction error and the cost via a simple weighted linearization: for $\lambda \in [0,1 ]$ we define the trade-off loss as 
\begin{equation} \label{eq:linearized-loss}
  \eta_{\lambda, m}(X, Y) =  \lambda \ell\{Y, f_m(X)\} + (1 - \lambda) \kappa_m(X)  \,.
\end{equation}
For such a particular trade-off our routing problem is formalized as the following: learn a function $g: \cX\to \{1, \dots, M\}$ 
that predicts the index of the model to be used for predicting the final outcome, \ie\ given an $(X, Y)$ we predict $Y$ as $f_{g(X)}(X)$. We refer to such a $g$ as \emph{router}. We want to learn the best possible router, also referred to as oracle router and Pareto router, that  
minimized the average trade-off loss: 
\begin{equation} \label{eq:risk-trade-off}
  \textstyle g_\lambda^\star =   \argmin_g \big \{ \cL_P(g, \lambda) =  \Ex_P \big[\sum_{m = 1}^M \bbI \{ g(X) = m\} \eta_{\lambda, m}(X, Y) \big]\big \} \,.
\end{equation} Here, the $\lambda$ in the subscript of  $g_\lambda^\star$ emphasises the dependence of oracle router on the trade-off parameter $\lambda$, as for different $\lambda$'s the  $g_\lambda^\star$'s might be different. 

By this point, the readers may have realized that this is inherently a classification problem; routers are essentially classifiers, whose outcomes are indices of LLMs. Often, this is more tractable than learning a predictor $f:\cX \to \cY$ from scratch or through fine-tuning, especially when $P$ includes a diverse set of prediction tasks. 
Both of our benchmark datasets contain the
MMLU \citep{hendrycks2020measuring},
which is a multiple choice question-answer benchmark with 57 different tasks organized by topics. The Open LLM Leaderboard \citep{open-llm-leaderboard-v2} combines MMLU with five other question-answer datasets. While one may find it challenging to train an LLM that is strictly the best on all of these benchmarks, a more feasible approach is to \emph{route through} pre-trained models that are expert in those particular tasks.


Since routing is essentially a classification problem, we can use standard statistical learning techniques to learn the oracle routers; given a $\lambda$ we estimate $g_\lambda^\star$ using an empirical risk minimization (ERM): 
\begin{equation} \label{eq:ERM}
  \textstyle  \widehat g_\lambda = \argmin_g \frac1n \sum_{i = 1}^n \sum_{m = 1}^M \ell_{\text{class}}(g(X_i), m) \eta_{\lambda, m}(X_i, Y_i)\,. 
\end{equation} where $\ell_{\text{class}}$ is a suitable loss for multiclass classification. Moreover, we can evaluate the predictive error and cost for  $\widehat g_\lambda$ on a different test data split $\cD_\text{test} = \{(X_i' ,Y_i')\}_{i = 1}^{n_{\text{test}}} \sim  \textrm{iid} ~  P $: 
\begin{equation} \label{eq:perf-cost}
   \textstyle  \widehat \cE_\lambda  =  \frac1{n_\text{test}} \sum_{i = 1}^{n_\text{test}}  \ell\{Y_i', f_{\widehat g_\lambda(X_i')}(X_i')\}, ~~ \widehat \cC _\lambda =  \frac1{n_\text{test}} \sum_{i = 1}^{n_\text{test}}  \kappa_{\widehat g_\lambda(X_i')}(X_i')\,. 
\end{equation}



% In our formulation of model routing, we only need to learn a classifier with outcome space $[M]$ that selects the best-suited model for prediction. In other words, we have reduced the outcome space from an arbitrary $\cY$ to a mere $[M]$. 


% such that given a new $(X, Y)$ the model model indexed by $g(X)$ is best suited to predict the outcome $Y$, \ie\ 




% Now, we want to learn a function $g: \cX \to \{1, \dots , M\}$ which, for a new $X$, predicts that the model indexed by $g(X)$ is best suited to predict the outcome. We refer to this $g$ as \emph{router}. For a pair $(X, Y)$ a router $g$  incurs a trade-off loss $\sum_{m = 1}^M \bbI \{ g(X) = m\} \eta_{\lambda, m}(X, Y)$, and naturally, we want to the best router that minimizes the average of trade-off loss: 
% \begin{equation} \label{eq:risk-trade-off}
%   \textstyle  \min_g \big \{ \cL_P(g, \lambda) =  \Ex_P \big[\sum_{m = 1}^M \bbI \{ g(X) = m\} \eta_{\lambda, m}(X, Y) \big]\big \} \,.
% \end{equation}
% At this point, the reader may have realized that this is a classification problem with $M$ classes. Often, this is more tractable than learning a predictor $f:\cX \to \cY$ from scratch, especially when $\cY$ is very complicated. For our LLM example, $\cY$ is the space of all possible answers, and training a $f:\cX \to \cY$ is very difficult. In our formulation of model routing, we only need to learn a classifier with outcome space $[M]$ that selects the best-suited model for prediction. In another word, we have reduced the outcome space from  an arbitrary $\cY$ to a mere $[M]$. 




% \begin{itemize}
%     \item {\bf Prediction error:} we have a prediction loss function $\ell$ such that the loss for predicting a response $Y$ using the $m$-th model is $\ell\{Y, f_m(X)\} \in \reals$. We want to pick the model with the smallest loss. 
%     \item {\bf Prediction cost:} together with a pre-trained model $f_m$, we also have a cost function $\kappa_m: \cX \to \reals$ that, given an input $X$, quantifies the cost of obtaining the prediction $f_m(X)$ as $\kappa_m(X)$. Usually, this prediction cost is related to factors such as the sizes of models, input tokens, etc. Although a large model (\eg\ GPT4) can accurately answer most questions, they are also more expensive to use. For a question that is easy to answer, we might turn to a smaller model, which can provide a good answer at a much lower cost. 
% \end{itemize}

% Now we are presented with a problem with multiple objectives: prediction error vs. cost. Moreover, they are often at odds with each other: a larger model will have a smaller prediction error, but at a higher cost, whereas a smaller model will have a lower prediction cost but a higher prediction error.  In such scenarios one often considers a ``trade-off'' loss between the prediction error and the cost via a simple weighted linearization: for $\lambda \in [0,1 ]$
% \begin{equation} \label{eq:linearized-loss}
%   \eta_{\lambda, m}(X, Y) =  \lambda \ell\{Y, f_m(X)\} + (1 - \lambda) \kappa_m(X)  \,.
% \end{equation}
% Now, we want to learn a function $g: \cX \to \{1, \dots , M\}$ which, for a new $X$, predicts that the model indexed by $g(X)$ is best suited to predict the outcome. We refer to this $g$ as \emph{router}. For a pair $(X, Y)$ a router $g$  incurs a trade-off loss $\sum_{m = 1}^M \bbI \{ g(X) = m\} \eta_{\lambda, m}(X, Y)$, and naturally, we want to the best router that minimizes the average of trade-off loss: 
% \begin{equation} \label{eq:risk-trade-off}
%   \textstyle  \min_g \big \{ \cL_P(g, \lambda) =  \Ex_P \big[\sum_{m = 1}^M \bbI \{ g(X) = m\} \eta_{\lambda, m}(X, Y) \big]\big \} \,.
% \end{equation}
% At this point, the reader may have realized that this is a classification problem with $M$ classes. Often, this is more tractable than learning a predictor $f:\cX \to \cY$ from scratch, especially when $\cY$ is very complicated. For our LLM example, $\cY$ is the space of all possible answers, and training a $f:\cX \to \cY$ is very difficult. In our formulation of model routing, we only need to learn a classifier with outcome space $[M]$ that selects the best-suited model for prediction. In another word, we have reduced the outcome space from  an arbitrary $\cY$ to a mere $[M]$. 
% In general, this routing approach is particularly suited for very complicated $\cY$, as in those cases learning a direct predictive model $f:\cX \to \cY$ usually requires a large dataset and computation resource.  



% Returning to our routing task,  we show in Lemma \ref{lemma:oracle-router}, for $\eta_{\lambda, m} ^\star(X) = \Ex_P [\eta_{\lambda, m}(X, Y) \mid X]$, the best router that minimizes the trade-off risk \eqref{eq:risk-trade-off} is $g_\lambda^\star(X) = \argmin_l ~ \eta_{\lambda, m} ^\star(X)$. We also refer to $g_\lambda^\star$ as a Pareto router. We can use standard statistical learning techniques to learn this Pareto routers; given a $\lambda$ we estimate $g_\lambda^\star$ using an empirical risk minimization (ERM): 
% \begin{equation}
%   \textstyle  \widehat g_\lambda = \argmin_g \frac1n \sum_{i = 1}^n \sum_{m = 1}^M \ell_{\text{class}}(g(X_i), m) \eta_{\lambda, m}(X_i, Y_i)\,. 
% \end{equation} where $\ell_{\text{class}}$ is a suitable loss for multiclass classification. Moreover, we can evaluate the predictive error and cost for  $\widehat g_\lambda$ on a different test data split $\cD_\text{test} = \{(X_i' ,Y_i')\}_{i = 1}^{n_{\text{test}}} \sim  \textrm{iid} ~  P $: 
% \begin{equation}
%    \textstyle  \widehat \cE_\lambda  =  \frac1{n_\text{test}} \sum_{i = 1}^{n_\text{test}}  \ell\{Y_i', f_{\widehat g_\lambda(X_i')}(X_i')\}, ~~ \widehat \cC _\lambda =  \frac1{n_\text{test}} \sum_{i = 1}^{n_\text{test}}  \kappa_{\widehat g_\lambda(X_i')}(X_i')\,. 
% \end{equation}



% \todo{revise from here.}
\noindent What is a suitable trade-off, \ie\ what is a good choice of $\lambda$? Instead of making this decision on our own, we want users to decide on this based on their preferred trade-off between performance and cost. To aid in this decision, we want to provide them with an estimate of the Pareto frontier curve to exhibit the trade-off in the prediction error and cost
\begin{equation}
    \textstyle \widehat \cF = \{(\widehat \cE _\lambda, \widehat \cC_\lambda ): \lambda \in [0, 1]\}\,, 
\end{equation} along with the class of all estimates of the oracle routers $\{\widehat g_\lambda: \lambda \in [0, 1]\}$. A naive approach could be to report both $\widehat g_\lambda$ and $(\widehat \cE _\lambda, \widehat \cC_\lambda )$ on a sufficiently fine grid of $\lambda$, where for each $\lambda$ on the grid, they are estimated using eq. \eqref{eq:ERM} and \eqref{eq:perf-cost}. But this defeats one the main purpose of the routing problem, reducing the computational requirement, as we now need to learn $\widehat g_\lambda$ on this suitable grid of $\lambda$. 


% Suppose that we want users to pick this $\lambda$ according to their preferred trade-off between performance and cost. For this, we want to provide them with an estimate of the Pareto frontier curve for the error and cost trade-off $\widehat \cF = \{(\widehat \cE _\lambda, \widehat \cC_\lambda ): \lambda \in [0, 1]\}$ so that they can make informed decisions about $\lambda$. Notice that, to calculate $(\widehat \cE _\lambda, \widehat \cC_\lambda )$ we require $\widehat g_\lambda$. So, a naive approach could be to learn $\widehat g_\lambda$ and $(\widehat \cE _\lambda, \widehat \cC_\lambda )$ on a sufficiently fine grid of $\lambda$'s and then interpolate for $(\widehat \cE _\lambda, \widehat \cC_\lambda )$ on the remaining $\lambda$'s to estimate the full curve. But this defeats the main purpose of the routing problem, reducing the computational requirement, as we now need to learn $\widehat g_\lambda$ on this suitable grid of $\lambda$. 


\emph{\bf Is there a more efficient way?} In this paper, we devise a computationally efficient approach to learn $\widehat g_\lambda$ for all $\lambda \in [0, 1]$ and use them to calculate $\widehat \cF$. The key intuition of our approach lies in the mathematical form of the oracle routers:  we establish in Lemma \ref{lemma:oracle-router} that  $g_\lambda^\star(X) = \argmin_m \eta_{\lambda, m} ^\star(X)$  where the loss regression functions $\eta_{\lambda, m} ^\star(X) = \Ex _P[\eta_{\lambda, m}(X, Y)\mid X]$ can be decomposed as  
\begin{equation}\label{eq:reg-decomposition}
    \eta_{\lambda, m} ^\star(X) = \Ex _P[\eta_{\lambda, m}(X, Y)\mid X] = \lambda \Ex_P[\ell\{Y , f_m(X)\}\mid X] + (1 - \lambda) \kappa_m(X)\,. 
\end{equation} 
The decomposition follows directly from Eq. \eqref{eq:linearized-loss}. Within this decomposition, the $\kappa_m$ is known to us, and thus only the $\Ex_P[\ell\{Y , f_m(X)\}\mid X]$ remains unknown. Note that, $\Ex_P[\ell\{Y , f_m(X)\}\mid X]$ is a regression function to predict $\ell\{Y , f_m(X)\}$ using $X$, and therefore can be learned by training a regression model on the training samples, where $\ell\{Y_i, f_m(X_i)\}$'s are treated as responses instead of $Y_i$'s. Let us denote this estimator by $\widehat \Phi_m(X)$. Now, we can replace $\Ex_P[\ell\{Y , f_m(X)\}\mid X]$ by $\widehat \Phi_m(X)$ within the decomposition in eq. \eqref{eq:reg-decomposition} to obtain a plug-in estimator for $\eta_{\lambda, m} ^\star(X)$, denoted as $\widehat \eta_{\lambda, m}(X)$. Then, our estimated router is simply $\widehat g_\lambda (X) = \argmin_{m} \widehat \eta_{\lambda, m}(X)$. In our whole procedure, we only need to estimate $M$ different regression functions $\Ex_P[\ell\{Y , f_m(X)\}\mid X]$, which is \emph{computationally more efficient} than to learn a router for each value of $\lambda$ on a suitable grid. 


While the procedure is computationally efficient, \emph{does it also lead to statistically efficient estimates of the oracle routers?} To answer this question, we perform a minimax investigation on the excess risk (defined in eq. \eqref{eq:excess-risk}), and show that for a suitable choice of $\widehat \Phi_m$ (\cf\ Remark \ref{cor:efficient-routers}) our plug-in routers achieve the minimax optimal rate of convergence. Broadly speaking, the steps in our minimax investigation are as follows: 
\begin{itemize}
    \item In Theorem \ref{thm:lower-bound} we consider a setting similar to non-parametric classification problems considered in \citet{audibert2007Fast} and establish a lower bound on the minimax rate of convergence for the excess risk.
    \item  In Theorem \ref{thm:upper-bound} we establish a matching upper-bound rate of convergence of excess risk when $\widehat \Phi_m(X)$ has a ``suitable'' rate of convergence (\cf\ Corollary \ref{cor:efficient-routers}). 
    \item In Section \ref{sec:reg-fn-estimate} we propose an estimate $\widehat \Phi_m(X)$ that achieves our desired rate of convergence. 
\end{itemize}
Finally, we utilize our approach on two benchmark datasets, namely \texttt{RouterBench}\footnote{https://huggingface.co/datasets/withmartian/routerbench}\citep{hu2024routerbench} and \openllm\
\footnote{https://huggingface.co/spaces/open-llm-leaderboard/open\_llm\_leaderboard} \citep{open-llm-leaderboard-v2}
to estimate the oracle routers and the Pareto frontier of error and cost trade-off. 
% Both of the benchmark datasets contain a diverse set of tasks, such as reasoning, math, coding, etc, which necessitates the routing rather than fine-tuning.  
As a sneak peek at our findings, in \routerbench\ through routing, we can achieve performance similar to GPT4 at half the cost, whereas $95\%$ of performance at less than $20\%$ of the cost. 


On a more technical side, our routing task, at its heart, is a multi-objective classification problem. Within this context, our contributions are the following: 
\begin{itemize}
    \item In the context of our routing application, we were required to extend previous minimax studies in nonparametric classification \citep{audibert2007Fast} on two fronts: (1) with more than two classes, and (2)  with general losses beyond $0/1$-loss. Both of these extensions require us introduce a generalized definition of margin (\cf\ eq. \eqref{eq:margin}), which reduces to the usual margin definition as in \citet{audibert2007Fast} when the classification task is binary and the loss is $0/1$. 
    \item  We establish minimax rates for multi-objective classification problems: in Section \ref{sec:lower-bound} we work with two objectives, namely performance and cost, which is relevant to our routing application, and in Section \ref{sec:general-multi-obj} we further extend the setting to a general instance of multiple objectives. In both cases, we establish that simple plug-in routers are minimax rate optimal for the entire collection of oracle routers. To the best of our knowledge, our paper is the first to analyze minimax optimality on the entire collection of oracle classifiers in classification problems with multiple objectives. 
    \item  For a multi-objective classification problem, we provide a computationally and statistically efficient approach to estimate all the oracle classifiers.  
\end{itemize}



% \SM{(1) talk about the extension to multi class classification, (2) introduction of a new notion of margin and explain how it relates to margin in binary case, (3) }

% We quantify the capability of a model in two front:


% % This problem is called the \emph{routing} problem. \SM{introduce some the routing and related linerature here.}
% % To formally introduce the routing problem, assume that we have access to $M$ pre-trained prediction models $f_1, \dots, f_M: \cX \to \cY$ and given a new $X\in \cX$ we need to pick the ``best capable'' one for our prediction task. We quantify the capability of a model in two front:




% \begin{itemize}
%     \item {\bf Accuracy:} for the response $Y$ and it's prediction $f_m(X)$ we consider a prediction loss function: $\ell\{Y, f_m(X)\} \in \reals$.        
%     \item {\bf Cost:} along with a pre-trained model $f_m$, we also receive a $\kappa_m: \cX \to \reals$ that, given an input $X$, quantifies the cost of obtaining the prediction $f_m(X)$ as $\kappa_m(X)$. \SM{say something a bit more about both loss and the cost.}
% \end{itemize} 



% Now, we're presented with a muli-objective problem, and for a given $\lambda > 0$ it is often standard to choose a combination  $\eta_{\lambda, m}(X, Y) \triangleq  \lambda \ell\{Y, f_m(X)\} + (1 - \lambda) \kappa_m(X)$. To this end, we want to learn a router $g: \cX \to \{1, \dots, L\}$ that minimizes our average cost-adjusted loss:
% \begin{equation}
%   \textstyle  \cL_P(g, \lambda) =  \Ex_P \big[\sum_{m = 1}^M \bbI \{ g(X) = l\} \eta_{\lambda, m}(X, Y) \big]\,.
% \end{equation}
% We provide the oracle router in the following  lemma: 







% \paragraph{The problem: learning the Pareto routers.} Of course, the oracle router depends on $\lambda > 0$, and given a $\lambda$ we can estimate the oracle router model as $\widehat g_\lambda$ using standard statistical learning techniques. But, say, we want to provide users with a class $\widehat \cG = \{\widehat g_\lambda: 0\le  \lambda \le 1\}$ that efficiently estimates the class $\cG^\star = \{g_\lambda^\star: 0\le \lambda\le 1 \}$ of oracle routers, which we call ``Pareto routers''. Together with them, we want to provide estimates of expected performance and cost in $P$, \ie\ an estimate of the Parato metric curve
% \begin{equation}
%     \cM^\star = \big\{ \big(\cL_P(g_\lambda^\star, 1), \cL_P(g_\lambda^\star, 0)\big): 0\le \lambda \le 1 \big\}
% \end{equation}
% so that the said users can make their own informed choice of $\lambda$ by looking at the performance vs. cost ``trade-off''. 

% \paragraph{Efficient learning of the Pareto routers.}
% How do we learn this $\widehat \cG$? Do we train separate routers for separate values of $\lambda$, which might be resource intensive? Through our minimax analysis, we show that $\cG^\star$ can be learned efficiently using a simple two-step procedure:


% \begin{algorithm}
%     \begin{algorithmic}[1]
% \Require data $\cD$
% \State Learn an ``efficient'' predictor $\widehat \Phi: \cX \to \reals^L$ for $\Phi^\star: \cX \to \reals^L$ where the $l$-th co-ordinate of $\Phi^\star(X)$ is $\Phi^\star_l(X) = \Ex_P[\ell\{Y, f_m(X)\}\mid X ]$. The term ``efficient'' is made more precise later in Section \ref{sec:upper-bound}. 
% \State For $0 \le \lambda \le 1$ estimate $\widehat g_\lambda$ as \begin{equation}\label{eq:eff-estimate-router}
%         \widehat g_\lambda(X) = \argmin_l \{\lambda \widehat \Phi(X) + (1 - \lambda) \kappa_m(X)\}\,. 
%     \end{equation}
% \end{algorithmic}
% \caption{Learning of Pareto routers}
% \label{alg:pareto-routers}
% \end{algorithm}


% This two-step procedure greatly reduces our computation burden for the learning of $\cG^\star$ since we no longer need to train $\widehat g_\lambda$ for individual $\lambda$'s, which can be computationally intensive. Instead, we only need to learn $\Phi^\star$ once and easily obtain the class $\widehat\cG$ from \eqref{eq:eff-estimate-router}. 

% \paragraph{Minimax investigation of Pareto routers.} To argue that our two-step procedure in Algorithm \ref{alg:pareto-routers} is minimax rate optimal,  we establish the following: For any $0\le \lambda\le 1$
% \begin{itemize}
%     \item Within a standard setting that is often considered in investigating minimax rates for non-parametric classification problems \citep{audibert2007Fast}, we establish a lower bound for the minimax rate of convergence for the excess risk of a router (\cf\ Theorem \ref{th:lower-bound} ). 
%     \item In Section \ref{sec:upper-bound} we show that as long as $\widehat \Phi$ satisfies the concentration bound in \eqref{} the excess risk of the $\widehat g_\lambda$ defined in \eqref{eq:eff-estimate-router} achieves the same minimax rate of convergence, which establishes that $\widehat g_\lambda$ is minimax rate-optimal.  
% \end{itemize}



% \paragraph{Application to the \texttt{RouterBench} dataset.} \texttt{RouterBench}\footnote{https://huggingface.co/datasets/withmartian/routerbench}\citep{hu2024routerbench} is a Q\&A dataset comprising of over $\sim 30000$ prompts and the responses from 11 different LLMs, along their associated costs and a performance scores. We use our proposed algorithm \ref{alg:pareto-routers} to learn the Pareto routers, where the performance score predictor $\widehat \Phi$ is trained on a training split of the dataset  and estimate the Parato metric curve on the remaining test split. \SM{Say somethings about the findings in a couple of lines. Keep it short.}


% \SM{Possible generalization to multiple metrics. This can go into conclusion section.}



\paragraph{Organization of the paper.} We end our introductory section with a short description of the organization of our paper. In Section \ref{sec:lower-bound} we establish information-theoretic lower bounds on the excess risk in estimating oracle routers and develop a computationally efficient algorithm to estimate them that achieves the same rates in their upper bound. In Section \ref{sec:routing-application} we use this algorithm for routing in two benchmark datasets. In Section \ref{sec:general-multi-obj} we extend the routing problem to general metrics and discuss an efficient estimation algorithm and establish minimax optimal rate of convergence for the oracle routers, which is in the similar vain in Section \ref{sec:lower-bound}. We end our paper with a discussion in Section \ref{sec:discussion}. 


\subsection{Related literature}


\paragraph{Performance vs cost trade-off in LLM predcitions.} Several recent studies have explored optimizing the cost and performance trade-offs in the implementation of
large-language models (LLMs). LLM-BLENDER \citep{jiang2023llm} ensembles outcomes from
multiple LLMs to select the best response. Frugal-ML, Frugal-GPT \citep{chen2020frugalml,chen2023frugalgpt} and FrugalFoE \cite{wang2023fusing} employ an LLM cascade to sequentially query LLMs until a reliable response is found. AutoMix \citep{madaan2023automix} relies on a smaller model to self-verify its response before potentially considering a larger model. While these approaches rely
on multiple LLM queries, our approach routes each query to a single LLM, an approach also considered in \citet{hu2024routerbench}. We complement these works by providing a statistically principled approach to learning this performance vs. cost trade-off. 

\paragraph{Ensemble learning.} The routing problem is closely related to ensemble learning that combines multiple models to obtain better performance. Classical ensemble methods include bagging (bootstrap aggregating), boosting, and
stacking (model blending) \citep{breiman1996bagging,breiman1996stacked,freund1996experiments,friedman2001greedy,wolpert1992stacked}. Most of these works implicitly assume that the models in the ensemble have \emph{similar expertise}, and
thus it is beneficial to aggregate their predictions, whereas in our case, models may have \emph{complementary expertise}, and averaging their outputs might be detrimental because most of them may not be suitable for an input. Therefore, we choose to predict using the model with the best outcome, rather than aggregating them. 

\paragraph{Minimax study in non-parametric classification.} One of the earliest work on the minimax rate of convergence in non-parametric classification settings is by \citet{audibert2007Fast}. These techniques were later adopted for investigating the ability of transfer learning under a distribution shift; some prominent examples being \citep{kpotufe2018Marginal,cai2019Transfer,maity2020Minimax}. All of these works consider binary classification with $0/1$ loss. In comparison, our minimax investigation differs in two fronts: we extend the settings to classification with more than two classes and general cost functions. 
% To quantify the difficulty of classification in our extended framework through a margin condition, as done in \citet{audibert2007Fast} for binary classification with $0/1$ loss, we needed to extend the notion of margin appropriately (\cf\ eq. 
 \eqref{eq:margin}). 

\paragraph{Multiobjective learning}