\section{Plug-in approach to routing}
\label{sec:setup}

%To describe the approach, let us introduce some notation. We have $M$ pre-trained LLMs indexed as $m \in [M] = \{1, \dots, M\}$ and $K$ metrics indexed as $k\in [K] = \{1, \dots, K\}$. %Throughout our paper, we index the models as $m \in [M]$ and the metrics as $k \in [K]$. 
%We denote a generic input or query as $X\in \cX$, where $\cX$ is the space of inputs.  Thus, for any input $X$, the metrics of interest are stored in a $M\times K$ matrix. We denote this matrix as $Y \in \reals^{M \times K}$, whose $(m, k)$-th entry $[Y]_{m, k}$ is the metric value for obtaining a prediction from the $m$-th model evaluated with respect to $k$-th metric.  For all metrics, we assume that a lower value is preferred. With this convention, we shall also refer to them as risks. For a probability distribution $P$ in the sample space $\cX \times \reals^{M\times K}$ we assume that the training dataset $\cD= \{(X_i, Y_i)\}_{i = 1}^n$ is an $\iid$ sample from $P$. 


We will consider a convex combination of our $K$ metrics with coefficients $\mu \in \Delta^{K-1} \triangleq \{(\mu_1, \dots, \mu_K): \mu_k \ge 0, \sum_k \mu_k = 1\}$ and a generic point $(X, Y)\sim P$. The $\mu$-th convex combination of the risks (or, $\mu$-th risk) can be written as $Y\mu\in \reals^{M}$, with the risk incurred for obtaining a prediction from the $m$-th model is 
\[
\textstyle [Y\mu]_m = \sum_{k = 1}^K [Y]_{m, k} \mu_k\,.
\] We want to learn a predictive router $g: \cX \to [M]$, that takes $X$ as an input and predicts the index of the LLM to be used for inference. The average $\mu$-th risk for using the router $g$ is 
\begin{equation}\label{eq:RM}
  \textstyle   \cR_P(g, \mu) = \Ex\big [\sum_{m = 1}^M[Y\mu]_m \bbI\{g(X) = m\} \big]\,. 
\end{equation} For a given $\mu$ let us refer to the minimizer $g_\mu^\star$ as an oracle router. Remember our objective: we would like to learn the oracle routers $g_\mu^\star$ at every value of $\mu$. While one may minimize an empirical risk corresponding to $\cR_P(g, \mu)$ to estimate the oracle router at a particular $\mu$, this approach is not scalable, any small change in $\mu$ would require refitting a new router. Given this, we develop a plug-in approach which lets us estimate the oracle routers at every value of $\mu$. The key intuition lies within an explicit form of the $g_\mu^\star$ that we provide in the next lemma. 
\begin{lemma} \label{lemma:oracle-router}
    Let us define $\Phi(x) = \Ex [Y\mid X = x]$ and $\eta_{\mu, m}(x) = \sum_{k = 1}^K \mu_k [\Phi (x)]_{m, k} $. Then for any $\mu\in \Delta^{K-1}$ the oracle router that minimizes $\cR_P(g, \mu)$ is 
    \begin{align} \label{eq:oracle-router-2}
        \textstyle g_\mu^\star(X) & \textstyle = \argmin_m ~ \eta_{\mu, m} (X)\\ 
       & \textstyle  = \argmin_m \big\{ \sum_{k = 1}^K \mu_k [\Phi (X)]_{m, k} \big\} \, \nonumber.
    \end{align}
\end{lemma}
The key conclusion of \ref{lemma:oracle-router} is the expression $ g_\mu^\star(X)= \argmin_m \{ \sum_{k = 1}^K \mu_k [\Phi (X)]_{m, k} \} $. %where we have isolated the effects of $\mu$. 
It suggests a straightforward approach to estimate $g_\mu^\star(X)$ at all values of $\mu$.  Namely, we only need to plug-in an estimate of $\Phi(X) = \Ex[Y \mid X]$ to the expression of $g_\mu^\star(X)$. Compared to minimizing empirical risk at different values of $\mu$, this plug-in approach is more scalable if the practitioner plans on tuning $\mu$. %In addition to estimating the routers, we also estimate the average risks 
%\[
%\textstyle \cR(\mu, k) = \Ex \big[\sum_{m = 1}^M[Y]_{m, k} \bbI\{g_\mu^\star(X) = m\}\big]
%\]
%on a test split of the dataset, which would be useful for understanding the trade-off across different risks.
We summarize our approach in algorithm \ref{alg:pareto-routers}. 
\begin{algorithm}
    \begin{algorithmic}[1]
\REQUIRE Dataset $\cD_n$
\STATE Randomly split the dataset into training and test splits: $\cD_n = \cD_{\text{tr}} \cup \cD_{\text{test}}$. 
\STATE  Learn an estimate $\hat \Phi (X)$ of $\Phi(X)$ using the $\cD_{\text{tr}}$. 
\FOR{$\mu \in \Delta^{K-1}$}
\STATE  Define $\widehat g_\mu(X) = \argmin_m \widehat \eta_{\mu, m}(X)$ where $\widehat \eta_{\mu, m}(X) =  \sum_{k = 1}^K \mu_k [\widehat \Phi (X)]_{m, k}   $. Break any tie within $\argmin$ randomly.
 \STATE Calculate 
 
 $\widehat \cR(\mu, k)  =  \frac1{|\cD_{\text{test}}|} \sum\limits_{(X, R) \in \cD_{\text{test}}}  [R]_{m, k} \bbI\{ \widehat g_\mu(X) = m\} $
\ENDFOR

\STATE {\bfseries Return:} $\{\widehat g_\mu: \mu \in \Delta^{K-1}\}$ and $ \{\widehat \cR(\mu, k): \mu \in \Delta^{K-1}, k\in [K]\}$. 
\end{algorithmic}
\caption{CARROT}
\label{alg:pareto-routers}
\end{algorithm}

%\begin{algorithm}[H]
  % \caption{ICL Refinement}\label{alg:label improvement}
%\begin{algorithmic}
  % \STATE {\bfseries Input:} Corrupted label pairs $\tilde{D}: \{(X_i, \tilde{Y}_i)\}_{i=1}^n$, source LLM $\cS$.
   %\REPEAT
   %\STATE Initialize $noChange = true$.
 %  \FOR{$i =1, 2, \dots, n$}
   %\IF{$x_i > x_{i+1}$}
  % \STATE Select in-context-learning examples  $\tilde{D}_{\text{ICL}}^i: \{(X_j, \tilde{Y}_j)\}_{j=1}^{n_{\text{ICL}}}$ from $\tilde{D}\backslash\{(X_i, \tilde{Y}_i)\}$
 %  \STATE Construct concatenated prompt $[\tilde{D}^i_{\text{ICL}} \circ X_i]$, and draw re-sampled label $\hat{Y}_i \sim \cS(\cdot|[\tilde{D}_{\text{ICL}} \circ X_i] )$.
   %\ENDIF
  % \ENDFOR
  % \STATE {\bfseries Return:} $\hat{\cD} \triangleq \{X_i, \hat{Y}_i\}_{i=1}^n$
   %\UNTIL{$noChange$ is $true$}
%\end{algorithmic}
%\end{algorithm}

%\SM{talk a bit about interpretibility and computational efficiency}