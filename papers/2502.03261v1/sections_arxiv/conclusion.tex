\section{Discussion}
\label{sec:discussion}
% In this paper, we have introduced a series of routers  based on plug-in estimators that output predictions for model cost and accuracy given a query. These routers are computationally efficient in that one only needs to fit the plug-in estimators to smoothly traverse the Pareto frontier of LLM cost and accuracy on a given data set. To establish the statistical efficiency of our routers, we have provided an information-theoretic lower bound on the excess risk of any router in Theorem \ref{thm:lower-bound}. This lower bound is dependent on the smoothness of the underlying accuracy/cost functions (Assumption \ref{assmp:smooth}), the margin of the oracle router (Assumption \ref{assmp:margin}) and the convex combination coefficients $\mu$ used to measure the risk of the router. Through Theorem \ref{thm:upper-bound} we have seen that for an appropriate choice of plug-in estimate (e.g. Local Polynomial Regression) the minimax risk of our routers achieves the lower bound previously established. In practice, we introduced two systems of plug-in estimates for routing: the first uses roberta-base while the second uses a non-parametric regressor (KNN) on text embeddings. On both open-LLM-leaderboard-v2 and RouterBench, each of the routers can achieve performance equal to (or greater than) the best models at significantly reduced cost.

We introduced CARROT, a plug-in based router that is both computationally and statistically efficient. The computational efficiency stems from the requirement of merely calculating the plug-in estimators (see Algorithm \ref{alg:pareto-routers}) to  perform routing %smoothly traverse the Pareto frontier of cost and accuracy for given group LLMs and dataset. 
Since collecting adequate data for router training might be challenging, we investigate CARROT's statistical efficiency in routing through a minimax rate study. To establish the statistical efficiency of CARROT, we have provided an information-theoretic lower bound on the excess risk of any router in Theorem \ref{thm:lower-bound} and corresponding upper bound for CARROT in Theorem \ref{thm:upper-bound}. To ensure a broad scope for CARROT to a diverse set of queries \emph{and} the latest state-of-the-art LLMs, we also introduced the \newdata\ dataset. %Using \newdata\ and other benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance. %Overall, our work presents a robust strategy toward building a router with a broad scope across queries, LLMs, and performance metrics.

Our routing and data approach is designed to be forward-looking. CARROT can incorporate many metrics besides performance and cost; an important next step is to explore which other metrics can improve LLM-based decision-making in practice. A related future goal is to benchmark our SPROUT-trained router on enterprise use cases like the Domain Intelligence Benchmark Suite (DIBS)\footnote{\url{https://www.databricks.com/blog/benchmarking-domain-intelligence}} to locate areas of improvement needed in our data.

% Likewise, on release, SPROUT will be designed to include new user queries and new models. Another future goal is to benchmark the \newdata\ data set itself. For example, one could battle test routers trained on \newdata\ a Domain Intelligence Benchmark Suite (DIBS)\footnote{\url{https://www.databricks.com/blog/benchmarking-domain-intelligence}} to locate areas of improvement needed in our data.