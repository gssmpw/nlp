% There is a rapidly growing number of open-source Large Language Models (LLMs) and benchmark datasets to compare them. While some models dominate these benchmarks, no single model typically achieves the best accuracy in all tasks and use cases. In this work, we address the challenge of selecting the best LLM out of a collection of models for new tasks. We propose a new formulation for the problem, in which benchmark datasets are repurposed to learn a "router" model for this LLM selection, and we show that this problem can be reduced to a collection of binary classification tasks. We demonstrate the utility and limitations of learning model routers from various benchmark datasets, where we consistently improve performance upon using any single model for all tasks.

% With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in \emph{LLM routing}, or directing queries to the cheapest LLM that can deliver a suitable response. %This goal often hints at balancing between cost and performance, \eg\ proprietary models offer high performance but are costly, while smaller open-source models are more affordable but frequently underperform. 
% Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates for model cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce a new benchmark dataset, the Scalable Price-aware Routing (\newdata) dataset, to facilitate routing with the latest state-of-the-art LLMs. Using \newdata\ and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers. %using the Routerbench, open-LLM-leaderboard-v2 benchmark datasets. Along side CARROT, we also introduce a new benchmark dataset, the Scalable Price-aware Routing (\newdata) dataset, to facilitate routing with latest state-of-the-art LLMs and validate CARROT's performance on \newdata.

% \my{also collect our own dataset with recent models}







%Our core idea relates the routing problem to a classification task with multiple objectives (cost and performance) and then exploits an explicit form of oracle routers to develop this plug-in approach.  We use this plug-in approach to understand the complete cost versus performance trade-off in two benchmark datasets, namely \routerbench\ and \openllm. In particular, for \routerbench\ through routing, we were able to obtain a performance similar to that of GPT-4 at half the cost. On a more technical note, we broaden the framework of minimax study for nonparametric classifications on two fronts: more than two classes and multiple objectives.

With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in \emph{LLM routing}, or directing queries to the cheapest LLM that can deliver a suitable response. 
Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware ROUTing (\newdata) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using \newdata\ and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers. \blfootnote{$^\dagger$ primary contributors and corresponding authors (smrstep@umich.edu, maiapolo@umich.edu)\\ \phantom{fill f} * lead investigators (mikhail.yurochkin@ibm.com, smaity@uwaterloo.ca)}