%\section{Discussion}
\section{Conclusion}
We introduce \ourbench to assess the robustness of LLMs against fraud and phishing inducements. By evaluating both open-source and widely used proprietary large language models, we highlight the significant improvement in models' ability to detect fraudulent information, particularly in role-play settings. Additionally, we call on model developers to prevent their models from being misused for generating fraudulent content.