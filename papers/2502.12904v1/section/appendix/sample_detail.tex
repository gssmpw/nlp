\section{More Prompts \& \ourbench Data Sample Details}

\subsection{Base Dataset Elicit Prompt}
To systematically use \texttt{Deepseek-R1}'s ability to generate fraudulent content, we design three data elicitation prompts, each targeting different real-world fraud raw data to create Base Dataset \(\mathcal{D}^{(0)}\):  \textbf{Message} (Figure~\ref{fig:base_data_generation_prompt_message}), \textbf{Fake Job Posting} (Figure~\ref{fig:base_data_generation_prompt_fake_job}), and \textbf{Dialogue} (Figure~\ref{fig:base_data_generation_prompt_dialogue})
\input{figure/base_data_generation_prompt/message}
\input{figure/base_data_generation_prompt/Dialogue}
\input{figure/base_data_generation_prompt/jobpost}
\label{app:prompt_basedata_elicit}

\subsection{Augmented Dataset Elicit Prompt}
\label{app:prompt_augmenteddata_elicit}
Based on the generated Base Dataset \(\mathcal{D}^{(0)}\), we utilized \texttt{Deepseek-R1} to create augmented data for the next three rounds with following prompt in Figure~\ref{fig:augmented_base_prompt_en} for English version and Figure~\ref{fig:augmented_base_prompt_cn} for Chinese version. Specifically, for each round, we applied a controlled transformation strategy to modify the original samples while preserving their core semantic and structural properties. This augmentation process followed a progressive enhancement approach, where each subsequent round incorporated more sophisticated modifications to increase the difficulty of fraud detection. 

In Round 1, the augmentation primarily focused on lexical and syntactic variations, such as paraphrasing, synonym replacement, and minor structural rearrangements, ensuring that the key fraudulent intent remained intact while making the content appear distinct. 

In Round 2, we introduced contextual enhancements inspired by real-world deception tactics, incorporating domain-specific jargon, fabricated but plausible statistical data, and references to well-known institutions or authorities. These changes aimed to increase the authenticity and persuasiveness of the fraudulent content, making detection more challenging.

In Round 3, we applied psychological manipulation techniques, including urgency cues (e.g., time-sensitive offers, limited availability warnings), social proof elements (e.g., fabricated testimonials, peer endorsements), and fear-based persuasion (e.g., potential financial loss or legal consequences). This round aimed to assess the model's ability to recognize deceptive intent when the fraudulent messages exploited cognitive biases.
\input{figure/augmented_data_creation/base_framework}


\subsection{Two Real-world Scenarios Prompt}
\label{app:Two Real-world Scenarios Prompt}
To comprehensively evaluate the model's ability to identify fraudulent content and provide appropriate guidance, we design two real-world scenarios: \textbf{Helpful Assistant} and \textbf{Role-play}. These scenarios are implemented in both English and Chinese, ensuring cross-linguistic robustness and diverse contextual coverage.

In the Helpful Assistant scenario (see Figure~\ref{fig:Two Real-world Scenarios Prompt_en} for English and Figure~\ref{fig:Two Real-world Scenarios Prompt_cn} for Chinese), the model assumes the role of an unbiased advisor, assisting users in assessing potentially fraudulent messages, emails, and job postings. The prompts are structured to reflect common user concerns, such as whether a received message warrants attention and how to appropriately respond. The model is expected to offer clear, informative, and reassuring guidance to the user.

The Role-play scenario, as illustrated in Figure~\ref{fig:Two Real-world Scenarios Prompt_en} (English) and Figure~\ref{fig:Two Real-world Scenarios Prompt_cn} (Chinese), introduces a contextualized perspective, where the model adopts a first-person stance based on a given background (\texttt{\{rolebg\}}). This approach allows for a more nuanced evaluation of how the model interprets deceptive content within a personalized setting. The model is prompted to decide whether to engage with the received message, email, or job posting, and to provide a response accordingly.

\input{figure/Two_Real-world_Scenarios_Prompt/en}
\input{figure/Two_Real-world_Scenarios_Prompt/cn}

\subsection{\ourbench Data Samples}
The following data samples(from Figure~\ref{fig:Chinese Sample of Phising Email} to Figure~\ref{fig:English Sample of Public}) include a diverse collection of fraud scenarios across multiple domains, covering both Chinese and English versions. Specifically, the samples encompass phishing emails, network friendship scams, acquaintance fraud, commercial spam, e-commerce logistics scams, fake job postings, fraud emails, investment and financial scams, and impersonation of public security, judiciary, and government agencies. Each category highlights distinct fraudulent techniques, providing a comprehensive benchmark for evaluating model performance in detecting deceptive content across different contexts and languages.

\input{figure/fraud_demo/Chinese/phising_email}
\input{figure/fraud_demo/English/phising_email}
\input{figure/fraud_demo/Chinese/network_friendship}
\input{figure/fraud_demo/English/network_friendship}
\input{figure/fraud_demo/Chinese/acquaintances}
\input{figure/fraud_demo/English/acquaintances}
\input{figure/fraud_demo/Chinese/commercial_spam}
\input{figure/fraud_demo/English/commercial_spam}
\input{figure/fraud_demo/Chinese/e-commerce_logistics_and_shopping}
\input{figure/fraud_demo/English/e-commerce_logistics_and_shopping}
\input{figure/fraud_demo/Chinese/fake_job_posting}
\input{figure/fraud_demo/English/fake_job_posting}
\input{figure/fraud_demo/Chinese/fraud_email}
\input{figure/fraud_demo/English/fraud_email}
\input{figure/fraud_demo/Chinese/investment_and_financial_management}
\input{figure/fraud_demo/English/investment_and_financial_management}
\input{figure/fraud_demo/Chinese/public_security_prosecution_judiciary_and_government_agencies}
\input{figure/fraud_demo/English/public_security_prosecution_judiciary_and_government_agencies}
