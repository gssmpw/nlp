\section{Related Works}
\label{sec:related_works}

\subsection{Conformal Prediction for Time Series}

Conformal prediction has gained widespread popularity for its effectiveness in uncertainty quantification for black-box models, requiring only the exchangeability assumptionVovk, "The Game-Theoretic Framework for Probability and Finance"__. However, applying CP methods to time series poses significant challenges, as time series inherently violate the exchangeability assumption due to their sequential and temporal dependencies. 

Numerous studies have extended conformal prediction (CP) beyond the exchangeability assumption. A significant line of research focuses on assigning unequal weights to past non-conformity scores or leveraging their historical context, allowing more informative scores to contribute more effectively. Such works include Wang et al., "Conformalized Quantile Regression"__, and Vovk et al., "Exchanging Induced Conformity with Inductive Conformity"__. In particular, Blanchet et al., introduced the Sequential Predictive Conformal Inference (SPCI) framework, which incorporates correlations in non-conformity scores to construct more robust prediction intervals by sequentially adopting a quantile regression estimator. Based on this idea, several studies have employed neural networks to enhance CP for time series. For example, Cotta et al., utilized the Transformer to capture the correlations in non-conformity scores. Bartlett et al., proposed HopCPT, which leverages Hopfield networks to achieve a similar objective.


\begin{figure*}[htb]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/region_transformation_covered_y0.pdf}
        \caption{Covered example ($p_0$)}
        \label{fig:covered_y0}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/region_transformation_covered_y1.pdf}
    \caption{Covered example ($q$)}
    \label{fig:covered_y1}
    \end{subfigure}
    
    \vspace{0.5cm}
    \begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/region_transformation_uncovered_y0.pdf}
        \caption{Uncovered example ($p_0$)}
        \label{fig:uncovered_y0}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/region_transformation_uncovered_y1.pdf}
        \caption{Uncovered example ($q$)}
        \label{fig:uncovered_y1}
    \end{subfigure}
    \caption{Transformation of an example between the base distribution ($p_0$) space and the target distribution ($q$) space using the trained conditional flow. The prediction region in the target distribution space (b,d) is visualized by transforming samples from the circumference of the ball with a probability measure of 0.95. The region in the base distribution space (a,c) is obtained by transforming the prediction region back to the base distribution space.}
    \label{fig:transformation}
\end{figure*}

\subsection{Conformal Prediction for Multi-dimensional Data}

Conformal prediction for multi-dimensional data has been actively studied, as modern data often contain multiple variables. One of the simplest approaches involves constructing coordinate-wise prediction intervals with Bonferroni correction. For instance, Lei and Wasserman applied this idea to generate coordinate-wise prediction intervals for multi-step time series forecasting by adjusting the significance level using Bonferroni correction. A similar approach has been explored for multivariate functional data Le et al., and multivariate functional time series data Li et al.,.

Recent studies have explored various uncertainty sets, such as copulas and ellipsoids, to construct prediction regions for multidimensional data. For example, Cervellera et al., investigated the use of copulas for constructing prediction regions, while Gruber et al., and Schettini et al., utilized ellipsoidal uncertainty sets. Liang et al., extended the application of copulas to exchangeable time series. Lei et al., applied the SPCI framework to non-conformity scores defined as the radius of ellipsoidal uncertainty sets, leveraging sequential correlations of the non-conformity scores to handle multi-dimensional outcomes.

Zhu et al., used normalizing flow for CP with multi-dimensional outcomes of exchangeable data. They defined non-conformity scores as the distances from the origin and employed split conformal prediction to construct prediction regions. While their study shares some methodological similarities with ours, it differs in two significant aspects: they used discrete normalizing flows and focused exclusively on exchangeable data.


 
\subsection{Probabilistic Forecasting using Deep Learning}

Probabilistic forecasting is a method of prediction that estimates the distribution of outcomes. Unlike typical time series forecasting, which outputs a point prediction, probabilistic forecasting can be used for uncertainty quantification since it outputs the distribution of the outcomes. With recent advances in deep learning, numerous probabilistic forecasting methods have been developed. Among these, Monti et al., "Temporal Fused Embeddings for Multivariate Time Series Forecasting"__, and Seo et al., "Temporally-Fused Transformer (TFT)"__ are widely used methods. DeepAR leverages RNNs and TFT utilizes attention mechanisms to capture the temporal dependencies for probabilistic forecasting. Oreshkin et al., also applied conditional normalizing flows for probabilistic forecasting, similar to our approach, but they used a discrete set of normalizing flow layers instead of continuous transformation.