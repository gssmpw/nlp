\section{Related Work}
\subsection{Dataset for Camouflage Object Detection}

% The rapid development of the field of camouflage target detection in recent years is partly due to the enhancement of deep learning algorithms, and partly attributed to the emergence of large-scale camouflage object detection datasets, which are the basis for the training and benchmarking the COD models. Data sets for static camouflage target detection include CAMO \cite{camo}, CHAMELEON \cite{chameleon}, COD10K \cite{fan2020camouflaged}, and NC4K \cite{Lv2021-RankNet}. The CAMO \cite{camo} contain 1,000 traing images and 250 test images, and covers a variety of challenging scenarios, including camouflaging animals and artificial camouflage. CHAMELEON \cite{chameleon} contains 76 images, focusing on camouflage animals. COD10K \cite{fan2020camouflaged} is the largest camouflage target dataset, and contains around 7000 camouflage images, and is notably often used in pre-training of VCOD models. On the VCOD dataset, the CAD dataset \cite{bideau2016s} is a small VCOD dataset, comprising 9 short sequences from YouTube with hand-labeled ground truth masks every 5 frames. The original Moving Camouflaged Animals (MoCA) dataset \cite{lamdouar2020betrayed} includes 37K frames from 141 YouTube videos at 720 × 1280 resolution and 24 fps, featuring 67 animal species in natural scenes, though not all are camouflaged. The ground truth in MoCA is provided as bounding boxes, which makes it difficult to evaluate the segmentation performance of the VCOD. \cite{cheng2022implicit} reorganize this dataset into MoCA-Mask, establishing a benchmark with more comprehensive evaluation criteria. Nevertheless, all of the VCOD datasets are animal-specific, different from these datasets, we propose MSVCOD dataset for multiple types of objects and scenarios.


The rapid development of camouflage object detection in recent years is partly due to advancements in deep learning algorithms and the emergence of large-scale camouflage object detection (COD) datasets, which form the foundation for training and benchmarking COD models. Datasets for static camouflage object detection include CAMO \cite{camo}, CHAMELEON \cite{chameleon}, COD10K \cite{fan2020camouflaged}, and NC4K \cite{Lv2021-RankNet}. The CAMO dataset \cite{camo} contains 1,000 training images and 250 test images, covering various challenging scenarios, including camouflaged animals and artificial camouflage. CHAMELEON \cite{chameleon} consists of 76 images, focusing on camouflaged animals. COD10K \cite{fan2020camouflaged}, the largest camouflage object dataset, includes around 10000 images and is frequently used for pre-training VCOD models.

For VCOD, the CAD dataset \cite{bideau2016s} is a small dataset, containing 9 short sequences from YouTube with hand-labeled ground truth masks every 5 frames. The original Moving Camouflaged Animals (MoCA) dataset \cite{lamdouar2020betrayed} includes 37K frames from 141 YouTube videos at 720 × 1280 resolution and 24 fps, featuring 67 animal species in natural scenes (though not all are camouflaged). MoCA provides ground truth as bounding boxes, making segmentation evaluation difficult. Cheng \emph {et al.} \cite{cheng2022implicit} reorganized MoCA into MoCA-Mask, establishing a benchmark with more comprehensive evaluation criteria. However, all existing VCOD datasets are animal-specific. In contrast, we propose the MSVCOD dataset, which covers multiple object types and scenarios.



\subsection{Image-based Camouflage Object Detection}

% Image-based COD aims to identify camouflage objects from still images. Those early methods \cite{pan2011study, liu2012foreground} leverage hand-designed features to identify camouflage objects from backgrounds environment. Then with the development of deep learning and the proposal of large-scale COD datasets \cite{camo,chameleon,fan2020camouflaged}, COD has been rapidly developed. Some methods \cite{FanDP2020-Pranet,fan2020camouflaged,FanDP2021-ConcealedOD} develop a coarse-to-fine approach to recognize the camouflages objects progressively. To further enhance performance, some studies \cite{zhai2021MGL,Lv2021-RankNet,he2023camouflaged} incorporate auxiliary tasks into a joint learning framework. MGL \cite{zhai2021MGL} combine classification or boundary detection tasks with COD, and LSR \cite{Lv2021-RankNet} propose a multi-task framework for COD to simultaneously localize, segment,and rank camouflaged objects. Combined with edge extraction, FEDER \cite{he2023camouflaged} propose a network to decompose features into
% different frequency bands with learnable wavelets. Some works \cite{pang2022zoom,jia2022-CODSegMar,Xing2023-SARNet} find that image or feature amplification can be useful to recognize camouflaged objects. ZoomNet \cite{pang2022zoom} employs a zoom-in-and-out technique to handle appearance features across three different scales. SegMaR \cite{jia2022-CODSegMar} utilizes a segment, magnify, and reiterate method in a multistage, coarse-to-fine process, effectively replicating human behavior in analyzing complex situations. SARNet \cite{Xing2023-SARNet} introduces a search, amplify, and recognize framework by enhancing the resolution of the target region to detect camouflaged objects. Since the above model is only focused on still images, 
% Since the above model focuses on still images, it cannot utilize motion information and perform poorly on video camouflage object detection tasks. 



Image-based COD aims to identify camouflaged objects in still images. Early methods \cite{pan2011study, liu2012foreground} relied on hand-designed features to distinguish camouflaged objects from their background. With the development of deep learning and large-scale COD datasets \cite{camo, chameleon, fan2020camouflaged}, the field has advanced rapidly. Some methods \cite{FanDP2020-Pranet, fan2020camouflaged, FanDP2021-ConcealedOD} use a coarse-to-fine approach to progressively identify camouflaged objects. To further enhance performance, some studies \cite{zhai2021MGL, Lv2021-RankNet, he2023camouflaged} integrate auxiliary tasks within a joint learning framework. Additionally, some works \cite{pang2022zoom, jia2022-CODSegMar, Xing2023-SARNet} explore image or feature amplification to improve camouflage recognition. For example, ZoomNet \cite{pang2022zoom} employs a zoom-in-and-out technique to process appearance features across three different scales. Other methods \cite{lin2023frequency, sun2025frequency, zhang2024frequency} attempt to segment camouflaged objects through frequency analysis. However, since these models are designed for still images, they cannot utilize motion information, which limits their performance in video camouflage object detection tasks.





\subsection{Video Camouflage Object Detection}
% Video camouflage object detection is a recently developed research field. Just like other video segment tasks (e.g., VSOD \cite{lan2022siamese,gao2022weakly,ji2021full} and VOS \cite{hong2023simulflow, miao2024region,seong2022video,yang2022decoupling}), motion cues are considered to be an effective means to break the camouflage of objects. Bideau et al.\cite{bideau2016s} use a variety of motion models derived from dense optical flow to detect camouflage object. Also using optical flow information, Lamdouar et al. \cite{lamdouar2020betrayed} propose a network for video registration and segmentation that utilizes optical flow and difference images to detect camouflaged objects. However, Lamdouar et al. \cite{lamdouar2020betrayed} can only output detection results at the bounding box level, due to dataset limitations. Optical flow \cite{deng2023explicit, teed2020raft, dosovitskiy2015flownet,sun2018pwc} provide motion information, but it can be disruptive to the model when the object is not moving, or when only the camera is moving, and the computational expense of optical flow is large. Cheng et al. \cite{cheng2022implicit} propose a two-stage model that implicitly incorporates motion information in terms of long and short time, and predict pixel level masks. Further, explicitly handling motion cues, Zhang et al\cite{zhang2024explicit} propose a two stream model to estimate optical flow and segment camouflage objects. Different from the above methods, accompanied by the MSVCOD dataset, we propose a single-stream camouflage object detection model without explicitly computing the optical flow information.


Video camouflage object detection is a recently developed research field. Similar to other video segmentation tasks (\emph {e.g.}, VSOD \cite{lan2022siamese, gao2022weakly, ji2021full} and VOS \cite{hong2023simulflow, miao2024region, seong2022video, yang2022decoupling}), motion cues are considered an effective means to break the camouflage of objects. Bideau \emph {et al.} \cite{bideau2016s} use various motion models derived from dense optical flow to detect camouflaged objects. Lamdouar \emph {et al.} \cite{lamdouar2020betrayed}, also using optical flow, propose a network for video registration and segmentation that utilizes optical flow and difference images to detect camouflaged objects. However, their model can only output detection results at the bounding box level due to dataset limitations.

While optical flow \cite{deng2023explicit, teed2020raft, dosovitskiy2015flownet, sun2018pwc} provides motion information, it can be problematic when the object is stationary or only the camera is moving. Additionally, the computational cost of optical flow is high. Cheng \emph {et al.} \cite{cheng2022implicit} propose a two-stage model that implicitly incorporates motion information over long and short time intervals and predicts pixel-level masks. Further, explicitly handling motion cues, Zhang \emph {et al.} \cite{zhang2024explicit} introduce a two-stream model to estimate optical flow and segment camouflaged objects. In contrast to these approaches, and with the support of the MSVCOD dataset, We propose a one-stream camouflage object detection model that does not require explicitly computing optical flow as input.