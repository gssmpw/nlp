%\documentclass[sigconf, nonacm]{acmart}
\PassOptionsToPackage{dvipsnames}{xcolor}
\documentclass[sigconf, nonacm, pdfa]{acmart}
%\documentclass{vldb}
%% The following content must be adapted for the final version
% paper-specific
% \newcommand\vldbdoi{10.14778/3675034.3675048}
% \newcommand\vldbpages{2576 - 2589}
% issue-specific
\newcommand\vldbvolume{17}
\newcommand\vldbissue{10}
\newcommand\vldbyear{2024}
% should be fine as it is
\newcommand\vldbauthors{\authors}
\newcommand\vldbtitle{\shorttitle} 
% leave empty if no availability url should be set
\newcommand\vldbavailabilityurl{http://vldb.org/pvldb/format_vol14.html} 
% whether page numbers should be shown or not, use 'plain' for review versions, 'empty' for camera ready
\newcommand\vldbpagestyle{empty} 

%Custom Sytles
\usepackage{enumitem}
% \usepackage{xcolor}
\usepackage{cleveref}
\usepackage{pifont}
%\usepackage[font=scriptsize]{caption}
\input{custom_sytles}
\pagenumbering{gobble}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{cleveref}
\usepackage{pifont}
\usepackage{cleveref}
\usepackage{makecell}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{fancyvrb}
\usepackage[dvipsnames]{xcolor}
\usepackage[breakable]{tcolorbox} % Load the breakable library

% \usepackage{tcolorbox}

\crefformat{section}{\S#2#1#3} % see manual of cleveref, section 8.2.1
\crefformat{subsection}{\S#2#1#3}
\long\def\comment#1{}
\newcommand{\kfadd}[1]{\textcolor{red}{Kangfei: #1}}
\newcommand{\rradd}[1]{\textcolor{red}{#1}}
\newcommand{\tjadd}[1]{\textcolor{green}{#1}}
\newcommand{\algocomment}[1]{\footnotesize $\rhd$ \emph{#1}}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\definecolor{LightRed}{rgb}{1,0.88,1}
\definecolor{LightYellow}{rgb}{1,1,0.88}
\definecolor{LightGray}{gray}{0.8}
\def\semichecked{\ding{52}\!\!\!\raisebox{0.3 em}{\tiny$\smallsetminus$}}
\setlength{\abovecaptionskip}{0.cm}
\setlength{\belowcaptionskip}{-0.2cm}
\usepackage{caption}
\usepackage{subfigure}
% \usepackage{subcaption}
\usepackage{listings}


\lstdefinestyle{sqlstyle}{
    language=SQL,
    backgroundcolor=\color{white},
    basicstyle=\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{green},
    stringstyle=\color{red},
    showstringspaces=false,
    numbers=none,
    breaklines=true,
}


\input{command}


\begin{document}


\title{Can Large Language Models Be Query Optimizer for Relational Databases?}

\author{Jie Tan}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
	\city{}%Beijing}
	\country{}%China}
}
\email{jtan@se.cuhk.edu.hk}

\author{Kangfei Zhao}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
	\city{}%Beijing}
	\country{}%China}
}
\email{zkf1105@gmail.com}

\author{Rui Li}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
	\city{}%Beijing}
	\country{}%China}
}
\email{lirui@se.cuhk.edu.hk}

\author{Jeffrey Xu Yu}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
	\city{}%Beijing}
	\country{}%China}
}
\email{yu@se.cuhk.edu.hk}

\author{Chengzhi Piao}
\affiliation{%
	\institution{Hong Kong Baptist University}
	\city{}%Hong Kong}
	\country{}%China}
}
\email{czpiao@comp.hkbu.edu.hk}

\author{Hong Cheng}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
 \city{}%Shenzhen}
	\country{}%China}
}
\email{hcheng@se.cuhk.edu.hk}

\author{Helen Meng}
\affiliation{%
	\institution{The Chinese University of Hong Kong}
 \city{}%Shenzhen}
	\country{}%China}
}
\email{hmmeng@se.cuhk.edu.hk}

\author{Deli Zhao}
\affiliation{%
	\institution{DAMO Academy, Alibaba group, Hupan Lab}
 \city{}%Shenzhen}
	\country{}%China}
}
\email{zhaodeli@gmail.com}

\author{Yu Rong}
\affiliation{%
	\institution{DAMO Academy, Alibaba group, Hupan Lab}
 \city{}%Shenzhen}
	\country{}%China}
}
\email{yu.rong@hotmail.com}



\begin{abstract}
Query optimization, which finds the optimized execution plan for a given query, is a complex planning and decision-making problem within the exponentially growing plan space in database management systems (DBMS). 
Traditional optimizers heavily rely on a certain cost model constructed by various heuristics and empirical tuning, probably leading to generating suboptimal plans. 
Recent developments of Large Language Models (LLMs) have demonstrated their potential in solving complex planning and decision-making problems, such as arithmetic and programmatic tasks. 
In this paper, we try to explore the potential of LLMs in handling query optimization and propose a tentative LLM-based query optimizer dubbed \LLMQO, established on \Postgres's execution engine. 
In \LLMQO, we formulate query optimization in an autoregressive fashion which directly generates the execution plan without explicit plan enumeration. 
To investigate the essential input of \LLMQO, we design a customized data recipe named \QueryInstruct to collect the training data from various optimizers and serialize the database's meta data, queries and corresponding plans into a textual format. 
Based on \QueryInstruct, we implement a two-stage fine-tuning pipeline, Query Instruction Tuning (\QIT) and Query Direct Preference Optimization (\QDPO), to empower the capability of general-purpose LLMs in handling query optimization. 
In our experiments, \LLMQO can generate valid and high-quality plans and consistently outperforms both traditional and learned optimizers on three query workloads. 
%\tjadd{In our experiments, \LLMQO(\QDPO) can generate valid and efficient plans, outperforming both traditional and learned optimizers across three query workloads. We also confirm its capability of generalizing to out-of-distribution queries.}
%Its goal is not only to assess whether a model's OOD generalization capability
Our findings verify that LLMs can be derived as query optimizers where generalization, efficiency and adaptivity deserve further research efforts. 
%差最后一句
% \QueryInstruct defines a serialize and deserialization protocol that 我还是觉得 data recipe这个说法很怪



\end{abstract}






\maketitle
%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
\pagestyle{\vldbpagestyle}
\begingroup\small\noindent\raggedright\textbf{PVLDB Reference Format:}\\
\vldbauthors. \vldbtitle. PVLDB, 
%\vldbvolume(\vldbissue): \vldbpages, \vldbyear.\\
% \href{https://doi.org/\vldbdoi}{doi:\vldbdoi}
\endgroup
\begingroup
\renewcommand\thefootnote{}\footnote{\noindent
% *Kangfei Zhao is the corresponding author.


\noindent This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit \url{https://creativecommons.org/licenses/by-nc-nd/4.0/} to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing \href{mailto:info@vldb.org}{info@vldb.org}. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. \\
\raggedright Proceedings of the VLDB Endowment, Vol. \vldbvolume, No. \vldbissue\ %
% ISSN 2150-8097. \\
% \href{https://doi.org/\vldbdoi}{doi:\vldbdoi} \\
}\addtocounter{footnote}{-1}\endgroup

%%% VLDB block end %%%

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
% \ifdefempty{\vldbavailabilityurl}{}{
% \vspace{.3cm}
% \begingroup\small\noindent\raggedright\textbf{PVLDB Artifact Availability:}\\
% The source code, data, and/or other artifacts have been made available at \url{https://github.com/FangShuheng/IACS}.
% \endgroup
% }
%%% VLDB block end %%%


\input{intro}
\input{related}
\input{prob}
\input{method}
\input{experiment}

\section{Conclusion \& Future Work}
\label{sec:conclusion}
%optimizer information 无法textulization送进去；
In this paper, we first explore the use of LLMs for SQL query planning by formulating query optimization as a sequence generation task.
To fulfill this desire, we propose an innovative framework, \LLMQO, which absorbs and distills intricate planning strategies from existing optimizers via LLM fine-tuning. 
%We train the LLMs to generate effective execution plans by assimilating preferences from existing well-designed optimizers. 
In \LLMQO, we customize a data recipe \QueryInstruct, based on which a two-stage training workflow is proposed to empower off-the-shelf LLM to generate valid and high-quality execution plans.
We conduct comprehensive experiments on \LLMQO for query evaluation in \Postgres's execution engine, which verify the promise of \LLMQO in both general and OOD settings of query workloads, as well as the effectiveness of our internal designs. 
Our study of \LLMQO paves the way for deploying general LLMs for query planning in database systems. In our investigation, many challenges about generalization, efficiency and adaptivity arise that deserve further exploration. 
% \tjadd{In our investigation, many challenges about generalization, efficiency and adaptivity arise and deserve further exploration. }
First and foremost, we will improve the training of LLMs to enable generalization across multiple database instances, underlying execution engines, query types and logical/physical operators. There is no doubt that this requires abundant computation resources and numerous high-quality training data. 
Second, to better underpin query processing in DBMS, the inference efficiency of \LLMQO should be further improved by systematic optimization. 
Third, \LLMQO may still suffer from the hallucination problem where the input prompt and generation process need to be refined to ensure that the execution plans are coherent with  necessary conditions.
Last but not least, due to the effectiveness of adding \db in \cref{sec:exp:preference adaption}, we plan to add more optimizers to enjoy new preference of plans and adaptivity to dynamic scenarios in \LLMQO.




\clearpage
\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{bibfile}


\clearpage
%\input{appendix}


\end{document}

