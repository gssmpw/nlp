\comment{Large language models (LLMs) have achieved impressive success across several fields, but their proficiency in understanding and resolving query optimization problems is less explored. 
To bridge this gap, we introduce QueryInstruct, a novel and comprehensive instruction-tuning dataset designed to equip language models with the ability to generate logical plans using SQL semantics and data distributions in the schema. 
Utilizing QueryInstruct, we build PlanLLM, an open-source language model capable of generating efficient plans for various query types. 
To enhance the model's capability and reliability, we incorporate the Direct Preference Optimization (DPO) framework into the training procedure. 
The enhanced model, PlanLLM-DPO, achieves near-optimal performance across several benchmarks. It reduces the plan execution time of PostgreSQL's native optimizer by up to 10\%.
Moreover, our research delves into the delicate balance between training data volume and model performance, highlighting the potential for overfitting with increased data. 
We also examine the transferability of the model's capabilities across different database schemas and query templates, highlighting its adaptability and practical application potential. Our investigation provides a new blueprint and valuable insights for developing LLMs specialized in query optimization challenges.
% However, there are several challenges that utilize LLMs to do query optimization. 
% First, it is challenging to provide appropriate prompts (e.g., instructions and demonstration examples) to enable LLMs to understand the database optimization problems. 
% Second, LLMs only capture the logical database characters (e.g., SQL semantics) but are not aware of physical characters (e.g., data distributions), and it requires to fine-tune LLMs to capture both physical and logical information. 
% Third, LLMs are not inherently trained for query optimization. Since LLMs have not encountered this task before, we need to use data-driven instruction tuning to equip them with the ability to function as query optimizers, enabling them to generate accurate and efficient plans.
}
\section{Introduction}
Query optimizer is a fundamental component in database management systems (DBMS), which has been continuously studied over decades~\cite{DBLP:books/sp/KimRB85, DBLP:books/mk/FreytagMV91, DBLP:journals/csur/JarkeK84}. 
%Query optimizer plays a critical role in database management system (DBMS). 
Generic query optimizers follow a `plan enumeration and search' paradigm, which enumerate candidate plans from an exponentially growing plan space and employ a cost model to find the plan with minimal cost~\cite{DBLP:conf/sigmod/SelingerACLP79, DBLP:journals/csur/Graefe93, DBLP:conf/job/Leis18, DBLP:conf/pods/Chaudhuri98}. 
% where a cost-based search model explores the plan space and find the plan with minimal estimated cost~\cite{DBLP:conf/sigmod/SelingerACLP79}. 
%As the plan space grows exponentially regarding the number of involved relations and operator types, intrinsic uncertainty from the cost model cascades from a base table to sub-queries. 
% Roy: 中间
%Therefore, within this paradigm, a precise and reliable cost estimation model is crucial for ensuring the quality of generated query plans. 
The cost model in query optimizers relies on various heuristics, assumptions, and hyper-parameters which are empirically calibrated and tuned over years under certain systems and hardware configurations. Recent studies have explored machine learning techniques to construct learning-based search algorithms, such as reinforcement learning algorithms, to replace dynamic programming to generate plans~\cite{DBLP:journals/corr/abs-1808-03196, DBLP:conf/kdd/0008Y000CZ022, DBLP:conf/icde/Yu0C020, DBLP:journals/pvldb/MarcusNMZAKPT19}, and inject learning-based strategies into generic query optimizers to steer the process of candidate plan selection~\cite{DBLP:conf/sigmod/MarcusNMTAK21, DBLP:journals/pvldb/YuC0L22, DBLP:journals/pvldb/ZhuCDCPWZ23}. 
%
This `plan enumeration and search' paradigm makes a good trade-off between plan space exploration and execution efficiency, as it is computationally infeasible to calculate costs for all possible plans using the cost model. However, the performance upper bound may be constrained by the candidate plans generated in the initial enumeration phase, potentially missing the better plan due to insufficient exploration of the plan space. 

\begin{figure}
    \centering
    \begin{subfigure}[An Overview of \LLMQO]{%
        \includegraphics[width=1.05\linewidth]{figures/intro_dsb/intro_dsb-figure1.pdf}
  \label{fig:intro:overview:plan}
     }\end{subfigure}
     \vspace{-1ex}
    \begin{subfigure}[Execution Time Comparsion with Traditional Optimizers on \dsb]{%
        \includegraphics[width=1\linewidth]{figures/intro_dsb/intro_dsb-figure0.pdf}
  \label{fig:intro:overview:performance}
     }\end{subfigure}
    \vspace{1ex}
    \caption{The Framework and Performance of \LLMQO}
    \label{fig:intro_overview}
\end{figure}
%This limitation motivate us to reconsider the query optimization problem from an alternative perspective: investigating the feasibility of direct plan generation within the complete plan space, rather than depending on a surrogate cost model for selection from a pre-enumerated candidate set. This approach inherently demands a complex planning and decision capabilities based on multiple factors, including data schema, data distribution, DBMS characteristics and even hardware configurations. 
Recently, we have witnessed the great success of Large Language Models (LLMs)~\cite{DBLP:journals/pvldb/LaoWLWZCCTW24, zhao2024surveylargelanguagemodels} in solving planning and decision-making problems. Pretrained on massive datasets, LLMs exhibit surprising emergent abilities for solving specific tasks~\cite{wei2022emergent}. Furthermore, after fine-tuned with sophisticated task-specific data, these models can accept the in-context information from inputs and conduct rigorous logical reasoning process to solve complex problems, such as mathematical~\cite{openai2024openaio1card} and programming tasks~\cite{jiang2024surveylargelanguagemodels}. Notably, recent database studies have also begun to explore using LLMs to address  problems in DBMS, including knob tuning~\cite{DBLP:journals/pvldb/LaoWLWZCCTW24} and query rewriting~\cite{DBLP:journals/pvldb/AroraYENHTR23, DBLP:journals/corr/abs-2312-17449}, etc.
Impressed by such abilities, it is worth reconsidering query optimization from an alternative perspective: Is it feasible to directly generate execution plans by LLMs without explicit plan enumeration?
%This approach is challenging and inherently demands a complex planning and decision capabilities based on multiple factors, including data schema, data distribution, DBMS characteristics and even hardware configurations. 
The advanced reasoning capabilities of LLMs, developed through extensive pretraining on massive datasets, may facilitate a comprehensive exploration of the plan space, potentially generating new and efficient plans. 

Despite the fascinating envison, deriving LLMs to serve as a query optimizer faces multiple intertwined challenges.
In the context of generative AI, query optimization task should shift from the `plan enumerate and search' paradigm to an `autoregressive generation' paradigm. This is a completely new task for general-purpose LLMs since unlike existing optimizers, they are unaware of information of involved database instances and expert knowledge for query optimization such as the operator types, algorithms and complexity.
Therefore, the principal problem we try to solve in this paper concentrates on enabling LLMs to comprehend query planning task and generate corresponding execution plan for an input SQL query, where the plan should be valid and efficient at the largest extent.
Specifically, in the data level, LLMs should be trained by high-quality ingredients relevant to query optimization, e.g., the description of the task, available operators, the query to be processed, the meta data in the catalog and the query plans etc.
Necessary ingredients should be delivered contextually by a clear and informative format, i.e., a data recipe, that aligns to the textual input-output specification of LLMs. 
In the algorithmic level, we need effective and efficient training algorithms to fine-tune LLMs with reasonable learning objectives. The algorithms should facilitate general-purpose LLMs to absorb the knowledge from the data recipe and gradually approach an expert optimizer to generate valid and efficient plans while preserving the emergent ability of LLMs. 
\comment{
% Before diving into the technical details, it is important to point out that deriving LLMs to serve as a query optimizer faces multiple intertwined challenges.  
\ding{172} \textbf{Problem formulation:} In the context of LLMs, query optimization task should shifts from the `plan enumerate and search' paradigm to an `auto-regressive generation' paradigm, which is challenging. The objective for how the LLM produces the correct plans should be figured out. 
\ding{173} \textbf{Data preparation:}  LLMs should be trained by high-quality ingredients relevant to query optimization. The essential information of query optimization task -- including the data schema, target query, data distribution, available operators, DBMS characteristics and hardware configurations -- should be organized into a clear and informative format——a data recipe——that aligns with the textual input-output paradigm of LLMs.
\ding{174} \textbf{Model finetuning:} Effective and efficient training algorithms are needed to inject knowledge from data recipe into LLMs, will enhance the generalization capability of LLMs on query optimization task, especially for out-of-distribution queries.
}

To this end,  we propose a tentative LLM-based framework dubbed \LLMQO, built upon \Postgres's execution engine. Fig.~\ref{fig:intro:overview:plan} depicts the overview of \LLMQO.
%We first make a rigorous formulation of query optimization in the context of LLMs. 
\LLMQO is formulated to `distill' the knowledge from the experiences of multiple existing optimizers and aspire to inferring better plans via the generalization and emergency of LLMs. 
In the perspective of data, we design a data preparing pipeline for collecting training data from a query workload, encapsulated in a customized data recipe named \QueryInstruct. 
To be specific, 
\QueryInstruct incorporates the input query, the target query plans collected from multiple optimizers, meta data of the database instance and a planning demonstration, and converts them into a textual format. 
This protocol is delicately designed, maintaining a necessary and minimal context to generate valid and efficient plans and save the usage of tokens for online generation. 
In the perspective of algorithm, we implement a two-stage fine-tuning pipeline in \LLMQO to empower the capabilities of general-purpose LLMs in handling the query optimization task. The first stage, named Query Instruction Tuning (\QIT), aims to initiate an LLM capable of generating valid plans.
The second stage, Query Direct Preference Optimization (\QDPO), further refines the model's expertise on query optimization by training it to differentiate between good and ordinary execution plans. 
In a nutshell, this two-stage training workflow guides LLMs to distill and synthesize the behavior of multiple query
optimizers, in a parameterized fashion, so that earn the potential
of being an overall best optimizer. 

The experimental results demonstrate that \LLMQO achieves an improvement of 5.6\%, 8.6\%, and 68.7\% in average execution time on \imdb, \job, and \dsb, respectively, compared with \Postgres built-in optimizer. Fig.~\ref{fig:intro:overview:performance} presents the per-template comparison of \LLMQO with \Postgres and \Oracle built-in optimizers on \dsb.
%  Compared to \PostgreSQL, \LLMQO achieves
% speedup ranging from 1.15x to 8.33x in total latency across
% different benchmarks.
The contribution of this paper is summarized as follows.
\begin{itemize}[leftmargin=*]
    \item %We first formulate 
    We take the first step towards formulating query optimization as a sequence generation task, which can be solved by generative LLMs. As an innovative trial, we propose a framework \LLMQO built on \Postgres's execution engine, which deploys and fine-tunes general-purpose LLMs for query optimization in DBMS. 
    %
    \item We develop \QueryInstruct,  a data recipe including data collecting methodology from multiple optimizers and textualization protocol that standardizes the input and output of \LLMQO. Building upon \QueryInstruct, we design a two-stage training workflow to fine-tune general-purpose LLMs, enabling distillation and incorporation behaviors from multiple query optimizers.
    %
    \item We conduct comprehensive experiments for \LLMQO on three query sets, which demonstrates that \LLMQO achieves the capability to generate valid and high-quality plans and outperforms traditional optimizers and learned optimizers, in general cases and out-of-distribution queries. The ablation studies and parameter studies evaluate different possible design choices, empirically justifying the effectiveness of \LLMQO.
    %
    \item Based on the insights and lessons learned from our trials, we verify that LLMs have the potential as optimizers to generate high-quality plans for DBMS. We identify future research directions in generalization, efficiency and adaptivity that will enhance the flexibility and usability of LLMs in query optimization. 
\end{itemize}

\stitle{Roadmap.} The rest of this paper is organized as follows. \cref{sec:related} introduces the related work. In~\cref{sec:background} we give the preliminary and formulate the problem. 
\cref{sec:overview} presents the overview of \LLMQO, which includes the data preparation pipeline and the training pipeline. We then elaborate on the two pipelines in \cref{sec:method:queryinstruct} and \cref{sec:method:training} respectively. We report the experimental studies in \cref{sec:exp}. \cref{sec:conclusion} concludes the paper and points out future research directions.