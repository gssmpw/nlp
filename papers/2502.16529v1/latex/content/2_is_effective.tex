\begin{figure}
    \centering
    \includegraphics[width=\columnwidth, keepaspectratio]{latex/figure/format.pdf}
    \caption{The topmost subfigure shows a single rung of LD and its corresponding visualized graph. The bottom displays XML tags exportable from a Ladder Diagram IDE, along with JSON and Metaprogram representations that capture structural relationships in the graph.}
    \label{fig:format}
\end{figure}


\begin{figure*}[!th]
    \centering
    \includegraphics[width=0.8\textwidth]{latex/figure/rag_performance_comparison.pdf} 
    \caption{Performance comparison between SFT and RAG, where RAG uses a larger LLM. $N$ represents the number of retrieved examples in RAG, and SFTâ€™s performance is represented by a red dotted line. We use XML as the text format.}
    \label{fig:rag_sft_performance}
\end{figure*}
\input{latex/table/text_format_sft_rag}

\section{Is Training-Based Approach Effective?}
In this section, we investigate the effectiveness of the training-based approach in comparison to the prompting-based approach for industrial VPL generation. We introduce Ladder Diagram (LD) as our test language (\S\ref{sec:ld}), then describe text format conversion in \S\ref{sec:conversion} to explore results across different text formats. Their results are presented in \S\ref{sec:sft_res}.
\subsection{Ladder Diagram}\label{sec:ld}
Programmable Logic Controller (PLC)~\citep{erickson1996programmable} controls physical devices such as sensors and actuators in industrial automation systems. For example, in a conveyor system, PLC logic enables a robotic arm to detect products via sensors and control its joints to transfer items between conveyors. This logic is typically implemented using Ladder Diagram (LD)~\citep{ladderlogic}, which consists of multiple rungs, each executing a specific task (e.g., operating a motor). Figure~\ref{fig:format} illustrates an LD with a single rung.

Each rung is further composed of contacts, coils, and function blocks and can be represented as a node-based graph, where each visual element is a node. These individual elements serve a distinct role in the logic sequence; contacts control the power flow, coils activate machinery, and function blocks (e.g., timers, counters) provide advanced control functions. They are connected to the PLC and mapped to I/O addresses that vary with the environment and hardware setup. This domain-specific address mapping enables customized control, as each rung manages unique I/O settings tailored to its setup.

\subsection{Text Format Conversion}\label{sec:conversion}
As LLMs cannot generate complex visual elements directly, prior studies~\cite{xue2024comfybenchbenchmarkingllmbasedagents,zhang2024benchmarking} generate VPL in text formats. As each format has unique characteristics, we convert VPL into various text formats to conduct comprehensive experiments. We consider three standard text formats for VPL: (1) XML, which represents visual elements sequentially; (2) JSON, which explicitly captures relationships between elements; (3) Metaprogram (code), which encodes VPL using a code-based syntax. 

Specifically, Figure~\ref{fig:format} illustrates that XML format represents LD as a list of visual elements, including contacts, lines, and function blocks. Each visual element corresponds to an \texttt{<Element>} tag containing its element type, coordinates, and other attributes. Since XML does not explicitly define relationships between elements, we extract these relationships using rule-based methods and convert them into a graph. We iterate through the visual elements in coordinate-based order, adding all elements except lines as nodes to the graph. We implement this graph using NetworkX~\cite{SciPyProceedings_11}, which is a widely used Python library for graph representation. We assign Node IDs starting from 0, increasing sequentially in coordinate order. To determine edges, we analyze node coordinates and line positions. Using this information, we construct a directed acyclic graph (DAG).
 
Using this graph representation of LD, we represent LD in both JSON and metaprogram formats. In the JSON format, we represent the LD as a dictionary; each node ID in the graph is a key, and its attributes and outgoing node IDs form the values. For the metaprogram (code) format, we represent the LD in Python syntax using NetworkX. We traverse the graph starting from the smallest node ID, visiting each node and its successors. Upon first visiting a node, we append a \texttt{G.add\_node(...)} statement with its attributes to the code. Similarly, we append a \texttt{G.add\_edge(...)} statement to the code for each neighbor relationship. This process continues until all nodes from the graph are visited. The generated code can be executed to reconstruct the original graph.

\begin{figure*}[!htb]
    \centering
    \includegraphics[width=\textwidth,keepaspectratio]{latex/figure/main_figure.pdf}
    \caption{An overview of two-stage training method. (1) RAFT-V: An off-the-shelf retriever is utilized for relevant prompt augmentation, and training is conducted with cross-entropy loss. (2) Preference Optimization: Preference learning leverages graph-edited preference pairs, with retrieved prompt-code pairs as additional input.}
    \label{fig:main_figure}
\end{figure*}

\subsection{Results}\label{sec:sft_res}
\paragraph{Training-based method outperforms prompting-based method}\label{par:sft_rag}
To evaluate the effectiveness of the training-based approach compared to the prompting-based approach for industrial VPL generation, we conduct a comparison between the supervised fine-tuning (SFT) method and Retrieval-Augmented Generation (RAG). Among prompting-based methods, we select RAG because this approach has been widely used in prior studies on VPL generation~\cite{xue2024comfybenchbenchmarkingllmbasedagents,zhang2024benchmarking}, and retrieval can provide examples that reflect the domain-specific configurations relevant to generation. SFT uses Llama3.1-8B-Instruct model as the backbone, while RAG uses Llama-3.1-70B-Instruct\footnote{Due to computational constraints, we employs the AWQ-quantized~\cite{MLSYS2024_42a452cb} model: \href{https://huggingface.co/hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4}{hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4}}. The RAG approach utilizes BM25~\cite{robertson2009probabilistic} to retrieve \(N\) similar prompt-code pairs from the SFT training dataset. We then append them to the input to generate code for the test prompt\footnote{Detailed experimental settings, including evaluation metrics, are presented in \S\ref{sec:exp_setup}.}.

As can be seen in Figure~\ref{fig:rag_sft_performance}, SFT consistently outperforms RAG across different number of retrieved examples (1, 3, 5, 7, and 9), despite its smaller backbone. Although RAG's performance improves as \(N\) increases, it eventually degrades, suggesting that learning domain-specific configurations in industrial VPL from retrieved examples alone is challenging. Therefore, these results demonstrate that SFT is an effective choice in this setting. We observe similar trends with a different LLM (Appendix~\ref{sec:detailed_results}), and the prompt template for the RAG model is provided in Appendix~\ref{sec:rag_details}. 


\paragraph{Training-based method excels across text formats}\label{par:sft_text_format}
To investigate whether the prior results are consistent across different text formats, we extend our experiments to include JSON and the metaprogram formats. We compare SFT with RAG, where performance is reported based on the number of retrieved examples that achieves the highest Program EM\footnote{Program EM is a binary metric (0 or 1) that indicates an exact match between the generated and reference programs. See \S\ref{sec:exp_setup} for details.} for each text format, as the optimal number of examples can vary across formats. 

From the results in Table~\ref{tab:text_format}, we can observe the following: (1) While SFT shows stable performance across different formats, RAG exhibits performance differences in Node/Edge F1, with the metaprogram-based format showing better performance. This aligns with prior results on prompting-based approaches from \citet{xue2024comfybenchbenchmarkingllmbasedagents}. (2) SFT outperforms RAG across all formats. These results further validate the effectiveness of the training-based approach.
