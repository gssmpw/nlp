\section*{Limitations}
One limitation of our study is that the experiments were conducted exclusively on ladder diagrams. Although ladder diagrams are widely used in visual programming languages (VPLs), extending our methodology to other VPLs is necessary for broader applicability. Nonetheless, ladder diagrams remain crucial in industrial automation but have been largely overlooked due to the text-centric design of most large language models (LLMs). Prior studies have struggled to generate even basic ladder diagrams, highlighting a significant gap. To bridge this, we proposed a method to represent ladder diagrams in multiple text formats, enabling LLMs to process them as a graphical language. This approach addresses the limitations of previous studies and opens new possibilities for LLM-based generation of visual programming languages.

Another limitation is that our dataset cannot be publicly released due to strict confidentiality constraints, as it contains proprietary industrial processes used in manufacturing. To safeguard sensitive information, we have anonymized and provided only a partial subset. Our dataset adhered to the IEC 61131-3 international standard and specifically utilized ladder diagrams, which are a widely adopted language in PLC programming. While our dataset has unique attributes for ladder elements and rung structures that differ across users, it remains applicable to other ladder diagram-based programs that adhere to the IEC 61131-3 standard. Consequently, our methodology is not restricted to this particular dataset but rather is applicable to other industrial formats, which demonstrates scalability and adaptability. Yet, recognizing the importance of further generalization, we acknowledge the need for a publicly available VPL-based benchmark, which we leave as future work.
\section*{Ethical Considerations}
In our research, we employed models such as Llama-3.1-8B-Instruct and Meta-Llama-3.1-70B-Instruct-AWQ-INT4, both of which are released under the Llama 3.1 Community License, as well as Qwen2.5-7B-Instruct, released under the Apache License 2.0, and Qwen2.5-72B-Instruct-AWQ, released under the Qwen license. All models were used strictly for research purposes, and no artifacts were utilized beyond the scope of the study.