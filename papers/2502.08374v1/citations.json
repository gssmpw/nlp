[
  {
    "index": 0,
    "papers": [
      {
        "key": "goodfellow2014explaining",
        "author": "Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian",
        "title": "Explaining and harnessing adversarial examples"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wang2022ab",
        "author": "Wang, Yixiang and Liu, Jiqiang and Chang, Xiaolin and Wang, Jianhua and Rodr{\\'\\i}guez, Ricardo J",
        "title": "AB-FGSM: AdaBelief optimizer and FGSM-based approach to generate adversarial examples"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "gupta2018cnn",
        "author": "Gupta, Harshit and Jin, Kyong Hwan and Nguyen, Ha Q and McCann, Michael T and Unser, Michael",
        "title": "CNN-based projected gradient descent for consistent CT image reconstruction"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "moosavi2016deepfool",
        "author": "Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal",
        "title": "Deepfool: a simple and accurate method to fool deep neural networks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "moosavi2017universal",
        "author": "Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal",
        "title": "Universal adversarial perturbations"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "duan2021advdrop",
        "author": "Duan, Ranjie and Chen, Yuefeng and Niu, Dantong and Yang, Yun and Qin, A Kai and He, Yuan",
        "title": "Advdrop: Adversarial attack to dnns by dropping information"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "joshi2019semantic",
        "author": "Joshi, Ameya and Mukherjee, Amitangshu and Sarkar, Soumik and Hegde, Chinmay",
        "title": "Semantic adversarial attacks: Parametric transformations that fool deep classifiers"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "luo2022frequency",
        "author": "Luo, Cheng and Lin, Qinliang and Xie, Weicheng and Wu, Bizhu and Xie, Jinheng and Shen, Linlin",
        "title": "Frequency-driven imperceptible adversarial attack on semantic similarity"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yan2023wavelet",
        "author": "Yan, Jun and Yin, Huilin and Zhao, Ziming and Ge, Wancheng and Zhang, Hao and Rigoll, Gerhard",
        "title": "Wavelet regularization benefits adversarial training"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "luo2022frequency",
        "author": "Luo, Cheng and Lin, Qinliang and Xie, Weicheng and Wu, Bizhu and Xie, Jinheng and Shen, Linlin",
        "title": "Frequency-driven imperceptible adversarial attack on semantic similarity"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhang2018residual",
        "author": "Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun",
        "title": "Residual dense network for image super-resolution"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2023imperceptible",
        "author": "Chen, Zihan and Wang, Ziyue and Huang, Jun-Jie and Zhao, Wentao and Liu, Xiao and Guan, Dejian",
        "title": "Imperceptible adversarial attack via invertible neural networks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "lu2021large",
        "author": "Lu, Shao-Ping and Wang, Rong and Zhong, Tao and Rosin, Paul L",
        "title": "Large-capacity image steganography based on invertible neural networks"
      }
    ]
  }
]