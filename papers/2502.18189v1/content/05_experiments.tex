\section{Empirical evaluation}
\label{sec:experiments}

Now we present experiments to evaluate our algorithms.
We used Python 3.12, with a core module written in C++20 for all computationally heavy tasks;
the code was compiled with GCC 13.2.0 in release mode.
We use CGAL 5.6.1 for geometric primitives and exact number types, Boost 1.83 for utility functions and pybind11 2.12 for Python bindings
and use the incremental SAT solver CaDiCaL 1.9.5 via the PySAT interface for solving the SAT models.
All experiments were performed on Linux workstations equipped with AMD Ryzen 9 7900 CPUs with 12 cores/24 threads and \qty{96}{GiB} of DDR5-5600 RAM running Ubuntu 24.04.1.

\subsection{Research questions}
Our experimental evaluation aims to answer the following questions.
\begin{enumerate}
  \item[Q1] How does the edge enumeration algorithm from \cref{sec:edge-enumeration} compare to the brute force enumeration in terms of runtime and the number of edges eliminated? 
            Can we solely rely on this algorithm or should we reconsider using the brute force enumeration?
  \item[Q2] What is the quality of the initial solutions computed by the Delaunay triangulation and the constrained Delaunay triangulations from \cref{sec:edge-enumeration} compared to the optimal solution?
  \item[Q3] How do our approaches compare to existing algorithms for the MDT w.r.t.\ runtime and solution quality?
            Can we solve instances with thousands of points to provable optimality?
  \item[Q4] How do \binmdt{} and \incmdt{} compare?
            Which should be used for large instances?
\end{enumerate}

\begin{figure}
    \begin{subfigure}[c]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/01_edge_enumeration/runtimes.pdf}
    \end{subfigure}\hfill
    \begin{subfigure}[c]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/01_edge_enumeration/edges.pdf}
        %\includegraphics[width=\linewidth]{figures/experiments/01_edge_enumeration/no_edges.pdf}
    \end{subfigure}
    \caption{Comparison of our approach from \cref{sec:edge-enumeration} and the $\Theta(n^4)$ brute force elimination on the \emph{random} instance set.
             \textbf{(Left)} The $\Theta(n^4)$ elimination is infeasible for larger instances.
             \textbf{(Right)}~In all cases, only a small number of (red) edges were not eliminated by our approach.}
    \label{fig:edge-enumeration}
    \label{fig:edge-enumeration-edges}
\end{figure}

\subsection{Experiment design}
To answer our questions, we collected and generated a large set of instances, consisting of instances from the following instance classes.
In all cases, the coordinates of points in the instances are either integers or double precision floating-point numbers.
\begin{description}
  \item[random-small] 
    We include instances from the work of \cite{DBLP:conf/cccg/BrandtGSR14}.
    The $210$ instances have fixed sizes $n\in \{10,20,\dots,70\}$ and were generated by placing uniformly random points inside a $10 \times 10$ square.
    For each size a total of $30$ instances were generated.
  \item[random] 
    We include two sets of randomly generated instances.
    These encompass a set of instances with points with float coordinates chosen uniformly between $0$ and $10^3$,
    ranging from \num{50} to \num{10000} points.
    This resulted in a total of \num{800} instances.
  \item[public] 
    We include instances from all well-known publicly available benchmark instance sets we could locate.
    These include point sets previously used in the CG:SHOP challenges~\cite{demaine2022area,demaine2020computing},
    TSPLIB instances~\cite{reinelt1991}, instances from a VLSI dataset\footnote{https://www.math.uwaterloo.ca/tsp/vlsi/index.html} and
    point sets from the Salzburg Database of Polygonal Inputs~\cite{EDER2020105984}.
    In total, we collected \num{486} instances with up to \num{10000} points and an additional \num{38} with up to \num{30000} points.
\end{description}

\subsection{Q1: Edge enumeration}

We first compare the edge enumeration algorithm from \cref{sec:edge-enumeration} to the $\Theta(n^4)$ brute force enumeration of all possible edges on the \emph{random} instance set.
Both preprocessing options include finding all pairwise intersections between the enumerated segments.
Due to the $\Theta(n^4)$ runtime, we only consider instances with up to \num{1000} points; see~\cref{fig:edge-enumeration}.

The $\Theta(n^4)$ algorithm precisely identifies all edges that have the ellipse property;
it can hence only eliminate more edges than the edge enumeration algorithm from \cref{sec:edge-enumeration}.
However, for our test instances, the number of edges that can be eliminated by our approach is almost identical to the $\Theta(n^4)$ algorithm;
see \cref{fig:edge-enumeration-edges} for an example.
The runtime makes the $\Theta(n^4)$ algorithm infeasible for larger instances; 
it takes more than \qty{250}{s} for instances with only \num{1000} points,
compared to $<\qty{1}{s}$ for our more efficient approach.

\subsection{Q2: Initial solutions}
\label{sec:experiments-initial-solutions}

\begin{figure}
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/03_delaunay_quality/gaps.pdf}        
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/07_comparison_with_existing/brandt_runtime.pdf}  
    \end{subfigure}
    \caption{\textbf{(Left)} Initial solution comparison on the \emph{random} set with up to \num{10000} points.
    Delaunay triangulations can be improved by shortcut edges, but are often close to the optimal solution.
    \textbf{(Right)}~Runtime comparison with the approaches from \cite{DBLP:conf/cccg/BrandtGSR14} and \cite{DBLP:journals/jgo/SattariI17} on the \emph{random-small} set.}
    \label{fig:initial-solutions-quality}
    \label{fig:brandt-runtime}
\end{figure}

Better initial solutions can reduce the number of candidate edges further than bad ones and thus affect the runtime of the overall algorithm.
Delaunay triangulations are a natural choice for the initial solution, but we suspect that they can be improved by adding shortcut edges.
\Cref{fig:initial-solutions-quality} shows that the relative dilation gap between the Delaunay triangulation and the optimal solution for the \emph{random} instance set.
It can be seen that the introduction of shortcut edges can indeed reduce the gap to the MDT to around \qty{1.5}{\%}.

\subsection{Q3: Comparison to state-of-the-art}
\label{sec:experiments-comparison-to-existing}

We compare our approaches to two exact state-of-the-art algorithms for the MDT.
Note that both of these use floating-point arithmetic and are not guaranteed to find the optimal solution.
However, we can confirm that all previous solutions are within a small relative error of our optimal solution.
The first approach is an integer programming (IP) approach by \cite{DBLP:conf/cccg/BrandtGSR14} that used the commercial software CPLEX to solve the MDT. 
The second comparison is with the most recent exact algorithm (BnB) from Sattari~and~Izadi~\cite{DBLP:journals/jgo/SattariI17}.
For both approaches the source code is no longer available, so we cannot compare our results on the same hardware.
Also for BnB~\cite{DBLP:journals/jgo/SattariI17} the instance data and results are no longer available. 
For both approaches we therefore use the data the authors published in their papers. 
Note that the drastic runtime difference that we see in our experiments cannot be attributed to improved hardware alone.

For \emph{random-small}, both \incmdt{} and \binmdt{} outperform the IP and BnB approach by a large margin (up to four orders of magnitude), see~\cref{fig:brandt-runtime}.
All instances were solvable in less than \qty{0.1}{s}.
Additionally, Sattari~and~Izadi~\cite{DBLP:journals/jgo/SattariI17} provided results for TSPLIB~\cite{reinelt1991} instances (part of our \emph{public} instance set) with up to \num{200} points.
\Cref{tab:tsplib-comparison} shows that our approach is faster than the algorithm from Sattari and Izadi.
We can solve instances to provable optimality in less than \qty{1}{s} while their algorithm took up to \qty{1248}{s}.

\subsection{Q4: Algorithm comparison}
\label{sec:experiments-algorithm-comparison}
\begin{figure}
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/04_mdt_comparison/uniform_no_dilations.pdf}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/04_mdt_comparison/uniform_runtimes.pdf}
    \end{subfigure}
    \caption{Experiments on the \emph{random} benchmark set.
             \textbf{(Left)} The number of dilation computations of \binmdt{} is significantly reduced compared to the incremental algorithm.
             \textbf{(Right)} \binmdt{} is significantly faster than the incremental algorithm.}
    \label{fig:experiments-algorithm-comparison}
\end{figure}
\begin{figure}
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/04_mdt_comparison/public_instance_set_runtimes.pdf}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/experiments/04_mdt_comparison/public_instance_set_stretches.pdf}
    \end{subfigure}
    \caption{Experiments on the \emph{public} benchmark set.
             \textbf{(Left)} Using the improved Delaunay triangulation as an initial solution significantly improved the performance.
             \textbf{(Right)} The dilation of the MDTs is at most $\sqrt{2}$ for all instances.}
    \label{fig:experiments-public-instance-set}
\end{figure}

We now compare \incmdt{} to \binmdt{}; see~\cref{sec:appendix-algorithm-comparison} for more detail.
Recall that \binmdt{} aims to reduce the time spent on dilation computations by 
reducing the number of dilation computations and merely sampling the dilation whenever that suffices.
The first experiment was conducted on the \emph{random} instances with up to \num{10000} points;
this experiments confirms that \binmdt{} indeed achieves a significantly lower runtime,
requires fewer dilation computations, and that sampling is sufficient in most cases, see~\cref{fig:experiments-algorithm-comparison}.

After we confirmed that \binmdt{} is superior,
we conducted an additional experiment with two different initial solution strategies on the \emph{public} instances up to \num{10000} points, see~\cref{fig:experiments-public-instance-set}.
The first strategy uses the Delaunay triangulation as an initial solution; the second strategy uses the improved Delaunay triangulation with shortcut edges.
The improved Delaunay triangulation significantly reduces the runtime of \binmdt{} for almost all instances.
Detailed results for all instances of the \emph{public} instance set are shown in~\cref{tab:public-comparison}.
An additional experiment on the \emph{public} instance set shows that \binmdt{} can solve instances with up to \num{30000} points in less than \qty{17}{h} to provable optimality, see~\cref{tab:large-comparison}.

\section{Improved bounds for regular \texorpdfstring{$n$}{n}-gons}\label{sec:n-gon-lb}
Vertex sets of regular $n$-gons are particularly challenging, as there are no points in the
interior to serve as Steiner points for shortcuts, making 
local heuristics less successful. They are also natural candidates for worst-case
dilation, as each diagonal constitutes an obstacle for the separated points.
Thus, they have received considerable
attention~\cite{mulzer2004minimum,DBLP:journals/ijcga/DumitrescuG16,DBLP:journals/comgeo/SattariI19},
with a lower bound of $1.4308$ (see~\cite{DBLP:journals/ijcga/DumitrescuG16}) and an upper bound
of $1.4482$ (see~\cite{DBLP:journals/comgeo/SattariI19})
on their worst-case dilation. 
Improving this gap is an open question posed by~\cite[Problem 1]{DBLP:journals/ijcga/DumitrescuG16}, originating
from~\cite{DBLP:journals/comgeo/BoseS13, DBLP:conf/iccit/Kanj13}.
With the help of our exact algorithm (see~\cref{sec:appendix-n-gons}),
we were able to compute bounds for $n\in\{4,5,\dots,100\}$,
answering the problem by Dumitrescu and Ghosh.

Our implementation currently uses floating-point precision to represent the coordinates of the input points.
Thus, we cannot exactly represent the necessarily irrational points of any regular $n$-gon ($n \geq 5$) in our solver.
However, we can compute the MDT of a rational point set that is a good approximation of a regular $n$-gon.
We can then bound the error and thus obtain a rigorous lower bound on the dilation of the regular $n$-gon.
\begin{theorem}
    Let $P$ be a set of $n = \lbN$ points placed at the vertices of a regular $n$-gon.
    Then the dilation of the MDT of $P$ is $\rho \geq \lbRho$.
\end{theorem}
\begin{proof}
    Let $P$ be the point set of a regular $\lbN$-gon and $Q$ be a point set that contains floating-point approximations of the points of $P$.
    There is a bijection $f: P \to Q$ with inverse $f^{-1}$ that maps each point in $P$ to the closest point in $Q$.
    For a given triangulation or path of $P$, we write $f(\cdot)$ to denote the triangulation or path where the points are transformed by pointwise application of $f$.
    Neither $P$ nor $Q$ contain collinear points and all points are in convex position,
    therefore $T$ is a triangulation of $P$ iff $f(T)$ is a triangulation of $Q$.

    Let $\epsilon \geq \max_{p_i, p_j\in P}|d(p_i,p_j)-d(f(p_i),f(p_j))|$ be a bound on the maximum absolute error on distances and let
    $\delta$ be a chosen such that \[\forall p_i,p_j \in P: (1-\delta)d(p_i, p_j) \leq d(f(p_i), f(p_j)) \leq (1+\delta)d(p_i,p_j).\]

    Let $T$ be the MDT of $P$ with dilation $\rho$.
    Let $f(p_i), f(p_j)$ be a dilation-defining pair in $f(T)$ with path $\pi \subset Q$. 
    Because $T$ has dilation $\rho$, we have (i) $\nicefrac{|f^{-1}(\pi)|}{d(p_i,p_j)} \leq \rho$.
    As $\pi$ has at most $n-1$ edges, we have (ii) $|\pi| - (n-1)\epsilon \leq |f^{-1}(\pi)| \leq |\pi| + (n-1)\epsilon$ and thus the following upper bound on the MDT of $Q$.

    \begin{align*}
        \frac{|\pi|}{d(f(p_i),f(p_j))} = 
        \frac{|\pi| - (n-1)\epsilon}{d(f(p_i), f(p_j))} + \frac{(n-1)\epsilon}{d(f(p_i), f(p_j))} 
        &\overset{(ii)}{\leq}
        \frac{|f^{-1}(\pi)|}{(1-\delta)d(p_i, p_j)} + \frac{((n-1)\epsilon)}{d(f(p_i), f(p_j))} \\
        \overset{(i)}{\leq} \frac{1}{1-\delta}\rho + \frac{(n-1)\epsilon}{d(f(p_i), f(p_j))}
        &\leq \frac{1}{1-\delta}\rho + \frac{(n-1)\epsilon}{\min_{q_i,q_j\in Q}d(q_i,q_j)}.
    \end{align*}
    
    Using exact calculations done with \emph{sympy}, we computed $\epsilon \leq \lbEpsilon $ and $\delta \leq \lbDelta$,
    which, combined with the lower bound on the dilation of $Q$ from our solver gives us $\rho \geq \lbRho$.
\end{proof}
