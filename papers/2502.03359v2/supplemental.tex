
\begin{figure*}[t]
  \centering 
  \includegraphics[width=0.8\textwidth]{figures/data_contam_eccv2024.pdf}
  \Caption[fig:NINCO_Examples]{Misclassified Unknown Samples}{We examined the unknown samples most frequently mispredicted from three OOD datasets: Places \cite{zhou2017places} SUN \cite{xiao2010sun}, and NINCO \cite{bitterwolf2023or}. We merged the 20 most confident samples into collages and created counterparts from the ImageNet 2012 validation set. Both Places and SUN are known to have significant class overlap \cite{bitterwolf2023or}, but NINCO was specifically designed to avoid such issues. We can see NINCO's most confused class merely has a similar background to a known ImageNet class, whereas Places and SUN seemingly have direct overlap. This separation between known and unknown data for ImageNet-1K/NINCO reinforces the significance of our results on NINCO.}
\end{figure*}

\section{Dataset details}

\subsubsection{ImageNet}
ImageNet-2012 \cite{ILSVRC15} consists of 1000 classes, each with up to 1600 images in training and 50 images in validation.
Images were collected from internet search queries and verified through Amazon Mechanical Turk. 
ImageNet classes largely consist of animals, manufactured artifacts, and some natural structures, foods, and plants. 
Many Images are taken from a person-level perspective and, due to the nature of internet-based harvesting, collected from various sources, locations, and cameras. 
The diverse large-scale nature of this dataset has made it central to image recognition; it has become a common benchmark for new networks. 
We utilize ImageNet-2012 as our knowns dataset because, in addition to its scale and complexity, many pre-trained models are available, allowing us to compare performance across various networks.

\subsubsection{Datasets from OOD Literature}
We utilize a recent purpose-built OOD dataset, NINCO: No ImageNet Class Objects \cite{bitterwolf2023or}, that was built from images that specifically exclude any semantically overlapping or background ImageNet objects.
While NINCO is not as large as ImageNet-2012 val, its authors took extensive measures to reduce data contamination.
We also utilize OpenImage-O \cite{wang2022vim}, a dataset constructed from a public image database.
We present results on other, older OOD datasets in which NINCO alleged contamination as part of an extended evaluation.

\subsubsection{Datasets from OSR Literature}
\label{sec:datasets}
ImageNet 21K-P \emph{Easy}/\emph{Hard} Open-Set Splits were proposed by Vaze \etal{vaze2022openset} in their semantic shift benchmark. 
Each split contains 50K images from ImageNet-21K \cite{ridnik2021}, and base classes were selected using semantic WordNet distance from ImageNet-1K.
We do not utilize the other semantic shift splits proposed by \cite{vaze2022openset}, as they are small-scale and would require retraining networks.

\section{Statistical Analysis and Additional Datasets}

We perform statistical testing by sampling each dataset (and the val set) 10 times, selecting 1000 knowns and unknowns.   
We use paired two-tailed t-tests to evaluate the statistical significance of each method's performance compared to GHOST. 
We find statistical significance across the board, except on SUN and Places, when GHOST was compared to MSC see \tab{full_auroc_sig}.

\begin{table*}[p]
\Caption[tab:full_auroc_sig]{Statistical Significance Evaluation}{AUROC paired t-tests results on OOD and OSR datasets specified in the main paper and additional OOD datasets SUN, iNaturalist, Textures, Places using MAE-H or ConvNeXtV2-H as the pretrained network. P-values are from two-sided paired t-test, with Bonferroni corrections,  for rejecting the null hypothesis that the given algorithm performance is the same as GHOST. }\centering
\subfloat[MAE-H]{
\begin{tabular}{lll|l|l|l|l}
             &                                    & GHOST & MSC                    & MaxLogit               & NNGuide         & Energy           \\ \cline{2-7} 
NINCO        & \multicolumn{1}{l|}{Mean}          & 0.900 & 0.825                  & 0.782                  & 0.543           & 0.738            \\
             & \multicolumn{1}{l|}{STD}           & 0.004 & 0.008                  & 0.009                  & 0.008           & 0.009            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 6.838e-12              & 3.241e-12              & 2.48e-15        & 9.790e-13        \\ \hline
OpenImage\_O & \multicolumn{1}{l|}{Mean}          & 0.956 & 0.874                  & 0.822                  & 0.772           & 0.771            \\
             & \multicolumn{1}{l|}{STD}           & 0.005 & 0.010                  & 0.010                  & 0.011           & 0.013            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 4.564e-10              & 2.178e-12              & 4.4605e-13      & 2.133e-12        \\ \hline
Places       & \multicolumn{1}{l|}{Mean}          & 0.830 & 0.823                  & 0.756                  & 0.803           & 0.694            \\
             & \multicolumn{1}{l|}{STD}           & 0.009 & 0.009                  & 0.011                  & 0.009           & 0.012            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 0.003                  & 1.212e-10              & 0.0001          & 5.142e-12        \\ \hline
SUN          & \multicolumn{1}{l|}{Mean}          & 0.851 & 0.835                  & 0.784                  & 0.804           & 0.733            \\
             & \multicolumn{1}{l|}{STD}           & 0.009 & 0.009                  & 0.012                  & 0.012           & 0.013            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 0.0002                 & 7.805e-10              & 9.106e-07       & 1.038e-11        \\ \hline
Textures     & \multicolumn{1}{l|}{Mean}          & 0.916 & 0.868                  & 0.857                  & 0.505           & 0.842            \\
             & \multicolumn{1}{l|}{STD}           & 0.004 & 0.008                  & 0.008                  & 0.004           & 0.008            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 3.491e-09              & 7.601e-10              & 6.722e-19       & 8.784e-11        \\ \hline
easy\_21k    & \multicolumn{1}{l|}{Mean}          & 0.837 & 0.796                  & 0.747                  & 0.694           & 0.701            \\
             & \multicolumn{1}{l|}{STD}           & 0.011 & 0.009                  & 0.012                  & 0.011           & 0.011            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 1.480e-08              & 1.798e-10              & 5.0781e-11      & 8.432e-12        \\ \hline
hard\_21k    & \multicolumn{1}{l|}{Mean}          & 0.812 & 0.748                  & 0.717                  & 0.522           & 0.683            \\
             & \multicolumn{1}{l|}{STD}           & 0.012 & 0.010                  & 0.009                  & 0.013           & 0.007            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 7.909e-10              & 6.672e-11              & 9.607e-14       & 2.880e-11        \\ \hline
iNaturalist  & \multicolumn{1}{l|}{Mean}          & 0.971 & 0.910                  & 0.889                  & 0.759           & 0.848            \\
             & \multicolumn{1}{l|}{STD}           & 0.004 & 0.007                  & 0.007                  & 0.008           & 0.006            \\
             & \multicolumn{1}{l|}{P-Value}       &       & 3.412e-12              & 3.286e-13              & 9.297e-15       & 1.664e-14 
\end{tabular}
}

\subfloat[ConvNeXtV2-H]{
\begin{tabular}{lll|l|l|l|l}
             &                                      & GHOST                  & MSC                    & MaxLogit               & NNGuide        & Energy         \\ \cline{2-7} 
NINCO        & \multicolumn{1}{l|}{Mean}            & 0.887                  & 0.828                  & 0.816                  & 0.737          & 0.800          \\
             & \multicolumn{1}{l|}{STD}             & 0.004                  & 0.005                  & 0.005                  & 0.009          & 0.006          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 4.057e-11              & 2.233e-10              & 6.248e-13      & 1.580e-10      \\ \hline
OpenImage\_O & \multicolumn{1}{l|}{Mean}            & 0.940                  & 0.884                  & 0.869                  & 0.830          & 0.849          \\
             & \multicolumn{1}{l|}{STD}             & 0.004                  & 0.006                  & 0.007                  & 0.007          & 0.007          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 1.552e-11              & 4.927e-12              & 6.118e-12      & 1.051e-11      \\ \hline
Places       & \multicolumn{1}{l|}{Mean}            & 0.827                  & 0.832                  & 0.789                  & 0.830          & 0.757          \\
             & \multicolumn{1}{l|}{STD}             & 0.008                  & 0.007                  & 0.008                  & 0.009          & 0.009          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 0.003                  & 1.219e-08              & 0.349          & 9.834e-11      \\ \hline
SUN          & \multicolumn{1}{l|}{Mean}            & 0.847                  & 0.846                  & 0.810                  & 0.845          & 0.779          \\
             & \multicolumn{1}{l|}{STD}             & 0.014                  & 0.012                  & 0.012                  & 0.005          & 0.012          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 0.494                  & 9.629e-08              & 0.646          & 1.002e-08      \\ \hline
Textures     & \multicolumn{1}{l|}{Mean}            & 0.892                  & 0.869                  & 0.876                  & 0.757          & 0.875          \\
             & \multicolumn{1}{l|}{STD}             & 0.006                  & 0.007                  & 0.008                  & 0.011          & 0.008          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 5.443e-08              & 1.908e-06              & 5.265e-10      & 4.378e-07      \\ \hline
easy\_21k    & \multicolumn{1}{l|}{Mean}            & 0.823                  & 0.791                  & 0.749                  & 0.789          & 0.718          \\
             & \multicolumn{1}{l|}{STD}             & 0.010                  & 0.009                  & 0.011                  & 0.007          & 0.013          \\
             & \multicolumn{1}{l|}{P-Value}         & 1.012e-06              & 7.497e-11              & 8.210e-07              &                & 5.304e-12      \\ \hline
hard\_21k    & \multicolumn{1}{l|}{Mean}            & 0.797                  & 0.736                  & 0.707                  & 0.674          & 0.685          \\
             & \multicolumn{1}{l|}{STD}             & 0.006                  & 0.009                  & 0.012                  & 0.013          & 0.013          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 6.759e-10              & 2.797e-10              & 3.891e-09      & 9.324e-11      \\ \hline
iNaturalist  & \multicolumn{1}{l|}{Mean}            & 0.965                  & 0.911                  & 0.901                  & 0.882          & 0.881          \\
             & \multicolumn{1}{l|}{STD}             & 0.005                  & 0.005                  & 0.003                  & 0.007          & 0.003          \\
             & \multicolumn{1}{l|}{P-Value}         &                        & 1.270e-10              & 1.480e-11              & 3.513e-11      & 2.035e-11
\end{tabular}
}
\end{table*}








\section{Normality Testing and Z-Score Plots}
\label{shapiro}
We conducted further statistical tests on raw features per-class per-dimension for normality. 
This involved 1,280,000 tests (1280 feature dimensions x 1000 classes) for MAE-H. 
We used the Shapiro-Wilk test for normality and Holm's step-down procedure for Family-wise error control. 
For MAE-H and ConvNeXtV2-H, only 2.79\% and 3.13\% of distributions rejected the null hypothesis (normality), as expected with 95\% confidence. 
Despite different architectures, both networks use autoencoder training. 
To better test effectiveness beyond these networks, we examined two additional influential networks using torchvision ImageNet-1K weights. 
Tests on Swin-T and DenseNet-121 rejected normality 0.56\% and 8.27\% of the distributions indicating the Gaussian assumption does not hold for every network. 
We believe the Shapiro-Wilks test (with Holm's step-down procedure) is a straight-forward method for determining if GHOST should be applied to a given DNN for OSR and urge end-users to investigate their target architecture before applying GHOST.
To this end, we include the code for running this test (and procedure) with our codebase for the convenience of GHOST's end-users.
We provide some insights into the performance of GHOST on DenseNet in a later section (Results on Additional Networks).

\section{OpenOOD}
\label{sec:openood}
We run GHOST on the OpenOOD large-scale ImageNet-1K benchmark.
We consistently find performance on Near-OOD better than Far-OOD tasks across two different networks.
ViT-B-16 achieves an AUROC of 80.83 and 90.75 for Near/Far OOD respectively.
Swin-T achieves an AUROC of 84.97 and 91.09 on Near/Far OOD.
These results show GHOST performs superior to other post-hoc algorithms in Near-OOD using the same backbones. 



\section{Results on Additional Networks and Methods}
\label{additional_networks}
We present results on additional networks in \tab{sup_global_metrics} and \tab{coeff-f95c}.
We note the poor performance on DenseNet-121 compared to the other networks we tested.
We find the decrease in performance is consistent with the Shapiro-Wilks statistical testing in \ref{shapiro}, which revealed that 8\% of per-class feature dimensions are not Gaussian for Densenet. 
Further, we recognize that out of MAE-H, ConvNeXtV2-H, Swin-T and DenseNet-121, DenseNet has the lowest closed-set accuracy, with a performance gap of 7\% to the nearest network accuracy. 
Additionally, we note that NNGuide's performance is dramatically worse than on other networks, which may be related to the drop in accuracy.
We leave exploring the relation between Gaussian features and network accuracy to future work.

We want to emphasize, however, even with DenseNet's sub-par accuracy, GHOST maintains a much lower coefficient of  variance than other methods, showing that GHOST's superior fairness still holds, even with a much worse base network.

We also present results from additional OOD post-processors SCALE \cite{xu2024scaling}, REACT \cite{sun2021react}, and KNN \cite{sun2022out} in \tab{sup_global_metrics}. 
For REACT, we found the found the feature activation clipping threshold using the train set rather than using the test set (as the original publication did) for fairness.
While KNN and REACT sometimes perform better than GHOST on the 21K-P Easy dataset, NINCO, the dataset built to avoid overlap with imagenet, still shows GHOST exhibits dramatic performance gains over other methods.
Additionally, paired t-tests reveal GHOST's performance is statistically significantly better across all datasets and both networks when compared with REACT, with P-Values of <0.0135, <0.0066 and <0.047 for AUOSCR, AUROC, and FPR95.
Similarly, GHOST's performance against KNN is statistically significantly better in terms of AUOSCR and AUROC, with P-Values of <0.0285 and <0.0363.
However, GHOST is slightly significantly worse than KNN in terms of FPR95, with a P-Value of <0.047.
\begin{table*}[tp]
\centering
\small
\Caption[tab:sup_global_metrics]{Quantitative Results}{We present quantitative results using AUOSCR, AUROC and FPR95 on four different pre-trained networks. We use the ImageNet-1K-trained checkpoint provided by torchvision or the official checkpoints provided by authors. For MAE-H and ConvNeXtV2-H we present results from additional post-processors SCALE \cite{xu2024scaling}, REACT \cite{sun2021react}, and KNN \cite{sun2022out}.}

\subfloat[Swin-T]{
\resizebox{\linewidth}{!}{
\begin{tabular}{l?ccccc}
\multicolumn{1}{c?}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Unknowns\\ \end{tabular}}}} & \multicolumn{5}{c}{\textbf{$\uparrow$ AUOSCR}  \textbf{$\uparrow$ AUROC} \textbf{$\downarrow$ FPR95}} \\ \cline{2-6} 
%\multicolumn{1}{c?}{} & \multicolumn{5}{c}{\textbf{Swin-T}} \\ \cline{2-6} 
\multicolumn{1}{c?}{} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{GHOST} (ours)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MSP} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MaxLogit} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{NNGuide} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Energy} \end{tabular}} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy} & \multicolumn{1}{c|}{$\uparrow$ 0.67 $\uparrow$ \textbf{0.78} $\downarrow$ \textbf{0.72}} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.68} $\uparrow$ \textbf{0.78} $\downarrow$ 0.71} & \multicolumn{1}{c|}{$\uparrow$ 0.64 $\uparrow$  0.74 $\downarrow$ 0.71} & \multicolumn{1}{c|}{$\uparrow$ 0.56 $\uparrow$ 0.66 $\downarrow$ 0.93} & \multicolumn{1}{c}{$\uparrow$ 0.59 $\uparrow$ 0.70 $\downarrow$ 0.77} \\
21K-P \emph{Hard} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.65} $\uparrow$ \textbf{0.76} $\downarrow$ \textbf{0.77}} & \multicolumn{1}{c|}{$\uparrow$ 0.64 $\uparrow$ 0.72 $\downarrow$ 0.83} & \multicolumn{1}{c|}{$\uparrow$ 0.62 $\uparrow$  0.70 $\downarrow$ 0.82} & \multicolumn{1}{c|}{$\uparrow$ 0.39 $\uparrow$ 0.45 $\downarrow$ 0.97} & \multicolumn{1}{c}{$\uparrow$ 0.58 $\uparrow$ 0.68 $\downarrow$ 0.83} \\
NINCO & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.72} $\uparrow$ \textbf{0.85} $\downarrow$ \textbf{0.66}} & \multicolumn{1}{c|}{$\uparrow$ 0.71 $\uparrow$ 0.82 $\downarrow$ 0.71} & \multicolumn{1}{c|}{$\uparrow$ 0.69 $\uparrow$  0.81 $\downarrow$ 0.68} & \multicolumn{1}{c|}{$\uparrow$ 0.41 $\uparrow$ 0.47 $\downarrow$ 0.98} & \multicolumn{1}{c}{$\uparrow$ 0.66 $\uparrow$ 0.78 $\downarrow$ 0.71} \\
OpenImage-O & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.77} $\uparrow$ \textbf{0.91} $\downarrow$ \textbf{0.48}} & \multicolumn{1}{c|}{$\uparrow$ 0.74 $\uparrow$ 0.86 $\downarrow$ 0.61} & \multicolumn{1}{c|}{$\uparrow$ 0.71 $\uparrow$  0.84 $\downarrow$ 0.59} & \multicolumn{1}{c|}{$\uparrow$ 0.55 $\uparrow$ 0.64 $\downarrow$ 0.95} & \multicolumn{1}{c}{$\uparrow$ 0.67 $\uparrow$ 0.80 $\downarrow$ 0.65} \\
\end{tabular}}}

%\Caption[tab:dense_sup_overall_metrics]{DenseNet-121 Quantitative Results}{We present quantitative results using AUOSCR, AUROC and FPR95 on DenseNet-121. We use the ImageNet-1K-trained checkpoint provided by torchvision.}
\subfloat[DenseNet-121]{
\resizebox{\linewidth}{!}{
\begin{tabular}{l?ccccc}
\multicolumn{1}{c?}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Unknowns\\ \end{tabular}}}} & \multicolumn{5}{c}{\textbf{$\uparrow$ AUOSCR}  \textbf{$\uparrow$ AUROC} \textbf{$\downarrow$ FPR95}} \\ \cline{2-6} 
%\multicolumn{1}{c?}{} & \multicolumn{5}{c}{\textbf{DenseNet-121}} \\ \cline{2-6} 
\multicolumn{1}{c?}{} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{GHOST} (ours)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MSP} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MaxLogit} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{NNGuide} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Energy} \end{tabular}} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy} & \multicolumn{1}{c|}{$\uparrow$ 0.61 $\uparrow$ 0.77 $\downarrow$ 0.75} & \multicolumn{1}{c|}{$\uparrow$ 0.63 $\uparrow$ 0.77 $\downarrow$ 0.76} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.64} $\uparrow$  \textbf{0.79} $\downarrow$ \textbf{0.74}} & \multicolumn{1}{c|}{$\uparrow$ 0.17 $\uparrow$ 0.27 $\downarrow$ 0.99} & \multicolumn{1}{c}{$\uparrow$ 0.63 $\uparrow$ \textbf{0.79} $\downarrow$ \textbf{0.74}} \\
21K-P \emph{Hard} & \multicolumn{1}{c|}{$\uparrow$ 0.58 $\uparrow$ \textbf{0.72} $\downarrow$ \textbf{0.85}} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.60} $\uparrow$ 0.71 $\downarrow$ 0.87} & \multicolumn{1}{c|}{$\uparrow$ 0.57 $\uparrow$  0.70 $\downarrow$ 0.87} & \multicolumn{1}{c|}{$\uparrow$ 0.20 $\uparrow$ 0.32 $\downarrow$ 1.00} & \multicolumn{1}{c}{$\uparrow$ 0.56 $\uparrow$ 0.69 $\downarrow$ 0.87}  \\
NINCO & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.65} $\uparrow$ \textbf{0.82} $\downarrow$ \textbf{0.74}} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.65} $\uparrow$ 0.79 $\downarrow$ 0.77} & \multicolumn{1}{c|}{$\uparrow$ 0.64 $\uparrow$  0.79 $\downarrow$ 0.77} & \multicolumn{1}{c|}{$\uparrow$ 0.16 $\uparrow$ 0.25 $\downarrow$ 1.00} & \multicolumn{1}{c}{$\uparrow$ 0.63 $\uparrow$ 0.79 $\downarrow$ 0.77} \\
OpenImage-O & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.69} $\uparrow$ \textbf{0.89} $\downarrow$ \textbf{0.56}} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.84 $\downarrow$ 0.67} & \multicolumn{1}{c|}{$\uparrow$ 0.69 $\uparrow$  0.88 $\downarrow$ 0.58} & \multicolumn{1}{c|}{$\uparrow$ 0.09 $\uparrow$ 0.15 $\downarrow$ 1.00} & \multicolumn{1}{c}{$\uparrow$ 0.69 $\uparrow$ 0.88 $\downarrow$ 0.57}  \\
\end{tabular}}}

%\Caption[tab:mae_sup_overall_metrics]{MAE-H Quantitative Results}{We present quantitative results using AUOSCR, AUROC and FPR95 on MAE-H. We use the official checkpoint provided by MAE's authors.}
\subfloat[MAE-H]{
\resizebox{\linewidth}{!}{
\begin{tabular}{l?cccccccc}
\multicolumn{1}{c?}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Unknowns\\ \end{tabular}}}} & \multicolumn{6}{c}{\textbf{$\uparrow$ AUOSCR}  \textbf{$\uparrow$ AUROC} \textbf{$\downarrow$ FPR95}} \\ \cline{2-9} 
%\multicolumn{1}{c?}{} & \multicolumn{6}{c}{\textbf{MAE-H}} \\ \cline{2-7} 
\multicolumn{1}{c?}{} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{GHOST} (ours)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MSP} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MaxLogit} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{NNGuide} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{Energy} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{SCALE} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{REACT} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{KNN} \end{tabular}}\\

\noalign{\hrule height 1.5pt}

21K-P \emph{Easy} & \multicolumn{1}{c|}{$\uparrow$ 0.75 $\uparrow$ 0.84 $\downarrow$ 0.58} & \multicolumn{1}{c|}{$\uparrow$ .0.72 $\uparrow$ .0.79 $\downarrow$ 0.65} & \multicolumn{1}{c|}{$\uparrow$ 0.67 $\uparrow$  0.75 $\downarrow$ 0.63} & \multicolumn{1}{c|}{$\uparrow$ 0.62 $\uparrow$ 0.69 $\downarrow$ 0.80} & \multicolumn{1}{c|}{$\uparrow$ 0.63 $\uparrow$ 0.70 $\downarrow$ 0.70} & \multicolumn{1}{c|}{$\uparrow$ 0.59 $\uparrow$ 0.66 $\downarrow$ 0.73} & \multicolumn{1}{c|}{$\uparrow$ 0.75 $\uparrow$ 0.84 $\downarrow$ 0.55} & \multicolumn{1}{c}{$\uparrow$ \textbf{0.77} $\uparrow$ \textbf{0.86} $\downarrow$ \textbf{0.52}}\\

21K-P \emph{Hard} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.73} $\uparrow$ \textbf{0.81} $\downarrow$ \textbf{0.62}} & \multicolumn{1}{c|}{$\uparrow$ .0.69 $\uparrow$ .0.75 $\downarrow$ 0.75} & \multicolumn{1}{c|}{$\uparrow$ 0.65 $\uparrow$  0.71 $\downarrow$ 0.74} & \multicolumn{1}{c|}{$\uparrow$ 0.47 $\uparrow$ 0.52 $\downarrow$ 0.89} & \multicolumn{1}{c|}{$\uparrow$ 0.61 $\uparrow$ 0.68 $\downarrow$ 0.79} & \multicolumn{1}{c|}{$\uparrow$ 0.59 $\uparrow$ 0.66 $\downarrow$ 0.80} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.75 $\downarrow$ 0.73} & \multicolumn{1}{c}{$\uparrow$ 0.63 $\uparrow$ 0.70 $\downarrow$ 0.80} \\

NINCO & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.81} $\uparrow$ \textbf{0.91} $\downarrow$ \textbf{0.47}} & \multicolumn{1}{c|}{$\uparrow$ .0.76 $\uparrow$ .0.83 $\downarrow$ 0.65} & \multicolumn{1}{c|}{$\uparrow$ 0.71 $\uparrow$  0.79 $\downarrow$ 0.62} & \multicolumn{1}{c|}{$\uparrow$ 0.49 $\uparrow$ 0.55 $\downarrow$ 0.88} & \multicolumn{1}{c|}{$\uparrow$ 0.66 $\uparrow$ 0.74 $\downarrow$ 0.69} & \multicolumn{1}{c|}{$\uparrow$ 0.63 $\uparrow$ 0.71 $\downarrow$ 0.71} & \multicolumn{1}{c|}{$\uparrow$ 0.77 $\uparrow$ 0.86 $\downarrow$ 0.57} & \multicolumn{1}{c}{$\uparrow$ 0.75 $\uparrow$ 0.84 $\downarrow$ 0.64} \\

OpenImage-O & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.84} $\uparrow$ \textbf{0.95} $\downarrow$ \textbf{0.26}} & \multicolumn{1}{c|}{$\uparrow$ .0.78 $\uparrow$ .0.87 $\downarrow$ 0.52} & \multicolumn{1}{c|}{$\uparrow$ 0.73 $\uparrow$  0.82 $\downarrow$ 0.49} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.77 $\downarrow$ 0.64} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.77 $\downarrow$ 0.56} & \multicolumn{1}{c|}{$\uparrow$ 0.65 $\uparrow$ 0.73 $\downarrow$ 0.62} & \multicolumn{1}{c|}{$\uparrow$ 0.83 $\uparrow$ 0.93 $\downarrow$ 0.34} & \multicolumn{1}{c}{$\uparrow$ 0.83 $\uparrow$ 0.94 $\downarrow$ 0.30}\\
\end{tabular}}}

%\Caption[tab:conv_sup_overall_metrics]{ConvNextV2-H Quantitative Results}{We present quantitative results using AUOSCR, AUROC and FPR95 on ConvNeXtV2-H. We use the official checkpoint provided by ConvNextV2-H authors.}
\subfloat[ConvNextV2-H]{
\resizebox{\linewidth}{!}{
\begin{tabular}{l?cccccccc}
\multicolumn{1}{c?}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Unknowns\\ \end{tabular}}}} & \multicolumn{6}{c}{\textbf{$\uparrow$ AUOSCR}  \textbf{$\uparrow$ AUROC} \textbf{$\downarrow$ FPR95}} \\ \cline{2-9} 
%\multicolumn{1}{c?}{} & \multicolumn{6}{c}{\textbf{ConvNextV2-H}} \\ \cline{2-7} 
\multicolumn{1}{c?}{} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{GHOST} (ours)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MSP} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{MaxLogit} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{NNGuide} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{Energy} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{SCALE} \end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}\textbf{REACT} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{KNN} \end{tabular}}\ \\
\noalign{\hrule height 1.5pt}
21K-P \emph{Easy} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.74} $\uparrow$ 0.83 $\downarrow$ 0.60} & \multicolumn{1}{c|}{$\uparrow$ 0.72 $\uparrow$ 0.79 $\downarrow$ 0.65} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$  0.75 $\downarrow$ 0.64} & \multicolumn{1}{c|}{$\uparrow$ 0.70 $\uparrow$ 0.79 $\downarrow$ 0.70} & \multicolumn{1}{c|}{$\uparrow$ 0.64 $\uparrow$ 0.72 $\downarrow$ 0.69} & \multicolumn{1}{c|}{$\uparrow$ 0.58 $\uparrow$ 0.66 $\downarrow$ 0.81} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.74} $\uparrow$ 0.83 $\downarrow$ 0.56} & \multicolumn{1}{c}{$\uparrow$ \textbf{0.74} $\uparrow$ \textbf{0.84} $\downarrow$ \textbf{0.53}} \\

21K-P \emph{Hard} & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.72} $\uparrow$ \textbf{0.80} $\downarrow$ \textbf{0.65}} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.74 $\downarrow$ 0.76} & \multicolumn{1}{c|}{$\uparrow$ 0.65 $\uparrow$  0.72 $\downarrow$ 0.74} & \multicolumn{1}{c|}{$\uparrow$ 0.60 $\uparrow$ 0.67 $\downarrow$ 0.83} & \multicolumn{1}{c|}{$\uparrow$ 0.62 $\uparrow$ 0.69 $\downarrow$ 0.78} & \multicolumn{1}{c|}{$\uparrow$ 0.55 $\uparrow$ 0.62 $\downarrow$ 0.87} & \multicolumn{1}{c|}{$\uparrow$ 0.69 $\uparrow$ 0.75 $\downarrow$ 0.72} & \multicolumn{1}{c}{$\uparrow$ 0.58 $\uparrow$ 0.65 $\downarrow$ 0.81} \\

NINCO & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.79} $\uparrow$ \textbf{0.89} $\downarrow$ \textbf{0.50}} & \multicolumn{1}{c|}{$\uparrow$ 0.75 $\uparrow$ 0.83 $\downarrow$ 0.64} & \multicolumn{1}{c|}{$\uparrow$ 0.73 $\uparrow$  0.82 $\downarrow$ 0.60} & \multicolumn{1}{c|}{$\uparrow$ 0.66 $\uparrow$ 0.74 $\downarrow$ 0.78} & \multicolumn{1}{c|}{$\uparrow$ 0.71 $\uparrow$ 0.80 $\downarrow$ 0.63} & \multicolumn{1}{c|}{$\uparrow$ 0.55 $\uparrow$ 0.62 $\downarrow$ 0.86} & \multicolumn{1}{c|}{$\uparrow$ 0.78 $\uparrow$ 0.87 $\downarrow$ 0.53} & \multicolumn{1}{c}{$\uparrow$ 0.70 $\uparrow$ 0.80 $\downarrow$ 0.67} \\

OpenImage-O & \multicolumn{1}{c|}{$\uparrow$ \textbf{0.83} $\uparrow$ \textbf{0.94} $\downarrow$ \textbf{0.32}} & \multicolumn{1}{c|}{$\uparrow$ 0.79 $\uparrow$ 0.88 $\downarrow$ 0.49} & \multicolumn{1}{c|}{$\uparrow$ 0.77 $\uparrow$  0.87 $\downarrow$ 0.44} & \multicolumn{1}{c|}{$\uparrow$ 0.74 $\uparrow$ 0.83 $\downarrow$ 0.64} & \multicolumn{1}{c|}{$\uparrow$ 0.75 $\uparrow$ 0.85 $\downarrow$ 0.47} & \multicolumn{1}{c|}{$\uparrow$ 0.68 $\uparrow$ 0.77 $\downarrow$ 0.69} & \multicolumn{1}{c|}{$\uparrow$ 0.82 $\uparrow$ 0.92 $\downarrow$ 0.34} & \multicolumn{1}{c}{$\uparrow$ 0.80 $\uparrow$ 0.92 $\downarrow$ 0.38} \\

\end{tabular}}}
\end{table*}



\begin{table*}[t!]
\centering
\small
\Caption[tab:coeff-f95c]{Coefficient of Variance and F@C95 Results}{This table includes the unfairness measure ${\cal V}_{\mathrm{CCR}}$ coefficients ($\downarrow$) of all methods, as well as the corresponding minimum FPR at 95\% of closed set accuracy ($\downarrow$). Each is computed on three pre-trained networks at 10\% FPR and evaluated on various unknown datasets.}
\subfloat[Swin-T Coefficient of Variance]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|cc@{}}
\textbf{Unknowns} & \textbf{GHOST} & \textbf{MSP} & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy}\\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.37}  & 0.52    & 0.59      & 1.13   & 0.69 \\
21K-P \emph{Hard}  & \textbf{0.39}  & 0.56    & 0.55      & 2.87   & 0.61 \\
NINCO              & \textbf{0.26}  & 0.45        & 0.36          & 2.42       & 0.40  \\
OpenImage-O        & \textbf{0.22}  & 0.39  & 0.33    & 1.25 & 0.39  
\end{tabular}}}\quad
%\Caption[tab:swin-sup-fatc]{Swin-T FPR@ 95\% Closed Set Accuracy}{The corresponding minimum FPR at 95\% of closed set accuracy ($\downarrow$). Each method's results are computed on a pre-trained Swin-T.}
\subfloat[Swin-T F@C95]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|cc@{}}
\textbf{Unknowns}  & \textbf{GHOST} & \textbf{MSP}         & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & 0.57  & \textbf{0.53}    & 0.56      & 0.92   & 0.68  \\
21K-P \emph{Hard}  & \textbf{0.63}  & 0.67    & 0.68      & 0.97   & 0.75  \\
NINCO              & \textbf{0.49}  & 0.50        & 0.50          & 0.97       & 0.60  \\
OpenImage-O        & \textbf{0.31}  & 0.39  & 0.40    & 0.94 & 0.54  
\end{tabular}}}

%\Caption[tab:dense-sup-cov]{DenseNet-121 Coefficient of Variance}{The unfairness measure ${\cal V}_{\mathrm{CCR}}$ coefficients ($\downarrow$) of all methods. Each is computed on a pre-trained DenseNet-121 at 10\% FPR and evaluated on various unknown datasets.}
\subfloat[DenseNet-121 Coefficient of Variance]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|cc@{}}
\textbf{Unknowns} & \textbf{GHOST} & \textbf{MSP} & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} &  \textbf{}\\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.38}  & 0.59    & 0.51      & 2.91   & 0.51  \\
21K-P \emph{Hard}  & \textbf{0.42}  & 0.71    & 0.65      & 2.21   & 0.66  \\
NINCO              & \textbf{0.32}  & 0.51        & 0.49          & 3.72       & 0.50   \\
OpenImage-O        & \textbf{0.28}  & 0.44  & 0.35    & 8.48 & 0.35 
\end{tabular}}}\quad
%\Caption[tab:dense-sup-fatc]{DenseNet-121 FPR@ 95\% Closed Set Accuracy}{The corresponding minimum FPR at 95\% of closed set accuracy ($\downarrow$). Each method's results are computed on a pre-trained DenseNet-121.}
\subfloat[DenseNet-121 F@C95]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|cc@{}}
\textbf{Unknowns}  & \textbf{GHOST} & \textbf{MSP}         & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} & \textbf{} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & 0.59  & \textbf{0.54}    & 0.55      & 0.99   & \textbf{0.59}  \\
21K-P \emph{Hard}  & \textbf{0.71}  & 0.68    & 0.73      & 1.00   & 0.76  \\
NINCO              & \textbf{0.55}  & 0.53        & 0.58          & 1.00      & 0.62    \\
OpenImage-O        & \textbf{0.35}  & 0.41  & 0.35    & 1.00 & 0.38  
\end{tabular}}}

%\Caption[tab:mae-sup-cov]{MAE-H Coefficient of Variance}{The unfairness measure ${\cal V}_{\mathrm{CCR}}$ coefficients ($\downarrow$) of all methods. Each is computed on a pre-trained MAE-H at 10\% FPR and evaluated on various unknown datasets.}
\subfloat[MAE-H Coefficient of Variance]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|c|c@{}}
\textbf{Unknowns} & \textbf{GHOST} & \textbf{MSP} & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} &  \textbf{SCALE}\\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.32}  & 0.55    & 0.68      & 1.35   & 0.83 & 1.30 \\
21K-P \emph{Hard}  & \textbf{0.35}  & 0.60    & 0.61      & 2.28   & 0.69 & 1.09 \\
NINCO              & \textbf{0.21}  & 0.45        & 0.50         & 2.18       & 0.68 & 1.09   \\
OpenImage-O        & \textbf{0.17}  & 0.38  & 0.52    & 1.16 & 0.82  & 1.21
\end{tabular}}}\quad
%\Caption[tab:mae-sup-fatc]{MAE-H FPR@ 95\% Closed Set Accuracy}{The corresponding minimum FPR at 95\% of closed set accuracy ($\downarrow$). Each method's results are computed on a pre-trained MAE-H.}
\subfloat[MAE-H F@C95]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|c|c@{}}
\textbf{Unknowns}  & \textbf{GHOST} & \textbf{MSP}         & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} & \textbf{SCALE} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.48}  & 0.53    & 0.54      & 0.76   & 0.65 & 0.69 \\
21K-P \emph{Hard}  & \textbf{0.53}  & 0.64    & 0.64      & 0.86   & 0.74 & 0.77 \\
NINCO              & \textbf{0.35}  & 0.51        & 0.51          & 0.86       & 0.62 & 0.66   \\
OpenImage-O        & \textbf{0.17}  & 0.39  & 0.39    & 0.60 & 0.50  & 0.58
\end{tabular}}}

%\Caption[tab:conv-sup-cov]{ConvNeXtV2-H Coefficient of Variance}{The unfairness measure ${\cal V}_{\mathrm{CCR}}$ coefficients ($\downarrow$) of all methods. Each is computed on a pre-trained ConvNeXtV2-H at 10\% FPR and evaluated on various unknown datasets.}
\subfloat[ConvNeXtV2-H Coefficient of Variance]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|c|c@{}}
\textbf{Unknowns} & \textbf{GHOST} & \textbf{MSP} & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} &  \textbf{SCALE}\\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.36}  & 0.59    & 0.64      & 0.92   & 0.70 & 1.39 \\
21K-P \emph{Hard}  & \textbf{0.42}  & 0.65    & 0.61      & 1.34   & 0.64 & 1.43 \\
NINCO              & \textbf{0.24}  & 0.46        & 0.40          & 1.06       & 0.41 & 1.52   \\
OpenImage-O        & \textbf{0.19}  & 0.36  & 0.34    & 0.72 & 0.34  & 0.92
\end{tabular}}}\quad
%\Caption[tab:conv-sup-fatc]{ConvNeXtV2-H FPR@ 95\% Closed Set Accuracy}{The corresponding minimum FPR at 95\% of closed set accuracy ($\downarrow$). Each method's results are computed on a pre-trained ConvNextV2-H. }
\subfloat[ConvNeXtV2-H F@C95]{
\resizebox{.48\linewidth}{!}{
\begin{tabular}{@{}l?c|c|c|c|c|c@{}}
\textbf{Unknowns}  & \textbf{GHOST} & \textbf{MSP}         & \textbf{MaxLogit} & \textbf{NNGuide} & \textbf{Energy} & \textbf{SCALE} \\ \noalign{\hrule height 1.5pt}
21K-P \emph{Easy}  & \textbf{0.49}  & 0.53    & 0.53      & 0.63   & 0.62 & 0.79 \\
21K-P \emph{Hard}  & \textbf{0.55}  & 0.64    & 0.63      & 0.79   & 0.72 & 0.85 \\
NINCO              & \textbf{0.37}  & 0.51        & 0.46          & 0.73       & 0.54 & 0.84   \\
OpenImage-O        & \textbf{0.20}  & 0.36  & 0.32    & 0.56 & 0.40 & 0.66
\end{tabular}}}
\end{table*}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/convnextv2_H_z_scores_sample_log_line.pdf}
  %  \includegraphics[width=.95\linewidth]{figures/mae_H Z_scores per-sample log.png}
  \Caption[fig:z-scores]{Distribution of Test-Time Z-Scores}{
    We investigate the distribution of sample z-scores according to (3) in the main paper in the validation (val) and two unknown datasets using ConvNeXtV2-H. 
    To improve visibility of failure cases, we plot the y-axis with a logarithmic axis. 
    Most val data has far lower z-scores than the peaks of NINCO and iNaturalist distributions. 
    %The figure is in log-scale and uses the sum of z-scores, so large feature vectors lead to a high composite z-score. 
    However, as one can see, a few val samples have very large z-scores, likely due to automated data collection for ILSVRC2012 or visually distinct subclasses (e.g. baseball class contains images of baseballs and baseball games). 
    While this may cause the normality test to fail, we consider it to be only a minor issue overall, given the significant performance gains reported with GHOST. }
\end{figure}


\section{Plotted Curves}
\label{sec:plots}
We present ROC and OSCR plots on the networks from the main paper in \fig{mae-H-roc}, \fig{mae-H-oscr}, \fig{convnextv2-H-roc}, and \fig{convnextv2-H-oscr}.


\begin{figure*}[t!]
    \centering
    \subfloat[a][21K-P \emph{Easy}]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_ROC_easy_i21k.pdf}
        } 
    \subfloat[b][21K-P \emph{Hard}]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_ROC_hard_i21k.pdf}
        } \\
    \subfloat[a][NINCO]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_ROC_NINCO.pdf}
        } 
    \subfloat[b][OpenImage-O]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_ROC_OpenImage-O.pdf}
        } \\
    \Caption[fig:mae-H-roc]{ROC Curves}{The Receiver Operating Characteristic curves of all methods on four unknown datasets from the main paper. All methods are derived from extractions from the same pre-trained architecture -- state-of-the-art MAE-H.}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \subfloat[a][21K-P \emph{Easy}]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_easy_i21k_Mean_per_point_OSCR.pdf}
        } 
    \subfloat[b][21K-P \emph{Hard}]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_hard_i21k_Mean_per_point_OSCR.pdf}
        } \\
    \subfloat[a][NINCO]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_NINCO_Mean_per_point_OSCR.pdf}
        } 
    \subfloat[b][OpenImage-O]{
        \includegraphics[width=0.48\textwidth]{figures/mae_H_OpenImage-O_Mean_per_point_OSCR.pdf}
        } \\
    \Caption[fig:mae-H-oscr]{OSCR Curves}{The Open-Set Classification Rate curves of all methods on four unknown datasets from Table 2 in the main paper. All methods are derived from extractions from the same pre-trained architecture -- state-of-the-art MAE-H.}
\end{figure*}



\begin{figure*}[t!]
    \centering
    \subfloat[a][21K-P \emph{Easy}]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_ROC_easy_i21k.pdf}
        } 
    \subfloat[b][21K-P \emph{Hard}]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_ROC_hard_i21k.pdf}
        } \\
    \subfloat[a][NINCO]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_ROC_NINCO.pdf}
        } 
    \subfloat[b][OpenImage-O]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_ROC_OpenImage-O.pdf}
        } \\
    \Caption[fig:convnextv2-H-roc]{ROC Curves}{The Receiver Operating Characteristic curves of all methods on four unknown datasets from the main paper. All methods are derived from extractions from the same pre-trained architecture -- state-of-the-art ConvNeXtV2-H.}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \subfloat[a][21K-P \emph{Easy}]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_easy_i21k_Mean_per_point_OSCR.pdf}
        } 
    \subfloat[b][21K-P \emph{Hard}]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_hard_i21k_Mean_per_point_OSCR.pdf}
        } \\
    \subfloat[a][NINCO]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_NINCO_Mean_per_point_OSCR.pdf}
        } 
    \subfloat[b][OpenImage-O]{
        \includegraphics[width=0.48\textwidth]{figures/convnextv2_H_OpenImage-O_Mean_per_point_OSCR.pdf}
        } \\
    \Caption[fig:convnextv2-H-oscr]{OSCR Curves}{The Open-Set Classification Rate curves of all methods on four unknown datasets from Table 2 in the main paper. All methods are derived from extractions from the same pre-trained architecture -- state-of-the-art ConvNeXtV2-H.}
\end{figure*}

\clearpage