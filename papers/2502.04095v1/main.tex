\documentclass[12pt,twoside]{report}



\newcommand{\reporttitle}{LLMs to Support a Domain Specific Knowledge Assistant}
\newcommand{\reportauthor}{Maria-Flavia Lovin}
\newcommand{\supervisor}{Dr. Pedro Baiz Villafranca}
\newcommand{\secondmarker}{Dr. Tolga Birdal}
\newcommand{\degreetype}{MSc Artificial Intelligence}


\input{includes}


\input{notation}

\date{September 2024}

\begin{document}

\input{titlepage}

\pagenumbering{roman}
\setcounter{page}{1}
\pagestyle{fancy}

\begin{abstract}
This work presents a custom approach to developing a domain-specific knowledge assistant for sustainability reporting using the International Financial Reporting Standards (IFRS). In this domain, there is no publicly available question-answer dataset, which has impeded the development of a high-quality chatbot to support companies with IFRS reporting. The two key contributions of this project therefore are:\\

(1) A high-quality synthetic question-answer dataset based on IFRS sustainability standards, created using a novel generation and evaluation pipeline leveraging Large Language Models (LLMs). This dataset comprises 1,063 diverse question-answer pairs that address a wide spectrum of potential user queries in sustainability reporting. Various LLM-based techniques are employed to create the dataset, including chain-of-thought reasoning and few-shot prompting. A custom evaluation framework is developed to assess question and answer quality across multiple dimensions, including faithfulness, relevance, and domain specificity. The resulting dataset averages a score range of 8.16 out of 10 on these metrics.\\

(2) Two custom architectures tailored for question-answering in the sustainability reporting domain - a retrieval augmented generation (RAG) pipeline and a fully LLM-based pipeline. The architectures are developed by experimenting, fine-tuning, and training on the question-answer dataset. The final pipelines feature an LLM fine-tuned on domain-specific data and an industry classification component to improve the handling of complex, multi-industry queries. The RAG architecture achieves an accuracy of 85.32\% on single-industry and 72.15\% on cross-industry multiple-choice questions, outperforming the baseline approach by 4.67 and 19.21 percentage points, respectively. The LLM-based pipeline achieves an accuracy of 93.45\% on single-industry and 80.30\% on cross-industry multiple-choice questions, an improvement of 12.80 and 27.36 percentage points over the baseline, respectively.  \\

\end{abstract}

\section*{Acknowledgments}

I extend my deepest appreciation to Dr. Pedro Baiz Villafranca for his invaluable guidance and support throughout this project. His encouragement and constructive feedback from the project's inception have been instrumental in its success.\\

I also wish to thank Dr. Tolga Birdal for his co-supervision and for providing clarity on a number of questions during the early stages of this project.\\

Lastly, I want to express my gratitude to my family and close friends for their continuous love and support. Without them, this work would not have been possible.

\tableofcontents 

\newpage

\pagenumbering{arabic}
\setcounter{page}{1}

\input{introduction}

\input{background}

\input{chapter3.tex}

\input{chapter4.tex}




\input{conclusion}


\input{appendix}

\bibliographystyle{unsrtnat}
\bibliography{refs}

\end{document}
