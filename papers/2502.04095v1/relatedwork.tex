\section{Related Work in LLMs for Domain-Specific \\Question-Answering}
Early methods for developing domain-specific question-answering systems involve training RAG architectures, or various components of the architecture, from scratch. These techniques embed knowledge directly into the language models underpinning the system. REALM \cite{guu2020realm} was an early system that pre-trained specific knowledge (in this case, Wikipedia) into the retriever. This was done by augmenting the pre-training with a latent knowledge retriever, allowing the model to access documents during pre-training, fine-tuning, and inference. A pre-training approach is also adopted in RETRO \cite{borgeaud2022improvinglanguagemodelsretrieving}, which uses training and fine-tuning of autoregressive models conditioned on retrieved document chunks. Two recent innovations are RAG-end2end \cite{siriwardhana2022improvingdomainadaptationretrieval}, which explores training the retriever and generator jointly to improve their adaptation to domain-specific question-answering, and RAFT \cite{zhang2024raftadaptinglanguagemodel}, which trains the model to ignore `distractor' documents that don't help in answering the query. \\


The adoption of the above methods to real-world application is hindered by their computationally intensive and inflexible nature. It takes a large amount of external knowledge and significant model adaptation to train or fine-tune models from scratch. Furthermore, once embedded, it is difficult to keep the information up-to-date over time, as that would require re-training \cite{gao2024retrievalaugmented}. As such, modern domain-specific applications of RAG use pipelines where knowledge is retrieved from the external database rather than being embedded into the LLM parameters. This method is less computationally intensive and easier to maintain over time, prompting widespread adoption of LLMs and RAG systems to a wide range of domains. A particularly popular domain is finance, where human/expert-annotated datasets like FinQA \cite{chen2022finqa} and Financebench \cite{islam2023financebench} have enabled the development of large-scale systems such as BloombergGPT \cite{wu2023bloomberggptlargelanguagemodel}. Other popular domains include medicine \cite{xiong2024benchmarkingretrievalaugmentedgenerationmedicine} and pharmaceuticals, where the latter even explored RAG for question-answering in pharmaceutical regulatory compliance \cite{kim2024ragqaragintegratinggenerative}. \\


Nonetheless, there is no standard approach utilised across all domains, as the requirements of specialised systems differ across different domains and tasks. Furthermore, the development of high-quality question-answering systems is more difficult in the absence of a dataset that can be used for training, fine-tuning, and evaluating the system. As a result, this project presents a novel implementation of LLMs and RAG to develop and evaluate a chatbot for the sustainability reporting domain.