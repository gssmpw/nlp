@misc{ey,
author = {},
title = {https://www.ey.com/en\_gl/insights/strategy/why-sustainability-has-become-a-corporate-imperative }}

@misc{deepeval_qa_gen,
author = {},
title = {https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms }}

@misc{mlflow,
author = {},
title = {https://mlflow.org/docs/latest/llms/rag/notebooks/question-generation-retrieval-evaluation.html }}


@misc{wu2023bloomberggptlargelanguagemodel,
      title={BloombergGPT: A Large Language Model for Finance}, 
      author={Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann},
      year={2023},
      eprint={2303.17564},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.17564}, 
}

@misc{kim2024ragqaragintegratinggenerative,
      title={From RAG to QA-RAG: Integrating Generative AI for Pharmaceutical Regulatory Compliance Process}, 
      author={Jaewoong Kim and Moohong Min},
      year={2024},
      eprint={2402.01717},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01717}, 
}

@misc{borgeaud2022improvinglanguagemodelsretrieving,
      title={Improving language models by retrieving from trillions of tokens}, 
      author={Sebastian Borgeaud and Arthur Mensch and Jordan Hoffmann and Trevor Cai and Eliza Rutherford and Katie Millican and George van den Driessche and Jean-Baptiste Lespiau and Bogdan Damoc and Aidan Clark and Diego de Las Casas and Aurelia Guy and Jacob Menick and Roman Ring and Tom Hennigan and Saffron Huang and Loren Maggiore and Chris Jones and Albin Cassirer and Andy Brock and Michela Paganini and Geoffrey Irving and Oriol Vinyals and Simon Osindero and Karen Simonyan and Jack W. Rae and Erich Elsen and Laurent Sifre},
      year={2022},
      eprint={2112.04426},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.04426}, 
}

@misc{zhang2024raftadaptinglanguagemodel,
      title={RAFT: Adapting Language Model to Domain Specific RAG}, 
      author={Tianjun Zhang and Shishir G. Patil and Naman Jain and Sheng Shen and Matei Zaharia and Ion Stoica and Joseph E. Gonzalez},
      year={2024},
      eprint={2403.10131},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.10131}, 
}
@misc{zhou2023leasttomostpromptingenablescomplex,
      title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models}, 
      author={Denny Zhou and Nathanael Schärli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc Le and Ed Chi},
      year={2023},
      eprint={2205.10625},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2205.10625}, 
}
@misc{shazeer2017outrageouslylargeneuralnetworks,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1701.06538}, 
}

@misc{siriwardhana2022improvingdomainadaptationretrieval,
      title={Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering}, 
      author={Shamane Siriwardhana and Rivindu Weerasekera and Elliott Wen and Tharindu Kaluarachchi and Rajib Rana and Suranga Nanayakkara},
      year={2022},
      eprint={2210.02627},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.02627}, 
}

@misc{xiong2024benchmarkingretrievalaugmentedgenerationmedicine,
      title={Benchmarking Retrieval-Augmented Generation for Medicine}, 
      author={Guangzhi Xiong and Qiao Jin and Zhiyong Lu and Aidong Zhang},
      year={2024},
      eprint={2402.13178},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13178}, 
}

@misc{openaiembeddingmodel,
author = {},
title = {https://platform.openai.com/docs/guides/embeddings }}

@inproceedings{rahutomo2012semantic,
  title={Semantic cosine similarity},
  author={Rahutomo, Faisal and Kitasuka, Teruaki and Aritsugi, Masayoshi and others},
  booktitle={The 7th international student conference on advanced science and technology ICAST},
  volume={4},
  number={1},
  pages={1},
  year={2012},
  organization={University of Seoul South Korea}
}

@misc{guo2024generativeaisyntheticdata,
      title={Generative AI for Synthetic Data Generation: Methods, Challenges and the Future}, 
      author={Xu Guo and Yiqiang Chen},
      year={2024},
      eprint={2403.04190},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.04190}, 
}

@inproceedings{han2023multilingual,
  title={Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs},
  author={Han, Kelvin and Gardent, Claire},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)},
  pages={13740--13756},
  year={2023},
  organization={Association for Computational Linguistics}
}


@misc{voyageembeddingmodel,
author = {},
title = {https://docs.voyageai.com/docs/embeddings}}

@article{nicolescu2022human,
  title={Human-computer interaction in customer service: the experience with AI chatbots—a systematic literature review},
  author={Nicolescu, Luminița and Tudorache, Monica Teodora},
  journal={Electronics},
  volume={11},
  number={10},
  pages={1579},
  year={2022},
  publisher={MDPI}
}


@misc{lewis2019bart,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.13461}, 
}

@misc{lewis2021retrievalaugmented,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{ifrsorgc9:online,
author = {},
title = {https://www.ifrs.org/projects/completed-projects/2023/general-sustainability-related-disclosures/}
}

@misc{ifrs_s1,
author = {},
title = {https://www.ifrs.org/issued-standards/ifrs-sustainability-standards-navigator/ifrs-s1-general-requirements/ }}

@misc{ifrs_s2,
author = {},
title = {https://www.ifrs.org/issued-standards/ifrs-sustainability-standards-navigator/ifrs-s2-climate-related-disclosures/ }}

@misc{ifrs_appendix,
author = {},
title = {https://www.ifrs.org/projects/completed-projects/2023/climate-related-disclosures/appendix-b-industry-based-disclosure-requirements/ }}

@misc{ifrs_companies,
author = {},
title = {https://www.ifrs.org/use-around-the-world/use-of-ifrs-standards-by-jurisdiction/\#analysis-of-use-of-ifrs-accounting-standards-around-the-world }}

@misc{sasb_reports,
author = {},
title = {https://sasb.ifrs.org/company-use/sasb-reporters/ }}

@article{yepes2024financial,
  title={Financial Report Chunking for Effective Retrieval Augmented Generation},
  author={Yepes, Antonio Jimeno and You, Yao and Milczek, Jan and Laverde, Sebastian and Li, Leah},
  journal={arXiv preprint arXiv:2402.05131},
  year={2024}
}

@misc{llamaindex_eval,
author = {},
title = {https://docs.llamaindex.ai/en/stable/module\_guides/evaluating/}}

@misc{deepeval,
author = {},
title = {https://github.com/confident-ai/deepeval }}

@article{deepeval_paper,
  title={Can Large Multimodal Models Uncover Deep Semantics Behind Images?},
  author={Yang, Yixin and Li, Zheng and Dong, Qingxiu and Xia, Heming and Sui, Zhifang},
  journal={arXiv preprint arXiv:2402.11281},
  year={2024}
}

@misc{guu2020realm,
      title={REALM: Retrieval-Augmented Language Model Pre-Training}, 
      author={Kelvin Guu and Kenton Lee and Zora Tung and Panupong Pasupat and Ming-Wei Chang},
      year={2020},
      eprint={2002.08909},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gao2024retrievalaugmented,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{sawarkar2024blended,
  title={Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers},
  author={Sawarkar, Kunal and Mangal, Abhilasha and Solanki, Shivam Raj},
  journal={arXiv preprint arXiv:2404.07220},
  year={2024}
}



@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@inproceedings{kandpal2023large,
  title={Large language models struggle to learn long-tail knowledge},
  author={Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={15696--15707},
  year={2023},
  organization={PMLR}
}

@misc{zhang2024raft,
      title={RAFT: Adapting Language Model to Domain Specific RAG}, 
      author={Tianjun Zhang and Shishir G. Patil and Naman Jain and Sheng Shen and Matei Zaharia and Ion Stoica and Joseph E. Gonzalez},
      year={2024},
      eprint={2403.10131},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{white2024livebench,
  title={LiveBench: A Challenging, Contamination-Free LLM Benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  journal={arXiv preprint arXiv:2406.19314},
  year={2024}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{es2023ragas,
  title={Ragas: Automated evaluation of retrieval augmented generation},
  author={Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  journal={arXiv preprint arXiv:2309.15217},
  year={2023}
}

@inproceedings{
yoran2024making,
title={Making Retrieval-Augmented Language Models Robust to Irrelevant Context},
author={Ori Yoran and Tomer Wolfson and Ori Ram and Jonathan Berant},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=ZS4m74kZpH}
}

@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{ragend2end,
  title={Improving the domain adaptation of retrieval augmented generation (RAG) models for open domain question answering},
  author={Siriwardhana, Shamane and Weerasekera, Rivindu and Wen, Elliott and Kaluarachchi, Tharindu and Rana, Rajib and Nanayakkara, Suranga},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1--17},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}




@misc{hoffmann2022training,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hada2023large,
  title={Are large language model-based evaluators the solution to scaling up multilingual evaluation?},
  author={Hada, Rishav and Gumma, Varun and de Wynter, Adrian and Diddee, Harshita and Ahmed, Mohamed and Choudhury, Monojit and Bali, Kalika and Sitaram, Sunayana},
  journal={arXiv preprint arXiv:2309.07462},
  year={2023}
}

@article{lin2023llm,
  title={Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models},
  author={Lin, Yen-Ting and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2305.13711},
  year={2023}
}

@article{kocmi2023gemba,
  title={GEMBA-MQM: Detecting translation quality error spans with GPT-4},
  author={Kocmi, Tom and Federmann, Christian},
  journal={arXiv preprint arXiv:2310.13988},
  year={2023}
}

@inproceedings{wu2023large,
  title={Large language models are diverse role-players for summarization evaluation},
  author={Wu, Ning and Gong, Ming and Shou, Linjun and Liang, Shining and Jiang, Daxin},
  booktitle={CCF International Conference on Natural Language Processing and Chinese Computing},
  pages={695--707},
  year={2023},
  organization={Springer}
}

@misc{lu2023error,
  title={Error analysis prompting enables human-like translation evaluation in large language models: A case study on chatgpt},
  author={Lu, Qingyu and Qiu, Baopu and Ding, Liang and Xie, Liping and Tao, Dacheng},
  year={2023},
  publisher={Preprints}
}

@article{gao2023human,
  title={Human-like summarization evaluation with chatgpt},
  author={Gao, Mingqi and Ruan, Jie and Sun, Renliang and Yin, Xunjian and Yang, Shiping and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2304.02554},
  year={2023}
}

@misc{schulhoff2024promptreportsystematicsurvey,
      title={The Prompt Report: A Systematic Survey of Prompting Techniques}, 
      author={Sander Schulhoff and Michael Ilie and Nishant Balepur and Konstantine Kahadze and Amanda Liu and Chenglei Si and Yinheng Li and Aayush Gupta and HyoJung Han and Sevien Schulhoff and Pranav Sandeep Dulepet and Saurav Vidyadhara and Dayeon Ki and Sweta Agrawal and Chau Pham and Gerson Kroiz and Feileen Li and Hudson Tao and Ashay Srivastava and Hevander Da Costa and Saloni Gupta and Megan L. Rogers and Inna Goncearenco and Giuseppe Sarli and Igor Galynker and Denis Peskoff and Marine Carpuat and Jules White and Shyamal Anadkat and Alexander Hoyle and Philip Resnik},
      year={2024},
      eprint={2406.06608},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.06608}, 
}

@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended abstracts of the 2021 CHI conference on human factors in computing systems},
  pages={1--7},
  year={2021}
}

@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{kojima2023largelanguagemodelszeroshot,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.11916}, 
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@article{gao2022precise,
  title={Precise zero-shot dense retrieval without relevance labels},
  author={Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
  journal={arXiv preprint arXiv:2212.10496},
  year={2022}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@article{sellam2020bleurt,
  title={BLEURT: Learning robust metrics for text generation},
  author={Sellam, Thibault and Das, Dipanjan and Parikh, Ankur P},
  journal={arXiv preprint arXiv:2004.04696},
  year={2020}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{fu2023gptscore,
  title={Gptscore: Evaluate as you desire},
  author={Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
  journal={arXiv preprint arXiv:2302.04166},
  year={2023}
}

@article{zhang2023interpretable,
  title={Interpretable unified language checking},
  author={Zhang, Tianhua and Luo, Hongyin and Chuang, Yung-Sung and Fang, Wei and Gaitskell, Luc and Hartvigsen, Thomas and Wu, Xixin and Fox, Danny and Meng, Helen and Glass, James},
  journal={arXiv preprint arXiv:2304.03728},
  year={2023}
}

@article{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.14251},
  year={2023}
}

@article{wang2023chatgpt,
  title={Is chatgpt a good nlg evaluator? a preliminary study},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint arXiv:2303.04048},
  year={2023}
}

@article{zhao2019moverscore,
  title={MoverScore: Text generation evaluating with contextualized embeddings and earth mover distance},
  author={Zhao, Wei and Peyrard, Maxime and Liu, Fei and Gao, Yang and Meyer, Christian M and Eger, Steffen},
  journal={arXiv preprint arXiv:1909.02622},
  year={2019}
}

@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@article{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@misc{lmsys,
author = {},
title = {https://lmsys.org/blog/2023-06-29-longchat/ }}

@misc{medium_rag_not_working,
author = {},
title = {Why your RAG is not working?},
url = {https://medium.com/@saurabhgssingh/why-your-rag-is-not-working-96053b4d5305},
note = "Accessed 21 July 2024"
}

@article{gao2021unsupervised,
  title={Unsupervised corpus aware language model pre-training for dense passage retrieval},
  author={Gao, Luyu and Callan, Jamie},
  journal={arXiv preprint arXiv:2108.05540},
  year={2021}
}

@inproceedings{mitkov_mcq,
author = {Mitkov, Ruslan and Ha, Le An},
title = {Computer-aided generation of multiple-choice tests},
year = {2003},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1118894.1118897},
doi = {10.3115/1118894.1118897},
abstract = {This paper describes a novel computer-aided procedure for generating multiple-choice tests from electronic instructional documents. In addition to employing various NLP techniques including term extraction and shallow parsing, the program makes use of language resources such as a corpus and WordNet. The system generates test questions and distractors, offering the user the option to post-edit the test items.},
booktitle = {Proceedings of the HLT-NAACL 03 Workshop on Building Educational Applications Using Natural Language Processing - Volume 2},
pages = {17–22},
numpages = {6},
series = {HLT-NAACL-EDUC '03}
}

@article{alberti2019synthetic,
  title={Synthetic QA corpora generation with roundtrip consistency},
  author={Alberti, Chris and Andor, Daniel and Pitler, Emily and Devlin, Jacob and Collins, Michael},
  journal={arXiv preprint arXiv:1906.05416},
  year={2019}
}

@inproceedings{liu2020asking,
  title={Asking questions the human way: Scalable question-answer generation from text corpus},
  author={Liu, Bang and Wei, Haojie and Niu, Di and Chen, Haolan and He, Yancheng},
  booktitle={Proceedings of The Web Conference 2020},
  pages={2032--2043},
  year={2020}
}

@article{bartolo2021improving,
  title={Improving question answering model robustness with synthetic adversarial data generation},
  author={Bartolo, Max and Thrush, Tristan and Jia, Robin and Riedel, Sebastian and Stenetorp, Pontus and Kiela, Douwe},
  journal={arXiv preprint arXiv:2104.08678},
  year={2021}
}

@article{puri2020training,
  title={Training question answering models from synthetic data},
  author={Puri, Raul and Spring, Ryan and Patwary, Mostofa and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2002.09599},
  year={2020}
}

@article{du2017learning,
  title={Learning to ask: Neural question generation for reading comprehension},
  author={Du, Xinya and Shao, Junru and Cardie, Claire},
  journal={arXiv preprint arXiv:1705.00106},
  year={2017}
}

@inproceedings{song2018leveraging,
  title={Leveraging context information for natural question generation},
  author={Song, Linfeng and Wang, Zhiguo and Hamza, Wael and Zhang, Yue and Gildea, Daniel},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
  pages={569--574},
  year={2018}
}

@inproceedings{sun2018answer,
  title={Answer-focused and position-aware neural question generation},
  author={Sun, Xingwu and Liu, Jing and Lyu, Yajuan and He, Wei and Ma, Yanjun and Wang, Shi},
  booktitle={Proceedings of the 2018 conference on empirical methods in natural language processing},
  pages={3930--3939},
  year={2018}
}

@misc{rus2010first,
  title={The first question generation shared task evaluation challenge},
  author={Rus, Vasile and Wyse, Brendan and Piwek, Paul and Lintean, Mihai and Stoyanchev, Svetlana and Moldovan, Cristian},
  year={2010}
}

@inproceedings{shakeri2020end,
  title={End-to-end synthetic data generation for domain adaptation of question answering systems},
  author={Shakeri, Siamak and dos Santos, Cicero and Zhu, Henghui and Ng, Patrick and Nan, Feng and Wang, Zhiguo and Nallapati, Ramesh and Xiang, Bing},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={5445--5460},
  year={2020}
}


@misc{johnson2017billionscale,
      title={Billion-scale similarity search with GPUs}, 
      author={Jeff Johnson and Matthijs Douze and Hervé Jégou},
      year={2017},
      eprint={1702.08734},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{karpukhin2020dense,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sanh2020distilbertdistilledversionbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}


@misc{borgeaud2022improving,
      title={Improving language models by retrieving from trillions of tokens}, 
      author={Sebastian Borgeaud and Arthur Mensch and Jordan Hoffmann and Trevor Cai and Eliza Rutherford and Katie Millican and George van den Driessche and Jean-Baptiste Lespiau and Bogdan Damoc and Aidan Clark and Diego de Las Casas and Aurelia Guy and Jacob Menick and Roman Ring and Tom Hennigan and Saffron Huang and Loren Maggiore and Chris Jones and Albin Cassirer and Andy Brock and Michela Paganini and Geoffrey Irving and Oriol Vinyals and Simon Osindero and Karen Simonyan and Jack W. Rae and Erich Elsen and Laurent Sifre},
      year={2022},
      eprint={2112.04426},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rae2016scaling,
      title={Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes}, 
      author={Jack W Rae and Jonathan J Hunt and Tim Harley and Ivo Danihelka and Andrew Senior and Greg Wayne and Alex Graves and Timothy P Lillicrap},
      year={2016},
      eprint={1610.09027},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{izacard2021leveraging,
      title={Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering}, 
      author={Gautier Izacard and Edouard Grave},
      year={2021},
      eprint={2007.01282},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dai2022dialog,
      title={Dialog Inpainting: Turning Documents into Dialogs}, 
      author={Zhuyun Dai and Arun Tejasvi Chaganty and Vincent Zhao and Aida Amini and Qazi Mamunur Rashid and Mike Green and Kelvin Guu},
      year={2022},
      eprint={2205.09073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xu2021goldfish,
      title={Beyond Goldfish Memory: Long-Term Open-Domain Conversation}, 
      author={Jing Xu and Arthur Szlam and Jason Weston},
      year={2021},
      eprint={2107.07567},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{komeili2021internetaugmented,
      title={Internet-Augmented Dialogue Generation}, 
      author={Mojtaba Komeili and Kurt Shuster and Jason Weston},
      year={2021},
      eprint={2107.07566},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{bai2020sparterm,
      title={SparTerm: Learning Term-based Sparse Representation for Fast Text Retrieval}, 
      author={Yang Bai and Xiaoguang Li and Gang Wang and Chaoliang Zhang and Lifeng Shang and Jun Xu and Zhaowei Wang and Fangshan Wang and Qun Liu},
      year={2020},
      eprint={2010.00768},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@misc{siriwardhana2022improving,
      title={Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering}, 
      author={Shamane Siriwardhana and Rivindu Weerasekera and Elliott Wen and Tharindu Kaluarachchi and Rajib Rana and Suranga Nanayakkara},
      year={2022},
      eprint={2210.02627},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zamani2024stochastic,
      title={Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization}, 
      author={Hamed Zamani and Michael Bendersky},
      year={2024},
      eprint={2405.02816},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{cheng2023lift,
      title={Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory}, 
      author={Xin Cheng and Di Luo and Xiuying Chen and Lemao Liu and Dongyan Zhao and Rui Yan},
      year={2023},
      eprint={2305.02437},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{kwiatkowski2019NQ,
    author = {Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and Toutanova, Kristina and Jones, Llion and Kelcey, Matthew and Chang, Ming-Wei and Dai, Andrew
                        M. and Uszkoreit, Jakob and Le, Quoc and Petrov, Slav},
    title = "{Natural Questions: A Benchmark for Question Answering
                    Research}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {7},
    pages = {453-466},
    year = {2019},
    month = {08},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00276},
    url = {https://doi.org/10.1162/tacl\_a\_00276},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00276/1923288/tacl\_a\_00276.pdf},
}

@misc{welbl2018constructing,
      title={Constructing Datasets for Multi-hop Reading Comprehension Across Documents}, 
      author={Johannes Welbl and Pontus Stenetorp and Sebastian Riedel},
      year={2018},
      eprint={1710.06481},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{press2023measuring,
      title={Measuring and Narrowing the Compositionality Gap in Language Models}, 
      author={Ofir Press and Muru Zhang and Sewon Min and Ludwig Schmidt and Noah A. Smith and Mike Lewis},
      year={2023},
      eprint={2210.03350},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{geva2021did,
      title={Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies}, 
      author={Mor Geva and Daniel Khashabi and Elad Segal and Tushar Khot and Dan Roth and Jonathan Berant},
      year={2021},
      eprint={2101.02235},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kalyan2021coffee,
      title={How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI}, 
      author={Ashwin Kalyan and Abhinav Kumar and Arjun Chandrasekaran and Ashish Sabharwal and Peter Clark},
      year={2021},
      eprint={2110.14207},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{hendrycks2021cuad,
      title={CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review}, 
      author={Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},
      year={2021},
      eprint={2103.06268},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2022finqa,
      title={FinQA: A Dataset of Numerical Reasoning over Financial Data}, 
      author={Zhiyu Chen and Wenhu Chen and Charese Smiley and Sameena Shah and Iana Borova and Dylan Langdon and Reema Moussa and Matt Beane and Ting-Hao Huang and Bryan Routledge and William Yang Wang},
      year={2022},
      eprint={2109.00122},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{islam2023financebench,
  title={Financebench: A new benchmark for financial question answering},
  author={Islam, Pranab and Kannappan, Anand and Kiela, Douwe and Qian, Rebecca and Scherrer, Nino and Vidgen, Bertie},
  journal={arXiv preprint arXiv:2311.11944},
  year={2023}
}
@misc{jin2019pubmedqa,
      title={PubMedQA: A Dataset for Biomedical Research Question Answering}, 
      author={Qiao Jin and Bhuwan Dhingra and Zhengping Liu and William W. Cohen and Xinghua Lu},
      year={2019},
      eprint={1909.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{abacha2017overview,
  title={Overview of the medical question answering task at TREC 2017 LiveQA.},
  author={Abacha, Asma Ben and Agichtein, Eugene and Pinter, Yuval and Demner-Fushman, Dina},
  booktitle={TREC},
  pages={1--12},
  year={2017}
}

@inproceedings{abacha2019bridging,
  title={Bridging the Gap Between Consumers' Medication Questions and Trusted Answers.},
  author={Abacha, Asma Ben and Mrabet, Yassine and Sharp, Mark and Goodwin, Travis R and Shooshan, Sonya E and Demner-Fushman, Dina},
  booktitle={MedInfo},
  year={2019}
}

@article{benoverview,
  title={Overview of the MEDIQA 2019 Shared Task on Textual Inference},
  author={Ben Abacha, A and Shivade, C and Demner-Fushman, D},
  journal={Question Entailment and Question Answering. iii}
}

@article{abacha2019question,
  title={A question-entailment approach to question answering. CoRR abs/1901.08079 (2019)},
  author={Abacha, Asma Ben and Demner-Fushman, Dina},
  journal={arXiv preprint arXiv:1901.08079},
  year={2019}
}
@misc{singhal2022large,
      title={Large Language Models Encode Clinical Knowledge}, 
      author={Karan Singhal and Shekoofeh Azizi and Tao Tu and S. Sara Mahdavi and Jason Wei and Hyung Won Chung and Nathan Scales and Ajay Tanwani and Heather Cole-Lewis and Stephen Pfohl and Perry Payne and Martin Seneviratne and Paul Gamble and Chris Kelly and Nathaneal Scharli and Aakanksha Chowdhery and Philip Mansfield and Blaise Aguera y Arcas and Dale Webster and Greg S. Corrado and Yossi Matias and Katherine Chou and Juraj Gottweis and Nenad Tomasev and Yun Liu and Alvin Rajkomar and Joelle Barral and Christopher Semturs and Alan Karthikesalingam and Vivek Natarajan},
      year={2022},
      eprint={2212.13138},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{xu2023retrieval,
  title={Retrieval meets long context large language models},
  author={Xu, Peng and Ping, Wei and Wu, Xianchao and McAfee, Lawrence and Zhu, Chen and Liu, Zihan and Subramanian, Sandeep and Bakhturina, Evelina and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2310.03025},
  year={2023}
}

@misc{petroni2021kilt,
      title={KILT: a Benchmark for Knowledge Intensive Language Tasks}, 
      author={Fabio Petroni and Aleksandra Piktus and Angela Fan and Patrick Lewis and Majid Yazdani and Nicola De Cao and James Thorne and Yacine Jernite and Vladimir Karpukhin and Jean Maillard and Vassilis Plachouras and Tim Rocktäschel and Sebastian Riedel},
      year={2021},
      eprint={2009.02252},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{papieni_bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: a method for automatic evaluation of machine translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}