[
  {
    "index": 0,
    "papers": [
      {
        "key": "Radford2021LearningTV",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya",
        "title": "Learning Transferable Visual Models From Natural Language Supervision"
      },
      {
        "key": "Fang2022EVAET",
        "author": "Yuxin Fang and Wen Wang and Binhui Xie and Quan-Sen Sun and Ledell Yu Wu and Xinggang Wang and Tiejun Huang and Xinlong Wang and Yue Cao",
        "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"
      },
      {
        "key": "Li2021AlignBF",
        "author": "Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq R. Joty and Caiming Xiong and Steven C. H. Hoi",
        "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"
      },
      {
        "key": "Bain2021FrozenIT",
        "author": "Max Bain and Arsha Nagrani and G{\\\"u}l Varol and Andrew Zisserman",
        "title": "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval"
      },
      {
        "key": "Luo2021CLIP4ClipAE",
        "author": "Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui",
        "title": "CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning"
      },
      {
        "key": "Mu2021SLIPSM",
        "author": "Norman Mu and\nAlexander Kirillov and\nDavid A. Wagner and\nSaining Xie",
        "title": "{SLIP:} Self-supervision Meets Language-Image Pre-training"
      },
      {
        "key": "Ma2022XCLIPEM",
        "author": "Ma, Yiwei and Xu, Guohai and Sun, Xiaoshuai and Yan, Ming and Zhang, Ji and Ji, Rongrong",
        "title": "X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval"
      },
      {
        "key": "Huang2022CloverTA",
        "author": "Jingjia Huang and Yinan Li and Jiashi Feng and Xiaoshuai Sun and Rongrong Ji",
        "title": "Clover: Towards A Unified Video-Language Alignment and Fusion Model"
      },
      {
        "key": "Xu2021VideoCLIPCP",
        "author": "Xu, Hu  and\nGhosh, Gargi  and\nHuang, Po-Yao  and\nOkhonko, Dmytro  and\nAghajanyan, Armen  and\nMetze, Florian  and\nZettlemoyer, Luke  and\nFeichtenhofer, Christoph",
        "title": "{V}ideo{CLIP}: Contrastive Pre-training for Zero-shot Video-Text Understanding"
      },
      {
        "key": "Chen2023InternVS",
        "author": "Zhe Chen and Jiannan Wu and Wenhai Wang and Weijie Su and Guo Chen and Sen Xing and Zhong Muyan and Qinglong Zhang and Xizhou Zhu and Lewei Lu and Bin Li and Ping Luo and Tong Lu and Yu Qiao and Jifeng Dai",
        "title": "Intern VL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"
      },
      {
        "key": "Xu2023mPLUG2AM",
        "author": "Haiyang Xu and Qinghao Ye and Mingshi Yan and Yaya Shi and Jiabo Ye and Yuanhong Xu and Chenliang Li and Bin Bi and Qiuchen Qian and Wei Wang and Guohai Xu and Ji Zhang and Songfang Huang and Feiran Huang and Jingren Zhou",
        "title": "mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video"
      },
      {
        "key": "Liu2023VisualIT",
        "author": "Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee",
        "title": "Visual Instruction Tuning"
      },
      {
        "key": "li2024llava",
        "author": "Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan",
        "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Radford2021LearningTV",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya",
        "title": "Learning Transferable Visual Models From Natural Language Supervision"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Jia2021ScalingUV",
        "author": "Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom",
        "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Li2021SupervisionEE",
        "author": "Yangguang Li and Feng Liang and Lichen Zhao and Yufeng Cui and Wanli Ouyang and Jing Shao and Fengwei Yu and Junjie Yan",
        "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Li2021AlignBF",
        "author": "Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq R. Joty and Caiming Xiong and Steven C. H. Hoi",
        "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Singh2021FLAVAAF",
        "author": "Amanpreet Singh and Ronghang Hu and Vedanuj Goswami and Guillaume Couairon and Wojciech Galuba and Marcus Rohrbach and Douwe Kiela",
        "title": "FLAVA: A Foundational Language And Vision Alignment Model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Wang2021SimVLMSV",
        "author": "Zirui Wang and Jiahui Yu and Adams Wei Yu and Zihang Dai and Yulia Tsvetkov and Yuan Cao",
        "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Yu2022CoCaCC",
        "author": "Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu",
        "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Li2022BLIPBL",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "{BLIP}: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Li2023BLIP2BL",
        "author": "Junnan Li and Dongxu Li and Silvio Savarese and Steven C. H. Hoi",
        "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2024llava",
        "author": "Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan",
        "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Bai2023QwenVLAV",
        "author": "Jinze Bai and Shuai Bai and Shusheng Yang and Shijie Wang and Sinan Tan and Peng Wang and Junyang Lin and Chang Zhou and Jingren Zhou",
        "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Zhang2024MMLLMsRA",
        "author": "Zhang, Duzhen  and\nYu, Yahan  and\nDong, Jiahua  and\nLi, Chenxing  and\nSu, Dan  and\nChu, Chenhui  and\nYu, Dong",
        "title": "{MM}-{LLM}s: Recent Advances in {M}ulti{M}odal Large Language Models"
      },
      {
        "key": "Yin2023ASO",
        "author": "Shukang Yin and Chaoyou Fu and Sirui Zhao and Ke Li and Xing Sun and Tong Xu and Enhong Chen",
        "title": "A Survey on Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Yao2021LearningAP",
        "author": "Yao, Shaowei and Tan, Jiwei and Chen, Xi and Yang, Keping and Xiao, Rong and Deng, Hongbo and Wan, Xiaojun",
        "title": "Learning a Product Relevance Model from Click-Through Data in E-Commerce"
      },
      {
        "key": "Chang2021ExtremeML",
        "author": "Chang, Wei-Cheng and Jiang, Daniel and Yu, Hsiang-Fu and Teo, Choon Hui and Zhang, Jiong and Zhong, Kai and Kolluri, Kedarnath and Hu, Qie and Shandilya, Nikhil and Ievgrafov, Vyacheslav and Singh, Japinder and Dhillon, Inderjit S.",
        "title": "Extreme Multi-label Learning for Semantic Matching in Product Search"
      },
      {
        "key": "Zou2021PretrainedLM",
        "author": "Zou, Lixin and Zhang, Shengqiang and Cai, Hengyi and Ma, Dehong and Cheng, Suqi and Wang, Shuaiqiang and Shi, Daiting and Cheng, Zhicong and Yin, Dawei",
        "title": "Pre-trained Language Model based Ranking in Baidu Search"
      },
      {
        "key": "Liu2021Que2SearchFA",
        "author": "Liu, Yiqun and Rangadurai, Kaushik and He, Yunzhong and Malreddy, Siddarth and Gui, Xunlong and Liu, Xiaoyi and Borisyuk, Fedor",
        "title": "Que2Search: Fast and Accurate Query and Document Understanding for Search at Facebook"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Zhu2023QueryLIFEQL",
        "author": "Hai Zhu and Yuankai Guo and Ronggang Dou and Kai Liu",
        "title": "Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce Relevance"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "Ye2023QueryawareMB",
        "author": "Chengcan Ye and Ting Peng and Tim Chang and Zhiyi Zhou and Feng Wang",
        "title": "Query-aware Multi-modal based Ranking Relevance in Video Search"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "Yao2021LearningAP",
        "author": "Yao, Shaowei and Tan, Jiwei and Chen, Xi and Yang, Keping and Xiao, Rong and Deng, Hongbo and Wan, Xiaojun",
        "title": "Learning a Product Relevance Model from Click-Through Data in E-Commerce"
      },
      {
        "key": "Zou2021PretrainedLM",
        "author": "Zou, Lixin and Zhang, Shengqiang and Cai, Hengyi and Ma, Dehong and Cheng, Suqi and Wang, Shuaiqiang and Shi, Daiting and Cheng, Zhicong and Yin, Dawei",
        "title": "Pre-trained Language Model based Ranking in Baidu Search"
      },
      {
        "key": "Wen2023EnhancingDI",
        "author": "Wen, Zhoufutu and Zhao, Xinyu and Jin, Zhipeng and Yang, Yi and Jia, Wei and Chen, Xiaodong and Li, Shuanglong and Liu, Lin",
        "title": "Enhancing Dynamic Image Advertising with Vision-Language Pre-training"
      },
      {
        "key": "Ye2023QueryawareMB",
        "author": "Chengcan Ye and Ting Peng and Tim Chang and Zhiyi Zhou and Feng Wang",
        "title": "Query-aware Multi-modal based Ranking Relevance in Video Search"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "Wen2023EnhancingDI",
        "author": "Wen, Zhoufutu and Zhao, Xinyu and Jin, Zhipeng and Yang, Yi and Jia, Wei and Chen, Xiaodong and Li, Shuanglong and Liu, Lin",
        "title": "Enhancing Dynamic Image Advertising with Vision-Language Pre-training"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "Ye2023QueryawareMB",
        "author": "Chengcan Ye and Ting Peng and Tim Chang and Zhiyi Zhou and Feng Wang",
        "title": "Query-aware Multi-modal based Ranking Relevance in Video Search"
      }
    ]
  }
]