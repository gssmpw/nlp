This section reviews STLs research and algorithmic stability studies.

\textbf{Self-consuming Training Loops}. Recent research has increasingly focused on generative models trained within STLs \citep{shumailov2024ai}, with much of the analysis conducted from an empirical perspective \citep{martinez2023towards}. For example, \citet{shumailov2024ai, briesch2023large} observe a decline in diversity in language models when a portion of the model's outputs is recursively used as inputs. %Similarly, \citet{briesch2023large} investigate the behavior of language models trained within self-consuming loops, finding that while early generations show improvements in quality and diversity, successive iterations ultimately lead to reduced output diversity.  
Additionally, \citet{wyllie2024fairness} highlights that recursive training on synthetic data amplifies biases, resulting in significant fairness concerns. To mitigate model collapse, some studies suggest incorporating real data into the training process \citep{alemohammadself}, expanding the size of synthetic datasets \citep{dohmatobtale,gerstgrasser2024is,dohmatob2024model,feng2024beyond1}, or providing guidance during the generation process \citep{gillmanself,alemohammad2024self,feng2024beyond2}.



%\citet{martinez2023towards} further demonstrates that training generative models on web-scale datasets polluted by synthetic samples also corrodes the quality of generated data.


While empirical research has extensively explored STLs of generative models, theoretical studies on this process remain relatively sparse \citep{kanabar2025minimax,seddik2024bad,marchi2024heat,gerstgrasser2024is,zhu2024synthesize,tao2024survey}. Notably, \citet{shumailov2024ai} and \citet{alemohammadself} offer initial theoretical insights by analyzing a simplified Gaussian model. In a more comprehensive analysis, \citet{bertrandstability} derive upper bounds on parameter deviations between those obtained within a STL and the optimal values, relying on assumptions about statistical and optimization error bounds. In contrast, \citet{futowards} propose bounds on the divergence between synthetic and real-world data distributions, without such assumptions. However, current research lacks a unified theoretical framework that accounts for the influence of different model architectures and does not provide generalization error bounds for STLs, thus failing to rigorously establish the conditions that guarantee the prevention of model collapse. Furthermore, the behavior of transformers within STLs remains unexplored, leaving substantial theoretical gaps.



\textbf{Algorithmic stability}. Algorithmic stability ensures generalization bounds independent of model capacity. A key measure, uniform stability, was introduced by \cite{bousquet2002stability} and has been instrumental in analyzing the generalization behavior of regularization methods. This measure was later extended to SGD \citep{hardt2016train}, including non-convex and non-smooth settings \citep{charles2018stability,bassily2020stability,lei2023stability}. Recent work shows that uniform stability can also provide near-optimal bounds with high probability \citep{feldman2019high,bousquet2020sharper,klochkov2021stability,li2021high,wang2024generalization}.

%Building on these foundations, recent research has shifted toward addressing stability in more complex, non-i.i.d. settings. A common approach models data as being drawn from stationary and mixing sequences \citep{Doukhan1994,yu1994rates}, where dependencies between observations gradually weaken, allowing stability bounds to be derived through mixing coefficients \citep{mohri2010stability,he2016stability,fu2023sharper}. However, accurately estimating these coefficients remains a significant challenge. Additionally, some studies \citep{zheng2023toward} have sought to address this by exploiting conditional independence properties within the data. 

Building on these foundations, recent research has focused on stability in more complex, non-i.i.d. settings. A common approach models data from stationary and mixing sequences \citep{Doukhan1994,yu1994rates}, where weakening dependencies allow stability bounds through mixing coefficients \citep{mohri2010stability,he2016stability,fu2023sharper}. However, estimating these coefficients remains challenging. Additionally, some studies \citep{zheng2023toward} address non-i.i.d. data by leveraging conditional independence properties. Nonetheless, current methodologies struggle with the complexities of STLs, as the non-i.i.d. nature of mixed datasets, where each generation's data is influenced by previous generations, presents unresolved challenges for stability frameworks.

\begin{remark}
 Building on previous challenges, our work advances this area by developing a more comprehensive theoretical framework for analyzing generative models within STLs. Specifically, we present the first generalization error bound by addressing the additional complexity arising from the non-i.i.d. nature of mixed datasets. To address this, we propose the key innovation of recursive stability, which quantifies error propagation across generations of synthetic data. Moreover, we are the first to extend this theoretical framework to transformers, explicitly utilizing error decomposition to illustrate the trade-off introduced by augmenting datasets with synthetic data.
\end{remark}


