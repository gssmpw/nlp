%High-quality data is the lifeblood of large language models (LLMs) training, yet the vast reservoir of publicly available language data on the internet has nearly been exhausted \citep{villalobos2022will}, pushing the research community to seek innovative yet plausible solutions. One emerging approach is to train the next generation of LLMs using synthetic data generated by previous iterations of the models themselves. Moreover, training on synthetic data has become almost inevitable, as many existing large datasets have already been contaminated by synthetic content. This has given rise to self-consuming loops (STLs), where generative models are recursively trained on mixtures of real and synthetic data. In theory, these STLs of data creation and refinement could propel models to new levels of capability, reducing reliance on external datasets.

High-quality data is essential for the training of generative artificial intelligence (AI) models, such as large language models (LLMs). However, the vast reservoir of publicly available data on the internet has nearly been exhausted \citep{villalobos2022will}, pushing the research community to seek innovative yet plausible solutions. One promising approach is to train the next generation of LLMs using synthetic data generated by earlier generations of the models themselves \citep{briesch2023large}. Additionally, reliance on synthetic data has become almost unavoidable, as many existing datasets are already contaminated with synthetic content \citep{schuhmann2022laion}, which proves difficult to detect reliably \citep{sadasivan2023can}. This has led to the development of self-consuming training loops (STLs), where generative models are recursively trained on a mix of real and synthetic data. In theory, these STLs of data creation and refinement could propel models to new levels of capability, reducing reliance on external datasets.

However, despite their potential, the empirical outcomes of STLs have been highly inconsistent across research teams \citep{shumailov2024ai,alemohammadself,bertrandstability}. Some studies \citep{gerstgrasser2024is, bertrandstability, gillmanself} have unlocked significant improvements, observing gains in model accuracy, robustness, and generalization, in which the models seem to thrive on their own generated data, refining their understanding and performance. Yet others \citep{shumailov2024ai,alemohammadself} have encountered serious setbacks—some models have shown signs of stagnation, failing to improve or adapt, while others have even regressed, collapsing into a state where performance sharply deteriorates.

However, despite the potential, the outcomes of STLs have been highly inconsistent across research teams \citep{shumailov2024ai,alemohammadself,bertrandstability}. Some \citep{gerstgrasser2024is, bertrandstability, gillmanself} have unlocked significant improvements, observing gains in model accuracy, robustness, and generalization, in which the models seem to thrive on their own generated data, refining their understanding and performance. Yet others \citep{shumailov2024ai,alemohammadself} have encountered serious setbacks—some models have shown signs of stagnation, failing to improve or adapt, while others have even regressed, collapsing into a state where performance sharply deteriorates.

%What accounts for these stark differences? Even though all “refined” LLMs are drawing from similar pools of model-generated data, the results vary wildly \citep{briesch2023large}. These inconsistencies raise important questions about the conditions under which generating and using synthetic data benefits or hinders model development, signaling that STLs, while promising, may require much deeper exploration and careful optimization to reach their full potential.

What accounts for these stark differences? Even though all “refined” LLMs are drawing from similar pools of model-generated data, the results vary wildly \citep{briesch2023large}. These inconsistencies raise important questions regarding the conditions under which the generation and use of synthetic data either benefits or hinders model development. This suggests that, while STLs hold promise, they may require much deeper investigation and careful optimization to reach their full potential. %This paper seeks to address this issue from a theoretical perspective, specifically by providing a generalization analysis of STLs.

However, despite the extensive empirical analysis conducted on STLs, theoretical insights remain notably sparse. Initial theoretical contributions have been made by \citep{shumailov2024ai} and \cite{alemohammadself}, who analyze a simplified Gaussian model. A more comprehensive examination by \cite{bertrandstability} derives upper bounds on parameter deviations between values obtained within STLs and their optimal counterparts, relying on assumptions regarding statistical and optimization error bounds. Conversely, \cite{futowards} establishes bounds on the divergence between synthetic and real data distributions without such assumptions. However, existing research lacks a unified theoretical framework and has not yet investigated the generalization error of STLs. Furthermore, the behavior of transformers within self-consuming loops remains unexplored, revealing critical theoretical gaps in the literature. Notably, current studies do not explicitly examine the theoretical trade-offs posed by synthetic data augmentation on model performance. This paper aims to address these challenges and fill the identified gaps. The main contributions of this work are as follows:











%The rapid progression of generative artificial intelligence (AI) has facilitated the proliferation of diverse forms of synthetic data. Publicly available generative models, such as Stable Diffusion \citep{rombach2022high} for generating images and GPT series \citep{brown2020language,achiam2023gpt} for text, have been instrumental in facilitating the large-scale creation and dissemination of synthetic content. This increase in generated data has intensified its presence on the Internet, leading to concerns that even large web-scale datasets are now known to include synthetic content \citep{schuhmann2022laion}. Furthermore, identifying such synthetic content presents unique technical challenges \citep{sadasivan2023can, huschens2023you}. Consequently, the inclusion of synthetic data in generative model training sets is becoming increasingly difficult to avoid.

%Moreover, synthetic data is increasingly being purposefully integrated into model training by practitioners for several compelling reasons. First, empirical evidence suggests that, in certain contexts, synthetic data can enhance model performance through data augmentation \citep{kingma2014semi, azizi2023synthetic}. Additionally, it plays a pivotal role in privacy protection \citep{dumont2021overcoming}, particularly in sensitive domains such as medical imaging. However, the most significant factor is the escalating demand for vast amounts of data required by large-scale generative models, which threatens to deplete the available supply of real-world data on the Internet \citep{villalobos2022will}. Consequently, future generations of deep generative models, whether deliberately or inadvertently, will inevitably encounter the inclusion of synthetic data within their training sets. This dynamic leads to the emergence of a self-consuming training loop, where models are recursively trained on synthetic data produced by previous generations.

%Research on deep generative models within the context of self-consuming loops has recently garnered significant attention \citep{shumailov2024ai}. Much of this analysis has been conducted from an empirical perspective \citep{briesch2023large}. Notably, \cite{shumailov2024ai} observe that output diversity tends to diminish after a sufficient number of training generations. Furthermore, \cite{alemohammadself} conclude that the incorporation of real data can effectively mitigate model collapse within these self-consuming loops. Despite these empirical findings, theoretical insights remain sparse. Initial theoretical contributions have been made by \citep{shumailov2024ai} and \cite{alemohammadself}, who analyze a simplified Gaussian model. A more comprehensive examination by \cite{bertrandstability} derives upper bounds on parameter deviations between values obtained within a self-consuming loop and their optimal counterparts, relying on assumptions regarding statistical and optimization error bounds. Conversely, \cite{futowards} establishes bounds on the divergence between synthetic and real data distributions without such assumptions. However, existing research lacks a unified theoretical framework and has not yet investigated the generalization error of self-consuming loops. Furthermore, the behavior of transformers within self-consuming loops remains unexplored, revealing critical theoretical gaps in the literature. Notably, current studies do not explicitly examine the theoretical trade-offs posed by synthetic data augmentation on model performance. This paper aims to address these challenges and fill the identified gaps. The main contributions of this work are as follows:

1. \textbf{Theoretical Generalization Framework:} This paper fills a gap in prior research by being the first to establish generalization error bounds. The key innovation, recursive stability, is introduced to address the core theoretical challenges, specifically the complex recursive structures and the non-i.i.d. nature of the data. Moreover, we demonstrate that the generalization error converges under the following conditions: (1) the generative model satisfies recursive stability, and (2) the proportion of real data is maintained at a non-negligible constant level.

2. \textbf{Application to Transformers in In-Context Learning:} This paper extends the theoretical framework to transformer models within the in-context learning paradigm. Specifically, we prove that transformers in this setting satisfy recursive stability, allowing us to demonstrate that the generalization error is bounded by $\mathcal{O}(n^{-1}\log^2(n) + n^{-1/2}\log(n) + n^{-1/4})$.

3. \textbf{Trade-off Analysis of Synthetic Data Augmentation:}  We investigate the trade-off introduced by synthetic data augmentation. By employing decomposition techniques, we demonstrate that while synthetic data improves the generalization performance of each generation on mixed datasets, it concurrently exacerbates distribution divergence across successive generations. Our theoretical findings further show that the optimal size of synthetic augmentation increases as the size of real dataset decreases.
