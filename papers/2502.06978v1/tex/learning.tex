\section{The Dual SDP Proxy Architecture}
\label{sec:architecture}

The core contribution of the paper is a dual-feasible architecture for DSDP-OPF,
which leverages a new dual completion layer that specifically handles the positive semidefinite constraint \eqref{eq:DSDPOPF:psd}.

Algorithm \ref{algo:DCP} presents the proposed DCP architecture.
First (step 1), an initial model, e.g., a deep neural network, predicts dual variables $\lambdaP, \lambdaQ$, $\nuThermalPfr, \nuThermalQfr, \nuThermalPto, \nuThermalQto$.
Dual variables $\lambdaPf$, $\lambdaQf$, $\lambdaPt$, $\lambdaQt$ are then obtained (step 2) by substituting these predicted values into dual equality constraints \eqref{eq:DSDPOPF:pf}-\eqref{eq:DSDPOPF:qt}.
Steps 3 and 4 use the same argument as \cite{qiu2024dual} to recover variables $\nuThermalSfr$, $\nuThermalSto$ and $\muPgMin$, $\muPgMax$, $\muQgMin$, $\muQgMax$ in closed-form, using constraints \eqref{eq:DSDPOPF:cone:nu} and \eqref{eq:DSDPOPF:pg}-\eqref{eq:DSDPOPF:qg} combined with dual optimality conditions.
Finally, $\mathbf{S}$ and $\muWmMin, \muWmMax$ are recovered as follows.
Letting $\muWmMin = \muWmMax = 0$ in Eq. \eqref{eq:AR_def}, define
\begin{align}
    \label{eq:completion:S_hat}
    \hat{\mathbf{S}} = -\mathcal{A}_{R}(\lambda, \mu, \nu) - \im \mathcal{A}_{I}(\lambda, \mu, \nu),
\end{align}
and let $\mathbf{S} = \hat{\mathbf{S}} - \delta I$, where $\delta = \min(0, \lambda_{min}(\hat{\mathbf{S}})) \leq 0$.
Note that $\delta$ is well defined because $\hat{\mathbf{S}}$ is Hermitian by construction, and that $\mathbf{S} \succeq 0$.
Next, let $(\muWmMin_{i}, \muWmMax_{i}) = (0, -\delta), \forall i \in \mathcal{N}$, which immediately ensures that the completed dual solution satisfies constraint \eqref{eq:DSDPOPF:W}.

The dual completion strategy presented in Algorithm \ref{algo:DCP} ensures that the proposed DCP architecture always outputs dual feasible solutions.
Using a neural network as the prediction model, training can be done using gradients of the objective function \eqref{eq:DSDPOPF:obj} propagated through the completion layer in an end-to-end fashion.
Training the model in this self-supervised way by using the objective function as training loss removes the need to generate ground truth solutions, which can be time-consuming.
For a more detailed description of the DCP architecture, the reader may refer to \cite{qiu2024dual, tanneau2024dual}.


\begin{algorithm}[!t]
    \caption{The DCP Methodology for DSDP-OPF.}
    \label{algo:DCP}
    \setcounter{AlgoLine}{0}
    Predict $\lambdaP, \lambdaQ$, $\nuThermalPfr, \nuThermalQfr, \nuThermalPto, \nuThermalQto$ \\
    Recover $\lambdaPf, \lambdaQf, \lambdaPt, \lambdaQt$ using constraints \eqref{eq:DSDPOPF:pf}--\eqref{eq:DSDPOPF:qt} \label{algo:recover_nu} \\
    Recover $\nuThermalSfr, \nuThermalSto$ using constraint \eqref{eq:DSDPOPF:cone:nu} \\
    Recover $\muPgMin, \muPgMax, \muQgMin, \muQgMax$ via \eqref{eq:DSDPOPF:pg}, \eqref{eq:DSDPOPF:qg} \label{algo:recover_mu} \\
    Recover $\mathbf{S} = \hat{\mathbf{S}} - \delta I$, $\muQgMin=0$, $\muWmMax=-\delta$, where $\hat{\mathbf{S}}$ is obtained as per Eq. \eqref{eq:completion:S_hat} and  $\delta = \min(0, \lambda_{min}(\hat{\mathbf{S}}))$ \label{algo:recover_S}
\end{algorithm}

