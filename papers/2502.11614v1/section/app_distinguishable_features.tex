% \section{Distinguishable Signals}

% \subsection{Linguistic Features}
% We first analyze the representative linguistic features between human and machine~\cite{guo-etal-2023-hc3}, and then measure the correlation between linguistic features and detection accuracy~\cite{chein2024human}.

\section{Distinguishable Signals}
\label{sec:distinctionfactor}
This section elaborates detection setting, accuracy and distinction signals summarized by 18 annotators for 16 datasets one by one.

\begin{table}[t!]
    \centering
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{lcccc}
            \toprule
            \textbf{Dialect} & \textbf{Human} & \textbf{\gptfouro} & \textbf{\qwentwo-7.5B} & \textbf{Overall MGT} \\
            \midrule
            EGY & 52.00 & 53.33 & 58.67 & 56.00 \\
            MOR & 54.00 & 53.33 & 48.00 & 50.67 \\
            LEV & 69.33 & 14.67 & 58.67 & 36.00 \\
            GULF & 81.33 & 26.67 & 30.67 & 28.67 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Arabic dialect tweet human detection accuracy over human vs. \gptfouro vs. \qwentwo-7.5B. Machine-generated text is harder than human text to discern. \gptfouro is harder than \qwentwo.}
    \label{tab:arabic-dialect_tweet-accuracy}
\end{table}

\subsection{Arabic}
\label{sec: arabic_insights}
\paragraph{Arabic Dialect Tweets}
% Mervat
The annotation was conducted under the setting III. Single-binary, where a total of 900 tweets across four dialects were analyzed, with ratio of machine-generated vs. human-written text as 2:1 (GPT-4o and Qwen2-7.5B).
% demonstrated strong performance in generating casual Arabic across all four dialects, with GPT-4.0 outperforming Qwen. 

The annotators were not very confident about their choices when deciding whether the data is human-written or not. They achieved an overall accuracy of 50.06\%, highlighting the difficulty of distinguishing machine-generated content in short texts. 
Overall, 64.17\% of human-written tweets were correctly annotated, 36\% human-written tweets were mis-identified as machine-generated.
\tabref{tab:arabic-dialect_tweet-accuracy} presents the human detection accuracy on human text and machine-generated tweets across four dialects, machine-generated text is harder than human text to discern. \gptfouro outputs are more similar to human text, thus more difficult to distinguish compared to \qwentwo.

Since LLMs effectively replicate native speaker vocabulary, human detection cannot rely on distinguishing lexical distinctions. A key indicator of machine-generated text was the use of emojis in an overly formulaic manner. Additionally, some tweets addressed topics that would typically be considered trivial or unlikely for humans to post, further suggesting machine generation.  
Machine-generated tweets also exhibited unnatural tones, misused native expressions, or contained incomplete content. A notable issue in \qwentwo's output was the inclusion of words from other languages within sentences and the mixing of dialects, which is uncommon in natural usage.

% \begin{table}[t!]
%     \centering
%     \resizebox{\columnwidth}{!}{
%         \begin{tabular}{lcccc}
%             \toprule
%             \textbf{Dialect} & \textbf{Human} & \textbf{\gptfouro} & \textbf{\qwentwo-7.5B} & \textbf{Overall MGT} \\
%             \midrule
%             EGY & 52.00 & 53.33 & 58.67 & 56.00 \\
%             MOR & 54.00 & 53.33 & 48.00 & 50.67 \\
%             LEV & 69.33 & 14.67 & 58.67 & 36.00 \\
%             GULF & 81.33 & 26.67 & 30.67 & 28.67 \\
%             \bottomrule
%         \end{tabular}
%     }
%     \caption{Arabic dialect tweet human detection accuracy over human vs. \gptfouro vs. \qwentwo-7.5B.}
%     \label{tab:arabic-dialect_tweet-accuracy}
% \end{table}

% Since the LLMs were able to replicate words commonly used by native speakers, the annotation process primarily focused on detecting generation patterns rather than assessing the accuracy of the terminology. One frequent indicator of machine-generated text was the use of emojis that were considered overly formulaic for natural usage. Additionally, some tweets addressed topics that would generally be seen as trivial or unnecessary for humans to tweet about, further hinting at machine generation.
% Some machine-generated tweets also exhibited tones that were not typically used by native speakers, used native words and expressions in the wrong context, or had incomplete tweets. A notable issue in the data generated by \qwentwo was the inclusion of words from other languages within sentences, and some tweets contained a mixture of dialects, which is uncommon in natural usage.


\paragraph{EASC Articles Summaries}
% Kareem
% The annotation adhered to the first setting where a total of 306 articles summaries were analyzed. We achieved 82\% annotation accuracy. The differentiation between human-written and machine-generated text was based on a feature set empirically validated for its effectiveness in distinguishing the two. Those features:

We sampled 100 (human, \gptfouro) pairs to identify which text is written by human, achieving 82\% accuracy.
The annotator differentiated human-written text from the machine-generated text based on five empirical distinguishable signals.
\begin{itemize}
    \item \textbf{Informative:} LLM summaries are more informative, while humans may overlook key points due to emotional biases, personal perspectives, or incomplete understanding of articles.
    \item \textbf{Abstract and concise:} LLMs present ideas in a more abstract and concise way, without emphasis on specific points. Human summaries often inject personal opinions and beliefs.
     % \item \textbf{Conciseness} LLMs outperform humans in terms of summary conciseness.
    \item \textbf{Religious language:} Humans can accurately use religious language, whereas LLMs generate text in standard language.
    \item \textbf{Prompt reflection:} LLMs often start with words from the prompt, such as
    % For example machine-generated summaries mostly start with: 
    \begin{quote}
    \small
    \begin{RLtext}
            \texttt{هذا المقال}
    \end{RLtext}
    \end{quote}
    \item \textbf{Formatting hints} Human-written summaries contain typos or grammar errors. Machine-generated text includes markdown elements, making it more easily detectable as machine-generated.
\end{itemize}

% It is important to note that some bias exists in the annotation process. Aside from the characteristic features discussed, human-written summaries contained occasional spelling or linguistic mistakes that gave unintended hints to the annotators. Additionally, the machine-generated text included markdown elements, making it more easily detectable as machine-generated.


\paragraph{Youm7 News Articles}
% Saad
% We conducted a human detection task to evaluate the quality of the generated text. Human annotators were tasked with distinguishing between machine-generated and human-written paragraphs. The annotation process achieved an accuracy of \textbf{92.7\%,} highlighting the subtle yet distinguishable differences between the two text types.

% A key finding was that human-generated paragraphs were typically presented as a single, continuous block of text. In contrast, GPT's responses were paraphrased and divided into smaller sections, which provided a structural cue for annotators to identify machine-generated content. Aside from the structural differences, no significant variations in the sequence or thematic patterns of the articles were detected between human- and machine-generated samples.

% These results underscore the importance of structural features, such as paragraph segmentation, in identifying machine-generated text. Although the models preserved the overall narrative and sequence, the segmentation of the text into multiple paragraphs became a key indicator that helped annotators in their task.

We paired 1,000 (human, \gptfouro) examples to identify which text is written by human, achieving accuracy of 92.7\%.
A key finding was that human-written paragraphs were typically presented as a single continuous block of text, whereas GPT-generated article was segmented into smaller sections. This structural difference served as a crucial cue for identifying machine-generated content. No significant variations were observed in thematic patterns or narrative sequences, paragraph segmentation emerged as a key indicator, highlighting the role of structural features in detection.



\paragraph{SANAD News}
% : Tarek
Using the SANAD Arabic news dataset in Modern Standard Arabic (MSA), we evaluated 100 samples to identify human vs. GPT-4o text, achieving $100\%$ annotation accuracy under the setting I. Pair-binary.
We identified several key features that differentiate machine-generated text from human-written text.
\begin{itemize}
    \item \textbf{Markdown presence:} 
    Machine-generated text often contains markdown, which is absent in human-written text.

    \item \textbf{Formatting style:} 
    Machine-generated text is consistently formatted into structured paragraphs, whereas human text tends to appear as large, unstructured blocks of text.

    \item \textbf{Content density:} 
    Human text is richer in factual information, while machine-generated text includes generic statements. For instance, phrases such as 
    % \begin{quote}
    %     \textarabic{ويأتي هذا التطور في ظل توجه عالمي نحو تنويع مصادر الطاقة وتقليل الاعتماد على الوقود الأحفوري}
    % \end{quote}
    mentions of ``Saudi Vision 2030'' are more frequent in machine-generated text. 

    \item \textbf{Source attribution issues:} 
    Machine-generated text often contains source attributions, but these are sometimes incorrect or against the prompt. 
    % For example:
    % \begin{quote}
    %     \textarabic{الرياض (رويترز)}
    % \end{quote}
    % is used instead of the expected ``Khobar Reuters.''

    \item \textbf{Presence of numbers and specific meta data:} 
    Human-written text contains more supporting numerical details, including URLs, phone numbers, currency exchange rates, dates, and amounts, which are not as frequent in machine-generated text.

    \item \textbf{Use of English terms:} 
    Human text includes sporadic English terms, especially in specialized contexts, while machine text remains fully in Arabic.

    \item \textbf{Hashtags and social media elements:} 
    Hashtags are commonly found in human-written text, whereas machine-generated text lacks such social media elements.

    \item \textbf{Narrative structure:} 
    Human-written text follows a narrative structure with a sequence of events, dates, and timelines. On the other hand, machine-generated text tends to resemble an essay on a given topic rather than a chronological news report.

    \item \textbf{Formatting consistency:} Human text formatting varies significantly, often appearing as inconsistent or messy blocks of text with irregular spacing or newlines. We attribute this apparent inconsistency to the fact that the human texts are composed by a large number of authors, while machine text is written by a single model which provides text that is more polished and consistent.

    \item \textbf{Readability and grammar:} 
    Machine-generated text is generally more readable and grammatically correct, while human text may contain stylistic inconsistencies.
\end{itemize}


\subsection{Chinese}
\label{sec:chinese-distinguishable-signal}
\paragraph{Zhihu QA}
The detection involves six unique individuals, with three female and three male annotators. 
We pair (human, \gptfouro) and (human, \qwenturbo), and annotate both under setting I, achieving the average accuracy of 1.0 and 0.98 respectively. The distinguishable factors are summarized below.
\begin{itemize}
    \item \textbf{Humans share personal experience and feelings.} For emotion-rich questions, humans provide empathic comforts by sharing their real personal experiences. However, narratives or stories generated by models tend to appear contrived and artificial, making it easy for humans to detect that they are not grounded by facts, similar to stories created by kids. Model responses thus typically offer solutions, but they are theoretically sound, while often lack practical applicability.    
    
    \item \textbf{Human answers can be informal, mean and sharp.} 
    Human responses sometimes are mean, strongly opinionated, and influenced by personal biases, reflecting a more self-centered perspective. LLMs provide general and less engaging information, but often attempting to help users and offering problem-solving assistance. Some individuals appreciate human answers for their authenticity and directness, others may find them offensive.
    
    \item \textbf{Different Intent.} Zhihu users prioritize expressing their feelings and opinions, rather than assisting and directly addressing the seeker's needs. So they often do not respond to the question directly. Though LLMs aim to assist but typically offer general information related to the entities or concepts in the question, rarely responding with direct and sharp answers.
   
    \item \textbf{Human answers can be extremely short or long.} Some human answers are excessively long and lack proper paragraph segmentation, making them harder to read. LLM-generated responses are generally well-segmented and structured with bullet points or listed points with bold subtitles.

    \item \textbf{LLM responses lack deviation.} LLMs adhere rigidly to instructions, presenting limited flexibility in their responses. When prompted to answer emotion-rich questions with greater empathy, their generative patterns remain predictable, often relying on superficial expressions such as more emoji inserted instead of deeply integrating empathy into the content. For instance, responses like \textit{I'm sorry this happened to you; you should probably consult a professional}, offer minimal support and feel unhelpful.

    \item \textbf{Other indicators} Human answers sometimes contain timeline of answer update and references. 
\end{itemize}

\textit{Improved Prompts}
We carefully designed prompts using a few different user personas: one with a positive attitude, another with a rational and realistic outlook, and a humorous one. For emotion-rich questions, we also applied \gptfouro utilizing \ecot, a framework designed to enhance LLMs’ emotional and empathetic responses~\cite{li2024ecot}. However, the responses are often brief, with emojis but minimal information, which limits their usefulness.


% \textit{Human vs. GPT-4o under I:} 
% [Yuxia], [Bai]
% Machine-generated answers often provide general information related to the entities or concepts in the question, but rarely address it directly and sharply. 

% For emotion-rich questions, model responses typically offer solutions, while humans provide empathic comforts by sharing their personal experiences. Most importantly, these model solutions are theoretically sound, while often lack practical applicability. 
% 3. Some answers I believe only humans can provide, detailed life experience sharing, I believe it is important to read the people sharing the similar experience, instead of general answers.

% Additionally, narratives or stories generated by models tend to appear contrived and artificial, making it easy for humans to detect that they are not grounded by facts, similar to stories created by kids.



% \textbf{[Zhuohan, Rui]}
% Zhuohan Thoughts while annotating the data:
% Intents are different:
% Zhihuers are there to express their feelings, most of them do not care about the questioners while LLMs at least try to help.

% As a third person, I probably like answers from zhihuers, since they are mean, interesting, honest, authentic.
% But As a person who really ask the questions, they probably like the answers that can take their stands (Assume there are really people who asking these questions, some are probably posted by the platform themselves there just to attract attentions)
% 2. Long answers without formatting is a disaster!!! It is not related to nlp, but it is hard to ignore mentally during annotation.
% 3. Some answers I believe only humans can provide, detailed life experience sharing, I believe it is important to read the people sharing the similar experience, instead of general answers.
% 4. Also, consider how much similar responses they have seen.
% 5. We generally do not think what non-ecot generates is good, because we saw them too much, so they become predictable.
%       a. At first, I think ECOT is good, but after I learnt the pattern, it becomes as boring as non-ecot, even worse. It basically gives nothing, at least Chatgpt is trying to do something.
% 6. Maybe we need a classifier, I think some questions still are solution seeking, even though it is related to relationships. (Like, this problem happened to me, what should I do? Ecot always say: i am sorry it happened to you, you should probably consult a professional, which is, I think, useless.

% \textit{Human vs. Qwen-turbo under I:} 
% \textbf{[Jiahui, Jinyan]}
% (1) Human is more informal, and sometimes doesn't response directly to the question. 
% (2)  Human answer can be harsh and more selfish, while LLM answer are more in a moral high ground. 
% (3) LLM like to answer with structure such as listed points with bolded summarization.
% (4) human answer use personal example.
% (5) sometimes, human answer contains time line of answer update
% (6) Human answer can be extremely short or long



% Junior and Senior 
\paragraph{High School Student Essays}
We perform human detection for student essays in two settings.
One NLP postdoc who is a Chinese native speaker did the detection under the setting I for 102 parallel pairs ($hwt$, $mgt_1$) and ($hwt$, $mgt_2$), obtaining the accuracy of 98\%.
For 600 non-parallel cases under the setting II. Pair-four-class, with 150 pairs for each class, another NLP postdoc and two NLP PhD students participated in annotations. They achieved an accuracy of 0.96, 0.96 and 0.99 respectively. 

During the annotation of high school student essays, we identified four remarkable distinction signals that make machine-generated texts easily recognizable:
\begin{itemize}
    \item \textbf{Title:} From the perspective of formatting, machine text tends to begin by ``title: \cn{《xxx》} or title: xxx'', and have newlines between paragraphs while humans does not have.
    % \item For student essay, the most distinctive trait is that, the MGT almost always has the title of the essay, while the human written student essay doesn't contain the title. 
    
    \item \textbf{Formulaic structure:} From the structure and the content of essays, the structure of machine-generated essays is generally formulaic. They often adopt an argumentative style that begins paragraphs with phrases such as ''first, then, moreover, additionally, finally, and overall'' (i.e., \cn{首先，其次，然而，总之，最后}), while HWT is more flexible and the styles are more diverse. Some MGT even use bullet points in an essay, which is rare in human text.
    % \item Machine-generated essays tend to follow a predictable pattern, often adopting an argumentative style that begins with phrases such as \cn{``首先 (first of all), 其次 (secondly), 再次 (then), 最后 (finally).''}

    \item \textbf{Sentiment:} Machine-generated essays tend to adopt a more neutral or positive tone, generally expressing less emotion compared to human-written essays. While real students often express a range of emotions, including sadness, anger, confusion, and a sense of being lost. These emotions reflect the authentic feelings of young people at that age.
    
    \item \textbf{Style:} Machine-generated content may incorporate elements from other genres, such as official document styles. Additionally, machine-generated content may unexpectedly switch to multilingual content, for example, outputting an English paragraph during Chinese content generation.
    % \item Machine-generated text occasionally inserts English words amid Chinese characters, likely due to the mixture of English and Chinese in the pre-training dataset.
\end{itemize}

\textit{Original vs. Improved Prompt}
% Rui
Based on the findings above, we further refined the prompts in the following ways: (1) instructing the model to avoid outputting titles, as these often serve as clear detection cues; (2) discouraging excessive use of connecting words like 'first of all,' 'secondly,' 'then,' and 'finally'; and (3) preventing the mixing of languages other than Chinese.


% distinguishable factors
% There are five remarkable distinction signals between human text and MGT. 
% [Yuxia] distinguishable signal:
% \textit{Parallel Data under I:} 
% One NLP postdoc who is a Chinese native speaker did the detection, obtaining the accuracy of 98\%.



% From the perspective of formatting, machine text tends to begin by ``title: \cn{《xxx》} or title: xxx'', and have newlines between paragraphs while humans does not have.
% From the structure and the content of essays, the structure of machine-generated essays is generally fixed, organizing by words ''first, then, moreover, additionally, finally, and overall'' (i.e., \cn{首先，其次，然而，总之，最后}), while HWT is more flexible and the styles are more diverse. Some MGT even use bullet points in an essay, which is rare in human text.



% \textit{Separate Sources for Human Essays and MGT under II:} 
% [Zhuohan] 
% One NLP postdoc and two NLP PhD students participate in annotations under the setting II. Pair-four-class. They achieved an accuracy of 0.96, 0.96 and 0.99 respectively. During the annotation of high school student essays, we identified several distinguishable factors that make machine-generated texts easily recognizable:


% \textbf{[Rui]}: 
% add accuracy and annotator info above
% Few extra findings:
% Machine-generated essays tend to adopt a more journalistic and neutral tone, generally expressing less emotion compared to human-written essays. Machine-generated content may incorporate elements from other genres, such as official document styles. Additionally, machine-generated content may unexpectedly switch to multilingual content, for example, outputting an English paragraph during Chinese content generation.


% \textbf{[Jiahui]}
% \textbf{[Jinyan]}
% For student essay, the most distinctive trait is that, the MGT almost always has the title of the essay, while the human written student essay doesn't contain the title. 



\paragraph{Government Report}
% : Jiahui
Under setting IV. Triplet-three-class, we presented human-written texts vs. two model outputs across 500 samples to a native Chinese-speaker (postdoctoral researcher specializing in NLG), and asked the annotator to identify which text is human-written. 
% selected the texts they believed were human-written rather than machine-generated. 
% Results showed that the 
The annotator achieved an accuracy of 97.2\%. Human-authored texts were typically longer and contained richer details, often covering multiple topics, while machine-generated texts were generally shorter, lacking noticeable rhythm variations. Additionally, machine-generated texts occasionally included distinct symbols, such as bold formatting and English words.
Errors in distinguishing humans from machine-generated texts primarily occurred when the machine-generated outputs were of similar length to human-written ones. 


\subsection{English Peer Meta Review}
% Alex

% Distinguishable Signals
% After being given a couple of labeled sample data points I was extremely confident of which texts were human-written and which texts were machine-generated as I knew what features were indicative of MGT. However before I was given examples of labeled sample data I still think it is very obvious as to which texts were machine-generated.

% The English machine-generated peer reviews exhibited easily distinguishable features, tending to follow predictable patterns. It commonly gave decisions in a specific format such as ``Decision: Accepted'', which was rarely seen in human texts. The MGT also commonly used labeled headings like ``Strengths'' and Weaknesses to structure peer reviews. Additionally, the MGT sometimes explicitly summarizes multiple reviews while the human texts were never as explicit or rarely included a summarization of multiple reviews. 

% the text could be expressed as a paragraph. The choice of bullet symbol that was used showed little to no variation, and the frequent use of bullet points was extremely common among MGT. 
% Additionally, many MGT responses were of similar length and were generally longer than human texts.

% The Human texts do not seem to follow a pattern, uncommonly contained bulleted lists of any kind, and varied large amounts in length while still being shorter than the MGT majority of the time.

% \textit{Improved prompt:}
% ``Generate a meta review based on the reviews' opinions and authors' rebuttal to make the final decision on whether the paper should be accepted: \texttt{\{Reviews\}}$\backslash $n$\backslash$n. When generating, don't use rigid format or structure such as ``Decision: XX" or headings such as ``Strengths", ``weaknesses" or bullet points. $\backslash $n$\backslash$n
% Meta review:"

Human detection accuracy is 99.75\%.
Before seeing labeled samples, the annotator found the distinction was obvious. After reviewing a few examples, the annotator was extremely confident in distinguishing human-written from machine-generated text based on indicative features of MGT. 

Machine-generated peer reviews exhibited distinct, predictable patterns. They frequently followed a structured format, often providing explicit decisions as ``Decision: Accepted'', which was rare in human-written reviews. MGT also commonly used headings such as ``Strengths'' and ``Weaknesses''. MGT tended to explicitly summarize multiple reviews while the human reviewers rarely did. An example of MGT is like ``Based on the reviews, this paper presents methods for embedding numerical features to improve deep learning models for tabular data. The key points are:''.

MGT additionally presents a notable preference for bullet points, even when a paragraph format was feasible, with minimal variation in bullet style. MGT responses tend to be more uniform in length and generally longer than human reviews. In contrast, human-written meta reviews lacked a fixed structure, rarely used bullet points, and exhibited greater variation in length, though they were typically shorter than MGT.




\subsection{Hindi News}
% : Raj
An overall accuracy of 85.17\% was achieved in distinguishing between the machine-generated and human-written Hindi BBC news articles.
The analysis reveals key stylistic and content-based distinctions.
One significant observation was that machine-generated news content tended to be more concise, presenting less overall information compared to its human-written counterpart. Additionally, machine-generated articles included fewer mentions of names of persons and specific dates, elements that are typically embedded within human-authored news to enhance credibility and specificity.

Furthermore, stylistic disparities were evident, particularly in the absence of colloquial language elements commonly used by human authors. Human-written articles often incorporate idioms, culturally significant phrases, and even a blend of Urdu vocabulary, reflecting the linguistic diversity and nuance of the Hindi language. These elements, however, were noticeably missing in machine-generated content, which instead adhered strictly to the main topic, with minimal linguistic or thematic deviations. This adherence to topic, while adding to clarity, lacked the depth and regional authenticity often present in human-created Hindi news content. Also there was use of English text in the machine generated version.


\subsection{Italian News}
Based on human text from DICE dataset~\citep{bonisoli2023}, we randomly selected machine-generated text from GPT-4o, Anita \citep{polignano2024advanced} and Llama3-405B \citep{llama3} outputs, resulting in total of 300 (human, MGT) pairs.
A native Italian speaker was asked to choose which text is human-written. Detection accuracy is 88.0\% for Anita, 99\% on Llama3-405B and 100\% for GPT-4o.
% Annotation Setting 1: Two options (A and B) are presented, and the task is to choose which text is human-written. For machine-generated text, either GPT-4o, Anita \citep{polignano2024advanced} or Llama-405b \citep{llama3} outputs are randomly selected (300 samples).

% Annotator Background: The annotator is a native Italian speaker.
% Accuracy: (DIcE: anita: 88.0\%, Llama-405b: 99\%, GPT-4o: 100\%).

% \paragraph{DICE Dataset} 
We identified the following distinguishable signals. 
When generating news, all models especially the larger ones, Llama-405b and GPT-4o have consistent formatting, e.g., article title is always enclosed in markdown-like double asterisks ``**'', the city where the issue happens is always mentioned first. These cues are immediately recognizable. After seeing only 2-3 examples, human annotator was confident to make decisions and obtain close to 100\% detection accuracy.


% \paragraph{CiTA Dataset} The main identification style is that models tend to generate more imaginative texts when compared to kids. The latter tend to tell real stories and not go into too much detail about their stories, while the former tend to add irrealistic events seemingly overestimating the imaginative component of a text written by a 11 or 12 years old child.


\subsection{Japanese News}
\label{japanese_news_distinctive_clues}
% : Masahiro and Ryuto
We divided 300 pairs into two groups and two annotators independently annotated them, to identify which text was a human-written BBC news article.
% The dataset consisted of BBC news headlines with articles - one written by a human and the other generated by an LLM for the headline.
% Our experimental results showed that 
Human annotators achieved an average accuracy of 62\%. % in distinguishing between human and LLM-generated texts. 
We identified several distinctive characteristics of LLM-generated texts:
\begin{itemize}
    \item \textbf{Style:} Some texts failed to match news writing styles.
    For instance, in Japanese, writing typically either uses the \textit{desu/masu} or \textit{dearu} style.
    While news articles conventionally use the \textit{dearu} style, LLM-generated texts often use the \textit{desu/masu} style.
    \item \textbf{High reliance on headlines:} The opening sentences frequently relied on the title (headline), either through direct repetition or close paraphrasing.
    \item \textbf{Formulaic phrase:} LLM outputs sometimes contained formulaic phrases like \textit{This article is provided as fiction} or \textit{Here are five reasons: 1. ...}.
    \item \textbf{Typos and grammar issues:} We observed various typographical errors and fluency issues, such as \textit{This four has shocked the entire UK} or \textit{An event that shook the air in Myanmar}.
\end{itemize}
These findings suggest that LLMs have not yet fully mastered the stylistic conventions of news writing.
% It is known that explicit instructions in LLM detection significantly affect the results~\cite{koike-etal-2024-prompt}, indicating that it is necessary to provide 
Explicit instructions that indicate the domain-specific format and style may help the LLM output.




\subsection{Kazakh Wikipedia}
Two native Kazakh speakers annotated 300 (human, \gptfouro) pairs under the setting I, with detection accuracy of 79.67\%.
% Annotation Setting 1: Two options (A and B) are presented, and the task is to choose which text is human-written. For machine-generated text GPT-4o model output was presented.
% Annotator Background: The annotators are native Kazakh speakers.
% Accuracy: 79.67%.
We summarized the following features of MGT.
\begin{itemize}
    \item The generated text lacks diversity in expression, often using repetitive sentence patterns and predictable phrasing, such as frequently ending with ``bolyp tabylady'', which contributes to a mechanical and formulaic feel.
    \item The generated text rarely includes concrete facts, such as numbers or years, and when they do appear, their occurrence is minimal.
    \item The text also frequently includes flattering language, which can be another signal of its artificial nature.
    \item Human-written texts include more Kazakh-specific cultural references where applicable, making them more relatable and authentic, which serves as a clear signal of human-generated content over LLM-generated text.
\end{itemize}



\subsection{Russian}
% Joni
\paragraph{News Articles}
A native Russian speaker (NLP PhD student) annotated 300 examples under the setting I, where machine-generated text was randomly selected from either GPT-4 or Vikhr outputs. Accuracy is 100\%. 
We found that human texts often include specific details like exact dates, numbers, names of people, places, or things (especially those not mentioned in the title or from ordinary backgrounds), as well as ages and other specifics. Additionally, human-written texts tend to reference sources, which is a strong indicator.

% 1. Annotation Setting 1: Two options (A and B) are presented, and the task is to choose which text is human-written. For machine-generated text, either GPT-4 or Vikhr outputs are randomly selected (300 samples).
% 2. Annotator Background: The annotator is a native Russian speaker (myself).
% 3. Accuracy: 100\% (‘Russia,’ ‘World,’ ‘Economy,’ ‘Sport,’ ‘Culture,’ and ‘Science and Technology.’)
% 4. Human-Written Indicators: Human texts often include specific details like exact dates, numbers, names of people, places, or things (especially those not mentioned in the title or from ordinary backgrounds), as well as ages and other specifics. Additionally, human-written texts tend to reference sources, which is a strong indicator.


\paragraph{Academic Article Summaries}
A native Russian speaker (NLP PhD student) was asked to identify whether the given text is human-written or machine-generated under the setting III. Single-binary. A text is randomly chosen from human-written, GPT-4, or Vikhr outputs (300 samples).
The overall accuracy is 80\% (Psychology: 80.0\%, Mechanical Engineering: 74.0\%, Agriculture and Forestry: 74.0\%, Geology: 86.0\%, Biology: 86.0\%, and Energy: 80.0\%).
There are several indicators. Machine-generated texts, especially from Vikhr, often begin with a paraphrased version of the title, which is a strong indicator. Human-written texts typically contain details such as numbers, references, and names. In some Vikhr outputs, sentences may lack coherence, and even after preprocessing, certain artifacts remain visible in the text.


% 1. Annotation Setting 3: The task is to identify whether the text is human-written or machine-generated. The dataset consists of 300 samples, and for each title, a text is randomly chosen from human-written, GPT-4, or Vikhr outputs (300 samples).
% 2. Annotator Background: The annotator is a native Russian speaker (myself).
% 3. Accuracy: 80\% (Psychology (80.0\%), Mechanical Engineering (74.0\%), Agriculture and Forestry (74.0\%), Geology (86.0\%), Biology (86.0\%), and Energy (80.0\%)).
% 4. Machine-Generated Indicators: Machine-generated texts, especially from Vikhr, often begin with a paraphrased version of the title, which is a strong indicator. Human-written texts typically contain details such as numbers, references, and names. In some Vikhr outputs, sentences may lack coherence, and even after preprocessing, certain artefacts remain visible in the text.






\subsection{Vietnamese}
% : Minh
We annotated 600 news summaries and 600 Wikipedia introduction passages in the setting of I. Pair-binary. 
We obtained accuracy of 80.33\% on news summaries, but random guess 50.67\% on Wikipedia text, showing minimal differences between human-written and machine-generated Wikipedia passages.

A key finding was that, for news articles, human tends to provide more details to support the statement (such as date, location, and other specific information), while LLMs tend to offer a general summary. Besides, GPT-4o usually uses short sentences in summaries, but Vietnamese journalists usually write long sentences.

For Wikipedia passages, it is much harder for humans to distinguish since GPT-4o was well-trained on Wikipedia data.
% also, it has a good knowledge about some common topics on the Internet. 
% Since the passages are informative, 
The differences between human-written and machine-generated Wikipedia text is minor, but there are still some distinctions.
For example, when GPT-4o was asked to write about Hai Phong city, city demographics and geography are expected, while it generated a review-like sentence:
% GPT-4o tends to write a passage including some information that a normal human doesn't look for (e.g. When it writes about Hai Phong city, normally, we usually looking for the city demographics, geography, etc., but GPT-4o has a sentence 
\textit{Modern infrastructure, along with open investment policies, have helped Hai Phong become an attractive destination for domestic and foreign investors, contributing to the city's sustainable development.}
%. This is similar to a review article rather than a normal Wikipedia introduction.

% \begin{table}[t]
%     \centering
%     \resizebox{\columnwidth}{!}{
%         \begin{tabular}{lcccc}
%             \textbf{Dataset} & \textbf{Accuracy} \\
%             \midrule
%             Vietnamese news & 80.33 \\
%             Vietnamese Wikipedia introduction passage & 50.67 \\
%             \bottomrule
%             \label{tab:tweets aaccuracy}
%         \end{tabular}
%     }
%     \caption{Accuracy rates for Human and Machine-generated passages across different domains.}
%     \label{tab:vietnamese_acc}
% \end{table}
