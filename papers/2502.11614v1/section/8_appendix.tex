\clearpage
% \onecolumn
\section*{Appendix}
\appendix

\input{section/2_relatedwork}
\input{section/app_datasets}
\input{section/app_distinguishable_features}
\input{section/app_prompting_fill_gap}



\subsection{Subjectivity in Fill-the-gap Survey}
\label{app:subjectivity-test}
\begin{figure*}[t!]
    \centering
    \includegraphics[scale=0.6]{section/images/IAA-heatmap.pdf}
    \caption{Three annotator agreement on Chinese essays regarding whether the improved prompts mitigate the gap between human text and machine-generated text.}
    \label{fig:iaa-heatmap}
\end{figure*}

To examine the subjectivity of this survey, i.e., the variation between annotators when evaluating the same set of examples, we asked three annotators who previously detected Chinese student essays to assess the same set of newly generated essays and measure their inter-annotator agreement over 200 cases.
\figref{fig:iaa-heatmap} shows that the two postdoc annotators exhibit a higher correlation, whereas the female PhD annotator demonstrates significant disagreement with them.
This suggests that annotators' backgrounds influence the survey results, and individual biases are not negligible factors.
To obtain more objective results, we conducted a second round of detection on the new generations, as we believe detection accuracy provides a more objective measure.

\subsection{Automatic Detection Data and Results}
\tabref{tab:multilingual_prompt_dist} presents the distribution of data used in automatic MGT detection, and the results are shown in \figref{fig:auto-acc-diff}. 19 among 26 automatic detection approaches demonstrate lower detection accuracy on the improved generations produced by the adjusted prompts.

\begin{figure*}[ht!]
    \centering
    \includegraphics[scale=0.55]{section/images/auto-acc-bars.pdf}
    \caption{\textbf{Detection accuracy differences} of 26 automatic machine-generated text detection approaches on original vs. improved generations.}
    \label{fig:auto-acc-diff}
\end{figure*}

\begin{table*}[ht]
\centering
\scalebox{0.7}{
\begin{tabular}{>{\raggedright\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{2cm}>{\raggedleft\arraybackslash}p{1.9cm}>{\raggedleft\arraybackslash}p{1.6cm}>{\raggedright\arraybackslash}p{12cm}}
\hline
\rule{0pt}{2.5ex}Source / Domain & Language & \# Improved & \# Original & LLM Generator List \rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}QA & Chinese & 3422 & 9842 & GPT-4o (3421), GPT-4o-mini (6845), GPT-4o-2024-05-13 (2998)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}Essay & Chinese & 849 & 702 & Claude-3-5-Sonnet (773), GLM-4-9B-Chat (778)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}GovReport & Chinese & 16776 & 0 & Baichuan2-13B-Chat (5521), ChatGLM3-6B (5359), GPT-4o (5896) \rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}News & Hindi & 0 & 1199 & GPT-4 (600), Human (599)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}News & Japanese & 0 & 300 & GPT-4o (300) \rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}News & Russian & 5915 & 600 & GPT-4o (3921), Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24 (3224)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}Sunmary & Arabic & 153 & 153 & GPT-4o (306)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}Sunmary & Russian & 5944 & 585 & Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24 (3279), GPT-4o (3300)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}Tweets & Arabic & 2800 & 214 & GPT-4-Turbo (1400), GPT-4 (1545), Qwen2.5 72B (69)\rule[-1.2ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex}Total & -- & 32,487 & 17,017 & -- \rule[-1.2ex]{0pt}{0pt}\\
\hline
\end{tabular}
}
\caption{Statistics of data used in automatic detection: generations using original and the improved prompts.}
\label{tab:multilingual_prompt_dist}
\end{table*}

\subsection{Why do Human Preference strongly differ in Zhihu QA?}
\label{app:humanpreference}
% \paragraph{Why do we strongly differ in Zhihu QA?}
We summarized three major reasons.

\textbf{Mean-spirited human Zhihu answers.}
One of the female annotators prefers responses that are sincere, authentic, and uplifting. However, many human-written responses tend to show the dark aspects of society by often adopting a strongly negative tone through harsh, sarcastic, or offensive remarks targeting specific groups. While these responses may contain some facts, they present a narrow, subjective perspective rather than a comprehensive view. In such cases, a more positive or neutral response is generally perceived as more mature and reasonable, aligning with Chinese cultural norms of expressing individual opinions in a mild and modest manner.  

This does not imply that machine-generated responses are ideal. When asked for personal opinions, LLMs typically provide generic, average viewpoints that lack depth, wisdom, and inspiration. Human annotators tend to prefer personalized, insightful reflections and suggestions informed by real experiences and critical thinking, rather than generic statements that merely reiterate common knowledge. This limitation may stem from their lack of personal experiences and the inability to internalize knowledge into a coherent philosophical perspective or behavioral framework.
Also, human answers would extend the answer from the current topic to other relevant topics, rather than only responding to this question.
They can tell from the history and naturally incorporate personal thoughts into it, while models do not have this ability or nature. 


\textbf{Humans more trust human suggestions.}
For questions asking for clinical suggestions, graduate program application experience, recommendation of restaurants, educational institution, tutoring courses, and teacher in a city, town or even a district, humans tend to trust more on human answers than model generations.
These questions require either expert knowledge or real personal experience.
Compared with model generic opinion and suggestions, humans offer advice in a way of real professional expertise or share firsthand experience with more details, feeling and suggestions, preferred by individuals.
 % qid = 264: 同大插班生和科兴教育辅导机构今年各学校都考走了多少学生？@科兴教育@同大插班生
For example, \textit{How many students did Tongda Students and Kexing Education Tutoring Institution get admitted to top universities this year?} Kexing Education and Tongda Students are two external tutoring schools to help improve scores of high school students in admission exams. This internal information is only known by a small group of people in these tutoring schools. LLMs generation must be less trustworthy and are even factually incorrect. 
% Question 250 :
% Quesion: ﻿如何评价《濑户内海》这篇小说？ 我的资讯--网易云阅读如题
% Inconsistency in model generations and factual errors


\textbf{Emotional and complex relationship issues are difficult for models.}
Sometimes it is difficult for models to understand complex relationship and emotional issues and provide practical suggestions.
For example, \textit{I have 87 days left until the college entrance exam as a student who attended this exam the second time, and my girlfriend, who is in university, and we have been together for over 450 days. When I went to see her, she told me she was exhausted and that I couldn't provide the support she needed. She said that I was not someone who could stand by her through tough times. Since this was my first relationship, I don't know how to do. She broke up with me decisively.}
In such a scenario, human responses are more realistic and practical, comforting from their own relationship experience and offering suggestions though some words can be more polite and kind.


