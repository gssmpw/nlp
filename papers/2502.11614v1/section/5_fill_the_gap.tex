\section{Can Prompting Fill in the Gap?}

% As we saw above, there are distinctions between human-written and machine-generated text. % in \secref{sec:human-detection-acc}. 
Given that LLMs can strictly follow instructions and their outputs are heavily influenced by the system and the user prompts, we investigated whether explicitly instructing LLMs to mimic human style can help narrow the gap. 
Responding to the distinguishable factors summarized in \appref{sec:distinctionfactor} for each dataset, we asked the human annotators to craft new prompts, aiming to improve the generations and to reduce the gap between human-written and LLM-generated texts. This involved trying instructions that (1) incorporate specific details and references, (2) avoid formulaic structures and formats, e.g., bullet points and Markdown, and (3) generate texts of varying length, structure, and sentiment.
\tabref{tab:ori-improved-prompts} presents the results for both the original and the improved prompts for all datasets.  


\textbf{Measurements:}
We re-generated the machine-generated parts of the text pairs, using the same models with improved prompts, and then sampled 200â€“600 examples from each dataset to assess whether and to what extent, the prompting strategy narrowed the gap between human-written and machine-generated texts. 
We used two approaches: (1) \textit{fill-the-gap survey}, where the original annotators evaluated whether the newly-generated text bridged the gap (Yes, No, or Partially), and (2) \textit{downstream detection}, where we compared the detection accuracy before and after applying the improved prompts. A decline in detection accuracy indicated a reduced distinction between human and machine text, making the differentiation more difficult, and further revealing that prompting was effective. Our experiments involved both human annotator evaluation and automated detection. 

\begin{figure}[t!]
    \centering
    \includegraphics[scale=0.38]{section/images/dist-stackedbar.pdf} 
    \caption{Evaluating whether the new generations fill in the gap: Yes, Partially, or No.}
    \label{fig:dist-survey}
\end{figure}

% \begin{figure*}[t!]
%     \centering
%     \includegraphics[scale=0.6]{section/images/dist-stackedbar.pdf} 
%     \caption{Distribution of survey evaluating whether the new generations fill the gap? Yes, Partially or No.}
%     \label{fig:dist-survey}
% \end{figure*}

% \begin{figure*}[t!]
%     \centering
%     \includegraphics[scale=0.6]{section/images/IAA-heatmap.pdf}
%     \caption{Three annotator agreement on Chinese essays regarding whether the improved prompts mitigate the gap between human text and machine-generated text.}
%     \label{fig:iaa-heatmap}
% \end{figure*}

% \begin{figure*}[t!]
%     \centering
%     \includegraphics[scale=0.55]{section/images/acc-bars.pdf}
%     \caption{Human detection accuracy differences on original vs. improved generations.}
%     \label{fig:acc-diff}
% \end{figure*}

% \begin{figure*}[t!]
%     \centering
%     \includegraphics[scale=0.55]{section/images/auto-acc-bars.pdf}
%     \caption{\textbf{Detection accuracy differences} of 26 automatic machine-generated text detection approaches on original vs. improved generations.}
%     \label{fig:auto-acc-diff}
% \end{figure*}

\paragraph{Fill-the-gap Survey}
The original annotators who conducted the detection on earlier generations were asked to evaluate whether the new prompts addressed the gaps for each example: \emph{Yes}, \emph{No}, and \emph{Partially}.
The distributions across the six datasets in \figref{fig:dist-survey} shows that in about 50\% of the cases, the prompt adjustments were effective to  either fully or partially mitigate the gaps. Large improvements were observed for Kazakh Wikipedia and Arabic tweets.
For the former, the revised prompt reduced repetitive sentence patterns (more diverse), but the formulaic expressions were not entirely eliminated. New outputs also included more concrete information, such as dates and names, while the inclusion of culturally-nuanced details remained challenging. The newly-generated Arabic tweets could touch on relatable human topics and express genuine emotions tied to daily experiences; however, the frequently added irrelevant hashtags at the end of the tweets made them easily identifiable as machine-generated. Moreover, the tweets often leaned on an overly optimistic tone even when negative experiences were mentioned. 

The annotators for English peer reviews noted that, despite the prompt adjustments, the models remained highly formulaic in their outputs, the length of the reviews remained relatively uniform, and the overall structure lacked variance. This may be due to the inherent nature of the peer review domain, while human reviews exhibited more variability in both length and structure, feeling more organic.
Similar issues remained for Chinese student essays (formulaic structure by using ``firstly, then, moreover, finally'' persisted) and government reports (certain repetitive phrases). 

% \textit{What remains challenging to address?}
Overall, adjusting the prompts did fill some gaps, but cultural nuances, diversity of length, structure and phrases, and sentiment adaption to scenarios remained challenging. See more in \appref{sec:fill-gap-prompts}.
Since annotators' background may influence the survey results (see \ref{app:subjectivity-test}), we conducted a second round of MGT detection on the new generations with the hop   e for more objective results.


\begin{figure}[t!]
    \centering
    \includegraphics[scale=0.4]{section/images/acc-bars.pdf}
    \caption{Human detection accuracy for the original vs. the improved generations.}
    \label{fig:acc-diff}
\end{figure}

\paragraph{MGT Detection on Improved Text}
We performed human detection on 13 datasets under the same annotation setting as described in \tabref{tab:detection-acc}, with the exact same annotators.
We observed sizable accuracy declines across all datasets in \figref{fig:acc-diff}, with average accuracy dropping to 72.5\%.
This implies that the improved machine-generated text became more similar to the human-written text, making it harder to discern and thus resulting in lower detection accuracy.


% \paragraph{Automatic Detection}
We further analyzed the impact of the improved generations on automatic detection accuracies.
% provide a quantitative analysis,
We collected a total of 17,017 texts using the original prompts and 32,487 texts using the improved prompts (detailed statistical distribution in \tabref{tab:multilingual_prompt_dist}).
We reproduced 26 MGT detection approaches presented in the COLING 2025 GenAI shared task~\cite{wang-etal-2025-genai} and evaluated them on the collected MGTs. As shown in \figref{fig:auto-acc-diff}, 19 methods exhibited lower accuracy on the newly generated texts, indicating that the texts produced using the improved prompts are more challenging to distinguish compared to those generated with the original prompts.
This suggests that prompting strategies can help bridge some gaps between machine-generated and human-written text when explicitly designed to mimic human writing style.



\begin{comment}
Interestingly, when we explicitly tell annotators that the given text is newly-generated and ask them to analyze whether the gaps have been resolved, they can clearly identified what issues are remained. When they are asked to distinguish between the improved machine-generated text and human-written text, some cases are harder for them to differentiate, leading to lower accuracy.
% We believe further research could analyze the impact of human attention in such tasks.
\end{comment}