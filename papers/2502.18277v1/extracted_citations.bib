@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{bjorck2018understanding,
  title={Understanding batch normalization},
  author={Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{graves2012long,
  title={Long short-term memory},
  author={Graves, Alex and Graves, Alex},
  journal={Supervised sequence labelling with recurrent neural networks},
  pages={37--45},
  year={2012},
  publisher={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{lillicrap2020backpropagation,
  title={Backpropagation and the brain},
  author={Lillicrap, Timothy P and Santoro, Adam and Marris, Luke and Akerman, Colin J and Hinton, Geoffrey},
  journal={Nature Reviews Neuroscience},
  volume={21},
  number={6},
  pages={335--346},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, R},
  journal={arXiv preprint arXiv:1211.5063},
  year={2013}
}

@article{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{xu2019understanding,
  title={Understanding and improving layer normalization},
  author={Xu, Jingjing and Sun, Xu and Zhang, Zhiyuan and Zhao, Guangxiang and Lin, Junyang},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{zhang2019gradient,
  title={Why gradient clipping accelerates training: A theoretical justification for adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  journal={arXiv preprint arXiv:1905.11881},
  year={2019}
}

