In this section, we first introduce the necessary notations, and then we expand on three physically motivated linear mixing models of interest, more precisely the LMM, SLMM and ELMM.

\subsection{Notation}

We will denote by $K$ the number of endmembers, by $N$ the number of pixels, and by $P$ the number of spectral bands. The abundance matrix is written as $\A \in \real^{K \times N}$, and the abundance vector of the $n$-th pixel is denoted by $\mathbf{a}_n, n = 1,2,\ldots, N$. Endmembers are denoted by the matrix $\E \in \real^{P\times K}$, and individual endmembers by $\e_k, k=1,2,\ldots,K$. An image matrix is denoted by $\mathbf{X} \in \real^{P \times N}$, and a single pixel is written as $\x_n, n=1, 2, \ldots, N$. Let $\|\mathbf{v}\|_p$ denote the $p$-norm of a vector $\mathbf{v} \in \real^D$:
\[
\|\mathbf{v}\|_p = \left(\sum_{d=1}^D |v_d|^p\right)^{\frac{1}{p}}
\]
and let $\|\mathbf{B}\|_{p, q}$ denote the $L_{p, q}$-norm of a matrix $\mathbf{B} \in \real^{M \times D}$:
\[
\|\mathbf{B}\|_{p, q} = \left(\sum_{d=1}^D \left( \sum_{m=1}^M |b_{md}|^p\right)^\frac{p}{q}\right)^\frac{1}{q}.
\]
In particular, let $\|\mathbf{B} \|_{2,2} := \|\mathbf{B} \|_F$ denote the Frobenius norm of a matrix. Furthermore, let $\mathrm{diag}(\mathbf{v})$ denote the diagonalization operator of a vector:
\begin{multline*}
    \mathrm{diag}: \real^D \rightarrow \real^{D \times D} : \\
    \mathbf{v} = \left( \begin{array}{c}
    v_1 \\ v_2 \\ \vdots \\ v_D
\end{array}\right) \mapsto \diag(\mathbf{v})=
\left(\begin{array}{cccc}
    v_1 & 0 & \cdots & 0 \\
    0 & v_2 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \cdots & v_D
\end{array}\right).
\end{multline*}

\subsection{Unmixing with the Linear Mixing Model}
The LMM assumes that every pixel can be written as a convex combination of EMs which are the same across the entire image. Under the LMM, variability in the scene is only caused by EMs appearing in different concentrations. Mathematically, the LMM can be written as
\begin{equation} \label{eq: linear mixing model}
    \x_n = \sum_{k=1}^K \e_{k} a_{kn} =  \E \mathbf{a}_n
\end{equation}
where there are two constraints to be imposed on $\mathbf{a}_n$ in order for the abundances to satisfy the convex combination constraint, and to make them physically meaningful: the \textit{abundance non-negativity constraint} (ANC) $\mathbf{a}_n \geq 0$, and the \textit{abundance sum-to-one constraint} (ASC) 
$\sum_{k=1}^K a_{nk} = \mathbf{1}^\top \mathbf{a}_n = 1$.

Performing unmixing with the LMM can be done using a convex least-squares optimization approach known as Fully Constrained Least-Squares Unmixing (FCLSU):
\begin{equation} \label{eq: fclsu}
    \begin{aligned}
    \min_{\mathbf{a}_n} &~ \frac{1}{2} \|\hat{\x}_n - \E \mathbf{a}_n\|^2_2 \\
    \mathrm{s.t.} &~ \ba_n \geq 0 \quad \text{(ANC)} \\
    &~\mathbf{1}^\top \ba_n = 1 \quad \text{(ASC)}
    \end{aligned}
\end{equation}
This is a convex quadratic program with both equality and inequality constraints. Therefore, one of the many well-established methods for solving constrained quadratic programs can be used for solving FCLSU. A well-known method is the active set method \cite{nocedal_numerical_2006}. This method works by identifying a set of active constraints, which are the constraints that are currently being treated as equality constraints. The algorithm then solves a simpler subproblem with only equality constraints, and iteratively updates the active set until the optimal solution is found. Another option is the interior-point method, which will be discussed later in this paper.

\subsection{Unmixing with the Scaled Linear Mixing Model (SLMM)}
The SLMM assumes that EMs can change from pixel to pixel by means of a scaling, and this scaling is the same for all EMs within a pixel. In this way, the SLMM generalizes the LMM by introducing a pixel-wise scaling factor $s_{\x_n} > 0$:
\begin{equation}
    \x_n = s_{\x_n} \E \ba_n.
\end{equation}
Unmixing with the SLMM is commonly done by a non-negative least-squares approach, by dropping the ASC in problem (\ref{eq: fclsu}). The abundances are then obtained via a post-processing normalization step. Let $\Tilde{\ba}_n$ denote the non-normalized abundances, then $s_{\x_n}$ and $\ba_n$  are given by:
\begin{equation}\label{eq: normalization}
            s_{\x_n} = \sum_{k=1}^K \Tilde{a}_{nk}, \quad \ba_n = \frac{\Tilde{\ba}_n}{s_{\x_n}}.
\end{equation}
This method is called the (partially) constrained least-squares unmixing (CLSU). A widely used algorithm for solving CLSU is the Lawson-Hanson method \cite[Ch. 23]{lawson_solving_1995}, which is also used by the \textsc{Matlab} solver \texttt{lsqnonneg} in a slightly adapted form.

\subsection{Unmixing with the Extended Linear Mixing Model (ELMM)}
Since spectral variability is often material-specific (e.g., in the case of topography-induced variability, as is evident from Hapke's model), the SLMM fails to accurately model many real-world scenes. Rather than a single scalar scaling, the ELMM introduces a scaling vector in every pixel, allowing each EM to be scaled differently in every pixel, which facilitates modeling more complex and material-specific variability \cite{drumetz_blind_2016}.  Define a pixel scaling vector $\s_n \in \real^K$ for every pixel, then the ELMM reads:
\begin{equation}
    \x_n = \E \mathrm{diag}(\s_n) \ba_n.
\end{equation}
Performing unmixing with the ELMM is done using  a regularized version of the least-squares cost function, that iteratively updates the abundances and scaling factors. For the update of the abundances $\A$, an ADMM algorithm is used, while the update for the scaling factors $\bS$ can be done analytically. The algorithm is initialized with the abundance estimates obtained from CLSU to improve performance. The ELMM is highly non-convex and  it requires careful tuning of the regularization parameters to achieve the best possible performance. As will be shown in the experiments, it is also very dependent on the initialization.