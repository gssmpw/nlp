% models exist
% problem exists
% Many applied data domains can be represented as event sequences: store purchases, bank transactions, and people's behaviour. In this work, we mostly consider transactional data. 
% A large amount of transactional data and its relevance to various problems of describing users' behaviour make such representations an important tool in bank practice. 
% However, models for this type of data usually do not consider external information that can change over time and influence the sequences of events under consideration.

Representation learning produces models in different domains, such as store purchases, client transactions, and general people's behaviour. 
However, such models for sequential data usually process a single sequence, ignoring context from other relevant ones, even in domains with rapidly changing external environments like finance or misguiding the prediction for a user with no recent events. 


We are the first to propose a method that aggregates information from multiple user representations augmenting a specific user one for a scenario of multiple co-occurring event sequences.
Our study considers diverse aggregation approaches, ranging from simple pooling techniques to trainable attention-based approaches, especially Kernel attention aggregation, that can highlight more complex information flow from other users.
The proposed method operates atop an existing encoder and supports its efficient fine-tuning. 
Across considered datasets of financial transactions and downstream tasks, Kernel attention improves ROC AUC scores, both with and without fine-tuning, while mean pooling yields a smaller but still significant~gain. 

% In the case of a frozen encoder model, attention-based aggregation significantly improves the quality of a model, while simpler pooling also improves the model that ignores external context. 
% Additional, the paper proposes an efficient procedure for fine-tuning an encoder to increase quality of aggregation. For it, attention-based aggregation provides an even better model; this time, pooling performs only slightly worse. 




% Our adoption of an attention-based method leads to improved representations for a particular moment of a considered sequence.
% We consider the inclusion of external information to describe each sequence's current state more accurately. 

%This attention-based aggregation improves quality for the downstream problems, demonstrating the importance of a proper aggregation for better representation quality.
%As evidence this is we show the improvements in quality for the downstream tasks, which demonstrate the importance of a proper aggregation for better representation quality.

% we propose a solution
% idea of a solution: attention-based aggregation, efficient, high-quality solution

% In this work, we consider external information to describe each sequence's current state more accurately. We take into account the external context by aggregating all sequence representations at the current time moment. We present and compare different types of such aggregation in different learning pipelines: contrastive and generative.
% Another important part of the project was validating the developed methods and models.

% In this work, we consider external information to describe each sequence's current state more accurately. 
% We consider efficient attention-based methods of the external context aggregation of all sequence representations at the current time moment.


% experimental evaluation: datasets with downstream problems, both local and global (event sequences - we talk about downstream problems)
% metrics, compare (vs mean vs vanilla)

% In this work, we consider external information to describe each sequence's current state more accurately. 
% We consider efficient attention-based methods of the external context aggregation of all sequence representations at the current time moment.

% The proposed models were considered as encoders in the context of solving applied downstream tasks in the banking sector.  Considered tasks included credit scoring and fraud detection.
% The obtained results show that the developed models work better than similar ones, that don't account for external information in terms of representations' global and local properties.
% The resulting model for constructing representations will allow us to solve a wide range of problems and can be implemented in the real world, for example in the bank.
% Its use will improve the quality of the decision-making process and will allow the use of event sequence representations in various applications.

