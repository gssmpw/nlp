\section{Conclusion and discussions}

We consider creating representations for transaction sequences, which are nonuniform event sequences. 
Our main contribution is the introduced methods for incorporating external contextual information, which enhance the quality of existing approaches and foundational solutions. 
We believe these aggregations can represent the both external context information, for example, macroeconomic parameters~\cite{begicheva2021bank} and behaviour of close users. 
The paper considers a range of methods for such aggregations based on pooling, attention mechanisms, and those inspired by the self-exciting temporal point process. 
% Also, we show that increasing the number of sequences improves the quality of representations.

The representations obtained using the addition of external context vectors are of better quality for applied problems, particularly those in the bank transaction data domain and churn, credit scoring, and fraud detection tasks. 
The most effective results were achieved using a trainable attention mechanism, which identifies the clients closest to the user under consideration.
In particular, the Kernel attention method was the best among all the considered methods. 
Mean and Max aggregations also show good results without requiring additional learning. 
Further improvement can be achieved by fine-tuning the model to better suit the aggregation pipeline.

The proposed pipeline is easy to include in large-scale industrial data processing, as the computational overhead for the introduced methods is negligible. 
We provide code for replicating the conducted experiments that can be easily included in existing open packages.

Although this work presents a broad comparative analysis of various methods of adding context information, considering diverse ideas, and testing them on diverse datasets and corresponding problems, we believe that further developments in this area would benefit the industrial and scientific communities.
First, a broader range of aggregation methods makes sense in this problem statement. 
This is also true for their training.
Another important question is how to define the best aggregation method for a specific dataset.
A high-level split would include two options: we design a single context for all users, or we create a specific context vector for each user. 
The experiments provided showed that while the second option with Kernel attention improves the quality, the improvement, if compared to pooling, can be marginal.
Another possible area for growth is a more accurate incorporation of Hawkes-process-based methods into the aggregation pipeline: our implementation led to unstable or inferior results for them while existing results suggest that better implementation could exist.
% It is interesting to propose new methods for external context analysis.
% Continuation of the development of methods based on the Hawkes process can be especially complex.  
% Secondly, it is intriguing to dive deeper into investigating methods based on attention. 
% For example, someone can compare the attention matrices obtained in the Learnable attention and Symmetrical attention approach. 
% Such research can shed light on exactly how different embeddings interact with each other.
