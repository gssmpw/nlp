\documentclass{article}


\usepackage[a4paper, total={6in, 8in}]{geometry}

\usepackage{lipsum}
\usepackage{endnotes}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{moreverb,url}
\usepackage{xcolor}
\usepackage{lipsum}  
\usepackage{footmisc}
\usepackage{enumitem}
\usepackage{float}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{authblk}
\usepackage[title]{appendix}

\usepackage[latin1]{inputenc}
\usepackage[normalem]{ulem}

\providecommand{\keywords}[1]{\small{\textbf{\textit{Keywords: }}} #1}

\date{}

\input{2013-10-19-Macros-common}

\newcommand{\emmanuel}[1]{ {\color{blue}[\noindent {\textbf{EMMANUEL:}~#1}]} }
\newcommand{\david}[1]{ {\color{red}[\noindent {\textbf{DAVID:}~#1}]} }
\newcommand{\luc}[1]{ {\color{red}[\noindent {\textbf{LUC:}~#1}]} }
\newcommand{\yann}[1]{ {\color{red}[\noindent {\textbf{YANN:}~#1}]} }
\newcommand{\mace}{Mac\'e}
\newcommand{\hl}[1]{{\color{blue} #1}}

%\title{The use of pitch uncertainty for expression and structural organisation in contemporary popular music: the case of Primaal's commercial works}

\title{Methods for pitch analysis in contemporary popular music: highlighting pitch uncertainty in Primaal's commercial works}

\author[1,3]{Emmanuel Deruty\thanks{CONTACT Emmanuel Deruty. Email: derutycsl@gmail.com}}
\author[2]{Luc Leroy}
\author[2]{Yann Mac\'{e}}
\author[3]{David Meredith}
\affil[1]{Sony Computer Science Laboratories, 6 rue Amyot, 75005 Paris, France}
\affil[2]{Neodrome Entertainment, 5 rue Vernet, 75008 Paris, France}
\affil[3]{Department of Architecture, Design and Media Technology, Aalborg University, Rendsburggade 14, 9000 Aalborg, Denmark}

\begin{document}
\maketitle



\begin{abstract}\noindent\sloppypar  We identify characteristic features of how pitch is manipulated for expressive purposes by Hyper Music, a mainstream commercial music company specialising in advertisement music for global corporations. The study shows that the use and organisation of pitch in the company's `Primaal' brand differs from Western classical music. Through interviews with producers and in-depth analysis of their work, we reveal that their methods centre on a conscious aim to construct a musical discourse based on \emph{pitch uncertainty}, contrasting with the clear transmission of well-defined pitches in Western classical traditions. According to the Primaal producers, who acknowledge the influence of artists such as Kanye West and Daft Punk and use widely available technology, pitch uncertainty captures the listener's attention. We provide analyses of musical excerpts demonstrating their approach, alongside descriptions of the tools and methods employed to achieve their expressive goals. These goals and methods are placed in a broader historical context, contrasting with fundamental principles of pitch organisation in Western music. Techniques used by Hyper Music to introduce and control pitch uncertainty include boosting upper partials, expressive use of inharmonicity, continuous pitch distributions around `poles' tied to specific `modes', and continuously evolving pitch. We examine these techniques from a psychoacoustic perspective, and conduct listening tests corroborating some of the observations. The ultimate goal of the study is to introduce a set of methods suited to the analysis of pitch in contemporary popular music.

\end{abstract}

\vspace{5mm}

\begin{keywords}
music analysis; pitch; contemporary popular music
\end{keywords}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newpage
\section{Introduction}

In this paper, we examine the elements that evoke a sensation of pitch in a small set of commercial musical works. Our analysis considers both their construction and organisation within the music. We use phenomenological reduction and summarise our findings in theoretical models. The study was conducted in collaboration with the producers, providing opportunities for validation.

The music we study is used in mainstream content like advertising, appealing to a wide audience as major brands acquire it for public representation. We focus on Hyper Music's brand `Primaal', the company's latest successful project. The Hyper Music producers, Luc Leroy and Yann Mac\'e, describe Primaal's music as electronic with urban elements. We expect that our results will apply to other music in these genres.

Our analysis shows that Hyper Music's approach to pitch differs radically from the way in which pitch is typically organised in Western classical music. In Primaal's works, tones are inharmonic. Low frequencies often fail to evoke pitch. Single complex tones can evoke multiple pitches and function as chords around which songs are structured. Pitches are distributed around scale degrees, with the spread of these distributions controlled as a musical parameter. Each song typically focuses on one or two scale degrees. Traditional chord sequences play only a minor role.

Hyper Music's producers deliberately introduce and manipulate {\em pitch uncertainty}, contrasting sharply with Western classical music, where tonal organisation and instrument design aim to {\em disambiguate\/} pitch.

The paper is structured as follows. Section~\ref{sec:Primaal} introduces Primaal's music.
Section~\ref{ref:conventions} defines terminology. Section~\ref{sec:pitch-uncertainty} provides an in-depth discussion of {\em pitch uncertainty}, and Section~\ref{sec:historical-context} places it in the context of Western music theory and psychoacoustics. Section~\ref{sec:methods-of-analysis} outlines our analysis methods. Section~\ref{sec:tools-and-techniques} describes the tools used by Mac\'e and Leroy. The analyses themselves are presented in Section~\ref{sec:analyses-of-works}. Finally, Section~\ref{sec:conclusion} summarises the paper's contributions.

Supplementary material is provided, detailing the results of preliminary listening tests and presenting signal analyses along with the corresponding audio. Sections in the supplementary material are denoted using capital letters, referenced as `SM' followed by the section letter or simply by the letter. The supplementary material can be found at:

\begin{center}
\url{https://primaal-suppl-mat.s3.eu-west-3.amazonaws.com/index.html}
\end{center}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Primaal 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Primaal}\label{sec:Primaal}


Primaal is a project of the Hyper Music production company \citep{hypermusic}, referred to in \citet{deruty2022development} and \citet{deruty2022melatonin}. In 2022 and 2023, Primaal produced music for brands such as L'Or\'eal, Adidas, Vichy, Honda, GoPro, and Chanel. The producers recognise Trent Reznor, Daft Punk, Kanye West, Skrillex, and Rosalia as influences. Roland TR-808 bass tracks, common in popular music, especially hip-hop \citep{lavoie2020}, are key to Primaal's music. We therefore assume that Primaal's production techniques reflect shared practices in the music industry.  

We analyse ten songs: `Boom' (SM~C.1--3), `Cardinal' (C.4--6), `Danger' (C.7), `Elevate (C8--9)', `Fire!' (C.10), `R U Ready' (C.11), `Silver' (C.12), `Sweet Money' (C.13), `Whomp' (C.14--15), and `Yada Yada' (C.16), selected on the basis of stem availability. Nine of these are under contracts with Alter-K \citep{AlterK2024} or Just Isn't Music \citep{Justisntmusic2024}, with one used in the upcoming Netflix series `Supacell' and another in the `Chance' perfume ad. The worldwide diffusion of Primaal's music ensures that the music we analyse in this paper is widely heard. Synchronisation of music to media typically takes ten months to two years, so more songs may have been synchronised by the time this paper goes to press.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Terminology
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Terminology}\label{ref:conventions}

In regards to tones, we use the following terminology:

\begin{enumerate}
    \item The term \emph{partial} denotes the spectral representation of a single periodic sine wave. The notion corresponds to what \citet[p.~23]{helmoltz1885sensations} call \emph{constitutents} or \emph{partial tones}.
    
    \item A \emph{harmonic complex tone} designates an ensemble of partials that are integer multiples of a fundamental frequency. The notion corresponds to what \citet[p.~23]{helmoltz1885sensations} called a \emph{compound}. We denote by $f_0$ the frequency that is the greatest common divisor for the partials' frequencies.
    
    \item An \emph{inharmonic complex tone} designates a tone that consists of an ensemble of partials that are near-integer multiples of a fundamental frequency. \citet{fletcher1962quality} and \citet[p.~9]{rasch1982perception} provide examples of such tones. Following \citet[p.~757]{fletcher1962quality}, we denote by $f_0$ the greatest common divisor of the harmonic frequencies in the harmonic complex tone that is most similar to the inharmonic complex tone. 
    
    %(i.e., it is perceived to have pitch)
    
    \item In a harmonic or inharmonic complex tone, an \emph{overtone} can be any of the partials except the one that corresponds to the fundamental frequency. The notion corresponds to what \citet[p.~23]{helmoltz1885sensations} called \emph{upper partial tones}.
    
    \item A {\em harmonic\/} is any sinusoidal component of a harmonic complex tone, with the $n^{th}$ harmonic having a frequency that is $n$ times the frequency of the fundamental (the fundamental is thus the first harmonic). The notion corresponds to what \citet[p.~23]{helmoltz1885sensations} called a \emph{harmonic upper partial tone}.
\end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Pitch uncertainty
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Pitch uncertainty}\label{sec:pitch-uncertainty}

A key feature of Primaal's music is evoking uncertainty in the perception of pitch. The producers believe this enhances perceptual richness and boosts listener appeal. 

\subsection{Aspects of pitch in Primaal's music}\label{sec:aspectsofpitch}

\subsubsection{Pitch in the production process}\label{sec:pitchdimensions}

\begin{figure}[ht]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/S_summary3.png}
  \caption{Summary of pitch-related processes in the elaboration of Primaal's music. $Q$ denotes the distribution's width. Musical parameters are framed and numbered.}
\label{fig:S_summary}
\end{figure}

Figure~\ref{fig:S_summary} summarises the processes in Primaal's music that relate to pitch. The production process involves several \textit{musical parameters} in \citepos{mcadams1999perspectives} sense:

\begin{enumerate}[label={(\arabic*)}]

    \item {\bfseries Origin of perceived pitch.} The producers rely on three techniques for producing pitch-evoking sounds:

    \begin{enumerate}[noitemsep, label={(\alph*)}]
    
      \item Using harmonic complex tones whose perceived pitches correspond to their fundamental frequencies, relating to the most common way of generating perceived pitches in Western classical music \citep{rameau1750demonstration}. 
            
      \item  
      Boosting specific overtones in complex tones so that they are heard as
      %Primaal's practice of boosting overtones makes them heard as 
      separate `tones' with independent pitches (Section~\ref{sec:loudharmonics}). In particular, the producers commonly boost the third and fifth harmonics.
      %3 and {\color{blue} major}\david{What is a `major harmonic'?} harmonic 5 as key degrees. 
      The bass often provides such partials.
      
      \item 
      Generating multiple perceived pitches
%      A perceived pitch may be generated 
through distortion, waveshaping (Section~\ref{ref:distortion}), or ring modulation (Section~\ref{ref:ringmodulation}).
      
    \end{enumerate}

  %  \emmanuel{mention each of these techniques have each own idiomaticism and provides its own affordances when selecting and organising pitches, [similar to different instruments from different cultures?] -- resulting scale versus acting scale?}\david{I think I've covered this in the next paragraph - but we need a reference for resultant and active scales at the end of the paragraph - could this be \citet[p.~82]{coeurdevey1998histoire}?}

    
The choice of the origin of a pitch (i.e., (a) fundamental, (b) boosted partial, or (c) generated partial) serves as a musical parameter. Changes in the origins of pitches used in a passage can be used to articulate a song's form and structure (Sections~\ref{sec:largescalestructure} and~\ref{sec:smallscalestructure}).
    
The choice of a particular pitch origin determines a set of affordances provided by that selected method of evoking a sense of pitch. In other words, each method of generating a pitch has its own `idiom' in a similar sense to that in which a musical instrument has its own idiom---that is, those techniques and patterns that are more natural and easy to use or perform on that instrument \citep[p.~103]{huron2009characterizing}.

The choice of a particular method of generating pitches (origin of pitch) may determine some finite set of pitches---effectively a `scale' or `mode'---from which the producer may select pitches. If one generates pitches by boosting selected partials, then the decision as to which complex tone to use as a source also determines the set of pitches (partials) from which one can select the ones to boost. This results in passages of the music being based on `resultant scales' that emerge from the choice of pitch origin, as opposed to `acting scales' that are proactively selected by the composer. This opposition is reminiscent of the shift from resultant harmony to active harmony mentioned by \citet[p.~82]{coeurdevey1998histoire} in relation to the transition from modal polyphonic writing to harmonic and tonal writing.
    
    \item {\bfseries `Pole' choice.} Perceived pitches are organised into scales with modes, typically derived from the twelve-tone chromatic scale (see Section~\ref{sec:modality}). Each scale step is realised according to a probability distribution centred on a most-probable, `pole' frequency. The pole frequencies may diverge from equal temperament. Although some of the tools used by the Primaal producers, such as the Spectrasonics Omnisphere synthesizer, include temperament settings,\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere/main/controls/page02.html/}} the producers choose not to use them.  

    \item {\bfseries Main pole.} One scale degree always takes prominence and can be compared to the final in early Western modes (Sections~\ref{sec:modalitybackground} and \ref{sec:modality}).


    
    \item {\bfseries Q.} Pitches are distributed around the scale degrees, with the distribution width set by the producers (Section~\ref{sec:dists}). The producers state that much of their music is about `hovering around a mode'.\footnote{Literal statements from the producers are between single quotes. The producers ask that we do not disclose the original transcripts of the interviews.}
    
    \item {\bfseries Stability.} Frequency instability and continuous evolutions play a role in shaping the distribution (Section~\ref{sec:continousfreqs}).
    
    \item {\bfseries Pitch strength.} Pitch strength is another musical parameter, referring to the clarity with which a pitch is perceived (\citealt{zwicker1990pitchstrength}, \citealt[p. 1708]{yost2009pitch}). In particular, drums in Primaal may have variable pitch strength (see Sections~\ref{sec:pitchcontentindrums} and~\ref{sec:tuneddrums}).

    \item {\bfseries Conformation.} Deviation from the above processes is considered a musical parameter. Such deviations can be used to articulate a song's form and structure (Sections~\ref{sec:clearertonalitylarge} and \ref{sec:clearertonalitysmall}). 

\end{enumerate}



Primaal's musical parameters relate to \citepos{schneider2009perception} dimensions for the
sounds of musical instruments:

%, according to which `[m]ost sounds produced from musical instruments can be ordered along [the following] dimensions':

\begin{enumerate}[noitemsep]
    \item `Signal', with values ranging from stationary to transient.
    \item `Periodicity', from clear to uncertain.
    \item `Spectrum', from harmonic to inharmonic.
    \item `Frequencies', from stable to fluctuating.
    \item `Pitch', from clear to ambiguous.
    \item `Typical', from the sensation of a single pitch to multiple/no pitch.
\end{enumerate}

For instance, our musical parameter (1), `Origin of perceived pitch', relates to \citeauthorpos{schneider2009perception} dimensions 5 and 6. Technique (a), using the harmonic series as a source of inspiration, leads to the clear sensation of a single pitch, while techniques (b) (boosting overtones) and (c) (generating overtones) lead to multiple and/or uncertain pitches.



\subsubsection{Consequences on pitch tracking} \label{sec:pitchtracking}



Pitch trackers extract pitches from monodic sounds using expert features \citep{drugman2018traditional} or deep-learning techniques \citep{kim2018crepe, riou2023pesto}, and may involve virtual pitch detection \citep{terhardt1979calculating, meddis2006virtual}.

The use by the Primaal producers of the seven musical parameters identified above and the way in which these parameters relate to \citeauthorpos{schneider2009perception} dimensions result in music that is resistant to automated pitch tracking. In particular, pitch trackers typically assume that one tone corresponds to one pitch, whereas `single' complex tones often evoke multiple perceived pitches in Primaal's music (relating to \citeauthorpos{schneider2009perception} dimension 6). Another problem is that the tones that evoke pitch sensations in Primaal's music are typically not harmonic, whereas automatic pitch trackers generally assume that pitch is only evoked by harmonic tones (relating to \citeauthorpos{schneider2009perception} dimension 3)
%Dimension 3 also poses a problem, as pitch trackers rely on harmonic tones, which are not typical in Primaal's music 
(see Section~\ref{sec:inharmonicity}). Another common assumption in automatic pitch trackers is that the pitch of a tone is stable throughout its duration, whereas continuous glides and fluctuations in pitch are common in Primaal's music (relating to \citeauthorpos{schneider2009perception} dimension 4)
%is another challenge, as stable note transcription is ineffective for fluctuating pitch 
\citep[p.~21]{benetos2018automatic}.

The term {\em pitch\/} refers to a {\em perceptual\/} attribute of a sound that can depend on a variety of different {\em physical\/} attributes of the sound, such as its intensity, its component frequencies and the distribution of energy across these component frequencies. In this paper, we do {\em not\/} aim to predict \textit{perceived} pitches from physical signals. References to specific frequencies or musical notes in this text (e.g., 450Hz, A4+39 cents) should therefore be interpreted as specifying physical frequencies or the periodicities of signals that are likely to be related to the perceived pitches.

\subsection{Inharmonicity}\label{sec:inharmonicity}

\subsubsection{Background}\label{sec:inharmonicitybackground}


In Primaal's music, tones are almost always inharmonic. Inharmonicity is defined as `the deviation of frequencies from an exact harmonic series' \citep{campbell2001inharmonicity}. A distinction is made between inharmonic sounds irrelevant to music (e.g., noise) and `coherent' inharmonic signals, which sound stable like harmonic signals \citep{deboer1956pitch}. We focus on inharmonicity caused by inharmonically-related partials.

%`the departure in frequency from the harmonic modes of vibration' \citep{young1952inharmonicity}, or

The relationship between inharmonic partials has been studied in piano strings \citep{young1952inharmonicity}, involving an \emph{inharmonicity coefficient} that indicates the gradual shift of partials from harmonic positions. 
%In this study, electronic and digital sources generate varied partial positions. % schuck1943observations,
Primaal's music was produced using electronic tools that allow for the generation of partials that deviate from harmonic positions.

Inharmonic complex tones may evoke one or more pitches. Thus,

\begin{itemize}[noitemsep]
\item if partials are close to harmonic positions, the tone evokes a single pitch, approximately the fundamental of the least-deviating harmonic series \citep[p.~9]{rasch1982perception}; whereas,

\item if partials are further from harmonic positions, both the fundamental and other partials may dominate \citep{jarvelainen2000effect}. As an example, \citet[p.~41]{bregman1996demonstrations} show how a partial becomes audible as a separate pitch from the fundamental as inharmonicity increases. %This shift is known as \emph{pitch-shift of the residue} \citep{schouten1940residue,deboer1956residue}.
\end{itemize}

Section~\ref{sec:severalperceived} discusses whether inharmonicity in Primaal's music results in one or several perceived pitches. We conclude that multiple pitches result from boosted partials (Section~\ref{sec:loudharmonics}) rather than inharmonicity. We carried out a listening test demonstrating that high inharmonicity can lead to listeners perceiving two separate pitches (\textbf{listening test~1}, SM A.1). 

% As mentioned in Section~\ref{ref:conventions}, we use the symbol, $f_0$, to denote that frequency component in a sound that is closest to the greatest common divisor of the harmonic approximation's partials.


\subsubsection{Inharmonic tones with low fundamental frequencies}\label{sec:lowinharmonic}



Loudspeakers do not have a flat frequency response, especially in the low frequencies. Expensive studio monitors like the Genelec 1236A \citep{Genelec2024} may have a flat response across the entire range. In contrast, near-field monitors often have a weaker response below 35Hz \citep{newell2001yamaha,deruty2024storch}, and consumer products show variable low-frequency responses \citep{Rtings2024}. Headphones like the Sony WH-1000XM5 offer a flatter low-frequency response \citep{Taboada2022} while laptop speakers struggle at these frequencies \citep{Dave2D2022}.

The $f_0$ values in Primaal's bass parts often lie between 35 and 45Hz (SM C), which some speakers may not reproduce. In harmonic tones, the auditory system may derive pitch through temporal modeling of the `missing fundamental' \citep{fletcher1924physical}. However, this may not apply if the tone is inharmonic, as the $f_0$ may differ from the pitch evoked through temporal processing. If the lowest partial is not transmitted, the $f_0$ becomes irrelevant for pitch perception. \textbf{Listening test~6} (SM A.6) shows how the first partial's transposition is sometimes inaudible. In these cases, temporal mechanisms may determine pitch, consistent with \citepos{sek1995frequency} position that low-frequency pitch discrimination depends on temporal mechanisms.




\subsection{Amplification of upper partials}\label{sec:loudharmonics}

See Section~\ref{ref:individualharmonics} for a discussion of the historical context of the debate regarding perception of upper partials as individual entities. 

\subsubsection{Process and purpose}\label{sec:partialamplificationprocess}




In Primaal's music, a key technique is amplifying upper partials while attenuating the fundamental, making the upper partials audible as carriers of perceivable pitches. \textbf{Listening test 3} (SM A.3) confirms that multiple pitches can be heard in complex tones.

%This method is applied to bass tracks and other instruments like synthesisers (Appendix~\ref{ref:cardinalsynthbreak}), keyboards (Appendix~\ref{ref:elevatekey}), and gimmicks (Appendix~\ref{ref:whompgimmick}).

In Primaal's music, partials do not follow equal temperament and may evolve continuously (Section~\ref{sec:continousfreqs}). %The producers emphasise which upper partial carries pitch and may boost it while transposing the sample to fit the song's mode.

The process of boosting selected partials is well-suited to bass parts with rich spectra. Using low $f_0$ values (e.g., around 35Hz) aids harmonic perception over the fundamental. At equal energy, lower partials produce lower loudness \citep{iso2262023} and may not be transmitted by the playback system \citep{deruty2024storch}. The producers aim to make the instrument a rich `harmonic entity' with `presence' and `personality'. Instead of adding instruments, they amplify the bass's upper partials, and attenuate the $f_0$ in order to emphasise these partials. The producers prefer bare arrangements where the richness of the bass stands out.

An extreme example is the bass track in `<Fire!' (C.10), where pitch sensation comes from the amplitude modulation of partials from a low $f_0$. Similar methods are used in `Cardinal' (C.6) and `Elevate' (C.9).

Amplifying upper partials demonstrates a \textit{pitch--timbre continuum}, where a partial's amplitude, traditionally a property relating to timbre \citep{peeters2011timbre}, can influence perceived pitch if it is sufficiently large \citep[p. 1706]{yost2009pitch}.

\subsubsection{Technical means}



The producers highlight upper partials by either boosting existing partials or generating new ones. For bass, they use synthesis engines like the `808 Woofer Warfare' (Section~\ref{ref:bassgeneration}) to create loud partials. They also use \textit{a posteriori} equalisation (see Section~\ref{ref:otheraudioprocs}) to boost medium frequencies and reduce or remove the fundamental. Examples include the bass in `Elevate' (+10dB@1kHz) and `Boom' (+10dB@5kHz), the synth break in `Cardinal' (C.6), and the gimmick in `Whomp' (C.14).

Distortion and waveshaping (Section~\ref{ref:distortion}) are also used. Distortion examples include:
\begin{itemize}[noitemsep]
\item `R U ready', synth bass; (C.11.1); 
\item `Boom', bass (C.1); 
\item `Danger', higher bass (C.7.2); and
\item `Sweet Money', bass (C.13).
\end{itemize}

Waveshaping examples include:
\begin{itemize}[noitemsep]
\item `R U ready', synth bass (C.11.1);
\item `Elevate' and `Silver', synth bass (C.8, C.12);
\item `Elevate', rising keyboard (C.9); and
\item `<Fire!' and `Sweet Money', bass (C.10, C.13).
\end{itemize}

Ring modulation (Section~\ref{ref:ringmodulation}) is used for the synth bass in `R U ready' (C.11.1), in `Danger' to boost partial 5 (C.7.1), and in `Silver' (C.12). Examples of frequency modulation (Section~\ref{ref:otheraudioprocs}) include the bass in `R U ready' and `<Fire!'.

Other techniques include using non-linearities from compressors (Section~\ref{ref:otheraudioprocs}) or reverbs, as in the synth bass from `R U ready' (C.11.1).


\subsubsection{Audible upper partials in complex tones are not unique to Primaal's music}\label{sec:audiblepartialsothers}


The presence of loud harmonics perceived as individual notes is not unique to Primaal's music. Figure~\ref{fig:Hunger} (a) shows the weighted power spectrum (see Section~\ref{sec:analyticalprocess}) of the keyboard part from Alt-J's `Hunger of the Pine' \citep[4'30--end]{AltJ2014Hunger}. \textbf{Listening test 2} (SM~A.2) shows that this quasi-harmonic complex tone results in the perception of multiple simultaneous pitches.

Figure~\ref{fig:Hunger} (b) shows a harmonic complex tone from a power chord on a guitar (played notes, A2 and E3), distorted with Native Instrument's Guitar Rig Rammfire.\footnote{\url{https://www.native-instruments.com/en/products/komplete/guitar/guitar-rig-7-pro/amps-and-cabinets/}} The played notes and higher partials are more audible than the $f_0$. See Section~\ref{ref:distortion} for more on partial generation due to distortion.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/hunger_guitar_note_key_weighted_upload.png}
\caption{(a) Alt-J, `Hunger of the Pine', 4'30 to 4'47, weighted audio (see Section~\ref{sec:analyticalprocess}), FT. (b) Harmonic complex tone stemming from a power chord, weighted, FT. In both diagrams, the x-grid shows the multiples of the $f_0$.}
\label{fig:Hunger}
\end{figure}



\citet{deruty2022melatonin} describe how the Primaal producers attenuated lower harmonics in an A.I.-generated bass track \citep{grachten2020bassnet}, revealing a coherent melody from upper harmonics.



\subsubsection{Odd harmonics and pitch uncertainty}\label{sec:oddharmonicspitchuncertainty}



As seen in the `Danger' bass track (SM C.7.1), the producers often use odd-harmonic tones. Such tones promote pitch ambiguity, particularly with low $f_0$. \citet[pp.~1705--1706]{yost2009pitch} notes that when a harmonic complex tone lacks its lowest partials, and the lowest is an odd harmonic, temporal analysis may yield two pitches. This also occurs when a tone has odd partials and a low $f_0$ (e.g., 30Hz). Low-frequency partials result in lower loudness and may not be transmitted (Section~\ref{sec:lowinharmonic}), making the lowest audible partial an odd upper partial. \textbf{Listening test~4} (SM A.4) confirms that perceived pitch increasingly differs between low-$f_0$ odd-harmonic tones and all-harmonic tones as $f_0$ decreases.



\subsection{Pitched content in drums}\label{sec:pitchcontentindrums}

\subsubsection{Context}

Musical signals have been divided into `percussive' and `harmonic' components. Percussion is short and noisy, while harmonic elements are longer and pitch-concentrated \citep{rump2010autoregressive}. These distinctions guide early source separation methods \citep{fitzgerald2010harmonic,yoo2010nonnegative}.

%and noise removal \citep{grunberg2014music}.

%\citet{ono2008real} note that harmonics appear horizontally in a spectrogram, percussion vertically. 

Drums, however, may contain pitched content \citep{richardson2010acoustic}. Though their eigenfrequencies are often inharmonic, they can be harmonic \citep{antunes2017possible}. Drum stems extracted by SpectraLayers or iZotope RX 8 confirm that pitch is often present \citep[14'30, 19'41]{Attack2022}. Thus, drums can be tuned. In popular music, acoustic drum tuning impacts sound quality \citep{toulson2009perception}, though there does not seem to be any consensus on tuning methods \citep{drummagazine2010}. %Pitch can also change with playing force \citep[p.~32]{richardson2010acoustic}, an issue avoided with electronic drums, where samples are pre-selected.

%Tonal elements in drums range from inharmonic to chaotic \citep{wu2018review}. 


\subsubsection{Drums in Primaal's music}\label{sec:primaaldrums}


The Primaal producers often tune the kick drum, especially for longer samples, but find the snare harder to tune. They may tune other percussions or leave them out-of-tune to act as `punctuation', as in `Cardinal', where metallic percussion contrasts with the bass.

They emphasise caution when tuning drums, prioritising timbre and register over pitch---a practice also noted by hip-hop producer Scott Storch \citep{deruty2024storch}. The next closest `pole' is usually chosen (see Section~\ref{sec:pitchdimensions}), but if transposition alters timbre too much, they leave the sample out of tune or select another. A semitone or tone shift is acceptable, but not a third. For example, they detuned the snare in `YadaYada' by one semitone to match the closest `pole'.

The producers note that out-of-tune drums may not always clash with a song's pitches, as drum pitch perception can change or be lost when played with tracks of higher pitch strength. \textbf{Listening test 5} (SM A.5) shows that perceived kick drum pitch changes when played with stronger-pitched tracks, though no clear rules emerged. See Section~\ref{sec:tuneddrums} for more on drum tuning in Primaal songs.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Pitch uncertainty in a historical context
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Pitch uncertainty in a historical context}
\label{sec:historical-context}

\subsection{Acoustic beats and combination tones}\label{ref:nonlinear}



Acoustic beats and combination tones result from the superposition of pure tones with different frequencies. \emph{Acoustical interference beats} are periodic amplitude fluctuations caused by two pure tones with slightly different frequencies. \citet[p.~12]{turner1977ohm} notes that when two intense tones are played together, the ear perceives a third, lower `combination' tone, called a `Tartini tone' after violinist Giuseppe Tartini (1692--1770). %\citet[pp.~254--256]{christensen2006cambridge} offers a detailed historical perspective on these phenomena.

While beating and combination tones are `different in kind' \citep[pp.~255]{christensen2006cambridge}, they arise from the same physical process. As the frequency difference increases, the combination tone becomes audible, turning into a distinct tone at around 20Hz \citep[p.~12]{turner1977ohm}. Figure~\ref{fig:RMS_freq_beating} illustrates the transition from acoustic beats to combination tones.



\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/RMS_spec_and_hr_20Hz_noHR_upload.png}
  \caption{Frequency beating from the superposition of two harmonic tones. $Y$-axis, interval in semitones between the $f_0$s, with white-on-black ratios for pure intervals. $X$-axis, beat frequency, measured by the signal's RMS. Bright pixels denote higher RMS variation, indicating stronger beating amplitude.
}
\label{fig:RMS_freq_beating}
\end{figure}





\subsubsection{Acoustic beats, tuning, and unison}\label{sec:acousticbeats}



Figure~\ref{fig:RMS_freq_beating} shows that pure intervals (small-integer ratios) generate no acoustic beats, while impure intervals produce beats. Impure intervals have been considered undesirable, leading to the development of temperaments that reduce acoustic beating \citep{lindley2001temperaments}. Instrument tuning, such as for organs \citep{baggaley2023mechanisms}, harpsichords \citep[p.~255]{christensen2006cambridge}, pianos \citep[p.~87]{white1917modern}, and guitars \citep{klickstein1993tuning}, also seeks to minimise beating. However, the `unison' effect used by Primaal (Section~\ref{ref:unison}) is designed to \emph{create} beats.

Figure~\ref{fig:S_beating} contrasts different attitudes towards beating corresponding to different historical periods. `Just intonation' refers to harmonic intervals tuned purely so they do not beat \citep{lindley2001justintonation}. Before \citet{rameau1737generation} endorsed equal temperament, minimising acoustic beating was a priority. In modern popular music, techniques like unison and overdubbing \citep[p.~31]{huber2013modern} intentionally produce beats by combining tracks with slightly different pitches.





\begin{figure}
  \centering
  \includegraphics[width=1\columnwidth]{imgs/S_beating.png}
  \caption{Development over history in attitudes towards acoustic beating in music.}
\label{fig:S_beating}
\end{figure}


\subsubsection{Combination tones, distortion and ring modulation}\label{sec:combinationtones}


Helmholtz observed that the tetrads in Palestrina's \textit{Stabat Mater} minimise combination tones, suggesting they are undesirable \citep[p.~225]{kursell2015third,helmoltz1885sensations}. In contrast, 20\textsuperscript{th} century composer G\'erard Grisey, following Hindemith's \emph{ring modulation harmony} \citep{hindemith1941craft}, used sum and difference tones to generate harmonic fields \citep[p.~52]{anderson2000provisional}. \citet{emmerson1977ring} provides examples of ring modulation harmony, and \citet{costa2019modeling} explores the link between ring modulation harmony and temperaments. The producers heavily use ring modulators, distortion, and waveshaping (Section~\ref{ref:distortion}).

% , wang2012spectral

Figure~\ref{fig:S_combination} summarises attitudes towards combination tones. Palestrina minimised them, viewing them as undesirable. \citet{kursell2015third} notes that after \citet{rameau1722traite} linked triads to overtones, the distribution of notes over the registers became less important, rendering combination tones irrelevant. However, combination tones regained significance with Hindemith, Grisey, and contemporary popular music, with the use of ring modulators, distortion, and waveshaping.



\begin{figure}
  \centering
  \includegraphics[width=1\columnwidth]{imgs/S_combination_tones.png}
  \caption{Development over history in attitudes towards combination tones in music.}
\label{fig:S_combination}
\end{figure}


\subsection{`Hearing out' individual harmonics}\label{ref:individualharmonics}

\subsubsection{Historical debate}\label{sec:ohmseebeck}

In Section~\ref{sec:loudharmonics}, we indicated that the producers boost higher formants to evoke pitches independently of the fundamental frequency, raising the question of how well humans can `hear out' individual harmonics. This debate has a long history. \citet{mersenne1636harmonie} suggested that a struck string produces at least five sounds, though only the best ears can hear them. \citet[pp.~13--14]{rameau1750demonstration} later used this idea to form his theory of harmony.

% \citet[p.~32]{euler1980rational} identified this as the first hypothesis that the ear acts as a frequency analyser. 

The ear as a frequency analyser was key to the Ohm--Seebeck dispute \citep{turner1977ohm}. \citet{ohm1843definition} argued that only the fundamental partial contributes to pitch, while \citet{seebeck1843definition} claimed overtones are involved. \citet[pp.~58--59]{helmoltz1885sensations} supported Ohm, stating overtones affect timbre but not pitch. For further discussion, see \citet{plomp1964ear,plomp2001intelligent} and \citet{turner1977ohm}. % and \citet{kim2003theories}.




\subsubsection{Practical experiments}

Experiments have explored the ear's ability to `hear out' harmonic partials \citep[pp.~86--88]{moore2012introduction}. These studies suggest humans can identify the first 5--8 harmonics of a periodic sound, limited by the ear's critical bands. \citet[p.~58]{helmoltz1885sensations} argues that the difficulty of hearing harmonics is not dependent on their energy. \citet{plomp1964ear} disagrees, stating that harmonics set at the same loudness level have `equal chances' of being heard. The Primaal's producers' practice of boosting harmonics to make them individually audible contradicts Helmholtz's view.

%\citep{plomp1964ear,plomp1968ear,soderquist1970frequency,moore1993audibility,moore2006frequency,moore2012introduction}


\subsubsection{Enlarging the scope of the debate}\label{sec:enlargingdebate}

The validity of the hypothesis that the ear is a frequency analyser has been questioned. \citet[p.~438]{dixonward1970} calls it a `quarter-truth', noting that the ear acts this way only in limited conditions. \citet{turner1977ohm} and \citet[p.~2]{plomp1976aspects} similarly suggest partial identification is possible only under specific conditions, with Plomp noting that it is nearly impossible in a musical context. 

Following Section~\ref{sec:audiblepartialsothers}, and based on the analysis of Primaal's music, we suggest that Plomp's `musical context' refers to Western classical music. Contemporary popular music employs production techniques that enhance overtone audibility. The use of individual partials for their audible pitches may distinguish contemporary popular music from Western classical music.


\subsection{Modality: background}\label{sec:modalitybackground}


The concept of `mode' has been interpreted in various ways in the literature. \citet{powers2001mode} distinguish between its use in European music history and as a modern concept in non-Western music. Another distinction is whether a mode is a \emph{scale} or a \emph{melodic type}. For Primaal's music, the early Western definition (900--1000) applies, where a mode is a scale with one important degree, the `final'. Later interpretations of `mode' are not considered here.

This interpretation appears in treatises such as \textit{Musica Enchiriadis} and \textit{Scholia Enchiriadis} \citep{Hucbaldus900musicaenrichidis,Hucbaldus900scholiaenrichidis}, translated by \citet{erickson1995musica}. \citet[p.~50]{erickson1995musica} describe the final as central to the scale. \citet[p.~17]{coeurdevey1998histoire} and \citet{powers2001mode} derive similar definitions from \emph{Dialogus de musica} (ca.~1000--1100). \citeauthor{coeurdevey1998histoire} states that `[a] tone or mode is the principle which distinguishes any song by its final.' The final determines the end of every song \citep{latina1841patrologiae}.

The final's role remains ambiguous. According to \emph{Dialogus de musica}, it is both the starting and ending scale degree. \citet{meeus2023theoretical} calls it the `reference' note, while \citet{powers2001final} refers to it as the concluding degree of any melody in a mode. In Primaal's music, the final serves as the `reference' note.


\subsection{Modality or tonality}\label{sec:modalitytonality}


There is ambiguity between modality and tonality, with debates on whether medieval and Renaissance polyphony is `modal' or `tonal'. \citet{powers1981tonal} calls the `modal system' a `doctrine', preferring to look for `tonal relationships', and questioning whether the concept of mode is real \citep{powers2017mode}. \citet{powers2001final} notes that the near synonymity of `final' and tonic is a cultural assumption rather than an inherent connection. \citet{meeus2013modalite} challenges this, stating that church modes are diatonic, while tonality requires a chromatic scale, but also recognises a `tonal center' in Renaissance polyphony \citep{meeus2023theoretical}. \citet{atcherson1973key} argues that `key theory' (tonality) is not a descendant of `modal theory', disputing that major and minor scales derive from church modes.

%powers1992modalite

Schenkerian analysis \citep{schenker1935satz} proposes that harmonic progressions reduce to I/V/I structures, contrasting with the looped `shuttles' of popular music \citep{tagg2009everyday}. \citet[p.~82]{coeurdevey1998histoire} describes the shift from modal polyphony to tonal writing as a move from \textit{resultant} to \textit{active} harmony. To qualify as `tonal', music must have directional harmonic progressions and active harmony. Primaal's music lacks both: its harmony is not directional and \textit{results} from complex tones, often from the bass. As a result, Primaal's music may be considered modal rather than tonal.

%In the next section, we explore the relationship between modality and tonality and explain why Primaal's music is not considered tonal.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Methods of analysis and analytical process
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Methods of analysis and analytical process}
\label{sec:methods-of-analysis}

\subsection{Analysis and `popular' music}\label{ref:analysisofpopularmusic}

In this section, we address several issues identified in previous work on popular music analysis. \citet{wicke2003popmusik} considers many of these concerns.

\subsubsection{The `primary text'}\label{ref:primarytext}

\citet[p.~1]{moore2018rock} contrast the `primary text' (the sounds themselves) with the `secondary text' (commentaries on the sounds). \citeauthor{moore2018rock} argue that popular music analysis has focused too much on the `secondary text' and not enough on the `primary text'. According to \citet[p.~338]{keil1966motion}, if analysis centres on the `primary text', the analyst's main duty is to explain the syntax or grammatical rules of the musical system, as `[a]ll music has syntax or embodied meaning'. In this article, we concentrate on the `primary text' to understand the syntax and grammatical rules related to pitch in Primaal's music.


\subsubsection{Harmony as a bias}

Popular music analysis may be biased by the nature of music analysis itself. \citet[p.~19]{brackett2023interpreting} notes that the language of music analysis carries its own ideology, affecting the analysis results. \citet[pp.~104--105]{middleton1990studying} argues that `mainstream musicology' from the 19\textsuperscript{th} and 20\textsuperscript{th} centuries is often not helpful for popular music, as it has a rich vocabulary for areas like harmony and tonality, but lacks vocabulary for pitch nuance and gradation outside the diatonic/chromatic system. In this paper, we have focused on pitch nuance and gradation beyond this system, showing for example that `dissonance' and `resolution' may be produced through non-harmonic means (Section~\ref{subsub:continuous}).

% In popular music, parameters like rhythm, pitch gradation, and timbre may be more important than harmony, and 


\subsubsection{The score as a bias}\label{ref:scoreasbias}

According to \citeauthor{middleton1990studying}, a key obstacle to analysing the `primary text' in popular music is the \emph{score}. Musicologists often adopt a `notation-centric' approach, where the score is seen as `the music', leading to specific forms of listening that may not apply to all music \citep[p.~105]{middleton1990studying}. This bias foregrounds musical parameters that are easily notated, while neglecting those that are not, such as non-standard pitch and pitch movement \citep[pp.~104--105]{middleton1990studying}. \citet[p.~16]{mellers1974twilight} notes that scores can be misleading, as they cannot capture improvised elements or pitch distortions that are central to orally conceived music.

Many analysts still rely on Western-style transcriptions for popular music \citep{tagg1982analysing,everett1986fantastic,middleton1990studying,moore2016song,moore2018rock}. In this study, we avoid a `notation-centric' approach, preferring signal analysis over scores to address `the volatility of sounds due to the lack of a system of notational symbols' \citep[p.~103]{aluas1996quatour} -- see Section~\ref{ref:reduction}.


\subsubsection{Pertinent pre-analytical approaches}

According to \citet[p.~10]{moore2018rock}, one goal of the popular musicologist is to `elucidate theoretical approaches pertinent to the music [...] This activity is best considered pre-analytical, since any analysis must be based on theoretical preconceptions'. We have proposed that conjoint critical listening with the music's producers backed up by signal analysis (SM C) may be a suitable `pre-analytical' theoretical approach. We have then performed analyses based on this approach.



\subsubsection{The producers' point of view}

\citet[p.~271]{everett2000expression} testifies that `[he]'ll demonstrate expressive manipulations of formal construction, vocal and instrumental colorings, rhythmic relationships, melodic devices, and tonal systems, without once ever considering whether the composers, arrangers, artists, or engineers might have been fully conscious of how [he] might hear what they were doing'. We want to avoid such a lack of communication with those who produce the music. We hope that maintaining strong communication with the producers addresses this issue.



\subsection{Phenomenological reduction and music analysis}\label{ref:phenomenologicalreduction}

\subsubsection{Husserl's phenomenology}

\citet[p.~33]{husserl1983ideas} defines the \emph{philosophical epoch\'{e}} as follows: 
\begin{quotation}
\noindent`the philosophical $\grave{\varepsilon} \pi o \chi \acute{\eta}$ that we are undertaking shall consist of our completely abstaining from any judgment regarding the doctrinal content of any previous philosophy and effecting all of our demonstrations within the limits set by this abstention'.%\footnote{In the original German: `Die philosophische $\grave{\varepsilon} \pi o \chi \acute{\eta}$, die wir uns vornehmen, soll [...], darin bestehen, da{\ss} wir uns hinsichtlich des Lehrgehaltes aller vorgegebenen Philosophie kommen des Urteils enthalten und alle untere Nachweifungen im Rahmen dieser Enthaltung vollziehen' \citep[p.~33]{husserl1913german}.} 
\end{quotation}
Abstaining from judgement means that `[t]he positing is ``put out of action'', parenthesized' \citep[pp.~59--60]{husserl1983ideas}---original German: \emph{Einklammert}, often translated as `bracketed'. The \emph{phenomenological epoch\'{e}} stands upon the act of bracketing, according to which the observers 
\begin{quotation}
\noindent`exclude all sciences relating to this natural world no matter how firmly they stand there for [them], no matter how much [they] admire them, no matter how little [they] think of making even the least objection to them' \citep[p.~61]{husserl1983ideas}.%\footnote{In the original German: `Also alle aus diese nat\"{u}rliche Welt bez\"{u}glichen Wiffenschasten, so sest sie mir steben, so sehr ich sie bewundere, so wenig ich daran denke, das mindeste gegen lie einzuwenden, schalte ich aus, ich mache von ihren Geltungen absolut keinen Gebrauch' \citep[p.~56]{husserl1913german}.}
\end{quotation}
Exclusion is not refutation. The process does not involve formulating a contrary judgment, it `shuts [the observer] off from any judgment' \citep[p.~61]{husserl1983ideas}. The bracketing process prompts \emph{phenomenological reduction} \citep[p.~66]{husserl1983ideas}. 





\subsubsection{Phenomenology and music analysis}

In music analysis, phenomenological epoch\'{e} involves making naive judgments based on face value and disregarding everyday knowledge \citep[p.~3]{serhan2022phenomenological}. \citeauthor{serhan2022phenomenological} highlights Schaeffer's reduced listening (\emph{\'{e}coute r\'{e}duite}) as an application of phenomenology. This involves listening to sounds purely as sound objects, removing their source and meaning \citep[p.~33]{chion1983guide}.

% \citet{kim2010critique} and 

A key difficulty in applying phenomenology to music analysis is the existence of the score (Section~\ref{ref:scoreasbias}). \citet{benson2011phenomenology} notes that in \citepos{ingarden1986work} ontology of the musical work, the score often eclipses the composition, despite acknowledging that the score is an incomplete guide for performance. According to \citeauthor{benson2011phenomenology}, this problem is intrinsic to notation. Even a superior notational system would not resolve the indeterminacy.


\subsubsection{Phenomenological reduction as the first step of the analysis}\label{ref:reduction}



At the start of our analysis, we choose to have minimal information about the music. We have the stems, with the producers noting the importance of some (e.g., bass) over others. In phenomenological reduction, we \emph{bracket out} cultural preconceptions. We do not know if pitch arises from harmonic tones, if pitches are stable enough to form notes, if their distribution forms a scale, or if simultaneous pitches form known chords.% We do not even retain \citepos{oxenham2012pitch} statement that `pitch is the perceptual correlate of periodicity', as phenomena like sine sweeps suggest otherwise.

\citet[p.~359]{ferrara1984phenomenology} describes \textit{open listening} as the first step of phenomenological music analysis. Our first step is open listening combined with signal analysis, with no scores to bracket out. Signal analysis addresses `the volatility of sounds due to the lack of a system of notational symbols' \citep[p.~103]{aluas1996quatour}, paralleling early Western attempts at notation.

Typically, signal analysis of Primaal's music provides the following observations. A spectral transform of a stem reveals partials forming an {\em auditory stream\/} \citep{bregman1994auditory}, though their relations are non-harmonic. We often hear multiple pitches from a single set of partials, which do not correspond to the lowest partial. Frequency values are rarely stable, and frequency distributions across tracks rarely coincide, even when perceived pitches are similar.

Such observations then lead to what \citet[p.~359]{ferrara1984phenomenology} describes as `syntactical' listening---the next step of phenomenological analysis (Section~\ref{ref:primarytext}).



\subsection{`Pitch', as understood by the machine learning and music information retrieval (MIR) community}\label{ref:mircommunity}

\subsubsection{MIDI files and piano rolls as reification of the score}


The reification of the score, as noted by \citet[pp.~104--105]{middleton1990studying} and discussed in Section~\ref{ref:scoreasbias}, influences methods in the MIR community. \citet[sec. 4.2]{briot2020deep} argue that the essence of music lies in the compositional process, revealed through symbolic representations like scores or lead sheets. A common MIR task is audio-to-MIDI alignment \citep{raffel2016optimizing}, where MIDI files act as symbolic `versions' of the pitched content \citep{raffel2016learning,benetos2018automatic}.

%ewert2012towards,
%or `transcriptions' 

However, in terms of lossy compression, transcribing Primaal's music to MIDI results in significant loss, making the algorithm inadequate. The original content cannot be faithfully reproduced. As the producers note, `if you play this music on a piano, it will be boring and will not sound like anything'.


\subsubsection{AI song contest and Italian secular monodies with \emph{basso continuo}}\label{sec:AIsongcontest}


\citet{ashworth2012basso} define \emph{basso continuo}, used between 1600 and 1750, as a bass line with specified or implied harmonies. Giulio Caccini's \emph{Nuove Musiche} (1602) helped codify this practice, widely applied in Italian secular monodies \citep{caccini1978nuove,williams2001continuo}.


%\citep{fortune1953italian,arnold1957alessandro,baron1968monody,caccini1978nuove,williams2001continuo}.

The AI song contest \citep{aisongcontest2024} promotes co-creative composition, where musicians use AI to blend human and machine creativity. The contest's focus on melody, harmony, and bass \citep{AIsongcontest_long} parallels 17\textsuperscript{th}-century monodies with \emph{basso continuo} \citep{deguernel2022personalizing}. However, Primaal's music diverges from this approach, which may not represent how contemporary popular music is conceived.

This modular view of popular music may derive from the tradition of teaching composition via figured bass theory. As \citet{williams2001continuo} observe, \emph{continuo} was fundamental in the 17\textsuperscript{th} and 18\textsuperscript{th} centuries, forming the basis for composition teaching and remaining relevant for theoretical analysis into the 19\textsuperscript{th} and 20\textsuperscript{th} centuries.



\subsubsection{The harmonic complex tone as the sole origin for the impression of pitch}\label{ref:soleorigin}

According to \citet{oxenham2012pitch}, the most common pitch-evoking sound is a harmonic complex tone, where two tones share the same pitch if they have the same $f_0$. This view is widely adopted in the MIR and machine learning communities. Pitch detection, or `pitch tracking', is often framed as an \emph{$f_0$ estimation task} \citep{drugman2018traditional,kim2018crepe}. Neural network approaches assume the signal is `periodic' or `quasiperiodic', relying on harmonic audio data for training \citep{riou2023pesto}.

%signol2008evaluation,

Such assumptions underpin other tasks in music information retrieval, like harmonic-percussive source separation \citep{ono2008real}, automatic music transcription \citep{ewert2014score}, and multi-pitch detection \citep{christensen2008multi}. Inharmonic models \citep{vincent2008harmonic} are rarely used. 

Equating `pitch' with `$f_0$ of harmonic complex tones' contrasts with psychoacoustic studies of inharmonicity (Section~\ref{sec:inharmonicitybackground}) and with our analyses of Primaal's music, where most instruments are inharmonic, and pitch is often carried by one or more overtones.

%Additionally, \citet{deruty2024inharmonicity} show that the \textit{HarmonicRatio} of post-1970 popular music is lower than that of orchestral and piano music. Low \textit{HarmonicRatio} values, whether from inharmonicity or sound positioning, are illustrated by a single instrument with a \textit{HarmonicRatio} lower than church bells.


\subsection{Analytical process}\label{sec:analyticalprocess}

Our analysis procedure consisted of five steps:

\begin{enumerate}[noitemsep]

	\item {\em Song selection}$\quad$The songs, produced in Avid Pro Tools, were exported as stems. Song choice was based on stem availability.
	\item {\em Critical listening and signal analysis}$\quad$We listened to the stems using phenomenological reduction (Section~\ref{ref:reduction}) and selected sections for signal analysis with the producers, focusing on the `bass' tracks, key to this music.
	\item {\em Interviews}$\quad$We conducted a six-day interview with the producers, using the analysis results to discuss the techniques used to manipulate pitch in each song.
	\item {\em Further analysis}$\quad$Additional signal analyses were performed to explore observations and hypotheses raised during the interviews.
	\item {\em Validation}$\quad$The producers reviewed and verified the conclusions.
	
\end{enumerate}

Signal analyses in this study incorporate equal-loudness-contour weighting, recognizing that humans are not equally sensitive to all frequencies \citep{fletcher1933loudness}. Various models exist that weight the power spectrum to reflect perception (\citealt{fletcher1933loudness,robinson1956re}; \citealt[p.~7]{skovenborg2004evaluation}). One such model is ISO226:2023 \citep{iso2262023}. We apply the ISO226:2023 50-phon equal-loudness contour before spectral analysis to produce results that better reflect what listeners actually hear.


\subsection{The songs' stems}

The song stems always include drums and basses, while other stems vary. Some songs feature lead vocals as rap flows or edited loops, but there are no melody-based lead vocals. Vocal melodies, when present, are short, recurring `hooks' \citep[p.~58]{delson1980dictionary}. Human shouts, vocal effects, and synthetic effects often act as `punctuation marks' according to the producers. Other stems may include elements with a strong sense of pitch, such as brass samples and arpeggios.


\subsection{Structure: background}\label{sec:structurebackground}

Sections~\ref{sec:largescalestructure} and~\ref{sec:smallscalestructure} describe the large- and small-scale structures in Primaal's music. \citet[p.~13]{deruty2013methodological} summarise the distinction between the two time scales.

The large-scale structure, following \citet{bimbot2012semiotic}, is the `semiotic structure', or `sectional form', which describes long-term regularities between musical parts. Segments at this scale are `autonomous and comparable blocks' \citep{bimbot2010decomposition}, with a typical duration of around 11.5s \citep{deruty2013methodological}. In Western classical music, such segments have been referred to as `periods' \citep[pp.~149--150]{monelle2014linguistics} and classified as `sentences' and `periods' \citep{schoenberg1967fundamentals,caplin1998classical}. Section~\ref{sec:largescalestructure} provides examples of Primaal's large-scale structure.

%\citet{bimbot2010decomposition,bimbot2012semiotic,bimbot2014semiotic},

The small-scale structure refers to the internal organisation of segments, also known as `form' \citep{caplin1998classical}, or the `morpho-syntagmatic level' \citep{bimbot2014semiotic}. Functions at this level include {\em contrast} \citep{bimbot2016system} and {\em antecedent} and {\em consequent} \citep{caplin1998classical}. Section~\ref{sec:smallscalestructure} offers examples of small-scale structure and determinants of form in Primaal's music.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Tools and techniques
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Tools and techniques}\label{sec:tools-and-techniques}

This section lists some of the tools and techniques used by the Primaal producers. A key tool for both generation and processing is the Spectrasonics Omnisphere synthesiser.\footnote{\url{https://www.spectrasonics.net/products/omnisphere/}} Widely used by professional producers, Omnisphere has been rated as the `world's best synthesiser' for several years, \citep{nagle2015omnisphere} suggesting that observations from Primaal's music may apply to other commercial tracks.


\subsection{The Roland TR-808 bass drum}\label{ref:bassgeneration}


The Roland TR-808 Rhythm Composer, an analogue drum machine produced between 1980 and 1983 \citep{hasnain2017tr}, is regarded as one of the most influential drum machines \citep{meyers2003tr,werner2014physically}. It has become a defining sound in hip-hop, with Scott Storch stating that modern trap music producers `live in an 808 world' \citep{storch2022}. The 808's distinctive presets are also classic sounds in genres like techno, electro, R\&B, and house music \citep{dayal2014tr}.


The 808's `long and velvet deep' bass drum \citep{carter1997tr} evolved from a kick drum to a tool for both bass and kick, often carrying the bassline in hip-hop \citep{lavoie2020}. Producers use it to fuse drums and bass \citep{Dunn2015,burke2019}. The producers use 808-style generators for bass parts but may create separate kick drum parts from other sources.

Percussive audio often contains rapidly decaying signals \citep{shier2023differentiable}. The 808 bass drum mimics this with a `decaying pseudo-sinusoid with a sighing pitch' \citep{werner2014physically}, a feature found in all Primaal songs.



 

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/808WooferWarfare.png}
  \caption{`808 Woofer Warfare' patch, key controls.}
\label{fig:808WooferWarfare}
\end{figure}

In Primaal's music, the primary tool for 808-style bass generation is the `808 Woofer Warfare' patch in Omnisphere's Seismic Shock library.\footnote{\url{https://www.sonicextensions.com/seismic-shock/}} Figure~\ref{fig:808WooferWarfare} shows its key controls. `Mode' selects which harmonics to highlight, and `Amount' determines how much to highlight them. `Pitch' controls the amplitude of the descending frequency glide, and `Decay' sets the note duration.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/808_warfare_max_values_for_each_upload.png}
  \caption{Omnisphere, Seismic Shock library, `808 Woofer Warfare' patch, STFT for the seven modes. (a) Unweighted audio. (b) Weighted audio.}
\label{fig:808warfare}
\end{figure}

Figure~\ref{fig:808warfare} shows the partials in different modes. Mode 1 emphasises harmonics 3 and 5, mode 2 highlights harmonics 8 and 10, and mode 3 favours even harmonics. The producers prefer mode 2, which makes the major third audible.

\subsection{Distortion and waveshaping}\label{ref:distortion}

We consider distortion and waveshaping together, as waveshaping produces non-linear distortion \citep{roads1979tutorial}. The Primaal producers use Omnisphere's Waveshaper,\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/layer-page-oscillator-page20a}} SoundToys' Decapitator,\footnote{\url{https://www.soundtoys.com/product/decapitator/}} and the SansAmp PSA-1 plug-in\footnote{\url{https://www.avid.com/plugins/sansamp-psa1}} for these effects.


\subsubsection{Distortion and waveshaping generate partials}\label{ref:waveshaping}

Distortion and waveshaping apply a non-linear transformation to the signal, causing intermodulation distortion \citep[p.~464]{newell2017recording}. This distortion produces partials from both input partials and their combinations. If $f_a$ and $f_b$ are the input frequencies, the output contains frequencies $k_a f_a + k_b f_b$, where $(k_a, k_b) \in \mathbb{Z}^2$. The generated partials include both lower and higher frequencies than the input.

\subsubsection{Interaction between original and generated partials}

Primaal's preferred distortion plug-in is SoundToys' Decapitator. Primaal's favourite settings result in equal energy between generated harmonics and original inharmonic partials (SM D).  In this case, distortion emulates the `Unison' process (Section~\ref{ref:unison}), combining close frequency partials and modifying the sound's envelope using the resulting acoustic beats (Section~\ref{ref:nonlinear}).

\subsubsection{SansAmp PSA-1}

Primaal also use the SansAmp PSA-1 plug-in. SansAmp provides more radical processing than Decapitator (SM C.1). The generated partials can evolve in the opposite direction to the original signal, resembling frequency folding during aliasing \citep{park1993aliasing}. The producers note that these partials help mask pitches and reinforce pitch ambiguity. %They also use the strong intermodulation distortion from SansAmp to add energy to the $f_0$ partial when needed.


\subsection{Ring modulation}\label{ref:ringmodulation}

The producers use Omnisphere's Ring Modulation\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/layer-page-oscillator-page17}} to boost or create partials. Unlike intermodulation distortion, which generates many partials ($k_a f_a + k_b f_b$), ring modulation with the same input frequencies only produces $f_a+f_b$ and $f_a-f_b$ \citep{parker2011simple}. This makes ring modulation more controllable, allowing producers to target specific partials.


\subsection{Unison}\label{ref:unison}

In Western classical music, `unison' is defined as the simultaneous execution of one part by multiple performers at the same pitch or an octave apart \citep{Unison}. The unison audio effect, originally found in analogue synthesisers, simulates this by superimposing slightly detuned versions of the original part, creating a `thicker' sound \citep{dailyanalog2024}. \citet[p.~34]{roederer2008physics} notes that superposing two tones livens up the sound. One effect of the unison audio process is the emergence of acoustic beats (see Section~\ref{sec:acousticbeats} and SM E). The producers extensively use Omnisphere's Unison effect.\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/layer-page-oscillator-page22}}




\subsection{Other audio processes}\label{ref:otheraudioprocs}

Other audio processes used in the creation of Primaal's music include the following.

\begin{itemize}[noitemsep]

\item {\em Equalisers to attenuate the fundamental frequency and boost upper harmonics.}\quad The Primaal producers use various types, including parametric equalisers \citep{massenburg1972parametric}, resonance controls in analogue synthesisers \citep{moog1965voltage}, and Sony CSL Resonance EQ \citep{grachten2019req}, which tracks spectral formants to adjust them.


\item {\em Frequency modulation.}\quad This is used sparingly by the producers to target inharmonic relations. In `<Fire!', the FM-based Piston Honda\footnote{\url{http://www.industrialmusicelectronics.com/products/21}} modulates a quasi-harmonic tone with FM-generated inharmonic formants. 

\item {\em Dynamic compression.}\quad The producers heavily use Omnisphere's Seismic Pump compressor\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/seismic-pump}} to stabilise dynamics and alter the signal's spectrum. Depending on settings, it can generate or damp formants.

\item {\em Reverberation.}\quad Omnisphere's Seismic Verb\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/seismic-verb}} is used on tracks like `Danger' and `Silver'. Its dynamic processing and detuning features are used to scramble pitches, especially in higher frequencies.

\item {\em Plug-ins that combine effects.}\quad Combined effects include dynamics, EQ, distortion, and reverb, like Native Instruments Guitar Rig\footnote{\url{https://www.native-instruments.com/en/products/komplete/guitar/guitar-rig-7-pro/}} and Omnisphere Tape Slammer.\footnote{\url{https://support.spectrasonics.net/manual/Omnisphere2/25/en/topic/fx-page-dynamics-page05}}


\item {\em Bends, glides and screws.}\quad\emph{Bends} or \emph{glides} involve continuously shifting pitch, typically using a pitch wheel or MIDI controller. \emph{Screws} are a specific form of bend, mimicking the sound of a tape deck or turntable speeding up or slowing down. Avid's Vari-fi plug-in\footnote{\url{https://www.avid.com/plugins/vari-fi-audiosuite}} can create screws.

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Analysis of Primaal's music
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Analysis of Primaal's music}
\label{sec:analyses-of-works}


In this section, we provide a detailed analysis of pitch-related aspects in Primaal's music, following the methods outlined in Section~\ref{sec:methods-of-analysis}. Our observations are primarily based on the signal analysis results presented in SM C.

\subsection{Inharmonicity in Primaal's music}\label{sec:inharmonicityprimaal} 

All the analysed tones were found to be inharmonic to some degree. As mentioned in Section~\ref{sec:pitchtracking}, we emphasise that {\em we do not attempt to determine the perceived pitch(es)}. We merely describe aspects of the signal and point to potential relations with perception.

\subsubsection{Cases of quasi-harmonicity}

Two of the studied examples are quasi-harmonic: `Elevate''s bass track (SM C.8) and `Yada Yada''s flute track (C.16). Two other examples are also quasi-harmonic:

\begin{itemize}[noitemsep]
    \item The vocals from `Boom' (C.2) deviate by +/- 10 cents around the $f_0$. According to \citet{elvander2020harmonic}, human speech deviations are small enough to exploit harmonic structure when estimating pitch, fitting this definition.
    \item The electric bass from `R U Ready' (C.11.2) has inharmonic partials above the seventh position only, making it quasi-harmonic \citep{jarvelainen1999audibility}.
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/boom_spec_corr_comp_2_upload.png}
  \caption{`Boom', bass, vocals, and kick drum track, 0'16 to 0'18. Difference between pitch derived from the lowest partial ($f_0$) and from autocorrelation.}
\label{fig:boomspeccorrcomp}
\end{figure}

\subsubsection{Autocorrelation/$f_0$ discrepancy}\label{sec:autocorrf0discrepancy}


Pitch perception has been subject to \emph{spectral modeling}, where perceived pitches are derived from the partial positions; and \emph{temporal modeling}, where perceived pitches are derived from autocorrelation of the waveform \citep{meddis2006virtual,yost2009pitch}. In this section, we compare the position of the $f_0$ with temporal analysis using either autocorrelation or frequency differences between partials. SM B details the relation between one and the other.
%
Figure~\ref{fig:boomspeccorrcomp} shows the difference between autocorrelation and $f_0$ values in the bass, vocal, and kick drum sections from `Boom' (SM C.3), illustrating differences within and between tracks.

Several cases in Primaal's music feature inharmonic tones with irregular partial disposition and pitch derived from temporal modeling lower than the $f_0$:

\begin{itemize}[noitemsep]
    \item `R U ready', synth bass (C.11.1): the frequency difference between consecutive partials is irregular and 0--2 semitones below $f_0$.
    \item `Danger', lower bass (C.7.1): the frequency difference between consecutive partials is 0--1 semitones below $f_0$.
    \item `Danger', higher bass (C.7.2): the frequency difference between consecutive partials is irregular and 1--3 semitones below $f_0$.
    \item `Silver', `type 1' bass  (C.12): the frequency difference between consecutive partials is slightly irregular and up to a semitone below $f_0$.
\end{itemize}

Two examples involve pitch higher than or around the $f_0$ value:

\begin{itemize}[noitemsep]
    \item `Silver', `type 2' bass: the frequency difference between consecutive partials is irregular and up to 60 cents above $f_0$.
    \item `Sweet money', bass (C.13): deviates by up to 4 semitones from $f_0$.
\end{itemize}



\subsubsection{Partials as carrier}

In the following examples, deviations from harmonicity are less relevant due to the tone being used as a carrier (see Section~\ref{sec:groupsofpartials}):

\begin{itemize}[noitemsep]
    \item `Cardinal', synth break (C.6).
    \item `Elevate', rising keyboard (C.9).
    \item `<Fire!', bass (C.10).
\end{itemize}

The gimmick track from `Whomp' (C.14) features a slightly inharmonic tone, where three partials are boosted, creating a higher inharmonic tone. Here, both the carrier and modulation result in audible pitch.


\subsubsection{Inharmonicity in kick drum samples}

The following examples show where inharmonicity is introduced in kick drum tracks:

\begin{itemize}[noitemsep]
    \item `Boom', kick drum (C.3): inharmonic, with frequency differences between partials up to a semitone higher than the $f_0$.
    \item `Danger', kick drum (C.7.3): four slightly inharmonic partials with variable frequency differences.
    \item `Silver', kick drum (C.12.4): inharmonic, as harmonic partials are barely louder than surrounding spectral content.
    \item `Whomp', kick drum (C.15): three visible, slightly inharmonic partials with variable frequency differences.
\end{itemize}


\subsubsection{Inharmonicity in Primaal's music: summary}

To summarise, Primaal's music involves various forms of inharmonic tones:

\begin{itemize}[noitemsep]
    \item Tones may have a variable number of partials.
    \item Upper formant frequencies are not exact multiples of $f_0$, with partials arranged irregularly.
    \item Pitch from temporal modeling (autocorrelation) often differs from $f_0$.
    \item Pitches from temporal modeling are usually, but not always, lower than the lowest frequency components (`missing fundamental').
    \item Frequency differences between partials can change over time.
\end{itemize}

\subsection{Salient/amplified upper partials}\label{sec:examplesofboostedpartials}

In this section, we identify some examples from Primaal's music where the most salient partial is not the $f_0$.

\subsubsection{Harmonic 5 (major third)}\label{sec:harmonic5}

The producers enjoy highlighting the major third interval from the harmonic series by boosting harmonic 5. Examples include:

\begin{itemize}[noitemsep]
    \item `Boom', bass (C.1): $f_0$ is B1 (61Hz) and highlighted overtone is D$\sharp$4 (309HZ).
    \item `Elevate', bass (C.8): $f_0$ is D3 (148Hz) and highlighted overtone is F$\sharp$5 (742Hz).
    \item `Silver', bass, type 1 (C.12): $f_0$ is D$\sharp$1 (39Hz) and highlighted overtone is F$\sharp$3 (188Hz).
    \item `Silver', bass, type 2: same $f_0$ as type 2 bass with two highlighted overtones.
    \item `Whomp', gimmick (C.14): $f_0$ is E2$+41$ cent (84Hz), partials 5, 10, and 15 are highlighted, leading to perceiving an A4-40 cent tone (430Hz).
\end{itemize}

A different approach to highlighting a major third interval can be observed in the synth bass from `R U ready' (C.11.1). The $f_0$ for the first `note' of the pattern is C$\sharp$1+33~cent. The sound is inharmonic. The two louder overtones are close to B4 and D$\sharp$5. The main perceived pitch for this `note' is close to B2, and it is possible to identify an interval of a major third.

The producers enjoy boosting harmonic 5 because of the resulting subjective timbre, not because of the resulting major interval. They often try to find a way to attenuate the perception of the resulting music as `major', while trying to conserve the timbral aspect of harmonic 5's presence.


\subsubsection{Other partials}

The producers also highlight other intervals. In the `Boom' bass (C.1), they emphasise the 11\textsuperscript{th} harmonic, which is 49 cents less than a tritone. This harmonic was selected to give the impression of a mistake resulting in a dissonant interval.

%(known as the \emph{diabolus in musica} in Renaissance theory \citep{drabkin2001tritone})

In the upper bass track from `Danger' (C.7.2), one audible partial is a low D, corresponding to the C$\sharp4+16$ cent partial, near the position of the 7\textsuperscript{th} harmonic (minor seventh). The tone is inharmonic and slightly lower than the 7\textsuperscript{th} harmonic.



\subsubsection{Consecutive partials}\label{sec:groupsofpartials}

The producers may highlight consecutive partials instead of a single one. In `<Fire!' (C.10), with a very low $f_0$ (ca.~37Hz), gain is applied to groups of partials around the 36\textsuperscript{th} harmonic, resulting in an uncertain pitch around 1320Hz. The complex tone from the first partial ($f_0$) can be seen as a \emph{carrier}, with modulation applied via selective gain. A similar approach is used in the `Cardinal' synth break (C.6), where groups of partials are highlighted with a filter's sliding resonance.



\subsubsection{Several perceived pitches: amplified partials or inharmonicity?}\label{sec:severalperceived}

\textbf{Listening test 1} (SM A.1) shows that an inharmonic tone can lead to the perception of more pitches than a harmonic tone. \textbf{Listening test 3} (SM A.3) shows how tones in Primaal's music result in multiple perceived pitches. Does this perception arise from inharmonicity or from boosted energy in the upper partials?

We argue that it generally stems from increased energy in upper partials. The producers boost upper partials to make them audible. The examples in SM C are less inharmonic than the tone in \textbf{Listening test 1}. In many cases, the $f_0$ is very low, and both the $f_0$ and the fundamental of the least-deviating harmonic series \citep[p.~9]{rasch1982perception} may not be heard on most listening systems.


\subsection{Continuous frequency distributions}\label{sec:continousfreqs}

As shown in Figure~\ref{fig:S_summary} (Section~\ref{sec:pitchdimensions}), in Primaal's music, frequency values that evoke pitch are continuously distributed around `poles'. This can result from (1) continuous frequency evolution within a single track, or (2) small variations in discrete frequencies occurring simultaneously across different tracks. The two aspects are interlaced, as frequency evolutions in different tracks are generally not parallel.

\subsubsection{Continuous frequency values: the Roland TR-808 bass as a model} 

A key method for producing continuous frequency values in Primaal's music is the use of the TR-808 bass drum. The producers state that the TR-808 is crucial in urban music, reflecting its influence on Primaal's sound (Section~\ref{ref:bassgeneration}).

The TR-808's $f_0$ drops by a semitone before stabilizsng \citep{deruty2024storch}, as seen in the bass tracks of `Elevate' (C.8) and `Silver' (C.12). For longer bass notes, pitch falls through larger intervals, as in `Boom' (C.1), where it drops half an octave.

This transient-like pitch drop is also used in non-percussive tracks, such as the stems `square synth' in `R U ready' (0'26-0'40), `sampled vocals' in `Elevate' (2'22-2'36), `vocals' in `Silver' (0'08-0'40), and `synths' in `Yada Yada' (0'01-0'14).


\subsubsection{Continuous frequency values: bends, glides, and screws}


Continuous frequency changes may be achieved using bends, glides, or screws (Section~\ref{ref:otheraudioprocs}). These processes are used to confuse pitch perception. To increase this confusion, the producers often set random pitch bend limits to avoid harmonic intervals like the octave or fifth. %, which provide familiar references.

The producers may adjust glide time to the length of the musical element. In the bass tracks from `Elevate' and `Silver' (C.8, C.12), they use the time between onsets to let the glide fully develop. This contrasts with tracks like `Danger', where the glide quickly stabilises (C.7). When possible, they prefer pitch contours that never fully stabilise to enhance pitch ambiguity.



\subsubsection{Examples of continuous frequency distribution stemming from continuous frequencies over time}\label{sec:dists}

Figure~\ref{fig:twodistributions} compares $f_0$ distributions in two tracks: the vocal loop in `Cardinal' (C.5) and the flute loop in `Yada Yada' (C.16), providing real examples of the schematic distributions in Figure~\ref{fig:S_summary}. The top distribution is wider than the bottom one, and the producers confirmed they intentionally set these widths.


\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/Two_distributions.png}
  \caption{Distribution of $f_0$ values over time, excluding contrasts (see Section~\ref{sec:smallscalestructure}). (a) `Cardinal', vocal loop. (b) `Yada Yada', flute loop.}
\label{fig:twodistributions}
\end{figure}

Regarding the `Yada Yada' flute, the producers edited the original sample to keep only content near each attack, making the pitches less stable. However, the overall result remained relatively stable, which the producers felt made it too easy for listeners to identify the pitch. To address this, they contrasted this stable part with wide glides, using the width of the distribution as a musical parameter.

In Primaal's music, frequency distributions exist around a `pole', and deviations from this `pole' contribute to the music's interest. To help listeners identify the `pole', the producers introduce anchors. An example is the vocal gimmick in `Boom', where the second `note' of the loop serves as a reference for the `pole' (C.2). However, the `pole' in one track may not match the tuning of others, as tuning is generally specific to each track. The next section explores the relation between frequency values across tracks.




\subsubsection{Examples of continuous distribution simultaneously stemming from the relations between tracks and from continuous frequencies over time}\label{subsub:continuous}

`Boom' features a kick drum, bass, and looped vocal gimmick. The $f_0$ sequences for these tracks are continuous. The $f_0$ values for the kick drum and bass tracks either follow similar continuous sequences or intersect (SM C.3). It also shows how the vocal track's $f_0$ often neighbours that of the kick drum, creating a continuous distribution through episodic proximity of the $f_0$ values.

In `Silver' (C.12), the bass's $f_0$ initially exceeds the kick drum's, creating dissonance. As the kick drum is shorter, it stops while the bass's pitch continues down. The bass `notes' 2, 3, and 4 start between D$\sharp$1 and E1 and end between D1 and D$\sharp$1. Temporal modeling suggests a perceived pitch lower than the $f_0$, while the kick drum contains a tonal component around D2, indicating initial dissonance, with the bass descending towards the kick drum's pitch (modulo the octave).



\subsubsection{Purpose of a continuous frequency space}\label{sec:purposecontinuous}

The producers use continuous frequencies and distributions to achieve several goals.
They describe Primaal's music as `mono-chordal', where controlled shifts from `poles' bring `perceptual richness'. Chord progressions would mask such shifts (their terms). For example, in `Boom' (C.2), the producers explain that the vocal track `hovers around stable pitches', keeping the listener wondering, `when will this tension be resolved'? Yet, the tension is never resolved, keeping listeners engaged.

Another goal is to emphasise rhythm over pitch. During glides, pitches are hard to pinpoint, so listeners turn to rhythm to find something familiar.

The TR-808 serves as a model for frequency evolution, where partials' frequencies decrease quickly and then stabilise, creating a `tension-release' effect that holds interest. 

The producers use different tuning patterns for each voice to make them stand out, citing the `Silver' brass theme as an example (`D D D E$\flat$ D', 0'02, 0'25, 0'33, 0'59, 1'07), where a higher tuning was chosen so the part stands out.

	


\subsection{Modal organisation in Primaal's music}\label{sec:modality}

\subsubsection{Constitution of the mode}

According to the producers, all pitches in each song originate from a single chosen \emph{final}. Pole pitches are then added through the processes shown in Figure~\ref{fig:S_summary}. The added `notes' may have the following relationships with the final:

\begin{enumerate}[noitemsep]
	\item They may come from a scale where the final is the first degree.
	\item They may be partials of the tone for which the final is the $f_0$.
	\item They may be partials of a tone where the final is a result of temporal modeling.
\end{enumerate}

All `note' choices are influenced by overtones, directly (cases 2 and 3) or indirectly (case 1). The determination of the scale relates to \emph{homoph\={o}noi} intervals \citep{richter2001ptolemy}. Figure~\ref{fig:S_summary_notated} isolates these processes. Relation (1) links arbitrary pitches to harmonic overtones, similar to Western classical music. Relations (2) and (3) directly derive from upper partials (Section~\ref{sec:loudharmonics}).

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/S_summary3_notated.png}
  \caption{Possible determination of poles from the final.} 
\label{fig:S_summary_notated}
\end{figure}

We attempt to identify the modes for each song by ear, though pitch uncertainty complicates the task. It is straightforward for `R U Ready' but difficult for `Danger' and `Sweet Money', and impossible for `<Fire!'. The scale degrees are transposed so that the final is always C.

\begin{itemize}[noitemsep]
	\item `Boom': \textbf{C} E$\flat$/E F G A B$\flat$ 
	\item `Cardinal': \textbf{C} D$\flat$ E$\flat$ G A$\flat$ B$\flat$
	\item `Danger': \textbf{C} E$\flat$ F G B$\flat$/B 
	\item `Elevate': B$\flat$/B \textbf{C} D E
	\item `<Fire!': no relation to the chromatic scale
        \item `R U Ready': B$\flat$ \textbf{C} E$\flat$ F G
	\item `Silver': \textbf{C} D$\flat$ E F G A$\flat$
	\item `Sweet Money': \textbf{C} D F G A$\flat$
	\item `Whomp': \textbf{C} E$\flat$/E F G A$\flat$
	\item `Yada Yada':  \textbf{C} D$\flat$ E$\flat$/E F G A$\flat$ B$\flat$
\end{itemize}

The producers state that they derive their modes from the minor and major diatonic scales, pentatonic modes, urban music, and blues without `blue notes' \citep{kubik2001bluenote}. The following observations can be made.

\begin{enumerate}[noitemsep]
    \item The fifth degree (G) is always present.
    \item The third (E) and seventh degrees (B) are often ambiguous, either being minor or major, or both present in a song.
    \item For the third degree, as noted in Section~\ref{sec:harmonic5}, the producers often balance the major third (harmonic 5) with the minor third to avoid a `too major' sound.
    \item The B$\flat$/B ambiguity recalls the pre-13\textsuperscript{th}-century modal system, where the B did not function as a leading tone. The alteration of the B was subject to interpretation, termed \emph{Music Ficta} \citep{bent2001MusicaFicta}.
\end{enumerate}

\citet[p.~42]{coeurdevey1998histoire} notes that, in the 16\textsuperscript{th} century, the bass note indicates the mode's final, which is also true in Primaal's music. %The bass track centres on the final, and the tonic is played by the bass, with any triad in root position.


\subsubsection{A constraint on the final}

Sections~\ref{sec:lowinharmonic}, \ref{sec:partialamplificationprocess}, \ref{sec:tuneddrums}, and \textbf{listening test 6} (SM A.6) discuss how first partials with low $f_0$ values may be poorly perceived or inaudible. This concern, also raised by hip-hop producer Scott Storch \citep{deruty2024storch}, applies to the TR-808 bass drum-type tones used by Primaal. The producers suggest that choosing D, E$\flat$, or E as the final note optimises these samples' potential. In practice, they use finals near these notes, including C$\sharp$1 in `R U Ready' (C.11), E1 in `Danger' (C.7), D1 in `<Fire!' (C.10), D$\sharp$1 in `Silver' (C.12), and C1 in `Sweet Money' (C.13).


\subsubsection{One or several `reference' notes}

\citet{meeus2023theoretical} uses the term `reference' or `nominal' note, which may not always be the mode's final. In some Primaal songs, the final is the sole `reference' note, while in others, the fifth and sometimes the third (major or minor) also play a key role. The salient notes for each studied song are: `Boom': B and F$\sharp$; `Cardinal': D minor triad; `Danger': B$\flat$; `Elevate': E$\flat$; `<Fire!': difficult to identify; `R U Ready': C minor triad; `Silver': D and A; `Sweet Money': E$\flat$; `Whomp': F major triad; and `Yada Yada': F and C. As noted in Section~\ref{sec:purposecontinuous}, the presence of a salient triad in some songs leads the producers to describe these songs as `mono-chordal'. However, as argued in Section~\ref{sec:modalitytonality}, the presence of a chord does not render the songs tonal.


\subsubsection{Purpose of modality}

In Section~\ref{sec:purposecontinuous}, we explain that the absence of chord progressions allows the derivation of musical parameters from continuous frequency distributions. Tonality would require chord changes, so the Primaal producers prefer a modal organisation. Beyond continuous frequency distributions, they also focus on highlighting rhythmic patterns and the precise editing of elements to fit short-term musical structures (Section~\ref{sec:smallscalestructure}).

This approach is common in hip-hop/R\&B. Many hip-hop tracks are based on a single mode with one final or tonic (Section~\ref{sec:modalitytonality}). The producers aim for music that `hovers around one note' to emphasise other musical elements. They reference Jamie xx's `Gosh' \citep{jamiexx2016gosh} as an example. Other examples include Massive Attack's `Angel' \citep{massiveattack1998angel} and Pop Smoke's `Dior' \citep{popsmoke2019dior}.




\subsubsection{Exceptions to modality}

In Section~\ref{sec:largescalestructure}, we illustrate how one semiotic segment may differ drastically from others, creating long-term structure. In Section~\ref{sec:smallscalestructure}, we show how `contrasts' contradict implications, creating structure at short time scales. In both cases, an element can either take on exceptional values within a dimension or derive from a different system. Sections~\ref{sec:clearertonalitylarge} and \ref{sec:clearertonalitysmall} provide examples of tonality and cadences being used for such structural patterns.

In Section~\ref{sec:largescalestructuretuning}, we present examples from `R U Ready' and `Silver' (Figure~\ref{fig:twostructures}) where tuning changes between segments, though the mode stays similar. While the modal aspect remains intact, this process differs from traditional modality.



\subsection{Tuned drums in Primaal's production}\label{sec:tuneddrums}

The producers tuned the kick drum in all ten examples considered in this paper, and the snare drum in `Elevate' and `Whomp'. Examples include:

\begin{itemize}[noitemsep]
    \item `Danger', kick drum (C.7.3): weakly harmonic, pitch close to the bass's.
    \item `Silver', kick drum (C.12.4): tuning based on temporal pitch modeling, not the $f_0$. All percussions in the song were tuned.
    \item `Whomp', kick drum (C.15): pitch is around C, loosely tuned to the tonality's 5\textsuperscript{th} degree, while the snare was transposed from C to B to fit the mode.
\end{itemize}

The producers also provided insights on drums not subject to signal analysis in this study:

\begin{itemize}[noitemsep]
    \item The pitches in `Sweet Money' were derived from the opening tom strokes, providing a reference.
    \item In `Elevate', the kick drum is perceived as D, the song's final, while the snare is tuned unusually to the minor sixth (F and B flat).
    \item In `<Fire!', the kick drum was tuned even though identifiable pitches are absent, suggesting that the presence of pitch sensation without pitch identification suffices for tuning.
\end{itemize}



\subsection{Large-scale structure (semiotic structure)}\label{sec:largescalestructure}

In this section, we consider various techniques used by the Primaal producers to articulate large-scale structure, as defined in Section~\ref{sec:structurebackground}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\columnwidth]{imgs/twostructures.png}
  \caption{Large-scale structures: (a) `R U Ready'; (b) `Silver'; (c) `Elevate'; (d) `Cardinal'. Top line, bar number. Segment splitting followed \citet{bimbot2012semiotic}, with segment labelling loosely based on the same source.} 
\label{fig:twostructures}
\end{figure}

\subsubsection{Tuning as a determinant of large-scale structure}\label{sec:largescalestructuretuning}

In `R U Ready' and `Silver', a change in bass sound contributes to the large-scale structure (SM~C.11, C.12). This change in sound is accompanied by a tuning shift, making the bass seem lower. However, this shift does not correspond to a tonal modulation---i.e., `a firmly established change of key' \citep{saslaw2001modulation}. The mode's final remains constant, with only the tuning altered. Figure~\ref{fig:twostructures} (a)(b) shows the large-scale structure, where the tuning of the orange `B' segments differs from that of the blue ones.

Non-Primaal examples of tuning as a determinant of large-scale structure include Diplo's `Express Yourself' \citep[1'19--1'37]{diplo2012expressyourself}, Jedi Mind Tricks' `Silence' \citep[1'00--1'11 and 2'01--2'12]{jedimind2009}, and Skrillex's `Scary Monsters and Nice Sprites' \citep{skrillex2011scary}.% In Skrillex's case, the 0'41-0'55 segment with different tuning is later combined with previous segments, linking to small-scale structure (Section~\ref{sec:smallscalestructure}).

\subsubsection{Change of mode and tuning as a determinant of large-scale structure}

In `Elevate', the producers use a mode change to build the large-scale structure. The section between 1'09 and 1'38, shown as orange segments in Figure~\ref{fig:twostructures} (c), uses G as the mode's final instead of E$\flat$ (SM C.8). Additionally, the tuning changes. The simultaneous changes in mode and tuning are intended to introduce a sense of uncertainty, breaking the established mode and creating tension, which resolves when the original mode returns.


\subsubsection{Clearer tonality as a determinant of large-scale structure}\label{sec:clearertonalitylarge}

In `Cardinal', the producers deviate from their usual writing process to shape the large-scale structure. This reflects the use of `[c]onformation to [the composition] process [as] a musical parameter' (Section~\ref{sec:aspectsofpitch}, Figure~\ref{fig:S_summary}). Figure~\ref{fig:twostructures} (d) shows the large-scale structure, where blue `A' segments revolve around D and F, with F as the mode's final. In the orange `B' segments, horns play sequences based on E$\flat$-D and E$\flat$-B$\flat$-D, while a synth plays arpeggios around E$\flat$ major and D minor chords. The tonal cadence is reminiscent of a flattened sub-mediant chord \citep[p.~120]{forte1979tonal}. This deliberate use of clearer tonality contrasts with their usual approach to establish large-scale structure.

Other Primaal songs show similar processes. While `<Fire!' (SM C.10) generally avoids the twelve-tone chromatic scale (Section~\ref{sec:modality}), the producers inserted two segments (1'15--1'30 and 2'37--2'50) featuring a brass section with identifiable pitches. Non-Primaal examples in which similar structure articulation techniques are used include Britney Spears' `Work Bitch' \citep[2'49--3'19]{britney2013workbitch}, Kanye West's `On Sight' \citep[1'17--1'30]{kanyewest2013onsight}, and Skrillex' `Rumble' \citep[1'02--1'15 and 2'11--end]{skrillex2023rumble}.



\subsection{Small-scale structure (form)}\label{sec:smallscalestructure}

In this section, we consider aspects of small-scale structure, as defined in Section~\ref{sec:structurebackground}. 

\subsubsection{Unexpected pitch movements as a determinant of form}\label{sec:smallscale1}

The Primaal producers often use unexpected pitch movements as contrasts. They explain that when they allow listeners to identify a stable pitch, they quickly disrupt it with wide-ranging pitch patterns, using bends, screws, and octaviations (transposing the audio by octaves). Examples include the vocal loop of `Cardinal' (cuts, bends, screws, and octaviations, SM C.5), the bass from `<Fire!' (slow upward progression followed by octaviation, SM C.10), and the flute track from `Yada Yada' (Section~\ref{sec:dists} and SM C.16). 

The producers note that creating small-scale structures using these techniques requires flexibility and precision only achievable in digital audio workstations, making these processes an \emph{idiom} of DAWs \citep{huron2009characterizing}.


\subsubsection{Clearer tonality as a determinant of form}\label{sec:clearertonalitysmall}\label{sec:smallscale2}

Section~\ref{sec:clearertonalitylarge} illustrates how the producers use tonality as a deviation from their compositional process to build large-scale structure. They may implement similar deviations for short-term structure. Implications are built in a modal context, making tonality a contrast. Examples include the following.

\begin{itemize}[noitemsep]
\item `Cardinal' (1'22): a violin arpeggio on two consecutive perfect triads provides this contrast.
\item `Whomp': with an F final, an organ at 0'30, 0'45, 1'37, and 1'50 plays a sequence evoking `F major--G$\flat$ major-- E$\flat$ major' chords.
\item `Boom': with a B final, an F$\sharp$ appears at the end of three segments (0'46, 1'30, and 1'53), resolving in a V-I sequence.
\end{itemize}




\subsubsection{Change of tuning and clearer tonality as a determinant of form}\label{sec:smallscale3}

In `Silver', contrasts occur at 0'14, 0'22, 0'31, and 1'23, featuring a synthesiser playing B$\flat$-A-A-A, followed by a D (the final) at the next segment's start. This pattern evokes a tonal cadence with a flattened sub-mediant chord. The tuning is lower than the surrounding tracks, with the last A close to A$\flat$. The lower tuning being unexpected, it enhances the contrast.

The producers note that for an unexpected element like this contrast, they would typically adjust the tuning \emph{upwards} (Section~\ref{sec:purposecontinuous}). Thus, a \textit{lower} tuning adds another layer of surprise. Using \citepos{conklin2010discovery} terminology, the contrast's unexpectedness comes from both `intra-opus' relations and `inter-opus' information.




\subsubsection{Contrasts may or may not be based on a previously presented musical parameter}


The producers acknowledge that every musical passage they write operates within a system, as described by \citet{bimbot2016system}. This system is based on the musical parameters outlined in Section~\ref{sec:aspectsofpitch}. To create contrasts, the producers either (1) introduce exceptional values for these parameters or (2) introduce new, unexpected parameters. Section~\ref{sec:smallscale1} illustrates contrasts of type~(1), where pitch is already part of the implications. Section~\ref{sec:smallscale2} represents contrasts of type~(2), where the modal context introduces a tonal contrast. Section~\ref{sec:smallscale3} combines both, where the contrast is tonal, but `tuning' is also a parameter within the implications.


\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Summary and conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary and conclusion}\label{sec:conclusion}


Primaal is a project under the Hyper Music production company, a branch of Neodrome Entertainment. Currently, Primaal's music is primarily sold to advertisement companies for use in ads for global corporations. Influences on Primaal's music come from urban and electronic genres (Section~\ref{sec:Primaal}).


\subsection{Summary of observations}


We critically listened to Primaal's music with the producers (Section~\ref{sec:analyticalprocess}), applying phenomenological reduction to \emph{bracket out} musical education (Section~\ref{ref:phenomenologicalreduction}). We examined the production process and the technologies (Section~\ref{sec:tools-and-techniques}) and analysed representative excerpts (SM C), focusing on pitch.

Our conclusion is that pitch manipulation in this music differs significantly from its use in Western classical music, specifically the~1650--1875 period. In particular, a central principle in Primaal's music is cultivating \emph{pitch uncertainty} (Section~\ref{sec:pitch-uncertainty}). As confirmed by \textbf{listening test 3} (SM A.3), resulting from deliberate production techniques, the number of pitches at a given moment is generally uncertain.

We suggested that Primaal's music is primarily \emph{modal} (Sections~\ref{sec:pitchdimensions} and \ref{sec:modality}), with scale degrees defined as \emph{distributions} rather than discrete values. The distributions stem from continuous frequency evolution over time and the superimposition of slightly different frequencies at a given moment (Sections~\ref{sec:pitchdimensions} and \ref{sec:continousfreqs}).

Most tones in Primaal's music are \emph{inharmonic}, sometimes highly so (Sections \ref{sec:inharmonicity} and \ref{sec:inharmonicityprimaal}). The frequency derived from temporal modeling is generally different from the $f_0$. The producers deliberately use inharmonicity to increase pitch uncertainty.

The producers derive pitches from the \emph{upper partials of bass tracks} (Sections~\ref{sec:loudharmonics} and \ref{sec:examplesofboostedpartials}), preventing pitches from being organised around equal temperament scales. The first partial is often inaudible (Section~\ref{sec:lowinharmonic}), making the overtones even more significant.

Drums are tuned, even though their pitch content is uncertain (Sections~\ref{sec:pitchcontentindrums} and \ref{sec:tuneddrums}). The producers deliberately use this \emph{pitch strength continuum} as a musical parameter.


\subsection{Historical perspective}


While Primaal's manipulation of pitch has little in common with late Baroque and Viennese classical music, it may relate more closely to earlier Western music concerns. Several aspects of Primaal's production support this: their use of \emph{homoph\={o}noi} intervals (Ptolemy, 2\textsuperscript{nd} century, Section~\ref{sec:modality}); their interpretation of \emph{mode} resembles 11\textsuperscript{th}-century definitions (Section~\ref{sec:modalitybackground}); and their use of \emph{combination tones} and \emph{acoustic beating} echoes 16\textsuperscript{th} and Renaissance music theory (Sections~\ref{sec:acousticbeats} and  \ref{sec:combinationtones}).

Despite differing from Western composers of the Baroque and classical eras (1650--1875), Primaal's techniques are similar to some 20\textsuperscript{th}-century `art' music. For example, Maurice Ravel blurred timbre and pitch in {\em Bol\'ero\/} (1928) by arranging a melody in parallel thirds, sixths, and fifths, producing rich timbral effects, similar to Primaal's boosting of the fifth harmonic (Section~\ref{sec:harmonic5}).

Further examples of continuous pitch manipulation in 20\textsuperscript{th}-century music include Ligeti's {\em Atmosph\`eres\/} (1961), Penderecki's {\em Threnody\/} (1961), and Stockhausen's use of ring modulation (Section~\ref{ref:ringmodulation}) in {\em Mixtur\/} (1964), {\em Mantra\/} (1970), and {\em Mikrophonie II\/} (1965). The Primaal producers acknowledge the influence of Ravel and Stockhausen in their work.


\subsection{Summary of contributions}

We believe the work presented here contributes to music analysis, music information retrieval, computational creativity, music generation, and psychoacoustics.

Contributions to \emph{music analysis} include the following.

\begin{itemize}[noitemsep]
    \item We demonstrate the potential of phenomenological reduction in popular music analysis. Ignoring score notation highlights under-documented musical dimensions related to pitch.
    \item This helps us better understand contemporary popular music: there is more to pitch than musical notes. Figure~\ref{fig:S_summary} (Section~\ref{sec:pitchdimensions}) outlines dimensions beyond notes.
    \item Boosting partials to make them audible underlines a timbre--pitch continuum (Section~\ref{sec:partialamplificationprocess}), bridging the gap between harmony-focused and production-focused literature.
    \item Our approach challenges the reification of the score (Section~\ref{ref:scoreasbias}). Instead of performing music analysis from scores, we suggest starting from the production process, the signal, and what the listener may actually hear.
\end{itemize}


Contributions to \emph{music information retrieval (MIR)} include the following.

\begin{itemize}[noitemsep]
    \item We show that one complex tone does not always result in one pitch (Sections~\ref{ref:soleorigin} and \ref{sec:pitchtracking}).
    \item Pitch tracking should estimate the probability of heard pitches, aligning more with psychoacoustics, rather than attempting to reverse-engineer the `notes' that were played in order to produce the sounds.
    \item Continuous pitch distributions suggest that representing pitch in terms of discrete notes may be generally inappropriate for popular music (Section~\ref{ref:mircommunity}).
\end{itemize}

Contributions to \emph{computational creativity} and \emph{music generation} include the following.

\begin{itemize}[noitemsep]
    \item Expressive variations in pitch and timbre are crucial for music generation---not just tempo, timing, and dynamics.
    \item Improved descriptions of contemporary music, accounting for pitch-manipulation techniques, could enhance text-to-music interfaces like Google's MusicLM.
    \item Understanding pitch manipulation may open new avenues for practical music generation applications such as the A.I. song contest.
\end{itemize}

Finally, the contributions of this paper to \emph{psychoacoustics} include the following.

\begin{itemize}[noitemsep]
    \item Instead of debating whether partials can be heard individually, we propose that partials may be audible if loud enough and suggest studying audibility thresholds.
    \item Conditions for hearing individual partials may occur more commonly than was previously thought (Sections~\ref{ref:bassgeneration}, \ref{ref:distortion}, and \ref{ref:otheraudioprocs}).
    \item Results from \textbf{listening tests 2 and 3} (SM A.2 and A.3) suggest probabilistic pitch models may better suit popular music. Assuming that the `number' of simultaneous pitches is always a positive integer may lead to an over-simplified representation of what is heard.
    %The number of simultaneous pitches in the ground truth may not be an integer.
    \item Inharmonicity in Primaal's music (Sections~\ref{sec:inharmonicity} and \ref{sec:inharmonicityprimaal}) may provide a new perspective on the assumption that `[t]he most commonly considered form of pitch-evoking sound is a harmonic complex tone' \citep{oxenham2012pitch} -- see Section~\ref{ref:soleorigin}.
    \item TR-808 basses, where the first partial is often inaudible, challenge the assumption that tones share the same pitch if they share the same $f_0$ (Section~\ref{sec:lowinharmonic}).
\end{itemize}




\subsection{Future work}

The main motivation of the Primaal producers is to sell their music, meaning the music must align with current trends. They claim their influences stem from widely-recognised genres and artists. We suggest that their approach is not unique and that the findings in this paper may apply to other artists in similar genres. In future work, we therefore plan to apply this methodology to other successful contemporary popular music artists.




\section*{Disclosure statement}

The authors report there are no competing interests to declare.


\bibliographystyle{apalike}
\bibliography{mybib.bib}

\end{document}



