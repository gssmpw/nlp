\begin{abstract}
Which large language model (LLM) is better? Every evaluation tells a story, but what do users really think about current LLMs?
This paper presents \method{}, an LLM-powered interviewer that conducts in-the-moment user experience interviews, right after users interacted with LLMs, and automatically gathers insights about user opinions from massive interview logs.
We conduct a study with thousands of users to understand user opinions on mainstream LLMs, recruiting users to first chat with a target LLM and then interviewed by \method{}.
Our experiments demonstrate that \method{} captures interesting user opinions, for example, the bipolar views on the displayed reasoning process of DeepSeek-R1 and demands for information freshness and multi-modality.
Our collected chat-and-interview logs will be released.\def\thefootnote{*}\footnotetext{These authors contributed equally to this work.}\def\thefootnote{â€ }\footnotetext{This work does not relate to their position at Amazon.}
\end{abstract}