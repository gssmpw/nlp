% \newpage
\section{Limitations}

One major limitation is that, being an academic project, our user study is limited to the population available on MTurk, which is not a thorough representation of the US nor global market. The user opinions collected thus only reflect this specific demographic distribution, which can be different from other populations. 
This is also a potential risk of our framework: \method{} is to capture the opinions of studied users, but may be misinterpreted as the universal opinions of all potential users.

Another limitation is that as the first demonstration of LLM-powered interviewing, we heavily rely on the power of existing LLMs through prompting API. Though being useful, there are a lot of possible improvements from the modeling side which can potentially further improve the interviewing effectiveness.

The Insighter produces both quantitative and qualitative insights automatically extracted from interview logs. Its effectiveness is fine to provide a high level idea of user opinions but not perfect as a once-for-all ultimate LLM leaderboard. For example, the numerical ratings are not sensitive enough to tell the differences between evaluated LLMs, albeit these are all top tier models with similar performances.
How to better extract insights from massive user interview logs is another future research direction.