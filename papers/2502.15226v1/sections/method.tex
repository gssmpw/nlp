\section{Methodology}

\method{} leverages LLMs to conduct in-the-moment UX interviews and understand user opinions. It includes two components: \method-Interviewer and \method-Insighter. 

\subsection{\method{}-Interviewer}
\label{sec.interviewer}

\method-Interviewer conducts in-the-moment UX interviews right after users interacted with a product, which in this study is chatting with a mainstream LLM. 
We develop \method-Interviewer by implementing standard user interview practices~\cite{hartson2012ux} into LLMs through carefully designed prompts.
% , to gather user opinions on evaluation dimensions derived from UX research.

\textbf{Interview Design.} \method-Interviewer is designed to conduct semi-structured interviews~\citep{wilson2013interview}, starting with a set of predefined interview dimensions and probing user for deeper insights, with the flexibility to explore topics emerged from user responses. 

Specifically, to understand user opinions on LLMs, we follow previous research on chatbot user experiences~\citep{casas2020trends} and include the evaluation dimensions listed in Table~\ref{tab:dim}.
The first four dimensions gather insights about the effectiveness of the target LLMs.
The improvements dimension aims to elicit user opinions in an open-ended manner, while the last one asks users for an explicit Likert rating of the target LLM. 

\textbf{LLM-Powered Interviewer.} We implement \method-Interviewer by building these interview principles into prompting an LLM. 

We design the prompts to include instructions that assign the interviewing task to the LLM, specifications of the interview task, and a step-by-step guild of how to complete the task. The steps includes reviewing the chat history between user and the target LLM for in-the-moment study, the designed interview flow, and instructions to conduct a semi-structured interview. The instructions include dimensions to cover and encourage follow-ups probes. The full prompts used in \method-Interviewer can be found in Appendix Figure~\ref{fig:interviewer_prompt}.

The capabilities of LLMs enables \method-Interviewer to collect in-depth user interviewers at a reduced cost, without the need of much human intervention from the UX side. It is also easier to collect in-the-moment interviewers as users can interact with the LLM interviewer anywhere they want, rather than being interviewed in a controlled setting by a human UX researcher.

\input{tables/dim}

\subsection{CLUE-Insighter}
\label{sec.insigher}

To gain collective insights from massive user experience interviews, we build \method-Insighter to analyze the interview logs. It first maps raw interview rounds into the interview dimensions 
and then analyzes corresponding user responses.

\textbf{Categorize Interview Rounds.} We first categorize each interview round---an interchange between \method-Interviewer and the user---into one of the evaluation dimensions in Table~\ref{tab:dim}. This is done by prompting LLMs with instructions.

Specifically, we provide the previous rounds in the interview session as well as the to-be classified round, as context to an LLM and prompt the model to categorize the round into the targeted categories. This is applied on all interview rounds to assign a dimension category to them. The detailed prompts are listed in Appendix Figure~\ref{fig:insight_dimension_classsifier_prompt}.

\textbf{Quantitative Metrics.} \method-Insighter  automatically generates a numerical score for each user response in the first four dimensions in Table~\ref{tab:dim}.
It is done by prompting an LLM to convert the user responses to a Likert rating of 1 (bad), 2 (mediocre), and 3 (good). 
Similar to the dimension mapping, we perform a zero-shot classification to the LLM and instruct it to produce the numerical rating. The prompt is in Appendix Figure \ref{fig:insight_rating_classsifier_prompt}.

The numerical ratings from individual user responses are merged to quantitative metric scores for corresponding dimensions.

\textbf{Topic Analysis.}  To surface high level user insights from raw responses, \method-Insighter applies standard topic analysis~\cite{grootendorst2022bertopic} on the user responses categorized to each dimension.

\input{tables/data_stat}

\method-Insighter first applies simple rule-based filters to remove chit-chat phrases and non-informative texts from user responses, as detailed in Appendix~\ref{app.implementation}. LLM prompting is used on the rest of the user responses to extract a list of insights from those responses. 
We then use BERTopic3~\cite{grootendorst2022bertopic} to cluster these user insights into topics.

Specifically, we embed user chat rounds using  OpenAI text-embedding-3-small, and then reduce their dimension from 1536 to 5 using uniform manifold approximation and projection~\cite{mcinnes2018umap}, with a local neighborhood size of 5. We cluster the result embeddings using HDBSCAN~\cite{malzer2020hybrid}.
We set the minimum cluster size to be 5 and used Claude 3.5 Sonnet (10-22) to summarize the key themes of each clustering on ten randomly sampled user rounds. 

The quantitative metrics and topics produced by \method-Insighter  aim to provide a bird's-eye view of user opinions. They serve as entry points to, but not replacements of the interview logs. The latter is the ultimate source for user opinions.