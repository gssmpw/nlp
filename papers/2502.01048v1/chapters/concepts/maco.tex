

The last section of this chapter will be dedicated to a novel method that will enable us one problem that we identify in \autoref{sec:concepts:craft}: the visualization of concept. Feature visualization -- defined in \autoref{def:intro:feature_viz} -- has gained substantial popularity, particularly after the seminal and influential work of the Clarity team~\cite{olah2017feature}, which established it as a crucial tool for explainability.
However, its widespread adoption has been limited due to a reliance on tricks to generate interpretable images, and corresponding challenges in scaling it to deeper neural networks.
Here, we will introduce \magfv, a simple approach to address these shortcomings.
The main idea is to generate images by optimizing the phase spectrum while keeping the magnitude constant to ensure that generated explanations lie in the space of natural images. Our approach yields significantly better results -- both qualitatively and quantitatively -- and unlocks efficient and interpretable feature visualizations for large state-of-the-art neural networks.
We also show that our approach exhibits an attribution mechanism allowing us to augment feature visualizations with spatial importance.


Overall, our approach unlocks, for the first time, feature visualizations for large, state-of-the-art deep neural networks without resorting to any parametric prior image model.

\begin{figure}[ht]
\begin{center}
   \includegraphics[width=.99\textwidth]{assets/maco/big_picture.jpg}
\end{center}

\caption{\textbf{Comparison between feature visualization methods for ``White Shark'' classification.}
\textbf{(Top)} Standard Fourier preconditioning-based method for feature visualization~\cite{olah2017feature}.
\textbf{(Bottom)} Proposed approach, \magfv, which incorporates a Fourier spectrum magnitude constraint. %
}
\label{fig:maco:logits_fail}

\end{figure}

\subsection{Introduction}

As discussed in \autoref{chap:attributions}, the initial tools in the explainability toolkit were primarily attribution methods~\cite{simonyan2014deep,smilkov2017smoothgrad,selvaraju2017gradcam,fel2021sobol,novello2022making,sundararajan2017axiomatic,zeiler2014visualizing,shrikumar2017learning,Fong_2017,graziani2021sharpening}. We also seen in ~\autoref{sec:attributions:metapred} that those approaches only offer a partial understanding of the learned decision processes as they aim to identify the location of the most discriminative features in an image, the ``\where'', leaving open the ``\what'' question, \textit{i.e.} the semantic meaning of those features.


Feature visualization methods, which aim to bridge this gap, involve formulating and solving an optimization problem to identify an input image that maximizes the activation of a specific target element (be it a neuron, layer, or the entire model)~\cite{zeiler2014visualizing}. Most of the approaches developed in the field fall along a spectrum based on how strongly they regularize the model. At one end of the spectrum, if no regularization is used, the optimization process can search the whole image space, but this tends to produce noisy images and nonsensical high-frequency patterns~\cite{erhan2009visualizing}. To circumvent this issue, researchers have proposed to penalize high-frequency in  the resulting images -- either by reducing the variance between neighboring pixels~\cite{mahendran2015understanding}, by imposing constraints on the image's total variation~\cite{nguyen2016synthesizing,nguyen2017plug,simonyan2014deep}, or by blurring the image at each optimization step~\cite{nguyen2015deep}. However, in addition to rendering images of debatable validity, these approaches also suppress genuine, interesting high-frequency features, including edges. To mitigate this issue, a bilateral filter may be used instead of blurring, as it has been shown to preserve edges and improve the overall result~\cite{tyka2016class}. Other studies have described a similar technique to decrease high frequencies by operating directly on the gradient, with the goal of preventing their accumulation in the resulting visualization~\cite{AudunGoogleNet}. One advantage of reducing high frequencies present in the gradient, as opposed to the visualization itself, is that it resists the amplification of high frequencies while still allowing them to manifest when consistently promoted by the gradient.
This process, known as "preconditioning" in optimization, can greatly simplify the optimization problem. The Fourier transform has been shown to be a successful preconditioner as it forces the optimization to be performed in a decorrelated and whitened image space~\cite{olah2017feature}. 

The emergence of high-frequency patterns in the absence of regularization is associated with a lack of robustness and sensitivity of the neural network to adversarial examples~\cite{szegedy2013intriguing}, and consequently, these patterns are less often observed in adversarially robust models~\cite{engstrom2019adversarial, santurkar2019image, tsipras2018robustness}. An alternative strategy to promote robustness involves enforcing small perturbations, such as jittering, rotating, or scaling, in the visualization process~\cite{mordvintsev2015inceptionism}, which, when combined with a frequency penalty~\cite{olah2017feature}, has been proved to greatly enhance the generated images.

Unfortunately, previous methods in the field of feature visualization have been limited in their ability to generate visualizations for newer architectures beyond VGG, resulting in a lack of interpretable visualizations for larger networks like ResNets~\cite{olah2017feature}. Consequently, researchers have shifted their focus to approaches that leverage statistically learned priors to produce highly realistic visualizations. One such approach involves training a generator, like a GAN~\cite{nguyen2016synthesizing} or an autoencoder~\cite{wang2022traditional, nguyen2017plug}, to map points from a latent space to realistic examples and optimizing within that space. Alternatively, a prior can be learned to provide the gradient (w.r.t the input) of the probability and optimize both the prior and the objective jointly~\cite{nguyen2017plug, tyka2016class}. Another method involves approximating a generative model prior by penalizing the distance between output patches and the nearest patches retrieved from a database of image patches collected from the training data~\cite{wei2015understanding}.
Although it is well-established that learning an image prior produces realistic visualizations, it is difficult to distinguish between the contributions of the generative models and that of the neural network under study. Hence, in this work, we focus on the development of visualization methods that rely on minimal priors to yield the least biased visualizations.


Our proposed approach, called MAgnitude Constrained Optimization (\magfv), builds on the seminal work by Olah et al. We propose a straightforward re-parametrization that essentially relies on exploiting the phase/magnitude decomposition of the Fourier spectrum, to exclusively optimizing the image's phase while keeping its magnitude constant.
Such a constraint is motivated by psychophysics experiments that have shown that humans are more sensitive to differences in phase than in magnitude~\cite{oppenheim1981importance,caelli1982visual,guyader2004image,joubert2009rapid, gladilin2015role}. Our contributions are threefold:

\begin{enumerate}[label=(\textit{\textbf{\roman*}})]

\item{We unlock feature visualizations for large modern CNNs without resorting to any strong parametric image prior (see Figure~\ref{fig:maco:logits_fail}).}

\item{We describe how to leverage the gradients obtained throughout our optimization process to combine feature visualization with attribution methods, thereby explaining both ``\what'' activates a neuron and ``\where'' it is located in an image.}

\item{We introduce new metrics to compare the feature visualizations produced with \magfv~to those generated with other methods.}
\end{enumerate}
As an application of our approach, we propose feature visualizations for FlexViT \cite{beyer2022flexivit} and ViT \cite{Dosovitskiy2021-zy} (logits and intermediate layers;  see Figure~\ref{fig:maco:logits_and_internal}).  We also employ our approach on a feature inversion task to generate images that yield the same activations as target images to better understand what information is getting propagated through the network and which parts of the image are getting discarded by the model (on ViT, see Figure~\ref{fig:maco:inversion}).
Finally, we will make a link with our work introduced in \autoref{sec:concepts:craft} and show how to combine our work with \craft (see Figure~\ref{fig:maco:concepts}). As feature visualization can be used to optimize in directions in the network's representation space, we employ \magfv~to generate concept visualizations, thus allowing us to improve the human interpretability of concepts and reducing the risk of confirmation bias. 

\subsection{Magnitude-Constrained Feature Visualization}




\paragraph{Notations}

Throughout, we consider a general supervised learning setting, with an input space $\sx \subseteq \Real^{h \times w}$, an output space $\sy \subseteq \Real^c$, and a classifier $\f : \sx \to \sy$ that maps inputs $\vx \in \sx$ to a prediction $\v{y} \in \sy$.
Without loss of generality, we assume that $\f$ admits a series of $L$ intermediate spaces $\s{A}_\ell \subseteq \Real^{p_\ell}, 1 < \ell < L$.
In this setup, $\f_\ell : \sx \to \s{A}_\ell$ maps an input to an intermediate activation $\v{v} = (v_1, \ldots, v_{p_\ell})^\intercal \in \s{A}_\ell$ of $\f$.
We respectively denote $\fourier$ and $\fourier^{-1}$ as the 2-D Discrete Fourier Transform (DFT) on $\sx$ and its inverse.








\paragraph{Optimization Criterion.}
The primary goal of a feature visualization method is to produce an image $\vx^\star$ that maximizes a given criterion $\mathcal{L}_{\v{v}}(\vx) \in \Real$; usually some value aggregated over a subset of weights in a neural network $\f$ (neurons, channels, layers, logits).
A concrete example consists in finding a natural "prototypical" image $\vx^\star$ of a class $k \in \llbracket 1, K \rrbracket$ without using a dataset or generative models.
However, optimizing in the pixel space $\Real^{W \times H}$ is known to produce noisy, adversarial-like $\vx^\star$. Therefore, the optimization is constrained using a regularizer $\Omega: \sx \to \Real^+$ to penalize unrealistic images:
\begin{equation}
\vx^\star = \argmax_{\vx \in \sx} \mathcal{L}_{\v{v}}(\vx) - \lambda \Omega(\vx).
\label{eq:maco:general}
\end{equation}
In Eq.~\ref{eq:maco:general}, $\lambda$ is a hyperparameter used to balance the main optimization criterion $\mathcal{L}_{\v{v}}$ and the regularizer $\Omega(\cdot)$. Finding a regularizer that perfectly matches the structure of natural images is hard, so  proxies have to be used instead. Previous studies have explored various forms of regularization spanning from total variation, $\ell_1$, or $\ell_2$ loss~\cite{nguyen2016synthesizing,nguyen2017plug,simonyan2014deep}. More successful attempts rely on the reparametrization of the optimization problem in the Fourier domain rather than on regularization.


\subsubsection{A Fourier perspective}

Mordvintsev et al.~\cite{mordvintsev2018differentiable} noted in their seminal work that one could use differentiable image parametrizations to facilitate the maximization of $\mathcal{L}_{\v{v}}$. Olah et al.~\cite{olah2017feature} proposed to re-parametrize the images using their Fourier spectrum. Such a parametrization allows amplifying the low frequencies using a scalar $\v{w}$. Formally, the prototypal image $\vx^\star$ can be written as $\vx^\star = \fourier^{-1}(\v{z}^\star \odot \v{w})$ with:

$$ \v{z}^\star = \argmax_{\v{z} \in \mathbb{C}^{W \times H}} \mathcal{L}_{\v{v}}(\fourier^{-1}(\v{z} \odot \v{w})).$$

Finding $\vx^\star$ boils down to optimizing a Fourier buffer
$\v{z} = \bm{a} + i \bm{b}$ together with boosting the low-frequency components and then recovering the final image by inverting the optimized Fourier buffer using inverse Fourier transform.

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{assets/maco/leakage.jpg};
\caption{\textbf{Comparison between Fourier FV and natural image power spectrum.} In \textbf{(left)}, the power spectrum is averaged over $10$ different logits visualizations for each of the $1000$ classes of ImageNet. The visualizations are obtained using the \textbf{Fourier FV}Fourier FV method to maximize the logits of a ViT network~\citep{olah2017feature}. In \textbf{(right)} the spectrum is averaged over all training images of the ImageNet dataset.}
\label{fig:maco:leakage}
\end{figure}






However, multiple studies have shown that the resulting images are not sufficiently robust, in the sense that a small change in the image can cause the criterion $ \mathcal{L}_{\v{v}}$ to drop. Therefore, it is common to see robustness transformations applied to candidate images throughout the optimization process. In other words, the goal is to ensure that the generated image satisfies the criterion even if it is rotated by a few degrees or jittered by a few pixels. Formally, given a set of possible transformation functions -- sometimes called augmentations -- that we denote $\mathcal{T}$ such that for any transformation $\augmentation \sim \mathcal{T}$, we have $\augmentation(\vx) \in \sx$, the optimization becomes:

$$ 
\v{z}^\star = \argmax_{\v{z} \in \mathbb{C}^{W \times H}}
\mathbb{E}_{\augmentation \sim \mathcal{T}}(\mathcal{L}_{\v{v}}((\augmentation \circ \fourier^{-1})(\v{z} \odot \v{w})).
$$


Empirically, it is common knowledge that the deeper the models are, the more transformations are needed and the greater their magnitudes should be. To make their approach work on models like VGG, Olah et al.~\cite{olah2017feature} used no less than a dozen transformations. However, this method fails for modern architectures, no matter how many transformations are applied. We argue that this may come from the low-frequency scalar (or booster) no longer working with models that are too deep. For such models, high frequencies eventually come through, polluting the resulting images with high-frequency content -- making them impossible to interpret by humans. %
To empirically illustrate this phenomenon, we compute the $k$ logit visualizations obtained by maximizing each of the logits corresponding to the $k$ classes of a ViT using the parameterization used by Olah et al.~ In Figure~\ref{fig:maco:leakage} (left), we show the average of the spectrum of these generated visualizations over all classes: $\frac{1}{k} \sum_{i=1}^k |\fourier(\vx^\star_i)|$. We compare it with the average spectrum of images on the ImageNet dataset (denoted $\mathcal{D}$): $\mathbb{E}_{\vx \sim \mathcal{D}}(|\fourier(\vx)|)$ (Figure~\ref{fig:maco:leakage}, right panel).
We observe that the images obtained through optimization put much more energy into high frequencies compared to natural images. Note that we did not observe this phenomenon in older models such as LeNet or VGG.

In the following section, we introduce our method named~\magfv, which is motivated by this observation. We constrain the magnitude of the visualization to a natural value, enabling natural visualization for any contemporary model, and reducing the number of required transformations to only two.


\subsubsection{\magfv: from Regularization to Constraint}
\begin{figure}[t!]
\center
\includegraphics[width=1\textwidth]{assets/maco/method.pdf}
\caption{\textbf{Overview of the approach:} \textbf{(a)}  Current Fourier parameterization approaches optimize the entire spectrum (yellow arrow). \textbf{(b)}  In contrast,  the optimization flow in our approach (green arrows) goes from the network activation ($\v{y}$) to the phase of the spectrum ($\v{\varphi}$) of the input image ($\vx$).}

\label{fig:maco:method}
\end{figure}

Parameterizing the image in the Fourier space makes it possible to directly manipulate the image in the frequency domain. We propose to take a step further and decompose the Fourier spectrum $\v{z}$ into its polar form $\v{z} = \v{r} e^{i \v{\varphi}}$ instead of its cartesian form $\v{z} = \bm{a} + i \bm{b}$, which allows us to disentangle the magnitude ($\v{r}$) and the phase ($\v{\varphi}$).

It is known that human recognition of objects in images is driven not by magnitude but by phase~\cite{oppenheim1981importance,caelli1982visual,guyader2004image,joubert2009rapid, gladilin2015role}. Motivated by this, we propose to optimize the phase of the Fourier spectrum while fixing its magnitude to a typical value of a natural image (with few high frequencies). In particular, the magnitude is kept constant at the average magnitude computed over a set of natural images (such as ImageNet), so $\v{r} = \mathbb{E}_{\vx \sim \mathcal{D}}(|\fourier(\vx)|)$. Note that this spectrum needs to be calculated only once and can be used at will for other tasks.

\begin{figure}[ht]
\input{assets/maco/algorithm}
\end{figure}


Therefore, our method does not backpropagate through the entire Fourier spectrum but only through the phase (Figure~\ref{fig:maco:method}), thus reducing the number of parameters to optimize by half. Since the magnitude of our spectrum is constrained, we no longer need hyperparameters such as $\lambda$ or scaling factors, and the generated image at each step is naturally plausible in the frequency domain.
We also enhance the quality of our visualizations via two data augmentations: random crop and additive uniform noise.
To the best of our knowledge, our approach is the first to completely alleviate the need for explicit regularization -- using instead a hard constraint on the solution of the optimization problem for feature visualization.
To summarize, we formally introduce our method:

\begin{definition}[\textbf{\magfv}]
The feature visualization results from optimizing the parameter vector $\v{\varphi}$  such that:
$$
\v{\varphi}^\star = \argmax_{\v{\varphi} \in \Real^{W \times H}}
\mathbb{E}_{\augmentation \sim \mathcal{T}}(\mathcal{L}_{\v{v}}((\augmentation \circ \fourier^{-1})(\v{r} e^{i \v{\varphi}})) ~~~\text{where}~~~ \v{r} = \mathbb{E}_{\vx \sim \mathcal{D}}(|\fourier(\vx)|)
$$
The feature visualization is then obtained by applying the inverse Fourier transform to the optimal complex-valued spectrum: $\vx^\star = \fourier^{-1}((\v{r} e^{i \v{\varphi}^\star})$
\end{definition}









\paragraph{Transparency for free:}\label{sec:maco:transparency}
Visualizations often suffer from repeated patterns or unimportant elements in the generated images. This can lead to readability problems or confirmation biases~\cite{borowski2020exemplary}. It is important to ensure that the user is looking at what is truly important in the feature visualization. The concept of transparency, introduced in \cite{mordvintsev2018differentiable}, addresses this issue but induces additional implementation efforts and computational costs.

We propose an effective approach, which leverages attribution methods -- specifically a variant of Smoothgrad seen in \autoref{chap:attributions}) -- that yields a transparency map $\v{\alpha}$ for the associated feature visualization without any additional cost. Our solution takes advantage of the fact that during backpropagation, we can obtain the intermediate gradients on the input $\partial \mathcal{L}_{\v{v}}( \vx) / \partial \vx$ for free as $\frac{\partial \mathcal{L}_{\v{v}}( \vx)}{\partial \v{\varphi}} =  \frac{\partial \mathcal{L}_{\v{v}}( \vx)}{\partial \vx} \frac{\partial \vx}{\partial \v{\varphi}}$. We store these gradients throughout the optimization process and then average them, as done in SmoothGrad, to identify the areas that have been modified/attended to by the model the most during the optimization process. We note that a similar technique has recently been used to explain diffusion models \cite{boutin2023diffusion}. In Algorithm \ref{alg:maco:cap}, we provide pseudo-code for \magfv~and an example of the transparency maps in Figure~\ref{fig:maco:inversion} (third column).




\begin{figure}
    \centering
    \includegraphics[width=0.98\textwidth]{assets/maco/qualitative_internal.jpg}
    \caption{\textbf{(left) Logits and (right) internal representations of FlexiViT.}  \magfv~was used to maximize the activations of \textbf{(left)} logit units and \textbf{(right)} specific channels located in different blocks of the FlexViT (blocks 1, 2, 6 and 10 from left to right).}
    \label{fig:maco:logits_and_internal}
\end{figure}





\subsection{Evaluation}
\label{section:maco:evaluation}
We now describe and compute three different scores to compare the different feature visualization methods: Fourier (Olah et al.), CBR (optimization in the pixel space), and \magfv~(ours). It is important to note that these scores are only applicable to output logit visualizations. We will then demonstrate how we can use our method to perform concept visualization. %
To keep a fair comparison, we restrict the benchmark to methods that do not rely on any learned image priors. Indeed, methods with learned prior will inevitably yield lower FID scores (and lower plausibility score) as the prior forces the generated visualizations to lie on the manifold of natural images.




\paragraph*{Plausibility score.} We consider a feature visualization plausible when it is similar to the distribution of images belonging to the class it represents.
We quantify the plausibility through an OOD metric (Deep-KNN, recently used in~\cite{sun2022out}): it measures how far a feature visualization deviates from the corresponding ImageNet object category images based on their representation in the network's intermediate layers (see Table~\ref{table:maco:ood_fid}).



\paragraph{FID score.} The FID quantifies the similarity between the distribution of the feature visualizations and that of natural images for the same object category. Importantly, the FID measures the distance between two distributions, while the plausibility score quantifies the distance from a sample to a distribution. To compute the FID,  we used images from the ImageNet validation set and used the Inception v3 last layer (see Table~\ref{table:maco:ood_fid}). Additionally, we center-cropped our $512\times 512$ images to $299\times 299$ images to avoid the center-bias problem~\cite{nguyen2016multifaceted}.



\paragraph{Transferability score.} This score measures how consistent the feature visualizations are with other pre-trained classifiers. To compute the transferability score, we feed the obtained feature visualizations into 6 additional pre-trained classifiers (MobileNet~\cite{howard2017mobilenets}, VGG16~\cite{simonyan2014deep}, Xception~\cite{chollet2017xception}, EfficientNet~\cite{tan2019efficientnet}, Tiny ConvNext~\cite{liu2022convnet} and Densenet~\cite{huang2017densely}), and we report their classification accuracy (see Table~\ref{table:maco:transferability}).

All scores are computed using 500 feature visualizations, each of them maximizing the logit of one of the ImageNet classes obtained on the FlexiViT~\cite{beyer2022flexivit}, ViT\cite{kolesnikov2020bit}, and ResNetV2\cite{he2016deep} models. For the feature visualizations derived from Olah et al.~ \cite{olah2017feature}, we used all 10 transformations set from the Lucid library\footnote{\href{https://github.com/tensorflow/lucid}{https://github.com/tensorflow/lucid}}.
CBR denotes an optimization in pixel space and using the same 10 transformations, as described in~\cite{nguyen2015deep}.
For \magfv, $\augmentation$ only consists of two transformations; first we add uniform noise $\bm{\delta} \sim \mathcal{U}([-0.1, 0.1])^{W \times H}$ and crops and resized the image with a crop size drawn from the normal distribution $\mathcal{N}(0.25, 0.1)$, which corresponds on average to 25\% of the image.
We used the NAdam optimizer \cite{dozat2016incorporating} with $lr=1.0$ and $N = 256$ optimization steps. Finally, we used the implementation of \cite{olah2017feature} and CBR which are available in the Xplique library~\cite{fel2022xplique} \footnote{\href{https://github.com/deel-ai/xplique}{https://github.com/deel-ai/xplique}} which is based on Lucid.

\begin{table}[ht]
\centering
        \begin{tabular}{lccc}
            & FlexiViT & ViT & ResNetV2\\
            \hline
            \multicolumn{4}{l}{$\bullet$\;\textbf{Plausibility score} (1-KNN) ($\downarrow$)}\\

            \magfv & {\bf 1473} & {\bf 1097 } & {\bf 1248} \\%\\
            Fourier~\cite{olah2017feature} & 1815 &  1817 & 1837 \\
            CBR~\cite{nguyen2015deep} &  1866 & 1920 & 1933 \\
            \hline
            \multicolumn{4}{l}{$\bullet$\;\textbf{FID Score}  ($\downarrow$)}\\
            \magfv & {\bf 230.68} & {\bf 241.68} & {\bf 312.66} \\
            Fourier~\cite{olah2017feature} &  250.25 & 257.81 & 318.15 \\
            CBR~\cite{nguyen2015deep} &  247.12 & 268.59 & 346.41 \\
            \hline
        \end{tabular}
        
        \caption{Plausibility and FID scores for different feature visualization methods applied on FlexiVIT, ViT and ResNetV2}
    \label{table:maco:ood_fid}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lccc}
    & FlexiViT & ViT & ResNetV2 \\
    \hline
    \multicolumn{4}{l}{$\bullet$\;\textbf{Transferability score($\uparrow$)}: \magfv / Fourier~\cite{olah2017feature}} \\

    MobileNet  & {\bf 68} \slash~38 & {\bf 48}\slash~37  & {\bf 93} \slash~36 \\
    VGG16         & {\bf 64} \slash~30 & {\bf 50} \slash~30 & {\bf 90} \slash~20 \\
    Xception      & {\bf 85} \slash~61 & {\bf 73} \slash~62 & {\bf 97} \slash~64 \\
    Eff. Net  & {\bf 88} \slash~25 & {\bf 63} \slash~25 & {\bf 82} \slash~21 \\
    ConvNext & {\bf 96} \slash~52 & {\bf 84} \slash~55 & {\bf 93} \slash~60\\
    DenseNet      & {\bf 84} \slash~32 & {\bf 66} \slash~31 & {\bf 93} \slash~25 \\
    \hline
    \\
    \end{tabular}
        \caption{Transferability scores for different feature visualization methods applied on FlexiVIT, ViT and ResNetV2.}
        \label{table:maco:transferability}
\end{table}


























For all tested metrics, we observe that \magfv~produces better feature visualizations than those generated by Olah et al.~\cite{olah2017feature} and CBR~\cite{nguyen2015deep}. We would like to emphasize that our proposed evaluation scores represent the first attempt to provide a systematic evaluation of feature visualization methods, but we acknowledge that each individual metric on its own is insufficient and cannot provide a comprehensive assessment of a method's performance. However, when taken together, the three proposed scores provide a more complete and accurate evaluation of the feature visualization methods.

\subsubsection{Human psychophysics study}
Ultimately, the goal of any feature visualization method is to demystify the CNN's underlying decision process in the eyes of human users. To evaluate \magfv~'s ability to do this, we closely followed the psychophysical paradigm introduced in~\cite{zimmermann2021well}. In this paradigm, the participants are presented with examples of a model's ``favorite'' inputs (i.e., feature visualization generated for a given unit) in addition to two query inputs. Both queries represent the same natural image, but have a different part of the image hidden from the model by a square occludor. The task for participants is to judge which of the two queries would be ``favored by the model'' (i.e., maximally activate the unit). The rationale here is that a good feature visualization method would enable participants to more accurately predict the model's behavior. Here, we compared four visualization conditions (manipulated between subjects): Olah~\cite{olah2017feature}, \magfv~with the transparency mask (the transparency mask is decribed in \ref{sec:maco:transparency}), \magfv~without the transparency mask, and a control condition in which no visualizations were provided. In addition, the network (VGG16, ResNet50, ViT) was a within-subject variable. The units to be understood were taken from the output layer.

\begin{figure}[ht]
\includegraphics[width=0.9\textwidth]{assets/maco/human_exp.png}
\caption{\textbf{Human causal understanding of model activations}. We follow the experimental procedure introduced in~\cite{zimmermann2021well} to evaluate Olah and \magfv~visualizations on $3$ different networks. The control condition is when the participant did not see any feature visualization. 
}
\label{fig:maco:human_results}    
\end{figure}

Based on the data of 174 participants on Prolific (\url{www.prolific.com}), we found both visualization and network to significantly predict the logodds of choosing the right query (Fig.~\ref{fig:maco:human_results}). That is, the logodds were significantly higher for participants in both the \magfv~conditions compared to Olah. On the other hand, our tests did not yield a significant difference between Olah and the control condition, or between the two \magfv~conditions. Finally, we found that, overall, ViT was significantly harder to interpret than ResNet50 and VGG16, with no significant difference observed between the latter two networks. Full experiment and analysis details can be found in the supplementary materials, section~\ref{sup:maco:psychophysics}. 

However, it should be noted that investigating the effect on a neuron-by-neuron basis, as in the original setup, may not be advisable for the issues outlined in \autoref{sec:concepts:craft} and referenced in \cite{elhage2022superposition}. Conducting a parallel study that confirms this by utilizing meaningful directions in the latent space -- e.g., with \craft -- instead of individual neurons would be of interest.

\subsubsection{Ablation study}

    \begin{table}%
        \centering
        \begin{tabular}{lccc}
            FlexiViT & Plausibility ($\downarrow$) & FID ($\downarrow$) & logit magnitude ($\uparrow$) \\
            \hline
            \magfv  & 571.68 & 211.0 & 5.12 \\
            - transparency & 617.9 (+46.2) & 208.1 (-2.9) & 5.05 (-0.1)\\
            - crop & 680.1 (+62.2) & 299.2 (-91.1) & 8.18 (+3.1)\\
            - noise & 707.3 (+27.1) & 324.5 (-25.3) & 11.7 (+3.5)\\
            \hline
            Fourier~\cite{olah2017feature} & 673.3 & 259.0 & 3.22\\
            - augmentations & 735.9 (+62.6) &  312.5 (+53.5) & 12.4 (+9.2)\\
        \end{tabular}
        \caption{\textbf{Ablation study on the FlexiViT model:} This reveals that 1. augmentations help to have better FID and Plausibility scores, but lead to lesser salients visualizations (softmax value), 2. Fourier~\cite{olah2017feature} benefits less from augmentations than \magfv.}
        \label{table:maco:ablation}
    \end{table}


    To disentangle the effects of the various components of \magfv, we perform an ablation study on the feature visualization applications. We consider the following components: (1) the use of a magnitude constraint, (2) the use of the random crop, (3) the use of the noise addition, and (4) the use of the transparency mask. We perform the ablation study on the FlexiViT model, and the results are presented in Table~\ref{table:maco:ablation}. We observe an inherent tradeoff between optimization quality (measured by logit magnitude) on one side, and the plausibility (and FID) scores on the other side. This reveals that plausible images which are close to the natural image distribution do not necessarily maximize the logit.
    Finally, we observe that the transparency mask does not significantly affect any of the scores confirming that it is mainly a post-processing step that does not affect the feature visualization itself.


\subsection{Applications}

We demonstrate the versatility of the proposed \magfv~technique by applying it to three different XAI applications:

\paragraph{Logit and internal state visualization.} For logit visualization, the optimization objective is to maximize the activation of a specific unit in the logits vector of a pre-trained neural network (here a FlexiViT\cite{beyer2022flexivit}). The resulting visualizations provide insights into the features that contribute the most to a class prediction (refer to Figure~\ref{fig:maco:logits_and_internal}a). For internal state visualization, the optimization objective is to maximize the activation of specific channels located in various intermediate blocks of the network (refer to Figure~\ref{fig:maco:logits_and_internal}b). This visualization allows us to better understand the kind of features these blocks -- of a FlexiViT\cite{beyer2022flexivit} in the figure -- are sensitive to.

\paragraph{Feature inversion.} The goal of this application is to find an image that produces an activation pattern similar to that of a reference image. By maximizing the similarity to reference activations, we are able to generate images representing the same semantic information at the target layer but without the parts of the original image that were discarded in the previous stages of the network, which allows us to better understand how the model operates.
Figure~\ref{fig:maco:inversion}a displays the images (second column) that match the activation pattern of the penultimate layer of a VIT when given the images from the first column. We also provide examples of transparency masks based on attribution (third column), which we apply to the feature visualizations to enhance them (fourth column).



\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{assets/maco/inversion.jpg}
    \caption{\textbf{Feature inversion.} Images in the second column match the activation pattern of the penultimate layer of a ViT when fed with the images of the first column. In the third column, we show their corresponding attribution-based transparency masks, leading to better feature visualization when applied (fourth column).}
    \label{fig:maco:inversion}
\end{figure}


\paragraph{Concept visualization.} Herein we combine \magfv~with concept-based explainability. Such methods aim to increase the interpretability of activation patterns by decomposing them into a set of concepts~\cite{ghorbani2019towards}. In this work, we leverage our \craft~concept-based explainability method~\cite{fel2023craft}, which uses Non-negative Matrix Factorization to decompose activation patterns into main directions -- that are called concepts --, and then, we apply \magfv~to visualize these concepts in the pixel space. To do so, we optimize the visualization such that it matches the concept activation patterns. In Figure~\ref{fig:maco:concepts}b, we present the top $2$ most important concepts (one concept per column) for five different object categories (one category per row) in a ResNet50 trained on ImageNet. The concepts' visualizations are followed by a mosaic of patches extracted from natural images: the patches that maximally activate the corresponding concept. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\textwidth]{assets/maco/concept_maco.jpg}
    \caption{\textbf{Concept visualization.} \magfv~is used to visualize concept vectors extracted with the \craft~ method~\autoref{sec:concepts:craft}. The concepts are extracted from a ResNet50 trained on ImageNet.}
    \label{fig:maco:concepts}
\end{figure}











\subsection{Limitations}\label{sec:maco:limitations}
We have demonstrated the generation of realistic explanations for large neural networks by imposing constraints on the magnitude of the spectrum. However, it is important to note that generating realistic images does not necessarily imply effective explanation of the neural networks. The metrics introduced in this section allow us to claim that our generated images are closer to natural images in latent space, that our feature visualizations are more plausible and better reflect the original distribution. However, they do not necessarily indicate that these visualizations helps humans in effectively communicating with the models or conveying information easily to humans.
Furthermore, in order for a feature visualization to provide informative insights about the model, including spurious features, it may need to generate visualizations that deviate from the spectrum of natural images. Consequently, these visualizations might yield lower scores using our proposed metrics.
Simultaneously, several interesting studies have highlighted the weaknesses and limitations of feature visualizations~\cite{borowski2020exemplary,geirhos2023dont,zimmermann2021well}. One prominent criticism is their lack of interpretability for humans, with research demonstrating that dataset examples are more useful than feature visualizations in understanding convolutional neural networks (CNNs)~\cite{borowski2020exemplary}. This can be attributed to the lack of realism in feature visualizations and their isolated use as an explainability technique.
With our approach, \magfv~, we take an initial step towards addressing this limitation by introducing magnitude constraints, which lead to qualitative and quantitative improvements. Additionally, we promote the use of feature visualizations as a supportive and complementary tool alongside other methods such as concept-based explainability, exemplified by \craft. We emphasize the importance of feature visualizations in combating confirmation bias and encourage their integration within a comprehensive explainability framework.



\subsection{Discussion}

In this section, we introduced a novel approach, \magfv, for efficiently generating feature visualizations in modern deep neural networks based on \tbi{i} a hard constraint on the magnitude of the spectrum to ensure that the generated visualizations lie in the space of natural images, and \tbi{ii} a new attribution-based transparency mask to augment these feature visualizations with the notion of spatial importance. This enhancement allowed us to scale up and unlock feature visualizations on large modern CNNs and vision transformers without the need for strong -- and possibly misleading -- parametric priors.
We also complement our method with a set of three metrics to assess the quality of the visualizations. Combining their insights offers a way to compare the techniques developed in this branch of XAI more objectively. We illustrated the scalability of \magfv~ with feature visualizations of large models like ViT, but also feature inversion and, critically, concept visualization.

Indeed, this tool integrates seamlessly with concept extraction methods, enabling the visualization of extracted concepts without resorting to image cropping. This approach offers a clearer, more causal view of the mechanisms that activate a given concept, thereby contributing significantly to our understanding of the internal workings of neural networks.
