The method outlined in the previous section utilizes a routine and tailored data to regularize models during training, aligning them with human attention. However, collecting such data can be laborious and sometimes impossible. In this section, we pivot to an alternative approach that shifts \textbf{from regularizing to constraining the model}. We employ 1-Lipschitz networks, trained with a transport loss. In \autoref{sec:attributions:mege}, we used our metric of algorithmic stability to demonstrate that 1-Lipschitz models provide more general explanations. Here, we will illustrate that the gradient of these models has a compelling interpretation: it points towards the counterfactual, meaning the closest real point belonging to a different class (see Figure~\ref{fig:lipschitz:big_picture}). We will show that these models, originally designed for robustness against adversarial attacks, are \textit{also} naturally aligned.

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.99\linewidth]{assets/lipschitz/big_picturev_2.jpg}
\caption{
\textbf{Illustration of the beneficial properties of $\losshkr$ gradients.} Examples \textbf{a)} and \textbf{b)} show that the gradients naturally provide a direction that enables the generation of adversarial images - a theoretical justification based on optimal transport is provided in the \autoref{sec:lipschitz:theory}. By applying the gradient $\rvx' = \rvx  -\alpha \nabla_{\rvx}  \f(\rvx)$ to the original image $\rvx$ (on the left), any digit from MNIST can be transformed into its counterfactual $\rvx'$ (e.g., turning a 0 into a 5). 
In \textbf{b)}, we illustrate that this approach can be applied to larger datasets, such as Celeb-A, by creating two counterfactual examples for the closed-mouth and blonde  classes. In \textbf{c)}, we compare the Saliency Map of a classical model with those of $\losshkr$ gradients, which are more focused on relevant elements. Finally, in \textbf{d)}, we show that following the gradients of $\losshkr$ could generate convincing feature visualizations that ease the understanding of the model's features. 
}
\label{fig:lipschitz:big_picture}
\end{figure*}

\subsection{Background}

Let us consider a probability space $(\Omega, \mathcal{F}, \P)$, where $\Omega$ represents the set of outcomes, $\mathcal{F}$ a $\sigma$-algebra of events, and $\P$ a probability measure. The space of all probability measures on a metric space $(\sx, \norm{\cdot})$ is denoted as $\s{P}(\sx)$. Here, $\sx \subseteq \Real^d$ signifies the input space, and $\sy = \{\pm 1\}$ the output space. The input data $\rvx : \Omega \rightarrow \sx$ and target label $\ry : \Omega \rightarrow \sy$ are modeled as random variables with distributions $\P_{\rvx}$ and $\P_{\ry}$, respectively, with $\P_{\rvx,\ry}$ representing their joint distribution over $\sx \times \sy$.

The Wasserstein distance, inspired by the theory of optimal transport~\cite{villani2009optimal}, measures the minimal cost required to transform one probability distribution into another. It roots back to the work of Gaspard Monge in the 18th century~\cite{monge1781memoire}, and was originally defined as:

\begin{equation}
    \wasserstein_1(\mu, \nu) = \inf_{\pi \in \Pi(\mu, \nu)} \int_{\sx \times \sx} \norm{\rvx - \rv{z}} \,d\pi(\rvx, \rv{z}),
\end{equation}

Where $\Pi(\mu, \nu)$ is the set of all couplings of $\mu$ and $\nu$, $\wasserstein_1$ denote the 1-Wasserstein distance, also known as the Earth-Mover's distance, between two probability measures $\mu$ and $\nu$ over $\sx$.
Moreover, it can be shown that dual representation of $\wasserstein_1$ is a special case of the duality theorem of Kantorovich and Rubinstein (\cite{kantorovich1960mathematical}) and is defined as:

\begin{align}\label{eq:lip:kantorovich}
    \wasserstein_1(\mu, \nu) &= \sup_{\f \in \lip_1(\sx)} \left( \int_{\sx} \f(\rvx) \,d\mu(\rvx) - \int_{\sx} \f(\rvx) \,d\nu(\rvx) \right) \\
    & = \sup_{\f \in \lip_1(\sx)} ~ ~ \underset{\rvx \sim \mu}{\E}(\f(\rvx)) ~ - ~ \underset{\rvx \sim \nu}{\E}(\f(\rvx)).
\end{align}

Where $\lip_1(\sx)$ denotes the space of 1-Lipschitz functions on $\sx$. For reference, a function is considered L-Lipschitz if for all pairs $(\rvx, \rv{z}) \in \sx^2$, the norm of the difference between $\rvx$ and $\rv{z}$ is less than or equal to $L$ times the norm of the difference between $\f(\rvx)$ and $\f(\rv{z})$ :

$$
\forall (\rvx, \rv{z}) \in \sx^2, \norm{\f(\rvx) - \f(\rv{z})} \leq L \norm{\rvx - \rv{z}}.
$$

This formulation in Equation~\ref{eq:lip:kantorovich} is particularly intriguing, as it renders the computation of the Wasserstein distance tractable if one can correctly parametrize to optimize over the space of 1-Lipschitz functions.
Recent works have proposed to use deep neural network to parametrize the function $\f(\cdot, \parameters)$ and have found various ways to constraint the function space such that $\f \in \lip_1$ at every step in the training process. We refer the reader to \cite{serrurier2022adversarial,hein_formal_2017,Sokolic_2017,tsipras2018robustness,salimans2016weight,miyato2018spectral} for more information.

\paragraph{\hkr: Robust Classification via Transport-Based Loss Function}

Building on these foundations, the \hkr~Loss introduced in~\cite{serrurier2021achieving}~incorporates a hinge regularization term to the Kantorovich-Rubinstein optimization objective, aiming to enhance binary classification performance. It is formulated as:
\begin{equation}
    \losshkr(\f) = 
    \underset{\rvx \sim \mu}{\E}(\f(\rvx)) ~ - ~ \underset{\rvx \sim \nu}{\E}(\f(\rvx)) 
    ~ +  \underset{(\rvx, \ry) \sim \P_{\rvx, \ry}}{\lambda ~ \E}\big(\margin - \ry \f(\rvx)\big)^+
\end{equation}
With $\margin > 0$, the margin introduces a significant contribution to the model's robustness and interpretability by promoting separation between the distributions of positive and negative classes. This loss has been thoroughly analyzed in~\cite{bethune2022pay}, providing insights into its interpretation, limitations, and advantages, especially in controlling the Lipschitz constant. Moreover, the HKR loss has been applied in computing SDF functions~\cite{bethune2023robust} and in DP-training~\cite{bethune2023dp}. In practice, the model is trained using the DeelLip\footnote{https://github.com/deel-ai/deel-lip} library (\cite{deelLip}).

\subsection{An optimal transport perspective of Saliency}
\label{sec:lipschitz:theory}

Models trained with the previously introduced \hkr~loss exhibit interesting properties from a transport perspective: the gradient points towards a point of the opposite class, a counterfactual. We will revisit these propositions and interpret the significance of this gradient, then explore how this translates into terms of alignment.

We note $\optiplan$ the optimal transport plan corresponding to the minimizer of the \hkr loss. In the most general setting, $\optiplan$ is a joint distribution over $\mu,\nu$ pairs. However, when $\mu$ and $\nu$ admit a density function~\cite{peyre2018computational} with respect to Lebesgue measure, then the joint density describes a deterministic mapping, i.e. a Monge map. Given $\rvx \sim \mu$ 
(resp. $\nu$) we note $\rv{z} = \transport(\rvx) \in \nu$ (resp. $\mu$) the image of $\rvx$ with respect to $\optiplan$. When $\optiplan$ is not deterministic (on real datasets that are defined as a discrete collection of Diracs), we take $\transport(\rvx)$ as the point of maximal mass with respect to $\optiplan$.

\begin{theorem}[Transportation plan direction~\cite{serrurier2024explainable}]\label{th:gradient_transport_plan}
Let $\f^\star$ an optimal solution minimizing the $\losshkr$. Given $\rvx \sim \mu$ (resp. $\nu$)  and  $\rv{z} = \transport(\rvx)$, then $\exists \alpha \geq 0$ (resp. $\alpha \leq 0$) such that $\transport(\rvx) = \rvx  -\alpha \nabla_{\rvx}  \f^\star(\rvx)$ almost surely. 
\end{theorem}

This proposition also holds for the Kantorovich-Rubinstein dual problem without hinge regularization, demonstrating that for $\rvx \sim \P_{\rvx,\ry}$, the gradient $\nabla_{\rvx} \f^{\star}(\rvx)$ indicates the direction in the transportation plan almost surely.

\begin{theorem}[Decision boundary~\cite{serrurier2024explainable}]\label{boundary_distance}
Let $\mu$ and $\nu$ two distributions with disjoint supports with minimal distance~$\xi$ and  $\f^\star$ an optimal solution minimizing the $\losshkr$~with~$\delta < 2\xi$. Given $\rvx \sim \P_{\rvx,\ry}$, $\rvx_\delta = \rvx -\f^\star(\rvx) \nabla_{\rvx} \f^\star(\rvx) \in \boundary $
where $\boundary = \left\{\rvx' \in \sx | \f^\star(\rvx') = 0 \right\}$  is the decision boundary (i.e. the 0 level set of $\f^\star$).
\end{theorem}

Experiments perform in \cite{serrurier2024explainable} suggest this probably remains true when the supports of $\mu$ and $\nu$  are not disjoint. 

\begin{corollary}[\cite{serrurier2024explainable}]\label{fx_grad_adversarial}
Let $\mu$ and $\nu$ two separable distributions with minimal distance $\xi$ and  $\f^\star$ an optimal solution minimizing the $\losshkr$ with $\delta <2\xi$, given $\rvx \sim \P_{\rvx, \ry}$, 
$adv(\f^\star,\rvx) = \rvx_{\delta}$ 
almost surely, where $\rvx_\delta = \rvx -\f^\star(\rvx) \nabla_{\rvx} \f^\star(\rvx)$.
\end{corollary}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=.9\textwidth]{assets/lipschitz/koch_v4.jpg}
    \caption{Level sets of an 1-Lipschitz classifier train with $\losshkr$ for two concentric Koch snowflakes \textbf{(a)}.  The decision boundary (denoted $\boundary$, also called the 0-level set) is the red dashed line. Figure \textbf{(b)} (resp. \textbf{(c)}) represents the translation of the form $\rvx'= \rvx -\f(\rvx)\nabla_{\rvx} \f(\rvx)$ of each point $\rvx$ of the first class (resp second class). 
    $(\rvx,\rvx')$ pairs are represented by blue (resp. orange)  segments.}
    \label{fig:lipschitz:koch}
\end{figure*}

This corollary is of great interest as it shows that adversarial examples are precisely identified for the classifier based on $\losshkr$: the direction is given by the gradient $\nabla_{\rvx} \f^\star(\rvx)$ and the distance by $\norm{\f^\star(\rvx)}$. In this scenario, the optimal adversarial attacks align with the gradient direction.

To illustrate these propositions, we learned a dense binary classifier with $\losshkr$ to separate two complex distributions, following two concentric Koch snowflakes. Figure~\ref{fig:lipschitz:koch}) \textbf{(a)} shows the two distributions (blue and orange snowflakes), the learned boundary ($0$-level set) (red dashed line). In the same figure, \textbf{(b)} and \textbf{(c)} show, for random samples $\rvx$ from the two distributions, the segments $[\rvx,\rvx_\delta]$ where $\rvx_\delta$ is defined in Proposition.~\ref{boundary_distance}.

\paragraph{Alignment induced by $\losshkr$.}

Thus, the learning process of those models induces a strong constraint on the gradients of the neural network, aligning them to the optimal transport plan. We claim that is the reason why the simple Saliency Maps have very good properties for those networks.

By adopting the metric we have proposed in~\autoref{sec:harmonization}, we have computed the human feature alignment of $\losshkr$ Saliency Maps and compare with the others models tested in ~\cite{fel2022aligning}-- more than 100 recent deep neural networks. In Figure ~\ref{fig:lipschitz:human_alignement}, we demonstrate that those model's Saliency Maps, do not only carry strong theoretical interpretation as the direction of the transport plan, it is also more aligned with human attention than any other tested models and significantly surpasses the Pareto front discovered previously. Perhaps the most surprising is that no clickmap or any specific routine like the harmonization one was used: the OTNN model is even more aligned than a ResNet50 model trained with the specific alignment objective proposed in~\autoref{sec:harmonization}.
The implications of these results are crucial for both cognitive science and industrial applications. A model that more closely aligns with human attention and visual strategies can provide a more comprehensive understanding of how vision operates for humans, and also enhance the predictability, interpretability, and performance of object recognition models in industry settings. 
Furthermore, the drop in alignment observed in recent models highlights the necessity of considering the alignment of model visual strategies with human attention while developing object recognition models to reduce the reliance on spurious correlations and ensure that our models are accurate for the right reasons.


\begin{figure*}[ht]
\centering
\includegraphics[width=.99\textwidth]{assets/lipschitz/human_alignment_flat_2.png}
\caption{\textbf{$\losshkr$~ naturally align gradients with Human attention.} Our study shows that the Saliency Map of $\losshkr$ model (denoted OTNN, for Optimal Transport Neural Network) is highly aligned with human attention. The degree of alignment between human and DNN saliency is measured using the mean Spearman correlation, normalized by the average inter-rater alignment of humans. 
}
\label{fig:lipschitz:human_alignement}
\end{figure*}

