\subsection{Qualitative comparison}

Regarding the visual consistency of our method, Fig.~\ref{app:sobol:qualitative_results} shows a side-by-side comparison between our method and the other methods tested in the Fidelity benchmark. The images are not hand-picked but are the first images from the ImageNet validation set.
To allow better visualization, the gradient-based methods were 2 percentile clipped.
The only black box methods are Occlusion, Rise and $\sob_{T_i}$. We found that $\sob_{T_i}$ consistently provides a sparser map than RISE~\cite{petsiuk2018rise} while being equally consistent.
On the other hand, we found that in general, the gradient-based method provides the sharpest map, but some are prone to failure (fourth row in the Fig.~\ref{app:sobol:qualitative_results}), which is a known problem~\cite{adebayo2018sanity}.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=1.05\linewidth]{assets/sobol/qualitative.png}
    \caption{\textbf{Qualitative comparison} with other explainability methods. The heatmaps are normalized and clipped at 2 percentile for Saliency, Guided-Backprop, DeconvNet, Smoothgrad and Integrated-Gradients.
    Explanations are generated from a ResNet50V2.
    }
    \label{app:sobol:qualitative_results}
\end{figure*}

\subsection{Effectiveness of modeling higher-order interactions}

We introduced two approaches, Sobol ($\hat{\sob}_{T_i}$) and Sobol signed ($\hat{\sob}^{\Delta}_{T_i}$), that combine effects of first- and all higher-orders interactions between image regions. For comparison, Occlusion~\cite{zeiler2014visualizing} only accounts for the first order as it removes one region at a time, while RISE~\cite{petsiuk2018rise} accounts for higher-order by removing around 50\% of regions at a time. As seen in Table~\ref{app:sobol:deletion_first_vs_higher}, RISE already surpasses Occlusion on ImageNet in term of Deletion scores, which may indicate that using higher-order information is effective.

To further demonstrates that it is critical to model the higher orders, we evaluate Sobol first-order ($\sob_{i}$) on our Deletion benchmark.
We report that Sobol ($\sob_{T_i}$) reaches lower deletions scores (lower is better) than Sobol first-order ($\sob_{i}$) with 0.121 against 0.170 respectively on ResNet50v2, and similar differences on VGG16, EfficientNet and MobileNetV2.

\begin{table*}[ht]
\centering
\begin{tabular}{lcccc}
\toprule
Method & \textit{ResNet50V2} & \textit{VGG16} & \textit{EfficientNet} & \textit{MobileNetV2} \\
\midrule  
Sobol first-order ($\hat{\sob}_{i}$) & 0.170 & 0.147 & 0.129 & 0.143 \\  
Sobol ($\hat{\sob}_{T_i}$) & \textbf{0.121} & \textbf{0.109} & \textbf{0.104} & \textbf{0.107} \\  
\bottomrule
\end{tabular}
\caption{\textbf{Deletion} scores obtained on 2,000 ImageNet validation set images. Lower is better. 
}\label{app:sobol:deletion_first_vs_higher}
\end{table*}

\subsection{Efficiency of Sobol estimator}\label{app:sobol:efficient}
Regarding the estimation of the Sobol indices, we notice that we can derive a `brute-force' (or often called double-loop method~\cite{sobol2001}) estimator from the definition \ref{def:sobol_indice}:

\begin{equation}
    \label{eq:sobol_double_loop}
    \sob_i = \frac{ \int \big( \int \f(\rvx) \diff \rvx_{\sim i} \big)^2 \diff \rvx_i -  ( \int \f(\rvx) \diff \rvx)^2 }
             {\int \f(\rvx)^2 \diff \rvx - ( \int \f(\rvx) \diff \rvx )^2 }
\end{equation}

However, one the main problems with this estimator is the cost of computation, which can be too heavy, especially with complex models such as large neural networks. This difficulty is particularly true for the calculation of total Sobol indices. 

Since the perturbation masks are used to approximate these integrals, an efficient way to proceed is to generate those masks from a low discrepancy sequences, also called Quasi-random sequences. These sequences allow to efficiently integrate functions on the hypercube $[0, 1]^d$. In fact, they have a faster convergence rate compared to ordinary Monte Carlo methods~\cite{gerber2015} (with $\pred$ sufficiently regular). This difference being due to the use of a deterministic sequence that covers $[0, 1]^d$ more uniformly.
In our experiments we used Sobol sequences~\cite{sobol1967sequence}, we refer the readers to~\cite{leobacher2014introduction} for more informations.
The efficiency of the estimator and the sampling is shown on Figures \ref{app:sobol:conv:resnet}, \ref{app:sobol:conv:vgg} and \ref{app:sobol:conv:mobilenet} where our estimator consistently converges faster than RISE~\cite{petsiuk2018rise}.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.80\linewidth]{assets/sobol/resnet.png}
    \caption{
      Spearman rank correlation of explanations as a function of the number of forwards, compared to an explanation generated with $10,000$ forwards.
      The model used is a ResNet50V2.
    }
    \label{app:sobol:conv:resnet}
\end{figure*}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.80\linewidth]{assets/sobol/vgg.png}
    \caption{      
    Spearman rank correlation of explanations as a function of the number of forwards, compared to an explanation generated with $1,0000$ forwards.
    The model used is a VGG16.
      }
      \label{app:sobol:conv:vgg}
\end{figure*}
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.80\linewidth]{assets/sobol/mobilenet.png}
    \caption{
      Spearman rank correlation of explanations as a function of the number of forwards, compared to an explanation generated with $1,0000$ forwards.
      The model used is a MobileNetV2.
    }
    \label{app:sobol:conv:mobilenet}
\end{figure*}

We also perform an ablation study of the number of forwards on the Deletion benchmark. In Table~\ref{app:sobol:deletion_first_vs_higher}, we show that competitive scores can be obtained with lower number of forwards such as 0.151 in Deletion score with 492 forwards instead of 0.121 with 3936 forwards which is our default number of forwards.

\begin{table*}[ht]
\centering
\begin{tabular}{cc}
\toprule
Number of samples & Deletion scores \\
\midrule  
492 & 0.151 \\
984 & 0.140 \\
1476 & 0.132 \\
1968 & 0.123 \\
2460 & 0.121 \\
2952 & 0.120 \\
3444 & 0.120 \\
3936 & 0.121 \\
\bottomrule
\end{tabular}
\caption{\textbf{Deletion} scores averaged over 2,000 images of ImageNet validation set using ResNet50V2 and Sobol ($\hat{\sob}_{T_i}$). Lower is better. 
}\label{app:sobol:deletion_ablation}
\end{table*}

\subsection{Sanity check}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.95\linewidth]{assets/sobol/sobol_sanity_check.jpg}
    \caption{\textbf{Sanity Check} model weights are progressively reinitialized from Mixed 6 to Mixed 1 in InceptionV3~\cite{szegedy2015going}, demonstrating our methodâ€™s sensitivity to model weights.}
    \label{sobol:app:sanitycheck}
\end{figure*}

We followed the procedure used by~\cite{adebayo2018sanity}, namely the progressive reset of the network weights. We used an Inception V3~\cite{szegedy2015going} model, each images shows the $\sob_{T_i}$ explanation for the network in which the upper layers (from logits) were reset. 
Fig.~\ref{sobol:app:sanitycheck} shows that our method passes the sanity check: it turns out to be sensitive to the modification of the model weights. 


\subsection{Word Deletion}
\label{sobol:app:word_deletion}

For the bidirectional LSTM, the word embedding is in $\mathbb{R}^{300}$ and is initialized with the pre-trained GloVe embedding. The layer has a hidden size of $64$ (bidirectional architectures: $32$ dimensions per direction). The resulting document representation is projected to $64$ dimensions then $2$ dimensions using fully connected layers, followed by a softmax and reached an accuracy of $89\%$ on the test dataset.

For the BERT-based models, we use the Transformers library from HuggingFace~\cite{wolf2020transformers}
and more specifically the bert-base-uncased model.
The final layer is tuned to minimize cross-entropy,
 with Adam optimizer~\cite{kingma2014adam}
and initial learning rate of $1e^{-3}$
to reach an accuracy of $92$\% on the test dataset.

The observation that local perturbation: with the majority of words present, gets a better score is verified by playing on the threshold of the perturbation function. By decreasing the percentage of words removed on average we observe that a better deletion score is obtained.

\begin{table}[ht]
\centering
\begin{tabular}{l cccc}
\toprule
 & $\hat{\sob}_{T_i}\Delta$ $50$\%  & $\hat{\sob}_{T_i}^\Delta$ $90$\% & $\hat{\sob}_{T_i}\Delta$ $95$\% & Occlusion \\
\midrule
Deletion & 0.598 & 0.553 & \textbf{0.527} &  \underline{0.531} \\
\bottomrule
\end{tabular}

\caption{\textbf{Word deletion scores} on the Bert based model when the perturbation threshold is modified to control the average presence of words in each generated perturbated input. Lower is better. 
}\label{app:sobol:word_deletion_bis}

\end{table}
