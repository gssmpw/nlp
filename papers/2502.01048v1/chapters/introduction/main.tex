\chapter{General Introduction}
\label{chap:intro}

\epigraph{``One sits down on a desert sand dune, sees nothing, hears nothing. Yet through the silence something throbs, and gleams.''}{\textit{Antoine de Saint-Exupéry}}

Some mysteries are meant to remain unsolved; Deep Learning is not one of them. At the entrance of this document, before exploring the subject of Deep Learning—where the \textit{silence} of our understanding contrasts sharply with the powerful \textit{noise} of its achievements—let us take a moment to reflect on the origins of AI.

The concept of creating thinking machines emerged during the Dartmouth Workshop in 1956~\cite{mccarthy2006proposal}\footnote{Interestingly, Lloyd Shapley, who we will encounter later in this manuscript, was invited and is already mentioned in the workshop proposal.}, a seminal event that marked the inception of Artificial Intelligence (AI) as a formal research discipline. This gathering laid the foundational stones for exploring the potential of developing machines endowed with intelligent capabilities. Since then, AI has traversed through various evolutionary stages, characterized by alternating waves of enthusiasm spurred by significant breakthroughs. Alan Turing's prediction regarding the ascent of artificial intelligence appears to have been prophetic, as evidenced by the successive emergence of Machine Learning and subsequently Deep Learning, two branches of statistical learning.

Approximately a decade ago, AI witnessed a transformation with the advent of Deep Learning (DL)~\cite{lecun2015deep,Serre2019DeepLT}. Deep Learning methodologies, rooted in deep neural networks, have catalyzed revolutionary advancements across diverse domains by showcasing exceptional aptitude in discerning complex patterns and behaviors from large datasets. The surge in Deep Learning's prominence can be attributed to several factors, including the exponential increase of data, advancements in hardware and software for machine learning, and pivotal breakthroughs in research methodologies.

A pivotal moment in the adoption of Deep Learning occurred in 2012, when the Computer Vision (CV) community witnessed a groundbreaking development. The winning solution of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), spearheaded by ~\cite{krizhevsky2012imagenet}, showcased the prowess of deep neural networks in image classification tasks. For the first time, a deep learning model outperformed traditional handcrafted methods by automatically learning rich and discriminative features directly from raw pixel data. This achievement marked a paradigm shift in computer vision, setting the stage for subsequent advancements in deep learning-based image analysis.
The success of deep learning methods extended beyond image classification, encompassing a broad spectrum of visual tasks, including object detection and segmentation. These techniques, empowered by the sheer complexity and expressiveness of deep neural networks, surpassed conventional approaches, exceeding expectations and inspiring further innovation.

Despite their remarkable achievements, deep learning models often operate as black boxes, with their decision-making processes obscured by their immense complexity. Moreover, they are susceptible to errors and can exhibit undesirable behaviors, such as learning shortcuts~\cite{geirhos2020shortcut} to achieve high accuracy on specific tasks. Recognizing these challenges, the need for eXplainable AI (XAI) methodologies has emerged~\cite{doshivelez2017rigorous}, aiming to elucidate the inner workings of deep learning models and enhance their transparency and trustworthiness.

This chapter aims to provide a succinct introduction and essential background in both deep learning and explainability, which will be useful for understanding the remainder of the manuscript. It is not intended as a comprehensive review of the state of the art but will offer key insights for grasping the thesis structure. The chapter is organized as follows: \autoref{sec:intro:deep_learning} revisits statistical learning fundamentals, deep learning, and its application in computer vision, while \autoref{sec:intro:xai_landscape} presents an overview of the explainability approaches in AI. We will conclude with \autoref{sec:intro:contrib}, where we describe the structure of the manuscript and the contributions it builds upon.

\input{chapters/introduction/deep_learning}

\input{chapters/introduction/xai_landscapes}

\input{chapters/introduction/frsign}

\input{chapters/introduction/contributions}
