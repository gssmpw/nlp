\begin{abstract}
Increasing test-time computation is a straightforward approach to enhancing the quality of responses in Large Language Models (LLMs). While Best-of-N sampling and Self-Consistency with majority voting are simple and effective,
they require a fixed number of sampling responses for each query, regardless of its complexity. This could result in wasted computation for simpler questions and insufficient exploration for more challenging ones.
In this work, we argue that model confidence of responses can be used for improving the efficiency of test-time scaling.
Unfortunately, LLMs are known to be overconfident and provide unreliable confidence estimation.
To address this limitation, we introduce \textbf{Self-Calibration} by distilling Self-Consistency-derived confidence into the model itself. This enables reliable confidence estimation at test time with one forward pass. 
% Our self-calibration framework generates input-output pairs from seed datasets and assigns confidence scores using soft self-consistency. It then trains the LLM with a combined loss to improve calibration while preserving its generation capability.
% \ljc{Here I think you should add a sentence to summarize how this self-calibration thing is done.}
We then design \textbf{confidence-based efficient test-time scaling methods} to handle queries of various difficulty, such as Early-Stopping for Best-of-N and Self-Consistency with calibrated confidence.
Experiments on three LLMs across six datasets demonstrate the effectiveness of our approach. 
% in both resource utilization and performance. 
Specifically, applying confidence-based Early Stopping to Best-of-N improves MathQA accuracy from 81.0 to 83.6 with a sample budget of 16 responses, 
indicating the efficency of the confidence-based sampling strategy at inference time~\footnote{Our codes are available at~\url{https://github.com/Chengsong-Huang/Self-Calibration}.}.
% across different questions, unlike Best-of-N, which uses a fixed number.


% \ljc{Mention some numbers from experiment results here.}
%result
\end{abstract}