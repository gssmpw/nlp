\section{Prompts}
\label{app:prompt}
\subsection{System Prompt}
Here we show the system prompt to let the model generate responses for Chain-of-Thoughts and format for extracting the final results.

\begin{quote}
\ttfamily
For the following question, provide a step-by-step explanation of your thought process. \\
Use the format demonstrated below for your response. \\

\verb|`|\verb|`|\verb|`|Example Format: \\
\texttt{Explanation: <Your detailed explanation here, outlining how you arrived at your answer.>} \\
\texttt{Answer: <Insert your concise answer here, which should include a \{\textit{answer\_type}\} (e.g., \{\textit{demo}\})>} \\

Ensure that your response strictly adheres to this format. Explicitly include the words \texttt{'Explanation:'}, \texttt{'Answer:'}. \\
\end{quote}

The answer type includes ``option letter'' and ``number''.

\subsection{Dataset Prompts}
We show the prompts for each dataset in Table~\ref{tab:dataset-prompts}.
All datasets and models are open-sourced.
\begin{table*}[t]
\centering
\small
\begin{tabular}{@{}lp{10cm}@{}}
\toprule
\textbf{Dataset} & \textbf{Query Template} \\
\midrule

\textbf{gsm8k} &
\texttt{Question: \{question\}\textbackslash n}
\\[6pt]

\textbf{sciq} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{commonsense\_qa} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{winogrande} &
\texttt{Question: \{sentence\}\textbackslash nOptions:\textbackslash nA. \{option1\}\textbackslash nB. \{option2\}\textbackslash n}
\\[6pt]

\textbf{openbookqa} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{reclor} &
\texttt{Passage:\textbackslash n\{passage\}\textbackslash n\textbackslash nQuestion: \{question\}\textbackslash n\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{math\_qa} &
\texttt{Problem: \{problem\_text\}\textbackslash nOptions:\textbackslash n\{options\_block\}\textbackslash n}
\\[6pt]

\textbf{arc\_challenge} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_str\}\textbackslash n}
\\[6pt]

\textbf{arc\_easy} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_str\}\textbackslash n}
\\[6pt]

\textbf{logiqa} &
\texttt{Article:\textbackslash n\{context\}\textbackslash n\textbackslash nQuestion: \{question\}\textbackslash n\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{svamp} &
\texttt{Question: \{Body + Question\}\textbackslash n}
\\[6pt]

\textbf{gpqa} &
\texttt{\{Question\}\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\[6pt]

\textbf{aqua\_rat} &
\texttt{Question: \{question\}\textbackslash nOptions:\textbackslash n\{options\_text\}\textbackslash n}
\\

\bottomrule
\end{tabular}
\caption{Query templates for each dataset .}

\label{tab:dataset-prompts}
\end{table*}

\section{Full Main Results}
\label{app:full_table}
Here we show the main results when sample budget = 4 in Table~\ref{tab:results1}.

\begin{table*}[h]
 \centering
 \small
 \setlength{\tabcolsep}{1.5pt}
 \resizebox{\textwidth}{!}{%
 \begin{tabular}{llll|lll|lll}
 \toprule
 & \multicolumn{3}{c}{Llama-3.1-8B-Instruct} & \multicolumn{3}{c}{Qwen2.5-7B-Instruct} & \multicolumn{3}{c}{DeepSeek-R1-Distill-1.5B} \\
 \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
 Methods & Obj\_C. & MathQA & ARC\_C. & Obj\_C. & MathQA & ARC\_C. & Obj\_C. & MathQA & ARC\_C. \\
 \midrule
 \rowcolor{gray!20} Pass@1 & 67.6 & 71.5 & 82.8 & 76.8 & 82.9 & 88.5 & 61.2 & 89.9 & 58.2 \\ 
 \midrule
 \multicolumn{10}{l}{\textit{Sample budget = 4}} \\
 SC & 72.0 & 78.8 & 85.7 & 78.8 & 85.7 & 90.0 & 63.6 & 91.4 & 63.0 \\
 SC w/ Conf.* & 72.4 (+0.4) & 81.8 (+3.0) & 86.4 (+0.7) & 78.2 (-0.6) & 86.5 (+0.8) & 89.8 (-0.2) & 60.8 (-3.2) & 90.6 (-0.8) & 62.6 (-0.4)\\
 \rowcolor{blue!10}SC w/ Conf. & 72.8 (+0.8) & \textbf{82.1} (+3.3) & 86.4 (+0.7) & 78.4 (-0.4) & 86.9 (+1.2) & 90.3 (+0.3) & \textbf{64.0} (+0.4) & 91.2 (-0.2) & 63.2 (+0.2) \\
 Best-of-N & 67.6 & 80.8 & 86.4 & 76.4 & 86.4 & 89.8 & 56.0 & 90.0 & 59.0 \\
 Early Stopping* & 65.6 (-2.0) & 81.2 (+0.4) & 86.1 (-0.3) & 76.0 (-0.4) & 86.6 (+0.2) & 89.6 (-0.2) & 55.2 (-0.8) & 90.5 (+0.5) & 58.8 (-0.2) \\
 \rowcolor{blue!10}Early Stopping & 67.2 (-0.4) & 81.7 (+0.9) & 86.2 (-0.2) & 78.4 (+2.0) & 87.1 (+0.7) & 90.1 (+0.3) & 56.0 (0.0) & 90.6 (+0.6) & 59.0 (0.0) \\
 ASC & 74.4 & 80.0 & 86.5 & 79.6 & 86.2 & \textbf{91.0} & 61.2 & 91.3 & 63.3 \\
 ASC w/ Conf.* & 73.2 (-1.2) & 81.7 (+1.7) & 86.5 (0.0) & 79.8 (+0.2) & 86.9 (+0.7) & 90.4 (-0.6) & 62.4 (+1.2) & 91.6 (+0.3) & 64.2 (+0.9) \\
 \rowcolor{blue!10}ASC w/ Conf. & \textbf{74.8} (+0.4) & 81.9 (+1.9) & \textbf{86.6} (+0.1) & \textbf{80.0} (+0.4) & \textbf{87.2} (+1.0) & 90.6 (-0.4) & {62.8} (+1.6) & \textbf{91.6} (+0.3) & \textbf{64.6} (+1.3) \\
 ESC & 72.0 & 78.6 & 85.8 & \textbf{80.0} & 86.9 & 89.6 & 58.0 & 91.2 & 63.0 \\
 RASC & 72.4 & 79.0 & 85.8 & \textbf{80.0} & 86.4 & 89.8 & 62.6 & 91.2 & 63.1 \\
 % \midrule
 % \midrule
 % \multicolumn{10}{l}{\textit{Sample budget = 16}} \\
 % SC & 76.0 & 81.0 & 87.1 & 81.2 & 86.3 & \textbf{91.2} & \textbf{70.8} & 91.6 & 65.6 \\
 % SC w/ Conf.* & \textbf{76.8} (+0.8) & 83.4 (+2.4)  & 87.4 (+0.3) & 80.8 (-0.4) & 87.5 (+1.2) & 90.5 (-0.7) & \textbf{70.8} (0.0) & \textbf{91.8} (+0.2) & 65.9 (+0.3) \\
 % \rowcolor{blue!10}SC w/ Conf.  & \textbf{76.8} (+0.8) & \textbf{83.6} (+2.6) & \textbf{87.7} (+0.6) & 81.2 (0.0) & \textbf{87.8} (+1.5) & 90.8 (-0.4) & \textbf{70.8} (0.0) & \textbf{91.8} (+0.2) & \textbf{66.5} (+0.9) \\
 % Best-of-N & 69.2 & 81.0 & 86.4 & 76.8 & 86.8 & 90.2 & 54.0 & 90.0 & 58.9 \\
 % Early Stopping* & \textbf{76.8} (+7.6) & 83.4 (+2.4) & 87.3 (+0.9) & 80.8 (+4.0) & 87.5 (+0.7) & 90.5 (+0.3) & 64.8 (+10.8) & 91.6 (+1.6) & 65.9 (+7.0)\\
 % \rowcolor{blue!10}Early Stopping & \textbf{76.8} (+7.6) & \textbf{83.6} (+2.6) & \textbf{87.7} (+1.3) & 81.2 (+4.4) & \textbf{87.8} (+1.0) & 90.8 (+0.6) & \textbf{70.8} (+16.8) & 91.6 (+1.6) & \textbf{66.5} (+7.6) \\
 % ASC & 74.8 & 80.0 & 86.5 & \textbf{81.6} & 86.2 & 90.6 & 70.4 & 91.6 & 64.3 \\
 % ASC w/ Conf.* & 74.8 (0.0) & 81.6 (+1.6) & 86.6 (+0.1) & \textbf{81.6} (0.0) & 86.9 (+0.7) & 90.4 (-0.2) & 70.4 (0.0) & 91.6 (0.0) & 64.7 (+0.4) \\
 % \rowcolor{blue!10}ASC w/ Conf. & 75.2 (+0.4) & 81.9 (+1.9) & 86.6 (+0.1) & \textbf{81.6} (0.0) & 87.2 (+1.0) & \textbf{91.2} (+0.6) & 70.4 (0.0) & \textbf{91.8} (+0.2) & 65.1 (+0.8) \\
 % ESC & 76.0 & 81.0 & 87.1 & 81.2 & 86.3 & {91.0} & \textbf{70.8} & 91.3 & 65.6 \\
 % RASC & 76.0 & 81.4 & 87.3 & 81.2 & 86.4 & 90.3 & \textbf{70.8} & 91.4 & 65.8 \\
 \bottomrule
 \end{tabular}
 }
 \caption{
 Accuracy comparison of different test-time scaling methods across three language models. The evaluation is conducted on three datasets: Obj\_C. (Object\_Counting), MathQA, and ARC\_C. (ARC\_Challenge). ``Sample budget'' refers to the average number of responses sampled per query. The improvements of confidence-augmented methods over their baselines are shown in parentheses. All methods use the same responses generated by Self-Calibration trained models, while methods marked with \textbf{*} use confidence scores from the vanilla model. 
 }
 % \vspace{-15pt}
 \label{tab:results1}
\end{table*}

When the sample budget is small, the model has limited opportunities to explore different reasoning paths. In this scenario, output variability is often high, and having an additional confidence signal (as in ASC w/ Conf.) is essential for filtering out noisy or incorrect responses. This confidence-augmented method helps select the most promising candidate under tight sampling constraints. 

However, when the sample budget increases, the model can generate more candidate solutions, which typically raises the chance of hitting the correct answer. In this setting, Early Stopping approach—especially when coupled with a high confidence threshold—can terminate as soon as it encounters a correct reasoning path.


\section{Full Results of Different Confidence Querying Prompts}
\label{app:confidence_query}

\subsection{Confidence Querying prompts}
\label{app:query_prompt}

We show the 6 confidence querying prompt we used in Sec.~\ref{sec:confideceprompt}.
\setlength\itemsep{0em}
\begin{itemize}[leftmargin=*]
    \item $I_1$: Is this the correct answer?
    \item $I_2$: Does this answer seem right?
    \item $I_3$: Is this the right answer?
    \item $I_4$: Is the given answer accurate?
    \item $I_5$: Would you say this answer is correct?
    \item $I_6$: Is this response correct?
\end{itemize}



\subsection{Results of Different Querying Prompts}\label{app:result_prompt}
In Table~\ref{tab:confidence_pr}, we show the results of different confidence querying prompts for tuned LLama-3.1-8B-Instruct.
\begin{table*}[h]
\small
% \renewcommand{\arraystretch}{1.2}
\centering
\begin{tabular}{llccccccc}
\toprule
   Dataset              &     Method          & 1     & 2     & 3     & 4     & 5     & 6     & Original \\
\midrule
                 & Early Stopping & 81.7  & 81.4  & 81.7  & 81.3  & 81.1  & \textbf{81.9}  & 81.7  \\
\textbf{MathQA}  & ASC w/o conf.  & 81.9  & 81.9  & 81.8  & 81.8  & 81.4  & \textbf{82.0}  & 81.9  \\
                 & SC w/o conf.   & 81.5  & 81.4  & 81.5  & 81.7  & 81.9  & 81.8  & \textbf{82.1}  \\
\midrule
                 & Early Stopping & 70.0  & 71.6  & 69.6  & 68.0  & \textbf{73.6}  & 72.0  & 67.2  \\
\textbf{Object\_Counting} & ASC w/o conf.  & \textbf{73.6}  & 73.6  & 74.4  & 73.6  & \textbf{76.0}  & 73.2  & 74.8  \\
                 & SC w/o conf.   & 72.8  & \textbf{74.0}  & 73.2  & 72.4  & 74.4  & 73.6  & 72.8  \\
\midrule
                 & Early Stopping & \textbf{86.8}  & 86.4  & \textbf{86.8}  & 86.5  & \textbf{86.8}  & 86.4  & 86.2  \\
\textbf{ARC\_challenge}   & ASC w/o conf.  & \textbf{86.7}  & 86.6  & 86.6  & 86.6  & \textbf{86.7}  & 86.6  & 86.6  \\
                 & SC w/o conf.   & 86.3  & 86.1  & 86.1  & \textbf{86.7}  & 86.3  & 86.6  & 86.4  \\
\bottomrule
\end{tabular}
\caption{The results for different confidence querying prompt.}
\label{tab:confidence_pr}
\end{table*}


\section{Results for Different Sample Budgets}
\label{app:different_budgets}
Here, we show  the performance under different sample budgets of other datasets and models.

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/llama_arc.pdf}
    \caption{Performance comparison of different inference strategies on ARC\_Challenge using Self-Calibration
trained Llama-3.1-8B-Instruct. }
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/llama_object.pdf}
    \caption{Performance comparison of different inference strategies on Object Counting using Self-Calibration
trained Llama-3.1-8B-Instruct. }
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/llama_mathqa.pdf}
    \caption{Performance comparison of different inference strategies on MathQA using Self-Calibration
trained Llama-3.1-8B-Instruct. }
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/qwen_arc.pdf}
    \caption{Performance comparison of different inference strategies on ARC\_Challenge using Self-Calibration
trained Qwen-2.5-7B-Instruction. }
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/qwen_object.pdf}
    \caption{Performance comparison of different inference strategies on Object Counting using Self-Calibration
trained Qwen-2.5-7B-Instruction. }
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
\includegraphics[width=0.95\linewidth]{figures/Different_budgets/llama_mathqa.pdf}
    \caption{Performance comparison of different inference strategies on MathQA using Self-Calibration
trained Qwen-2.5-7B-Instruction. }
    \label{fig:enter-label}
\end{figure}

\section{Hyperparameters}
\label{app:hyperparameter}

This section details the hyperparameters used in our experiments. We categorize them into training data generation, training process, and response generation
\subsection{Training Data Generation}
When creating the datasets, we set the number of responses for each query $N=32$. For the parameter in dynamic temperature, we follow the default hyperparameter settings from the original paper: \(T_0=0.8\), \(M=0.8\), \(\gamma=1.0\), and \(\tau_0=0.001\).
\subsection{Training Process}
In the training objective, we set the threshold $\eta = 0.75$ to filter the response used in generation ability training and the weight $w=0.1$ to balance two losses.

In the training process, we use the AdamW optimizer with a learning rate of $5 \times 10^{-5}$. The total number of training samples is set to 100,000, while 1,000 samples are used for evaluation. We employ a batch size of 1 with gradient accumulation steps of 64 to simulate a larger effective batch size. The model is trained for 1 epoch.

For parameter-efficient fine-tuning, we apply LoRA with rank $r=32$, scaling factor $\alpha=16$, and dropout rate of $0.05$. In the whole training examples, the ratio of causal language modeling data is 0.7.
We train the model on multiple datasets with varying proportions of training and evaluation data. Specifically, GSM8K and SVAMP each contribute 15\% of the training and evaluation samples. SciQ, CommonsenseQA, Winogrande, OpenBookQA, ReClor, ARC-Easy, and LogiQA each contribute 5\% of the training and evaluation samples.

During the sample training data selection process, we ensure that the data is evenly distributed across different confidence intervals. This balancing strategy prevents overrepresentation of any specific confidence range, allowing the model to learn from a diverse set of samples. By maintaining an equal number of training examples in each confidence bin, we improve the robustness of confidence calibration and reduce potential biases in the learning process.

\subsection{Response Generation}
When generating the response, we set the temperature equals to 1.0.


