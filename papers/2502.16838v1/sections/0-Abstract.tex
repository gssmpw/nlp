\begin{abstract}
Event argument extraction identifies arguments for predefined event roles in text. Traditional evaluations rely on exact match (EM), requiring predicted arguments to match annotated spans exactly. However, this approach fails for generative models like large language models (LLMs), which produce diverse yet semantically accurate responses. EM underestimates performance by disregarding valid variations, implicit arguments (unstated but inferable), and scattered arguments (distributed across a document). To bridge this gap, we introduce \textbf{R}eliable \textbf{E}valuation framework for \textbf{Gen}erative event argument extraction (\textbf{REGen}), a framework that better aligns with human judgment. Across six datasets, REGen improves performance by an average of 23.93 F1 points over EM. Human validation further confirms REGenâ€™s effectiveness, achieving 87.67\% alignment with human assessments of argument correctness.

% Event argument extraction identifies arguments for predefined event roles in text. Prior works evaluate argument extraction as an exact match (EM) problem where the predicted argument for a role must be similar to gold-label annotated spans. However, this is not well suited for models that generate human-like responses, such as large language models (LLMs). Generative models often produce diverse yet semantically accurate arguments. Thus, if we attempt to translate the EM evaluation to the generative setting, performance is severely underestimated as the correct output can be generated in different surface forms and vary from the ground truth. Furthermore, EM evaluation fails to capture implicit arguments (those without direct textual mentions) and scattered arguments (those dispersed throughout the document). This underscores the need for a better evaluation framework that captures models' actual performance. 

% To address this gap, we propose a \textbf{R}eliable \textbf{E}valuation framework for \textbf{Gen}erative event argument extraction (\textbf{REGen}) with improved alignment with human judgments. Our evaluation across six datasets shows that model performance improves by an average of 23.93 F1 points using REGen, which is lost under the EM approach. Our human validation demonstrates that REGen achieves 87.67\% alignment with human judgment on argument correctness.  

\end{abstract}



% \begin{abstract}
% Event argument extraction identifies arguments for predefined event roles in text. Prior works evaluate argument extraction as an exact match problem where the predicted argument for a role must be similar to gold-label annotated spans. However, this is not well suited for models that generate human-like responses, such as large language models (LLMs). Generative models produce diverse but semantically accurate arguments. Thus, if we attempt to translate the exact match evaluation to the generative setting, performance is severely underestimated as the correct output can be generated in different surface forms and vary from the ground truth. Moreover, in exact match settings, evaluating implicit (arguments with no direct mention in the text) and scattered (arguments dispersed throughout the document) is impossible. \textcolor{red}{Why do we care? Is it because people should/can use LLMs for this task? Is there a high-level noteworthy advantage of doing this? }

% To address this gap, we propose a \textbf{R}eliable \textbf{E}valuation framework for \textbf{Gen}erative event argument extraction (\textbf{REGen}) with improved alignment with human judgments. We systematically evaluate six different datasets to find the limitations of the current evaluation approach and show how our framework better captures the true performance. Results indicate that 54.8\% of performance is lost solely due to the constraints of current evaluation approaches

% Results indicate the average improvement of the best-performing model by 10\% across the dataset. \textcolor{blue}{Results indicate that, for some datasets, over 50\% of performance is lost solely due to the constraints of current evaluation approaches.} \textcolor{red}{<<< yes this is the key!!! This is why people care! }Our human evaluation indicates that the proposed framework most aligns with the human judgment of argument correctness. 
% \end{abstract}

%Moreover, in exact match settings, evaluating implicit (arguments with no direct mention in the text) and scattered (arguments dispersed throughout the document) is impossible. We need framework that better evaluated the generative model to get the actual performance. 

%\textcolor{red}{Why do we care? Is it because people should/can use LLMs for this task? Is there a high-level noteworthy advantage of doing this?}

%Results also shows that REGen reduces 41.20\% of the inferences  
%Results also show that on  
