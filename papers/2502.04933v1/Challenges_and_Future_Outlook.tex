\section{Challenges, Trends, and Research Directions}
\label{sec:Challenges_and_future_outlook}
This section highlights the fundamental
challenges that may hinder the integration of \glspl{LLM} in 6G networks (see Fig.~\ref{fig:LNF_challenges}), and proposes novel approaches along with promising research areas:
\smallskip

\textbf{Data Volumes and Quality.} \glspl{LLM} should process large volumes of heterogeneous data. \glspl{MNO} can harness knowledge distillation techniques \cite{Acharya2024Survey} to generate smaller focused datasets using domain-specific expert models, inherited from their conventional \gls{OAM}, to teach a general-purpose \gls{SOTA} \gls{LLM}. Particularly, this will extend the \gls{LLM}'s vocabulary with domain-relevant terminology, e.g. to understand specialized jargon used in trouble tickets. Efficient \gls{MNO}'s retention policies are also helpful to store, manage, and eventually delete internal data (e.g. network logs) within an optimal duration, weighting training needs and storage costs.

On the other hand, the performance of the \glspl{LLM} for \gls{MNO}-specific tasks is heavily dependent on the quality and breadth of the data. This calls for federated data governance policies that clean, compress and structure data locally at the data sources level before uploading to a central repository, provided that governance tools are perfectly aligned in multi-vendor environments to avoid conflicts.
\smallskip

\textbf{Computational Complexity.} The \gls{LLM} requires strong computational power and storage to analyze data effectively and deliver insights promptly. Multi-\gls{GPU} training leveraging parallel processing capabilities across multiple \glspl{GPU} can be used to distribute the training workload. Several approaches such as data parallelism, model parallelism, pipeline parallelism and hybrid parallelism can be envisioned to assign to each \gls{GPU}, a portion of the data, a slice of the model, a specific layer of the model, or a mix of the former blocks, respectively, to be processed in parallel. This introduces, however, an increased communication overhead and requires a seamless synchronization between the parallel \glspl{GPU}.

The \gls{LLM} may also be instantiated as distributed \glspl{NF} across edge, metro, and cloud segments. At the edge, \gls{LLM} instances can handle low-latency operations and localized decision-making such as tackling disruptions related to radio link. Metro \gls{LLM} instances can analyze region-wide trends, e.g. to deal with mobility-related anomalies across several cells. At the cloud, the focus is on centralized decision-making \cite{Chaparadza2023optimization} such as global outages. It is challenging to maintain a real-time orchestration and scale dynamically across these segments to meet fluctuating demands especially in heterogeneous hardware and software environments.% over these segments can also be one more bottleneck

Additionally, computationally-intensive \gls{LLM} operations lead to significant carbon footprint calling for green energy initiatives, carbon offsetting and hosting datacenters in cooler climates.
\smallskip

\textbf{Security and Privacy Concerns.} \gls{LLM} suffers from adversarial attacks and data leakage vulnerabilities. The first attack relies on intentionally crafting the input data to corrupt the \gls{LLM} decisions. The training dataset should incorporate examples of such attacks to boost its resilience. The second vulnerability is designed to infer sensitive information from \gls{LLM} outputs. It can be mitigated by differential privacy that injects artificial randomness to data or computation process to protect data confidentiality. The amount of the injected noise should be carefully controlled to maintain the accuracy of the \gls{LLM} results.

Moreover, \glspl{MNO} tend to build their private \glspl{LLM} using open-source solutions (e.g. \gls{LLaMA}, DeepSeek) instead of commercial ones to avoid exposing sensitive data to third-party services \cite{Kan2024mobile_llama}.
\smallskip

\textbf{\gls{MNO} acceptance of \gls{LLM}-generated insights.} Fully autonomous \glspl{LLM} within 6G networks could potentially be perceived as "black boxes". Explainable \gls{AI} principles enable \glspl{LLM} to document their decision-making processes, making their actions understandable and auditable \cite{maatouk2024large}. Self-governance mechanisms allow these systems to self-regulate and mitigate errors, fostering confidence in their autonomy. The complexity of the \gls{LLM} models and the high-dimensionality of the data make it challenging to trace the decision-making process without reliance on approximations and simplifications.
\smallskip

\textbf{Lack of telecom-centric \gls{AI} standards.}
Due to the lack of \gls{AI} standardization efforts in the telecommunication field, each \gls{MNO} can take a distinct approach to embrace the \gls{LLM} technology. This may lead to adopting suboptimal \glspl{LLM} or disparate \gls{AI} practices, leading to incompatibilities. Initiatives such as ITU-T Y.3000 series and GSMA Responsible \gls{AI} Maturity Roadmap can orient telecommunication stakeholders in adopting \gls{AI} and \glspl{LLM} both strategically and ethically.
% By establishing clear and transparent operations, \glspl{LLM} enhance trust among stakeholders and pave the way for broader adoption of fully autonomous solutions. 
% to prevent them being seen been seens as black box and
%  function as "black boxes," making their internal workings difficult to interpret
% ensure seamless integration and user acceptance. 

% to avoid sharing the identity of their users and the sensitive network data over proprietary solutions that lacks code transparency.

%Although GPT models have demonstrated advanced performance, many private institutions or companies, including mobile carriers, 
%As the data is the cornerstone of the \glspl{LLM}, can be corrupted by intentionally falsified data.adversarial attacks
%An Adversarial Attack involves the manipulation or exploitation of a Machine Learning model using carefully crafted data.

%can be corrupted by intentionally falsified input data leading to misleading predictions or decisions.

% cannot use commercial LLM services with their private user and network data. Instead, they prefer open-source \glspl{LLMs} (e.g. \gls{LLaMA}) to prevent  have enabled institutions that cannot provide their data to proprietary services to build their private LLM services.
\begin{figure}[t!]
\centering
\includegraphics[width=.4\textwidth]{Fig4.eps}
    \caption{Key challenges for \gls{LLM}-powered 6G.}
    \label{fig:LNF_challenges}
\end{figure}
