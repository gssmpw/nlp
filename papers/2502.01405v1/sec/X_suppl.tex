\clearpage
\setcounter{page}{1}
\maketitlesupplementary

\section*{A. Supplementary Results on NeRF Synthetic and LLFF dataset}

First, we note that as part of the supplementary materials we have \textbf{included a interactive website}, which provides qualitative comparisons with two closest baselines to our method (methods that have comparable running times): TensoRF \cite{Chen2022ECCV} and ZeroRF \cite{shi2024zerorf}. As can be seen in the provided website, our method significantly outperforms those baselines in terms of quality of reconstructions in the few-shot setting, and has fewer artefacts, especially when considering very few input views. We provide qualitative comparisons both in terms of the novel view synthesis (RGB) as well as depth estimation compared to these baseline approaches. We encourage the reader to consider the videos provided in the interactive website (please allow a few seconds to load the videos) to see the improvement provided by our method.

In addition, below we include details on the statistics of our evaluations on the LLFF dataset in tables \ref{tab:llff-details-3},\ref{tab:llff-details-6},\ref{tab:llff-details-9} and on the NeRF synthetic dataset in tables \ref{tab:nerf_synthetic_4_details} and \ref{tab:nerf_synthetic_6_details}. For the LLFF dataset we reproduced the ZeroRF experiments to obtain the per scene score.

\begin{table*}[ht]
    \centering
    \caption{Details quantitative comparison on the LLFF real dataset 3 views.}
    \begin{tabular}{lcccccccccc}
        \toprule
        Method & Statistic & fortress & room & horns & orchids & leaves & fern & flower & trex & mean\\
        \midrule
        \multirow{3}{*}{FreeNeRF~\cite{yang2023freenerf}}
          & PSNR $\uparrow$  & \first 23.437 & \first 22.020 & \first 18.506 & \first 15.286 & \second 16.250 & \first 21.187 & \second 20.413 & \second 19.941 & \first 19.630	  \\
        & SSIM $\uparrow$  & \first 0.583 & \first 0.834 & \second 0.585 & \second 0.407 & \second 0.521 & \second 0.662 & \second 0.617 & \second 0.687 & \second 0.612	 \\
        & LPIPS $\downarrow$ & \second 0.319 & \first 0.190 & \second 0.355 & \second 0.377 & \second 0.350 & \second 0.286 & \second 0.291 & \second 0.297 & \second 0.308   \\

        \midrule
        \multirow{3}{*}{ZeroRF~\cite{shi2024zerorf}}
          & PSNR $\uparrow$  & \third 20.633 & \third 18.833 & \third 13.688 & \third 13.900 & \third 16.275 & \third 18.700 & \third 17.880 & \third 16.786 & \third 17.087  \\
        & SSIM $\uparrow$  & \third 0.435 & \third 0.663 & \third 0.233 & \third 0.275 & \third 0.533 & \third 0.523 & \third 0.490 & \third 0.517 & \third 0.459  \\
        & LPIPS $\downarrow$ & \third 0.386 & \third 0.392 & \third 0.612 & \third 0.527 & \third 0.398 & \third 0.422 & \third 0.423 & \third 0.451 & \third 0.451  \\
        \midrule
        \multirow{3}{*}{Ours}
        & PSNR $\uparrow$  & \second 22.109 & \second 20.271 & \second 18.290 & \second 15.103 & \first 16.524 & \second 20.965 & \first 21.062 & \first 20.103 & \second 19.303  \\
        & SSIM $\uparrow$  & \second 0.573 & \second 0.792 & \first 0.627 & \first 0.422 & \first 0.587 & \first 0.667 & \first 0.674 & \first 0.745 & \first 0.636  \\
        & LPIPS $\downarrow$ & \first 0.305 & \second 0.294 & \first 0.336 & \first 0.359 & \first 0.290 & \first 0.271 & \first 0.266 & \first 0.271 & \first 0.299  \\
        \bottomrule
    \end{tabular}
    \label{tab:llff-details-3}
\end{table*}  

\begin{table*}[ht]
    \centering
    \caption{Details quantitative comparison on the LLFF real dataset 6 views.}
    \begin{tabular}{lcccccccccc}
        \toprule
        Method & Statistic & fortress & room & horns & orchids & leaves & fern & flower& trex & mean\\
        \midrule
        \multirow{3}{*}{FreeNeRF~\cite{yang2023freenerf}}
          & PSNR $\uparrow$  & \second28.728 & \second27.302 &  \first23.592 & \second17.263 & \second19.047 &  \first24.647 &  \first24.665 &  \first24.596 &  \first23.730	  \\
        & SSIM  $\uparrow$  & \second0.832 & \second0.910 & \second0.792 & \second0.555 & \second0.685 & \second0.796 & \second0.797 &  \first0.864 & \second0.779	 \\
        & LPIPS $\downarrow$ & \second0.162 &  \first0.117 &  \first0.218 &  \first0.291 & \second0.260 &  \first0.196 &  \first0.162 &  \first0.154 & \first0.195  \\
          
        \midrule
        \multirow{3}{*}{ZeroRF~\cite{shi2024zerorf}}
           & PSNR $\uparrow$  & \third 23.767 & \third 27.083 & \third 19.188 & \third 14.425 & \third 18.475 & \third 23.533 & \third 21.780 & \third 21.957 & \third 21.276  \\
        & SSIM  $\uparrow$  & \third 0.802 & \third 0.880 & \third 0.606 & \third 0.318 & \third 0.670 & \third 0.753 & \third 0.712 & \third 0.796 & \third 0.692  \\
        & LPIPS $\downarrow$ & \third 0.195 & \third 0.211 & \third 0.387 & \third 0.519 & \third 0.319 & \third 0.280 & \third 0.277 & \third 0.279 & \third 0.308  \\
        \midrule
        \multirow{3}{*}{Ours}
        & PSNR $\uparrow$  &  \first29.031 &  \first28.792 & \second23.273 &  \first17.484 &  \first19.187 & \second24.466 & \second24.510 & \second22.019 & \second23.595  \\
        & SSIM $\uparrow$  &  \first0.878 &  \first0.920 &  \first0.815 &  \first0.558 &  \first0.727 &  \first0.792 &  \first0.822 & \second0.810 &  \first0.790  \\
        & LPIPS $\downarrow$ &  \first0.144 & \second0.165 & \second0.217 & \second0.313 &  \first0.214 & \second0.210 & \second 0.174 & \second0.243 & \second0.210  \\
        \bottomrule
    \end{tabular}
    \label{tab:llff-details-6}
\end{table*}  

\begin{table*}[ht]
    \centering
    \caption{Details quantitative comparison on the LLFF real dataset 9 views.}
    \begin{tabular}{lcccccccccc}
        \toprule
        Method & Statistic & fortress & room & horns & orchids & leaves & fern & flower & trex & mean\\
        \midrule
        \multirow{3}{*}{FreeNeRF~\cite{yang2023freenerf}} 
         & PSNR $\uparrow$ & \second 29.421 & \first 29.927 & \first 25.154 & \first 19.083 & \second 20.678 & \first 26.073 & \second 26.182 & \second 24.522 & \first 25.130 \\
        & SSIM $\uparrow$ & \second 0.865 & \first0.938 & \second 0.846 & \first 0.662 & \second 0.756 & \first 0.831 & \second 0.843 & \second 0.875 & \second 0.827	 \\
        & LPIPS $\downarrow$ & \first 0.124 & \first 0.091 & \first 0.174 & \first 0.237 & \second 0.222 & \first 0.159 & \first 0.133 & \first 0.139 & \first 0.16  \\

        \midrule
        \multirow{3}{*}{ZeroRF~\cite{shi2024zerorf}}
           & PSNR $\uparrow$ & \third 24.350 & \third26.883 & \third21.675 & \third16.125 & \third19.200 & \third24.400 & \third23.240 & \third24.629 & \third22.563  \\
        & SSIM $\uparrow$ &    \third0.797 & \third0.903 & \third0.733 & \third0.465 & \third0.700 & \third0.787 & \third0.762 & \third0.850 & \third0.750  \\
        & LPIPS $\downarrow$ & \third0.195 & \third0.189 & \third0.314 & \third0.424 & \third0.300 & \third0.242 & \third0.250 & \third0.229 &\third 0.268  \\
        \midrule
        \multirow{3}{*}{Ours}
        & PSNR $\uparrow$ &    \first 29.567 & \second 29.011 & \second 24.799 & \second 19.046 & \first 20.839 & \second 25.774 & \first  26.488 & \first 24.562 & \second 25.011  \\
        & SSIM $\uparrow$ &    \first 0.881 & \second 0.931 & \first 0.860 & \second 0.636 & \first 0.775 & \second 0.825 & \first 0.854 & \first 0.876 & \first 0.830  \\
        & LPIPS $\downarrow$ & \second 0.153 & \second 0.171 & \second 0.194 & \second 0.283 & \first 0.200 & \second 0.187 & \second 0.158 & \second 0.198 & \second 0.193  \\
        \bottomrule
    \end{tabular}
    \label{tab:llff-details-9}
\end{table*}  

\begin{table*}[ht]
    \centering
    \caption{Details quantitative comparison on the NeRF synthetic dataset 4 views.}
    \begin{tabular}{lcccccccccc}
        \toprule
        Method & Statistic & chair & drums & ficus & hotdog & lego & materials & mic & ship & mean\\
        \midrule
        \multirow{3}{*}{FreeNeRF~\cite{yang2023freenerf}}
          & PSNR $\uparrow$ & \third20.22 & \third14.99 & \third17.35 & \third23.58 & \third20.43 & \second 21.36 & \third15.05 & \third 17.52 & \cellcolor{yellow!25}{18.81} \\
          & SSIM $\uparrow$ & \third0.843 & \third0.746 & \third0.809 & \third0.899 & \third0.818 & \second 0.857 & \third0.802 & \third0.687 & \cellcolor{yellow!25}{0.808} \\
          & LPIPS $\downarrow$ & \third0.109 & \third0.280 & \third0.144 & \third0.108 & \third0.156 & \third0.174& \third0.218& \third0.318 & \cellcolor{yellow!25}{0.188} \\
        \midrule
        \multirow{3}{*}{ZeroRF~\cite{shi2024zerorf}}
          & PSNR $\uparrow$ & \second 23.04 & \second 16.91 & \first 20.12 & \first 29.11 & \second 22.11 & \third20.50 & \first 24.76 & \second 19.01 & \cellcolor{red!25}{21.94}\\
          & SSIM $\uparrow$ & \second 0.880 & \second 0.791 & \first 0.866 & \first 0.944 & \second 0.868 & \third0.848 & \first 0.944 & \second 0.707 & \cellcolor{orange!25}{0.856}\\
          & LPIPS $\downarrow$ &\first 0.074 & \first 0.131 & \first 0.100 & \first 0.075 & \first 0.085 &  \second 0.132 & \first 0.050 & \first 0.256 & \cellcolor{red!25}{0.113}\\
        \midrule
        \multirow{3}{*}{Ours}
        & PSNR $\uparrow$ & \first 24.13 & \first 17.33 & \second 18.56 & \second27.26 & \first 22.41 & \first 21.15 & \second23.35 & \first 19.64 & \cellcolor{orange!25}{21.73}  \\
         & SSIM $\uparrow$ & \first 0.895 & \first 0.804 & \second 0.848 & \second 0.933 & \first 0.871 & \first 0.858 & \second0.929 & \first 0.724 & \cellcolor{red!25}{0.858}  \\
         & LPIPS $\downarrow$ & \second 0.107 & \second 0.206 & \second 0.120 &  \second 0.088 & \second 0.122 & \first 0.129 & \second 0.056 & \second0.283 & \cellcolor{orange!25}{0.139}  \\
        \bottomrule
    \end{tabular}
    \label{tab:nerf_synthetic_4_details}
\end{table*}


\begin{table*}[ht]
    \centering
    \caption{Details quantitative comparison on the NeRF synthetic dataset 6 views.}
    \begin{tabular}{lcccccccccc}
        \toprule
        Method & Statistic & chair & drums & ficus & hotdog & lego & materials & mic & ship & mean\\
        \midrule
        \multirow{3}{*}{FreeNeRF~\cite{yang2023freenerf}}
          & PSNR $\uparrow$ & \second26.72 & \third18.16 & \third18.46 & \third27.18 & \third24.32 & \first 21.63 & \third25.64 & \third20.23 & \third22.77 \\
          & SSIM $\uparrow$ & \third0.916 & \third0.827 & \third0.840 & \third0.929 & \third0.887 & \second0.853 & \second0.942 & \third0.729 & \third0.865 \\
          & LPIPS $\downarrow$ & \second0.071 & \second0.176 & \second0.161 & \second0.096 & \third0.132 & \third0.202 & \second0.066 & \third0.290 & \third0.149 \\
        \midrule
        \multirow{3}{*}{ZeroRF~\cite{shi2024zerorf}}
          & PSNR $\uparrow$ & \first 27.62 & \first 20.88 & \first 22.21 & \first29.93 & \second26.26 & \third21.41 & \first27.40 & \second22.13 & \first 24.73 \\
          & SSIM $\uparrow$ & \first 0.926 & \first 0.869 & \first 0.898 & \first 0.949 & \second0.913 & \third0.849 & \first0.954 & \second0.756 & \first 0.889\\
          & LPIPS &\first 0.074 & \first 0.131 & \first 0.100 & \first 0.075 & \first 0.085 & \first 0.132 &\first 0.050 & \first 0.256 & \first 0.113\\
        \midrule
        \multirow{3}{*}{Ours}
         & PSNR $\uparrow$ & \third26.62 & \second19.30 & \second19.43 & \second28.84 & \first 27.09 & \second21.46 & \second25.78 & \first 22.89 & \second23.93  \\
         & SSIM $\uparrow$ & \second0.918 & \second0.838 & \second0.860 & \second0.939 & \first 0.915 & \first 0.856 & \second0.942 & \first 0.767 & \second0.879  \\
         & LPIPS $\downarrow$ & \third0.095 & \third0.182 & \third0.124 & \third0.108 &\second0.103 & \second0.141 & \third0.072 & \second0.261 & \second0.136  \\
        \bottomrule
    \end{tabular}
    \label{tab:nerf_synthetic_6_details}
\end{table*}


\section*{B. Details on Implementation and settings}

Finally, we provide details surrounding the settings of our implementation and experiments. All of our experiments were run in an nvidia RTX 4090 graphics card.
We build our code base in top of the TensoRF \cite{Chen2022ECCV} repository. Our repository can be found in the following link: \url{https://github.com/diego1401/FourieRF}.

Our method uses the AdamW optimizer \cite{kingma2014adam,loshchilov2017decoupled} with $\beta_1  = 0.9, \beta_2= 0.98$, and a weight decay of $0.2$ for synthetic scenes and $0$ for real scenes. When performing frequency-control on real scenes we have to deal with matter appearing in front of the camera as a form of overfitting, as highlighted by FreeNeRF \cite{yang2023freenerf}. We find that applying their occlusion regularization works without any modification in our pipeline, thus we use their hyper parameters to compute our metrics. Moreover, we note that it is also efficient to use the gradient scaling introduced in the Floaters No More paper \cite{philip2023floaters}, this approach does not require to set a hyper parameter. We train for 10k iterations to match with our baselines, mainly ZeroRF \cite{shi2024zerorf}.

The key hyper parameters of our method differ in the synthetic and real datasets. 
This can be attributed to the fact that the synthetic dataset has a solid color, white background, which alters the behavior of our method.

For the synthetic dataset, the clipping threshold is initialized as $f_0=0.3$, and it is linearly increased with $\delta = \frac{1}{2 000}= 2\times10^{-3}$. We use the same configuration parameters as TensoRF \cite{Chen2022ECCV} with the following differences. We apply a TV loss (with weight $w_{TV} = 1.0$) on the appearance and density features. We find that setting the weight decay to $0.2$ in the optimizer is the key to removing floaters (in our method and in ZeroRF \cite{shi2024zerorf}).

For the real dataset, the clipping threshold is initialized as $f_0=0.01$, and it is linearly increased until the end of training, i.e. $\delta = \frac{1}{10 000}= 10^{-4}$. We use the same configuration parameters as TensoRF \cite{Chen2022ECCV} with the following differences. We apply a TV loss (with weight $w_{TV} = 1.0$) on the appearance and density features, and an L1 loss (with weight $w_{L1} = 10^{-4}$) on the density features. We find that applying the L1 loss in this type of scenes is more efficient than setting a weight decay for the optimizer.