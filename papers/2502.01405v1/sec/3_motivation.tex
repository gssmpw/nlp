\section{Motivation and Overview}
\label{sec:motivation}
\begin{figure*}[t]
	\centering
    \vspace{-1em}
	\includegraphics[width=\linewidth]{./images/our_fail_cases.pdf}
	\caption{\textbf{Overfitting on the few-shot rendering problem.} ``Catastrophic overfitting" is a common behavior for standard NeRF representations on the few-shot rendering problem. Degenerate geometry is learned, which might result in plausible views near train inputs but does not generalize to novel views. }
    \vspace{-1em}
	\label{fig:fail_cases}
\end{figure*}

The few-shot rendering problem is inherently ill-posed.
% NeRF representation is highly expressive.
With only a few images, there is insufficient information to uniquely determine the reconstructed 3D scene.
As a result, training a standard NeRF model on very limited data will inevitably lead to overfitting, where the model memorizes the few input images and captures noise instead of learning an underlying 3D structure.
When an overfitted NeRF tries to synthesize new views, the results will be inaccurate or unnatural, producing distorted images that are unrealistic and inconsistent with the true 3D structure of the scene~\cite{yang2023freenerf,yu2021pixelnerf}.
% Being extremely under-constrained implies that fitting standard NeRFs, regardless of the representation used, will results in overfitting and create degenerate novel views \cite{yang2023freenerf,yu2021pixelnerf}.

%NeRF uses positional encodings to map 3D coordinates into a higher-dimensional space, allowing the neural network to model complex, high-frequency details (like sharp edges or fine textures). These encodings are typically a set of sinusoidal functions that introduce high-frequency components into the input data.

The problem highlighted by the FreeNeRF paper is that the vanilla NeRF's use of high-frequency positional encodings can cause the model to overfit drastically during the initial training iterations when given only a few input views. These high-frequency positional encoding inputs allow the model to quickly learn to fit the available data (the few training views) too well, but in doing so, it generates unrealistic or degenerate geometries, such as floaters. These geometries do not accurately represent the true structure of the scene but are instead arbitrarily constructed patches that help the network mimic patterns in input views.

This overfitting behavior is not limited to MLP-based NeRFs with positional encodings but is also observed in other NeRF representations. TensoRF~\cite{Chen2022ECCV} is an improved NeRF design that utilizes tensor decomposition to reduce computational complexity and memory usage while maintaining quality for 3D scene reconstruction. However, when directly used in few-shot scenarios, TensoRF also suffers from the overfitting problem.
In Fig.~\ref{fig:teaser}, we can see that TensoRF quickly fills the space with floaters that help the reconstruction on the set of limited views. These floaters do not generalize well to new views, but since they fit correctly the input views, removing them is challenging.

%This problem was first linked to the high frequency of positional encodings of the vanilla NeRF representation by the paper FreeNeRF \cite{yang2023freenerf}. This leads to ``catastrophic overfitting" in the first iterations of training, i.e. overfitting the limited training views with degenerate geometry such as floaters.

%FreeNeRF \cite{yang2023freenerf} approaches this by masking the positional encodings that serve as input for the MLP representation of the scene. This idea is not directly applicable to grid-methods such as TensoRF \cite{Chen2022ECCV}, thus reducing the applicability of the method with the \textbf{long training times} ($\approx$ 1 day) of vanilla NeRF. ZeroRF \cite{shi2024zerorf} is the first work that leverages accelerated NeRF structures to tackle the few-shot rendering problem. It utilizes a convolutional network to generate the feature maps of a TensoRF \cite{Chen2022ECCV} representation, this is based on the Deep Image Prior \cite{ulyanov2018deep} which shows that such architectures are robust to noise. Their method results thus in ``clean" features maps which are trained quickly ($\approx$ 30 min). According to the authors this approach does not generalize well to real scenes \cite{shi2024zerorf}, their prior is too strong and not valid for non-synthetic scenes.

\begin{figure*}[t]
	\centering
    \vspace{-1em}
	\includegraphics[width=0.95\linewidth,trim={0 0 0 0},clip]{./images/nerf_synthetic_comparison.pdf}
	\caption{\textbf{Comparison on Blender Dataset.} In the Lego scene, trained with 4 views, we compare the performance of FreeNeRF, ZeroRF, and our method. ZeroRF renders a compact and clean reconstruction of the scene, however, at the cost of omitting some key details. FreeNeRF fails in this new setting due to its reliance on complex occlusion regularization. Despite employing a simple prior, FourieRF accurately captures both geometry and appearance, demonstrating a faithful reconstruction of the scene's details.}
    %\vspace{-1em}
	\label{fig:blender-qualitative}
\end{figure*}

FreeNeRF~\cite{yang2023freenerf} addresses overfitting by masking positional encodings for the MLP scene representation. This method is not directly applicable to grid-based methods like TensoRF~\cite{Chen2022ECCV}, limiting its application given the long training times of MLP-based NeRF. ZeroRF~\cite{shi2024zerorf} is the first work to use accelerated NeRF structures to tackle the few-shot rendering problem. It employs a convolutional network to generate feature maps of a TensoRF~\cite{Chen2022ECCV} representation, resulting in quickly trained ``clean" feature maps. However, this approach doesn't generalize well to real scenes~\cite{shi2024zerorf}, as its strong prior is not valid for non-synthetic scenes.

\textbf{FourieRF} deals with these two issues: it is an \textbf{accelerated} method, training in less than 10 minutes, that can tackle a wide variety of scenes, from \textbf{synthetic} to \textbf{real}. See Fig.~\ref{fig:method} for an illustration of our method. Using our approach, we can obtain correct coarse geometry from simple and complex scenes, see Fig.~\ref{fig:coarse-geometry-extraction}. 

Overall, our method is built on two key observations. First, we note that both strong overfitting and high-frequency artifacts typically occur early in the optimization process (see Fig.~\ref{fig:fail_cases}), and, if avoided in these early stages, they are significantly less prominent in the final result. Second, we note that by \textit{gradually} increasing the maximal Fourier frequency of the learned signal both significantly regularizes the learned NeRF, while at the same time, providing the network enough degrees of freedom to learn the fine details (in the final stages of the optimization). 

In other words, progressively increasing the available frequencies builds a robust trajectory to maintain the correctness of the shape as well as produce photo-realistic results \ref{fig:teaser}. This coarse to fine prior is not specific to any data type, and thus works in both real and synthetic scenes.
