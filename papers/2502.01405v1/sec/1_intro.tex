\vspace{-1em}
\section{Introduction}
\label{sec:intro}


% General problem

The introduction of Neural Radiance Fields (NeRFs)~\cite{mildenhall2020nerf} has marked a significant milestone in the realm of 3D scene generation from 2D images using neural networks.
NeRFs create continuous 3D scene representations by predicting color and density from various viewpoints, allowing them to synthesize photorealistic novel views from perspectives not included in the training data.
This breakthrough has revolutionized applications in novel view synthesis, 3D asset generation, and inverse rendering, enabling unprecedented accuracy and realism in these domains~\cite{mueller2022instant,Jin2023TensoIR,NeRFshop23}.
%The introduction of Neural Radiance Fields (NeRFs) \cite{mildenhall2020nerf} has brought unprecedented accuracy to applications such as novel view synthesis, 3D asset generation, and inverse rendering to name a few \cite{mueller2022instant,Jin2023TensoIR,NeRFshop23}.

However, one major challenge with NeRFs is their need for a large number of input images to ensure accurate scene reconstruction~\cite{yu2021pixelnerf,yang2023freenerf}.
This limitation highlights the importance of the \textit{few-shot rendering problem}, which aims to perform novel view synthesis with only a limited set of input views. Advancements in this domain are critical, as they can expand the applicability of NeRFs to practical scenarios where data is sparse, effectively bridging the gap between 2D and 3D data representation. Addressing the few-shot rendering challenge requires robust reconstruction techniques and a deep understanding of image data, given the inherently under-constrained nature of the problem.
%However, a key challenge of NeRFs and related techniques is their reliance on a \textit{dense} pool of input images \cite{yu2021pixelnerf,yang2023freenerf}.
%The \textit{few-shot rendering problem}, consists in performing novel view synthesis given \textit{a limited set} of input views. As a result, such developments in this domain have direct applications in practical scenarios involving a small number of views. They can ultimately help erode the barrier between two and three-dimensional data.
%Since few-shot rendering is an inherently under-constrained problem, solving it requires strong insights on image understanding and robust reconstruction.

% Broad categories

Several works tackle the few-shot rendering problem~\cite{yu2021pixelnerf,chen2021mvsnerf,jain2021putting,wang2023sparsenerf,seo2023flipnerf,kim2022infonerf,yang2023freenerf,shi2024zerorf}, each with a unique approach but sharing the common goal of addressing the ambiguities of this ill-posed problem by introducing priors. Some methods incorporate \textit{data-driven priors}~\cite{yu2021pixelnerf,chen2021mvsnerf,jain2021putting,wang2023sparsenerf} by pre-training on diverse scenes~\cite{yu2021pixelnerf,chen2021mvsnerf} or leveraging robust pre-trained modules, such as vision-language~\cite{jain2021putting} or depth models~\cite{wang2023sparsenerf}.
A limitation of data-driven priors is that they often have difficulty generalizing their knowledge to new, unseen scenes.
For example, these priors work well with scenes similar to their training data on indoor objects but struggle with novel or diverse scenes on wild natural or in vivo scenes due to the huge domain gap between the scene's distribution.
%Several works tackle the few-shot rendering problem \cite{yu2021pixelnerf,yang2023freenerf,shi2024zerorf}, each with their unique approach, but the common goal of resolving the ambiguities of the ill-posed problem with the introduction of a prior. Some works introduce \textit{data priors} \cite{yu2021pixelnerf,chen2021mvsnerf,jain2021putting,wang2023sparsenerf} by pre-training on several scenes \cite{yu2021pixelnerf,chen2021mvsnerf}, or leveraging pretrained robust modules, such as vision-language \cite{jain2021putting} or depth \cite{wang2023sparsenerf} models.

Unlike data-driven priors, some approaches rely solely on the information available in the given training data and use \textit{explicit regularization}~\cite{seo2023flipnerf,kim2022infonerf,yang2023freenerf,shi2024zerorf}.
%On the other hand, some approaches opt to only utilize the available information and thus rely on \textit{specially designed priors} \cite{seo2023flipnerf,kim2022infonerf,yang2023freenerf,shi2024zerorf}.
Our work follows this latter direction, imposing a prior that constrains the search space of learnable parameters, similar in spirit to FreeNeRF's use of frequency masking~\cite{yang2023freenerf} or ZeroRF's application of the Deep Image Prior~\cite{ulyanov2018deep,shi2024zerorf}.
%Our work imposes a prior that limits the search space of the learnable parameters, such as FreeNeRF \cite{yang2023freenerf} with frequency masking or ZeroRF \cite{shi2024zerorf} using the Deep Image Prior \cite{ulyanov2018deep}.

% Limitations

Existing methods for few-shot rendering face significant limitations in practical scenarios. Approaches leveraging \textit{data-driven priors} are often computationally intensive, restricting their real-world applicability. Beyond the substantial computational cost of pre-training, most methods~\cite{yang2023freenerf,yu2021pixelnerf,chen2021mvsnerf,wang2023sparsenerf,jain2021putting} are built on the original NeRF~\cite{mildenhall2020nerf} or Mip-NeRF~\cite{barron2021mipnerf} frameworks, which are notoriously slow to train.
While various techniques exist to accelerate NeRF training~\cite{Chen2022ECCV,mueller2022instant,kerbl3Dgaussians}, only ZeroRF~\cite{shi2024zerorf}—to the best of our knowledge—applies accelerated representations, such as grid-based methods, to the \textit{few-shot setting without data priors}. ZeroRF adapts TensoRF~\cite{Chen2022ECCV} for this context but struggles to handle real-world scenes effectively, as acknowledged by its authors~\cite{shi2024zerorf}. Other approaches address few-shot rendering using 3D Gaussian splatting~\cite{li2024dngaussian,zhu2025fsgs}; however, these rely on depth information, placing them outside the scope of our comparisons.

%All existing methods for few-shot rendering, however, suffer from limitations in practical scenarios. Approaches that use \textit{data-driven priors} are often computationally expensive, limiting their applicability. In addition to the computational toll needed to pre-train, the vast majority of works~\cite{yang2023freenerf,yu2021pixelnerf,chen2021mvsnerf,wang2023sparsenerf,jain2021putting} are built on the original NeRF~\cite{mildenhall2020nerf} or Mip-NeRF~\cite{barron2021mipnerf} frameworks, which are notoriously slow to train.
%While there are numerous methods designed to accelerate NeRFs~\cite{Chen2022ECCV,mueller2022instant,kerbl3Dgaussians}, to the best of our knowledge, in the \textit{few-shot context without data priors} only ZeroRF~\cite{shi2024zerorf} leverages accelerated representations (specifically, grid-based methods) like TensoRF~\cite{Chen2022ECCV} does in the dense setting. However, the authors of ZeroRF acknowledge that their method struggles to accurately process real-world scenes~\cite{shi2024zerorf}. There exist methods that tackle the few-shot rendering problem by leveraging 3D gaussian splatting \cite{li2024dngaussian,zhu2025fsgs}, however these methods rely on leveraging the depth information of the scene, and thus are out of the scope of our comparisons.

% Contribution + Consequences

In this work, we present \textbf{FourieRF} a method to parameterize the features of grid-based NeRF methods using a general prior based on the Fourier Transform. Our approach has virtually no computational overhead since we apply it per iteration. FourieRF is fast, robust, and effective across a range of scenes, from synthetic to real. To showcase our method we compare FourieRF against the best existing \textit{learning-free} methods
%:
%ZeroRF~\cite{shi2024zerorf} for synthetic scenes and Free NeRF~\cite{yang2023freenerf} for real scenes. Our quantitative and qualitative results %
and show that FourieRF establishes a new state-of-the-art by delivering robust results in record time. In summary, our contributions are as follows:

% Attempt 1
% \begin{itemize}
%     \item We show that clipping spatial features in the fourier space allows for the extraction of coarse geometry in severly underconstrained settings.
%     \item We demonstrate that controlling the frequency of these features in fourier space allows to mantain correct geometry throughout training.
%     \item Based on these findings, we introduce a novel method to parameterize the spatial features of NeRF grid-methods.
% \end{itemize}

% Attempt 2

\begin{itemize}
\item We demonstrate that by constraining the maximum Fourier frequency, it is possible to regulate the level of details in NeRF's scene representations in an artifact-free manner.
%We demonstrate that clipped features enable the learning of high-resolution, simplified scene representations.
%We show that clipped features help to learn high resolution simplified versions of scenes
\item We show that the smooth shapes learned with low frequency accurately capture the scene's coarse geometry, providing robust and stable initialization in both few-shot and dense inputs.
%We show that these simple shapes accurately capture the scene’s coarse geometry, providing robust and stable information regardless of whether we use sparse or dense inputs.
%We demonstrate that these simple shapes consist of correct coarse geometry of the scene. This information is robust, and stable regardless of whether we use sparse or dense inputs.
\item We introduce a fast grid-based NeRF representation that band-limits feature grids’ frequency with a novel training curriculum. Our simple approach produces results on par with state-of-the-art while requiring a fraction of the time to converge.
% \item We introduce a fast grid-based NeRF representation that band-limits feature grids' frequency with a novel training curriculum, achieving state-of-the-art few-shot reconstruction in both efficiency and accuracy.
%We introduce a novel training curriculum that progressively increases the frequency of feature grids.

% This is optional:
%\item Extensive experiments confirm the effectiveness of our curriculum in both synthetic and real scenes, accurately extracting geometry with minimal input.
%We validate that our curriculum works in both synthetic and real scenes, extracting correct geometry given few inputs.
\end{itemize}

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{./images/architecture.pdf}
	\caption{\textbf{Method illustration.} From left to right. Feature vectors and matrices are initialized in the spatial space. They are projected using the FFT. The Fourier coefficients are clipped using the masking procedure. Finally, the inverse FFT is applied to retrieve the smoothed features. }
    \vspace{-1em}
	\label{fig:method}
\end{figure}
        
% To summarize our contributions,

% \begin{itemize}
%     \item We show that using the Fourier Transform we can parameterize a TensoRF to extract correct coarse geometry and color of a scene from as little as 3 views.
%     \item We reveal that progressively adding complexity given this correct coarse information leads to a proper reconstruction of the scene.
% \end{itemize}


% Failures:
% \begin{itemize}
%     \item ZeroRF -> real scenes
%     \item FreeNeRF -> Computation times -> $\approx$ 1 day
%     \item TensoRF -> filling scene with floaters
% \end{itemize}

% Ours
% \begin{itemize}
%     \item We can extract simple geometry from a vast set of scenes. -> have a figure (3 vs 100 views)
%     \item This correct geometry serves as prior to learn better shapes -> Slowly adding frequencies leads to good results \ref{fig:increasing-frequencies-progression}.
%     \item Overview of approach \ref{fig:method}
% \end{itemize}





% Neural Radiance Fields (NeRFs) \cite{mildenhall2020nerf} have quickly become a to-go technique in many Computer Graphics and Vision applications, such as novel view synthesis, 3D asset generation, inverse rendering,to name a few \cite{mueller2022instant,Jin2023TensoIR,NeRFshop23}. These models, however, heavily rely on a dense pool of input images. When given few images, these models are extremely prone to overfitting, which leads to poor reconstruction on unseen views.

% Despite the novelty of NeRFs, there is already several works that tackle the few-shot rendering problem. The most common approach is to add some prior to the pipeline to better pose the problem. For instance, some papers introduce geometric priors in the form of extra depth regularization \cite{wang2023sparsenerf}, or somehow controlling the search space of the parameters \cite{yang2023freenerf,shi2024zerorf}. Other lines of work include leveraging data-priors \cite{niemeyer2022regnerf,yu2021pixelnerf}. Nevertheless, most of these methods, while perfomant, are slow; being based on the original NeRF representation, modelling the scene with a deep neural network, their training and inference times are extremely slow. There exist vast efforts in speeding up the learning of radiance fields, for example with the use of grids of features \cite{Chen2022ECCV} or hierarchical structures \cite{mueller2022instant}. ZeroRF \cite{shi2024zerorf} tackles problem for synthetic scenes, using the Deep Image prior, however it is reported by the authors that their method fails for real scenes. To the best of our knowledge there are not fast and robust methods that solve the few-shot rendering problem for synthetic and real scenes.

% In this work we leverage the classical \textbf{Fourier Transform} $\mathcal{F}$ to construct a smooth and robust training trajectory for the learning of complex objects given a limited number of views. Our method leverages the following claims: learning coarse geometry and color is possible with a very limited set of views; given correct coarse information, we can add the next layer of complexity while avoiding catastrophic overfitting. In Fig.~ \ref{fig:increasing-frequencies-progression}, one can see that our method starts with an extremely simple version of the object, and progressively adds details. In contrast, vanilla NeRF methods, because of their assumption of a dense pool of input images, quickly overfit the input images, filling the scene with floaters that cannot be removed with further training.

% In this work we introduce \textbf{FourieRF}, a method for NeRF grid-representations to solve the few-shot problem with virtually no computational overhead. Concretely our contributions include,

% \begin{itemize}
%     \item A robust technique to control the representation power of a grid-based NeRF,
%     \item A procedure to progressively increase the complexity of such models to avoid overfitting in the challenging few-shot problem,
% \end{itemize}

% Our \textbf{FourieRF} method is fast and robust, and is able to tackle wide variety of scenes, from synthetic to real. Having virtually no computational overhead means that this technique is perfect as a baseline to add more complex data-driven priors to advance the performance even further.

% The way NeRFs fail on the few-shot task depends directly on the representation used. Classical NeRFs, based on deep MLP architectures, exhibit catastrophic performance in the under-constrained setup. They completely fail to extract any meaningful geometry, and do not generalize at all to new views. Several works aim to mitigate this problem, with geometric (\cite{yang2023freenerf, niemeyer2022regnerf}), or data-drive priors (\cite{niemeyer2022regnerf}). On the other hand, grid methods \cite{Chen2022ECCV, mueller2022instant}, fail in more manageable ways, see Fig.~\ref{fig:mlp-vs-grid}. Grid methods have shown to be robust and fast to train. Thus, in the following work, we focus our efforts in mitigating the artifacts these methods produce in the few-shot setting. A key insight to our method is that grid methods exhibit artifacts, due to overly fast convergence to the training views. We can limit the expressivity of this representation by setting smaller resolutions for the grid of features. In Fig.~\ref{fig:grid-varying-resolution}, we can see that ... (ANALYSIS).

% We present \textbf{FourieRF}, a fast sparse view reconstruction that leverages the Fourier Transform to control the expressivity of our grid representation.


% Insights:
% \begin{itemize}
%     \item Extracting correct coarse geometry is possible with as little as 3 views.
%     \item Given correct coarse geometry adding new higher frequencies is easier
%     \item The speed at which we add these frequencies is important
% \end{itemize}