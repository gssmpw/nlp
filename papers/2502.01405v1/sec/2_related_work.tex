\section{Related Work}
\label{sec:related_work}

\begin{figure*}[t]
	\centering
	\includegraphics[width=0.95\linewidth,trim={0 0 0 0},clip]{./images/simple_shapes.pdf}
	\caption{\textbf{Coarse Geometry Extraction.} Our method is capable of extracting correct coarse geometry from as little as 3 views. This coarse geometry remains relatively stable regardless of the number of views we input.}
    \vspace{-10px}
	\label{fig:coarse-geometry-extraction}
\end{figure*}

\paragraph{Radiance Field Representations}

The seminal work Neural Radiance Fields (NeRF) \cite{mildenhall2020nerf} uses deep neural architectures and a set of given images to produce photo-realistic novel-view synthesis (NVS). Subsequent grid methods, accelerate the pipeline by replacing the deep neural architecture with a 3D grid of features \cite{Chen2022ECCV}, or a multi-resolution hash grid \cite{mueller2022instant}. These grids' NeRF approaches were shown to converge orders of magnitudes faster than the original work while maintaining high-quality results. Encoding the information in an explicit 3D representation is a weak prior that leads to significantly easier learning. However, a common struggle of all NeRF representations is that they are \textit{data hungry}, they require several images to perform the NVS task properly. When given limited images, say 3 or 6, these models are extremely prone to overfitting; \textit{they produce incoherent geometry and images from novel points of view.}

\vspace{-1em}\paragraph{Few-shot Novel View Synthesis}

The problem described above is commonly referred to as the few-shot rendering problem. Approaches to address it can be categorized into two groups: methods that rely on data priors, such as scene depth~\cite{wang2023sparsenerf,zhu2025fsgs,li2024dngaussian} or diffusion models~\cite{wu2024reconfusion} to mitigate reconstruction ambiguities; and methods that operate without external data~\cite{yu2021pixelnerf,chen2021mvsnerf,jain2021putting,seo2023flipnerf,kim2022infonerf,yang2023freenerf,shi2024zerorf}. In this work, we focus on comparing our approach with state-of-the-art methods that do not rely on data priors, applying solely \textit{explicit regularization}, specifically FreeNeRF~\cite{yang2023freenerf} and ZeroRF~\cite{shi2024zerorf}.
We demonstrate that our method achieves state-of-the-art results while setting new records for speed, leveraging the Fourier transform to effectively control the complexity of features in a 3D grid.

%The setting mentioned above is commonly referred to as the few-shot rendering problem. The approaches to tackle this problem include methods relying on data-priors, such using the depth of the scene \cite{wang2023sparsenerf,zhu2025fsgs,li2024dngaussian}, or leveraging diffusion models \cite{wu2024reconfusion} to reduce the ambiguities of the reconstruction; and methods that do not leverage any external data \cite{yu2021pixelnerf,chen2021mvsnerf,jain2021putting,seo2023flipnerf,kim2022infonerf,yang2023freenerf,shi2024zerorf}. In this work, we focus on comparing with the state-of-the-art methods that do not leverage any data priors: FreeNeRF \cite{yang2023freenerf} and ZeroRF \cite{shi2024zerorf}.

%In this work, we show that we can obtain results that are on par with SOTA and record speed by leveraging the Fourier transform to control the complexity of the features of a 3D grid.

\vspace{-1em}\paragraph{Compression Neural Fields}

The work FreeNeRF \cite{yang2023freenerf} shows there exists a link between the failure of few-shot neural rendering and the positional encoding used by deep neural network-based NeRF methods. Their method proposes to mask the encoding and progressively give it to the network. This allows for a coarse-to-fine reconstruction. Nevertheless, their take is specific to NeRF representations that are based on deep neural architecture, it is not trivial to apply it to accelerated grid methods. Therefore making FreeNeRF \textit{extremely} slow to train.

On the other hand, ZeroRF \cite{shi2024zerorf} leverages the Deep Image Prior \cite{ulyanov2018deep} to parameterize a grid NeRF representation. This work constitutes, to our knowledge, the first instance of an accelerated NeRF representation that specifically tackles the few-shot rendering problem. The authors, however, acknowledge the limited applicability of their method to \textit{real} (i.e., non-synthetic) scenes.

We present FourieRF a method to parameterize the features of grid-based NeRF representations. Our method trains in record time (approximately 10 minutes) and can tackle real and synthetic scenes.

