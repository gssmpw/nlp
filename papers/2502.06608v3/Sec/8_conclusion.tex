\section{Conclusion and Discussion}


\subsection{Conclusion}
We present \method{}, a new image-to-3D generation model via the rectified-flow-based transformer. To efficiently train the model for high-fidelity shape generation, we propose a data-building system to process data from original datasets.
Compared to using all in-the-wild 3D models in the training dataset, filtered and fixed high-quality data can be properly reproduced into training data and effectively improve the model's training performance.
Additionally, we leverage the advance of SDF representation with surface normal guidance and eikonal regularization for finer geometry details and avoid aliasing artifacts.
Furthermore, a rectified-flow-based transformer with MoE and a high-resolution strategy is introduced for the scale-up training.
Experiments demonstrate that \method{} can generate high-fidelity 3D shapes, leading to a new state-of-the-art performance.

\subsection{Discussion}
In recent years, 3D generation has followed a unique exploration route, with methods such as using text-to-image models as priors for 3D generation via the SDS solution, such as DreamFusion\cite{poole2022dreamfusion}, and leveraging decoder-only transformer architectures to reconstruct 3D models from single or multiple views, such as LRM\cite{hong2023lrm}. However, due to the scarcity of large-scale datasets and limited experience in scaling up training for 3D generation tasks, the large-scale flow models, which have proven highly successful in 2D image and video generation, have not been widely applied to 3D generation. \method{} has deeply explored the 3D flow route from the perspective of data and training, successfully achieving 3D generation with strong generalization, exceptional detail, and high fidelity. It has effectively replicated the success of image and video generation architectures in the field of 3D generation. Through \method{}, 3D generation now aligns with image and video generation in terms of architecture and development stage, allowing the field of 3D generation to draw upon the wealth of architectures and training experience from 2D image and video generation.

Looking ahead, we can further scale up model parameters and training data, and employ more fine-grained conditional information injection methods to generate even more detailed 3D models. Additionally, based on the \method{} foundation, we can also explore tasks such as 3D model super-resolution, scene generation, and stylization.

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Images/geo_demo_show.pdf}
    \caption{A diverse array of texture-free 3D shapes generated by \method{}.}
    \label{fig:geo_demo_show}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Images/tex_demo_show.pdf}
    \caption{A diverse array of textured 3D shapes generated by \method{}.}
    \label{fig:texture_demo_show}
\end{figure*}