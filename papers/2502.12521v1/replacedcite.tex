\section{Related Work}
\label{sec:related}
\textbf{LLM Reasoning} is the ability of LLMs to logically process information and draw coherent conclusions, enabling them to solve complex problems____. The success of LLMs in Natural Language Generation____ and Natural Language Understanding____ has sparked interest in exploring reasoning capabilities. A range of datasets have been introduced to evaluate reasoning, covering tasks in arithmetic____, logic____, common sense____, and algorithmic reasoning____. We introduce these tasks in more detail in 
Section~\ref{sec:eval}, and report results across these tasks in Section~\ref{sec:experiments}.


\textbf{LLM Planning} involves constructing a sequence of actions to achieve defined goals____. LLMs have been employed as planners or high-level controllers for robotic tasks____ and as agents for web navigation____, scientific discovery____, and autonomous vehicles____. Despite their broad adoption, studies reveal that LLMs often struggle to generate valid plans for complex  tasks____. We provide details on evaluated planning problems in Section~\ref{sec:eval}, with results and analyses in Section~\ref{sec:experiments}.

\textbf{Inference Time Techniques} %\hongyi{This format is not consistent with previous LLM reasoning}
for LLMs are methods applied during output generation to improve performance, and alignment with downstream tasks____. These techniques aid reasoning and planning by breaking complex tasks into smaller, manageable steps for systematic problem-solving. For instance, Chain-of-Thought prompting (CoT)____ and its variants____ decompose problems into sequential steps, while self-consistency____ refines CoT by aggregating multiple responses through voting. Tree of Thought____, Graph of Thought____, and Monte Carlo Tree Search____ enhance problem-solving by systematically exploring reasoning paths. Details on inference-time methods are in Section~\ref{sec:inference_time}, with results in Section~\ref{sec:experiments}.