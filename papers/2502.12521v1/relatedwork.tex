\section{Related Work}
\label{sec:related}
\textbf{LLM Reasoning} is the ability of LLMs to logically process information and draw coherent conclusions, enabling them to solve complex problems~\citep{PrOntoQA}. The success of LLMs in Natural Language Generation~\citep{radford2018improving} and Natural Language Understanding~\citep{vaswani2017attention, devlin2019bert} has sparked interest in exploring reasoning capabilities. A range of datasets have been introduced to evaluate reasoning, covering tasks in arithmetic~\citep{aqua,cobbe2021gsm8k}, logic~\citep{arc_agi,wang2022lsat}, common sense~\citep{yang2018hotpotqa, geva2021did}, and algorithmic reasoning~\citep{yao2024tree}. We introduce these tasks in more detail in 
Section~\ref{sec:eval}, and report results across these tasks in Section~\ref{sec:experiments}.


\textbf{LLM Planning} involves constructing a sequence of actions to achieve defined goals~\citep{valmeekam2023planning, zheng2024natural}. LLMs have been employed as planners or high-level controllers for robotic tasks~\cite{liu2023llmp, huang2022language} and as agents for web navigation~\citep{deng2024mind2web}, scientific discovery~\citep{wang2024survey}, and autonomous vehicles~\citep{yang2023llm4drive}. Despite their broad adoption, studies reveal that LLMs often struggle to generate valid plans for complex  tasks~\citep{kambhampatiposition, xie2024travelplanner}. We provide details on evaluated planning problems in Section~\ref{sec:eval}, with results and analyses in Section~\ref{sec:experiments}.

\textbf{Inference Time Techniques} %\hongyi{This format is not consistent with previous LLM reasoning}
for LLMs are methods applied during output generation to improve performance, and alignment with downstream tasks~\citep{welleck2024from}. These techniques aid reasoning and planning by breaking complex tasks into smaller, manageable steps for systematic problem-solving. For instance, Chain-of-Thought prompting (CoT)~\citep{wei2022chain} and its variants~\citep{zhou2023leasttomost, kojima2022large} decompose problems into sequential steps, while self-consistency~\citep{wang2023selfconsistency} refines CoT by aggregating multiple responses through voting. Tree of Thought~\citep{yao2024tree}, Graph of Thought~\citep{besta2024graph}, and Monte Carlo Tree Search~\citep{rap,lats} enhance problem-solving by systematically exploring reasoning paths. Details on inference-time methods are in Section~\ref{sec:inference_time}, with results in Section~\ref{sec:experiments}.