% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{multirow,multicol}
\usepackage{graphicx}
\usepackage{arydshln}
\usepackage{amsmath}
\usepackage{enumitem}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{\our: An IE Free Rider on LLM Training Paradigm}
\title{\our: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}




\author{Letian Peng, Zilong Wang, Feng Yao, Jingbo Shang \\
University of California, San Diego \\
  \texttt{\{lepeng, ziw049, fengyao, jshang\}@ucsd.edu}
  }
%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\usepackage{xspace}

\newcommand{\our}{Cuckoo\xspace}
\newcommand{\jingbo}[1]{\textcolor{blue}{\textbf{Jingbo:} #1}}
\newcommand{\zilong}[1]{\textcolor{cyan}{\textbf{Zilong:} #1}}
\newcommand{\feng}[1]{\textcolor{red}{\textbf{feng:} #1}}
\newcommand{\zihanmod}[1]{\textcolor{brown}{#1}}

% \newcommand{\jingbo}[1]{}
% \newcommand{\zilong}[1]{}

\begin{document}
\maketitle
\begin{abstract}
    \input{0-abs}
    % 
\end{abstract}

\input{1-intro}
\input{2-rel}
\input{3-method}
\input{4-exp}
\input{5-analysis}
\input{6-con}
\input{7-lim}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\clearpage

\appendix

\section{\our v.s. LLMs}
\label{apdx:vs_llm}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/coevolution_sft_llm_radar.pdf}
    \caption{The performance comparison between \our and LLMs on few-shot IE performance.}
    \label{fig:llm_radar}
    \vspace{-5mm}
\end{figure}

We extend the comparison to \our versus LLMs. We select \texttt{LLaMA-3-8B-TuluV3} and \texttt{GPT-4o} to represent the fine-tunable open-source LLMs and API-based close-source LLMs. For \texttt{LLaMA-3-8B-TuluV3}, we fine-tune the LLM with the same templated data as our \our. For both LLMs, we evaluate their in-context learning IE ability based on the few shots.

We present the experiment result in Figure~\ref{fig:llm_radar}, which demonstrate that \our can outperform even fine-tuned 8B LLMs. This implicates the superior learning efficiency of NTE over NTP on IE tasks. The ICL performance of LLM significantly lags behind the fine-tuned one, restraining the performance of close-source LLMs. Finally, Rainbow \our validates itself again as the strongest few-shot IE learner even when LLMs are considered.

\paragraph{Efficiency} The time efficiency of \our is significantly higher than LLMs thanks to the specialized learning paradigm for IE. Taking NER as an example, \our is around 20$\times$ faster than \texttt{LLaMA-3-8B-TuluV3}. When the LLM is using ICL, the efficiency advantage becomes more than $50\times$, demonstrating the superior efficiency of \our. 

\section{Templates and Hyperparameters}
\label{apdx:detail}

\paragraph{Task Templates} are included in Table~\ref{tab:template}, which are used to fine-tune NTE and NTP models like \our and LLaMA on IE tasks.


\begin{table}
\centering
\small
\scalebox{0.9}{
\begin{tabular}{p{1.5cm}p{5.2cm}}
\toprule
Target & Template\\
\midrule
Entity & \textbf{User:} [Context] Question: What is the [Label] mentioned? \textbf{Assistant:} Answer: The [Label] is \\
\midrule
Relation (Kill) & \textbf{User:} [Context] Question: Who does [Entity] kill? \textbf{Assistant:} Answer: [Entity] kills \\
\midrule
Relation (Live) & \textbf{User:} [Context] Question: Where does [Entity] live in? \textbf{Assistant:} Answer: [Entity] lives in \\
\midrule
Relation (Work) & \textbf{User:} [Context] Question: Who does [Entity] work for? \textbf{Assistant:} Answer: [Entity] works for \\
\midrule
Relation (Located) & \textbf{User:} [Context] Question: Where is [Entity] located in? \textbf{Assistant:} Answer: [Entity] is located in \\
\midrule
Relation (Based) & \textbf{User:} [Context] Question: Where is [Entity] based in? \textbf{Assistant:} Answer: [Entity] is based in \\
\midrule
Relation (Adverse) & \textbf{User:} [Context] Question: What is the adverse effect of [Entity]? \textbf{Assistant:} Answer: The adverse effect of [Entity] is \\
\midrule
Query & \textbf{User:} [Context] Question: [Question] \textbf{Assistant:} Answer: \\
\midrule
Instruction (Entity) & \textbf{User:} [Context] Question: What is the [Label] mentioned? ([Instruction]) \textbf{Assistant:} Answer: The [Label] is \\
\midrule
Instruction (Query) & \textbf{User:} [Context] Question: [Question] ([Instruction]) \textbf{Assistant:} Answer: \\
\bottomrule
\end{tabular}
}
\caption{The templates used in our experiments for different tasks.} 
\vspace{-5mm}
\label{tab:template}
\end{table}

\paragraph{Hyperparameter} All models are fully fine-tuned except for \texttt{LLaMA-3-8B-TuluV3}, which exhibits a poor performance without LoRA~\citep{lora}. We use a $128$-dimension LoRA for \texttt{LLaMA-3-8B-TuluV3}. All fine-tuning uses AdamW~\citep{AdamW} as the optimizer, learning rate initialized as $1\times 10^{-5}$ to fully fine-tune RoBERTa and OPT, and $2\times 10^{-4}$ to fine-tune the LoRA. The batch size is set to $64$ for all fine-tuning. 

\section{Benchmark Details}
\label{apdx:itie}

All results in the main experiments are an average of $3$ runs on different subsets of a few shots. MRC results are evaluated on the validation split as in previous works. Instruction-following IE only focuses on the modified entity types like organization and miscellaneous.

\paragraph{Relation Extraction} gives the ground-truth entities to extract related entities. We don't run end-to-end experiments to avoid mixing entity and relation extraction abilities.

\paragraph{Duplicates} When an entity is extracted as multiple types in NER, we keep all of them because modern generative IE models (e.g., LLM) allow such features to fit into a broader usage. For instance, an LLM would say ``Kobe Bryant'' to be both a ``person'' and a ``basketball player''. For MRC, when multiple answers are extracted, we will select the answer that appears the most.

\paragraph{SQuAD-V2} is a special MRC dataset that contains unanswerable questions. We follow the initial evaluation to assign $1.0$ F1 score to abstain for these questions and $0.0$ F1 score for any answer. Adaptive training for SQuAD-V2 contains extra $32$-shot unanswerable questions.

\paragraph{Disambiguation} The $3$ instructions used for disambiguation are presented in Table~\ref{tab:instruction}. We use the follow template to prompt \texttt{GPT-4o} for filtering.

\textit{[Instruction] Does ``[Entity]'' in ``[Context]'' satisfy the definition above? Answer ``yes'' or ``no'' only.}

We manually check the filtering quality of $50$ random cases for each instruction, and find a high filtering quality of $134/150=89.33\%$.

\paragraph{Miscellaneous} For CoNLL2003, as there is already a miscellaneous type, we manually write an instruction to define the scope of miscellaneous. For MIT-Restaurant dataset, we combine ``amenity'', ``hours'', and ``price'' entity types. For MIT-Movie dataset, we combine ``actor'', ``soundtrack'', and ``quote'' entity types. Then we simply collect those types of entities to build the miscellaneous type for the benchmark. In the instruction, we include negations of miscellaneous as distractors to increase the difficulty in instruction-following.


\begin{table}
\centering
\small
\scalebox{0.9}{
\begin{tabular}{p{0.8cm}p{1.5cm}p{4cm}}
\toprule
Task & Dataset & Instruction\\
\midrule
Disamb. & CoNLL2003 & The organization entity must be a subject of any active action in the context. \\
\cmidrule(lr){2-3}
& BioBLP2004 & The provided context must contain some descriptive information about the protein. \\
\cmidrule(lr){2-3}
& Restaurant & The rating should describe a food or drink mentioned in the sentence. \\
\midrule
Prefer. & SQuAD & Give the longest answer \\
& & Give the shortest answer \\
& & Give a concise answer \\
\midrule
Misc. & CoNLL2003 & Miscellaneous includes events, nationalities and products but not person, location or organization. \\
\cmidrule(lr){2-3}
 & Restaurant & Miscellaneous includes amenity, hours and price but not rating, dish, or location. \\
\cmidrule(lr){2-3}
  & Movie & Miscellaneous includes actor, soundtrack and quote but not director, opinion, or plot. \\
\bottomrule
\end{tabular}
}
\caption{The specific instructions used for instruction-following IE.} 
\vspace{-5mm}
\label{tab:instruction}
\end{table}

The specific instructions used for instruction-following IE are listed in Table~\ref{tab:instruction}.



\section{Adaptive Supervision Scaling}
\label{apdx:adaptive_scaling}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/adaptive_scaling.pdf}
    \vspace{-8mm}
    \caption{The scaling-up performance on adaptive supervision from CoNLL2003 of pre-trained IE models.}
    \label{fig:adaptive_scaling}
\end{figure}

In the application for IE, it's common to scale up the adaptive supervision (few-shot instances) to strengthen the model's IE ability. We plot such an example for CoNLL2003 in Figure~\ref{fig:adaptive_scaling} for transferring learning with different scales of supervision, from $5$-shot to $320$-shot. For comparison, we include the strongest NER baseline, NuNER, from the main experiment.

The results demonstrate that \our can scale up similarly as NuNER, the in-domain transfer of NuNER shows its advantage under very weak supervision but is surpassed by \our when the adaptive supervision is enough for domain understanding. Finally, Rainbow \our consistently show advantages under different adaptive supervision scales.

\section{Robustness to Verbalization}


\begin{table}
\centering
\small
\scalebox{0.9}{
\begin{tabular}{p{1.0cm}p{6.cm}}
\toprule
Rephrase & New Template/Label \\
\midrule
Template & \textbf{User:} [Context] Instruction: Extract [Label] from the text above. \textbf{Assistant:} [Label]: \\
\cmidrule(lr){2-2}
& \textbf{User:} List all [Label] entities: [Context] \textbf{Assistant:} Here are [Label] entities: 1. \\
\midrule
Label & (CoNLL2003) Person $\rightarrow$ Name\\
\cmidrule(lr){2-2}
 & (BioBLP2004) DNA $\rightarrow$ Deoxyribonucleic acid\\
\cmidrule(lr){2-2}
 & (Restaurant) Rating $\rightarrow$ Recommendation\\
\cmidrule(lr){2-2}
 & (Movie) Genre $\rightarrow$ Category\\
\bottomrule
\end{tabular}
}
\caption{The template/label variants used for robustness testing.} 
\vspace{-5mm}
\label{tab:variant}
\end{table}

As \our relies on prompts to perform different tasks. Its robustness to different verbalization of tasks and labels needs more emphasis. We select NER as an example and rephrase templates and labels in our experiments, which are listed in Table~\ref{tab:variant}. We rerun the experiments with these modifications and find the NER performance is not significantly (defined as $p < 0.05$ in significance testing) different from the initial results. This indicates \our to be robustness to different verbalization styles.

\end{document}
