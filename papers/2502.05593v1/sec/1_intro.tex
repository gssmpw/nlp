% \section{Introduction}
% \label{sec:intro}


% Deep learning has demonstrated remarkable capabilities and broad application prospects in medical image analysis\cite{10601163,10374392}. 
% Over the past decade, significant milestones have been achieved in tasks such as organ segmentation, tumor classification, and disease progression prediction\cite{7404017}. 
% Despite these advancements, real-world clinical applications often require robust performance across diverse datasets from multiple institutions\cite{multi_center}. 
% This highlights the importance of addressing data heterogeneity caused by differences in scanner vendors, imaging protocols, and operators\cite{9837077}. 
% Such heterogeneity often leads to substantial variations in probability distributions among clinical datasets, which significantly impacts the performance of deep learning models \cite{liu2020ms, wang2020domainmix, li2021simple}. 
% Consequently, when deep neural network models are applied to new, unseen data from different domains, their limited generalization ability restricts their practical applicability in clinical environments where generalization is essential \cite{liu2020green,dgdr2023}.

% Domain generalization has recently gained significant attention as a potential solution to this challenge\cite{wang2022generalizing,zhou2022domain}. 
% Existing approaches can be broadly categorized into data-centric, feature-centric, and model-centric methods. 
% Data-centric methods rely on data augmentation to increase domain diversity, such as Mixup\cite{zhang2017mixup} and style augmentation-based\cite{li2023intra} generation, which enhance model robustness by simulating unseen scenarios\cite{concutmix}. 
% Feature-centric methods, such as invariant risk minimization (IRM)\cite{arjovsky2019invariant}, focus on learning domain-invariant features to improve generalization across different domains\cite{chen2022pair, lin2022birm, li2022invariant}. 
% However, while vicinal invariant risk minimization (VIRM)\cite{zhu2024enlarging} demonstrates potential in large-scale datasets, 
% its random direction selection strategy often results in inefficient or meaningless augmentations (as shown in \Cref{fig:meaningless}) in the context of medical imaging, where annotated data is scarce and expensive.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.45\textwidth]{images/direction_selector.pdf}
%     \caption{
%         % Closer inter-domain distance increases feature support overlap.
%         Data augmentation methods expand feature overlap. 
%         However, the relatively small scale of medical image datasets and the clustered nature of features often result in many meaningless directions when random data augmentation is applied.
%         }
%     \label{fig:meaningless}
% \end{figure}

% Random direction selection may fail in medical image analysis scenarios, as augmentations without explicit alignment toward the target domain fail to bridge domain gaps.
% This arises mainly due to the fact that medical image datasets are usually smaller in order of magnitude than natural images and have high variability.
% Although other domain generalization algorithms tailored for medical image analysis, such as GDRNet\cite{dgdr2023}, have been proposed, their primary drawback lies in their strong specialization. 
% This makes them less suitable for the diverse imaging modalities in medical images, limiting their ability to generalize across different types of medical imaging data.

% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{images/Framework_MedVIRM.pdf}
%     \caption{Overview of the proposed MedVIRM framework.
%         $\mathbf{x}^i$ denotes the input image from domain $i$, $\mathbf{z}^i$ denotes the feature representation of $\mathbf{x}^i$, 
%         $\mathbf{d}^i_j$ denotes the augment direction for domain $i$ to domian $j$, 
%         and $\tilde{z}^i_j$ denotes the augmented feature representation of $\mathbf{z}^i$ in domain $j$.
%     }
%     \label{fig:framework}
% \end{figure*}

% To address these challenges, we propose a novel domain direction selector to replace the random augmentation strategy in VIRM. 
% Unlike VIRM, which aims to improve the overlap of representations between domains through random augmentations, our method dynamically guides each augmentation toward the target domain.
% This ensures that augmented samples contribute meaningfully to reducing domain discrepancies and enhancing domain generalization. 
% The proposed gated direction selector is designed to dynamically adjust the augmentation direction based on the inter-domain covariance, ensuring that the augmented samples contribute meaningfully to reducing domain discrepancies.
% The overall framework of our proposed method is illustrated in \Cref{fig:framework}.
% We evaluate our method on medical image domain generalization datasets: Diabetic Retinopathy. 
% Experimental results demonstrate that our approach consistently outperforms state-of-the-art methods, particularly in scenarios with limited data and significant domain heterogeneity. 
% These findings underscore the robustness and practicality of our framework, providing a strong foundation for its broader application in medical imaging tasks.

\section{Introduction}
\label{sec:intro}

Deep learning has shown remarkable capabilities and broad applicability in medical image analysis \cite{10601163, 10374392}.
In the past decade, significant progress has been made in tasks such as organ segmentation, tumor classification, and disease progression prediction \cite{7404017}.
Despite these advancements, real-world clinical applications often require robust performance across diverse datasets from multiple institutions \cite{multi_center}.
This emphasizes the importance of addressing data heterogeneity, which arises from variations in scanner vendors, imaging protocols, and operators \cite{9837077}.
Such heterogeneity leads to substantial variations in probability distributions across clinical datasets, significantly impacting the performance of deep learning models \cite{liu2020ms, wang2020domainmix, li2021simple}.
As a result, when deep neural network models are applied to new, unseen data from different domains, their limited generalization ability restricts their practical applicability in clinical settings, where generalization is crucial \cite{liu2020green, dgdr2023}.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{images/direction_selector.pdf}
    \caption{
        % Closer inter-domain distance increases feature support overlap.
        Data augmentation methods expand feature overlap. 
        However, the relatively small scale of medical image datasets and the clustered nature of features often result in many meaningless directions when random data augmentation is applied.
        }
    \label{fig:meaningless}
\end{figure}

Domain generalization has recently attracted significant attention as a potential solution to this challenge \cite{wang2022generalizing, zhou2022domain}.
Existing approaches can be broadly categorized into data-centric, feature-centric, and model-centric methods.
Data-centric methods focus on data augmentation to enhance domain diversity, including techniques such as Mixup \cite{zhang2017mixup} and style augmentation-based generation \cite{li2023intra}, which improve model robustness by simulating unseen scenarios \cite{concutmix}.
Feature-centric methods, such as invariant risk minimization (IRM) \cite{arjovsky2019invariant}, aim to learn domain-invariant features to improve generalization across different domains \cite{chen2022pair, lin2022birm, li2022invariant}.
However, while vicinal invariant risk minimization (VIRM) \cite{zhu2024enlarging} shows promise in large-scale datasets,
its random direction selection strategy often results in inefficient or meaningless augmentations (as shown in \cref{fig:meaningless}) in the context of medical imaging, where annotated data is scarce and expensive.
Random direction selection may fail in medical image analysis, as augmentations without explicit alignment toward the target domain fail to bridge domain gaps.

This issue is primarily due to the fact that medical image datasets are usually smaller in scale compared to natural images and exhibit high variability.
Although other domain generalization algorithms tailored for medical image analysis, such as GDRNet \cite{dgdr2023}, have been proposed, their main limitation lies in their strong specialization.
This specialization makes them less adaptable to the diverse imaging modalities encountered in medical images, thereby restricting their ability to generalize across different types of medical imaging data.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{images/Framework_MedVIRM.pdf}
    \caption{Overview of the proposed method framework.
    Our method includes an inter-domain covariance-guided direction selector and a distribution estimator that enhances the range of distribution.
        $\mathbf{x}^i$ denotes the input image from domain $i$, $\mathbf{z}^i$ denotes the feature representation of $\mathbf{x}^i$, 
        $\mathbf{d}^i_j$ denotes the augment direction for domain $i$ to domian $j$, 
        and $\tilde{z}^i_j$ denotes the augmented feature representation of $\mathbf{z}^i$ in domain $j$.
    }
    \label{fig:framework}
\end{figure*}


To address these challenges, we propose a novel domain direction selector, guided by inter-domain covariance, to replace the random augmentation strategy used in VIRM.
Unlike VIRM, which aims to improve the overlap of representations between domains through random augmentations, our method dynamically guides each augmentation toward the target domain.
This ensures that augmented samples contribute meaningfully to reducing domain discrepancies and enhancing domain generalization.
The proposed direction selector is designed to adjust the augmentation direction based on the inter-domain covariance, ensuring that the augmented samples effectively reduce domain discrepancies.
The overall framework of our proposed method is illustrated in \cref{fig:framework}.
We evaluate our method on a medical image domain generalization dataset: Diabetic Retinopathy.
Experimental results demonstrate that our approach consistently outperforms state-of-the-art methods, particularly in scenarios with limited data and significant domain heterogeneity.
These findings highlight the robustness and practicality of our framework, providing a solid foundation for its broader application in medical imaging tasks.

