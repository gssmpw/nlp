\section{Related Work}
\label{sec:related_work}

% Domain generalization (DG) has emerged as an important area of research aimed at developing models that can generalize well across different domains, especially when applied to diverse medical image datasets. 
% Various techniques have been proposed in the literature to tackle domain shifts, which often arise due to differences in imaging equipment, acquisition protocols, and patient demographics. 
% These approaches can be broadly categorized into three groups: data-centric methods, feature-centric methods, and model-centric methods. Below, we review these categories in the context of medical image analysis and discuss the strengths and limitations of each.

Domain generalization (DG) has emerged as a critical area of research with the goal of developing models that generalize well across different domains, particularly in the context of medical image datasets. 
A variety of techniques have been proposed in the literature to address domain shifts, which arise due to factors such as differences in imaging equipment, acquisition protocols, and patient demographics. 
These approaches can be broadly classified into three categories: data-centric methods, feature-centric methods, and model-centric methods. 
In this section, we review these categories in the context of medical image analysis and discuss the strengths and limitations of each.

\subsection{Data-Centric Methods}

Data-centric approaches focus on enhancing domain diversity through data augmentation strategies, enabling the model to learn from a broader range of scenarios. These methods simulate unseen domain variations, which helps improve generalization performance. Popular techniques include:
Mixup: A data augmentation method that generates new samples by combining pairs of images and their corresponding labels, fostering improved model robustness \cite{zhang2017mixup}.
StyleGAN: A generative approach that synthesizes diverse data variations by learning the distribution of image styles across different domains \cite{karras2019style}.
While these methods contribute to improved model performance by simulating a variety of scenarios, they often face challenges in medical image analysis, where annotated data is limited and expensive. The limited availability of annotated data in medical domains reduces the effectiveness of random data augmentation strategies.

\subsection{Feature-Centric Methods}

Feature-centric methods aim to learn domain-invariant features that generalize well across multiple domains. These methods focus on identifying common representations shared among domains to mitigate domain shifts and improve performance on unseen data.
Invariant Risk Minimization (IRM): IRM seeks to minimize the risk of domain-specific variations by learning features that are invariant across different domains \cite{arjovsky2019invariant}.
Domain-Adversarial Neural Networks (DANN): DANN employs adversarial training to align feature distributions between domains, encouraging the network to extract domain-invariant features \cite{ganin2016domain}.
VIRM: The recent method VIRM introduces a random augmentation strategy to enhance domain overlap and improve invariant feature learning \cite{zhu2024enlarging}.
While VIRM shows promise in large-scale datasets, its random direction selection often results in inefficient augmentations for medical imaging, where annotated data is scarce and highly variable. 
While feature-centric methods have demonstrated success in improving generalization across domains, they can struggle with medical imaging tasks where domain overlap is minimal or where data is highly heterogeneous. 
This often leads to suboptimal feature alignment.


\subsection{Model-Centric Methods}

Model-centric methods focus on designing novel model architectures or learning strategies to handle domain shifts more effectively. 
These methods typically incorporate domain-specific information into the learning process or employ meta-learning strategies to improve model adaptation.
Meta-Learning: Meta-learning approaches such as Model-Agnostic Meta-Learning (MAML) aim to train models that can quickly adapt to new domains with minimal data \cite{finn2017model}.
Domain Alignment Networks: These models introduce domain-specific components into the architecture to align features across domains while preserving domain-specific characteristics \cite{li2018domain}.
Although model-centric methods offer flexibility and adaptability, they often require large-scale datasets for training and can be computationally expensive, which limits their applicability in medical imaging tasks where labeled data is scarce.

\subsection{Domain Generalization in Medical Imaging}

Recent research has focused on applying domain generalization techniques specifically to medical image analysis. 
These studies aim to address challenges such as variations in imaging modalities, acquisition protocols, and limited annotated data. 
Key advancements in this area include:
GREEN\cite{liu2020green} method utilizes a Graph Convolutional Network to model class dependencies in diabetic retinopathy grading, addressing label uncertainty and improving the classification results through a residual re-ranking mechanism. 
GDRNet \cite{dgdr2023} effectively reduces domain discrepancies and enhances out-of-distribution generalization, particularly under conditions of limited data and significant domain heterogeneity. However, its specificity limits its generalization to other medical imaging tasks with varying imaging principles and modalities.
