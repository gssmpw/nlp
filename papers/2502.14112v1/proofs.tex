\section{Omitted Proofs}\label{apx:proofs}

% \begin{proposition}
%     There is a symmetric equilibrium, where for every agent $i$, $r^*_i=(c')^{-1}\left(R_r+\frac{R_a}{n}\right)$; and $$x^*_i= (\hat c)^{-1}\left(R_a \frac{n-1}{n^2}K\right)=(\hat c)^{-1}\left(R_a \frac{n-1}{n}r^*_i\right). $$
% \end{proposition}
\rmr{
\begin{proposition} Consider general $c_r,c_a$ cost functions. 
    The optimal strategy in the protected condition is to play $x^*_0 = 1$, and  $r^*_0$ is the unique $r$ s.t. $c'(r)=\frac{R_r+R_a}{2}$.
\end{proposition}

\begin{proof}
If $x_0>1$ then $w_0 > K$, and $a_i=\frac{x_0}{x_0}K=K$. So the agent pays $c(w_0)>c(K)$ without getting any additional benefit beyond $R_a\cdot K$. Thus $x_0>1$ is dominated.

If $x_0<1$ then $a_0=x_0 K = x_0 r_0$, and  
$$u_i=r_0 R_r + a_0 R_a- c_r(r_0) - c_a(w_0)= r_0 R_r + r_0 x_0 R_a- c_r(r_0) - c_a( r_0 x_0).$$

 We consider both partial derivatives of $u_0$:
\begin{align*}
    \frac{\partial u_0}{\partial r_0} & = R_r(1+x_0) - c'_r(r_0)-x_0 c'_a(r_0 x_0)\\
    \frac{\partial u_0}{\partial x_0} & = r_0 R_a - r_0 c'_a(r_0 x_0) \tag{since $a_0=x_0 r_0$}\\
    &\geq R_r - c'_a(r_0 x_0) \tag{by assumption} \\
    &> R_r - c'_a(r_0) \tag{by convexity and $x_0<1$}
     =  \frac{\partial u_0}{\partial r_0}.
\end{align*}
If the strategy is optimal, then both derivatives are 0. However this would mean
\begin{align*}
    R_r &< R_a=c'(r_0 x_0) < c'(r_0) &\Rightarrow\\
    \frac{\partial u_0}{\partial r_0} & = R_r+x_0 R_r - c'(r_0)-x_0 c'(r_0 x_0)\\
    &< c'(r_0) + x_0 c'(r_0 x_0) - c'(r_0)-x_0 c'(r_0 x_0)=0,
\end{align*}
i.e. a contradiction.

The strategy of the player therefore reduces to a single variable $r_0$, and the utility can be re-written as $u_0(r_0)=r_0(R_r+R_a) - 2c(r_0)$.
By derivation, we get 
that $r^*_0$ is the unique point where $c'_r(r)+c'_a(r) = R_r+R_a$.
\end{proof}
}
\begin{proposition}
    There is a symmetric equilibrium in the no-protection model, where for every agent $i$, 
    \begin{enumerate}
        \item  $c'(r^*_i)=R_r+\frac{R_a}{n^2}$; and 
        \item $x^*_i c'(n\cdot r^*_i x^*_i)= \frac{n-1}{n^2}R_a$.
    \end{enumerate}
\end{proposition}
\begin{proof}
\begin{description}
    \item[Exploration] Suppose that exploitation strategies $x_j$ are fixed, and by symmetry they are all equal so $x_j=x$ for some constant $x$.  We look for equilibrium exploration efforts $r_i$.
    Rewriting the utility function as a function of $r_i$,
    \begin{align*}
        u_i(r_i)&=r_i R_r + a_i R_a - c(r_i) - c(K x_i)
        %& = r_i R_r + \frac{x_i}{\sum_j x_j} R_a - c(r_i) - c(\sum_j r_j x_i)&\Rightarrow\\
    \end{align*}
    \rmr{somehow the proof is completely wrong but the result is correct...
    The derivatives in equilibrium are 
    \begin{align}
    0&=\frac{\partial u_i}{\partial r_i} = R_r+\frac1n R_a - c'_r(r_i)-x\cdot c'_a(\sum_j r_j x) \label{eq:pu_r}\\
    0&=\frac{\partial u_i}{\partial x_i} = KR_a \cdot \frac{x_{-i}}{(x_i+x_{-i})^2}-K\cdot c'_a(K x_i) \label{eq:pu_x}
    \end{align}
    Now let $r^*,x^*$ be the symmetric equilibrium strategies, then $x^*_{-i}=(n-1)x^*$. We get
    \begin{align*}
        T^*&:= x^*\cdot c'_a(\sum_j r^*_j x^*) = x^* \cdot c'(nr^* x^*)\\
        T^*&= R_r+\frac1n R_a -c'_r(r^*)   \tag{From Eq.~\eqref{eq:pu_r}}\\
        T^*&= \frac{n-1}{n^2}R_a &\Rightarrow  \tag{From Eq.~\eqref{eq:pu_x}}\\
        &R_r+\frac1n R_a-c'_r(r^*)   = \frac{n-1}{n^2}R_a &\Rightarrow\\
        c'_r(r^*)&= R_r+\frac1n R_a-\frac{n-1}{n^2}R_a  = R_r+ \frac{1}{n^2}R_a
    \end{align*}
    }
    
    Recall that $x_i\geq k_i$ and thus 
    $$a_i=k_i = K\cdot \frac{x_i}{\sum_j x_j}= K/n = \frac{\sum_j r_j}{n}.$$
    Thus the utility as a function of $r_i$ is 
    $$u_i(r_i)=r_iR_r + \frac{R_a}{n}(r_i + r_{-i})-c(r_i)-c(x_i),$$
    and the derivative is 
    \begin{align*}
        \frac{\partial u_i}{\partial r_i}&= R_r + \frac{R_a}{n}-c'(r_i)\\ &\Rightarrow
        r^*_i = (c')^{-1}(R_r + \frac{R_a}{n}).
    \end{align*}
    \item[Exploitation]  Now assume that exploration strategies $r_j$ are fixed, so $K=\sum_j r_j$ is a constant, and we look for $x_i$. By our assumption of over-exploitation, $a_i=K\frac{x_i}{x_i+x_{-i}}$, and 
    $$u_i(x_i) = r_iR_r + a_i R_a -c(r_i)-c(K\cdot x_i) = r_iR_r + R_a\frac{x_i}{x_i+x_{-i}}K  -c(r_i)-c(K\cdot x_i).$$
    Taking derivative, 
    \begin{align*}
          0=\frac{\partial u_i}{\partial x_i} & = KR_a \cdot \frac{x_{-i}}{(x_i+x_{-i})^2} - K\cdot c'(K\cdot x_i)&\Rightarrow \tag{in eq.}\\
          x_{-i} R_a &= c'(K\cdot x_i)(x_i+x_{-i})^2\tag{assuming symmetry}\\
           (n-1)x KR_a&= c'(K\cdot x)(nx)^2 &\Rightarrow\\
           c'(K \cdot x)x=&R_a \frac{n-1}{n^2}, %= (r_i^*)R_a\frac{n-1}{n}.
    \end{align*}
    which profs the theorem as $K=nr^*_j$.
\end{description}
\end{proof}

\begin{proposition}
    Suppose that $c(x) = \alpha \cdot x^\beta$.\\
    Then $x^*_i=\frac1n (\frac{R_a}{R_r})^{\frac{1}{\beta}}+\Theta\left(\frac{1}{n^{1+\frac{1}{\beta}}}\right)$.
\end{proposition}
\begin{proof}
    First note that $c'(x)=\alpha\beta x^{\beta-1}$. 
    Recall that $c'(r^*_i)=R_r+\frac{1}{n^2}R_a$ so that 
    $$r^*_i = (\frac{R_r+\frac{1}{n^2}R_a}{\alpha\beta})^{\frac{1}{\beta-1}}%=(\frac{R_r}{\alpha\beta})^{\frac{1}{\beta-1}}+\Theta(\frac{1}{n^2}).
    $$
    Next, recall that 
    $$x^*_i c'(K x^*_i) = \frac{n-1}{n^2}R_a = \frac{1}{n}R_a+ \Theta(\frac{1}{n^2}),$$
    where $K=nr^*_i = n(\frac{R_r+\frac{1}{n^2}R_a}{\alpha\beta})^{\frac{1}{\beta-1}} $.
    Plugging in our $c'$, 
    \begin{align*}
        \frac{1}{n}R_a& = x^*_i \alpha\beta \left(  n(\frac{R_r+\frac{1}{n^2}R_a}{\alpha\beta})^{\frac{1}{\beta-1}}\cdot x^*_i\right)^{\beta-1} + \Theta(\frac{1}{n^2})\\ 
        &=(x^*_i)^\beta\cdot \alpha\beta \cdot n^{\beta-1}\frac{R_r+\frac{1}{n^2}R_a}{\alpha\beta} + \Theta(\frac{1}{n^2})&\Rightarrow\\
        R_a &= (x^*_i)^\beta\cdot n^{\beta}(R_r+\frac{1}{n^2}R_a) + \Theta(\frac{1}{n}),
    \end{align*}
    so we can already see that $x^*_i=\Theta(\frac1n)$.
    Thus we can continue
    \begin{align*}
               R_a &= (x^*_i)^\beta n^{\beta}R_r+ (x^*_i)^\beta n^{\beta}\frac{1}{n^2}R_a + \Theta(\frac{1}{n}) \\
               &=(x^*_i)^\beta n^{\beta}R_r+ \Theta(\frac{1}{n^2}) + \Theta(\frac{1}{n})=(x^*_i)^\beta n^{\beta}R_r+ \Theta(\frac{1}{n})&\Rightarrow\\
               (x^*_i)^\beta &= \frac{R_a+\Theta(\frac{1}{n})}{n^\beta R_r} = \frac{R_a(1+\Theta(\frac1n)}{n^\beta R_r} &\Rightarrow\\
               x^*_i&=\frac1n\left(\frac{R_a}{R_r}\right)^{\frac1\beta}(1+\Theta(\frac1n))^{\frac1\beta}
               = \frac1n\left(\frac{R_a}{R_r}\right)^{\frac1\beta}\left(1+\Theta(\frac1{n^{\frac1\beta}})\right)\\
               &= \frac1n\left(\frac{R_a}{R_r}\right)^{\frac1\beta} +\Theta\left(\frac1{n^{1+\frac1\beta}}\right),
    \end{align*}
    as required.
\end{proof}
