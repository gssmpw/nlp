
\section{Theoretical Analysis}\label{sec:theory}
In this section we present an analytic solution from a game theoretical point of view. The theoretical analysis assumes Fully Informed Bayesian Players (FIBP) play the treasure hunt game and know the a-priori payoff structure (including the probability of finding a treasure in a new mine). It is important to note that in the real world, full information is rarely available to the operating agents (e.g., innovators) and thus in the experimental investigation presented in section \ref{sec:experiment}, the game was played without providing real participants a-priori full information about the incentive structure (see Section \ref{sec:experiment} for the information provided to real players in the experiment). Accordingly, we refer to the analytic solution as a benchmark for optimality under simplifying assumptions of full information. A final simulation is then used to estimate the game results of this benchmark solution.

The first decision each FIBP takes at the beginning of each round is whether to explore a new hexagon or not given the current state of the board and the costs of exploration.

A deterministic strategy is essentially a threshold in each of these board state cases. Hence, our main objective is to investigate the optimal threshold cost, for each stage of the game, for which the FIBP should explore if and only if the exploration cost in a specific round is lower than the threshold\footnote{Notice that a higher threshold value implies more exploration.}.


In the Protection condition, we can treat each specific exploration stage in the current mine, and compute an appropriate threshold. In the No Protection condition, we roughly divide it into two main situations: (1) search for a first treasure and (2) search for subsequent treasures. We are interested in specifying how this threshold changes under the different experimental conditions. 

In both cases we analyzed optimal (or equilibrium) strategies for FIBP assuming an infinite board and infinite time. The meaning of an infinite board is that without prior knowledge, there is a 5 percent probability of finding treasure in each hexagon. The meaning of infinite time is that, from the player's point of view, the optimal strategy cannot be calculated by calculating backwards from the last step in the game.


\subsection{Protection}

In this section we analyze the optimal exploration strategy under the Protection condition. After being granted Protection, a player can exclusively explore around his first treasure. Therefore, our approach is to examine what is the best threshold for each exploration stage. Notice that the optimal exploration strategy in each stage is affected by the exploration strategy that will be taken in the future during the search prosses at the same mine. For this reason, we calculate the optimal behaviour backwards- from finding the third treasure to searching for the first one.   To keep the text more fluent, we present here only the bottom line results, and present the calculation in Appendix~\ref{apdx:patent}.

\begin{prop}
Suppose the game has no time limit.  In the optimal exploration strategy under the Protection condition,
\begin{enumerate}
\item The decision threshold for exploration is independent of the board state;
\item    With our game parameters, the threshold is $20.42$.
\end{enumerate} 
\end{prop}
To show the robustness of the first result, we prove that it also holds in a somewhat simpler game, a 2-step deterministic game with general reward and uniform cost. The proof can be found in Appendix \ref{apdx:patent}.

Intuitively, the threshold does not depend on whether the player searches for first or subsequent treasure, neither on how much of the protected area has been explored.  This is since the alternative cost of waiting, which is the loss of one round in the game, is constant in all exploration stages. Therefore, it makes sense that the threshold value will stay the same within each stage. 


\subsection{No Protection}
Under the No Protection condition, we consider two scenarios. The first is when the players explore for a first treasure and the second is when one of the players find a treasure and all the players can use the information about the treasure's location, in order to find subsequent treasures in the same mine. 

We start the analysis with the second case, and then calculate backwards the cost threshold in the first case. The challenge in the second case is to compute the cost thresholds and the expected payoffs in equilibrium when these depend on the other players' choices.

The decision to explore around a first treasure yields two types of revenues. The first is the expected payoff from the treasure itself. This revenue decreases with the number of players that explore around this mine, as explained above.

The second type of gain from exploration is the information gain. Whether the player finds a treasure or not, any search reveals information that helps narrow down the search in the next round. For example, after a player finds a first treasure in an unexplored area, both successful and failed subsequent searches increase the probability of finding a treasure in the next round from 0.33 to 0.5.\footnote{One failed subsequent search left 4 options for the next 2 treasures (notice they both have to be linked) so if the next search is one of the 3 hexagons that are not linked to the failed search, the payer has probability of 0.5 to find a treasure.}

The value of this information depends on its distribution among the players, and on their future choices. In addition, the players' choices (the cost thresholds they pick and the hexagons they choose) depend on their expected future payoffs. 

Analyzing all the different scenarios is complicated, and the accurate number is likely not as important as the boundary values.
Therefore, we focus on computing lower and upper bounds to the cost threshold. We describe the result in the main text, and leave the detailed calculation for Appendix~\ref{apdx:nopatent}. 
\begin{prop}
Over an infinite time span, 
\begin{enumerate}
    \item the equilibrium cost threshold in the case of searching for a subsequent treasure is between 21.28 and 25.1,
\\ and
    \item the equilibrium cost threshold in the case of searching for a first treasure is between 16 and 16.5.
\end{enumerate} 
\end{prop}

To summarize, optimal/equilibrium searching cost thresholds by condition are:
\begin{center}
 \begin{tabular}{c|| c c } 
 \hline
  & First treasures & Subsequent treasures  \\ [0.5ex] 
 \hline\hline
 Protection & 20.42 & 20.42 \\ 
 \hline
 No Protection & 16-16.5 & 21.28-25.1  \\
 \hline

\end{tabular}
\end{center}


\subsection{Singleton}
Under the Singleton condition, each player plays in his own hive, and his payoff is independent of the other players' choices. The analysis is the same as in the Protection condition, since, from a theoretical point of view, searching for a first treasure is independent of the other players choices, and searching for subsequent treasure as a singleton player, is the same as the exclusivity search in the Protection condition.


\section{Theoretical Analysis Appendix}

\subsection{Protection}\label{apdx:patent}
We denote the payoff from finding a treasure and obtaining exclusive rights to explore around it in order to find another two treasures by U. 

In order to calculate U, we compute for each exploration stage $t$, the optimal searching strategy, denoted by $C_t$, which is the cost threshold in which the player decides to explore in stage $t$ if and only if the cost he obtains is under this threshold. We also denote $p_t=Pr(c<C_t)$ 

under the Protection condition, where the player has an exclusive right to explore around a treasure, so his strategy is independent on the other players' strategies.

First we denote the value of each round in the game by $x$. $x$ is the opportunity cost of any deviation from optimal strategy in a certain round."
Since $x$ represents the overall gain from playing one more round according to optimal behavior.
 

By definition, the expected payoff in each round of the game equals the probability to search, which is the probability that the cost will be lower than the threshold, multiplied by the mean payoff from searching, which is the expected payoff from treasure, minus the conditional expected cost. 

Hence, we can write $x$ as: $$x(c_1,c_2,...,c_t)=p_t(0.05*U(c_1,c_2,...,c_t)-E(c|c<c_t))$$
The value of $x$ depends on the thresholds values, that also depend on $x$. We extract $x$ after expressing the cost thresholds by $x$ and solve for $x$. 

We calculate the cost thresholds backwards, starting in the last case, when only 1 uncovered hexagon is left. This yields 80 with probability 1. In this case, $c_1$ maximizes the following:
$$v_1=argmax\sum_{n=0}^\infty(1-p_1)^np_1(80-E(c|c<c_1)-(n+1)x)$$
\rmr{are we maximizing over $c_1$? then $v_1$ should actually be $\max$ not $argmax$?}
Where $p_1=\frac{c_1-5}{30}$ is the probability to obtain a cost that is smaller than $c_1$, and $n$ is the number of rounds until this scenario occurs.

Solving this for $c_1$, we obtain: $c_1=5+2\sqrt{15}\sqrt{x}$ and $v_1=75-2\sqrt{15}\sqrt{x}$.

When the player knows that there is a treasure in a specific hexagon with probability 0.5, his threshold value maximizes:
$$v_2=argmax\sum_{n=0}^\infty((1-p_2)^np_2(\frac{1}{2}v_1 + \frac{1}{2} 80-E(c|c<c_2)-(n+1)x)$$

Solving this for $c_2$, we obtain: $c_2=5+2\sqrt{15}\sqrt{x}$ and $v_2=72.5-3\sqrt{15}\sqrt{x}$

In the case of 2 unrevealed hexagons, as in Figure~\ref{fig:expprocces}\textbf{(a)} , which is the same calculation for the case of 3-not-linked hexagons, as in Figure~\ref{fig:expprocces}\textbf{(b)} where the probability to find a treasure is 1 for each, the revenue is $2v_1$. 

Now we proceed to calculate the cost threshold when there are 3 linked unrevealed hexagons, as in Figure \ref{fig:expprocces}\textbf{(c)}. This is the same calculation as for the cases shown in Figure \ref{fig:expprocces}\textbf{(d)}, Figure~\ref{fig:expprocces}\textbf{(e)} and Figure~\ref{fig:expprocces}\textbf{(f)}. In those cases, $$v_3=argmax\sum_{n=0}^\infty((1-p_3)^np_3(80+v_2-E(c|c<c_3)-(n+1)x)$$

Solving this for $c_3$, we obtain: $c_3=5+2\sqrt{15}\sqrt{x}$ and $v_3=147.5-5\sqrt{15}\sqrt{x}$.

The next step is to calculate the cost threshold for the case of 5 unrevealed hexagons (after one unsuccessful try), as in Figure~\ref{fig:expprocces}\textbf{(g)}. In this case, the player chooses a cost threshold that maximizes:
$$v_4=argmax\sum_{n=0}^\infty((1-p_4)^np_4(\frac{1}{2}(80+v_2)+\frac{1}{2}v_3-E(c|c<c_4)-(n+1)x)$$

Solving this for $c_4$, we obtain: $c_4=5+2\sqrt{15}\sqrt{x}$ and $v_4=145-6\sqrt{15}\sqrt{x}$.

The last stage is to calculate the threshold value for the first search, right after the player found a first treasure. In this case the threshold value maximizes:
$$v_5=argmax\sum_{n=0}^\infty((1-p_5)^np_5(\frac{1}{3}(80+v_2)+\frac{2}{3}v_4-E(c|c<c_5)-(n+1)x)$$

Solving this for $c_5$, we obtain: $c_5=5+2\sqrt{15}\sqrt{x}$ and $v_5=142.5-7\sqrt{15}\sqrt{x}$.

Now we are able to calculate the payoff of finding a mine, denoted by $V$, as a function of $x$. As before, we calculate the cost threshold for exploring for the first treasure and this threshold, $C$, maximizes: $$V=argmax(P (0.05(320+v5)-E(c|c<C))$$

Solving for $C$, finding $V$ and solving the equation: $V=x$ we obtain:
$x=3.96=V$ and $C=c1=c2=c3=c4=c5=20.42$

\begin{figure} [!ht]
\centering
\begin{tabular}{cccc}
\includegraphics[width=0.15\textwidth]{2Left.png} 
\label{fig:2Left}&
\includegraphics[width=0.15\textwidth]{3Left.png}
\label{fig:3 left.a}&
\includegraphics[width=0.15\textwidth]{3LeftLink.png} 
\label{fig:3 left.b}&
\includegraphics[width=0.15\textwidth]{4Left.png}
\label{fig:4 left.a}\\
\textbf{(a)}  & \textbf{(b)} & \textbf{(c)} & \textbf{(d)} \\[6pt]
\end{tabular}
\begin{tabular}{cccc}
\includegraphics[width=0.15\textwidth]{4LeftNotSeq.png} 
\label{fig:4 left.b}&
\includegraphics[width=0.15\textwidth]{4LeftNotSeq1.png}
 \label{fig:4 left.c}&
\includegraphics[width=0.15\textwidth]{5Left.png}
 \label{fig:5 left}\\
\textbf{(e)}  & \textbf{(f)} & \textbf{(g)} \\[6pt]
\end{tabular}
\caption{Exploration process of subsequent treasure.}
\label{fig:expprocces}
\end{figure}


\rmr{If I understand correctly, this is a variation of our game where all searches succeed. The first $k-1$ initial treasures (`maps') yield reward 0 but allow one protected slot whose reward in the last subsequent search is $R$. 

\begin{proposition}
    In the simple game with $k=1$ (i.e. no initial treasures), the optimal threshold is $c=R$, and the continuation value is $x=\frac{R^2}{2A}$.
\end{proposition}
Intuitively, as long as the cost is at most $R$ it is worthwhile to take the reward and continue. 
\begin{proof}
    Suppose we play for $T$
 rounds, then one way to write the total gain is $x\cdot T$. 

 Another way is to consider $n$ rounds until the reward is taken, and then $T-n$ rounds with a total gain of $(T-n)x$. Since the next rounds are independent of $n$, another way to write the expected total gain is
 $$R-E[c'|c'<c] + (T-E[n])x.$$
 Therefore
 \begin{align*}
     x &= \frac{1}{T}\left(R-E[c'|c'<c] + (T-E[n])x\right)&\\
     &= \frac{1}{T}\left(R-E[c'|c'<c] -E[n]x\right) +x &\Rightarrow\\
     E[n]x &= R-E[c'|c'<c]&\Rightarrow\\
     x &= \frac{R-E[c'|c'<c]}{E[n]}.
 \end{align*}
 We now use the facts that in our uniform distribution case, 
 \begin{align*}
     &E[n] = \frac{1}{Pr[c'<c]} = \frac{A}{c}, \text{ and} \\
     &E[c'|c'<c] = \frac{c}{2}
 \end{align*}
to get 
$$x=\frac{R-c/2}{A/c} = \frac{1}{A}(Rc-\frac{c^2}{2}).$$
By derivation we get that the optimal threshold is $c^*=R$ and the continuation value is $x=\frac{R^2}{2A}$.
  \end{proof}

\begin{proposition}
   For any treasure game, regardless of rewards, success probabilities and search cost distribution,  the optimal thresholds for all steps are the same. 

   In for the simple case above with $k$ treasures per batch, we get that the optimal threshold is $c=R/k$ and the continuation value is $R^2/k^2A$.
\end{proposition}
\begin{proof}
For the game with $k$ initial treasure, we can similarly write the total gain once as $Tx$ and once as 
$$R-\sum_{j=1}{k}E[c'|c'<c_j]+ (T-\sum_{j=1}^kE[n_j])x,$$
where $n_j$ are the number of rounds until we find the $j$'th treasure.

Note that as before, $E[n_j]=\frac{A}{c_j}$ and $E[c'|c'<c_j] = c_j/2$ and thus all the $j$ terms a completely symmetric. Therefore, w.l.o.g. we that there is a single optimal threshold $c$ and all $c_j=c$.

\medskip
It is not hard to see (but still requires a proof!) that the above argument also generalizes if we add arbitrary rewards along the way (then $R$ is the sum of all rewards),  arbitrary success probabilities for each  search, and arbitrary cost distribution as long as it is same distribution in all rounds.

\medskip
We get that the continuation value is 
$$x=  \frac{R-k\cdot E[c'|c'<c]}{k\cdot E[n]} = \frac{R/k- E[c'|c'<c]}{E[n]}.$$

Moreover, for uniform threshold $c$, we get
$$x = \frac{R/k - c/2}{A/c} = \frac{1}{A}(Rc/k-c^2/2).$$
Derivation provides us with the optimal threshold $c^*=R/k$ and the continuation value
$x=\frac{R^2}{2k^2}$.
\end{proof}

The reason we need to assume $T$ tends to infinity is that we neglect the probability that waiting will lead to ending the game before the current batch of treasures is exploited. For large $T$, this probability is negligible in all but the last few rounds.
} 
This attribute, where all thresholds are equal in all the game stages,  holds also in more general games. Assume for instance a two-stage game of treasure seeker, where in the first stage the player needs to find a treasure map and after he finds the map he can search for the treasure itself. Searching the map and the treasure is deterministic, i.e., when the player decides to search he finds them with probability 1. Finding a treasure leads to the reward R, and finding a map leads no direct reward, except the opportunity to find a treasure in the next round. The game has infinite rounds and infinite treasures and map-treasures. Search is costly, and the cost is uniformly distributed over [0,A]. 

As before, we denote the mean revenue from one round in the game with $x$, $c_1$ is the cost threshold to find a treasure-map, and $c_2$ is the cost threshold to find a treasure, after a map was found. We obtain $p_1=\frac{c1}{A}$ and $p_2=\frac{c2}{A}$ be the probability to search on stage 1 and on stage 2, respectively,

Hence, $v=argmax\sum_{n=0}^\infty(1-p_2)^np_2(R-E(c|c<c_2)-(n+1)x)$ is the value of finding a treasure-map, and we obtain $c_2=\sqrt{2Ax}$ and $v=R-\sqrt{2Ax}$. Therefore, $c_1=v=R-\sqrt{2Ax}$ and $x$ solves: $x=p_1(v-E(c|c<c_1)$ i.e. $x=\frac{R^2}{8A}$. As a result we obtain $c_1=c_2=\frac{R}{2}$.

We leave the formal proof of this nice result to more theoretic oriented future studies.


 
\subsection{No Protection}\label{apdx:nopatent}
\rmr{
\paragraph{A simple competition game}
In the simplest sequential competition, there is a initial search that succeeds w.p. $\alpha$, get a reward of $R_0$ and takes $n$ turns. 

Then, there is a single subsequent treasure than can be found with probability $\beta$, if searched. The search cost is the same as above (say, uniform in $[0,A]$).

It will be more convenient to write the strategy of the player as the search probability ($p_i$ in initial search, and  $p$ in sequential search), and the expected cost as $pA/2$. The strategy of the other player is denoted by $q$.

There are two agents. In the sequential search phase:
\begin{itemize}
    \item If both agents find the treasure, they each get $R_2$;
    \item If only one finds the treasure, she gets $R_1$;
    \item If no one finds, the treasure remains for the next turn. 
\end{itemize}

Again we denote the continuation value by $x$. If there are $T$ turns, the total value per player is $xT$. The search for the treasure takes $m$ turns, which is a random variable depending on both strategies $p$ and $q$.

Another way to write the total value (as before), is by summing the rewards and costs during initial search ($V$) and during sequential search ($U$),  and  then the remaining turns, so that:
$$E[V] + E[U] +(T-E[m]-E[n])x = Tx,$$
which means
$$x = \frac{E[V]+E[U]}{E[m]+E[n]}.$$
Now we know that:
\begin{itemize}
    \item $n$ depends only on $p_i,\alpha$.
    \item $m$ is a geometric variable whose expectation is $\frac{1}{1-(1-p\beta)(1-q\beta)}= \frac{1}{p\beta+q\beta-pq\beta^2}$;
    \item The expectation of $U$ does not depend on the round in which the item is found. There are four outcomes:
    \begin{description}
        \item[Our player searches] w.p. $p$. Expected cost is $Ap/2$. The utility depends on:
        \begin{description}
            \item[Both players find] w.p. $q\beta^2$, reward is $R_2$;
            \item[Only our player find] w.p. $\beta(1-q\beta)$, reward is $R_1$;
            \item[Other player finds] w.p. $\beta q(1-\beta)$
            \item[No player finds] reward is 0.
        \end{description}
        So the total utility is $(q\beta^2)R_2+\beta(1-q\beta)R_1$.
        \item[Our player does not search] w.p. $1-p$. Then w.p. of $q\beta$ the treasure is still found.
        \end{description}
    %     Utility for player is $R_2-Ap/2$;
    %     \item[Our player searches] w.p. $p(1-q)$. Utility is $R_1-Ap/2$;
    %     \item[Other player searches] w.p. $(1-p)q$. Utility is 0;
    %     \item[No player searches] w.p. $(1-p)(1-q)$. The treasure waits.
    % \end{description}
    \end{itemize}
    In total, in every turn where the treasure is not yet found, there is a probability of $1-(1-p\beta)(1-q\beta)=p\beta+q\beta-pq\beta^2$ that the game ends. At that turn, our player gets
    $$E[U]=\frac{p R(q)-Ap^2/2}{p\beta+q\beta-pq\beta^2},$$
    where $R(q):=q\beta^2R_2+\beta(1-q\beta)R_1$.
Thus 
% $$E[U]= \frac{pq(R_2-Ap/2) + p(1-q)(R_1-Ap/2)}{pq+p(1-q)+q(1-p)}=\frac{pq(R_2-Ap/2) + p(1-q)(R_1-Ap/2)}{p+q-pq}.$$
%     We also have that $E[m]=\frac{1}{p+q-pq}$, so 
    \begin{align*}
        x&= \frac{E[V]+E[U]}{E[n]+E[m]} = \frac{E[V]+\frac{p R(q)-Ap^2/2}{p\beta+q\beta-pq\beta^2}}{E[n]+\frac{1}{p\beta+q\beta-pq\beta^2}}\\
        &=\frac{\frac{E[V](p\beta+q\beta-pq\beta^2)+p R(q)-Ap^2/2}{p\beta+q\beta-pq\beta^2}}{\frac{1+E[n](p\beta+q\beta-pq\beta^2)}{p+q-pq}}\\
&=\frac{E[V](p\beta+q\beta-pq\beta^2)+p R(q)-Ap^2/2}{1+E[n](p\beta+q\beta-pq\beta^2)}\\
    \end{align*}
    We will make a first simplifying assumption that $E[n]\gg 1$, and thus:
    \begin{align*}
        x&\approx \frac{E[V](p\beta+q\beta-pq\beta^2)+p R(q)-Ap^2/2}{E[n](p\beta+q\beta-pq\beta^2)}\\
        &=\frac{E[V]}{E[n]} + \frac{p R(q)-Ap^2/2}{E[n](p\beta+q\beta-pq\beta^2)}\\
    \end{align*}
    
The first part is constant w.r.t. $p$, as is $E[n]$. 
    Thus to find the optimal $p$, we should derive:
    \begin{align*}
        0 &= \frac{\partial \frac{p R(q)-Ap^2/2}{(p\beta+q\beta-pq\beta^2)}}{\partial p} = \frac{( R(q)-Ap)(p\beta+q\beta-pq\beta^2)-(p R(q)-Ap^2/2)\beta(1-q\beta)}{p\beta+q\beta-pq\beta^2)^2}&\Rightarrow\\
        0&=( R(q)-Ap)(p\beta+q\beta-pq\beta^2)-(p R(q)-Ap^2/2)\beta(1-q\beta) \\
        &=(R(q)-Ap)p\beta(1-q\beta)+q\beta(R(q)-Ap) - (R(q)-Ap/2)p\beta(1-q\beta)\\
        &=q(R(q)-Ap)-p(1-q\beta)Ap/2\\
        &=qR(q) - Apq -Ap^2/2 +Ap^2q\beta/2\\
        &=qR(q) - Apq - p^2A(1-q\beta)/2.
    \end{align*}
In a symmetric equilibrium $p^*=q^*$, so we get that $p^*$ is the unique value (if exists) for which 
$$A\beta p^2 - (3A+2(R_1-R_2))p + 2\beta R_1=0.$$
    

    
E.g. for $R_1=A=\beta=1, R_2=0$ we would get $p^*=q^*=\frac{5-\sqrt{17}}{2}$.

\medskip
We can now move on to compute the optimal strategy in the initial phase, treating $E[U]$ and $E[m]$ as constants. 
For initial search threshold $d$, the success probability is $\alpha d/A$ and 
$$ E[V]=R_0-E[\text{number of searches until success}]E[\text{cost of each search}]=\frac{1}{\alpha}\frac{d}{2} =\frac{d}{2\alpha}, $$
and $E[n]=\frac{A}{\alpha d}$.

Thus 
\begin{align*}
x &= \frac{E[U]+R_0 - \frac{d}{2\alpha}}{E[m] +\frac{A}{\alpha d} } = \frac{\frac{(E[U]+R_0)2\alpha-d}{2\alpha}}{\frac{E[m]\alpha d+A}{\alpha d}}\\
&=\frac{((E[U]+R_0)2\alpha-d)\alpha d}{2A\alpha(E[m]\alpha d+A)}\\
&\approx \frac{2(E[U]+R_0)\alpha^2 d -\alpha d^2}{2A^2\alpha} = \frac{2(E[U]+R_0)A\alpha d - d^2}{2A^2}, 
\end{align*}
where the approximation is for $\alpha \ll 1$,
so $d^*=(E[U]+R_0)\alpha$.

}

First we calculate the lower and upper bound for the cost threshold in exploration for subsequent treasure.\\
\textbf{Lower bound}:
We obtain the lower bound of the cost threshold (under the assumption of a symmetric solution) by ignoring the information gained from exploration. The players take into account only the expected payoff from finding a treasure. Each player chooses a cost threshold, $c_1$ ,that implies that his probability to search is: $p_1=\frac{c_1-5}{30}$. The following equation describes the condition for the Nash equilibrium in mixed strategies. With probability 1/3, the player finds the second treasure. His reward depends on the number of players that find the treasure jointly with him. Each of the three other players search with probability $p_1$, and choose the same hexagon with probability 1/6. Finally, the player is not willing to pay more than the cost $c_1$ that solves: 
$$\frac{1}{3}(\binom{3}{3}(1-p_1)^0 p_1^3 ( \binom{3}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^3 (80) + $$$$
       \binom{3}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^2 (16) + 
       \binom{3}{2}(\frac{1}{6})^2\cdot(\frac{5}{6})^1 (4)) + 
    $$$$\binom{3}{2}(1 - p_1)^1 p_1^2 (\binom{2}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^2 (80) + 
       \binom{2}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^1 (16) + 
       \binom{2}{2}(\frac{1}{6})^2\cdot(\frac{2}{6})^0 (4)) + 
$$$$\binom{3}{1} (1 - p_1)^2 p_1^1$$$$ (\binom{1}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^1 (80) + 
       (\frac{1}{6})^1\cdot(\frac{5}{6})^0 (16)) + (1 - 
       p_1)^3 p_1^0 (80))-c_1=0$$ 

Solving this equation we obtain $c1=21.28$ Therefore, this is a lower bound for the cost threshold. Following this bound as a cost threshold, leads the players to search whenever their cost is less than or equals 20, so their probability to explore is 4/7. 

\textbf{Upper bound}:
We use the exploration probability that we obtained in the lower bound calculation, and compute the information gained from exploration. Since we use a minimum cost threshold, we get minimum probability of exploration, so the probability that the searching process ends after only one round is minimized, and the gain from information is maximized (since information is valuable only in future rounds). 

We are looking for the cost threshold, which is the cost that makes the player indifferent between exploring and skipping. If the player decides to explore, with probability 2/3 he finds nothing, and gets the information gained from exploration only in two cases:\\
\begin{itemize}
    \item No one else found a treasure. In this case his information gain increases the probability of exploring for the next treasure from 1/3 to 1/2. The probability of this scenario is:$\binom{3}{1}(\frac{3}{7})^2\frac{4}{7}\cdot\frac{2}{3}+\binom{3}{2}\frac{3}{7}(\frac{4}{7})^2\cdot(\frac{2}{3})^2+\binom{3}{3}(\frac{4}{7})^3(\frac{2}{3})^3=0.45$. An upper bound for the payoff gain in this scenario is generated by the Protection case, when a player searches with no competition, and is equals to $v_5-v_4=10.21$. 
    \item Other players found only one treasure. In this case, the player gains only if his first search was linked to the hexagon that was found. This scenario occurs with probability 1/3. The information gained in this case is that the next treasure can be found with probability 1 instead of a probability 1/2. 
    In any other case, there is no gain from exploration, since the information about the location of the third hexagon is available to all players, whether they search for it or not. In order to calculate the probability for this scenario, we first calculate the probability to find two treasures which is equals to $(\frac{4}{7})^3\cdot\frac{1}{6}+3\cdot(\frac{3}{7})^1(\frac{4}{7})^2\cdot2\cdot\frac{1}{6}=0.054$. Therefore, the probability for this scenario is: $1-0.054-0.45=0.496$. We obtain that an upper bound for the player's payoff in this case is the payoff he obtains when he explores with no competition, as in the Protection case. This upper bound equals $v_2-v_1=10.21$ (The gain from searching the third hexagon with probability 1 instead of searching it with probability 1/2)  \\
\end{itemize} 

With probability 1/3 the player finds a treasure. The information gained is the same as when the other players do not find it themselves. Otherwise, the player can get the information gain anyway. 

The probability that other players will not find this specific treasure is: $(\binom{3}{0}(\frac{3}{7})^3(\frac{5}{6})^0+\binom{3}{1}(\frac{3}{7})^2(\frac{4}{7})^1(\frac{5}{6})^1+\binom{3}{2}(\frac{3}{7})^1(\frac{4}{7})^2(\frac{5}{6})^2+\binom{3}{3}(\frac{3}{7})^0(\frac{4}{7})^3(\frac{5}{6})^3)=0.74$\\
Therefore, 0.74 is the probability that no other player finds this hexagon.

With probability $1-(\binom{3}{1}(\frac{3}{7})^2(\frac{4}{7})^1\frac{5}{6}+\binom{3}{2}(\frac{3}{7})^1(\frac{4}{7})^2(\frac{5}{6})^2+\binom{3}{3}(\frac{4}{7})^3(\frac{5}{6})^3)=0.338$ the third treasure is not found is conditional on the fact that at least one player found the second treasure. In this case the searching process continues to the next round. 

In the next round the player obtains the payoff from finding the third treasure with probability 1/2, and obtains the information gain if no player finds the third treasure. The probability for gaining from this information is: $\binom{3}{1}(\frac{3}{7})^2(\frac{4}{7})^1(\frac{1}{2})^2+\binom{3}{2}(\frac{3}{7})^1(\frac{4}{7})^2(\frac{1}{2})^3+\binom{3}{3}(\frac{4}{7})^3(\frac{1}{2})^3=0.154$ and an upper bound for this gain is $v_1-v_2=10.213$ which is the gain from searching with probability 1 over searching with probability 1/2 under the  no- competition regime (the Protection condition) 

We denote by $c_2$ the threshold cost for searching for the third treasure, and $p_2 = \frac{c_2-5}{30}$ the probability of searching for it. The probability to explore in this round in Nash Equilibrium is obtained by solving the following equation for $c_2$: $$\frac{1}{2}(\binom{3}{3}p_2^3(\binom{3}{0}(\frac{1}{2})^3\cdot80+\binom{3}{1}(\frac{1}{2})^1(\frac{1}{2})^2\cdot16+\binom{3}{2}(\frac{1}{2})^2\frac{1}{2}\cdot4)+$$$$\binom{3}{2}(1-p_2)^1\cdot p_2^2(\binom{2}{0}(\frac{1}{2})^2\cdot80+\binom{2}{1}(\frac{1}{2})^1(\frac{1}{2})^1\cdot16+\binom{2}{2}(\frac{1}{2})^2\cdot4)+$$$$\binom{3}{1}(1-p)^2p_2(\binom{1}{0}(\frac{1}{2})^1\cdot80+\binom{1}{1}(\frac{1}{2})^1\cdot16)+(1-p_2)^3\cdot80)-c_2=0$$. Solving this we obtain: $c_2=20.263$, and $p_2 = \frac{1}{2}$.
Hence, substitute the previous result in $$\frac{1}{2}(\binom{3}{3}p_2^3(\binom{3}{0}(\frac{1}{2})^3\cdot80+\binom{3}{1}(\frac{1}{2})^1(\frac{1}{2})^2\cdot16+\binom{3}{2}(\frac{1}{2})^2\frac{1}{2}\cdot4)$$$$+\binom{3}{2}(1-p_2)^1\cdotp^2(\binom{2}{0}(\frac{1}{2})^2\cdot80+\binom{2}{1}(\frac{1}{2})^1(\frac{1}{2})^1\cdot16+\binom{2}{2}(\frac{1}{2})^2\cdot4)$$$$+\binom{3}{1}(1-p)^2p(\binom{1}{0}(\frac{1}{2})^1\cdot80+\binom{1}{1}(\frac{1}{2})^1\cdot16)+(1-p_2)^3\cdot80)-\frac{c_2+5}{2}$$ we obtain that the upper bound for the payoffs from finding the third treasure is 7.63.

Overall, an upper bound for the payoff from the information gain when searching around a first treasure is: $$\frac{2}{3}(0.452\cdot10.2128 + 0.496\cdot\frac{1}{3}\cdot10.2128) + 
 \frac{1}{3}(0.74\cdot0.338\cdot(7.63 + 0.154\cdot10.2128))=4.97$$
 
 We obtain the following equation for $c_3$: $$\frac{1}{3}(\binom{3}{3}(1-p_3)^0 p_3^3 ( \binom{3}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^3 (80) + 
       \binom{3}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^2 (16) + 
       \binom{3}{2}(\frac{1}{6})^2\cdot(\frac{5}{6})^1 (4)) + 
    $$$$\binom{3}{2}(1 - p_3)^1 p_3^2 (\binom{2}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^2 (80) + 
       \binom{2}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^1 (16) + 
       \binom{2}{2}(\frac{1}{6})^2\cdot(\frac{2}{6})^0 (4)) + 
$$$$\binom{3}{1} (1 - p_3)^2 p_3^1 (\binom{1}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^1 (80) + 
       (\frac{1}{6})^1\cdot(\frac{5}{6})^0 (16)) + (1 - 
       p_3)^3 p_3^0 (80))+4.97-c_3=0$$
When $p_3=\frac{c_3-5}{30}$. Solving for $c_3$ we obtain $c_3=25.1$. \\
An upper bound for the total payoff from searching around a first treasure is: $$\frac{1}{3}(\binom{3}{3}(1-p_3)^0 p_3^3 ( \binom{3}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^3 (80) + 
       \binom{3}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^2 (16) + 
       \binom{3}{2}(\frac{1}{6})^2\cdot(\frac{5}{6})^1 (4)) + 
    $$$$\binom{3}{2}(1 - p_3)^1 p_3^2 (\binom{2}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^2 (80) + 
       \binom{2}{1}(\frac{1}{6})^1\cdot(\frac{5}{6})^1 (16) + 
       \binom{2}{2}(\frac{1}{6})^2\cdot(\frac{2}{6})^0 (4)) + 
$$$$\binom{3}{1} (1 - p_3)^2 p_3^1 (\binom{1}{0}(\frac{1}{6})^0\cdot(\frac{5}{6})^1 (80) + 
       (\frac{1}{6})^1\cdot(\frac{5}{6})^0 (16)) + (1 - 
       p_3)^3 p_3^0 (80))+4.97-\frac{c_3+5}{2}=10.07$$
Hence we obtain that the upper bound for the threshold is $c_3=25.1$, and the upper bound for the total payoff from exploration around a first treasure is 10.07. 


Therefore, in the case of exploration for subsequent treasures, the expected payoff is not higher than $0.05(320+10.07)-c$, where $c$ is the cost threshold in the case of first treasures. Hence, an upper bound to the cost threshold in this case is $c=16.5$. 

A lower bound for this threshold is obtained when there is no gain from subsequent treasure, thus it equals the $c$ that solves: $0.05(320)-c=0$. Hence the lower bound for cost threshold is $c=16$