
% \documentclass[conference]{IEEEtran}
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage[utf8]{inputenc}
\usepackage[nosort]{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage[T1]{fontenc}
\usepackage{textgreek}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
% \usepackage[dvipsnames]{xcolor}
\usepackage{adjustbox}
% \usepackage{algorithmic}
\usepackage{algpseudocode}

\usepackage{geometry}

\geometry{a4paper, margin=1in}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{UniCP: A Unified Caching and Pruning Framework for Efficient Video Generation}

% \author{Anonymous ICME submission}

\author{
Wenzhang Sun\textsuperscript{1*}, 
Qirui Hou\textsuperscript{2*}, 
Donglin Di\textsuperscript{1},
Jiahui Yang\textsuperscript{2},
Yongjia Ma\textsuperscript{3},\\
Jianxun Cui\textsuperscript{2}
\\
\textsuperscript{1}Li Auto, 
\textsuperscript{2}Harbin Institute of Technology, 
\\
% {\tt\small 23s132082@stu.hit.edu.cn, sunwenzhang@lixiang.com, liangzhuding@hit.edu.cn}
}


\maketitle
  
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Equal contribution.}

\begin{abstract}
% The Diffusion Transformer (DiT) excels in video generation but faces significant computational challenges due to the quadratic complexity of attention. 
% Existing methods cache attention blocks based on the U-shaped error distribution in diffusion processes, but fail to handle sudden error spikes and large discrepancies effectively. 
% Diffusion Transformer (DiT) excels in video generation but faces significant computational challenges due to the quadratic complexity of attention, particularly in spatial and temporal dimensions. Notably, attention differences between adjacent diffusion steps form a U-shaped pattern, which current methods attempt to optimize by caching attention blocks, yet they still struggle with sudden error spikes and large discrepancies.
% To address this, we propose UniCP—a unified framework of caching and pruning for efficient video generation. 
% UniCP tackles these issues across both temporal and spatial dimensions, 
% (1) Error-Aware Dynamic Cache Window (EDCW): dynamically adjusts cache window sizes for different blocks at various timesteps to adapt to abrupt error changes. 
% (2) PCA-based Slicing (PCAS) and Dynamic Weight Shift (DWS): PCAS prunes redundant attention components, while DWS optimizes caching operations for modules with significant disparities. 
% By dynamically adjusting cache windows and pruning redundant components, UniCP enhances computational efficiency and maintains detail fidelity in video generation.
% Experimental results demonstrate that UniCP outperforms existing methods, delivering superior performance and efficiency.

Diffusion Transformers (DiT) excel in video generation but encounter significant computational challenges due to the quadratic complexity of attention. Notably, attention differences between adjacent diffusion steps follow a U-shaped pattern. Current methods leverage this property by caching attention blocks; however, they still struggle with sudden error spikes and large discrepancies. To address these issues, we propose UniCP—a unified caching and pruning framework for efficient video generation. UniCP optimizes both temporal and spatial dimensions through:
Error-Aware Dynamic Cache Window (EDCW): Dynamically adjusts cache window sizes for different blocks at various timesteps to adapt to abrupt error changes.
PCA-based Slicing (PCAS) and Dynamic Weight Shift (DWS): PCAS prunes redundant attention components, while DWS integrates caching and pruning by enabling dynamic switching between pruned and cached outputs. By adjusting cache windows and pruning redundant components, UniCP enhances computational efficiency and maintains video detail fidelity. Experimental results show that UniCP outperforms existing methods, delivering superior performance and efficiency.


\end{abstract}




\begin{IEEEkeywords}
DiT, Caching, Pruning, Attention Mechanism, Video Generation
\end{IEEEkeywords}

\input{section/1-intro}
\input{section/2-relatedwork}
\input{section/3-method}
\input{section/4-experiment}
\input{section/5-conclusion}

\bibliographystyle{IEEEbib}
\bibliography{main}

\end{document}
