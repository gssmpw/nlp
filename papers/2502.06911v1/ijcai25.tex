%%%% ijcai25.tex

%\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}


% Use the postscript times font!
% Use the postscript times font!
\usepackage{times}
\usepackage{soul,xcolor}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{bbding}
\usepackage{graphicx}

\usepackage{mathrsfs}
% \usepackage{bookmark}
\usepackage{amsmath}
\let\Bbbk\relax
\usepackage{tabularx}
\usepackage{lineno}
\usepackage{epsfig}
\usepackage{chngpage}
\usepackage{float}

\usepackage{graphicx}
\usepackage{array}
\usepackage{diagbox}
\usepackage{epstopdf}
\usepackage{amsfonts} 
\usepackage{algpseudocode}
\usepackage{threeparttable}
\usepackage{dsfont}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{url}
\usepackage{footnote}
\usepackage{ifpdf}
\usepackage[colorlinks,linkcolor=blue,bookmarks=true]{hyperref}
%\newcommand{\hj}[1]{\textcolor{blue}{[HJ: #1]}}
%\newcommand{\xx}[1]{\textcolor{blue}{[SX: #1]}}
%\usepackage{marvosym}

\makesavenoteenv{table}
% Comment out this line in the camera-ready submission
%\linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
%\newtheorem{example}{Example}
%newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

\title{Foundation Models for Anomaly Detection: Vision and Challenges}


% Single author syntax


% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)

\author{
	Jing Ren$^1$,
	Tao Tang$^2$,
	Hong Jia$^{3}$,
	Haytham Fayek$^{1}$,
	Xiaodong Li$^{1}$,
	Suyu Ma$^{4}$,
	Xiwei Xu$^{4}$, \And \\
	Feng Xia$^1$%\textsuperscript{(\Letter)}\\
	\affiliations
	$^1$RMIT University, Australia\\
	$^2$University of South Australia, Australia\\
	$^3$University of Melbourne, Australia\\
	$^4$CSIRO's Data61, Australia\\
	\emails
	\{jing.ren, tao.tang\}@ieee.org, hong.jia@unimelb.edu.au, haytham.fayek@ieee.org, xiaodong.li@rmit.edu.au, \{suyu.ma, xiwei.xu\}@data61.csiro.au, f.xia@ieee.org
}
% \fi

\begin{document}
	
	\maketitle
	
	\begin{abstract}

As data continues to grow in volume and complexity across domains such as finance, manufacturing, and healthcare, effective anomaly detection is essential for identifying irregular patterns that may signal critical issues. Recently, foundation models (FMs) have emerged as a powerful tool for advancing anomaly detection. They have demonstrated unprecedented capabilities in enhancing anomaly identification, generating detailed data descriptions, and providing visual explanations. This survey presents the first comprehensive review of recent advancements in FM-based anomaly detection. We propose a novel taxonomy that classifies FMs into three categories based on their roles in anomaly detection tasks, i.e., as encoders, detectors, or interpreters. We provide a systematic analysis of state-of-the-art methods and discuss key challenges in leveraging FMs for improved anomaly detection. We also outline future research directions in this rapidly evolving field.

	\end{abstract}
	
	\section{Introduction}
	% Anomaly detection (a.k.a. outlier detection), through the lens of data analysis, is the process to identify patterns, events, or observations that deviate significantly from the norm or expected behavior within a dataset~\cite{ren2023graph}. This task is commonly existing in various disciplines such as finance~\cite{park2024enhancing}, industry~\cite{gu2024anomalygpt}, and healthcare~\cite{moor2023foundation}. Traditionally, anomalies are detected using classical distance-based methods such as k-nearest neighbors or clustering algorithms. More recently, various deep learning models, including one-class classification, self-supervised learning, and generative adversarial networks, have revolutionized this field and proved extremely successful in detecting or even predicting anomalies from normal data\hj{real-world data?}, making them the primary approaches of anomaly detection in a wide range of fields.
	
	Anomaly detection, also known as outlier detection, is the process of identifying patterns or events in data that significantly deviate from expected behavior~\cite{chandola2009anomaly}. %TODO
	This process is vital across various fields, including finance~\cite{park2024enhancing}, manufacturing~\cite{gu2024anomalygpt}, and healthcare~\cite{moor2023foundation}. Traditionally, classical methods like $k$-nearest neighbors and clustering algorithms have been employed for this purpose. However, recent advancements in machine learning, such as deep learning, one-class classification, self-supervised learning, and generative adversarial networks, have revolutionized this field. These modern techniques have proved extremely successful in detecting or even predicting anomalies from normal data, making them the primary approaches of anomaly analysis in a wide range of applications.
	
	% In recent years, building artificial intelligence (AI) systems based on a general class of models, which is termed as FMs~\cite{bommasani2021opportunities}, has been an emerging paradigm\hj{not finished?}. As the latest generation of AI models, FMs are trained on massive, diverse datasets that can be adapted to numerous downstream tasks of interest like image captioning and visual question answering; representative models include GPT-4~\cite{achiam2023gpt}, Gemini~\cite{team2023gemini} and LLaMA~\cite{touvron2023llama}. Their ability to learn rich, high-level representations of data, combined with transfer learning, makes them appropriate for anomaly detection tasks especially where anomalous samples are scarce and diverse\hj{why?????? unclear; motivation is very weak.}. The versatility of such kind of models marks a significant shift from earlier AI models, which were built to tackle specific tasks one at a time.
	
	Foundation models (FMs) are a class of large-scale, pre-trained machine learning models that are trained on massive, diverse datasets using self-supervised or unsupervised learning~\cite{bommasani2021opportunities}. In recent years, they have shown impressive performance in learning a wide range of representations and tasks, such as translation, summarization, and question answering, with notable examples including include GPT-4~\cite{achiam2023gpt}, Gemini~\cite{team2023gemini} and CLIP~\cite{radford2021learning}. % TODO Re-sentence, definition, citation, examples. 
	Trained on extensive and diverse datasets, FMs comprise a large number of parameters that enable them to capture intricate patterns and subtle nuances within data. This ability to model such complexity makes them particularly well-suited for anomaly detection, where identifying deviations from normal behavior is essential.
	
	% \hj{link is weak}Driven by improvements in computer hardware, advances in model architectures, and availability of much more training data, FMs can bring several advantages to anomaly detection task. Firstly,
	% these models enable in-context learning, through which the language model could carry out entirely new anomaly detection tasks by merely providing it with a natural language description of the task~\cite{bakumenko2024advancing}\hj{unclear..}. Secondly, many latest FMs can integrate multiple data modalities~\cite{lu2022unified,aghajanyan2022cm3}, such as text, images, and time-series data, allowing for more complex anomaly detection where diverse types of data are involved. For example, the recent Gato model is a representative of multimodal models, which can complete a series of tasks, like chatting, image captioning, and robotic control~\cite{moor2023foundation}. Therefore, Gato is acknowledged as a generalist agent. Additionally, applying FMs to anomaly detection can indeed improve explainability, which is critical for sensitive applications like healthcare, finance, and cybersecurity.
	
	% \textbf{FMs assisted anomaly detection.} 
	FMs offer several advantages for anomaly detection, driven by advancements in computational hardware, model architectures, and access to large-scale training data. 
	A key advantage is their capacity for in-context learning, which enables seamless adaptation to entirely new anomaly detection tasks using only natural language instructions~\cite{bakumenko2024advancing}. 
	This eliminates the need for extensive task-specific training for real-world applications, enabling a more flexible and efficient approach. Additionally, many modern FMs integrate multiple data modalities~\cite{lu2022unified}, such as text, images, and time-series data, which is crucial for detecting anomalies in complex scenarios involving diverse data types. 
	For instance, multimodal models such as Gato~\cite{DBLP:journals/tmlr/ReedZPCNBGSKSEBREHCHVBF22}, can perform tasks ranging from image captioning to robotic control, exemplifying the potential of such models as generalist agents. 
	Furthermore, the application of FMs in anomaly detection can enhance explainability, a critical requirement in high-stakes domains such as healthcare, finance, and cybersecurity, where understanding the rationale behind detected anomalies is critical.
	
	
	% \textbf{FMs assist anomaly detection.} With the assistance of FMs, there has been a notable shift in the way we cope with
	% anomaly detection tasks, particularly those text-based question answering systems. As shown in Figure~\ref{fig:framework001}, FMs can be assisted in the three key steps of the anomaly detection process in different downstream tasks. Integrating FMs with traditional
	% deep learning (DL) models can be mutually beneficial and improve the process of anomaly detection task from different perspectives. Firstly, these models enable in-context learning, through which the language model could carry out entirely new anomaly detection tasks by merely providing it with a natural language description of the task without further fine-tuning~\cite{jeong2023winclip}. Secondly, many latest FMs can integrate multiple data modalities, such as text, images, and time-series data, allowing for more complex anomaly detection where diverse types of data are involved~\cite{zanella2024harnessing}. Additionally, applying FMs to anomaly detection can indeed improve explainability~\cite{zhang2024holmes,li2023myriad}, which is critical for sensitive applications like healthcare, finance, and cybersecurity.
	% For example, to cope with the unbalanced dataset, jeong et al.~\cite{jeong2023winclip} realize language-guided zero-shot anomaly detection after being pre-trained on large-scale dataset. Therefore, foundation model will not be influenced by the imbalance of source dataset. In addition, \cite{zanella2024harnessing} uses large language models to detect video anomalies exclusively from a scene description without further training. Benefiting from the question-answering capacity of FMs, \cite{guan2024dabl} designs a prompt learner to provide explanations of the image information in human-understandable language with the help of FM.
	
	
	%FMs are transforming anomaly detection by enhancing its efficiency and versatility across various tasks. By integrating FMs with traditional deep learning (DL) models, the process benefits from improved performance and expanded capabilities. Firstly, FMs enable in-context learning, allowing them to perform entirely new anomaly detection tasks based on natural language task descriptions without requiring additional fine-tuning~\cite{jeong2023winclip}.  For instance, \cite{zanella2024harnessing} employed large language models to identify video anomalies based solely on scene descriptions, bypassing the need for further training. Secondly, their ability to handle multiple data modalities—such as text, images, and time-series data—enables more comprehensive anomaly detection in complex scenarios~\cite{zanella2024harnessing}. In~\cite{jeong2023winclip}, language-guided zero-shot anomaly detection using pre-trained FMs could effectively extract and aggregate image-level features aligned with text. Moreover, FMs enhance explainability, a critical factor in sensitive domains like healthcare, finance, and cybersecurity~\cite{zhang2024holmes,li2023myriad}. Specifically, \cite{guan2024dabl} utilized the question-answering capabilities of FMs to design a prompt learner that generates human-readable explanations of image data. These examples highlight the significant potential of FMs to advance anomaly detection across a wide range of applications.
	
	% \textbf{Motivations.} 
	% FMs have been increasingly applied in anomaly detection tasks, there is therefore a growing need for a systematic review of this rapidly developing research direction. Despite that~\cite{su2024large} has reviewed the application of large language models (LLMs) in forecasting and anomaly detection, this survey lacks a taxonomy specifically focused on how FMs are applied to anomaly detection tasks. Another survey with similar topic \cite{xu2024large} focuses on the problem of anomaly and out of distribution detection with LLMs, but this review has limitations in other FMs that can take in and output other data modalities. In this survey, we focus on methodologies using FMs to assist in the process of anomaly detection. To achieve a better systematic overview, we categorize the models according to the role (i.e., encoder, detector, and interpreter) played by FMs throughout the entire detection process. 
	

	% \textbf{Motivations.} 
	FMs are increasingly being applied to anomaly detection tasks. However, systematic reviews that thoroughly examine and depict this field are still limited. While some works have explored the use of LLMs for anomaly detection and have made initial attempts to formalize the research landscape, few provide a comprehensive summary of current progress or address the key challenges in this area. For instance, \cite{su2024large} reviews the application of LLMs in forecasting and anomaly detection but does not provide a taxonomy specifically tailored to show how FMs are applied to anomaly detection tasks. Similarly, \cite{xu2024large} focuses on anomaly and out-of-distribution detection with LLMs but overlooks other FMs capable of processing diverse data modalities. This highlights the need for a more systematic and inclusive review. In this survey, we focus on methodologies that leverage FMs for anomaly detection to provide a clearer and more structured perspective by categorizing the models based on the roles FMs play in the detection process—specifically as encoders, detectors, or interpreters. This framework offers a comprehensive overview of the field, presents key insights and advancements in the field, and identifies potential directions for future research. %TODO
	
	% Prior surveys have explored the use of LLMs for anomaly detection.
	% For example, \cite{su2024large} reviews the application of LLMs in forecasting and anomaly detection, defining a taxonomy specifically tailored to LLMs applied to anomaly detection tasks. 
	% \cite{xu2024large} surveys the field with a focus on anomaly and out-of-distribution detection with LLMs.
	% FMs, including but not limited to LLMs, are increasingly being applied to anomaly detection tasks.
	% To the best of our knowledge, there are no systematic reviews of FMs that thoroughly examine and organize this field.
	% In this survey, we provide a comprehensive summary of current progress and address the key challenges in this area % TODO Haytham
	
	
	
	Our main contributions include:
	\begin{itemize}
		% \item  \textbf{A structured taxonomy} We offer a brief overview of how FMs are incorporated into anomaly detection tasks, with a structured taxonomy that classifies existing works into three categories.
		\item \textbf{A novel taxonomy.} We propose a structured taxonomy that categorizes the role of FMs in anomaly detection into three primary functions: encoder, detector, and interpreter. This classification provides a clear framework for understanding how FMs contribute to different stages of anomaly detection.
		% \item \textbf{A comprehensive review} The current research progress of incorporating FMs into anomaly detection tasks is systematically delineated, according to the taxonomy we proposed.
		\item \textbf{A systematic review.} We conduct an extensive review of state-of-the-art methods that leverage FMs for anomaly detection, organizing them according to our proposed taxonomy. This review highlights the latest trends, methodologies, and applications across various domains.

		% \item \textbf{Future directions} We discuss the core challenges still existing in current works and point out possible future research directions.
		\item \textbf{Future directions.} We identify key challenges in FM-based anomaly detection, including efficiency, bias, explainability, and multimodality. Furthermore, we outline promising future research directions to address these challenges and advance the field.

	\end{itemize}
	
	
	
	\section{Preliminaries}
	We first introduce the basic concepts of FMs, then, give a clear problem statement of anomaly detection using FMs, and finally, present our proposed taxonomy.
    
	\subsection{Foundation Models}
	% \subsubsection{Definition}
	% While FMs have been widely used in a wide range of application scenarios, there is currently no clear definition for them; here we provide a specific
	% definition for FMs mentioned in this survey.\hj{can we weaken this argument? maybe remove this sentence? it might be challenged by reviewers.} FMs are firstly named in~\cite{bommasani2021opportunities} as a general class of models, which inherit the concepts from deep neural networks and self-supervised learning. As a specific subset of FMs, LLMs are trained on vast amounts of text and can generate, understand, or translate human language. Different from LLMs that focus exclusively on natural language, FMs, with a wider range, can be applied to not just language but also images, audio, and other data types. Specifically, they refer to large, pre-trained models that undergo pre-training on a significant amount of data, which can be easily further fine-tuned on task-specific data and then serve as a base for many downstream tasks across different domains.
	
	
	\textbf{Definition.} FMs are a class of large, pre-trained models that serve as the common basis for a wide range of downstream tasks across various domains. First introduced by~\cite{bommasani2021opportunities}, FMs build on concepts from deep neural networks and self-supervised learning. A prominent subset of FMs, LLMs, are trained on extensive text datasets and are able to perform tasks like language generation, comprehension, and translation. Unlike LLMs, which are limited to written language, FMs have a broader scope, capable of processing diverse data types such as text, images, and audio. They undergo large-scale pre-training on vast datasets and can be fine-tuned with task-specific data, making them highly versatile for numerous applications.
	
	\textbf{Composition.}
	FMs are built on the basis of large data, self-supervised pretraining, and transformer-based architecture~\cite{zhou2024comprehensive}. Pretraining focuses on training a general model to learn generic representations using large amounts of diverse, unlabelled data. This general model, inspired by transfer learning~\cite{niu2020decade}, could then be used to perform different downstream tasks and enhance model performance in other fields through fine-tuning. In the pretraining stage, self-supervised learning~\cite{liu2022graph} is applied across a wide range of domains and areas where unlabeled data is naturally available. As for the model structure, the transformer architecture is the most popular for FMs in different areas, like natural language processing (NLP) and computer vision (CV). These pretrained models may be adapted to specific tasks using a number of methods, such as transfer learning to fine-tune some or all of the parameters of FMs with a much smaller task-specific dataset~\cite{zhang2022transfer}, few-shot learning with only a few samples, or zero-shot learning without any task-specific examples
    
    % When pretrained models are adapted to specific tasks, the adaptation process relys on transfer learning to fine-tune parameters of FMs in a much smaller task-specific dataset~\cite{zhang2022transfer}. According to the number of samples in the dataset, the fine-tuning stage is classified into few-shot learning with only a few samples and zero-shot learning without any task-specific examples.
	
	
	%\subsection{Problem Statement}
	%The objective of anomaly detection is to train a model that works effectively for detecting anomalies on test datasets in specific application scenarios without any training on the target data, so the training set is generally expected to be drawn from distributions from the test sets. Given a dataset $\mathcal{X}=\{x_1,x_2,...,x_N\}$ with $x_i\in\mathbb{R}^D$ and a representation space $\mathcal{Z}\in\mathbb{R}^K(K\ll N)$, the aims of current anomaly detection with deep learning models are learning a feature representation mapping function $\phi(\cdot): \mathcal{X} \mapsto \mathcal{Z}$ to calculate anomaly scores or an end-to-end anomaly score learning function $\tau(\cdot):\mathcal{X}\mapsto\mathbb{R}$, where anomalies could be extracted from normal samples in the space yielded by the $\phi(\cdot)$ or $\tau(\cdot)$ functions. Here, both $\phi(\cdot)$ and $\tau(\cdot)$ are neural network-based mapping function with hidden layers and weight matrices. Based on deep anomaly detection, foundation models can be incorporated to empower this process and here we give a specific definition.
	
	%\textbf{FM-empowered Anomaly Detection}
	%Given a test dataset $\mathcal{D}_{test}=\{x_1,x_2,...,x_n\}$, the pre-trained FMs are incorporated into the feature representation function $\phi(\cdot)$ and/or anomaly score learning function $\tau(\cdot)$. The objective of FM-empowered anomaly detection is to develop a detection model $f_{FM}(\cdot)$ to calculate the anomaly score of each sample $x_i\in\mathcal{D}_{test}$ and predict whether they are anomalous samples.
	
	\subsection{Proposed Taxonomy}
	As shown in Figure~\ref{fig:framework001}, the taxonomy of this survey classifies current anomaly detection models into three main categories: 1) FM as Encoder, where FMs are incorporated into the process of computing embeddings for high-level representations; 2) FM as Detector, where FMs are directly used as anomaly detectors to identify and localize specific anomalies; 3) FM as Interpreter, where FMs are assisted in providing explanations on the causes of anomalies. Examples of downstream tasks include fake news detection in social networks, driver fatigue detection in autonomous robotic systems, and plant/human disease detection in agricultural systems, to name a few.

	\begin{figure*}
		\centering
		\includegraphics[width=0.99\linewidth]{framework.png}
		\caption{An illustration of applying foundation model to the three key stages of anomaly detection, playing roles as encoder, detector, and interpreter. Three cases are illustrated with image, tabular, and time series data, respectively.}
		\label{fig:framework001}
	\end{figure*}
    
	It should be noted that in some works, due to the diversity of FMs, more than one kind of FMs are used, and sometimes they serve different roles in different stages of anomaly detection. Therefore, it is inappropriate to categorize them exclusively into one of these three main classes. For example, LogiCode~\cite{zhang2024logicode} transforms structured request prompts and logical rules into executable Python codes by harnessing the power of the LLM to transform structured request prompts and logical rules into Python codes, which regards the foundation model as a code generator. AnomalyRuler~\cite{yang2025follow} employs two different FMs, a Vision-Language Model (VLM) to generate descriptions for input video frames and a LLM to derive rules for anomaly detection by contrasting the rules for normality. Audit-LLM~\cite{song2024audit} regards a FM as an assistant by serving as task decomposer, tool builder, and executor in every stage during the whole process of insider threat detection.
	Table~\ref{sum} summarizes the models that leverage FMs to assist anomaly detection tasks according to the proposed taxonomy.
	
	\section{FM as Encoder}
	In an anomaly detection model, the encoder module plays a critical role in transforming input data (e.g., text, time series, images, etc.) into a latent feature embeddings. This representation captures essential characteristics of the data samples that can later be analyzed to detect deviations or anomalies. FM as encoder approaches focus on enhancing the
	quality of data embeddings with the help of powerful FMs.
	The derived embeddings are directly inputted into downstream
	classifiers for anomaly detection. Referring to Figure~\ref{fig:fmen}, we naturally categorize these approaches into two branches: LLM-based and hybrid embedding, depending on whether or not the latent embeddings are only generated by foundation model.
	
	There is a special case where FM is not the encoder of data samples. We classify this kind of models in this section because the FM indirectly participates in the encoding process. Specifically, AnomalyLLM~\cite{liu2024large} is a knowledge distillation-based time series anomaly detection model by employing the foundation model as its teacher network. The anomalies are detected based on the discrepancy between the features of the teacher and student networks, where a large representation gap reflects anomalous samples. 
	
	\begin{figure}
		\centering  %图片全局居中
		\vspace{-0.35cm} %设置与上面正文的距离
		\subfigtopskip=2pt %设置子图与上面正文或别的内容的距离
		\subfigbottomskip=2pt %设置第二行子图与第一行子图的距离，即下面的头与上面的脚的距离
		\subfigcapskip=-5pt %设置子图与子标题之间的距离
		\subfigure[FM-based Embedding]{
			\label{fig:fmena}
			\includegraphics[width=0.39\linewidth]{fmasencoder.png}}
		\quad %默认情况下两个子图之间空的较少，使用这个命令加大宽度
		\subfigure[Hybrid Embedding]{
			\label{fig:fmenb}
			\includegraphics[width=0.36\linewidth]{fmasencoder1.png}}
		
		\caption{FM as encoder.}
		\label{fig:fmen}
	\end{figure}
	
	\subsection{LLM-based Embedding}
	With reference to Figure~\ref{fig:fmena}, FMs are directly utilized as the unique encoder to output embeddings into the classifier for anomaly detection:
	% \begin{equation}
		\begin{align}
			\textnormal{Embedding:}&~~ \textbf{z}_i=\phi_{FM}(x_i),\\
			\textnormal{Anomaly Detection:} &~~~\hat{Y}~=\tau(\textbf{z}_i).
		\end{align}
		% \end{equation}
	In these equations, the text information $x_i$ is encoded by a foundation model $\phi_{FM}(\cdot)$ into $\textbf{z}_i$. The embeddings generated by this kind of approach are directly fed into the classifier $\tau(\cdot)$ for classification label $\hat{Y}$, typically without the need for any other encoders. Generally, most of these works use a Large Vision-Language Model (LVLM) to generate both textual and visual embeddings for image/video anomaly detection.
	
	In the case of image anomaly detection, there are generally two encoders, one for text embedding to describe the content of images, the other for visual embedding to encode images~\cite{radford2021learning}. One representative example is WinCLIP~\cite{jeong2023winclip}, which proposed language-guided zero-shot anomaly detection by introducing a compositional prompt ensemble. To leverage the normal images available in the few normal shots setting, its few-normal-shot extension WinCLIP+ is introduced to aggregate complementary information from WinCLIP and visual signals from normal samples. However, the performance of WinCLIP+ is heavily dependent on extensive engineering on hundreds of manually defined prompts. To solve this problem, AnomalyCLIP~\cite{zhou2024anomalyclip} uses an object-agnostic prompt template to model the semantics of general abnormality and normality, thus improving the performance of generalized zero-shot anomaly detection.  A similar InCTRL model~\cite{zhu2024toward} also explores the problem of generalist anomaly detection, meaning that a single model can detect anomalies in different data sets from various application scenarios without the need of additional training on the target dataset. The detection strategy is to identify the discrepancies between query images and a set of few-shot normal images from the auxiliary data, where anomalies are expected to have larger discrepancies than normal samples. Moreover, ALFA~\cite{zhu2024llms} and MVFA \cite{huang2024adapting} propose to solve generalist anomaly detection in zero/few-shot scenarios as well. Specifically, a run-time prompt adaptation strategy is utilized in ALFA to generate informative anomaly prompts for every image. Then, a fine-grained aligner is developed to learn local semantic space projection, which can be generalized to support pixel-level anomaly localization. As for MVFA, the authors design a multi-level visual feature adaptation architecture for medical image anomaly detection, on the basis of CLIP model. In \cite{sinha2024real}, the authors use relatively small FMs (e.g., 120M parameters) to detect deviations from prior experiences in real time. At the same time, the LLM-based monitor can reason about the safety consequences of anomalous scenarios, thereby determining whether intervention is necessary.
	
	\subsection{Hybrid Embedding}
	Approaches using hybrid embeddings focus on utilizing the capability of FMs to capture additional information as shown in Figure~\ref{fig:fmenb}. Taking graph anomaly detection as an example, the embeddings are generated by combining the output of both foundation model $\phi_{FM}(cdot)$ and GNNs $\phi_{GNNs}(cdot)$:
	% \begin{equation}
		\begin{align}
			\textnormal{Embedding:}&~\textbf{z}_i=F(\phi_{FM}(x_i), \phi_{GNN}(x_i)),\\
			\textnormal{Anomaly Detection:} &~\hat{Y}=\tau(\textbf{z}_i).
		\end{align}
		% \end{equation}
	There are multiple fusion strategies $F(\cdot)$ of embeddings, such as concatenation, weighted averaging, or using attention mechanisms to highlight relevant features. This fused representation captures both semantic and relational information, enriching the dataset without the need for large quantities of labeled data.
	
	For example, AnomalyLLM~\cite{liu2024anomalyllm} was proposed to detect anomaly edges by aligning LLM with dynamic graph. Instead of directly using LLM as an encoder, the backbone LLM takes the embedding from a GNN encoder as input to generate the final representation vector for anomaly detection. Despite that FMs have the powerful capacity to capture semantic information,
	\cite{bakumenko2024advancing} uses LLMs to encode non-semantic categorical data (i.e., journal entries) from real-world financial records. Compared with traditional encoders, LLMs could solve the issues of feature heterogeneity and sparsity in financial audits. In \cite{bakumenko2024advancing}, a hybrid model that combines sentence-transformer embeddings with machine learning (ML) classifiers is designed to enhance anomaly detection performance. To compare the performance of different models, three LLMs and five ML classifiers are evaluated from the perspectives of quality, efficiency, and speed, thereby facilitating a comprehensive evaluation. 
	
	
	\textbf{Discussion.}
	Utilizing FMs as encoder has demonstrated superior performance on anomaly detection, being capable of effectively capturing rich, general-purpose representations. Moreover, many multimodal FMs (e.g., CLIP or GPT-4) enable the simultaneous encoding of data from multiple modalities (e.g., text, image, video) into a unified space, enhancing anomaly detection in complex and multimodal datasets. However, despite some papers claiming strong scalability, using FM as encoders faces the challenge of explainability. The representations generated by FM directly impact the detection results of models, which may in turn pose transparency and trustworthiness issues in critical applications. 
	
	
	
	\begin{figure}
		\centering  %图片全局居中
		\vspace{-0.35cm} %设置与上面正文的距离
		\subfigtopskip=2pt %设置子图与上面正文或别的内容的距离
		\subfigbottomskip=2pt %设置第二行子图与第一行子图的距离，即下面的头与上面的脚的距离
		\subfigcapskip=-5pt %设置子图与子标题之间的距离
		\subfigure[Serialization-based]{
			\label{fmdea}
			\includegraphics[width=0.36\linewidth]{fmasdetector1.png}}
		\quad %默认情况下两个子图之间空的较少，使用这个命令加大宽度
		\subfigure[Encoding-based]{
			\label{fmdeb}
			\includegraphics[width=0.37\linewidth]{fmasdetector2.png}}
		
		\caption{FM as detector}
		\label{fmde}
	\end{figure}
	\section{FM as Detector}
	The core idea behind this category is to utilize FMs as anomaly detectors to detect anomalies for a wide range of tasks, including classifications and localization. However, applying FMs directly as detectors presents unique challenges, primarily because FMs are often prompt-based, while the source data in most cases present different modalities, such as time-series, image, and video. In this section, we classify the models broadly into serialization-based and encoding-based detection, depending on how data are preprocessed before input to FMs.
	\subsection{Serialization-based Detection}
	Most of the existing attempts to employ the question-answering capability of the FM to directly detect anomalies, which omits the representation learning process of data embeddings. As shown in Figure \ref{fmdea}, serialization-based detection typically involves two steps: (1) transforming source data into a sequence of text with a serialization function $SRL(·)$, and (2) extracting the detected anomalies from the FM output with a parsing function $Parse(·)$, as illustrated below: 
	% \begin{equation}
		\begin{align}
			\textnormal{Data Serialization: }& \mathcal{X}_{txt} = SRL(\mathcal{X}),\\
			\textnormal{Prediction: }& \hat{Y} = Parse(\phi_{FM}(\mathcal{X}_{txt},p)),
		\end{align}
		% \end{equation}
	where $p$ denotes the instruction prompt for the specific task.
	
	The parsing strategies of models are generally standardized. For example, given that the output of FMs often involves their reasoning and logic processes, several works~\cite{dong2024can,zanella2024harnessing,li2024anomaly} utilize specific prompts to extract the predicted label from the output. Another way is to regard anomaly detection as a Q\&A problem where FMs are instructed to answer questions in a specific format. For instance, some works~\cite{gu2024anomalygpt,alnegheimish2024large,elhafsi2023semantic,chaudhuri2024spiced} limit LLM’s output format via guiding instructions in prompts, such as “This is a photo of leather. Is there any anomaly in the image?”. In addition, some methods~\cite{hadadi2024anomaly} fine-tune FMs to directly output the label of anomalies, allowing them
	to provide accurate predictions without additional parsing steps.
	
	Considering that some FMs sometimes show failure cases, such as pairing incorrect indices and values, generating indices beyond the batch length, and listing every data item as abnormal. ~\cite{li2024anomaly} simulates a synthetic dataset with ground-truth labels for LLMs to be fine-tuned in a supervised manner. Note that the data are serialized into text before being inputted into the FMs. When detecting anomalies from unstable logs in software systems, one critical challenge is the lack of information about new logs because there is insufficient log data in new software versions. To mitigate the data insufficiency issue,~\cite{hadadi2024anomaly} pre-trains LLMs on vast amount of data for robust understanding of diverse patterns and contextual information. Specifically, the authors compare fine-tuned and prompt-engineered FMs to demonstrate which strategy performs better. 
	
	SIGLLM~\cite{alnegheimish2024large} is mainly made up of two parts, a PROMPTER to identify parts of a sequence that LLM thinks are anomalous and a DETECTOR to find anomalies using the residual between the original signal and the forecast. Before inputting into the LLM, a time series-to-text conversion module is devised to convert time series data into LLM-ready input. Similarly, to explore whether FMs could be used as a time series anomaly detector, \cite{dong2024can} designs a prompt learning strategy and synthesizes a data set to automatically generate time series anomalies with explanations. With instruction fine-tuning on this dataset, the authors demonstrate that foundation model can show improved performance in time-series anomaly detection tasks.
	
	\cite{elhafsi2023semantic} introduces a monitoring framework to detect semantic anomalies limited by vision-based policies; the monitor is composed of an LLM to infer what kind of observed objects in a scene may lead to confusion that could result in policy errors. To improve the reasoning ability of LLM, prompt engineering like few-shot prompting and chain-of-thought reasoning are employed in the instantiations of this framework. The same prompt learning strategy is used in SPICED~\cite{chaudhuri2024spiced}, which is an LLM-based framework for the detection and localization of syntactical bugs and analog Trojans in circuit net lists.
	
	\begin{table*}\tiny
		\caption{\label{sum}A summary of models that leverage FMs to assist anomaly detection or prediction tasks in literature. \textbf{FMs} shows the specific open-sourced FMs used in the paper. Acronyms in FM type: LLM (Large Language Model); LVLM (Large Vision-Language Models; MLLM (Multimodal Large Language Model). \textbf{Fine-tuning} denotes whether the parameters of FMs are fine-tuned during the detection process, and $\bigstar$ indicates that models employ parameter-efficient fine-tuning (PEFT). \textbf{Prompting} indicates the use of text-formatted prompts in LLM. \textbf{Data} indicates the anomalous data type detected in the paper. }
		\begin{tabular}{p{0.01cm}<{\centering} p{3.5cm}<{} p{2cm}<{} p{1.5cm}<{\centering}  p{1.2cm}<{\centering}  p{1cm}<{\centering} p{1.5cm}<{} p{2.2cm}<{} p{0.5cm}<{\centering}}
			
			\hline
			&	\textbf{Model}&\textbf{FMs}&\textbf{FM type}&\textbf{Fine-tuning}&\textbf{Prompting}&\textbf{Data}&\textbf{Domain}&\textbf{Code}\\
			\hline
			\multirow{8}{*}{\rotatebox{90}{FM as Encoder}}			&	
			\cite{bakumenko2024advancing}	& Transformer &LLM &\XSolidBrush&\XSolidBrush&Tabular&Finance&-	\\
			
			&	ANOMALYLLM\cite{liu2024large}&GPT-2 &LLM	&\Checkmark&\XSolidBrush&Time series&-&-\\
			&ALFA \cite{zhu2024llms}	& GPT &LVLM &\XSolidBrush&\Checkmark&Image&Industry&	-\\
			&InCTRL \cite{zhu2024toward}	& OpenCLIP &LVLM &\XSolidBrush&\Checkmark&Image&-&	\href{https://github.com/mala-lab/InCTRL}{Link}\\
			&AnomalyCLIP \cite{zhou2024anomalyclip}	& CLIP &LVLM &\Checkmark&\Checkmark&Image&-&\href{https://github.com/zqhang/AnomalyCLIP}{Link}	\\
			
			&WinCLIP \cite{jeong2023winclip}	& OpenCLIP &LVLM &\XSolidBrush&\Checkmark&Image&-&- \\
			&MVFA \cite{huang2024adapting}	& CLIP &LVLM &\Checkmark&\Checkmark&Image&Medical&\href{https://github.com/MediaBrain-SJTU/MVFA-AD}{Link} \\
			&	\cite{sinha2024real}&Many &LLM	&\XSolidBrush&\Checkmark&Text&Robotics&\href{https://sites.google.com/view/aesop-llm}{Link}\\
			& AnomalyLLM \cite{liu2024anomalyllm}&Transformer &LLM	&\XSolidBrush&\Checkmark&Graph&-&\href{https://github.com/AnomalyLLM/AnomalyLLM}{Link}\\
			&\cite{kim2023unsupervised}	& ChatGPT &LVLM &\Checkmark&\Checkmark&Video&Real-world surveillance&	-\\
			\hline
			\multirow{9}{*}{\rotatebox{90}{FM as Detector}}	&LAVAD~ \cite{zanella2024harnessing}	& Llama-2&LVLM\&LLM &\XSolidBrush&\Checkmark&Video&Real-world surveillance&	\href{https://lucazanella.github.io/lavad/}{Link}\\
			&AnomalyGPT \cite{gu2024anomalygpt}	& Vicuna &LLM &\Checkmark&\Checkmark&Image&Industry&-	\\
			
			&\cite{li2024anomaly}	& GPT-4 &LLM &~~~~~${\text{\Checkmark}}^{\bigstar}$
			&\Checkmark&Tabular&- &	-\\
			&\cite{elhafsi2023semantic}	& - &LLM &\XSolidBrush&\Checkmark&Video& Autonomous driving&-	\\
			
			&\cite{dong2024can}	& GPT-4 \& LLaMA3 &LLM &~~~~~${\text{\Checkmark}}^{\bigstar}$
			&\Checkmark&Time series&-&-	\\
			&	LLMAD \cite{liu2024large2}&GPT-4 &LLM	&\XSolidBrush&\Checkmark&Time series&-&-\\
			&SIGLLM \cite{alnegheimish2024large}	& GPT \& MISTRAL &LLM &\Checkmark&\Checkmark&Time series&-&\href{https://github.com/sintel-dev/sigllm}{Link}	\\
			&\cite{hadadi2024anomaly}	& GPT-3 &LLM &\Checkmark&\Checkmark&Log&Software system&	-\\
			&SPICED~\cite{chaudhuri2024spiced}	& GPT-3.5 &LLM &\XSolidBrush&\Checkmark&Signal& Electronics&	-\\
			
			\hline
			
			\multirow{5}{*}{\rotatebox{90}{Interpreter}}		
			&	
			Holmes-VAD \cite{zhang2024holmes}& Llama3-Instruct-70B&MLLM	&~~~~~${\text{\Checkmark}}^{\bigstar}$
			&\Checkmark&Video&Real-world surveillance&\href{https://holmesvad.github.io/}{Link}\\		
			&\cite{park2024enhancing}	& - &LLM &\XSolidBrush&\Checkmark&Tabular&Finance&	-\\
			&	DABL~\cite{guan2024dabl}&Llama-2 &LLMs	&~~~~~${\text{\Checkmark}}^{\bigstar}$
			&\Checkmark&Text&Business&\href{https://github.com/guanwei49/DABL}{Link}\\
			&Myriad~\cite{li2023myriad}	& GPT-3.5 &LVLM &\XSolidBrush&\Checkmark&Image& Industry&\href{https://github.com/tzjtatata/Myriad}{Link}	\\
			&	VAD-LLaMA~\cite{lv2024video}&LLaMA &LVLM	&\XSolidBrush&\Checkmark&Video&Real-world surveillance&-\\
			&	LogConfigLocalizer~\cite{shan2024face}	& GPT-4 &LLM &\XSolidBrush&\Checkmark&Log&Software system&	\href{https://github.com/shanshw/LogConfigLocalizer/}{Link}\\	
			
			
			\hline
			\multirow{3}{*}{\rotatebox{90}{Others}}			
			&LogiCode \cite{zhang2024logicode}	& GPT-4&LLM &\XSolidBrush&\Checkmark&Image&Industry	&-\\
			&AnomalyRuler~\cite{yang2025follow}	& GPT-4 \& Mistral-7B &LVLM\&LLM &\XSolidBrush&\Checkmark&Video&Real-world surveillance&\href{https://github.com/Yuchen413/AnomalyRuler}{Link}\\
			&Audit-LLM~\cite{song2024audit}&GPT-3.5 &LLM	&\XSolidBrush&\Checkmark&Log&Audits&-\\
			
			\hline
		\end{tabular}
	\end{table*}
	\subsection{Encoding-based Detection}
	Deep learning has demonstrated impressive capabilities in understanding different data structures through neural networks, which excel at recognizing patterns in complex and high-dimensional data. As illustrated in Figure
	\ref{fmdeb}, encoding-based detection leverages the advantages of deep learning to incorporate complex characteristics present in source data, allowing FMs to be characteristic-aware: 
	% \begin{equation}
		\begin{align}
			\textnormal{Representation Learning:}& ~~~\textbf{z}_i = f_{DL}(x_i),\\
			\textnormal{Prediction:}& ~~~\hat{Y} = Parse(\phi_{FM}(\textbf{z}_i,p)),
		\end{align}
		% \end{equation}
	where $f_{DL}$ is the encoder for data representation learning based on deep learning (DL). DL-based prediction also utilizes a parser to retrieve FM output.
	
	To combat the challenge that traditional industrial anomaly detection models can only provide anomaly scores of data samples and the threshold must be manually determined, AnomalyGPT~\cite{gu2024anomalygpt} employs an image decoder to provide fine-grained semantics and design a prompt learner to fine-tune the LVLM using prompt embeddings. Therefore, it could directly assess the locations of anomalies and provide image information in a human-understandable manner. 
	
	
	LAVAD \cite{zanella2024harnessing} uses LLMs to detect video anomalies exclusively from a scene description without further training. After generating a textual description for each video frame with a pre-trained VLM, an LLM is applied to capture the dynamics of the scene and summarize captions within a temporal window, which will be further used to provide an anomaly score for each frame. 
	
	
	
	\textbf{Discussion.} 
	Utilizing FMs directly as detectors shows superiority in
	processing textual attributes of different types of data, especially achieving remarkable zero-shot performance compared with traditional DL models. The ultimate goal is to develop and refine methods for encoding these structured information into a format that
	FMs can comprehend and manipulate effectively and efficiently. Despite the fact that LLMs have shown their potential in understanding long-context and mathematical reasoning, they cannot be directly applied as an anomaly detector without prompt learning and fine-tuning strategy. Moreover, for encoding-based detection, training an additional DL module and inserting it into FMs for joint training is challenging due to the problem of vanishing gradients in the early layers of deep transformers~\cite{li2024survey}.
	
	\begin{figure}
		\centering  %图片全局居中
		\vspace{-0.35cm} %设置与上面正文的距离
		
		
		\subfigure[Direct detection]{
			\label{fmina}
			\includegraphics[width=0.3\linewidth]{fmasinterpreter2.png}}
		\subfigure[Indirect detection]{
			\label{fminb}
			\includegraphics[width=0.3\linewidth]{fmasinterpreter3.png}}
		\subfigure[Verification]{
			\label{fminc}
			\includegraphics[width=0.35\linewidth]{fmasinterpreter1.png}}
		\caption{FM as interpreter}
		\label{fmde}
	\end{figure}
	
	\section{FM as Interpreter}
	In the last stage of anomaly detection, the FMs could be used as an interpreter to provide explanations on the detection results. We classify the models into detection-based and verification-based models based on whether FM serves as an anomaly detector as well.
	\subsection{Detection-based Explanation}
	% Despite that FMs are used as detectors, we still classify the following works into the "FM as Interpreter" section. This is because all of these models' main aims are interpreting the anomalous samples, such as the reasoning process and the extra information of these anomalies. According to figure~\ref{fmina} and \ref{fminb}, the approaches are divided into direct detection and indirect detection based on the input structure of FMs. FMs are used as detectors and interpreters with the help of their powerful capacity in natural language understanding and processing. Due to the lack of detailed annotations and few amount of anomaly detection datasets, several instruction templates for specific anomaly detection task should be constructed. 
	This classification is based on the primary focus of interpreting anomalous samples, including the reasoning behind anomalies and the additional context they provide. As illustrated in Figures~\ref{fmina} and \ref{fminb}, these approaches can be grouped into direct and indirect detection, depending on the input structure used with FMs. 
	Correspondingly, the explanation $Exp$ of FMs $f_{FM}(\cdot)$ is paired with a corresponding anomaly-aware question $P_d$ to construct an instruction item set $\mathcal{I}$:
	% \begin{equation}
		\begin{align}
			&\textnormal{Explanation:} ~~Exp = f_{FM}(P_t,y_i,c_i)\\
			&\textnormal{Instruction Dataset Construction:}\notag\\
			&\mathcal{I}_i = \{``user:":P_d, ``FM": Exp\},
		\end{align}
		% \end{equation}
	where task prompt $P_t$ combined with the abnormal label $y_i$ and detailed caption $c_i$ are inputs to the foundation model $f_{FM}(\cdot)$ to make judgements and provide explanations.
	
	\textbf{Direct detection.}
	Holmes-VAD \cite{zhang2024holmes} is composed of three key components, namely, a Video Encoder for encoding input video, a Temporal Sampler for abnormal frame prediction, and a Multi-modal LLM for generating text explanations. To create a generic model capable of detecting semantic anomalies in business processes, DABL~\cite{guan2024dabl} fine-tunes the Llama by incorporating traces into question and answer content. Specifically, every trace item (i.e., business process) and its label are inputs to the foundation model so that the model could be fine-tuned in a supervised way. Then, the fine-tuned model outputs whether the given trace is normal or anomalous, and provides causes of anomalous traces. LLMAD~\cite{liu2024large2} is an LLM-based framework for time series anomaly detection. It improves detection performance and interpretation quality by injecting data background and domain knowledge into model via time-series In-Context Learning and Chain-of-Thought approach guiding its decision-making process. 
	
	\textbf{Indirect detection.}
	In Myriad~\cite{li2023myriad}, a vision expert tokenizer embeds the anomaly map into vision expert tokens to make LLM perceive prior knowledge, and a vision expert instructor generates domain vision-language tokens to compensate for the errors of vision experts. VAD-LLaMA~\cite{lv2024video} is composed of a video encoder and a foundation model, which are connected by a projection layer called adapter. By treating the foundation model as a question-answer system, the foundation model provides detailed information (e.g., the concrete video content and the accurate time frames when anomalies appeared) of anomalies by answering the human queries.
	
	\subsection{Verification-based Explanation}
	Verification-based FMs aim to further verify the detection results by providing some textual explanations about the detected anomalies (figure~\ref{fminc}). To ensure the effectiveness of FMs, specific prompts are designed to consistently generate identical output for the same queries.
	
	To further validate the authenticity of detected anomalies, ~\cite{park2024enhancing} proposes an LLM-based multi-agent framework to analyze the detailed anomaly information, which serves as a critical interface between the AI-driven analysis process and human decision-making.
	With the aim of assisting end-users in coping with configuration errors in software system through log analysis, ~\cite{shan2024face} proposes a two-stage strategy to localize the root-cause configuration logs. The first stage is to identify anomalous logs through obtaining key log messages, and the second stage is to use an LLM for further verification with the help of their strong power in natural language understanding and processing. Specifically, strategies are designed to increase the reliability of LLMs’ judgments and provide additional information about the configuration errors.
	
	\textbf{Discussions.}
	Although FMs excel in providing explanations on the anomaly detection results, its interpretability is still limited due to the difficulty of well-crafted prompts. Actually, creating these prompts needs domain specific knowledge from experts. Therefore, how to improve the data quality with acceptable labeling costs is still a core challenge to be solved in the future.
	\section{Open Challenges and Way Forward}
	Based on the above review and analysis, we believe that there are still many challenges and potentials for further enhancement in this field. In this section, we list some future research
	directions for further exploration.
	
	\subsection{Efficiency} 
	Notwithstanding the stellar progress and accomplishments of FMs, the improvements of performance in these models come at the expense of the model's efficiency. However, anomaly detection models need to be particularly efficient because they are often applied in real-time, high-stakes environments where timely detection and response to anomalies are critical. Common application scenarios include fraud detection and healthcare, where even small delays of identification may lead to significant financial loss or even safety risks. While some lightweight adaptation techniques have been proposed to improve the parameter efficiency, \cite{lester2021power} gives an example that, as the model size increases, the performance gap between full fine-tuning and lightweight adaptation is diminishing rapidly.
	Therefore, exploring mechanisms to balance the trade-off between efficiency and expressivity of FMs still remains a notable challenge. 
	\subsection{Bias} 
	In recent years, FMs have led to an extraordinary level of homogenization, which refers to the consolidation of methodologies for building machine learning systems across a wide range of applications~\cite{bommasani2021opportunities}: current NLP models are often adapted from one of popular FMs like BERT. Despite that any improvements of FMs can help produce immediate benefits, such kind of extension might also have the potential to inherit or even amplify the problematic biases of these models. A biased anomaly detection model may potentially lead to incorrect or unfair outcomes. For example, a biased model may disproportionately flag specific data points or groups (e.g., gender and racial bias) as anomalous even when they are normal, limiting their capability of detecting genuine anomalies. Such kind of false positives or false negatives can lead to unfair treatment of certain individuals or groups, missed critical alerts, or a lack of trust in the system, ultimately compromising its effectiveness and fairness.
	Therefore, it is critical to eliminate the intrinsic bias present within FMs, thereby further avoiding extrinsic harms in downstream anomaly detection systems.
	
	\subsection{Explainability}
	Despite that FMs are currently used as interpreters, in many works, to illustrate why anomalies are detected by providing textual explanations in a human-understandable manner, the models themselves are not transparent and interpretable enough to give explanations of the internal model structures and behaviors. However, providing evidence and logical steps for decision-making is a critical issue in anomaly detection especially in applications like healthcare and finance, where understanding the reasoning behind an anomaly is as important as detecting it~\cite{chandola2009anomaly}. Therefore, how to improve the interpretability of FMs remains an open research question, and it is absolutely important for researchers to enhance the trust, usability, and decision-making of anomaly detection. 
	
	
	%\subsection{Powerful detectors}
	%It is acknowledged that state-of-the-art generative FMs have more powerful capabilities to generate high-quality, cheap, and personalized content than prior AI models. The same abilities of FMs that make them powerful generators of creative content can also make them strong detectors of harmful model-generated content. Existing work \cite{alnegheimish2024large} has demonstrated that LLMs are capable of being zero-shot anomaly detectors without any prior learning, but their performance are still inferior than state-of-the-art deep learning models. Therefore, applying FMs to develop more powerful detection systems of machine-generated, harmful content will be a promising future work.
	\subsection{Multimodality}
	While multimodality is considered a critical element of intelligence, and serves as a crucial component for the development of both thorough and broad comprehension of the world, models that go beyond simple alignment of vision and language are yet to emerge~\cite{radford2021learning,lu2019vilbert}. In real-world application scenarios, taking healthcare as an example, medical data are highly multimodal, with various data types, scales, and styles. Multimodal models generally have better performance on anomaly detection by integrating and analyzing data from different sources than models with a single modality. However, current anomaly detection models are mainly developed for single modality (e.g., text, image, and gene), and do not learn from various modalities. By harnessing information across different data types, multimodal data can provide richer and more robust anomaly detection, thereby improving the accuracy of detection results across various applications. Future studies should further examine the design of FMs that integrate various modalities and domains.
	\section{Conclusion}
	The application of FMs to anomaly detection has emerged as a prominent area of research in recent years.
	In this survey, we provided an in-depth review of the use of FMs in anomaly detection tasks. We introduced a novel taxonomy classifying the methods into three approaches based on the role of FMs played in different stages of anomaly detection, namely encoder, detector, and interpreter. This taxonomy clarifies how FMs can empower the process of data representations, anomaly detection, and explainable result analysis of detection. We also discussed challenges and highlighted several future research directions, aiming to shed light on the advances and challenges in the field of anomaly detection with FMs, thereby encouraging further progress in this domain. As FMs continue to evolve, their role in anomaly detection is expected to expand, unlocking new possibilities for more accurate, interpretable, and scalable anomaly detection systems.
	\appendix
	


%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai25}

\end{document}

