%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

%%%%%%%%%%%%%%% Author-added packages

\usepackage{hyperref}
\usepackage{url}
% \usepackage{ulem}
\usepackage{hyperref}
% \usepackage[dvipsnames]{xcolor}
\usepackage[most]{tcolorbox}
\usepackage{wrapfig}
% \usepackage{multirow}
% \usepackage{makecell}
\usepackage{graphicx,xcolor,float}
\usepackage{subcaption}
\usepackage{threeparttable}
\usepackage{algorithm}
\usepackage{pifont}
\usepackage[icml,subfig]{definition}

\newcommand{\shen}[1]{\textcolor{red}{(shen: #1)}}
\newcommand{\yibo}[1]{\textcolor{red}{(yibo: #1)}}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Multimodal Large Language Models Can Significantly Advance Scientific Reasoning}
% \icmltitlerunning{Position: Leverage Multimodal Large Language Model for Scientific Reasoning}

\begin{document}

\twocolumn[
\icmltitle{Position: Multimodal Large Language Models Can Significantly \\ Advance Scientific Reasoning}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}
\icmlsetsymbol{correspondence}{\dag}

\begin{icmlauthorlist}
\icmlauthor{Yibo Yan}{aaa,bbb,ccc}
\icmlauthor{Shen Wang}{aaa}
\icmlauthor{Jiahao Huo}{bbb}
\icmlauthor{Jingheng Ye}{aaa,fff}
\icmlauthor{Zhendong Chu}{aaa} \\
\icmlauthor{Xuming Hu}{correspondence,bbb,ccc} 
\icmlauthor{Philip S. Yu}{ddd}
\icmlauthor{Carla Gomes}{eee}
\icmlauthor{Bart Selman}{eee}
\icmlauthor{Qingsong Wen}{correspondence,aaa}
\end{icmlauthorlist}

\icmlaffiliation{aaa}{Squirrel Ai Learning.}
\icmlaffiliation{bbb}{The Hong Kong University of Science and Technology (Guangzhou).}
\icmlaffiliation{ccc}{The Hong Kong University of Science and Technology.}
\icmlaffiliation{ddd}{University of Illinois, Chicago.}
\icmlaffiliation{eee}{Cornell University}
\icmlaffiliation{fff}{Tsinghua University.}

\icmlcorrespondingauthor{Xuming Hu}{xuminghu@hkust-gz.edu.cn}
\icmlcorrespondingauthor{Qingsong Wen}{qingsongedu@gmail.com}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Scientific reasoning, the process through which humans apply logic, evidence, and critical thinking to explore and interpret scientific phenomena, is essential in advancing knowledge reasoning across diverse fields. However, despite significant progress, current scientific reasoning models still \textit{struggle with generalization across domains and often fall short of multimodal perception}. Multimodal Large Language Models (MLLMs), which integrate text, images, and other modalities, present an exciting opportunity to overcome these limitations and enhance scientific reasoning. Therefore, \textbf{this position paper argues that MLLMs can significantly advance scientific reasoning} across disciplines such as mathematics, physics, chemistry, and biology. First, we propose a four-stage research roadmap of scientific reasoning capabilities, and highlight the current state of MLLM applications in scientific reasoning, noting their ability to integrate and reason over diverse data types. Second, we summarize the key challenges that remain obstacles to achieving MLLM's full potential. To address these challenges, we propose actionable insights and suggestions for the future. Overall, our work offers a novel perspective on MLLM integration with scientific reasoning, providing the LLM community with valuable vision for achieving Artificial General Intelligence (AGI).
\end{abstract}

\section{Introduction}
\label{sec:intro}

Scientific reasoning, at its core, is the process through which humans apply logic, evidence, and critical thinking to explore and interpret phenomena in various scientific domains \cite{bao2009learning,lawson2004nature}. This cognitive ability is essential not only for advancing knowledge but also for fostering a deeper understanding of the natural world, particularly in fields such as mathematics, physics, chemistry, and biology. In education, AI for Science, and other domains, scientific reasoning serves as a cornerstone for cultivating problem-solving skills, analytical thinking, and innovation \cite{huang2022towards,willemsen2023role}. However, despite shared objectives, each domain has unique characteristics in terms of data representation, knowledge construction, and reasoning methods \cite{wang2023scientific}.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/big_picture.png}
    \vspace{-2mm}
    \caption{The big picture of our position. We focus on multimodal scientific fields,  especially mathematics, physics, chemistry, and biology as our scope (a), and we advocate leveraging MLLMs with multiple reasoning functions for scientific reasoning (b). We further propose a four-stage roadmap for scientific reasoning capability, ultimately achieving AGI (c).}
    \label{fig:roadmap}
    \vspace{-4mm}
\end{figure*}


In response to these challenges, the scientific community has explored a range of approaches, from traditional statistical methods to the more recent advancements in deep learning, with the goal of improving knowledge reasoning across disciplines \cite{goodman2016aligning,lu2022survey}. While significant progress has been made in enhancing scientific reasoning within specific domains, a gap remains in the broader context of scientific research. Current scientific reasoning models, and even those targeted toward domain-specific applications, are still \textit{far from achieving the generalization capabilities necessary for Artificial General Intelligence (AGI), which aims to exhibit unified reasoning across all fields} \cite{birhane2023science}.

The rapid rise of Large Language Models (LLMs) in recent years has brought transformative changes across various domains, pushing the boundaries of what is possible in natural language processing and understanding \cite{min2023recent,zhao2023survey}. Despite their remarkable zero-shot reasoning abilities, many areas, particularly in scientific fields, require multimodal inputs to build a comprehensive understanding of knowledge. This has led to the emergence and growth of Multimodal Large Language Models (MLLMs), which are capable of integrating and reasoning over multiple types of data, such as text, images, and other modalities \cite{liang2024survey,bai2024survey}. MLLMs are not only revolutionizing language understanding but also paving the way for advancements in scientific reasoning by processing complex multimodal data in ways that were previously unachievable \cite{wang2024exploring,zou2025deep}.

Building on the rapid evolution of MLLMs and the growing demand for enhanced multimodal reasoning capabilities in scientific domains \cite{reddy2024towards,zhang2024scientific}, \textbf{this paper proposes a position: MLLMs can significantly advance scientific reasoning}. By integrating multimodal learning techniques, MLLMs have the potential to address the pressing challenges in scientific reasoning, as shown in Figure \ref{fig:roadmap}. This paper aims to break down the analysis into three key sections: the current state of MLLM applications in scientific reasoning, the challenges encountered, and the future steps needed to achieve greater success.

Our analysis delves into these topics in detail, starting with an overview of background and research roadmap (Sec. \ref{sec:background}), followed by how MLLMs are currently handling scientific reasoning (Sec. \ref{sec:how_reason_now}) as well as a discussion of the challenges faced (Sec. \ref{sec:challenges}), and concluding with the promising opportunities that lie ahead (Sec. \ref{sec:discussion}). In particular, we first explore how MLLMs have been applied across scientific disciplines, detailing the techniques used for data integration, pattern recognition, contextual understanding, and more. The Challenges section examines the inherent difficulties, ranging from technical to ethical aspects, that need to be overcome for MLLMs to achieve optimal performance. Finally, in the Discussion section, we highlight future steps with relevant literature, from data \& training strategies to agent-based collaboration, as key areas to focus on for advancing the integration of MLLMs with scientific reasoning. Through this, we aim to provide a comprehensive understanding of the landscape and offer strategic insights for future research in the intersection of MLLMs and scientific reasoning.

Our position and analytical framework contribute in three significant ways. \ding{182} We present \textbf{a novel perspective} on the integration of MLLMs with scientific reasoning, highlighting how this synthesis could reshape research in the field. \ding{183} We offer \textbf{a systematic review and categorization} of recent advancements, showcasing representative work and outlining a clear roadmap for future progress. \ding{184} We identify and explore \textbf{future opportunities}, providing the community with promising insights that could guide the next generation of research in scientific reasoning.
\vspace{-2mm}
\section{Background}
\label{sec:background}

\subsection{Scientific Reasoning}
\label{sec:sci_reasoning_definition}
Scientific reasoning is the intellectual process of forming hypotheses, interpreting evidence, and applying logical frameworks to solve problems or explain phenomena  \cite{bao2009learning,lawson2004nature}. Its importance spans diverse scientific domains, such as mathematics, physics, chemistry, and biology, where it drives discovery, fosters understanding, and enables practical innovation. With the rise of multimodal data, scientific reasoning increasingly requires integrating and synthesizing information from multiple sources, including textual, visual, and other modalities. We elaborate on the formal formulation of the task in Appendix \ref{app:task_formulation}.

The significance of scientific reasoning in the MLLM context is profound. By enabling models to connect disparate data points and infer relationships across modalities, MLLMs hold the potential to transform how researchers approach interdisciplinary problems. This capability is critical for addressing grand challenges such as climate modeling, drug discovery, and sustainable engineering \cite{zhang2024scientific}. Moreover, enhancing MLLM-based scientific reasoning aligns with the broader goal of advancing AGI, as it exemplifies the synthesis of learning, abstraction, and decision-making across various domains.

\subsection{Multimodal Large Language Models}
\label{sec:mllm_definition}
Most existing MLLMs consist of three primary modules: a modality encoder, an LLM module, and a projector between them \cite{fu2024mme}. Typically, the modality encoder extracts embeddings from non-language modalities such as images or audio, which are then projected into the word space of the LLM via the projector. The post-projection embeddings are subsequently combined with word embeddings derived from system prompts and user queries to serve as input for the LLM. Similar to LLMs, MLLMs generate responses in an autoregressive manner:$$p(\mathbf{w}_O \mid \mathbf{w}_V, \mathbf{w}_T) \sim \prod_{t=1}^L P(w_t \mid w_{<t}, \mathbf{w}_V, \mathbf{w}_T)$$ Here, $\mathbf{w}_V$ and $\mathbf{w}_T$ denote the post-projection embeddings and word embeddings respectively, while $\mathbf{w}_O = \{w_{o,t}\}_{t=1}^L$ represents the generated word token sequence of length $L$. With their capability to comprehend visual inputs, contemporary MLLMs demonstrate remarkable performance in various tasks, including visual question answering (VQA)~\cite{ishmam2024image,uppal2022multimodal,dang2024exploring}, image captioning~\cite{vaishnavi2024video,agarwal2024methods}, and multimodal reasoning~\cite{yan2024georeasoner,yan2024survey,huo2024mmneuron}.
\par Presently, there is a plethora of open-source foundation MLLMs capable of general multimodal tasks. Notable examples include the LLaVA family~\cite{liu2023llava,liu2023improvedllava,liu2024llavanext}, the Qwen-VL series~\cite{Qwen-VL, Qwen2VL}, the InternVL series~\cite{chen2024internvl,chen2024far}, LLaMA-3.2-Vision~\cite{dubey2024llama3}, etc. Despite these advancements, open-source MLLMs still lag behind closed-source models like GPT-4o~\cite{achiam2023gpt4o}, Claude~\cite{anthropic2024claude3.5}, and Gemini-Pro~\cite{team2024gemini1.5} in complex reasoning tasks~\cite{liu2025mmbench,yue2024mmmu}. With the emergence of o1-like reasoning models~\cite{jaech2024o1}, preliminary efforts are underway to elicit the slow-thinking capabilities of MLLMs, as seen in works like QvQ~\cite{qvq-72b-preview}, Mulberry~\cite{yao2024mulberry}, etc.


\section{How MLLMs Benefit Scientific Reasoning}
\label{sec:how_reason_now}

\subsection{Research Roadmap}
\label{sec:roadmap}
The development of (M)LLMs for scientific reasoning can be categorized into four progressive stages: \textit{Broad Knowledge and Recognition}, \textit{Analogical Reasoning and Generalization}, \textit{Insightful Inference}, and \textit{Creative Hypothesis Generation}. Each stage is defined by its unique characteristics across four dimensions: data and knowledge requirements, reasoning mechanisms, model generalization, and applications and impact (See the detailed comparison in Appendix \ref{app:domain_data_differences}). Figure \ref{fig:roadmap}(c) provides an overview of four stages, highlighting their evolution progress.

\textbf{Stage 1: Broad Knowledge and Recognition.} The initial stage focuses on building a strong foundational understanding across domains. MLLMs in this stage rely on highly diverse and multimodal datasets to capture a broad range of knowledge. Reasoning mechanisms are primarily retrieval-based, with emphasis on pattern recognition, data alignment, and summarization. Model generalization remains limited, operating primarily within predefined domains \cite{white2023future,pei2024leveraging,chen2023fine}. 

\textbf{Stage 2: Analogical Reasoning and Generalization.} This stage emphasizes the ability to draw connections and analogies across domains. Data requirements shift towards moderately diverse datasets that emphasize relationships and cross-domain patterns. Reasoning mechanisms incorporate relational reasoning and analogical thinking, enabling MLLMs to generalize effectively across domains. Applications include interdisciplinary problem-solving, transfer learning, and identifying cross-domain insight, reflecting a moderate increase in complexity and impact \cite{webb2023emergent,lewis2024evaluating}.

\textbf{Stage 3: Insightful Inference.} The third stage focuses on inferring deep insights from minimal and high-context data. Data requirements narrow to low-diversity, domain-specific datasets, allowing MLLMs to develop nuanced understanding. Reasoning mechanisms involve predictive reasoning and contextual interpretation, enabling the model to deduce complex outcomes. Generalization becomes highly context-specific, and applications include optimization and predictive modeling, making this stage highly impactful \cite{melko2024language,barman2025large}.

\textbf{Stage 4: Creative Hypothesis Generation.} In the final stage, MLLMs achieve the ability to generate innovative hypotheses and explore uncharted territories. Data requirements include highly diverse and synthetic datasets or simulation environments, fostering creativity. Reasoning mechanisms reach their highest complexity, involving generative reasoning and hypothesis exploration. Generalization becomes innovation-driven, synthesizing knowledge across fields. Applications at this stage have the highest impact, including proposing new theories, designing experiments, and driving scientific discovery \cite{xiong2024improving,qi2024large,pelletier2024explainable,orwig2024language}.

\subsection{Data Heterogeneity Across Four Scientific Domains}
\label{sec:data_heterogeneity}
MLLMs are designed to process and integrate information from both textual and visual modalities, offering a versatile framework for handling complex scientific reasoning. However, the distinct nature of data across disciplines introduces unique challenges in model training and application. Appendix \ref{app:domain_data_differences} summarizes the key differences in visual features for four scientific subjects within our scope.

Each subject presents unique challenges in data representation, with mathematical tasks primarily focusing on abstract symbols and formulas, while other subjects, particularly biology, require a mix of detailed real-world imagery and conceptual explanations. These differences necessitate domain-specific adaptations in how MLLMs process and understand multimodal data \cite{bai2024survey}.

\subsection{MLLM-based Scientific Reasoning}
\label{sec:mllm-based_reasoning}

As shown in Figure \ref{fig:current_paradigms}, current MLLM-based scientific reasoning can generally be divided into the following five paradigms, which progressively enhance the reasoning capabilities of MLLMs, ultimately moving towards AGI.

\textbf{Data Integration.} One of the primary strengths of MLLMs is their ability to integrate multimodal data from various scientific domains. For example, in physics, models can combine textual descriptions of a problem, such as Newton’s second law, with visual representations like force diagrams. The model can then reason about how different forces interact and predict motion \cite{barman2025large,sato2024exploring}. Similarly, in chemistry, MLLMs can combine chemical equations with 3D molecular structures, offering deeper insights into reaction mechanisms \cite{guo2023can,Zhang2024ChemLLMAC}. This integrated approach allows MLLMs to handle intricate, often disjointed, data sources to generate coherent scientific explanations.

The ability to integrate and synthesize multimodal information enables the MLLM to solve complex problems more effectively. However, challenges arise when the visual data does not perfectly align with the textual explanation, potentially leading to misinterpretations \cite{zhang2025mathverse,lu2023mathvista,zhuang2024math}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1 \linewidth]{figures/current_paradigms.png}
    \caption{Overview of MLLM-based scientific reasoning paradigms and corresponding reasoning capabilities.}
    \label{fig:current_paradigms}
    % \vspace{-8mm}
\end{figure}

\textbf{Knowledge Retrieval.} A significant aspect of scientific reasoning is knowledge retrieval. In fields like physics and chemistry, the vast amount of scientific knowledge available - such as established theories, laws, or empirical data - can be overwhelming. Knowledge retrieval helps MLLMs access external knowledge bases, databases, and scientific literature to supplement their reasoning. For instance, when solving a chemistry problem, an MLLM could retrieve data from a chemical database to identify missing properties of substances or reactions that were not explicitly stated in the task \cite{prince2024opportunities,sze2024evaluation}. In addition, knowledge retrieval can aid MLLMs in bridging gaps between modalities. For example, an MLLM working on a biological problem may retrieve relevant studies from scientific papers to fill in missing knowledge, such as identifying unknown interactions between proteins or cells \cite{li2024benchmarking,li2025biomedrag,huang2024adapting}. 

This aspect of MLLMs’ reasoning ensures that the model remains up-to-date with the latest discoveries and can apply a deeper layer of scientific knowledge in reasoning processes. However, challenges in accurately selecting and integrating relevant knowledge remain, particularly when sources of conflicting information are present \cite{fan2024survey}.

\textbf{Contextual Understanding.} Contextual understanding in scientific reasoning involves understanding not only the literal data presented but also the broader context in which it is used. MLLMs are capable of this by combining visual data, such as molecular structures in chemistry, with textual descriptions of chemical properties. This allows them to reason about potential interactions between molecules in a way that goes beyond simple matching \cite{liu2025integrating,horawalavithana2023scitune}. \citet{wang2024t} leverage Chain-of-Thought rationale as teaching signals to train small models to perform reasoning in complicated scenarios.

This contextual capability is crucial in fields like biology, where visual images of biological processes must be linked with underlying theories to make accurate predictions. However, this capability can be limited when the model fails to integrate textual and visual information effectively, leading to errors in its reasoning \cite{li2024multimodal}.

\textbf{Pattern Recognition.} In scientific reasoning, pattern recognition is a crucial skill that MLLMs excel at. MLLMs can detect patterns across different modalities, whether they are geometric in mathematics or experimental in chemistry. For instance, in biology, MLLMs can recognize cellular structures in images and relate them to known biological processes described in text, such as identifying mitochondria and correlating their function with energy production \cite{Luu2023BioinspiredLLMCL,kraus2024masked}. Additionally, an example of pattern recognition in mathematics could involve an MLLM matching visual representations of geometric figures with algebraic equations to find solutions to geometry problems \cite{mouselinos2024beyond}. This capability enhances the model's ability to understand complex systems across disciplines, including identifying patterns in large datasets that might be too intricate for manual analysis.

This skill allows MLLMs to be highly effective in analyzing multistep reasoning problems, which are often required in scientific disciplines \cite{qiao2024we,yan2024errorradar}. However, pattern recognition can be hindered by noisy or low-quality visual data, particularly in domains like biology, where image clarity is critical for correct interpretation \cite{zhang2024multimodal,ren2024pixellm,bai2024survey}.

\textbf{Simulation and Hypothesis Testing.} MLLMs also possess the ability to perform simulation and hypothesis testing, a fundamental part of scientific reasoning \cite{qi2023large}. For example, in physics, MLLMs can simulate the effect of various forces on an object, predict outcomes, and validate those predictions against real-world data or experiments \cite{melko2024language,gao2024large,yu2024climsim}. This capacity allows MLLMs to conduct scientific inquiries in a manner akin to human researchers, testing hypotheses and refining conclusions. In biology, given a diagram of an ecological system, an MLLM can hypothesize how a change in one species' population might impact the entire ecosystem, testing these hypotheses by comparing them to real-world ecological data \cite{morera2024foundation}.

Despite these strengths, hypothesis testing is constrained by the quality and quantity of available data, which in some scientific domains remains insufficient or incomplete. This limits the generalizability and reliability of MLLMs in tasks requiring deep, multistep reasoning \cite{xiong2024improving}.
\vspace{-2mm}
\section{Challenges}
\label{sec:challenges}
Even though MLLMs show substantial promise in solving scientific reasoning tasks, significant challenges remain. Based on the inherent characteristics of scientific reasoning - the need for multi-step inference and precise speculation, while ensuring transparency and ethicality - we further propose the following five key challenges (Figure \ref{fig:challenges}).

% \textbf{Multimodal Alignment.} One of the primary challenges in leveraging MLLMs for scientific reasoning is the alignment of textual and visual modalities across disciplines. MLLMs must understand the relationships between the two forms of data to reason effectively, but achieving this alignment is not always straightforward \cite{li2024multimodal}. In disciplines like biology, where both conceptual and highly detailed imagery are crucial, the challenge is particularly pronounced. The challenge of multimodal alignment is especially significant in biology, where accurate interpretation of cellular diagrams or ecological models requires both detailed visual data and contextual textual information \cite{liang2024scemqa}.

\textbf{Data Diversity.} Another challenge is the diversity of data across different scientific domains (summary of multi-domain scientific datasets can be seen in Appendix \ref{app:multidomain_scibench}). While mathematics is rich in textual data, such as equations and proofs, the availability of high-quality visual data is more limited \cite{qiao2024we,sun2024mm,liu2024mathllm,he2024olympiadbench}. In contrast, fields like chemistry and biology benefit from abundant visual data, such as molecular structures and microscopic images, but the corresponding textual descriptions may not always provide the depth required for comprehensive reasoning \cite{alampara2024probing,hocky2024connecting}. Without sufficient high-quality data for all modalities, the model's ability to generalize across domains is compromised.



\textbf{Reasoning Depth.} MLLMs frequently struggle with tasks that require deep, multi-step reasoning, especially when abstract concepts are involved. In mathematics, for example, solving a theorem involves a series of logical steps that must be followed precisely \cite{chen2023theoremqa}. In physics, simulating complex systems, such as thermodynamics or quantum mechanics, requires a deep understanding of abstract principles and real-world conditions \cite{melko2024language}. MLLMs often fail to maintain this depth of reasoning, especially when applied to tasks involving intricate concepts or lengthy proof processes. This issue is particularly prevalent in fields where the complexity of reasoning extends beyond surface-level analysis and requires models to maintain rigorous logical consistency \cite{yang2024leandojo}. Therefore, recent work has focused on two directions to improve the length of correct reasoning chains: the development of high-quality reasoning process datasets \cite{yan2024errorradar,song2025prmbench,zheng2024processbench} and the introduction of process reward models \cite{skyworkopeno12024,xiong2024rlhflowmath,wang2024math}.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1 \linewidth]{figures/challenges.png}
    \caption{Challenges for MLLM-based scientific reasoning.}
    \label{fig:challenges}
    \vspace{-4mm}
\end{figure}

\textbf{Error Propagation.} Error propagation is another significant challenge in multimodal reasoning. Errors in one modality, such as a misinterpreted graph or an unclear image, can propagate throughout the reasoning process, leading to incorrect conclusions \cite{li2024evaluating,yan2024errorradar,li2024ask}. For example, in a physics problem involving force vectors, an error in interpreting the vector diagram could lead to an incorrect calculation of the net force, which would then affect subsequent steps in the solution process \cite{jaiswal2024improving}. The risk of error propagation is particularly high when models are tasked with handling complex, multistep problems across multiple modalities. In particular, the impact of error propagation is especially acute in fields like physics and chemistry, where the accuracy of one step can influence the entire solution process. Small errors in initial data interpretation can lead to significant discrepancies in the final outcome \cite{xu2024ai,li2024bringing}.

\textbf{Role of Hallucinations.} One of the most complex challenges in leveraging MLLMs for scientific reasoning is determining whether hallucinations, the generation of information not grounded in the input data or knowledge base, are inherently harmful or potentially beneficial \cite{bai2024hallucination,liu2024survey}. While hallucinations are widely regarded as detrimental in factual tasks, their role in scientific reasoning is nuanced, particularly when considering the ultimate goal of advancing to Stage 4 of the research roadmap (\textit{i.e.}, Creative Hypothesis Generation) \cite{jiang2024survey}. In scientific reasoning, hallucinations can undermine trust and reliability by introducing inaccuracies in critical domains. For example, in physics, a hallucinated formula or principle might lead to invalid conclusions, while in chemistry, a fabricated reaction pathway could suggest impossible or even dangerous experiments. These inaccuracies not only hinder immediate problem-solving but can also propagate errors if used as a basis for further research \cite{li2024deceptive,chakraborty2024hallucination,xu2024hallucination}. 

\textbf{Ethical and Interpretability Issues.} Ethical concerns and model interpretability are major challenges when deploying MLLMs in high-stakes scientific domains, such as medical research or chemical engineering. MLLMs often lack transparency, making it difficult for users to understand how the model arrived at a particular conclusion \cite{alsaad2024multimodal}. Furthermore, ethical concerns arise when MLLMs are used to make decisions that could have significant consequences, such as in medical diagnoses or environmental impact assessments \cite{rahman2024survey}. In biology and medicine, the potential for biased reasoning in MLLMs, especially when trained on unbalanced datasets, could lead to harmful or misleading conclusions \cite{Stureborg2024LargeLM,wang2024fair}. An MLLM trained on biased medical data could fail to recognize critical symptoms in underrepresented populations, leading to erroneous diagnoses or treatment recommendations \cite{norori2021addressing,jones2024causal,flores2024addressing}.

\vspace{-2mm}
\section{Discussion: What Next?}
\label{sec:discussion}

\begin{figure}[ht!]
    \centering
    % \vspace{-2mm}
    \includegraphics[width=1 \linewidth]{figures/future_directions.png}
    \caption{Eight prospects for the future of MLLMs in the field of multimodal scientific reasoning. We base our core expectation on developing unified scientific MLLMs, and further elaborate our prospects from four high-level aspects: input side, output side, environments interact with itself, and internal reasoning schemes.}
    \label{fig:future_directions}
    % \vspace{-4mm}
\end{figure}


Building on the challenges outlined in Section \ref{sec:challenges}, it is evident that while MLLMs hold great promise in advancing scientific reasoning, targeted solutions must be developed to address the limitations. In this section, we explore eight key perspectives for improving MLLMs in scientific reasoning tasks, as illustrated in Figure \ref{fig:future_directions}.

\textbf{The Necessity of Unified Scientific MLLMs.}  
Although many domain-specific models have achieved remarkable performance in specialized scientific fields, exploring unified scientific MLLMs remains a critical pursuit \cite{taylor2022galactica}. Domain-specific models are optimized for particular areas (summary of scientific MLLMs can be seen in Appendix \ref{app:multimodal_scillm}), but they often lack the ability to integrate knowledge across disciplines \cite{wang2023survey,shi2024continual}. In contrast, a unified MLLM could facilitate interdisciplinary reasoning, leveraging connections between fields to tackle complex problems that require holistic understanding, such as climate change modeling \cite{nguyen2023climax} or biomedical research \cite{wang2023pre}.  

For example, a unified scientific MLLM could simultaneously analyze chemical reaction pathways and their biological implications, enabling breakthroughs in drug discovery \cite{oniani2024emerging,guan2024drug}. Similarly, it could integrate physics-based simulations with mathematical optimization to design more efficient renewable energy systems \cite{gao2024physically,xu2024survey}. 
% Achieving this vision requires developing training paradigms that emphasize both breadth and depth, combining cross-domain data with mechanisms for retaining domain-specific expertise. 

\textbf{Improving Multimodal Datasets.} A critical step in advancing MLLMs' capabilities is the improvement of multimodal datasets \cite{gadre2024datacomp,rahate2022multimodal,bayoudh2022survey}. Current datasets often lack the richness and variety required to train models effectively across disciplines. For instance, in chemistry, existing datasets may focus heavily on molecular structures without providing sufficient textual descriptions of reaction mechanisms \cite{cao2023instructmol}. Similarly, in biology, while there are abundant images of anatomical structures, these are often not paired with detailed descriptions of biological processes \cite{tang2023explainable,zhang2024benchmark}. By creating multimodal datasets that include both high-quality images and comprehensive textual descriptions across all domains, the model can better learn to correlate visual features with their corresponding scientific explanations \cite{albalak2024survey,muennighoff2023scaling,yu2024large}.

For example, in physics, datasets that combine experimental setups with corresponding theoretical explanations could help improve a model’s understanding of underlying principles, such as energy conservation or force interactions. This integration would facilitate a more robust training process, ensuring that models can handle a wider range of scientific reasoning tasks. As a concrete suggestion, developing domain-specific multimodal datasets that cover not only the subject but also different teaching contexts (\textit{e.g.,} beginner vs. advanced materials) would help MLLMs generalize across varying levels of complexity \cite{shi2023large}.

\textbf{Integrating Expert Knowledge and Explainability.} Integrating expert knowledge into MLLMs can significantly enhance their ability to reason accurately and logically \cite{pan2024unifying,yang2024give}. Expert knowledge, such as specialized theories in physics or established principles in biology, provides a framework within which the MLLM can operate. By embedding expert systems, prior research, and domain-specific knowledge into the models, MLLMs can make more informed predictions and deliver more robust scientific reasoning outputs \cite{lu2024chameleon}. Additionally, by integrating causal reasoning into MLLMs, the models can better explain the relationships between variables, such as causes and effects, rather than simply identifying correlations \cite{xiong2024improvingcausal,jin2024cladder,chi2024unveiling}. This allows the model to trace the reasoning process step-by-step, making the decision-making process more transparent. 

For example, in chemistry, integrating knowledge about chemical bonding, molecular dynamics, and reaction mechanisms can help guide the model’s predictions and interpretations \cite{zaki2024mascqa,m2024augmenting}. Additionally, enhancing the explainability of MLLMs is crucial for transparency \cite{dang2024explainable}. Ensuring that the model can justify its reasoning in a way that humans can easily understand, especially when making scientific claims, will increase its credibility and trustworthiness.
% Implementing explainable AI techniques that allow for detailed reasoning traces will provide users with a clearer understanding of how the model arrived at its conclusions, improving scientific reliability and fostering greater acceptance in research communities.

\textbf{Expanding Scientific Reasoning to Generative Tasks.}
While significant progress has been made in using MLLMs for problem-solving, error detection, and theorem proving \cite{yan2024survey}, the potential of these models in generative tasks remains underexplored. Generative tasks such as creating curriculum-aligned questions \cite{mulla2023automatic}, designing comprehensive syllabi \cite{hu2024teaching}, or enabling digital teaching assistants \cite{onu2024potential} are highly relevant to real-world applications, especially in educational contexts. Neglecting this dimension could limit the broader adoption of MLLMs in scenarios where dynamic, customizable, and scalable content creation is crucial.

For example, MLLMs could be used to generate topic-specific exam questions that align with diverse educational standards or assist in creating adaptive learning materials tailored to different proficiency levels \cite{denny2024desirable}. A practical use case might involve a digital teaching assistant that generates personalized lesson plans and explanations based on students' unique learning patterns and challenges. Actionable steps include fine-tuning MLLMs with datasets derived from educational content and incorporating user feedback loops to iteratively improve content relevance. 

\textbf{Hallucinations as a Creative Tool.} Hallucinations may play a constructive role in fostering creativity and innovation, particularly in exploratory scientific tasks \cite{huang2023survey,li2024dawn}. At the frontier of Stage 4 (shown in Sec. \ref{sec:roadmap}), MLLMs are expected to hypothesize beyond existing knowledge, where generating plausible but unverified information might stimulate novel ideas. For instance, in biology, an MLLM could propose hypothetical interactions between cellular components, which, though not yet observed, might inspire experimental validation. 

A critical challenge lies in striking the right balance between mitigating harmful hallucinations and leveraging beneficial ones. This requires a fine-grained approach to model design, where hallucination mechanisms are carefully controlled based on task context. For foundational reasoning tasks, strict adherence to validated knowledge is essential, while exploratory tasks may allow controlled deviations to inspire innovation. By addressing this challenge, our community can better leverage MLLMs to advance both reliable reasoning and innovative exploration \cite{jiang2024survey}.

\textbf{Interactive Feedback Systems.} Another powerful strategy involves the development of interactive feedback systems, which would allow MLLMs to engage with users dynamically, iterating on their answers based on user input or feedback \cite{abramson2022improving,shtarbanov2023sleeveio}. This interactive feature would not only enable models to adjust their reasoning during the problem-solving process but also allow them to ask clarifying questions, improving the overall user experience and enhancing the model’s output.

For example, in biology, a researcher could input a biological query related to an ecological model and receive initial results from the model. If the results are unclear or ambiguous, the researcher could provide feedback to guide the model toward more accurate predictions or interpretations. This back-and-forth interaction would provide a mechanism for error correction and refinement, ensuring that the model’s outputs align more closely with expert understanding \cite{pan2023automatically,wu2023fine}. 
% Additionally, incorporating a feedback loop would mitigate issues related to model hallucinations, as the system can learn from corrections in real-time \cite{xiao2024detecting}.


\textbf{Agent-based Collaboration.} A promising avenue for future development is agent-based collaboration, which involves the integration of multiple specialized agents working together to solve complex scientific problems \cite{xi2023rise,guo2024large,wang2024survey}. Each agent could be tailored to handle specific scientific tasks, such as mathematical reasoning, chemical reaction prediction, or biological system analysis. These agents could communicate and collaborate with each other to cross-check information, validate hypotheses, and combine knowledge from their respective domains \cite{hao2023reasoning,chen2023agentverse}.

For instance, in a physics problem involving both mechanics and electromagnetism, an agent focused on classical mechanics could collaborate with an agent specialized in electromagnetism to deliver a comprehensive solution that accounts for the interactions between mechanical forces and electromagnetic fields. The agents would share insights, identify potential errors, and improve each other’s reasoning in a cooperative manner. By building a system where multiple agents, each bringing a unique expertise, work collaboratively, MLLMs could approach complex scientific reasoning tasks with higher accuracy and robustness \cite{guo2024large,zhao2024expel,wu2023autogen}.

\textbf{Evolving Reasoning Schemes.} Current reasoning architectures in MLLMs remain constrained by opaque, monolithic designs that limit adaptability to diverse scientific domains \cite{besta2025reasoning}. Existing paradigms of Reasoning Large Models (RLMs) bifurcate into implicit RLMs (\textit{e.g.,} QwQ \cite{teamqwq}), where reasoning is embedded in model weights as a black box, and explicit RLMs (\textit{e.g.,} LLaMA-Berry \cite{zhang2024llama} \& o1 \cite{jaech2024o1}), which deploy structured reasoning strategies like Monte Carlo Tree Search (MCTS) or Beam Search with modular components. While explicit methods enable stepwise evaluation and refinement, their reliance on fixed templates and proprietary training schemes hinders reproducibility and domain-specific customization.

To advance scientific reasoning, future MLLMs should integrate three innovations: (i) dynamic reasoning structures (\textit{e.g.,} nested graphs) that adapt to multimodal inputs; (ii) process-based supervision with stepwise uncertainty metrics (\textit{e.g.,} token-level entropy) to refine domain-specific reasoning paths; and (iii) open-source, composable toolkits for hybrid training (\textit{i.e.,} Supervised Fine-Tuning + Reinforcement Learning phases) that decouple policy/value models, enabling collaborative, cost-efficient optimization across scientific disciplines \cite{besta2025reasoning}.


% \vspace{-4mm}
\section{Alternative Views}
\label{sec:alternative_view}
While this paper advocates for leveraging MLLMs to advance scientific reasoning, it is important to acknowledge and address alternative perspectives that question the feasibility, necessity, or effectiveness of this paradigm. 
% Below, we discuss two key opposing perspectives and provide counterarguments to address these concerns.
\vspace{-1mm}
\subsection{Domain-Specific Models as a Superior Alternative}
\label{sec:alternative1}

One argument suggests that \textit{highly specialized, domain-specific models tailored to individual scientific disciplines may outperform general-purpose MLLMs in reasoning tasks}, as indicated in Figure \ref{fig:alternative_views}(a). Proponents of this view highlight that scientific reasoning often requires deep domain expertise, nuanced understanding, and customized data processing pipelines that are difficult to replicate in generalized multimodal architectures \cite{zhang2024scientific,barman2025large}. For example, domain-specific models like AlphaFold for protein structure prediction \cite{jumper2021highly} or symbolic computation tools for solving mathematical problems \cite{mirzadeh2024gsm,lu2021inter} excel precisely because of their narrow focus.

\textbf{Counterargument.} While domain-specific models have demonstrated remarkable success in narrow applications, they lack the flexibility to generalize across multiple domains or integrate diverse modalities of data. Scientific reasoning increasingly involves interdisciplinary approaches, such as bioinformatics combining biology and computational techniques, or climate science requiring both geospatial and textual analysis \cite{reddy2024towards}. MLLMs, by design, offer the ability to process and reason over heterogeneous data sources, enabling a broader and more integrative approach \cite{zhang2024comprehensive}. Furthermore, domain-specific knowledge can still be fine-tuned within MLLMs, allowing these systems to leverage the best of both generalization and specialization \cite{chen2023fine}.
\vspace{-2mm}
\subsection{Risks of Over-reliance on MLLMs}
\label{sec:alternative2}

\begin{figure}[t!]
    \centering
    % \vspace{-2mm}
    \includegraphics[width=1 \linewidth]{figures/alternative_view.png}
    \caption{Illustrations of alternative view 1 (a) and view 2 (b), as well as our corresponding counterarguments.}
    \label{fig:alternative_views}
    \vspace{-8mm}
\end{figure}

Another valid concern is \textit{the potential over-reliance on MLLMs, which could exacerbate issues such as hallucination and lack of explainability}, as shown in Figure \ref{fig:alternative_views}(b). Critics argue that MLLMs, while powerful, are prone to generating plausible-sounding but incorrect or unsubstantiated outputs. This risk is particularly concerning in scientific reasoning, where accuracy and rigor are paramount \cite{bai2024hallucination}. Additionally, the black-box nature of these models makes it difficult for researchers to validate their reasoning processes or trust their conclusions, which could hinder their adoption in critical scientific applications \cite{cambria2024xai,rodis2024multimodal,dang2024explainable}.

\textbf{Counterargument.} These concerns are valid and underscore the need for a cautious and measured approach to MLLM adoption. However, rather than dismissing MLLMs outright, these issues highlight areas for improvement. For example, integrating explainability mechanisms, such as visual attention maps \cite{chefer2021generic,dehimi2024attention} or rationale generation \cite{hu2024learning,wu2024usable}, can enhance transparency. Additionally, hybrid models that combine MLLMs with symbolic reasoning \cite{li2024deceptive,zhou2024mitigating} or expert systems \cite{guan2024mitigating,niu2024mitigating} can mitigate risks of hallucination while maintaining the strengths of multimodal reasoning. Finally, iterative feedback loops and human-in-the-loop systems can ensure reliability in reasoning workflows \cite{xiao2024detecting,zou2024look,zheng2024reefknot}.
% \vspace{-4mm}
\section{Conclusion}
\label{conlcusion}
This paper aims to emphasize the transformative potential of MLLMs in advancing scientific reasoning across diverse domains, including mathematics, physics, chemistry, and biology. Our key position is that MLLMs represent a significant step forward in enabling more comprehensive and accurate reasoning about scientific phenomena, bridging gaps between different types of data and reasoning methods. To support this stance, we reviewed the current state of MLLM applications in scientific reasoning, outlined key challenges, and proposed actionable insights for future progress.

Our objective is to raise awareness of the potential for MLLMs to reshape scientific reasoning and provide a foundation for future research in this space. By proposing a structured research roadmap and highlighting areas for innovation, we aim to guide the development of MLLMs in ways that can enhance generalization and multimodal integration across scientific fields, moving toward achieving AGI. 

% While this position paper may invite varied opinions, our goal is to spark discussion, inspire new approaches, and foster collaboration among researchers. 



% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

% \clearpage
\section*{Impact Statement}
\label{impact_statement}
This position paper seeks to redefine the role of MLLMs in advancing scientific reasoning, advocating for their transformative potential across domains such as mathematics, physics, chemistry, and biology. By integrating diverse modalities, MLLMs present a unique opportunity to overcome limitations in current reasoning frameworks, enabling richer, more comprehensive analytical capabilities. Our vision outlines a future where scientific discovery is accelerated through the synergistic application of MLLMs, offering enhanced precision, adaptability, and scalability.

While our primary focus is on advancing academic research and methodological innovation, we also anticipate meaningful societal impacts, such as improved problem-solving approaches in education, healthcare, and other knowledge-intensive sectors. Importantly, we emphasize the ethical imperatives of leveraging MLLMs responsibly, ensuring transparency, fairness, and interpretability in their applications to scientific reasoning. Although no immediate risks are evident, we recognize the need for continuous monitoring of societal implications as MLLMs become increasingly integrated into critical decision-making processes. This paper aims to inspire both researchers and practitioners to embrace this interdisciplinary frontier, fostering collaboration and innovation toward achieving AGI.

\bibliography{position}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Formulation of Scientific Reasoning Task}
\label{app:task_formulation}
Mathematically, the scientific reasoning process can be modeled as an optimization task over a multimodal knowledge graph $G = (V, E)$, where $V$ denotes nodes (concepts, entities, or data points) and $E$ represents edges (relationships or interactions). Let $X_m$ represent the modality-specific input data, including mandatory modalities such as textual descriptions $X_t$ and visual representations $X_v$, as well as optional modalities like numerical data $X_n$ or other specialized inputs $X_o$. The goal is to predict or infer target outputs $Y$ based on a reasoning function $f_\theta$, parameterized by $\theta$, over $G$:
\[
Y = f_\theta(G, X_m) = f_\theta(V, E, X_t, X_v, X_n, X_o).
\]

\textbf{Mathematics:} Consider solving a geometry problem where $X_t$ provides the problem description, $X_v$ includes the geometric diagram, and $X_n$ optionally contains measurements or coordinates. The reasoning function $f_\theta$ integrates these inputs to infer the solution, such as identifying the area of a triangle.

\textbf{Physics:} In a physics experiment, $X_t$ describes the theoretical background, $X_v$ presents the experimental setup image, and $X_n$ includes sensor data such as velocity or temperature measurements. The function $f_\theta$ predicts the outcome or validates a hypothesis.

\textbf{Chemistry:} A multimodal analysis of a chemical reaction could include $X_t$ for the reaction mechanism, $X_v$ for molecular structure visualizations, and $X_o$ for spectroscopic data. The model predicts reaction yield or product properties.

\textbf{Biology:} When studying gene expression, $X_t$ describes the biological context, $X_v$ contains microscope images, and $X_n$ optionally includes numerical gene expression levels. The reasoning function predicts gene interactions or cellular behavior.

These examples illustrate how MLLMs can handle diverse inputs, integrating mandatory and optional modalities to perform complex scientific reasoning tasks.


\section{Four Phases of Research Roadmap}
\label{app:roadmap}

MLLMs have seen significant advancements in recent years, positioning their reasoning capabilities as a pivotal element on the pathway to achieving Artificial General Intelligence (AGI) \cite{wang2024exploring,yan2024survey,sun2023survey,jin2024reasoning,yan2024urbanclip,wei2024enhancing}. However, realizing AGI requires navigating a structured roadmap characterized by progressively complex reasoning tasks. This section outlines the Four Phases of Research Roadmap, each delineated by unique data requirements, reasoning mechanisms, generalization abilities, and impact. Table~\ref{tab:dimensions} provides a comparative overview of these phases.

\subsection{Phase 1: Broad Knowledge and Recognition}

In this phase, MLLMs prioritize high diversity and low specificity in data and knowledge. Tasks involve integrating vast and diverse datasets, emphasizing retrieval and alignment mechanisms. For example, MLLMs excel in synthesizing encyclopedic knowledge, aligning visual inputs (e.g., diagrams) with textual descriptions, and providing domain-specific insights. The generalization is limited to specific domains, resulting in low-impact applications like data retrieval and integration.

\subsection{Phase 2: Analogical Reasoning and Generalization}

This stage emphasizes medium diversity and specificity in data, leveraging contextual understanding to enable relational and analogical reasoning. For instance, MLLMs may draw analogies between chemical reaction pathways and electrical circuits, enhancing interdisciplinary insights. The models exhibit medium-level generalization across domains, allowing for moderate complexity tasks like explaining scientific phenomena using cross-domain analogies.

\subsection{Phase 3: Insightful Inference}

As reasoning tasks grow in complexity, MLLMs in this phase focus on low diversity but high specificity datasets. Predictive reasoning mechanisms are central, enabling context-specific inferences. For example, a model might predict the behavior of a physical system under certain constraints or optimize complex processes like material design. These capabilities lead to high-impact applications, including scientific optimization and inferential problem-solving.

\subsection{Phase 4: Creative Hypothesis Generation}

The final phase demands both high diversity and high creativity in data. Generative reasoning mechanisms empower MLLMs to propose innovative solutions and simulate hypotheses. For instance, models might design novel molecules for drug discovery or hypothesize ecological models for sustainable ecosystems. This phase represents very high-impact applications, bridging the gap between scientific discovery and innovation.

\subsection{Summary}

In summary, the Four Phases of Research Roadmap reflect the increasing complexity and potential of MLLMs in scientific reasoning. While current MLLMs have demonstrated impressive capabilities, they remain far from achieving AGI \cite{mumuni2025large,wang2024lighthouse,feng2024far,fei2022towards}. The community must continue to explore advanced reasoning abilities, fostering collaboration and innovation along this roadmap to address the challenges of AGI-driven scientific reasoning.


% highlighted format needed
\begin{table*}[!t]
  \centering
  \caption{Comparison across four stages along key dimensions.}
  \SetTblrInner{rowsep=0.9pt}
  \begin{tblr}{
    colspec = {ccccc},
    row{1} = {bg=gray!25},
    row{even} = {bg=gray!10},
  }
  \toprule
  { \textbf{Dimension}} & 
  { \textbf{Broad Knowledge} \\ \textbf{and Recognition}} & 
  { \textbf{Analogical Reasoning} \\ \textbf{and Generalization}} & 
  { \textbf{Insightful} \\ \textbf{Inference}} & 
  { \textbf{Creative Hypothesis} \\ \textbf{Generation}}\\
  \midrule
  { \textbf{Data and Knowledge} \\ \textbf{Requirements}} & 
  { High diversity, \\ low specificity} & 
  {Medium diversity,\\medium specificity} & 
  {Low diversity,\\high specificity} & 
  { High diversity, \\ high creativity} \\
  { \textbf{Reasoning} \\ \textbf{Mechanisms}} &
  {Low complexity \\ (retrieval, alignment)} &
  { Medium complexity \\ (relational, analogical)} &
  { High complexity \\ (predictive)} &
  { Very high complexity \\ (generative)} \\
  { \textbf{Model} \\ \textbf{Generalization}} &
  {Low \\ (domain-specific)} &
  { Medium \\ (cross-domain)} &
  {High \\ (context-specific)} &
  { Very high \\ (innovative)} \\
  { \textbf{Applications} \\ \textbf{and Impact}} &
  { Low impact \\ (retrieval, integration)} &
  { Medium impact \\ (interdisciplinary insights)} &
  { High impact \\ (optimization, inference)} &
  { Very high impact \\ (discovery, innovation)} \\
  \bottomrule
  \end{tblr}
  \label{tab:dimensions}
  \vskip-0.5em
\end{table*}

% \clearpage
\section{Data Differences among Four Domains}
\label{app:domain_data_differences}

The reasoning capabilities of MLLMs make them particularly well-suited for processing heterogeneous multimodal data \cite{pattnayak2024survey,li2024benchsurvey,li2024benchsurvey2}. By integrating and analyzing diverse data formats such as text, images, and structured information, MLLMs enable more comprehensive insights across various scientific disciplines. This section highlights the unique data characteristics of four domains: mathematics, physics, chemistry, and biology, as summarized in Table~\ref{tab:subject_features}.

\subsection{Mathematics: Structured Abstraction}

Mathematical data is characterized by its symbolic equations, graphs, and geometric figures. These data types are highly structured and abstract, requiring precise interpretation and manipulation. Visual features such as coordinate axes and geometric shapes often complement formal textual elements like equations and proofs. The integration of these modalities enables MLLMs to solve complex mathematical problems and support theorem proving.

\subsection{Physics: Real-world Dynamics}

Physics data encompasses diagrams (e.g., vector and circuit diagrams), graphs, and descriptions of real-world phenomena. Its data structure reflects system dynamics and real-world applications, combining descriptive text with visual representations like force vectors or particle motion. MLLMs leverage these multimodal inputs to model physical systems and predict outcomes under varying conditions.

\subsection{Chemistry: Molecular and Symbolic}

Chemistry relies heavily on molecular structures, reaction pathways, and the periodic table. The data is both symbolic and structural, involving visual elements such as 3D molecular models and reaction schemes. Textural features include chemical equations and reaction mechanisms. MLLMs facilitate understanding chemical interactions and even predicting new compounds or reaction outcomes.

\subsection{Biology: Conceptual Complexity}

Biological data is diverse, covering anatomical diagrams, cellular structures, and ecological models. Its structure is conceptual and often involves biological and anatomical representations. Visual inputs like cell diagrams and ecosystem models are paired with textual descriptions of processes and interactions. MLLMs support tasks such as identifying biological patterns and simulating ecological dynamics.

\subsection{Summary and Future Directions}

In summary, MLLMs demonstrate strong reasoning capabilities across mathematics, physics, chemistry, and biology by integrating diverse multimodal data. However, their potential is not confined to these four disciplines. Future research should explore reasoning capabilities in broader domains such as geospatial analysis \cite{roberts2024charting,mai2024opportunities,hao2024urbanvlp,zhong2024urbancross} and coding \cite{li2024mmcode,guo2024deepseekcode,di2024codefuse,hui2024qwen2code}, which demand advanced generalization abilities. Such endeavors are crucial for achieving the comprehensive reasoning capabilities envisioned in the AGI roadmap.


\begin{table*}[!t]
  \centering
  \caption{Comparison of data features among four domains within the scope of this position paper.}
  \SetTblrInner{rowsep=0.9pt}
  \begin{tblr}{
    colspec = {ccccc},
    row{1} = {bg=gray!25},  % 表头底色
    row{even} = {bg=gray!10}  % 偶数行底色
  }
    \toprule
    {\textbf{Feature/Domain}} 
      & {\textbf{Mathematics}} 
      & {\textbf{Physics}} 
      & {\textbf{Chemistry}}
      & {\textbf{Biology}} \\
    \midrule
    {\textbf{Data Types}} 
      & {Symbolic equations,\\ graphs, geometric figures} 
      & {Diagrams (vector, \\circuit), graphs, \\real-world phenomena}
      & {Molecular structures,\\ reaction pathways,\\ periodic table}
      & {Anatomical diagrams,\\ cellular structures,\\ ecological models} \\
    {\textbf{Data Structure}}
      & {Abstract, highly structured,\\ formal notation}
      & {Real-world applications,\\ system dynamics}
      & {Symbolic and molecular,\\ structural}
      & {Conceptual, biological,\\ and anatomical} \\
    {\textbf{Visual Features}}
      & {Coordinate axes,\\ geometric shapes}
      & {Diagrams e.g., force vectors,\\ particle motion}
      & {3D molecular models,\\ reaction schemes}
      & {Photos, cell diagrams,\\ ecosystem models} \\
    {\textbf{Textural Features}}
      & {Equations, proofs,\\ formal definitions}
      & {Descriptive, experimental \\setups, theories}
      & {Chemical equations,\\ reaction mechanisms}
      & {Biological processes,\\ ecological interactions} \\
    \bottomrule
  \end{tblr}
  \label{tab:subject_features}
  \vskip-0.5em
\end{table*}


\clearpage
\section{Multi-Domain Scientific Reasoning Benchmark}
\label{app:multidomain_scibench}
The emergence of multi-domain scientific reasoning benchmarks has played a pivotal role in advancing AI models' ability to reason across diverse scientific domains. These benchmarks vary in their focus on multimodal integration, educational levels, and the comprehensiveness of domain coverage, as summarized in Table~\ref{tab:multi_domain_bench}.

\textbf{Comprehensive Domain Coverage:} Several benchmarks, such as \textbf{MMMU-Pro}, \textbf{CMMMU}, and \textbf{SciEval}, provide extensive domain coverage, including mathematics, physics, chemistry, and biology. These benchmarks target diverse educational contexts, ranging from primary education to PhD-level tasks, ensuring broad applicability. Notably, \textbf{MMMU-Pro} and \textbf{SciBench} have become instrumental for college-level evaluation, while \textbf{CMMU} extends its scope to younger learners, addressing a critical gap in foundational scientific reasoning.

\textbf{Multimodal Reasoning:} The integration of multimodal capabilities has become a defining feature of contemporary benchmarks. Over 60\% of the surveyed benchmarks, such as \textbf{EXAMS-V}, \textbf{SciBench}, and \textbf{ScienceQA}, incorporate multimodal tasks that involve textual, visual, and symbolic reasoning. These tasks reflect real-world problem-solving scenarios where multiple modalities interact, making them essential for evaluating the holistic reasoning capabilities of advanced AI models.

\textbf{Specialized vs. General Benchmarks:} While benchmarks like \textbf{OlympiadBench} and \textbf{OlympicArena} are tailored to high-stakes competitions, their narrow focus on specific tasks, such as Olympiad-level challenges, limits their generalizability. Conversely, resources like \textbf{AGIEval} and \textbf{SciEval} aim to provide a broader evaluation of scientific reasoning, covering multiple domains across various educational levels. However, their lack of multimodal integration highlights the need for more versatile benchmarks.

% \textbf{Challenges and Gaps:} Despite the diversity of available benchmarks, challenges persist. Many datasets are domain-specific, focusing heavily on one or two areas while neglecting interdisciplinary reasoning. Additionally, most benchmarks lack real-world complexity, such as incorporating dynamic feedback, continuous learning, or collaborative problem-solving, which are essential for practical applications.

\textbf{Future Directions:} The future of multi-domain scientific reasoning benchmarks lies in developing unified frameworks that combine multimodal reasoning, domain comprehensiveness, and adaptability across educational levels. Incorporating elements like interactive feedback systems and collaborative reasoning tasks will bridge the gap between theoretical evaluation and practical applications, fostering the next generation of scientific reasoning models.



\begin{table*}[htp]
\caption{Comparison of multi-domain scientific reasoning benchmarks.}
\label{tab:multi_domain_bench}
	\SetTblrInner{rowsep=0.9pt}
	\begin{tblr}{
	colspec = {ccccccccc},
	row{1-2} = {bg=gray!25},
	row{even[3-28]} = {bg=gray!5}
	}
 \toprule
\SetCell[r=2]{c}\textbf{Paper} & 
\SetCell[r=2]{c}\makecell{\textbf{Organization}}&
\SetCell[r=2]{c}\makecell{\textbf{Venue}}&
\SetCell[r=2]{c}\makecell{\textbf{Multimodal}}&
\SetCell[r=2]{c}\makecell{\textbf{Education}\\\textbf{Level}} &
\SetCell[c=4]{c}{\textbf{Domain(s)}}& & &
 \\
\cmidrule[lr]{6-9}
  & & & &  & \textbf{Math} & \textbf{Physics} &  Chemistry & \textbf{Biology}\\
  \midrule
\textbf{EMMA}~\cite{hao2025can} 
  & UESTC 
  & arXiv'25
  & \checkmark 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & 
\\
\textbf{MMVU}~\cite{zhao2025mmvumeasuring} 
  & Yale University 
  & arXiv'25
  & \checkmark 
  & College
  &  
  & \checkmark 
  & \checkmark 
  & \checkmark
\\
\textbf{SciBench}~\cite{wang2023scibench} 
  & UCLA 
  & ICML'24 
  & \checkmark 
  & College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & 
\\
\textbf{MMMU}~\cite{yue2024mmmu} 
  & \makecell[cc]{University of Waterloo \&\\Ohio State University} 
  & CVPR'24 
  & \checkmark 
  & College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
  \textbf{EXAMS-V}~\cite{das2024exams} 
  & MBZUAI 
  & ACL'24
  & \checkmark 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
  \textbf{ArxivQA/Cap}~\cite{li2024multimodalarxiv} 
  & HKU
  & ACL'24
  & \checkmark 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{OlympiadBench}~\cite{he2024olympiadbench} 
  & Tsinghua University
  & ACL'24 
  & \checkmark
  & Competition 
  & 
  & 
  & \checkmark 
  & \checkmark 
\\
\textbf{SceMQA}~\cite{liang2024scemqa} 
  & University of Notre Dame
  & ACL Short'24 
  & \checkmark
  & College
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{SciEval}~\cite{sun2024scieval} 
  & Shanghai Jiaotong University 
  & AAAI'24 
  & 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{CMMU}~\cite{he2024cmmu} 
  & \makecell[cc]{Beijing Academy of\\Artificial Intelligence}
  & IJCAI'24 
  & \checkmark 
  & \makecell[cc]{Primary/\\Middle/High} 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{AGIEval}~\cite{zhong-etal-2024-agieval} 
  & Microsoft 
  & NAACL'24 
  & 
  & {High/College} 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{CMMLU}~\cite{li2024cmmlu} 
  & MBZUAI 
  & ACL Findings'24
  & 
  & High/College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{MMWorld}~\cite{he2024mmworld} 
  & UCSC 
  & arXiv'24 
  & \checkmark 
  & General
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{MMMU-Pro}~\cite{yue2024mmmupro} 
  & CMU 
  & arXiv'24 
  & \checkmark 
  & College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{CMMMU}~\cite{zhang2024cmmmu} 
  & HKUST 
  & arXiv'24 
  & \checkmark 
  & College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{M4U}~\cite{wang2024m4u} 
  & Chinese Academy of Sciences
  & arXiv'24 
  & \checkmark 
  & College 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{MMSci}~\cite{li2024mmsci} 
  & UCSB
  & arXiv'24 
  & \checkmark 
  & PhD 
  & 
  & \checkmark 
  & \checkmark 
  & \checkmark
\\
\textbf{OlympicArena}~\cite{huang2024olympicarena} 
  & Shanghai Jiaotong University
  & arXiv'24 
  & 
  & Competition 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{LitQA2}~\cite{skarlinski2024language} 
  & FutureHouse Inc.
  & arXiv'24 
  &  
  & {General} 
  & 
  & 
  & \checkmark 
  & \checkmark
\\
\textbf{ScienceAgentBench}~\cite{chen2024scienceagentbench} 
  & OSU
  & arXiv'24 
  &  
  & {General} 
  & 
  & 
  & \checkmark 
  & \checkmark
\\
\textbf{JEEBench}~\cite{arora2023have} 
  & \makecell[cc]{Microsoft \&\\UC Berkeley} 
  & EMNLP'23 
  & 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark 
  &  
\\
\textbf{M3Exam}~\cite{zhang2023m3exam} 
  & Alibaba
  & NeurIPS'23 
  & \checkmark 
  & {Primary/Middle/High} 
  & \checkmark
  & 
  & \checkmark 
  &  
\\
\textbf{LitQA}~\cite{lala2023paperqa} 
  & FutureHouse Inc.
  & arXiv'23 
  &  
  & {General} 
  & 
  & 
  & \checkmark 
  & \checkmark
\\
\textbf{ScienceQA}~\cite{lu2022learn} 
  & UCLA 
  & NeurIPS'22 
  & \checkmark 
  & {Primary/High} 
  &  
  & \checkmark 
  & \checkmark 
  & \checkmark 
\\
\textbf{IconQA}~\cite{lu2021iconqa} 
  & UCLA 
  & NeurIPS'21 
  & \checkmark 
  & General 
  & \checkmark 
  & \checkmark 
  &  
  &  
\\
\textbf{MMLU}~\cite{hendrycks2021mmlu} 
  & UC Berkeley 
  & ICLR'21 
  & 
  & General 
  & \checkmark 
  & \checkmark 
  & \checkmark
  & \checkmark
\\
\bottomrule
\end{tblr}
\vskip-0.5em
\end{table*}



\clearpage
\section{Multimodal Scientific (M)LLMs}
\label{app:multimodal_scillm}
Scientific (M)LLMs represent an emerging class of models that integrate multiple modalities to tackle complex problems across various scientific disciplines, as summarized in Table \ref{tab:multimodal_scillm}. These models leverage massive datasets combining text, images, graphs, and other forms of scientific data to provide deeper insights and advanced reasoning capabilities. Unlike traditional models, which typically focus on either textual or visual information, scientific MLLMs are designed to harmonize and synthesize diverse sources of scientific knowledge, enabling enhanced performance in tasks such as mathematical problem solving, chemical reaction prediction, biological analysis, and physical simulations \cite{morris2023scientists,pei2024leveraging,reddy2024towards,zhang2024comprehensive}.


\begin{table*}[htp]
\caption{Summary of scientific (M)LLMs.}
\label{tab:multimodal_scillm}
	\SetTblrInner{rowsep=0.9pt}
	\begin{tblr}{
	colspec = {ccccccccc},
	row{1-2} = {bg=gray!25},
	row{even[3-60]} = {bg=gray!5}
	}
 \toprule
\SetCell[r=2]{c}\textbf{Paper} & 
\SetCell[r=2]{c}\makecell{\textbf{Organization}}&
\SetCell[r=2]{c}\makecell{\textbf{Venue}}&
\SetCell[r=2]{c}\makecell{\textbf{Multimodal}}&
\SetCell[r=2]{c}\makecell{\textbf{Parameter}} &
\SetCell[c=4]{c}{\textbf{Domain(s)}}& & &
 \\
\cmidrule[lr]{6-9}
  & & & &  & Math & Physics &  Chemistry & Biology\\
  \midrule
\textbf{Galactica}~\cite{taylor2022galactica} 
  & Meta
  &  
  & \checkmark 
  & 125M/1.3B/6.7B/30B/120B
  & \checkmark 
  & \checkmark 
  & \checkmark 
  & \checkmark
\\

\textbf{LLM-SR}~\cite{Shojaee2024LLMSRSE}
  & Virginia Tech
  & 
  & 
  & 8x7B
  & \checkmark
  & \checkmark
  & 
  & \checkmark
\\

\textbf{SciLitLLM}~\cite{Li2024SciLitLLMHT}
  & USTC
  & 
  & 
  & 7B/14B
  & 
  & \checkmark
  & \checkmark
  & \checkmark
\\

\textbf{Darwin series}~\cite{Xie2023DARWINSD}
  & University of New South Wales
  & 
  & 
  & 7B
  & 
  & \checkmark
  & \checkmark
  & 
\\

\textbf{SPMM}~\cite{SPMM}
  & KAIST
  & Nature Communications'24
  & \checkmark
  & -
  & 
  & 
  & \checkmark
  & \checkmark
\\

\textbf{InstructMol}~\cite{Cao2023InstructMolMI}
  & IDEA \& HKUST
  & COLING'25
  & \checkmark
  & 7B
  & 
  & 
  & \checkmark
  & \checkmark
\\

\textbf{BioinspiredLLM}~\cite{Luu2023BioinspiredLLMCL}
  & MIT
  & Advanced Science'24
  & 
  & 13B
  & 
  & 
  & \checkmark
  & \checkmark
\\

\textbf{nach0}~\cite{Livne2023nach0MN}
  & NVIDIA
  & Chemical Science'24
  & \checkmark
  & 250M/780M
  & 
  & 
  & \checkmark
  & \checkmark
\\

\textbf{Mole-BERT}~\cite{Xia2023MoleBERTRP}
  & Westlake University
  & ICLR’23
  & 
  & -
  & 
  & 
  & \checkmark
  & \checkmark
\\

\textbf{BioGPT}~\cite{Luo2022BioGPTGP}
  & Microsoft
  & Briefings in bioinformatics'22
  & 
  & 355M
  & 
  & 
  & 
  & \checkmark
\\

\textbf{Evolla}~\cite{Zhou2025evolla}
  & Westlake University
  & 
  & \checkmark
  & 80B
  & 
  & 
  & 
  & \checkmark
\\

\textbf{Prollama}~\cite{Lv2024ProLLaMAAP}
  & Peking University
  & 
  & 
  & 7B
  & 
  & 
  & 
  & \checkmark
\\

\textbf{Chemdfm}~\cite{Zhao2024ChemDFMAL}
  & Shanghai Jiaotong University
  & 
  & 
  & 13B
  & 
  & 
  & \checkmark
  & 
\\

\textbf{ChemDFM-X}~\cite{Zhao2024ChemDFMXTL}
  & Shanghai Jiaotong University
  & 
  & \checkmark
  & 8B
  & 
  & 
  & \checkmark
  & 
\\

\textbf{ChemLLM}~\cite{Zhang2024ChemLLMAC}
  & Shanghai AI Lab
  & 
  & 
  & 7B
  & 
  & 
  & \checkmark
  & 
\\

\textbf{GIT-Mol}~\cite{Liu2023GITMolAM}
  & Peng Cheng Lab
  & {Computers in Biology \\ and Medicine'24}
  & \checkmark
  & 700M
  & 
  & 
  & \checkmark
  & 
\\

\textbf{MolGPT}~\cite{Bagal2021MolGPTMG}
  & {International Institute of \\ Information Technology}
  & {Journal of Chemical Information \\ and Modeling'21}
  & 
  & 6M
  & 
  & 
  & \checkmark
  & 
\\

\textbf{MOOSE-Chem}~\cite{Yang2024MOOSEChemLL}
  & NTU \& Shanghai AI Lab
  & 
  & 
  & -
  & 
  & 
  & \checkmark
  & 
\\

\textbf{BatGPT-Chem}~\cite{Yang2024BatGPTChemAF}
  & Shanghai Jiaotong University
  & 
  & 
  & 15B
  & 
  & 
  & \checkmark
  & 
\\

\textbf{DARWIN 1.5}~\cite{Xie2024DARWIN1L}
  & University of New South Wales
  & 
  & 
  & 7B
  & 
  & 
  & \checkmark
  & 
\\

\textbf{MolMetaLM}~\cite{Wu2024MolMetaLMAP}
  & Central South University
  & 
  & 
  & -
  & 
  & 
  & \checkmark
  & 
\\

\textbf{SMI-TED}~\cite{Soares2024SMI-TED}
  & IBM
  & 
  & 
  & 289M
  & 
  & 
  & \checkmark
  & 
\\

\textbf{MathCoder}~\cite{Wang2023MathCoderSC}
  & CUHK
  & ICLR'24
  & 
  & 7B/13B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MAmmoTH1}~\cite{Yue2023MAmmoTHBM}
  & UWaterloo
  & ICLR’24
  & 
  & 7B/13B/70B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Math-LLaVA}~\cite{Shi2024MathLLaVABM}
  & NUS
  & EMNLP Finding'24
  & 
  & 13B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{JiuZhang 2.0}~\cite{Zhao2023JiuZhang2.0A}
  & RUC \& iFLYTEK
  & KDD'23
  & 
  & -
  & \checkmark
  & 
  & 
  & 
\\

\textbf{JiuZhang 1.0}~\cite{Zhao2022JiuZhang1.0AC}
  & RUC \& iFLYTEK
  & KDD'22
  & 
  & 145M
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Minerva}~\cite{Lewkowycz2022Minerva}
  & Google
  & NeurIPS’22
  & 
  & 8B/62B/540B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Hypertree Proof Search}~\cite{Lample2022HyperTreePS}
  & Meta
  & NeurIPS'22
  & 
  & -
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Qwen2.5-Math}~\cite{Yang2024Qwen25MathTR}
  & Alibaba
  & 
  & 
  & 1.5B/7B/72B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Qwen2-Math}~\cite{yang2024qwen2math}
  & Alibaba
  & 
  & 
  & 1.5B/7B/72B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Qwen2-Math-Instruct}~\cite{yang2024qwen2math}
  & Alibaba
  & 
  & 
  & 1.5B/7B/72B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MathGPT}~\cite{mathgpt}
  & TAL Group
  & 
  & \checkmark
  & 130B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{math-specialized Gemini \\ 1.5 Pro}~\cite{team2024geminipro}
  & Google
  & 
  & \checkmark
  & -
  & \checkmark
  & 
  & 
  & 
\\

\textbf{InternLM2-Math}~\cite{Ying2024InternLMMathOM}
  & Shanghai AI Lab
  & 
  & 
  & 1.8B/7B/20B/8x22B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{InternLM2.5-StepProver}~\cite{Wu2024InternLM25StepProverAA}
  & Shanghai AI Lab
  & 
  & 
  & 7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Llemma}~\cite{Azerbayev2023LlemmaAO}
  & Princeton University \& Eleuther AI
  & 
  & 
  & 7B/34B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{ChatGLM-Math}~\cite{Xu2024ChatGLMMathIM}
  & Zhipu AI
  & 
  & 
  & 32B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MetaMath}~\cite{Yu2023MetaMathBY}
  & Cambridge \& Huawei
  & 
  & 
  & 7B/13B/70B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MathGLM}~\cite{yang2023mathglm}
  & Tsinghua \& Zhipu AI
  & 
  & 
  & {10M/100M/335M/500M \\ /2B/6B/10B}
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MathGLM-Vision}~\cite{Yang2024MathGLMVisionSM}
  & Tsinghua \& Zhipu AI
  & 
  & \checkmark
  & 9B/19B/32B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Skywork-13B-Math}~\cite{skyworkmath}
  & SkyworkAI
  & 
  & \checkmark
  & 7B/13B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{DeepSeekMath}~\cite{Shao2024DeepSeekMathPT}
  & DeepSeek AI
  & 
  & 
  & 7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{DeepSeekProver-V1}~\cite{Xin2024DeepSeekProverAT}
  & DeepSeek AI
  & 
  & 
  & 7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{DeepSeek-Prover-V.15}~\cite{xin2024deepseekproverv15harnessingproofassistant}
  & DeepSeek AI
  & 
  & 
  & 7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Mathstral}~\cite{mistral2024mathstral}
  & Mistral AI
  & 
  & 
  & 7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{JiuZhang 3.0}~\cite{Zhou2024JiuZhang30EI}
  & RUC \& iFLYTEK
  & 
  & 
  & 7B/8B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Math-LLM}~\cite{liu2024mathllm}
  & East China Normal University
  & 
  & \checkmark
  & 8.26B/7B/72B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{GPT-f}~\cite{Polu2020gpt-f}
  & OpenAI
  & 
  & 
  & 160M/400M/700M/
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Rho-Math}~\cite{lin2024rhomath}
  & Microsoft
  & 
  & 
  & 1B/7B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{WizardMath}~\cite{Luo2023WizardMathEM}
  & Microsoft
  & 
  & 
  & 7B/70B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{Xwin-LM}~\cite{Ni2024XwinLMSA}
  & Microsoft
  & 
  & 
  & 7B/13B/70B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{MAmmoTH2}~\cite{Yue2024MAmmoTH2SI}
  & UWaterloo
  & 
  & 
  & 7B/8B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{GAIRMath-Abel}~\cite{gairmathabel}
  & Shanghai Jiaotong University
  & 
  & 
  & 7B/13B/70B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{KwaiYiiMath}~\cite{Fu2023KwaiYiiMathTR}
  & Kuaishou
  & 
  & 
  & 13B
  & \checkmark
  & 
  & 
  & 
\\

\textbf{k0-math}~\cite{k0math}
  & Moonshot AI
  & 
  & 
  & -
  & \checkmark
  & 
  & 
  & 
\\

\textbf{NuminaMath}~\cite{numina_math_7b}
  & Numina
  & 
  & 
  & 7B/72B
  & \checkmark
  & 
  & 
  & 
\\

\bottomrule
\end{tblr}
\vskip-0.5em
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
