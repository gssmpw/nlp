\section{Experimental Setup}


\textbf{Base LLMs.} We conduct experiments with various base LLMs, using Llama2-7B \cite{Llama2} as the foundation for the following variants:
\begin{compactenum}[i)]
\item \emph{Code-specific variant}: CodeLlama-7B \cite{codeLlama}, optimized for code and programming-related tasks.
\item \emph{Size variant}: Llama2-13B \cite{Llama2}, a larger-scale version of Llama2.
% \item \emph{Version variant}: Llama3.1 8B \cite{Llama3}, a more recent version with better multilingual capabilities.
\item \emph{Version variant}: Llama3 8B \cite{Llama3}, a more recent iteration with enhanced multilingual capabilities. 
\end{compactenum}

\noindent\textbf{Oracle LLM.} To ensure reproducibility, we employ Llama3.1-405B Instruct \cite{Llama3} as our Oracle model for generating the PoT dataset and assessing the quality of the code.

% \textbf{Machine Translation} We employ the distilled version\footnote{\scriptsize \url{https://huggingface.co/facebook/nllb-200-distilled-600M}} of NLLB-200 \cite{nllb} for translating inline comments.



\vspace{2mm}
\noindent \textbf{Evaluation.}
We evaluate model performance by measuring accuracy on the MGSM \cite{mgsm} dataset in a zero-shot setting using greedy decoding.
%
The study includes the following languages: English (en), German (de), French (fr), Spanish (es), Russian (ru), Chinese (zh), Japanese (ja), Thai (th), Swahili (sw), and Bengali (bn).
%
For CoT evaluation, numerical outputs are extracted via regular expressions and compared to labels, following \citet{mathoctopus}.
For PoT evaluation, generated programs are executed in a Python interpreter, with outputs compared to labels for accuracy.





\vspace{2mm}
\noindent \textbf{Measures}: As outlined in Table~\ref{tab:compare-metods}, in cross-lingual setting, we finetune each LLM independently on GSM8K \cite{cobbe2021gsm8k} and GSM8KPoT, using both \(\mathcal{D}^\texttt{GSM8KPoT}_\texttt{en}\) and \(\mathcal{D}^\texttt{GSM8KPoT}_\texttt{nc}\) variants.
%
For multilingual CoT, we finetune each LLM separately on MGSM8K Instruct Parallel and Cross \cite{mathoctopus}.
%
For multilingual PoT, we utilize the generated answers from GSM8KPoT and map the questions for each language in MGSM8K Instruct to create MGSM8KPoT.
%
To study the effects of inline comments, we create versions of GSM8K and MGSM8KPoT without inline comments by removing them from the original datasets.
%
Additionally, we generate a variation of MGSM8KPoT by applying machine translation.
%
We utilize nllb-200-distilled-600M~\cite{nllb} for translating inline comments, ensuring coverage across all languages in this study.



% \textcolor{blue}{(Jab) shorten, highlight only 3 + move full to appendix // but keep Table 2}






