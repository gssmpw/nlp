\section{PoT Generation Methods}
\label{ap:pot-syn}






% \begin{figure*}[ht]
%   \begin{subfigure}{0.45\textwidth}
%     \includegraphics[width=\linewidth]{latex/figures/pipeline-cross-v1.pdf}
%     \caption{Cross-lingual Setup}
%     \label{fig:pipeline-cross}
%   \end{subfigure}
%   \begin{subfigure}{0.55\textwidth}
%     \includegraphics[width=\linewidth]{latex/figures/pipeline-muti-v1.pdf}
%     \caption{Multilingual Setup}
%     \label{fig:pipeline-multi}
%   \end{subfigure}  
  
%     \caption{
%     Pipeline overview \textcolor{blue}{Idea: Put something in the main for eye catching}
%     }
%     \centering
%     \label{fig:pipeline-overview}
% \end{figure*}











To facilitate a fair comparison between PoT and CoT, we employ the GSM8K dataset, a collection of grade-school math problems that require 2-8 reasoning steps to solve, as the foundational benchmark.
%
As illustrated in Figure~\ref{fig:pipeline-cross}, we generate solutions in a programming language using an Oracle LLM through various methodologies:
\begin{compactenum}[1.]
% \begin{enumerate}
    \item \textit{Zero-shot PoT Prompting}: Following the zero-shot prompting framework from \citet{pot}, the model is instructed to generate the \texttt{solver()} function in Python using a prompt $\vb*{S}_\text{PoT}$ with no exemplars. 
    %
    Formally, the PoT synthesis from an Oracle LLM is represented as $\hat{\vb*{R}_i}\sim p_\text{Oracle}(\vb*{Q}_i|\vb*{S}_\text{PoT})$.
    
    \item \textit{Few-shot PoT Prompting}: Building on the methodologies of \citet{pot, pal}, $k$ in-context exemplars, $\vb*{E}_\text{FS}=\{(\vb*{Q}_1, \vb*{R}_1), ...,  (\vb*{Q}_k, \vb*{R}_k)\}$, are incorporated into the prompt to provide explicit guidance on desired outputs. 
    %
    The PoT synthesis is thus defined as $\hat{\vb*{R}_i}\sim p_\text{Oracle}(\vb*{Q}_i|\vb*{E}_\text{FS},\vb*{S}_\text{PoT})$.
    
    \item \textit{Few-shot PoT Prompting + CoT Guidance}: Based on initial observations that high-quality PoT outputs often align with structured CoT reasoning $\vb*{C})$, an additional CoT guidance mechanism is introduced to better direct program generation. 
    %
    In this setting, the examples $\vb*{E}_\text{FS-CoT}=\{(\vb*{Q}_1, \vb*{C}_1, \vb*{R}_1), ...,  (\vb*{Q}_k, \vb*{C}_k, \vb*{R}_k)\}$ include both CoT reasoning ($\vb*{C}_i$) and the corresponding PoT solution ($\vb*{R}_i$). 
    %
    The PoT synthesis is then formulated as $\hat{\vb*{R}_i}\sim p_\text{Oracle}(\vb*{Q}_i|\vb*{C}_i, \vb*{E}_\text{FS-CoT},\vb*{S}_\text{PoT})$.
\end{compactenum}
% \end{enumerate}


% To address the absense of PoT data, we introduce a simple yet effective approach to generate PoT training data from the existing GSM8K dataset.
%
We empirically tested three approaches to identify the most effective method for maximizing the match between program execution outputs and gold-standard answers, using Llama3.1 405B Instruct \cite{Llama3} as the Oracle LLM: zero-shot prompting, few-shot prompting, and few-shot prompting with CoT reasoning.
%
In zero-shot prompting, the model is given only the original GSM8K question and generates the corresponding Python code to solve it.
%
Few-shot prompting extends this by providing the model with two exemplars of correctly solved GSM8K questions along with their corresponding Python solutions. 
%
Few-shot prompting with CoT reasoning further builds upon this by incorporating both the original answer and its Chain-of-Thought (CoT) reasoning from GSM8K.
%
Our evaluation demonstrated that the few-shot + CoT approach consistently outperformed the other methods, achieving a correctness rate of 96.1\% in synthesizing PoT samples. In comparison, the few-shot prompting method yielded a correctness rate of 94.5\%, while the zero-shot approach resulted in a significantly lower accuracy of 58.7\%.
% 

% \begin{table}[htbp]
% \tiny
%   \centering
%   \resizebox{0.7\columnwidth}{!}{
%   \begin{tabular}{l|c}
%     \hline
%     \textbf{Method} & Correctness (\%) \\
%     \hline
%     a & b \\
%     \hline
%   \end{tabular}
%   }
%   \caption{
%   various pot syn.
%   }
%   \label{tab:compare-pot-syn}
% \end{table}








% \begin{figure*}
%   \begin{subfigure}{0.42\textwidth}
%     \includegraphics[width=\linewidth]{latex/figures/pipeline-cross-v0.pdf}
%     \caption{Cross-lingual Setup \textcolor{blue}{add symbols}}
%     \label{fig:pipeline-cross}
%   \end{subfigure}
%   \begin{subfigure}{0.58\textwidth}
%     \includegraphics[width=\linewidth]{latex/figures/pipeline-muti-v1.pdf}
%     \caption{Multilingual Setup}
%     \label{fig:pipeline-multi}
%   \end{subfigure}  
  
%     \caption{
%     % \textcolor{red}{illustrated or emphasize question map from En to L2 that they are the same} Overview of our proposed study.
%     Overview of cross-lingual and multilingual pipelines, detailing PoT dataset construction from existing CoT datasets \cite{cobbe2021gsm8k} and subsequent evaluations.
%     \textbf{(a)}  \emph{Cross-Lingual PoT}: A standardized program-of-thought dataset, \texttt{GSM8KPoT}, is derived from the English CoT dataset using few-shot PoT prompting with CoT guidance from an oracle LLM. This dataset is then employed for fine-tuning LLMs and assessing their performance across nine additional, previously unseen languages.
%     \textbf{(b)}  \emph{Multilingual PoT}: To establish a multilingual PoT dataset, English questions are mapped to their target-language counterparts using \texttt{MGSM8KInstruct} \cite{mathoctopus}, aligning model capabilities across multiple languages. Additionally, inline comments from the program reasoning in \texttt{GSM8KPoT} are translated into target languages. The resulting dataset is leveraged to fine-tune models and evaluate their performance across 10 languages, including both high-resource (HRL) and underrepresented languages (URL).
%     }
%     \centering
%     \label{fig:pipeline-overview}
% \end{figure*}



\begin{figure}[h]
    \small
    \centering
    \begin{mdframed}
    \textbf{System} \newline
    You are a helpful assistant. Answer the following question
    by implementing a solver() function in Python program
    step by step, and then return the answer.
    \newline
    Solve them in a step-by-step fashion and output a single option as the final answer in [language] language.
    \end{mdframed}
    \begin{mdframed}
    \textbf{User} \newline
    Question: [Question]
    \end{mdframed}    
    \caption{
    Zero-shot PoT prompt template for PoT synthesis, where [Question] serves as a placeholder for the problem statement.
    }
    \label{fig:zs-prompt}
\end{figure}



\begin{figure*}[h]
    \small
    \centering
    \begin{mdframed}
    \textbf{System} \newline
    You are a helpful assistant. Answer the following question
    by implementing a solver() function in Python program
    step by step, and then return the answer.
    \newline
    Solve them in a step-by-step fashion and output a single option as the final answer in [language] language.
    \end{mdframed}
    \begin{mdframed}
    \textbf{User} \newline
    Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?
    \end{mdframed}
    \begin{mdframed}
    \textbf{Assistant}\newline
    def solver():\newline\hspace*{6mm}    \# Roger started with 5 tennis balls.\newline\hspace*{6mm}    tennis\_balls = 5\newline\hspace*{6mm}    \# 2 cans of 3 tennis balls each is\newline\hspace*{6mm}    bought\_balls = 2 * 3\newline\hspace*{6mm}    \# tennis balls. The answer is\newline\hspace*{6mm}    answer = tennis\_balls + bought\_balls"\newline\hspace*{6mm}    return answer
    \end{mdframed}
    \begin{mdframed}
    \textbf{User}\newline
        Question: The bakers at the Beverly Hills Bakery baked 200 loaves of bread on Monday morning. They sold 93 loaves in the morning and 39 loaves in the afternoon. A grocery store returned 6 unsold loaves. How many loaves of bread did they have left?
    \end{mdframed}
    \begin{mdframed}
        \textbf{Assistant}\newline
        def solver():\newline\hspace*{6mm}    \# The bakers started with 200 loaves\newline\hspace*{6mm}    loaves\_baked = 200\newline\hspace*{6mm}    \# They sold 93 in the morning and 39 in the afternoon\newline\hspace*{6mm}    loaves\_sold\_morning = 93\newline\hspace*{6mm}    loaves\_sold\_afternoon = 39\newline\hspace*{6mm}    \# The grocery store returned 6 loaves.\newline\hspace*{6mm}    loaves\_returned = 6\newline\hspace*{6mm}    \# The answer is\newline\hspace*{6mm}    answer = loaves\_baked - loaves\_sold\_morning - loaves\_sold\_afternoon + loaves\_returned\newline\hspace*{6mm}    return answer
    \end{mdframed}
    \begin{mdframed}
        \textbf{User}\newline
        Question: [Question]
    \end{mdframed}
    \caption{
    Few-shot PoT prompt template for PoT synthesis, with exemplars adapted from \cite{pal, pot}.
    }
    \label{fig:fs-prompt}
\end{figure*}



\begin{figure*}[h]
    \small
    \centering
    \begin{mdframed}
    \textbf{System} \newline
    You are a helpful assistant. Answer the following question
    by implementing a solver() function in Python program
    step by step, and then return the answer.
    \newline
    Solve them in a step-by-step fashion and output a single option as the final answer in [language] language.
    \end{mdframed}
    \begin{mdframed}
    \textbf{User} \newline
    Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\newline
    Chain-of-thought: Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.
    \end{mdframed}
    \begin{mdframed}
    \textbf{Assistant}\newline
    def solver():\newline\hspace*{6mm}    \# Roger started with 5 tennis balls.\newline\hspace*{6mm}    tennis\_balls = 5\newline\hspace*{6mm}    \# 2 cans of 3 tennis balls each is\newline\hspace*{6mm}    bought\_balls = 2 * 3\newline\hspace*{6mm}    \# tennis balls. The answer is\newline\hspace*{6mm}    answer = tennis\_balls + bought\_balls"\newline\hspace*{6mm}    return answer
    \end{mdframed}
    \begin{mdframed}
    \textbf{User}\newline
        Question: The bakers at the Beverly Hills Bakery baked 200 loaves of bread on Monday morning. They sold 93 loaves in the morning and 39 loaves in the afternoon. A grocery store returned 6 unsold loaves. How many loaves of bread did they have left?\newline
        Chain-of-thought: The bakers started with 200 loaves of bread. They sold 93 loaves in the morning and 39 loaves in the afternoon: 93 + 39 = 132 loaves sold. A grocery store returned 6 loaves, so they got 6 loaves back. 200 - 132 + 6 = 74 loaves left. The answer is 74.
    \end{mdframed}
    \begin{mdframed}
        \textbf{Assistant}\newline
        def solver():\newline\hspace*{6mm}    \# The bakers started with 200 loaves\newline\hspace*{6mm}    loaves\_baked = 200\newline\hspace*{6mm}    \# They sold 93 in the morning and 39 in the afternoon\newline\hspace*{6mm}    loaves\_sold\_morning = 93\newline\hspace*{6mm}    loaves\_sold\_afternoon = 39\newline\hspace*{6mm}    \# The grocery store returned 6 loaves.\newline\hspace*{6mm}    loaves\_returned = 6\newline\hspace*{6mm}    \# The answer is\newline\hspace*{6mm}    answer = loaves\_baked - loaves\_sold\_morning - loaves\_sold\_afternoon + loaves\_returned\newline\hspace*{6mm}    return answer
    \end{mdframed}
    \begin{mdframed}
        \textbf{User}\newline
        Question: [Question]\newline
        Chain-of-thought: [CoT]
    \end{mdframed}
    \caption{
    Few-shot PoT prompt template incorporating our proposed CoT-guided approach for PoT synthesis, where [CoT] serves as a placeholder for natural language reasoning.
    }
    \label{fig:fs-prompt}
\end{figure*}

