\section{Full Tables}

\subsection{Main Results}
\label{ap:full-main}

This subsection serves as an extension of the results presented in Section~\ref{sec:QR-Alignment}.
%
In particular, we present the complete results for all fine-tuning alignment strategies in Table \ref{tab:ablation-cross} for cross-lingual settings and Table \ref{tab:ablation-multi} for multilingual settings.
%
These tables provide a detailed breakdown of performance across different configurations, reinforcing the trends observed in Section~\ref{sec:QR-Alignment}. 
%
The results confirm that PoT fine-tuning significantly improves multilingual reasoning, with cross-lingual generalization benefiting from the removal of inline comments and multilingual settings achieving higher alignment when comments are translated into target languages.

\begin{table*}[htbp]
\tiny
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
With Comments & 58.3 & 37.9 & 40.0 & 44.4 & 39.2 & 33.2 & 25.1 & 6.8  & 5.2  & 9.9  & 30.0 \\
Without Comments & 58.0 & 40.4 & 40.4 & 43.6 & 37.1 & 38.4 & 32.7 & 7.6  & 5.6  & 12.0 & 31.6 \\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
With Comments & 61.4 & 45.2 & 47.6 & 47.0 & 41.6 & 37.9 & 35.6 & 29.2 & 5.2  & 15.6 & 36.6 \\
Without Comments & 58.8 & 48.4 & 51.6 & 53.6 & 49.8 & 41.6 & 39.6 & 26.8 & 4.4  & 11.2 & 38.6 \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
With Comments & 67.3 & 48.4 & 49.4 & 54.0 & 44.4 & 44.4 & 35.2 & 11.6 & 6.4  & 13.2 & 37.4 \\
Without Comments & 64.0 & 52.4 & 54.4 & 55.6 & 51.2 & 44.0 & 40.0 & 13.9 & 7.2  & 13.6 & 39.6 \\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
With Comments & 46.4 & 48.2 & 38.3 & 49.2  & 41.8 & 49.6  & 36.9  & 37.9 & 20.7 & 37.5 & 40.6 \\
Without Comments & 68.4  & 62.2 & 59.2  & 62.4  & 60.4  & 52.4  & 45.4 & 43.6  & 34.8  & 46.0   & 53.5 \\
\hline
\end{tabular}
}
\caption{
Accuracy (\%) on MGSM for all cross-lingual PoT variants, providing the full results corresponding to the subset shown in Table \ref{tab:pot-inline-comment}
}
\label{tab:ablation-cross}
\end{table*}

\begin{table*}[htbp]
\tiny
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 54.8 & 47.2 & 51.2 & 46.2 & 42.8 & 33.2 & 34.8 & 20.0 & 17.6 & 18.0 & 36.6 \\
PoT Cross Question & 46.0 & 37.6 & 43.0 & 44.4 & 39.6 & 39.6 & 36.3 & 31.6 & 30.4 & 28.8 & 37.7 \\
PoT Parallel & 56.0 & 47.2 & 46.4 & 54.0 & 49.6 & 44.4 & 40.0 & 40.4 & 37.6 & 30.8 & 44.6 \\
PoT No Comment & 53.6 & 41.6 & 42.8 & 44.8 & 44.0 & 39.2 & 40.0 & 36.0 & 34.4 & 29.2 & 40.6 \\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 58.0 & 47.2 & 51.4 & 52.4 & 48.0 & 44.2 & 38.0 & 28.8 & 20.4 & 22.4 & 41.1 \\
PoT Cross Question & 48.0 & 42.8 & 46.0 & 44.6 & 45.0 & 41.0 & 36.9 & 39.4 & 32.0 & 28.8 & 40.5 \\
PoT Parallel & 61.9 & 52.8 & 54.4 & 52.4 & 53.6 & 50.4 & 44.8 & 44.8 & 39.6 & 35.6 & 49.0 \\
PoT No Comment & 56.8 & 47.6 & 46.4 & 48.8 & 52.0 & 46.4 & 44.0 & 44.4 & 34.4 & 35.2 & 45.6 \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
PoT Cross Comment & 62.0 & 53.6 & 52.4 & 54.8 & 50.0 & 42.0 & 39.2 & 21.6 & 23.2 & 23.2 & 42.2 \\
PoT Cross Question & 53.0 & 47.6 & 49.4 & 51.2 & 48.8 & 48.8 & 42.4 & 38.0 & 35.9 & 35.9 & 45.1 \\
PoT Parallel & 63.5 & 56.4 & 59.2 & 59.2 & 55.2 & 54.0 & 51.6 & 50.0 & 52.8 & 44.4 & 54.6 \\
PoT No Comment & 58.4 & 51.6 & 52.4 & 48.8 & 50.4 & 45.6 & 39.2 & 43.6 & 39.2 & 35.2 & 46.4 \\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
PoT Cross Comment & 72.8 & 62.4 & 66.4 & 67.2 & 63.6 & 52.0 & 49.6 & 52.0 & 46.2 & 51.2 & 58.3 \\
PoT Cross Question & 37.2 & 30.3 & 34.3 & 37.6 & 33.1 & 27.4 & 23.6 & 35.1 & 27.1 & 30.4 & 31.6\\
PoT Parallel & 76.5 & 64.4 & 63.2 & 66.4 & 64.0 & 63.2 & 56.4 & 57.6 & 59.6 & 55.2 & 62.6 \\
PoT No Comment & 65.2 & 60.0 & 59.6 & 59.2 & 57.2 & 57.2 & 49.4 & 55.2 & 53.6 & 48.4 & 56.5\\
\hline
\end{tabular}
}
\caption{
Accuracy (\%) on MGSM for all multilingual PoT variants, providing the full results corresponding to the subset shown in Table \ref{tab:multilingual-ablation} 
}
\label{tab:ablation-multi}
\end{table*}


\subsection{Code Analysis}
\label{ap:code-analysis}

This subsection extends the analysis presented in Section~\ref{section:code-analysis-results} by providing a full set of code quality evaluation results.
%
Our code analysis scores are presented in Table~\ref{tab:ablation-cross-icescore} and Table \ref{tab:ablation-multi-icescore} for cross-lingual and multilingual \texttt{ICE-Score}, respectively. Similarly, Table~\ref{tab:ablation-cross-codebert} and Table~\ref{tab:ablation-multi-codebert} provide the corresponding results for \texttt{CodeBERT-Score}.
%
These results are consistent with the findings in Section~\ref{section:code-analysis-results}, confirming a strong correlation between reasoning quality and final answer correctness. 
%
The observed trends support the effectiveness of leveraging code quality for test-time scaling, with improvements in underrepresented languages being particularly notable.

\begin{table*}[htbp]
\tiny
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
With Comments & 2.40 & 1.87 & 1.84 & 2.03 & 1.76 & 1.41 & 1.26 & 0.32 & 0.14 & 0.45 & 1.35 \\
Without Comments & 2.49 & 1.87 & 1.94 & 1.94 & 1.82 & 1.67 & 1.62 & 0.39 & 0.15 & 0.49 & 1.44 \\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
With Comments & 2.66 & 2.06 & 2.21 & 2.11 & 1.98 & 1.83 & 1.57 & 1.26 & 0.16 & 0.61 & 1.65 \\
Without Comments & 2.54 & 2.13 & 2.15 & 2.31 & 2.13 & 1.85 & 1.82 & 1.10 & 0.23 & 0.54 & 1.68 \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
With Comments & 2.79 & 2.21 & 2.29 & 2.37 & 2.02 & 2.04 & 1.76 & 0.56 & 0.21 & 0.60 & 1.69 \\
Without Comments & 2.49 & 1.87 & 1.94 & 1.94 & 1.82 & 1.67 & 1.62 & 0.39 & 0.15 & 0.49 & 1.44 \\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
With Comments & 2.74 & 2.32 & 2.40 & 2.63 & 2.36 & 2.07 & 1.86 & 2.20 & 1.34 & 1.81 & 2.17 \\
Without Comments & 2.75 & 2.46 & 2.61 & 2.56 & 2.54 & 2.00 & 1.92 & 1.88 & 1.64 & 2.00 & 2.24 \\
\hline
\end{tabular}
}
\caption{
\texttt{ICE-Score} on MGSM for all cross-lingual PoT variants, providing the full results corresponding to the subset shown in Table \ref{tab:code-quality} 
}
\label{tab:ablation-cross-icescore}
\end{table*}


\begin{table*}[htbp]
\tiny
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 2.56 & 2.41 & 2.53 & 2.40 & 2.25 & 2.05	& 2.03 & 1.17 & 1.17 & 1.26 & 1.98\\
PoT Cross Question & 2.32 & 2.07 & 2.23 & 2.27 & 2.18 & 2.09 & 2.11 & 1.75 & 1.78 & 1.52 & 2.03\\
PoT Parallel & 2.83 & 2.55 & 2.46 & 2.80 & 2.55 & 2.43 & 2.25 & 2.29 & 2.36 & 1.96 & 2.45\\
PoT No Comment & 2.54 & 2.16 & 2.30 & 2.27 & 2.34 & 2.15 & 2.17 & 1.79 & 1.86 & 1.71 & 2.13\\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 2.84 & 2.40 & 2.54 & 2.48 & 2.51 & 2.42 & 2.13 & 1.62 & 1.24 & 1.34 & 2.15\\
PoT Cross Question & 2.45 & 2.23 & 2.19 & 2.33 & 2.28 & 2.29 & 2.06 & 1.95 & 1.75 & 1.54 & 2.11\\
PoT Parallel & 2.88 & 2.68 & 2.64 & 2.82 & 2.79 & 2.57 & 2.49 & 2.41 & 2.29 & 2.04 & 2.56\\
PoT No Comment & 2.61 & 2.41 & 2.35 & 2.43 & 2.49 & 2.30 & 2.31 & 2.23 & 1.86 & 1.87 & 2.28\\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
PoT Cross Comment & 2.91 & 2.76 & 2.67 & 2.88 & 2.58 & 2.50 & 2.25 & 1.40 & 1.65 & 1.55 & 2.31\\
PoT Cross Question & 2.69 & 2.48 & 2.48 & 2.58 & 2.52 & 2.48 & 2.30 & 2.12 & 2.12 & 1.84 & 2.36\\
PoT Parallel & 2.94 & 2.91 & 2.90 & 2.82 & 2.93 & 2.81 & 2.79 & 2.70 & 2.75 & 2.36 & 2.79\\
PoT No Comment & 2.70 & 2.52 & 2.62 & 2.55 & 2.45 & 2.45 & 2.30 & 2.30 & 2.26 & 2.17 & 2.43\\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
PoT Cross Comment & 3.12 & 2.75 & 2.87 & 2.90 & 2.84 & 2.44 & 2.42 & 2.32 & 2.13 & 2.38 & 2.61 \\
PoT Cross Question & 2.51 & 2.07 & 2.31 & 2.25 & 2.13 & 2.04 & 1.95 & 2.11 & 1.67 & 1.83 & 2.09\\
PoT Parallel & 3.15 & 2.88 & 2.82 & 3.03 & 2.84 & 2.82 & 2.58 & 2.72 & 2.68 & 2.56 & 2.81 \\
PoT No Comment & 2.76 & 2.54 & 2.47 & 2.53 & 2.48 & 2.56 & 2.24 & 2.46 & 2.33 & 2.10 & 2.45 \\
\hline
\end{tabular}
}
\caption{
\texttt{ICE-Score} on MGSM for all multilingual PoT variants, providing the full results corresponding to the subset shown in Table \ref{tab:code-quality}  
}
\label{tab:ablation-multi-icescore}
\end{table*}

\begin{table*}[htbp]
\tiny
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
With Comments & 90.50 & 83.53 & 84.18 & 83.21 & 85.68 & 85.94 & 86.02 & 81.33 & 79.24 & 81.81 & 84.14 \\
Without Comments & 90.08 & 81.56 & 82.03 & 81.16 & 83.94 & 85.66 & 86.61 & 82.15 & 78.56 & 81.92 & 83.37 \\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
With Comments & 90.69 & 85.23 & 84.00 & 82.80 & 86.33 & 86.15 & 86.40 & 84.14 & 78.87 & 83.04 & 84.77 \\
Without Comments & 89.85 & 84.67 & 83.88 & 83.11 & 86.54 & 85.68 & 86.74 & 84.07 & 79.61 & 83.21 & 84.74 \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
With Comments & 90.50 & 84.66 & 84.29 & 83.75 & 85.12 & 87.10 & 87.05 & 82.00 & 80.71 & 82.82 & 84.80 \\
Without Comments & 90.29 & 85.62 & 85.08 & 84.78 & 86.72 & 87.06 & 87.64 & 83.52 & 81.53 & 83.60 & 85.58 \\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
With Comments & 83.23 & 80.30 & 79.90 & 81.22 & 80.36 & 80.06 & 79.58 & 80.65 & 78.61 & 79.64 & 80.36 \\
Without Comments & 84.36 & 82.11 & 81.60 & 80.38 & 82.23 & 79.26 & 78.16 & 79.95 & 78.34 & 79.50 & 80.59 \\
\hline
\end{tabular}
}
\caption{
\texttt{CodeBERT-Score} (F1) on MGSM for all cross-lingual PoT variants. 
}
\label{tab:ablation-cross-codebert}
\end{table*}

\begin{table*}[htbp]
\small
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l|llllllllll|l}
\hline
\textbf{Method} & en & de & fr & es & ru & zh & ja & th & sw & bn & All \\
\hline
\multicolumn{1}{l|}{\underline{Llama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 90.26 & 88.07 & 87.94 & 87.56 & 87.38 & 86.81 & 87.13 & 85.03 & 82.63 & 84.33 & 86.71\\
PoT Cross Question & 89.13 & 88.41 & 88.12 & 88.16 & 88.39 & 87.22 & 87.60 & 86.11 & 86.24 & 86.18 & 87.56\\
PoT Parallel & 89.95 & 89.14 & 88.90 & 89.27 & 88.72 & 87.99 & 88.34 & 87.35 & 87.53 & 86.89 & 88.41\\
PoT No Comment & 89.73 & 88.74 & 88.29 & 88.60 & 88.13 & 87.24 & 88.14 & 86.64 & 86.79 & 86.62 & 87.89\\
\hline
\multicolumn{1}{l|}{\underline{CodeLlama2-7B}} & & & & & & & & & & & \\
PoT Cross Comment & 90.95 & 88.38 & 88.45 & 88.74 & 87.89 & 87.75 & 88.23 & 84.79 & 83.55 & 85.23 & 87.40\\
PoT Cross Question & 89.10 & 88.26 & 87.84 & 87.79 & 87.25 & 87.06 & 87.03 & 86.45 & 86.02 &85.95 & 87.28\\
PoT Parallel & 90.08 & 88.79 & 89.03 & 88.77 & 88.47 & 87.69 & 87.68 & 87.37 & 86.55 & 87.09 & 88.15\\
PoT No Comment & 89.84 & 88.44 & 88.71 & 88.66 & 88.04 & 87.47 & 87.49 & 86.90 & 86.55 & 86.14 & 87.82\\
\hline
\multicolumn{1}{l|}{\underline{Llama2-13B}} & & & & & & & & & & & \\
PoT Cross Comment & 90.26 & 87.80 & 87.75 & 87.36 & 87.27 & 86.83 & 87.53 & 83.72 & 82.91 & 84.05 & 86.55\\
PoT Cross Question & 89.92 & 88.84 & 88.63 & 88.65 & 88.48 & 87.97 & 88.11 & 86.92 & 87.21 & 87.13 & 88.19\\
PoT Parallel & 90.40 & 89.53 & 89.32 & 89.51 & 89.55 & 88.53 & 88.92 & 88.10 & 87.93 & 87.57 & 88.94\\
PoT No Comment & 89.99 & 89.02 & 89.14 & 89.00 & 88.74 & 88.40 & 88.44 & 87.30 & 87.10 & 87.04 & 88.42\\
\hline
\multicolumn{1}{l|}{\underline{Llama3-8B}} & & & & & & & & & & & \\
PoT Cross Comment & 91.02 & 89.32 & 88.69 & 89.06 & 89.01 & 88.29 & 88.32 & 87.91 & 86.59 & 87.55 & 88.58\\
PoT Cross Question & 80.30 & 78.94 & 78.95 & 79.61 & 79.63 & 79.22 & 79.51 & 79.18 & 79.12 & 79.63 & 79.38\\
PoT Parallel & 90.49 & 90.17 & 89.81 & 89.31 & 89.38 & 88.71 & 88.99 & 88.90 & 88.40 & 88.75 & 89.29\\
PoT No Comment & 89.80 & 88.81 & 88.78 & 89.07 & 88.40 & 88.35 & 88.70 & 88.37 & 88.08 & 88.10 & 88.65\\
\hline
\end{tabular}
}
\caption{
\texttt{CodeBERT-Score} (F1) on MGSM in for all multilingual PoT variants. 
}
\label{tab:ablation-multi-codebert}
\end{table*}

\begin{table*}[htbp]
\small
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|llllllllll}
\hline
Method & en & de & fr & es & ru & zh & ja & th & sw & bn \\
\hline \hline
\multicolumn{11}{c}{\textit{Cross-lingual}} \\
\hline    
\underline{Llama2-7B} & & & & & & & & & & \\ 
AUC  & 0.9659  & 0.9544  & 0.9782  & 0.9728  & 0.9733  & 0.9622  & 0.9680  & 0.9683  & 0.7376  & 0.9068  \\
T-Statsitic     & 28.66   & 25.67   & 32.72   & 31.29   & 31.82   & 28.81   & 29.04   & 12.87   & 3.23    & 10.56   \\
\hline   
\underline{CodeLlama-7B} & & & & & & & & & & \\ 
AUC  & 0.9752  & 0.9708  & 0.9661  & 0.9736  & 0.9723  & 0.9606  & 0.9528  & 0.9215  & 0.8524  & 0.9096  \\
T-Statsitic     & 28.85   & 29.85   & 29.82   & 31.68   & 31.36   & 28.86   & 25.30   & 16.48   & 4.96    & 9.96    \\
\hline \hline
\multicolumn{11}{c}{\textit{Multilingual}} \\
\hline
\underline{Llama2-7B} & & & & & & & & & & \\ 
AUC  & 0.9847  & 0.9561  & 0.9725  & 0.9771  & 0.9675  & 0.9714  & 0.9865  & 0.9556  & 0.9437  & 0.9480  \\
T-Statsitic     & 31.21   & 25.70   & 28.94   & 28.51   & 29.04   & 27.80   & 36.85   & 25.14   & 22.99   & 21.79   \\
\hline   
\underline{CodeLlama-7B} & & & & & & & & & & \\ 
AUC  & 0.9627  & 0.9327  & 0.9627  & 0.9756  & 0.9536  & 0.9511  & 0.9476  & 0.9532  & 0.9537  & 0.9476  \\
T-Statsitic     & 25.13   & 21.46   & 25.94   & 28.20   & 23.93   & 23.45   & 22.96   & 25.07   & 24.10   & 23.96   \\
\hline
\end{tabular}
}
\captionsetup{justification=centerlast}
\caption{T-Statistic and AUC scores for Llama2-7B and CodeLlama-7B across MGSM}
\label{tab:ttest-stats}
\end{table*}