\section{Inter-Subject Noise Correction Derivation}
\label{sec:methods-interanimal}
Herein we describe how the metric $\mathcal{M}$ should correct for noise if there is trial-to-trial variability.
This is unified and adapted from~\citet{nayebi2021unsupervised,nayebi2021explaining,nayebi2023neural}.

If you prefer to skip the derivation, for correlation-based metrics this yields the following model-to-data mapping correction: Let $L$ be the set of model layers, let $r^{\ell}$ be the set of model responses at model layer $\ell \in L$, $M$ be the mapping, and let $\mathrm{s}$ be the trial-averaged pseudo-population response.

\begin{equation}\label{modelcon}
\begin{split}
\max_{\ell\in L}\median\bigoplus_{\animalB \in \mathcal{A}} \left\langle\dfrac{\corr\left(M\left(r^{\ell}_{\text{train}};\sfBtrain\right)_{\test}, \ssBtest\right)}{\sqrt{\widetilde{\corr}\left(M\left(r^{\ell}_{\text{train}};\sfBtrain\right)_{\test}, M\left(r^{\ell}_{\text{train}};\ssBtrain\right)_{\test}\right) \times \widetilde{\corr}\left(\sfBtest, \ssBtest\right)}}\right\rangle,
\end{split}
\end{equation}
where the average is taken over bootstrapped split-half trials, $\oplus$ denotes concatenation of units across animals or subjects $\animalB \in \mathcal{A}$ followed by the median value across units, and $\corr(\cdot,\cdot)$ denotes the Pearson correlation of the two quantities.
$\widetilde{\corr}(\cdot, \cdot)$ denotes the Spearman-Brown corrected value of the original quantity (cf. \S\ref{ss:methods-interanimal-spearman-brown}).
We derive the analogous correction for RSA in \S\ref{ss:methods-interanimal-rsa}.

The above correction in \eqref{modelcon} is fully implemented in the 
\texttt{brainmodel\_utils} package (\url{https://github.com/neuroagents-lab/brainmodel_utils}), 
specifically in the \texttt{get\_linregress\_consistency} function. 
This function can be imported as follows:

\begin{lstlisting}
from brainmodel_utils.metrics.consistency import get_linregress_consistency
\end{lstlisting}

The \texttt{r\_xy\_n\_sb} value returned by this function corresponds to the ratio in \eqref{modelcon}.
Refer to the
\href{https://github.com/neuroagents-lab/brainmodel_utils#readme}{README} and the function docstring for usage details across a range of linearly regressed and non-regressed (e.g. RSA) metrics.

\subsection{Single Subject Pair}
\label{ss:methods-interanimal-pair}
Suppose we have neural responses from two animals (or subjects) $\animalA$ and $\animalB$.
Let $\mathrm{t}_i^p$ be the vector of true responses (either at a given time bin or averaged across a set of time bins) of animal $p \in \mathcal{A} = \{\animalA,\animalB,\dots\}$ on stimulus set $i \in \{\train, \test\}$.
Of course, we only receive noisy observations of $\mathrm{t}_i^p$, so let $\mathrm{s}_{j,i}^p$ be the $j$th set of $n$ trials of $\mathrm{t}_i^p$.
Finally, let $M(x;y)_i$ be the predictions of a mapping $M$ (e.g., PLS) when trained on input $x$ to match output $y$ and tested on stimulus set $i$.
For example, $M\left(\trueA;\trueB\right)_{\test}$ is the prediction of mapping $M$ on the test set stimuli trained to match the true neural responses of animal $\animalB$ given, as input, the true neural responses of animal $\animalA$ on the train set stimuli.
Similarly, $M\left(\sfAtrain;\sfBtrain\right)_{\test}$ is the prediction of mapping $M$ on the test set stimuli trained to match the trial-average of noisy sample 1 on the train set stimuli of animal $\animalB$ given, as input, the trial-average of noisy sample 1 on the train set stimuli of animal $\animalA$.

With these definitions in hand, the inter-animal mapping consistency from animal $\animalA$ to animal $\animalB$ corresponds to the following ``true'' quantity to be estimated by $\Mest$ in the limit of infinite trials:
\begin{equation}\label{interancontrue}
\mathcal{M}_{\text{true}} := \corr\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right),
\end{equation}
where $\corr(\cdot, \cdot)$ is the Pearson correlation across a stimulus set.
In what follows, we will argue that Eq~\eqref{interancontrue} can be approximated with the following ratio of measurable quantities, where we split in half and average the noisy trial observations, indexed by 1 and by 2:
\begin{equation}\label{interancon}
\begin{split}
& \Mtrue := \corr\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right) \\
& \sim \Mest := \dfrac{\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, \ssBtest\right)}{\sqrt{\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\ssAtrain;\ssBtrain\right)_{\test}\right) \times \corr\left(\sfBtest, \ssBtest\right)}}.
\end{split}
\end{equation}
In words, the inter-animal consistency (i.e., the quantity on the left side of Eq~\eqref{interancon}) corresponds to the predictivity of the mapping on the test set stimuli from animal $\animalA$ to animal $\animalB$ on two different (averaged) halves of noisy trials (i.e., the numerator on the right side of Eq~\eqref{interancon}), corrected by the square root of the mapping reliability on animal $\animalA$'s responses to the test set stimuli on two different halves of noisy trials multiplied by the internal consistency of animal $\animalB$.

We justify the approximation in Eq~\eqref{interancon} by gradually replacing the true quantities ($\mathrm{t}$) by their measurable estimates ($\mathrm{s}$), starting from the original quantity in Eq~\eqref{interancontrue}.
First, we make the approximation that:
\begin{equation}\label{step1}
\corr\left(M\left(\trueA;\trueB\right)_{\test}, \ssBtest\right) \sim \corr\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right) \times \corr\left(\trueBtest, \ssBtest\right),
\end{equation}
by the transitivity of very positive correlations. 
Namely, in scenarios where correlations are very close to 1, a form of transitivity holds, meaning if variable $A$ is highly correlated with variable $B$, and variable $B$ with variable $C$, then variable $A$ is also highly correlated with variable $C$. 
This is the desired situation, as low or negative correlations indicate neurons that are not self-consistent.
Moreover, calculating certain metrics in these cases can result in undefined values due to operations like taking the square root of a negative number. 
Assuming high correlations is reasonable, especially when the number of stimuli is large.
Next, by transitivity and normality assumptions in the structure of the noisy estimates and since the number of trials ($n$) between the two sets is the same, we have that:
\begin{align}\label{step2}
\corr\left(\sfBtest, \ssBtest\right) &\sim \corr\left(\sfBtest, \trueBtest\right) \times \corr\left(\trueBtest, \ssBtest\right) \nonumber \\
&\sim \corr\left(\trueBtest, \ssBtest\right)^2.
\end{align}
In words, Eq~\eqref{step2} states that the correlation between the average of two sets of noisy observations of $n$ trials each is approximately the square of the correlation between the true value and average of one set of $n$ noisy trials.
Therefore, combining Eq~\eqref{step1} and Eq~\eqref{step2}, it follows that:
\begin{equation}\label{lemma1}
\corr\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right) \sim \dfrac{\corr\left(M\left(\trueA;\trueB\right)_{\test}, \ssBtest\right)}{\sqrt{\corr\left(\sfBtest, \ssBtest\right)}}.
\end{equation}

From the right side of Eq~\eqref{lemma1}, we can see that we have removed $\trueBtest$, but we still need to remove the $M\left(\trueA;\trueB\right)_{\test}$ term, as this term still contains unmeasurable (i.e., true) quantities.
We apply the same two steps, described above, by analogy, though these approximations may not always be true (they are, however, true for Gaussian noise):
\begin{equation*}
\begin{split}
\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, \ssBtest\right) & \sim \corr\left(\ssBtest, M\left(\trueA;\trueB\right)_{\test}\right) \\
& \times \corr\left(M\left(\trueA;\trueB\right)_{\test}, M\left(\sfAtrain;\sfBtrain\right)_{\test}\right)
\end{split}
\end{equation*}
\begin{equation*}
\begin{split}
& \corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\ssAtrain;\ssBtrain\right)_{\test}\right) \\
& \sim \corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\trueA;\trueB\right)_{\test}\right)^2,
\end{split}
\end{equation*}
which taken together implies the following:
\begin{equation}\label{lemma2}
\corr\left(M\left(\trueA;\trueB\right)_{\test}, \ssBtest\right) \sim \dfrac{\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, \ssBtest\right)}{\sqrt{\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\ssAtrain;\ssBtrain\right)_{\test}\right)}}.
\end{equation}
Eq~\eqref{lemma1} and Eq~\eqref{lemma2} together imply the final estimated quantity given in Eq~\eqref{interancon}.

\subsection{Multiple Subject Pairs}
\label{ss:methods-interanimal-multiple}
For multiple animals, we consider the average of the true quantity for each target in $\animalB$ in Eq~\eqref{interancontrue} across source animals $\animalA$ in the ordered pair $(\animalA,\animalB)$ of animals $\animalA$ and $\animalB$:
\begin{equation*}\label{multipleinterancon}
\begin{split}
&\Mtrue := \left\langle \corr\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right)\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}} \\
& \sim \Mest := \left\langle\dfrac{\corr\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, \ssBtest\right)}{\sqrt{\widetilde{\corr}\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\ssAtrain;\ssBtrain\right)_{\test}\right) \times \widetilde{\corr}\left(\sfBtest, \ssBtest\right)}}\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}}.
\end{split}
\end{equation*}
We also bootstrap across trials, and have multiple train/test splits, in which case the average on the right hand side of the equation includes averages across these as well.

Note that each neuron in our analysis will have this single average value associated with it when \emph{it} was a target animal ($\animalB$), averaged over source animals/subsampled source neurons, bootstrapped trials, and train/test splits.
This yields a vector of these average values, which we can take median and standard error of the mean (s.e.m.) over, as we do with standard explained variance metrics.

\subsection{RSA}
\label{ss:methods-interanimal-rsa}
We can extend the above derivations to other commonly used metrics for comparing representations that involve correlation.
Since $\rsa(x,y) \coloneqq \corr(\rdm(x), \rdm(y))$, then the corresponding quantity in Eq~\eqref{interancon} analogously (by transitivity of maximally positive correlations) becomes:
\begin{equation}\label{rsainterancon}
\begin{split}
&\Mtrue := \left\langle\rsa\left(M\left(\trueA;\trueB\right)_{\test}, \trueBtest\right)\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}} \\
& \sim \Mest := \left\langle\dfrac{\rsa\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, \ssBtest\right)}{\sqrt{\widetilde{\rsa}\left(M\left(\sfAtrain;\sfBtrain\right)_{\test}, M\left(\ssAtrain;\ssBtrain\right)_{\test}\right) \times \widetilde{\rsa}\left(\sfBtest, \ssBtest\right)}}\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}}.
\end{split}
\end{equation}

Note that in this case, each \emph{animal} (rather than neuron) in our analysis will have this single average value associated with it when \emph{it} was a target animal ($\animalB$) (since RSA is computed over images and neurons), where the average is over source animals/subsampled source neurons, bootstrapped trials, and train/test splits.
This yields a vector of these average values, which we can take median and s.e.m. over, across animals $\animalB \in \mathcal{A}$.

For RSA, we can use the identity mapping (since RSA is computed over neurons as well, the number of neurons between source and target animal can be different to compare them with the identity mapping). 
As parameters are not fit, we can choose $\train = \test$, so that Eq~\eqref{rsainterancon} becomes:
\begin{equation}\label{rsainteranconid}
\Mtrue := \left\langle\rsa\left(\trueAid,\trueBid\right)\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}} \sim \Mest := \left\langle\dfrac{\rsa\left(\sfAid, \ssBid\right)}{\sqrt{\widetilde{\rsa}\left(\sfAid, \ssAid\right) \times \widetilde{\rsa}\left(\sfBid, \ssBid\right)}}\right\rangle_{\animalA \in \mathcal{A}: (\animalA,\animalB)\in \mathcal{A}\times\mathcal{A}}.
\end{equation}

\subsection{Pooled Source Animal}
\label{ss:methods-interanimal-holdouts}
Often times, we may not have enough neurons per animal to ensure that the estimated inter-animal consistency in our data closely matches the ``true'' inter-animal consistency.
In order to address this issue, we holdout one animal at a time and compare it to the pseudo-population aggregated across units from the remaining animals, as opposed to computing the consistencies in a pairwise fashion.
Thus, $\animalB$ is still the target heldout animal as in the pairwise case, but now the average over $\animalA$ is over a sole ``pooled'' source animal constructed from the pseudo-population of the remaining animals.

Pooling data across subjects to create larger pseudopopulations is a common practice~\citep{rust2020understanding}, and helps researchers better isolate core representational principles that are conserved across individuals when data collection modalities limit the number of collected neurons per session.

\subsection{Spearman-Brown Correction}
\label{ss:methods-interanimal-spearman-brown}
The Spearman-Brown correction can be applied to each of the terms in the denominator individually, as they are each correlations of observations from half the trials of the \emph{same} underlying process to itself (unlike the numerator). Namely,
\begin{equation*}
\widetilde{\corr}\left(X,Y\right) \coloneqq \frac{2\corr\left(X,Y\right)}{1 + \corr\left(X,Y\right)}.
\end{equation*}
Analogously, since $\rsa(X,Y) \coloneqq \corr(\rdm(x), \rdm(y))$, then we define
\begin{align*}
\widetilde{\rsa}\left(X,Y\right) &\coloneqq \widetilde{\corr}(\rdm(x), \rdm(y)) \\
    &= \frac{2\rsa\left(X,Y\right)}{1 + \rsa\left(X,Y\right)}.
\end{align*}

\section{Notions of Brain-Likeness}
\label{sec:notions}
In developing artificial intelligence that mirrors the biological brain, the concept of brain-likeness has been interpreted in various ways. Here, we explore the most common notions of brain-likeness (cf. Table~\ref{tab:brain_likeness} for a summary):

\paragraph{Brain-Likeness in structural components} refers to how closely a model’s internal architecture---such as layer organization, connectivity patterns, and computational units---resembles that of the brain. Modern convolutional neural networks (CNNs) exemplify this by integrating key neural computation principles like nonlinear transduction, divisive normalization, and max-based pooling~\citep{yamins2016using}. These design choices are directly inspired by electrophysiological studies of the mammalian visual cortex, where simple and complex cells in area V1 filter and pool visual inputs to extract features at different scales~\citep{Hubel1962}. Similarly, recurrent neural networks (RNNs) capture temporal dependencies through recurrent connectivity, paralleling biological circuits where feedback connections are essential for maintaining and integrating information over time, as seen in the prefrontal cortex supporting working memory and sequential processing~\citep{goldman1995cellular}. Spiking neural networks (SNNs) strive for even greater structural similarity by incorporating neuron-like spiking activity and temporal dynamics, reflecting biological processes such as synaptic integration and spike-timing-dependent plasticity~\citep{gerstner2002spiking}. Additionally, modular architectures in AI, where different modules specialize in tasks like memory, control, or perception, are inspired by the brain’s division of labor across distinct but interacting subsystems, such as the hippocampus for memory and the prefrontal cortex for decision-making~\citep{anderson2004integrated}. This modularity facilitates domain-specific processing in a manner that mirrors biological brain organization.

\paragraph{Brain-Likeness in inductive biases} involves the inherent assumptions or constraints within a model’s design that reflect principles believed to govern neural computation. For example, sparse coding in models like Sparse Autoencoders~\citep{ng2011sparse} utilizes sparse activation patterns to prioritize energy-efficient information encoding, mirroring the brain’s efficient neural representation~\citep{olshausen2004sparse}. Equivariance in CNNs allows these networks to recognize objects regardless of their orientation or position, reflecting the brain’s transformational invariance in object recognition~\citep{yamins2016using}. These inductive biases help create internal representations that are more akin to those found in the brain, although models with such biases may still process information differently from biological systems.

\textbf{Brain-likeness in training} examines whether the learning processes of models resemble the experience-driven development that shapes biological brains. Models may employ learning paradigms that mirror the brain’s ability to develop through experience and interaction with the environment. For example, self-supervised learning, as in contrastive learning models like SimCLR~\citep{chen2020simple}, parallels the brain’s ability to learn from unlabelled sensory inputs. Curriculum learning~\citep{bengio2009curriculum} involves progressively tackling more complex tasks, mirroring the staged learning observed in human development, where simpler skills are acquired before more complex ones. Furthermore, embodied agents that interact with their environment to acquire knowledge reflect the brain's dynamic learning through active engagement and adaptation to changing conditions~\citep{pfeifer2006body}. Similarly, curiosity-driven learning~\citep{pathak2017curiosity} encourages models to explore by generating intrinsic rewards based on prediction errors in learned feature spaces, mirroring how biological agents seek out novel, informative experiences to guide learning in the absence of explicit external rewards. Regularization techniques in deep learning can also be drawn from biological principles. Dropout, which randomly deactivates a subset of units during training, was motivated by the stochastic nature of biological neurons, which exhibit Poisson-like firing variability~\citep{hinton2012improving}.

\paragraph{Brain-likeness in computational principles} 
A model can be considered brain-like if its computational or theoretical foundations align with well-established principles of neural computation. 
For example, the most notable of these include classic ideas of predictive coding~\citep{rao1999predictive}, sparse coding~\citep{olshausen1996emergence}, energy efficiency~\citep{laughlin2001energy}, and redundancy reduction~\citep{barlow1961possible}.


\begin{table*}[t]
    \centering
    \caption{Comparative overview of alternate notions of ``brain-likeness''}
    \label{tab:brain_likeness}
    \begin{tabular}{>{\bfseries\raggedright\arraybackslash}m{2.5cm} >{\raggedright\arraybackslash}m{4.5cm} >{\raggedright\arraybackslash}m{5cm} >{\raggedright\arraybackslash}m{4cm}}
        \toprule
        \textbf{Notion of Brain-Likeness} & \textbf{Description} & \textbf{Key Examples} & \textbf{References} \\
        \midrule
        \textbf{Structural Components} & Resemblance in architecture and connectivity patterns & Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Spiking Neural Networks (SNNs), Modular Architectures & Yamins \& DiCarlo (2016); Hubel \& Wiesel (1962) \\
        
        \textbf{Inductive Biases} & Inherent assumptions or constraints in model design & Sparse Autoencoders, Equivariance in CNNs & Olshausen \& Field (1996); Hinton et al. (2012) \\
        
        \textbf{Training Paradigms} & Learning processes that mirror biological development & Self-Supervised Learning (SimCLR), Curriculum Learning, Curiosity-Driven Learning & Chen et al. (2020); Pathak et al. (2017) \\
        
        \textbf{Computational Principles} & Theoretical frameworks guiding neural computation & Predictive Coding, Energy Efficiency, Redundancy Reduction & Rao \& Ballard (1999); Laughlin (2001); Barlow (1961) \\
        \bottomrule
    \end{tabular}
\end{table*}

\subsection{Matching model variability to animal variability}
\label{ss:notions-variability}
A more stringent future direction for model development involves ensuring that the variability observed in models aligns with the variability observed in biological systems. If a model posits a mechanism of variability---such as differences arising from random initial states (e.g., random seeds), stochastic training processes, or architectural variations---it should exhibit a distribution of representational alignments that matches the inter-animal variability seen in neural data. For example, if the alignment scores between a model and neural data vary significantly across different random initializations (or any assumed mechanism of variability), this variability should resemble the natural variability observed across individuals within a species. This requirement ensures that models not only capture the shared computational principles of the brain but also reflect the inherent diversity and noise present in biological systems. By incorporating this constraint, we can develop models that are not only brain-like in their representations but also in their variability, further bridging the gap between artificial and biological intelligence.


\section{Modeling efforts for closing the gap in the NeuroAI Turing Test}
\label{ss:notions-gap}
Despite significant progress in NeuroAI, across various domains, current models remain far from achieving representations that are indistinguishable from those found in the brain. These discrepancies can be broadly categorized into architectural, training, and data-related gaps, each presenting unique challenges that require novel solutions. Additionally, enhancing models to exhibit more brain-like behaviors---such as increased robustness, adaptability, and generalization---can further contribute to bridging the gap in achieving brain-like representations.
\paragraph{Architectural gaps}
The architecture of most artificial neural networks diverges significantly from the brain’s structure, but selectively incorporating certain biological features could help achieve more brain-like representations. Recurrent dynamics, for instance, enable feedback loops and temporal processing~\citep{goldman1995cellular}, allowing models to maintain context, integrate information over time, and develop richer internal states---capabilities that are often limited in feedforward architectures. Modularity, another key feature, mirrors the brain’s organization into specialized, functionally distinct regions that interact hierarchically and in parallel. This could enhance models’ ability to decompose tasks, generalize across domains, and scale efficiently. Additionally, the heterogeneity of neuron types, such as excitatory and inhibitory neurons, plays a critical role in balancing and regulating network activity, which could improve the stability and robustness of artificial systems~\citep{rubin2017balanced}. Another promising feature is sparsity~\citep{olshausen2004sparse}, which reflects the brain’s efficient use of sparse connectivity and activation patterns, reducing computational costs while enabling more flexible and interpretable representations. By thoughtfully integrating these biologically inspired features---recurrent dynamics, modularity, heterogeneity of neuron types, and sparsity---we can develop models that not only perform tasks more effectively but also exhibit internal representations that more closely resemble those of the brain.

\paragraph{Training gaps}
The training paradigms for artificial neural networks often lack key elements that are central to how the brain learns. Unlike the brain, which learns through multimodal training---integrating information from vision, sound, touch, and other senses---many AI models are trained on unimodal datasets, limiting their ability to develop rich representations that are essential for building accurate world models. Additionally, the brain’s learning is deeply rooted in embodiment~\citep{pfeifer2006body}, where sensory and motor experiences are tightly coupled, enabling agents to interact with and learn from their environment in a grounded, context-dependent manner. This is closely tied to agency~\citep{baldassarre2013intrinsically}, the capacity to take actions and observe their consequences, which drives curiosity, exploration, and goal-directed behavior. Incorporating these principles---multimodal training, embodiment, and agency---into AI systems could foster more robust, adaptive, and generalizable learning, possibly also bringing models internal representations closer to the brain.

\paragraph{Data gaps}
A significant challenge in developing brain-like representations lies in the limitations of the data used to train artificial neural networks. Current datasets, such as ImageNet~\citep{Deng2009} for vision and AudioSet~\citep{gemmeke2017audio} for audio, often fail to match the vast and continuous stream of sensory input the brain processes over a lifetime. ImageNet, for instance, contains static, curated images that lack the temporal dynamics and contextual richness of real-world visual experiences, limiting the ability of models to learn spatiotemporal relationships and contextual dependencies. Similarly, AudioSet, though large, is limited in its coverage of natural auditory scenes and their interactions with other modalities, restricting the development of multimodal representations that are critical for understanding complex environments. These datasets also lack diversity and naturalism, as they are often domain-specific and collected in controlled settings, failing to capture the noisy, unstructured, and interactive qualities of real-world experiences. Newer datasets like Ego4D~\citep{grauman2022ego4d}, which focuses on egocentric, multimodal video data captured from wearable cameras, aim to address these gaps by providing large-scale, diverse, and naturalistic datasets that reflect the dynamic, first-person perspective of human interaction with the world. By training on such data, models can develop more brain-like internal representations---rich, context-aware, and multimodal---that mirror the brain’s ability to process and integrate complex, real-world information

The gap in achieving brain-like representations in NeuroAI reflects limitations across architecture, training paradigms, and data. While addressing these gaps individually is crucial, they are deeply interconnected: improvements in architecture and training can benefit from better data, and behavioral alignment can provide constraints that shape internal representations to be more brain-like. Closing the gap for brain-like behaviors, including robustness, adaptability, and generalization, is also likely to drive corresponding improvements in representational alignment. 


\section{Metrics for representational comparisons} 
\label{ss:notions-metrics}
No single metric can fully capture the complexity of brain-like representations. Therefore, a combination of complementary metrics that probe different dimensions of neural alignment should be used to provide a comprehensive evaluation. Metrics for evaluating model-brain alignment can be broadly divided into two main categories: alignment-based measures and representational similarity matrix (RSM)-based measures. Alignment-based measures quantify the distance or similarity between model and neural representations after aligning their dimensions, while RSM-based measures compare stimulus-by-stimulus similarity matrices derived from model and neural data. These categories can be further subdivided based on symmetry, scope of similarity (global vs. local), and level of alignment (population vs. unit-level).
Alignment-based measures include methods like linear predictivity~\citep{yamins2014performance}, canonical correlation analysis (CCA)~\citep{hotelling1992relations}, Procrustes distance~\citep{williams2021generalized}, soft matching~\citep{khosla2024soft}, and pairwise matching~\citep{khosla2024privileged, li2015convergent}. These methods differ in whether they quantify similarity at the population level (e.g., overall information content, as in CCA or linear predictivity) or the unit level (e.g., correspondence between individual model and neural units, as in soft or pairwise matching). They also differ in symmetry: some are symmetric (e.g., CCA, Procrustes, soft matching), treating both representations equally, while others are asymmetric (e.g., linear predictivity, pairwise matching), reflecting directional relationships.
RSM-based measures, such as representational similarity analysis (RSA)~\citep{kriegeskorte2008representational}, centered kernel alignment (CKA)~\citep{kornblith2019similarity}, and mutual $k$-nearest neighbors (mutual $k$-NN)~\citep{huhposition}, focus on comparing the similarity structure of model and neural representations. These methods can be distinguished by their scope of similarity: global metrics like RSA and CKA use all samples to compute distances, capturing the overall geometry of the representational space, while local metrics like mutual $k$-NN focus on neighborhood consistency, evaluating whether individual stimuli have similar neighboring points across the two representational spaces.

Each metric captures a distinct dimension of similarity and together, they provide complementary insights into the nature of alignment between models and brains (cf. Table~\ref{tab:metrics} for a summary). For example, global metrics like RSA and CKA reveal whether the model captures the overall geometry of neural representations, while local metrics like mutual $k$-NN assess whether local neighborhoods of a stimulus are similar across the model and brain representations. Alignment-based measures like linear predictivity and CCA evaluate how well the model’s information content aligns with neural data, while unit-level measures like soft matching test whether individual model units correspond to specific neural units. A model might close the gap in terms of overall information content (e.g., as measured by linear predictivity or CCA) but fail to replicate unit-level responses that are consistent across animals (e.g., as measured by soft matching or pairwise matching). This discrepancy would indicate that while the model captures the global structure of neural representations, important fine-grained details---such as the specific tuning curves or response properties of individual units---remain unexplained. Such findings can prompt novel model development efforts, particularly those focused on producing the correct axes of neural representations (e.g., tuning curves, receptive fields) that are conserved across individuals. By systematically evaluating models across multiple metrics, we can identify which dimensions of alignment are well-matched and which require further refinement, ultimately driving the development of models that more fully emulate the brain’s representational properties.

\begin{table}[t]
\centering
\caption{Categorization of common metrics for model-brain alignment. 
Symmetry and scope are also indicated for each metric.}
\label{tab:metrics}
\resizebox{0.85\columnwidth}{!}{
\begin{tabular}{ll lll}
\toprule
\textbf{Category}         & \textbf{Subcategory}         & \textbf{Metric}        & \textbf{Symmetry}  & \textbf{Scope}       \\
\midrule
\multirow{5}{*}{\textbf{Alignment-Based}}    
                          & \multirow{3}{*}{Population-Level Similarity} 
                          & Linear Predictivity         & Asymmetric   & Global  \\
                          &                              & CCA                     & Symmetric    & Global  \\
                          &                              & Procrustes              & Symmetric    & Global  \\
                          & \multirow{2}{*}{Unit-Level Similarity}   
                          & Soft Matching              & Symmetric    & Global  \\
                          &                              & Pairwise Matching       & Asymmetric   & Global  \\
\midrule
\multirow{3}{*}{\textbf{RSM-Based}}  
                          & \multirow{2}{*}{Global Similarity}  
                          & RSA                         & Symmetric    & Global  \\
                          &                              & CKA                     & Symmetric    & Global  \\
                          & Local Similarity            & Mutual $k$-NN           & Symmetric    & Local   \\
\bottomrule
\end{tabular}
}
\end{table}