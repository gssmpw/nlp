\section{Related work}
\paragraph{Graph inference with different query models.}
Graph inference has been studied under various models, with {edge detection} and {edge counting} being two prominent approaches motivated by applications in biology. In these models, queries allow one to check whether an induced subgraph contains any edges or to determine the number of edges in the subgraphBollob√°s et al., "The Isolation Game"__Chen et al., "Efficient Graph Reconstruction"

demonstrated that bounded-degree graphs can be fully reconstructed using $\widetilde{O}(n^{3/2})$ SP queries. They further showed that bounded-treewidth chordal graphs and outerplanar graphs can be reconstructed with $\widetilde{O}(n\log n)$ SP queries. This result has been recently generalized to bounded-treewidth graphs without long cycles by Chen et al., "Graph Reconstruction via Sparsification"__, with additional related work by Rong et al., "Reconstructing Graphs from Shortest Path Queries".

In contrast to the SP model, significantly fewer theoretical results are known for the {effective resistance (ER) model}. It has been established that a hidden graph can be fully reconstructed if the ER distances between all pairs of its vertices are knownKarger and Cheung, "Graph Reconstruction via Effective Resistance"__and is further investigated in Chen et al., "Efficient Graph Reconstruction".

A continuous variant of the graph reconstruction problem, known as \emph{Calder\'{o}n's inverse problem}, is to recover the conductivity of an object from measurements of current and potential on its surface.  Calder\'{o}n's inverse problem has been studied extensively by mathematiciansSylvester, "The Calder\'{o}n Problem"__and found important applications in Electrical Impedance Tomography (EIT) in medical imagingNatterer, "The Mathematics of Computerized Tomography"__ and Electrical Resistivity Tomography (ERT) in geophysicsBinley et al., "Electrical Resistivity Tomography".

\paragraph{Property testing.}
We study the gap version of checking properties of graphs using ER queries. In this setting, the goal is to distinguish between graphs that possess a certain property and those that are ``far'' from having that property, using only a few ER queries. This part of our work is related to property testing of graphs in the bounded-degree model. Many properties have been studied in this model, including $k$-connectivity, bipartiteness, subgraph exclusion, minor exclusion, and planarity. We refer the reader to Alon et al., "Property Testing"__for an extensive exposition of known results in this area. 
For contrast, we study property testing algorithms that rely only on resistance distance queries rather than adjacency queries.

More broadly, our work is also related to sublinear-time algorithms for finite metric spaces. Such algorithms become particularly relevant when one is interested in estimating parameters such as the average ER distance or identifying the central point in the ER metric space. Notably, these algorithms operate without reconstructing the graph or explicitly learning its topology. There is a substantial body of work on testing properties of metric spaces; see, for example,Gurjar et al., "Testing Metric Distances".

\paragraph{Graph machine learning.}

One important (albeit perhaps less direct) motivation for our work is graph machine learning. Currently, there are no polynomial-time machine learning algorithms (e.g.,~graph neural networks) that can completely capture the structure of a graph; that is to say, all existing methods will give the same output on some set of non-isomorphic graphs (see Dehmamy et al., "Learning Graphs with Topological Constraints"__for an example). This means that no graph learning algorithm captures all properties of a graph.
\par 
As an imperfect solution, one approach is compute some quantities associated with the graph and use these as input to the machine learning algorithm. For example, one could compute the effective resistance between all pairs of vertices (as in Karger et al., "Graph Reconstruction via Effective Resistance")__and use this as an input to a neural network. These graph quantities are sometimes called \textit{positional encodings}. Since the use of positional encodings is known not to completely capture the topology of a graph, researchers instead ask which properties of a graph these encodings do capture. For example, effective resistance increases the expressive power of message-passing neural networksKipf et al., "Variational Graph Autoencoders"__transfomers Li et al., "Graph Neural Networks with Effective Resistance" using effective resistance as a positional encoding can determine which vertices are cut vertices (a property neither message-passing neural networks nor shortest-path distance can detect)___ and transformers using effective resistance can determine which edges are cut edges__.