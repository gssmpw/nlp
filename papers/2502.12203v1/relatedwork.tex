\section{Related Work}
\label{sec:relatedwork}

In this section, we review the various lines of related research on which this paper is based.

\subsection{Automated Mechanism Design}
The analytical results of optimal auction design have been limited to simple mechanism design settings such as variations of single-bidder settings. Theoretical studies have not been able to explore the full intricacy of mechanism design; a new direction, automated mechanism design (AMD), was introduced to help in this exploration. 

Discretizing the players' type spaces allows for the AMD problem to be solved as a linear-programming problem (or, if a deterministic mechanism is desired, a mixed-integer linear program)~\cite{Conitzer02:Complexity,Conitzer04:Self,conitzer2003applications}.
But the cost of such generality is that it is hard to scale this approach.
Several more scalable approaches to AMD have been developed to address scalability issues. One such approach is parametric mechanism design, which restricts the search space to a specific class of parameterized mechanisms. This method has proven effective in various settings, including helping conjecture and proving analytical results. Examples include auction design~\cite{Sandholm15:Automated,sandholm2003automated} and the design of mechanisms that redistribute as much of the auction revenue back to bidders as possible~\cite{cavallo2008efficiency,guo2016competitive,guo2007worst,guo2008undominated,guo2024worst,guo2014better,guo2012worst,guo2011vcg,guo2010optimal,guo2008better} (for an overview of this approach, see~\cite{Guo10:Computationally}).  
On the other hand, in a sense this approach is only partly automated, in that specifying a good parameterized class of mechanisms still requires human insight. Consequently, this approach has been successful only in some domains. 



\subsection{Differentiable Auction Design and Neurosymbolic AI} 
More recently, differentiable methods have been introduced that use neural networks to do auction design~\cite{RochetNet,GEMNet,shen2018automated,rahme2021permutation,feng2018deep}. The main challenge is to fulfill the expressiveness, strategy-proofness, and multi-bidder requirements. In terms of expressiveness, though the optimal auctions are represented by the neural network, the resulting mechanisms are hard to interpret from the weights of the neural network.

A recent direction for AI research, neurosymbolic approaches that combine neural networks with symbolic reasoning, is promising for solving the interpretability issue. These methods have shown success in learning interpretable program models, improving efficiency and generalization in various tasks, and enhancing AI system explainability~\cite{hitzler2022neuro,sarker2022neuro,sheth2023neurosymbolic}. By bridging neural computation with symbolic representation, neurosymbolic AI could potentially address interpretability challenges in mechanism design while maintaining computational efficiency.

\subsection{Large Language Models and Code Generation}
Large Language Models (LLMs) have revolutionized natural language processing, demonstrating remarkable capabilities in reasoning, problem-solving, and text generation~\cite{zhao2023survey}. Recent advancements have led to models with enhanced abilities in multi-step reasoning and logical deduction, such as GPT-o1 and DeepSeek-R1\footnote{GPT-o1: \url{https://platform.openai.com/docs/models\#o1}, DeepSeek-R1: \url{https://github.com/deepseek-ai/DeepSeek-R1}.}~\cite{xiang2025towards,guan2025rstar,liu2024deepseek,mercer2025brief}.

In the realm of code generation, LLMs have shown impressive capabilities~\cite{nijkamp2022codegen,fried2022incoder,chen2021evaluating}.
Code generation refers to the automatic creation of source code from high-level descriptions, specifications, or natural language prompts. LLMs have achieved notable performance in code generation tasks, such as solving problems from coding competitions~\cite{AlphaCode}, debugging~\cite{Program-Repair-Inferfix,chen2023teaching,liventsev2023fully}, and improving the given code~\cite{Code-edits}. One reason for LLMs' excellent performance is their training on vast datasets of both natural language and code, enabling them to understand context, generate syntactically correct code, and work across multiple programming languages.
These works provide the foundations for solving various tasks via LLM-powered code generation. 
Developers can already take advantage of existing LLM-based code generation tools such as GitHub Copilot\footnote{\url{https://github.com/features/copilot}} to assist with code explanation, debugging, and writing. 
Given the recent advancements in LLMs, it is natural to explore the application of LLM-based code generation techniques to mechanism design problems. 


\subsection{Evolutionary Algorithms}
Evolutionary Algorithms (EAs) are a class of optimization techniques inspired by biological evolution. These algorithms leverage principles such as natural selection, mutation, and crossover to solve complex problems in computer science and engineering, iteratively improving a population of candidate solutions through score-based selection (often called ``fitness-based'' in the EA literature) and stochastic variation operators. 
EAs excel in navigating high-dimensional, multi-modal, and non-differentiable search spaces where traditional gradient-based methods often get stuck~\cite{yu2010introduction,slowik2020evolutionary}. 

Recent works combine EAs with LLMs, introducing EA-based prompt engineering, particularly for mathematical and algorithmic discovery.
FunSearch~\cite{FunSearch} iteratively generates improved solutions in the form of computer ``function'' code given previous good solutions using LLMs, verifies the generated solutions with an automated ``evaluator'', then maintains a pool of good solutions with the island-based evolutionary method to encourage exploration and avoid getting trapped at sub-optimal solutions.
Evolution of Heuristics (EoH)~\cite {liu2024evolution} proposes a similar heuristic evolution framework as FunSearch.  EoH explicitly specifies the evolution strategies and incorporates one of these strategies into the prompt in each iteration. The LLM can then understand this strategy prompt and evolve accordingly. 
Self-Taught Optimizer (STOP)~\cite{zelikman2023self} investigates sequential heuristic optimization techniques with other optimization techniques in addition to evolutionary algorithms. The techniques discussed in STOP include multi-armed bandits, tree search, and simulated annealing-based search. 
There are also techniques that utilize EAs to do automatic prompt improvement. An example is Promptbreeder~\cite{fernando2023promptbreeder}, which automatically evolves and optimizes the prompts for the LLM. 
It iteratively improves the task prompts and the mutation prompts, guiding their evolution.



\subsection{Programming-by-Example}
While LLMs are known for their expertise in deductive reasoning tasks (following the input instructions and reasoning as told), they also have strong capabilities in inductive reasoning tasks, where they infer underlying patterns from input-output pairs or cause-effect relationships~\cite{cheng2024inductive}. This capability makes them particularly well-suited for Programming-by-Example (PBE), a technique where a system automatically generates programs or algorithms from example input-output pairs. Instead of manually writing code, users provide examples of the desired behavior, and the system infers the rules to replicate and generalize that behavior for new inputs~\cite{gulwani2017program,halbert1984programming}.
PBE has been successfully applied in various domains, such as automating repetitive tasks in spreadsheets~\cite{wu2023programming}, and synthesizing data transformations~\cite{jin2017foofah,feser2015synthesizing}. This method significantly reduces the need for manual coding. 
Recent advancements in LLMs have expanded PBE's scope, enabling systems to handle more complex tasks with fewer examples. By leveraging their training data and reasoning capabilities, LLMs can infer patterns and generate robust, generalizable programs~\cite{cheng2024inductive}.