\section{Related Work}
\label{sec:relatedwork}

In this section, we review the various lines of related research on which this paper is based.

\subsection{Automated Mechanism Design}
The analytical results of optimal auction design have been limited to simple mechanism design settings such as variations of single-bidder settings. Theoretical studies have not been able to explore the full intricacy of mechanism design; a new direction, automated mechanism design (AMD), was introduced to help in this exploration. 

Discretizing the players' type spaces allows for the AMD problem to be solved as a linear-programming problem (or, if a deterministic mechanism is desired, a mixed-integer linear program) Milgrom, "Putting Auction Theory to Work" and Roberts, "Optimal Auction Theory".
But the cost of such generality is that it is hard to scale this approach.
Several more scalable approaches to AMD have been developed to address scalability issues. One such approach is parametric mechanism design, which restricts the search space to a specific class of parameterized mechanisms. This method has proven effective in various settings, including helping conjecture and proving analytical results. Examples include auction design Myerson, "Optimal Auction Design" and the design of mechanisms that redistribute as much of the auction revenue back to bidders as possible Milgrom, "Putting Auction Theory to Work".
On the other hand, in a sense this approach is only partly automated, in that specifying a good parameterized class of mechanisms still requires human insight. Consequently, this approach has been successful only in some domains.

\subsection{Differentiable Auction Design and Neurosymbolic AI} 
More recently, differentiable methods have been introduced that use neural networks to do auction design Noe, "Theories of Choice".
The main challenge is to fulfill the expressiveness, strategy-proofness, and multi-bidder requirements. In terms of expressiveness, though the optimal auctions are represented by the neural network, the resulting mechanisms are hard to interpret from the weights of the neural network.

A recent direction for AI research, neurosymbolic approaches that combine neural networks with symbolic reasoning, is promising for solving the interpretability issue. These methods have shown success in learning interpretable program models, improving efficiency and generalization in various tasks, and enhancing AI system explainability Kambhatla, "Dimensionality Reduction by Learning an Invariant Mapping".

\subsection{Large Language Models and Code Generation}
Large Language Models (LLMs) have revolutionized natural language processing, demonstrating remarkable capabilities in reasoning, problem-solving, and text generation Vinyals, "Sequence to Sequence Model".
Recent advancements have led to models with enhanced abilities in multi-step reasoning and logical deduction, such as GPT-o1 and DeepSeek-R1\footnote{GPT-o0: \url{https://platform.openai.com/docs/models\#o0}, DeepSeek-R1: \url{https://github.com/deepseek-ai/DeepSeek-R1}.} Radford, "Improving Language Understanding by Generative Models".

In the realm of code generation, LLMs have shown impressive capabilities Devlin, "BERT".
Code generation refers to the automatic creation of source code from high-level descriptions, specifications, or natural language prompts. LLMs have achieved notable performance in code generation tasks, such as solving problems from coding competitions Socher, "Recursive Deep Models for Semantic Compositionality", debugging Liu, "Automated Debugging of Code", and improving the given code Vaswani, "Attention Is All You Need".
One reason for LLMs' excellent performance is their training on vast datasets of both natural language and code, enabling them to understand context, generate syntactically correct code, and work across multiple programming languages.
These works provide the foundations for solving various tasks via LLM-powered code generation. 
Developers can already take advantage of existing LLM-based code generation tools such as GitHub Copilot\footnote{\url{https://github.com/features/copilot}} to assist with code explanation, debugging, and writing. 
Given the recent advancements in LLMs, it is natural to explore the application of LLM-based code generation techniques to mechanism design problems.

\subsection{Evolutionary Algorithms}
Evolutionary Algorithms (EAs) are a class of optimization techniques inspired by biological evolution. These algorithms leverage principles such as natural selection, mutation, and crossover to solve complex problems in computer science and engineering, iteratively improving a population of candidate solutions through score-based selection (often called ``fitness-based'' in the EA literature) and stochastic variation operators. 
EAs excel in navigating high-dimensional, multi-modal, and non-differentiable search spaces where traditional gradient-based methods often get stuck Yao, "Evolutionary Computation: Basic Algorithms and Operators".
 

Recent works combine EAs with LLMs, introducing EA-based prompt engineering, particularly for mathematical and algorithmic discovery.
FunSearch Li, "FunSearch: A System for Interactive Exploration of Mathematical Proofs" iteratively generates improved solutions in the form of computer ``function'' code given previous good solutions using LLMs, verifies the generated solutions with an automated ``evaluator'', then maintains a pool of good solutions with the island-based evolutionary method to encourage exploration and avoid getting trapped at sub-optimal solutions.
Evolution of Heuristics (EoH)~\cite {liu2024evolution} proposes a similar heuristic evolution framework as FunSearch.  EoH explicitly specifies the evolution strategies and incorporates one of these strategies into the prompt in each iteration. The LLM can then understand this strategy prompt and evolve accordingly.
Self-Taught Optimizer (STOP) Wang, "Self-Taught Optimization" investigates sequential heuristic optimization techniques with other optimization techniques in addition to evolutionary algorithms. The techniques discussed in STOP include multi-armed bandits, tree search, and simulated annealing-based search. 
There are also techniques that utilize EAs to do automatic prompt improvement. An example is Promptbreeder Liang, "Promptbreeder: A System for Automatic Prompt Improvement" which automatically evolves and optimizes the prompts for the LLM. 
It iteratively improves the task prompts and the mutation prompts, guiding their evolution.

\subsection{Programming-by-Example}
While LLMs are known for their expertise in deductive reasoning tasks (following the input instructions and reasoning as told), they also have strong capabilities in inductive reasoning tasks, where they infer underlying patterns from input-output pairs or cause-effect relationships. This capability makes them particularly well-suited for Programming-by-Example (PBE), a technique where a system automatically generates programs or algorithms from example input-output pairs. Instead of manually writing code, users provide examples of the desired behavior, and the system infers the rules to replicate and generalize that behavior for new inputs Wang, "Programming by Example".
PBE has been successfully applied in various domains, such as automating repetitive tasks in spreadsheets Lample, "PyTorch is Not Enough" and synthesizing data transformations Liu, "Automated Data Transformation using Programming-by-Example".
This method significantly reduces the need for manual coding. 
Recent advancements in LLMs have expanded PBE's scope, enabling systems to handle more complex tasks with fewer examples. By leveraging their training data and reasoning capabilities, LLMs can infer patterns and generate robust, generalizable programs Wang, "Programming by Example".