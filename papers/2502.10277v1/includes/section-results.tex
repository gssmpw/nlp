\section{Results}

\subsection{Data Set Characteristics}
The data sets encompassed $\num{6669}$ patients, each represented by one dental panoramic radiograph (DPR), across continents and clinical sites. 
The training data set (from the Netherlands) comprised $\num{4044}$ patients, while the test data sets (from the Netherlands, Brazil, Taiwan) included a total of $\num{2625}$ patients (48.2\% female and 51.7\% male\footnote{Accounting only the Netherlands test set and the Taiwan set, where demographics were known.}).
The overall mean age was 40.2 years.
The test DPRs contained a total of \num{84000} full dentition teeth slots, exhibiting various findings.
The prevalence of findings included fillings ($n=\num{16926}$; 20.15\%), missing teeth ($n=\num{14581}$; 17.36\%), crown/bridges ($n=\num{6288}$; 7.49\%), root canal fillings ($n=\num{3832}$; 4.56\%), caries ($n=\num{2822}$; 3.36\%), implants ($n=\num{1405}$; 1.67\%), periapical radiolucencies ($n=\num{1035}$; 1.23\%), and residual roots ($n=\num{427}$; 0.51\%).
Detailed statistics of the data sets are provided in Table~\ref{tbl:data-statistics}.

\subsection{Performance Comparison of AI with Human Readers}
\label{sec:ai-vs-reader}

\input{./includes/fig-ai-vs-reader}

In the Taiwan* test subset of $\num{118}$ images, we assessed the performance of the AI system and four readers (G1, G2, S1, and S2) against the reference.
The AI system's receiver operating characteristic (ROC) curve and the set operating points are displayed in Figure~\ref{fig:ai-vs-reader}.
% Appendix~\ref{sec:performance-comparison-detailed} includes more numerical results.
Supplementary Material includes more numerical results.
All operating points were chosen for the optimal $\textrm{F}_2$ score to prioritize sensitivity for screening scenarios.
AUC-ROC values for all findings exceeded 80\%, reaching a macro-averaged AUC-ROC of 96.2\% (95\% CI: 94.6\%--97.8\%) across 8 finding types.

The AI illustrated a statistically significant improvement in sensitivity for periapical radiolucencies at +67.9\% (95\% CI: 54.0\%--81.9\%; $p < .001$ for superiority) compared to the average human reader, while maintaining non-inferiority in specificity ($p < .001$ at a pre-specified 5\% margin).
Similarly, for missing teeth, the AI system demonstrated, over the average reader, a statistically significant improvement in sensitivity at +4.7\% (95\% CI: 1.4\%--8.0\%; $p = .008$) along with non-inferiority in specificity ($p < .001$).

For other dental findings, the AI system achieved simultaneous non-inferiority in both sensitivity ($p = .0049$) and specificity ($p < .001$) for implants, crown/bridges ($p = .0012$, $p < .001$), root canal fillings ($p = .0090$, $p < .001$), and caries ($p = .040$, $p < .001$).
Specificity for residual roots showed non-inferiority ($p < .001$), and for fillings, sensitivity also demonstrated non-inferiority ($p = .034$).

\subsection{AI Generalization across Multinational Data}
\label{sec:ai-generalizability}

\input{./includes/tbl-ai-multinational-short}
\input{./includes/fig-ai-generalizability}

The AI system, trained exclusively on the Netherlands training set, was tested and evaluated on the Netherlands test set, the Brazil set, and the Taiwan set.
An operating point optimized for screening settings was chosen similarly to Section~\ref{sec:ai-vs-reader}, and the system's performance was compared against the reference finding summary, as depicted in Figure~\ref{fig:ai-generalizability} and Table~\ref{tbl:ai-multinational-short}.

Across both internal (the Netherlands) and external (Brazil and Taiwan) test sets, the AUC-ROC scores were consistently above 80\% for all findings.
The macro-averaged AUC-ROC across test sets was 99.4\% (95\% CI: 99.1\%--99.7\%) for root canal fillings, 99.2\% (95\% CI: 98.3\%--100.0\%) for implants, and 98.8\% (95\% CI: 97.7\%--99.9\%) for crown/bridges.
AUC-ROC scores for periapical radiolucencies and caries were 92.1\% (95\% CI: 87.7\%--96.6\%) and 81.5\% (95\% CI: 79.1\%--84.0\%), respectively.

The average sensitivity across test sets was highest for implants at 97.6\% (95\% CI: 95.0\%--100.0\%) and lowest for caries at 52.1\% (95\% CI: 44.7\%--59.5\%).
Similarly, specificity peaked for residual roots at 99.5\% (95\% CI: 99.0\%--100.0\%) and was lowest for caries at 90.4\% (95\% CI: 84.6\%--96.1\%).
Precision was highest for root canal fillings at 91.4\% (95\% CI: 86.6\%--96.2\%) and notably lower for caries at 21.9\% (95\% CI: 9.7\%--34.1\%).

Evaluating discrepancies in AI performance between the internal and external test sets revealed no statistically significant differences in AUC-ROC or sensitivity across all findings.
However, specificity for root canal fillings showed a statistically significant decrease in the external test sets compared to the internal test set ($p = .035$).
Similarly, precision for residual roots was significantly lower in the external test sets ($p = .042$).

As for the agreements between the AI and the reference, see Supplementary Material for a detailed discussion.

\subsection{Reading Times}

The average reading time on a DPR for the four human readers was 122 seconds (95\% CI: 118~s--126~s; IQR: 79~s--155~s).
In comparison, the AI system demonstrated markedly faster processing times across its three stages.
The first stage, which involved detecting findings in the DPRs, required an average of 0.28 seconds per case (95\% CI: 0.27~s--0.28~s; IQR: 0.26~s--0.30~s).
The second stage, dedicated to classifying tooth indices, took 0.20 seconds (95\% CI: 0.19~s--0.20~s; IQR: 0.18~s--0.22~s).
The final post-processing stage required 1.08 seconds (95\% CI: 1.05~s--1.11~s; IQR: 1.00~s--1.14~s).
Consequently, the total runtime for the AI system averaged 1.55 seconds per image (95\% CI: 1.52~s--1.58~s; IQR: 1.43~s--1.66~s), based on the machine specifications detailed in Section~\ref{sec:ai-system}.