\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\textwidth, height=0.8\textheight, keepaspectratio]{./assets/fig-ai-generalizability.pdf}
    \caption{
        \textbf{AI Generalization Performance across Multinational Data Sets.}
        This figure evaluates the AI's capability to generalize its performance across different geographic data sets, focusing on the assessment of DPRs.
        The operating point of the AI system was optimized to maximize the $\textrm{F}_2$ score on a held-out validation set, simulating a screening scenario.
        Each bar represents the AI's performance metric for a specific dental finding within a dataset, with the 95\% confidence intervals shown as error bars.
        Notably, the $y$-axes for some metrics do not start from zero to highlight specific performance ranges.
        Cohen's Kappa values among pairs of the human readers (G1, G2, S1, and S2) were computed and displayed along the AI's Kappa against the reference, serving as a contextual upper limit for AI performance.
        % A comprehensive exploration on the inter-human-reader agreements is included in Appendix~\ref{sec:consistency-of-human}.
        A comprehensive exploration on the inter-human-reader agreements is included in Supplementary Material.
    }
    \label{fig:ai-generalizability}
\end{figure}