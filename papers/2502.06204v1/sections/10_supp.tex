\begin{figure*}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/zero-shot-lms.png} 
    \caption{Probabilities of each pair of $(u, s)$, predicted by different LLMs under \textbf{zero-shot} prompting (with $\tau=1$) (facets, x-axis), plotted against human results (y-axis), coded for each type of interpretation (color) and item (dot shape).}
    \label{fig:expt1}
\end{figure*}

\begin{table}[h]
\centering
\begin{tabular}{llll}
\toprule
 \textbf{LLM} & GPT & Claude & Gemini \\ \midrule
 1-shot price prior CoT& 0.7  & 0.596 & 0.774 \\
 1-shot speaker goals CoT & 0.472 & 0.552 & 0.501 \\
 full LM-based RSA & 0.783  & 0.80 & 0.76 \\
 \bottomrule
\end{tabular}
\caption{Correlation between human predictions of $(s,u)$ probabilities, and results from LLMs under different RSA-inspired approaches. Results for ablations of the CoT prompt are presented where only reasoning about the prior (1-shot price prior CoT) or the speaker communicative goal (1-shot speaker goal CoT) are included. LLM-based RSA refers to results of the full RSA model with both LLM priors and LLM speaker likelihoods. \label{tab:gpt-prompting-comparison}}
\end{table}

\subsection{LLM Zero-Shot performance}
\label{sec:app:zero-shot}
To test whether LLMs arrive at non-literal meanings of
numbers when people do, we closely follow the procedure
and the scenarios presented in \citet{kao2014nonliteral}. To this end, we construct zero-shot prompts to sample LLMs' judgments of probabilities of different true prices $s \in S$, given a speaker's utterance mentioning a price $u \in U$. An example prompt is presented in~\autoref{tab:prompts}.
Results of LLM predictions for all items and all $(u,s)$ pairs are shown against human results in~\autoref{fig:expt1}. 
Under zero-shot prompting, LLMs did not show high correlation with human results, instead showing a tendency towards literal interpretations. 
Furthermore, different models exhibited distinct distributional patterns: GPT-4o-mini tended to assign inflated probabilities to individual utterance-meaning pairs, while Gemini-1.5-pro generally exhibited a bimodal distribution of ratings at the ends of the scale.

\subsection{Guiding LLM Interpretation with the RSA model}
\label{sec:prompting}

To test if the computational steps formalized by the RSA model
can be used to guide LLMs’ interpretation of hyperbole and pragmatic halo in a more human-like way, we compare two possible approaches to integrating the RSA model with LLMs. 

First, we construct a one-shot chain-of-thought (CoT) prompt that verbally describes critical components within the RSA model: reasoning about possible speaker goals and priors of prices for an example every-day item (a toaster).
The full prompt is shown in~\autoref{prompt:rsa}.
\input{figs/rsa}

Results reported in~\autoref{tab:cor_table} (1-shot RSA CoT) indicate that the RSA-couched prompting effectively helped to guide LLMs towards more human-like interpretation, improving the correlation between LLM predictions and human data from \citet{kao2014nonliteral}.

To critically assess the robustness of the prompting and which aspects of the prompt really drive the performance improvements, we ablate parts of the prompt corresponding to different computational components of the RSA model.
Specifically, we construct a speaker-goals prompt which only exemplifies reasoning about different speaker goals (see~\autoref{prompt:rsa-qud}), and a priors prompt which only exemplifies reasoning about price priors (see~\autoref{prompt:rsa-priors}).
\input{figs/qud_only}
\input{figs/priors_only}
Results of these ablations as measured by the correlation with human data are presented in~\autoref{tab:gpt-prompting-comparison}.
Compared to the full one-shot CoT prompt, the speaker goals only prompt led to lower correlation between LLM and human data for all LLMs.
The priors only prompt, on the other hand, increased the correlation between LLM and human results more strongly than the full one-shot CoT prompt (see~Table~\ref{tab:cor_table} in main text). 
These ablation results suggest
that LLM performance can be supported through RSA model
inspired prompting, but the prompt components required for substantially increasing LLM performance may not necessarily have to fully replicate all the computational components
needed for explaining human performance.

\subsection{LM-RSA Simulations}
Second, we used the RSA model to quantify the LLMs' internal consistency between its own predicted priors and zero-shot prompting based predictions.
To this end, we used the priors of prices for different items and for priors for affect, given a price, predicted by LLMs, elicited in Experiment~3.
We then fit the RSA model proposed by \citet{kao2014nonliteral} using the priors from each LLM, resulting in the \textit{LM-RSA model}.
The RSA model includes two hyperparameters that were fit to human behavioral data. 
To adjust for biases against using the extreme probability ratings for the $(u,s)$ pairs, a power-law transformation was performed: we
multiplied the predicted probability for each $(u,s)$ pair by a free parameter $\lambda$, and renormalized the probabilities to sum up to 1 for each utterance $u$. 
The $\lambda$ was jointly fit with the model’s cost ratio $C$. 
$C(u) = 1$ was used when $u$ was a round number (divisible by 10) and the cost for sharp utterances was fit to human data.
We tune the cost and $\lambda$ hyperparameters individually for each LM-RSA. 
The optimal $\lambda$ was chosen via search over $[0, 1)$ with steps of 0.01. The optimal $C$ was chosen via search over $[1, 4)$ with steps of 
0.1. The best hyperparameters which were used to produce results reported in the main text are shown in~\autoref{tab:rsa-hyperparams}.
\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
                   & $\lambda$ & $C$ \\ 
\midrule
Human priors       & 0.44   & 1.2  \\ 
GPT-4o-mini priors & 0.41   & 1.4   \\ 
Claude-3.5-sonnet priors & 0.39   & 2.0   \\ 
Gemini-1.5-pro priors & 0.38 & 1.1 \\ 
\bottomrule
\end{tabular}
\caption{Best hyperparameters of the RSA model, fit separately for each LLM-RSA model. \label{tab:rsa-hyperparams}}
\end{table}

