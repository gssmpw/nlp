[
  {
    "index": 0,
    "papers": [
      {
        "key": "rahimi2007random",
        "author": "Rahimi, Ali and Recht, Benjamin",
        "title": "Random features for large-scale kernel machines"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "gerace2020generalisation",
        "author": "Gerace, Federica and Loureiro, Bruno and Krzakala, Florent and M{\\'e}zard, Marc and Zdeborov{\\'a}, Lenka",
        "title": "Generalisation error in learning with random features and the hidden manifold model"
      },
      {
        "key": "goldt_gaussian_2021",
        "author": "Goldt, Sebastian and Loureiro, Bruno and Reeves, Galen and Krzakala, Florent and Mezard, Marc and Zdeborova, Lenka",
        "title": "The Gaussian equivalence of generative models for learning with shallow neural networks"
      },
      {
        "key": "mei2022generalization",
        "author": "Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea",
        "title": "Generalization error of random feature and kernel methods: hypercontractivity and kernel matrix concentration"
      },
      {
        "key": "Mei2023",
        "author": "Song Mei and Theodor Misiakiewicz and Andrea Montanari",
        "title": "Generalization error of random feature and kernel methods: Hypercontractivity and kernel matrix concentration"
      },
      {
        "key": "xiao2022precise",
        "author": "Xiao, Lechao and Hu, Hong and Misiakiewicz, Theodor and Lu, Yue and Pennington, Jeffrey",
        "title": "Precise learning curves and higher-order scalings for dot-product kernel regression"
      },
      {
        "key": "defilippis2024dimension",
        "author": "Defilippis, Leonardo and Loureiro, Bruno and Misiakiewicz, Theodor",
        "title": "Dimension-free deterministic equivalents for random feature regression"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mei2022generalization",
        "author": "Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea",
        "title": "Generalization error of random feature and kernel methods: hypercontractivity and kernel matrix concentration"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ghorbani2021linearized",
        "author": "Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea",
        "title": "Linearized two-layers neural networks in high dimension"
      },
      {
        "key": "ba2020generalization",
        "author": "Ba, Jimmy and Erdogdu, Murat and Suzuki, Taiji and Wu, Denny and Zhang, Tianzong",
        "title": "Generalization of two-layer neural networks: An asymptotic viewpoint"
      },
      {
        "key": "dandi2024random",
        "author": "Dandi, Yatin and Pesce, Luca and Cui, Hugo and Krzakala, Florent and Lu, Yue M and Loureiro, Bruno",
        "title": "A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "barbier2019optimal",
        "author": "Barbier, Jean and Krzakala, Florent and Macris, Nicolas and Miolane, L{\\'e}o and Zdeborov{\\'a}, Lenka",
        "title": "Optimal errors and phase transitions in high-dimensional generalized linear models"
      },
      {
        "key": "aubin2018committee",
        "author": "Aubin, Benjamin and Maillard, Antoine and Krzakala, Florent and Macris, Nicolas and Zdeborov{\\'a}, Lenka and others",
        "title": "The committee machine: Computational to statistical gaps in learning a two-layers neural network"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mei2022generalization",
        "author": "Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea",
        "title": "Generalization error of random feature and kernel methods: hypercontractivity and kernel matrix concentration"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "BenArous2021",
        "author": "Gerard {Ben Arous} and Reza Gheissari and Aukosh Jagannath",
        "title": "Online stochastic gradient descent on non-convex losses from high-dimensional inference"
      },
      {
        "key": "abbe2022merged",
        "author": "Abbe, Emmanuel and Boix-Adsera, Enric  and Misiakiewicz, Theodor",
        "title": "The merged-staircase property: a necessary and nearly sufficient condition for sgd learning of sparse functions on two-layer neural networks"
      },
      {
        "key": "dandi2024twolayer",
        "author": "Yatin Dandi and Florent Krzakala and Bruno Loureiro and Luca Pesce and Ludovic Stephan",
        "title": "How Two-Layer Neural Networks Learn, One (Giant) Step at a Time"
      },
      {
        "key": "damian2024computational",
        "author": "Damian, Alex and Pillaud-Vivien, Loucas and Lee, Jason D and Bruna, Joan",
        "title": "The Computational Complexity of Learning Gaussian Single-Index Models"
      },
      {
        "key": "dandi2024benefits",
        "author": "Dandi, Yatin and Troiani, Emanuele and Arnaboldi, Luca and Pesce, Luca and Zdeborov{\\'a}, Lenka and Krzakala, Florent",
        "title": "The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents"
      },
      {
        "key": "arnaboldi2024repetita",
        "author": "Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Pesce, Luca and Stephan, Ludovic",
        "title": "Repetita iuvant: Data repetition allows sgd to learn high-dimensional multi-index functions"
      },
      {
        "key": "lee2024neural",
        "author": "Lee, Jason D and Oko, Kazusato and Suzuki, Taiji and Wu, Denny",
        "title": "Neural network learns low-dimensional polynomials with SGD near the information-theoretic limit"
      },
      {
        "key": "bietti2023learning",
        "author": "Bietti, Alberto and Bruna, Joan and Pillaud-Vivien, Loucas",
        "title": "On learning gaussian multi-index models with gradient flow"
      },
      {
        "key": "simsek2024learning",
        "author": "Simsek, Berfin and Bendjeddou, Amire and Hsu, Daniel",
        "title": "Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity and Directional Convergence"
      },
      {
        "key": "arous2024stochastic",
        "author": "Arous, G{\\'e}rard Ben and Gerbelot, C{\\'e}dric and Piccolo, Vanessa",
        "title": "Stochastic gradient descent in high dimensions for multi-spiked tensor PCA"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "arnaboldi2024repetita",
        "author": "Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Pesce, Luca and Stephan, Ludovic",
        "title": "Repetita iuvant: Data repetition allows sgd to learn high-dimensional multi-index functions"
      },
      {
        "key": "lee2024neural",
        "author": "Lee, Jason D and Oko, Kazusato and Suzuki, Taiji and Wu, Denny",
        "title": "Neural network learns low-dimensional polynomials with SGD near the information-theoretic limit"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "damian2024computational",
        "author": "Damian, Alex and Pillaud-Vivien, Loucas and Lee, Jason D and Bruna, Joan",
        "title": "The Computational Complexity of Learning Gaussian Single-Index Models"
      },
      {
        "key": "troiani2024fundamental",
        "author": "Troiani, Emanuele and Dandi, Yatin and Defilippis, Leonardo and Zdeborov{\\'a}, Lenka and Loureiro, Bruno and Krzakala, Florent",
        "title": "Fundamental limits of weak learnability in high-dimensional multi-index models"
      }
    ]
  }
]