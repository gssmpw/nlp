@inproceedings{10.1145/2168836.2168866,
    author = {Kapitza, R\"{u}diger and Behl, Johannes and Cachin, Christian and Distler, Tobias and Kuhnle, Simon and Mohammadi, Seyed Vahid and Schr\"{o}der-Preikschat, Wolfgang and Stengel, Klaus},
    title = {CheapBFT: Resource-Efficient Byzantine Fault Tolerance},
    year = {2012},
    isbn = {9781450312233},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2168836.2168866},
    doi = {10.1145/2168836.2168866},
    booktitle = {Proceedings of the 7th ACM European Conference on Computer Systems},
    pages = {295–308},
    numpages = {14},
    keywords = {byzantine failures, resource efficiency},
    location = {Bern, Switzerland},
    series = {EuroSys '12}
}

@inproceedings{10.1145/2872362.2872367,
author = {Kaufmann, Antoine and Peter, SImon and Sharma, Naveen Kr. and Anderson, Thomas and Krishnamurthy, Arvind},
title = {High Performance Packet Processing with FlexNIC},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872367},
doi = {10.1145/2872362.2872367},
abstract = {The recent surge of network I/O performance has put enormous pressure on memory and software I/O processing sub systems. We argue that the primary reason for high memory and processing overheads is the inefficient use of these resources by current commodity network interface cards (NICs). We propose FlexNIC, a flexible network DMA interface that can be used by operating systems and applications alike to reduce packet processing overheads. FlexNIC allows services to install packet processing rules into the NIC, which then executes simple operations on packets while exchanging them with host memory. Thus, our proposal moves some of the packet processing traditionally done in software to the NIC, where it can be done flexibly and at high speed.We quantify the potential benefits of FlexNIC by emulating the proposed FlexNIC functionality with existing hardware or in software. We show that significant gains in application performance are possible, in terms of both latency and throughput, for several widely used applications, including a key-value store, a stream processing system, and an intrusion detection system.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {67–81},
numpages = {15},
keywords = {DMA, flexible network processing, match-and-action processing, network interface card},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3127479.3132252,
author = {Le, Yanfang and Chang, Hyunseok and Mukherjee, Sarit and Wang, Limin and Akella, Aditya and Swift, Michael M. and Lakshman, T. V.},
title = {UNO: uniflying host and smart NIC offload for flexible packet processing},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3132252},
doi = {10.1145/3127479.3132252},
abstract = {Increasingly, smart Network Interface Cards (sNICs) are being used in data centers to offload networking functions (NFs) from host processors thereby making these processors available for tenant applications. Modern sNICs have fully programmable, energy-efficient multi-core processors on which many packet processing functions, including a full-blown programmable switch, can run. However, having multiple switch instances deployed across the host hypervisor and the attached sNICs makes controlling them difficult and data plane operations more complex.This paper proposes a generalized SDN-controlled NF offload architecture called UNO. It can transparently offload dynamically selected host processors' packet processing functions to sNICs by using multiple switches in the host while keeping the data centerwide network control and management planes unmodified. UNO exposes a single virtual control plane to the SDN controller and hides dynamic NF offload behind a unified virtual management plane. This enables UNO to make optimal use of host's and sNIC's combined packet processing capabilities with local optimization based on locally observed traffic patterns and resource consumption, and without central controller involvement. Experimental results based on a real UNO prototype in realistic scenarios show promising results: it can save processing worth up to 8 CPU cores, reduce power usage by up to 2x, and reduce the control plane overhead by more than 50\%.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {506–519},
numpages = {14},
keywords = {virtualization and containers, networking and SDNs},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/3132747.3132756,
author = {Li, Bojie and Ruan, Zhenyuan and Xiao, Wencong and Lu, Yuanwei and Xiong, Yongqiang and Putnam, Andrew and Chen, Enhong and Zhang, Lintao},
title = {KV-Direct: High-Performance In-Memory Key-Value Store with Programmable NIC},
year = {2017},
isbn = {9781450350853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132747.3132756},
doi = {10.1145/3132747.3132756},
abstract = {Performance of in-memory key-value store (KVS) continues to be of great importance as modern KVS goes beyond the traditional object-caching workload and becomes a key infrastructure to support distributed main-memory computation in data centers. Recent years have witnessed a rapid increase of network bandwidth in data centers, shifting the bottleneck of most KVS from the network to the CPU. RDMA-capable NIC partly alleviates the problem, but the primitives provided by RDMA abstraction are rather limited. Meanwhile, programmable NICs become available in data centers, enabling in-network processing. In this paper, we present KV-Direct, a high performance KVS that leverages programmable NIC to extend RDMA primitives and enable remote direct key-value access to the main host memory.We develop several novel techniques to maximize the throughput and hide the latency of the PCIe connection between the NIC and the host memory, which becomes the new bottleneck. Combined, these mechanisms allow a single NIC KV-Direct to achieve up to 180 M key-value operations per second, equivalent to the throughput of tens of CPU cores. Compared with CPU based KVS implementation, KV-Direct improves power efficiency by 3x, while keeping tail latency below 10 μs. Moreover, KV-Direct can achieve near linear scalability with multiple NICs. With 10 programmable NIC cards in a commodity server, we achieve 1.22 billion KV operations per second, which is almost an order-of-magnitude improvement over existing systems, setting a new milestone for a general-purpose in-memory key-value store.},
booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
pages = {137–152},
numpages = {16},
keywords = {Key-Value Store, Performance, Programmable Hardware},
location = {Shanghai, China},
series = {SOSP '17}
}

@inproceedings{10.1145/3286062.3286068,
author = {Stephens, Brent and Akella, Aditya and Swift, Michael M.},
title = {Your Programmable NIC Should be a Programmable Switch},
year = {2018},
isbn = {9781450361200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286062.3286068},
doi = {10.1145/3286062.3286068},
abstract = {Today's NICs are becoming programmable ("smart"). To support new network protocols, services, and offloads, there are NICs today that have on-board FPGAs, embedded processors, programmable forwarding pipelines, and specialized engines to support features like RDMA. Unfortunately, existing programmable NICs have a number of key limitations. It is difficult to chain offloads, schedule competing accesses to shared resources, and support functions that require variable processing time and thus may not run at line-rate.In this paper, we propose PANIC, a new architecture for programmable NICs that overcomes the limitations of existing NIC designs. We divide the NIC into three components: 1) self-contained offload engines, 2) a logical switch, and 3) a logical scheduler. This design overcomes the limitations of existing designs and is able to scale with increasing line-rates to a large number of offloads and long offload chains.},
booktitle = {Proceedings of the 17th ACM Workshop on Hot Topics in Networks},
pages = {36–42},
numpages = {7},
location = {Redmond, WA, USA},
series = {HotNets '18}
}

@inproceedings{10.1145/3321408.3323087,
author = {Yan, Jinli and Tang, Lu and Li, Junnan and Yang, Xiangrui and Quan, Wei and Chen, Hongyi and Sun, Zhigang},
title = {UniSec: a unified security framework with SmartNIC acceleration in public cloud},
year = {2019},
isbn = {9781450371582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321408.3323087},
doi = {10.1145/3321408.3323087},
abstract = {In the public cloud, the software security functions that multitenants deploy in their virtual networks have limited performance. SmartNIC overcomes these limitations by implementing these security functions with hardware acceleration. However, the shared SmartNIC resources are not open for external users with security considerations. Since the security requirements of tenants are diverse, it is tedious for network operators to develop these functions from scratch with low-level APIs.This paper presents UniSec, a unified programming framework for fast security functions development while improving performance with SmartNIC acceleration. UniSec provides modular abstraction for a single function and module sharing among multiple security functions. With the well-defined APIs of UniSec, developers only need to focus on the core logic instead of complex underlying operations including resource management, matching algorithms, etc. Experimental results show that the code has been reduced by 65\% on average for each security function with UniSec. UniSec also improves processing performance up to 76\%, compared with the software-only implementation.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
articleno = {9},
numpages = {6},
keywords = {security function, programming framework, SmartNIC},
location = {Chengdu, China},
series = {ACM TURC '19}
}

@inproceedings{10.1145/3341302.3342079,
author = {Liu, Ming and Cui, Tianyi and Schuh, Henry and Krishnamurthy, Arvind and Peter, Simon and Gupta, Karan},
title = {Offloading Distributed Applications onto SmartNICs Using IPipe},
year = {2019},
isbn = {9781450359566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341302.3342079},
doi = {10.1145/3341302.3342079},
abstract = {Emerging Multicore SoC SmartNICs, enclosing rich computing resources (e.g., a multicore processor, onboard DRAM, accelerators, programmable DMA engines), hold the potential to offload generic datacenter server tasks. However, it is unclear how to use a SmartNIC efficiently and maximize the offloading benefits, especially for distributed applications. Towards this end, we characterize four commodity SmartNICs and summarize the offloading performance implications from four perspectives: traffic control, computing capability, onboard memory, and host communication.Based on our characterization, we build iPipe, an actor-based framework for offloading distributed applications onto SmartNICs. At the core of iPipe is a hybrid scheduler, combining FCFS and DRR-based processor sharing, which can tolerate tasks with variable execution costs and maximize NIC compute utilization. Using iPipe, we build a real-time data analytics engine, a distributed transaction system, and a replicated key-value store, and evaluate them on commodity SmartNICs. Our evaluations show that when processing 10/25Gbps of application bandwidth, NIC-side offloading can save up to 3.1/2.2 beefy Intel cores and lower application latencies by 23.0/28.0 μs.},
booktitle = {Proceedings of the ACM Special Interest Group on Data Communication},
pages = {318–333},
numpages = {16},
keywords = {distributed applications, SmartNIC},
location = {Beijing, China},
series = {SIGCOMM '19}
}

@inproceedings{10.1145/3365609.3365851,
author = {Ibanez, Stephen and Shahbaz, Muhammad and McKeown, Nick},
title = {The Case for a Network Fast Path to the CPU},
year = {2019},
isbn = {9781450370202},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365609.3365851},
doi = {10.1145/3365609.3365851},
abstract = {For the past two decades, the communication channel between the NIC and CPU has largely remained the same---issuing memory requests across a slow PCIe peripheral interconnect. Today, with application service times and network fabric delays measuring hundreds of nanoseconds, the NIC--CPU interface can account for most of the overhead when programming modern warehouse-scale computers.In this paper, we tackle this issue head-on by proposing a design for a fast path between the NIC and CPU, called Lightning NIC (L-NIC), which deviates from the established norms of offloading computation onto the NIC (inflating latency), or using centralized dispatcher cores for packet scheduling (limiting throughput). L-NIC adds support for a fast path from the network to the core of the CPU by writing and reading packets directly to/from the CPU register file. This approach minimizes network IO latency, providing significant performance improvements over traditional NIC--CPU interfaces.},
booktitle = {Proceedings of the 18th ACM Workshop on Hot Topics in Networks},
pages = {52–59},
numpages = {8},
keywords = {and P4, Programmable NIC, PISA},
location = {Princeton, NJ, USA},
series = {HotNets '19}
}

@inproceedings{10.1145/3387514.3405895,
author = {Grant, Stewart and Yelam, Anil and Bland, Maxwell and Snoeren, Alex C.},
title = {SmartNIC Performance Isolation with FairNIC: Programmable Networking for the Cloud},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405895},
doi = {10.1145/3387514.3405895},
abstract = {Multiple vendors have recently released SmartNICs that provide both special-purpose accelerators and programmable processing cores that allow increasingly sophisticated packet processing tasks to be offloaded from general-purpose CPUs. Indeed, leading data-center operators have designed and deployed SmartNICs at scale to support both network virtualization and application-specific tasks. Unfortunately, cloud providers have not yet opened up the full power of these devices to tenants, as current runtimes do not provide adequate isolation between individual applications running on the SmartNICs themselves.We introduce FairNIC, a system to provide performance isolation between tenants utilizing the full capabilities of a commodity SoC SmartNIC. We implement FairNIC on Cavium LiquidIO 2360s and show that we are able to isolate not only typical packet processing, but also prevent MIPS-core cache pollution and fairly share access to fixed-function hardware accelerators. We use FairNIC to implement NIC-accelerated OVS and key/value store applications and show that they both can cohabitate on a single NIC using the same port, where the performance of each is unimpacted by other tenants. We argue that our results demonstrate the feasibility of sharing SmartNICs among virtual tenants, and motivate the development of appropriate security isolation mechanisms.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {681–693},
numpages = {13},
keywords = {performance isolation, cloud hosting, Network adapters},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@article{10.1145/3390251.3390257,
author = {Sivaraman, Anirudh and Mason, Thomas and Panda, Aurojit and Netravali, Ravi and Kondaveeti, Sai Anirudh},
title = {Network architecture in the age of programmability},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {1},
issn = {0146-4833},
url = {https://doi.org/10.1145/3390251.3390257},
doi = {10.1145/3390251.3390257},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {mar},
pages = {38–44},
numpages = {7},
keywords = {programmable networks, network architecture}
}

@inproceedings{10.1145/3477132.3483555,
author = {Schuh, Henry N. and Liang, Weihao and Liu, Ming and Nelson, Jacob and Krishnamurthy, Arvind},
title = {Xenic: SmartNIC-Accelerated Distributed Transactions},
year = {2021},
isbn = {9781450387095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477132.3483555},
doi = {10.1145/3477132.3483555},
booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
pages = {740–755},
numpages = {16},
keywords = {Distributed Transactions, RDMA, SmartNICs},
location = {Virtual Event, Germany},
series = {SOSP '21}
}

@inproceedings{10.1145/3492321.3519568,
    author = {Decouchant, J\'{e}r\'{e}mie and Kozhaya, David and Rahli, Vincent and Yu, Jiangshan},
    title = {DAMYSUS: Streamlined BFT Consensus Leveraging Trusted Components},
    year = {2022},
    isbn = {9781450391627},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    booktitle = {Proceedings of the Seventeenth European Conference on Computer Systems},
    pages = {1–16},
    numpages = {16},
    keywords = {trusted component, consensus, fault tolerance},
    location = {Rennes, France},
    series = {EuroSys '22}
}

@inproceedings{10.1145/3552326.3587455,
author = {Gupta, Suyash and Rahnama, Sajjad and Pandey, Shubham and Crooks, Natacha and Sadoghi, Mohammad},
title = {Dissecting BFT Consensus: In Trusted Components We Trust!},
year = {2023},
isbn = {9781450394871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552326.3587455},
doi = {10.1145/3552326.3587455},
abstract = {},
booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
pages = {521–539},
numpages = {19},
keywords = {SGX, byzantine fault-tolerance, parallelism, consensus, responsiveness, permissioned blockchain},
location = {Rome, Italy},
series = {EuroSys '23}
}

@inproceedings{10.1145/3563647.3563654,
author = {Kaplan, Alexander and Feibish, Shir Landau},
title = {Practical handling of DNS in the data plane},
year = {2022},
isbn = {9781450398923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563647.3563654},
doi = {10.1145/3563647.3563654},
abstract = {The Domain Name System (DNS) is a significant component of modern-day internet. Despite this fact, DNS traffic is mostly unencrypted, and as such a likely target for exploitation by malicious actors. The advancement of programmable switches presents researchers with the opportunity to explore DNS traffic from a new vantage point, without sacrificing network bandwidth. In spite of the incentive, DNS research in programmable switches has been scarce, owing to the difficulty in parsing DNS packets.We present a general solution to DNS packet parsing that can handle the vast majority of DNS packets (97\%) using current hardware and can easily be scaled to parse all DNS packets as hardware improves. Our highly configurable solution can be adjusted to fit many distinct use cases. Additionally, we explore the challenges involved in parsing DNS packets and present common pitfalls appearing in previous research attempting to do so.},
booktitle = {Proceedings of the Symposium on SDN Research},
pages = {59–66},
numpages = {8},
keywords = {DNS, data plane, network measurement, programmable networks, programmable switch},
location = {Virtual Event},
series = {SOSR '22}
}

@inproceedings{10.1145/3603269.3604874,
author = {Sun, Guangda and Jiang, Mingliang and Khooi, Xin Zhe and Li, Yunfan and Li, Jialin},
title = {NeoBFT: Accelerating Byzantine Fault Tolerance Using Authenticated In-Network Ordering},
year = {2023},
isbn = {9798400702365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603269.3604874},
doi = {10.1145/3603269.3604874},
abstract = {Mission critical systems deployed in data centers today are facing more sophisticated failures. Byzantine fault-tolerant (BFT) protocols are capable of masking these types of failures, but are rarely deployed due to their performance cost and complexity. In this work, we propose a new approach to designing high performance BFT protocols in data centers. By re-examining the ordering responsibility between the network and the BFT protocol, we advocate a new abstraction offered by the data center network infrastructure. Concretely, we design a new authenticated ordered multicast primitive (aom) that provides transferable authentication and non-equivocation guarantees. Feasibility of the design is demonstrated by two hardware implementations of aom- one using HMAC and the other using public key cryptography for authentication - on new-generation programmable switches. We then co-design a new BFT protocol, NeoBFT, that leverages the guarantees of aom to eliminate cross-replica coordination and authentication in the common case. Evaluation results show that NeoBFT outperforms state-of-the-art protocols on both latency and throughput metrics by a wide margin, demonstrating the benefit of our new network ordering abstraction for BFT systems.},
booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
pages = {239–254},
numpages = {16},
keywords = {state machine replication, byzantine-fault tolerance, in-network ordering, programmable networks},
location = {New York, NY, USA},
series = {ACM SIGCOMM '23}
}

@inproceedings{10.1145/3620678.3624786,
author = {You, Myoungsung and Nam, Jaehyun and Seo, Minjae and Shin, Seungwon},
title = {HELIOS: Hardware-assisted High-performance Security Extension for Cloud Networking},
year = {2023},
isbn = {9798400703874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620678.3624786},
doi = {10.1145/3620678.3624786},
abstract = {With the increasing adoption of containerization in cloud services, container networking has become a critical concern, as it enables the agile deployment of microservices but also introduces new vulnerabilities susceptible to network attacks, posing a threat to container environments. While several security solutions have been introduced to address this concern, they unfortunately exhibit significant shortcomings, including security vulnerabilities and limited performance. We thus propose Helios, a novel hardware-based network security extension that addresses the security and performance limitations in existing solutions. Leveraging a smartNIC, Helios enhances both the security and performance facets of container networking through two key mechanisms: (i) the establishment of physically isolated container communication channels and (ii) the network security engines fully offloaded to the smartNIC. Our evaluation shows that Helios mitigates various network threats initiated from both container- and host-side while performing up to 3x faster than the existing solutions in container communication.},
booktitle = {Proceedings of the 2023 ACM Symposium on Cloud Computing},
pages = {486–501},
numpages = {16},
keywords = {SmartNIC, Security Policy Enforcement, Container Network},
location = {<conf-loc>, <city>Santa Cruz</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {SoCC '23}
}

@ARTICLE{10292786,
  author={Pacífico, Racyus D. G. and Duarte, Lucas F. S. and Vieira, Luiz F. M. and Raghavan, Barath and Nacif, José A. M. and Vieira, Marcos A. M.},
  journal={IEEE/ACM Transactions on Networking}, 
  title={eBPFlow: A Hardware/Software Platform to Seamlessly Offload Network Functions Leveraging eBPF}, 
  year={2023},
  volume={},
  number={},
  pages={1-14},
  keywords={Hardware;Engines;Parallel processing;Software;Field programmable gate arrays;Codes;Throughput;Networking functions virtualization;programmable data plane;eBPF;NetFPGA},
  doi={10.1109/TNET.2023.3318251}}

@INPROCEEDINGS{10329593,
  author={Lettieri, Giuseppe and Fais, Alessandra and Antichi, Gianni and Procissi, Gregorio},
  booktitle={2023 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)}, 
  title={SmartNIC-Accelerated Stream Processing Analytics}, 
  year={2023},
  volume={},
  number={},
  pages={135-140},
  keywords={Pipelines;Programming;Flowmeters;Software;Network function virtualization;Telemetry;Software defined networking;Stream Processing;Computation Offload;SmartNICs;Accelerated Data Path;eBPF/XDP},
  doi={10.1109/NFV-SDN59219.2023.10329593}}

@inproceedings{6681599,
    author = {Aublin, Pierre-Louis and Mokhtar, Sonia Ben and Quéma, Vivien},
    booktitle = {2013 IEEE 33rd International Conference on Distributed Computing Systems}, 
    title = {RBFT: Redundant Byzantine Fault Tolerance}, 
    year = {2013},
    pages = {297-306},
    doi = {10.1109/ICDCS.2013.53}
}

@INPROCEEDINGS{6853195,
  author={Putnam, Andrew and Caulfield, Adrian M. and Chung, Eric S. and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and Haselman, Michael and Hauck, Scott and Heil, Stephen and Hormati, Amir and Kim, Joo-Young and Lanka, Sitaram and Larus, James and Peterson, Eric and Pope, Simon and Smith, Aaron and Thong, Jason and Xiao, Phillip Yi and Burger, Doug},
  booktitle={2014 ACM/IEEE 41st International Symposium on Computer Architecture (ISCA)}, 
  title={A reconfigurable fabric for accelerating large-scale datacenter services}, 
  year={2014},
  volume={},
  number={},
  pages={13-24},
  doi={10.1109/ISCA.2014.6853195}}

@INPROCEEDINGS{8891991,
  author={Ruiz, Mario and Sidler, David and Sutter, Gustavo and Alonso, Gustavo and López-Buedo, Sergio},
  booktitle={2019 29th International Conference on Field Programmable Logic and Applications (FPL)}, 
  title={Limago: An FPGA-Based Open-Source 100 GbE TCP/IP Stack}, 
  year={2019},
  volume={},
  number={},
  pages={286-292},
  doi={10.1109/FPL.2019.00053}}

@INPROCEEDINGS{9114811,
  author={Forencich, Alex and Snoeren, Alex C. and Porter, George and Papen, George},
  booktitle={2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)}, 
  title={Corundum: An Open-Source 100-Gbps Nic}, 
  year={2020},
  volume={},
  number={},
  pages={38-46},
  doi={10.1109/FCCM48280.2020.00015}}

@INPROCEEDINGS{9220629,
  author={Matus, Francis},
  booktitle={2020 IEEE Hot Chips 32 Symposium (HCS)}, 
  title={Distributed Services Architecture}, 
  year={2020},
  volume={},
  number={},
  pages={1-17},
  doi={10.1109/HCS49909.2020.9220629}}

@article{Castro:2002,
    author = {Castro, Miguel and Liskov, Barbara},
    title = {Practical Byzantine Fault Tolerance and Proactive Recovery},
    year = {2002},
    journal = {ACM Trans. Comput. Syst.},
    keywords = {asynchronous systems, state transfer, Byzantine fault tolerance, state machine replication, proactive recovery}
}

@article{Chan2018PaLaAS,
    title={PaLa: A Simple Partially Synchronous Blockchain},
    author={T-H. Hubert Chan and Rafael Pass and Elaine Shi},
    journal={IACR Cryptol. ePrint Arch.},
    year={2018},
    volume={2018},
    pages={981}
}

@article{Chan2018PiLiAE,
    title={PiLi: An Extremely Simple Synchronous Blockchain},
    author={T-H. Hubert Chan and Rafael Pass and Elaine Shi},
    journal={IACR Cryptol. ePrint Arch.},
    year={2018},
    volume={2018},
    pages={980}
}

@article{DBLP:journals/corr/abs-1803-05069,
    author    = {Ittai Abraham and Guy Gueta and Dahlia Malkhi},
    title     = {Hot-Stuff the Linear, Optimal-Resilience, One-Message BFT Devil},
    journal   = {CoRR},
    volume    = {abs/1803.05069},
    year      = {2018},
    url       = {http://arxiv.org/abs/1803.05069},
    eprinttype = {arXiv},
    eprint    = {1803.05069},
    timestamp = {Mon, 13 Aug 2018 16:49:08 +0200},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1807-04938,
    author    = {Ethan Buchman and
               Jae Kwon and
               Zarko Milosevic},
    title     = {The latest gossip on {BFT} consensus},
    journal   = {CoRR},
    volume    = {abs/1807.04938},
    year      = {2018},
    url       = {http://arxiv.org/abs/1807.04938},
    eprinttype = {arXiv},
    eprint    = {1807.04938},
    timestamp = {Thu, 04 Mar 2021 15:40:35 +0100},
    biburl    = {https://dblp.org/rec/journals/corr/abs-1807-04938.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Suri_Payer_2021,
	doi = {10.1145/3477132.3483552},
	year = 2021,
	month = {oct},
	publisher = {{ACM}},
	author = {Florian Suri-Payer and Matthew Burke and Zheng Wang and Yunhao Zhang and Lorenzo Alvisi and Natacha Crooks},
	title = {Basil},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 28th Symposium on Operating Systems Principles {CD}-{ROM}}
}

@misc{alibaba_smartnics, 
  title = " Zero-Copy Optimization for Alibaba Cloud Smart NIC Solution ",
  url = {https://www.alibabacloud.com/blog/zero-copy-optimization-for-alibaba-cloud-smart-nic-solution_593986},
  note= {\today}
}

@inproceedings{avocado,
    author = {Maurice Bailleu and Dimitra Giantsidi and Vasilis Gavrielatos and Do Le Quoc and Vijay Nagarajan and Pramod Bhatotia},
    title = {Avocado: A Secure {In-Memory} Distributed Storage System},
    booktitle = {2021 USENIX Annual Technical Conference (USENIX ATC 21)},
    year = {2021},
    isbn = {978-1-939133-23-6},
    pages = {65--79},
    url = {https://www.usenix.org/conference/atc21/presentation/bailleu},
    publisher = {USENIX Association}
}

@article{bft-smart,
    author = {Sousa, João and Bessani, Alysson},
    year = {2012},
    month = {05},
    pages = {},
    title = {From Byzantine Consensus to BFT State Machine Replication: A Latency-Optimal Transformation},
    journal = {Proceedings - 9th European Dependable Computing Conference, EDCC 2012},
    publisher={IEEE},
    doi = {10.1109/EDCC.2012.32}
}

@misc{bluefield_smartnics, 
  title = "NVIDIA BlueField Data Processing Units",
  url = {https://www.nvidia.com/en-gb/networking/products/data-processing-unit/
},
  note={\today}
}

@misc{broadcom_smartnics, 
  title = "Broadcom Stingray SmartNIC Accelerates Baidu Cloud Services",
  url = {https://www.broadcom.com/company/news/product-releases/53106
},
  note={\today}
}

@misc{ccf,
  title = {{CCF documentation}},
  key = {Confidential Consortium Framework},
  howpublished = {\url{https://microsoft.github.io/CCF/master/}},
  url = {\url{https://microsoft.github.io/CCF/master/}},
  note = {Last accessed: Jan, 2021}
}

@inproceedings{corundum,
author = {Hoseinzadeh, Morteza and Swanson, Steven},
title = {Corundum: Statically-Enforced Persistent Memory Safety},
year = {2021},
isbn = {9781450383172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445814.3446710},
doi = {10.1145/3445814.3446710},
abstract = {Fast, byte-addressable, persistent main memories (PM) make it possible to build complex
data structures that can survive system failures. Programming for PM is challenging,
not least because it combines well-known programming challenges like locking, memory
management, and pointer safety with novel PM-specific bug types. It also requires
logging updates to PM to facilitate recovery after a crash. A misstep in any of these
areas can corrupt data, leak resources, or prevent successful recovery after a crash.
Existing PM libraries in a variety of languages -- C, C++, Java, Go -- simplify some
of these problems, but they still require the programmer to learn (and flawlessly
apply) complex rules to ensure correctness. Opportunities for data-destroying bugs
abound. This paper presents Corundum, a Rust-based library with an idiomatic PM programming
interface and leverages Rust’s type system to statically avoid most common PM programming
bugs. Corundum lets programmers develop persistent data structures using familiar
Rust constructs and have confidence that they will be free of those bugs. We have
implemented Corundum and found its performance to be as good as or better than Intel's
widely-used PMDK library, HP's Atlas, Mnemosyne, and go-pmem.},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {429–442},
numpages = {14},
keywords = {static bug detection, crash-consistent programming, non-volatile memory programming library},
location = {Virtual, USA},
series = {ASPLOS 2021}
}

@misc{coyote,
    title = {{Coyote: OS for FPGAs}},
    url = {https://github.com/fpgasystems/Coyote},
    note = {Last accessed: \today}
}

@unknown{honeycomb,
author = {Liu, Junyi and Dragojevic, Aleksandar and Flemming, Shane and Katsarakis, Antonios and Korolija, Dario and Zablotchi, Igor and Ng, Ho-cheung and Kalia, Anuj and Castro, Miguel},
year = {2023},
month = {03},
pages = {},
title = {Honeycomb: ordered key-value store acceleration on an FPGA-based SmartNIC}
}

@inproceedings{hybster,
    author = {Behl, Johannes and Distler, Tobias and Kapitza, R\"{u}diger},
    title = {{Hybrids on Steroids: SGX-Based High Performance BFT}},
    year = {2017},
    booktitle = {Proceedings of the Twelfth European Conference on Computer Systems (EuroSys)}
}

@inproceedings{levin2009trinc,
  title = {TrInc: Small Trusted Hardware for Large Distributed Systems.},
  author = {Levin, Dave and Douceur, John R and Lorch, Jacob R and Moscibroda, Thomas},
  booktitle = {NSDI},
  volume = {9},
  pages = {1--14},
  year = {2009}
}

@misc{liquidIO_smartnics, 
  title = "LiquidIO II Smart NICs",
  url = {https://www.marvell.com/products/infrastructure-processors/liquidio-smart-nics/liquidio-ii-smart-nics.html},
  note= {\today}
}

@article{minBFT,
    author = {Veronese, Giuliana and Correia, Miguel and Bessani, Alysson and Lung, Lau and Veríssimo, Paulo},
    year = {2013},
    month = {01},
    pages = {16-30},
    title = {Efficient Byzantine Fault-Tolerance},
    volume = {62},
    journal = {Computers, IEEE Transactions on},
    doi = {10.1109/TC.2011.221}
}

@misc{msr_smartnics, 
  title = "Project Catapult",
  url = {https://www.microsoft.com/en-us/research/project/project-catapult/},
  note={\today}
}

@misc{netronome_smartnics, 
  title = "Netronome",
  url = {https://www.netronome.com/},
  note= {\today}
}

@misc{nitro_smartnics, 
  title = "AWS Nitro System",
  url = {https://aws.amazon.com/ec2/nitro/},
  note= {\today}
}

@misc{opennic_project,
  title = {AMD OpenNIC Project},
  howpublished = {https://github.com/Xilinx/open-nic},
  note = {Accessed: \today}
}

@misc{shan2022supernic,
      title={SuperNIC: A Hardware-Based, Programmable, and Multi-Tenant SmartNIC}, 
      author={Yizhou Shan and Will Lin and Ryan Kosta and Arvind Krishnamurthy and Yiying Zhang},
      year={2022},
      eprint={2109.07744},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@inproceedings{storm,
author = {Sidler, David and Wang, Zeke and Chiosa, Monica and Kulkarni, Amit and Alonso, Gustavo},
title = {StRoM: Smart Remote Memory},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387519},
doi = {10.1145/3342195.3387519},
abstract = {Big data applications often incur large costs in I/O, data transfer and copying overhead, especially when operating in cloud environments. Since most such computations are distributed, data processing operations offloaded to the network card (NIC) could potentially reduce the data movement overhead by enabling near-data processing at several points of a distributed system. Following this idea, in this paper we present StRoM, a programmable, FPGA-based RoCE v2 NIC supporting the offloading of application level kernels. These kernels can be used to perform memory access operations directly from the NIC such as traversal of remote data structures as well as filtering or aggregation over RDMA data streams on both the sending or receiving sides. StRoM bypasses the CPU entirely and extends the semantics of RDMA to enable multi-step data access operations and in-network processing of RDMA streams. We demonstrate the versatility and potential of StRoM with four different kernels extending one-sided RDMA commands: 1) Traversal of remote data structures through pointer chasing, 2) Consistent retrieval of remote data blocks, 3) Data shuffling on the NIC by partitioning incoming data to different memory regions or CPU cores, and 4) Cardinality estimation on data streams.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {29},
numpages = {16},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{treaty,
    author = {Giantsidi, Dimitra and Bailleu, Maurice and Crooks, Natacha and Bhatotia, Pramod},
    booktitle = {2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)}, 
    title = {Treaty: Secure Distributed Transactions}, 
    year = {2022},
    pages = {14-27},
    doi = {10.1109/DSN53405.2022.00015}
}

@misc{u280_smartnics, 
  title = "Alveo U280 Data Center Accelerator Card",
  url = {https://www.xilinx.com/products/boards-and-kits/alveo/u280.html},
  note={\today}
}

