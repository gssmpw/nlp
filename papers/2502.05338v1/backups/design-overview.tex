%\section{Design}
%\dimitra{
%\begin{itemize}
%    \item Intro
%    \item Background + Motivation
%    \item Overview (including sys/data model etc.)
%    \item Design + Implementation (TNIC: hw architecture, TNIC libraries: sw abstraction, Applications: use-cases)
%\end{itemize}
%}


\subsection{System Model}

\myparagraph{Model sketch}
We model the distributed system as a set of {\tt N} nodes each of which is attached to a single \projecttitle{} instance that is loaded into an FPGA-based SmartNIC as Alveo U280~\cite{u280_smartnics}. The nodes communicate by exchanging messages through bi-directional network links that connect their FPGAs. The system is managed and owned by the third-party cloud infrastructure which is untrusted.

\myparagraph{Threat model}
We target a strong adversary that can gain full control over the cloud infrastructure including any privileged CPU software (e.g., the OS, VMM, and device drivers) and the FPGA-based SmartNIC devices (post-manufacturing). Such an adversary can also have full access to the infrastructure (e.g., shutdown the servers, or even try to re-program the FPGAs) although, as in ~\cite{levin2009trinc, minBFT, Castro:2002} they cannot compromise the cryptographic primitives. As in~\cite{10.1145/3503222.3507733, 10.1145/2168836.2168866}, we further assume that the physical package, supply chain, and manufacturer of the FPGAs are trusted.  The bitstreams are implemented and synthesized correctly whereas any secret data are distributed securely using remote attestation ($\S$~\ref{subsec:nic_attest_kernel}). The tool flow used to generate the accelerator is trusted and run in a secure environment for covert channels resilience. 

The host CPU is considered untrusted and we do not rely on any CPU TEE. Specifically, while we use the application code to transfer data, we assume the host CPU is untrusted, i.e., can exhibit Byzantine behavior~\cite{Lamport:1982}, as well as the local host memory, storage, etc. Similarly, we make no assumptions about the network infrastructure, e.g., adversaries can drop, re-order, double-send, read, and manipulate the messages in any way. 

We do not consider denial-of-service (DoS) attacks; the cloud provider has physical control of the hardware and can simply unpower it. Nevertheless such attacks affect availability and not the correctness.


%The CSP is incentivized to prevent DoS attacks due to the revenue loss when the FPGA instance is unavailable. %We do not consider attacks against the CSP, as the Shell already protects against malicious FPGA users. 


%We trust that the RDMA stack, along with the attestation kernel, are implemented and synthesized correctly, whereas the bitstream and the keys are distributed and flushed to the FPGAs securely using remote attestation.





%The \projecttitle{} architecture implements a  network stack, similarly to~\cite{erpc, rdma-scale}, but focuses on security leveraging SmartNICs---specifically, FPGA-based NICs~\cite{intel_smartnics, alveo_smartnics}. 




\if 0
\begin{figure}[t!]
    \centering
    \includegraphics[width=.45\textwidth]{figures/trusted-nic-attestation_kernel.drawio.pdf}
    \caption{\trustedfpga{} attestation kernel overview (transmission path).}
    \label{fig:attestation_kernel}
\end{figure}    
\fi




\subsection{Design Challenges}
\myparagraph{Challenge \#1: Robustness} The distributed applications hosted in the third-party cloud infrastructure need to be highly available. As such, cloud services and applications build on top of replication protocols that offer fault tolerance and, importantly, can remain available when failures occur~\cite{Jimenez-Peris2001}. The vast majority of such deployed protocols in the cloud operate under the Crash Fault Tolerant model (CFT) where the machines can {\em only} fail by crashing or omitting some steps. However, the CFT model is inadequate in modern cloud infrastructure as it has been observed that the machines or other parts of the infrastructure can fail arbitrarily (i.e., exhibit Byzantine behavior~\cite{Lamport:1982}) due to malicious adversaries, compromised OS/hypervisor in machines, faulty network links and compromised memory and storage medium~\cite{Gunawi_bugs-in-the-cloud, ciad, fast-08-corruption, security-one-sided-communication, accountable-cloud}. Consequently, the current replication protocols target a quite limited fault model which does not match modern's applications security needs that are hosted in the (untrusted) cloud.

\myparagraph{Solution} Our \projecttitle{} overcomes this limitation by offering  trusted and easily adoptable network operations, which are at the core of any distributed protocol, to help system designers building more robust protocols. To achieve this, we build an extended implementation of the classical, widely-adopted, RDMA network stack~\cite{rdma} on programmable hardware, i.e., FPGA-based SmartNICs~\cite{u280_smartnics}, offloading on this hardware the necessary required security processing and mechanisms. 

%More importantly, conventional BFT protocols present the following characteristics. First, they require an extra set of $f$ participant machines to tolerate up to $f$ failures. Compared to CFT protocols that operate with $2f+1$ participants, classical BFT protocols present limited scalability as they require at least $3f+1$ participants~\cite{BFT_THEORY}. In addition to this, BFT protocols can be slow as they usually run at least three phases of broadcasts~\cite{Castro:2002, DBLP:journals/corr/abs-1803-05069} and incur high message complexity (e.g., $O(n^2)$). Lastly, BFT protocols are complex: they are hard to understand, let alone be optimised~\cite{10.1145/2658994}. Even intuitive algorithmic improvements to optimize for the common case or recovery can significantly affect other parts of the protocol (e.g., view-change in~\cite{10.1145/1658357.1658358}, normal case adds 2 extra phases in~\cite{DBLP:journals/corr/abs-1803-05069}) .% Consequently, they have seen little adoption in commercial cloud applications due to their limited scalability and performance.


\myparagraph{Challenge \#2: Performance and scalability} Researchers~\cite{Castro:2002, DBLP:journals/corr/abs-1803-05069, 10.1145/1658357.1658358} presented a range of robust replication protocols that remain correct when arbitrary failures occur targeting the BFT model~\cite{Lamport:1982}. Unfortunately, these BFT protocols have recognised little adoption because they cannot meet the performance requirements of deployed applications~\cite{bft-time-is-now}. In addition, the vast majority~\cite{Castro:2002, DBLP:journals/corr/abs-1803-05069} introduces resources overheads and limits scalability because it requires at least $3f+1$ machines to tolerate up to $f$ faults. That is, at least more $f$ machines compared to currently deployed CFT protocols. Consequently, BFT protocols are not well suited for performance in modern high-end distributed systems~\cite{bftForSkeptics}.

\myparagraph{Solution} We bridge the gap between performance, scalability and robustness. Our \projecttitle{} offers robustness by materialising the necessary foundations for building BFT protocols~\cite{clement2012} in programmable, yet fast, hardware, while it also improves performance and scalability by limiting the number of required participant machines to the minimum, i.e., $2f+1$. More specifically, \projecttitle{} implements the theoretical foundations of Clement et. al~\cite{clement2012} to translate a CFT protocol to a BFT protocol without having to increase the CFT protocol's replication degree. We explain this mechanism in $\S$~\ref{sec:background}.  %Their work has shown that a translation between any CFT protocol to a BFT protocol {\em always} exists if the security properties of the transferable authentication and the non-equivocation are guaranteed. We discuss the properties and the translation mechanism in$\S$~\ref{}. 

%\begin{itemize}
 %   \item {\bf{Transferable authentication.}} Potentially malicious nodes cannot impersonate other (honest) nodes. Essentially, any node can verify that a message is signed by the correct sender, even for forwarded messages.
 %   \item {\bf{Non-equivocation.}} A sender cannot send different messages to different nodes in the same round while it is supposed to send the same message according to the protocol.
%\end{itemize}

%we designed and implemented \projecttitle{} to offer the two properties of non-equivocation and transferable authentication that allow us to design and build BFT protocols with the minimum possible participant nodes ($2f+1$), resolving the trade-off of scalability, performance, and BFT at once. 

%More precisely, our design relies on the theoretical findings 

%Our \projecttitle{} materializes these properties on the NIC-level by implementing and integrating an attestation kernel for generating message authentication certificates or attestations and verifying those when messages are received ($\S$~\ref{subsec:tfpga}). That way \projecttitle{} builds and exposes the minimal abstraction required for implementing robust protocols under the Byzantine Fault model with $2f+1$ participant nodes.


\myparagraph{Challenge \#3: Adaptability} Due to the traditional BFT protocols limitations, a new line of research has attempted to optimize them~\cite{10.1145/3492321.3519568, minBFT, hybster, 10.1145/2168836.2168866, DBLP:journals/corr/LiuLKA16a, trinc} making use of trusted hardware, precisely, Trusted Execution Environments (TEEs)~\cite{cryptoeprint:2016:086, arm-realm, amd-sev, riscv-multizone, intelTDX}.  Unfortunately, the safety requirements of these optimized protocols highly depend on very specific and CPU-dependant TEEs. Consequently, in addition to their limit adaptability and generality, these protocols' correct implementation and deployment requires that there will {\em always} be available the required number of machines equipped with specific CPU generation and TEE hardware versions. In any other case, system designers are compelled to be able to quickly learn and program any another available TEE. This complicates the widespread adoption of such protocols because the task of programming heterogeneous TEEs as rather challenging~\cite{10.1145/3460120.3485341} as error prone; various TEEs present different programming models and security properties~\cite{10.1007/978-3-031-16092-9_7}. %To sum up, this heterogeneity complicates the widespread adoption of such protocols.
%it raises questions regarding performance and correctness. 

%---in fact, we found that all such open-sourced protocols~\cite{hybster, 10.1145/3492321.3519568, minBFT, DBLP:journals/corr/LiuLKA16a} are built on top Intel SGX~\cite{intel-sgx}.

%We argue that the protocols' reliance on such specific TEEs limits generality and adoption in modern heterogeneous cloud infrastructure. For example, to deploy these protocols, a cloud provider must guarantee that there would always be available a required number of machines equipped with specific CPU generation and TEE hardware versions. In cases where there are no machines available, or the TEE has been discontinued (e.g., this is the case with Intel SGX~\cite{sgx_deprecated}), protocol designers are compelled to be able to quickly learn and program another available TEE. However, programming heterogeneous TEEs is a task rather challenging~\cite{10.1145/3460120.3485341}, and it raises questions regarding performance and correctness. Heterogeneous TEEs not only have different programming and performance characteristics but the security properties they offer can greatly vary too~\cite{10.1007/978-3-031-16092-9_7}. As an example of this, Keystone (RISC-V)~\cite{keystone_eurosys} and Intel SGX (x86)~\cite{intel-sgx} have quite different programming APIs. In addition, Intel SGX can only support a very limited Trusted Computing Base (TCB), only up to 256MB, compared to Intel TDX~\cite{intelTDX} and AMD-SEV~\cite{amd-sev}. 
%\antonis{may mention arm as well?}
%Importantly, commercially available TEEs~\cite{arm-trustzone, intel-sgx, amd-sev, keystone_eurosys, 197162, timber} offer different levels of security (i.e., integrity, freshness, and confidentiality), whereas not all of them come with built-in support for secure bootstrapping and remote attestation~\cite{10.1007/978-3-031-16092-9_7, 7807249, secTEE}. All these characteristics make the widespread adoption of existing BFT protocols impractical.


\myparagraph{Solution} We attack this challenge by removing any dependencies on CPU-based TEEs and unshackling the designers from having to continuously learn and program various TEEs. Our \projecttitle{} makes use of programmable hardware, i.e., FPGAs, to implement a trusted network stack offloading any security-related processing in the NIC hardware ($\S$~\ref{subsec:tfpga}) and to offer a unified abstraction (network library) to the system designers ($\S$~\ref{sec:net-lib}). While our \projecttitle{} shifts the homogeneity from the CPU layer to the FPGA-based NIC layer, our architectural design is not hypothetical; \projecttitle{} fits well in recent deployments in commercial clouds, e.g. Microsoft's Catapult design~\cite{msr_smartnics, 211249}. 

%machines. To achieve this, we implement our entire network stack, including the trusted subsystem for non-equivocation and authentication, on the NIC's hardware-level, leveraging the SmartNIC technology~\cite{}. Essentially, our \projecttitle{} shifts the homogeneity from the CPU layer to the NIC layer:  while the host CPUs participating in a protocol can be heterogeneous, our \projecttitle{} is built on top of homogeneous SmartNICs \antonis{seems stricter than what we assume? maybe FPGA-enabled networking?}, exposing a unified abstraction for exchanging and verifying network messages.

%We implemented our network stack on top of FPGA-based SmartNICs, specifically Alveo U280~\cite{alveo_smartnics}. While our design could be adapted to be applicable to  SoC-based SmartNICs (e.g., Mellanox BlueField~\cite{bluefield_smartnics}, Alveo SN1000~\cite{alveo_sn1000}), we decided against it due to their performance limitations in 100G era~\cite{211249}.\antonis{weak argument, Bluefield 3 is up to 400Gbits. Let's say: "Our design is applicable to ... and our evaluation shows that hardware implementation is more beneficial.} Instead, given the increasingly wide deployment of such specialized hardware in DCs as an efficient way to offload network processing our architectural design is not hypothetical. \projecttitle{} fits well in recent deployments in commercial clouds. An example of this is Microsoft’s Catapult, where the FPGA, which sits on the data path in front of the network card and applies ``smart'' processing, could be extended (as in $\S$~\ref{subsec:tfpga}) to improve security.

%Our system achieves these goals by implementing a minimal hardware-based authentication subsystem, the \emph{attestation kernel}, that guarantees the necessary security properties required for BFT. The attestation kernel generates and verifies authentication certificates for the network messages to ensure two core security properties: the non-equivocation and the (transferable) authentication properties. These two properties have been proven to be necessary and sufficient for decreasing the replication factor for BFT protocols~\cite{clement2012}. Further, we carefully implemented \projecttitle{} to optimize for performance and scalability by integrating the attestation kernel ``on path'' at the NIC-level. That way, our system offers security without introducing unnecessary overheads both in performance and adoption: data is processed \emph{on their way} to the network whereas the protocols do not have to rely on a specific TEE in the host CPU layer. 