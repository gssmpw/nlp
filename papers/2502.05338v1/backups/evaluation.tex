\section{Implementation and Evaluation}
\label{sec:eval}
\dimitra{EVALUATION PLAN TODO}
\subsection{Hardware evaluation}
\myparagraph{Research questions}
\begin{itemize}
    \item[1] What is the overall latency and throughput of the (single-node) Attestation kernel, i.e., the invocations of \texttt{Attest}/\texttt{Verify} functions (secure operations)?
    \item[2] Performance breakdown: how much does the PCI transfer and the secure operations cost w.r.t. the overall execution?
    \item[3] {\bf \color{red} BONUS:} What is the comparison of an Attestation kernel in the SGX vs SmartNics? 
\end{itemize}

\begin{figure}[t!]
    \centering
    \includegraphics[width=.5\textwidth]{eval-plots/plots/rsa.pdf}
    \caption{Attestation kernel (transmission path) latency evaluation.}
    \label{fig:initialization}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=.5\textwidth]{eval-plots/plots/sha.pdf}
    \caption{Attestation kernel (transmission path) latency evaluation.}
    \label{fig:initialization}
\end{figure}

\myparagraph{Current progress/planning}

{\color{blue} 
\begin{itemize}
    \item[1]  {\bf{SKETCH:}} @Robert has (almost) implemented the functions, and we have both discussed and sketched the code for the benchmarking. \\{\bf STATUS: on-track}
    \item[2]  {\bf{SKETCH:}} To measure the PCI transfers we execute the benchmark, calling into the device/FPGA executing an empty kernel.\\{\bf STATUS: on-track}.
    \item[3] \color{red} {\bf{SKETCH:}} A stand-alone running SGX process that receives and sends localhost requests for attest and verify.\\ {\bf STATUS: optional}. 
\end{itemize}
}

\subsection{Benchmark \#2: \projecttitle{}}
\begin{itemize}
    \item[1] What is the overall latency and throughput of a native SmartNic-based \texttt{send}/\texttt{recv} operations w.r.t. state-of-the-art networking, RDMA/DPDK (e.g., eRPC)?
    \item[2] What is the overheads for BFT w.r.t. the native SmartNic-based \texttt{send}/\texttt{recv} operations?
    \item[3] {\bf \color{red} BONUS (optional for completeness)} Can we have two network stacks, i.e., openNIC and Coyote comparison?
\end{itemize}


\begin{center}
\begin{table}[ht]
\centering
\begin{tabular}{ |m{3cm}||m{2cm}|m{2cm}|}
 \hline
  & Tps (MB/s) & Latency (us) \\
  \hline
 native RDMA & 270 & 5  \\
 \projecttitle{} w/o rsa & 10.87 & 16 \\
 TEE-RDMA &  &  \\
 \projecttitle{} w/o rsa & 10.87 & 16 \\
 \projecttitle{} & 2.41 & 100 \\
 \hline
 \end{tabular}
\caption{\projecttitle{} throughput (Tps) and latency evalaution w.r.t. a native (untrusted) RDMA stack.}
\end{table}\label{res:net_stack}
\end{center}






\myparagraph{Current progress/planning}

{\color{blue} 
\begin{itemize}
    \item[1] {\bf SKETCH:} We compare a native port of a SmartNic-based network stack (openic or Coyote) with native RDMA/DPDK to measure latency, throughput (would be nice to also show scalability, in terms of network connections). 
    \\ {\bf STATUS: planned: Felix-openic (and dimitra-Coyote)}.
\end{itemize}
}


\subsection{Benchmark \#3: Use cases}
\begin{itemize}
    \item[1] What is the overheads of BFT (transformed) protocols w.r.t. to their native versions?
\end{itemize}
{\color{blue} 
\begin{itemize}
    \item[1] {\bf SKETCH:} We compare a native implementations of 3 Crash-Fault-Tolerant protocols with their BFT versions. The code runs with eRPC (native RDMA/DPDK) where we mock the latency of the attestation kernel.
    \\ {\bf STATUS: native protocols done --- BFT protocols design/implementation in progress}.
\end{itemize}
}