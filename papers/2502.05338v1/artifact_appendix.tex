% LaTeX template for Artifact Evaluation V20201122
%
% Prepared by 
% * Grigori Fursin (cTuning foundation, France) 2014-2020
% * Bruce Childers (University of Pittsburgh, USA) 2014
%
% See examples of this Artifact Appendix in
%  * SC'17 paper: https://dl.acm.org/citation.cfm?id=3126948
%  * CGO'17 paper: https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf
%  * ACM ReQuEST-ASPLOS'18 paper: https://dl.acm.org/citation.cfm?doid=3229762.3229763
%
% (C)opyright 2014-2020
%
% CC BY 4.0 license
%

%\documentclass[sigplan,twocolumn]{acmart}

%\usepackage{hyperref}

%\newcommand{\projecttitle}{\textsc{tnic}\xspace}
%\newcommand{\scone}{\textsc{scone}\xspace}

%\begin{document}


%\special{papersize=8.5in,11in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove above part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\section{Artifact Appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Abstract}
Our artifacts include the \projecttitle{} codebase as well as the software artifact with the four \projecttitle{} applications, i.e., A2M, BFT, CR, and PeerReview. In addition, we provide the codebases of all the microbenchmarks we discuss in the paper including those of the TEE-based systems. Lastly, we attach the security proofs of \projecttitle{} system operations and attestation protocol based on Tamarin~\cite{tamarin-prover}. This appendix provides the necessary information to set up, build, and run the experiments we present in the paper.



\subsection{Artifact check-list (meta-information)}

%{\em Obligatory. Use just a few informal keywords in all fields %applicable to your artifacts
%and remove the rest. This information is needed to find appropriate reviewers and gradually 
%unify artifact meta information in Digital Libraries.}

{\small
\begin{itemize}
 % \item {\bf Algorithm: }
  \item {\bf Program:} \projecttitle{} hardware implementation codebase. \projecttitle{} software codebases that include the systems where \projecttitle{} has been applied (run in emulated hardware) and microbenchmarks (e.g., network benchmark). \projecttitle{}'s security proofs based on Tamarin~\cite{tamarin-prover}.
  \item {\bf Compilation:} Requires Vitis HLS~\cite{vitis-hls}, Vivado~\cite{vivado}, CMake, C++, Boost, eRPC~\cite{erpc}, DPDK~\cite{dpdk}, Tamarin~\cite{tamarin-prover}.
  %\item {\bf Transformations: }
  %\item {\bf Binary: }
  %\item {\bf Model: }
  %\item {\bf Data set: }
  \item {\bf Run-time environment:} Requires NixOS, 5.15.4, {\sc scone}~\cite{scone} (for SGX-based experiments).
  \item {\bf Hardware:} Requires Alveo U280 cards~\cite{u280_smartnics}, Intel(R) Core(TM) i9-9900K with Intel Corporation Ethernet Controllers (XL710) (or any other DPDK compatible NIC) and AMD EPYC 7413. 
  % \item {\bf Run-time state: }
  \item {\bf Execution:} The time of the experiments are configurable. Each of our experiments did not take more than 10 minutes. However, the compilation and synthesis phases of the \projecttitle{} hardware implementation might take up to 4 hours. 
  \item {\bf Metrics:} Throughput and latency
  %\item {\bf Output: }
  % \item {\bf Experiments:} 
  %\item {\bf How much disk space required (approximately)?: }
  %\item {\bf How much time is needed to prepare workflow (approximately)?: }
  %\item {\bf How much time is needed to complete experiments (approximately)?: }
  \item {\bf Publicly available:} Yes.
  \item {\bf Code licenses:} MIT License. \projecttitle{} doesn't use any external license.
  %\item {\bf Data licenses (if publicly available)?: }
  %\item {\bf Workflow framework used?: }
  \item {\bf Archived (DOI):} \url{10.5281/zenodo.14775354}
\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description}

\subsubsection{How to access}

The open-source version of the \projecttitle{} codebase can be found on GitHub at the following address:

\url{https://github.com/TUM-DSE/TNIC-main.git}

%{\em Obligatory}

\subsubsection{Hardware dependencies}
For AMD-SEV and \projecttitle{}-hardware setups, you need three machines with AMD EPYC 7413 CPU. Each machine is equipped with an Alveo U280 card~\cite{u280_smartnics} and one of every U280's QSFP28 ports connects to the 100Gbps network. For Intel SGX setups, you need machines with Intel(R) Core(TM) i9-9900K with Intel Corporation Ethernet Controllers (XL710) (or any other DPDK compatible NIC) for network connection. 

\subsubsection{Software dependencies}
The software build process involves building the low-level 
Linux kernel driver and the high-level user application layers.
All codebases run on top of NixOS, 5.15.4. We provide the appropriate \texttt{.nix} files to set up a \texttt{nix-shell} environment with all necessary system dependencies. 

The code has been built with \texttt{Makefile} and \texttt{cmake}. The applications, as well as the TEE-based code and application layer, are  written in C++17. We depend on Boost libraries and gflgas for
the parsing of the command line arguments. We rely on several other dependencies, which we explain in our README files, including; {\sc scone}~\cite{scone} for SGX-based experiments, Vivado~\cite{vivado} and Vitis HLS~\cite{vitis-hls} for building \projecttitle{} hardware, eRPC~\cite{erpc}, DPDK~\cite{dpdk}, and Tamarin~\cite{tamarin-prover}.

%\subsubsection{Data sets}

%\subsubsection{Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Installation}
The artifact is linked to the repository as submodules. Each repository provides analytical instructions in their \texttt{README.md} files of how to build and run the binaries.

To build the \projecttitle{}'s hardware implementation, please follow the instructions provided in ~\cite{build-hardware-for-fpga}.

To build the software including the driver and the benchmarks, please follow the instructions in~\cite{build-software}.

To run the experiments for the \projecttitle{} hardware implementation, you need to first load the \projecttitle{}'s kernel module and then run the compiled binary. Detailed instructions are available in ~\cite{tnic-run}.  

Similar instructions have been documented for the applications~\cite{tnic-apps} and the security proofs~\cite{tnic-proofs}.

%{\em Obligatory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Experiment workflow}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation and expected results}
Each of the experiments will output information about its progress; this is a hint that the script is still
running and hasnâ€™t halted. The output of the experiment reports important measurements about the execution. The results are expected not to vary significantly (less than 5$\%$) when compared to the results presented in the paper. However, as discussed, we observed quite a significant variance in some TEE-based systems (Intel SGX and AMD-SEV).
%{\em Obligatory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Experiment customization}
%A wide variety of experiemnt customization can be available
%through different execution parameters. The users can cre-
%ate different versions of the system through combinations of
%vFPGAs, network and memory stacks.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Notes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Methodology}

Submission, reviewing, and badging methodology:

\begin{itemize}
  \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
  \item \url{http://cTuning.org/ae/submission-20201122.html}
  \item \url{http://cTuning.org/ae/reviewing-20201122.html}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\bibliographystyle{ACM-Reference-Format}
%\bibliography{sample}
%\end{document}
