\section{INTRODUCTION}
% Introduction into the topic
Home robotics is a rapidly growing trend driven by advancements in actuators, sensors, and artificial intelligence. These developments have allowed home robots to perform a wider range of tasks and interact with humans in more meaningful ways~\cite{aibo, lovot, qoobo, disney_learning}. 
For example, aibo~\cite{aibo}, a robotic pet introduced by Sony, is capable of learning and developing its own unique personality through interactions with its home environment and owner. This emotional connection with robotic pets demonstrates the potential for robots to play a significant role in our daily lives~\cite{companionAIBO2003, tanaka2021pilot, AIBOasDog2003, KANG2020207}.

\begin{figure}[!t]
    \centering
    % \vspace{5pt}
    \includegraphics[width=\linewidth]{figures/fig1.pdf}
    \caption{For the aibo small home robot pictured above, we design a sim-to-real based \ac{rl} approach to minimize the foot contact velocity in the physics simulator, which highly correlates with the footstep sound in the real world to achieve quiet walking. Project webpage: \url{https://sony.github.io/QuietWalk/}}
    \label{fig:quiet_walking_concept}
    \vspace{-2ex}
\end{figure}


\begin{figure*}
    \centering
    \vspace{10pt}
    \includegraphics[width=\linewidth]{figures/system_overview.png}
    \caption{System overview of the \ac{rl} training framework for learning quiet locomotion with aibo. The agent, aibo, uses its IMU, joint encoders, and switch contact sensors to compute observations. As an action for 12 joints, the policy outputs target joint position and the joint PD gain scale, which enables the tracking of the target joints with high PD gain and the dampening of the joints with low PD gain. On the right is the Isaac Gym~\cite{Makoviychuk2021-th} simulation environment, which we leverage for parallel training on GPUs of multiple agents. The reward scales are divided into two phases, where aibo first learns just to walk, and then in the second phase, it adapts its walk to be quieter.}
    \label{fig:system_overview}
    \vspace{-2ex}
\end{figure*}

Reinforcement learning (RL) has recently been applied to robotic locomotion, significantly improving robustness in a variety of terrains~\cite{anymal_terrain, anymal_perceptive, Choi2023-cf, Wu2023-nz, anymal_dtc, legged_gym}. While these advances have proven beneficial for outdoor use, bringing similar robustness and adaptability to home robots remains an important goal. However, much of the research in \ac{rl} based legged locomotion has prioritized robustness and efficiency, with little focus on reducing the footstep noise generated during walking.
In home environments, where quiet operation is critical, reducing walking noise is essential. For example, one of the main concerns of aibo users is that the walking sound is too loud. This feedback highlights the need for quieter locomotion policies in home robots.

In this work, we focus on minimizing footstep noise by using sim-to-real based \ac{rl} to reduce foot contact velocity, which serves as a proxy for footstep sound reduction, as shown in \figref{fig:quiet_walking_concept}. To achieve this, we introduce three key elements aimed at effectively reducing foot contact velocity during locomotion. First, we allow the \ac{rl} network to dynamically adjust the PD gains of the actuators, allowing for better joint damping and stiffening. Second, we incorporate foot switch contact sensors that detect when the robot's foot touches the ground to selectively dampen joints during the contact phase and stiffen them during the stance phase for body support. Third, we employ a curriculum learning approach that initially trains the robot on basic locomotion and progressively applies penalties to noisy walking such as foot contact velocity to ensure quieter walking.

We validate our approach through hardware experiments with Sony's quadruped robot aibo. In these experiments, we show that foot contact velocity correlates with footstep noise, and our method produces the quietest locomotion compared to both Sony's carefully hand-tuned controllers and other \ac{rl} baselines. In addition, we explore the trade-off between robustness and quietness in locomotion and show that this balance can be adjusted using \ac{dr} parameters.

In summary, our main contributions are as follows: 
\begin{itemize} 
\item Demonstrate superior quiet locomotion in a small home robot by minimizing physical parameters, such as foot contact velocity, that correlate with footstep sound using a sim-to-real \ac{rl} approach. 
\item Develop an RL framework that integrates three core elements: adaptive PD gains, foot contact sensors, and curriculum learning, resulting in an effective policy for quiet walking. 
\item Identify and demonstrate the trade-off between robustness and quietness in robot locomotion, with \ac{dr} parameters providing a way to balance these competing objectives. 
\end{itemize}

