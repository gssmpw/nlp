\section{Introduction}
\label{sec:introduction}

Self-supervised monocular depth estimation (SSMDE)~\citep{godard2019digging} is a task that learns depth solely from a continuous RGB image sequence without needing corresponding ground-truth depth maps for each frame in a video.
This approach significantly simplifies data acquisition compared to traditional supervised methods~\citep{fu2018deep, lee2019big, bhat2021adabins}, which often involve high costs for annotation.
% Self-supervised monocular depth estimation (SSMDE)~\citep{godard2019digging} significantly simplifies data acquisition compared to traditional supervised methods~\citep{fu2018deep, lee2019big, bhat2021adabins}, which often involve high costs for annotation.
% This fascinating advantage originated from the photometric constancy between the images with different camera viewpoints, without needing corresponding ground-truth depth maps for each frame in a video.
As such, many SSMDE studies~\citep{godard2019digging, zhou2017unsupervised, garg2016unsupervised, guizilini20203d} have explored its viability as a mainstay for applications such as autonomous driving, highlighting its potential in outdoor environments.

Despite its advantages, SSMDE approaches typically challenge in accurate depth estimation on non-Lambertian surfaces such as mirrors, transparent objects, and specular surfaces.
This difficulty primarily arises from the assumption of Lambertian reflectance~\citep{basri2003lambertian} embedded in most SSMDE methods.
As illustrated in \Figref{fig:reflective_error}, these non-Lambertian surfaces violate the photometric constancy principle, which posits that the color and brightness of a point should appear constant across different images~\citep{godard2017unsupervised}.
This violation leads to incorrect depth training, particularly on non-Lambertian surfaces.
%This violation leads to incorrect depth predictions because minimizing the photometric error on such surfaces does not guarantee accurate depth training.
Consequently, this issue manifests in a phenomenon known as the ``black-hole effect''~\citep{shi20233d}, where the model erroneously predicts depths that are greater than the actual surface depth in areas with specular reflections.
This effect is a prevalent challenge across various reflective surfaces, significantly impacting the performance and reliability of SSMDE systems.

Recent advancements~\citep{costanzino2023learning, shi20233d} attempt to tackle these challenges by utilizing training strategies that involve generating pseudo-labels through inpainting~\citep{costanzino2023learning} or reconstructing 3D meshes~\citep{shi20233d}.
However, these methods still rely on extra labels such as segmentation mask annotations~\citep{costanzino2023learning} or use auxiliary methods that have excessive computational costs such as ensemble-based uncertainty algorithms~\citep{shi20233d}, TSDF-fusion~\citep{newcombe2011kinectfusion} and mesh rendering~\citep{pyrender}.
%identify reflective regions.
% which can introduce additional errors if the detection of a specular surface is not precise.

\begin{figure}[t]
\begin{center}
  \includegraphics[width=\linewidth]{figure/reflective_error_final_ver.png}
\end{center}
\caption{Photometric constancy violation on reflective surfaces. The projected non-reflective surface point (denoted as \includegraphics[height=8pt]{figure/icons/blue.png}) satisfies the photometric constancy so the model can obtain the accurate depth by photometric error minimization. On the other hand, projected reflective surface point (denoted as \includegraphics[height=8pt]{figure/icons/red.png},\includegraphics[height=8pt]{figure/icons/green.png}) violates the photometric constancy, resulting in wrong disparity by photometric error minimization. This figure depicts a scenario where the relative positions of the cameras shift horizontally, akin to rectified stereo, to simplify the illustration.}
\label{fig:reflective_error}
\end{figure}

To address these issues, we propose a novel training strategy called ``\textit{reflection-aware triplet mining}'' that enhances the performance of SSMDEs by leveraging the triplet mining~\citep{schroff2015facenet}. 
%deep metric learning schemes.
%Our strategy specifically targets abnormalities in photometric error to accurately identify reflective areas at the pixel level, which typically violate the photometric constancy principle as illustrated in~\Figref{fig:reflective_error}.
%We incorporate the triplet mining~\citep{schroff2015facenet} to mitigate the issue of incorrect photometric error minimization in reflective areas.
The underlying principle of our approach is that reflective areas, such as mirror light sources or objects, exhibit disparities corresponding to the reflected object rather than the actual surface as illustrated in~\Figref{fig:reflective_error}.
While non-reflective areas exhibit photometric error due to the difference in camera views from two different perspectives (\textit{e.g.}, source and reference views), reflective areas have abnormally low photometric error between the two views due to the low disparity of reflected objects.
Accordingly, our approach treats views from the same camera coordinates as positive pairs and those from different coordinates as negative pairs, as illustrated in \Figref{fig:triplet}. 
Our method aims to minimize the conventional photometric error between positive pairs while maximizing it between negative pairs. This approach effectively neutralizes the impact of contaminated gradients in reflective regions, thereby significantly improving accuracy on these regions.
% Furthermore, our method selectively apply the triplet loss to reflective region to 

% According to these intuition, our method minimizes the conventional photometric error between positive pairs in the same camera coordinate system while maximizing the error for negative pairs.
% The proposed method effectively neutralizes the impact of contaminated gradients in reflective regions, resulting in improving accuracy on reflective regions.
% Specifically, for negative pairs, the method maximizes the error caused by inevitable viewpoint differences between cameras, excluding regions with abnormally low photometric error and thereby improving accuracy on reflective surfaces.
% However, while the model trained with the proposed loss enhances performance on reflective surfaces, it slightly lacks high-frequency details on non-reflective surfaces due to the dual optimization challenge.
% Furthermore, we observe that previous methods aimed at improving performance on reflective surfaces introduce a side effect, where the predicted depth on non-reflective surfaces shows a slight lack of high-frequency details.

\begin{comment}
Furthermore, we introduce a \textit{reflective-aware knowledge distillation} approach to keep the high-frequency details in the predicted depth for non-reflective regions.
% Inspired by 3D distillation, our distillation method aims to keep the high-frequency details in the predicted depth for non-reflective regions.
% we observe that previous approaches designed to enhance performance on reflective surfaces inadvertently result in a slight loss of high-frequency details in the predicted depth for non-reflective regions.
In this method, the student network is trained by distilling knowledge from two distinct SSMDE networks.
The first utilizes the proposed triplet loss, providing robustness against reflective areas, while the second employs solely photometric minimization loss, adept at preserving high-frequency details that contribute to the perceptual quality and visual fidelity of the depth map.
Our distillation method simplifies the computationally intensive processes in previous work~\citep{shi20233d}, such as training multiple networks for ensemble uncertainty, and per-scene mesh rendering. This results in a significant improvement in computational efficiency.
Moreover, this hybrid training strategy effectively combines the strengths of both training methods, creating a versatile and effective depth estimation framework.
% By leveraging the unique capabilities of each model, the student network can achieve a more comprehensive understanding of depth across various surface conditions.
% Our approach localizes reflective regions using triplet mining in an end-to-end method, reducing computational cost compared to ensemble uncertainty (which requires multiple training) in 3D distillation.
% Our triplet Mining approach localizes reflective regions using triplet mining in an end-to-end method, reducing computational cost compared to ensemble uncertainty (which requires multiple training) in 3D distillation.
% in two sentences:
% In 3D distillation, reflective regions are detected using ensemble uncertainty, which requires multiple training of different networks.
% In contrast, our approach localizes reflective regions using triplet mining in an end-to-end method, significantly reducing the computational cost while maintaining effective detection.
\end{comment}

Moreover, we introduce a ``\textit{reflection-aware knowledge distillation}'' approach to keep the high-frequency details in the predicted depth for non-reflective regions inspired by previous works~\citep{shi20233d}. 
In this method, the student network is trained by distilling knowledge from two distinct SSMDE networks.
The first utilizes the proposed triplet loss, providing robustness against reflective areas, while the second employs solely photometric minimization loss, adept at preserving high-frequency details that contribute to the perceptual quality and visual fidelity of the depth map.
This hybrid training strategy effectively combines the strengths of both training methods, creating a more versatile and effective depth estimation framework.
By leveraging the unique capabilities of each model, the student network can achieve a more comprehensive understanding of depth across various surface conditions.

Our method is broadly applicable to general SSMDE frameworks that rely on photometric error minimization.
We validate our method on three well-known SSMDE networks~\citep{godard2019digging, lyu2021hr, zhao2022monovit} across three public datasets~\citep{dai2017scannet, shotton2013scene, ramirez2023booster} featuring reflective objects and surfaces. The results demonstrate that our method significantly improves depth prediction accuracy on reflective surfaces while preserving performance on non-reflective surfaces.
Our main contributions are fourfold as follows:
\begin{itemize}[leftmargin=15pt]
    \item[1.] We propose a new \textit{reflection-aware triplet mining loss} that significantly enhances the accuracy on reflective surfaces and can be easily integrated into general SSMDE frameworks.
    \item[2.] We introduce \textit{reflection-aware knowledge distillation} to improve the overall accuracy on reflective surfaces while preserving high-frequency details on non-reflective surfaces.
    % \item[2.] We introduce \textit{reflective-aware blend knowledge distillation} that simplifies the excessive computational load used in 3D distillation while effectively boosting depth quality across all regions.
    % option 1
    % \item[2.] We introduce \textit{reflective-aware knowledge distillation} that simplifies the excessive computational load of previous work while preserving high-frequency details on non-reflective surfaces. 
    \item[3.] To the best of our knowledge, our strategy represents the first end-to-end method specifically designed to enhance the performances of SSMDE on reflective surfaces.
    \item[4.] The proposed method outperforms the existing self-supervised training method and shows comparable results against 3D information distillation methods on various indoor depth benchmarks.
\end{itemize}

