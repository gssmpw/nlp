\section{Related Work}
\label{sec:related_work}

\subsection{Self-supervised monocular depth estimation}
\label{sec:rel_selsupmono}
Self-supervised Monocular Depth Estimation (SSMDE) is a task that estimates a depth map from a single image without a ground truth depth map.
This approach significantly simplifies the process of data acquisition, making it scalable for a wide variety of datasets. 
% SfmLearners~\cite{zhou2017unsupervised} is the first SSMDEs framework that learns depth from the photometric consistency loss of the synthesized target view and the original target view by utilizing the depth map estimated for the target view and pose estimated from the sequential views.
% However, minimizing photometric consistency loss under certain conditions (e.g. dynamic scene modeling, occlusion, non-Lambertian object) may cause the incorrect depth.
%Garg et al.~\cite{garg2016unsupervised} initially posited a clue that depth maps can be learned without relying on supervised signals using the photometric consistency loss between stereo images.
SfMLearner~\citep{zhou2017unsupervised} introduces a pioneering framework for self-supervised depth map estimation, which simultaneously learns depth maps for the input image and pose parameters from sequential views.
Monodepth2~\citep{godard2019digging} proposes a masking scheme and minimum reprojection loss to filter out the regions that violate photometric constancy, such as moving objects and occluded regions.
Subsequent methods~\citep{zhou2021self, guizilini20203d, lyu2021hr} have been refined, effectively integrating features of different resolutions based on established constraints.
With the introduction of ViT~\citep{dosovitskiy2020image}, the field of SSMDE has begun to incorporate transformer backbones. 
Monoformer~\citep{bae2023deep} and MonoViT~\citep{zhao2022monovit} have emerged, utilizing hybrid networks of CNN and transformers to adeptly merge local and global features.
% Recent studies like Litemono~\cite{zhang2023lite} focus on reducing the computational burden of ViTs while maintaining their effectiveness.

\subsection{Generalization of monocular depth estimation}
\label{sec:rel_genmono}
Recent research has expanded to consider factors such as the impact of weather variations~\citep{saunders2023self, gasperini2023robust}, the differences in inference capabilities between CNNs and Transformers~\citep{bae2023study}, the robustness of SSMDEs against various types of data corruption~\citep{kong2024robodepth}, and methods for accurately modeling transparent and mirrored surfaces, which are typically non-Lambertian~\citep{costanzino2023learning}.
In addition, the 3D Distillation~\citep{shi20233d} addresses a critical flaw in traditional SSMDEs: the photometric constancy principle used in applying photometric consistency loss may not hold for non-Lambertian surfaces encountered in real-world scenarios, resulting in SSMDE models producing unreliable and low-quality depth estimates for reflective surfaces.
To counter this problem, 3D Distillation leverages the 3D mesh rendering function along with ensemble uncertainty to localize the reflective surfaces and refine the inaccurate depth on these regions.
% To counter this problem, 3D Distillation estimates aggregated depth maps from meshes reconstructed from multiple views and employs uncertainty measures across different trained models to generate pseudo-labels.
% These labels are then distilled to refine the handling of reflective surfaces.
% However, it requires a larger volume of observations for mesh reconstruction compared to standard SSMDE training methods. Additionally, accurately addressing the uncertainties inherent in the diverse network architectures is crucial for effectively generating robust pseudo-labels for reflective surfaces.

\subsection{Deep metric learning}
\label{sec:rel_deep_metric}
Deep metric learning~\citep{chen2020simple, chen2021exploring, khosla2020supervised} seeks to develop an effective distance measure between data points.
These methods strive to minimize the distance between samples of the same class while maximizing it between samples from different classes.
While traditionally focused on classification tasks, where positive and negative pairs are defined based on class similarity, recent studies~\citep{spurr2021self, wang2022contrastive, zha2024rank} have expanded the application of deep metric learning to regression contexts.
% These studies vary in approach; some directly use target distances to contrast samples~\citep{wang2022contrastive, zha2024rank}, while others incorporate representation learning within a semi-supervised framework~\citep{spurr2021self}.
% These methods often applied in recognition tasks amenable to augmentation, have proven effective and reliable.
Particularly in the context of depth estimation, deep metric learning has demonstrated versatility beyond simple augmentation-based consistency.
It has been applied to enhance accuracy through contrasting depth distributions~\citep{fan2023contrastive, choi2024depth} and addressing issues such as edge fattening~\citep{chen2023self}.
In this paper, we utilize the triplet mining scheme, initially popularized by~\citet{schroff2015facenet}, to enhance recognition accuracy, specifically focusing on improving performance on reflective surfaces.