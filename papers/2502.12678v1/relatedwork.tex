\section{Related work on two-player markov game \& optimistic online gradient descent}
Two-player Markov games have been widely studied since the seminal work \citep{shapley1953stochastic}. Particularly relevant to our work is the research line on policy gradient algorithms for two-player Markov games such as \citet{daskalakis2020independent,wei2021last,alacaoglu2022natural}.
% \textbf{optimistic online gradient descent} 
Our \oomdmethod{} is strictly related to the idea of optimistic online gradient descent \citep{popov1980modification,chiang2012online,rakhlin2013online} originally proposed in online learning to achieve small regret in case of slow varying loss sequences. Our update that uses only one projection per update was proposed in \citet{joulani17a}. The name of our method is due to a similar algorithm introduced in the context of variational inequalities by \citet{malitsky2020forward}.
\rebuttal{