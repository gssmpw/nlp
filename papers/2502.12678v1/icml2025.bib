@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
@article{jiang2022generalized,
  title={Generalized optimistic methods for convex-concave saddle point problems},
  author={Jiang, Ruichen and Mokhtari, Aryan},
  journal={arXiv preprint arXiv:2202.09674},
  year={2022}
}
@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the national academy of sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}
@article{popov1980modification,
  title={A modification of the Arrow-Hurwitz method of search for saddle points},
  author={Popov, Leonid Denisovich},
  journal={Mat. Zametki},
  volume={28},
  number={5},
  pages={777--784},
  year={1980}
}
@inproceedings{wei2021last,
  title={Last-iterate convergence of decentralized optimistic gradient descent/ascent in infinite-horizon competitive Markov games},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  booktitle={Conference on Learning Theory},
  pages={4259--4299},
  year={2021},
  organization={PMLR}
}
@book{Puterman:1994,
author = {Puterman, M. L.},
title = {{M}arkov {D}ecision {P}rocesses: Discrete Stochastic Dynamic Programming},
year = {1994},
publisher = {John Wiley \& Sons, Inc.},
address = {USA},
edition = {1st}
}
@inproceedings{levy2023efficient,
  title={Efficient rate optimal regret for adversarial contextual MDPs using online function approximation},
  author={Levy, Orin and Cohen, Alon and Cassel, Asaf and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={19287--19314},
  year={2023},
  organization={PMLR}
}
@article{neu2021online,
  title={Online learning in MDPs with linear function approximation and bandit feedback.},
  author={Neu, Gergely and Olkhovskaya, Julia},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10407--10417},
  year={2021}
}
@misc{neu2017unified,
      title={A unified view of entropy-regularized Markov decision processes}, 
      author={Gergely Neu and Anders Jonsson and Vicenç Gómez},
      year={2017},
      eprint={1705.07798},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.07798}, 
}
@book{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010},
  publisher={Carnegie Mellon University}
}
@article{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  journal={arXiv preprint arXiv:1512.08562},
  year={2015}
}
@article{viano2022proximal,
  title={Proximal point imitation learning},
  author={Viano, Luca and Kamoutsi, Angeliki and Neu, Gergely and Krawczuk, Igor and Cevher, Volkan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24309--24326},
  year={2022}
}
@inproceedings{bas2021logistic,
  title={Logistic Q-learning},
  author={Bas-Serrano, Joan and Curi, Sebastian and Krause, Andreas and Neu, Gergely},
  booktitle={International conference on artificial intelligence and statistics},
  pages={3610--3618},
  year={2021},
  organization={PMLR}
}
@InProceedings{joulani17a,
  title = 	 {A Modular Analysis of Adaptive (Non-)Convex Optimization: Optimism, Composite Objectives, and Variational Bounds},
  author = 	 {Joulani, Pooria and György, András and Szepesvári, Csaba},
  booktitle = 	 {Proceedings of the 28th International Conference on Algorithmic Learning Theory},
  pages = 	 {681--720},
  year = 	 {2017},
  editor = 	 {Hanneke, Steve and Reyzin, Lev},
  volume = 	 {76},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--17 Oct},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v76/joulani17a/joulani17a.pdf},
  url = 	 {https://proceedings.mlr.press/v76/joulani17a.html},
  abstract = 	 {Recently, much work has been done on extending the scope of online learning and incremental stochastic optimization algorithms. In this paper we contribute to this effort in two ways: First, based on a new regret decomposition and a generalization of Bregman divergences, we provide a self-contained, modular analysis of the two workhorses of online learning: (general) adaptive versions of Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms. The analysis is done with extra care so as not to introduce assumptions not needed in the proofs and allows to combine, in a straightforward way, different algorithmic ideas (e.g., adaptivity, optimism, implicit updates) and learning settings (e.g., strongly convex or composite objectives). This way we are able to reprove, extend and refine a large body of the literature, while keeping the proofs concise. The second contribution is a byproduct of this careful analysis: We present algorithms with improved variational bounds for smooth, composite objectives, including a new family of optimistic MD algorithms with only one projection step per round. Furthermore, we provide a simple extension of adaptive regret bounds to practically relevant non-convex problem settings with essentially no extra effort.}
}
@inproceedings{rakhlin2013online,
  title={Online learning with predictable sequences},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  pages={993--1019},
  year={2013},
  organization={PMLR}
}
@InProceedings{chiang2012online,
  title = 	 {Online Optimization with Gradual Variations},
  author = 	 {Chiang, Chao-Kai and Yang, Tianbao and Lee, Chia-Jung and Mahdavi, Mehrdad and Lu, Chi-Jen and Jin, Rong and Zhu, Shenghuo},
  booktitle = 	 {Proceedings of the 25th Annual Conference on Learning Theory},
  pages = 	 {6.1--6.20},
  year = 	 {2012},
  editor = 	 {Mannor, Shie and Srebro, Nathan and Williamson, Robert C.},
  volume = 	 {23},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Edinburgh, Scotland},
  month = 	 {25--27 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v23/chiang12/chiang12.pdf},
  url = 	 {https://proceedings.mlr.press/v23/chiang12.html},
  abstract = 	 {We study the online convex optimization problem, in which an online algorithm has to make repeated decisions with convex loss functions and hopes to achieve a small regret. We consider a natural restriction of this problem in which the loss functions have a small deviation, measured by the sum of the distances between every two consecutive loss functions, according to some distance metrics. We show that for the linear and general smooth convex loss functions, an online algorithm modified from the gradient descend algorithm can achieve a regret which only scales as the square root of the deviation. For the closely related problem of prediction with expert advice, we show that an online algorithm modified  from the multiplicative update algorithm can also achieve a similar regret bound for a different measure of deviation. Finally, for loss functions which are strictly convex, we show that an online algorithm modified from the online Newton step algorithm can achieve a regret which is only logarithmic in terms of the deviation, and as an application, we can also have such a logarithmic regret for the portfolio management problem.}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}
@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}
@inproceedings{warmuth1997continuous,
  title={Continuous and discrete-time nonlinear gradient descent: Relative loss bounds and convergence},
  author={Warmuth, Manfred K and Jagota, Arun K and others},
  booktitle={Electronic proceedings of the 5th International Symposium on Artificial Intelligence and Mathematics},
  volume={326},
  year={1997},
  organization={Citeseer}
}
@article{tang2024generalized,
  title={Generalized preference optimization: A unified approach to offline alignment},
  author={Tang, Yunhao and Guo, Zhaohan Daniel and Zheng, Zeyu and Calandriello, Daniele and Munos, R{\'e}mi and Rowland, Mark and Richemond, Pierre Harvey and Valko, Michal and Pires, Bernardo {\'A}vila and Piot, Bilal},
  journal={arXiv preprint arXiv:2402.05749},
  year={2024}
}
@inproceedings{
rafailov2024r,
title={From \$r\$ to \$Q{\textasciicircum}*\$: Your Language Model is Secretly a Q-Function},
author={Rafael Rafailov and Joey Hejna and Ryan Park and Chelsea Finn},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=kEVcNxtqXk}
}
@misc{orabona2023onlinelearning,
      title={A Modern Introduction to Online Learning}, 
      author={Francesco Orabona},
      year={2023},
      eprint={1912.13213},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.13213}, 
}
@inproceedings{perolat2015approximate,
  title={Approximate dynamic programming for two-player zero-sum Markov games},
  author={Perolat, Julien and Scherrer, Bruno and Piot, Bilal and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={1321--1329},
  year={2015},
  organization={PMLR}
}
@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@misc{sun2019dual,
      title={Dual Policy Iteration}, 
      author={Wen Sun and Geoffrey J. Gordon and Byron Boots and J. Andrew Bagnell},
      year={2019},
      eprint={1805.10755},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{
loshchilov2017sgdr,
title={{SGDR}: Stochastic Gradient Descent with Warm Restarts},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=Skq89Scxx}
}
@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}
@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}
@article{lai2024step,
  title={Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Yang, Senqiao and Peng, Xiangru and Jia, Jiaya},
  journal={arXiv preprint arXiv:2406.18629},
  year={2024}
}
@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}
@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}
@inproceedings{liu2024augmenting,
  title={Augmenting Math Word Problems via Iterative Question Composing},
  author={Liu, Haoxiong and Zhang, Yifan and Luo, Yifan and Yao, Andrew Chi-Chih},
  booktitle={ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models},
  year={2024},
  url={https://openreview.net/forum?id=0asPFqWyTA}
}
@inproceedings{
yu2024metamath,
title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=N8N0hgNDRt}
}
@inproceedings{zengtoken,
  title={Token-level Direct Preference Optimization},
  author={Zeng, Yongcheng and Liu, Guoqing and Ma, Weiyu and Yang, Ning and Zhang, Haifeng and Wang, Jun},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@article{zhang2024iterative,
  title={Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning},
  author={Zhang, Yuheng and Yu, Dian and Peng, Baolin and Song, Linfeng and Tian, Ye and Huo, Mingyue and Jiang, Nan and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2407.00617},
  year={2024}
}
@article{hwang2024self,
  title={Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards},
  author={Hwang, Hyeonbin and Kim, Doyoung and Kim, Seungone and Ye, Seonghyeon and Seo, Minjoon},
  journal={arXiv preprint arXiv:2404.10346},
  year={2024}
}
@inproceedings{wu2024self,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
booktitle={International Conference on Learning Representations},
  year={2025}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@inproceedings{li2024remax,
  title={Remax: A simple, effective, and efficient method for aligning large language models},
  author={Li, Ziniu and Xu, Tian and Zhang, Yushun and Yu, Yang and Sun, Ruoyu and Luo, Zhi-Quan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{liu2024tis,
  title={TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights},
  author={Liu, Aiwei and Bai, Haoping and Lu, Zhiyun and Sun, Yanchao and Kong, Xiang and Wang, Simon and Shan, Jiulong and Jose, Albin Madappally and Liu, Xiaojiang and Wen, Lijie and others},
  journal={arXiv preprint arXiv:2410.04350},
  year={2024}
}
@inproceedings{swamyminimaximalist,
  title={A Minimaximalist Approach to Reinforcement Learning from Human Feedback},
  author={Swamy, Gokul and Dann, Christoph and Kidambi, Rahul and Wu, Steven and Agarwal, Alekh},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@inproceedings{munos2024nash,
  title={Nash Learning from Human Feedback},
  author={Munos, R{\'e}mi and Valko, Michal and Calandriello, Daniele and Azar, Mohammad Gheshlaghi and Rowland, Mark and Guo, Zhaohan Daniel and Tang, Yunhao and Geist, Matthieu and Mesnard, Thomas and Michi, Andrea and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@article{daskalakis2020independent,
  title={Independent policy gradient methods for competitive reinforcement learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5527--5540},
  year={2020}
}
@inproceedings{zhong2022pessimistic,
  title={Pessimistic minimax value iteration: Provably efficient equilibrium learning from offline datasets},
  author={Zhong, Han and Xiong, Wei and Tan, Jiyuan and Wang, Liwei and Zhang, Tong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Machine Learning},
  pages={27117--27142},
  year={2022},
  organization={PMLR}
}
@inproceedings{alacaoglu2022natural,
  title={A natural actor-critic framework for zero-sum Markov games},
  author={Alacaoglu, Ahmet and Viano, Luca and He, Niao and Cevher, Volkan},
  booktitle={International Conference on Machine Learning},
  pages={307--366},
  year={2022},
  organization={PMLR}
}
@article{wang2024q,
  title={Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning},
  author={Wang, Chaojie and Deng, Yanchen and Lv, Zhiyi and Yan, Shuicheng and Bo, An},
  journal={arXiv preprint arXiv:2406.14283},
  year={2024}
}
@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}
@article{malitsky2020forward,
  title={A forward-backward splitting method for monotone inclusions without cocoercivity},
  author={Malitsky, Yura and Tam, Matthew K},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={2},
  pages={1451--1472},
  year={2020},
  publisher={SIAM}
}
@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on learning theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}
@article{zhang2024chain,
  title={Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs},
  author={Zhang, Xuan and Du, Chao and Pang, Tianyu and Liu, Qian and Gao, Wei and Lin, Min},
  journal={arXiv preprint arXiv:2406.09136},
  year={2024}
}
@article{bai2024mt,
  title={Mt-bench-101: A fine-grained benchmark for evaluating large language models in multi-turn dialogues},
  author={Bai, Ge and Liu, Jie and Bu, Xingyuan and He, Yancheng and Liu, Jiaheng and Zhou, Zhanhui and Lin, Zhuoran and Su, Wenbo and Ge, Tiezheng and Zheng, Bo and others},
  journal={arXiv preprint arXiv:2402.14762},
  year={2024}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{liang2024mathchat,
  title={MathChat: Benchmarking Mathematical Reasoning and Instruction Following in Multi-Turn Interactions},
  author={Liang, Zhenwen and Yu, Dian and Yu, Wenhao and Yao, Wenlin and Zhang, Zhihan and Zhang, Xiangliang and Yu, Dong},
  journal={arXiv preprint arXiv:2405.19444},
  year={2024}
}
@article{xiong2024watch,
  title={Watch Every Step! LLM Agent Learning via Iterative Step-Level Process Refinement},
  author={Xiong, Weimin and Song, Yifan and Zhao, Xiutian and Wu, Wenhao and Wang, Xun and Wang, Ke and Li, Cheng and Peng, Wei and Li, Sujian},
  journal={arXiv preprint arXiv:2406.11176},
  year={2024}
}
@article{freund1999adaptive,
  title={Adaptive game playing using multiplicative weights},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Games and Economic Behavior},
  volume={29},
  number={1-2},
  pages={79--103},
  year={1999},
  publisher={Elsevier}
}
@article{shani2024multi,
  title={Multi-turn Reinforcement Learning from Preference Human Feedback},
  author={Shani, Lior and Rosenberg, Aviv and Cassel, Asaf and Lang, Oran and Calandriello, Daniele and Zipori, Avital and Noga, Hila and Keller, Orgad and Piot, Bilal and Szpektor, Idan and others},
  journal={arXiv preprint arXiv:2405.14655},
  year={2024}
}
@article{shi2024direct,
  title={Direct Multi-Turn Preference Optimization for Language Agents},
  author={Shi, Wentao and Yuan, Mengqi and Wu, Junkang and Wang, Qifan and Feng, Fuli},
  journal={arXiv preprint arXiv:2406.14868},
  year={2024}
}
@article{wang2024self,
  title={Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning},
  author={Wang, Tianduo and Li, Shichen and Lu, Wei},
  journal={arXiv preprint arXiv:2407.18248},
  year={2024}
}
@article{song2024trial,
    author={Yifan Song and Da Yin and Xiang Yue and Jie Huang and Sujian Li and Bill Yuchen Lin},
    title={Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents},
    year={2024},
    eprint={2403.02502},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}
@article{singh2024dipper,
  title={DIPPER: Direct Preference Optimization to Accelerate Primitive-Enabled Hierarchical Reinforcement Learning},
  author={Singh, Utsav and Chakraborty, Souradip and Suttle, Wesley A and Sadler, Brian M and Namboodiri, Vinay P and Bedi, Amrit Singh},
  journal={arXiv preprint arXiv:2406.10892},
  year={2024}
}

@article{pang2024iterative,
  title={Iterative reasoning preference optimization},
  author={Pang, Richard Yuanzhe and Yuan, Weizhe and Cho, Kyunghyun and He, He and Sukhbaatar, Sainbayar and Weston, Jason},
  journal={arXiv preprint arXiv:2404.19733},
  year={2024}
}
@article{dong2024rlhf,
  title={Rlhf workflow: From reward modeling to online rlhf},
  author={Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong},
  journal={arXiv preprint arXiv:2405.07863},
  year={2024}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}
@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}
@article{lu2024step,
  title={Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning},
  author={Lu, Zimu and Zhou, Aojun and Wang, Ke and Ren, Houxing and Shi, Weikang and Pan, Junting and Zhan, Mingjie},
  journal={arXiv preprint arXiv:2407.00782},
  year={2024}
}
@article{wang2023rlhf,
  title={Is rlhf more difficult than standard rl? a theoretical perspective},
  author={Wang, Yuanhao and Liu, Qinghua and Jin, Chi},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}
@article{hong2024orpo,
  title={Orpo: Monolithic preference optimization without reference model},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  journal={arXiv preprint arXiv:2403.07691},
  volume={2},
  number={4},
  pages={5},
  year={2024}
}
@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{tversky1969intransitivity,
  title={Intransitivity of preferences.},
  author={Tversky, Amos},
  journal={Psychological review},
  volume={76},
  number={1},
  pages={31},
  year={1969},
  publisher={American Psychological Association}
}
@article{gardner1970mathematical,
  title={Mathematical games},
  author={Gardner, Martin},
  journal={Scientific american},
  volume={222},
  number={6},
  pages={132--140},
  year={1970},
  publisher={JSTOR}
}