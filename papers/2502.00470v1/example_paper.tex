%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}


%\usepackage{todonotes}
\newcommand{\andi}[1]{\todo[size=\tiny,color=green]{#1}}
\newcommand{\andinote}[1]{\todo[inline,color=green]{#1}}
\newcommand{\runxiongnote}[1]{\todo[inline,color=red]{#1}}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\newcommand \RR {\mathbb{R}}
\newcommand {\diag}[1] {\mathrm{diag}\left(#1\right)}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\DeclareMathOperator*{\argmin}{arg\, min}
\DeclareMathOperator*{\argmax}{arg\, max}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}

\renewcommand{\Pr}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\condP}[2]{\Pr\left(#1\;\middle|\;#2\right)}
\newcommand{\condE}[2]{\E\left[#1\;\middle|\;#2\right]}

\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\bn}[1] {\bm{\mathrm{#1}}}

\newcommand{\inner}[1]{\left\langle #1\right\rangle}
\newcommand{\T}{^\top}
\newcommand{\hh}{^{\mathsf{H}}}
\newcommand{\inv}{^{-1}}
\newcommand{\by}{\times}
\newcommand{\invT}{^{-\top}}
\newcommand {\tr}[1] {\mathrm{tr}\left(#1\right)}

\mathchardef\mhyphen="2D
\newcommand {\sA}{\mathcal{A}}
\newcommand {\sB}{\mathcal{B}}
\newcommand {\sC}{\mathcal{C}}
\newcommand {\sD}{\mathcal{D}}
\newcommand {\sE}{\mathcal{E}}
\newcommand {\sF}{\mathcal{F}}
\newcommand {\sG}{\mathcal{G}}
\newcommand {\sH}{\mathcal{H}}
\newcommand {\sI}{\mathcal{I}}
\newcommand {\sJ}{\mathcal{J}}
\newcommand {\sK}{\mathcal{K}}
\newcommand {\sL}{\mathcal{L}}
\newcommand {\sM}{\mathcal{M}}
\newcommand {\sN}{\mathcal{N}}
\newcommand {\sO}{\mathcal{O}}
\newcommand {\sP}{\mathcal{P}}
\newcommand {\sQ}{\mathcal{Q}}
\newcommand {\sR}{\mathcal{R}}
\newcommand {\sS}{\mathcal{S}}
\newcommand {\sT}{\mathcal{T}}
\newcommand {\sU}{\mathcal{U}}
\newcommand {\sV}{\mathcal{V}}
\newcommand {\sW}{\mathcal{W}}
\newcommand {\sX}{\mathcal{X}}
\newcommand {\sY}{\mathcal{Y}}
\newcommand {\sZ}{\mathcal{Z}}


\newcommand \QQ {\mathbb{Q}}
\newcommand \CC {\mathbb{C}}
\newcommand \ZZ {\mathbb{Z}}
\newcommand \NN {\mathbb{N}}
\newcommand \ii {\sqrt{-1}}
\newcommand{\onevec}{\mathbf{1}}
\newcommand{\zerovec}{\mathbf{0}}

\newcommand{\vol}{\text{vol}}

\newcommand \so {\Rightarrow}
\newcommand \from {\Leftarrow}
\newcommand \eqiv {\iff}

\newcommand{\brs}[1]{\left(#1\right)}
\newcommand{\brm}[1]{\left[#1\right]}
\newcommand{\brl}[1]{\left\{#1\right\}}
\newcommand{\set}[2]{\left\{#1\middle|#2\right\}}

\newcommand{\mat}[1]{{
\begin{bmatrix}
\end{bmatrix}
}
}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Distributed Primal-Dual Algorithms}

\begin{document}

\twocolumn[
\icmltitle{Distributed Primal-Dual Algorithms: Unification, Connections, and Insights }

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Runxiong Wu}{yyy}
%\icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
\icmlauthor{Dong Liu}{comp}
\icmlauthor{Xueqin Wang}{sch}
\icmlauthor{Andi Wang}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
% %\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of Industrial and Systems Engineering, University of Wisconsinâ€“Madison, Madison, WI, USA. Email: calvin.wu@wisc.edu, andi.wang@wisc.edu.}
\icmlaffiliation{comp}{The School of Gifted Young, University of Science and Technology of China, Hefei, P.R.China.}
\icmlaffiliation{sch}{The School of Management, University of Science and Technology of China, Hefei, P.R.China}

\icmlcorrespondingauthor{Andi Wang}{andi.wang@wisc.edu}
%\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
We study primal-dual algorithms for general empirical risk minimization problems in distributed settings, focusing on two prominent classes of algorithms. The first class is the communication-efficient distributed dual coordinate ascent (CoCoA), derived from the coordinate ascent method for solving the dual problem. The second class is the alternating direction method of multipliers (ADMM), including consensus ADMM, linearized ADMM, and proximal ADMM. We demonstrate that both classes of algorithms can be transformed into a unified update form that involves only primal and dual variables. This discovery reveals key connections between the two classes of algorithms: CoCoA can be interpreted as a special case of proximal ADMM for solving the dual problem, while consensus ADMM is closely related to a proximal ADMM algorithm. This discovery provides the insight that by adjusting the augmented Lagrangian parameter, we can easily enable the ADMM variants to outperform the CoCoA variants. We further explore linearized versions of ADMM and analyze the effects of tuning parameters on these ADMM variants in the distributed setting. Our theoretical findings are supported by extensive simulation studies and real-world data analysis.
\end{abstract}


\section{Introduction}


In this paper, we consider algorithms solving a federated learning problem where $K$ machines collaboratively solve a general empirical risk minimization problem, based on $n$ samples $\left\{x_i\right\}_{i=1}^{n} \subset \mathbb{R}^d$ distributed in all machines,  
\begin{equation}\label{primal}
\underset{w \in \mathbb{R}^d}{\min} \left\{ \mathcal{P}(w) := \frac{1}{n} \sum_{k=1}^{K} \sum_{i \in \mathcal{P}_k} \ell_i(w^\top x_i) + g(w) \right\}. 
\end{equation}
In this formulation, $\left\{\mathcal{P}_k\right\}_{k=1}^{K}$ denotes the partition of these samples in machines, $|\mathcal{P}_k| = n_k$ and $\sum_{k=1}^{K} n_k = n$. The parameter of common interest is \(w \in \mathbb{R}^d\), \(\ell_i(\cdot)\) is the local convex loss function potentially incorporating label information for the \(i\)-th data sample, and \(g(\cdot)\) is a convex regularization penalty possibly non-smooth. 
Examples of loss functions include least squares loss, quantile loss, Huber loss, and hinge loss, while examples of penalty functions include the $\ell_1$ norm, $\ell_2$ norm and elastic net. Problems of this type is pervasive in various applications of machine learning. 

Over the past decades, efficient distributed algorithms have been designed to solve problem \eqref{primal}. % However, most existing frameworks are limited to solving specific subsets of these problems, often requiring the objective function to be strongly convex or smooth. 
%These methods can be broadly classified into three main categories: gradient-based algorithms, coordinate-based algorithms, and primal-dual algorithms. Gradient-based distributed algorithms, as the name suggests, rely on the gradient information of the objective function. They are easy to implement and well-suited for parallelization but require the part of the objective function to be smooth, meaning either the loss function or penalty function must be smooth. Examples of such methods include distributed variants of first-order methods such as stochastic gradient descent (SGD) \cite{mahajan2013parallel,zinkevich2010parallelized,recht2011hogwild}, accelerated SGD \cite{shamir2014distributed}, variance reduction SGD \cite{lee2015distributed,j2015variance}, mirror descent method \cite{yuan2021federated,bao2022fast}. To improve communication efficiency, many methods \cite{reddi2016aide,mahajan2018efficient,shamir2014communication,zhang2015disco,wang2018giant,jiang2024stabilized} incorporate curvature information in addition to the gradient. 
One popular class of the algorithms to solve the problem \eqref{primal} % popular type of distributed algorithm 
is 
% based on modifying the coordinate descent method. Examples include stochastic coordinate descent methods  \cite{fercoq2016optimization,liu2014asynchronous,necoara2016parallel,richtarik2016parallel}, dual coordinate ascent algorithms \cite{richtarik2016distributed,yang2013trading,zheng2017general}, and 
 communication-efficient distributed dual coordinate ascent (CoCoA) framework and its variants \cite{yang2013trading,ma2015adding,smith2018cocoa,jaggi2014communication,dunner2018distributed,lee2020distributed}. This approach originates from adapting the dual coordinate descent method \cite{shalev2013stochastic} for distributed scenarios. It create an upper bound of the dual objective which enables parallel update of the corresponding dual variables on individual machines, under the assumption that the penalty function of $g$ is strongly convex.  %\runxiongnote{In the original CoCoA paper, these is a sentence "The core idea is to use the dual variables to efficiently merge the parallel updates from the different workers without much conflict, by exploiting the fact that they all work on disjoint sets of dual variables."} 
 % While coordinate descent offers theoretical advantages over gradient descent in centralized learning settings \cite{wright2015coordinate,shalev2013stochastic,johnson2013accelerating}, coordinate-based distributed algorithms often require gradient information during execution or depending on the objective function being partially separable. Consequently, these algorithms are only suited to addressing parts of these problems \eqref{primal}.
 
 Another class of methods that solves \eqref{primal} is the alternating direction method of multipliers (ADMM) and its variants \cite{boyd2011distributed}. %tran2021feddr,zhang2021fedpd,wang2022fedadmm,zhou2023federated,chang2014multi,chang2016asynchronous,yang2022proximal}. 
 For example, consensus ADMM method has been recognized as an effective way to solve federated learning problems, which tailors the classical two-block ADMM method for distributed scenarios through duplicating many local variables. Recently, significant research has focused on developing ADMM variants to address the federated learning problems. % As the number of edge devices increases, this method becomes less effective due to loose approximations, resulting in poor communication efficiency, even though executing this type of method does not require the objective function to be strongly convex or smooth. 
An extension is generalized (or proximal) ADMM algorithms, for example \cite{deng2016global}, to achieve faster convergence rate for the ADMM algorithm. The reviews \cite{yang2022survey,han2022survey,glowinski2014alternating,maneesha2021survey} provide comprehensive discussions on the recent advancements of using ADMM variants in distributed optimization. 

In this study, we present an interesting discovery that CoCoA, consensus ADMM, and two distributed proximal ADMM algorithms \cite{deng2016global,deng2017parallel} we identified can all be cast into the same kind of update rules that only involve the primal variables and dual variables. Up to our knowledge, this is an original discovery, and the unified update rules result in (1) an easy calculation of the dual gap, (2) a novel understandings on the connections among CoCoA and ADMM-type algorithms in the existing literature,  and (3) a unified proof for the convergence of ADMM-type algorithms. A major outcome is that the update rule of CoCoA is identical to a special proximal ADMM algorithm with a specific selection of step size, whereas this proximal ADMM algorithm has a strong connection with a consensus ADMM algorithm. 

Our main contributions can be summarized as follows:

\begin{enumerate}
\item We reformulate consensus ADMM, linear consensus ADMM, two proximal ADMM algorithms, and CoCoA into a unified update form that involves only the primal variable $w$ and the dual variable $v$. The two proximal ADMM algorithms are original to solves the regularized federated learning problem \eqref{primal}. We also propose a primal-dual gap difference certificate to serve as a stopping criterion for consensus ADMM.

\item Based on this unified formulation, we establish connections among these three distributed algorithm frameworks. The dual variable updates in the CoCoA framework is equivalent with the first proximal ADMM algorithm, which in turn associated with the consensus ADMM. The linearized version of the consensus ADMM is associated with the second proximal ADMM formulation that enable leveraging the closed-form expression of the proximal operators of the loss. 

\item We thoroughly study the effects of the tuning parameters in both the proximal ADMM and consensus ADMM and use synthetic and real data experiments to verify our results.
\end{enumerate}

The remaining part of the article is organized as follows. In Section 2, we introduce the five algorithms and cast them into a unified form of primal-dual update. In Section 3, we use the unified update form to evaluate the connections between algorithms. In Section 4,  further provides a unified proof of the convergence for all algorithms, leveraging the update form. Section 5 use experiments to validates our results, and Section 6 concludes the article.  All proofs are included in the appendix. 

\paragraph{Notations.} Let \( X = [x_1, \ldots, x_n] \in \mathbb{R}^{d \times n} \) represent the whole training data matrix. We use a column vector \( v = [v_1, \ldots, v_n]^{\top} \in \mathbb{R}^n \) to denote the dual variable. We use $v_{[k]}\in\RR^{n_k}$ and $X_{[k]}\in\RR^{d\times n_k}$ to denote the dual variable block and training data block on the $k$-th machine, where $X=[X_{[1]},\ldots, X_{[K]}]$ and $v = (v_{[1]}\T,\ldots, v_{[K]})\T$. Correspondingly, we define $\ell_{[k]}^*(v_{[k]})=\sum_{i\in \mathcal{P}_k}\ell_i^*(v_i)$. For a positive semidefinite matrix $S$, we denote by $\|x\|_{S}:=\sqrt{x^{\top}Sx}.$ \(\lambda_{\max}(M)\) denotes the largest eigenvalue of  matrix $M$. The proximal operator for any convex function \( f(\cdot) \) and positive constant \( \lambda > 0 \) is defined as
\[
\text{prox}_{\lambda f}(v) = \arg\min_{x\in\RR^m} \left( f(x) + \frac{1}{2\lambda} \|x - v\|^2 \right).
\]

\if 0
We will often use the following Moreau identity through this paper:
\[
\text{Prox}_{\lambda f}(v)+\lambda \text{Prox}_{f^*/\lambda }(v/\lambda)=v. 
\]
From the Moreau identity above, we know that if the proximal operator of the Fenchel conjugate function is easy to compute, we can determine the proximal mapping of the original function. 
\fi


\section{Distributed Algorithms via Primal and Dual Updates}\label{algorithm description}
In this section, we demonstrate that various distributed algorithms, including CoCoA algorithm with ridge penalty  \cite{jaggi2014communication,ma2015adding,ma2021accelerated,smith2018cocoa}, global consensus ADMM algorithm with regularization \cite{boyd2011distributed} and its linearized variant  \cite{lin2011linearized}, and two proximal ADMM \cite{deng2016global} that enable distributed solution of problem \eqref{primal}, can all be cast into an update form that only involves the updates for the primal and the dual variables. As we will see in the next section, the transformations will reveal valuable connections between the different techniques. The transformation of the CoCoA algorithm and the proximal ADMM algorithms will both rely on the dual problem of problem \eqref{primal} below (see Appendix~\ref{sec:dualproof}). 
\begin{equation}\label{dual}
\underset{v\in\mathbb{R}^n}{\min} \left\{ 
\mathcal{D}(v):=\frac{1}{n}\sum_{k=1}^{K} \sum_{i\in\mathcal{P}_k} \ell^*_i(v_i)+g^*\left(-Xv/n\right) 
\right\}.
\end{equation}
Here \( f^* \)  denotes the Fenchel conjugate of a proper, convex, and lower semi-continuous function $f:\RR^m\to\RR$, 
 defined as $f^*(u) = \sup_{v \in \mathbb{R}^m} \left\{\langle u, v \rangle - f(v)\right\}$. 

\subsection{CoCoA with Ridge Penalty}
With the ridge penalty $g(w) = \lambda \norm {w}_2^2/2$, the dual form \eqref{dual} can be written as
\begin{equation*}
\underset{v\in\mathbb{R}^n}{\min} \left\{ 
\mathcal{D}(v):=\frac{1}{n}\sum_{k=1}^{K} \sum_{i\in\mathcal{P}_k} \ell^*_i(v_i)+\frac{1}{2n^2\lambda}\|Xv\|^2\right\}.
\end{equation*}
CoCoA follows a majorization-minimization scheme and minimizes $Q(v|v^{(t)})$, an upper bound function of $\mathcal{D}(v)$ in each iteration $t$ with the current dual variable $v^{(t)}$ \cite{smith2018cocoa} in a distributed manner: 
\begin{equation*}
\begin{split}
&Q(v|v^{(t)})=\frac{1}{n}\sum_{k=1}^{K} \sum_{i\in\mathcal{P}_k} \ell^*_i(v_i)+\frac{1}{2n^2\lambda}\Big\|\sum_{k=1}^{K} X_{[k]}v_{[k]}^{(t)}\Big\|^2\\
&+\frac{1}{n^2\lambda} \langle X^{\top}Xv^{(t)}, v \rangle+\frac{\sigma}{2n^2\lambda} \sum_{k=1}^{K} \Big\|v_{[k]}-v_{[k]}^{(t)} \Big\|_{X_{[k]}^{\top}X_{[k]}}^2. 
\end{split}
\end{equation*}
The specific algorithm can be expressed as 
\begin{equation*}
\begin{split}
\tilde{v}^{(t)} &=  \underset{v\in \mathbb{R}^n}{\arg\min}\; Q(v|v^{(t)}), \\
v^{(t+1)} &= v^{(t)} + \gamma (\tilde{v}^{(t)}-v^{(t)} ),\\
w^{(t+1)} &= -\frac{1}{n\lambda} \sum_{k=1}^{K} X_{[k]}v_{[k]}^{(t+1)}.
\end{split}    
\end{equation*}
where the $w$-step recovers the primal decision variable, according to the KKT conditions, while the $v$-step aims to decrease $\mathcal D (v)$. The tuning parameter $\sigma$ governs the approximation of the original dual problem and $\gamma$ controlling the adjustment of the dual variable. As it has been shown that $\gamma=1$ and  $\sigma=K$ to give the fastest guaranteed convergence \citet{smith2018cocoa}, % The error of the update in $\tilde{v}^{(t)}$ in the first step can be tolerated. \todo{use the language in the source} 
the CoCoA is simplified to the update rule \eqref{cocoa_pd} that involve iterative primal and dual variables $v$ and $w$, denoted as \textbf{CoCoA-PD} for abbreviation.  
\begin{align}
&v^{(t+1)}_{[k]} =  \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \; \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) - \frac{1}{n} \langle X_{[k]}^{\top}w^{(t)}, v_{[k]}\rangle \nonumber \\
&\quad + \frac{K}{2n^2\lambda} \Big\|v_{[k]}-v_{[k]}^{(t)} \Big\|_{X_{[k]}^{\top}X_{[k]}}^2,  k \in [K] \; \text{(in parallel)},\nonumber \\
&w^{(t+1)}= -\frac{1}{n\lambda} \sum_{k=1}^{K} X_{[k]}v^{(t+1)}_{[k]}. 
\label{cocoa_pd}
\end{align}




\subsection{Global Consensus ADMM with Regularization}

Global consensus ADMM with regularization transforms the problem \eqref{primal} into an equivalent form
\begin{equation}\notag
\underset{w\in\mathbb{R}^d}{\min} \;\frac{1}{n}\sum_{k=1}^{K} \sum_{ i\in \mathcal{P}_k} \ell_i(w_k^{\top}x_i) + g(w) \mbox{ s.t. } w_k=w, k\in [K].  
\end{equation}
and apply the standard ADMM algorithm to solve it in a distributed manner (see Section 7.1.1 of \cite{boyd2011distributed}): 
% we define the augmented Lagrangian function for any $\beta>0$ as 
% $$ \mathcal{L}_{\beta}\left( \left\{w_k\right\}_{k=1}^{K},w;\left\{u_k\right\}_{k=1}^{K}   \right):= \frac{1}{n}\sum_{k=1}^{K} \sum_{ i\in \mathcal{P}_k} \ell_i(w_k^{\top}x_i) + g(w) -\sum_{k=1}^{K} \langle u_k,w_k-w\rangle+\frac{\beta}{2}\sum_{k=1}^{K} \|w_k-w\|^2 .$$
\begin{equation*}
\begin{split}
w_{k}^{(t+1)} = & \underset{w_k \in \mathbb{R}^d}{\arg\min} \; \frac{1}{n} \sum_{i\in\mathcal{P}_k} \ell_i(w_k^{\top}x_i)-\langle u_k^{(t)}, w_k-w^{(t)} \rangle  \\
&+ \frac{\beta}{2} \| w_k-w^{(t)}\|^2,  k\in [K] (\text{in parallel}),\\ \\
u_k^{(t+1)} =& u_k^{(t)} - \beta (w_k^{(t+1)}-w^{(t)}), k\in [K] (\text{in parallel}),\\
w^{(t+1)}  =&  \underset{w \in \mathbb{R}^d}{\arg\min} \; g(w) -\sum_{k=1}^{K} \langle u_k^{(t+1)}, w_k^{(t+1)}-w \rangle \\
& +\sum_{k=1}^{K} \frac{\beta}{2}\| w_k^{(t+1)}-w \|^2.
\end{split}
\end{equation*}  
In the above algorithm, $\beta$ denotes the tuning parameter. %in the consensus ADMM algorithm, while $\rho$ is used for the augmented Lagrangian parameter in the proximal ADMM, as we will explore the correspondence between these two parameters to establish connections between the two algorithms in the next Section. 
This algorithm can be cast into an iterative update rule \textbf{Consensus-PD} of the primal variable \(w\) and the dual variable \(v\), summarized in Proposition \ref{prop:consensus_equiv}. 
\begin{proposition}\label{prop:consensus_equiv}
The global consensus ADMM with regularization for solving the primal problem \eqref{primal} is equivalent to the following update rule:
\begin{align}
&v^{(t+1)}_{[k]} =  \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \; \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) +
 \frac{1}{2n^2\beta} \Big\|v_{[k]}-v_{[k]}^{(t)} \Big\|_{X_{[k]}^{\top}X_{[k]}}^2 \nonumber \\
&\quad   - \frac{1}{n} \Big\langle X_{[k]}^{\top} w^{(t)} , v_{[k]}\Big\rangle, \quad k \in [K] \; \text{(in parallel)},\nonumber\\
&w^{(t+1)} = \mathrm{prox}_{ (\beta K)^{-1} g  } \left(  w^{(t)}-\frac{1}{n\beta K} X\left(2v^{(t+1)}-v^{(t)} \right)\right).
\label{consensus_pd}
\end{align}
\end{proposition}

To leverage the closed-form proximal operators of $\ell_i^*(\cdot)$s in $v$-steps, the linearized ADM approach \cite{lin2011linearized} can be employed, resulting in   \textbf{LinConsensus-PD} update rule: 
\begin{align}
v_{[k]}^{(t+1)} &= \mathrm{prox}_{(n\beta/\tau)\ell^*_{[k]}}\left( v_{[k]}^{(t)} + \frac{n\beta}{\tau}X_{[k]}^{\top}w^{(t)} \right), \nonumber\\
&\quad k \in [K] \; \text{(in parallel)}, \nonumber\\
w^{(t+1)} &= \mathrm{prox}_{ (\beta K)^{-1} g  } \left(  w^{(t)}-\frac{1}{n\beta K} X\left(2v^{(t+1)}-v^{(t)} \right)\right).
\label{lin_consensus_pd}
\end{align}
where \(\tau\) is chosen such that \(\tau I_k \succeq X_{[k]}^{\top}X_{[k]}\) for all \(k \in [K]\). The selection $\tau=\tau^*:=\max \left\{ \lambda_{\max}\left( X_{[1]}^{\top}X_{[1]} \right), \ldots,\lambda_{\max}\left( X_{[K]}^{\top}X_{[K]} \right) \right\}$ thereby achieves nearly optimal convergence speed. 

%A novel advantage of reformulating the consensus ADMM method into \eqref{consensus_pd} is that the dual gap calculated from the primal and dual objective \todo{still need to write the dual objective? Not sure if the v update really the dual variable of original problem of (1)} as a stopping criterion. Furthermore, this representation allows us to analyze the differences and connections among various primal-dual algorithms. 
% \runxiongnote{We can prove this dual varible $v$ could converge to the gloabl dual variable in theory.}

\subsection{Distributed Proximal ADMM}

\citet{deng2016global} introduces an additional proximal term into the standard ADMM algorithm for solving $\min_{x,y} f(x) + g(y)$ subject to $Ax + By = b$ , which is referred to as generalized ADMM or proximal ADMM. % A parallel multi-block ADMM method \cite{deng2017parallel,he2015full,he2016proximal} is proposed for efficiently solving multi-block separable structural problems, which can be regarded as special cases of the proximal ADMM framework. 
\if 0
\begin{align*}
y^{(t+1)} =& \underset{y}{\arg\min} f(x^{(t)}) + g(y) - \langle w, Ax^{(t)} + By - b\rangle \\
&+ \rho \norm{Ax^{(t)}+By-b}_2^2 + 1/2 \norm {y-y^{(t)}}_Q\\
x^{(t+1)} =& \underset{y}{\arg\min} f(x) + g(y^{(t+1)}) - \langle w, Ax + By^{(t+1)} - b\rangle  \\
&+ \rho \norm{Ax+By^{(t+1)}-b}_2^2 + 1/2 \norm {x-x^{(t)}}_P\\
w^{(t+1)} =& w^{(t)} - \gamma \rho \left( Ax^{(t+1)} + By^{(t+1)} - b\right).
\end{align*}
\fi 
Applying Algorithm 2 of \citet{deng2016global}, we can solve the dual problem \eqref{dual} with following update rule: 
\begin{equation*}
\begin{split}
v^{(t+1)}  &=  \underset{v\in\RR^n}{\arg\min}\; \frac{1}{n}\sum_{k=1}^{K} \sum_{ i\in \mathcal{P}_k} \ell^*_i(v_i)-\langle w^{(t)}, \frac{1}{n}Xv+u^{(t)}\rangle \\
&+ \frac{\rho}{2} \Big\|\frac{1}{n} Xv+u^{(t)} \Big\|^2+ \frac{1}{2} \|v - v^{(t)}\|_{Q}^2,\\
u^{(t+1)}&= \underset{u\in\RR^d}{\arg\min }\; g^*(u)-\langle w^{(t)}, \frac{1}{n}Xv^{(t+1)}+u\rangle \\
&+ \frac{\rho}{2} \Big\| \frac{1}{n}Xv^{(t+1)}+u \Big\|^2,\\
w^{(t+1)} &= w^{(t)}-\rho \left( \frac{1}{n}Xv^{(t+1)}+u^{(t+1)} \right),
\end{split}
\end{equation*}
where $\rho>0$ is the tuning parameter and $Q$ is a positive semi-definite matrix. 

Motivated by the \citet{deng2017parallel} that solves distributed optimization problems without the regularization term, we identified two choices of the positive semi-definite matrices $Q$s based on the data matrix $X_{[k]}$s to solve \eqref{dual}, which enables parallel updates of \( v  \) across $K$ machines: 
\[Q_1 = \frac{\rho}{n^2} ( \eta_1 \, \text{diag}( X_{[1]}^{\top} X_{[1]}, \ldots, X_{[K]}^{\top} X_{[K]} ) - X^{\top} X );\]
\[Q_2 = \frac{\rho}{n^2} \left( \eta_2 I - X^{\top} X \right) \]
Here \(\eta_1\) and \(\eta_2\) are chosen to ensure that $Q_1$ and $Q_2$ are positive semi-definite. The resulted distributed proximal ADMM algorithms can both be cast into a compact update form that involves only $w$-steps and $v$-steps. 

\begin{proposition}\label{prop:proximal_equiv}
The updating formula \eqref{Q1_pd} and \eqref{Q2_pd} below respectively result in the same iterative sequence of $\{v^{(t)}\}$ and $\{w^{(t)}\}$ as the distributed proximal ADMM algorithm with choices of matrices $Q_1$ and $Q_2$. 
\begin{align}
v^{(t+1)}_{[k]} =& \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} &&\nonumber\\
&\frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) + \frac{\rho \eta_1}{2n^2} \Big\|v_{[k]}-v_{[k]}^{(t)} \Big\|_{X_{[k]}^{\top}X_{[k]}}^2 &&\nonumber\\
 &-\frac{1}{n} \Big\langle X_{[k]}^{\top}\left( 2w^{(t)} - w^{(t-1)} \right), v_{[k]} \Big\rangle,
 k \in [K], &&\nonumber\\
   w^{(t+1)} =& \mathrm{prox}_{\rho g} \left(  w^{(t)} - \frac{\rho}{n} Xv^{(t+1)} \right);&&
    \label{Q1_pd}
\end{align}
\begin{flalign}
v_{[k]}^{(t+1)} = && \nonumber 
\end{flalign}
\begin{multline*}
\mathrm{prox}_{(n/\rho\eta_2)\ell^*_{[k]}}\left( v_{[k]}^{(t)} + \frac{n}{\rho\eta_2}X_{[k]}^{\top}\left(2w^{(t)}-w^{(t-1)}\right) \right), \\
 k \in [K],     
\end{multline*}
\begin{flalign}
 w^{(t+1)} = \mathrm{prox}_{\rho g} \left(  w^{(t)} - \frac{\rho}{n} Xv^{(t+1)} \right).&&
\label{Q2_pd}
\end{flalign}
\end{proposition}

The update rule of \eqref{Q1_pd} and \eqref{Q2_pd} are named \textbf{Proximal-1-PD} and \textbf{Proximal-2-PD}, respectively. The distributed proximal ADMM algorithms of either $Q$ are guaranteed to converge for any \(\rho > 0\). The following lemma provides a reliable choice for selecting the tuning parameters \(\eta_1\) and \(\eta_2\) that ensures $Q_1$ and $Q_2$ to be positive semidefinite, satisfying the requirement of \citet{deng2016global}.  

\begin{lemma}\label{lemma1}
For any data matrix $X$, 
\[
K \, \mathrm{diag}\left( X_{[1]}^{\top}X_{[1]}, \ldots, X_{[K]}^{\top}X_{[K]} \right) \succeq X^{\top}X, 
\]
% Based on this relationship, we propose a reliable and nearly optimal choice for the hyper-parameters \(\eta_1\) and \(\eta_2\):
and thus when $\eta_1 = \eta_1^* := K, \eta_2 = \eta_2^* := K \tau^*$, 
\( Q_1\) and $Q_2$ are positive semi-definite.  
\end{lemma}

The minimal \(\eta_2\) to let $Q_2\succeq 0$ is $\lambda_{\max}\left( X^{\top}X \right)$.  However, this choice is practically infeasible in a federated learning setup, as it requires the aggregation of samples from all machines. 
% It is worth mentioning that although similar techniques are used in \cite{deng2017parallel} towards distributed optimization, their approach cannot be directly applied to solve our problem given the regularization term $g(w)$ in our objective.  



\subsection{Summary}
The five algorithms CoCoA-PD, Consensus-PD, LinConsensus-PD, Proximal-1-PD, and Proximal-2-PD \eqref{cocoa_pd}--\eqref{Q2_pd} have a unified form of iterative primal and dual updates, which enables us to investigate the connection between algorithms and apply a unified analysis of convergence for these algorithms in Section~\ref{sec:theory}. The updates of $v_{[k]}$ in all algorithms involve applying $\mathrm{prox}_{ \ell_{[k]}^*}(\cdot)$ on a linear combination of $w^{(t)}$ and $v_{[k]}^{(t)}$. All updates of $w$ involve a linear combination of current $w^{(t)}$, the information transmitted from individual machines for the current time step $X_{[k]}v_{[k]}^{(t+1)}$, and the information from the previous time step $X_{[k]}v_{[k]}^{(t)}$. 

An immediate benefit of using these unified primal-dual update formula, instead of their original algorithms, is that they enable a quick evaluation of the dual gaps that bound the error in objectives. Such dual gaps are computed from plugging in the updated values of $\{v_{[k]}^{(t)}\}_{k=1}^K, w^{(t)}$ into the primal objective \eqref{primal} and dual objective \eqref{dual} respectively.   


\paragraph{Effects of Tuning Parameters.} We summarize the selection of tuning parameters in the five algorithms mentioned above. 
With fixed optimal parameter $\sigma=K$ and $\gamma=1$ in CoCoA algorithm \cite{smith2018cocoa}, CoCoA-PD does not have tuning parameters. 
The optimal selection of parameters $\eta_1,\eta_2$ in Proximal-1-PD, Proximal-2-PD, and $\tau$ in LinConsensus-PD are given in this article and confirmed by the experiments. The step sizes $\beta$ of Consensus-PD and LinConsensus-PD, and the step size $\rho$ of the Proximal-1-PD and Proximal-2-PD significantly affect the convergence speed \cite{boyd2011distributed} and should be tuned in a case-specific manner, as validated  in our experiments (See Section~\ref{sec:exp1}). 


\section{Connections Between the Primal-Dual Algorithms}\label{sec:connection}

We now present the relationship between the algorithms from their update forms, which is described in Figure~\ref{fig:connection}. 

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{pictures/connection.png}
    \caption{The relationship between update rules. }
    \label{fig:connection}
\end{figure}


\paragraph{CoCoA-PD and Proximal-1-PD.} Through the updating formula, we identified an interesting connection between CoCoA-PD and Proximal-1-PD when \( g(w) = \frac{\lambda}{2}\|w\|^2\): the following corollary shows when the tuning parameters satisfies $\rho=\lambda^{-1}, \eta_1=\sigma$, and when the CoCoA-PD selects the recommended parameter $\gamma = 1$, Proximal-1-PD and the CoCoA-PD will have identical values of dual variable updates. The result is obtained by noting that plugging the update of the primal variable $w$ into the update formula of the dual variable $v_{[k]}$ will result in the same update formula for $v_{[k]}$. 
 
\begin{corollary}\label{corollary1}
 Assume that $g(w) = \lambda\norm{w}_2^2$,  $\rho = \lambda^{-1}$, $\gamma = 1$ and $\eta_1=\sigma$. The update procedure of \eqref{cocoa_pd} and \eqref{Q1_pd} will give identical updates for the dual variable $v_{[k]}^{(t)}, k\in [K]$, given that both algorithm starts at the same $v_{[k]}^{(1)}, k\in [K]$. 
\end{corollary}

It is worth noting that the $w$-steps of CoCoA-PD and that of Proximal-1-PD with $g=\lambda \norm{w}_2^2/2 $ are different. The $w$-update for Proximal-1-PD can be represented by   
\[
w^{(t+1)} =  \frac 1 2 (w^{(t)} + \tilde w^{(t+1)}), 
\]
where $\{\tilde w (t)\}$ is the $w$-updates of CoCoA-PD. It indicates that the $w$-update of Proximal-1-PD is an exponentially weighted average of the $w$-updates of CoCoA-PD. 

It is also interesting to see if the connection between CoCoA-PD and Prixmal-1-PD can be extended to other CoCoA variants with general penalty $g$ \cite{smith2018cocoa}. To this question, we give a negative answer, because the connection in Corollary \ref{corollary1} relies on the same quadratic structure of the ridge penalty in CoCoA and the augmented Lagrangian in the Proximal ADMM algorithm.  

The important insight from the comparison between CoCoA-PD and Proximal-1-PD is that the CoCoA-PD with the optimal selection of $\gamma$ and $\sigma$ has the same convergence rate as Proximal-1-PD, if a specific step size $\rho=\lambda\inv$ is selected. However, such selection may not necessarily be the optimal one that ensures fastest convergence of Proximal-1-PD. By tuning $\rho$ of Proximal-1-PD on a case-specific basis, Proximal-1-PD is able to achieve a higher convergence rate than the CoCoA-PD, as validated in our experiments. 

\paragraph{Proximal ADMM and Consensus ADMM.} 

To understand the relationship between distributed Proximal ADMM and Consensus ADMM with regularization, we express the primal problem \eqref{primal} into the saddle point problem:
\begin{equation}\label{saddlepoint}
\begin{split}
\underset{w \in \mathbb{R}^d}{\min} \; \underset{v \in \mathbb{R}^n}{\max} \; L(w; v),
\end{split}
\end{equation}
where $L(w; v) := \frac{1}{n} \sum_{i=1}^{n} \left( v_i \langle w, x_i \rangle - \ell_i^*(v_i) \right) + g(w)$, given that $\ell_i(w^{\top}x_i) = \underset{v_i \in \mathbb{R}}{\sup} \left\{ v_i \langle w, x_i \rangle - \ell_i^*(v_i) \right\}$. 
The following lemma shows that all algorithms \eqref{consensus_pd}--\eqref{Q2_pd} can be represented by a \textit{\textbf{generic update rules}} with
\begin{equation}\label{genericrule}
   P(z^{(t)}-z^{(t+1)}) \in \mathcal{F}(z^{(t+1)}),    
\end{equation} 
where $z=(w,v)$ denotes the primal and dual updates, $\mathcal{F}(z)=\mathcal{F}(w,v)=\begin{pmatrix}
\partial_{w} L(w;v) \\
-\partial_{v} L(w;v)
\end{pmatrix}$, and  $P\in\RR^{ (n+p)\times (n+p) }$ is a positive semi-definite matrix. 

\begin{proposition}\label{prop:genericupdaterule}
The generic update rules \eqref{genericrule} with $P$ selected as the matrices $P_1$, $P_2$, $P_3$ and $P_4$ are the same as the update rule \eqref{consensus_pd}, \eqref{lin_consensus_pd}, \eqref{Q1_pd} and \eqref{Q2_pd}, corresponding to Consensus-PD, LinConsensus-PD, Proximal-1-PD, and Proximal-2-PD, respectively:

$
P_1 =
\begin{pmatrix}
\beta K I & \frac 1 n A \\
\frac 1 n A\T & \frac{\beta\inv} {n^2} B
\end{pmatrix}, 
P_2 =
\begin{pmatrix}
\beta K I & \frac 1 n A \\
\frac 1 n A\T & \frac {\tau\beta\inv}{n^2} I
\end{pmatrix}$ 

$P_3 =
\begin{pmatrix}
\rho^{-1} I & -\frac 1 n  A \\
-\frac 1 n A\T & \frac{\rho\eta_1}{n^2} B
\end{pmatrix},  
P_4 =
\begin{pmatrix}
\rho^{-1} I & -\frac 1 n A \\
-\frac 1 n A\T & \frac{\rho\eta_2}{n^2} I
\end{pmatrix}, $
where $A = X, B= \mathrm{diag}\left(X_{[1]}^{\top}X_{[1]}, \ldots, X_{[K]}^{\top}X_{[K]}\right)$. 
\end{proposition}
The generic update formula reveal structural similarity between Consensus-PD and Proximal-1-PD, and between LinConsensus-PD and Proximal-2-PD. When parameters $\eta_1,\eta_2, \tau $ are selected to ensure fastest convergence rate, i.e., $\eta_1 = K$, $\tau = \max_{k\in[K]} \lambda_{\max}(X_{[k]}\T X_{[k]})$, and $\eta_2=K\tau$, adjusting the step size of Consensus-type algorithms and Proximal-type algorithms such that $\beta K = \rho\inv$ will lead to the following compact forms of $P_3$ and $P_4$: 

{\centering
 $P_3 = \begin{pmatrix}
\beta K I & -\frac 1 n A \\
-\frac 1 n A & \frac{\beta\inv}{n^2} B
\end{pmatrix}\qquad
P_4 = \begin{pmatrix}
\beta K I & -\frac 1 n A \\
-\frac 1 n A & \frac{\tau\beta\inv}{n^2} I
\end{pmatrix}
$.     
} \\
It indicates $P_3$ and $P_1$ are the same, but the off-diagonal blocks flip the sign.  $P_2$ and $P_4$  are the same, but the off-diagonal blocks flip the sign. However, how such connection relates to the convergence properties of each pair of algorithms remains unclear, and we will leave it for future study. 

% Specifically, the distributed proximal ADMM with $Q_1$  is derived by introducing an additional proximal term to the standard two-block ADMM algorithm, we find that it can be interpreted as the dual counterpart of the consensus ADMM algorithm under specific parameter configurations. By some simple algebra operations, we can obtain this observation stated in the following corollary.

%\begin{corollary}\label{corollary2}
% Under the augmented Lagrangian parameter setting \(\rho = \frac{1}{\beta K}\), the proximal ADMM with the first matrix choice and \(\eta_1 = K\) can be interpreted as the dual counterpart of the original consensus ADMM. Similarly, with the same augmented Lagrangian parameter relationship, the proximal ADMM with the second matrix choice and \(\eta_2 = \tau K\) can be regarded as the dual counterpart of the linearized consensus ADMM.
% \end{corollary}

% Given the connections between proximal ADMM and consensus ADMM, the proximal ADMM with the first matrix choice is often referred to as the dual consensus ADMM, while the proximal ADMM with the second matrix choice is called the dual linearized ADMM. Similarly, the consensus ADMM with the linearization scheme is referred to as the primal linearized ADMM (primal LADMM).\todo{is it your original research, or is it from any existing paper? This paragraph only has statements, no reasoning. Pending deletion. }



\section{A Unified Proof of Convergence}\label{sec:theory}
 Representing the four ADMM-based  primal-dual update forms \eqref{consensus_pd}--\eqref{Q2_pd} into the generic update rules also provides a unified and straightforward approach of their convergence analysis. Using the convergence analysis framework of \citet{he20121,lu2023unified}, we establish an $O(1/T)$ ergodic rates of these algorithms. Theorem~\ref{Thm1} characterizes the $O(1/T)$ ergodic convergence rate under exact updates.
\begin{theorem}\label{Thm1}
Let \(\left\{ z^{(t)} = (w^{(t)}, v^{(t)}) \right\}_{t=0}^{\infty}\) be the sequence  generated by the generic update rule \eqref{genericrule} with a positive semi-definite matrix \(P\) and  the initial point \(z^{(0)} = (w^{(0)}, v^{(0)})\). For any \(z = (w, v)\), the following inequality holds:
\[
L(\bar{w}^{(T)}; v) - L(w; \bar{v}^{(T)}) \leq \frac{\|z - z^{(0)}\|^2_{P}}{2T},
\]
where \(\bar{z}^{(T)} = (\bar{w}^{(T)}, \bar{v}^{(T)}) = \frac{1}{T} \sum_{t=1}^{T} z^{(t)}\). 
\end{theorem}

By selecting $z = (w^*, v^*)$, the optimal solutions to \eqref{primal} and \eqref{dual}, Theorem~\ref{Thm1} indates that $L(\bar{w}^{(T)}; v^*) - L(w^*; \bar{v}^{(T)})$ converges to zero, which implies that $\bar z^{(T)}$ converges to the optimal solution with rate $O(1/T)$.

Theorem~\ref{Thm1} guarantees that all starting points $z^{(0)}\in B_P(z^*,M)=\{z:\norm{z-z^*}_P<M\}$ converges with rate $M/2T$. The volume of $B_P(z^*,1)$ is thereby an indicator for the overall convergence rate associated with a generic update rule with $P$, which proportional to $(\det P)\inv$. Clearly, $\det P_1 = \det P_3$ and $\det P_2 = \det P_4$, so the overall size of the bound provided by Theorem~\ref{Thm1} are the same for Consensus-PD and Proximal-1-PD, and the same for LinConsensus-PD and Proximal-2-PD. Similar convergence behavior for both pairs of update rules are further validated in our experiment studies. 

All $v$-steps of the updates \eqref{consensus_pd}--\eqref{Q2_pd} solve a  minimization problem which would rely on an inner loop, in case no closed-form solution is available. We present a unified proof of convergence for \eqref{consensus_pd}--\eqref{Q2_pd} which addresses the inexact updates, based on the technique of \citet{lu2023unified}. 

\begin{theorem}\label{Thm2} 
Let \(P\) be positive definite, and \(z^* = (w^*, v^*)\) be the optimal solution of the saddle point problem \eqref{saddlepoint}. 
If the sequence $\{z^{(t)}\}$ satisfies 
\begin{equation} \label{eqn5.2}
 P(z^{(t)} - z^{(t+1)}) + \epsilon^{(t+1)} \in \mathcal{F}(z^{(t+1)})
\end{equation}
with 
\(
\sum_{t=1}^{\infty} \|\epsilon^{(t)}\|_2 < \infty, 
\)
then there exists a constant \(D < \infty\) such that
\[
\sup_t \|z^* - z^{(t)}\| \leq D
\]
and 
\begin{multline*}
L(\bar{w}^{(T)}; v^*) - L(w^*; \bar{v}^{(T)}) \leq \\
\frac{\|z^* - z^{(0)}\|_P^2}{2T} + \frac{D \sum_{t=1}^{T} \|\epsilon^{(t)}\|_2}{T}. 
\end{multline*}
\end{theorem}

In this theorem, $\{z^{(t)}\}$ is the sequence generated by the inexact algorithm subject to inner-loop computational errors,  \(\epsilon^{(t)}\) represents the computational error incurred due to the inexact update of iteration \(t\). Under the assumption that the total error over all iterations is  bounded, an $O(1/T)$ convergence rate can be achieved.  


\section{Experiment}\label{sec:simulation}
In this section, we perform three experiments to test the performance of the primal-dual update rules under different parameter settings. The individual goals of the three experiments are as follows: 
\begin{itemize}
    \item In experiment 1, we study how the the tuning parameters affect each algorithm, to verify our suggestions on tuning parameter selection.  
    \item In, experiment 2, we evaluate the performance of the five update rules using synthetic data for Lasso and Ridge regression tasks. 
    \item In experiment 3, we continue to evaluate the performance of the  five update rules  on three real-world binary classification tasks employing SVM. 
\end{itemize}

\textbf{Performance Metric.} The relative gap difference is used to evaluate the performance of the algorithms in all experiments. It is defined as  
\[
\epsilon_{G} := \frac{|\mathcal{P}(w) +\mathcal{D}(v)|}{1 + |\mathcal{P}(w)| + |\mathcal{D}(v)|},
\]
where $\mathcal{P}(w)$ and $\mathcal{D}(v)$ are calculated from \eqref{primal} and \eqref{dual} based on the $v$-step and $w$-step updates of each iteration $t$. Note that  under our definition of the dual problem \eqref{dual} the numerator gives the dual gap. The algorithm for which $\epsilon_G\to 0$ at a higher rate performs better. 


\subsection{Experiment 1}\label{sec:exp1}

Experiment 1 aims to verify the effect of $\eta_1,\eta_2$, $\tau$ for the Proximal-1-PD, Proximal-2-PD, and LinConsensus-PD update rules, and compare them with the effect of the step sizes $\rho$ and $\beta$. 

\textbf{Datasets.} We used \texttt{a1a} dataset in the LibSVM library\cite{chang2011libsvm}: \texttt{a1a}, \texttt{w8a}, and \texttt{real-sim}. Details of this dataset, including the number of samples, features, and clients, is included in Table~\ref{tab1}. In the problem, we evenly distribute the data to $K = 10$ machines. 

\textbf{Method.} We train the model using $\ell_2$-regularized SVM model with regularization parameter of $\lambda = 1/n$. We tested the performance of three algorithms, where Proximal-1-PD is subject to the tuning parameters $\eta_1$ and $\rho$, Proximal-2-PD is subject to the tuning parameters $\eta_2$ and $\rho$, and LinConsensus-PD is subject to $\tau$ and $\beta$. In the experiments, we test each method through fixing one tuning parameter and setting multiple values for the other tuning parameter. We record the trajectory of the relative gap difference in 500 communication rounds.   

\textbf{Results.} The trajectory of the gap are shown in Figure~\ref{fig11}. The first column demonstrated the validity of the selection of $\eta_1,\eta_2$ and $\tau$ for the three methods. The recommended values, denoted by light blue lines, ensure the convergence of the algorithm. When these values become smaller, the convergence speed increases only slightly (e.g., the green and purple line). When these values become too small, however, the algorithms may fail to converge. Second, we can see from the three figures in second column that the ADMM step size parameter $\rho$ and $\beta$ has significantly impacts the algorithms' performance. 

\begin{figure}[ht]
\centering
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/pADMM1_eta.png} 
\caption{Proximal-1-PD, fixed $\rho$}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/pADMM1_rho.png} 
\caption{Proximal-1-PD, fixed $\eta_1$}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/pADMM2_eta.png} 
\caption{Proximal-2-PD, fixed $\rho$}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/pADMM2_rho.png} 
\caption{Proximal-2-PD, fixed $\eta_2$}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/LADMM_tau.png} 
\caption{LinConsensus-PD, fixed $\beta$}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Effect_of_parameters/LADMM_beta.png} 
\caption{LinConsensus-PD, fixed $\tau$}
\end{subfigure}
\caption{Effect of tuning parameters on various distributed algorithms in Experiment 1. } 
\label{fig11}
\end{figure}




\subsection{Experiment 2}

In this experiments, we test five the update rules on Ridge Regression problem and LASSO problem, where each $\ell_i = \frac{1}{2}(y_i - x_i^{\top}w)^2$, using synthetic data. 

\textbf{Dataset.} We generate $n=3000$ training examples $\{x_i, y_i\}_{i=1}^{n}$ according to the model
\begin{equation*}
y_i = \langle x_i, w^* \rangle + \epsilon_i, \quad \epsilon_i \sim \mathcal{N}(0,1),    
\end{equation*}
where $x_i \in \mathbb{R}^d$ with $d = 500$. The samples are distributed uniformly on $K=30$ machines. We set $w^*$ as the vector of all ones, whereas for the $\ell_1$ penalty, we let the first 100 elements of $w^*$ be ones and the rest be zeros. 

For the generation of $x_i$'s, we designed two cases: IID data and non-IID data. (1) Under the IID setting, we generate each $x_i \sim \mathcal{N}(0,\Sigma)$ where the covariance matrix $\Sigma$ is diagonal with $\Sigma_{j,j}=j^{-2}$. This covariance setting renders an ill-conditioned dataset, making it a challenging situation of solving distributed and large-scale optimization problem. (2) To generate the non-IID case, we follow a setup similar to the one in \cite{zhou2023federated}. Specifically, we generate $[n/3]$ samples $x_i$ from the standard normal distribution, $[n/3]$ samples from the Student's $t$-distribution with 5 degrees of freedom, and the rest samples are from the uniform distribution on $[-5, 5]$. 
After generating all the samples, we shuffle them and randomly distribute them across $K$ machines. 

\textbf {Method.} We run the five update rules to solve the Ridge Regression problem on IID and non-IID dataset, and run the four ADMM algorithms to solve the LASSO problem. In these update rules, we  select the suggested value of $\gamma, \sigma, \eta_1, \eta_2,$ and $\tau$, and select the optimal  $\beta$ or $\rho$ to achieve optimal performance. Notably, it has been observed that the optimal $\beta$ and $\rho$ in Consensus-PD and Proximal-1-PD satisfies $\beta K =\rho\inv$, and so are the optimal $\beta$ and $\rho$ in LinConsensus-PD and Proximal-2-PD, indicating their connection. 

%results
\textbf {Results.} We present the simulation results in Figure \ref{fig1}. We observe that the performance of Consensus-PD and Proximal-1-PD are almost identical, while the performance of LinConsensus-PD and Proximal-2-PD are almost identical. These simulation results further confirm the strong connection between these two pairs. All four ADMM variants, with the optimized tuning parameters, significantly outperform the CoCoA framework. This is because of CoCoA is the Proximal-1-PD with a specific step size $\rho =\lambda\inv$. The figure also shows that Consensus-PD and Proximal-1-PD achieve smaller relative gap difference compared with LinConsensus-PD and Proximal-2-PD in the same amount of rounds, though the computation for the latter two variants are significantly simpler. 

\begin{figure}[ht]
\centering
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Ridge_with_IID/ridge_with_iid.png} 
\caption{Ridge with IID}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Ridge_with_Non-IID/ridge_with_non_iid.png} 
 \caption{Ridge with Non-IID}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Lasso_with_IID/lasso_with_iid.png} 
 \caption{Lasso with IID}
\end{subfigure}
\begin{subfigure}[t]{0.49\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Lasso_with_Non-IID/lasso_with_non_iid.png} 
\caption{Lasso with Non-IID}
\end{subfigure}
\caption{Relative gap difference versus the number of communication rounds for various synthetic datasets when using different update rules in Experiment 2.}
\label{fig1}
\end{figure}

\subsection{Binary Classification with Real Data}
Finally, we test the performance of the five update rules on regularized SVM classification problem using real datasets.  

\paragraph{Datasets.} The real datasets from the LibSVM library \cite{chang2011libsvm} used in the study are \texttt{a1a}, \texttt{w8a}, and \texttt{real-sim}. Details of each dataset, including the number of samples and features are summarized in Table \ref{tab1}. In our experiments, all samples in each dataset are evenly distributed on the machines. We select different numbers of machines for each dataset to evaluate the performance of the proposed approach, where the number of machines is also given in Table~\ref{tab1}. 

\paragraph{Method.} We use the update rules to solve two regularized SVM classification problems: 
\begin{equation}\notag
\underset{w \in \mathbb{R}^d}{\min}\, \frac{1}{n} \sum_{k=1}^{K} \sum_{i \in \mathcal{P}_k} \max\left(0, 1-y_i w^{\top}x_i \right) + g(w),
\end{equation}
where the penalty function $g(w)$ are selected as either (1) $\ell_1$ penalty $\lambda\|w\|_1$ and (2) the $\ell_2$ penalty $\frac{\lambda}{2}\|w\|^2$. We use three real datasets in LibSVM package for each problem. 
We choose the regularization parameter $\lambda=\frac{1}{n}$  in all experiments conducted in this subsection. Like Experiment 2, we select the optimal parameters for $\beta$ and $\rho$ and prescribe the values for all other tuning parameters. 

\paragraph{Results.} The results are shown in Figure \ref{fig2}. They again validated that the performance of Consensus-PD and Proximal-1-PD are almost overlapping, and LinConsensus-PD and Proximal-2-PD are almost overlapping. All ADMM variants consistently outperform the CoCoA method across all experiments.  Finally, Consensus-PD and Proximal-1-PD achieve the better performance compared with LinConsensus-PD and Proximal-2-PD. 
These results confirms with the study in Experiment 2. However, in the SVM with lasso penalty scenarios, LinConsensus-PD and Proximal-2-PD exhibit slightly less stability compared to Consensus-PD and Proximal-1-PD.

\begin{figure}[ht]
\centering
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/a1a_l2_gap.png} 
\caption{Data: \texttt{a1a}, SVM+Ridge}
\end{subfigure}
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/a1a_l1_gap.png} 
\caption{Data: \texttt{a1a}, SVM+$\ell_1$}
\end{subfigure}
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/w8a_l2_gap.png} 
 \caption{\texttt{w8a}, SVM+Ridge}
\end{subfigure}
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/w8a_l1_gap.png} 
 \caption{\texttt{w8a}, SVM+$\ell_1$}
\end{subfigure}
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/real-sim_l2_gap.png} 
 \caption{\texttt{real-sim}, SVM+Ridge}
\end{subfigure}
\begin{subfigure}{0.48\columnwidth}
  \centering
\includegraphics[width=\linewidth]{pictures/Real_data_analysis/real-sim_l1_gap.png} 
 \caption{\texttt{real-sim}, SVM+$\ell_1$}
\end{subfigure}
\caption{Relative gap differences versus the number of communication rounds for various real datasets across different models. The first row of plots illustrates the results for SVM with a lasso penalty across different datasets, while the second row shows the results for SVM with a ridge penalty across the same datasets.} 
\label{fig2}
\end{figure}

\begin{table}[!ht]
\caption{Description of the datasets.}
\label{tab1}
\centering
\begin{tabular}{lccc}
\toprule
\text{Dataset} & \textbf{$n$} & \textbf{$d$} & \textbf{$K$} \\
\midrule
\texttt{a1a} &  1605       & 119        & 10   \\
\texttt{w8a}          &     49749   & 300  & 60     \\
\texttt{real-sim}   & 72309    & 20958 & 100       \\
\bottomrule
\end{tabular}
\end{table}


\section{Conclusion}\label{sec:conclusion}
In this article, we unified distributed primal-dual algorithms, including CoCoA,  two proximal ADMM algorithms, consensus ADMM, and linearized ADMM into updates rule that only involve the primal and dual variable updates. Among them, the two proximal ADMM algorithms are new, obtained from choosing two positive definite matrices to enable the proximal ADMM algorithm to solve distributed, regularized federated learning problem. The unified update rules reveal that the CoCoA algorithm can be interpreted as a special case of proximal ADMM with a specific tuning parameter, and proximal ADMM and consensus ADMM are strongly related and have similar convergence property. This framework enables the use of the gap between the primal and dual objectives as a stopping criterion for the consensus ADMM algorithm. The framework also enables us to use a simple and unified ergodic convergence analysis for ADMM variants. By thoroughly investigating the influence of tuning parameters on convergence speed, we found that all ADMM variants consistently outperform the CoCoA-PD with properly selected tuning parameters, as validated by the experiments with synthetic and real-world datasets. 

One missing stone in the connection between the algorithms we investigated is an accurate characterization of the connection between Consensus-PD and Proximal-1-PD, and between LinConsensus-PD and Proximal-2-PD, as both experiments and transformation have indicated strong associations between both pairs. Another interesting task is to investigate and include other primal dual algorithms into this category, identify their relationships and and describe their common characteristics. We will leave them for future studies. 

% Future work will focus on developing acceleration schemes for these distributed primal-dual algorithms and extending the current framework to fully decentralized topologies and federated learning settings.




% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% usually should) include acknowledgements.  Such acknowledgements
% should be placed at the end of the section, in an unnumbered section
% that does not count towards the paper page limit. Typically, this will 
% include thanks to reviewers who gave useful comments, to colleagues 
% who contributed to the ideas, and to funding agencies and corporate 
% sponsors that provided financial support.

\pagebreak

% \section*{Impact Statement}
% This paper presents work whose goal is to advance the field
% of Machine Learning. There are many potential societal
% consequences of our work, none which we feel must be
% specifically highlighted here.


% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

% ``This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.''

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}


\bibliography{reference}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Derivation of the Dual Problem}
\label{sec:dualproof}
\begin{proof}
Let $w^{\top}x_i=u_i$ for any $i=1,\ldots,n$, we can equivalently transform the original problem \eqref{primal} as the following form:
\begin{equation}\label{eqnA.1}
\underset{w\in\RR^d,u\in\RR^n}{\min}\;  \frac{1}{n} \sum_{i=1}^{n} \ell_i(u_i)+g(w)  \quad \mbox{ s.t. } w^{\top}x_i=u_i, \quad i=1,\ldots,n.
\end{equation}
By introducing the Lagrangian multiplier $v=[v_1,\ldots,v_n]^{\top}$, we can write the Lagrangian function as
$$ L(w,u;v):= \frac{1}{n} \sum_{i=1}^{n} \ell_i(u_i)+g(w)+\frac{1}{n} \sum_{i=1}^{n}v_i(w^{\top}x_i-u_i).$$
Note that we incorporate the fraction constant $\frac{1}{n}$ into the Lagrange multiplier to ensure alignment with the loss function when minimizing the Lagrangian function for the primal variables. Thus, the dual problem could be obtained by taking the infimum to both $w$ and $u$:
 \begin{eqnarray*}
 \underset{w,u}{\inf}\; L(w,u;v) &=& \underset{u}{\inf} \left\{ \frac{1}{n}\sum_{i=1}^{n} \left(\ell_i(u_i)-v_iu_i \right) \right\}+ \underset{w}{\inf} \left\{  g(w)+\langle w, \frac{1}{n}\sum_{i=1}^{n}v_ix_i \rangle    \right\}\\
 &=& -\frac{1}{n}\sum_{i=1}^{n} \ell^*_i(v_i)-g^*\left(-\frac{1}{n}\sum_{i=1}^{n}v_ix_i\right).
\end{eqnarray*}
After changing the sign to make the maximization of the dual problem into the minimization, we have the following dual formulation:
\begin{equation}\notag
\underset{v\in\mathbb{R}^n}{\min} \left\{ 
\mathcal{D}(v):=\frac{1}{n}\sum_{i=1}^{n} \ell^*_i(v_i)+g^*\left(-\frac{1}{n}\sum_{i=1}^{n}v_ix_i\right) 
\right\}.
\end{equation}
For the distributed problem form \eqref{dual}, the corresponding distributed dual problem form is thus 
\begin{equation}\notag
\underset{v\in\mathbb{R}^n}{\min} \left\{ 
\mathcal{D}(v):=\frac{1}{n}\sum_{k=1}^{K} \sum_{i\in \mathcal{P}_k}\ell^*_i(v_i)+g^*\left(-\frac{1}{n}\sum_{k=1}^{K} \sum_{i\in \mathcal{P}_k}v_ix_i\right) 
\right\}.
\end{equation}
% Furthermore, the KKT conditions are listed as follows:
% \begin{equation}\notag
% \left\{
% \begin{aligned}
% &x_i^{\top}w^*=u_i^*,  \quad i=1,\ldots,n, \\
% &v_i^* \in \partial \ell_i(u_i^*), \quad i=1,\ldots,n, \\
% &-\frac{1}{n} \sum_{i=1}^{n} v_i^*x_i\in \partial g(w^*).
% \end{aligned}
% \right.
% \end{equation}
% After simplification, we have 
% \begin{equation}\notag
% \left\{
% \begin{aligned}
%  x_i^{\top}w^* &=\text{Prox}_{\ell_i}\left( x^{\top}_iw^*+v_i^*  \right), \, \quad \mbox{ for any } i=1,\ldots,n,\\
%  w^*&=\text{Prox}_{g}\left( w^*-\frac{1}{n}\sum_{i=1}^{n}v_i^*x_i \right).
%  \end{aligned}
% \right.
% \end{equation}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proofs for the Results in Section \ref{algorithm description}}
\if 0
\subsection{Proof of Proposition \ref{pro1}}
\begin{proof}
When \(\gamma = 1\) and  \(\sigma = K\), the CoCoA method updates as follows:
\begin{eqnarray*}
v^{(t+1)} &\approx& \underset{v \in \mathbb{R}^{n}}{\arg\min}\; 
 Q(v|v^{(t)}), \\
          &\approx& \underset{v \in \mathbb{R}^{n}}{\arg\min} \; \frac{1}{n} \sum_{k=1}^{K}\sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) +\frac{K}{2n^2\lambda}\sum_{k=1}^{K} \left( v_{[k]} - v_{[k]}^{(t)} \right)^{\top} X_{[k]}^{\top} X_{[k]} \left( v_{[k]} - v_{[k]}^{(t)} \right) \\
          &      & \quad + \frac{1}{n^2\lambda} \sum_{k=1}^{K} \langle X_{[k]}^{\top}Xv^{(t)}, v_{[k]}-v_{[k]}^{(t)}  \rangle, \\
w^{(t+1)} &=& -\frac{1}{n\lambda} \sum_{k=1}^{K} X_{[k]}v^{(t+1)}_{[k]}.
\end{eqnarray*} 
From the updated formula for the primal variable \(w\), we observe that 
\(w^{(t)} = -\frac{1}{n\lambda}Xv^{(t)}\) for any time step \(t\). We obtain the corresponding update formula by substituting this relationship into the dual variable \(v\) update formula and simplifying it in a parallel way.
\end{proof}
\fi

\subsection{Proof of Proposition \ref{prop:consensus_equiv}}
\begin{proof}
To better understand the procedure of consensus ADMM, we focus on the dual form of the \(w_k\)-update problem for the \(k\)-th agent. Let \(w_k^{\top}x_i = \tilde{u}_i\) for any \(i \in \mathcal{P}_k\). Using this substitution, we can equivalently rewrite the original problem in the following form:

\begin{equation}\label{eqnpro1}
\underset{w_k \in \mathbb{R}^d, \tilde{u}_{[k]} \in \mathbb{R}^{n_k}}{\min} \; \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell_i(\tilde{u}_i) + \frac{\beta}{2} \|w_k - w^{(t)} - \beta^{-1}u_k^{(t)}\|^2 
\quad \text{s.t.} \quad w_k^{\top}x_i = \tilde{u}_i, \; i \in \mathcal{P}_k.
\end{equation}

By introducing the Lagrange multiplier \(\tilde{v}_{[k]} \in \mathbb{R}^{n_k}\), the Lagrangian function becomes:

\[
L(w_k, \tilde{u}_{[k]}; \tilde{v}_{[k]}) := \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell_i(\tilde{u}_i) 
+ \frac{\beta}{2} \|w_k - w^{(t)} - \beta^{-1}u_k^{(t)}\|^2 
+ \frac{1}{n} \sum_{i \in \mathcal{P}_k} \tilde{v}_i (w_k^{\top}x_i - \tilde{u}_i).
\]

Taking the infimum of the Lagrangian with respect to \(w_k\) and \(\tilde{u}_{[k]}\), we derive the dual form of this subproblem:

\begin{equation}\label{eqn_proximal_equiv}
\underset{\tilde{v}_{[k]} \in \mathbb{R}^{n_k}}{\min} \; 
\frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(\tilde{v}_i) 
+ \frac{1}{2n^2\beta} \left( \tilde{v}_{[k]} - \tilde{v}_{[k]}^{(t)} \right)^{\top} X_{[k]}^{\top}X_{[k]} \left( \tilde{v}_{[k]} - \tilde{v}_{[k]}^{(t)} \right)
- \frac{1}{n} \Big\langle X_{[k]}^{\top} \left( w^{(t)} + \frac{1}{\beta}u_k^{(t)} - \frac{1}{n\beta}X_{[k]}\tilde{v}_{[k]}^{(t)} \right), \tilde{v}_{[k]} - \tilde{v}_{[k]}^{(t)} \Big\rangle.
\end{equation}

Let \(\tilde{v}_{[k]}^{(t+1)}\) denote the optimal solution of the above dual problem. Since \(w^{(t+1)}\) is the optimal primal solution, the KKT conditions between the primal and dual solutions imply:

\[
w_k^{(t+1)} = w^{(t)} + \frac{1}{\beta}u_k^{(t)} - \frac{1}{n\beta}X_{[k]}\tilde{v}_{[k]}^{(t+1)}.
\]
Substituting the above relationship into the \(u_k^{(t+1)}\) update formula, we obtain:
\[
u_k^{(t+1)} = \frac{1}{n} X_{[k]}\tilde{v}_{[k]}^{(t+1)}.
\]

We can further simplify the \(w_k^{(t+1)}\) update as:
\[
w_k^{(t+1)} = w^{(t)} + \frac{1}{n\beta}X_{[k]} \left( \tilde{v}_{[k]}^{(t)} - \tilde{v}_{[k]}^{(t+1)} \right).
\]

Representing \(w_k^{(t)}\) and \(u_k^{(t)}\) in terms of \(w^{(t)}\) and \(\tilde{v}_{[k]}^{(t)}\) in the consensus ADMM updates, we derive the following updates:

For the dual variable \(\tilde{v}_{[k]}\):
\[
\tilde{v}_{[k]}^{(t+1)} \approx \underset{\tilde{v}_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \; \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(\tilde{v}_i) 
+ \frac{1}{2n^2\beta} \left( \tilde{v}_{[k]} - \tilde{v}_{[k]}^{(t)} \right)^{\top} X_{[k]}^{\top} X_{[k]} \left( \tilde{v}_{[k]} - \tilde{v}_{[k]}^{(t)} \right)
\]
\[
- \frac{1}{n} \Big\langle X_{[k]}^{\top} w^{(t)}, \tilde{v}_{[k]} \Big\rangle, \quad k \in [K] \; \text{(in parallel)}.
\]

For the primal variable \(w^{(t+1)}\):
\[
w^{(t+1)} = \mathrm{prox}_{(\beta K)^{-1} g} \left( w^{(t)} - \frac{1}{n\beta K} X \left( 2\tilde{v}^{(t+1)} - \tilde{v}^{(t)} \right) \right).
\]
To complete the proof, we need to show that the dual variable \(\tilde{v}\) converges to the global dual variable \(v\). The details of this convergence will be addressed in the convergence theory section.
By further linearizing the local data matrix \(X_{[k]}^{\top}X_{[k]}\) in the dual variable \(v\) update, we derive the corresponding update formula for the consensus ADMM incorporating linearization techniques.
\end{proof}


\subsection{Proof of Proposition \ref{prop:proximal_equiv}}
\begin{proof}
For the first matrix choice of $Q=\frac{\rho}{n^2}\left( \eta_1 \mbox{diag}\left( X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}   \right)-X^{\top}X \right) $, the proximal ADMM updates can be equivalently written as:
\begin{eqnarray*}
v^{(t+1)} &\approx&  \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \; \frac{1}{n} \sum_{k=1}^{K} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) +
\frac{\rho \eta_1}{2n^2} \sum_{k=1}^{K} \left( v_{[k]} - v_{[k]}^{(t)} \right)^{\top} X_{[k]}^{\top} X_{[k]} \left( v_{[k]} - v_{[k]}^{(t)} \right) \\
& \qquad & + \Big\langle \frac{\rho}{n}X^{\top}\left( \frac{1}{n} Xv^{(t)}+u^{(t)}-\rho^{-1}w^{(t)}
\right), v-v^{(t)} \Big\rangle,\\
u^{(t+1)} &=& \mbox{Prox}_{ \rho^{-1} g^* } \left(  \rho^{-1}w^{(t)}-\frac{1}{n} Xv^{(t+1)}  \right),\\
w^{(t+1)} &=& w^{(t)}-\rho \left( \frac{1}{n}Xv^{(t+1)}+u^{(t+1)} \right).
\end{eqnarray*}
For the \(v\)-update, note that the update formula for the primal variable \(w\) satisfies:
\[
\frac{1}{n} Xv^{(t)} + u^{(t)} - \frac{1}{\rho} w^{(t)} = \frac{1}{\rho} \left( w^{(t-1)} - 2w^{(t)} \right).
\]
Substituting this relationship into the dual variable \(v\)-update formula and simplifying in parallel, we immediately obtain the corresponding update formula for \(v\). For the \(w\)-update, using the Moreau identity \( \mathrm{prox}_{\lambda f}(v) + \lambda \, \mathrm{prox}_{f^*/\lambda}(v/\lambda) = v \), we have:
\begin{eqnarray*}
w^{(t+1)} &=& \rho\left( \rho^{-1} w^{(t)}-\frac{1}{n}Xv^{(t+1)}-u^{(t+1)}   \right)\\
          &=& \rho\left( \rho^{-1} w^{(t)}-\frac{1}{n}Xv^{(t+1)}-\mbox{Prox}_{ \rho^{-1} g^* } \left(  \rho^{-1}w^{(t)}-\frac{1}{n} Xv^{(t+1)}  \right)   \right)\\ 
          &=& \mbox{Prox}_{ \rho g } \left(  w^{(t)}-\frac{\rho}{n} Xv^{(t+1)}  \right). 
\end{eqnarray*}
Thus, we can equivalently transform the proximal ADMM with the first matrix choice of $Q$ as the corresponding update formula. Further linearizing the local data matrix $X^{\top}_{[k]}X_{[k]}$, we can obtain the corresponding update formula for the proximal ADMM with the second matrix choice of $Q$.
\end{proof}

\subsection{Proof of Lemma \ref{lemma1}}
\begin{proof}
For any vector \( u = [u_{[1]}, \ldots, u_{[K]}]^{\top} \in \mathbb{R}^n \) with each \( u_{[k]} \in \mathbb{R}^{n_k} \), we have:
\begin{eqnarray*}
u^{\top}X^{\top}Xu &=& K^2 \Big\| \frac{1}{K} \sum_{k=1}^{K} X_{[k]}u_{[k]} \Big\|^2, \\
&\leq& K^2 \cdot \frac{1}{K} \sum_{k=1}^{K} \Big\| X_{[k]}u_{[k]} \Big\|^2, \\
&=& K \sum_{k=1}^{K} \Big\| X_{[k]}u_{[k]} \Big\|^2, \\
&=& u^{\top} \, K \, \mathrm{diag}\left( X_{[1]}^{\top}X_{[1]}, \ldots, X_{[K]}^{\top}X_{[K]} \right) u.
\end{eqnarray*}
The second inequality holds due to the convexity property of the squared norm, \(\|\cdot\|^2\). Thus, we conclude that:
\[
K \, \mathrm{diag}\left( X_{[1]}^{\top}X_{[1]}, \ldots, X_{[K]}^{\top}X_{[K]} \right) \succeq X^{\top}X.
\]
Based on the above relationship, it is straightforward to verify that these tuning parameters 
\[ \eta_1 = K \mbox{ and } \eta_2 = K \max \left\{ \lambda_{\max}\left( X_{[1]}^{\top}X_{[1]} \right), \ldots, \lambda_{\max}\left( X_{[K]}^{\top}X_{[K]} \right) \right\}\]
ensure that the matrix \(Q\) is positive semi-definite.
\end{proof}


\section{Proofs for the Results in Section~\ref{sec:connection}}
\subsection{Proof of Corollary \ref{corollary1}}
Substituting $g(w)=\frac{\lambda}{2}\|w\|^2$ into the updates of \eqref{Q1_pd}, we immediately simplifies the updates of Proximal-1-PD as follows:
\begin{eqnarray*}
v^{(t+1)}_{[k]} &=& \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) + \frac{\rho \eta_1}{2n^2} \Big\|v_{[k]}-v_{[k]}^{(t)}\Big\|_{X_{[k]}^{\top}X_{[k]}}^2 -\frac{1}{n} \Big\langle X_{[k]}^{\top}\left( 2w^{(t)} - w^{(t-1)} \right), v_{[k]} \Big\rangle,
 k \in [K] \\
w^{(t+1)} &=& \frac{1}{\lambda\rho+1} \left( w^{(t)}-\frac{\rho}{n}Xv^{(t+1)} \right).
\end{eqnarray*}
Considering $\rho=\frac{1}{\lambda}$, we have by the $w$-update 
$$ w^{(t+1)}=\frac{1}{2}\left( w^{(t)}-\frac{1}{n\lambda} Xv^{(t+1)} \right), \mbox{ for any } t. $$
Substituting the above relationship with timestep $t$ into the $v$-update gives us 
$$ v^{(t+1)}_{[k]} = \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) + \frac{\eta_1}{2n^2\lambda} \Big\|v_{[k]}-v_{[k]}^{(t)}\Big\|_{X_{[k]}^{\top}X_{[k]}}^2 +\frac{1}{n^2\lambda} \Big\langle X_{[k]}^{\top}Xv^{(t)}, v_{[k]} \Big\rangle,
 k \in [K] . $$
Compared to the CoCoA-PD update, this update formula matches it when \(\eta_1 = \sigma\), but differs in the \(w\)-update.

\subsection{Proof of Proposition \ref{prop:genericupdaterule}}
\begin{proof}
Notice that we have $\mathcal{F}(z^{(t+1)})=\begin{pmatrix}
\frac{1}{n} Xv^{(t+1)}+\partial g(w^{(t+1)})\\
\frac{1}{n} \partial \ell^*(v^{(t+1)})- \frac{1}{n}X^{\top}w^{(t+1)}
\end{pmatrix}$ for the min-max objective function defined in Section 5. Next, we would derive the corresponding semi-positive matrix $P$ individually according to the different algorithm updates.
\paragraph{Distributed proximal ADMM.} For the distributed proximal ADMM with the first matrix choice, we consider the update rules by updating the primal variable $w$ first and then the dual variable $v$ as follows:
\begin{align*}
w^{(t+1)} &= \mathrm{prox}_{\rho g} \left(  w^{(t)} - \frac{\rho}{n} Xv^{(t)} \right),\\
v^{(t+1)}_{[k]} &\approx  \underset{v_{[k]} \in \mathbb{R}^{n_k}}{\arg\min} \; \frac{1}{n} \sum_{i \in \mathcal{P}_k} \ell^*_i(v_i) +
\frac{\rho \eta_1}{2n^2} \left( v_{[k]} - v_{[k]}^{(t)} \right)^{\top} X_{[k]}^{\top} X_{[k]} \left( v_{[k]} - v_{[k]}^{(t)} \right) \\
& \quad -\frac{1}{n} \Big\langle X_{[k]}^{\top}\left( 2w^{(t+1)} - w^{(t)} \right), v_{[k]} \Big\rangle, \quad k \in [K] \; \text{(in parallel)}. 
\end{align*}
By utilizing the first-order optimality conditions, we can equivalently transform the above update rules as follows:
\begin{eqnarray*}
0 &\in& \partial g(w^{(t+1)})+\rho^{-1}\left(  w^{(t+1)}-w^{(t)}+\frac{\rho}{n}Xv^{(t)}    \right). \\
0 &\in& \frac{1}{n} \partial \ell^*(v^{(t+1)})+\frac{\rho\eta_1}{n^2}\mbox{diag}\left( X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}  \right) (v^{(t+1)}-v^{(t)})-\frac{1}{n}X^{\top}\left(2w^{(t+1)}-w^{(t)}  \right) ,\\
\end{eqnarray*}
By rearranging the above update terms, we have
$$P_1(z^{(t)}-z^{(t+1)})=\begin{pmatrix}
\rho^{-1} I & -\frac{1}{n}X\\
-\frac{1}{n}X^{\top} &  \frac{\rho\eta_1}{n^2} \diag{X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}}    
\end{pmatrix}
\begin{pmatrix}
 w^{(t)}-w^{(t+1)}\\
v^{(t)}-v^{(t+1)}   
\end{pmatrix}
\in \mathcal{F}(z^{(t+1)}).$$
Similarly, the updates of the distributed proximal ADMM with the second matrix choice can be equivalently written as follows:
\[
\begin{aligned}
w^{(t+1)} &= \mathrm{prox}_{\rho g} \left( w^{(t)} - \frac{\rho}{n} Xv^{(t)} \right), \\
v_{[k]}^{(t+1)} &= \mathrm{prox}_{(n/\rho\eta_2)\ell^*_{[k]}}\left( v_{[k]}^{(t)} + \frac{n}{\rho\eta_2}X_{[k]}^{\top}\left(2w^{(t+1)} - w^{(t)}\right) \right), \quad k \in [K] \; \text{(in parallel)}.
\end{aligned}
\]

Using the first-order optimality conditions and rearranging terms, we have:
\[
P_2 \left( z^{(t)} - z^{(t+1)} \right) =
\begin{pmatrix}
\rho^{-1} I & -\frac{1}{n}X \\
-\frac{1}{n}X^{\top} & \frac{\rho\eta_2}{n^2} I
\end{pmatrix}
\begin{pmatrix}
w^{(t)} - w^{(t+1)} \\
v^{(t)} - v^{(t+1)}
\end{pmatrix}
\in \mathcal{F}(z^{(t+1)}).
\]

Thus, in the distributed proximal ADMM, the corresponding matrices are given by:
\[
P_1 =
\begin{pmatrix}
\rho^{-1} I & -\frac{1}{n}X \\
-\frac{1}{n}X^{\top} & \frac{\rho\eta_1}{n^2} \, \mathrm{diag}\left(X_{[1]}^{\top}X_{[1]}, \ldots, X_{[K]}^{\top}X_{[K]}\right)
\end{pmatrix}
\quad \text{and} \quad
P_2 =
\begin{pmatrix}
\rho^{-1} I & -\frac{1}{n}X \\
-\frac{1}{n}X^{\top} & \frac{\rho\eta_2}{n^2} I
\end{pmatrix}.
\]


\paragraph{Consensus ADMM.} 
For the standard consensus ADMM, we could equivalently write the updates in the Proposition \ref{prop:consensus_equiv} by utilizing the first-order optimality conditions as follows:
\begin{eqnarray*}
0 &\in& \partial g(w^{(t+1)})+\beta K\left(  w^{(t+1)}-w^{(t)}+\frac{1}{n\beta K}X \left(2v^{(t+1)}-v^{(t)}\right)    \right), \\
0 &\in& \frac{1}{n} \partial \ell^*(v^{(t+1)})+\frac{1}{n^2\beta}\mbox{diag}\left( X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}  \right) (v^{(t+1)}-v^{(t)})-\frac{1}{n}X^{\top}w^{(t)} .\\
\end{eqnarray*}
By rearranging the above update terms, we have
$$P_1(z^{(t)}-z^{(t+1)})=\begin{pmatrix}
\beta K I & \frac{1}{n}X\\
\frac{1}{n}X^{\top} &  \frac{1}{n^2\beta} \diag{X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}}    
\end{pmatrix}
\begin{pmatrix}
 w^{(t)}-w^{(t+1)}\\
v^{(t)}-v^{(t+1)}   
\end{pmatrix}
\in \mathcal{F}(z^{(t+1)}).$$
Similarly using the first-order optimality conditions and rearranging terms, we have for the updates of the consensus ADMM with the linearization technology:
\[
P_2 \left( z^{(t)} - z^{(t+1)} \right) =
\begin{pmatrix}
\beta K I & \frac{1}{n}X\\
\frac{1}{n}X^{\top} &  \frac{\tau}{n^2\beta} I   
\end{pmatrix}
\begin{pmatrix}
 w^{(t)}-w^{(t+1)}\\
v^{(t)}-v^{(t+1)}   
\end{pmatrix}
\in \mathcal{F}(z^{(t+1)}).
\]
Thus, in the consensus ADMM, the corresponding matrices are given by:
\[
P_1 =
\begin{pmatrix}
\beta K I & \frac{1}{n}X\\
\frac{1}{n}X^{\top} &  \frac{1}{n^2\beta} \diag{X_{[1]}^{\top}X_{[1]},\ldots, X_{[K]}^{\top}X_{[K]}}    
\end{pmatrix}\quad \text{and} \quad
P_2 =
\begin{pmatrix}
\beta K I & \frac{1}{n}X\\
\frac{1}{n}X^{\top} &  \frac{\tau}{n^2\beta} I   
\end{pmatrix}.\]

\end{proof}

\section{Proofs for the Results in Section~\ref{sec:theory}}

\subsection{Proof of Theorem \ref{Thm1}}
\begin{proof}
Let $u^{(t+1)}=P(z^{(t)}-z^{(t+1)}) \in \mathcal{F}(z^{(t+1)})$. From the convexity-concavity property of the objective function $L(w;v)$, we have that
\begin{eqnarray*}
L(w^{(t+1)};v)-L(w;v^{(t+1)}) &=& L(w^{(t+1)};v)-L(w^{(t+1)};v^{(t+1)})+L(w^{(t+1)};v^{(t+1)})-L(w;v^{(t+1)})\\
&\leq&  \langle u^{(t+1)} , z^{(t+1)}-z \rangle = \left( z^{(t)}-z^{(t+1)} \right)^{\top}P\left( z^{(t+1)}-z \right)\\
&=& \frac{1}{2}\|z^{(t)}-z\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z\|_{P}^2-\frac{1}{2}\|z^{(t)}-z^{(t+1)}\|_{P}^2\\
&\leq& \frac{1}{2}\|z^{(t)}-z\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z\|_{P}^2,
\end{eqnarray*}
where the last inequality follows from the fact that $\|\cdot\|_{P}$ is a semi-norm. Thus, we have
$$ L(\bar{w}^{(T)};v)-L(w;\bar{v}^{(T)}) \leq  \frac{1}{T}\sum_{t=0}^{T-1}\left\{ L(w^{(t+1)};v)-L(w;v^{(t+1)})
   \right\} \leq \frac{1}{2T}\|z^{(0)}-z\|^2_{P}, $$
where the first inequality comes from the convexity-concavity of $L(w;v)$ and the second inequality comes from the above relation.
\end{proof}




\subsection{Proof of Theorem \ref{Thm2}}
\begin{proof}
We first show that $\{z^{(t)}\}$ is bounded. 

Let $z^*=(w^*,v^*)$ denote the optimal solution of the saddle point problem \eqref{saddlepoint}. % We claim that if we choose $D_0=\frac{1}{4}\left( \sqrt{\sum_{t=1}^\infty \|\epsilon^{(t)}\|}+\sqrt{\sum_{t=1}^\infty \|\epsilon^{(t)}\|+4\|z^{(0)}-z^*\|}\right)^2$, then we will have $\|z^{(t)}-z^*\| \leq D_0$ for any $t$, thus giving a bound of the iterate sequence.
Firstly, from the convexity-concavity property of the objective function $L(w;v)$, we have that
\begin{equation}\label{eqnC.3}
\begin{aligned}
L(w^{(t+1)};v)-L(w;v^{(t+1)}) &= L(w^{(t+1)};v)-L(w^{(t+1)};v^{(t+1)})+L(w^{(t+1)};v^{(t+1)})-L(w;v^{(t+1)})\\
&\leq  \langle u^{(t+1)} , z^{(t+1)}-z \rangle = \left( z^{(t)}-z^{(t+1)} \right)^{\top}P\left( z^{(t+1)}-z \right) +\langle \epsilon^{(t+1)} , z^{(t+1)}-z \rangle\\%
&= \frac{1}{2}\|z^{(t)}-z\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z\|_{P}^2-\frac{1}{2}\|z^{(t)}-z^{(t+1)}\|_{P}^2+\langle \epsilon^{(t+1)} , z^{(t+1)}-z \rangle\\%
&\leq \frac{1}{2}\|z^{(t)}-z\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z\|_{P}^2+\langle \epsilon^{(t+1)} , z^{(t+1)}-z \rangle\\
&\leq \frac{1}{2}\|z^{(t)}-z\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z\|_{P}^2+ \|\epsilon^{(t+1)}\|\|z^{(t+1)}-z\|.\\
\end{aligned}
\end{equation}
Choosing $z=z^*$ and using $L(w^{(t+1)};v^*)-L(w^*;v^{(t+1)})\geq 0$, we have
\begin{align*}
    \frac{1}{2}\|z^{(t+1)}-z^*\|_{P}^2 &\leq \frac{1}{2}\|z^{(t)}-z^*\|_{P}^2+ \|\epsilon^{(t+1)}\|\|z^{(t+1)}-z^*\|\\
    &\leq \frac{1}{2}\|z^{(t)}-z^*\|_{P}^2+ C\|\epsilon^{(t+1)}\|\|z^{(t+1)}-z^*\|_{P},
\end{align*}
where $C$ is a constant satisfying $\|z\|\leq C\|z\|_P$, which exists since $P$ is positive definite. Therefore, 
\begin{align*}
    (\|z^{(t+1)}-z^*\|_{P}-C\epsilon^{(t+1)})^2 \leq \|z^{(t)}-z^*\|_{P}^2 + (\epsilon^{(t+1)})^2.
\end{align*}
Taking square root of both sides yields that
\begin{align*}
    \|z^{(t+1)}-z^*\|_{P}-C\epsilon^{(t+1)} &\leq \sqrt{\|z^{(t)}-z^*\|_{P}^2 + (\epsilon^{(t+1)})^2}\\
    &\leq \|z^{(t)}-z^*\|_{P} + \epsilon^{(t+1)}.
\end{align*}
Simple induction gives that
\[
     \|z^{(T)}-z^*\|_{P} \leq  \|z^{(0)}-z^*\|_{P} + (C+1) \sum_{t=1}^T \epsilon^{(t)}
\]
As a result, we have
\[
\sup_T \|z^{(T)} - z^*\| \leq C\sup_T \|z^{(T)} - z^*\|_P \leq C\|z^{(0)}-z^*\|_{P} + C(C+1) \sum_{t=1}^\infty \epsilon^{(t)},
\]
which gives the boundedness of $\{z^{(t)}\}$.


Let $u^{(t+1)} \in \mathcal{F}(z^{(t+1)})$. From \eqref{eqnC.3}, we have that
\begin{eqnarray*}
L(w^{(t+1)};v^*)-L(w^*;v^{(t+1)}) &\leq& \frac{1}{2}\|z^{(t)}-z^*\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z^*\|_{P}^2+ \|\epsilon^{(t+1)}\|\|z^{(t+1)}-z^*\|\\
&\leq& \frac{1}{2}\|z^{(t)}-z^*\|_{P}^2-\frac{1}{2}\|z^{(t+1)}-z^*\|_{P}^2+ D\|\epsilon^{(t+1)}\|,
\end{eqnarray*}
where the last-second inequality follows from Cauchy-Schwarz inequality and the last inequality from the definition of $D$. Thus, we have
$$ L(\bar{w}^{(T)};v^*)-L(w^*;\bar{v}^{(T)}) \leq  \frac{1}{T}\sum_{t=0}^{T-1}\left\{ L(w^{(t+1)};v^*)-L(w^*;v^{(t+1)})
   \right\} \leq \frac{1}{2T}\|z^{(0)}-z^*\|^2_{P}+\frac{D \sum_{t=1}^{T}\|\epsilon^{(t)}\| }{T}, $$
where the first inequality comes from the convexity-concavity of $L(w;v)$ and the second inequality comes from the above relation.
\end{proof}

%\section{Numerical Studies}



\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
