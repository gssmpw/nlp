[
  {
    "index": 0,
    "papers": [
      {
        "key": "IQL",
        "author": "Ilya Kostrikov and\nAshvin Nair and\nSergey Levine",
        "title": "Offline Reinforcement Learning with Implicit Q-Learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "CQL",
        "author": "Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey",
        "title": "Conservative Q-Learning for Offline Reinforcement Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "COMBO",
        "author": "Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea",
        "title": "COMBO: Conservative Offline Model-Based Policy Optimization"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "BAIL",
        "author": "Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Ross, Keith",
        "title": "BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bradtkeAdaptiveLinearQuadratic1994",
        "author": "Bradtke, S.J. and Ydstie, B.E. and Barto, A.G.",
        "title": "Adaptive Linear Quadratic Control Using Policy Iteration"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "kiumarsiReinforcementQLearningOptimal2014",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "deanSampleComplexityLinear2020",
        "author": "Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen",
        "title": "On the {{Sample Complexity}} of the {{Linear Quadratic Regulator}}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "cohenLearningLinearQuadraticRegulators2019",
        "author": "Cohen, Alon and Koren, Tomer and Mansour, Yishay",
        "title": "Learning {{Linear-Quadratic Regulators Efficiently}} with Only $\\sqrt{T}$ {{Regret}}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "laleExploreMoreImprove2020",
        "author": "Lale, Sahin and Azizzadenesheli, Kamyar and Hassibi, Babak and Anandkumar, Anima",
        "title": "Explore {{More}} and {{Improve Regret}} in {{Linear Quadratic Regulators}}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "simchowitzNaiveExplorationOptimal2020",
        "author": "Simchowitz, Max and Foster, Dylan J.",
        "title": "Naive {{Exploration}} Is {{Optimal}} for {{Online LQR}}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "agarwalOnlineControlAdversarial2019",
        "author": "Agarwal, Naman and Bullins, Brian and Hazan, Elad and Kakade, Sham and Singh, Karan",
        "title": "Online Control with Adversarial Disturbances"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "hazanNonstochasticControlProblem2020",
        "author": "Hazan, Elad and Kakade, Sham and Singh, Karan",
        "title": "The {{Nonstochastic Control Problem}}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "fosterLogarithmicRegretAdversarial2020",
        "author": "Foster, Dylan and Simchowitz, Max",
        "title": "Logarithmic Regret for Adversarial Online Control"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "depersisFormulasDataDrivenControl2020",
        "author": "De Persis, Claudio and Tesi, Pietro",
        "title": "Formulas for {{Data-Driven Control}}: {{Stabilization}}, {{Optimality}}, and {{Robustness}}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "vanwaardeNoisyDataFeedback2022",
        "author": "{van Waarde}, Henk J. and Camlibel, M. Kanat and Mesbahi, Mehran",
        "title": "From Noisy Data to Feedback Controllers: Non-Conservative Design via a Matrix {{S-lemma}}"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "coulsonDataEnabledPredictiveControl2019",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhongValueFunctionApproximation2013",
        "author": "Zhong, Mingyuan and Johnson, Mikala and Tassa, Yuval and Erez, Tom and Todorov, Emanuel",
        "title": "Value Function Approximation and Model Predictive Control"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "lowreyPlanOnlineLearn2018",
        "author": "Lowrey, Kendall and Rajeswaran, Aravind and Kakade, Sham and Todorov, Emanuel and Mordatch, Igor",
        "title": "Plan {{Online}}, {{Learn Offline}}: {{Efficient Learning}} and {{Exploration}} via {{Model-Based Control}}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "bhardwajBlendingMPCValue2020",
        "author": "Bhardwaj, Mohak and Choudhury, Sanjiban and Boots, Byron",
        "title": "Blending {{MPC}} \\& {{Value Function Approximation}} for {{Efficient Reinforcement Learning}}"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "watkinsQlearning1992",
        "author": "Watkins, Christopher John Cornish Hellaby and Dayan, Peter",
        "title": "Q-Learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "lillicrapContinuousControlDeep2015",
        "author": "Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan",
        "title": "Continuous Control with Deep Reinforcement Learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "bradtkeAdaptiveLinearQuadratic1994",
        "author": "Bradtke, S.J. and Ydstie, B.E. and Barto, A.G.",
        "title": "Adaptive Linear Quadratic Control Using Policy Iteration"
      },
      {
        "key": "kiumarsiReinforcementQLearningOptimal2014",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "deanSampleComplexityLinear2020",
        "author": "Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen",
        "title": "On the {{Sample Complexity}} of the {{Linear Quadratic Regulator}}"
      },
      {
        "key": "simchowitzNaiveExplorationOptimal2020",
        "author": "Simchowitz, Max and Foster, Dylan J.",
        "title": "Naive {{Exploration}} Is {{Optimal}} for {{Online LQR}}"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "agarwalOnlineControlAdversarial2019",
        "author": "Agarwal, Naman and Bullins, Brian and Hazan, Elad and Kakade, Sham and Singh, Karan",
        "title": "Online Control with Adversarial Disturbances"
      },
      {
        "key": "hazanNonstochasticControlProblem2020",
        "author": "Hazan, Elad and Kakade, Sham and Singh, Karan",
        "title": "The {{Nonstochastic Control Problem}}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "willemsNotePersistencyExcitation2005",
        "author": "Willems, Jan C. and Rapisarda, Paolo and Markovsky, Ivan and De Moor, Bart L. M.",
        "title": "A Note on Persistency of Excitation"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "depersisFormulasDataDrivenControl2020",
        "author": "De Persis, Claudio and Tesi, Pietro",
        "title": "Formulas for {{Data-Driven Control}}: {{Stabilization}}, {{Optimality}}, and {{Robustness}}"
      },
      {
        "key": "vanwaardeNoisyDataFeedback2022",
        "author": "{van Waarde}, Henk J. and Camlibel, M. Kanat and Mesbahi, Mehran",
        "title": "From Noisy Data to Feedback Controllers: Non-Conservative Design via a Matrix {{S-lemma}}"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "coulsonDataEnabledPredictiveControl2019",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "BCQ",
        "author": "Scott Fujimoto and David Meger and Doina Precup",
        "title": "Off-Policy Deep Reinforcement Learning without Exploration"
      },
      {
        "key": "guo2020batch",
        "author": "Guo, Yijie and Feng, Shengyu and Le Roux, Nicolas and Chi, Ed and Lee, Honglak and Chen, Minmin",
        "title": "Batch reinforcement learning through continuation method"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "BEAR",
        "author": "Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey",
        "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction"
      },
      {
        "key": "BRAC",
        "author": "Yifan Wu and G. Tucker and Ofir Nachum",
        "title": "Behavior Regularized Offline Reinforcement Learning"
      },
      {
        "key": "IQL",
        "author": "Ilya Kostrikov and\nAshvin Nair and\nSergey Levine",
        "title": "Offline Reinforcement Learning with Implicit Q-Learning"
      },
      {
        "key": "CQL",
        "author": "Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey",
        "title": "Conservative Q-Learning for Offline Reinforcement Learning"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "gabbianelli2023offline",
        "author": "Gabbianelli, Germano and Neu, Gergely and Okolo, Nneka and Papini, Matteo",
        "title": "Offline primal-dual reinforcement learning for linear mdps"
      },
      {
        "key": "hong2023primal",
        "author": "Hong, Kihyuk and Li, Yuhang and Tewari, Ambuj",
        "title": "A primal-dual-critic algorithm for offline constrained reinforcement learning"
      },
      {
        "key": "le2019batch",
        "author": "Le, Hoang and Voloshin, Cameron and Yue, Yisong",
        "title": "Batch policy learning under constraints"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "COMBO",
        "author": "Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea",
        "title": "COMBO: Conservative Offline Model-Based Policy Optimization"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "morel",
        "author": "Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten",
        "title": "Morel: Model-based offline reinforcement learning"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "BAIL",
        "author": "Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Ross, Keith",
        "title": "BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "zhongValueFunctionApproximation2013",
        "author": "Zhong, Mingyuan and Johnson, Mikala and Tassa, Yuval and Erez, Tom and Todorov, Emanuel",
        "title": "Value Function Approximation and Model Predictive Control"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "lowreyPlanOnlineLearn2018",
        "author": "Lowrey, Kendall and Rajeswaran, Aravind and Kakade, Sham and Todorov, Emanuel and Mordatch, Igor",
        "title": "Plan {{Online}}, {{Learn Offline}}: {{Efficient Learning}} and {{Exploration}} via {{Model-Based Control}}"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "bhardwajBlendingMPCValue2020",
        "author": "Bhardwaj, Mohak and Choudhury, Sanjiban and Boots, Byron",
        "title": "Blending {{MPC}} \\& {{Value Function Approximation}} for {{Efficient Reinforcement Learning}}"
      }
    ]
  }
]