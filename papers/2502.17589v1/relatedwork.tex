\section{Related Work}
\subsection{Chart Summarization}

Automated chart summarization has emerged as a critical research area, driven by the increasing volume of visual data and the need for efficient information extraction. Early approaches to chart summarization often relied on template-based methods and rule-based systems, which, while effective for simple charts, lacked the flexibility and robustness to handle the diversity and complexity of real-world charts \cite{TemplateChartSum}. More recently, deep learning techniques, particularly those leveraging visual-language models (VLMs), have revolutionized the field, enabling more sophisticated and human-like summarization capabilities.

Several studies have explored the application of VLMs for chart summarization. Some early works focused on extracting structured data from charts using Optical Character Recognition (OCR) and specialized chart parsing modules, and then feeding this structured information into sequence-to-sequence models for text generation \cite{OCRChartSum,StructChartSum}. For instance, the OCR-Chart2text approach \cite{OCRChart2text} exemplifies this paradigm, combining OCR with rule-based methods for data extraction. While these approaches achieved initial success, they are limited by the accuracy of the data extraction step and may not fully capture the visual context and nuanced interpretations inherent in charts.

To address these limitations, more recent research has explored end-to-end approaches that directly process chart images using VLMs. These methods aim to learn a direct mapping from visual chart input to textual summaries, leveraging the ability of VLMs to jointly understand visual and textual information. ChartAssistant \cite{ChartAssistant2024} represents a recent VLM specifically designed for chart comprehension and generation tasks, demonstrating improved performance in chart summarization.  Furthermore, the ChartThinker model \cite{ChartThinker2024}, which directly motivates our work, introduced a contextual chain-of-thought approach, incorporating context retrieval to enhance the reasoning and descriptive capabilities of VLMs for chart summarization.  Visual In-Context Learning has also been proposed to improve the performance of Large Vision-Language Models in visual tasks \cite{zhou2024visual}. ChartAdapter \cite{ChartAdapter2024} proposed a lightweight transformer module to efficiently adapt large VLMs for chart summarization, highlighting the growing interest in leveraging pre-trained VLMs for this task.  Moreover, advancements in efficient video generation with large language models, such as vision representation compression techniques, are relevant to processing visual information effectively \cite{zhou2024less}.

Despite the significant progress, challenges remain in achieving truly robust and accurate chart summarization. Ensuring high fidelity between the generated summary and the chart's data content, mitigating hallucination, and enabling complex reasoning over intricate chart patterns are still active areas of research. Our work builds upon the recent advancements in end-to-end VLM-based chart summarization, aiming to further enhance the reasoning capabilities of these models by introducing a visual Chain-of-Thought mechanism directly within the LVLM training process.

\subsection{Large Language Models}

Large Language Models (LLMs) have emerged as a transformative force in natural language processing (NLP) and artificial intelligence, demonstrating remarkable capabilities across a wide spectrum of tasks. These models, typically based on deep neural networks with billions or even trillions of parameters, are pre-trained on massive text corpora, enabling them to learn intricate patterns and representations of language \cite{LLMTasks}.  Recent research, like Weak to Strong Generalization for Large Language Models with Multi-capabilities, explores the generalization abilities of these models \cite{zhou2025weak}. The scale of these models, coupled with innovative architectures like the Transformer \cite{Transformer}, has led to unprecedented performance in language understanding, generation, and reasoning.

One of the key breakthroughs enabling the success of LLMs is the Transformer architecture, which allows for efficient parallel processing of sequential data and captures long-range dependencies in text \cite{Transformer}. This architecture, with its self-attention mechanism, has become the foundation for many state-of-the-art LLMs, including models like BERT, GPT, and their numerous variants \cite{BERT,GPT}.  Pre-training techniques, such as masked language modeling and next sentence prediction, have also been crucial in enabling LLMs to learn general-purpose language representations from unlabeled text data \cite{BERT}.  Furthermore, the application of diffusion models with representation alignment has shown promise in various domains, potentially influencing the development of LLMs as well \cite{wang2024diffusion}.

LLMs have demonstrated impressive capabilities in a variety of NLP tasks, including text generation, machine translation, question answering, and text summarization \cite{LLMTasks}. Their ability to generate coherent and contextually relevant text has led to their widespread adoption in applications such as chatbots, content creation, and code generation. Furthermore, research has shown that LLMs exhibit emergent abilities, demonstrating complex behaviors like few-shot learning and in-context learning, where they can adapt to new tasks with minimal task-specific training data or even just through carefully designed prompts \cite{EmergentAbilities}.

Despite their remarkable progress, LLMs also face challenges and limitations. These include issues related to bias and fairness in model outputs, the potential for generating factually incorrect or misleading information (hallucination), and the computational demands of training and deploying these massive models \cite{LLMChallenges}.  However, ongoing research, including studies on memory-augmented state space models, aims to improve the efficiency and performance of these models \cite{wang2024memorymamba}. Ongoing research is actively addressing these challenges, exploring techniques for improving model robustness, interpretability, and trustworthiness. The continued development and refinement of LLMs promise to further revolutionize NLP and AI, enabling even more sophisticated and human-like interactions with machines.