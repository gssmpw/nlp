\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{extarrows}
\usepackage{diagbox}
\usepackage{microtype}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makecell}
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\method}{\texttt{AF-FCL}}
\input{math_commands.tex}
\definecolor{text}{rgb}{0.4,0.1,0.4}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}

\title{Accurate Forgetting for Heterogeneous Federated Continual Learning}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.  Funding acknowledgements go at the end of the paper.} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }

\renewcommand\footnotemark{}

\author{Abudukelimu Wuerkaixi\textsuperscript{* 1}\qquad Sen Cui\textsuperscript{* 1}\qquad Jingfeng Zhang\textsuperscript{* 2,3}\qquad Kunda Yan\textsuperscript{~1}\And
Bo Han\textsuperscript{~4,3}\qquad Gang Niu\textsuperscript{~3}\qquad Lei Fang\textsuperscript{~5}\qquad Changshui Zhang\textsuperscript{\dag~1}\qquad Masashi Sugiyama\textsuperscript{\dag~3,6}\thanks{\textsuperscript{*}These authors contributed equally to this work.}\thanks{\textsuperscript{\dag}Corresponding authors}\\
\textsuperscript{1} Institute for Artificial Intelligence, Tsinghua University (THUAI)\\
~~~Beijing National Research Center for Information Science and Technology (BNRist)\\
~~~Department of Automation, Tsinghua University, Beijing, P.R.China\\
\textsuperscript{2} The University of Auckland\quad \textsuperscript{3} RIKEN\quad \textsuperscript{4} Hong Kong Baptist University\\
\textsuperscript{5} DataCanvas Technology Co., Ltd.\quad \textsuperscript{6} The University of Tokyo\thanks{Code is at: \url{https://github.com/zaocan666/AF-FCL}.}
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% \providecommand{\we}[1]{\textcolor{black}{{#1}}}
% \providecommand{\WE}[1]{\textcolor{orange}{[{\bf #1}]}}

\providecommand{\we}[1]{\textcolor{orange}{{#1}}}
\providecommand{\WE}[1]{\textcolor{orange}{[{\bf #1}]}}
\providecommand{\cs}[1]{\textcolor{red}{{#1}}}
\providecommand{\CS}[1]{\textcolor{red}{[{\bf #1}]}}
\providecommand{\cus}[1]{\textcolor{gray}{{#1}}}
\providecommand{\zjf}[1]{\textcolor{blue}{[{#1}]}}
\providecommand{\ZJF}[1]{\textcolor{blue}{[{\bf #1}]}}
\providecommand{\question}[1]{\textcolor{cyan}{{#1}}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Recent years have witnessed a burgeoning interest in federated learning (FL).
% \CS{delete here}
However, the contexts in which clients engage in sequential learning remain under-explored.
Bridging FL and continual learning (CL) gives rise to a challenging practical problem: federated continual learning (FCL).
% \CS{ state the existing problem, then emphasize we consider a new  problem}
Existing research in FCL primarily focuses on mitigating the catastrophic forgetting issue of continual learning while collaborating with other clients. We argue that the forgetting phenomena are not invariably detrimental.
In this paper, we consider a more practical and challenging FCL setting characterized by potentially unrelated or even antagonistic data/tasks across different clients.
In the FL scenario, statistical heterogeneity and data noise among clients may exhibit spurious correlations which result in biased feature learning.
While existing CL strategies focus on a complete utilization of previous knowledge, we found that forgetting biased information is beneficial in our study. Therefore, we propose a new concept \textit{accurate forgetting} (AF) and develop a novel generative-replay method~\method~which selectively utilizes previous knowledge in federated networks.
We employ a probabilistic framework based on a normalizing flow model to quantify the credibility of previous knowledge.
% \CS{one sentence summarize how we achieve selective utilization.}
Comprehensive experiments affirm the superiority of our method over baselines.
% \method~excels in both the limitless task pool setting and common FCL setting.

\end{abstract}

\vspace{-.4cm}
\section{Introduction}
\vspace{-.2cm}
Continual learning is a learning scenario where a model tries to learn a series of new arriving tasks and maintain performance on old tasks~\citep{DBLP:conf/iros/Thrun94,kumar2012learning,DBLP:conf/eccv/LiH16,DBLP:conf/iclr/JeonLSK23}.
%Such a paradigm, who having such an ability inspires the building of an artificial general intelligence, is similar to the lifelong learning behavior of humans.
This approach, inspired by human lifelong learning, is central to advancing the development of artificial general intelligence.
Since birth, a person would gather experience about real world by constantly learning various tasks and remembering them.
Humans not only accumulate knowledge through self-directed learning but also collaboratively learn from others.
However, concerns about data privacy and communication overhead arise when cooperating with others.
Federated learning, which has attracted significant interests and gained various applications in industry~\citep{mcmahan2017communication,yang2019federated,li2021ditto}, has been an alternative to addressing these concerns.
This leads to the concept of federated continual learning (FCL)~\citep{DBLP:conf/iclr/QiZ023}, incorporating continual learning into federated learning.

%Also, the privacy-preserving characteristics of federated learning have rendered it widely applicable in the industry.
% under the federated learning scheme
%In practice, it is necessary for a machine learning algorithm involving multiple clients to consider data privacy.

In FCL, the goal is that clients learn models for their private sequential tasks collaboratively without violating the data privacy of individual clients. 
This could encounter challenges from three fronts. One is \emph{statistical heterogeneity} due to non-IID data across local clients.
Such heterogeneity could severely degrade performance~\citep{qu2022rethinking} when learning from clients collaboratively.
Another is catastrophic forgetting, stemming from restricted access to data from previous tasks due to realistic factors such as storage constraints, privacy issues, etc~\citep{wang2023comprehensive}.~%\CS{use chatGPT this is a  wrong sentence.}
%The data from previous tasks is not fully accessible due to practical reasons (storage constraints or privacy issues).
This can lead the model to lose its ability to perform previous tasks proficiently after assimilating new tasks.
%Thus, the model could suffer from catastrophic forgetting, losing its ability to perform the previous tasks after learning new tasks.
% Each client is continuously learning new tasks which are not necessarily the same among clients at each \cs{period}.
% Besides, the federated learning scheme includes different clients, probably containing non-IID. data.
% Existing research reveals that such statistical heterogeneity may result in under-performance~\citep{qu2022rethinking}.
% In the context of federated environments, this issue is exacerbated as, at any  time, the new tasks being continuously learned by clients may vary considerably.
There are a few studies seeking to address the above two problems in FCL.
For example, \cite{DBLP:journals/corr/abs-2109-04197} extended the \textit{Learning without Forgetting}~\citep{DBLP:conf/eccv/LiH16} method to the FCL scenario, memorizing previous tasks among all clients.
% \cite{DBLP:conf/iclr/QiZ023} proposed to adapt generative replay based methods in CL for the class-incremental federated learning setting.
The third concern is associated with the potential introduction of feature bias resulting from the federated scenario, which in turn could impact the memory within CL models. Research indicates that the memorization of noisy labels can significantly impair the model's performance~\citep{DBLP:conf/icml/00030YYXTS20}.
\begin{figure}[tbh]
\vspace{-.2cm}
\setlength{\abovecaptionskip}{-.1cm}
\setlength{\belowcaptionskip}{-.3cm}
\centering{
\includegraphics[width=0.86\columnwidth]{figures/problem.pdf}}
\caption{
Illustration of the FCL problem. Multiple hospitals within a federated learning network engage in the sequential acquisition of disease prediction tasks. 
The global memory bank, a crucial tool for the classifier in mitigating catastrophic forgetting, may possess biased features arising from statistical heterogeneity.
Notably, the overall performance of the classifier could suffer degradation without strategic forgetting (The experimental verification is in Sec. \ref{sec:4}).}
\label{fig:problem}
\vspace{-.2cm}
\end{figure}

Existing research developing FCL methods mainly assumed that thorough memorization of previous tasks yields overall performance benefits~\citep{DBLP:journals/corr/abs-2109-04197,DBLP:conf/iclr/QiZ023}.
% \cs{And knowledge from previous tasks is beneficial for the learning of current task. 
Elaborate strategies were employed to memorize previous information~\citep{DBLP:conf/icml/YoonJLYH21, DBLP:conf/ijcai/LiuQW023}.
%However, feature bias typically exists in the distributed dataset, especially when there are a large number of clients within the federated network.
In practice, feature bias typically exists in the dataset, especially when there are lots of clients within the federated network.
% Clients exhibit statistical heterogeneity, characterized by diverse joint distributions of data and labels
% For instance, clients may provide varying annotations for similar data, resulting in label noise.
Because of such statistical heterogeneity, biased or even harmful information from particular clients may reside in the \textit{memory bank} (i.e., memory buffer, generative models or model parameters) as shown in Figure~\ref{fig:problem}.
The federated model may inadvertently learn to identify and rely upon spurious correlations arising from diverse tasks among multiple clients.
% also potentially incorporating label noise introduced by a few clients.
Furthermore, the model may integrate label noise~\citep{zhang2024badlabel} introduced by a few clients.
For example, in a federated learning system implemented among hospitals nationwide, these medical institutions may encounter varying disease profiles over time.
Besides, hospitals located at distinct geographical areas often cater to diverse distributions as depicted in Figure~\ref{fig:problem}.
%Therefore, utilizing and memorizing such history knowledge without selection can have detrimental effects on both the learning process of the current task and the overall performance of previous tasks.
% Therefore, strategically mitigating erroneous knowledge during the acquisition of new tasks facilitates more robust learning processes.
Therefore, strategically mitigating erroneous knowledge during the acquisition of new tasks is required.
% which could potentially impair the model performance across all clients.
%Because of statistical heterogeneity, \cs{biased} or even \cs{harmful} information from particular clients may reside in the \textit{memory bank} (memory buffer, generative models or model parameters). Utilizing such history knowledge without selection \cs{could hurt the model learning for new tasks~\citep{DBLP:conf/iclr/JeonLSK23}}.

%In a federated learning system among hospitals nationwide, hospitals located at different area may encounter distinct epidemic\CS{please revise this sentence with chatGPT4}.


% Because of statistical heterogeneity, \cs{biased} or even \cs{harmful} information for \cs{learning tasks} of clients may reside in the \textit{memory bank} (memory buffer, generative models or model parameters).
% Utilizing such history knowledge without selection \text{is harmful for the model to learn current tasks~\citep{DBLP:conf/iclr/JeonLSK23}.

% In real-world application, the new arriving tasks of each client may not be correlated.
Motivated by the phenomenon in reality that the new arriving tasks of each client may not be correlated, we consider a more practical and challenging FCL setting in this paper: \textit{limitless task pool} (LTP).
From a temporal perspective, the tasks that a single client randomly selects from the LTP at various time points might be unrelated or even antagonistic, thereby presenting a significant challenge for model learning.
%Similarly, when viewed across different clients, the tasks undertaken by various clients at a given time can also be unrelated or exhibit conflicts.
% where the tasks for each client are randomly chosen from large number of tasks and two clients may not contain any common tasks. 
% \we{When considering multiple clients, their tasks at a given time can also be unrelated or conflicting.}
%\CS{revise this sentence to be shorter with chatGPT4}
% Under the setting of LTP, the issue of statistical heterogeneity among clients is \cs{largely} exacerbated, as the \cs{learned} model could \cs{face} severely biased features and results in poor generalizability \cs{across all tasks.}
To overcome the problem, we propose a novel generation-based method \textit{Accurate Forgetting Federated Continual Learning} (\method).
We argue that the forgetting phenomena are not invariably detrimental~\citep{DBLP:conf/icml/00030YYXTS20}.
Conversely, accurate forgetting mitigates the negative impact of the heterogeneity on model learning.

%\CS{ state a sample, the heterogeneity and accurate forgetting}

%\cus{We employed the \textit{normalizing flow} (\textit{NF}) model for generative replay~\citep{rezende2015variational}.
%Normalizing flow is a widely used modeling framework that is capable of learning complex distribution with a series of bijective transformations~\citep{DBLP:conf/nips/DurkanB0P19,DBLP:journals/corr/abs-1912-00042}.
%We also value the capacity of normalizing flow to estimate the probability density of the observed data, which is not achievable with GAN.
%We train a global NF model with federated learning framework in the feature space of classifier for selective generative replay to avoid forgetting.
%By learning generative model in the feature level, we can reduce the complexity of generation, exploit more robust semantic information to reduce bias, and reduce raw data leakage to protect client privacy.
%The global NF model learns the feature of all seen tasks from all clients.
%When training the classifier locally, we generate feature vectors with NF model containing previous information.
%We also perform likelihood estimation for each generated feature vector with the local data through NF model.
%The classifier trained with local data and generated feature can remember the previous tasks.
%At the same time, using the likelihood as weight for loss function of generated feature, the classifier can adaptively learn more general feature while reduce the impact of biased feature and irrelevant feature.
%The classifier and NF model are both expected to be of increasing generalizability as training progresses.
%%We also estimate the likelihood of each generated feature vector belonging to local dataset.
%%By likelihood estimation, we quantify the relevance of 
%Besides, we apply knowledge distillation in the feature space to mitigate drastic drift so the training of NF model can be more stable.}
%\CS{This paragraph is too messy and disorganized, re-write it according the exiting papers (especially the paper ``learning without Prejudices.''). I prefer there is a picture assistly explains of our algorithm}
Instead of learning a generative adversarial network (GAN) for indiscriminate generative-replay in existing FCL methods~\citep{DBLP:conf/iclr/QiZ023}, \method~aims to facilitate a selective utilization of previous knowledge through \emph{correlation estimation}. 
In order to accurately identify benign knowledge from previous tasks, we achieve correlation estimation with a learned normalizing flow (NF) model~\citep{DBLP:conf/nips/DurkanB0P19,DBLP:journals/corr/abs-1912-00042, rezende2015variational} in feature space.
Specifically, an NF model could map an arbitrarily complex data distribution to a pre-defined distribution through a sequence of bijective transformations. Such invertability enables the NF to have a lossless memory of the input knowledge and accurately estimate the probability density of observed data.
%While a few clients could learn biased features (spurious correlation) from their heterogeneous data, we suggest common features learned by most clients are less likely to be biased. 
%In other words, the probability density of the feature distribution serves as a viable metric for ascertaining presence of bias within a particular feature.
While the information in the NF model could contain biased features or spurious correlation due to heterogeneous data, we suggest outlier features with respect to the current tasks are suspicious and may pose a threat to the learning process.
More precisely, the credibility of a particular feature could be quantified with its probability density in the current tasks.
% \CS{delete here}
% With the aforementioned analysis, we achieve \emph{accurate forgetting} through the following procedure: (\rom{1}) we infer the local feature distribution $p^{t}_{i}(h(x))$ of the current tasks with the learned NF model; (\rom{2}) we assess the likelihood $p^{t}_{i}(h(x^{0}))$ of the generated feature $h(x^0)$ pertaining to $p^{t}_{i}(h(x))$; (\rom{3}) we assign the weights of the generated features in the objective with the estimated likelihood. In this way, biased features are subject to precise forgetting owing to a relatively small probability value.
% With the aforementioned analysis, we achieve \emph{accurate forgetting} through the following procedure: (\rom{1}) we infer the local feature distribution of the current tasks with the learned NF model; (\rom{2}) we assess the likelihood of the generated feature pertaining to the local distribution; (\rom{3}) we assign the weights of the generated features in the objective with the estimated likelihood. In this way, biased features are subject to precise forgetting owing to a relatively small probability value.

% By utilizing this likelihood as a weight in the loss function of the generated feature, the classifier can adaptively learn more general features while reducing the influence of biased and irrelevant feature
%\cus{The proposed method incorporates \textit{feature generative-replay}, \textit{correlation estimation}, and \textit{knowledge distillation}, within a framework built upon the \textit{normalizing flow} (\textit{NF}) model.
%Normalizing flow, widely recognized for its ability to learn complex distributions through a sequence of bijective transformations, serves as the foundation of our approach~\citep{DBLP:conf/nips/DurkanB0P19,DBLP:journals/corr/abs-1912-00042, rezende2015variational}.
%Additionally, we highlight the capability of normalizing flow to accurately estimate the probability density of observed data, which is not achievable with GANs.
%(1) To prevent complete forgetting, we train a global NF model in the feature space of classifier for generative replay with federated learning framework.
%Inspired by the feature generation methods in federated learning~\citep{DBLP:conf/icml/ZhuHZ21, DBLP:conf/ijcai/WuKLHFPY22}, we train the NF model at the feature level.
%This approach offers several advantages: it reduces the complexity of generation, exploits more robust semantic information to mitigate bias, and avoid raw data leakage to ensure client privacy.
%The global NF model learns the features of all previously encountered tasks across all clients.
%During local classifier training, we utilize the NF model to generate feature vectors that encapsulate past information.
%(2) In order to accurately identify benign knowledge from previous tasks, we employ correlation estimation with NF model.
%The local data is transformed into the latent space of the NF model to estimate latent distribution.
%Subsequently, we assess the likelihood of the generated feature belonging to this local distribution.
%By utilizing this likelihood as a weight in the loss function of the generated feature, the classifier can adaptively learn more general features while reducing the influence of biased feature and irrelevant feature.
%As training progresses, the classifier and the NF model are both expected to improve their generalizability.
%(3) Additionally, we employ knowledge distillation in the feature space to mitigate significant drift, thereby enhancing the stability of the training process for the NF model.
%}\CS{too many unimportant contents, for example, feature generation and KD are not our novelty and could be deleted.}
Experimental results corroborate that \method~significantly outperforms all baselines on a series of benchmark datasets.
% \method~achieves outstanding performance not only in the setting of LTP, but also in common task reshuffling setting
We summarize our key contributions as follows:
\begin{itemize}
%\item \cs{We consider a more practical and \cs{challenging FCL setting.} We suggest the harm of remembering biased or irrelevant feature, which may be exacerbated due to statistical heterogeneity.}\CS{do you have experimental verification?}
\item We consider a more practical and challenging FCL setting. We suggest the harm of remembering biased or irrelevant features, which could be unavoidable in the federated scenario due to statistical heterogeneity.
\item We propose the concept \emph{accurate forgetting} and develop a novel generative method, \method.
%It selectively utilize previous information by correlation estimation from an NF model;
It adaptively mitigates erroneous information by correlation estimation with an NF model.
\item We conduct extensive experiments on a series of benchmark datasets. The results with ablation studies demonstrate the effectiveness and superiority of our proposed accurate forgetting over existing state-of-the-art methods.

% a novel method, \method, \cs{which selectively utilizes the previous knowledge for all clients}. We utilize the probability density estimation capacity of normalizing flow to mitigate the impact of biased feature from previous tasks of distinct clients.
% We propose to use normalizing flow model for generative replay in the feature space of classifier to adequately exploit semantic information and protect data privacy.
\end{itemize}
% The rest of this paper is organized as follows: Section 2 provides a brief overview of existing work. Section 3 formulates our problem. In Section 4, we present a verification of accurate forgetting phenomenon. Our method is in Section 6. The effectiveness of our method is further validated through experimental results in Section 6. Finally, we conclude the paper in Section 7.


\vspace{-.2cm}
\section{Related Work}
\vspace{-.2cm}
\textbf{Continual Learning}. 
% As a topic of extensive research, continual learning has witnessed the development of diverse methodologies~\citep{DBLP:journals/pami/LangeAMPJLST22}, which can be roughly divided into three families:
Continual learning has witnessed the development of diverse methodologies~\citep{DBLP:journals/pami/LangeAMPJLST22}, which can be roughly divided into three families:
% The methods can be roughly divided into three families: regularization-based methods, parameter isolation methods and replay-based methods~\citep{DBLP:journals/pami/LangeAMPJLST22}.
% Regularization-based methods circumvent the need to store raw inputs by incorporating an additional regularization term into the loss function.
%This regularization term helps consolidate previous knowledge while learning from new data.
(\rom{1}) Regularization-based methods: LwF employs the knowledge distillation loss, where the previous model's output is utilized as soft labels for the current tasks when working with new data~\citep{DBLP:conf/eccv/LiH16}.
%IMM~\citep{DBLP:conf/nips/LeeKJHZ17} utilize Gaussian mixture model framework to approximate the posterior distribution across multiple tasks.
Stable SGD~\citep{DBLP:conf/nips/MirzadehFPG20} demonstrated performance enhancements by calibrating pivotal hyperparameters and systematically reducing the learning rate upon the arrival of each task.
% Through the strategic allocation of model parameters to individual tasks, parameter isolation methods aim to mitigate potential catastrophic forgetting.
(\rom{2}) Parameter isolation methods: \cite{DBLP:journals/corr/RusuRDSKKPH16} suggested augmentation of the model with new branches tailored to incoming tasks.
% concurrently maintaining the previously established task parameters.
%Replay-based methods either preserve samples of previous tasks or synthesize pseudo-samples utilizing generative models.
% As a replay-based method, Continual Prototype Evolution (CoPE) combines the principles of the nearest-mean classifier with a reservoir-based sampling strategy~\citep{DBLP:conf/iccv/LangeT21}.
(\rom{3}) Replay-based methods: 
% Continual Prototype Evolution (CoPE) combines the principles of the nearest-mean classifier with a reservoir-based sampling strategy~\citep{DBLP:conf/iccv/LangeT21}.
%To avoid overfitting to a subset of retained samples, GEM applies constrained updates for new tasks such that they do not adversely affect prior tasks~\citep{DBLP:conf/nips/Lopez-PazR17}.
%Furthermore, while generative replay-based techniques fall under the category of replay-based methods, they eliminate the necessity for a replay buffer to store data. Rather, an auxiliary generator model the data distribution of acquired knowledge, producing synthetic data for replay in instances~\citep{DBLP:conf/icml/OdenaOS17, DBLP:conf/nips/WuHLWWR18}.
Generative replay-based methods use an auxiliary generator to model the data distribution of acquired knowledge, producing synthetic data for replay in instances~\citep{DBLP:conf/icml/OdenaOS17, DBLP:conf/nips/WuHLWWR18}.
%\CS{too long, too much useless sentences}
While existing research predominantly focused on the efficient memorization of past knowledge, we turn our attention to a more foundational question: \emph{is prior knowledge perpetually beneficial?}

%Regularization-based methods avoids storing raw inputs. Instead, they introduce an extra regularization term in the loss function, consolidating previous knowledge when learning on new data.
%LwF utilizes knowledge distillation loss, using the previous model output as soft labels for current tasks on the new data~\citep{DBLP:conf/eccv/LiH16}.
%IMM~\citep{DBLP:conf/nips/LeeKJHZ17} proposes to learn the posterior distribution for multiple tasks as a mixture of Gaussians.
%Stable SGD~\citep{DBLP:conf/nips/MirzadehFPG20} shows impressive performance gain through controlling essential hyperparameters and gradually decreasing learning rate each time a new task arrives.
%Parameter isolation methods dedicates different model parameters to each task, to prevent any possible forgetting.
%\cite{DBLP:journals/corr/RusuRDSKKPH16} propose to grow new branches for new tasks, while freezing previous task parameters.
%Replay-based methods stores samples in raw format or generates pseudo-samples with a generative model.
%Continual Prototype Evolution (CoPE) combines the nearest-mean classifier approach with an efficient reservoir-based sampling scheme~\citep{DBLP:conf/iccv/LangeT21}.
%GEM propose to avoid overfitting the subset of stored samples by only constraining new task updates to not interfere with previous tasks~\citep{DBLP:conf/nips/Lopez-PazR17}.
%In addition, the generative replay based methods belong to the replay-based methods, but they do not need a replay buffer for storing previous data. Instead, an additional generator is trained to capture the data distribution of data learnt so far, and it generates synthetic data for replay when the real data becomes unavailable~\citep{DBLP:conf/icml/OdenaOS17, DBLP:conf/nips/WuHLWWR18}.
%Existing continual learning methods rarely apply normalizing flow model for generative replay, the likelihood density estimation of generative models for feature learning also remains to explore.

\textbf{Federated Learning}. 
% \WE{delete here}
Federated learning represents a distributed learning paradigm among multiple clients and a central server.
% Federated learning represents a distributed learning paradigm with the objective of establishing a global model on a central server by aggregating the parameters trained at client nodes based on their local datasets.
%In recent years, federated learning has attracted increasing attention.
%Notable challenges associated with this domain encompass communication efficiency~\citep{konevcny2016federated}, privacy constraints~\citep{agarwal2018cpsgd}, and statistical heterogeneity~\citep{karimireddy2020scaffold}.
Researchers have been endeavoring to address the  statistical heterogeneity by developing a comprehensive global model~\citep{DBLP:conf/iclr/WangYSPK20}.
\cite{mohri2019agnostic} aimed to achieve a fair distribution of model performance by optimizing its efficacy across any given target distribution.
%\cite{DBLP:conf/iclr/WangYSPK20} propose novel aggregation strategies based on Bayesian non-parametric approaches.
% \cite{DBLP:conf/iclr/ShiLZTB23} incorporated a regularization term during local training to promote uncorrelated representations, thereby mitigating the risk of dimensional collapse.
% \cite{li2020federated} introduced a proximal term, aiming to ensure that local updates remain in proximity to the global model.
\cite{DBLP:conf/icml/ZhuHZ21} suggested the utilization of a generator to aggregate user information. This, in turn, guides the local training by employing the acquired knowledge as an inductive bias.
%\CS{too long, too much useless sentences}
In this work, we consider a more challenging learning problem associated with statistical heterogeneity in federated scenarios: how to facilitate collaboration when all clients are tackling different tasks?
% \cs{Federated learning methodologies operate within defined privacy constraints.
% Our approach formulates a generator within the feature space and exclusively transmits model parameters, adhering to these privacy restrictions.}

%Federated learning is a distributed learning framework, which aims to learn a global model on a server while aggregating the parameters learned at the clients on their private data.
%Recent years have witnessed growing attention to federated learning~\citep{mcmahan2017communication}, of which several challenges have been concerning topics including communication efficiency~\citep{konevcny2016federated}, privacy~\citep{agarwal2018cpsgd} and data heterogeneity~\citep{karimireddy2020scaffold}.
%There are researchers aiming to tackle the heterogeneity by learning a global model. \cite{mohri2019agnostic} seek a fair model performance distribution by maximizing the model performance on any arbitrary target distribution.
%\cite{DBLP:conf/iclr/WangYSPK20} introduce well-designed aggregation policies by leveraging Bayesian non-parametric methods.
%\cite{DBLP:conf/iclr/ShiLZTB23} applies a regularization term during local training that encourages uncorrelated representations to mitigate dimensional collapse.
%\cite{li2020federated} propose a proximal term to restrict the local updates to be closer to the initial model.
%\cite{DBLP:conf/icml/ZhuHZ21} proposes to learn a generator to ensemble user information to regulate local training using the learned knowledge as an inductive bias.
%Federated learning methods are subject to privacy constraints.
%Our method constructs generator in the feature space and only transmits model parameters, strictly following the privacy constraints.

\textbf{Federated Continual Learning}.
To date, there are a few studies in the domain of federated continual learning.
\cite{casado2020federated} studied the scenario of data distributions changing over time in federated learning.
Federated reconnaissance presented a scenario with incrementally new classes during training and proposed to utilize prototype networks~\citep{hendryx2021federated}.
\cite{guo2021new} proposed a regularization-based algorithm and a new theoretical framework for it.
\cite{DBLP:journals/corr/abs-2109-04197} presented a distillation-based method to deal with catastrophic forgetting, using previous model and global model as teachers for the training of local models.
\cite{yoon2021federated} proposed a novel parameter isolation method for the federated diagram, where the network weights are decomposed into global parameters and task-specific parameters.
\cite{DBLP:conf/cvpr/DongWFSXW022} considered a federated class-incremental setting and developed a distillation-based method to alleviate catastrophic forgetting from both local and global perspectives.
\cite{DBLP:conf/iclr/QiZ023} customized the generative replay based method ACGAN with model consolidation and consistency enforcement.
% Our method exhibits notable differences in several aspects compared to the aforementioned methods. 
% Firstly, we consider the issue of memorizing biased features due to statistical heterogeneity, a concern that potentially compromises the performance across all clients and tasks.
% Then, we propose to train an NF model in the facilitation of generative replay in feature space, aimed at realizing accurate forgetting.
% Furthermore, the likelihood of generated features pertaining to the local distribution estimated through the NF model is used to accurately pinpoint unbiased knowledge.
Our method considers the issue of memorizing biased feature due to statistical heterogeneity, exhibiting notable differences compared to the aforementioned methods.

% \cs{Firstly, We consider the issue of memorizing biased feature, which may be aggravated due to statistical heterogeneity in federated learning scenario.
% We propose to train normalizing flow model in the feature space for generative replay.
% And the probability density of feature estimated by normalizing flow model is used to adaptively select unbiased knowledge.}


% \section{Federated Continual Learning with \method}
\vspace{-.2cm}
\section{Problem Definition}
\vspace{-.2cm}
% In this section, we initially outline the problem definitions for CL and FL. Subsequently, we introduce the LTP setting for FCL.
% \vspace{-.2cm}
\subsection{Notations}
\vspace{-.1cm}
\label{sec:problem_definition}
\textbf{Continual Learning.} In standard continual learning scenario, there are a sequence of tasks $\mathcal{T}=\{\mathcal{T}^1, \mathcal{T}^2, \ldots, \mathcal{T}^T\}$, where $T$ is the number of tasks, and $\mathcal{T}^t$ is the $t$-th task.
Each dataset is composed of $n^t$ pairs of data and labels:  $D^t=\{x_k^t, y_k^t\}_{k=1}^{n^t}$.
When learning on the $t$-th task, one has no direct access to previous data $D^{t'}, t'<t$. The goal of continual learning is to effectively manage the current task while preserving its performance on all previous tasks:
%\begin{equation}
%\min\limits_{\theta^t}~[\mathcal{L}(\theta^t; \overline{\mathcal{T}}^1), \mathcal{L}(\theta^t; \overline{\mathcal{T}}^2),\ldots,\mathcal{L}(\theta^t; \overline{\mathcal{T}}^t)],
%\end{equation}
\begin{equation}
\min\limits_{\theta^t}~[\mathcal{L}(\theta^t; \mathcal{T}^1), \mathcal{L}(\theta^t; \mathcal{T}^2),\ldots,\mathcal{L}(\theta^t; \mathcal{T}^t)],
\end{equation}
where $\mathcal{L}$ is the risk objective of tasks and $\theta^t$ is the model parameters learned on the $t$-th task.
%\CS{adding an equation here.}
% Nevertheless, using data from exemplar memory bank or generative model is permitted.
% \CS{delete here}
% Continual learning typically falls under the following two settings~\citep{DBLP:conf/iccv/LangeT21}: (\rom{1}). \emph{task incremental learning}: it focuses on learning new tasks over time and the task IDs are accessible to learning algorithm; 
% (\rom{2}). \emph{class incremental learning}: new classes are introduced incrementally and there is no overlapped classes between any two tasks, i.e., $\{y_i^p\}_{i=1}^{n_p}\cap\{y_i^q\}_{i=1}^{n_q}=\emptyset, p\neq q.$ Task IDs are not accessible in this setting.
%\CS{adding more details, for example, class incremental learning cannot see task IDs?}
% Our method is applicablcannot e to both task incremental learning and class incremental learning settings.

\textbf{Federated Learning and Statistical Heterogeneity.} In federated learning scenario, there are $N$ clients, and each client owns a private dataset. %$D_{k}$.
The goal of federated learning is collaboratively learning models without accessing the datasets belonging to the local clients.
The data of clients consists of the input space $X_{i}$ and output space $Y_{i}$, where $X_{i}$ and $Y_{i}$ are shared across all clients.
There are $n_i$ samples in the $i$-th client denoted as $\left\{ x^{i}_{k}, y^{i}_{k} \right\}_{k=1}^{n_i}$.
Different clients may exhibit non-identical joint distributions $p(x, y)$ of features and labels, i.e., $p(x_{i_1}, y_{i_1}) \not= p(x_{i_2}, y_{i_2})$, where $i_1 \not= i_2$.

% e.g., there is a centralized server transmitting and receiving model parameters or gradients updated from clients.
% Suppose the risk objective of the $k$-th client $D_{k}$ is $l_k$.
% \WE{delete here}
% The classical federated learning algorithm FedAvg~\citep{mcmahan2017communication} assumes that data from all clients are i.i.d., and seeks to train a global model that minimizes the risk objectives over samples from all clients.
% However, the i.i.d.~assumption is largely violated as the local data distributions may be significantly distinctive~\citep{mohri2019agnostic}. 

% i.e., 
% \begin{equation}
% \min _{\theta} \quad \frac{1}{\sum_{k=1}^{N} n_{k}} \sum_{k=1}^{N} \sum_{i=1}^{n_{k}} l_{k}\left(h\left(x^{i}_{k}\right), y^{i}_{k}\right),
% \label{eq:fedavg}
% \end{equation}
% where $\theta$ denotes the model parameters. From Eq.(\ref{eq:fedavg}),
% The FedAvg algorithm assumes that data from all clients are i.i.d.
% It trains a local model in the client with a private dataset, and the parameters of local models are aggregated by weighted averaging in the server.

% \textbf{Statistical Heterogeneity} In reality, the i.i.d.~assumption is largely violated as the local data distributions may be significantly distinctive~\citep{mohri2019agnostic}. Different clients may exhibit non-identical joint distributions $p(x, y)$ of features and labels, i.e., $p(x_{k_1}, y_{k_1}) \not= p(x_{k_2}, y_{k_2}).$ ($k_1 \not= k_2$).

\vspace{-.2cm}
\subsection{Federated Continual Learning}
\vspace{-.2cm}
FCL refers to a practical learning scenario that melds the principles of federated learning and continual learning.
%Suppose there are $N$ clients, each client possesses a \cs{private series of datasets $\left\{ D^{t}_{k} \right\}_{t=1}^{T}$. The dataset $D^{t}_{k}$ at step $t$ corresponds to a particular learning task $\left\{ \mathcal{T}^{i}_{k} \right\}_{i=1}^{T} \subset \mathcal{T}$, where $\mathcal{T}$ denotes a limitless task pool (LTP).}
Suppose there are $N$ clients, and each client possesses a private series of datasets $\left\{ D^{t}_{k} \right\}_{t=1}^{T}$.
Please note that, at a given step $t$, client $k$ can only have access to $D_{k}^{t}$ as in continual learning.
In existing literature, the primary focus is on a specific task reshuffling setting, wherein the task set is identical for all users, yet the arrival sequence of tasks differs~\citep{DBLP:conf/icml/YoonJLYH21}.
In practical scenarios, it may be observed that the task set of clients is not necessarily correlated.
Thus we consider a practical setting, the limitless task pool (LTP), denoted as $\mathcal{T}$.
For each client, the dataset $D^{t}_{k}$ of the $k$-th client at step $t$ corresponds to a particular learning task $\mathcal{T}^{t}_{k} \subset \mathcal{T}$. There is no guaranteed relation among the tasks $\{\mathcal{T}_k^1,\mathcal{T}_k^2,\ldots,\mathcal{T}_k^T\}$ in the $k$-th client at different steps.
Similarly, at step $t$, there could be no relation among the tasks $\{\mathcal{T}_1^t,\mathcal{T}_2^t,\ldots,\mathcal{T}_N^t\}$ across different clients.

\textbf{Limitless Task Pool.}
In the setting of LTP, tasks are selected randomly from a substantial repository of tasks, creating a situation where two clients may not share any common tasks, i.e., $\left |\{\mathcal{T}_p^i\}_{i=1}^{t_p}\cap \{\mathcal{T}_q^i\}_{i=1}^{t_q}\right|\ge0,~p,q=1,2\ldots,N$.
More importantly, clients possess diverse joint distributions of data and labels $p(x,y)$ due to statistical heterogeneity.
Therefore, features learned from other clients could invariably introduce bias when applied to the current task.
% For instance, if the model learned to classify animals based on their color in previous tasks of other clients, but the current task requires classifying characters by their shape, the learned 'color' feature would become a bias for the current task.
% Due to the limitless task pool and statistical heterogeneity, it is possible for the model to memorize more biased or even harmful information from specific clients

%\CS{this paragraph detailly demonstrate the mechanism between bias and statistical heterogeneity.}

\textbf{Biased Features.} The bias originating from a particular client can adversely affect the performance of the model across different clients and a range of tasks. We tackle a more practical and challenging FCL problem that differs from the task reshuffling setting~\citep{DBLP:conf/icml/YoonJLYH21} from two perspectives: (\rom{1}) For different steps, tasks allocated to each client are randomly drawn from an extensive task pool.
(\rom{2}) For different clients, tasks across various clients may be unrelated or even contradictory in each step, consequently amplifying bias during the learning process.

Our goal is to facilitate the collaborative construction of the global model with parameters $\theta$.
Under the privacy constraint inherent in federated learning and continual learning, we aim to harmoniously learn current tasks while preserving performance on previous tasks for all clients, thereby seeking to optimize performance across all tasks seen so far by all clients, i.e.,
\begin{equation}
\vspace{-.2cm}
\min\limits_{\theta^t}~[\mathcal{S}^L_1,\mathcal{S}^L_2,\ldots\mathcal{S}^L_N], \text{where}~{S}^L_i=[\mathcal{L}(\theta^t; \mathcal{T}^1_i), \mathcal{L}(\theta^t; \mathcal{T}^2_i),\ldots,\mathcal{L}(\theta^t; \mathcal{T}^t_i)].
\vspace{-.2cm}
\end{equation}

\vspace{-.2cm}
\section{Validation of Accurate Forgetting}
\label{sec:4}
In this section, we present the results on a noisy dataset to intuitively demonstrate the effectiveness of our motivation and approach.
\vspace{-.2cm}
\subsection{Dataset with Label Noise}
\vspace{-.2cm}
We argue that forgetting is not invariably detrimental within the realm of FCL and propose the concept of accurate forgetting.
To validate our argument and the efficacy of our proposed method, we curate the EMNIST-noisy dataset, wherein a subset of noisy clients is simulated by introducing random labels to the data.
Additionally, we acknowledge the presence of noise in practical datasets, notably in the form of label noise.
% In the context of real-world applications, the robustness of FCL methods against such noise is crucial.

As a character image dataset, the EMNIST-noisy dataset comprises 8 clients, each encompassing 6 tasks, with each task containing 2 classes of character images.
We randomly select several clients and assign random labels for their initial three tasks, as displayed in Figure~\ref{fig:EMNIST_noisy_diagram}.
These incorrect labels have the potential to propagate adverse effects, affecting subsequent task learning across different clients through the memory bank.
After learning sequentially on all tasks, we evaluate the final three tasks, which do not contain any noisy labels.
This evaluation allows us to exclusively assess the impact of incorporating noisy information from previous tasks into the memory bank.
\vspace{-.2cm}
\subsection{Results}
\vspace{-.2cm}
The baselines in Figure~\ref{fig:EMNIST_noisy_result} are representative CL and FCL methods.
It is observed that: (\rom{1}) the performance of the baselines demonstrates inferiority compared to the naive FedAvg method; (\rom{2}) the performance of the baselines suffers a rapid deterioration with an increasing number of noisy clients.

These CL and FCL baseline methods are meticulously designed to effectively retain knowledge from previous tasks.
However, the presence of noisy clients introduces harmful information into the model learning process.
The memorization of such erroneous information proves detrimental to the overall performance.
Consequently, the baselines exhibit suboptimal performance compared to FL method, which does not employ explicit memorization techniques.
In contrast, our approach incorporates adaptive mechanisms to mitigate the impact of erroneous information.
By effectively alleviating the adverse influence of noisy clients, our method consistently surpasses all baselines.
Notably, the performance of our method maintains relative stability even with an increasing number of noisy clients in the dataset.
\begin{figure}[thbp]
\setlength{\abovecaptionskip}{-.1cm}
\setlength{\belowcaptionskip}{-.3cm}
\centering
\subfigure[Diagram of the dataset]{
\centering
\includegraphics[width=0.52\columnwidth]{figures/EMNIST_noisy_diagram.pdf}
\label{fig:EMNIST_noisy_diagram}
}
\hspace{0.1cm}
\subfigure[Accuracy of methods]{
\centering
\includegraphics[width=0.37\columnwidth]{figures/EMNIST_noisy_result.pdf}
\label{fig:EMNIST_noisy_result}
}
\caption{Illustration of the EMNIST-noisy dataset and results. (a) The initial several tasks in Client2 exhibit label noise.
% , which could propagate adverse effects on the subsequent task learning of other clients through the memory bank.
(b) The average accuracy of methods is presented with respect to an increasing number of malicious clients. The baseline methods are illustrated by dash-dotted lines, while our method is depicted with solid line.}
\label{fig:EMNIST_noisy}
\end{figure}
\vspace{-.2cm}
\section{Methodology}
\vspace{-.2cm}
% In this section, we firstly introduce the necessary preliminaries, including normalizing flow and its properties. Then, we will provide a detailed description of our method, \method.
\vspace{-.2cm}
\subsection{Preliminary: Normalizing Flow}
\vspace{-.2cm}
% Normalizing flow is a type of generative model that draw much attention in machine learning.
% It enables more flexible posterior approximations in the variational inference and supports more sophisticated generative models. 
% Normalizing flow model is able to map a complex, multi-modal distribution to a simple probability distribution such as standard Gaussian distribution through a sequence of smooth and invertible transformations~\citep{rezende2015variational}.
% Besides, it can estimate the probability density of data sample from the learned dataset.

% The NF model is a diffeomorphism $g$ composed of a series of invertible transformations $g=g_1\circ g_2\ldots\circ g_k$.
% Each transformation is specially designed to be invertible.
% Also, the determinant of the Jacobian matrix of the transformation can be efficiently computed.
% A widely applied transformation is affine coupling layer~\citep{DBLP:conf/nips/KingmaD18}.
% The input vector is partitioned into two halves $x_a$ and $x_b$.
% An affine transformation is applied to one part of the input, conditioned on the other part:

% \CS{use a figure to show the structure of NF, if it is possible.}
Normalizing flow is a type of generative model. It is able to map a complex, multi-modal distribution to a simple probability distribution such as standard Gaussian distribution through a sequence of smooth and invertible transformations~\citep{rezende2015variational}. In particular, an NF model is a diffeomorphism $g$ composed of a series of invertible transformations $g=g_1\circ g_2\ldots\circ g_k$, of which a widely applied transformation is affine coupling layer~\citep{DBLP:conf/nips/KingmaD18}.
% \WE{delete here}
% The Jacobian determinant of the affine coupling layer is easy to calculate: 
% \begin{equation}
% \left| \det \frac{\partial g_{l+1}}{\partial g_{l}}\right|=\exp\left(\sum_i s_i(x_{half})\right),
% \end{equation}
% where $s_{i}$ denotes functions that create scaling parameters, which can be implemented with neural networks and learned from the data. And $x_{half}$ denotes half of the input vector.

\textbf{Lossless Memory.}
Through meticulous design of the invertible layers, normalizing flow accomplishes a bijective transformation, preserving the one-to-one correspondence between the elements of the input and output spaces. 
% The invertability ensures a lossless memory of the original input.
The bijectivity ensures a lossless memory of the original input.
Consequently, this inherent property of NF is pivotal in enabling the accurate modeling of complex distributions, and stands central in generative applications.

%\CS{this paragraph high-lights that a normalizing flow could not loss any infromation because of the invertibility.}

\textbf{Exact Likelihood Estimation.} The invertibility enables precise estimation of the probability density of data samples within the learned dataset. Specifically, with a target dataset $Z=\{z_i\}_{i=1}^n, z_i\in\mathbb{R}^d$ and a prior distribution $p_u(u), u\in\mathbb{R}^d$, an NF model learns the diffeomorphism $g$ with the parameters $\phi$ that maps dataset distribution $p_z$ to the prior: $u=g(z)$.
Under above transformation, the probability density of the given datapoint $z$ can be computed as:
\begin{equation}
\log p_z(z)=\log p_u(u) + \log \left| \det \frac{\partial u}{\partial z}\right| =\log p_u(g(z))+\sum_{l=1}^{k-1} \log \left| \det \frac{\partial g^{l+1}}{\partial g^l}\right|,
\label{eq:nf_probability}
\vspace{-.2cm}
\end{equation}
where $g^l$ denotes input of the $l$-th transformation of NF model.
The transformations of the NF model are deliberately crafted to facilitate efficient computation of their Jacobian determinants $\left| \det \frac{\partial g^{l+1}}{\partial g^l}\right|$.
% The probability density estimation of any sample is performed with Eq.~\ref{eq:nf_probability} since $p_u(u)$ is tractable and Jacobian determinant of each transformation can be easily computed
A conditional NF model can take label $y$ as conditional information in likelihood estimation $p_z(z,y)$.

\textbf{The Training of NF Models.} The training objective of NF model is also derived from Eq.~\ref{eq:nf_probability}~, trained to maximize the likelihood of samples from target dataset $Z$, i.e.,
\begin{equation}
\mathcal{L}_{NF}(g; Z) = -\frac{1}{n}\sum_{i=1}^{n} \log p_z(z_i)=-\frac{1}{n}\sum_{i=1}^{n}\left(\log p_u(g(z_i))+\sum_{l=1}^{k-1} \log \left| \det \frac{\partial g^{l+1}_i}{\partial g^l_i}\right|\right).
\vspace{-.2cm}
\end{equation}
\begin{figure}[tbp]
\vspace{-.1cm}
\setlength{\abovecaptionskip}{-.1cm}
\setlength{\belowcaptionskip}{-.3cm}
\centering{
\includegraphics[width=0.85\columnwidth]{figures/method.pdf}}
\caption{
The diagram of training the classifier locally with our method. The training objective consists of three integral components: (\rom{1}) $\mathcal{L}_{ce}^g$, representing the objective for training using features generated and estimated probabilities derived from the global NF model; (\rom{2}) $L_{ce}^x$, corresponding to the objective for training using original data; (\rom{3}) $L_{KD}$, which denotes the objective for knowledge distillation within the feature space.}
\label{fig:method}
\vspace{-.1cm}
\end{figure}
\vspace{-.2cm}
\subsection{An Overview of \method}
\label{sec:4-2}
\vspace{-.2cm}
In FCL, statistical heterogeneity among clients brings extra challenges for continuously learning a sequence of tasks.
Especially in LTP setting, particular clients could possess unrelated tasks and biased dataset. When bias or spurious correlation from particular clients is memorized by the model, a decline in model performance may occur in the task sequences of all clients.
Therefore, a direct deployment of continual learning methods designed to mitigate catastrophic forgetting is hard to address the heterogeneity issues in FCL.

We propose a novel method~\method~, which adaptively utilizes memorized knowledge and learns unbiased feature for all clients under the FedAvg framework~\citep{mcmahan2017communication}. 
The training schematic of the classifier in each client is illustrated in Figure~\ref{fig:method}.
Overall, the implementation of \method~consists of the following components:
(\rom{1}) \textit{feature generative-replay}. To prevent complete forgetting, we train a global NF model in the feature space of classifier for generative replay.
% \WE{delete here}
% In local model training, we augment the learning process with the incorporation of generative feature learning.
% By generating in the feature space, we reduce the complexity of learning NF model, exploit more robust semantic information to mitigate bias, and avoid raw data leakage to ensure client privacy.
%The global NF model learns the features of all previously encountered tasks across all clients.
%During local classifier training, we utilize the NF model to generate feature vectors that encapsulate past information.
(\rom{2}) \textit{knowledge distillation}. Additionally, we employ knowledge distillation in the feature space to mitigate significant drift, thereby enhancing the stability of the training process for the NF model.
(\rom{3}) \textit{correlation estimation}. 
%In order to accurately identify benign knowledge from previous tasks, we employ correlation estimation with NF model.
We suggest that features exhibiting outlier characteristics with respect to the current tasks can potentially undermine the learning process.
Therefore, we assess the reliability of the generated feature by its probability density within the current tasks.
% \WE{delete here}
% Leveraging the NF model, we approximate the local feature distribution to evaluate the probability of a given generated feature aligning with the current distribution.
%\CS{a brief introduction of \method with a figure. explain why we do this. For example, 1. why we use a generative framework; 2. why we generate feature rather than the original data; 3. why we infer local distribution; 4\ldots.}
% In the following we elaborate on how biased feature may affect the federated continual learning and introduce our method.

% 说一下FCL的setting，其他client的记忆可能如何影响当前client的学习
%\cus{As introduced in Section~\ref{sec:problem_definition}, there are $N$ clients and a centralized server in federated continual learning.
%The private dataset of each client consists of a sequence of tasks $D_{k}=\{\mathcal{T}^1_k, \mathcal{T}^2_k, \ldots, \mathcal{T}^t_k\}$.
%Tasks of clients are selected randomly from a substantial repository of tasks $\mathcal{T}$.
%Then two clients may not share any tasks in common, i.e., $\left |\{T_p^i\}_{i=1}^{t_p}\cap \{T_q^i\}_{i=1}^{t_q}\right|\ge0,~p,q=1,2\ldots,N$.
%The federated algorithms construct a comprehensive global model capable of handling all the tasks of all participating clients.
%For example, \cite{mcmahan2017communication} propose FedAvg.
%The algorithm collaborative learns a global model $h$ for by minimizing the empirical risk over the samples from all clients:}
%\begin{equation}
%\min_{h\in\mathcal{H}}\frac{1}{\sum_{k=1}^N n^k}\sum_{k=1}^N\sum_{i=1}^{n_k}\mathcal{L}_{cls}\left(h(x_i^k, y_i^k)\right),
%\end{equation}
%\cus{where $\mathcal{L}_{cls}$ signifies the loss objective of clients, particularly denoting classification risk in this study.
%And $\mathcal{H}$ is the function space of $h$.
%To protect data privacy, local models are trained in the client with private dataset.
%And the parameters of local models are transmitted to the server then aggregated (by weighted averaging) and assigned to the global model.
%A simple strategy for addressing federated continual learning is to train the continual learning model with FedAvg.
%Continual learning methods aiming to address catastrophic forgetting seek to maintain the knowledge of previous tasks.
%However, machine learning models may remember bias feature while learning previous tasks.
%When applied in federated continual learning scenario, the issue may be exacerbated due to statistical heterogeneity among clients.
%The tasks of two clients could be fundamentally disparate.
%The memorized knowledge from other clients may be irrelevant or even biased feature for current task.
%When learning the classifier locally on current task, utilizing such knowledge could result in a biased model.
%For example, in Figure 1\ldots.
%Therefore, memorizing all knowledge without discrimination in federated continual learning is highly probable to fall short of achieving optimal performance.
%We propose \textit{accurate forgetting} with exact likelihood estimation by normalizing flow model.}
%\CS{too many repeated sentences, same meaning as in previous content, I suggest delete all of them.}

\vspace{-.2cm}
\subsection{Accurate Forgetting for heterogeneous FCL}
\vspace{-.2cm}
The above Sec.\ref{sec:4-2}~gives an overview of our method. In this section, we provide a detailed description of~\method~and how it is implemented.

\textbf{Generative-replay in Feature Space.} We consider the classification tasks, where we need to train a classifier with $L$ layers: $h=\{h_1,h_2,\ldots,h_L\}$.
We split the classifier into three sub-modules:
$h_a=\{h_1,h_2,\ldots,h_l\},~h_b=\{h_{l+1},\ldots,h_{L-1}\},~h_c=\{h_L\}$.
The $h_a$ and $h_b$ are two successive feature extractors, $h_c$ is the classifier head.
To maintain the performance on previous tasks, we train a conditional normalizing flow model $g$ in the feature space, which is the output space of $h_a$. In this way, the normalizing flow model retains the feature of previous tasks.
The NF model $g$ is trained globally with FedAvg algorithm using client datasets and sampled data:
\begin{equation}
\widetilde{\mathcal{L}}_{NF}(g; D_k^t, G_z) = -\frac{1}{|D_k^t|}\sum_{x_i,y_i\sim D_k^t} \log p_z(h_a(x_i), y_i)-\frac{1}{|G_z|}\sum_{z_i,y_i\sim G_z} \log p_z(z_i, y_i),
\label{eq:nf_loss}
\end{equation}
where $D_k^t$ is the dataset of the $t$-th task in the $k$-th client, and $p_z$ is the likelihood calculated as in Eq.~\ref{eq:nf_probability}. $G_z$ is the feature set sampled from NF model $g'$ ($g'$ is the stored NF model after training on the last task), so that the current NF model avoids forgetting previous features.

Normalizing flows operate within a latent space that maintains dimensional parity with the target data space.
Training the NF model in high-dimensional data space $X$ could be computationally intensive.
Furthermore, the inherent sparsity of raw data can hinder the NF model's capacity to obtain a representative sample of the data distribution~\citep{brehmer2020flows}.
Therefore, we train the NF model in the compact, low-dimensional feature space as opposed to the data space, thereby reducing the complexity of generation.
% Besides, learning in feature space avoids the danger of leaking raw data through generative model, thus protecting data privacy~\citep{DBLP:conf/ijcai/WuKLHFPY22}.
% Besides, learning in feature space can mitigate the danger of leaking raw data, thus protecting data privacy to some extent~\citep{DBLP:conf/ijcai/WuKLHFPY22}.

We also leverage the feature space to extract more robust semantic information.
%\cus{We train the NF model in the feature space instead of data space for three reasons: (1) Data privacy is crucial in federated learning. Learning a generative model of raw data is in danger of leaking data. (2) We aim to exploit more robust semantic information in the feature space. (3) Learning NF model in the feature space can reduce the complexity of generation.} 
%\CS{such brief demonstration should be put in sec 4.2. Here you need a more detailed description. For example, why reducing compleixty is important? (because learning an NF model is hard). and so on.}

\textbf{Knowledge Distillation for a Consistent Feature Distribution.} 
The NF model is trained in the feature space of classifier to maintain previous knowledge.
The NF model retains knowledge from previous tasks, conveying it to the classifier via feature generation.
Yet, feature extractor of the classifier undergoes continual modifications throughout the training process.
If the feature space of the classifier drifts significantly, the knowledge memorized by the NF model may become obsolete.

Therefore, the feature space of the classifier needs to retain relative consistency during the training.
We propose to apply knowledge distillation in the feature space of the classifier to control the drift of feature distribution:
\begin{equation}
\mathcal{L}_{KD}(h; D_k^t)=\frac{1}{n_k^t}\sum_{i=1}^{n_k^t}||h_a(x_i)-h_a'(x_i)||^2,
\end{equation}
where $h_a'$ is the stored classifier feature extractor after training on the last task. 
%\CS{ use chatGPT to revise the content. KD is an important component of our method. Here need more details. If you do not know what to write, refer to existing works.}

\textbf{Correlation Estimation for Accurate Forgetting.} From the above, we train the classifier with the aid of NF model by generating features.
However, utilizing previous knowledge without discrimination may lead to biased model as stated before.
Thus we propose to accurately exploit the memorized knowledge with the characteristics of the NF model for correlation estimation. In particular, when training the classifier for the $t$-th task of client $k$, we firstly map the feature of local data to the latent space of normalizing flow, i.e., $\hat{U}_k^t=\{u_i=g(h_a(x_i))\}_{i=1}^{n_k^t},~x_i\in D_k^t$.
% \begin{equation}
% \hat{U}_k^t=\{u_i=g(h_a(x_i))\}_{i=1}^{n_k^t},~x_i\in D_k^t.
% \end{equation}
%\CS{the above equation is empirical distribution. use hat to denote} 
As the NF models transform the features to a disentangled latent space, which is the centered isotropic multivariate Gaussian. Therefore, we approximate the true distribution $U_k^t$ in each class as a multivariate Gaussian with a diagonal covariance structure. 
%\CS{diagonal cov is because of the property of NF, not our assumption. The above content need to modify.}.
The mean vector $\mu_k^t$ and covariance matrix $\Sigma_k^t$ of $\hat{U}_k^t$ can be easily computed by
\begin{equation}
\begin{aligned}
\mu_k^t=\frac{1}{n_k^t}\sum_{i=1}^{n_k^t}u_i,~~~\Sigma_k^t=\frac{1}{n_k^t}\sum_{i=1}^{n_k^t}\text{diag}(u_i-\mu_k^t)\cdot\text{diag}(u_i-\mu_k^t),~u_i\in \hat{U}_k^t,
\label{eq:nf_mean_std}
\end{aligned}
\end{equation}
where $\text{diag}(u)$ turns the vector $u$ into a diagonal matrix.

For generative replay, we sample a batch of latent vectors in the NF model and project them to feature space: $\bar{U}_g = \{\bar{u}_i, ~\bar{z}_i=g^{-1}(\bar{u}_i),~\bar{y}_i\}_{i=1}^n,~\bar{u}_i\in p_u$.
Please note that we use bar superscripts to denote generated data.
The generated features from NF model represent the knowledge of previous tasks among all clients.
However, in FCL scenario, there may exist irrelevant or even biased feature from other clients due to statistical heterogeneity. Enhancing the memorizing of biased feature could cause subpar performance or even failing to converge.
Considering that outlier features with respect to the current tasks could be unreliable, we quantify the credibility of generated feature with its relevance to local dataset.
To evaluate the correlation between the generated feature and the current task, we propose to use the the probability density of the sampled latent vector $\bar{u}_{i}$ within the current feature distribution quantified in Eq.(\ref{eq:nf_mean_std}), i.e.,
\begin{equation} 
p_{D_k^t}(\bar{u}_i) = \frac{1}{\sqrt{(2\pi)^d|\Sigma_k^t|}}\text{exp}\left(-\frac{1}{2}(\bar{u}_i-\mu_k^t)^T(\Sigma_k^t)^{-1}(\bar{u}_i-\mu_k^t)\right)
\label{eq:nf_generate_prob}
\end{equation}
%\CS{use an equation to denote how to compute.}
% To precisely select the benign and advantageous feature, we compute the probability of each sample $\hat{u}_i$  $\mathcal{U}_k^t$ with the parameters from Eq.~\ref{eq:nf_mean_std}~.
The probability $p_{D_k^t}(\bar{u}_i)$ above quantifies the degree of correlation between the current task in the local client and the sampled features from NF model.
We use the correlation probability of the generated features to re-weight the loss objective $\mathcal{L}_{ce}^g$.
And the final objective $\mathcal{L}_{cls}$ consisting of three terms is as follows:
\begin{equation}
\begin{aligned}
\mathcal{L}_{ce}^x(h; D_k^t)=&\frac{1}{n_k^t}\sum_{i=1}^{n_k^t} \mathcal{L}_{ce}(h(x_i), y_i),\\
\mathcal{L}_{ce}^g(h; \bar{U}_g)=&\frac{1}{n}\sum_{\bar{u}_i\in \bar{U}_g}p_{D_k^t}(\bar{u}_i)\mathcal{L}_{ce}(h_{b,c}(g^{-1}(\bar{u}_i)), \bar{y}_i),\\
\mathcal{L}_{cls}(h; D_k^t, \bar{U}_g) =& \mathcal{L}_{ce}^x(h; D_k^t)+\mathcal{L}_{ce}^g(h; \bar{U}_g)+\mathcal{L}_{KD}(h; D_k^t)\\
\end{aligned}
\label{eq:cls_loss}
\end{equation}
where $\mathcal{L}_{ce}^x(h; D_k^t)$ denotes the cross-entropy loss of raw dataset, and $\mathcal{L}_{ce}^g(h; \bar{U}_g)$ denotes the unbiased objective of generated data.
%\CS{$L_{KD}$ must have input in the equation.}
% By utilizing the exact probability of sampled features, we seek to reduce the adverse effects of biased or irrelevant feature from other clients.
% At the same time, the classifier memorizes the benign feature of previous tasks
With the proposed method, the classifier learns beneficial features from previous tasks and accurately forgetting biased features. Moreover, the NF model memorizes more benign features. Both the NF model and the classifier are expected to be of increasing generalizability with the advancement of training progress. The implementation of \method~ is in Algorithm~\ref{alg:1}.

\vspace{-.2cm}
\section{Experiments}
\vspace{-.2cm}
\subsection{Experimental Settings and Evaluations}
\vspace{-.2cm}
\textbf{Datasets and Settings.} We curate three FCL datasets with different settings. We use $N$ to denote the number of clients, $T$ to denote the number of tasks in each client, $C$ to denote the number of classes in each task. For the EMNIST-based dataset containing 26 classes of handwritten letter images~\citep{cohen2017emnist}, we set the following two settings with $N$=8, $T$=6, $C$=2.
\textbf{1) EMNIST-LTP:} in LTP setting, we randomly sampled classes from the entire dataset for each client.
\textbf{2) EMNIST-shuffle:} in conventional shuffle setting, the task sets are consistent across all clients, while arranged in different orders.
% \textbf{3) EMNIST-noisy:} we set a few noisy clients in the EMNIST-LTP dataset which are assigned random labels to the data.
\textbf{3) CIFAR100}: We randomly sample 20 classes among 100 classes of CIFAR100~\citep{krizhevsky2009learning} as a task for each of the 10 clients, and there are 4 tasks for each client ($N=10, T=4, C=20$).
\textbf{4) MNIST-SVHN-F}: We set 10 clients with this mixed dataset. Each client contains 6 tasks, and each task has 3 classes.

\textbf{Metrics.} We use the metrics of accuracy and average forgetting for evaluation following recent works~\citep{DBLP:conf/iclr/MirzadehFGP021, DBLP:conf/icml/YoonJLYH21}. \textbf{Average forgetting} assesses the extend of backward transfer during continual learning, quantified as the disparity between the peak accuracy and the ending accuracy of each task.

\vspace{-.2cm}
\subsection{baselines}
\vspace{-.2cm}
We compare our method~\method~with baselines from FL, CL and FCL.
In FL, we consider two representative models \textbf{FedAvg}~\citep{mcmahan2017communication} and \textbf{FedProx}~\citep{li2020federated}.
In CL, \textbf{PODNet} incorporates a spatial-based distillation loss onto the feature maps of the classifier~\citep{douillard2020podnet}.
\textbf{ACGAN-Replay} employs a GAN-based generative replay method ~\citep{DBLP:conf/nips/WuHLWWR18}.
The CL models are respectively combined with the FL models.
In FCL, \textbf{FLwF2T} leverages the concept of knowledge distillation within the framework of federated learning~\citep{DBLP:journals/corr/abs-2109-04197}.
\textbf{FedCIL} extends the ACGAN-Replay method within the federated scenario~\citep{DBLP:conf/iclr/QiZ023}.
\textbf{GLFC} exploits a distillation-based method to alleviate the issue of catastrophic forgetting from both local and global perspectives~\citep{DBLP:conf/cvpr/DongWFSXW022}.

\begin{table}[tbhp]
\centering
\setlength{\abovecaptionskip}{-.3cm}
\setlength{\belowcaptionskip}{-1pt}
\caption{Average accuracy and forgetting on EMNIST-LTP and EMNIST-shuffle dataset. }
%\resizebox{\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c}{EMNIST-LTP} & \multicolumn{2}{c}{EMNIST-shuffle}  \\
\cmidrule(r){2-3} \cmidrule(r){4-5} & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ \\
\hline
FedAvg & 32.5$_{\pm 0.9}$ & 20.8$_{\pm 0.8}$ & 70.3$_{\pm 0.4}$ & 4.9$_{\pm 0.6}$\\
FedProx & 35.3$_{\pm 0.5}$ & 19.2$_{\pm 0.6}$ & 69.4$_{\pm 0.9}$ & 6.0$_{\pm 1.3}$\\
\hline
PODNet+FedAvg  & 36.9$_{\pm 1.3}$ & 19.8$_{\pm 0.9}$ & 71.0$_{\pm 0.4}$ & \textbf{3.9}$_{\pm 0.4}$\\
PODNet+FedProx  & 40.4$_{\pm 0.4}$ & 14.3$_{\pm 0.5}$ & 70.6$_{\pm 0.7}$ & 9.6$_{\pm 0.3}$ \\
ACGAN-Replay+FedAvg  & 38.4$_{\pm 0.2}$ & 9.8$_{\pm 0.8}$ & 70.0$_{\pm 0.5}$ & 4.7$_{\pm 0.3}$ \\
ACGAN-Replay+FedProx & 41.3$_{\pm 0.9}$ & 10.4$_{\pm 0.7}$ & 70.3$_{\pm 1.2}$ & 6.1$_{\pm 2.0}$\\
\hline
FLwF2T  & 40.1$_{\pm 0.3}$ & 15.5$_{\pm 0.5}$ & 71.0$_{\pm 0.9}$ & 8.1$_{\pm 0.8}$\\
FedCIL  & 42.0$_{\pm 0.6}$ & 12.4$_{\pm 0.3}$ & 71.1$_{\pm 0.4}$ & 6.4$_{\pm 0.2}$\\
GLFC & 40.1$_{\pm 0.8}$ & 14.3$_{\pm 0.5}$ & 74.9$_{\pm 0.6}$ & 5.6$_{\pm 0.7}$\\
\method  & \textbf{47.5}$_{\pm 0.3}$ & \textbf{7.9}$_{\pm 0.5}$  & \textbf{75.8}$_{\pm 0.2}$ & 4.2$_{\pm 0.1}$\\
\bottomrule
\end{tabular}
\label{table:emnist_ltp_shuffle}
%\vspace{-.3cm}
\end{table}


\vspace{-.2cm}
\subsection{Experiments on EMNIST-based Datasets}
\vspace{-.2cm}
\textbf{EMNIST-LTP}.
In this dataset, clients may encompass unrelated tasks, thus rendering the dataset challenging.
As the results shown in Table~\ref{table:emnist_ltp_shuffle}, some of the CL methods integrated with FL algorithms demonstrate comparable performance to that of FCL methods in the EMNIST-LTP dataset.
For instance, the average accuracy of ACGAN-Replay+FedProx is 41.3\%, higher than two FCL methods FLwF2T and GLFC.
This phenomenon can be attributed to challenge posed by the elevated degree of heterogeneity under the LTP setting, which is difficult for these FCL methods to deal with, consequently diminishing their inherent advantages.
Nevertheless, our method outperforms all the baselines in the EMNIST-LTP dataset.
We argue that statistical heterogeneity in federated networks inevitably results in biased information residing in the memory bank.
Both CL methods and existing FCL methods assume that memorization is beneficial, potentially losing their advantages under LTP setting.
%We argue that strengthening the memorization of unrelated previous information from other clients, as commonly practiced in existing FCL methods, could result in learning biased features, detrimentally impacting performance.
Our method adopts accurate forgetting to mitigate the negative impact of heterogeneity and selectively encourages the forgetting of malign information.
It shows the highest accuracy rate and lowest forgetting rate.

\textbf{EMNIST-shuffle.}
Different from the EMNIST-LTP dataset, EMNIST-shuffle represents a more tractable dataset within the conventional setting, resulting in higher overall accuracy rates as in Table~\ref{table:emnist_ltp_shuffle}.
The FCL methods exhibit superior accuracy compared to CL methods, underscoring their strength.
And our method still showcases a superior capacity than all baselines in this commonly adopted dataset setting.

% \textbf{EMNIST-noisy}. We conduct experiments in the EMNIST-noisy dataset with an increasing number of noisy clients.
% It is observed that the performance of the methods consistently diminishes with the escalating count of noisy clients, as depicted in Table~\ref{table:emnist_malicious}.
% The presence of noisy clients introduce harmful information into the model learning process and memorization of such information proves detrimental to the overall performance.
% Thus, some of the CL and FCL methods, which aim to fight forgetting, exhibit inferior performance compared to FL methods.
% Our approach employs adaptive mechanisms to mitigate the impact of erroneous information.
% By alleviating the negative influence of noisy clients, our method consistently surpasses all baselines in both accuracy and resistance to forgetting.


\vspace{-.2cm}
\subsection{Experiments on More Complicated Datasets}
\vspace{-.2cm}
CIFAR100 comprises 100 classes of images.
The composite dataset MNIST-SVHN-F comprises two distinct digit classification datasets: MNIST and SVHN, characterized by complex colors and backgrounds, along with a clothing image classification dataset. 
% both of these datasets exhibit a higher level of complexity compared to the original MNIST datasets.
% MNIST-SVHN-F is composed of two digit classification dataset, with SVHN presents complex color and backgrounds, and a clothing image classification dataset. Both datasets are much complicited than MNIST datasets.
Table~\ref{table:cifar100_msf} displays the results of these two challenging datasets CIFAR100 and MNIST-SVHN-F.
Different tasks exhibit reliance on varying features. For instance, shape features pertinent to digits differ significantly from those relevant to clothing classification.
A naive collaboration among clients may lead to a model overly reliant on spurious correlations, overlooking the importance of task-specific features.
We suggest a strategy of selective utilization and memorization of learned feature. By relying on the generated features with a higher correlation, \method~significantly exceeds the performance of baselines.

\begin{table}[tbhp]
\centering
\setlength{\abovecaptionskip}{-.3cm}
\setlength{\belowcaptionskip}{-1pt}
\caption{Average accuracy and forgetting on CIFAR100 and MNIST-SVHN-F dataset. }
%	\resizebox{1.05\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c}{CIFAR100} & \multicolumn{2}{c}{MNIST-SVHN-F}  \\
\cmidrule(r){2-3} \cmidrule(r){4-5} & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ \\
\hline
FedAvg & 26.3$_{\pm 2.5}$ & 8.4$_{\pm 1.2}$ & 55.7$_{\pm 1.4}$ & 21.9$_{\pm 0.9}$\\
FedProx  & 28.7$_{\pm 1.4}$ & 8.2$_{\pm 1.0}$ & 56.1$_{\pm 1.0}$ & 21.3$_{\pm 1.8}$\\
\hline
PODNet+FedAvg & 30.5$_{\pm 0.8}$ & 8.6$_{\pm 1.7}$ & 54.2$_{\pm 0.8}$ & 20.6$_{\pm 1.5}$\\
PODNet+FedProx & 32.5$_{\pm 0.5}$ & 6.4$_{\pm 0.4}$ & 56.4$_{\pm 0.4}$ & 20.0$_{\pm 1.2}$ \\
ACGAN-Replay+FedAvg & 32.1$_{\pm 1.6}$ & 5.4$_{\pm 1.1}$ & 56.0$_{\pm 0.7}$ & 21.4$_{\pm 0.8}$\\
ACGAN-Replay+FedProx & 31.8$_{\pm 0.7}$ & 6.2$_{\pm 1.2}$ & 56.4$_{\pm 2.1}$ & 22.1$_{\pm 1.4}$\\
\hline
FLwF2T & 30.2$_{\pm 0.7}$ & 7.2$_{\pm 1.8}$ & 54.2$_{\pm 0.6}$ & 25.6$_{\pm 0.5}$\\
FedCIL & 33.5$_{\pm 0.7}$ & 6.5$_{\pm 1.0}$ & 57.2$_{\pm 1.7}$ & 19.7$_{\pm 1.0}$\\
GLFC & 35.6$_{\pm 0.6}$ & 6.2$_{\pm 0.7}$ & 61.8$_{\pm 0.8}$ & 10.8$_{\pm 1.3}$\\
\method & \textbf{36.3}$_{\pm 0.4}$ & \textbf{4.9}$_{\pm 0.1}$ &  \textbf{68.1}$_{\pm 0.9}$ & \textbf{7.5}$_{\pm 1.0}$\\
\bottomrule
\end{tabular}
\label{table:cifar100_msf}
%\vspace{-.3cm}
\end{table}
\vspace{-.3cm}
\section{Conclusion}
\vspace{-.3cm}
In this study, we navigate the challenges of continual learning in real-world federated contexts, specifically when faced with data or task streams that might be biased or noisy across clients. Current research in continual learning emphasizes the adverse consequences of "catastrophic forgetting". However, we advocate for a perspective that reveals the merit of selective forgetting, especially as a mechanism to mitigate the biased information induced by statistical heterogeneity in reality. Inspired by it, we present a generative framework, termed as \method, meticulously crafted to achieve targeted forgetting by re-weighting generated features based on inferred correlations. The experimental results clearly demonstrate its effectiveness.
% In the future, we'll look into how intentional forgetting interacts with challenges like uneven labeled data and statistical heterogeneity, making it an interesting area for more research.

\section{Acknowledgments*}
This work is funded by the Natural Science Fundation of China(NSFC. No. 62176132) and the Guoqiang Institute of Tsinghua University, with Grant No. 2020GQG0005.
MS was supported by JST CREST Grant Number JPMJCR18A2 and a grant from Apple, Inc. Any views, opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and should not be interpreted as reflecting the views, policies or position, either expressed or implied, of Apple Inc.
BH was supported by the NSFC General Program No. 62376235 and CCF-Baidu Open Fund.

\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\appendix
\section{Datasets}
We construct a series of datasets comprising multiple federated clients, with each client possessing a sequence of tasks.
Suppose we use $N$ to denote the number of clients, $T$ to denote the number of tasks in each client, $C$ to denote the number of classes in each task.
We curate tasks by randomly selecting several classes from the datasets and sample part of the instances from these classes.
Adhering to the principle of class incremental learning, there are no overlapped classes between any two tasks within a client.

\textbf{EMNIST-LTP.} The EMNIST dataset is a character classification dataset with 26 classes~\citep{cohen2017emnist}.
It contains 145600 instances of 26 English letters.
The data contains both upper and lower case with the same label, making it more challenging for classification.
To curate a dataset under LTP setting, we randomly sampled classes from the entire dataset for each client.
The EMNIST-LTP dataset consists of 8 clients, with each client encompassing 6 tasks, each task comprising 2 classes ($N=8, T=6, C=2$).

\textbf{EMNIST-shuffle.} 
In conventional reshuffling setting, the task sets are consistent across all clients, while arranged in different orders.
Therefore, with the same structure as EMNIST-LTP, we construct EMNIST-shuffle dataset with 8 clients, 6 tasks each, and each task comprising 2 classes.
While the 6 tasks of all clients are the same but in shuffled orders.

\textbf{EMNIST-noisy.} 
In this paper, we argue that forgetting is not invariably detrimental in FCL and propose the concept of accurate forgetting.
To validate our argument and effectiveness of our method, we curate the EMNIST-noisy dataset with a few malicious clients by assigning random labels to the data.
Besides, there could be noise in realistic dataset, including label noise.
And malicious clients with adversarial behavior should also be taken into consideration under cross-device setting in Federate Learning.
Robustness of FCL methods is crucial in real-world application.
The EMNIST-noisy possesses the same structure as EMNIST-LTP dataset ($N=8, T=6, C=2$).
We randomly selects several clients and assign random labels to their first three tasks.
After learning sequentially on all tasks, we evaluate on the last three tasks without noisy labels.
By this means, we assess the impact of incorporating noisy information into the memory bank from previous tasks.

\textbf{CIFAR100.} 
As a challenging image classification dataset, CIFAR100 consists of low resolution images containing various objects and complex image backgrounds~\citep{krizhevsky2009learning}.
We randomly sample 20 classes among 100 classes of CIFAR100 as a task for each of the 10 clients, and there are 4 tasks for each client ($N=10, T=4, C=20$).
For each class, we randomly sample 400 instances into the client dataset.

\textbf{MNIST-SVHN-F.} 
The mixed dataset is constructed with MNIST~\citep{lecun1998gradient}, SVHN~\citep{netzer2011reading} and FashionMNIST~\citep{DBLP:journals/corr/abs-1708-07747}.
Similar to MNIST, SVHN dataset serves as a benchmark for digit classification tasks, notable for its representation of real-world scenarios with complex backgrounds.
We unify the labels of these two datasets.
FashionMNIST dataset is designed for clothing image classification.
We set 10 clients in the mixed dataset, with each client containing 6 tasks, and each task has 3 classes. ($N=10, T=6, C=3$).
In this mixed dataset, different tasks rely on different features. For example, shape features that are relevant to digit classification differ significantly from those that are important for classifying clothing items. If clients collaborate naively, it may result in a model that relies too heavily on spurious correlations, thus neglecting the significance of task-specific features.

\section{Baselines}
We compare our method~\method~with two baselines from FL, two baselines from CL and three baselines from FCL.
The FL methods simply train a global model on sequential tasks, without any memorizing technique.
The CL methods are respectively combined with the FL methods, training a global model while fighting catastrophic forgetting.
The FCL methods focus on addressing the issues of catastrophic forgetting along with statistical heterogeneity.

\textbf{FedAvg}~\citep{mcmahan2017communication}. As a representative FL method, FedAvg trains the models in each client with local dataset and averages their parameters to attain a global model.

\textbf{FedProx}~\citep{li2020federated}.
The algorithm is similiar to FedAvg.
While training local models, a regularization term is employed to govern the proximity between the local parameters and the global parameters.
This regularization term serves to effectively control the degree of deviation exhibited by the local models from the global model during the training process.

\textbf{PODNet}~\citep{douillard2020podnet}.
As a CL method, the algorithm incorporates a spatial-based distillation loss onto the feature maps of the classifier.
This loss term serves to encourage the local models to align their respective feature maps with those of the previous model, thereby maintaining the performance in previous tasks.

\textbf{ACGAN-Replay}. 
This CL algorithm employs a GAN-based generative replay method ~\citep{DBLP:conf/nips/WuHLWWR18}.
The algorithm trains an ACGAN in the data space to memorize the distribution of previous tasks.
While learning on new tasks, the classifier is trained on new task data along with generated data from ACGAN.

\textbf{FLwF2T}.
As a FCL algorithm, FLwF2T leverages the concept of knowledge distillation within the framework of federated learning~\citep{DBLP:journals/corr/abs-2109-04197}.
It employs both the old classifier from previous task and global classifier from server to train the local classifier.

\textbf{FedCIL}.
The FCL algorithm extends the ACGAN-Replay method within the federated scenario, addressing the statistical heterogeneity issue with distillation loss~\citep{DBLP:conf/iclr/QiZ023}.


\textbf{GLFC}. In FCL scenario, the algorithm exploits a distillation-based method to alleviate the issue of catastrophic forgetting from both local and global perspectives~\citep{DBLP:conf/cvpr/DongWFSXW022}.

\section{Implementation Details}
\subsection{Algorithm}
The algorithm of our method is detailed in Algorighm~\ref{alg:1}.

\begin{algorithm}[t]
\setlength{\belowcaptionskip}{-5pt}
\caption{Federated continual learning framework \method}
\hspace*{0.02in} {\bf Input:}
Datasets of $T$ tasks for $N$ clients $\{D_1, D_2,\ldots,D_N\}$, $D_{k}=\{\mathcal{T}^1_k, \mathcal{T}^2_k, \ldots, \mathcal{T}^t_k\}$, classifier $h$ and normalizing flow model $g$;
\begin{algorithmic}[1]
\FOR{task $t=1,2,\ldots,T$}
\STATE $h'\leftarrow h;~g'\leftarrow g$
\FOR{round $r=1,2,\ldots$}
\STATE \textbf{Server} randomly selects clients $\mathcal{C}$ for local training and send them model parameters
\FOR{client $\mathcal{C}_k\in\mathcal{C}$}
\STATE Optimize $g$ as in Eq.~\ref{eq:nf_loss}~ with client dataset $\mathcal{D}^t_k$ and $g'$
\STATE Calculate distribution parameters of client data with $g$ as in Eq.~\ref{eq:nf_mean_std}
\STATE Generate features $\bar{u}_i$ with $g$ and perform likelihood estimation with above parameters
\STATE Optimize $h$ as in Eq.~\ref{eq:cls_loss}~with client dataset, generated features, exact likelihood $p_{D_k^t}(\bar{u}_i)$ and $h'$
\ENDFOR
\STATE the {\bf Server} aggregates the parameters of $h^{i}_\theta$ and $g^{i}_\phi$ from clients $\mathcal{C}$ and weighted averages the parameters by client data number
\ENDFOR
\ENDFOR

\STATE \textbf{Output:} the learned classification model $h$.
\end{algorithmic}
\label{alg:1}
\end{algorithm}

\subsection{Metrics}
We use the metrics of accuracy and average forgetting for evaluation following recent works~\citep{DBLP:conf/iclr/MirzadehFGP021, DBLP:conf/icml/YoonJLYH21}. 
Suppose $a_{k}^{t,i}$ is the test set accuracy of the $i-$th task after learning the $t-$th task in client $k$.

\textbf{Average Accuracy.}
We evaluate the performance of the model on all tasks in all clients after it finish learning all tasks.
By using a weighted average, we calculated the test set accuracy for all seen tasks across all clients, with the number of samples in each task serving as the weights:
\begin{equation}
\text{Average Accuracy}=\frac{1}{\sum_{k=1}^{N}\sum_{i=1}^{T}n_k^i}\sum_{k=1}^{N}\sum_{i=1}^{T}a_{k}^{T,i}*n_k^i.
\end{equation}
This approach allows us to account for variations in task difficulty and ensure a fair evaluation across different tasks and clients.

\textbf{Average Forgetting}
The metric of average forgetting assesses the extend of backward transfer during continual learning, quantified as the disparity between the peak accuracy and the ending accuracy of each task.
We also use a weighted average when calculating average forgetting:
\begin{equation}
\text{Average Forgetting}=\frac{1}{\sum_{k=1}^{N}\sum_{i=1}^{T-1}n_k^i}\sum_{k=1}^{N}\sum_{i=1}^{T-1}\max_{t\in\{1,\ldots,T-1\}}(a_k^{t,i}-a_{k}^{T,i})*n_k^i.
\end{equation}

\subsection{Optimization}
The Adam optimizer is employed for training all models.
For all experiments except for CIFAR100, a learning rate of 1e-4 is utilized, with a global communication round of 60, and local iteration of 100.
We set learning rate as 1e-3, global communication round as 40, and local iteration as 400 for CIFAR100.
Consistent with prior research~\citep{DBLP:conf/icml/YoonJLYH21, DBLP:conf/iclr/QiZ023}, all clients participate in each communication round.
For training, a mini-batch size of 64 is adopted.
The number of generated samples in an iteration aligns with this mini-batch size.
We report the mean and standard deviation of each experiment, conducted three times with different random seed.

\subsection{Model Architectures}
In the case of CIFAR100, we utilize the feature extractor of a ResNet-18~\citep{DBLP:conf/cvpr/HeZRS16} as $h_a$ and $h_b$ comprises two FC layers 
, both with 512 units.
While for other datasets we adopt a three-layer CNN followed by a FC layer with 512 units as $h_a$.
The channel numbers of the convolutional layers are $[64, 128, 256]$.
And $h_b$ is represented by a FC layer.
The outputs of $h_a$ belong to $\mathbb{R}^{512}$.
All the FC layers employed in the architectures consist of 512 units.
The convolutional layers and FC layers are followed by a Leaky ReLU layer.
Another FC layer serves as $h_c$ and operates as the classification head.

The NF models consist of four layers of random permutation layer and affine coupling layer. The random permutation layers randomly permute the input vector so that various dependency among dimensions of input vectors could be effectively modeled. The inverse function of random permutation layers is to reversely permute the vector back to the original order. The affine coupling layers firstly partition the input vector into two halves $x_a$ and $x_b$. Then an affine transformation is applied to one part of the input, conditioned on the other part:
\begin{align}
y_a&=\exp(s(x_a))\odot x_b+t(x_a),\\
y_b&=x_b,
\end{align}
where $s$ and $t$ denote functions that create scaling and translation parameters, which we implemented with 2 blocks of residual neural network and learned from the data. The output vector $y$ is the concatenation of $y_a$ and $y_b$. The invertibility of affine coupling transformation is readily apparent.

\section{Additional Experimental Results}
\subsection{Ablation Studies}
Our method consists of three major components:
(\rom{1}) feature generative-replay (GR). For generative replay, we train a global NF model in the feature space of classifier.
By augmenting the learning process of classifier with the generated features, we prevent complete forgetting of previous tasks.
%The global NF model learns the features of all previously encountered tasks across all clients.
%During local classifier training, we utilize the NF model to generate feature vectors that encapsulate past information.
(\rom{2}) knowledge distillation (KD). 
The NF model is trained in the feature space of classifier.
To maintain the stability of the training process for the NF model, a knowledge distillation loss is employed in the feature space of classifier, mitigating significant drift.
(\rom{3}) correlation estimation for accurate forgetting (AF). 
We assess the reliability of the generated feature by its probability density within the current tasks.
Leveraging the NF model, we approximate the local feature distribution to evaluate the probability of a given generated feature aligning with the current distribution.

We conduct ablation studies on the EMNIST-LTP and EMNIST-shuffle dataset as displayed in Table~\ref{table:emnist_ltp_shuffle_ablation}.
Our method achieves optimal performance with all the three modules.
Without the GR module, the AF module also loses efficacy.
Therefore, left with the KD module, the performance of our model is comparable to that of PODNet and FLwF2T which relies on knowledge distillation to retain previous knowledge.
Without the AF module, our method degrades into naive generative reply based method, thus the performance is close to FedCIL and ACGAN-Replay.

\begin{table}[htbp]
\centering
%\setlength{\abovecaptionskip}{-.3cm}
%\setlength{\belowcaptionskip}{-1pt}
\caption{Ablation studies on EMNIST-LTP and EMNIST-shuffle dataset. }
%\resizebox{\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c}{EMNIST-LTP} & \multicolumn{2}{c}{EMNIST-shuffle}  \\
\cmidrule(r){2-3} \cmidrule(r){4-5} & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ \\
\hline
PODNet+FedAvg  & 36.9$_{\pm 1.3}$ & 19.8$_{\pm 0.9}$ & 71.0$_{\pm 0.4}$ & \textbf{3.9}$_{\pm 0.4}$\\
PODNet+FedProx  & 40.4$_{\pm 0.4}$ & 14.3$_{\pm 0.5}$ & 70.6$_{\pm 0.7}$ & 9.6$_{\pm 0.3}$ \\
ACGAN-Replay+FedAvg  & 38.4$_{\pm 0.2}$ & 9.8$_{\pm 0.8}$ & 70.0$_{\pm 0.5}$ & 4.7$_{\pm 0.3}$ \\
ACGAN-Replay+FedProx & 41.3$_{\pm 0.9}$ & 10.4$_{\pm 0.7}$ & 70.3$_{\pm 1.2}$ & 6.1$_{\pm 2.0}$\\
FLwF2T  & 40.1$_{\pm 0.3}$ & 15.5$_{\pm 0.5}$ & 71.0$_{\pm 0.9}$ & 8.1$_{\pm 0.8}$\\
FedCIL  & 42.0$_{\pm 0.6}$ & 12.4$_{\pm 0.3}$ & 71.1$_{\pm 0.4}$ & 6.4$_{\pm 0.2}$\\
\hline
\method~w/o GR & 38.8$_{\pm 1.5}$ & 15.3$_{\pm 0.4}$ & 70.8$_{\pm 0.7}$ & 6.7$_{\pm 0.5}$ \\
\method~w/o KD & 44.3$_{\pm 0.6}$ & 10.7$_{\pm 0.7}$ & 72.1$_{\pm 0.5}$ & 5.8$_{\pm 0.3}$ \\
\method~w/o AF & 41.8$_{\pm 0.3}$ & 13.7$_{\pm 1.2}$ & 71.0$_{\pm 0.9}$ & 6.7$_{\pm 0.4}$ \\
\hline
\method  & \textbf{47.5}$_{\pm 0.3}$ & \textbf{7.9}$_{\pm 0.5}$  & \textbf{75.8}$_{\pm 0.2}$ & 4.2$_{\pm 0.1}$\\
\bottomrule
\end{tabular}
\label{table:emnist_ltp_shuffle_ablation}
%\vspace{-.3cm}
\end{table}

\subsection{CIFAR100 in A Different Setting}
We conduct experiments on CIFAR100 with a more challenging setting.
We randomly sample 10 classes among 100 classes of CIFAR100 as a task for each of the 8 clients, and there are 6 tasks for each client ($N=8, T=6, C=10$).
For each class, we randomly sample 400 instances into the client dataset.
Therefore, each client possesses more tasks while less samples per task.

% 遗忘率很低，虽然其他方法记忆全部知识，但记住错误知识反而影响以往任务的准确率，而我们方法\ldots
\begin{table}[htbp]
\centering
%\setlength{\abovecaptionskip}{-.3cm}
%\setlength{\belowcaptionskip}{-1pt}
\caption{Average accuracy and forgetting on CIFAR100 when $N=8$, $T=6$, $C=10$.}
%	\resizebox{1.05\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
Model & Accuracy$\uparrow$ & Forgetting$\downarrow$  \\
\hline
FedAvg & 19.5$_{\pm 0.3}$ & 2.4$_{\pm 0.20}$ \\
FedProx & 20.1$_{\pm 0.2}$ & 1.9$_{\pm 0.08}$ \\
\hline
PODNet+FedAvg & 21.3$_{\pm 0.1}$ & 2.0$_{\pm 0.06}$ \\
PODNet+FedProx & 21.6$_{\pm 0.4}$ & 2.1$_{\pm 0.15}$ \\
ACGAN-Replay+FedAvg & 19.5$_{\pm 0.6}$ & 3.0$_{\pm 0.36}$ \\
ACGAN-Replay+FedProx & 19.6$_{\pm 0.2}$ & 2.8$_{\pm 0.40}$ \\
\hline
FLwF2T & 21.5$_{\pm 0.7}$ & 5.9$_{\pm 0.67}$ \\
FedCIL & 19.6$_{\pm 0.3}$ & 2.9$_{\pm 0.52}$ \\
GLFC & 19.9$_{\pm 0.4}$ & 3.2$_{\pm 0.31}$ \\
\method & \textbf{23.8}$_{\pm 0.6}$ & \textbf{0.9}$_{\pm 0.07}$ \\
\bottomrule
\end{tabular}
\label{table:cifar100_different_setting}
%\vspace{-.3cm}
\end{table}

As shown in Table~\ref{table:cifar100_different_setting}, our method attains the highest accuracy among the evaluated methods.
Although the CL methods and conventional FCL methods emphasize the retention of knowledge acquired from previous tasks, indiscriminate memorization of potentially erroneous knowledge can detrimentally impact the performance on previous tasks.
In contrast, our proposed method adopts a adaptive approach to forgetting biased features, resulting in a notable reduction of forgetting compared to established baselines, thus preserving a higher degree of task-specific knowledge retention.

\subsection{Results of EMNIST-noisy dataset}
We conduct experiments in the EMNIST-noisy dataset with an increasing number of noisy clients.
We display the complete comparison of accuracy and forgetting among baselines here.
It is observed that the performance of the methods consistently diminishes with the escalating count of noisy clients, as depicted in Table~\ref{table:emnist_noisy}.
The presence of noisy clients introduce harmful information into the model learning process and memorization of such information proves detrimental to the overall performance.
Thus, some of the CL and FCL methods, which aim to fight forgetting, exhibit inferior performance compared to FL methods.
Our approach employs adaptive mechanisms to mitigate the impact of erroneous information.
By alleviating the negative influence of noisy clients, our method consistently surpasses all baselines in both accuracy and resistance to forgetting.
 
% \begin{table}[htbp]
% \centering
% %\setlength{\abovecaptionskip}{-.3cm}
% %\setlength{\belowcaptionskip}{-1pt}
% \caption{Average accuracy and forgetting on EMNIST-noisy dataset in the last 3 tasks with different number of malicious clients $M$. }
% \resizebox{1.05\linewidth}{!}{
% 	\begin{tabular}{ccccccc}
% 		\toprule
% 		\multirow{2}{*}{Model} & \multicolumn{2}{c}{$M=1$} & \multicolumn{2}{c}{$M=2$} &
% 		\multicolumn{2}{c}{$M=4$} \\
% 		\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ \\
% 		\hline
% 		FedAvg & 54.4$_{\pm 0.7}$ & 16.1$_{\pm 0.9}$ & 52.7$_{\pm 0.5}$ & 16.0$_{\pm 0.4}$ & 55.5$_{\pm 0.6}$ & 16.1$_{\pm 0.8}$\\
% 		FedProx & 56.4$_{\pm 0.5}$ & 21.8$_{\pm 0.4}$ & 54.3$_{\pm 0.6}$ & 18.8$_{\pm 1.4}$ & 58.0$_{\pm 0.5}$ & 11.5$_{\pm 0.7}$ \\
% 		\hline
% 		PODNet+FedAvg & 36.3$_{\pm 1.3}$ & 20.3$_{\pm 0.7}$ & 33.5$_{\pm 0.9}$ & 20.1$_{\pm 0.2}$ & 33.8$_{\pm 0.7}$ & 14.0$_{\pm 0.9}$\\
% 		PODNet+FedProx  & 39.3$_{\pm 0.6}$ & 19.6$_{\pm 0.7}$ & 32.3$_{\pm 1.3}$ & 21.2$_{\pm 0.8}$ & 39.1$_{\pm 1.3}$ & 13.4$_{\pm 0.6}$\\
% 		ACGAN-Replay+FedAvg  & 52.0$_{\pm 0.6}$ & \textbf{12.6}$_{\pm 0.5}$ & 51.4$_{\pm 0.9}$ & 10.5$_{\pm 0.6}$ & 52.2$_{\pm 0.9}$ & 6.0$_{\pm 0.9}$\\
% 		ACGAN-Replay+FedProx & 58.6$_{\pm 0.4}$ & 10.5$_{\pm 0.2}$ & 50.5$_{\pm 1.0}$ & 17.2$_{\pm 0.4}$ & 48.6$_{\pm 0.6}$ & 16.4$_{\pm 0.7}$\\
% 		\hline
% 		FLwF2T  & 55.2$_{\pm 0.7}$ & 36.6$_{\pm 2.3}$ & 54.6$_{\pm 0.3}$ & 36.8$_{\pm 1.9}$ & 53.0$_{\pm 0.5}$ & 34.1$_{\pm 0.3}$\\
% 		FedCIL  & 47.0$_{\pm 0.4}$ & 20.2$_{\pm 0.9}$ & 38.8$_{\pm 0.7}$ & 21.1$_{\pm 0.5}$ & 46.0$_{\pm 0.8}$ & 7.8$_{\pm 1.4}$ \\
% 		GLFC & 53.9$_{\pm 0.7}$ & 32.1$_{\pm 0.5}$ & 57.3$_{\pm 0.9}$ & 29.3$_{\pm 0.4}$ & 52.8$_{\pm 0.5}$ & 31.0$_{\pm 0.4}$\\
% 		\method  & \textbf{55.5}$_{\pm 0.5}$ & 7.5$_{\pm 0.8}$ & \textbf{56.5}$_{\pm 0.4}$ & \textbf{9.3}$_{\pm 0.5}$ & \textbf{54.5}$_{\pm 0.6}$ & \textbf{9.8}$_{\pm 0.7}$\\
% 		\bottomrule
% 	\end{tabular}
% }
% 	\label{table:emnist_malicious}
% 	%\vspace{-.3cm}
% \end{table}

\begin{table}[htbp]
\centering
%\setlength{\abovecaptionskip}{-.3cm}
%\setlength{\belowcaptionskip}{-1pt}
\caption{Average accuracy and forgetting on EMNIST-noisy dataset in the last 3 tasks with different number of malicious clients $M$. }
\resizebox{1.05\linewidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c}{$M=1$} & \multicolumn{2}{c}{$M=2$} &
\multicolumn{2}{c}{$M=4$} \\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7} & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ & Accuracy$\uparrow$ & Forgetting$\downarrow$ \\
\hline
FedAvg & 52.3$_{\pm 0.7}$ & 16.1$_{\pm 0.9}$ & 51.7$_{\pm 0.5}$ & 16.0$_{\pm 0.4}$ & 50.4$_{\pm 0.6}$ & 12.1$_{\pm 0.8}$\\
FedProx & 52.5$_{\pm 0.5}$ & 12.5$_{\pm 0.4}$ & 51.8$_{\pm 0.6}$ & 18.8$_{\pm 1.4}$ & 51.0$_{\pm 0.5}$ & 13.5$_{\pm 0.7}$ \\
\hline
PODNet+FedAvg & 43.3$_{\pm 1.3}$ & 20.3$_{\pm 0.7}$ & 38.5$_{\pm 0.9}$ & 20.1$_{\pm 0.2}$ & 33.8$_{\pm 0.7}$ & 19.0$_{\pm 0.9}$\\
PODNet+FedProx  & 44.3$_{\pm 0.6}$ & 19.6$_{\pm 0.7}$ & 37.3$_{\pm 1.3}$ & 21.2$_{\pm 0.8}$ & 34.1$_{\pm 1.3}$ & 18.4$_{\pm 0.6}$\\
ACGAN-Replay+FedAvg  & 45.8$_{\pm 0.6}$ & 18.6$_{\pm 0.5}$ & 42.6$_{\pm 0.9}$ & 17.5$_{\pm 0.6}$ & 40.2$_{\pm 0.9}$ & 16.0$_{\pm 0.9}$\\
ACGAN-Replay+FedProx & 50.2$_{\pm 0.4}$ & 18.5$_{\pm 0.2}$ & 43.7$_{\pm 1.0}$ & 17.2$_{\pm 0.4}$ & 39.6$_{\pm 0.6}$ & 16.4$_{\pm 0.7}$\\
\hline
FLwF2T  & 52.1$_{\pm 0.7}$ & 14.7$_{\pm 2.3}$ & 47.6$_{\pm 0.3}$ & 18.6$_{\pm 1.9}$ & 44.5$_{\pm 0.5}$ & 14.1$_{\pm 0.3}$\\
FedCIL  & 49.8$_{\pm 0.4}$ & 15.2$_{\pm 0.9}$ & 45.8$_{\pm 0.7}$ & 19.1$_{\pm 0.5}$ & 42.0$_{\pm 0.8}$ & 15.8$_{\pm 1.4}$ \\
% GLFC & 50.5$_{\pm 0.7}$ & 11.5$_{\pm 0.5}$ & 47.3$_{\pm 0.9}$ & 29.3$_{\pm 0.4}$ & 52.8$_{\pm 0.5}$ & 31.0$_{\pm 0.4}$\\
\method  & \textbf{55.5}$_{\pm 0.5}$ & \textbf{7.5}$_{\pm 0.8}$ & \textbf{54.9}$_{\pm 0.4}$ & \textbf{11.8}$_{\pm 0.5}$ & \textbf{54.0}$_{\pm 0.6}$ & \textbf{12.8}$_{\pm 0.7}$\\
\bottomrule
\end{tabular}
}
\label{table:emnist_noisy}
%\vspace{-.3cm}
\end{table}

\subsection{Results of ImageNet-Subset dataset}
We conducted experiments on a subset of the ImageNet dataset. Each client among 10 clients contains 4 tasks, where each task consists of 40 classes among 200 classes. As shown in the table below, our method surpasses existing baselines. This empirical evidence demonstrates the efficacy of our method, particularly in handling richer semantic information on large datasets such as ImageNet.

\begin{table}[htbp]
\centering
%\setlength{\abovecaptionskip}{-.3cm}
%\setlength{\belowcaptionskip}{-1pt}
\caption{Average accuracy and forgetting on ImageNet-Subset dataset when $N=10$, $T=4$, $C=40$.}
%	\resizebox{1.05\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
Model & Accuracy$\uparrow$ & Forgetting$\downarrow$  \\
\hline
FedAvg & 14.7 & 3.2 \\
FedProx & 15.1 & 2.3 \\
\hline
ACGAN-Replay+FedAvg & 17.4 & 1.6 \\
ACGAN-Replay+FedProx & 17.3 & 1.8 \\
\hline
FedCIL & 17.8 & \textbf{1.2} \\
GLFC & 18.0 & 1.9 \\
\method & \textbf{20.4} & 1.7 \\
\bottomrule
\end{tabular}
\label{table:imagenet}
%\vspace{-.3cm}
\end{table}


\section{Computation Analysis and Devices}
As a generative-replay based model,~\method~has a similar number of parameters with other generative-replay based methods, including the baselines FedCIL, ACGAN-Replay, etc.
Due to the special design of NF models, the generation and density estimation of them are fast and efficient.
Therefore, ~\method~does not bring many extra computational and communication costs.
We provide the running-time comparisons with baselines in Table~\ref{table:time}.
As shown in the table, running-time of the proposed method is less than that of the generative-replay based models mentioned above.

\textbf{Devices} In the experiments, we conduct all methods on a local Linux server that has two physical CPU chips (Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz) and 32 logical kernels. All methods are implemented using Pytorch framework and all models are trained on GeForce RTX 2080 Ti GPUs.




\begin{table}[htbp]
%\vspace{-.1cm}
\centering
%\setlength{\abovecaptionskip}{-1pt}
%\setlength{\belowcaptionskip}{-1pt}
\caption{Run-time consumption comparisons on the EMNIST-LTP and CIFAR100 dataset}
\begin{tabular}{ccc}%l=left, r=right,c=center分别代表左对齐，右对齐和居中，字母的个数代表列数
\toprule
Methods & \makecell{Run-time consumption \\ (EMNIST-LTP)} & \makecell{Run-time consumption \\ (CIFAR100)} \\
\hline
FedAvg & 22 min & 238 min    \\
FedProx & 26 min & 245 min    \\
\hline
PODNet+FedAvg & 35 min & 252 min       \\
PODNet+FedProx & 37 min & 253 min \\
ACGAN-Replay+FedAvg & 85 min & 312 min \\
ACGAN-Replay+FedProx & 89 min & 315 min \\
\hline
FLwF2T & 33 min & 248 min \\
FedCIL & 93 min & 322 min \\
\method & 62 min &  302 min       \\
\bottomrule
\end{tabular}
\label{table:time}
\vspace{-.1cm}
\end{table}

\section{Related notions}

\subsection{Biased features}
Researchers have employed various definitions for biased features, one of which involves defining them as spurious correlations. We denote $\mathcal{X}$, $\mathcal{Y}$ as an input and output space of machine learning algorithm. An algorithm learns a mapping from the data $x\in\mathcal{X}$ to the prediction $\hat{y}\in\mathcal{Y}$: $\hat{y}=f(x)$. We assume there are attributes $\gamma_1, \gamma_2,...$ abstracted from the data $x$. For example, $\gamma_1$ represents the shape of the object in the input image $x$, and $\gamma_2$ denotes the number of black pixels in the input image $x$. The machine learning algorithm actually relies on many attributes to conduct infering: $\hat{y}=f(\gamma_{i_1}, \gamma_{i_2}, ..., \gamma_{i_N})$. We define an attribute $\gamma$ as biased feature if it does not comply with the natural meaning of the target $y$~\cite{jeon2022conservative}. Relying on such biased attribute would result in poor generalizability of the algorithm. The biased features could be attained through biased training dataset and the learned mapping $f$ relying on the biased features may not perform well in the testing dataset. For instance, if in the training image dataset all cows are standing on the grass, the machine learning model may rely on the attribute 'grass' for classifying images of cows.

In Sec.~\ref{sec:4}, we instantiate biased features with label noise~\citep{zhang2021noilin, chen2020noise}. With random labels, the model probably extracts misaligned attributes.
In benchmark datasets, machine learning models may also learn biased features even without label noise~\citep{zhu2021understanding}.

\subsection{Concept Drifts}
Different from the studies about Federated Continual Learning, the evaluation in the concept drift studies is conducted at each time step. Therefore, there is no memorization requirement or catastrophic forgetting problem in the concept drift studies. A novel clustering algorithms for reacting to concept drifts is proposed~\citep{jothimurugesan2023federated}. Adaptive-FedAVG adapted the learning rate to react to concept drift~\citep{canonaco2021adaptive}. Panchal et al. proposed to detect concept drift through the magnitude of parameter updates and designed a novel adaptive optimizer~\cite{panchal2023flash}.

\subsection{Orthogonal Training}
The incorporation of orthogonal training and our accurate forgetting method is a promising direction. 
Bakman et al. proposed to modify the subspace of model layers in learning new tasks such that it is orthogonal to the global principal subspace of old tasks~\citep{bakman2023federated}. By distinguishing the subspace inside the model for each task, catastrophic forgetting of old tasks is mitigated, and it also relieves the influence of unrelated tasks. We will continue to explore the employment of orthogonal training in our method.

Our method explicitly quantifies the correlations of generated features through probability calculations. Moreover, we facilitate selective forgetting by assigning lower weights to erroneous old knowledge, thus enabling the classifier to discard biased features and achieve improved overall performance. 
\end{document}
