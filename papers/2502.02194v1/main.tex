\documentclass[
%1p,
%times,
%review,
final,1p,times
]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{pdfpages}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
\usepackage{lineno}

\usepackage[numbers]{natbib}

%\usepackage[table]{xcolor}
\usepackage{rotating} % Rotating table
\usepackage[colorlinks]{hyperref}
\usepackage{longtable}
\usepackage{array}
\usepackage{soul}
\usepackage{float}
\usepackage{calc}
%\usepackage{xcolor}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{cleveref}
\usepackage{rotating}
\usepackage[nolist]{acronym}
%\usepackage{acronym}
\usepackage[inline]{enumitem}
\usepackage{lscape}

% Remove space before \paragraph
\makeatletter
\def\paragraph{\secdef{\els@aparagraph}{\els@bparagraph}}
\def\els@aparagraph[#1]#2{\elsparagraph[#1]{#2.}}
\def\els@bparagraph#1{\elsparagraph*{#1.}}

\renewcommand\elsparagraph{\@startsection{paragraph}{4}{\parindent}%
           {0pt}%
           {-6\p@}%
           {\normalfont\itshape}}
\makeatother

\usepackage[horizontal,grid=lightgray,skipempty]{credits}

\journal{Anonimyzed journal}

% comment before submission
%\usepackage{fancyhdr,datetime2}\date{\highlight{\ttfamily Version: \DTMnow}}\pagestyle{fancy}\fancyhead{}\renewcommand{\headrulewidth}{0pt}\fancyhead[c]{\highlight{\ttfamily Version: \DTMnow}}

\usepackage{changes}

\definechangesauthor[color=red,name=Andrea Esposito]{AE}
\definechangesauthor[color=blue,name=Giuseppe Desolda]{GD}
\definechangesauthor[color=green,name=Francesco Greco]{FG}
\definechangesauthor[color=orange,name=Cesare Tucci]{CT}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}
\title{Understanding User Mental Models in AI-Driven Code Completion Tools: Insights from an Elicitation Study}

\author[uniba]{Giuseppe Desolda\corref{cor1}}
\ead{giuseppe.desolda@uniba.it}
\ead[orcid]{https://orcid.org/0000-0001-9894-2116}
\cortext[cor1]{Corresponding author}
\author[uniba]{Andrea Esposito}
\ead{andrea.esposito@uniba.it}
\ead[orcid]{https://orcid.org/0000-0002-9536-3087}
\author[uniba]{Francesco Greco}
\ead{francesco.greco@uniba.it}
\ead[orcid]{https://orcid.org/0000-0003-2730-7697}
\author[uniba,unisa]{Cesare Tucci}
\ead{ctucci@unisa.it}
\ead[orcid]{https://orcid.org/0000-0001-5181-7115}
\author[uniba]{Paolo Buono}
\ead{paolo.buono@uniba.it}
\ead[orcid]{https://orcid.org/0000-0002-1421-3686}
\author[uniba]{Antonio Piccinno}
\ead{antonio.piccinno@uniba.it}
\ead[orcid]{https://orcid.org/0000-0003-1561-70736}

\affiliation[uniba]{%
    organization={Department of Computer Science, University of Bari Aldo Moro},
    addressline={Via E. Orabona 4},
    city={Bari},
    postcode={70125},
    country={Italy}
}
\affiliation[unisa]{%
    organization={University of Salerno},
    addressline={Via Giovanni Paolo II 132},
    city={Fisciano (Salerno)},
    postcode={84084},
    country={Italy}
}

\begin{abstract}
%% Text of abstract
Integrated Development Environments increasingly implement AI-powered code completion tools (CCTs), which promise to enhance developer efficiency, accuracy, and productivity. However, interaction challenges with CCTs persist, mainly due to mismatches between developers' mental models and the unpredictable behavior of AI-generated suggestions. This is an aspect underexplored in the literature. To address this gap, we conducted an elicitation study with 56 developers using focus groups, to elicit their mental models when interacting with CCTs. The study findings provide actionable insights for designing human-centered CCTs that align with user expectations, enhance satisfaction and productivity, and foster trust in AI-powered development tools. To demonstrate the feasibility of these guidelines, we also developed ATHENA, a proof-of-concept CCT that dynamically adapts to developers' coding preferences and environments, ensuring seamless integration into diverse workflows.
\end{abstract}

%%Graphical abstract
%\begin{graphicalabstract}
    %\includegraphics[width=\linewidth]{model.pdf}
%\end{graphicalabstract}

%%Research highlights
%\begin{highlights}
	%\item Focus on Human-Centered AI in Code Completion Tools (CCTs).
	%\item Studied developer-AI interaction via focus groups with 56 participants.
	%\item Key insights on when, where, and how code suggestions should appear.
	%\item Guidelines for designing user-friendly and effective AI-powered CCTs.
	%\item Aligns CCT design strategies with developers' mental models and needs.
%\end{highlights}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Code Completion Tools \sep
Generative AI \sep
Mental Models
%% PACS codes here, in the form: \PACS code \sep code
%\PACS 0000 \sep 1111
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
%\MSC 0000 \sep 1111
\end{keyword}

\end{frontmatter}

%\linenumbers

%\section*{\texorpdfstring{List of acronyms (\hl{To be removed: kept only for debugging})}{List of acronyms}}
\begin{acronym}
    \acro{IDE}{Integrated Development Environment}
    \acro{AI}{Artificial Intelligence}
    \acro{CCT}{Code Completion Tool}
    \acro{HCAI}{Human-Centered Artificial Intelligence}
    \acro{HCI}{Human-Computer Interaction}
    \acro{LLM}{Large Language Model}
    \acro{HCI}{Human-Computer Interaction}
    \acro{CNN}{Convolutional Neural Network}
    \acro{XAI}{eXplainable AI}
    \acro{ML}{Machine Learning}
    \acro{UI}{User Interface}
\end{acronym}

\section{Introduction}\label{introduction}

\acp{IDE} support developers with valuable tools to write and debug code in current software development practices. In many \acp{IDE}, code suggestion by automated systems has become a key element. Employing ever-developing \ac{AI} capabilities, these \emph{\acp{CCT}} intend to boost developer efficiency, accuracy, and productivity by cutting down on the manual input needed for repetitive code segments and speeding up the entire coding task. \acp{CCT} powered by \ac{AI}, like GitHub Copilot and JetBrains \ac{AI}, indicate a movement towards advanced and informed programming assistance.

When dealing with \acp{CCT}, while potentially benefitting from increased efficiency, users are exposed to a wide range of risks strictly related to automation. For example, one of the main risks in the domain of code completion is deskilling \cite{Sambasivan2022Deskilling}, i.e., the risk of losing personal abilities in the automated task (in this case, code writing). Similarly, and as already highlighted by previous studies \cite{Sergeyuk2025Using}, \acp{CCT} may increase the risk of generation of unsecured code. In response to the challenges that generally affect interaction with \ac{AI} systems, as in the case of \acp{CCT}, a new field of study has emerged in recent years, lying at the intersection of \ac{HCI} and \ac{AI}, commonly known as \ac{HCAI} \cite{Shneiderman2022HumanCentered,Xu2019HumanCentered}. \ac{HCAI} proposes to develop systems that are designed, developed, and evaluated by involving users in the process, aiming to increase performances and satisfaction in specified tasks \cite{Desolda2024Humancentred}.

While the technical aspects of \ac{AI}'s role in code generation are well-researched (for example, algorithms and AI models used by such tools \cite{izadi2024language, husein2024large}), \ac{HCAI} systems for code completions are still underresearched, exposing developers (and their software) to various risks. In fact, there is little indication on the interaction of developers with these tools, for example, how a system function is represented in a user's mental model, which crucially affects the efficiency and success of using these tools. Unlike conventional code suggestion systems, \ac{AI} tools frequently show unpredictable and changing behavior that might not match users' mental models. When interpreting the advice these tools give or when choosing to accept and employ them, developers may experience challenges. Although some studies explored coder's expectations when dealing with \acp{CCT} \cite{Sergeyuk2025Using,Wang2023How}, the understanding of the cognitive and interaction dynamics that developers face upon adopting \acp{CCT} is limited. Thus, the necessity for thoroughly investigating how users engage with \acp{CCT} has become crucial. Understanding developers' mental models in using such tools, useful in a human-centered approach, can lead to developing \acp{IDE} that align with user requirements, foster user satisfaction, and simultaneously improve coding productivity while promoting their adoption \cite{Sergeyuk2025Using}.

This study addresses the lack of understanding of the user's mental model in the usage of \acp{CCT} by reporting an elicitation study carried out as 8 focus groups with a total of 56 participants. Driven by the limitations identified during the analysis of state of the art, the study aims to understand specific aspects of the interaction with \acp{CCT}: where to show the suggestions, when the suggestion should be triggered during the interaction, how to show the suggested code, which type of code should be suggested, and personalization of the suggestion. Moreover, we also focus on various aspects of the interaction with the explanation of the tool's suggestion: where to show the explanation, when the explanation should be shown, and what should be explained. Insights gained from this analysis will help dictate strategies for creating user-friendly interaction approaches in \acp{IDE} while increasing cohesiveness among developers and \ac{AI} technologies in software development. 

The manuscript is structured as follows. \Cref{rationale-and-background} presents the rationale and background of our study, providing a survey of existing \acp{CCT} and their interaction modalities. \Cref{methodology} presents the methodology of our study, detailing the focus groups. \Cref{findings} reports the findings of our elicitation study. \Cref{discussion} discusses the findings, presenting developers' preferences and their mental model of \emph{human-centered} \ac{AI}-based \acp{CCT}. \Cref{prototype-development} illustrates a first working prototype that implements the elicited mental model. Finally, \Cref{conclusion} concludes the article, presenting its limitations and potential future work.

\section{Rationale and Background}\label{rationale-and-background}

With the rise of \ac{AI} in software development environments, \ac{AI}-driven \acp{CCT} are quickly revolutionizing developers' approach toward programming tasks. Real-time assistance is provided through these tools with suggestions for code snippets, auto-completion of code syntax, and predicting coding patterns while improving productivity, lowering the cognitive load, and streamlining the coding process. Although the implementation and usability of \acp{CCT} very much rely on the developer's expectations, understanding, and workflows, the success of these tools largely relies on how closely they align with what developers are already using, what they expect to use, their skills, and their needs. Achieving this alignment mainly hinges on users' (internal) mental models or internal representations of how the system works.

A mental model is generally a mental picture users have of how a certain system works \cite{Norman1983Observations,Norman2013Design}. It includes a user's assumptions, beliefs, and expectations while interacting with a system that will lead to their actions, interactions, and problem-solving behavior. Mental models also change over time, might contain errors, and are constrained by the user's prior experiences or technical background. Multiple mental models of a single object may be held by one person to reflect its many functions, and two persons will not always have the same mental model. If mental models are accurate and considered in the design of a system, users can anticipate system responses, feel confident during the interaction, and adapt quickly to new features. On the other hand, gaps between the users' mental model of the system's functionality and its actual behavior can lead users to confusion, frustration, and errors, which will reduce their productivity and satisfaction \cite{190/sym130.33050795}.

Mental models are crucial in the context of \acp{CCT} supported by \ac{AI}. These tools employ \ac{ML} algorithms or \acp{LLM}, thus relying on probabilistic computations rather than being deterministic. For example, \ac{AI}-driven suggestions may use aggregated pattern data, which are not directly readable by users. Thus, the suggestions produced might be contextually nonrelevant or impossible to interpret. If a developer's mental model does not match the underlying mechanisms of an \ac{AI} tool, users might struggle to trust the tool, interpret its suggestions accurately, or recognize when and how to use it effectively.

The need to understand mental models in the domain of \ac{AI}-based \acp{CCT} is multifaceted, and different aspects can benefit from a deep understanding of users' mental models. The first is \emph{interaction} with \acp{CCT} since users might predict the tool's behavior and know when a suggestion will be useful and when it could mislead. For instance, a tool designed considering users' mental models might allow developers to know when the \ac{AI} might make contextually relevant suggestions and when it can blunder, and so on, to keep the coding flow in hand and avoid wasting time for distraction. Another aspect that can benefit regards \emph{trust}. \acp{CCT} can be largely obscure to those operating outside the normal programming logic. It has been proven that transparency and interpretability are essential for establishing user trust, and understanding the user's mental model is essential to making users comfortable when adopting the tools \cite{RN1500}. This helps create trust in a tool by aligning design features with users' mental models, making developers more likely to adopt it into their daily workflow. Another aspect that can benefit from the mental model is \emph{cognitive load}: \acp{CCT} are meant to reduce repetitive tasks and cognitive load; thus, users can concentrate on more difficult problem-solving jobs. However, if users cannot intuitively understand how or why these suggestions are being made, the cognitive load can actually rise rather than fall. Refining these tools to become less disjointed in relation to user mental models means we can improve the flow of work, minimize interruptions, and ultimately help users be more productive. The last aspect is the possible \textit{support to learning}: especially for novice programmers, developers can recognize common coding patterns and problem-solving techniques, enhancing both tool competency and coding proficiency. The overall improvements in systems that stem from following users' mental models throughout the design are also a potent driver for increasing systems' adoption and acceptability \cite{Sergeyuk2025Using}. A recent study by \citeauthor{Wang2023How} highlights that 54\% of the developers recruited for their study are eager for better \acp{CCT} \cite{Wang2023How}.

Exploring the users' mental models is a complex process since these models are typically abstract, partially formed, or even subconscious. Without elicitation studies, bridging this gap is an arduous task, and they are the ones that prescribe structured methodologies to help yield, analyze, and interpret users' cognitive models regarding system functionality. The techniques for eliciting mental models include design workshops \cite{Jacko2012Human}, interviews \cite{Rogers2023Interaction}, concept mapping \cite{Jacko2012Human}, think-aloud protocols \cite{Lewis1982Using}, and scenario-based design \cite{Rosson2012ScenarioBased}. These techniques allow researchers to design intricate representations of users' mental models of system behavior, what they expect the system to do \emph{a priori}, and how they can expect to interact with, for example, \acp{CCT}. Such insights inform tool design and can help bolster our understanding of \ac{HCI} within \ac{AI}-augmented coding domains towards supporting frameworks and guidelines for improved user experiences in such environments and beyond.

In the next sub-sections, the state of the art concerning two important aspects of this study will be discussed, namely
\begin{enumerate*}[label=(\roman*)]
    \item the interaction currently offered by existing \acp{CCT}, and
    \item studies in the field of \ac{HCI} on \acp{CCT}.
\end{enumerate*}

\subsection{\texorpdfstring{AI Code Completion Tools }{AI Code Completion Tools }}\label{ai-code-completion-tools}

The proliferation of powerful \ac{AI} tools, such as \acp{LLM}, is stimulating the creation of many \acp{CCT}. The analysis of the literature and the market allowed us to identify a total of 17 tools. Each tool is characterized by many aspects, ranging from technical features (e.g., the underlying \ac{AI} model) to more social aspects, such as interaction with them. Given the purpose of this study, we analyzed the 17 \acp{CCT} with respect to the interaction techniques offered. However, 4 do not provide a graphical user interface, so they are not considered in the following.

The analysis of the remaining 13 \acp{CCT} providing a \ac{UI} was guided by two main aspects: the \emph{code suggestion} itself and the \emph{explanation}, if any, of why that code was suggested. After familiarizing ourselves with the \acp{CCT}, we analyzed users' interaction with them across different dimensions. To simplify the analysis and the reporting of the results, we used the 5W model, which is adopted in various fields, such as journalism and customer analysis, and more generally in problem-solving, to analyze the complete story of a fact. Each dimension of the interaction with the tool was addressed in terms of the question of the 5W model. In particular, the analysis of the tools with respect to the code suggestion was done by answering these questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \emph{Where} to show the code suggestion in the \ac{UI}?
\item
  \emph{When} should the code suggestions be activated during the interaction?
\item
  \emph{How} to show the suggested code?
\item
  \emph{What} should be suggested?
\item
  \emph{How} should the suggestion be customized?
\end{enumerate}

The analysis regarding the explanations was guided by the following questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\item
  \emph{Where} to show the explanation in the UI
\item
  \emph{When} to show the explanation during the interaction
\item
  \emph{What} to explain.
\end{enumerate}

A summary of the complete set of such models is depicted in \Cref{tab:tools}.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% \usepackage{lscape}
\begin{sidewaystable}
\begin{table}[H]
\centering
\caption{Summary of the analysis of  interaction with code and explanations generated by 13 Code Completion Tools.}
\label{tab:tools}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|lllll|lll|}
\hline
\multirow{2}{*}{\textbf{}} & \multicolumn{5}{c|}{\textbf{Code completion}} & \multicolumn{3}{c|}{\textbf{Explanation}} \\ \cline{2-9}
 & \multicolumn{1}{l|}{\textbf{What}} & \multicolumn{1}{l|}{\textbf{When}} & \multicolumn{1}{l|}{\textbf{How to show}} & \multicolumn{1}{l|}{\textbf{How to customize}} & \textbf{Where} & \multicolumn{1}{l|}{\textbf{What}} & \multicolumn{1}{l|}{\textbf{When}}  & \multicolumn{1}{l|}{\textbf{Where}}  \\ \hline
\textbf{Intellicode \cite{Svyatkovskiy2020IntelliCode}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{curent file} & inline & \multicolumn{1}{l|}{-} & \multicolumn{1}{l|}{-}  & \multicolumn{1}{l|}{-}  \\ \hline
\textbf{Codex \cite{Chen2021Evaluating}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{manual} & \multicolumn{1}{l|}{text} & \multicolumn{1}{l|}{chat history} & right side & \multicolumn{1}{l|}{answer} & \multicolumn{1}{l|}{prompt}  & \multicolumn{1}{l|}{chatbot}  \\ \hline
\textbf{Copilot \cite{Friedman2021Introducing}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{answer} & \multicolumn{1}{l|}{prompt}  & \multicolumn{1}{l|}{chatbot} \\ \hline
\textbf{TravTrans \cite{Kim2021Code}} & \multicolumn{1}{l|}{token} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{dropdown} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{-} & \multicolumn{1}{l|}{-}  & \multicolumn{1}{l|}{-} \\ \hline
\textbf{StarCoder \cite{li2023starcoder}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{-} & \multicolumn{1}{l|}{-}  & \multicolumn{1}{l|}{-}  \\ \hline
\textbf{Codegeex \cite{Zheng2023CodeGeeX}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{answer, description} & \multicolumn{1}{l|}{prompt, click} & \multicolumn{1}{l|}{chatbot} \\ \hline
\textbf{CodeWhisperer  \cite{What}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{hybrid} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{source} & \multicolumn{1}{l|}{click}  & \multicolumn{1}{l|}{sidebar}  \\ \hline
\textbf{Codeium  \cite{Codeium}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{improvements, reasons} & \multicolumn{1}{l|}{click}  & \multicolumn{1}{l|}{chatbot} \\ \hline
\textbf{Replit  \cite{Replit}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{description} & \multicolumn{1}{l|}{click}  & \multicolumn{1}{l|}{pointer}  \\ \hline
\textbf{Cody  \cite{Cody}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{repository} & inline & \multicolumn{1}{l|}{answer} & \multicolumn{1}{l|}{click, prompt}  & \multicolumn{1}{l|}{chatbot}  \\ \hline
\textbf{Tabnine  \cite{Tabnine}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{answer} & \multicolumn{1}{l|}{prompt}  & \multicolumn{1}{l|}{chatbot}  \\ \hline
\textbf{Xcode \cite{Xcode}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{-} & \multicolumn{1}{l|}{-} & \multicolumn{1}{l|}{-}  \\ \hline
\textbf{Blackbox  \cite{Chat}} & \multicolumn{1}{l|}{lines} & \multicolumn{1}{l|}{proactive} & \multicolumn{1}{l|}{grey text} & \multicolumn{1}{l|}{current file} & inline & \multicolumn{1}{l|}{improvement} & \multicolumn{1}{l|}{click}  & \multicolumn{1}{l|}{sidebar}  \\ \hline
\end{tabular}%
}
\end{table}
\end{sidewaystable}

\subsubsection{Code suggestions}\label{code-suggestions}

An important characteristic affecting the interaction with \acp{CCT} is the timing to provide suggestions (\emph{when}). The analysis of the existing tools revealed two main approaches: \emph{proactive} and \emph{manual}. Proactive \acp{CCT} 
%\cite{DeMoor2024TransformerBased}
provide suggestions at a certain time without requiring a user action to trigger the completion. This type of design can be either implemented in an intrusive manner (by suggesting a completion at any time)  or discreetly (by generating completions only when the context is sufficient). The manual approach, in contrast, requires the user to perform a specific action to visualize the completion. However, manual activation of \acp{CCT} is not very popular, as it is adopted in only two tools. A hybrid timing approach is also implemented, even if only in the case of CodeWhisperer, as completions are proactive but can be forced through a shortcut \cite{What}.

Another aspect is the content of \acp{CCT} suggestions (\emph{what} is provided as a suggestion?). Two main modalities emerged from our analysis: \emph{single token suggestions} (less popular, as it was proposed only with the TravTrans prototype \cite{Kim2021Code}) and \emph{multiple line completions}, which are widely adopted. While the first solution is quite simple, the second one results in a feature that is hard to control and assess since the length of the suggestions may vary depending on the context and \ac{LLM} characteristics. As a matter of fact, multi-line suggestion length can range from short code blocks (e.g., for loops, switches, if-else) to entire functions or classes.

The suggestion's location (\emph{where}) in the \ac{UI} is also worth exploring. A predominant approach is to put completions directly inside the code (\emph{inline suggestions}). The other solution instead consists of providing the suggestion in a \emph{separate space} with respect to the coding area. Codex \cite{Chen2021Evaluating} is the only tool that adopts the latter modality.

It is useful to discuss \emph{how to show} code completions that appear before they are accepted and integrated into the live code. A consolidated approach is to display the completed code in gray, allowing users to easily distinguish it from the live code, which is typically shown in white (or other colors, depending on the users' preferred color scheme), before accepting the proposals of the \ac{CCT}. However, another method has emerged: displaying multiple possible completions in a dropdown menu. This latter approach may be particularly convenient for single-token suggestions or very short completions, as demonstrated by TravTrans.

Finally, it is worth investigating the customizability of \acp{CCT}, as the relevance and helpfulness of suggestions strongly depend on the type of user receiving them (\emph{how to customize}). Context-aware suggestions may consider the user expertise, the specific formatting/adherence to coding standards, and the functional and non-functional requirements of specific software development scenarios to provide the most accurate code snippets possible. The strategies adopted for this aim result in three categories: personalization based on the context of the current file, personalization based on a code repository, and personalization based on chat history. The first category is the most popular, while Cody \cite{Cody} is the only tool that managed to include a code repository for more relevant completions. Nevertheless, this last approach seems to fail for big repositories. Codex  provides more aware suggestions by processing the conversation between the programmer and the chatbot as context.

\subsubsection{Explanations of the suggested code}\label{explanatory-features}

Some of the \acp{CCT} analyzed
%, such as Intellicode, TravTrans, and Starcode,
do not offer any explanatory feature. By contrast, the remaining tools use various methods to provide developers with explanations as they write new code.

The location in the UI (\emph{where}) of code explanations is an important aspect of \acp{CCT}, as it influences other interaction characteristics. Three main approaches are observed: explanations are either delivered inside a chatbot, or shown in a sidebar, or finally displayed inside the coding space. Tabnine \cite{Tabnine}, Cody \cite{Cody}, CodeGeeX \cite{Zheng2023CodeGeeX}, Copilot \cite{Friedman2019Value}, Codeium \cite{Codeium}, and Codex \cite{Chen2021Evaluating} implement the first approach, providing chat-based explanations. 
In contrast, CodeWhisperer \cite{What} and Blackbox \cite{Chat} report code explanations in a sidebar. In this case, the user is not allowed of submitting prompts for additional details, but such an approach delivers code explanations quicker, as the user does not have to think about a prompt in order to receive explanations.
Finally, Replit \cite{Replit} follows a unique approach, showing explanations inside a tooltip at the mouse pointer's location (which means the explanations appear within the coding space).


%Static explanations, conversely, may consist of either discursive text (as in CodeWhisperer \cite{What} and Replit ) or a combination of text and code (as seen in Codeium \cite{Codeium} and Blackbox \cite{Chat}).



%\emph{How} explanations are presented is important, as it influences other interaction characteristics. Two main approaches are observed: explanations delivered through a chatbot interface and static explanations. Tabnine \cite{Tabnine}, Cody \cite{Cody}, CodegeeX \cite{Zheng2023CodeGeeX}, Copilot \cite{Friedman2019Value}, and Codex \cite{Chen2021Evaluating} provide chat-based explanations in the first category. Static explanations, conversely, may consist of either discursive text (as in CodeWhisperer \cite{What} and Replit \cite{Replit}) or a combination of text and code (as seen in Codeium \cite{Codeium} and Blackbox \cite{Chat}).

As mentioned earlier, the position in which explanations are delivered directly impacts their content (\emph{what}). Chat-based explanations typically offer direct responses to specific user questions. Static explanations, in contrast, can vary widely. For instance, CodeGeeX and Replit  provide descriptive text for code, with Replit defaulting to a short, numbered list format, as too much text would be too intrusive to fit inside the coding space. CodeWhisperer lists sources used for generating completions, and Blackbox and Codeium suggest code improvements, with the latter adding implementation rationales to its suggestions.

%The location of these explanations within the \ac{UI} (\emph{where}) also varies significantly across the tools. A primary distinction can be drawn between explanations displayed directly within the coding area and those positioned in a separate block. Most tools adopt the second approach: Codex and Codeium display explanations in a tab on the right, Cody, Tabnine, CodegeeX, and Copilot position them on the left, while CodeWhisperer places them at the bottom. However, Replit follows a unique approach, showing explanations at the mouse pointer's location (which means the explanations appear within the coding space).

 The timing approaches (\emph{when}) are exclusively manual for explanations. Two primary modalities emerge: explanations can be triggered by a mouse click or provided after submitting a prompt (in the case of chat-based explanations). CodeWhisperer, Codeium, Replit, and Blackbox follow the former approach, although multiple clicks are often required to access the explanations. The latter approach is used by Codex, Tabnine, and Copilot. CodeGeeX and Cody adopt a hybrid approach, offering explanations through both methods.

\subsection{Usability studies on code completion tools}\label{studies-in-the-field-of-hci-on-code-completion-tools}

The usability of \acp{CCT} has been a research focus for quite some time, aiming to make these tools more intuitive and helpful for developers. One of the first attempts was carried out in 2015 by \citeauthor{muaruașoiu2015empirical}, which empirically investigated how professional developers interact with \acp{CCT} \cite{muaruașoiu2015empirical}. They analyzed the behaviors, intentions, and obstacles programmers encounter when employing these instruments. The study results revealed that code completion is primarily employed to speed up the coding process and guarantee accuracy. Besides, developers frequently use it as real-time feedback to seek mistakes.

Another aspect investigated by HCI researchers focused on the users' behavior while adopting \acp{CCT}. From this study, two main modalities emerged \cite{Prather2024Its}: in ``acceleration'' mode, the programmer is aware of their next steps and utilizes the tool to speed up the coding process. In contrast, in the ``exploration'' mode, the programmer is uncertain about how to proceed and employs the tool to investigate his options. Acceleration mode is usually preferred, as developers often use the tools to complete repetitive code that cannot be copy-pasted \cite{Liang2024LargeScale}, and for recalling syntax they don't remember \cite{Xu2022IDE}. As a result, the more developers accept \acp{CCT} suggestions, the more they perceive themselves as productive \cite{Bird2022Taking}.

\citeauthor{Liang2024LargeScale} conducted a study to understand the usability of \acp{CCT} (such as GitHub Copilot and Tabnine) by utilizing a structured survey distributed to 410 GitHub users who had engaged with \acp{CCT} \cite{Liang2024LargeScale}. Questions covered participants' motivations for using or not using \ac{AI} assistants, the usability issues they encountered, and the strategies they used to optimize the tool's output. The survey revealed that developers are most motivated to use AI programming assistants because they help developers reduce keystrokes, finish programming tasks quickly, and recall syntax. They also found that developers often do not use CCTs because these tools do not generate code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output.

Another important requirement that emerged from user studies is the need for \acp{CCT} to learn from feedback and adapt their behavior to developers' styles and project needs. For instance, in \cite{Zhang2023Demystifying}, it emerged that programmers would like to customize the shortcuts  and to set suggestions length and frequency \cite{Liang2024LargeScale}. The literature also highlights the need for explanations (such as reporting the source or linking to documentation) for additional context on the generated code \cite{Liang2024LargeScale,Xu2022IDE}.

The proactivity of \acp{CCT} has also been investigated, with research encouraging its implementation \cite{Sergeyuk2024IDE}. \citeauthor{Vaithilingam2023More} suggested that automatic inline gray-text suggestions, as opposed to traditional lightbulb interfaces, significantly improve discoverability and usability of \acp{CCT} \cite{Vaithilingam2023More}. The authors established five design principles to guide future \ac{AI}-driven code suggestion interfaces:

\begin{itemize}
    \item \textit{Glanceability}. Suggestions should be visible at a glance without manual initiation.
    \item \textit{Juxtaposition}. Clearly displaying original vs. suggested code enhances comprehension.
    \item \textit{Familiarity}. Using familiar visual elements, like red and green colors for highlighting differences with previous code, simplifies understanding.
    \item \textit{Visibility for Validation}. Users should be able to view suggestions fully and evaluate them without additional steps.
    \item \textit{Snoozability}. The ability to temporarily dismiss suggestions reduces interruptions.
\end{itemize}

Many users have asked for a ``snooze'' feature that allows them to pause inline suggestions for a specified period or the current session. This points out the need for further research to find the right balance between proactiveness and minimizing interruptions, ensuring that suggestions are presented at the most helpful moments without disrupting the coding process.

\section{Methodology}\label{methodology}

\subsection{Research design}\label{research-design}

This study investigates the mental model of developers interacting with \acp{CCT}. Based on the results and limitations that emerged during the literature analysis, two key objectives guided our investigation. The first revolves around the interaction with \acp{CCT}. The second one regards the interaction with explanations provided by such tools.

To achieve this, we followed an elicitation study methodology conducted through design workshops. We have chosen this technique because, particularly when performed in workshop formats, it facilitates in-depth insights into users' thought processes, preferences, expectations, needs, and perceptions about complex systems (similar to what has been done by \cite{Desolda2017Empowering,Marquardt2012Crossdevice,Voida2005Study}). Moreover, workshops stimulate participants to collaboratively propose, discuss, and model their ideas on code completion tools, offering rich qualitative data suited to the study's objectives. To structure the workshop discussions, we adopted a scenario-based design approach. This solution helps participants provide their answers while referring to a realistic situation \cite{Rosson2012ScenarioBased}.

\subsection{Participants}\label{participants}

The elicitation study involved a total of 56 participants {8 female, 48 male}), aged between 20 and 30 years (M = 22.88, SD = 2.63, min = 20, max = 30). They were randomly divided into 8 groups of 7 participants; this group size was chosen to enable balanced discussions where each participant could contribute their perspectives while fostering dynamic group interactions. The participants were students from both the University of Bari and the University of Salerno; 4 already had bachelor's degrees in computer science, while the remaining were students in the third year of their bachelor's degrees in computer science. Participants included novice (20), intermediate (32), and expert programmers (4). Their programming experience ranged from 1 year to 8 years, with familiarity in languages such as C, C++, Python, Java, C\#, and JavaScript. A total of 27 participants used \acp{CCT}; 22 participants had never used \acp{CCT}, but they knew what \acp{CCT} do, while 7 participants had never used and heard about \acp{CCT}.

All relevant ethical guidelines and regulations were followed, and the study received ethical approval from the Independent Ethical Review Board of the Computer Science Department of the University of Salerno. The participants digitally provided their informed consent and could leave the study anytime.

\subsection{Procedure}\label{procedure}

Two weeks before the start of the workshops, 100 emails were sent to the students inviting them to participate in the study. A total of 58 students agreed to attend the study, but then 2 of them missed the workshops. Those who signed up voluntarily filled in a questionnaire asking for personal data (first name, last name, age, gender), and data on technical skills (self-rating programming experience as novice, intermediate, expert), number of years of experience as a programming professional, use of \acp{CCT} (``yes'', ``No, but I know what they are and how they can work'', ``No, and I don't know what they are''), and used programming languages. We also surveyed their availability for the week of the study to schedule their participation according to their preferences.

Two \ac{HCI} researchers performed the study on four consecutive days in a quiet university laboratory; one was the conductor, and the other acted as the observer. The entire study consisted of 8 sessions, one for each group. Each workshop was planned to last around 1 hour and comprised four stages: introduction, scenario exploration, mental model elicitation, and debriefing.

For each session, the group sat around a table and was provided with paper sheets and markers to sketch their proposals. One of the two \ac{HCI} researchers began by welcoming participants and thanking them for attending the study; then, the conductor gave a 5-minute presentation to provide an overview of the study's objectives, ensuring that participants understood the focus on user interaction with \acp{CCT}. Participants were also informed of the confidentiality and voluntary nature of the study.

To allow participants to recall the main concepts of \acp{CCT} (if they already used them) or to familiarize themselves with them, we presented a scenario involving a typical developer named Andrea, employed in a company producing web applications. In this scenario, Andrea has access to new functions of the \ac{IDE} for which an \ac{AI}-based module can suggest code to help him in his work. No concrete ideas or possible solutions were reported in the scenario to avoid bias in the participants' proposals.

After the introduction and the scenario presentation, the workshop's main phase began. The conductor led the discussion, focusing on those critical aspects of the interaction with \acp{CCT} that emerged from the literature review. In particular, for code completion, we posed the following questions:

\begin{enumerate}
    \item Where to show the code completion in the \ac{UI}?
    \item When should the suggestion be activated during the interaction?
    \item How should the suggested code be shown?
    \item What should be suggested?
    \item How should the suggestion be customized?
\end{enumerate}

\noindent For the explanation part, the discussion was guided by the following questions:

\begin{enumerate}
\setcounter{enumi}{5}
    \item Where to show the code completion explanation in the \ac{UI}?
    \item When to show the explanation during the interaction?
    \item What should be explained?
\end{enumerate}

For each question, the participants were asked to reflect individually for about 30 seconds and present the solution they had thought of to the others; afterward, the group was driven by the conductor in a discussion to come up with one or more ideas to answer the specific question.

Once all the questions had been answered, the session ended with a debriefing to summarise the key points raised by the participants and to revise, if necessary, some of their answers in the light of what had emerged throughout the discussion.

\subsection{Data Collection}\label{data-collection}

The data collected during the workshops were 1) the notes taken by the researchers, 2) the audio recordings, and 3) the sketches drawn by participants. The two researchers transcribed the notes and audio recordings, and independently rechecked 80\% of the material. The initial reliability value was 70\%; then, the researchers discussed the differences and reached full reliability.

The researchers analyzed the transcripts systematically using an inductive thematic analysis \cite{Braun2006Using}. According to the thematic analysis protocol, the evaluators performed the following 6 steps: familiarizing with the data, generating codes, mapping codes that share similar meanings, reviewing potential themes, defining and naming themes, and producing a report. The eight guiding questions structured the analysis, with the final themes answering each question.

\section{Findings}\label{findings}

This section presents the lessons learned about the user mental model on code completion for both suggestion and explanation, drawn from the elicitation study. The findings are presented with respect to the questions that structured the discussions during the workshops and provide a concrete description of users' thoughts about desirable interaction with code completion and explanation features. Each finding derives from a single theme that emerged from the thematic analysis, which is, in turn, supported by one or more low-level codes. All the themes, codes, and frequencies are reported in \ref{app:themes}.

The names of each theme are presented in italics in the following subsections. Participants' answers are given in double quotes to illustrate how one of the answers led to the identification of a theme. We also specified the number of groups that proposed the solution linked to each theme. It is worth noting that we chose to report the number of groups rather than the number of participants because, within a group, several solutions for each question were initially proposed individually; however, subsequent discussion among group members led to the identification of one or more solutions to answer the question.

\subsection{UI for code completion}\label{ui-for-code-completion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{findings-ui.pdf}
    \caption{Themes emerged by analyzing the developers' answers to the questions on user interfaces of CCTs.}
    \label{fig:findings-ui}
\end{figure}

There were differing proposals with regard to \textbf{when} the \acp{CCT} should provide code suggestions for participants. Three main strategies emerged. The first one consists of \emph{proactive} behavior (4 groups), i.e., the \ac{CCT} automatically suggests the code without users' requests when the user is not actively typing, e.g., coding `breaks' in the coding flow (``\emph{When someone is blocked, there a suggestion is given to help me}'' -- G1). Another strategy proposed by the users regards a \emph{manual} activation (5 groups) by keyboard shortcut or mouse interaction (``\emph{It must be activated manually via a shortcut}'' -- G2). This solution leaves complete control to the user over the use of \ac{AI}, which could then be less intrusive. The third solution, finally, consists of a \emph{hybrid} approach (6 groups). In this solution, the participants stated that a basic behavior could involve a proactive \ac{AI} strategy that intervenes only when there is a well-defined context (e.g., a long code already written) and when the suggestion is almost taken for granted and difficult to discard by the user (e.g., completion of a control structure). On the other hand, manual intervention would compensate the user for the lack of automatic \ac{AI} intervention, provided that the user is sure that they require \ac{AI} support (``\emph{Proactive when it's really obvious and useful, or when the user explicitly requests it}'' -- G8). Furthermore, several participants specify that, in general, suggestions should be generated only if there is enough \emph{coding context available} (4 groups) (``\emph{It's better not to try immediately, but take from context}'' -- G2). This was also consistent with the perceived necessity of very precise, context-sensitive recommendations \cite{asaduzzaman2014cscc}.

The second aspect concerns \textbf{how to show} the suggestions. A first preference expressed by the users was for a visualization \emph{inline} \emph{with distinct styling} (5 groups). Specifically, code suggestions should be displayed within the main coding window, but with differences in formatting, such as unique font styles or colors (``... \emph{chosen the `phantom' code suggested, it is then shown in our code, to give a `preview'}'' -- G6). This method allows users to view suggestions in context while maintaining clarity, particularly when the suggested code is short (``\emph{For little code, it is convenient showing it intext}'' -- G2). In addition, a button could be useful to switch this display on or off, i.e., to show \ac{AI} and user-written code in the same or different fonts (``\emph{... turn on/off the `show AI/human written code' mode...{}}'' -- G8). A second proposal concerns the visualization of suggestions in a \emph{separate area} from the text editor (7 groups), such as a sidebar. This modality allows users to review suggestions (especially when they are lengthy or more than one) without cluttering up the main coding space while keeping the focus on the existing code (``\emph{A separate window with a list of suggestions}'' -- G4; ``\emph{For on-demand things or lengthier suggestions, use a separate window}'' -- G3). A third strategy involves \emph{clicking on an icon} for manual activation (2 groups) and displaying it in a popup near the line where the suggestion is applied. By clicking on the icon, users can see and confirm the insertion of the suggestion, minimizing interruptions and increasing the level of control (``\emph{Maybe a `lightbulb' icon that allows opening a popup}'' -- G3). A final option concerns using \emph{chatbots} (2 groups), allowing users to request suggestions in a conversational manner. The suggestion would then be entered directly into the \ac{IDE} when the user accepts the chatbot's recommendation (``\emph{It should be conversational to improve suggestions}'' -- G3).

The third aspect concerns \textbf{where} to display the suggestion in the user interface of the IDE. The first preference expressed by participants is to show the suggestion in a \emph{sidebar} (6 groups), (``\emph{It's} \emph{better on the side, separately}'' -- G1; ``\emph{In a movable tab of the IDE}'' -- G7). The second strategy suggested by participants is to show the suggestion in a \emph{pop-up} (3 groups) near the main code (``\emph{In a togglable pop-up near the main code}'' -- G3). Another strategy that participants came up with is to show the suggestion \emph{inline} (5 groups) with the code that the developer is writing; in this case, the user could also be given a clear and immediate option to accept or reject the suggestion, e.g., an accept or reject icon (``\emph{{[}the suggestion{]} is shown within the editor, with the possibility to confirm the insertion'' --} G8). Finally, the last mode combines the previous ones: an \emph{adaptive visualization} (2 groups)\emph{,} in which shorter suggestions appear inline and longer ones are presented in a separate window (``\emph{In loco or in a different area. The choice depends on the code quantity''} -- G2). This approach allows flexibility depending on the length and complexity of the suggestion.

The fourth aspect concerns \textbf{what} to show in the suggestion. Participants expressed different expectations of what constitutes valuable content in code suggestions. In general, the strategy of \emph{controlling granularity} emerged (7 groups)\emph{.} Notably, participants expressed very contrasting needs for different levels of granularity for code suggestions: while some groups agreed on preferring suggestions up to a maximum granularity level of \emph{function} (``\emph{Limit to completing the function: if it completes everything, randomness increases and precision decreases}'' -- G1), others agreed on the usefulness of generating up to entire code files or classes (``\emph{Potentially a class}'' -- G7). Some participants proposed inserting a slider at suggestion time to control the level of detail of the suggestions, allowing developers to switch from minimal to very long suggestions according to their needs (``\emph{Let the user choose what to suggest, for example with a slider}'' -- G2). There was no single agreement on the minimum number of tokens that should be suggested; however, there was a certain agreement on preferring, initially, \emph{minimal suggestions with details asked on-demand} (4 groups) to foster the user's reasoning (``\emph{Only suggest the function name to insert, so that {[}the developer{]} can solve the problem on their own {[}...{]} pieces of code with comments that allow us to receive cues/hints; do not suggest too much code.}'' \emph{--} G6). The aspect of having \emph{different alternatives offered} by the code completion tool was also brought up (3 groups) as a preferable feature to improve precision in suggestions, particularly in the case of coding challenges that the developer has never faced (``\emph{Better to have many suggestions for new things, but for more `precise' things it's better to have single suggestions}'' -- G1). A cross-cutting aspect of the above concerns the suggestion of \emph{code accompanied by documentation} (2 groups) to improve comprehension and facilitate faster decision-making about the acceptance or rejection of the suggestion (``\emph{Include references to documentation for functions}'' -- G5). A final solution, finally, consists of suggesting \emph{code adapted to the context} in which it is suggested (3 groups), including variable names or coding styles relevant to the current project. According to the participants' proposals, the contexts could be represented by the developer's profiles (e.g., previous projects stored in repositories) or the projects already developed by the company (``\emph{{[}define{]} the standard of the suggested code, the style (in line with my style, or with the style of my company, of other repositories)...{}}'' -- G4).

The last aspect investigated during the study concerned \textbf{how to customize} the suggestions. The first need proposed by users (6 groups) concerns personalizing the \emph{timing of suggestion activation} (When) to allow each developer to tailor the responsiveness of the tool to their own workflow (``\emph{The} \emph{activation timing, to disable/enable automatic hints}'' -- G5); the need of customizing the \emph{activation timing of explanations} (discussed in the next subsection) also emerged to adapt to different expertise levels of programmers (``\emph{Automatic generation of explanations is fine for novices, but could be obnoxious or even `outrageous' for experts}'' -- G2). Another aspect that emerged in this dimension concerns customization of \emph{appearance} (6 groups): for example, many participants emphasized the need to customize the fonts, colors, and text size of the suggestions to ensure that they are visually distinct from the user's code according to their preferences (``\emph{Customize character size, color, font of suggestions..}'' -- G4). A third aspect is instead related to the \emph{granularity of suggestions} (6 groups): in the What dimension, we reported the strategy of controlling granularity, which generally prescribes proposing the suggestion with different levels of granularity. Here emerged that users should be able to customize this option, e.g., the user could choose a 3, 4, 5 level scale of granularity, and for each of them, users can choose what should be suggested, e.g., the statement the user is writing, the control structure, the function, the class, or others (``\emph{Set the level and scope of suggestions (the context of action -- functions, loops, operators)}'' -- G7). The need for customization also emerged for the \emph{granularity of explanations,} to adapt to the user's knowledge by generating more or fewer comments to explain the suggested code (``\emph{... the presence of automatic comments and their quantity/frequency (every line, every function, etc.)}'' -- G5; ``\emph{Customize what is generated as explanations...{} Customization can be simple, such as a `what level of programming are you?' initial question}'' -- G6). Finally, the last aspect that emerged was the \emph{coding style} (4 groups). In particular, participants stated that developers should adapt the tool to a certain coding style by fine-tuning it by feeding in, e.g., some of their own code repositories or their companies' past projects as examples (``\emph{Which context to use in the code generation as a `background training' ... set what repositories to consider}'' -- G2). Moreover, the developers should also be able to define quality standards to which the suggested code should adhere (``\emph{Control the quality of generated code, adherence to standards (even security ones)}'' -- G4).

\subsection{Explanations of the completion}\label{explanations-of-the-completion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{findings-explanations.pdf}
    \caption{Themes emerged by analyzing the developers' answers to the questions on explanations produced by CCTs}
    \label{fig:findings-explanations}
\end{figure}

The first aspect we analyzed regarding suggested code explanations concerns \textbf{where} the suggestion should be displayed in the user interface of the \acp{CCT}. The first strategy concerned using a \emph{separate window or pop-up} (7 groups). Several participants proposed that the explanations are better suited to a separate interface element, such as a sidebar or pop-up, allowing them to access the explanations without cluttering up the coding work area (``\emph{The} \emph{explanation and the function must be shown separately, otherwise there's too much text}'' -- G1). Another strategy, on the other hand, concerns visualization employing \emph{inline comments} within the code (6 groups), thus providing an immediate context for the suggested code without having to navigate elsewhere (``\emph{As an expandible text under the code'' --} G7); however, this solution was indicated as viable only if the explanation length was limited, in order to avoid confusion in the code (``\emph{No comments, as they tend to be too long...{} but a `title' of the suggestion can be kept as a brief explanation in a comment}'' -- G6). The last solution concerns using \emph{chatbots} (3 groups). Some participants suggested accessing the explanations via a chatbot, allowing users to query the system in a conversational manner to obtain further clarification of the suggestions (\emph{``An alternative could be the chatbot to which I ask why {[}the code was suggested{]} after selecting the code''} -- G8).

Three complementary strategies emerged concerning the timing of explanations, i.e., \textbf{when} explanations should be shown during the interaction with the \acp{CCT}. The first solution is to activate the explanations by \emph{manually} \emph{interacting with the suggested code} (6 groups). For example, users can select the piece of suggested code they want to explain, right-click, then choose an ad-hoc function from a contextual menu, and the explanation is then displayed in a separate window, in the chatbot, or as a comment (``\emph{For example with the right click on the code and then pressing `explain'}'' -- G1); hovering over suggested code to show explanations contextually was also proposed by some groups (``\emph{... and then with an explicit request ...{} hovering on the code}'' -- G6). An alternative solution concerns activation via~\emph{shortcuts} (3 groups). Indeed, some participants suggested activating the explanations through a dedicated keyboard shortcut, granting users control without interfering with their workflow (``\emph{With a key I invoke the explanation}'' -- G8). Finally, an automatic approach along with the suggestion has also been proposed (3 groups), i.e., also accompanying the suggested code with an \emph{automatic short explanation, expandable on-demand}, which is especially useful when the suggestion is complex, reducing cognitive effort by presenting both simultaneously. A longer suggestion should be provided on-demand, for example, by interacting with the short suggestion and invoking more details (``\emph{... generated together with the code, as long as it is brief}'' -- G2; ``\emph{{[}explanation{]} details are provided on-demand}'' -- G3).

The last aspect concerns \textbf{what} to explain. The desired content of the explanations was varied, with participants identifying three key elements. The first aspect concerns \emph{purpose} (5 groups), i.e., explaining why a certain code suggestion was given. Indeed, many participants emphasized the need for explanations that clarify the purpose of the suggested code, specifying what it achieves in the broader context of the program (``\emph{{[}explain{]} why did it give me this suggestion?}'' -- G6; ``\emph{{[}explain{]} pros and cons of a suggested technique}'' -- G8). The second main aspect regards \emph{functionality} (4 groups), i.e., describing how the suggested code fulfills its purpose by reporting technical details such as the data structures, code constructs, data types and syntax involved (``\emph{What is the code composed of (in terms of data structures and chosen constructs)?}'' -- G6; ``\emph{explain the code, data types, ...{} syntax}'' -- G3); some groups also suggested displaying flow diagrams or pseudo-code to help developers understand complex suggestions and visualize the inner workings of the generated code (``\emph{With pseudocode, maybe also flowcharts}'' -- G1). Another popular aspect concerns the use of \emph{examples and references} to sources (5 groups): participants recommended that explanations include examples of the use of similar codes or references to reliable sources that might enable users to assess the credibility of the suggestion (``\emph{It may be sufficient to provide simple `pointers' to something that helps me understand ...{} such as links to source codes, or similar code examples as `insights'}'' -- G2). Regarding the scope of explanations, it emerged that \emph{explanations should be contextual} (4 groups) and not regard the entirety of the suggested code, but only the pieces of code that the user indicates (``\emph{We're not interested in being explained everything necessarily, but only of a piece {[}of code{]}}'' -- G1). A final aspect concerns the length of explanations: there was a popular agreement that \emph{explanations should be minimal and provide more details on request} (4 groups). Participants suggested that this can be achieved by, e.g., clicking a button to expand the explanation preview or by interacting with a chatbot to obtain an explanation incrementally (``\emph{If something else specific is needed, the user can ask explicitly}'' -- G3).

\section{Discussion}\label{discussion}

Our findings highlight important points regarding developer preferences and requirements while working with \ac{AI}-driven \acp{CCT}. In particular, this work underlines the importance of designing \acp{CCT} for developers' mental models to promote productivity, efficiency, and an intuitive coding experience. In the discussion reported in the following sub-sections, the interpretation of these results reveals how they challenge our current \ac{CCT} design paradigms and point toward improvements in \ac{CCT} design. \Cref{fig:mental-model} summarizes users' preferences and requirements, attempting to elicit developers' mental model of \acp{CCT}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{model.pdf}
    \caption{Graphical representation of users' preferences and mental model. The four aspects of \acp{CCT}, namely activation, visualization, content granularity, and explanations, are shown. All these dimensions are relevant for users' personalization.}
    \label{fig:mental-model}
\end{figure}

\subsection{Activation and control}\label{activation-and-control}

Participants expressed different preferences regarding when code suggestions by \ac{CCT} should be triggered, namely proactive, manual, and hybrid activation. This diversity in the mental model points to a key insight: in different contexts and coding tasks, developers might prefer different degrees of control. Some users mentioned that proactive suggestions, automatically activated during the coding flow breaks, might increase coding speed without explicit request. However, most users expressed the need for activation on-demand to control exactly when suggestions appeared. This is in line with similar studies regarding activation, as frequently \acp{CCT} are not adopted as they might disrupt developers' workflow \cite{Sergeyuk2025Using}. Rather, users favored a hybrid approach in which proactive behavior occurs only when a clear contextual need is present (such as when completing a complicated bit of code). 
However, proactive behavior should only occur once there is enough typing context (e.g., suggest code only if the file contains X tokens or more) to avoid generating unprecise or random suggestions. 
Therefore, a dynamic and adaptive activation model could serve different user needs by altering its behavior in response to task complexity and user-characteristic usage patterns. Such a model would leave developers in control of their workflow while helping proactively when needed.

\subsection{Visualization of suggestions}\label{visualization-of-suggestions}

The visualization mechanism of suggestions is crucial to the usability and acceptance of \acp{CCT}. The participants proposed different visualization strategies, each with pros and cons. The proposed strategies are inline suggestions shown with a different font, suggestions displayed in sidebars, or suggestions visualized in pop-ups. Having inline suggestions can be useful to avoid losing the coding focus and allow the user to accept or reject the suggestion immediately. However, the inline solution is well suited for short and concise suggestions that do not interfere too much with the code manually written by the users; on the contrary, in the case of long and complex suggestions, it may be better to have separate windows or pop-ups, to limit visual clutter. A further level of control would be having users manually invoke popups containing the suggestion by clicking an icon shown close to the handwritten code. Moreover, a chatbot in a separate window could be used as an alternative way to suggest code on-demand, with all the attached benefits of using conversational agents for code generation \cite{Ross2023Programmers}.

All these results may reveal an \emph{adaptable visualization}, where users can choose or alternate between inline, sidebar, and popups, and an \emph{adaptive visualization}, where the system visualizes the suggestion according to factors such as the suggestion length. Such modalities can improve usability by adapting to different workflows and developer preferences and might reduce the errors due to wrong intention communication as multiple choices may be provided when needed \cite{Sergeyuk2025Using}. This flexibility can also lower the cognitive overhead caused, for instance, by long pieces of generated code shown next to user-written code; in this way, \ac{CCT} allows developers to adjust the display of suggestions according to the complexity of the coding task or their personal coding style.

\subsection{Content and granularity}\label{content-and-granularity}

The study findings revealed that \acp{CCT} should be capable of generating suggestions at varying levels of granularity and that this granularity must be in the control of the users. Participants did not clearly agree on the minimum or maximum amount of tokens that should be suggested at any given time. Consequently, the \acp{CCT} should be designed to produce suggestions at different scopes, from predicting the next token in the code to completing control structures and generating entire functions or classes.

Although longer suggestions are useful, they can overwhelm the developer if displayed without considering the task context. For this reason, participants prefer retaining control over the level of granularity of suggestions. The necessity for varying degrees of granularity is also shared by other participants in different studies \cite{Wang2023How}. However, in general, users expressed a preference towards minimal, ``lower-scope'', suggestions at the first moment, with the possibility to obtain a longer, ``higher-scope'', suggestion on-demand; this approach of ``letting the user reason'' could help to prevent overreliance and deskilling. In practice, these directives might translate concretely into a minimalist suggestions behavior by default, with the possibility of using a slider or a control mechanism to adjust granularity in real time and adapt the suggestions to the contextual needs of the developer.

The control of granularity should also consider the number of offered alternatives; in certain use contexts, such as when developers face coding problems that they are not confident in, it may be beneficial for the user to have multiple options. Furthermore, code suggestions in such contexts may include documentation for constructs or functions the developer is not used to handling. Conversely, a suggestion with limited or no accompanying documentation should be presented for more straightforward and routinary tasks. These aspects could enhance user trust and overall acceptance of the suggestions.

\subsection{Explanation preferences}\label{explanation-preferences}

Participants generally considered explanations useful, but the answers to the question of \emph{what} should be contained in an explanation revealed a need for special care in their design. The concept of what defines a good explanation is not trivial and is an aspect that is widely studied in the literature \cite{Miller2019Explanation,Holzinger2020Measuring}. Moreover, even well-designed explanations should be evaluated with users to measure their quality \cite{Holzinger2020Measuring}. This elicitation study can be a precious source of information in understanding the desiderata of explanations in \acp{CCT} from the developers' point of view. A key finding is that explanations should be classified into two categories: \emph{why-explanations} and \emph{what-explanations}. Why-explanations address the rationale or purpose behind the generated code, whereas what-explanations concentrate on the functionality and technical intricacies of the code suggestion. The content should, however, be minimal, with the possibility to obtain more details when requested. This might translate into the \ac{CCT} by initially showing a brief why-explanation, providing a bird-eye view of what the generated code is for. A more thorough, on-demand explanation would instead detail the code nuances and technical aspects to help the developer get a deeper understanding of the suggestion, possibly even with flowcharts. Detailed explanations should also include references to trusted sources, such as documentation snippets, book pieces, etc., and even examples of use to enhance understanding.

Regarding where to show explanations, participants typically preferred separate elements (e.g., popups, sidebars), mainly because they did not want the explanations to be invasive and occupy space within the coding area. However, inline explanations may be accepted as comments close to the suggested code as long as their length is very limited. However, separate windows may allow developers to initiate an explanation process with a conversational agent, similar to what is possible to achieve with tools such as ChatGPT \cite{ChatGPT}.

Timing also plays a crucial role in showing the explanation. Some participants stated that explanations should be triggered manually using shortcuts, mouse clicks, or mouse hovering; notably, selecting code to explain with the mouse was a popular preference, also because it allows limiting the explanation to the context of the selection. Such an approach would have the advantage of reducing the amount of non-relevant explanation text to show to the user; moreover, it would also allow asking for further detailed explanations limited to a specific piece of manually selected code, possibly to a chatbot. Some other participants instead expressed that brief explanations should be shown automatically (especially for novice developers), letting the user choose whether to receive more details on demand. Thus, all these findings indicate that adaptive, context-aware explanations can increase the understanding and trust of a tool dealing with complex or ambiguous code suggestions.

\subsection{Personalization needs}\label{personalization-needs}

An aspect that emerged as essential to fit the CCT's behavior in different mental models is the explicit personalization of the CCT. There was indeed little consensus among participants towards one universally accepted solution; in fact, many individual factors, such as experience with coding, quality requirements, and personal preferences, play a role in determining the optimal behavior (and, therefore, acceptance) of the CCT. For example, developers want to customize when suggestions should appear, how to visualize them, and which granularity should be used by default. Choosing whether suggestions should also be suggested automatically resulted in being, indeed, crucial to users for the acceptance of the CCT, while they also expressed the preference to edit what manual action (e.g., shortcut, toggle button, etc.) activates the code completion. In addition, the possibility of customizing the suggestions' font, colors, and size and controlling the suggestions' position within the \ac{IDE} also proved useful. Another critical point regarded the need to customize the granularity of suggestions to control the amount of code provided by the tool, both regarding the scope of the suggestion (function-level, control structure-level, etc.) and the number of alternatives provided.

Moreover, users expressed the need to customize aspects regarding generating explanations regarding the suggested code. Therefore, it is important for developers to customize aspects such as the activation timing of explanations (whether to provide them proactively) and their granularity (such as the amount and frequency of comments within the generated code and the explanation abstraction).

Finally, customization of a \ac{CCT} should include the choice of default stylistic code (such as coding conventions, variable names, and styles) when generating code suggestions, possibly adapting to other past projects. Therefore, the developer should be allowed to ``fine-tune'' the code-generating model with a selection of other code repositories to align the suggestions with a knowledge base representing the generated code's style. This customization should also allow the developer to set standards of quality and security to which the generated code has to comply.

Thus, a personalization layer in \acp{CCT} should be introduced to allow developers to define \ac{CCT} settings to improve the tool's usability, acceptance, and trust. These customization options may aid in implementing a smoother running and adaptable \ac{CCT} experience to strengthen the correspondence of the \ac{CCT} conduct with developers' mental models.


\section{Prototype Development}\label{prototype-development}

The insights that emerged during the elicitation study represent a set of actionable guidelines for CCTs designers. To verify and demonstrate the feasibility of these guidelines, we developed \textit{ATHENA (AI Tool for Human-centered ENhanced coding Assistance)}, a proof of concept of a CCT for the Visual Studio Code \ac{IDE}. The tool's name was inspired by Athena, the Greek goddess of arts, crafts, and wisdom, and symbolizes intelligence, skill, and creativity—all attributes that align well with a tool designed to support developers. Developers can view the tool as a source of guidance, precision, and mastery, like Athena represents strategic thinking and expertise. The tool is available as open source software at the following link: \url{https://github.com/IVU-Laboratory/ATHENA}.

The extension dynamically adapts to the user's coding preferences and environment, ensuring seamless integration into various workflows. The AI backend employs OpenAI's \textit{GPT-4o mini}\footnote{https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/} to generate code suggestions and explanations. Of course, the AI model can be replaced with other similar solutions.

One of the major takeaways from the user study is that no ``one-size-fits-all'' approach exists to accommodate the needs of different types of users. Therefore, high customization was designated as a core feature in the tool's design. To this aim, \textit{ATHENA} offers robust configurability through its \textit{Settings Wizard Panel}, which is automatically displayed upon installation and remains accessible via a customizable shortcut. Settings are managed through Visual Studio Code's built-in infrastructure, supporting workspace and user-level configurations. The wizard is divided into two main sections: \textit{General Settings} and \textit{Shortcut Configuration}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{settings2.pdf}
    \caption{Screenshot of the settings provided with the prototype.}
    \label{fig:settings}
\end{figure}

The general settings (Figure \ref{fig:settings}) enable users to customize the behavior and appearance of the CCT:

\begin{itemize}
    \item \textit{Suggestion Length}: A slider ranging from 1 to 5 adjusts the granularity of suggestions, balancing concise completions with detailed recommendations tailored to the user’s needs.    
    \item \textit{Suggestion Appearance}: Users can choose from four display modes:
    \begin{itemize}
        \item Inline: Embeds suggestions directly in the text editor for a seamless experience.
        \item Tooltip: Shows suggestions in a hover menu near the cursor.
        \item Side Window: Displays suggestions in a dedicated subpanel for enhanced focus.
        %\item Chatbot: Analogously to the Side Window, displays suggestions in a side tab,  but also allows to interact with a chatbot. 
        \item Hybrid: Combines inline/tooltip suggestions for short completions and the side window for longer or more complex suggestions. 
    \end{itemize}
   \item \textit{Suggestion Timing}: Users can toggle between:
   \begin{itemize}
       \item Proactive: Automatically triggers suggestions as the user types, ideal for uninterrupted workflows.
        \item Manual: Requires explicit activation through a shortcut, reducing distractions.
   \end{itemize}
   \item \textit{Source References}: A checkbox lets users include or omit sources of suggestions, ensuring transparency for users who value understanding the origin of generated code
   \item \textit{Comments Frequency}: A slider allows users to adjust the frequency of comments in generated code, catering to both minimalist and documentation-focused coding styles.
\end{itemize}

%The ability to toggle auto-completion via a shortcut is particularly valuable for developers who work across varied tasks, as suggested in [Vaithilingam2023More]. For instance, during debugging, users may prefer to pause proactive suggestions to avoid distractions, while re-enabling them during standard coding sessions.

%While personalization focuses on tailoring suggestion behavior, the extension also includes an integrated chatbot to support developers with explanations on the code, both generated or written by the user. The chatbot is always available, regardless of the chosen suggestion modality, and serves as a conversational assistant for coding queries, clarifications on the generated code, and guidance. The user can toggle its presence in the \ac{UI} through a shortcut, which is customizable.

The shortcut configuration section, on the other side, allows users to assign shortcuts to key actions:
\begin{itemize}
    \item \textit{Invoke chatbot}: Quickly access a persistent chatbot for coding queries, explanations, and guidance.
    \item \textit{Open settings panel}: Revisit the settings at any time to adjust preferences.
    \item \textit{Trigger manual suggestions}: Activate suggestions when working in manual mode.
    \item \textit{Toggle auto-completion}: Enable or disable automated suggestions dynamically.
\end{itemize}

After the system is installed and customized, it can be used within Visual Studio Code. To assist developers during coding activities, ATHENA provides different interaction modalities. The first one is completely automatic and consists of proactive suggestions, which are automatically produced by ATHENA after a short idle time, and according to the preferences expressed by the users. If the developer wants to be more in control of the suggestions, ATHENA provides two different solutions. In the first case, shortcuts can be triggered while writing pieces of code, while in the second case, a chatbot can be open to interactively receive suggestions. 

Moreover, ATHENA allows the developer to receive explanations for selected pieces of code within the editor via contextual IDE options. Specifically, a light-bulb icon appears at the top of the selected code, allowing for three distinct actions:
\begin{itemize}
    \item \textit{Explain the Code (Concise)}: Offers a concise summary of the code's functionality for the selected code. 
    \item \textit{Explain the Code (Detailed)}: Offers a deeper explanation of the purpose and structure of the selected code. This can also include the use of examples.
    \item \textit{Open Chatbot}: Provides direct access to the chatbot with the selected code as context for further assistance.
\end{itemize}

Regardless of the solutions used by the developer to invoke the code suggestions and explanations, ATHENA's output can be visualized in two ways, according to the developer's preferences. The first solution consists of showing code/explanations within the code editor (either inline or in a tooltip). Another option is to show suggestions and explanations separately from the code editor within a side panel, as shown in Figure \ref{fig:sidebar}:

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{sidebar3.pdf}
    \caption{Prototype interface view in case the user prefers suggestions to be delivered in a separate panel.}
    \label{fig:sidebar}
\end{figure}

\begin{itemize}
    \item \textit{Suggestions/Completions}: Displays code completions only when the user has configured the display mode to ``Side Window'' or ``Hybrid.''
    \item \textit{Explanations}: Provides detailed explanations for selected code, ensuring clarity and context for the developer's work.
\end{itemize}

Given the high degree of customizability, \textit{ATHENA} addresses the issue of cold start by prompting the user with a question regarding their programming experience upon initial execution. Based on the user's response (which may be ``beginner'', ``intermediate'', or ``advanced''), the tool adapts the default values in order to tailor its behavior. For instance, the results of the elicitation study suggest that activation should be on-demand for intermediate users, as this was the most preferred behavior overall. On the other hand, a novice user might benefit from a proactive approach that suggests code as they type. As another example, an intermediate user might benefit from the inclusion of documentation references in the suggestions, whereas an expert user might perceive them as superfluous or cumbersome. These default settings configurations were chosen arbitrarily; however, future work may inform the design of the optimal configurations for different categories of users. Nevertheless, after the initial question, the user is presented with the settings panel, where each configuration can be readily modified. 

\subsection{Use Case Scenarios}
In the following, two scenarios are reported to clarify how the ATHENA tool can be installed and used the first time (Scenario 1, \Cref{scenario-1}) and how the tool can be used by the same users in different contexts, thus demonstrating its suitability to different mental models of the same users (Scenario 2, \Cref{scenario-2}). Two videos of the two scenarios are also attached to show how ATHENA works.

\subsubsection{Scenario 1: ATHENA installation and first usage}\label{scenario-1}

Alex, a junior software developer at CodeCraft, is starting a new back-end API project for an e-commerce platform. To streamline their workflow, Alex installs the ATHENA Extension in Visual Studio Code.
After installation, the extension prompts Alex with a popup asking their level of experience with programming. Alex answers the question by indicating ``intermediate'': this will automatically set the tool's parameters to an intermediate user profile, e.g., by disabling proactive suggestions. %; for example, proactive suggestions will be disabled, as they might better fit a novice rather than an experienced user.
Nonetheless, the tool launches its \textit{Settings Panel}, guiding Alex through the initial configuration process and giving them the possibility to change the default parameters. In the general settings, Alex sets the display mode to \textit{Inline} to benefit from suggestions directly placed inside the editor. Alex thinks that suggestions that appear automatically while coding would be better and, therefore, chooses to set the suggestion trigger mode to \textit{Proactive}. To fine-tune the experience, Alex adjusts the \textit{suggestion length} slider to a medium level for balanced granularity.
In the \textit{Shortcut Configuration} section, Alex assigns shortcuts for invoking the chatbot, toggling auto-completion, and manually triggering suggestions. Satisfied with the setup, Alex saves the preferences and begins coding.
As Alex starts writing the first few lines, inline suggestions appear seamlessly, offering useful completions for common coding patterns. 

\subsubsection{Scenario 2: Adapting to Debugging Needs}\label{scenario-2}

A few weeks later, Alex is tasked with debugging a critical issue in the API's payment processing module. While the \textit{Proactive Mode} had been helpful during development, Alex finds it distracting when troubleshooting errors. Recognizing the extension's flexibility, Alex opens the Settings Panel and switches the trigger mode to \textit{Manual}, ensuring suggestions only appear when explicitly requested. Alex also reduces the \textit{Suggestion Length} to receive concise completions that are better suited for debugging.

During debugging, Alex selects a block of code that seems problematic. A lightbulb icon appears next to the selected code, offering three options: ``Explain the Code (Concise)'', ``Explain the Code (Detailed)'', and ``Open Chatbot''. Alex selects the first option (\textit{Explain the Code (Concise)}) and promptly receives a brief summary of the code's functionality. However, Alex wants to delve deeper into the details of the generated code; therefore, they select the second option (\textit{Explain the Code (Detailed)}), which provides a more in-depth explanation, helping them understand the logic and potential pitfalls. Finally, to receive additional guidance, Alex selects the \textit{Open Chatbot} option; this invokes the chatbot, which provides context-aware suggestions for refactoring the code. 

Later, Alex notices the Side Panel's explanation subpanel automatically updating with insights about the selected code. Combined with the concise suggestions displayed in the completion subpanel, Alex efficiently resolves the issue.

By tailoring the tool’s behavior to their specific debugging needs, Alex maintains focus and leverages the extension's features to complete the task effectively. The combination of personalized settings, code actions, and a context-aware chatbot reinforces the tool's versatility and value in diverse workflows.

\section{Conclusion}\label{conclusion}

The use of \ac{CCT}s has seen a notable increase in recent years and chances are that they will be used more and more in the future. Nevertheless, their acceptance strongly depends on their alignment with developers' mental models. This study investigated the desiderata of \ac{CCT}s through an elicitation study with programmers of varying expertise levels. Our findings indicate that, except for a few shared properties, there is no consensus on features such as activation timing, position, and granularity of suggestions and explanations. This lack of agreement on the specifics of CCTs thus indicates that they necessitate a high degree of customizability.

Based on the findings of the elicitation study, we have also developed \textit{ATHENA}, a prototype of a \ac{CCT} for Visual Studio Code that is highly customizable and implements most of the features identified by our users. This tool is openly available to the research community and will be essential to conduct future user studies that assess how different characteristics of a \ac{CCT} (e.g., the position of the code suggestion or the activation behavior) can affect its usability and user performance.
In future work, we will investigate these differences with a controlled experiment to isolate different variables and measure their effects individually.

Limitations of this study mostly regard the convenience sampling methodology that was adopted, which led to a sample of very young participants, with limited to no expertise in companies. Therefore, despite the large sample size, the findings of this study are not directly generalizable to professional developers. To address this limitation we plan to conduct usablity studies with different categories of users. Such studies will be initially conducted in a laboratory setting, and then in-the-wild within an IT company; this will allow us to measure the effectiveness and usability of \textit{ATHENA} compared to other popular \ac{CCT}s. Moreover, we will observe how different features of a CCT can affect the usability and performance of users with varying degrees of expertise with different categories of users. 
Future work will also entail further developing our \ac{CCT} and extending its functionalities by implementing the remaining features that emerged from the elicitation study. Moreover, we will explore the use of different \ac{LLM}s as the AI code completion engine of the tool; in fact, to generate code suggestions and explanations \textit{ATHENA} employs OpenAI's GPT-4o mini, an \ac{LLM} which has a limited size but performs well on coding problems \cite{2024GPT4oMini}. However, different models may prove more suitable for use in corporate settings. For instance, a non-commercial solution such as Meta's open-source LLM \textit{LLama} \cite{2024LLama3-2} could be deployed on a company's server to prevent sharing confidential data, such as project repositories, with third parties. Furthermore, models of varying sizes could be contemplated in light of a tradeoff between costs and performance.      


\section*{Acknowledgements}\label{sec:acknowledgements}
This research is partially funded by the Italian Ministry of University and Research (MUR) and by the European Union - NextGenerationEU, Mission 4, Component 2, Investment 1.1, under grant PRIN 2022 ``DevProDev: Profiling Software Developers for Developer-Centered Recommender Systems'' — CUP: H53D23003620006.

The research of Andrea Esposito is funded by a Ph.D.~fellowship within the framework of the Italian ``D.M.~n.~352, April 9, 2022'' - under the National Recovery and Resilience Plan, Mission 4, Component 2, Investment 3.3 - Ph.D. Project ``Human-Centered Artificial Intelligence (HCAI) techniques for supporting end users interacting with AI systems'', co-supported by ``Eusoft S.r.l.'' (CUP H91I22000410007).

The research of Francesco Greco is funded by a PhD fellowship within the framework of the Italian “D.M. n. 352, April 9, 2022”- under the National Recovery and Resilience Plan, Mission 4, Component 2, Investment 3.3 - PhD Project “Investigating XAI techniques to help user defend from phishing attacks”, co-supported by “Auriga S.p.A.” (CUP H91I22000410007).

\section*{Statements and Declaration}\label{statements-and-declaration}

\subsection*{Conflicts of Interest}\label{conflicts-of-interest}

The authors declare no conflicts of interest.

\subsection*{Authors Contribution Statement}
\credit{Giuseppe Desolda}{Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing -- original draft, Writing -- review \& editing}
\credit{Andrea Esposito}{Investigation, Methodology,  Validation, Visualization, Writing -- original draft, Writing -- review \& editing}
\credit{Francesco Greco}{Data curation, Formal analysis, Investigation, Methodology, Software, Writing -- original draft, Writing -- review \& editing}
\credit{Cesare Tucci}{Data curation, Formal analysis, Investigation, Methodology, Software, Writing -- original draft, Writing -- review \& editing}
\credit{Paolo Buono}{Writing -- original draft, Writing -- review \& editing}
\credit{Antonio Piccinno}{Writing -- original draft, Writing -- review \& editing}

\insertcreditsstatement

 \bibliographystyle{elsarticle-num-names}
 \bibliography{main}


%\clearpage
%\appendix

%\section{Thematic Analysis Themes and Codes}\label{app:themes}

%In the following are reported the themes and codes that emerged from the thematic analysis divided for each research question.

%% RQ8
%\begin{table}[ht]
%\centering
%\caption{Themes for RQ8}
%\label{tab:rq8themes}
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{@{}m{0.15\linewidth}c|m{0.55\linewidth}c@{}}
%\toprule
%\textbf{Themes} & \textbf{\begin{tabular}[c]{@{}c@{}}Theme\\ Frequency\end{tabular}} & \textbf{Codes} & \textbf{\begin{tabular}[c]{@{}c@{}}Code\\ Frequency\end{tabular}} \\ \midrule
%\multirow{3}{\linewidth}{\textit{Purpose}} & \multirow{3}{*}{5} & - Explain why the code was generated in a specific manner & 4 \\
% &  & - List pros and cons about the generated code & 1 \\
% &  & - Explain different possible alternatives & 1 \\
%\hline
%\multirow{3}{\linewidth}{\textit{Examples and references}} & \multirow{3}{*}{5} & - Provide real-world examples for better understanding & 4 \\
% &  & - Add documentation references & 3 \\
% &  & - Use trusted sources to report additional information in the explanation & 2 \\
%\hline
%\textit{Contextual explanation} & 4 & - Provide suggestion of the selected piece of code & 4 \\
%\hline
%\multirow{3}{\linewidth}{\textit{Minimal explanation, details on-demand}} & \multirow{3}{*}{4} & - Explanation should be minimal, with the possibility to manually ask for more detail & 2 \\
% &  & - It would be useful to provide the explanation as a dialogue in a chat interaction & 1 \\
% &  & - Provide an explanation preview that is expandable on Demand & 1 \\
%\hline
%\multirow{5}{\linewidth}{\textit{Functionality}} & \multirow{5}{*}{4} & - Explanation should describe what the code is and does & 3 \\
% &  & - Explanation should cover what data structures and code constructs appear in the generated code & 2 \\
% &  & - Show pseudocode or flowcharts & 2 \\
% &  & - Explanation should cover aspects that are not familiar to the user & 1 \\
% &  & - Explanation should also explain low level concepts such as syntax and data types & 1 \\ \bottomrule
%\end{tabular}%
%}
%\end{table}

\appendix
\section{Themes and Codes}\label{app:themes}
\input{tables}

\end{document}