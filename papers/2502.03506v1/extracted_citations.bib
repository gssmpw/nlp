@article{bohmer2019exploration,
  title={Exploration with unreliable intrinsic reward in multi-agent reinforcement learning},
  author={B{\"o}hmer, Wendelin and Rashid, Tabish and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1906.02138},
  year={2019}
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI/IAAI},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}

@inproceedings{foerster2017stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip HS and Kohli, Pushmeet and Whiteson, Shimon},
  booktitle={International conference on machine learning},
  pages={1146--1155},
  year={2017},
  organization={PMLR}
}

@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{huang2023sampling,
  title={Sampling efficient deep reinforcement learning through preference-guided stochastic exploration},
  author={Huang, Wenhui and Zhang, Cong and Wu, Jingda and He, Xiangkun and Zhang, Jie and Lv, Chen},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{kim2020maximum,
  title={A maximum mutual information framework for multi-agent reinforcement learning},
  author={Kim, Woojun and Jung, Whiyoung and Cho, Myungsik and Sung, Youngchul},
  journal={arXiv preprint arXiv:2006.02732},
  year={2020}
}

@inproceedings{li2024optimistic,
  title={Optimistic Value Instructors for Cooperative Multi-Agent Reinforcement Learning},
  author={Li, Chao and Zhang, Yupeng and Wang, Jianqi and Hu, Yujing and Dong, Shaokang and Li, Wenbin and Lv, Tangjie and Fan, Changjie and Gao, Yang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={17453--17460},
  year={2024}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{liu2021cooperative,
  title={Cooperative exploration for multi-agent deep reinforcement learning},
  author={Liu, Iou-Jen and Jain, Unnat and Yeh, Raymond A and Schwing, Alexander},
  booktitle={International conference on machine learning},
  pages={6826--6836},
  year={2021},
  organization={PMLR}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{lyu2018likelihood,
  title={Likelihood quantile networks for coordinating multi-agent reinforcement learning},
  author={Lyu, Xueguang and Amato, Christopher},
  journal={arXiv preprint arXiv:1812.06319},
  year={2018}
}

@article{papoudakis2020benchmarking,
  title={Benchmarking multi-agent deep reinforcement learning algorithms in cooperative tasks},
  author={Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:2006.07869},
  year={2020}
}

@article{pina2022residual,
  title={Residual q-networks for value function factorizing in multiagent reinforcement learning},
  author={Pina, Rafael and De Silva, Varuna and Hook, Joosep and Kondoz, Ahmet},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={35},
  number={2},
  pages={1534--1544},
  year={2022},
  publisher={IEEE}
}

@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={178},
  pages={1--51},
  year={2020}
}

@article{rashid2020weighted,
  title={Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10199--10210},
  year={2020}
}

@article{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{shen2022resq,
  title={Resq: A residual q function-based approach for multi-agent reinforcement learning value factorization},
  author={Shen, Siqi and Qiu, Mengwei and Liu, Jun and Liu, Weiquan and Fu, Yongquan and Liu, Xinwang and Wang, Cheng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5471--5483},
  year={2022}
}

@inproceedings{son2019qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International conference on machine learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@inproceedings{sun2021dfac,
  title={DFAC framework: Factorizing the value function via quantile mixture for multi-agent distributional Q-learning},
  author={Sun, Wei-Fang and Lee, Cheng-Kuang and Lee, Chun-Yi},
  booktitle={International Conference on Machine Learning},
  pages={9945--9954},
  year={2021},
  organization={PMLR}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@article{wang2019influence,
  title={Influence-based multi-agent exploration},
  author={Wang, Tonghan and Wang, Jianhao and Wu, Yi and Zhang, Chongjie},
  journal={arXiv preprint arXiv:1910.05512},
  year={2019}
}

@article{wang2020qplex,
  title={Qplex: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2008.01062},
  year={2020}
}

@inproceedings{zhao2023conditionally,
  title={Conditionally optimistic exploration for cooperative deep multi-agent reinforcement learning},
  author={Zhao, Xutong and Pan, Yangchen and Xiao, Chenjun and Chandar, Sarath and Rajendran, Janarthanan},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={2529--2540},
  year={2023},
  organization={PMLR}
}

