\newacronym{MAP}{map}{maximum-a-posteriori}
\newacronym{MLE}{mle}{maximum likelihood estimation}
\newacronym{MNLL}{mnll}{mean negative loglikelihood}
\newacronym{NLL}{nll}{negative loglikelihood}
\newacronym{LL}{ll}{log-likelihood}
\newacronym{RMSE}{rmse}{root mean squared error}
\newacronym{ECE}{ece}{expected calibration error}
\newacronym{FID}{fid}{Fr\'echet Inception Distance}
\newacronym{MSE}{mse}{mean squared error}

\newacronym{PCA}{pca}{principal component analysis}
\newacronym{AE}{ae}{autoencoder}
\newacronym{WAE}{wae}{Wasserstein Autoencoder}
\newacronym{VAE}{vae}{Variational Autoencoder}
\newacronym{BAE}{bae}{Bayesian autoencoder}
\newacronym{CDF}{cdf}{cumulative density function}
\newacronym{GAN}{gan}{Generative Adversarial Network}

\newacronym{MC}{mc}{Monte Carlo}
\newacronym{MCMC}{mcmc}{Markov chain Monte Carlo}
\newacronym{HMC}{hmc}{Hamiltonian Monte Carlo}
\newacronym{MH}{mh}{Metropolis-Hastings}
\newacronym{NUTS}{nuts}{no-u-turn sampler}
\newacronym{SGHMC}{sghmc}{stochastic gradient Hamiltonian Monte Carlo}

\newacronym{DGP}{dgp}{deep Gaussian process} %
\newacronym{GPLVM}{gplvm}{Gaussian process latent variable model}
\newacronym{DPMM}{dpmm}{Dirichlet Process Mixture Model}

\newacronym{VFE}{vfe}{variational free energy}

\newacronym[firstplural=Gaussian Processes]{GP}{gp}{Gaussian Process}

\newacronym{VI}{vi}{variational inference}

\newacronym{ELBO}{elbo}{evidence lower bound}
\newacronym{NELBO}{nelbo}{negative evidence lower bound}
\newacronym{ELL}{ell}{expected log likelihood}
\newacronym{KL}{kl}{Kullback-Leibler divergence}
\newacronym{AUC}{auc}{area under the curve}

\newacronym[firstplural=Bayesian neural networks]{BNN}{bnn}{Bayesian neural network}
\newacronym[firstplural=deep neural networks]{DNN}{dnn}{deep neural network}
\newacronym[]{CNN}{cnn}{convolutional neural network}
\newacronym{MLP}{mlp}{multilayer perceptron}
\newacronym{NN}{nn}{neural network}
\newacronym{RELU}{ReLU}{rectified linear unit}

\newacronym{NF}{nf}{normalizing flow}

\newacronym{RBF}{rbf}{radial basis function}
\newacronym{ARD}{ard}{automatic relevance determination}

\newacronym{RKHS}{rkhs}{reproducing kernel Hilbert space}

\newacronym{OT}{ot}{optimal transport}
\newacronym{WD}{wd}{Wasserstein distance}
\newacronym{SWD}{swd}{sliced-Wasserstein distance}
\newacronym{DSWD}{dswd}{distributional sliced-Wasserstein distance}
\newacronym{BSGPAE}{bsgpae}{Bayesian Sparse Gaussian Process Autoencoder}
\newacronym{GPBAE}{{gp}-{bae}}{Gaussian Process Bayesian Autoencoder}
\newacronym{CVAE}{cvae}{Conditional Variational Autoencoder}
\newacronym{SGPBAE}{{sgp}-{bae}}{Sparse Gaussian Process Bayesian Autoencoder}




\newcommand{\iid}{i.i.d~} 

\newcommand{\name}[1]{{\textsc{#1}}\xspace}

\newcommand{\lenet}{\name{lenet5}}
\newcommand{\vgg}{\name{vgg16}}
\newcommand{\preresnet}{\name{preresnet20}}

\newcommand{\mnist}{\name{mnist}}
\newcommand{\celeba}{\name{celeba}}
\newcommand{\yale}{\name{yale}}
\newcommand{\frey}{\name{frey}}
\newcommand{\freyyale}{\textsc{frey}-\textsc{yale}\xspace}

\newcommand{\wae}{\name{wae}}
\newcommand{\vae}{\name{vae}}
\newcommand{\vaes}{\name{vaes}}
\newcommand{\bae}{\name{bae}}
\newcommand{\vamp}{\textsc{vae}+\textsc{vamp prior}\xspace}
\newcommand{\sylvester}{\name{frey}}

\newcommand{\adrflvm}{\textsl{advised}\textsc{rflvm}\xspace}
\newcommand{\gpvae}{\textsc{gp}-\textsc{vae}\xspace}
\newcommand{\svgpvae}{\textsc{svgp}-\textsc{vae}\xspace}
\newcommand{\deepsvigp}{\textsc{deep}-\textsc{svigp}\xspace}
\newcommand{\deepbsgpae}{\textsc{deep}-\textsc{bsgpae}\xspace}
\newcommand{\deepsgpbae}{\textsc{dsgp}-\textsc{bae}\xspace}
\newcommand{\gppvae}{\textsc{gppvae}\xspace}
\newcommand{\sgpvae}{\textsc{sgp}-\textsc{vae}\xspace}
\newcommand{\igp}{\textsc{igp}\xspace}
\newcommand{\gpar}{\textsc{gpar}\xspace}
\newcommand{\nll}{\textsc{nll}\xspace}
\newcommand{\mae}{\textsc{mae}\xspace}
\newcommand{\smse}{\textsc{smse}\xspace}