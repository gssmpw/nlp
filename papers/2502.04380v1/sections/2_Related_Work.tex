

\section{Related Work}
\paragraph{Data Selection} Fine-tuning is a pivotal training paradigm for enhancing LLMs' task-specific and domain-specific capabilities. Research has shown that a small set of instruction pairs can enable LLMs to follow major instructions effectively \cite{zhou2024lima,djv1}. This fine-tuning can be achieved through rule-based methods, which focus on attributes such as Error L2-Norm~\cite{paul2021el2n} and token length~\cite{raffel2020exploring}. More recently, model-based heuristics have been explored, including methods based on instruction-following difficulty~\cite{li2024super}, GPT scoring~\cite{chen2024alpagasus, 2024qurating}, data model selection~\cite{2024dsdm}, and influence scores derived from loss~\cite{xialess}.

\paragraph{Diversity \& Data Mixing} A fundamental principle for LLMs is being able to handle diverse human requests, underscoring data diversity as essential for effective fine-tuning~\cite{yu2022can, ding2023enhancing}. Data diversity encompasses aspects such as data deduplication~\cite{abbas2023semdedup}, the coverage scope of tags~\cite{lu2023instag}, model-based diversity evaluation~\cite{liu2023deita, zhang2024harnessing}, and scaling properties~\cite{song2024scaling}. Typically, data mixing approaches~\cite{albalak2023efficient, ye2024data, ge2024bimix} focus on adjusting the proportional weights of different domains to enhance model capabilities.

\paragraph{Our Position} 
From a modeling perspective, our work shares a focus with many data mixing methodologies regarding diversity measurement. However, we address a more challenging setting relevant to real-world applications, where available datasets often lack domain labels. This situation presents challenges for existing mixing methods in balancing label granularity and normalization, and in determining which domains should be considered as candidates for improved solution spaces and tuning performance.

Methodologically, our approach aligns with the data selection category but differs in both the learning process (utilizing a rewarding model) and the selection criteria (employing semantic entropy). Additionally, we revisit the applicability of existing selection methods in multi-domain scenarios. This area is under-explored and requires new insights to avoid biased modeling of diverse domain distributionsâ€”a topic we further investigate in this paper.