%%%% ijcai25.tex

\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
% \usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{comment}
% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

\title{Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content }
%\title{Invisible Walls in Cities: Revealing Segregation Experience in Social Media Content with Large Language Model}


% Single author syntax
%\author{
%    Author Name
%    \affiliations
%    Affiliation
%    \emails
%    email@example.com
%}
% \author{Anonymous Submission}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
Bingbing Fan$^1$\thanks{These two authors contributed equally.}
\and
Lin Chen$^2$\footnotemark[1]\and
Songwei Li$^{1}$\and
Jian Yuan$^1$ \and
Fengli Xu$^{1}$ \thanks{Corresponding author}\and
Pan Hui$^{2,3}$ \footnotemark[2]\and
Yong Li$^{1}$\footnotemark[2]\\
\affiliations
$^1$Tsinghua University\\
$^2$The Hong Kong University of Science and Technology\\
$^3$Hong Kong University of Science and Technology (Guangzhou)\\
\emails
fbb24@mails.tsinghua.edu.cn,
lchencu@connect.ust.hk,
lisw21@mails.tsinghua.edu.cn,
\{jyuan,fenglixu\}@tsinghua.edu.cn,
panhui@ust.hk,
liyong07@tsinghua.edu.cn
}
% \fi

\begin{document}

\maketitle

\begin{abstract}
    Understanding experienced segregation in urban daily life is crucial for addressing societal inequalities and fostering inclusivity. The abundance of user-generated reviews on social media encapsulates nuanced perceptions and feelings associated with different places, offering rich insights into segregation. However, leveraging this data poses significant challenges due to its vast volume, ambiguity, and confluence of diverse perspectives. To tackle these challenges, we propose using Large Language Models (LLMs) to automate online review mining for segregation prediction. We design a \textbf{Reflective LLM Coder} to digest social media content into insights consistent with real-world feedback, and eventually produce a codebook capturing key dimensions that signal segregation experience, such as \textit{cultural resonance and appeal}, \textit{accessibility and convenience}, and \textit{community engagement and local involvement}. Guided by the codebook, LLMs can generate both informative review summaries and ratings for segregation prediction. Moreover, we design a \textbf{\underline{RE}asoning-and-\underline{EM}bedding (RE'EM)} framework, which combines the reasoning and embedding capabilities of language models to integrate multi-channel features for segregation prediction. 
    Experiments on real-world data demonstrate that our framework greatly improves prediction accuracy, with a 22.79\% elevation in R$^{2}$ and a 9.33\% reduction in MSE. 
    The derived codebook is generalizable across three different cities, consistently improving prediction accuracy.
    Moreover, our user study confirms that the codebook-guided summaries provide cognitive gains for human participants in perceiving POIs' social inclusiveness.
    Our study marks an important step toward understanding implicit social barriers and inequalities, demonstrating the great potential of promoting social inclusiveness with AI.
\end{abstract}
%, demonstrating the effectiveness of our method in generating human-comprehensible summaries and reliable predictions
%providing a unique opportunity to understand and predict experienced segregation at scale
%To validate our approach, we conduct both qualitative user studies and quantitative experiments on four US cities. Results show that our method can generate operational summaries that enhance human understanding, and improve prediction accuracy by 22.79\%. 
%Through qualitative user studies and quantitative experiments in four U.S. cities, we demonstrate that our approach enhances human understanding and improves prediction accuracy by 22.79\%, which is generalizable across cities. 
%This codebook effectively guides LLM to generate informative online review summaries 

\section{Introduction}

Segregation refers to the systematic separation of individuals or groups based on certain characteristics. 
Historically, research on segregation has focused primarily on residential patterns~\cite{park25city}, where individuals of the same racial or ethnic group are more likely to reside in the same neighborhoods~\cite{schelling2006micromotives}. 
This type of spatial segregation has been linked to negative social outcomes, such as limited upward social mobility and increased crime rates~\cite{gordon2006urban,kramer2009segregation}.
%With the proliferation of mobility data from smart devices, 
Recent studies have shifted focus to experienced segregation—the dynamic segregation individuals experience in daily movements~\cite{moro2021mobility}.
Despite the seemingly free human movements in most modern urban spaces, certain demographic groups continue to face barriers to equal access and social interactions.
In other words, there seem to be “invisible walls” in cities that prevent sufficient social interactions between groups. 
These walls are not merely the result of physical proximity but are influenced by cultural, social, and economic factors that drive segregation on a more nuanced level.
Accurately predicting segregation experiences can inform individuals to avoid potentially uncomfortable situations and support policymakers in fostering social inclusiveness.
Moreover, research suggests that segregation experiences can intensify in larger urban areas~\cite{nilforoshan2023human}, underscoring the need to explore the underlying mechanisms for growing more equitable cities admist ever-increasing urbanization.
However, existing studies only present retrospective and holistic measurements, providing limited insights and prediction capabilities.

The rapid advancement of web technologies has enabled fine-grained records of social interactions through diverse media, such as textual posts~\cite{weller2014twitter}, photos~\cite{gilbert2013need}, and short videos~\cite{chen2024shorter}. %,neri2012sentiment
As a result, social media platforms have become extensive social sensing systems, generating rich digital traces that reflect social dynamics in the physical world~\cite{stier2021evidence,iqbal2023lady}. 
Such data offers a unique opportunity to uncover subtle patterns or preferences in individuals' everyday life, enabling more accurate predictions and insights into how segregation manifests beyond spatial confines. 
%Analyzing such content can uncover the hidden barriers that perpetuate experienced segregation, enabling more accurate predictions and insights into how segregation manifests beyond spatial confines. 
However, identifying cues of segregation experience from massive social media content poses significant challenges, requiring advanced methods to capture nuanced feelings, and there is no established procedure to guide this process. 
%Against this backdrop, this paper addresses the critical research challenge of identifying segregation experiences embedded in massive social media content. 
%Online reviews of physical locations serve as a rich resource for crowd-sourcing user perceptions of subtle socio-economic factors~\cite{iqbal2023lady}, such as cultural resonance, family-friendliness, and community atmosphere. 
%The proliferation of social media content, particularly online reviews of places, presents a promising opportunity to explore these dynamic segregation experiences. 
%By analyzing such data, we can uncover the hidden barriers that perpetuate segregation in everyday life, enabling more accurate predictions and insights into how segregation manifests beyond spatial confines. 
%The availability of social media content, such as online reviews of places, provides a promising avenue to move beyond static spatial contexts and investigate dynamic segregation experiences, \emph{i.e.,} revealing the ``invisible walls’’ that prevent social interactions. 
%Earlier segregation studies primarily focused on static spatial distributions of demographic groups~\cite{kramer2009segregation}, characterizing the difficulty of social mixing with physical distance.
%Besides, an important hypothesis suggests that segregation experiences may increase in compact urban environments~\cite{nilforoshan2023human}, underscoring the need to explore the ``invisible walls’’ formed by complex socio-economic factors beyond physical proximity. 
   

To address these challenges, we propose to leverage the reasoning power of LLMs for automated social media content analysis. 
We propose a \textbf{Reflective LLM Coder}, featuring a strategic agentic workflow that integrates two key components: a \textit{reflective attributor} and a \textit{code summarizer}. 
The \textit{reflective attributor} employs an abductive reasoning approach: %to integrate online reviews with empirical observations of segregation experiences. 
it prompts the LLM to estimate a location’s appeal to different demographic groups from its social media content, and reconcile discrepancies through iterative reflection on observed segregation patterns. %compare these predictions with observed segregation patterns, and facilitate iterative reflection to reconcile discrepancies. 
%This process enables the LLM to correct potential biases and generate insights consistent with real-world observations. 
Subsequently, the \textit{code summarizer} applies chain-of-thought reasoning~\cite{wei2022chain} to iteratively merge insights into a structured codebook. %that highlights key dimensions for identifying segregation cues such as cultural resonance, accessibility, and community engagement. 
This codebook guides LLMs to transform free-text reviews into structured summaries, highlighting segregation-related factors like cultural resonance and community engagement.
Complementing this qualitative approach, we propose a \textbf{\underline{RE}asoning and \underline{EM}bedding (RE'EM) framework} for quantitative segregation prediction, which combines LLMs' reasoning capabilities with the representational power of pre-trained embedding models. 
First, we prompt the LLM to provide structured ratings of a place’s appeal to different groups based on the codebook, allowing the reasoning outcomes of LLMs to be vectorized and easily integrated with other channels of features. %This allows the reasoning outcomes of LLMs to be represented in a vector format and thus can be easily integrated with other features. 
Concurrently, we fine-tune a pre-trained embedding model to learn global representations optimized for segregation prediction. 
Finally, the RE'EM framework fuses structured ratings, global embeddings, and population information using a neighbor-aware multi-view predictor. %using a two tower-like neural network to predict segregation levels.

We validate our approach through qualitative user studies and quantitative experiments on four US cities. 
%The experiments utilize the Yelp online review data, SafeGraph mobility data, and demographic distributions from the U.S. Census to compute ground truth experienced segregation measures~\cite{moro2021mobility}.
%In our user study, 75 graduate students assessed the informativeness of online reviews for predicting a location's appeal to different racial/ethnic groups. 
%Participants struggled to extract segregation-related insights directly from original online reviews, but their accuracy improved by 19.02\% when provided with LLM-generated summaries. 
%The results show that participants' prediction accuracy greatly improved when provided with LLM-generated summaries.
In our user study with 75 researchers, participants' prediction accuracy greatly improved when provided with LLM-generated summaries.
Furthermore, as many as 80\% of participants prefer the codebook-guided summaries over vanilla LLM outputs. 
In quantitative experiments, the RE'EM framework improves the predictive $R^2$ by 22.79\% and reduces the MSE by 9.33\% compared to baseline models relying solely on local racial composition, which is generalizable across multiple cities.

Our contributions are summarized as follows:
\begin{itemize}
\item We are the first to explore the use of social media content for predicting POI experienced segregation.
\item We design a reflective LLM coder to effectively summarize online reviews and identify cues of segregation.
\item We propose a REasoning-and-EMbedding (RE'EM) framework that combines the reasoning and embedding capabilities of language models to predict segregation.
\item We validate our approach through comprehensive qualitative and quantitative evaluations, demonstrating its effectiveness in extracting operationable insights and generalizing segregation prediction improvement. %predictive accuracy for segregation prediction with social media content.
\end{itemize}


% %
% \subsection{Length of Papers}

% All paper {\em submissions} to the main track must have a maximum of seven pages, plus at most two for references / acknowledgements / contribution statement / ethics statement.

% The length rules may change for final camera-ready versions of accepted papers and
% differ between tracks. Some tracks may disallow any contents other than the references in the last two pages, whereas others allow for any content in all pages. Similarly, some tracks allow you to buy a few extra pages should you want to, whereas others don't.

% If your paper is accepted, please carefully read the notifications you receive, and check the proceedings submission information website\footnote{\url{https://proceedings.ijcai.org/info}} to know how many pages you can use for your final version. That website holds the most up-to-date information regarding paper length limits at all times.


% \subsection{Word Processing Software}

% As detailed below, IJCAI has prepared and made available a set of
% \LaTeX{} macros and a Microsoft Word template for use in formatting
% your paper. If you are using some other word processing software, please follow the format instructions given below and ensure that your final paper looks as much like this sample as possible.




\section{Related Work}

%\subsection{Urban Segregation}
\noindent \textbf{Experienced Segregation.}
The study of segregation traces its roots back to the early 20th century, when sociologists examined the division of urban spaces into ``ecological niches'', each inhabited by distinct social groups~\cite{park25city}. %such as Robert Park and Ernest Burgess
%This phenomenon gained further attention after the U.S. Civil Rights Movement. 
Researchers revealed the detrimental effects of enduring segregation even in the absence of ``legalized racial segregation'', on education, income, housing, and crime~\cite{king1973racial,massey1987effect,charles2003dynamics}.
Albeit offering valuable insights, these studies are highly constrained by data availability, overlooking the reality that individuals spend significant time and engage in numerous interactions beyond the confines of their residential neighborhoods~\cite{wang2018urban}.
With the rapid proliferation of smart mobile devices, the ability to track people's intricate movements in urban spaces has emerged~\cite{xu2016understanding}.
This has paved the way for a novel research avenue aimed at quantifying and understanding the type of segregation individuals actually \textit{experience} in their daily movements~\cite{moro2021mobility,athey2021estimating,de2024people}, including how it may change during disasters~\cite{yabe2023behavioral,chen2023getting} and scale with city sizes~\cite{nilforoshan2023human}.
Nevertheless, existing studies primarily focus on static spatial distribution of demographic groups and physical movement, overlooking the complex socioeconomic factors behind the segregation phenomenon, such as cultural resonance and local involvement.
Thus, these works can only provide retrospective measurement but have limited predictive power. 
In contrast, our work establishes an LLM-based method to automatically extract nuanced features from online reviews for experienced segregation prediction.

\noindent \textbf{Mining Web Data with LLMs.}
The digital footprints and rich textual contents people generate on Web platforms have proven to be informative for a wide array of social phenomena, including health outcome~\cite{nguyen2016building}, mental well-being~\cite{mitchell2013geography}, crime rates~\cite{fatehkia2019correlated}, and neighborhood disparities~\cite{rama2020facebook,iqbal2023lady}. However, these studies often rely on pre-calculated indices or pre-defined word lists to engineer and extract features.
This is not only labor-intensive but also lacks adaptability to evolving research questions and contexts.
Given the remarkable language understanding and reasoning capabilities of LLMs, recent research has explored the potential of leveraging LLMs to mine Web data for social good, such as revealing food-related social prejudice~\cite{luo2024othering}, evaluating public accessibility~\cite{li2024toward}, and capturing urban perception~\cite{santos2024real}.
Nevertheless, these studies often lack an examined framework for insight extraction from massive social media content, which limits their effectiveness in capturing the full complexity of Web data.
In contrast, our work presents the first step toward unlocking the reasoning power of LLMs to code free-form online reviews, extracting human-comprehensible, informative insights for segregation prediction.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/reflective_coding.png}
    \caption{Demonstration of Reflective Coding.}
    %\Description{Demonstration of Reflective Coding.}
    \label{fig:coding}
\end{figure*}


\section{Preliminary}

\subsection{Problem Formulation}

Inspired by~\cite{moro2021mobility}, we compute the proportion of visitors at POI $i$ by each group $q$, denoted as $\tau_{qi}$. We then quantify the segregation at POI $i$ as the deviation of the visitor proportion $\tau_{qi}$ from the city's residential proportion $T_q$ (k is a constant that normalizes $S_{i}$ to range between 0 and 1):
\begin{equation}
    S_{i} = k\sum_{q}(|\tau_{iq}-T_{q}|).
\end{equation}

Our task can be formulated into a POI segregation prediction problem.
Given a set of POIs $I = \{i_1, i_2, ..., i_N\}$ along with their corresponding social media content $C = \{c_1, c_2, ..., c_N\}$
and local residential composition $L = \{l_1, l_2, ..., l_N\}$, the objective is to learn a function $f(i, c, l)$ to minimize the discrepancy between the predicted segregation and the real segregation $S_{i}$:
\begin{equation}
    min~\text{diff}(f(i, c, l), S_{i}). 
\end{equation}



\subsection{Data}

We use three datasets to obtain social media, demographic, and mobility information. 
Social media and demographic data serve as input features, while mobility data is used to calculate the ground truth segregation at POIs, i.e., our prediction targets.
We select cities based on the sufficiency of available POIs within the overlapping scope of the three datasets.
As a result, we identify four cities for analysis: Philadelphia (5,360 POIs), Tucson (2,703 POIs), Tampa (2,222 POIs), and New Orleans (2,392 POIs). 
%Taking into account the scale of the city and the extent of city segregation within the overlap scope of these three datasets, we select a total of 12,677 POIs across four cities to form the set of POIs for analysis: 5,360 POIs in Philadelphia, 2,703 POIs in Tucson, 2,222 POIs in Tampa, and 2,392 POIs in New Orleans. 
%the American Community Survey 5-year Estimates (ACS), the Yelp Open Dataset, and the Safegraph Patterns Dataset




\noindent \textbf{Demographic Data.}
We obtain the demographics of CBG residents from the American Community Survey 5-year Estimates (ACS)\footnote{https://www.census.gov/programs-surveys/acs/}.
Specifically, we categorize the residents of CBGs into five distinct groups: \textit{hispanic}, \textit{black}, \textit{asian}, \textit{white}, and \textit{others}, and calculate their respective ratios by dividing the population of each group by the total CBG population. 

\noindent \textbf{Social Media Data.}
We use the Yelp Open Dataset\footnote{https://www.yelp.com/dataset} for POI social media data. %, which contains more than 6M reviews and 200K photos associated with over 150K businesses in the US.
For each POI, we obtain its name, location, stars, categories, service attributes, and multi-modal user-generated content. 
The category captures its business domain, such as ``food'' and ``department stores''. %, and ``coffee \& tea''.
The attributes reflect its specific business traits, such as price range, delivery options, and parking availability.
The user-generated content includes textual reviews and images uploaded by visitors. %, providing a wealth of nuanced perceptions and emotional cues.
Each POI is associated with at least 5 reviews. %, while the availability of other features may vary.
%For each POI, we obtain its name, location (``city'', ``latitude'', and ``longitude''), tags (``stars'', ``categories'', and ``attributes''), and user-generated content (``reviews'' and ``images''). 
%The ``categories'' section includes keywords denoting the POI's business domain, e.g., ``food'', ``department stores'', and ``coffee \& tea''.
%The ``attributes'' section delineates the POI's specific business traits, such as the price range and the availability of credit card acceptance, restaurant delivery, and business parking.
%The ``reviews'' and ``images'' sections contain original textual and visual content uploaded by visitors, providing a wealth of nuanced perceptions and emotional cues about the POIs.
%` Accepts Credit Cards' `Restaurants Delivery' to `Business Parking' `Restaurants Price Range' varies greatly among POIs.

\noindent \textbf{Mobility Data.}
%Safegraph's Places Data\footnote{https://docs.safegraph.com/docs/places}.
%To capture the real-world visitation patterns and further 
To derive the ground truth of experienced segregation, we utilize the Safegraph Patterns Dataset (now accessible through Advan)\footnote{https://www.deweydata.io/data-partners/advan}.
This dataset records monthly visits to each POI originating from various CBGs.
We aggregate one year's visitation records to construct a robust dataset with extensive observations.
%We aggregate visitation records spanning the entire year 2019 to construct a robust dataset with extensive observations that were unaffected by disruptions related to the COVID-19 pandemic.
To address the distinct POI indexing systems between Yelp and SafeGraph, we match POIs by ensuring identical names and a location deviation within 200 meters. 
In Appendix A, we analyze the variability of POI features, highlighting the importance of our study.
%This alignment process yields the matching of 5,360 POIs in Philadelphia.



%\section{Method}

%\subsection{Segregation Quantification}
%\subsection{Coding Set Construction}
%For each city, we fit a doubly-constrained gravity model to capture the impact of residential distribution and geographical distances on POI visitation, and hence segregation.



\section{Reflective LLM Coder}
The vast volume of raw social media content creates a significant cognitive barrier to revealing the encoded segregation experience. 
%interpret and analyze it. %To reveal segregation experience encoded in social media content, 
Therefore, an effective approach is needed to process and extract insights.
Building on research demonstrating the consistency and stability of LLM-based coding~\cite{dai2023llm,tai2024examination}, we design a \textit{Reflective LLM Coder} to generate an insightful codebook from a small set of POI data, capturing the multi-faceted factors influencing segregation and offering a structured framework for deeper analysis.
As shown in Figure~\ref{fig:coding}, it contains two modules, \textit{reflective attributor} and \textit{code summarizer}.
%With this subset, we design two modules, \textit{reflective attributor} and \textit{code summarizer}, to form the Reflective LLM Coder, as shown in Figure~\ref{fig:coding}.
%\subsection{Automatic Open Coding}
%Mention abductive concept: observation+reasoning synergy
%画图：一边是review，一边是mobility observation，怎么提取。参考EXPEL (LLM as exp? learning)从memory里提取insight的图。
%As shown in Figure~\ref{fig:coding}, our Reflective LLM Coder consists of two main modules, \textit{reflective attributor} and \textit{code summarizer}.

\subsection{Reflective Attributor}

We design a \textit{reflective attributor} to identify factors influencing a POI’s appeal to different groups. 
Specifically, we design a two-step Chain-of-Thought (CoT) scheme~\cite{wei2022chain} that guides an LLM to integrate multiple perspectives from texts and images, culminating in a reflection-driven process that refines insights based on real-world feedback.

\textbf{Multi-source Insight Generation.}
In this step, the LLM generates insights by integrating multiple sources of information: the POI's name, user-posted reviews, and images. 
It first evaluates the name for potential cultural, racial, ethnic, or socioeconomic associations that might influence the appeal to specific groups. 
Next, it analyzes the reviews and images to identify key aspects like atmosphere, pricing, service quality, and cultural relevance. 
These analyses are then synthesized into a concise set of insights, each identifying factors that could attract or repel particular racial/ethnic groups, ensuring comprehensive coverage without redundancy.

%\textbf{Name Implication Analysis.}
%The LLM evaluates whether and how the POI's name conveys cultural, racial, ethnic, or socioeconomic associations that might influence its appeal to specific groups. 
%%For example, names that reference particular cuisines or cultural symbols may resonate with certain communities while deterring others.

%\textbf{Review and Image Analysis.}
%%Next, the analysis extends to Yelp reviews and user-posted images. 
%%This step identifies key aspects such as atmosphere, pricing, service quality, and cultural relevance, from user-posted reviews and images. 
%The LLM analyzes user-posted reviews and images to identify key aspects such as atmosphere, pricing, and cultural relevance.
%%For example, reviews might highlight a family-friendly environment or premium pricing, while images could reveal aesthetic or cultural elements that cater to specific preferences. 
%It yields a rich set of features characterizing the POI’s appeal, e.g., the friendliness of environment and presence of local ties.

%\textbf{Integration.}
%The LLM integrates perspectives from the name, review, and image analyses into a concise set of insights.
%Each insight identifies a distinct factor that potentially attracts or repels specific racial/ethnic groups, ensuring comprehensive yet non-redundant coverage.

\begin{table*}[ht]
\centering

\vspace{-10pt}
\scalebox{0.8}{
\begin{tabular}{@{}cp{4.2cm}p{15.2cm}@{}}
\toprule
\textbf{Index} & \textbf{Name} & \textbf{Detail} \\ 
\midrule
1  & \textbf{Cultural Resonance and Appeal}  & Culturally themed offerings, such as Italian-American or South Indian cuisine, attract visitors seeking authentic or familiar experiences, influencing visitation based on cultural representation and resonance. \\
\midrule
2  & \textbf{Price Sensitivity and Economic Accessibility}  & Moderate pricing, coupons, and cost-effective policies like BYOB appeal to budget-conscious visitors, impacting visitation patterns based on affordability and economic considerations.  \\
\midrule
3  & \textbf{Service Quality and Customer Experience}  & Professional and attentive service, despite occasional inconsistencies, attracts visitors valuing high service standards and personal interactions, influencing demographics based on service expectations.  \\
\midrule
4  & \textbf{Atmosphere and Social Environment}  & Lively, trendy, or family-friendly settings attract visitors prioritizing social and communal experiences, impacting visitation based on social and family-oriented preferences.  \\
\midrule
5  & \textbf{Accessibility and Convenience}  & Central locations, parking availability, and delivery services attract visitors prioritizing efficiency and accessibility, influencing patterns based on transportation and convenience.  \\
\midrule
6  & \textbf{Visual and Aesthetic Appeal}  & Modern, chic, and historically themed environments attract visitors who appreciate aesthetic and immersive experiences, influencing demographics based on visual and cultural preferences.  \\
\midrule
7  & \textbf{Cultural and Social Inclusivity}  & Inclusive, diverse, and culturally sensitive environments attract a broad demographic by catering to varied identities and preferences, influencing visitor composition based on inclusivity and cultural representation.  \\
\midrule
8  & \textbf{Product Variety and Quality}  & Diverse and high-quality offerings, including visually appealing and culturally themed products, attract visitors prioritizing variety and quality, influencing visitation based on product expectations. \\
\midrule
9  & \textbf{Community Engagement and Local Involvement}  & Establishments with strong community ties and neighborhood vibes attract visitors valuing local engagement and communal experiences, influencing demographics based on community integration and involvement.  
 \\
\bottomrule
\end{tabular}
}
\caption{Automatically constructed codebook.}
\label{tab:codebook}
\end{table*}

\textbf{Reflection-guided Insight Refinement.}
Finally and arguably most importantly, we introduce real-world data to guide LLM's reflections upon these insights. 
By comparing actual visitor demographics with expected residential compositions, the LLM refines the established aspects in an abductive manner, discarding inconsistencies and maintaining alignment with observed behaviors.
%It is expected to maintain those insights consistent with the observation while discarding the conflicting ones.
This step not only enhances the relevance of the insights, but also provides a grounded explanation for observed visitation preferences.



\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/REEM.png}
    \caption{Reasoning-and-Embedding (RE'EM) framework.}
    \label{fig:reem}
\end{figure*}

Combining these two steps, the \textit{reflective attributor} links POI attributes with patterns in visitation behavior, offering a data-driven understanding of segregation experiences.





\subsection{Code Summarizer}

The \textit{code summarizer} module aggregates outputs from the \textit{reflective attributor} into a comprehensive and orthogonal codebook that encapsulates the diverse factors influencing POI appeal. 
We design another four-step CoT scheme to guide the LLM reasoning process.

\textbf{Extraction.} 
Taking the insights extracted by the \textit{reflective attributor}, this step extracts phrases representing the analysis perspectives for each insight. 
It ensures that previously-identified features are captured for further refinement.
%It ensures that every meaningful feature identified in the previous module is captured for further refinement.

\textbf{Semantic Combination.} 
This step combines insights with similar semantics to reduce redundancy, e.g., merging “Cultural Relevance and Appeal” and “Inclusivity and Cultural Representation” into a unified and coherent code. 
%For example, “Cultural Relevance and Appeal” and “Inclusivity and Cultural Representation” may be merged into a unified and coherent code. 

\textbf{Quality-Based Removal.}
This step filters out insights that are less distinguishable or less generalizable.
It ensures that the final codebook focuses on the most relevant and impactful factors, reducing the impact of noise. % and enhancing analytical precision.

\textbf{Explanation Refinement.} 
Finally, this step refines the one-sentence explanation for each code, highlighting broader, thematic insights to ensure flexibility and interpretability across contexts while preserving its analytical rigor.
%Instead of explicitly referencing specific racial or ethnic groups, the explanations highlight broader, thematic insights. 


%Combining these four steps, the \textit{Code Summarizer} produces a codebook that encapsulates the multifaceted factors influencing place attractiveness. This codebook serves as a critical tool for analyzing segregation patterns and understanding how POIs appeal to diverse racial/ethnic groups.

After executing the whole coding process (formalized in Algorithm 1 in Appendix B), we obtain \textbf{a codebook identifying 9 distinct ``bricks'' that form the invisible walls}, shown in Table~\ref{tab:codebook}.
Each brick represents a key aspect of the visitor experience, allowing a nuanced understanding of how places appeal to diverse racial demographics.
%Altogether, they capture the multifaceted factors that influence the social inclusiveness of places. 
For example, \textit{Cultural Resonance and Appeal} captures how culturally themed offerings such as Italian-American cuisines attract visitors seeking authentic experiences, while \textit{Price Sensitivity and Economic Accessibility} captures the impact of affordability on visitation, with moderate pricing and cost-effective policies like BYOB appealing to budget-conscious visitors. 







\section{REasoning-and-EMbedding (RE'EM) Framework}

To effectively integrate different features for accurate segregation prediction, we design a \textbf{REasoning-and-EMbedding (RE’EM)} framework with four key components: a \textit{reasoning channel}, a \textit{embedding channel}, a \textit{population channel}, and a \textit{neighbor-aware multi-view predictor}, as shown in Figure~\ref{fig:reem}.




\subsection{Reasoning Channel}

We prompt an LLM to assess place attractiveness to different racial/ethnic groups under the guidance of our codebook (Table~\ref{tab:codebook}). 
Specifically, we instruct the LLM to simulate the perspective of each racial/ethnic group, and rate the POI along the codebook-identified dimensions. %, generating a total of 45 scores per POI.
To unleash the LLM's reasoning power, we design a two-step CoT scheme.

\noindent \textbf{Codebook-guided Content Analysis.}
We instruct the LLM to analyze the given content (POI's name, review text and images, if any) and summarize the POI’s characteristics along the 9 codebook-defined dimensions, focusing on how these may attract or repel specific racial groups.

\noindent \textbf{Structured Rating.}
We ask the LLM to imagine itself as a member of each racial/ethnic group, and rate the POI's attractiveness across the 9 codebook-defined dimensions based on the summary obtained in Step 1.
Ratings are assigned on a scale from 0 to 10, where 0 indicates strong repulsion, 5 indicates neutrality, and 10 indicates strong attraction.
%The ratings range from 0 (strongest repulsion) to 5 (neutral) to 10 (strongest attraction). 
This process yields 45 ratings $r_{i}$ with corresponding textual explanations for each POI $i$, providing both quantitative scores and qualitative insights into the POI’s social inclusiveness.
To integrate the rating data into our predictive framework, we employ a \textit{reasoning adapter} to process the LLM-generated ratings.
This adapter consists of a Multi-Layer Perceptron (MLP) that transforms the ratings into a vector representation $v_{i}^{r}$, which will be subsequently fed into the predictor.
%In terms of handling quantitative rating data, the rating $r_{i}$ is preprocessed by a Reasoning Adapter, composed of a Multi Layer Perceptron (MLP) model, before being fed into the predictor, resulting in a vector representation $v_{i}^{r}$:
\begin{equation}
    v_{i}^r = \text{ReasonAdapter}(\text{LLM}(c_{i} | \text{Codebook})).
\end{equation}

\subsection{Embedding Channel}
With the \textit{embedding channel}, we obtain deep representations $v_{i}^{e}$ of the review corpus for each POI $i$. 
Given the input token length constraint, we employ data augmentation by sampling different subsets of reviews for the same POI.
%To make full use of the review corpus under the constrained input token length, we sample different reviews for the same POI for data augmentation.
We fine-tune an open-source text embedding model named GTE-base~\cite{GTE-base} to enhance its capability of extracting higher-level representations while preserving the pre-trained semantic knowledge. 
Similar to \textit{reasoning channel}, the resulting embedding $e_{i}$ is adjusted to $v_{i}^{e}$ by the Embedding Adapter and then input to the predictor. 
\begin{equation}
    v_{i}^e=\text{EmbeddingAdapter}(\text{GTE}(c_{i}))
\end{equation}
%Due to the limitation of the input token length for embeddings, we construct fine-tuning training datasets by performing random multiple resampling on multiple reviews data for the same POI. 
%The sampling times is positively correlated with the number of reviews, which allows us to more comprehensively utilize the text information in the original reviews.

\subsection{Population Channel}
For each POI $i$, we calculate the racial composition of CBGs located within a 0.5km radius.
This feature, termed $p_{i}$, provides the static demographic context based on the POI's geographic location.
We introduce the corresponding Population Adapter to obtain $v_{i}^p$ from $p_{i}$ for subsequent prediction.
% Consistent with the approach used in other channels, 
\begin{equation}
    v_{i}^p=\text{PopulationAdapter}(l_{i})
\end{equation}


\subsection{Neighbor-aware Multi-view Predictor} %\subsection{Multi-view Neighbor-Enhanced Predictor}  
The \textit{neighbor-aware multi-view predictor} primarily accomplishes two tasks: neighbor aggregation and multi-view fusion.
% Inspired by the idea of aggregating information from POI, 
For each POI, we identify the five closest neighbors in the reasoning space (similarity to $r_{i}$), the embedding space (similarity to $e_{i}$), and the geographic space (geographical proximity), respectively, forming the neighbor sets $N_{i}^r=\{n_1^r,...,n_5^r\}$, $N_{i}^e=\{n_1^e,...,n_5^e\}$ and $N_{i}^p=\{n_1^p,...,n_5^p\}$.
Then we employ three graph-based aggregators to aggregate the neighbors' features $v_{n_{i}}^r$, $v_{n_{i}}^e$, and $v_{n_{i}}^p$:
\begin{equation}
    v_{n_{i}}^*=GAT_{*}(v_{i}^*,\{v_{n}^*|n\in N_{i}^*\})
\end{equation}
Finally, the multi-view fusion component integrates the features from REasoning, EMbedding, and Population, combining both the individual's $v_{i}^*$ and the neighbor's $v_{n_{i}}^*$. %, resulting in a total of six input streams. 
This fusion process ultimately outputs the predicted segregation $\hat{S_{i}}$:
\begin{equation}
    \hat{S_{i}}=Fuse(v_{i}^r,v_{n_{i}}^r,v_{i}^e,v_{n_{i}}^e,v_{i}^p,v_{n_{i}}^p) 
\end{equation}

%  integrates the surrounding racial demographic background, the embedding representation, and ratings from reasoning, thereby enhancing the target performance.
% % achieve the objectives of accurate segregation prediction and the comprehensive utilization and integration of multi-input information,
% To enhance the prediction of racial segregation from multi-view data, we develop a novel \textit{Predictor component} structure that aggregates neighbor POIs' feature, at the same time, synergistically utilizes information from reasoning ratings, and review embeddings and population data.







% Two parallel outputs

\section{User Study}
We conduct a user study to evaluate the cognitive gain to humans provided by our generated codebook.
The study involves 75 researchers with hands-on experience or sufficient knowledge in social media studies. 
To ensure that participants fully understood the survey tasks, we provided clear explanations of the geographic and racial concepts required for the study.
Our questionnaire is publicly accessible~\footnote{\url{https://drive.google.com/file/d/1-NIjIPiVi_m_ONBFruYYuh4nvyhe4PF-/view?usp=sharing}}.

We randomly sample four POIs where visitor demographics significantly differ from local residents. %the local resident demographics. 
For each POI, we generate review summaries using both a vanilla method (directly prompting LLMs without the codebook) and our codebook-guided method, as shown in Figure ~\ref{fig:case-study} in the Appendix.
Participants answer four questions per POI, progressively incorporating different levels of contextual information:
\textbf{Baseline Estimation}: Participants predict whether each racial group is over- or underrepresented at the POI based solely on its basic attributes (e.g., name, category, and service details).
\textbf{Review-informed Prediction}: Participants reassess their estimates after being provided with a random sample of user reviews.
\textbf{Summary-enhanced Prediction}: Participants make a final prediction after reviewing a summary of the user reviews.
\textbf{Summary Preference Evaluation}: Participants determine whether the codebook-guided summary or the vanilla summary is more informative.
%In the first question, we ask participants to make estimations based solely on the POI's basic information, including name, category, and service attributes.
%In the second question, we further provide randomly-sampled user reviews and ask participants to make another round of predictions.
%In the third question, we ask the participants to make a final round of predictions by considering the newly provided review summary.
%To justify the effectiveness of our \textit{codebook-guided summary}, we compare it with a summary generated from directly prompting LLMs without the codebook, which we refer to as the \textit{review summary}.
%Finally, we ask participants to determine which version of the summary they find more informative.

%Participants were asked to make predictions for White, Hispanic, Black, and Asian visitors, indicating whether each group would be "lower than local composition" or "higher than local composition." 
%The first three questions require participants to assess whether each racial group would have a higher or lower proportion of visitors compared to the composition of the local residents. 
%provide the name and category of the POI, the demographic distribution of the POI's location, and feature descriptions from the original dataset to investigate the role of basic POI information. 
%to assess the potential impact of raw review information on human judgment. %ensuring the total length of reviews for each POI was consistent, 
%summaries using both the vanilla method and our codebook-guided method, thereby demonstrating the effectiveness of our approach. 
%The fourth question is based on the third question, asked which summary provided more information, thus comparing the performance of the codebook-guided method with the vanilla method. The order in which the summaries appeared was also randomized to prevent any cognitive bias due to sequence effects.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{figs/figure40211.png}
    \caption{Accuracy of visitor attraction prediction.}
    % \Description{Accuracy of visitor attraction prediction.}
    \label{fig:user-study-1}
\end{figure}


\begin{table*}[t]
    \centering
    %\resizebox{\linewidth}{!}{
\scalebox{0.9}{
\begin{tabular}{@{}crrrrrrrr@{}}
\toprule
Model &
  \multicolumn{1}{c}{MSE↓} &
  \multicolumn{1}{c}{Improv.} &
  \multicolumn{1}{c}{RMSE↓} &
  \multicolumn{1}{c}{Improv.} &
  \multicolumn{1}{c}{MAE↓} &
  \multicolumn{1}{c}{Improv.} &
  \multicolumn{1}{c}{R2↑} &
  \multicolumn{1}{c}{Improv.} \\ \midrule
Population & 0.0075±0.0002 & ------ & 0.0864±0.0012 & ------ & 0.0683±0.0013 & ------  & 0.3164±0.0204 & ------ \\
GTE        & 0.0073±0.0002 & 2.67\% & 0.0855±0.0011 & 1.04\% & 0.0685±0.0010 & -0.29\% & 0.3249±0.0151 & 2.69\% \\
BERT       & 0.0072±0.0002 & 4.00\% & 0.0846±0.0011 & 2.08\% & 0.0680±0.0010 & 0.44\%  & 0.3394±0.0176 & 6.78\% \\
GloVE      & 0.0072±0.0002 & 4.00\% & 0.0848±0.0011 & 1.85\% & 0.0685±0.0008 & -0.29\% & 0.3357±0.0140 & 5.75\% \\
\textbf{Our Model} &
  \textbf{0.0068±0.0003} &
  \textbf{9.33\%} &
  \textbf{0.0823±0.0021} &
  \textbf{4.75\%} &
  \textbf{0.0662±0.0021} &
  \textbf{3.07\%} &
  \textbf{0.3885±0.0278} &
  \textbf{22.79\%} \\ \bottomrule
\end{tabular}
}
    %}
    \caption{Prediction performances.}
    \label{tab:prediction_result}
\end{table*}


Figure~\ref{fig:user-study-1} presents the human prediction accuracies with different information availability. 
When relying solely on basic POI attributes, accuracy fluctuates around 50\%, indicating that visitor preferences cannot be reliably inferred from POI metadata alone. 
Moreover, introducing randomly sampled user reviews does not lead to a notable improvement in prediction accuracy.
This is likely due to the sparsity and unstructured nature of raw review data, which can be difficult to process and may even mislead human judgment. 
In contrast, providing participants with the review summary consistently enhances prediction accuracy across all sampled POIs.
This result underscores the effectiveness of the codebook-guided summarization, which condenses extensive social media content into concise yet highly informative text snippets, enhancing human understanding of POIs' social inclusiveness.
%This indicates that the \textit{codebook-guided summary} effectively distills the vast amount of social media content into shorter yet more informative text snippets, helping users to quickly grasp the social inclusiveness of places.
%largely because information is sparse and thus hard to digest, which may even mislead human judgment.
%Upon adding the original reviews, an improvement was observed in only one POI, while performance for the other three POIs declined. 
%This suggests that a small number of reviews, due to their limited quantity and subjective nature, may mislead human judgment. 
%demonstrating the effectiveness of using summaries to aid human judgment.



Figure~\ref{fig:user-study-2} presents the results of the summary preference evaluation.
Across all sampled POIs, 60\%-80\% of participants prefer the codebook-guided summary over the vanilla one, with an average improvement of 40\%, showing that our approach more effectively distills useful information to support human judgment.
As illustrated in Figure~\ref{fig:case-study} in the Appendix, the codebook-guided summaries capture nuanced insights--such as potential deterrants for certain minority groups--which are often absent or less explicit without codebook guidance. 
%The results of the fourth question are shown in Figure~\ref{fig:user-study-2}. 
%The proportion of participants who believed that the codebook-guided method provided more informative summaries compared to the vanilla method ranged from 60\% to 80\%. 
%This indicates the effectiveness of our method in generating summaries that assist human judgment. 
%This preference may be attributed to the codebook-guided method providing more information related to racial attraction. 
%The highlighted parts in Figure~\ref{fig:case-study} illustrate such information, such as "could repel minority groups, particularly black and LGBTQ+ visitors".
%\textcolor{red}{By utilizing the LLM workflow, we meticulously distill the original lengthy reviews and image descriptions into shorter, more knowledge-intensive summaries, which are only \textbf{43.54\%} in length compared to the original information.}












\section{Prediction Experiments}
% 对baseline和experimental settings的介绍，包括之前review里提到的我们采用什么版本的LLM。
% 先讲在主城市Philadelphia上的结果，再讲ablation study，最后讲cross-city generalization
% 我们的思路具有可行性

\subsection{Experiment Settings}

%\subsubsection{Baselines}
We compare our model against four baselines. 
The first baseline is an MLP making use of only the population information.
The other three baselines process the social media content with a frozen pre-trained text embedding model, and fuse it with population information.
We adopt three widely-used powerful embedding models: GTE-base~\cite{GTE-base}, BERT-base~\cite{BERT}, and GloVE-330B~\cite{glove}. 
The structures of the population and embedding MLPs are identical to those in our model.
%As \textbf{baseline} experiments, to validate our motivation, we report the predictive performance using only the Population Adapter. Additionally, to demonstrate the RE`EM's capability, we use a frozen pre-trained text Embedding model with a trainable Embedding Adapter to process social media content and fuse the Population Adapter and Embedding Adapter using a single fully connected layer. We select three classic pre-trained text embedding models: GTE-base, BERT-base, and GloVE-330B. The structures of the Population Adapter and Embedding Adapter are identical to those in our model.
%\subsubsection{Evaluation Metrics}
We use four metrics to evaluate model performances: mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), and coefficient of determination (R\textsuperscript{2}).

%\subsubsection{Implementation Details}
We employ GPT-4o for reflective coding on a small subset (n=190) of POIs, and GPT-4o mini for codebook-guided reasoning on all POIs for economic considerations.
All models are trained using the Adam optimizer to minimize the MSE loss, with hyperparameters (e.g., learning rate, weight decay) tuned based on validation performances. 
POIs in each city are randomly split into training, validation, and test sets with a ratio of 6:2:2.
For further implementation details, please refer to Appendix C and our released code\footnote{https://anonymous.4open.science/r/REEM-73DB/}.
%For \textbf{Reflective Coding}, we use GPT-4o as the Reflective Attributor and Code Summarizer.
%In the \textbf{Reflective Coding} section, we select a total of 190 POIs in Philadelphia to form a representative subset of data, utilizing GPT-4o as the Reflective Attributor and Code Summarizer. 
%After 19 iterations, each providing 10 new POI information entries, we obtain the CodeBook as shown in Table~\ref{tab:codebook}.
%In the \textbf{REasoning} section, considering cost efficiency, we employ the more economical GPT-4o mini model to conduct codebook-guided reasoning on all POIs, yielding 45 ratings along with corresponding textual explanations for each. 
%The training parameters included dropout=0.2, alpha=0.2, and head=1. 
%In the \textbf{Generalization} experiments, we maintain all model structures and CodeBook contents unchanged, only switching to different city data for training and evaluation, to test the generalizability of the model and the insights derived from the CodeBook.
%Reasoning (64$\rightarrow$128), Embedding (128$\rightarrow$128), and Population (30$\rightarrow$30). 



\begin{table*}[ht]
    \centering
    {
    \scalebox{0.9}{
    \begin{tabular}{@{}ccccc@{}}
    \toprule
     Model     & MSE↓          & RMSE↓        & MAE↓           & R2↑             \\ \midrule
    Population & 0.0075±0.0002             & 0.0864±0.0012             & 0.0683±0.0013             & 0.3164±0.0204               \\
     Embedding & 0.0096±0.0002             & 0.0980±0.0011             & 0.0814±0.0008            & 0.1118±0.0052              \\
    
    Rating & 0.0104±0.0003            & 0.1021±0.0013             & 0.0837±0.0010            & 0.0384±0.0117              \\
   \textbf{Our Model} & \textbf{0.0068±0.0002}  & \textbf{0.0823±0.0021} &  \textbf{0.0662±0.0021}  & \textbf{0.3885±0.0278}   \\ \bottomrule
    \end{tabular}
    }
    }
    \caption{Ablation study.}
    \label{tab:Ablation}
\end{table*}


\begin{table*}[t]
\centering
% \resizebox{\linewidth}{!}
{
\scalebox{0.9}{
\begin{tabular}{@{}cccrrrr@{}}
\toprule
City &
  POI Num &
  Model &
  \multicolumn{1}{c}{MSE↓} &
  \multicolumn{1}{c}{RMSE↓} &
  \multicolumn{1}{c}{MAE↓} &
  \multicolumn{1}{c}{R2↑}  \\ \midrule
\multirow{4}{*}{Tucson} &
  \multirow{4}{*}{2,221} &
  GTE &
  0.0048±0.0001 &
  0.0692±0.0011 &
  0.0565±0.0009 &
  0.2117±0.0134  \\
 &
   &
  BERT &
  0.0049±0.0002 &
  0.0698±0.0012 &
  0.0572±0.0011 &
  0.1983±0.0165 \\
 &
   &
  GloVE &
  0.0047±0.0002 &
  0.0684±0.0011 &
  0.0560±0.0011 &
  0.2287±0.0175 \\
 &
   &
  \textbf{Our Model} &
  \textbf{0.0039±0.0001} &
  \textbf{0.0625±0.0009} &
  \textbf{0.0506±0.0011} &
  \textbf{0.3744±0.0290} \\ \midrule
\multirow{4}{*}{Tampa} &
  \multirow{4}{*}{2,703} &
  GTE &
  0.0049±0.0003 &
  0.0697±0.0018 &
  0.0578±0.0018 &
  0.2905±0.0300  \\
 &
   &
  BERT &
  0.0052±0.0002 &
  0.0719±0.0016 &
  0.0594±0.0016 &
  0.2455±0.0255  \\
 &
   &
  GloVE &
  0.0049±0.0002 &
  0.0704±0.0015 &
  0.0582±0.0016 &
  0.2762±0.0268 \\
 &
   &
  \textbf{Our Model} &
  \textbf{0.0044±0.0002} &
  \textbf{0.0668±0.0014} &
  \textbf{0.0525±0.0017} &
  \textbf{0.3499±0.0224}  \\ \midrule
\multirow{4}{*}{New Orleans} &
  \multirow{4}{*}{2,391} &
  GTE &
  0.0100±0.0006 &
  0.1002±0.0028 &
  0.0814±0.0029 &
  0.1958±0.0135 \\
 &
   &
  BERT &
  0.0110±0.0006 &
  0.1051±0.0029 &
  0.0858±0.0030 &
  0.1154±0.0101 \\
 &
   &
  GloVE &
  0.0099±0.0006 &
  0.0996±0.0029 &
  0.0804±0.0029 &
  0.2045±0.0209 \\
 &
   &
  \textbf{Our Model} &
  \textbf{0.0087±0.0005} &
  \textbf{0.0929±0.0028} &
  \textbf{0.0745±0.0024} &
  \textbf{0.2781±0.0424}  \\ \bottomrule
\end{tabular}}
}
\caption{Cross-city generalization performances.}
\label{tab:prediction_result city generalize}
\end{table*}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{figs/figure5.png}
    \caption{Summary preference evaluation.
    %Preference rate of our designed codebook-guided summary w.r.t. the vanilla summary.
    %Human preference between two versions of review summary. 
    %(vanilla summary v.s. codebook-guided summary)
    }
    % \Description{Preference rate of our designed codebook-guided summary w.r.t. vanilla summary.}
    \label{fig:user-study-2}
\end{figure}

\subsection{Experiment Results}
Table~\ref{tab:prediction_result} presents the performances of our RE'EM model alongside four baselines, with results reported as the mean and standard deviation over five repetitions on 50\% randomly sampled test sets. 
A key insight is that \textbf{all models incorporating social media data outperform the population-only baseline}. %(row 1 vs. rows 2–4)
This result underscores the predictive power of social media content, which provides crucial insights beyond static population distributions. 
It supports our hypothesis that segregation patterns are shaped not only by demographic distributions but also by the social and cultural perceptions reinforcing the “invisible walls” in cities. % embedded in online discourse, reinforcing the presence of “invisible walls” in urban environments.
Further, \textbf{RE'EM consistently and significantly surpasses all embedding-based baselines}.
It achieves a 9.33\%, 4.75\%, and 3.07\% improvement in MSE, RMSE, and MAE, respectively, over the population-only baseline. 
R\textsuperscript{2} increases to 0.3885, marking a substantial 22.79\% improvement.
These results indicate that while social media data encapsulates rich and valuable information, a naive embedding strategy is insufficient to fully capture the interplay between population distribution, POI attributes, and visitor dynamics. 
In contrast, the structured multi-view approach of RE'EM effectively integrates heterogeneous information sources, enabling accurate predictions of segregation.
%The results are reported as the mean and standard deviation over five repetitions on 50\% randomly sampled test sets. 
%The RE`EM achieves the lowest MSE of 0.0068, representing a 9.33\% improvement over the baseline using only population data. 
%RMSE and MAE also decrease significantly, improving by 4.75\% and 3.07\%, respectively. 
%demonstrating that a simple embedding strategy is insufficient to fully capture the interplay between population distribution, POI attributes, and visitor dynamics. 
%A closer analysis reveals two key insights:
%\textbf{First, social media content enhances segregation prediction performance.}
%Compared to using only population data (row 1), incorporating social media content improves the performance of all the other baselines (rows 2 to 4) and our model.
%This indicates that social media content provides additional information beyond demographic factors, reinforcing the existence of "invisible walls" in the city.
%\textbf{Second, RE'EM consistently and significantly outperforms all simple embedding baselines.}
%By xxx, our model presents an effective way to extract useful information from social media content to shed light on the visitation preferences of different subpopulations. 
%On the other hand, our RE'EM model demonstrates comprehensive superiority over all simple embedding baselines (rows 2 to 4), highlighting the effectiveness of our model design.
%the performance increases when social media content is taken into account, in both the other three baselines (rows 2 to 4) and our model, indicating that social media content contains useful information not captured by population data, suggesting the existence of "invisible walls" in the city.


To validate our design of different model components, we perform an ablation study. 
As Table~\ref{tab:Ablation} shows, each adapter (Reasoning, Embedding, Population) exhibits certain predictive capabilities, but none achieves optimal performance. 
The full RE'EM model, which strategically combines all three adapters, consistently delivers superior results. 
Thus, the integration of multi-view signals enables complementary information flow, allowing the model to refine its predictions beyond what any single feature source can achieve.
%To validate the effectiveness of different model components, we present the ablation study in Table~\ref{tab:Ablation}.
%Additionally, Table~\ref{tab:Ablation} shows the results of the ablation study. Without the Predictor component, each Adapter exhibits some predictive capability but none achieves the best, indicating that RE`EM can leverage multi-view data to enhance each other and improve predictive power.

To assess the generalization capability across cities, we use the codebook obtained in Philadelphia to train models in the other three cities. %three distinct cities, Tucson, Tampa, and New Orleans. 
As shown in Table~\ref{tab:prediction_result city generalize}, RE'EM consistently achieves the best performance in all three cities along all metrics. 
Compared to the strongest baseline, RE'EM achieves substantial improvements, with MSE reduced by as much as 17.02\%, MAE reduced by as much as 9.64\%, and R² increasing by as much as 63.71\%.
These findings indicate that RE'EM, and specifically, our constructed codebook, captures fundamental segregation mechanisms that extend beyond city-specific characteristics, making it a promising tool  across diverse geographic and socio-economic settings.
%Finally, Table~\ref{tab:prediction_result city generalize} presents the model's predictive performance in three other cities: Tucson, Tampa, and New Orleans. 
%MSE improved by 17.02\%, 10.20\%, and 12.12\%; RMSE improved by 8.63\%, 4.16\%, and 6.73\%; MAE improved by 9.64\%, 9.17\%, and 7.34\%; and R2 improved by 63.71\%, 20.45\%, and 35.99\%, respectively.
%Compared to the strongest baseline, the MSE is reduced by as large as 17.02\%, MAE reduced by as large as 9.64\%, and R\textsuperscript{2} increased by 63.71\%. 




% %This indicates a moderate level of accuracy in predicting racial segregation using demographic data alone.
% In contrast, our designed RE'EM model demonstrates comprehensive superiority over the baseline. 
%  These results suggest that the comprehensive inclusion of ratings and embeddings effectively captures multifaceted characteristics of POIs, refining the prediction of racial segregation.

% Without the reasoning component (RE`EM (w/o Rating)), the performance drops, which underscores the importance of the ratings.
% Nevertheless, even without the ratings, the model still outperforms the baseline, highlighting the usefulness of the embedding features. Specifically, adding these features from POI reviews leads to moderate improvements: MSE drops by 5.97\%, RMSE by 3.17\%, MAE by 2.46\%, and R\textsuperscript{2} goes up by 10.49\%. This indicates that both embedding features and rating features contribute to capturing important details from the text that improve prediction accuracy.

% In general, the integration of embedding and rating features substantially enhances model performance, highlighting their effectiveness in capturing complex patterns related to racial segregation beyond geographic factors.





%\subsection{Generated Explanation}

\section{Implication}

Our work highlights the transformative potential of LLMs to uncover segregation experiences encoded in social media content. 
By revealing the nuanced and often invisible barriers that shape social interactions from online reviews, this research exemplifies the ethical and socially beneficial application of AI, demonstrating how advanced technologies can be harnessed to foster inclusivity and promote more equitable urban environments.
Policymakers, urban planners, and community leaders can leverage these insights to better understand and address patterns of social exclusion, ultimately building more cohesive and diverse communities.

From a technical perspective, our framework contributes to the application of LLMs for tackling complex societal challenges. 
With reflective coding and integration of LLMs' reasoning and embedding capabilities, our framework moves beyond conventional predictive tasks to offer actionable insights. 
Furthermore, our work demonstrates how prompt-guided analytical processes can mitigate biases and hallucinations, paving the way for more reliable and socially responsible AI applications.




\section{Conclusion}

In this paper, %we explore the possibility of revealing cues of segregation experiences encoded in massive social media content.
we pioneer the use of social media data to predict experienced segregation, designing an LLM Reflective Coder to generate insightful summaries and a REasoning-and-EMbedding (RE'EM) framework to integrate reasoning and embedding for accurate predictions. 
Our approach is validated through both user studies and quantitative experiments, demonstrating its effectiveness in producing human-comprehensible review summaries and reliable segregation predictions. 
This work not only advances the understanding of experienced segregation but also provides a foundation for leveraging social media data to address broader societal challenges, such as fostering inclusivity and mitigating social inequalities. 






% \begin{table}
%     \centering
%     \begin{tabular}{lrr}
%         \toprule
%         Scenario  & $\delta$ (s) & Runtime (ms) \\
%         \midrule
%         Paris     & 0.1          & 13.65        \\
%                   & 0.2          & 0.01         \\
%         New York  & 0.1          & 92.50        \\
%         Singapore & 0.1          & 33.33        \\
%                   & 0.2          & 23.01        \\
%         \bottomrule
%     \end{tabular}
%     \caption{Booktabs table}
%     \label{tab:booktabs}
% \end{table}





% Algorithms and listings are a special kind of figures. Like all illustrations, they should appear floated to the top (preferably) or bottom of the page. However, their caption should appear in the header, left-justified and enclosed between horizontal lines, as shown in Algorithm~\ref{alg:algorithm}. The algorithm body should be terminated with another horizontal line. It is up to the authors to decide whether to show line numbers or not, how to format comments, etc.

% In \LaTeX{} algorithms may be typeset using the {\tt algorithm} and {\tt algorithmic} packages, but you can also use one of the many other packages for the task.

% \begin{algorithm}[tb]
%     \caption{Example algorithm}
%     \label{alg:algorithm}
%     \textbf{Input}: Your algorithm's input\\
%     \textbf{Parameter}: Optional list of parameters\\
%     \textbf{Output}: Your algorithm's output
%     \begin{algorithmic}[1] %[1] enables line numbers
%         \STATE Let $t=0$.
%         \WHILE{condition}
%         \STATE Do some action.
%         \IF {conditional}
%         \STATE Perform task A.
%         \ELSE
%         \STATE Perform task B.
%         \ENDIF
%         \ENDWHILE
%         \STATE \textbf{return} solution
%     \end{algorithmic}
% \end{algorithm}








%\clearpage

\section*{Ethical Statement}
The Yelp review data was collected under users' consent and fully anonymized.
The Safegraph mobility data was aggregated to the CBG level by month and processed with differential privacy techniques to safeguard against individual identification.
The ACS demographic data is publicly accessible at the CBG level.
Thus, no approval from the Institutional Review Board was required by the authors’ institutions.


% There are no ethical issues.

%\section*{Acknowledgments}


%% The file named.bst is a bibliography style file for BibTeX 0.99c

\bibliographystyle{named}
\bibliography{ijcai25}

\begin{comment}
    

\appendix

\section{Variability of POI features}
Taking Philadelphia as an example, Figure~\ref{fig:poi-variation-statistics} illustrates the distributions of the variations for POI features within a single CBG, including stars, prices, income segregation, and racial segregation.
We can observe that POIs exhibit considerable variability even when examined within the CBG locality, which underscores the significance of our study.
% counts, diversity of POI categories, and the standard deviations of  
%by simply examining within the CBG area, our POI dataset still demonstrates that neighboring POIs exhibit variability.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figs/figure1_页面_1.png}
    \caption{The Coefficient of Variation distributions for POIs features within the same CBG highlight considerable variability among POIs. Figures a-c demonstrate the distributions of stars, price range, and racial segregation, respectively. 
    }
    % \Description{Statistics.}
    \label{fig:poi-variation-statistics}
\end{figure}

\section{Reflective Coding Algorithm}
We formalize the process of reflective coding in Algorithm~\ref{algorithm}.

\begin{algorithm}
\caption{Reflective Coding Algorithm}
\label{algorithm}
\begin{algorithmic}[1]
\State \textbf{Input:} A set $O$ of tuple  (\text{POI} $I$, \text{POI name} $N$, \text{POI reviews and images} $M$, \text{real visitor composition} $\tau_{real}$, \text{local residential composition} $l_{res}$)

\State \textbf{Output:} Codebook $B$
\State Initialize an empty list $L$
\For{each tuple ($I$, $N$, $M$, $tau_{real}$, $l_{res}$) in $O$}
    \State $L_1 \gets \text{analyze}(N)$
    \State $L_2 \gets \text{analyze}(M)$
    \State $L_{\text{sum}} \gets \text{summary}(L_1,L_2)$
    \State $\tau_{\text{diff}} \gets \text{compare}(\tau_{real}, l_{res})$
    \State $L_I \gets \text{refinement}(\tau_{\text{diff}}, L_{\text{sum}})$
    \State Add $L_I$ to $L$
\EndFor

\State Initialize an empty list $B$
\State Divide $L$ into multiple subsets $L_{\text{sub}}$
\For{each $L_{\text{sub}}$ in $L$}
    \State Initialize an empty list $B_{\text{sub}}$
    \For{each $L_I$ in $L_{\text{sub}}$}
        \State $(c,e) \gets \text{extract\_code\_and\_explanations}(L_I)$
        \State Add $(c,e)$ to $B_{\text{sub}}$
    \EndFor
    \State $B_{\text{sub}} \gets \text{semantic\_combination}(B_{\text{sub}})$
    \State $B_{\text{sub}} \gets \text{quality\_based\_removal}(B_{\text{sub}})$
    \State $B_{\text{sub}} \gets \text{explanation\_refinement}(B_{\text{sub}})$
    \State $B \gets \text{update}(B, B_{\text{sub}})$
\EndFor
\State \textbf{Return} $B$
\end{algorithmic}
\end{algorithm}




\section{Implementation Details}
To obtain a representative data subset for the coding process, we categorize all POIs into 36 types according to the different combinations of visitor-residential racial composition gaps (e.g., higher \textit{black} and \textit{asian} ratios with lower \textit{white}, \textit{hispanic}, and \textit{other} ratios). %$2^5=36$  %(approximately 200 samples) 
We then perform stratified sampling to randomly select POIs from each type to ensure representiveness. %ensuring that the sampled set maintains diversity.

For the \textbf{reasoning} channel, we train an MLP with hidden dimensions of 512, 128, and 64, removing the output layer to form the Rating Adapter.
For the \textbf{embedding} channel, we fine-tune the last two layers of the pre-trained GTE-base model and extend it with three fully connected layers (512, 256, 128) to form the Embedding Adapter.
For the \textbf{population} channel, we train an MLP with dimensions of 100, 30, and 10, extracting the weights of the first two layers to form the Population Adapter.
%For the \textbf{neighbor-aware multi-view predictor}, we train three independent GATs to aggregate the geographic, rating, and embedding neighbor information. 
For the \textbf{neighbor-aware multi-view predictor}, we adopt Graph Attention Networks (GATs)~\cite{GAT} as the neighbor aggregators. 
The Reasoning GAT maps feature from 64 to 128, the Embedding GAT maintains a 128 to 128 mapping, and the Population GAT maintains a 30 to 30 mapping. %the input-output transformations are as follows: 
The multi-view fusion module comprises three fully connected layers with dimensions 512, 128, and 64. 
During training, we first optimize the three Adapters, then freeze them before training the predictor.

\section{Case study}

In Figure~\ref{fig:case-study}, we present a case study to compare the original reviews, the vanilla method-generated summary, and our codebook-guided summary.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.92\linewidth]{figs/case_study.png}
    \caption{Case study.}
    % \Description{Case study.}
    \label{fig:case-study}
\end{figure*}
\end{comment}


\appendix

\section{Variability of POI features}
Taking Philadelphia as an example, Figure~\ref{fig:poi-variation-statistics} illustrates the distributions of the variations for POI features within a single CBG, including stars, prices, income segregation, and racial segregation.
We can observe that POIs exhibit considerable variability even when examined within the CBG locality, which underscores the significance of our study.
% counts, diversity of POI categories, and the standard deviations of  
%by simply examining within the CBG area, our POI dataset still demonstrates that neighboring POIs exhibit variability.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figs/figure1.png}
    \caption{The Coefficient of Variation distributions for POIs features within the same CBG highlight considerable variability among POIs. Figures a-c demonstrate the distributions of stars, price range, and racial segregation, respectively. 
    }
    % \Description{Statistics.}
    \label{fig:poi-variation-statistics}
\end{figure}

\section{Reflective Coding Algorithm}
We formalize the process of reflective coding in Algorithm~\ref{algorithm}.

\begin{algorithm}[h]
\caption{Reflective Coding Algorithm}
\label{algorithm}
\begin{algorithmic}[1]
\State \textbf{Input:} A set $O$ of tuple  (\text{POI} $I$, \text{POI name} $N$, \text{POI reviews and images} $M$, \text{real visitor composition} $\tau_{real}$, \text{local residential composition} $l_{res}$)

\State \textbf{Output:} Codebook $B$
\State Initialize an empty list $L$
\For{each tuple ($I$, $N$, $M$, $tau_{real}$, $l_{res}$) in $O$}
    \State $L_1 \gets \text{analyze}(N)$
    \State $L_2 \gets \text{analyze}(M)$
    \State $L_{\text{sum}} \gets \text{summary}(L_1,L_2)$
    \State $\tau_{\text{diff}} \gets \text{compare}(\tau_{real}, l_{res})$
    \State $L_I \gets \text{refinement}(\tau_{\text{diff}}, L_{\text{sum}})$
    \State Add $L_I$ to $L$
\EndFor

\State Initialize an empty list $B$
\State Divide $L$ into multiple subsets $L_{\text{sub}}$
\For{each $L_{\text{sub}}$ in $L$}
    \State Initialize an empty list $B_{\text{sub}}$
    \For{each $L_I$ in $L_{\text{sub}}$}
        \State $(c,e) \gets \text{extract\_code\_and\_explanations}(L_I)$
        \State Add $(c,e)$ to $B_{\text{sub}}$
    \EndFor
    \State $B_{\text{sub}} \gets \text{semantic\_combination}(B_{\text{sub}})$
    \State $B_{\text{sub}} \gets \text{quality\_based\_removal}(B_{\text{sub}})$
    \State $B_{\text{sub}} \gets \text{explanation\_refinement}(B_{\text{sub}})$
    \State $B \gets \text{update}(B, B_{\text{sub}})$
\EndFor
\State \textbf{Return} $B$
\end{algorithmic}
\end{algorithm}




\section{Implementation Details}
To obtain a representative data subset for the coding process, we categorize all POIs into 36 types according to the different combinations of visitor-residential racial composition gaps (e.g., higher \textit{black} and \textit{asian} ratios with lower \textit{white}, \textit{hispanic}, and \textit{other} ratios). %$2^5=36$  %(approximately 200 samples) 
We then perform stratified sampling to randomly select POIs from each type to ensure representiveness. %ensuring that the sampled set maintains diversity.

For the \textbf{reasoning} channel, we train an MLP with hidden dimensions of 512, 128, and 64, removing the output layer to form the Rating Adapter.
For the \textbf{embedding} channel, we fine-tune the last two layers of the pre-trained GTE-base model and extend it with three fully connected layers (512, 256, 128) to form the Embedding Adapter.
For the \textbf{population} channel, we train an MLP with dimensions of 100, 30, and 10, extracting the weights of the first two layers to form the Population Adapter.
%For the \textbf{neighbor-aware multi-view predictor}, we train three independent GATs to aggregate the geographic, rating, and embedding neighbor information. 
For the \textbf{neighbor-aware multi-view predictor}, we adopt Graph Attention Networks (GATs)~\cite{GAT} as the neighbor aggregators. 
The Reasoning GAT maps feature from 64 to 128, the Embedding GAT maintains a 128 to 128 mapping, and the Population GAT maintains a 30 to 30 mapping. %the input-output transformations are as follows: 
The multi-view fusion module comprises three fully connected layers with dimensions 512, 128, and 64. 
During training, we first optimize the three Adapters, then freeze them before training the predictor.

\section{Case study}

In Figure~\ref{fig:case-study}, we present a case study to compare the original reviews, the vanilla method-generated summary, and our codebook-guided summary.

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{figs/case_study.png}
    \caption{Case study.}
    % \Description{Case study.}
    \label{fig:case-study}
\end{figure*}

\end{document}

