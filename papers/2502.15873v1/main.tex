%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Practical Principles for AI Cost and Compute Accounting}

\begin{document}

\twocolumn[
\icmltitle{Practical Principles for AI Cost and Compute Accounting}


\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Stephen Casper}{mit}
\icmlauthor{Luke Bailey}{stanford}
\icmlauthor{Tim Schreier}{fli}
\end{icmlauthorlist}

\icmlaffiliation{mit}{MIT CSAIL (this work was done partly at MIT CSAIL and partly independently)}
\icmlaffiliation{stanford}{Stanford University}
\icmlaffiliation{fli}{Future of Life Institute}

\icmlcorrespondingauthor{Stephen Casper}{scasper@mit.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}


Policymakers are increasingly using development cost and compute as proxies for AI model capabilities and risks.
Recent laws have introduced regulatory requirements that are contingent on specific thresholds. 
However, technical ambiguities in how to perform this accounting could create loopholes that undermine regulatory effectiveness. 
This paper proposes seven principles for designing practical AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.


\end{abstract}


\begin{figure*}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/figure_1_new.pdf}
    \vspace{-20pt}
    \caption{Seven principles for cost and compute accounting discussed in \Cref{sec:principles}.}
    \label{fig:principles}
\end{figure*}

\section{Introduction} \label{sec:intro}

As artificial intelligence systems become more capable, policymakers face a mounting challenge: identifying which AI systems warrant heightened oversight. Recent laws and governance frameworks have approached this challenge by making regulatory requirements contingent on development costs and computational resources (e.g., \citealp{EU_AI_Act_Article_51,CA_SB_1047_2023}). 
For example, the U.S. Bureau of Industry and Security's 2025 \textit{Framework for Artificial Intelligence Diffusion} controls the export of AI model weights for systems whose development exceeded $10^{26}$ floating point operations (FLOP) in training compute \citep{framework_ai_diffusion_2025}.

Development costs and compute are compelling metrics for use in AI governance because they ``correlate with capabilities and risks, are quantifiable, can be measured early in the AI lifecycle, and can be verified by external actors''  \citep{heim2024training}. Cost and compute thresholds also allow regulators to focus oversight on the most advanced AI models while avoiding unnecessary burdens on smaller developers. However, their practicality as regulatory tools depends on establishing clear accounting standards. This requires resolving several technical ambiguities about what should be counted 
\citep{hooker2024limitations, heim2024training, reuel2024open}. 

This paper asks the question: \textit{\textbf{How can the cost and compute used during model development be counted in a way that is practical, limits gameability, and avoids disincentivizing responsible risk management?}} Key challenges include determining which activities to count, establishing reporting requirements, and allowing for standards to adapt as technology evolves.


%\emph{In this paper, we propose seven guiding principles (\Cref{fig:principles}) that can be used to address ambiguities like these in a way that is practical and aligns with public interest.}

%We note that this paper does not take any positions on how high cost and compute thresholds should be, what requirements they should trigger, and how they should be incorporated into laws. Instead, we present practical principles for the implementation of such thresholds that are applicable across regulations and can guide the development of related technical standards.
To address these challenges, we propose seven principles for designing practical AI cost and compute accounting standards. We argue that these principles can resolve technical ambiguities while aligning with public interest and enabling consistent implementation across companies and jurisdictions. While we do not take positions on specific laws, thresholds, or requirements, our framework provides policymakers and standards bodies with a foundation for developing robust standards for AI cost and compute accounting.



\section{Background} \label{sec:background}

%\textbf{Related work.} In the AI field, ``scaling laws'' and other correlations between costs/compute and model capabilities have been a major subject of interest in recent years \citep{Villalobos2023ScalingLaws, sevilla2024training}. Meanwhile, academic literature has begun considering the opportunities and challenges of cost and compute thresholds \citep{hooker2024limitations, heim2024training} while recent laws and regulations have been drafted to make certain requirements contingent on cost or compute thresholds (e.g., \citealp{framework_ai_diffusion_2025, EU_AI_Act_Article_51, CA_SB_1047_2023}). However, to date, there has been little work to recommend specific practices for how to do cost and compute accounting. To the best of our knowledge, the only openly available set of guidelines for cost and compute accounting was published by the \citet{FrontierModelForum2024MeasuringCompute}, a collaboration between major tech companies that represents industry interests \citep{wei2024ai}. Here, we echo the \citet{FrontierModelForum2024MeasuringCompute} in the position that certain practical approximations of cost/compute should be permissible. However, we identify several proposed exemptions in their recommendations that could create gameable loopholes in AI regulations.\footnote{These include allowing context-dependent calculations, excluding recomputations, excluding discarded branches, and only counting resources expended on systems trained end-to-end.} 
\textbf{Related work.} AI research has studied ``scaling laws'' demonstrating how AI model performance improves predictably with increased computational resources and data \citep{kaplan2020scaling, Villalobos2023ScalingLaws, sevilla2024training}. While these relationships provide a scientific basis for the theoretical value of cost and compute thresholds in AI regulation \citep{sastry2024computing}, researchers have identified important limitations and highlighted unsolved implementation challenges. Without standardized methodology, complex technical questions about which activities to count and how to report such counts remain unresolved \citep{hooker2024limitations, heim2024training}.

To our knowledge, the only openly-available set of guidelines for cost and compute accounting has been previously published by the \citet{FrontierModelForum2024MeasuringCompute}, a collaboration between major tech companies that represents industry interests \citep{wei2024ai}. Here, we echo the \citet{FrontierModelForum2024MeasuringCompute} in the position that certain practical approximations of cost/compute should be permissible 
(\Cref{sec:estimates}). However, the forum also recommends allowing for contex-dependent calculations, counting only end-to-end training, and exclusion of recomputations and discarded branches. We argue that these guidelines would create loopholes which would allow developers to strategically omit substantial portions of their development process from regulatory oversight (\Cref{sec:project}).

\textbf{Key terms.} In the context of this paper:
\begin{itemize}
    \item \textbf{Developer} refers to the entity undertaking the process of creating an AI model. A single developer can encompass multiple legal entities in formal partnership.\footnote{We use this definition to preclude loopholes involving multiple legal entities formally collaborating to develop a single model. Detailed standards will need to account for collaborative developments, including crowdsourced or federated approaches.} 
    \item \textbf{Development} refers to the process of curating data, training models, creating scaffolding, and testing AI systems. It does not encompass human labor, operations, or procuring hardware.
    \item An \textbf{AI model} refers to a neural information processing structure trained using machine learning. An \textbf{AI system} refers to a set of one or more AI models combined with other software components configured to accomplish a specific task. For example, GPT-4o \citep{hurst2024gpt} is an AI model while ChatGPT-GPT-4o is an AI system. 
\end{itemize}

\textbf{What if multiple models are very similar?} It is possible to develop two distinct but very closely related models. For example, two models may only differ by a small amount of fine-tuning if they are different derivatives of the same `base' model. This poses a challenge to regulators because two such models will often, but not always, have similar behaviors. It may also often be impractical to subject multiple models to potentially redundant regulatory requirements. For this reason, policymakers may want to make developers or `model families' the object of regulation as opposed to individual models. However, recommendations for how to practically handle these cases are beyond the scope of this paper. 



\section{Principles} \label{sec:principles}

Here, we discuss seven principles for developing cost and compute accounting standards. As presented in \Cref{fig:principles}, \Cref{sec:project} - \Cref{sec:safety} cover what to count and not to count, \Cref{sec:estimates} - \Cref{sec:reports} cover how to perform and report on counts, and \Cref{sec:independent} - \Cref{sec:updates} cover how to design thresholds. 


\subsection{Count all of a project’s expended costs and compute} \label{sec:project}


\textbf{Principle:} Count all technical costs and compute that the developer expends in the process of developing an AI model, not simply theoretical, proximal, or upstream ones. 

\textbf{Purpose:} Closing loopholes, and limiting the gameability of accounting standards. 

Developers tend to undertake a variety of activities during the process of developing frontier AI models. However, a narrow view of what counts could be used to exclude certain activities integral to the model development process. For example:


\begin{itemize}
    \item Some activities are not theoretically needed for the final model to have been produced. For example, in the process of training models, there are often many multiplications or additions by zero due to the use of dropout \citep{srivastava2014dropout} and sparsity (e.g., \citealp{correia2019adaptively}). Even though they are not theoretically needed, they are carried out by hardware nonetheless and are often used to improve performance. 
    \item Some activities are not proximal to the model's training process. For example, dataset creation/curation/compression (e.g., \citealp{kaddour2023minipile, solaiman2021process, chen2024automated}) or training a teacher model for distillation \citep{yang2024survey} do not directly involve the final model's training. However, these activities are nonetheless integral to the model’s development and capabilities. 
    \item Some activities are not upstream of the model development process. For example, developers often iteratively train, evaluate, retrain, re-evaluate, etc. until they have a system that meets their desired specifications. Other times, they will train multiple models using different setups and simply select the one which performs best. Although some evaluations and development branches are not directly upstream of the final model, they are nonetheless an integral part of the development process. 
\end{itemize}


When there exists an incentive to make a model seem very cheap using narrow accounting standards, developers can find creative ways to game the count.

\begin{quote}
    \textit{``Any statistical relationship will break down when used for policy purposes.''}\\
    -- Jón Danielsson 
\end{quote}

For example, consider the recent DeepSeek-V3 model \citep{liu2024deepseek}. Its development process was reported to heavily feature distillation from a more powerful model, Deepseek-R1 \citep{guo2025deepseek}. This was reported to significantly improve DeepSeek-V3’s capabilities at a much cheaper cost than fine-tuning it from scratch. \citet{liu2024deepseek} myopically reported that Deepseek-V3’s direct development costs were less than \$6 million in total. However, this count did not include training the teacher model, Deepseek-R1 (whose development costs were not reported by \citep{guo2025deepseek}). Thus, the actual costs utilized behind the making of DeepSeek-V3 were much greater than the reported \$6 million. Deepseek-V3 offers an example of the extent to which developers can use a myopic accounting framework to report misleadingly low apparent costs and compute behind a very capable model. Codifying accounting standards that allowed for similar loopholes would produce further incentives for developers to repose much of a project’s costs and compute into arbitrarily exempt activities. 


Finally, sometimes, there will exist genuine grey-areas related to whether a certain activity was a meaningful part of a model’s development process. For example, if a developer conducts basic research to develop techniques that they will use downstream for the development of a model, would that be counted? Given that different research and development processes undertaken by a company are never conducted 100\% in isolation, some level of ambiguity in which activities were part of a model’s development will be inevitable. However, \Cref{sec:reports} will discuss reporting requirements as a mechanism for fostering transparency and holding developers accountable for their cost and compute accounting practices. 






\subsection{Exclude costs and compute behind pre-existing, openly-available resources} \label{sec:open}


\textbf{Principle:} Count costs and compute that the developer directly incurs through their activities, purchases, and partnerships. Exempt the costs and compute used to produce open resources that developers obtain for free from others. 

\textbf{Purpose:} Practicality and focusing on proprietary resources.

Developers can produce capable models through multiple sources of cost and compute. They often curate their own data and train their own models in-house. However, they can also purchase resources, query systems from external providers, and outsource parts of the development process to partners. For the reasons outlined in \Cref{sec:project}, these are generally needed for thorough accounting.

But, what about open resources that developers obtain freely from others? For example, a developer may simply download an open model or dataset from the web. In this case, there are two reasons not to include this in compute and cost estimates. First, due to inconsistencies with model \citep{mitchell2019model} and data \citep{longpre2023data} provenance, it will often be intractable to find precise information on the costs or compute behind open models, systems, and data. Second, because such resources are already openly available, they offer a zero-effort floor for widely available capabilities. 

However, one modification to this exemption may be necessary to close a loophole. If resources that were recently (e.g., within 6 months prior to when a model’s development begins), openly released by the same developer\footnote{Recall in \Cref{sec:background} that we define ``developer'' to include formal collaborations between multiple legal entities. This type of definition would prevent multiple legal entities from spliting the development process via open-weight checkpoints to avoid passing a threshold so long as they had a contractual agreement to do so.} in question, regulators may wish to require that this resource is still counted. Without this exception, developers would be able to openly release partially-developed model components (e.g., a pretrained base model) in order to exclude them from accounting. 

As a final note, regulators may wish to uniquely handle cases in which a developer begins with an open model whose development already passed thresholds and further develops it. For example, a failed 2024 California bill \citep{CA_SB_1047_2023} defined a ``covered'' model in terms of either a primary threshold or a secondary threshold for when additional development is applied to an existing ``covered'' model. This type of regulatory strategy may be appealing to regulators because of how modest amounts of further development of highly capable models can substantially alter their capabilities. However, recommendations on how regulators should handle these cases are beyond the scope of this paper. 







\subsection{Exclude activities undertaken only to reduce societal risks} \label{sec:safety}


\textbf{Principle:} Allow developers to exempt activities undertaken only for the purpose of reducing risks to society which do not have side effects of enhancing model capabilities.  

\textbf{Purpose:} Not disncentivizing societal risk-reduction practices.

Over the course of developing an AI model, most key activities are undertaken either partially or entirely to improve its capabilities. For example, pretraining and fine-tuning are principally meant to make models more capable and useful. However, some activities are undertaken strictly to reduce risks. Examples include filtering child sexual abuse material (CSAM) from training data (e.g., \citealp{thiel2023identifying}), fine-tuning models to refuse criminal requests (e.g., \citealp{yuan2024refuse}), and testing for national security risks (e.g., \citealp{shevlane2023model}). To avoid disincentivizing risk mitigation measures, developers must be allowed to exclude these types of activities from their accounting. 

How should it be determined when an activity is undertaken only for the purpose of mitigating societal risks? This can be difficult due to the lack of a clean dichotomy and the prevalence of ``safetywashing'' \citep{ren2024safetywashing}. To mitigate this challenge, developers can be required to produce a rigorous, auditable justification for why an activity only reduces risks without simultaneously increasing capabilities in an accounting report (see \Cref{sec:reports}).







\subsection{Allow for reasonable estimates} \label{sec:estimates}

\textbf{Principle:} When counting costs and compute used for a model’s development, developers should be permitted (and often expected) to use reasonable estimations when precise information is not practically attainable. 

\textbf{Purpose:} Practicality.

Information about costs and compute expended during a model’s development is not always precisely quantifiable. For example, developers will often not know exactly how much compute has been expended when they query a closed-source system from some outside provider. However, in a case like this, reasonable estimates can be made based on contextual knowledge and the market value of compute \citep{sevilla2022estimating, cottier2024rising}. These types of estimates would be analogous to how similar estimates of the ``fair value'' of assets are commonly used in financial accounting \citep{IFRS13_2022}. In accounting, imprecision in some items will be inevitable, but to reduce the risk of this being gamed or resulting in unreliable counts, developers can be required to provide a report on their approach to accounting that documents included estimates (see \Cref{sec:reports}). Meanwhile, regulators or standards bodies could publish guidance on appropriate estimation methodologies, tolerable error margins, and suitable documentation templates. 







 \subsection{Require itemized accounting reports} \label{sec:reports}


\textbf{Principle:} Require developers to produce an auditable, itemized accounting report detailing their approach, including justifications for estimates and exemptions. 

\textbf{Purpose:} Transparency and accountability.

In financial accounting, companies are regularly required to send records and reports to governing bodies (e.g., \citealp{SEC_FRM_Topic_2}). This has both the direct effect of helping government oversight offices spot issues and the indirect effect of incentivizing due diligence from companies. The same applies to AI cost and compute accounting. These reports would also be key for developers to provide explanations and justifications for technical exemptions (\Cref{sec:project}), open resource exemptions (\Cref{sec:open}), risk mitigation exemptions (\Cref{sec:safety}), and estimations (\Cref{sec:estimates}). Such reports would improve accountability around accounting practices and inform regulators about industry trends in development expenditures.

%For accounting reports to be truly effective, they must contain sufficient detail to enable meaningful review. Documentation for standard development activities (e.g., data preparation, data creation, pretraining, reinforcement learning) should include specific FLOP estimates and associated costs.

%For more complex claims—particularly exemptions under Principle 3 for risk mitigation activities—documentation should be substantially more comprehensive. This should include:
%1. Clear description of the activity and its purpose
%2. Evidence demonstrating the activity was undertaken solely for risk reduction
%3. Explanation of why the activity does not enhance model capabilities
%4. Methodology used to isolate these activities from capability-enhancing work
%5. Quantification of resources that would have been counted without the exemption

%Timely reporting is also critical. Regulators should establish reasonable reporting deadlines that balance the need for current information with practical constraints on developers. Ideally, reports should be submitted shortly after significant development milestones or on a regular periodic basis for ongoing development.

%Standardized reporting templates would help ensure consistency across developers while reducing compliance burdens. These templates could evolve over time through collaboration between regulators and industry to address emerging challenges in documentation.






\subsection{Use independent thresholds for costs and compute} \label{sec:independent}

\textbf{Principle:} Regulatory requirements should be independently triggered by separate thresholds for cost and compute. 

\textbf{Purpose:} Closing loopholes, and limiting the gameability of accounting standards.

Cost and compute are correlated, but they can still be decoupled, especially when developers have an incentive to game standards. For example, machine-generated data is cheap but computationally intensive while human-generated data is expensive but computationally free. A developer could design a project to be low-cost/high-compute or vice versa by adjusting the extent to which they use machine- versus human-generated data. As a result, having both cost and compute triggers would reduce gameability. 

Separate cost and compute thresholds can also serve as insurance for each other in case of error or fraud. For example, if a developer purchases queries or other services from an external provider, precise information on the amount of compute used might not be available, but the costs are unambiguous and auditable. Meanwhile, different computing devices can use different amounts of power to perform the same computations, but the compute is unambiguous.











\subsection{Require regular updates to thresholds and standards} \label{sec:updates}

\textbf{Principle:} Require that thresholds and accounting standards are regularly updated to reflect technological developments. 

\textbf{Purpose:} Ensuring standards and thresholds remain effective by adapting to technological advances and evolving societal needs.

In AI, state-of-the-art systems and methods change rapidly. Over time, it is not clear how trends in scaling training, scaling inference, and computational efficiency will affect costs and compute in the development of frontier AI models \citep{pilz2023increased}. Accordingly, governance frameworks will need to be adaptive to ensure they remain relevant over time. To regulate incisively, government offices and/or standards bodies will need to revisit and curate standards on a regular (e.g., quarterly or semiannual) basis in response to new developments in the state-of-the-art. 






\section{Discussion}


\textbf{Significance:} Regulating AI is challenging. It is an emerging technology shrouded in uncertainty about what impacts it will have and how it will evolve. Regulatory thresholds involving cost and compute, however, are a uniquely practical \citep{heim2024training} yet technically challenging \citep{hooker2024limitations} strategy for designing regulations that target frontier AI models. Technical ambiguities in how cost and compute are counted are a central challenge to their effective use. Lacking sound accounting standards could result in these counts being insufficiently useful proxies for risk. Furthermore, under loose guidelines for how costs and compute are counted, developers will have a strong incentive to engage in ``creative compliance'' \citep{shah1996creative} to actively game them. To make cost and compute thresholds more tenable as a regulatory strategy, standards for accounting must be clear, consistent, tight, and aligned with public interest. To support the development of such standards, we have proposed a principles-first framework to resolve ambiguities and introduced seven principles designed to reduce gameability, avoid disincentivizing societal risk mitigation practices, and enable consistent implementation across companies and jurisdictions. 

%International Alignment
%The global nature of AI development necessitates international alignment on cost and compute accounting standards. Inconsistent measurement approaches across jurisdictions create unnecessary compliance burdens for developers while complicating regulatory cooperation. Alignment would enable firms to implement a single accounting methodology that satisfies multiple regulatory frameworks, facilitate mutual recognition between oversight bodies, and prevent regulatory arbitrage. While jurisdictions will set their own thresholds and requirements, a shared foundation for measurement would significantly enhance the practicality and effectiveness of cost and compute accounting as a global governance approach. Key steps toward alignment include developing common measurement protocols, standardized reporting templates, and mechanisms for cross-border information sharing.






\textbf{Limitations:} This work was not written in the context of any specific law. We make no recommendations about what kinds of regulatory requirements should be triggered and how. Key questions about how high to set thresholds, what they should trigger, and how they should be incorporated into a broader governance framework are all beyond the scope of this paper. Furthermore, as we have discussed, while the principles discussed here can resolve much ambiguity, grey areas will be inevitable. This underscores the role that accounting reports can play in improving regulatory awareness. 

\textbf{Future work:} Whereas this paper has sought to outline principles for designing standards, future work will be needed to produce concrete standards. Implementing these principles in practice will require specific attention to the purpose and scope of any individual law and may require compromises to ensure logistical and/or political feasibility. 




\section*{Acknowledgments}

We would like to thank Anthony Aguirre, Alexander Erben, James Petrie, Joe Kwon, Lennart Heim, Mark Brakel, Nandi Schoots, and Richard Mallah for discussions and feedback. 
Stephen Casper and Luke Bailey are funded by a Future of Life Institute Vitalik Buterin Fellowship. Luke Bailey is also funded by the SAP Stanford Graduate Fellowship.



\bibliography{bibliography}
\bibliographystyle{icml2025}

\end{document}
