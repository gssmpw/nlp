\section{Introduction}
\label{introduction}


The expressiveness of GNNs fundamentally depends on their ability to capture and transform local topological structures into meaningful representations of graph-structured data. However, although they achieved remarkable success in diverse domains ranging from molecular modeling \cite{gilmer2017neuralmessagepassingquantum} to social network analysis \cite{hamilton2018inductiverepresentationlearninglarge}, the extent to which GNNs performance is fundamentally tied to the topology of their input graphs remains poorly understood. Specifically, how does the topology of the input graph influence the transformation of local features into global representations in GNNs, and what determines whether this leads to oversmoothing \cite{chen2019measuringrelievingoversmoothingproblem} or effective, discriminative embeddings?

A key challenge lies in the interplay between two aspects: (1) the intrinsic topological structure of the input graph, which governs the connectivity patterns and influences information flow during message passing, and (2) the dynamic evolution of node representations through successive GNN layers. Although effective learning relies on exploiting these topological features, certain graph properties, such as high local similarity or poorly connected regions, can lead to phenomena like oversmoothing, where node embeddings become indistinguishable \cite{chen2019measuringrelievingoversmoothingproblem}. Understanding whether GNNs are inherently constrained by these topological factors is critical for both theoretical insights and practical advancements.

% from preserving structural privacy \cite{xiang2023preservingnodelevelprivacygraph} to preventing the phenomenon of over-smoothing \cite{zhao2020pairnormtacklingoversmoothinggnns, chen2019measuringrelievingoversmoothingproblem, kelesis2024reducingoversmoothinginformedweight} in deep architectures.


Recent work has partially addressed these issues. For example, \citet{xu2019powerfulgraphneuralnetworks} explored the expressiveness of GNNs, focusing on their ability to distinguish non-isomorphic graphs through their aggregation mechanism and readout function. In contrast, \citet{nguyen2023revisitingoversmoothingoversquashingusing} examined the link between graph curvature and oversmoothing. Meanwhile, \citet{bodnar2023neuralsheafdiffusiontopological} introduced a framework that leverages cellular sheaf theory to explain oversmoothing, modeling non-trivial sheaf structures to better understand the underlying causes of this phenomenon. 

These approaches may appear distinct, but they are fundamentally related. Whether it is curvature, the Laplacian spectrum, or cellular sheaves, they are all defined or linked through the local connectivity patterns within the input graph. Even the solutions proposed to mitigate oversmoothing rely on perturbing these connectivity patterns, such as by dropping edges or nodes, rewiring, adding residual connections, or co-training with random walks. Therefore, in this work, rather than focusing on a specific aspect of this phenomenon, we investigate its underlying source, namely its local connectivity patterns.

We examine the impact of these local connectivity patterns on the performance of GNNs through $k$-hop similarity. Here, we do not refer to $k$-hop isomorphism, where two graphs have isomorphic k-hop neighborhoods (which would be trivial). Rather, we focus on a broader case, where the sets of $k$-hop neighborhoods are identical, although the overall structure or edge arrangement may differ. 

For example, Figure \ref{two-hop} illustrates this concept: although these two graphs are not two-hop isomorphic, they are two-hop similar. The question that arises is as follows: 
\begin{center}
\textbf{\textit{Does training on two $k$-hop similar graphs lead to consistent node representations?
}}    
\end{center}


\begin{figure}[H]
    \vskip 0.2in
    \begin{center}    \centerline{\includegraphics[width=0.5\columnwidth]{Figures/two_hop.png}}
    \caption{Illustration of two $2$-hop similar graphs with distinct edge arrangements. Although the $2$-hop neighborhoods are identical, the graphs are not $2$-hop isomorphic.}
    \label{two-hop}
    \end{center}
    \vskip -0.2in
\end{figure}

To answer this question, we propose Conjecture \ref{conjecture: weight_consistency}, which formalizes our intuition that graphs with similar local structures should induce similar learning behaviors in GNNs. Specifically, if two graphs are $k$-hop similar, the optimal parameters learned by a $k$-layer GNN should be approximately equivalent, as they are essentially solving the same local learning problems.
\begin{conjecture}[\textbf{Weight Consistency under $k$-Hop Similarity in GNNs}]
\label{conjecture: weight_consistency}
Let $G_1$ and $G_2$ be two graphs that are $k$-hop similar. Let $f_\theta$ denote a GNN with $k$ layers, and let $\theta_1$ and $\theta_2$ represent the optimal learned parameters of the GNN after training on graphs $G_1$ and $G_2$, respectively. We conjecture that the functions induced by these optimal weights, $f_{\theta_1}$ and $f_{\theta_2}$, satisfy the following approximate equality:
\begin{equation*}
    f_{\theta_1} \approx f_{\theta_2}
\end{equation*}
\end{conjecture}

In the following, we aim to validate our conjecture and explore its implications on the performance of GNNs and the oversmoothing problem. Our contributions are threefold:

\begin{itemize}
    \item We develop an algorithm to generate $k$-hop similar graphs, which will allow us to test the validity of our conjecture.
    \item We empirically validate the conjecture under various graph structures, using stochastic block models as controls.
    \item We provide an explanation for the oversmoothing phenomenon based on our conjecture, illustrating how graph topology can negatively affect GNN performance.
\end{itemize}

