%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
%\input{math_commands.tex}
%%%%% NEW MATH DEFINITIONS %%%%%

\usepackage{amsmath,amsfonts,bm}

% Mark sections of captions for referring to divisions of figures
\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}

% Highlight a newly defined term
\newcommand{\newterm}[1]{{\bf #1}}


% Figure reference, lower-case.
\def\figref#1{figure~\ref{#1}}
% Figure reference, capital. For start of sentence
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
% Section reference, lower-case.
\def\secref#1{section~\ref{#1}}
% Section reference, capital.
\def\Secref#1{Section~\ref{#1}}
% Reference to two sections.
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
% Reference to three sections.
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
% Reference to an equation, lower-case.
\def\eqref#1{equation~\ref{#1}}
% Reference to an equation, upper case
\def\Eqref#1{Equation~\ref{#1}}
% A raw reference to an equation---avoid using if possible
\def\plaineqref#1{\ref{#1}}
% Reference to a chapter, lower-case.
\def\chapref#1{chapter~\ref{#1}}
% Reference to an equation, upper case.
\def\Chapref#1{Chapter~\ref{#1}}
% Reference to a range of chapters
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
% Reference to an algorithm, lower-case.
\def\algref#1{algorithm~\ref{#1}}
% Reference to an algorithm, upper case.
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
% Reference to a part, lower case
\def\partref#1{part~\ref{#1}}
% Reference to a part, upper case
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


% Random variables
\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
% rm is already a command, just don't name any random variables m
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

% Random vectors
\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

% Elements of random vectors
\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

% Random matrices
\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

% Elements of random matrices
\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

% Vectors
\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

% Elements of vectors
\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

% Matrix
\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

% Tensor
\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


% Graph
\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

% Sets
\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
% Don't use a set called E, because this would be the same as our symbol
% for expectation.
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

% Entries of a matrix
\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

% entries of a tensor
% Same font as tensor, without \bm wrapper
\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

% The true underlying data generating distribution
\newcommand{\pdata}{p_{\rm{data}}}
% The empirical distribution defined by the training set
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
% The model distribution
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
% Stochastic autoencoder distributions
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
% Wolfram Mathworld says $L^2$ is for function spaces and $\ell^2$ is for vectors
% But then they seem to use $L^2$ for vectors throughout the site, and so does
% wikipedia.
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
% \usepackage{hyperref}
\usepackage[dvipsnames]{xcolor} % 引入颜色宏包
\usepackage[colorlinks=true, citecolor=blue, linkcolor=red, urlcolor=RoyalBlue]{hyperref} % 超链接设置
\usepackage{bm}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\definecolor{darkgreen}{RGB}{0,70,34} % Forest Green
% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}


\usepackage{multirow}  % 用于合并行
\usepackage{booktabs}  % 用于制作三线表
\usepackage{xcolor}    % 用于单元格背景色
\usepackage{bbding}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}
% \PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{breakurl}
\usepackage{hyperref}


\icmltitlerunning{Knowledge Swapping via Learning and Unlearning}

\begin{document}

\twocolumn[
\icmltitle{Knowledge Swapping via Learning and Unlearning}


%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Mingyu Xing}{sch}
\icmlauthor{Lechao Cheng\textsuperscript{\Envelope}}{sch}
\icmlauthor{Shengeng Tang}{sch}
\icmlauthor{Yaxiong Wang}{sch}
\icmlauthor{Zhun Zhong\textsuperscript{\Envelope}}{sch}
\icmlauthor{Meng Wang}{sch}
%\icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
\icmlaffiliation{sch}{School of Computer and Information, Hefei University of Technology}

\icmlcorrespondingauthor{Lechao Cheng}{chenglc@hfut.edu}
\icmlcorrespondingauthor{Zhun Zhong}{zhunzhong007@gmail.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\printAffiliations{}
\begin{abstract}
We introduce \textbf{Knowledge Swapping}, a novel task designed to selectively regulate knowledge of a pretrained model by enabling the forgetting of user-specified information, retaining essential knowledge, and acquiring new knowledge simultaneously. 
By delving into the analysis of knock-on feature hierarchy, we find that incremental learning typically progresses from low-level representations to higher-level semantics, whereas forgetting tends to occur in the opposite direction—starting from high-level semantics and moving down to low-level features.
%We further discover that \textit{Learning} process is relatively more challenging than forgetting 
Building upon this, we propose to benchmark the knowledge swapping task with the strategy of \textit{Learning Before Forgetting}.
Comprehensive experiments on various tasks like image classification, object detection, and semantic segmentation validate the effectiveness of the proposed strategy. The source code is available at \href{https://github.com/xingmingyu123456/KnowledgeSwapping}{https://github.com/xingmingyu123456/Knowledge\allowbreak Swapping}


% To achieve this, we propose a two-stage training strategy, \textit{Learning Before Forgetting}(LBF), motivated by the following insight. Learning new knowledge induces global parameter adjustments across both low-level and high-level features, while forgetting is a more localized process that primarily affects high-level representations. 
% %
% By decoupling these processes, our LBF facilitates efficient task adaptation while mitigating catastrophic forgetting. Comprehensive experiments on image classification, object detection, and semantic segmentation benchmarks demonstrate the effectiveness of our method in achieving precise knowledge regulation and robust task performance.
% This document provides a basic paper template and submission guidelines.
% Abstracts must be a single paragraph, ideally between 4--6 sentences long.
% Gross violations will trigger corrections at the camera-ready test111
\end{abstract}
\section{Introduction}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{assets/teaser.pdf}
    \vspace{-8mm}
    \caption{\small
Comparison of three tasks: Continuous Learning, Machine Unlearning, and our Knowledge Swapping.}
    \label{fig:teaser}
    \vspace{-5mm}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.5\linewidth]{assets/模型架构.png}
%     \caption{The framework of our proposed model}
%     \label{fig:framework}
% \end{figure}

The proliferation of deep learning has led to the widespread adoption of pretrained models~\cite{han2021pre}, which are typically fine-tuned using task-specific data to achieve parameter-efficient adaptation. In the context of streaming tasks, researchers have increasingly explored methods for continuously optimizing and adapting pretrained models to new tasks~\cite{lin2023pcr,chen2024llm,zhu2023continual}, a paradigm referred to as continual learning~\cite{wang2024comprehensive}. However, in practical applications, as deep models integrate more knowledge, they often encounter additional requirements, such as the need to continuously block or forget certain sensitive content. Recent works, such as machine unlearning~\cite{liu2024towards,wang2025towards,zhang2024defensive}, have begun to address the unilateral forgetting of specific content within pretrained models. Nonetheless, approaches that simultaneously enable the learning of new knowledge and the forgetting of specific content remain underexplored.

%While existing continual learning frameworks excel at incrementally learning new tasks in the short term or for simpler scenarios—owing to the inherent capacity of deep models—they face significant challenges when the volume of embedded knowledge exceeds the model's capacity, leading to underfitting. A potential solution to this issue is the intentional ``forgetting'' of less critical or infrequently used knowledge, thereby freeing up model capacity to accommodate new tasks.

Inspired by this insight, we propose a novel task termed Knowledge Swapping, which enables the selective forgetting of specific categories of knowledge while preserving others, tailored to the requirements of new tasks. As depicted in Figure~\ref{fig:teaser}, \textit{continual learning} aims to integrate new task knowledge into an existing pretrained model. Current mainstream approaches~\cite{li2024atlas,wang2022learning} often involve attaching a new adapter for each task and fine-tuning it, yet the need to forget outdated or less relevant knowledge remains an underexplored challenge. Recent advancements~\cite{liu2024rethinking,wang2025towards} in \textit{machine unlearning} have demonstrated that isolating or removing specific knowledge from a pretrained model necessitates an explicit unlearning process. In contrast, our proposed \textbf{Knowledge Swapping} task facilitates the learning of new tasks while simultaneously forgetting less important prior knowledge or sensitive data that requires protection, thereby preserving the core capabilities of the pretrained model.

We further delve into how to perform knowledge swapping more effectively by leveraging empirical insights. Intuitively, this process can be divided into two stages: forgetting specific knowledge and learning novel knowledge. A natural assumption might be that the model should first forget less important or potentially detrimental priors in order to “free up” the capacity for new information. We conduct a set of straightforward experiments to analyze, in isolation, how incremental learning and targeted forgetting each influence model parameters. Our findings indicate that incremental learning typically progresses from low-level representations to higher-level semantic features, whereas forgetting tends to occur in the opposite direction—starting from high-level semantics and moving down to low-level features. This contrast provides valuable insights for designing strategies for knowledge swapping task. Specifically, if we perform targeted forgetting first, we may complete the forgetting of high-level semantics before any major adjustments occur in the low-level feature space. Once we begin introducing new content afterward, these low-level changes may no longer align with the previously forgotten high-level semantic representations, thereby creating potential conflicts. Conversely, if we first learn the new task (thus updating the low-level feature distribution), and only then conduct targeted forgetting, the process is more likely to remain confined to higher-level semantics. As a result, the updated low-level distributions are less likely to be perturbed during the forgetting stage, which helps to maintain the integrity of previously acquired knowledge. We empirically show \textit{learning new tasks first, followed by selective forgetting of specific knowledge, leads to significantly better results.} 
%Also, our exhaustive experimental results demonstrate our analysis. 
Our contributions are summarized as follows:
\begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parsep}{0pt}
    \setlength{\parskip}{0pt}
    \item  We propose the concept of \textbf{Knowledge Swapping}, a novel task that facilitates the learning of new tasks while simultaneously forgetting less important prior knowledge and preserving essential pretrained capabilities.
    %aiming to selectively forget specific, less-critical knowledge while preserving essential pretrained capabilities.
    \item We uncover that incremental learning progresses from low-level to higher-level semantic features, whereas targeted forgetting begins at high-level semantics and works downward. This directional contrast provides key insights into how to design effective knowledge swapping procedures.
    \item Building upon the insight from feature-hierarchy interplay, we propose to achieve knowledge swapping by sequential learning-then-forgetting principle. Comprehensive experiments also demonstrate that the proposed strategy significantly improves overall performance.    
\end{itemize}
% However, our preliminary experiments (as detailed in Section~X) show that this sequence of operations yields suboptimal results. Surprisingly, we find that \textit{learning new tasks first, followed by selective forgetting of specific knowledge, leads to significantly better results.} In other words, the sequential process of task learning followed by targeted forgetting proves more effective than the reverse.

% We introduce a novel task, referred to as Knowledge Swapping, which enables the selective regulation of a model's knowledge. The primary objective of Knowledge Exchange is three fold: 1) to forget user-specified knowledge, 2) to retain core knowledge essential for task performance, and 3) to learn new knowledge relevant to the new task. 

% To achieve this goal, we propose a two-stage training strategy that follows learn first, then forget approach. The pinciple behind this strategy is based on the observation that learning new knowledge involves global changes to the model’s parameters, affecting both low-level features (such as edges) and high-level features (such as object categories and semantic relations). In contrast, forgetting existing knowledge is a more localized process, primarily affecting high-level parameters without significantly altering the underlying feature extraction layers. By first allowing the model to learn new knowledge and then applying a targeted forgetting process, we ensure that the model adapts to the new task without compromising its previously learned skills. 

% Our method leverages two key techniques: LoRA for fine-tuning pre-trained models and group sparse regularization to selectively forget or retain specific knowledge. LoRA fine-tunes the model's parameters, specifically focusing on linar layers of transformer, which are known to contain critical knowledge. Group sparse regularization is then applied to constrain the LoRA parameters, enabling the model to selectively forget specific knowledge and retain core information. In this paper, we demonstrate the effectiveness of our approach through extensive experiments on image classification, object detection, and semantic segmentation tasks. Our results show that our method provides a robust solution for task adaptation in real-world applications.
% Our contributions are summarized as follows:


% (1) We introduce the concept of Knowledge Swapping, a novel task aimed at selectively regulating a model’s knowledge, enabling the forgetting of user-specified knowledge, retaining core knowledge, and learning new knowledge relevant to a new task.

% (2) We propose a two-stage training strategy, based on the “learn first, then forget” principle, which ensures that the model adapts to new tasks without compromising previously learned skills. This strategy separates the learning and forgetting processes to address the catastrophic forgetting problem in continual learning.

% (3) We combine LoRA fine-tuning with group sparse regularization, where LoRA fine-tunes the model’s critical linear layers, and group sparse regularization constrains the parameters to selectively forget non-essential knowledge while preserving core information.

% (4) Extensive experimental results on image classification, object detection, and semantic segmentation benchmarks demonstrate the effectiveness of our method in preventing catastrophic forgetting and achieving superior performance.

\section{Related Work}
\label{sec:re}


\subsection{Continual Learning}

% \textbf{Paper Deadline:} The deadline for paper submission that is
% advertised on the conference website is strict. If your full,
% anonymized, submission does not reach us on time, it will not be
% considered for publication. 


% Informal publications, such as technical
% reports or papers in workshop proceedings which do not appear in
% print, do not fall under these restrictions.
% Continual learning, also known as lifelong learning, aims to enable models to learn new tasks or knowledge incrementally while retaining performance on previously learned tasks. Techniques in this area typically address the catastrophic forgetting problem\cite{french1999catastrophic}, where learning new tasks leads to a degradation in performance on previously learned tasks. Existing approaches to continual learning can be broadly categorized into three types:Regularization-Based Methods\cite{kirkpatrick2017overcoming,liu2018rotate,dhar2019learning}, Replay-Based Methods\cite{caccia2020online,lopez2017gradient,hou2019learning}, Architecture-Based  Methods\cite{mallya2018piggyback,aljundi2017expert,hu2019overcoming}.

% Continual learning, also known as lifelong learning, aims to enable models to learn new tasks or knowledge incrementally while retaining performance on previously learned tasks. Techniques in this area typically address the catastrophic forgetting problem where learning new tasks leads to a degradation in performance on previously learned tasks. Existing approaches to continual learning can be broadly categorized into three types: Regularization-Based Methods, Memory-Based Methods and ,Architecture-Based Methods.

% Regularization-based methods introduce constraints in the loss function to retain past knowledge. EWC~\cite{kirkpatrick2017overcoming} estimates parameter importance using Fisher Information to limit critical weight updates. LwF~\cite{li2017learning} distills knowledge from old models to new ones for prediction consistency. PASS~\cite{zhu2021prototype} leverages prototype augmentation and self-supervised learning to maintain decision boundaries. PAR\cite{} dynamically selects parameter regularization for similar tasks and parameter allocation for dissimilar tasks based on task similarity measured by nearest-prototype distance.
% RGO\cite{liu2022continual} adjusts gradient updates using a projection matrix to minimize task interference, estimates past task losses via second-order Taylor expansion, and employs a Virtual Feature Encoding Layer to maintain task-specific representations without extra parameters.
% Memory-based methods maintains an external memory that stores or generates old data, features, or knowledge representations for retrieval during training. ICaRL~\cite{rebuffi2017icarl} selectively stores exemplars and employs a nearest-mean-of-exemplars classifier with knowledge distillation. CST~\cite{ashok2022class} introduces cross-space clustering for class-level feature structures and controlled transfer for inter-class knowledge regulation. %HAL~\cite{chaudhry2021using} optimizes anchor points through bilevel optimization.%
% MEMO\cite{zhou2022model} balances memory usage in class-incremental learning by selectively storing exemplars while expanding deep model layers, optimizing memory efficiency and knowledge retention without relying solely on replay-based methods.
% BMKP\cite{sun2023decoupling} introduces a bilevel memory framework that decouples learning and remembering, where a working memory adapts to new tasks and a long-term memory retains compact knowledge representations via knowledge projection.
% Architecture-based methods modify the model by expanding the network. Progressive Neural Networks~\cite{rusu2016progressive} allocate new network columns for each task with lateral connections. DyTox~\cite{douillard2022dytox} employs a transformer-based framework with dynamically expanding task-specific tokens and a shared encoder. FOSTER~\cite{wang2022foster} first expands the model using gradient boosting and then compresses it via knowledge distillation.
% ArchCraft\cite{lu2024revisiting} optimizes neural network architectures for continual learning by using neural architecture search (NAS) to balance stability and plasticity, generating wider and shallower networks that improve knowledge retention while reducing parameter overhead. 

% Our proposed method shares similarities with continual learning in its goal of balancing retention and learning. However,knowledgeeswappingg introduces an additional challenge of selective forgetting, which is not explicitly addressed in traditional continual learning approaches.


Continual learning, also known as lifelong learning, aims to enable models to learn new tasks incrementally while mitigating catastrophic forgetting. Existing approaches can be broadly categorized into Regularization-Based Methods~\cite{kirkpatrick2017overcoming,li2017learning,zhu2021prototype, liu2022continual, wang2023task}, Memory-Based Methods~\cite{rebuffi2017icarl,ashok2022class,chaudhry2021using,zhou2022model,sun2023decoupling}, and Architecture-Based Methods~\cite{rusu2016progressive,douillard2022dytox,wang2022foster,lu2024revisiting}.

Regularization-based methods introduce constraints in the loss function to retain past knowledge. For instance, EWC~\cite{kirkpatrick2017overcoming} distills knowledge from old models to new ones for prediction consistency. 
%RGO~\cite{liu2022continual} adjusts gradient updates using a projection matrix to minimize task interference and employs a Virtual Feature Encoding Layer to maintain task-specific representations without extra parameters.
Memory-based methods maintain an external memory to store or generate past knowledge. 
%ICaRL ~\cite{zhou2022model} balances memory usage by expanding deep model layers while selectively storing exemplars. 
BMKP~\cite{sun2023decoupling} introduces a bilevel memory framework, where a working memory adapts to new tasks and a long-term memory retains compact knowledge representations.
Architecture-based methods expand the model to accommodate new tasks. Progressive Neural Networks\cite{rusu2016progressive}
expands the model using gradient boosting and compresses it via knowledge distillation. ArchCraft~\cite{lu2024revisiting} leverages neural architecture search (NAS) to balance stability and plasticity, generating architectures that enhance knowledge retention with minimal parameter overhead.
Our proposed method shares the goal of balancing retention and learning with continual learning approaches. However, knowledge swapping introduces an additional challenge of selective forgetting, which is not explicitly addressed in traditional continual learning methods.

\subsection{Machine Unlearning}

Machine unlearning~\cite{koh2017understanding, kurmanji2024towards, liu2024model} focuses on efficiently removing specific data or knowledge from a trained model without requiring full retraining, which is crucial for data privacy compliance. 
% As this field is still in its early stages, we present a chronological overview of representative methods that have shaped the development of this area. 
One of the earliest approaches is fine-tuning, which exploits catastrophic forgetting by retraining the model on a retention dataset, though it may leave residual traces of forgotten data. This method forms the foundation for subsequent unlearning techniques. Building on this, Influence Functions~\cite{koh2017understanding} emerged, whiestimatetes the influence of individual data points on model parameters, providing a more precise and computationally efficient method for data removal without retraining the entire model. Later, more sophisticated methods are introduced. NegGrad+~\cite{kurmanji2024towards} balances the loss on the forgotten set and the retention dataset, offering a more controlled trade-off in the unlearning process. 
% Following this, SCRUB~\cite{kurmanji2024towards} further advances the field by incorporating contrastive learning, where a student model mimics the behavior of a teacher model on retained data while contrasting its output on the forgotten data, allowing for a more targeted approach to unlearning. 
To further refine the removal of specific knowledge, L1-Sparse~\cite{liu2024model} introduces the use of L1-regularization to zero out parameters associated with forgotten data, effectively eliminating their influence on the model. Additionally, Relabeling techniques, such as Saliency Unlearning~\cite{feldman2020does} disrupts the model’s memory of forgotten data by altering its labels, focusing on modifying key parameters that store the data's influence. Unlike conventional unlearning methods, which primarily focus on individual data points, our proposed framework introduces a novel approach for category-level forgetting. By integrating the processes of learning, retention, and forgetting into a unified system, this framework offers more flexibility and control over knowledge management, marking a significant advancement in this area of research.
\begin{figure*}[!htb]
    \centering
    \subfigure[\small Learning Before Forgetting ($L \rightarrow F$)]{
        \includegraphics[width=0.85\linewidth, trim=0mm 0mm 0mm 0mm, clip]{assets/fltf-combine-l2nrom_0126.pdf}
    } \\
    \vspace{-3mm}
    \subfigure[\small Learning After Forgetting ($F \rightarrow L$)]{
        \includegraphics[width=0.85\linewidth]{assets/fftl-combine-l2nrom_0126.pdf}
    }
    \vspace{-4mm}
    \caption{\small \textbf{$\mathcal{L}_2$ norm for each parameter under $L\rightarrow F$ and $F\rightarrow L$.} The superscript $W$ denotes the weight norm value at the current stage. The figure illustrates that (a) during the \textit{Learning Before Forgetting} phase, changes in parameter norms are predominantly concentrated in layers responsible for high-level semantic representations. Conversely, (b) in the \textit{Learning After Forgetting} phase, parameter norm changes primarily occur in layers associated with low-level feature representations.
    % Each group of LoRA parameters corresponds to a Transformer block, with indices 0-23 representing encoder LoRA parameters and indices 24-39 representing decoder LoRA parameters. In Figure (a), the L2 norm of each group of LoRA parameters is computed at the initial time, after learning, and after forgetting. Then, the absolute difference between the L2 norm after forgetting and the L2 norm after learning is calculated to represent the parameter changes induced by the forgetting process, which is shown by the green line. In Figure (b), the L2 norm of each group of LoRA parameters is computed at the initial time, after forgetting, and after learning. Then, the absolute difference between the L2 norm after forgetting and the L2 norm after learning is calculated to represent the parameter changes induced by the forgetting process, which is shown by the red line.
    }
    \vspace{-5mm}
    \label{fig:l2norm-seg}
\end{figure*}
% Machine unlearning focuses on efficiently removing specific data or knowledge from a trained model without retraining it from scratch, making it highly relevant for data privacy compliance (e.g., GDPR). Methods in this area can be broadly categorized as follows:
% Fine-tuning exploits catastrophic forgetting by training the model on the retention dataset $D_{r}$, though it may leave residual traces of the forgotten set $D_{f}$. NegGrad+\cite{kurmanji2024towards} balances maximizing the loss on the forget set and minimizing the loss on the retention dataset, achieving a more controlled trade-off. SCRUB\cite{kurmanji2024towards} refines this idea by using contrastive learning, where a student model mimics a teacher on retained data while contrasting its behavior on $D_{f}$. Other methods, such as influence functions\cite{koh2017understanding}, estimate the impact of data points on model parameters, offering precise yet computationally lightweight data removal. Techniques such as L1-Sparse\cite{liu2024model} utilize $L_1$-regularization to zero out parameters associated with $D_{f}$, while relabeling methods, such as Saliency Unlearning\cite{feldman2020does}, disrupt the model's memory of $D{f}$ by altering its labels and focusing on critical parameters.

% Unlike traditional unlearning methods, which focus on data removal at the individual level, our proposed framework introduces a new task that enables category-level forgetting. This framework integrates learning, retention, and forgetting into a unified system, allowing for more flexible and controlled knowledge management.

% The final versions of papers accepted for publication should follow the
% same format and naming convention as initial submissions, except that
% author information (names and affiliations) should be given. See
% \cref{final author} for formatting instructions.
\section{Knowledge Swapping}

\subsection{Task Definition}
We introduce a novel task, referred to as \textbf{Knowledge Swapping}, which aims to selectively regulate a model's knowledge by employing specific swapping mechanisms to achieve three primary objectives: (1) forgetting user-specified knowledge, (2) retaining core knowledge, and (3) simultaneously learning new knowledge.

Let $\mathcal{D}_p = (X_p, Y_p)$ be the \textbf{pretraining dataset} on which an initial model $M_0$ has been trained. We define three additional sets:

\begin{itemize}
    % \setlength{\itemsep}{2pt}
    % \setlength{\parsep}{0pt}
    \setlength{\parskip}{3pt}
    \item \textbf{Retaining Set:} $\mathcal{D}_r = (X_r, Y_r)$, which contains the knowledge that must be preserved.
    \item \textbf{Forgetting Set:} $\mathcal{D}_f = (X_f, Y_f)$, containing the knowledge that the model needs to forget.
    \item \textbf{Learning Set:} $\mathcal{D}_l = (X_l, Y_l)$, comprising new knowledge to acquire.
\end{itemize}

In general, both $\mathcal{D}_r$ and $\mathcal{D}_f$ are subsets of the pretraining dataset $\mathcal{D}_p$, i.e., $\mathcal{D}_r, \mathcal{D}_f \subseteq \mathcal{D}_p$, while $\mathcal{D}_l$ could represent an entirely new task or domain.

\textbf{Objectives:} We seek to train an updated model $M_1$ such that:
\begin{enumerate}
    \setlength{\itemsep}{3pt}
    % \setlength{\parsep}{0pt}
    % \setlength{\parskip}{0pt}
    \item For each $x_r \in X_r$, $M_1$ \emph{correctly} predicts its label $y_r$. Formally, $P\bigl(M_1(x_r) = y_r\bigr) \approx 1, \quad \forall x_r \in X_r$. (Retention)
    \item For each $x_f \in X_f$, $M_1$ does \emph{not} correctly predict its label $y_f$. Formally,  $P\bigl(M_1(x_f) = y_f\bigr) \approx 0, \quad \forall x_f \in X_f$. (Forgetting)
    \item For each $x_l \in X_l$, $M_1$ \emph{correctly} predicts its label $y_l$. Formally, $P\bigl(M_1(x_l) = y_l\bigr) \approx 1, \quad \forall x_l \in X_l$ (Learning)
\end{enumerate}

Here, $P\bigl(\cdot\bigr)$ denotes the probability of the corresponding event under the trained model. The objectives are then to promote or discourage each of these criteria accordingly.
\begin{figure*}[tb]
    \centering
    \includegraphics[width=0.95\textwidth]{assets/overview.pdf}
    \vspace{-3mm}
    \caption{\small Benchmark Framework. First, we decouple knowledge swapping into separate learning and forgetting processes. We observed that the learning process progresses from low-level features to high-level features, while the forgetting process proceeds in the opposite direction—from high-level features to low-level features. Therefore, a two-stage strategy of \textit{Learning Before Forgetting} is adopted. In general, we adopt LoRA to fine-tune the linear layers in each Transformer block, with all other parameters frozen to enable selective regulation of the model knowledge.}
    \label{fig:overview}
\end{figure*}

\subsection{To Forget Before Learning, or to Learn Before Forgetting?}
Revisiting that we have already provided a comprehensive definition of the knowledge swapping task, we note that—based on its criteria—it can be naturally divided into two core phases: forgetting and learning. This highlights a pivotal question: should a model first forget certain existing knowledge before learning new information (which seems intuitively appealing), or should it learn new content first and then perform forgetting? The way we answer this sequence dilemma directly informs how we design a robust knowledge swapping benchmark. Although intuitively, forgetting old knowledge first appears to free up capacity for accommodating the new, is this really the optimal approach? To explore this, we conduct two sets of experiments on dense prediction tasks such as semantic segmentation, each corresponding to one of these two learning orders. We then examine how the neural network’s parameters, across various layers, evolve under each approach (see Figure~\ref{fig:l2norm-seg}).”

\textbf{Knock-on Feature Hierarchy}
In this section, we directly evaluate the weight norms and parameter differences at each stage of the process. Specifically, \(L \rightarrow F\) denotes  \textit{Learning  Before Forgetting}, while \(F \rightarrow L\) indicates  \textit{Learning After Forgetting}. The superscript \(W\) represents the weight norms at different stages under each sequence. We aggregate results from multiple image segmentation tasks and observe that when following the \(L \rightarrow F\) sequence, the majority of parameter updates occur in the latter layers of the neural network---those responsible for generating semantic-level features. Conversely, in the \(F \rightarrow L\) sequence, the principal changes are concentrated in the earlier layers, which produce low-level features. Based on these results, we found:

\textbf{Discovery-I:} \textit{Incremental learning typically progresses from low-level representations to higher-level semantic features, whereas forgetting tends to occur in the opposite direction—starting from high-level semantics and moving down to low-level features. }

\textbf{Remark.} What is the practical significance of this seemingly intuitive finding? Clearly, its hierarchical feature implications offer valuable insights for designing knowledge swapping strategies. Specifically, if we conduct targeted forgetting first, we may erase high-level semantic parameters before making any substantial adjustments to the low-level feature parameter space. However, once we subsequently introduce new content, further modifications to the low-level parameters can cause inconsistencies in the high-level semantics (breaking the forgetting pipeline owing to altering low-level parameters), potentially leading to conflicts. By contrast, if we begin by learning a new task (thereby updating the low-level parameters) and then perform targeted forgetting, the forgetting process is more likely confined to the high-level semantic parameters. %As a result, the newly updated low-level feature distribution remains relatively undisturbed, which helps to preserve the integrity of newly acquired knowledge.

\textbf{Principle: Learning Before Forgetting.} Recall that we demonstrate that initiating the forgetting process before learning disrupts the intended forgetting due to alterations in low-level feature learning. This raises the question: does conducting the learning process before forgetting similarly interfere with previously acquired knowledge? We also measure the average gradient changes across two primary sequences, \( L \rightarrow F \) and \( F \rightarrow L \), as shown in Figure~\ref{fig:grad-images}. The superscript $G$ means the log average gradient at the current stage. First, parameter changes during the learning phases (\( L^G \rightarrow F \) and \( F \rightarrow L^G \)) are consistently more significant, indicating that the \textit{Learning} process is relatively challenging; second, in the \( L \rightarrow F^G \) phase, the final updates to forgetting gradients remain consistently small, suggesting that \textit{Learning Before Forgetting} is more stable. %We finally arrive at our core conclusion of \textit{Learning Before Forgetting}.
%Our findings indicate that parameter changes during the \emph{learning} phase are consistently more substantial across all scenarios. In other words, the learning process remains relatively challenging regardless of the sequence. Conversely, in the \textit{Learning Before Forgetting} sequence, the \emph{forgetting} phase exhibits the smallest parameter shift, suggesting that forgetting is more effective in this arrangement.

%Based on the preceding experiments and analyses, we arrive at our core conclusion: \textit{Learning Before Forgetting}.We also measure the average gradient changes across two primary sequences, $L\rightarrow F$ and $F \rightarrow L$, examining four distinct conditions: $L^G\rightarrow F$, $L\rightarrow F^G$, $F^G \rightarrow L$ and $F \rightarrow L^G$. Our findings indicate that parameter changes during the \emph{learning} phase are consistently more substantial across all scenarios. However, in the ‘Learning Before Forgetting’ sequence, the \emph{forgetting} phase exhibits the smallest parameter shift.
% We introduce a novel task, referred to as \textbf{Knowledge Swapping}, which aims to selectively regulate a model's knowledge by employing specific exchange mechanisms to achieve three primary objectives: (1) forgetting user-specified knowledge, (2) retaining core knowledge, and (3) simultaneously learning new knowledge. The formal definition of the task is as follows:
% Let $\mathcal{D}_p = (X_p, Y_p)$ denote the pretraining dataset, where $X_p$ represents the input data and $Y_p$ denotes the corresponding labels (e.g., categories, bounding boxes, or ground truth masks). Assume that a model $M_0$ has been trained on this pretraining dataset. To adapt the model to new task requirements, we perform knowledge swapping. We define the following datasets:
% \begin{itemize}
%     \item \textbf{Pretraining Dataset} $\mathcal{D}_p = (X_p, Y_p)$ is the original dataset used to train the model $M$.
%     \item \textbf{Retaining Dataset} $\mathcal{D}_r = (X_r, Y_r)$ contains the knowledge that must be preserved to ensure stable performance on previously learned tasks.
%     \item \textbf{Forgetting Dataset} $\mathcal{D}_f = (X_f, Y_f)$ includes the knowledge that the model needs to forget in order to accommodate new task-specific knowledge.
%     \item \textbf{Learning Dataset} $\mathcal{D}_l = (X_l, Y_l)$ contains the new knowledge that the model must acquire to solve the new task.
% \end{itemize}
% Both $\mathcal{D}_r$ and $\mathcal{D}_f$ are subsets of the pretraining dataset $\mathcal{D}_p$, i.e., $\mathcal{D}_r, \mathcal{D}_f \subseteq \mathcal{D}_p$. Retraining the model on the entire dataset $\mathcal{D}_p$ is computationally infeasible due to resource limitations. Therefore, we require that $|\mathcal{D}_r| \ll |\mathcal{D}_p|$ and $|\mathcal{D}_f| \ll |\mathcal{D}_p|$, where $|\mathcal{D}_r|$ and $|\mathcal{D}_f|$ denote the number of samples in the respective datasets. This ensures the efficiency of the knowledge swapping process.
% We introduce a novel task, referred to as \textbf{Knowledge Swapping}, which aims to selectively regulate a model's knowledge by employing specific exchange mechanisms to achieve three primary objectives: (1) forgetting user-specified knowledge, (2) retaining core knowledge, and (3) simultaneously learning new knowledge. The formal definition of the task is as follows:
% Let us assume that a model $M$ has been trained on a pretraining dataset $D_p = (X_p, Y_p)$, where $X_p$ represents the input data and $Y_p$ corresponds to the associated labels, which may include categories, bounding boxes, or ground truth masks. Now, in order to adapt the model to new task requirements, we perform knowledge swapping. We define the following datasets:
% \begin{itemize}
%     \item $X$ represents the input data, and $Y$ represents the corresponding labels.
%     \item The pretraining dataset $D_p = (X_p, Y_p)$ denotes the original dataset on which model $M$ was initially trained.
%     \item The retaining dataset $D_r = (X_r, Y_r)$ consists of knowledge that needs to be preserved to ensure stable model performance on previously learned tasks.
%     \item The forgetting dataset $D_f = (X_f, Y_f)$ contains knowledge that the model must forget to accommodate new task-specific knowledge.
%     \item The learning dataset $D_l = (X_l, Y_l)$ includes the new knowledge that the model needs to acquire for the new task.
% \end{itemize}
% Both $D_r$ and $D_f$ are subsets of the original pretraining dataset $D_p$, i.e., $D_r, D_f \subseteq D_p$. Due to resource limitations and the computational cost associated with retraining from scratch, it is impractical to retrain the model on the entire $D_p$. Consequently, we impose the constraint that $|D_r| \ll |D_p|$ and $|D_f| \ll |D_p|$ to ensure the efficiency of the knowledge swapping process. Here, $|D_r|$ and $|D_f|$ represent the cardinalities (i.e., the number of samples) of the respective datasets, and the condition $|D_r| \ll |D_p|$ and $|D_f| \ll |D_p|$ ensures that the process remains computationally feasible and does not require retraining on the entire pretraining dataset $D_p$.
% We propose a novel task called Knowledge Swapping, aiming to selectively regulate model knowledge through specific exchange methods to achieve the following three goals: forgetting user-specified knowledge, retaining core knowledge, and simultaneously learning new knowledge. The formal definition is as follows:

% Assume that a model $M$ has been trained on a pretraining dataset $D_p=(X_p,Y_p).$ Now knowledge swapping needs to be performed to meet new task requirements. We define the following datasets:

% $X$ represents the data. $Y$ represents the labels, which could be categories,bounding boxes, or ground truth mask. Pretraining dataset $D_{p}=(X_{p},Y_{p})$ represents the original dataset on which the model $M$ was trained prior to the task. Retaining dataset $D_{r}=(X_{r},Y_{r})$ contains knowledge for which the model's performance needs to remain stable.Forgetting dataset $D_{f}=(X_{f},Y_{f})$ contains the knowledge that model need to forget.Learning dataset $D_{l}=(X_{l},Y_{l})$ contains knowledge that the model needs to newly acquire. $D_r$ and $D_f$ are subsets of $D_p$, i.e., $D_r, D_f \subseteq D_p$. Retraining all data from $D_p$ is almost impossible due to resource constraints and is computationally expensive. Therefore, we require that $|D_r| \ll |D_p|$ and $|D_f| \ll |D_p|$ to ensure the efficiency of the process.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.5\linewidth]{assets/模型架构.png}
%     \caption{The framework of our proposed model}
%     \label{fig:framework}
% \end{figure}

\begin{figure*}[!htb]
    \centering
     \includegraphics[width=0.87\linewidth]{assets/grid_combined_plot_0124.pdf}
    \vspace{-3mm}
    \caption{\small \textbf{Logarithm of the Average Gradient.} We compute the logarithm of cumulative average gradient changes at different stages in the \( L \rightarrow F \) and \( F \rightarrow L \) processes. %(The superscript \( G \) indicates that we utilize a logarithmic scale for ease of analysis, which does not affect the interpretation of the results.)%
    We observe two key phenomena: first, parameter changes during the learning phases (\( L^G \rightarrow F \) and \( F \rightarrow L^G \)) are consistently more significant, indicating that the \textit{Learning} process is relatively challenging; second, in the \( L \rightarrow F^G \) phase, the final updates to forgetting gradients remain consistently small, suggesting that \textit{Learning Before Forgetting} is more stable.
    % In the semantic segmentation task, we use MaskFormer as the pre-trained model. Subclasses of ADE20K are used as the retention set and forgetting set, while six classes from Pascol Voc, Oxford-lllT Pet and DeepGlobe Land are selected as the learning set. We employ two strategies: "learn first, then forget"(fltf) and "forget first, then learn"(fftl). Both learning and forgetting processes are trained for 7000 iters, and the average gradients are calculated accordingly.
    }
    \label{fig:grad-images}
    \vspace{-3mm}
\end{figure*}

%\section{why first learn then forget}
% \begin{figure*}[!htb]
%     \centering
%      \includegraphics[width=\linewidth]{assets/grid_combined_plot_0124.pdf}
 
%     \caption{\textbf{Logarithm of the Average Gradient.} In the semantic segmentation task, we use Mask2Former as the pre-trained model. Subclasses of ADE20K are used as the retention set and forgetting set, while six classes from VOC, Deep, and Oxford Pet datasets are selected as the learning set. We employ two strategies: "learn first, then forget"(fltf) and "forget first, then learn"(fftl) Both learning and forgetting processes are trained for 20 epochs, and the average gradients are calculated accordingly.}
%     \label{fig:grad-images}
% \end{figure*}



% \begin{figure*}[htp]
%     \centering
%     \subfigure[voc dataset]{
%         \includegraphics[width=0.3\linewidth]{assets/voc-grad.png}
%     }
%     \subfigure[sat dataset]{
%         \includegraphics[width=0.3\linewidth]{assets/sat-grad.png}
%     }
%     \subfigure[oxford pet dataset]{
%         \includegraphics[width=0.3\linewidth]{assets/pet-grad.png}
%     }
%     \caption{grad compare between fltf and fftl}
%     \label{fig:grad-images}
% \end{figure*}
% \vspace{-1cm} 
% \begin{figure*}[htp]
%     \centering
%     \subfigure[fltf on voc]{
%         \includegraphics[width=0.3\linewidth, trim=0mm 10mm 0mm 10mm, clip]{assets/fltf-voc-l2norm.png}
%     }
%     \subfigure[fltf on sat]{
%         \includegraphics[width=0.3\linewidth]{assets/fltf-sat-l2norm.png}
%     }
%     \subfigure[fltf on oxford pet]{
%         \includegraphics[width=0.3\linewidth]{assets/fltf-pet-l2norm.png}
%     }
%     \\
%     \subfigure[fftl on voc]{
%         \includegraphics[width=0.3\linewidth]{assets/fftl-voc.png}
%     }
%     \subfigure[fftl on sat]{
%         \includegraphics[width=0.3\linewidth]{assets/fftl-sat.png}
%     }
%     \subfigure[fftl on oxford pet]{
%         \includegraphics[width=0.3\linewidth]{assets/fftl-pet.png}
%     }
%     \caption{l2 norm compare between fltf and fftl}
%     \label{fig:l2norm-images}
% \end{figure*}

% \begin{figure*}[!htb]
%     \centering
%     \subfigure[fltf]{
%         \includegraphics[width=\linewidth, trim=0mm 0mm 0mm 0mm, clip]{assets/fltf-combine-l2nrom_0126.pdf}
%     }
%     \subfigure[fltf]{
%         \includegraphics[width=\linewidth]{assets/fftl-combine-l2nrom_0126.pdf}
%     }

%     \caption{l2 norm compare between fltf and fftl.}
%     \label{fig:l2norm-images}
% \end{figure*}



% To achieve our goal, we chose a two-stage training strategy of first learn then forget. This means that the model first learns new knowledge, then forgets the old knowledge. We base our analysis on two assumptions:

% 1.	Learning is relatively difficult, while forgetting is simpler. From  figure \ref{fig:grad-images}, we can observe that for the same number of training epochs, the average gradient changes during learning are much larger than those during forgetting.

% 2.	Learning focuses mainly on low-level and mid-level features (such as edges, textures, etc.), while forgetting primarily involves high-level semantic features. The parameters changes during learning are mainly concentrated in the earlier layers of the model, while the parameters changes during forgetting are focused on the later layers,as shown figure \ref{fig:l2norm-images}.

% Based on these assumptions, if the model forgets before learning, the parameters in the front layers of the network have already changed. As previous studies have shown, the lower layers of the model determine its ability to transfer. Because the parameters in the lower layers have already changed, the parameters involved in forgetting are less likely to adapt to the new model structure, leading to poor forgetting performance.
% In contrast, if the model learns first and then forgets, when it learns a new dataset, it needs to build new representations. This typically requires adjustments to the parameters from the input layer through the middle layers to capture new low-level features (such as edges, textures, etc.) and high-level features (such as object categories, semantic relationships, etc.). During this process, the model adapts to the changes in the lower and middle layers, making the subsequent forgetting process easier. Although, during the early stages of forgetting, the model might experience some interference, leading to a decline in performance for both the learning and retention sets, the stability of the lower and middle layer features allows the model to later fine-tune high-level features. As a result, the performance of both the learning and retention sets gradually recovers and reaches the desired state.
% This is the core reason behind our choice of the "first learn then forget" strategy.

\section{Benchmark}
\subsection{Overview}
As illustrated in Figure~\ref{fig:overview}, we employ the Low-Rank Adaptation (LoRA) technique~\cite{hu2021lora} to fine-tune the pretrained model \(M_0\) ( Sec.~\ref{sec:lora_ft}). Additionally, we leverage group sparse regularization to constrain the selective learning and forgetting of specific knowledge (Sec.~\ref{sec:spa_con}).
% As shown in Figure \ref{fig:framework}, we primarily employ the LoRA technique to fine-tune the pretrained model $M$ (details in Section 3.1). Additionally, we leverage group sparse regularization to constrain LoRA\cite{hu2021lora}, enabling selective forgetting of specific knowledge (details in Section 3.2).
%\subsection{LoRA-based Finetuning}
\subsection{LoRA-Based Fine-Tuning}\label{sec:lora_ft}

Building on the findings in ~\cite{geva2020transformer}, which demonstrate that the linear layers within Transformers encapsulate a substantial amount of the model's knowledge, we employ the Low-Rank Adaptation (LoRA) technique~\cite{hu2021lora} to fine-tune only these linear layers. Let \(\mX\) denote the input to the Feed-Forward Network (FFN) of the \(k\)-th Transformer block after the \(t\)-th gradient update. The weights and biases of the first linear layer are represented by \(\mW^t_{k1}\) and \(\vb^t_{k1}\), respectively, while those of the second linear layer are denoted by \(\mW^t_{k2}\) and \(\vb^t_{k2}\). The computation performed by the FFN can be expressed as:
\begin{equation}
\mathrm{FFN}_k^t(\mX) = \mathrm{ReLU}\left(\mX \mW_{k1}^t + \vb_{k1}^t\right) \mW_{k2}^t + \vb_{k2}^t.
\end{equation}
Using LoRA, the weights are decomposed into their original pretrained components and learnable low-rank adaptations:
\begin{equation}
\mW_{k1}^t = \mW_{k1}^0 + \Delta \mW_{k1}^t, \quad \Delta \mW_{k1}^t = \mA_{k1}^t \mB_{k1}^t.
\end{equation}
\begin{equation}
\mW_{k2}^t = \mW_{k2}^0 + \Delta \mW_{k2}^t, \quad \Delta \mW_{k2}^t = \mA_{k2}^t \mB_{k2}^t.
\end{equation}
In these equations, \(\mW_{k1}^0\) and \(\mW_{k2}^0\) represent the original pretrained weights, while \(\Delta \mW_{k1}^t\) and \(\Delta \mW_{k2}^t\) are the low-rank updates at time step \(t\), parameterized by the matrices \(\mA\) and \(\mB\). This approach ensures efficient adaptation by focusing solely on the linear layers of the Transformer, which are hypothesized to store the majority of the model's knowledge. Although the biases \(\vb_{k1}^t\) and \(\vb_{k2}^t\) may also be fine-tuned, they typically involve fewer parameters compared to the weights. By restricting updates to low-rank matrices, LoRA enables efficient fine-tuning with reduced computational and storage overhead while preserving the knowledge embedded in the original pretrained weights.

% According to finding in \cite{geva2020transformer}, the linear layers in Transformers contain a substantial amount of knowledge. Therefore, we decided to use LoRA to fine-tune only the linear layers of the Transformer.

% Assume that after the t-th gradient update, the input to the Feed-Forward Network (FFN) of the K-th Transformer block is denoted as $\mX$. The weight and bias of the first linear layer are represented as $\mW^t_{k1}$ and $\vb^t_{k1}$, respectively, while the weight and bias of the second linear layer are represented as $\mW^t_{k2}$ and $\vb^t_{k2}$.The overall computation of the FFN can be formulated as follows:
% \begin{equation}
% \mathrm{FFN}_k^t(\mX)=\mathrm{ReLU}(\mX\mW_{k1}^t+\evb_{k1}^t)\mW_{k2}^t+\vb_{k2}^t
% \end{equation}
% \begin{equation}
% \mW_{k1}^t=\mW_{k1}^0+\Delta \mW_{k1}^t,\Delta \mW_{k1}^t=\mA_{k1}^t\mB_{k1}^t
% \end{equation}
% \begin{equation}
% \mW_{k2}^t=\mW_{k2}^0+\Delta \mW_{k2}^t,\Delta \mW_{k2}^t=\mA_{k2}^t\mB_{k2}^t
% \end{equation}
% This approach ensures that the adaptation is efficient and focuses only on the linear layers of the Transformer, which are hypothesized to store the majority of the model's knowledge. The biases $b_{k1}^t$ and $b_{k2}^t$ may also be fine-tuned, but they typically involve fewer parameters compared to the weights.

% By restricting the updates to low-rank matrices, LoRA enables efficient fine-tuning with reduced computational and storage overhead while preserving the knowledge embedded in the original pre-trained weights.


\begin{table*}[!htb]
\setlength{\tabcolsep}{5pt}  
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{c|ccc|ccc|ccc|ccc}
\hline
\multirow{2}{*}{Stages} & \multicolumn{3}{c|}{Cub} & \multicolumn{3}{c|}{Resisc45} & \multicolumn{3}{c|}{Oxford-pet} & \multicolumn{3}{c}{Plantvillage} \\
\cline{2-13}
& $\text{Acc}_r$ $\uparrow$ & $\text{Acc}_l$ $\uparrow$ & $\text{Acc}_f$ $\downarrow$ &  $\text{Acc}_r$ $\uparrow$ & $\text{Acc}_l$ $\uparrow$ & $\text{Acc}_f$ $\downarrow$ &  $\text{Acc}_r$ $\uparrow$ & $\text{Acc}_l$ $\uparrow$ & $\text{Acc}_f$ $\downarrow$ &  $\text{Acc}_r$ $\uparrow$ & $\text{Acc}_l$ $\uparrow$ & $\text{Acc}_f$ $\downarrow$ \\
\hline
\multicolumn{13}{c}{\textit{Learning Set}: 5 classes, \textit{Forgetting Set}: 5 classes, \textit{Retaining Set}: 95 classes } \\
\hline
Start & 88.08 & 0 & 84.4 & 88.08 & 0.2 & 84.4 & 88.08 & 0.4 & 84.4 & 88.08 & 0 & 84.4 \\\cline{1-13}
$F$ & 86.63 & 0 & 0.4 & 86.63 & 0.4 & 0.4 & 86.63 & 0.4 & 0.4 & 86.63 & 0 & 0.4 \\
$F\rightarrow L$ & 86.94 & 94.04 & 80.8 & 87.62 & 99 & 70.8 & 88.48 & 93.6 & 77.2 & 88.06 & 99.13 & 74.8 \\
\cline{1-13}
$L$ & 86.67 & 94.04 & 82.44 & 87.93 & 98.8 & 82.0 & 87.83 & 94.4 & 82.8 & 87.97 & 99.56 & 82.4 \\

$L\xrightarrow{}F$ & 86.4 & 91.66 & 0 & 86.77 & 99.2 & 0 & 87.01 & 93.6 & 0 & 87.26 & 99.78 & 0 \\
\hline

\multicolumn{13}{c}{\textit{Learning Set}: 10 classes, \textit{Forgetting Set}: 10 classes, \textit{Retaining Set}: 90 classes } \\
\hline


Start & 87.75 & 0 & 89.2 & 87.75 & 0.1 & 89.2 & 87.75 & 1.8 & 89.2 & 87.75 & 0 & 89.2 \\\cline{1-13}
$F$ & 85.22 & 0 & 0 & 85.22 & 0.2 & 0 & 85.2 & 2 & 0 & 85.22 & 0 & 0 \\

$F\xrightarrow{}L$ & 86.84 & 96.27 & 82 & 87.2 & 98.7& 82 & 88 & 96 & 83 & 87.66 & 98.55 & 82.2 \\\cline{1-13}

$L$ & 85.06 & 95.03 & 83.6 & 86.84 & 98.9 & 84.4 & 87.0 & 95.8 & 85.2 & 87.35 & 98.86 & 85.4 \\
$L\rightarrow F$ & 84.68 & 93.78 & 0 & 85.97 & 98.7 & 0.6 & 86.22 & 95.2 & 0.2 & 85.48 & 98.65 & 0 \\
\hline


\end{tabular}}
%\vspace{-2mm}
\caption{\small \textbf{Image classification results on Imagenet100 under \textit{Learning Before Forgetting}}. $L$ and $F$ are short for \textit{Learning} and \textit{Forgetting}, respectively. $\text{Acc}_r$, $\text{Acc}_l$ and $\text{Acc}_f$ represent the accuracy of the retaining set, the learning set, and the forgetting set.
% $L$ represents the moment when the learning process ends. $L\xrightarrow{}F$ represents the moment when "first learn then forget" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the accuracy of retaining set, learning set and forgetting set.
% The learning set consists of 5 or 10 classes selected from the four datasets in the table, the forgetting set
% contains 5 or 10 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
}
%\vspace{-4mm}
\label{tab:classification_lbf}
\end{table*}

\subsection{Sparse Constriant}\label{sec:spa_con}
We employ Group Coefficient Regularization to selectively retain specific knowledge within the Feed-Forward Network (FFN) modules. Specifically, we adopt the Lasso strategy ~\cite{liu2015sparse, wen2016learning, yuan2006model} for group sparse regularization. Lasso achieves the selective retention of knowledge by zeroing out the $A$ and $B$ matrices of irrelevant FFN modules within LoRA, thereby enabling targeted learning and forgetting.
The Lasso regularization loss $\mathcal{L}_{\text{re}}$is defined as: 
\begin{equation}
\mathcal{L}_\mathrm{re} = \sum_{k=1}^n \left( \|\mA_k\|_F^2 + \|\mB_k\|_F^2 \right),
\end{equation}
% \begin{equation} \mathcal{L}_\mathrm{re} = \sum{k=1}^n \left( |\mA_k|_F^2 + |\mB_k|_F^2 \right) \end{equation} 
where 
$\|\cdot\|_F$ denotes the Frobenius norm, calculated as the square root of the sum of the squared elements of a matrix, and $n$ represents the number of FFN groups.

\textbf{Remark.} Sparse constraints enhance parameter efficiency by limiting non-zero parameters, reducing computational and storage overhead, and accelerating inference. In knowledge swapping tasks, they enable the selective retention of crucial parameters for the current task while suppressing redundant ones, thereby preventing conflicts between new and existing knowledge. Additionally, parameter sparsification mitigates interference from irrelevant variables during learning and forgetting (similar idea in model pruning), allowing the model to focus on important information. Specifically, Lasso regularization penalizes the Frobenius norms of matrices, promoting group sparsification that selectively retains and forgets at the module level and maintains stability in low-level feature parameters when introducing new knowledge. Consequently, the model preserves new knowledge while maintaining the stability of existing representations. Overall, sparse constraints effectively manage parameters in knowledge swapping, enabling efficient adaptation to new tasks and maintaining previously acquired knowledge, thereby supporting scalable continual learning.
% %Sparse constraints improve parameter efficiency by limiting the number of non-zero parameters. 
% This reduction not only decreases computational and storage overhead but also accelerates model inference. Secondly, within the knowledge swapping task, sparse constraints facilitate the selective retention of parameters that are crucial for the current task while suppressing or "forgetting" redundant parameters unrelated to it. This selective mechanism prevents conflicts and interference between new and existing knowledge. Moreover, parameter sparsification helps mitigate the interference of irrelevant variables during the learning and forgetting processes. By restricting the update and retention of non-essential parameters, the model can focus more effectively on learning important knowledge. 
% %This selective focus improves the stability and effectiveness of continual learning by suppressing information that is not pertinent to the current task, thereby maintaining the integrity of newly acquired knowledge.
% Specifically, Lasso regularization penalizes the Frobenius norms of the matrices, encouraging most of their elements to approach zero. This group sparsification not only achieves selective retention and forgetting at the module level but also ensures that the low-level feature parameter space remains stable when new knowledge is introduced. Consequently, the model preserves the new knowledge while maintaining the stability of existing representations. In summary, Sparse constraint provides an effective mechanism for managing parameters within knowledge swapping. It ensures that the model can adapt to new tasks efficiently while maintaining the stability of previously acquired knowledge. This mechanism plays a critical role in achieving efficient and scalable continual learning.


% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c|}{resisc45} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% \cline{2-13}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% \hline
% Start & 87.75 & 0 & 89.2 & 87.75 & 0.1 & 89.2 & 87.75 & 1.8 & 89.2 & 87.75 & 0 & 89.2 \\
% $F$ & 85.22 & 0 & 0 & 85.22 & 0.2 & 0 & 85.2 & 2 & 0 & 85.22 & 0 & 0 \\
% $F\xrightarrow{}L$ & 86.84 & 96.27 & 82 & 87.2 & 98.7& 82 & 88 & 96 & 83 & 87.66 & 98.55 & 82.2 \\
% \hline
% \end{tabular}
% \caption{\textbf{First Forget then Learn on Imagenet100 for image classification.} $F$ represents the moment when the learning process ends. $F\xrightarrow{}L$ represents the moment when "first forget then learn" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the accuracy of retaining set, learning set and forgetting set.
% The learning set consists of 10 classes selected from the four datasets in the table, the forgetting set
% contains 10 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
% }
% \label{classification-10-fftl}
% \end{table*}

% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c}{cub} & \multicolumn{3}{c}{resisc45} & \multicolumn{3}{c}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% \cline{2-13}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% \hline
% Start & 87.75 & 0 & 89.2 & 87.75 & 0.1 & 89.2 & 87.75 & 1.8 & 89.2 & 87.75 & 0 & 89.2 \\
% $L$ & 85.06 & 95.03 & 83.6 & 86.84 & 98.9 & 84.4 & 87.0 & 95.8 & 85.2 & 87.35 & 98.86 & 85.4 \\
% $L\xrightarrow{}F$ & 84.68 & 93.78 & 0 & 85.97 & 98.7 & 0.6 & 86.22 & 95.2 & 0.2 & 85.48 & 98.65 & 0 \\
% \hline
% \end{tabular}
% \caption{\textbf{First Learn and Forget on Imagenet100 for image classification with 10 classes.} The learning set consists of 10 classes selected from the four datasets in the table, the forgetting set contains 10 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
% }
% \label{classification-10}
% \end{table*}

% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c|}{resisc45} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% \cline{2-13}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% Your new row & 88.08 & 0 & 84.4 & 88.08 & 0.2 & 84.4 & 88.08 & 0.4 & 84.4 & 88.08 & 0 & 84.4 \\
% \hline
% Start & 88.08 & 0 & 84.4 & 88.08 & 0.2 & 84.4 & 88.08 & 0.4 & 84.4 & 88.08 & 0 & 84.4 \\
% $L$ & 86.67 & 94.04 & 82.44 & 87.93 & 98.8 & 82.0 & 87.83 & 94.4 & 82.8 & 87.97 & 99.56 & 82.4 \\
% $L\xrightarrow{}F$ & 86.4 & 91.66 & 0 & 86.77 & 99.2 & 0 & 87.01 & 93.6 & 0 & 87.26 & 99.78 & 0 \\
% \hline
% \end{tabular}
% \end{table*}

% We employ group coefficient regularization to select FFN blocks containing specific knowledge. Specifically, we adopt the Lasso strategy \cite{liu2015sparse,wen2016learning,yuan2006model} for group sparse regularization. Lasso achieves the selection of specific knowledge by zeroing out the $A$ and $B$ matrices of irrelevant FFN blocks in LoRA.
% The total loss function is defined as:
% \begin{equation}
% \mathcal{L}_{\text{total}}= \mathcal{L}_\mathrm{data}+\alpha.\mathcal{L}_\mathrm{re}
% \end{equation}
% $\mathcal{L}_\mathrm{all}$ is the overall loss function. $\mathcal{L}_\mathrm{data}$ is the loss function for the original data. $\mathcal{L}_\mathrm{re}$ is the lasso regularization loss function. $\alpha$ is a hyperparameter that controls the trade-off between the data loss and the regularization term.

% The Lasso regularization loss $\mathcal{L}_\mathrm{re}$ is defined as:
% \begin{equation}
% \mathcal{L}_\mathrm{re}=\sum_{k=1}^n\left(\|\emA_k\|_F^2+\|\emB_k\|_F^2\right)
% \end{equation}
% $\|.\|_F $ denotes the Frobenius norm, which is the square root of the sum of the squared elements of the matrix.$n$ denotes the number of FFN group.

% This group-based regularization encourages sparsity at the block level by applying the Frobenius norm to the entire $A_k$ and $B_k$ 
%   matrices within each FFN block. By penalizing the magnitude of these matrices, irrelevant FFN blocks are effectively "zeroed out", allowing the model to selectively retain only the FFN blocks relevant to specific knowledge.

\subsection{Training and Inference Protocol}
In the \textbf{learning phase}, the objective is for the model to acquire new knowledge while retaining essential existing knowledge. Accordingly, the loss function for this phase is defined as follows.
\begin{equation}
\mathcal{L}_{\mathrm{retain}} = \mathcal{L}(f(\mX_{r}), \mY_{r}),
\end{equation}
\begin{equation}
\mathcal{L}_{\mathrm{learn}} = \mathcal{L}(f(\mX_{l}), \mY_{l}),
\end{equation}
\begin{equation}
\mathcal{L}_{\mathrm{all}} = \mathcal{L}_{\mathrm{retain}} + \beta \mathcal{L}_{\mathrm{learn}} + \alpha \mathcal{L}_{\mathrm{re}},
\end{equation}
where $(\mX_r, \mY_r)$ denotes the data from the retention set, $(\mX_l, \mY_l)$ denotes the data from the learning set, and $\alpha$ and $\beta$ are hyperparameters that balance the contributions of the different loss components.

In the \textbf{forgetting phase}, the goal is to eliminate specific knowledge while retaining both the original and newly acquired knowledge. This involves minimizing $\mathcal{L}(f(\mX_r), \mY_r)$ and $\mathcal{L}(f(\mX_l), \mY_l)$, while maximizing $\mathcal{L}(f(\mX_f), \mY_f)$. However, directly maximizing the negative loss (i.e., minimizing $-\mathcal{L}(f(\mX_f), \mY_f)$) can result in unbounded loss growth, leading to optimization instability. To address this issue, we introduce a boundary constraint (BND) to stabilize the loss. The final loss function for the forgetting phase is defined as:
\begin{equation}
\mathcal{L}_{\mathrm{forget}} = \mathrm{ReLU}(\mathrm{BND} - \mathcal{L}(f(\mX_f), \mY_f)),
\end{equation}
\begin{equation}
\mathcal{L}_{\mathrm{all}} = \mathcal{L}_{\mathrm{retain}} + \mathcal{L}_{\mathrm{learn}} + \beta \mathcal{L}_{\mathrm{forget}} + \alpha \mathcal{L}_{\mathrm{re}},
\end{equation}
where BND defines the forgetting boundary, and $(\mX_f, \mY_f)$ represents the data from the forgetting set.

% In the learning phase, we aim for the model to learn new knowledge while retaining the knowledge it needs to remember. Therefore, the loss function for the learning phase is defined as:
% \begin{equation}
% \mathcal{L}_{\mathrm{retain}}=\mathcal{L}(f(\mX_{r}),\mY_{r})
% \end{equation}
% \begin{equation}
% \mathcal{L}_{\mathrm{learn}}=\mathrm{\mathcal{L}}(f(\mX_l),\mY_l)
% \end{equation}
% \begin{equation}
% \mathcal{L}_\mathrm{all}=\mathcal{L}_\mathrm{retain}+\beta\mathcal{L}_{\mathrm{learn}}+\alpha\mathcal{L}_\mathrm{re}
% \end{equation}
% where $(\mX_r,\mY_r)$ represents the data from the retention set, $(\mX_l,\mY_l)$ represents the data from the learning set, $\alpha$ and $\beta$ are hyperparameters that control the weights of different losses.

% In the forgetting phase, we aim for the model to forget specific knowledge while retaining both the old knowledge it was designed to remember and the new knowledge it recently learned. This requires minimizing $\mathcal{L}(f(\mX_r),\mY_r)$ and $\mathcal{L}( f( \mX_l),\mY_l)$, while maximizing $\mathcal{L}(f(\mX_f),\mY_f)$. However, directly maximizing the negative loss (i.e.,minimizing$-\mathcal{L}(f(\mX_f),\mY_f))$ can lead to unbounded loss growth, making optimization unstable. To address this, we introduce a boundary constraint BND to stabilize the loss.

% The final loss function for the forgetting phase is defined as:
% \begin{equation}
% \mathcal{L}_{\mathrm{forget}}=\mathrm{ReLU}(\mathrm{BND}-\mathcal{L}(f(\mX_f),\mY_f))
% \end{equation}
% \begin{equation}
% \mathcal{L}_{\mathrm{all}}=\mathcal{L}_{\mathrm{retain}}+\mathcal{L}_{\mathrm{learn}}+\beta\mathcal{L}_{\mathrm{forget}}+\alpha\mathcal{L}_{\mathrm{re}}
% \end{equation}

% % where BND defines the forgetting boundary,$(\mX_{forget},\mY_{forget})$ represents the data from the forgetting set;
% % where BND defines the forgetting boundary, \newline
% % $(X_{forget}, Y_{forget})$ represents the data from the forgetting set;

% where BND defines the forgetting boundary, $(\mX_f,\mY_f)$ represents the data from the forgetting set;


% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c|}{resisc45} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% \cline{2-13}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% \hline
% Start & 88.08 & 0 & 84.4 & 88.08 & 0.2 & 84.4 & 88.08 & 0.4 & 84.4 & 88.08 & 0 & 84.4 \\
% $L$ & 86.67 & 94.04 & 82.44 & 87.93 & 98.8 & 82.0 & 87.83 & 94.4 & 82.8 & 87.97 & 99.56 & 82.4 \\
% $L\xrightarrow{}F$ & 86.4 & 91.66 & 0 & 86.77 & 99.2 & 0 & 87.01 & 93.6 & 0 & 87.26 & 99.78 & 0 \\
% \hline
% \end{tabular}
% \caption{\textbf{First Learn and Forget on Imagenet100 for image classification with 5 classes.} $L$ represents the moment when the learning process ends. $L\xrightarrow{}F$ represents the moment when "first learn then forget" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the accuracy of retaining set, learning set and forgetting set.
% The learning set consists of 5 classes selected from the four datasets in the table, the forgetting set
% contains 5 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
% }
% \label{classificaiton-5}
% \end{table*}

\section{Experiments}\label{sec:exp}
%\label{submission}

\subsection{Experimental Setup}
All experiments are conducted on a hardware setup comprising 2×RTX 4090 GPUs, with the software environment configured as Python 3.12, PyTorch 2.5.1, and CUDA 12.4. The AdamW optimizer is employed for all training and forgetting phases. 
%Notably, the number of images in both the forgetting set and the retaining set is smaller than that of the original dataset, ensuring efficient and targeted knowledge manipulation.

For \textbf{image classification} tasks, the learning set includes: CUB-200-2011~\cite{wah2011caltech}, Oxford-IIIT Pet~\cite{parkhi2012cats}, RESISC45~\cite{cheng2017remote} and PlantVillage~\cite{geetharamani2019identification}. Both the retention set and the forgetting set are selected from ImageNet-100. During the training phase, the hyperparameters are set to $\alpha=0.05$ and $\beta=0.2$, while $\text{BND} = 105$ in the forgetting phase. The classification performance is evaluated using accuracy as the primary metric. 

For \textbf{object detection} tasks, the learning set consists of CUB-200-2011 and Stanford Dogs~\cite{dataset2011novel}. Both the retention set and the forgetting set are sourced from the COCO~\cite{lin2014microsoft} dataset. The learning phase employs 
$\alpha=0.01$ and $\beta=0.9$, while the forgetting phase uses $\text{BND} = 15$, 
$\alpha=0.01$, and $\beta=0.2$. The detection capability is assessed using the mean Average Precision (mAP) metric. 

For \textbf{semantic segmentation} tasks, the learning set includes: Pascal VOC~\cite{hoiem2009pascal}, COCO, Oxford-IIIT Pet~\cite{parkhi2012cats}, and DeepGlobe Land~\cite{demir2018deepglobe}. These datasets cover a diverse range of segmentation domains. The learning phase is configured with $\alpha=0.01$ and $\beta=0.9$ while the forgetting phase is set to $\text{BND} = 115$, 
$\alpha=0.01$, and $\beta=0.2$. The segmentation accuracy is evaluated using the mean Intersection over Union (mIoU) metric.

% All experiments were conducted on 2*RTX 4090,with the software environment configured as Python 3.12, PyTorch 2.5.1, and CUDA 12.4, using AdamW as the optimizer. The number of images in both the forgotten and retained sets is significantly smaller than that of the original dataset.

% For image classification, the learning set consists of CUB-200-2011\cite{wah2011caltech}, Oxford-IIIT Pet\cite{parkhi2012cats}, RESISC45\cite{cheng2017remote}, and PlantVillage\cite{geetharamani2019identification}., while both the retention set and the forgetting set are selected from ImageNet-100. The learning phase adopts  $\alpha= 0.05$ and $\beta=0.2$ , while the forgetting phase is set to BND = 105,$\alpha= 0.05$, and $\beta=0.2$. Classification performance is evaluated using accuracy.

% For object detection, the learning set includes CUB-200-2011 and Stanford Dogs, with both the retention set and the forgetting set sourced from COCO. The learning phase uses$\alpha= 0.01$ and $\beta=0.9$, while the forgetting phase adopts BND = 15, $\alpha= 0.01$, and $\beta=0.2$. The model’s detection ability is assessed using mAP.

% For semantic segmentation, the learning set comprises Pascal VOC, COCO, Oxford-IIIT Pet, and DeepGlobe Land, covering various segmentation domains. The learning phase is configured with $\alpha= 0.01$ and $\beta=0.9$,, while the forgetting phase is set to BND = 115,$\alpha= 0.01$, and $\beta=0.2$. The model’s segmentation accuracy is evaluated using mIoU.

\begin{figure*}[!htb]
    \centering
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/forget_remain_S/ade_1155_drawio.png}
    }\hspace{-0.5em}
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/forget_remain_L/ade_1155_drawio.png}
    }\hspace{-0.5em}
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/forget_remain_LF/ade_1155_drawio.png}
    }
    
    \vspace{-0.1em}
    {\small \textbf{The forgotten classes are \textit{lamp} and \textit{scope}. The learned class is \textit{cow}. The retained classes are all remaining classes. }\par}
    \vspace{-0.1em}
    
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/voclearn_S/2011_2885_drawio.png}
    }\hspace{-0.5em}
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/voclearn_L/2011_2885_drawio.png}
    }\hspace{-0.5em}
    \subfigure{
        \includegraphics[width=0.31\linewidth]{visual/voclearn_LF/2011_2885_drawio.png}
    }
    
    \vspace{0em}
    \makebox[\linewidth]{
        \makebox[0.31\linewidth]{Pretrained }
        \makebox[0.31\linewidth]{Learning}
        \makebox[0.31\linewidth]{Forgetting After Learning}
    }
    \vspace{-2em} % 减小 caption 和图像之间的间距
    \caption{\small \textbf{Qualitative results on semantic segmentation.} The forgotten classes are marked with \textcolor{red}{red dotted lines}, and the learned class is marked with \textcolor{darkgreen}{dark green dotted lines}. 
    %Fltf represents the results obtained from the model inference after the process of first learn then forget.
    }
    \label{fig:vis_seg_lbf}
\end{figure*}


\begin{table*}[!htb]
\setlength{\tabcolsep}{5pt}  % 减小列间距
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{c|ccc|ccc|ccc|ccc}
\hline
\multirow{2}{*}{procedure} & \multicolumn{3}{c|}{VOC} & \multicolumn{3}{c|}{Oxford-pet} & \multicolumn{3}{c|}{COCO} & \multicolumn{3}{c}{Deepglobe Land} \\
\cline{2-13}
 & $\text{mIoU}_r$ $\uparrow$ & $\text{mIoU}_l$ $\uparrow$ & $\text{mIoU}_f$ $\downarrow$ &  $\text{mIoU}_r$ $\uparrow$ & $\text{mIoU}_l$ $\uparrow$ & $\text{mIoU}_f$ $\downarrow$ &  $\text{mIoU}_r$ $\uparrow$ & $\text{mIoU}_l$ $\uparrow$ & $\text{mIoU}_f$ $\downarrow$ &  $\text{mIoU}_r$ $\uparrow$ & $\text{mIoU}_l$ $\uparrow$ & $\text{mIoU}_f$ $\downarrow$ \\
\hline
Start & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 \\\cline{1-13}
$F$ & 50.36 & 0 & 2.26 & 50.61 & 0 & 3.48 & 50.24 & 0 & 2.41 & 50.66 & 0 & 3.65 \\
$F\xrightarrow{}L$ & 50.7 & 85.45 & 49.42 & 50.28 & 59.45 & 53.67 & 51.03 & 90.87 & 54.47 & 50.38 & 54.33 & 60.25 \\
$F\xrightarrow{}L\xrightarrow{}F$&50.98&88.07&0.15&50.17&61.85&0.33&50.64&94.64&0.39&50.87&63.86&0.27\\
\cline{1-13}
$L$ & 50.2 & 84.97 & 60.67 & 48.92 & 62.21 & 65.5 & 50.54 & 93.46 & 61.85 & 50.96 & 59.8 & 64.61
 \\
$L\xrightarrow{}F$ & 50.57 & 85.43 & 0.12 & 49.87 & 69.55 & 0.08 & 50.35 & 93.36 & 0.71 & 49.54 & 58.34 & 0.4
 \\
 $L\xrightarrow{}F \xrightarrow{}L$ & 50.5 & 95.83 & 45.51 & 50.97 & 86.98 & 53.87 & 50.41 & 97.27 & 50.03 & 50.54 & 69.18 & 57.25
 \\
\hline
\end{tabular}
}
\vspace{-3mm}
\caption{\textbf{Semantic segmentation results on four datasets.} For each dataset, the learning set and forgetting set include randomly selected 5 classes. The retaining set includes all other classes from ADE20K.
%$L$represents the moment when the learning process ends. $L\xrightarrow{}F$ represents the moment when “first learn then forget” process ends. $Acc_r$, $Acc_l$, and $Acc_f$ represent the mIoU of the retaining set, learning set, and forgetting set, respectively. The learning set consists of 6 classes selected from the four datasets in the table, the forgetting set contains 6 classes selected from ADE20K, and the retaining set includes all other classes from ADE20K.
}%标题
\label{tab:seg-lbf}
\vspace{-5mm}
\end{table*}

\subsection{Classification Results}
% For the image classification task, we select the VIT-B16 model pre-trained on ImageNet as the base model. We randomly chose 5, 10, 20, and 40 classes from ImageNet100 as the forgetting set and use the remaining classes as the retention set. Additionally, for each forgetting set (5, 10, 20, 40 classes), we randomly select the learning set from CUB-200-2011, Oxford-IIIT Pet, RESISC45, and PlantVillage. 
% Specifically, CUB-200-2011 is a fine-grained bird species dataset, Oxford-IIIT Pet is a fine-grained cat and dog dataset, RESISC45 is a satellite image dataset, and PlantVillage is a dataset of crop disease images.Our dataset includes both in-domain and cross-domain data.

We use VIT-B16 model pretrained on ImageNet100 as the base model.
As shown in Table~\ref{tab:classification_lbf}, under the \textit{Learning Before Forgetting} setting, the accuracy of the learning set consistently increases from approximately 0\% to over 90\%, demonstrating effective knowledge acquisition. Concurrently, the forgetting phase appears to be more straightforward, as the accuracy of the forgetting set decreases from approximately 80\% to 0\%, indicating successful forgetting. Besides, the retaining set can also be well preserved even though there exist limited negative impacts on the whole phase. We further evaluate the reverse order (\textit{Learning After Forgetting}) in the same setting. We observe that although the accuracy of the forgetting set initially drops significantly during the forgetting phase, the subsequent learning phase induces substantial changes in the model’s lower-level parameters. This renders the previously forgotten higher-level parameters ineffective, resulting in an increase in the accuracy of the forgetting set during the later stages. These findings confirm the validity of our hypothesis.
% regardless of the number of categories, the accuracy of the learning set consistently increases from around 0\% to over 90\%, while the accuracy of the forgetting set drops from approximately 80\% to 0\%. Meanwhile, the accuracy loss for the retention set remains below 3\%. Moreover, since these datasets span multiple domains, including fine-grained datasets and satellite imagery datasets, these results strongly validate the effectiveness of our learn-then-forget strategy.
% Using the same set of parameters, the results of the forget-then-learn strategy are presented in Table \ref{classification-10-fftl}. It can be observed that although the accuracy of the forgetting set initially drops significantly during the forgetting phase. The subsequent learning phase induces substantial changes in the model’s lower-level parameters, rendering the previously forgotten higher-level parameters ineffective. As a result, the accuracy of the forgetting set rises again in the later stages, which confirms the correctness of our hypothesis.


% the effectiveness of knowledge transfer across these datasets demonstrates the robustness of our approach. The results in table \ref{classificaiton-5},\ref{classification-10} highlight the superior performance of our method in handling diverse datasets and facilitating effective knowledge swapping.
% Results of 20 and 40 classes is in appendix \ref{image classification}.
\begin{figure*}[!htp]
    \centering
    \includegraphics[width=0.88\textwidth, trim=0mm 0mm 0mm 0mm, clip]{assets/combined_plots_0126.pdf}
    \vspace{-5mm}
    \caption{$\mathcal{L}_2$ norm of weights in $F\rightarrow L \rightarrow F$}
    %\caption{\textbf{\mathcal{L}} norm of $F\rightarrow L \rightarrow F$}.
    \label{fig:seg_flf_l2}
    \vspace{-.2in}
\end{figure*}

\subsection{Semantic Segmentation Results}
% L
% For the semantic segmentation task, we selected the pretrained Mask2Former\cite{cheng2021per} model on ADE20K\cite{zhou2017scene} as the pretraining model. The forgotten set consists of 6 randomly chosen classes from ADE20K, while the retained set includes all the remaining classees.We selected 6 classes from the COCO\cite{lin2014microsoft},Oxford-IIIT Pet\cite{parkhi2012cats}, Pascal Voc\cite{hoiem2009pascal} or DeepGlobe Land dataset \cite{demir2018deepglobe} as the learning set.
% For the semantic segmentation task, we utilize the MaskFormer model pretrained on ADE20K. The forgetting set consisted of six randomly selected classes from ADE20K: \textit{lamp}, \textit{mountain}, \textit{fenc}, \textit{sink}, \textit{flower}, and \textit{sconc}, while the retained set included all remaining classes. The learning set comprises six classes for every different dataset: COCO (cow, elephant, bear, zebra, giraffe), Pascal VOC (bird, cat, cow, dog, horse, sheep), Oxford-IIIT Pet (Abyssinian, American Bulldog, American Pit Bull Terrier, Basset Hound, Beagle, Bengal), and all six classes from DeepGlobe Land (urban land, agriculture land, rangeland, forest land, water, barren land). %This diverse selection ensures a comprehensive evaluation of the knowledge exchange framework across multiple domains, including objects, fine-grained species, and geospatial segmentation.
 We select the pretrained Mask2Former\cite{cheng2021per} model on ADE20K as the pretraining model. 
 %The forgotten set consists of 6 randomly chosen classes from ADE20K, while the retained set includes all the remaining classes. We selected 6 classes from the corresponding learning set in Section 5.1.
The results in Table~\ref{tab:seg-lbf} demonstrate that under the \textit{Learning Before Forgetting} strategy, the mIoU of the retention set remains stable, ensuring effective memory retention. In contrast, the mIoU of the forgetting set decreases from 68.31\% to nearly 0\%, indicating complete forgetting. Concurrently, the learning set achieves a high mIoU, confirming successful knowledge acquisition. Figure~\ref{fig:vis_seg_lbf} further illustrates this process, where the classes \textit{lamp} and \textit{sconce} are successfully forgotten and blended into the wall, while the learned class \textit{cow} remains well retained even after the forgetting phase.
% The qualitative results in Table \ref{segment-fltf} show that under the learn-then-forget strategy, the mIoU of the retention set remains stable, ensuring good memory retention, while the mIoU of the forgetting set drops from 68.31\% to nearly 0\%, indicating complete forgetting. Meanwhile, the learning set achieves a high mIoU, confirming effective knowledge acquisition. Figure \ref{fig:visual forget and retain for fltf on semantic segmentation} further illustrates this process, where lamp and sconce are successfully forgotten and blended into wall, while the learned class cow is well retained even after the forgetting phase.
In contrast, under the \textit{Learning After Forgetting} setting (Table~\ref{tab:seg-lbf}), although both the retention and learning sets perform well, the mIoU of the forgetting set increases after learning due to significant changes in low-level parameters, rendering previously tuned high-level forgetting parameters ineffective. Figure~\ref{fig:vis_seg_laf} highlights this issue, showing that \textit{mountain}, which is initially erased and blended into \textit{sand}, re-emerges after learning, demonstrating the instability of this approach.

% Expriment result is as table \ref{segment-fltf}. Visualization is showen in figure \ref{fig:visual forget and retain for fltf on semantic segmentation}.

% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  % 减小列间距
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{voc} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c|}{coco} & \multicolumn{3}{c}{sat} \\
% \cline{2-13}
%  & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% \hline
% Start & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 & 50.51 & 0 & 68.31 \\
% $F$ & 50.36 & 0 & 2.26 & 50.61 & 0 & 3.48 & 50.24 & 0 & 2.41 & 50.66 & 0 & 3.65 \\
% $F\xrightarrow{}L$ & 50.7 & 85.45 & 49.42 & 50.28 & 59.45 & 53.67 & 51.03 & 90.87 & 54.47 & 50.38 & 54.33 & 60.25 \\
% \hline
% \end{tabular}
% \caption{\textbf{First Forget and Learn for semantic segmentation.} $F$ represents the moment when the forgetting process ends. $F\xrightarrow{}L$ represents the moment when "first forget then learn" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the mIoU of retaining set, learning set and forgetting set. The learning set consists of 6 classes selected from the four datasets in the table, the forgetting set contains 6 classes selected from ADE20K, and the retaining set includes all other classes from ADE20K.}
% \label{segmentation-fftl}
% \end{table*}

% \subsection{ablation study}
\subsection{Object Detection Results}
\begin{table}[!htb]
\resizebox{0.5\textwidth}{!}{
% \setlength{\tabcolsep}{1pt}  
\centering
\vspace{-3mm}
\begin{tabular}{c|ccc|ccc}
\hline
\multirow{2}{*}{procedure} & \multicolumn{3}{c|}{Cub} & \multicolumn{3}{c}{Oxford-dog} \\
\cline{2-7}
& $\text{mAP}_r$ $\uparrow$ & $\text{mAP}_l$ $\uparrow$ & $\text{mAP}_f$ $\downarrow$ &  $\text{mAP}_r$ $\uparrow$ & $\text{mAP}_l$ $\uparrow$ & $\text{mAP}_f$ $\downarrow$   \\
\hline
Start & 55.4 & 0 & 44.5 & 55.4 & 0 & 44.5  \\ \cline{1-7}

$F$ & 54.9 & 16.8 & 3.4 & 54.8 & 9.7 & 3.4  \\
$F\xrightarrow{}L$ & 55 & 65.4 & 7.7 & 54.6 & 78.5 & 11.1  \\\cline{1-7}

$L$ & 55.3 & 64.3 & 37.6 & 54.5 & 67.5 & 37.5  \\
$L\xrightarrow{}F$ & 55.5 & 62.2 & 0.5 & 55 & 80.1 & 0.6  \\
\hline
\end{tabular}
}
\vspace{-3mm}
\caption{\small Object Detection Results on COCO.
%\vspace{-5mm}
%$L$ represents the moment when the learning process ends. $L\xrightarrow{}F$ represents the moment when "first learn then forget" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the mAP of retaining set, learning set and forgetting set.
%The learning set consists of 5 classes selected from the two datasets in the table, the forgetting set
%contains 5 classes selected from COCO, and the retaining set includes all other classes from COCO.
}
\vspace{-3mm}
\label{tab:obj_lbf}
\end{table}

% \begin{figure}[!htb]
%     \centering
%     \subfigure{
%         \includegraphics[width=0.32\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_forget_S/170278.png}
%     }\hspace{-1em}
%     \subfigure{
%         \includegraphics[width=0.32\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_forget_L/170278.png}
%     }\hspace{-1em}
%     \subfigure{
%         \includegraphics[width=0.32\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_forget_LF/170278.png}
%     }
%     %\vspace{-5em}
%     \subfigure{
%         \includegraphics[width=0.3\linewidth,trim=20mm 10mm 20mm 10mm, clip]{visual/cub_forget_S/200421.png}
%     }\hspace{-0.5em}
%     \subfigure{
%         \includegraphics[width=0.3\linewidth,trim=20mm 10mm 20mm 10mm, clip]{visual/cub_forget_L/200421.png}
%     }\hspace{-0.5em}
%     \subfigure{
%         \includegraphics[width=0.3\linewidth,trim=20mm 10mm 20mm 10mm, clip]{visual/cub_forget_LF/200421.png}
%     }
%      \makebox[\linewidth]{
%         \makebox[0.31\linewidth]{$\text{Start}$}
%         \makebox[0.31\linewidth]{$L$}
%         \makebox[0.31\linewidth]{$L\xrightarrow{}F$}
%     }
%     %\vspace{-3em}
%     \caption{\textit{Learning Before Forgetting} on object dection}
%     \label{fig:vis_obj}
% \end{figure}
% For the object detection task, we select DINO\cite{zhang2022dino} trained on the COCO\cite{lin2014microsoft} dataset as the base model. The forgetting set consists of 5 randomly selected classes, while  the rest classes are retaining set. The number of images in both the forgetting and keeping sets is much smaller than the original dataset. The learning set consists of 5 classes from the CUB-200-2011 or Stanford Dogs Dataset\cite{dataset2011novel} dataset.
For the object detection task, we use DINO~\cite{zhang2022dino} pretrained on the COCO dataset as the base model.
%The forgetting set consists of 5 randomly selected classes, while  the rest classes are retaining set. 
The forgetting set consists of five randomly selected classes: \textit{person}, \textit{teddy bear}, \textit{toilet}, \textit{bench}, and \textit{bed}, while all remaining classes form the retention set. The learning sets consist of 5 classes: \textit{Black-footed Albatross}, \textit{Laysan Albatross}, \textit{Sooty Albatross}, \textit{Groove-billed Ani}, and \textit{Brewer Blackbird} for CUB-200-2011 and \textit{Chihuahua}, \textit{Maltese Dog}, \textit{Basset}, \textit{American Staffordshire Terrier}, and \textit{Norwich Terrier} for Stanford Dogs, respectively. 
\begin{figure}[!htb]
\vspace{-3mm}
    \centering
    % \subfigure{
    %     \includegraphics[width=0.31\linewidth]{visual/forget_remain_S/ADE_val_00000077.jpg}
    % }
    % \subfigure{
    %     \includegraphics[width=0.31\linewidth]{visual/forget_remain_F/ADE_val_00000077.jpg}
    % }
    % \subfigure{
    %     \includegraphics[width=0.31\linewidth]{visual/forget_remain_FL/ADE_val_00000077.jpg}
    % }
    \subfigure{
        \includegraphics[width=0.3\linewidth]{visual/forget_remain_S/ade_114_drawio.png}
    }\hspace{-0.6em}
    \subfigure{
        \includegraphics[width=0.3\linewidth]{visual/forget_remain_F/ade_114_drawio.png}
    }\hspace{-0.6em}
    \subfigure{
        \includegraphics[width=0.3\linewidth]{visual/forget_remain_FL/ade_114_drawio.png}
    }
    % \vspace{0em}
    % \makebox[\linewidth]{
    %     \makebox[0.2\linewidth]{initial}
    %     \makebox[0.2\linewidth]{inference after \\learn}
    %     \makebox[0.2\linewidth]{inference after fftl}
    % }
    \makebox[\linewidth]{
    \makebox[0.31\linewidth]{$S$}
    \makebox[0.31\linewidth]{\shortstack{$F$}}
    \makebox[0.31\linewidth]{\shortstack{$F \rightarrow L$}}
}
    %   \makebox[\linewidth]{
    %     \makebox[0.31\linewidth]{$S$}
    %     \makebox[0.31\linewidth]{$F$}
    %     \makebox[0.31\linewidth]{$F\xrightarrow{}L$}
    % }
    % \makebox[\linewidth]{
    %     \makebox[0.3\linewidth]{initial}
    %     \makebox[0.3\linewidth]{inference after learn}
    %     \makebox[0.3\linewidth]{inference after fltf}
    % }
    \vspace{-2em} % 减小 caption 和图像之间的间距
    \caption{\small Semantic segmentation results for \textit{Learning After Forgetting} on ADE20K.} 
    \vspace{-2mm}
    \label{fig:vis_seg_laf}
\end{figure}
The quantitative results in Table~\ref{tab:obj_lbf} demonstrate the effectiveness of our  \textit{Learning Before Forgetting} strategy, as the mAP of the retention set remains stable at around 55\%, the forgetting set drops from 44.5\% to below 1\%, and the learning set improves from 0 to a satisfactory level, confirming the success of our approach. In contrast, it also shows that in the \textit{Learning After Forgetting}($F\rightarrow L$) setting, the forgetting set retains a relatively high mAP, indicating ineffective forgetting. This supports our hypothesis that learning progresses from low-level to high-level features, while forgetting follows the opposite direction, from high-level to low-level features.

% The quantitative experiments is in table \ref{detection-5-fltf} . Qualitative experiments is in appendix \ref{object dection}.
\subsection{Insights and Discussion}

To further validate the effectiveness of our strategy, we conduct an additional experiment involving a \textit{Forget-Learn-Forget} sequence. As shown in Table~\ref{tab:seg-lbf}, although the mIoU of the forgetting set remains high after the initial forgetting and subsequent learning phases, it is significantly reduced after the second forgetting phase. This result demonstrates the robustness of the \textit{Learn Before Forget} strategy. The results $L \rightarrow F \rightarrow L$ further provide indirect evidence that positioning the learning phase at the end influences the content that was previously forgotten. We analyze the $\mathcal{L}_2$ norm of model parameters at different stages, as illustrated in Figure~\ref{fig:seg_flf_l2}. The red line represents parameter changes from \( F \) to \( F \xrightarrow{} L \), while the black line indicates changes from \( F \xrightarrow{} L \) to \( F \xrightarrow{} L \xrightarrow{} F \). The results show that learning-induced parameter changes are primarily concentrated in the early layers of the model, whereas forgetting-related changes are more prominent in the later layers. These observations align well with our previous findings.

% To further validate the effectiveness of our strategy, we conduct an additional experiment involving first forget then learn and finally forget. Although the mIoU of the forgetting set remained high after the initial forgetting and subsequent learning phase, it was significantly reduced after the second forgetting phase, demonstrating the robustness of the first learn then forget strategy.Additionally, we analyzed the L2 norm of model parameters at different stages in figure \ref{fig:flf on semantic segmentation}. The red line represents parameter changes from $F$ to $F\xrightarrow{}L$, while the black line indicates changes from $F\xrightarrow{}L$ to $F\xrightarrow{}L\xrightarrow{}F$. The results show that learning-induced parameter changes are primarily concentrated in the early layers of the model, whereas forgetting-related changes are more prominent in the later layers, aligning well with our previous findings.
% \textbf{first forget then learn then forget.} To validate the correctness of the theory, we designed an experiment involving forgetting, learning, and then forgetting again. As seen in figure \ref{fig:flf on semantic segmentation},it was observed that the parameter changes caused by forgetting are primarily concentrated in the latter part of the model. Moreover, the final results align with expectations: the accuracy of the forgotten set is very low, while the accuracy of the retained and learned sets is very high.
% \textbf{first forget then learn.} We also conducted quantitative experiments with forgetting followed by learning, as shown in Table \ref{classification-10-fftl},\ref{detection-5-fftl},\ref{segmentation-fftl}. It can be observed that the final forgetting effect is poor. 
% \begin{table}[htbp]
% \setlength{\tabcolsep}{1pt}  
% \centering
% \begin{tabular}{c|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c}{oxford-dog} \\
% \cline{2-7}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$   \\
% \hline
% Start & 55.4 & 0 & 44.5 & 55.4 & 0 & 44.5  \\
% $F$ & 54.9 & 16.8 & 3.4 & 54.8 & 9.7 & 3.4  \\
% $F\xrightarrow{}L$ & 55 & 65.4 & 7.7 & 54.6 & 78.5 & 11.1  \\
% \hline
% \end{tabular}
% \caption{\textbf{First Forget and Learn on COCO for object dection with 5 classes.} $F$ represents the moment when the learning process ends. $F\xrightarrow{}L$ represents the moment when "first learn then forget" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the mAP of retaining set, learning set and forgetting set.
% The learning set consists of 5 classes selected from the two datasets in the table, the forgetting set
% contains 5 classes selected from COCO, and the retaining set includes all other classes from COCO.
% }
% \label{detection-5-fftl}
% \end{table}

% \begin{figure*}[!htb]
%     \centering
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_S/ADE_val_00001155.jpg}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_L/ADE_val_00001155.jpg}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_LF/ADE_val_00001155.jpg}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_S/ADE_val_00001518.jpg}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_L/ADE_val_00001518.jpg}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth]{visual/forget_remain_LF/ADE_val_00001518.jpg}
%     }
%      \makebox[\linewidth]{
%         \makebox[0.31\linewidth]{$S$}
%         \makebox[0.31\linewidth]{$L$}
%         \makebox[0.31\linewidth]{$L\xrightarrow{}F$}
%     }
%     \caption{\textbf{Qualitative results for "first learn then forget" on semantic segmentation.} Forget classes are flower sconce and lamp.Retain class are the rest class.$S$ represents the results obtained from the model inference at the initial stage, $l$ represents the results obtained from the model inference after the learning process, and $L\xrightarrow{}F$ represents the results obtained from the model inference after the process of first learn then forget.}
%     \label{fig:visual forget and retain for fltf on semantic segmentation}
% \end{figure*}
% % \begin{figure*}[!htb]
% %     \centering
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/forget_remain_S/ade_1155.png}
% %     }\hspace{-0.5em}
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/forget_remain_L/ade_1155.png}
% %     }\hspace{-0.5em}
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/forget_remain_LF/ade_1155.png}
% %     }
% %     \vspace{1em}  % 添加垂直空间
    
% %     \textbf{forget classes are lamp and scope. learn classes is cow.  }  % 添加文字
% %     \vspace{1em}  % 添加垂直空间
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_S/2011_2885.png}
% %     }\hspace{-0.5em}
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_L/2011_2885.png}
% %     }\hspace{-0.5em}
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_LF/2011_2885.png}
% %     }
% %      \makebox[\linewidth]{
% %         \makebox[0.31\linewidth]{initial}
% %         \makebox[0.31\linewidth]{inference after learn}
% %         \makebox[0.31\linewidth]{inference after fltf}
% %     }
% %     \caption{\textbf{Qualitative results for "first learn then forget" on semantic segmentation.} Forget classes are flower sconce and lamp.Retain class are the rest class.$S$ represents the results obtained from the model inference at the initial stage, $l$ represents the results obtained from the model inference after the learning process, and $L\xrightarrow{}F$ represents the results obtained from the model inference after the process of first learn then forget.}
% %     \label{fig:visual forget and retain for fltf on semantic segmentation}
% % \end{figure*}
% % \begin{figure*}[!htb]
% %     \centering
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_S/2007_004644.jpg}
% %     }
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_L/2007_004644.jpg}
% %     }
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth]{visual/voclearn_LF/2007_004644.jpg}
% %     }
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth,trim=0mm 25mm 0mm 0mm,clip]{visual/voclearn_S/2007_007748.jpg}
% %     }
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth,trim=0mm 25mm 0mm 0mm,clip]{visual/voclearn_L/2007_007748.jpg}
% %     }
% %     \subfigure{
% %         \includegraphics[width=0.31\linewidth,trim=0mm 25mm 0mm 0mm,clip]{visual/voclearn_LF/2007_007748.jpg}
% %     }
% %      \makebox[\linewidth]{
% %         \makebox[0.31\linewidth]{$S$}
% %         \makebox[0.31\linewidth]{$L$}
% %         \makebox[0.31\linewidth]{$L\xrightarrow{}F$}
% %     }
% %     \caption{\textbf{Qualitative results for "first learn then forget"on semantic segmentation.} Learn classes are dog and house.$S$ represents the results obtained from the model inference at the initial stage, $l$ represents the results obtained from the model inference after the learning process, and $L\xrightarrow{}F$ represents the results obtained from the model inference after the process of first learn then forget.}
% %     \label{fig:visual learn set for fltf on semantic segmentation}
% % \end{figure*}
\section{Conclusion and Future Works}
We proposed \textbf{Knowledge Swapping}, a novel task that enables selective regulation of model knowledge by achieving three goals: forgetting user-specified knowledge, retaining essential knowledge, and learning new knowledge. To accomplish this, we introduced a two-stage training strategy based on the \textit{Learning Before Forgetting} principle, which decouples learning and forgetting to mitigate catastrophic forgetting effectively. We benchmark our \textit{Learning Before Forgetting} with various experiments. However, our experiments also reveal that the difficulty of learning new knowledge for different categories and forgetting old knowledge varies. An interesting direction for future research is to explore and analyze the difficulty of forgetting specific knowledge and learning new knowledge of categories.
%Experimental results on image classification, object detection, and semantic segmentation tasks demonstrate the robustness and versatility of our method across diverse datasets and tasks. 

% In the future, we plan to extend the Knowledge Swapping framework to multi-modal tasks, improve its adaptability for dynamic task requirements, and optimize computational efficiency for large-scale applications. Additionally, we aim to explore its potential in real-world scenarios, such as privacy-preserving models and regulatory compliance, to further enhance its practical impact.

%\newpage
% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}
% \section*{Impact Statement}
% This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.
\bibliography{arxiv}
\bibliographystyle{icml2024}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn






% \section{image classfication}\label{image classification}

% % You can have as much text here as you want. The main body must be at most $8$ pages long.
% % For the final version, one more page can be added.
% % If you want, you can use an appendix like this one.  

% % The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.

% \begin{table*}[htbp]
% \setlength{\tabcolsep}{5pt}  
% \centering
% \begin{tabular}{c|ccc|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c|}{resisc45} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% \cline{2-13}
% & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% \hline

% \multicolumn{13}{c}{First Learn and Forget on Imagenet100 for image classification with 20 classes} \\
% \hline

% Start & 86.65 & 0 & 95.84 & 86.65 & 0.15 & 95.84 & 86.65 & 0.9 & 95.84 & 86.65 & 1.75 & 95.84 \\
% $L$ & 83.32 & 93.0 & 81.17 & 85.75 & 94.1 & 92.32 & 85.85 & 95.3 & 91.38 & 85.55 & 97.71 & 92.19 \\
% $L\xrightarrow{}F$ & 82.35 & 88.44 & 0.05 & 83.97 & 96.0 & 0.09 & 83.97 & 96.4 & 0.09 & 84.15 & 98.33 & 0.15 \\
% \hline

% \multicolumn{13}{c}{First Learn and Forget on Imagenet100 for image classification with 40 classes} \\
% \hline

% Start & 89.26 & 0 & 85.85 & 89.26 & 0.07 & 85.85 & 89.26 & 1.19 & 85.85 & 89.26 & 0.2 & 85.85 \\
% $L$ & 86.7 & 91.48 & 69.6 & 88.16 & 86.9 & 79.3 & 88.9 & 90.86 & 80.1 & 88.06 & 95.56 & 76.6 \\
% $L\xrightarrow{}F$ & 83.66 & 82.81 & 0 & 81.86 & 94.4 & 0.05 & 83.2 & 93.64 & 0.05 & 83.73 & 97.47 & 0 \\
% \hline


% \end{tabular}
% \caption{\textbf{First Learn and Forget on Imagenet100 for image classification with 20 and 40 classes.} $L$ represents the moment when the learning process ends. $L\xrightarrow{}F$ represents the moment when "first learn then forget" process ends. $Acc_r$, $Acc_l$ and $Acc_f$ represents the accuracy of retaining set, learning set and forgetting set.
% The learning set consists of 20 or 40 classes selected from the four datasets in the table, the forgetting set
% contains 20 or 40 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
% }
% \label{classification-20}
% \end{table*}



% % \begin{table*}[htbp]
% % \setlength{\tabcolsep}{5pt}  
% % \centering
% % \begin{tabular}{c|ccc|ccc|ccc|ccc}
% % \hline
% % \multirow{2}{*}{procedure} & \multicolumn{3}{c|}{cub} & \multicolumn{3}{c|}{resisc45} & \multicolumn{3}{c|}{oxford-pet} & \multicolumn{3}{c}{plantvillage} \\
% % \cline{2-13}
% % & $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ &  $acc_r$ $\uparrow$ & $acc_l$ $\uparrow$ & $acc_f$ $\downarrow$ \\
% % \hline
% % Start & 89.26 & 0 & 85.85 & 89.26 & 0.07 & 85.85 & 89.26 & 1.19 & 85.85 & 89.26 & 0.2 & 85.85 \\
% % $L$ & 86.7 & 91.48 & 69.6 & 88.16 & 86.9 & 79.3 & 88.9 & 90.86 & 80.1 & 88.066 & 95.56 & 76.6 \\
% % $L\xrightarrow{}F$ & 83.66 & 82.81 & 0 & 81.86 & 94.4 & 0.05 & 83.2 & 93.64 & 0.05 & 83.73 & 97.47 & 0 \\
% % \hline
% % \end{tabular}
% % \caption{\textbf{First Learn and Forget on Imagenet100 for image classification with 40 classes.} 
% % The learning set consists of 40 classes selected from the four datasets in the table, the forgetting set
% % contains 40 classes selected from Imagenet100, and the retaining set includes all other classes from Imagenet100.
% % }
% % \label{classification-40}
% % \end{table*}


% \section{object dection}\label{object dection}

% % You can have as much text here as you want. The main body must be at most $8$ pages long.
% % For the final version, one more page can be added.
% % If you want, you can use an appendix like this one.  

% % The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.

% % \begin{figure*}[htp]
% %     \centering
% %     \includegraphics[width=1\textwidth, trim=0mm 0mm 0mm 0mm, clip]{assets/combined_plots_0126.pdf}
    

% %     \caption{L2 norm of $F \xrightarrow{} L \xrightarrow{} F$}
% %     \label{fig:three-images}
% % \end{figure*}




% \begin{figure*}[!htb]
 
%     \centering
%     \subfigure[first learn then forget(fltf)]{
%         \includegraphics[width=0.5\linewidth, trim=0mm 0mm 0mm 0mm, clip]{assets/fltf-combine-dection.pdf}
%     }
%     \subfigure[first forget then learn(fltf)]{
%         \includegraphics[width=0.5\linewidth]{assets/fftl-combine-dection.pdf}
%     }

%     \caption{\textbf{l2 norm compare between fltf and fftl.}}
%     \label{fig:l2norm-images}
% \end{figure*}


% \begin{figure*}[h]
%     \vspace{-10mm}
%     \centering
%     \includegraphics[width=\linewidth]{assets/grid_combined_plot_dection.pdf}
%     \caption{\textbf{Logarithm of the Average Gradient on object dection.}In the object dection task, we use DINO as the pre-trained model. Subclasses of COCO are used as the retention set and forgetting set, while five classes from Cub-200-2011 or Stanford Dogs are selected as the learning set. We employ two strategies: "learn first, then forget"(fltf) and "forget first, then learn"(fftl). Both learning and forgetting processes are trained for 7000 iters, and the average gradients are calculated accordingly.}
%     \label{fig:grad-images}
%     % \vspace{-30mm}  % Adjust this value as needed
% \end{figure*}
% \begin{figure*}[h]
%     \centering
%     \includegraphics[width=0.8\textwidth, trim=0mm 0mm 0mm 0mm, clip]{assets/combined_plots_flf_dection.pdf}
%     \caption{L2 norm of $F \xrightarrow{} L \xrightarrow{} F$}
%     \label{fig:three-images}
% \end{figure*}


% \begin{figure*}[!htb]
%     \centering
%     \subfigure{
%         \includegraphics[width=0.31\linewidth, trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_S/581948.png}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_L/581948.png}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_LF/581948.png}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_S/581972.png}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_L/581972.png}
%     }
%     \subfigure{
%         \includegraphics[width=0.31\linewidth,trim=20mm 20mm 20mm 20mm, clip]{visual/cub_learn_LF/581972.png}
%     }
%      \makebox[\linewidth]{
%         \makebox[0.31\linewidth]{$S$}
%         \makebox[0.31\linewidth]{$L$}
%         \makebox[0.31\linewidth]{$L\xrightarrow{}F$}
%     }
%     \caption{Qualitative results for "first learn then forget"on object dection}
%     \label{fig:visual_on_dection}
% \end{figure*}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
