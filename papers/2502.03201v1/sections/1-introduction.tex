\section{Introduction}
\label{sec:introduction}


With the rapid development of the Internet in recent years, graph-structured data has become ubiquitous. However, this popularity also presents a significant challenge: identifying anomalous nodes within a graph to prevent them from compromising the entire system. This task is commonly known as Node Anomaly Detection (NAD), which appears in various real-world scenarios, such as detecting money laundering in financial networks \citep{dgraphfin22huang}, identifying malicious comments in review networks \citep{review19li}, and spotting bots on social platforms \citep{bot22guo}. While NAD is crucial for maintaining the integrity of these systems, effectively addressing it presents several challenges. Firstly, graph data inherently captures complex relationships across various domains, and the intricate shapes of the data complicate the accurate generation of node representations for NAD \citep{xiangyu2025smoothgnn}. Secondly, the ubiquitous issue of limited supervision in real scenarios makes it even harder to obtain sufficient comprehensive information for various types of nodes. 

In the literature, researchers have widely employed Graph Neural Networks (GNNs) in their methods to solve general graph-related tasks. They have explored multiple frameworks from different spaces to enhance the expressiveness of their GNNs. For instance, GCN \citep{gcn17kipf}, GraphSage \citep{graphsage17hamilton}, GAT \citep{gat18velickovic}, and GIN \citep{gin19xu} embed graphs into Euclidean space, while HNN \citep{hnn18ganea}, HGCN \citep{hgcn19chami}, and HYLA \citep{hyla23yu} encode graphs into non-Euclidean space.

In addition to the generalized GNNs mentioned above, various specialized GNNs have been developed to address complex challenges in NAD tasks. Some of these models leverage the properties of anomalous nodes within Euclidean space to improve the quality of node representations for NAD, including GDN \citep{gdn23gao}, SparseGAD \citep{sparsegad23gong}, GAGA \citep{gaga23wang} and XGBGraph \citep{gadbench23tang}. Others enhance performance by employing a spectral view in Euclidean space, such as AMNet \citep{amnet22chai}, BWGNN \citep{bwgnn22tang}, and GHRN \citep{ghrn23gao}. Moreover, to extract sufficient information from limited supervision, data augmentation techniques have been incorporated in recent work like CONSISGAD \citep{consisgad24chen}. 

\input{figures/geometry/geometry}

However, both generalized and specialized GNNs have overlooked the key challenges when applied to NAD tasks. For instance, without considering the diverse structural properties in real NAD scenarios, it is unlikely to design the most suitable node projection functions and propagation methods. As shown in Figure \ref{fig:geometry}, we abstract subgraphs from real-world NAD datasets and provide their corresponding aptâ€Œ projection spaces \citep{kappa20bachmann}. Specifically, the Euclidean space suits plain relational structures within graphs \citep{plain20bandyopadhyay}, serving as the base projection space for NAD tasks. However, certain subfields in NAD, such as rumor detection \citep{tree18ma, rumor20bian}, require the ability to handle hierarchical data. 
The Hyperbolic space, which expands exponentially, is particularly adept at accommodating such data. 
Additionally, in financial networks, anomalies like money laundering crime usually display circle patterns \citep{mlaund22dumitrescu, circle23altman}. 
The Spherical space allows for a nuanced understanding of node properties in such data. 
As a result, directly encoding graphs from different NAD tasks in a single space with a fixed curvature $\kappa$ can result in suboptimal performance, as shown in our experiments. Furthermore, the limited supervision in real NAD applications presents another challenge for current methods. Given the imbalanced nature of the data, data augmentation techniques may not always effectively provide sufficient information, as will be shown in our experiments. 

To address the above concerns, we present both empirical and theoretical analyses of NAD tasks with limited supervision. Motivated by this, we introduce SpaceGNN, a novel graph learning framework, which consists of three key components: {\bf Learnable Space Projection (LSP)}, {\bf Distance Aware Propagation (DAP)}, and {\bf Multiple Space Ensemble ({\update MulSE})}. Specifically, we design an insightful measure and conduct an empirical analysis to investigate the influence of various spaces on distinct classes of nodes, revealing the advantages of the adjustable projection function discussed in Section \ref{subsec:LSP}. Building on these empirical findings, we propose LSP as a projection function that embeds nodes into the most suitable spaces by a learnable curvature. Moreover, we introduce a novel metric to explore the benefits of a distance-based attention mechanism during propagation across different spaces. This metric further showcases the utility of various space representations from both empirical and theoretical perspectives, as elaborated in Section \ref{subsec:DAP}. Based on these results, we design DAP to adjust edge weights according to the distances within different spaces during feature propagation, which effectively mitigates the influence of noisy features propagated from different classes. Additionally, through an investigation of recent research, we empirically evaluate the limitations of relying on synthetic information via data augmentation in Section \ref{subsec:MSE}. To provide a more robust solution, we theoretically demonstrate that model augmentation approaches can serve as more effective alternatives. Thus, we develop {\update MulSE} to aggregate information from the ensemble of models from multiple spaces, a process shown to be effective from empirical and theoretical perspectives. 


In summary, the main contributions of our work are as follows: 
\begin{itemize}[topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
    \item We are the first, to the best of our knowledge, to reveal the benefits of leveraging multiple spaces for supervised NAD tasks from both empirical and theoretical perspectives. 
    \item We propose SpaceGNN, a novel framework that ensembles comprehensive information from different spaces with a specialized attention mechanism based on solid analysis. 
     \item Extensive experiments demonstrate the effectiveness of our framework. Compared to state-of-the-art models, SpaceGNN achieves superior performance in terms of AUC and F1 scores. 
 \end{itemize}



