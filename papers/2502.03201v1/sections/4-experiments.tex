\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}
\label{subsec:setup}
\textbf{Datasets.} We evaluate SpaceGNN on 9 real-world datasets from the benchmark paper \citep{gadbench23tang}, including Weibo, Reddit, Tolokers, Amazon, T-Finance, YelpChi, Questions, DGraph-Fin, and T-Social. The detailed information on the datasets is listed in the Appendix \ref{subsec:dataset-baseline}. To simulate the real application with limited supervision, we randomly divide each dataset into 50/50 for training/validation, and the rest of the nodes for testing. 

\textbf{Baselines.} 
We compare SpaceGNN against 16 SOTA competitors, including generalized models, aiming to solve general graph-related tasks, and specialized models, which are designed for NAD. 
\begin{itemize} [topsep=0.5mm, partopsep=0pt, itemsep=0pt, leftmargin=10pt]
    \item Generalized Models: MLP \citep{mlp58f}, GCN \citep{gcn17kipf}, GraphSAGE \citep{graphsage17hamilton}, GAT \citep{gat18velickovic}, GIN \citep{gin19xu}, HNN \citep{hnn18ganea}, HGCN \citep{hgcn19chami}, and HYLA \citep{hyla23yu}. 
    \item Specialized Models: AMNet \citep{amnet22chai}, BWGNN \citep{bwgnn22tang}, GDN \citep{gdn23gao}, SparseGAD \citep{sparsegad23gong}, GHRN \citep{ghrn23gao}, GAGA \citep{gaga23wang}, XGBGraph \citep{gadbench23tang}, and CONSISGAD \citep{consisgad24chen}. 
\end{itemize}

\textbf{Experimental Settings}. To ensure a fair comparison, we obtain the source code of all competitors from GitHub and execute these models using the default parameter settings suggested by their authors. The hyperparameters of SpaceGNN are set according to the best value of the F1 score of the validation set in each dataset. The specific hyperparameters can be found in Appendix \ref{subsec:setting}.
  
\subsection{Experimental Results}
\label{subsec:results}

We evaluate the performance of SpaceGNN against 8 generalized models and 8 specialized models. Tables \ref{tab:general50} and \ref{tab:gad50} report the AUC and F1 scores of each model on 9 datasets, respectively. The best result on each dataset is highlighted in boldface. As we can see, SpaceGNN outperforms almost all baseline models on all datasets. Next, we provide our detailed observations. 

\input{tables/general50}

Firstly, the most simple neural network, MLP, can only process the node features without considering structure information in the graph. The result is surprisingly high in several datasets compared with some generalized GNN models, which shows without correctly dealing with special structural properties, propagation may hurt performance in NAD tasks. In contrast, our SpaceGNN leverages information from multiple spaces, which is suitable for various structures, outperforming MLP by 17.34\% and 9.91\% on these 9 datasets in terms of average AUC and F1 scores, respectively. 

Secondly, we examine four Euclidean GNNs, i.e., GCN, GraphSage, GAT, and GIN. They are the most popular GNNs for graph-related tasks. However, due to the lack of ability to tackle complex structures in different NAD datasets under limited supervision, they fail to generalize their power to such tasks, leading to inferior performance. In particular, compared with them, SpaceGNN takes the lead by 11.94\%, 18.98\%, 21.57\%, and 17.17\% on these 9 datasets in terms of average AUC score, and 17.10\%, 17.16\%, 17.12\%, and 15.39\% in terms of average F1 score, separately. 

Thirdly, to the best of our knowledge, HNN is the first neural network that projects features into non-Euclidean space. The result aligns with the performance of MLP, that is, without carefully considering the suitable space for corresponding structures in NAD datasets, no structural information included may enhance the performance. On the contrary, our proposed model considers both Euclidean and non-Euclidean spaces for node projection and propagation, effectively utilizing structural features within graphs, so SpaceGNN can surpass HNN by 9.82\% and 9.05\% on these 9 datasets in terms of average AUC and F1 scores, respectively. 

Fourthly, HGCN and HYLA are two non-Euclidean GNNs, encoding graph information into a single non-Euclidean space. The underfitting issue of complicated structural information in NAD graphs results in unsatisfactory performance on several datasets. In comparison with them, SpaceGNN captures enough features accurately through multiple spaces, exceeding them by 17.13\% and 20.63\% in terms of average AUC score, and 12.60\% and 18.09\% in terms of average F1 score, separately. 

\input{tables/gad50}


Fifthly, we compare our SpaceGNN with four specialized models within Euclidean space, i.e. GDN, SparseGAD, GAGA, and XGBGraph. They are built on the observation of the underlying properties of NAD graphs. Nevertheless, under limited supervision, the observed properties lose their power to be applied to the entire dataset. As a result, their performance degrades severely. In comparison, without manually detecting the special structures, our SpaceGNN can automatically capture accurate properties underlying datasets in different spaces, taking the lead by 15.32\%, 18.58\%, 12.45\%, and 11.54\% in terms of average AUC score, and 17.26\%, 17.63\%, 12.54\%, and 8.12\% in terms of average F1 score, respectively. 


Sixly, several specialized models, like AMNet, BWGNN, and GHRN, have considered NAD from a spectral view within Euclidean space, trying to gain diverse features to handle NAD tasks. Although such spectral kernels can detect frequency change because of anomalous nodes, they still fall behind our SpaceGNN by 20.60\%, 12.75\%, and 12.77\% in terms of average AUC score, and 10.65\%, 7.76\%, and 7.52\% in terms of average F1 score, separately, due to the inability to capture comprehensive enough properties within NAD datasets. 

Finally, CONSISGAD tries to handle the problem of limited labels existing within real NAD tasks. Specifically, CONSISGAD, the most recent work in this area, generates pseudo labels for nodes to gain more supervision. However, as shown in Section \ref{subsec:MSE}, such a technique may lead to enormous noise, leading to subordinate results. By contrast, our theoretical analysis supports the usage of an ensemble of multiple spaces in SpaceGNN, and its performance demonstrates it empirically. To be specific, on 9 real-world datasets, CONSISGAD falls back SpaceGNN by 8.55\% and 4.31\% in terms of AUC and F1 scores on average, respectively.


Beyond the above results, we also provide parameter analysis, ablation study, additional experiments on different settings, an alternative model, the learned $\kappa$, time complexity, performance with more training data, and performance under GADBench \citep{gadbench23tang} semi-supervised setting in Appendix \ref{subsec:parameter}, \ref{subsec:ablation}, \ref{subsec:Additional}, \ref{subsec:alternative}, \ref{subsec:learnedk}, \ref{subsec:time}, \ref{subsec:moredata}, and \ref{subsec:gadbench}, separately, which can further demonstrate the effectiveness of our proposed SpaceGNN. 