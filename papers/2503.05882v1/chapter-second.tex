\newpage
\chapter{Second-Order Methods}\label{chapter:second_order}
\begingroup
\hypersetup{
linkcolor=structurecolor,
linktoc=page,  % page: only the page will be colored; section, all, none etc
}
\minitoc \newpage
\endgroup


We previously discussed first-order methods in Chapter~\ref{chapter:gd_convg}, which rely solely on function values and gradients.
Beyond these methods, this chapter explores Newton's method and its common variations—including damped Newton's method, Levenberg gradient descent, quasi-Newton methods, and conjugate gradient methods—all of which leverage second-order information to enhance convergence speed (note that the analysis of the conjugate gradient method requires second-order information). Additionally, we examine the trust-region framework, a robust approach for solving nonconvex optimization problems.



\section{Newton's Method}\label{section:new_methods}
Gradient-based methods rely solely on the information of function values and gradients (i.e., first-order information). 
However, if the function $ f(\bx) $ is sufficiently smooth, second-order derivative information can be used to construct a more effective descent direction $ \bd^\toptzero $ for each iteration. 
Newton-type algorithms are those that use second-order derivative information to construct their update rules. 
By incorporating more information, these methods can significantly outperform gradient-based approaches, though they also impose stricter requirements on $ f(\bx) $. This section first introduces the construction and properties of Newton's method, followed by several modified versions.

\subsection{Pure Newton's Method}
Newton's method is a second-order optimization technique that approximates the loss function using a quadratic expansion, providing an estimate of the minimum location based on this approximation.
We will also show that the stochastic optimizer AdaDelta is derived from the principle of unit consistency in second-order methods (Section~\ref{section:adadelta}). 
For a twice continuously differentiable function $ f(\bx) $, consider the quadratic approximation $ f(\bx) $ at the iteration point $ \bx^\toptzero $ (Theorem~\ref{theorem:quad_app_theo}):
\begin{subequations}\label{equation:newton_secon_approx_ALL}
\begin{equation}\label{equation:newton_secon_approx_eq1}
	f(\bx^\toptzero + \bd) = f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} (\bd)^\top \nabla^2 f(\bx^\toptzero) \bd + o(\normtwobig{\bd}^2).
\end{equation}
Our goal is to use this second-order approximation to determine  an appropriate descent direction $ \bd = \bd_{\text{n}}^\toptzero $ (Definition~\ref{definition:uncons_des_direct}). Ignoring the higher-order terms in \eqref{equation:newton_secon_approx_eq1}, we treat the right-hand side as a quadratic function of $ \bd $:
\begin{equation}\label{equation:class_new_quadr}
	g_t(\bd) \triangleq f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} \bd^\top \nabla^2 f(\bx^\toptzero ) \bd.
\end{equation}
We can find its stationary points by setting the gradient of $g_t(\bd)$ to zero, leading to the \textit{Newton equation}
\begin{equation}\label{equation:newton_secon_approx_eq3}
	\nabla^2 f(\bx^\toptzero) \bd = -\nabla f(\bx^\toptzero).
\end{equation}
\end{subequations}
If $ \nabla^2 f(\bx^\toptzero) $ is nonsingular (hence positive definite), the update direction $ \bd=\bd_{\text{n}}^\toptzero $ can be computed as 
$$ 
\bd_{\text{n}}^\toptzero = -\big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \nabla f(\bx^\toptzero),
$$
which is known as the \textit{Newton step} (or \textit{Newton direction} for $f$, at $\bx^\toptzero$).
The positive definiteness of $ \nabla^2 f(\bx^\toptzero) $ also shows that the Newton step is a descent direction unless $\nabla f(\bx^\toptzero)=\bzero$ (Theorem~\ref{theorem:uncons_des_dir}). 
Moreover, because $g_t(\bd)$ is convex when $\nabla f(\bx^\toptzero)$ is positive definite (Exercise~\ref{exercise:conv_quad}),  $\bd_{\text{n}}^\toptzero$ is the minimizer of $g_t(\bd)$.



Therefore, the update formula for   Newton's method at $t$-th iteration is
$$
\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{n}}^\toptzero.
$$
In other words, the steepest descent step is rescaled by the inverse of the Hessian.
Intuitively, this suggests that $\bx^\toptzero + \bd_{\text{n}}^\toptzero$ should provide a highly accurate estimate of the minimizer of  $f$, especially when the function $f$ is nearly quadratic or when $\bx$ is near the optimum point $\bx^*$.


Newton's update can be intuitively understood as adjusting the stepsize based on curvature information from the Hessian. Specifically:
\begin{itemize}
\item  When the curvature is steep, the inverse Hessian scales down the stepsize, making updates smaller.
\item When the curvature is flat, the inverse Hessian scales up the stepsize, allowing larger updates.
\end{itemize}
However, for nonlinear functions $f(\bx)$, a single Newton step is usually insufficient to reach the minimum.
Like the first-order optimization methods introduced earlier, Newton's method is applied iteratively, as summarized in  Algorithm~\ref{alg:class_newton} \citep{roweis1996levenberg, goodfellow2016deep}. 
Notably, in the update formula above, the stepsize $\eta_t $ is always set to 1, eliminating the need for stepsize selection. 
For this reason, Newton's method with a fixed stepsize of 1 is often referred to as \textit{classical Newton's method} (\textit{pure Newton's method} or simply \textit{Newton's method}).




\begin{algorithm}[h] 
\caption{Newton's Method}
\label{alg:class_newton}
\begin{algorithmic}[1] 
\Require A twice continuously differentiable function $f(\bx)$; 
\State {\bfseries Input:} Initialize $\bx^{(1)}$;
\For{$t=1,2,\ldots$}
\State $\bd_{\text{n}}^\toptzero \leftarrow $ solution of $\nabla^2 f(\bx^\toptzero) \bd = -\nabla f(\bx^\toptzero)$;
\State $\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{n}}^\toptzero$;
\EndFor
\State {\bfseries Return:}  final $\bx\leftarrow \bx^{(t)}$;
%\State (Output Option 2) Output  $\bx_{\text{avg}}\leftarrow \frac{1}{T}(\sum_{t=1}^{t}\bx^{(t)})$ or $\sum_{t=1}^{T} \frac{2t}{T(T+1)} \bx^{(t)}$;
%\State (Output Option 3) Output  $\bx_{\text{best}}\leftarrow \argmin_{t\in\{1,2,\ldots,T\}} f(\bx^{(t)})$;
\end{algorithmic} 
\end{algorithm}

The computational complexity of Newton's method primarily arises from the need to compute the inverse of the Hessian matrix at each training iteration.
For a function $f$ with $n$ parameters  ($\bx\in \real^n, \nabla^2 f(\bx)\in \real^{n\times n}$), the Hessian matrix contains $n^2$ entries, and its inversion has a computational complexity of $\mathcalO(n^3)$ \citep{trefethen1997numerical, boyd2018introduction, lu2021numerical}. 
As a result, Newton's method is only practical for training models with a relatively small number of parameters, such as shallow neural networks or multi-layer perceptrons.



\paragrapharrow{Newton's method via greedy search.}
In Section~\ref{section:als-gradie-descent-taylor}, we introduced non-Euclidean gradient descent methods that use greedy search with different norms, along with their convergence properties in Section~\ref{section:noneucli_gd}. 
The Newton step can be interpreted as a greedy search using the $\bQ$-norm with $\bQ\triangleq\nabla f(\bx^\toptzero)$ at the $t$-th iteration:
$$
\norm{\bd}_{\nabla f(\bx^\toptzero)}
=
\big(\bd^\top \nabla f(\bx^\toptzero) \bd\big)^{1/2}.
$$
When the Hessian $\nabla f(\bx^\toptzero)$ closely  approximates the Hessian at the optimal point (especially when $\bx^\toptzero$ is close to $\bx^*$), $\nabla f(\bx^\toptzero) \approx \nabla f(\bx^*)$, the condition number for the non-Euclidean gradient descent method (here, equivalent to Newton's method) is close to one, leading to accelerated convergence (see \eqref{equation:gree_cond_opt}).

\paragrapharrow{Newton's method via linearized optimality condition.}
In \eqref{equation:class_new_quadr}, we approximated the function $f(\bx^\toptzero+\bd)$ using a quadratic function. 
Similarly, given the optimality condition $\nabla f(\bx^*)=\bzero$, we can approximate $\nabla f(\bx^\toptzero +\bd)$ using an affine model:
$$
\nabla f(\bx^\toptzero +\bd)\approx \nabla f(\bx) + \nabla^2 f(\bx^\toptzero)\bd=\bzero.
$$ 
This formulation is equivalent to the Newton equation derived in \eqref{equation:newton_secon_approx_eq3}.


\paragrapharrow{Affine invariance of the Newton step.}
Let  $\bA\in\real^{n\times n}$ be a nonsingular matrix,  and define a transformed function $\widetildef(\by) \triangleq f(\bA\by)$. Then, for any $\bx=\bA\by$,
$$
\nabla \widetildef(\by) = \bA^\top\nabla f(\bx)
\qquad\text{and}\qquad
\nabla^2 \widetildef(\by) = \bA^\top\nabla^2 f(\bx)\bA.
$$
Therefore, the Newton step for $\widetildef$ at $\by$ is given by 
$$
\widetildebd_{\text{n}} = - \big(\bA^\top\nabla^2 f(\bx)\bA\big)^{-1}\bA^\top\nabla f(\bx) = \bA^{-1} \bd_{\text{n}}, 
$$ 
where $\bd_{\text{n}}$ is the Newton step for $f$ at $\bx$. 
This result shows that the Newton step is affine invariant:
$$
\bx+\bd_{\text{n}} = \bA (\by+\widetildebd_{\text{n}}).
$$

%\index{Spectral decomposition}
%\index{Reparametrization}
%\paragrapharrow{Reparametrization of the space around stationary points.}
%A {stationary point} is a point $\bx$ where the gradient of $f(\bx)$ vanishes. A useful reparametrization of the objective function $f$ {around stationary points} is derived from Taylor's expansion. Since the gradient vanishes, \eqref{equation:class_new_quadr} can be written as
%\begin{equation}
%	f(\bx+\bd) \approx f(\bx)  + \frac{1}{2} \bd^\top \nabla^2 f(\bx) \bd.
%\end{equation}
%Since the Hessian $\nabla^2 f(\bx)$ is symmetric, it admits the spectral decomposition 
%$
%\nabla^2 f(\bx)=\bQ\bLambda\bQ^\top \in \real^{n\times n},
%$
%where the columns of $\bQ = [\bq_1, \bq_2, \ldots , \bq_n]$ are the eigenvectors of $\nabla^2 f(\bx)$ and are mutually orthonormal, and the entries of $\bLambda = \diag(\lambda_1, \lambda_2, \ldots , \lambda_n)$ are the corresponding real eigenvalues of $\bA$ (Theorem~\ref{theorem:spectral_theorem}). We define the following vector $\bv$:
%$$
%\bv=
%\begin{bmatrix}
%	\bq_1^\top \\ \vdots \\ \bq_n^\top 
%\end{bmatrix}
%\bd=
%\bQ^\top \bd.
%$$
%Then the reparametrization follows
%\begin{equation}\label{equation:reparametrization-newton}
%	\begin{aligned}
%		f(\bx+\bd) &\approx f(\bx)  + \frac{1}{2} \bd^\top \nabla^2 f(\bx) \bd\\
%		&= f(\bx)  +  \frac{1}{2}  \bv^\top \bLambda \bv 
%		= f(\bx)  +  \frac{1}{2}  \sum_{i=1}^{n} \lambda_i ( v_i)^2,
%	\end{aligned}
%\end{equation}
%where $ v_i$ is the $i$-th element of $\bv$. A conclusion on the type of the stationary point follows immediately from the reparametrization:
%\begin{itemize}
%	\item If all eigenvalues are nonzero and positive, then the stationary point is a local minimum;
%	
%	\item If all eigenvalues are nonzero and negative, then the stationary point is a local maximum;
%	
%	\item If the eigenvalues are nonzero, and both positive and negative eigenvalues exist, then the stationary point is a saddle point.
%\end{itemize}
%This aligns with out conclusion in Remark~\ref{remark:charac_statpoint}.
%In vanilla GD, if an eigenvalue $\lambda_i$ is positive (resp. negative), then the step moves towards (resp. away) from $\bx$ along $ \bv$, guiding the GD towards an optimal point $\bx^*$. The step along any direction $\bq_i$ is given by $-\lambda_i v_i$. 
%In contrast, in Newton's method, the step is rescaled by the inverse Hessian, making the step along direction $\bq_i$ scaled into $- v_i$. This may cause problem when the eigenvalue is negative, resulting in the step moving in the \textit{opposite} direction compared to  vanilla GD \citep{dauphin2014identifying}. 
%
%The reparametrization shows that rescaling the gradient along the direction of each eigenvector can result in wrong direction when the eigenvalue $\lambda_i$ is negative. This suggests the rescale by its magnitude, i.e., scale by $1/|\lambda_i|$ rather than $1/\lambda_i$, preserving sign of the gradient and addressing the slowness issue of GD at the same time. From \eqref{equation:reparametrization-newton}, when both positive and negative eigenvalues exist, both vanilla GD and Newton's method may get stuck in saddle points, leading to suboptimal performance. However, scaling by $1/|\lambda_i|$ can partly solve this problem, since the movement around the saddle point can either increase  or decrease the loss from this rescaling, rather than stay where it is \citep{nocedal1999numerical, dauphin2014identifying}.
%
%\paragrapharrow{Damped Newton's Method.}
%Newton's method addresses the slowness problem by rescaling the gradients in each direction with the inverse of the corresponding eigenvalue, yielding the step $\Delta \bx_t = -\bH_t^{-1}\bg_t$ at iteration $t$. However, this approach can result in moving in an undesired  direction when the eigenvalue is negative, causing the  Newton's step to proceed along the eigenvector in a direction opposite to the gradient descent step and increasing the error. 
%
%To mitigate this issue, damping the Hessian is proposed, where negative curvature is eliminated by introducing a constant $\alpha$ to its diagonal, yielding the step $\Delta \bx_t= - (\bH+\alpha \mathbf{I})^{-1} \bg_t$. We can view $\alpha$ as the tradeoff between Newton's method and vanilla GD. When $\alpha$ is small, it is closer to Newton's method; when $\alpha$ is large, it is closer to vanilla GD. In this case, we get the step $-\frac{\lambda_i}{\lambda_i + \alpha}\Delta \bg_t$. 
%However, obviously, the drawback of damping Newton's method is evident{\textemdash}it may result in a small step size across many eigen-directions due to the influence of the large damping factor $\alpha$.
%
%
%\paragrapharrow{Levenberg (-Marquardt) Gradient Descent.}
%The quadratic rule is not universally better since it assumes a linear approximation of $f(\bx)$, which is only valid when it's in proximity to a minimum. The \textit{Levenberg gradient descent} goes further by combining the idea of damped Newton's method and vanilla GD. Initially, we can apply a steepest descent type method until we approach a minimum, prompting switching to the quadratic rule. The distance from a minimum is described by evaluating the loss \citep{levenberg1944method}. If the loss is increasing, the quadratic approximation is not working well and we are not likely near a minimum, yielding a larger $\alpha$ in damped Newton's method; while if the loss is decreasing, the quadratic approximation is working well and we are approaching a minimum, yielding a smaller $\alpha$ in damped Newton's method.
%
%Marquardt improved this method by incorporating the local curvature information. In this modification,  one replaces the identity matrix in Levenberg's method by the diagonal of the Hessian, resulting in the \textit{Levenberg-Marquardt gradient descent} \citep{marquardt1963algorithm}:
%$$
%\Delta \bx_t= - \bigg(\bH+\alpha \cdot \diag(\bH)\bigg)^{-1} \bg_t.
%$$
%The Levenberg-Marquardt gradient descent method is nothing more than a heuristic method since it is not optimal for any well defined criterion of speed or error measurements, and it is merely a well thought out optimization procedure. However, it is an optimization method that works extremely well in practice, especially for medium sized nonlinear models. 


\paragrapharrow{Equality-constrained Newton's method.}
We  apply Newton's method to problems with linear equality constraints, formulated as:
$$
\min_{\bx} f(\bx) \quad \text{s.t.} \quad \bA\bx = \bb.
$$
One approach to solving this problem is through dual optimization. However, a more direct method is the equality-constrained Newton's method. Initially, we choose $ \bx^{(1)} $ such that $ \bA\bx^{(1)} = \bb $. Then, we iteratively update our solution using:
$$
\bx^\toptone \leftarrow  \bx^\toptzero + \eta_t \bd^\toptzero,
$$
where $\bd^\toptzero$ is determined by minimizing:
$$
\bd^\toptzero = \argmin_{\bA\bd=\bzero} \nabla f(\bx^\toptzero)^\top(\bd - \bx^\toptzero) + \frac{1}{2}(\bd - \bx^\toptzero)^\top\nabla^2 f(\bx^\toptzero)(\bd - \bx^\toptzero)
$$
This process ensures that $ \bx^\toptone $ remains within the feasible set since $ \bA\bx^\toptone = \bA\bx^\toptzero + \eta_t\bA\bd^\toptzero = \bb + \bzero = \bb $.
Furthermore, $ \bd^\toptzero $ represents the solution for minimizing a quadratic function subject to equality constraints. From KKT conditions $ \bd^\toptzero $ satisfies
$$
\begin{bmatrix}
	\nabla^2 f(\bx^\toptzero) & \bA^\top \\
	\bA & \bzero
\end{bmatrix}
\begin{bmatrix}
	\bd^\toptzero \\
	\bv
\end{bmatrix}
=
\begin{bmatrix}
	-\nabla f(\bx) \\
	\bzero
\end{bmatrix}
$$
for some vector $ \bv $. 
Consequently, the Newton direction $ \bd^\toptzero $ is again found by solving a linear system involving the Hessian matrix (though this system is larger due to the inclusion of constraint information).



\subsection{Convergence Analysis}
Newton's method exhibits excellent local convergence properties.
We begin by demonstrating the quadratic rate of convergence of Newton's method for functions that are strongly convex and twice Lipschitz continuously differentiable.
\begin{theoremHigh}[Newton's method for SC and Lipschits Functions]\label{theorem:conv_new_sssc}
Let $ f:\real^n\rightarrow \real $ be a twice continuously differentiable function defined over $\real^n$. Assume that:
\begin{itemize}
\item $f$ is $\alpha$-strongly convex: $ \nabla^2 f(\bx) \geq \alpha \bI $ for any $ \bx \in \real^n $,
\item $f$ is twice Lipschitz continuously differentiable: $ \normtwo{\nabla^2 f(\bx) - \nabla^2 f(\by)} \leq L \normtwo{\bx - \by } $ for any $ \bx, \by \in \real^n $.
\end{itemize}
\noindent Let $ \{\bx^\toptzero\}_{t>0} $ be the sequence generated by Newton's method (Algorithm~\ref{alg:class_newton}), with $ \bx^* $ being the unique minimizer of $ f $ over $\real^n$. Then, for any $ t>0$, we have
\begin{subequations}
\begin{equation}\label{equation:conv_new_sssc_eq1}
\normtwobig{\bx^\toptone - \bx^*} \leq \frac{L}{2\alpha} \normtwobig{\bx^\toptzero - \bx^*}^2
\end{equation}
Additionally, if $ \normtwo{\bx^\topone - \bx^*} \leq \frac{\alpha}{L} $, then
\begin{equation}\label{equation:conv_new_sssc_eq2}
\normtwobig{\bx^\toptzero - \bx^*} \leq \frac{2\alpha}{L} \left( \frac{1}{2} \right)^{2^{t-1}}, \quad \forall t>0.
\end{equation}
\end{subequations}
In other words, Newton's method exhibits \textbf{quadratic convergence} (Definition~\ref{definition:quadratic-convergence}).
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:conv_new_sssc}]
For $t>0$, using the update rule of Newton's method, the fact that $\nabla  f(\bx^*)=\bzero$, and the fundamental theorem of calculus (Theorem~\ref{theorem:fund_theo_calculu}), we have 
$$
\small
\begin{aligned}
\bx^\toptone - \bx^* 
%&= \bx^\toptzero - \big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \nabla f(\bx^\toptzero) - \bx^* \\
&= \bx^\toptzero - \bx^* + \big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \big(\nabla f(\bx^*) - \nabla f(\bx^\toptzero)\big) \\
&= \bx^\toptzero - \bx^* + \big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \int_0^1 \big[\nabla^2 f\big(\bx^\toptzero + \mu(\bx^* - \bx^\toptzero)\big) - \nabla^2 f(\bx^\toptzero)\big] (\bx^* - \bx^\toptzero) \, d\mu \\
&= \big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \int_0^1 \big[\nabla^2 f\big(\bx^\toptzero + \mu(\bx^* - \bx^\toptzero)\big) - \nabla^2 f(\bx^\toptzero)\big] (\bx^* - \bx^\toptzero) \, d\mu.
\end{aligned}
$$
The $\alpha$-strongly convexity of $f$ implies that $\normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \leq \frac{1}{\alpha}$. 
From the above equality, using Cauchy-Schwartz inequality (Proposition~\ref{proposition:cauchy-schwarz-inequ}),
$$
\small
\begin{aligned}
\normtwobig{\bx^\toptone - \bx^*} 
&\leq \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \normtwo{\int_0^1 \big[\nabla^2 f\big(\bx^\toptzero + \mu(\bx^* - \bx^\toptzero)\big) - \nabla^2 f(\bx^\toptzero)\big] (\bx^* - \bx^\toptzero) \, d\mu} \\
&\leq \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \int_0^1 \normtwo{\big[\nabla^2 f\big(\bx^\toptzero + \mu(\bx^* - \bx^\toptzero)\big) - \nabla^2 f(\bx^\toptzero)\big] (\bx^* - \bx^\toptzero) } \, d\mu \\
&\leq \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \int_0^1 \normtwo{\nabla^2 f\big(\bx^\toptzero + \mu(\bx^* - \bx^\toptzero)\big) - \nabla^2 f(\bx^\toptzero)} \cdot \normtwo{\bx^* - \bx^\toptzero} \, d\mu \\
&\leq \frac{L}{\alpha} \normtwobig{\bx^\toptzero - \bx^*}^2\int_0^1 \mu  \, d\mu = \frac{L}{2\alpha} \normtwobig{\bx^\toptzero - \bx^*}^2.
\end{aligned}
$$
This proves the claim in \eqref{equation:conv_new_sssc_eq1}.
To prove \eqref{equation:conv_new_sssc_eq2}, we use induction on $ t $. Note that for $ t = 1 $, we assumed that
$
\normtwo{\bx^\topone - \bx^*} \leq \frac{\alpha}{L},
$
which implies
$$
\normtwo{\bx^\topone - \bx^*} \leq \frac{2\alpha}{L} \left( \frac{1}{2} \right)^{2^0}.
$$
Assume that \eqref{equation:conv_new_sssc_eq2} holds for an integer $ t $, that is,
$
\normtwobig{\bx^\toptzero - \bx^*} \leq \frac{2\alpha}{L} \left( \frac{1}{2} \right)^{2^{t-1}}
$.
We will show it also holds for $ t + 1 $. By \eqref{equation:conv_new_sssc_eq1} we have
$$
\normtwo{\bx^\toptone - \bx^*} \leq \frac{L}{2\alpha} \normtwobig{\bx^\toptzero - \bx^*}^2 \leq \frac{L}{2\alpha} \left( \frac{2\alpha}{L} \left( \frac{1}{2} \right)^{2^{t-1}} \right)^2 = \frac{2\alpha}{L} \left( \frac{1}{2} \right)^{2^{t}}.
$$
This completes the proof.
\end{proof}
The result indicates that Newton's method converges quadratically only when $ \normtwo{\bx^\topone - \bx^*} \leq \frac{\alpha}{L} $ for strongly convex and twice Lipschitz continuously differentiable functions. Therefore, the initial guess significantly affects the performance of Newton's method.

More generally, we have the following local convergence result of Newton's method.
\begin{theoremHigh}[Local Convergence of   Newton's Method]\label{theorem:conv_classNewton}
Let $ f:\real^n\rightarrow \real $ be a twice continuously differentiable function, and let the Hessian matrix be $L$-Lipschitz continuous in a neighborhood $ \sB(\bx^*, \varepsilon) $ of the optimal point $ \bx^* $:
$$
\normtwo{\nabla^2 f(\bx) - \nabla^2 f(\by)} \leq L \normtwo{\bx - \by}, \quad \forall \bx, \by \in \sB(\bx^*, \varepsilon).
$$
If the function $ f(\bx) $ satisfies $ \nabla f(\bx^*) = \bzero $ and $ \nabla^2 f(\bx^*) \succ \bzero $ at the point $ \bx^* $, then  Newton's method (Algorithm~\ref{alg:class_newton}) follows:
\begin{enumerate}[(i)]
\item If the initial point is sufficiently close to $ \bx^* $, the sequence $ \{\bx^\toptzero\} $ generated by Newton's method converges to $ \bx^* $.
\item The sequence $ \{\bx^\toptzero\} $ converges to $ \bx^* $ \textbf{quadratically} (Definition~\ref{definition:quadratic-convergence}).
\item The sequence $ \big\{\normtwobig{\nabla f(\bx^\toptzero)}\big\} $ converges to $\bzero$ \textbf{quadratically}.
\end{enumerate}
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:conv_classNewton}]
\textbf{(i, ii).}
From the update rule and the property of the optimal point $ \bx^* $ that $ \nabla f(\bx^*) = \bzero $, we obtain:
\begin{equation}\label{equation:conv_classNewton11}
\small
\begin{aligned}
\normtwo{\bx^\toptone - \bx^*} &= \normtwo{\bx^\toptzero - \big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \nabla f(\bx^\toptzero) - \bx^*} \\
&= \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1} \left[ \nabla^2 f(\bx^\toptzero) (\bx^\toptzero - \bx^*) - \big(\nabla f(\bx^\toptzero) - \nabla f(\bx^*)\big) \right]}\\
&\leq \normtwobig{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \normtwo{\nabla^2 f(\bx^\toptzero) (\bx^\toptzero - \bx^*) - \big(\nabla f(\bx^\toptzero) - \nabla f(\bx^*)\big) }
\end{aligned}
\end{equation}
By the fundamental theorem of calculus Theorem~\ref{theorem:fund_theo_calculu}\eqref{equation:fund_theo_calculu1}, we have:
$$
\nabla f(\bx^\toptzero) - \nabla f(\bx^*) = \int_0^1 \nabla^2 f\big(\bx^* + \mu(\bx^\toptzero - \bx^*)\big)  \, d\mu\,(\bx^\toptzero - \bx^*),
$$
Thus, assuming $\bx^\toptzero\in \sB(\bx^*, \varepsilon)$, the second term in \eqref{equation:conv_classNewton11} follows:
\begin{equation}\label{equation:conv_classNewton22}
\small
\begin{aligned}
&\quad \normtwo{\nabla^2 f(\bx^\toptzero) (\bx^\toptzero - \bx^*) - \big(\nabla f(\bx^\toptzero) - \nabla f(\bx^*)\big)} \\
&= \normtwo{\int_0^1 \left[ \nabla^2 f\big(\bx^* + \mu(\bx^\toptzero - \bx^*)\big) - \nabla^2 f(\bx^\toptzero) \right] \, d\mu \, \cdot   (\bx^\toptzero - \bx^*)} \\
&\stackrel{\dag}{\leq} \int_0^1 \normtwo{\nabla^2 f\big(\bx^* + \mu(\bx^\toptzero - \bx^*)\big) - \nabla^2 f(\bx^\toptzero)}  \, d\mu \,\cdot  \normtwobig{\bx^\toptzero - \bx^*} \\
&\stackrel{\ddag}{\leq} L\normtwobig{\bx^\toptzero - \bx^*}^2 \int_0^1  \mu \, d\mu 
= \frac{L}{2} \normtwobig{\bx^\toptzero - \bx^*}^2,
\end{aligned}
\end{equation}
where the inequality ($\dag$) follows from the Cauchy-Schwartz inequality (Proposition~\ref{proposition:cauchy-schwarz-inequ}), the inequality ($\ddag$) follows from the Lipschitzness of the Hessian matrix.


Since  $ f $ is twice continuously differentiable, its Hessian $ \nabla^2 f(\bx) $ is a continuous function of $ \bx $. In particular, this means that for any point $ \bx^* $, there exists a neighborhood around $ \bx^* $ where $ \nabla^2 f(\bx) $ is close to $ \nabla^2 f(\bx^*) $ in norm.
Since $ \nabla^2 f(\bx^*) $ is nonsingular, its inverse $ \big(\nabla^2 f(\bx^*)\big)^{-1} $ exists. Moreover, the nonsingularity implies that $ \nabla^2 f(\bx) $ is invertible for all $ \bx $ sufficiently close to $ \bx^* $, because the determinant of $ \nabla^2 f(\bx) $ will not be zero in a small neighborhood around $ \bx^* $.
The map $ \bA \mapsto \bA^{-1} $ is continuous for nonsingular matrices. Specifically, if $ \normtwo{\bA - \bB} $ is small, then $ \normtwo{\bA^{-1} - \bB^{-1}} $ is also small. For $ \nabla^2 f(\bx) $ near $ \nabla^2 f(\bx^*) $, the continuity ensures that $ (\nabla^2 f(\bx))^{-1} $ will remain close to $ \big(\nabla^2 f(\bx^*)\big)^{-1} $.
Since $ \big(\nabla^2 f(\bx^*)\big)^{-1} $ is bounded (as $ \nabla^2 f(\bx^*) $ is nonsingular), the continuity of the inverse ensures that there exists a radius $ \varepsilon_1 > 0 $ such that for all $ \bx^\toptzero $ satisfying $ \bx^\toptzero \in \sB(\bx^*, \varepsilon_1) $, the norm $ \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} $ is close to $ \normtwo{\big(\nabla^2 f(\bx^*)\big)^{-1}} $. Specifically, one can choose $ \varepsilon_1 $ small enough that $ \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \leq 2 \normtwo{\big(\nabla^2 f(\bx^*)\big)^{-1}} $. The factor ``2" comes from choosing a sufficiently small neighborhood around $ \bx^* $ where the deviation of $ \nabla^2 f(\bx^\toptzero) $ from $ \nabla^2 f(\bx^*) $ is controlled. The continuity of $ \nabla^2 f(\bx^\toptzero) $ and its inverse guarantees this bound.
Combining \eqref{equation:conv_classNewton11},  \eqref{equation:conv_classNewton22}, and $ \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}} \leq 2 \normtwo{\big(\nabla^2 f(\bx^*)\big)^{-1}} $, we get:
\begin{equation}\label{equation:conv_classNewton33}
\normtwo{\bx^\toptone - \bx^*} \leq L \normtwo{\nabla^2 f(\bx^*)^{-1}} \normtwobig{\bx^\toptzero - \bx^*}^2.
\end{equation}
Therefore, if the initial point $ \bx^{(1)} $ satisfies
$
\normtwo{\bx^{(1)} - \bx^*} \leq \min \left\{ \varepsilon, \varepsilon_1 \right\} \triangleq \widehat{\varepsilon},
$
then \eqref{equation:conv_classNewton33} shows the sequence $ \{\bx^\toptzero\} $ remains within the neighborhood $ \sB(\bx^*, \widehat{\varepsilon}) $, and thus $ \{\bx^\toptzero\} $ converges quadratically to $ \bx^* $.

\paragraph{(iii).}
From the Newton equation~\eqref{equation:newton_secon_approx_eq3}, $\nabla^2 f(\bx^\toptzero) \bd^\toptzero +\nabla f(\bx^\toptzero) =\bzero$, the update rule $\bx^\toptone \leftarrow \bx^\toptzero + \bd^\toptzero$, and the fundamental theorem of calculus Theorem~\ref{theorem:fund_theo_calculu}\eqref{equation:fund_theo_calculu1},  we have:
$$
\small
\begin{aligned}
\normtwo{\nabla f(\bx^\toptone)} 
&= \normtwo{\nabla f(\bx^\toptone) - \nabla f(\bx^\toptzero) - \nabla^2 f(\bx^\toptzero) \bd^\toptzero} \\
&= \normtwo{\int_0^1 \nabla^2 f(\bx^\toptzero + \mu \bd^\toptzero) \bd^\toptzero d\mu - \nabla^2 f(\bx^\toptzero) \bd^\toptzero} \\
&\leq \int_0^1 \normtwo{\nabla^2 f(\bx^\toptzero + \mu \bd^\toptzero) - \nabla^2 f(\bx^\toptzero)} \normtwobig{\bd^\toptzero} d\mu 
\leq \frac{L}{2} \normtwobig{\bd^\toptzero}^2 \\
&\leq \frac{L}{2}  \normtwo{\big(\nabla^2 f(\bx^\toptzero)\big)^{-1}}^2 \normtwobig{\nabla f(\bx^\toptzero)}^2 
\leq 2 L \normtwo{\nabla^2 f(\bx^*)^{-1}}^2 \normtwobig{\nabla f(\bx^\toptzero)}^2.
\end{aligned}
$$
This proves that the sequence $ \big\{\normtwobig{\nabla f(\bx^\toptzero)}\big\} $ converges to $\bzero$ quadratically.
\end{proof}


Theorem~\ref{theorem:conv_classNewton} states that  Newton's method is a fast-converging algorithm, but its convergence is conditional. First, the initial point $ \bx^{(1)} $ must be sufficiently close to the solution of the problem; in other words, Newton's method exhibits only local convergence. 
When $ \bx^{(1)} $ is far from the solution, Newton's method often fails. Second, the Hessian matrix $ \nabla^2 f(\bx^*) $ needs to be positive definite. There exist examples where, if $ \nabla^2 f(\bx^*) $ is singular or positive semidefinite, the convergence rate of Newton's method may only reach linearly. 
In the proof of Theorem~\ref{theorem:conv_classNewton}, it can be seen that the condition number of the problem does not significantly affect the convergence speed of Newton's method; the Lipschitz constant $ L $ is usually dominated by $ \normtwobig{\bx^\toptzero - \bx^*} $ in later iterations. However, for ill-conditioned problems, the convergence domain of Newton's method may shrink, imposing stricter requirements on the choice of the initial value.

On the other hand, if exact line search is applicable, Newton's method with exact line search (Algorithm~\ref{alg:class_newton_exctline}) is guaranteed to converge globally under mild conditions.
\begin{algorithm}[h] 
\caption{Newton's Method with Exact Line Search}
\label{alg:class_newton_exctline}
\begin{algorithmic}[1] 
\Require A twice continuously differentiable function $f(\bx)$; 
\State {\bfseries Input:} Initialize $\bx^{(1)}$;
\For{$t=1,2,\ldots$}
\State $\bd_{\text{n}}^\toptzero \leftarrow $ solution of $\nabla^2 f(\bx^\toptzero) \bd = -\nabla f(\bx^\toptzero)$;
\State $\eta_t\leftarrow \argmin_{\eta} f(\bx^\toptzero +\eta\bd_{\text{n}}^\toptzero)$; \Comment{exact line search}
\State $\bx^\toptone \leftarrow \bx^\toptzero + \eta_t\bd_{\text{n}}^\toptzero$;
\EndFor
\State {\bfseries Return:}   final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic} 
\end{algorithm}

\begin{theoremHigh}[Global Convergence of Newton's Method with Exact Line Search]\label{theorem:newton_exactline}
Let $f: \real^n \rightarrow \real$ be twice continuously differentiable on an open convex set $\sS \subset \real^n$. Assume that $f$ is $\alpha$-strongly convex such that $f(\bx)$ satisfies
\begin{equation}
\bu^\top \nabla^2 f(\bx) \bu \geq \alpha \normtwo{\bu}^2, \; \forall \bu \in \real^n, \bx \in \sL,
\end{equation}
where $\sL \triangleq \lev[f, \bx^{(1)}]= \{\bx \in\sS \mid f(\bx) \leq f(\bx^{(1)})\}$ is the corresponding level set. Then the sequence $\{\bx^\toptzero\}$ generated by Newton's method with exact line search (Algorithm~\ref{alg:class_newton_exctline}) satisfies
\begin{enumerate}
\item When $\{\bx^\toptzero\}$ is a finite sequence, then $\nabla f(\bx^\toptzero) = \bzero$ for some $t$;
\item When $\{\bx^\toptzero\}$ is an infinite sequence, then $\{\bx^\toptzero\}$ converges to the unique minimizer $\bx^*$ of $f$.
\end{enumerate}
\end{theoremHigh}

\begin{proof}[of Theorem~\ref{theorem:newton_exactline}]
Since $f$ is $\alpha$-SC, by Theorem~\ref{theorem:exi_close_sc}, its stationary point is the unique global minimizer.
On the other hand, since the level set $\sL$ is a bounded closed convex set and the sequence $\{f(\bx^\toptzero)\}$ is monotonically decreasing, it follows that $\{\bx^\toptzero\} \subset \sL$ and $\{\bx^\toptzero\}$ is bounded. Therefore there exists a limit point $\widetildebx \in \sL$ with $\bx^\toptzero \rightarrow \widetildebx$, and further $f(\bx^\toptzero) \rightarrow f(\widetildebx)$. By Theorem~\ref{theorem:conv_line_search}, we have $\nabla f(\bx^\toptzero) \rightarrow \nabla f(\widetildebx) = \bzero$. Finally, since the stationary point is unique, then the whole sequence $\{\bx^\toptzero\}$ converges to $\widetildebx$ which is the unique minimizer.
\end{proof}



In summary, Newton's method is suitable for high-precision solutions to optimization problems, but it lacks global convergence properties. Therefore, in practical applications, gradient-based methods are often used initially to obtain a low-precision solution, which is then refined using Newton's method for higher precision.
The advantages and disadvantages of Newton's method are summarized in Remark~\ref{remark:procon_newton}.
\begin{remark}[Pros and Cons of Newton's Method]\label{remark:procon_newton}
\textbf{Advantages}
\begin{enumerate}[(i)]
	\item Quadratically convergent from a good starting point if $\nabla f^2(\bx^*)$ is positive definite.
	\item Simple and easy to implement.
\end{enumerate}

\textbf{Disadvantages}
\begin{enumerate}[(i)]
	\item Not globally convergent for many problems.
	\item May converge towards a maximum or saddle point of $f$.
	\item The system of linear equations to be solved in each iteration may be ill-conditioned or singular.
	\item Requires analytic second-order derivatives of $f$.
\end{enumerate}
\end{remark}



\subsection{Modified and Damped Newton Method}\label{section:modified_damp_new}

Although we have proposed Newton's method in Algorithm~\ref{alg:class_newton} and analyzed its theoretical properties, this approach is almost impractical for real-world applications due to several limitations:
\begin{enumerate}
\item Each iteration requires solving an $ n $-dimensional linear system, which leads to large computational costs in high-dimensional problems. The Hessian matrix $ \nabla^2 f(\bx^\toptzero) $ is not only difficult to compute but also challenging to store.

\item When $ \nabla^2 f(\bx^\toptzero) $ is not positive definite, the solution $ \bd^\toptzero $ derived from the Newton equation~\eqref{equation:newton_secon_approx_eq3} is usually poor. For example, when the Hessian matrix is positive definite, $ \bd^\toptzero $ may be unsatisfactory. For instance, when the Hessian matrix is positive definite, $\bd^\toptzero$ serves as a descent direction (Theorem~\ref{theorem:uncons_des_dir}); however, in other cases, it might not be so.

\item When the current point is far from the optimal solution, choosing the stepsize $\eta_t = 1$ directly can lead to significant instability, potentially causing the sequence of iterations to diverge.
\end{enumerate}



To address these issues, modifications to the pure Newton's method are necessary to make it more practical. We introduce the \textit{modified Newton method with line search}. The core idea is to adjust the Hessian matrix  $\nabla^2 f(\bx^\toptzero)$ to ensure it is positive definite and has a smaller condition number. Additionally, incorporating line search improves the stability of the algorithm. The general framework is presented in Algorithm~\ref{alg:modified_newton}.

\begin{algorithm}[H] 
\caption{Modified Newton Method with Line Search}
\label{alg:modified_newton}
\begin{algorithmic}[1] 
\Require A twice continuously differentiable function $f(\bx)$; 
\State {\bfseries Input:} Initialize $\bx^{(1)}$;
\For{$t=1,2,\ldots$}
\State \algoalign{Determine a correction matrix $\bP^\toptzero$ such that $\bB^\toptzero \triangleq \nabla^2 f(\bx^\toptzero) + \bP^\toptzero$ is positive definite and has a small condition number;}
\State Solve the modified Newton equation $\bB^\toptzero \bd = -\nabla f(\bx^\toptzero)$ to obtain direction $\bd^\toptzero$;
\State Use any line search rule to determine the stepsize $\eta_t$;
\State $\bx^\toptone \leftarrow \bx^\toptzero + \eta_t \bd^\toptzero$;
\EndFor
\State {\bfseries Return:}   final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic} 
\end{algorithm}


\paragrapharrow{Damped Newton method.}
The critical aspect in Algorithm~\ref{alg:modified_newton} is selecting the correction matrix $\bP^\toptzero$. One straightforward choice is to take $\bP^\toptzero \triangleq \mu_t \bI$, i.e., $\bP^\toptzero$ is a scalar multiple of the identity matrix. 
Methods using this approach are known as \textit{damped Newton methods}. 
According to matrix theory, when $\mu_t$ is sufficiently large, $\bB^\toptzero$ will always be  positive definite. 
However,  $\mu_t$ should not be excessively large because, as $\mu_t$ approaches infinity, the direction $\bd^\toptzero_{\text{dn}}$ converges towards the negative gradient direction. 
A more suitable choice involves estimating the smallest eigenvalue of $\nabla^2 f(\bx^\toptzero)$ and then appropriately determining  $\mu_t$.
In this context, instead of finding the step as a stationary point of the quadratic \eqref{equation:class_new_quadr}, the direction $\bd^\toptzero_{\text{dn}}$ is determined as a stationary point of
\begin{equation}\label{equation:modify_new_quadr}
g_{\mu_t}(\bd) \triangleq g_t(\bd) +  \frac{1}{2}  \mu_t\bd^\top\bd
= f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} \bd^\top \big(\nabla^2 f(\bx^\toptzero )+\mu_t\bI\big) \bd.
\end{equation}
When $\mu_t > \min\{\lambda_{\min}, 0\}$, where $\lambda_{\min}$ is the smallest eigenvalue of $\nabla^2 f(\bx^\toptzero )$, Theorem~\ref{theorem:eigen_charac} shows that $\nabla^2 f(\bx^\toptzero )+\mu_t\bI$ is positive definite. Therefore, the function $g_{\mu_t}(\bd)$ becomes a convex function, and $\bd^\toptzero_{\text{dn}}$ is not only a stationary point, but also a minimizer of $g_{\mu_t}$. And Theorem~\ref{theorem:uncons_des_dir} shows that $\bd^\toptzero_{\text{dn}}$ is a descent direction.

To be more specific,
from the \textit{damped Newton equation} 
\begin{equation}\label{equation:damped_newton_eq}
\bd^\toptzero_{\text{dn}} \leftarrow \text{ solution of }\big(\nabla^2 f(\bx^\toptzero )+\mu_t\bI\big) \bd = -\nabla f(\bx^\toptzero),
\end{equation}
if $\mu_t$ is large, the direction $\bd^\toptzero_{\text{dn}}\approx  -\frac{1}{\mu_t} \nabla f(\bx^\toptzero)$ represents a short step in the steepest descent direction. 
This approach is particularly useful in the early stages of the iteration process when the current point  $\bx^\toptzero$ is far from the minimizer $\bx^*$ \citep{frandsen1999unconstrained}.
Conversely, if $\mu_t$ is small, then $\bd^\toptzero_{\text{dn}}$ closely resembles the classical Newton step, which is advantageous when $\bx^\toptzero$ is near $\bx^*$ (Theorem~\ref{theorem:conv_classNewton}). 
Thus, by appropriately adjusting the damping parameter $\mu_t$, we obtain a method that combines the global convergence properties of the steepest descent method with the fast local convergence of  Newton's method.

\paragrapharrow{Levenberg-Marquardt  damped Newton method.}
An interesting relation between a trust region approach (Section~\ref{section:trs_intro} or Section~\ref{section:des_trust_reg}) and Algorithm~\ref{alg:modified_newton} is provided by the following theorem, originally presented by \citet{marquardt1963algorithm}.
\begin{theorem}[Damped Newton as Trust Region Approach]\label{theorem:damped_trust}
Let $f:\real^n\rightarrow \real^n$ be a twice continuously difference function.
If the matrix $ \nabla^2 f(\bx^\toptzero) + \mu_t \bI $ is positive definite, then
$$
\bd_{\text{dn}}^\toptzero = \mathop{\argmin}_{\normtwo{\bd} \leq \normtwobig{\bd^\toptzero_{\text{dn}}}} \{ g_t(\bd) \},
$$
where $ g_t $ is given by \eqref{equation:class_new_quadr} and $ \bd_{\text{dn}}^\toptzero $ is obtained by the damped Newton equation $\big(\nabla^2 f(\bx^\toptzero)+\mu_t\bI\big) \bd = -\nabla f(\bx^\toptzero)$.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:damped_trust}]
For any $\mu_t \geq 0$,  let $g_{\mu_t}(\bd) \triangleq g_t(\bd) + \frac{1}{2} \mu_t \bd^\top \bd$. The gradient of $ g_{\mu_t} $ is
$$
\nabla g_{\mu_t}(\bd) \triangleq \nabla  g_t(\bd) + \mu_t \bd \triangleq \bg^\toptzero + (\bH^\toptzero + \mu_t \bI) \bd,
$$
where $ \bg^\toptzero \triangleq \nabla f(\bx^\toptzero) $ and $ \bH^\toptzero \triangleq \nabla^2 f(\bx^\toptzero) $. Since $ \bH^\toptzero + \mu_t \bI $ is positive definite,  the linear system of equations $ \nabla g_{\mu_t}(\bd) = \bzero $ has a unique solution, which is the minimizer of $ g_{\mu_t} $. This solution is recognized as $ \bd_{\text{dn}}^\toptzero $.

On the other hand, let
$
\widetildebd \triangleq \mathop{\argmin}_{\normtwo{\bd} \leq \normtwo{\bd_{\text{dn}}^\toptzero}} \{ g_t(\bd) \}.
$
Then, $ g_t(\widetildebd) \leq g_t(\bd_{\text{dn}}^\toptzero) $ and $ \widetildebd^\top \widetildebd \leq \bd_{\text{dn}}^\toptzeroTOP \bd_{\text{dn}}^\toptzero $, so that
$$
g_{\mu_t}(\widetildebd) = g_t(\widetildebd) + \frac{1}{2} \mu_t \widetildebd^\top \widetildebd \leq g_t(\bd_{\text{dn}}^\toptzero) + \frac{1}{2} \mu_t \bd_{\text{dn}}^\toptzeroTOP \bd_{\text{dn}}^\toptzero = g_{\mu_t}(\bd_{\text{dn}}^\toptzero).
$$
However, $ \bd_{\text{dn}}^\toptzero $ is the unique minimizer of $ g_{\mu_t} $, so $ \widetildebd = \bd_{\text{dn}}^\toptzero $.
This completes the proof.
\end{proof}


In a proper trust region method, we monitor the trust region radius $ \Delta_t $ at each iteration. 
The above theorem indicates that if we instead monitor the damping parameter, we can interpret this approach as a trust region method where the trust region radius is implicitly defined as $ \Delta_t = \normtwobig{\bd_{\text{dn}}^\toptzero} $.

For  Levenberg-Marquardt type methods, $ \mu_t $ is updated during each iteration. 
Given the current value of the parameter, the Cholesky factorization of $ \nabla^2 f(\bx^\toptzero) + \mu_t \bI $ is used  to check for positive definiteness (see, for example, \citet{lu2021numerical} for more details), and $ \mu_t $ is increased if the matrix is not sufficiently  positive definite. Otherwise, the solution $ \bd_{\text{dn}}^\toptzero $ is efficiently obtained through the factorization (using forward and backward substitution procedures).

The direction provided  by $ \bd_{\text{dn}}^\toptzero $ ensures a descent direction, leading to the ``trial point" $ \bx^\toptzero + \bd_{\text{dn}}^\toptzero $ (corresponding to $ \eta_t = 1 $ in Algorithm~\ref{alg:modified_newton}). As in a trust region method (Section~\ref{section:des_trust_reg}), we evaluate the cost function at the trial point, i.e., $ f(\bx^\toptzero + \bd_{\text{dn}}^\toptzero) $. If it is sufficiently below $ f(\bx^\toptzero) $, then the trial point is chosen as the next iterate. 
Otherwise, $ \bx^\toptzero $ remains the current iterate (corresponding to $ \eta_t = 0 $ in Algorithm~\ref{alg:modified_newton}), and $ \mu_t $ is increased. 
Simply checking whether $ f(\bx^\toptzero + \bd_{\text{dn}}^\toptzero) < f(\bx^\toptzero) $ is insufficient; to ensure overall convergence, it is necessary to test if the actual decrease in the function value is greater than some small fraction of the decrease predicted by the quadratic model \eqref{equation:class_new_quadr}, i.e., if
$$
\nu_t \triangleq \frac{f(\bx^\toptzero) - f(\bx^\toptzero + \bd_{\text{dn}}^\toptzero)}{g_t(\bzero) - g_t(\bd_{\text{dn}}^\toptzero)} > \delta,
$$
where $ \delta $ is a small positive number (typically $ \delta = 10^{-3} $).
We recognize $ \nu_t $ as the \textit{gain factor}. It is also used to monitor $ \mu_t $: 
\begin{itemize}
\item If $ \nu_t $ is close to one, then one may expect the model to be a good approximation to $ f $ in a neighbourhood of $ \bx^\toptzero $, which is large enough to include the trial point, and the influence of Newton's method should be increased by decreasing $ \mu_t $. 
\item If, on the other hand, the actual decrease of $ f $ is much smaller than expected, then $ \mu_t $ must be increased in order to adjust the method more towards the steepest descent method. It is important to note that in this case the length of $ \bd_{\text{dn}}^\toptzero $ is also reduced, since $\bd^\toptzero_{\text{dn}}\approx  -\frac{1}{\mu_t} \nabla f(\bx^\toptzero)$ when $\mu_t$ is large.
\end{itemize}
An updating strategy similar to the one used in Algorithm~\ref{alg:trust_region0} could be:
\begin{equation}\label{equation:newtrs_up1}
\text{(UP1)}:\qquad
\boxed{\begin{aligned}
	&\text{if } \nu_t > 0.75 \\
	&\qquad\mu_{t+1} \leftarrow  \frac{1}{3}\mu_t; \\
	&\text{if } \nu_t < 0.25 \\
	&\qquad\mu_{t+1} \leftarrow  2\cdot \mu_t ;
\end{aligned}}
\end{equation}
However, abrupt  changes in $ \mu_t $ when $ \nu_t $ is near  0.25 or 0.75 can cause ``flutter," slowing down convergence.  Therefore, \citet{nielsen1999damping, frandsen1999unconstrained, madsen2004methods}  recommend using a smoother strategy:
\begin{equation}\label{equation:newtrs_up2}
\text{(UP2)}:\qquad
\boxed{\begin{aligned}
	&\text{if } \nu_t > 0 \\
	&\qquad\mu_{t+1} \leftarrow   \max\left\{\frac{1}{3}, 1 - (2\nu_t - 1)^3\right\} \cdot \mu_t ;\\
	&\text{else} \\
	&\qquad\mu_{t+1} \leftarrow 2\cdot \mu_t;
\end{aligned}}
\end{equation}
Refer to Figure~\ref{fig:newton_trust_reg} for a graphical illustration. The outlined method is detailed in  Algorithm~\ref{algorithm:leve_dam_new}.
Following \eqref{equation:des_stopcri1} and \eqref{equation:des_stopcri2}, the stopping criteria can be either
$$
\norminf{\nabla f(\bx^\toptzero)} \leq \varepsilon_1 \qquad \text{ or } \qquad \normtwo{\bd_{\text{dn}}} \leq \varepsilon_2 (\varepsilon_2 + \normtwobig{\bx^\toptzero}). 
$$
While the simplicity of the original Newton's method has been lost in the pursuit of global convergence, this method generally performs well.
\begin{SCfigure}%[h]
\centering
\includegraphics[width=0.5\textwidth]{./imgs/newton_trust_reg.pdf} 
\caption{Updating of the damping parameter $ \mu_{t+1} $ by \eqref{equation:newtrs_up1} (dashed line) and by \eqref{equation:newtrs_up2} (solid line).}
\label{fig:newton_trust_reg}
\end{SCfigure}






\begin{algorithm}[h]
\caption{Levenberg-Marquardt Damped Newton Method \citep{goldfeld1966maximization, madsen2010and}}
\label{algorithm:leve_dam_new}
\begin{algorithmic}[1]
\Require A twice continuously differentiable function $f(\bx)$; 
\State {\bfseries Input:}  Initialize $\bx^{(1)}, \mu_1$, and $ \delta$ (by default $\delta\triangleq 10^{-3}$);
\For{$t=1,2,\ldots$}
\While{$\nabla^2 f(\bx^\toptzero) + \mu_t \bI$ is not positive definite}
\State $\mu_t \leftarrow 2\mu_t$
\EndWhile
\State $\bd_{\text{dn}}^\toptzero\leftarrow $ solution of  $(\nabla^2 f(\bx^\toptzero) + \mu_t \bI) \bd = -\nabla f(\bx^\toptzero)$;
\State Compute gain factor $\nu_t$;
\If{$\nu_t > \delta$} \Comment{$f$ decreases}
\State $\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{dn}}^\toptzero$ \Comment{new iterate}
\State $\mu_{t+1} \leftarrow  \max\left\{\frac{1}{3}, 1 - (2\nu_t - 1)^3\right\} \cdot \mu_t$ 
\Else
\State $\bx^\toptone \leftarrow \bx^\toptzero $;  \Comment{old iterate}
\State $\mu_{t+1} \leftarrow 2\cdot \mu_t $;
\EndIf
\EndFor
\State {\bfseries Return:}   final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic}
\end{algorithm}


\paragrapharrow{Gill-Murray's modified Cholesky factorization.}
Another way to choose the correction matrix $\bP^\toptzero$ is implicitly through modifying the Cholesky decomposition to solve the Newton equation~\eqref{equation:newton_secon_approx_eq3} \citep{gill1974newton, gill2019practical}. We know that when the Hessian matrix is positive definite, Equation~\eqref{equation:newton_secon_approx_eq3} can be  easily solved using Cholesky decomposition (Theorem~\ref{theorem:cholesky-factor-exist}, using forward and backward substitutions). 
However, if the Hessian matrix is indefinite or has a high condition number (the ratio of the largest to smallest eigenvalues), the standard Cholesky decomposition may fail.
The \textit{modified Cholesky decomposition} algorithm adjusts the basic Cholesky decomposition algorithm  to ensure the decomposed matrix remains close to the original matrix while their product is positive definite.

To be more specific, for any  positive definite matrix $\bA = \{a_{ij}\}$, its Cholesky decomposition can be written as
$ \bA = \bL\bD\bL^\top, $
where $\bL = \{l_{ij}\}$ is a unit lower triangular matrix with diagonal elements all equal to 1, and $\bD = \diag(d_{11}, d_{22}, \ldots, d_{nn})$ is a diagonal matrix with positive diagonal elements.  
Based on the form of Cholesky decomposition in  Algorithm~\ref{alg:compute-choklesky-_ldl}, if $\bA$ is positive definite with a small condition number, the diagonal elements of matrix $\bD$ should not be too small (Problem~\ref{problem:cond_pd}). If during the computation process, $d_{jj}$ for any $j\in\{1,2,\ldots,n\}$ is found to be too small, it must be corrected immediately. 
Additionally, we need to ensure that the corrections are bounded so that the elements of the modified matrix also have upper bounds. Specifically, two positive parameters $\alpha, \beta$ are chosen such that
$$ 
d_{jj} \geq \alpha>0, \quad r_{ij}\triangleq l_{ij} \sqrt{d_{jj}} \leq \beta, \quad i = j + 1, j + 2, \ldots, n. 
$$
In Algorithm~\ref{alg:compute-choklesky-_ldl}, only the update of $ d_{jj} $ needs modification to meet these conditions.  
The specific update rule is equivalent to updating each $d_{jj}$ in Algorithm~\ref{alg:compute-choklesky-_ldl} by
$$ 
d_{jj} \leftarrow \max \left\{ |c_{jj}|, \left( \frac{\theta_j}{\beta} \right)^2, \alpha \right\}, \quad \theta_j = \max_{i > j} |c_{ij}|. 
$$
It can be demonstrated that the modified Cholesky decomposition algorithm effectively computes the Cholesky decomposition of the corrected matrix $ \nabla^2 f(\bx^\toptzero) + \bP^\toptzero $, where $ \bP^\toptzero $ is a diagonal matrix with nonnegative diagonal elements. When $ \nabla^2 f(\bx^\toptzero) $ is positive definite and has a small condition number, $ \bP^\toptzero = \bzero $ \citep{gill1974newton, sun2006optimization}.

\subsection{Inexact Newton's Method}

In  pure Newton's method, computing the Newton direction $ \bd_{\text{n}}^\toptzero $ involves solving a linear system. 
When $ n $ is large but $ \nabla^2 f(\bx^\toptzero) $ exhibits a sparse structure, iterative methods are necessary to solve the Newton equation~\eqref{equation:newton_secon_approx_eq3}. Since iterative methods inherently introduce some level of error, it's important to understand how this affects the convergence of Newton's method and how we can control the precision of the solution to ensure that Newton's method still converges. We will briefly address these issues.

For simplicity, let $F(\bx)\triangleq\nabla f(\bx)$.
Recall that the basic Newton step is obtained by solving the Newton equation \eqref{equation:newton_secon_approx_eq3}:
\begin{equation}
\nabla F(\bx^\toptzero)\bd = -F(\bx^\toptzero)
\end{equation}
and setting
\begin{equation}
\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{in}}^\toptzero.
\end{equation}
Consider an inexact solution $ \bd_{\text{in}}^\toptzero $ of the Newton equation. We introduce the residual  vector $ \br^\toptzero $ to represent the residual, then the inexact Newton direction satisfies the \textit{inexact Newton equation}:
\begin{equation}
\bd_{\text{in}}^\toptzero\leftarrow \text{ solution of } \nabla F(\bx^\toptzero)\bd = -F(\bx^\toptzero) + \br^\toptzero,
\end{equation}
where we assume the relative error $ \rho_t $ satisfies:
\begin{equation}
\normtwobig{\br^\toptzero} \leq \rho_t \normtwobig{F(\bx^\toptzero)}.
\end{equation}
Here, $ \br^\toptzero = \nabla F(\bx^\toptzero)\bd_{\text{in}}^\toptzero + F(\bx^\toptzero) $ denotes the residual, and $ \{\rho_t\} $ (with $ 0 < \rho_t < 1 $) denotes a forcing sequence controlling the level of inexactness. The procedure is outlined in Algorithm~\ref{alg:inexac_newton}, under the following assumption:
\begin{assumption}[Inexact Newton's Method]\label{assumption:inex_newton}
Let $F(\bx)\triangleq\nabla f(\bx)$ for any differentiable function $f:\real^n\rightarrow \real$. We assume that
\begin{enumerate}[(i)]
\item There exists $ \bx^* $ such that $ F(\bx^*) = \bzero $.

\item $ F $ is continuously differentiable in the neighborhood of $ \bx^* $.

\item $ \nabla F(\bx^*) $ is nonsingular.
\end{enumerate}
\end{assumption}




\begin{algorithm}[h] 
\caption{Inexact Newton's Method \citep{sun2006optimization}}
\label{alg:inexac_newton}
\begin{algorithmic}[1] 
\Require A twice continuously differentiable function $f(\bx)$ and $F(\bx)\triangleq\nabla f(\bx)$; 
\State {\bfseries Input:}  Initialize $\bx^{(1)}$;
\For{$t=1,2,\ldots$}
\State Select noise level $\rho_t$
\State $\bd_{\text{in}}^\toptzero\leftarrow $ solution of  $\nabla F(\bx^\toptzero)\bd = -F(\bx^\toptzero) + \br^\toptzero$, where $\normtwobig{\br^\toptzero} \leq \rho_t \normtwobig{F(\bx^\toptzero)}$;
\State $\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{in}}^\toptzero$;
\EndFor
\State {\bfseries Return:}  final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic} 
\end{algorithm}

In the following, we establish the linear convergence of inexact Newton's method.
\begin{theoremHigh}[Local Convergence of Inexact Newton's Method]\label{theorem:inex_newton_linear}
Let $F : \real^n \to \real^n$ satisfy Assumption~\ref{assumption:inex_newton}. Assume that the sequence $\{\rho_t\}$ satisfies $0 \leq \rho_t \leq \rho < \zeta < 1$ (i.e., $\rho$ is the upper bound of the sequence $\{\rho_t\}$). Then, for some $\epsilon > 0$, if the starting point $\bx^{(1)}$ is sufficiently near $\bx^*$, the sequence $\{\bx^\toptzero\}$ generated by inexact Newton's method (Algorithm~\ref{alg:inexac_newton}) converges \textbf{linearly} to $\bx^*$ (Definition~\ref{definition:linear-convergence}), i.e.,
\begin{equation}\label{equation:inex_newton_linear_res}
\normbig{\bx^\toptone - \bx^*}_* \leq \zeta \normbig{\bx^\toptzero - \bx^*}_*,
\end{equation}
where $\norm{\by}_* \triangleq \normtwo{\nabla F(\bx^*)\by}$ for any $\by\in\real^n$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:inex_newton_linear}]
Since $\nabla F(\bx^*)$ is nonsingular, for $\by \in \real^n$, we have
\begin{equation}\label{equation:inex_newton_linear0}
\frac{1}{\mu} \normtwo{\by} \leq \norm{\by}_* \leq \mu \normtwo{\by}, \text{ where }\mu \triangleq \max\left\{\normtwo{\nabla F(\bx^*)}, \normtwo{\nabla F(\bx^*)^{-1}}\right\}.
\end{equation}
Since $1=\normtwo{\bI} = \normtwo{F(\bx^*)\cdot F(\bx^*)^{-1}}\leq \normtwo{F(\bx^*) } \normtwo{F(\bx^*)^{-1}} $, we have $\mu>1$.
On the other hand, since $\rho < \zeta$, there exists a sufficiently small $\gamma > 0$ satisfying
\begin{equation}\label{equation:inex_newton_linear01}
\rho (1 + \mu \gamma) + 2 \mu \gamma \leq  \frac{\zeta}{1 +  \mu\gamma}
\quad\implies\quad 
(1 +  \mu\gamma)[\rho (1 + \mu \gamma) + 2 \mu \gamma] \leq \zeta.
\end{equation}
Since $F(\bx)$ is continuously differentiable in the neighborhood of $\bx^*$ by Assumption~\ref{assumption:inex_newton},  choose $\epsilon > 0$ sufficiently small such that  $\normtwo{\by - \bx^*} \leq \mu^2 \epsilon$, whence we have
\begin{align}
\normtwo{\nabla F(\by) - \nabla F(\bx^*)} &\leq \gamma, \label{equation:inex_newton_linear1}\\
\normtwo{\nabla F(\by)^{-1} - \nabla F(\bx^*)^{-1}} &\leq \gamma,\label{equation:inex_newton_linear2}\\
\normtwo{F(\by) - F(\bx^*) - \nabla F(\bx^*)(\by - \bx^*)} &\leq \gamma \normtwo{\by - \bx^*}, \label{equation:inex_newton_linear3}
\end{align}
where the continuity of $\nabla F(\cdot)^{-1}$ follows from Theorem~\ref{theorem:invfunctheo_var}.

Let $\normtwo{\bx^{(1)} - \bx^*} \leq \epsilon$. We now prove \eqref{equation:inex_newton_linear_res} by induction. By using \eqref{equation:inex_newton_linear0} and assumption of the induction, we have
$$
\begin{aligned}
\normtwobig{\bx^\toptzero - \bx^*}
&\leq \mu \normbig{\bx^\toptzero - \bx^*}_* \leq \mu\zeta^t  \normbig{\bx^{(1)} - \bx^*}_* 
\leq \mu^2\zeta^t \normtwobig{\bx^{(1)} - \bx^*} \leq \mu^2 \epsilon.
\end{aligned}
$$
Then, when $\by\triangleq \bx^\toptzero$, \eqref{equation:inex_newton_linear1}$\sim$\eqref{equation:inex_newton_linear3} hold. Given the update rule $\bx^\toptone \leftarrow \bx^\toptzero +\bd_{\text{in}}^\toptzero$ and the assumption that $F(\bx^*)=\bzero$, it follows that 
$$
\small
\begin{aligned}
\nabla &F(\bx^*)(\bx^\toptone - \bx^*) 
= \nabla F(\bx^*)\left\{\bx^\toptzero - \bx^* - \nabla F(\bx^\toptzero)^{-1} F(\bx^\toptzero) + \nabla F(\bx^\toptzero)^{-1} \br^\toptzero\right\} \\
&= \nabla F(\bx^*) \nabla F(\bx^\toptzero)^{-1} \left\{\nabla F(\bx^\toptzero)(\bx^\toptzero - \bx^*) - F(\bx^\toptzero) + \br^\toptzero\right\} \\
&= \left\{\bI + \nabla F(\bx^*) \big[\nabla F(\bx^\toptzero)^{-1} - \nabla F(\bx^*)^{-1}\big]\right\} \\
&\quad\times \left\{\br^\toptzero + \big[\nabla F(\bx^\toptzero) - \nabla F(\bx^*)\big] (\bx^\toptzero - \bx^*) 
- \big[F(\bx^\toptzero) - F(\bx^*) - \nabla F(\bx^*) (\bx^\toptzero - \bx^*)\big]\right\},
\end{aligned}
$$
Taking norms of the above inequality, and using Cauchy-Schwartz inequality, triangle inequality, \eqref{equation:inex_newton_linear0}, \eqref{equation:inex_newton_linear1}, \eqref{equation:inex_newton_linear2}, \eqref{equation:inex_newton_linear3}, and the assumption that $\normtwobig{\br^\toptzero} \leq \rho_t \normtwobig{F(\bx^\toptzero)}$, we obtain
\begin{equation}\label{equation:inex_newton_linear4}
\small
\begin{aligned}
&\normbig{\bx^\toptone - \bx^\toptzero}_* \leq \left\{1 + \normtwo{\nabla F(\bx^*)}\normtwo{\nabla F(\bx^\toptzero)^{-1} - \nabla F(\bx^*)^{-1}}\right\}\\ 
& \times 
\left\{\normtwobig{\br^\toptzero} + \normtwo{\nabla F(\bx^\toptzero) - \nabla F(\bx^*)} \normtwobig{\bx^\toptzero - \bx^*} + \normtwo{F(\bx^\toptzero) - F(\bx^*) - \nabla F(\bx^*)(\bx^\toptzero - \bx^*)}\right\} \\
&\leq (1 + \mu \gamma) \left\{\rho_t \normtwobig{F(\bx^\toptzero)} + 2\gamma \normtwobig{\bx^\toptzero - \bx^*} \right\}.
\end{aligned}
\end{equation}
Additionally, given that $F(\bx^*)=\bzero$, it follows that 
$$
F(\bx^\toptzero) = \left\{\nabla F(\bx^*)(\bx^\toptzero - \bx^*)\right\} + \left\{F(\bx^\toptzero) - F(\bx^*) - \nabla F(\bx^*)(\bx^\toptzero - \bx^*)\right\},
$$
whence we have
$$
\normtwobig{F(\bx^\toptzero)} \leq \normbig{\bx^\toptzero - \bx^*}_* + \gamma \normtwobig{\bx^\toptzero - \bx^*}.
$$
Substituting the above inequality into \eqref{equation:inex_newton_linear4} and using \eqref{equation:inex_newton_linear0}, \eqref{equation:inex_newton_linear01}, and the fact that $\mu>1$ yield
$$
\begin{aligned}
\normbig{\bx^\toptone - \bx^*}_* 
&\leq (1 + \mu \gamma) \left\{\rho_t \big[\normbig{\bx^\toptzero - \bx^*}_* + \gamma \normtwobig{\bx^\toptzero - \bx^*}\big] + 2 \gamma \normtwobig{\bx^\toptzero - \bx^*}\right\} \\
&\leq (1 + \mu \gamma) \left\{\rho (1 + \mu \gamma) + 2 \mu \gamma\right\} \normbig{\bx^\toptzero - \bx^*}_*
\leq \zeta \normbig{\bx^\toptzero - \bx^*}_*.
\end{aligned}
$$
This completes the proof.
\end{proof}

Clearly, the convergence of inexact Newton's method depends on the choice of the relative error $\normtwobig{\br^\toptzero} \leq \rho_t \normtwobig{F(\bx^\toptzero)}$. Intuitively, the more accurately the Newton equation is solved, the better the convergence properties of  inexact Newton's method. 
In fact, different conditions on this relative error bound yields different local convergence results, which we provide in the following and the details can be found in \citet{fletcher2000practical, sun2006optimization}.
\begin{theoremHigh}[Convergence of Inexact Newton's Methods]\label{theorem:conv_inex_newton}
Let the assumptions of Theorem~\ref{theorem:inex_newton_linear} be satisfied. 
If the starting point $\bx^{(1)}$ is sufficiently near $\bx^*$, the sequence $\{\bx^\toptzero\}$ generated by inexact Newton's method (Algorithm~\ref{alg:inexac_newton}) converges:
\begin{enumerate}[(i)]
\item If there exists a constant $\rho < 1$ such that $\rho_t$ satisfies $0 < \rho_t < \rho$ for $t = 1, 2, \ldots$, then the algorithm converges \textbf{linearly} (the result of Theorem~\ref{theorem:inex_newton_linear}).

\item If $\lim_{t \to \infty} \rho_t = 0$, then the algorithm converges \textbf{superlinearly}.

\item If $\rho_t = \mathcalO(\normtwobig{\nabla f(\bx^\toptzero)})$, then the algorithm converges \textbf{quadratically}.
\end{enumerate}
\end{theoremHigh}

The intuitive implication of Theorem~\ref{theorem:conv_inex_newton} is that achieving better convergence requires solving the Newton equation more accurately. 
In general iterative methods, the stopping criterion usually depends on the size of the relative error. 
According to the first statement of Theorem~\ref{theorem:conv_inex_newton}, setting the relative error to a fixed value ensures convergence. Compared to pure Newton's method, an inexact Newton's method with a fixed error only achieves linear convergence but may perform better on ill-conditioned problems than traditional gradient methods. To achieve quadratic convergence with  inexact Newton's method, it becomes necessary to solve the Newton equation with high accuracy in later iterations, essentially aligning it with  Newton's method.

A commonly employed variant of  inexact Newton's method is the \textit{Newton-Conjugate Gradient method}, which utilizes the conjugate gradient method (Section~\ref{section:conjugate-descent}) to solve the Newton equation \eqref{equation:newton_secon_approx_eq3}. 
Given the conjugate gradient method's effectiveness in solving linear systems, it often requires only a few steps (sometimes just one step) to meet the criteria outlined in the first conclusion of Theorem~\ref{theorem:conv_inex_newton}. The Newton-Conjugate Gradient method demonstrates good numerical performance across many problems and serves as an essential optimization tool for tackling various optimization challenges.




\subsection{Proximal Newton Method}
We described the proximal gradient method in \eqref{equation:prox_decom} using the proximal operators. 
By combining the principles of the proximal gradient method with the derivation of Newton's method in \eqref{equation:newton_secon_approx_ALL}, we introduce the \textit{proximal Newton method}. The update at the $t$-th iteration is given by: 
\begin{subequations}\label{equation:prox_new_updv1}
\begin{align}
\bd^\toptzero &\leftarrow \argmin_{\bd} \left\{G_t(\bd) \triangleq g_t(\bd) + g(\bx^\toptzero +\bd)\right\};\\
\bx^\toptone &\leftarrow \bx^\toptzero + \eta_t \bd^\toptzero,
\end{align}
\end{subequations}
where $g_t(\bd) \triangleq f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} \bd^\top \bH^\toptzero \bd$, $\bH^\toptzero\triangleq\nabla^2 f(\bx^\toptzero )$, $\eta_t$ is the stepsize, and $g(\bx)$ is a \textbf{proper closed and convex} function~\footnote{A few examples are discussed in the paragraph below Definition~\ref{definition:opt_probs_all}.}.
Thus, when $\bH^\toptzero $ is positive definite, $G_t(\bd)$ is also convex.

Previously, we defined the proximal operator using the $\ell_2$ norm (Definition~\ref{definition:projec_prox_opt}). If we replace the $\ell_2$ norm with the $\bQ$-norm (see \eqref{equation:q_norm}, $\norm{\bx}^2_{\bQ} = \bx^\top\bQ\bx = \normtwo{{\bQ}^{1/2}\bx}^2$ for any $\bx$), we obtain the \textit{scaled proximal operator}:
\begin{equation}\label{equation:scaled_prox_opt}
\textbf{(Scaled proximal)}:\quad 
\prox_{f, \bQ}(\by) \triangleq 
\mathop{\argmin}_{\bx\in\real^n} \left( f(\bx) + \frac{1}{2}\norm{\bx-\by}_{\bQ}^2 \right).
\end{equation}
Then, the proximal Newton update in \eqref{equation:prox_new_updv1} can be equivalently stated as follows:
\begin{tcolorbox}[colback=white,colframe=black]
\begin{minipage}{1\textwidth}
\begin{subequations}\label{equation:prox_new_updv2}
\small
\begin{align}
\bu^\toptzero &\leftarrow \argmin_{\bu} \left\{\nabla f(\bx^\toptzero)^\top \bu
+ \frac{1}{2} (\bu-\bx^\toptzero)^\top \bH^\toptzero (\bu-\bx^\toptzero) + g(\bu)\right\}\\
&= \argmin_{\bu}  \frac{1}{2} \norm{\bx^\toptzero - \bH^{(t)-1} \nabla f(\bx^\toptzero) - \bu }_{\bH^\toptzero}^2 
+g(\bu)  \\
&= \prox_{f, \bH^\toptzero}\Big( \bx^\toptzero - \bH^{(t)-1} \nabla f(\bx^\toptzero) \Big);\\
\bx^\toptone &\leftarrow \bx^\toptzero + \eta_t (\bu^\toptzero - \bx^\toptzero).
\end{align}
\end{subequations}
\end{minipage}
\end{tcolorbox}
When $f$ is $\alpha$-strongly convex and $\nabla^2 f$ is $L$-Lipschitz, it can be proved that
$$
\normtwo{\bx^\toptone - \bx^*} \leq \frac{L}{2\alpha} \normtwo{\bx^\toptzero - \bx^*}^2
$$
when $\bx^\toptzero$ is sufficiently close to $\bx^*$ (indicating  a local quadratic convergence result). We shall not go into the details and more information can be found in \citet{lee2014proximal}.



\section{Quasi-Newton Methods}\label{section:quasi_newton_method}

Pure Newton's method achieves excellent results both theoretically and practically. However, for large-scale problems, computing the Hessian matrix can be particularly expensive or difficult to obtain. Even if we manage to compute the Hessian matrix, solving a large-scale linear system remains a challenge. 
A natural question arises: Can we solve a large-scale linear system using an approximation of the Hessian matrix or its inverse in Newton's method?
\textit{Quasi-Newton methods} (from Latin, quasi means nearly) are algorithms that generate approximate matrices at each step with a lower  computational cost while still ensuring the sequence of iterations exhibits superlinear convergence properties.

Quasi-Newton methods do not compute the Hessian matrix $\nabla^2 f(\bx^\toptzero)$ directly but construct an approximate matrix $\bH^\toptzero$ or its inverse $\bZ^\toptzero$. We hope that $\bH^\toptzero$ or $\bZ^\toptzero$ retains some properties of the Hessian matrix, such as ensuring that $\bd^\toptzero$ derived from the Newton equations using these approximations remains a descent direction. 

\index{Secant equation}
\subsection{Secant Equations}

First, let us review the derivation of Newton's method. Suppose $f(\bx)$ is a twice continuously differentiable function. According to linear approximation theorem (Theorem~\ref{theorem:linear_approx}), the gradient function $\nabla f(\bx)$ can be approximated near $\bx^\toptone$ as:
$$
\nabla f(\bx) = \nabla f(\bx^\toptone) + \nabla^2 f(\bx^\toptone)(\bx - \bx^\toptone) + \mathcalO\big(\normtwobig{\bx - \bx^\toptone}^2\big).
$$
Let $\bx \triangleq \bx^\toptzero$, $\bh^\toptzero \triangleq \bx^\toptone - \bx^\toptzero$, and $\by^\toptzero \triangleq \nabla f(\bx^\toptone) - \nabla f(\bx^\toptzero)$. That is, $\bh^\toptzero$ denotes the descent step and $\by^\toptzero$ represents the increase in the gradient.
Then,
$$
\nabla^2 f(\bx^\toptone) \bh^\toptzero + \mathcalO(\normtwobig{\bh^\toptzero}^2) = \by^\toptzero.
$$
Ignoring the higher-order term $\normtwobig{\bh^\toptzero}^2$, we hope that the approximate Hessian matrix $\bH^\toptone$ satisfies the equation:
\begin{subequations}
\begin{equation}\label{equation:secant1}
	\textbf{(SE1)}:\qquad \by^\toptzero = \bH^\toptone \bh^\toptzero,
\end{equation}
or its inverse approximate matrix $\bZ^\toptone$ satisfies the equation:
\begin{equation}\label{equation:secant2}
	\textbf{(SE2)}:\qquad \bh^\toptzero = \bZ^\toptone \by^\toptzero,
\end{equation}
\end{subequations}
Equations~\eqref{equation:secant1} and \eqref{equation:secant2} are known as the \textit{secant equations}.

We can also understand the secant equations \eqref{equation:secant1} from another perspective. 
Newton's method essentially performs a second-order approximation of the objective function $f(\bx)$ at the iterate point $\bx^\toptzero$. Consider the second-order approximation at $\bx^\toptone$ (Theorem~\ref{theorem:quad_app_theo}):
$$
f(\bx^\toptone +\bh) \approx\psi_{t+1}(\bh) \triangleq f(\bx^\toptone) + \nabla f(\bx^\toptone)^\top \bh + \frac{1}{2} \bh^\top \bH^\toptone \bh.
$$
A natural requirement is that the gradient of $\psi_{t+1}(\bh)$ at $\bh = -\bh^\toptzero$ and $\bh = \bzero$ should match the gradient of $f(\bx)$ at $\bx = \bx^\toptzero$ and $\bx = \bx^\toptone$, respectively:
\begin{equation}
\nabla \psi_{t+1}(-\bh^\toptzero) = \nabla f(\bx^\toptzero)
\qquad\text{and}\qquad
\nabla \psi_{t+1}(\bzero) = \nabla f(\bx^\toptone).
\end{equation}
Note that the latter equality $\nabla \psi_{t+1}(\bzero) = \nabla f(\bx^\toptone)$ is naturally satisfied. To ensure the first condition is satisfied, we need:
$$
\nabla \psi_{t+1}(-\bh^\toptzero) = \nabla f(\bx^\toptone) - \bH^\toptone \bh^\toptzero = \nabla f(\bx^\toptzero).
$$
Rearranging terms yields the (SE1) equation \eqref{equation:secant1}.

Additionally, note that the positive definiteness of the approximate matrix $ \bH^\toptzero $ is a crucial factor. By premultiplying both sides of the  (SE1) equation \eqref{equation:secant1} by $ \bh^\toptzeroTOP $, we get $ \bh^\toptzeroTOP \bH^\toptone \bh^\toptzero = \bh^\toptzeroTOP \by^\toptzero $, thus the condition
\begin{subequations}
\begin{equation}\label{equation:secant1_2}
\textbf{(SE1$'$)}:\qquad \innerproduct{\bh^\toptzero,  \by^\toptzero} > 0
\end{equation}
is a necessary condition for $ \bH^\toptone $ to be positive definite. This condition must hold throughout the iteration process; it is known as the curvature condition.  
For general objective functions $ f(\bx) $, we need to use Wolfe line search conditions to ensure the curvature condition \eqref{equation:secant1_2}. In practice, according to the second Wolfe condition \eqref{equation:wolfe_2}, we have $ \innerproduct{\nabla f(\bx^\toptone),  \bh^\toptzero} \geq c_2 \innerproduct{\nabla f(\bx^\toptzero), \bh^\toptzero} $, where $0<c_2<1$ is a constant. Subtracting $ \nabla f(\bx^\toptzero)^\top \bh^\toptzero $ from both sides yields that
\begin{equation}\label{equation:secant1_3}
\textbf{(SE1$''$)}:\qquad \innerproduct{\by^\toptzero,  \bh^\toptzero} \geq (c_2 - 1)  \innerproduct{\nabla f(\bx^\toptzero), \bh^\toptzero} > 0,
\end{equation}
since $0< c_2 < 1 $ and $ \bh^\toptzero = \eta_t \bd^\toptzero $ is a descent direction. 
\end{subequations}

In most cases, the approximate matrices $ \bH^\toptone $ or $ \bZ^\toptone $ are obtained by adding a correction to the previous iteration and requiring them to satisfy the secant equation \eqref{equation:secant1}. Below provides a general framework for quasi-Newton methods (Algorithm~\ref{alg:quasi_newton_frame}), and the next subsection will discuss specific matrix update methods. 
An overview comparing the quasi-Newton method and Newton's method is presented in  Table~\ref{tab:comparison_quasi_new}.

\index{Quasi-Newton method}
\begin{algorithm}[H]
\caption{Quasi-Newton Method}
\label{alg:quasi_newton_frame}
\begin{algorithmic}[1]
\Require A twice continuously differentiable function $f(\bx)$
\State {\bfseries Input:}  Initialize $ \bx^{(1)} \in \real^n $, $ \bH^{(1)} \in \real^{n \times n} $ (or $ \bZ^{(1)} $);
\For{$t=1,2,\ldots$}
\State Compute direction $ \bd^\toptzero = -(\bH^\toptzero)^{-1} \nabla f(\bx^\toptzero) $ or $ \bd^\toptzero = -\bZ^\toptzero \nabla f(\bx^\toptzero) $.
\State Use line search method to determine a suitable stepsize $ \eta_t > 0 $;
\State $ \bx^\toptone = \bx^\toptzero + \bh^\toptzero $, where $\bh^\toptzero\triangleq \eta_t \bd^\toptzero$;
\State Update approximate Hessian matrix $ \bH^\toptone $ or its inverse $ \bZ^\toptone $;
\EndFor
\State {\bfseries Return:}   final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic}
\end{algorithm}

In practical applications, quasi-Newton methods based on $ \bZ^\toptzero $ are more commonly used because computing the descent direction $ \bd^\toptzero $ does not require solving a linear system due to the inverse of $\bH^\toptzero$, while solving a linear system is very time-consuming for large-scale problems. 
However, quasi-Newton methods that utilize $ \bH^\toptzero $ possess superior theoretical properties, leading to a more stable sequence of iterations. 
If an efficient method for solving the linear system becomes available, employing quasi-Newton methods based on $ \bH^\toptzero $ could also be feasible. 


\begin{table}[h]
\centering
\caption{Comparison between quasi-Newton method and Newton's method.}
\label{tab:comparison_quasi_new}
\begin{tabular}{|p{6.8cm}|p{6.8cm}|}
\hline
\textbf{Quasi-Newton method} & \textbf{Newton's method} \\ \hline\hline
Requires only function values and gradients & Requires function values, gradients, and Hessians \\ \hline
$\{\bH^\toptzero\}$ maintains positive definiteness  for several updates & $\{\nabla^2 (\bx^\toptzero)\}$ may not be positive definite \\ \hline
Needs $\mathcalO(n^2)$ multiplications per  iteration & Needs $\mathcalO(n^3)$ multiplications per  iteration \\ \hline
\end{tabular}
\end{table}
\subsection{Updating Quasi-Newton Matrices}\label{section:quasi_new_update}

This subsection introduces some common methods for updating quasi-Newton matrices.

\index{Symmetric rank-one update}
\subsection*{Symmetric Rank-One Update (SRO)}

The \textit{symmetric rank-one (SRO)} update formula  is the simplest approach for updating quasi-Newton matrices. Suppose $ \bH^\toptzero $ is the approximate Hessian matrix at step $ t $. We update $ \bH^\toptzero $ to $ \bH^\toptone $ by applying  a symmetric rank-one correction to satisfy the secant equation \eqref{equation:secant1}. 
To be more specific, we update by the rank-one correction:
$$
\bH^\toptone \leftarrow \bH^\toptzero + \gamma \bu \bu^\top,
$$
where $ \bu \in \real^n $ and $ \gamma \in \real $ are variables to be determined. Based on the (SE1) equation \eqref{equation:secant1},
$
\bH^\toptone \bh^\toptzero = (\bH^\toptzero + \gamma \bu \bu^\top) \bh^\toptzero = \by^\toptzero,
$
we obtain
\begin{equation}\label{equation:sro_rawequa}
(\gamma \cdot \bu^\top \bh^\toptzero) \bu = \by^\toptzero - \bH^\toptzero \bh^\toptzero.
\end{equation}
Notice that $ \gamma \cdot \bu^\top \bh^\toptzero $ is a scalar, so $ \bu $ and $ \by^\toptzero - \bH^\toptzero \bh^\toptzero $ must have the same direction. 
Letting $ \bu \triangleq \by^\toptzero - \bH^\toptzero \bh^\toptzero $, substituting into the original equation \eqref{equation:sro_rawequa} gives
$$
\begin{aligned}
&\gamma \left(\left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right)^\top \bh^\toptzero\right) (\by^\toptzero - \bH^\toptzero \bh^\toptzero) = \by^\toptzero - \bH^\toptzero \bh^\toptzero\\
&\quad\implies\quad 
\gamma = \frac{1}{\left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right)^\top \bh^\toptzero},
\quad\text{assuming $ \left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right)^\top \bh^\toptzero \neq 0 $}.
\end{aligned}
$$
The update formula becomes
\begin{subequations}
\begin{equation}\label{equation:sro_rawequa1}
\textbf{(SRO1)}:\qquad 
\bH^\toptone \leftarrow \bH^\toptzero + 
\frac{\left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right) \left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right)^\top}{\left(\by^\toptzero - \bH^\toptzero \bh^\toptzero\right)^\top \bh^\toptzero},
\end{equation}
which is known as the \textit{SRO update formula for $ \bH^\toptzero $} \citep{broyden1965class}. 
By following an analogous process, we can derive the \textit{SRO update formula for $ \bZ^\toptzero $} based on the second secant equation \eqref{equation:secant2}:
\begin{equation}\label{equation:sro_rawequa2}
\textbf{(SRO2)}:\qquad 
\bZ^\toptone \leftarrow \bZ^\toptzero + \frac{\left(\bh^\toptzero - \bZ^\toptzero \by^\toptzero\right) \left(\bh^\toptzero - \bZ^\toptzero \by^\toptzero\right)^\top}{\left(\bh^\toptzero - \bZ^\toptzero \by^\toptzero\right)^\top \by^\toptzero}.
\end{equation}
\end{subequations}
We observe that \eqref{equation:sro_rawequa1} and \eqref{equation:sro_rawequa2} are dual to each other in form. 

A distinctive property of the SRO update is its natural quadratic termination. Specifically, for a quadratic function, it does not require line search and can terminate within $n+1$ steps, i.e., $\bZ^{(n+1)} =\bA^{-1}$, where $\bA$ is the Hessian of the
quadratic function. This fact is proved by the following theorem.
\begin{theorem}[Quadratic Termination of SRO Update]
Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx-\bb^\top\bx+c$ where $\bA\in\real^{n\times n}$ is positive definite.
Suppose the iterates of descent steps $ \bh^{(1)}, \bh^{(2)}, \ldots, \bh^{(n)} $ generated by the SRO method are linearly independent. Then, the  SRO method terminates at $ n+1 $ steps, meaning $ \bZ^{(n+1)} = \bA^{-1} $.
\end{theorem}

\begin{proof}
Since Hessian $ \bA $ is positive definite, we have 
\begin{equation}\label{equation:sro_indu_eq1}
\by^{(t)} = \bA \bh^{(t)}, \quad  t = 1,2, \ldots, n.
\end{equation}
We prove by the following two steps.
\paragraph{Induction result.}
First, by induction, we prove the following property:
\begin{equation}\label{equation:sro_indu_eq2}
\bZ^{(i+1)} \by^{(k)} = \bh^{(k)}, \quad  k =1, 2, \ldots, i.
\end{equation}
For $ i = 1 $, the result holds trivially from \eqref{equation:sro_rawequa2}. Now suppose it is true for $ i > 1 $; we will show it holds for $ i + 1 $.
From \eqref{equation:sro_rawequa2}, we have
\begin{equation}\label{equation:sro_indu_eq3}
\bZ^{(i+1)} \by^{(k)} = \bZ^{(i)} \by^{(k)} + \frac{(\bh^{(i)} - \bZ^{(i)} \by^{(i)})(\bh^{(i)} - \bZ^{(i)} \by^{(i)})^\top \by^{(k)}}{(\bh^{(i)} - \bZ^{(i)} \by^{(i)})^\top \by^{(i)}}.
\end{equation}
When $ k < i $, from the induction hypothesis and \eqref{equation:sro_indu_eq1}, we have
$$
\begin{aligned}
(\bh^{(i)} - \bZ^{(i)} \by^{(i)})^\top \by^{(k)} 
&= (\bh^{(i)})^\top \by^{(k)} - (\by^{(i)})^\top \bZ^{(i)} \by^{(k)} \\
&= (\bh^{(i)})^\top \by^{(k)} - (\by^{(i)})^\top \bh^{(k)}
= (\bh^{(i)})^\top \bA \bh^{(k)} - (\bh^{(i)})^\top \bA \bh^{(k)}
= 0.
\end{aligned}
$$
Substituting into \eqref{equation:sro_indu_eq3} yields that 
$$
\bZ^{(i+1)} \by^{(k)} = \bZ^{(i)} \by^{(k)} = \bh^{(k)}, \; \forall k < i.
$$
The equality for $ k = i $ follows directly from \eqref{equation:sro_rawequa2} that
$
\bZ^{(i+1)} \by^{(i)} = \bh^{(i)}.
$
Therefore, \eqref{equation:sro_indu_eq2} holds for $i+1$.

\paragraph{The result.}
The above induction proof shows that 
$$
\bh^{(k)} = \bZ^{(n+1)} \by^{(k)} = \bZ^{(n)} \bA \bh^{(k)}, \; k =  1, 2, \ldots, n.
$$
Since $ \bh^{(k)} \; (k = 1, 2, \ldots, n) $ are linearly independent, then $ \bZ^{(n+1)} \bA = \bI $, which implies $ \bZ^{(n+1)} = \bA^{-1} $. 
\end{proof}

The above theorem highlights several characteristics of the SRO update:
\begin{enumerate}[(i)]
\item The SRO update possesses natural quadratic termination.
\item The SRO update satisfies the  property: $ \bZ^{(t+1)} \by^{(k)} = \bh^{(k)}, k \leq  t $.
\item The SRO update does not retain the positive definiteness of $ \bZ^\toptzero $. It retains positive definiteness if and only if $ \innerproduct{\bh^\toptzero  - \bZ^\toptzero \by^\toptzero, \by^\toptzero} > 0 $ (see \eqref{equation:sro_rawequa2}). 
However, this condition is hard to guarantee. A solution is to use the SRO update within a trust region framework, as the trust region method does not require positive definiteness of the Hessian approximations.
\item Sometimes, the denominator $ \innerproduct{\bh^\toptzero  - \bZ^\toptzero \by^\toptzero, \by^\toptzero}  $ is very small or zero, leading to serious numerical difficulties or even algorithm failure. This drawback limits its applications.  A special skipping strategy to prevent the SRO update from breaking down involves using \eqref{equation:sro_rawequa2} only if:
\begin{equation}\label{equation:sro_skip}
\abs{\innerproduct{\bh^{(t)} - \bZ^{(t)} \by^{(t)},  \by^{(t)}}} \geq \zeta \normtwo{\bh^{(t)} - \bZ^{(t)} \by^{(t)}} \normtwobig{\by^{(t)}},
\end{equation}
where $ \zeta \in (0, 1) $; otherwise we set $ \bZ^\toptone  \leftarrow \bZ^{(t)} $.
\item The SRO update has a good behavior that it continues to generate good Hessian approximations, which is stated in the following theorem.
\end{enumerate}
\begin{theorem}[\citep{sun2006optimization}]
Let $ f $ be twice continuously differentiable, and its Hessian be bounded and Lipschitz continuous in a neighborhood of a point $ \bx^* $. Let $ \{\bx^\toptzero\} $ be a sequence of iterates converging to $\bx^* $. Suppose that the skipping rule \eqref{equation:sro_skip} holds for all $ t $, and the steps $ \bh^\toptzero  $ are uniformly linearly independent. Then the matrix sequence $ \{\bH^\toptzero\} $ generated by SRO update satisfies
\begin{equation}
\lim_{t \to \infty} \normtwo{\bZ^{(t)} - [\nabla^2 f(\bx^*)]^{-1}} = 0.
\end{equation}
\end{theorem}

%Although the SRO formula has a simple structure, it has a significant drawback: it does not guarantee that the matrix remains positive definite during the iteration process. It is easy to verify that $ \innerproduct{\by^\toptzero - \bH^\toptzero \bh^\toptzero,  \bh^\toptzero} > 0 $ is a sufficient condition for $ \bH^\toptone $ to be positive definite, but this condition may not always be satisfied during the iteration process. Therefore, the SRO formula is rarely used in practice.



\subsection*{BFGS Formula}

To address the limitations of the SRO formula, we now consider a symmetric rank-two update for $ \bH^\toptzero $. Specifically, we define
$$
\bH^\toptone = \bH^\toptzero + \gamma \bu \bu^\top + \zeta \bv \bv^\top,
$$
where $ \bu, \bv \in \real^n $ and $ \gamma, \zeta \in \real $ are parameters  to be determined. Based on the (SE1) equation \eqref{equation:secant1},
$$
\bH^\toptone \bh^\toptzero = (\bH^\toptzero + \gamma \bu \bu^\top + \zeta \bv \bv^\top) \bh^\toptzero = \by^\toptzero,
$$
we derive
$$
(\gamma \cdot \bu^\top \bh^\toptzero) \bu + (\zeta \cdot \bv^\top \bh^\toptzero) \bv = \by^\toptzero - \bH^\toptzero \bh^\toptzero.
$$
By selecting  $ \bu $ and $ \bv $ appropriately,  this equation can be satisfied. A direct approach is to equate terms on both sides:
$$
\begin{aligned}
\bu &\triangleq \by^\toptzero, \qquad &\gamma& \cdot \bu^\top \bh^\toptzero \triangleq 1, \\
\bv &\triangleq \bH^\toptzero \bh^\toptzero, \qquad &\zeta& \cdot \bv^\top \bh^\toptzero \triangleq -1.
\end{aligned}
$$
Consequently, the update rule for $\bH^\toptone$ is
\begin{subequations}
\begin{equation}\label{equation:bfgs_update}
	\textbf{(BFGS1)}:\qquad 
	\bH^\toptone = \bH^\toptzero + \frac{\by^\toptzero \by^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero} - \frac{\bH^\toptzero \bh^\toptzero (\bH^\toptzero \bh^\toptzero)^\top}{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}.
\end{equation}
This formulation is known as the \textit{BFGS formula for $ \bH^\toptzero $}, named after \citet{broyden1970convergence}, \citet{fletcher1970new}, \citet{goldfarb1970family}, and \citet{shanno1970conditioning}.

Using the SMW formula~\footnote{Sherman-Morrison formula: $(\bA+\bb\bc^\top)^{-1} = \bA^{-1} - \frac{\bA^{-1}\bb\bc^\top\bA^{-1}}{1+\bc^\top\bA^{-1}\bb}$. Sherman-Morrison-Woodbury formula generalizes this by: $(\bA+\bH\bC)^{-1} = \bA^{-1}-\bA^{-1}\bH(\bI+\bC\bA^{-1}\bH)^{-1}\bC\bA^{-1}$, which is derived based on Schur complement; see, for example, \citet{lu2021numerical}.}  and assuming $ \bZ^\toptzero = (\bH^\toptzero)^{-1} $, we obtain the  \textit{BFGS formula for $ \bZ^\toptzero $}:
\begin{equation}\label{equation:bfgs2_update}
	\textbf{(BFGS2)}:\quad 
	\bZ^\toptone = \bigg(\bI - \frac{ \bh^\toptzero\by^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}\bigg) \bZ^\toptzero 
	\bigg(\bI -  \frac{\by^\toptzero \bh^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}\bigg) +  \frac{\bh^\toptzero \bh^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}.
\end{equation}
\end{subequations}
For the BFGS formula to guarantee that $ \bZ^\toptone $ remains positive definite, it suffices that inequality \eqref{equation:secant1_2} holds, and $ \bZ^\toptzero $ is positive definite. 
If condition \eqref{equation:secant1_2} does not hold, line search using the Wolfe conditions can enforce this requirement.

The BFGS formula stands out as one of the most effective quasi-Newton methods currently available, combining strong theoretical properties with straightforward implementation.
The BFGS update formula (BFGS2) has additional significance as it satisfies a form of approximate optimality. 
In particular,  $\bZ^\toptone$ defined by equation (BFGS2), solves the following optimization problem:
\begin{equation}\label{equation:opt_bfgs}
\begin{aligned}
& \min_{\bZ} & & \norm{\bZ - \bZ^\toptzero}_{\bW}, \\
& \text{s.t.} & & \bZ = \bZ^\top, \\
& & & \bZ \by^\toptzero = \bh^\toptzero.
\end{aligned}
\end{equation}
This optimization seeks the matrix $\bZ$ that is closest to $\bZ^\toptzero$ among all symmetric matrices satisfying the (SE2) equation \eqref{equation:secant2}. Here, $\norm{\cdot}_{\bW}$ denotes  the weighted norm, defined as
$
\norm{\bZ}_{\bW} \triangleq \normf{\bW^{1/2} \bZ \bW^{1/2}},
$
where $\bW$  is any matrix fulfilling the secant equation $\bW \bh^\toptzero = \by^\toptzero$.





\subsection*{DFP Formula}

In the derivation of the BFGS formula, if we use the (SE2) equation \eqref{equation:secant2} to update $ \bZ^\toptzero $ using  a rank-two correction, we arrive at what is known as the \textit{DFP formula for $ \bZ^\toptzero $}:
\begin{subequations}
\begin{equation}\label{equation:dfp1}
	\textbf{(DFP1)}:\qquad 
	\bZ^\toptone = \bZ^\toptzero - \frac{(\bZ^\toptzero \by^\toptzero )(\bZ^\toptzero \by^\toptzero)^\top}{\by^\toptzeroTOP \bZ^\toptzero \by^\toptzero} + \frac{\bh^\toptzero \bh^\toptzeroTOP}{\by^\toptzeroTOP \bh^\toptzero}.
\end{equation}
This iterative format was first discovered by \citet{davidon1991variable}, later refined by \citet{fletcher1963rapidly}, hence it is named the DFP formula. 
Utilizing  the SMW formula, we can derive the corresponding formula for $ \bH^\toptzero $:
\begin{equation}\label{equation:dfp2}
	\textbf{(DFP2)}:\qquad 
	\bH^\toptone = \bigg(\bI - \frac{ \by^\toptzero\bh^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}\bigg) \bH^\toptzero 
	\bigg(\bI - \frac{\bh^\toptzero \by^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}\bigg) +   \frac{\by^\toptzero \by^\toptzeroTOP}{\bh^\toptzeroTOP \by^\toptzero}.
\end{equation}
\end{subequations}


It is evident that the DFP formulas (DFP1)--(DFP2) and the BFGS formulas (BFGS1)--(BFGS2) are dual to each other. By replacing $ \bZ^\toptzero $ with $ \bH^\toptzero $ and interchanging  $ \bh^\toptzero $ with $ \by^\toptzero $ in the BFGS formulas, we obtain the DFP formulas. Moreover, the duality also exists in the approximation properties. Specifically, the definition of  $ \bH^\toptone $ in \eqref{equation:dfp2} solves the following optimization problem:
\begin{equation}\label{equation:opt_dfp}
\begin{aligned}
&\min_{\bH} & &  \norm{\bH - \bH^\toptzero}_{\bW}\\
&\text{s.t.}& &   \bH = \bH^\top,\\
& & &\bH \bh^\toptzero = \by^\toptzero,
\end{aligned}
\end{equation}
where $ \norm{\cdot}_{\bW} $ is the weighted norm defined as
$
\norm{\bZ}_{\bW} \triangleq \normf{\bW^{1/2} \bZ \bW^{1/2}}.
$
The interpretation of  $\norm{\cdot}_{\bW}$ and the fundamental concept in equations \eqref{equation:opt_dfp} and \eqref{equation:opt_bfgs} are similar; however, $\bW$ is any matrix satisfying $\bW\by^\toptzero = \bh^\toptzero$. 

Despite the numerous similarities between the DFP and BFGS approaches in various aspects, from a practical standpoint, the DFP method is generally considered less effective than the BFGS method. Consequently, in practical applications, the BFGS approach is more commonly favored.


\subsection{Global Convergence of Quasi-Newton Methods}

This subsection introduces the convergence properties of quasi-Newton methods. First, we use Zoutendijk's condition (Theorem~\ref{theorem:zoutendijk_cond}) to obtain the global convergence of quasi-Newton methods, and then introduce the convergence rate.


\begin{theoremHigh}[Global Convergence of BFGS \citep{nocedal1999numerical}]\label{theorem:conv_bfgs_glo}
Assume the initial matrix $\bH^{(1)}$ is symmetric positive definite, the objective function $f(\bx)$ is twice continuously differentiable, and the level set
$$
\sL \triangleq \lev[f, f(\bx^{(1)})] \triangleq \{ \bx \in \real^n \mid f(\bx) \leq f(\bx^{(1)}) \}
$$
is convex. 
Furthermore, suppose there exist positive constants $\alpha$ and $\beta$ such that for any $\bz \in \real^n$ and any $\bx \in \sL$,
\begin{equation}\label{equation:bfgs_rssrsc}
\alpha \normtwo{\bz}^2 \leq \bz^\top \nabla^2 f(\bx) \bz \leq \beta \normtwo{\bz}^2.~\footnote{
That is, the eigenvalues of the Hessian of $f$ for any $\bx\in\sL$ is bounded in the interval $[\alpha, \beta]$ (Theorem~\ref{theorem:eigen_charac}).
This condition is closely related to the restricted strong convexity and restricted strong smoothness for design matrices (Definition~\ref{definition:res_scss_mat}).}
\end{equation}
Then the BFGS update formula  \eqref{equation:bfgs_update} for $\bH^\toptzero$ combined with  line search under the Wolfe condition (Definition~\ref{definition:wolfe_cond}) ensures that the quasi-Newton algorithm (Algorithm~\ref{alg:quasi_newton_frame}) globally converges to a local minimizer $\bx^*$ of $f(\bx)$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:conv_bfgs_glo}]
For convenience, we define
\begin{equation}\label{equation:bfgs_alphabeta}
\alpha_t \triangleq \frac{\by^\toptzeroTOP \bh^\toptzero}{\bh^\toptzeroTOP \bh^\toptzero}
\qquad \text{and}\qquad 
\beta_t \triangleq \frac{\by^\toptzeroTOP \by^\toptzero}{\by^\toptzeroTOP \bh^\toptzero}.
\end{equation}
Given the assumption in  \eqref{equation:bfgs_rssrsc} and the fact that 
$
\by^\toptzero = \widetildebZ \bh^\toptzero$, with $\widetildebZ\triangleq\int_0^1 \nabla^2 f(\bx^\toptzero + \mu(\bx^\toptone - \bx^\toptzero))  d\mu$ denoting the average Hessian (Theorem~\ref{theorem:fund_theo_calculu}), it follows that 
$\alpha_t = \frac{\bh^\toptzeroTOP \widetildebZ \bh^\toptzero}{\bh^\toptzeroTOP \bh^\toptzero}$ 
and 
$\beta_t = \frac{(\bs^\toptzero)^\top \widetildebZ \bs^\toptzero}{(\bs^\toptzero)^\top \bs^\toptzero}$, where $\bs^\toptzero\triangleq \widetildebZ^{1/2}\bh^\toptzero$,
whence we have 
$$
\alpha_t \geq \alpha
\qquad \text{and}\qquad 
\beta_t \leq \beta.
$$
Taking  trace on both sides of the BFGS update formula \eqref{equation:bfgs_update} for $\bH^\toptzero$, we get
\begin{equation}\label{equation:bfgs_trace}
\trace(\bH^\toptone) = \trace(\bH^\toptzero) 
+ \frac{\normtwobig{\by^\toptzero}^2}{\by^\toptzeroTOP \bh^\toptzero}
- \frac{\normtwo{\bH^\toptzero \bh^\toptzero}^2}{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}.
\end{equation}
In addition, it can also be shown that 
\begin{equation}\label{equation:bfgs_det}
\det(\bH^\toptone) = \det(\bH^\toptzero) \frac{\by^\toptzeroTOP \bh^\toptzero}{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}.
\end{equation}
Next, we define
\begin{equation}\label{equation:bfgs_cos_zeta}
\cos (\theta_t) \triangleq \frac{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}{\normtwo{\bh^\toptzero} \normtwo{\bH^\toptzero \bh^\toptzero}}
\qquad \text{and}\qquad  
\quad \zeta_t \triangleq \frac{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}{\bh^\toptzeroTOP \bh^\toptzero},
\end{equation}
where $\theta_t$ denotes the angle between $\bh^\toptzero$ and $\bH^\toptzero \bh^\toptzero$.
Rearranging the third term on the right-hand side of \eqref{equation:bfgs_trace} yields
\begin{equation}\label{equation:bfgs_conv_bh_theta}
\frac{\normtwo{\bH^\toptzero \bh^\toptzero}^2}{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero} 
= \frac{\normtwo{\bH^\toptzero \bh^\toptzero}^2 \normtwo{\bh^\toptzero}^2}{\big(\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero\big)^2} \frac{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero}{\normtwo{\bh^\toptzero}^2} = \frac{\zeta_t}{\cos^2 (\theta_t)}.
\end{equation}
Similarly, rearranging \eqref{equation:bfgs_det} gives
$$
\det(\bH^\toptone) = \det(\bH^\toptzero) \frac{\by^\toptzeroTOP \bh^\toptzero}{\bh^\toptzeroTOP \bh^\toptzero} \frac{\bh^\toptzeroTOP \bh^\toptzero}{\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero} = \det(\bH^\toptzero) \frac{\alpha_t}{\zeta_t}.
$$
Additionally, define the  function
$
\phi(\bH) \triangleq \trace(\bH) - \ln \det(\bH).
$
This yields a recursive relation between $\phi(\bH^\toptone)$ and $\phi(\bH^\toptzero)$:
\begin{equation}\label{equation:bfgs_phi_rel}
\begin{aligned}
&\phi(\bH^\toptone) = \trace(\bH^\toptzero) + \beta_t - \frac{\zeta_t}{\cos^2 (\theta_t)} - \ln (\det(\bH^\toptzero)) - \ln(\alpha_t) + \ln (\zeta_t) \\
&= \phi(\bH^\toptzero) + (\beta_t - \ln(\alpha_t) - 1) + \left(1 - \frac{\zeta_t}{\cos^2 (\theta_t)}
+ \ln \left(\frac{\zeta_t}{\cos^2 (\theta_t)}\right) \right) 
+ \ln (\cos^2 (\theta_t))\\
&\leq  \phi(\bH^\toptzero) + (\beta - \ln(\alpha) - 1)
+ \ln (\cos^2 (\theta_t)),
\end{aligned}
\end{equation}
where the last inequality follows from that fact that $\beta>\beta_t$, $\alpha<\alpha_t$ for all $t$, and the fact that $1 - \mu + \ln \mu \leq 0,\, \forall \mu>0$.
Telescoping the sum over $j\in\{1,2,\ldots,t\}$ yields that 
$$
0 < \phi(\bH^{(t+1)}) \leq \phi(\bH^{(1)}) + t \sigma + \sum_{j=1}^t \ln \cos^2 (\theta_j),
\quad\forall t>0,
$$
where $\sigma\triangleq \beta - \ln (\alpha) - 1$ and without loss of generality we assume that $\sigma > 0$. Note that $\bh^\toptzero = -\eta_t (\bH^\toptzero)^{-1} \nabla f(\bx^\toptzero)$ is the descent step, then $\cos (\theta_t)$ is the cosine of the angle between the descent direction and the negative gradient direction. According to Theorem~\ref{theorem:zoutendijk_cond} and Theorem~\ref{theorem:conv_line_search} for the Zoutendijk condition based on the Wolfe condition (which is imposed in the theorem), $\normtwobig{\nabla f(\bx^\toptzero)}$ is greater than some nonzero constant  only if $\cos (\theta_t) \to 0$. Therefore, to prove $\normtwobig{\nabla f(\bx^\toptzero)} \to 0$, we only need to prove $\cos (\theta_t) \not\to 0$. Below we use a proof by contradiction to show this conclusion. Assume $\cos (\theta_t) \to 0$, then there exists $t_1 > 0$, for any $t > t_1$, we have
$
\ln (\cos^2 (\theta_t)) < -2\sigma.
$
Combining with  \eqref{equation:bfgs_phi_rel}, when $t > t_1$, we have:
$$
\begin{aligned}
0 &< \phi(\bH^\toptone) \leq \phi(\bH^{(1)}) + t\sigma + \sum_{j=1}^{t_1} \ln (\cos^2 (\theta_j)) + \sum_{j=t_1+1}^t (-2\sigma) \\
&= \phi(\bH^{(1)}) + \sum_{j=1}^{t_1} \ln (\cos^2 \theta_j) + 2\sigma t_1  - \sigma t. 
\end{aligned}
$$
The right-hand side of the above inequality is negative for sufficiently large $t$, while the left-hand side is 0, leading to a contradiction. Therefore, the assumption does not hold, i.e., there exists a subsequence $\{j_t\}_{t=1,2,\ldots}$ such that $\cos \theta_{j_t} \geq \delta > 0$. According to the Zoutendijk condition under the Wolfe condition (Theorem~\ref{theorem:zoutendijk_cond}), we can obtain $\liminf_{t \to \infty} \normtwobig{\nabla f(\bx^\toptzero)} \to 0$. 
\end{proof}



Theorem~\ref{theorem:conv_bfgs_glo} establishes the global convergence of the BFGS method but does not address its rate of convergence.
The following theorem outlines the conditions necessary for achieving superlinear convergence by the BFGS method.
The proof first shows that 
$
\lim_{t \to \infty} \frac{\normtwo{(\bH^\toptzero - \nabla^2 f(\bx^*)) \bh^\toptzero}}{\normtwo{\bh^\toptzero}} = 0
$, which combined with the Wolfe condition indicates a superlinear convergence; see \citet{nocedal1999numerical} for more details.
\begin{theoremHigh}[Rate of Convergence  of BFGS under Twice Lipschitz]\label{theorem:rate_bfgs}
Let $f(\bx):\real^n\rightarrow \real$ be twice Lipschitz continuously differentiable in a neighborhood of the optimal point $\bx^*$: $\normtwo{\nabla^2 f(\bx) - \nabla^2 f(\bx^*)}\leq L\normtwo{\bx-\bx^*}$ for all $\bx$ near $\bx^*$ with full-rank $\nabla^2 f(\bx^*)$.
Suppose that the iterates generated by the BFGS algorithm converge to an optimal point $\bx^*$. If the sequence $\{\bx^\toptzero\}$ satisfies
\begin{equation}\label{equation:bfgs_sum_error}
\sum_{t=1}^\infty \normtwobig{\bx^\toptzero - \bx^*} < +\infty,
\end{equation}
then $\{\bx^\toptzero\}$ converges \textbf{superlinearly} to $\bx^*$.
\end{theoremHigh}

As expected, because the quasi-Newton method uses an approximate Hessian matrix, it achieves only superlinear convergence, which is slower than the quadratic convergence of  Newton's method. However, since the quasi-Newton method does not require computing the Hessian matrix at each iteration, it may offer greater computational efficiency overall. This makes it particularly suitable for practical applications.


%\begin{proof}[of Theorem~\ref{theorem:rate_bfgs}]
%Let $\bZ^* \triangleq \nabla^2 f(\bx^*)$, where $ \bx^* $ is a minimizer of $ f $. Since $\bZ^*$ has full rank, Theorem~\ref{theorem:second_nec_loca} implies that $\bZ^*$ is positive definite.
%Therefore, we can introduce the following quantities
%$$
%\widetildebh^\toptzero \triangleq (\bZ^*)^{1/2} \bh^\toptzero, 
%\qquad \widetildeby^\toptzero \triangleq (\bZ^*)^{-1/2} \by^\toptzero, 
%\qquad \widetildebH^\toptzero \triangleq (\bZ^*)^{-1/2} \bH^\toptzero (\bZ^*)^{-1/2}.
%$$
%It then follows that $\bh^\toptzeroTOP \bH^\toptzero \bh^\toptzero=(\widetildebh^\toptzero)^\top \widetildebH^\toptzero \widetildebh^\toptzero$ and $\by^\toptzeroTOP \bh^\toptzero = (\widetildeby^\toptzero)^\top \widetildebh^\toptzero$.
%Similarly to \eqref{equation:bfgs_cos_zeta} and \eqref{equation:bfgs_alphabeta}, we define
%$$
%\cos(\widetilde{\theta}_t) = \frac{(\widetildebh^\toptzero)^\top \widetildebH^\toptzero \widetildebh^\toptzero}{\normtwobig{\widetildebh^\toptzero} \normtwobig{\widetildebH^\toptzero \widetildebh^\toptzero}}
%\qquad\text{and}\qquad 
%\widetilde{\zeta}_t = \frac{(\widetildebh^\toptzero)^\top \widetildebH^\toptzero \widetildebh^\toptzero}{\normtwobig{\widetildebh^\toptzero}^2},
%$$
%and
%$$
%\widetilde{\alpha}_t = \frac{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero}{\normtwobig{\widetildebh^\toptzero}^2}
%\qquad\text{and}\qquad 
%\widetilde{\beta}_t = \frac{\normtwobig{\widetildeby^\toptzero}^2}{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero}.
%$$
%
%By pre- and postmultiplying the BFGS update formula \eqref{equation:bfgs_update} by $ (\bZ^*)^{-1/2} $ and grouping terms appropriately, we obtain
%$$
%\widetildebH^\toptone = \widetildebH^\toptzero 
%+ \frac{\widetildeby^\toptzero (\widetildeby^\toptzero)^\top}{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero}
%- \frac{\widetildebH^\toptzero \widetildebh^\toptzero (\widetildebh^\toptzero)^\top \widetildebH^\toptzero}{(\widetildebh^\toptzero)^\top \widetildebH^\toptzero \widetildebh^\toptzero} .
%$$
%Since this expression has precisely the same form as the BFGS formula \eqref{equation:bfgs_update}, it follows from the argument leading to \eqref{equation:bfgs_phi_rel} that
%\begin{equation}\label{equation:rate_bfgs_recur_phi}
%\small
%\begin{aligned}
%\phi(\widetildebH^\toptone) &= \phi(\widetildebH^\toptzero) + (\widetilde{\beta}_t - \ln (\widetilde{\alpha}_t) - 1) 
%+ \left(1 - \frac{\widetilde{\zeta}_t}{\cos^2 (\widetilde{\theta}_t)} 
%+ \ln \frac{\widetilde{\zeta}_t}{\cos^2 (\widetilde{\theta}_t)}\right)
%+ \ln (\cos^2 (\widetilde{\theta}_t)).
%\end{aligned}
%\end{equation}
%
%Recalling the fact that 
%$
%\by^\toptzero = \widetildebZ \bh^\toptzero$, with $\widetildebZ\triangleq\int_0^1 \nabla^2 f(\bx^\toptzero + \mu(\bx^\toptone - \bx^\toptzero))  d\mu$ denoting the average Hessian,
%it follows that
%$
%\by^\toptzero - \bZ^* \bh^\toptzero = (\widetildebZ - \bZ^*) \bh^\toptzero,
%$
%whence we have 
%$$
%\widetildeby^\toptzero - \widetildebh^\toptzero = (\bZ^*)^{-1/2} (\widetildebZ - \bZ^*) (\bZ^*)^{-1/2} \widetildebh^\toptzero.
%$$
%By the assumption of twice Lipschitz continuity in a neighborhood of the optimal point $\bx^*$,  the definition of average Hessian $\widetildebZ$, and the Cauchy-Schwartz inequality, the above equality implies that 
%\begin{align}
%&\normtwobig{\widetildeby^\toptzero - \widetildebh^\toptzero} \leq \normtwo{(\bZ^*)^{-1/2}}^2 \normtwobig{\widetildebh^\toptzero} \normtwo{\widetildebZ - \bZ^*} \leq \normtwo{(\bZ^*)^{-1/2}}^2 \normtwobig{\widetildebh^\toptzero} \cdot L \epsilon_t \nonumber\\
%&\quad\implies\quad 
%\normtwobig{\widetildeby^\toptzero - \widetildebh^\toptzero} \leq \tau_t \epsilon_t \normtwobig{\widetildebh^\toptzero},
%\quad\text{ with } \tau_t\triangleq \normtwo{(\bZ^*)^{-1/2}}^2 \cdot L \epsilon_t, \label{equation:bfgs_rate_yh_rel}
%\end{align}
%where $ \epsilon_t $ is defined as
%$
%\epsilon_t \triangleq \max \big\{ \normtwobig{\bx^\toptone - \bx^*}, \normtwobig{\bx^\toptzero - \bx^*} \big\}.
%$
%Using the triangle inequality, the above inequality indicates that 
%$$
%\normtwobig{\widetildeby^\toptzero} - \normtwobig{\widetildebh^\toptzero} \leq \tau_t \epsilon_t \normtwobig{\widetildebh^\toptzero} 
%\qquad \text{and}\qquad 
%\normtwobig{\widetildebh^\toptzero} - \normtwobig{\widetildeby^\toptzero} \leq \tau_t \epsilon_t \normtwobig{\widetildebh^\toptzero},
%$$
%which implies that 
%\begin{equation}\label{equation:bfgs_rate_ripy}
%	(1 - \tau_t \epsilon_t) \normtwobig{\widetildebh^\toptzero} \leq \normtwobig{\widetildeby^\toptzero} \leq (1 + \tau_t \epsilon_t) \normtwobig{\widetildebh^\toptzero}.
%\end{equation}
%Combining \eqref{equation:bfgs_rate_yh_rel} and  \eqref{equation:bfgs_rate_ripy} shows that 
%$$
%\small
%\begin{aligned}
%&\gap \normtwobig{\widetildebh^\toptzero}^2 - 2 (\widetildeby^\toptzero)^\top \widetildebh^\toptzero + (1 - \tau_t \epsilon_t)^2\normtwobig{\widetildebh^\toptzero}^2 \\
%&\leq 
%\normtwobig{\widetildebh^\toptzero}^2 - 2 (\widetildeby^\toptzero)^\top \widetildebh^\toptzero + \normtwobig{\widetildeby^\toptzero}^2 
%= \normtwobig{\widetildebh^\toptzero - \widetildeby^\toptzero}^2
%\leq 
%\tau_t^2 \epsilon_t^2 \normtwobig{\widetildebh^\toptzero}^2.
%\end{aligned}
%$$
%Combining the above inequality and the first inequality in \eqref{equation:bfgs_rate_ripy} yields that
%$$
%2 (\widetildeby^\toptzero)^\top \widetildebh^\toptzero \geq (1 - 2 \tau_t \epsilon_t + \tau_t^2 \epsilon_t^2 + 1 - \tau_t^2 \epsilon_t^2) \normtwobig{\widetildebh^\toptzero}^2 = 2 (1 - \tau_t \epsilon_t) \normtwobig{\widetildebh^\toptzero}^2.
%$$
%This provides a lower bound on $\widetilde{\alpha}_t$, which combined with the second inequality in \eqref{equation:bfgs_rate_ripy} also yields an upper bound on $\widetilde{\beta}_t$ (note that the positiveness of $1 - \tau_t \epsilon_t$ will be discussed in the sequel):
%\begin{equation}\label{equation:rate_bfgs_low_alpha}
%\widetilde{\alpha}_t = \frac{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero}{\normtwobig{\widetildebh^\toptzero}^2} \geq 1 - \tau_t \epsilon_t
%\qquad\text{and}\qquad 
%\widetilde{\beta}_t = \frac{\normtwobig{\widetildeby^\toptzero}^2}{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero} \leq \frac{1 + \tau_t \epsilon_t}{1 - \tau_t \epsilon_t}.
%\end{equation}
%%By combining \eqref{equation:bfgs_rate_ripy} and \eqref{equation:rate_bfgs_low_alpha}, we obtain also that
%%\begin{equation}\label{equation:rate_bfgs_upper_beta}
%%	\widetilde{\beta}_t = \frac{\normtwobig{\widetildeby^\toptzero}^2}{(\widetildeby^\toptzero)^\top \widetildebh^\toptzero} \leq \frac{1 + \tau_t \epsilon_t}{1 - \tau_t \epsilon_t}.
%%\end{equation}
%Since $\bx^\toptzero \to \bx^*$, we have that $\epsilon_t \to 0$, and thus by \eqref{equation:rate_bfgs_low_alpha} there exists a positive constant $c > \tau_t$ such that the following inequalities hold for all sufficiently large $t$:
%\begin{equation}\label{equation:rate_bfgs_upper_beta2}
%	\widetilde{\beta}_t \leq 1 + \frac{2 \tau_t}{1 - \tau_t \epsilon_t} \epsilon_t \leq 1 + c \epsilon_t.
%\end{equation}
%
%Using the fact of the nonpositiveness of the function $h(t)=1 - \mu + \ln \mu \leq 0,\, \forall \mu>0$, we have
%$
%\frac{-x}{1 - x} - \ln(1 - x) = h\left(\frac{1}{1 - x}\right) \leq 0.
%$
%Therefore, for $ t $ large enough we can assume that $ \tau_t \epsilon_t < \frac{1}{2} $, which combined with the above inequality implies that 
%$$
%\ln(1 - \tau_t \epsilon_t) \geq \frac{-\tau_t \epsilon_t}{1 - \tau_t \epsilon_t} \geq -2 \tau_t \epsilon_t.
%$$
%This relation and the lower bound on $\widetilde{\alpha}_t$ in \eqref{equation:rate_bfgs_low_alpha} imply that for sufficiently large $ t $, we have
%\begin{equation}\label{equation:rate_bfgs_low_alpha2}
%	\ln (\widetilde{\alpha}_t) \geq \ln(1 - \tau_t \epsilon_t) \geq -2 \tau_t \epsilon_t > -2 c \epsilon_t.
%\end{equation}
%Combining with the upper bound on $\widetilde{\beta}_t$ in \eqref{equation:rate_bfgs_upper_beta2}, this relation shows that $(\widetilde{\beta}_t - \ln (\widetilde{\alpha}_t) - 1) \leq 3 c \epsilon_t $. Plugging into  \eqref{equation:rate_bfgs_recur_phi} gives that 
%\begin{equation}
%0 < \phi(\widetildebH^\toptone) \leq \phi(\widetildebH^\toptzero) + 3 c \epsilon_t 
%+ \left(1 - \frac{\widetilde{\zeta}_t}{\cos^2 (\widetilde{\theta}_t)} + \ln \frac{\widetilde{\zeta}_t}{\cos^2 (\widetilde{\theta}_t)}\right)
%+ \ln \cos^2 (\widetilde{\theta}_t).
%\end{equation}
%Performing telescopic cancellations and making use of \eqref{equation:bfgs_sum_error} we have that
%$$
%\sum_{j=1}^\infty \left( \ln \frac{1}{\cos^2 (\widetilde{\theta}_j)} - \left[ 1 - \frac{\widetilde{\zeta}_j}{\cos^2 (\widetilde{\theta}_j)} + \ln \frac{\widetilde{\zeta}_j}{\cos^2 (\widetilde{\theta}_j)} \right] \right) 
%\leq \phi(\widetildebH^{(1)}) + 3 c \sum_{j=1}^\infty \epsilon_j < +\infty.
%$$
%Since the term in the square brackets is nonpositive, and since $ \ln \left( 1 / \cos^2 (\widetilde{\theta}_j) \right) \geq 0 $ for all $ j $, we obtain the two limits
%$$
%\lim_{j \to \infty} \ln \frac{1}{\cos^2 (\widetilde{\theta}_j)} = 0 
%\qquad\text{and}\qquad 
%\lim_{j \to \infty} \left( 1 - \frac{\widetilde{\zeta}_j}{\cos^2 (\widetilde{\theta}_j)} + \ln \frac{\widetilde{\zeta}_j}{\cos^2 (\widetilde{\theta}_j)} \right) = 0,
%$$
%which imply that
%\begin{equation}\label{equation:bfgs_rate_limit_cond}
%\lim_{j \to \infty} \cos (\widetilde{\theta}_j) = 1
%\qquad\text{and}\qquad 
%\lim_{j \to \infty} \widetilde{\zeta}_j = 1.
%\end{equation}
%
%The essence of the result has now been proven; we need only to interpret these limits in terms of the Dennis--Mor\'{e} characterization of superlinear convergence.
%
%Recalling \eqref{equation:bfgs_conv_bh_theta}, we have
%$$
%\begin{aligned}
%&\frac{\normtwo{(\bZ^*)^{-1/2} (\bH^\toptzero - \bZ^*) \bh^\toptzero}^2}{\normtwo{(\bZ^*)^{1/2} \bh^\toptzero}^2} 
%= \frac{\normtwo{(\widetildebH^\toptzero - \bI) \widetildebh^\toptzero}^2}{\normtwobig{\widetildebh^\toptzero}^2}\\
%&= \frac{\normtwobig{\widetildebH^\toptzero \widetildebh^\toptzero}^2 - 2 (\widetildebh^\toptzero)^\top \widetildebH^\toptzero \widetildebh^\toptzero + \normtwobig{\widetildebh^\toptzero}^2}{\normtwobig{\widetildebh^\toptzero}^2}
%= \frac{\widetilde{\zeta}_t^2}{\cos^2 (\widetilde{\theta}_t)} - 2 \widetilde{\zeta}_t + 1,
%\end{aligned}
%$$
%which, by \eqref{equation:bfgs_rate_limit_cond}, the right-hand-side converges to 0. This concludes that 
%$$
%\lim_{t \to \infty} \frac{\normtwo{(\bH^\toptzero - \bZ^*) \bh^\toptzero}}{\normtwo{\bh^\toptzero}} = 0.
%$$
%\end{proof}




\section{Trust Region Method}\label{section:des_trust_reg}

This section introduces the trust region method. Both this method and the quasi-Newton algorithm are based on Taylor's expansion to approximate the target function locally, but they differ in how they utilize the approximating function. In the quasi-Newton algorithm, we first use the approximation model to determine the descent direction and then specify the step length. In contrast, in the trust region method, we directly solve the approximation model within a bounded region and then iterate to the next point. Therefore, the trust region method effectively selects both the direction and the step length simultaneously.

\subsection{Trust Region Method}

The methods discussed here generate a series of steps leading from the starting position towards the final solution. In the descent methods of Chapter~\ref{chapter:gradient-descent} and Newton's method described in Section~\ref{section:new_methods}, the directions of the steps are determined by the properties of $ f(\bx) $ at the current position.  Similar considerations lead us to trust region methods, where iteration steps are derived from the characteristics of a model of the objective function within a given region. The size of this region is adjusted during the iterations.

We provide an intuitive mathematical expression for the trust region method. Based on the Taylor expansion with Lagrange's remainder term,
$ f(\bx^\toptzero + \bd) = f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} \bd^\top \nabla^2 f(\bx^\toptzero + \gamma\bd) \bd, $
where $ \gamma\in (0, 1) $ is a positive number related to $ \bd $ (Theorem~\ref{theorem:linear_approx}). Similar to  Newton's method (Section~\ref{section:new_methods}), we use a quadratic approximation of $ f(\bx) $ at point $ \bx = \bx^\toptzero $:
\begin{equation}\label{equation:trs_approx}
\psi_t(\bd) \triangleq f(\bx^\toptzero) + \nabla f(\bx^\toptzero)^\top \bd + \frac{1}{2} \bd^\top \bH^\toptzero \bd,  
\end{equation}
where $ \bH^\toptzero $ is a symmetric matrix  that should approximate the Hessian matrix. 
If $ \bH^\toptzero $ exactly matches the Hessian matrix of $ f(\bx) $ at point $ \bx = \bx^\toptzero $, then when $ f(\bx) $ is sufficiently smooth, the approximation error of $ \psi_t(\bd) $ is $ o(\normtwo{\bd}^2) $ (Theorem~\ref{theorem:quad_app_theo}), and $\psi_t(\bd)$ reduces to the form in \eqref{equation:class_new_quadr}.

We have used the second-order Taylor expansion to approximate the target function $ f(\bx) $, it is important to consider that the Taylor expansion only holds for small values of $ \bd $. When $ \bd $ is too large, the model \eqref{equation:trs_approx} may no longer accurately describe the behavior of $ f(\bx) $. 
Therefore, constraints must be added to this model.  We only consider the approximation of $ f(\bx) $ within the following ball:
$$ 
\sB_t \triangleq \sB_2[\bx^\toptzero, \Delta_t]  \triangleq \{\bx^\toptzero + \bd \mid \normtwo{\bd} \leq \Delta_t\}, 
$$
where $ \Delta_t > 0 $ is a parameter related to the iteration. We call $ \sB_t $ the \textit{trust region}, and $ \Delta_t $ the \textit{trust region radius}. As the name suggests, the trust region is the area where we believe $ \psi_t(\bd) $ can adequately  approximate $ f(\bx) $, with $ \Delta_t $ representing the size of this region. 
Thus, each step of the trust region method requires solving the following subproblem (called the \textit{trust region subproblem, TRS}):
\begin{equation}\label{equation:trs_subpro}
\textbf{(TRS)}:\qquad \min_{\bd \in \real^n} \quad \psi_t(\bd), \quad \text{s.t.} \quad \normtwo{\bd} \leq \Delta_t.
\end{equation}

\begin{SCfigure}%[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\includegraphics[width=0.65\textwidth]{./imgs/trust_region_ill.pdf}
\caption{Trust region method at the $t$-th iteration, where $\bd_{\text{n}}^\toptzero$ denotes the optimizer of $\psi(\bd)$ and $\bd_{\text{tr}}^\toptzero$ denotes the optimizer of the trust region method.}
\label{fig:trust_region}
\end{SCfigure}

Figure~\ref{fig:trust_region} shows the solution process for the subproblem in \eqref{equation:trs_subpro}. 
Solid lines represent the contour lines of $ f(\bx) $, while dashed lines represent those of $ \psi_t(\bd) $ (here, $ \bd = \bx - \bx^\toptzero $).
The vector  $ \bd_{\text{n}}^\toptzero $ denotes the descent direction obtained by solving the unconstrained problem $\min_{\bd} \psi_t(\bd)$ (if $ \bH^\toptzero $ is the Hessian matrix, then $ \bd_{\text{n}}^\toptzero $ is the Newton direction), and the vector $ \bd_{\text{tr}}^\toptzero $ denotes the descent direction obtained by solving the trust region subproblem \eqref{equation:trs_subpro}. 
It is evident that these two directions can be quite different. 
The trust region method restricts the size of $ \bd $, making the iteration more conservative and thus performing well even when the Newton direction is not optimal.

In the subproblem \eqref{equation:trs_subpro}, we must also determine the trust region radius $ \Delta_t $. 
In practice, selecting an appropriate trust region radius is crucial as it significantly influences the algorithm's convergence. 
Considering that the trust region radius is a measure of ``how much we trust the model $ \psi_t(\bd) $", if $ \psi_t(\bd) $ accurately approximates the function $ f(\bx) $, we should expand the trust region radius to leverage this approximation over a larger area; otherwise, we should reduce the radius and recompute. 
To measure the quality of the approximation $ \psi_t(\bd) $, we introduce the following \textit{gain factor}:
\begin{equation}\label{equation:trs_reduc_ratio}
\textbf{(Gain factor)}: \qquad \nu_t \triangleq \frac{f(\bx^\toptzero) - f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero)}{\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)},
\end{equation}
where $ \bd_{\text{tr}}^\toptzero $ is the descent direction obtained by solving the subproblem \eqref{equation:trs_subpro}. According to the definition of $ \nu_t $, it represents the ratio of the \textit{actual reduction in the function value} to the \textit{predicted reduction} from the quadratic approximation:
\begin{itemize}
\item If $ \nu_t $ is close to 1, it indicates that using $ \psi_t(\bd) $ to approximate $ f(\bx) $ is highly  successful, suggesting we should increase $ \Delta_t $. 
\item If $ \nu_t $ is very small or even negative, it implies that we have overly trusted the quadratic approximation $ \psi_t(\bd) $, necessitating a reduction in $ \Delta_t $.
\end{itemize}
This mechanism dynamically adjusts $ \Delta_t $ to keep the domain of the quadratic model $ \psi_t(\bd) $ within a reasonable range.


Algorithm~\ref{alg:trust_region1} outlines the complete trust region method. Note that the trust region radius $ \Delta_t $ 
will not grow indefinitely because it has an upper bound control $ \Delta_{\max} $. Moreover, if the trust region constraint does not play a significant role (i.e., the optimal value of the quadratic model is within the trust region), there is no need to increase the trust region radius. Only when $ \psi_t(\bd) $ provides a good approximation and the trust region constraint is effective should we consider increasing $ \Delta_t $.



\begin{algorithm}
\caption{Descent Method with Trust Region}
\label{alg:trust_region1}
\begin{algorithmic}[1]
\Require A twice differentiable function $f(\bx)$; 
\State {\bfseries Input:}  Set the maximum radius $ \Delta_{\max} $, initial radius $ \Delta_1 $, initial point $ \bx^{(1)} $, accept radius $\gamma\in[0,\frac{1}{4})$;
\For{$t=1,2,\ldots$}
\State $\bd_{\text{tr}}^{\toptzero} \leftarrow \text{Solution of trust region subproblem \eqref{equation:trs_subpro}}$;
\State $\nu_t \leftarrow \text{gain factor \eqref{equation:trs_reduc_ratio}}$;
\If{$\nu_t > 0.75$ and $\normtwobig{\bd_{\text{tr}}^\toptzero} =\Delta_t$} \Comment{very good step, and the step is at the border}
\State $\Delta_{t+1} \leftarrow \min\{2 \Delta_t, \Delta_{\max}\}$; \Comment{larger trust region}
\EndIf
\If{$\nu_t < 0.25$} \Comment{poor step}
\State $\Delta_{t+1} \leftarrow \Delta_t / 4$; \Comment{smaller trust region}
\EndIf
\If{$\nu_t > \gamma$} \Comment{reject step if $\nu_t \leq \gamma$}
\State $\bx^\toptone \leftarrow \bx^\toptzero + \bd_{\text{tr}}^{\toptzero}$;
\Else
\State $\bx^\toptone \leftarrow \bx^\toptzero$;
\EndIf
\EndFor
\State {\bfseries Return:}  final $\bx\leftarrow \bx^{(t)}$;
\end{algorithmic}
\end{algorithm}






\subsection{Solving the Trust Region Subproblem}\label{section:solve_trs}
In Algorithm~\ref{alg:trust_region1}, one key issue remains unaddressed: how to solve the trust region subproblem.
In most practical applications, an explicit solution to the trust region subproblem \eqref{equation:trs_subpro} cannot be directly obtained. To find the iteration direction $ \bd_{\text{tr}}^\toptzero $, we need to design algorithms to either solve or approximate the subproblem \eqref{equation:trs_subpro}. 

\subsection*{Hidden Convexity of TRS}
Omitting the superscripts, we consider the following trust region subproblem:
\begin{equation}\label{equation:trs_sub_hidd}
\textbf{(TRS)}:\quad 	\min\, \left\{\psi(\bd) \triangleq f + \bg^\top \bd + \frac{1}{2} \bd^\top \bH \bd, \quad \text{s.t.} \quad \normtwo{\bd} \leq \Delta\right\},
\end{equation}
where $\bH\in\real^{n\times n}$ is symmetric, $\bg\in\real^n$, and $f\in\real$.
Since $\bH$ may not be necessarily positive semidefinite, the objective function is (possibly) non-convex, and the TRS
is (possibly) non-convex. 
We will now show how to transform (TRS) into a convex optimization problem.
First, by the spectral decomposition theorem (Theorem~\ref{theorem:spectral_theorem}), there exist an orthogonal matrix $\bQ$ and a diagonal matrix $\bLambda = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$ such that $\bH = \bQ \bLambda \bQ^\top$. 
Hence, (TRS) can be rewritten as
\begin{equation}\label{equation:trs_sub_hidd2}
\min \left\{ \bd^\top \bQ \bLambda \bQ^\top \bd + 2 \bg^\top \bQ \bQ^\top \bd + 2f : \normtwobig{\bQ^\top \bd}^2 \leq \Delta \right\},
\end{equation}
where we used orthogonal invariance of the $\ell_2$ norm:  $\normtwo{\bQ^\top \bd} = \normtwo{\bd}$. Making the linear change of variables $\by \triangleq \bQ^\top \bd$ and denoting $\bb \triangleq \bQ^\top \bg$,  \eqref{equation:trs_sub_hidd2} reduces to
\begin{equation}\label{equation:trs_sub_hidd3}
\begin{aligned}
& \min_{\by} && \sum_{i=1}^n \lambda_i y_i^2 + 2 \sum_{i=1}^n b_i y_i + 2f \\
& \text{s.t.} && \sum_{i=1}^n y_i^2 \leq \Delta.
\end{aligned}
\end{equation}
The problem is still non-convex since some of the $\lambda_i$'s might be negative. 
However, the signs of the optimal decision variables are known in advance, as stated in the following lemma.
\begin{lemma}[TRS]\label{lemma:trs_slack}
Let $\by^*$ be an optimal solution of \eqref{equation:trs_sub_hidd3}. Then $b_i y_i^* \leq 0$ for all $i = 1, 2, \ldots, n$.
\end{lemma}

\begin{proof}[of Lemma~\ref{lemma:trs_slack}]
Denote the objective function of problem \eqref{equation:trs_sub_hidd3} by
$ f(\by) \triangleq \sum_{i=1}^n \lambda_i y_i^2 + 2 \sum_{i=1}^n b_i y_i + 2f. $
For a $i \in \{1, 2, \ldots, n\}$, define the vector $\widetilde{\by}$ as
$ 
\widetilde{y}_j 
\triangleq 
\small
\begin{cases} 
y_j^*, & j \neq i, \\
-y_i^*, & j = i.
\end{cases} 
$

Then, obviously $\widetilde{\by}$ is also a feasible solution of \eqref{equation:trs_sub_hidd3}, and since $\by^*$ is an optimal solution of \eqref{equation:trs_sub_hidd3}, it follows that
$ f(\by^*) \leq f(\widetilde{\by})$.
This inequality simplifies to
$ \sum_{i=1}^n \lambda_i (y_i^*)^2 + 2 \sum_{i=1}^n b_i y_i^* + 2f \leq \sum_{i=1}^n \lambda_i \widetilde{y}_i^2 + 2 \sum_{i=1}^n b_i \widetilde{y}_i + 2f. $

Using the definition of $\widetilde{\by}$, the above inequality reduces after much cancelation of terms to
$ 2 b_i y_i^* \leq 2 b_i (-y_i^*), $
which implies the desired inequality $b_i y_i^* \leq 0$.
\end{proof}

As a direct consequence of Lemma~\ref{lemma:trs_slack}, for any optimal solution $\by^*$, the equality $\sign(y_i^*) = -\sign(b_i)$ holds when $b_i \neq 0$ and where the $\sign$ function is defined as
$ \sign(x) \triangleq 
\small
\begin{cases} 
1, & x \geq 0, \\
-1, & x < 0.
\end{cases} $

When $b_i = 0$, both $\by^*$ and $\widetilde{\by}$ are optimal (as shown in the proof of Lemma~\ref{lemma:trs_slack}), and hence the sign of $\by^*$ can be chosen arbitrarily. As a consequence, we can make the change of variables $y_i \triangleq -\sign(b_i) \sqrt{z_i} (z_i \geq 0)$, and problem \eqref{equation:trs_sub_hidd3} becomes
\begin{equation}\label{equation:trs_sub_convexrel}
\begin{aligned}
& \min_{\bz} && \sum_{i=1}^n \lambda_i z_i - 2 \sum_{i=1}^n |b_i| \sqrt{z_i} + f \\
& \text{s.t.} && \sum_{i=1}^n z_i \leq \Delta, \\
&&& z_1, z_2, \ldots, z_n \geq 0.
\end{aligned}
\end{equation}
This is clearly a convex optimization problem, with linear constraints and an objective function that is a sum of linear terms and positive multipliers of convex functions $-\sqrt{z_i}$. Therefore, we have shown that the non-convex trust region subproblem (TRS) is equivalent to the convex optimization problem \eqref{equation:trs_sub_convexrel}, which can be solved using any convex programming packages.




\subsection*{Iterative Method}
The trust region subproblem is a constrained optimization problem involving quadratic functions. A pertinent question arises: Can we use the optimality conditions from constrained optimization to solve this subproblem? The following theorem outlines the conditions that an optimal solution $ \bd^* $ must satisfy:


\begin{theorem}[Optimality Conditions of TRS]\label{theorem:trs_kkt}
Let $ \bd^* $ be any optimal point of  the following trust region subproblem
\begin{equation}\label{equation:trs_kkt1}
\min \quad \psi(\bd) = f + \bg^\top \bd + \frac{1}{2} \bd^\top \bH \bd, \quad \text{s.t.} \quad \normtwo{\bd} \leq \Delta,
\end{equation}
where $\bH\in\real^{n\times n}$ is symmetric, $\bg\in\real^n$, and $f\in\real$.
The global minimum is achieved if and only if $ \bd^* $ is feasible and there exists $ \lambda \geq 0 $ such that
\begin{subequations}\label{equation:trs_kkt_conds}
\begin{align}
(\bH + \lambda \bI) \bd^* &= -\bg,\label{equation:trs_kkt2} \\
\lambda (\Delta - \normtwo{\bd^*}) &= 0, \label{equation:trs_kkt3}\\
(\bH + \lambda \bI) &\succeq \bzero. \label{equation:trs_kkt4}
\end{align}
\end{subequations}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:trs_kkt}]
\textbf{Necessity.} We apply the KKT conditions (Theorem~\ref{theorem:kktslat1_slater}) to directly derive the relationships satisfied by $ \bd^* $. 
Since there exist $\widehatbd\in\real^n$ such that $\normtwobig{\widehatbd}< \Delta$, 
the Lagrangian function for problem \eqref{equation:trs_kkt1} is given by:
$$
L(\bd, \lambda) = f + \bg^\top \bd + \frac{1}{2} \bd^\top \bH \bd + \frac{\lambda}{2} (\normtwo{\bd}^2 - \Delta^2),
$$
where the multiplier $ \lambda \geq 0 $. According to the KKT conditions, $ \bd^* $ is a feasible solution, and
$
\nabla_{\bd} L(\bd^*, \lambda) = (\bH + \lambda \bI) \bd^* + \bg = \bzero.
$
Additionally, the complementary slackness shows that 
$
\frac{\lambda}{2} (\Delta^2 - \normtwo{\bd^*}^2) = \bzero,
$
which after rearrangement gives \eqref{equation:trs_kkt2} and \eqref{equation:trs_kkt3}. To prove \eqref{equation:trs_kkt4}, we choose any $ \bd $ satisfying $ \normtwo{\bd} = \Delta $. By optimality and the complementary slackness, we have
$$
\psi(\bd) \geq \psi(\bd^*) = \psi(\bd^*) + \frac{\lambda}{2} (\normtwo{\bd^*}^2 - \normtwo{\bd}^2).
$$
Using equation \eqref{equation:trs_kkt2} to eliminate $\bg$ and substituting into the above formula gives
$
(\bd - \bd^*)^\top(\bH + \lambda \bI)(\bd - \bd^*) \geq \bzero,
$
showing that $\bH + \lambda \bI$ is positive semidefinite.

\paragraph{Sufficiency.}
Since $\bH$ is not necessarily positive semidefinite, the function $\psi(\bd)$ may not be convex, whence we cannot apply Theorem~\ref{theorem:kktslat1_slater} to prove the sufficiency.
Define the auxiliary function
$$
\widehat{\psi}(\bd) \triangleq f + \bg^\top \bd + \frac{1}{2}\bd^\top(\bH + \lambda \bI)\bd = \psi(\bd) + \frac{\lambda}{2}\bd^\top \bd.
$$
From condition \eqref{equation:trs_kkt4}, $\widehat{\psi}(\bd)$ is a convex function with respect to $\bd$. According to condition \eqref{equation:trs_kkt2}, $\bd^*$ satisfies the first-order optimality condition of the convex function. By Theorem~\ref{theorem:suff_sta_conv}, it can be deduced that $\bd^*$ is a global minimizer of $\widehat{\psi}(\bd)$. Given the complementary condition \eqref{equation:trs_kkt3}: $\lambda(\Delta^2 - \normtwo{\bd^*}^2) = 0$, for any feasible $\bd$, we have
$$
\psi(\bd) \geq \psi(\bd^*) + \frac{\lambda}{2}(\normtwo{\bd^*}^2 - \normtwo{\bd}^2)
= \psi(\bd^*) + \frac{\lambda}{2}(\Delta^2 - \normtwo{\bd}^2) \geq \psi(\bd^*). 
$$
This completes the proof.
\end{proof}

Theorem~\ref{theorem:trs_kkt} suggests an iterative method for finding $\bd^*$ when the problem dimension $n$ is small. Based on \eqref{equation:trs_kkt2}, the optimal solution forms a family of vectors parameterized by $\lambda$. 
Suppose $\bH + \lambda \bI$ is positive definite; we define
\begin{equation}
\bd(\lambda) \triangleq -(\bH + \lambda \bI)^{-1}\bg. 
\end{equation}
Thus, we only need to find an appropriate $\lambda$ such that \eqref{equation:trs_kkt3} and \eqref{equation:trs_kkt4} are satisfied. From the complementary condition \eqref{equation:trs_kkt3}, when $\lambda > 0$, we must have $\normtwo{\bd(\lambda)} = \Delta$. According to the positive semidefiniteness condition \eqref{equation:trs_kkt4}, $\lambda$ must satisfy $\lambda \geq -\lambda_{\min}(\bH)$ by the eigenvalue characterization theorem (Theorem~\ref{theorem:eigen_charac}), where $\lambda_{\min}(\bH)$ denotes the smallest eigenvalue of $\bH$. 

Now, let's examine the properties of $\normtwo{\bd(\lambda)}$ as $\lambda$ varies. Suppose $\bH$ admits a spectral decomposition $\bH = \bQ\bLambda \bQ^\top$ (Theorem~\ref{theorem:spectral_theorem}), where $\bQ = [\bq_1, \bq_2, \ldots, \bq_n]$ is an orthogonal matrix, $\bLambda = \diag(\lambda_1, \lambda_2, \ldots, \lambda_n)$ with $\lambda_1 \leq \lambda_2 \leq \ldots \leq \lambda_n$ is a diagonal matrix containing the eigenvalues of $\bH$. 
%For convenience, consider only the case $\lambda_1 \leq 0$ and $\lambda_1<\lambda_2$. Other cases can be analyzed similarly. Clearly, $\bH + \lambda \bI$ has a spectral decomposition $\bH + \lambda \bI = \bQ(\bLambda + \lambda \bI)\bQ^\top$. 
For $\lambda \neq \lambda_i, i\in\{1,2,\ldots,n\}$, we have  
\begin{equation}\label{equation:trs_dlambda}
\bd(\lambda) = -\bQ(\bLambda + \lambda \bI)^{-1}\bQ^\top \bg = -\sum_{i=1}^n \frac{\bq_i^\top \bg}{\lambda_i + \lambda}\bq_i
\quad\implies\quad 
\normtwo{\bd(\lambda)}^2 = \sum_{i=1}^n \frac{(\bq_i^\top \bg)^2}{(\lambda_i + \lambda)^2}.
\end{equation}
From this equation, it follows that:
\begin{itemize}
\item When $\lambda > -\lambda_1$, $\normtwo{\bd(\lambda)}^2$ is a continuous and nonincreasing  function of $\lambda$.
\item When $\lambda > -\lambda_1$ and $\bq_i^\top \bg \neq 0$ for all $i=1,2,\ldots,n$, $\normtwo{\bd(\lambda)}^2$ is a strictly decreasing function of $\lambda$.
\item It follows that $\lim_{\lambda \to \infty} \normtwo{\bd(\lambda)} = 0$.
\item When $\bq_i^\top \bg \neq 0$, $\lim_{\lambda \to -\lambda_i^+} \normtwo{\bd(\lambda)} = \infty$ for all $i=1,2,\ldots,n$.
\end{itemize}
See Figure~\ref{fig:trs_iterative} for a visual illustration.
Since the radius $\Delta>0$, when $\bq_1^\top\bg\neq 0$, there is always a unique solution $\lambda^*\in(-\lambda_1, \infty)$ such that $\normtwo{\bd(\lambda^*)}=\Delta$.
The positive semidefiniteness condition in \eqref{equation:trs_kkt4} requires that $\lambda^*\geq -\lambda_1$. Therefore, such a solution of $\lambda^*$ is unique in $\real$ as well.

\begin{figure}[h]
\centering  
\vspace{-0.15cm} 
%\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\includegraphics[width=0.8\textwidth]{./imgs/trs_iterative.pdf}
\caption{$\normtwo{\bd(\lambda)}$ as a function of $\lambda$, where we assune $\bq_3^\top \bg \neq 0$, $\bq_2^\top \bg \neq 0$, and $\bq_1^\top \bg \neq 0$. When $\lambda\in(-\lambda_1, \infty)$, $\normtwo{\bd(\lambda)}$ is continuous and nonincreasing.}
\label{fig:trs_iterative}
\end{figure}
\paragrapharrow{Case $\bq_1^\top\bg\neq 0$. }
In this scenario, if $\bH$ is positive definite and $\normtwo{\bH^{-1}\bg}\leq \Delta$, then the value $\lambda^*=0$ satisfies the optimality conditions in \eqref{equation:trs_kkt_conds}.
Otherwise, we may call the \textit{Newton-Raphson procedure}  to find the root of $\normtwo{\bd(\lambda)}=0$ in $(-\lambda_1, \infty)$.
Let $g(\lambda) \triangleq \normtwo{\bd(\lambda)} - \Delta$. We aim to find a $\lambda^*$ such that $g(\lambda^*)=0$.
To do this, we initialize $\lambda^{(1)} \in (-\lambda_1, \infty)$ for the first iteration. For the $t$-th iteration, using the linear approximation theorem at $\lambda^\toptzero$ (Theorem~\ref{theorem:linear_approx}):
$$
g(\lambda^\toptzero + \delta) \approx g(\lambda^\toptzero) +   \delta g'(\lambda^\toptzero).
$$
The condition $g(\lambda^\toptzero + \delta)=0$ implies the update rule
\begin{equation}
\lambda^\toptone \leftarrow \lambda^\toptzero - \frac{g(\lambda^\toptzero)}{g'(\lambda^\toptzero)}.
\end{equation}
The full procedure is described in Algorithm~\ref{alg:trs_itera}.
In fact, the approach described above can be applied even when the most negative eigenvalue is a multiple eigenvalue (that is, $0 > \lambda_1 = \lambda_2 = \ldots$), provided that $\bQ_1^\top \bg \neq \bzero$, where $\bQ_1$ is the matrix whose columns span the subspace corresponding to the eigenvalue $\lambda_1$. 


\begin{algorithm}
\caption{Trust Region Subproblem}
\label{alg:trs_itera}
\begin{algorithmic}[1]
%\Require 
\State {\bfseries Input:}  $\lambda^{(1)}$, and given the radius $\Delta > 0$;
\For{$t = 1, 2, \ldots$}
%\State Factor $\bH + \lambda^{(t)} \bI = \bR^\top \bR$ using Cholesky decomposition (Theorem~\ref{section:choleskydecomp});
%\State Solve $\bR^\top \bR \bd_{\text{tr}}^\toptzero = -\bg$, $\bR^\top q_\ell = \bd_{\text{tr}}^\toptzero$;
\State  $\lambda^\toptone \leftarrow \lambda^\toptzero - \frac{g(\lambda^\toptzero)}{g'(\lambda^\toptzero)}$;
\EndFor
\State {\bfseries Return:}  $\bd \leftarrow \bd(\lambda^\toptzero)$;
\end{algorithmic}
\end{algorithm}



\paragrapharrow{Case $\bq_1^\top\bg= 0$. }
When $\bq_1^\top\bg= 0$ or $\bQ_1^\top \bg = \bzero$,  where $\bQ_1$ is the matrix whose columns span the subspace corresponding to the eigenvalue $\lambda_1$, then the condition $\lim_{\lambda \to -\lambda_1^+} \normtwo{\bd(\lambda)} = \infty$ does not hold.
Therefore, there may not be a value $\lambda^* \in (-\lambda_1, \infty)$ such that $\normtwo{\bd(\lambda^*)} = \Delta$ \citep{more1983computing, nocedal1999numerical}. 
At first glance, it might not be clear how $\bd$ and $\lambda$ can be chosen to satisfy the optimality conditions in \eqref{equation:trs_kkt_conds} in this case. 
However, Theorem~\ref{theorem:trs_kkt} still guarantees that the correct value of $\lambda^*$ lies within the interval $[-\lambda_1, \infty)$. 
Thus, the only  possibility is $\lambda^* = -\lambda_1$. All that is left is to find the corresponding $\bd$.
 To find $\bd$, it is not sufficient to simply delete the terms for which $\lambda_i = \lambda_1$ from the formula \eqref{equation:trs_dlambda} and set
\begin{equation}
	\bd = \sum_{i:\lambda_i \neq \lambda_1} \frac{\bq_i^\top \bg}{\lambda_i + \lambda} \bq_i.
\end{equation}
Instead, we note that $(\bH - \lambda_1 \bI)$ is singular, meaning there exists a vector $\bu$ such that $\normtwo{\bu} = 1$ and $(\bH - \lambda_1 \bI)\bu = \bzero$ ($\bu$ is an eigenvector of $\bH$ corresponding to the eigenvalue $\lambda_1$).
Therefore, by the property of the spectral decomposition,  we have $\bq_i^\top \bu = 0$ for $\lambda_i \neq \lambda_1$. 
From this property, if we set
\begin{equation}
\bd \triangleq \sum_{i:\lambda_i \neq \lambda_1} \frac{\bq_i^\top \bg}{\lambda_i + \lambda} \bq_i + \mu \bu
\end{equation}
for any scalar $\mu$, we have
$$
\normtwo{\bd}^2 = \sum_{i:\lambda_i \neq \lambda_1} \left(\frac{\bq_i^\top \bg}{\lambda_i + \lambda}\right)^2 + \mu^2.
$$
This implies that by choosing an appropriate $\mu$, we can always ensure that $\normtwo{\bd} = \Delta$. 
It is straightforward to verify that the optimality conditions \eqref{equation:trs_kkt_conds} are satisfied for this choice of $\bd$ and $\lambda = -\lambda_1$.







\subsection{Convergence Analysis}

This subsection provides a brief introduction to the convergence results of the trust region method.

To estimate the improvement in function values obtained by solving each trust region subproblem, we introduce the definition of the Cauchy point.
\begin{definition}[Cauchy Point]\label{definition:cauchy_point}
Let $\psi_t(\bd)$ be a quadratic approximation of $f(\bx)$ at the point $\bx = \bx^\toptzero$. The constant $\mu_t$ is the solution to the following optimization problem:
$$
\mu_t = \mathop{\argmin}_{\mu\in\real}  \psi_t(-\mu \nabla f(\bx^\toptzero)),
\quad\text{s.t.}\quad
\normtwo{\mu \nabla f(\bx^\toptzero)} \leq \Delta_t, \mu \geq 0.
$$
Then the point $\bx_c^\toptzero \triangleq \bx^\toptzero + \bd_c^\toptzero$ is called the \textit{Cauchy point}, where $\bd_c^\toptzero \triangleq -\mu_t \nabla f(\bx^\toptzero)$.
\end{definition}

According to this definition, the Cauchy point essentially represents an application of the gradient method with exact line search to $\psi_t(\bd)$, considering the trust region constraint. Figure~\ref{fig:cauchy_point} visually illustrates the concept of the Cauchy point.

\begin{SCfigure}%[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\includegraphics[width=0.6\textwidth]{./imgs/cauchy_point.pdf}
\caption{Calculation of the Cauchy point at the $t$-th iteration, which is equivalent to a line search constrained within the trust region.}
\label{fig:cauchy_point}
\end{SCfigure}

In fact, given $\psi_t(\bd)$, the Cauchy point can be explicitly calculated. For convenience, denote $\bg^\toptzero \triangleq \nabla f(\bx^\toptzero)$. 
When $ \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero \leq 0$, the function $\psi_t(-\mu \nabla f(\bx^\toptzero))$ is concave quadratic in $\mu$ and  decreases monotonically with $\mu$ whenever $\bg^\toptzero\neq \bzero$. 
Thus, $\mu_t$ is simply the largest value that satisfies the trust region bound.
When $ \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero >0$, the function $\psi_t(-\mu \nabla f(\bx^\toptzero))$ is convex quadratic in $\mu$, so $\mu_t$ is either unconstrained minimizer of this quadratic function, $\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero$,  or the boundary value, which is equivalent to the first case. 
This yields the following form:
$$
\mu_t = 
\begin{cases} 
\frac{\Delta_t}{\normtwobig{\bg^\toptzero}}, & \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero \leq 0, \\
\min \left\{ \frac{\normtwobig{\bg^\toptzero}^2}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero}, \frac{\Delta_t}{\normtwobig{\bg^\toptzero}} \right\}, & \text{otherwise}.
\end{cases}
$$

The above analysis shows that the Cauchy point is a feasible solution for the trust region subproblem \eqref{equation:trs_subpro}. In practice, the Cauchy point is not generally used as an approximate solution for the next iteration because it essentially represents a steepest descent method with a truncated step length, failing to fully utilize the Hessian matrix $\bH^\toptzero$.
However, in the nonlinear least squares problem, the Cauchy point can be applied to find an approximation with additional considerations; see Section~\ref{section:powell_dog_leg1}.

Despite this, the Cauchy point serves as a benchmark for evaluating the performance of algorithms solving the trust region subproblem. Specifically, it requires that the points generated by the subproblem algorithm are at least as effective as the Cauchy point. It is straightforward to see that using the Cauchy point ensures a decrease in the objective function value of the quadratic model. Indeed, we have the following descent lemma under the Cauchy point.
\begin{lemma}[Descent Lemma under the Cauchy Point]\label{lemma:descen_cauchy_point}
Let $\psi_t(\bd)$ be a quadratic approximation of $f(\bx)$ at the point $\bx = \bx^\toptzero$, and let $\bd_c^\toptzero$ be the descent direction generated by solving for the Cauchy point. 
Then,
\begin{equation}
\psi_t(\bzero) - \psi_t(\bd_c^\toptzero) 
\geq \frac{1}{2} \normtwobig{\bg^\toptzero}
\min \left\{ \Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}} \right\}.
\end{equation}
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:descen_cauchy_point}]
\textbf{Case 1: $\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero \leq 0$.} In this case, we have 
\begin{align*}
\psi_t(\bd_c^\toptzero) - \psi_t(\bzero) 
&= \psi_t\Big(-\frac{\Delta_t }{\normtwobig{\bg^\toptzero}} \bg^\toptzero\Big) - f_t 
= \frac{\Delta_t^2}{2\normtwobig{\bg^\toptzero}^2} \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero -\Delta_t \normtwobig{\bg^\toptzero} \\
&\leq -\Delta_t \normtwobig{\bg^\toptzero} 
\leq -\normtwobig{\bg^\toptzero} \min \left\{  \Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwobig{\bH^\toptzero}} \right\},
\end{align*}
where $f_t \triangleq f(\bx^\toptzero) $, $\bg^\toptzero \triangleq\nabla f(\bx^\toptzero)$, and $\bH^\toptzero \triangleq\nabla^2 f(\bx^\toptzero)$.
This yields the desired result.

\paragraph{Case 2: $\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero > 0$ and $\frac{\normtwobig{\bg^\toptzero}^2}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero} \leq \frac{\Delta_t}{\normtwobig{\bg^\toptzero}}$.}
In this case,  it follows that  $\mu_t = \frac{\normtwobig{\bg^\toptzero}^2}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero}$, whence we have 
$$ 
\small
\begin{aligned}
\psi_t(\bd_c^\toptzero) - \psi_t(\bzero) 
&=  \frac{1}{2} \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero \frac{\normtwobig{\bg^\toptzero}^4}{\big(\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero\big)^2} 
-\frac{\normtwobig{\bg^\toptzero}^4}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero}
= -\frac{1}{2} \frac{\normtwobig{\bg^\toptzero}^4}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero} \\
&\stackrel{\dag}{\leq} -\frac{1}{2} \frac{\normtwobig{\bg^\toptzero}^4}{\normtwo{\bH^\toptzero} \normtwobig{\bg^\toptzero}^2} 
= -\frac{1}{2} \frac{\normtwobig{\bg^\toptzero}^2}{\normtwo{\bH^\toptzero}} 
\leq -\frac{1}{2} \normtwobig{\bg^\toptzero} \min \left\{\Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}}\right\},
\end{aligned}
$$
where the inequality ($\dag$) follows from the Cauchy-Schwartz inequality. This also yields the desired result.

\paragraph{Case 3: $\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero > 0$ and $\frac{\normtwobig{\bg^\toptzero}^2}{\bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero} > \frac{\Delta_t}{\normtwobig{\bg^\toptzero}}$.}
In the remaining case, we have $\mu_t = \frac{\Delta_t}{\normtwobig{\bg^\toptzero}}$. Therefore,
$$
\small
\begin{aligned}
\psi_t(\bd_c^\toptzero) - \psi_t(\bzero) 
&= \frac{1}{2} \frac{\Delta_t^2}{\normtwobig{\bg^\toptzero}^2} \bg^\toptzeroTOP \bH^\toptzero \bg^\toptzero 
-\frac{\Delta_t}{\normtwobig{\bg^\toptzero}} \normtwobig{\bg^\toptzero}^2 
\leq  \frac{1}{2} \frac{\Delta_t^2}{\normtwobig{\bg^\toptzero}^2} \frac{\normtwobig{\bg^\toptzero}^3}{\Delta_t} -\Delta_t \normtwobig{\bg^\toptzero} \\
&= -\frac{1}{2} \Delta_t \normtwobig{\bg^\toptzero} 
\leq -\frac{1}{2} \normtwobig{\bg^\toptzero} \min \left\{\Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}}\right\},
\end{aligned}
$$
yielding the desired result once again.
\end{proof}

In practice, it is then essential to obtain iteration directions $\bd_{\text{tr}}^\toptzero$ that satisfy
$ \psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero) \geq(\psi_t(\bzero) - \psi_t(\bd_c^\toptzero)) $ to ensure sufficient decrease at each iteration.
This means that the estimate
$ \psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero) \geq  \frac{1}{2}\normtwobig{\bg^\toptzero} \min \left\{ \Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}} \right\} $
holds in many cases. This provides a basis for proving the convergence of the trust region algorithm.
\subsection*{Global Convergence}

Now we introduce the global convergence of the trust region algorithm. Recall Algorithm~\ref{alg:trust_region1}, where an acceptance radius $\gamma\in[0,\frac{1}{4})$ is introduced to determine whether to update the iteration point. 
There are two scenarios: when $\gamma = 0$, as long as the original objective function has a decrease will the trust region step be accepted; when $\gamma \in(0,\frac{1}{4})$, only if the improvement $\nu_t$ reaches a certain level will an update be made. 
The convergence results obtained in these two situations differ. Following \citet{nocedal1999numerical}, we separately introduce these two results.
\begin{theoremHigh}[Global Convergence of Trust Region under $\gamma=0$ and SS]\label{theorem:global_conv_trs_eta0}
Let $\gamma = 0$ in Algorithm~\ref{alg:trust_region1}. Suppose that $\normtwo{\bH^\toptzero} \leq L$ for some constant $L$, that $f$ is bounded below on the level set $\sL\triangleq\lev[f, f(\bx^{(1)})]$ and is $\beta$-smooth in the open neighborhood $\sB(\sL, R)  \triangleq \{\bx \mid  \normtwo{\bx-\by} < R \text{ for some } \by\in \sL\}$ for some $R > 0$, and that all approximate solutions of the trust region subproblem satisfy the following inequalities: 
\begin{subequations}
\begin{align}
\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero) 
&\geq c_1 \normtwobig{\bg^\toptzero}
\min \left\{ \Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}} \right\}; \label{equation:global_conv_trs_eta01}\\
\normtwobig{\bd_{\text{tr}}^\toptzero} & \leq c_2\Delta_t, \label{equation:global_conv_trs_eta02}
\end{align}
\end{subequations}
for some positive constants $c_1\leq 1$ and $c_2\geq 1$~\footnote{Note that $c_1=\frac{1}{2}$ in the setting of Cauchy points by Lemma~\ref{lemma:descen_cauchy_point}.}, where $\bd_{\text{tr}}^\toptzero$ is a solution to the trust region subproblem in \eqref{equation:trs_subpro}.
Then
$$
\liminf_{t \to \infty} \normtwobig{\bg^\toptzero} = 0,
$$
i.e., the limit points of $\bx^\toptzero$ contain stationary points.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:global_conv_trs_eta0}]
By performing some technical manipulation with the gain factor $\nu_t$ from \eqref{equation:trs_reduc_ratio}, we obtain
\begin{align*}
|\nu_t - 1| 
&= \left| \frac{\big(f(\bx^\toptzero) - f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero)\big) - \big(\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)\big)}{\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)} \right| 
= \left| \frac{\psi_t(\bd_{\text{tr}}^\toptzero) - f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero)}{\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)} \right|.
\end{align*}
For simplicity, denote $\bg(\bx) \triangleq \nabla f(\bx)$. By the fundamental theorem of calculus (Theorem~\ref{theorem:fund_theo_calculu}), we have  
$$
f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero) = f(\bx^\toptzero) + \bg(\bx^\toptzero)^\top \bd_{\text{tr}}^\toptzero + \int_0^1 \big[\bg\big(\bx^\toptzero + \mu \bd_{\text{tr}}^\toptzero\big) - \bg(\bx^\toptzero)\big]^\top \bd_{\text{tr}}^\toptzero \, d\mu.
$$
It then follows from the definition  of the quadratic approximation $\psi_t$ (Equation~\eqref{equation:trs_approx}) that
\begin{equation}\label{equation:global_conv_trs_eta0_prv1}
\begin{aligned}
\abs{\psi_t(\bd_{\text{tr}}^\toptzero) - f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero)}
&= \left| \frac{1}{2} \bd_{\text{tr}}^\toptzeroTOP \bH^\toptzero \bd_{\text{tr}}^\toptzero - \int_0^1 \big[\bg\big(\bx^\toptzero + \mu \bd_{\text{tr}}^\toptzero\big) - \bg(\bx^\toptzero)\big]^\top \bd_{\text{tr}}^\toptzero \, d\mu \right| \\
&\leq (L/2) \normtwobig{\bd_{\text{tr}}^\toptzero}^2 + \beta \normtwobig{\bd_{\text{tr}}^\toptzero}^2,
\end{aligned}
\end{equation}
where the last inequality follows from the triangle inequality and the Cauchy-Schwartz inequality.
Note we assumed that $\normtwobig{\bd_{\text{tr}}^\toptzero} \leq R$ to ensure that $\bx^\toptzero$ and $\bx^\toptzero + \mu\bd_{\text{tr}}^\toptzero$ both lie in the set $\sB(\sL, R)$.

Suppose for contradiction that there exists $\epsilon > 0$ and a positive index $T$ such that
\begin{equation}\label{equation:global_conv_trs_eta0_assup}
\normtwobig{\bg^\toptzero} \geq \epsilon, \quad \text{for all } t \geq T.
\end{equation}
This indicates that, by \eqref{equation:global_conv_trs_eta01}, 
\begin{equation}\label{equation:global_conv_trs_eta0_prv2}
\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero) 
\geq c_1 \normtwobig{\bg^\toptzero} \min \left\{\Delta_t, \frac{\normtwobig{\bg^\toptzero}}{\normtwo{\bH^\toptzero}}\right\} \geq c_1 \epsilon \min \left( \Delta_t, \frac{\epsilon}{L} \right), 
\quad\forall\, t \geq T.
\end{equation}
Combining \eqref{equation:global_conv_trs_eta0_prv1}, \eqref{equation:global_conv_trs_eta0_prv2}, and the assumption \eqref{equation:global_conv_trs_eta02} yields that 
\begin{equation}\label{equation:global_conv_trs_eta0_prv3}
|\nu_t - 1| \leq \frac{c_2^2 \Delta_t^2 (L/2 + \beta)}{c_1 \epsilon \min(\Delta_t, \epsilon/L)}.
\end{equation}

\paragraph{Case 1: $\Delta_t$ is upper bounded  by $\widetilde{\Delta}$. } We now derive a bound on the right-hand side of the above inequality that holds for all sufficiently small values of $\Delta_t$, that is, for all $\Delta_t \leq \widetilde{\Delta}$, where $\widetilde{\Delta}$ is defined as follows:
\begin{equation}\label{equation:global_conv_trs_eta0_prv4}
\widetilde{\Delta} \triangleq \min \left\{\frac{1}{2} \frac{c_1 \epsilon}{c_2^2 (L/2 + \beta)}, \frac{R}{c_2}\right\}.
\end{equation}
The $R/c_2$ term in this definition ensures that the bound \eqref{equation:global_conv_trs_eta0_prv2} is valid (because $\normtwobig{\bd_{\text{tr}}^\toptzero} \leq c_2 \Delta_t \leq c_2 \widetilde{\Delta} \leq R$). Note that since $c_1 \leq 1$ and $c_2 \geq 1$, we have $\widetilde{\Delta} \leq \epsilon/L$. The  condition $\widetilde{\Delta} \leq \epsilon/L$ implies that for all $\Delta_t \in [0, \widetilde{\Delta}]$, we have $\min(\Delta_t, \epsilon/L) = \Delta_t$, so from \eqref{equation:global_conv_trs_eta0_prv3} and \eqref{equation:global_conv_trs_eta0_prv4}, we have
$$
|\nu_t - 1| \leq \frac{c_2^2 \Delta_t^2 (L/2 + \beta)}{c_1 \epsilon \Delta_t} = \frac{c_2^2 \Delta_t (L/2 + \beta)}{c_1 \epsilon} \leq \frac{c_2^2 \widetilde{\Delta} (L/2 + \beta)}{c_1 \epsilon} \leq \frac{1}{2}.
$$
Therefore, $\nu_t > \frac{1}{4}$, and so by the workings of Algorithm~\ref{alg:trust_region1}, we have $\Delta_{t+1} \geq \Delta_t$ whenever $\Delta_t$ falls below the threshold $\widetilde{\Delta}$. 
\paragraph{Case 2: $\Delta_t$ is lower bounded by $\widetilde{\Delta}$. }It follows that the reduction of $\Delta_t$ (by a factor of $\frac{1}{4}$  in Algorithm~\ref{alg:trust_region1}) can occur in our algorithm only if
$
\Delta_t \geq \widetilde{\Delta}.
$

Combining the two cases concludes that
\begin{equation}\label{equation:global_conv_trs_eta0_prv5}
\Delta_t \geq \min \left( \Delta_T, \frac{\widetilde{\Delta}}{4} \right) \qquad \text{for all } t \geq T.
\end{equation}
Suppose now that there is an infinite subsequence $\sT$ such that $\nu_t \geq \frac{1}{4}$ for $t \in \sT$. 
For $t \in \sT$ and $t \geq T$, by the definition of the gain factor $\nu_t$ in \eqref{equation:trs_reduc_ratio} and \eqref{equation:global_conv_trs_eta0_prv2}, we have 
$$
f(\bx^\toptzero) - f(\bx^\toptone) = f(\bx^\toptzero) - f(\bx^\toptzero + \bd_{\text{tr}}^\toptzero) 
\geq \frac{1}{4} [\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)] 
\geq \frac{1}{4} c_1 \epsilon \min \left( \Delta_t, \frac{\epsilon}{L} \right).
$$
Since $f$ is bounded below, the above inequality indicates that
$
\lim_{t \in \sT, \; t \to \infty} \Delta_t = 0,
$
which contradicts \eqref{equation:global_conv_trs_eta0_prv5}. Hence no such infinite subsequence $\sT$ can exist, and we must have $\nu_t < \frac{1}{4}$ for all $t$ sufficiently large. In this case, $\Delta_t$ will eventually be multiplied by $\frac{1}{4}$ at every iteration, and we have $\lim_{t \to \infty} \Delta_t = 0$, which again contradicts \eqref{equation:global_conv_trs_eta0_prv5}. 
Therefore, the assumption in \eqref{equation:global_conv_trs_eta0_assup} does not hold, and this completes the proof.
\end{proof}

Theorem~\ref{theorem:global_conv_trs_eta0} indicates that if $\gamma=0$ in Algorithm~\ref{alg:trust_region1}, meaning the algorithm always accepts the step when the gain factor is positive, then Algorithm~\ref{alg:trust_region1} only guarantees subsequential convergence; the sequence of iterates itself may not converge.
However, the following theorem demonstrates that choosing $\gamma > 0$ can lead to stronger convergence results.
\begin{theoremHigh}[Global Convergence of Trust Region under $\gamma\neq0$ and SS]\label{theorem:glo_conv_trs_othe}
Let $\gamma \in (0, \frac{1}{4})$ in Algorithm~\ref{alg:trust_region1}, and consider the same conditions  as Theorem~\ref{theorem:global_conv_trs_eta0}.
Then,
\begin{equation}\label{equation:glo_conv_trs_othe}
\lim_{t \to \infty} \bg^\toptzero = \bzero.
\end{equation}
\end{theoremHigh}

\begin{proof}
Consider a particular positive iteration $z$ with a nonzero gradient vector: $\bg^{(z)} \neq \bzero$. Since $f$ is $\beta$-smooth on the set $\sB(\sL, R)$, we have
$$
\normtwobig{\bg(\bx) - \bg^{(z)}} \leq \beta \normtwobig{\bx - \bx^{(z)}}, \quad \text{for all }\bx \in \sB(\sL, R).
$$
Define the scalars $\epsilon$ and $R$ to satisfy
$$
\epsilon \triangleq \frac{1}{2} \normtwobig{\bg^{(z)}}
\qquad \text{and}\qquad 
\widetildeR \triangleq \min \left( \frac{\epsilon}{\beta}, R \right).
$$
Note that the closed ball
$
\sB[\bx^{(z)}, \widetildeR] \triangleq \big\{ \bx \mid \normtwo{\bx - \bx^{(z)}} \leq \widetildeR \big\}
$
is contained in the open neighborhood $\sB(\sL, R)$, so the smoothness of $f$ also holds inside $\sB[\bx^{(z)}, \widetildeR] $. 
We have 
$$
\bx \in \sB[\bx^{(z)}, \widetildeR] 
\quad\implies\quad
\normtwobig{\bg(\bx)} \stackrel{\dag}{\geq} \normtwobig{\bg^{(z)}} - \normtwobig{\bg(\bx) - \bg^{(z)}} \stackrel{\ddag}{\geq} \frac{1}{2} \normtwobig{\bg^{(z)}} = \epsilon.
$$
where the inequality $(\dag)$ follows from the  triangle inequality $\abs{\normtwo{\ba}-\normtwo{\bb}}\leq \normtwo{\ba}-\normtwo{\bb}$ for all $\ba,\bb$, and the inequality $(\ddag)$ follows from the smoothness and the definition of $\widetildeR$.

If the entire sequence $\{\bx^\toptzero\}_{t \geq z}$ stays inside the closed ball $\sB[\bx^{(z)}, \widetildeR] $, we would have $\normtwobig{\bg^\toptzero} \geq \epsilon > 0$ for all $t \geq z$, which contradicts the result in \eqref{equation:glo_conv_trs_othe}. Therefore, there must be an index $t \geq z$ such that $\bx^\toptzero \notin \sB[\bx^{(z)}, \widetildeR] $ for all $t \geq z$. The reasoning in the proof of Theorem~\ref{theorem:global_conv_trs_eta0} can be used to show that this scenario does not occur. Therefore, the sequence $\{\bx^\toptzero\}_{t \geq z}$ eventually leaves $\sB[\bx^{(z)}, \widetildeR] $.

Let $l \geq z$ be the iteration indix such that $\bx^{(l+1)}$ is the first iterate after $\bx^{(z)}$ outside $\sB[\bx^{(z)}, \widetildeR] $. Since $\normtwobig{\bg^\toptzero} \geq \epsilon$ for $t = z, z+1, \ldots, l$, performing telescopic cancellations over $t = z, z+1, \ldots, l$ and using \eqref{equation:global_conv_trs_eta0_prv2}, we have 
\begin{align*}
f(\bx^{(z)}) - f(\bx^{(l+1)}) &= \sum_{t=z}^{l} f(\bx^\toptzero) - f(\bx^\toptone) 
= \sum_{t=z, \bx^\toptzero \neq \bx^\toptone}^{l} \nu_t \big[\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)\big] \\
&\stackrel{\dag}{\geq} \sum_{t=z, \bx^\toptzero \neq \bx^\toptone}^{l} \gamma \big[\psi_t(\bzero) - \psi_t(\bd_{\text{tr}}^\toptzero)\big]
\geq \sum_{t=z, \bx^\toptzero \neq \bx^\toptone}^{l} \gamma c_1 \epsilon \min \left( \Delta_t, \frac{\epsilon}{L} \right),
\end{align*}
where the inequality $(\dag)$ follows from the fact that $\nu_t >\gamma $ when $\bx^\toptzero \neq \bx^\toptone$ in Algorithm~\ref{alg:trust_region1}.
If $\Delta_t \leq \epsilon/L$ for all $t = z, z+1, \ldots, l$, we have
\begin{equation}\label{equation:glo_conv_trs_othe1}
f(\bx^{(z)}) - f(\bx^{(l+1)}) \geq \gamma c_1 \epsilon \sum_{t=z, \bx^\toptzero \neq \bx^\toptone}^{l} \Delta_t \geq \gamma c_1 \epsilon \widetildeR 
= \gamma c_1 \epsilon \min \left( \frac{\epsilon}{\beta}, R \right).
\end{equation}
where the last inequality follows from the fact that $\bx^\toptzero \in \sB[\bx^{(z)}, \widetildeR] $ for $t=z, z+1, \ldots,l$.
Otherwise, we have $\Delta_t > \epsilon/L$ for some $t = z, z+1, \ldots, l$. Therefore,
\begin{equation}\label{equation:glo_conv_trs_othe2}
f(\bx^{(z)}) - f(\bx^{(l+1)}) \geq \gamma c_1 \epsilon \frac{\epsilon}{L}.
\end{equation}
Since the sequence $\{f(\bx^\toptzero)\}_{t=1}^{\infty}$ is decreasing and bounded below, we have that
\begin{equation}
f(\bx^\toptzero) \downarrow f^*, \quad \text{for some } f^* > -\infty.
\end{equation}
Combining the two bounds in \eqref{equation:glo_conv_trs_othe1} and \eqref{equation:glo_conv_trs_othe2}, and the definition of $\epsilon=\frac{1}{2} \normtwobig{\bg^{(z)}}$, we have 
\begin{align*}
f(\bx^{(z)}) - f^* &\geq f(\bx^{(z)}) - f(\bx^{(l+1)}) 
\geq \gamma c_1 \epsilon \min \left( \frac{\epsilon}{L}, \frac{\epsilon}{\beta}, R \right) \\
&= \frac{1}{2} \gamma c_1 \normtwobig{\bg^{(z)}} \min \left( \frac{\normtwo{\bg^{(z)}}}{2L}, \frac{\normtwo{\bg^{(z)}}}{2\beta}, R \right) > 0.
\end{align*}
Since $f(\bx^{(z)}) - f^* \downarrow 0$, we must have $\bg^{(z)} \rightarrow \bzero$, establishing the desired result.
\end{proof}

The above two theorems demonstrate that, unlike Newton-type methods, the trust region method possesses global convergence properties and therefore has less stringent requirements on the choice of the initial iterate. In contrast, the convergence of Newton's method is highly dependent on the choice of the initial iterate (see Theorem~\ref{theorem:conv_classNewton} for more details).




\index{Conjugate gradient}
\index{Hessian-orthogonal}
\section{Conjugate Gradient Method}\label{section:conjugate-descent}
We have discussed the gradient descent (GD, or steepest descent) method (Section~\ref{section:gradient-descent-all}) and Newton's method (Section~\ref{section:new_methods}) previously. In this section we introduce the \textit{conjugate gradient  (CG)} method, which is one between the gradient descent method and  Newton's method.
We have shown that the pure GD (employing the negative gradient as the descent direction) can move back and forth in a zigzag pattern when applied in a quadratic bowl (a ravine-shaped loss curve, see example in Figure~\ref{fig:quadratic_vanillegd_contour8}). 
This zigzag behavior becomes more pronounced if the stepsize is guaranteed by exact line search strategies (Section~\ref{section:line_search}), since the gradient is orthogonal to the previous update step (Lemma~\ref{lemm:linear-search-orghonal} and example in Figure~\ref{fig:conjguatecy_zigzag2}). The choice of orthogonal descent directions fails to preserve the minimum along the previous search directions, and the line search will undermine the progress we have already achieved in the direction of the previous line search. This results in the zigzag pattern in  movement.

Instead of favoring a descent direction that is orthogonal to previous search direction (i.e., $\bd^\toptoneTOP \bd^\toptzero=0$), the {conjugate descent} deflects the direction of the gradient descent method by selecting a search direction that is \textit{Hessian-orthogonal} (i.e., $\bd^\toptoneTOP\bH\bd^\toptzero=0$, or conjugate with respect to $\bH$) or by adding to the steepest descent direction a positive multiple of the direction used in the last step. 
This method only requires the first-order derivatives but overcomes the gradient descent method's shortcoming of slow convergence. At the same
time, the method need not save and compute the second-order derivatives which are needed  Newton's method. In particular, since it does not require
the Hessian matrix or its approximation, it is widely used to solve large scale optimization problems.
However, since the analysis of this method needs the second-order information, so we include this methods in the second-order chapter.

This choice of the conjugate gradient method ensures that the movement is compensated by the curvature information of the loss function. In Figure~\ref{fig:conjugate_tile_A_orthogonals}, we show examples of Hessian-orthogonal pairs when the eigenvalues of the Hessian matrix $\bH$ are different or identical. When the eigenvalues of the Hessian matrix are the same, the Hessian-orthogonality reduces to standard orthogonal cases (this can be shown by the spectral decomposition of the Hessian matrix, where the orthogonal transformation does not alter the orthogonality \citep{lu2021numerical}).



\begin{figure}[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\subfigure[Surface plot: Hessian with different eigenvalues.]{\label{fig:conjugate_tile_A_orthogonal_diffeigenv}
\includegraphics[width=0.481\linewidth]{./imgs/conjugate_tile_A_orthogonal_diffeigenv.pdf}}
\subfigure[Surface plot: Hessian with same eigenvalues.]{\label{fig:conjugate_tile_A_orthogonal_sameeigenv}
\includegraphics[width=0.481\linewidth]{./imgs/conjugate_tile_A_orthogonal_sameeigenv.pdf}}
\caption{Illustration of $\bH$-orthogonal for different Hessian matrices in two-dimensional case:
$\bH=\footnotesize\begin{bmatrix}
	40 & 5 \\ 7 & 10
\end{bmatrix}$ for Fig~\ref{fig:conjugate_tile_A_orthogonal_diffeigenv}
and 
$\bH=\footnotesize\begin{bmatrix}
	40 & 0 \\ 0 & 40
\end{bmatrix}$ 
for Fig~\ref{fig:conjugate_tile_A_orthogonal_sameeigenv}. The $\bH$-orthogonal pairs are orthogonal when $\bH$ has identical eigenvalues.}
\label{fig:conjugate_tile_A_orthogonals}
\end{figure}

We now provide the formal definition of conjugacy as follows:
\begin{definition}[Conjugacy]\label{definition:conjugacy}
Let $\bA\in \real^{n\times n}$ be a positive definite matrix. Then the vectors $\bu, \bv\in \real^n$ are called  \textit{conjugate} with respect to $\bA$ (a.k.a., \textit{$\bA$-conjugate} or simply \textit{conjugate}) if $\bu,\bv\neq \bzero$ and $\bu^\top\bA\bv = 0$.  
The definition can be extended to a set of $m\leq n$ vectors $\bd_1, \bd_2, \ldots, \bd_m\in \real^n$. If 
$$
\bd_i^\top\bA\bd_j = 0, \quad \forall i\neq j,
$$
then the vectors $\bd_1, \bd_2, \ldots, \bd_m$ are called $\bA$-conjugate or simply conjugate.
\end{definition}
Note that if $\bd_1, \bd_2, \ldots, \bd_m$ are  conjugate, then they are linearly independent (see Problem~\ref{prob:indep_conjugate}). When $\bA=\bI$, then the conjugacy reduces to the usual orthogonality.


To the end of this section, we determine a descent direction that is conjugate to the previous search direction with respect to the Hessian matrix $\bH$ for the conjugate gradient method, ensuring that the new update step will not undo the progress made in the previous directions:
$$
\textbf{(CG)}:\qquad \bd^\toptzero = -\nabla f(\bx^\toptzero) + \beta_t \bd^\toptminus,
$$
where $\beta_t$ is a coefficient controlling how much the previous direction would add back to the current search direction.
Three commonly used methods to compute the coefficient are as follows \citep{hestenes1952methods, fletcher1964function}:
\begin{subequations}\label{equation:cg_all_forms}
\begin{align}
	\text{Fletcher-Reeves:\gap } &\beta_t^F = \frac{\nabla f(\bx^\toptzero)^\top \nabla f(\bx^\toptzero)}{\nabla f(\bx^\toptminus)^\top \nabla f(\bx^\toptminus)},\\
	%\noindent \text{and}\gap\gap\gap\gap\gap\gap\gap\gap\gap\gap&\\
	\text{Polak-Ribi\`ere:\gap } &\beta_t^P = \frac{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top \nabla f(\bx^\toptzero)}{\nabla f(\bx^\toptminus)^\top \nabla f(\bx^\toptminus)},\\
	\text{Hestenes-Stiefel:\gap } &\beta_t^H = \frac{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top \nabla f(\bx^\toptzero)}{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top
		\bd^\toptminus}.
\end{align}
\end{subequations}
In the case of a quadratic loss function, the conjugate gradient ensures that the gradient along the previous direction does not increase in magnitude \citep{shewchuk1994introduction, nocedal1999numerical, iserles2009first, goodfellow2016deep}. The full procedure of the conjugate gradient method is formulated in Algorithm~\ref{alg:conjugate_descent}, where it is observed that the first step of conjugate gradient is identical to a step of steepest descent when the stepsize is calculated by exact line search since $\beta_1=0$.

%\begin{lemma}[Orthogonality from Conjugacy]
%Suppose $\bd^\toptzero$ is conjugate to any vector $\ba\in \real^n$ which is orthogonal to $\bg^\toptzero$ (i.e., $\ba^\top \bg^\toptzero = 0$). Then $\bg^\toptone$ is orthogonal to $\ba$.
%\end{lemma}




\begin{algorithm}[h] 
\caption{Fletcher-Reeves Conjugate Gradient}
\label{alg:conjugate_descent}
\begin{algorithmic}[1]
\Require A differentiable function $f(\bx)$;
\State {\bfseries Input:} Initialize $\bx^\topone$, $\bd^\topzero =\bzero $, and $\bg^\topzero = -\bd^\topzero+\bepsilon$;
\For{$t=1,2,\ldots$ } 
\State Compute gradient $\bg^\toptzero = \nabla f(\bx^\toptzero)$;
\State Compute coefficient $\beta_{t} = \frac{ \bg^\toptzeroTOP \bg^\toptzero}{\bg^\toptminusTOP \bg^\toptminus}$ (\text{Fletcher-Reeves});
\State Compute descent direction $\bd^\toptzero = -\bg^\toptzero +\beta_{t}  \bd^\toptminus$;
\State Fixed stepsize $\eta_t=\eta$ or find it by line search: $\eta_t = \arg\min f(\bx^\toptzero + \eta \bd^\toptzero)$;
\State Apply update $\bx^\toptone \leftarrow  \bx^\toptzero + \eta_t\bd^\toptzero$;
\EndFor
\State {\bfseries Return:} resulting parameters $\bx^\toptzero$, and the loss $f(\bx^\toptzero)$.
\end{algorithmic}
\end{algorithm}

\begin{figure}[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\subfigure[GD, fixed $\eta=0.08$.]{\label{fig:cgm_conjugate8}
\includegraphics[width=0.23\linewidth]{./imgs/steepest_gd_mom-0_lrate-8.pdf}}
\subfigure[GD with line search.]{\label{fig:cgm_zigzag2}
\includegraphics[width=0.23\linewidth]{./imgs/steepest_gd_bisection.pdf}}
\subfigure[Conjugate descent, fixed $\eta=0.06$.]{\label{fig:cgm_conjugate2}
\includegraphics[width=0.23\linewidth]{./imgs/conjugate_gd_bisection_fix.pdf}}
\subfigure[Conjugate descent, exact line search.]{\label{fig:cgm_conjugate3}
\includegraphics[width=0.23\linewidth]{./imgs/conjugate_gd_bisection.pdf}}
\caption{Illustration for the  GD with a fixed stepsize, GD with line search, and CG of quadratic form with $\bA=\footnotesize\begin{bmatrix}
20 & 7 \\ 5 & 5
\end{bmatrix}$, $\bb=\bzero$, and $c=0$. The starting point to descent is $\bx_1=[-3,3.5]^\top$.}
\label{fig:cgm-zigzzag}
\end{figure}

In the subsequent sections, we base our derivation of the conjugate gradient on the assumption of a symmetric positive definite $\bA$;  
however, it can be readily adapted to asymmetric matrices. A comparison among GD with a fixed stepsize, GD with line search, and conjugate gradient is shown in Figure~\ref{fig:cgm-zigzzag}, where we observe that the updates in CG have less zigzag pattern than GD with a fixed stepsize and GD with line search.

\index{Quadratic form}
\index{Quadratic model}
\index{Conjugate direction method}
\subsection{Quadratic Model in Conjugate Direction (CD) Method}
%\subsubsection{Quadratic Form in Conjugate Descent}
Following the discussion of the quadratic form in GD (Section~\ref{section:quadratic_vanilla_GD}), the quadratic form in GD with line search (Section~\ref{section:quadratic-in-steepestdescent}), and the quadratic form in momentum (Section~\ref{section:quadratic-in-momentum}), we turn our attention to  the quadratic form in CG. 
%Similarly, the update for the conjugate descent becomes
%\begin{equation}\label{equation:conjugate-quadratic}
%\begin{aligned}
%	\text{Conjugate Descent with Line Search: \gap }\bx^\toptone =  \bx^\toptzero + \eta_t \bd^\toptzero &= \bx^\toptzero  - \frac{\bd^\toptzeroTOP \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero } \bd^\toptzero, \\
%\end{aligned}
%\end{equation}
%where $\bd^\toptzero=(-\bg^\toptzero +\beta_{t}  \bd^\toptminus)$, $\beta_t =\frac{ \bg^\toptzeroTOP \bg^\toptzero}{\bg^\toptminusTOP \bg^\toptminus}$ by Fletcher-Reeves update.



%Suppose the conjugate descent in quadratic form is well defined and when time step $t\rightarrow \infty$, the error (Definition~\ref{definition:error-gd-}) decreases to zero. Since this decrease results from the descent directions, the initial error vector at time $0$ then can be expressed as a linear combination of descent directions:
%$$
%\be_0 = \sum_{i=0}^{T} \gamma_i \bd^{(i)},
%$$
%where $\gamma_i$'s can be obtained in the following equation:
%$$
%\begin{aligned}
%\bd^\toptzeroTOP \bA\be_0 &= \sum_{i=1}^{T} \gamma_i \bd^\toptzeroTOP \bA\bd^{(i)}=\gamma_t \bd^\toptzeroTOP \bA\bd^\toptzero &\text{(by conjugacy)}\\
%\leadto \gamma_t &= \frac{\bd^\toptzeroTOP \bA\be_0}{\bd^\toptzeroTOP \bA\bd^\toptzero}= \frac{\bd^\toptzeroTOP \bA(\be_0+ \sum_{i=0}^{t-1}\eta_i \bd^{(i)} )}{\bd^\toptzeroTOP \bA\bd^\toptzero} &\text{(by conjugacy)}\\
%&=\frac{\bd^\toptzeroTOP \bA\be^\toptzero}{\bd^\toptzeroTOP \bA\bd^\toptzero}.
%\end{aligned}
%$$
%When $\bA$ is further symmetric and nonsingular, we have $\be^\toptzero = \bx^\toptzero-\bx^*  = \bx^\toptzero-\bA^{-1}\bb$. It can be shown $\gamma_t$ is equal to $\frac{\bd^\toptzeroTOP \bg^\toptzero}{\bd^\toptzeroTOP \bA\bd^\toptzero}$. This is exactly the same form (in magnitude) as the stepsize at time $t$ in GD with line search: $\gamma_t = -\eta_t$ (see \eqref{equation:eta-gd-steepest}).


%\subsubsection{Quadratic Form in Conjugate Direction (CD) Method}
As a beginning, we proceed by an exploration of the \textit{conjugate direction (CD)} method, where the distinction between them will become evident in the subsequent discussions. 
According to the definition of conjugacy (Definition~\ref{definition:conjugacy}), it is easy to show that any set of vectors $\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^{(n)}\}\in \real^n$ satisfying this property with respect to the symmetric positive definite Hessian matrix $\bH=\frac{1}{2}(\bA^\top+\bA)$: 
\begin{equation}\label{equation:conjguate-definis}
\bd^{(i)\top} \bH\bd^{(j)}, \gap \forall i\neq j,
\end{equation}
is also linearly independent. That is, the set span the entire $\real^n$ space:
$$
\spn\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^{(n)}\} = \real^n.
$$
Given the initial parameter $\bx^\topone$ and a set of \textit{conjugate directions} $\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^{(n)}\}$ (defined in \eqref{equation:conjguate-definis}), the update at iteration $t$ is given by 
\begin{equation}\label{equation:conjugate_direction-update}
\bx^\toptone \leftarrow \bx^\toptzero +\eta_t \bd^\toptzero,
\end{equation}
where $\eta_t$ is the stepsize at time $t$ and is obtained by minimizing the one-dimensional quadratic function $\phi(\eta)=f(\bx^\toptzero+\eta\bd^\toptzero)$, as presented in \eqref{equation:eta-gd-steepest}:
\begin{equation}\label{equation:conjugate_direction-update2}
\eta_t = - \frac{\bd^\toptzeroTOP \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero } \gap \text{with}\gap  \bg^\toptzero \triangleq \nabla f(\bx^\toptzero).
\end{equation}
Thus, we call it the \textit{conjugate direction method with exact line search}.
Then, we can establish the following theorem that the updates following from the conjugate directions will converge in $n$ steps (the dimension of the parameter) when $\bA$ is symmetric positive definite (the Hessian $\bH=\bA$ in this case).
\begin{theorem}[Converge in $n$ Steps]\label{theorem:conjudate_direc_d-steps}
Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx-\bb^\top\bx+c$ with positive definite $\bA$.
Then, for any initial parameter $\bx^\topone$, the sequence $\{\bx^\toptzero\}$ generated by the conjugate direction method with exact line search in \eqref{equation:conjugate_direction-update} converges to the optimal point $\bx^*$ in at most $n$ steps.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:conjudate_direc_d-steps}]
Since conjugate directions $\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^{(n)}\}$ span the entire $\real^n$ space, the initial error vector $\be^\topone \triangleq \bx^\topone - \bx^*$ (Definition~\ref{definition:error-gd-}) then can be expressed as a linear combination of the conjugate directions:
\begin{equation}\label{equation:dsteps-symmetric}
	\be^\topone = \bx^\topone-\bx^* = \gamma_1\bd^{(1)} + \gamma_2\bd^{(2)}+\ldots+\gamma_n\bd^{(n)}.
\end{equation}
Using the conjugacy in \eqref{equation:conjguate-definis} and the fact that $\bH=\bA$ when $\bA$ is positive definite, the $\gamma_i$'s can be obtained by the following equation:
$$
\begin{aligned}
\bd^\toptzeroTOP \bH\be^\topone &= \sum_{i=1}^{n} \gamma_i \bd^\toptzeroTOP \bH\bd^{(i)}=\gamma_t \bd^\toptzeroTOP \bH\bd^\toptzero \\
\implies \gamma_t &= \frac{\bd^\toptzeroTOP \bH\be^\topone}{\bd^\toptzeroTOP \bA\bd^\toptzero}= \frac{\bd^\toptzeroTOP \bH(\be^\topone+ \sum_{i=1}^{t-1}\eta_i \bd^{(i)} )}{\bd^\toptzeroTOP \bH\bd^\toptzero} 
=\frac{\bd^\toptzeroTOP \bH\be^\toptzero}{\bd^\toptzeroTOP \bH\bd^\toptzero}.
\end{aligned}
$$
When $\bA$ is  symmetric and nonsingular, we have $\be^\toptzero \triangleq \bx^\toptzero-\bx^*  = \bx^\toptzero-\bA^{-1}\bb$. It can be shown that $\gamma_t$ is equal to $\frac{\bd^\toptzeroTOP \bg^\toptzero}{\bd^\toptzeroTOP \bA\bd^\toptzero}$. This is exactly the same form (in magnitude) as the stepsize at iteration $t$ in GD with line search: $\gamma_t = -\eta_t$ (see \eqref{equation:eta-gd-steepest} or \eqref{equation:conjugate_direction-update2}). Substituting into \eqref{equation:dsteps-symmetric}, it follows that 
$$
\bx^* = \bx^\topone + \eta_1\bd^{(1)}+\eta_2\bd^{(2)}+\ldots +\eta_n\bd^{(n)}.
$$
Alternatively, we have updates by \eqref{equation:conjugate_direction-update} that
$$
\begin{aligned}
\bx^{(n+1)} &= \bx^{(n)} + \eta_n\bd^{(n)} 
=\big(\bx^{(n-1)} +\eta_{n-1}\bx^{(n-1)}\big) + \eta_n\bd^{(n)} \\
&= \ldots \\
&= \bx^\topone + \eta_1\bd^{(1)} + \eta_2\bd^{(2)}+\ldots+\eta_n\bd^{(n)} = \bx^*,
\end{aligned}
$$
which completes the proof.
\end{proof}

The above theorem states the conjudate direction given by \eqref{equation:conjugate_direction-update} converges in $n$ steps, i.e., $\bx^{(n+1)}$ minimizes the quadratic function $f(\bx)=\frac{1}{2}\bx^\top\bA\bx-\bb^\top\bx+c$ over the entire space $\real^n$. Furthermore, we can prove at each iteration $t\leq d$, the update $\bx^\toptone$ minimizes the quadratic function over a subspace of $\real^n$. This is known as the \textit{expanding subspace minimization theorem} or the \textit{principal theorem of the conjugate direction method}.
\begin{theorem}[Expanding Subspace Minimization]\label{theorem:expanding_subspace_minimization}
Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx-\bb^\top\bx+c$ with positive definite $\bA$.
For any initial parameter $\bx^\topone$, let the sequence $\{\bx^\toptzero\}$ be generated by the conjugate direction method with exact line search in  \eqref{equation:conjugate_direction-update}. Then it follows that 
\begin{equation}\label{equation:expanding_subspace_minimization_zero}
\bg^\toptoneTOP \bd^{(i)}=0, \gap \forall i=1,2,\ldots, t, \text{ and } t\in \{1,2,\ldots, n\},
\end{equation}
where $\bg^\toptzero \triangleq \nabla f(\bx^\toptzero)= \bA\bx^\toptzero - \bb$,
and $\bx^\toptone$ is the minimizer of $f(\bx)$ over the subspace
\begin{equation}\label{equation:space_d_t}
	\mathbb{D}_t=\left\{\bx \mid \bx=\bx^\topone + \spn\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^\toptzero\}\right\}.
\end{equation}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:expanding_subspace_minimization}]
We first prove $\bg^\toptoneTOP \bd^{(i)}$ by induction. When $t=1$, since $\eta_1$ is obtained to minimize $\phi(\eta)=f(\bx^\topone+\eta\bd^{(1)})$, by Lemma~\ref{lemm:linear-search-orghonal}, we have $\bg^{(2)} = \nabla f(\bx^{(2)})$ that is orthogonal to $\bd^{(1)}$. Suppose now for general $t-1$, the induction hypothesis is satisfied with $\bg^\toptzeroTOP\bd^{(i)}=0$ for $i=0,1,\ldots, t-1$. The $\bg^\toptzero$ has the following update
\begin{equation}\label{equation:conjguate-redsidual-update}
\begin{aligned}
\bg^\toptone &= \bA\bx^\toptone-\bb  =  \bA (\bx^\toptzero+\eta_t\bd^\toptzero) -\bb 
= \bg^\toptzero + \eta_t\bA\bd^\toptzero.
\end{aligned}
\end{equation}
By conjugacy and the induction hypothesis, we have $\bg^\toptoneTOP  \bd^{(i)}=0$ for $i=\{0,1,\ldots,t-1\}$. If we further prove this is also true for $\bg^\toptoneTOP \bd^\toptzero$, we complete the proof. This follows again from Lemma~\ref{lemm:linear-search-orghonal}, the current gradient is orthogonal to the previous search direction $\bd^\toptzero$ under exact line search strategies.


For the second part, we define $g(\bm{\eta}) = f(\bx^\topone+\eta_1\bd^{(1)}+\eta_2\bd^{(2)}+\ldots +\eta_t\bd^\toptzero)$, which is a strictly convex quadratic function over $\bm{\eta}=[\eta_1, \eta_2, \ldots, \eta_t]^\top$ such that 
$$
\frac{\partial g(\bm{\eta})}{\partial \eta_i} = 0, \gap \forall i=1,2,\ldots, t.
$$
This implies 
$$
\underbrace{\nabla f(\bx^\topone +\eta_1\bd^{(1)}+\eta_2\bd^{(2)}+\ldots +\eta_t\bd^\toptzero}_{\nabla f(\bx^\toptone)})^\top \bd^{(i)} = 0,  \gap \forall i=1,2,\ldots, t.
$$
That is, $\bx^\toptone\in \big\{\bx \mid \bx=\bx^\topone + \spn\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^\toptzero\}\big\}$ is the minimizer of $f(\bx)$.
\end{proof}
This theorem, while straightforward, is crucial as it underpins all conjugate direction methods. It's important to highlight that when exact line search is employed, these methods fulfill condition \eqref{equation:expanding_subspace_minimization_zero} and exhibit the property of quadratic termination. In essence, combining conjugacy with exact line search leads to the efficient resolution of quadratic problems, emphasizing the practical significance of this approach in optimization.


\index{Quadratic form}
\subsection{Quadratic Model in Conjugate Gradient (CG) Method}
We have mentioned that the conjugate gradient (CG) method differs from the conjugate descent (CD) method. The distinction lies  in the fact  that the CG method computes a new vector $\bd^\toptone$ using only the previous vector $\bd^\toptzero$ rather than the entire sequence $\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^\toptzero\}$. 
And the resulting $\bd^\toptone$ will automatically be conjugate to the sequence in this sense. In the CG method, each search direction $\bd^\toptzero$ is chosen to be a linear combination of negative gradient $-\bg^\toptzero$ (the steepest descent direction) and the previous direction $\bd^\toptminus$:
\begin{equation}\label{equation:cd_gradient_direction}
\bd^\toptzero =  -\bg^\toptzero + \beta_t \bd^\toptminus.
\end{equation}
Choosing $\beta_t$ to ensure the conjugacy $\bd^\toptzeroTOP \bA\bd^\toptminus = 0$ yields that 
$$
\beta_t = \frac{\bg^\toptzeroTOP\bA\bd^\toptminus}{\bd^\toptminusTOP \bA\bd^\toptminus}
%=\frac{-\br_t^\top\bA\bd^\toptminus}{\bd^\toptminusTOP \bA\bd^\toptminus}
.
$$
This choice of $\beta_t$ and $\bd^\toptzero$ actually results in the conjugate sequence $\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^\toptzero\}$. To see this, we first provide the definition of the \textit{Krylov subspace of degree $t$ for vector $\bv$ with respect to matrix $\bA$}:
$$
\mathcal{K}(\bv; t) \triangleq \spn\{\bv, \bA\bv, \ldots, \bA^{t-1}\bv\}.
$$

\begin{theorem}[Converge in $n$ Steps]\label{theorem:conjudate_CD_d-steps}
Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx-\bb^\top\bx+c$ with positive definite $\bA$.
For any initial parameter $\bx^\topone$, the sequence $\{\bx^\toptzero\}$ generated by the conjugate descent method with exact line search and search directions generated by \eqref{equation:cd_gradient_direction}, converges to the optimal point $\bx^*$ in at most $n$ steps.
The result follows from the following claims:
\begin{subequations}
\begin{align}
\bg^\toptzeroTOP \bg^{(i)} &= 0, \gap \text{for $i=\{1,2,\ldots, t-1\}$};\label{equation:conjudate_CD_d1}\\
\spn\{\bg^{(1)}, \bg^{(2)}, \ldots, \bg^\toptzero\} &= \spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}\}=\mathcal{K}(\bg^{(1)}; t);\label{equation:conjudate_CD_d2}\\
\spn\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^\toptzero\} &= \spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}\}=\mathcal{K}(\bg^{(1)}; t);\label{equation:conjudate_CD_d3}\\
\bd^\toptzeroTOP\bA\bd^{(i)} &= 0, \gap \text{for $i=\{1,2,\ldots, t-1\}$},\label{equation:conjudate_CD_d4}
\end{align}
where \eqref{equation:conjudate_CD_d4} indicates the sequence $\{\bd^\toptzero\}$ is conjugate. 
Using the definition of search directions in \eqref{equation:cd_gradient_direction} and the above results, it also follows that 
\begin{equation}\label{equation:conjudate_CD_d5}
\bd^{(i)\top}\bg^{(i)} = -\bg^{(i)\top}\bg^{(i)} , \gap \text{for $i=\{1,2,\ldots, t\}$}.
\end{equation}
\end{subequations}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:conjudate_CD_d-steps}]
The proof proceeds through induction.  The equations hold trivially when $t=1$. 
Assuming that  for $t$, \eqref{equation:conjudate_CD_d2}, \eqref{equation:conjudate_CD_d3}, and \eqref{equation:conjudate_CD_d4} hold as well; if we can show the  equations still hold for $t+1$, then we complete the proof. By the induction hypothesis, we have 
$$
\bg^\toptzero \in \spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}\}, 
\gap 
\bd^\toptzero \in \spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}\}.
$$
%\subsection*{Forward inclusion}
Left multiplying by $\bA$, it follows that
\begin{equation}\label{equation:dstesps_induction00}
\bA\bd^\toptzero \in \spn\{\bA\bg^{(1)}, \bA^2\bg^{(1)}, \ldots, \bA^{t}\bg^{(1)}\}.
\end{equation}
Since 
\begin{equation}\label{equation:dstesps_induction11}
\begin{aligned}
\bg^\toptone &= \bA\bx^\toptone-\bb 
=\bA(\bx^\toptzero+\eta_t \bd^\toptzero) -\bb = \bg^\toptzero + \eta_t\bA\bd^\toptzero,
\end{aligned}
\end{equation}
then we have 
\begin{equation}\label{equation:dstesps_induction2}
	\bg^\toptone\in \spn\{\bg^{(1)},\bA\bg^{(1)}, \bA^2\bg^{(1)}, \ldots, \bA^{t}\bg^{(1)}\}.
\end{equation}
Combining \eqref{equation:dstesps_induction2} and \eqref{equation:conjudate_CD_d2}, we have 
$$
\spn\{\bg^{(1)}, \bg^{(2)}, \ldots, \bg^\toptzero, \bg^\toptone\} \subset \spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}, \bA^t\bg^{(1)}\}.
$$
%\subsection*{Reverse inclusion}
To see the reverse inclusion, by \eqref{equation:conjudate_CD_d3}, it follows that 
$$
\bA^t \bg^{(1)} = \bA(\bA^{t-1}\bg^{(1)}) \in \spn\{\bA\bd^{(1)}, \bA\bd^{(2)}, \ldots, \bA\bd^\toptzero\}.
$$
Again, by \eqref{equation:dstesps_induction11}, we have $\bA\bd^\toptzero = (\bg^\toptone-\bg^\toptzero)/\eta_t$. Therefore,
$$
\bA^t \bg^{(1)} \in \spn\{\bg^{(1)}, \bg^{(2)}, \ldots, \bg^\toptzero, \bg^\toptone\} .
$$
Combining with \eqref{equation:conjudate_CD_d2}, we have 
$$
\spn\{\bg^{(1)}, \bA\bg^{(1)}, \ldots, \bA^{t-1}\bg^{(1)}, \bA^{t}\bg^{(1)}\}
\subset 
\spn\{\bg^{(1)}, \bg^{(2)}, \ldots, \bg^\toptzero, \bg^\toptone\}.
$$
Therefore, \eqref{equation:conjudate_CD_d2} holds for $t+1$. \eqref{equation:conjudate_CD_d3} follows similarly and also holds for $t+1$.
To see how \eqref{equation:conjudate_CD_d4} holds for $t+1$, we have 
$$
\bd^\toptoneTOP\bA\bd^{(i)} = (-\bg^\toptone + \beta_{t+1}\bd^\toptzero)^\top\bA\bd^{(i)}.
$$
By Theorem~\ref{theorem:expanding_subspace_minimization}, we have 
\begin{equation}\label{equation:dstesps_induction_argue41}
	\bg^\toptoneTOP \bd^{(i)}=0 \text{ for } i\in \{1,2,\ldots, t\}.
\end{equation}
Furthermore, by \eqref{equation:dstesps_induction00} and \eqref{equation:conjudate_CD_d3}, we have 
\begin{equation}\label{equation:dstesps_induction_argue42}
	\bA\bd^{(i)} \in \spn\{\bA\bg^{(1)}, \bA^2\bg^{(1)}, \ldots, \bA^{i}\bg^{(1)}\}\subset 
	\spn\{\bd^{(1)}, \bd^{(2)}, \ldots, \bd^{(i)}, \bd^{(i+1)}\}.
\end{equation}
Combining \eqref{equation:dstesps_induction_argue41} and \eqref{equation:dstesps_induction_argue42}, it then follows that 
$$
\bd^\toptoneTOP\bA\bd^{(i)}=0,\gap \text{ for }i\in \{1,2,\ldots,t-1\}.
$$
We need to further demonstrate $\bd^\toptoneTOP\bA\bd^\toptzero=0$, a result that is evident given the intentional design of the algorithm to satisfy this condition.

To establish the validity of  \eqref{equation:conjudate_CD_d1}, we have $\bd^{(i)} = -\bg^{(i)}+\beta_i\bd^{(i-1)}$. Therefore, $\bg^{(i)} \in \spn\{\bd^{(i)},\bd^{(i-1)}\}$. Furthermore, employing \eqref{equation:dstesps_induction_argue41}, we prove $\bg^\toptzeroTOP\bg^{(i)}=0$ for $i\in\{1,2,\ldots, t-1\}$.
\end{proof}

Note that the equations \eqref{equation:conjudate_CD_d1}, \eqref{equation:conjudate_CD_d4}, and \eqref{equation:conjudate_CD_d5} represent conjugacy of search directions, orthogonality of gradients, and descent property of the search directions, respectively.
Therefore, the CG method developed by \eqref{equation:cd_gradient_direction} that creates conjugate directions $\bd^\toptone\bA\bd^\toptzero=0$ indeed finds a conjugate set $\bd^\toptone\bA\bd^{(i)}=0$ for $i\in\{1,2,\ldots,t\}$. By Theorem~\ref{theorem:conjudate_direc_d-steps}, the CG method thus converges in at most $n$ steps (when $\bA$ is symmetric PD and using exact line search strategies, where the stepsize for iteration $t$ is given in \eqref{equation:conjugate_direction-update2}). The complete procedure is then formulated in Algorithm~\ref{alg:vanilla_conjugate_descent}.

\begin{algorithm}[H] 
\caption{Vanilla Conjugate Gradient Method for Quadratic Models}
\label{alg:vanilla_conjugate_descent}
\begin{algorithmic}[1]
\Require  Symmetric positive definite $\bA\in \real^{n\times n}$;
\State {\bfseries Input:} Initial parameter $\bx^\topone$;
\State {\bfseries Input:} Initialize $\bd^\topzero =\bzero $ and $\bg^\topzero = -\bd^\topzero+\bepsilon$;
\For{$t=1:n$ } 
\State Compute gradient $\bg^\toptzero \leftarrow \nabla f(\bx^\toptzero)$;
\State Compute coefficient $\beta_{t} \leftarrow \frac{ \bg^\toptzeroTOP\bA \bd^\toptminus}{\bg^\toptminusTOP \bA\bg^\toptminus}$;
\State Compute descent direction $\bd^\toptzero \leftarrow -\bg^\toptzero +\beta_{t}  \bd^\toptminus$;
\State Stepsize $\eta_t \leftarrow - \frac{\bd^\toptzeroTOP \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero }$;
\State Apply update $\bx^\toptone \leftarrow \bx^\toptzero + \eta_t\bd^\toptzero$;
\EndFor
\State {\bfseries Return:} resulting parameters $\bx^\toptzero$, and the loss $f(\bx^\toptzero)$.
\end{algorithmic}
\end{algorithm}

\index{Complexity}
\index{Flops}

To further reduce the complexity of the CG algorithm, we  introduce the notion of floating-point operation (flop) counts. We follow the classical route and count the number of \textit{floating-point operations (flops)} that the algorithm requires. Each addition, subtraction, multiplication, division, and square root is considered one flop. Note that we have the convention that an assignment operation is not counted as one flop.
The calculation of the complexity extensively relies on the complexity of the multiplication of two matrices so that we formulate the finding in the following lemma \citep{lu2021numerical}.
\begin{lemma}[Vector Inner Product Complexity]
Given two vectors $\bv,\bw\in \real^{n}$. The  inner product of the two vectors $\bv^\top\bw$ is given by $\bv^\top\bw=v_1w_1+v_2w_2+\ldots v_nw_n$, involving $n$ scalar multiplications and $n-1$ scalar additions. Therefore, the complexity for the inner product is $2n-1$ flops.
\end{lemma}

The complexity of  matrix multiplications thus relies on the complexity of the inner product.
\begin{lemma}[Matrix Multiplication Complexity]\label{lemma:matrix-multi-complexity}
For matrix $\bA\in\real^{m\times n}$ and $\bB\in \real^{n\times k}$, the complexity of the multiplication $\bC=\bA\bB$ is $mk(2n-1)$ flops.
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:matrix-multi-complexity}]
We notice that each entry of $\bC$ involves a vector inner product that requires $n$ multiplications and $n-1$ additions. And there are $mk$ such entries, which leads to the conclusion.
\end{proof}


By Theorem~\ref{theorem:conjudate_CD_d-steps}, we can replace the formula for calculating stepsizes with:
$$
\eta_t = - \frac{\bd^\toptzeroTOP \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero }
\qquad\implies\qquad  
\eta_t = \frac{\textcolor{mylightbluetext}{\bg^\toptzero}^\top \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero }.
$$
According to \eqref{equation:conjguate-redsidual-update}, it follows that $\eta_t\bA\bd^\toptzero = \bg^\toptone-\bg^\toptzero$. Combining with \eqref{equation:expanding_subspace_minimization_zero} and \eqref{equation:conjudate_CD_d1}, $\beta_t$ can also be expressed as 
$$
\beta_t = \frac{\bg^\toptzeroTOP\bA\bd^\toptminus}{\bd^\toptminusTOP \bA\bd^\toptminus}
\qquad\implies\qquad  
\beta_t 
=
-\frac{\bg^\toptzeroTOP\bg^\toptzero}{\bd^\toptminusTOP \bg^\toptminus}
=\frac{\bg^\toptzeroTOP\bg^\toptzero}{\bg^\toptminusTOP \bg^\toptminus}
.
$$
This reduces the computational complexity from $\mathcalO(4n^2)$ to $\mathcalO(4n)$ flops. The practical CG method for positive definite quadratic models is then outlined in Algorithm~\ref{alg:practical_conjugate_descent}.

\begin{algorithm}[H] 
\caption{Practical Conjugate Gradient Method for Quadratic Models}
\label{alg:practical_conjugate_descent}
\begin{algorithmic}[1]
\Require Symmetric positive definite $\bA\in \real^{n\times n}$;
\State {\bfseries Input:} Initial parameter $\bx^\topone$;
\State {\bfseries Input:} Initialize $\bd^\topzero =\bzero $ and $\bg^\topzero = -\bd^\topzero+\bepsilon$;
\For{$t=1:n$ } 
\State Compute gradient $\bg^\toptzero \leftarrow \nabla f(\bx^\toptzero)$;
\State Compute coefficient $\beta_{t} \leftarrow  \frac{\bg^\toptzeroTOP\bg^\toptzero}{\bg^\toptminusTOP \bg^\toptminus}$; \Comment{set $\beta_1=0$ by convention}
\State Compute descent direction $\bd^\toptzero \leftarrow -\bg^\toptzero +\beta_{t}  \bd^\toptminus$;
\State Stepsize $\eta_t \leftarrow \frac{{\bg^\toptzero}^\top \bg^\toptzero}{ \bd^\toptzeroTOP \bA\bd^\toptzero }$;
\State Apply update $\bx^\toptone \leftarrow \bx^\toptzero + \eta_t\bd^\toptzero$;
\EndFor
\State {\bfseries Return:} resulting parameters $\bx^\toptzero$, and the loss $f(\bx^\toptzero)$.
\end{algorithmic}
\end{algorithm}

\index{Spectral decomposition}
\index{Quadratic form}
\index{Symmetry}
\index{Positive definite}
\subsection{Convergence Analysis for  Positive Definite Quadratic Models}
We further discuss the convergence results of the CG method. 
According to \eqref{equation:conjudate_CD_d3}, there exists a set of $\{\sigma_1,\sigma_2,\ldots,\sigma_t\}$ coefficients such that 
\begin{equation}\label{equation:cg-convergence-xt1}
\begin{aligned}
	\bx^\toptone &=\bx^\topone + \eta_1\bd^{(1)}+\eta_2\bd^{(2)}+\ldots+\eta_t\bd^\toptzero  \\
	&= \bx^\topone + \sigma_1\bg^{(1)}+\sigma_2\bA \bg^{(1)}+\ldots+\sigma_t\bA^{t-1}\bg^{(1)}\\
	&\triangleq \bx^\topone + P^{\textcolor{mylightbluetext}{*}}_{t-1}(\bA)\bg^{(1)},
\end{aligned}
\end{equation}
where $P^{\textcolor{mylightbluetext}{*}}_{t-1}(\bA) \triangleq \sigma_1\bI+\sigma_2\bA +\ldots+\sigma_t\bA^{t-1}$ is a polynomial of degree $t-1$ with coefficients $\{\sigma_1, \sigma_2, \ldots, \sigma_t\}$. 
This polynomial is a special case of a polynomial of degree $t-1$ with random coefficients $\{\omega_1, \omega_2, \ldots, \omega_t\}$, denoted by $P_{t-1}(\bA) = \omega_1\bI+\omega_2\bA +\ldots+\omega_t\bA^{t-1}$. (Note that $P_{t-1}$ can take either a scalar or a matrix as its argument).
Suppose the symmetric positive definite $\bA$ admits the spectral decomposition (Theorem~\ref{theorem:spectral_theorem}):
$$
\bA=\bQ\bLambda\bQ^\top  \in \real^{n\times n} 
\qquad\implies\qquad
\bA^{-1} = \bQ\bLambda^{-1}\bQ^\top,
$$ 
where the columns of $\bQ = [\bq_1, \bq_2, \ldots , \bq_n]$ are eigenvectors of $\bA$ and are mutually orthonormal, and the entries of $\bLambda = \diag(\lambda_1, \lambda_2, \ldots , \lambda_n)$ with $ \lambda_1\geq \lambda_2\geq \ldots\geq \lambda_n>0$ are the corresponding eigenvalues of $\bA$, which are real and ordered by magnitude (the eigenvalues are positive due to the positive definiteness assumption of $\bA$). It then follows that any eigenvector of $\bA$ is also an eigenvector of $P_{t-1}(\bA)$:
$$
P_{t-1}(\bA) \bq_i = P_{t-1}(\lambda_i) \bq_i, \gap \forall i\in \{1,2,\ldots, n\}.
$$
Moreover, since the eigenvectors span the entire space $\real^n$, there exists a set of $\{\nu_1,\nu_2,\ldots, \nu_n\}$ coefficients such that the initial error vector $\be^\topone$ can be expressed as 
$
\be^\topone=\bx^\topone - \bx^* = \sum_{i=1}^{n} \nu_i \bq_i,
$
where $\bx^\topone$ is the initial parameter. Combining \eqref{equation:cg-convergence-xt1} and and the expression of $\be^\topone$, this yields the update of the error vector:
\begin{equation}\label{equation:cg-convergence-xt3}
	\small
\begin{aligned}
\be^\toptone &=\bx^\toptone - \bx^*
=\bx^\topone +  P^{\textcolor{black}{*}}_{t-1}(\bA)\bg^{(1)}-\bx^*
=\bx^\topone +  P^{\textcolor{black}{*}}_{t-1}(\bA)\big(\bA\bx^\topone - \bA\underbrace{\bA^{-1} \bb}_{\bx^*}\big)-\bx^*\\
&=\bx^\topone +  P^{\textcolor{black}{*}}_{t-1}(\bA)\bA(\bx^\topone - \bx^*)-\bx^*
=\Big(\bI+P^{\textcolor{black}{*}}_{t-1}(\bA)\bA\Big) (\bx^\topone - \bx^*)\\
&=\Big(\bI+P^{\textcolor{black}{*}}_{t-1}(\bA)\bA\Big) \sum_{i=1}^{n} \nu_i \bq_i= \sum_{i=1}^{n}\Big(1+ \lambda_i P^{\textcolor{black}{*}}_{t-1}(\bA)\Big) \nu_i\bq_i.
\end{aligned}
\end{equation}
To further discuss the convergence results, we  need to use the notion of \textit{energy norm} for error vector $\norm{\be}_{\bA} = (\be^\top\bA\be)^{1/2}$ as discussed in Section~\ref{section:general-converg-steepest}. 
It can be shown that minimizing $\norm{\be^\toptzero}_{\bA}$ is equivalent to minimizing $f(\bx^\toptzero)$ by \eqref{equation:energy-norm-equivalent}.

\begin{remark}[Polynomial Minimization]
Since we proved in Theorem~\ref{theorem:expanding_subspace_minimization} that $\bx^\toptone$ minimizes $f(\bx)$ over the subspace $\mathbb{D}_t$ defined in \eqref{equation:space_d_t}, it also minimizes the energy norm $\norm{\be}_{\bA}$ over the subspace $\mathbb{D}_t$ at iteration $t$. It then follows that $P^{\textcolor{black}{*}}_{t-1}(\bA)$ minimizes over the space of all possible polynomials of degree $t-1$:
$$
P^{\textcolor{black}{*}}_{t-1}(\bA)
=\mathop{\arg\min}_{P_{t-1}(\bA)}  \norm{\bx^\topone +  P_{t-1}(\bA)\bg^{(1)}-\bx^*}_{\bA}.
$$
\end{remark}
Then the update of the squared energy norm can be obtained by
$$
\begin{aligned}
\normbig{\be^\toptone}_{\bA}^2 &= \be^\toptoneTOP \bA\be^\toptone =\be^\toptoneTOP \left(\sum_{i=1}^{n}\lambda_i \bq_i\bq_i^\top\right) \be^\toptone
 = \sum_{i=1}^{n} \lambda_i (\be^\toptoneTOP\bq_i)^2 \\
&\stackrel{\dag}{=}\sum_{i=1}^{n} \lambda_i \bigg(\bq_i^\top \Big(\sum_{j=1}^{n}\big(1+ \lambda_j P^{\textcolor{black}{*}}_{t-1}(\bA)\big) \nu_j\bq_j\Big)\bigg)^2 
\stackrel{\ddag}{=}\sum_{i=1}^{n}  \bigg(1+ \lambda_i P^{\textcolor{black}{*}}_{t-1}(\lambda_i)\bigg)^2  \lambda_i\nu_i^2   \\
&=\mathop{\min}_{P_{t-1}} \sum_{i=1}^{n}  \bigg(1+ \lambda_i  P_{t-1}(\lambda_i)\bigg)^2  \lambda_i\nu_i^2  
\stackrel{+}{\leq} m_t \sum_{i=1}^{n} \lambda_i\nu_i^2    
\leq m_t \cdot \norm{\be_{1}}_{\bA}^2,
\end{aligned}
$$
where the equality ($\dag$) follows from  \eqref{equation:cg-convergence-xt3}, the equality ($\ddag$) follows by $\bq_i^\top\bq_j=0$ if $i\neq j$,
and the inequality ($+$) follows from  $m_t = \mathop{\min}_{P_{t-1}}\mathop{\max}_{1\leq j\leq n} (1+ \lambda_j P_{t-1}(\lambda_j))^2 $. 
Therefore, the rate of convergence for the CG method is controlled by 
\begin{equation}\label{equation:cg-convergence-xt5}
m_t = \mathop{\min}_{P_{t-1}}\mathop{\max}_{1\leq j\leq n}\big(1+ \lambda_j P_{t-1}(\lambda_j)\big)^2.
\end{equation}

\subsection*{Special Case: $\bA$ Has Only $r$ Distinct Eigenvalues}
We then consider some special cases. Firstly, we want to show the CG method terminates in exactly $r$ iterations if the symmetric positive definite $\bA$ has only $r$ distinct eigenvalues. To establish this, suppose $\bA$ has distinct eigenvalues $\mu_1<\mu_2<\ldots<\mu_r$ and  define a polynomial $Q_r(\lambda)$ by 
$$
Q_r(\lambda) \triangleq\frac{(-1)^r}{\mu_1\mu_2\ldots\mu_r} (\lambda-\mu_1)(\lambda-\mu_2)\ldots (\lambda-\mu_r),
$$
where $Q_r(\lambda_i)=0$ for $i=\{1,2,\ldots, n\}$ and $Q_r(0)=1$. Therefore, it follows that the polynomial 
$$
R_{r-1}(\lambda) \triangleq \frac{Q_r(\lambda)-1}{\lambda}
$$
is a polynomial of degree $r-1$ with a root at $\lambda=0$. Setting $t-1=r-1$ in \eqref{equation:cg-convergence-xt5}, we have
$$
\begin{aligned}
0&\leq m_{r}=\mathop{\min}_{P_{r-1}}\mathop{\max}_{1\leq j\leq n}(1+ \lambda_j P_{r-1}(\lambda_j))^2
=\mathop{\max}_{1\leq j\leq n}(1+ \lambda_j R_{r-1}(\lambda_j))^2 
= \mathop{\max}_{1\leq j\leq n} Q_r^2(\lambda_i) = 0.
\end{aligned}
$$
As a result, $m_{r}$=0, and $\norm{\be_{r+1}}_{\bA}=0$, implying $\bx_{r+1} = \bx^*$ and the algorithm terminates at iteration $r$. A specific example is shown in Figure~\ref{fig:conjugate_specialcases}, where Figure~\ref{fig:conjugate_specialcases_2eigenvalue} terminates in two steps since it has two distinct eigenvalues, and Figure~\ref{fig:conjugate_specialcases_1eigenvalue} terminates in just one step as it has one distinct eigenvalue.

\begin{figure}[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\subfigure[CG, 2 distinct eigenvlaues. Finish in 2 steps.]{\label{fig:conjugate_specialcases_2eigenvalue}
	\includegraphics[width=0.481\linewidth]{./imgs/conjugate_gd_bisection_2eigenvector.pdf}}
\subfigure[CG, 1 distinct eigenvalue. Finish in 1 step.]{\label{fig:conjugate_specialcases_1eigenvalue}
	\includegraphics[width=0.481\linewidth]{./imgs/conjugate_gd_bisection_1eigenvector.pdf}}
\caption{Illustration of special cases for CG with exact line search of quadratic forms. $\bA=\footnotesize\begin{bmatrix}
		20 & 5 \\ 5 & 5
	\end{bmatrix}$, $\bb=\bzero$, $c=0$, and starting point to descent is $\bx^\topone=[-2, 2]^\top$ for Fig~\ref{fig:conjugate_specialcases_2eigenvalue}. $\bA=\footnotesize\begin{bmatrix}
		20 & 0 \\ 0 & 20
	\end{bmatrix}$, $\bb=\bzero$, $c=0$, and starting point to descent is $\bx^\topone=[-2, 2]^\top$ for Fig~\ref{fig:conjugate_specialcases_1eigenvalue}.}
\label{fig:conjugate_specialcases}
\end{figure}



\subsection*{Closed Form by Chebyshev Polynomials}
It can be shown that \eqref{equation:cg-convergence-xt5} is minimized by a Chebyshev polynomial, given by
$$
1+ \lambda_j P_{t-1}(\lambda_j) = \frac{T_{t}\left( \frac{\lambda_{\max} + \lambda_{\min} - 2\lambda_j}{\lambda_{\max}-\lambda_{\min}} \right) }
{T_{t}\left( \frac{\lambda_{\max} + \lambda_{\min} }{\lambda_{\max}-\lambda_{\min}} \right) },
$$
where $T_t(w) = \frac{1}{2} \left[ (w+\sqrt{w^2+1})^t + (w-\sqrt{w^2-1})^t\right]$ represents the \textit{Chebyshev polynomial} of degree $t$, and $\lambda_{\max}$ and $\lambda_{\min}$ denote the largest and smallest eigenvalues of $\bA$.
\begin{proof}
To see this, we can express the $m_t$ in \eqref{equation:cg-convergence-xt5} as
\begin{equation}\label{equation:cg-convergence-xt5_rewrite}
	m_t = \mathop{\min}_{P_{t-1}}\mathop{\max}_{1\leq j\leq n}(1+ \lambda_j P_{t-1}(\lambda_j))^2 = \mathop{\min}_{P_{t-1}}\mathop{\max}_{1\leq j\leq n} (\widetilde{P}_{t}(\lambda_i))^2,
\end{equation}
where $\widetilde{P}_{t}(\lambda) \triangleq 1+ \lambda P_{t-1}(\lambda)=1+w_1\lambda + \ldots+w_t\lambda^t$ is a special polynomial of degree  $t$ with $\widetilde{P}_{t}(0)=1$. We note that the Chebyshev polynomial can be expressed on the interval $w\in [-1,1]$ as
$$
T_t(w) =\cos(t \cos^{-1} w), \gap w\in [-1,1] 
\quad\implies\quad 
\abs{T_t(w)} \leq 1,\gap \text{if } w\in [-1,1].
$$
It is observable that $\widetilde{P}_{t}(\lambda)$ oscillates within the range $\pm {T_{t}\left( \frac{\lambda_{\max} + \lambda_{\min} }{\lambda_{\max}-\lambda_{\min}} \right) }^{-1}$ over the domain $[\lambda_{\min}, \lambda_{\max}]$. Suppose there exists a polynomial $S_t(\lambda)$ of degree $t$ such that $S_t(0)=1$ and $S_t$ is better than $\widetilde{P}_t$ on the domain $[\lambda_{\min}, \lambda_{\max}]$. It then follows that the $S_t-\widetilde{P}_t$ has a zero at $\lambda=0$ and other $t$ zeros on the range $[\lambda_{\min}, \lambda_{\max}]$, making it has $t+1$ zeros, which leads to a contradiction. Therefore, $\widetilde{P}_t$ is the optimal polynomial of degree $t$.
This completes the proof.
\end{proof}


Therefore, it follows that
$$
\begin{aligned}
\normbig{\be^\toptone}_{\bA} &\leq T_t\left(  \frac{\lambda_{\max} + \lambda_{\min}}{\lambda_{\max} - \lambda_{\min}}   \right)^{-1} \cdot\normbig{\be^\topone}_{\bA} 
=T_t\left(  \frac{\kappa+1}{\kappa-1}   \right)^{-1} \cdot \normbig{\be^\topone}_{\bA}\\
&= 2\left[ \left(\frac{\sqrt{\kappa}+1}{\sqrt{\kappa}-1}  \right)^t +
\left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}  \right)^t
\right]^{-1} \cdot\normbig{\be^\topone}_{\bA},
\end{aligned}
$$
where $\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}$ is the condition number, and $\left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}  \right)^t \rightarrow 0$ as iteration $t$ grows. A weaker inequality can be obtained by 
$$
\normbig{\be^\toptone}_{\bA} \leq  2 \left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}  \right)^t
\cdot\normbig{\be^\topone}_{\bA}.
$$
Figure~\ref{fig:rate_convergen_conjugae_comparison}  compares the rate of convergence of GD with line search and CG per iteration. It is observed that  CG exhibits significantly faster convergence compared to the GD with line search method.

\begin{figure}[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\subfigure[Rate of convergence for GD with line search per iteration (same as Figure~\ref{fig:rate_convergen_steepest}). The $y$-axis is $\frac{\kappa-1}{\kappa+1}$.]{\label{fig:rate_convergen_steepest1}
	\includegraphics[width=0.481\linewidth]{./imgs/rate_convergen_steepest.pdf}}
\subfigure[Rate of convergence for CG per iteration. The $y$-axis is $\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}$.]{\label{fig:rate_convergen_conjugate}
	\includegraphics[width=0.481\linewidth]{./imgs/rate_convergen_conjugae.pdf}}
\caption{Illustration of the rate of convergence for CG and GD with line search.}
\label{fig:rate_convergen_conjugae_comparison}
\end{figure}

\index{Rate of convergence}
\index{Preconditioning}
\index{Change of variables}
\subsection*{Preconditioning}
Since the smaller the condition number $\kappa$, the faster the convergence (Figure~\ref{fig:rate_convergen_conjugate}). We can accelerate the convergence of CG by transforming the linear system to improve the eigenvalue distribution of $\bA${\textemdash}the procedure is known as \textit{preconditioning}, which is closely related to the change of variables in the non-Euclidean gradient descent methods (see \eqref{equation:gree_cond_opt}, and Sections~\ref{section:als-gradie-descent-taylor} and \ref{section:noneucli_gd}). The variable $\bx$ is transformed to $\widehat{\bx}$ via a nonsingular matrix $\bP$, satisfying
$$
\begin{aligned}
\whbx &\triangleq \bP\bx
\qquad\implies \qquad 
\whf(\whbx) =\frac{1}{2}\whbx^\top (\bP^{-\top} \bA\bP^{-1})\whbx - (\bP^{-\top}\bb)^\top \whbx +c.
\end{aligned}
$$
When $\bA$ is symmetric, the solution of $\whf(\whbx)$ is equivalent to the solution of the linear equation
$$
\begin{aligned}
(\bP^{-\top} \bA\bP^{-1})\whbx &= \bP^{-\top}\bb 
\qquad\implies\qquad \bP^{-\top}\bA\bx=\bP^{-\top}\bb 
\qquad\implies\qquad \bA\bx=\bb.
\end{aligned}
$$
That is, we can solve $\bA\bx=\bb$ indirectly by solving $\bP^{-\top}\bA\bx=\bP^{-\top}\bb$.
Therefore, the rate of convergence of the quadratic form $\whf(\whbx)$ depends on the condition number of $\bP^{-\top} \bA\bP^{-1}$, which can be controlled by the nonsingular matrix $\bP$. 
Intuitively,  preconditioning is a procedure to stretch the quadratic form to make it more spherical so that the eigenvalues are clustered in a smaller range. A specific example is given in Figure~\ref{fig:conjugate_specialcases} that we want to transform the elliptical contour in Figure~\ref{fig:conjugate_specialcases_2eigenvalue} into the spherical contour in Figure~\ref{fig:conjugate_specialcases_1eigenvalue}.
Based on Algorithm~\ref{alg:practical_conjugate_descent}, the preconditioned CG method is formulated in Algorithm~\ref{alg:predicition_CG}.

\begin{algorithm}[h] 
\caption{Transformed-Preconditioned CG for Quadratic Functions}
\label{alg:predicition_CG}
\begin{algorithmic}[1]
\Require  Symmetric positive definite $\bA\in \real^{n\times n}$;
\State {\bfseries Input:} Initial parameter $\whbx^{(1)}$;
\State {\bfseries Input:} Initialize $\whbd^{(0)} =\bzero $ and $\whbg^{(0)} = \whbd^{(0)}+\bepsilon$;
\For{$t=1:n$ } 
\State Compute gradient $\whbg_t \leftarrow \nabla \whf(\whbx^\toptzero) = (\bP^{-\top} \bA\bP^{-1})\whbx- \bP^{-\top}\bb $; \Comment{$=\textcolor{mylightbluetext}{\bP^{-\top}}\bg^\toptzero$}
\State Compute coefficient $\widehat{\beta}_{t} \leftarrow  \frac{\whbg_t^\top\whbg_t}{\whbg_{t-1}^\top \whbg_{t-1}}
$; \Comment{$=
\frac{\bg^\toptzeroTOP \textcolor{mylightbluetext}{(\bP^\top\bP)^{-1}}\bg^\toptzero}
{\bg^\toptminusTOP\textcolor{mylightbluetext}{(\bP^\top\bP)^{-1}} \bg^\toptminus}$}
\State Compute descent direction $\whbd_t \leftarrow -\whbg_{t} +\widehat{\beta}_{t}  \whbd_{t-1}$;
\Comment{$=-\textcolor{mylightbluetext}{\bP^{-\top}}\bg^\toptzero +\widehat{\beta}_{t}  \whbd_{t-1}$}
\State stepsize 
$\widehat{\eta}_t \leftarrow \frac{{\whbg_t}^\top \whbg_t}{ \whbd_t^\top (\bP^{-\top} \bA\bP^{-1})\whbd_t }
$;
\Comment{$=
- \frac{{\bg^\toptzero}^\top \textcolor{mylightbluetext}{(\bP^\top\bP)^{-1}}\bg^\toptzero}{ \whbd_t^\top (\bP^{-\top} \bA\bP^{-1})\whbd_t }$}
\State Apply update $\whbx_{t+1} \leftarrow \whbx^\toptzero + \widehat{\eta}_t\whbd_t$;
\EndFor
\State {\bfseries Return:} resulting parameters $\textcolor{mylightbluetext}{\bx^\toptzero=\bP^{-1}\whbx^\toptzero}$, and the loss $f(\bx^\toptzero)$.
\end{algorithmic}
\end{algorithm}

However, the procedure in Algorithm~\ref{alg:predicition_CG} is not desirable since we need to transform $\bx$ into $\whbx=\bP\bx$ and transform back by $\bx=\bP^{-1}\whbx$ as highlighted in the blue texts of Algorithm~\ref{alg:predicition_CG}. This introduces additional computational overhead. Let $\bM=\bP^\top\bP$, Algorithm~\ref{alg:untransformed_predicition_CG} is proposed to formulate the untransformed-preconditioned CG, which proves to be more efficient  than Algorithm~\ref{alg:predicition_CG}.

\begin{algorithm}[h] 
\caption{Untransformed-Preconditioned CG for Quadratic Functions}
\label{alg:untransformed_predicition_CG}
\begin{algorithmic}[1]
\Require  Symmetric positive definite $\bA\in \real^{n\times n}$;
\State {\bfseries Input:} Initial parameter $\bx^\topone$;
\State {\bfseries Input:} Initialize $\bd^\topzero =\bzero $ and $\bg^\topzero = -\bd^\topzero+\bepsilon$;
\For{$t=1:n$ } 
\State Compute gradient $\bg^\toptzero \leftarrow \nabla f(\bx^\toptzero)$;
\Comment{Same as that of Algorithm~\ref{alg:practical_conjugate_descent}}
\State Compute coefficient $\widehat{\beta}_{t} \leftarrow  \frac{\bg^\toptzeroTOP\textcolor{mylightbluetext}{\bM^{-1}}\bg^\toptzero}{\bg^\toptminusTOP\textcolor{mylightbluetext}{\bM^{-1}} \bg^\toptminus}$; \Comment{Same as that of Algorithm~\ref{alg:predicition_CG}}
\State Compute descent direction $\widetilde{\bd}_t = -\textcolor{mylightbluetext}{\bM^{-1}}\bg^\toptzero +\widehat{\beta}_{t}  \widetilde{\bd}_{t-1}$;
\Comment{$=-\textcolor{mylightbluetext}{\bP^{-1}} \whbd_{t}$ in Algorithm~\ref{alg:predicition_CG}}
\State Stepsize $\widehat{\eta}_t \leftarrow {({\bg^\toptzero}^\top\textcolor{mylightbluetext}{\bM^{-1}} \bg^\toptzero)}/{ (\widetilde{\bd}_t^\top \bA\widetilde{\bd}_t )}$; \Comment{Same as that of Algorithm~\ref{alg:predicition_CG}}
\State Apply update $\bx^\toptone \leftarrow \bx^\toptzero + \widehat{\eta}_t\widetilde{\bd}_t$; \Comment{$=-\textcolor{mylightbluetext}{\bP^{-1}} \Delta\whbx^\toptzero$ in Algorithm~\ref{alg:predicition_CG}}
\EndFor
\State {\bfseries Return:} resulting parameters $\bx^\toptzero$, and the loss $f(\bx^\toptzero)$.
\end{algorithmic}
\end{algorithm}

\begin{figure}[h]
\centering  
\vspace{-0.35cm} 
\subfigtopskip=2pt 
\subfigbottomskip=2pt 
\subfigcapskip=-5pt 
\subfigure[Contour plot of quadratic function with $\bA$.]{\label{fig:conjugate_precondition1}
	\includegraphics[width=0.481\linewidth]{./imgs/conjugate_precondition1.pdf}}
\subfigure[Contour plot of quadratic function with $\bP^{-\top} \bA\bP^{-1}$.]{\label{fig:conjugate_precondition2}
	\includegraphics[width=0.481\linewidth]{./imgs/conjugate_precondition2.pdf}}
\caption{Illustration of preconditioning for $\bA=\footnotesize\begin{bmatrix}
		20&5 \\5&5
	\end{bmatrix}$. $\bP$ is obtained by the Cholesky decomposition such that $\bM=\bA=\bP^\top\bP$.}
\label{fig:conjugate_precondition13}
\end{figure}
\index{Cholesky decomposition}

\paragrapharrow{Second perspective of preconditioning.}
The matrices $\bM^{-1}\bA$ and $\bP^{-\top} \bA\bP^{-1}$ have the same eigenvalues. To see this, suppose the eigenpair of $\bM^{-1}\bA$ is $(\bM^{-1} \bA) \bv =\lambda \bv$, it follows that
$$
(\bP^{-\top} \bA\bP^{-1}) (\bP\bv) = \bP^{-\top} \bA\bv = 
\bP\bP^{-1}\bP^{-\top} \bA\bv 
=\bP\bM^{-1}\bA\bv=\lambda (\bP\bv).
$$
Therefore, the preconditioning can be understood from two perspectives. While the second perspective is to solve $\bM^{-1}\bA\bx = \bM^{-1}\bb$, where the condition number is decided by matrix $\bM^{-1}\bA$.
%The first one we have already formulated above; solve quadratic function $\whf(\whbx)$ with respective to $\whbx$ such that the condition number is decided by $(\bP^{-\top} \bA\bP^{-1})$ where
%$$
%\whf(\whbx) =\frac{1}{2}\whbx^\top (\bP^{-\top} \bA\bP^{-1})\whbx - (\bP^{-\top}\bb)^\top \whbx +c.
%\gap \text{(Perspective 1)}
%$$
%While the second perspective is to solve the quadratic function $f(\bM^{-1}\bx)$ with respective to $\bM^{-1}\bx$
%$$
%f(\bM^{-1}\bx) = \frac{1}{2}\whbx^\top (\bM^{-1} \bA\bM^{-1})\whbx - (\bM^{-1}\bb)^\top \whbx +c
%$$
The simplest preconditioner $\bM^{-1}$ is  a diagonal matrix whose diagonal entries are identical to those of $\bA$, known as \textit{diagonal preconditioning}, in which case  we scale the quadratic form along the coordinate axes. In contrast, the \textit{perfect preconditioner} is $\bM=\bA$ such that $\bM^{-1}\bA=\bI$, whose condition number is 1, in which case  the quadratic form is scaled along its eigenvector directions. In this sense, the $\bP$ can be obtained by the (pseudo) Cholesky decomposition (Theorems~\ref{theorem:cholesky-factor-exist}) such that $\bM=\bA=\bP^\top\bP$. Figure~\ref{fig:conjugate_precondition13} shows the perfect preconditioning on $\bM=\bA=
\footnotesize
\begin{bmatrix}
20&5 \\5&5\\
\end{bmatrix}$ such that the eigenvalues of $\bP^{-\top}\bA\bP^{-1}$ are identical and the condition number is thus equal to 1.


\index{Cholesky decomposition}

\subsection{General Conjugate Gradient Method and Convergence Analysis}
We now revisit the general CG method as introduced in \citet{fletcher1964function}. The method has been previously formulated in Algorithm~\ref{alg:conjugate_descent} at the beginning of this section, where the search direction at $t$-th iteration is 
\begin{equation}\label{equation:search_frcg}
\bd^\toptzero =  -\bg^\toptzero + \beta_t^F \bd^\toptminus
\qquad\text{with}\qquad
\beta_t^F = \frac{\nabla f(\bx^\toptzero)^\top \nabla f(\bx^\toptzero)}{\nabla f(\bx^\toptminus)^\top \nabla f(\bx^\toptminus)}
=\frac{ \bg^\toptzeroTOP \bg^\toptzero}{\bg^\toptminusTOP \bg^\toptminus},
\end{equation}
We may notice the \textit{Fletcher-Reeves Conjugate Gradient} method (Algorithm~\ref{alg:conjugate_descent}) is just the same as the \textit{Practical Conjugate Gradient} method (Algorithm~\ref{alg:practical_conjugate_descent}) under the conditions of a strongly convex quadratic loss function and the use of an exact line search for the stepsize $\eta_t$.

To see why the Fletcher-Reeves Conjugate Gradient (FRCG) algorithm (Algorithm~\ref{alg:conjugate_descent}) works, the search direction $\bd^\toptzero$ must satisfy the descent condition  such that $ \bg^\toptzeroTOP \bd^\toptzero<0$ (Definition~\ref{definition:uncons_des_direct}). The descent condition is satisfied when the stepsize is calculated by exact line search, in which case the gradient $\nabla f(\bx^\toptzero) = \bg^\toptzero$ is orthogonal to search direction $\bd^\toptminus$ (Lemma~\ref{lemm:linear-search-orghonal}): $\bg^\toptzeroTOP\bd^\toptminus=0$. Therefore, 
$$
\bg^\toptzeroTOP \bd^\toptzero = \bg^\toptzeroTOP (-\bg^\toptzero +\beta_t^F\bd^\toptminus ) = -\normtwobig{\bg^\toptzero}^2 + \beta_t^F \bg^\toptzeroTOP \bd^\toptminus<0
$$
when $\eta_t$ is determined by exact line search. These properties result in the global convergence of the Fletcher-Reeves CG method (see Theorem~\ref{theorem:glob_fr_cg}). However, when $\eta_t$ is fixed or calculated by inexact line search, the descent condition $\bg^\toptzeroTOP\bd^\toptzero$ may not be satisfied. This problem, however, can be attacked by \textit{strong Wolfe conditions} \citep{nocedal1999numerical, fletcher1964function}; and we will not go into the details.


\paragrapharrow{Polak-Ribi\`ere conjugate gradient.} We have mentioned previously that the $\beta_t$ can also be computed by the Polak-Ribi\`ere coefficient:
$$
\text{Polak-Ribi\`ere:\gap } \beta_t^P = \frac{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top \nabla f(\bx^\toptzero)}{\nabla f(\bx^\toptminus)^\top \nabla f(\bx^\toptminus)}
=
\frac{(\bg^\toptzero - \bg^\toptminus)^\top  \bg^\toptzero}{ \bg^\toptminusTOP \bg^\toptminus}
.
$$
When the loss function is strongly convex quadratic and the stepsize is chosen by exact line search, the Polak-Ribi\`ere coefficient $\beta_t^P$ is identical to the Fletcher-Reeves coefficient $\beta_t^F$ since $\bg^\toptminusTOP\bg^\toptzero=0$ by Theorem~\ref{theorem:conjudate_CD_d-steps}. 


\paragrapharrow{Hestenes-Stiefel conjugate gradient.} Hestenes-Stiefel coefficient is yet another variant of the Polak-Ribi\`ere coefficient:
$$
\text{Hestenes-Stiefel:\gap } \beta_t^H = \frac{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top \nabla f(\bx^\toptzero)}{\Big(\nabla f(\bx^\toptzero) - \nabla f(\bx^\toptminus)\Big)^\top
\bd^\toptminus}
=
\frac{(\bg^\toptzero - \bg^\toptminus)^\top  \bg^\toptzero}{ (\bg^\toptzero - \bg^\toptminus)^\top \bd^\toptminus}.
$$
When the loss function is strongly convex quadratic and the stepsize is chosen by exact line search, the Hestenes-Stiefel coefficient $\beta_t^H$ is identical to the Fletcher-Reeves coefficient $\beta_t^F$ since $\bg^\toptminusTOP\bg^\toptzero=0$ by Theorem~\ref{theorem:conjudate_CD_d-steps} and $\bg^\toptzeroTOP\bd^{(t-2)}=\bg^\toptminusTOP\bd^{(t-2)}=0$ by Theorem~\ref{theorem:expanding_subspace_minimization} \citep{hestenes1952methods}.

Moreover, numerical experiments show that the Polak-Ribi\`ere coefficient and Hestenes
-Stiefel coefficient are more robust than Fletcher-Reeves coefficient in non-convex settings \citep{nocedal1999numerical}.


For simplicity, we only prove the global convergence of the Fletcher-Reeves CG method with exact line search. The convergence results for alternative algorithms can be found, for example, in \citet{nocedal1999numerical, dai1999nonlinear, sun2006optimization}.
\begin{theoremHigh}[Global Convergence of FRCG with Exact Line Search]\label{theorem:glob_fr_cg}
Let  $f: \real^n \to \real$ be a continuously differentiable function on a bounded level set $\sL \triangleq\lev[f, \bx^\topone] = \{\bx \in \real^n \mid f(\bx) \leq f(\bx^\topone)\}$, and let the Fletcher-Reeves CG method (Algorithm~\ref{alg:conjugate_descent}) be implemented with exact line search. Then the produced sequence $\{\bx^\toptzero\}_{t>0}$ has at least one accumulation point which is a stationary point, i.e.,
\begin{enumerate}[(i)]
\item When $\{\bx^\toptzero\}$ is a finite sequence, then the final point $\bx^*$ is a stationary point of $f$;
\item When $\{\bx^\toptzero\}$ is an infinite sequence, it has limit point, and any limit point is a stationary point.
\end{enumerate}
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:glob_fr_cg}]
\textbf{(i).} When $\{\bx^\toptzero\}$ is finite, from the termination condition, it follows that the final point $\bx^*$ satisfies $\nabla f(\bx^*) = \bzero $, and hence $\bx^*$ is a stationary point of $f$.

\paragraph{(ii).} When $\{\bx^\toptzero\}$ is infinite, we have $\nabla f(\bx^\toptzero) \neq \bzero, \forall t$. Noting that $\bd^\toptzero = -\bg^\toptzero + \beta_{t} \bd^\toptminus$ and $\bg^\toptzeroTOP \bd^\toptminus = 0$ by exact line search (Lemma~\ref{lemm:linear-search-orghonal}), we have
\begin{equation}
\bg^\toptzeroTOP \bd^\toptzero = -\normtwobig{\bg^\toptzero}^2 + \beta_{t} \bg^\toptzeroTOP \bd^\toptminus = -\normtwobig{\bg^\toptzero}^2 < 0,
\end{equation}
which means that $\bd^\toptzero$ is a descent direction, $\{f(\bx^\toptzero)\}$ is a monotone descent sequence, and thus $\{\bx^\toptzero\} \subset \sL$. Therefore $\{\bx^\toptzero\}$ is a bounded sequence and must have a limit point.

Let $\bx^*$ be a limit point of $\{\bx^\toptzero\}$. Then there is a subsequence $\{\bx^\toptzero\}_{\sT_1}$ converging to $\bx^*$, where $\sT_1$ is an index set of a subsequence of $\{\bx^\toptzero\}$. Since $\{\bx^\toptzero\}_{\sT_1} \subset \{\bx^\toptzero\}$, $\{f(\bx^\toptzero)\}_{\sT_1} \subset \{f(\bx^\toptzero)\}$. It follows from the continuity of $f$ that for $t \in \sT_1$,
\begin{equation}
f(\bx^*) = f(\lim_{t \to \infty} \bx^\toptzero) = \lim_{t \to \infty} f(\bx^\toptzero).
\end{equation}

Similarly, $\{\bx^\toptone\}$ is also a bounded sequence. Hence there exists a subsequence $\{\bx^\toptone\}_{\sT_2}$ converging to $\widetildebx^*$, where $\sT_2$ is an index set of a subsequence of $\{\bx^\toptone\}$. In this case,
\begin{equation}
f(\widetildebx^*) = f(\lim_{t \to \infty} \bx^\toptone) = \lim_{t \to \infty} f(\bx^\toptone).
\end{equation}
This indicates $
f(\widetildebx^*) = f(\bx^*)
$.

Now we prove $\nabla f(\bx^*) = \bzero$ by contradiction. Suppose that $\nabla f(\bx^*) \neq \bzero$, then, for $\eta$ sufficiently small, there exists a search direction $\bd^*$ such that 
\begin{equation}\label{eeuation:conv_frcd_lim}
f(\bx^* + \eta \bd^*) < f(\bx^*).
\end{equation}
Since
$ f(\bx^\toptone) = f(\bx^\toptzero + \eta_t \bd^\toptzero) \leq f(\bx^\toptzero + \eta \bd^\toptzero), \; \forall \eta > 0, $
then for $t \in \sT_2$, passing to the limit $t \to \infty$ and using \eqref{eeuation:conv_frcd_lim}, we get
\begin{equation}
f(\widetildebx^*) \leq f(\bx^* + \eta \bd^*) < f(\bx^*),
\end{equation}
which contradicts the fact $
f(\widetildebx^*) = f(\bx^*)
$. 
This proves $\nabla f(\bx^*) = \bzero$, i.e., $\bx^*$ is a stationary point of $f$. 
\end{proof}





\begin{problemset}
% https://math.stackexchange.com/questions/4653146/condition-number-change-in-cholesky-matrix-decomposition
%\item \label{problem:cond_pd} Given the Cholesky decomposition of a PD matrix: $\bA=\bL\bD\bL^\top$, show that $\cond(\bA)\geq \cond(\bD)$.

\item Prove the relation in \eqref{equation:bfgs_det}.

\item \label{prob:indep_conjugate} Prove that if $\bd_1, \bd_2, \ldots, \bd_m$ are $\bA$-conjugate, where $\bA\in\real^{n\times n}$ is positive definite, then they are linearly independent.

\item Use Newton's method, trust region method, and the Fletcher-Reeves Conjugate Gradient (FRCG) algorithm to minimize the following function:
$$
f(\bx) = x_1^2 + 8x_2^2 +3x_1x_2 +6x_1
$$
with the initial point $\bx^{(1)} = [0,0]^\top$.

\item Verify that the BFGS updates in \eqref{equation:bfgs_update} and \eqref{equation:bfgs2_update} are inverses to each other.

\item Prove the equalities in \eqref{equation:bfgs_trace} and \eqref{equation:bfgs_det}.

\item Show that when applied to a quadratic function, using CG with exact line search strategy, both the Polak-Ribi\`ere and Hestenes-Stiefel updates reduce to the Fletcher-Reeves update in \eqref{equation:cg_all_forms}.
\end{problemset}



