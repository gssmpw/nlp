
\newpage
\chapter{Optimization and Optimality Conditions}\label{chapter:opt_cond}
\begingroup
\hypersetup{
linkcolor=structurecolor,
linktoc=page,  % page: only the page will be colored; section, all, none etc
}
\minitoc \newpage
\endgroup

\section{Classes of Sets and Functions}



We  briefly introduce different notions of sets and functions.

\subsection{Interior Points and Closed Sets}

Given a specific norm definition, we introduce the concepts of an open ball and a closed ball as follows:
\begin{definition}[Open Ball, Closed Ball]\label{definition:open_closed_ball}
Let $\norm{\cdot}_p: \real^n\rightarrow \real_+$ be the $\ell_p$ norm function. The \textit{open ball} centered at $\bc\in\real^n$ with radius $r$  is defined as 
$$
\sB_p(\bc, r) \triangleq \{\bx\in\real^n\mid  \norm{\bx-\bc}_p <r\}.
$$
Similarly, the \textit{closed ball} centered at $\bc\in\real^n$ with radius $r$  is defined as 
$$
\sB_p[\bc,r] \triangleq \{\bx\in\real^n\mid \norm{\bx-\bc}_p \leq r\}.
$$
For example, $\sB_2[\bzero,1]$ represents  the unit closed ball w.r.t. to  the $\ell_2$ norm.
To simplify notation, we omit the subscript 2 for  $\ell_2$ norms and  $\bzero$ for balls centered at zero, e.g., $ \sB[1] \triangleq \sB_2[\bzero,1]  $.
As a special case, the notation $\sB_0[k] \triangleq\sB_0[\bzero, k]$ denotes the set of \textit{$k$-sparse vectors}, i.e., containing vectors that have only $k$ (or less) nonzero elements.
More generally, let $\norm{\cdot}$ be any norm, the induced open and closed balls are denoted as 
$$
\sB_{\norm{\cdot}} (\bc, r)
\qquad \text{and}\qquad 
\sB_{\norm{\cdot}} [\bc, r].
$$
\end{definition}

Subsequently, we define the concepts of interior and relative interior points. These concepts are foundational in topology and convex analysis and are based on the definitions of balls.
\index{Interior points}
\index{Relative interior points}
\begin{definition}[Interior and Relative Interior Points]
The \textit{interior} of a set $ \sS $ in a topological space is the set of all points in $ \sS $ that have a neighborhood completely contained within $ \sS $. Formally, the interior of $ \sS $, denoted by $ \interior(\sS) $, is given by:
$$
\interior(\sS) = \{ \bx \in \sS \mid \exists \epsilon > 0 \text{ such that } \sB(\bx, \epsilon) \subseteq \sS \}.
$$
where $ \sB(\bx, \epsilon) $ is an open ball centered at $ \bx $ with radius $ \epsilon $.



The \textit{relative interior} of a set $ \sS $ in a topological space, typically within the context of convex analysis, is the interior of $ \sS $ relative to its affine hull. The \textit{affine hull} of $ \sS $, denoted by $ \aff(\sS) $, is the smallest affine space containing $ \sS $ (Definition~\ref{definition:coms_hulls}). The relative interior of $ \sS $, denoted by $ \relint(\sS) $, is given by:
$$
\relint(\sS) = \{ \bx \in \sS \mid \exists \epsilon > 0 \text{ such that } \sB_{\aff(\sS)}(\bx, \epsilon) \subseteq \sS \}.
$$
where $ \sB_{\aff(\sS)}(\bx, \epsilon) $ is the open ball centered at $ \bx $ with radius $ \epsilon $ in the subspace topology of $ \aff(\sS) $.

In other words, the \textit{interior} of a set is concerned with the open balls in the ambient space; the \textit{relative interior} is concerned with open balls in the affine hull of the set, which is particularly important in higher dimensions and in convex analysis where the set may lie in a lower-dimensional subspace.
\end{definition}


\begin{example}[Interior and Relative Interior Points]
\textbf{Interval in $\real$.} Let $ \sS = [0, 1] $. Then $ \interior(\sS) = (0, 1) $ and $ \relint(\sS) = (0, 1) $. Here, the interior and relative interior are the same because the set $ [0, 1] $ is a subset of $\real$ and $\aff(\sS) = \real$.

\paragraph{Line Segment in $\real^2$.} Let $ \sS = \{ (x, y) \in \real^2 \mid 0 \leq x \leq 1, y = 0 \} $ with
$\aff(\sS)=\{(x,0)\in\real^2 \mid x\in\real\}$. Then  $ \interior(\sS) = \varnothing $ and $ \relint(\sS) = \{ (x, 0) \mid 0 < x < 1 \} $.
The interior is empty because there are no open balls in $\real^2$ entirely contained within $ \sS $. However, the relative interior is the open interval (0, 1) in the context of the line segment (the affine hull is the line $ y = 0 $).

\paragraph{Triangle in $\real^2$.} Let $ \sS $ be a triangle with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. Then the interior consists of all points inside the triangle, excluding the boundary; while the  relative interior is the same as the interior in this case because the affine hull of the triangle is the entire plane $ \real^2 $.
\end{example}

\index{Open sets}
\index{Closed sets}
\index{Compact sets}
\index{Level sets}
\begin{definition}[Open, Closed, Compact, and Level Sets]\label{definition:open_close_sets}
A set $\sS_1$ is said to be \textit{open} if it consists of only interior points. That is, for every $\bx\in\sS$, there exists a scalar $s>0$ such that $\sB(\bx, s)\subseteq\sS_1$.

A set $\sS_2$ is said to be \textit{closed} if its complement $\comple{\sS_2}$ is open.
Alternatively, $\sS_2$ is closed if it contains all the limit points of convergent sequence of points in $\sS_2$; that is, for every sequence of points $\{\bx_i\}_{i\geq 1}\subseteq \sS_2$ satisfying $\bx_i\rightarrow \bx^\star$ as $i\rightarrow \infty$, it follows that $\bx^\star\in\sS_2$.
In the meantime, the \textit{closure} of a set $\sS$, denoted by $\closure(\sS)$, is defined as the smallest closed set containing $\sS$:
$$
\closure(\sS) = \cap\left\{ \sT\mid  \sS \subseteq \sT, \sT \text{ is closed} \right\}.
$$

A set $\sS \subseteq \real^n$ is called \textit{bounded} if there exists $M > 0$ for which $\sS \subseteq \sB(\bzero, M)$, where $\sB(\bzero, M)$ is the ball of finite radius $M$ centered at the origin. 
A set $\sS \subseteq \real^n$ is called \textit{compact} if it is closed and bounded.

Given a function $ f: \sS \rightarrow \real $ where $ \sS \subseteq \real^n $, the \textit{level set} of $ f $ at a particular value $ c \in \real $ is defined as:
$$
\lev[f, c] = \{ \bx \in \sS \mid f(\bx) \leq c \}.~\footnote{Note that we use square brackets instead of parentheses to indicate that the equality can be obtained; same as the definition of closed balls in Definition~\ref{definition:open_closed_ball}.}
$$
In other words, the level set $ \lev[f, c] $ consists of all points $ \bx $ in the domain $ \sS $ for which the function $ f $ evaluates to smaller than or equal to  the constant $ c $.
\end{definition} 

\subsection{Continuous Functions}

A continuous function is one that does not exhibit abrupt changes in value---referred to as \textit{discontinuities}. More formally, it means that small changes in the input of the function lead to correspondingly small changes in its output. Continuous functions are foundational in calculus and analysis, boasting several important properties.
\begin{definition}[Continuous Functions]\label{definition:conti_funs}
Let $f:\sS \subseteq \real^n\rightarrow \real$. The function $f$ is said to be \textit{continuous} at a point $\by \in \sS$ if for every $\epsilon > 0$, there exists a $\delta > 0$ such that for all $\bx$ in $\sS$:
\begin{equation}
\forall \epsilon > 0, \exists \delta > 0 :\quad \forall \bx \in \sS,
\normtwo{\bx - \by} < \delta 
\quad\implies \quad
\abs{f(\bx) - f(\by)} < \epsilon.
\end{equation}
In simpler terms, this definition indicates that we can make the values of $f(\bx)$ arbitrarily close to $f(\by)$ by selecting  $\bx$ sufficiently close to $\by$.

If $f$ is continuous at every point in its domain $\sS$, then $f$ is said to be \textit{continuous} on $\sS$ or simply continuous.
\end{definition}

\begin{remark}[Properties of Continuous Functions]
For a continuous function, we have the following properties:
\begin{enumerate}
\item \textit{Intermediate value theorem.} If $f$ is continuous on a closed interval $[a, b]$ and $y$ is any number between $f(a)$ and $f(b)$, then there exists a $c \in [a, b]$ such that $f(c) = y$.
\item \textit{Extreme value theorem.} If $f$ is continuous on a closed interval $[a, b]$, then $f$ attains both a maximum and minimum value on that interval (Theorem~\ref{theorem:weierstrass_them}).
\item \textit{Composition of continuous functions.} If $g$ is continuous at $c$ and $f$ is continuous at $g(c)$, then the composition $f \circ g$ is continuous at $c$.
\item \textit{Arithmetic operations.} If $f$ and $g$ are continuous at $c$, then so are $f + g$, $f - g$, $f g$, and $\frac{f}{g}$ (provided $g(c) \neq 0$).
\item \textit{Continuity and limits.} A function $f$ is continuous at $c$ if and only if $\lim_{x \to c} f(x) = f(c)$.
\end{enumerate}
\end{remark}

\index{Continuous}
\begin{example}[Continuous Functions]
Following are some continuous functions:
\begin{itemize}
\item Polynomial functions are continuous everywhere.
\item Rational functions are continuous wherever they are defined (i.e., where the denominator is not zero).
\item Trigonometric functions like sine and cosine are continuous everywhere.
\item Exponential and logarithmic functions are continuous on their domains.
\item Absolute value function $\abs{x}$ is continuous everywhere.
\end{itemize}
There are different types of discontinuities:
\begin{itemize}
\item \textit{Removable discontinuity.} The function has a hole at a point, but it can be ``filled" to become continuous.
\item \textit{Jump discontinuity.} The left-hand limit and right-hand limit exist but are not equal.
\item \textit{Infinite discontinuity.} The function approaches  positive or negative infinity at a point.
\item \textit{Oscillating discontinuity.} The function does not approach a single value as the input approaches a point.
\end{itemize}
Continuous functions are easier to analyze and manipulate, while discontinuities can lead to complex behaviors that require special handling. Recognizing the type of discontinuity helps in determining appropriate strategies for dealing with these functions in various applications.
\end{example}


\begin{definition}[Uniform Continuity]\label{definition:uniform_cont}
A function $ f:\sS \subseteq \real^n\rightarrow \real $ is said to be \textit{uniformly continuous} on a set $ \sS $ if for every $ \epsilon > 0 $, there exists a $ \delta > 0 $ such that for all $ \bx $ and $ \by $ in $ \sS $, whenever the distance between $ \bx $ and $ \by $ is less than $ \delta $ (that is, $ \abs{\bx - \by} < \delta $), it follows that the distance between $ f(\bx) $ and $ f(\by) $ is less than $ \epsilon $ (that is, $ \abs{f(\bx) - f(\by)} < \epsilon $).
Formally, $ f: \sS \rightarrow \real $ is uniformly continuous on $ \sS $ if:
$$
\forall \epsilon > 0, \exists \delta > 0 :\quad \forall \bx, \textcolor{mylightbluetext}{\by} \in \sS, \normtwo{\bx - \by} < \delta 
\quad\implies\quad
\abs{f(\bx) - f(\by)} < \epsilon.
$$

The key difference between uniform continuity and ordinary (pointwise) continuity is the choice of $ \delta $. For pointwise continuity, $ \delta $ can depend on both $ \epsilon $ and the point $ \by $ in the domain. However, for uniform continuity, $ \delta $ must work for all points in the set $ \sS $ simultaneously, given an $ \epsilon $.
\end{definition}
Uniform continuity is a stronger form of continuity. Every uniformly continuous function is continuous, but not every continuous function is uniformly continuous. Uniform continuity is especially important in analysis because it guarantees certain desirable  properties, like the preservation of Cauchy sequences and the ability to interchange limits and function evaluations under suitable conditions.

\index{Uniformly continuous}
\begin{example}[Continuity vs Uniform Continuity]
Consider $ f(x) = x^2 $. For any given $ y \in \real $, we can always find a $\delta$ depending on $ y $ and $\epsilon$ to satisfy the definition of continuity. Hence, $ f(x) = x^2 $ is continuous at every point $ y \in \real $.

\paragraph{Not uniformly continuous.} To show that $ f(x) = x^2 $ is not uniformly continuous on $\real$, consider two sequences $ x_t = t $ and $ y_t = t + \frac{1}{t} $ where $ t $ is an integer. As $ t \to \infty $, the distance between $ x_t $ and $ y_t $ approaches  0 ($ \abs{x_t - y_t} = \frac{1}{t} \to 0 $), but the difference in function values does not approach  0:
$$
\abs{f(x_t) - f(y_t)} = \abs{t^2 - \left(t + \frac{1}{t}\right)^2} = \abs{t^2 - \left(t^2 + 2 + \frac{1}{t^2}\right)} = \abs{-2 - \frac{1}{t^2} } \to 2
$$
Since the difference in function values does not become arbitrarily small even when the inputs are arbitrarily close, $ f(x) = x^2 $ is not uniformly continuous on $\real$.
This shows that while $ f(x) = x^2 $ is continuous everywhere on the real line, it fails to be uniformly continuous because the required $\delta$ in the definition of uniform continuity cannot be chosen independently of $ x $.
\end{example}
\begin{remark}[Consequence of Uniform Continuity]\label{remark:conse_uniform_cont}
Let $\nabla f$ be uniformly continuous. Then,
$$
\innerproduct{\nabla f(\bx_1), \bd} = \innerproduct{\nabla f(\bx_2), \bd} + o(\normtwo{\bd}), \quad \text{where }\bd\triangleq\bx_1-\bx_2.
$$
To see this,
by the definition of uniform continuity, for any $\epsilon > 0$, there exists a $\delta > 0$ such that:
$$
\normtwo{\bd} < \delta \quad\implies\quad\normtwo{\nabla f(\bx_1) - \nabla f(\bx_2)} < \epsilon.
$$
This implies that as $\normtwo{\bd} \to 0$, we can choose $\delta$ arbitrarily small, and the gradient difference satisfies:
$
\normtwo{\nabla f(\bx_1) - \nabla f(\bx_2)} = o(1).
$
Using the linearity of the inner product, we can write:
$$
\innerproduct{\nabla f(\bx_1), \bd} = \innerproduct{\nabla f(\bx_2), \bd} + \innerproduct{\nabla f(\bx_1) - \nabla f(\bx_2), \bd},
$$
where
$
\innerproduct{\nabla f(\bx_1) - \nabla f(\bx_2),  \bd} = \normtwo{\nabla f(\bx_1) - \nabla f(\bx_2)} \cdot \normtwo{\bd} \cdot \cos(\theta),
$
and $\theta$ is the angle between $\nabla f(\bx_1) - \nabla f(\bx_2)$ and $\bd$.
Since $\normtwo{\nabla f(\bx_1) - \nabla f(\bx_2)} = o(1)$, we have:
$
\innerproduct{\nabla f(\bx_1) - \nabla f(\bx_2), \bd} = o(\normtwo{\bd}).
$
Therefore, combining these results, we get the desired result.
\end{remark}

\index{Lower semicontinuity}
\index{Lower semicontinuous}
\begin{definition}[Lower Semicontinuity]
A function $ f: \real^n \rightarrow \real\cup \{-\infty, \infty\} $ is called \textit{lower semicontinuous at $ \bx^* \in \real^n $} if
$$
f(\bx) \leq \liminf_{t \rightarrow \infty} f(\bx^\toptzero)
$$
for any sequence $ \{\bx^\toptzero\}_{t \geq 1} \subseteq \real^n $ for which $ \bx^\toptzero \rightarrow \bx^* $ as $ t \rightarrow \infty $.
In other words, the limit inferior of the function values at points approaching $\bx^*$ must be greater than or equal to the function value at $\bx^*$ . This means that the function does not have any sudden drops as you approach $\bx^*$.
A function $ f: \real^n \rightarrow  \real \cup \{-\infty, \infty \} $ is called \textit{lower semicontinuous} if it is {lower semicontinuous} at each point in $ \real^n $.
\end{definition}

Note that including $\{-\infty, \infty\}$ in the codomain of a function when defining lower semicontinuityis not strictly necessary for all functions, but it allows for greater generality and flexibility in mathematical analysis. 
Some functions may have points where they tend towards infinity, either positively or negatively. By including $\{-\infty, \infty\}$, we can still discuss the continuity properties of such functions at those points.

Figure~\ref{fig:low_nonlowersemis} depicts examples of lower semicontinuous and non-lower semicontinuous functions.
In optimization problems, lower semicontinuity plays a key role because it guarantees that if a sequence of feasible points approaches a minimum, then the limit of this sequence will also be a feasible point and will achieve the minimum value. This property ensures that optimal solutions exist under certain conditions.
In many applications, especially in calculus of variations and optimal control, lower semicontinuity is used to prove the existence of minimizers of functionals. If a functional is lower semicontinuous and coercive (it tends to infinity as the norm of its argument grows), then under some compactness assumptions, one can show that there exists a minimizer; see \ref{weier2_prop_close} in Theorem~\ref{theorem:weierstrass_them}.
In numerical methods and iterative algorithms, lower semicontinuity can help in proving convergence properties. For instance, if a sequence generated by an algorithm is minimizing a lower semicontinuous function, it can be shown that the limit points of the sequence are stationary points; for example, the lower semicontinuity can be applied to prove the uniqueness of the optimizer for a closed and strongly convex function (Theorem~\ref{theorem:exi_close_sc}).
For this reason, in most of our discussions, we consider lower semicontinuous (closed) functions for evaluation.

\begin{figure}[h!]
\centering                      
\vspace{-0.35cm}                
\subfigtopskip=2pt            
\subfigbottomskip=2pt           
\subfigcapskip=-5pt           
\subfigure[A lower semicontinuous funtion.]{\label{fig:aaa-1}
	\includegraphics[width=0.31\linewidth]{./imgs/lower_semi1.pdf}}
\subfigure[A non-lower semicontinuous funtion]{\label{fig:aaa-2}
	\includegraphics[width=0.31\linewidth]{./imgs/lower_semi2.pdf}}
\subfigure[A lower semicontinuous funtion.]{\label{fig:aaa-3}
	\includegraphics[width=0.31\linewidth]{./imgs/lower_semi3.pdf}}
\caption{Lower semicontinuous and non-lower semicontinous funtions. In numerical methods and iterative algorithms, lower semicontinuity can help in proving convergence properties. For instance, if a sequence generated by an algorithm is minimizing a lower semicontinuous function, it can be shown that the limit points of the sequence are stationary points.}
\label{fig:low_nonlowersemis}
\end{figure}

\subsection{Extended Real-Valued Functions}
Extended real-valued functions are those that can take values from the extended real number line, which includes all real numbers along with two additional elements: positive infinity ($+\infty$) and negative infinity ($-\infty$). These functions are widely  used in mathematical analysis, optimization theory, and measure theory, providing a convenient framework to handle limits and boundary conditions.

\index{Extended real-valued functions}
\index{Proper functions}
\index{Closed functions}
\index{Epigraph}
\begin{definition}[Extended Real-Valued, Proper, Closed Functions]\label{definition:extrel_pro_clo_funcs}
An \textit{extended real-valued function} $f$ is a function defined on a set $\sS$ (often a subset of $\real^n$ or another topological space) that maps each point $\bx$ in $\sS$ to a value in the \textit{extended real number line} $\extreal = \real \cup \{-\infty, \infty \}$. Formally, an extended real-valued function is written as:
$$
f : \sS \rightarrow \extreal
\qquad \text{or}\qquad 
f : \sS \rightarrow \real \cup \{-\infty, \infty \}.
$$
The \textit{effective domain} or simply the \textit{domain} and the \textit{epigraph} of an extended real-valued function are the sets:
$$
\begin{aligned}
\textbf{(domain)}:\qquad &\dom(f) &\triangleq& \{\bx\in\sS: f(\bx)<\infty\};\\
\textbf{(epigraph)}:\qquad & \epi(f) &\triangleq& \{(\bx, r) \in \sS \times \real : f(\bx) \leq r\}.
\end{aligned}
$$
That is, the epigraph of an extended real-valued function $f$ is the set of points lying on or above its graph.

In the meantime,  a function $f: \sS \rightarrow \extreal$ is called \textit{proper} if it satisfies the following two conditions:
\begin{enumerate}
\item \textit{Non-identically infinite.} The function does not attain the value $+\infty$ everywhere in its domain. In other words, there exists at least one point $\bx \in \sS$ such that $f(\bx) < +\infty$.
\item \textit{No negative infinity values.} The function never takes on the value $-\infty$. That is, for all $\bx \in \sS, f(\bx) > -\infty$.
\end{enumerate}
\noindent These conditions ensure that the function has some finite values and avoids the undefined behavior associated with $-\infty$.
For a proper function, this domain is nonempty because of the first condition above.

A function $f$ is said to be \textit{closed} if its epigraph is a closed set in the product topology of $\sS \times \real$. In other words, for every sequence $(\bx^{(t)}, r_t)$ in $\text{epi}(f)$ that converges to a limit $(\bx^*, r^*)$, we have $f(\bx^*) \leq r^*$, meaning that the limit point $(\bx^*, r^*)$ also belongs to the epigraph.
\end{definition}

\begin{definition}[Coerciveness]\label{definition:coerciveness}
Let $f: \real^n \rightarrow \real$ be a continuous function defined over $\real^n$. The function $f$ is called \textit{coercive} if
$$
\lim_{\normtwo{\bx} \rightarrow \infty} f(\bx) = \infty.
$$
\end{definition}

\begin{exercise}[Coerciveness of Quadratic Functions]\label{exercise:coerci_quad}
	Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx+\bb^\top\bx+c$, where $\bA\in\real^{n\times n}$ is symmetric, $\bb\in\real^n$, and $c\in\real$. Show that $f(\bx)$ is coercive if $\bA$ is positive definite.
\end{exercise}

Proper functions are particularly significant  in convex analysis and optimization theory because they allow for a well-defined notion of minimization. When dealing with optimization problems, one often seeks to minimize a function over a given set. A proper function ensures that there are feasible points to consider (points where the function value is finite), which is necessary for the problem to be meaningful. Therefore, unless otherwise stated, we only consider proper functions in this book.
Moreover, many results in convex analysis require the objective function to be proper. For example, the Fenchel-Moreau theorem, which relates a function to its biconjugate, requires the function to be proper, convex, and lower semi-continuous.


\begin{example}[Proper Functions]\label{example:proper_funcs}
	The following functions are proper:
	\begin{itemize}
		\item A linear function $f(x) = ax + b$ on $\real$ is proper since it never reaches $\pm\infty$.
		\item The indicator function $\indicatorS(\bx)$, which is $0$ if $\bx$ belongs to a set $\sS$ and $+\infty$ otherwise, is proper if $\sS$ is nonempty.
		\item The function $f(x) = \frac{1}{x}$ on $\real$ is not proper since it tends to $+\infty$ as $x$ approaches $0$ from the positive side and to $-\infty$ from the negative side.
	\end{itemize}
Consider why the non-proper function $f(x) = \frac{1}{x}$ is not well-defined for a minimization problem.
\end{example}





\index{Indicator function}
\begin{exercise}[Closedness of Indicator]\label{exercise_closed_indica}
Show that the indicator function $\indicatorS$, which is $0$ if $\bx$ belongs to a set $\sS$ and $+\infty$ otherwise,  is closed if and only if $\sS$ is a closed set.
\end{exercise}



\begin{theorem}[Equivalence of Closedness, Lower Semicontinuity, and Closedness of Level Sets]\label{theorem:equiv_close_clkos_semicon}
Let $ f: \real^n\rightarrow  \real \cup \{-\infty, \infty \} $. Then the following three statements  are equivalent:

\begin{enumerate}
\item[(i)] $ f $ is lower semicontinuous.
\item[(ii)] $ f $ is closed.
\item[(iii)] For any $ \alpha \in \real $, the level set
$
\lev[f, \alpha] = \{ \bx \in \real^n \mid f(\bx) \leq \alpha \}
$
is closed.
\end{enumerate}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:equiv_close_clkos_semicon}]
\textbf{(i) $\implies$ (ii).} Assume  that $ f $ is lower semicontinuous. We will demonstrate  that $ \epi(f) $ is closed. 
Let  $ \{(\bx^\toptzero, y^\toptzero)\}_{t \geq 1} \subseteq \epi(f) $ be a sequence such that $ (\bx^\toptzero, y^\toptzero) \rightarrow (\bx^*, y^*) $ as $ t \rightarrow \infty $. By definition, for any $ t \geq 1 $,
$$
f(\bx^\toptzero) \leq y^\toptzero.
$$
Due to the lower semicontinuity of $ f $ at $ \bx^* $, we have
$$
f(\bx^*) \leq \liminf_{t \rightarrow \infty} f(\bx^\toptzero) \leq \liminf_{t \rightarrow \infty} y^\toptzero = y^*,
$$
which shows that $ (\bx^*, y^*) \in \epi(f) $, proving that $f$ is closed.

\paragraph{(ii) $\implies$ (iii).} Suppose that $ f $ is closed, i.e., the epigraph $ \epi(f) $ is closed. 
For any $ \alpha \in \real $, we aim to show that  $ \lev[f, \alpha] $ is closed. If $ \lev[f, \alpha] = \varnothing $, the claim holds trivially. 
Otherwise, take a sequence $ \{\bx^\toptzero\}_{t \geq 1} \subseteq \lev[f, \alpha] $ that converges to $ \widehatbx $. Obviously, $ (\bx^\toptzero, \alpha) \in \epi(f) $ for any $ t $ and $ (\bx^\toptzero, \alpha) \rightarrow (\widehatbx, \alpha) $ as $ t \rightarrow \infty $. By the closedness of $ \epi(f) $, it follows that $ (\widehatbx, \alpha) \in \epi(f) $, establishing the fact that $ \widehatbx \in \lev[f, \alpha] $.

\paragraph{(iii) $\implies$ (i).} Assuming all level sets of $ f $ are closed, we prove that it is lower semicontinuous. Suppose for contradiction that $ f $ is not lower semicontinuous, meaning that there exists $ \bx^* \in \real^n $ and $ \{\bx^\toptzero\}_{t \geq 1} \subseteq \real^n $ such that $ \bx^\toptzero \rightarrow \bx^* $ and $ \liminf_{t \rightarrow \infty} f(\bx^\toptzero) < f(\bx^*) $. 
Choose  $ \alpha $ satisfying
\begin{equation}\label{equation:equiv_lowsemi}
\liminf_{t \rightarrow \infty} f(\bx^\toptzero) < \alpha < f(\bx^*). 
\end{equation}
Then there exists a subsequence $ \{\bx_{n_t}\}_{t \geq 1} $ such that $ f(\bx_{n_t}) \leq \alpha $ for all $ t \geq 1 $. By the closedness of the level set $ \lev[f, \alpha] $ and the fact that $ \bx_{n_t} \rightarrow \bx^* $ as $ t\rightarrow \infty $, it follows that $ f(\bx^*) \leq \alpha $, which is a contradiction to \eqref{equation:equiv_lowsemi}, establishing that (iii) implies (i).
\end{proof}










\subsection{Convex Functions}
This subsection introduces the concepts of affine, convex, and conic combinations and hulls within the context of vector sets in $\real^n$, providing definitions and mathematical formulations for these fundamental geometric constructs.
\begin{definition}[Affine/Convex/Conic Combinations and  Hulls]\label{definition:coms_hulls}
Given a set of vectors $\bx_1,\bx_2,\ldots,\bx_p\in\real^n$, 
an \textit{affine combination} of these $p$ vectors is a vector of the form  $\sum_{i=1}^{p} \lambda_i\bx_i$, where $\sum_{i=1}^{p} \lambda_i=1$, i.e., a linear combination of these points where the coefficients (not necessarily nonnegative) sum to 1; 
a \textit{convex combination} of these $p$ vectors is a vector of the form $\sum_{i=1}^{p} \lambda_i\bx_i$, where $\lambda_i\geq 0$ for $i\in\{1,2,\ldots,p\}$ satisfying $\sum_{i=1}^{p}\lambda_i=1$ (i.e., $\{\lambda_i\}$ belongs to the unit-simplex in $\real^p$); 
when only requiring $\lambda_i\geq 0$ without the constraint on their sum, the combination is referred to as a \textit{conic combination} of these vectors. 

The \textit{affine hull} of a set $ \sS $ is the smallest affine space (a translation of a vector subspace) that contains $ \sS $.
Formally, given a set $ \sS \subseteq \real^n $, the affine hull of $ \sS $, denoted as $ \aff(\sS) $, is defined as the set of all affine combinations of points from $ \sS $:
$$
\aff(\sS) \triangleq \left\{ \sum_{i=1}^p \lambda_i \bx_i \mid   \bx_1,\bx_2,\ldots,\bx_p\in\sS, \lambda_i \in \real, \bone^\top\blambda=1,p\in\naturalset \right\}.
$$
The \textit{convex hull} of $\sS$, denoted as $\conv(\sS)$, is the set comprising all the convex combinations of vectors from $\sS$: 
$$
\conv(\sS) \triangleq \left\{ \sum_{i=1}^{p} \lambda_i\bx_i\mid \bx_1,\bx_2,\ldots,\bx_p\in\sS, \blambda\in\Delta_p, p\in\naturalset \right\}.
$$ 
Similarly, the \textit{conic hull} of $\sS$, denoted as $\cone(\sS)$, is the set comprising all the conic combinations of vectors from $\sS$:
$$
\cone(\sS) \triangleq \left\{\sum_{i=1}^{p} \lambda_i\bx_i\mid \bx_1,\bx_2,\ldots,\bx_p\in\sS, \blambda\in\real^n_+, p\in\naturalset  \right\}.
$$
\end{definition}

\begin{exercise}[Closedness of Conic Hull of a Finite Set]\label{exercise:closed_fini_cone}
Let $\bx_1, \bx_2, \ldots,\bx_p\in\real^n$. Show that $\cone(\{\bx_1, \bx_2, \ldots,\bx_p\})$ is closed.
\end{exercise}

\begin{exercise}[Closure]
Show that 
$$
\begin{aligned}
\closure(\real_{++}^n) &= \real_+^n; \\
\closure(\sB(\bx,r)) &= \sB[\bx,r],\quad \text{where $\bx\in\real^n$, $r\in\real_{++}$};\\
\closure((\bx,\by)) &= [\bx,\by], \quad \text{where $\bx,\by\in\real^n$ and $\by\geq \bx$}.
\end{aligned}
$$
\end{exercise}

\begin{exercise}[Interior and Closure]\label{exercise:int_clos}
Let $\sS\subseteq\real^n$ be a convex set with a nonempty interior. Show that 
$$
\closure(\interior(\sS)) = \closure(\sS)
\qquad\text{and}\qquad 
\interior(\closure(\sS)) =\interior(\sS).
$$
\end{exercise}

For vectors $\bx$ and $\by$,  the point $\lambda\bx+(1-\lambda)\by$, where $\lambda\in[0,1]$, is known as  a convex combination of the two vectors.
A set that is closed under arbitrary convex combinations is referred to as a convex set.
The standard definition follows:
\begin{definition}[Convex Set]\label{definition:convexset}
A set $\sS\subseteq \real^n$ is called \textit{convex} if, for any $\bx,\by\in\sS$ and $\lambda\in[0,1]$, the point $\lambda\bx+(1-\lambda)\by$ also belongs to $\sS$.
\end{definition}
Geometrically, convex sets  contain all line segments
that join two points within the set (Figure~\ref{fig:cvxset}). Consequently, these sets do not feature any concave indentations.

\begin{definition}[Cone and Convex Cone]\label{definition:convex_cone}
A set $ \sS \subseteq \real^n $ is a \textit{cone} if for every $ \bx \in \sS $, $ \alpha \bx \in \sS $ for any $ \alpha \geq 0 $.
A set $ \sS $ is a \textit{convex cone}  if it is both a cone and a convex set.
\end{definition}

\begin{figure}[h]
\centering       
\vspace{-0.25cm}                 
\subfigtopskip=2pt               
\subfigbottomskip=-2pt         
\subfigcapskip=-10pt      
\includegraphics[width=0.98\textwidth]{imgs/cvxset.pdf}
\caption{A set is considered	 convex if it includes all convex combinations of its points. If there exists even one convex combination that lies outside the set, then by definition, the set is not convex. Therefore, a convex set must have a shape without any inward ``dents" or ``bulges". It's worth noting that the collection of sparse vectors does not satisfy this criterion and thus forms a non-convex set. The illustration provided is adapted from \citet{jain2017non}.}
\label{fig:cvxset}
\end{figure}


A related concept is that of convex functions, which exhibit specific behavior under convex combinations. We now recall the definition:
\begin{definition}[Convex Functions]\label{definition:convexfuncs}
A function $f:\sS\rightarrow \real$ defined over a convex set $\sS\subseteq \real^n$ is called \textit{convex} if 
$$
f(\lambda\bx+(1-\lambda)\by)
\leq \lambda f(\bx) + (1-\lambda) f(\by), \text{ for any }\bx,\by\in\sS, \lambda\in[0,1].
$$
Moreover,   $f$ is called \textit{strictly convex} if 
$$
f(\lambda\bx+(1-\lambda)\by)
< \lambda f(\bx) + (1-\lambda) f(\by),\text{ for any }\bx\neq \by\in\sS, \lambda\in(0,1).
$$
\end{definition}
A well-known inequality derived from the concept of convex functions is provided below without a proof.
\begin{theorem}[Jensen's Inequality]\label{theorem:jensens_ineq}
Let $f: \sS \rightarrow \real$ be a convex function defined on a convex subset $\sS \subseteq \real^{n}$. For any finite sequence of points $\bx_{1}, \bx_{2}, \ldots, \bx_{m} \in \sS$ and any sequence of nonnegative weights $\lambda_{1}, \lambda_{2}, \lambda_{3}, \ldots, \lambda_{m}$ such that $\sum_{i=1}^{m} \lambda_{i} = 1$, Jensen's inequality states:
$$
f\left(\sum_{i=1}^{m} \lambda_{i} \bx_{i}\right) \leq \sum_{i=1}^{m} \lambda_{i} f(\bx_{i}).
$$
If $f$ is concave, the inequality is reversed:
$$
f\left(\sum_{i=1}^{m} \lambda_{i} \bx_{i}\right) \geq \sum_{i=1}^{m} \lambda_{i} f(\bx_{i}).
$$
In the context of probability theory, if $\rvx$ is a random vector with values in $\sS$ and $f$ is a convex function, Jensen's inequality can be stated as follows:
$$
f(\Exp[\rvx]) \leq \Exp[f(\rvx)],
$$
where $\Exp[\cdot]$ denotes the expectation operator over the random vector $\rvx$. For a concave function, the inequality is again reversed.
\end{theorem}

Similarly, we provide the definition of quasi-convexity and strict quasi-convexity.
\begin{definition}[Quasi-Convex Function]\label{definition:quasi_convex}
Let  $f:\sS\subseteq\real^n \rightarrow \real$ be a function defined over the convex set $\sS$. 
Then $f$ is called \textit{quasi-convex} if for any $\mu\in\real$ the level set $\lev[f, \mu]$ is convex. Formally, it satisfies that 
$$
f(\lambda \bx + (1-\lambda)\by) \leq  \max\{f(\bx), f(\by)\}, \text{ for any }\bx,\by\in\sS, \lambda\in[0,1].
$$
Similarlly, $f$ is called \textit{strictly quasi-convex} if 
$$
f(\lambda \bx + (1-\lambda)\by) <  \max\{f(\bx), f(\by)\},\text{ for any }\bx\neq \by\in\sS, \lambda\in(0,1).
$$ 
\end{definition}

The geometric interpretation of a  quasi-convex function is that the value of the function on any line segment within its domain does not exceed the maximum value of the function at the endpoints of the segment.
Quasi-convexity is a broader property than convexity since all convex functions are also quasi-convex, but not all quasi-convex functions are convex. For example, $f(x)=\sqrt{\abs{x}}$ is a quasi-convex function, but it is not convex.
Although a  quasi-convex function is not necessarily a convex function,  its level sets are convex, and it can include some well-behaved non-convex functions (Theorem~\ref{theorem:uni_qua_conv}). 





In scenarios involving multiple variables, the input vector  $\bx$ can be partitioned into $\bx=(\ba, \bb)\in\real^n$. 
When discussing properties of functions in this context, convexity can sometimes be referred to as \textit{joint convexity}, meaning that the function is convex with respect to all components of the input simultaneously.
Additionally, there are instances where a function exhibits \textit{partial convexity}, often termed \textit{marginal convexity}, indicating that the function is convex when considered with respect to one or more subsets of its input variables while keeping others constant.

\begin{definition}[Marginally Convex]\label{definition:marginal_convexfuncs}
A function $f(\ba,\bb):\sS\subseteq\real^n\rightarrow \real$ (i.e., $(\ba,\bb)\in\real^n$), defined over a convex set $\sS$, is called \textit{marginally convex} if 
$$
f(\lambda\bx+(1-\lambda)\by, \bb)
\leq \lambda f(\bx, \bb) + (1-\lambda) f(\by, \bb), \text{ for any }(\bx,\bb),(\by,\bb)\in\sS, \lambda\in[0,1].
$$
\end{definition}

\begin{exercise}
Show that the norm functions $\normtwo{\bx}^2$  and $\normone{\bx}$ are convex.
\end{exercise}

\begin{exercise}
Suppose the continuously differentiable function $f$ is convex. Show that the directional derivative (Definition~\ref{definition:partial_deri}) $g(\bd)\triangleq f^\prime(\bx;\bd)$ is also convex.
\end{exercise}

\begin{exercise}[Convexity of Quadratic Functions]\label{exercise:conv_quad}
Let $f(\bx)=\frac{1}{2}\bx^\top\bA\bx+\bb^\top\bx+c$, where $\bA\in\real^{n\times n}$ is symmetric, $\bb\in\real^n$, and $c\in\real$. Show that $f(\bx)$ is convex (resp. strict convex) if and only if $\bA\succeq \bzero$ (resp. $\bA\succ\bzero$)
\end{exercise}

\begin{exercise}[Closure of Convex]\label{exercise:clo_conv}
Let $\sS\subseteq \real^n$ be a convex set. Show that $\closure(\sS)$ is also convex.
\end{exercise}

\begin{exercise}[Convexity of Indicator]\label{exercise_convex_indica}
	Show that the indicator function $\indicatorS$, which is $0$ if $\bx$ belongs to a set $\sS$ and $+\infty$ otherwise,  is convex if and only if $\sS$ is a convex set.
\end{exercise}

\paragraph{First-order characterizations of convex functions.}
Convex functions do not necessarily have to be differentiable. However, when they are  differentiable, such functions can be characterized by the gradient inequality.
\begin{theorem}[Gradient Inequality]\label{theorem:conv_gradient_ineq}
Let $f:\sS\rightarrow \real$ be a {continuously differentiable} function defined on a convex set $\sS\subseteq\real^n$. Then, $f$ is convex over $\sS$ if and only if 
\begin{equation}\label{equation:conv_gradient_ineq1}
f(\bx) +\nabla f(\bx)^\top (\by-\bx)\leq f(\by), \text{ for any $\bx,\by\in\sS$}.
\end{equation}
Similarly, the function is strictly convex over $\sS$ if and only if 
\begin{equation}\label{equation:conv_gradient_ineq2}
f(\bx) +\nabla f(\bx)^\top (\by-\bx)< f(\by), \text{ for any $\bx\neq \by\in\sS$}.
\end{equation}
This indicates that the graph of a convex function lies above its tangent plane at any point. For concave or strictly concave functions, the inequality signs are reversed.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:conv_gradient_ineq}]
For brevity, we only prove \eqref{equation:conv_gradient_ineq1}, and \eqref{equation:conv_gradient_ineq2} can be proved analogously.
Suppose first that $ f $ is convex. Let $ \bx, \by \in \sS $ and $ \lambda \in [0, 1] $. If $ \bx = \by $, then \eqref{equation:conv_gradient_ineq1} trivially holds. We will therefore assume that $ \bx \neq \by $. Then, the definition of convexity shows that 
$$
f(\lambda \by + (1-\lambda) \bx) \leq \lambda f(\by) + (1-\lambda) f(\bx)
\;\implies\;
\frac{f(\bx + \lambda (\by - \bx)) - f(\bx)}{\lambda} \leq f(\by) - f(\bx).
$$
Taking $ \lambda \to 0^+ $, the left-hand side converges to the directional derivative of $ f $ at $ \bx $ in the direction $ \by - \bx $ (Definition~\ref{definition:partial_deri}), whence we have 
$
f'(\bx; \by - \bx) \leq f(\by) - f(\bx).
$
Since $ f $ is continuously differentiable, it follows that $ f'(\bx; \by - \bx) = \nabla f(\bx)^\top (\by - \bx) $ by \eqref{equation:direc_contdiff}, and hence \eqref{equation:conv_gradient_ineq1} follows.

Conversely, assume that the gradient inequality holds. Let $ \bx, \by \in \sS $, and let $ \lambda \in [0, 1] $. We will show that $ f(\lambda \bx + (1 - \lambda) \by) \leq \lambda f(\bx) + (1 - \lambda) f(\by) $. The cases for $\lambda=0$ or $\lambda=1$ holds trivially. We will therefore assume that $\lambda\in(0,1)$.
Let $ \ba \triangleq \lambda \bx + (1 - \lambda) \by \in \sS $. Then
$
 -\frac{\lambda}{1 - \lambda}  (\bx - \ba)  = (\by - \ba).
$
Combining with the gradient inequality implies that 
$$
f(\ba) + \nabla f(\ba)^\top (\bx - \ba) \leq f(\bx)
\qquad\text{and}\qquad 
f(\ba) - \frac{\lambda}{1 - \lambda} \nabla f(\ba)^\top (\bx - \ba) \leq f(\by).
$$
Multiplying the first inequality by $ \frac{\lambda}{1 - \lambda} $ and adding it to the second one, we obtain
$
\frac{1}{1 - \lambda} f(\ba) \leq \frac{\lambda}{1 - \lambda} f(\bx) + f(\by),
$
establishing the desired result.
\end{proof}

\begin{theorem}[Monotonicity of Gradient of Convex Functions]\label{theorem:monoton_convgrad}
Let $f:\sS\rightarrow \real$ be a {continuously differentiable} function defined over a convex set $\sS\subseteq\real^n$. Then, given any $\bx,\by\in\sS$, $f$ is convex over $\sS$ if and only if 
\begin{equation}\label{equation:monoton_convgrad}
\big(\nabla f(\bx) - \nabla f(\by)\big)^\top (\bx-\by)\geq 0.
\end{equation}
Similarly, given any $\bx\neq \by\in\sS$, $f$ is strictly convex over $\sS$ if and only if 
\begin{equation}\label{equation:monoton_convgrad2}
	\big(\nabla f(\bx) - \nabla f(\by)\big)^\top (\bx-\by)> 0.
\end{equation}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:monoton_convgrad}]
For brevity, we only prove \eqref{equation:monoton_convgrad}, and \eqref{equation:monoton_convgrad2} can be proved analogously.
Assume  that $ f $ is convex over $ \sS $. Then by the gradient inequality, for any $ \bx, \by \in \sS $,  we have 
$$
f(\bx) \geq f(\by) + \nabla f(\by)^\top (\bx - \by)
\qquad\text{and}\qquad 
f(\by) \geq f(\bx) + \nabla f(\bx)^\top (\by - \bx).
$$
Summing the two inequalities yields the desired inequality in \eqref{equation:monoton_convgrad}.

Conversely, assume that \eqref{equation:monoton_convgrad} holds, and let $ \bx, \by \in \sS $. Define $g(\mu) \triangleq f(\bx + \mu (\by - \bx)),  \mu \in [0, 1]$ as a one-dimensional function.
By the fundamental theorem of calculus (Theorem~\ref{theorem:fund_theo_calculu}), we have
$$
\begin{aligned}
f(\by) 
&= g(1) = g(0) + \int_0^1 g'(\mu) \, d\mu
= f(\bx) + \int_0^1 (\by - \bx)^\top \nabla f\big(\bx + \mu (\by - \bx)\big) \, d\mu\\
&= f(\bx) + \nabla f(\bx)^\top (\by - \bx) + \int_0^1 (\by - \bx)^\top \big(\nabla f(\bx + \mu (\by - \bx)) - \nabla f(\bx)\big) \, d\mu\\
&\geq f(\bx) + \nabla f(\bx)^\top (\by - \bx),
\end{aligned}
$$
where the last inequality follows from the monotonicity of the gradient. This shows that $f$ is convex by Definition~\ref{definition:convexfuncs}.
\end{proof}

\paragraph{Second-order characterizations of convex functions.}

When the function is further assumed to be twice continuously differentiable,
its convexity can be characterized by the positive semidefiniteness (see Definition~\ref{definition:psd-pd-defini}) of the Hessian matrix
\begin{theorem}[PSD Hessian of Convex Functions]\label{theorem:psd_hess_conv}
Let $f:\sS\subseteq\real^n\rightarrow \real$ be a twice continuously differentiable function defined on an \textbf{open} convex set $\sS$, then the function is convex \textbf{if and only if} $\nabla^2 f(\bx)\succeq \bzero $ for any $\bx\in\sS$.~\footnote{Note that the openness of $\sS$ can be relaxed to prove the convexity of $\nabla^2 f(\bx)\succeq \bzero $ for any $\bx\in\interior(\sS)$.}
Moreover, \textbf{if} $\nabla^2 f(\bx)\succ \bzero $ for any $\bx\in\sS$, then the function is strictly convex over $\sS$~\footnote{Notice that the former condition is both sufficient and necessary, the latter condition is merely sufficient but not necessary. For example, $f(x)=x^6$ is strictly convex, but $f^{\prime\prime}(x)=30x^4$ is equal to zero at $x=0$.}. 
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:psd_hess_conv}]
Assume that $\nabla^2 f(\bx) \succeq \bzero$ for all $\bx \in \sS$, and let $\bx, \by \in \sS$. 
By the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), there exists $\bxi \in [\bx, \by]$ (and hence $\bxi \in \sS$) such that
\begin{equation}\label{equation:psd_hess_conv1}
f(\by) = f(\bx) + \nabla f(\bx)^\top (\by - \bx) + \frac{1}{2} (\by - \bx)^\top \nabla^2 f(\bxi) (\by - \bx), \quad \bxi \in [\bx, \by].
\end{equation}
Given that  $\nabla^2 f(\bxi) \succeq \bzero$, it follows that $(\by - \bx)^\top \nabla^2 f(\bxi) (\by - \bx) \geq 0$, whence by \eqref{equation:psd_hess_conv1} we have  $f(\by) \geq f(\bx) + \nabla f(\bx)^\top (\by - \bx)$, establishing convexity by Theorem~\ref{theorem:conv_gradient_ineq}.

Conversely, assume that $f$ is convex over $\sS$. Let $\bx \in \sS$ and let $\by \in \real^n$. Since $\sS$ is open, there exists a scalar $\varepsilon>0$ such that  $\bx + \lambda \by \in \sS$ for any  $\lambda \in(0, \varepsilon)$. 
The gradient inequality (Theorem~\ref{theorem:conv_gradient_ineq}) shows that 
\begin{equation}\label{equation:psd_hess_conv2}
f(\bx + \lambda \by) \geq f(\bx) + \lambda \nabla f(\bx)^\top \by.
\end{equation}
Additionally, by the quadratic approximation theorem (Theorem~\ref{theorem:quad_app_theo}), we have
$$
f(\bx + \lambda \by) = f(\bx) + \lambda \nabla f(\bx)^\top \by + \frac{\lambda^2}{2} \by^\top \nabla^2 f(\bx) \by + o(\lambda^2 \normtwo{\by}^2),
$$
which combined with \eqref{equation:psd_hess_conv2} yields the inequality
$
\frac{\lambda^2}{2} \by^\top \nabla^2 f(\bx) \by + o(\lambda^2 \normtwo{\by}^2) \geq 0
$
for any $\lambda \in (0, \varepsilon)$. Dividing the latter inequality by $\lambda^2$ yields that 
$
\frac{1}{2} \by^\top \nabla^2 f(\bx) \by + \frac{o(\lambda^2 \normtwo{\by}^2)}{\lambda^2} \geq 0.
$
Taking $\lambda \to 0^+$, we conclude that
$
\by^\top \nabla^2 f(\bx) \by \geq 0
$
for any $\by \in \real^n$, implying that $\nabla^2 f(\bx) \succeq \bzero$ for any $\bx \in \sS$.
The strict convexity can be proved analogously.
\end{proof}



\begin{exercise}[Preservation of Closedness and Convexity]\label{exercise:pres_conv_clos}
Prove the following results:
\begin{enumerate}[(i)]
\item Let $\bA\in\real^{n\times n}$, and let $f: \real^n \rightarrow (-\infty, \infty]$ be an extended real-valued closed (resp. convex) function. Then the function 
$
g(\bx) = f(\bA\bx+\bb)
$
is closed (resp. convex).

\item Let $f_1, f_2, \ldots, f_m: \real^n \rightarrow (-\infty, \infty]$ be extended real-valued closed (resp. convex) functions, and let $\sigma_1, \sigma_2, \ldots, \sigma_m \in \real_+$. Then the function $f = \sum_{i=1}^{m} \sigma_i f_i$ is closed (resp. convex).

\item Let $f_i: \real^n \rightarrow (-\infty, \infty], i \in \sI$ be extended real-valued closed (resp. convex) functions, where $\sI$ is a given index set. Then the function
$
f(\bx) = \max_{i \in \sI} f_i(\bx)
$
is closed (resp. convex).
\end{enumerate}
\textit{Hint: the epigraph of $\max_{i \in \sI} f_i(\bx)$ is the intersection of the epigraphs of $f_i$'s.}
\end{exercise}



\subsection{Subgradient and Conjugate Functions}\label{section:sub_conjug}



The gradient inequality for convex functions applies specifically to continuously differentiable functions. However, this concept can be extended through the notion of a \textit{subgradient}, which plays a crucial role in optimization, especially for non-differentiable or non-smooth functions.

\begin{definition}[Subgradient and Subdifferential]\label{definition:subgrad}
Let $f: \sS\subseteq\real^n \rightarrow \real$. A vector $\bg\in\real^n$ is called a \textit{subgradient} of $f$ at $\bx\in\sS$ if
$$
f(\by) \geq  f(\bx) + \innerproduct{\bg, \by-\bx} \quad \text{for all $\by\in\sS$}.
$$
The inequality is called a \textit{subgradient inequality}.
The set of all subgradients of $f$ at $\bx$, denoted by $\partial f(\bx)$, is called the \textit{subdifferential} of $f$ at $\bx$:
$$
\partial f(\bx) \triangleq\left\{\bg\in\real^n\mid f(\by) \geq  f(\bx) + \innerproduct{\bg, \by-\bx}\text{ for all $\by\in\sS$} \right\}.
$$
Any subgradient of $f$ at $\bx$ can be denoted as
$$
f'(\bx) \in \partial f(\bx).
$$
\end{definition}
It's worth noting that the notion of a subgradient is applicable not only to convex functions but also extends to non-convex settings. For convex functions, however, it is assured that the subdifferential at any point within the domain is nonempty (Theorem~\ref{theorem:nonemp_relint_conv}).

\begin{exercise}[Subdifferential of Norms]\label{exercise:sub_norms}
Let $f(\bx)=\normtwo{\bx}$. Show that 
$$
\partial f(\bx)=
\begin{cases}
\left\{\frac{\bx}{\normtwo{\bx}}\right\}, & \bx\neq \bzero;\\
\sB_2[\bzero, 1], & \bx= \bzero.
\end{cases}
$$
Additionally, let $g(\bx)=\normone{\bx}$. Show that $\partial g(\bx) = \sum_{i=1}^{n} \partial g_i(\bx)$, where $g_i(\bx) = \abs{x_i}$ and 
$$
\partial  g_i(\bx)=
\begin{cases} 
\{\sign(x_i) \be_i\}, & x_i \neq 0, \\
[-\be_i, \be_i], & x_i = 0.
\end{cases}
$$
This indicates that 
$$
\sign(\bx)\in\partial g(\bx),
$$ 
where $\sign(\bx)$ returns the sign for each component.
\end{exercise}

An established result in convex analysis asserts that the relative interior of a convex set is always nonempty. Moreover, for a proper convex function, it is guaranteed to be subdifferentiable at every relative interior point of its effective domain. The following theorem encapsulates these findings without proof.
\begin{theorem}[Nonemptiness of Relative Interior \citep{rockafellar2015convex, beck2017first}]\label{theorem:nonemp_relint_conv}
Let $\sS\subseteq \real^n$ be a nonempty convex set. Then, the relative interior of $\sS$, denoted as $\relint(\sS)$, is nonempty.
Moreover, let $f : \real^n\rightarrow  (-\infty, \infty]$ be a proper convex function, 	and let $\bx \in \relint(\dom(f))$. 
Consequently, the subdifferential of $f$ at $\bx$,  $\partial f(\bx)$, is nonempty.
\end{theorem}


We then provide the definition and properties of conjugate functions.
\begin{definition}[Conjugate Functions]\label{definition:conjug_func}
Let $f : \real^n \rightarrow [-\infty,\infty]$ be an extended real-valued function. The conjugate function  $f^* : \real^n \rightarrow  \real \cup \{-\infty, \infty \}$ of $f$ is defined by
$$
f^*(\by) = \max_{\bx \in \real^n} \{ \innerproduct{\by, \bx } - f(\bx) \}, \quad \by \in \real^n.
$$
\end{definition}
Fenchel's inequality follows immediately from the definition of conjugate functions.
\index{Fenchel's inequality}
\begin{theorem}[Fenchel's Inequality]\label{theorem:fenchel_ineq}
Let $f: \real^n \rightarrow (-\infty, \infty]$ be a proper and  extended real-valued  function. Then for any $\bx,\by \in \real^n$,
$$
f(\bx) + f^*(\by) \geq \innerproduct{\by, \bx}.
$$
\end{theorem}

\begin{exercise}\label{exercise:biconjugate}
Let $f:\real^n\rightarrow [-\infty,\infty]$ be an extended real-valued function. Show that $f(\bx)\geq f^{**}(\bx)$ for any $\bx\in\real^n$.
Additionally, let $g:\real^n\rightarrow (-\infty,\infty]$ be a proper closed and convex function. Show that $g(\bx)= g^{**}(\bx)$
\end{exercise}

\begin{exercise}[Closedness and Convexity of Conjugate]\label{exercise:closedconv_conj}
Let $f:\real^n\rightarrow (-\infty,\infty]$ be a proper  function. Show that $f^*$ is  closed and convex.
\end{exercise}
\begin{exercise}[Properness of Conjugate]\label{exercise:proper_conj}
Let $f:\real^n\rightarrow (-\infty,\infty]$ be a proper convex function. Show that $f^*$ is also proper.
\end{exercise}

The main result concerning the subdifferential of a conjugate function is the so-called \textit{conjugate subgradient theorem}.

\index{Conjugate subgradient theorem}
\begin{theorem}[Conjugate Subgradient Theorem]\label{theorem:conju_subgra}
Let $ f : \real^n \to (-\infty, \infty] $ be a  proper and \textbf{convex} function. The following two claims are equivalent for any $ \bx, \by \in \real^n $:
\begin{enumerate}[(i)]
\item $ \innerproduct{\bx, \by} = f(\bx) + f^*(\by) $. 
\item $ \by \in \partial f(\bx) $.
\end{enumerate}
\noindent If  $ f $ is additionally  \textbf{closed}, then (i) and (ii) are equivalent to
\begin{itemize}[(iii)]
\item $ \bx \in \partial f^*(\by) $.
\end{itemize}
\noindent Alternatively, let $ f : \real^n \to (-\infty, \infty] $ be a proper \textbf{closed convex} function. Then for any $\bx, \by \in \real^n$,
\begin{subequations}
\begin{align}
\partial f(\bx) &= \argmax_{\bu \in \real^n} \left\{ \innerproduct{\bx, \bu} - f^*(\bu) \right\};\\
\partial f^*(\by) &= \argmax_{\bv \in \real^n} \left\{ \innerproduct{\by, \bv} - f(\bv) \right\}.
\end{align}
\end{subequations}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:conju_subgra}]
By the subgradient inequality of $ \by \in \partial f(\bx) $, it follows that 
$$
f(\bu) \geq f(\bx) + \innerproduct{\by, \bu - \bx} 
\quad\implies\quad 
\innerproduct{\by, \bx } - f(\bx) \geq \innerproduct{ \by, \bu} - f(\bu)
\text{ for all } \bu \in \real^n.
$$
Taking the maximum over $ \bu $, the above inequality is equivalent to 
$$
\innerproduct{\by, \bx} - f(\bx) \geq f^*(\by),
$$
which by Fenchel's inequality (Theorem~\ref{theorem:fenchel_ineq}) is the same as the equality $\innerproduct{\bx, \by} = f(\bx) + f^*(\by)$, establishing the equivalence between (i) and (ii). 
When $f$ is proper closed and convex, by Exercise~\ref{exercise:biconjugate}, $f^{**} = f$, which  implies that (i) is equivalent to
$
\innerproduct{\bx, \by}= f^*(\by) + f^{**}(\bx)
$. By the above argument, we conclude that (i) is equivalent to $\bx \in \partial f^*(\by)$.
\end{proof}

\index{Fenchel's duality theorem}
An important result regarding conjugate functions is known as  \textit{Fenchel's duality theorem}. We briefly discuss the result here; and details can be found, for example, in \citet{bertsekas2009convex, rockafellar2015convex, beck2017first}.
Consider the following (primal) problem and its equivalent statement with an auxiliary variable:
$$
\begin{aligned}
\text{(P)}:\qquad  \quad& \min_{\bx \in \real^n} f(\bx) + g(\bx)\\
=&\min_{\bx, \by \in \real^n} \{f(\bx) + g(\by) : \bx = \by\}.
\end{aligned}
$$
Construct the Lagrangian function for (P) (see Section~\ref{section:gen_kkt_cond} for more details):
$$
L(\bx, \by, \blambda) = f(\bx) + g(\by) + \innerproduct{\blambda, \by - \bx} = -\left\{\innerproduct{\blambda, \bx} - f(\bx)\right\} - \left\{(-\blambda, \by) - g(\by)\right\}.
$$
The dual objective function is computed by minimizing the Lagrangian w.r.t. the primal variables $\bx, \by$:
$$
q(\blambda) = \min_{\bx, \by\in \real^n} L(\bx, \by, \blambda) = -f^*(\blambda) - g^*(-\blambda).
$$
Therefore, \textit{Fenchel's dual} can be expressed using the conjugate functions of the primal functions w.r.t. the Lagrangian multipliers $\blambda$:
$$
\text{(D)}:\qquad \min_{\blambda \in \real^n} \{f^*(\blambda) + g^*(-\blambda)\}.
$$
Fenchel's duality theorem then shows that strong duality (equivalence of (P) and (D)) holds for convex functions.
\begin{theorem}[Fenchel's Duality Theorem \citet{bertsekas2009convex, rockafellar2015convex, beck2017first}]\label{theorem:fen_dual_theo}
Let $f, g : \real^n \to (-\infty, \infty]$ be proper convex functions. If $\relint(\dom(f)) \cap \relint(\dom(g)) \neq \emptyset$~\footnote{By Theorem~\ref{theorem:nonemp_relint_conv}, the subdifferential in this set is nonempty.}, then
$$
\min_{\bx \in \real^n} \{f(\bx) + g(\bx)\} = \min_{\blambda \in \real^n} \{f^*(\blambda) + g^*(-\blambda)\}.
$$
\end{theorem}

\subsection{Lipschitz, Strongly Convex, Strongly Smooth Functions}
This section explores the properties of Lipschitz, strongly convex, and strongly smooth functions, defining these concepts and examining their implications on function behavior, including the boundedness of subdifferential sets for convex functions.
\index{Lipschitzness}
\begin{definition}[Lipschitz Functions]\label{definition:lipschi_funs}
Let $L\geq 0$, and let $f:\sS\rightarrow \real$ be a function defined over $\sS\subseteq  \real^n$. Then, the function $f$ is called \textit{L-Lipschitz} if, for every $\bx,\by\in\sS$, it follows that
$$
\abs{f(\bx)-f(\by)} \leq L\cdot \normtwo{\bx-\by}.
$$
If the function is continuously differentiable, then its gradient is called \textit{Lipschitz continuous} over $\real^n$ (or the function is called \textit{Lipschitz continuously differentiable}) if, for every $\bx,\by\in\sS$, it follows that
$$
\normtwo{\nabla f(\bx) - \nabla f(\by)} \leq L\cdot \normtwo{\bx-\by}.~\footnote{The concept of gradient Lipschitzness can be defined using dual norms: $\norm{\nabla f(\bx) - \nabla f(\by)}_* \leq L\cdot \norm{\bx-\by}$, where $\norm{\cdot}_*$ is the dual norm of $\norm{\cdot}$. Notably, the $\ell_2$ vector norm is self-dual. In our case, we only consider the $\ell_2$ vector norm.}
$$
The class of functions with a Lipschitz gradient and constant $L$ is denoted by $C_L^{1,1}(\real^n)$ or simply by $C_L^{1,1}$.

Similarly, the function is called \textit{twice Lipschitz continuously differentiable} with constant $L$, denoted by $C_L^{2,2}(\real^n)$, if, for every $\bx,\by\in\sS$, it follows that
$$
\normtwo{\nabla^2 f(\bx) - \nabla^2 f(\by)} \leq L\cdot \normtwo{\bx-\by}.
$$

More generally, let $\sS\subseteq\real^n$. We denote by $C_L^{k,p}(\sS)$ the class of functions possessing  the
following properties:
\begin{itemize}
\item Any $f\in C_L^{k,p}(\sS)$ is $k$ times continuously differentiable on $\sS$.
\item  Its $p$-th derivative is Lipschitz continuous on $\sS$ with constant $L$:
$\normtwo{\nabla^p f(\bx) - \nabla^p f(\by)} \leq L\cdot \normtwo{\bx-\by}.$
for all $\bx,\by\in\sS$. 
\end{itemize}
In this book, we usually work with $p = 0$, $p=1$, and $p = 2$. Clearly, we always have $p\leq k$. And it follows that $C_L^{t,p}(\sS) \subseteq  C_L^{k,p}(\sS)$ if $t\geq k$.
For simplicity, we also denotes $C^k(\sS)$ as the set of $k$ times continuously differentiable functions on $\sS$.
\end{definition}


\begin{example}\label{example:lipschitz_spar}
Consider the following examples:\begin{itemize}
\item Since $\absbig{\normone{\bx} - \normone{\by}} \leq \normone{\bx-\by} \leq \sqrt{n}\normtwo{\bx-\by}$ for any $\bx,\by\in\real^n$, $f_1(\bx)=\normone{\bx}$ is thus $\sqrt{n}$-Lipschitz.

\item Since $\absbig{\normtwo{\bb-\bA\bx} - \normtwo{\bb-\bA\by}} \leq \normtwo{(\bb-\bA\bx) - (\bb-\bA\by)} \leq \normtwo{\bA}\normtwo{\bx-\by}$, $f_2(\bx) = \normtwo{\bb-\bA\bx}$ is $\normtwo{\bA}$-Lipschitz, where $\normtwo{\bA}$ represents the spectral norm of $\bA$.
\end{itemize}
The function $f_3(\bx) \triangleq f_2^2(\bx) = \normtwo{\bb-\bA\bx}^2$ is not Lipschitz. However, it can be shown that $f_3(\bx)$ is Lipschitz continuously differentiable with constant $2\normtwo{\bA^\top\bA}$.
\end{example}

\begin{exercise}
Let $ f_1 \in C^{k,p}_{L_1}(\sS) $, $ f_2 \in C^{k,p}_{L_2}(\sS) $, $ \alpha_1, \alpha_2 \in \real $, and 
$ L_3 = \abs{\alpha_1} \cdot L_1 + \abs{\alpha_2} \cdot L_2 $.
Show that $ \alpha_1 f_1 + \alpha_2 f_2 \in C^{k,p}_{L_3}(\sS) $.
\end{exercise}

\begin{exercise}\label{exercise:cl2111_hess_bound}
Show that a function $ f(\cdot) $ belongs to the class $ C^{2,1}_L(\real^n) \subset C^{1,1}_L(\real^n) $ if and only if for all $ \bx \in \real^n $ we have
$
\normtwo{\nabla^2 f(\bx)} \leq L.
$~\footnote{Since the spectral norm of $\nabla^2 f(\bx)$ is the largest singular value of $\nabla^2 f(\bx)$, where $\nabla^2 f(\bx)$ is symmetric. This also indicates that $-L\bI\preceq \nabla^2 f(\bx) \preceq L\bI$.}
\textit{Hint: use the fundamental theorem of calculus (Theorem~\ref{theorem:fund_theo_calculu}).}
\end{exercise}

\begin{theorem}[Lipschitz and Boundedness of Subdifferential Sets]\label{theorem:lipsc_equiv}
Let $f:\sS \rightarrow \real$ be a  \textbf{convex} function, and let $\sX \subseteq \interior(\sS)$. Consider the following two claims:
\begin{enumerate}[(i)]
\item $\abs{f(\bx) - f(\by)} \leq L\normtwo{\bx - \by}$ for any $\bx, \by \in \sX$.
\item $\normtwo{\bg} \leq L$ for any $\bg \in \partial f(\bx), \bx \in \sX$.
\end{enumerate}
Then,
\begin{enumerate}[(a)]
\item The implication (ii) $\implies$ (i) holds,
\item If $\sX$ is open, then statement  (i) holds if and only if  statement  (ii) holds.
\end{enumerate}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:lipsc_equiv}]
\textbf{(a).} Assume that (ii) is satisfied, and let $\bx, \by \in \sX$. Let $\bg_x \in \partial f(\bx)$ and $\bg_y \in \partial f(\by)$.
By the definitions of $\bg_x, \bg_y$ and the  Cauchy-Schwarz inequality (Proposition~\ref{proposition:cauchy-schwarz-inequ}),
\begin{align*}
f(\bx) - f(\by) &\leq \innerproduct{\bg_x, \bx - \by} \leq \normtwo{\bg_x} \normtwo{\bx - \by} \leq L\normtwo{\bx - \by}; \\
f(\by) - f(\bx) &\leq \innerproduct{\bg_y, \by - \bx} \leq \normtwo{\bg_y} \normtwo{\bx - \by} \leq L\normtwo{\bx - \by},
\end{align*}
which establishes the validity of (i).

\paragraph{(b).} The implication (ii) $\implies$ (i) was shown in (a). Conversely, assume that (i) is satisfied. Take $\bx \in \sX$ and $\bg \in \partial f(\bx)$. Let $\widetildebg\triangleq\frac{\bg}{\normtwo{\bg}}$ such that $\normtwo{\widetildebg} = 1 $ and $ \innerproduct{\widetildebg, \bg} = \normtwo{\bg}$. Since $\sX$ is open, we can take $\epsilon > 0$ small enough such that $\bx + \epsilon \widetildebg \in \sX$. 
Given the subgradient inequality, it follows that
$
f(\bx + \epsilon \widetildebg) \geq f(\bx) + \epsilon \innerproduct{\bg, \widetildebg},
$
whence we have
$$
\epsilon \normtwo{\bg}  \leq f(\bx + \epsilon \widetildebg) - f(\bx) \leq L \normtwo{\bx + \epsilon \widetildebg - \bx} = L\epsilon
\quad\implies\quad \normtwo{\bg} \leq L.
$$
This completes the proof.
\end{proof}


\begin{exercise}[Gradient Lipschitzness of Quadratic Functions]
Let $f(\bx) = \frac{1}{2} \bx^\top\bA\bx+\bb^\top\bx+c$, where $\bA$ is symmetric, $\bb\in\real^n$, and $c\in\real$. Show that the gradient of $f(\bx)$ is $\normtwo{\bA}$-Lipschitz. This also indicates that the gradient function is 0-Lipschitz when $\bA=\bzero$ (an affine function). 
\end{exercise}

Below, we provide rigorous definitions of \textit{strong convexity (SC)} and \textit{strong smoothness (SS, or simply smoothness)}. Although both terms can be defined for non-differentiable functions using subgradients in convex cases, we will focus on differentiable functions in this book.
\begin{figure}[htp]
\centering       
\vspace{-0.25cm}                 
\subfigtopskip=2pt               
\subfigbottomskip=-2pt         
\subfigcapskip=-10pt      
\includegraphics[width=0.98\textwidth]{imgs/cvxfunc.pdf}
\caption{A convex function is always bounded below by its tangent at any point. In contrast, strongly convex functions are not only bounded below but also have a quadratic lower bound that limits how slowly they can grow. Similarly, smooth functions have an upper bound on their growth rate, which prevents them from increasing too rapidly. These bounds ensure that strongly convex and smooth functions cannot grow either too slowly or too quickly compared to quadratic functions. In each figure, the shaded area represents the region where the function's curve is allowed to lie. The figure is adapted from \citet{jain2017non}.}
\label{fig:cvxfunc}
\end{figure}
\index{Strongly convex}
\index{Strongly smooth}
\index{Smooth}
\begin{definition}[Strongly Convex/Smooth Functions]\label{definition:scss_func}
Let $f:\sS\rightarrow \real$ be a  differentiable function defined over a \textbf{convex} $\sS\subseteq  \real^n$~\footnote{Note the notions of strong convexity and smoothness are primarily meaningful for differentiable functions (at least mostly for differentiable) defined over a convex set. For example, $\bS$ can be set to $\real^n$. The reason will be clear in the sequel.}. Then, $f$ is called \textit{$\alpha$-strongly convex (SC, or simply $\alpha$-convex)} and \textit{$\beta$-strongly smooth (SS, or simply $\beta$-smooth)} if, for every $\bx,\by\in\sS$, it follows that 
\begin{equation}\label{equation:scss_func1}
\frac{\alpha}{2} \normtwo{\bx-\by}^2
\leq f(\by)-f(\bx)-\nabla f(\bx)^\top (\by-\bx)
\leq \frac{\beta}{2} \normtwo{\bx-\by}^2.~\footnote{In many texts, the second inequality is called the \textit{descent lemma} for $\beta$-strongly smooth functions since $f(\by) \leq f(\bx)+\nabla f(\bx)^\top (\by-\bx)+\frac{\beta}{2} \normtwo{\bx-\by}^2$, i.e., an update of the function value  from $f(\bx)$ to $f(\by)$ is upper-bounded.}
\end{equation}
When the function is twice differentiable, Theorem~\ref{theorem:psd_hess_conv} also indicates  that 
\begin{equation}\label{equation:scss_func2}
\alpha\bI \preceq \nabla^2 f(\bx) \preceq \beta\bI, \quad\text{for all } \bx\in\interior(\sS).~\footnote{We relax to $\bx\in\interior(\sS)$ as opposed to claiming an open set in Theorem~\ref{theorem:psd_hess_conv}.}
\end{equation}
That is, the smallest eigenvalue of $\nabla^2 f(\bx)$ is at least $\alpha$, and the largest eigenvalue of $\nabla^2 f(\bx)$ is at most $\beta$ (Theorem~\ref{theorem:eigen_charac}):
\begin{equation}\label{equation:scss_func3_ra}
\alpha\leq \frac{\bv^\top \nabla^2 f(\bx) \bv}{\normtwo{\bv}^2} \leq \beta, \quad\text{for all } \bx\in\sS, \text{and nonzero } \bv\in\real^n.~\footnote{$\frac{\bv^\top\bA\bv}{\normtwo{\bv}^2}$ is called the \textit{Rayleigh quotient} of vector $\bv$ associated with the matrix $\bA$, which lies between the largest and smallest eigenvalues of $\bA$; see, for example, \citet{lu2021numerical} for more details.}
\end{equation}
It is evident that if the function is $\beta_1$-strongly smooth, it is also $\beta_2$-strongly smooth for any $\beta_2\geq \beta_1$.
A $\alpha$-strongly convex function is necessarily a convex function (when $\alpha=0$, it reduces to a standard convex function). 
While if the function is $\alpha_1$-strongly convex, it is also $\alpha_2$-strongly convex for any $\alpha_2\in(0, \alpha_1]$.
\end{definition}
Strong convexity and smoothness play crucial roles in analyzing gradient descent algorithms (see Chapter~\ref{chapter:gd_convg}). Definition~\ref{definition:res_scss_func} extends these notions to non-convex sets.
Strong convexity ensures the function curves upwards sharply, providing a lower bound on its curvature and preventing gradients from vanishing too quickly. Conversely, strong smoothness imposes a quadratic upper bound on the curvature, ensuring that gradients do not change too rapidly, thereby controlling the magnitude of gradient descent steps and avoiding overly aggressive updates (see Figure~\ref{fig:cvxfunc}).




\begin{example}[Convex, SC]
Let $f(\bx) = \bx^\top \bA \bx + \bb^\top \bx + c$.
Then the function is 
\begin{itemize}
\item Convex if and only if $\bA \succeq \bzero$; strictly convex if and only if $\bA \succ \bzero$.
\item Concave if and only if $\bA \preceq \bzero$; strictly concave if and only if $\bA \prec \bzero$.
\end{itemize}
The proofs are easy if we use the second-order characterization of convexity (Theorem~\ref{theorem:psd_hess_conv}).
\end{example}

\begin{exercise}[Sum of SC and Convex, SS]\label{exercise:sum_sc_conv}
Prove the following two results:
\begin{itemize}
\item Let $f$ be a $\alpha$-SC function and $g$ be a convex function. Show that $f+g$ is $\alpha$-SC. 
\item Let $f$ be a $\beta_1$-SS function and $g$ be a $\beta_2$-SS function. Show that $f+g$ is $(\beta_1+\beta_2)$-SS. 
\end{itemize}
\end{exercise}
\begin{exercise}[Level Sets of SC and SS]
Let $f:\real^n\rightarrow \real$ be $\alpha$-SC and $\beta$-SS, and define the level set $\lev[f, \gamma] \triangleq \{\bx \mid f(\bx)\leq\gamma\}$. Show that 
$$
\sB_2\Big[\bx^*, \sqrt{\frac{2}{\beta}(\gamma-f(\bx^*))}\Big]
\subseteq
\lev[f, \gamma]\subseteq 
\sB_2\Big[\bx^*, \sqrt{\frac{2}{\alpha}(\gamma-f(\bx^*))}\Big],
$$
where $\bx^*$ is the global minimum point of $f$ (such that $f(\bx^*)\leq f(\bx)$ for all $\bx$; Definition~\ref{definition:local_global_opt}).
That is, the level set lies between the two balls.
\end{exercise}



\begin{theorem}[SS Property-O: Equivalence between Gradient Lipschitzness and Smoothness]\label{theorem:equi_gradsch_smoo}
Let $f:\sS\rightarrow \real$ be a  differentiable function defined over a \textbf{convex} set $\sS\subseteq  \real^n$.
If $f$ is gradient  Lipschitz continuous with constant $\beta$, i.e., $f\in C_{\beta}^{1,1}(\sS)$, then it is also $\beta$-smooth.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:equi_gradsch_smoo}]
By the fundamental theorem of calculus (Equation~\eqref{equation:fund_theo_calculu3}), it follows that 
$
f(\by) - f(\bx) = \innerproduct{\nabla f(\bx), \by - \bx}+ \int_0^1 \innerproduct{\nabla f(\bx + \mu(\by - \bx)) - \nabla f(\bx), \by - \bx} d\mu.
$
Since $\sS$ is a convex set, the function $f(\bx + \mu(\by - \bx))$ is well-defined for $\mu\in[0,1]$.
This results in 
$$
\begin{aligned}
&\gap \abs{f(\by) - f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx}} =  \abs{\int_0^1 \innerproduct{\nabla f(\bx + \mu(\by - \bx)) - \nabla f(\bx), \by - \bx} d\mu } \\
&\overset{\dag}{\leq} \int_0^1 \normtwo{\nabla f(\bx + \mu(\by - \bx)) - \nabla f(\bx)}\cdot  \normtwo{\by - \bx} d\mu
\leq   \int_0^1 \beta \mu \normtwo{\by - \bx}^2 d\mu 
= \frac{\beta}{2} \normtwo{\by - \bx}^2,
\end{aligned}
$$
where the inequality $(\dag)$ follows from the  Cauchy-Schwarz inequality (Proposition~\ref{proposition:cauchy-schwarz-inequ}).
\end{proof}

If $ f $ is $\beta$-smooth and has a global minimum point $ \bx^* $, an important corollary is that we can use the quadratic upper bound to estimate the magnitude of $f(\bx) - f(\bx^*)$, where $ \bx $ can be any point in the domain.
\begin{theorem}[SS\&SC Property-I: Bound of $f(\bx) - f(\bx^*)$]\label{theorem:smoo_prop2_bound}
Let $ f:\real^n\rightarrow \real $ be  a differentiable function  defined on $ \real^n $  and have a global minimum point $ \bx^* $. If $ f(\bx) $ is  $ \beta $-smooth and $\alpha$-strongly convex, then
$$
\frac{1}{2\beta} \normtwo{\nabla f(\bx)}^2 \leq f(\bx) - f(\bx^*)
\leq \frac{1}{2\alpha}  \normtwo{\nabla f(\bx)}^2,\quad  \text{ for any } \bx\in\real^n.
$$
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:smoo_prop2_bound}]
Since $ \bx^* $ is a global minimum point, for any $\by\in\real^n$, applying the quadratic upper bound from the smoothness gives
$$
f(\bx^*) \leq f(\by) \leq f(\bx) + \nabla f(\bx)^\top (\by - \bx) + \frac{\beta}{2} \normtwo{\by - \bx}^2.
$$
Fixing $ \bx $, note that the above inequality holds for any $ \by $, thus we can take the infimum on the right side of the inequality:
$$
\begin{aligned}
f(\bx^*) &\leq \inf_{\by \in \real^n} \left\{ f(\bx) + \nabla f(\bx)^\top (\by - \bx) + \frac{\beta}{2} \normtwo{\by - \bx}^2 \right\} 
= f(\bx) - \frac{1}{2\beta} \normtwo{\nabla f(\bx)}^2,
\end{aligned}
$$
where the minimum is attained at $\by = \bx-\frac{1}{\beta}\nabla f(\bx)$ (since the domain is $\real^n$).

For the second part, since $f$ is strongly convex, we have 
$$
\begin{aligned}
f(\by)&\geq f(\bx) +\nabla f(\bx)^\top (\by-\bx) + \frac{\alpha}{2} \normtwo{\by-\bx}^2\\
&\geq f(\bx) +\nabla f(\bx)^\top (\widetildeby-\bx) + \frac{\alpha}{2} \normtwo{\widetildeby-\bx}^2\\
&=f(\bx)-\frac{1}{2\alpha} \normtwo{\nabla f(\bx)}^2,
\end{aligned}
$$
where $\widetildeby \triangleq \bx-(1/\alpha) \nabla f(\bx)$ minimizes the right-hand side of the above inequality. 
Letting $\by\triangleq\bx^*$ completes the proof.
\end{proof}

The second result in the above theorem shows that 
\begin{equation}
\normtwo{\nabla f(\bx)} \leq (2\alpha\varepsilon)^{1/2}
\quad\implies\quad 
f(\bx) - f(\bx^*)\leq \varepsilon,
\end{equation}
where $\varepsilon$ represents a positive  \textit{tolerance}.
This generalizes the \textit{optimality condition for convex functions} stated  in Theorem~\ref{theorem:fetmat_opt}.
Additionally, the theorem indicates that a strongly smooth function exhibits a specific growth characteristic near the minimizer.

The next theorem states that a proper closed and strongly convex function has a unique minimizer and  satisfies a certain growth property around this minimizer.
\begin{theorem}[SC Property-II: Existence and Uniqueness of a Minimizer of Closed SC Functions]\label{theorem:exi_close_sc}
Let $f :  \real^n \rightarrow (-\infty, \infty]$ be a differentiable~\footnote{Note that this theorem also holds for non-differentiable functions, and subgradient can be used in the proof by Theorem~\ref{theorem:nonemp_relint_conv}.}, proper closed, and $\alpha$-strongly convex function ($\alpha > 0$). Then,
\begin{enumerate}[(i)]
\item  $f$ has a unique minimizer.
\item  $f(\bx) - f(\bx^*) \geq \frac{\alpha}{2} \normtwo{\bx - \bx^*}^2$ for all $\bx \in \real^n$, where $\bx^*$ is the unique minimizer of $f$.
\end{enumerate}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:exi_close_sc}]
\textbf{(i).} Let $\bx_0\in\real^n$. By  strong convexity, it follows that
$$
\begin{aligned}
&f(\bx) \geq f(\bx_0) + \innerproduct{\nabla f(\bx_0), \bx - \bx_0} + \frac{\alpha}{2} \normtwo{\bx - \bx_0}^2 \\
&\quad\implies 
f(\bx) \geq f(\bx_0) - \frac{1}{2\alpha} \normtwo{\nabla f(\bx_0)}^2 + \frac{\alpha}{2} \normtwo{\bx - \left(\bx_0 - \frac{1}{\alpha} \nabla f(\bx_0)\right)}^2 \quad \text{for any } \bx \in \real^n.
\end{aligned}
$$
This indicates that
$$
\lev[f, f(\bx_0)] \subseteq \sB_{2}\left[\bx_0 - \frac{1}{\alpha} \nabla f(\bx_0), \frac{1}{\alpha} \normtwo{\nabla f(\bx_0)}\right].
$$
Since $f$ is closed, the above level set is closed (Theorem~\ref{theorem:equiv_close_clkos_semicon}); and since it is contained in a ball, it is also bounded. Therefore, $\lev[f, f(\bx_0)]$ is compact. We can thus deduce that the optimal set for minimizing $f$ over $\dom(f)$ is identical to the optimal set for minimizing $f$ over the nonempty compact set $\lev[f, f(\bx_0)]$. Invoking Weierstrass theorem  for proper closed functions (\ref{weier2_prop_close}.\ref{weier2_prop_close_v1} in Theorem~\ref{theorem:weierstrass_them}), it follows that a minimizer exists. To show the uniqueness, assume that $\widetildebx$ and $\bx^*$ are minimizers of $f$. Then $f(\widetildebx)  = f(\bx^*)$, where $f(\bx^*)$ is the minimal value of $f$. Then by property (iv) of Theorem~\ref{theorem:charac_stronconv},
$$
f(\bx^*) \leq f\left(\frac{1}{2}\widetildebx + \frac{1}{2}\bx^*\right) \leq \frac{1}{2} f(\widetildebx) + \frac{1}{2} f(\bx^*) - \frac{\alpha}{8} \normtwo{\widetildebx - \bx^*}^2 = f(\bx^*) - \frac{\alpha}{8} \normtwo{\widetildebx - \bx^*}^2,
$$
implying that $\widetildebx = \bx^*$, thus proving the uniqueness of the minimizer of $f$.

\paragraph{(ii).} Let $\bx^*$ be the unique minimizer of $f$. Then by optimality condition for convex functions (Theorem~\ref{theorem:fetmat_opt}), $ \nabla f(\bx^*) = \bzero$. Thus, by the definition of strong convexity,
$$
f(\bx) - f(\bx^*) \geq \langle \bzero, \bx - \bx^* \rangle + \frac{\alpha}{2} \normtwo{\bx - \bx^*}^2 = \frac{\alpha}{2} \normtwo{\bx - \bx^*}^2 ,
\;\text{ for any $\bx \in \real^n$},
$$
establishing claim (ii).
\end{proof}


The definition of smoothness does not require the function to be convex. However, when it indeed is, the function can be equivalently characterized as follows. 
\begin{theorem}[Characterization Theorem of SS and Convexity \citep{beck2017first}]\label{theorem:charac_smoo}
Let $f: \sS\subseteq\real^n \rightarrow \real$ be a differentiable \textbf{convex} function defined on a convex set $\sS$, and let $\beta > 0$. Then the following claims are equivalent:
\begin{enumerate}[(i)]
\item $f$ is $\beta$-smooth.
\item The function $g(\bx)\triangleq \frac{\beta}{2}\bx^\top\bx - f(\bx)$ is convex.
\item $f(\by) \leq f(\bx) + \innerproduct{\nabla f(\bx), \by - \bx} + \frac{\beta}{2} \normtwo{\bx - \by}^2$ for all $\bx, \by \in \sS$.
\item $ f(\by) \geq f(\bx) + \innerproduct{\nabla f(\bx), \by - \bx} + \frac{1}{2\beta} \normtwo{\nabla f(\bx) - \nabla f(\by)}^2 $ for all $\bx, \by \in \sS$.
\item $f(\lambda \bx + (1 - \lambda)\by) \geq \lambda f(\bx) + (1 - \lambda)f(\by) - \frac{\beta}{2} \lambda (1 - \lambda) \normtwo{\bx - \by}^2$ for any $\bx, \by \in \sS$ and $\lambda \in [0, 1]$.
\end{enumerate}
Reversing $\bx$ and $\by$ in (iii) and (iv), we can also obtain 
\begin{equation}\label{equ:charac_smoo_3} 
\frac{1}{\beta} \normtwo{\nabla f(\bx) - \nabla f(\by)}^2 
\leq  \innerproduct{\nabla f(\bx) - \nabla f(\by), \bx - \by} 
\leq  
\beta\normtwo{\bx-\by}^2,  
\text{ for all  $\bx, \by \in \sS$.}
\end{equation}
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:charac_smoo}]
\textbf{(i)$\implies$(ii).} For any $\bx,\by\in\sS$, it follows that 
$$
\begin{aligned}
\big(\nabla g(\bx) - \nabla g(\by)\big)^\top (\bx - \by) 
&= \beta \normtwo{\bx - \by}^2 - \big(\nabla f(\bx) - \nabla f(\by)\big)^\top (\bx - \by)\\
&\geq \beta \normtwo{\bx - \by}^2 - \normtwo{\bx - \by} \normtwo{\nabla f(\bx) - \nabla f(\by)} \geq 0.
\end{aligned}
$$
where the last inequality follows from Theorem~\ref{theorem:equi_gradsch_smoo} and the definition of smoothness.
Thus, $ g(\bx) $ is a convex function by Theorem~\ref{theorem:monoton_convgrad}.

\paragraph{(ii)$\implies$(iii).}
Since $ g(\bx) \triangleq \frac{\beta}{2} \normtwo{\bx}^2 - f(\bx) $ is convex, this implies
$$
g(\by) \geq g(\bx) + \nabla g(\bx)^\top (\by - \bx), \quad \forall \bx, \by \in \sS,
$$
where
$
\nabla g(\bx) = \beta \bx - \nabla f(\bx).
$
Substituting the gradient into the convexity condition yields that
\begin{align}
\frac{\beta}{2} \normtwo{\by}^2 - f(\by) \geq \frac{\beta}{2} \normtwo{\bx}^2 - f(\bx) + \big(\beta \bx - \nabla f(\bx)\big)^\top (\by - \bx) \nonumber\\
\quad\implies\quad f(\by) - f(\bx) \leq \nabla f(\bx)^\top (\by - \bx) + \frac{\beta}{2} \normtwo{\by - \bx}^2. \label{equation:charac_smoo11}
\end{align}


\paragraph{(iii)$\implies$(iv).} We can assume that $\nabla f(\bx) \neq \nabla f(\by)$ since otherwise the inequality (iv) is trivial by the convexity of $f$. For a fixed $\bx \in \sS$, consider the function
$$ 
g_{\bx}(\by) \triangleq f(\by) - f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx}, \quad \by \in \sS, 
$$
which is convex w.r.t. $\by$.
Note that $\nabla g_{\bx}(\by) = \nabla f(\by)-\nabla f(\bx)$ for any $\by\in\sS$.
By the condition of (iii), for any $\by, \bu \in \sS$, we have 
\begin{equation}\label{equation:char_ss_eqq1}
\begin{aligned}
g_{\bx}(\bu) &= f(\bu) - f(\bx) - \innerproduct{\nabla f(\bx), \bu - \bx} \\
&\leq \big\{f(\by) + \innerproduct{\nabla f(\by), \bu - \by} + \frac{\beta}{2} \normtwo{\bu - \by}^2\big\} - f(\bx) - \innerproduct{\nabla f(\bx), \bu - \bx} \\
&= f(\by) - f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx} + \innerproduct{\nabla f(\by) - \nabla f(\bx), \bu - \by} + \frac{\beta}{2} \normtwo{\bu - \by}^2 \\
&= g_{\bx}(\by) + \innerproduct{\nabla g_{\bx}(\by), \bu - \by} + \frac{\beta}{2} \normtwo{\bu - \by }^2,
\end{aligned}
\end{equation}
Since $\nabla g_{\bx}(\bx) = \bzero$, which by the convexity of $g_{\bx}$ implies that $\bx$ is a global minimizer of $g_{\bx}$ such that
$
0=g_{\bx}(\bx) \leq g_{\bx}(\bu),\, \text{for all } \bu \in \sS.  
$
Let $\by \in \sS$, and let $\widetildebg \triangleq \frac{\nabla g_{\bx}(\by)}{\normtwo{\nabla g_{\bx}(\by)}}$ such that  $\normtwo{\widetildebg} = 1$ and $\innerproduct{\nabla g_{\bx}(\by), \widetildebg} = \normtwo{\nabla g_{\bx}(\by)}$. Defining
$ \bu \triangleq \by - \frac{\normtwo{\nabla g_{\bx}(\by)}}{\beta} \widetildebg  $, the optimum of $g_{\bx}(\bx)$ shows that 
$$
0 = g_{\bx}(\bx) \leq g_{\bx} \left( \by - \frac{\normtwo{\nabla g_{\bx}(\by)}}{\beta} \widetildebg \right). 
$$
Combining the preceding inequality with \eqref{equation:char_ss_eqq1}, we obtain
\begin{align*}
0 &= g_{\bx}(\bx) 
\leq g_{\bx}(\by) - \frac{\normtwo{\nabla g_{\bx}(\by)}}{\beta} \innerproduct{\nabla g_{\bx}(\by), \widetildebg} + \frac{\normtwo{\nabla g_{\bx}(\by)}^2 \cdot \normtwo{\widetildebg}^2 }{2\beta} 
= g_{\bx}(\by) - \frac{\normtwo{\nabla g_{\bx}(\by)}^2}{2\beta}  \\
&= f(\by) - f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx} - \frac{1}{2\beta} \normtwo{\nabla f(\bx) - \nabla f(\by)}^2,
\end{align*}
establishing (iv).

\paragraph{(iii)$\implies$(v).}
Let $\bx, \by \in \sS$ and $\lambda \in [0, 1]$, and denote $\bxi \triangleq \lambda \bx + (1 - \lambda) \by$. Since $\sS$ is convex, we also have $\bxi\in\sS$.
Invoking (iii) with $\bx,\bxi$ and $\by,\bxi$, and plugging in the expression of $\bxi$ yields that 
$$
\begin{aligned}
	f(\bx) &\leq f(\bxi) + (1 - \lambda) \innerproduct{\nabla f(\bxi), \bx - \by} + \frac{\beta (1 - \lambda)^2}{2} \normtwo{\bx - \by}^2, \\
	f(\by) &\leq f(\bxi) + \lambda \innerproduct{\nabla f(\bxi), \by - \bx} + \frac{\beta \lambda^2}{2} \normtwo{\bx - \by}^2.
\end{aligned}
$$
Multiplying the first inequality by $\lambda$ and the second by $1 - \lambda$ and adding them yields the inequality (v).

\paragraph{(v)$\implies$(iii).} Rearranging terms in the inequality (v), we obtain that it is equivalent to
$$
f(\by) \leq f(\bx) + \frac{f\big(\bx + (1 - \lambda)(\by - \bx)\big) - f(\bx)}{1 - \lambda} + \frac{\beta}{2} \lambda \normtwo{\bx - \by}^2. 
$$
Taking $\lambda \to 1^-$, the preceding inequality becomes
$ f(\by) \leq f(\bx) + f'(\bx; \by - \bx) + \frac{\beta}{2} \normtwo{\bx - \by}^2$.
Since $f$ is differentiable, \eqref{equation:direc_contdiff} shows that $f'(\bx; \by - \bx) = \innerproduct{\nabla f(\bx), \by - \bx}$, establishing the desired result. 
\end{proof}



\begin{theorem}[Characterization Theorem of SC \citep{beck2017first}]\label{theorem:charac_stronconv}
Let $ f:\sS\subseteq\real^n\rightarrow \real $ be a convex and differentiable function defined on a convex set $\sS$, and let $ \alpha > 0 $. Then the following  claims are equivalent:
\begin{enumerate}[(i)]
\item $ f $ is $ \alpha $-strongly convex.
\item $
f(\by) \geq f(\bx) + \innerproduct{\nabla f(\bx) , \by - \bx} + \frac{\alpha}{2} \normtwo{\by - \bx}^2
$
for any $ \bx , \by \in \sS$.
\item $
\innerproduct{\nabla f(\bx)  - \nabla f(\by) , \bx - \by} \geq \alpha \normtwo{\bx - \by}^2
$
for any $ \bx, \by \in \sS $.
\item $f(\lambda \bx+(1-\lambda)\by )\leq \lambda f(\bx)+(1-\lambda)f(\by) -\frac{\alpha}{2}\lambda(1-\lambda)\normtwo{\bx-\by}^2$ for any $\lambda\in[0,1]$ and $\bx,\by\in\sS$.
\end{enumerate}
\end{theorem}
The proof is similar to that of Theorem~\ref{theorem:charac_smoo} and is left as an exercise.
Notably, combining Theorem~\ref{theorem:charac_smoo} and Theorem~\ref{theorem:charac_stronconv}, if $f:\sS\subseteq\real^n\rightarrow \real$ is differentiable, $\alpha$-SC, and $\beta$-SS defined on a convex set $\sS$ with $0<\alpha<\beta$, then for any $\bx,\by\in\sS$,
\begin{subequations}
\begin{align}
\frac{\alpha}{2} \normtwo{\bx-\by}^2
\;&\leq f(\by) -f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx}
&\leq&  \frac{\beta}{2} \normtwo{\bx - \by}^2; \label{equation:sssc_eq1} \\
\alpha \normtwo{\bx - \by}^2 
\;&\leq \innerproduct{\nabla f(\bx)  - \nabla f(\by) , \bx - \by} 
&\leq& \beta\normtwo{\bx-\by}^2;\label{equation:sssc_eq2} \\
\frac{\alpha\zeta}{2}\normtwo{\bx-\by}^2 
\;&\leq \big\{\lambda f(\bx)+(1-\lambda)f(\by)\} - f\big(\lambda \bx+(1-\lambda)\by \big) 
&\leq& \frac{\beta\zeta}{2}  \normtwo{\bx - \by}^2, \label{equation:sssc_eq3}
\end{align}
\end{subequations}
where $\zeta\triangleq \lambda(1-\lambda)$ for any $\lambda\in[0,1]$, and \eqref{equation:sssc_eq1} is equivalent to Definition~\ref{definition:scss_func}.
In some texts, the definitions of SC and SS are defined using \eqref{equation:sssc_eq3} instead since it does not require the function to be differentiable.
Again, we focus on differentiable functions in this book. 
When the function is not differentiable, the gradient in Theorem~\ref{theorem:charac_smoo} or  Theorem~\ref{theorem:charac_stronconv} can be replaced with subgradients due to the nonemptyness of subdifferential by Theorem~\ref{theorem:nonemp_relint_conv}.
Additionally, we have the following characterization theorem for SC and SS functions.
\begin{theorem}[Characterization Theorem of SC and SS]\label{theorem:charac_smoo_n_stronconv}
Let $f:\sS\subseteq\real^n\rightarrow \real$ be a differentiable, $\alpha$-strongly convex, and $\beta$-smooth function defined on a convex set $\sS$ with $\alpha\leq \beta$. Then, for any $\bx,\by\in\sS$, it follows that 
\begin{equation}\label{equation:baillon_hadded}
\innerproduct{\nabla f(\bx) - \nabla f(\by), \bx -\by}
\geq
\frac{\alpha\beta}{\alpha+\beta} \normtwo{\bx-\by}^2 + \frac{1}{\alpha+\beta} \normtwo{\nabla f(\bx) - \nabla f(\by)}^2.
\end{equation}
When $\alpha=0$, this reduces to the implication in \eqref{equ:charac_smoo_3} of Theorem~\ref{theorem:charac_smoo}.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:charac_smoo_n_stronconv}]
Let $g(\bx) \triangleq f(\bx) -\frac{1}{2} \alpha\normtwo{\bx}^2$. Then $\nabla g(\bx) = \nabla f(\bx) -\alpha\bx$.
Using (iii) in Theorem~\ref{theorem:charac_stronconv} and \eqref{equ:charac_smoo_3} in Theorem~\ref{theorem:charac_smoo}, this implies $g(\bx)$ is $(\beta-\alpha)$-smooth and 
$$
\frac{1}{\beta-\alpha} \normtwo{\nabla g(\bx) - \nabla g(\by)}^2 
\leq  \innerproduct{\nabla g(\bx) - \nabla g(\by), \bx - \by},
$$
which is equivalent to the result.
\end{proof}



In non-convex optimization problems, we may also be interested  in the concept of restricted convexity/smoothness for functions.
\begin{definition}[Restricted Strong Convexity/Smoothness]\label{definition:res_scss_func}
Let $f:\sS\subseteq \real^n\rightarrow \real$ be a  differentiable function. 
Then $f$ is said to satisfy \textit{restricted convexity} over a (possibly non-convex) set $\sS\subseteq  \real^n$ if for every $\bx,\by\in\sS$, it follows that 
\begin{equation}\label{equation:res_scss_func0}
f(\by) \geq f(\bx) +\nabla f(\bx)^\top (\by-\bx).
\end{equation}
Additionally, $f$ is said to satisfy \textit{$\alpha$-restricted strong convexity (RSC)} and \textit{$\beta$-restricted strong smoothness (RSS)} over a (possibly non-convex) set $\sS\subseteq  \real^n$ if for every $\bx,\by\in\sS$, it follows that 
\begin{equation}\label{equation:res_scss_func1}
\frac{\alpha}{2} \normtwo{\bx-\by}^2
\leq f(\by)-f(\bx)-\nabla f(\bx)^\top (\by-\bx)
\leq \frac{\beta}{2} \normtwo{\bx-\by}^2.
\end{equation}
When the function is twice differentiable, Theorem~\ref{theorem:psd_hess_conv} also indicates  that 
\begin{equation}\label{equation:res_scss_func2}
\alpha\bI \preceq \nabla^2 f(\bx) \preceq \beta\bI,
\end{equation}
for any $\bx\in\interior(\sS)$ and there exists a vector $\by\in\real^n$ such that $\bx+\lambda\by\in\sS$ for some  sufficiently small $\lambda$ (see proof of Theorem~\ref{theorem:psd_hess_conv}).
That is, 
\begin{equation}\label{equation:res_scss_func3_ra}
\alpha\leq \frac{\bv^\top \nabla^2 f(\bx) \bv}{\normtwo{\bv}^2} \leq \beta,
\end{equation}
for any $\bx\in\interior(\sS)$ and $\bv\in\real^n$ such that $\bx+\lambda\bv\in\sS$ for some sufficiently small $\lambda$.
\end{definition}
Figure~\ref{fig:rssfunc} depicts the situation of restricted convexity, RSC, RSC. 
We note that when $f(\bx) = \frac{1}{2m}\normtwo{\bA\bx-\bb}^2$, where $\bA\in\real^{m\times n}$ and $\bb\in\real^m$, \eqref{equation:res_scss_func3_ra} becomes $\alpha\leq \frac{\bv^\top (\frac{1}{m}\bA^\top\bA) \bv}{\normtwo{\bv}^2} \leq \beta$. 
This yields the RSC and RSS properties for sparse problems (Definition~\ref{definition:res_scss_mat}).


\begin{figure}
\centering       
\vspace{-0.25cm}                 
\subfigtopskip=0pt               
\subfigbottomskip=0pt         
\subfigcapskip=0pt      
\includegraphics[width=0.98\textwidth]{imgs/rssfunc.pdf}
\caption{
An illustration of restricted convexity properties. The first function $f$ exhibits non-convex behavior over the entire real line, yet it shows convex characteristics within the shaded region delineated by the dotted vertical lines. The second and third functions are also non-convex overall but demonstrate restricted strong convexity. Outside the shaded area (once more, marked by the dotted vertical lines), these functions fail to maintain convexity, as evidenced by their curves falling below their tangents. However, within the defined region, they exhibit strong convexity. Figure is adapted from \citet{jain2017non}.}
\label{fig:rssfunc}
\end{figure}






\section{Projection, Proximal, Bregman-Proximal, and Separation}\label{section:proj_prox_sep}

In this section, we explore the fundamental concepts of projection and proximal operators, which are essential tools in optimization theory and convex analysis. These concepts are particularly important for projected/proximal gradient descent methods discussed in Chapter~\ref{chapter:gd_convg}, as well as for proving various theorems.


To begin, let us define a divergence measure based on a convex and differentiable function.
\begin{definition}[Bregman Distance]\label{definition:breg_dist}
The \textit{Bregman distance (or Bregman divergence)} generalizes the concept of squared Euclidean distance and measures the difference between two points in a space.
It is defined for a  convex and differentiable function $ \phi: \sS \rightarrow \real $, where $ \sS \subseteq \real^n $ is a convex set. The Bregman distance from point $ \by $ to point $ \bx $ with respect to $ \phi $ is given by:
$$
\mathcalD_{\phi}(\bx,\by) = \phi(\bx) - \phi(\by) - \innerproduct{\nabla \phi(\by), \bx - \by }.
$$
\end{definition}

For brevity, we summarize the key properties of the Bregman distance in the following remark.
\begin{remark}[Properties of Bregman Distance]\label{remark:bregnan_dist}
The definition of the Bregman distance has the following properties:
\begin{enumerate}
\item \textit{Nonnegativity.}
$
\mathcalD_{\phi}(\bx, \by) \geq 0, \text{for all} \quad \bx, \by \in \sS.
$
When $\phi$ is strictly convex, the quality holds if and only if $ \bx = \by $. 

\item \textit{Convexity in the first argument.}
For a fixed $ \by $, $ \mathcalD_{\phi}(\cdot, \by) $ is convex in the first argument. This property is important in optimization algorithms as it ensures that minimizing $ \mathcalD_{\phi}(\bx, \by) $ over $ \bx $ leads to a well-defined problem.

\item \textit{Not symmetric:}
In general, $ \mathcalD_{\phi}(\bx, \by) \neq \mathcalD_{\phi}(\by, \bx) $. Thus, Bregman distances/divergences do not satisfy the symmetry property required for a distance metric. The term \textit{Bregman distance} is used for historical reasons.

\item \textit{Linearity in the gradient.}
If $ \phi $ is a quadratic function, then the Bregman distance simplifies to a scaled version of the squared Euclidean distance. More generally, if $ \phi $ is linear, the Bregman distance becomes zero.

\item \textit{Pythagorean property.}
Suppose $ \sT $ is a nonempty, closed, and convex subset of $ \sS $, and let $ \projectT^{\phi}(\by) $ denote the projection of $ \by $ onto $ \sT $ with respect to $ \mathcalD_{\phi} $ (Definition~\ref{definition:projec_prox_opt}). Then for any $ \bx \in \sT $,
$$
\mathcalD_{\phi}(\bx, \by) = \mathcalD_{\phi}(\bx, \projectT^{\phi}(\by)) + \mathcalD_{\phi}(\projectT^{\phi}(\by), \by)
$$
This property is analogous to the Pythagorean theorem in Euclidean geometry and is useful in proving convergence results for iterative algorithms.

\item \textit{Three-point property.}
Given three points $ \bx, \by, \bz \in \sS $, the following identity holds:
\begin{equation}\label{equation:three_point_breg}
\mathcalD_{\phi}(\bx, \by) + \mathcalD_{\phi}(\by, \bz) = \mathcalD_{\phi}(\bx, \bz) + \langle \nabla \phi(\bz) - \nabla \phi(\by), \bx - \by \rangle
\end{equation}
This can be used to establish bounds on the Bregman distance.

\item \textit{Local behavior.}
When $\bx$ is near $ \by $, $ \mathcalD_{\phi}(\bx, \by) $ behaves like the second-order Taylor expansion of $ \phi $ around $ \by $ (by the quadratic approximation theorem in Theorem~\ref{theorem:quad_app_theo}). Specifically, if $ \phi $ is twice continuously differentiable, then for small $ \normtwo{\bx - \by} $,
$$
\mathcalD_{\phi}(\bx, \by) \approx \frac{1}{2} (\bx - \by)^\top \nabla^2 \phi(\by) (\bx - \by)
$$
where $ \nabla^2 \phi(\by) $ is the Hessian matrix of $ \phi $ at $ \by $.
\end{enumerate}
\end{remark}

The above remark shows that when $\phi(\bx)$ is strictly convex, the equality holds if and only if $\bx=\by$.
Two commonly used examples of strongly convex functions are provided below.
\begin{example}[Bregman with Euclidean and Negative Entropy]\label{example:breg_examp}
Note that when $\phi(\bx)\triangleq\frac{1}{2}\normtwo{\bx}^2: \real^n\rightarrow (-\infty,\infty]$, $\mathcalD_{\phi}(\bx,\by)$ becomes 
$$
\mathcalD_{\phi}(\bx,\by)=\frac{1}{2}\normtwo{\bx-\by}^2,
$$
which is equivalent to the Euclidean distance.
When $\phi(\bx)\triangleq
\begin{cases}
\sum_{i=1}^{n}x_i\ln (x_i)& \bx\in\real^n_+;\\
\infty&\text{otherwise},
\end{cases} 
$, $\mathcalD_{\phi}(\bx,\by)$ becomes 
$$
\begin{aligned}
\mathcalD_{\phi}(\bx,\by)
&=
\sum_{i=1}^{n} x_i \ln(x_i) - \sum_{i=1}^{n} y_i \ln(y_i)
-
\sum_{i=1}^{n} (\ln(y_i+1))(x_i-y_i)\\
&=\sum_{i=1}^{n} x_i\ln(x_i/y_i),
\end{aligned}
$$
which is also known as the \textit{Kullback-Leibler divergence} between nonnegative vectors $\bx$ and $\by$.
\end{example}

Bregman distances find applications in various fields including optimization, machine learning, statistics, and information theory. They are particularly useful in designing algorithms for convex optimization problems because they provide a way to measure progress towards an optimal solution while respecting the geometry induced by the underlying convex function $\phi$. For instance, Bregman distances play a central role in mirror descent methods, which generalize gradient descent to non-Euclidean geometries (Section~\ref{section:mirror}).


Next, we provide  definitions of the projection and proximal operators, and a variant called \textit{Bregman-proximal} operators.
\begin{definition}[Projection, Proximal, Bregman-Proximal Operators]\label{definition:projec_prox_opt}
Given a \textbf{closed} set $\sS\subseteq \real^n$ and a point $\by\in\real^n$, the \textit{(orthogonal) projection} of $\by$, denoted by $\projectS(\by):\real^n\rightarrow \sS$, is defined as 
\begin{equation}\label{equation:projec_def}
\textbf{(Projection)}:\quad 
\widetildeby\triangleq\projectS(\by)
\triangleq
\mathop{\argmin}_{\bx\in\sS} \normtwo{\bx-\by}
=
\mathop{\argmin}_{\bx\in\sS} \normtwo{\bx-\by}^2.
\end{equation}
Given a \textbf{proper} function $f:\real^n\rightarrow (-\infty,\infty]$ and a point $\by\in\real^n$, the \textit{proximal mapping} of $f$, denoted by $\proxf(\by)$, is defined as
\begin{equation}\label{equation:prox_def}
\textbf{(Proximal)}:\quad 
\widehatby \triangleq \proxf(\by) \triangleq 
\mathop{\argmin}_{\bx\in\real^n} \left( f(\bx) + \frac{1}{2}\normtwo{\bx-\by}^2 \right).
\end{equation}
Equipped with the definition of the indicator function $\indicatorS$  (Example~\ref{example:proper_funcs}),  if $\sS$ is nonempty, the definitions of projection and proximal operators shows that 
\begin{equation}\label{equation:equi_proj_prox}
\prox_{\indicatorS}(\by) = \projectS(\by)\quad \text{for all }\by\in\sS.
\end{equation}
If we use the Bregman distance (Definition~\ref{definition:breg_dist}) instead of the Euclidean distance in \eqref{equation:prox_def}, we have the \textit{Bregman-proximal mapping}, denoted by $\bprox_f(\by)$, as 
\begin{equation}\label{equation:bregprox_def}
\textbf{(Bregman)}:\qquad 
\widebarby \triangleq \bproxfphi(\by) \triangleq 
\mathop{\argmin}_{\bx\in\real^n} \big( f(\bx) + \mathcalD_\phi(\bx, \by) \big),
\end{equation}
where $\phi:\real^n\rightarrow (-\infty,\infty]$ is a proper \textbf{convex} function due to the definition of the Bregman distance (Definition~\ref{definition:breg_dist}). By Example~\ref{example:breg_examp}, 
$$
\bproxfphi(\by) \equiv \proxf(\by)
\quad 
\text{if $\phi(\bx)=\frac{1}{2}\normtwo{\bx}^2$}.
$$
\end{definition}

Unless otherwise stated, we only consider closed sets for projection operators and proper functions for proximal operators.
The following example provides an informal explanation for this restriction.
\begin{example}[Counterexample for Non-Closed $\sS$ and Non-Proper Functions]\label{example:non_clo_proj}
Consider the open set $\sS = \{x \in \real : x > 0\}$ and let $y = 0$. The projection problem then becomes:
$
\widehat{y} = \arg\min_{x > 0} x^2.
$
\begin{itemize}
\item The infimum of $x^2$ is $0$, but $x = 0$ is not in $\sS$. Thus, there is no point in $\sS$ achieving the infimum.
\item Any sequence $\{x_t\}_{t>0} \subset \sS$ with $x_t \rightarrow 0$ minimizes $x^2$, but the ``solution" is not unique since it depends on the sequence chosen.
\end{itemize}
Therefore, projection operators are not well-defined for non-closed sets. Similarly, for non-proper functions, the proximal operator is also not well-defined.
\end{example}



\subsection{Properties of Projection Operators}
We introduce some key properties of projection   operators.
\begin{lemma}[Projection Property-O]\label{lemma:proj_prop0}
Let $\sS\subseteq \real^n$ be \textbf{any closed set}, and let $\by\in\real^n$ such that $\widetildeby\triangleq\projectS(\by)$ is the projection of $\by$ onto the set $\sS$. Then, for all $\bx\in\sS$, we have $\normtwo{\widetildeby - \by}\leq \normtwo{\bx-\by}$.

\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:proj_prop0}]
This proof follows by simply observing that the projection step solves the the optimization
problem $\projectS(\by)=\mathop{\argmin}_{\bx\in\sS} \normtwo{\bx-\by}^2$. 
\end{proof}





Note that the inequality in Projection Property-O holds for all closed sets, whether convex or not.
However, the following three properties necessarily hold only for convex sets.
\begin{lemma}[Projection Property-I]\label{lemma:proj_prop1}
Let $\sS\subseteq \real^n$ be a closed \textbf{convex set}, and let $\by\in\real^n$ such that $\widetildeby\triangleq\projectS(\by)$. Then, for all $\bx\in\sS$, we have $\innerproduct{\bx-\widetildeby, \by-\widetildeby}\leq 0$, i.e., the angle between the two vectors is greater than or equal to 90\textdegree.
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:proj_prop1}]
Assume for contradiction that $\innerproduct{\bx-\widetildeby, \by-\widetildeby}> 0$ for some $\bx\in\sS$. 
Since $\sS$ is convex and $\widetildeby, \bx \in \sS$, for any $\lambda \in [0, 1]$, we have
$
\bxi_{\lambda} \triangleq \lambda \cdot \bx + (1 - \lambda) \cdot \widetildeby \in \sS.
$
We will now show that  there exists a value of  $\lambda \in [0, 1]$ such that $\normtwo{\by - \bxi_{\lambda}}^2 < \normtwo{\by - \widetildeby}^2$, which contradicts the fact that $\widetildeby$ is the closest point in the convex set to $\by$ and prove the lemma. 
To see this, let $\lambda_1\triangleq\frac{2\innerproduct{\bx - \widetildeby, \by - \widetildeby}}{\normtwo{\bx - \widetildeby}^2}$ for the moment. We have 
$$
\normtwo{\by-\bxi_{\lambda_1}}^2
= 
\normtwo{\by-\widetildeby}^2 - 2\lambda_1 \innerproduct{\bx-\widetildeby, \by-\widetildeby} + \lambda_1^2 \normtwo{\bx-\widetildeby}^2
=\normtwo{\by-\widetildeby}^2.
$$
Let $g(\lambda) \triangleq \normtwo{\by-\widetildeby}^2 - 2\lambda \innerproduct{\bx-\widetildeby, \by-\widetildeby} + \lambda^2 \normtwo{\bx-\widetildeby}^2$. It can be shown that $\lambda=\lambda_1$ does not obtain the minimum of $g(\lambda)$ by the property of quadratic function.
Since we assumed $\langle \bx - \widetildeby, \by - \widetildeby \rangle > 0$,
letting $0 < \lambda < \min\left\{1, \frac{2\innerproduct{\bx - \widetildeby, \by - \widetildeby}}{\normtwo{\bx - \widetildeby}^2}\right\}$, we have $\normtwo{\by - \bxi_{\lambda}}^2 < \normtwo{\by - \widetildeby}^2$. This contradict the property of projection operators, and completes the proof.
\end{proof}


\begin{lemma}[Projection Property-II]\label{lemma:proj_prop2}
Let $\sS\subseteq \real^n$ be a closed  \textbf{convex set}, and let $\by\in\real^n$ such that $\widetildeby\triangleq\projectS(\by)$. Then, for all $\bx\in\sS$, we have $\normtwo{\widetildeby - \bx}^2\leq \normtwo{\by-\bx}^2 - \normtwo{\by-\widetildeby}^2$, which also implies $\normtwo{\widetildeby - \bx} \leq \normtwo{\by-\bx}$ (the former property is related to the Pythagorean theorem).
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:proj_prop2}]
We have the following elementary inequalities
$$
\begin{aligned}
\normtwo{\by-\bx}^{2} &= \normtwo{(\widetildeby-\bx)-(\widetildeby-\by)}^{2} 
= \normtwo{\widetildeby-\bx}^{2} + \normtwo{\widetildeby-\by}^{2} - 2\langle\widetildeby-\bx, \widetildeby-\by\rangle \\
&\stackrel{\dag}{\geq} \normtwo{\widetildeby-\bx}^{2} + \normtwo{\widetildeby-\by}^{2}
\geq \normtwo{\widetildeby-\bx}^{2},
\end{aligned}
$$
where inequality ($\dag$) follows from the Projection Property-I.
\end{proof}



\begin{lemma}[Projection Property-III]\label{lemma:proj_prop3}
Let $\sS\subseteq \real^n$ be a closed  \textbf{convex set}, and let $\by\in\real^n$. Then, $\projectS(\by)
\triangleq
\mathop{\argmin}_{\bx\in\sS} \normtwo{\bx-\by}^2$ has a \textbf{unique} optimal solution.
\end{lemma}
\begin{proof}[Lemma~\ref{lemma:proj_prop3}]
Since  the  objective function in $\projectS(\by)
\triangleq
\mathop{\argmin}_{\bx\in\sS} \normtwo{\bx-\by}^2$ is a quadratic function associated with a positive definite
matrix, it follows by Exercise~\ref{exercise:coerci_quad} that the objective function is coercive and hence, by Theorem~\ref{theorem:att_coer}, that the problem has at least one optimal solution. In addition, since the
objective function is strictly convex (again, since the objective function is quadratic associated with a
positive definite matrix), it follows by Theorem~\ref{theorem:stric_op_str_conv} that there exists only one optimal
solution.
\end{proof}

\paragraph{Convex set.} Note that Projection Properties-I, II, and III are also called first-order properties and can be violated if the underlying set is non-convex. However, Projection Property-O, often called a zeroth-order property, always holds regardless of whether the underlying set is convex or not; see Figure~\ref{fig:proj_prop}.

\begin{figure}[h]
\centering       
\vspace{-0.25cm}                 
\subfigtopskip=2pt               
\subfigbottomskip=-2pt         
\subfigcapskip=-10pt      
\includegraphics[width=0.98\textwidth]{imgs/proj_prop.pdf}
\caption{
Projection operators identify the closest point within a set to a given point outside the set. For convex sets, Projection Property-I guarantees that the angle $\theta$ formed between the line segment connecting the original point to its projection and any line segment from the projection to another point in the set is never acute. Sets that adhere to Projection Property-I also comply with Projection Property-II, which asserts that projecting onto these sets will not increase the distance between the projected point $\by$ and any other point within the set.
However, non-convex sets may violate Projection Property-II. 
}
\label{fig:proj_prop}
\end{figure}

\begin{example}[Projection onto Subsets of $\real^n$]
Below are examples of nonempty closed and convex sets along with their corresponding orthogonal projections:
\begin{enumerate}[(i)]
\item \textbf{Nonnegative orthant $\sS_1 = \real^n_+$}: $\project_{\sS_1}(\by) = \{\max\{y_i, 0\}\}_{i=1}^n$.
\item \textbf{Box $\sS_2 = \text{Box}[\bl, \bu]\triangleq\{\bx\in\real^n\mid \bl\leq \bx\leq \bu\}$}: $\project_{\sS_2}(\by) = \left\{\min(\max(y_i, l_i), u_i)\right\}_{i=1}^n$.
\item \textbf{Closed $\ell_2$ Ball $\sS_3 = \sB_2[\ba, \alpha]$}: $\project_{\sS_3}(\by)=\ba + \frac{\alpha}{\max\{\normtwo{\by - \ba}, \alpha\}}(\by - \ba)$.
\item \textbf{Half-space $\sS_4 = \{\bx\mid \bc^\top \bx \leq \beta\}$}: $\project_{\sS_4}(\by)=\by - \frac{\max\{\bc^\top \by - \beta, 0\}}{\normtwo{\bc}^2}\bc$.
\item \textbf{Affine set $\sS_5 = \{\bx \in \real^n \mid \bA\bx = \bb\}$}: $\project_{\sS_5}(\by) = \by - \bA^\top(\bA\bA^\top)^{-1}(\bA\by - \bb)$.
\end{enumerate}
where $\bl \in  [-\infty, \infty)^n, \bu \in (-\infty, \infty]^n$ satisfying $\bl \leq \bu$, $\ba \in \real^n$, $\alpha > 0$, $\bc \in \real^n \setminus \{\bzero\}$,  $\beta \in \real$, $\bA \in \real^{m \times n}$ has full row rank such that $\bA\bA^\top$ is nonsingular, and $\bb \in \real^m$.
The results in (i)--(iv) holds trivially. 
For (v),
it's equivalent to solving  the following optimization problem:
$$
\min_{\bx \in \real^n} \quad \frac{1}{2} \normtwo{ \bx - \by}^2 \quad\text{s.t.}\quad\bA\bx = \bb,
$$
where $\bA \in \real^{m \times n}$, $\bb \in \real^m$ and $\by \in \real^n$ are given matrices and vectors. 
We will use the result of KKT conditions to prove this (Section~\ref{section:gen_kkt_cond}); feel free to skip for a first reading.
We assume that the matrix $\bA$ has full row rank (for matrices that do not have full row rank, we can remove linearly dependent rows to obtain a reduced constraint condition). 
For the equality constraint, we introduce the Lagrange multiplier $\blambda \in \real^m$ and construct the Lagrangian function
$$
L(\bx, \blambda) = \frac{1}{2} \normtwo{\bx - \by}^2 + \blambda^\top(\bA\bx - \bb).
$$
Since the quadratic function is a convex function and there is only an equality constraint, the Slater's condition is satisfied. Theorem~\ref{theorem:kktslat1_slater} shows that $\bx^*$ is a global optimum if and only if there exists $\blambda^* \in \real^m$ such that
$
\begin{cases}
\bx^* - \by + \bA^\top\blambda = \bzero, \\
\bA\bx^* = \bb.
\end{cases}
$
This yields that 
$$
\bA \bx^* - \bA \by + \bA\bA^\top\blambda = \bzero
\qquad \implies\qquad 
\blambda = (\bA\bA^\top)^{-1}(\bA\by - \bb).
$$
Substituting $\blambda$ back into the first KKT condition obtains the desired result.
\end{example}



\subsection{Properties of Proximal Operators}
Analogously, for the proximal operator, if we require the function to be closed, it can be shown under some coerciveness assumptions (Definition~\ref{definition:coerciveness}) that $\proxf(\by)$ is never an empty set.
\begin{lemma}[Proximal Property-O: Nonemptiness of  Prox under Closedness and Coerciveness]\label{lemma:prox_prop0}
Let $f: \real^n \rightarrow (-\infty, \infty]$ be a proper \textbf{closed} function, and assume that the following condition holds:
$$
\text{the function } \bx \mapsto f(\bx) + \frac{1}{2} \normtwo{\bx - \by}^2 \text{ is coercive for any } \by \in \real^n. 
$$
Then $\proxf(\by)$ is \textbf{nonempty} for any $\by \in \real^n$.
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:prox_prop0}]
For any $\bx \in \real$, the proper function $g(\bx) \triangleq f(\bx) + \frac{1}{2} \normtwo{\bx - \by}^2$ is closed as a sum of two closed functions. 
Since by assumption it is also coercive, Theorem~\ref{theorem:att_coer} (which requires the function to be proper closed and coercive) ensures that $\proxf(\by)$, which consists of the minimizers of $g$, is nonempty.
\end{proof}


\begin{lemma}[Proximal Property-I]\label{lemma:prox_prop1}
Let $ f: \real^n \rightarrow (-\infty, \infty] $ be a proper \textbf{closed and convex} function. Then for any $ \by, \widehatby \in \real^n $, the following three claims are equivalent:
\begin{enumerate}[(i)]
\item $ \widehatby = \proxf(\by) $.
\item $ \by - \widehatby \in \partial f(\widehatby) $.
\item $ \innerproduct{\by - \widehatby, \bz - \widehatby} \leq f(\bz) - f(\widehatby) $ for any $ \bz \in \real^n $.
\end{enumerate}
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:prox_prop1}]
By definition, $ \widehatby = \proxf(\by) $ if and only if $ \widehatby $ is the minimizer of the problem
$
\mathopmin{\bv} \left\{ f(\bv) + \frac{1}{2} \normtwo{\bv - \by}^2 \right\},
$
which, by the optimality condition (Theorem~\ref{theorem:fetmat_opt}) and the sum rule of subdifferential calculus, is equivalent to the relation
$
\bzero \in \partial f(\widehatby) + \widehatby - \by. 
$
This shows the equivalence between claims (i) and (ii). Finally, by the definition of the subgradient (Definition~\ref{definition:subgrad}), the membership relation of claim (ii) is equivalent to (iii).
\end{proof}

When $ f = \indicatorS $, with $ \sS $ being a nonempty closed and convex set, the equivalence between claims (i) and (iii) in the Proximal Property-I amounts to the Projection Property-I (Lemma~\ref{lemma:proj_prop1}).



To maintain consistency, we also introduce the Proximal Property-II, though it's not so that interesting in practice.
\begin{lemma}[Proximal Property-II]\label{lemma:prox_prop2}
Let $ f: \real^n \rightarrow (-\infty, \infty] $ be a proper \textbf{closed and convex} function. Then for any $ \widehatby \triangleq \proxf(\by) $ and $\bz\in\real^n$, it follows that
$
\normtwo{\by-\bz} \geq \normtwo{\widehatby-\bz}^2 + \normtwo{\widehatby-\by}^2 + 2\left( f(\widehatby) - f(\bz) \right).
$
%If $\by$ is a minimizer of $f$, we have $\by=\widehatby$ (Theorem~\ref{theorem:opt_cond_prox}), then we also obtain the Pythagorean theorem.
\end{lemma}


\begin{lemma}[Proximal Property-III]\label{lemma:prox_prop3}
Let $f: \real^n \rightarrow (-\infty, \infty]$ be a proper \textbf{closed and convex} function. Then $\proxf(\by)$ is a \textbf{singleton} for any $\by \in \real^n$.
\end{lemma}

\begin{proof}[of Lemma~\ref{lemma:prox_prop3}]
For any $\bx \in \real^n$,
\begin{equation}\label{equation:prox_prop0_e1}
\proxf(\by) = \arg\min_{\bx \in \real^n} g(\by;\bx) ,
\end{equation}
where $g(\by;\bx) = f(\bx) + \frac{1}{2}\normtwo{\bx - \by}^2$. The function $g(\by;\bx)$ is a closed and strongly convex function as a sum of the closed and strongly convex function $\frac{1}{2}\normtwo{\bx - \by}^2$ and the closed and convex function $f$ (Exercise~\ref{exercise:sum_sc_conv} and Exercise~\ref{exercise:pres_conv_clos}). The properness of $g(\by;\bx)$ immediately follows from the properness of $f$. Therefore, by the SC Property-II (Theorem~\ref{theorem:exi_close_sc}), there exists a unique minimizer to the problem in \eqref{equation:prox_prop0_e1}.
\end{proof}
The Proximal Property-III also proves the Projection Property-III (Lemma~\ref{lemma:proj_prop3}) by noting that $\prox_{\indicatorS}(\by) = \projectS(\by)$ for any $\by\in\sS$ if $\sS$ is convex and closed (the indicator function is closed convex due to Exercise~\ref{exercise_closed_indica}).

When $f$ is proper closed and convex, the preceding lemma shows that $\proxf(\by)$ is a singleton for any $\by \in \real^n$. In these cases, which will constitute the vast majority of cases that will be discussed in this book, we will treat $\proxf$ as a single-valued mapping from $\real^n$ to $\real^n$, meaning that we will write $\proxf(\by) = \widehatby$ instead of $\proxf(\by) = \{\widehatby\}$.



\paragraph{Convexity and Closedness.} Note again  that Proximal Properties-I, II, and III are also called first-order properties and can be violated if the underlying function is non-convex. However, Projection Property-O, often called a zeroth-order property, always holds, whether the underlying function is convex or not.
In all cases, we require the function to be closed to ensure the attainment due to the Weierstrass theorem (Theorem~\ref{theorem:weierstrass_them}) or Theorem~\ref{theorem:att_coer}.

\begin{theorem}[Projection and Proximal Property-IV: Nonexpansiveness]\label{theorem:proj_nonexpan}
Let $\sS\subseteq \real^n$ be a closed \textbf{convex set}, and let $f:\real^n\rightarrow (-\infty, \infty]$ be a proper \textbf{closed and convex} function. Then, 
\begin{enumerate}
\item \textit{Firm nonexpansiveness.} For any $\bx, \by\in\real^n$, it follows that 
$$
\begin{aligned}
\normtwo{\projectS(\bx)-\projectS(\by)}^2 &\leq \innerproduct{\projectS(\bx)-\projectS(\by), \bx-\by};\\
\normtwo{\proxf(\bx)-\proxf(\by)}^2 &\leq \innerproduct{ \proxf(\bx)-\proxf(\by), \bx-\by}.
\end{aligned}
$$
\item \textit{Nonexpansiveness.} For any $\bx, \by\in\real^n$, it follows that 
$$
\begin{aligned}
\normtwo{\projectS(\bx)-\projectS(\by)} &\leq \normtwo{\bx-\by};\\
\normtwo{\proxf(\bx)-\proxf(\by)}&\leq \normtwo{\bx-\by}.
\end{aligned}
$$
\end{enumerate} 
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:proj_nonexpan}]
\textbf{Projection operator.} By the Projection Property-I (Lemma~\ref{lemma:proj_prop1}),  for any $\bu \in \real^n$ and $\bv \in \sS$, we have that
$
\innerproduct{ \bv - \projectS(\bu), \bu - \projectS(\bu)} \leq 0. 
$
Invoking this inequality with $\bu \triangleq \bx, \bv \triangleq \projectS(\by)$ and $\bu \triangleq \by, \bv \triangleq \projectS(\bx)$:
$$
\begin{aligned}
\innerproduct{\projectS(\by) - \projectS(\bx), \bx - \projectS(\bx)} &\leq 0 
\qquad\text{and}\qquad
\innerproduct{\projectS(\bx) - \projectS(\by), \by - \projectS(\by)} &\leq 0. 
\end{aligned}
$$
Adding the two inequalities yields that
$
\innerproduct{\projectS(\by) - \projectS(\bx),  \bx - \by + \projectS(\by) - \projectS(\bx)} \leq 0,
$
showing the firm nonexpansiveness of projection operators.

To prove the nonexpansiveness, note that if $\projectS(\bx) = \projectS(\by)$, the inequality  holds trivially. We will therefore assume that $\projectS(\bx) \neq \projectS(\by)$. By the Cauchy-Schwarz inequality we have
$$
\innerproduct{\projectS(\bx) - \projectS(\by),  \bx - \by} \leq \normtwo{\projectS(\bx) - \projectS(\by)} \cdot \normtwo{\bx - \by},
$$
which combined with the firm nonexpansivess yields the desired result.

\paragraph{Proximal operator.} Denoting $ \bu \triangleq \proxf(\bx) $, $ \bv \triangleq \proxf(\by) $, by the equivalence of (i) and (ii) in the Proximal Property-I (Lemma~\ref{lemma:prox_prop1}), it follows that
$$
\bx - \bu \in \partial f(\bu)
\qquad \text{and}\qquad  
\by - \bv \in \partial f(\bv).
$$
By the subgradient inequality, we have
$$
f(\bv) \geq f(\bu) + \langle \bx - \bu, \bv - \bu \rangle
\qquad \text{and}\qquad  
f(\bu) \geq f(\bv) + \langle \by - \bv, \bu - \bv \rangle.
$$
Adding the two inequalities yields that
$
0 \geq \innerproduct{\by - \bx + \bu - \bv, \bu - \bv},
$
showing the firm nonexpansiveness of proximal operators.

To prove the nonexpansiveness, if $ \proxf(\bx) = \proxf(\by) $, then the inequality is trivial. Therefore, we assume that $ \proxf(\bx) \neq \proxf(\by) $. By the Cauchy-Schwarz inequality, it follows that
$$
\innerproduct{\proxf(\bx) - \proxf(\by), \bx - \by} \leq \normtwo{\proxf(\bx) - \proxf(\by)} \cdot \normtwo{\bx - \by}.
$$
which combined with the firm nonexpansivess yields the desired result.
\end{proof}
Note that the (firm) nonexpansiveness of projection operators can be  directly inferred from the properties of proximal operators by setting $f\triangleq\indicatorS$.



\begin{example}[Soft Thresholding, Proximal of $\ell_1$ Norms]\label{example:soft_thres}
Let  $f(\bx) = \lambda \normone{\bx} =\sum_{i=1}^{n} \psi(x_i)$, where $\bx\in\real^n$, $\lambda > 0$, and $\psi(u) = \lambda |u|$. 
Then $
\proxf(\bx) = \big\{\prox_{\psi}(x_i)\big\}_{i=1}^n,
$
where $\prox_{\psi}(y) = \mathcalT_{\lambda}(y)$, and  $\mathcalT_{\lambda}$ is known as the \textit{soft thresholding function} and is defined as
$$
\mathcalT_{\lambda}(y) \triangleq
[\abs{y} - \lambda]_+ \cdot \sign(y)=
\begin{cases}
	y - \lambda, & y \geq \lambda, \\
	0, & |y| < \lambda, \\
	y + \lambda, & y \leq -\lambda.
\end{cases}
$$
where $[u]_+ = \max\{u, 0\}$ for any $u\in\real$. See Figure~\ref{fig:soft_threshold} for an illustration of this soft thresholding function.
More compactly, the proximal operation of $f$ can be denoted as 
$$
\prox_f(\bx) = \mathcalT_\lambda(\bx) = \left\{\mathcalT_\lambda(x_i)\right\}_{i=1}^n 
= [\abs{\bx} - \lambda \bone]_+ \hadaprod \sign(\bx),
$$
where $\hadaprod$ denotes the Hadamard product and $\bone$ denotes a vector of all ones.
\end{example}
\begin{SCfigure}%[h]
	\centering
	\includegraphics[width=0.55\textwidth]{./imgs/soft_threshold.pdf} 
	\caption{Illustration of the soft thresholding function $\mathcalT_{\lambda}(y)$ for different values of $\lambda$.}
	\label{fig:soft_threshold}
\end{SCfigure}
\subsection{Properties of Bregman-Proximal Operators}

The zeroth-order property of the Bregman-proximal operator  indicates the unique attainment of a sum of two functions, which is essential for other Bregman-proximal properties.
\begin{lemma}[Bregman-Proximal Property-O: Attainment]\label{lemma:breg_prox_propo}
Let
\begin{itemize}
\item $\phi : \real^n \to (-\infty, \infty]$ be a proper \textbf{closed and convex} function differentiable over $\dom(\partial \phi)$.
\item $f : \real^n \to (-\infty, \infty]$ be a proper \textbf{closed and convex} function satisfying $\dom(f) \subseteq \dom(\phi)$.
\item $\phi + \delta_{\dom(f)}$ be $\sigma$-strongly convex ($\sigma > 0$).
\end{itemize}
\noindent
Then the minimizer of the problem
\begin{equation}\label{equation:breg_prox_propoe1}
\min_{\bx \in \real^n} \{f(\bx) + \phi(\bx)\}
\end{equation}
is \textbf{uniquely} attained at a point in $\dom(f) \cap \dom(\partial \phi)$.
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:breg_prox_propo}]
Problem \eqref{equation:breg_prox_propoe1} is the same as
\begin{equation}\label{equation:breg_prox_propoe2}
\min_{\bx \in \real^n} \omega(\bx), \quad \text{where $\omega \triangleq f + \phi$}.
\end{equation}
The function $\omega$ is closed since both $f$ and $\phi$ are closed (Exercise~\ref{exercise:pres_conv_clos}); it is proper by the fact that $\dom(\omega) = \dom(f) \neq \emptyset$. Since $\phi + \delta_{\dom(f)}$ is $\sigma$-strongly convex and $f$ is convex, their sum $f + \phi + \delta_{\dom(f)} = f + \phi = \omega$ is $\sigma$-strongly convex. To conclude, $\omega$ is proper closed and $\sigma$-strongly convex, and hence, by the SC Property-II (Theorem~\ref{theorem:exi_close_sc}), problem \eqref{equation:breg_prox_propoe2} has a unique minimizer $\bx^*$ in $\dom(\omega) = \dom(f)$. To show that $\bx^* \in \dom(\partial \phi)$, note that by first-order condition of convex optimization problem  (Theorem~\ref{theorem:fetmat_opt}), $\bzero \in \partial \omega(\bx^*)$, and in particular $\partial \omega(\bx^*) \neq \emptyset$. Therefore,  by the sum rule of subdifferential calculus, $\partial \omega(\bx^*) = \partial f(\bx^*) + \partial \phi(\bx^*)$, it follows in particular that $\partial \phi(\bx^*) \neq \emptyset$, meaning that $\bx^* \in \dom(\partial \phi)$.
\end{proof}

For the Bregman-proximal operator, we have a similar property as Lemma~\ref{lemma:prox_prop1} for the proximal operator.
\begin{lemma}[Bregman-Proximal Property-I]\label{lemma:breg_prox_prop1}
Let 
\begin{itemize}
\item $\phi : \real^n \to (-\infty, \infty]$ be a proper \textbf{closed and convex} function differentiable over $\dom(\partial \phi)$;
\item $f : \real^n \to (-\infty, \infty]$ be a proper \textbf{closed and convex} function satisfying $\dom(f) \subseteq \dom(\phi)$;
\item $\phi + \delta_{\dom(f)}$ be $\sigma$-strongly convex ($\sigma > 0$).
\end{itemize}
\noindent Then for any $ \by, \widehatby \in \dom(\partial \phi) $, the following two claims are equivalent:
\begin{enumerate}[(i)]
\item $ \widebarby = \bproxfphi(\by) \triangleq \mathop{\argmin}_{\bx \in \real^n} \left\{ f(\bx) + \mathcalD_\phi(\bx, \by) \right\}$ .
\item $ \innerproduct{\nabla \phi(\by) - \nabla \phi(\widebarby), \bz - \widebarby} \leq f(\bz) - f(\widebarby)$ for any $ \bz \in \dom(f) $.
\end{enumerate}
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:breg_prox_prop1}]
By the definition of the Bregman distance (Definition~\ref{definition:breg_dist}), $\widebarby = \bproxfphi(\by)$ can be rewritten as
\begin{equation}
\widebarby = \mathop{\argmin}_{\bx \in \real^n} \left\{ f(\bx) - \innerproduct{\nabla \phi(\by), \bx} + \phi(\bx) \right\}.
\end{equation}
The fact that $\widebarby \in \dom(\partial \phi)$ follows by invoking Lemma~\ref{lemma:breg_prox_propo} with $f(\bx) - \innerproduct{\nabla \phi(\by), \bx}$ taking the role of $f(\bx)$. Using the first-order condition of convex optimization problems (Theorem~\ref{theorem:fetmat_opt}), it follows by $\widebarby = \bproxfphi(\by)$ that there exists $f'(\widebarby) \in \partial f(\widebarby)$ for which
$
f'(\widebarby) + \nabla \phi(\widebarby) - \nabla \phi(\by) = \bzero.
$
Hence, by the subgradient inequality (Definition~\ref{definition:subgrad}), for any $\bz \in \dom(f)$,
$$
\innerproduct{\nabla \phi(\by) - \nabla \phi(\widebarby), \bz - \widebarby} = \innerproduct{f'(\widebarby), \bz - \widebarby} \leq f(\bz) - f(\widebarby),
$$
which completes the proof.
\end{proof}

\subsection{Separation Theorems}
The following strict separation theorem, derived from the properties of projection operators, is important for proving  Farkas' lemma (Lemma~\ref{lemma:farka_lemm}), which in turn is crucial for proving KKT conditions.
\begin{theorem}[Strict Separation Theorem]\label{theorem:stric_sep_theo}
Let $\sS \subseteq \real^n$ be a closed \textbf{convex} set, and let $\by \notin \sS$. Then there exist $\bw \in \real^n \setminus \{\bzero\}$ and $\alpha \in \real$ such that
$$
\bw^\top \by > \alpha
\qquad\text{and}\qquad
\bw^\top \bx \leq \alpha, \quad \text{for all } \bx \in \sS.
$$
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:stric_sep_theo}]
Let $\widetildeby \triangleq \projectS(\by) \in \sS$. By the Projection Property-I (Lemma~\ref{lemma:proj_prop1}), 
$$
\innerproduct{\bx - \widetildeby, \by - \widetildeby} \leq 0
\quad\implies\quad (\by - \widetildeby)^\top \bx \leq (\by - \widetildeby)^\top \widetildeby
,\quad  \text{for all } \bx \in \sS.
$$
Denote $\bw \triangleq \by - \widetildeby \neq \bzero$ (since $\by \notin \sS$) and $\alpha \triangleq (\by - \widetildeby)^\top \widetildeby$. Then we have that $\bw^\top \bx \leq \alpha$ for all $\bx \in \sS$. On the other hand,
$$
\bw^\top \by = (\by - \widetildeby)^\top \by = (\by - \widetildeby)^\top (\by - \widetildeby) + (\by - \widetildeby)^\top \widetildeby =\normtwo{\by - \widetildeby}^2 + \alpha > \alpha,
$$
establishing the desired result.
\end{proof}

More generally, we have the following separation theorem.
\begin{theorem}[General Separation Theorem]\label{theorem:stric_sep_theo2}
Let $\sS, \sT \subseteq \real^n$ be \textbf{convex} sets with empty intersection $\sS \cap \sT = \varnothing$. Then there exists a point $\ba \in \real^n$ and a number $\beta \in \real$ such that
\begin{enumerate}[(i)]
\item For all $\bx \in \sS$, we have $\innerproduct{\ba, \bx} \geq \beta$.
\item For all $\bx \in \sT$, we have $\innerproduct{\ba, \bx} \leq \beta$.
\end{enumerate}
If $\sS$ and $\sT$ are closed and at least one of them is bounded, then we can replace the inequalities by strict inequalities.
\end{theorem}


The case we're most concerned with is when both sets are compact (i.e., closed and bounded). We highlight its proof here.
\begin{proof}[of Theorem~\ref{theorem:stric_sep_theo2} for Compact Sets]
In this case, the Cartesian product $\sS \times \sT$ is also compact. Therefore, the distance function $\normtwo{\bx - \by}$ attains its minimum over $\sS \times \sT$ (Theorem~\ref{theorem:weierstrass_them}). Taking $\bu, \bv$ to be two points that achieve the minimum. A separating hyperplane is given by the hyperplane perpendicular to $\bv - \bu$ that passes through the midpoint between $\bu$ and $\bv$. That is, $\ba = \bv - \bu$ and $\beta =\frac{-\innerproduct{\ba, \bv+\bu}}{2}$ (use the result of Problem~\ref{prob:dist_hyper} to prove this). 
For the sake of contradiction, suppose there is a point $\bz$ on this hyperplane contained in one of the two sets, say, $\sS$. Then the line segment from $\bu$ to $\bz$ is also contained in $\sS$ by convexity. We can then find a point along the line segment that is closer to $\bv$ than $\bu$ is, thus contradicting our assumption.
\end{proof}


\begin{theorem}[Supporting Hyperplane Theorem]\label{theorem:supp_hyp_theo}
Let $\sS \subseteq \real^n$ be a \textbf{convex} set (not necessarily closed) and let $\by \notin \sS$. Then there exists $\bzero \neq \bw \in \real^n$ such that
$$
\bw^\top \bx \leq \bw^\top \by, \quad  \text{ for any } \bx \in \sS.
$$
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:supp_hyp_theo}]
Since the set is not closed, we cannot apply the properties of projection operators directly; however, we can apply these properties to the closure $\closure(\sS)$.
Since $\by \notin \interior(\sS)$, it follows that $\by \notin \interior(\closure(\sS))$ (by Exercise~\ref{exercise:int_clos}, $\interior(\sS) = \interior(\closure(\sS))$). Therefore, there exists a sequence $\{\by^\toptzero\}_{t \geq 1}$ satisfying $\by^\toptzero \notin \closure(\sS)$ such that $\by^\toptzero \rightarrow \by$. Since $\closure(\sS)$ is convex by Exercise~\ref{exercise:clo_conv} and closed by its definition, it follows by the strict separation theorem (Theorem~\ref{theorem:stric_sep_theo}) that there exists $\bzero \neq \bw^\toptzero \in \real^n$ such that
$$
(\bw^\toptzero)^\top \bx < (\bw^\toptzero)^\top \by^\toptzero,\quad \text{for all } \bx \in \closure(\sS), \text{ where } \by^\toptzero \notin \closure(\sS).
$$
Dividing the  inequality by $\normtwo{\bw^\toptzero} \neq \bzero$, we obtain
\begin{equation}\label{equation:supp_eq1}
\frac{(\bw^\toptzero)^\top}{\normtwo{\bw^\toptzero}}(\bx - \by^\toptzero) < 0,\quad \text{ for any } \bx \in \closure(\sS), \text{ where } \by^\toptzero \notin \closure(\sS).
\end{equation}
Since the sequence $\left\{\frac{\bw^\toptzero}{\normtwo{\bw^\toptzero}}\right\}_{t \geq 1}$ is bounded, it follows that there exists a subsequence $\left\{\frac{\bw^\toptzero}{\normtwo{\bw^\toptzero}}\right\}_{t \in \sT}$ indexed by $\sT$ such that $\frac{\bw^\toptzero}{\normtwo{\bw^\toptzero}} \rightarrow \bw$ as $t \rightarrow \infty$ for some $\bw \in \real^n$. Obviously, $\normtwo{\bw} = 1$ and hence in particular $\bw \neq \bzero$. Taking the limit as $t \rightarrow \infty$ in inequality \eqref{equation:supp_eq1}, we obtain that
$$
\bw^\top(\bx - \by) \leq 0, \quad  \text{ for any } \bx \in \closure(\sS),
$$
which completes the proof since $\sS \subseteq \closure(\sS)$.
\end{proof}



\section{Optimization and Optimality Conditions}


Optimization holds a pivotal role across various scientific disciplines and practical applications, including economics, operations research, network analysis, and the optimal design of mechanical or electrical systems, among others.
In this book, we will explore numerical methods designed to solve continuous optimization problems. In these problems, the objective is formulated as a real-valued function of multiple variables, with the goal of identifying the set of input values that yields the minimum possible function value. Such optimization challenges often emerge from parameter estimation tasks, including data fitting as a specific application.
\begin{definition}[Optimization Problem]\label{definition:opt_probs_all}
Let $f: \real^n \rightarrow \real$, the \textit{unconstrained optimization problem} is defined as
$$
\textbf{(P1)}:\qquad \text{Find}\quad \bx^* = \mathop{\argmin}_{\bx} f(\bx).
$$
For finding the minimum over a set $\sS$, the \textit{constrained optimization problem} becomes
$$
\textbf{(P2)}:\qquad \text{Find}\quad \bx^* = \mathop{\argmin}_{\bx} f(\bx)\quad \text{s.t.}\quad\bx\in\sS.
$$
Similarly, we may also want to find the minimum point of a composite function:
$$
\textbf{(P3)}:\qquad \text{Find}\quad \bx^* = \mathop{\argmin}_{\bx} \left\{F(\bx)\triangleq f(\bx)+g(\bx) \right\},
$$
where $f$ possesses some differentiability properties (e.g., smoothness) but is not assumed to be convex, while $g$ is convex but may lack special differentiability properties.
When the $\sS$ in the problem (P2) has the following form, we deal with the constrained optimization problem with equality and inequality constraints:
$$
\begin{aligned}
\textbf{(P4)}:\qquad \text{Find}\quad 
&\bx^* &=& \mathop{\argmin}_{\bx} f(\bx) \\
&\text{s.t.}  &c_i&(\bx)=0, \,\,i\in\mathcalE, \,\,\text{with $\abs{\mathcalE}=p$};\\
&  &c_i&(\bx)\leq 0, \,\,i\in\mathcalI, \,\,\text{with $\abs{\mathcalI}=q$}.\\
\end{aligned}
$$
Since we focus on minimization, we assume in all cases, unless otherwise stated, that the underlying  function is proper (Definition~\ref{definition:extrel_pro_clo_funcs}).
\end{definition}
In some cases we want a maximizer of a function. This is easily determined if we find a minimizer of the function with opposite sign.
In this sense, problem (P1) is called a \textit{unconstrained optimization}, (P2) is called a \textit{constrained optimization}, and (P3) is called a non-convex composite problem. 
The function $f$ or $F$ is called the \textit{objective function} or \textit{cost function}, and $\bx^*$ is the \textit{minimum point (or simply minimizer)}.
Different forms of $g$  lead to different optimization types:
\begin{itemize}
\item When $g(\bx)=0$,  problem (P3) reduces to an unconstrained problem (P1).
\item When $g(\bx)=\indicatorS(\bx)$,  problem (P3)  transforms into a constrained problem (P2).
\item When $g(\bx)=\lambda\normone{\bx}$,  problem (P3) becomes an $\ell_1$ regularized problem. 
\end{itemize}

Regarding (P3), it is assumed that $f$ can be accessed through a first-order oracle and that $g$ is known and ``simple," where simplicity will become clearer upon examining the algorithm description in Chapter~\ref{chapter:gd_convg}.
%\begin{remark}[Assumption for (P3)]\label{remark:assums_p3}
%In problem (P3), we often assume 
%\begin{itemize}
%\item[(A1)] $ g: \real^n \rightarrow (-\infty, \infty] $ is proper, closed, and convex.
%\item[(A2)] $ f: \real^n \rightarrow (-\infty, \infty] $ is proper and closed, $ \dom(f) $ is convex, $ \dom(g) \subseteq \textcolor{mylightbluetext}{\interior}(\dom(f)) $, and $ f $ is $ \beta $-smooth over $ \textcolor{mylightbluetext}{\interior}(\dom(f)) $.
%\end{itemize}
%Alternatively, we may assume
%\begin{itemize}
%\item[(B1)] $ g: \real^n \rightarrow (-\infty, \infty] $ is proper, closed, and convex and \textcolor{mylightbluetext}{$\dom(g)$ is compact}.
%\item[(B2)] $ f: \real^n \rightarrow (-\infty, \infty] $ is proper, closed, and  $ \beta $-smooth over $ \dom(f) $ ($ \beta > 0 $), which is assumed to be an open and convex set satisfying $ \dom(g) \subseteq \dom(f) $.
%\end{itemize}
%The iterative methods we introduce will use the function $g$ to generate a ``candidate" update. Therefore, we assume the function $g$ is proper closed and convex.
%The first set of assumption of (A) is used for proximal mapping related algorithm (Section~\ref{section:prox_gd}), where we do not assume the function $g$ has a compact domain; since the proximal operator has a quadratic term such that the function is strongly convex. This ensures the update has a minimum (Lemma~\ref{lemma:prox_prop3}, Theorem~\ref{theorem:exi_close_sc}).
%While the second set of assumption of (B) assumes $\dom(g)$ is compact, which ensures the minimum can be attained due to Weierstrass theorem (Theorem~\ref{theorem:weierstrass_them}).
%This assumption typically works for the generalized conditional gradient methods (Section~\ref{section:cond_gd}).
%\end{remark}
%The assumption that $ \dom(g) \subseteq \interior(\dom(f)) $ is crucial in the context of composite optimization problems for several reasons:
%\begin{enumerate}
%	\item \textbf{Feasibility and Domain Compatibility:}
%	\begin{itemize}
%		\item This assumption ensures that the domain of $ g $, where $ g $ is defined, lies within the interior of the domain of $ f $. This means that any point where $ g $ is defined is also a feasible point for $ f $, ensuring that the composite function $ F(x) = f(x) + g(x) $ is well-defined over its entire domain.
%	\end{itemize}
%	
%	\item \textbf{Smoothness and Differentiability:}
%	\begin{itemize}
%		\item If $ f $ is smooth (i.e., differentiable) over its domain, then it is particularly important that the points where $ g $ is evaluated are in the interior of $ f $'s domain. This ensures that $ f $ is not only defined but also smooth at these points, which is necessary for applying gradient-based optimization methods.
%	\end{itemize}
%	
%	\item \textbf{Optimization Algorithms:}
%	\begin{itemize}
%		\item Many optimization algorithms rely on the properties of the functions involved, such as continuity, differentiability, and convexity. By ensuring that $ \dom(g) \subseteq \interior(\dom(f)) $, we guarantee that these properties hold where they need to, facilitating the application of these algorithms.
%	\end{itemize}
%	
%	\item \textbf{Avoiding Boundary Issues:}
%	\begin{itemize}
%		\item If $ g $ were defined on points that lie on the boundary of $ f $'s domain, it could lead to undefined or problematic behavior of the composite function $ F $. For instance, if $ f $ is not differentiable at the boundary, this could complicate the optimization process.
%	\end{itemize}
%	
%	\item \textbf{Convexity Preservation:}
%	\begin{itemize}
%		\item If both $ f $ and $ g $ are convex, and $ \dom(g) \subseteq \interior(\text{dom}(f)) $, then the sum $ F(x) = f(x) + g(x) $ will also be convex. This is a critical property for many optimization problems, as convex functions have nice properties that make them easier to optimize.
%	\end{itemize}
%	
%	\item \textbf{Numerical Stability:}
%	\begin{itemize}
%		\item Ensuring that $ g $ is evaluated in the interior of $ f $'s domain helps maintain numerical stability. Evaluating functions near the boundary can sometimes lead to numerical issues due to the potential for discontinuities or rapid changes in function values.
%	\end{itemize}
%\end{enumerate}
%\textcolor{red}{TODO}


The ideal scenario in optimization occurs when the objective function has a single, unique minimizer known as the global minimizer. However, some functions may have multiple minimizers, or even an infinite number, e.g., a cosine function.  In these cases, identifying any one of these minimizers can be sufficient for solving the problem at hand.


In many practical applications, objective functions feature both a global minimizer and numerous local minimizers. Developing algorithms that reliably locate the global minimizer in such scenarios presents a significant challenge.
Throughout this book, we will focus on methods designed to identify a local minimizer of the objective function. Once a minimizer is found, it remains uncertain whether it is the global minimizer or merely one of several local minimizers. Additionally, there is no guarantee that the algorithm will find the local minimizer closest to the initial starting point. To explore various local minimizers, one approach is to conduct multiple runs with different starting points. Ideally, one could also analyze intermediate results from algorithms designed for global optimization.

A \textit{local minimizer (or local minimum point)} for a function $f$ is an argument vector giving the smallest function value inside a certain region, defined by $\epsilon$; while a \textit{global minimizer (or global minimum point)} is an argument vector given the smallest function value over the feasible set. 
In general, local minimizer and global minimizer are collectively referred to as \textit{minimizers or optimal points}.
Rigorously, we have the following definition.
\begin{definition}[Local/Global Minimum and Maximum]\label{definition:local_global_opt}
Let $f : \sS\subseteq \real^n \rightarrow \real$ be defined on a set $\sS \subseteq \real^n$. Then,
\begin{enumerate}
\item $\bx^* \in \sS$ is called a \textit{local minimum point} of $f$ over $\sS$ if there exists $\epsilon > 0$ for which $f(\bx^*) \leq f(\bx)$ for any $\bx \in \sS \cap \sB(\bx^*, \epsilon)$,
\item $\bx^* \in \sS$ is called a \textit{strict local minimum point} of $f$ over $\sS$ if there exists $\epsilon > 0$ for which $f(\bx^*) < f(\bx)$ for any $\bx \neq \bx^* \in \sS \cap \sB(\bx^*, \epsilon)$,
\item $\bx^* \in \sS$ is called a \textit{local maximum point} of $f$ over $\sS$ if there exists $\epsilon > 0$ for which $f(\bx^*) \geq f(\bx)$ for any $\bx \in \sS \cap \sB(\bx^*, \epsilon)$,
\item $\bx^* \in \sS$ is called a \textit{strict local maximum point} of $f$ over $\sS$ if there exists $\epsilon > 0$ for which $f(\bx^*) > f(\bx)$ for any $\bx \neq \bx^* \in \sS \cap \sB(\bx^*, \epsilon)$.
\end{enumerate}
Similarly,
\begin{enumerate}
\item $\bx^* \in \sS$ is called a \textit{global minimum point} of $f$ over $\sS$ if $f(\bx) \geq f(\bx^*)$ for any $\bx \in \sS$,
\item $\bx^* \in \sS$ is called a \textit{strict global minimum point} of $f$ over $\sS$ if $f(\bx) > f(\bx^*)$ for any $\bx \neq \bx^* \in \sS$,
\item $\bx^* \in \sS$ is called a \textit{global maximum point} of $f$ over $\sS$ if $f(\bx) \leq f(\bx^*)$ for any $\bx \in \sS$,
\item $\bx^* \in \sS$ is called a \textit{strict global maximum point} of $f$ over $\sS$ if $f(\bx) < f(\bx^*)$ for any $\bx \neq \bx^* \in \sS$.
\end{enumerate}
\end{definition}

\subsection*{Fundamental Theorems for Optimality Conditions}
For obtaining a \textit{global optimal point} (a.k.a. a global extremum point or a global optimizer, which can be either a global minimum or maximum), the Weierstrass theorem provides conditions under which such optimizers can be attained.
We  present  the Weierstrass theorem and its variants for optimization problems involving continuous or proper closed functions.
\begin{theorem}[Weierstrass Theorem and Variants]\label{theorem:weierstrass_them}
We consider the Weierstrass theorem and its variants for different types of functions and sets:
\begin{enumerate}[(i)]
\item \label{weier1_continus} Let $f:\sS\rightarrow (-\infty, \infty]$ be a \textbf{continuous function} defined over a \textit{nonempty and compact (closed and bounded) set} $\sS\subseteq\real^n$.
Then, there exists a global minimum point  and a global maximum point of $f$ over $\sS$.


\item \label{weier1_continus_lev}  Let $f:\sS\rightarrow (-\infty, \infty]$ be a \textbf{continuous function} defined over a \textit{nonempty and closed set} $\sS\subseteq\real^n$. Suppose that all the level sets $\lev[f, \alpha]=\{\bx\in\sS: f(\bx)\leq \alpha\}$ are bounded. Then, $f$ has a global minimum point over $\sS$.


\item  \label{weier2_continus_coerc} Let $f:\sS\rightarrow  (-\infty, \infty]$ be a \textbf{continuous and coercive function} and let $\sS\subseteq\real^n$ be a \textit{nonempty and closed set}. Then, $f$ has a global minimum point over $\sS$. (\text{The coerciveness ensures the function is bounded over a subset.})



\item \label{weier2_prop_close} Let $f:\sS\rightarrow (-\infty, \infty]$ be a \textbf{proper closed function}, and one of the following is satisfied:
\begin{enumerate}[(a)]
\item \label{weier2_prop_close_v1}  $f$ is defined over a \textit{nonempty and compact set} $\sS$. 
\item \label{weier2_prop_close_v2}  There exists a \textit{nonempty and bounded level set} $\lev[f, \alpha]=\{\bx\in\sS: f(\bx)\leq \alpha\}$. 
\item \label{weier2_prop_close_v3} $f$ is coercive, i.e., $\mathop{\lim}_{\normtwo{\bx}\rightarrow\infty}=\infty$.
\end{enumerate}
Then, there exists a global minimum point of $f$ over $\sS$. And the set of minimizers $\{\bx\in\sS:  f(\bx)\leq  f(\by), \forall \by\in \sS\}$  of $\mathopmin{\bx\in\sS} f(\bx)$ is nonempty and compact.
\end{enumerate}

\end{theorem}
Note the coerciveness in \ref{weier2_continus_coerc} ensures the function is bounded over a subset. The three conditions of \ref{weier2_prop_close}.\ref{weier2_prop_close_v1}$\sim$\ref{weier2_prop_close}.\ref{weier2_prop_close_v3} essentially ensure that the minimum value of $f(\bx)$ cannot be attained at infinity.
The results in \ref{weier2_prop_close} are used more extensively in optimization analysis. To provide a counterexample, let $f=\exp(-x)$ defined on $\real$, which is a proper closed function.
However, the domain or some level sets of $f$ are not bounded, and $f$ is not coercive. Therefore, the attainment of the global optimal point is not guaranteed.

\index{Fermat's theorem}
\textit{Fermat's theorem}, also known as \textit{Fermat's theorem on stationary points}, is a fundamental result in calculus and mathematical optimization. It provides a necessary condition for a function to have a local optimum (either a local maximum or a local minimum) at a point inside the domain of the function.
For a univariate function, Fermat's theorem states the optimality condition for a optimal point that lies in the interior of a set, i.e., a one-dimensional constrained optimization problem.
\begin{theorem}[Fermat's Theorem: Necessary Condition for Univariate Functions]\label{theorem:fermat_theorem}
Let $f: (a,b)\rightarrow \real$ be a one-dimensional differentiable function defined over an interval ($a, b$). 
If a point $x^*\in(a,b)$ (i.e., $x^*\in\interior([a,b])$) is a local maximum or minimum, then $f^\prime(x^*)=0$. 
\end{theorem}
In other words, if a function $f$ has a local maximum or minimum at a point $x^*$ where the function is differentiable, then the slope of the tangent line at that point is zero; the derivative of the function at that point must be zero.
It's important to note that this condition is necessary but \textbf{not} sufficient for $x^*$ to be an optimum. There are cases where the derivative is zero but the point is neither a maximum nor a minimum, such as in the case of an inflection point. Additionally, Fermat's theorem does \textbf{not} apply to boundary points of the domain of $f$ or to points where $f$ is not differentiable.



\subsection*{Descent Directions}
The first-order optimality conditions utilize gradient (first-order) information to evaluate  the optimality of a given point. Here, we first consider the case where the objective function is differentiable and provide the definition of descent directions for constrained and unconstrained optimization problems.
\begin{definition}[Unconstrained and Constrained Descent Directions]\label{definition:uncons_des_direct}
Consider the unconstrained optimization problem (P1) in Definition~\ref{definition:opt_probs_all},
where $ f $ is continuously differentiable over  $\real^n $. Then a vector $ \bd \neq \bzero $ is called an \textit{unconstrained descent direction} at $ \bx$ if $ f'(\bx; \bd)=\nabla f(\bx)^\top \bd < 0 $.

Alternatively, consider the constrained optimization problem (P2) in Definition~\ref{definition:opt_probs_all}, where $f$ is defined on $\sS\subseteq\real^n$. Then a vector $ \bd \neq \bzero $ is called a \textit{constrained descent direction or a feasible descent directions} at $\bx$ if $ f'(\bx; \bd)=\nabla f(\bx)^\top \bd < 0 $, and there exists $ \varepsilon > 0 $ such that $ \bx + \mu\bd \in \sS $ for all $ \mu \in [0, \varepsilon] $.
When the setting is clear from the context, we will simply refer to \textit{unconstrained descent directions} or \textit{constrained descent directions} as \textit{descent directions} for brevity.
\end{definition}


\begin{lemma}[Unconstrained and Constrained Descent Property]\label{lemma:descent_property}
Let $ f $ be a continuously differentiable function over $\sS\subseteq\real^n$ (resp. $\real^n$), and let $\bx \in \sS$ (resp. $\bx\in\real^n$). Suppose that $\bd$ is a descent direction of $ f $ at $\bx$. Then, there exists $\varepsilon > 0$ such that 
$$
f(\bx + \mu \bd) < f(\bx),\quad \text{for any $ \mu \in (0, \varepsilon] $.}
$$
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:descent_property}]
Since $ f'(\bx; \bd)=\nabla f(\bx)^\top \bd < 0 $, it follows from the definition of the directional derivative (Definition~\ref{definition:partial_deri}) that
$$
\lim_{\mu \to 0^+} \frac{f(\bx + \mu \bd) - f(\bx)}{\mu} = f'(\bx; \bd) < 0.
$$
Therefore, there exists an $\varepsilon > 0$ such that
$
\frac{f(\bx + \mu \bd) - f(\bx)}{\mu} < 0
$
for any $ \mu \in (0, \varepsilon] $, which completes the proof.
\end{proof}


\index{Sufficient decrease condition}
The definition and property of descent directions formalize the concept of moving from a current point in a direction that ensures a reduction in the objective function's value, with specific conditions for both unconstrained and constrained settings.
Building on this concept, we can leverage the properties of descent directions to establish criteria that guarantee a sufficient decrease in the function value when taking a step in such a direction.
\begin{lemma}[Sufficient Decrease Condition from Descent Directions]\label{lemma:valid_suff_des_armi}
Let $ f $ be a continuously differentiable function over $\real^n$, and let $\bx \in \real^n$. Suppose that $\bzero \neq \bd \in \real^n$ is a descent direction of $f$ at $\bx$ and let $\alpha \in (0,1)$. Then there exists $\varepsilon > 0$ such that the inequality
$$
f(\bx) - f(\bx + \mu \bd) \geq -\alpha \mu \nabla f(\bx)^\top \bd
$$
holds for all $\mu \in [0, \varepsilon]$.
\end{lemma}
\begin{proof}[of Lemma~\ref{lemma:valid_suff_des_armi}]
Since $f$ is continuously differentiable, by the linear approximation theorem (Theorem~\ref{theorem:linear_approx})
\begin{align}
&f(\bx + \mu \bd) = f(\bx) + \mu \nabla f(\bx)^\top \bd + o(\mu \normtwo{\bd}) \nonumber\\
&\quad\implies 
f(\bx) - f(\bx + \mu \bd) = -\alpha \mu \nabla f(\bx)^\top \bd - (1 - \alpha) \mu \nabla f(\bx)^\top \bd - o(\mu \normtwo{\bd}). \label{equation:valid_suff_des_armi2}
\end{align}
Since $\bd$ is a descent direction of $f$ at $\bx$, we have
$$
\lim_{\mu \to 0^+} \frac{(1 - \alpha) \mu \nabla f(\bx)^\top \bd + o(\mu \normtwo{\bd})}{\mu} = (1 - \alpha) \nabla f(\bx)^\top \bd < 0.
$$
Therefore, there exists an $\varepsilon > 0$ such that the inequality $
(1 - \alpha) \mu \nabla f(\bx)^\top \bd + o(\mu \normtwo{\bd}) < 0
$ holds for all $\mu \in (0, \varepsilon]$, which combined with \eqref{equation:valid_suff_des_armi2} implies the desired result.
\end{proof}
The sufficient decrease condition guarantees the existence of the Armijo condition, the Goldstein condition, and the Wolfe condition in descent methods with line search (Section~\ref{section:line_search}).

On the other hand, using gradient information, we can construct arbitrary descent directions.
\begin{theorem}[Unconstrained Descent Directions]\label{theorem:uncons_des_dir}
Let $f:\real^n\rightarrow \real$ be a differentiable function.
If $ \nabla f(\bx) \neq \bzero $ and $ \bB $ is a positive definite matrix, then
$$
\bd_1 = -\bB\nabla f(\bx) \qquad \text{and} \qquad \bd_2 = -\bB^{-1}\nabla f(\bx)
$$
are descent directions.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:uncons_des_dir}]
A positive definite matrix $ \bB \in \real^{n \times n} $ satisfies
$
\bu^\top \bB \bu > 0, \text{ for all }  \bzero\neq \bu \in \real^n.
$
If we take $ \bu \triangleq \bd_1 $ and exploit the symmetry of $ \bB $, we get
$$
\bd_1^\top \nabla f(\bx) = -\nabla f(\bx)^\top \bB^\top \nabla f(\bx) = -\nabla f(\bx)^\top \bB \nabla f(\bx) < 0.
$$
Similarly, if we let $ \bu \triangleq \bd_2 $, we get
$$
\bd_2^\top \nabla f(\bx) = \bd_2^\top (-\bB \bd_2) = -\bd_2^\top \bB \bd_2 < 0.
$$
Thus, the condition in Definition~\ref{definition:uncons_des_direct} is satisfied in both cases.
\end{proof}
Note that when $\bB\triangleq\bI$, the descent direction becomes the negative gradient direction, which is also known as the \textit{steepest descent direction} and will be explored further in Chapter~\ref{chapter:gradient-descent}.

\paragrapharrow{Optimality conditions and stationary conditions.}
In the remainder of this section, we will introduce  \textbf{optimality conditions} for problems (P1), (P2), and (P3) as defined in Definition~\ref{definition:opt_probs_all}. The optimality conditions for problem (P4) are discussed in Section~\ref{section:gen_kkt_cond}.
In a nutshell, these optimality conditions are outlined in Table~\ref{tab:optimality_conditions}.
\begin{table}[H]
\centering
\caption{Optimality conditions for problems (P1), (P2), and (P3) as defined in Definition~\ref{definition:opt_probs_all}, where ``Nec." is short for ``Necessary" and ``Suff." is short for ``Sufficient".}
\label{tab:optimality_conditions}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Problem} & \textbf{First-Order Condition} & \textbf{Second-Order Condition} \\ \hline
Differentiable (P1) & $\nabla f(\bx^*) = \bzero$ (Nec.) & 
\begin{tabular}{@{}l@{}}
$\nabla^2 f(\bx^*) \succeq \bzero$ (Nec.) \\
$\nabla^2 f(\bx^*) \succ \bzero$ (Suff.)
\end{tabular} \\ \hline
Nonsmooth (P1) & $\bzero \in \partial f(\bx^*)$ (Nec.) & --- \\ \hline
Convex (P1) & 
\begin{tabular}{@{}l@{}}
$\bzero \in \partial f(\bx^*)$ (Nec./Suff.) \\
$\bx^* = \proxf(\bx^*)$  (Nec./Suff.)
\end{tabular} 
& --- \\ \hline
Convex (P2) & $\nabla f(\bx^*)^\top (\bx-\bx^*) \geq 0$ (Nec./Suff.) & ---\\ \hline 
Composite (P3) & $-\nabla f(\bx^*) \in \partial g(\bx^*)$ (Nec.) & --- \\ \hline
\end{tabular}
\end{table}
Additionally, \textbf{stationary conditions} of problems (P1), (P2), and (P3) are defined in Definition~\ref{definition:stat_point}, Definition~\ref{definition:stat_point_uncons_convset}, and Definition~\ref{definition:stat_opt_cond_p3}, respectively:
\begin{subequations}\label{equation:stationar_p123}
\begin{align}
&\textbf{(P1)}:\qquad  \nabla f(\bx^*) &&=\bzero;\\
&\textbf{(P2)}:\qquad  \nabla f(\bx^*)^\top (\bx - \bx^*)& &\geq 0 \text{ for any $\bx\in\sS$};\\
&\textbf{(P3)}:\qquad  -\nabla f(\bx^*) &&\in \partial g(\bx^*).
\end{align}
\end{subequations}

\subsection{Unconstrained Optimization}
Unconstrained differentiable optimization problems are typically expressed as (P1) in Definition~\ref{definition:opt_probs_all}:
\begin{equation}
\text{(P1)}:\qquad \min_{\bx \in \real^n} f(\bx),
\end{equation}
where it is assumed that $ f $ is a continuously differentiable function. Definition~\ref{definition:local_global_opt} introduced the definitions of local and global minimizers. Given a point $\widetildebx$, we want to determine whether this point is a local or global minimizer of the function $ f $. If we proceed from the definition, we need to judge all points in its neighborhood, which is impractical. Therefore, we need a simpler way to verify whether a point is an extremum point. We call these \textit{optimality conditions}, which mainly include first-order optimality conditions and second-order optimality conditions.

\index{Optimality condition}




\subsection*{Local Optimality}
Most objective functions, especially those with several local minimizers,
contain local maximizers and other points which satisfy a necessary condition for a local minimizer. The following theorems help us identify  such points and distinguish  local minimizers from  irrelevant points.

Definition~\ref{definition:uncons_des_direct} and Lemma~\ref{lemma:descent_property} show that as long as there is a descent direction, the function does not reach  a local minimum. Only when $\nabla f(\bx^*)=\bzero$ at $\bx^*$ there are no descent directions for the unconstrained optimization problem (P1). Rigorously, we have the following first-order necessary condition for a local minimum point.
\begin{theoremHigh}[First-Order Necessary Condition for a Local Minimum]\label{theorem:fermat_fist_opt}
Let $f: \real^n \rightarrow \real$ be a  differentiable function. If $\bx^*$ is a local minimizer for $f$, then
$$
\nabla f(\bx^*) = \bzero.
$$
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:fermat_fist_opt}]
Let $i \in \{1, 2, \ldots, n\}$ and consider the one-dimensional function $g(\mu) = f(\bx^* + \mu \be_i)$. Note that $g$ is differentiable at $\mu = 0$ and that $g'(0) = \frac{\partial f}{\partial x_i}(\bx^*)$. Since $\bx^*$ is a local minimum point of $f$, it follows that $\mu = 0$ is a local minimum of $g$, which immediately implies that $g'(0) = 0$ by Theorem~\ref{theorem:fermat_theorem}. This equality is exactly the same as $\frac{\partial f}{\partial x_i}(\bx^*) = 0$. Since this holds for any $i \in \{1, 2, \ldots, n\}$, we obtain $\nabla f(\bx^*) = \bzero$.
\end{proof}



\index{Stationary point}
The local minimizers are among the points with $\nabla f(\bx) = \bzero$. They have a special name.
\begin{definition}[Stationary Point, Saddle Point for (P1)]\label{definition:stat_point}
Let $f: \real^n \rightarrow \real$ be a differentiable function. If $\nabla f(\widetildebx) = \bzero$, then $\widetildebx$ is said to be a \textit{stationary point} for $f$.
In the meantime, a stationary point $\widetildebx$ is called a \textit{saddle point} of $f$ if it is neither a local minimum point nor a local maximum point of $f$ (where $\nabla^2 (\widetildebx)$ has both positive and negative eigenvalues); see Figure~\ref{fig:saddle_point_all}.
\end{definition}

\begin{figure}[h]
\centering       
\vspace{-0.25cm}                 
\subfigtopskip=2pt               
\subfigbottomskip=-2pt         
\subfigcapskip=-10pt      
\includegraphics[width=0.98\textwidth]{imgs/saddle_point.pdf}
\caption{Illustration of stationary points, showing minimum, maximum, and saddle points.
}
\label{fig:saddle_point_all}
\end{figure}
Stationary points include local maximizers,  local minimizers, and ``the rest" (which we call \textit{saddle points}). 
Without additional assumptions, even if the first-order necessary conditions are satisfied, we cannot determine whether a stationary point is a local minimum. 
To distinguish between them, we need one extra term in the Taylor expansion. Provided that $f$ is twice continuously differentiable, by the quadratic approximation theorem (Theorem~\ref{theorem:quad_app_theo}),
\begin{equation}\label{equation:necess_cond_loca2}
f(\bx + \bd) = f(\bx) + \bd^\top \nabla f(\bx) + \frac{1}{2} \bd^\top \nabla^2 f(\bx) \bd + \mathcalO(\normtwo{\bd}^3).
\end{equation}
For a stationary point $\widetildebx$, \eqref{equation:necess_cond_loca2} takes the form
$$
f(\widetildebx + \bd) = f(\widetildebx) + \frac{1}{2} \bd^\top \nabla^2 f(\widetildebx) \bd + \mathcalO(\normtwo{\bd}^3).
$$
If the second term is positive for all $\bd$, we say that the matrix $\nabla^2 f(\widetildebx)$ is positive definite (Definition~\ref{definition:psd-pd-defini}). Further, we can take $\normtwo{\bd}$ so small that the remainder term is negligible, and it follows that $\widetildebx$ is a local minimizer. Rigorously, we have the following results.
\begin{theoremHigh}[Second-Order Necessary Condition for a Local Minimum]\label{theorem:second_nec_loca}
Let $f: \real^n \rightarrow \real$ be a twice continuously differentiable function.  If $\bx^*$ is a local minimizer (resp. local maximizer), then $\nabla^2 f(\bx^*)$ is positive semidefinite (resp. negative semidefinite).
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:second_nec_loca}]
We will prove the result for a  local minimum; the result for a  local maximum follows by considering the function $-f$.
Since $\bx^*$ is a local minimum point, there exists an open ball neighboring $\bx^*$ with a radius $\tau$: $\sB(\bx^*, \tau)$ such that
$
f(\bx) \geq f(\bx^*)
$
for all $\bx \in \sB(\bx^*, \tau)$.
Let $\bd \in \real^n$ be a nonzero vector. For any $0 < \mu < \frac{\tau}{\normtwo{\bd}}$, we have $\bx_\mu = \bx^* + \mu \bd \in \sB(\bx^*, \tau)$, and thus  for any such $\mu$
\begin{equation}\label{equation:second_nec_loca1}
f(\bx_\mu) \geq f(\bx^*).  
\end{equation}
On the other hand, by the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), it follows that there exists a vector $\bu_\mu \in [\bx^*, \bx_\mu]$ such that
\begin{equation}\label{equation:second_nec_loca2}
\begin{aligned}
f(\bx_\mu) - f(\bx^*) 
&= \nabla f(\bx^*)^\top (\bx_\mu - \bx^*) + \frac{\mu^2}{2} \bd^\top \nabla^2 f(\bu_\mu) \bd
= \frac{\mu^2}{2} \bd^\top \nabla^2 f(\bu_\mu) \bd,
\end{aligned}
\end{equation}
where the last equality follows from the first-order necessary condition in Theorem~\ref{theorem:fermat_fist_opt}.

Combining \eqref{equation:second_nec_loca1} and \eqref{equation:second_nec_loca2}, it follows that for any $\mu \in (0, \frac{\tau}{\normtwo{\bd}})$, the inequality $\bd^\top \nabla^2 f(\bu_\mu) \bd \geq 0$ holds. Finally, using the fact that $\bu_\mu \rightarrow \bx^*$ as $\mu \rightarrow 0^+$, and the continuity of the Hessian ($f$ is twice continuously differentiable), we obtain that $\bd^\top \nabla^2 f(\bx^*) \bd \geq 0$. Since this inequality holds for any $\bd \in \real^n$, we conclude the desired result.
\end{proof}


Theorem~\ref{theorem:second_nec_loca} provides a  necessary condition for a local optimum $\bx^*$.
The Taylor expansion \eqref{equation:necess_cond_loca2}  also forms the basis for the proof of the following theorem.

\begin{theoremHigh}[Second-Order Sufficient Condition for a Local Minimum]\label{theorem:second_nec_nonstrict_loca}
Let $f:  \real^n \rightarrow \real$ be a  twice continuously differentiable function, and suppose that $\bx^*$ is a stationary point. 
Further, assume that $\nabla^2 f(\bx)$ is positive semidefinite  in a neighbourhood of $\widetildebx$; that is, there exist a $\tau>0$ such that 
$$
\nabla^2 f(\bx)\succeq \bzero, \text{ for any }\bx\in\sB(\widetildebx, \tau).
$$
Then $\widetildebx$ is a local minimizer.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:second_nec_nonstrict_loca}]
By the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), it follows that for any $\bx \in \sB(\widetildebx, \tau)$, there exists a vector $\bxi \in [\bx^*, \bx]$ (hence $\bxi\in\sB(\widetildebx, \tau)$) for which
$$
f(\bx) - f(\bx^*) = \frac{1}{2} (\bx - \bx^*)^\top \nabla^2 f(\bxi) (\bx - \bx^*), \quad\text{for any $\bx \in \sB(\widetildebx, \tau)$}.
$$
Since $\nabla^2 f(\bxi) \succeq \bzero$, we have that $f(\bx) \geq f(\bx^*)$, establishing the result that $\bx^*$ is a local minimum point of $f$ over $\sB(\widetildebx, \tau)$.
\end{proof}

\begin{theoremHigh}[Second-Order Sufficient Condition for a Strict Local Minimum]\label{theorem:second_suff_loca}
Let $f:  \real^n \rightarrow \real$ be a  twice continuously differentiable function, and suppose that $\bx^*$ is a stationary point. 
If $\nabla^2 f(\bx^*) \succ \bzero$ (resp. $\nabla^2 f(\bx^*) \prec \bzero$), then $\bx^*$ is a strict local minimum point (resp. strict local maximum point) of $f$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:second_suff_loca}]
We will prove the result for a strict local minimum; the result for a strict local maximum follows by considering the function $-f$. Suppose  that $\bx^*$ is a stationary point satisfying $\nabla^2 f(\bx^*) \succ \bzero$. Since the Hessian is continuous ($f$ is assumed to be twice continuously differentiable), it follows that there exists an open ball $\sB(\bx^*, \tau)$ for which $\nabla^2 f(\bx) \succ \bzero$ for any $\bx \in \sB(\bx^*, \tau)$. By the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), it follows that for any $\bx \in \sB(\bx^*, \tau)$, there exists a vector $\bxi \in [\bx^*, \bx]$ (and hence $\bxi \in \sB(\bx^*, \tau)$) for which
\begin{equation}\label{equation:second_suff_loc1}
f(\bx) - f(\bx^*) = \frac{1}{2} (\bx - \bx^*)^\top \nabla^2 f(\bxi) (\bx - \bx^*),\quad \text{ for any $\bx \in \sB(\bx^*, \tau)$}.
\end{equation}
Since $\nabla^2 f(\bxi) \succ \bzero$, it follows by \eqref{equation:second_suff_loc1} that for any $\bx \in \sB(\bx^*, \tau)$ with $\bx \neq \bx^*$, the inequality $f(\bx) > f(\bx^*)$ holds, implying that $\bx^*$ is a strict local minimum point of $f$ over $\sS$.
\end{proof}





\begin{exercise}[Sufficient Condition for a Saddle Soint]\label{exercise:second_suff_locasadd}
Let $f: \real^n \rightarrow \real$ be a twice continuously differentiable function, and suppose that $\bx^*$ is a stationary point. If $\nabla^2 f(\bx^*)$ is an indefinite matrix, then $\bx^*$ is a saddle point of $f$ over $\sS$.
\end{exercise}

%\textit{Proof.} Since $\nabla^2 f(\bx^*)$ is indefinite, it has at least one positive eigenvalue $\lambda > 0$, corresponding to a normalized eigenvector which we will denote by $\bu$. Since $\sS$ is an open set, it follows that there exists a positive real $r > 0$ such that $\bx^* + \alpha \bu \in \sS$ for any $\alpha \in (0, r)$.
%
%By the quadratic approximation theorem  and recalling that $\nabla f(\bx^*) = \bzero$, we have that there exists a function $g: \real_{++} \rightarrow \real$ satisfying
%$$
%\frac{g(\mu)}{\mu} \rightarrow 0 \quad \text{as } \mu \rightarrow 0, 
%$$
%such that for any $\alpha \in (0, r)$
%$$
%f(\bx^* + \alpha\bu) = f(\bx^*) + \frac{\alpha^2}{2}\bu^\top \nabla^2 f(\bx^*)\bu + g(\alpha^2 \normtwo{\bu}^2)
%$$
%$$
%= f(\bx^*) + \frac{\lambda \alpha^2}{2} + g(\alpha^2).
%$$
%Since $\normtwo{v} = 1$, the latter can be rewritten as
%$$
%f(\bx^* + \alpha\bu) = f(\bx^*) + \frac{\lambda \alpha^2}{2} + g(\alpha^2).
%$$
%By it follows that there exists an $\epsilon_1 \in (0, r)$ such that $g(\alpha^2) > -\frac{\lambda \alpha^2}{2}$ for all $\alpha \in (0, \epsilon_1)$, and hence $f(\bx^* + \alpha\bu) > f(\bx^*)$ for all $\alpha \in (0, \epsilon_1)$. This shows that $\bx^*$ cannot be a local maximum point of $f$ over $\sS$. A similar argumentexploiting an eigenvector of $\nabla^2 f(\bx^*)$ corresponding to a negative eigenvalueshows that $\bx^*$ cannot be a local minimum point of $f$ over $\sS$, establishing the desired result that $\bx^*$ is a saddle point.


In conclusion, the local maximizers and the \textit{saddle points}, can be characterized by the following remark.
\begin{remark}[Characterization Theorem of Stationary Points]\label{remark:charac_statpoint}
Assume that $\widetildebx$ is a stationary point and that $\nabla^2 f(\widetildebx) \neq \bzero$. Then,
\begin{enumerate}
\item If $\nabla^2 f(\widetildebx)$ is PD: $\widetildebx$ is a strict local minimizer (Theorem~\ref{theorem:second_suff_loca}).
\item If $\nabla^2 f(\widetildebx)$ is PSD: $\widetildebx$ is a local minimizer or a saddle point (Theorem~\ref{theorem:second_nec_loca}).
\item If $\nabla^2 f(\widetildebx)$ is ND: $\widetildebx$ is a strict local maximizer (Theorem~\ref{theorem:second_suff_loca}).
\item If $\nabla^2 f(\widetildebx)$ is NSD: $\widetildebx$ is a local maximizer or a saddle point (Theorem~\ref{theorem:second_nec_loca}).
\item If $\nabla^2 f(\widetildebx)$ is neither definite nor semidefinite: $\widetildebx$ is a saddle point (Exercise~\ref{exercise:second_suff_locasadd}).
\item If $\nabla^2 f(\widetildebx) = \bzero$, then we need higher order terms in the Taylor expansion in order to find the local minimizers among the stationary points.
\end{enumerate}
\end{remark}



\subsection*{Global Optimality}
The conditions outlined in the previous section can, at best, ensure local optimality of stationary points, as they rely solely on local information---specifically, the values of the gradient and the Hessian at a given point (or in the neighborhood of the stationary points as in Theorem~\ref{theorem:second_nec_nonstrict_loca}). To guarantee global optimality, conditions must incorporate global information. For instance, if the Hessian of the function is always positive semidefinite, then all stationary points are also global minima. This property, which we  refer to as convexity (Theorem~\ref{theorem:psd_hess_conv}), ensures that any stationary point found is not just locally but globally optimal.
\begin{theoremHigh}[Global Optimality]\label{theorem:global_optima}
Let $f$ be a twice continuously differentiable function defined over $\real^n$. Suppose that $\nabla^2 f(\bx) \succeq \bzero$ for any $\bx \in \real^n$. Let $\bx^* \in \real^n$ be a stationary point of $f$. Then $\bx^*$ is a global minimum point of $f$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:global_optima}]
By the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), it follows that for any $\bx \in \real^n$, there exists a vector $\bxi \in [\bx^*, \bx]$ for which
$$
f(\bx) - f(\bx^*) = \frac{1}{2} (\bx - \bx^*)^\top \nabla^2 f(\bxi) (\bx - \bx^*).
$$
Since $\nabla^2 f(\bxi) \succeq \bzero$, we have that $f(\bx) \geq f(\bx^*)$, establishing the result that $\bx^*$ is a global minimum point of $f$.
\end{proof}









\subsection{Constrained Optimization}\label{section:constrain_opt}

In this book, we will also consider the constrained optimization problem (P2) given by
$$
\begin{aligned}
\text{(P2)} \qquad & \min f(\bx)  \quad  \text{s.t.}\quad \bx \in \sS\subseteq\real^n,
\end{aligned}
$$
where $f$ is a continuously differentiable function and $\sS$ can be either a convex or non-convex set. 
While stationarity is a necessary condition for an unconstrained local optimal point, the situation becomes more complex when dealing with constrained problems of the form (P2). Instead of examining \textit{stationary points of a function}, we need to consider the notion of \textit{stationary points of a problem}. This subsection discusses the optimality conditions for general constrained optimization problems; for optimality conditions specific to equality and inequality constrained optimization problems, refer to Section~\ref{section:gen_kkt_cond}, which covers KKT conditions.


As previously mentioned, a well-known result for a one-dimensional function $f$ defined and differentiable over an interval $ (a, b) $ is that if a point $ x^* \in (a, b) $ is a local maximum or minimum point, then $ f'(x^*) = 0 $.
This is also known as \textit{Fermat's theorem} (Theorem~\ref{theorem:fermat_theorem}). 
The first-order necessary condition for an unconstrained optimization problem (P1) is also based on this result (Theorem~\ref{theorem:fermat_fist_opt}).
On the other hand, the multidimensional extension of this result states that the gradient is also zero at local optimal points. We refer to such an optimality condition as a \textit{first-order optimality condition for constrained optimization problems}, as it is expressed in terms of  first-order derivatives. In what follows, we will also discuss \textit{second order optimality conditions for constrained optimization problems} that use in addition information on the second order (partial) derivatives.

\index{Fermat's theorem}
\begin{theoremHigh}[First-Order Necessary Condition for an Interior Local Minimum]\label{theorem:fermat_fist_opt_int}
Let $ f : \sS \to \real $ be a function defined on a  set $ \sS \subseteq \real^n $ (not necessarily a convex set). Suppose that $ \bx^* \in \interior(\sS) $~\footnote{The condition can be modified to such that $\bx^*\in\sS$ where $\sS$ is an open set. Note the difference between Theorem~\ref{theorem:fermat_fist_opt_int} and Theorem~\ref{theorem:fermat_fist_opt}.} is a local minimum point and that all the partial derivatives of $ f $ exist at $ \bx^* $. Then $ \nabla f(\bx^*) = \bzero $, i.e., the gradient vanishes at all local minimum points.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:fermat_fist_opt_int}]
Let $ i \in \{1, 2, \ldots, n\} $ and consider the one-dimensional function $ g(\mu) = f(\bx^* + \mu \be_i) $. Note that $ g $ is differentiable at $ \mu = 0 $ and that $ g'(0) = \frac{\partial f}{\partial x_i}(\bx^*) $. Since $ \bx^* $ is a local minimum point of $ f $, it follows that $ \mu = 0 $ is a local minimum of $ g $, which immediately implies that $ g'(0) = 0 $ by Fermat's theorem (Theorem~\ref{theorem:fermat_theorem}). The latter equality is exactly the same as $ \frac{\partial f}{\partial x_i}(\bx^*) = 0 $. Since this is true for any $ i \in \{1, 2, \ldots, n\} $, it holds that $ \nabla f(\bx^*) = \bzero $.
\end{proof}
Note again that  this optimality condition is a necessary condition; however, there could be vanished points which are not local maximum or minimum point. For example, the derivative of the function $f(x)=x^5$ is zero at $x=0$, but this point is neither a local minimum point nor a local maximum point.

\begin{theoremHigh}[Second-Order Necessary Condition for an Interior Local Minimum]\label{theorem:second_nec_loca_int}
Let $f: \sS\subseteq\real^n \rightarrow \real$ be a twice continuously differentiable function defined on $\sS$.  If $\bx^*\in\interior(\sS)$~\footnote{The condition can be modified to such that $\bx^*\in\sS$ where $\sS$ is an open set. Note the difference between Theorem~\ref{theorem:second_nec_loca_int} and Theorem~\ref{theorem:second_nec_loca}.} is a local minimizer (resp. local maximizer), then $\nabla^2 f(\bx^*)$ is positive semidefinite (resp. negative semidefinite).
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:second_nec_loca_int}]
Since $\bx^*\in\interior(\sS)$ is a local minimum point, there exists an open ball neighboring $\bx^*$ with a radius $\tau$: $\sB(\bx^*, \tau) \subseteq \interior(\sS)$ such that
$
f(\bx) \geq f(\bx^*)
$
for all $\bx \in \sB(\bx^*, \tau)$.
The proof follows from the same argument as the proof of Theorem~\ref{theorem:second_nec_loca} by using the first-order necessary condition in Theorem~\ref{theorem:fermat_fist_opt_int} instead of Theorem~\ref{theorem:fermat_fist_opt}.
\end{proof}

%Let $\bd \in \real^n$ be a nonzero vector. For any $0 < \mu < \frac{\tau}{\normtwo{\bd}}$, we have $\bx_\mu = \bx^* + \mu \bd \in \sB(\bx^*, \tau)$, and hence for any such $\mu$
%\begin{equation}\label{equation:second_nec_loca1}
%f(\bx_\mu) \geq f(\bx^*).  
%\end{equation}
%On the other hand, by the linear approximation theorem (Theorem~\ref{theorem:linear_approx}), it follows that there exists a vector $\bu_\mu \in [\bx^*, \bx_\mu]$ such that
%\begin{equation}\label{equation:second_nec_loca2}
%\begin{aligned}
%f(\bx_\mu) - f(\bx^*) 
%&= \nabla f(\bx^*)^\top (\bx_\mu - \bx^*) + \frac{1}{2} (\bx_\mu - \bx^*)^\top \nabla^2 f(\bu_\mu) (\bx_\mu - \bx^*)\\
%&= \frac{\mu^2}{2} \bd^\top \nabla^2 f(\bu_\mu) \bd,
%\end{aligned}
%\end{equation}
%where the last equality follows from the first-order necessary condition in Theorem~\ref{theorem:fermat_fist_opt_int}.

%Combining \eqref{equation:second_nec_loca1} and \eqref{equation:second_nec_loca2}, it follows that for any $\mu \in (0, \frac{r}{\normtwo{\bd}})$, the inequality $\bd^\top \nabla^2 f(\bu_\mu) \bd \geq 0$ holds. Finally, using the fact that $\bu_\mu \rightarrow \bx^*$ as $\mu \rightarrow 0^+$, and the continuity of the Hessian ($f$ is twice continuously differentiable), we obtain that $\bd^\top \nabla^2 f(\bx^*) \bd \geq 0$. Since the preceding inequality holds for any $\bd \in \real^n$, we obtain the desired result.
%
%The proof of the result for a local maximizer follows immediately by employing the above result on the function $-f$.

\begin{theoremHigh}[Second-Order Sufficient Condition for a Strict $\&$ Interior Local Minimum]\label{theorem:second_suff_loca_int}
Let $f: \sS \subseteq \real^n \rightarrow \real$ be a twice continuously differentiable defined on $\sS$, and suppose that $\bx^*\in\interior(\sS)$~\footnote{Again, the condition can be modified to such that $\bx^*\in\sS$ where $\sS$ is an open set. Note the difference between Theorem~\ref{theorem:second_suff_loca_int} and Theorem~\ref{theorem:second_suff_loca}.} is a stationary point. 
If $\nabla^2 f(\bx^*) \succ \bzero$ (resp. $\nabla^2 f(\bx^*) \prec \bzero$), then $\bx^*$ is a strict local minimum point (resp. strict local maximum point) of $f$ over $\sS$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:second_suff_loca_int}]
Suppose  that $\bx^*$ is a stationary point satisfying $\nabla^2 f(\bx^*) \succ \bzero$. Since the Hessian is continuous ($f$ is assumed twice continuously differentiable) and $\bx^*\in\interior(\sS)$, it follows that there exists an open ball $\sB(\bx^*, \tau) \subseteq \sS$ for which $\nabla^2 f(\bx) \succ \bzero$ for any $\bx \in \sB(\bx^*, \tau)$.
The proof then follows from the same argument as the proof of Theorem~\ref{theorem:second_suff_loca}.
\end{proof}

\begin{exercise}[Sufficient Condition for a Saddle Point]\label{exercise:second_suff_locasadd_int}
Let $f: \sS\subseteq \real^n \rightarrow \real$ be a function defined on an open set $\sS \subseteq \real^n$. Suppose that $f$ is twice continuously differentiable over $\sS$ and that $\bx^*$ is a stationary point. If $\nabla^2 f(\bx^*)$ is an indefinite matrix, then $\bx^*$ is a saddle point of $f$ over $\sS$.
\end{exercise}





Note that we will introduce stationary points of constrained optimization problems over a convex set in  Definition~\ref{definition:stat_point_uncons_convset} and Theorem~\ref{theorem:stat_point_uncons_convset}. 
For non-convex constrained sets, the descent direction (Definition~\ref{definition:uncons_des_direct}) can serve as a first-order necessary condition.
\begin{theoremHigh}[First-Order Necessary Condition for (P2)]\label{theorem:_nonconv_fea_loca_optim}
Consider the constrained optimization problem (P2) in Definition~\ref{definition:opt_probs_all}, where $\sS$ can be either convex or non-convex.
If $ \bx^* $ is a local optimal solution of (P2), then there are \textbf{no} constrained/feasible descent directions at $ \bx^* $ (Definition~\ref{definition:uncons_des_direct}).

\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:_nonconv_fea_loca_optim}]
The proof is by contradiction. If there is a constrained/feasible descent direction at $\bx^*$, that is, a vector $ \bd $ and $ \varepsilon_1 > 0 $ such that $ \bx^* + \mu\bd \in \sS $ for all $ \mu \in [0, \varepsilon_1] $ and $ \nabla f(\bx^*)^\top \bd < 0 $ (Definition~\ref{definition:uncons_des_direct}), then by  Lemma~\ref{lemma:descent_property}, there is an $ \varepsilon_2 < \varepsilon_1 $ such that $ f(\bx^* + \mu\bd) < f(\bx^*) $ for all $ \mu \in [0, \varepsilon_2] $, which leads to a contradiction to the local optimality of $ \bx^* $.
\end{proof}

Having established the criteria for a stationary point to be a global minimum in Theorem~\ref{theorem:global_optima}, we now turn our attention to the conditions under which a global minimum is guaranteed to exist.
\begin{theorem}[Attainment Under Coerciveness]\label{theorem:att_coer}
Let $f: \real^n\rightarrow \real$ be a \textcolor{black}{proper closed  (or continuous)} and coercive function, and let $\sS\subseteq\real^n$ be a nonempty closed set. Then $f$ has a global minimum
point over $\sS$.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:att_coer}]
Let $\bx_0 \in \sS$ be an arbitrary point in $\sS$. Since the function is coercive (Definition~\ref{definition:coerciveness}), it follows that there exists a $B > 0$ such that
\begin{equation}\label{equation:att_coer}
	f(\bx) > f(\bx_0) \text{ for any } \bx \text{ such that } \normtwo{\bx} > B. 
\end{equation}
Since any global minimizer $\bx^*$ of $f$ over $S$ satisfies $f(\bx^*) \leq f(\bx_0)$, it follows from \eqref{equation:att_coer} that the set of global minimizers of $f$ over $\sS$ is the same as the set of global minimizers of $f$ over $\sS \cap \sB[0, B]$. The set $\sS \cap \sB[0, B]$ is compact and nonempty, and thus by the Weierstrass theorem (\ref{weier2_prop_close} in Theorem~\ref{theorem:weierstrass_them}, which requires the function to be proper closed and coercive; while \ref{weier1_continus} requires the function to be continuous), there exists a global minimizer of $f$ over $\sS \cap \sB[0, B]$ and hence also over $\sS$.
\end{proof}


\subsection{Constrained Optimization over Convex Sets}\label{section:constr_convset}

%Additionally, Theorem~\ref{theorem:fermat_fist_opt_int} can only apply to the interior local optimal points and does not apply to boundary points of the domain of $f$ or to points where $f$ is not differentiable. We need a more general optimality condition for constrained optimization problem (P2).
We restrict the problem to be an optimization problem over a \textbf{convex} set $\sS$. 
In this setting, if the function $f$ is also convex, the problem becomes a \textit{convex optimization problem} (\S~\ref{section:convex_optimiz}).
 Previously, in Definition~\ref{definition:stat_point}, we introduced stationary points for unconstrained problems. In contrast, constrained problems necessitate a different definition.
\begin{definition}[Stationary Points of Constrained Problems on a Convex Set]\label{definition:stat_point_uncons_convset}
	Consider the constrained optimization problem (P2) in Definition~\ref{definition:opt_probs_all}.
	Let $f$ be a continuously differentiable function over a closed \textbf{convex} set $\sS$. Then $\bx^* \in \sS$ is called a stationary point of (P2) if $\nabla f(\bx^*)^\top (\bx - \bx^*) \geq 0$ for any $\bx \in \sS$.
\end{definition}

%\begin{remark}[Stationarity of Constrained Problems and Functions]
Note that Definition~\ref{definition:stat_point} defines  stationary points for functions; while Definition~\ref{definition:stat_point_uncons_convset} pertains to the definition of stationary points for optimization problems.
%\end{remark}

%Stationarity actually means that there are no feasible descent directions of $f$ at $\bx^*$ (Definition~\ref{definition:uncons_des_direct}). This suggests that stationarity is in fact a necessary condition for a local minimum of (P2), assuming $f$ is continuously differentiable  over a closed convex set $\sS$.






\begin{theoremHigh}[First-Order Necessary Condition for (P2) on a Convex Set]\label{theorem:stat_point_uncons_convset}
Consider the constrained optimization problem (P2) in Definition~\ref{definition:opt_probs_all}.
Let $f$ be a continuously differentiable function over a closed \textbf{convex} set $\sS$, and let $\bx^*$ be a local minimum of (P2). Then $\bx^*$ is a stationary point of (P2).
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:stat_point_uncons_convset}]
Let $\bx^*$ be a local minimum of (P2), and assume in contradiction that $\bx^*$ is not a stationary point of (P2). Then there exists $\bx \in \sS$ such that $\nabla f(\bx^*)^\top (\bx - \bx^*) < 0$. By Lemma~\ref{lemma:descent_property}, it follows that there exists $\varepsilon \in (0, 1)$ such that $f(\bx^* + \mu \bd) < f(\bx^*)$ for all $\mu \in (0, \varepsilon)$, where $\bd\triangleq \bx-\bx^*$. Since $\sS$ is convex we have that $\bx^* + \mu \bd = (1 - \mu)\bx^* + \mu\bx \in \sS$, leading to the conclusion that $\bx^*$ is not a local minimum point of (P2), which results in a contradiction to the assumption that $\bx^*$ is a local minimum point of (P2).
\end{proof}

When the projection onto the convex set $\sS$ can be expressed in a closed-form, the necessity and sufficiency of the first-order condition has the following result.
\begin{theoremHigh}[Necessity/Sufficiency for (P2) on a Convex Set under Projection]\label{theorem:stat_point_uncons_convset_proj}
Consider the constrained optimization problem (P2) in Definition~\ref{definition:opt_probs_all}.
Let $f$ be a continuously differentiable function over a closed \textbf{convex} set $\sS$, and let $\eta > 0$ be an arbitrary positive scalar. Then $\bx^*$ is a stationary point (P2)
if and only if
$$
\bx^* = \projectS(\bx^* - \eta \nabla f(\bx^*)).
$$
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:stat_point_uncons_convset_proj}]
By the Projection Property-I (Lemma~\ref{lemma:proj_prop1}), it follows that $\bx^* = \projectS(\bx^* - \eta \nabla f(\bx^*))$ if and only if
$$
\begin{aligned}
&\innerproduct{\bx^* - \eta \nabla f(\bx^*) - \bx^*, \bx - \bx^*} \leq 0 \\
&\quad \implies\quad \nabla f(\bx^*)^\top (\bx - \bx^*) \geq 0, \text{ for any } \bx \in \sS.
\end{aligned}
$$
This completes the proof.
\end{proof}

\subsection{Convex Optimization: Unconstrained}\label{section:convex_opt_uncons}

Subdifferential sets are extremely useful in characterizing minimum points. 
One of the most fundamental optimality conditions states that a point is a global minimum of a proper extended real-valued convex function if and only if $\bzero$ belongs to the subdifferential set at the point. In essence, this is a generalization of Fermat's optimality condition at points of differentiability: $\nabla f(\bx^*) = \bzero$. 
\begin{theoremHigh}[Necessity/Sufficiency  of Unconstrained Convex]\label{theorem:fetmat_opt}
	Let $f: \real^n \rightarrow (-\infty, \infty]$ be a proper convex function. Then,
	$$
	\bx^* \in \mathop{\argmin}_{\bx \in \real^n}f(\bx) 
	$$
	if and only if $\bzero \in \partial f(\bx^*)$.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:fetmat_opt}]
	By the definition of the subgradient (Definition~\ref{definition:subgrad}), it holds that $\bx^* \in \mathop{\argmin}_{\bx \in \real^n}f(\bx) $ if and only if 
	$$
	f(\bx) \geq f(\bx^*) + \innerproduct{\bzero, \bx - \bx^*} \quad \text{for any }  \bx \in \domain(f),
	$$
	which is the same as the inclusion $\bzero \in \partial f(\bx^*)$.
\end{proof} 

A direct consequence of Theorem~\ref{theorem:fetmat_opt} and the Proximal Property-I (Lemma~\ref{lemma:prox_prop1}) is that for a proper closed and convex function, $ \bx = \proxf(\bx) $ if and only if $ \bx $ is a minimizer of $ f $.
\begin{theoremHigh}[Necessity/Sufficiency  of Unconstrained Convex Optimization Under Proximal]\label{theorem:opt_cond_prox}
Let $ f:  \real^n \rightarrow (-\infty, \infty]  $ be a proper closed and convex function. Then, $ \bx^* $ is a minimizer of $ f $ if and only if $ \bx^* = \proxf(\bx^*) $.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:opt_cond_prox}]
By Theorem~\ref{theorem:fetmat_opt}, $ \bx^* $ is a minimizer of $ f $ if and only if $ \bzero \in \partial f(\bx^*) $, that is, if and only if $\bx^* - \bx^* \in \partial f(\bx^*) $, which, by the Proximal Property-I (Lemma~\ref{lemma:prox_prop1}),  is the same as $ \bx^* = \proxf(\bx^*) $.
\end{proof}

\subsection{Convex Optimization: Constrained}\label{section:convex_optimiz}

A \textit{convex optimization problem} (or simply a convex problem) involves minimizing a convex function over a convex set:
\begin{equation}\label{equation:convex_optim1} 
\textbf{(Convex Optimization)}:\qquad
\begin{aligned}
&\min \quad f(\bx) \quad &&\text{(convex function)}\\
&\text{s.t.}\quad \bx\in\sS \quad &&\text{(convex set)}.
\end{aligned}
\end{equation}



\begin{theorem}[Local is Global in Convex Optimization]\label{theorem:local_glob_conv}
Let $f: \sS \rightarrow \real$ be a convex function (resp. strictly convex function) defined over the convex set $\sS$. 
If $\bx^* \in \sS$ be a local minimum of $f$ over $\sS$, then $\bx^*$ is the global minimum (resp. strict global minimum) of $f$ over $\sS$.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:local_glob_conv}]
Since $\bx^*$ is a local minimum of $f$ over $\sS$, there exists a scalar $\tau > 0$ such that $f(\bx) \geq f(\bx^*)$ for any $\bx \in \sS$ satisfying $\bx \in \sB[\bx^*, \tau]$. Now let $\by \in \sS$ satisfy $\by \neq \bx^*$. It suffices to show that $f(\by) \geq f(\bx^*)$. Let $\lambda \in (0, 1]$ be such that $\bx^* + \lambda(\by - \bx^*) \in \sB[\bx^*, \tau]$. An example of such $\lambda$ is $\lambda = \frac{\tau}{\normtwo{\bx^* - \by}}$. Since $\bx^* + \lambda(\by - \bx^*) \in \sB[\bx^*, \tau] \cap \sS$, it follows that
$
f(\bx^*) \leq f(\bx^* + \lambda(\by - \bx^*)),
$
and hence by Jensen's inequality
$
f(\bx^*) \leq f(\bx^* + \lambda(\by - \bx^*)) \leq (1 - \lambda) f(\bx^*) + \lambda f(\by).
$
Therefore, we obtain $f(\bx^*) \leq f(\by)$.

A slight modification of the above argument shows that any local minimum of a strictly convex function over a convex set is indeed  a strict global minimum of the function over the set.
\end{proof}



The optimal set of the convex problem \eqref{equation:convex_optim1}  is the set of all minimizers, that is, $\sX^*=\argmin\{f(\bx) : \bx \in \sS\}$. This definition of an optimal set is also valid for general problems. 
A notable property of convex problems is that their optimal sets are also convex.



\begin{theorem}[Convexity of the Optimal Set in Convex Optimization]\label{theorem:stric_op_str_conv}
Let $f: \sS \rightarrow \real$ be a convex function defined over the convex set $\sS \subseteq \real^n$. Then the set of optimal solutions of the problem,
$
\sX^*=\argmin\{f(\bx) : \bx \in \sS\},
$ 
is convex. If, in addition, $f$ is strictly convex over $\sS$, then there exists \textbf{at most one} optimal solution.
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:stric_op_str_conv}]
If $\sX^* = \varnothing$, the result follows trivially. 
We then assume that $\sX^* \neq \varnothing$ and denote the optimal value by $f^*$. Let $\bx, \by \in \sX^*$ and $\lambda \in [0, 1]$. Then, by Jensen's inequality $f(\lambda \bx + (1 - \lambda) \by) \leq \lambda f^* + (1 - \lambda) f^* = f^*$, and hence $\lambda \bx + (1 - \lambda) \by$ is also optimal, i.e., belongs to $\sX^*$, establishing the convexity of $\sX^*$. Suppose now that $f$ is strictly convex and $\sX^*$ is nonempty; to show that $\sX^*$ is a singleton, suppose in contradiction that there exist $\bx, \by \in \sX^*$ such that $\bx \neq \by$. Then $\frac{1}{2}\bx + \frac{1}{2}\by \in \sS$, and by the strict convexity of $f$ we have
$$
f\left(\frac{1}{2}\bx + \frac{1}{2}\by\right) < \frac{1}{2}f(\bx) + \frac{1}{2}f(\by) = \frac{1}{2}f^* + \frac{1}{2}f^* = f^*,
$$
which leads to a contradiction to the fact that $f^*$ is the optimal value.
\end{proof}

For strictly quasi-convex functions (Definition~\ref{definition:quasi_convex}), we have the following theorem concerning the existence and uniqueness of solutions:
\begin{theorem}[Unique Miminizer of Closed Strictly Quasi-Convex Functions]\label{theorem:uni_qua_conv}
Let $\sS$ be a nonempty, closed, and convex subset of $\real^n$, and let $f: \sS \rightarrow (-\infty, +\infty]$ be a proper, closed, and strictly quasi-convex function. Then there exists a unique $\bx^*$ such that
$$
f(\bx^*) < f(\bx), \quad \forall \bx \in \sS \setminus \{\bx^*\}.
$$
\end{theorem}
\begin{proof}[of Theorem~\ref{theorem:uni_qua_conv}]
By the Weierstrass theorem (Theorem~\ref{theorem:weierstrass_them}), $f$ has at least one global minimizer $\bx^*$. Suppose there is another global minimizer $\by^*$; then $f(\bx^*) = f(\by^*)$. According to the definition of a strictly quasi-convex function (Definition~\ref{definition:quasi_convex}), for any $\lambda\in(0,1)$, we have
$$
f(\lambda \bx^* + (1 - \lambda)\by^*) < \max\{f(\bx^*), f(\by^*)\} = f(\bx^*),
$$
which contradicts the global optimality of $\bx^*$.
\end{proof}
From the definition of a strictly quasi-convex function, any strictly convex function is also strictly quasi-convex, but a convex function is not necessarily strictly quasi-convex. Using the above conclusion, for any closed strictly convex function defined on a bounded convex set (such as $f(x) = x^2$), its optimal solution is unique. However, for a general convex function, the optimal solution may not be unique. For example, the function $f(x) = \max\{x, 0\}$ has any $x \leq 0$ as an optimal solution.

Stationarity is a \textbf{necessary optimality condition} for local optimality. However, when the objective function is additionally assumed to be convex, stationarity is a \textbf{necessary and sufficient condition} for optimality.

\begin{theoremHigh}[Necessity/Sufficiency  of Constrained Convex]\label{thm:conv_stationary_optimality}
Let $ f:\sS\subseteq\real^n\rightarrow\real $ be a continuously differentiable convex function over a closed and convex set $ \sS$. Then $ \bx^* $ is a stationary point  (Definition~\ref{definition:stat_point_uncons_convset}) of 
$$
\text{(P2+Convex)} \qquad \min_{\bx \in \sS} f(\bx)
$$
if and only if $ \bx^* $ is an optimal solution of (P2+Convex).
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{thm:conv_stationary_optimality}]
If $ \bx^* $ is an optimal solution of (P2+Convex), then by Theorem~\ref{theorem:stat_point_uncons_convset}, it follows that $ \bx^* $ is a stationary point of (P2+Convex). To prove the sufficiency of the stationarity condition, assume that $ \bx^* $ is a stationary point (Definition~\ref{definition:stat_point_uncons_convset}) of (P2+Convex). For any $ \bx \in \sS $, we have:
$$
f(\bx) \geq f(\bx^*) + \nabla f(\bx^*)^\top (\bx - \bx^*) \geq f(\bx^*),
$$
where the first inequality follows from the gradient inequality for convex functions (Theorem~\ref{theorem:conv_gradient_ineq}), and the second inequality follows from the definition of a stationary point (Definition~\ref{definition:stat_point_uncons_convset}). This shows that $ \bx^* $ is indeed the global minimum point of (P2+Convex), completing the proof.
\end{proof}


\begin{theoremHigh}[Sufficiency of Stationarity of Constrained Convex]\label{theorem:suff_sta_conv}
Let $ f:\sS\subseteq\real^n\rightarrow \real $ be a continuously differentiable and convex function defined on a convex set $ \sS $. Suppose that $ \nabla f(\bx^*) = \bzero $ for some $ \bx^* \in \sS $. Then $ \bx^* $ is a global minimizer of $ f $ over $ \sS $.
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:suff_sta_conv}]
Let $ \bz \in \sS $. Plugging $ \bx = \bx^* $ and $ \by = \bz $ in the gradient inequality (Theorem~\ref{theorem:conv_gradient_ineq}), we obtain that
$$
f(\bz) \geq f(\bx^*) + \nabla f(\bx^*)^\top (\bz - \bx^*),
$$
which by the fact that $ \nabla f(\bx^*) = \bzero $ implies that $ f(\bz) \geq f(\bx^*) $, thus establishing that $ x^* $ is the global minimizer of $ f $ over $ \sS $. 
\end{proof}
Note that Theorem~\ref{theorem:suff_sta_conv} establishes only the sufficiency of the stationarity condition (of the function, not the problem; see Definition~\ref{definition:stat_point} and Definition~\ref{definition:stat_point_uncons_convset}) $\nabla f(\bx^*) = \bzero$ for guaranteeing that $\bx^*$ is a global optimal solution. When $\sS$ is not the entire space, this condition is not necessary . However, when $\sS=\real^n$, then by Theorem~\ref{theorem:fermat_fist_opt} (necessary condition for local optima) and  Theorem~\ref{theorem:local_glob_conv} (local=optimal for convex cases),  this becomes both a necessary and sufficient condition; the same argument in Theorem~\ref{theorem:fetmat_opt}.


\begin{example}[Equality and Inequality Constraints]
Consider the following problem:
\begin{equation}\label{equation:conv_eqineq_const}
\begin{aligned}
\min & \quad f(\bx) \\
\text{s.t.} & \quad g_i(\bx) \leq 0, \quad i = \{1, 2, \ldots, m\},\\
&\quad h_j(\bx) = 0, \quad j = \{1,2, \ldots, p\},
\end{aligned}
\end{equation}
where $f, g_1, g_2, \ldots,g_m:\real^n\rightarrow \real$ are convex functions, and $h_1, h_2, \ldots,h_p$ are affine functions.
Since the objective function is convex and the feasible set is a convex set, this problem is a convex optimization problem.
The feasible set can be written as
$$
\sS = \bigg( \bigcap_{i=1}^m \lev[g_i, 0] \bigg) \cap \bigg( \bigcap_{j=1}^p \{ \bx \mid  h_j(\bx) = 0 \} \bigg),
$$
which is a convex set since $\sS$ is  an intersection of level sets of convex functions and hyperplanes, both of which are also convex sets.
\end{example}

\begin{example}[Linear Programming (LP)]\label{example:linear_program}
A \textit{linear programming (LP) problem}  involves minimizing a linear objective function subject to linear equalities and inequalities:
$$
\text{(LP)}\qquad 
\begin{aligned}
\min & \quad \bc^\top \bx +d \\
\text{s.t.}
&\quad \bG\bx \leq \bh, \\
&\quad \bA\bx = \bb,
\end{aligned}
$$
where $ \bG \in \real^{m \times n} $, $ \bh \in \real^m $, $ \bA \in \real^{p \times n} $, $ \bb \in \real^p $, and $ \bc \in \real^n $. 
This constitutes a convex optimization problem since affine functions are inherently convex. The constant $d$ in the objective function can be omitted without affecting the optimal set.
Consider the following LP problem:
$$
\text{(Standard LP)}\qquad 
\begin{aligned}
\min & \quad \bc^\top \bx \\
\text{s.t.} & \quad \bA\bx = \bb, \\
& \quad \bx \geq \bzero.
\end{aligned}
$$
This formulation is often referred to as the ``standard form" of LP in literature.
To convert an LP to its standard form, we can  introduce nonnegative slack variables $\bs$  such that $\bG\bx +\bs=  \bh$ and   express $\bx$ as the difference of two nonnegative variables $\bx\triangleq\bx^+-\bx^-$, where $\bx^+, \bx^-\geq \bzero$:
$$
\text{(LP$'$)}\qquad 
\begin{aligned}
\min & \quad \bc^\top \bx^+ - \bc^\top\bx^- +d \\
\text{s.t.}
&\quad \bG\bx^+ - \bG\bx^-  +\bs=  \bh,   \\
&\quad \bA\bx^+ - \bA\bx^-  = \bb, \\
&\quad \bs \geq \bzero, \bx^+ \geq \bzero, \bx^-\geq \bzero, 
\end{aligned}
\quad\iff \quad
\begin{aligned}
\min & \quad [\bc^\top , - \bc^\top, \bzero] \widetildebx +d \\
\text{s.t.}
&\quad  [\bG, -\bG, \bI] \widetildebx =\bh,   \\
&\quad [\bA, - \bA, \bzero ] \widetildebx  = \bb, \\
&\quad \widetildebx \geq \bzero, 
\end{aligned}
$$
where 
$
\widetildebx\triangleq
\scriptsize
\begin{bmatrix}
\bx^+ \\  \bx^- \\\bs 
\end{bmatrix}
$. This is in a standard form with variables $\widetildebx$. For each feasible solution $\bx^*$ of (LP), we can set $\bs\triangleq\bh-\bG\bx^*$, $x_i^+\triangleq \max\{0, x_i\}$, and $x_i^-\triangleq \max\{0, -x_i\}$ for all $i\in\{1,2,\ldots, n\}$, which is a feasible solution of (LP$'$). This shows the optimal value of (LP$'$) is less than or equal to the optimal value of (LP). 
Conversely, suppose $\bx^+, \bx^-$, and $\bs$ are feasible solutions of (LP$'$). Then, $\bx\triangleq\bx^+-\bx^-$ is a feasible solution of (LP), demonstrating that the optimal value of (LP) is less than or equal to the optimal value of (LP$'$).  Therefore, the optimization problems (LP) and (LP$'$) are equivalent.
\end{example}

\begin{example}[Quadratic Programming]
The convex optimization problem \eqref{equation:conv_eqineq_const} is called a \textit{quadratic program (QP)} if the objective function is quadratic with positive semidefinite (convex), and the constraint functions  are affine. A general form can be written as:
$$
\begin{aligned}
\text{min}& \quad \bx^\top \bP \bx + 2 \bq^\top \bx + r \\
\text{s.t.} & \quad \bG\bx \leq \bh, \\
&\quad \bA\bx=\bb,
\end{aligned}
$$
where $\bP \in \real^{n \times n}$ is positive semidefinite, $\bq \in \real^n$, $\bG\in\real^{m\times n}$, $\bh\in\real^m$, $\bA \in \real^{p \times n}$, and $\bb \in \real^p$. 
If both the objective function and inequality constraints are convex quadratic:
$$
\begin{aligned}
\text{min}& \quad \bx^\top \bP \bx + 2 \bq^\top \bx + r \\
\text{s.t.} & \quad \bx^\top\bG_i\bx + 2\bh_i^\top\bx+ c_i \leq 0,\quad i=\{1,2,\ldots,m\},\\
&\quad \bA\bx=\bb,
\end{aligned}
$$
where $\bP, \bG_1, \bG_2, \ldots,\bG_m$ are positive semidefinite, the problem is called a \textit{quadratically constrained quadratic program (QCQP)}.
In a QCQP, we minimize a convex quadratic function over a feasible region that is the intersection of ellipsoids when $\bG_i\succ \bzero$.
\end{example}




\subsection{Non-Convex Composite Optimization}
We finally consider optimality conditions for a composite problem (P3) as defined in Definition~\ref{definition:opt_probs_all}:
$$
\textbf{(P3)}:\qquad \text{Find}\quad \bx^* = \mathop{\argmin}_{\bx} \left\{F(\bx)\triangleq f(\bx)+g(\bx) \right\}.
$$
\begin{theoremHigh}[Optimality Conditions for the Composite Problem (P3)]\label{theorem:opt_cond_p3}
Let $f: \real^n \rightarrow (-\infty, \infty]$ be a \textcolor{black}{proper} function, and let $g: \real^n \rightarrow (-\infty, \infty]$ be a \textcolor{black}{proper} \textbf{convex} function such that $\dom(g) \subseteq \interior(\dom(f))$. Then, problem (P3) has the following properties: 
\begin{enumerate}[(i)]
\item  \textit{Necessary condition.} If $\bx^* \in \dom(g)$ is a local optimal solution of (P3) and $f$ is differentiable at $\bx^*$, then
\begin{equation}\label{equation:opt_cond_p3_e1}
-\nabla f(\bx^*) \in \partial g(\bx^*).
\end{equation}

\item \textit{Necessary and sufficient condition for convex problems.} Suppose additionally that $f$ is convex. If $f$ is differentiable at $\bx^* \in \dom(g)$, then $\bx^*$ is a global optimal solution of (P3) if and only if \eqref{equation:opt_cond_p3_e1} is satisfied.
\end{enumerate}
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:opt_cond_p3}]
\textbf{(i).} Let $\by \in \dom(g)$. By the convexity of $\dom(g)$, for any $\lambda \in (0, 1)$, the point $\bx_\lambda = (1 - \lambda)\bx^* + \lambda \by$ is in $\dom(g)$. 
By the local optimality of $\bx^*$, it follows that, for sufficiently small $\lambda$,
$$
\begin{aligned}
&f(\bx_\lambda) + g(\bx_\lambda) \geq f(\bx^*) + g(\bx^*)\\
&\implies\quad f\big((1 - \lambda)\bx^* + \lambda \by\big) + g\big((1 - \lambda)\bx^* + \lambda \by\big) \geq f(\bx^*) + g(\bx^*).
\end{aligned}
$$
Using the convexity of $g$, it follows that
$$
\begin{aligned}
&f\big((1 - \lambda)\bx^* + \lambda \by\big) + (1 - \lambda)g(\bx^*) + \lambda g(\by) \geq f(\bx^*) + g(\bx^*)\\
&\implies\quad \frac{f\big((1 - \lambda)\bx^* + \lambda \by\big) - f(\bx^*)}{\lambda} \geq g(\bx^*) - g(\by).
\end{aligned}
$$
Taking $\lambda \rightarrow 0^+$ in the above inequality and by \eqref{equation:direc_contdiff}: $f^\prime(\bx^*; \by - \bx^*) = \innerproduct{\nabla f(\bx^*), \by - \bx^*}$), we have
$$
f^\prime(\bx^*; \by - \bx^*) =\innerproduct{\nabla f(\bx^*), \by - \bx^*}\geq g(\bx^*) - g(\by),
$$
where we used the fact that since $f$ is differentiable at $\bx^*$, its directional derivatives exist. 
Therefore, for any $\by \in \dom(g)$,
$$
g(\by) \geq g(\bx^*) + \innerproduct{-\nabla f(\bx^*), \by - \bx^*},
$$
showing that indeed $-\nabla f(\bx^*) \in \partial g(\bx^*)$.

\paragraph{(ii).} Suppose further that $f$ is convex. If $\bx^*$ is an optimal solution of (P3), then we have already shown in part (i) that \eqref{equation:opt_cond_p3_e1} is satisfied. Now assume that \eqref{equation:opt_cond_p3_e1} is satisfied. Then, for any $\by \in \dom(g)$,
\begin{equation}\label{equation:opt_cond_p3_ii1}
g(\by) \geq g(\bx^*) + \innerproduct{-\nabla f(\bx^*), \by - \bx^*}.
\end{equation}
By the convexity of $f$, for any $\by \in \dom(g)$,
\begin{equation}\label{equation:opt_cond_p3_ii2}
f(\by) \geq f(\bx^*) + \innerproduct{\nabla f(\bx^*), \by - \bx^*}.
\end{equation}
Adding \eqref{equation:opt_cond_p3_ii1} and \eqref{equation:opt_cond_p3_ii2}, we find
$$
f(\by) + g(\by) \geq f(\bx^*) + g(\bx^*), \text{ for any $\by \in \dom(g)$}.
$$
This proves that $\bx^*$ is an optimal solution of (P3).
\end{proof}

Note that Definition~\ref{definition:stat_point} defines  stationary points for functions; while Definition~\ref{definition:stat_point_uncons_convset} pertains to the definition of stationary points for optimization problems.
The condition \eqref{equation:opt_cond_p3_e1} is an important optimality condition for the composite problem (P3), and we will refer
to it as the ``stationarity" condition of (P3). Their comparison is shown in \eqref{equation:stationar_p123}.
\begin{definition}[Stationarity of (P3)]\label{definition:stat_opt_cond_p3}
Consider the problem (P3) in Definition~\ref{definition:opt_probs_all}. Let $f: \real^n \rightarrow (-\infty, \infty]$ be \textcolor{black}{proper}, and let $g: \real^n \rightarrow (-\infty, \infty]$ be a \textcolor{black}{proper} \textbf{convex} function such that $\dom(g) \subseteq \interior(\dom(f))$. 
A point $\bx^*$ in which $f$ is differentiable is called a \textit{stationary point} of (P3) if
\begin{equation}
-\nabla f(\bx^*) \in \partial g(\bx^*).
\end{equation}
\end{definition}


\section{Constrained Optimization: Equality/Inequality Constraints}\label{section:gen_kkt_cond}
We have already observed that finding global solutions can be challenging in the absence of constraints (Remark~\ref{remark:charac_statpoint}). However, introducing constraints can improve the situation. The feasible set may exclude many local minima, making it easier to identify the global minimum from the remaining candidates.

In Section~\ref{section:constrain_opt}, we introduced optimality conditions for constrained optimization problems that do not rely on the algebraic specification of the set $\sS$, but rather on its geometric properties. This section addresses the optimality conditions that depend on the algebraic specifications, specifically equality and inequality constraints, as seen in problem (P4) of Definition~\ref{definition:opt_probs_all}. For simplicity, we use different letters for the equality and inequality constraints:
\begin{equation}\label{equation:P4_in_kkt}
(\text{P4}')\qquad 
\begin{aligned}
\min & \quad f(\bx) \\
\text{s.t.} & \quad g_i(\bx) \leq 0, \quad i = \{1, 2, \ldots, m\} \triangleq\mathcalI,\\
&\quad h_j(\bx) = 0, \quad j = \{1,2, \ldots, p\}\triangleq\mathcalE.
\end{aligned}
\end{equation}
That is, the \textit{feasible set} is $\sS = \{\bx \mid g_i(\bx) \leq 0, i\in\mathcalI;    h_j(\bx) = 0, j\in \mathcalE\}$.
For the sake of convenience,  any constraint (either equality or inequality) can be denoted by 
$$
c_i, \quad i \in \mathcalE \cup \mathcalI,
$$
where $c_i(\bx) = g_i(\bx)$ if $i\in\mathcalI$ and  $c_i(\bx) = h_i(\bx)$ if $i\in\mathcalE$.






\subsection{Mathematical Tools}
Before delving into the optimality conditions of $(\text{P4}')$, we provide some mathematical background.
Let $\bg(\bx) \triangleq \left\{g_{i}(\bx)\right\}_{i\in\{1,2,\ldots,m\}}:\real^n\rightarrow \real^{m}$ and $\bh(\bx) \triangleq \left\{h_{i}(\bx)\right\}_{i\in\{1,2,\ldots,p\}}:\real^n\rightarrow \real^{p}$. Then
\begin{equation}\label{equation:jacob_inkkt}
\nabla \bg(\bx) = 
\begin{bmatrix}
\nabla g_1(\bx)^\top \\
\nabla g_2(\bx)^\top \\
\vdots \\
\nabla g_m(\bx)^\top \\
\end{bmatrix}
\in\real^{m\times n}
\qquad \text{and}\qquad 
\nabla \bh(\bx) = 
\begin{bmatrix}
\nabla h_1(\bx)^\top \\
\nabla h_2(\bx)^\top \\
\vdots \\
\nabla h_p(\bx)^\top \\
\end{bmatrix}
\in\real^{p\times n}
\end{equation}
are Jacobian matrices, where each row corresponds to the transpose of the gradient of the respective function.
\begin{definition}[Sets of (P4$'$)]\label{definition:setsp4prime}
Given a  point $\bx$ in $(\text{P4}')$, we define the following sets: 
\begin{itemize}
	\item $\sD(\bx) \triangleq \{\bd \mid \nabla f(\bx)^\top \bd < 0\}$, the cone (Definition~\ref{definition:convex_cone}) of ``improving" directions of $f(\bx)$  at   $\bx$  (not including the origin $\bzero$ in the cone), i.e., the set of descent directions (Definition~\ref{definition:uncons_des_direct}) at $\bx$.
	\item $\sI(\bx)\triangleq \{i \mid g_i(\bx) = 0\}$, the set of indices of the binding inequality constraints at $\bx$, i.e., the set of active constraints.
	\item $\sG(\bx)\triangleq \{\bd \mid \nabla g_i(\bx)^\top \bd < 0 \text{ for all } i \in \sI(\bx) \}$, the cone of ``inward" pointing directions for the binding constraints at $\bx$, (not including the origin $\bzero$ in the cone).
	\item $\sH(\bx)\triangleq \{\bd \mid \nabla h_i(\bx)^\top \bd = 0 \text{ for all } i = 1,2, \ldots, p\}$, the set of tangent directions for the equality constraints at $\bx$.
	\item $\sA(\bx)\triangleq \sI(\bx) \cup \mathcalE$, the set of union of active constraints and equality constraints, i.e., the \textit{general active set}.
\end{itemize}
\end{definition}


From an introductory course in optimization, there is an important relationship between $ \bg^* $, the gradient of the cost function, and $ \ba_i^* $ ($i\in \mathcalI\cup \mathcalE$), the gradients of the constraint functions, all evaluated at a local minimizer. This leads to the introduction of the \textit{Lagrangian function}:
\begin{definition}[Lagrange's Function]\label{definition:lag_func}
Given the differentiable objective function $ f $ and the constraints $ c_i, i=1, 2, \ldots, q $, where $q \triangleq m+p$ is the total number of constraints for problem (P4$'$) in \eqref{equation:P4_in_kkt}. \textit{Lagrange's function (or Lagrangian function)} is defined as:
$$
L(\bx, \blambda) = f(\bx) - \sum_{i=1}^{q} \lambda_i c_i(\bx).
$$
The scalars $ \left\{ \lambda_i \right\} $ are called \textit{Lagrangian multipliers}.
The gradient of $ L $ with respect to $ \bx $ is denoted by $ \nabla_{\bx} L \triangleq \nabla L $, and we see that
$$
\nabla_{\bx} L(\bx, \blambda) = \nabla f(\bx) - \sum_{i=1}^{q} \lambda_i \nabla c_i(\bx).
$$
\end{definition}



When characterizing the directions in which we can step away from $\bx$ while remaining feasible, 
a related concept is called \textit{tangent}, which is a limiting direction of a feasible sequence.

\begin{definition}[Tangent Vector, Tangent Cone]
The vector $\bd$ is said to be a \textit{tangent (or tangent vector)} to the set $\sS$ at a point $\bx\in\sS$ if there are a feasible sequence $\{\bu^\toptzero\}_{t>0}$ approaching $\bx$ and a sequence of positive scalars $\{c_t\}_{t>0}$ with $c_t \to 0$ such that
\begin{equation}
	\lim_{t \to \infty} \frac{\bu^\toptzero - \bx}{c_t} = \bd.
\end{equation}
The set of all tangents to $\sS$ at $\bx$ is called the \textit{tangent cone} and is denoted by $\mathcalT_\sS(\bx)$.
\end{definition}


It is easy to see that the tangent cone is indeed a cone (Definition~\ref{definition:convex_cone}). If $\bd$ is a tangent vector with corresponding sequences $\{\bu^\toptzero\}$ and $\{c_t\}$, then by replacing each $c_t$ by $\alpha^{-1} c_t$, for any $\alpha > 0$, we find that $\alpha \bd \in \mathcalT_\sS(\bx^*)$. We obtain that $\bzero \in \mathcalT_\sS(\bx)$ by setting $\bu^\toptzero \triangleq \bx$ in the definition of feasible sequence.

We turn now to the \textit{linearized feasible direction set}, which we define as follows.

\begin{definition}[(Linearized, Sequential) Feasible Directions]\label{definition:lfd_sfd}
Let $\bx\in\sS$ be a feasible point. If there exists $\varepsilon>0$ such that $\bx+\mu\bd\in\sS$ for all $\mu\in[0, \varepsilon]$, then $\bd$ is called a \textit{feasible direction} of $\sS$ at $\bx$. The set of all feasible directions of $\sS$ at $\bx$ is denoted as 
$$
\fd(\bx) \triangleq \left\{\bd\neq\bzero \mid \bx + \mu\bd \in \sS, \forall \mu\in[0, \varepsilon]\right\}.
$$
Given further the general active set $\sA(\bx)\triangleq\sI(\bx) \cup \mathcalE$ of Definition~\ref{definition:setsp4prime}, the set of \textit{linearized feasible directions}, denoted as $\lfd(\bx)$, is
$$
\lfd(\bx) \triangleq \left\{ \bd \; \middle| \;
\begin{array}{ll}
	\bd^\top \nabla c_i(\bx) = 0, & \text{for all } i \in \mathcalE, \\
	\bd^\top \nabla c_i(\bx) \leq  0, & \text{for all } i \in \sI(\bx)
\end{array}
\right\}.
$$
As with the tangent cone, it is easy to verify that $\lfd(\bx)$ is a cone.
If there exist sequences $\{\bd^\toptzero\}_{t>0}$ and $\{\mu_t>0\}_{t>0}$ such that $\bx^\toptzero\triangleq\bx+\mu_t\bd^\toptzero \in\sS$ for all $t>0$ and $\bd^\toptzero\rightarrow\bd, \mu_t\rightarrow 0$, then the limiting direction $\bd$ is called the \textit{sequential feasible direction} of $\sS$ at $\bx$. The set of all sequential feasible directions of $\sS$ at $\bx$ is 
$$
\sfd(\bx) \triangleq \left\{ \bd \; \middle| \;
\begin{array}{ll}
\bx+\mu_t\bd^\toptzero\in\sS, & \forall t, \\
\bd^\toptzero\rightarrow \bd, \mu_t\rightarrow 0 &
\end{array}
\right\}.
$$
Note that 
\begin{itemize}
\item $\bx^\toptzero\neq \bx$ for all $t>0$.
\item $\lim_{t\to \infty}\bx^\toptzero = \bx$.
\item $\bx^\toptzero\in\sS$ for all $t$ sufficiently large.
\item If we set $\mu_t\triangleq\normtwo{\bx^\toptzero - \bx}$, then $\bd^\toptzero = \frac{\bx^\toptzero - \bx}{\normtwo{\bx^\toptzero - \bx}} \rightarrow \bd$. Therefore, 
$$
\mathcalT_\sS(\bx) = \sfd(\bx) \cup\{\bzero\}.
$$
\end{itemize}
\end{definition}
Note the difference between $\lfd(\bx)$ and $\sD(\bx)\triangleq \{\bd \mid \nabla f(\bx)^\top \bd < 0\}$ we have defined previously.
Intuitively speaking, vectors in the linearized feasible direction set $\lfd(\bx)$ should ensure that 
\begin{itemize}
\item The gradient of equality constraint functions remains perpendicular to these directions, thus preserving the value of $c_i(\bx)$, $i \in \mathcal{E}$ (or $h_j(\bx),  j = \{1,2, \ldots, p\}$).
\item  For the active constraints $\sI(\bx)=\sA(\bx) \cap \mathcal{I}$, the value of inequality constraint functions $g_i(\bx)$ should not increase along these directions. Therefore, the linearized feasible direction for $c_i(\bx)$, $i \in \sA(\bx) \cap \mathcal{I}$ (or $g_i(\bx),  i = \{1,2, \ldots, m\}$), can be a descent direction.
\end{itemize}
However, for constraints in the non-active set, there is no requirement for any specific direction in the linearized feasible direction set.



It is important to note that the definition of tangent cone does not rely on the algebraic specification of the set $\sS$, only on its geometry. The linearized feasible direction set does, however, depend on the definition of the constraint functions $c_i$, $i \in \mathcalE \cup \mathcalI$.





Using the definition of general active set $ \sA(\bx) $, we define the notion of linear independence constraint qualification (LICQ), the importance of which will be clear in the sequel.
\index{Linear independence constraint qualification}
\index{LICQ}
\begin{definition}[Linear Independence Constraint Qualification (LICQ)]\label{definition:licq}
Consider the problem in \eqref{equation:P4_in_kkt}.
Given a feasible point $ \bx $ and the corresponding general active set $ \sA(\bx) $. If the gradients of the constraint functions corresponding to the active set, i.e., $ \nabla c_i(\bx), i \in \sA(\bx) $ ($c_i$ can be either the equality constraint or the inequality constraint function), are linearly independent, then the \textit{linear independence constraint qualification (LICQ)} holds at the point $ \bx $.
\end{definition}






We end up this subsection by providing Farkas' lemma and its variants, which is a necessary tool for proving the KKT conditions of $(\text{P4}')$ in the sequel.
\begin{lemma}[Farkas' Lemma and Variants]\label{lemma:farka_lemm}
Let $\bc \in \real^n$ and $\bA \in \real^{m \times n}$. Then \textbf{exactly one} of the following systems has a solution:
\begin{enumerate}[(i)]
\item $\bA\bx \leq \bzero, \bc^\top \bx > 0.$
\item $\bA^\top \by = \bc, \by \geq \bzero.$  (i.e., $\bc$ is a conic combination of rows of $\bA$.)
\end{enumerate}
\noindent Equivalently, this implies  the following two claims are equivalent:
\begin{enumerate}[(a)]
\item The implication $\bA\bx \leq \bzero \implies \bc^\top \bx \leq 0$ holds true.
\item There exists $\by\in \real_{+}^{m}$ such that $\bA^\top \by = \bc$.
\end{enumerate}

The above Farka's lemma also indicates the following result.
Given matrices $ \bD, \bE, $ and $ \bF $ of appropriate dimensions, \textbf{exactly one} of the following two systems has a solution:
\begin{enumerate}[(1)]
\item $ \bD\bx < \bzero, \bE \bx \leq \bzero, \bF \bx = \bzero, $
\item $ \bD^\top \bu + \bE^\top \bw + \bF^\top \bv = \bzero, $ $ \bu \geq \bzero, \bw \geq \bzero, \bone^\top \bu = 1. $
\end{enumerate}
\end{lemma}

\begin{proof}[of Lemma~\ref{lemma:farka_lemm}]
\textbf{(a)$\iff$(b).}
Since the system (i, ii) is equivalent to the system (a, b), we only prove the latter here.
Suppose that system (b) is feasible, meaning that there exists $\by\in \real_{+}^{m}$ such that $\bA^\top \by = \bc$. To see that the implication (a) holds, suppose that $\bA\bx \leq \bzero$ for some $\bx\in \real^{n}$. Since $\by$ is nonnegative, premultiplying the inequality $\bA\bx \leq \bzero$  by $\by^\top$ yields
$
\bc^\top\bx = \by^\top \bA\bx \leq \bzero,
$
where $\bc^\top = \by^\top \bA$ by system (b).

Conversely, assume that the implication (a) holds.  Suppose in contradiction that system (b) is infeasible, and consider the following closed and convex set:
$$
\sS = \left\{ \bu \in \real^n \mid  \bu = \bA^\top \by \text{ for some } \by \in \real_{+}^{m} \right\}.
$$
The closedness of $\sS$ follows from Exercise~\ref{exercise:closed_fini_cone}. The infeasibility of (b) means that $\bc \notin \sS$. By Theorem~\ref{theorem:stric_sep_theo}, it follows that there exists a vector $\bw \in \real^{m} \setminus \{\bzero\}$ and $\alpha \in \real$ such that 
\begin{equation}\label{equation:fakar_eq1}
\bw^\top \bc > \alpha
\qquad \text{and}\qquad 
\bw^\top \bu \leq \alpha \text{ for all } \bu \in \sS. 
\end{equation}
Since $\bzero \in \sS$, we can conclude that $\alpha \geq 0$, and hence also that $\bw^\top \bc > 0$. In addition, the second equality in \eqref{equation:fakar_eq1} is equivalent to
\begin{equation}\label{equation:fakar_eq2}
(\bA\bw)^\top \by=\bw^\top \bA^\top\by \leq \alpha, \text{ for all } \by \in \real_{+}^{m}.
\end{equation}
This implies that $\bA\bw \leq 0$. Indeed, if an index $i \in \{1,2,\ldots, m\}$ existed such that $(\bA\bw)_{i} > 0$, then choosing $\by \triangleq \gamma \be_{i}$ would result in $(\bA\bw)^\top \by = \gamma (\bA\bw)_{i}$, which is an expression that approaches $\infty$ as $\gamma \rightarrow \infty$. Taking a large enough $\gamma$ will contradict \eqref{equation:fakar_eq2}, thereby contradicting our assumption that implication (a) holds, leading us to conclude that system (b) must be feasible.



\paragraph{(1)$\iff$(2).}
Suppose (1) does not have a solution. Then the following system  has no solution:
$$
\begin{cases}
\bD\bx + \bone\gamma \leq \bzero, & \gamma > \bzero; \\
\bE\bx \leq \bzero; \\
\bF\bx \leq \bzero; \\
-\bF\bx \leq \bzero
\end{cases}
\quad\iff\quad
\begin{bmatrix}
\bD & \bone \\
\bE & \bzero \\
\bF & \bzero \\
-\bF & \bzero
\end{bmatrix}
\begin{bmatrix}
\bx \\
\gamma
\end{bmatrix}
\leq \bzero, \quad [0, \ldots, 0, 1] \cdot
\begin{bmatrix}
\bx \\
\gamma
\end{bmatrix}
> 0.
$$
From Farkas' lemma, there exists a vector $ [\bu; \bw; \bv^1; \bv^2] \geq 0 $ such that:
$$
\begin{bmatrix}
\bD & \bone \\
\bE & 0 \\
\bF & 0 \\
-\bF & 0
\end{bmatrix}^\top
\begin{bmatrix}
\bu \\
\bw \\
\bv^1 \\
\bv^2
\end{bmatrix}
=
\begin{bmatrix}
0 \\
\vdots \\
0 \\
1
\end{bmatrix}.
$$
This can be rewritten as:
$$
\bD^\top \bu + \bE^\top \bw + \bF^\top (\bv^1 - \bv^2) = 0 \,, \quad \bone^\top \bu = 1 \,.
$$
Setting $\bv \triangleq\bv^1 -\bv^2$ completes the proof.
\end{proof}


\subsection{KKT Conditions for Linearly Constrained Problems}
To begin, we suppose the equality and inequality constraints of (\text{P4}$'$) in \eqref{equation:P4_in_kkt} are linear functions.
Below, we outline the\textit{Karush-Kuhn-Tucker (KKT) conditions} for problems with linear constraints.

\begin{theoremHigh}[KKT Conditions for Linearly Constrained Problems, Theorem 10.7 in \citet{beck2014introduction}]\label{theorem:kktcond}
Consider the minimization problem
$$
(\text{P})\qquad
\begin{aligned}
\min & \quad f(\bx), \quad\\
\text{s.t.}&\quad g_i(\bx) =\ba_i^\top \bx - b_i\leq 0, \quad i\in\{1,2,\ldots, m\},\\
&\quad h_j(\bx)=\bc_j^\top\bx-d_j=0, \quad j\in\{1,2,\ldots, p\},
\end{aligned}
$$
where $f(\cdot)$ is  continuously differentiable over $\real^n$, $\ba_1,\ba_2,\ldots, \ba_m,\bc_1,\bc_2,\ldots, \bc_p\in\real^n$, and $b_1,b_2,\ldots,b_m, d_1,d_2,\ldots,d_p\in\real$.
Then, 
\begin{enumerate}[(i)]
\item \textbf{Necessity of the KKT conditions.}
Let $\bx^*$ be a local minimum point of (P). Then, there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that 
\begin{subequations}
\begin{align}
	&\nabla f(\bx^*) + \sum_{i=1}^{m} \lambda_i\ba_i +\sum_{j=1}^{p}\mu_j\bc_j=\bzero ,\label{equa:kkt1}\\
	&\lambda_i (\ba_i^\top\bx^*-b_i)=0, \quad i=\{1,2,\ldots, m\}. \label{equa:kkt2}
\end{align}
\end{subequations}
where \eqref{equa:kkt2} is called the \textit{complementary slackness} condition.

\item \textbf{Sufficiency in the convex case.} Suppose further that the function $f$ is convex over $\real^n$, and $\bx^*$ is a feasible solution of (P) for which there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that \eqref{equa:kkt1} and \eqref{equa:kkt2} are satisfied. Then, $\bx^*$ is an optimal solution of (P).
\end{enumerate}

Moreover, we can define the \textit{Lagrangian function} (Definition~\ref{definition:lag_func}):
$$
L(\bx, \blambda, \bmu) = f(\bx) + \sum_{i=1}^{m} \lambda_ig_i(\bx) + \sum_{j=1}^{p} \mu_jh_j(\bx).
$$
The KKT condition \eqref{equa:kkt1} can be derived  from setting the gradient of the Lagrangian function with respect to $\bx$ to zero:
$$
\nabla_{\bx} L(\bx, \blambda, \bmu) 
= \nabla f(\bx) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\bx) + \sum_{j=1}^{p} \mu_j \nabla h_j(\bx)
=\bzero.
$$
\end{theoremHigh}
To prove the desired result, we first need to establish the KKT conditions for linear inequality constraints as presented in \eqref{equation:kkt_ineq}. For brevity, these conditions are encapsulated within a single theorem.
\begin{proof}[of Theorem~\ref{theorem:kktcond}]
\textbf{(i).} Consider the equivalent problem
$$
(\text{P}^\prime)\qquad
\begin{aligned}
\min\;  f(\bx) \quad 
\text{s.t.}\quad &\ba_i^\top \bx - b_i\leq 0, \quad i\in\{1,2,\ldots, m\},\\
&\bc_j^\top\bx-d_j\leq 0, \quad j\in\{1,2,\ldots, p\}, \\
-&\bc_j^\top\bx+d_j\leq0, \quad j\in\{1,2,\ldots, p\},
\end{aligned}
$$
Since $ \bx^* $ is a local minimum solution of (P), it is also a local minimum solution of ($\text{P}^\prime$).

\paragraph{(i). KKT for linear inequality constraints.} To validate our claim, consider the following more general inequality-constrained optimization problem:
$$
\text{(Q)}\qquad
\begin{aligned}
\min\;  f(\bx) \quad 
\text{s.t.}\quad &\bg_i^\top \bx - f_i\leq 0, \quad i\in\{1,2,\ldots, l\}.
\end{aligned}
$$
Assume $ \widehatbx $ is a local minimum point of (Q). We aim to show that there exist multipliers $\kappa_1, \kappa_2, \ldots, \kappa_l\geq 0$ such that
\begin{equation}\label{equation:kkt_ineq}
\textbf{(KKT for Ineq.)}: \qquad \nabla f(\widehatbx) + \sum_{i=1}^{l} \kappa_i \bg_i = \bzero 
\qquad\text{and}\qquad
\kappa_i (\bg_i^\top\widehatbx -f_i) = 0, \,\forall i.
\end{equation}
This is known as the \textit{KKT conditions for linear inequality constraints}. The result in Theorem~\ref{theorem:kktcond} provides a more general result.
To see this,
it follows by Theorem~\ref{theorem:stat_point_uncons_convset} that $ \widehatbx $ is a stationary point, meaning that $ \nabla f(\widehatbx)^\top (\bx - \widehatbx) \geq 0 $ for every $ \bx \in \real^n $ satisfying $ \bg_i^\top \bx \leq f_i $ for any $ i = \{1, 2, \ldots, l\} $.
Making the change of variables $ \by \triangleq \bx - \widehatbx $, we obtain that $ \nabla f(\widehatbx)^\top \by \geq 0 $ for any $ \by \in \real^n $ satisfying $ \bg_i^\top (\by + \widehatbx) \leq f_i $ for any $ i = \{1, 2, \ldots, l\} $, that is, for any $ \by \in \real^n $ satisfying
$$
\bg_i^\top \by \leq f_i - \bg_i^\top \widehatbx, \,\,\forall i\quad\implies\quad 
\qquad \begin{cases}
\bg_i^\top \by \leq 0, & i \in \sI(\widehatbx), \\
\bg_i^\top \by \leq f_i - \bg_i^\top \widehatbx, & i \notin \sI(\widehatbx),
\end{cases}
$$
where $\sI(\widehatbx) \triangleq \{i \mid  \bg_i^\top \widehatbx = f_i\}$ denotes  the \textit{set of active constraints} (Definition~\ref{definition:setsp4prime}).
We will show that in fact the second set of inequalities in the latter system can be removed, that is, that the following implication is valid:
\begin{equation}\label{equation:kkt_pre1}
\bg_i^\top \by \leq 0 \text{ for all } i \in \sI(\widehatbx) \quad\implies\quad  \nabla f(\widehatbx)^\top \by \geq 0.
\end{equation}
Suppose then that $ \by $ satisfies $ \bg_i^\top \by \leq 0 $ for all $ i \in \sI(\widehatbx) $. Since $ f_i - \bg_i^\top \widehatbx > 0 $ for all $ i \notin \sI(\widehatbx) $, it follows that there exists a small enough $ \gamma > 0 $ for which $ \bg_i^\top (\gamma \by) \leq f_i - \bg_i^\top \widehatbx $ for  $i \notin \sI(\widehatbx)$. Thus, since in addition $ \bg_i^\top (\gamma \by) \leq 0 $ for any $ i \in \sI(\widehatbx) $, it follows by the stationarity condition that $ \nabla f(\widehatbx)^\top (\gamma \by) \geq 0 $, and hence that $ \nabla f(\widehatbx)^\top \by \geq 0 $. This shows the implication in \eqref{equation:kkt_pre1}.
%$$
%\bg_i^\top \by \leq 0 \text{ for all } i \in \sI(\widehatbx) \quad\implies\quad \nabla f(\widehatbx)^\top \by \geq 0.
%$$
Thus, by Farkas' lemma (Lemma~\ref{lemma:farka_lemm}), it follows that there exist $ \kappa_i \geq 0, i \in \sI(\widehatbx) $, such that
$
-\nabla f(\widehatbx) = \sum_{i \in \sI(\widehatbx)} \kappa_i \bg_i.
$
Defining $ \kappa_i \triangleq 0 $ for all $ i \notin \sI(\widehatbx) $, we get that $ \kappa_i (\bg_i^\top \widehatbx - f_i) = 0 $ for all $ i = \{1, 2, \ldots, l\} $ and that $\nabla f(\widehatbx) + \sum_{i=1}^{l} \kappa_i \bg_i = 0$, confirming \eqref{equation:kkt_ineq}.



\paragraph{(i). Main result.}
Returning to problem ($\text{P}^\prime$), the above derivation for problem (Q) shows that  that there exist multipliers $ \lambda_1, \lambda_2, \ldots, \lambda_m \geq 0 $ and $ \mu_1^+, \mu_1^-, \mu_2^+, \mu_2^-, \ldots, \mu_p^+, \mu_p^- \geq 0 $ such that
\begin{equation}\label{equation:kkt_tm1}
\nabla f(\bx^*) + \sum_{i=1}^{m} \lambda_i \ba_i + \sum_{j=1}^{p} \mu_j^+ \bc_j - \sum_{j=1}^{p} \mu_j^- \bc_j = \bzero
\end{equation}
and
\begin{equation}\label{equation:kkt_tm2}
\begin{aligned}
\lambda_i (\ba_i^\top \bx - b_i) &= 0, \quad i = \{1, 2, \ldots, m\}, \\
\mu_j^+ (\bc_j^\top \bx - d_j) &= 0, \quad j = \{1, 2, \ldots, p\}, \\
\mu_j^- (-\bc_j^\top \bx + d_j) &= 0, \quad j = \{1, 2, \ldots, p\}.
\end{aligned}
\end{equation}
We thus obtain that \eqref{equa:kkt1} and \eqref{equa:kkt1} are satisfied with $ \mu_j \triangleq \mu_j^+ - \mu_j^-, \,\, j = \{1, 2, \ldots, p\} $.
Note that $\mu_j$ are not necessarily nonnegative from this deduction.

\paragraph{(ii).} To prove the second part, we still need to prove the sufficiency of \eqref{equation:kkt_ineq} for the linearly inequality constrained problem (Q). 
\paragraph{(ii). Sufficiency of KKT for linear inequality constraints.}
Suppose that $ \widehatbx $ is a feasible solution of (Q) satisfying \eqref{equation:kkt_ineq}. Let $ \bx $ be any feasible solution of (Q). Define the function
$$
s(\bx) \triangleq f(\bx) + \sum_{i=1}^{l} \kappa_i (\bg_i^\top \bx - f_i).
$$
Then by \eqref{equation:kkt_ineq}, it follows that $ \nabla s(\widehatbx) = \bzero $. Since $ s $ is convex, it follows by Theorem~\ref{theorem:suff_sta_conv} that $ \widehatbx $ is a minimizer of $ s $ over $ \real^n $, which combined with \eqref{equation:kkt_ineq} implies that
$$
f(\bx) = f(\widehatbx) + \sum_{i=1}^{l} \kappa_i (\bg_i^\top \widehatbx - f_i) = s(\widehatbx) \leq s(\bx) = f(\bx) + \sum_{i=1}^{m} \kappa_i (\bg_i^\top \bx - f_i) \leq f(\bx),
$$
where the last inequality follows from the fact that $ \kappa_i \geq 0 $ and $ \bg_i^\top \bx - f_i \leq 0 $ for $ i = \{1, 2, \ldots, l\} $. This proves that $ \widehatbx $ is a global optimal solution of (Q).


\paragraph{(ii). Main result.}
Returning to the sufficiency of \eqref{equa:kkt1} and \eqref{equa:kkt2} for  equality and inequality constrained optimization,
suppose that $ \bx^* $ satisfies \eqref{equa:kkt1} and \eqref{equa:kkt1}. Then it also satisfies \eqref{equation:kkt_tm1} and \eqref{equation:kkt_tm2} with
$$
\mu_j^+ = [\mu_j]_+\triangleq \max\{\mu_j, 0\} \qquad \text{and} \qquad \mu_j^- = [\mu_j]_- = -\min\{\mu_j, 0\},
$$
which by the above deduction implies that $ \bx^* $ is an optimal solution of $ (\text{P}^\prime) $, and thus is also an optimal solution of (P).
\end{proof}






\subsection{KKT Conditions for Nonlinearly Constrained Problems}

Equipped with various feasible directions as defined in Definition~\ref{definition:lfd_sfd}, we provide some optimality conditions for the constrained optimization problem $(\text{P4}')$.
Recalling that Theorem~\ref{theorem:_nonconv_fea_loca_optim} establishes the first-order necessary condition for a general constrained optimization (P2), which states that  there are no feasible descent directions (Definition~\ref{definition:uncons_des_direct}). When we have algebraic specifications  of the constrained set in $(\text{P4}')$, we have the following result.
\begin{theoremHigh}[Geometric First-Order Necessary Condition-I: First-Order Necessary Condition for $(\text{P4}')$:]\label{theorem:_nonconv_fea_loca_optim_p4p}
Let $f:\sS\rightarrow \real$ be continuously differentiable where $\sS$ is given by $(\text{P4}')$,  and consider the constrained optimization problem $(\text{P4}')$. 
If $ \bx^* $ is a local optimal solution of $(\text{P4}')$ and $f, c_i$ for $i\in\mathcalI\cup\mathcalE$ are differentiable at $\bx^*$, then 
$$
\bd^\top \nabla f(\bx^*)\geq 0, \quad \text{for all $\bd\in\mathcalT_\sS(\bx^*)$},
$$
which is also equivalent to
$$
\mathcalT_\sS(\bx^*) \cap \sD(\bx^*) = \varnothing, \quad  \text{ where  $\sD(\bx^*) \triangleq \{\bd \mid \nabla f(\bx^*)^\top \bd < 0\}$}.
$$
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:_nonconv_fea_loca_optim_p4p}]
The proof is by contradiction. Assume by contradiction that at point $\bx^*$ with $\mathcalT_\sS(\bx^*) \cap \{\bd \mid \big(\nabla f(\bx^*)\big)^\top \bd < 0\} \neq \varnothing$, let $\bd \in \mathcalT_\sS(\bx^*) \cap \{\bd \mid \big(\nabla f(\bx^*)\big)^\top \bd < 0\}$. According to the definition of tangent vectors, there exist $\{c_t\}_{t>0}$ and $\{\bd^\toptzero\}_{t>0}$ such that $\bx^* + c_t \bd^\toptzero \in \sS$, where $c_t \to 0$ and $\bd^\toptzero \to \bd$. Since $\big(\nabla f(\bx^*)\big)^\top \bd < 0$, for sufficiently large $t$, we have by the linear approximation theorem (Theorem~\ref{theorem:linear_approx}) that 
$$
\begin{aligned}
&f(\bx^* + c_t \bd^\toptzero) = f(\bx^*) + c_t \big(\nabla f(\bx^*)\big)^\top \bd^\toptzero +  o(c_t)\\
&= f(\bx^*) + c_t \big(\nabla f(\bx^*)\big)^\top \bd + c_t \big(\nabla f(\bx^*)\big)^\top (\bd^\toptzero - \bd) +  o(c_t)\\
&= f(\bx^*) + c_t \big(\nabla f(\bx^*)\big)^\top \bd + o(c_t)
< f(\bx^*),
\end{aligned}
$$
where the last inequality follows from the fact that $\frac{o(c_t)}{c_t}\rightarrow 0$ as $c_t\rightarrow 0^+$ and $\big(\nabla f(\bx^*)\big)^\top \bd<0$.
This contradicts the local minimality of $\bx^*$ and completes the proof.
\end{proof}



\begin{theoremHigh}[Geometric First-Order Necessary Condition-II]\label{theorem:geo_for_nec}
Let $ \bx^* $ be a local minimum of the problem $(\text{P4}')$
\begin{align*}
\min & \quad f(\bx) \\
\text{s.t.} & \quad g_i(\bx) \leq 0, \quad i = \{1, 2, \ldots, m\},\\
&\quad h_j(\bx) = 0, \quad j = \{1,2, \ldots, p\},
\end{align*}
where $f, g_1, g_2, \ldots, g_m$ are continuously differentiable functions over $ \real^n $. 
Suppose either:
\begin{enumerate}[(i)]
\item $ \bh(\bx) $ is a linear function, i.e., $ \bh(\bx) = \bA\bx - \bb $ for $ \bA \in \real^{p \times n} $, or
\item $ \nabla h_i(\bx^*), i = \{1,2, \ldots, p\} $, are linearly independent,
\end{enumerate}
\noindent Then
$$
\sD(\bx^*) \cap \sG(\bx^*) \cap \sH(\bx^*) = \varnothing. 
$$
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:geo_for_nec}]
\textbf{(i).}
Assume $ \bh(\bx) $ is the linear function $ \bh(\bx) = \bA\bx - \bb $, whereby $ \nabla h_i(\bx^*) = \bA[i,:] $ for $ i \in \{1,2, \ldots, p\} $ and $ \sH(\bx^*) = \{\bd \mid \bA\bd = \bzero\} $. Suppose $ \bd \in \sD(\bx^*) \cap \sG(\bx^*) \cap \sH(\bx^*) $.
Since because $ \bd \in \sG(\bx^*) $, then there exist $\varepsilon_1>0$ such that for all $\eta\in(0, \varepsilon_1)$,  $ g_i(\bx^* + \eta \bd) < g_i(\bx^*) = 0 $ for $ i \in \sI(\bx^*) $ (Theorem~\ref{theorem:_nonconv_fea_loca_optim}). 
Since $g_i$ are continuous and we have  the fact that $ g_i(\bx^*) < 0 $ for $ i \notin \sI(\bx^*) $, there exists $\varepsilon_2$ such that $ g_i(\bx^* + \eta \bd) < 0 $ for all $\eta\in(0, \varepsilon_2)$. Let $\eta\in(0, \min\{\varepsilon_1, \varepsilon_2\}]$, we have $ g_i(\bx^*) < 0 $ for all $i\in\{1,2,\ldots,p\}$.
Furthermore $ \bh(\bx^* + \eta \bd) = (\bA\bx^* - \bb) + \eta \bA\bd = \bzero $.

Therefore, $ \bx^* + \eta \bd \in \sS $ for all $\eta\in(0, \min\{\varepsilon_1, \varepsilon_2\})$, where $\sS\triangleq\{\bx\mid \bg(\bx)\leq \bzero, \bh(\bx)=\bzero\}$. On the other hand, for all $\eta\in(0, \min\{\varepsilon_1, \varepsilon_2\})$, it holds that $ f(\bx^* + \eta \bd) < f(\bx^*) $. This contradicts the assumption that $ \bx^* $ is a local minimum of $(\text{P4}')$.

\paragraph{(ii).}
The proof when $ \bh(\bx) $ is nonlinear is a bit involved, which relies on the implicit function theorem (Theorem~\ref{theorem:implic_func_theorem}).
Let $ \bA \triangleq \nabla \bh(\bx^*) \in \real^{p \times n} $. Then $ \bA $ has full row rank, and its columns (along with corresponding elements of $ \bx^* $) can be re-arranged so that $ \bA = [\bB, \bN] $ and $ \bx^* = [\by^*; \bz^*] $, where $ \bB\in\real^{p\times p} $ is nonsingular and $\bN\in\real^{p\times (n-p)}$. Let $ \bz $ lie in a small neighborhood of $ \bz^* $: $\bz\in \sB(\bz^*, \varepsilon)$. Then, from the implicit function theorem (Theorem~\ref{theorem:implic_func_theorem}), there exists a function $ \bs(\bz): \real^{n-p}\rightarrow \real^p $ such that $ \bh(\bs(\bz), \bz) = \bzero $.

Suppose in contradiction that $ \bd \in \sD(\bx^*) \cap \sG(\bx^*) \cap \sH(\bx^*)  $, and denote $\bd$ as $ \bd \triangleq [\bq; \bp] $, where $\bq\in\real^p$ and $\bp\in\real^{n-p}$. Then $ \bzero = \bA\bd = \bB\bq + \bN\bp $, whereby $ \bq = -\bB^{-1}\bN\bp $.
Let 
$$
\bz(\theta) \triangleq \bz^* + \theta \bp, \qquad
\by(\theta) \triangleq \bs(\bz(\theta)) = \bs(\bz^* + \theta \bp), 
\qquad\text{and}\qquad
\bx(\theta) \triangleq [\by(\theta); \bz(\theta)], 
$$
where $\bz(\theta)  \in \sB(\bz^*, \varepsilon)$ is in the small neighborhood of $\bz^*$.
We will derive a contradiction by showing that $ \bd $ is an improving feasible direction, i.e., for small $ \theta > 0 $, $ \bx(\theta) $ is feasible and $ f(\bx(\theta)) < f(\bx^*) $.

To show feasibility of $ \bx(\theta) $, note that for $ \theta > 0 $ sufficiently small such that $\bz(\theta)  \in \sB(\bz^*, \varepsilon)$, it follows from the implicit function theorem (Theorem~\ref{theorem:implic_func_theorem}) that:
$$
\bh(\bx(\theta)) = \bh(\bs(\bz(\theta)), \bz(\theta)) = \bzero,
$$
and for $ i = \{1,2, \ldots, p\} $, we have:
$$
\frac{\partial h_i(\bx(\theta))}{\partial \theta} = \sum_{k=1}^p \frac{\partial h_i(\bs(\bz(\theta)), \bz(\theta))}{\partial y_k} \frac{\partial s_k(\bz(\theta))}{\partial \theta} + \sum_{k=1}^{n-p} \frac{\partial h_i(\bs(\bz(\theta)), \bz(\theta))}{\partial z_k} \frac{\partial z_k(\theta)}{\partial \theta} = 0. 
$$
Let $ r_k \triangleq \frac{\partial s_k(\bz(\theta))}{\partial \theta} $, and recall that $ \frac{\partial z_k(\theta)}{\partial \theta} = p_k $. At $ \theta = 0 $, the above equation system can then be re-written as $ \bzero = \bB\br + \bN\bp $, or $ \br = -\bB^{-1}\bN\bp = \bq $. Therefore,
$$
\frac{\partial x_k(\theta)}{\partial \theta} = d_k, \quad\text{for}\quad k = \{1,2, \ldots, n\}. 
$$
For $ i \in \sI(\bx^*) $,
$$
\begin{aligned}
g_i(\bx(\theta)) &= g_i(\bx^*) + \theta \frac{\partial g_i(\bx(\theta))}{\partial \theta} \bigg|_{\theta=0} + \abs{\theta} \alpha_i(\theta)
= \theta \sum_{k=1}^n \frac{\partial g_i(\bx(\theta))}{\partial x_k} \frac{\partial x_k(\theta)}{\partial \theta} \bigg|_{\theta=0}\\
&= \theta \nabla g_i(\bx^*)^\top \bd + \abs{\theta} \alpha_i(\theta),
\end{aligned}
$$
where $ \alpha_i(\theta) \rightarrow 0 $ as $ \theta \rightarrow 0 $. Hence $ g_i(\bx(\theta)) < 0 $ for all $ i = 1,2, \ldots, m $ for $ \theta > 0 $
sufficiently small, and therefore, $ \bx(\theta) $ is feasible for any $ \theta > 0 $ sufficiently small.

On the other hand,
$$ f(\bx(\theta)) = f(\bx^*) + \theta \nabla f(\bx^*)^\top \bd + \abs{\theta} \alpha(\theta) < f(\bx^*) $$
for $ \theta > 0 $ sufficiently small, where $ \alpha(\theta) \rightarrow 0 $ as $ \theta \rightarrow 0 $. But this contradicts the local optimality of $ \bx^* $. Therefore no such $ \bd $ can exist, and the theorem is proved.
\end{proof}
Note that Theorem~\ref{theorem:geo_for_nec} essentially states that if a point $ \bx^* $ is (locally) optimal, there is no direction $ \bd $ which is both a feasible direction (i.e., such that $ g(\bx^* + \lambda \bd) \leq 0 $ and $ h(\bx^* + \lambda \bd) \approx 0 $ for small $ \lambda > 0 $) and is an improving direction (i.e., such that $ f(\bx^* + \lambda \bd) < f(\bx^*) $ for small $ \lambda > 0 $), which makes sense intuitively.
Using Theorem~\ref{theorem:geo_for_nec}, we prove the following Fritz-John conditions.
\index{Fritz-John conditions}
\begin{theoremHigh}[Fritz-John Necessary Conditions for Equality/Inequality Constraints]\label{theorem:frijohn_eqineq}
Let $ \bx^* $ be a local minimum point  of the problem $(\text{P4}')$
\begin{align*}
\min & \quad f(\bx) \\
\text{s.t.} & \quad g_i(\bx) \leq 0, \quad i = \{1, 2, \ldots, m\},\\
&\quad h_j(\bx) = 0, \quad j = \{1,2, \ldots, p\},
\end{align*}
where $ f, g_1, \ldots, g_m $ are continuously differentiable functions over $ \real^n $. Then, there exist multipliers $ \lambda_0, \lambda_1, \ldots, \lambda_m \geq 0, \mu_1, \mu_2, \ldots,\mu_p\in\real $, which are not all zeros (i.e., nontriviality: $[\lambda_0, \blambda, \bmu]^\top\neq \bzero$), such that
\begin{subequations}
\begin{align}
	\lambda_0 \nabla f(\bx^*) &+ \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) +\sum_{j=1}^{p} \mu_j\nabla h_j(\bx^*) = \bzero,\label{equation:frijob_full1} \\
	&\lambda_i g_i(\bx^*) = 0, \quad i = \{1, 2, \ldots, m\}.
\end{align}
\end{subequations}
Note that \eqref{equation:frijob_full1} can be compactly written as $\lambda_0 \nabla f(\bx^*) = \nabla \bg(\bx)^\top \blambda + \nabla \bh(\bx)^\top \bmu$ using Jacobian matrices (see \eqref{equation:jacob_inkkt}).


\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:frijohn_eqineq}]
If the vectors $ \{\nabla h_i(\bx^*)\} $ are linearly dependent, then there exists $ \bmu \neq \bzero $ such that $ \sum_{j=1}^p \mu_j \nabla h_i(\bx^*) = \bzero $. Setting $ [\lambda_0, \blambda] \triangleq \bzero $ establishes the result.

Suppose now that the vectors $ \{\nabla h_i(\bx^*)\} $ are linearly independent. Then we can apply Theorem~\ref{theorem:geo_for_nec} and assert that $ \sD(\bx^*) \cap \sG(\bx^*) \cap \sH(\bx^*) = \varnothing $. Without loss of generality, assume for simplicity that $ \sI(\bx^*) = \{1,2, \ldots, l\} $ with $l\leq m$. Let
$$
\bD \triangleq \begin{bmatrix}
\nabla f(\bx^*)^\top \\
\nabla g_1(\bx^*)^\top \\
\vdots \\
\nabla g_l(\bx^*)^\top
\end{bmatrix}
\quad\text{and}\quad
\bF \triangleq \begin{bmatrix}
\nabla h_1(\bx^*)^\top \\
\vdots \\
\nabla h_p(\bx^*)^\top
\end{bmatrix}.
$$
Then there is no $ \bd $ that satisfies $ \bD\bd < \bzero $ and  $ \bF\bd = \bzero $. From the system (1 $\&$ 2) of Lemma~\ref{lemma:farka_lemm}, there exists $ (\lambda_0, \lambda_1, \ldots, \lambda_l) $ and $ (\mu_1,\mu_2 \ldots, \mu_p) $ such that
$$
\lambda_0 \nabla f(\bx^*) + \sum_{i=1}^l \lambda_i \nabla g_i(\bx^*) + \sum_{j=1}^p \mu_j \nabla h_j(\bx^*) = \bzero,
$$
with $ \lambda_0 + \lambda_1 + \cdots + \lambda_l = 1 $ and $ (\lambda_0, \lambda_1, \ldots, \lambda_l) \geq 0 $. Define $ \lambda_{l+1}, \ldots, \lambda_m \triangleq 0 $. Then, $ (\lambda_0, \blambda) \geq \bzero $ and $ (\lambda_0, \blambda) \neq \bzero $, and for any $ i $, either $ g_i(\bx^*) = 0 $, or $ \lambda_i = 0 $. Furthermore,
$$
\lambda_0 \nabla f(\bx^*) + \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) + \sum_{i=1}^p \mu_i \nabla h_i(\bx^*) = \bzero,
$$
which obtains the desired result.
\end{proof}



\index{KKT conditions}
\index{Linear independence constraint qualification}
\index{LICQ}

A major drawback of the Fritz-John conditions is in the fact that they allow $ \lambda_0 $ to be zero. The case $ \lambda_0 = 0 $ is not particularly informative since condition \eqref{equation:frijob_full1} then becomes
$$ \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) +\sum_{j=1}^{p}\mu_j\nabla h_j(\bx^*) =\bzero , $$
which indicates that the gradients of the active constraints $ \{\nabla g_i(\bx^*)\}_{i \in \sI(\bx^*)} $ and the equality constraints $\{\nabla h_j(\bx^*)\}_{j\in\{1,2,\ldots,p\}}$ are linearly dependent.
This situation provides no information about the objective function, implying many points satisfying the Fritz-John conditions may not be local minima.

If we add an assumption that the gradients of the active/equality constraints are linearly independent at $\bx^*$, then we can establish the KKT conditions, which are the same
as the Fritz-John conditions with $\lambda_0 = 1$.
The condition that the gradients of the active/quality constraints are linearly independent is one of many types of assumptions that are referred to in the literature as ``\textit{constraint qualifications}." \citep{bazaraa2006nonlinear, beck2014introduction}.
We summarize  this \textit{linear independence constraint qualification (LICQ)} result in the following theorem, which follows directly from the Fritz-John conditions stated in  Theorem~\ref{theorem:frijohn_eqineq}.
\begin{theoremHigh}[KKT  Conditions for Equality/Inequality under LICQ]\label{theorem:kkt_licq}
Consider the optimization problem $(\text{P4}')$
\begin{align*}
\min & \quad f(\bx) \\
\text{s.t.} & \quad g_i(\bx) \leq 0, \quad i = \{1, 2, \ldots, m\},\\
&\quad h_j(\bx) = 0, \quad j = \{1,2, \ldots, p\},
\end{align*}
where $ f, g_1, g_2, \ldots, g_m, h_1, h_2, \ldots, h_p $ are continuously differentiable functions over $ \real^n $. 
\begin{enumerate}[(i)]
\item \textbf{Necessity of the KKT conditions.} Let $ \bx^* $ be a local minimum of $(\text{P4}')$. Suppose that the gradients of the active constraints and the equality constraints
$$ \{\nabla g_i(\bx^*) : i \in \sI(\bx^*)\} \cup \{\nabla h_j(\bx^*) : j = 1, 2, \ldots, p\} $$
are linearly independent (where $ \sI(\bx^*) \triangleq \{i : g_i(\bx^*) = 0\} $, i.e., LICQ in Definition~\ref{definition:licq}). Then there exist multipliers $ \lambda_1, \lambda_2, \ldots, \lambda_m \geq 0 $ and $ \mu_1, \mu_2, \ldots, \mu_p \in \real $ such that
\begin{subequations}
\begin{align}
	\nabla f(\bx^*) &+ \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) + \sum_{j=1}^p \mu_j \nabla h_j(\bx^*) = \bzero, \label{equation:kkt_licq1}\\
	&\lambda_i g_i(\bx^*) = 0, \quad i = \{1, 2, \ldots, m\}. \label{equation:kkt_licq2}
\end{align}
\end{subequations}
\item \label{suff:kkt_licq} \textbf{Sufficiency in the convex case.}
Suppose further that the function $f, g_1, g_2\ldots, g_m$ are \textbf{convex} over $\real^n$, $h_1, h_2, \ldots, h_p$ are \textbf{affine} functions, and $\bx^*$ is a feasible solution of $(\text{P4}')$ for which there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that \eqref{equation:kkt_licq1} and \eqref{equation:kkt_licq2} are satisfied. Then, $\bx^*$ is an optimal solution of $(\text{P4}')$.
\end{enumerate}
\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:kkt_licq}]
The first part is a direct consequence of the Fritz-John necessary conditions. 
For the sufficiency under the convexity, 
let $ \bx $ be a feasible solution of $(\text{P4}')$. We will show that $ f(\bx) \geq f(\bx^*) $. Note that the function
$$ s(\bx) = f(\bx) + \sum_{i=1}^m \lambda_i g_i(\bx) + \sum_{j=1}^p \mu_j h_j(\bx) $$
is convex, and since $ \nabla s(\bx^*) = \nabla f(\bx^*) + \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) + \sum_{j=1}^p \mu_j \nabla h_j(\bx^*) = \bzero $, it follows by Theorem~\ref{theorem:suff_sta_conv} that $ \bx^* $ is a minimizer of $ s(\cdot) $ over $ \real^n $, and in particular $ s(\bx^*) \leq s(\bx) $ for any feasible point $\bx$.
Therefore, the KKT conditions and the feasibility of $\bx^*$ imply that 
\begin{align*}
f(\bx^*) &= f(\bx^*) + \sum_{i=1}^m \lambda_i g_i(\bx^*) + \sum_{j=1}^p \mu_j h_j(\bx^*)
= s(\bx^*)  \\
&\leq s(\bx) 
= f(\bx) + \sum_{i=1}^m \lambda_i g_i(\bx) + \sum_{j=1}^p \mu_j h_j(\bx)
\leq f(\bx).
\end{align*}
This completes the proof.
\end{proof}

\index{KKT points}
The above theorem introduces two concepts: KKT points and regularity, which we formulate in the following definitions.
\begin{definition}[KKT Points]\label{definition:kkt_point}
Consider the optimization problem $(\text{P4}')$ in \eqref{equation:P4_in_kkt}, where $ f, g_1, \ldots, g_m, h_1, h_2, \ldots, h_p $ are continuously differentiable functions over $ \real^n $. A feasible point $ \bx^* $ is called a \textit{KKT point} if there exist $ \lambda_1, \lambda_2, \ldots, \lambda_m \geq 0 $ and $ \mu_1, \mu_2, \ldots, \mu_p \in \real $ such that
$$
\begin{aligned}
\nabla f(\bx^*) &+ \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) +\sum_{j=1}^{p} \mu_j\nabla h_j(\bx^*) = \bzero, \\
&\lambda_i g_i(\bx^*) = 0, \quad i = \{1, 2, \ldots, m\}.
\end{aligned}
$$
\end{definition}

\index{Regularity}
\begin{definition}[Regularity]
Consider again the optimization problem $(\text{P4}')$ in \eqref{equation:P4_in_kkt}, where $ f, g_1, \ldots, g_m, h_1, h_2, \ldots, h_p $ are continuously differentiable functions over $ \real^n $. A feasible point $ \bx^* $ is called \textit{regular} if the gradients of the active constraints among the inequality constraints and of the equality constraints
$$ \big\{\nabla g_i(\bx^*) : i \in \sI(\bx^*)\big\} \cup \big\{\nabla h_j(\bx^*) : j = \{1, 2, \ldots, p\}\big\} $$
are linearly independent.
\end{definition}



%\begin{theoremHigh}[KKT  Conditions for Equality/Inequality under CQ]\label{theorem:kkt_cq}
%Let $\bx^*$ be a local minimum point of problem $(\text{P4}')$. If the constraint qualification (CQ)
%\begin{equation}
%\sfd(\bx^*) = \lfd(\bx^*)
%\end{equation}
%holds, then there exist Lagrange multipliers $\lambda_i^*$ such that the following conditions are satisfied at $(\bx^*, \blambda^*)$:
%\begin{align}
%\nabla f(\bx^*) - \sum_{i=1}^{m} \lambda_i^* \nabla c_i(\bx^*) &= 0, \label{equation:kkt_cq_eq1}  \\
%c_i(\bx^*) &= 0, \quad \forall i \in \mathcalE,  \\
%c_i(\bx^*) &\geq 0, \quad \forall i \in \mathcalI,  \\
%\lambda_i^* &\geq 0, \quad \forall i \in \mathcalI,\\
%\lambda_i^* c_i(\bx^*) &= 0, \quad \forall i \in \mathcalI. 
%\end{align}
%\end{theoremHigh}
%\begin{proof}
%Since $\bx^*$ is a local minimizer, $\bx^*$ is feasible and the equality and inequalities constraints are satisfied.
%Let $\bd \in \mathcalT_\sS(\bx^*)$; since $\bx^*$ is a local minimizer, it follows from Theorem~\ref{theorem:_nonconv_fea_loca_optim_p4p} that $\bd^\top \nabla f(\bx^*) \geq 0$. By constraint qualification $\mathcalT_\sS(\bx^*) = \lfd(\bx^*)$, we have $\bd \in \lfd(\bx^*)$. Thus the system
%\begin{align}
%\bd^\top \nabla c_i(\bx^*) &= 0, \quad i \in \mathcalE,  \\
%\bd^\top \nabla c_i(\bx^*) &\geq 0, \quad i \in I(\bx^*),  \\
%\bd^\top \nabla f(\bx^*) &< 0 
%\end{align}
%has no solution. By Farkas' lemma (Lemma~\ref{lemma:farka_lemm}), we immediately obtain that
%\begin{equation}
%	\nabla f(\bx^*) = \sum_{i \in \mathcalE} \lambda_i^* \nabla c_i(\bx^*) + \sum_{i \in I(\bx^*)} \lambda_i^* \nabla c_i(\bx^*),
%\end{equation}
%where $\lambda_i^* \in \real $ (if $i \in \mathcalE$) and $\lambda_i^* \geq 0$  (if $i \in I(\bx^*)$). Setting $\lambda_i^* = 0 $ ($i \in I \setminus I(\bx^*)$), it follows that
%$$
%\nabla f(\bx^*) = \sum_{i=1}^{m} \lambda_i^* \nabla c_i(\bx^*),
%$$
%which is \eqref{equation:kkt_cq_eq1}. It is obvious that $\lambda_i^* \geq 0, \forall i \in I$.
%
%Finally, note that:
%- when $i \in I(\bx^*)$, $c_i(\bx^*) = 0$ and $\lambda_i^* \geq 0$, therefore $\lambda_i^* c_i(\bx^*) = 0$;
%- when $i \in I \setminus I(\bx^*)$, $c_i(\bx^*) > 0$ but $\lambda_i^* = 0$, therefore we also have $\lambda_i^* c_i(\bx^*) = 0$.
%\end{proof}






\subsection{KKT Conditions for Convex Optimization Problems}

Specifically, for convex optimization problems (Section~\ref{section:convex_optimiz}), we can use another set of conditions to state the KKT conditions, i.e., \textit{Slater's condition}.
\begin{theoremHigh}[KKT Conditions under  Slater's Condition]\label{theorem:kktslat1_slater}
Consider the minimization problem
\begin{equation}\label{equation:kktslat1_slater1}
\begin{aligned}
	\min &\quad  f(\bx) \\
	\text{s.t.}
	&\quad g_i(\bx) \leq 0, \quad i\in\{1,2,\ldots, m\}, \quad \text{(convex)}\\
	&\quad h_j(\bx)= 0, \quad j\in\{1,2,\ldots, p\}, \quad \text{(affine)}\\
\end{aligned}
\end{equation}
where $f$ is  continuously differentiable over $\real^n$, $g_1, \ldots, g_m$ are \textbf{convex} and continuously differentiable over $\real^n$, $h_1, h_2, \ldots h_p$  are \textbf{affine}. 
Then, we have the following results:
\begin{enumerate}[(i)]
\item \textbf{Necessity of the KKT conditions.}
Let $\bx^*$ be a local minimum point of \eqref{equation:kktslat1_slater1}. 
Suppose that $\{\nabla h_j(\bx^*)\}_{j\in\{1,2,\ldots,p\}}$ are linearly independent~\footnote{When the number of affine constraint is zero, this condition can be relaxed.}, and there exists $\widehatbx\in\real^n$ such that the following  Slater's condition holds:
$$
\textbf{(Slater's condition)}: \quad
\left\{
\begin{aligned}
	g_i(\widehatbx) &\textcolor{mylightbluetext}{<}0, \quad i\in\{1,2,\ldots, m\}, \\
	h_j(\widehatbx)&= 0, \quad j\in\{1,2,\ldots, p\},\\
\end{aligned}
\right.
$$
Then, there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that 
\begin{subequations}
\begin{align}
	&\nabla f(\bx^*) + \sum_{i=1}^{m} \lambda_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\mu_j \nabla h_j(\bx^*)  =\bzero,\label{equa:kktslat1_gen1}\\
	&\lambda_i g_i(\bx^*)=0, \quad i=\{1,2,\ldots, m\}.\label{equa:kktslat1_gen2}
\end{align}
\end{subequations}

\item \textbf{Sufficiency in the convex case.} Suppose further that the function $f$ is \textbf{convex} over $\real^n$, and $\bx^*$ is a feasible solution of \eqref{equation:kktslat1_slater1} for which there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that \eqref{equa:kktslat1_gen1} and \eqref{equa:kktslat1_gen2} are satisfied. Then, $\bx^*$ is an optimal solution of \eqref{equation:kktslat1_slater1}. 
This is equivalent to the claim in Theorem~\ref{theorem:kkt_licq}\ref{suff:kkt_licq}.
\end{enumerate}

\end{theoremHigh}
\begin{proof}[of Theorem~\ref{theorem:kktslat1_slater}]
As in the proof of the necessity of the KKT conditions under LICQ (Theorem~\ref{theorem:kkt_licq}), since $ \bx^* $ is an optimal solution of \eqref{equation:kktslat1_slater1}, then the Fritz-John necessary conditions (Theorem~\ref{theorem:frijohn_eqineq}) are satisfied. That is, there exist nonnegative scalars $ \widetilde{\lambda}_0, \widetilde{\lambda}_1, \widetilde{\lambda}_2, \ldots,\widetilde{\lambda}_m\geq 0  $ and real scalars $\widetilde{\mu}_1, \widetilde{\mu}_2, \ldots, \widetilde{\mu}_p\in\real$, which are not all zeros, such that
\begin{equation}\label{equation:kktslat1_slater_prov1}
\begin{aligned}
	&\widetilde{\lambda}_0\nabla f(\bx^*) + \sum_{i=1}^{m} \widetilde{\lambda}_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\widetilde{\mu}_j \nabla h_j(\bx^*)  =\bzero,\\
	&\widetilde{\lambda}_i g_i(\bx^*)=0, \quad i=\{1,2,\ldots, m\}.
\end{aligned}
\end{equation}
To complete the proof, we need to show that $ \widetilde{\lambda}_0 > 0 $, and then the conditions \eqref{equa:kktslat1_gen1} and \eqref{equa:kktslat1_gen2} will be satisfied with $ \lambda_i = \frac{\widetilde{\lambda}_i}{\widetilde{\lambda}_0}, i = \{1, 2, \ldots, m\}$ and $ \mu_j = \frac{\widetilde{\mu}_j}{\widetilde{\lambda}_0}, j = \{1, 2, \ldots, p\}$. To prove that $ \widetilde{\lambda}_0 > 0 $, assume, for contradiction, that it is zero then
\begin{equation}\label{equation:kktslat1_slater_prov2}
\sum_{i=1}^{m} \widetilde{\lambda}_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\widetilde{\mu}_j \nabla h_j(\bx^*) =\bzero.
\end{equation}
By the convexity of $g_i$, for all $ i = \{1, 2, \ldots, m\} $, we have
$$
\begin{aligned}
&0 > g_i(\widehatbx) \geq g_i(\bx^*) + \nabla g_i(\bx^*)^\top (\widehatbx - \bx^*).\\
\end{aligned}
$$
Multiplying the $ i $-th inequality by $ \widetilde{\lambda}_i $ and summing over $ i = \{1, 2, \ldots, m\} $, we obtain
$$
\begin{aligned}
0 > &\sum_{i=1}^m \widetilde{\lambda}_i g_i(\bx^*) + \left( \sum_{i=1}^m \widetilde{\lambda}_i \nabla g_i(\bx^*) \right)^\top (\widehatbx - \bx^*)\\
\end{aligned}
$$
where the inequality is strict since not all the $ \widetilde{\lambda}_i $ are zero (use the fact that  $\{\nabla h_j(\bx^*)\}_{j\in\{1,2,\ldots,p\}}$ are linearly independent such that $\widetilde{\lambda}_i$'s are nonnegative and sum to 1; see the proof of the Fritz-John conditions in Theorem~\ref{theorem:frijohn_eqineq}). Plugging the identities \eqref{equation:kktslat1_slater_prov1} and \eqref{equation:kktslat1_slater_prov2} into the above inequality, we  obtain the impossible statement that $ 0 > 0 $, thus establishing the result. 
\end{proof}



%The KKT conditions also hold under the generalized Slater's condition.
%\begin{theorem}[KKT Conditions under  Generalized Slater's Condition]\label{theorem:kkt_gen_slater}
%Consider the minimization problem
%\begin{equation}\label{equation:kkt_gen_slater1}
%\begin{aligned}
%	\min f(\bx),\qquad 
%	\text{s.t.}\quad 
%	&g_i(\bx) \leq 0, \quad i\in\{1,2,\ldots, m\}, \quad \text{(convex)}\\
%	&h_j(\bx)\leq 0, \quad j\in\{1,2,\ldots, p\}, \quad \text{(affine)}\\
%	&s_k(\bx)= 0, \quad k\in\{1,2,\ldots, q\},  \quad\text{(affine)}\\
%\end{aligned}
%\end{equation}
%where $f, g_1, \ldots, g_m$ are  continuously differentiable over $\real^n$, $h_j, s_k$ for all $j,k$ are affine. 
%Then, we have the following results:
%\begin{enumerate}[(i)]
%\item \textbf{Necessity of the KKT conditions.}
%Let $\bx^*$ be a local minimum point of \eqref{equation:kkt_gen_slater1}. 
%Suppose that there exists $\widehatbx\in\real^n$ such that the following generalized Slater's condition holds:
%$$
%\text{Generalized Slater's condition: }
%\left\{
%\begin{aligned}
%g_i(\widehatbx) &\textcolor{mylightbluetext}{<}0, \quad i\in\{1,2,\ldots, m\}, \\
%h_j(\widehatbx)&\leq 0, \quad j\in\{1,2,\ldots, p\},\\
%s_k(\widehatbx)&= 0, \quad k\in\{1,2,\ldots, q\},
%\end{aligned}
%\right.
%$$
%Then, there exist $\lambda_1, \lambda_2, \ldots,\lambda_m, \eta_1, \eta_2,\ldots,\eta_p\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that 
%\begin{align}
%&\nabla f(\bx^*) + \sum_{i=1}^{m} \lambda_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\eta_j \nabla h_j(\bx^*) +\sum_{k=1}^{q}\mu_k \nabla s_k(\bx^*) =\bzero,\label{equa:kkt1_gen}\\
%&\lambda_i g_i(\bx^*)=0, \quad i=\{1,2,\ldots, m\}; 
%\quad 
%\eta_j h_j(\bx^*)=0, \quad j=\{1,2,\ldots, p\}.\label{equa:kkt2_gen}
%\end{align}
%
%\item \textbf{Sufficiency in the convex case.} Suppose further that the function $f$ is convex over $\real^n$, and $\bx^*$ is a feasible solution of \eqref{equation:kkt_gen_slater1} for which there exist $\lambda_1, \lambda_2, \ldots,\lambda_m\geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p\in\real$ such that \eqref{equa:kkt1_gen} and \eqref{equa:kkt2_gen} are satisfied. Then, $\bx^*$ is an optimal solution of \eqref{equation:kkt_gen_slater1}.
%\end{enumerate}
%
%\end{theorem}
%\begin{proof}[of Theorem~\ref{theorem:kkt_gen_slater}]
%As in the proof of the necessity of the KKT conditions under LICQ (Theorem~\ref{theorem:kkt_licq}), since $ \bx^* $ is an optimal solution of \eqref{equation:kkt_gen_slater1}, then the Fritz-John necessary conditions (Theorem~\ref{theorem:frijohn_eqineq}) are satisfied. That is, there exist nonnegative scalars $ \widetilde{\lambda}_0, \widetilde{\lambda}_1, \widetilde{\lambda}_2, \ldots,\widetilde{\lambda}_m, \widetilde{\eta}_1, \widetilde{\eta}_2,\ldots, \widetilde{\eta}_p\geq 0  $ and real scalars $\widetilde{\mu}_1, \widetilde{\mu}_2, \ldots, \widetilde{\mu}_p\in\real$, which are not all zeros, such that
%\begin{equation}\label{equation:kkt_gen_slater_prov1}
%\begin{aligned}
%&\widetilde{\lambda}_0\nabla f(\bx^*) + \sum_{i=1}^{m} \widetilde{\lambda}_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\widetilde{\eta}_j \nabla h_j(\bx^*) +\sum_{k=1}^{q}\widetilde{\mu}_k \nabla s_k(\bx^*) =\bzero,\\
%&\widetilde{\lambda}_i g_i(\bx^*)=0, \quad i=\{1,2,\ldots, m\}; 
%\quad 
%\widetilde{\eta}_j h_j(\bx^*)=0, \quad j=\{1,2,\ldots, p\}.
%\end{aligned}
%\end{equation}
%All that we need to show is that $ \widetilde{\lambda}_0 > 0 $, and then the conditions \eqref{equa:kkt1_gen} and \eqref{equa:kkt2_gen} will be satisfied with $ \lambda_i = \frac{\widetilde{\lambda}_i}{\widetilde{\lambda}_0}, i = \{1, 2, \ldots, m\}, \eta_j = \frac{\widetilde{\eta}_j}{\widetilde{\lambda}_0}, j = \{1, 2, \ldots, p\},  $ and $\mu_k = \frac{\widetilde{\mu}_k}{\widetilde{\lambda}_0}, k = \{1, 2, \ldots, q\}$. To prove that $ \widetilde{\lambda}_0 > 0 $, assume in contradiction that it is zero then
%\begin{equation}\label{equation:kkt_gen_slater_prov2}
%\sum_{i=1}^{m} \widetilde{\lambda}_i\nabla g_{i}(\bx^*) +\sum_{j=1}^{p}\widetilde{\eta}_j \nabla h_j(\bx^*) +\sum_{k=1}^{q}\widetilde{\mu}_k \nabla s_k(\bx^*) =\bzero.
%\end{equation}
%By the gradient inequality, for all $ i = \{1, 2, \ldots, m\} $ and $j\in\{1,2,\ldots,p\}$, we have
%$$
%\begin{aligned}
%&0 > g_i(\widehatbx) \geq g_i(\bx^*) + \nabla g_i(\bx^*)^\top (\widehatbx - \bx^*);\\
%&0 \geq  h_j(\widehatbx) = h_j(\bx^*) + \nabla h_j(\bx^*)^\top (\widehatbx - \bx^*).
%\end{aligned}
%$$
%where the inequality ($\dag$) can be set as equal.
%Multiplying the $ i $-th inequality by $ \widetilde{\lambda}_i $ and summing over $ i = \{1, 2, \ldots, m\} $, we obtain
%$$
%\begin{aligned}
%0 > &\sum_{i=1}^m \widetilde{\lambda}_i g_i(\bx^*) + \left( \sum_{i=1}^m \widetilde{\lambda}_i \nabla g_i(\bx^*) \right)^\top (\widehatbx - \bx^*)\\
%&+
%\sum_{j=1}^p \widetilde{\eta}_j h_j(\bx^*) + \left(\sum_{j=1}^p \widetilde{\eta}_j\nabla h_j(\bx^*)^\top\right) (\widehatbx - \bx^*)\\
%&+
%\sum_{k=1}^q \widetilde{\mu}_k s_k(\bx^*) + \left(\sum_{k=1}^q \widetilde{\mu}_k\nabla s_k(\bx^*)^\top\right) (\widehatbx - \bx^*).
%\end{aligned}
%$$
%where the inequality is strict since not all the $ \widetilde{\lambda}_i $ are zero. Plugging the identities \eqref{equation:kkt_gen_slater_prov1} and \eqref{equation:kkt_gen_slater_prov2} into the above inequality, we want to obtain the impossible statement that $ 0 > 0 $, thus establishing the result. It suffices to show that not all $\widetilde{\lambda}_1, \widetilde{\lambda}_2, \ldots, \widetilde{\lambda}_m$ are zero.
%\end{proof}

%% Duplicate
%\begin{example}
%The KKT conditions can be utilized to find the orthogonal projection onto an affine space:
%$$
%\begin{aligned}
%	\mathop{\min}_{\bx\in\real^n}\quad &f(\bx) =\normtwo{\bx-\by}^2 \qquad \text{s.t.}\quad & \bA\bx=\bb,
%\end{aligned}
%$$
%where $\bA\in\real^{m\times n}$ and $\bb\in\real^m$.
%This problem aims to find the closest point to $\by$ in the \textit{affine space} $\mathcalV=\{\bx\in\real^n: \bA\bx=\bb\}$.
%Since the norm function is convex, the KKT conditions are necessary and sufficient for obtaining the optimal solution of the problem.
%Therefore, the KKT conditions are 
%$
%2(\bx-\by) + 2\bA^\top\bmu = \bzero
%$
%and 
%$
%\bA\bx = \bb.
%$
%Thus, we obtain 
%$
%\bA(\by-\bA^\top\bmu) = \bb
%\implies 
%\bA\by - \bb = \bA\bA^\top\bmu.
%$
%If $\bA$ has full row rank, then
%$
%\bmu = (\bA\bA^\top)^{-1} (\bA\by - \bb).
%$
%Therefore, the optimal solution $\bx^*$ can be obtained by 
%$
%\begin{aligned}
%	\bx^* &= \by - \bA^\top \bmu
%	= \by - \bA^\top  (\bA\bA^\top)^{-1} (\bA\by - \bb).
%\end{aligned}
%$
%
%When $\bA$ is a vector $\ba^\top$, the problem reduces to finding the orthogonal projection onto the \textit{hyperplane}:
%$
%\mathcalV' = \{\bx\in\real^n: \ba^\top\bx = b\}.
%$
%Then, the optimal solution is 
%$
%\bx^* =\by-\frac{ (\ba^\top\by - b)}{\ba^\top\ba} \ba.
%$
%
%\end{example}

%\subsection{Second-Order Conditions for Nonlinearly Constrained Problems}
%\begin{theoremHigh}[second order necessary conditions for equality and inequality constrained problems]
%Consider the problem
%
%\begin{equation}
%\begin{aligned}
%	& \min && f(\bx) \\
%	& \text{s.t.} && g_i(\bx) \leq 0, & i &= 1, 2, \ldots, m, \\
%	& && h_j(\bx) = 0, & j &= 1, 2, \ldots, p,
%\end{aligned}
%\end{equation}
%where $ f, g_1, \ldots, g_m, h_1, \ldots, h_p $ are twice continuously differentiable over $\real}^n$. Let $\bx^*$ be a local minimum of problem, and suppose that $\bx^*$ is regular, meaning that $\{\nabla g_i(\bx^*), \nabla h_j(\bx^*)\}$ are linearly independent, where
%$ \sI(\bx^*) = \{i \in \{1, 2, \ldots, m\} : g_i(\bx^*) = 0\}. $
%Then there exist $\lambda_1, \lambda_2, \ldots, \lambda_m \geq 0$ and $\mu_1, \mu_2, \ldots, \mu_p \in \mathbb{R}$ such that
%$$
%\begin{aligned}
%&\nabla f(\bx^*) + \sum_{i=1}^m \lambda_i \nabla g_i(\bx^*) + \sum_{j=1}^p \mu_j \nabla h_j(\bx^*) = \bzero,\\
%&\lambda_i g_i(\bx^*) = 0, \quad i = 1, 2, \ldots, m,
%\end{aligned}
%$$
%and
%$$
%\bd^\top \left[ \nabla^2 f(\bx^*) + \sum_{i=1}^m \lambda_i \nabla^2 g_i(\bx^*) + \sum_{j=1}^p \mu_j \nabla^2 h_j(\bx^*) \right] \bd \geq 0
%$$
%for all $\bd \in \sV(\bx^*)$ where
%$$
%\sV(\bx^*) \equiv \{\bd \in \mathbb{R}^n : \nabla g_i(\bx^*)^\top \bd = 0, \nabla h_j(\bx^*)^\top \bd = 0, i \in \sI(\bx^*), j = 1, 2, \ldots, p\}.
%$$
%\end{theoremHigh}




\begin{problemset}
\item Using the proof of Theorem~\ref{theorem:psd_hess_conv}, prove the equivalence among \eqref{equation:scss_func1}, \eqref{equation:scss_func2}, and \eqref{equation:scss_func3_ra} for the definition of strongly convexity and strongly smoothness.

\item Prove the properties of Bregman distances as  outlined in Remark~\ref{remark:bregnan_dist}.

\item Let $ f \in C^{2,2}_L(\real^n) $. Show that  for all $ \bx, \by \in \real^n $,  the following inequalities hold:
$$
\begin{aligned}
&\normtwo{\nabla f(\by) - \nabla f(\bx) - \nabla^2 f(\bx)(\by - \bx)} \leq \frac{L}{2} \normtwo{\by - \bx}^2;\\
&\abs{f(\by) - f(\bx) - \innerproduct{\nabla f(\bx), \by - \bx} - \frac{1}{2} \innerproduct{\nabla^2 f(\bx)(\by - \bx), \by - \bx}} \leq \frac{L}{6} \normtwo{ \by - \bx}^3.
\end{aligned}
$$
Additionally, if $\normtwo{\bx-\by}\leq M$, demonstrate that:
$$
\nabla^2 f(\bx) -L M \bI \preceq \nabla^2 f(\by) \preceq \nabla^2 f(\bx)+ LM  \bI.
$$
\textit{Hint: Refer to Theorem~\ref{theorem:equi_gradsch_smoo} and Exercise~\ref{exercise:cl2111_hess_bound}.}

\item \label{prob:dist_hyper} \textbf{Distance between a vector and a hyperplane.} Given a nonzero vector $\bzero\neq \ba\in\real^n$ and a scalar $\beta$,  we define  the hyperplane $H(\ba, \beta) \triangleq \{\bx\in\real^n:\ba^\top\bx+\beta=0\}$. For any vector $\by\in\real^n$, show that the distance between the vector $\by$ and the hyperplane $H(\ba, \beta)$ is given by 
\begin{equation}
	d(\by, H(\ba, \beta)) = \frac{\abs{\ba^\top\by + \beta}}{\normtwo{\ba}}.
\end{equation}
\textit{Hint: Select  two random points on the plane and first show that $\ba$ is orthogonal to the plane.}

\end{problemset}


