@article{Beurer-Kellner_Fischer_Vechev_2024, title={{Guiding {LLMs}} {T}he {R}ight {W}ay: {F}ast, {N}on-{I}nvasive {C}onstrained {G}eneration}, rights={Creative Commons Attribution 4.0 International}, url={https://arxiv.org/abs/2403.06988}, DOI={10.48550/ARXIV.2403.06988}, abstractNote={To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.}, publisher={arXiv}, author={Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin}, year={2024} }

@inproceedings{Geng_Josifoski_Peyrard_West_2023, address={Singapore}, title={{{Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning}}}, url={https://aclanthology.org/2023.emnlp-main.674}, DOI={10.18653/v1/2023.emnlp-main.674}, abstractNote={Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly. To address this issue, grammar-constrained decoding (GCD) can be used to control the generation of LMs, guaranteeing that the output follows a given structure. Most existing GCD methods are, however, limited to specific tasks, such as parsing or code generation. In this work, we demonstrate that formal grammars can describe the output space for a much wider range of tasks and argue that GCD can serve as a unified framework for structured NLP tasks in general. For increased flexibility, we introduce input-dependent grammars, which allow the grammar to depend on the input and thus enable the generation of different output structures for different inputs. We then empirically demonstrate the power and flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity disambiguation, and (3) constituency parsing. Our results indicate that grammar-constrained LMs substantially outperform unconstrained LMs or even beat task-specific finetuned models. Grammar constraints thus hold great promise for harnessing off-the-shelf LMs for a wide range of structured NLP tasks, especially where training data is scarce or finetuning is expensive. Code and data: https://github.com/epfl-dlab/GCD.}, booktitle={{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}}, publisher={Association for Computational Linguistics}, author={Geng, Saibo and Josifoski, Martin and Peyrard, Maxime and West, Robert}, editor={Bouamor, Houda and Pino, Juan and Bali, Kalika}, year={2023}, month=dec, pages={10932–10952} }

@inproceedings{Kudo_Richardson_2018, address={Brussels, Belgium}, title={{{SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing}}}, url={https://aclanthology.org/D18-2012}, DOI={10.18653/v1/D18-2012}, abstractNote={This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at https://github.com/google/sentencepiece.}, booktitle={{Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}}, publisher={Association for Computational Linguistics}, author={Kudo, Taku and Richardson, John}, editor={Blanco, Eduardo and Lu, Wei}, year={2018}, month=nov, pages={66–71} }

@inproceedings{Oh_Schuler_2024, address={Miami, Florida, USA}, title={{Leading Whitespaces of Language Models’ Subword Vocabulary Pose a Confound for Calculating Word Probabilities}}, url={https://aclanthology.org/2024.emnlp-main.202}, booktitle={{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}}, publisher={Association for Computational Linguistics}, author={Oh, Byung-Doh and Schuler, William}, editor={Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}, year={2024}, month=nov, pages={3464–3472} }

@article{Park_Wang_Berg_2024, title={{Grammar-Aligned Decoding}}, url={http://arxiv.org/abs/2405.21047}, DOI={10.48550/arXiv.2405.21047}, abstractNote={Large Language Models (LLMs) struggle with reliably generating highly structured outputs, such as program code, mathematical formulas, or well-formed markup. Constrained decoding approaches mitigate this problem by greedily restricting what tokens an LLM can output at each step to guarantee that the output matches a given constraint. Specifically, in grammar-constrained decoding (GCD), the LLM’s output must follow a given grammar. In this paper, we demonstrate that GCD techniques (and in general constrained decoding techniques) can distort the LLM’s distribution, leading to outputs that are grammatical but appear with likelihoods that are not proportional to the ones given by the LLM, and so ultimately are low-quality. We call the problem of aligning sampling with a grammar constraint, grammar-aligned decoding (GAD), and propose adaptive sampling with approximate expected futures (ASAp), a decoding algorithm that guarantees the output to be grammatical while provably producing outputs that match the conditional probability of the LLM’s distribution conditioned on the given grammar constraint. Our algorithm uses prior sample outputs to soundly overapproximate the future grammaticality of different output prefixes. Our evaluation on code generation and structured NLP tasks shows how ASAp often produces outputs with higher likelihood (according to the LLM’s distribution) than existing GCD techniques, while still enforcing the desired grammatical constraints.}, note={arXiv:2405.21047 [cs]}, number={arXiv:2405.21047}, publisher={arXiv}, author={Park, Kanghee and Wang, Jiayu and Berg-Kirkpatrick, Taylor and Polikarpova, Nadia and D’Antoni, Loris}, year={2024}, month=nov, language={en} }

@inproceedings{Pimentel_Meister_2024, address={Miami, Florida, USA}, title={{How to Compute the Probability of a Word}}, url={https://aclanthology.org/2024.emnlp-main.1020}, abstractNote={Language models (LMs) estimate a probability distribution over strings in a natural language; these distributions are crucial for computing perplexity and surprisal in linguistics research. While we are usually concerned with measuring these values for words, most LMs operate over subwords. Despite seemingly straightforward, accurately computing probabilities over one unit given probabilities over the other requires care. Indeed, we show here that many recent linguistic studies have been incorrectly computing these values. This paper derives the correct methods for computing word probabilities, highlighting issues when relying on language models that use beginning-of-word (bow)-marking tokenisers, e.g., the GPT family. Empirically, we show that correcting the widespread bug in probability computations affects measured outcomes in sentence comprehension and lexical optimisation analyses.}, booktitle={{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}}, publisher={Association for Computational Linguistics}, author={Pimentel, Tiago and Meister, Clara}, editor={Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}, year={2024}, month=nov, pages={18358–18375} }

@article{Wen-Yi_Mimno_2023, title={{Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings}}, url={http://arxiv.org/abs/2311.18034}, DOI={10.48550/arXiv.2311.18034}, abstractNote={Cross-lingual transfer learning is an important property of multilingual large language models (LLMs). But how do LLMs represent relationships between languages? Every language model has an input layer that maps tokens to vectors. This ubiquitous layer of language models is often overlooked. We find that similarities between these input embeddings are highly interpretable and that the geometry of these embeddings differs between model families. In one case (XLM-RoBERTa), embeddings encode language: tokens in different writing systems can be linearly separated with an average of 99.2\% accuracy. Another family (mT5) represents cross-lingual semantic similarity: the 50 nearest neighbors for any token represent an average of 7.61 writing systems, and are frequently translations. This result is surprising given that there is no explicit parallel cross-lingual training corpora and no explicit incentive for translations in pre-training objectives. Our research opens the door for investigations in 1) The effect of pre-training and model architectures on representations of languages and 2) The applications of cross-lingual representations embedded in language models.}, note={arXiv:2311.18034}, number={arXiv:2311.18034}, publisher={arXiv}, author={Wen-Yi, Andrea W. and Mimno, David}, year={2023}, month=nov }

@article{Zhang_Lu_Tran_Schuster_Metzler_Lin_2024, title={{Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models}}, url={http://arxiv.org/abs/2411.04530}, abstractNote={Human understanding of language is robust to different word choices as far as they represent similar semantic concepts. To what extent does our human intuition transfer to language models, which represent all subwords as distinct embeddings? In this work, we take an initial step on measuring the role of shared semantics among subwords in the encoder-only multilingual language models (mLMs). To this end, we form “semantic tokens” by merging the semantically similar subwords and their embeddings, and evaluate the updated mLMs on 5 heterogeneous multilingual downstream tasks. Results show that the general shared semantics could get the models a long way in making the predictions on mLMs with different tokenizers and model sizes. Inspections on the grouped subwords show that they exhibit a wide range of semantic similarities, including synonyms and translations across many languages and scripts. Lastly, we found the zero-shot results with semantic tokens are on par or even better than the original models on certain classification tasks, suggesting that the shared subword-level semantics may serve as the anchors for crosslingual transferring.}, note={arXiv:2411.04530 [cs]}, number={arXiv:2411.04530}, publisher={arXiv}, author={Zhang, Xinyu and Lu, Jing and Tran, Vinh Q. and Schuster, Tal and Metzler, Donald and Lin, Jimmy}, year={2024}, month=nov, language={en} }

