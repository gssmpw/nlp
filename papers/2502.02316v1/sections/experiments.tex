\begin{figure*}[t!]
    \hspace{1.8cm}
    \resizebox{0.3\textwidth}{!}{
    \input{figures/ablations/diffusion_steps/humanoid_run/legend}}%    
    \hspace{1.6cm}
    \resizebox{0.5\textwidth}{!}{
    \input{figures/legend_gym}}%
    
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/ablations/diffusion_steps/humanoid_run/diff_Steps_dis_G95_lr3e-4_humanoid_run}}
       \subcaption[]{Varying the Diffusion Steps}
       \label{fig::exps_new_ablations_vary_diff_steps::humanoid_run}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.256\textwidth}
        \centering
       \resizebox{0.9\textwidth}{!}{\input{figures/ablations/diffusion_steps/humanoid_run/runtime}}
       \subcaption[]{Runtime for 1M Steps}
       \label{fig::exps_new_ablations_runtime_diff_steps::humanoid_run}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.24\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/gym_returns/ant_v3}}
       \subcaption[]{Ant-v3}
       \label{fig::exps_new::ant-v3}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.23\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/gym_returns/humanoid_v3}}
       \subcaption[]{Humanoid-v3}
       \label{fig::exps::humanoid-v3}
    \end{minipage}\hfill
    \vspace{-2.0mm}
    \caption{\textbf{Varying the Number of diffusion steps (a)-(b).} The number of diffusion steps might affect the performance and the computation time. (a) shows DIME's learning curves for varying diffusion steps. \textit{Two} diffusion steps perform badly, whereas \textit{four} and \textit{eight} diffusion steps perform similar but still worse than \textit{16} and \textit{32} diffusion steps which perform similarly. (b) shows the computation time for 1MIO steps of the corresponding learning curves. The smaller the diffusion steps the less computation time is required. \textbf{Learning Curves on Gym Benchmark Suite (c)-(d).} We compare DIME against various diffusion baselines and CrossQ on the (c) \textit{Ant-v3} and (d) \textit{Humanoid-v3} from the Gym suite. While all diffusion-based methods are outperformed by DIME, DIME performs on par with CrossQ on the Ant environment. DIME performs favorably on the high-dimensional \textit{Humanoid-v3} environment where it also outperforms CrossQ.}
\end{figure*}
\section{Experiments}
We analyze DIME's algorithmic features with an intensive ablation study where we clarify the role of the reward scaling parameter $\alpha$, the effect of varying diffusion steps, and the gained performance boost when using a diffusion policy representation over a Gaussian representation. 
In a broad range of 13 sophisticated learning environments from different benchmark suits ranging from mujoco gym \cite{gymopenai}, deepmind control suit (DMC) \cite{dmcontrol}, and myo suite \cite{MyoSuite2022} we compare DIME's performance against recent diffusion-based RL methods \baseline{QSM} \cite{psenkalearning}, \baseline{Diffusion-QL} \cite{wang2023diffusion}, \baseline{Consistency-AC} \cite{dingconsistency} and \baseline{DIPO} \cite{yang2023policy}. Additionally, we compare against the state-of-the-art RL methods \baseline{CrossQ} \cite{bhattcrossq} and \baseline{BRO} \cite{nauman2024bigger}, where we have used the provided learning curves from the latter. Both methods use a Gaussian parameterized policy and have shown remarkable results. The considered environments are challenging locomotion and manipulation learning tasks with up to 39-dimensional action and 223-dimensional observation spaces.  
We have run all learning curves for 10 seeds and report the \textit{interquartile mean (IQM)} with a 95\% stratified bootstrap confidence interval as suggested by \citet{agarwal2021deep}.

\subsection{Ablation Studies}
\textbf{Exploration Control.} The parameter $\alpha$ balances the exploration-exploitation trade-off by scaling the reward signal. We analyze the effect of this parameter by comparing DIME's learning curves with different $\alpha$ values on the dog-run task from the DMC (see Fig. \ref{fig::exps_new_ablations_vary_alpha::dog_run}). Additionally, we show the performance of the last return measurements for each learning curve in Fig. \ref{fig::exps_new_ablations_vary_alpha::dog_run_pareto}. Too high $\alpha$ values ($\alpha=0.1$) do not incentivize maximizing the task's return leading to no learning at all, whereas small values ($\alpha\leq10^{-5})$ lead to suboptimal performance because the policy does not explore sufficiently. We can also see a clear trend that starting from $\alpha=10^{-12}$ the performance gradually increases until the best performance is reached for $\alpha=10^{-3}$. 

\textbf{Diffusion Policy Benefit.} We aim to analyze the performance benefits of the diffusion-parameterized policy compared to a Gaussian parameterization in the same setup by only exchanging the policy and the corresponding policy update. This comparison ensures that the Gaussian policy is trained with the identical implementation details from DIME as described in Sec. \ref{sec:implementation details} and showcases the performance benefits of a diffusion-based policy. Fig. \ref{fig::exps_new_ablations_gauss_vs_diff_distrq::humanoid_run} and  \ref{fig::exps_new_ablations_gauss_vs_diff_distrq::dog_run} show the learning curves of both versions on DMC's humanoid-run and dog-run environments. The diffusion policy's expressivity leads to a higher aggregated return in the humanoid-run and to significantly faster convergence in the high-dimensional dog-run task. We attribute this performance benefit to an improved exploration behavior.  

\textbf{Number of Diffusion Steps.} The number of diffusion steps determines how accurately the stochastic differential equations are simulated and is a hyperparameter that affects the performance. Usually, the higher the number of diffusion steps the better the model performs at the burden of higher computational costs. In Fig. \ref{fig::exps_new_ablations_vary_diff_steps::humanoid_run} we plot DIME's performance for varying diffusion steps on DMC's humanoid-run environment and report the corresponding runtimes for 1 Mio environment steps in Fig. \ref{fig::exps_new_ablations_runtime_diff_steps::humanoid_run} on an \textit{Nvidia A100} GPU machine. With an increasing number of diffusion steps, the performance and runtime increases. However, from $16$ diffusion steps on, the performance stays the same.

\subsection{Comparisson Against Baselines}
We consider environments with high dimensional observation and action spaces from three benchmark suits for a robust performance assessment (please see Appendix \ref{apdx::environment_details}). 

\textbf{Gym Environments.} Fig \ref{fig::exps_new::ant-v3} and Fig. \ref{fig::exps::humanoid-v3} show the learning curves for the \textit{An-tv3} and \textit{Humanoid-v3} tasks respectively. While the diffusion-based baselines perform reasonably well on the \textit{Ant-v3} task with DIPO outperforming the rest, they are all outperformed by DIME and CrossQ which perform comparably. On the \textit{Humanoid-v3} DIME achieves a significantly higher return than all baselines.

\begin{figure*}[t!]
    \centering  
    \begin{minipage}[b]{0.245\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/dog_run}}
       \subcaption[]{Dog Run}
       \label{fig::exps_new::dog_run}
    \end{minipage}\hfill
   \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/dog_trot}}
       \subcaption[]{Dog Trot}
       \label{fig::exps_new::dog_trot}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/dog_walk}}
       \subcaption[]{Dog Walk}
       \label{fig::exps_new::dog_walk}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/dog_stand}}
       \subcaption[]{Dog Stand}
       \label{fig::exps_new::dog_stand}
    \end{minipage}\hfill
    %\vspace{0.15cm}
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/humanoid_run}}
       \subcaption[]{Humanoid Run}
       \label{fig::exps_new::humanoid_run}
    \end{minipage}\hfill
   \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/humanoid_walk}}
       \subcaption[]{Humanoid Walk}
       \label{fig::exps_new::humanoid_walk}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/dmc_task_returns/humanoid_stand}}
       \subcaption[]{Humanoid Stand}
       \label{fig::exps_new::humanoid_stand}
    \end{minipage}\hfill    
    \begin{minipage}[b]{0.25\textwidth}
    % Legend is in this subplot
        \centering
        \hspace{0.5cm}
        \vspace{0.5cm}
       \resizebox{0.75\textwidth}{!}{\input{figures/legend_dmc}}       
       \label{fig::exps_new::humanoid_stand}
    \end{minipage}\hfill    
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/myo_suite_success_rates/myo_hand_obj_hold_rndm}}
       \subcaption[]{Object Hold Hard}
       \label{fig::exps_new::myo_hand_obj_hold_hard}
    \end{minipage}\hfill
   \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/myo_suite_success_rates/myo_hand_reach_rndm}}
       \subcaption[]{Reach Hard}
       \label{fig::exps_new::myo_hand_reach_hard}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/myo_suite_success_rates/myo_hand_key_turn_rndm}}
       \subcaption[]{Key Turn Hard}
       \label{fig::exps_new::myo_hand_key_turn_rndm}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
       \resizebox{1\textwidth}{!}{\input{figures/myo_suite_success_rates/myo_hand_pen_twirl_rndm}}
       \subcaption[]{Pen Twirl Hard}
       \label{fig::exps_new::myo_hand_pen_twirl_rndm}
    \end{minipage}\hfill
    \vspace{-2mm}
    \caption{\textbf{Training curves on DMC's dog, humanoid tasks, and the hand environments from the MYO Suite.} DIME performs favorably on the high-dimensional dog tasks where it significantly outperforms all baselines (dog-run) or converges faster to the final performance. On the humanoid tasks, DIME outperforms all diffusion-based baselines, CrossQ and BRO Fast, and performs on par with BRO on the humanoid-stand task and slightly worse on the humanoid-run and humanoid-walk tasks. In the MYO SUITE environments, DIME performs consistently on all tasks, either outperforming the baselines or performing on par.}
    \label{fig::exps_new::dmc_tasks_myo}
\end{figure*}

\textbf{DMC: Dog and Humanoid Tasks (Fig. \ref{fig::exps_new::dmc_tasks_myo}).} 
We benchmark on DMC suit's challenging \textit{dog} and \textit{humanoid} environments, where we additionally consider BRO and BRO Fast as a Gaussian-based policy baseline. 
BRO Fast is identical to BRO but differs only in the update-to-data (UTD) ratio of two as DIME and CrossQ. 
Please note that we used the online available learning curves provided by the official implementation for BRO. 
DIME outperforms all baselines significantly on the \textit{dog-run} environment and converges faster to the same end performance on the remaining dog environments (see Fig. \ref{fig::exps_new::dog_run} - \ref{fig::exps_new::dog_stand}). BRO has slightly higher average performance on the \textit{humanoid-run} and \textit{humanoid-walk} (see Fig. \ref{fig::exps_new::humanoid_walk} - \ref{fig::exps_new::humanoid_run})) tasks indicating that DIME performs favorably on more high-dimensional tasks like the dog environments and tasks from the myo suite. However, DIME's asymptotic behavior in the \textit{humanoid-run} achieves slightly higher aggregated performance than BRO, where we have run both algorithms for 3M steps (Fig. \ref{fig::appendix_dime_bro_humanoid_run_long}). 
However, BRO requires full parameter resets leading to performance drops during training and it is run with a UTD ratio of 10 which is 5 times higher than DIME. This leads to longer training times. 
As reported in their paper \cite{nauman2024bigger}, BRO needs an average training time of 8.5h whereas DIME trains in approximately 4.5h with 16 diffusion steps on the humanoid-run with the same Hardware (\textit{Nvidia A100}).  

\textbf{MYO Suite (Fig. \ref{fig::exps_new::dmc_tasks_myo}).} Except for \textit{pen twirl hard} (Fig. \ref{fig::exps_new::myo_hand_pen_twirl_rndm}), DIME consistently outperforms BRO and BRO Fast in that it converges to a higher or faster to the end success rate. 
DIME also consistently outperforms CrossQ in terms of the achieved success rates on all the tasks except for the object hold hard task \ref{fig::exps_new::myo_hand_obj_hold_hard} where DIME converges faster. 


