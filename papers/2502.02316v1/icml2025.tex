%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\input{util/math_commands.tex}

\usepackage{url}
\usepackage{footmisc}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{tikz}

\usepackage{color}
\usetikzlibrary{positioning, arrows, automata}
\usetikzlibrary{backgrounds, calc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.8}
\usepackage{pgfplotstable}
\usepgfplotslibrary{groupplots}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% Colors used for tikz plotting
\input{__color_style__}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

\newcommand{\fpi}{\vec{\pi}}
\newcommand{\bpi}{\cev{\pi}}
\newcommand{\bq}{\cev{q}}
\newcommand{\ppi}{\pi^{\theta}}

\newcommand{\ac}{a}
\newcommand{\st}{s}
\newcommand{\dQ}{Q_{\text{D}}}
\newcommand{\dV}{V_{\text{D}}}
\newcommand{\dpi}{\pi_{\text{D}}}
\newcommand{\St}{\mathcal{S}}
\newcommand{\Ac}{\mathcal{A}}
\newcommand{\Ent}{\mathcal{H}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\fP}{\vec{\mathbb{P}}}
\newcommand{\bP}{\cev{\mathbb{P}}}
\newcommand{\plb}{\ell^{\theta}_{\mathcal{H}}}
\newcommand{\lb}{\ell^{\theta}_{\mathcal{H}}}
\definecolor{nfvi}{RGB}{255,127,14} % orange
\newcommand{\baseline}[1]{\textcolor{nfvi}{#1}}
\newcommand{\blb}{\ell_{\bpi}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{DIME: Diffusion-Based Maximum Entropy Reinforcement Learning}

\begin{document}

\twocolumn[
\icmltitle{DIME: Diffusion-Based Maximum Entropy Reinforcement Learning}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}
% Onur Celik, Zechu Li, Denis Blessing, Ge Li, Daniel Palenicek, Jan Peters, Georgia Chalvatzaki, Gerhard Neumann
\begin{icmlauthorlist}
\icmlauthor{Onur Celik}{kit}
\icmlauthor{Zechu Li}{tud}
\icmlauthor{Denis Blessing}{kit}
\icmlauthor{Ge Li}{kit}
\icmlauthor{Daniel Palenicek}{tud,hessianai}\\
\icmlauthor{Jan Peters}{tud,hessianai,dfki,cogscience}
\icmlauthor{Georgia Chalvatzaki}{tud,hessianai}
\icmlauthor{Gerhard Neumann}{kit}
\end{icmlauthorlist}

\icmlaffiliation{kit}{Karlsruhe Institute of Technology, Germany}
\icmlaffiliation{tud}{Technical University of Darmstadt, Germany}
\icmlaffiliation{hessianai}{Hessian.AI}
\icmlaffiliation{dfki}{German Research Center for AI(DFKI)}
\icmlaffiliation{cogscience}{Centre for Cognitive Science, TU Darmstadt}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Onur Celik}{celik@kit.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\begin{abstract}
Maximum entropy reinforcement learning (MaxEnt-RL) 
has become the standard approach to RL due to its beneficial exploration properties. Traditionally, policies are parameterized using Gaussian distributions, which significantly limits their representational capacity. Diffusion-based policies offer a more expressive alternative, yet integrating them into MaxEnt-RL poses challengesâ€”primarily due to the intractability of computing their marginal entropy. 
To overcome this, we propose Diffusion-Based Maximum Entropy RL (DIME). \emph{DIME} leverages recent advances in approximate inference with diffusion models to derive a lower bound on the maximum entropy objective. 
Additionally, we propose a policy iteration scheme that provably converges to the optimal diffusion policy. Our method enables the use of expressive diffusion-based policies while retaining the principled exploration benefits of MaxEnt-RL, significantly outperforming other diffusion-based methods on challenging high-dimensional control benchmarks. It is also competitive with state-of-the-art non-diffusion based RL methods while requiring fewer algorithmic design choices and smaller update-to-data ratios, reducing computational complexity.  
\end{abstract}


\input{sections/introduction}
\input{sections/related_works}
\input{sections/preliminaries}
\input{sections/experiments}


\section{Conclusion and Future Work}
In this work, we introduced DIME, a method for learning diffusion models for maximum entropy reinforcement learning by leveraging connections to approximate inference.
We view this work as a starting point for exciting future research. Specifically, we explored \textit{denoising} diffusion models, where the forward process follows an Ornstein-Uhlenbeck process. However, approximate inference with diffusion models is an active and rapidly evolving field, with numerous recent advancements that consider alternative stochastic processes. For example, \citet{richterimproved} proposed learning both the forward and backward processes, while \citet{nusken2024transport} further enhanced exploration by incorporating the gradient of the target density into the diffusion process. Additionally, \citet{chen2024sequential} combined learned diffusion models with Sequential Monte Carlo \cite{del2006sequential}, resulting in a highly effective inference method. These approaches hold significant promise for further improving diffusion-based policies in RL. We have conducted preliminary experiments on the framework from \citet{richterimproved} and provide them in Appendix \ref{appdx:gbs}.
Finally, we note that the loss function used in this work (see Eq. \ref{eq: joint control as inference2}) is based on the Kullback-Leibler divergence. However, in principle, any divergence could be used. For instance, the log-variance divergence \cite{richterimproved} has shown promising results in optimizing diffusion models for approximate inference \cite{chen2024sequential, noble2024learned}. Exploring alternative objectives could lead to additional performance improvements.


\bibliography{icml2025}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{sections/appendix/derivations}
\input{sections/appendix/environments}
\input{sections/appendix/hyper_parameters}
\input{sections/appendix/extensions_to_general_samplers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
