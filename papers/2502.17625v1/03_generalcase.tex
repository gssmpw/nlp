\section{Instance-Dependent Regret Bounds for General Zero-Sum Games}\label{sec:MSNE}
{
\allowdisplaybreaks

We now provide and discuss our main theorem for general zero-sum games,
which states two regret bounds both in the form of $c_1\log T + \sqrt{c_2T}$ for some game-dependent constants $c_1$ and $c_2$.
\begin{theorem}\label{thm:general-bound-together}
If both players follow the Tsallis-INF algorithm, then for any $x \in \cP_m$ and $y\in \cP_n$, the following two upper bounds simultaneously hold for the quantity: %
\begin{equation}
\max\cbrm[\Big]{
            \Rr_T(x)
            +
            \sqrt{T}\constd{\E\sbrm[\big]{
                D(x, x_{T+1})
            }},
            \Rc_T(y)
            +
            \sqrt{T}\constd{\E\sbrm[\big]{
                D(y, y_{T+1})
            }}}
    \tag{$\star$}\label{eq:thm2-lhs}
\end{equation}
\begin{itemize}[leftmargin=*]
\item \label{enum:main-bound-omega} \hspace{1in}
$\displaystyle
\rbr{\text{\ref{eq:thm2-lhs}}}=
O\rbrm[\Big]{\sqrt{T(|I|+|J|-2)} + 
\omegar
\log_{+}\frac{mT}{\omegar^2}
+
\omegac
\log_{+}\frac{nT}{\omegac^2}},
$


where $(\xstar, \ystar)$ is an NE with maximum support, $I$ and $J$ are the support of them respectively,
$\Deltar = \rbrm[\big]{\xstar^\top A \ystar}\one - A \ystar$, %
$\Deltac = A^\top \xstar - \rbrm[\big]{\xstar^\top A \ystar}\one$, $\omegar=\sum_{i \notin I}\frac{1}{\Deltar(i)}$, and $\omegac=\sum_{j \notin J}\frac{1}{\Deltac(j)}$
;

\item \label{enum:main-bound-gamma} \hspace{1in}
$\displaystyle
\rbr{\text{\ref{eq:thm2-lhs}}}=
O\rbrm[\bigg]{\sqrt{T}\rbrm[\Big]{
    \gammar\sqrt{\log_{+}\frac{m}{\gammar^2}}+\gammac\sqrt{\log_{+}\frac{n}{\gammac^2}}
} + 
\frac{m+n}{c}\log T
},
$

where $\gammar = \max_{\xstar \in \xstarset} \sum_{i\in [m]} \sqrt{\xstar(i)} - 1$, $\gammac = \max_{\ystar \in \ystarset} \sum_{j\in [n]} \sqrt{\ystar(j)} - 1$,
and $c >0$ is a game-dependent constant such that $\DG(x,y)\geq c \min_{\xstar\in\xstarset}\nbr{x-\xstar}_1 +c \min_{\ystar\in\ystarset}\nbr{y-\ystar}_1$ holds for all $(x,y) \in \cP_m \times \cP_n$ (which always exists).

\end{itemize}

\end{theorem}



While the key of the proof also relies on the self-bounding technique that is common in the analysis of Tsallis-INF,
some new ideas are required; see details in Appendix~\ref{sec:app:proof-thm2}.
We note that Eq.~\eqref{eq:thm2-lhs} is an upper bound on $\max\{\Rr_T(x), \Rc_T(x)\}$ since Bregman divergence is non-negative,
and we include the Bregman divergence terms in Eq.~\eqref{eq:thm2-lhs} because they are crucial for proving the last-iterate convergence result in Section~\ref{sec:last-iterate}.

In both bounds of Theorem~\ref{thm:general-bound-together}, the coefficients for $\sqrt{T}$ are smaller than the trivial bound $\max\{\sqrt{m}, \sqrt{n}\}$ and reflect the proximity of the NE to a pure strategy; specifically, $\sqrt{\abs{I}+\abs{J}-2}=\gammar=\gammac=0$ when the game has a unique PSNE. This case will be further elaborated in Section~\ref{sec:PSNE}.
More generally, the coefficient $\sqrt{\abs{I}+\abs{J}-2}$ in the first bound is small when the support of the NE is small, and this bound can be seen as a generalization of that in~\citet{balsubramani2016instance} for the special case of dueling bandits.
On the other hand, the coefficients $\gammar$ and $\gammac$ in the second bound are small when the NE are close to the boundary so that some actions have much larger weight than others.
This kind of problem dependence resembles that of~\citet{maiti2023instance} who study sample complexity of finding approximate NE in the special case of $2\times n$ games.
Indeed, their sample complexity to reach $\epsilon$ duality gap is at a high-level of order $1/\epsilon^2$ multiplied with a qualitatively similar problem-dependent constant, which exactly corresponds to our $\sqrt{T}$ regret term.

The inverse coefficients for the $\log T$ term, $\Deltar$ ($\Deltac$) and $c$, quantify the relative suboptimality of alternative actions compared to the NE. 
In particular, $\Deltar$ and $\Deltac$ are exactly the standard suboptimality gaps for a stochastic MAB instance with loss vector $-A\ystar$ and $A^\top\xstar$ respectively.
Very roughly speaking, this $\log T$ term can then be interpreted as the overhead of finding the non-support of the NE, which is relatively small and is as if playing an MAB with the opponent fixed to a minimax or maximin strategy.
On the other hand, the meaning of the inverse coefficient $c$ is less clear, but its existence is guaranteed by~\citet[Theorem~5]{wei2021linear}, and we also refer the reader to their work for more details on this constant.
It only approaches zero when a strategy sufficiently different from the NE has a disproportionately small duality gap. We demonstrate this with an example:
\begin{equation}
    A=\sbrm[\bigg]{
        \begin{array}{cc}
            0 &             3\eps \\
            1 - \eps &      2\eps
        \end{array}
    },\label{eq:example-2x2-game-matrix-simplified}
\end{equation}
where $0<\eps<\frac{1}{3}$. This game has a unique NE $\xstar=(1-3\eps,3\eps), \ystar=(\eps,1-\eps)$. Direct calculation shows that $c=\eps$ satisfies the requirement for $c$. When $\eps$ approaches zero, $\gamma\approx \sqrt{\eps}$ vanishes while $\frac 1c=\frac 1\eps$ explodes.
In particular, when $\epsilon \approx 1/T^{1/3}$, our regret bound is of order $T^{1/3}$, thus provably smaller than the worst-case $\sqrt{T}$ regret.
We will revisit this example in numerical experiments in Section~\ref{sec:experiments}.


    

    



    

}
