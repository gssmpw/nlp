\newcommand{\supp}{\mathrm{supp}}
\section{Proofs in \cref{sec:theory}}


\paragraph{Notations}
For a distribution over finite class $\fS$, denote $\supp(P)\subseteq \fS$ as the support of $P$. For two distributions $P,Q$ over finite set $\fS$, denote the cross entropy as
\begin{align*}
H(P,Q)=-\sum_{x\in \fS }P(x)\log Q(x),
\end{align*}
and denote the KL divergence as
\begin{align*}
KL(P,Q)=-\sum_{x\in \fS }P(x)\log \frac{Q(x)}{P(x)}.
\end{align*}



\subsection{Proof of~\cref{thm:exponential task generalization}}\label{appendix:maintheorem}

To identify the true distribution $\tilde\theta$ from $\Theta$ at inference time, we need the following lemma to provide a non-asymptotic bound for distribution discrimination. 



\begin{lemma}[Non-Asymptotic Discrimination of Two Distributions]\label{lem:dist_discrim}
Let $\fS$ be any finite set and $P, Q \in \Delta(\mathcal{S})$ be two distributions with total variation distance $\tv (P, Q) = c > 0$. Suppose we observe $n$ independent samples $X_1, \dots, X_n$ from an unknown distribution $Y$, where $Y$ is either $P$ or $Q$. Then, there exists a testing algorithm that identifies $Y$ with probability at least $1 - \delta$ provided that 
\[
n \geq \frac{2 \ln(1/\delta)}{c^2}.
\]
\end{lemma}

\begin{proof}
\textbf{Testing Procedure.}  
Define the testing statistic $\phi$ as follows:
\[
\phi = \frac{1}{n} \sum_{i=1}^n (-1)^{\mathbf{1}[P(X_i) < Q(X_i)]}.
\]
Equivalently, $\phi$ can be written in terms of the empirical distribution $\hat{Y}_n$:
\[
\phi = \sum_{x \in \mathcal{S}} \hat{Y}_n(x) \cdot (-1)^{\mathbf{1}[P(x) < Q(x)]},
\]
where $\hat{Y}_n(x) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}[X_i = x]$.

Compute the expected values of $\phi$ under $Y = P$ and $Y = Q$:
\[
\mu_P = \sum_{x \in \mathcal{S}} P(x) \cdot (-1)^{\mathbf{1}[P(x) < Q(x)]}, \quad
\mu_Q = \sum_{x \in \mathcal{S}} Q(x) \cdot (-1)^{\mathbf{1}[P(x) < Q(x)]}.
\]
The algorithm reports $\hat{Y} = P$ if $|\phi - \mu_P| < |\phi - \mu_Q|$, and $\hat{Y} = Q$ otherwise.

\textbf{Proof of Correctness.}  
Without loss of generality, assume $Y = P$. We analyze the probability of error:
\[
\Pr\left( \hat{Y} \neq P \right) = \Pr\left( |\phi - \mu_P| \geq |\phi - \mu_Q| \right).
\]
Note that $\mathbb{E}[\phi] = \mu_P$ under $Y = P$. From the definition of total variation distance:
\[
\mu_Q - \mu_P = \sum_{x \in \mathcal{S}} (Q(x) - P(x)) \cdot (-1)^{\mathbf{1}[P(x) < Q(x)]} = 2 \cdot d_{\mathrm{TV}}(P, Q) = 2c.
\]
Thus, the error probability can be bounded as:
\[
\Pr\left( |\phi - \mu_P| \geq |\phi - \mu_Q| \right) \leq \Pr\left( \phi \geq \mu_P + c \right).
\]
Since $\phi$ is the average of $n$ independent random variables taking values in $\{-1, +1\}$, by Hoeffding's inequality:
\[
\Pr\left( \phi \geq \mu_P + c \right) \leq \exp\left( -\frac{c^2 n}{2} \right).
\]
Setting $\exp\left( -\frac{c^2 n}{2} \right) \leq \delta$ gives the required sample complexity $n \geq \frac{2 \ln(1/\delta)}{c^2}$.
\end{proof}

To prove Theorem \ref{thm:exponential task generalization}, we introduce the following lemma:

\begin{lemma}\label{lem:exponential task generalization}  % 修改标签避免冲突
Consider a compositional task class $\mathcal{F}$ satisfying Assumption~\ref{assm: compositional structure}. Suppose the training tasks $\fF_\train= \{f_{\theta^i}\}_{i=1}^{n_\theta}$ satisfy the \textbf{per-component coverage} condition: for every timestep $t \in [T]$,
\[
\{P_{\theta^i_t}\}_{i=1}^{n_\theta} = \mathcal{P}_{\Theta_t}.
\]
Then there exists a learner $\mathcal{A}$ such that when trained on $\mathcal{D}_{\mathrm{train}} = \{\mathcal{D}_i\}_{i=1}^{n_\theta}$ with $\mathcal{D}_i \iid P_{\theta^i}$ where $\fD_i$ consists of $n_x$ i.i.d. samples, and given $\ell \geq \frac{2\ln(100Tn_\theta)}{c^2}$ inference-time demonstration samples i.i.d. sampled from unseen task $P_{\tilde \theta}$, denoted by $\fD_\demo$, 
then it holds that:
\[
\lim_{n_x \to \infty} \Pr\left[ \mathcal{A}(\mathcal{D}_{\demo}; \mathcal{D}_{\mathrm{train}}) \neq (P_{\tilde{\theta}_1}, \dots, P_{\tilde{\theta}_T}) \right] \leq 0.01,
\]
where the probability is over the randomness in $\mathcal{D}_{\mathrm{train}}$ and $\mathcal{D}_{\demo}$.
\end{lemma}

\begin{proof}\textbf{}
    


\textbf{Step 1: Training Stage.}

We construct a learning algorithm that recovers
\[
f_{\theta^i} \;=\; \bigl(P_{\theta_1^i},\dots,P_{\theta_T^i}\bigr)
\]
from 
\[
\mathcal{D}_i \;=\; \{(\bm x^{i,j},\, \bm y^{i,j})\}_{j=1}^{n_x}
\iid\;  P_{\theta^i}(\bm x,\bm y),
\]
which is part of the training set $\mathcal{D}_{\mathrm{train}}$. The procedure is shown below:

\begin{algorithm}[H]
\caption{Training Stage}
\begin{algorithmic}[1]
\Require Training set $\mathcal{D}_{\mathrm{train}}=\{\mathcal{D}_i\}_{i=1}^{n_\theta}$
\For{$i = 1$ to $n_\theta$}
  \For{$t = 1$ to $T$}
    \State $\mathrm{Observed\_Support}_t \;\gets\; \{(\bm x^{i,j},\,\bm y^{i,j}_{1:t})\}_{j=1}^{n_x}$
    \State $\mathcal{P}_{\Xi_t'} \;\gets\;
            \Bigl\{
              P_{\xi_t}\in \mathcal{P}_{\Xi_t}
              :\, \mathrm{supp}\bigl(P_{\theta^i_{1:t-1},\,\xi_t}\bigr)
              = \mathrm{Observed\_Support}_t
            \Bigr\}$
    \State $\hat{\theta}_t^i \;\gets\;
           \displaystyle \arg\max_{\xi_t \,\in\, \Xi_t'} 
           \sum_{j=1}^{n_x} \log 
             P_{\hat{\theta}_{1:t-1}^i,\,\xi_t}\!\bigl(\bm x^{i,j},\, \bm y^{i,j}_{1:t}\bigr)$
  \EndFor
\EndFor
\State \textbf{return} $\fP_{\hat\Theta_t}=\{{P}_{\hat{\theta}_t^i}\}_{i=1}^{n_\theta}$ for each $t\in[T]$.
\end{algorithmic}
\end{algorithm}

We now show that, as $n_x \to \infty$, 
\[
\Pr\bigl[
  \mathcal{P}_{\hat{\Theta}_t} \;=\; \mathcal{P}_{\Theta_t}
  \;\;\forall\,t \in [T]
\bigr] \;\rightarrow\;1.
\]
Assume $\hat{\theta}^i_{1:t-1} = \theta^i_{1:t-1}$. As $n_x\to \infty$,
\[
\Pr\bigl[
  \mathrm{Observed\_Support}_t \;\neq\; \mathrm{supp}\bigl(P_{\theta^i_{1:t}}\bigr)
\bigr]
\;\le\;
\sum_{(\bm x,\bm y_{1:t}) \,\in\, \mathrm{supp}\bigl(P_{\theta^i_{1:t}}\bigr)}
\Pr\bigl[
  (\bm x^{i,j},\bm y^{i,j}_{1:t}) \neq (\bm x,\bm y_{1:t}) \;\;\forall\,j \in [n_x]
\bigr]
\;\to\; 0.
\]

Conditioned on
$\mathrm{Observed\_Support}_t 
  = \mathrm{supp}\bigl(P_{\theta^i_{1:t}}\bigr)$,
any $P_{\xi_t}$ in $\mathcal{P}_{\Xi_t}'$ must share the same support:
\[
\mathrm{supp}\bigl(P_{\theta^i_{1:t-1},\,\xi_t}\bigr)
=
\mathrm{supp}\bigl(P_{\theta^i_{1:t-1},\,\theta_t^i}\bigr).
\]
Thus the cross-entropy is finite. By the law of large numbers and Pinsker’s inequality, for $P_{\xi_t} \neq P_{\theta_t^i}$ we have

\begin{align*}
&\lim _{n_x\to \infty }\left(\frac{1}{n_x} \sum_{j=1}^{n_x} \log P_{\theta_{1:t-1}^i,\theta^i_t}(\bm x^{i,j}, \bm y^{i,j}_{1:t})-\frac{1}{n_x} \sum_{j=1}^{n_x} \log P_{\theta_{1:t-1}^i,\xi_t}(\bm x^{i,j}, \bm y^{i,j}_{1:t})\right)\\
\to& KL(P_{\theta_{1:t-1}^i,\theta_t^i},P_{\theta_{1:t-1}^i,\xi_t})\\
\geq& 2\tv({P_{\theta_{1:t-1}^i,\theta_t^i},P_{\theta_{1:t-1}^i,\xi_t})}^2\\
>&0
\end{align*}
almost surely. Thus,
\[
\Pr\bigl[P_{\hat{\theta}_t^i} \neq P_{\theta_t^i}\bigr]
\;\le\;
\sum_{\xi_t \,\in\, \Xi_t',\, P_{\xi_t}\neq P_{\theta_t^i}}
  \Pr\Bigl[
    \tfrac1{n_x} \sum_{j=1}^{n_x} \log P_{\theta^i_{1:t-1},\,\xi_t}(\bm x^{i,j},\,\bm y^{i,j}_{1:t})
    \;\ge\;
    \tfrac1{n_x} \sum_{j=1}^{n_x} \log P_{\theta^i_{1:t-1},\,\theta_t^i}(\bm x^{i,j},\,\bm y^{i,j}_{1:t})
  \Bigr]
\;\to\; 0.
\]
Recursively applying this argument from $t=1$ to $T$ and taking a union bound over all $i\in[n_\theta]$ and $t\in[T]$,
\[
\lim_{n_x\to\infty} 
\Pr\bigl[~\exists\, (t,i) : P_{\hat{\theta}_t^i} \neq P_{\theta_t^i}\bigr]
\;=\;0.
\]
Finally, by the assumption that 
$\{P_{\theta^1_t}, \dots, P_{\theta^{n_\theta}_t}\} = \mathcal{P}_{\Theta_t}$ 
for each $t$, we conclude
\[
\Pr\Bigl[\mathcal{P}_{\hat{\Theta}_t} \;=\; \mathcal{P}_{\Theta_t} 
      \;\;\forall\,t \in[T]\Bigr]
\;\to\;1
\quad\text{as}\quad
n_x\to\infty.
\]




\subsection*{Step 2: Inference Stage}

Assume that, in the training phase, the learner identifies the true distribution sets 
\[
\fP_{\hat{\Theta}_t} \;=\; \bigl\{P_{\hat{\theta}_t^1}, \dots, P_{\hat{\theta}_t^{n_\theta}}\bigr\}
\;=\; 
\fP_{\Theta_t}
\quad
\text{for all }t=1,\dots,T.
\]
We now construct an algorithm that, given 
\(\ell \,\ge\, \tfrac{2\,\ln\bigl(100\,T\,n_{\theta}\bigr)}{c^2}\) 
independent samples from the unseen composite task 
\[
f_{\tilde{\theta}} 
\;=\;
\bigl(P_{\tilde{\theta}_1},\,\dots,\,P_{\tilde{\theta}_T}\bigr),
\]
outputs the same distribution tuple 
\(\bigl(P_{\tilde{\theta}_1},\,\dots,\,P_{\tilde{\theta}_T}\bigr)\) 
with probability at least \(0.99\). 

To achieve this, we leverage the distribution discrimination technique of Lemma~\ref{lem:dist_discrim} to distinguish between candidates in $\fP_{\hat{\Theta}_t}$, given sufficiently many demonstration samples.

\begin{algorithm}[H]
\caption{Inference Stage}
\label{alg:inference}
\begin{algorithmic}[1]
\Require Inference-time demonstration samples 
\(\fD_{\demo} \;=\; \{(\tilde{\bm x}^j,\,\tilde{\bm y}^j)\}_{j=1}^{\ell}\) 
i.i.d.\ from \(P_{\tilde{\theta}}\), 
and the identified sets
\(\fP_{\hat{\Theta}_t} = \{P_{\hat{\theta}_t^1}, \dots, P_{\hat{\theta}_t^{n_\theta}}\}\) 
for each \(t \in [T]\).

\For{$t = 1$ to $T$}
  \State Initialize \(P_{\zeta_t} \gets P_{\hat{\theta}_t^1}\). 
  \For{$i = 2$ to $n_\theta$}
    \State Compute
      \[
      \phi 
      \;\leftarrow\; 
      \frac{1}{\ell}\,\sum_{j=1}^{\ell} 
      \;(-1)^{\,\mathbf{1}\bigl[
        P_{\zeta_{1:t-1},\,\zeta_t}(\tilde{\bm x}^j,\tilde{\bm y}^j_{1:t})
        \;<\;
        P_{\zeta_{1:t-1},\,\hat{\theta}_t^i}(\tilde{\bm x}^j,\tilde{\bm y}^j_{1:t})
      \bigr]}\,.
      \]
    \If{\begin{align*}
      &\left|\,
        \phi 
        \;-\;
        \sum_{(\bm x,\bm y_{1:t})\in\fX\times \fY^t}
        P_{\zeta_{1:t-1},\,\hat{\theta}_t^i}(\bm x,\bm y_{1:t})\;
        (-1)^{\,\mathbf{1}\bigl[
          P_{\zeta_{1:t-1},\,\zeta_t}(\bm x,\bm y_{1:t})
          < 
          P_{\zeta_{1:t-1},\,\hat{\theta}_t^i}(\bm x,\bm y_{1:t})
        \bigr]}
      \right|\\<&
      \left|\,
        \phi 
        \;-\;
        \sum_{(\bm x,\bm y_{1:t})\in\fX\times \fY^t} 
        P_{\zeta_{1:t-1},\,\zeta_t}(\bm x,\bm y_{1:t})\; 
        (-1)^{\,\mathbf{1}\bigl[
          P_{\zeta_{1:t-1},\,\zeta_t}(\bm x,\bm y_{1:t})
          < 
          P_{\zeta_{1:t-1},\,\hat{\theta}_t^i}(\bm x,\bm y_{1:t})
        \bigr]}
      \right|.
      \end{align*}}
      \State Update \(P_{\zeta_t} \gets P_{\hat{\theta}_t^i}\).
    \EndIf
  \EndFor
\EndFor
\State \textbf{return} \(\bigl(P_{\zeta_1},\,\dots,P_{\zeta_T}\bigr)\).
\end{algorithmic}
\end{algorithm}

\paragraph{Error Analysis.}
Let $P_{\zeta_t}$ be the chosen distribution at step $t$. 
Given $P_{\zeta_{1:t-1}} = P_{\tilde{\theta}_{1:t-1}}$, 
Lemma~\ref{lem:dist_discrim} ensures that any incorrect candidate can be detected with high probability, as long as $P_{\tilde{\theta}_t} \in \fP_{\hat{\Theta}_t}$. Specifically,
\begin{align*}
&\Pr\Bigl[P_{\zeta_t} \,\neq\, P_{\tilde{\theta}_t}
  \;\bigm|\; 
  P_{\zeta_{1:t-1}} = P_{\tilde{\theta}_{1:t-1}}
\Bigr]\\
\;\le\;&
\sum_{i=2}^{n_\theta}
\Pr\Bigl[
  \text{distribution testing fails at step $i$}
  \;\bigm|\;
  \zeta_t = \tilde{\theta}_t 
  \;\text{or}\;
  \hat{\theta}_t^i = \tilde{\theta}_t
\Bigr]
\;\le\;
n_\theta\,\exp\!\bigl(-\tfrac{c^2\,\ell}{2}\bigr).
\end{align*}
A union bound over $t=1,\dots,T$ then implies
\[
\Pr\bigl[
  (P_{\zeta_1},\dots,P_{\zeta_T})
  \,\neq\,
  (P_{\tilde{\theta}_1},\dots,P_{\tilde{\theta}_T})
\bigr]
\;\le\;
T\,n_\theta\,\exp\!\bigl(-\tfrac{c^2\,\ell}{2}\bigr).
\]
Since
\(\ell \,\ge\, \tfrac{2\,\ln\bigl(100\,T\,n_\theta\bigr)}{c^2}\),
we get 
\[
T\,n_\theta\,\exp\;\bigl(-\tfrac{c^2\,\ell}{2}\bigr) 
\;\leq \;
0.01.
\]


\subsection*{Step 3: Combining Training and Inference}

From the results of Step 1 and Step 2, we have
\begin{align*}
&\lim_{n_x \to \infty} 
  \Pr\bigl[
    \mathcal{A}(\mathcal{D}_{\demo};\,\mathcal{D}_{\mathrm{train}}) 
    \;\neq\; 
    (P_{\tilde{\theta}_1}, \dots, P_{\tilde{\theta}_T})
  \bigr]
\\
\quad \le &
\lim_{n_x\to\infty} \Bigl(
  \Pr\bigl[
    (P_{\zeta_1},\dots,P_{\zeta_T}) 
    \neq 
    (P_{\tilde{\theta}_1}, \dots, P_{\tilde{\theta}_T})
    \;\bigm|\;
    \fP_{\hat{\Theta}_t} = \fP_{\Theta_t}
    \;\forall t
  \bigr]
  \;+\;
  \Pr\bigl[
    \exists\,t \in [T]:\, \fP_{\hat{\Theta}_t} \neq \fP_{\Theta_t}
  \bigr]
\Bigr)
\\
\quad = &\; 0.01 + 0 \;=\; 0.01.
\end{align*}
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:exponential task generalization}]
By Lemma~\ref{lem:exponential task generalization}, it suffices to verify that per-component coverage condition holds for each timestep with high probability when $n_\theta = \d \ln\bigl(100\,\d\,T\bigr)$.

For each timestep $t\in[T]$, observe
\begin{align*}
\Pr\bigl[
  \{P_{\theta_t^i}\}_{i=1}^{n_\theta} \,\neq\, \fP_{\Theta_t}
\bigr]
&\;\le\;
\sum_{P_{\theta_t}\in \fP_{\Theta_t}}
\Pr\bigl[
  P_{\theta_t^i} \neq P_{\theta_t} \;\;\forall\,i \in [n_\theta]
\bigr]
\\
&=\;
\d \,\Bigl(1 - \frac{1}{\d}\Bigr)^{n_\theta}.
\end{align*}
Hence,
\begin{align*}
\Pr\bigl[
  \exists\,t \in [T]:
  \{P_{\theta_t^i}\}_{i=1}^{n_\theta} \neq \fP_{\Theta_t}
\bigr]
&\;\le\;
\sum_{t=1}^{T}
\Pr\bigl[
  \{P_{\theta_t^i}\}_{i=1}^{n_\theta} \neq \fP_{\Theta_t}
\bigr]
\\
&\leq\;
\d\,T
\,\Bigl(1 - \frac{1}{\d}\Bigr)^{n_\theta}
\;<\;
\d\,T \,e^{-n_\theta/\d}
\;=\;
0.01.
\end{align*}
This completes the proof.
\end{proof}






\subsection{Proof of \cref{corollary:parity}}

\begin{proof}[Proof of \cref{corollary:parity}]
It suffices to verify that for the sparse parity problem, the constant $c$ in ~\cref{assm: compositional structure} is $\frac 12$. 

We denote $P_{ i_1,\cdots,i_t}(\bm x,\bm y_{<t}) = \frac 1 {2^d} \times \mathbf 1  [y_1 = x_{i_1}]\prod_{s=2}^t \mathbf 1[y_s = y_{s-1}\oplus x_{i_s}]$.
For any $i_1,\cdots,i_{t-1}\in [d]$, and $i_{t}\neq i_{t}'\in [d]$ and  it holds that 
\begin{align*}
\tv(P_{i_1,\cdots,i_{t-1}, i_t},P_{i_1,\cdots,i_{t-1},i_t'})&=\frac 1 {2^n } \sum_{x\in \{0,1\}^d}\mathbf 1 [x_{i_1}\oplus\cdots\oplus x_{i_{t-1}}\oplus x_{i_t}\neq x_{i_1}\oplus\cdots\oplus x_{i_{t-1}}\oplus x_{i_t'}]\\
&=\frac 1 {2^n }\sum_{x\in \{0,1\}^d} \mathbf 1[x_{i_{t}}\neq  x_{i_{t}'}]\\
&=\frac 12 .
\end{align*}
\end{proof}
This completes the proof.