\section{Setups}

Representation learning:\cite{ye2021towards} defines variation and informativeness between different environments with a shared representation. \cite{arjovsky2019invariant} approaches this by designing the training objective. Some earlier work on linear models / kernel regression can be found in ~\cite{du2017hypothesis, lei2021near}.


Distribution shift: \cite{mansour2009domain} defines generalization error when training on P, but test on Q and suffers d(P,Q) bias. \cite{cortes2010learning} on learning to reweight the samples, if some samples from Q are available. 
In a similar manner, many work studies the case when both samples from P, Q are available, and how samples from P can help learning in Q. One famous setup is covariate shift \cite{kpotufe2021marginal,ma2023optimally}. 

Robust learning: in a variation of the distribution shift setup,  we only sample from the source distribution P. To generalize on an unknown distribution Q, one could train robustly with adversarial perturbations, \cite{madry2017towards, raghunathan2020understanding}.

Our work follows the robust problem setup, where we aim to achieve good performance on a class of distributions $\mathcal{P}$, instead of a target distribution. However, we assume more structures motivated by in-context learning from language modeling. 
Specifically, we consider random variables $X  = \{X_{t, i}\}_{t \le T, l \le L} \sim P_{\theta}^{\otimes L} \in \mathcal{P}$, where $T$ is the length of a sequence, and $L$ is the number of independent demonstrative examples.
We further let $\theta = \{\theta_1, ..., \theta_T\} $ and assume that for every $l$, we have i.i.d sampled sequence $X_{1:T, l}$,
\begin{align*}
    X_{t, l} | x_{1, l}, ..., x_{t-1, l} \sim P_{\theta_t}(\cdot | x_1, ..., x_{t-1}).
\end{align*}
WLOG we assume $x_0 \sim P_0$. During training, we assume that the algorithm do not know $\Theta_t$, but need to learn from a large class (e.g., defined by the expressivity of transformers) $Z$ where $\Theta_t \subseteq Z_t$. We do not quantify the complexity of learning from $Z_t$ and simply assume learnability below. Specifically, we make the following assumptions:
\begin{assumption}
Setup for ICL.
\begin{enumerate}
    \item Size of token-wise hypothesis class: $\theta_t \in \Theta_t, |\Theta_t| \le d$. 
    \item In-context Identifiability, for any $\theta_{1:t} \neq \theta'_{1:t}$, $X_{1:t} \sim P_{\theta_{1:t}}, X_{1:t}' \sim P_{\theta'_{1:t}}$ we have
    \[
    \text{KL}(X_{1:t}, X_{1:t}') \ge c > 0.
    \] %(Maybe tokenwise?)
    \item Token-wise learnability. 
    For any $\zeta_t \in Z_t$ and $\theta_{t} \in \Theta_t, \theta_{t} \neq \zeta_t$, when we sample $X \sim P_{\theta_{1:t-1}, \theta_t}, X' \sim P_{\theta_{1:t-1}, \zeta_t}$, we have,
    \[
    \text{KL}(X, X') > 0.
    \]
\end{enumerate}    
\end{assumption}


Interpreting the above assumptions with a concrete parity example would be good here.  


A learning algorithm in the ICL setup has access to training samples $D(n_x, n_\theta) = \{(X^{(i)}, \theta^{(j)})\}_{i \le n_{x}, j \le n_{\theta}},$ where in each pair $(X, \theta)$, we have $X \sim P_{\theta}$. The goal in the test time is to complete the sequence, given $l-1$ demonstrations. Formally, for a fixed algorithm $\mathcal{A}$, it generates model parameter $h = \mathcal{A}(D)$ from training data, and during testing, we evaluate 
\begin{align*}
    \text{ICL Error}(\mathcal{A}, D) = \max_\theta \text{KL}(P_{\theta}, \hat{P}(h, \{X_{t,i}\}_{t, i\le l})),
\end{align*}
where the predicted distribution $\hat{P}(h, \{X_{t,i}\}_{t, i\le l})$ is the inferred sequence distribution from trained parameters $h$ and demonstrating examples $\{X_{t,i}\}_{t, i\le l-1})$.

We say the algorithm $\mathcal{A}$ can learn from Dataset $D$ with \textbf{distribution complexity} $n_\theta$ if 
\begin{align*}
    \lim_{n_x \to \infty}\text{ICL Error}(\mathcal{A}, D(n_x, n_\theta)) \to 0.
\end{align*}
Hence, this definition focus on \textbf{distribution complexity} $n_\theta$ rather than \textbf{sample complexity} $n_x$ in the dataset. In other words, how many distinct $\mathcal{P}_\theta, \theta \in \Theta$ do we need to sample from to generate dataset D?

We claim that if $l \ge \Tilde{O}(1/c)$, then there exists an algorithm (token-wise MLE over the last example) that only requires $n_{\theta} = \Tilde{O}(d)$, in  contrast to the set of $d^{T}$ possible distributions. Proof: Argue via identifiability that if an algorithm fail to detect $\theta_t$ then, it is not optimal on training data.


\paragraph{Proof sketch:} We prove by providing  such an algorithm. This is actually a bit trivial given the assumptions. 

First, we design the task collection $\mathcal{T} \subset \Theta^{\otimes T}$, such that $\hat{\Theta} = \mathcal{O}(d)$, and that for any $t \in \{1, ..., T\}, \xi_t \in \Theta_t$, we can find $\theta \in \mathcal{T}$, and $\theta_t = \xi$.

Second, we define the training procedure. The algorithm identify the task collection $\Theta_t$ for all $t$ using the condition that $n_x \to \infty$ and token-wise learnability  in assumption.

Finally, during inference, when the demonstrative example has $l \ge \log(1/\delta)/c$, the algorithm can infer $\theta_t \in \Theta_t$ correctly with probability at least $1-\delta$. To complete the last example, the algorithm can just generate according to the inferred $\theta_t, t \in \{1, ..., T\}$..

% \huaqing{I wonder in the second step, is it reasonable to assume that each $\Theta_t$ is learned independently? Is it possible that the model learn some joint distribution of $\{\Theta_t\}$ so that it does not generalize well to $d^T$ cases?}



\paragraph{Discussion:} Connection to robust estimator under distribution shift: Note that by assumption, we have $\text{KL}(P,Q) \ge c$. In a worst case robust estimation setup, the test error cannot go below $c$ even as sample size $n$ go to infinity.

Comparison to domain adaptation / covariate shift: one can consider the training set $D$ as the source domain, and the $l$ demonstrations as the target domain. However, up until now, there is no practical approach to our case where the target distribution and source distribution can potentially have no overlap in pdf (and hence the density ratio is unbounded). 


