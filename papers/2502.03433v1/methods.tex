\section{Methods}

In this section, we discuss the methodology used to analyze the characteristics of political discourse on Discord. Political discourse is broadly understood as the communication of ideas, opinions, and debates related to political ideologies, often reflecting the values, beliefs, and actions of different political groups.

\subsection{Analysis of Political Discourse}
\label{sec:txt}

\subsubsection{Political Valence of Messages}

The concept of \textit{political valence} helps to understand how specific words, phrases, and references align with political ideologies. In this analysis, we use it to identify words that are associated with Democratic- and Republican-aligned servers. This metric, introduced in \cite{conover2011political} for hashtags, has been adapted for general terms in subsequent studies~\cite{locatelli2022characterizing}. Unlike topic modeling, which clusters discussions into broad themes without capturing ideological stance, political valence directly quantifies the ideological bias of terms, making it more suitable for analyzing fragmented and short-form political discourse on Discord. By exploring political valence, we aim to uncover the distinct characteristics of the content shared by different groups.

For this work, political valence is defined as:

\[
V(t) = \frac{\frac{N(t, R)}{N(R)} - \frac{N(t, D)}{N(D)}}{\frac{N(t, R)}{N(R)} + \frac{N(t, D)}{N(D)}}
\]


\noindent
where \( N(R) \) and \( N(D) \) denote the total occurrences of all terms in Republican-aligned and Democratic-aligned servers, respectively, while \( N(t, R) \) and \( N(t, D) \) refer to the frequency of a specific term \( t \) in these servers. Additionally, we define \( N(D) = \sum_t N(t,D) \) for a given leaning \( D \). This metric ranges from \([-1, 1]\), where a score of \( -1 \) indicates that a term is exclusively used in Democratic-aligned servers, while a score of \( +1 \) indicates exclusive usage in Republican-aligned servers. A score close to \( 0 \) suggests that the term is used relatively equally across both groups.


%Unlike the previous formulation, this revision ensures that both Democratic- and Republican-aligned usage contribute symmetrically to the metric, making the interpretation more balanced. 

We calculate political valence for words and websites shared by Discord users to better understand how political discourse varies between the two opposing groups.


\subsubsection{Embedding Analysis}

\label{sec:embeddings}
A way to understand political discourse on Discord is by examining implicit biases and the semantic contexts of key terms across different ideological spectra. This can be effectively achieved through word embeddings, such as those generated by the \textit{Word2Vec} model\cite{mikolov2013efficient,mikolov2013distributed}. These embeddings map words into a high-dimensional vector space, where semantically similar terms are positioned closer together, capturing contextual relationships in the data.

To investigate these biases, we trained separate \textit{Word2Vec} models for Democratic- and Republican-aligned servers, further segmented by the temporal phases of the election. This approach enables us to analyze how key terms are represented within each context, revealing shifts in their connotations and associations across ideological boundaries and over time. 

However, the dataset segmentation reduces the amount of data available for each model, potentially affecting training effectiveness. To address this limitation, we initialized the training process with a neutral pre-trained \textit{Word2Vec} model. This model was trained on a diverse dataset comprising Wikipedia articles, OpenCrawl data, and movie subtitles \cite{speer2017conceptnet}. 
 
To assess the semantic representation of politically charged terms (e.g., socialism), we adopt the methodology of the Word Embedding Association Test (WEAT)~\cite{caliskan2017semantics}. This approach quantifies the association between target words and reference terms with positive (e.g., good, important) and negative (e.g., bad, terrible) connotations by leveraging the cosine similarity metric in the word embedding space. For a target word \( w \) and two sets of attribute words \( A \) (positive) and \( B \) (negative), the normalized association score \( s(w, A, B) \) is calculated as:


\[
s(w, A, B) = 
\frac{\text{mean} \left( \cos(w, a), \, \forall a \in A \right) - \text{mean} \left( \cos(w, b), \, \forall b \in B \right)}{\text{stddev} \left( \cos(w, x), \, \forall x \in A \cup B \right)},
\]

\noindent
where \( \cos(w, a) \) is the cosine similarity between \( w \) and \( a \). This score quantifies the association of \( w \) with \( A \) and \( B \), identifying implicit biases in word embeddings based on semantic proximity to positive or negative terms. A positive \( s(w, A, B) \) indicates a stronger association of \( w \) with the positive attribute set \( A \), while a negative \( s(w, A, B) \) indicates a stronger association with the negative attribute set \( B \).

In addition to candidate and party names, we arbitrarily selected politically relevant target words, such as \textit{capitalism}, \textit{feminism}, and \textit{market}. For each target word, a set of three positive and three negative reference words was defined based on its context, following the approach outlined in \cite{ottoni2018analyzing}. The selection of positive reference words was informed by previous studies, ensuring coverage of different topics within political discussions \cite{magno2021measuring}. For candidate and party names, a comprehensive set of terms was included to reflect the full spectrum of the debate.

 

\subsection{Hate Speech}
\label{sec:hatespeech}

The analysis of hate speech within political discourse provides critical insights into the nature and dynamics of discussions, particularly during charged periods such as election campaigns. For this study, we aim to evaluate the prevalence of toxic speech over the course of the electoral cycle and across different political spectra. This approach allows us to understand how toxicity levels fluctuate with key events and how they vary between ideological groups.

% \wmj{o que exatamente são esses grupos? como são definidos? como são identificados? fique confuso.}
In addition, we seek to identify those most targeted by discriminatory discourse in political discussions on Discord. By doing so, we aim to investigate sociopolitical biases in the marginalization of these individuals and examine how such intolerance is intertwined with political debate and the electoral period.

%\wmj{ou não fala de grupo, apenas categorizando ações discriminatórias, ou então temos que introduzir os grupos.}
To achieve these objectives, we utilize a RoBERTa-based classification model specifically trained for multi-class hate speech detection \cite{antypas2023robust}. This model is designed to classify text into the following categories: Sexism, Racism, Disability, Sexual Orientation, Religion, Other and Not Hate. The classifier was trained on an extensive dataset of tweets, which closely resembles the Discord environment due to its informal context and the prevalence of short messages. We chose RoBERTa over other options, such as the Perspective API, because of its multi-class classification capability, which enables a more nuanced analysis by covering a broader range of hate speech categories rather than a binary or toxicity-based classification.
