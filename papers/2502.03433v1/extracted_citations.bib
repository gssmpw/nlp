@article{allcott24theeffects,
author = {Hunt Allcott  and Matthew Gentzkow  and Winter Mason  and Arjun Wilkins  and Pablo Barberá  and Taylor Brown  and Juan Carlos Cisneros  and Adriana Crespo-Tenorio  and Drew Dimmery  and Deen Freelon  and Sandra González-Bailón  and Andrew M. Guess  and Young Mie Kim  and David Lazer  and Neil Malhotra  and Devra Moehler  and Sameer Nair-Desai  and Houda Nait El Barj  and Brendan Nyhan  and Ana Carolina Paixao de Queiroz  and Jennifer Pan  and Jaime Settle  and Emily Thorson  and Rebekah Tromble  and Carlos Velasco Rivera  and Benjamin Wittenbrink  and Magdalena Wojcieszak  and Saam Zahedian  and Annie Franco  and Chad Kiewiet de Jonge  and Natalie Jomini Stroud  and Joshua A. Tucker },
title = {The effects of Facebook and Instagram on the 2020 election: A deactivation experiment},
journal = {Proceedings of the National Academy of Sciences},
volume = {121},
number = {21},
pages = {e2321584121},
year = {2024},
}

@misc{balasubramanian2024publicdatasettrackingsocial,
      title={A Public Dataset Tracking Social Media Discourse about the 2024 U.S. Presidential Election on Twitter/X}, 
      author={Ashwin Balasubramanian and Vito Zou and Hitesh Narayana and Christina You and Luca Luceri and Emilio Ferrara},
      year={2024},
      eprint={2411.00376},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/2411.00376}, 
}

@inproceedings{embd-2,
author = {Ottoni, Raphael and Cunha, Evandro and Magno, Gabriel and Bernardina, Pedro and Meira Jr., Wagner and Almeida, Virg\'{\i}lio},
title = {Analyzing Right-wing YouTube Channels: Hate, Violence and Discrimination},
year = {2018},
isbn = {9781450355636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3201064.3201081},
doi = {10.1145/3201064.3201081},
abstract = {As of 2018, YouTube, the major online video sharing website, hosts multiple channels promoting right-wing content. In this paper, we observe issues related to hate, violence and discriminatory bias in a dataset containing more than 7,000 videos and 17 million comments. We investigate similarities and differences between users' comments and video content in a selection of right-wing channels and compare it to a baseline set using a three-layered approach, in which we analyze (a) lexicon, (b) topics and (c) implicit biases present in the texts. Among other results, our analyses show that right-wing channels tend to (a) contain a higher degree of words from "negative'' semantic fields, (b) raise more topics related to war and terrorism, and (c) demonstrate more discriminatory bias against Muslims (in videos) and towards LGBT people (in comments). Our findings shed light not only into the collective conduct of the YouTube community promoting and consuming right-wing content, but also into the general behavior of YouTube users.},
booktitle = {Proceedings of the 10th ACM Conference on Web Science},
pages = {323–332},
numpages = {10},
keywords = {youtube, hate speech, discriminatory bias, comments},
location = {Amsterdam, Netherlands},
series = {WebSci '18}
}

@article{fujiwara2024effect,
  title={The effect of social media on elections: Evidence from the united states},
  author={Fujiwara, Thomas and M{\"u}ller, Karsten and Schwarz, Carlo},
  journal={Journal of the European Economic Association},
  volume={22},
  number={3},
  pages={1495--1539},
  year={2024},
  publisher={Oxford University Press}
}

@Article{hate-speech-1,
AUTHOR = {Alkomah, Fatimah and Ma, Xiaogang},
TITLE = {A Literature Review of Textual Hate Speech Detection Methods and Datasets},
JOURNAL = {Information},
VOLUME = {13},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/2078-2489/13/6/273},
ISSN = {2078-2489},
ABSTRACT = {Online toxic discourses could result in conflicts between groups or harm to online communities. Hate speech is complex and multifaceted harmful or offensive content targeting individuals or groups. Existing literature reviews have generally focused on a particular category of hate speech, and to the best of our knowledge, no review has been dedicated to hate speech datasets. This paper systematically reviews textual hate speech detection systems and highlights their primary datasets, textual features, and machine learning models. The results of this literature review are integrated with content analysis, resulting in several themes for 138 relevant papers. This study shows several approaches that do not provide consistent results in various hate speech categories. The most dominant sets of methods combine more than one deep learning model. Moreover, the analysis of several hate speech datasets shows that many datasets are small in size and are not reliable for various tasks of hate speech detection. Therefore, this study provides the research community with insights and empirical evidence on the intrinsic properties of hate speech and helps communities identify topics for future work.},
DOI = {10.3390/info13060273}
}

@inproceedings{hate-speech-2,
author = {Saha, Punyajoy and Das, Mithun and Mathew, Binny and Mukherjee, Animesh},
title = {Hate Speech: Detection, Mitigation and Beyond},
year = {2023},
isbn = {9781450394079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539597.3572721},
doi = {10.1145/3539597.3572721},
abstract = {Social media sites such as Twitter and Facebook have connected billions of people and given the opportunity to the users to share their ideas and opinions instantly. That being said, there are several negative consequences as well such as online harassment, trolling, cyber-bullying, fake news, and hate speech. Out of these, hate speech presents a unique challenge as it is deeply engraved into our society and is often linked with offline violence. Social media platforms rely on human moderators to identify hate speech and take necessary action. However, with the increase in online hate speech, these platforms are turning toward automated hate speech detection and mitigation systems. This shift brings several challenges to the plate, and hence, is an important avenue to explore for the computation social science community.In this tutorial, we present an exposition of hate speech detection and mitigation in three steps. First, we describe the current state of research in the hate speech domain, focusing on different hate speech detection and mitigation systems that have developed over time. Next, we highlight the challenges that these systems might carry like bias and the lack of transparency. The final section concretizes the path ahead, providing clear guidelines for the community working in hate speech and related domains. We also outline the open challenges and research directions for interested researchers.},
booktitle = {Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
pages = {1232–1235},
numpages = {4},
keywords = {counter speech, detection, hate speech, mitigation, social media},
location = {Singapore, Singapore},
series = {WSDM '23}
}

@inproceedings{hate-speech-3,
  title={Automated hate speech detection and the problem of offensive language},
  author={Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={11},
  number={1},
  pages={512--515},
  year={2017}
}

@article{heslep2024mapping,
  title={Mapping Discord’s darkside: Distributed hate networks on Disboard},
  author={Heslep, Daniel G and Berge, PS},
  journal={new media \& society},
  volume={26},
  number={1},
  pages={534--555},
  year={2024},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{magno2021measuring,
  title={Measuring international online human values with word embeddings},
  author={Magno, Gabriel and Almeida, Virgilio},
  journal={ACM Transactions on the Web (TWEB)},
  volume={16},
  number={2},
  pages={1--38},
  year={2021},
  publisher={ACM New York, NY}
}

@misc{roose17thiswas,
author = {Kevin Roose},
title={This Was the Alt-Right’s Favorite Chat App. Then Came Charlottesville}, 
howpublished={https://www.nytimes.com/2017/08/15/technology/discord-chat-app-alt-right.html}, 
year={2017} 
}

@inproceedings{valence,
    title = "Predicting the Topical Stance and Political Leaning of Media using Tweets",
    author = "Stefanov, Peter  and
      Darwish, Kareem  and
      Atanasov, Atanas  and
      Nakov, Preslav",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.50",
    doi = "10.18653/v1/2020.acl-main.50",
    pages = "527--537",
    abstract = "Discovering the stances of media outlets and influential people on current, debatable topics is important for social statisticians and policy makers. Many supervised solutions exist for determining viewpoints, but manually annotating training data is costly. In this paper, we propose a cascaded method that uses unsupervised learning to ascertain the stance of Twitter users with respect to a polarizing topic by leveraging their retweet behavior; then, it uses supervised learning based on user labels to characterize both the general political leaning of online media and of popular Twitter users, as well as their stance with respect to the target polarizing topic. We evaluate the model by comparing its predictions to gold labels from the Media Bias/Fact Check website, achieving 82.6{\%} accuracy.",
}

