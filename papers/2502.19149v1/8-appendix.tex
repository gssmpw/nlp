\newpage

\section{Dataset}

\subsection{Legal Compliance and License}
The problems we use are from the LiveCodeBench, and the solutions we use to generate pseudocode are from LeetCode,
which are the publicly visible portions.
We did not include the user-submitted solutions in our final benchmark but their extracted pseudocode.
Following \citet{henry21} and LiveCodeBench~\cite{livecb}, we abide by Fair Use 107: ``the fair use of a copyrighted work, including such use by \ldots\xspace scholarship, or research, is not an infringement of copyright'', where fair use is determined by the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes'', ``the amount and substantiality of the portion used in relation to the copyrighted work as a whole'', and ``the effect of the use upon the potential market for or value of the copyrighted work.''
The collected data in \name is used only for academic purposes.
Moreover, \name is used for benchmarking, and we do not use it for training models.

\subsection{Basic Stats}
\Cref{tab:loc-tokens-full} shows the number of files and statistics of source code and pseudocode from different languages in \name.
The statistics is basically consistent with the sampled subset in \Cref{subsec:resrq4}.
Each pseudocode corresponds to a problem in LiveCodeBench and can use its testcases to test the correctness of the code generated from the pseudocode.

\begin{table}[h]
    \centering
    \begin{adjustbox}{max width=\linewidth}
    \setlength{\tabcolsep}{4pt}
    \begin{NiceTabular}{c c | cc | cc  }
    \CodeBefore
    \Body
        \toprule
        \Block{2-1}{Language} & \Block{2-1}{\#Files} & \Block{1-2}{Source Code} && \Block{1-2}{Pseudocode} &  \\
        & & LoC & Tokens & LoC & Tokens \\
        \midrule
C++     & 355  & 18.20 & 192.23 & 13.05 & 122.58 \\
Rust    & 348  & 18.59 & 215.71 & 13.66 & 129.76 \\
Python	& 357  & 13.75 & 140.30 & 11.33 & 108.29 \\
    \bottomrule
    \end{NiceTabular}
    \end{adjustbox}
    \caption{Statistics of source code and pseudocode from different languages in \name }
    \label{tab:loc-tokens-full}
\end{table}

\section{Human Annotations}
Six programmers with more than five years of C++ experience participate in the annotation of pseudocode on 55 sampled C++ solution code.
Each annotated piece of pseudocode is validated by two other participants from the same group.

The approval from the ethics review board is exempted because the annotation procedure is not physically or mentally harmful and does not impose an intense workload in a short time.
The participants have been compensated according to the local legislation.
The consent to use the annotated data has been obtained from the participants.

\section{Case Study}

\subsection{Motivating Example}\label{subsec:motv-ex}
\Cref{lst:problem-motiv} lists the full problem and \Cref{lst:cpp-motiv} lists the user-submitted C++ solution where the pseudocode is converted from.
Note that the pseudocode simplifies the solution by replacing the map structure with a set structure.

\subsection{Simplifying Common Procedures}\label{subsec:simplication}
\Cref{lst:cpp-simp} shows a user-submitted C++ solution with detailed steps, and \Cref{lst:pseudo-simp} shows a concise but semantic-preserving pseudocode converted from the long solution.
Powerful LLMs such as GPT-4o-mini and Qwen32B can implement code correctly in all three languages, while smaller LLMs such as Phi-3.5 have lower success rates and even drop to zero when writing Rust codes. 

\subsection{Underflow in Rust}\label{subsec:rust-underflow}
\Cref{lst:rust-underflow} shows an example of a user-submitted Rust solution with the subtraction underflow problem.
Specifically, the variable \codef{pos} is from \codef{.len()} (line~5) and should be a \codef{usize} (unsigned) variable.
The user uses a nonstandard way to control the loop termination: when \codef{pos} is 0 and subtracts 1 from it in the release mode, it becomes the biggest unsigned integer, so the loop terminates because \codef{pos > arr.len()}.
However, such a coding style is not encouraged in Rust.
In the debug mode, the Rust program will panic (\ie, running into an invalid state because \codef{pos} is unsigned and should not underflow) and terminate the execution.

The pseudocode generated by DeepSeeek-R1 (\Cref{lst:pseudo-rust-underflow}) focuses on the solution logic, which does not contain such detailed type information and uses a more standard coding style (loop until \codef{pos} is negative).
Based on the pseudocode, only Qwen32B notices the possible sign problem and can generate code that correctly converts the type as \codef{isize} (line~6, \Cref{lst:rust-fix-underflow}), while all other less powerful models failed to do so.



\subsection{Worsening Pseudocode}\label{subsec:worsening}
\Cref{lst:python-acc}, \ref{lst:pseudo-python-acc}, and \ref{lst:python-acc-wrong-gen} show a case where the pseudocode generated from a Python solution misleads LLMs and causes a lower pass@1 compared with generating Python code from the problem.

\subsection{Failure of Pseudocode Generation}\label{subsec:fail-pseudogen}
\Cref{lst:python-being-wrongly-pseudogen} and \ref{lst:pseudo-wrong-condition} show a case of a Python solution and its generated pseudocode that is not semantic preserving.
The problem is at the last line, where the Python code will return \codef{max\_sum} if it is negative but not \codef{-inf}, while the pseudocode incorrectly assumes \codef{max\_sum} to be non-negative, possibly due to the hallucination problem in LLMs.


\section{Prompts}\label{sec:prompts}
\smalltitle{Generating Pseudocode}
\Cref{lst:pseudogen-prompt} is the prompt (a single user query as suggested by the DeepSeek team~\cite{ds-r1}) we use to query \dsr to generate pseudocode from Python code.
The prompts to generate pseudocode from C++ and Rust are similar with minor difference in the example code snippets.

\smalltitle{Generating Code from Pseudocode}
\Cref{lst:query-prompt-zero} is the zero-shot prompt, and \Cref{lst:query-prompt-one} is the one-shot prompt for generating Python code.
The prompts to generate C++ and Rust code are similar with language difference in the one-shot example.

\section{Additional Experiment Results}\label{sec:add-exp-results}
\Cref{fig:compare-config-cpp}, \ref{fig:compare-config-python}, and \ref{fig:compare-config-rust} show the pass@k of code generation from pseudocode from C++, Python, and Rust, respectively, compared with the Pass@k of code generation from the problem.



\input{listings/motiv}
\input{listings/case-simp-common-alg-3233}

\input{listings/rust-underflow}
\input{listings/pseudo-rust-underflow}
\input{listings/rust-gen-fix-underflow}


\input{listings/python-acc}
\input{listings/pseudo-python-acc}
\input{listings/python-acc-wrong-gen}

\input{listings/python-being-wrongly-pseudogen}
\input{listings/pseudo-wrong-condition}

\input{listings/prompt-pseudogen}
\input{listings/prompt-query}

\input{figs/compare_config_all}
