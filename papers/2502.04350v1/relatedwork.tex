\section{Related Work}
\label{sec: Related Work}
\textbf{Code Generation and Symbolic Computing in LLM Tasks}\quad LLMs are widely used for general agent tasks, such as interacting with softwares and websites \citep{webarena,travelplanner,llmfp,crab}, planning robot actions \citep{scalable-multi-robot,saycan}, and inferring with logic~\citep{big-bench-hard}. Literally, many test tasks in previous works can be solved with direct coding~\citep{meta-prompting,pal}. Some recent works also further extend the applications of coding into tasks involving commonsense reasoning and semantic analysis~\citep{chain-of-code,weir2024learning}. Most of previous works mainly utilize text~\citep{Tree-of-thought,saycan,text2motion} or code~\citep{code-as-policies,codeplan-code-use-llm,code-based-self-verify} as the only output modality. \citet{codesteering} highlights the importance of smartly switching between code and text generation in LLMs but notes current methods have clear drawbacks.\\
\textbf{LLM Self-reflection and CoT Models}\quad LLM-generated feedback via self-evaluation can improve performance on a variety of tasks \citep{yang2022re3, welleck2022generating, madaan2023self}. The OpenAI o1~\citep{O1-model} and DeepSeek R1~\citep{deepseek} models demonstrate the potential of agentic LLMs that use Chain-of-Thought (CoT) text generation to explore and self-reflect, enhancing reasoning and planning. However, they lack symbolic computing and code generation capabilities, leading to weaker performance on complex symbolic tasks and consuming substantial tokens and time~\citep{overthink-o1}.\\
\textbf{LLM Fine-tuning with Multi-step SFT and DPO}\quad SFT~\citep{SFT-self-play} and DPO~\citep{DPO} are extensively implemented for LLM fine-tuning. To enhance LLM's capability in multi-step agent tasks, these methods are further modified with multi-step goals and rewards~\citep{multi-turn-RLHF,VLM-RL-multi-Turn,CPO}. LLM self-generated data have become increasingly important for model improvement when combined with search algorithms and rejection sampling~\citep{LATS,rstar-math}.