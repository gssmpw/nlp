\section{Related Work}
\label{sec: Related Work}
\textbf{Code Generation and Symbolic Computing in LLM Tasks}\quad LLMs are widely used for general agent tasks, such as interacting with softwares and websites ____, planning robot actions ____, and inferring with logic____. Literally, many test tasks in previous works can be solved with direct coding____. Some recent works also further extend the applications of coding into tasks involving commonsense reasoning and semantic analysis____. Most of previous works mainly utilize text____ or code____ as the only output modality. ____ highlights the importance of smartly switching between code and text generation in LLMs but notes current methods have clear drawbacks.\\
\textbf{LLM Self-reflection and CoT Models}\quad LLM-generated feedback via self-evaluation can improve performance on a variety of tasks ____. The OpenAI o1____ and DeepSeek R1____ models demonstrate the potential of agentic LLMs that use Chain-of-Thought (CoT) text generation to explore and self-reflect, enhancing reasoning and planning. However, they lack symbolic computing and code generation capabilities, leading to weaker performance on complex symbolic tasks and consuming substantial tokens and time____.\\
\textbf{LLM Fine-tuning with Multi-step SFT and DPO}\quad SFT____ and DPO____ are extensively implemented for LLM fine-tuning. To enhance LLM's capability in multi-step agent tasks, these methods are further modified with multi-step goals and rewards____. LLM self-generated data have become increasingly important for model improvement when combined with search algorithms and rejection sampling____.