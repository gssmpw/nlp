[
  {
    "index": 0,
    "papers": [
      {
        "key": "webarena",
        "author": "Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others",
        "title": "Webarena: A realistic web environment for building autonomous agents"
      },
      {
        "key": "travelplanner",
        "author": "Hao, Yilun and Chen, Yongchao and Zhang, Yang and Fan, Chuchu",
        "title": "Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools"
      },
      {
        "key": "llmfp",
        "author": "Hao, Yilun and Zhang, Yang and Fan, Chuchu",
        "title": "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming"
      },
      {
        "key": "crab",
        "author": "Xu, Tianqi and Chen, Linyao and Wu, Dai-Jie and Chen, Yanjun and Zhang, Zecheng and Yao, Xiang and Xie, Zhiqiang and Chen, Yongchao and Liu, Shilong and Qian, Bochen and others",
        "title": "Crab: Cross-environment agent benchmark for multimodal language model agents"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "scalable-multi-robot",
        "author": "Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu",
        "title": "Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?"
      },
      {
        "key": "saycan",
        "author": "Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "big-bench-hard",
        "author": "Suzgun, Mirac and Scales, Nathan and Sch{\\\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others",
        "title": "Challenging big-bench tasks and whether chain-of-thought can solve them"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "meta-prompting",
        "author": "Suzgun, Mirac and Kalai, Adam Tauman",
        "title": "Meta-prompting: Enhancing language models with task-agnostic scaffolding"
      },
      {
        "key": "pal",
        "author": "Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham",
        "title": "Pal: Program-aided language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chain-of-code",
        "author": "Li, Chengshu and Liang, Jacky and Zeng, Andy and Chen, Xinyun and Hausman, Karol and Sadigh, Dorsa and Levine, Sergey and Fei-Fei, Li and Xia, Fei and Ichter, Brian",
        "title": "Chain of code: Reasoning with a language model-augmented code emulator"
      },
      {
        "key": "weir2024learning",
        "author": "Weir, Nathaniel and Khalifa, Muhammad and Qiu, Linlu and Weller, Orion and Clark, Peter",
        "title": "Learning to Reason via Program Generation, Emulation, and Search"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Tree-of-thought",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      },
      {
        "key": "saycan",
        "author": "Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others",
        "title": "Do as i can, not as i say: Grounding language in robotic affordances"
      },
      {
        "key": "text2motion",
        "author": "Lin, Kevin and Agia, Christopher and Migimatsu, Toki and Pavone, Marco and Bohg, Jeannette",
        "title": "Text2motion: From natural language instructions to feasible plans"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "code-as-policies",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      },
      {
        "key": "codeplan-code-use-llm",
        "author": "Bairi, Ramakrishna and Sonwane, Atharv and Kanade, Aditya and Iyer, Arun and Parthasarathy, Suresh and Rajamani, Sriram and Ashok, B and Shet, Shashank",
        "title": "Codeplan: Repository-level coding using llms and planning"
      },
      {
        "key": "code-based-self-verify",
        "author": "Zhou, Aojun and Wang, Ke and Lu, Zimu and Shi, Weikang and Luo, Sichun and Qin, Zipeng and Lu, Shaoqing and Jia, Anya and Song, Linqi and Zhan, Mingjie and others",
        "title": "Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "codesteering",
        "author": "Chen, Yongchao and Jhamtani, Harsh and Sharma, Srinagesh and Fan, Chuchu and Wang, Chi",
        "title": "Steering Large Language Models between Code Execution and Textual Reasoning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yang2022re3",
        "author": "Yang, Kevin and Tian, Yuandong and Peng, Nanyun and Klein, Dan",
        "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision"
      },
      {
        "key": "welleck2022generating",
        "author": "Welleck, Sean and Lu, Ximing and West, Peter and Brahman, Faeze and Shen, Tianxiao and Khashabi, Daniel and Choi, Yejin",
        "title": "Generating Sequences by Learning to Self-Correct"
      },
      {
        "key": "madaan2023self",
        "author": "Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others",
        "title": "Self-refine: Iterative refinement with self-feedback"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "O1-model",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "Openai o1 system card"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "overthink-o1",
        "author": "Chen, Xingyu and Xu, Jiahao and Liang, Tian and He, Zhiwei and Pang, Jianhui and Yu, Dian and Song, Linfeng and Liu, Qiuzhi and Zhou, Mengfei and Zhang, Zhuosheng and others",
        "title": "Do NOT Think That Much for 2+ 3=? On the Overthinking of o1-Like LLMs"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "SFT-self-play",
        "author": "Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan",
        "title": "Self-play fine-tuning converts weak language models to strong language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "DPO",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "multi-turn-RLHF",
        "author": "Zhou, Yifei and Zanette, Andrea and Pan, Jiayi and Levine, Sergey and Kumar, Aviral",
        "title": "Archer: Training language model agents via hierarchical multi-turn rl"
      },
      {
        "key": "VLM-RL-multi-Turn",
        "author": "Zhai, Yuexiang and Bai, Hao and Lin, Zipeng and Pan, Jiayi and Tong, Shengbang and Zhou, Yifei and Suhr, Alane and Xie, Saining and LeCun, Yann and Ma, Yi and others",
        "title": "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning"
      },
      {
        "key": "CPO",
        "author": "Zhang, Xuan and Du, Chao and Pang, Tianyu and Liu, Qian and Gao, Wei and Lin, Min",
        "title": "Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "LATS",
        "author": "Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong",
        "title": "Language agent tree search unifies reasoning acting and planning in language models"
      },
      {
        "key": "rstar-math",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      }
    ]
  }
]