\section{Related work}
\subsection{Ransomware Defense using Storage I/O Attributes}
\label{RW_w_IO}
Almost all research we are aware of combines I/O features with data at the file-system, process, and byte-data levels. For example, works like \cite{Shukla-et-al, Kharaz-et-al-Redemption-2017, Paik-et-al-2018, Amoeba-2018, Wang-et-al-Mimosa-2019} use a variety of I/O features like the number of bytes read, written, and overwritten, file-level features such as file-type and file-path diversity or patterns in directory transversal. Some also use the written byte entropy, and the similarity between the read and overwritten data. Algorithms in these earlier works were mostly rule-based algorithms (the exception is logistic regression in \cite{Amoeba-2018}). More advanced tabular methods were used in \cite{SSD-insider-2018, Baek-et-al-SSD++-2021} where IO and entropy features were calculated from time windows a few seconds wide, fed into a Decision Tree to generate predictions later aggregated along wider time windows. In \cite{Hirano-et-al-2022a} and \cite{Hirano-et-al-2022b} the authors add more I/O features and train a Random Forest (RF), an SVM, and a KNN model at granularity of tens of seconds. An RF was also used in \cite{eBPF-2023} applied to higher OS data at the process ID granularity, and \cite{Minding_the_Semantic_Gap-2024} used a Decision Tree. More recently, an XGBoost \cite{xgboost-paper}, was used in \cite{Wang2024-alibaba} to form the DeftPunk model using features like the IO size, IO byte, IOPS, and $offset$ statistics for different types of commands (read, write, overwrite, multi-read, etc.). XGBoost was also used in \cite{reategui2024_ibm} with entropy, I/O, and file-level features, calculated from a window a few seconds wide.

The data used in the majority of works involves between 1--15 families of ransomware (see \cite{Amoeba-2018, SSD-insider-2018, Wang-et-al-Mimosa-2019, Baek-et-al-SSD++-2021, Hirano-et-al-2022b, eBPF-2023, Minding_the_Semantic_Gap-2024, Wang2024-alibaba}) with the exception of \cite{Kharaz-et-al-Redemption-2017} using 29 families and \cite{TravellingHypervisor} using 32. 
The total volume read or written in \cite{Hirano-et-al-2022a} and \cite{Wang2024-alibaba} at $9$ terabyte and $12$ terabyte respectively. 
None of these published data sets is labeled at the command level making it impossible for us to use.

The SotA ransomware detection algorithms we compare to are tabular models. Due to the lack of published code, we developed a Random Forest (RF) model to represent a typical tabular approach in the literature, inspired by \cite{SSD-insider-2018}. It is designed to capture patterns in $size$, $OV_{WAR}$, and $\Delta t_{WAR}$, and uses several aggregated features per slice. The second model is DeftPunk which we also implement in code. For further details on the RF and DeftPunk, we refer to \cref{appendix: models}.

\subsection{Token Level Objective with Transformers}
\label{per_token_AI}
Our training tasks are per-token classification and regression. Similar per-token tasks can be found both in the NLP and the Computer Vision literature. Especially, Named Entity Recognition (NER) is, by construction, a token-level classification task and is closest to the task our CLT performs. To our knowledge, it was first benchmarked by a transformer in \cite{Bert-2019} via fine-tuning -- see also the recent \cite{Portuguese_NER-2020}, the review on NER in \cite{NER-review-2023}, and the recent idea in \cite{GPT-NER-2023}, where the problem is treated as a generative few shot learner. A similar task to what our PLT does is described for object recognition in \cite{AllTokensMatter-2021}. There, image tokens densely participate in the classification objective by optimizing the sum of the per-token cross-entropies and the class token cross-entropy. This approach is also natural in image segmentation as done by \cite{HSI-BERT-2019} with BERT.