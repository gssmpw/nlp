
\subsection{\label{sec_exp_design}Experiments design}

All the experiments were conducted using software attached to this paper. The experiments targeting analysis of trainset size's influence on the solver's performance included solving 20 scrambles of both 3$\times$3$\times$3 and 4$\times$4$\times$4 Rubik's cubes using different models as beam search heuristics. For this experiment, we prepared 20 models, whose parameters are demonstrated in the first 20 rows of Table~\ref{tbl_neural_net}. Each model was trained during 16384 epochs. The snapshots of the model parameters were saved after 16, 64, 256, 1024, 4096, and 16384 epochs. Then, each model snapshot was integrated as a heuristic into beam search with $W=2^{18}$, which was used to solve the first 20 scrambles from the dataset. DeepCubeA dataset~\cite{agostinelli2019solving} was used for 3$\times$3$\times$3 Rubik's cube, and the 2023 Kagle Santa Challenge~\cite{santa-2023} dataset was used for 4$\times$4$\times$4 puzzle. The results achieved by each solver configuration on the corresponding dataset were averaged and analyzed as experimental results. Unsolved scrambles were excluded from consideration in this experiment.


The first experiment's results are demonstrated in Figure~\ref{fig_param_vs_len}a. Single layer MLPs for 4$\times$4$\times$4 Rubik's cube are not presented in Table~\ref{tbl_neural_net} as during preliminary research solvers equipped with this type of model did not manage to solve any scramble before reaching the 200 steps limit.

During the second experiment, we used only 10 layer models with size 4M (models No.8 and 16 from Table~\ref{tbl_neural_net}). The first experiment's results did not show a significant effect of increasing $T$ (train size) from 4B to 16B. Thus, the second experiment used finer granularity with 4B, 8B, and 16B train sizes to select the appropriate size more precisely. Each snapshot of the models trained with the mentioned above train sets was integrated into solvers with $W$ of $2^{12}$, $ 2^{14}$, $2^{16}$, $2^{18}$, $2^{20}$,  $2^{22}$, and $2^{24}$. Then, these solvers were used to unscramble the first 20 puzzles from the same dataset used in the first experiment. The results achieved by each solver configuration on the corresponding dataset were averaged. Unsolved scrambles were excluded from consideration in this experiment.

The results of the second experiment are demonstrated in Figure~\ref{fig_param_vs_len}b. A deeper analysis of the experimental results shows that if we consider only $W$ values that give a puzzle winning probability above 50\%, the agent with the model trained on 8B states has a slightly better average solution length than the competitors~(Table~\ref{tbl_beam_vs_train}). Thus, for the rest of the experiments, we used the 8B train set as a compromise between solver performance and training time. 


The third experiment analyzed the influence of the number of agents $A$ on the solver's efficiency. We used models No.8, 16, and 25 for this experiment from Table~\ref{tbl_neural_net}. We trained each of these models multiple times during 8192 epochs. Then, each model was integrated into a dedicated agent. Due to computation limitations, we run only two agents in parallel at the same time, assuming that with more available GPU instances, it will be possible to compute all of them simultaneously. Finally, the total number of pretrained agents for 3$\times$3$\times$3 was 26, 4$\times$4$\times$4 -- 29, and 5$\times$5$\times$5 -- 69. As in previous experiments, the agents aimed to solve 3$\times$3$\times$3 cubes were tested on the scrambles DeepCubeA dataset, while the rest were verified using the 2023 Kagle Santa Challenge dataset. Due to the large size of the DeepCubeA dataset, in the third experiment, we used a subset of 69 3$\times$3$\times$3 scrambles, which were considered most difficult during preliminary research. The results of the experiment are shown in Figure~\ref{fig_multi_agent}.

The authors of~\cite{agostinelli2019solving}, along with the well-known DeepCubeA dataset, were using DeepCubeA$_h$ set containing the scrambles that are furthest away from the goal state, assuming these scrambles are more challenging to solve. At the same time, original DeepCubeA solutions were robustly and optimally solving them. During the current research, we found another subset of the DeepCubeA dataset containing 16 scrambles, which were not solved optimally during the experimental studies. We believe that a significantly rising number of agents will lead to finding solutions to all of them. However, the first element of this subset~(scramble No.17 from original DeepCubeA) was never optimally solved in any of our attempts, even during preliminary research and experiments not covered by this paper. We believe that analyzing the scrambles in this subset will help us understand why they are so hard to solve compared to the rest of the DeepCubeA data. Finally, this understanding will lead to the development of new, more efficient ML methods.\footnote{A possible explanation is that the number of optimal solution paths for such cubes is lower than average or equal to one, making these paths more difficult to find.} Thus, we decided to publish these 16 scrambles as a self-contained dataset accompanied by this paper.

The experimental results listed in Table~\ref{tbl_best} were achieved by solving all the scrambles from the corresponding dataset defined in the third column of Table~\ref{tbl_best} using the proposed solver. The key solver parameters are listed in the fourth column. The last column of Table~\ref{tbl_neural_net} demonstrates for which results from Table~\ref{tbl_best} each model was used.

The last experiment conducted in the current research was aimed to compare computational efficiency with the EfficientCube~\cite{takano2023selfsupervision} (a state-of-the-art solution claimed by its author to have better efficiency than DeepCubeA). For the fairness of comparison, we set up a virtual machine with the following resources: AMD EPYC 7513 32-core Processor running at 2.6GHz; 240\,GB RAM; 250\,GB NFS file storage; a single dedicated GPU NVIDIA A100-SXM 80GB. The virtual machine ran Red Hat Enterprise Linux version 8.7 and CUDA version 11.8. The latest version~(March 10th, 2024) of the EfficientCube was downloaded from the official GitHub repository\footnote{\url{https://github.com/kyo-takano/efficientcube}} and configured according to the author's instructions to reproduce the results from~\cite{takano2023selfsupervision}. Our solution was installed on the same virtual machine and configured with the same beam width of $2^{18}$. First, we sequentially trained a model for each solution and measured the time required for these procedures. Then, we tested both solvers on all the scrambles from the DeepCubeA dataset. We recorded the solving time for each scramble and then averaged it among the whole dataset. Finally, we compared training time and average solving time between EfficientCube and our solution. During this experiment, only one solution was running on the virtual machine at the same time.