Rubik's cube is one of the most famous puzzles, which is believed to be played by more than a billion people in the world~\cite{rubik2020cubed}. According to~\cite{van2002inventing}, it was included in the 100 most influential inventions of the 20th century. Even decades after its first introduction, it is still used as a benchmark and model task in various fields: 
artificial intelligence~\cite{agostinelli2019solving},
robotics~\cite{openai2019solvingrubikscuberobot},  
graphs algorithms~\cite{korf2008linear, sturtevant2013minimizing}, 
cryptography \cite{petit2013rubik},
image encryption \cite{loukhaoukha2012secure}, 
statistical physics~\cite{chen2014rubik, gower2024saddles}, 
group theory~\cite{joyner2008adventures, cornock2015teaching}, 
for human cognitive abilities~\cite{meinz2023ability}.  


From a more general perspective, solving the Rubik's Cube is a particular case of a planning problem---one needs to plan a sequence of actions to transit between two given states. Planning robot moves and games like chess or Go represent similar problems---for example, a game's goal is to plan moves to transit from the initial position to the winning position(s). The mathematical framework for such problems is pathfinding on graphs (state transition graphs): all possible states are represented as nodes, and edges correspond to transitions between states based on actions (moves). The planning task thus reduces to finding a path from a given initial node to one or more desired nodes. A specific class of graphs represents the Rubik's Cube and similar puzzles---Cayley-type graphs of the puzzle's symmetry group. These are highly symmetric state transition graphs where the symmetry group can transform any node into another.
Cayley graphs are of fundamental importance in modern mathematics~\cite{gromov1993geometric, tao2015expansion} and have numerous applications: in bioinformatics for estimating evolutionary distances~\cite{Pevzner1995human2mice, Pevzner1999cabbage2turnip, wilson2024cayley, bulteau2019parameterized}; in processor interconnection networks~\cite{akers1989group,cooperman1991applications,heydemann1997cayley}; in coding theory for the construction of expander graphs and related codes~\cite{hoory2006expander}; in cryptography for constructing specific hash functions~\cite{zemor1994hash,petit2013rubik}; in machine learning~(ML)~\cite{wilson2024cayley}; and in quantum computing~\cite{ruiz2024quantum,sarkar2024quantum,dinur2023good, acevedo2006exploring, gromada2022some}. 

Finding the shortest paths on generic finite Cayley graphs is an NP-hard problem~\cite{even1981minimum}, as it is for many particular groups: the Rubik's Cube group~\cite{demaine2017solving} and some others~\cite{bulteau2015pancake, wilson2024cayley}.
Brute force breadth-first search, Dijkstra's, and related methods can find the shortest paths on graphs with billions of nodes, the bidirectional trick squares feasible sizes, but these methods require extremely large computational resources and are not practical for much larger sizes, which are of our interest.
Moreover, no effective tools are currently available to find any (not just the shortest) paths on Cayley graphs of large finite groups. For example, modern computer algebra systems like GAP~\cite{linton2007gap} fail on any sufficiently large group, such as the 4$\times$4$\times$4 Rubik's Cube.

{\bf Results.} To address these issues, we develop machine learning-based methods to find paths on a broad class of graphs (specified below) of unprecedented sizes and the ability to produce unprecedentedly short paths. In the present paper, we provide code applicable to Cayley graphs (or, more generally, Schreier graphs) of any finite permutation group and focus on demonstrating its efficiency for Rubik's groups.
The presented approach is the first machine learning-based method to successfully solve the 4$\times$4$\times$4 and 5$\times$5$\times$5 Rubik's Cubes, with  $7.4\times{10}^{45}$ and $ 1.2\times{10}^{74}$ elements, respectively. The obtained solution lengths are shorter than those produced by any available method, including the combination of top results from the Kaggle Santa 2023 Challenge~\cite{santa-2023}, where more than a thousand participants applied and developed various methods.
Moreover, for the 4$\times$4$\times$4 cube, the average solution length is 46.51, which is below the conjectural diameter 48~\cite{hirata2024graph}, thus providing further evidence for the quality of our solutions.
For the 3$\times$3$\times$3 Rubik's Cube, we achieve 98.4\% optimality solving scrambles from the DeepCubeA dataset, surpassing previous machine learning approaches: DeepCubeA at 60. 3\%~\cite{agostinelli2019solving} and EfficientCube at 69.6\%~\cite{takano2023selfsupervision}. 

To conclude, this research aims to make a significant step in advancing machine learning applications to graph pathfinding and to demonstrate its efficiency in the case of Rubik's cubes of different sizes, providing more optimal solutions than any available approach for large groups.
The main contributions are the following:

% \paragraph{Machine learning-based pathfinding.}  
% We propose a novel multi-agent, machine learning-based approach to find paths on Cayley graphs of finite groups. It is the first machine learning approach capable of handling groups as large as $ {10}^{74}$. It achieves over 98\% optimality on the DeepCubeA dataset of 3$\times$3$\times$3 cubes, reaching the level of task-oriented solvers based on pattern databases. It produces better results (shorter solution paths) than any known competitor for 4$\times$4$\times$4 and 5$\times$5$\times$5 Rubik's Cubes, including the aggregated best results from the 2023 Kaggle Santa Challenge, representing the current state of the art.

% \paragraph{Training efficiency.}
% We demonstrate that increasing the size of the set used to train multilayer perceptrons with residual blocks has a limited impact on the pathfinder's performance. At the same time, increasing the beam width and number of agents robustly improves the average solution length and optimality. This surprising finding helped choose the size of the train data for each agent and achieve best-in-class performance without wasting computational resources on additional training.

% \paragraph{Computational efficiency.} The training time and computational resources required for our approach are significantly smaller than those for state-of-the-art approaches. Our solution, tested on the same hardware and beam width as EfficientCube (the previous leading ML solution), performs pathfinding slightly better than EfficientCube, solving the task $\approx26$x faster and requiring up to 18.5x less model training time than the competitor.

\begin{enumerate}
    \item We propose a novel multi-agent, machine learning-based approach to find paths on Cayley graphs of finite groups. It is the first machine learning approach capable of handling groups as large as $ {10}^{74}$. It achieves over 98\% optimality on the DeepCubeA dataset of 3$\times$3$\times$3 cubes, reaching the level of task-oriented solvers based on pattern databases. It produces better results (shorter solution paths) than any known competitor for 4$\times$4$\times$4 and 5$\times$5$\times$5 Rubik's Cubes, including the aggregated best results from the 2023 Kaggle Santa Challenge, representing the current state of the art.
    \item We demonstrate that increasing the size of the set used to train multilayer perceptrons with residual blocks has a limited impact on the pathfinder's performance. At the same time, increasing the beam width and number of agents robustly improves the average solution length and optimality. This surprising finding helped choose the size of the train data for each agent and achieve best-in-class performance without wasting computational resources on additional training.
    \item The training time and computational resources required for our approach are significantly smaller than those for state-of-the-art approaches. Our solution, tested on the same hardware and beam width as EfficientCube (the previous leading ML solution), performs pathfinding slightly better than EfficientCube, solving the task $\approx26$x faster and requiring up to 18.5x less model training time than the competitor.
\end{enumerate}


In recent years, machine learning has been emerging as "a tool in theoretical science"~\cite{douglas2022machine}, leading to several noteworthy applications to mathematical problems~\cite{lample2019deep,davies2021advancing, bao2021polytopes, romera2024mathematical, coates2024machine,alfarano2024global, charton2024patternboost,shehper2024makes}. This research is part of the larger project, which aims to create an open-source machine learning Python framework for analyzing Cayley graphs and contribute to the fascinating, emerging area of machine learning applications in theoretical sciences.
