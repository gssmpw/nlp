\section{Our approach}

\begin{figure*}[t]
\centering  
\includegraphics[width=.99\textwidth]{figures/framework.pdf}
\vspace{-3mm}
\caption{
The encoder downsizes the input point clouds and generates super-points with associated features. 
The global geometric Transformer injects geometric information into learned features. 
Coarse matching of the super-points is carried out between the two downsampled inputs. 
The local geometric Transformer is utilized to generate distinctive local features, which enables the prediction of fine-level correspondences between the inputs. 
Finally, the rigid transformation is estimated from the fine-level correspondences.}
\label{fig:frame}
\end{figure*}




\subsection{Overview}\label{sec:probf}
Point cloud registration refers to recover a transformation $\bm{T}\in SE(3)$ that aligns the source set $\bm{\mathcal{P}}=\{\bm{p}_i \in\mathbb{R}^{3}|i = 1, 2, ..., N\}$ to the target set $\bm{\mathcal{Q}}=\{\bm{q}_j \in\mathbb{R}^{3}|j = 1, 2, ..., M\}$.
$N$ and $M$ are the number of points in $\bm{\mathcal{P}}$ and $\bm{\mathcal{Q}}$, respectively. $\bm{T}$ can be calculated using correspondences between $\bm{\mathcal{P}}$ and $\bm{\mathcal{Q}}$. 
Fig.~\ref{fig:frame} shows \ourmethod's pipeline, which adopts a hierarchical paradigm to predict correspondences in a coarse-to-fine manner. 
Given the pair of point clouds $\bm{\mathcal{P}}$ and $\bm{\mathcal{Q}}$, the encoder aggregates the raw points into superpoints $\bar{\bm{\mathcal{P}}}$ and $\bar{\bm{\mathcal{Q}}}$, while jointly learning their associated characteristics $\bm{\mathcal{F}}_{\bar{p}}$ and $\bm{\mathcal{F}}_{\bar{q}}$. 
The full geometric Transformer block updates the features as $\hat{\bm{\mathcal{F}}}_{\bar{p}}$ and $\hat{\bm{\mathcal{F}}}_{\bar{q}}$. 
A \textit{Coarse Matching} module is applied to extract super-point correspondences whose neighboring local patches overlap with each other. 
The decoder transforms the features into per-point features $\bm{\mathcal{F}}_{p}$, $\bm{\mathcal{F}}_{q}$.
Then, we apply a local geometric self-attention on each patch to refine the features.
Lastly, a \textit{Fine Matching} module extracts cluster-level correspondences, which are then used to estimate the transformation.   

% \vspace{-2mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Feature Extraction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Encoder.}
We use KPConv-FPN \cite{thomas2019kpconv} to downsample $\bm{\mathcal{P}}$ and $\bm{\mathcal{Q}}$ into super-points $\bar{\bm{\mathcal{P}}}=\{\bar{\bm{p}}_i \in\mathbb{R}^{3}|i = 1, 2, ..., \bar{N}\}$ and $\bar{\bm{\mathcal{Q}}}=\{\bar{\bm{q}}_j \in\mathbb{R}^{3}|j = 1, 2, ..., \bar{M}\}$, and to extract associated point-wise features $\bm{\mathcal{F}}_{\bar{p}}=\{\bm{f}_{\bar{p}} \in\mathbb{R}^{b}|i = 1, 2, ..., \bar{N}\}$ and $\bm{\mathcal{F}}_{\bar{q}}=\{\bm{f}_{\bar{q}_j} \in\mathbb{R}^{b}|j = 1, 2, ..., \bar{M}\}$, respectively, with $b=256$.
KPConv-FPN consists of a series of ResNet-like blocks and stridden convolutions.


\vspace{-2mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Full Geometric Transformer} 
% The geometry aware overlap attention module, which estimates the probability (overlap score) of whether a point is in the overlapping area, consists of positional encoding, self-attention, and cross-attention. To better leverage the 3D geometric structures of point clouds, we introduce positional encoding that assigns intrinsic geometric properties to per-point features, thus enhancing distinctions among point features in indistinctive regions. Self-attention models the long-range dependencies. And cross attention exploits the intra-relationship within the source and target point clouds, which models the potential overlap regions. 


\noindent\textbf{Global Geometric Self-attention.}
We use the Geometric self-attention as it is implemented in GeoTransformer~\cite{qin2022geometric}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Our method entails developing a geometric cross-attention mechanism capable of identifying global correlations between super-points in two point clouds, encompassing both feature and geometric spaces. To encode the transformation-invariant geometric structure of the super-points, we introduce a new geometric structure embedding. Our approach relies on utilizing the consistent distances and local covariance matrix of the super-points across different point clouds of the same scene.

\noindent\textbf{Global Geometric Cross-attention.}
We develop a new fully-geometric cross-attention strategy that can identify global correlations between super-points in two point clouds, based on both feature and coordinate information.
% To encode the transformation-invariant geometric structure of the super-points, we introduce a new embedding for the geometric structure. Our geometry-enhanced cross-attention is inspired by GeoTransformer~\cite{qin2022geometric}.
% However, unlike GeoTransformer, which calculates distances and angles between super-points within the same point cloud, we compute relative distances and angles between super-points of different point clouds.
Given two super-points $\bar{\bm{p}}_i\in \bar{\bm{\mathcal{P}}}$ and $\bar{\bm{q}}_j\in \bar{\bm{\mathcal{Q}}}$, the cross-attention output $\bm{\hat{f}}_{\bar{p}_i}\in\hat{\bm{\mathcal{F}}}_{\bar{p}}$ for $\bm{\bar{p}}_i$ can be obtained by computing the weighted sum of all projected input features:
%+++++++++++++++++++++++++++
\begin{equation}
    \bm{\hat{f}}_{\bar{p}_i} = \sum_{j=1}^{\bar{M}}\alpha_{ij}\bm{f}_{\bar{q}_j}\bm{W}^V,
\end{equation}
%+++++++++++++++++++++++++++
where the weight coefficient $\alpha_{ij}$ is calculated using row-wise softmax on the attention scores as:
%+++++++++++++++++++++++++++
\begin{equation}
    \alpha_{ij} = \mbox{softmax}\left(  {\bm{f}_{\bar{p}_i}\bm{W}^Q\left(\bm{f}_{\bar{q}_j}\bm{W}^K+\bm{r}_{ij}\bm{W}^R\right)^\top}\big/\sqrt{b}\right),
\end{equation}
%+++++++++++++++++++++++++++
% \fabiocomment{can't we write here $\alpha_{ij} = \mbox{softmax} \left( \frac{\bm{f}_{\bar{p}_i}\bm{W}^Q\left(\bm{f}_{\bar{q}_j}\bm{W}^K+\bm{r}_{ij}\bm{W}^R\right)^\top}{\sqrt{b}} \right)$}
where $\bm{W}^Q,\bm{W}^K,\bm{W}^R,\bm{W}^V$ correspond to the projection of queries, keys, values, and geometric structure embeddings, respectively.
$\bm{r}_{ij}$ is the embedding of the cross-geometric structure of distance and angle that we compute as follows. 

\begin{figure}[t]
\centering  
\includegraphics[width=0.95\columnwidth]{figures/geo_fig.pdf}
\caption{
Angle and distance provide geometry information for cross-attention.}
\vspace{-0.4cm}
\label{fig:geo_figure}
\end{figure}


The distance and angle calculated in GeoTransformer are invariant only for rigid transformations within a single point cloud~\cite{qin2022geometric}. 
However, these measures are not invariant to rigid transformations when calculated between different point clouds that live in different reference frames.
To address this issue, we have developed a new way of computing distance and angle measures to compare points between different point clouds.
As shown in Fig.~\ref{fig:geo_figure}, we first uniformly sample $k=10$ neighbors $\Omega_{\bar{p}_i}$ of $\bar{\bm{p}}_i$ in a ball of radius $r>0$, and compute the covariance matrix $\Sigma_{\bar{p}_i}$ of these neighbouring points as:
%++++++++++++++++++++++++++++++++++++++++++++++++


\begin{equation}
    \begin{aligned}
        \Sigma_{\bar{\bm{p}}_i} &= \sum_{\bm{x}_t\in\Omega_{\bar{\bm{p}}_i}}\omega_{x_t}(\bm{x}_t-\bar{\bm{p}}_i)(\bm{x}_t-\bar{\bm{p}}_i)^\top,\\
        \omega_{x_t} & = \frac{\phi-\|\bm{x}_t-\bar{\bm{p}}_i\|_2}{\sum_{\bm{x}_t\in\Omega_{\bar{\bm{p}}_i}}(\phi-\|\bm{x}_t-\bar{\bm{p}}_i\|_2)}, 
    \end{aligned}
\end{equation}

%++++++++++++++++++++++++++++++++++++++++++++++++
where $\phi=\max\limits_{\bm{x}_t\in\Omega_{\bar{\bm{p}}_i}}\|\bm{x}_t-\bar{\bm{p}_i}\|_2$.
For $\bar{\bm{p}}_i$, we calculate an eigenvalue tuple of $\Sigma_{\bar{\bm{p}}_i}$ denoted by $\bm{{\lambda}}_{\bar{p}_i}=({\lambda}_{\bar{p}_i}^{1}, {\lambda}_{\bar{p}_i}^{2}, {\lambda}_{\bar{p}_i}^{3})$.
with ${\lambda}_{\bar{p}_i}^{1} \leq {\lambda}_{\bar{p}_i}^{2}\leq {\lambda}_{\bar{p}_i}^{3}$.
The $\Sigma_{\bar{\bm{p}}_i}$ is transformation invariant.
We sign the eigenvector associated with ${\lambda}_{\bar{p}i}^{1}$ as $\bm{v}_{\bar{p}_i}$, ensuring that its orientation is positive from the center of the point cloud towards the current point.
Using the same operation, we get $\bm{{\lambda}}_{\bar{q}_j}$ for $\bar{\bm{q}}_j\in\bar{\bm{\mathcal{Q}}}$ and $\bm{v}_{\bar{q}_j}$.

For distance embedding, we choose the Gromov-Wasserstein distance~\cite{peyre2019computational}, which is transformation invariant, and it can calculate the distance between metrics defined within each of the source and target spaces. 
Therefore, we use the GWD map to measure the transformation relationship $\bm{S}=\{s_{ij}\}$ of points from $\bar{\bm{\mathcal{P}}}$ and $\bar{\bm{\mathcal{Q}}}$, which formulates as:
%++++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}\label{eq:gw}
\begin{aligned}
&d_{gw}\left(\bar{\bm{\mathcal{P}}},\bar{\bm{\mathcal{Q}}}\right)=\min_{S\geq0}\sum_{stkl}\left(C_{sk}^{\bar{p}}-{C_{tl}^{\bar{q}}}\right)^2 \bm{S}_{st}\bm{S}_{kl},\\
&\mbox{s.t.,~} 
\begin{cases}
C_{sk}^{\bar{p}}=\|\bar{\bm{p}}_{s}-\bar{\bm{p}}_{k}\|^2_2+\alpha\|\bm{v}_{\bar{p}_s}-\bm{v}_{\bar{p}_k}\|^2_2,\\
C_{sk}^{\bar{q}}=\|\bar{\bm{q}}_{t}-\bar{\bm{q}}_{l}\|^2_2+\alpha\|\bm{v}_{\bar{q}_t}-\bm{v}_{\bar{q}_l}\|^2_2,
\end{cases}
\end{aligned}
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++
where $\alpha>0$ is a learning parameter. The $\bm{S}_{ij}$ describes the similarity between the points $\bar{\bm{p}}_i$ and $\bar{\bm{q}}_{j}$.
Eq.~\eqref{eq:gw} is solved using the Sinkhorn algorithm~\cite{peyre2019computational}.


For angle computation, we first define $\bm{\lambda}_c=\frac{1}{\bar{N}+\bar{M}}\left(\sum_{i=1}^{\bar{N}}\bm{\lambda}_{\bar{\bm{p}}_i} + \sum_{j=1}^{\bar{M}}\bm{\lambda}_{\bar{\bm{q}}_j}\right)$ as the center of union of $\bar{\bm{\mathcal{P}}}$ and $\bar{\bm{\mathcal{Q}}}$ in the eigenvalue space.
For each $\bar{\bm{p}}_i$, we compute a feature vector
$\bm{f}^g_{\bar{p}_i}= \mbox{cat}\left[\frac{\|\bm{\lambda}_{\bar{\bm{p}}_i}-{\bm{\lambda}}_c\|_2}{\max\limits_j\|\bar{\bm{p}}_j-\bar{\bm{p}}_c\|_2},\bm{\lambda}_{\bar{\bm{p}}_i}\right]$ that encodes the geometric and spatial properties of the local patch of a single point within a single point cloud and the global structure information from two point clouds.
$\mbox{cat}[\cdot, \cdot]$ concatenates two vectors into a single vector.
Applying the same operator to $\bar{\bm{q}}_j\in\bar{\bm{\mathcal{Q}}}$, we can obtain $\bm{f}^g_{\bar{q}_j}$ for $\bar{\bm{q}}_j$.
After that, for each ${\bm{x}\in\Omega_{\bar{\bm{p}}_i}}$, we compute the angle $\theta^x_{ij}$ between the vectors $\bm{f}^g_{\bar{p}_i}-\bm{f}^g_{\bar{q}_j}$ and $\bm{f}^g_{x}-\bm{f}^g_{\bar{q}_j}$ as:
%++++++++++++++++++++++++++++++++++++++++
\begin{equation}
    \theta^x_{ij} =\arccos\frac{\left<\bm{f}^g_{\bar{p}_i}-\bm{f}^g_{\bar{q}_j}, \bm{f}^g_{x}-\bm{f}^g_{\bar{q}_j}\right>}{\|\bm{f}^g_{\bar{p}_i}-\bm{f}^g_{\bar{q}_j}\|\| \bm{f}^g_{x}-\bm{f}^g_{\bar{q}_j}\|}.
\end{equation}
%++++++++++++++++++++++++++++++++++++++++
The geometric structure embedding of $\bar{\bm{p}}_i\in \bar{\bm{\mathcal{P}}}$ and $\bar{\bm{q}}_j\in \bar{\bm{\mathcal{Q}}}$ comprises a pair-wise cross distance embedding and a triplet-wise cross angular embedding defined as follows:
% \fabiocomment{"their geometric structure embedding consists of a pair-wise distance embedding and a triplet-wise angular embedding", the geometric structure embedding is defined in Eq. 4, do you want to say that the geometric structure embedding that we are seeking to define is composed of these two terms? YES}
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=*]
% \itemsep0em
    \item{\verb|Pair-wise Cross Distance Embedding.|} The distance embedding $\bm{r}^D_{ij}$ between $\bar{\bm{p}}_i$ and $\bar{\bm{q}}_j$ is calculated as $\bm{r}^D_{ij}{=}\mbox{sinu}(\left(1-s_{ij}\right) {/} \sigma_{\rho})$, where $\mbox{sinu}(\cdot)$ is a sinusoidal function as in~\cite{vaswani2017attention}, and $\sigma_{\rho}{>}0$ is a learning parameter.
    \item{\verb|Triplet-wise Cross Angle Embedding.|} Angular embedding is computed by using triplets of super-points. 
    Specifically, for each ${\bm{x}\in\Omega_{\bar{\bm{p}}_i}}$, the triplet-wise angular embedding $\bm{r}^A_{ijx}$ is computed as 
    $\bm{r}^A_{ijx}{=}\mbox{sinu}(\theta^x_{ij}/\sigma_{\theta})$ with a learning parameter $\sigma_{\theta}{>}0$.
    % \fabiocomment{why do you indicate the sinusoidal function with sinu? isn't it just sin? Guofeng:It is similar the position embedding, containing sin and cos}
\end{itemize}
Lastly, the geometric structure embedding $\bm{r}_{ij}$ is obtained by combining the pair-wise distance embedding and the triplet-wise angular embedding through aggregation, expressed as:
%++++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}
\bm{r}_{ij} = \bm{r}^D_{ij}\bm{W}^D+\max_x\{\bm{r}^A_{ijx}\bm{W}^A\},
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++
where  $\bm{W}^D,\bm{W}^A$ are projection matrices corresponding to the two kinds of embeddings, respectively.
The latent features $\hat{\bm{\mathcal{F}}}_{\bar{p}}$ then carry the knowledge of $\hat{\bm{\mathcal{F}}}_{\bar{q}}$, and vice versa. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Decoder.} 
The decoder, based on KPConv layers \cite{thomas2019kpconv}, starts from the super-points $\bar{\bm{\mathcal{P}}}$ and the concatenations of $\hat{\bm{\mathcal{F}}}_{\bar{p}}$ and  $\bm{\mu}_{\bar{p}}$, and outputs the point cloud $\bm{\mathcal{P}}$ with associated features $\bm{\mathcal{F}}_{p}\in\mathbb{R}^{N\times 32}$ and overlap scores $\bm{\mu}_{p}\in[0,1]^{N}$. The raw point cloud $\bm{\mathcal{Q}}$ and its associated features $\bm{\mathcal{F}}_{q}\in\mathbb{R}^{M\times 32}$ are obtained in the same way.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Local Geometric Self-attention.}
For each super-point, we first construct a local patch of points around it using the point-to-node grouping strategy~\cite{yu2021cofinet}.
For a super-point $\bar{\bm{p}}_i\in \bar{\bm{\mathcal{P}}}$, its associated point set $G_{\bar{p}_i}$ and feature set $G_{\bm{f}_{\bar{p}_i}}$ are denoted as:
%++++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}
    \begin{cases}
		G_{\bar{p}_i}=\{\bm{p}\in \bm{\mathcal{P}}\big|\|\bm{p}-\bm{\bar{p}}_i\|_2\leq\|\bm{p}-\bm{\bar{p}}_j\|_2, i\neq j\}, \\
		G_{\bm{f}_{\bar{p}_i}}=\{\bm{f}_{\bm{x}_j}\in \bm{\mathcal{F}}_{p}\big|\bm{x}_j \in G_{\bar{p}_i}\}.
	\end{cases}
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++
In a similar way, we can get $G_{\bar{q}_i}$ and $G_{\bm{f}_{\bar{q}_i}}$.

Given the local patch $G_{\bar{p}_i}=\{\bar{\bm{p}}_{i1},\bar{\bm{p}}_{i2}, \cdots,\bar{\bm{p}}_{iK}\}$, 
to perform local geometric attention, we first calculate the distance matrix $D^i=\{d^i_{kl}\}_{k,l=1}^K$, 
where $d^i_{kl}=\{\bar{\bm{p}}_{i1},\bar{\bm{p}}_{i2}, \cdots, \bar{\bm{p}}_{iK}\}$ with $d^i_{kl}=\|\bar{\bm{p}}_{ik}-\bar{\bm{p}}_{il}\|^2_2$.
Distance-based weights are calculated by $R^i=\mathtt{DS}(D^i)=\{r^i_{kl}\}$. $\mathtt{DS}(\dot)$ is a Dual Softmax operator.
Then, the self-attention output $\bm{\bm{f}}^i_{\bar{p}_{ik}}\in G_{\bm{f}_{\bar{p}_i}}$ for $\bm{\bar{p}}_{ik}$ can be updated by computing the weighted sum of all weighted input features:
%+++++++++++++++++++++++++++
\vspace{-0.2cm}
\begin{equation}
    \bm{f}^i_{\bar{p}_{ik}} = \sum_{l=1}^{K}\frac{\beta_{kl}}{\sum_j\beta_{kj}}\bm{f}^i_{\bar{p}_{il}},
% \vspace{-0.2cm}
\end{equation}
%+++++++++++++++++++++++++++
where the weight coefficient $\beta_{kl}$ is calculated using row-wise softmax on the attention scores as:
%+++++++++++++++++++++++++++
\begin{equation}
    \beta_{kl} = r_{kl}^i\cdot\mbox{softmax} \left(  \frac{\bm{f}^i_{\bar{p}_{ik}}\bm{W}_i^Q(\bm{f}^i_{\bar{p}_{il}}\bm{W}_i^K)^\top}{\sqrt{b}}\right),
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++
We also applied the same operator to update $G_{\bm{f}_{\bar{q}_i}}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Correspondence Prediction}


\noindent \textbf{Coarse Matching.}
Coarse Matching estimates super-point correspondences between $\bm{\bar{\mathcal{P}}}$ and $\bm{\bar{\mathcal{Q}}}$, which can be formulated as an assignment problem and solved by calculating an assignment matrix $\bar{\Gamma}\in \mathbb{R}^{\bar{N}\times \bar{M}}$ as:
%++++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}\label{eq:super}
\min_{\bar{\Gamma}}\left<\bar{\bm{C}}, \bar{\Gamma}\right>, 
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++
where $\left<\cdot, \cdot\right> $ is the Frobenius dot product. 
$\bar{\bm{C}}$ is a distance matrix with elements that satisfy 
\begin{small}
\begin{equation*}
\bar{\bm{C}}_{ij}=(1-\eta)\|\frac{\hat{\bm{f}}_{\bar{p}_i}}{\|\hat{\bm{f}}_{\bar{p}_i}\|}-\frac{\hat{\bm{f}}_{\bar{p}_j}}
{\|\hat{\bm{f}}_{\bar{p}_j}\|}\|
+
\eta\|\frac{\bm{f}^g_{\bar{p}_i}}{\|\bm{f}^g_{\bar{p}_i}\|}-\frac{{\bm{f}}^g_{\bar{q}_j}}{\|\bm{f}^g_{\bar{q}_j}\|}\|,
\end{equation*}
\end{small}
with  $\hat{\bm{f}}_{\bar{p}_i}\in\hat{\bm{\mathcal{F}}}_{},\hat{\bm{f}}_{\bar{q}_j}\in\hat{\bm{\mathcal{F}}}_{\bar{q}}$, and each $\bar{\Gamma}_{ij} \in \bar{\Gamma}\in[0,1]^{\bar{N}\times \bar{M}}$ represents the matching score between $\bm{\bar{p}}_i$ and $\bm{\bar{q}}_j$.
$\eta=0.1$ is a parameter that controls the weight of the feature distance and the structure distance.
Eq.~\eqref{eq:super} is an example of the optimal transport problem \cite{cuturi2013sinkhorn} and can be solved efficiently using the Sinkhorn-Knopp algorithm \cite{cuturi2013sinkhorn}.
After computing $\bar{\Gamma}$, we select correspondences with confidence higher than a threshold $\tau_c$, and enforce the mutual nearest neighbor (MNN) constraint to have fewer but reliable correspondences. 
The super-point correspondence set $\mathcal{\bar{M}}$ is then defined as:
%++++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}\label{eq:sset}
	\mathcal{\bar{M}}=\{(\bm{\bar{p}}_{\hat{i}},\bm{\bar{q}}_{\hat{j}})\big|\forall(\hat{i},\hat{j})\in \mbox{MNN}(\bar{\Gamma}), \bar{\Gamma}_{\hat{i},\hat{j}}\geq\tau_c\}.
\end{equation}
%++++++++++++++++++++++++++++++++++++++++++++++++




\noindent \textbf{Fine Matching.}
Extracting point correspondences is analogous to matching two smaller-scale point clouds by solving an optimal transport problem to calculate a matrix $\Gamma^{G_{\bar{p}_i}}$ in a manner of coarse-level done.
For correspondences, we choose the maximum confidence score of $\Gamma^{G_{\bar{p}_i}}$ in every row and column to guarantee higher precision. The final point correspondence set $\mathcal{M}$ is represented as the union of all the correspondence sets obtained. After obtaining the correspondences $\mathcal{M}$, following \cite{qin2022geometric,yu2021cofinet},  a variant of RANSAC \cite{fischler1981random} that is specialized in 3D correspondence-based registration \cite{zhou2018open3d} is utilized to estimate the transformation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Loss Function and Training}
We train \ourmethod using ground-truth correspondences as supervision. 
The loss function is: $\mathcal{L} = \mathcal{L}_{C}  + \mathcal{L}_{F}$,
%+++++++++++++++++++++++++++++++++++++++++++
% \vspace{-2mm}
% \begin{equation}
% \mathcal{L} = \mathcal{L}_{C}  + \mathcal{L}_{F},
% \vspace{-2mm}
% \end{equation}
%+++++++++++++++++++++++++++++++++++++++++++
where $\mathcal{L}_{C}$ and $\mathcal{L}_{F}$ denote a coarse and a fine matching loss.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Coarse Matching Loss.}
Following \cite{yu2021cofinet,fu2021robust}, we formulate super-point matching as a multilabel classification problem and adopt a cross-entropy loss with optimal transport. As there is no direct supervision for super-point matching, we leverage the overlap ratio $r_{ij}$ of points in $G_{\bar{p}_i}$ that have correspondences in $G_{\bar{q}_j}$ to depict the matching probability between super-points $\bar{p}_i$ and $\bar{q}_j$. $r_{ij}$ is defined as:
%+++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}\label{eq:cratio}
r_{ij} =\frac{1}{{|G_{\bar{p}_i}|}} {|\{\bm{p}\in G_{\bar{p}_i}\big|\min_{\bm{q}\in G_{\bar{q}_j}}\|\hat{\bm{T}}\left(\bm{p}\right) -\bm{q}\|_2<r_p\}|},
\end{equation}
%+++++++++++++++++++++++++++++++++++++++++++++++
where $\hat{\bm{T}}$ is the ground-truth transformation and $r_p$ is a set threshold.
% For circle loss, a pair of super-points are positive if their corresponded patches share at least $10\%$ overlap, and negative if they do not overlap. 
% \fabiocomment{why are you talking about circle loss here? you never mentioned it before.
% you have to introduce it and explain why we use it.}
All other pairs are omitted. We select the super-points in $\bm{\bar{\mathcal{P}}}$ which have at least one positive super-point in $\bm{\bar{\mathcal{Q}}}$ to form a set of anchor super-points, $\bm{\tilde{\mathcal{P}}}$. 
Based on Eq.~\eqref{eq:cratio}, we define the weight matrix $\mathbf{\bar{W}} \in \mathbb{R}^{\bar{N} \times \bar{M}}$ as:
%+++++++++++++++++++++++++++++++++++++++++++++++
\begin{scriptsize}
\begin{equation*}
    \mathbf{\bar{W}}\left(i, j\right){=} 
    \begin{cases}
    r\left(i, j\right),  & i \leq \bar{N} \wedge j \leq \bar{M}, \\  
    0, & \text {otherwise.}
    \end{cases}
\end{equation*}
\end{scriptsize}
%+++++++++++++++++++++++++++++++++++++++++++++++
Finally, the coarse matching loss can be written as:
%+++++++++++++++++++++++++++++++++++++++++++++++
\begin{equation}
\mathcal{L}_C=-\frac{\sum_{i, j} \mathbf{\bar{W}}\left(i, j\right) \log \left(\mathbf{\bar{\Gamma}}\left(i, j\right)\right)}{\sum_{i, j} \mathbf{\bar{W}}\left(i, j\right)}.
\end{equation}
%+++++++++++++++++++++++++++++++++++++++++++++++

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Fine Matching Loss.}
We apply the circle loss again to supervise the point matching.
Consider a pair of matched super-points $\bar{\bm{p}}_i$ and $\bar{\bm{q}}_j$ with associated patches $G_{\bar{p}_i}$ and $G_{\bar{q}_j}$, we first extract a set of anchor points $\tilde{G}_{\bar{p}_i} \subseteq G_{\bar{p}_i}$ satisfying that each $\bm{g}^k_{\bar{p}_i}\in \tilde{G}_{\bar{p}_i}$ has at least one (possibly multiple) correspondence in $G_{\bar{q}_j}$, i.e.,
\begin{equation*}
\tilde{G}_{\bar{p}_i} = \{\bm{g}^k_{\bar{p}_i}\in \tilde{G}_{\bar{p}_i} |\min_{\bm{g}^l_{\bar{q}_j}\in G_{\bar{q}_j}}\|\hat{\bm{T}}\left(\bm{g}^k_{\bar{p}_i}\right)-\bm{g}^l_{\bar{q}_j}\|_2 < r_p\}.
\end{equation*}
% Each element $\bm{W}^{{\bar{p}_i}}_{kl}$ of the ground-truth matching probability matrix $\bm{W}^{\bar{p}_i}$ between patches $G_{\bar{p}_i}$ and $G_{\bar{q}_j}$ is calculated directly by
% \begin{equation}\label{eq:bn}
% 	\bm{W}^{{\bar{p}_i}}_{kl} = 
% 	\begin{cases}
% 		1, & \|\hat{\bm{T}}\left(G_{\bm{\mu}_{\bar{p}_i}}(k)\right)-G_{\bar{q}_j}(l)\|_2 < r_p \\
% 		0, & \text{otherwise}
% 	\end{cases}.
% \end{equation}
For each anchor $\bm{g}^k_{\bar{p}_i}\in \tilde{G}_{\bar{p}_i}$,  we denote the set of its positive points in $G_{\bar{q}_j}$ as $\mathcal{N}_p^{\bm{g}^k_{\bar{p}_i}}$. All points of $\mathcal{\bm{Q}}$ outside a (larger) radio $r_n$ form the set of its negative patches as $\mathcal{N}_n^{\bm{g}^k_{\bar{p}_i}}$. The fine-level matching loss $\mathcal{L}_{F}^{\mathcal{\bm{P}}}$ on $\mathcal{\bm{P}}$ is calculated as:
%++++++++++++++++++++++++++++++++++
\vspace{-2mm}
\begin{scriptsize}
\begin{equation*}
\begin{aligned}
    \mathcal{L}_{F}^{\mathcal{\bm{P}}} &=\frac{1}{|\bm{\tilde{\mathcal{P}}}|}\sum_{\tilde{\bm{p}}_i\in\bm{\bar{\mathcal{P}}}}\frac{1}{|\tilde{G}_{\bar{p}_i}|} \sum_{\bm{g}^s_{\bar{p}_i}\in \tilde{G}_{\bar{p}_i}}\log\left[1+\xi_s\right], \\
    \xi_s &= \sum_{\bm{g}^k_{\bar{q}_j}\in\mathcal{N}_p^{\bm{g}^s_{\bar{p}_i}}}e^{r^k_s\beta_p^{sk}(d_s^k-\Delta p)}\cdot\sum_{\bm{g}^l_{\bar{q}_j}\in\mathcal{N}_n^{\bm{g}^s_{\bar{p}_i}}}e^{\beta_n^{sl}(\Delta n - d_s^l)},
\end{aligned}
\end{equation*}
\end{scriptsize}
%+++++++++++++++++++++++++++++++++
where $d_s^k=\mathcal{D}_f(\bm{f}_{\bm{g}^s_{\bar{p}_i}},\bm{f}_{\bm{g}^s_{\bar{q}_j}})$ is the distance in the feature space. The weights $\beta_p^{sk}=\omega d_s^k$ and $\beta_n^{sl}{=}\omega (2.0-d_s^l)$ are determined individually for each positive and negative example with a learned scale factor $\omega\geq 1$. $\Delta p = 0.1$ and $\Delta n = 1.4$. The same goes for the loss $\mathcal{L}_{F}^{\bm{\mathcal{Q}}}$ on $\bm{\mathcal{Q}}$. The
overall super-point matching loss is written as
$\mathcal{L}_{F} {=} \frac{1}{2}(\mathcal{L}_{F}^{\mathcal{\bm{P}}} + \mathcal{L}_{F}^{\mathcal{\bm{Q}}})$.
% \begin{equation}
%   \mathcal{L}_{F} = \frac{1}{2}(\mathcal{L}_{F}^{\mathcal{\bm{P}}} + \mathcal{L}_{F}^{\mathcal{\bm{Q}}}).