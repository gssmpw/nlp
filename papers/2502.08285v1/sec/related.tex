\section{Related Work}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Correspondence-based Registration.}
Correspondence-based methods typically involve two main steps: feature extraction and correspondence estimation through feature matching. 
They perform outlier rejection and robust estimation of the rigid transformation. 
FCGF~\cite{choy2019fully}, RGM~\cite{fu2021robust}, and GeDi~\cite{GEDI} are examples of methods used to extract discriminative features. 
For correspondence prediction, RPMNet~\cite{yew2020rpm} performs feature matching by integrating the Sinkhorn algorithm into a network that generates soft feature correspondences.
IDAM~\cite{li2019iterative} incorporates both geometric and distance features in the iterative matching process. 
To reject outliers, DGR~\cite{choy2020deep} and 3DRegNet~\cite{pais20203dregnet} use networks for inlier prediction.
Correspondence-based techniques can be further classified into two groups based on the strategy they employ to extract correspondences~\cite{qin2022geometric}. 
The methods in the first group aim to identify repeatable keypoints \cite{bai2020d3feat, huang2021predator} and develop discriminative descriptors for those keypoints \cite{ao2021spinnet, wang2022you, wang2023roreg}. 
The effectiveness of keypoint detection methods may be limited in scenarios with uneven point density or similar local structures. 
Repetitive local structures are typically present in indoor settings, where featureless flat surfaces can occupy a significant portion of the visual field. 
The methods in the second group aim to retrieve correspondences without detecting keypoints by examining all possible matches~\cite{yu2021cofinet, qin2022geometric}. 
They first downsample the point clouds into super-points and then match them by examining whether their neighborhoods (patches) overlap~\cite{mei2021point, zhang2022patchformer, yu2021cofinet}. 
The accuracy of dense point correspondences relies on the accuracy of super-point matches~\cite{qin2022geometric}. 
When dealing with low-overlapping point clouds, the super-point matching mechanism merely exchanges information from the feature spaces, which contain only partial structural information. 
This limitation emerges when compared to the original 3D scenes contained within the point cloud pair, leading to false matches. 
The points of a patch tend to have similar features, which can challenge dense correspondence prediction. 
To overcome these limitations, \ourmethod merges the advantages of both cross-geometric structures and feature relationships, enhancing the accuracy of super-point matching. 
We introduce a distance-enhanced local self-attention mechanism that generates point-level features, improving dense matching capabilities.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent\textbf{Transformer on Registration.}
Transformer attention~\cite{vaswani2017attention} has recently been successful in point cloud tasks due to its ability to learn long-range dependencies and invariance to input token permutations.
Using the Transformer has been shown to enhance point cloud registration performance effectively.
DCP~\cite{wang2019deep} applies standard cross-attention to highlight similarities of matched points across two point clouds for soft correspondence generation.
The Geometric Transformer~\cite{qin2022geometric} aims to improve feature matching accuracy by enhancing the effectiveness of self-attention in acquiring geometric information.
Their method encodes both pairwise distances and triplet-wise angles, allowing it to handle low-overlap scenarios while remaining invariant to rigid transformations.
REGTR~\cite{yew2022regtr} integrates the Transformer~\cite{vaswani2017attention} into a network that generates soft correspondences from local features, allowing feature matching for point clouds with partial overlaps.
Predator~\cite{huang2021predator} and PRNet~\cite{wang2019prnet} apply Transformer to detect points in the overlap region and use the features of the detected points to generate matches.
Several of these methods fail to consider the fact that multiple regions within a point cloud may display similar structures, which can limit the effectiveness of standard cross-attention when dealing with comparable local structures.
Motivated by this, we propose an improved cross-attention that incorporates transformation-invariant geometric structure into learned features to better highlight overlap regions of both point clouds.