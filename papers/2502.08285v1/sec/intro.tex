\section{Introduction}
\label{sec:intro}
\thispagestyle{empty}
Point cloud registration aims to determine a relatively rigid transformation that aligns two partially observed point clouds. 
This is important in various applications, including 3D printing \cite{xie2023bayesian, nie2024t2td}, robotics \cite{kim2018slam}, and autonomous driving \cite{brightman2023point}.
In recent registration advances, deep learning-based methods have outperformed hand-crafted ones in both efficiency and accuracy \cite{choy2019fully, GEDI}.

Learning-based point cloud registration 
can be categorized into \textit{correspondence-free}~\cite{aoki2019pointnetlk, huang2020feature, xu2021omnet, mei2022augfree} or \textit{correspondence-based}~\cite{GEDI, choy2020deep, bai2021pointdsc, huang2021predator, yew2022regtr, corsetti2023revisit, wang2024zeroregzeroshotpointcloud}.
The former aims to minimize the difference between the global features of two point clouds.
However, global features may hinder these approaches in handling partially overlapping scenes~\cite{zhang2020deep, choy2020deep}. 
The latter aims to detect keypoints, compute local descriptors, find correspondences, and estimate the rigid transformation~\cite{huang2021predator,mei2021point}.
Correspondences can be defined at the point level or at the distribution level~\cite{GEDI,wang2023roreg}.
Point-level correspondences may be noisy in the case of point clouds with different densities of points and/or with geometrically repetitive and uninformative local patterns (e.g.~flat surfaces)~\cite{xu2022glorn,mei2023overlap}.
Distribution-level correspondences are designed to align point clouds with varying densities without establishing point-level correspondences, however, they fall short in handling point clouds with low overlaps~\cite{mei2022overlap,huang2022unsupervised}.
There also exist methods that replace keypoint detection by downsampling input point clouds into super-points in order to make computation efficient~\cite{yu2021cofinet}.
Super-points are matched between point clouds to find correspondences, which are in turn propagated at point-level to build dense point correspondences.
Furthermore, self-attention and cross-attention in Transformers~\cite{vaswani2017attention} can be used to incorporate global information (context) into features~\cite{huang2021predator, yu2021cofinet, qin2022geometric}, thus producing distinctive features to register point clouds more accurately.
Self-attention is performed in the coordinate space to encode the transformation-invariant geometric structure from each point cloud \cite{qin2022geometric}.
Cross-attention is performed in the feature space to model the geometric consistency across point clouds, by allowing information from one point cloud to be attended by another \cite{qin2022geometric}.

We argue that previously proposed cross-attention formulations only employ point feature information, overlooking coordinate information.
Although cross-attention in the feature space is effective in improving correspondence quality between super-points, point-level correspondences remain rather noisy (we will show this experimentally).
Intuitively, if we only consider feature information, disregarding their location, there could be situations where similar objects in different locations have similar geometric structures, hence similar features. 
This can produce incorrect correspondences. 
By enriching the cross-attention with coordinate information, we can encourage the network to explicitly learn corresponding geometric structures across point clouds, thus promoting feature distinctiveness.

To this end, in this paper we present a \textbf{f}u\textbf{l}ly-geometric cross-\textbf{at}tention formulation, \ourmethod for short, followed by overlap-constrained clustering to learn accurate correspondences for point cloud registration.
Unlike GeoTransformer~\cite{qin2022geometric}, which only considers geometric relationships within a single point cloud. Our method, \ourmethod, uses geometric cross-attention to incorporate both source and target relationships. This provides comprehensive scene information, overcoming the limitations of partial scene representation in overlapped point clouds. In addition, we develop cross-spatial invariant geometric features and use the Gromov-Wasserstein distance to measure discrepancies across different metric spaces, such as pose differences.
Our cross-attention is significantly more challenging to achieve, as measures of distance and angle used in GeoTransformer are no longer applicable because they are not invariant to rigid transformations with respect to different reference frames.
To fix this gap, we introduce two new metrics, one for measuring the pair-wise distance and the other for determining the triplet-wise angle that can be computed between two different point clouds.
As these two metrics are invariant to rigid transformation, our geometry-enhanced attention can efficiently exchange geometric structural information between point clouds, leading to more reliable correspondences, even in scenarios with low overlaps.
Our registration approach follows a coarse-to-fine correspondence prediction strategy, identifying approximate matches using super-points and refining them by expanding them to patches (i.e.~sets of points defined in the neighborhood of a super-point).
Moreover, unlike previous techniques, we employ a distance-weighted self-attention to inject the local location information to further improve the distinctive of the local features.
We evaluate our method on four popular benchmarks:
3DMatch \cite{zeng20173dmatch} and 3DLoMatch \cite{huang2021predator} (indoors), KITTI \cite{geiger2012we} (outdoors), and cross-source 3DCSR~\cite{huang2021comprehensive} (indoors).
The results show that \ourmethod outperforms previous approaches~\cite{huang2021predator,yu2021cofinet,qin2022geometric}.
In summary, our contributions are:
\begin{itemize}[noitemsep,topsep=0pt]

\item We introduce a geometry-enhanced cross-attention mechanism alongside a distance-weighted self-attention approach, aiming to refine the learning of accurate correspondences for point cloud registration.
\item Our proposed geometry-enhanced cross-attention effectively integrates a transformation invariant geometric structure, enabling the model to learn distinctive features and emphasize the overlapping regions between point clouds.
\item Leveraging local self-attention, which is grounded in coordinate relative distances, we generate distinctive features that enhance fine matching capabilities.
\end{itemize}
