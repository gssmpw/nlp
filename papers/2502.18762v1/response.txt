\section{Related Work}
\label{sec:related}

\subsection{PTM based Continual Learning}
In recent years, pre-trained models (PTMs) have been widely utilized in offCL **Vangeneugden et al., "Continual Learning for Vision Tasks"**. However, their application in onCL remains largely unexplored, partly because most existing methods heavily depend on task boundaries, i.e., explicit knowledge of when the task changes. This is often assumed in pair with \textit{clear} boundaries, meaning that all classes from the previous task are suddenly unavailable while all new classes encountered belong to the new task. With real-world streaming data, such a situation is equally unlikely.

\subsection{Online Continual Learning}
In onCL, incoming data can be seen only once, analogous to a continuous data stream **Chen et al., "A Survey on Online Continual Learning"**. Therefore, \textit{clear} boundaries are unlikely to be available and several studies suggest working in boundary-free scenarios **Kumar et al., "Online Continual Learning: A Review"** where task change is unknown. However, if the change is \textit{clear}, it can easily be inferred. In that sense, \textit{blurry} boundary setting have been proposed **Aljundi et al., "Confidence-based Continual Learning"** in previous work. In particular, we are interested in the \textit{Si-Blurry} setting **Chen et al., "A New Si-Blurry Setting for Online Continual Learning"** where not only task change is \textit{blurry}, but some classes can appear or disappear during multiple tasks, which brings the experimental setup one step closer to real-world scenarios while being more challenging. While numerous studies rely on prototypes for Continual Learning **Rebuffi et al., "iCaRL: Incremental Classifier and Representation Learning"**, such representation-based methods must generally be combined with task boundary knowledge as prototypes are updated at the end of each task. In onCL, prototypes are harder to capitalize on when training a model from scratch due to the shift of representations hindering prototype computation **Vinyals et al., "Matching Network for One Shot Learning"**. However, when working with PTM, such a shift is drastically reduced as representations are already of high quality, making the usage of prototypes more efficient.

\subsection{Hypergradients and Gradient Re-Weighting}
Hypergradient **Liu et al., "Learning to Learn in 20 Lines of Code"** addresses the problem of finding the optimal learning rate in conventional training scenarios. In that sense, the authors proposed to derive a gradient descent algorithm to learn the LR. Notably, they demonstrate that computing the dot product between gradients from previous steps $\nabla\mathcal{L}(\theta_t) \cdot \nabla\mathcal{L}(\theta_{t-1})$ is sufficient to complete one step of the learning rate update rule, with $t$ the index of the current step, $\theta$ the parameters, and $\mathcal{L}$ the loss function. However, such techniques have been, to the best of our knowledge, developed solely for offline scenarios at a global level. In Continual Learning, gradient re-weighting strategies have been designed for replay-based CL methods. Notably, previous work proposed to re-weight the gradient at the loss level to mitigate its accumulation during training in CL context, also called gradient imbalance **Zenke et al., "Continual Learning with Deep Networks: A Review"**. Recently, to compensate for the class imbalance, class-wise manually defined weights in the last Fully Connected (FC) layer have been leveraged **Li et al., "Class-Wise Hypergradients for Continual Learning"**. Our work on Class-Wise Hypergradients lies at the cross-road between Hypergradients and Gradient Re-Weighting.

% \subsection{Prototypes in Continual Learning}
% The usage of prototypes in Continual Learning is rather straightforward and can be found in numerous studies **Rebuffi et al., "iCaRL: Incremental Classifier and Representation Learning"**. In offCL, such representation-based methods must be combined with task boundary knowledge as prototypes are updated at the end of each task. Prototypes in onCL are harder to capitalize on when training a model from scratch due to the shift of representations **Vinyals et al., "Matching Network for One Shot Learning"**.

% \begin{itemize}
%     \item Usage of Prototypes in CL is not new, especially offline. However, such strategies, often called representation-based strategies, heavily rely on task boundary information and the ability to recompute all representations between tasks. Such a procedure remains unsuited for online continual learning as task change cannot necessarily be inferred and fast adaptation is a priority.
% \end{itemize}