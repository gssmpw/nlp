\section{Related Work}
Our work contributes to the growing body of research on decision-making with partial access to votes.  \citet{filmus2014efficient} and \citet{oren2013efficient} studied \(t\)-top queries, where each agent reports their top \(t\)-candidates, and investigated how large \(t\) must be to reliably identify the correct winner under various voting rules. Similarly, \citet{bentert2020comparing} examined \(t\)-wise comparison queries, analyzing which voting rules can be implemented with this feedback. More recently, \citet{halpern2024computing} provided a complete characterization of positional scoring rules that can be computed using \(t\)-wise comparison feedback.  

These works build on foundational results regarding pairwise comparisons, which are often represented as (weighted) tournament graphs. Tournament graphs serve as the primary input for many well-known voting rules, including Borda count and several Condorcet-consistent rules, such as Copeland, Kemeny, and Minimax~\cite{brandt2016handbook}. Our work builds on and extends the results of \citet{halpern2024computing}, which we discuss in greater detail later. To the best of our knowledge, no prior work has studied improvement feedback query for identifying the correct winner under different voting rules. 

The query complexity of identifying the correct candidate has been also studied over different queries. For example, the query complexity of tournament graphs has been studied in the context of identifying Condorcet winners~\citep{procaccia2008note}. Other works have explored the query complexity of complete rankings, focusing either on identifying the winner~\cite{dey2015sample} or recovering the full ranking~\cite{micha2020can} of different voting rules. In contrast, our work focuses on information-theoretic impossibilities, assuming perfect access to the feedback model under consideration, and does not analyze the sample complexity of learning voting rules.

Our work is also related to frameworks like coactive learning~\citep{shivaswamy2015coactive} and interactive preference learning~\citep{tucker2024coactive}, which focus on scenarios where users provide incremental improvements rather than global rankings. However, these frameworks aim to minimize regret and learn a good candidate for a single user through iterative interaction. In contrast, we investigate whether improvement feedback is sufficient to identify the correct candidate when preferences are heterogeneous across a population.