\section*{Limitations}

The proposed method relies heavily on the Visual Genome dataset for constructing its visual-aid knowledge base, which limits its generalizability to domains lacking high-quality, well-annotated datasets. Expanding to domain-specific or low-resource scenarios may require significant manual effort to curate new knowledge bases. Additionally, while the approach effectively verifies object existence, attributes, and relations, it struggles with fine-grained semantic understanding, particularly in handling compositional queries, negations, and multi-entity interactions. For instance, it may fail to distinguish between "two women playing against each other" and simply "playing table tennis," highlighting a limited ability to process intricate logical dependencies in multimodal reasoning.