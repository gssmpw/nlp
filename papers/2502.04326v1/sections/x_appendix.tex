\section{Broader Impacts}
Our work on WorldSense has several potential positive impacts on society and AI development, while also presenting certain risks that warrant careful consideration. WorldSense contributes to advancing MLLMs' ability to understand and interact with the real world through multiple modalities. This progress could benefit various applications, including  assistive technologies, educational tools, human-AI interaction systems, safety systems, and so on. We also acknowledge potential risks and challenges. The development of more capable AI systems might raise privacy concerns. Advanced multimodal understanding capabilities could potentially be misused for surveillance or monitoring purposes. We believe that open discussion of these impacts is crucial for responsible development of MLLMs. 

\section{Ethics Statement}
Our research on WorldSense adheres to strict ethical principles and guidelines. We acknowledge several important ethical considerations: 
\begin{itemize}
    \item ~\textbf{Data Collection and Privacy.} All video content in WorldSense has been collected from publicly available sources with appropriate licensing agreements. We have con   ducted thorough reviews and implemented comprehensive data processing procedures to ensure privacy protection, including the removal of any personally identifiable information.
    \item ~\textbf{Potential Biases.} While acknowledging that inherent biases may exist in any dataset, we have undertaken systematic efforts to ensure diverse representation across our video content and question-answer pairs, encompassing various domains, cultures, and contexts. Nevertheless, we recognize that completely eliminating bias remains a significant challenge, and users should carefully consider these potential limitations when utilizing our dataset. 
    \item ~\textbf{Intended Use.} WorldSense is specifically designed to advance research in omnimodal real-world understanding. While we actively encourage the use of this benchmark for academic and research purposes, we strongly caution against any applications that could potentially result in harmful or discriminatory outcomes. Users are expected to adhere to ethical guidelines and responsible practices.
\end{itemize}


\section{License}
The WorldSense dataset is released under the CC BY-NC-SA 4.0 License. Authors bear all responsibility in case of violation of rights and confirmation of the
data license.


% \section{Implement Details}
% For open-source MLLMs, we strictly follow their official implementations and recommended preprocessing pipelines to ensure fair comparison. For GPT 4o and Claude 3.5 Sonnet, we sample 16 frames uniformly from each video, while for Gemini 1.5 Pro, we utilize the official API for raw video file uploads.

% \section{Evaluation Prompt}
% Following previous works~\cite{fu2024video, li2024mvbench}, we adopt the format of “whole video frames + whole subtitles/audios (optional) +
% question with prompt” as prompt. We show the evaluation prompt across three input configurations: video-only input, video with subtitles, and video with audio content as following.

% \begin{tcolorbox}[title=Evaluation Prompt]
%     \small 
%     \texttt{Carefully watch this video and pay attention to every detail. Based on your observations, select the best option that accurately addresses the question. \\ \\
%     These are the frames of a video. Select the best answer to the following multiple-choice question based on the video. Respond with only the letter (A, B, C, or D) of the correct option.}
%     \\ \\
%     \textbf{Question:} \{\} 
%     \\
%     \{Option1\} \\
%     \{Option2\} \\
%     \{Option3\} \\
%     \{Option4\} \\
%     \textbf{Answer:}\\
% \end{tcolorbox}

% \begin{tcolorbox}[title=Evaluation Prompt with Subtitles]
%     \small 
%     \texttt{Carefully watch this video and pay attention to every detail. Based on your observations, select the best option that accurately addresses the question. \\ \\
%     These are the frames of a video. This video's subtitles are listed below: \\ \\
%     \{subtitles\} \\ \\
%     Select the best answer to the following multiple-choice question based on the video. Respond with only the letter (A, B, C, or D) of the correct option.}
%     \\ \\
%     \textbf{Question:} \{\} 
%     \\
%     \{Option1\} \\
%     \{Option2\} \\
%     \{Option3\} \\
%     \{Option4\} \\
%     \textbf{Answer:}\\
% \end{tcolorbox}

% \begin{tcolorbox}[title=Evaluation Prompt with Audios]
%     \small 
%     \texttt{Carefully watch this video and pay attention to every detail. Based on your observations, select the best option that accurately addresses the question. \\ \\
%     These are the frames of a video and the corresponding audio. Select the best answer to the following multiple-choice question based on the video. Respond with only the letter (A, B, C, or D) of the correct option.}
%     \\ \\
%     \textbf{Question:} \{\} 
%     \\
%     \{Option1\} \\
%     \{Option2\} \\
%     \{Option3\} \\
%     \{Option4\} \\
%     \textbf{Answer:}\\
% \end{tcolorbox}


% \section{Datasheets}
% \subsection{Motivation}
% \begin{itemize}

% \item \textbf{For what purpose was the dataset created?}

% To evaluate MLLMs' capabilities in real-world omnimodal understanding. 

% \item \textbf{Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?}

% The authors of this paper.

% \item \textbf{Who funded the creation of the dataset?}

% Xiaohongshu Inc.

% \item \textbf{Any other comments?}

% No

% \end{itemize}

% \subsection{Composition}
% \begin{itemize}

% \item \textbf{What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)?} 

% Videos along with captions and question/answer pairs.

% \item \textbf{How many instances are there in total (of each type, if appropriate)?}

% WorldSense contains 3,172 question-answer pairs and contains 1,662 videos in total.

% \item \textbf{Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?}

% Videos of WorldSense are sampled from FineVideo and Music AVQA. All QA pairs are re-annotated manually.

% \item \textbf{What data does each instance consist of?} 

% Each instance contains one video with its corresponding audio, a question about the video content and the corresponding answer, the category of the video, the fine-grained video understanding capability examined by the question, and the class of audio content. Each instance also contain the auto-generated subtitles sourced from YouTube.

% \item \textbf{Is there a label or target associated with each instance?} 

% Yes. We provide the ground-truth answer for each question.

% \item \textbf{Is any information missing from individual instances?}

% N/A.

% \item \textbf{Are relationships between individual instances made explicit (e.g., users' movie ratings, social network links)?}

% N/A.

% \item \textbf{Are there recommended data splits (e.g., training, development/validation, testing)?} 

% No, WorldSense is designed for evaluation only.

% \item \textbf{Are there any errors, sources of noise, or redundancies in the dataset?}

% No.

% \item \textbf{Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)?} 

% WorldSense is self-contained.

% \item \textbf{Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctor -- patient confidentiality, data that includes the content of individuals' non-public communications)?} 

% N/A.

% \item \textbf{Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?}

% N/A.

% \end{itemize}

% \subsection{Collection Process}
% \begin{itemize}

% \item \textbf{How was the data associated with each instance acquired?} 

% See main paper for details.

% \item \textbf{What mechanisms or procedures were used to collect the data (e.g., hardware apparatuses or sensors, manual human curation, software programs, software APIs)?}

% Humans are required to propose a question and corresponding answer based on the video. MLLMs, such as Qwen2-VL, Video-LLaMA2 and OneLLM are utilized to perform quality control.

% \item \textbf{If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)?}

% Yes, we sample the videos from FineVideo and Music-AVQA. See main paper for details.

% \item \textbf{Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)?}

% The authors and contractors are involved in the data collection process and are paid a fair wage.

% \item \textbf{Over what timeframe was the data collected?} 

% The dataset is collected in 2024.

% \item \textbf{Were any ethical review processes conducted (e.g., by an institutional review board)?} 

% All videos in our benchmark are human-selected based on appropriate value propositions and undergo a second manual quality check to ensure there are no ethical violations.

% \end{itemize}

% \begin{itemize}


% \item \textbf{Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (e.g., websites)?}

% We obtained video data from FineVideo and Music-AVQA.

% \item \textbf{Were the individuals in question notified about the data collection?} 

% We didn’t collect the data from the individuals. The data was collected from public web sources instead.

% \item \textbf{Did the individuals in question consent to the collection and use of their data?} 

% N/A.

% \item \textbf{If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses?} 

% N/A.

% \item \textbf{Has an analysis of the potential impact of the dataset and its use on data subjects (e.g., a data protection impact analysis) been conducted?} 

% N/A.

% \item \textbf{Any other comments?}

% No.

% \end{itemize}

% \subsection{Preprocessing/cleaning/labeling}
% \begin{itemize}

% \item \textbf{Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)?} 

% We firstly select videos based on pre-designed categories, and then clip the video based on visual-audio correlation and dynamic scores.

% \item \textbf{Was the ``raw'' data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)?} 

% N/A.

% \item \textbf{Is the software that was used to preprocess/clean/label the data available?} 

% We use the open-source models.

% \item \textbf{Any other comments?}

% No.

% \end{itemize}

% \subsection{Uses}

% \begin{itemize}

% \item \textbf{Has the dataset been used for any tasks already?} 

% Yes. We have used the dataset to evaluate video question answering in real-world.

% \item \textbf{Is there a repository that links to any or all papers or systems that use the dataset?} 

% No. 

% \item \textbf{What (other) tasks could the dataset be used for?}

% It also can be used to evaluate the video understanding capability of VLMs.

% \item \textbf{Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?} 

% No.

% \item \textbf{Are there tasks for which the dataset should not be used?} 

% N/A.

% \item \textbf{Any other comments?}

% No.

% \end{itemize}

% \subsection{Distribution}

% \begin{itemize}

% \item \textbf{Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created?} 

% Yes, the dataset will be made publicly available.

% \item \textbf{How will the dataset will be distributed (e.g., tarball on website, API, GitHub)?} 

% We host it on the webpage, GitHub, and Huggingface.

% \item \textbf{When will the dataset be distributed?}

% It’s availale and open to the public now.

% \item \textbf{Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?} 

% We release our benchmark under CC BY-NC 4.0 license.

% \item \textbf{Have any third parties imposed IP-based or other restrictions on the data associated with the instances?} 

% No.

% \item \textbf{Do any export controls or other regulatory restrictions apply to the dataset or to individual instances?} 

% No.

% \item \textbf{Any other comments?}

% No.

% \end{itemize}

% \subsection{Maintenance}

% \begin{itemize}

% \item \textbf{Who will be supporting/hosting/maintaining the dataset?}

% The authors will be supporting/hosting/maintaining the dataset.

% \item \textbf{How can the owner/curator/manager of the dataset be contacted (e.g., email address)?}

% No.

% \item \textbf{Is there an erratum?} 

% Currently, we do not have an erratum. We will update if we find errors.

% \item \textbf{Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances)?} 

% Yes. We will make announcements on GitHub if there is any update.

% \item \textbf{If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (e.g., were the individuals in question told that their data would be retained for a fixed period of time and then deleted)?} 

% N/A.

% \item \textbf{Will older versions of the dataset continue to be supported/hosted/maintained?} 

% Yes.

% \item \textbf{If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?} 

% Yes. Contributors can post issues or submit pull requests on GitHub. We will review and verify
% contributions, and update the dataset if the contribution is useful.

% \item \textbf{Any other comments?}

% No.

% \end{itemize}
