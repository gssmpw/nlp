@INPROCEEDINGS{9597390,
	author={Suresh, Varsha and Ong, Desmond C.},
	booktitle={2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)}, 
	title={Using Knowledge-Embedded Attention to Augment Pre-trained Language Models for Fine-Grained Emotion Recognition}, 
	year={2021},
	volume={},
	number={},
	pages={1-8},
	keywords={Emotion recognition;Analytical models;Affective computing;Social networking (online);Computational modeling;Bit error rate;Psychology;Affective Computing;Facial Emotion Recognition;Transfer Learning},
	doi={10.1109/ACII52823.2021.9597390}}

@inproceedings{demszky-etal-2020-goemotions,
	title = "{G}o{E}motions: A Dataset of Fine-Grained Emotions",
	author = "Demszky, Dorottya  and
	Movshovitz-Attias, Dana  and
	Ko, Jeongwoo  and
	Cowen, Alan  and
	Nemade, Gaurav  and
	Ravi, Sujith",
	editor = "Jurafsky, Dan  and
	Chai, Joyce  and
	Schluter, Natalie  and
	Tetreault, Joel",
	booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
	month = jul,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.acl-main.372/",
	doi = "10.18653/v1/2020.acl-main.372",
	pages = "4040--4054",
	abstract = "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement."
}

@inproceedings{emoLLM,
	author = {Liu, Zhiwei and Yang, Kailai and Xie, Qianqian and Zhang, Tianlin and Ananiadou, Sophia},
	title = {EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis},
	year = {2024},
	isbn = {9798400704901},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3637528.3671552},
	doi = {10.1145/3637528.3671552},
	abstract = {Sentiment analysis and emotion detection are important research topics in natural language processing (NLP) and benefit many downstream tasks. With the widespread application of large language models (LLMs), researchers have started exploring the application of LLMs based on instruction-tuning in the field of sentiment analysis. However, these models only focus on single aspects of affective classification tasks (e.g. sentimental polarity or categorical emotions), and overlook the regression tasks (e.g. sentiment strength or emotion intensity), which leads to poor performance in downstream tasks. The main reason is the lack of comprehensive affective instruction tuning datasets and evaluation benchmarks, which cover various affective classification and regression tasks. Moreover, although emotional information is useful for downstream tasks, existing downstream datasets lack high-quality and comprehensive affective annotations. In this paper, we propose EmoLLMs, the first series of open-sourced instruction-following LLMs for comprehensive affective analysis based on fine-tuning various LLMs with instruction data, the first multi-task affective analysis instruction dataset (AAID) with 234K data samples based on 3 classification tasks and 2 regression tasks to support LLM instruction tuning, and a comprehensive affective evaluation benchmark (AEB) with 8 regression tasks and 6 classification tasks from various sources and domains to test the generalization ability of LLMs. We propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various affective instruction tasks. We compare our models with a variety of LLMs and sentiment analysis tools on AEB, where our models outperform all other open-sourced LLMs and sentiment analysis tools, and surpass ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve the ChatGPT-level and GPT-4-level generalization capabilities on affective analysis tasks, and demonstrates our models can be used as affective annotation tools. This project is available at https://github.com/lzw108/EmoLLMs/.},
	booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	pages = {5487â€“5496},
	numpages = {10},
	keywords = {affective evaluation benchmark, affective instruction dataset, emotion detection, large language models, sentiment analysis},
	location = {Barcelona, Spain},
	series = {KDD '24}
}

@misc{xenos2024vllmsprovidebettercontext,
	title={VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning}, 
	author={Alexandros Xenos and Niki Maria Foteinopoulou and Ioanna Ntinou and Ioannis Patras and Georgios Tzimiropoulos},
	year={2024},
	eprint={2404.07078},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2404.07078}, 
}

@misc{zhang2024dialoguellmcontextemotionknowledgetuned,
	title={DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models for Emotion Recognition in Conversations}, 
	author={Yazhou Zhang and Mengyao Wang and Youxi Wu and Prayag Tiwari and Qiuchi Li and Benyou Wang and Jing Qin},
	year={2024},
	eprint={2310.11374},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2310.11374}, 
}

