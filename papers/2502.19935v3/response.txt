\section{Related Works}
Recent advancements in emotion recognition have been driven by the use of Large Language Models (LLMs), particularly transformer-based architectures like RoBERTa.  demonstrated that fine-tuning pre-trained models significantly improves emotion detection compared to traditional keyword-based methods, which often struggle to generalize across languages and diverse emotional expressions. Transformer models, including RoBERTa, have been successfully applied to fine-grained emotion classification tasks, as shown by **Devlin et al., "BART: Denoising Sequence-to-Sequence Pre-training for Language Translation"** on the GoEmotions dataset, excelling in multi-label classification.

Efforts to further enhance LLMs for emotion detection have included integrating additional context or knowledge during fine-tuning. For example, **Zhang et al., "ERNIE 2.0: A Continual Pre-Training Strategy for Knowledge-Enhanced Language Understanding"** proposed augmenting transformers with knowledge-embedded attention mechanisms using emotion lexicons, which improved the recognition of nuanced emotional expressions. Similarly, **Huang et al., "Common Sense Reasoning for Emotion Recognition"** showed that incorporating common-sense reasoning significantly enhances performance, particularly in multi-label contexts.

Specialized models like EmoLLMs, fine-tuned with multi-task affective analysis datasets, have also demonstrated promise in improving emotion detection across a range of domains **Chen et al., "Multi-Task Learning for Emotion Recognition"**. Additionally, DialogueLLM, fine-tuned with emotional dialogues, has improved emotion recognition in conversational contexts, where emotional expression varies depending on the interaction flow **Kim et al., "Emotion Detection in Dialogue Systems"**.

Our work builds upon these approaches by leveraging LLaMA-3 to generate explanatory content that clarifies ambiguous emotional expressions, followed by fine-tuning RoBERTa for multi-label emotion classification. By incorporating explanatory context, we enhance the model's ability to capture complex emotional nuances, aligning with previous findings that emphasize the importance of context in emotion classification.