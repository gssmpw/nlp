\section{Literature Review}
\subsection{Track Detection Methods }
In this section, we focus on existing work on track detection methods for autonomous racing vehicles, which is a specialized application of segmentation in road scenes. We first review state-of-the-art segmentation methods, then segmentation in road scenes, and finally, track detection methods. 
% Our work frames track detection as a segmentation task, it is appropriate to compare both segmentation and track detection state of the art methods from the literature.

% \subsection{Segmentation Methods}

% Segmentation methods can be divided into general object segmentation and road-specific segmentation. General methods can be applied to various tasks, while road segmentation methods are specialized for track detection.

% \subsubsection{Segmentation for General Tasks}

\textit{Segmentation for General Tasks:} YOLOv8____ excels in both object detection and segmentation, combining CSPDarknet for feature extraction, PANet for feature aggregation, and a U-Net inspired decoder. With cIoU and DiceLoss, it achieves state-of-the-art segmentation. However, its  requirement of a large memory limits its deployment on resource-constrained devices. Hetnet____ integrates low-level features (e.g., intensity contrast) with high-level contextual information for mirror detection. SAM2-Unet____, based on the Segment Anything Model (SAM2)____, uses SAM2 as an encoder for U-Net architectures, showing strong segmentation performance with a Hiera backbone and U-shaped decoder. Reseg____ combines CNN-extracted local features with the long-range dependency modeling of Recurrent Neural Networks (RNNs) using the ReNet____ model for segmentation tasks. DeepLabv3____%, building on DeepLab v1 and v2____
, revisits atrous convolutions to manage the filter’s field-of-view and capture multi-scale context, improving segmentation across varying object sizes.

% \subsubsection{Segmentation for Road Scenes}

% The methods described below are tailored for segmentation tasks in road-related contexts. 
\textit{Segmentation for Road Scenes:} WeBACNN____ employs a weighted branch aggregation strategy to combine local and global features through context-aware aggregation. It frames track detection as a segmentation task. SegNet____ is designed for efficient pixel-wise semantic segmentation in road scenes. It consists of an encoder and decoder network, with the encoder architecture based on the 13 convolutional layers of the VGG16 network____, followed by a pixel-wise classification layer. Ultrafast____ is a lane detection method optimized for speed. Instead of pixel-wise segmentation, it identifies lane locations, making it faster compared to deep segmentation models. It also uses global features, providing a larger receptive field compared to traditional segmentation approaches.

\textit{Lane Detection Methods:} Automatic Lane Detection Methods in the literature can be broadly categorized into three types: parameter-based, anchor-based, and segmentation-based approaches. Parameter-based methods typically involve techniques such as polynomial curve fitting, as seen in ____, where the lane boundaries are modeled using mathematical equations. Anchor-based methods include models like Line-CNN____ and LaneAtt____, both of which rely on predefined lane line suggestions. Line-CNN utilizes a Convolutional Neural Network (CNN), while LaneAtt employs an attention mechanism to refine lane predictions. As mentioned above, racing scenarios may lack clearly defined lane boundaries, which is why these methods are ineffective in our case. Segmentation-based methods treat lane detection as a pixel-wise segmentation problem. For example, ____ integrates both high- and low-level features by incorporating the global context and refining it with low-level details. Similarly, ____ introduces a multi-level memory aggregation network, which enhances feature representation across different scales. ____ proposes the Global Association Network (GANet), where lane key points are directly regressed to their starting positions, and the Lane-aware Feature Aggregator improves local predictions by incorporating global context. 

\begin{figure*}[!htb]
% \setlength\tabcolsep{2pt}%%
% \centering
\begin{tabular}{
        >{\columncolor[HTML]{FFFFFF}}c  % Need to reset the first column to white
        c
        c
        c
        c
        c}

 \includegraphics[width=1.02in]{imgs/input_images_resized/front_right_frame_0221.jpg}
 &\includegraphics[width=1.02in]{imgs/input_images_resized/front_right_frame_0350.jpg}
 &\includegraphics[width=1.02in]{imgs/input_images_resized/front_left_frame_0411.jpg}
 &\includegraphics[width=1.02in]{imgs/input_images_resized/front_left_frame_0536.jpg}
 &\includegraphics[width=1.02in]{imgs/input_images_resized/front_right_frame_0012.jpg}
 &\includegraphics[width=1.02in]{imgs/input_images_resized/front_right_frame_0112.jpg} \\

 Normal &Dazzle Light & \parbox[t]{80pt}{Color Imbalance\\ - Green Hue} &Curved Road & \parbox[t]{80pt}{Color Imbalance\\ - Underexposed} &Blurry \\
\end{tabular}
\caption{Images depicting normal and challenging road scenarios—such as dazzle light, color imbalance, curved roads, and blurriness. \vspace{0pt}}
\label{fig:dataset_composition}
\end{figure*}


\subsection{Existing Datasets}
%Can include a column here that is usability, like image/video/rosbags?

%Table \ref{tab:dataset_comparisons} shows a comparison of our dataset and existing lane detection datasets. The last column Lane Markings is important because it can be shown that most models are heavily reliant on the bounding lines of the lane to perform lane detection. %Road courses do not have lane markings and those models would not be able to detect the lanes in these scenarios. As shown in the table, our dataset includes two camera angles, and the data collected is from high-speed racing scenarios. We also provide lane segmentation masks as annotations to detect the track. Most traffic datasets are curated using city traffic which has a completely different distribution and appearance than racing data. While RACECAR____ provides a racing dataset, the dataset is in rosbags which is not directly usable and contain no annotations. WeBACNN____ provides a racing dataset which also contains images that have the common problems of racing data, however, that dataset has been curated using animation racing videos, and generally model learning might not be transferable to a real life dataset. In this case, the angles of the mounted cameras also affect model performance and are different in a real life scenario as opposed to in simulation.  

Table \ref{tab:dataset_comparisons} shows a detailed comparison of existing lane detection datasets. In the last row, we also provide a comparison with the proposed RoRaTrack dataset. %The last column Lane Markings is important because it can be shown that most models are heavily reliant on the bounding lines of the lane to perform lane detection. %Road courses do not have lane markings and those models would not be able to detect the lanes in these scenarios. 

Most of the existing datasets are annotated specifically for lane detection, and only two are based on racing datasets. They often provide annotations of the bounding lines, as seen in TuSimple ____, CULane ____, LLAMAS ____, and VIL-100 ____, which makes them unsuitable for track detection algorithm development. While semantic segmentation or masks are available for lane identification for some datasets such as GTA5 ____, nuScenes ____, BDD100k ____, and a2d2 ____, the characteristics of these traffic datasets differ significantly from those of racing data, with all of them providing data from only the front dash camera. While SYNTHIA ____ lane detection dataset provides multi camera data, the data is synthetically generated, and not real.

While RACECAR ____ offers a racing dataset, it is stored in rosbags, which are not directly usable and lack annotations. WeBACNN ____ provides a racing dataset that includes images exhibiting the common challenges of racing data. However, this dataset was curated using animated racing videos, which may limit the transferability of model learning to real-world datasets. 

As the table indicates, there is currently no dataset that meets all the following criteria:
\begin{itemize}
    \item Built specifically for track detection in racing environments.
    \item Annotated with segmentation masks that clearly separate the road from the background.
    \item Has a multi-camera feed.
    \item Provides real-life data (non-synthetic).
\end{itemize}
In this paper, we address this vital gap in existing datasets, by providing a track detection dataset that includes two camera angles, with data collected from real-life high-speed racing scenarios, and provides lane segmentation masks as annotations.