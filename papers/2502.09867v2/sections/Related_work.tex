\section{RELATED WORK}
\subsection{Challenges of Design Space Exploration}
Exploring the design space is a key part of the creative process, helping designers consider different possibilities and find the best solution, with studies highlighting its role in problem-solving and innovation \cite{maher1996modeling, dorst2001creativity}. Design space exploration involves identifying and testing various alternatives across dimensions such as form, function, aesthetics, and usability \cite{yilmaz2015design}. However, the complexity of design problems often overwhelms the exploration process, particularly for novices who may lack experience in identifying relevant dimensions and exploring trade-offs between solutions \cite{march1991exploration}. While expert designers can rely on tacit knowledge and heuristics, novices often struggle to understand the structure of the design space and how to traverse it effectively \cite{ahmed2003understanding}. Research has shown that novices focus on surface-level features and have difficulty framing problems and generating alternatives \cite{goel1992structure, atman1999comparison}. This issue is exacerbated in complex domains like product design, where multiple conflicting constraints must be balanced \cite{lawson2006how}. The formative study later aims to deepen the understanding of novices' and experts' challenges and strategies in design space exploration, building on prior research to inform the development of more effective scaffolding tools.

\subsection{Tools for Visual Design Space Exploration}
Interactive tools have been proposed to support design exploration, with some success in guiding users through multi-dimensional trade-offs \cite{frich2021digital}. Visualization tools, for instance, allow designers to navigate and explore design dimensions \cite{buxton2007sketching, kang2021metamap, suh2024luminate}. This research investigates how we might support better design exploration by novices by helping them focus on deeper, rather than surface-level, features in a design space.

Visuals play a pivotal role in design space exploration by bridging the gap between abstract ideas and tangible solutions. Prototypes, such as sketches, diagrams, and digital models, help designers articulate and explore complex design problems \cite{buxton2007sketching}. In this context, visuals act as boundary objects—shared artifacts that help designers and AI establish common ground and converge on shared interpretations to explore the design space effectively \cite{star1989structure, fischer2001articulating}. Visuals allow designers to externalize their thought processes, making tacit knowledge more explicit and facilitating better communication and collaboration \cite{gero1990design, card1999readings}. For instance, early design sketches can capture a wide range of possibilities and support iterative exploration by providing a visual reference for evaluating different design alternatives \cite{gero1990design}. Conceptual diagrams and storyboards enable designers to organize and manipulate information, which can lead to deeper insights and more informed decisions \cite{stolterman2010concept}. The iterative nature of prototyping allows designers to explore various design dimensions, including functionality, usability, and aesthetics, and discover unforeseen issues and opportunities, which can be difficult to identify through conceptual thinking alone \cite{dow2010parallel}. 

Recent advancements in Generative AI (GenAI) have significantly expanded the possibilities for generating visual content in the design process. Tools like DALL-E \cite{ramesh2021zero, ramesh2022hierarchical, betker2023improving}, Stable Diffusion \cite{rombach2022high}, and MidJourney have demonstrated tremendous potential in producing high-quality images from textual descriptions, which can help accelerate design exploration and visualization \cite{goodfellow2014generative, dhariwal2021diffusion, ramesh2022hierarchical}. These tools can generate content across various modalities, including text \cite{ouyang2022training, bai2022constitutional, touvron2023llama1, touvron2023llama2}, images \cite{ramesh2021zero, rombach2022high, saharia2022photorealistic, betker2023improving, chang2023muse, liu2023generative, liu2024logomotion}, 3D models \cite{poole2022dreamfusion, nichol2022point, gao2022get3d, lin2023magic3d, shi2023zero123++, zhou2024gala3d, liu2024one, liu2024one++}, and video \cite{singer2022make, ho2022imagen, villegas2022phenaki, kondratyuk2023videopoet, bar2024lumiere}.

While these tools have enhanced creative autonomy, they still require users to construct precise prompts, which poses a challenge for novice designers. Additionally, in the field of Human-Computer Interaction (HCI) and graphics, image-image interaction techniques such as in-painting, point-based manipulation, and sketch-based control have been explored to enhance user control over AI-generated outputs without relying solely on textual inputs \cite{iizuka2017globally, pan2023drag, zhang2023adding}. These approaches allow designers to refine outputs visually, providing more flexible and interactive methods of engaging with AI-generated images. You might generate many poor alternatives that fall into "valleys" rather than "hills," similar to simulated annealing, where the goal is to avoid suboptimal solutions by exploring a broader solution space \cite{ngoon2019dark}. Therefore, despite these advances, novice designers still encounter difficulties refining prompts or controlling the generated outputs through purely visual methods, underscoring the need for better tools that integrate visual and text-based interactions to support more intuitive design exploration. By offering a broad overview and the option to focus on details, dimensional scaffolding helps designers avoid pitfalls and discover better solutions more easily.

\subsection{Prompt Engineering for Product Design}
Prompt engineering is a critical component of GenAI interactions, as it directly influences the relevance and quality of the generated outputs. While general-purpose AI systems have made significant strides in supporting prompt crafting, they often lack the specificity required for dimension-based design exploration, where users must balance multiple design aspects like geometry, style, and functionality. Novice designers are particularly disadvantaged in these tasks, as they struggle to manage these competing design considerations. Novices struggle to construct meaningful prompts and often lack the domain-specific knowledge required to generate effective outputs \cite{zamfirescu2023johnny, palani2021active, palani2024evolving}. Novices may also find themselves overwhelmed by the complexity of generative AI systems, leading to suboptimal or irrelevant results. Even expert designers face the problem of abstraction matching and expressing tacit knowledge in text-based prompts: when the user has a well-formed intent, how do they select an utterance from the near-infinite space of naturalistic utterances that they believe the system will reliably map to a satisfactory solution? This involves “matching” the utterance to the right level of “abstraction” by specifying the utterance at a level of granularity and detail that matches the set of actions the system can take and selecting suitable words and grammar \cite{liu2023wants}. A study of how professional designers craft prompts shows that they focus more on the strategies and practices involved in prompt crafting. In contrast, novice designers often struggle with surfacing key design dimensions and lack effective prompt writing practices \cite{chong2024prompting}. This gap in prompt crafting knowledge among novices presents a significant barrier to utilizing AI tools effectively.

Efforts in HCI have focused on developing UI interfaces for prompt engineering, which assist users in crafting more effective prompts by providing structured input and output fields \cite{choi2024creativeconnect, suh2024luminate, brade2023promptify} or augmenting search \cite{son2024genquery, chen2024memovis}. For example, systems like Jamplate structure AI prompts using familiar templates, helping users generate effective outputs without fully surfacing key design dimensions \cite{xu2024jamplate}. These tools simplify prompt creation but do not provide comprehensive guidance for dimension-based exploration. In addition to structured UIs, the concept of LLM chaining has been explored, where users iteratively refine prompts and outputs by chaining multiple steps together \cite{liu2022opal, di2022idea, wu2022promptchainer}. This multi-step approach allows for more complex interactions and refinement of generated content, supporting more sophisticated design workflows. However, even these advancements do not fully address the needs of novice designers, who require more comprehensive support for balancing and exploring multiple design dimensions simultaneously. This research examines how AI can help novice designers discover the correct language for their prompts by inspecting the curated images and surfacing the key product dimensions in a palette.
