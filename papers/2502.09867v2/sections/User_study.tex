\section{USER STUDY}
We conducted a user study to explore whether integrated dimensional scaffolding improves novice reasoning and aligns their design process with expert-level thinking. Focusing on chair design, a familiar object with rich stylistic variation, we examined how structured guidance influences participants' understanding of design dimensions, prompt construction, and final outputs. We compared our full tool with a baseline interface, offering dimensional scaffolding and structured prompts.

\subsection{Design Task}
We chose chair design for our user study because of its universal familiarity and design complexity. As an everyday object, it provides novices with a practical entry point into design processes. Chairs have long been a focus for designers and architects, especially during formative training, due to their rich history and evolution across various design movements. Their diverse design dimensions—ergonomics, aesthetics, and materials—make chairs a versatile subject that balances functional needs with creative expression \cite{fiell2005chairs}.

\subsection{Participants}

We recruited a group of 52 participants (19 to 31 years old; 36 females) in a hybrid format (5 remotely and 47 in person) from varying backgrounds and varying experience with design, large-language-model (LLM), and text-to-image-model (T2I). Regarding the respective experience level, ~\autoref{fig:user_study_participant_experience} provides a comprehensive overview.

\subsection{Baseline Condition} 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/user_study/user_study_baseline.png} 
    \caption{The baseline interface mimics a standard text-to-image setup, excluding scaffolding components.}
    \label{fig:user_study_baseline}
    \Description{The baseline interface features a text input box labeled "A dining chair that is cozy, modern and wooden" at the top. The right panel is an image gallery with a few generated images, and 2 of them are liked. Key scaffolding features such as the Dimension Palette and info button are absent.}
\end{figure}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/user_study/user_study_workflow.png}
    \caption{Workflow of the user study.}
    \label{fig:user_study_workflow}
    \Description{This figure illustrates the progression of the user study, which includes several steps such as the initial setup (1 minute), brief introduction (5 minutes), preliminary exploration (5 minutes), a main task (20 minutes), and final evaluation (25 minutes). Each arrow indicates the time allotted for that stage, helping participants understand the flow of activities.}
\end{figure*}

To assess the efficacy of dimensional scaffolding, our study compares the performance of \toolname{} with a baseline version of \toolname{}. The baseline condition removes key features such as the initial digestion of the design document, the info button on the Image Panel for extracting dimensions, and the Dimension Palette on the Design Panel, retaining only the Prompt Box, Like Button, and Favorite Folder to mimic a standard text-to-image interface (see ~\autoref{fig:user_study_baseline}). This baseline condition was chosen to isolate the specific impact of dimensional scaffolding by removing features that explicitly support design dimension extraction and organization. By mirroring a more straightforward, commonly used text-to-image interface, the baseline allows us to evaluate how these scaffolding features influence participants' ability to navigate and generate within the design space.


\subsection{Study Protocol}

Participants read the background of the user study, completed a screening survey, and reviewed the consent form. Upon consenting, participants were assigned to either the baseline group or the \toolname{} group, each receiving an introduction to their respective tools. Before beginning the tasks, a scenario overview was provided, followed by guidance on the tool features, as shown in \autoref{fig:user_study_workflow}.

\subsubsection{Consent Form (1 minute)}
Before starting this IRB-exempt experiment, participants reviewed a consent form. 

\subsubsection{Introduction to the Scenario and Familiarization with Tools (10 minutes)}
After the initial survey, participants in both groups received documents, including a client email with design requirements, a client persona with detailed information, sketches of dining chair concepts, and a mood board. Participants had 5 minutes to review these materials, which remained accessible throughout the design process. Baseline group participants received a tutorial on their baseline tool, while \toolname{} group participants were introduced to \toolname{} with additional tag selection and information reveal features. Both groups could access the tutorial slides during the design process to ensure familiarity with the tools. This introduction video stage also takes 5 minutes. 

\subsubsection{Design Exercise (20 minutes)}

Participants were then given 15 minutes, plus a 1-minute grace period, to generate images for a dining chair design. The baseline group used the tool with simple text prompts, while the \toolname{} group utilized the full tool's tag selection and information reveal features to craft prompts. Each prompt submission generated three images, and participants could view all generated images, selecting those they 'Liked' for the potential final design. An additional few minutes were provided after the exercise to finalize selections. After the time is up, they will have a few minutes to pick the final image from all the liked images.

\subsubsection{Post-Survey and Interview (20-30 minutes)}

After completing the tasks, participants filled out feedback surveys tailored to their group experience, assessing criteria for final design selection, alignment with client needs, and understanding of design dimensions. The surveys evaluated satisfaction with the tool's outputs, ease of converting ideas into prompts, and overall support in visualizing and refining concepts. They will elaborate on their Likert question response by thinking out aloud. The audio is automatically transcribed and used for later quantitative and qualitative analysis. This was followed by an in-depth interview exploring participants' experiences, design processes, tool effectiveness, and any challenges encountered. Feedback from surveys and interviews offered insights into tool interaction and highlighted areas for improvement.

\subsection{Data Collection}
We gathered data from three primary sources throughout the experiment. First, we collected the prompts used and images generated by each participant, along with the dimensions and tags used by each \toolname{} participant. We also tracked the time taken for each generation iteration. In terms of surveys, participants completed a screening survey that collected demographic and background information, including age, gender, language proficiency, and experience with design, LLMs, and T2I models. Following the experiment, participants responded to a post-experiment survey, which included Likert-scale ratings (from 1-7, Strongly Disagree to Strongly Agree) and open-ended questions covering a broad range of topics we aimed to explore.

In addition, we recorded audio transcriptions of the participants' verbal responses during the Likert scale ratings and collected elaborations through an open interview after the experiment. To evaluate the final images selected by the participants, we gathered ratings from six design experts (2-5 years of design experience), who rated novelty and alignment with the client's request on a scale from 1 to 7 (strongly dislike to strongly like).

One user from the baseline condition was excluded because a large portion of the design document was directly pasted into the prompt box, creating outliers when analyzing the prompt. This eliminated participant reduced the number of participants in the baseline group from 26 to 25.

\subsection{Data Analysis}
\subsubsection{Quantitative Data}
We compared the numerical difference between prompt length, diversity (number of design terms it contains), iteration time, and the quantitative part of the survey. Design term here is defined as a word or phrase that represents a specific aspect or dimension of a design, such as materials (e.g., "oak wood"), aesthetics (e.g., "minimalist"), functionality (e.g., "ergonomic"), or other domain-relevant attributes.

For design term extraction, we developed a customized Natural Language Processing (NLP) pipeline with four key components:

\begin{itemize}
    \item \textbf{Stopword Filtering:} Standard preprocessing (lowercasing, stopword removal, lemmatization) plus a custom list to filter non-design terms.
    \item \textbf{POS Tagging:} Extracted \textit{nouns} and \textit{adjectives} representing materials, aesthetics and key design attributes.
    \item \textbf{TF-IDF:} Ranked terms by importance, filtering out common words and highlighting key design terms.
    \item \textbf{Word Embeddings:} Used Word2Vec to ensure extracted terms aligned with a design-specific vocabulary.
\end{itemize}

We analyze the design terms from three sources: 1) the design document, 2) the prompts produced, and 3) the audio transcriptions.

Additionally, we used the ViT-B/32 CLIP model \cite{radford2021learning} to calculate both image and prompt semantic similarities for the Baseline and \toolname{} conditions across iterations. We also added Levenshtein Distances to measure the word edits in each iteration.

\subsubsection{Qualitative Data}
Two authors used Zoom's automatic transcription to transcribe and verify the recorded audio into text scripts for qualitative data, including think-aloud elaborations and open-ended user interviews. They then performed a thematic analysis of these transcripts. The insights extracted and user patterns are reported in the following result section. 

\subsection{Reliability Assessment}

We merged similar dimensions into broader meta-dimensional categories and then visualized these groupings in a bar chart and found that additional design dimensions emerged beyond the initial three (Aesthetic, Sustainability, and Functionality) that were derived from the design requirements document (see Appendix~\ref{appA1:prompts_doc_digest}). Without explicit prompt engineering, \toolname{} users organically discovered nuanced design dimensions, such as comfort, material, and durability mentioned in the design requirement, as shown in Appendix~\ref{appD:dd}. These results highlight \toolname{}'s ability to support multi-dimensional exploration and structured creativity, enabling participants to develop valid design dimensions even without professional guidance.

