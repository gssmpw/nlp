[
  {
    "index": 0,
    "papers": [
      {
        "key": "simonyan2014visualising",
        "author": "Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew",
        "title": "Visualising image classification models and saliency maps"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "selvaraju2017gradcam",
        "author": "Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv",
        "title": "Grad-CAM: Visual explanations from deep networks via gradient-based localization"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "springenberg2014striving",
        "author": "Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin",
        "title": "Striving for simplicity: The all convolutional net"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "shrikumar2017learning",
        "author": "Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul",
        "title": "Learning important features through propagating activation differences"
      },
      {
        "key": "dombrowski2019explanations",
        "author": "Dombrowski, Anne-Kathrin and Alber, Maximilian and Anders, Christopher J and Ackermann, Marcel and M{\\\"u}ller, Klaus-Robert and Kessel, Pan",
        "title": "Explanations can be manipulated and geometry is to blame"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sundararajan2017axiomatic",
        "author": "Mukund Sundararajan and Ankur Taly and Qiqi Yan",
        "title": "Axiomatic Attribution for Deep Networks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "miglani2020investigating",
        "author": "Miglani, Varun and Kokhlikyan, Narine and Alsallakh, Bilal and Miglani, Deepak",
        "title": "Investigating saturation effects in integrated gradients"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "erion2021improving",
        "author": "Erion, Gabriel and Janizek, Joseph D and Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In",
        "title": "Improving performance of deep learning models with axiomatic attribution priors and expected gradients"
      },
      {
        "key": "sturmfels2020visualizing",
        "author": "Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In",
        "title": "Visualizing the impact of feature attribution baselines"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kapishnikov2019xrai",
        "author": "Kapishnikov, Alex and Bolukbasi, Tolga and Vi{\\'e}gas, Fernanda and Wattenberg, Martin",
        "title": "XRAI: Better attributions through regions"
      },
      {
        "key": "smilkov2017smoothgrad",
        "author": "Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\\'e}gas, Fernanda and Wattenberg, Martin",
        "title": "SmoothGrad: Removing noise by adding noise"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "miglani2020investigating",
        "author": "Miglani, Varun and Kokhlikyan, Narine and Alsallakh, Bilal and Miglani, Deepak",
        "title": "Investigating saturation effects in integrated gradients"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kapishnikov2021guided",
        "author": "Kapishnikov, Alex and Venugopalan, Subhrajit and Avci, Bastien and Rigotti, Mattia and Zhang, Yang",
        "title": "Guided Integrated Gradients: An adaptive path method for removing noise"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "bereska2024mechanistic",
        "author": "Bereska, L and Gavves, E",
        "title": "Mechanistic Interpretability for AI Safety--A Review"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bereska2024mechanistic",
        "author": "Bereska, L and Gavves, E",
        "title": "Mechanistic Interpretability for AI Safety--A Review"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "he2024dictionary",
        "author": "He, Zhaozhi and Ge, Xinyuan and Tang, Qixun and others",
        "title": "Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "miller2024transformer",
        "author": "Miller, John and Chughtai, Bilal and Saunders, William",
        "title": "Transformer Circuit Faithfulness Metrics are not Robust"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2023interpretability",
        "author": "Wang, Kevin Ro and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob",
        "title": "Interpretability in the Wild: A Circuit for Indirect Object Identification in GPT-2 Small"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "hanna2024faith",
        "author": "Hanna, M. and Pezzelle, S. and Belinkov, Y.",
        "title": "Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "lieberum2023circuit",
        "author": "Lieberum, T. and Rahtz, M. and Kram{\\'a}r, J. and others",
        "title": "Does circuit analysis interpretability scale? Evidence from multiple choice capabilities in Chinchilla"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "conmy2023automated",
        "author": "Conmy, Arthur and Mavor-Parker, Alexa and Lynch, Andrew and others",
        "title": "Towards Automated Circuit Discovery for Mechanistic Interpretability"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "syed2023attribution",
        "author": "Syed, A. and Rager, C. and Conmy, A.",
        "title": "Attribution Patching Outperforms Automated Circuit Discovery"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "hanna2024faith",
        "author": "Hanna, M. and Pezzelle, S. and Belinkov, Y.",
        "title": "Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "hanna2024gpt2",
        "author": "Hanna, M. and Liu, O. and Variengien, A.",
        "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "cunningham2023sparse",
        "author": "Cunningham, H. and Ewart, A. and Riggs, L. and others",
        "title": "Sparse Autoencoders Find Highly Interpretable Features in Language Models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "marks2024sparse",
        "author": "Marks, S. and Rager, C. and Michaud, E. J. and others",
        "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "wu2024interpretability",
        "author": "Wu, Z. and Geiger, A. and Icard, T. and others",
        "title": "Interpretability at Scale: Identifying Causal Mechanisms in Alpaca"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "taori2023stanford",
        "author": "Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B.",
        "title": "Stanford Alpaca: An Instruction-Following LLaMA Model"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "geiger2024finding",
        "author": "Geiger, Atticus and Wu, Zhengxuan and Potts, Christopher and Icard, Thomas and Goodman, Noah",
        "title": "Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations"
      }
    ]
  }
]