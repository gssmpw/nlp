
@book{lehmann_theory_2006,
	location = {New York},
	title = {Theory of point estimation},
	publisher = {Springer Science \& Business Media},
	author = {Lehmann, Erich L and Casella, George},
	date = {2006},
}

@book{noauthor_theory_1998,
	location = {New York},
	title = {Theory of Point Estimation},
	rights = {http://www.springer.com/tdm},
	isbn = {978-0-387-98502-2},
	url = {http://link.springer.com/10.1007/b98854},
	series = {Springer Texts in Statistics},
	publisher = {Springer-Verlag},
	urldate = {2025-02-11},
	date = {1998},
	langid = {english},
	doi = {10.1007/b98854},
}

@online{noauthor_choice_nodate,
	title = {{ON} {THE} {CHOICE} {OF} m {IN} {THE} m {OUT} {OF} n {BOOTSTRAP} {AND} {CONFIDENCE} {BOUNDS} {FOR} {EXTREMA} on {JSTOR}},
	url = {https://www.jstor.org/stable/24308525?casa_token=m7BdhYWrGIQAAAAA%3AHhJDbTjinbtO00b-Eemh-YOFQIqDde7AobelFO5UK8iFbZsxb8YB5htxYKVcDSjwcDabgbQKSfJfiZ0aOQkAelOSD0JcwoYNPQd87bukH7fofl489A&seq=1},
	urldate = {2025-02-06},
}

@article{singh_asymptotic_1981,
	title = {On the Asymptotic Accuracy of Efron's Bootstrap},
	volume = {9},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-6/On-the-Asymptotic-Accuracy-of-Efrons-Bootstrap/10.1214/aos/1176345636.full},
	doi = {10.1214/aos/1176345636},
	abstract = {In the non-lattice case it is shown that the bootstrap approximation of the distribution of the standardized sample mean is asymptotically more accurate than approximation by the limiting normal distribution. The exact convergence rate of the bootstrap approximation of the distributions of sample quantiles is obtained. A few other convergence rates regarding the bootstrap method are also studied.},
	pages = {1187--1195},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Singh, Kesar},
	urldate = {2025-02-06},
	date = {1981-11},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G05, 62G15, Berry-Esseen bound, Edgeworth expansion, Law of iterated logarithm, Zero-one law, bootstrap, central limit theorem, lattice distributions},
}

@inproceedings{han_bootstrap_2016,
	title = {Bootstrap Model Aggregation for Distributed Statistical Learning},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/1ce927f875864094e3906a4a0b5ece68-Abstract.html},
	abstract = {In distributed, or privacy-preserving learning, we are often given a set of probabilistic models estimated from different local repositories, and asked to combine them into a single model that gives efficient statistical estimation. A simple method is to linearly average the parameters of the local models, which, however, tends to be degenerate or not applicable on non-convex models, or models with different parameter dimensions. One more practical strategy is to generate bootstrap samples from the local models, and then learn a joint model based on the combined bootstrap set. Unfortunately, the bootstrap procedure introduces additional noise and can significantly deteriorate the performance. In this work, we propose two variance reduction methods to correct the bootstrap noise, including a weighted M-estimator that is both statistically efficient and practically powerful. Both theoretical and empirical analysis is provided to demonstrate our methods.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Han, Jun and Liu, Qiang},
	urldate = {2025-02-06},
	date = {2016},
}

@article{modayil_towards_2021,
	title = {Towards Bootstrap Learning for Object Discovery},
	abstract = {We show how a robot can autonomously learn an ontology of objects to explain aspects of its sensor input from an unknown dynamic world. Unsupervised learning about objects is an important conceptual step in developmental learning, whereby the agent clusters observations across space and time to construct stable perceptual representations of objects. Our proposed unsupervised learning method uses the properties of allocentric occupancy grids to classify individual sensor readings as static or dynamic. Dynamic readings are clustered and the clusters are tracked over time to identify objects, separating them both from the background of the environment and from the noise of unexplainable sensor readings. Once trackable clusters of sensor readings (i.e., objects) have been identiﬁed, we build shape models where they are stable and consistent properties of these objects. However, the representation can tolerate, represent, and track amorphous objects as well as those that have well-deﬁned shape. In the end, the learned ontology makes it possible for the robot to describe a cluttered dynamic world with symbolic object descriptions along with a static environment model, both models grounded in sensory experience, and learned without external supervision.},
	author = {Modayil, Joseph and Kuipers, Benjamin},
	date = {2021},
	langid = {english},
}

@misc{nakkiran_deep_2021,
	title = {The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers},
	url = {http://arxiv.org/abs/2010.08127},
	doi = {10.48550/arXiv.2010.08127},
	shorttitle = {The Deep Bootstrap Framework},
	abstract = {We propose a new framework for reasoning about generalization in deep learning. The core idea is to couple the Real World, where optimizers take stochastic gradient steps on the empirical loss, to an Ideal World, where optimizers take steps on the population loss. This leads to an alternate decomposition of test error into: (1) the Ideal World test error plus (2) the gap between the two worlds. If the gap (2) is universally small, this reduces the problem of generalization in offline learning to the problem of optimization in online learning. We then give empirical evidence that this gap between worlds can be small in realistic deep learning settings, in particular supervised image classification. For example, {CNNs} generalize better than {MLPs} on image distributions in the Real World, but this is "because" they optimize faster on the population loss in the Ideal World. This suggests our framework is a useful tool for understanding generalization in deep learning, and lays a foundation for future research in the area.},
	number = {{arXiv}:2010.08127},
	publisher = {{arXiv}},
	author = {Nakkiran, Preetum and Neyshabur, Behnam and Sedghi, Hanie},
	urldate = {2025-02-06},
	date = {2021-02-19},
	eprinttype = {arxiv},
	eprint = {2010.08127 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory},
}

@inproceedings{fromont_model_2004,
	location = {Berlin, Heidelberg},
	title = {Model Selection by Bootstrap Penalization for Classification},
	isbn = {978-3-540-27819-1},
	doi = {10.1007/978-3-540-27819-1_20},
	abstract = {We consider the binary classification problem. Given an i.i.d. sample drawn from the distribution of an \${\textbackslash}mathcal\{X\}{\textbackslash}times{\textbackslash}\{0,1{\textbackslash}\}\$-valued random pair, we propose to estimate the so-called Bayes classifier by minimizing the sum of the empirical classification error and a penalty term based on Efron’s or i.i.d. weighted bootstrap samples of the data. We obtain exponential inequalities for such bootstrap type penalties, which allow us to derive non-asymptotic properties for the corresponding estimators. In particular, we prove that these estimators achieve the global minimax risk over sets of functions built from Vapnik-Chervonenkis classes. The obtained results generalize Koltchinskii [12] and Bartlett, Boucheron, Lugosi’s [2] ones for Rademacher penalties that can thus be seen as special examples of bootstrap type penalties.},
	pages = {285--299},
	booktitle = {Learning Theory},
	publisher = {Springer},
	author = {Fromont, Magalie},
	editor = {Shawe-Taylor, John and Singer, Yoram},
	date = {2004},
	langid = {english},
}

@book{freedman_statistics_2007,
	title = {Statistics: Fourth International Student Edition},
	isbn = {978-0-393-93043-6},
	shorttitle = {Statistics},
	abstract = {The Fourth Edition has been carefully revised and updated to reflect current data.},
	pagetotal = {6},
	publisher = {W.W. Norton \& Company},
	author = {Freedman, David and Pisani, Robert and Purves, Roger},
	date = {2007-02-20},
	langid = {english},
	note = {Google-Books-{ID}: {mviJQgAACAAJ}},
	keywords = {Mathematics / Probability \& Statistics / General},
}

@online{noauthor_statistics_nodate,
	title = {Statistics},
	url = {https://wwnorton.com/books/Statistics},
	abstract = {Renowned for its clear prose and no-nonsense  emphasis on core concepts, {\textless}em{\textgreater}Statistics{\textless}/em{\textgreater} covers  fundamentals using real examples to illustrate  the techniques., Statistics, David Freedman, Robert Pisani, Roger Purves, 9780393929720},
	urldate = {2025-02-06},
	langid = {english},
}

@book{ibragimov_heavy-tailed_2015,
	location = {Cham},
	title = {Heavy-Tailed Distributions and Robustness in Economics and Finance},
	volume = {214},
	rights = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-319-16876-0 978-3-319-16877-7},
	url = {https://link.springer.com/10.1007/978-3-319-16877-7},
	series = {Lecture Notes in Statistics},
	publisher = {Springer International Publishing},
	author = {Ibragimov, Marat and Ibragimov, Rustam and Walden, Johan},
	urldate = {2025-02-05},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-16877-7},
	keywords = {Diversification, Econometrics, Financial markets, Heavy tailed distribution, Insurance markets, Risk management},
}

@article{hall_error_1991,
	title = {On the error incurred using the bootstrap variance estimate when constructing confidence intervals for quantiles},
	volume = {38},
	issn = {0047-259X},
	url = {https://www.sciencedirect.com/science/article/pii/0047259X9190032W},
	doi = {10.1016/0047-259X(91)90032-W},
	abstract = {We show that the coverage error of confidence intervals and level error of hypothesis tests for population quantiles constructed using the bootstrap estimate of sample quantile variance is of precise order n−12 in both one- and two-sided cases. This contrasts markedly with more classical problems, where the error is of order n−12 in the one-sided case, but n−1 in the two-sided case, and results from an unusual feature of the Edgeworth expansion in that the leading term, of order n−12, is proportional to a polynomial containing both odd and even powers of the argument. Our results also show that for two-sided confidence intervals and hypothesis tests, and in large samples, the bootstrap variance estimate is inferior to the Siddiqui-Bloch-Gastwirth variance estimate provided the smoothing parameter in the latter is chosen to minimize coverage/level error.},
	pages = {70--81},
	number = {1},
	journaltitle = {Journal of Multivariate Analysis},
	shortjournal = {Journal of Multivariate Analysis},
	author = {Hall, Peter and Martin, Michael A},
	urldate = {2025-02-02},
	date = {1991-07-01},
	keywords = {Edgeworth expansion, Studentize, bootstrap, confidence interval, coverage error, hypothesis test, level error, quantile},
}

@article{hall_exact_1988,
	title = {Exact convergence rate of bootstrap quantile variance estimator},
	volume = {80},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/BF00356105},
	doi = {10.1007/BF00356105},
	abstract = {It is shown that the relative error of the bootstrap quantile variance estimator is of precise order n-1/4, when n denotes sample size. Likewise, the error of the bootstrap sparsity function estimator is of precise order n-1/4. Therefore as point estimators these estimators converge more slowly than the Bloch-Gastwirth estimator and kernel estimators, which typically have smaller error of order at most n-2/5.},
	pages = {261--268},
	number = {2},
	journaltitle = {Probability Theory and Related Fields},
	shortjournal = {Probab. Th. Rel. Fields},
	author = {Hall, Peter and Martin, Michael A.},
	urldate = {2025-02-02},
	date = {1988-12-01},
	langid = {english},
	keywords = {Convergence Rate, Mathematical Biology, Probability Theory, Relative Error, Stochastic Process},
}

@article{cheung_variance_2005,
	title = {Variance estimation for sample quantiles using them out ofn bootstrap},
	volume = {57},
	issn = {1572-9052},
	url = {https://doi.org/10.1007/BF02507026},
	doi = {10.1007/BF02507026},
	abstract = {We consider the problem of estimating the variance of a sample quantile calculated from a random sample of sizen. Ther-th-order kernel-smoothed bootstrap estimator is known to yield an impressively small relative error of {orderO}(n−r/(2r+1)). It nevertheless requires strong smoothness conditions on the underlying density function, and has a performance very sensitive to the precise choice of the bandwidth. The unsmoothed bootstrap has a poorer relative error of {orderO}(n−1/4), but works for less smooth density functions. We investigate a modified form of the bootstrap, known as them out ofn bootstrap, and show that it yields a relative error of order smaller {thanO}(n−1/4) under the same smoothness conditions required by the conventional unsmoothed bootstrap on the density function, provided that the bootstrap sample sizem is of an appropriate order. The estimator permits exact, simulation-free, computation and has accuracy fairly insensitive to the precise choice ofm. A simulation study is reported to provide empirical comparison of the various methods.},
	pages = {279--290},
	number = {2},
	journaltitle = {Annals of the Institute of Statistical Mathematics},
	shortjournal = {Ann Inst Stat Math},
	author = {Cheung, K. Y. and Lee, Stephen M. S.},
	urldate = {2025-02-02},
	date = {2005-06-01},
	langid = {english},
	keywords = {m out ofn bootstrap, quantile, smoothed bootstrap},
}

@article{kolassa_edgeworth_1990,
	title = {Edgeworth Series for Lattice Distributions},
	volume = {18},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-18/issue-2/Edgeworth-Series-for-Lattice-Distributions/10.1214/aos/1176347637.full},
	doi = {10.1214/aos/1176347637},
	abstract = {This paper investigates the use of Edgeworth expansions for approximating the distribution function of the normalized sum of \$n\$ independent and identically distributed lattice-valued random variables. We prove that the continuity-corrected Edgeworth series, using Sheppard-adjusted cumulants, is accurate to the same order in \$n\$ as the usual Edgeworth approximation for continuous random variables. Finally, as a partial justification of the Sheppard adjustments, it is shown that if a continuous random variable \$Y\$ is rounded into a discrete part \$D\$ and a truncation error \$U\$, such that \$Y = D + U\$, then under suitable limiting conditions the truncation error is approximately uniformly distributed and independent of \$Y\$, but not independent of \$D\$.},
	pages = {981--985},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Kolassa, John E. and {McCullagh}, Peter},
	urldate = {2025-01-30},
	date = {1990-06},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60F05, 62E20, Edgeworth series, Sheppard correction, cumulant, lattice distribution, rounding error},
}

@book{massart_concentration_2007,
	location = {Berlin, Heidelberg},
	title = {Concentration Inequalities and Model Selection},
	volume = {1896},
	isbn = {978-3-540-48497-4},
	url = {http://link.springer.com/10.1007/978-3-540-48503-2},
	series = {Lecture Notes in Mathematics},
	publisher = {Springer},
	author = {Massart, Pascal},
	editor = {Picard, Jean},
	urldate = {2023-11-07},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-48503-2},
	keywords = {62J0, Information, Maxima, adaptive estimation, concentration inequalities, empirical processes, information and communication, circuits, model selection, statistical learning},
}

@book{feller_introduction_1991,
	title = {An Introduction to Probability Theory and Its Applications, Volume 2},
	isbn = {978-0-471-25709-7},
	abstract = {The classic text for understanding complex statistical probability An Introduction to Probability Theory and Its Applications offers comprehensive explanations to complex statistical problems. Delving deep into densities and distributions while relating critical formulas, processes and approaches, this rigorous text provides a solid grounding in probability with practice problems throughout. Heavy on application without sacrificing theory, the discussion takes the time to explain difficult topics and how to use them. This new second edition includes new material related to the substitution of probabilistic arguments for combinatorial artifices as well as new sections on branching processes, Markov chains, and the {DeMoivre}-Laplace theorem.},
	pagetotal = {709},
	publisher = {John Wiley \& Sons},
	author = {Feller, William},
	date = {1991-01-08},
	langid = {english},
	note = {Google-Books-{ID}: {rxadEAAAQBAJ}},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@book{johnson_information_2004,
	title = {Information Theory and the Central Limit Theorem},
	isbn = {978-1-86094-537-3},
	abstract = {This book provides a comprehensive description of a new method of proving the central limit theorem, through the use of apparently unrelated results from information theory. It gives a basic introduction to the concepts of entropy and Fisher information, and collects together standard results concerning their behaviour. It brings together results from a number of research papers as well as unpublished material, showing how the techniques can give a unified view of limit theorems.},
	pagetotal = {230},
	publisher = {World Scientific},
	author = {Johnson, Oliver},
	date = {2004},
	langid = {english},
	note = {Google-Books-{ID}: r5XI8a0lYykC},
	keywords = {Computers / Information Theory, Mathematics / Probability \& Statistics / General},
}

@online{noauthor_information_nodate,
	title = {Information Theory and the Central Limit Theorem},
	url = {https://www.worldscientific.com/worldscibooks/10.1142/p341?srsltid=AfmBOorQXIvAgaYxI0sWLCT4qVEkfr_6pS1pGKXr5favASKKc6QBKjPl},
	abstract = {This book provides a comprehensive description of a new method of proving the central limit theorem, through the use of apparently unrelated results from information theory. It gives a basic introd...},
	urldate = {2025-01-23},
	langid = {english},
}

@book{bickel_mathematical_2015,
	location = {New York},
	title = {Mathematical Statistics: Basic Ideas and Selected Topics, Volumes I-{II} Package},
	isbn = {978-1-315-36926-6},
	shorttitle = {Mathematical Statistics},
	abstract = {This package includes both Mathematical Statistics: Basic Ideas and Selected Topics, Volume I, Second Edition, as well as Mathematical Statistics: Basic Ideas and Selected Topics, Volume {II}.
Volume I presents fundamental, classical statistical concepts at the doctorate level without using measure theory. It gives careful proofs of major results and explains how the theory sheds light on the properties of practical methods. Volume {II} covers a number of topics that are important in current measure theory and practice. It emphasizes nonparametric methods which can really only be implemented with modern computing power on large and complex data sets. In addition, the set includes a large number of problems with more difficult ones appearing with hints and partial solutions for the instructor.},
	pagetotal = {1066},
	publisher = {Chapman and Hall/{CRC}},
	author = {Bickel, Peter J. and Doksum, Kjell A.},
	date = {2015-12-07},
	doi = {10.1201/9781315369266},
}

@article{bahadur_note_1966,
	title = {A Note on Quantiles in Large Samples},
	volume = {37},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-37/issue-3/A-Note-on-Quantiles-in-Large-Samples/10.1214/aoms/1177699450.full},
	doi = {10.1214/aoms/1177699450},
	abstract = {The Annals of Mathematical Statistics},
	pages = {577--580},
	number = {3},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Bahadur, R. R.},
	urldate = {2025-01-20},
	date = {1966-06},
	note = {Publisher: Institute of Mathematical Statistics},
}

@book{serfling_approximation_2009,
	title = {Approximation Theorems of Mathematical Statistics},
	isbn = {978-0-470-31719-8},
	abstract = {Approximation Theorems of Mathematical Statistics  This convenient paperback edition makes a seminal text in statistics accessible to a new generation of students and practitioners. Approximation Theorems of Mathematical Statistics covers a broad range of limit theorems useful in mathematical statistics, along with methods of proof and techniques of application. The manipulation of "probability" theorems to obtain "statistical" theorems is emphasized. Besides a knowledge of these basic statistical theorems, this lucid introduction to the subject imparts an appreciation of the instrumental role of probability theory.  The book makes accessible to students and practicing professionals in statistics, general mathematics, operations research, and engineering the essentials of: * The tools and foundations that are basic to asymptotic theory in statistics * The asymptotics of statistics computed from a sample, including transformations of vectors of more basic statistics, with emphasis on asymptotic distribution theory and strong convergence * Important special classes of statistics, such as maximum likelihood estimates and other asymptotic efficient procedures; W. Hoeffding's U-statistics and R. von Mises's "differentiable statistical functions" * Statistics obtained as solutions of equations ("M-estimates"), linear functions of order statistics ("L-statistics"), and rank statistics ("R-statistics") * Use of influence curves * Approaches toward asymptotic relative efficiency of statistical test procedures},
	pagetotal = {399},
	publisher = {John Wiley \& Sons},
	author = {Serfling, Robert J.},
	date = {2009-09-25},
	langid = {english},
	note = {Google-Books-{ID}: {enUouJ}4EHzQC},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@book{noauthor_approximation_1980,
	title = {Approximation Theorems of Math},
	isbn = {978-0-470-31648-1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470316481.fmatter},
	abstract = {The prelims comprise: Title Copyright Preface Table of Contents},
	publisher = {John Wiley \& Sons, Ltd},
	urldate = {2025-01-08},
	date = {1980},
	langid = {english},
	doi = {10.1002/9780470316481.fmatter},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470316481.fmatter},
}

@thesis{sakov_using_1998,
	location = {United States -- California},
	title = {Using the m out of n bootstrap in hypothesis testing},
	rights = {Database copyright {ProQuest} {LLC}; {ProQuest} does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/304424705/abstract/8056E90502524943PQ/1},
	abstract = {Since its introduction the bootstrap has attracted a lot of attention. Theoretical considerations as well as simulation studies support the use of the bootstrap in many examples. The 'naive' nonparametric bootstrap draws bootstrap samples of size n from the empirical distribution function. Throughout the years, however, different examples in which the bootstrap fails were pointed out. Hypothesis testing is an example of a procedure for which using the nonparametric bootstrap generally fails. The reason is that calculations of the p-value or critical value use only the data and ignore the restrictions imposed by the null hypothesis. This usually results in a decision not to reject the null hypothesis even when the null hypothesis is wrong. This problem is well known. However, imposing the null is not a trivial matter in general. Recent literature proposes using bootstrap samples of size m = o(n) (known as the m out of n bootstrap, also referred to here as the m-bootstrap) when the bootstrap fails.
Our work has focused on the use of the m-bootstrap in hypothesis testing to estimate the critical value or the p-values. Using the m-bootstrap does not impose the null hypothesis, nevertheless, this approach seems to work. This might seem an easy way to bypass the need to impose the null hypothesis. However, there are at least two crucial questions: Is it important which value of m we use? and if yes, then how do we choose m?
This dissertation gives a partial solution to these two questions. As it turns out, the answers depend on whether or not an Edgeworth-type expansion for the distribution of the test statistic and its bootstrap version exist. If they do, we propose a method which uses the m-bootstrap together with regression and extrapolation to improve the zero-order accuracy of the m-bootstrap to a first order accuracy. With this correction the choice of m is not so critical. On the other hand, when expansions do not exist, the choice of m is important and we provide a data-dependent rule to pick m.},
	pagetotal = {120},
	institution = {University of California, Berkeley},
	type = {phdthesis},
	author = {Sakov, Anat},
	urldate = {2025-01-08},
	date = {1998},
	note = {{ISBN}: 9780591993288},
	keywords = {Biological sciences, Biostatistics, Bootstrap, Edgeworth expansion, Extrapolation, Hypothesis testing, Pure sciences, Statistics},
}

@report{shao_note_1988,
	title = {A Note on Bootstrap Variance Estimation},
	url = {https://www.stat.purdue.edu/docs/research/tech-reports/1988/tr88-29.pdf},
	number = {\#88-29},
	institution = {Purdue University},
	type = {Technical Report},
	author = {Shao, Jun},
	urldate = {2025-01-08},
	date = {1988},
}

@online{noauthor_httpswwwstatpurdueedudocsresearchtech-reports1988tr88-29pdf_nodate,
	title = {https://www.stat.purdue.edu/docs/research/tech-reports/1988/tr88-29.pdf},
	url = {https://www.stat.purdue.edu/docs/research/tech-reports/1988/tr88-29.pdf},
	urldate = {2025-01-08},
}

@book{dasgupta_asymptotic_2008,
	location = {New York, {NY}},
	title = {Asymptotic Theory of Statistics and Probability},
	rights = {http://www.springer.com/tdm},
	isbn = {978-0-387-75970-8 978-0-387-75971-5},
	url = {http://link.springer.com/10.1007/978-0-387-75971-5},
	series = {Springer Texts in Statistics},
	publisher = {Springer},
	author = {Dasgupta, Anirban},
	urldate = {2025-01-08},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-0-387-75971-5},
	keywords = {Median, Uniform integrability, Variance, best fit, central limit theorems, false discovery, likelihood, nonparametrics, resampling},
}

@article{ghosh_note_1984,
	title = {A Note on Bootstrapping the Sample Median},
	volume = {12},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-12/issue-3/A-Note-on-Bootstrapping-the-Sample-Median/10.1214/aos/1176346731.full},
	doi = {10.1214/aos/1176346731},
	abstract = {Efron (1979, 1982), in his treatment of the bootstrap, discusses its use for estimation of the asymptotic variance of the sample median, in the sampling situation of independent and identically distributed random variables with common distribution function \$F\$ having a positive derivative continuous in a neighborhood of the true median \${\textbackslash}mu\$. The natural conjecture that the bootstrap variance estimator converges almost surely to the asymptotic variance is shown by an example to be false unless a tail condition is imposed on \$F\$. We prove that such strong convergence does hold under the fairly nonrestrictive condition that \$E{\textbackslash}lbrack{\textbackslash}mid X{\textasciicircum}{\textbackslash}alpha{\textbackslash}rbrack {\textless} {\textbackslash}infty\$ for some \${\textbackslash}alpha {\textgreater} 0\$.},
	pages = {1130--1135},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Ghosh, Malay and Parr, William C. and Singh, Kesar and Babu, G. Jogesh},
	urldate = {2025-01-08},
	date = {1984-09},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62E20, 62G05, bootstrap, median, standard error estimation},
}

@book{chikuse_statistics_2003,
	location = {New York, {NY}},
	title = {Statistics on Special Manifolds},
	volume = {174},
	rights = {http://www.springer.com/tdm},
	isbn = {978-0-387-00160-9 978-0-387-21540-2},
	url = {http://link.springer.com/10.1007/978-0-387-21540-2},
	series = {Lecture Notes in Statistics},
	publisher = {Springer},
	author = {Chikuse, Yasuko},
	editorb = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
	editorbtype = {redactor},
	urldate = {2025-01-04},
	date = {2003},
	doi = {10.1007/978-0-387-21540-2},
	keywords = {correlation, manifold, mathematical statistics, statistical inference, statistics},
}

@misc{fan_typical_2022,
	title = {The Typical Behavior of Bandit Algorithms},
	url = {http://arxiv.org/abs/2210.05660},
	doi = {10.48550/arXiv.2210.05660},
	abstract = {We establish strong laws of large numbers and central limit theorems for the regret of two of the most popular bandit algorithms: Thompson sampling and {UCB}. Here, our characterizations of the regret distribution complement the characterizations of the tail of the regret distribution recently developed by Fan and Glynn (2021) ({arXiv}:2109.13595). The tail characterizations there are associated with atypical bandit behavior on trajectories where the optimal arm mean is under-estimated, leading to mis-identification of the optimal arm and large regret. In contrast, our {SLLN}'s and {CLT}'s here describe the typical behavior and fluctuation of regret on trajectories where the optimal arm mean is properly estimated. We find that Thompson sampling and {UCB} satisfy the same {SLLN} and {CLT}, with the asymptotics of both the {SLLN} and the (mean) centering sequence in the {CLT} matching the asymptotics of expected regret. Both the mean and variance in the {CLT} grow at \${\textbackslash}log(T)\$ rates with the time horizon \$T\$. Asymptotically as \$T {\textbackslash}to {\textbackslash}infty\$, the variability in the number of plays of each sub-optimal arm depends only on the rewards received for that arm, which indicates that each sub-optimal arm contributes independently to the overall {CLT} variance.},
	number = {{arXiv}:2210.05660},
	publisher = {{arXiv}},
	author = {Fan, Lin and Glynn, Peter W.},
	urldate = {2025-01-04},
	date = {2022-10-11},
	eprinttype = {arxiv},
	eprint = {2210.05660 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Statistics Theory},
}

@misc{fan_fragility_2024,
	title = {The Fragility of Optimized Bandit Algorithms},
	url = {http://arxiv.org/abs/2109.13595},
	doi = {10.48550/arXiv.2109.13595},
	abstract = {Much of the literature on optimal design of bandit algorithms is based on minimization of expected regret. It is well known that designs that are optimal over certain exponential families can achieve expected regret that grows logarithmically in the number of arm plays, at a rate governed by the Lai-Robbins lower bound. In this paper, we show that when one uses such optimized designs, the regret distribution of the associated algorithms necessarily has a very heavy tail, specifically, that of a truncated Cauchy distribution. Furthermore, for \$p{\textgreater}1\$, the \$p\$'th moment of the regret distribution grows much faster than poly-logarithmically, in particular as a power of the total number of arm plays. We show that optimized {UCB} bandit designs are also fragile in an additional sense, namely when the problem is even slightly mis-specified, the regret can grow much faster than the conventional theory suggests. Our arguments are based on standard change-of-measure ideas, and indicate that the most likely way that regret becomes larger than expected is when the optimal arm returns below-average rewards in the first few arm plays, thereby causing the algorithm to believe that the arm is sub-optimal. To alleviate the fragility issues exposed, we show that {UCB} algorithms can be modified so as to ensure a desired degree of robustness to mis-specification. In doing so, we also show a sharp trade-off between the amount of {UCB} exploration and the heaviness of the resulting regret distribution tail.},
	number = {{arXiv}:2109.13595},
	publisher = {{arXiv}},
	author = {Fan, Lin and Glynn, Peter W.},
	urldate = {2025-01-04},
	date = {2024-11-12},
	eprinttype = {arxiv},
	eprint = {2109.13595 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory},
}

@inproceedings{chen_assouad_2024,
	title = {Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability},
	url = {https://openreview.net/forum?id=hUGD1aNMrp},
	shorttitle = {Assouad, Fano, and Le Cam with Interaction},
	abstract = {We develop a unifying framework for information-theoretic lower bound in statistical estimation and interactive decision making. Classical lower bound techniques---such as Fano's inequality, Le Cam's method, and Assouad's lemma---are central to the study of minimax risk in statistical estimation, yet are insufficient to provide tight lower bounds for {\textbackslash}emph\{interactive decision making\} algorithms that collect data interactively (e.g., algorithms for bandits and reinforcement learning). Recent work of Foster et al. provides minimax lower bounds for interactive decision making using seemingly different analysis techniques from the classical methods. These results---which are proven using a complexity measure known as the {\textbackslash}emph\{Decision-Estimation Coefficient\} ({DEC})---capture difficulties unique to interactive learning, yet do not recover the tightest known lower bounds for passive estimation. We propose a unified view of these distinct methodologies through a new lower bound approach called {\textbackslash}emph\{interactive Fano method\}. As an application, we introduce a novel complexity measure, the {\textbackslash}emph\{Decision Dimension\}, which facilitates the new lower bounds for interactive decision making that extend the {DEC} methodology by incorporating the complexity of estimation. Using the Decision Dimension, we (i) provide a unified characterization of learnability for {\textbackslash}emph\{any\} structured bandit problem, (ii) close the remaining gap between the upper and lower bounds in Foster et al. (up to polynomial factors) for any interactive decision making problem in which the underlying model class is convex.},
	eventtitle = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
	author = {Chen, Fan and Foster, Dylan J. and Han, Yanjun and Qian, Jian and Rakhlin, Alexander and Xu, Yunbei},
	urldate = {2025-01-04},
	date = {2024-11-06},
	langid = {english},
}

@article{chen_assouad_nodate,
	title = {Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability},
	abstract = {We develop a unifying framework for information-theoretic lower bound in statistical estimation and interactive decision making. Classical lower bound techniques—such as Fano’s inequality, Le Cam’s method, and Assouad’s lemma—are central to the study of minimax risk in statistical estimation, yet are insufficient to provide tight lower bounds for interactive decision making algorithms that collect data interactively (e.g., algorithms for bandits and reinforcement learning). Recent work of Foster et al. [36, 38] provides minimax lower bounds for interactive decision making using seemingly different analysis techniques from the classical methods. These results—which are proven using a complexity measure known as the Decision-Estimation Coefficient ({DEC})—capture difficulties unique to interactive learning, yet do not recover the tightest known lower bounds for passive estimation. We propose a unified view of these distinct methodologies through a new lower bound approach called interactive Fano method. As an application, we introduce a novel complexity measure, the Decision Dimension, which facilitates the new lower bounds for interactive decision making that extend the {DEC} methodology by incorporating the complexity of estimation. Using the Decision Dimension, we (i) provide a unified characterization of learnability for any structured bandit problem, (ii) close the remaining gap between the upper and lower bounds in Foster et al. [36, 38] (up to polynomial factors) for any interactive decision making problem in which the underlying model class is convex.},
	author = {Chen, Fan and Qian, Jian and Foster, Dylan J and Han, Yanjun and Rakhlin, Alexander and Xu, Yunbei},
	langid = {english},
}

@book{cormen_introduction_2022,
	title = {Introduction to Algorithms, fourth edition},
	isbn = {978-0-262-36750-9},
	abstract = {A comprehensive update of the leading algorithms text, with new material on matchings in bipartite graphs, online algorithms, machine learning, and other topics.Some books on algorithms are rigorous but incomplete; others cover masses of material but lack rigor. Introduction to Algorithms uniquely combines rigor and comprehensiveness. It covers a broad range of algorithms in depth, yet makes their design and analysis accessible to all levels of readers, with self-contained chapters and algorithms in pseudocode. Since the publication of the first edition, Introduction to Algorithms has become the leading algorithms text in universities worldwide as well as the standard reference for professionals. This fourth edition has been updated throughout.New for the fourth edition New chapters on matchings in bipartite graphs, online algorithms, and machine {learningNew} material on topics including solving recurrence equations, hash tables, potential functions, and suffix arrays140 new exercises and 22 new {problemsReader} feedback–informed improvements to old {problemsClearer}, more personal, and gender-neutral writing {styleColor} added to improve visual {presentationNotes}, bibliography, and index updated to reflect developments in the {fieldWebsite} with new supplementary {materialWarning}: Avoid counterfeit copies of Introduction to Algorithms by buying only from reputable retailers. Counterfeit and pirated copies are incomplete and contain errors.},
	pagetotal = {1313},
	publisher = {{MIT} Press},
	author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
	date = {2022-04-05},
	langid = {english},
	note = {Google-Books-{ID}: {RSMuEAAAQBAJ}},
	keywords = {Computers / Computer Science, Computers / Programming / Algorithms, Computers / Reference},
}

@misc{sarig_local_2021,
	title = {Local limit theorems for inhomogeneous Markov chains},
	url = {http://arxiv.org/abs/2109.05560},
	doi = {10.48550/arXiv.2109.05560},
	abstract = {We prove the Local Limit Theorems for bounded additive functionals of uniformly elliptic inhomogeneous Markov arrays. As an application we obtain the precise asymptotics in the large deviation regime for bounded additive functionals of uniformly elliptic Markov chains. The proofs rely on new reduction theorems for Markov arrays.},
	number = {{arXiv}:2109.05560},
	publisher = {{arXiv}},
	author = {Sarig, Dmitry Dolgopyat ans Omri},
	urldate = {2024-12-15},
	date = {2021-09-12},
	eprinttype = {arxiv},
	eprint = {2109.05560 [math]},
	keywords = {Mathematics - Dynamical Systems, Mathematics - Probability},
}

@misc{dolgopyat_berry-esseen_2021,
	title = {A Berry-Esseen theorem and Edgeworth expansions for uniformly elliptic inhomogeneous Markov chains},
	url = {http://arxiv.org/abs/2111.03738},
	doi = {10.48550/arXiv.2111.03738},
	abstract = {We prove a Berry-Esseen theorem and Edgeworth expansions for partial sums of the form \$S\_N={\textbackslash}sum\_\{n=1\}{\textasciicircum}\{N\}f\_n(X\_n,X\_\{n+1\})\$, where \${\textbackslash}\{X\_n{\textbackslash}\}\$ is a uniformly elliptic inhomogeneous Markov chain and \${\textbackslash}\{f\_n{\textbackslash}\}\$ is a sequence of uniformly bounded functions. The Berry-Esseen theorem holds without additional assumptions, while expansions of order \$1\$ hold when \${\textbackslash}\{f\_n{\textbackslash}\}\$ is irreducible, which is an optimal condition. For higher order expansions, we then focus on two situations. The first is when the essential supremum of \$f\_n\$ is of order \$O(n{\textasciicircum}\{-{\textbackslash}be\})\$ for some \${\textbackslash}be{\textbackslash}in(0,1/2)\$. In this case it turns out that expansions of any order \$r{\textless}{\textbackslash}frac1\{1-2{\textbackslash}be\}\$ hold, and this condition is optimal. The second case is uniformly elliptic chains on a compact Riemannian manifold. When \$f\_n\$ are uniformly Lipschitz continuous we show that \$S\_N\$ admits expansions of all orders. When \$f\_n\$ are uniformly H{\textbackslash}"older continuous with some exponent \${\textbackslash}al{\textbackslash}in(0,1)\$, we show that \$S\_N\$ admits expansions of all orders \$r{\textless}{\textbackslash}frac\{1+{\textbackslash}al\}\{1-{\textbackslash}al\}\$. For H{\textbackslash}"older continues functions with \${\textbackslash}al{\textless}1\$ our results are new also for uniformly elliptic homogeneous Markov chains and a single functional \$f=f\_n\$. In fact, we show that the condition \$r{\textless}{\textbackslash}frac\{1+{\textbackslash}al\}\{1-{\textbackslash}al\}\$ is optimal even in the homogeneous case.},
	number = {{arXiv}:2111.03738},
	publisher = {{arXiv}},
	author = {Dolgopyat, Dmitry and Hafouta, Yeor},
	urldate = {2024-12-15},
	date = {2021-11-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2111.03738 [math]},
	keywords = {Mathematics - Probability},
}

@article{bobkov_fisher_2014,
	title = {Fisher information and the central limit theorem},
	volume = {159},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/s00440-013-0500-5},
	doi = {10.1007/s00440-013-0500-5},
	abstract = {An Edgeworth-type expansion is established for the relative Fisher information distance to the class of normal distributions of sums of i.i.d. random variables, satisfying moment conditions. The validity of the central limit theorem is studied via properties of the Fisher information along convolutions.},
	pages = {1--59},
	number = {1},
	journaltitle = {Probability Theory and Related Fields},
	shortjournal = {Probab. Theory Relat. Fields},
	author = {Bobkov, Sergey G. and Chistyakov, Gennadiy P. and Götze, Friedrich},
	urldate = {2024-11-14},
	date = {2014-06-01},
	langid = {english},
	keywords = {Central limit theorem, Edgeworth-type expansions, Entropic distance, Entropy, Primary 60E},
}

@misc{deb_trade-off_2024,
	title = {Trade-off Between Dependence and Complexity for Nonparametric Learning -- an Empirical Process Approach},
	url = {http://arxiv.org/abs/2401.08978},
	doi = {10.48550/arXiv.2401.08978},
	abstract = {Empirical process theory for i.i.d. observations has emerged as a ubiquitous tool for understanding the generalization properties of various statistical problems. However, in many applications where the data exhibit temporal dependencies (e.g., in finance, medical imaging, weather forecasting etc.), the corresponding empirical processes are much less understood. Motivated by this observation, we present a general bound on the expected supremum of empirical processes under standard \${\textbackslash}beta/{\textbackslash}rho\$-mixing assumptions. Unlike most prior work, our results cover both the long and the short-range regimes of dependence. Our main result shows that a non-trivial trade-off between the complexity of the underlying function class and the dependence among the observations characterizes the learning rate in a large class of nonparametric problems. This trade-off reveals a new phenomenon, namely that even under long-range dependence, it is possible to attain the same rates as in the i.i.d. setting, provided the underlying function class is complex enough. We demonstrate the practical implications of our findings by analyzing various statistical estimators in both fixed and growing dimensions. Our main examples include a comprehensive case study of generalization error bounds in nonparametric regression over smoothness classes in fixed as well as growing dimension using neural nets, shape-restricted multivariate convex regression, estimating the optimal transport (Wasserstein) distance between two probability distributions, and classification under the Mammen-Tsybakov margin condition -- all under appropriate mixing assumptions. In the process, we also develop bounds on \$L\_r\$ (\$1{\textbackslash}le r{\textbackslash}le 2\$)-localized empirical processes with dependent observations, which we then leverage to get faster rates for (a) tuning-free adaptation, and (b) set-structured learning problems.},
	number = {{arXiv}:2401.08978},
	publisher = {{arXiv}},
	author = {Deb, Nabarun and Mukherjee, Debarghya},
	urldate = {2024-11-06},
	date = {2024-01-17},
	eprinttype = {arxiv},
	eprint = {2401.08978},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory},
}

@article{bradley_examples_1993,
	title = {Some Examples of Mixing Random Fields},
	volume = {23},
	issn = {0035-7596},
	url = {https://projecteuclid.org/journals/rocky-mountain-journal-of-mathematics/volume-23/issue-2/Some-Examples-of-Mixing-Random-Fields/10.1216/rmjm/1181072573.full},
	doi = {10.1216/rmjm/1181072573},
	abstract = {Rocky Mountain Journal of Mathematics},
	pages = {495--519},
	number = {2},
	journaltitle = {Rocky Mountain Journal of Mathematics},
	author = {Bradley, Richard C.},
	urldate = {2024-11-06},
	date = {1993-06},
	note = {Publisher: Rocky Mountain Mathematics Consortium},
	keywords = {60G10, 60G60, Strictly stationary random field, Strong mixing},
}

@article{efron_defining_1975,
	title = {Defining the Curvature of a Statistical Problem (with Applications to Second Order Efficiency)},
	volume = {3},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-3/issue-6/Defining-the-Curvature-of-a-Statistical-Problem-with-Applications-to/10.1214/aos/1176343282.full},
	doi = {10.1214/aos/1176343282},
	abstract = {Statisticians know that one-parameter exponential families have very nice properties for estimation, testing, and other inference problems. Fundamentally this is because they can be considered to be "straight lines" through the space of all possible probability distributions on the sample space. We consider arbitrary one-parameter families \${\textbackslash}mathscr\{F\}\$ and try to quantify how nearly "exponential" they are. A quantity called "the statistical curvature of \${\textbackslash}mathscr\{F\}\$" is introduced. Statistical curvature is identically zero for exponential families, positive for nonexponential families. Our purpose is to show that families with small curvature enjoy the good properties of exponential families. Large curvature indicates a breakdown of these properties. Statistical curvature turns out to be closely related to Fisher and Rao's theory of second order efficiency.},
	pages = {1189--1242},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Efron, Bradley},
	urldate = {2024-10-31},
	date = {1975-11},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62B10, 62F20, Cramer-Rao lower bound, Fisher information, curvature, deficiency, exponential families, locally most powerful tests, maximum likelihood estimation, second order efficiency},
}

@article{chatterjee_sample_2018,
	title = {The sample size required in importance sampling},
	volume = {28},
	issn = {1050-5164, 2168-8737},
	url = {https://projecteuclid.org/journals/annals-of-applied-probability/volume-28/issue-2/The-sample-size-required-in-importance-sampling/10.1214/17-AAP1326.full},
	doi = {10.1214/17-AAP1326},
	abstract = {The goal of importance sampling is to estimate the expected value of a given function with respect to a probability measure \${\textbackslash}nu\$ using a random sample of size \$n\$ drawn from a different probability measure \${\textbackslash}mu\$. If the two measures \${\textbackslash}mu\$ and \${\textbackslash}nu\$ are nearly singular with respect to each other, which is often the case in practice, the sample size required for accurate estimation is large. In this article, it is shown that in a fairly general setting, a sample of size approximately \${\textbackslash}exp(D({\textbackslash}nu{\textbackslash}parallel{\textbackslash}mu))\$ is necessary and sufficient for accurate estimation by importance sampling, where \$D({\textbackslash}nu{\textbackslash}parallel{\textbackslash}mu)\$ is the Kullback–Leibler divergence of \${\textbackslash}mu\$ from \${\textbackslash}nu\$. In particular, the required sample size exhibits a kind of cut-off in the logarithmic scale. The theory is applied to obtain a general formula for the sample size required in importance sampling for one-parameter exponential families (Gibbs measures).},
	pages = {1099--1135},
	number = {2},
	journaltitle = {The Annals of Applied Probability},
	author = {Chatterjee, Sourav and Diaconis, Persi},
	urldate = {2024-10-28},
	date = {2018-04},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60F05, 65C05, 65C60, 82B80, Gibbs measure, Monte Carlo methods, importance sampling, phase transition},
}

@book{dembo_large_2010,
	location = {Berlin, Heidelberg},
	title = {Large Deviations Techniques and Applications},
	volume = {38},
	rights = {http://www.springer.com/tdm},
	isbn = {978-3-642-03310-0 978-3-642-03311-7},
	url = {http://link.springer.com/10.1007/978-3-642-03311-7},
	series = {Stochastic Modelling and Applied Probability},
	publisher = {Springer},
	author = {Dembo, Amir and Zeitouni, Ofer},
	urldate = {2024-10-26},
	date = {2010},
	doi = {10.1007/978-3-642-03311-7},
	keywords = {Area, {DEX}, {DNA}, Rang, Sharp, convergence, electrical engineering, field, large deviations, mathematics, mechanics, probability, statistics, techniques, tool},
}

@article{cook_typical_2024,
	title = {Typical structure of sparse exponential random graph models},
	volume = {34},
	issn = {1050-5164, 2168-8737},
	url = {https://projecteuclid.org/journals/annals-of-applied-probability/volume-34/issue-3/Typical-structure-of-sparse-exponential-random-graph-models/10.1214/23-AAP2025.full},
	doi = {10.1214/23-AAP2025},
	abstract = {We consider general exponential random graph models (ergms) where the sufficient statistics are functions of homomorphism counts for a fixed collection of simple graphs Fk. Whereas previous work has shown a degeneracy phenomenon in dense ergms, we show this can be cured by raising the sufficient statistics to a fractional power. We rigorously establish the naïve mean-field approximation for the partition function of the corresponding Gibbs measures, and in case of “ferromagnetic” models with vanishing edge density show that typical samples resemble a typical Erdős–Rényi graph with a planted clique and/or a planted complete bipartite graph of appropriate sizes. We establish such behavior also for the conditional structure of the Erdős–Rényi graph in the large deviations regime for excess Fk-homomorphism counts. These structural results are obtained by combining quantitative large deviation principles, established in previous works, with a novel stability form of a result of (Adv. Math. 319 (2017) 313–347) on the asymptotic solution for the associated entropic variational problem. A technical ingredient of independent interest is a stability form of Finner’s generalized Hölder inequality.},
	pages = {2885--2939},
	number = {3},
	journaltitle = {The Annals of Applied Probability},
	author = {Cook, Nicholas A. and Dembo, Amir},
	urldate = {2024-10-26},
	date = {2024-06},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {05C80, 60C05, 60F10, 82B26, Brascamp, Erdős, Gibbs measures, Lieb inequality, Rényi graphs, homomorphism counts, large deviations, upper tails, variational problems},
}

@misc{lopatto_quenched_2023,
	title = {Quenched large deviation principles for random projections of \${\textbackslash}ell\_p{\textasciicircum}n\$ balls},
	url = {http://arxiv.org/abs/2308.00649},
	abstract = {Let (kn)n∈N be a sequence of positive integers growing to inﬁnity at a sublinear rate, kn → ∞ and kn/n → 0 as n → ∞. Given a sequence of n-dimensional random vectors \{Y (n)\}n∈N belonging to a certain class, which includes uniform distributions on suitably scaled ℓnp -balls or ℓnp -spheres, p ≥ 2, and product distributions with sub-Gaussian marginals, we study the large deviations behavior of the corresponding sequence of kn-dimensional orthogonal projections n−1/2an,kn Y (n), where an,kn is an (n × kn)-dimensional projection matrix lying in the Stiefel manifold of orthonormal knframes in Rn. For almost every sequence of projection matrices, we establish a large deviation principle ({LDP}) for the corresponding sequence of projections, with a fairly explicit rate function that does not depend on the sequence of projection matrices. As corollaries, we also obtain quenched {LDPs} for sequences of ℓ2-norms and ℓ∞-norms of the coordinates of the projections. Past work on {LDPs} for projections with growing dimension has mainly focused on the annealed setting, where one also averages over the random projection matrix, chosen from the Haar measure, in which case the coordinates of the projection are exchangeable. The quenched setting lacks such symmetry properties, and gives rise to signiﬁcant new challenges in the setting of growing projection dimension. Along the way, we establish new Gaussian approximation results on the Stiefel manifold that may be of independent interest. Such {LDPs} are of relevance in asymptotic convex geometry, statistical physics and high-dimensional statistics.},
	number = {{arXiv}:2308.00649},
	publisher = {{arXiv}},
	author = {Lopatto, Patrick and Ramanan, Kavita and Xie, Xiaoyu},
	urldate = {2024-10-26},
	date = {2023-08-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2308.00649 [math]},
	keywords = {Mathematics - Functional Analysis, Mathematics - Probability},
}

@incollection{rajendran_concentration_2023,
	title = {Concentration of polynomial random matrices via Efron-Stein inequalities},
	url = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch138},
	series = {Proceedings},
	abstract = {Analyzing concentration of large random matrices is a common task in a wide variety of fields. Given independent random variables, several tools are available to bound the norms of random matrices whose entries are linear in the variables, such as the matrix-Bernstein inequality. However, for many recent applications, we need to bound the norms of random matrices whose entries are polynomials in the variables. Such matrices arise naturally in the analysis of spectral algorithms (e.g., Hopkins et al. [{STOC} 2016], Moitra and Wein [{STOC} 2019]), and in lower bounds for semidefinite programs based on the Sum-of-Squares ({SoS}) hierarchy (e.g. Barak et al. [{FOCS} 2016], Jones et al. [{FOCS} 2021]).
In this work, we present a general framework to obtain such bounds, based on the beautiful matrix Efron-Stein inequalities developed by Paulin, Mackey and Tropp [Annals of Probability 2016]. The Efron- Stein inequality bounds the norm of a random matrix by the norm of another potentially simpler (but still random) matrix. We view the latter matrix as arising by “differentiating” the starting matrix. By recursively differentiating, our framework reduces the main task to bounding the norms of far simpler matrices. These simpler matrices are in fact deterministic matrices in the case of Rademacher random variables and hence, bounding their norm is a far easier task. In general for non-Rademacher random variables, the task reduces to the much easier task of scalar concentration. Moreover, in the setting of polynomial matrices, our main result also generalizes the work of Paulin, Mackey and Tropp.
As applications of our basic framework, we recover known bounds in the literature, especially for simple “tensor networks” and “dense graph matrices”. As applications of our general framework, we derive bounds for “sparse graph matrices”. The sparse graph matrix bounds were obtained only recently by Jones et al. [{FOCS} 2021] using a nontrivial application of the trace power method, and was a core component in their work. We expect this framework will also be helpful for other applications involving concentration phenomena for nonlinear random matrices.},
	pages = {3614--3653},
	booktitle = {Proceedings of the 2023 Annual {ACM}-{SIAM} Symposium on Discrete Algorithms ({SODA})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Rajendran, Goutham and Tulsiani, Madhur},
	urldate = {2024-10-26},
	date = {2023-01},
	doi = {10.1137/1.9781611977554.ch138},
}

@incollection{boucheron_moment_2013,
	title = {Moment Inequalities},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0015},
	abstract = {This chapter is dedicated to upper bounds for higher centered moments of functions of independent random variables. The bounds derived here may be regarded as generalizations of the Efron–Stein inequality. Our approach is reminiscent to the entropy method that led us to “exponential Efron–Stein” inequalities. However, instead of using modified logarithmic Sobolev inequalities to obtain differential inequalities for the moment-generating function, here we use the Φ-Sobolev inequalities to obtain recursive inequalities for the moments. Solving these recursions leads us to the main results of this chapter.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0015},
}

@incollection{boucheron_variance_2013,
	title = {The Variance of Suprema of Empirical Processes},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0011},
	abstract = {In this chapter we focus our attention on the variance of the supremum of an empirical process. In this relatively simple, problem, we gain insight into some of the principal phenomena in a transparent way. In the two subsequent chapters technically more challenging exponential concentration inequalities are developed and some tools for bounding the expected value are surveyed. Our main tool is, once again, the Efron–Stein inequality. Various estimates of the variance are derived.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0011},
}

@incollection{boucheron_influences_2013,
	title = {Influences and Threshold Phenomena},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0009},
	abstract = {This chapter is devoted to the study of functions defined on the n-dimensional binary hypercube. We derive an improvement of the Efron–Stein inequality that implies some fundamental properties for influences of binary-valued functions. Properties of influences of monotone sets are studied. We study the evolution of the probability of monotone subsets.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0009},
}

@incollection{boucheron_index_2013,
	title = {Index},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.001.0001},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
}

@incollection{boucheron_references_2013,
	title = {References},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.001.0001},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
}

@incollection{boucheron_-entropies_2013,
	title = {Φ-Entropies},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0014},
	abstract = {The purpose of this chapter and the next is to introduce a methodology to bound higher moments of functions of independent random variables. This method, though more technical than the entropy method, is at least as powerful and works for random variables that are not necessarily exponentially integrable. Our approach is based on a generalization of the entropy method. The basic pillar of the method is the introduction of certain convex functionals of random variables that we call Φ-entropies.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0014},
}

@incollection{boucheron_expected_2013,
	title = {The Expected Value of Suprema of Empirical Processes},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0013},
	abstract = {Bounding the expected value of the supremum of an empirical process is a central object of the study of empirical processes and the purpose of this chapter is to present elements of this rich theory. We discuss the perhaps most important basic technique for obtaining sharp upper bounds for suprema of empirical processes, the so-called chaining argument. We investigate various scenarios and prove bounds for {VC} classes Rudelson’s inequality, the Klartag–Mendeslon theorem, and introduce the techniques of peeling and re-weighting.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0013},
}

@incollection{boucheron_suprema_2013,
	title = {Suprema of Empirical Processes: Exponential Inequalities},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0012},
	shorttitle = {Suprema of Empirical Processes},
	abstract = {In this chapter we continue the study of suprema of empirical processes started in Chapter 11 and we prove exponential concentration inequalities. Our main tool is the entropy method introduced in Chapter 6. The main result in this chapter is Bousquet’s inequality, a Bennett-type inequality for suprema of centered empirical processes.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0012},
}

@incollection{boucheron_isoperimetry_2013,
	title = {Isoperimetry on the Hypercube and Gaussian Spaces},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0010},
	abstract = {The purpose of this chapter is to explore further the rich connection between concentration and isoperimetry on the n-dimensional binary cube and also on Rn, equipped by the canonical Gaussian measure. We introduce an alternative way of measuring the size of the boundary of a subset of the binary hypercube and prove a corresponding isoperimetric inequality. This isoperimetric result is the consequence of Bobkov’s inequality. One of the most important corollaries of Bobkov’s inequality is the Gaussian isoperimetric theorem. We also derive some further results on threshold widths for certain monotone sets.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0010},
}

@incollection{boucheron_concentration_2013,
	title = {Concentration and Isoperimetry},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0007},
	abstract = {In this chapter we discuss some aspects of the rich relationship between isoperimetric problems and concentration inequalities. We establish a connection between isoperimetric inequalities in general metric spaces and concentration of Lipschitz functions. We present a powerful concentration inequality, known as Talagrand’s convex distance inequality.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0007},
}

@incollection{boucheron_entropy_2013,
	title = {The Entropy Method},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0006},
	abstract = {The purpose of this chapter is to present an attempt to generalize the methodology based on logarithmic Sobolev inequalities that allows one to prove exponential concentration bounds that hold for functions of arbitrary independent random variables.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0006},
}

@incollection{boucheron_logarithmic_2013,
	title = {Logarithmic Sobolev Inequalities},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0005},
	abstract = {In this chapter we prove a few inequalities known as logarithmic Sobolev inequalities and present Herbst’s argument to prove concentration inequalities. We also establish a collection of closely related results, starting from the so-called Bonami–Beckner inequality. We close this chapter by invoking Gaussian hypercontractive inequalities to prove a challenging tail bound for the largest eigenvalue of random matrices from the Gaussian unitary ensemble.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0005},
}

@incollection{boucheron_basic_2013,
	title = {Basic Information Inequalities},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0004},
	abstract = {This chapter introduces a series of inequalities which have their origin in different fields, such as geometry, combinatorics, and information theory. These elementary results, which, for historical reasons, we call information inequalities, will be the basis of exponential concentration inequalities for functions of various independent random variables.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0004},
}

@incollection{boucheron_bounding_2013,
	title = {Bounding the Variance},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0003},
	abstract = {The purpose of this chapter is to introduce a simple, yet powerful, inequality which offers a useful upper bound for the variance of a general function of several independent random variables. The basic result – the Efron–Stein inequality – provides a bound in terms of “local” variations of the function f. This inequality is a prologue to the numerous results presented in this book in which concentration properties may be controlled by studying the local behavior of the function at hand. A large part of this chapter is devoted to applications of the Efron–Stein inequality for bounding the variance of complex functions of independent random variables.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0003},
}

@incollection{boucheron_basic_2013-1,
	title = {Basic Inequalities},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0002},
	abstract = {In this chapter we first review some elementary facts about tail probabilities. Then, we describe the so-called Cramér–Chernoff method. We single out two types of tail behaviors, sub-Gaussian and sub-gamma random variables. A simple useful inequality is presented for bounding the expected maximum of random variables. Hoeffding’s inequality, Bennett’s inequality and Bernstein’s inequality are shown and proved. We describe the Johnson–Lindenstrauss lemma as an interesting application of concentration of sums of independent random variables.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0002},
}

@incollection{boucheron_introduction_2013,
	title = {Introduction},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0001},
	abstract = {In this introductory chapter we briefly review the history of the subject and outline the contents, as an appetizer for the rest of the book.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0001},
}

@incollection{boucheron_foreword_2013,
	title = {Foreword},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.002.0004},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.002.0004},
}

@incollection{boucheron_transportation_2013,
	title = {The Transportation Method},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.003.0008},
	abstract = {In this chapter we present the main ideas behind a different way of proving concentration inequalities that we call the transportation method. It is based on a beautiful idea of coupling and provides a simple and elegant approach that leads to concentration inequalities.},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.003.0008},
}

@incollection{boucheron_copyright_2013,
	title = {Copyright Page},
	isbn = {978-0-19-953525-5},
	url = {https://doi.org/10.1093/acprof:oso/9780199535255.002.0003},
	pages = {0},
	booktitle = {Concentration Inequalities: A Nonasymptotic Theory of Independence},
	publisher = {Oxford University Press},
	editor = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	urldate = {2024-10-26},
	date = {2013-02-07},
	doi = {10.1093/acprof:oso/9780199535255.002.0003},
}

@article{paulin_efronstein_2016,
	title = {Efron–Stein inequalities for random matrices},
	volume = {44},
	issn = {0091-1798, 2168-894X},
	url = {https://projecteuclid.org/journals/annals-of-probability/volume-44/issue-5/EfronStein-inequalities-for-random-matrices/10.1214/15-AOP1054.full},
	doi = {10.1214/15-AOP1054},
	abstract = {This paper establishes new concentration inequalities for random matrices constructed from independent random variables. These results are analogous with the generalized Efron–Stein inequalities developed by Boucheron et al. The proofs rely on the method of exchangeable pairs.},
	pages = {3431--3473},
	number = {5},
	journaltitle = {The Annals of Probability},
	author = {Paulin, Daniel and Mackey, Lester and Tropp, Joel A.},
	urldate = {2024-10-26},
	date = {2016-09},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60B20, 60E15, 60F10, 60G09, Concentration inequalities, Efron–Stein inequality, Exchangeable pairs, Random matrix, Stein’s method, bounded differences, coupling, noncommutative, trace inequality},
}

@collection{bansal_proceedings_2023,
	location = {Philadelphia, {PA}},
	title = {Proceedings of the 2023 Annual {ACM}-{SIAM} Symposium on Discrete Algorithms ({SODA})},
	isbn = {978-1-61197-755-4},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611977554},
	abstract = {Analyzing concentration of large random matrices is a common task in a wide variety of fields. Given independent random variables, several tools are available to bound the norms of random matrices whose entries are linear in the variables, such as the matrix-Bernstein inequality. However, for many recent applications, we need to bound the norms of random matrices whose entries are polynomials in the variables. Such matrices arise naturally in the analysis of spectral algorithms (e.g., Hopkins et al. [{STOC} 2016], Moitra and Wein [{STOC} 2019]), and in lower bounds for semidefinite programs based on the Sum-of-Squares ({SoS}) hierarchy (e.g. Barak et al. [{FOCS} 2016], Jones et al. [{FOCS} 2021]).},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Bansal, Nikhil and Nagarajan, Viswanath},
	urldate = {2024-10-26},
	date = {2023-01},
	langid = {english},
	doi = {10.1137/1.9781611977554},
}

@inproceedings{aden-ali_optimal_2023,
	title = {Optimal {PAC} Bounds without Uniform Convergence},
	isbn = {9798350318944},
	url = {https://www.computer.org/csdl/proceedings-article/focs/2023/189400b203/1T971Rnelzi},
	doi = {10.1109/FOCS57990.2023.00071},
	abstract = {In statistical learning theory, determining the sample complexity of realizable binary classification for {VC} classes was a long-standing open problem. The results of Simon [1] and Hanneke [2] established sharp upper bounds in this setting. However, the reliance of their argument on the uniform convergence principle limits its applicability to more general learning settings such as multiclass classification. In this paper, we address this issue by providing optimal high probability risk bounds through a framework that surpasses the limitations of uniform convergence arguments.Our framework converts the leave-one-out error of permutation invariant predictors into high probability risk bounds. As an application, by adapting the one-inclusion graph algorithm of Haussler, Littlestone, and Warmuth [3], we propose an algorithm that achieves an optimal {PAC} bound for binary classification. Specifically, our result shows that certain aggregations of one-inclusion graph algorithms are optimal, addressing a variant of a classic question posed by Warmuth [4].We further instantiate our framework in three settings where uniform convergence is provably suboptimal. For multiclass classification, we prove an optimal risk bound that scales with the one-inclusion hypergraph density of the class, addressing the suboptimality of the analysis of Daniely and Shalev-Shwartz [5]. For partial hypothesis classification, we determine the optimal sample complexity bound, resolving a question posed by Alon, Hanneke, Holzman, and Moran [6]. For realizable bounded regression with absolute loss, we derive an optimal risk bound that relies on a modified version of the scale-sensitive dimension, refining the results of Bartlett and Long [7]. Our rates surpass standard uniform convergence-based results due to the smaller complexity measure in our risk bound.},
	eventtitle = {2023 {IEEE} 64th Annual Symposium on Foundations of Computer Science ({FOCS})},
	pages = {1203--1223},
	publisher = {{IEEE} Computer Society},
	author = {Aden-Ali, Ishaq and Cherapanamjeri, Yeshwanth and Shetty, Abhishek and Zhivotovskiy, Nikita},
	urldate = {2024-10-26},
	date = {2023-11-01},
}

@article{baraud_new_2017,
	title = {A new method for estimation and model selection:\$\${\textbackslash}rho \$\$-estimation},
	volume = {207},
	issn = {1432-1297},
	url = {https://doi.org/10.1007/s00222-016-0673-5},
	doi = {10.1007/s00222-016-0673-5},
	shorttitle = {A new method for estimation and model selection},
	abstract = {The aim of this paper is to present a new estimation procedure that can be applied in various statistical frameworks including density and regression and which leads to both robust and optimal (or nearly optimal) estimators. In density estimation, they asymptotically coincide with the celebrated maximum likelihood estimators at least when the statistical model is regular enough and contains the true density to estimate. For very general models of densities, including non-compact ones, these estimators are robust with respect to the Hellinger distance and converge at optimal rate (up to a possible logarithmic factor) in all cases we know. In the regression setting, our approach improves upon the classical least squares in many respects. In simple linear regression for example, it provides an estimation of the coefficients that are both robust to outliers and simultaneously rate-optimal (or nearly rate-optimal) for a large class of error distributions including Gaussian, Laplace, Cauchy and uniform among others.},
	pages = {425--517},
	number = {2},
	journaltitle = {Inventiones mathematicae},
	shortjournal = {Invent. math.},
	author = {Baraud, Y. and Birgé, L. and Sart, M.},
	urldate = {2024-10-25},
	date = {2017-02-01},
	langid = {english},
}

@article{baraud_rho-estimators_2018,
	title = {Rho-estimators revisited: General theory and applications},
	volume = {46},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-46/issue-6B/Rho-estimators-revisited-General-theory-and-applications/10.1214/17-AOS1675.full},
	doi = {10.1214/17-AOS1675},
	shorttitle = {Rho-estimators revisited},
	abstract = {Following Baraud, Birgé and Sart [Invent. Math. 207 (2017) 425–517], we pursue our attempt to design a robust universal estimator of the joint distribution of \$n\$ independent (but not necessarily i.i.d.) observations for an Hellinger-type loss. Given such observations with an unknown joint distribution \${\textbackslash}mathbf\{P\}\$ and a dominated model \${\textbackslash}mathscr\{Q\}\$ for \${\textbackslash}mathbf\{P\}\$, we build an estimator \${\textbackslash}widehat\{{\textbackslash}mathbf\{P\}\}\$ based on \${\textbackslash}mathscr\{Q\}\$ (a \${\textbackslash}rho\$-estimator) and measure its risk by an Hellinger-type distance. When \${\textbackslash}mathbf\{P\}\$ does belong to the model, this risk is bounded by some quantity which relies on the local complexity of the model in a vicinity of \${\textbackslash}mathbf\{P\}\$. In most situations, this bound corresponds to the minimax risk over the model (up to a possible logarithmic factor). When \${\textbackslash}mathbf\{P\}\$ does not belong to the model, its risk involves an additional bias term proportional to the distance between \${\textbackslash}mathbf\{P\}\$ and \${\textbackslash}mathscr\{Q\}\$, whatever the true distribution \${\textbackslash}mathbf\{P\}\$. From this point of view, this new version of \${\textbackslash}rho\$-estimators improves upon the previous one described in Baraud, Birgé and Sart [Invent. Math. 207 (2017) 425–517] which required that \${\textbackslash}mathbf\{P\}\$ be absolutely continuous with respect to some known reference measure. Further additional improvements have been brought as compared to the former construction. In particular, it provides a very general treatment of the regression framework with random design as well as a computationally tractable procedure for aggregating estimators. We also give some conditions for the maximum likelihood estimator to be a \${\textbackslash}rho\$-estimator. Finally, we consider the situation where the statistician has at her or his disposal many different models and we build a penalized version of the \${\textbackslash}rho\$-estimator for model selection and adaptation purposes. In the regression setting, this penalized estimator not only allows one to estimate the regression function but also the distribution of the errors.},
	pages = {3767--3804},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Baraud, Yannick and Birgé, Lucien},
	urldate = {2024-10-25},
	date = {2018-12},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {\${\textbackslash}rho\$-estimation, 62C20, 62F99, 62G05, 62G07, 62G08, 62G35, Density estimation, {VC}-classes, maximum likelihood estimators, metric dimension, regression with random design, robust estimation, statistical models},
}

@article{barron_risk_1999,
	title = {Risk bounds for model selection via penalization},
	volume = {113},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/s004400050210},
	doi = {10.1007/s004400050210},
	abstract = {Performance bounds for criteria for model selection are developed using recent theory for sieves. The model selection criteria are based on an empirical loss or contrast function with an added penalty term motivated by empirical process theory and roughly proportional to the number of parameters needed to describe the model divided by the number of observations. Most of our examples involve density or regression estimation settings and we focus on the problem of estimating the unknown density or regression function. We show that the quadratic risk of the minimum penalized empirical contrast estimator is bounded by an index of the accuracy of the sieve. This accuracy index quantifies the trade-off among the candidate models between the approximation error and parameter dimension relative to sample size.},
	pages = {301--413},
	number = {3},
	journaltitle = {Probability Theory and Related Fields},
	shortjournal = {Probab. Theory Relat. Fields},
	author = {Barron, Andrew and Birgé, Lucien and Massart, Pascal},
	urldate = {2023-07-03},
	date = {1999-02-01},
	langid = {english},
	keywords = {Key words and phrases: Penalization – Model selection – Adaptive estimation – Empirical processes – Sieves – Minimum contrast estimators, Mathematics subject classifications (1991): Primary 62G05, 62G07; secondary 41A25},
}

@book{fan_nonlinear_2003,
	location = {New York, {NY}},
	title = {Nonlinear Time Series},
	rights = {http://www.springer.com/tdm},
	isbn = {978-0-387-26142-3 978-0-387-69395-8},
	url = {http://link.springer.com/10.1007/978-0-387-69395-8},
	series = {Springer Series in Statistics},
	publisher = {Springer},
	author = {Fan, Jianqing and Yao, Qiwei},
	urldate = {2024-10-25},
	date = {2003},
	langid = {english},
	doi = {10.1007/978-0-387-69395-8},
	note = {{ISSN}: 0172-7397},
	keywords = {Time series, econometrics, linear optimization, mathematical statistics, modeling, nonparametric methods, quantitative finance, statistical method, statistics},
}

@article{barron_entropy_1986,
	title = {Entropy and the Central Limit Theorem},
	volume = {14},
	issn = {0091-1798},
	url = {https://www.jstor.org/stable/2244098},
	abstract = {A strengthened central limit theorem for densities is established showing monotone convergence in the sense of relative entropy.},
	pages = {336--342},
	number = {1},
	journaltitle = {The Annals of Probability},
	author = {Barron, Andrew R.},
	urldate = {2024-10-25},
	date = {1986},
	note = {Publisher: Institute of Mathematical Statistics},
}

@book{ljung_system_1999,
	location = {{USA}},
	title = {System identification (2nd ed.): theory for the user},
	isbn = {978-0-13-656695-3},
	shorttitle = {System identification (2nd ed.)},
	pagetotal = {609},
	publisher = {Prentice Hall {PTR}},
	author = {Ljung, Lennart},
	date = {1999},
}

@book{krishnamurthy_partially_2016,
	location = {Cambridge},
	title = {Partially Observed Markov Decision Processes: From Filtering to Controlled Sensing},
	isbn = {978-1-107-13460-7},
	url = {https://www.cambridge.org/core/books/partially-observed-markov-decision-processes/505ADAE28B3F22D1594F837DEAFF1E0C},
	shorttitle = {Partially Observed Markov Decision Processes},
	abstract = {Covering formulation, algorithms, and structural results, and linking theory to real-world applications in controlled sensing (including social learning, adaptive radars and sequential detection), this book focuses on the conceptual foundations of partially observed Markov decision processes ({POMDPs}). It emphasizes structural results in stochastic dynamic programming, enabling graduate students and researchers in engineering, operations research, and economics to understand the underlying unifying themes without getting weighed down by mathematical technicalities. Bringing together research from across the literature, the book provides an introduction to nonlinear filtering followed by a systematic development of stochastic dynamic programming, lattice programming and reinforcement learning for {POMDPs}. Questions addressed in the book include: when does a {POMDP} have a threshold optimal policy? When are myopic policies optimal? How do local and global decision makers interact in adaptive decision making in multi-agent social learning where there is herding and data incest? And how can sophisticated radars and sensors adapt their sensing in real time?},
	publisher = {Cambridge University Press},
	author = {Krishnamurthy, Vikram},
	urldate = {2024-10-19},
	date = {2016},
	doi = {10.1017/CBO9781316471104},
}

@article{efron_jackknife_1981,
	title = {The Jackknife Estimate of Variance},
	volume = {9},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-3/The-Jackknife-Estimate-of-Variance/10.1214/aos/1176345462.full},
	doi = {10.1214/aos/1176345462},
	abstract = {Tukey's jackknife estimate of variance for a statistic \$S(X\_1, X\_2, {\textbackslash}cdots, X\_n)\$ which is a symmetric function of i.i.d. random variables \$X\_i\$, is investigated using an {ANOVA}-like decomposition of \$S\$. It is shown that the jackknife variance estimate tends always to be biased upwards, a theorem to this effect being proved for the natural jackknife estimate of \${\textbackslash}operatorname\{Var\} S(X\_1, X\_2, {\textbackslash}cdots, X\_\{n-1\})\$ based on \$X\_1, X\_2, {\textbackslash}cdots, X\_n\$.},
	pages = {586--596},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Efron, B. and Stein, C.},
	urldate = {2024-08-24},
	date = {1981-05},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {\$U\$ statistics, 62G05, {ANOVA} decomposition, bootstrap, jackknife, variance estimation},
}

@article{ledoux_talagrands_1997,
	title = {On Talagrand's deviation inequalities for product measures},
	volume = {1},
	issn = {1292-8100, 1262-3318},
	url = {http://www.esaim-ps.org/10.1051/ps:1997103},
	doi = {10.1051/ps:1997103},
	pages = {63--87},
	journaltitle = {{ESAIM}: Probability and Statistics},
	shortjournal = {{ESAIM}: {PS}},
	author = {Ledoux, Michel},
	urldate = {2024-08-24},
	date = {1997},
}

@incollection{akaike_information_1998,
	location = {New York, {NY}},
	title = {Information Theory and an Extension of the Maximum Likelihood Principle},
	isbn = {978-1-4612-1694-0},
	url = {https://doi.org/10.1007/978-1-4612-1694-0_15},
	abstract = {In this paper it is shown that the classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion. This observation shows an extension of the principle to provide answers to many practical problems of statistical model fitting.},
	pages = {199--213},
	booktitle = {Selected Papers of Hirotugu Akaike},
	publisher = {Springer},
	author = {Akaike, Hirotogu},
	editor = {Parzen, Emanuel and Tanabe, Kunio and Kitagawa, Genshiro},
	urldate = {2024-08-23},
	date = {1998},
	langid = {english},
	doi = {10.1007/978-1-4612-1694-0_15},
	keywords = {Autoregressive Model, Final Prediction Error, Maximum Likelihood Principle, Statistical Decision Function, Statistical Model Identification},
}

@article{mallows_comments_1973,
	title = {Some Comments on {CP}},
	volume = {15},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1267380},
	doi = {10.2307/1267380},
	abstract = {We discuss the interpretation of {CP}-plots and show how they can be calibrated in several ways. We comment on the practice of using the display as a basis for formal selection of a subset-regression model, and extend the range of application of the device to encompass arbitrary linear estimates of the regression coefficients, for example Ridge estimates.},
	pages = {661--675},
	number = {4},
	journaltitle = {Technometrics},
	author = {Mallows, C. L.},
	urldate = {2024-08-23},
	date = {1973},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
}

@article{akaike_information_nodate,
	title = {Information Theory and an Extension of {IthnefoMrmaaxtiimonumThLeiokreyliahnododanPrEinxcteipnlseion} of the Maximum Likelihood Principle},
	abstract = {Abstract In this paper it is shown that the classical maximum likelihood principle {cInanthibsepacponersiidt} eisresdhotwonbtehaat tmheecthlaosdsicoafl masayxmimptuomticlikreelailhiozaotdiopnrinocfipalne coapntimbeumcoensstiidmearteedwtiothbreesapemctettohoadveorfy agseynmerpatloitnicforremaalitzioantiotnheoorfetainc corpitteimriounm. Teshtiismoabtesewrvitahtiroenspsehcotwtos aanveexrytegnesnioenraol finthfoerpmrainticoipnlethteoorpertoiccvriditeerainosnw. Terhsistoombsaenrvyaptiroanctischaolwpsroabnleemxtsenosfisotnatiosftitchael pmroindceilplfeitttiongp. rovide answers to many practical problems of statistical model fitting.},
	author = {Akaike, Hirotogu},
	langid = {english},
}

@article{serfozo_semi-stationary_1972,
	title = {Semi-stationary processes},
	volume = {23},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/BF00532855},
	doi = {10.1007/BF00532855},
	pages = {125--132},
	number = {2},
	journaltitle = {Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete},
	shortjournal = {Z. Wahrscheinlichkeitstheorie verw Gebiete},
	author = {Serfozo, Richard F.},
	urldate = {2024-08-12},
	date = {1972-06-01},
	langid = {english},
	keywords = {Mathematical Biology, Probability Theory, Stochastic Process},
}

@misc{canonne_short_2023,
	title = {A short note on an inequality between {KL} and {TV}},
	url = {http://arxiv.org/abs/2202.07198},
	abstract = {The goal of this short note is to discuss the relation between Kullback--Leibler divergence and total variation distance, starting with the celebrated Pinsker's inequality relating the two, before switching to a simple, yet (arguably) more useful inequality, apparently not as well known, due to Bretagnolle and Huber. We also discuss applications of this bound for minimax testing lower bounds.},
	number = {{arXiv}:2202.07198},
	publisher = {{arXiv}},
	author = {Canonne, Clément L.},
	urldate = {2024-08-11},
	date = {2023-08-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2202.07198 [math, stat]},
	keywords = {Mathematics - Probability, Mathematics - Statistics Theory},
}

@article{donoho_ideal_1994,
	title = {Ideal spatial adaptation by wavelet shrinkage},
	volume = {81},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/81.3.425},
	doi = {10.1093/biomet/81.3.425},
	abstract = {With ideal spatial adaptation, an oracle furnishes information about how best to adapt a spatially variable estimator, whether piecewise constant, piecewise polynomial, variable knot spline, or variable bandwidth kernel, to the unknown function. Estimation with the aid of an oracle offers dramatic advantages over traditional linear estimation by nonadaptive kernels; however, it is a priori unclear whether such performance can be obtained by a procedure relying on the data alone. We describe a new principle for spatially-adaptive estimation: selective wavelet reconstruction. We show that variable-knot spline fits and piecewise-polynomial fits, when equipped with an oracle to select the knots, are not dramatically more powerful than selective wavelet reconstruction with an oracle. We develop a practical spatially adaptive method, Risk Shrink, which works by shrinkage of empirical wavelet coefficients. {RiskShrink} mimics the performance of an oracle for selective wavelet reconstruction as well as it is possible to do so. A new inequality in multivariate normal decision theory which we call the oracle inequality shows that attained performance differs from ideal performance by at most a factor of approximately 2 log n, where n is the sample size. Moreover no estimator can give a better guarantee than this. Within the class of spatially adaptive procedures, {RiskShrink} is essentially optimal. Relying only on the data, it comes within a factor log2n of the performance of piecewise polynomial and variableknot spline methods equipped with an oracle. In contrast, it is unknown how or if piecewise polynomial methods could be made to function this well when denied access to an oracle and forced to rely on data alone.},
	pages = {425--455},
	number = {3},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {Donoho, David L and Johnstone, Iain M},
	urldate = {2024-08-11},
	date = {1994-09-01},
}

@book{ash_probability_2000,
	title = {Probability and Measure Theory},
	isbn = {978-0-12-065202-0},
	abstract = {Probability and Measure Theory, Second Edition, is a text for a graduate-level course in probability that includes essential background topics in analysis. It provides extensive coverage of conditional probability and expectation, strong laws of large numbers, martingale theory, the central limit theorem, ergodic theory, and Brownian motion.  Clear, readable style Solutions to many problems presented in text Solutions manual for instructors Material new to the second edition on ergodic theory, Brownian motion, and convergence theorems used in statistics No knowledge of general topology required, just basic analysis and metric spaces Efficient organization},
	pagetotal = {536},
	publisher = {Academic Press},
	author = {Ash, Robert B. and Doleans-Dade, Catherine A.},
	date = {2000},
	langid = {english},
	note = {Google-Books-{ID}: {GkqQoRpCO}2QC},
	keywords = {Mathematics / Algebra / General, Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@book{noauthor_probability_1999,
	title = {Probability and Measure Theory},
	isbn = {978-0-08-051487-1},
	url = {https://shop.elsevier.com/books/probability-and-measure-theory/ash/978-0-08-051487-1},
	abstract = {Probability and Measure Theory, Second Edition, is a text for a graduate-level course in probability that includes essential background topics},
	urldate = {2024-08-01},
	date = {1999-11-15},
	langid = {american},
}

@article{masnadi-shirazi_step_nodate,
	title = {A Step by Step Mathematical Derivation and Tutorial on Kalman Filters},
	abstract = {We present a step by step mathematical derivation of the Kalman ﬁlter using two diﬀerent approaches. First, we consider the orthogonal projection method by means of vector-space optimization. Second, we derive the Kalman ﬁlter using Bayesian optimal ﬁltering. We provide detailed proofs for both methods and each equation is expanded in detail.},
	author = {Masnadi-Shirazi, Hamed and Masnadi-Shirazi, Alireza and Dastgheib, Mohammad-Amir},
	langid = {english},
}

@article{goggin_convergence_1992,
	title = {Convergence of filters with applications to the Kalman-Bucy case},
	volume = {38},
	issn = {1557-9654},
	url = {https://ieeexplore.ieee.org/abstract/document/135648},
	doi = {10.1109/18.135648},
	abstract = {For each N, and each fixed time T, a signal X/sup N/ and a 'noisy' observation Y/sup N/ are defined by a pair of stochastic difference equations. Under certain conditions (X/sup N/, Y/sup N/) converges in distribution to (X, Y, where {dX}(t)=f(t, X(t))dt+{dV}(t), {dY}(t)=g(t, X(t))dt+{dW}(t). Conditions are found under which convergence in distribution of the conditional expectations E(F(X/sup N/) mod Y/sup N/) to E(F(X) mod Y) follows, for every bounded continuous function F. The case in which the conditional expectations still converge but the limit is not E(F(X) mod Y) is also studied. In the situation where f and g are linear functions of X, an examination of this limit leads to a Kalman-Bucy-type estimate of X/sup N/ which is asymptotically optimal and is an improvement on the usual Kalman-Bucy estimate.{\textless}{\textgreater}},
	pages = {1091--1100},
	number = {3},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Goggin, E.M.},
	urldate = {2024-06-26},
	date = {1992-05},
	note = {Conference Name: {IEEE} Transactions on Information Theory},
	keywords = {Additive white noise, Computer aided software engineering, Conferences, Convergence, Difference equations, Filtering, Filters, Q measurement, Stochastic resonance, Tin},
}

@inproceedings{sidford_near-optimal_2018,
	title = {Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/bb03e43ffe34eeb242a2ee4a4f125e56-Abstract.html},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
	urldate = {2024-04-08},
	date = {2018},
}

@article{davydov_convergence_1968,
	title = {Convergence of Distributions Generated by Stationary Stochastic Processes},
	volume = {13},
	issn = {0040-585X},
	url = {https://epubs.siam.org/doi/abs/10.1137/1113086},
	doi = {10.1137/1113086},
	pages = {691--696},
	number = {4},
	journaltitle = {Theory of Probability \& Its Applications},
	shortjournal = {Theory Probab. Appl.},
	author = {Davydov, Yu. A.},
	urldate = {2024-02-21},
	date = {1968-01},
	note = {Publisher: Society for Industrial and Applied Mathematics},
}

@article{bhatt_occupation_1996,
	title = {Occupation measures for controlled Markov processes: characterization and optimality},
	volume = {24},
	issn = {0091-1798, 2168-894X},
	url = {https://projecteuclid.org/journals/annals-of-probability/volume-24/issue-3/Occupation-measures-for-controlled-Markov-processes-characterization-and-optimality/10.1214/aop/1065725192.full},
	doi = {10.1214/aop/1065725192},
	shorttitle = {Occupation measures for controlled Markov processes},
	abstract = {For controlled Markov processes taking values in a Polish space, control problems with ergodic cost, infinite-horizon discounted cost and finite-horizon cost are studied. Each is posed as a convex optimization problem wherein one tries to minimize a linear functional on a closed convex set of appropriately defined occupation measures for the problem. These are characterized as solutions of a linear equation asssociated with the problem. This characterization is used to establish the existence of optimal Markov controls. The dual convex optimization problem is also studied.},
	pages = {1531--1562},
	number = {3},
	journaltitle = {The Annals of Probability},
	author = {Bhatt, Abhay G. and Borkar, Vivek S.},
	urldate = {2024-01-17},
	date = {1996-07},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60J25, 93E20, Controlled Markov processes, infinite-dimensional linear programming, occupation measures, optimal control},
}

@article{valiant_theory_1984,
	title = {A theory of the learnable},
	volume = {27},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/1968.1972},
	doi = {10.1145/1968.1972},
	pages = {1134--1142},
	number = {11},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Valiant, L. G.},
	urldate = {2023-11-08},
	date = {1984-11-05},
	keywords = {inductive inference, probabilistic models of learning, propositional expressions},
}

@article{athreya_kernel_1998,
	title = {Kernel Estimation for Real-Valued Markov Chains},
	abstract = {The purpose of this paper is to study the problem of estimation of the stationary density and the transition density of a real-valued recurrent Markov chain. By using techniques of regenerative processes we are able to significantly reduce the strong hypotheses on the Markov chain such as Doeblin recurrence, stationarity, and mixing that were imposed in all the earlier works. We assume that the Markov chain satisfies a much weaker condition known as Harris recurrence. Our results hold for any initial distribution and we assume no mixing.},
	pages = {18},
	author = {Athreya, Krishna B},
	date = {1998},
	langid = {english},
}

@article{loffler_spectral_2021,
	title = {Spectral thresholding for the estimation of Markov chain transition operators},
	volume = {15},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-15/issue-2/Spectral-thresholding-for-the-estimation-of-Markov-chain-transition-operators/10.1214/21-EJS1935.full},
	doi = {10.1214/21-EJS1935},
	abstract = {We consider nonparametric estimation of the transition operator P of a Markov chain and its transition density p where the singular values of P are assumed to decay exponentially fast. This is for instance the case for periodised, reversible multi-dimensional diffusion processes observed in low frequency. We investigate the performance of a spectral hard thresholded Galerkin-type estimator for P and p, discarding most of the estimated singular triplets. The construction is based on smooth basis functions such as wavelets or B-splines. We show its statistical optimality by establishing matching minimax upper and lower bounds in L2-loss. Particularly, the effect of the dimensionality d of the state space on the nonparametric rate improves from 2d to d compared to the case without singular value decay.},
	pages = {6281--6310},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	author = {Löffler, Matthias and Picard, Antoine},
	urldate = {2023-11-02},
	date = {2021-01},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {62C20, 62G05, Markov chain, {SDE}, Transition density, low rank, minimax rates of convergence, nonparametric estimation, transition operator},
}

@online{mattu_machine_nodate,
	title = {Machine Bias},
	url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
	abstract = {There’s software used across the country to predict future criminals. And it’s biased against blacks.},
	titleaddon = {{ProPublica}},
	author = {Mattu, Jeff Larson, Lauren Kirchner, Surya, Julia Angwin},
	urldate = {2023-10-12},
	langid = {english},
}

@article{haussler_probably_1990,
	title = {Probably Approximately Correct Learning},
	url = {https://cdn.aaai.org/AAAI/1990/AAAI90-163.pdf},
	journaltitle = {{AAAI}-90 Proceedings},
	author = {Haussler, David},
	date = {1990},
	langid = {english},
}

@incollection{woeginger_exact_2003,
	location = {Berlin, Heidelberg},
	title = {Exact Algorithms for {NP}-Hard Problems: A Survey},
	isbn = {978-3-540-36478-8},
	url = {https://doi.org/10.1007/3-540-36478-1_17},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Exact Algorithms for {NP}-Hard Problems},
	abstract = {We discuss fast exponential time solutions for {NP}-complete problems. We survey known results and approaches, we provide pointers to the literature, and we discuss several open problems in this area. The list of discussed {NP}-complete problems includes the travelling salesman problem, scheduling under precedence constraints, satisfiability, knapsack, graph coloring, independent sets in graphs, bandwidth of a graph, and many more.},
	pages = {185--207},
	booktitle = {Combinatorial Optimization — Eureka, You Shrink!},
	publisher = {Springer},
	author = {Woeginger, Gerhard J.},
	editor = {Jünger, Michael and Reinelt, Gerhard and Rinaldi, Giovanni},
	urldate = {2023-09-19},
	date = {2003},
	langid = {english},
	doi = {10.1007/3-540-36478-1_17},
}

@inproceedings{taskesen_statistical_2021,
	location = {New York, {NY}, {USA}},
	title = {A Statistical Test for Probabilistic Fairness},
	isbn = {978-1-4503-8309-7},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445927},
	doi = {10.1145/3442188.3445927},
	series = {{FAccT} '21},
	abstract = {Algorithms are now routinely used to make consequential decisions that affect human lives. Examples include college admissions, medical interventions or law enforcement. While algorithms empower us to harness all information hidden in vast amounts of data, they may inadvertently amplify existing biases in the available datasets. This concern has sparked increasing interest in fair machine learning, which aims to quantify and mitigate algorithmic discrimination. Indeed, machine learning models should undergo intensive tests to detect algorithmic biases before being deployed at scale. In this paper, we use ideas from the theory of optimal transport to propose a statistical hypothesis test for detecting unfair classifiers. Leveraging the geometry of the feature space, the test statistic quantifies the distance of the empirical distribution supported on the test samples to the manifold of distributions that render a pre-trained classifier fair. We develop a rigorous hypothesis testing mechanism for assessing the probabilistic fairness of any pre-trained logistic classifier, and we show both theoretically as well as empirically that the proposed test is asymptotically correct. In addition, the proposed framework offers interpretability by identifying the most favorable perturbation of the data so that the given classifier becomes fair.},
	pages = {648--665},
	booktitle = {Proceedings of the 2021 {ACM} Conference on Fairness, Accountability, and Transparency},
	publisher = {Association for Computing Machinery},
	author = {Taskesen, Bahar and Blanchet, Jose and Kuhn, Daniel and Nguyen, Viet Anh},
	urldate = {2023-09-19},
	date = {2021-03-01},
	keywords = {Wasserstein distance, algorithmic bias, equal opportunity, equalized odds, fairness},
}

@inproceedings{black_fliptest_2020,
	location = {New York, {NY}, {USA}},
	title = {{FlipTest}: fairness testing via optimal transport},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372845},
	doi = {10.1145/3351095.3372845},
	series = {{FAT}* '20},
	shorttitle = {{FlipTest}},
	abstract = {We present {FlipTest}, a black-box technique for uncovering discrimination in classifiers. {FlipTest} is motivated by the intuitive question: had an individual been of a different protected status, would the model have treated them differently? Rather than relying on causal information to answer this question, {FlipTest} leverages optimal transport to match individuals in different protected groups, creating similar pairs of in-distribution samples. We show how to use these instances to detect discrimination by constructing a flipset: the set of individuals whose classifier output changes post-translation, which corresponds to the set of people who may be harmed because of their group membership. To shed light on why the model treats a given subgroup differently, {FlipTest} produces a transparency report: a ranking of features that are most associated with the model's behavior on the flipset. Evaluating the approach on three case studies, we show that this provides a computationally inexpensive way to identify subgroups that may be harmed by model discrimination, including in cases where the model satisfies group fairness criteria.},
	pages = {111--121},
	booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	publisher = {Association for Computing Machinery},
	author = {Black, Emily and Yeom, Samuel and Fredrikson, Matt},
	urldate = {2023-09-19},
	date = {2020-01-27},
	keywords = {disparate impact, fairness, machine learning, optimal transport},
}

@inproceedings{lipton_does_2018,
	title = {Does mitigating {ML}' s impact disparity require treatment disparity?},
	volume = {31},
	url = {https://papers.nips.cc/paper_files/paper/2018/hash/8e0384779e58ce2af40eb365b318cc32-Abstract.html},
	abstract = {Following precedent in employment discrimination law, two notions of disparity are widely-discussed in papers on fairness and {ML}. Algorithms exhibit treatment disparity if they formally treat members of protected subgroups differently;
algorithms exhibit impact disparity when outcomes differ across subgroups (even unintentionally). Naturally, we can achieve impact parity through purposeful treatment disparity. One line of papers aims to reconcile the two parities proposing disparate learning processes ({DLPs}). Here, the sensitive feature is used during training but a group-blind classifier is produced. In this paper, we show that: (i) when sensitive and (nominally) nonsensitive features are correlated, {DLPs} will indirectly implement treatment disparity, undermining the policy desiderata they are designed to address; (ii) when group membership is partly revealed by other features, {DLPs} induce within-class discrimination; and (iii) in general, {DLPs} provide suboptimal trade-offs between accuracy and impact parity. Experimental results on several real-world datasets highlight the practical consequences of applying {DLPs}.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Lipton, Zachary and {McAuley}, Julian and Chouldechova, Alexandra},
	urldate = {2023-09-19},
	date = {2018},
}

@misc{li_breaking_2023,
	title = {Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model},
	url = {http://arxiv.org/abs/2005.12900},
	abstract = {This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider \${\textbackslash}gamma\$-discounted infinite-horizon Markov decision processes ({MDPs}) with state space \${\textbackslash}mathcal\{S\}\$ and action space \${\textbackslash}mathcal\{A\}\$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least \${\textbackslash}frac\{{\textbar}{\textbackslash}mathcal\{S\}{\textbar}{\textbar}{\textbackslash}mathcal\{A\}{\textbar}\}\{(1-{\textbackslash}gamma){\textasciicircum}2\}\$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of \${\textbackslash}frac\{{\textbar}{\textbackslash}mathcal\{S\}{\textbar}{\textbar}{\textbackslash}mathcal\{A\}{\textbar}\}\{1-{\textbackslash}gamma\}\$ (modulo some log factor). Moving beyond infinite-horizon {MDPs}, we further study time-inhomogeneous finite-horizon {MDPs}, and prove that a plain model-based planning algorithm suffices to achieve minimax-optimal sample complexity given any target accuracy level. To the best of our knowledge, this work delivers the first minimax-optimal guarantees that accommodate the entire range of sample sizes (beyond which finding a meaningful policy is information theoretically infeasible).},
	number = {{arXiv}:2005.12900},
	publisher = {{arXiv}},
	author = {Li, Gen and Wei, Yuting and Chi, Yuejie and Chen, Yuxin},
	urldate = {2023-08-18},
	date = {2023-04-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.12900 [cs, math, stat]},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Mathematics - Optimization and Control, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@inproceedings{garg_counterfactual_2019,
	location = {Honolulu {HI} {USA}},
	title = {Counterfactual Fairness in Text Classification through Robustness},
	isbn = {978-1-4503-6324-2},
	url = {https://dl.acm.org/doi/10.1145/3306618.3317950},
	doi = {10.1145/3306618.3317950},
	abstract = {In this paper, we study counterfactual fairness in text classification, which asks the question: How would the prediction change if the sensitive attribute referenced in the example were different? Toxicity classifiers demonstrate a counterfactual fairness issue by predicting that “Some people are gay” is toxic while “Some people are straight” is nontoxic. We offer a metric, counterfactual token fairness ({CTF}), for measuring this particular form of fairness in text classifiers, and describe its relationship with group fairness. Further, we offer three approaches, blindness, counterfactual augmentation, and counterfactual logit pairing ({CLP}), for optimizing counterfactual token fairness during training, bridging the robustness and fairness literature. Empirically, we find that blindness and {CLP} address counterfactual token fairness. The methods do not harm classifier performance, and have varying tradeoffs with group fairness. These approaches, both for measurement and optimization, provide a new path forward for addressing fairness concerns in text classification.},
	eventtitle = {{AIES} '19: {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	pages = {219--226},
	booktitle = {Proceedings of the 2019 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher = {{ACM}},
	author = {Garg, Sahaj and Perot, Vincent and Limtiaco, Nicole and Taly, Ankur and Chi, Ed H. and Beutel, Alex},
	urldate = {2023-09-19},
	date = {2019-01-27},
	langid = {english},
}

@article{lazimy_mixed-integer_1982,
	title = {Mixed-integer quadratic programming},
	volume = {22},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01581047},
	doi = {10.1007/BF01581047},
	abstract = {This paper considers mixed-integer quadratic programs in which the objective function is quadratic in the integer and in the continuous variables, and the constraints are linear in the variables of both types. The generalized Benders' decomposition is a suitable approach for solving such programs. However, the program does not become more tractable if this method is used, since Benders' cuts are quadratic in the integer variables. A new equivalent formulation that renders the program tractable is developed, under which the dual objective function is linear in the integer variables and the dual constraint set is independent of these variables. Benders' cuts that are derived from the new formulation are linear in the integer variables, and the original problem is decomposed into a series of integer linear master problems and standard quadratic subproblems. The new formulation does not introduce new primary variables or new constraints into the computational steps of the decomposition algorithm.},
	pages = {332--349},
	number = {1},
	journaltitle = {Mathematical Programming},
	shortjournal = {Mathematical Programming},
	author = {Lazimy, Rafael},
	urldate = {2023-09-19},
	date = {1982-12-01},
	langid = {english},
	keywords = {Generalized Benders Decomposition, Generalized Inverses, Integer Linear Programs, Mixed-Integer Quadratic Programming, Quadratic Duality Theory, Quadratic Programming},
}

@article{mattu_machine_nodate,
	title = {Machine Bias},
	url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
	abstract = {There’s software used across the country to predict future criminals. And it’s biased against blacks.},
	journaltitle = {{ProPublica}},
	author = {Mattu, Jeff Larson, Lauren Kirchner, Surya, Julia Angwin},
	urldate = {2023-09-19},
	langid = {english},
}

@article{mattu_how_nodate,
	title = {How We Analyzed the {COMPAS} Recidivism Algorithm},
	url = {https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm},
	abstract = {{ProPublica} is an independent, non-profit newsroom that produces investigative journalism in the public interest.},
	journaltitle = {{ProPublica}},
	author = {Mattu, Julia Angwin, Lauren Kirchner, Surya, Jeff Larson},
	urldate = {2023-09-19},
	langid = {english},
}

@misc{kuppam_fair_2020,
	title = {Fair Decision Making using Privacy-Protected Data},
	url = {http://arxiv.org/abs/1905.12744},
	abstract = {Data collected about individuals is regularly used to make decisions that impact those same individuals. We consider settings where sensitive personal data is used to decide who will receive resources or benefits. While it is well known that there is a tradeoff between protecting privacy and the accuracy of decisions, we initiate a first-of-its-kind study into the impact of formally private mechanisms (based on differential privacy) on fair and equitable decision-making. We empirically investigate novel tradeoffs on two real-world decisions made using U.S. Census data (allocation of federal funds and assignment of voting rights benefits) as well as a classic apportionment problem.},
	number = {{arXiv}:1905.12744},
	publisher = {{arXiv}},
	author = {Kuppam, Satya and Mckenna, Ryan and Pujol, David and Hay, Michael and Machanavajjhala, Ashwin and Miklau, Gerome},
	urldate = {2023-09-19},
	date = {2020-01-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1905.12744 [cs]},
	keywords = {Computer Science - Databases},
}

@inproceedings{dwork_fairness_2012,
	location = {Cambridge Massachusetts},
	title = {Fairness through awareness},
	isbn = {978-1-4503-1115-1},
	url = {https://dl.acm.org/doi/10.1145/2090236.2090255},
	doi = {10.1145/2090236.2090255},
	abstract = {We study fairness in classiﬁcation, where individuals are classiﬁed, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classiﬁer (the university). The main conceptual contribution of this paper is a framework for fair classiﬁcation comprising (1) a (hypothetical) task-speciﬁc metric for determining the degree to which individuals are similar with respect to the classiﬁcation task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of “fair aﬃrmative action,” which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classiﬁcation are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of diﬀerential privacy may be applied to fairness.},
	eventtitle = {{ITCS} '12: Innovations in Theoretical Computer Science},
	pages = {214--226},
	booktitle = {Proceedings of the 3rd Innovations in Theoretical Computer Science Conference},
	publisher = {{ACM}},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
	urldate = {2023-09-19},
	date = {2012-01-08},
	langid = {english},
}

@inproceedings{chang_privacy_2021,
	title = {On the Privacy Risks of Algorithmic Fairness},
	doi = {10.1109/EuroSP51992.2021.00028},
	abstract = {Algorithmic fairness and privacy are essential pillars of trustworthy machine learning. Fair machine learning aims at minimizing discrimination against protected groups by, for example, imposing a constraint on models to equalize their behavior across different groups. This can subsequently change the influence of training data points on the fair model, in a disproportionate way. We study how this can change the information leakage of the model about its training data. We analyze the privacy risks of group fairness (e.g., equalized odds) through the lens of membership inference attacks: inferring whether a data point is used for training a model. We show that fairness comes at the cost of privacy, and this cost is not distributed equally: the information leakage of fair models increases significantly on the unprivileged subgroups, which are the ones for whom we need fair learning. We show that the more biased the training data is, the higher the privacy cost of achieving fairness for the unprivileged subgroups will be. We provide comprehensive empirical analysis for general machine learning algorithms.},
	eventtitle = {2021 {IEEE} European Symposium on Security and Privacy ({EuroS}\&P)},
	pages = {292--303},
	booktitle = {2021 {IEEE} European Symposium on Security and Privacy ({EuroS}\&P)},
	author = {Chang, Hongyan and Shokri, Reza},
	date = {2021-09},
	keywords = {Costs, Data Privacy, Data privacy, Group Fairness, Machine learning, Machine learning algorithms, Membership Inference Attacks, Privacy, Training, Training data, Trustworthy Machine Learning},
}

@article{li_survey_2018,
	title = {A survey on one-bit compressed sensing: theory and applications},
	volume = {12},
	issn = {2095-2236},
	url = {https://doi.org/10.1007/s11704-017-6132-7},
	doi = {10.1007/s11704-017-6132-7},
	shorttitle = {A survey on one-bit compressed sensing},
	abstract = {In the past few decades, with the growing popularity of compressed sensing ({CS}) in the signal processing field, the quantization step in {CS} has received significant attention. Current research generally considers multi-bit quantization. For systems employing quantization with a sufficient number of bits, a sparse signal can be reliably recovered using various {CS} reconstruction algorithms.},
	pages = {217--230},
	number = {2},
	journaltitle = {Frontiers of Computer Science},
	shortjournal = {Front. Comput. Sci.},
	author = {Li, Zhilin and Xu, Wenbo and Zhang, Xiaobo and Lin, Jiaru},
	urldate = {2023-09-19},
	date = {2018-04-01},
	langid = {english},
	keywords = {compressed sensing, consistency, one-bit quantization, sign information, support},
}

@book{dunn_generalized_2018,
	location = {New York, {NY}},
	title = {Generalized Linear Models With Examples in R},
	isbn = {978-1-4419-0117-0 978-1-4419-0118-7},
	url = {http://link.springer.com/10.1007/978-1-4419-0118-7},
	series = {Springer Texts in Statistics},
	publisher = {Springer},
	author = {Dunn, Peter K. and Smyth, Gordon K.},
	urldate = {2023-09-19},
	date = {2018},
	doi = {10.1007/978-1-4419-0118-7},
	keywords = {Randomized quantile residuals, Saddlepoint approximation, Tweedie family distribution, generalized linear models, likelihood score tests, linear regression},
}

@online{noauthor_amazoncom_nodate,
	title = {Amazon.com: Generalized Linear Models (Chapman \& Hall/{CRC} Monographs on Statistics and Applied Probability): 9780412317606: {McCullagh}, P.: Books},
	url = {https://www.amazon.com/Generalized-Chapman-Monographs-Statistics-Probability/dp/0412317605/ref=asc_df_0412317605/?tag=hyprod-20&linkCode=df0&hvadid=266033622375&hvpos=&hvnetw=g&hvrand=18257114043851712630&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9016722&hvtargid=pla-469055424894&psc=1},
	urldate = {2023-09-19},
}

@misc{mehrabi_survey_2022,
	title = {A Survey on Bias and Fairness in Machine Learning},
	url = {http://arxiv.org/abs/1908.09635},
	abstract = {With the widespread use of {AI} systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect {AI} applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in {AI} systems. In addition to that, we examined different domains and subdomains in {AI} showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in {AI} systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	number = {{arXiv}:1908.09635},
	publisher = {{arXiv}},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	urldate = {2023-09-19},
	date = {2022-01-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1908.09635 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{cummings_compatibility_2019,
	location = {Larnaca Cyprus},
	title = {On the Compatibility of Privacy and Fairness},
	isbn = {978-1-4503-6711-0},
	url = {https://dl.acm.org/doi/10.1145/3314183.3323847},
	doi = {10.1145/3314183.3323847},
	eventtitle = {{UMAP} '19: 27th Conference on User Modeling, Adaptation and Personalization},
	pages = {309--315},
	booktitle = {Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization},
	publisher = {{ACM}},
	author = {Cummings, Rachel and Gupta, Varun and Kimpara, Dhamma and Morgenstern, Jamie},
	urldate = {2023-09-19},
	date = {2019-06-06},
	langid = {english},
}

@inproceedings{icarte_using_2018,
	title = {Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning},
	url = {https://proceedings.mlr.press/v80/icarte18a.html},
	abstract = {In this paper we propose Reward Machines \{—\} a type of finite state machine that supports the specification of reward functions while exposing reward function structure to the learner and supporting decomposition. We then present Q-Learning for Reward Machines ({QRM}), an algorithm which appropriately decomposes the reward machine and uses off-policy q-learning to simultaneously learn subpolicies for the different components. {QRM} is guaranteed to converge to an optimal policy in the tabular case, in contrast to Hierarchical Reinforcement Learning methods which might converge to suboptimal policies. We demonstrate this behavior experimentally in two discrete domains. We also show how function approximation methods like neural networks can be incorporated into {QRM}, and that doing so can find better policies more quickly than hierarchical methods in a domain with a continuous state space.},
	eventtitle = {International Conference on Machine Learning},
	pages = {2107--2116},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Icarte, Rodrigo Toro and Klassen, Toryn and Valenzano, Richard and {McIlraith}, Sheila},
	urldate = {2023-09-05},
	date = {2018-07-03},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}

@article{icarte_using_nodate,
	title = {Using Reward Machines for High-Level Task Specificationand Decomposition in Reinforcement Learning},
	abstract = {In this paper we propose Reward Machines – a type of ﬁnite state machine that supports the speciﬁcation of reward functions while exposing reward function structure to the learner and supporting decomposition. We then present Q-Learning for Reward Machines ({QRM}), an algorithm which appropriately decomposes the reward machine and uses off-policy q-learning to simultaneously learn subpolicies for the different components. {QRM} is guaranteed to converge to an optimal policy in the tabular case, in contrast to Hierarchical Reinforcement Learning methods which might converge to suboptimal policies. We demonstrate this behavior experimentally in two discrete domains. We also show how function approximation methods like neural networks can be incorporated into {QRM}, and that doing so can ﬁnd better policies more quickly than hierarchical methods in a domain with a continuous state space.},
	author = {Icarte, Rodrigo Toro and Klassen, Toryn Q and Valenzano, Richard and {McIlraith}, Sheila A},
	langid = {english},
}

@article{lee_markov_2018,
	title = {Markov decision process model for patient admission decision at an emergency department under a surge demand},
	volume = {30},
	issn = {1936-6590},
	url = {https://doi.org/10.1007/s10696-017-9276-8},
	doi = {10.1007/s10696-017-9276-8},
	abstract = {We study an admission control problem for patients arriving at an emergency department in the aftermath of a mass casualty incident. A finite horizon Markov decision process ({MDP}) model is formulated to determine patient admission decisions. In particular, our model considers the time-dependent arrival of patients and time-dependent reward function. We also consider a policy restriction that immediate-patients should be admitted as long as there is available beds. The {MDP} model has a continuous state space, and we solve the model by using a state discretization technique and obtain numerical solutions.Structural properties of an optimal policy are reviewed, and the structures observed in the numerical solutions are explained accordingly.Experimental results with virtual patient arrival scenarios demonstrates the performance and advantage of optimal policies obtained from the {MDP} model.},
	pages = {98--122},
	number = {1},
	journaltitle = {Flexible Services and Manufacturing Journal},
	shortjournal = {Flex Serv Manuf J},
	author = {Lee, Hyun-Rok and Lee, Taesik},
	urldate = {2023-09-05},
	date = {2018-06-01},
	langid = {english},
	keywords = {Admission control, Disaster response, Emergency department, Markov decision process, Mass casualty incident, Optimal policy},
}

@article{ben-israel_what_1986,
	title = {What is invexity?},
	volume = {28},
	issn = {1839-4078, 0334-2700},
	url = {https://www.cambridge.org/core/journals/anziam-journal/article/what-is-invexity/82C3938EDF3585B2AC5C27093E23814F},
	doi = {10.1017/S0334270000005142},
	abstract = {Recently it was shown that many results in Mathematical Programming involving convex functions actually hold for a wider class of functions, called invex. Here a simple characterization of invexity is given for both constrained and unconstrained problems. The relationship between invexity and other generalizations of convexity is illustrated. Finally, it is shown that invexity can be substituted for convexity in the saddle point problem and in the Slater constraint qualification.},
	pages = {1--9},
	number = {1},
	journaltitle = {The {ANZIAM} Journal},
	author = {Ben-Israel, A. and Mond, B.},
	urldate = {2023-08-28},
	date = {1986-07},
	langid = {english},
	note = {Publisher: Cambridge University Press},
}

@article{hanson_sufficiency_1981,
	title = {On sufficiency of the Kuhn-Tucker conditions},
	volume = {80},
	issn = {0022-247X},
	url = {https://www.sciencedirect.com/science/article/pii/0022247X81901232},
	doi = {10.1016/0022-247X(81)90123-2},
	pages = {545--550},
	number = {2},
	journaltitle = {Journal of Mathematical Analysis and Applications},
	shortjournal = {Journal of Mathematical Analysis and Applications},
	author = {Hanson, Morgan A},
	urldate = {2023-08-27},
	date = {1981-04-01},
}

@article{kerkyacharian_density_1992,
	title = {Density estimation in Besov spaces},
	volume = {13},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/016771529290231S},
	doi = {10.1016/0167-7152(92)90231-S},
	abstract = {One can slightly modify the usual Lp differentiability constraints of Sobolev types on densities with the help of Besov norms. This has the advantage, using the wavelets characterization of Besov spaces, to reduce the question of density estimation with Besov constraints to a problem in a sequences space, leading to very natural proofs. In this framework, we obtain the usual rate of minimax convergence and study the behaviour of a wavelet estimator.},
	pages = {15--24},
	number = {1},
	journaltitle = {Statistics \& Probability Letters},
	shortjournal = {Statistics \& Probability Letters},
	author = {Kerkyacharian, G. and Picard, D.},
	urldate = {2023-08-07},
	date = {1992-01-02},
	langid = {english},
	keywords = {Besov norms, Density estimation, Sobolev spaces},
}

@book{bergh_interpolation_1976,
	location = {Berlin, Heidelberg},
	title = {Interpolation Spaces: An Introduction},
	volume = {223},
	isbn = {978-3-642-66453-3 978-3-642-66451-9},
	url = {http://link.springer.com/10.1007/978-3-642-66451-9},
	series = {Grundlehren der mathematischen Wissenschaften},
	shorttitle = {Interpolation Spaces},
	publisher = {Springer},
	author = {Bergh, Jöran and Löfström, Jörgen},
	editorb = {Chern, S. S. and Doob, J. L. and Douglas, J. and Grothendieck, A. and Heinz, E. and Hirzebruch, F. and Hopf, E. and Mac Lane, S. and Magnus, W. and Postnikov, M. M. and Schmidt, F. K. and Schmidt, W. and Scott, D. S. and Stein, K. and Tits, J. and Van Der Waerden, B. L. and Eckmann, B. and Moser, J. K.},
	editorbtype = {redactor},
	urldate = {2023-08-07},
	date = {1976},
	langid = {english},
	doi = {10.1007/978-3-642-66451-9},
	keywords = {Interpolationsraum, Mac {OS} X 10.7 (Lion), approximation, approximation theory, compactness, duality, extrema, function, interpolation, iteration, theorem},
}

@incollection{bergh_interpolation_1976-1,
	location = {Berlin, Heidelberg},
	title = {Interpolation of Sobolev and Besov Spaces},
	isbn = {978-3-642-66451-9},
	url = {https://doi.org/10.1007/978-3-642-66451-9_6},
	series = {Grundlehren der mathematischen Wissenschaften},
	abstract = {We present definitions, interpolation results and various inclusion and trace theorems for the Sobolev and Besov spaces; our approach follows Peetre [5]. In the first section, we introduce briefly the Fourier multipliers on Lp, and we prove the Mihlin multiplier theorem. In Section 8, we discuss interpolation of semi-groups of operators. Many other topics are touched upon in the notes and comment, e.g., interpolation of Hardy spaces Hp.},
	pages = {131--173},
	booktitle = {Interpolation Spaces: An Introduction},
	publisher = {Springer},
	author = {Bergh, Jöran and Löfström, Jörgen},
	editor = {Bergh, Jöran and Löfström, Jörgen},
	urldate = {2023-08-07},
	date = {1976},
	langid = {english},
	doi = {10.1007/978-3-642-66451-9_6},
	keywords = {Besov Space, Fourier Multiplier, Hardy Space, Infinitesimal Generator, Interpolation Space},
}

@article{hoffmann_controlled_2019,
	title = {Controlled exploration of chemical space by machine learning of coarse-grained representations},
	volume = {100},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.100.033302},
	doi = {10.1103/PhysRevE.100.033302},
	abstract = {The size of chemical compound space is too large to be probed exhaustively. This leads high-throughput protocols to drastically subsample and results in sparse and nonuniform datasets. Rather than arbitrarily selecting compounds, we systematically explore chemical space according to the target property of interest. We first perform importance sampling by introducing a Markov chain Monte Carlo scheme across compounds. We then train a machine learning ({ML}) model on the sampled data to expand the region of chemical space probed. Our boosting procedure enhances the number of compounds by a factor 2 to 10, enabled by the {ML} model's coarse-grained representation, which both simplifies the structure-property relationship and reduces the size of chemical space. The {ML} model correctly recovers linear relationships between transfer free energies. These linear relationships correspond to features that are global to the dataset, marking the region of chemical space up to which predictions are reliable; this is a more robust alternative to the predictive variance. Bridging coarse-grained simulations with {ML} gives rise to an unprecedented database of drug-membrane insertion free energies for 1.3 million compounds.},
	pages = {033302},
	number = {3},
	journaltitle = {Physical Review E},
	shortjournal = {Phys. Rev. E},
	author = {Hoffmann, Christian and Menichetti, Roberto and Kanekal, Kiran H. and Bereau, Tristan},
	urldate = {2023-08-03},
	date = {2019-09-03},
	note = {Publisher: American Physical Society},
}

@misc{zanette_tighter_2019,
	title = {Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds},
	url = {http://arxiv.org/abs/1901.00210},
	abstract = {Strong worst-case performance bounds for episodic reinforcement learning exist but fortunately in practice {RL} algorithms perform much better than such bounds would predict. Algorithms and theory that provide strong problemdependent bounds could help illuminate the key features of what makes a {RL} problem hard and reduce the barrier to using {RL} algorithms in practice. As a step towards this we derive an algorithm and analysis for ﬁnite horizon discrete {MDPs} with state-of-the-art worst-case regret bounds and substantially tighter bounds if the {RL} environment has special features but without apriori knowledge of the environment from the algorithm. As a result of our analysis, we also help address an open learning theory question (Jiang \& Agarwal, 2018) about episodic {MDPs} with a constant upper-bound on the sum of rewards, providing a regret bound function of the number of episodes with no dependence on the horizon.},
	number = {{arXiv}:1901.00210},
	publisher = {{arXiv}},
	author = {Zanette, Andrea and Brunskill, Emma},
	urldate = {2023-07-26},
	date = {2019-11-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1901.00210 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{mou_optimal_2022,
	title = {Optimal and instance-dependent guarantees for Markovian linear stochastic approximation},
	url = {https://proceedings.mlr.press/v178/mou22a.html},
	abstract = {We study stochastic approximation procedures for approximately solving a ddd-dimensional linear fixed point equation based on observing a trajectory of length nnn from an ergodic Markov chain.  We first exhibit a non-asymptotic bound of the order tmixdntmixdnt\_\{{\textbackslash}mathrm\{mix\}\} {\textbackslash}tfrac\{d\}\{n\} on the squared error of the last iterate of a standard scheme, where tmixtmixt\_\{{\textbackslash}mathrm\{mix\}\} is a mixing time.  We then prove a non-asymptotic instance-dependent bound on a suitably averaged sequence of iterates, with a leading term that matches the local asymptotic minimax limit, including sharp dependence on the parameters (d,tmix)(d,tmix)(d, t\_\{{\textbackslash}mathrm\{mix\}\}) in the higher order terms. We complement these upper bounds with a non-asymptotic minimax lower bound that establishes the instance-optimality of the averaged {SA} estimator. We derive corollaries of these results for policy evaluation with Markov noise—covering the {TD}(λλ{\textbackslash}lambda) family of algorithms for all λ∈[0,1)λ∈[0,1){\textbackslash}lambda {\textbackslash}in [0, 1)—and linear autoregressive models. Our instance-dependent characterizations open the door to the design of fine-grained model selection procedures for hyperparameter tuning (e.g., choosing the value of λλ{\textbackslash}lambda when running the {TD}(λλ{\textbackslash}lambda) algorithm).},
	eventtitle = {Conference on Learning Theory},
	pages = {2060--2061},
	booktitle = {Proceedings of Thirty Fifth Conference on Learning Theory},
	publisher = {{PMLR}},
	author = {Mou, Wenlong and Pananjady, Ashwin and Wainwright, Martin and Bartlett, Peter},
	urldate = {2023-07-26},
	date = {2022-06-28},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}

@article{devore_degree_1990,
	title = {Degree of Adaptive Approximation},
	volume = {55},
	issn = {0025-5718},
	url = {https://www.jstor.org/stable/2008437},
	doi = {10.2307/2008437},
	abstract = {We obtain various estimates for the error in adaptive approximation and also establish a relationship between adaptive approximation and free-knot spline approximation.},
	pages = {625--635},
	number = {192},
	journaltitle = {Mathematics of Computation},
	author = {{DeVore}, Ronald A. and Yu, Xiang Ming},
	urldate = {2023-07-15},
	date = {1990},
	note = {Publisher: American Mathematical Society},
}

@incollection{massart_gaussian_2007,
	location = {Berlin, Heidelberg},
	title = {Gaussian Model Selection},
	isbn = {978-3-540-48503-2},
	url = {https://doi.org/10.1007/978-3-540-48503-2_4},
	series = {Lecture Notes in Mathematics},
	pages = {83--146},
	booktitle = {Concentration Inequalities and Model Selection},
	publisher = {Springer},
	editor = {Massart, Pascal and Picard, Jean},
	urldate = {2023-07-03},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-48503-2_4},
	keywords = {Adaptive Estimation, Bias Term, Change Point Detection, Gaussian Sequence, Less Square Estimator},
}

@article{barron_minimum_1991,
	title = {Minimum complexity density estimation},
	volume = {37},
	issn = {1557-9654},
	doi = {10.1109/18.86996},
	abstract = {The authors introduce an index of resolvability that is proved to bound the rate of convergence of minimum complexity density estimators as well as the information-theoretic redundancy of the corresponding total description length. The results on the index of resolvability demonstrate the statistical effectiveness of the minimum description-length principle as a method of inference. The minimum complexity estimator converges to true density nearly as fast as an estimator based on prior knowledge of the true subclass of densities. Interpretations and basic properties of minimum complexity estimators are discussed. Some regression and classification problems that can be examined from the minimum description-length framework are considered.{\textless}{\textgreater}},
	pages = {1034--1054},
	number = {4},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Barron, A.R. and Cover, T.M.},
	date = {1991-07},
	note = {Conference Name: {IEEE} Transactions on Information Theory},
	keywords = {Convergence, Data compression, Helium, Information systems, Laboratories, Probability density function, Probability distribution, Source coding, Statistical distributions, Statistics},
}

@book{ledoux_concentration_2001,
	title = {The Concentration of Measure Phenomenon},
	isbn = {978-0-8218-3792-4},
	abstract = {The observation of the concentration of measure phenomenon is inspired by isoperimetric inequalities. This book offers the basic techniques and examples of the concentration of measure phenomenon. It presents concentration functions and inequalities, isoperimetric and functional examples, spectrum and topological applications and product measures.},
	pagetotal = {194},
	publisher = {American Mathematical Soc.},
	author = {Ledoux, Michel},
	date = {2001},
	langid = {english},
	note = {Google-Books-{ID}: {rRKChz}4Om6gC},
}

@online{noauthor_concentration_nodate,
	title = {The Concentration of Measure Phenomenon},
	url = {https://bookstore.ams.org/surv-89-s},
	urldate = {2023-06-28},
}

@book{ledoux_probability_1991,
	location = {Berlin, Heidelberg},
	title = {Probability in Banach Spaces},
	isbn = {978-3-642-20211-7 978-3-642-20212-4},
	url = {http://link.springer.com/10.1007/978-3-642-20212-4},
	publisher = {Springer},
	author = {Ledoux, Michel and Talagrand, Michel},
	urldate = {2023-06-19},
	date = {1991},
	doi = {10.1007/978-3-642-20212-4},
	keywords = {Banach Space, Fourier series, Law of large numbers, Random variable, differential equation, entropy, law of the iterated logarithm, logarithm, measure},
}

@article{chen_time-varying_nodate,
	title = {Time-Varying Matrix Factor Model},
	abstract = {High-dimensional matrix-valued data are frequently encountered in finance and economics, such as international trade flow data covering multiple countries over an extended period. To account for potential structural changes and identify the underlying information context in the matrix structure, we propose a time-varying matrix factor model that allows for smooth changes in factor loadings over time. Our nonparametric principal component analysis ({PCA}) method uncovers the latent timevarying dynamic structure and achieves dimension reduction. We establish the consistency and asymptotic normality of our estimator under general conditions that account for correlations across time, rows, or columns of the noise. Our simulation study demonstrates the effectiveness of our proposed estimator. Using international trade flow data, we apply our model to investigate trading hubs, centrality, patterns, and trends in the trading network.},
	author = {Chen, Bin and Chen, Elynn Y and Chen, Rong},
	langid = {english},
}

@article{recht_simpler_2011,
	title = {A Simpler Approach to Matrix Completion},
	volume = {12},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v12/recht11a.html},
	abstract = {This paper provides the best bounds to date on the number of randomly sampled entries required to reconstruct an unknown low-rank matrix. These results improve on prior work by Candès and Recht (2009), Candès and Tao (2009), and Keshavan et al. (2009). The reconstruction is accomplished by minimizing the nuclear norm, or sum of the singular values, of the hidden matrix subject to agreement with the provided entries. If the underlying matrix satisfies a certain incoherence condition, then the number of entries required is equal to a quadratic logarithmic factor times the number of parameters in the singular value decomposition. The proof of this assertion is short, self contained, and uses very elementary analysis. The novel techniques herein are based on recent work in quantum information theory.},
	pages = {3413--3430},
	number = {104},
	journaltitle = {Journal of Machine Learning Research},
	author = {Recht, Benjamin},
	urldate = {2023-06-03},
	date = {2011},
}

@article{cai_max-norm_2013,
	title = {A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion},
	volume = {14},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v14/cai13b.html},
	abstract = {We consider in this paper the problem of noisy 1-bit matrix completion under a general non-uniform sampling distribution using the max-norm as a convex relaxation for the rank. A max- norm constrained maximum likelihood estimate is introduced and studied. The rate of convergence for the estimate is obtained. Information-theoretical methods are used to establish a minimax lower bound under the general sampling model. The minimax upper and lower bounds together yield the optimal rate of convergence for the Frobenius norm loss. Computational algorithms and numerical performance are also discussed.},
	pages = {3619--3647},
	number = {114},
	journaltitle = {Journal of Machine Learning Research},
	author = {Cai, Tony and Zhou, Wen-Xin},
	urldate = {2023-06-03},
	date = {2013},
}

@article{davenport_1-bit_2014,
	title = {1-Bit matrix completion},
	volume = {3},
	issn = {2049-8764},
	url = {https://doi.org/10.1093/imaiai/iau006},
	doi = {10.1093/imaiai/iau006},
	abstract = {In this paper, we develop a theory of matrix completion for the extreme case of noisy 1-bit observations. Instead of observing a subset of the real-valued entries of a matrix M, we obtain a small number of binary (1-bit) measurements generated according to a probability distribution determined by the real-valued entries of M. The central question we ask is whether or not it is possible to obtain an accurate estimate of M from this data. In general, this would seem impossible, but we show that the maximum likelihood estimate under a suitable constraint returns an accurate estimate of M when ∥M∥∞ ≤ α and rank(M) ≤ r. If the log-likelihood is a concave function (e.g. the logistic or probit observation models), then we can obtain this maximum likelihood estimate by optimizing a convex program. In addition, we also show that if instead of recovering M we simply wish to obtain an estimate of the distribution generating the 1-bit measurements, then we can eliminate the requirement that M when ∥M∥∞ ≤ α. For both cases, we provide lower bounds showing that these estimates are near-optimal. We conclude with a suite of experiments that both verify the implications of our theorems as well as illustrate some of the practical applications of 1-bit matrix completion. In particular, we compare our programme to standard matrix completion methods on movie rating data in which users submit ratings from 1 to 5. In order to use our program, we quantize this data to a single bit, but we allow the standard matrix completion program to have access to the original ratings (from 1 to 5). Surprisingly, the approach based on binary data performs significantly better.},
	pages = {189--223},
	number = {3},
	journaltitle = {Information and Inference: A Journal of the {IMA}},
	shortjournal = {Information and Inference: A Journal of the {IMA}},
	author = {Davenport, Mark A. and Plan, Yaniv and van den Berg, Ewout and Wootters, Mary},
	urldate = {2023-05-31},
	date = {2014-09-01},
}

@article{candes_exact_2009,
	title = {Exact Matrix Completion via Convex Optimization},
	volume = {9},
	issn = {1615-3383},
	url = {https://doi.org/10.1007/s10208-009-9045-5},
	doi = {10.1007/s10208-009-9045-5},
	abstract = {We consider a problem of considerable practical interest: the recovery of a data matrix from a sampling of its entries. Suppose that we observe m entries selected uniformly at random from a matrix M. Can we complete the matrix and recover the entries that we have not seen?},
	pages = {717--772},
	number = {6},
	journaltitle = {Foundations of Computational Mathematics},
	shortjournal = {Found Comput Math},
	author = {Candès, Emmanuel J. and Recht, Benjamin},
	urldate = {2023-05-31},
	date = {2009-12-01},
	langid = {english},
	keywords = {15A52, 90C25, 90C59, Compressed sensing, Convex optimization, Decoupling, Duality in optimization, Low-rank matrices, Matrix completion, Noncommutative Khintchine inequality, Nuclear norm minimization, Random matrices},
}

@book{gut_probability_2005,
	title = {Probability: a graduate course},
	volume = {5},
	publisher = {Springer},
	author = {Gut, Allan},
	date = {2005},
}

@article{baraud_estimator_2011,
	title = {Estimator selection with respect to Hellinger-type risks},
	volume = {151},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/s00440-010-0302-y},
	doi = {10.1007/s00440-010-0302-y},
	abstract = {We observe a random measure N and aim at estimating its intensity s. This statistical framework allows to deal simultaneously with the problems of estimating a density, the marginals of a multivariate distribution, the mean of a random vector with nonnegative components and the intensity of a Poisson process. Our estimation strategy is based on estimator selection. Given a family of estimators of s based on the observation of N, we propose a selection rule, based on N as well, in view of selecting among these. Little assumption is made on the collection of estimators and their dependency with respect to the observation N need not be known. The procedure offers the possibility to deal with various problems among which model selection, convex aggregation and construction of T-estimators as studied recently in Birgé (Ann Inst H Poincaré Probab Stat 42(3):273–325, 2006). For illustration, we shall consider the problems of estimation, complete variable selection and selection among linear estimators in possibly non-Gaussian regression settings.},
	pages = {353--401},
	number = {1},
	journaltitle = {Probability Theory and Related Fields},
	shortjournal = {Probab. Theory Relat. Fields},
	author = {Baraud, Yannick},
	urldate = {2023-05-17},
	date = {2011-10-01},
	langid = {english},
	keywords = {62G07, 62G35, 62J05, 62J12, Estimator aggregation, Estimator selection, Hellinger loss, Histogram, Model selection, Primary 62G05, Secondary 62C12, T-estimator, Variable selection},
}

@article{osborne_lasso_nodate,
	title = {On the {LASSO} and Its Dual},
	author = {Osborne, Michael R and Turlach, Berwin A},
	langid = {english},
}

@article{plan_robust_2013,
	title = {Robust 1-bit Compressed Sensing and Sparse Logistic Regression: A Convex Programming Approach},
	volume = {59},
	issn = {1557-9654},
	doi = {10.1109/TIT.2012.2207945},
	shorttitle = {Robust 1-bit Compressed Sensing and Sparse Logistic Regression},
	abstract = {This paper develops theoretical results regarding noisy 1-bit compressed sensing and sparse binomial regression. We demonstrate that a single convex program gives an accurate estimate of the signal, or coefficient vector, for both of these models. We show that an -sparse signal in can be accurately estimated from m = O(s log(n/s)) single-bit measurements using a simple convex program. This remains true even if each measurement bit is flipped with probability nearly 1/2. Worst-case (adversarial) noise can also be accounted for, and uniform results that hold for all sparse inputs are derived as well. In the terminology of sparse logistic regression, we show that O (s log (2n/s)) Bernoulli trials are sufficient to estimate a coefficient vector in which is approximately -sparse. Moreover, the same convex program works for virtually all generalized linear models, in which the link function may be unknown. To our knowledge, these are the first results that tie together the theory of sparse logistic regression to 1-bit compressed sensing. Our results apply to general signal structures aside from sparsity; one only needs to know the size of the set where signals reside. The size is given by the mean width of K, a computable quantity whose square serves as a robust extension of the dimension.},
	pages = {482--494},
	number = {1},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Plan, Yaniv and Vershynin, Roman},
	date = {2013-01},
	note = {Conference Name: {IEEE} Transactions on Information Theory},
	keywords = {Compressed sensing, Government, Logistics, Noise, Noise measurement, Standards, Vectors, data compression, parameter estimation, quantization, regression analysis, signal reconstruction},
}

@article{ai_one-bit_2014,
	title = {One-bit compressed sensing with non-Gaussian measurements},
	volume = {441},
	issn = {0024-3795},
	url = {https://www.sciencedirect.com/science/article/pii/S0024379513002450},
	doi = {10.1016/j.laa.2013.04.002},
	series = {Special Issue on Sparse Approximate Solution of Linear Systems},
	abstract = {In one-bit compressed sensing, previous results state that sparse signals may be robustly recovered when the measurements are taken using Gaussian random vectors. In contrast to standard compressed sensing, these results are not extendable to natural non-Gaussian distributions without further assumptions, as can be demonstrated by simple counter-examples involving extremely sparse signals. We show that approximately sparse signals that are not extremely sparse can be accurately reconstructed from single-bit measurements sampled according to a sub-gaussian distribution, and the reconstruction comes as the solution to a convex program.},
	pages = {222--239},
	journaltitle = {Linear Algebra and its Applications},
	shortjournal = {Linear Algebra and its Applications},
	author = {Ai, Albert and Lapanowski, Alex and Plan, Yaniv and Vershynin, Roman},
	urldate = {2023-05-08},
	date = {2014-01-15},
	langid = {english},
	keywords = {Convex programming, One-bit compressed sensing, Quantization, Signal reconstruction},
}

@article{deb_multivariate_2023,
	title = {Multivariate Rank-Based Distribution-Free Nonparametric Testing Using Measure Transportation},
	volume = {118},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2021.1923508},
	doi = {10.1080/01621459.2021.1923508},
	abstract = {In this article, we propose a general framework for distribution-free nonparametric testing in multi-dimensions, based on a notion of multivariate ranks defined using the theory of measure transportation. Unlike other existing proposals in the literature, these multivariate ranks share a number of useful properties with the usual one-dimensional ranks; most importantly, these ranks are distribution-free. This crucial observation allows us to design nonparametric tests that are exactly distribution-free under the null hypothesis. We demonstrate the applicability of this approach by constructing exact distribution-free tests for two classical nonparametric problems: (I) testing for mutual independence between random vectors, and ({II}) testing for the equality of multivariate distributions. In particular, we propose (multivariate) rank versions of distance covariance and energy statistic for testing scenarios (I) and ({II}), respectively. In both these problems, we derive the asymptotic null distribution of the proposed test statistics. We further show that our tests are consistent against all fixed alternatives. Moreover, the proposed tests are computationally feasible and are well-defined under minimal assumptions on the underlying distributions (e.g., they do not need any moment assumptions). We also demonstrate the efficacy of these procedures via extensive simulations. In the process of analyzing the theoretical properties of our procedures, we end up proving some new results in the theory of measure transportation and in the limit theory of permutation statistics using Stein’s method for exchangeable pairs, which may be of independent interest.},
	pages = {192--207},
	number = {541},
	journaltitle = {Journal of the American Statistical Association},
	author = {Deb, Nabarun and Sen, Bodhisattva},
	urldate = {2023-04-12},
	date = {2023-01-02},
	keywords = {Asymptotic null distribution, Consistency against fixed alternatives, Distance covariance, Distribution-free inference, Energy distance, Multivariate ranks, Multivariate two-sample testing, Quasi-Monte Carlo sequences, Stein’s method for exchangeable pairs, Testing for mutual independence},
}

@article{baraud_estimating_2009,
	title = {Estimating the intensity of a random measure by histogram type estimators},
	volume = {143},
	issn = {1432-2064},
	url = {https://doi.org/10.1007/s00440-007-0126-6},
	doi = {10.1007/s00440-007-0126-6},
	abstract = {The purpose of this paper is to estimate the intensity of some random measure N on a set \$\$\{{\textbackslash}mathcal\{X\}\}\$\$by a piecewise constant function on a finite partition of \$\$\{{\textbackslash}mathcal\{X\}\}\$\$. Given a (possibly large) family \$\$\{{\textbackslash}mathcal\{M\}\}\$\$of candidate partitions, we build a piecewise constant estimator (histogram) on each of them and then use the data to select one estimator in the family. Choosing the square of a Hellinger-type distance as our loss function, we show that each estimator built on a given partition satisfies an analogue of the classical squared bias plus variance risk bound. Moreover, the selection procedure leads to a final estimator satisfying some oracle-type inequality, with, as usual, a possible loss corresponding to the complexity of the family \$\$\{{\textbackslash}mathcal\{M\}\}\$\$. When this complexity is not too high, the selected estimator has a risk bounded, up to a universal constant, by the smallest risk bound obtained for the estimators in the family. For suitable choices of the family of partitions, we deduce uniform risk bounds over various classes of intensities. Our approach applies to the estimation of the intensity of an inhomogenous Poisson process, among other counting processes, or the estimation of the mean of a random vector with nonnegative components.},
	pages = {239--284},
	number = {1},
	journaltitle = {Probability Theory and Related Fields},
	shortjournal = {Probab. Theory Relat. Fields},
	author = {Baraud, Yannick and Birgé, Lucien},
	urldate = {2023-04-12},
	date = {2009-01-01},
	langid = {english},
	keywords = {62G05, Adaptive estimation, Discrete data, Histogram, Intensity estimation, Model selection, Poisson process},
}

@article{banerjee_pac-bayes_2021,
	title = {{PAC}-Bayes Bounds on Variational Tempered Posteriors for Markov Models},
	volume = {23},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/23/3/313},
	doi = {10.3390/e23030313},
	abstract = {Datasets displaying temporal dependencies abound in science and engineering applications, with Markov models representing a simplified and popular view of the temporal dependence structure. In this paper, we consider Bayesian settings that place prior distributions over the parameters of the transition kernel of a Markov model, and seek to characterize the resulting, typically intractable, posterior distributions. We present a Probably Approximately Correct ({PAC})-Bayesian analysis of variational Bayes ({VB}) approximations to tempered Bayesian posterior distributions, bounding the model risk of the {VB} approximations. Tempered posteriors are known to be robust to model misspecification, and their variational approximations do not suffer the usual problems of over confident approximations. Our results tie the risk bounds to the mixing and ergodic properties of the Markov data generating model. We illustrate the {PAC}-Bayes bounds through a number of example Markov models, and also consider the situation where the Markov model is misspecified.},
	pages = {313},
	number = {3},
	journaltitle = {Entropy},
	author = {Banerjee, Imon and Rao, Vinayak A. and Honnappa, Harsha},
	date = {2021-03},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Markov chain, ergodicity, probably approximately correct, variational Bayes},
}

@book{mishra_invexity_2008,
	location = {Berlin, Heidelberg},
	title = {Invexity and Optimization},
	volume = {88},
	isbn = {978-3-540-78561-3 978-3-540-78562-0},
	url = {http://link.springer.com/10.1007/978-3-540-78562-0},
	series = {Nonconvex Optimization and Its Applications},
	publisher = {Springer},
	author = {Mishra, Shashi Kant and Giorgi, Giorgio},
	editorb = {Pardalos, Panos},
	editorbtype = {redactor},
	urldate = {2023-04-06},
	date = {2008},
	doi = {10.1007/978-3-540-78562-0},
	keywords = {Duality, Generalized Convexity, Generalized Monotonicity, Invex Functions, Nonlinear Mathematical Programming, Optimality, Optimality Conditions, Vector Optimization, linear optimization, nonlinear optimization, optimization},
}

@misc{maity_meta-analysis_2022,
	title = {Meta-analysis of heterogeneous data: integrative sparse regression in high-dimensions},
	url = {http://arxiv.org/abs/1912.11928},
	shorttitle = {Meta-analysis of heterogeneous data},
	abstract = {We consider the task of meta-analysis in high-dimensional settings in which the data sources are similar but non-identical. To borrow strength across such heterogeneous datasets, we introduce a global parameter that emphasizes interpretability and statistical eﬃciency in the presence of heterogeneity. We also propose a one-shot estimator of the global parameter that preserves the anonymity of the data sources and converges at a rate that depends on the size of the combined dataset. For high-dimensional linear model settings, we demonstrate the superiority of our identiﬁcation restrictions in adapting to a previously seen data distribution as well as predicting for a new/unseen data distribution. Finally, we demonstrate the beneﬁts of our approach on a large-scale drug treatment dataset involving several diﬀerent cancer cell-lines1.},
	number = {{arXiv}:1912.11928},
	publisher = {{arXiv}},
	author = {Maity, Subha and Sun, Yuekai and Banerjee, Moulinath},
	urldate = {2022-10-31},
	date = {2022-06-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1912.11928},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
}

@misc{deb_multivariate_2019,
	title = {Multivariate Rank-based Distribution-free Nonparametric Testing using Measure Transportation},
	url = {http://arxiv.org/abs/1909.08733},
	doi = {10.48550/arXiv.1909.08733},
	abstract = {In this paper, we propose a general framework for distribution-free nonparametric testing in multi-dimensions, based on a notion of multivariate ranks defined using the theory of measure transportation. Unlike other existing proposals in the literature, these multivariate ranks share a number of useful properties with the usual one-dimensional ranks; most importantly, these ranks are distribution-free. This crucial observation allows us to design nonparametric tests that are exactly distribution-free under the null hypothesis. We demonstrate the applicability of this approach by constructing exact distribution-free tests for two classical nonparametric problems: (i) testing for mutual independence between random vectors, and (ii) testing for the equality of multivariate distributions. In particular, we propose (multivariate) rank versions of distance covariance (Sz{\textbackslash}'ekely et al., 2007) and energy statistic (Sz{\textbackslash}'ekely and Rizzo, 2013) for testing scenarios (i) and (ii) respectively. In both these problems, we derive the asymptotic null distribution of the proposed test statistics. We further show that our tests are consistent against all fixed alternatives. Moreover, the proposed tests are tuning-free, computationally feasible and are well-defined under minimal assumptions on the underlying distributions (e.g., they do not need any moment assumptions). We also demonstrate the efficacy of these procedures via extensive simulations. In the process of analyzing the theoretical properties of our procedures, we end up proving some new results in the theory of measure transportation and in the limit theory of permutation statistics using Stein's method for exchangeable pairs, which may be of independent interest.},
	number = {{arXiv}:1909.08733},
	publisher = {{arXiv}},
	author = {Deb, Nabarun and Sen, Bodhisattva},
	urldate = {2023-04-06},
	date = {2019-10-04},
	eprinttype = {arxiv},
	eprint = {1909.08733},
	keywords = {62G30, 62G10, 62G20, Mathematics - Statistics Theory, Statistics - Methodology},
}

@misc{loffler_spectral_2021,
	title = {Spectral thresholding for the estimation of Markov chain transition operators},
	url = {http://arxiv.org/abs/1808.08153},
	doi = {10.48550/arXiv.1808.08153},
	abstract = {We consider nonparametric estimation of the transition operator \$P\$ of a Markov chain and its transition density \$p\$ where the singular values of \$P\$ are assumed to decay exponentially fast. This is for instance the case for periodised, reversible multi-dimensional diffusion processes observed in low frequency. We investigate the performance of a spectral hard thresholded Galerkin-type estimator for \$P\$ and \$\{p\}\$, discarding most of the estimated singular triplets. The construction is based on smooth basis functions such as wavelets or B-splines. We show its statistical optimality by establishing matching minimax upper and lower bounds in \$L{\textasciicircum}2\$-loss. Particularly, the effect of the dimensionality \$d\$ of the state space on the nonparametric rate improves from \$2d\$ to \$d\$ compared to the case without singular value decay.},
	number = {{arXiv}:1808.08153},
	publisher = {{arXiv}},
	author = {Löffler, Matthias and Picard, Antoine},
	urldate = {2022-11-15},
	date = {2021-10-25},
	eprinttype = {arxiv},
	eprint = {1808.08153},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
}

@misc{phan_thompson_2020,
	title = {Thompson Sampling with Approximate Inference},
	url = {http://arxiv.org/abs/1908.04970},
	doi = {10.48550/arXiv.1908.04970},
	abstract = {We study the effects of approximate inference on the performance of Thompson sampling in the \$k\$-armed bandit problems. Thompson sampling is a successful algorithm for online decision-making but requires posterior inference, which often must be approximated in practice. We show that even small constant inference error (in \${\textbackslash}alpha\$-divergence) can lead to poor performance (linear regret) due to under-exploration (for \${\textbackslash}alpha{\textless}1\$) or over-exploration (for \${\textbackslash}alpha{\textgreater}0\$) by the approximation. While for \${\textbackslash}alpha {\textgreater} 0\$ this is unavoidable, for \${\textbackslash}alpha {\textbackslash}leq 0\$ the regret can be improved by adding a small amount of forced exploration even when the inference error is a large constant.},
	number = {{arXiv}:1908.04970},
	publisher = {{arXiv}},
	author = {Phan, My and Abbasi-Yadkori, Yasin and Domke, Justin},
	urldate = {2022-11-15},
	date = {2020-01-14},
	eprinttype = {arxiv},
	eprint = {1908.04970},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{lambert_challenges_2022,
	title = {The Challenges of Exploration for Offline Reinforcement Learning},
	url = {http://arxiv.org/abs/2201.11861},
	abstract = {Ofﬂine Reinforcement Learning ({ORL}) enables us to separately study the two interlinked processes of reinforcement learning: collecting informative experience and inferring optimal behaviour. The second step has been widely studied in the ofﬂine setting, but just as critical to data-efﬁcient {RL} is the collection of informative data. The task-agnostic setting for data collection, where the task is not known a priori, is of particular interest due to the possibility of collecting a single dataset and using it to solve several downstream tasks as they arise. We investigate this setting via curiosity-based intrinsic motivation, a family of exploration methods which encourage the agent to explore those states or transitions it has not yet learned to model. With Explore2Ofﬂine, we propose to evaluate the quality of collected data by transferring the collected data and inferring policies with reward relabelling and standard ofﬂine {RL} algorithms. We evaluate a wide variety of data collection strategies, including a new exploration agent, Intrinsic Model Predictive Control ({IMPC}), using this scheme and demonstrate their performance on various tasks. We use this decoupled framework to strengthen intuitions about exploration and the data prerequisites for effective ofﬂine {RL}.},
	number = {{arXiv}:2201.11861},
	publisher = {{arXiv}},
	author = {Lambert, Nathan and Wulfmeier, Markus and Whitney, William and Byravan, Arunkumar and Bloesch, Michael and Dasagi, Vibhavari and Hertweck, Tim and Riedmiller, Martin},
	urldate = {2023-04-05},
	date = {2022-02-18},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2201.11861},
	keywords = {Computer Science - Machine Learning},
}

@misc{wang_sample-efficient_2022,
	title = {Sample-Efficient Reinforcement Learning for Linearly-Parameterized {MDPs} with a Generative Model},
	url = {http://arxiv.org/abs/2105.14016},
	abstract = {The curse of dimensionality is a widely known issue in reinforcement learning ({RL}). In the tabular setting where the state space \${\textbackslash}mathcal\{S\}\$ and the action space \${\textbackslash}mathcal\{A\}\$ are both finite, to obtain a nearly optimal policy with sampling access to a generative model, the minimax optimal sample complexity scales linearly with \${\textbar}{\textbackslash}mathcal\{S\}{\textbar}{\textbackslash}times{\textbar}{\textbackslash}mathcal\{A\}{\textbar}\$, which can be prohibitively large when \${\textbackslash}mathcal\{S\}\$ or \${\textbackslash}mathcal\{A\}\$ is large. This paper considers a Markov decision process ({MDP}) that admits a set of state-action features, which can linearly express (or approximate) its probability transition kernel. We show that a model-based approach (resp.\${\textasciitilde}\$Q-learning) provably learns an \${\textbackslash}varepsilon\$-optimal policy (resp.\${\textasciitilde}\$Q-function) with high probability as soon as the sample size exceeds the order of \${\textbackslash}frac\{K\}\{(1-{\textbackslash}gamma){\textasciicircum}\{3\}{\textbackslash}varepsilon{\textasciicircum}\{2\}\}\$ (resp.\${\textasciitilde}\$\${\textbackslash}frac\{K\}\{(1-{\textbackslash}gamma){\textasciicircum}\{4\}{\textbackslash}varepsilon{\textasciicircum}\{2\}\}\$), up to some logarithmic factor. Here \$K\$ is the feature dimension and \${\textbackslash}gamma{\textbackslash}in(0,1)\$ is the discount factor of the {MDP}. Both sample complexity bounds are provably tight, and our result for the model-based approach matches the minimax lower bound. Our results show that for arbitrarily large-scale {MDP}, both the model-based approach and Q-learning are sample-efficient when \$K\$ is relatively small, and hence the title of this paper.},
	number = {{arXiv}:2105.14016},
	publisher = {{arXiv}},
	author = {Wang, Bingyan and Yan, Yuling and Fan, Jianqing},
	urldate = {2022-11-01},
	date = {2022-10-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2105.14016},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Mathematics - Optimization and Control, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@misc{mazumdar_thompson_2020,
	title = {On Thompson Sampling with Langevin Algorithms},
	url = {http://arxiv.org/abs/2002.10002},
	abstract = {Thompson sampling for multi-armed bandit problems is known to enjoy favorable performance in both theory and practice. However, it suﬀers from a signiﬁcant limitation computationally, arising from the need for samples from posterior distributions at every iteration. We propose two Markov Chain Monte Carlo ({MCMC}) methods tailored to Thompson sampling to address this issue. We construct quickly converging Langevin algorithms to generate approximate samples that have accuracy guarantees, and we leverage novel posterior concentration rates to analyze the regret of the resulting approximate Thompson sampling algorithm. Further, we specify the necessary hyperparameters for the {MCMC} procedure to guarantee optimal instance-dependent frequentist regret while having low computational complexity. In particular, our algorithms take advantage of both posterior concentration and a sample reuse mechanism to ensure that only a constant number of iterations and a constant amount of data is needed in each round. The resulting approximate Thompson sampling algorithm has logarithmic regret and its computational complexity does not scale with the time horizon of the algorithm.},
	number = {{arXiv}:2002.10002},
	publisher = {{arXiv}},
	author = {Mazumdar, Eric and Pacchiano, Aldo and Ma, Yi-an and Bartlett, Peter L. and Jordan, Michael I.},
	urldate = {2022-11-15},
	date = {2020-06-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2002.10002},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{banerjee_offline_2022,
	title = {Offline Estimation of Controlled Markov Chains: Minimax Nonparametric Estimators and Sample Efficiency},
	url = {http://arxiv.org/abs/2211.07092},
	shorttitle = {Offline Estimation of Controlled Markov Chains},
	abstract = {Controlled Markov chains ({CMCs}) have wide applications in engineering and machine learning, forming a key component in many reinforcement learning problems. In this work, we consider the estimation of the transition probabilities of a finite-state finite-control {CMC}, and develop a minimax sample complexity bounds for nonparametric estimation of these transition probability matrices. Unlike most studies that have been done in the online setup, we consider offline {MDPs}. Our results are quite general, since we do not assume anything specific about the logging policy. Instead, the dependence of our statistical bounds on the logging policy comes in the form of a natural mixing coefficient. We demonstrate an interesting trade-off between stronger assumptions on mixing versus requiring more samples to achieve a particular {PAC}-bound. We demonstrate the validity of our results under various examples, like ergodic Markov chains, weakly ergodic inhomogenous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use the properties of the estimated transition matrix to perform estimate the value function when the controls are stationary and Markov.},
	number = {{arXiv}:2211.07092},
	publisher = {{arXiv}},
	author = {Banerjee, Imon and Honnappa, Harsha and Rao, Vinayak},
	urldate = {2022-11-15},
	date = {2022-11-13},
	eprinttype = {arxiv},
	eprint = {2211.07092},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@misc{ryabko_nonparametric_2012,
	title = {Nonparametric Statistical Inference for Ergodic Processes},
	url = {http://arxiv.org/abs/0804.0510},
	abstract = {In this work a method for statistical analysis of time series is proposed, which is used to obtain solutions to some classical problems of mathematical statistics under the only assumption that the process generating the data is stationary ergodic. Namely, three problems are considered: goodness-of-ﬁt (or identity) testing, process classiﬁcation, and the change point problem. For each of the problems a test is constructed that is asymptotically accurate for the case when the data is generated by stationary ergodic processes. The tests are based on empirical estimates of distributional distance.},
	number = {{arXiv}:0804.0510},
	publisher = {{arXiv}},
	author = {Ryabko, Daniil and Ryabko, Boris},
	urldate = {2023-04-06},
	date = {2012-04-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {0804.0510},
	keywords = {Computer Science - Information Theory, Mathematics - Statistics Theory},
}

@misc{canonne_near-optimal_2022,
	title = {Near-Optimal Bounds for Testing Histogram Distributions},
	url = {http://arxiv.org/abs/2207.06596},
	abstract = {We investigate the problem of testing whether a discrete probability distribution over an ordered domain is a histogram on a specified number of bins. One of the most common tools for the succinct approximation of data, \$k\$-histograms over \$[n]\$, are probability distributions that are piecewise constant over a set of \$k\$ intervals. The histogram testing problem is the following: Given samples from an unknown distribution \${\textbackslash}mathbf\{p\}\$ on \$[n]\$, we want to distinguish between the cases that \${\textbackslash}mathbf\{p\}\$ is a \$k\$-histogram versus \${\textbackslash}varepsilon\$-far from any \$k\$-histogram, in total variation distance. Our main result is a sample near-optimal and computationally efficient algorithm for this testing problem, and a nearly-matching (within logarithmic factors) sample complexity lower bound. Specifically, we show that the histogram testing problem has sample complexity \${\textbackslash}widetilde {\textbackslash}Theta ({\textbackslash}sqrt\{nk\} / {\textbackslash}varepsilon + k / {\textbackslash}varepsilon{\textasciicircum}2 + {\textbackslash}sqrt\{n\} / {\textbackslash}varepsilon{\textasciicircum}2)\$.},
	number = {{arXiv}:2207.06596},
	publisher = {{arXiv}},
	author = {Canonne, Clément L. and Diakonikolas, Ilias and Kane, Daniel M. and Liu, Sihan},
	urldate = {2022-11-01},
	date = {2022-07-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2207.06596},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Mathematics - Statistics Theory},
}

@misc{banerjee_meta_2022,
	title = {Meta Sparse Principal Component Analysis},
	url = {http://arxiv.org/abs/2208.08938},
	abstract = {We study the meta-learning for support (i.e. the set of non-zero entries) recovery in high-dimensional Principal Component Analysis. We reduce the sufficient sample complexity in a novel task with the information that is learned from auxiliary tasks. We assume each task to be a different random Principal Component ({PC}) matrix with a possibly different support and that the support union of the {PC} matrices is small. We then pool the data from all the tasks to execute an improper estimation of a single {PC} matrix by maximising the \$l\_1\$-regularised predictive covariance to establish that with high probability the true support union can be recovered provided a sufficient number of tasks \$m\$ and a sufficient number of samples \$ O{\textbackslash}left({\textbackslash}frac\{{\textbackslash}log(p)\}\{m\}{\textbackslash}right)\$ for each task, for \$p\$-dimensional vectors. Then, for a novel task, we prove that the maximisation of the \$l\_1\$-regularised predictive covariance with the additional constraint that the support is a subset of the estimated support union could reduce the sufficient sample complexity of successful support recovery to \$O({\textbackslash}log {\textbar}J{\textbar})\$, where \$J\$ is the support union recovered from the auxiliary tasks. Typically, \${\textbar}J{\textbar}\$ would be much less than \$p\$ for sparse matrices. Finally, we demonstrate the validity of our experiments through numerical simulations.},
	number = {{arXiv}:2208.08938},
	publisher = {{arXiv}},
	author = {Banerjee, Imon and Honorio, Jean},
	urldate = {2022-10-31},
	date = {2022-08-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2208.08938},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{makhlouf_machine_2021,
	title = {Machine learning fairness notions: Bridging the gap with real-world applications},
	volume = {58},
	issn = {03064573},
	url = {http://arxiv.org/abs/2006.16745},
	doi = {10.1016/j.ipm.2021.102642},
	shorttitle = {Machine learning fairness notions},
	abstract = {Fairness emerged as an important requirement to guarantee that Machine Learning ({ML}) predictive systems do not discriminate against speciﬁc individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey that illustrates the subtleties between fairness notions through a large number of examples and scenarios. In addition, unlike other surveys in the literature, it addresses the question of “which notion of fairness is most suited to a given real-world scenario and why?”. Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) ﬁtting these two elements to recommend the most suitable fairness notion in every speciﬁc setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of {ML} fairness notions.},
	pages = {102642},
	number = {5},
	journaltitle = {Information Processing \& Management},
	shortjournal = {Information Processing \& Management},
	author = {Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
	urldate = {2023-03-21},
	date = {2021-09},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2006.16745},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{barik_fair_2021,
	title = {Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem},
	url = {http://arxiv.org/abs/2102.09704},
	shorttitle = {Fair Sparse Regression with Clustering},
	abstract = {In this paper, we study the problem of fair sparse regression on a biased dataset where bias depends upon a hidden binary attribute. The presence of a hidden attribute adds an extra layer of complexity to the problem by combining sparse regression and clustering with unknown binary labels. The corresponding optimization problem is combinatorial, but we propose a novel relaxation of it as an invex optimization problem. To the best of our knowledge, this is the ﬁrst invex relaxation for a combinatorial problem. We show that the inclusion of the debiasing/fairness constraint in our model has no adverse eﬀect on the performance. Rather, it enables the recovery of the hidden attribute. The support of our recovered regression parameter vector matches exactly with the true parameter vector. Moreover, we simultaneously solve the clustering problem by recovering the exact value of the hidden attribute for each sample. Our method uses carefully constructed primal dual witnesses to provide theoretical guarantees for the combinatorial problem. To that end, we show that the sample complexity of our method is logarithmic in terms of the dimension of the regression parameter vector.},
	number = {{arXiv}:2102.09704},
	publisher = {{arXiv}},
	author = {Barik, Adarsh and Honorio, Jean},
	urldate = {2022-11-15},
	date = {2021-06-14},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2102.09704},
	keywords = {Computer Science - Machine Learning},
}

@misc{chan_efficient_2013,
	title = {Efficient Density Estimation via Piecewise Polynomial Approximation},
	url = {http://arxiv.org/abs/1305.3207},
	abstract = {We give a highly efficient "semi-agnostic" algorithm for learning univariate probability distributions that are well approximated by piecewise polynomial density functions. Let \$p\$ be an arbitrary distribution over an interval \$I\$ which is \${\textbackslash}tau\$-close (in total variation distance) to an unknown probability distribution \$q\$ that is defined by an unknown partition of \$I\$ into \$t\$ intervals and \$t\$ unknown degree-\$d\$ polynomials specifying \$q\$ over each of the intervals. We give an algorithm that draws \${\textbackslash}tilde\{O\}(t{\textbackslash}new\{(d+1)\}/{\textbackslash}eps{\textasciicircum}2)\$ samples from \$p\$, runs in time \${\textbackslash}poly(t,d,1/{\textbackslash}eps)\$, and with high probability outputs a piecewise polynomial hypothesis distribution \$h\$ that is \$(O({\textbackslash}tau)+{\textbackslash}eps)\$-close (in total variation distance) to \$p\$. This sample complexity is essentially optimal; we show that even for \${\textbackslash}tau=0\$, any algorithm that learns an unknown \$t\$-piecewise degree-\$d\$ probability distribution over \$I\$ to accuracy \${\textbackslash}eps\$ must use \${\textbackslash}Omega(\{{\textbackslash}frac \{t(d+1)\} \{{\textbackslash}poly(1 + {\textbackslash}log(d+1))\}\} {\textbackslash}cdot \{{\textbackslash}frac 1 \{{\textbackslash}eps{\textasciicircum}2\}\})\$ samples from the distribution, regardless of its running time. Our algorithm combines tools from approximation theory, uniform convergence, linear programming, and dynamic programming. We apply this general algorithm to obtain a wide range of results for many natural problems in density estimation over both continuous and discrete domains. These include state-of-the-art results for learning mixtures of log-concave distributions; mixtures of \$t\$-modal distributions; mixtures of Monotone Hazard Rate distributions; mixtures of Poisson Binomial Distributions; mixtures of Gaussians; and mixtures of \$k\$-monotone densities. Our general technique yields computationally efficient algorithms for all these problems, in many cases with provably optimal sample complexities (up to logarithmic factors) in all parameters.},
	number = {{arXiv}:1305.3207},
	publisher = {{arXiv}},
	author = {Chan, Siu-On and Diakonikolas, Ilias and Servedio, Rocco A. and Sun, Xiaorui},
	urldate = {2022-11-01},
	date = {2013-05-14},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1305.3207},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhang_concentration_2021,
	title = {Concentration Inequalities for Statistical Inference},
	volume = {37},
	issn = {1674-5647, 2707-8523},
	url = {http://arxiv.org/abs/2011.02258},
	doi = {10.4208/cmr.2020-0041},
	abstract = {This paper gives a review of concentration inequalities which are widely employed in non-asymptotical analyses of mathematical statistics in a wide range of settings, from distribution-free to distribution-dependent, from sub-Gaussian to sub-exponential, sub-Gamma, and sub-Weibull random variables, and from the mean to the maximum concentration. This review provides results in these settings with some fresh new results. Given the increasing popularity of high-dimensional data and inference, results in the context of high-dimensional linear and Poisson regressions are also provided. We aim to illustrate the concentration inequalities with known constants and to improve existing bounds with sharper constants.},
	pages = {1--85},
	number = {1},
	journaltitle = {Communications in Mathematical Research},
	shortjournal = {{CMR}},
	author = {Zhang, Huiming and Chen, Song Xi},
	urldate = {2023-04-06},
	date = {2021-06},
	eprinttype = {arxiv},
	eprint = {2011.02258},
	keywords = {60F10, 60G50, 62E17, Computer Science - Machine Learning, Mathematics - Probability, Mathematics - Statistics Theory, Statistics - Machine Learning},
}

@book{villani_optimal_2009,
	location = {Berlin, Heidelberg},
	title = {Optimal Transport},
	volume = {338},
	url = {http://link.springer.com/10.1007/978-3-540-71050-9},
	series = {Grundlehren der mathematischen Wissenschaften},
	publisher = {Springer},
	author = {Villani, Cédric},
	editorb = {Berger, M. and Eckmann, B. and de la Harpe, P. and Hirzebruch, F. and Hitchin, N. and Hörmander, L. and Kupiainen, A. and Lebeau, G. and Ratner, M. and Serre, D. and Sinai, Ya. G. and Sloane, N. J. A. and Vershik, A. M. and Waldschmidt, M.},
	editorbtype = {redactor},
	urldate = {2023-04-05},
	date = {2009},
	doi = {10.1007/978-3-540-71050-9},
	keywords = {Monge-Kantorovich problem, Optimal transport, Riemannian geometry, curvature, dynamical systems, partial differential equations},
}

@article{borkar_topics_1991,
	title = {Topics in controlled Markov chains},
	author = {Borkar, Vivek S},
	date = {1991},
	note = {Publisher: Longman Scientific \& Technical Harlow},
}

@inproceedings{barik_sparse_2022,
	title = {Sparse Mixed Linear Regression with Guarantees: Taming an Intractable Problem with Invex Relaxation},
	url = {https://proceedings.mlr.press/v162/barik22a.html},
	shorttitle = {Sparse Mixed Linear Regression with Guarantees},
	abstract = {In this paper, we study the problem of sparse mixed linear regression on an unlabeled dataset that is generated from linear measurements from two different regression parameter vectors. Since the data is unlabeled, our task is to not only figure out a good approximation of regression parameter vectors but also label the dataset correctly. In its original form, this problem is {NP}-hard. The most popular algorithms to solve this problem (such as Expectation-Maximization) have a tendency to stuck at local minima. We provide a novel invex relaxation for this intractable problem which leads to a solution with provable theoretical guarantees. This relaxation enables exact recovery of data labels. Furthermore, we recover close approximation of regression parameter vectors which match the true parameter vectors in support and sign. Our formulation uses a carefully constructed primal dual witnesses framework for the invex problem. Furthermore, we show that the sample complexity of our method is only logarithmic in terms of the dimension of the regression parameter vectors.},
	eventtitle = {International Conference on Machine Learning},
	pages = {1627--1646},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Barik, Adarsh and Honorio, Jean},
	urldate = {2023-04-06},
	date = {2022-06-28},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}

@article{ghosal_convergence_2007,
	title = {Convergence rates of posterior distributions for noniid observations},
	volume = {35},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-35/issue-1/Convergence-rates-of-posterior-distributions-for-noniid-observations/10.1214/009053606000001172.full},
	doi = {10.1214/009053606000001172},
	abstract = {We consider the asymptotic behavior of posterior distributions and Bayes estimators based on observations which are required to be neither independent nor identically distributed. We give general results on the rate of convergence of the posterior measure relative to distances derived from a testing criterion. We then specialize our results to independent, nonidentically distributed observations, Markov processes, stationary Gaussian time series and the white noise model. We apply our general results to several examples of infinite-dimensional statistical models including nonparametric regression with normal errors, binary regression, Poisson regression, an interval censoring model, Whittle estimation of the spectral density of a time series and a nonlinear autoregressive model.},
	pages = {192--223},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Ghosal, Subhashis and Vaart, Aad van der},
	urldate = {2023-04-06},
	date = {2007-02},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G08, 62G20, Hellinger distance, Infinite dimensional model, Markov chains, covering numbers, independent nonidentically distributed observations, posterior distribution, rate of convergence, tests},
}

@article{ghosal_convergence_2000,
	title = {Convergence rates of posterior distributions},
	volume = {28},
	pages = {500--531},
	number = {2},
	journaltitle = {Annals of Statistics},
	author = {Ghosal, Subhashis and Ghosh, Jayanta K and Van Der Vaart, Aad W},
	date = {2000},
	note = {Publisher: {IMS} {INSTITUTE} {OF} {MATHEMATICAL} {STATISTICS}},
}

@article{shalizi_dynamics_2009,
	title = {Dynamics of Bayesian updating with dependent data and misspecified models},
	volume = {3},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-3/issue-none/Dynamics-of-Bayesian-updating-with-dependent-data-and-misspecified-models/10.1214/09-EJS485.full},
	doi = {10.1214/09-EJS485},
	abstract = {Much is now known about the consistency of Bayesian updating on infinite-dimensional parameter spaces with independent or Markovian data. Necessary conditions for consistency include the prior putting enough weight on the correct neighborhoods of the data-generating distribution; various sufficient conditions further restrict the prior in ways analogous to capacity control in frequentist nonparametrics. The asymptotics of Bayesian updating with mis-specified models or priors, or non-Markovian data, are far less well explored. Here I establish sufficient conditions for posterior convergence when all hypotheses are wrong, and the data have complex dependencies. The main dynamical assumption is the asymptotic equipartition (Shannon-{McMillan}-Breiman) property of information theory. This, along with Egorov’s Theorem on uniform convergence, lets me build a sieve-like structure for the prior. The main statistical assumption, also a form of capacity control, concerns the compatibility of the prior and the data-generating process, controlling the fluctuations in the log-likelihood when averaged over the sieve-like sets. In addition to posterior convergence, I derive a kind of large deviations principle for the posterior measure, extending in some cases to rates of convergence, and discuss the advantages of predicting using a combination of models known to be wrong. An appendix sketches connections between these results and the replicator dynamics of evolutionary theory.},
	pages = {1039--1074},
	issue = {none},
	journaltitle = {Electronic Journal of Statistics},
	author = {Shalizi, Cosma Rohilla},
	urldate = {2023-04-06},
	date = {2009-01},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {60F10, 62C10, 62G20, 62M05, 62M09, 92D15, 94A17, Asymptotic equipartition, Bayesian consistency, Bayesian nonparametrics, Egorov’s theorem, large deviations, posterior convergence, replicator dynamics, sofic systems},
}

@article{ghosal_multivariate_2022,
	title = {Multivariate ranks and quantiles using optimal transport: Consistency, rates and nonparametric testing},
	volume = {50},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-50/issue-2/Multivariate-ranks-and-quantiles-using-optimal-transport--Consistency-rates/10.1214/21-AOS2136.full},
	doi = {10.1214/21-AOS2136},
	shorttitle = {Multivariate ranks and quantiles using optimal transport},
	abstract = {In this paper, we study multivariate ranks and quantiles, defined using the theory of optimal transport, and build on the work of Chernozhukov et al. (Ann. Statist. 45 (2017) 223–256) and Hallin et al. (Ann. Statist. 49 (2021) 1139–1165). We study the characterization, computation and properties of the multivariate rank and quantile functions and their empirical counterparts. We derive the uniform consistency of these empirical estimates to their population versions, under certain assumptions. In fact, we prove a Glivenko–Cantelli type theorem that shows the asymptotic stability of the empirical rank map in any direction. Under mild structural assumptions, we provide global and local rates of convergence of the empirical quantile and rank maps. We also provide a sub-Gaussian tail bound for the global L2-loss of the empirical quantile function. Further, we propose tuning parameter-free multivariate nonparametric tests—a two-sample test and a test for mutual independence—based on our notion of multivariate quantiles/ranks. Asymptotic consistency of these tests are shown and the rates of convergence of the associated test statistics are derived, both under the null and alternative hypotheses.},
	pages = {1012--1037},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Ghosal, Promit and Sen, Bodhisattva},
	urldate = {2023-04-06},
	date = {2022-04},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {35J96, 60F15, 62G20, 62G30, Brenier–{McCann}’s theorem, Glivenko–Cantelli type theorem, Legendre–Fenchel dual, convergence of subdifferentials of convex functions, local uniform rate of convergence, semidiscrete optimal transport, testing mutual independence, two-sample goodness-of-fit testing},
}

@article{lacour_adaptive_2007,
	title = {Adaptive estimation of the transition density of a Markov chain},
	volume = {43},
	issn = {02460203},
	url = {http://arxiv.org/abs/math/0611680},
	doi = {10.1016/j.anihpb.2006.09.003},
	abstract = {In this paper a new estimator for the transition density \${\textbackslash}pi\$ of an homogeneous Markov chain is considered. We introduce an original contrast derived from regression framework and we use a model selection method to estimate \${\textbackslash}pi\$ under mild conditions. The resulting estimate is adaptive with an optimal rate of convergence over a large range of anisotropic Besov spaces \$B\_\{2,{\textbackslash}infty\}{\textasciicircum}\{({\textbackslash}alpha\_1,{\textbackslash}alpha\_2)\}\$. Some simulations are also presented.},
	pages = {571--597},
	number = {5},
	journaltitle = {Annales de l'Institut Henri Poincare (B) Probability and Statistics},
	shortjournal = {Annales de l'Institut Henri Poincare (B) Probability and Statistics},
	author = {Lacour, Claire},
	urldate = {2022-12-12},
	date = {2007-09},
	eprinttype = {arxiv},
	eprint = {math/0611680},
	keywords = {62G05, 62H12, 62M05, Adaptive estimation, Markov chain, Mathematics - Statistics Theory, Model selection, Penalized contrast, Transition density},
}

@article{schrage_queue_1966,
	title = {The Queue M/G/1 with the Shortest Remaining Processing Time Discipline},
	volume = {14},
	issn = {0030-364X},
	url = {https://www.jstor.org/stable/168730},
	abstract = {A priority queuing model in which the processing times of jobs are known upon arrival and preemption without loss of time or processing already accomplished is studied. Priority is assigned to jobs according to the length of processing remaining with highest priority going to the job with least processing left. A preemption will occur whenever the processing time of a newly arriving job is less than the remaining processing time of the job then in service. The Laplace-Stieltjes transforms of the waiting time and time-in-system distributions are obtained and comparisons with other queuing disciplines are made.},
	pages = {670--684},
	number = {4},
	journaltitle = {Operations Research},
	author = {Schrage, Linus E. and Miller, Louis W.},
	urldate = {2023-04-05},
	date = {1966},
	note = {Publisher: {INFORMS}},
}

@article{birge_robust_2013,
	title = {Robust tests for model selection},
	volume = {9},
	url = {https://projecteuclid.org/ebooks/institute-of-mathematical-statistics-collections/From-Probability-to-Statistics-and-Back--High-Dimensional-Models/chapter/Robust-tests-for-model-selection/10.1214/12-IMSCOLL905},
	doi = {10.1214/12-IMSCOLL905},
	abstract = {{\textless}!-- *** Custom {HTML} *** --{\textgreater}{\textless}p{\textgreater}It was shown almost 40 years ago by Lucien Le Cam that the existence of suitable tests between Hellinger balls in the parameter set led to the construction of some sort of universal estimators for parametric statistical problems with i.i.d. observations. This idea of deriving estimators from families of robust tests was developed and substantially generalized in some of my previous work and more recently extended to Model Selection based estimation. Since the key ingredient for the design of such estimators for a given statistical framework is the construction of the relevant tests for this particular framework, it is essential to explain how to build them for as many different frameworks as possible. The purpose of this paper is to provide improved results about the existence of such tests for the problems of estimation based on independent (not necessarily i.i.d.) observations, estimation of conditional densities and of Markov transitions.{\textless}/p{\textgreater}},
	pages = {47--65},
	journaltitle = {From Probability to Statistics and Back: High-Dimensional Models and Processes -- A Festschrift in Honor of Jon A. Wellner},
	author = {Birgé, Lucien},
	urldate = {2023-04-05},
	date = {2013-01-01},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{akakpo_inhomogeneous_2011,
	title = {Inhomogeneous and anisotropic conditional density estimation from dependent data},
	volume = {5},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-5/issue-none/Inhomogeneous-and-anisotropic-conditional-density-estimation-from-dependent-data/10.1214/11-EJS653.full},
	doi = {10.1214/11-EJS653},
	abstract = {The problem of estimating a conditional density is considered. Given a collection of partitions, we propose a procedure that selects from the data the best partition among that collection and then provides the best piecewise polynomial estimator built on that partition. The observations are not supposed to be independent but only β-mixing; in particular, our study includes the estimation of the transition density of a Markov chain. For a well-chosen collection of possibly irregular partitions, we obtain oracle-type inequalities and adaptivity results in the minimax sense over a wide range of possibly anisotropic and inhomogeneous Besov classes. We end with a short simulation study.},
	pages = {1618--1653},
	issue = {none},
	journaltitle = {Electronic Journal of Statistics},
	author = {Akakpo, Nathalie and Lacour, Claire},
	urldate = {2023-04-05},
	date = {2011-01},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {62G05, 62H12, 62M05, 62M09, Anisotropy, Conditional density, Model selection, adaptive estimation, dependent data},
}

@inproceedings{yin_optimal_2021,
	title = {Optimal Uniform {OPE} and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings},
	url = {https://openreview.net/forum?id=yMf3SLah5-y},
	abstract = {This work studies the statistical limits of uniform convergence for offline policy evaluation ({OPE}) problems with model-based methods (for episodic {MDP}) and provides a unified framework towards optimal learning for several well-motivated offline tasks. Uniform {OPE} \${\textbackslash}sup\_{\textbackslash}Pi{\textbar}Q{\textasciicircum}{\textbackslash}pi-{\textbackslash}hat\{Q\}{\textasciicircum}{\textbackslash}pi{\textbar}{\textless}{\textbackslash}epsilon\$ is a stronger measure than the point-wise {OPE} and ensures offline learning when \${\textbackslash}Pi\$ contains all policies (the global class). In this paper, we establish an \${\textbackslash}Omega(H{\textasciicircum}2 S/d\_m{\textbackslash}epsilon{\textasciicircum}2)\$ lower bound (over model-based family) for the global uniform {OPE} and our main result establishes an upper bound of \${\textbackslash}tilde\{O\}(H{\textasciicircum}2/d\_m{\textbackslash}epsilon{\textasciicircum}2)\$ for the {\textbackslash}emph\{local\} uniform convergence that applies to all {\textbackslash}emph\{near-empirically optimal\} policies for the {MDPs} with {\textbackslash}emph\{stationary\} transition. Here \$d\_m\$ is the minimal marginal state-action probability. Critically, the highlight in achieving the optimal rate \${\textbackslash}tilde\{O\}(H{\textasciicircum}2/d\_m{\textbackslash}epsilon{\textasciicircum}2)\$ is our design of {\textbackslash}emph\{singleton absorbing {MDP}\}, which is a new sharp analysis tool that works with the model-based approach. We generalize such a model-based framework to the new settings: offline task-agnostic and the offline reward-free with optimal complexity \${\textbackslash}tilde\{O\}(H{\textasciicircum}2{\textbackslash}log(K)/d\_m{\textbackslash}epsilon{\textasciicircum}2)\$ (\$K\$ is the number of tasks) and \${\textbackslash}tilde\{O\}(H{\textasciicircum}2S/d\_m{\textbackslash}epsilon{\textasciicircum}2)\$ respectively. These results provide a unified solution for simultaneously solving different offline {RL} problems.},
	eventtitle = {Advances in Neural Information Processing Systems},
	author = {Yin, Ming and Wang, Yu-Xiang},
	urldate = {2023-04-05},
	date = {2021-10-26},
	langid = {english},
}

@misc{talagrand_concentration_1994,
	title = {Concentration of Measure and Isoperimetric Inequalities in Product Spaces},
	url = {http://arxiv.org/abs/math/9406212},
	doi = {10.48550/arXiv.math/9406212},
	abstract = {The concentration of measure prenomenon roughly states that, if a set \$A\$ in a product \${\textbackslash}Omega{\textasciicircum}N\$ of probability spaces has measure at least one half, ``most'' of the points of \${\textbackslash}Omega{\textasciicircum}N\$ are ``close'' to \$A\$. We proceed to a systematic exploration of this phenomenon. The meaning of the word ``most'' is made rigorous by isoperimetric-type inequalities that bound the measure of the exceptional sets. The meaning of the work ``close'' is defined in three main ways, each of them giving rise to related, but different inequalities. The inequalities are all proved through a common scheme of proof. Remarkably, this simple approach not only yields qualitatively optimal results, but, in many cases, captures near optimal numerical constants. A large number of applications are given, in particular in Percolation, Geometric Probability, Probability in Banach Spaces, to demonstrate in concrete situations the extremely wide range of application of the abstract tools.},
	number = {{arXiv}:math/9406212},
	publisher = {{arXiv}},
	author = {Talagrand, Michel},
	urldate = {2023-04-05},
	date = {1994-06-07},
	eprinttype = {arxiv},
	eprint = {math/9406212},
	keywords = {60E, Mathematics - Functional Analysis, Mathematics - Probability},
}

@article{sunder_fugledes_2015,
	title = {Fuglede’s theorem},
	volume = {46},
	issn = {0019-5588, 0975-7465},
	url = {http://link.springer.com/10.1007/s13226-015-0143-6},
	doi = {10.1007/s13226-015-0143-6},
	abstract = {In this short note, we give an elementary (set-theoretic) proof of Fuglede’s theorem that the com mutant of a normal operator is *-closed.},
	pages = {415--417},
	number = {4},
	journaltitle = {Indian Journal of Pure and Applied Mathematics},
	shortjournal = {Indian J Pure Appl Math},
	author = {Sunder, V. S.},
	urldate = {2023-03-30},
	date = {2015-08},
	langid = {english},
}

@book{pollard_users_2001,
	location = {Cambridge},
	title = {A User's Guide to Measure Theoretic Probability},
	isbn = {978-0-521-80242-0},
	url = {https://www.cambridge.org/core/books/users-guide-to-measure-theoretic-probability/A257FE6572A9142FE3B811FFF3FD0171},
	series = {Cambridge Series in Statistical and Probabilistic Mathematics},
	abstract = {Rigorous probabilistic arguments, built on the foundation of measure theory introduced eighty years ago by Kolmogorov, have invaded many fields. Students of statistics, biostatistics, econometrics, finance, and other changing disciplines now find themselves needing to absorb theory beyond what they might have learned in the typical undergraduate, calculus-based probability course. This 2002 book grew from a one-semester course offered for many years to a mixed audience of graduate and undergraduate students who have not had the luxury of taking a course in measure theory. The core of the book covers the basic topics of independence, conditioning, martingales, convergence in distribution, and Fourier transforms. In addition there are numerous sections treating topics traditionally thought of as more advanced, such as coupling and the {KMT} strong approximation, option pricing via the equivalent martingale measure, and the isoperimetric inequality for Gaussian processes. The book is not just a presentation of mathematical theory, but is also a discussion of why that theory takes its current form. It will be a secure starting point for anyone who needs to invoke rigorous probabilistic arguments and understand what they mean.},
	publisher = {Cambridge University Press},
	author = {Pollard, David},
	urldate = {2023-03-21},
	date = {2001},
	doi = {10.1017/CBO9780511811555},
}

@misc{baraud_estimating_2006,
	title = {Estimating the intensity of a random measure by histogram type estimators},
	url = {http://arxiv.org/abs/math/0608663},
	abstract = {The purpose of this paper is to estimate the intensity of some random measure N on a set X by a piecewise constant function on a ﬁnite partition of X . Given a (possibly large) family M of candidate partitions, we build a piecewise constant estimator (histogram) on each of them and then use the data to select one estimator in the family. Choosing the square of a Hellinger-type distance as our loss function, we show that each estimator built on a given partition satisﬁes an analogue of the classical squared bias plus variance risk bound. Moreover, the selection procedure leads to a ﬁnal estimator satisfying some oracle-type inequality, with, as usual, a possible loss corresponding to the complexity of the family M. When this complexity is not too high, the selected estimator has a risk bounded, up to a universal constant, by the smallest risk bound obtained for the estimators in the family. For suitable choices of the family of partitions, we deduce uniform risk bounds over various classes of intensities. Our approach applies to the estimation of the intensity of an inhomogenous Poisson process, among other counting processes, or the estimation of the mean of a random vector with nonnegative components.},
	number = {{arXiv}:math/0608663},
	publisher = {{arXiv}},
	author = {Baraud, Yannick and Birgé, Lucien},
	urldate = {2023-03-21},
	date = {2006-08-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {math/0608663},
	keywords = {62G05, Mathematics - Statistics Theory},
}

@article{kontorovich_obtaining_nodate,
	title = {Obtaining Measure Concentration from Markov Contraction},
	abstract = {Concentration bounds for non-product, non-Haar measures are fairly recent: the ﬁrst such result was obtained for contracting Markov chains by Marton in 1996 via the coupling method. The work that followed, with few exceptions, also used coupling. Although this technique is of unquestionable utility as a theoretical tool, it is not always simple to apply. As an alternative to coupling, we use the elementary Markov contraction lemma to obtain simple, useful, and apparently novel concentration results for various Markov-type processes. Our technique consists of expressing probabilities as matrix products and applying Markov contraction to these expressions; thus it is fairly general and holds the potential to yield further results in this vein.},
	author = {Kontorovich, A},
	langid = {english},
}

@article{marton_bounding_1996,
	title = {Bounding \${\textbackslash}bar\{d\}\$-distance by informational divergence: a method to prove measure concentration},
	volume = {24},
	issn = {0091-1798, 2168-894X},
	url = {https://projecteuclid.org/journals/annals-of-probability/volume-24/issue-2/Bounding-bard-distance-by-informational-divergence--a-method-to/10.1214/aop/1039639365.full},
	doi = {10.1214/aop/1039639365},
	shorttitle = {Bounding \${\textbackslash}bar\{d\}\$-distance by informational divergence},
	abstract = {There is a simple inequality by Pinsker between variational distance and informational divergence of probability measures defined on arbitrary probability spaces. We shall consider probability measures on sequences taken from countable alphabets, and derive, from Pinsker's inequality, bounds on the \${\textbackslash}bar\{d\}\$-distance by informational divergence. Such bounds can be used to prove the "concentration of measure" phenomenon for some nonproduct distributions.},
	pages = {857--866},
	number = {2},
	journaltitle = {The Annals of Probability},
	author = {Marton, K.},
	urldate = {2023-03-21},
	date = {1996-04},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {\${\textbackslash}bar\{d\}\$-distance, 60F10, 60G05, 60G70, Isoperimetric inequality, Markov chains, informational divergence, measure concentration},
}

@online{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:ZRqeScsR9okJ:scholar.google.com/&output=citation&scisdr=CgUBrAZREJqdjBP58v4:AAGBfm0AAAAAY4j_6v7QzUHm_lxEU5kP21UXk6bY4ffR&scisig=AAGBfm0AAAAAY4j_6hAs1NBKvbtXHO9D5n7Uv7kgPkGA&scisf=4&ct=citation&cd=-1&hl=en},
	urldate = {2022-12-01},
}

@article{roussas_nonparametric_1969,
	title = {Nonparametric estimation in Markov processes},
	volume = {21},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/10.1007/BF02532233},
	doi = {10.1007/BF02532233},
	pages = {73--87},
	number = {1},
	journaltitle = {Annals of the Institute of Statistical Mathematics},
	shortjournal = {Ann Inst Stat Math},
	author = {Roussas, George G.},
	urldate = {2022-12-01},
	date = {1969-12},
	langid = {english},
}

@article{banerjee_ine_nodate,
	title = {Ofﬂine Estimation of Controlled Markov Chains: Minimax Nonparametric Estimators and Sample Efﬁciency},
	abstract = {Controlled Markov chains ({CMCs}) have wide applications in engineering and machine learning, forming a key component in many reinforcement learning problems. In this work, we consider the estimation of the transition probabilities of a ﬁnite-state ﬁnite-control {CMC}, and develop a minimax sample complexity bounds for nonparametric estimation of these transition probability matrices. Unlike most studies that have been done in the online setup, we consider ofﬂine {MDPs}. Our results are quite general, since we do not assume anything speciﬁc about the logging policy. Instead, the dependence of our statistical bounds on the logging policy comes in the form of a natural mixing coefﬁcient. We demonstrate an interesting trade-off between stronger assumptions on mixing versus requiring more samples to achieve a particular {PAC}-bound. We demonstrate the validity of our results under various examples, like ergodic Markov chains, weakly ergodic inhomogenous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use the properties of the estimated transition matrix to perform estimate the value function when the controls are stationary and Markov.},
	pages = {67},
	author = {Banerjee, Imon and Honnappa, Harsha and Rao, Vinayak},
	langid = {english},
}

@online{noauthor_2022-10-08_nodate,
	title = {2022-10-08 - (Neurips\_2020)\_Ts\_Withapproximate\_Inference.pdf},
	url = {https://www.dropbox.com/home/ImonPrateek?preview=2022-10-08+-+%28Neurips_2020%29_Ts_Withapproximate_Inference.pdf},
	urldate = {2022-11-15},
}

@article{jain_robust_nodate,
	title = {Robust Density Estimation from Batches: The Best Things in Life are (Nearly) Free},
	abstract = {In many applications data are collected in batches, some potentially biased, corrupt, or even adversarial. Learning algorithms for this setting have therefore garnered considerable recent attention. In particular, a sequence of works has shown that all approximately piecewise polynomial distributions—and in particular all Gaussian, Gaussian-mixture, log-concave, low-modal, and monotone-hazard distributions—can be learned robustly in polynomial time. However, these results left open the question, stated explicitly in (Chen et al., 2020), about the best possible sample complexity of such algorithms. We answer this question, showing that, perhaps surprisingly, up to logarithmic factors, the optimal sample complexity is the same as for genuine, non-adversarial, data! To establish the result, we reduce robust learning of approximately piecewise polynomial distributions to robust learning of the probability of all subsets of size at most k of a larger discrete domain, and learn these probabilities in optimal sample complexity linear in k regardless of the domain size. In simulations, the algorithm runs very quickly and estimates distributions to essentially the accuracy achieved when all adversarial batches are removed. The results also imply the ﬁrst polynomial-time sample-optimal algorithm for robust interval-based classiﬁcation based on batched data.},
	pages = {11},
	author = {Jain, Ayush and Orlitsky, Alon},
	langid = {english},
}

@article{shamir_sample_nodate,
	title = {The Sample Complexity of Learning Linear Predictors with the Squared Loss},
	abstract = {We provide a tight sample complexity bound for learning bounded-norm linear predictors with respect to the squared loss. Our focus is on an agnostic {PAC}-style setting, where no assumptions are made on the data distribution beyond boundedness. This contrasts with existing results in the literature, which rely on other distributional assumptions, refer to speciﬁc parameter settings, or use other performance measures.},
	pages = {12},
	author = {Shamir, Ohad},
	langid = {english},
}

@article{mcrae_sample_nodate,
	title = {Sample complexity and effective dimension for regression on manifolds},
	abstract = {We consider the theory of regression on a manifold using reproducing kernel Hilbert space methods. Manifold models arise in a wide variety of modern machine learning problems, and our goal is to help understand the effectiveness of various implicit and explicit dimensionality-reduction methods that exploit manifold structure. Our ﬁrst key contribution is to establish a novel nonasymptotic version of the Weyl law from differential geometry. From this we are able to show that certain spaces of smooth functions on a manifold are effectively ﬁnite-dimensional, with a complexity that scales according to the manifold dimension rather than any ambient data dimension. Finally, we show that given (potentially noisy) function values taken uniformly at random over a manifold, a kernel regression estimator (derived from the spectral decomposition of the manifold) yields minimax-optimal error bounds that are controlled by the effective dimension.},
	pages = {12},
	author = {{McRae}, Andrew D and Romberg, Justin and Davenport, Mark A},
	langid = {english},
}

@article{banerjee_convergence_2019,
	title = {On Convergence of the Class Membership Estimator in Fuzzy \$k\$-Nearest Neighbor Classifier},
	volume = {27},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2018.2874017},
	abstract = {The fuzzy \$k\$-nearest neighbor classifier (F\$k\${NN}) improves upon the flexibility of the \$k\$-nearest neighbor classifier by considering each class as a fuzzy set and estimating the membership of an unlabeled data instance for each of the classes. However, the question of validating the quality of the class memberships estimated by F\$k\${NN} for a regular multiclass classification problem still remains mostly unanswered. In this paper, we attempt to address this issue by first proposing a novel direction of evaluating a fuzzy classifier by highlighting the importance of focusing on the class memberships estimated by F\$k\${NN} instead of its misclassification error. This leads us to finding novel theoretical upper bounds, respectively, on the bias and the mean squared error of the class memberships estimated by F\$k\${NN}. Additionally the proposed upper bounds are shown to converge toward zero with increasing availability of the labeled data points, under some elementary assumptions on the class distribution and membership function. The major advantages of this analysis are its simplicity, capability of a direct extension for multiclass problems, parameter independence, and practical implication in explaining the behavior of F\$k\${NN} in diverse situations (such as in presence of class imbalance). Furthermore, we provide a detailed simulation study on artificial and real data sets to empirically support our claims.},
	pages = {1226--1236},
	number = {6},
	journaltitle = {{IEEE} Transactions on Fuzzy Systems},
	author = {Banerjee, Imon and Mullick, Sankha Subhra and Das, Swagatam},
	date = {2019-06},
	note = {Conference Name: {IEEE} Transactions on Fuzzy Systems},
	keywords = {Class membership estimator, Convergence, Fuzzy sets, Nearest neighbor methods, Pattern classification, error bound, error convergence, fuzzy \$k\$ -nearest neighbor classifier (F \$k\$ {NN}), fuzzy sets},
}

@online{noauthor_view_nodate,
	title = {View article},
	url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9MotWmwAAAAJ&citation_for_view=9MotWmwAAAAJ:u-x6o8ySG0sC},
	urldate = {2022-10-31},
}

@online{noauthor_entropy_nodate,
	title = {Entropy {\textbar} Free Full-Text {\textbar} {PAC}-Bayes Bounds on Variational Tempered Posteriors for Markov Models {\textbar} {HTML}},
	url = {https://www.mdpi.com/1099-4300/23/3/313/htm},
	urldate = {2022-10-31},
}

@online{noauthor_entropy_nodate-1,
	title = {Entropy {\textbar} Free Full-Text {\textbar} {PAC}-Bayes Bounds on Variational Tempered Posteriors for Markov Models},
	url = {https://www.mdpi.com/1099-4300/23/3/313},
	urldate = {2022-10-31},
}

@article{azuma_weighted_1967,
	title = {Weighted sums of certain dependent random variables},
	volume = {19},
	pages = {357--367},
	number = {3},
	journaltitle = {Tohoku Mathematical Journal, Second Series},
	author = {Azuma, Kazuoki},
	date = {1967},
	note = {Publisher: Mathematical Institute, Tohoku University},
}

@online{noauthor_virtual_nodate,
	title = {Virtual Site},
	url = {https://icml.cc/virtual/2022/oral/16290},
	urldate = {2022-10-31},
}

@inproceedings{hajnal_weak_1958,
	title = {Weak ergodicity in non-homogeneous Markov chains},
	volume = {54},
	pages = {233--246},
	booktitle = {Mathematical Proceedings of the Cambridge Philosophical Society},
	publisher = {Cambridge University Press},
	author = {Hajnal, John and Bartlett, Maurice S},
	date = {1958},
}

@inproceedings{dieng_variational_2017,
	title = {Variational Inference via χ Upper Bound Minimization},
	pages = {2732--2741},
	booktitle = {Advances in Neural Information Processing Systems},
	author = {Dieng, Adji Bousso and Tran, Dustin and Ranganath, Rajesh and Paisley, John and Blei, David},
	date = {2017},
}

@article{blei_variational_2017,
	title = {Variational inference: A review for statisticians},
	volume = {112},
	pages = {859--877},
	number = {518},
	journaltitle = {Journal of the American statistical Association},
	author = {Blei, David M and Kucukelbir, Alp and {McAuliffe}, Jon D},
	date = {2017},
	note = {Publisher: Taylor \& Francis},
}

@inproceedings{dieng_variational_2017-1,
	title = {Variational Inference via \${\textbackslash}chi \$ Upper Bound Minimization},
	pages = {2732--2741},
	booktitle = {Advances in Neural Information Processing Systems},
	author = {Dieng, Adji Bousso and Tran, Dustin and Ranganath, Rajesh and Paisley, John and Blei, David},
	date = {2017},
}

@inproceedings{wang_variational_2019,
	title = {Variational Bayes under model misspecification},
	pages = {13357--13367},
	booktitle = {Advances in Neural Information Processing Systems},
	author = {Wang, Yixin and Blei, David},
	date = {2019},
}

@inproceedings{grunwald_safe_2012,
	title = {The safe bayesian},
	pages = {169--183},
	booktitle = {International Conference on Algorithmic Learning Theory},
	publisher = {Springer},
	author = {Grünwald, Peter},
	date = {2012},
}

@article{mukhamedov_dobrushin_2013,
	title = {The Dobrushin ergodicity coefficient and the ergodicity of noncommutative Markov chains},
	volume = {408},
	pages = {364--373},
	number = {1},
	journaltitle = {Journal of Mathematical Analysis and Applications},
	author = {Mukhamedov, Farrukh},
	date = {2013},
	note = {Publisher: Elsevier},
}

@inproceedings{ryabko_testing_2008,
	title = {Testing statistical hypotheses about ergodic processes},
	pages = {257--260},
	booktitle = {2008 {IEEE} Region 8 International Conference on Computational Technologies in Electrical and Electronics Engineering},
	publisher = {{IEEE}},
	author = {Ryabko, Daniil},
	date = {2008},
}

@article{heidergott_taylor_2003,
	title = {Taylor series expansions for stationary Markov chains},
	volume = {35},
	pages = {1046--1070},
	number = {4},
	journaltitle = {Advances in Applied Probability},
	author = {Heidergott, Bernd and Hordijk, Arie},
	date = {2003},
	note = {Publisher: Cambridge University Press},
}

@book{lehmann_testing_2006,
	title = {Testing statistical hypotheses},
	publisher = {Springer Science \& Business Media},
	author = {Lehmann, Erich L and Romano, Joseph P},
	date = {2006},
}

@article{geman_stochastic_1984,
	title = {Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images},
	pages = {721--741},
	number = {6},
	journaltitle = {{IEEE} Transactions on pattern analysis and machine intelligence},
	author = {Geman, Stuart and Geman, Donald},
	date = {1984},
	note = {Publisher: {IEEE}},
}

@article{billingsley_statistical_1961,
	title = {Statistical methods in Markov chains},
	pages = {12--40},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Billingsley, Patrick},
	date = {1961},
	note = {Publisher: {JSTOR}},
}

@article{wolfer_statistical_2021,
	title = {Statistical estimation of ergodic Markov chain kernel over discrete state space},
	volume = {27},
	pages = {532--553},
	number = {1},
	journaltitle = {Bernoulli},
	author = {Wolfer, Geoffrey and Kontorovich, Aryeh and {others}},
	date = {2021},
	note = {Publisher: Bernoulli Society for Mathematical Statistics and Probability},
}

@article{qi_sparse_2013,
	title = {Sparse principal component analysis by choice of norm},
	volume = {114},
	pages = {127--160},
	journaltitle = {Journal of multivariate analysis},
	author = {Qi, Xin and Luo, Ruiyan and Zhao, Hongyu},
	date = {2013},
	note = {Publisher: Elsevier},
}

@article{rosenblatt-roth_theorems_1964,
	title = {Some theorems concerning the strong law of large numbers for non-homogeneous Markov chains},
	volume = {35},
	pages = {566--576},
	number = {2},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Rosenblatt-Roth, M},
	date = {1964},
	note = {Publisher: {JSTOR}},
}

@article{rosenblatt-roth_theorems_1963,
	title = {Some theorems concerning the law of large numbers for non-homogeneous Markoff chains},
	volume = {1},
	pages = {433--445},
	number = {5},
	journaltitle = {Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete},
	author = {Rosenblatt-Roth, M},
	date = {1963},
	note = {Publisher: Springer},
}

@incollection{birge_robust_1983,
	title = {Robust testing for independent non identically distributed variables and Markov chains},
	pages = {134--162},
	booktitle = {Specifying Statistical Models},
	publisher = {Springer},
	author = {Birgé, Lucien},
	date = {1983},
}

@article{ibragimov_limit_1962,
	title = {Some limit theorems for stationary processes},
	volume = {7},
	pages = {349--382},
	number = {4},
	journaltitle = {Theory of Probability \& Its Applications},
	author = {Ibragimov, Ildar A},
	date = {1962},
	note = {Publisher: {SIAM}},
}

@article{miller_robust_2018,
	title = {Robust Bayesian inference via coarsening},
	journaltitle = {Journal of the American Statistical Association},
	author = {Miller, Jeffrey W and Dunson, David B},
	date = {2018},
	note = {Publisher: Taylor \& Francis},
}

@article{jaiswal_risk-sensitive_2019,
	title = {Risk-sensitive variational Bayes: Formulations and bounds},
	journaltitle = {{arXiv} preprint {arXiv}:1903.05220},
	author = {Jaiswal, Prateek and Honnappa, Harsha and Rao, Vinayak A},
	date = {2019},
}

@article{li_renyi_2016,
	title = {Rényi divergence variational inference},
	volume = {29},
	pages = {1073--1081},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Li, Yingzhen and Turner, Richard E},
	date = {2016},
}

@article{van_erven_renyi_2014,
	title = {Rényi divergence and Kullback-Leibler divergence},
	volume = {60},
	pages = {3797--3820},
	number = {7},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Van Erven, Tim and Harremos, Peter},
	date = {2014},
	note = {Publisher: {IEEE}},
}

@article{hernandez-lerma_recurrence_1991,
	title = {Recurrence conditions for Markov decision processes with Borel state space: a survey},
	volume = {28},
	pages = {29--46},
	number = {1},
	journaltitle = {Annals of Operations Research},
	author = {Hernández-Lerma, Onésimo and Montes-de-Oca, Raúl and Cavazos-Cadena, Rolando},
	date = {1991},
	note = {Publisher: Springer},
}

@book{sutton_reinforcement_2018,
	title = {Reinforcement learning: An introduction},
	publisher = {{MIT} press},
	author = {Sutton, Richard S and Barto, Andrew G},
	date = {2018},
}

@article{shen_rates_2001,
	title = {Rates of convergence of posterior distributions},
	volume = {29},
	pages = {687--714},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Shen, Xiaotong and Wasserman, Larry},
	date = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{yu_q-learning_2013,
	title = {Q-learning and policy iteration algorithms for stochastic shortest path problems},
	volume = {208},
	pages = {95--132},
	number = {1},
	journaltitle = {Annals of Operations Research},
	author = {Yu, Huizhen and Bertsekas, Dimitri P},
	date = {2013},
	note = {Publisher: Springer},
}

@article{wolfowitz_products_1963,
	title = {Products of indecomposable, aperiodic, stochastic matrices},
	volume = {14},
	pages = {733--737},
	number = {5},
	journaltitle = {Proceedings of the American Mathematical Society},
	author = {Wolfowitz, Jacob},
	date = {1963},
	note = {Publisher: {JSTOR}},
}

@article{cruz_weak_2019,
	title = {On Weak and Strong Ergodicity},
	volume = {13},
	pages = {28},
	number = {2},
	journaltitle = {Journal of Statistical Theory and Practice},
	author = {Cruz, Juan Alberto Rojas and Diniz, Iesus C},
	date = {2019},
	note = {Publisher: Springer},
}

@book{bishop_pattern_2006,
	title = {Pattern recognition and machine learning},
	publisher = {Springer},
	author = {Bishop, Christopher M},
	date = {2006},
}

@article{ghosh_probability_2002,
	title = {Probability inequalities related to Markov's theorem},
	volume = {56},
	pages = {186--190},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Ghosh, {BK}},
	date = {2002},
	note = {Publisher: Taylor \& Francis},
}

@article{jones_markov_2004,
	title = {On the Markov chain central limit theorem},
	volume = {1},
	pages = {299--320},
	journaltitle = {Probability Surveys},
	author = {Jones, Galin L},
	date = {2004},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
}

@article{rousseau_frequentist_2016,
	title = {On the frequentist properties of Bayesian nonparametric methods},
	volume = {3},
	pages = {211--231},
	journaltitle = {Annual Review of Statistics and Its Application},
	author = {Rousseau, Judith},
	date = {2016},
	note = {Publisher: Annual Reviews},
}

@article{mannor_empirical_2005,
	title = {On the empirical state-action frequencies in Markov decision processes under general policies},
	volume = {30},
	pages = {545--561},
	number = {3},
	journaltitle = {Mathematics of Operations Research},
	author = {Mannor, Shie and Tsitsiklis, John N},
	date = {2005},
	note = {Publisher: {INFORMS}},
}

@article{cogburn_central_1991,
	title = {On the central limit theorem for Markov chains in random environments},
	pages = {587--604},
	journaltitle = {The Annals of Probability},
	author = {Cogburn, Robert},
	date = {1991},
	note = {Publisher: {JSTOR}},
}

@article{alzer_inequalities_1997,
	title = {On some inequalities for the gamma and psi functions},
	volume = {66},
	pages = {373--389},
	number = {217},
	journaltitle = {Mathematics of Computation},
	author = {Alzer, Horst},
	date = {1997},
}

@article{rio_mcdiarmids_2013,
	title = {On {McDiarmid}'s concentration inequality},
	volume = {18},
	pages = {1--11},
	journaltitle = {Electronic Communications in Probability},
	author = {Rio, Emmanuel},
	date = {2013},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
}

@inproceedings{mukhamedov_dobrushin_2013,
	title = {On Dobrushin Ergodicity Coefficient and weak ergodicity of Markov Chains on Jordan Algebras},
	volume = {435},
	pages = {012002},
	booktitle = {Journal of Physics: Conference Series},
	publisher = {{IOP} Publishing},
	author = {Mukhamedov, Farrukh},
	date = {2013},
	note = {Issue: 1},
}

@article{le_cam_local_1975,
	title = {On local and global properties in the theory of asymptotic normality of experiments},
	pages = {13--54},
	journaltitle = {Stochastic processes and related topics (Proc. Summer Res. Inst. Statist. Inference for Stochastic Processes, Indiana Univ., Bloomington, Ind., 1974, Vol. 1},
	author = {Le Cam, L},
	date = {1975},
}

@article{wu_bounds_2005,
	title = {On bounds of extremal eigenvalues of irreducible and m-reducible matrices},
	volume = {402},
	pages = {29--45},
	journaltitle = {Linear algebra and its applications},
	author = {Wu, Chai Wah},
	date = {2005},
	note = {Publisher: Elsevier},
}

@article{yu_boundedness_2013,
	title = {On boundedness of Q-learning iterates for stochastic shortest path problems},
	volume = {38},
	pages = {209--227},
	number = {2},
	journaltitle = {Mathematics of Operations Research},
	author = {Yu, Huizhen and Bertsekas, Dimitri P},
	date = {2013},
	note = {Publisher: {INFORMS}},
}

@article{yakowitz_nonparametric_1979,
	title = {Nonparametric Estimation of Markov Transition Functions},
	volume = {7},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-3/Nonparametric-Estimation-of-Markov-Transition-Functions/10.1214/aos/1176344687.full},
	doi = {10.1214/aos/1176344687},
	abstract = {Let \${\textbackslash}\{X\_n{\textbackslash}\}\$ be a Markov chain having a stationary transition function and assume that the state set is an arbitrary set in a Euclidean space. The state transition law of the chain is given by a function \$F(y{\textbar}x) = P{\textbackslash}lbrack X\_\{n+1\} {\textbackslash}leqslant y{\textbar}X\_n = x{\textbackslash}rbrack\$, which is assumed defined and continuous for all \$x\$. In this paper we give a statistical procedure for determining a function \$F\_n(y{\textbackslash}mid x)\$ on the basis of the sample \${\textbackslash}\{X\_j{\textbackslash}\}{\textasciicircum}n\_\{j=1\}, n = 1, 2,{\textbackslash}cdots,\$ and prove that if the chain is irreducible, aperiodic, and possesses a limiting distribution \${\textbackslash}pi\$, then with probability 1, \${\textbackslash}sup\_y{\textbar}F\_n(y{\textbar}x) - F(y{\textbar}x){\textbar} {\textbackslash}rightarrow\_n0\$ for every \$x\$ such that any open sphere containing \$x\$ has positive \${\textbackslash}pi\$ probability. This result improves upon a study by Roussas which gives only weak convergence. We demonstrate that a certain clustering algorithm is useful for obtaining efficient versions of our estimates. The potential value of our methods is illustrated by computer studies using simulated data.},
	pages = {671--679},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Yakowitz, Sidney},
	urldate = {2022-10-02},
	date = {1979-05},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G05, 62M05, Markov-chain, consistent estimator, hydrologic time series, nonparametric inference},
}

@article{schwartz_bayes_1965,
	title = {On bayes procedures},
	volume = {4},
	pages = {10--26},
	number = {1},
	journaltitle = {Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete},
	author = {Schwartz, Lorraine},
	date = {1965},
	note = {Publisher: Springer},
}

@article{bhattacharya_motif_2020,
	title = {Motif Estimation via Subgraph Sampling: The Fourth Moment Phenomenon},
	journaltitle = {{arXiv} preprint {arXiv}:2011.03026},
	author = {Bhattacharya, Bhaswar B and Das, Sayan and Mukherjee, Sumit},
	date = {2020},
}

@article{jarner_necessary_2003,
	title = {Necessary conditions for geometric and polynomial ergodicity of random-walk-type},
	volume = {9},
	pages = {559--578},
	number = {4},
	journaltitle = {Bernoulli},
	author = {Jarner, Søren F and Tweedie, Richard L},
	date = {2003},
	note = {Publisher: Bernoulli Society for Mathematical Statistics and Probability},
}

@inproceedings{birge_model_2006,
	title = {Model selection via testing: an alternative to (penalized) maximum likelihood estimators},
	volume = {42},
	pages = {273--325},
	booktitle = {Annales de l'{IHP} Probabilités et statistiques},
	author = {Birgé, Lucien},
	date = {2006},
	note = {Issue: 3},
}

@article{rosenthal_minorization_1995,
	title = {Minorization conditions and convergence rates for Markov chain Monte Carlo},
	volume = {90},
	pages = {558--566},
	number = {430},
	journaltitle = {Journal of the American Statistical Association},
	author = {Rosenthal, Jeffrey S},
	date = {1995},
	note = {Publisher: Taylor \& Francis},
}

@book{hall_martingale_2014,
	title = {Martingale limit theory and its application},
	publisher = {Academic press},
	author = {Hall, Peter and Heyde, Christopher C},
	date = {2014},
}

@article{van_eeden_minimax_2006,
	title = {Minimax estimators and their admissibility},
	pages = {33--67},
	journaltitle = {Restricted Parameter Space Estimation Problems: Admissibility and Minimaxity Properties},
	author = {van Eeden, Constance},
	date = {2006},
	note = {Publisher: Springer},
}

@article{brandwein_minimax_1980,
	title = {Minimax estimation of location parameters for spherically symmetric distributions with concave loss},
	volume = {8},
	pages = {279--284},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Brandwein, Ann Cohen and Strawderman, William E},
	date = {1980},
	note = {Publisher: Institute of Mathematical Statistics},
}

@book{meyn_markov_2012,
	title = {Markov chains and stochastic stability},
	publisher = {Springer Science \& Business Media},
	author = {Meyn, Sean P and Tweedie, Richard L},
	date = {2012},
}

@inproceedings{noauthor_kullback_2007,
	title = {Kullback Leibler ({KL}) Distance of Two Normal (Gaussian) Probability Distributions},
	booktitle = {Allisons.org},
	date = {2007},
}

@article{wainwright_introduction_2008,
	title = {Introduction to Variational Methods for Graphical Models},
	volume = {1},
	pages = {1--103},
	journaltitle = {Foundations and Trends in Machine Learning},
	author = {Wainwright, Martin J and Jordan, Michael I},
	date = {2008},
}

@article{vershynin_introduction_2010,
	title = {Introduction to the non-asymptotic analysis of random matrices},
	journaltitle = {{arXiv} preprint {arXiv}:1011.3027},
	author = {Vershynin, Roman},
	date = {2010},
}

@book{tsybakov_introduction_2009,
	title = {Introduction to Nonparametric Estimation.},
	pagetotal = {I–{XII}},
	publisher = {Springer},
	author = {Tsybakov, Alexandre B},
	date = {2009},
	note = {Publication Title: Springer series in statistics},
}

@book{van_lint_introduction_2012,
	title = {Introduction to coding theory},
	volume = {86},
	publisher = {Springer Science \& Business Media},
	author = {Van Lint, Jacobus Hendricus},
	date = {2012},
}

@article{hajek_hitting-time_1982,
	title = {Hitting-time and occupation-time bounds implied by drift analysis with applications},
	pages = {502--525},
	journaltitle = {Advances in Applied Probability},
	author = {Hajek, Bruce},
	date = {1982},
	note = {Publisher: {JSTOR}},
}

@book{vershynin_high-dimensional_2018,
	title = {High-dimensional probability: An introduction with applications in data science},
	volume = {47},
	publisher = {Cambridge university press},
	author = {Vershynin, Roman},
	date = {2018},
}

@article{anthonisse_exponential_1977,
	title = {Exponential convergence of products of stochastic matrices},
	volume = {59},
	pages = {360--364},
	number = {2},
	journaltitle = {Journal of Mathematical Analysis and Applications},
	author = {Anthonisse, Jac M and Tijms, Henk},
	date = {1977},
	note = {Publisher: Elsevier},
}

@article{wang_frequentist_2019,
	title = {Frequentist consistency of variational Bayes},
	volume = {114},
	pages = {1147--1161},
	number = {527},
	journaltitle = {Journal of the American Statistical Association},
	author = {Wang, Yixin and Blei, David M},
	date = {2019},
	note = {Publisher: Taylor \& Francis},
}

@article{ormerod_explaining_2010,
	title = {Explaining variational approximations},
	volume = {64},
	pages = {140--153},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Ormerod, John T and Wand, Matt P},
	date = {2010},
	note = {Publisher: Taylor \& Francis},
}

@article{metropolis_equation_1953,
	title = {Equation of state calculations by fast computing machines},
	volume = {21},
	pages = {1087--1092},
	number = {6},
	journaltitle = {The journal of chemical physics},
	author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
	date = {1953},
	note = {Publisher: American Institute of Physics},
}

@article{beck_error_2012,
	title = {Error bounds for constant step-size Q-learning},
	volume = {61},
	pages = {1203--1208},
	number = {12},
	journaltitle = {Systems \& control letters},
	author = {Beck, Carolyn L and Srikant, Rayadurgam},
	date = {2012},
	note = {Publisher: Elsevier},
}

@article{bertsekas_dynamic_2011,
	title = {Dynamic programming and optimal control 3rd edition, volume {II}},
	journaltitle = {Belmont, {MA}: Athena Scientific},
	author = {Bertsekas, Dimitri P},
	date = {2011},
}

@article{ghosal_entropies_2001,
	title = {Entropies and rates of convergence for maximum likelihood and Bayes estimation for mixtures of Normal densities},
	pages = {1233--1263},
	journaltitle = {Annals of Statistics},
	author = {Ghosal, Subhashis and Van Der Vaart, Aad W},
	date = {2001},
	note = {Publisher: {JSTOR}},
}

@article{zhang_convergence_2020,
	title = {Convergence rates of variational posterior distributions},
	volume = {48},
	pages = {2180--2207},
	number = {4},
	journaltitle = {Annals of Statistics},
	author = {Zhang, Fengshuo and Gao, Chao},
	date = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{coppersmith_conditions_2008,
	title = {Conditions for weak ergodicity of inhomogeneous Markov chains},
	volume = {78},
	pages = {3082--3085},
	number = {17},
	journaltitle = {Statistics \& probability letters},
	author = {Coppersmith, Don and Wu, Chai Wah},
	date = {2008},
	note = {Publisher: Elsevier},
}

@article{lecam_convergence_1973,
	title = {Convergence of estimates under dimensionality restrictions},
	volume = {1},
	pages = {38--53},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {{LeCam}, Lucien},
	date = {1973},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{kontorovich_concentration_2008,
	title = {Concentration inequalities for dependent random variables via the martingale method},
	volume = {36},
	pages = {2126--2158},
	number = {6},
	journaltitle = {Annals of Probability},
	author = {Kontorovich, Leonid Aryeh and Ramanan, Kavita and {others}},
	date = {2008},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{alquier_concentration_2020,
	title = {Concentration of tempered posteriors and of their variational approximations},
	volume = {48},
	pages = {1475--1497},
	number = {3},
	journaltitle = {Annals of Statistics},
	author = {Alquier, Pierre and Ridgway, James},
	date = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
}

@book{boucheron_concentration_2013,
	title = {Concentration inequalities: A nonasymptotic theory of independence},
	publisher = {Oxford university press},
	author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
	date = {2013},
}

@article{seneta_coefficients_1979,
	title = {Coefficients of ergodicity: structure and applications},
	pages = {576--590},
	journaltitle = {Advances in applied probability},
	author = {Seneta, Eugene},
	date = {1979},
	note = {Publisher: {JSTOR}},
}

@article{dobrushin_central_1956,
	title = {Central limit theorem for nonstationary Markov chains. {II}},
	volume = {1},
	pages = {329--383},
	number = {4},
	journaltitle = {Theory of Probability \& Its Applications},
	author = {Dobrushin, Roland L’vovich},
	date = {1956},
	note = {Publisher: {SIAM}},
}

@article{dobrushin_central_1956-1,
	title = {Central limit theorem for nonstationary Markov chains. I},
	volume = {1},
	pages = {65--80},
	number = {1},
	journaltitle = {Theory of Probability \& Its Applications},
	author = {Dobrushin, Roland L},
	date = {1956},
	note = {Publisher: {SIAM}},
}

@article{merlevede_bernstein_2009,
	title = {Bernstein inequality and moderate deviations under strong mixing conditions},
	volume = {5},
	pages = {273--292},
	journaltitle = {High dimensional probability V: the Luminy volume},
	author = {Merlevède, Florence and Peligrad, Magda and Rio, Emmanuel and {others}},
	date = {2009},
}

@article{bradley_basic_2005,
	title = {Basic Properties of Strong Mixing Conditions. A Survey and Some Open Questions},
	volume = {2},
	url = {"https://doi.org/10.1214/154957805100000104"},
	doi = {10.1214/154957805100000104},
	pages = {107--144},
	journaltitle = {Probability Surveys},
	shortjournal = {Probab. Surveys},
	author = {Bradley, Richard C.},
	date = {2005},
	note = {Publisher: "The Institute of Mathematical Statistics and the Bernoulli Society"},
}

@article{bhattacharya_bayesian_2019,
	title = {Bayesian fractional posteriors},
	volume = {47},
	pages = {39--66},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Bhattacharya, Anirban and Pati, Debdeep and Yang, Yun},
	date = {2019},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{fourdrinier_bayes_2013,
	title = {Bayes minimax estimation under power priors of location parameters for a wide class of spherically symmetric distributions},
	volume = {7},
	pages = {717--741},
	journaltitle = {Electronic Journal of Statistics},
	author = {Fourdrinier, Dominique and Mezoued, Fatiha and Strawderman, William E},
	date = {2013},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
}

@book{taniguchi_asymptotic_2012,
	title = {Asymptotic theory of statistical inference for time series},
	publisher = {Springer Science \& Business Media},
	author = {Taniguchi, Masanobu and Kakizawa, Yoshihide},
	date = {2012},
}

@book{van_der_vaart_asymptotic_2000,
	title = {Asymptotic statistics},
	volume = {3},
	publisher = {Cambridge university press},
	author = {Van der Vaart, Aad W},
	date = {2000},
}

@article{jaiswal_asymptotic_2020,
	title = {Asymptotic Consistency of α-Rényi-Approximate Posteriors},
	volume = {21},
	pages = {1--42},
	number = {156},
	journaltitle = {Journal of Machine Learning Research},
	author = {Jaiswal, Prateek and Rao, Vinayak and Honnappa, Harsha},
	date = {2020},
}

@book{le_cam_asymptotic_2012,
	title = {Asymptotic methods in statistical decision theory},
	publisher = {Springer Science \& Business Media},
	author = {Le Cam, Lucien},
	date = {2012},
}

@article{donsker_asymptotic_1975,
	title = {Asymptotic evaluation of certain Markov process expectations for large time, I},
	volume = {28},
	pages = {1--47},
	number = {1},
	journaltitle = {Communications on Pure and Applied Mathematics},
	author = {Donsker, Monroe D and Varadhan, {SR} Srinivasa},
	date = {1975},
	note = {Publisher: Wiley Online Library},
}

@article{jaiswal_asymptotic_nodate,
	title = {Asymptotic consistency of loss-calibrated variational Bayes},
	volume = {9},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.258},
	doi = {https://doi.org/10.1002/sta4.258},
	pages = {e258},
	number = {1},
	journaltitle = {Stat},
	author = {Jaiswal, Prateek and Honnappa, Harsha and Rao, Vinayak A.},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.258},
	keywords = {approximate Bayesian inference, data-driven decision making, loss-calibrated variational Bayes},
}

@article{birge_approximation_1983,
	title = {Approximation dans les espaces métriques et théorie de l'estimation},
	volume = {65},
	pages = {181--237},
	number = {2},
	journaltitle = {Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete},
	author = {Birgé, Lucien},
	date = {1983},
	note = {Publisher: Springer},
}

@article{tropp_introduction_2015,
	title = {An introduction to matrix concentration inequalities},
	journaltitle = {{arXiv} preprint {arXiv}:1501.01571},
	author = {Tropp, Joel A},
	date = {2015},
}

@inproceedings{lacoste-julien_approximate_2011,
	title = {Approximate inference for the loss-calibrated Bayesian},
	pages = {416--424},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	author = {Lacoste-Julien, Simon and Huszár, Ferenc and Ghahramani, Zoubin},
	date = {2011},
}

@book{wasserman_all_2004,
	title = {All of statistics: a concise course in statistical inference},
	volume = {26},
	publisher = {Springer},
	author = {Wasserman, Larry},
	date = {2004},
}

@article{berend_sharp_2013,
	title = {A sharp estimate of the binomial mean absolute deviation with applications},
	volume = {83},
	pages = {1254--1259},
	number = {4},
	journaltitle = {Statistics \& Probability Letters},
	author = {Berend, Daniel and Kontorovich, Aryeh},
	date = {2013},
	note = {Publisher: Elsevier},
}

@article{apostol_elementary_1999,
	title = {An elementary view of Euler's summation formula},
	volume = {106},
	pages = {409--418},
	number = {5},
	journaltitle = {The American Mathematical Monthly},
	author = {Apostol, Tom M},
	date = {1999},
	note = {Publisher: Taylor \& Francis},
}

@article{marton_measure_1996,
	title = {A measure concentration inequality for contracting Markov chains},
	volume = {6},
	pages = {556--571},
	number = {3},
	journaltitle = {Geometric \& Functional Analysis {GAFA}},
	author = {Marton, Katalin},
	date = {1996},
	note = {Publisher: Springer},
}

@book{brannan_first_2006,
	title = {A first course in mathematical analysis},
	publisher = {Cambridge University Press},
	author = {Brannan, David Alexander},
	date = {2006},
}

@article{arlotto_central_2016,
	title = {A central limit theorem for temporally nonhomogenous markov chains with applications to dynamic programming},
	volume = {41},
	pages = {1448--1468},
	number = {4},
	journaltitle = {Mathematics of Operations Research},
	author = {Arlotto, Alessandro and Steele, J Michael},
	date = {2016},
	note = {Publisher: {INFORMS}},
}

@article{rozanov_central_1960,
	title = {A central limit theorem for additive random functions},
	volume = {5},
	pages = {221--223},
	number = {2},
	journaltitle = {Theory of Probability \& Its Applications},
	author = {Rozanov, Yu A},
	date = {1960},
	note = {Publisher: {SIAM}},
}

@article{yang_alpha_2020,
	title = {\${\textbackslash}alpha \$-variational inference with statistical guarantees},
	volume = {48},
	pages = {886--905},
	number = {2},
	journaltitle = {Annals of Statistics},
	author = {Yang, Yun and Pati, Debdeep and Bhattacharya, Anirban},
	date = {2020},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{mania_active_2020,
	title = {Active learning for nonlinear system identification with guarantees},
	journaltitle = {{arXiv} preprint {arXiv}:2006.10277},
	author = {Mania, Horia and Jordan, Michael I and Recht, Benjamin},
	date = {2020},
}

@article{levine_offline_2020,
	title = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
	journaltitle = {{arXiv} preprint {arXiv}:2005.01643},
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	date = {2020},
}

@article{hoi_online_2021,
	title = {Online learning: A comprehensive survey},
	volume = {459},
	pages = {249--289},
	journaltitle = {Neurocomputing},
	author = {Hoi, Steven {CH} and Sahoo, Doyen and Lu, Jing and Zhao, Peilin},
	date = {2021},
	note = {Publisher: Elsevier},
}

@article{yu_mopo_2020,
	title = {Mopo: Model-based offline policy optimization},
	volume = {33},
	pages = {14129--14142},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
	date = {2020},
}

@article{kidambi_morel_2020,
	title = {Morel: Model-based offline reinforcement learning},
	volume = {33},
	pages = {21810--21823},
	journaltitle = {Advances in neural information processing systems},
	author = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
	date = {2020},
}

@article{li_settling_2022,
	title = {Settling the sample complexity of model-based offline reinforcement learning},
	journaltitle = {{arXiv} preprint {arXiv}:2204.05275},
	author = {Li, Gen and Shi, Laixi and Chen, Yuxin and Chi, Yuejie and Wei, Yuting},
	date = {2022},
}

@article{yakowitz_nonparametric_1989,
	title = {Nonparametric density and regression estimation for Markov sequences without mixing assumptions},
	volume = {30},
	pages = {124--136},
	number = {1},
	journaltitle = {Journal of Multivariate Analysis},
	author = {Yakowitz, Sidney},
	date = {1989},
	note = {Publisher: Elsevier},
}

@book{zhang_matrix_2011,
	title = {Matrix theory: basic results and techniques},
	publisher = {Springer},
	author = {Zhang, Fuzhen},
	date = {2011},
}

@article{wei_note_2005,
	title = {A note on the componentwise perturbation bounds of matrix inverse and linear systems},
	volume = {169},
	pages = {1221--1236},
	number = {2},
	journaltitle = {Applied mathematics and computation},
	author = {Wei, Yimin and Cao, Yanhua and Xiang, Hua},
	date = {2005},
	note = {Publisher: Elsevier},
}

@article{kapoor_multi-agent_2018,
	title = {Multi-agent reinforcement learning: A report on challenges and approaches},
	journaltitle = {{arXiv} preprint {arXiv}:1807.09427},
	author = {Kapoor, Sanyam},
	date = {2018},
}

@inproceedings{li_settling_2022-1,
	title = {Settling the horizon-dependence of sample complexity in reinforcement learning},
	pages = {965--976},
	booktitle = {2021 {IEEE} 62nd Annual Symposium on Foundations of Computer Science ({FOCS})},
	publisher = {{IEEE}},
	author = {Li, Yuanzhi and Wang, Ruosong and Yang, Lin F},
	date = {2022},
}

@article{kuleshov_algorithms_2014,
	title = {Algorithms for multi-armed bandit problems},
	journaltitle = {{arXiv} preprint {arXiv}:1402.6028},
	author = {Kuleshov, Volodymyr and Precup, Doina},
	date = {2014},
}

@article{rashidinejad_bridging_2021,
	title = {Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
	volume = {34},
	pages = {11702--11716},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
	date = {2021},
}

@article{yin_towards_2021,
	title = {Towards instance-optimal offline reinforcement learning with pessimism},
	volume = {34},
	pages = {4065--4078},
	journaltitle = {Advances in neural information processing systems},
	author = {Yin, Ming and Wang, Yu-Xiang},
	date = {2021},
}

@article{shi_pessimistic_2022,
	title = {Pessimistic q-learning for offline reinforcement learning: Towards optimal sample complexity},
	journaltitle = {{arXiv} preprint {arXiv}:2202.13890},
	author = {Shi, Laixi and Li, Gen and Wei, Yuting and Chen, Yuxin and Chi, Yuejie},
	date = {2022},
}

@article{liu_improving_2021,
	title = {Improving ant colony optimization algorithm with epsilon greedy and Levy flight},
	volume = {7},
	pages = {1711--1722},
	number = {4},
	journaltitle = {Complex \& Intelligent Systems},
	author = {Liu, Yahui and Cao, Buyang and Li, Hehua},
	date = {2021},
	note = {Publisher: Springer},
}

@inproceedings{wunder_classes_2010,
	title = {Classes of multiagent q-learning dynamics with epsilon-greedy exploration},
	booktitle = {{ICML}},
	author = {Wunder, Michael and Littman, Michael L and Babes, Monica},
	date = {2010},
}

@article{liu_reinforcement_2020,
	title = {Reinforcement learning for clinical decision support in critical care: comprehensive review},
	volume = {22},
	pages = {e18477},
	number = {7},
	journaltitle = {Journal of medical Internet research},
	author = {Liu, Siqi and See, Kay Choong and Ngiam, Kee Yuan and Celi, Leo Anthony and Sun, Xingzhi and Feng, Mengling and {others}},
	date = {2020},
	note = {Publisher: {JMIR} Publications Inc., Toronto, Canada},
}

@article{yu_reinforcement_2021,
	title = {Reinforcement learning in healthcare: A survey},
	volume = {55},
	pages = {1--36},
	number = {1},
	journaltitle = {{ACM} Computing Surveys ({CSUR})},
	author = {Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
	date = {2021},
	note = {Publisher: {ACM} New York, {NY}},
}

@article{shortreed_informing_2011,
	title = {Informing sequential clinical decision-making through reinforcement learning: an empirical study},
	volume = {84},
	pages = {109--136},
	number = {1},
	journaltitle = {Machine learning},
	author = {Shortreed, Susan M and Laber, Eric and Lizotte, Daniel J and Stroup, T Scott and Pineau, Joelle and Murphy, Susan A},
	date = {2011},
	note = {Publisher: Springer},
}

@article{armony_patient_2015,
	title = {On patient flow in hospitals: A data-based queueing-science perspective},
	volume = {5},
	pages = {146--194},
	number = {1},
	journaltitle = {Stochastic systems},
	author = {Armony, Mor and Israelit, Shlomo and Mandelbaum, Avishai and Marmor, Yariv N and Tseytlin, Yulia and Yom-Tov, Galit B},
	date = {2015},
	note = {Publisher: {INFORMS}},
}

@article{vidyasagar_learning_2006,
	title = {A learning theory approach to system identification and stochastic adaptive control},
	pages = {265--302},
	journaltitle = {Probabilistic and randomized methods for design under uncertainty},
	author = {Vidyasagar, Mathukumalli and Karandikar, Rajeeva L},
	date = {2006},
	note = {Publisher: Springer},
}

@article{chen_probabilistic_2021,
	title = {Probabilistic machine learning for healthcare},
	volume = {4},
	pages = {393--415},
	journaltitle = {Annual Review of Biomedical Data Science},
	author = {Chen, Irene Y and Joshi, Shalmali and Ghassemi, Marzyeh and Ranganath, Rajesh},
	date = {2021},
	note = {Publisher: Annual Reviews},
}

@article{ljung_perspectives_2010,
	title = {Perspectives on system identification},
	volume = {34},
	pages = {1--12},
	number = {1},
	journaltitle = {Annual Reviews in Control},
	author = {Ljung, Lennart},
	date = {2010},
	note = {Publisher: Elsevier},
}

@book{tangirala_principles_2018,
	title = {Principles of system identification: theory and practice},
	publisher = {Crc Press},
	author = {Tangirala, Arun K},
	date = {2018},
}

@article{woodroofe_one-armed_1979,
	title = {A one-armed bandit problem with a concomitant variable},
	volume = {74},
	pages = {799--806},
	number = {368},
	journaltitle = {Journal of the American Statistical Association},
	author = {Woodroofe, Michael},
	date = {1979},
	note = {Publisher: Taylor \& Francis},
}

@inproceedings{showkatbakhsh_system_2016,
	title = {System identification in the presence of adversarial outputs},
	pages = {7177--7182},
	booktitle = {2016 {IEEE} 55th Conference on Decision and Control ({CDC})},
	publisher = {{IEEE}},
	author = {Showkatbakhsh, Mehrdad and Tabuada, Paulo and Diggavi, Suhas},
	date = {2016},
}

@article{chin_active_2020,
	title = {Active learning for linear parameter-varying system identification},
	volume = {53},
	pages = {989--994},
	number = {2},
	journaltitle = {{IFAC}-{PapersOnLine}},
	author = {Chin, Robert and Maass, Alejandro I and Ulapane, Nalika and Manzie, Chris and Shames, Iman and Nešić, Dragan and Rowe, Jonathan E and Nakada, Hayato},
	date = {2020},
	note = {Publisher: Elsevier},
}

@article{maes_offline_2016,
	title = {Offline synchronization of data acquisition systems using system identification},
	volume = {381},
	pages = {264--272},
	journaltitle = {Journal of Sound and Vibration},
	author = {Maes, Kristof and Reynders, Edwin and Rezayat, Ali and De Roeck, Guido and Lombaert, Geert},
	date = {2016},
	note = {Publisher: Elsevier},
}

@article{yan_model-based_2022,
	title = {Model-Based Reinforcement Learning Is Minimax-Optimal for Offline Zero-Sum Markov Games},
	journaltitle = {{arXiv} preprint {arXiv}:2206.04044},
	author = {Yan, Yuling and Li, Gen and Chen, Yuxin and Fan, Jianqing},
	date = {2022},
}

@article{langford_epoch-greedy_2007,
	title = {The epoch-greedy algorithm for multi-armed bandits with side information},
	volume = {20},
	journaltitle = {Advances in neural information processing systems},
	author = {Langford, John and Zhang, Tong},
	date = {2007},
}

@incollection{tewari_ads_2017,
	title = {From ads to interventions: Contextual bandits in mobile health},
	pages = {495--517},
	booktitle = {Mobile Health},
	publisher = {Springer},
	author = {Tewari, Ambuj and Murphy, Susan A},
	date = {2017},
}

@inproceedings{pinto_robust_2017,
	title = {Robust adversarial reinforcement learning},
	pages = {2817--2826},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
	date = {2017},
}

@article{raychaudhuri_active_1996,
	title = {Active learning for nonlinear system identification and control},
	volume = {29},
	pages = {2592--2596},
	number = {1},
	journaltitle = {{IFAC} Proceedings Volumes},
	author = {{RayChaudhuri}, Tirthankar and Hamey, Leonard {GC}},
	date = {1996},
	note = {Publisher: Elsevier},
}

@article{krolicki_supervised_2021,
	title = {Supervised {DKRC} with Images for Offline System Identification},
	journaltitle = {{arXiv} preprint {arXiv}:2109.02241},
	author = {Krolicki, Alexander and Lavertu, Pierre-Yves},
	date = {2021},
}

@inproceedings{yin_near-optimal_2021,
	title = {Near-optimal provable uniform convergence in offline policy evaluation for reinforcement learning},
	pages = {1567--1575},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
	date = {2021},
}

@article{rosenbaum_central_1983,
	title = {The central role of the propensity score in observational studies for causal effects},
	volume = {70},
	pages = {41--55},
	number = {1},
	journaltitle = {Biometrika},
	author = {Rosenbaum, Paul R and Rubin, Donald B},
	date = {1983},
	note = {Publisher: Oxford University Press},
}

@article{sakhi_pac-bayesian_2022,
	title = {{PAC}-Bayesian Offline Contextual Bandits With Guarantees},
	journaltitle = {{arXiv} preprint {arXiv}:2210.13132},
	author = {Sakhi, Otmane and Chopin, Nicolas and Alquier, Pierre},
	date = {2022},
}

@article{dai_queueing_2022,
	title = {Queueing network controls via deep reinforcement learning},
	volume = {12},
	pages = {30--67},
	number = {1},
	journaltitle = {Stochastic Systems},
	author = {Dai, Jim G and Gluzman, Mark},
	date = {2022},
	note = {Publisher: {INFORMS}},
}

@inproceedings{foster_beyond_2020,
	title = {Beyond ucb: Optimal and efficient contextual bandits with regression oracles},
	pages = {3199--3210},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Foster, Dylan and Rakhlin, Alexander},
	date = {2020},
}

@inproceedings{li_nearly_2019,
	title = {Nearly minimax-optimal regret for linearly parameterized bandits},
	pages = {2173--2174},
	booktitle = {Conference on Learning Theory},
	publisher = {{PMLR}},
	author = {Li, Yingkai and Wang, Yining and Zhou, Yuan},
	date = {2019},
}

@inproceedings{sart_estimation_2014,
	title = {Estimation of the transition density of a Markov chain},
	volume = {50},
	pages = {1028--1068},
	booktitle = {Annales de l'{IHP} Probabilités et statistiques},
	author = {Sart, Mathieu},
	date = {2014},
	note = {Issue: 3},
}

@article{sutulo_offline_2015,
	title = {Offline system identification of ship manoeuvring mathematical models with a global optimization algorithm},
	pages = {8--11},
	journaltitle = {{MARSIM} 2015},
	author = {Sutulo, Serge and Guedes Soares, C},
	date = {2015},
}

@article{mutti_importance_2022,
	title = {The Importance of Non-Markovianity in Maximum State Entropy Exploration},
	journaltitle = {{arXiv} preprint {arXiv}:2202.03060},
	author = {Mutti, Mirco and De Santi, Riccardo and Restelli, Marcello},
	date = {2022},
}

@online{noauthor_research_nodate,
	title = {Research Statement},
	url = {https://www.overleaf.com/project/633612701bb1da83880aece0},
	abstract = {An online {LaTeX} editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of {LaTeX} templates, and more.},
	urldate = {2022-10-31},
	langid = {english},
}

@inproceedings{agarwal_model-based_2020,
	title = {Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal},
	url = {https://proceedings.mlr.press/v125/agarwal20b.html},
	abstract = {This work considers the sample and computational complexity of obtaining an ϵϵ{\textbackslash}epsilon-optimal policy in a discounted Markov Decision Process ({MDP}), given only access to a generative model. In this model, the learner accesses the underlying transition model via a sampling oracle that provides a sample of the next state, when given any state-action pair as input. We are interested in a basic and unresolved question in model based planning: is this naïve “plug-in” approach — where we build the maximum likelihood estimate of the transition model in the {MDP} from observations and then find an optimal policy in this empirical {MDP} — non-asymptotically, minimax optimal? Our main result answers this question positively. With regards to computation, our result provides a simpler approach towards minimax optimal planning: in comparison to prior model-free results,  we show that using {\textbackslash}emph\{any\} high accuracy, black-box planning oracle in the empirical model suffices to obtain the minimax error rate. The key proof technique uses a leave-one-out analysis, in a novel “absorbing {MDP}” construction, to decouple the statistical dependency issues that arise in the analysis of model-based planning; this construction may be helpful more generally.},
	eventtitle = {Conference on Learning Theory},
	pages = {67--83},
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
	publisher = {{PMLR}},
	author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
	urldate = {2022-10-02},
	date = {2020-07-15},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}

@article{zacks_review_1970,
	title = {Review: Sidney J. Yakowitz, Mathematics of Adaptive Control Processes},
	volume = {41},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-41/issue-3/Review-Sidney-J-Yakowitz-Mathematics-of-Adaptive-Control-Processes/10.1214/aoms/1177696998.full},
	doi = {10.1214/aoms/1177696998},
	shorttitle = {Review},
	abstract = {The Annals of Mathematical Statistics},
	pages = {1128--1131},
	number = {3},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Zacks, S.},
	urldate = {2022-10-02},
	date = {1970-06},
	note = {Publisher: Institute of Mathematical Statistics},
}

@inproceedings{honorio_tight_2014,
	title = {Tight bounds for the expected risk of linear classifiers and {PAC}-Bayes finite-sample guarantees},
	pages = {384--392},
	booktitle = {Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Honorio, Jean and Jaakkola, Tommi},
	date = {2014},
}

@article{lei_sparsistency_2015,
	title = {Sparsistency and agnostic inference in sparse {PCA}},
	volume = {43},
	pages = {299--322},
	number = {1},
	journaltitle = {The Annals of Statistics},
	author = {Lei, Jing and Vu, Vincent Q},
	date = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
}

@book{paul_nonparametric_2005,
	title = {Nonparametric estimation of principal components},
	publisher = {Stanford University},
	author = {Paul, Debashis},
	date = {2005},
}

@article{paul_asymptotics_2007,
	title = {Asymptotics of sample eigenstructure for a large dimensional spiked covariance model},
	pages = {1617--1642},
	journaltitle = {Statistica Sinica},
	author = {Paul, Debashis},
	date = {2007},
	note = {Publisher: {JSTOR}},
}

@inproceedings{zhang_meta_2021,
	title = {Meta Learning for Support Recovery in High-dimensional Precision Matrix Estimation},
	pages = {12642--12652},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Zhang, Qian and Zheng, Yilin and Honorio, Jean},
	date = {2021},
}

@book{pollard_processes_1984,
	title = {{PROCESSES}: {THEORY} {AND} {APPLICATIONS}},
	author = {Pollard, David},
	date = {1984},
}

@inproceedings{wang_sample_2021,
	title = {The Sample Complexity of Meta Sparse Regression},
	pages = {2323--2331},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Wang, Zhanyu and Honorio, Jean},
	date = {2021},
}

@inproceedings{amini_high-dimensional_2008,
	title = {High-dimensional analysis of semidefinite relaxations for sparse principal components},
	pages = {2454--2458},
	booktitle = {2008 {IEEE} international symposium on information theory},
	publisher = {{IEEE}},
	author = {Amini, Arash A and Wainwright, Martin J},
	date = {2008},
}

@book{boyd_convex_2004,
	title = {Convex optimization},
	publisher = {Cambridge university press},
	author = {Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
	date = {2004},
}

@article{vu_fantope_2013,
	title = {Fantope projection and selection: A near-optimal convex relaxation of sparse {PCA}},
	volume = {26},
	journaltitle = {Advances in neural information processing systems},
	author = {Vu, Vincent Q and Cho, Juhee and Lei, Jing and Rohe, Karl},
	date = {2013},
}

@article{marshall_multivariate_1960,
	title = {Multivariate chebyshev inequalities},
	pages = {1001--1014},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Marshall, Albert W and Olkin, Ingram},
	date = {1960},
	note = {Publisher: {JSTOR}},
}

@article{lin_development_2008,
	title = {Development of wireless brain computer interface with embedded multitask scheduling and its application on real-time driver's drowsiness detection and warning},
	volume = {55},
	pages = {1582--1591},
	number = {5},
	journaltitle = {{IEEE} Transactions on Biomedical Engineering},
	author = {Lin, Chin-Teng and Chen, Yu-Chieh and Huang, Teng-Yi and Chiu, Tien-Ting and Ko, Li-Wei and Liang, Sheng-Fu and Hsieh, Hung-Yi and Hsu, Shang-Hwa and Duann, Jeng-Ren},
	date = {2008},
	note = {Publisher: {IEEE}},
}

@inproceedings{zheng_attribute_2015,
	title = {Attribute knowledge integration for speech recognition based on multi-task learning neural networks},
	booktitle = {Sixteenth Annual Conference of the International Speech Communication Association},
	author = {Zheng, Hao and Yang, Zhanlei and Qiao, Liwei and Li, Jianping and Liu, Wenju},
	date = {2015},
}

@article{overton_sum_1992,
	title = {On the sum of the largest eigenvalues of a symmetric matrix},
	volume = {13},
	pages = {41--45},
	number = {1},
	journaltitle = {{SIAM} Journal on Matrix Analysis and Applications},
	author = {Overton, Michael L and Womersley, Robert S},
	date = {1992},
	note = {Publisher: {SIAM}},
}

@article{sun_image_2019,
	title = {Image classification base on {PCA} of multi-view deep representation},
	volume = {62},
	pages = {253--258},
	journaltitle = {Journal of Visual Communication and Image Representation},
	author = {Sun, Yaoqi and Li, Liang and Zheng, Liang and Hu, Ji and Li, Wenchao and Jiang, Yatong and Yan, Chenggang},
	date = {2019},
	note = {Publisher: Elsevier},
}

@inproceedings{deshpande_information-theoretically_2014,
	title = {Information-theoretically optimal sparse {PCA}},
	doi = {10.1109/ISIT.2014.6875223},
	pages = {2197--2201},
	booktitle = {2014 {IEEE} International Symposium on Information Theory},
	author = {Deshpande, Yash and Montanari, Andrea},
	date = {2014},
}

@article{meinshausen_lasso-type_2009,
	title = {Lasso-type recovery of sparse representations for high-dimensional data},
	volume = {37},
	pages = {246--270},
	number = {1},
	journaltitle = {The annals of statistics},
	author = {Meinshausen, Nicolai and Yu, Bin},
	date = {2009},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{meinshausen_high-dimensional_2006,
	title = {High-dimensional graphs and variable selection with the lasso},
	volume = {34},
	pages = {1436--1462},
	number = {3},
	journaltitle = {The annals of statistics},
	author = {Meinshausen, Nicolai and Bühlmann, Peter},
	date = {2006},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{van_de_geer_conditions_2009,
	title = {On the conditions used to prove oracle results for the Lasso},
	volume = {3},
	pages = {1360--1392},
	journaltitle = {Electronic Journal of Statistics},
	author = {Van De Geer, Sara A and Bühlmann, Peter},
	date = {2009},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
}

@article{zhao_model_2006,
	title = {On model selection consistency of Lasso},
	volume = {7},
	pages = {2541--2563},
	journaltitle = {The Journal of Machine Learning Research},
	author = {Zhao, Peng and Yu, Bin},
	date = {2006},
	note = {Publisher: {JMLR}. org},
}

@article{park_sparse_2019,
	title = {Sparse principal component analysis with missing observations},
	volume = {13},
	pages = {1016--1042},
	number = {2},
	journaltitle = {The Annals of Applied Statistics},
	author = {Park, Seyoung and Zhao, Hongyu},
	date = {2019},
	note = {Publisher: Institute of Mathematical Statistics},
}

@incollection{lounici_sparse_2013,
	title = {Sparse principal component analysis with missing observations},
	pages = {327--356},
	booktitle = {High dimensional probability {VI}},
	publisher = {Springer},
	author = {Lounici, Karim},
	date = {2013},
}

@article{zou_sparse_2006,
	title = {Sparse principal component analysis},
	volume = {15},
	pages = {265--286},
	number = {2},
	journaltitle = {Journal of computational and graphical statistics},
	author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
	date = {2006},
	note = {Publisher: Taylor \& Francis},
}

@article{johnstone_consistency_2009,
	title = {On consistency and sparsity for principal components analysis in high dimensions},
	volume = {104},
	pages = {682--693},
	number = {486},
	journaltitle = {Journal of the American Statistical Association},
	author = {Johnstone, Iain M and Lu, Arthur Yu},
	date = {2009},
	note = {Publisher: Taylor \& Francis},
}

@inproceedings{zhang_global_2008,
	title = {A global perspective on renewable energy resources: {NASA}’s prediction of worldwide energy resources (power) project},
	pages = {2636--2640},
	booktitle = {Proceedings of {ISES} World Congress 2007 (Vol. I–Vol. V)},
	publisher = {Springer},
	author = {Zhang, Taiping and Chandler, William S and Hoell, James M and Westberg, David and Whitlock, Charles H and Stackhouse, Paul W},
	date = {2008},
}

@article{hoffmann_kernel_2007,
	title = {Kernel {PCA} for novelty detection},
	volume = {40},
	pages = {863--874},
	number = {3},
	journaltitle = {Pattern recognition},
	author = {Hoffmann, Heiko},
	date = {2007},
	note = {Publisher: Elsevier},
}

@article{mourtada_improper_2022,
	title = {An improper estimator with optimal excess risk in misspecified density estimation and logistic regression.},
	volume = {23},
	pages = {31--1},
	journaltitle = {J. Mach. Learn. Res.},
	author = {Mourtada, Jaouad and Gaïffas, Stéphane},
	date = {2022},
}

@article{ma_sparse_2013,
	title = {Sparse principal component analysis and iterative thresholding},
	volume = {41},
	pages = {772--801},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Ma, Zongming},
	date = {2013},
	note = {Publisher: Institute of Mathematical Statistics},
}

@inproceedings{jenatton_structured_2010,
	title = {Structured sparse principal component analysis},
	pages = {366--373},
	booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{JMLR} Workshop and Conference Proceedings},
	author = {Jenatton, Rodolphe and Obozinski, Guillaume and Bach, Francis},
	date = {2010},
}

@article{persichetti_data-driven_2021,
	title = {A data-driven functional mapping of the anterior temporal lobes},
	volume = {41},
	pages = {6038--6049},
	number = {28},
	journaltitle = {Journal of Neuroscience},
	author = {Persichetti, Andrew S and Denning, Joseph M and Gotts, Stephen J and Martin, Alex},
	date = {2021},
	note = {Publisher: Soc Neuroscience},
}

@inproceedings{yamane_multitask_2016,
	title = {Multitask principal component analysis},
	pages = {302--317},
	booktitle = {Asian Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Yamane, Ikko and Yger, Florian and Berar, Maxime and Sugiyama, Masashi},
	date = {2016},
}

@inproceedings{yu_supervised_2006,
	title = {Supervised probabilistic principal component analysis},
	pages = {464--473},
	booktitle = {Proceedings of the 12th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	author = {Yu, Shipeng and Yu, Kai and Tresp, Volker and Kriegel, Hans-Peter and Wu, Mingrui},
	date = {2006},
}

@article{baik_eigenvalues_2006,
	title = {Eigenvalues of large sample covariance matrices of spiked population models},
	volume = {97},
	pages = {1382--1408},
	number = {6},
	journaltitle = {Journal of multivariate analysis},
	author = {Baik, Jinho and Silverstein, Jack W},
	date = {2006},
	note = {Publisher: Elsevier},
}

@article{nadler_finite_2008,
	title = {Finite sample approximation results for principal component analysis: A matrix perturbation approach},
	volume = {36},
	pages = {2791--2817},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Nadler, Boaz},
	date = {2008},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{jung_pca_2009,
	title = {{PCA} consistency in high dimension, low sample size context},
	volume = {37},
	pages = {4104--4130},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Jung, Sungkyu and Marron, J Stephen},
	date = {2009},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{hoyle_principal-component-analysis_2004,
	title = {Principal-component-analysis eigenvalue spectra from data with symmetry-breaking structure},
	volume = {69},
	pages = {026124},
	number = {2},
	journaltitle = {Physical Review E},
	author = {Hoyle, David C and Rattray, Magnus},
	date = {2004},
	note = {Publisher: {APS}},
}

@article{birnbaum_minimax_2013,
	title = {Minimax bounds for sparse {PCA} with noisy high-dimensional data},
	volume = {41},
	pages = {1055},
	number = {3},
	journaltitle = {Annals of statistics},
	author = {Birnbaum, Aharon and Johnstone, Iain M and Nadler, Boaz and Paul, Debashis},
	date = {2013},
	note = {Publisher: {NIH} Public Access},
}

@article{tiomoko_pca-based_2021,
	title = {Pca-based multi task learning: a random matrix approach},
	journaltitle = {{arXiv} preprint {arXiv}:2111.00924},
	author = {Tiomoko, Malik and Couillet, Romain and Pascal, Frédéric},
	date = {2021},
}

@inproceedings{verleysen_curse_2005,
	title = {The curse of dimensionality in data mining and time series prediction},
	pages = {758--770},
	booktitle = {International work-conference on artificial neural networks},
	publisher = {Springer},
	author = {Verleysen, Michel and François, Damien},
	date = {2005},
}

@article{cai_sparse_2013,
	title = {Sparse {PCA}: Optimal rates and adaptive estimation},
	volume = {41},
	pages = {3074--3110},
	number = {6},
	journaltitle = {The Annals of Statistics},
	author = {Cai, T Tony and Ma, Zongming and Wu, Yihong},
	date = {2013},
	note = {Publisher: Institute of Mathematical Statistics},
}

@article{xie_meta_2022,
	title = {Meta Learning for High-dimensional Ising Model Selection Using \$l\_1\$-regularized Logistic Regression},
	journaltitle = {{arXiv} preprint {arXiv}:2208.09539},
	author = {Xie, Huiming and Honorio, Jean},
	date = {2022},
}

@inproceedings{jain_improved_2018,
	title = {Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning.},
	pages = {2454--2458},
	booktitle = {Interspeech},
	author = {Jain, Abhinav and Upreti, Minali and Jyothi, Preethi},
	date = {2018},
}

@article{zeng_new_2021,
	title = {A new deep belief network-based multi-task learning for diagnosis of Alzheimer’s disease},
	pages = {1--12},
	journaltitle = {Neural Computing and Applications},
	author = {Zeng, Nianyin and Li, Han and Peng, Yonghong},
	date = {2021},
	note = {Publisher: Springer},
}

@article{xing_new_2021,
	title = {A new multi-task learning framework for fuel cell model outputs in high-dimensional spaces},
	volume = {482},
	pages = {228930},
	journaltitle = {Journal of Power Sources},
	author = {Xing, {WW} and Yu, F and Leung, {PK} and Li, X and Wang, P and Shah, {AA}},
	date = {2021},
	note = {Publisher: Elsevier},
}

@article{fan_joint_2018,
	title = {Joint optical performance monitoring and modulation format/bit-rate identification by {CNN}-based multi-task learning},
	volume = {10},
	pages = {1--12},
	number = {5},
	journaltitle = {{IEEE} Photonics Journal},
	author = {Fan, Xiaojie and Xie, Yulai and Ren, Fang and Zhang, Yiying and Huang, Xiaoshan and Chen, Wei and Zhangsun, Tianwen and Wang, Jianping},
	date = {2018},
	note = {Publisher: {IEEE}},
}

@article{liao_multi-task_2019,
	title = {Multi-task deep convolutional neural network for cancer diagnosis},
	volume = {348},
	pages = {66--73},
	journaltitle = {Neurocomputing},
	author = {Liao, Qing and Ding, Ye and Jiang, Zoe L and Wang, Xuan and Zhang, Chunkai and Zhang, Qian},
	date = {2019},
	note = {Publisher: Elsevier},
}

@article{khodak_adaptive_2019,
	title = {Adaptive gradient-based meta-learning methods},
	volume = {32},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Khodak, Mikhail and Balcan, Maria-Florina F and Talwalkar, Ameet S},
	date = {2019},
}

@inproceedings{wang_bridging_2021,
	title = {Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation},
	pages = {10991--11002},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Wang, Haoxiang and Zhao, Han and Li, Bo},
	date = {2021},
}

@article{hospedales_meta-learning_2021,
	title = {Meta-learning in neural networks: A survey},
	volume = {44},
	pages = {5149--5169},
	number = {9},
	journaltitle = {{IEEE} transactions on pattern analysis and machine intelligence},
	author = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	date = {2021},
	note = {Publisher: {IEEE}},
}

@article{wu_learning_2019,
	title = {Learning to learn and predict: A meta-learning approach for multi-label classification},
	journaltitle = {{arXiv} preprint {arXiv}:1909.04176},
	author = {Wu, Jiawei and Xiong, Wenhan and Wang, William Yang},
	date = {2019},
}

@online{noauthor_statistical_nodate,
	title = {Statistical Estimation of Inhomogenous Markov Chains (Corrected Complexity) - Online {LaTeX} Editor Overleaf},
	url = {https://www.overleaf.com/project/62c5ce8b05e1677c7d59e9e4},
	urldate = {2022-10-02},
}
