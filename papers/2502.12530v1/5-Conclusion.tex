\section{Conclusion}

We justify that a flow matching generative model can produce dense and reliable rewards for training LLMs to explain the decisions of RL agents and other LLMs. 
Looking into the future, we envision extending this method to a general LLM training approach, automatically generating high-quality dense rewards, and ultimately reducing the reliance on human feedback. 

% Our method has the potential to facilitate human-AI collaboration applications, such as transportation, education, and security defense.

\newpage
\section{Impact Statements}
This paper presents work whose goal is to advance the field of machine learning by developing a model-agnostic explanation generator for intelligent agents, enhancing transparency and interpretability in agent decision prediction. The ability to generate effective and interpretable explanations has the potential to foster trust in AI systems, improving effectiveness in high-stakes applications such as healthcare, finance, and autonomous systems. Overall, we believe our work contributes positively to the broader AI ecosystem by promoting more explainable and trustworthy AI.