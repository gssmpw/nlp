\section{Related Work}
\paragraph{Image Super-Resolution.} 
Deep learning based approaches have demonstrated striking power in the realm of SR____.
As a groundbreaking work, SRCNN____ initiates the track of solving SR problem via deep learning based approach.
Thereafter, substantial contributions have been made to explore the best SR network architecture.
For example, RCAN____ leverages the residual in residual structure and deepens the network to more than 400 layers.
SwinIR____ is based on vision transformer structure and utilizes spatial window self-attention to capture the overall structure information.
CAT____ combines the attention mechanism and the CNN structure to make the most of the local and the global information.
However, most of these conventional image super-resolution methods can not handle the Real-SR task because of the complex degradation in real world.

\vspace{-4mm}
\paragraph{Diffusion Model.} 
In recent years, the diffusion based methods have gained remarkable performance in many computer vision tasks and SR is no exception.
For instance, SR3____ restores the LQ by transforming the standard normal distribution into the empirical data distribution by learning a series of iterative refinement steps.
DiffBIR____ capitalizes on two restoration stage to seek the tradeoff of fidelity and quality.
SinSR____ effectively reduces the inference step to only one step via distillation and regularization.
Following SinSR, OSEDiff____ modifies the distillation paradigm and novel losses are introduced to improve face restoration ability.
Despite the greatly improved inference speed, the model size remains the same and there is still room for further acceleration.



\vspace{-4mm}
\paragraph{Binarization.} 
As the most extreme form of quantization, binarization typically compresses the weight into only 1 bit.
In binarization, all the weights are seen as $\pm 1$ and the multiplications between weights and activations are converted to bit operation on sign bit of activation, allowing maximum compression and acceleration.
Binarization related researches are mainly about classification tasks initially____.
Recently, researchers begin to perform binarization on image restoration tasks.
Binary Latent Diffusion____ trains an auto-encoder with a binary latent space and mainly focus on the Bernoulli distribution instead of acceleration.
BiDM____ leverages timestep-friendly binary structure and space patched distillation to compress the diffusion model to 1 bit.
BI-DiffSR____ designs several binary friendly modules and redistribute the activation of different time step.
However, the inference step remains the same.
Therefore, it is necessary to further compress the model to one step.


\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/overview.pdf}
    \vspace{-7mm}
    \caption{Overview of our proposed BiMaCoSR which employs three different compressed matrix branches. (a) The structure of a convolution layer in BiMaCoSR after binarization. Two auxiliary branches, \ie LRMB and SMB, support BiMaCoSR's excellent performance. The linear layer can be regarded as 1$\times$1 convolution layer and is processed with the same pipeline. (b) Illustration of the initialization sequence and how the three branches solve the weakness of other branch. 
}
    \label{fig:method-overview}
    \vspace{-4.5mm}
\end{figure*}