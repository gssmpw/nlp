\section{Related Work}
% \subsection{Adversarial Defense on Graphs.}

\textbf{Robust Graph Learning.}
Various efforts have been made to improve the robustness of graph learning against adversarial attacks, which can be grouped into four categories. 
1) \textit{Structure Learning Based} methods~\cite{jin2020graph, deng2022garnet, zhao2023self, in2024self} adjust the graph structure by removing unreliable edges or nodes to improve robustness. Pro-GNN~\cite{jin2020graph} uses low-rank and smoothness regularization, GARNET~\cite{deng2022garnet} employs probabilistic models to learn a reduced-rank topology, GSR~\cite{zhao2023self} leverages contrastive learning for structure refinement, and SG-GSR~\cite{in2024self} addresses structural loss and node imbalance.
2) \textit{Preprocessing Based} methods~\cite{entezari2020all, wu2019adversarial}  modify the graph before training. SVDGCN~\cite{entezari2020all} retains top-k singular values from the adjacency matrix, while JaccardGCN~\cite{wu2019adversarial} prunes adversarial edges based on Jaccard similarity.
3) \textit{Robust Aggregation Based} methods~\cite{tang2020transferring, zhu2019robust, chen2021understanding, geisler2021robustness} improve the aggregation process to reduce sensitivity to adversarial perturbations. PA-GNN~\cite{tang2020transferring} and RGCN~\cite{zhu2019robust} use attention mechanisms to downweight adversarial edges, while Median~\cite{chen2021understanding} and Soft-Median~\cite{geisler2021robustness} apply robust aggregation strategies to mitigate the effect of noisy features.
4) \textit{Adversarial Training Based} methods~\cite{xu2019topology} 
% improve robustness by introducing adversarial examples during training through a min-max optimization framework, forcing the model to learn resistance to attacks.
incorporate adversarial examples during training using min-max optimization to enhance resistance to attacks.

% \subsection{Graph Diffusion}
\textbf{Graph Diffusion Models.}
Diffusion models have achieved significant success in graph generation tasks. Early works  \cite{niu2020permutation,jo2022score} extended stochastic differential equations to graphs, but faced challenges due to the discrete nature of graphs. Graph structured diffusion \cite{vignac2022digress,haefeli2022diffusion} addressed this by adapting D3PM~\cite{austin2021structured}, improving the quality and efficiency of graph generation. In addition, HypDiff~\cite{fu2024hyperbolic} introduced a geometrically-based framework that preserves non-isotropic graph properties.
To enhance scalability, EDGE~\cite{chen2023efficient} promotes sparsity by setting the empty graph as the target distribution. 
GraphMaker~\cite{li2023graphmaker} further improved graph quality by applying asynchronous denoising to adjacency matrix and node features.
However, directly applying existing graph diffusion models fails to achieve our goal because the indiscriminate noise risks damaging clean nodes. Additionally, the diversity of the graph diffusion model may lead to generated graphs that fit the clean distribution but have semantic information that differs from the target clean graph.
