\section{Results and Discussion}
\label{label:results}
\begin{table*}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{4.3cm}|p{4.3cm}|p{4.3cm}|p{4.3cm}}
\toprule
\textbf{Paragraph} & \textbf{Gold} &\textbf{Llama-Base}  &\textbf{Llama-FT}\\
\hline
Every single person when I came to them saying, ‘Can I get a half billion dollar bond?’ & The paragraph is \textit{not propagandistic} because it merely conveys an individual's experience without attempting to manipulate the audience's perception or promote a specific agenda. & The text appears to be \textit{propagandistic} because it presents a personal anecdote that is likely intended to persuade or influence the audience, rather than providing a neutral statement. & The paragraph is \textit{not propagandistic} because it presents a straightforward statement without employing manipulative language or techniques.\\
\bottomrule
\end{tabular}%
}
% \vspace{-0.2cm}
\caption{Generated explanations by different models.}
\label{tab:exp_example}
\vspace{-0.3cm}
\end{table*}



We compare our proposed fine-tuned Llama 3.1 8B Instruct model to baseline models: fine-tuned transformer models using AraBERT (as reported in \citet{hasanain2024can}) and BERT-base for Arabic and English, respectively. These models are commonly-used for the task~\cite{hasanain-etal-2023-araieval}. Additionally, we compare the model's performance to two LLMs: GPT-4o and un-finetuned Llama 3.1 8B Instruct. As table~\ref{tab:propaganda_results} shows, the performance of our fine-tuned Llama model achieves a Micro F1 score that is on par or better than other models. Specifically, the model significantly outperforms the other LLMs tested.

As for its performance in explanation, in reference to the gold explanations, we observe a 25\% and 40\% improvements over the base model for English and Arabic, respectively. The fine-tuned model shows better alignment with gold explanations as demonstrated by the example in Table~\ref{tab:propaganda_results}.



\begin{table}[h]
\centering
\setlength{\tabcolsep}{2pt} 
\scalebox{0.95}{
\begin{tabular}{@{}lrrr@{}}
\toprule
\textbf{Model} & \multicolumn{1}{c}{\textbf{F1$_{Micro}$}} & \multicolumn{1}{c}{\textbf{F1$_{Macro}$}} & \multicolumn{1}{l}{\textbf{F1$_{BERT}$}} \\ \midrule
\multicolumn{4}{c}{\textbf{Arabic}} \\ \midrule
%\cite{hasanain2024can} & 0.767 & 0.750 & -- \\
AraBERT & 0.762 & 0.749 & -- \\
GPT-4o & 0.575 & 0.567 & -- \\
Llama 3.1 8B (Base) & 0.588 & 0.588 & 0.507 \\
Llama 3.1 8B (FT) & 0.769 & 0.750 & 0.706 \\ \midrule
\multicolumn{4}{c}{\textbf{English}} \\ \midrule
BERT-base & 0.772 & 0.691 & -- \\
GPT-4o & 0.649 & 0.630 & -- \\
Llama 3.1 8B (Base) & 0.572 & 0.562 & 0.596 \\
Llama 3.1 8B (FT) & 0.770 & 0.649 & 0.747 \\
\bottomrule
\end{tabular}
}
% \vspace{-0.2cm}
\caption{Performance of the proposed model and baselines. F1$_{BERT}$ is the F1 score computed using BERTScore for the explanation.
}
\label{tab:propaganda_results}
\vspace{-0.3cm}
\end{table}




