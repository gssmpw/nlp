
\section{Annotation Guideline}
\label{sec:app_annotation_guideline}
You will be shown a news paragraph, a label assigned to it, and an explanation for the assigned label. As an annotator, your task is to carefully examine each news paragraph, label, and explanation. Then assess the quality of the explanation provided for the assigned label. Follow the steps below to ensure a thorough evaluation:

\textbf{Analyze the News Paragraph}

\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item Observe the image and read the accompanying text.
    \item Understand the overall message and potential implications of the news paragraph.
\end{itemize}

\textbf{Check the Assigned Label}
\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item Check the given label. The label is the result of annotation done by multiple human annotators.
\end{itemize}

\textbf{Evaluate the Explanation}
\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item Read the explanation provided for why the news paragraph has been assigned its label.
    \item Assess the explanation based on the metrics below. Each metric is scored on a Likert scale from 1-5.
\end{itemize}

\subsection*{Metrics}

\paragraph{Informativeness}
Measures the extent to which the explanation provides relevant and meaningful information for understanding the reasoning behind the label. A highly informative explanation offers detailed insights that directly contribute to the justification, while a low-informative explanation may be vague, incomplete, or lacking key details.

As an annotator, you are judging if the explanation is providing enough information to explain the label assigned.

\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item 1 = Not informative: The explanation lacks relevant details and does not help understand why the news paragraph is labeled as such.
    \item 2 = Slightly informative: The explanation provides minimal information, but key details are missing or unclear.
    \item 3 = Moderately informative: The explanation contains some useful details but lacks depth or supporting reasoning.
    \item 4 = Informative: The explanation is well-detailed, providing a clear and meaningful justification for the label.
    \item 5 = Very informative: The explanation is thorough, insightful, and fully justifies the label with strong supporting details.
\end{itemize}

\paragraph{Clarity}
Assesses how clearly the explanation conveys its meaning. A clear explanation is well-structured, concise, and easy to understand without requiring additional effort. It should be free from ambiguity, overly complex language, or poor phrasing that might hinder comprehension.

As an annotator, you are judging the language and the structure of the explanation. Spelling mistakes, awkward use of language, and wrong translation will affect this metric negatively.

\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item 1 = Very unclear: The explanation is confusing, vague, or difficult to understand.
    \item 2 = Somewhat unclear: The explanation has some clarity but includes ambiguous or poorly structured statements.
    \item 3 = Neutral: The explanation is somewhat clear but may require effort to fully grasp.
    \item 4 = Clear: The explanation is well-structured and easy to understand with minimal ambiguity.
    \item 5 = Very clear: The explanation is highly readable, precise, and effortlessly understandable.
\end{itemize}

\paragraph{Plausibility}
Refers to the extent to which an explanation logically supports the assigned label and appears reasonable given the news paragraph's content. A plausible explanation should be coherent, factually consistent, and align with the expected reasoning behind the label. While it does not require absolute correctness, it should not contain obvious contradictions or illogical claims.

As an annotator, you are judging if the explanation actually supports the label assigned to it. For example, if a text is labeled as ``Not Propaganda,'' the explanation given should be for that label.

\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item 1 = Not plausible at all: The explanation does not align with the label and seems completely incorrect.
    \item 2 = Weakly plausible: The explanation has some relevance but lacks strong justification or contains logical inconsistencies.
    \item 3 = Moderately plausible: The explanation somewhat supports the label but may be incomplete or partially flawed.
    \item 4 = Plausible: The explanation logically supports the label and is mostly reasonable.
    \item 5 = Highly plausible: The explanation is fully aligned with the label and presents a strong, logical justification.
\end{itemize}

\paragraph{Faithfulness}
Measures how accurately an explanation reflects the reasoning behind the assigned label. A faithful explanation correctly represents the key factors and logical steps that justify the label, without adding misleading or unrelated details. High faithfulness means the explanation stays true to the actual reasoning used for classification, ensuring reliability and consistency.

As an annotator, you are judging how well the explanation reflects the logic behind the label. For example, if the explanation claims an implication of the text, it should also present the logical reasoning behind it.

\begin{itemize}[noitemsep,topsep=0pt,labelsep=.5em]
    \item 1 = Not faithful at all: The explanation is completely unrelated to the given label and does not reflect a valid reasoning process.
    \item 2 = Weakly faithful: Some elements of the explanation are relevant, but much of it is misleading, inconsistent, or lacks proper justification.
    \item 3 = Moderately faithful: The explanation captures parts of the reasoning but includes unrelated, unclear, or unnecessary justifications.
    \item 4 = Faithful: The explanation aligns well with the reasoning behind the label and includes relevant, logical details.
    \item 5 = Highly faithful: The explanation fully and accurately reflects the correct reasoning, without any misleading or irrelevant information.
\end{itemize}

\section{Annotation Platform}
\label{sec:app_annotation_platform}

We present the screenshot of the interface designed for the evaluation of LLM generated explanation, which consisted
of a paragraph, label, and explanation for the label, annotation guidelines, and four different evaluation metrics including informativeness, clarity, plausibility, and faithfulness. 5-point Likert scale is used for each evaluation metric and the annotator is asked to follow the annotation guideline to select an appropriate Likert scale value for each metric.

\begin{figure*}[]
    \centering
    \includegraphics[scale=0.4]{figures/english_propaganda_annotation_interface.png}
    \caption{A screenshot of the annotation platform for the explanation evaluation of English propaganda.}
    \label{fig:hateful_meme_annotation_interface}
\end{figure*}

\section{Annotation Setup}
\label{sec:app_annotation_setup}
We recruited annotators who are native Arabic speakers and fluent in English, all holding at least a bachelor's degree. Since they were proficient in English, they also worked on English news paragraphs. We provided annotation guidelines and necessary consultation. All annotators had prior experience with similar tasks. A total of six annotators participated in the evaluation task. In accordance with institutional requirements, each signed a Non-Disclosure Agreement (NDA). For their compensation, we hired a third-party company to manage payments at standard hourly rates based on location.



\section{Prompts}
\label{apndix:prompts}
To generate instructions for the instruction-following dataset, we prompt the LLMs using the following prompt: \textit{We are creating an English instruction-following dataset for an [language] dataset covering the task of propaganda detection with explanation. The user defined the task as follows: Detecting propaganda in a piece of text and explaining why this piece of text is propagandistic. Propaganda can be defined as a form of communication aimed at influencing peopleâ€™s opinions or actions toward a specific goal, using well-defined rhetorical and psychological techniques. For that task, the labels include: ['non-propagandistic', 'propagandistic']. Write 10 very diverse and concise English instructions making sure the labels provided above are part of the instruction. Only return the instructions without additional text.}



\section{Data Release}
\label{apndix:release}
Our proposed dataset\footnote{\url{anonymous.com}} will be released under the CC BY-NC-SA 4.0 -- Creative Commons Attribution 4.0 International License: \url{https://creativecommons.org/licenses/by-nc-sa/4.0/}.
