

\section{Introduction}
\label{sec:intro}

The rise of online job platforms has dramatically transformed the hiring landscape. Applicants now have the ability to apply to a large number of jobs with minimal effort, resulting in job postings often receiving an overwhelming number of applications. 
To manage this influx, many employers rely on algorithmic tools to aid in the screening process --- three-fourths of employers in the United States use automated tools to screen candidates \citep{fuller2021hidden}. These tools range from simple keyword filters to advanced machine learning models that evaluate answers to interview questions \citep{raghavan2020mitigating}.
Research has shown that algorithmic recommendations can improve job fill rates \citep{horton2017effects}, demonstrating their potential to enhance labor market efficiency.  
Despite these benefits, the increasing reliance and widespread adoptions on algorithmic systems raises questions about their implications on resulting outcomes for both firms and applicants.

While larger firms may be able to develop such algorithmic systems in-house, many firms employ tools provided by external vendors (e.g., LinkedIn, HireVue, ThriveMap, etc.). This can result in multiple firms using the \textit{same} algorithm, which raises fundamental questions about competition and efficiency in hiring outcomes in such settings.   
This scenario where multiple agents leverage the same algorithm is referred to as \textit{algorithmic monoculture}, a term which draws parallels to the agricultural practice of cultivating a single crop species, which can lead to vulnerabilities such as disease outbreaks due to lack of diversity. Similarly, algorithmic monoculture can create inefficiencies and homogenization in hiring outcomes. Recent studies have highlighted potential risks associated with this phenomenon, including reduced firm utility and adverse effects on applicant welfare \citep{kleinberg2021algorithmic,bommasani2022picking,peng2023monoculture}. 
In this paper, we consider a setting where algorithmic monoculture exists, and we evaluate how firms can make \textit{strategic} interview and hiring decisions to mitigate inefficiencies.

Concretely, consider an algorithm that evaluates candidates based on their resumes and assigns each a scalar score representing their predicted value to employers. When multiple firms use the same algorithm, they all see identical scores for each candidate. 
In a simplified setting where each firm can interview exactly one applicant, all firms might target the highest-scoring candidate.  This is an undesirable outcome from both the perspective of the firms (at most one firm will successfully hire) as well as for the applicants (at most one applicant will be hired). However, this inefficiency is not inevitable as firms can adopt \textit{strategic behaviors}, such as avoiding competing for top candidates when they anticipate high competition. The extent to which such strategies can mitigate inefficiencies and improve labor market outcomes is the focus of this paper.









We consider a model with $N$ firms and a shared pool of applicants. 
Each firm makes interview decisions that are capacity-constrained, with the goal of maximizing the number of successful hires.
Each applicant is associated with a score $s \in [0, 1]$, visible to all firms, which represents the probability that the applicant will pass an interview.
Each firm decides which applicants to interview, and then gives an offer to all applicants who pass the interview.
If an applicant receives offers from multiple firms, they accept one of them at random.
We consider two variants of how the offer decisions are correlated across firms for the same applicant, either fully correlated or independent.  

We define social welfare to be the total number of applicants who are accept a job. 
Under this model, we consider three different solutions that vary in the strategic nature of the firms:
\begin{enumerate}
    \item \textit{Naive}: All firms interview the highest scoring candidates.
    \item \textit{Nash equilibrium (NE)}: All firms are strategic in their interview decisions, and the strategies form a Nash equilibrium. 
    \item \textit{Centralized}: Every firm's decision is controlled by a centralized decision maker who chooses the outcome that maximizes overall firm and social welfare.
\end{enumerate}

\subsection{Summary of Results}


\textbf{Characterize Nash equilibria.}
We first fully characterize the set of Nash equilibria under our model.
We characterize a strategy profile by a set of \textit{thresholds} of applicant scores, where a pair of consecutive thresholds determine the range of applicant scores that receive a specific number of interviews.
We identify a set of properties for the thresholds, where a set of strategies form a Nash equilibrium if and only if there are a set of corresponding thresholds that satisfy these properties.
Interestingly, the resulting firm best responses are sometimes non-monotonic in candidate quality---for example, a firm may choose to interview the top and third deciles of candidates, but not the second decile. 

We also characterize how the number of interviews each applicant receives depends on their score under the Nash equilibrium. 
We show that when firm's hiring decisions are independent, all applicants who receive interviews get nearly the same number of interviews, while under correlated decisions, the number of interviews increases steadily with applicant scores.

\textbf{Social welfare.} 
We show that social welfare, the total number of applicants hired, increases as one goes down the list from Naive, to NE, to Centralized.
Then, we analyze the \textit{Price of Naive Selection (PoNS)}, the ratio of social welfare between the NE and Naive solutions.
We establish that PoNS is high in regimes where there is a large number of firms and the interview capacity is small; specifically, when the interview capacity goes to 0, the PoNS goes to $N$.
We also show that for any interview capacity, the PoNS is higher when the offer decisions are correlated across firms, compared to when they are independent.
Therefore, under these regimes, naive strategies result in large inefficiencies, and there is a huge welfare gain when firms behave strategically. 

We also evaluate the \textit{Price of Anarchy (PoA)}, the ratio of welfare between the Centralized and NE solutions.
In the same regimes where we show that the PoNS is high, we show at the PoA goes to 1.
That is, there is essentially no loss in welfare due to the lack of a centralized decision-maker.
Therefore, strategic behavior by firms is desirable from both the firms' and the applicants' perspectives.


\textbf{Convergence.}
Though we show that the NE is desirable, it is unclear whether firms will be able to converge to an NE in practice.
To answer this, we first show that best response dynamics will always converge to an NE. Moreover, when interview capacities are not large, a simple set of ``one-turn best response'' dynamics---where each firm sequentially chooses the best response assuming they are the last to act---will also converge to an NE.
Therefore, if firms can compute best responses, it is relatively easy for an NE to arise.

However, firms need information on their competitors' strategies in order to compute a best response---information that is typically not available. Our results show that it is sufficient to know how many other firms are interviewing each candidate (i.e., applicant competitiveness). Absent this information, firms may simply use historical data on whether applicants accepted their job offers, and we show that this makes convergence to a NE difficult.




\subsection{Implications}


\textbf{Value of strategic behavior.} 
First, we show that there is substantial value for firms to act strategically when hiring under algorithmic monoculture.
This improves welfare for both sides of the market, firms and applicants.
We show that a simple set of best response dynamics converge to the Nash equilibrium, showing that the equilibrium can arise as long as firms can compute their best response.

\textbf{Congestion information.}
Our findings highlight the importance of sharing information on the level of congestion for each applicant.
Without this information, it is difficult for firms to compute the best response, needed to converge to an NE.
In settings where firms operate on a common algorithmic hiring platform, the platform can play a crucial role by providing firms with data on the number of competing firms interviewing each applicant. With this information, firms can make more informed and strategic decisions, reducing inefficiencies caused by overlapping interview selections. 
Thus, platforms that prioritize transparency and provide insights into applicant competition levels can enable more effective use of algorithmic hiring systems, benefiting both firms and the applicants.

\textbf{Value of algorithmic hiring.}
In cases where sharing information on congestion is unavailable or infeasible, our results imply that the utility of a common algorithmic hiring platform may be limited. Without such information, firms are more likely to default to naive strategies, which can lead to significant congestion and low social welfare. This limitation highlights an important consideration for firms evaluating whether to adopt an algorithmic hiring platform. Specifically, if the platform cannot facilitate coordination or mitigate competition among firms, its adoption may fail to deliver the intended benefits and could even exacerbate inefficiencies. 
This is in line with existing literature that have raised concerns with algorithmic monoculture \citep{kleinberg2021algorithmic,peng2023monoculture}.

\textbf{Value of personalization.}
The above concern is predicated on the assumption that all firms receive \textit{identical} scores for each applicant.
In practice, firms can have heterogeneous preferences, which could be reflected in their hiring decisions. 
For example, one firm might prioritize specific technical skills, while another might focus on leadership potential or cultural fit. 
This raises the potential value of personalization, where a platform can tailor the recommendations to each firm's unique preferences.
By reducing uniformity in candidate rankings across firms, such personalization can alleviate congestion at the top of the applicant pool and promote a more efficient allocation of interview slots, even when firms employ naive strategies.


\subsection{Related Work}

\textbf{Algorithmic monoculture and homogenization.}
The concept of algorithmic monoculture was formalized by \citet{kleinberg2021algorithmic}, who showed that firms relying on a common algorithm may hire weaker applicants than when each firm uses an independent, but less individually accurate, hiring method.
\citet{peng2023monoculture} incorporate two-sided preferences and competition to compare outcomes between monoculture and polyculture (when firms make independent decisions).
They leverage a two-sided matching model  and evaluate the stable matching outcome under monoculture and polyculture.
They show that monoculture can reduce firm utility compared to polyculture, but monoculture can improve average utility for the applicants.


Compared to the above works, the goal of this paper is not to evaluate the benefits or downsides of monoculture. Rather, we simply assume that monoculture exists, and then we evaluate how firms should make decisions in a setting with congestion effects.
We show that social welfare can drastically improve when firms make \textit{strategic} decisions based on the algorithm's output, compared to when they naively follow the algorithm's recommendation.

One consequence of  algorithmic monoculture is \textit{outcome homogenization}, the idea that certain individuals systematically experience undesirable outcomes by many algorithmic systems.  
There is growing line of work that study homogenization caused by algorithms \citep{ajunwa2019paradox,bommasani2022picking,jain2024algorithmic,toups2024ecosystem}, and the recent advances in generative AI has sparked studies on its impact on diversity of outcomes \citep{padmakumar2023does,anderson2024homogenization,doshi2024generative,raghavan2024competition,zhou2024generative}.
Our paper effectively studies outcome homogenization in the hiring context. 
Indeed, under the naive baseline where all firms interview the top-scoring candidates, every applicant receives the same outcome (interview decision) from every firm. 
We study whether this homogenization can be mitigated through strategic behavior. 




\textbf{Congestion in matching markets.}
A key difference of our model to that of \citet{peng2023monoculture} is that the latter uses \textit{stable matching} as the solution concept, without specifying the \textit{process} in which the stable matching arises.
There are also papers that study stable matching in a market where interviews are conducted to learn the utility of match  
 \citep{beyhaghi2021randomness,allman2025signaling,ashlagi2025stable}.
A stable matching can be found, for example, iteratively using the deferred acceptance algorithm \citep{gale1962college}. 
In contrast, our paper fixes a simple, one-step process in which firms hire applicants: firms decide simultaneously which applicants to interview and gives offers to everyone who passes the interview.
This process is motivated by the fact that firms face screening costs and hence have capacity constraints on the number of applicants they can interview. 
This process causes issues due to congestion; i.e., reduced utility when multiple firms interview the same applicant. 

Other existing papers have modeled congestion or search costs in matching models, such as  \citet{halaburda2018competing,arnosti2021managing,kanoria2021facilitating}. They show that various restrictions on the matching process can improve outcomes, such as reducing the number of applicants that an individuals can send, or restricting which side can initiate a matching.
Compared to these works, the main difference of our paper is that we assume all firms have access to an informative signal for all applicants, while these papers assume that each agent has no a priori knowledge about other agents (i.e., no algorithmic recommendation).


Several empirical studies have evaluated various interventions to improve efficiency under congestion.
\citet{gee2019more,besbes2023signaling,fradkin2023competition,filippas2024costly} empirically show that signaling the level of competition can improve efficiency.
The benefit of this intervention is also established in our paper, and therefore our work is complementary to these empirical findings.
\citet{manshadi2023redesigning} design a ranking algorithm to take congestion into account on an online platform to match volunteers to nonprofits.

Specific to application of hiring, \citet{horton2017effects} shows that leveraging algorithmic recommendations of applicants to firms substantially increase the fill rate, demonstrating the value of algorithmic hiring.
\citet{horton2024reducing} conduct a field experiment which showed that imposing a cap on the number of applications a job opening can receive can improve efficiency.
\citet{coles2013preference} study a mechanism where applicants can send a signal of interest to firms, and this can improve applicant welfare.
\citet{dwork2024equilibria} studies congestion and incoordination in a social network where individuals can refer others for job opportunities.

Lastly, there is a large literature studying algorithmic hiring, on developing the algorithms themselves (e.g., \citet{purohit2019hiring,epstein2022order,aminian2023fair}), human perceptions of hiring algorithms (e.g., \citet{fumagalli2022ok,zhang2022examining}), as well as evaluating bias propagated or incited by such algorithms (e.g., \citet{raghavan2020mitigating,li2020hiring,baek2023feedback,komiyama2024statistical,gaebler2024auditing}).




\section{Model}
\label{sec:model}


We consider a labor market with $N \geq 2$ firms who are hiring from a shared pool of applicants. All firms leverage a common hiring platform that evaluates all applicants and generates a score $s \in [0, 1]$ for each applicant. 
There is a continuum of applicants of mass 1, and the scores of these applicants follow a continuous distribution $\mathcal{D}$ on $[0, 1]$ with density $\varphi(s)$.
We assume $\varphi(s) > 0$ for all $s \in [0,1]$.


\paragraph{Firms' decisions.}
The firms make decisions about which applicants to interview, which are made only on the basis of an applicant's score. 
Firm $i$ decides on a function $f_i(s): [0,1] \rightarrow \{0,1\}$, where $f_i(s) = 1$ means that they interview applicants with score $s$.
Each firm can interview at most $c \in (0, 1]$ mass of applicants; specifically, the strategy $f_i$ must satisfy $\Pr_{S \sim \mathcal{D}}(f_i(S) = 1) \leq c$.
We restrict the strategies to ones where the applicants interviewed can be written as a union of a finite number of intervals; that is, we can write $\{s \in [0, 1]: f_i(s) = 1\} = \cup_{k=1}^{K_i} [a_k, b_k]$, for $a_k < b_k$ and $K_i \in \mathbb{Z}$.
We call $\mathbf{f} = (f_1, \dots, f_N)$ a \textit{strategy profile}, and we let $\mathcal{F}$ be the set of all feasible strategy profiles.

We denote by $M(s; \mathbf{f}) = \sum_{i=1}^N f_i(s)$ the total number of firms that interview an applicant of score $s$ under strategy profile $\mathbf{f}$. 
We use $\Mmax(\mathbf{f}) = \max_{s\in [0,1]}M(s; \mathbf{f})$ to denote the maximal number of firms competing for the same applicant. 

\paragraph{Interview and hiring process.}
We assume that an applicant's score $s \in [0, 1]$ represents the probability that the applicant will pass the interview process for a firm and get an offer, which we assume is the same across all firms.
If an applicant receives offers from multiple firms, we assume they accept one of them uniformly at random.
We consider two decision schemes, $\theta \in \{\corr, \indep\}$, specifying how hiring decisions are correlated across firms:
\begin{enumerate}
    \item \textbf{Correlated} ($\theta = \corr$): The firms' offer decisions conditioned on an interview are perfectly correlated. 
    For an applicant with score $s$, if $n$ firms interview them, they will receive all $n$ offers with probability $s$ and zero offers with probability $1-s$.
    \item \textbf{Independent} ($\theta = \indep$): The firms' offer decisions conditioned on an interview are independent.
    Each firm that interviews an applicant with score $s$ will independently extend an offer with probability $s$.
\end{enumerate}

Whether the decision scheme is correlated or independent (or somewhere in between) can depend on type of job and the interview process.
For example, if the interview is very similar across all firms, then the results of the interview could be highly correlated for the same applicant across firms.
On the other hand, if each firm uses a unique evaluation method, then the hiring decisions may be independent across firms.  

An instance of the model $\cI = (N, c, \cD, \theta)$ is specified by the number of firms $N$, the capacity $c$, the score density function $\varphi:[0, 1] \to \mathbb{R}$, and the hiring decision scheme $\theta \in \{\corr, \indep\}$.


\paragraph{Utility and social welfare.}
A firm's utility is the expected mass of applicants that they successfully hire.
The firm derives the same utility from any successful hire regardless of the applicant's score $s$; the score only matters insofar as much as it increases the probability that they pass the interview.
If there are $n$ firms interviewing an applicant with score $s$, we denote by the function $U_n(s)$ to be the expected utility derived by \textit{one} of these $n$ firms from this applicant. 
That is, $U_n(s)$ denotes the probability that a firm successfully hires an applicant of score $s$ if they interview them, given that there are $n$ firms interviewing them in total. We assume $U_n(0) = 0$, and that $U_n(s)$ is continuous and is strictly increasing in $s$ and strictly decreasing in $n$. 
Under the correlated model, we have $U_n(s) = s/n$, while in the independent model, $U_n(s) = (1-(1-s)^n)/n$ (see Appendix \ref{deri:U_n_indep} for the derivation). 
Figure~\ref{fig:utility_lines} plots these utility functions for $n = 1, \dots, 6$ for both $\theta \in \{\corr, \indep\}$.



\begin{figure}[ht]
    \centering
    \subfigure[$\theta = \corr$]{
        \includegraphics[width=0.47\linewidth]{figures/utility_correlated.pdf}
        \label{fig:utility_correlated}
    }
    \subfigure[$\theta = \indep$]{
        \includegraphics[width=0.47\linewidth]{figures/utility_indep.pdf}
        \label{fig:utility_indep}
    }
    \caption{Plots of the utility curves $U_n(s)$ when $\theta \in \{\corr, \indep\}$ and $n = 1, \dots, 6$.}
    \label{fig:utility_lines}
\end{figure}


Then, given firm $i$'s action, $f_i$, and the actions of all other firms, $f_{-i}$, the utility for firm $i$ is
\begin{align*}
    u(f_i, f_{-i}) = \int_{0}^1 f_i(s) U_{M(s, \mathbf{f})}(s) \varphi(s)ds.
\end{align*} 
We define the social welfare to be the sum of the utilities for all firms:
\begin{align*}
    \SW(f_1, \dots, f_N) = \sum_{i=1}^N u(f_i, f_{-i}).
\end{align*}
This term also represents the social welfare on the applicant's side---since the firm's utility is equal mass of successful hires, $\SW(f_1, \dots, f_N)$ equals the mass of applicants who get a job.


\paragraph{Solution concepts.}
For a problem instance $\cI$, we consider three different solution concepts that vary in how the strategy profiles $(f_i)_{i=1}^N$ are chosen.

\begin{enumerate}
\item  \textbf{Naive}: 
The naive solution is one where all firms interview the applicants with the highest scores up to the capacity. 
Specifically, let $s_c \in [0, 1]$ be the threshold such that $\int_{s_c}^1 \varphi(s) ds = c$, and let $f^{\text{Naive}}(s) = 1$ for all $s \geq s_c$, and $f^{\text{Naive}}(s) = 0$ otherwise.
We denote by $\SW_\text{naive}(\cI) = \SW(f^{\text{Naive}}, \dots, f^{\text{Naive}})$ the social welfare under the naive solution.
\item \textbf{Nash equilibrium (NE)}:  A strategy profile $(f_1, \dots, f_N)$ is a Nash equilibrium if no firm can unilaterally deviate to another strategy to strictly increase their utility. 
Specifically, for every $i$ and for any strategy $f'$ that satisfies the capacity constraint,
\begin{align*}
   u(f', f_{-i}) \leq u(f_i, f_{-i}).
\end{align*}
Let $\mathcal{F}_{\text{NE}} \subseteq \mathcal{F}$ be the set of all strategy profiles that is a Nash equilibrium.
We define $\SW_\text{NE}$ to be the smallest social welfare from a Nash equilibrium solution:
\begin{align*}
    \SW_\text{NE}(\cI) = \inf_{(f_1, \dots, f_N) \in \mathcal{F}_{\text{NE}}}  \SW(f_1, \dots, f_N).
\end{align*}
\item \textbf{Centralized}: 
The centralized solution is one where all firms' decisions are controlled by a centralized decision maker who chooses the outcome that maximizes social welfare. We denote social welfare under this as
\begin{align*}
    \SW_\text{max}(\cI) = \sup_{(f_1, \dots, f_N) \in \mathcal{F}} \SW(f_1, \dots, f_N ).
\end{align*}
\end{enumerate}

We define the \textit{Price of Naive Selection (PoNS)} as the ratio between the social welfare under the Nash equilibrium solution to the Naive solution:
\begin{align*}
    \PoNS(\cI) = \frac{\SW_\text{NE}(\cI)}{\SW_\text{naive}(\cI)}.
\end{align*}
We define the \textit{Price of Anarchy} as the ratio between the social welfare under the Centralized solution to the Nash equilibrium.
\begin{align*}
    \PoA(\cI) = \frac{\SW_\text{max}(\cI)}{\SW_\text{NE}(\cI)}.
\end{align*}

We discuss several of the modeling assumptions and their limitations in \cref{sec:discussion_and_conclusion}.



\section{Characterizing the Nash Equilibrium}


In this section, we characterize structure of Nash equilibrium outcomes.
We first explain this characterization before rigorously formalizing the result in \cref{thm:equilibrium}.


\textbf{Thresholds.}
A key concept in our characterization is the idea of non-decreasing thresholds, 
$0 \leq \tau_1 \leq \tau_2 \leq \dots \leq \tau_N \leq 1$.
The meaning of these thresholds is that all applicants with score $s \in [\tau_i, \tau_{i+1})$ is interviewed by exactly $i$ firms.
We show that every Nash equilibrium is associated with a set of thresholds $(\tau_i)_{i=1}^N$, and further, there are a strict set of conditions that these thresholds must satisfy.
We differentiate between two classes of equilibria, dubbed ``equal-utility'' and ``variable-utility'', based on two different classes of conditions that the thresholds satisfy.



\textbf{Equal-utility equilibria.}
These equilibria are those in which the thresholds satisfy $U_i(\tau_i) = U_j(\tau_j)$ for $\tau_i, \tau_j \in (0, 1)$.
That is, across the thresholds, the utility for a firm that is interviewing an applicant at the threshold is equal.
Graphically, an equal-utility equilibrium is characterized by a \textit{horizontal line} in the plot of the utility curves $U_n(s)$, where $\tau_i$ is the intersection of the horizontal line with the curve $U_i(s)$.
We explain the significance of the horizontal lines through an example.


\begin{figure}[ht]
    \centering
    \subfigure[Capacity of each firm is 0.2.]{
        \includegraphics[width=0.47\linewidth]{figures/example1.pdf}
        \label{fig:ex1}
    }
    \subfigure[Capacity of each firm is 0.35.]{
        \includegraphics[width=0.47\linewidth]{figures/example2.pdf}
        \label{fig:ex2}
    }
    \caption{Examples of equal-utility equilibria when $N = 2$ and $\theta = \corr$. 
    An equilibrium is characterized by the dashed red horizontal line in the upper plots. 
    The lower plots depict two possible strategy profiles that form an NE with the corresponding thresholds.
    In Figure \ref{fig:ex1}, $c=0.2$ and the equilibrium is characterized by the horizontal line $y=0.6$ with $\tau_1 = 0.6$. 
    In Figure \ref{fig:ex2}, the capacity is $c = 0.35$ and an equal-utility equilibrium is characterized by $y=13/30$ with $\tau_1 = 13/30$ and $\tau_2 = 13/15$. 
    }
    \label{fig:side_by_side}
\end{figure}

Consider an instance with two firms A and B,
each with capacity $c = 0.2$, and suppose applicant scores are uniformly distributed from 0 to 1.
There are infinitely many equilibria for this instance, and we illustrate two of them in Figure \ref{fig:ex1}.
Specifically, any strategy profile in which all applicants with score $s \geq 0.6$ are interviewed by exactly one firm is an equilibrium. 
This is characterized by a horizontal line at $y = 0.6$, and the corresponding thresholds are $\tau_1 = 0.6$ and $\tau_2 = 1$.
Note that each firm derives a utility of at least 0.6 for each applicant interviewed.
There is no incentive for both firms to interview the same applicant (``double-interviewing''), as the highest utility that a firm can derive from double-interviewing an applicant is 0.5.  
Moreover, there is also no incentive for a firm to deviate to interviewing an applicant with score less than 0.6, since that also results in a lower utility.

Next, if the capacities of the firms are increased to $c = 0.35$, then there is a gain in double-interviewing the applicants whose score is close to 1, compared to single-interviewing an applicant whose score is less than 0.5. 
In this case, equilibria correspond to a horizontal line at $y = 13/30$, corresponding to thresholds $\tau_1 = 13/30$ and $\tau_2 = 13/15$ (see Figure \ref{fig:ex2}).

\begin{figure}[ht]
    \centering
        \includegraphics[width=0.47\linewidth]{figures/example3.pdf}
    \caption{
    Example of a variable-utility equilibrium with $N = 2$, $\theta = \corr$, and $c = 0.35$.
    $f_A(s) = 1$ if and only if $s\in[0.4, 0.55]\cup [0.8,1]$, and $f_B(s) = 1$ if and only if $s\in[0.55, 0.8]\cup [0.9,1]$. 
    The dashed horizontal lines highlight the utility at the two thresholds $\tau_1$ and $\tau_2$. Under this strategy profile, $\tau_1 = 0.4$ and $\tau_2 = 0.9$, and the utility at the thresholds are $U_1(\tau_1) = 0.4$ and $U_2(\tau_2) = 0.45$.}
    \label{fig:ex3}
\end{figure}


\textbf{Variable-utility equilibria.}
Not all equilibria have thresholds described by a horizontal line. 
Using the same instance with the capacities $c = 0.35$ (same as Figure \ref{fig:ex2}), Figure \ref{fig:ex3} provides an example of strategy profiles that constitute an equilibrium, 
but the utility at the thresholds are not equal; $U_1(\tau_1) \neq U_2(\tau_2)$.

In this example, all applicants with score ranging from 0.4 to 0.9 are interviewed by \textit{one} firm. This means that double-interviewing an applicant of score 0.85 yields higher utility than single-interviewing an applicant of score 0.4. 
However, in this example, firm A is interviewing applicants from 0.4 to 0.45, but they are also already interviewing those from 0.8 to 0.9. Therefore, firm A cannot make any deviations to improve their utility.
Therefore, this is an equilibrium even though the utility at the thresholds differ. 

In this example, we have $U_1(\tau_1) < U_2(\tau_2)$, and firm A interviewed applicants right above $\tau_1$ as well as right below $\tau_2$. A variable-utility equilibrium has this property in general: when the utility at the thresholds differ, it must be that all firms who interview right above the lower threshold must also have interview right below the upper threshold.

\subsection{Formal Characterization}
We formalize the above ideas by characterizing the conditions of a Nash equilibrium in the following theorem.


\begin{theorem} \label{thm:equilibrium}
The strategy profile $\bbf = (f_1, \dots, f_N)$ is a Nash equilibrium if and only if 
there exist thresholds $0 = \tau_0 \leq \tau_1 \leq \tau_2 \leq \dots, \leq \tau_N \leq \tau_{N+1}= 1$ that satisfy the following conditions:
\begin{enumerate}
    \item  $\Pr(f_i(S)=1) = c$ for all $i \in [N]$.
    \item  $M(s, \bbf) = m$ for all $s \in [\tau_m, \tau_{m+1})$ for all $m = 0, 1,  \dots, \Mmax(\bbf)$.
    \item  $U_n(\tau_n) \leq U_m(\tau_m)$ for all $n < m \leq \Mmax(\bbf)$.
    
    \item Consider any $n < m \leq \Mmax(\bbf) +1$ where 
    $U_n(\tau_n) < U_m(\tau_m)$, and consider any firm $i$ and score $s \in [\tau_n, \tau_{n+1})$ where $f_i(s) = 1$ and $U_n(s) < U_m(\tau_m)$. 
    For any $s' \in [\tau_{m-1}, \tau_m)$ where $U_m(s') > U_n(s)$, we have that $f_i(s') = 1$.
\end{enumerate}
\end{theorem}

The first condition states that every firm will use their entire capacity.
The second condition states that exactly $m$ firms will interview applicants between score $\tau_m$ and $\tau_{m+1}$.
The third condition states that the utilities at the thresholds are non-decreasing.
The last condition states additional conditions that need to be satisfied if the utilities at the thresholds are strictly decreasing. 
Specifically, if $U_n(\tau_n) < U_m(\tau_m)$, then  it must be that any firm who interviews applicants slightly above $\tau_n$ must also interview those slightly below $\tau_m$.


\begin{definition}
\label{def:types_of_NE}
A strategy profile $\bbf = (f_1, f_2, \cdots, f_N)$ is a \textit{equal-utility Nash equilibrium} if it is a Nash equilibrium where the thresholds defined in \cref{thm:equilibrium} satisfy $U_n(\tau_n) = U_m(\tau_m)$ for all $n,m \in[\Mmax(\bbf)]$.
Any other Nash equilibrium is a \textit{variable-utility Nash equilibrium}.
\end{definition}  


\subsection{Nash Equilibrium Properties}

We prove properties regarding the number of interviews received by each applicant in the NE solution, under both $\theta = \corr$ and $\indep$.
These properties can be visualized in Figure~\ref{fig:utility_lines_large_n}.


\begin{figure}[ht]
    \centering
    \subfigure[$\theta = \corr$]{
        \includegraphics[width=0.47\linewidth]{figures/utility_correlated_limit.pdf}
        \label{fig:utility_correlated_limit}
    }
    \subfigure[$\theta = \indep$]{
        \includegraphics[width=0.47\linewidth]{figures/utility_indep_limit.pdf}
        \label{fig:utility_indep_limit}
    }
    \caption{Comparison of utility curves  \( U_n(s) \) and the thresholds for \( n \in \{1, 2, \dots, 6\} \) under $\theta = \{\corr, \indep\}$. The dashed horizontal line $y=0.2$ characterizes equal-utility equilibria. When $\theta = \corr$, the thresholds are evenly spaced across the applicant score \( s \). In contrast, when $\theta = \indep$, most thresholds are concentrated near \( s = 0 \); hence a large portion of applicants who receive interviews will be interviewed by the same number of firms.}
    \label{fig:utility_lines_large_n}
\end{figure}

Notice that under the $\theta = \corr$ scheme displayed in Figure \ref{fig:utility_correlated_limit}, the thresholds $\tau_1$ to $\tau_5$ are evenly spaced out. 
This means that the number of interviews received by each applicant increases with their score $s$ in regular intervals.
In the example in the figure, the set of scores from 0 to 1 is equally divided into five sets, where the first set represents scores that receive 0 interviews, the second set of scores receive 1 interview, and so on.

Contrastingly, under $\theta = \indep$ shown in Figure \ref{fig:utility_indep_limit}, the thresholds $\tau_1$ to $\tau_4$ are very close together, close to 0, while $\tau_5$ is at the maximum value. 
This implies that there is a large range of scores, $[0.331, 1]$, where every applicant in that range receive four interviews. 
It may seem unintuitive that an applicant with score $s = 0.5$ receives the same number of interviews as an applicant with score $s = 1$, but this is due to the  independent realizations of the offer decisions, 
Specifically, if four firms interview an applicant with score $s = 0.5$, on average only two of the firms will give them an offer, and therefore those two firms are only competing with each other to hire that applicant. 
However, if four firms interview an applicant with score $s = 1$, they will all give an offer, and therefore a firm competes with three other firms for that applicant.
In general, under the $\theta = \indep$ scheme, a large portion of applicants who receive interviews will be interviewed by the same number of firms.

We formalize these properties described in the following two propositions.
First, under $\theta = \corr$, we show that under an equal-utility NE, every threshold $\tau_m$ will be an exact multiple of $\tau_1$. 

\begin{proposition}
    \label{prop:NE_shared}
    Fix a distribution $\cD$ and capacity $c \in (0, 1]$, and let $\cI(N) = (N, c, \cD, \corr)$ be the instance with $N$ firms and the correlated decision rule. Let $\mathbf{f_N}$ be a Nash equilibrium for instance $\cI(N)$. Then $\tau_m \geq m \tau_1$ for all $m\in [\Mmax(\mathbf{f_N})]$. If $\mathbf{f_N}$ is an equal-utility Nash equilibrium, then $\tau_m = m \tau_1$ for all $i\in [\Mmax(\mathbf{f_N})]$.
\end{proposition}


Next, under $\theta = \indep$, we show that as $N \to \infty$, the number of firms that interview an applicant will differ by at most 1. That is, every applicant will be interviewed either $\Mmax(\mathbf{f_N})$ times or $\Mmax(\mathbf{f_N}) - 1$ times.

\begin{proposition}
\label{prop:NE_indep}
Fix a distribution $\cD$ and capacity $c \in (0, 1]$, and let $\cI(N) = (N, c, \cD, \indep)$ be the instance with $N$ firms and the independent decision rule.
Let $\mathbf{f_N}$ be a Nash equilibrium for instance $\cI(N)$.
Then, $\lim_{N \to \infty} Pr(|M(S; \mathbf{f_N}) - \Mmax(\mathbf{f_N})|>1) = 0$.
\end{proposition}

\jbcomment{TODO: Emphasize these results in the introduction more?}




\section{Social Welfare}
In this section, we evaluate how the social welfare compares under the three different solution concepts: Naive, Nash equilibrium, and Centralized. 
We show that the Price of Naive Selection can grow with $N$ when the capacity is small, while the Price of Anarchy goes to 1 in the same regime.


We first establish that $\SW_{\text{naive}} < \SW_\text{NE} \leq \SW_\text{max}$.
The second inequality holds by definition of the Centralized solution, and we show that the first inequality holds under general conditions.
\begin{theorem}\label{thm:SW1}
Suppose the utility functions $U_n(s)$ are continuous, strictly increasing in $s \in [0, 1]$, and strictly decreasing in $n \in [N]$.
Then, $\SW_{\text{NE}} > \SW_\text{naive}$.
\end{theorem}
Note that \cref{thm:SW1} uses a general condition on the utility function, which is satisfied for both $\theta \in \{\corr, \indep\}$.


\subsection{Price of Naive Selection}

We compare the social welfare across the Naive and Nash equilibrium solutions using the Price of Naive Selection (PoNS).
We first analyze the PoNS when the capacity $c$ is at its extremes. 
Keeping $N$ fixed, we show that the PoNS goes to $N$ when $c  \to 0$, and the PoNS goes to 1 when $c \to 1$.

\begin{theorem} \label{thm:SW_PoNS2}
For any distribution $\cD$, number of firms $N$, and decision rule $\theta \in \{\indep, \corr\}$,
if $\cI(c) = (N, c, \cD, \theta)$ is the instance parameterized by capacity $c \in (0, 1)$,
$\lim_{c \to 0^+} \PoNS(\cI(c)) = N$ and $\lim_{c \to 1^-} \PoNS(\cI(c)) = 1$.
\end{theorem} 

\cref{thm:SW_PoNS2} establishes that there is substantial inefficiency of firms using the naive strategies when each firm has a small interview capacity.
This is more pronounced with a large number of firms, as the PoNS grows with $N$ when $c \to 0$.
Conversely, as $c \to 1$, the PoNS converges to 1, indicating that strategic behavior offers little advantage when firms can interview almost every applicant. 

This implies that the importance of strategic selection is thus most pronounced when capacities are low and the number of firms is large.
In this regime, firms must allocate their limited capacity carefully.
Naive strategies, which prioritize top scores uniformly, result in excessive competition for a small subset of candidates, leaving many applicants underutilized. Strategic selection diversifies this allocation, significantly improving social welfare.


Next, we consider a regime where the capacity $c$ is fixed, and the number of firms $N$ goes to infinity.
In this case, we derive two results for each of the two hiring schemes.
First, under the independent decision rule, we show that the PoNS goes to $\frac{1}{c}$ when $N \to \infty$.
\begin{theorem}\label{thm:SW_PoNS4}
    For any distribution $\cD$, capacity $c$, if $\cI(N) = (N, c, \cD, \indep)$ is the instance with $N$ firms and the independent decision rule, 
    then $\lim_{N \to \infty} \PoNS(\cI(N)) = \frac{1}{c}$
\end{theorem}

Next, under the correlated decision rule, when $\mathcal{D}$ is the uniform distribution, the PoNS goes to $\frac{1}{c(2 - c)}$ when $N \to \infty$.
\begin{theorem}\label{thm:SW_PoNS3}
    Let $\cD_0$ be the uniform distribution on $[0, 1]$.
    Let $\cI(N) = (N, c, \cD_0, \corr)$ be the instance with $N$ firms and the correlated decision rule. 
    Then, $\PoNS(\cI(N))$ increases with $N$, and $\lim_{N \to \infty} \PoNS(\cI(N)) =\frac{1}{c(2 - c)}$. In addition, if $Nc\leq 0.5$, $\PoNS(\cI(N))\geq 1.5$.
\end{theorem}

The results of \cref{thm:SW_PoNS4} and \cref{thm:SW_PoNS3} establish how the PoNS changes for intermediate values of $c$.
Specifically, as $c$ decreases, the PoNS increases at a rate of $O(1/c)$.
Next, comparing the two decision rule, when $N \to \infty$, for any fixed capacity, the PoNS is higher under the correlated decision rule compared to the independent decision rule. 
Hence, correlation in interview outcomes exacerbates the inefficiencies in naive strategies and makes strategic selection more important.









\subsection{Price of Anarchy}

Next, we examine the \textit{Price of Anarchy (PoA)}, which measures the inefficiency of strategic and de-centralized decisions, compared to the socially optimal outcome that can be achieved by a central decision-maker.

\begin{theorem}
\label{thm:PoA}
    For any distribution $\cD$ and decision rule $\theta \in \{\indep, \corr\}$,
    let $\cI(c, N) = (N, c, \cD, \theta)$ be the instance parameterized by the capacity $c$ and number of firms $N$.
    For any $N$, we have $\lim_{c\rightarrow 0} \PoA(\cI(c, N)) =1$, and for any $c \in (0, 1)$, we have $\lim_{N\rightarrow \infty} \PoA(\cI(c, N)) =1$.
\end{theorem}




\cref{thm:PoA} shows that, in the regime where $N \to \infty$ or when $c \to 0$, the social welfare when firms are strategic converges to the highest possible social welfare in the system. 
In other words, there is little inefficiency of individual firms acting in their own self-interest.


\section{Equilibrium Convergence} \label{sec:eq_convergence}
The previous section establishes that the social welfare is substantially higher under the Nash equilibrium than under the Naive solution.
However, the relevance of this finding depends on whether firms can reasonably arrive at an NE.
To investigate this, we study whether best response dynamics converge to an NE.

Best response dynamics is a process in which firms iteratively choose their strategies to their current best responses, given the strategies of the other firms.
If this iterative process converges to a point where no firm can improve its payoff by a unilateral deviation, then this corresponds to an NE. However, best response dynamics, in general, is not guaranteed to converge.

First, we show that in our model, best response dynamics is guaranteed to converge to an NE. 
This is established by showing that the game we study is a potential game, and all potential games have the property that best response dynamics converge to the NE. 


\begin{theorem}
    \label{thm:congestion}
    The game defined by the model is a potential game, and hence best response dynamics will converge to a Nash equilibrium.
\end{theorem}


This establishes that if firms iteratively update their action to be the best response, then eventually this process will converge to the NE. 

However, \cref{thm:congestion} does not specify how many iterations this process will take. 
Next, we establish a stronger result that holds under mild assumptions, where we show that a simpler set of best response dynamics where each firm only takes one turn, will converge to an NE.


\textbf{One-turn best response.}
We define the \textit{one-turn best response} dynamics to be the following. Sequentially, each firm takes one turn to decide their action, starting with firm 1 and ending with firm $n$.
On its turn, firm $i$ selects the action that maximizes its payoff, assuming the actions of firms 1 to $i-1$ are fixed, and treating itself as the last firm to act.  In other words, firm $i$ optimizes its action under the assumption that no subsequent firm will adjust its behavior in response to its choice. This process continues until all $n$ firms have taken their turn.


\begin{theorem}
\label{thm:convergence_corr}
Suppose there is a $\delta > 0$ such that $\varphi(s) \geq \delta \; \forall s \in [0,1]$ 
    and $c \leq 0.5 \delta$ for every $i$.
    If $\theta = \corr$, one-turn best response dynamics converges to an equal-utility Nash equilibrium.
\end{theorem}

\begin{theorem}\label{thm:convergence_indep}
Fix a distribution $\cD$, number of firms $N$, and $\theta = \indep$. Suppose there is a $\delta > 0$ such that $\varphi(s) \geq \delta \; \forall s \in [0,1]$. There exists a $c_0$ such that if $c \leq c_0$, then one-turn best response dynamics converges to an equal-utility Nash equilibrium. 
\end{theorem}

The above results establish that when capacities are small, an NE can be reached even when each firm only takes one turn, and they take the best response assuming they are the last to act.
This is a stronger result than showing that best response dynamics converge to an NE, and hence if each firm is able to compute their best response, it is not a strong assumption to assume that an NE would arise in practice.


\subsection{Computing the Best Response} \label{sec:compute_br}
We have established that a Nash equilibrium can be reached through a sequence of best response dynamics.
However, it is not clear how a firm would compute their best response, since a firm would not have access to the exact strategies of other firms in practice.

Specifically, to compute the utility $U_n(s)$ of interviewing an applicant, the firm needs both the score $s$, and the total number of firms who selected the applicant, $n$.
The firm has access to $s$ through the algorithm, but they do not know $n$ if they do not know the strategies of the other firms.
We consider a setting where a firm can aim to \textit{estimate} the utility $U_n(s)$ using historical data on acceptance decisions.
Concretely, we assume that there are pools of applicants where both $s$ and $n$ is the same for all applicants in the same pool.
Then, for example, if a firm has made job offers to applicants from this pool in the past that were always accepted, then the firm can estimate that $n$ is small.
We calculate how many samples a firm needs to be able to accurately determine which applicants yield higher utility.


\textbf{Comparing two pools of applicants.}
We consider a simple setting where a firm needs to determine which pool of applicants, out of two, yield higher utility.
Suppose there are two pools of applicants, where every applicant in the same pool has the same score; $s_1$ and $s_2$ respectively.
Consider firm 1 deciding which pool to interview from, and assume that all other firms' strategies are fixed, but unknown to firm 1.
We assume that each firm has to either interview everyone from a pool or no one from a pool, and hence two applicants from the same pool are interviewed by the same set of firms.
Note that the expected utility of interviewing an applicant is equal to the probability that a firm successfully hires them, given that they get an interview.
Let $p_1, p_2 \in (0, 1)$ be the probabilities that firm 1 successfully hires if they interview applicants from pool 1 and 2 respectively.
Firm 1 would like to choose the pool with higher expected utility, but these values are unknown to the firm as they do not know how many other firms are interviewing.

Suppose firm 1 can collect data by interviewing $k$ applicants from each pool, and then selects the pool with a greater number of successful hires.
Then, how large does $k$ need to be for firm 1 to correctly determine which pool yields higher utility (with high probability)?
The answer depends on the exact values of $p_1$ and $p_2$, as well as the probability guarantee.
We provide the answer for a range of these values.
For a given $p_1 < p_2$ and probability $q \in [0, 1]$, we find the smallest number of samples $k$ needed that guarantees that if $X_1 \sim \text{Binom}(k, p_1)$ and $X_2 \sim \text{Binom}(k, p_2)$, we have $\Pr(X_1 < X_2) \geq q$.
We vary $p_1 \in \{0.1, 0.5\}$, $p_2 \in [p_1+0.05, p_1+0.3]$ and $q \in \{0.8, 0.9, 0.95\}$ and compute the corresponding $k$. The results are shown in Figure \ref{fig:computing_br}.



\begin{figure}[ht]
    \centering
        \includegraphics[width=1\linewidth]{figures/p1p2q.pdf}
    \caption{For $p_1 \in \{0.1, 0.5\}$, $p_2 > p_1$, and $q \in \{0.8, 0.9, 0.95\}$, we compute the smallest number of samples $k$ needed so that if $X_1 \sim \text{Binom}(k, p_1)$ and $X_2 \sim \text{Binom}(k, p_2)$, then $\Pr(X_1 < X_2) \geq q$. We vary $p_2$ from $p_1 + 0.05$ to $p_1+0.3$ in increments of 0.01.}
    \label{fig:computing_br}
\end{figure}


When $p_1 = 0.1$ and $p_2 = 0.15$, the number of samples needed to differentiate the two pools correctly with probability 80\%, 90\%, and 95\% are $k=80$, 162, and 254 respectively.
Note that $k$ is the number of samples needed from \textit{each} pool, hence $2k$ samples are needed in total.
This is a \textit{significant} number of samples that a firm needs to collect for the goal of distinguishing between two pools of applicants, which is practically infeasible for small to moderate sized firms.
The number of samples required decreases as the gap between $p_1$ and $p_2$ increases, however, it remains non-trivial. 
Even under a 0.2 gap between $p_1$ and $p_2$, to differentiate between $p_1 = 0.5$ and $p_2 = 0.7$ with 90\% probability, a firm needs 24 samples from each pool.

We note that the above calculations made several simplifications to the actual task of computing the best response.
First, the calculation was only to differentiate between \textit{two} pools of candidates.
If there are multiple pools, the firm will need to gather samples from all pools.
Second, we also assume that all other firms' strategies stay constant, while one firm is ``experimenting'' to collect data.
To converge an NE, all firms need to compute their best response and hence will need to experiment; if multiple firms experiment at the same time, this will interfere with each others' estimation.
Third, we also assumed that there are distinct ``pools'' of candidates with the same score, and there are many applicants in each pool.
In reality, there may not exist discrete ``pools'' of candidates, or there are not enough applicants from each pool needed to correctly estimate utilities.
Lastly, it may be unreasonable to assume that firms can ``experiment'' for the sake of collecting data for better estimation as interviewing is costly.

Given the large number of samples needed, as well as the reasons stated above, 
it seems unrealistic to hope that firms, using their own estimates of utility, can naturally arrive at an NE.

The bottleneck in computing the best response is in estimating the utility $U_n(s)$. 
Even though the algorithm provides a highly informative signal, $s$, about the applicants, the lack of knowledge on $n$ renders the information on $s$ almost useless.
If firms knew $n$, then they would be able to exactly compute the utility $U_n(s)$ and calculate their best response strategy.













\section{Extension: Flexible Capacity with Fixed Welfare}

So far, we have assumed that all firms have a fixed capacity $c$, and we showed that there is a large gap in social welfare (total number of applicants hired) when comparing the naive solution to the Nash equilibrium.
However, in reality, firms may update their capacity to meet their hiring needs.
In this section, we fix the total social welfare, and then we evaluate what the capacity needs to be under the different solution concepts to reach that level of social welfare.


We show that under both $\theta \in \{\corr, \indep\}$,
when the social welfare is fixed, the total capacity needed to reach the same level of welfare \textit{scales with $N$} under the naive solution, while under the Nash equilibrium, the total capacity stays constant with $N$.

\begin{proposition} \label{prop:fixedW_corr}
Fix the social welfare $W \in (0, N \int_0^1 U_N(s)\varphi(s)ds)$, decision scheme $\theta \in \{ \corr, \indep\}$.
There exists a $c > 0$ such that:
\begin{itemize}
    \item With $N$ firms each with capacity $c$, the naive solution yields a social welfare of $W$.
    \item When $W \leq \int_{0.5}^1 s \varphi(s)ds$, with $N$ firms each with capacity $c/N$, there is a Nash equilibrium that yields a social welfare of $W$.
\end{itemize}
\end{proposition}

This result corroborates the claim that the Nash equilibrium is a much more desirable solution than the Naive solution.
Previously, we have established that when firm capacities are fixed, then the welfare is substantially higher until the NE compared to Naive.
In this section, we show that the same welfare can be achieved under the NE solution with substantially less capacity compared to the Naive solution.
Hence, even if the same number of applicants are eventually hired, the NE solution is more efficient in that firms can substantially reduce their interview capacity.






 



    


\section{Conclusion and Discussion} \label{sec:discussion_and_conclusion}


To conclude, this paper studies the role of strategic behavior in algorithmic hiring environments under congestion and algorithmic monoculture. 
By analyzing Nash equilibrium strategies and their impact on social welfare, we demonstrate that strategic selection can mitigate the inefficiencies of congestion, which benefits both firms and applicants. 
Our findings highlight the value of providing firms with information about applicant congestion, as it facilitates convergence to a Nash equilibrium.
This result implies that the effectiveness of algorithmic hiring platforms is contingent on their ability to enhance coordination among firms, via congestion information or providing personalized recommendations.
Without mechanisms to address competition for top-scoring candidates, platforms risk exacerbating inefficiencies, limiting their value.


Lastly, we discuss several assumptions of our model, and corresponding limitations and future directions.

\textbf{One-shot process.}
One of the main assumption of our model is that hiring is a one-shot process where all firms make one set of interview decisions, which then lead to hiring decisions. 
In reality, the hiring process may take multiple stages, where firms that fail to hire in the initial round may revisit the pool of candidates to interview additional applicants.
At the opposite extreme, hiring could culminate in a stable matching, achieved through numerous iterations (e.g., via the deferred acceptance algorithm). This requires that provisional matches formed in earlier rounds can be broken if a blocking pair arises.
Our work focuses on the ``one-shot'' nature of the hiring process and the congestion it induces.
Real-world hiring likely falls between these two extremes, with limited rounds of iteration that neither resolve all congestion issues nor achieve full stability. 
We leave as an interesting direction to analyze a model that interpolates between these two regimes.


\textbf{Estimating utilities.}
Our analysis highlights the importance of providing firms with information about applicant congestion levels to improve decision-making.
In our model, since we assume that the utility for interviewing an applicant is $U_n(s)$, a firm can exactly compute this utility if they have access to both $n$ and $s$.
However, in reality, there are many factors that prohibit this exact calculation.
First, the exact form of $U_n(s)$ depends on the decision scheme (e.g., $\theta \in \{\corr, \indep\}$).
Firms may know exactly which regime they are in, and the regime may lie in between the two we consider.
Even so, we believe our results are still significant in that the utilities heavily depend on \textit{both} $s$ and $n$, and therefore having access to $n$ can greatly help the firm make decisions.
For example, if two applicants have the same value of $n$ but the first applicant has a higher score, then clearly the first applicant dominates the second, even if the exact form of $U_n(s)$ is unknown.


\textbf{Interview decision based on the score.}
In our model, we assume that firms make interview decisions solely based on the algorithmic score $s$.
In reality, firms may have access to additional features about the applicant which can be used in their interview decisions. For example, firm A might prioritize applicants with score $s = 0.6$ who graduated from college X, while firm B focuses on applicants with $s = 0.6$ from college Y. In such cases, there is no overlap between the two firms’ interview pools, despite their reliance on the same score.
Our model effectively accommodates this scenario by assuming that scores are continuous, allowing firms to select subsets of $[0, 1]$ with arbitrary precision. This can be interpreted as encoding additional applicant attributes in the decimal representation of $s$.
Mathematically, this equivalence ensures that the model captures the effects of feature-based selection without loss of generality.


\textbf{Interpretation of the algorithmic score.}
We also interpret an applicant's score $s$ as the probability that the applicant will pass the interview.
In reality, the algorithm might simply give a ranking over the candidates, or a score that does not exactly represent the probability of passing an interview.
In this case, the firm will need some time and experience to understand how to interpret the output of the algorithm.
Of course, the algorithmic output could simply be very inaccurate; in this case the firm will ideally eventually learn to put a small weight on this output. 


\textbf{Homogeneous preferences.}
Our model assumes that if an applicant receives multiple job offers, they choose among them uniformly at random. This is equivalent to assuming that each applicant's preferences over firms are drawn uniformly across all possible orderings. In reality, applicant preferences may be influenced by factors such as firm reputation, salary, or location, leading to correlated preference structures. Investigating models where applicant preferences are correlated could provide deeper insights into real-world hiring dynamics and is a promising direction for future research.

\textbf{Homogeneous firm-side utility.}
We also assume that the firm receives equal utility from hiring any applicant, as long as they pass the interview.
In reality, an applicant's profile is multi-dimensional, and a firm may incur different utilities from different profiles. 
We believe that assuming equal utility from all hires is a good approximation of hiring practices for roles with many positions (e.g., entry-level software engineering), whereas this may not be a good assumption for a specialized position (e.g., a C-suite role).



    