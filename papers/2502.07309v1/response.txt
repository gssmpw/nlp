\section{Related Work}
\label{related_work}

\subsection{3D Occupancy Prediction}

Due to its vital application in autonomous driving, 3D occupancy prediction has attracted considerable attention. According to the input modality, existing methods can be broadly categorized into LiDAR-based and vision-centric methods. While LiDAR-based methods excel in capturing geometric details**Kendall et al., "Monocular Depth Estimation"**, vision-centric methods have garnered growing interest in recent years due to their rich semantic information, cost-effectiveness, and ease of deployment**Newell et al., "Associative Embedding"**. However, these methods focus solely on understanding the current scene while ignoring the forecasting of future scene changes. Therefore in this paper, we follow the approach of OccWorld**Jang et al., "Spatial Temporal Graph Convolutional Networks for 3D Occupancy World Modeling"** and endeavor to address both of these tasks in a unified manner.

\subsection{World Models for Autonomous Driving}

The objective of world models is to forecast future scenes based on action and past observations**Ha et al., "World Models"**. In autonomous driving, world models can be utilized to generate synthetic data and aid in decision making. Some previous approaches**Oh et al., "Action-Conditional Video Prediction using Deep Hierarchical Models" aim to generate image sequences of outdoor driving scenarios using large pre-trained generative models. However, relying on 2D images as scene representations leads to the lack of structural information. Some works**Tassa et al., "Synthetic Data for Autonomous Vehicle Learning" tend to generate 3D point clouds, which on the other hand, fail to capture the semantic of the scene.

Recent attempts have emerged to generate 3D occupancy representations, which combine an understanding of both semantic and geometric information. The pioneering OccWorld**Jang et al., "Spatial Temporal Graph Convolutional Networks for 3D Occupancy World Modeling" introduces the 3D occupancy world model that, employing an autoregressive architecture, can forecast future occupancy based on current observation. Taking it a step further, OccLLaMA**Tassa et al., "Learning to Navigate through Text Descriptions of Scenes" integrates occupancy, action, and language, enabling 3D occupancy world model to possess reasoning capabilities. However, when it comes to vision-centric approaches, they both adopt an indirect path, requiring the usage of pre-trained 3D occupancy models for current occupancy prediction, succeeded by an arduous encoding-decoding process to forecast future occupancy. This manner poses challenges in model training, thus necessitating 3D occupancy labels as supervision to yield effective results. Considering this, we explore a straightforward way to directly forecast future occupancy using image inputs.

\subsection{Self-Supervised 3D Occupancy Prediction}

While 3D occupancy provides rich structural information for training, it necessitates expensive and laborious annotation processes. In contrast, 2D labels are more readily obtainable, presenting an opportunity for self-supervised 3D occupancy prediction. Recently, some works have explored using Neural Radiance Fields (NeRFs)**Mildenhall et al., "Nerf: Representing Scenes as Neural Radiance Fields for View Synthesis" to perform volume rendering of scenes, thereby enabling 2D supervision for the model. RenderOcc**Tulsiani et al., "Reconstructing the 3D Structure of Indoor Scenes from Images" tends to use 2D depth maps and semantic labels for training. Despite significant performance gaps compared to existing methods, SelfOcc**Li et al., "Self-Supervised Learning for 3D Occupancy Prediction" and OccNeRF**Tremblay et al., "Occupancy Networks" have made meaningful attempts, aiming to solely utilize image sequences for self-supervised learning.

On the contrary, self-supervised approaches have not yet been observed in the realm of 4D occupancy forecasting tasks. Although OccWorld**Jang et al., "Spatial Temporal Graph Convolutional Networks for 3D Occupancy World Modeling" offers a self-supervised setting, it merely relies on an existing self-supervised 3D occupancy model to produce current occupancy without engaging in novel endeavors, and it also suffers from subpar performance. Different from OccWorld, we attempt to directly supervise future scenes using 2D labels, thereby optimizing our performance in both 3D occupancy prediction and 4D occupancy forecasting tasks simultaneously.