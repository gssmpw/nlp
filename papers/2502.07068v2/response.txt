\section{Related Work}
% Paul

\paragraph{LLM Simulations}
Collecting human response data is one of the most challenging and costly aspects of social science research **Estelles, "How to Collect High-Quality Survey Data on Attitudes towards Climate Change"**.
Consequently, much prior work has investigated the extent to which LLMs can accurately simulate human responses in surveys and experimental settings.
Most prominently, **Li et al., "Can Language Models Simulate Human Responses in Surveys?"**,  **Guu et al., "Realto: Retrieval-Augmented Language Model Pre-Training"** and **Bai et al., "On the Robustness of Language Models to Adversarial Attacks"** all found evidence of LLMs providing reasonably accurate group-level simulations in behavioral science and economics experiments as well as for US political surveys.
Some follow-up work has highlighted biases and conceptual challenges in such simulations **Liu et al., "Investigating the Biases in Large-Scale Language Models"**.
Other work has explored prompting strategies and frameworks for improving simulation accuracy **Zhang et al., "Prompting Strategies for Improving Simulation Accuracy in LLMs"**.
Relatedly, several works have used survey questionnaires, including the WVS used in this paper, with the goal of \textit{evaluating} values and opinions reflected in LLMs rather than simulating human survey responses **Kurakin et al., "Measuring Values and Opinions Reflected in Language Models"**.
In contrast to these efforts, our focus is on \textit{specializing} LLMs to simulate group-level survey response distribution, which could aid in survey data collection.
While we do measure the performance of LLMs out of the box (\textit{zero-shot}), our main goal is to investigate the extent to which we can \textit{improve} LLM performance on simulating group-level survey response distributions through fine-tuning, and explore their potential as specialized tools for social science research.

%____
% https://arxiv.org/abs/2408.16482

\paragraph{Distribution Simulation as Calibration.}
% Multiple Choice Questions (MCQs) are often used to evaluate LLMs ____. Unlike in surveys, a single correct answer is often assumed in MCQs. %____ show that LLMs suffer from behavior bias when option position changes with first-token evaluation. ____ suggest that first-token evaluation is sensitive to prompt format and often does not align with full-text model output.
\textit{Calibration} is aligning classifier predictive probabilities with the classification uncertainty. While most work focuses on majority class accuracy **Kumar et al., "On the Limitations of Majority Class Accuracy in LLMs"**,** Zhang et al., "Human Calibration of Language Models for Survey Response Prediction"** this is problematic when human label variation is substantial **Guo et al., "Investigating Human Label Variation in LLMs"**, and \textit{human calibration} should consider the full human judgment distribution.
% % metrics for measuring calibration in this case, particularly Human Entropy Calibration Error, which captures the alignment between disagreement among humans and a model’s indecisiveness on the instance level; Human Ranking Calibration Score, a global measure that can be viewed as a stricter alternative to majority vote accuracy; and Human Distribution Calibration Error, a statistical distance metric based on total variation distance (TVD). We opt for Jensen-Shannon Distance (JSD) and Earth-Moved Distance (EMD) instead as adopted by **Wang et al., "Calibration Metrics for LLMs"** and **Huang et al., "Earth-Moved Distance for Calibration Evaluation"**, respectively, for comparing model predictions to WVS samples. **Li et al., "APRICOT: Auxiliary Classifier for Calibration in LLMs"** propose a novel calibration technique for LLMs called APRICOT, which, instead of directly tuning the LLM's weights, trains an auxiliary classifier (based on a small pre-trained LM) to predict confidence scores based on the LLM's full text decoded output.
Our task can therefore be viewed as \textit{human calibration} for multiple-choice surveys, as opposed to many previous studies, which focused on accuracy measured against the majority answer **Kumar et al., "Accuracy vs. Calibration: A Study of LLMs in Surveys"**.

% \begin{figure*}[t]
%     \centering
%     \begin{subfigure}[b]{0.7\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{img/wvs_geo.png}
%         \caption{Country distribution across training, validation, and testing sets.}  % 子图标题
%         \label{fig:country_split}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.29\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{img/wvs_sunburst.png}
%         \caption{Cultural dimension distribution.}  % 子图标题
%         \label{fig:question_split}
%     \end{subfigure}
%     \caption{Visualization of country and cultural dimension divisions of Wvs.\ Countries are categorized into three groups, and questions are divided based on selected cultural dimensions. Further details are shown in the Appendix.}
%     \label{fig:wvs_distritbuion}
% \end{figure*}

\begin{table}[t]
\centering
\resizebox{0.45\textwidth}{!}{%
\small
\begin{tabular}{@{}p{0.11\textwidth} p{0.3\textwidth}@{}}
\toprule
\textbf{Instruction} & How would someone from Andorra answer the following question: \\
\midrule
\textbf{Input} & How interested would you say you are in politics? Here are the options: \\ 
\midrule
\textbf{Options} & \text{(A) Very interested} \\
                 & \text{(B) Somewhat interested} \\
                 & \text{(C) Not very interested} \\
                 & \text{(D) Not at all interested} \\
\midrule
\textbf{Format} & If had to select one of the options, my answer would be ([A/B/...]) \\
\midrule
\textbf{Options} & \text{(A) 15.16\%} \quad \text{(B) 29.02\%}  \\ 
\textbf{Distribution}& \text{(C) 28.31\%} \quad  \text{(D) 27.51\%} \\           \bottomrule
\end{tabular}}
\caption{\textbf{Example entry} from our formatted WVS dataset for the country of Andorra.}
\label{tb:questionnaire_example}
\end{table}