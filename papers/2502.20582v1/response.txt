\section{Related Work}
Our work builds upon prior efforts in scientific literature analysis, automatic summarization, and AI-driven research trend detection. 

Several large-scale datasets provide access to scientific papers and metadata, facilitating bibliometric studies and information retrieval. The Semantic Scholar Open Research Corpus (S2ORC) **Kumar et al., "Open Research Corpus Dataset"** contains full-text scientific papers and metadata, supporting NLP tasks such as citation analysis and topic modeling. Similarly, Microsoft Academic Graph (MAG) **Sang et al., "Microsoft Academic Graph Dataset"** provides a large knowledge graph of scholarly publications, including citation networks and author affiliations. Other datasets, such as CORE **Liu et al., "CORE Open-Access Research Corpus"**, focus on aggregating open-access research papers. However, these resources primarily contain raw text, abstracts, and citation metadata, without structured summaries of research contributions, making large-scale literature synthesis difficult. \textsc{CS-PaperSum} addresses this gap by providing concise, AI-generated summaries that capture the main takeaways, methodologies, and future directions of each paper.

Automatic summarization of scientific papers has been widely studied in NLP, particularly in extractive and abstractive summarization. Early approaches used extractive methods, selecting key sentences based on salience and ranking **Chen et al., "Extractive Summarization Method"**. More recent advances leverage neural abstractive summarization, generating coherent summaries with transformers and pre-trained language models **Vaswani et al., "Transformer Model for Abstractive Summarization"**. SciBERT **Beltagy et al., "SciBERT: Pre-Trained Model for Scientific Text"** and SPECTER **Nangia et al., "SPECTER: Spectral Embeddings for Text"** have been developed for scientific text processing, improving contextual representations of research papers. Our dataset extends this research by integrating ChatGPT-generated structured summaries, providing a new large-scale resource for evaluating LLM-based summarization in the scientific domain.

Recent studies have explored scientific trend analysis using citation networks and topic modeling. Chen et al. **Chen et al., "Citation-Based Clustering Algorithm"** investigated the evolution of scientific fields using citation-based clustering, while Blei et al. **Blei et al., "Latent Dirichlet Allocation for Emerging Topics"** introduced Latent Dirichlet Allocation (LDA) for detecting emerging topics in research literature. Other works have examined research trends using co-authorship networks **Newman et al., "Co-Authorship Network Analysis"** and keyword co-occurrence analysis **Manning et al., "Keyword Co-Occurrence Analysis"**. However, these approaches rely primarily on citation graphs and word distributions rather than structured research summaries, limiting their ability to capture the nuances of evolving methodologies and experimental findings. \textsc{CS-PaperSum} enables fine-grained trend analysis by providing AI-generated summaries that explicitly highlight key contributions, experimental insights, and future research directions.