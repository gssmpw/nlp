% !TeX root = ../camera.tex
% \newpage
\section{Ethics Considerations}
\label{sec:ethics}
Our research exclusively uses publicly available Facebook data on CrowdTangle, adhering to the platform's terms of service and research guidelines. We implement strict data protection measures: all user identifiers are anonymized, personal information is excluded from our analysis, and we focus solely on aggregate engagement patterns. Our data collection and processing procedures have been reviewed and approved. We maintain data minimization principles, collecting only information necessary for our research objectives.

\section{Experimental Settings}
\label{sec:exp_settings}
To evaluate our proposed \icmamba model, we conducted systematic experiments with different parameter configurations. This section includes our experimental environment, hyperparameters, and optimization approach.

\subsection{Experimental Environment}
\label{subsec:exp_env}
All experiments were conducted using PyTorch 2.0 on a GPU cluster with 4xNVIDIA A100 GPUs with 40GB memory.
All reported figures are averaged across ten runs with different random seeds.

\subsection{Hyper-parameters}
\label{subsec:hyper-parameters}
\cref{tab:hyperparameters} lists the hyperparameter ranges used in our experiments.
\begin{table}[htb]
\caption{\icmamba Hyperparameters}
\label{tab:hyperparameters}
\begin{tabular}{llc}
\toprule
\toprule
 & \textbf{Parameter} & \textbf{Range} \\
\midrule
& Hidden Size ($N$) & [256, 1024] \\
& Input Dimension ($D$) & [64, 128] \\
& Number of IC-Mamba Blocks & [2, 8] \\
& Embedding Dimension ($d$) & [128, 512] \\
& Interval-Censor State Dim & [512, 2048] \\
& Sequence Length ($L$) & [1024, 8192] \\
\midrule
& Batch Size & [16, 128] \\
& Learning Rate & [1e-5, 1e-3] \\
& Warmup Steps & [500, 1650] \\
& Weight Decay & [0.005, 0.15] \\
& Dropout Rate & [0.15, 0.3] \\
& $\lambda$ (Loss Weight) & [(0.1, 0.9),(0.4,0.6)] \\
& Training Epochs & [50, 150] \\
& Early Stopping Patience & [5, 20] \\
\midrule
& $\tau$ (RTE Parameter) & [5000, 20000] \\
& Time Granularity & [5m, 1h] \\
& Max Prediction Window & [7d, 28d] \\
\midrule
& $\beta_1$ & [0.85, 0.95] \\
& $\beta_2$ & [0.995, 0.9999] \\
& $\varepsilon$ & [1e-9, 1e-7] \\
& Gradient Clipping & [0.5, 5.0] \\
\bottomrule
\bottomrule
\end{tabular}
\end{table}

%\subsection{Optimization Strategy}

\section{Mathematical Notations and Definitions}
\label{sec:appendix_notation}

\cref{tab:notations} summarizes the notations used throughout the paper to describe social outbreak events, associated posts, and the engagement predictions. Each notation is accompanied by a brief explanation for clarity and ease of reference.
\begin{table}[htb]
\caption{Notation Table}
\label{tab:notations}
\begin{adjustbox}{max width=1.0\linewidth}
\begin{tabular}{ll}
\toprule
\toprule
\textbf{Notation} & \textbf{Description} \\
\midrule
$\mathcal{E}$ & A social outbreak event \\
$\mathcal{P}$ & The set of associated posts for $\mathcal{E}$, $\mathcal{P} = \{p_1, p_2, \dots, p_N\}$ \\
$p$ & A single post $p \in \mathcal{P}$ \\
$t_0$ & The original posting time of a post $p$ \\
$x$ & The textual content of a post $p$ \\
$u$ & User metadata associated with the post \\
$\mathcal{O}$ & The set of possible opinion classes \\
$o$ & The opinion class of a post, $o \in \mathcal{O}$ \\
$\mathcal{P}_o$ & The set of posts sharing opinion $o$, $\{p \in \mathcal{P} \mid o(p) = o\}$ \\
$H$ & Interval-censored engagement history of a post, \\ & $H = \{(t_1, e_1), \dots, (t_m, e_m)\}$ \\
$t_j$ & Observation time for engagement measurement in $H$ \\
$e_j$ & $d$-dimensional vector capturing different types of \\ & engagement at time $t_j$ \\
$\Delta t_j$ & Interval between consecutive observations, \\ & $\Delta t_j = t_{j+1} - t_j$ \\
$\tau_{obs}$ & Observation window duration (e.g., 1 day) \\
$H_{\tau_{obs}}(p)$ & Initial engagement history within observation window, \\ & $\{(t, e) \in H \mid t_0 \leq t \leq t_0 + \tau_{obs}\}$ \\
$T$ & Prediction horizon (e.g., 28 days) \\
$\tau_{\text{step}}$ & Fixed time interval for predictions (e.g., 5 minutes) \\
$K$ & Number of prediction points, $K = \lfloor T / \tau_{\text{step}} \rfloor$ \\
$\hat{e}(t)$ & Predicted engagement at time $t$ \\
$\hat{e}_{\text{total}}$ & Predicted total cumulative engagement over horizon $T$ \\
\bottomrule
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}



\section{Next-time Social Engagement Prediction}
\label{sec:next_token_pred}
While overall engagement prediction provides valuable insights into model performance, the ability to predict engagement at future time points is crucial for real-time social media monitoring and intervention. This section focuses on models capable of generating predictions for upcoming engagement values at the next future time point. We evaluate Informer~\cite{zhou2021informer}, Autoformer~\cite{wu2021autoformer}, Mamba~\cite{mamba2}, and \icmamba for this task, as these models are architecturally designed for next-point prediction.

We follow the same temporal set up for next-time social engagement prediction task, with 6-hour history data as the input.
For this task, we set up three different temporal stages of post lifecycle, each representing different length of intervals and data availability scenarios. 
Early-stage predictions (within first hour) have limited historical data but require quick response to emerging trends. 
Mid-stage predictions (within first day) balance data availability with evolving engagement patterns. 
Late-stage predictions (within first week) have rich historical context but must account for long-term engagement dynamics.

\begin{table}[htb]
    \caption{Engagement prediction results with fixed 6-hour historical window; RMSE scores reported; lower is better; best results in boldface. All models use exactly 6 hours of historical data regardless of when the next engagement occurs.}
    \centering
    \begin{adjustbox}{max width=1.0\linewidth}
    \begin{tabular}{lccccc}
    \toprule
    \toprule
    Model                              & Bushfire       & Climate        & Vaccination    & CoVID          & DiN            \\ \midrule
    Informer~\cite{zhou2021informer}   & 0.208          & 0.215          & 0.203          & 0.211          & 0.248          \\
    Autoformer~\cite{wu2021autoformer} & 0.196          & 0.203          & 0.191          & 0.199          & 0.234          \\
    \midrule
    Mamba~\cite{mamba2}                & 0.152          & 0.158          & 0.147          & 0.155          & 0.184          \\
    \icmamba                           & \textbf{0.144} & \textbf{0.150} & \textbf{0.139} & \textbf{0.147} & \textbf{0.175} \\
    \bottomrule
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{tab:fixed_window}
\end{table}

\begin{table}[htb]
\caption{Early-stage engagement prediction results (next interval $\leq$ 1 hour); RMSE scores reported; lower is better; best results in boldface.}
\centering
\begin{adjustbox}{max width=1.0\linewidth}
\begin{tabular}{lccccc}
\toprule
\toprule
Model                              & Bushfire       & Climate        & Vaccination    & CoVID          & DiN            \\ \midrule
Informer~\cite{zhou2021informer}   & 0.245          & 0.252          & 0.238          & 0.248          & 0.299          \\
Autoformer~\cite{wu2021autoformer} & 0.231          & 0.238          & 0.225          & 0.234          & 0.284          \\
\midrule
Mamba~\cite{mamba2}                & 0.188          & 0.194          & 0.193          & 0.201          & 0.265          \\
\icmamba                           & \textbf{0.169} & \textbf{0.175} & \textbf{0.164} & \textbf{0.172} & \textbf{0.235} \\
\bottomrule
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:early_stage}
\end{table}

\begin{table}[htb]
\caption{Mid-stage engagement prediction results (next interval $\leq$24 hours); RMSE scores reported; lower is better; best results in boldface.}
\centering
\begin{adjustbox}{max width=1.0\linewidth}
\begin{tabular}{lccccc}
\toprule
\toprule
Model                              & Bushfire       & Climate        & Vaccination    & CoVID          & DiN            \\ \midrule
Informer~\cite{zhou2021informer}   & 0.198          & 0.205          & 0.193          & 0.201          & 0.235          \\
Autoformer~\cite{wu2021autoformer} & 0.187          & 0.194          & 0.182          & 0.190          & 0.223          \\
\midrule
Mamba~\cite{mamba2}                & 0.142          & 0.148          & 0.137          & 0.145          & 0.172          \\
\icmamba                           & \textbf{0.135} & \textbf{0.141} & \textbf{0.130} & \textbf{0.138} & \textbf{0.164} \\
\bottomrule
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:mid_stage}
\end{table}

\begin{table}[htb]
\caption{Late-stage engagement prediction results (next interval $\leq$1 week); RMSE scores reported; lower is better; best results in boldface.}
\centering
\begin{adjustbox}{max width=1.0\linewidth}
\begin{tabular}{lccccc}
\toprule
\toprule
Model                              & Bushfire       & Climate        & Vaccination    & CoVID          & DiN            \\ \midrule
Informer~\cite{zhou2021informer}   & 0.165          & 0.137          & 0.152          & 0.168          & 0.175          \\
Autoformer~\cite{wu2021autoformer} & 0.156          & 0.128          & 0.163          & 0.159          & 0.168          \\
\midrule
Mamba~\cite{mamba2}                & 0.118          & 0.123          & 0.114          & 0.121          & 0.144          \\
\icmamba                           & \textbf{0.112} & \textbf{0.117} & \textbf{0.108} & \textbf{0.115} & \textbf{0.137} \\
\bottomrule
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:late_stage}
\end{table}

\paragraph{Fixed-Window Prediction (6-Hour Input)} Table~\ref{tab:fixed_window} presents the RMSE scores for engagement prediction using a fixed 6-hour historical window. All models use exactly 6 hours of historical data regardless of when the next engagement occurs. 
We observe that \icmamba consistently achieves the lowest RMSE scores across all datasets, indicating strong performance in capturing short-term temporal patterns. However, it's noteworthy that baseline models like Autoformer and Informer also perform competitively, suggesting that the fixed-window approach provides sufficient context for short-term prediction.
An interesting finding is that the performance gap between \icmamba and Mamba is relatively small in this setting. 


\paragraph{Early-Stage Prediction ($\leq$ 1 hour)}
In the early-stage prediction task, models forecast the next engagement within the first hour of a post's publication. As shown in Table~\ref{tab:early_stage}, all models experience increased RMSE compared to the fixed-window prediction, reflecting the challenge of making accurate predictions with limited historical data (typically 2-9 data points). Notably, \icmamba achieves the lowest RMSE, but the performance gap between \icmamba and Mamba widens in this setting.

Another observation is that the baseline models, Informer and Autoformer, show a heavy drop in performance during early-stage predictions. 
Additionally, the DiN dataset shows higher RMSE scores across all models, indicating that early-stage prediction is particularly challenging for post related to disinformation. 

\paragraph{Mid-Stage Prediction ($\leq$24 hours)}
In the mid-stage predictions, with more historical data available, all models show improved RMSE scores (Table~\ref{tab:mid_stage}). The performance gap between the models becomes smaller, indicating that the availability of additional data helps all models make better predictions. \icmamba continues to outperform the baselines.

An interesting finding is that the performance on Vaccination theme shows a significant reduction in RMSE for all models in the mid-stage prediction. This may imply that engagement patterns for vaccination-related content become more predictable within the first day, possibly due to sustained public interest and consistent interaction patterns.


\paragraph{Late-Stage Prediction ($\leq$1 week)}
 For late-stage predictions, with extensive historical data (up to one week), all models achieve their best RMSE scores (Table~\ref{tab:late_stage}). The performance differences between models are less pronounced, though \icmamba still holds a slight advantage.

 We found that the Climate theme shows relatively low RMSE scores across all models in late-stage prediction. This could reflect consistent engagement patterns over longer periods for climate-related content, perhaps due to sustained public interest and ongoing discussions.






