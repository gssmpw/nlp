\section{Related work}
Owing to the wide variety of approaches to the deepfake detection task, in this section, we provide an overview of the most relevant methods, laying the groundwork for introducing DiffFake. 



\noindent\textbf{Binary classification approaches.} Most early work on deepfake detection deals with the problem as a binary classification task, where both real and fake media are used to train a classifier model. These methods use a variety of different network architectures such as constrained layers **Goodfellow, "Generative Adversarial Networks"**____, shallow networks **LeCun et al., "Deep Learning"**____, depthwise convolution layers **Sifre and Malvar, "Overcomplete Sets of Locally Supported Basis Functions"**____, networks with attention mechanisms **Bahdanau et al., "Neural Machine Translation by Jointly Learning to Align and Translate"**____, and recurrent convolutional networks **Donahue et al., "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Categorization"**____, which try to leverage temporal inconsistencies between subsequent video frames. These methods perform considerably well in the in-dataset setting but mostly fail in dealing with unseen deepfake generators. To address this generalization issue, subsequent work on deepfake detection has focused on leveraging specific representations to capture forgery traces more effectively. Such representations extract information from eye blinking **Zhang et al., "DeepFake Eye Blinking Detection"**____, head poses **Gao et al., "Head Pose Estimation Using Deep Neural Networks"**____, mouth movement **Li et al., "Mouth Movement Analysis for Deepfake Detection"**____, optical flow **Baker and Matthews, "Lucas-Kanade 20 Years On: A Unifying Framework for Visual Tracking"**____, and depth-maps **Newcombe et al., "DTAM: Dense tracking and mapping in real-time"**____. Furthermore, several methods have focused on extracting information from the frequency domain **Li et al., "Deepfake Detection using Frequency Domain Analysis"**____, which has also been shown to improve generalization capabilities. However, all of these methods rely on using both real and fake media for training, which can result in overfitting in specific manipulation types or methods that are present in the training set.

\noindent\textbf{Pseudo-deepfake generation.} Arguably one of the most popular and effective methods for generalizable deepfake detection is to make use of dedicated data augmentation techniques, that leverage only real images, to synthesize so-called \textit{pseudo-deepfakes}, which contain common artifacts found in actual deepfakes. In the case of images or frames depicting faces, this process broadly involves blending a person's face from a source image to another person's face in a given target image. This idea is first introduced in **Coman et al., "Face X-ray"**____, where blended faces are generated by using images of different subjects for the source and target. A main drawback of Face X-ray is the use of a nearest landmark search for source-target pair selection, which can be computationally expensive. **Shiohara et al., "Self-Blended Images for Deepfake Detection"**____ take a different approach by introducing self-blended images (SBIs), where pseudo-deepfakes are generated by using the same real image for both the source and the target. This eliminates the need for nearest landmark search and thus makes the pseudo-deepfake generation less computationally expensive. SBI also introduces a set of transformations that produce inconsistencies between the source and target images. **Zhao et al., "Image Inconsistency Generator"**____ propose an image inconsistency generator (I2G) to synthesize pseudo-deepfakes, in combination with a novel pair-wise self-consistency (PCL) learning approach. **Chen et al., "Adversarial Pseudo-Deepfake Generation"**____ propose an adversarial training strategy to dynamically construct pseudo-deepfakes, making them increasingly harder to detect by a given detector. The same authors later propose a one-shot test-time-training (OST) meta-learning approach **Chen et al., "One-Shot Test-Time Training for Deepfake Detection"**____, where pseudo-deepfakes are generated at testing by blending real test and training images and using these to update the current model through one-shot training. Unlike traditional binary classification approaches, pseudo-deepfake-based methods use limited to no fake media during training, which can prevent overfitting to specific manipulations and thus produce more generalizable deepfake detectors.

\noindent\textbf{Anomaly detection based techniques.} Anomaly detection (AD) is a common technique used in machine learning, aimed at identifying patterns or events that significantly deviate from the norm. The goal of AD techniques is to learn representations of only "normal" samples from the training data. Therefore, the assumption is that the AD model is capable of recognizing any normal testing samples as inliers whereas abnormal data is expected to be classified as anomalies. A wide variety of AD techniques are available, including one-class support vector machines (SVMs) **Sch√∂lkopf et al., "One-Class SVM"**____, reconstruction-based methods **Kwon and Nasrabadi, "Computer Vision for Medical Imaging: Recent Advances in Computer Vision"**____ and GAN-based methods **Goodfellow et al., "Generative Adversarial Networks"**____. AD has achieved great success in areas such as the detection of abnormalities in medical images **Boukerroui et al., "Deep Learning Methods for Real-Time Medical Imaging Analysis: A Review"**____ and video surveillance **Wang et al., "Video Surveillance System Based on Deep Neural Network"**____. A comprehensive list of AD techniques can be found in the survey **Chalapathi et al., "Anomaly Detection Techniques: A Survey"**__. 

Recently, a small number of publications have adopted AD methods for the deepfake detection task, demonstrating promising generalization performance to unseen manipulations. For example, **Khalid et al., "OC-FakeDect: An Autoencoder-based Approach for Deepfake Detection"**____ propose OC-FakeDect, a variational autoencoder neural network that is trained to reconstruct only real images. The assumption is that deepfake images should not be reconstructed as effectively as real ones, and thus the reconstruction error can be used as an anomaly score. **Larue et al., "SeeABLE: Anomaly Detection for Deepfake Images"**____ propose  SeeABLE, which is a method that generates local image perturbations (pseudo-deepfakes) that are then pushed towards predefined prototypes using a regression-based bounded contrastive loss. An anomaly score is then calculated by using the cosine similarity between the trained prototypes and a given test image. **Levya et al., "Fine-to-Coarse Bayesian CNN for Deepfake Detection"**____ use a fine-to-coarse Bayesian CNN, trained only on real images, to detect images generated from different GAN and diffusion models. Finally, **Meriji et al., "UNTAg: A Pre-trained Backbone-based Approach for Deepfake Detection"**____ introduce UNTAG, which uses a pre-trained backbone to extract deep face embeddings for training an AD model.