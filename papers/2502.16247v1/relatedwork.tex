\section{Related work}
Owing to the wide variety of approaches to the deepfake detection task, in this section, we provide an overview of the most relevant methods, laying the groundwork for introducing DiffFake. 



\noindent\textbf{Binary classification approaches.} Most early work on deepfake detection deals with the problem as a binary classification task, where both real and fake media are used to train a classifier model. These methods use a variety of different network architectures such as constrained layers \cite{bayar2016deep_constrained_layers}, shallow networks \cite{afchar2018mesonet}, depthwise convolution layers \cite{rossler2019faceforensics++}, networks with attention mechanisms \cite{dang2020detection_attention,zhao2021multi}, and recurrent convolutional networks \cite{sabir2019recurrent,guera2018deepfake_recurrent}, which try to leverage temporal inconsistencies between subsequent video frames. These methods perform considerably well in the in-dataset setting but mostly fail in dealing with unseen deepfake generators. To address this generalization issue, subsequent work on deepfake detection has focused on leveraging specific representations to capture forgery traces more effectively. Such representations extract information from eye blinking \cite{jung2020blinking}, head poses \cite{yang2019head_poses}, mouth movement \cite{haliassos2021lips}, optical flow \cite{amerini2019optical_flow}, and depth-maps \cite{maiano2022depthfake}. Furthermore, several methods have focused on extracting information from the frequency domain \cite{zhang2019detecting_freq,frank2020leveraging_freq,qian2020thinking_in_freq,liu2021spatial_phase_freq,luo2021generalizing_freq}, which has also been shown to improve generalization capabilities. However, all of these methods rely on using both real and fake media for training, which can result in overfitting in specific manipulation types or methods that are present in the training set.

\noindent\textbf{Pseudo-deepfake generation.} Arguably one of the most popular and effective methods for generalizable deepfake detection is to make use of dedicated data augmentation techniques, that leverage only real images, to synthesize so-called \textit{pseudo-deepfakes}, which contain common artifacts found in actual deepfakes. In the case of images or frames depicting faces, this process broadly involves blending a person's face from a source image to another person's face in a given target image. This idea is first introduced in Face X-ray \cite{li2020face_x_ray}, where blended faces are generated by using images of different subjects for the source and target. A main drawback of Face X-ray is the use of a nearest landmark search for source-target pair selection, which can be computationally expensive. Shiohara \etal \cite{shiohara2022detecting} take a different approach by introducing self-blended images (SBIs), where pseudo-deepfakes are generated by using the same real image for both the source and the target. This eliminates the need for nearest landmark search and thus makes the pseudo-deepfake generation less computationally expensive. SBI also introduces a set of transformations that produce inconsistencies between the source and target images. Zhao \etal \cite{zhao2021learning} propose an image inconsistency generator (I2G) to synthesize pseudo-deepfakes, in combination with a novel pair-wise self-consistency (PCL) learning approach. Chen \etal \cite{chen2022self_adversarial} propose an adversarial training strategy to dynamically construct pseudo-deepfakes, making them increasingly harder to detect by a given detector. The same authors later propose a one-shot test-time-training (OST) meta-learning approach \cite{chen2022ost}, where pseudo-deepfakes are generated at testing by blending real test and training images and using these to update the current model through one-shot training. Unlike traditional binary classification approaches, pseudo-deepfake-based methods use limited to no fake media during training, which can prevent overfitting to specific manipulations and thus produce more generalizable deepfake detectors.

\noindent\textbf{Anomaly detection based techniques.} Anomaly detection (AD) is a common technique used in machine learning, aimed at identifying patterns or events that significantly deviate from the norm. The goal of AD techniques is to learn representations of only "normal" samples from the training data. Therefore, the assumption is that the AD model is capable of recognizing any normal testing samples as inliers whereas abnormal data is expected to be classified as anomalies. A wide variety of AD techniques are available, including one-class support vector machines (SVMs) \cite{scholkopf1999one_class_svm}, reconstruction-based methods \cite{xia2015reconstruction_based} and GAN-based methods \cite{sabokrou2018adversarially}. AD has achieved great success in areas such as the detection of abnormalities in medical images \cite{baur2019deep_AD_MR} and video surveillance \cite{sultani2018real_video_surv}. A comprehensive list of AD techniques can be found in the survey \cite{yang2022visual}. 

Recently, a small number of publications have adopted AD methods for the deepfake detection task, demonstrating promising generalization performance to unseen manipulations. For example, Khalid \etal \cite{khalid2020ocfakedect} propose OC-FakeDect, a variational autoencoder neural network that is trained to reconstruct only real images. The assumption is that deepfake images should not be reconstructed as effectively as real ones, and thus the reconstruction error can be used as an anomaly score. Larue \etal \cite{larue2023seeable} propose  SeeABLE, which is a method that generates local image perturbations (pseudo-deepfakes) that are then pushed towards predefined prototypes using a regression-based bounded contrastive loss. An anomaly score is then calculated by using the cosine similarity between the trained prototypes and a given test image. Levya \etal \cite{leyva2024data} use a fine-to-coarse Bayesian CNN, trained only on real images, to detect images generated from different GAN and diffusion models. Finally, Meriji \etal \cite{mejri2023untag} introduce UNTAG, which uses a pre-trained backbone to extract deep face embeddings for training an AD model.