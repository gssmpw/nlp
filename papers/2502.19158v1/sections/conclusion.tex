This work addresses gaps in LLM personalization research by introducing a systematic evaluation framework. We establish a principled methodology for characterizing preference datasets through: inter-user disagreement, intra-user consistency, and minority representation. Our analysis across P-SOUPS, TL;DR, and Personal-LLM datasets reveals distinct challenges that personalization methods must address, from high disagreement to varying levels of minority viewpoint representation.

Our comprehensive evaluation framework extends beyond accuracy to address practical constraints and potential risks. Through this lens, we evaluate eight representative personalization methods, finding that Individual RM provides a strong baseline while collaborative approaches like PRM achieve up to 6\% improvement. Notably, some methods successfully preserve minority preferences that standard RLHF would overlook. However, we also identify a "personalization tax," where optimizing for individual preferences can degrade model safety and reasoning capabilities.

These findings demonstrate both the promise and challenges of personalization. We hope this work's systematic framework and empirical insights will guide the development of more robust, inclusive, and responsible personalization approaches that can better serve diverse global user. 






