\section{Background of Cost Estimation} \label{sec:background}
This section first gives a brief overview of classical and learned cost estimation. 
Afterwards, we describe the learning procedure of \lcms and provide a taxonomy that guides our selection of recent \lcms for this study in \Cref{sec:methodology}.

\subsection{Traditional \& Learned Cost Estimation}
\textbf{Traditional Cost Estimation.} 
Precise cost estimates for different plan candidates in a database are crucial for the query optimizer to select optimal plans from a large search space.
Thus, a lot of engineering effort has been spent since the beginning of database development to estimate the execution costs of a query plan.
Most database systems such as MySQL \cite{widenius2002}, Oracle, PostgreSQL, or System R \cite{astrahan1976} use hand-crafted cost models to reason about the execution costs of a query plan.
These models typically provide a cost function for each physical operator in a query plan that estimates its runtime costs according to CPU usage, I/O operations, memory consumption, expected tuples, and random or sequential page accesses.
However, due to the wide variety of data, queries, and data layouts, traditional cost models need to make simplifying assumptions (e.g., independence of attributes).
These often lead to incorrect predictions of the execution cost. 
Consequently, the query optimizer makes sub-optimal decisions that degrade the query performance by increasing its runtime \cite{leis_how_2015}.
%-------------------------------------------------------

\noindent\textbf{Learned Cost Estimation.}
The need to improve prediction accuracy and the rise of machine learning motivated the idea of \lcms. 
The main idea is to approximate the complex cost functions with a learned model.
Generally, a typical model learns from previous query executions to predict execution costs like runtime.
In contrast to traditional cost models, the promise of \lcms is that they can better learn arbitrarily complex functions.
Thus, improved prediction accuracy can be expected in contrast to traditional approaches based on simplifying assumptions.
Overall, the higher accuracy is expected to lead to a selection of query plans with improved query performance.

%-----------------------------------------
\subsection{Learning Procedure of \lcms}
For our study, we look at effects that also result from the learning procedure of \lcms.
As such, we briefly review the traditional procedure as depicted in \Cref{fig:learning_procedure} to provide the necessary background:
\circles{A}~At first, a workload generator is used to create a large set of randomized, synthetic SQL-Strings that involve a variety of representative query properties such as filter predicates, joins, or aggregation types.
\circles{B}~These queries are executedses (e.g., an airline or movie database) to collect the actual costs of queries.
An important aspect here is that training procedures of many \lcms leads to biases in the dataset due to timeouts and pre-optimized queries, as discussed later.
\circles{C}~Next, various information is extracted from the workload execution.
Most importantly, the physical query plans are extracted, which serve as input to cost models.
In addition to physical plans, \lcms require different information, such as data characteristics like histograms or sample bitmaps.
\circles{D}+\circles{E}~Finally, the workload (i.e., plans and runtime) is then split for training and testing the \lcms. 

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{./figures/training_procedure.pdf}
    \caption{
    Learning procedure of \lcms. 
    \circles{\textsc{A}} Generation of synthetic training queries. \circles{\textsc{B}} Query execution on training databases. 
    \circles{\textsc{C}} Feature (query plans, data characteristics, and sample bitmaps) and label (query runtimes) extraction to generate the training and test dataset. 
    \circles{\textsc{D}} Training of the \lcm with supervised learning. 
    \circles{\textsc{E}} Evaluation of the \lcm against unseen test data.}
    \label{fig:learning_procedure}
\end{figure*}

%------------------------------------------------------
\subsection{Taxonomy of \lcms} \label{subsec:taxonomy}
\lcms developed in the last years differ in various dimensions.
This section provides a brief taxonomy of recent \lcms to structure the different methodological approaches. 
This taxonomy will guide the selection of \lcms that we use in this study and ensure that we cover the different methodologies to analyze how they affect the ability of \lcms to support query optimization.

\noindent\textbf{Input Features.}
The first crucial dimension is the input features that a \lcm learns from.
The input features are extracted from the executed workloads (cf. \Cref{fig:learning_procedure}\circles{C}).
The query plan and the underlying data distribution need to be modeled so that a \lcm is informed to make reasonable predictions about the execution costs, which in turn affects query optimization, as we will show.
However, \lcms make use of different information for cost estimation.

\begin{enumerate}[leftmargin=*, nosep]
\item \textbf{SQL-String vs. Query Plans}: 
Some of the first models rely on the SQL string to describe a query, as it gives insights about the tables, predicates, and joins. 
However, details of the execution plan, such as physical operators or the order of joins, are not described there. 
Thus, most \lcms utilize the physical query plan, which includes the operators (e.g., scans, joins) and physical operator types  (e.g., nested loop vs. hash join).
As we will see later, this is fundamental for query optimization.

\item \textbf{Cardinalities}:
Intermediate cardinalities are an important input signal for the overall cost of a plan as they denote the number of tuples an operator needs to process \cite{leis_how_2015}.
Thus, many \lcms leverage intermediate cardinalities as input features, which are either annotated by the databases' cardinality estimator or obtained through an additional learned estimator from related work \cite{hilprecht2020deepdb, kipf2019, yang2020}.
While some \lcms also ignore cardinalities as input for cost prediction, we show in our study that they, in fact, improve the usefulness of cost estimates from \lcms for various query optimization tasks.

\item\textbf{Data Distribution}:
Another helpful factor in estimating cost is understanding the data distribution in the base tables, especially if no cardinalities are used.
For instance, the fact of how many distinct values exist in a column might influence the efficiency of physical operators (e.g., hash join). 
As such, some \lcms use data distribution represented as database statistics and histograms or sample bitmaps (which we explain later) from the base tables as inputs.
However, as we will show in our study, their effect on query optimization tasks remains unclear.

\item \textbf{Cost Estimates}: 
Finally, some of the most recent \lcms even leverage the cost estimates provided by a classical cost estimator as an input feature, which serves as a strong input signal.
This idea renders these \lcms to \textit{hybrid} as they combine a traditional cost model with a learned approach.
The study shows that this provides significant benefits.
\end{enumerate}

%-----------------------------------------------------
\noindent \textbf{Query Representation.}
Many \lcms use model architectures use a graph-based representation to encode query plans as input to the models\footnote{The graph-based representation of the queries refers to the fact whether a model leverages the query graph structure and not to the model learning architecture itself.}.
These approaches thus explicitly leverage information about the order (parent-child relationships) of operators in plans.
However, other \lcms \cite{kipf2019, akdere2012} represent a query plan (or the SQL string) as a flat vector of fixed size without modeling the operator dependencies, which we refer to as \textit{flat} representation in this paper.
While intuitively, capturing the structure and not using a flat representation should be beneficial for \lcms, the results of using graph structure in this study are not that clear. 

%-------------------------------------------------------
\noindent \textbf{Database Dependency.}
Furthermore, an important aspect is whether \lcms can generalize to unseen databases (i.e., a new set of tables) or not.
\textit{Database-agnostic} \lcms were designed \cite{hilprecht2022, zibo_liang_dace_2024} to enable cost predictions for unseen databases that were not part of the training data.
This approach has the advantage of directly providing results without requiring database-specific training data. 
In contrast, \textit{database-specific} \cite{sun2019, zhao2022, marcus2019} models cannot generalize for unknown databases.
For this study, an interesting question is if one of these classes is better suited to support query optimization tasks as database-specific can better adapt to one single database while database-agnostic models can generalize better.

%----------------------------------------
\noindent \textbf{Model Architecture.}
Finally, the presented \lcms differ largely in their learning approach.
Various learning architectures were proposed, including decision trees, tree-structured neural networks, neural units, graph neural networks, and transformer architectures.
While different architectures show different results on the cost estimation tasks, it is still open to see which architecture provides the best results for query optimization.
%----------------------------------------