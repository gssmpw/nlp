\section{Introduction} \label{sec:introduction}
\noindent\textbf{Cost Estimation is Crucial for Databases.}
Accurate cost prediction of a query plan is essential for optimizing the query performance in a database.
During query optimization, estimated costs of various candidate plans guide the plan selection for execution \cite{leis_how_2015}.
Consequently, accurate cost estimates are pivotal in query optimization.
In the worst case, incorrect cost estimates can lead to the selection of highly unfavorable plans with a runtime that is several factors higher than the optimal one.
However, it is well known that providing accurate cost estimates is difficult and inaccurate estimates influence the results of finding an optimal plan significantly \cite{lan2021survey, heinrich2024}.

%---------------------------------------
\noindent\textbf{The Need for Accurate Cost Models.}
In recent decades, classical rule- or heuristic-based cost estimation methods have been the backbone for query optimization in commercial DBMSs.
However, since they rely on heuristics and simple analytical models, traditional methods struggle with accuracy and provide estimates that often deviate by orders of magnitude from the actual execution costs \cite{leis_how_2015}, leading to sub-optimal query execution plans with prolonged runtimes.
Thus, much research has been dedicated to making cost models more precise and improving overall performance \cite{karampaglis2014, he2005}.

\noindent\textbf{The Rise of Learned Cost Models.} 
Supported by the high potential of Machine Learning (ML), many \acfp{lcm} have been proposed over the last years \cite{hilprecht2022, ganapathi2009, akdere2012, kipf2019, marcus2019, zibo_liang_dace_2024, yang2023, zhao2022, li_learned_2024, chang2024, lu2022, duggan2011, heinrich2024, zhou2020, wu2022, agnihotri2024}.
These models typically leverage actual costs from executing training queries to learn patterns and predict the execution cost of new queries.
The main promise of \lcms lies in the fact that they can better capture complex data distributions and inter-dependencies with workloads and thus potentially lead to more efficient query processing and shorter query runtimes.
As a result, many recent papers about \lcms \cite{zibo_liang_dace_2024, sun2019, hilprecht2022} show that they can significantly outperform classical cost models that are employed in traditional database systems such as PostgreSQL in terms of cost prediction.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/motivating_plot.pdf}
    \caption{\circles{A} \lcms outperform traditional approaches in terms of cost estimation on an unseen IMDB dataset. 
    \circles{B} However, when optimizing a workload (JOB-Light) for join order, the traditional PostgreSQL (PG) model still performs best.}
    \label{fig:motivating_plot}
\end{figure}

%-------------------------------------------------------
\noindent\textbf{Do \lcms Really Help in Query Optimization?}
However, while \lcms have led to improvements in accuracy, a core question is if they lead to improvements for query optimization and to what extent. 
Surprisingly, most existing evaluations primarily focus on the accuracy of the cost estimation task and largely neglect a deeper analysis of how these cost models actually improve query optimization \cite{hilprecht2022, ganapathi2009, akdere2012, kipf2019, marcus2019, zibo_liang_dace_2024, sun2019, yang2023, zhao2022, lu2022, zhou2020}.
In this paperâ€š we argue that accuracy alone is not meaningful, as it cannot reflect important tasks in query optimization, such as the ranking and selection of plans.
We thus aim to close this gap and conduct a systematic study to assess \textit{how good learned cost models really are for query optimization?}
Unfortunately, the results of our study are rather grim, as shown by \Cref{fig:motivating_plot}, which highlights some of the findings of our study.
In \Cref{fig:motivating_plot} \circles{A}, we compare the accuracy of a broad spectrum of recent \lcms. Here, in terms of prediction error, the traditional approach PostgreSQL (PG, black bar) is outperformed by all \lcm competitors (colored bars) on the IMDB dataset\footnote{We report the median Q-error as standard metric for cost models. It defines the relative deviation of the predicted from the actual cost. A perfect prediction has a Q-error of $1$. See \Cref{subsec:setup} for more details on the setup.}
However, the picture is very different when using the cost models for finding optimal join orders on the JOB-Light benchmark \cite{kipf2019}. 
\Cref{fig:motivating_plot} \circles{B} shows that the total query runtime is \textit{not} improving when using \lcms for join ordering.
Here, \textit{none} of the \lcms is able to provide better selections than PostgreSQL, resulting in a higher total runtime of selected plans on the JOB-Light benchmark of up to 832s, whereas PostgreSQL achieves 510s. 

%--------------------------------------
\noindent\textbf{A Novel Evaluation Study.}
From these results, it becomes clear that focusing alone on the accuracy of cost estimation is not sufficient.
As such, in this paper, we provide a systematic study to shed some light on the question of why \lcms fail to enable better optimizer decisions.
To answer this question, we have chosen \textit{three} of the most important tasks of query optimization (\textit{join ordering}, \textit{access path selection}, and \textit{physical operator selection}) and analyze whether or not \lcms are able to improve plan selection.
As a main contribution, we evaluate a set of recent \lcms that cover a broad spectrum of approaches proposed in the literature and compare their impact on query optimization against the traditional cost model of PostgreSQL.
We suggest a task-specific, fine-grained evaluation strategy for each downstream task that goes beyond prediction accuracy, assessing how \lcms affect query optimization.

\noindent\textbf{Key Insights of Our Study.}
Our evaluation reveals three key insights that we summarize in the following:
\begin{enumerate}[leftmargin=*, nosep]
    \item \textit{High accuracy in cost is not sufficient}: Across all analyzed query optimization tasks, we observed that it is insufficient to focus solely on the prediction accuracy of plan costs.
    Instead, \lcms need to fulfill other properties such as reliable ranking and selection of plans.
    Moreover, existing \lcms majorly only optimize for median prediction errors while possessing high errors in the tail, leading to large over- and underestimation and making \lcms prone to select non-optimal plans.
    \item \textit{Training data matters}:
    As \lcms are typically trained on queries that have been pre-optimized by a traditional query optimizer, their training data is biased towards near-optimal plans.
    However, during query optimization, \lcms must predict costs for both optimal and non-optimal plans. 
    Moreover, training data quality can also introduce other biases, especially when timeouts are used during query execution for training data collection, distorting the \lcms understanding of ``bad'' plans. 
    For instance, query plans with nested-loop joins may often timeout before completion and thus, only the cases where nested-loop joins are beneficial are included in the training data.
    \item \textit{Don't throw away, what we know}:
    Traditional cost models often deviate significantly from actual costs in their estimates. 
    However, they incorporate extensive expert knowledge based on years of experience.
In our paper, we found that using their estimates as input to \lcms is highly beneficial as it significantly improves the cost estimates for query optimization tasks.
\end{enumerate}
\noindent\textbf{Consequences for \lcms.} 
Overall, we believe that the results of our study can guide future research and development efforts toward more reliable ML-based cost estimation that makes informed decisions about query optimization tasks. 
We discuss some directions based on the evidence of this paper that will help to provide \lcms, which actually benefits query optimization.
Furthermore, to enable the research community to build on our results, we made the source code, models, and all the evaluation data publicly available\footnote{
\label{code_link}\textbf{Source Code}: \url{https://github.com/DataManagementLab/lcm-eval};\\
\label{data_link}\textbf{Experimental data \& trained models}:
\url{https://osf.io/rb5tn/}}

\noindent\textbf{Outline.}
We first provide a background in cost estimation in \Cref{sec:background}.
Next, we present our evaluation methodology in \Cref{sec:methodology}, including a taxonomy of recent \lcms.
In the subsequent sections, we then evaluate the downstream tasks of join ordering (\Cref{sec:join_order}), access path selection (\Cref{sec:access_path_selection}), and physical operator selection (\Cref{sec:physical_operator}).
We provide our recommendations for \lcms in \Cref{sec:lessons} and summarize this paper in \Cref{sec:conclusion}.