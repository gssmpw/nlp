\firstsection{Introduction}
\maketitle
Interactive volume visualization techniques are crucial for enabling researchers across various disciplines to efficiently discover insightful features within scientific datasets from fields like medical imaging, geophysics, meteorology, materials science, and physical simulations. A visualization system that quickly responds to user interactions, adapting to data and viewing adjustments, can greatly enhance the efficiency and effectiveness of exploring complex scientific datasets. However, interactive volume visualization is challenging because of the following factors: First, the size of volumetric data generated nowadays is growing exponentially, necessitating an efficient storage and I/O system to facilitate large-scale data streaming between different computing units for generating comprehensive visualization results. Second, visualization techniques, like ray casting, ray tracing, global illumination, and high-order rendering, often demand significant computational resources to generate high-resolution, high-fidelity images.

Various strategies have been proposed to address this performance issue in volumetric data visualization. For example, distributed volume visualization methods~\cite{10386434, 5219060} harness the parallel machines to divide the workload and then composite the partially rendered results into the final rendering image. Multi-resolution methods~\cite{Heckbert1999MultiresolutionMF, 10.1145/1186822.1073277, GUTHE200451, 1234567} optimize the arrangement of data segments with different levels of detail (LOD) to improve the rendering latency while maintaining a high rendering quality. To improve the smoothness of volumetric data exploration, visualization systems also utilize caching and prefetching~\cite{10.1145/279361.279372, 10.1145/2907071} to reduce the data movement across the system memory hierarchy to decrease the input latency while rendering continuous frames along a user's exploratory trajectory. The user behavior while exploring volumetric data can be learned~\cite{10549835, 8365978} to better assist the prefetching through the prediction of view parameters.

Recent image synthesis techniques utilizing deep learning-based super-resolution in both spatial and temporal domains~\cite{10.1145/3485132,10.1007/978-3-030-00563-4_11, liu2022video} are being adopted for visualizing large-scale volumetric datasets with responsive input latency. Given a partially rendered image from a view angle, where only a small percentage of the total pixels are rendered, the idea is to guess or interpolate the missing pixels through a trained neural network in constant time by leveraging the parallelization of GPU instead of going through the complex rendering algorithm to calculate the color blending for each pixel of the final image. The network that reconstructs the incomplete image to a full image is called a reconstruction neural network and we name such network as RecNN for the rest of the paper. Those methods rely on training an implicit neural representation~\cite{NEURIPS2020_53c04118, 10.1007/978-3-031-19809-0_5} from the original large-scale data considering complex rendering pipeline, and the trained representation is fast to inference for interactive visualization tasks. Volume visualization methods utilizing RecNNs give state-of-the-art performances in rendering latency~\cite{8237743, 9903564} when handling large-scale scientific datasets with complicated lighting effects.

The bag of pixels to render for each partially rendered image is determined by a binary sampling pattern provided by the specific reconstruction neural network used (e.g., downsampling patterns for super-resolution RecNNs and foveal patterns for foveated rendering RecNNs). However, such a pattern is a predefined hyperparameter before training the network, and it does not adapt to any of the key visualization parameters like user's views, transfer functions, and features of the underlying dataset. In this paper, we provide a method to further optimize the sampling pattern by finding which pixels contribute the most to the final reconstructed image (important pixels) and only rendering those pixels instead of all the pixels in the sampling pattern. The selection of important pixels from the sampling pattern is called the Importance Mask (IM). We proposed an Importance Mask Learning Network (IML Net) to learn the important pixels from the sampling pattern by jointly considering the dataset, user's view parameters, and the downstream RecNN. The learned IM will be used to train an Importance Mask Synthesis Network (IMS Net), which will directly generate the importance mask from each new view during the user's exploration. To the best of our knowledge, this is the first attempt at optimizing sampling patterns of visualization frameworks using RecNN. We use two state-of-the-art image inpainting RecNNs for volume visualization, EnhanceNet~\cite{8237743} for super-resolution and FoVolNet\cite{9903564} for foveated rendering, to showcase how our method can help to further improve the rendering latency for free without sacrificing noticeable rendering quality. The main contributions of this work include:
%=====
\setlist{nolistsep}
\begin{itemize}[leftmargin=*]
  \item Importance Mask Learning Network(IML Net), a unified neural network to learn the importance mask from diverse sampling patterns by jointly considering the volumetric dataset, user's view parameters, and the downstream reconstruction neural network.
  \item Importance Mask Synthesis Network(IMS Net), a regressor to directly predict the importance mask from the view parameters for fast generation of the partially rendered images.
  \item IML/S Net + RecNN, a visualization image synthesis network to further improve the already fast volume visualization methods using RecNN for free with similar rendering quality.
  \item Our networks can also be efficiently trained independently to the downstream RecNN to optimize the rendering latency for off-the-shelf pre-trained RecNN.
\end{itemize}
%=====



