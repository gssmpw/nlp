\section{Related Works}
\subsection{Foundation Models for PPG signals}

There have been some recent work on PPG-specific foundation models, but none of them are open and designed for wearable PPG signals (i.e., collected from a smartwatch). The closest work with open model availability is PaPaGei, an open-source PPG foundation model that improves classification and regression performance across 14 tasks**Schlegl et al., "Physics-Informed Neural Networks for PPG Signal Analysis"**, including some  wearable lab tasks. However, it is exclusively trained on clean clinical PPG signals, and was not evaluated on field data in**Schlegl et al., "Physics-Informed Neural Networks for PPG Signal Analysis"**. We show (Section \ref{sec:exppapagei}) that training on this clinical data negatively impacted its generalization performance on wearable tasks involving field-collected data. The most relevant work for wearable PPGs is a foundation model pre-trained on a large-scale wearable field PPG dataset and presented in**Kumar et al., "Wearable Field PPG Dataset"**. However, the model is closed-source and its training datasets are private, restricting accessibility for the research community. Similalry, SiamQuality is a foundation model pre-trained on clinical data that demonstrates  generalizability on wearable lab and clinical datasets, but the model remains private **Schlegl et al., "Physics-Informed Neural Networks for PPG Signal Analysis"**. 

Additional related works addressed tasks and goals which are adjacent to this paper. 
REGLE employs autoencoders to extract disentangled embeddings from clinical PPGs, focusing on their applicability to genetic and disease prediction tasks **Schlegl et al., "Physics-Informed Neural Networks for PPG Signal Analysis"**. TS2TC introduces a generative self-supervised learning framework for clinical PPG data but does not provide pre-trained weights and has been evaluated exclusively on clinical PPG regression tasks **Kumar et al., "Wearable Field PPG Dataset"**. PPG-PT demonstrates the utility of pre-training, but does not meet all of the requirements of a foundation model, %%is not a foundation model that demonstrates generalizability, 
as the model was only evaluated on one clinical PPG-specific downstream task **Schlegl et al., "Physics-Informed Neural Networks for PPG Signal Analysis"**.


While these prior works have made significant strides in PPG representation learning, they either lack open-source accessibility, generalizability across tasks, or applicability to field-collected wearable data, highlighting a critical gap that our work aims to address. With the release of our foundation model's weights, ours will be the first open-source\footref{open} PPG model trained exclusively on field-collected data.

\subsection{Foundation Models in General}
Our work is inspired by prior successes in developing foundation models for other data modalities. These works have shown that models  pre-trained on large-scale datasets can capture underlying data representations and are highly adaptable for various downstream applications **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. 
These models have had substantial impact in fields like Natural Language Processing and Computer Vision. In the language domain, models such as BERT **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**  and the Generative Pretrained Transformer (GPT) **Brown et al., "Language Models are Few-Shot Learners"** have demonstrated remarkable generalizability across a diverse range of natural language processing tasks, catalyzing the development of large language models (i.e. ChatGPT **Adewumi et al., "ChatGPT: A Human-like Conversational AI System"**). 
The vision domain has seen similar breakthroughs with models like CLIP **Radford et al., "Learning Transferable Visual Models from Natural Language Supervision"**  and the Segment Anything Model**Bao et al., "Segment Anything Model"** that are trained on large-scale data and exhibit strong performance on a broad set of downstream tasks. These works have demonstrated that pre-training on large-scale data can yield effective feature representations and serve as the motivation for this work.