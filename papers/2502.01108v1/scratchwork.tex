
To evaluate the effectiveness of our foundation model, we benchmark its performance against PAPAGEI~\cite{pillai2024papagei}, the first large-scale open PPG foundation model pre-trained on over 57,000 hours of publicly available clinical PPG data. PAPAGEI employs a novel self-supervised approach to optimize agreement between PPG signals with similar shape and characteristics across individuals. It computes three PPG matrices: (1) stress-induced Vascular Response Index (sVRI) for amplitude variations, (2) Inflection Point Area ratio (IPA) for signal width, and (3) Signal Quality index (SQI) for signal quality. A ResNet-18 CNN backbone, integrated with three linear projection heads, generates embeddings that are optimized to learn distinct signal attributes. The objective function combines contrastive loss (using sVRI to form positive pairs) and mean absolute error to ensure the model effectively captures informative feature representations. 

We opted to use PAPAGEI as a baseline rather than adopting their approach for several reasons. First, PAPAGEI relies on signal pre-processing to clean PPG signals for producing the target indices. While this approach is effective for relatively clean clinical datasets collected via finger PPG, it is less suitable for field data. In the field, PPG is often collected using wrist-worn devices, which for various reasons induce a lot more noise. Hence, the extent of filtering required for field data can attenuate signal characteristics, diminishing the effectiveness of these PPG morphology indices. Whereas, a filtering less approach may become more effectively adoptable specially for data collected from filed studies. Second, while PAPAGEI demonstrated strong performance across various datasets, we observed from the released model weights and code that a family of models was used for downstream evaluation tasks—one foundation model for each task. In contrast, we seek to build a single foundation model that can be used across different datasets and tasks. Thus, while PAPAGEI sets a critical stepping stone for PPG only foundations modeling, our goal is to build a single open source generalizable PPG foundation model.

Given these key considerations, we combine approaches from~\cite{xurebar} and~\cite{xu2024relcon} to build a foundation model more capable of addressing the nuances of field data. In particular, we leverage the learnable distance measure from~\cite{xurebar} with relative contrastive approach from~\cite{xu2024relcon}. Similarity measure from~\cite{xurebar} is preferred for its invariance to time-series data, while relative contrastive loss is chosen for its ability to learn fine-grained interactions within and between individuals. 


We report results of the various downstream tasks using learned representations from field ppg by PPG-RelCon, and compare them with the respective results reported by PaPaGEI, another foundation model but from clinical ppg. To ensure a fair comparison, we use the publicly available weights of PaPaGEI and apply a linear probing approach for each downstream task. In linear probing, the pre-trained weights of a model are frozen, and used only to compute feature representations from the input data. A lightweight linear classifier or regressor is then trained on these features, without modifying the pre-trained model itself. This permits evaluation of its learned representations against PPG-RelCon, which is also tested using linear probing. 

Stress has an overall negative impact on individual wellness, making its automatic detection through AI-driven solutions a critical task. To achieve this, it is crucial for a foundation model to sufficiently capture temporal patterns in PPG signal that can be effectively mapped to a stress response later on. Previous studies have highlighted the cyclical nature of physiology in response to stress. Heart rate variability traditionally used to estimate stress response has been found to follow cyclical patterns in lab settings~\cite{lamichhane2017towards,wilson2018couples}. Another study showed heart rate increases and stays high till the stress stimuli is present, but goes down to the pre-stress level soon it ends, creating a cyclical pattern. Beyond laboratory settings, a field study\cite{bari2020automated} involving couples observed similar cyclical patterns of arousal during stressful conversations. Their findings extended to other stress inducing events, such as work and commute. Median duration of cycles for stressful conversation, work and commute related stress were 3.5, 4.2 and 4.0 minutes, respectively. Additionally, their stressful conversation detection model, which utilized features from stress cycles during conversations, achieved a high F1-score of 0.83. Building on these insights, we segment the PPG time series of each participant into non-overlapping 4-minute windows. Our goal is to capture both micro and macro level perturbation dynamics of PPG effectively into a representation, which might be particularly useful for challenging tasks like stress detection.

% Out of 118 participants, we discard those participants who consistently rated the prompted episodes as either \emph{Probably Not Stressed} or \emph{Not Stressed}. After this filtering process, we are left with X participants. 


% which allows us to assess heart rate and heart rate variability, which are critical indicators of the body's stress response. By analyzing this raw data, we can gain insights into how stress affects physiological parameters. To account for the impact of physical activity on these stress episodes, we incorporate accelerometer (ACC) signals, which provide valuable information about the participants' movement patterns during the stress events.

% In our analysis, we focus on stress episodes that lasted between 4 and 30 minutes. This duration range is selected to ensure that we capture enough time for the physiological responses to manifest while excluding excessively long episodes that might not accurately reflect the stress response. To model the physiological responses to stress, we utilize raw photoplethysmography (PPG) data which  allows us to assess heart rate and heart rate variability, which are critical indicators of the body's stress response. By analyzing this raw data, we can gain insights into how stress affects physiological parameters. To account for the impact of physical activity on these stress episodes, we incorporate accelerometer (ACC) signals, which provide valuable information about the participants' movement patterns during the stress events.

% \subsection{Data Segmentation for Pre-training}
% Stress has an overall negative impact on individual wellness, making its automatic detection through AI-driven solutions a critical task. 
% To achieve this, it is crucial for a foundation model to sufficiently capture temporal patterns in PPG signal that can be effectively mapped to a stress response later on. Previous studies have highlighted the cyclical nature of physiology in response to stress. Heart rate variability traditionally used to estimate stress response has been found to follow cyclical patterns in lab settings~\cite{lamichhane2017towards,wilson2018couples}. Another study showed heart rate increases and stays high till the stress stimuli is present, but goes down to the pre-stress level soon it ends, creating a cyclical pattern. Beyond laboratory settings, a field study\cite{bari2020automated} involving couples observed similar cyclical patterns of arousal during stressful conversations. Their findings extended to other stress inducing events, such as work and commute. Median duration of cycles for stressful conversation, work and commute related stress were 3.5, 4.2 and 4.0 minutes, respectively. Additionally, their stressful conversation detection model, which utilized features from stress cycles during conversations, achieved a high F1-score of 0.83. Building on these insights, we segment the PPG time series of each participant into non-overlapping 4-minute windows. Our goal is to capture both micro and macro level perturbation dynamics of PPG effectively into a representation, which might be particularly useful for challenging tasks like stress detection.


% Metrics were selected following a prior report (Apple, 2021): mean squared error (MSE), std dev of
% squared error (SDSE), mean absolute error (MAE), std dev of absolute error (SDAE), and Pearson’s
% Correlation Coefficient. Mean and std devs were calculated by aggregating predictions across all
% inputs of a given user and are related to bias and variance respectively. Correlation is used in order
% to assess how each user’s average gait metric corresponds to ground truth values. Ranges for each
% metric were calculated by retraining the linear regression probe five times with different set seeds.
% Activity Classification: We evaluated activity classification performance using self-reported activity
% labels gathered from data in AHMS. We used a subset of data with ∼2k total users across 14
% workouts (full list in Table 2). The 14 selected workouts captured a range of diverse activities (e.g.
% kickboxing and rowing) that are non-trivial to separate (i.e. outdoor cycling vs. indoor cycling).
% For evaluation, workouts were class balanced so each included ∼22 hours of data, for a total of 310
% workout hours. We used a 4/1/5 train/val/test split based on participant ID.We ensured the subset of
% data used for classification did not overlap with the pre-training dataset, preventing any data leakage.
% Embeddings are generated for each 2.56s-long subsequence. We evaluate classification on both the
% subsequence-level as well as the workout-level. At the workout-level, we predict workout classes
% across each of 2.56s subsequences within the workout, and select the most frequently predicted
% workout. Including two prediction scales allow us to evaluate provides additional context about
% how information learned by the embedding interacts with time aggregation. We report F1, Kappa,
% Accuracy, and macro AUC metrics following previous work (Haresamudram et al., 2022; Yuan
% et al., 2024; Xu et al., 2024). Ranges per metric are obtained by retraining the probe five times and
% calculating the mean and standard deviation.
% 6


--------------------------------------------------------------------------------

\subsubsection{Robustness to the Noise of Real-World, mHealth PPG data:}

Due to the noise present in field settings, using morphological specific wavelet segment unlikely to do well. For example PaPaGei, does not do well. So how can do motif comparisons then? we can learn it with this idea....


wavelet-based aumgnetion methods would be unlikely to do well. 

However, unlike prior work, we show this works well for real-world mhealth ppg data



However, we do not use a filter. First we train a reconstruction function, as done in prior work. This reconstruction function learns how to do well, despite noise present in the data. This is because 

Our pre-training approach needs to invariant to noise. Therefore, we learn with noise augmentations.... 
Prior work showed that using motifs 

PPG in of itself is an understudied sensor with non-obvious information. We identify 

subtle features of the data.

prior work focuses on statistical features. however, foundaiton models are pwoerful, however how exactly can we learn a representation?

Field data is messy, how can we do something with messy data? statistical features cant work, we need something learnable...

we do some cleaning, but we can use motifs motifs are good even with messy data. learnable motifs!!

How can we identify positive relationships in our data? contrastive methods do not work
identify positive pairs with motifs

how cwe capture sublte nuances
relcon







Pre-training models on data collected in real-world settings involves several unique challenges. These arise from the intrinsic properties of time-series, the variability of field environments, and computational demands.
\begin{itemize}
    \item\textbf{Designing Effective Pretext Tasks:}
    Identifying a suitable pretext task for learning the underlying structure of physiological data captured via PPG is non-trivial. Unlike vision tasks, which leverage well-defined augmentations (e.g., cropping or flipping) by exploiting invariances that can withstand such modifications, devising a similar strategy for time-series is less straightforward. 

    \item\textbf{Distribution Preserving Augmentations:} In time-domain, augmentation strategies such as adding noise, jittering, scaling, rotating, shuffling, time-warping is performed~\cite{um2017data}. However, such approaches can lead to irreversible changes destroying the underlying data characteristics. For example, shuffling an ECG waveform destroys the temporal structure of the QRS complex, and scaling it can change the clinical diagnosis~\cite{nault2009clinical}. 

    \item\textbf{Determining Time Interval for Pattern Matching:} 
    Selecting an appropriate time interval for locating similar patterns in field data is nontrivial. Short interval may undermine pattern resemblance while large intervals may become computationally expensive for model training. 
    
    \item\textbf{Generalization and Representation Robustness:} While field data exposes the model to diverse conditions, it does not inherently guarantee generalizability. The representation space must be robust enough to capture within-person variability over time but at the same time accommodate inter-individual similarities. A fine grained representation ensures that when data from a new user arrives, the model can still make reasonable inferences, even in highly variable real-world scenarios.

    \item\textbf{Scalability and Computational Constraints:} Pre-training on high-frequency, longitudinal field data is computationally expensive. Scaling SSL models to such large datasets with significant variability requires balancing model size and performance. Ensuring that the model learns robust representations without becoming computationally infeasible or excessively large is a critical challenge.

    \item\textbf{Cross-Domain Generalizability:} Identifying a suitable data unit for pre-training a foundation model that can be leveraged across various mobile health applications—spanning both lab and field settings—is particularly challenging for psychological health tasks. Capturing representations that remain invariant to physical or mental health states while retaining sensitivity to task-specific nuances is difficult.  
    
\end{itemize}
 
\subsection{Leaned Similarity Measure in place of Augmentation}
A recent study~\cite{xurebar} introduced a novel approach for identifying positive pairs in time-series using a learned similarity measure, instead of relying on augmentations. The method conceptualizes time-series data as a sequence of subsequences, each associated with a class label. Real-world physiological signals often follow this structure; for example, accelerometry signals can include subsequences of walking or sitting, with smaller recurring temporal patterns, or "motifs," embedded within. Similarly, ppg might exhibit similar motifs in physiological arousal during stress events. This approach, called Retrieval-Based Reconstruction (REBAR), detects such motifs by using a reconstruction-based method where masked samples in one subsequence are reconstructed using values retrieved from another subsequence. A cross-attention model matches context windows between subsequences, achieving high reconstruction quality when motifs align.
REBAR cross-attention retrieval for a single masked out point $\bar{x}_q$ of a query sequence $\textbf{X}_q$ is: 
$$
\text{REBAR}(\bar{x}_q; \textbf{X}_k) = \sum_{\textbf{X}_k \in \textbf{X}_k} \frac{\exp\left(\text{sim}\left(f_q(\bar{x}_q), f_k(\textbf{X}_k)\right)\right)}{\sum_{\textbf{X}_k' \in \textbf{X}_k} \exp\left(\text{sim}\left(f_q(\bar{x}_q), f_k(\textbf{X}_k')\right)\right)} f_v(\textbf{X}_k)
$$
which identifies a region in $\textbf{X}_k$ for reconstruction via dilated convolution $f$. REBAR then uses the following distance function for computing the reconstruction error of a query (anchor) sequence $\bar{\textbf{X}_q}$ which has masked region/s:
$$
d(\textbf{X}_{\text{anchor}}, \textbf{X}_{\text{cand}}) := \lVert \text{REBAR}(\bar{X}_{\text{anchor}}, \textbf{X}_{\text{cand}}) - \textbf{X}_{\text{anchor}} \rVert_2^2
$$

We incorporate this approach into our pre-training framework for field PPG data to handle inherent noisiness and diversity in ppg signal. Information from vicinity of a masked sequence in the field can draw more meaningful insights from another likely sequence of similar context, thereby closely emulating the variability. A key consideration is therefore to decide on the length of of the masked sequence that can be successfully reconstructed without significant distortion. We used a sequence length of 6 seconds. 

\subsection{Pattern Retrieval within One Hour of Data for Similarity Measure}

To address the challenge of determining an appropriate time interval for pattern matching for learning similarity measure, we use a one-hour window for locating sequences with similar patterns in field-collected physiological data. This interval balances computational efficiency and the likelihood of finding meaningful matches. Physiological states, such as heart rate dynamics or stress responses, often exhibit stability or gradual transitions over shorter durations, making one hour a reasonable timeframe to identify close matches. Additionally, limiting retrieval to one hour reduces the computational overhead compared to searching across longer intervals, ensuring scalable model training while preserving the temporal relevance of the patterns.

\subsection{Relative Contrastive Learning for Representation Robustness}\label{sec:relative_contrastive_loss}
To address the challenge of generalization and representation robustness, we employ a relative contrastive learning framework designed to create fine-grained, semantically meaningful representations. While retrieval-based contrastive loss functions outperform benchmark SSL methods for downstream tasks, hard assignment of negative pairs can be less effective for field data, which includes a broad spectrum of natural variations. For example, in stress assessment, being stressed due to bad traffic differs from the experience of being tailgated, but the two are more similar compared to being engaged in a verbal conflict. Treating all negative instances equally ignores such subtle semantic differences and risks creating overly coarse representation clusters.

To address this, ~\cite{xu2024relcon} introduced the concept of relative dissimilarity via multiple negative sets. For each positive pairing, a negative set is created by selecting samples whose distance from the anchor exceeds the distance of the positive pair. Each candidate in the dataset is iteratively used to form a positive pair, while the remaining candidates contribute to the negative set:
\[
f_{\textrm{neg}}({X}_{\textrm{anc}}, {X}_{\textrm{pos}}, \mathcal{S}) = \{{X} \in \mathcal{S} \mid d({X}_{\textrm{anc}}, {X}) > d({X}_{\textrm{anc}}, {X}_{\textrm{pos}}) \}
\]
This concept is incorporated into the Relative Contrastive Loss (RelCon) framework, which builds representation spaces that are aware of relative distances and semantic nuances:
\[
\mathcal{L}_{\textrm{RelCon}} = \sum_{{X}_{\textrm{i}} \in \mathcal{S}_{\textrm{cand}}} \ell({X}_{\textrm{anc}},\ {X}_{\textrm{pos}} \coloneqq {X}_{\textrm{i}},\ \mathcal{S}_{\textrm{neg}} \coloneqq f_{\textrm{neg}}({X}_{\textrm{anc}}, {X}_{\textrm{i}}, \mathcal{S}_{\textrm{cand}}))
\]
By incorporating relative dissimilarity into contrastive learning, the model can form tight clusters within a representation space that reflects fine-grained relationships. This approach enhances the model's ability to generalize to unseen users by creating a representation space that captures nuanced relationships both within and across classes. By incorporating relative dissimilarity into the contrastive loss, the model learns to form tight clusters for similar patterns while preserving meaningful distinctions for subtle variations. This ensures that representations are not only robust to within-person variability but also adaptable enough to accommodate unseen physiological patterns in new individuals. As a result, the learned representations are better equipped to handle the high variability inherent in field data and provide reliable inferences for users whose data was not encountered during training.


\subsection{Efficient Pre-training on Large-Scale Field Data}




% \subsection{Similarity Measure and Relative Contrastive Learning}\label{sec:relative_contrastive_loss}
% Basic principle of self-supervised contrastive learning dictates entities with similar patterns to get closer in the embedding space as positive pairs. However, identifying positive pairs is nontrivial as it needs robust pattern matching to recognize the underlying compatibility despite variations. In computer vision, well defined augmentation techniques are used to create image variants with inherent invariances intact for constructing positive pairs. In contrast, invariances in time-series data are far less obvious. A recent approach---REBAR~\cite{xurebar} addressed this challenge with a learnable similarity measure instead of augmentation to identify positive pairs. In a naturally occurring lengthy time series, an identical sequence e.g. walking is likely to repeat. These recurring sequences can help reconstruct masked out portions of a time series, in effect, form positive pairs for contrastive learning. To retrieve the most suitable sequence out of several candidate sequences for reconstruction, REBAR first uses cross-attention to produce a weighted sum of the candidate sequence which is a condensed version of it. REBAR cross-attention retrieval for a single masked out point $\bar{x}_q$ of a query sequence $\textbf{X}_q$ is: 
% $$
% \text{REBAR}(\bar{x}_q; \textbf{X}_k) = \sum_{\textbf{X}_k \in \textbf{X}_k} \frac{\exp\left(\text{sim}\left(f_q(\bar{x}_q), f_k(\textbf{X}_k)\right)\right)}{\sum_{\textbf{X}_k' \in \textbf{X}_k} \exp\left(\text{sim}\left(f_q(\bar{x}_q), f_k(\textbf{X}_k')\right)\right)} f_v(\textbf{X}_k)
% $$
% which identifies a region in $\textbf{X}_k$ for reconstruction via dilated convolution $f$. REBAR then uses the following distance function for computing the reconstruction error of a query (anchor) sequence $\bar{\textbf{X}_q}$ which has masked region/s:
% $$
% d(\textbf{X}_{\text{anchor}}, \textbf{X}_{\text{cand}}) := \lVert \text{REBAR}(\bar{X}_{\text{anchor}}, \textbf{X}_{\text{cand}}) - \textbf{X}_{\text{anchor}} \rVert_2^2
% $$
% Once this class-discriminative similarity measure is learned, it is used for identifying positive pairs from within-time series and negative pairs from within- and between- time series. These positive and negative instances are used as labels for training the contrastive loss function. Although, the retrieval based contrastive loss function showed better performance than benchmark SSL methods for several downstream tasks, hard assignment of negative instances may be less effective for pre-training on a field dataset with wide range of subtle to crude natural variations. For example, in stress assessment, getting stressed due to bad traffic is different from being tailgated by someone but is less different than being engaged in a verbal conflict. Hence, utilization of relative dissimilarity can induce more semantically representative tight clusters. To address the limitation 
% ~\cite{xu2024relcon} introduced the concept of multiple negative sets. For a positive pairing, a function creates a negative set from sample candidates if their distances from the anchor are larger than the distance of the positive pairing. Each time one candidate is used to form a positive pairing and a new set of negatives from the rest of the sample candidates. The following equation outlines the creation of multiple negative sets:
% \[
% f_{\textrm{neg}}({X}_{\textrm{anc}}, {X}_{\textrm{pos}}, \mathcal{S}) = \{{X} \in \mathcal{S} \mid d({X}_{\textrm{anc}}, {X}) > d({X}_{\textrm{anc}}, {X}_{\textrm{pos}}) \}
% \]
% which is then incorporated into the below contrastive loss framework to build fine grained relative distance aware representation spaces.  
% \[
% \mathcal{L}_{\textrm{RelCon}} = \sum_{{X}_{\textrm{i}} \in \mathcal{S}_{\textrm{cand}}} \ell({X}_{\textrm{anc}},\ {X}_{\textrm{pos}} \coloneqq {X}_{\textrm{i}},\ \mathcal{S}_{\textrm{neg}} \coloneqq f_{\textrm{neg}}({X}_{\textrm{anc}}, {X}_{\textrm{i}}, \mathcal{S}_{\textrm{cand}}))
% \]
% It showed that relative contrastive loss based motion foundation model 
% performs better across multiple downstream tasks compared to other SSL approaches and foundation models. Most notably, it consistently yields better performance compared to~\cite{xurebar} although they use the exact learned distance function. 



% We would like to learn a foundation model that learns an embedding space that is generalizable across a variety of different datasets and tasks. Then, in order to do so, we need to design a pre-training task that is able to capture the most important features that capture obvious semantic information, but also subtle ones, so that we can uncover. There are many challenges to do, especially since for our PPG domain, the raw PPG in the real world and field data is full of messiness. PPG models blood volume, and we can see it directly to capture secret features, but statistical models handle this by normalizing missingness into statistics, but we lose information and limits the knowledge that the model can learn. We identify three key challenges that we address with our PPG-RelCon method: 1) messiness of real-world field mobile health PPG settings, 2) identifying a domain-specific pre-training task that exploits domain knowledge, 3) capturing subtle nuances in the data to have robsutness across settings 

% Our goal is to develop a foundation model capable of learning a generalizable embedding space that can be effectively applied to a diverse set of datasets (ranging from clinical PPG to mHealth field PPG) and downstream tasks (ranging from blood pressure prediction to stress detection). To achieve this, we must design a pre-training task that not only captures high-level, obvious semantic features—like heart rate and blood volume changes—but also uncovers subtle, latent patterns in the data, such as variations in pulse waveform morphology or transient physiological responses.

% This is particularly challenging in the PPG domain, where real-world field data is inherently noisy due to motion artifacts, ambient light interference, and skin condition variability \citep{xu2022pulseimpute}. 


% 1) the messiness of real-world, mobile health PPG data, which requires robust noise-handling mechanisms; 2) the development of a domain-specific pre-training task that leverages PPG-specific domain knowledge, such as the cyclical nature of cardiac signals and the relationship between pulse waveforms and physiological states; and 3) the ability to capture subtle, yet meaningful, patterns in the data—such as variations in pulse amplitude or waveform shape—that are essential for ensuring robustness across diverse and dynamic real-world settings.

% Note that this methodology is borrowed from prior work \citep{xurebar}, which shows a proof of concept idea in toy scenario across various physiological signals. Specifically, in each of the experiments, they pre-trained and evaluated on the same, small labeled dataset, rather than our foundation model approach, in which we pre-trained on one large, unlabeled and evaluated across a wide range of downstream tasks across multiple datasets. In addition to this, crucially, this prior work did not demonstrate performance on noisy field conditions. We iterate upon this idea to demonstrate its capability to handle real-world noisy conditions. 

% use a learnableour motif-based distance function
% How exactly this distance function is designed is critical to strong pre-training generalizability, especially because 


learned 