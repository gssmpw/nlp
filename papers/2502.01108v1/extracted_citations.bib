@article{abbaspourazad2023large,
  title={Large-scale training of foundation models for wearable biosignals},
  author={Abbaspourazad, Salar and Elachqar, Oussama and Miller, Andrew C and Emrani, Saba and Nallasamy, Udhyakumar and Shapiro, Ian},
  journal={arXiv preprint arXiv:2312.05409},
  year={2023}
}

@article{bommasani2021oppoandriskforfm,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{davies2024interpretable,
  title={Interpretable Pre-Trained Transformers for Heart Time-Series Data},
  author={Davies, Harry J and Monsen, James and Mandic, Danilo P},
  journal={arXiv preprint arXiv:2407.20775},
  year={2024}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{ding2024siamquality,
  title={SiamQuality: a ConvNet-based foundation model for photoplethysmography signals},
  author={Ding, Cheng and Guo, Zhicheng and Chen, Zhaoliang and Lee, Randall J and Rudin, Cynthia and Hu, Xiao},
  journal={Physiological Measurement},
  volume={45},
  number={8},
  pages={085004},
  year={2024},
  publisher={IOP Publishing}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@article{pillai2024papagei,
  title={PaPaGei: Open Foundation Models for Optical Physiological Signals},
  author={Pillai, Arvind and Spathis, Dimitris and Kawsar, Fahim and Malekzadeh, Mohammad},
  journal={arXiv preprint arXiv:2410.20542},
  year={2024}
}

@techreport{radford2018improving,
  author = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
  title = {Improving Language Understanding by Generative Pre-Training},
  year = {2018},
  institution = {OpenAI},
  note = {Technical Report},
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{yun2024unsupervised,
  title={Unsupervised representation learning on high-dimensional clinical data improves genomic discovery and prediction},
  author={Yun, Taedong and Cosentino, Justin and Behsaz, Babak and McCaw, Zachary R and Hill, Davin and Luben, Robert and Lai, Dongbing and Bates, John and Yang, Howard and Schwantes-An, Tae-Hwi and others},
  journal={Nature Genetics},
  volume={56},
  number={8},
  pages={1604--1613},
  year={2024},
  publisher={Nature Publishing Group US New York}
}

@article{zhang2024general,
  title={A general framework for generative self-supervised learning in non-invasive estimation of physiological parameters using photoplethysmography},
  author={Zhang, Zexing and Lu, Huimin and Ma, Songzhe and Peng, Jianzhong and Lin, Chenglin and Li, Niya and Dong, Bingwang},
  journal={Biomedical Signal Processing and Control},
  volume={98},
  pages={106788},
  year={2024},
  publisher={Elsevier}
}

@article{zhou2024comprehensive,
  title={A comprehensive survey on pretrained foundation models: A history from bert to chatgpt},
  author={Zhou, Ce and Li, Qian and Li, Chen and Yu, Jun and Liu, Yixin and Wang, Guangjing and Zhang, Kai and Ji, Cheng and Yan, Qiben and He, Lifang and others},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--65},
  year={2024},
  publisher={Springer}
}

