\section{Related Works}
\subsection{Foundation Models for PPG signals}

There have been some recent work on PPG-specific foundation models, but none of them are open and designed for wearable PPG signals (i.e., collected from a smartwatch). The closest work with open model availability is PaPaGei, an open-source PPG foundation model that improves classification and regression performance across 14 tasks____, including some  wearable lab tasks. However, it is exclusively trained on clean clinical PPG signals, and was not evaluated on field data in____. We show (Section \ref{sec:exppapagei}) that training on this clinical data negatively impacted its generalization performance on wearable tasks involving field-collected data. The most relevant work for wearable PPGs is a foundation model pre-trained on a large-scale wearable field PPG dataset and presented in____. However, the model is closed-source and its training datasets are private, restricting accessibility for the research community. Similalry, SiamQuality is a foundation model pre-trained on clinical data that demonstrates  generalizability on wearable lab and clinical datasets, but the model remains private ____. 

Additional related works addressed tasks and goals which are adjacent to this paper. 
REGLE employs autoencoders to extract disentangled embeddings from clinical PPGs, focusing on their applicability to genetic and disease prediction tasks ____. TS2TC introduces a generative self-supervised learning framework for clinical PPG data but does not provide pre-trained weights and has been evaluated exclusively on clinical PPG regression tasks ____. PPG-PT demonstrates the utility of pre-training, but does not meet all of the requirements of a foundation model, %%is not a foundation model that demonstrates generalizability, 
as the model was only evaluated on one clinical PPG-specific downstream task ____.


While these prior works have made significant strides in PPG representation learning, they either lack open-source accessibility, generalizability across tasks, or applicability to field-collected wearable data, highlighting a critical gap that our work aims to address. With the release of our foundation model's weights, ours will be the first open-source\footref{open} PPG model trained exclusively on field-collected data.

\subsection{Foundation Models in General}
Our work is inspired by prior successes in developing foundation models for other data modalities. These works have shown that models  pre-trained on large-scale datasets can capture underlying data representations and are highly adaptable for various downstream applications ____. These models have had substantial impact in fields like Natural Language Processing and Computer Vision. In the language domain, models such as BERT ____ and the Generative Pretrained Transformer (GPT) ____ have demonstrated remarkable generalizability across a diverse range of natural language processing tasks, catalyzing the development of large language models (i.e. ChatGPT ____). 
The vision domain has seen similar breakthroughs with models like CLIP ____ and the Segment Anything Model____ that are trained on large-scale data and exhibit strong performance on a broad set of downstream tasks. These works have demonstrated that pre-training on large-scale data can yield effective feature representations and serve as the motivation for this work.