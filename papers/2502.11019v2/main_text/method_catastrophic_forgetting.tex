

\section{Catastrophic forgetting of LLMs}
\label{sec3}

This section empirically examines
% evaluate catastrophic forgetting of multiple LLMs in several scenarios focusing on instruction tuning stage. Our investigation concentrates on 
the research question of \textit{{when forgetting occurs during continual instruction tuning}}, 
%Through empirical studies, we aim to uncover the unified rule behind the forgetting across 
specifically in relation to \textit{task types}, \textit{training stages} and \textit{language models}.


\textbf{Datasets.} We build the task sequences for continual instruction tuning using SuperNI~\citep{wang2022super},   a collection of NLP tasks with expert-written instructions that are unseen to the pre-trained model. SuperNI is commonly used for 
% TRACE~\citep{wang2023trace}, a set of diverse complex generation tasks. 
% SuperNI is commonly used in fine-tuning language models to test 
assessing cross-task generation and conflict after fine-tuning language models. 
% We leverage it to construct different sequences enabling the rigorous benchmarking of forgetting under various setting. 
To investigate the relationship between forgetting and task types, i.e., generation and classification, we design six task sequences.  These sequences consist of \textit{pure generation tasks}, \textit{pure classification tasks} and \textit{mixed sequences containing both generation and classification tasks}. 
% By observing and comparing the behaviors across learning different task sequences, we aim to figure out the correlation between the forgetting and the types of the learned tasks. 
Their main information are listed in Table~\ref{tab:sec3:data}, with additional details available in Appendix~\ref{app:dataset}.


% \begin{table*}[h]
% \begin{center}
% \begin{tiny}
% \begin{tabular}{l|lllll}
% \toprule
%  & Sequence & Task type & Num. per task  \\ \midrule
% NI-Seq-C1 & NI195 $\rightarrow$ NI1343 $\rightarrow$ NI1310 $\rightarrow$ NI1292 $\rightarrow$ NI363 & Classification & 1,000    \\
% % NI-Seq-C2 &  &  &  &  &  \\
% NI-Seq-G1 & NI618 $\rightarrow$ NI1290 $\rightarrow$ NI589 $\rightarrow$ NI511 $\rightarrow$ NI1357 & Generation & 1,000    \\
% % NI-Seq-G2 &  &  &  &  &  \\
% NI-Seq-M1 & NI360 $\rightarrow$ NI363 $\rightarrow$ NI1290 $\rightarrow$ NI339 $\rightarrow$ NI1510 & Classification \& Generation  & 1,000   \\
% % NI-Seq-M2 &  &  &  &  &  \\
% TRACE &  Cstance $\rightarrow$ Fomc $\rightarrow$ Meet $\rightarrow$ Py150 $\rightarrow$ SciQA $\rightarrow$ Numgluecm & Classification \& Generation & 3,000 \\ \bottomrule
% \end{tabular}
% \caption{Basic information of continual learning task sequences used in main text.}
% \label{tab:sec3:data}
% \vspace{-0.7em}
% \end{tiny}
% \end{center}
% \end{table*}
% TRACE~\citep{wang2023trace} is a public benchmark in continual learning for LLM which includes one learning sequence consists of multi-choice QA, code generation, mathematical reasoning and summary. We use it mainly for comparing different approaches.

\textbf{Evaluation metrics.} 
%To quantitatively evaluate the forgetting in different aspects, 
We adopt the following five metrics to quantify various aspects of forgetting:
(1) $\text{\textbf{GP}} = \frac{1}{N^g}\sum_{j=1}^{N^g} a^{T^e_j}_{N}$, which is the average zero-shot performance across $N^g$ general evaluation tasks after instruction tuning on the final $N$-th task. Here, $a^{q}_{m}$ denotes the zero-shot performance on task $q$ after sequentially tuning the $m$-th task, and $T^e_j$ refers to the $j$-th general evaluation task. Performance is uniformly measured using Rouge-L~\citep{lin2004rouge}, where classification accuracy equals to Rouge-L with output post-processing~\citep{zhao2024sapt}. We set $N^g=4$ general evaluation tasks, covering Hellaswag~\citep{zellers2019hellaswag}, CommonsenseQA~\citep{talmor2018commonsenseqa}, Alpaca~\citep{hendrycks2020measuring}, and BBH-Object-Count~\citep{srivastava2022beyond}, also applying to ~\ref{sec4} and extending to $N^g=6$ in Sec.~\ref{sec6}.
(2) $\text{\textbf{IP}} =\frac{1}{N^g}\sum_{j=1}^{N^g} \hat{a}^{T^e_j}_{N}$, which is the average in-context performance on $N^g$ general evaluation tasks after tuning on the last $N$-th task. The in-context performance, $\hat{a}^{q}_{m}$, is conditioned on the $n$-shot ICL input $[p,x]$, where $p=[(x_1, y_1), ..., (x_n, y_n)]$ with $n=5$ for this work.
(3) $\text{\textbf{FP}} = \frac{1}{N}\sum_{j=1}^{N} a^{T_j}_{N}$, which is the average zero-shot performance across all $N$ instruction tuning tasks after tuning on the final $N$-th task. $T_j$ represents the $j$-th instruction tuning task in the sequence.
(4) $\text{\textbf{AP}}=\frac{1}{N}\sum_{j=1}^N a_j^{T_j}$, which is the average zero-shot performance when learning every $j$-th instruction tuning task.
(5) $\text{\textbf{Forget}}=\text{\textbf{AP}}-\text{\textbf{FP}}$, which has been widely adopted~\cite{wu2022pretrained, ke2023continual} to measure forgetting.
% that measures 
% utilize the average zero-shot general performance $\text{\textbf{GP}} = \frac{1}{n}\sum_{i=1}^{n} a^{h_i}_{T}$ to measure the shift of LLMs' general capabilities, average in-content general performance $\text{\textbf{IP}} =\frac{1}{n}\sum_{i=1}^{n} \hat{a}^{h_i}_{T}$ to evaluate forgetting in reasoning abilities, and final trained performance $\text{\textbf{FP}} = \frac{1}{T}\sum_{i=1}^{T} a^{t_i}_{T}$ to assess catastrophic forgetting on newly learned abilities. 
% Here, $a^{m}_{n}$ represents the zero-shot evaluation score on the evaluation task $m$ after sequentially learning the $n$-th task. $h_i$ and $t_i$ denotes the $i$-th general evaluation set and $i$-th training task, respectively. $\hat{a}$ denotes the in-context evaluation score, computing on the output of n-shot ICL input $[p,x]$, where $p=[(x_1, y_1), ..., (x_n, y_n)]$ and n is set to 10 in this paper.
% Additionally, we use the adaptive performance $\text{\textbf{AP}}=\frac{1}{T}\sum_{i=1}^T a_i^{t_i}$ to measure the plasticity of fine-tuned model and the difference between the adaptive performance and the final trained performance $\text{\textbf{Forget}}=\text{\textbf{AP}}-\text{\textbf{FP}}$ to measure the ability to avoid forgetting. 
% In this paper, we use Rouge-L~\citep{lin2004rouge} for evaluation on all tasks, while classification accuracy is equals to Rouge-L with output post-processing~\cite{zhao2024sapt}.
% As for the general evaluation datasets, we utilize Hellaswag~\citep{zellers2019hellaswag}, CommonsenseQA~\citep{talmor2018commonsenseqa}, Alpaca~\citep{hendrycks2020measuring}, and BBH-Object-Count~\citep{srivastava2022beyond} in Sec.~\ref{sec3} and ~\ref{sec4} for analysing. In Sec.~\ref{sec6}, we enlarge the evaluation set size to 6. 
More detailed information about the datasets and evaluation metrics is presented in Appendix~\ref{app:dataset}. 


\textbf{Instruction tuning setup.} For each task in the sequence, we continually fine-tune four language models, including Llama2-7b-chat, Llama2-13B-chat~\citep{touvron2023llama}, Llama3-8B-chat~\citep{dubey2024llama}, Mistral-7B-instruct-v2.0~\citep{jiang2023mistral} using the causal language model loss~\citep{radford2019language}. % reference? (Zhaoyi)
Unless otherwise noted, we use the LoRA fine-tuning approach~\citep{hu2021lora}, employing the Adam optimizer with a learning rate of $1e^{-4}$ and a batch size  of 32. Additional implementation details can be found in the Appendix~\ref{app:implement}.


\begin{table*}[!t]
% \vspace{-1.8em}
\begin{center}
% \begin{scriptsize}
\begin{tiny}
\begin{tabular}{l|llllr|llllr|lll}
\toprule
 & \multicolumn{5}{c|}{Zero-Shot Performance in General Task} & \multicolumn{5}{c|}{In-Context Performance in General Task} & \multicolumn{3}{c}{Performance in Trained Task} \\ \midrule
 & Hella. & Com. & Alpa. & Ob. & \textbf{GP} $\uparrow$/$\Delta$ $\uparrow$ & Hella. & Com. & Alpa. & Ob. & \textbf{IP} $\uparrow$/$\Delta$ $\uparrow$ & \textbf{AP} $\uparrow$ & \textbf{FP} $\uparrow$ & \textbf{Forget}  $\downarrow$\\ \midrule
  \multicolumn{14}{c}{\textbf{Llama2-7b-chat}} \\ \midrule
$M_0$ & 57.89 & 57.37 & 26.5 & 27.12 &  \multicolumn{1}{l|}{\textbf{42.22}} & 58.95 & 57.89 & 35.17 & 34.21 & \multicolumn{1}{l|}{\textbf{46.55}} & / & / & / \\
NI-Seq-C1 & 47.37 & 40.00 & 32.00 & 31.61 & \color{red}{\textbf{-4.48}} & 24.21 & 27.89 & 28.89 & 26.84 & \color{red}{\textbf{-19.60}} & 86.10 & 83.80 & \color{red}{\textbf{2.30}} \\
NI-Seq-G1 & 48.95 & 39.47 & 27.36 & 39.72 & \color{red}{\textbf{-3.35}} & 37.89 & 42.63 & 28.84 & 38.95 & \color{red}{\textbf{-9.48}} & 24.96 & 19.35 & \color{red}{\textbf{5.61}} \\
NI-Seq-M1 & 52.11 & 42.63 & 31.09 & 29.51 & \color{red}{\textbf{-3.39}} & 45.79 & 31.05 & 24.58 & 33.16 & \color{red}{\textbf{-12.91}} & 59.02 & 54.32 & \color{red}{\textbf{4.69}} \\ \midrule
\multicolumn{14}{c}{\textbf{Llama3-8b-chat}} \\ \midrule

$M_0$ & 81.58 & 58.42 & 22.64 & 40.04 & \multicolumn{1}{l|}{\textbf{50.67}} & 85.26 & 63.16 & 27.42 & 49.47 & \multicolumn{1}{l|}{\textbf{56.32}} & / & / & / \\
NI-Seq-C1 & 79.47 & 46.84 & 23.27 & 32.32 & \color{red}{\textbf{-5.20}} & 79.47 & 40.00 & 25.62 & 45.79 & \color{red}{\textbf{-8.60}} & 83.40 & 82.10 & \color{red}{\textbf{1.30}} \\
NI-Seq-G1 & 72.63 & 35.79 & 22.05 & 29.39 & \color{red}{\textbf{--10.70}} & 67.89 & 31.05 & 19.77 & 41.58 & \color{red}{\textbf{-16.26}} & 28.29 & 21.09 & \color{red}{\textbf{7.19}} \\
NI-Seq-M1 & 78.42 & 40.00 & 21.93 & 21.58 & \color{red}{\textbf{-10.19}} & 76.84 & 40.00 & 21.32 & 35.91 & \color{red}{\textbf{-12.81}} & 60.74 & 52.62 & \color{red}{\textbf{8.11}} \\ \midrule
 \multicolumn{14}{c}{\textbf{Mistral-7b-instruct}} \\ \midrule
				
$M_0$ & 73.68 & 60 & 24.74 & 5.02 & \multicolumn{1}{l|}{\textbf{40.86}} & 79.47 & 66.32 & 32.36 & 37.89 & \multicolumn{1}{l|}{\textbf{54.01}} & / & / & / \\
NI-Seq-C1 & 63.16 & 50.00 & 32.04 & 15.3 & \color{red}{\textbf{-0.75}} & 66.84 & 51.05 & 36.8 & 37.89 & \color{red}{\textbf{-5.87}} & 84.70 & 85.40 & \color{red}{\textbf{-0.70}} \\
NI-Seq-G1 & 57.37 & 45.26 & 26.3 & 13.81 & \color{red}{\textbf{ -5.18}} & 57.89 & 35.79 & 32.04 & 39.47 & \color{red}{\textbf{-12.71}} & 27.62 & 19.77 & \color{red}{\textbf{7.85}} \\
NI-Seq-M1 & 65.26 & 47.89 & 33.02 & 12.35 & \color{red}{\textbf{-1.23}} & 63.68 & 38.42 & 34.79 & 45.79 & \color{red}{\textbf{-8.34}} & 61.96 & 57.00 & \color{red}{\textbf{4.95}} \\ \midrule 
 \multicolumn{14}{c}{\textbf{Llama2-13b-chat}} \\ \midrule
$M_0$ & 69.47 & 51.05 & 28.99 & 15.09 & \multicolumn{1}{l|}{\textbf{41.15}} & 75.26 & 57.89 & 35.46 & 43.16 & \multicolumn{1}{l|}{\textbf{52.94}} & / & / & / \\
NI-Seq-C1 & 65.79 & 52.63 & 34.18 & 21.51 & \color{red}{\textbf{+2.38}} & 66.32 & 48.42 & 38.48 & 38.95 & \color{red}{\textbf{-4.90}} & 83.20 & 82.26 & \color{red}{\textbf{0.93}} \\
NI-Seq-G1 & 63.16 & 38.95 & 28.12 & 13.84 & \color{red}{\textbf{-5.13}}& 65.79 & 32.11 & 30.92 & 34.21 & \color{red}{\textbf{-12.18}} & 25.64 & 18.16 & \color{red}{\textbf{7.47}} \\
NI-Seq-M1 & 71.58 & 49.47 & 34.10 & 28.09 & \color{red}{\textbf{+4.66}} & 70.53 & 48.42 & 36.51 & 37.37 &\color{red}{\textbf{-4.73}} & 60.10 & 56.33 & \color{red}{\textbf{3.76}} \\ \bottomrule
% \midrule
%   \multicolumn{14}{c}{\textbf{Llama2-chat-70b}} \\ \midrule
% Initial &  \\
% Seq.C &  \\
% Seq.G & \\
% Seq.M &   \\ 

\end{tabular}
% \vspace{-0.6em}
\caption{Final performance on 3 SuperNI benchmarks on 4 language models. Hella., Com., Alpa., and Ob. denote evaluation score on Hellswag, CommonsenseQA, Alpaca, Object Count datasets, respectively. The $\Delta$ value in red bold style is compared to performance of their initial model $M_0$. Higher \textbf{Forget} or lower $\Delta$ represent more forgetting. \textit{\textbf{Main conclusion: }Forgetting consistently occurs in both general and newly learned tasks, showing considerable variations depending on the types of tasks, stages of training, and the specific language models involved.}}
\vspace{-2.7em}
\label{tab:sec3:main}
\end{tiny}
% \end{scriptsize}
\end{center}
\end{table*}

% \subsection{Empirical Results}
We report the results on continual learning of four language models on three SuperNI sequences in Table~\ref{tab:sec3:main}, highlighting that forgetting occurs across general ability, in-context learning ability, and fine-tuned ability. 
Higher scores for general and in-context abilities signify better mitigation to forgetting. For fine-tuned ability, we report the values of \textbf{AP}, \textbf{FP} and their difference \textbf{Forget}, where a lower \textbf{Forget} value indicates less forgetting. A detailed breakdown of the results for the other three SuperNI sequences is provided in Appendix~\ref{app:more_seq}.
Figure~\ref{fig:sec3:heat} illustrates the forgetting of the Llama2-7b and Llama3-8b models during continual learning on NI-seq-C1 and NI-seq-G1. The vertical axis signifies the training stage, where M$i$ denotes the model after completing the $i$-th task. The horizontal axis displays test performance across tasks, with the performance of $M$0 (without continual instruction tuning) shown at the top. The heatmaps show the relative shifts in performance compared to $M$0,
%shown in the heatmaps are indicative of performance shifts, 
with declines indicated by bluer values and improvements by redder colors.

From Table~\ref{tab:sec3:main} and Fig.~\ref{fig:sec3:heat}, we observe two major trends: (1) consistent forgetting of LLMs across both general and newly acquired tasks, irrespective of the task sequence type, and (2) considerable variability in forgetting across evaluation tasks -- e.g., Hellaswag appeals to be more prone to forgetting than Alpaca.
Beyond these general findings, we further investigate how forgetting is influenced by task types, training stages, and the specific language models employed. 


% The results reveal a consistent presence of the forgetting effect of LLMs across both general and newly acquired tasks throughout continual instruction tuning. Detailed analysis are presented as follow:


\begin{figure*}[t!]
  \centering
  \includegraphics[width=1.\linewidth]{pdf_figs/sec3_1_heat.pdf}
  \vspace{-1.0em}
  \caption{Performance heatmap during continual learning of 2 different sequences on Llama2-7b-chat and Llama3-8b-chat. The numbers above the heatmap indicate the baseline performance of each task, with the performance of the pre-trained model for general testing (e.g., in a-(II) 66.3 is the score of Commonsense on original Llama2-7b-chat) and performance right after completing current task for trained task testing (e.g., in a-(I) 28.2 is the score of T2 on Llama2-7b-chat post 2-th task training). The numbers on the heatmap show the percentage change relative to the baseline (e.g., in a-(I) first column 47 indicates the score at 38.6*47\%).  \textit{\textbf{Main conclusion:} (1) Learning generation tasks (a/c) vs. classification tasks (b/d) lead to more forgetting.; (2) Forgetting may reduce naturally (a-(II)/d-(II)); (3) Forgetting is model-dependent (a/b vs. c/d).}}
  \label{fig:sec3:heat}
  \vspace{-0.6em}
\end{figure*}


\textbf{Task type perspective: generation task sequences lead to greater forgetting.} 
% By looking into Table~\ref{tab:sec3:main} and Fig.~\ref{fig:sec3:heat}, we observe consistent forgetting across all types of sequences and considerable variability across evaluation tasks -- it seems easier to forget Hellaswag compared to Alpaca.
% Still, 
Upon analyzing the performance of NI-Seq-C1 (classification tasks) and NI-Seq-G1 (generation tasks) in Table~\ref{tab:sec3:main}, we observe a noticeable increase in forgetting when learning generation task sequences. For instance, the Llama3-8b-chat model shows larger performance declines with NI-Seq-G1 (10.7, 16.2, and 7.2 in general, in-context, and trained tasks, respectively) compared to NI-Seq-C1 (5.2, 8.6, and 1.3 declines). 
Additionally, the forgetting score \textbf{Forget}
% Comment by Zhaoyi: "forgetting rate" here needs to be defined.
of all models over all tasks in the NI-Seq-C1 sequence is below 2.3, suggesting a stronger ability to mitigate forgetting for LLMs than small language  models~\citep{qin2022lfpt,razdaibiedina2023progressive}. 
% On the contrary, % Comment by Zhaoyi: "However" here seems a little bit strange.
% the forgetting results show a considerable variability across different evaluation tasks. For example, the performance on Alpaca remains consistent compare to Hellaswag in Fig.~\ref{fig:sec3:heat}.
% Furthermore, our observations reveal considerable variability in forgetting across different tasks. For example, the performance on Alpaca remains consistent compare to the Hellaswag in Fig.~\ref{fig:sec3:heat}.
% These call for advanced analytical tools capable of dissecting the intricate forgetting of model under various settings, 
% revealing how different tasks impact LLMs' acquired ability with different effect. 
We further evaluate LLMs with more sequences, obtaining similar observations as shown in Appendix~\ref{app:more_seq}.


\textbf{Training stage perspective: forgetting may naturally mitigate during training.} Figure~\ref{fig:sec3:heat} illustrates the extent of forgetting at each training phase across various evaluation datasets. Contrary to the nearly consistent performance drop seen in previous studies~\citep{luo2024empirical, wu2022pretrained}, we frequently observe a phenomenon where performance initially decreases but later rebounds. For instance, the fourth column of \textbf{(a)-(II)} shows the “Ob.” test score dropping to 67\% on the M2 model; however, after two stages, the performance leaps to 122\%. 
% At the same time, the learning tasks of the following two stages show less similarity with the test data, which should not result in task transfer according to~\citep{}. 
% However, in these two continual training stages, the distributions of the training task data and the testing data are clearly discrepant, which is not supposed to result in positive knowledge transfer according to the traditional understanding of continual learning works~\citep{}.
This contradiction further raises further questions about how sequential fine-tuning on new tasks impacts the internal capabilities of LLMs, allowing them to recover previously forgotten capabilities.
% This non-trivial observation challenges our understanding of the internal workings of forgetting, questioning how learning affects the model's computational structure. % computational structure also seems a little bit vague. commented by Zhaoyi.



\textbf{Model perspective: forgetting is model-dependent.} We compare forgetting between LLMs;
%, as shown in Fig.~\ref{fig:sec3:heat} (a) and (c). 
specifically, for the “Ob.” task performance shown in \textbf{(a)-(II)} and \textbf{(c)-(II)}, continual instruction tuning of Llama2-7b-chat demonstrates a performance increase of up to 146\% relative to using the Llama2-7b-chat itself, while that of Llama3-7b-chat shows a decrease to 73\%. 
% This showcase that forgetting is not only task-related across different models; it is a model-dependent effect influenced by various factors such as model size, architecture, and the diversity of the data used for pre-training. 
This suggestš that forgetting is not only task-related but also heavily influenced by model-dependent factors such as model size, architecture, and the diversity of pre-training data.
These factors shape each model's unique capacity to tasks, revealing that the mere feature similarity between tasks (e.g., hidden states in the last layer) is insufficient to predict model-dependent forgetting patterns (see Appendix~\ref{app:hidden_sim}).
% These call for advanced analytical tools capable of dissecting the intricate forgetting of model under various settings, 