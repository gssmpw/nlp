\section{Conclusion}

In this study, we tackle the issue of catastrophic forgetting in Large Language Models (LLMs) via a detailed investigation using the Function Vector (FV) approach, highlighting its pivotal role in characterizing and mitigating forgetting phenomena. Our analysis across a vast array of benchmarks reveals that model forgetting is intricately linked to shifts in latent concept variables (characterized by function vector), facilitated by our novel function vector-guided training strategy. This method, integrating a regularization term with a function vector-guided Kullback-Leibler divergence loss, significantly curtails forgetting, thereby enhancing both general and in-context learning capabilities of LLMs in continual learning settings.

% Our contributions illuminate the underlying mechanisms of forgetting and introduce a robust strategy to combat it, opening a new direction to study forgetting via tracable internal task function.




% In our research, we introduce the concept of the Instruction Vector (IV), which serves as a framework for extracting representations closely associated with the task processing capabilities of Large Language Models (LLMs), enabling detailed analysis into the model's inherent behavior. 
% By analyzing IV dynamics before and after training, we demonstrate that forgetting is due to the overlay of newly acquired, specialized reasoning patterns over pre-existing skills and the performance can be recover through empirically add the Instruction Vector in the computation graph.
% Furthermore, we propose IV-guided training as a novel fine-tuning method to successfully reduce forgetting by maintaining the model's computation graph in harmony with the IV. 
% Our findings provide valuable insights into the internal mechanisms causing forgetting in LLMs. We believe that our research will contribute to advancing the development and application of LLMs alignment.