
% Summary of the results
We introduce $\ours$, an AI-based 3D spatial transcriptomics (ST) prediction framework based on non-destructive 3D tissue images. 
With emerging 3D ST technologies, through \textit{in-situ} sequencing\cite{wang2018three, wang2021easi, fang2024three, sui2024scalable} or aligning serial sections with 2D ST measurements\cite{vickovic2022three, zeira2022alignment, zhou2023integrating,wang2023construction, lin2023multiplexed, schott2024open}, there are significant hurdles due to cost and limited coverage volume. $\ours$ provides a cost-effective and rapid alternative by leveraging the ability of deep learning models to learn fine-grained morphological correlates of gene expression, or \textit{morphomolecular links}.
Training $\ours$ on a collection of morphology and 2D ST data pairs from the same disease/tissue type results in a 3D ST prediction model that generalizes across unseen samples (3D CRC, \textbf{Extended Data Figure~\ref{fig:breast_crc}G}). This suggests that generic morphomolecular links, which are conserved across diverse patients, can be captured with sufficient training data. 
Additionally, fine-tuning the pretrained model on ST measurements of a few tissue sections from a volume of interest (VOI) further enhances the performance by integrating sample-specific morphomolecular links.
While the primary focus of $\ours$ is on non-destructive 3D tissue images, we demonstrate the model's flexibility in handling serial 2D tissue sections, a common approach for obtaining pseudo-3D ST.
Furthermore, leveraging the aligned morphological and transcriptomic embedding space from contrastively trained image and transcriptomics encoders, $\ours$ can retrieve corresponding morphological regions for custom molecular query, hinting at potential biomarker exploration tasks.

% How VORTEX is a paradigm-shifter
$\ours$ presents a scalable paradigm for 3D molecular analyses, building on the latest advances in deep learning. Current 3D ST computational approaches align and integrate ST measurements from multiple tissue sections within the same volume, without relying on the underlying tissue morphology\cite{zeira2022alignment, zhou2023integrating, wang2023construction,mo2024tumour, schott2024open, tang2024search}.
Consequently, each volume requires abundant ST measurements spread across multiple sections within each volume, and the model must be trained separately for each sample.
This prevents the reuse of shared disease- or organ-specific molecular traits across the samples, even within the same disease or organ cohort, confining the 3D molecular analysis to a relatively small number of samples due to financial and time constraints. 
In this context, $\ours$ enables the integration and reuse of morphomolecular traits both \textit{across} and \textit{within} the samples, leveraging 3D tissue morphology as the common binding factor. The model can then match and integrate morphological characteristics across different imaging modalities and dimensions (e.g., 3D imaging modality and 2D H\&E) and learn the correspondence between such morphological characteristics and transcriptomics expression commonly shared or specific to each sample. This allows $\ours$ to easily scale and generalize to other samples of similar disease profiles of any physical size.
Finally, the predictive performance is expected to further increase with continued developments in computational pathology\cite{jaume2024hest, chen2024towards, zimmermann2024virchow, campanella2024clinical} and single-cell foundation models\cite{cui2024scgpt, hao2024large}, on top of increasing availability for ST-morphology data pairs.

A limitation of the study is the relatively coarse resolution of microCT and Visium, which is insufficient for achieving single-cell resolution. With advances in non-destructive tissue 3D imaging and the increasing availability of single-cell sequencing data paired with high-resolution morphology data, we expect the resolution constraint to be temporary. On the imaging front, the next-generation microCT\cite{frohn20203d, walsh2021imaging,palermo2025investigating} and other 3D imaging modalities such as open-top light-sheet microscopy\cite{glaser2017light, bishop2024end} and holotomography\cite{kim2024holotomography}, have shown promise in capturing morphological details at the cellular level. Furthermore, increasing the availability of paired morphology and single-cell sequencing data through concerted efforts\cite{jaume2024hest, chen2024stimagekm} will provide sufficient data for $\ours$ training. Combined with emerging works showing that single-cell gene expression can be reliably predicted from histomorphology\cite{comiter2023inference, chadoutaud2024scellst, zhang2024inferring}, we expect $\ours$ to easily extend to 3D ST prediction at the single-cell level.
In conclusion, $\ours$ paves the way for a scalable approach to 3D ST prediction. 
We envision $\ours$ to assist clinicians and biomedical researchers in the 3D multimodal analysis of tissue at a large scale towards novel biomarker exploration.