
\hheading{AI-based 3D ST prediction with $\ours$}

$\ours$ is a deep learning model that enables 3D ST prediction for 3D tissue images captured with high-resolution non-destructive 3D pathology modalities\cite{liu2021harnessing, song2024analysis, wang20243d}, which are anticipated to become more common as a complementary approach to serial tissue sectioning\cite{kiemen2022coda, braxton20243d}. Non-destructive imaging preserves tissues for downstream assays, thereby facilitating morphomolecular analyses \cite{bishop2024end, li2023feasibility}.
Upon modeling the link between 3D tissue morphology and corresponding spatially resolved gene expression profiles in local 3D regions (or patches), $\ours$ processes each 2D section of the test volume (or volume of interest, VOI), and its neighboring sections together to provide 2D ST predictions for all sections. This stack of predicted 2D ST images constitutes a 3D ST prediction for thick tissue specimens, accommodating any tissue volume size.
The 2D ST measurements are obtained with the Visium platform\cite{staahl2016visualization, rao2021exploring}, which captures aggregate gene expression profiles from several neighboring cells for each sequencing spot (55-micron spot size). Small 2D or 3D tissue image patches centered around each sequencing spot represent the localized tissue morphology, providing the morphology and transcriptomics data pairs that $\ours$ operates on.


\begin{figure*}
\centering %main.png
\includegraphics[width=\textwidth]{figures/Fig1_VORTEX.pdf}
\caption{\textbf{Overview of $\ours$}. 
\textbf{(a)} Workflow of 3D ST prediction with $\ours$ on a test volume (or volume of interest, VOI). $\ours$ provides efficient whole volume 3D ST prediction for gene sets of interest based on the 3D tissue images and ST measurements. A 3D tissue image is obtained with a non-destructive 3D imaging modality (microCT chosen as an illustrative example). ST is performed on a few 2D tissue sections from the same tissue volume (Visium chosen as an illustrative example).  $\ours$ is trained over two stages. It is first pretrained on a disease-specific cohort of 2D (or 3D) tissue images and 2D ST data pairs. It is further fine-tuned on data pairs of 2D (or 3D) tissue images and 2D ST acquired from the VOI. $\ours$ can also be extended to 2.5D tissue images comprised of serial tissue sections.
\textbf{(b)} Illustration of $\ours$ architecture. All deep learning components of $\ours$ are trained with a combination of \textit{ST reconstruction} and \textit{cross-modal alignment} loss. The green arrows indicate the prediction workflow of $\ours$ once trained.
\textbf{(c)} Applications for $\ours$ on efficient large 3D ST prediction, joint morphology and ST analysis, and 3D morphology query. ST: Spatial transcriptomics. Morph. Seg.: Morphological segmentation.
}
\label{fig:main}
\end{figure*} 

The predictive capacity of $\ours$ is further enhanced by fine-tuning the model on 2D ST captured from tissue sections within the VOI. While the model input is still the same 3D tissue image, the ST prediction stage can benefit from the incorporation of subtle volume-specific attributes (\textbf{Figure~\ref{fig:main}A}). 
The structure of $\ours$ offers two avenues for data scaling. First, scaling the training dataset to include different tissue volumes of the same disease or tissue type increases the training data scale and the statistical power of transcriptomics analyses\cite{stuart2019comprehensive, korsunsky2019fast}. This also helps $\ours$ extract generic morphomolecular signatures for relevant tissue types that are preserved across heterogeneous examples of a tissue type/disease of interest. Next, incorporating the 3D morphological context and 2D ST measurements from a VOI through a principled model-based approach increases the predictive performance. To facilitate concurrent analysis for correspondence between the distinct tissue morphologies and spatial transcriptomic expression patterns, we also provide an efficient AI-based 3D morphological segmentation mask constructed from annotations on 2D tissue sections\cite{kirillov2023segment}.
 
To ensure good predictive performance, we first pretrain $\ours$ on 2D hematoxylin and eosin (H\&E) tissue sections and 2D ST data pairs. This step allows the model to accurately learn the relationship between transcriptomic expression and its 2D morphological correlates, which forms the basis for 3D ST prediction. $\ours$ is composed of four main components, the 2D and 3D \textit{image encoders} for extracting low-dimensional embedding of 2D and 3D image patches, the \textit{transcriptomics encoder} for extracting low-dimensional embedding of ST, as well as the \textit{transcriptomics predictor} for predicting ST from patch embeddings (\textbf{Figure~\ref{fig:main}B}).
To extract representative histology patch and transcriptomics embeddings, the image and transcriptomic encoders are initialized with a pathology foundation model CONCH\cite{lu2024visual} (pretrained on millions of histology image and text pairs) and a single-cell foundation model (scGPT)\cite{cui2024scgpt} (pretrained on single-cell transcriptomics data from millions of cells of various cancer types), respectively. The entire model is trained in a multi-task setting, combining the contrastive loss to align the image and transcriptomic embeddings and the reconstruction loss to predict ST from the image embedding\cite{yu2022coca}.
Once pretrained, $\ours$ is extended to integrate the 3D morphological context, by employing a lightweight module on top of the image encoder to aggregate neighboring tissue regions at different depths. Further details on the model architecture can be found in \textbf{Online Methods} section \textbf{Model Architecture}.

%% Difference between existing 3D-ST works
$\ours$ presents a fundamentally different mechanism for 3D ST prediction from other frameworks. Specifically, existing works meticulously align multiple 2D tissue sections with 2D ST measurements from the same volume to construct a 2.5D ST heatmap\cite{dong2022deciphering, zeira2022alignment, zhou2023integrating,wang2023construction, tang2024search, shu2024efficient,li2024high, lin2024bridging}.
Consequently, obtaining a 3D or 2.5D ST profile of a sample still results in high costs and turnaround time from having to sequence a large number of tissue sections. Moreover, these approaches do not have extrapolation capacity across the plane, restricting the predicted ST coverage to within the ST planar capture area. In contrast, $\ours$ operates on continuous 3D tissue morphology as input, based on the underlying morphomolecular links learned by the models. $\ours$ can provide 3D ST for each volume with orders of magnitude less cost and time because it requires significantly fewer ST measurements from a VOI for fine-tuning. Here we show that fine-tuning the model on a single 2D ST capture area from the VOI can help predict the ST profile for any other tissue regions outside the capture area, across the plane and at varying depths. Consequently, $\ours$ can operate on tissue volumes of any size (\textbf{Figure~\ref{fig:main}C}). 

\hheading{3D ST prediction for prostate cancer}

% Registration between H\&E and microCT
To evaluate the performance of $\ours$ on clinical tissue specimens, we apply the model to 3D ST prediction of prostate cancer volumes.
We use microCT\cite{withers2021x, palermo2025investigating} with an isotropic resolution of $4~\mu m$/voxel to acquire 3D high-resolution images for 11 tissue volumes from 11 different patients from Mass General Brigham, with each image covering $7 \times 11 \times 3\, mm^3$ field-of-view. After imaging each volume with microCT, we obtain both Visium ST and H\&E tissue images from those volumes.  For five of the volumes, we obtained two pairs of tissue sections spaced apart by 250~$\mu m$.  For the other six volumes, we obtained a single section each, resulting in a total of 16 sections and 65,715 training pairs (morphology patch with corresponding 2D ST spot) (\textbf{Figure~\ref{fig:main}A}). We additionally curated a public dataset of 2D H\&E sections with corresponding 2D Visium and Spatial Transcriptomics ST data from various studies, encompassing 49 sections (72,832 spots).
The data integration shows that $\ours$ can bridge the modality gaps between 2D ST, 2D H\&E tissue images, and 3D tissue images. 
Additionally, it shows the scale of data that typical 3D non-destructive tissue imaging modalities produce (typically on the order of several hundred 2D image sections) can be handled by $\ours$\cite{song2024analysis, coleman2024unlocking, erturk2024deep}. Further details on the prostate cancer dataset can be found in \textbf{Extended Data Table~\ref{tab:dataset}} and \textbf{Online Methods} in section \textbf{Datasets}.

As the first preprocessing step for $\ours$, we perform cross-modal registration between 2D and 3D tissue images. While the 2D ST measurements are spatially registered to 2D H\&E tissue sections by default, registering the sectioned images to the microCT tissue volume is often non-trivial.
We use landmark-based registration pipelines\cite{bay2006surf, fischler1981random, gatenbee2023virtual,chicherova2014histology} to estimate the depth and the angle at which tissue sections were cut from the tissue volume. Using the estimated parameters, we register 2D tissue image and the ST sequencing spots onto the tissue volume (\textbf{Figure~\ref{fig:prostate}A}).
As a result, all 16 tissue sections with 2D ST measurements are registered to respective tissue volumes.
We then create a 2D H\&E patch of $112\times112~\mu m$ ($112\times 112$ pixels) and a 3D microCT patch of $448\times 448 \times 84~\mu m$ ($112 \times 112 \times 21$ pixels), centered around each ST spot as the corresponding 2D and 3D morphological context. The depth of the 3D patch ensures that large benign prostatic glands are covered. Further details on cross-modal registration and data preprocessing can be found in \textbf{Online Methods} in section \textbf{3D image data preprocessing}.

\begin{figure*}[]
\centering
\includegraphics[width=\textwidth]{figures/Fig2_PROSTATE.pdf}
\caption{\textbf{$\ours$ analysis on prostate cancer}. 
\textbf{(a)} Cross-modal registration between the 3D microCT tissue image (4$\mu m$/voxel) and the H\&E-stained tissue sections with 2D ST.
Checkerboard visualization of co-registered microCT and H\&E images.
\textbf{(b)} Schematics for different training scenarios: 2D image and 2D ST pairs (\textit{2D}), adding 3D image and 2D ST pairs  (\textit{3D}), and further adding 3D image and 2D ST pairs from the VOI (\textit{3D + VOI}).
\textbf{(c)} PCC and SSIM between the predicted and the measured expression for three gene sets for five patients: All Genes (264 genes), the top 50 highly predictive genes, and marker genes. Error bars indicate one standard deviation from the mean, over ten sections across five patients.
\textbf{(d)} Spearman's $\rho$ between the variance of measured and predicted expressions across all genes. Each black dot represents a tissue section. 
\textbf{(e)} Difference in Moran's I and Geary's C metric between measured and predicted expressions aggregated across all genes in five patients.
\textbf{(f)} 3D ST prediction heatmap for select genes, with 3D morphological segmentation masks. Additional examples can be found in \textbf{Extended Data Figure~\ref{fig:ext_prostate_3D}}.
\textbf{(g)} Cross-section visualizations of morphology, measured and predicted ST for \textit{AZGP1}, and morphological segmentation masks.
\textbf{(h)} ARI metrics across the depth of tissue volume. The ARI metric is measured between the segmentation mask and predicted spatial domains. Each black dot represents a tissue section.
\textbf{(i)} The spatial domains identified by $\ours$ for the plane at $400 \mu m$. All scalebars are $1\,mm$.  Statistical significance was assessed with the Wilcoxon signed-rank test. $^{\ast}p\leq 0.05$, $^{\ast\ast}p\leq 0.01$, $^{\ast\ast\ast}p\leq 0.001$. Whiskers extend to data points within 1.5$\times$ the interquartile range. VOI: Volume of interest. PCC: Pearson Correlation Coefficient. SSIM: Structural Similarity Index Measure. ARI: Adjusted Rand Index. 
}
\label{fig:prostate}
\end{figure*}

% 2D and 3D trends
We evaluate the predictive performance of $\ours$ for five volumes for which we obtained two 2D ST sections at different depths (samples P1$\sim$P5). Performance is assessed using a leave-one-volume-out approach, with one volume assigned as VOI and the rest as the training set. Three different training scenarios are examined for delineating data-related effects: \textit{2D}, \textit{3D}, and \textit{3D+VOI} (\textbf{Figure~\ref{fig:prostate}B}). In the \textit{2D} scenario, the training set combines public 2D H\&E and 2D ST data pairs with internal 2D microCT image and 2D ST pairs. For the \textit{3D} scenario, 3D microCT images, instead of 2D microCT images, are used to provide 3D morphological context for ST prediction. The \textit{3D + VOI} scenario further fine-tunes the model by incorporating an additional data pair from the VOI, in the form of a single 2D ST section. The remaining ST section not used for fine-tuning (the second ST section for each specimen) is used for evaluation, with the roles subsequently switched to yield two predictions for each VOI. These experiments are designed to elucidate the benefits of 3D morphological context (\textit{3D} vs. \textit{2D}) and integrating VOI-specific training pairs on top of training pairs from generic volumes of the same cancer/tissue type (\textit{3D + VOI} vs. \textit{3D}).
We use an average of Pearson Correlation Coefficient (PCC) and Structural Similarity Index Measure (SSIM) across two sections for which ST profiles are available. PCC is computed for an individual gene between the measured and predicted expressions across all spots in a plane, with a higher correlation indicating better ST predictions. SSIM assesses the structural similarity between the measured and predicted expressions by treating them as images, with a higher value indicating a more similar spatial structure\cite{wang2004image, zhang2024inferring, wang2025benchmark}.
To assess the robustness of $\ours$ to the choice of different genes for prediction, we choose three genes sets: 19 genes curated from Oncotype DX\cite{klein201417, cullen2015biopsy} and Decipher\cite{klein2016decipher} (\textit{marker genes}, \textbf{Extended Data Table~\ref{tab:marker_genes}}), the top 50 genes with the highest PCC (or SSIM) across the patients (\textit{Top 50 genes}), and the 264 genes that comprise the union of the 250 highly-expressed genes (HEG) and marker genes (\textit{all genes}).
Further details on model evaluation can be found in \textbf{Online Methods} section \textbf{Evaluation Metrics}.

We observe that \textit{3D + VOI} setting achieves the best PCC across all patients with an average of 0.46 for all, 0.57 for the top 50 predictive, and 0.42 for marker genes, and outperforming the 3D (\textit{$P\leq 0.001$} for all 0.29, top-50 0.41, marker 0.23) and the \textit{2D} settings (\textit{$P\leq 0.001$} for all 0.27, top-50 0.39, marker 0.21) (\textbf{Figure~\ref{fig:prostate}C}). Evaluation with SSIM provides the same conclusion with the \textit{3D+VOI} setting (all 0.56, top-50 0.58, marker 0.37) outperforming the \textit{3D} (all 0.51 \textit{$P\leq 0.001$}, top-50 0.52 \textit{$P\leq 0.001$}, marker 0.33 \textit{$P\leq 0.01$}) and the \textit{2D} settings (all 0.50 \textit{$P\leq 0.001$}, top-50 0.51 \textit{$P\leq 0.001$}, marker 0.32 \textit{$P\leq 0.01$}).
The trend is also maintained with the high-variable genes (HVG) or when the gene set size is expanded to 1,000 HEG, demonstrating the robustness of $\ours$ to gene sets (\textbf{Extended Data Figure~\ref{fig:ext_1000HEG_and_HVG}}). Next, we sought to assess whether $\ours$ can accurately capture the variance of expression levels across different spatial locations. First, we use Spearman's $\rho$ to compute the correlation between the variance of the measured expression levels and the variance of $\ours$-predicted expression levels across all 264 genes within each of 10 tissue sections (\textbf{Figure~\ref{fig:prostate}D}). 
Additionally, to assess whether $\ours$ can capture spatially heterogeneous expression patterns of the genes, we compute Moran's I\cite{moran1950notes} and Geary's C\cite{geary1954contiguity} for all genes to evaluate spatial autocorrelation. Specifically, we compute the difference of Moran's I and Geary's C between the ground truth and $\ours$-prediction, with smaller values indicating that $\ours$ better captures the expression heterogeneity (\textbf{Figure~\ref{fig:prostate}E}). We observe that \textit{3D + VOI} faithfully captures the expression variability, with Spearman's $\rho$ achieving the highest value and the two other metrics achieving the median value closest to 0. Examples of gene expression variance show that $\ours$ with \textit{3D+VOI} setting identifies and predicts gene expressions across a wide spectrum of variance (\textbf{Extended Data Figure~\ref{fig:ext_variance_ablation}}).

These results collectively indicate two important data scaling trends. 
First, incorporating depth context enhances the predictive performance, suggesting that the 3D context provides more morphological cues for predicting accurate transcriptomics expression. The second trend indicates that integrating VOI-specific morphomolecular information is crucial for ST prediction. Integrating measured ST data from a VOI apparently enables $\ours$ to learn VOI-specific morphomolecular links that are not represented in other volumes due to heterogeneity between cases (even of similar diseases or tissue types).

\hheading{Morphomolecular analysis of prostate cancer tissue volume}

\begin{figure*}[]
\centering  
\includegraphics[width=\textwidth]{figures/Fig3_PROSTATE_large.pdf}
\caption{\textbf{$\ours$ on large prostate cancer tissue}. \textbf{(a)} 3D ST prediction by $\ours$ on large prostate cancer tissue volume for \textit{EpCAM} and \textit{ACTA2} genes, with the spatial domains identified by $\ours$. Cross-sections at 620 $\mu m$ and 1,120 $\mu m$ are also displayed. The red box indicates the ST capture area at the depth of 490 $\mu m$. The corresponding H\&E tissue image based on which the ST capture area was selected is also shown.
\textbf{(b)} Zoomed-in regions-of-interests from the tissue section at depth 1,120 $\mu m$.
\textbf{(c)} The coronal and sagittal plane of the tissue volume and the corresponding prediction for \textit{EpCAM} and \textit{ACTA2}.
Additional examples can be found in \textbf{Extended Data Figure~\ref{fig:ext_prostate_3D_largeFOV}}. Scalebar is 1 mm.
}
\label{fig:ext_prostate_large}
\end{figure*}

To better understand the spatial distribution of predicted expressions and their links to the underlying tissue morphology, we construct 3D ST prediction heatmaps and 3D morphological segmentation masks. We construct two types of 3D ST prediction heatmaps, either based on the gene of interest or the gene set. We utilize spatial domains for the gene set, obtained by K-means clustering gene set prediction into distinct molecular groups. To render 3D ST prediction with higher spatial resolution than Visium sequencing spots, we apply the super-resolution framework TESLA\cite{hu2023deciphering}, which imputes ST for non-sequenced regions by aggregating expression levels of neighboring spots, on $\ours$-predicted expressions for each axial plane. 3D segmentation mask, generated based on the combination of pathologist's annotations on a few tissue sections and AI-based segmentation\cite{kirillov2023segment, ravi2024sam2segmentimages}, provides a morphological reference for comparison with molecular counterparts throughout the tissue volume. We create four to five morphological categories, dependent on the prostatic tissue subtypes present on each volume. For example, for P1 (\textbf{Figure~\ref{fig:prostate}F)}, we define tumor, benign glands, stroma, and adipose regions.
Utilizing both ST heatmaps and segmentation masks, we observe the consistency between the spatial distributions of the measured (ground truth) and predicted ST, both of which are localized to specific morphological categories (\textbf{Figure~\ref{fig:prostate}F, G, Extended Data Figure~\ref{fig:ext_prostate_3D}}). For example, the predicted \textit{SPON2} expression is upregulated in tumoral regions, \textit{MSMB} is upregulated in normal glands, and ACTA2 is upregulated in stromal regions, aligning with previous findings\cite{whitaker2010rs10993994, qian2012spondin, berglund2018spatial}. Further details on how 3D morphological segmentation masks are built can be found in \textbf{Online Methods} section \textbf{3D morphological segmentation}.

Visualization of ST heatmaps also enables analyzing inter-tumoral heterogeneity in 3D. A notable example is \textit{AZGP1}, part of OncotypeDx and the marker gene set, for which down-regulation in prostatic tumor glands is associated with poor prognosis and shorter biochemical recurrence (BCR)\cite{lapointe2004gene, burdelski2016reduced, kristensen2019predictive} (\textbf{Extended Data Figure~\ref{fig:ext_intertumoral}}). We observe that $\ours$ captures this inter-tumoral heterogeneity, and predicts different expression patterns based on the BCR status of each sample. P1 (low-risk for BCR) has high \textit{AZGP1} expression for both tumor and benign glands and P3 and P4 (high-risk for BCR) have low and high \textit{AZGP1} expression for tumor and benign glands, respectively. This reaffirms earlier observations that despite identifying cohort-wise consistent morphomolecular links, VOI fine-tuning can help further identify volume- or patient-specific as well as conflicting links (tumor glands with high and low \textit{AZGP1} expression for low and high BCR risk, respectively). 

Finally, we quantify the agreement between the predicted spatial domains and underlying morphology. Using 3D morphological segmentation masks as the ground truth annotation for each level, we compute the adjusted rand index (ARI) for the spatial domains along all levels of the axial dimension across three training scenarios (\textbf{Figure~\ref{fig:prostate}H}). Reflecting the previous trends, we observe that \textit{3D + VOI} results in the best ARI metric, with \textit{3D} and \textit{2D} achieving similar performance. Visual inspection of the spatial domains also confirms that the spatial domains discovered by \textit{3D + VOI} agrees the most with the segmentation masks (\textbf{Figure~\ref{fig:prostate}I}, \textbf{Extended Data Figure~\ref{fig:ext_spat_cluster}}). 

\hheading{3D ST prediction for large tissue volume}

The 3D ST prediction with $\ours$ can be easily scaled to a larger tissue volume captured with 3D imaging modalities, for which the planar field-of-view exceeds that of a typical ST capture area. As an example, $\ours$ fine-tuned on one tissue section with ST measurements at the depth of 490 $\mu m$ of the VOI can produce prediction for the large microCT tissue volume with larger planar area (tissue area $6.62\times 8.85\, mm^2$ vs. ST capture area for this sample $5.3 \times 6.5 \,mm^2$) and 171 times larger depth along the axial dimension (thickness for tissue $1.71 \,mm$ vs. one ST section $5 \,\mu m$) (\textbf{Figure~\ref{fig:ext_prostate_large}A}). Even in regions far apart from the tissue section with the ST measurement (plane at depth of 1,120 $\mu m$, with the distance of 630 $\mu m$ from the ST section at the depth of 490 $\mu m$), we observe that the expression of representative genes, \textit{EPCAM} and \textit{ACTA2}, show consistent overlap with tumor glands and stroma, respectively. This is also reflected in the alignment of the spatial domains with the different morphological classes, where domains 1, 2, 3, and 4 correspond to tumoral glands, benign glands, stroma, and adventitia (or adipose), respectively.
The spatial domains and gene expression patterns segment along fine-grained morphology, such as pockets of tumoral glands surrounded by stroma (\textbf{Figure~\ref{fig:ext_prostate_large}B}).
With access to continuous 3D morphology in the tissue volume, it is also easy to examine different views of the tissue, such as sagittal and coronal planes (\textbf{Figure~\ref{fig:ext_prostate_large}C}). Additional examples of $\ours$ scaling to larger tissue samples can be found in \textbf{Extended Data Figure~\ref{fig:ext_prostate_3D_largeFOV}}.
We emphasize that other 2.5D or 3D ST approaches lack such scalability. Tissue sections with ST measurements on both sides and close to the test tissue area are required for smooth interpolation, requiring a large number of ST measurements to profile thick tissue. Furthermore, prediction via extrapolation outside the ST capture area for each axial section is non-trivial.  

% OTLS results
Finally, we assess the generalization capability of $\ours$ by applying the model to 3D ST prediction for a prostate cancer image captured with open-top lightsheet microscopy (OTLS), another non-destructive imaging modality that can provide H\&E-like appearance in 3D\cite{bishop2024end}. To this end, we apply $\ours$ pretrained on 2D H\&E morphology and ST pairs and predict the ST profile for each OTLS image plane, imaged at 1~$\mu m$/voxel, across the axial dimension (\textbf{Extended Data Figure~\ref{fig:ext_otls}}). We observe close agreement of the expression pattern with underlying morphology throughout the volume, such as \textit{KLK3} with tumoral glands and \textit{COL1AI} with stroma. This demonstrates $\ours$'s ability to handle different 3D imaging modalities flexibly and also underscores its generalizability even in the absence of ST measurements from a VOI.

\hheading{$\ours$ analysis for serial tissue sections}

Although 3D ST prediction based on 3D tissue images is the primary focus of $\ours$, the same principles can be applied to 2.5D tissue images consisting of serial tissue sections. While the sparse number of sections at certain intervals provides discontinuous and insufficient coverage of the tissue volume compared to 3D tissue images, easy integration into the current tissue processing workflow makes the serial section approach a practical alternative. To make $\ours$ compatible with 2.5D tissue images, we make two small adjustments. First, we replace the cross-modal registration with serial tissue section registration using VALIS\cite{gatenbee2023virtual} (\textbf{Extended Data Figure \ref{fig:breast_crc}A}). Next, with 3D morphological context for localized ST prediction infeasible due to non-contiguous sections, we construct a 2.5D context with equidistant neighboring sections instead, using the same depth aggregation module. Additional information about the 2.5D context can be found in \textbf{Online Methods} section \textbf{2.5D image data preprocessing}.

We validate $\ours$ on publicly available breast and colorectal cancer cohort volumes with serial tissue sections.
For the breast cancer cohort, we curate 101 H\&E-stained tissue sections with ST (58,263 spots) aggregated from several studies\cite{andersson2021spatial,he2020integrating,staahl2016visualization}. The curated dataset contains a mixture of serial sections cut at 32 $\mu m$ intervals for eight volumes and single sections from the remaining volumes.  $\ours$ evaluations are performed on four volumes for which six serial sections are available\cite{andersson2021spatial}. We use immediate neighboring sections placed at +32 $\mu m$ and -32 $\mu m$ as 2.5D context for each section. For the colorectal cancer cohort, we curate 26 H\&E-stained tissue sections with 2D ST (72,042 spots) from two studies\cite{valdeolivas2024profiling,mirzazadeh2023spatially}. Compared to the other cohorts for which 3D or serial 2D tissue images are available, the colorectal cancer cohort has only two sections with morphology and 2D ST from each tissue volume. Further details about the datasets can be found in \textbf{Extended Data Table \ref{tab:dataset}} and in the \textbf{Online Methods} section \textbf{Datasets}.

To understand how the data scaling trend \textit{across} tissue volumes influences the predictive performance, we investigate the performance of $\ours$ for the breast cancer cohort only with cohort pretraining (2.5D), only with training data pairs from VOI (VOI), and the combination of both (2.5D + VOI). We additionally evaluate how different amounts of VOI training pairs affect the performance, to understand the data scaling trend \textit{within} tissue volume (\textbf{Extended Data Figure~\ref{fig:breast_crc}B}). Specifically, for evaluating the top section of the volume with 2.5D context (S2), we gradually increase the number of ST sections from the bottom section with 2.5D context (S5) used for fine-tuning $\ours$, and vice versa. We evaluate the averaged performance for four patients with PCC and SSIM across three similar gene sets as before, adapted for this cohort with the marker gene set curated from HER2DX and anti-HER2 therapy\cite{prat2020multivariable, smith2021her2+}. 
First, we observe the data scaling trend within a tissue volume, where the predictive performance is increased as more tissue sections with paired morphology and 2D ST from the VOI are integrated. Including the maximum-allowable three sections with 2.5D context achieves the best performance across all gene sets, regardless of whether or not $\ours$ is pretrained with cohort data.
Furthermore, we observe the data scaling trend across tissue volumes, with \textit{2.5D + VOI} outperforming both \textit{2.5D} and $\textit{VOI}$ only (\textbf{Extended Data Figure~\ref{fig:breast_crc}C}). This trend is also maintained when the gene set is expanded to 1,000 HEG (\textbf{Extended Data Figure~\ref{fig:ext_1000HEG_and_HVG}C}).
For the same number of VOI fine-tuning tissue sections, the \textit{2.5D + VOI} setting always outperforms the \textit{VOI} setting, emphasizing the importance of cohort pretraining.
For the analyses on colorectal cancer, despite being restricted to \textit{2D} and \textit{2D+VOI} due to the lack of neighboring sections, we observe similarly that \textit{2D + VOI} performs better in both PCC and SSIM than the non-fine-tuning alternative of \textit{2D} setting (\textbf{Extended Data Figure~\ref{fig:breast_crc}D}). Additional analysis on the expanded gene set of 1,000 HEG also preserves the trend (\textbf{Extended Data Figure~\ref{fig:ext_1000HEG_and_HVG}D}).

Visualization of the predicted 2.5D ST heatmap shows that $\ours$ can reliably predict and localize morphological correlates of transcriptomic expressions for breast cancer, such as overexpression of \textit{ESR1} and \textit{COX6C} \cite{kim2017epithelial} in tumor (\textbf{Extended Data Figure~\ref{fig:breast_crc}E, \ref{fig:ext_CRC_3D}A}). The same holds true for the colorectal cancer cohort, where $\ours$ accurately captures the morphomolecular relationship such as up-regulation of \textit{EpCAM}, \textit{CEACAM5} and \textit{KRT8} in tumoral regions\cite{xiao2024integrating}(\textbf{Extended Data Figure~\ref{fig:breast_crc}F}, \textbf{Extended Data Figure~\ref{fig:ext_CRC_3D}B}).

Finally, we assess whether $\ours$ pretrained on a colorectal cancer cohort can generalize to an unseen large colorectal cancer tissue specimen. To this end, we use publicly available 22 serially-sectioned large H\&E tissue images at the intervals of roughly 25$\mu m$ from colorectal adenocarcinoma patient\cite{lin2023multiplexed} as an input volume to $\ours$, with the axial plane area of $12 \times 10\, mm^2$ easily exceeding typical ST capture area (\textbf{Extended Data Figure~\ref{fig:breast_crc}G}, \textbf{Extended Data Figure~\ref{fig:ext_CRC_3D}C}). While the lack of measured ST prevents quantitative evaluation of prediction quality, it provides a valuable validation for $\ours$ generalization capacity to unseen large volumes.
The five spatial domains identified by $\ours$ show close agreement with the five morphological clusters across the volume, achieving high and consistent ARI values across the depth. The localization of representative gene expression patterns to specific morphological regions supports this observation, such as \textit{EpCAM}, known to be up-regulated in tumoral regions\cite{spizzo2011epcam}, and \textit{ZG16}, known to be down-regulated in tumoral regions\cite{xu2020identification}. This localization captures subtle variations in fine-grained morphology, exemplified by a heterogeneous region with a thin `cord-like' structure consisting of stroma (left half) and normal mucosa (right half) surrounded by adenocarcinoma (\textbf{Extended Data Figure~\ref{fig:breast_crc}H}). $\ours$ successfully identifies three distinct spatial domains within this region, also with the predicted \textit{ZG16} and \textit{EpCAM} showing high expression for normal mucosa and adenocarcinoma, respectively. These results collectively underscore the capacity of $\ours$ to generalize to unseen volumes of large physical dimensions.

\hheading{Morphological biomarker exploration with $\ours$}

\begin{figure*}[!h]
\centering
\includegraphics[width=\textwidth]{figures/Fig4_zero-shot.pdf}
\caption{\textbf{Cross-modal morphology retrieval with $\ours$}. Aligned morphology-transcriptomics embedding space, formed by 3D image encoder and transcriptomics encoder of $\ours$, enables cross-modal retrieval. Given a molecular query of transcriptomics profile based on biological functions of interest, the corresponding 3D morphology regions are retrieved, as determined by the closest Euclidean distance in the embedding space. 
\textbf{(a)} A schematic for 3D morphological retrieval with molecular queries. Genes are divided into three categories, well-known genes for a biological function (\textit{genes of interest}), the additional set of genes for which the expression levels across the ST spots are correlated with those genes (\textit{correlated genes}), and the remaining genes in the Visium sequencing panel shared across other samples in the cohort (\textit{rest of genes}). ST spot embeddings are filtered based on the expression levels of \textit{spatial filter genes} (combination of \textit{genes of interest} and \textit{correlated genes}) and averaged to form each molecular query embedding.
\textbf{(b)} 3D similarity heatmap, cross-sections, and representative patches from VOI. The number in the top-right corner of each patch indicates the similarity percentile rank of the patch for a given molecular query, with the higher percentile indicating the higher similarity. 
\textbf{(c)} Additional examples of similar and dissimilar 3D patches for each molecular query. For each 3D patch, the 2D microCT and H\&E patches from the middle section are also displayed. Unless specified otherwise, scalebar is 1mm.
}
\label{fig:recall}
\end{figure*} 

In addition to 3D ST prediction, $\ours$ can retrieve closely related 3D morphological regions for a transcriptomic profile query, referred to as cross-modal retrieval in a zero-shot setting.
Such a task can naturally be extended to biomarker exploration for identifying 3D morphological underpinnings of a specific transcriptomic profile, such as co-expression of genes of interest from specific functional gene sets.
This process involves using transcriptomic profiles as query inputs to obtain morphological outputs, representing the reverse of $\ours$ prediction workflow, where morphology is used as input to predict transcriptomic profiles.
Instead, this leverages the aligned image and transcriptomic embedding space from training $\ours$ with the contrastive loss, where the most similar 3D VOI patch embeddings are retrieved based on the Euclidean distance to the transcriptomic query embedding.

We design three molecular queries based on well-known biological processes. For well-known \textit{genes of interest} up-regulated in a biological function of interest, we identify a set of highly-correlated (co-expressed) genes across the ST spots. The union of the two gene sets (\textit{spatial filter genes}) is then used for filtering ST spots in the VOI, for curation of coherent expression profiles within the volume. Finally, we obtain the molecular query embedding by averaging the transcriptomic embeddings of the filtered spots.
This process ensures that spot-wise technical variations are removed and the rest of the genes in the query are at the baseline expression levels. 
The biological functions of the three queries correspond to \textit{Tumor cell growth} (query 1) with key genes \textit{TFF3}, and \textit{SPON2} associated with the \textit{PI3K/AKT/mTOR} pathway\cite{liu2018overexpression,zhang2024biological}, \textit{Myogenesis}\cite{liberzon2015molecular, ma2023prostate} (query 2) with the key genes \textit{TPM2}, and \textit{TAGLN}, and \textit{Tumor suppression} (query 3) with key genes \textit{MSMB}\cite{sjoblom2016microseminoprotein}, and \textit{ACPP}\cite{veeramani2005cellular}, respectively (\textbf{Figure~\ref{fig:recall}A}). More details on designing molecular queries and filtering process can be found in \textbf{Online Methods} Section \textbf{Molecular queries for cross-modal retrieval}.

We observe that the corresponding 3D similarity heatmaps and the representative 3D image patches agree with the morphological correlates of the gene subsets, as highlighted in red regions (\textbf{Figure~\ref{fig:recall}B}). The most similar morphology for the first query corresponds to the tumoral glands, which is expected due to the up-regulation of \textit{PI3K/AKT/mTOR} pathway involved in tumor growth\cite{berglund2018spatial, shorning2020pi3k}. The stromal regions are retrieved for the second query, with the \textit{Myogensis} pathway linked to stroma composition remodeling\cite{dakhova2014genes, ma2023prostate}. Finally, the benign glands are retrieved for the third query, with \textit{MSMB} and \textit{ACPP} involved in tumor suppression\cite{sjoblom2016microseminoprotein,veeramani2005cellular} and known to be up-regulated compared to the cancerous glands\cite{bjartell2007association, dahlman2011evaluation}.
To further quantify similarity, we rank the patches based on their distance to the molecular query in the embedding space, with a higher percentile indicating higher similarity. 
We observe that morphology of high similarity for one molecular query shows a lower similarity for other queries. For instance, the most similar stromal patch that ranks in the 99.6\textsuperscript{th} percentile for molecular query 2 is placed at the 57.1\textsuperscript{st} and 55.6\textsuperscript{th} for other queries (\textbf{Figure~\ref{fig:recall}B}). Additional examples of similar and dissimilar patches, for the tissue sections with corresponding H\&E images available, confirm the separation of the embedding space along different morphological concepts and the alignment with different transcriptomic profiles (\textbf{Figure~\ref{fig:recall}C}).
We additionally evaluate on the large CRC volume with serial sections, which reaffirms that $\ours$ can reliably retrieve morphological correlates of transcriptomic profiles (\textbf{Extended Data Figure~\ref{fig:ext_CRC_query}}).

These examples hint at $\ours$'s potential as a biomarker discovery tool for unknown 3D morphological correlates of custom transcriptomics profiles. Additionally, clinicians can triage sections or regions of interest of high or low similarity for further examination or molecular tests, based on the similarity heatmap provided by $\ours$.