%!TEX root=main.tex
\section{Synthesis Algorithm}\label{sec:algo}
In this section, we detail the algorithm we propose for synthesizing synchronized process models from specifications.
This algorithm takes as input a specification $\mathcal{S} = \langle \{ \textit{PS}^i \}_{i \in \mathcal{I}}, \phi \rangle$ for a distributed system, and attempts to synthesize  local implementations  $\{ T^i \}_{i \in \mathcal{I}}$, that satisfy the corresponding local specification (i.e., $T^i \models \mathit{PS}^i$, for every $i \in \mathcal{I}$); and whose  asynchronous parallel composition satisfies the global temporal requirement $\phi$, i.e., $\parallel_{i \in \mathcal{I}} T^i \models \phi$. The algorithm also uses a bound  $k$ to limit the maximum number of states for the synthesized LTSs.  When an implementation is found, it is returned in the {\NuSMV} language; if not, the algorithm deems the specification as unsatisfiable within the bound $k$. 

First, we present Alg.~\ref{alg:the_alg},  a basic  version of the synthesis procedure. 
In line \ref{alg1-for-loop}, it inspects all instances of the current specification.  Line \ref{alg1-base-case} handles the base case (the last specification): a model checker is called to verify the selected instances; if successful the obtained solution is returned; otherwise, another instance is chosen. Line \ref{alg1-recursive-call} addresses the recursive case, where a different instance is examined, and the algorithm continues recursively with the next specification.
As shown in Section \ref{sec:examples}  this algorithm can only cope with small problems. 
{\scriptsize
\begin{algorithm*}[t]
\caption{A Simple Search Algorithm}
\label{alg:the_alg}
%\SetAlgoLined
\SetKwProg{Fn}{Function}{}{end}
\SetKwFunction{Synt}{Synt}%
\SetFuncSty{textbf} 
\KwData{$i$ (process number)
$\textit{PS}^0,\dots,\textit{PS}^n$ (process specifications), $\phi$ (global property), $k$ (instance bound)}
\Fn{\Synt{$i,\textit{PS}^0,\dots,\textit{PS}^n, k $}}{
\KwResult{$r_0, \dots, r_n$ with $r_i \vDash \textit{PS}^i$ and
$r_0 \parallel \dots \parallel r_n \vDash \phi$ or $\emptyset$ otherwise}
 \For{all instances $M_i$ of $\textit{PS}^i$}{  \label{alg1-for-loop}
            $r_i \gets M_i$\;
            \lIf{$i=n \wedge r_0 \parallel \dots \parallel r_n \vDash \phi$}{ \Return{$\{r_0,\dots,r_n $\}} } \label{alg1-base-case}
                  %  \lIf{$r_0 \parallel \dots \parallel r_n \vDash \phi$}{ \Return{$\{r_0,\dots,r_n $\}} } \label{alg1-model-check}
                %}
             %{
             \If{$i < n$}{
                $\textit{found} \gets \Synt(i+1,\textit{PS}^0, \dots, \textit{PS}^n, k)$\; \label{alg1-recursive-call}
                \lIf{$\textit{found} \neq \emptyset$}{\Return{$\textit{found}$}}
            %
            }
   }
\Return{$\emptyset$}\;
}
\end{algorithm*}
}
One main issue with Alg.~\ref{alg:the_alg} is that a wrong choice for the initial instance of the first specifications  (in lexicographic order, e.g., $\textit{PS}^0$) could result in the algorithm
getting stuck while searching for instances of the last specifications (e.g.,  $\textit{PS}^n$) before coming back to the initial specifications to try with different instances of them.  

We improve Alg.~\ref{alg:the_alg} using two main techniques: first, we force the synthesizer to start from better instances (see below); second, we use  counterexamples to speed up the search.
For the first point we add to the specifications formulas that ensure that the obtained instances contain a large number of transitions, which can be pruned in later stages.  Specifically, for every action $\textit{act}$ in a specification $\textit{PS}^i$ we add the formula:
\[
    \forall s \in S : \textit{Pre}_{\textit{act}}(s) \Rightarrow \exists s' \in S : \textit{act}(s,s')
\]
which states that, for every state where the precondition of the action ($\textit{Pre}_{\textit{act}}$) holds,  an execution of $\textit{act}$ can be observed.  This ensures that the obtained model has a good amount of transitions.  We use this for the second technique we apply,  namely, we use counterexamples to prune action executions that may violate the global formulas.  This approach is obviously sound but not complete, because a wrong selection of initial instances may imply that no solution will be found. However, in Section \ref{sec:examples} we show that this procedure is able to deal with an interesting set of examples.  
Furthermore, to avoid that the algorithm gets stuck while inspecting instances of the last specifications without comebacking to try new instances of the first components, we introduce the use of batches.
More specifically,  we use a sequence of bounds $b_0 \dots b_n$
aimed at performing a bounded backtracking. Furthermore,   the counterexamples collected in each batch are utilized for speeding up the process.  Roughly speaking,  we first execute the algorithm inspecting only $b_0$ instances of each specification; if no solution is found,  we use the counterexamples collected  but now with $b_1$ batches,  and so on. 

Some words are useful about the way in which our algorithm uses counterexamples for improving the search. Given the LTSs $\{ T^i \}_{i \in \mathcal{I}}$ and the global {\LTLX} property $\phi$, a \emph{counterexample} of $\parallel_{i \in \mathcal{I}} T^i \models \phi$ is an execution $\pi$ of $\parallel_{i \in \mathcal{I}} T^i$ such that $\pi \nvDash \phi$.  Our modified algorithm takes a counterexample $\pi$ generated by a model checker, and \emph{projects} this global execution to local executions of the participating processes. This information is then used to \emph{refine} the local process specifications to get rid of the projected counterexamples, and explore new implementations for the processes participating in the removed counterexample.

In finite transition structures, counterexamples can be represented by finite paths, called \emph{lasso traces} (a finite sequence of states, such that the last state has a loop to some previous state) \cite{Biere+1999}.  Noting that any finite path can be identified with a formula in \emph{conjunctive normal form} yields the following definition.

\begin{definition}Given an LTS $\lts{T}$ and a finite path $\pi = s_0, s_1, \dots ,s_{m} \in \Path{T}$, we define the formula:
$
\CNF(\pi) = \bigwedge_{0 \leq j < m}(\bigvee_{a \in \mathit{Act}}(a(s_j,$ $s_{j+1})),
$
where $s_0,\dots,s_m$ are free variables.
\end{definition}

The idea behind this definition is that paths can be captured by means of formulas. Let us denote by  $\llbracket \CNF(\pi) \rrbracket$ the set of clauses of formula $\CNF(\pi)$. For instance, $\refin{\mathit{PS},T} \oplus \CNF(\pi)$ captures the refinements of $T$ satisfying specification $\mathit{PS}$ and preserving path $\pi$. Similarly, we can define a formula that removes a counterexample from the instances of a specification.

\begin{definition}\label{def:not} Let $\lts{T}$ be an LTS and $\pi = s_0, s_1, \dots, s_m \in \Path{T}$ a path such that $s_i \neq s_{i+1}$ for some $i$. We define the following formula over $T$:
$
\NOT(\pi) = \bigvee_{0 \leq i < m} (\bigwedge_{a \in \mathit{Act}} \neg  a(s_{i},s_{i+1})  \wedge \ (s_i \neq s_{i+1})),
$
where $s_0,\dots,s_m$ are free variables.
\end{definition}

$\refin{\mathit{PS},T} \oplus \NOT(\pi)$ identifies the refinements of $T$ that do not have path $\pi$, as proved by the following theorem.

\begin{theorem}\label{theorem:cex-entails} Let $\mathit{PS}$ and $T$ be a specification and an LTS, respectively, such that $T \vDash \mathit{PS}$, and $\pi = s_0,\dots, s_m \in \Path{T}$ , with $s_i \neq s_{i+1}$ for some $i$. Then:
$
	\refin{\mathit{PS},T} \oplus \NOT(\pi)  \nvDash \CNF(\pi).
$
\end{theorem}
	
Given LTSs $\{ T^i \}_{i \in \mathcal{I}}$ and a finite path $\pi = s_0, \dots, s_m \in \Path{\parallel_{i \in \mathcal{I}} T^i}$, we denote by $\pi {\uparrow} i$ the path projected to an execution of process $T^i$, defined as  $\pi {\uparrow} i = s_0 {\uparrow} i, \dots, s_m {\uparrow} i$. Projecting a global execution may introduce stuttering steps in local executions. The projections of a global execution form a tuple  $\langle \pi{\uparrow}i \rangle_{i \in \mathcal{I}}$, that will be used to refine the instances obtained via the satisfiability solver. 

Using these definitions we introduce our updated algorithm.  Alg.~\ref{alg:improved_alg} implements the ideas previously discussed.  The Algorithm consists of a starting function (\textbf{StartSearch}) that sets the starting models of each specification (line \ref{alg2-initial-models}), as explained above these initial models are obtained by enriching the specification with specific formulas.  Line \ref{alg2-counterexamples-init}
initializes each specification with a tailored specifications $\textit{Ref}(\textit{PS}^i,M_i) \oplus \bigwedge_{\pi \in \textit{cexs}} \NOT(\pi{\uparrow}i)$.  Intuitively, these specifications consider all the refinements of the initial LTSs together with a set of counterexamples that can be used for refining them.  Line \ref{alg2-call-batchsynth} calls to the auxiliary function \textbf{BatchSynt}, which has similar behavior to Alg.~\ref{alg:the_alg}, but it takes into account the bounds for each batch  (line \ref{alg2-batch-loop}).
%One main issue in Algorithm \ref{} is that the procedure could stay exploring the instances of the last specification,  which could prevent the algorithm from backtracking and exploring another component.  For dealing with this, we use batches of runs,  intuitively, we impose a bound in the number of times that the loop of line \ref{} is executed.  This is achieved by using a sequence of bounds $b_0, b_1, \dots$ for $b_i \in \mathbb{N}$.  The first time the loop of line \ref{} is performed $b_0$ times, and then it backtracks, the second time it is executed $b_1$ times, and so on. 
%This sequence of bounds could be sequence of integers. However, since we use the aforementioned loop to collect counterexamples if the bound are small only few ocunter examples are collected for each batch.  Hence, we need a balance between how fast we want to backtrack and how many counterexamples we collect in the loop.  In this section we use the exponential progression: $2,4,8,\dots$. intuitively, we collect few counterexamples first,  enforcing early backtracking,  but in later iterations the number of counterexamples starts to increasing in an exponential way. In Section \ref{} we make a comparison with other possible sequence of bounds.
{\scriptsize
\begin{algorithm*}[t]
\caption{Batches Algorithm}
\label{alg:improved_alg}
%\SetAlgoLined
\SetKwComment{Comment}{/* }{ */}
\SetKwProg{Fn}{Function}{}{end}
\SetKwFunction{StartSearch}{StartSearch}%
\SetKwFunction{BatchSynt}{BatchSynt}%
\SetFuncSty{textbf} 
\KwData{$\textit{PS}^0,\dots,\textit{PS}^n$ (process specifications), $\phi$ (global property), $k$ (instance size bound), $b_0,\dots,b_m$ (sequence of batch bounds), $cexs$ (global set of counterexamples)}
\Fn{\StartSearch{$\textit{PS}^0,\dots,\textit{PS}^n$, k,  $b_0,\dots,b_m$}}{
\KwResult{$r_0, \dots, r_n$ with $r_i \vDash \textit{PS}^i$ and
$r_0 \parallel \dots \parallel r_n \vDash \phi$ or $\emptyset$ otherwise}
$cexs \gets \emptyset$\;
 \lForEach{ i = 0 \dots n}{$M_i \gets \text{initial instance of } \textit{PS}^i \textit{of size } k$} \label{alg2-initial-models}
\For{$b = b_0,\dots,b_m$}{ \label{alg2-batch-loop}
    \lForEach{$i=0\dots n$}{  $\textit{PS}^i \gets \textit{Ref}(\textit{PS}^i,M_i) \oplus \bigwedge_{\pi \in \textit{cexs}} \NOT(\pi{\uparrow}i),$ }  \label{alg2-counterexamples-init}
    found $\gets$ {\BatchSynt}($0$, $\textit{PS}^0,\dots,\textit{PS}^n$, $\phi$,$b$)\; \label{alg2-call-batchsynth}
    \lIf{$\textit{found} \neq \emptyset$}{\Return{found}}
}
\Return{$\emptyset$}\;
}
\Fn{\BatchSynt{$i,\textit{PS}^0,\dots,\textit{PS}^n, \phi, b$}}{
%\KwData{$i$ (process number), $\textit{PS}^0,\dots,\textit{PS}^n$ (process specifications), $\phi$ (global property), $k$ (instance size bound), $b$ (batch bound)}
\KwResult{$r_0, \dots, r_n$ with $r_i \vDash \textit{PS}^i$ and
$r_0 \parallel \dots \parallel r_n \vDash \phi$ or $\emptyset$ otherwise}
$j \gets 0$\;
 \While{$\textit{PS}^i$ has unprocessed instances and $j < b$}{  \label{alg2-for-loop}
            $r_i \gets \text{next instance of } \textit{PS}^i$\;
            \If{$i=n$}{
                 \lIf{$r_0 \parallel \dots \parallel r_n \vDash \phi$}{\Return{$\{r_0,\dots,r_n \}$}}    \label{alg2-base-case}
                 $cexs \gets \text{ process counterexamples}$\;
              %   $   \lIf{$r_0 \parallel \dots \parallel r_n \vDash \phi$}{ \Return{$\{r_0,\dots,r_n $\}} } \label{alg1-model-check}
               %$ 
              }
             \If{$i<n$}{
                $\textit{found} \gets {\BatchSynt}(i+1,\textit{PS}^0,\dots,\textit{PS}^n,\phi,b)$\; \label{alg2-recursive-call}
                \lIf{$\textit{found} \neq \emptyset$}{\Return{$\textit{found}$}}
            }
    $j \gets j+1$ \; 
}
\Return{$\emptyset$}\;
}

\end{algorithm*}
}

\iffalse
Fig.~\ref{fig:algorithm} provides an overview of our approach. First, given the input specification $\mathcal{S} = \langle \{ \textit{PS}^i \}_{i \in \mathcal{I}}, \phi \rangle$ and the bound $k$, it checks whether the specifications are satisfiable or not. In the positive case, the SAT solver returns the local implementations $\{ T^i \}_{i \in \mathcal{I}}$ for the process specifications. Next, the approach relies on model checking to verify whether $\parallel_{i \in \mathcal{I}} T^i \models \phi$. If the answer is positive, the algorithm terminates returning the implementation of the processes, whose composition satisfies the global temporal requirement. Otherwise, the model checker returns a counterexample, i.e., an execution of the distributed system that violates the global property $\phi$. Finally, the produced counterexample is used for extracting information useful for improving the search, and helping the satisfiability procedure to produce new local implementations. Our prototype tool uses the Alloy Analyzer~\cite{AlloyBook} for satisfiability checking and {\NuSMV} \cite{Cimatti+2002} to model check LTSs against properties. 

\begin{figure}[t!]
\centering
\includegraphics[scale=0.25]{Figs/algorithm.pdf} % second figure itself
\caption{An Overview of the Algorithm}
\label{fig:algorithm}
\end{figure}

Let us describe how counterexamples are used for pruning the search (see step 3 in Fig.~\ref{fig:algorithm}). Given the LTSs $\{ T^i \}_{i \in \mathcal{I}}$ and the global {\LTLX} property $\phi$, a \emph{counterexample} of $\parallel_{i \in \mathcal{I}} T^i \models \phi$ is an execution $\pi$ of $\parallel_{i \in \mathcal{I}} T^i$ such that $\pi \nvDash \phi$. The refinement phase of our algorithm takes a counterexample $c$ generated by a model checker, and \emph{projects} this global execution to local executions of the participating processes. This information is then used to \emph{refine} the local process specifications to get rid of the projected counterexamples, and explore new implementations for the processes participating in the removed counterexample.

In finite transition structures, counterexamples can be represented by finite paths, called \emph{lasso traces} (a finite sequence of states, such that the last state has a loop to some previous state) \cite{Biere+1999}. Furthermore, any finite path can be identified with a formula in \emph{conjunctive normal form}. 

\begin{definition}Given an LTS $\lts{T}$ and a finite path $\pi = s_0, s_1, \dots ,s_{m} \in \Path{T}$, we define the formula:
$
\CNF(\pi) = \bigwedge_{0 \leq j < m}(\bigvee_{a \in \mathit{Act}}(a(s_j,$ $s_{j+1})),
$
where $s_0,\dots,s_m$ are free variables.
\end{definition}

The idea behind this definition is that paths can be captured by means of formulas. Let us denote by  $\llbracket \CNF(\pi) \rrbracket$ the set of clauses of formula $\CNF(\pi)$. For instance, $\refin{\mathit{PS},T} \oplus \CNF(\pi)$ captures the refinements of $T$ satisfying specification $\mathit{PS}$ and preserving path $\pi$. Similarly, we can define a formula that removes a counterexample from the instances of a specification.

\begin{definition}\label{def:not} Let $\lts{T}$ be an LTS and $c = s_0, s_1, \dots, s_m \in \Path{T}$ a path such that $s_i \neq s_{i+1}$ for some $i$. We define the following formula over $T$:
$
\NOT(c) = \bigvee_{0 \leq i < m} (\bigwedge_{a \in \mathit{Act}} \neg  a(s_{i},s_{i+1})  \wedge \ (s_i \neq s_{i+1})),
$
where $s_0,\dots,s_m$ are free variables.
\end{definition}

$\refin{\mathit{PS},T} \oplus \NOT(c)$ identifies the refinements of $T$ that do not have path $c$, as proved by the following theorem.

\begin{theorem}\label{theorem:cex-entails} Let $\mathit{PS}$ and $T$ be a specification and an LTS, respectively, such that $T \vDash \mathit{PS}$, and $c = s_0,\dots, s_m \in \Path{T}$ , with $s_i \neq s_{i+1}$ for some $i$. Then:
$
	\refin{\mathit{PS},T} \oplus \NOT(c)  \nvDash \CNF(c).
$
\end{theorem}
	
Given LTSs $\{ T^i \}_{i \in \mathcal{I}}$ and a finite path $\pi = s_0, \dots, s_m \in \Path{\parallel_{i \in \mathcal{I}} T^i}$, we denote by $\pi {\uparrow} i$ the path projected to an execution of process $T^i$, defined as  $\pi {\uparrow} i = s_0 {\uparrow} i, \dots, s_m {\uparrow} i$. Projecting a global execution may introduce stuttering steps in local executions. The projections of a global execution form a tuple  $\langle \pi{\uparrow}i \rangle_{i \in \mathcal{I}}$, that will be used to refine the instances obtained via the satisfiability solver. 

\begin{algorithm*}[t]
\SetAlgoLined
\SetKwProg{Fn}{Function}{}{end}
\SetKwFunction{Synt}{Synt}%
\Fn{\Synt{$i,\textit{PS}^0,\dots,\textit{PS}^n, k $}}{
\KwData{$i$ (process number)
$\textit{PS}^0,\dots,\textit{PS}^n$ (process specifications), $\phi$ (global property), $k$ (instance bound)}
\KwResult{$r_0, \dots, r_n$ with $r_i \vDash \textit{PS}^i$ and
$r_0 \parallel \dots \parallel r_n \vDash \phi$ or $\emptyset$ otherwise}
$\textit{Q}_i \gets \textit{new stack}$\; \label{Q:creation}
 \For{all instance $M_i$ of $\textit{PS}^i$}{  \label{for-loop}
    $\textit{sol} \gets \textit{get solver for } \textit{Ref}(\textit{PS}^i,M_i)$\; \label{solver-creation}
    $\textit{push}(Q_i, (\textit{sol},\emptyset))$\; \label{push-sol}
    \While{$Q_i \textit{ is not empty}$}{ \label{while-loop}
        $(\textit{solver}_i,\textit{cexs}_i) \gets \textit{pop}(Q_i)$\; \label{solver-popped}
        \While{$\textit{solver}_i \textit{ has instances}$}{ \label{solver-loop}
            $r_i \gets \textit{next instance of solver}$\;
            \eIf{$i=n$}{ \label{base-case}
                \eIf{$r_0 \parallel \dots \parallel r_n \vDash \phi$}{ \Return{$\{r_0,\dots,r_n $\}} \label{model-check}
                }{
                    $\textit{cex} \gets \textit{found counterexample}$\; \label{found-cex}
                    \For{$m \gets 0$ to $n$}{ \label{cex-dealing-starts}
                        \If{$\forall c \in \textit{cexs}_m: c * \textit{cex} \vee \textit{cex} \sqsubseteq c $}{ \label{cex-treatment}
                            $(\textit{oldSol}, \textit{oldCexs}) \gets (\textit{sol}_m,\textit{cexs}_m)$\; \label{sol-stored}
                            push($Q_m$, $(\textit{oldSol},\textit{oldCexs}))$\; \label{solver-pushed}
                            $\displaystyle \textit{sol}_m \gets \textit{solver for } \textit{Ref}(\textit{PS}^i,M_i) \oplus \bigwedge_{c \in \textit{cexs}_m} \NOT(c)$\; \label{new-solver-creation}
                            $\textit{cexs}_m \gets \textit{cexs}_m \cup \{\textit{cex} \}$\;  \label{cex-dealing-ends}
                        }
                        }
                    }
                }
            {
                $\textit{found} \gets \textit{Synt}(i+1,\textit{PS}^0, \dots, \textit{PS}^n, k)$\; \label{recursive-call}
                \lIf{$\textit{found} \neq \emptyset$}{\Return{$\textit{found}$}}
            
            }
            }
        }
    }
\Return{$\emptyset$}\;
}
\end{algorithm*}

$\refin{\mathit{PS},T} \oplus \NOT(c)$ identifies the refinements of $T$ that do not have path $c$, as proved by the following theorem.

\begin{theorem}\label{theorem:cex-entails} Let $\mathit{PS}$ and $T$ be a specification and an LTS, respectively, such that $T \vDash \mathit{PS}$, and $c = s_0,\dots, s_m \in \Path{T}$ , with $s_i \neq s_{i+1}$ for some $i$. Then:
$
	\refin{\mathit{PS},T} \oplus \NOT(c)  \nvDash \CNF(c).
$
\end{theorem}
	
Given LTSs $\{ T^i \}_{i \in \mathcal{I}}$ and a finite path $\pi = s_0, \dots, s_m \in \Path{\parallel_{i \in \mathcal{I}} T^i}$, we denote by $\pi {\uparrow} i$ the path projected to an execution of process $T^i$, defined as  $\pi {\uparrow} i = s_0 {\uparrow} i, \dots, s_m {\uparrow} i$. Projecting a global execution may introduce stuttering steps in local executions. The projections of a global execution form a tuple  $\langle \pi{\uparrow}i \rangle_{i \in \mathcal{I}}$, that will be used to refine the instances obtained via the satisfiability solver. 

	The synthesis algorithm is described in Alg.1. The algorithm uses the Alloy model finder (aka, Alloy solver) to get instances of the  specifications,  
This procedure takes as input an index ($i$) indicating the specification being processed, the collection of process specifications ($\textit{PS}^0,\dots,\textit{PS}^n$), the global property  ($\phi$), a bound on the number of states of the processes to be synthesized ($k$). It performs a backtracking search over all the process instances for each specification. For a given $i$, a queue $Q_i$ stores the current model finder and the set of the found counterexamples. The loop of line \ref{while-loop} inspects all the instances of specification number $i$. For each instance $M_i$ obtained, a model finder is created for the specification $\textit{Ref}(\textit{PS}^i, M_i)$ (capturing the refinements of $\textit{PS}^i$), and it is pushed onto the stack, together with an empty collection of
counterexamples. Then, the loop of line \ref{while-loop} iterates over the elements of $Q_i$, the main idea here is that the model finders on the top of the stack work over strengthened specifications, and so these Alloy solvers have less instances to find than the ones placed  above in the stack.  Also, note that the Alloy solver in the bottom of the stack considers no counterexamples and so it can be used to get all the instances of the original specification. The queue $Q_i$ guarantees that all the model finders will be eventually used, thus no instance of the specification will be skipped.
	In line \ref{solver-popped} the current Alloy solver and the accompanying counterexamples are stored in variables $(\textit{solver}_i, \textit{cexs}_i)$, afterwards all
	the instances of $\textit{solver}_i,$ are inspected. If $i=n$ (line \ref{base-case}), this is the base case and the algorithm checks whether the instances obtained for each process ($r_0,\dots,r_n$) satisfy the global property, returning a valid program, or adding the found counterexample to the set of counterexamples (lines \ref{cex-dealing-stars}-\ref{cex-dealing-ends}), before continuing with the search. Our approach uses counterexamples to improve the search in the following way: when a new counterexample is found, the procedure checks (for every process $m$) if the projection of the counterexample to process $m$ is disjoint or refines the counterexamples being under consideration for process $m$ (line \ref{cex-treatment}), in such a case, it adds the projected counterexample to the corresponding collection, and  it creates a new model finder for specification $\refin{\mathit{PS}^i,M_i}\oplus (\bigwedge_{c \in \mathit{cexs}_i} \NOT(c))$ (line \ref{new-solver-creation}), and the stack is updated (line \ref{}). If  $i \neq n$, this is no the base case, and the procedure calls itself recursively (line \ref{recursive-call}).




%
% for the current specification $M_i$
%
%
%
% \ref{for-loop} inspects all the instances of specification number $i$.
%For each instance $M_i$ obtained, a model finder is obtained for $\textit{Ref}(\textit{PS}^i,M_i)$ and then
%
%
%A queue $Q_i$ (for every instance $i$) is used to store the model finders and counterexamples used during the different phases of the search. For each instance $i$, $Q_i$
%
%
%
%A collection $\mathit{gcexs}$ is used to keep track of the found counterexamples. The loop of line $4$ inspects all the instances of specification number $i$. For each instance $M[i]$ obtained, we use two auxiliary sets: $\mathit{inCexs}[i]$ keeps track of the projections of the counterexamples found when dealing with the current instance (it behaves in a stack-like way); and $\mathit{outCexs}[i]$, used to save the counterexamples that were (unsuccessfully) taken into account during the iterations. Then, all the instances of $\refin{\mathit{PS}^i,M[i]}\oplus (\bigwedge_{c \in \mathit{inCexs}[i]} \NOT(c))$ are inspected in the loop of line $7$. In the first iteration, $\bigwedge_{c \in \mathit{inCexs}[i]} \NOT(c) = \textit{true}$, since $\mathit{inCexs}[i]$ is empty. In line $17$, the procedure calls itself recursively until the last specification is reached ($i=n$). At this point, the algorithm checks if the instances obtained for each process ($r[0],\dots,r[n]$) satisfy the global property, returning a valid program, or adding the found counterexample to the set of counterexamples, before continuing with the search. 
%	 
%Our approach uses counterexamples to improve the search in two ways: \emph{(i)} if a disjoint counterexample is found, we restart the search adding the new counterexample to $\mathit{inCexs[i]}$ for every $i$ (call to $\mathit{UpdateCexs}$ in line $13$). If a counterexample refining some counterexample in $\mathit{gcexs}$ is found (line $14$), the latter is changed by the former, i.e., we refine the set of counterexamples (represented by call to $\mathit{RefineCex}$). More detailed algorithmic descriptions of these counterexample processing mechanisms are deferred to the Appendix (Algs. 2 and 3), due to space restrictions.  

%A particular case arises when the found counterexample is only disjoint with the current one (line $2$ in function \textit{UpdateCex}), in which case we add the corresponding counterexample to $\mathit{inCexs}_n$ and the search is resumed. For the other specifications (that is, if $i<n$), if no program was found then either new counterexamples were added to $\mathit{inCexs_i}$, in which case the Alloy solver will search for instances over a refined specification (line $7$); or no further counterexamples were added to $\mathit{inCexs}_i$ and the stack is popped. The stack is used to strengthen the specification, so that the instance finding process can be more efficient. 
	  
The soundness of this algorithm is direct, since a model checker is used to verify the output. Termination is guaranteed by the fact that both,  the number of instances of specifications, and the number of possible counterexamples are finite, thus the loops of lines \ref{solver-loop} and \ref{while-loop} terminate. Bounded completeness follows from the queue policy used in the algorithm, in the worst case all the instances for the specifications are inspected

\begin{theorem}\label{theorem:cex-completeness} Alg.1 terminates, is sound and (bounded-)complete.
\end{theorem}
\fi

	
	
