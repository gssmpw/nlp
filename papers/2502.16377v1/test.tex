\begin{table*}[th!]
\centering\small
\resizebox{\linewidth}{!}{%
\begin{tabular}{lcccccccccccc}
\toprule
                      & \multicolumn{6}{c}{\textbf{Trigger}} & \multicolumn{6}{c}{\textbf{Argument}} \\ \cmidrule(l){2-7} \cmidrule(l){8-13} 
 &
  \multicolumn{3}{c}{\textbf{Identification}} &
  \multicolumn{3}{c}{\textbf{Classification}} &
  \multicolumn{3}{c}{\textbf{Identification}} &
  \multicolumn{3}{c}{\textbf{Classification}} \\
  \cmidrule(l){2-4} \cmidrule(l){5-7} \cmidrule(l){8-10} \cmidrule(l){11-13}
{} &
  \textbf{Precision} & \textbf{Recall} & \textbf{F1} &
  \textbf{Precision} & \textbf{Recall} & \textbf{F1} &
  \textbf{Precision} & \textbf{Recall} & \textbf{F1} &
  \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
  \midrule
\textbf{BERT-based Sequence Labeling} &  0.581   &   \textbf{0.499}   &   \textbf{0.537}   &  0.566   &  \textbf{0.486}   &  \textbf{0.523}   &   0.491   &  \textbf{0.403}    &  \textbf{0.454}    &   0.355   &   \textbf{0.383}  &  \textbf{0.368}   \\
\hspace{5mm} {w/ ground-truth triggers} & - & - & - & - & - & - & 0.653      & 0.671      & 0.662      & 0.642       & 0.660       & 0.651 \\
\hspace{5mm} {w/o email thread history} & 0.577 & 0.493 & 0.531 & 0.532 & 0.483 & 0.506 & 0.488 & 0.397 & 0.438 & 0.335 & 0.380 & 0.356\\
\textbf{BART-based Generative Extraction}   &  \textbf{0.701}   &    0.395   &   0.505   &  \textbf{0.701}   &   0.394   &  0.500   &   \textbf{0.592}   &  0.351    &  0.441    &   \textbf{0.374}   &   0.350  &  0.363  \\ 
\hspace{5mm} {w/ ground-truth triggers} & - & - & - & - & - & - & 0.690 & 0.482 & 0.568 & 0.688 & 0.471 & 0.560 \\
\hspace{5mm} {w/o email thread history} & 0.688 & 0.389 & 0.500  & 0.679  & 0.388 & 0.494 & 0.572 & 0.333 & 0.421 & 0.370 & 0.339 & 0.354 \\\midrule
\textbf{In-context Learning (GPT-3.5)} &      &       &       &     &      &     &      &      &       &      &    &      \\ 

\hspace{5mm}{text-davinci-003} &  0.167    &  0.171    &   0.169   & 0.100   &  0.101   &  0.100   &  0.068   &  0.069   &  0.068    &   0.058  &  0.06 &  0.058   \\
\hspace{8mm}{w/ ground-truth triggers} &  -    &  -    &   -   & -   &  -   &  -   &  0.379   &  0.356  & 0.367   &   0.349  &  0.33 &  0.338   \\
\hspace{5mm}{gpt-3.5-turbo} &  0.183    &  0.095    &   0.121   & 0.098   &  0.060   &  0.072   &  0.058   &  0.045   &  0.050    &   0.056  &  0.04 &  0.048   \\
\hspace{8mm}{w/ ground-truth triggers} &  -    &  -    &   -   & -   &  -   &  -   &  0.256   &  0.198   &  0.223    &   0.242  &  0.19 &  0.211   \\
% \hspace{5mm} {w/ ground-truth triggers} & - & - & - & - & - & - & & & & & & \\
% \hspace{5mm} {w/o email thread history} &  &  &  &  &  &  & & & & & & \\
\bottomrule
\end{tabular}
}
\caption{Results on \dataset test set. For each fine-tuned model, we also report its argument extraction performance when feeding ground-truth triggers (``{w ground-truth trigger}''), and its overall performance when the email thread history is ablated (``w/o email thread history''). For experiments involving ``ground-truth triggers'' with both the BART- and In-context Learning-based approaches, we feed the templates iteratively one by one.}
\label{tab:all_results}
\end{table*}