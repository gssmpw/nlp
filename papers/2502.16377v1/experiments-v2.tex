\section{Experiments}

\input{experimental-setup-v3}

\input{e2e_full}
\subsection{RQ1: Do the annotation guidelines allow an LLM to more precisely extract occurring events?}
To assess the impact of incorporating annotation guidelines in the EE instructions, we compare instruction-tuning an LLM with and without guidelines. We hypothesize that including the annotation guidelines can help the LLM more easily distinguish between similar event types. To understand its impact, we also compare this approach with a ``negative sampling (NS)'' approach. Specifically, we instruction-tune the LLM on an augmented training set, where each training example is supplemented with 15 randomly selected negative samples, i.e., triplets of $(e_{neg}, X, \phi)$ with non-existing event type $e_{neg}$ yielding empty extraction output. We note that annotation guidelines and negative sampling are two complementary approaches for an LLM to learn to distinguish between event types. In our experiments, we thus evaluated the effect of annotation guidelines in two independent settings: (1) training on the original training set (\textbf{w/o NS}) and (2) training on the negative sample-augmented training set (\textbf{w/ NS}).


Table~\ref{tab:full_train_table} shows the results.
In the \textbf{w/o NS} setting, including annotation guidelines (\textbf{Guideline-P}, \textbf{PN}, and \textbf{PS}) consistently improves performance across both datasets. Our analysis in Section~\ref{sec:analyais} further validated that the guidelines indeed enable the LLM to understand the nuanced differences between event types. On {ACE w/o NS}, \textbf{Guideline-P} achieves the highest scores across all four metrics, leading to around 10\% TC and 5\% AC gains over \textbf{NoGuideline}.
Similarly, on {RichERE w/o NS}, \textbf{Guideline-PN} outperforms \textbf{NoGuideline} by about around 5\% TC and 2\% AC.  

Training the LLM with augmented negative samples, as we expected, helps the model better distinguish between event types; for example, \textbf{NoGuideline} in the \textbf{w/ NS} setting achieves 30\% higher AC on ACE and 6\% higher AC on RichERE, compared to its counterparts in the \textbf{w/o NS} setting. 
However, the effects of annotation guidelines in the \textbf{w/ NS} setting diverge between the two datasets. For {ACE}, adding the guidelines in the instruction does not offer a further advantage, where \textbf{NoGuideline} and \textbf{Guideline-PN} achieved a comparable, the best performance, while all other guideline variants do not show to help. On RichERE, however, the benefit of annotation guidelines complements the negative samples', where \textbf{Guideline-PN} and \textbf{Guideline-PS} achieve around 25\% gain on AC over \textbf{NoGuideline}. We notice that RichERE is annotated with a smaller training set but defines more fine-grained event schemas than ACE; for example, the courser-grained \texttt{Transport} event type in ACE is represented by two event types, i.e., \texttt{TransportPerson} and \texttt{TransportArtifact}. As the guideline provides not only a detailed description of an event type but also a comparison with similar ones (Table~\ref{tab:guideline-examples}), the LLM can leverage this information for better EE performance.

\input{e2e_2000}
\input{e2e_100}
% \subsection{RQ2: Do Contrastive and Diverse Guidelines Improve Event Extraction?}
\subsection{RQ2: Are machine-generated annotation guidelines effective?}
Interestingly, from Table~\ref{tab:full_train_table}, we noticed that the guidelines provided by the ACE annotators do not yield a performance gain and that the machine-generated guideline variants are not equally effective. Specifically, \textbf{Guideline-H} achieves a comparable performance in \textbf{w/o NS} and an inferior one in \textbf{w/ NS} on ACE; \textbf{Guideline-PN-Int} and \textbf{Guideline-PS-Int} provide either no or limited performance gain in both \textbf{w/o NS} and \textbf{w/ NS} settings, while \textbf{Guideline-P} and \textbf{Guideline-PS} are not consistently better than \textbf{NoGuideline}. \textbf{Guideline-PN} shows to be the most stable, outperforming \textbf{NoGuideline} on RichERE and performing comparably to the best model on ACE.

Qualitatively, as shown in Table~\ref{tab:guideline-examples}, the human-written guidelines (\textbf{Guideline-H}) lack explicit contrasts, making event boundaries ambiguous—for instance, \texttt{Transport} (a movement event) and \texttt{Extradite} (a justice event) both involve relocation, yet the fact that only the latter is legally enforced is not clarified in the guidelines.
% Still, only the latter is legally enforced. 
% Similarly, \textbf{Guideline-PS} focuses on sibling event types, such as \texttt{ChargeIndict} vs. \texttt{Convict}, yet fails to address distinctions across different event hierarchies, such as between movement-based versus legally driven ones. This suggests that sibling differentiation alone is insufficient. Meanwhile, \textbf{-Adv} variants underperform due to excessive consolidation, which collapses multiple distinctions into a single definition, diluting critical event contrasts. As shown in \citet{cai-etal-2024-improving-event}, exposure to diverse definitions improves event understanding, reinforcing why models trained with diverse definitions generalize better. By presenting varied definitions per training instance, these guidelines help models learn broader event boundaries and avoid overfitting to narrow schemas or lexical cues.
\textbf{Guideline-P} provides examples and edge cases of the target event, but these may not be sufficient for the model to distinguish between similar event types. While both \textbf{Guideline-PS} and \textbf{Guideline-PN} have supplied this comparison, \textbf{-PS} shows to be limited by focusing on only sibling differentiations (e.g., \texttt{Extradite} vs. \texttt{Convict}). Finally, surprisingly, the two \textbf{-Int} variants, despite being comprehensive, lead to mixed results. We observed that models tend to overfit to these comprehensive instructions. In contrast, training the models with 5 diverse guidelines per event type as in \textbf{-PN} and \textbf{-PS} avoids this issue, which shares a similar finding as \citet{cai-etal-2024-improving-event, sainz2024gollie}.

% Qualitatively, as shown in Table~\ref{tab:guideline-examples}, \textbf{Guideline-H}, while compact, lack explicit contrasts between event types. For instance, ACE defines \textbf{Extradite} as the process of moving a \textbf{Person} to a foreign state for legal proceedings and \textbf{Transport} as ``{\highlight{F0F0F0}{whenever an ARTIFACT or a PERSON is moved from one PLACE to another.}}'' Since both involve movement, the distinction is ambiguous. In contrast, \textbf{Guideline-PN} explicitly differentiates them by adding a. On the other hand, we hypothesize that while diverse and contrastive definitions help LLMs generalize better, the \textbf{-Adv} variants—generated by consolidating five machine-generated guidelines into one—failed to maintain contrast between event types. By sampling from multiple definitions during training, \textbf{Guideline-PN} and \textbf{-PS} expose the model to more varied perspectives, enhancing generalization. 
% Future work should ensure contrast is preserved in consolidated guidelines.    

\subsection{RQ3: Are the annotation guidelines helpful when there is only a small amount of training data?}
% , making it essential to determine how much data is necessary for effective training. 
With 2000 samples (Table~\ref{tab:train2000_table}), \textbf{Guideline-P}, \textbf{Guideline-PN} and \textbf{Guideline-P} improve \textbf{NoGuideline} on ACE and RichERE w/o NS by up to 30\% TC and 20\% AC. Unlike our observation on the full-training setting, this trend also holds in \textbf{ACE w/ NS}, where guidelines provide a similar advantage. 
Excitingly, the results also show that annotation guidelines can compensate for limited training data, enabling models trained with only 2000 samples to achieve performance comparable to full-data training. For example, on ACE, \textbf{Guideline-P w/ NS (2k)} outperforms \textbf{NoGuideline w/o NS (full)} by 10\% AC; on RichERE, \textbf{Guideline-PN w/ NS (2k)} outperforms \textbf{NoGuideline (full)} by 18\% AC in ``w/o NS '' and 12\% AC in ``w/ NS''.
% \swetac{For example, Guideline-P w/ NS (2000 samples) outperforms NoGuideline w/o NS (full training data) by up to 10.78\% AC on ACE and 16.71\% AC on RichERE.} This is particularly crucial since high-quality annotated data is often scarce.


%\srivc{\textbf{Guideline-P} and \textbf{Guideline-PN} in \textbf{w/ NS} with 2000 train samples outperform both \textbf{NoGuideline} and \textbf{Guideline-H} in \textbf{w/o NS} by about 5\% and 10\% AC on ACE and RichERE, respectively.} 

However, when training data is reduced to 100 samples (Table~\ref{tab:train_100_results}), the benefits become dataset-dependent. In \textbf{ACE w/ NS}, \textbf{NoGuideline} slightly outperforms guideline-based models, suggesting that with extremely limited data, the model resorts to memorization rather than learning schema constraints. In contrast, in \textbf{RichERE w/ NS}, which has more diverse and fine-grained event structures, guidelines remain beneficial—\textbf{Guideline-PN} surpasses \textbf{NoGuideline} by 2\% AC, indicating that guidelines help in settings where direct memorization is insufficient.

\input{cross_dataset_transfer}
%we can highlight that 2k w NS can be better than full wo NS
\subsection{RQ4: Do annotation guidelines improve cross-schema generalization?}
% \zyc{model generalizability? not sure yet. if we have time, pick 1 model and limited settings (based on what we want to highlight..but I'm still waiting for the results)}
% \zyc{Unclear what msgs you want to deliver here.}
In Table~\ref{tab:RQ4_f1_scores}, we evaluate different variants' generalizability to a new schema in EE. Notably, while ACE and RichERE share the same domain, RichERE has a finer schema design.
{In \textbf{RichERE w/o NS → ACE}, performance remains below the in-distribution baseline. 
% with \textbf{Guideline-PN} achieving 40\% TC and 19\% AC, indicating moderate transferability but still falling short. While TC reaches 40\%, 
While \textbf{Guideline-PN} achieves 40\% TC, nearly matching the in-distribution score, its AC drops by nearly 10\%, likely due to RichERE’s expanded argument roles that do not always align well with ACE’s simpler schema. This suggests that fine-to-coarse schema migration is partially feasible but still faces challenges in argument mapping. Contrastive learning helps mitigate some of this gap, as seen in \textbf{Guideline-PS (w/ NS)}, which improves TC to 64\% and AC to 32\%, highlighting the benefits of structured alignment. In contrast, \textbf{ACE → RichERE} generalizes even better, with \textbf{Guideline-PN (w/ NS)} achieving 64\% TC and 44\% AC, surpassing the in-distribution baseline by over 22\% TC and 12\% AC. This suggests that training on ACE, which has well-defined event boundaries, provides a stronger foundation for adapting to RichERE’s more detailed schema. Since RichERE introduces additional argument roles for certain events in ACE, structured guidelines play a key role in preventing role confusion and ensuring more consistent schema adaptation.}
%We present error analysis and successful transfer examples in Appendix~\ref{X}.
