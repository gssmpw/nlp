\section{Discussion}
In this study, we presented a novel ProMRVL model by introducing a proactive dialogue framework and multi-modal analysis, addressing significant challenges in medical dialogue and image integration. The framework's research paradigm and practical applications offer substantial advancements, such as improving interaction quality and mimicking real-world medical evaluations. These contributions highlight ProMRVL's capability to handle complex dialogic interactions and its potential for broader impact in medical AI.


Evaluation results validate the system's effectiveness and robustness. Comparative experiments reveal that ProMRVL outperforms baseline methods, even when enriched with textual input as shown in Table \ref{ablation}. Additionally, the inclusion of a knowledge graph significantly enhances diagnostic precision and recall metrics (i.e., BLEU and ROUGE), while maintaining professionalism and conciseness. Further experiments in Table \ref{exp_noise_input} and Table \ref{textual_model_scales} demonstrate the model's resilience to data variability, including low-resolution and noisy inputs, and its scalability, achieving satisfactory performance despite a significant reduction in system complexity using LoRA.