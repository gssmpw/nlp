\section{Conclusion}
This paper devises a proactive dialogue system, ProMRVL-CAD, with the unique multi-modality feature of processing both clinical visuals and medical dialogue for disease diagnosis. The proposed model deploys a novel proactive question generator to mimic the nature of proactive dialogue during conventional patient-doctor interactions to collect the patients' health conditions. Our model has the superior performance of handling multi-image input over conventional LLMs with a nature of multi-round conversation. Evaluating on two publicly available datasets, we demonstrate that ProMRVL-CAD outperforms state-of-the-arts in generating medical reports. Our framework also creates the first synthetic proactive dialogue that integrates both medical visuals and patients' textual health status information from the existing clinical dataset. Future work will focus on implementing the system across multiple datasets empowered by federated learning. 