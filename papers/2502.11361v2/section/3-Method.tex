
\section{\underline{V}ision \underline{L}anguage \underline{D}isinformation Detection \underline{Bench}mark}  
\label{method}  
\textsf{\textbf{\textsc{VLDBench}}} (Figure~\ref{fig:vlbias}) is a comprehensive classification multimodal benchmark for disinformation detection in news articles. It comprises 31,339 articles and visual samples curated from 58 news sources ranging from the Financial Times, CNN, and New York Times to Axios and Wall Street Journal as shown in Figure \ref{fig:news_sources_distribution}. \textsf{\textbf{\textsc{VLDBench}}} spans 13 unique categories (Figure \ref{fig:news_categories}) : \textit{National, Business and Finance, International, Entertainment, Local/Regional, Opinion/Editorial, Health, Sports, Politics, Weather and Environment, Technology, Science, and Other} —adding depth to the disinformation domains. We present the further statistical details in Appendix \ref{app:data-analysis}.
 
\subsection{Task Definition}
\textbf{Disinformation Detection:}  
The core task is to determine whether a text–image news article contains disinformation. We adopt the following definition:  

\emph{“False, misleading, or manipulated information—textual or visual—intentionally created or disseminated to deceive, harm, or influence individuals, groups, or public opinion.”}  

This definition aligns with established social science research \cite{benkler2018network} and governance frameworks \cite{unesco2023journalism}. We specifically focus on the `intent' behind disinformation, which remains relevant over time but has broader effects beyond just being factually incorrect.
\begin{figure*}
    \centering
    \includegraphics[width=0.95\textwidth]{figures/qualitative_figure.pdf}
    \vspace{-1em}
\caption{Disinformation Trends Across News Categories: We analyze the likelihood of disinformation across different categories, based on disinformation narratives and confidence levels generated by GPT-4o.}
    \vspace{-1em}
    \label{fig:disinfo-analysis}
\end{figure*}
\subsection{Data Pipeline}  
\textbf{Dataset Collection:}  
From May 6, 2023, to September 6, 2023, we aggregated data via Google RSS feeds from diverse news sources (Table~\ref{tab:sources}), adhering to Google’s terms of service \cite{google_tos}. We carefully curated  high-quality visual samples from these news sources to ensure a diverse representation of topics. All data collection complied with ethical guidelines \cite{uwaterloo_ethics_review}, regarding intellectual property and privacy protection. 

\textbf{Quality Assurance.}  
Collected articles underwent a rigorous human review and pre-processing phase. First, we removed entries with incomplete text, low-resolution or missing images, duplicates, and media-focused URLs (e.g., \texttt{/video}, \texttt{/gallery}). Articles with fewer than 20 sentences were discarded to ensure textual depth. For each article, the first image was selected to represent the visual context. We periodically reviewed the quality of the curated data to ensure the API returned valid and consistent results. These steps yielded over 31k curated text-image news articles that are moved to the annotation pipeline.

\subsection{Annotation Pipeline}  
To the best of our knowledge, \textsf{\textbf{\textsc{VLDBench}}} is the largest and most comprehensive humanly verified disinformation detection benchmark with over 300 hours of human verification. Figure \ref{fig:vlbias} shows our semi-annotated, data collection and annotation pipeline. After quality assurance, each article was prompted and categorized by GPT-4o as either \texttt{Likely} or \texttt{Unlikely} to contain disinformation, a binary choice designed to balance nuance with manageability. To ensure reliability, GPT-4o assessed text-image alignment three times per sample—first, to minimize random variance in its responses, and second, to resolve potential ties in classification, with an odd number of evaluations ensuring a definitive outcome. GPT-4o was chosen for this task due to its demonstrated effectiveness in both textual \cite{kim2024meganno+} and visual reasoning tasks \cite{shahriar2024putting}. An example is shown in Figure \ref{fig:disinfo-analysis}.

We categorized our data into 13 unique news categories (Figure \ref{fig:news_categories}) by providing image-text pairs to GPT-4o, drawing inspiration from AllSlides \cite{allsides_mediabiaschart}  and frameworks like Media Cloud \cite{media_cloud}. The dataset statistics are given in Table~\ref{tab:dataset_statistics}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/news_categories_distribution.pdf}
    \caption{Category distribution with overlaps. Total unique articles = 31,339. Percentages sum to \(>100\%\) due to multi-category articles.}
    \label{fig:news_categories}
    \vspace{-1em}
\end{figure}

To ensure high-quality benchmarking, a team of 22 domain experts (Appendix~\ref{app:team}) systematically reviewed the GPT-4o labels and rationales, assessing their accuracy, consistency, and alignment with human judgment. This process included a rigorous structured reconciliation phase, refining annotation guidelines and finalizing the labels. The evaluation resulted in a Cohen’s $\kappa$ of 0.78, indicating strong inter-annotator agreement.


\paragraph{Stability of Automatic Annotations:} To assess the reliability of automated annotations, we conducted a controlled experiment comparing GPT-4o labels with those of human annotators. We randomly selected 1,000 GPT-4o-annotated samples from the previous step, provided annotation guidelines, and asked domain experts (without showing the GPT-4o labels) to manually annotate them. Comparing both sets of labels, GPT-4o achieved an F1 score of 0.89 and an MCC of 0.77, while human annotators scored F1 = 0.92 and MCC = 0.81 (Figure~\ref{fig:alignment_metrics}). These results demonstrate the effectiveness of our semi-annotated pipeline, aligning well with human judgment and ensuring reliable automated labeling.

\input{tables/stats}
