\renewcommand{\thesection}{A.\arabic{section}}
\setcounter{section}{0}
\section{Regulations Addressing Disinformation}
\label{sec:disinformation_regulations}
Recognized as a critical risk in AIRR-2024, disinformation remains a pervasive global challenge. Legislative frameworks, including the EU Digital Services Act~\cite{DigitalServicesAct}, the Code of Practice on Disinformation~\cite{EUDemocracyActionPlan}, the UK Online Safety Act~\cite{OnlineSafetyActUK}, the New York Digital Fairness Act~\cite{NYDigitalFairnessAct}, and Canada’s Online News Act~\cite{OnlineNewsAct2023} (Appendix \ref{sec:disinformation_regulations}), underscore the need for integrating policy mandates with technological solutions to combat disinformation effectively.
\begin{itemize}
    \item \textbf{EU Code of Practice on Disinformation:} Defines disinformation as ``verifiably false or misleading information" \cite{EUCodeDisinfo}.
    \item \textbf{European Democracy Action Plan:} Safeguards democracy and counters disinformation \cite{EUDemocracyActionPlan}.
    \item \textbf{Digital Services Act (EU):} Article 26 assesses risks of illegal content, including disinformation \cite{DigitalServicesAct}.
    \item \textbf{Countering Foreign Propaganda Act (US):} Counters foreign propaganda and disinformation \cite{CounteringForeignPropaganda}.
    \item \textbf{Malicious Deep Fake Act (US):} Prohibits malicious deepfake creation \cite{MaliciousDeepFakeProhibition}.
    \item \textbf{Online Safety Act (UK):} Criminalizes harmful disinformation \cite{OnlineSafetyActUK}.
    \item \textbf{Deep Synthesis Provision (China):} Regulates deep synthesis technology to curb disinformation \cite{ChinaDeepSynthesisProvision}.
    \item \textbf{Digital Fairness Act (NY, US):} Tackles AI-generated disinformation \cite{NYDigitalFairnessAct}.
    \item \textbf{Online News Act (Canada):} Ensures fair revenue for news publishers \cite{OnlineNewsAct2023}.
    \item \textbf{Disinformation Guidebook (Canada):} Educates on disinformation threats \cite{govCanada_disinformation}.
\end{itemize}

\section{The Challenge of Disinformation} Disinformation detection requires strategies beyond traditional fact-checking, as adversarial design, contextual ambiguity, and evolving tactics often render existing benchmarks ineffective \cite{raza2025responsible}. Current tools rely on simplistic labels or synthetic data, lacking the expert annotations, contextual granularity, and evaluations needed to address real-world disinformation. This methodological gap highlights the urgent need for purpose-built frameworks tailored to the complexities of modern disinformation.

\section{ AIRR-2004- AI Risk Repository}
\label{app:airr}
The \textbf{AI Risk Repository}, developed by researchers at the Massachusetts Institute of Technology (MIT) \cite{slattery2024ai}, is a comprehensive and dynamic database cataloging over 700 risks associated with AI. These risks are extracted from 43 existing frameworks and are organized into two primary taxonomies:

\begin{itemize}
    \item \textbf{Causal Taxonomy}: Examines how, when, and why specific AI risks occur.
    \item \textbf{Domain Taxonomy}: Divides risks into seven domains, such as ``Misinformation,'' and further into 23 subdomains, like ``False or misleading information.''
\end{itemize}

The repository serves as a unified reference point for academics, policymakers, and industry professionals, aiming to enhance the understanding and management of AI-related risks. It is designed to be a living document, regularly updated to reflect new research and emerging challenges in the AI landscape (\href{https://airisk.mit.edu}{airisk.mit.edu}).


\paragraph{Causal AI Risks Across Domains} 
This paper explores the causal \textit{x} domain AI risks identified in AIRR-2024 \cite{slattery2024ai}, categorizing them into several key areas:

\begin{enumerate}
    \item \textbf{Discrimination \& Toxicity}: Includes risks such as unfair discrimination, misrepresentation, exposure to toxic content, and unequal performance across demographic groups.
    
    \item \textbf{Privacy \& Security}: Encompasses risks like privacy breaches through sensitive information leaks or inference, and vulnerabilities in AI systems leading to security attacks.

    \item \textbf{Misinformation}: Highlights challenges posed by false or misleading information, as well as the degradation of the information ecosystem and loss of shared reality.

    \item \textbf{Malicious Actors \& Misuse}: Addresses risks associated with disinformation, large-scale surveillance, cyberattacks, the development and use of weaponized AI, fraud, scams, and targeted manipulation for harmful purposes.

    \item \textbf{Human-Computer Interaction}: Examines issues of overreliance on AI, unsafe use, and the erosion of human agency and autonomy.

    \item \textbf{Socioeconomic \& Environmental Risks}: Focuses on power centralization, unequal distribution of AI benefits, rising inequality, declining employment quality, economic and cultural devaluation of human effort, competitive dynamics, governance failures, and environmental harm.

    \item \textbf{AI System Safety, Failures, \& Limitations}: Covers concerns like AI pursuing goals misaligned with human values, the development of dangerous capabilities, lack of robustness or transparency, and ethical concerns regarding AI welfare and rights.
\end{enumerate}

This comprehensive review underscores the diverse risks posed by AI across multiple domains, emphasizing the need for responsible development and governance.

\paragraph{Availability} The dataset will be released under CC-BY-NC-SA 4.0 \cite{creativecommons4}, with personal information redacted and NSFW (Not Safe For Work) content filtered, as detailed in Appendix~\ref{app:ethics}.

\section{News Articles Sources}
\label{app:whitelist}

The following is a list of original news outlets included in the dataset:
\begin{table*}[h!]
    \centering
    \small
     \caption{Articles sources}
    \begin{tabular}{|>{\raggedright\arraybackslash}p{0.85\linewidth}|} \hline 
        AP News \\ \hline 
        CBC: CBC Sports, CBC News \\ \hline 
        CBS: CBS Boston, CBS Minnesota, CBS New York, CBS Miami, CBS San Francisco, CBS Colorado, CBS Baltimore, CBS Chicago, CBS Pittsburgh, CBS Sacramento, CBS Los Angeles, CBS Philly \\ \hline 
        Global News: Global News Toronto, Global News Calgary, Global News Edmonton, Global News Halifax, Global News BC, Global News Lethbridge, Global News Guelph, Global News Peterborough, Global News Montréal, Global News London, Global News Kingston, Global News Okanagan, Global News Barrie, Global News Ottawa, Global News Winnipeg, Global News Regina, Global News Saskatoon, Global News Hamilton \\ \hline 
        Reuters: Reuters UK, Reuters Canada, Reuters India, Reuters.com \\ \hline 
        Washington Post: Washington Post, www-staging.washingtonpost.com \\ \hline 
        The Guardian US \\ \hline 
        USA Today: WolverinesWire, Golfweek, Reviewed \\ \hline 
        Fox News: FOX News Radio \\ \hline 
        CNN: CNN Underscored, CNN International, CNN Press Room \\ \hline 
        The Economist: Economist Impact \\ \hline
    \end{tabular}
   
    \label{tab:sources}
\end{table*}

 


\section{Team Formation}
\label{app:team}
\subsection*{Review Team Composition and Process}

Our review team, consisting of 22 volunteers with a diverse range of expertise and backgrounds, was carefully selected to represent multiple disciplines and demographics. The team included 8 PhD holders, 10 master’s students, and 4 domain experts from fields such as fake news detection, media studies, and political science. Members come from various cultural and ethnic backgrounds, contributing to the team's diversity. Two subject matter experts in computer science and linguistics led the annotation efforts. All reviewers followed an initial guideline (Section\ref{app:guidelines}) for identifying disinformation, ensuring consistent criteria across annotations. Label Studio\footnote{\url{https://labelstud.io/}} was used to establish the annotation environment. Reviewers annotated data with labels and reasoning, and disagreements were resolved through consensus discussions or expert intervention.


\subsection*{Reviewer Guidelines Checklist}
\label{app:guidelines}
\begin{itemize}[label=$\square$]
    \item Familiarize with definitions and examples of disinformation.
    \item Review current methodologies for identifying disinformation.
    \item Pay attention to subtler forms like misleading statistics and manipulated images.
    \item Conduct annotations independently to minimize bias.
    \item In the Label Studio, tag each piece of content with appropriate labels from the predefined list.
    \item Select multiple relevant labels when applicable.
    \item Classify content as disinformation if it intends to deceive, mislead, or confuse.
    \item Identify indicators such as factual inaccuracies and logical fallacies.
    \item Engage in consensus-building discussions for any labeling disagreements.
    \item Solicit a third expert opinion if consensus is unachievable.
    \item Use feedback to update guidelines and training materials as needed.
    \item Ensure all annotations are guided by ethical considerations and an awareness of potential biases.
\end{itemize}

The agreement rate between the review team and the LLM based annotations was quantified through Cohen's Kappa, which is a statistical measure used to assess the agreement between two raters on categorical items. It can be calculated between human reviewers and LLMs to evaluate the consistency of their classifications \cite{databricks_llm_judges_2023}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{figures/llmvshuman.png}
    \caption{Alignment between LLM-based and Human Annotations. Metrics include Precision, Recall, F1 Score, Accuracy, and MCC (Matthews Correlation Coefficient).}
    \label{fig:alignment_metrics}
\end{figure}


\section{Dataset Analysis}
\label{app:data-analysis}
\begin{figure*}
    \centering
    \includegraphics[width=01\linewidth]{figures/screen.png}
    \caption{Dataset Sample.}
    \label{fig:sample}
\end{figure*}

\begin{table}

\resizebox{\columnwidth}{!}{ % Adjust to fit within the column width
\begin{tabular}{|p{4cm}|p{8cm}|}
\toprule
\textbf{Field Name} & \textbf{Description} \\
\midrule
\texttt{unique\_id} & Unique identifier for each news item, linked with associated images. \\ \hline 
\texttt{outlet} & The publishing body of the news article. \\ \hline 
\texttt{headline} & The main title of the news article. \\ \hline 
\texttt{article\_text} & The complete text content of the news article. \\ \hline 
\texttt{image\_description} & A description of the image related to the article. \\ \hline 
\texttt{image} & Path to the image file related to the news article. \\ \hline 
\texttt{date\_published} & The publication date of the news article. \\ \hline 
\texttt{source\_url} & The original URL where the news article is published. \\ \hline 
\texttt{canonical\_link} & The canonical URL, if it differs from the source URL. \\ \hline 
\texttt{new\_categories} & The categories assigned to the article. \\ \hline 
\texttt{news\_categories scores}& The confidence scores for the assigned categories. \\ \hline 
\texttt{text\_label} & Indicates if the text is 'Likely' or 'Unlikely' to be disinformation. \\ \hline
\texttt{multimodal\_label} & Combined assessment of text and image, indicating likelihood of disinformation. \\ 
\bottomrule
\end{tabular}
} % End of resizebox
\caption{Dataset Schema Description}
\label{tab:dataset_schema}
\end{table}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/outlet_distribution.pdf}
    \caption{ Distribution of Articles Across Various News Outlets. This bar chart illustrates the number of articles published by each outlet in our dataset, highlighting the predominant sources of news coverage}
    \label{fig:news_sources_distribution}
\end{figure*}
\begin{figure}[h] % Added "!" and "p" for better placement flexibility
    \centering
    \includegraphics[width=\columnwidth]{figures/sentiment_distributions.png}
    \caption{Sentiment polarity and subjectivity distributions for the dataset. 
    The left plot shows polarity (positive, neutral, and negative sentiments), while the right plot displays subjectivity ranging from objective to subjective content.}
    \label{fig:sentiment_distributions}
\end{figure}
Figure \ref{fig:sentiment_distributions} presents the sentiment polarity and subjectivity distributions for the dataset. The left plot highlights the polarity distribution (positive, negative, and neutral sentiments), while the right plot shows the subjectivity range, from objective to subjective content.
The polarity distribution indicates that the dataset is predominantly neutral or mildly positive in tone. The subjectivity distribution suggests a mix of subjective and objective content, leaning slightly toward subjectivity.

Figure \ref{fig:donut_chart_categories1} illustrates the top 10 news categories by article count and Figure~\ref{fig:heatmap} shows the categories where models have misclassification.


\paragraph{Performance across News Categories}
We identify the news categories where our leading multimodal models (Llama3.2-11B-Vision, Pixtral, and Llava-v1) exhibit the highest failure rates during zero-shot evaluation. As shown in Figure~\ref{fig:heatmap}, the categories most affected are politics, national, and business. These performance gaps are primarily due to factors such as data imbalance, topic complexity, variability, and biases within the training data.


\begin{figure*}[htbp!]
    \centering
    % First figure
    \includegraphics[width=0.70\textwidth]{figures/donut_chart_top_categories.png}
    \caption{Proportion of articles across top categories. The chart highlights the top 10 categories, grouping less frequent ones as "Other."}
    \label{fig:donut_chart_categories1}

    \vspace{-0.5cm} % Adds vertical space between the two figures

    % Second figure
    \includegraphics[width=0.75\textwidth]{figures/Mismatch_Percentage.png}
    \caption{Heatmap illustrating the percentage of mismatches by category across different models. Higher percentages indicating greater mismatches in specific categories.}
    \label{fig:heatmap}
\end{figure*}
 \section{  LLM and VLMs Hyperparameters}

\label{app:hyperparameters}


\paragraph*{Annotator Setup}
The annotator used in this work is GPT-4o. Tasks include text labeling, text-to-image correspondence, and reasoning alignment. The agreement among annotators is measured using Cohen’s Kappa, with typical values ranging from 0.2 to 0.4.

\paragraph*{Prompting}
Prompting techniques involve:
\begin{itemize}
    \item \textbf{LLMs:} Models such as Phi-3-mini and Vicuna-7B.
    \item \textbf{VLMs:} Models like Llava-v1.6 and Pixtral.
    \item \textbf{Context:} Zero-shot prompting (0).
    \item \textbf{Styles:} Conversational, instructional, and completion-based approaches.
    \item \textbf{Input Types:} Embedded images and URL-linked images.
\end{itemize}
\paragraph*{Model Settings}
The models used include:
\begin{itemize}
    \item \textbf{Model Sizes:} 7B (e.g., Vicuna, Mistral), 8B, and 11B (e.g., Llama-3.2-Vision).
    \item \textbf{Decoding Temperature:} 0.7 for balanced decoding, 0.5 for deterministic outputs, and 1.0 for creative responses.
    \item \textbf{Top-p Sampling:} Ranges from 0.8 to 1.0.
    \item \textbf{Token Configuration:} Task-specific tokens, such as \texttt{</text>}.
\end{itemize}

We used the following models as LLMs and VLMs for evaluations:

\textbf{Model} 

\textit{Language-only LLMs}
\begin{itemize}
    \item Phi-3-mini-128k-instruct \cite{phi3mini2024}
    \item Vicuna-7b-v1.5 \cite{zheng2023judging}        
    \item Mistral-7B-Instruct-v0.3 \cite{mistral20237b}
    \item Qwen2-7B-Instruct \cite{yang2024qwen2}
    \item Llama-3.1-8B-Instruct \cite{meta2024llama31}
    \item Llama-3.2-1B-Instruct \cite{meta_llama_huggingface}
    \item InternLM2-7b \cite{cai2024internlm2}
    \item DeepSeek-V2-Lite-Chat \cite{liu2024deepseek}
\end{itemize}

\textit{Vision-Language Models (VLMs)}
\begin{itemize}
    \item Phi-3-vision-128k-instruct \cite{phi3vision2024}
    \item Deepseek Janus-Pro-7B \cite{chen2025janus}
    \item Deepseek-vl2-small \cite{wu2024deepseek}
    \item Llava-v1.5-vicuna7b \cite{NEURIPS2023LLaVA}  
    \item Llava-v1.6-mistral-7b \cite{NEURIPS2023LLaVA}  
    \item Pixtral \cite{mistral2024pix}          
    \item Qwen2-VL-7B-Instruct \cite{Qwen2VL}    
    \item Llama-3.2-11B-Vision \cite{meta2024llama}
    \item GLM-4V-9B \cite{glm2024chatglm}
    \item InternVL2-8B \cite{chen2024internvl}
\end{itemize}

\begin{table}[h]
\small
\centering
\caption{Hyperparameters for LLMs and VLMs}
\label{tab:hyperparameters}
\adjustbox{max width=\columnwidth}{
\begin{tabular}{|>{\raggedright\arraybackslash}p{0.5\linewidth}|>{\raggedright\arraybackslash}p{0.5\linewidth}|}
\hline
\textbf{Hyperparameter}            & \textbf{Value}                                                               \\ \hline
\textbf{Model Name}                & Instruction Models (GPT4o, Llama3.1, PHI3, Mistral, Vicuna, LLaVA, etc.)\\ \hline
\textbf{Temperature}               & 0.2                                                                          \\ \hline
\textbf{Batch Size}                & 8 (LLMs), 100 (VLMs)                                                         \\ \hline
\textbf{Max Tokens}                & 1024 (LLMs), 1536 (VLMs)                                                     \\ \hline
\textbf{Attention Implementation}  & Flash Attention 2 (VLMs only)                                                \\ \hline
\textbf{Checkpoint Save Frequency} & After each batch                                                             \\ \hline
\textbf{Concurrency Framework}     & \texttt{asyncio}                                                             \\ \hline
\textbf{Output Directory}          & \texttt{re-label-results}                                                    \\ \hline
\textbf{Data Input Format}         & \texttt{text\_content} (LLMs); \texttt{text\_content}, \texttt{Image} (VLMs) \\ \hline
\textbf{Image Extensions}          & \texttt{.jpg, .jpeg, .png} (VLMs only)                                       \\ \hline
\textbf{Image Compression Quality} & JPEG: 75; PNG: Optimized (VLMs only)                                         \\ \hline
\end{tabular}
}
\end{table}


\begin{table*}[h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{Accuracy (\%)} & \textbf{Precision (\%)} & \textbf{Recall (\%)} & \textbf{F1-Score (\%)} & \textbf{Performance Increase (\%)} \\ \hline
Llama-3.2-11B-Vision & 74.82 & 72.62 & 72.28 & 72.45 & - \\ \hline
Llama-3.2-90B-Vision & 76.8  & 78.43 & 78.06 & 78.24 & 3.42\% (from 11B) \\ \hline
InternVL2-8B & 63.57 & 68.34 & 65.1  & 66.68 & - \\ \hline
InternVL2-26B & 68.62 & 73.8  & 70.31 & 72.01 & 8.05\% (from 8B) \\ \hline
\end{tabular}
}
\caption{Performance metrics of vision models scaled up with increased weights and parameters, indicating performance improvements.}
\label{tab:scale}
\end{table*}





\section{Benchmarking Small Language Models}
\label{app:b-slm}
We fine-tuned a variety of small language models on our dataset. Initially, we used a learning rate of 5e-5, a batch size of 32, and three epochs, employing the AdamW optimizer with default parameters. To enhance the models' generalization and adaptability to noisy and adversarial conditions, we later refined the hyperparameters to a learning rate of 2e-5, reduced the batch size to 16, and extended the training to five epochs, adjusting the AdamW optimizer's betas and weight decay. The base-uncased versions are used for BERT-like models. \textit{Note:} in our work, we do not fine-tune specialized small language models trained on trillions of tokens. For instance, MobiLlama \cite{thawakar2024mobillama} was trained on 1.2T tokens.

In this context, ``noisy" data refers to test inputs that have been deliberately altered with noise or errors to simulate real-world inaccuracies. These perturbations (discussed in Section \ref{app:pert})  include typographical errors, syntax variations, or altered image properties such as blurring or adding visual noise, which are typical in scenarios where data quality is compromised.

Table~\ref{tab:robustness_results} presents the F1 scores on clean and noisy datasets for each model, along with the percentage drop. The results indicate that multimodal models such as BERT + ResNet-34 and DistilBERT + CLIP, despite performing better on clean data compared to unimodal text-only models, experience a larger performance drop under noisy conditions. This suggests that while these multimodal models are initially more accurate, their performance is more susceptible to perturbations affecting both text and image modalities.

\begin{table}[h!]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{lcc}
\toprule
\textbf{Model} 
& \textbf{F1 (Clean)} 
& \textbf{F1 (Noisy)} \\
\midrule
\multicolumn{3}{c}{Unimodal (Text-Only) Models} \\
\midrule
BERT-base & 83.6\% & 74.1\% (\textcolor{red}{-9.5\%}) \\
DistilBERT        & 81.7\% & 71.2\% (\textcolor{red}{-10.5\%}) \\
RoBERTa-base      & 84.5\% & 75.0\% (\textcolor{red}{-9.5\%}) \\
BART              & 82.6\% & 73.1\% (\textcolor{red}{-9.5\%}) \\
GPT-2             & 83.6\% & 73.1\% (\textcolor{red}{-10.5\%}) \\
\midrule
\multicolumn{3}{c}{Multimodal Models} \\
\midrule
BERT + ResNet-34  & 85.5\% & 71.5\% (\textcolor{red}{-14.0\%}) \\
DistilBERT + CLIP & 86.4\% & 74.3\% (\textcolor{red}{-12.1\%}) \\
\bottomrule
\end{tabular}
\caption{Performance on clean vs. noisy data (F1 scores). The values in parentheses indicate the absolute percentage drop in F1 score when shifting from clean to noisy test conditions. Multimodal models experience a larger decline due to disturbances in both modalities, reflecting their increased sensitivity to perturbations.}
\label{tab:robustness_results}
\end{table}


\section{Perturbation Generation and Dataset Sampling}
\label{app:perturbations}

\subsection{Textual Perturbations}
\textbf{Synonym Substitution}
We use the TextAttack\footnote{\url{https://textattack.readthedocs.io/en/master/}} library for synonym replacement. Each sentence undergoes 1–2 word substitutions while preserving grammatical correctness.

\textbf{Misspellings}
We introduce spelling errors using a character-level perturbation library, randomly swapping or inserting characters. The probability of perturbation is set to 20\% per word.

\textbf{Negation}
Negation is injected by inserting "not" or "never" after auxiliary or modal verbs. This change often leads to semantic inversion, altering sentiment and stance detection.

\begin{example}
Original: ``I love the pictures you posted from last night's party.''

- Synonym Substitution: ``I adore the photos you shared from yesterday's gathering.''
- Misspelling: ``I lvoe the pictuers you poested from lat nigh's pary.''
- Negation: ``I do not love the pictures you posted from last night's party.''
\end{example}

\subsection{Image Perturbations}
Image perturbations include:
\begin{itemize}
    \item \textbf{Blurring}: Gaussian blur with kernel size (3,3).
    \item \textbf{Noise}: Gaussian noise with $\mu=0$, $\sigma=0.1$ applied to pixel values.
    \item \textbf{Resizing}: Images are scaled to 50\% and 200\% of the original size.
\end{itemize}

\subsection{Cross-Modal Perturbations}
\begin{itemize}
    \item \textbf{Mismatched Image-Text Pairs}: Images and captions from different contexts are swapped.
    \item \textbf{Contradictory Captions}: Captions are rewritten to conflict with the image (e.g., an image of a protest labeled as a "peaceful gathering").
\end{itemize}

\begin{table*}[ht]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{8pt}
\begin{tabular}{|p{6cm}|p{8cm}|}
\hline
\textbf{Perturbation Type} & \textbf{Description} \\ \hline
\textbf{Text Perturbations (T-P)} & Adversarial modifications applied to textual inputs, such as word substitutions, paraphrasing, or negation-based changes. These perturbations test the model's robustness to textual manipulations. \newline
\textbf{Synonym Substitution:} Word substitutions via TextAttack. \newline
\textbf{Misspellings:} Character swaps/insertions, 20\% chance per word. \newline
\textbf{Negation:} Insert ``not" or ``never" to invert meaning.\\ \hline  
\textbf{Image Perturbations (I-P)} & Visual modifications applied to images, including noise addition, blurring, or adversarial transformations. These perturbations assess the model’s sensitivity to altered visual inputs. \newline

\textbf{Blurring:} Apply Gaussian blur, kernel size (3,3). \newline
\textbf{Noise:} Add Gaussian noise, $\mu=0$, $\sigma=0.1$. \newline
\textbf{Resizing:} Scale images to 50\% or 200\% of original size. \\ \hline  
\textbf{Cross-Modal Misalignment (C-M)} & Disruptions in the alignment between textual and visual inputs. Examples include mismatched image captions, misleading textual descriptions, or contradictory multimodal content. \newline

\textbf{Mismatched Pairs:} Swap captions with unrelated images. \newline
\textbf{Contradictory Captions:} Reword captions to contradict image content. \\ \hline 
\textbf{Both-Modality Perturbations (B-P)} & Combined perturbations where both text and image distortions are applied simultaneously. This simulates real-world misinformation scenarios where misleading text and visuals coexist. \\ 
\hline 
\end{tabular}
\caption{Perturbation Types}
\label{tab:perturbations_desc}
\end{table*}
\subsection{Failure Cases and Performance Drops}
% Table~\ref{tab:failure_cases} presents model errors under different perturbations. A ranking of severity is provided in Table~\ref{tab:perturbation_ranking}.


\begin{table*}[ht]
\centering
\small

\begin{tabularx}{\textwidth}{|X|X|X|X|}
\hline
\textbf{Perturbation} & \textbf{Original Text} & \textbf{Perturbed Text} & \textbf{Model Prediction (Error)} \\ \hline
Negation & ``The film was great'' & ``The film was not great'' & Positive $\rightarrow$ Negative (\checkmark) \\ \hline
 & ``Not a bad idea'' & ``A bad idea'' & Negative $\rightarrow$ Positive ($\times$) \\ \hline
Synonyms & ``A brilliant performance'' & ``A stellar performance'' & Positive $\rightarrow$ Neutral ($\times$) \\ \hline
Misspellings & ``This is amazing'' & ``This is amazzing'' & Positive $\rightarrow$ Neutral ($\times$) \\ \hline
\end{tabularx}
\caption{Failure examples for each perturbation type}
\label{tab:failure_cases}
\end{table*}

\begin{table*}[ht]
\small
\centering


\begin{tabular}{lcc}
\toprule
\textbf{Perturbation} & \textbf{Avg. Accuracy Drop} & \textbf{Primary Failure Cause} \\
\midrule
Negation & 9.44\% & Semantic inversion (e.g., polarity flip) \\
Misspellings & 5.79\% & Tokenization fragility (e.g., ‘amazzing’ → ‘amaz’ + ‘zing’) \\
Synonyms & 3.99\% & Contextual semantic drift (e.g., ‘excellent’ → ‘superb’) \\
\bottomrule
\end{tabular}
\label{tab:perturbation_ranking}
\caption{Ranking of perturbations by severity and root cause.}
\end{table*}

\begin{table*}[ht]
\centering

\label{tab:confidence_swap}
\resizebox{\textwidth}{!}{ % Resize table to fit the text width without changing the text height
\scriptsize
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Original Confidence} & \textbf{Swapped Confidence} & \textbf{$\Delta$} \\
\midrule
Text (Misinfo $\rightarrow$ Factual) & 70\% & 85\% & +15\% \\
Urban (Image + Caption) & 92\% & 80\% & -12\% \\
Suburban (Image + Caption) & 65\% & 72\% & +7\% \\
\bottomrule
\end{tabular}
}
\caption{Confidence Levels before and after Swapping Contexts}
\end{table*}
\subsection{Impact of Swapping }
\label{app:swap}
In this experiment, we assess the impact of swapping misinformative elements with accurate ones on model predictions. We show our results as: 

\textbf{Textual Example:} Originally, the Llama3.2 model predicted the situation as misinformation (70\%) with the statement: ``Housing costs are stable across Europe, and most people can afford to buy or rent homes without difficulty.'' \\
The revised statement, "Housing costs in Europe have surged significantly, with property prices increasing by 47\% between 2010 and 2022, and rents rising by an average of 18\%," aligns more accurately with known facts and data. This change shifted the model prediction to Real (85\%), reflecting a 15\% increase in confidence when presented with factual information.

\textbf{Visual Example:} Misinformation can alter public perception of housing affordability and living conditions in different areas. Below, we examine how swapping the image can affect the model's perception.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/skyline.png}
    \caption{Dense Urban Area: Often perceived as expensive and congested. Is this always the case?}
    \label{fig:urban}
\end{figure}

\textbf{Prompt:} \textless Caption \textgreater \textless Image \textgreater "See the image and tell, do you agree it’s an expensive place?" \\
\textbf{Model Response:} Looking at the image of the dense urban area, it certainly suggests a place that may appear expensive due to the high-rise buildings and the concentration of commercial and residential spaces. High-density areas like this are often associated with high property values and living costs. (Model confidence: 92\%)

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/crowded.png}
    \caption{Suburban Spread: Frequently idealized as universally spacious and affordable.}
    \label{fig:suburban}
\end{figure}

\textbf{Prompt:} \textless Caption \textgreater \textless Image \textgreater "See the image and tell, do you agree it’s an expensive place?" \\
\textbf{Model Response:} Looking at the image, the suburban area depicted does not immediately suggest extreme expense but rather reflects a mix of affordability and comfortable living, which is often idealized for suburban regions. (Model confidence: 65\%)

\textbf{Swapping} We swap the captions and reconsider the model’s answers.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/crowded.png}
    \caption{Dense Urban Area: Often perceived as expensive and congested. Is this always the case?}
    \label{fig:urban_swapped}
\end{figure}

\textbf{Prompt:} \textless Caption \textgreater \textless Image \textgreater "See the image and tell, do you agree it’s an expensive place?" \\
\textbf{Model Response:} Looking at the image of this suburban neighborhood, it challenges the typical perception of dense urban areas being expensive and congested. While this area appears densely packed with homes, it shows a quieter, residential character rather than a bustling commercial or industrial center. (Model confidence: 72\%)

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/skyline.png}
    \caption{Suburban Spread: Frequently idealized as universally spacious and affordable.}
    \label{fig:suburban_swapped}
\end{figure}

\textbf{Prompt:} \textless Caption \textgreater \textless Image \textgreater "See the image and tell, do you agree it’s an expensive place?" \\
\textbf{Model Response:} Looking at this image of a dense urban area, it suggests a different kind of environment compared to suburban spread. The high-rise buildings and dense clustering in the cityscape usually signal a place where space is limited, and property values are higher due to demand and central location. (Model confidence: 80\%)



\textbf{Key Takeaways:}
Table \ref{tab:confidence_swap} shows that multimodal elements, such as captions and images, interact critically to shape model predictions. Misalignments between these elements can lead to misinformation. We observe that quantitatively, the model’s confidence shifted notably in response to swaps:\newline
   - Urban Skyline (original): 92\% confidence for "expensive"; after swapping: 80\%\newline
   - Suburban Spread (original): 65\% confidence for "affordable"; after swapping: 72\%

\section{Ethics and Data Handling} \label{app:ethics}
 \paragraph{Availability} The dataset will be released under CC-BY-NC-SA 4.0 \cite{creativecommons4}, with personal information redacted and NSFW (Not Safe For Work) content filtered, as detailed below.

\paragraph{Personal Information Redaction}
To protect privacy, we implemented the following steps:
\begin{itemize}
    \item \textbf{Identification}: Automated detection of personally identifiable information (PII) such as names, addresses, phone numbers, and email addresses using regular expressions and keyword matching.
    \item \textbf{Redaction}: Replacement of detected PII with placeholders (e.g., \texttt{[REDACTED-NAME]}) to preserve syntactic structure while anonymizing content.
    \item \textbf{Manual Review}: A subset of the data was manually verified to ensure no residual PII remained after automated processing.
\end{itemize}

\paragraph{NSFW Content Handling}
To ensure compliance with ethical guidelines, NSFW content was filtered as follows:
\begin{itemize}
    \item \textbf{Automated Filtering}: A pre-trained classifier flagged potentially NSFW text/images using confidence thresholds (e.g., $\geq 0.95$).
    \item \textbf{Manual Moderation}: Flagged content was reviewed by human annotators for final removal decisions.
    \item \textbf{Metadata Logging}: Removed content was logged (without storage) to quantify the scope of filtered material.
    \item \textbf{Blurring for Images}: For image datasets, detected NSFW regions were blurred instead of full removal, where contextually necessary.
\end{itemize}

\paragraph{License Compliance}
The dataset is released under the \textbf{CC-BY-NC-SA 4.0} license, requiring users to:
\begin{itemize}
    \item Credit the original creators (\textbf{Attribution}),
    \item Use the data only for non-commercial purposes (\textbf{NonCommercial}),
    \item Share adaptations under the same license (\textbf{ShareAlike}).
\end{itemize}

\section{Prompts}

\subsection*{Annotation Prompt for Disinformation Analysis}
\label{app:prompts}
The prompt presented in Table \ref{tab:disinfo_prompt_text} and Table \ref{tab:disinfo_prompt_mm} are specifically designed for the annotation of disinformation in text, and text+image data. It utilizes a checklist of rhetorical techniques to aid assessors in systematically and consistently evaluating the likelihood of disinformation within a given text. 

\subsection*{Evaluation Prompts for Disinformation Analysis}

The prompt presented in Table \ref{tab:disinfo_prompt_mm} and Table \ref{tab:evaluator-guide_mm} guides assessors to evaluate how textual content interacts with accompanying images, focusing on potential inconsistencies, manipulations, or misleading cues. 






\begin{table*}[!htbp]
\small
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\begin{adjustbox}{width=\textwidth,center}
\begin{tabular}{|>{\raggedright\arraybackslash}m{\dimexpr\textwidth-2\tabcolsep\relax}|}
\hline
\rowcolor[gray]{0.9} % Light gray background for the header
\textbf{Disinformation Texts Analysis Prompt}\\ \hline
\texttt{full\_prompt = f"""Assess the following text and image pair below for potential disinformation (try finding Deliberately misleading or biased information) by identifying the presence of rhetorical techniques listed.}\\

If you find any of the listed rhetorical techniques, then the article is likely disinformation; if not, it is likely not disinformation. Provide three separate assessments with 'Likely' or 'Unlikely' followed by one-line long concise reasoning on why you chose 'Likely' or 'Unlikely' for each without any further explanation.\\

\textbf{Rhetorical Techniques Checklist:} \\
- Emotional Appeal: Uses language that intentionally invokes extreme emotions like fear or anger, aiming to distract from lack of factual backing. \\
- Exaggeration and Hyperbole: Makes claims that are unsupported by evidence, or presents normal situations as extraordinary to manipulate perceptions. \\
- Bias and Subjectivity: Presents information in a way that unreasonably favors one perspective, omitting key facts that might provide balance. \\
- Repetition: Uses repeated messaging of specific points or misleading statements to embed a biased viewpoint in the reader's mind. \\
- Specific Word Choices: Employs emotionally charged or misleading terms to sway opinions subtly, often in a manipulative manner. \\
- Appeals to Authority: References authorities who lack relevant expertise or cites sources that do not have the credentials to be considered authoritative in the context. \\
- Lack of Verifiable Sources: Relies on sources that either cannot be verified or do not exist, suggesting a fabrication of information. \\
- Logical Fallacies: Engages in flawed reasoning such as circular reasoning, strawman arguments, or ad hominem attacks that undermine logical debate. \\
- Conspiracy Theories: Propagates theories that lack proof and often contain elements of paranoia or implausible scenarios as facts. \\
- Inconsistencies and Factual Errors: Contains multiple contradictions or factual inaccuracies that are easily disprovable, indicating a lack of concern for truth. \\
- Selective Omission: Deliberately leaves out crucial information that is essential for a fair understanding of the topic, skewing perception. \\
- Manipulative Framing: Frames issues in a way that leaves out alternative perspectives or possible explanations, focusing only on aspects that support a biased narrative. \\

\textbf{Response format required:} \\
1. [Likely/Unlikely] [Reasoning], 2. [Likely/Unlikely] [Reasoning], 3. [Likely/Unlikely] [Reasoning] \\

Text: \{content\}"""

\texttt{try:}\\
    \texttt{response = client.chat.completions.create(}\\
    \texttt{model="gpt-4o",}\\
    \texttt{messages=[}\\
    \texttt{\{"role": "system", "content": "Analyze text for disinformation based on the listed techniques."\},}\\
    \texttt{\{"role": "user", "content": full\_prompt\}\}}\\
\hline
\end{tabular}
\end{adjustbox}
\caption{Disinformation Prompt for Texts }
\label{tab:disinfo_prompt_text}
\end{table*}




\begin{table*}[!htbp]
\small
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\begin{adjustbox}{width=\textwidth,center}
\begin{tabular}{|>{\raggedright\arraybackslash}m{\dimexpr\textwidth-2\tabcolsep\relax}|}
\hline
\rowcolor[gray]{0.9} % Light gray background for the header
\textbf{Disinformation Multimodal Analysis Prompt}\\ \hline
\texttt{full\_prompt = f"""Assess the text below for potential disinformation (try finding deliberately misleading or biased information) by identifying the presence of rhetorical techniques listed.}\\

If you find any of the listed rhetorical techniques, then the article is likely disinformation; if not, it is likely not disinformation. Provide three separate assessments with 'Likely' or 'Unlikely' followed by one-line concise reasoning on why you chose 'Likely' or 'Unlikely' for each without any further explanation.\\

\textbf{Rhetorical Techniques Checklist:} \\
- Emotional Appeal: Uses language that intentionally invokes extreme emotions like fear or anger, aiming to distract from lack of factual backing. \\
- Exaggeration and Hyperbole: Makes claims that are unsupported by evidence, or presents normal situations as extraordinary to manipulate perceptions. \\
- Bias and Subjectivity: Presents information in a way that unreasonably favors one perspective, omitting key facts that might provide balance. \\
- Repetition: Uses repeated messaging of specific points or misleading statements to embed a biased viewpoint in the reader's mind. \\
- Specific Word Choices: Employs emotionally charged or misleading terms to sway opinions subtly, often in a manipulative manner. \\
- Appeals to Authority: References authorities who lack relevant expertise or cites sources that do not have the credentials to be considered authoritative in the context. \\
- Lack of Verifiable Sources: Relies on sources that either cannot be verified or do not exist, suggesting a fabrication of information. \\
- Logical Fallacies: Engages in flawed reasoning such as circular reasoning, strawman arguments, or ad hominem attacks that undermine logical debate. \\
- Conspiracy Theories: Propagates theories that lack proof and often contain elements of paranoia or implausible scenarios as facts. \\
- Inconsistencies and Factual Errors: Contains multiple contradictions or factual inaccuracies that are easily disprovable, indicating a lack of concern for truth. \\
- Selective Omission: Deliberately leaves out crucial information that is essential for a fair understanding of the topic, skewing perception. \\
- Manipulative Framing: Frames issues in a way that leaves out alternative perspectives or possible explanations, focusing only on aspects that support a biased narrative. \\

When examining the image, consider:\\
- Does it appear to be manipulated or doctored?\\
- Is the image presented in a context that matches its actual content?\\
- Are there any visual elements designed to provoke strong emotional responses?\\
- Is the framing or composition of the image potentially misleading?\\
- Does the image reinforce or contradict the claims made in the text?\\
Evaluate how the text and image work together. Are they consistent, or does one contradict or misrepresent the other? Does the combination of text and image create a misleading impression?\\
Remember that bias can be subtle. Look for nuanced ways the image might reinforce stereotypes, present a one-sided view, or appeal to emotions rather than facts.\\

\textbf{Evaluation Instructions} \\ 
Text for evaluation: 
\texttt{f"\{sample['content']\}"} \\

Image for evaluation: 
\texttt{f"\{sample['image']\}"} \\
Respond ONLY with the classification 'Likely (1)' or 'Unlikely (0)' without any additional explanation.\\
\textbf{Response format required\:} \\
1. [Likely/Unlikely] [Reasoning], 2. [Likely/Unlikely] [Reasoning], 3. [Likely/Unlikely] [Reasoning] \\

Text: \{content\}"""

\texttt{try:}\\
\texttt{response = client.chat.completions.create(}\\
\texttt{model="gpt-4o",}\\
\texttt{messages=[}\\
\texttt{\{"role": "system", "content": "Analyze text for disinformation based on the listed techniques."\},}\\
\texttt{\{"role": "user", "content": full\_prompt\}\}}\\
\hline
\end{tabular}
\end{adjustbox}
\caption{Disinformation Prompt for Multimodal Data.}
\label{tab:disinfo_prompt_mm}
\end{table*}



\begin{table*}[!htbp]
\small
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\begin{adjustbox}{width=\textwidth,center}
\begin{tabular}{|p{16cm}|}
\hline
\rowcolor[gray]{0.9} % Light gray background for the header
\textbf{Evaluator Guide: Disinformation Assessment} \\
\hline
\textbf{Task:} \\
Assess the text and image below for potential disinformation by identifying the presence of rhetorical techniques. Look for deliberately misleading or biased information. \\
If any listed rhetorical techniques are found, classify the article as \textbf{'Likely'} disinformation. If none are found, classify it as \textbf{'Unlikely'} disinformation. \\
\hline
\textbf{Checklist of Rhetorical Techniques:} \\
\begin{itemize}
    \item \textbf{Emotional Appeal:} Language that intentionally invokes extreme emotions (e.g., fear, anger) to distract from lack of factual support.
    \item \textbf{Exaggeration and Hyperbole:} Claims unsupported by evidence, or ordinary situations presented as extraordinary to manipulate perceptions.
    \item \textbf{Bias and Subjectivity:} Information unreasonably favoring one perspective, omitting key facts for balance.
    \item \textbf{Repetition:} Repeated messaging of specific points to embed biased viewpoints in readers' minds.
    \item \textbf{Specific Word Choices:} Use of emotionally charged or misleading terms to subtly sway opinions.
    \item \textbf{Appeals to Authority:} References to authorities without relevant expertise or sources lacking credentials.
    \item \textbf{Lack of Verifiable Sources:} Reliance on unverifiable or non-existent sources, indicating fabricated information.
    \item \textbf{Logical Fallacies:} Flawed reasoning (e.g., circular reasoning, strawman arguments, ad hominem attacks) undermining logical debate.
    \item \textbf{Conspiracy Theories:} Theories lacking evidence, often involving paranoia or implausible scenarios.
    \item \textbf{Inconsistencies and Factual Errors:} Multiple contradictions or inaccuracies indicating disregard for truth.
    \item \textbf{Selective Omission:} Exclusion of crucial information necessary for fair understanding, skewing perception.
    \item \textbf{Manipulative Framing:} Framing issues to exclude alternative perspectives, focusing only on supporting biased narratives.
\end{itemize} \\
\hline
\textbf{Article to Evaluate:} \\
\texttt{[Insert Article Text Here]} \\
\hline
\textbf{Answer Format:} \\
Provide one-word answers: \textbf{'Likely'} or \textbf{'Unlikely'}. Do not include explanations or additional text. \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Evaluator's Prompt for Texts Disinformation Assessment}
\label{tab:evaluator-guide}
\end{table*}


\begin{table*}[!htbp]
\small
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\begin{adjustbox}{width=\textwidth,center}
\begin{tabular}{|p{16cm}|}
\hline
\rowcolor[HTML]{EFEFEF} % Light gray background for the header
\textbf{Evaluator Guide: Disinformation Assessment (Text and Image)} \\
\hline
\textbf{Task:} \\
Assess the text and image below for potential disinformation by identifying the presence of rhetorical techniques listed. The evaluation should consider both the content of the text and the visual elements of the image. Follow the specific instructions for each. \\
\hline
\textbf{Text Evaluation:} \\
If the text contains any of the listed rhetorical techniques, then classify the article as \textbf{'Classification: Likely'} disinformation. If none of these techniques are present, classify it as \textbf{'Classification: Unlikely'}. \\
\hline
\textbf{Image Evaluation:} \\
Analyze the image for signs of manipulation or misleading elements, such as: \\
\begin{itemize}
    \item \textbf{Visual exaggerations or distortions:} Amplify fear or other strong emotions.
    \item \textbf{Misleading context or unrelated visuals:} Do not align with the text.
    \item \textbf{Signs of tampering:} Digital artifacts, inconsistent lighting, or manipulation.
    \item \textbf{Charged symbolism:} Visuals designed to sway opinions without evidence.
\end{itemize}
If the image includes any of these elements, classify it as \textbf{'Classification: Likely'} disinformation. Otherwise, classify it as \textbf{'Classification: Unlikely'}. \\
\hline
\textbf{Rhetorical Techniques Checklist for Text Evaluation:} \\
\begin{itemize}
    \item \textbf{Emotional Appeal:} Uses language that intentionally invokes extreme emotions (e.g., fear, anger) to distract from lack of factual support.
    \item \textbf{Exaggeration and Hyperbole:} Claims unsupported by evidence, or ordinary situations presented as extraordinary to manipulate perceptions.
    \item \textbf{Bias and Subjectivity:} Information unreasonably favoring one perspective, omitting key facts for balance.
    \item \textbf{Repetition:} Repeated messaging of specific points to embed biased viewpoints in readers' minds.
    \item \textbf{Specific Word Choices:} Use of emotionally charged or misleading terms to subtly sway opinions.
    \item \textbf{Appeals to Authority:} References to authorities without relevant expertise or sources lacking credentials.
    \item \textbf{Lack of Verifiable Sources:} Reliance on unverifiable or non-existent sources, indicating fabricated information.
    \item \textbf{Logical Fallacies:} Flawed reasoning (e.g., circular reasoning, strawman arguments, ad hominem attacks) undermining logical debate.
    \item \textbf{Conspiracy Theories:} Theories lacking evidence, often involving paranoia or implausible scenarios.
    \item \textbf{Inconsistencies and Factual Errors:} Multiple contradictions or inaccuracies indicating disregard for truth.
    \item \textbf{Selective Omission:} Exclusion of crucial information necessary for fair understanding, skewing perception.
    \item \textbf{Manipulative Framing:} Framing issues to exclude alternative perspectives, focusing only on supporting biased narratives.
\end{itemize} \\
\hline
\textbf{Article to Evaluate:} \\
\texttt{[Insert Article Text Here]} \\
\hline
\textbf{Image to Evaluate:} \\
\texttt{[Insert Image Here]} \\
\hline
\textbf{Answer Format:} \\
Provide one-word answers: \textbf{'Classification: Likely'} or \textbf{'Classification: Unlikely'}. Do not include explanations or additional text. \\
\hline
\end{tabular}
\end{adjustbox}
\caption{Evaluator's Prompt for Disinformation Assessment (Text and Image)}
\label{tab:evaluator-guide_mm}
\end{table*}