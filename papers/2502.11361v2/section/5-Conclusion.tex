\section{Conclusion}
% {Alignment with AI Regulation}
\textsf{\textbf{\textsc{VLDBench}}} addresses the urgent challenge of disinformation through a design rooted in responsible data stewardship and human-centered principles, integrating best practices from AI governance (human-centredness, ethical data preparation, evaluations). Unlike other benchmarks, \textsf{\textbf{\textsc{VLDBench}}} uniquely targets the complexity of disinformation in an era of generative AI. It is the first dataset explicitly designed to evaluate modern LLMs and VLMs (athough other ML models can also be trained or evaluated) on emerging disinformation challenges, maintaining a topical focus.
However, some limitations need attention (Section \ref{limits}). The reliance on pre-verified news sources may introduce potential sampling bias, and the annotation process (AI + humans) may inherit annotators biases \cite{gilardi2023chatgpt}. There is also need to study into more adversarial attacks in multimodality. The current focus on English language only limits its applicability to multilingual and culturally diverse contexts. Despite these limitations, \textsf{\textbf{\textsc{VLDBench}}} represents an effort in benchmarking disinformation detection and open venues for collaboration from researchers and practitioners to address this challenge.
