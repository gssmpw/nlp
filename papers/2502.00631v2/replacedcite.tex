\section{Related Work}
\subsection{Deep Learning for Bone Mineral Density Prediction}

The prediction of bone mineral density (BMD) and the evaluation of fracture risk through the application of deep learning techniques ____ have garnered increasing attention in recent years. A notable study by Hsieh et al. (2021) ____ introduced an innovative approach that utilizes deep learning models applied to plain radiographs for the automated prediction of BMD and fracture risk assessment. Their method demonstrated highly promising results, achieving area under precision-recall curve (AUPRC) scores of 0.89 for hip osteoporosis and 0.83 for spine osteoporosis prediction. Furthermore, their model exhibited an impressive accuracy of 91.7\% in estimating the risk of hip fractures. Leveraging a large dataset comprising pelvis and lumbar spine radiographs, the study underscored the potential of deep learning in addressing osteoporosis detection, particularly in scenarios where dual-energy X-ray absorptiometry (DXA) remains underutilized.

In another significant contribution, Yasaka et al. (2020) ____ explored the use of CT imaging for BMD prediction, employing a convolutional neural network (CNN) specifically designed to estimate lumbar vertebrae BMD from unenhanced CT scans. Their findings demonstrated a strong correlation between CNN-predicted BMD values and those obtained through DXA, achieving area under the receiver operating characteristic curve (AUC) scores of 0.965 and 0.970 for internal and external validation datasets, respectively. This study laid the groundwork for using CT imaging as an effective alternative to DXA in BMD prediction, illustrating the capability of CNN-based models to accurately capture bone density-related features.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{Comparison_of_models.png}
    \caption{
        Comparison between 3D ResNet and 2D ResNet architectures for volumetric medical data processing. 
        The upper pipeline illustrates the 3D ResNet-based MedConv model, which leverages three-dimensional convolutions to capture spatial and contextual information across volumetric CT scans. 
        The inclusion of Bal-CE Loss further refines the model's focus on imbalanced data distributions, ensuring accurate predictions for the L1 vertebra segmentation task.
        Conversely, the lower pipeline showcases the standard 2D ResNet approach, where slices are treated independently without spatial continuity across adjacent slices, potentially limiting performance in tasks requiring volumetric context. 
        This figure highlights the architectural and methodological differences, emphasizing the advantages of 3D ResNet for tasks that demand structural and contextual understanding of medical images.}
    \label{fig:comparison_models}
\end{figure}

Building upon this research, Dagan et al. (2019) ____ developed a model aimed at predicting fracture risk based on routine CT scans, particularly when DXA-derived data is unavailable. Their CT-based method demonstrated superior AUC scores and sensitivity compared to the FRAX tool when BMD inputs were excluded, indicating that CT scans can serve as a reliable resource for assessing fracture risk. This approach suggests that CT imaging could effectively compensate for the underutilization of DXA in clinical settings.

In another noteworthy study, Gonz√°lez et al. (2018) ____ proposed a direct image-to-biomarker prediction approach. By employing a deep learning regression model, they predicted BMD directly from CT scans. Their results highlighted the effectiveness of a single convolutional neural network in simultaneously segmenting relevant anatomical regions and predicting BMD values with high accuracy. This streamlined approach provides an efficient alternative to traditional methods that rely on separate segmentation and prediction steps.

Lastly, Fang et al. (2020) ____ demonstrated the potential of multi-detector CT imaging for opportunistic osteoporosis screening. By combining U-Net for vertebral segmentation with DenseNet-121 for BMD estimation, their method achieved a strong correlation with quantitative computed tomography (QCT) benchmarks. This fully automated pipeline showcased the feasibility of integrating CT-derived BMD analysis into routine clinical practice for opportunistic screening. Their study highlighted how deep learning can facilitate cost-effective and automated osteoporosis detection in diverse healthcare environments.


\subsection{Addressing Long-Tailed Distribution in Classification Tasks}

Long-tailed distributions, characterized by a few dominant classes and a large number of underrepresented classes, pose significant challenges in classification tasks. These challenges arise due to the imbalance in the data distribution, which can lead to biased model predictions favoring majority classes while neglecting minority ones. Two widely adopted strategies for addressing this issue are resampling methods and balanced augmentation (BalAug), both of which aim to mitigate the effects of data imbalance by adjusting the training process.

Resampling methods involve manipulating the class distribution in the training dataset. Oversampling techniques, such as random duplication or Synthetic Minority Over-sampling Technique (SMOTE), increase the representation of minority classes, thereby providing the model with more exposure to these underrepresented categories. However, these approaches may lead to overfitting on the minority classes due to repeated exposure to the same data points. On the other hand, undersampling methods reduce the number of majority class samples to balance the dataset, but this can result in a loss of valuable information from the majority classes, as noted in ____. Consequently, while resampling methods are straightforward and often effective, they require careful tuning to avoid introducing new challenges.

Balanced augmentation (BalAug) offers an alternative approach by integrating data augmentation techniques with class balancing. Augmentation strategies such as rotation, cropping, flipping, and other transformations are selectively applied to the minority classes, enhancing the diversity of training data for these underrepresented categories. For instance, ____ introduced a class-balanced loss that dynamically weights samples based on their effective number, ensuring that the model learns equitably from all classes. Furthermore, advanced techniques like class-aware sampling combined with augmentation, as proposed in ____, have demonstrated improved performance on long-tailed datasets by carefully balancing the sampling probabilities and incorporating diverse transformations. These methods not only enrich the training data but also help the model generalize better to unseen data.

In addition to data-focused strategies, training optimization methods have emerged as powerful tools for addressing long-tailed distributions. Foret et al. (2020) ____ introduced Sharpness-Aware Minimization (SAM), a novel optimization approach designed to enhance model generalization by simultaneously minimizing the loss value and the sharpness of the loss landscape. SAM identifies parameter regions with consistently low loss, effectively mitigating overfitting and improving generalization, particularly in overparameterized models. Through rigorous evaluation on benchmark datasets like CIFAR ____ and ImageNet ____, SAM demonstrated superior performance, excelling in robustness to label noise and training stability, making it a valuable addition to the arsenal of techniques for long-tailed datasets.

Building on these ideas, Fang et al. (2023) ____ proposed a schedule-free optimization framework to address long-tailed distributions by replacing traditional learning rate schedules with momentum-driven primal averaging. Their approach dynamically balances gradient updates, avoiding the gradient collapse often observed in imbalanced datasets. This innovative method achieved state-of-the-art results across various tasks, including CIFAR-10 and ImageNet, by combining robust convergence properties with efficient generalization capabilities. By reducing reliance on extensive hyperparameter tuning, this approach offers a practical solution for training on long-tailed data.

In summary, addressing the challenges posed by long-tailed distributions typically requires a combination of data-level and training-level strategies. Data-level approaches, such as resampling and balanced augmentation, aim to correct the imbalance in the dataset, ensuring that all classes are adequately represented during training. Training-level techniques, like SAM and schedule-free optimization, focus on improving model generalization by optimizing the training process itself. When these methods are combined effectively, they can complement each other, leveraging the strengths of both data and training interventions to achieve robust and unbiased performance on long-tailed datasets.