\section{Related Work}
\label{sec:Related Work}

\subsection{Medical Image Segmentation}

Medical image segmentation aims to assign a closed-set class label to each pixel. UNet \citep{ronneberger2015u} has gradually become the preferred model in the medical segmentation field since it was first proposed in 2015. Such success is mainly attributed to its unique structural design, especially the encoder-decoder structure and the skip connection mechanism, which endows the model with strong detail recovery. Subsequently, it is enhanced by exploring dense skip connections~\citep{guan2019fully,zhou2018unet++}, multi-scale receptive fields~\citep{xiao2018weighted} and global information~\citep{chen2021transunet}. 
In addition to 2D medical scenes, UNet has been extended to 3D medical scenes, such as MRI and CT, by replacing 2D convolutions with 3D convolutions~\citep{cciccek20163d}. Another similar approach is VNet \citep{milletari2016v}, which also employs the encoder-decoder structure. The difference with 3D-UNet is that VNet utilises a convolutional layer instead of the pooling layer for downsampling, thereby mitigating information loss. 

More recent studies~\citep{10093768,horst2024cellvit} have explored methods based on vision transformer (ViT)~\citep{dosovitskiy2020image} for the medical segmentation task, leveraging their capability for long-range modelling. Other recent approaches~\citep{chowdary2023diffusion,wu2024medsegdiff} can enhance the segmentation quality by introducing the Diffusion Probabilistic Model (DPM)~\citep{ho2020denoising}. 
Although the fully supervised segmentation techniques described above exhibit solid performance, they require a large number of voxel-based annotations that are difficult and expensive to obtain in real medical scenarios. 
One way to mitigate the need for such annotations is based on the development of semi-supervised learning methods that require much smaller sets of annotated data and large sets of un-annotated data. We review semi-supervised learning methods below. 


% \gustavo{It may sound strange for reviewers that we only discuss until VNet in this subsection. Should we justify why we don't discuss more modern segmentation methods? Or should we discuss more modern methods?}
% \yanyan{Do I need to discuss the Segment Anything Model in this part?}
% Following prior semi-supervised medical image segmentation works \citep{liu2022translation, yu2019uncertainty}, 3D-UNet is employed as the backbone network on LA and Pancreas-CT datasets, while VNet serves as the base model on the BraTS19 dataset \gustavo{This sentence should move to the next section since it talks about semi-supervised learning, right?}. \yanyan{Can I remove this sentence, because it is also stated in Sec. 4.2 Implementation Details? }





\subsection{Semi-supervised Medical Image Segmentation}

Significant advancements have been made in semi-supervised medical image segmentation~\citep{miao2023caussl, wang2023mcf}. Current models primarily adopt consistency regularisation strategies to leverage unlabelled information~\citep{hang2020local, wang2020double}. The underlying idea behind these strategies is that the model's predictions for unlabelled samples should remain consistent under various perturbations~\citep{bai2023bidirectional, gao2023correlation}. The Mean Teacher framework, which explores weak and strong augmentation strategies, is quite effective in the implementation of this idea. Based on this framework, various weak and strong augmentation techniques have been proposed to generate prediction disagreements. \citet{li2020transformation} apply different data augmentation techniques, such as Gaussian noise and contrast variation, on the input data. \citet{liu2022translation} adjust the spatial context of the input samples to enrich their diversity. Also, \citet{xu2022learning} and \citet{zheng2022double} focus on inducing prediction inconsistencies by adding perturbations at the feature level.


Despite the promising performance of well-designed data augmentation techniques, the pseudo-labels generated by teacher networks still contain a fair amount of noise, which hinders the model's segmentation capability. Recent works argue that incorporating additional supervised information would help mitigate this problem. One of the representative efforts is the multi-teacher embedding approach~\citep{liu2022perturbed, zhao2023alternate}. The core idea of this kind of approach lies in the generation of pseudo-labels from different perspectives. To ensure diversity, the teacher models typically employ different initialization parameters and update mechanisms. However, not all perspectives necessarily improve the accuracy of pseudo-labels, and sometimes conflicting labels may emerge. It is thus difficult to utilise different perspectives from unlabelled information to improve segmentation performance in complex situations. 

\begin{figure*}[!t]
\centering
\includegraphics[width=6.5in]{whole_architecture.pdf}
\caption{The architecture of the proposed model. Based on the teacher-student structure, the Cooperative Rectification Learning Network (CRLN) consists of two stages. In the learning stage, multiple category prototypes are built and initialised. Subsequently, the Dynamic Interaction Module (DIM) implements pairwise interactions, as well as spatial-aware and cross-class aggregation between prototypes and the semantics of the labelled data to obtain the holistic relationship map $\mathscr{M}(x)$ which adaptively improves the segmentation quality of $\hat{y}$ with~\eqref{eq:rectification_student}. By minimising the deviation between predictions and labels, the proposed CRLN effectively learns valuable category prototypes and understands how to use them for voxel-level correction. In the rectification stage, the learned category prototypes serve as prior knowledge to rectify the pseudo-labels $\bar{y}$. After rectification, the higher-quality pseudo-labels $\bar{y}_{r}$ are used as supervision signals. Moreover, the Collaborative Positive Supervision (CPS) mechanism constructs unassertive centres by integrating learned category prototypes and category mean representations, allowing for better contrastive learning ($\ell_{cp}(\cdot)$ in ~\eqref{eq:cp} of representations with lower predictive confidence in the student network. This empowers the model to distinguish uncertain regions.
% \gustavo{I changed many of the variables in the text -- can you update the figure with the new nomenclature? This Figure and Figure 2 are too similar.  Can you in this figure provide new points about CRNL, DIM, and CPS ?} \yanyan{I have updated the figure and added some new points. The letters "$\hat{y}_l$", "$\hat{y}_{lr}$", "$\bar{y}_{u}$" and "$\bar{y}_{ur}$"have been retained for ease of representation. Is this version appropriate? Do these letters need to be removed? }\gustavo{Sorry, I think we'll need to change this one more time to reflect the new nomenclature used in the paper.}\yanyan{I have updated it. Since the prototypes in the rectification stage are updated by the EMA of the prototypes learned in the learning stage, $P_t$ is used to denote the prototypes in the rectification stage.}} 
\label{fig:network_structure}}
\end{figure*}

Another technique to suppress the negative effects of noise in pseudo-labels is to filter out or reduce the weight of samples classified as uncertain during training~\citep{wang2021tripled,xia2020uncertainty}. UA-MT estimates the uncertainty of the teacher's prediction with the classification entropy and uses only reliable (i.e., low-entropy) predictions to supervise the student network~\citep{yu2019uncertainty}. \citet{luo2021efficient} propose to use multi-scale prediction discrepancy as a measure of uncertainty and then treat the uncertainty score as a pixel-level coefficient to reduce the loss contribution from the uncertain regions. \citet{luo2021semi} perform uncertainty estimation via subjective logic. Furthermore, \citet{su2024mutual} compute the reliability of the pseudo-labels based on the intra-class consistency. 
The computation of these uncertainty maps focuses on pixel-level local information and overlooks the benefits of the global view. Therefore, \citet{ADIGAV2024103011} employ a denoising autoencoder to reconstruct the predictions of the teacher network and then implement uncertainty estimation by calculating the difference between the teacher model's prediction and its reconstruction. \textcolor{red}{Recently, \citet{10273222} propose to adaptively weight the pseudo supervision loss in a voxel-wise manner based on the uncertainty of model predictions and promote feature consistency across differently augmented samples using a contrastive loss. These methods, which filter out or reduce the loss weight of voxels classified as uncertain, can reduce the negative impact of noise in pseudo-labels. However, voxels classified as reliable may, in fact, contain incorrect predictions, potentially harming model performance. Moreover, many regions in the pseudo-labels have low predictive confidence during training, especially in the early training stages, leading to the under-utilization of both these labels and their corresponding raw unlabelled data. Hence, we propose to leverage the labelled knowledge to explicitly rectify the low-quality predictions present in the pseudo-labels.}
%Different from these approaches, we propose to enhance the semi-supervised 3D medical image segmentation quality from the perspective of improving the prediction quality of pseudo-labels. To achieve this goal, we leverage the labelled data knowledge to explicitly rectify the low-quality predictions in the pseudo-labels
\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{DIM.png}
\caption{\textcolor{red}{The architecture of the Dynamic Interaction Module (DIM).}}
\label{fig:dim}
\end{figure}