\textbf{Prompt Optimization.}
The field of prompt optimization has been gaining significant popularity recently.
Earlier works on this topic have focused on optimizing the prompt for white-box LLMs \cite{Shin2020ElicitingKF,Shi2022TowardHR,lester2021power,Li2021PrefixTuningOC,zhong2021optiprompt,deng2022rlprompt}.
More recently, a number of works have developed prompt optimization methods for black-box LLMs \cite{chen2023instructzero,zhou2023large,fernando2023promptbreeder,guo2023connecting,hu2024localized,lin2023instinct,zhan2024unlocking,juneja2024task,wang2023promptagent,kong2024prewrite,schneider2024hyperband,shi2024best}.
In addition, some recent works have focused on automatically selecting the exemplars for in-context learning \cite{wang2023latent,chang2023data-model,li2023support-examples,zhang2022active,nguyen2023incontext,albalak2024survey-data-selection,ye2023compositional,liu2022makes,gao2024ambiguityaware,rubin2022retrieval,ye2023compositional,levy2023diverse,gupta2023coverage},
whereas a few methods have been proposed to jointly optimize the prompt and select the exemplars \cite{opsahl2024optimizing,wan2024teach,wu2024prompt}.
However, to the best of our knowledge, our algorithm is the first approach that is able to efficiently optimize the meta-prompt for LLM-based agents in sequential decision-making tasks.

\textbf{LLM-Based Sequential Decision-Making.}
Some recent works have proposed to leverage the strong capability of LLMs to solve sequential decision-making tasks, such as Bayesian optimization \cite{yang2023large}, multi-armed bandits \cite{krishnamurthy2024can,xia2024beyond,chen2024efficient,mukherjee2024pretraining}, and reinforcement learning \cite{dai2024context,monea2024llms,wang2024transformers}.
However, these works often provide a fixed manually designed meta-prompt to the LLM, and are hence unable to fully unleash the potential of LLM-based sequential decision-making.
The field of LLM-based agents has seen a surging interest recently, for which a number of benchmarks have been proposed \cite{liu2023agentbench,wu2023smartplay,xi2024agentgym}. We defer more a comprehensive discussion of LLM-based agents to recent surveys on this topic \cite{cheng2024exploring,wang2024survey,xi2023rise}.

