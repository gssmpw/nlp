\section{Related Work}
\label{sec:related}

% Discuss the main related work and cite around key papers. The number
% of cites depend on the page limit. Never below 15, 20-30 is often fine
% for conference papers.
% The related work section should be approx. 1 column long, assuming 
% a 6-page paper, up to one page for 8-10 page papers.  You can structure 
% the  section in paragraphs, grouping the  papers, and describing the key 
% approaches with 1-2 sentences. Avoid dull enumerations of papers. If 
% applicable, describe the key difference to your approach at the end 
% of each paragraph briefly. Avoid adding subsections, al least for a 
% conference paper.


\subsection{Point-based Implicit Neural Representation}


Robotics has long relied on explicit map representations with discrete primitives like point clouds~\cite{Curless1996ReconstructingElastic3DModel}, surfels~\cite{Buehler2001Making3DSurfel}, meshes~\cite{Lowe1987ThreeDimensionalMeshes}____, or voxel grids~\cite{Curless1998VoxelHashing}____ for core tasks like localization~\cite{Lowry2015VisionAerialRobotics}____ and planning~\cite{Dube2014Planning3DManifold}____.
%

Recently, implicit neural representations have been proposed to model radiance fields~\cite{Mildenhall2020NeRFRadianceFields}, and geometric (occupancy or distance) fields~\cite{Sitzmann2019SceneRepresentationMLP}____ using \mbox{multi-layer perceptrons (MLP)}. 
%
These continuous representations offer advantages like compact storage, and better handling of regions with sparse observations or occlusions, while supporting conversion to explicit representations for downstream tasks.
%

Instead of using a single MLP for the entire scene, recent methods use hybrid representations that combine local feature vectors with a shared shallow MLP.
% Explain neural point here
Point-based implicit neural representations~\cite{Park2020PiNRadianceFields}____ store optimizable features in a neural point cloud, which has advantages over grid-based alternatives through its flexible spatial layout and inherent elasticity under transformations for example caused by loop closures.
%

%
Point-based implicit neural representations have been used for modeling either radiance fields or distance fields for various applications including differentiable rendering~\cite{Huang2020DifferentiableRendering}, dynamic scene modeling~\cite{NeuralPhysicsEngine2019}, surface reconstruction~\cite{Kazhdan2006SurfaceReconstruction}, visual odometry~\cite{Mur-Artal2017ORBVisualOdometry}____, and globally consistent mapping~\cite{Strasdat2014RealtimeSLAM}. 
%
In particular, PIN-SLAM~\cite{Riegler2019PinSLAM}____ demonstrates the effectiveness of representing local distance fields for odometry estimation and using its elasticity during loop closure correction.
%

In this work, we propose a novel LiDAR-visual SLAM system inspired by PIN-SLAM~\cite{Riegler2019PinSLAM}____ and Scaffold-GS~\cite{ScaffoldGS2020}____ encoding a Gaussian splatting radiance field within the neural points, and jointly optimizing it with the distance field.
%
Compared to NeRF-based approaches~\cite{NeRF2019}, this also offers much faster novel view rendering suitable for robotics applications.



\subsection{Gaussian Splatting Radiance Field}

NeRF~\cite{Barron2020NeRFGaussianRadiance}____ pioneered the use of MLPs to map 3D positions and view directions to color and volume density, encoding radiance fields through volume rendering-based training with posed RGB images.
%
% The rendering photorealism, training and inference efficiency as well as the scalability have been later improved to a certain extent by using either the proper anti-aliasing~\cite{Zhang2021AntiAliasing}____ or the hybrid representations~\cite{Sitzmann2019SceneRepresentationMLP}____ combining optimizable local features and a shallow global MLP.
% Add more citations, such as TensorRF
More recently, 3DGS~\cite{Bosse2020GaussianRBF3DGaussian}____ introduced explicit 3D Gaussian primitives to represent the radiance fields, achieving high-quality novel view synthesis.
%
Compared to NeRF-based methods, 3DGS is more efficient by using primitive-based differentiable rasterization~\cite{Bosse2022PrimitivesRasterization}____ instead of ray-wise volume rendering.
%
The explicit primitives also enables editing and manipulation of the radiance field.
%
These properties make 3DGS promising for robotics applications~\cite{Riegler2019PinSLAM}____.
%
However, two main challenges limit its usage: geometric accuracy and scalability for incremental mapping.
% 
We discuss the related works addressing geometric accuracy in the following and addressing scalable mapping in \secref{subsec:large_scale_3d_reconstruction}.



While 3DGS achieves high-fidelity photorealistic rendering, it often lacks the geometric accuracy. 
% needed for robotics applications.
%
To tackle this limitation, SuGaR~\cite{SuGar2020SufarMeshes}____ uses a hybrid representation to extract meshes from 3DGS and align the Gaussian primitives with the surface meshes.
%
To address the ambiguity in surface description, another solution is to flatten the 3D Gaussian ellipses to 2D disks~\cite{Wang2018Gaussian2DDisks}____.
%
The 2D disks gradually align with surfaces during training, enabling more accurate depth and normal rendering.
%
However, extracting surface meshes from these discrete primitives still requires either TSDF fusion~\cite{Taverniers2020TSDFFusion}____ with rendered depth or Poisson surface reconstruction~\cite{Kazhdan2006SurfaceReconstruction}____. 
% with post-processing.
%

Another line of works~\cite{Wang2018Gaussian2DDisks, Taverniers2020TSDFFusion}____ model discrete Gaussian opacity as a continuous field, similar to NeRF-based surface reconstruction~\cite{Barron2020NeRFGaussianRadiance}____.
%
Several works~\cite{Wang2018Gaussian2DDisks,Taverniers2020TSDFFusion}____ jointly train a distance field with 3DGS and align the Gaussian primitives with the zero-level set of the distance field to achieve accurate surface reconstruction.
%
However, these methods rely solely on image rendering supervision for both 3DGS and neural SDF training without direct 3D geometric constraints, leading to ambiguities in textureless or specular regions.
%
The volume rendering-based SDF training also impacts efficiency.
%

While 3DGS originally uses structure-from-motion point clouds, robotic platforms with LiDAR can initialize primitives directly from LiDAR measurements~\cite{Mur-Artal2017ORBVisualOdometry}____.
%
Direct depth measurements can further supervise depth rendering to improve geometric accuracy and convergence speed~\cite{Strasdat2014RealtimeSLAM}____.

% Different from aforementioned works, our approach adopts the geometrically consistent 2D Gaussian primitives and train them together with a neural distance field supervised by direct depth measurements from LiDAR.
%
% We unify the Gaussian splatting radiance field and SDF in one single implicit neural map representation and enforce the consistency of the primitives and the distance field to improve the geometric accuracy of both fields.
%
% Recent work GSFusion~\cite{GSFusion2022}____ maintains a voxel-based distance field and a Gaussian splatting radiance field simultaneously. However, the two fields are decoupled without mutual supervision.
%
Our approach uniquely combines geometrically consistent 2D Gaussian disks with a neural distance field supervised by direct LiDAR measurements, enforcing mutual geometric consistency between the representations.
%
This differs from GSFusion~\cite{GSFusion2022}____, which maintains decoupled distance and radiance fields without mutual supervision.
%

\subsection{Large-Scale 3D Reconstruction}
\label{subsec:large_scale_3d_reconstruction}

This paper focuses on online large-scale 3D reconstruction.
%, particularly for block and city-scale scenes.
% at ground level.
%
There have been numerous works for the scalable occupancy or distance field mapping in the past decade, using efficient data structures such as Octree~\cite{Kopf2007Octrees}____, voxel hashing~\cite{Curless1998VoxelHashing}____,  VDB~\cite{Matusik2010VDBVolumetric}____, or wavelets~\cite{Weiss2004WaveletReconstruction}____.
%

Scalable radiance field mapping has also made significant progress recently.
%
For large scale scenes captured by aerial images, recent works~\cite{Flynn2021LevelOfDetailRendering}____ demonstrate promising results using level-of-detail rendering and neural Gaussian compression.
%
For driving scenes with short sequences containing hundreds of images, both NeRF-based~\cite{Barron2020NeRFGaussianRadiance}____ and 3DGS-based~\cite{Bosse2022PrimitivesRasterization}____ approaches have demonstrated high-fidelity offline radiance field reconstruction, enabling closed-loop autonomous driving simulation~\cite{Mur-Artal2017ORBVisualOdometry}____.
%

%
However, radiance field mapping for even larger scenes at ground level with thousands of images still remains a challenge.
% 
In this work, we propose a novel LiDAR-visual SLAM system to address the challenges in large-scale 3D reconstruction.