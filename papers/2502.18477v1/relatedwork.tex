\section{Related Work}
% The introduction to related work
Recommender systems and generative models are two rapidly evolving fields. While traditional recommender systems rely on pre-existing catalogs, generative approaches offer the promise of creating novel, user-specific content. This section reviews prior work in these areas, positioning our method as an underexplored bridge between them.


% Talk about recommender systems
\subsection{Recommender Systems}
Modern recommender systems are often described as understanding users better than they understand themselves. This perception stems from their ability to gather and analyze vast amounts of online activity data, building detailed profiles of user interests and habits. Such systems have become highly effective at matching users to items within pre-existing catalogs \cite{castells2023recommendersystemsprimer, li2023recentdevelopmentsrecommendersystems}.  Novel-item generative recommenders can enhance the current catalog offering, not just by creating, but also by making items more suitable to an individual's preferences.

\subsection{Generative Recommenders}
% Talk about work at the intersection THAT IS NOT  in the same line as our work, despite combining them
In recent years, there has been substantial progress at the intersection of generative models and recommender systems. Research in generative retrieval \cite{zhai2024actionsspeaklouderwords} and the use of large language models (LLMs) for \textit{preference discernment} \cite{paischer2024preferencediscerningllmenhancedgenerative} has introduced new paradigms, including the term ``Generative Recommender'' \cite{zhai2024actionsspeaklouderwords}. While these developments are exciting, they are not the focus of this work because they address the problem of within-catalog recommendation with generative item retrieval. Instead, we reference them here to provide contrast and contextualize our approach.

Despite the relative novelty of generative recommenders, the field has already seen terminological overlap. One particularly relevant work is GeneRec \cite{wang2024generativerecommendationnextgenerationrecommender}, which takes initial steps in framing the problem, identifying key challenges, and outlining directions for future research. Their proposed generative recommender paradigm consists of three main components: (1) an \textit{instructor} that preprocesses user instructions and feedback, (2) a \textit{generator} that creates new items, and (3) an \textit{editor} that refines and repurposes existing catalog items. This formulation, however, proposes an LLM that mediates between the user and the AI generator, necessitating explicit and active user instructions, which they are often unwilling to provide.

A more recent approach focuses on personalized fashion recommendations \cite{genoutfit2024}, but the scope is limited: it requires fitting a new model each time a novel item class enters the catalog and thus fails to leverage the rich general-purpose representations of base text-to-image models.



\subsection{Model Alignment}

Aligning generative models' outputs with human values and preferences is a vibrant research domain whose discourse often extends beyond technical communities into the public sphere. From a technical perspective, one widely adopted approach is Reinforcement Learning with Human Feedback (RLHF) \cite{christiano2023deepreinforcementlearninghuman, ziegler2020finetuninglanguagemodelshuman}, which optimizes model behavior based on reward signals derived from human preferences. However, RLHF remains computationally expensive, requires careful reward function design, and can be prone to mode collapse.

Another promising approach is Direct Preference Optimization (DPO) \cite{rafailov2024directpreferenceoptimizationlanguage}, which aligns base models with human values through contrastive preference learning. DPO assumes uniform user preferences, treating human feedback as globally consistent, which is problematic in personalized settings like recommender systems, where preferences are highly heterogeneous. Additionally, DPO still requires an implicit reward structure, meaning that careful curation of preference data is crucial to avoid biases.

In our case, where we seek to model individual user preferences dynamically, both RLHF and DPO present limitations. Rather than imposing a global reward structure, we instead condition generation on user embeddings, allowing the model to capture personalized preferences in a more flexible, data-driven manner.

\subsection{Adapters, Priors and Decoders}
% Introduce our solution techniques
While our approach addresses the problem setting of GeneRec \cite{wang2024generativerecommendationnextgenerationrecommender}, our proposal is close to the \textbf{adapter} in generative modeling. The purpose of adapters is to produce augmentation to new input conditions or fine-tuning behavior \cite{zhang2023adding, ye2023ip-adapter} of large pre-trained models, and they typically require text captions during training. We argue that text captions are not only unusual in most recommendation datasets, but they also fail to distill the nuances of individual preference, better captured in the features tracked in modern recommender systems \cite{zhai2024actionsspeaklouderwords}. Although some adapters can be successfully calibrated with Low-Rank adaptations \cite{hu2021loralowrankadaptationlarge}, they are fine-tuned  per user, which not only leads to poor scaling properties, but also does not benefit from correlations between individuals. Instead, we propose a probabilistic adaptation framework that leverages CLIP latents as \textit{custom priors} and an off-the-shelf \textit{decoder} in a principled adapter formulation. In the past, \textit{priors} and \textit{decoders} have been utilized to train full base text-to-image models \cite{pradeep-etal-2023-generative}. \texttt{REBECA} is the first used to produce adapting behavior to additional input signals.


\subsection{Challenges in Establishing Baselines} 


Generative recommenders, as a novel class of systems, currently lack established baselines or datasets combining user ratings with image captions. Traditional methods in recommender systems focus on retrieval, while generative models lack personalization mechanisms. Adapters, although promising, require paired datasets that are impractical in recommendation contexts. This lack of baselines underscores the need for innovative methodologies and benchmarks, which we aim to address in this work.