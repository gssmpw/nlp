This section presents the resulting atomic parts of the legal texts and their hierarchical decomposition, offering a detailed breakdown of the sections and cases within each document type. The following results illustrate the scope and depth of the collected data, providing a foundation for further exploration of trends and patterns across the legal corpus.

\subsection{Dataset}



After collecting and structuring the data, the three types of legal documents had the following atomic parts of data, either as sections in the constitution and statutes or cases from case law:

\begin{itemize}
    \item \textbf{Constitution:} 265 sections
    \item \textbf{Statutes:} 28,251 sections
    \item \textbf{Case Law:}
        \begin{itemize}
            \item \textbf{\textit{ Court of Appeals:}} 10,072 cases
            \item \textbf{\textit{Supreme Court:}} 5,727 cases
        \end{itemize}
    
\end{itemize}

Figure~\ref{fig:court_cases} shows the trends in the 5,727 Supreme Court and 10,072 Court of Appeals cases over the years,  as they were available from Justia \cite{justia}, which also includes the expansions and creations of the courts themselves.

\begin{figure*}[ht]
    \centering
    % Single Row
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/sunburst_chart_constitution.pdf}
        \caption{10 latent topics from \\ \textbf{Constitutional Provisions}}
        \label{fig:decomp_const}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/sunburst_chart_statutes.pdf}
        \caption{985 latent topics from \\ \textbf{Statutory Sections}}
        \label{fig:decomp_stat}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/sunburst_chart_appeals.pdf}
        \caption{420 latent topics from \\ \textbf{Court of Appeals Cases}}
        \label{fig:decomp_sup}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/sunburst_chart_supreme.pdf}
        \caption{248 latent leaf topics from \textbf{Supreme Court Cases}}
        \label{fig:decomp_app}
    \end{subfigure}
    \vspace{-.5em}
    \caption{Legal Documents from New Mexico hierarchically decomposed. The Constitution only had enough documents to decompose the first depths, whereas the other three sources continued to the terminal depth of 2 (a hyper-parameter of decomposition). Each H-cluster has a natural language label, where depth-0 from each can be seen in Tables \ref{tab:Constitution}, \ref{tab:statutes}, \ref{tab:supreme}, and \ref{tab:appeals}. }
    \label{fig:decomp_all}
    \vspace{-1.5em}
\end{figure*}


\subsection{Decomposition}


The four component data types were decomposed hierarchically with \textit{NMFk}. The vocabulary for building the TF-IDF matrix was collected using specific parameters for each part. For the Constitution vocabulary, the minimum token document frequency (DF) was set to 5 documents, with a maximum token DF of 80\% of the corpus, resulting in a final size of 416 tokens. For the Statutes vocabulary, the minimum token DF was set to 30 documents, with a maximum token DF of 70\% of the corpus, yielding 7,508 tokens. The Court of Appeals vocabulary used a minimum token DF of 50 documents (cases) and a maximum token DF of 70\% of the corpus, resulting in 10,189 tokens. Last, the Supreme vocabulary employed a minimum token DF of 50 papers and a maximum token DF of 70\% of the corpus, with a final size of 8,425 tokens.
The maximum depth was set to 2, of which only the constitution sections did not reach due to the limited number of sections. The limiting factor of further decompositions was 100 documents, so if the preceding cluster had $\geq 100$, the cluster would decompose and stop otherwise. As seen in Figure \ref{fig:decomp_const}, the largest H-cluster is from cluster 4 in dark blue with 49 sections, with the fewest documents in yellow with six sections in H-cluster 0. The other three decompositions can be examined in the larger Figure \ref{fig:decomp_all}, where the court cases, there are 10 leaf H-clusters in the constitution decomposition, 985 leaf H-clusters in the statutes decomposition,  420 leaf H-clusters in the Court of Appeals cases, and 248 leaf H-clusters in the Supreme Court cases. From the methods in \cite{topic_tag}, each H-cluster throughout the decomposition hierarchies has LLM-generated labels for ease of reference and quick insight. Labels for the first decomposition depth for the constitution can be observed in Table \ref{tab:Constitution},  the statutes in Table \ref{tab:statutes}, the Supreme court in Table \ref{tab:supreme}, and the appeals in Table \ref{tab:appeals}. The depth-0 H-clustering corresponds to the first ring radial from the center totals in Figure \ref{fig:decomp_all}.

 
\definecolor{darkgreen}{rgb}{0.0, 0.6 , 0.0}
\definecolor{lightgreen}{rgb}{0.0, 0.9, 0.0}
\definecolor{goldyellow}{rgb}{1.0, 0.84, 0.0}
\definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
\definecolor{lightblue}{rgb}{0.0, 0.9, 1.0}
\definecolor{darkpurple}{rgb}{0.4, 0.0, 0.4}

\begin{table}[!htbp]
    \scriptsize  
    % \vspace{-1.5em}
    \caption{NM Constitutional Depth-0 H-Clusters}
    \vspace{-1em}
    \label{tab:Constitution}
    \renewcommand{\arraystretch}{0.9} 
    \rowcolors{2}{gray!25}{white}
    \begin{tabular}{@{}p{0.02\columnwidth}p{0.89\columnwidth}@{}}
        \rowcolor{darkgreen} 
        \textbf{\#} & \textbf{Label} \\
        \toprule
        0 & Irrigation and Water Resource Management Principles \\
        1 & Regulation of Private Sector Influence on Public Schools and Education Services \\
        2 & Branches of Government Structure and Functionality \\
        3 & Education Funding for New Mexico's Educational Institutions \\
        4 & Legislative Proceedings and Lawmaking Activities Enacted During Sessions \\
        5 & Territorial Transition: Constitutional Ratification and Statehood Provisions\\
        6 & Governance, Land, and Taxation Framework \\
        7 & Municipal and County Financial Obligations and Liabilities Management \\
        8 & Judicial Power and Jurisdictional Frameworks \\
        9 & Public Service Election Governance Structure and Processes \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!htbp]
    \scriptsize 
    % \vspace{-1.5em}
    \caption{NM Statutory Depth-0 H-Clusters}
    \vspace{-1em}
    \label{tab:statutes}
    \renewcommand{\arraystretch}{0.9}  
    \rowcolors{2}{gray!25}{white}
    \begin{tabular}{@{}p{0.02\columnwidth}p{0.89\columnwidth}@{}}
        \rowcolor{lightgreen} 
        \textbf{\#} & \textbf{Label} \\
        \toprule
        0  & Municipal Court Civil Cases Involving Children's Rights \\
        1  & Public Education Infrastructure Management Systems \\
        % 2  &  FIX - New Mexican Subdivision Legislation Amendment Act of 2021 \\

        2 &  Criminal Codes, Local Governance Boundaries, Licensing Rules\\
        3  & Comprehensive Emergency Health and Human Services Response Framework \\
        4  & Taxation and Revenue Collection Oversight \\
        % 5  & FIX - Election Governance and Administrative Matters \\ %for Members \\
        5 & Military Decorations, Licensing Procedures, Governance Boards \\
        6  & Regulatory Insurance Contract Law and Policy Analysis \\
        7  & Public Obligations Financing and Project Bonds Issuance \\
        8  & State Government Investment Grants for Education and Economic Development \\
        9  & Irrigation and Water Rights Regulations \\
        % 10 & FIX - Legislative Repeals and Enactments \\
        % Regarding Congressional Provisions \\
        10 & Military Honors, Discrimination Penalties, and Trust Authority \\
        11 & Corporation Governance Framework and Regulatory Compliance \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!htbp]
    \scriptsize  
    % \vspace{-1.5em}
    \caption{NM Appeals Court Case Law Depth-0 H-Clusters}
    \vspace{-1em}
    \label{tab:appeals}
    \renewcommand{\arraystretch}{0.9}  
    \rowcolors{2}{gray!25}{white}
    \begin{tabular}{@{}p{0.02\columnwidth}p{0.89\columnwidth}@{}}
        \rowcolor{goldyellow} 
        \textbf{\#} & \textbf{Label} \\
        \toprule
        0  & Real Property Rights and Interests \\
        1  & Civil Liability and Injury Issues Arising from Healthcare Services \\
        2  & Parental Rights and Custody Proceedings Involving Disputed Parental Fitness \\
        3  & Motor Vehicle Insurance and Liability Claims Processing Procedures \\
        4  & Mortgage Foreclosure and Secured Lending Frameworks \\
        % 5  & FIX - Jurisdictional Determinations and Dispute Resolution Outcomes \\

        5 & Arraignments, Tribal Jurisdiction, Divorce, Bond Conditions, Motor Licensing \\ 
        6  & Courtroom Advocacy and Representation Strategies \\
        7  & Petitioner's Right to Parental Decision Making \\
        8  & Fourth Amendment Protections Against Unlawful Searches and Seizures \\
        9  & Taxation of Gross Receipts and Sales Transactions in a Business Context \\
        10 & Key Legal Concepts Related to Sexual Offenses \\
        11 & Child Protective Services Laws and Regulations \\
        12 & Work-Related Injury and Disability Compensation Process \\
        13 & Healthcare Contract Dispute Resolution Processes \\
        14 & Marital Property and Financial Disposition \\
        15 & Legal Proceedings Involving Jury Determination of Guilt \\
        16 & Probation Supervision and Monitoring Oversight Process \\
        % 17 & FIX - Delays of Criminal Trials Due to Pretrial Proceedings \\
        17 & Juvenile Protection, Miranda Rights, Evidence Collection \\
        % 18 & FIX - Court Proceedings and Decisions Regarding Agency Dispositions \\ %and Convictions \\
        18 & Firearms, Substances, DWI, and Sentencing \\
        19 & Sentencing Enhancements for Serious Repeat Offenders \\
        20 & Traffic Stop Under Suspicion with Mandatory Blood Alcohol Testing \\
        21 & Criminal Proceedings Trial Litigation Documentation and Record-Keeping Procedures \\
        22 & Workers' Rights and Insurance Benefits \\
        23 & Children's Welfare and Family Reunification Efforts \\
        24 & Public Municipal Legal Frameworks and Governance Structure \\
        % 25 & FIX - Official NMRA Decisions and Rulings Regarding State-Specific Matters \\
        25 & Business Disputes, Wrongful Injury, Taxation Appeals, Workers’ Compensation \\ 
        % 26 & FIX - Proposed Electronic Filing Requirements \\ % Memorandum \\
        26 & Administrative Disputes,  Native American Legal Memorandums \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!htbp]
    \scriptsize  
    % \vspace{-1.5em}
    \caption{NM Supreme Court Case Law Depth-0 H-Clusters}
    \vspace{-1em}
    \label{tab:supreme}
    \renewcommand{\arraystretch}{0.9} 
    \rowcolors{2}{gray!25}{white}
    \begin{tabular}{@{}p{0.02\columnwidth}p{0.89\columnwidth}@{}}
        \rowcolor{darkorange} 
        \textbf{\#} & \textbf{Label} \\
        \toprule
        0  & Arbitration of Contract Disputes and Judicial Decision-Making in Motor Vehicle Cases \\
        1  & Revenue and Taxation Frameworks in Governance and Administration \\
        % 2  & FIX - Mineral Rights Leases \\
        2  & Mineral Rights Leases \\
        3  & Native American Self-Governance and Tribal Jurisdictional Frameworks \\
        4  & Municipal Zoning Ordinances and Regulations of Local Governance Areas \\
        5  & Damages Award for Wrongful Conduct Against Business Partners \\
        % 6  & FIX - Sentencing Framework for Criminal Offenders \\ %Federal Offenders \\
        6 & Jurisdictional Appeals, Juvenile Sentencing, Felony Enhancements, Parole Terms \\
        7  & Post-Divorce Asset Distribution and Management Strategies \\
        8  & Constitutional Challenges to Public Education Governance \\
        9  & Secured Financial Instruments and Property Rights \\
        10 & Water Resource Allocation and Management \\
        11 & Electric Utility Rate Regulation Oversight Authority \\
        12 & Law Enforcement Procedures and Rights Protection under Fourth Amendment Protections \\
        13 & State Legislative Review Process Decisions \\
        14 & Denial of Petition for Habeas Corpus \\ % Review \\
        15 & Workers' Compensation Process for Work-Related Injuries and Disabilities \\
        16 & Real Estate Boundary Disputes and Conveyance Matters \\
        17 & Parental Rights and Legal Guardianship Proceedings \\
        18 & Appellant's Argument Against the Ruling of a Trial Court \\
        19 & Document Terms and Conditions Regarding Business Transactions \\
        20 & Mutual Insurance Policies for Vehicle and Individual Coverage \\
        21 & Accident resulting from driver error on public roadways leads to legal consequences \\
        22 & Court proceedings involving criminal trials and testimonial evidence \\
        23 & Civil Litigation Proceedings and Trials \\
        \bottomrule
    \end{tabular}
    % \vspace{-2em}
\end{table}


\begin{table}[ht]

\centering
\caption{Neo4j Node and Edge Overview}
    \vspace{-1em}
\label{tab:neo4j_counts}
\definecolor{headerblue}{HTML}{CFE2F3} 
\definecolor{lightgray}{gray}{0.92}     
\rowcolors{2}{lightgray}{white}
\begin{tabular}{@{}lrrr@{}}
  \rowcolor{headerblue}
  \toprule
  \textbf{Node Type}      & \textbf{Nodes}   & \textbf{Out Edges}   & \textbf{Legal Cites} \\
  \midrule
  \textit{NMFk} Topics             & 2,469            & 92,634               & --                   \\
  \textit{NMFk} Keyword            & 11,076            & 8,281,843                   & --                   \\
  BOW Vocabulary          & 132,423          & --                   & --                   \\
  Constitution     & 265              & 9,067                & 41                   \\
  Statute          & 28,251           & 1,930,707            & 81,353               \\
  Supreme Court Case      & 5,727            & 2,437,161            & 76,478               \\
   Court of Appeals Case       & 10,072           & 4,176,288            & 131,230              \\
  \midrule
  \textbf{Total Unique}   & \textbf{190,283} & \textbf{16,927,700}  & \textbf{289,102}     \\
  \bottomrule
\end{tabular}
\end{table}

\begin{figure}[ht]
    % \vspace{-.9em}
    \centering
    \includegraphics[width=\columnwidth]{figs/estopple.png}
    \vspace{-2em}
    \caption{Examination of `Estoppel' relating to being a keyword in topics, vs bag of word vocabulary }
    \vspace{-1em}
    \label{fig:estoppel}
\end{figure}
\subsection{Knowledge Graph}
The four data parts, 265 constitutional provisions, 28,251 Statute sections, 5,727  Supreme Court cases, and 10,072 Court of Appeals cases, were inserted into the neo4j \cite{neo4j2023} knowledge graph. 
The graph's number of nodes and edges can be seen in Table \ref{tab:neo4j_counts}, where edge counts are where the triplet's tail originates with the row's node. The legal citations were collected by iterating the text of each case or section into chat-gpt-3.5-turbo with the following prompt: "You are an expert legal document analyzer. Your job is to find all references to the Constitution, Case Law, or Statutes in the text." The result was that the LLM acted like a named entity extractor, such that any citations in the text were pulled out in an enumerated list. The citations mainly included the cases, statutes, and constitution of New Mexico but also had references to the United States Constitution, New Mexico Administrative Code, and New Mexico Rules Annotated (NMRA). The NMRA had many references to Uniform Jury instructions and the rules of criminal and civil proceedings.

In figure \ref{fig:estoppel}, the \textit{NMFk} topic cluster keyword and a bag of word vocabulary were both queried for `estoppel.' The \textit{NMFk} keyword is Dark blue, the topics are light blue, and the BOW node is brown. Three documents occur for this keyword: the statutes are green nodes, the Court of Appeals cases are yellow, and the Supreme Court cases are orange. The constitution neither clustered over the term nor mentions it, which is not represented in Figure \ref{fig:estoppel}. There is a partition in the nodes at the brown bag of words node since all nodes with the \textit{NMFk} keyword have the bag of word node connection. Still, not all documents mentioning `estoppel' were clustered with the word, which is to say other terms and concepts from those terms had more importance for the documents on the left side of the image that `estoppel'. There are 14 topics, 441 Court of Appeals cases,  276 Supreme Court Cases, and 131 Statutes in Figure \ref{fig:estoppel}. These topics have `estoppel' in their top keywords, whereas if every topic that contained `estoppel' in its words were called, there would be 341 topics. Of the 14 topics, one was connected to the Statutes, \scriptsize ``Collection and recovery of liabilities made to board members with errors and omissions." 
\normalsize Three of the 14 topics were connected to supreme court cases: 
\scriptsize ``Employment Rights and Property Disputes in New Mexico Municipal Affairs", ``Public Corporation Property Taxation Matters and Disputes with Licensing Authorities", ``Drilling and Gas Agreement Terms Regarding Oil Wells."
\normalsize Finally, the remain 10 of the 14 topics with `estoppel' in its top words were connected to cases from the Court of Appeals: \scriptsize "Litigation outcomes and jurisdictional limitations", "Administrative License Revocation Proceedings by Division Officers", "Legal Proceedings and Litigation Issues in a Medical Context", "Corporate Governance and Financial Management Matters", "Dispute Resolution Process for Agricultural Property Transactions", "Motor Vehicle Administrative License Actions", "Insanity Defense Expert Witness Testimony", "Malpractice claim within time constraints", "Employer Liability for Federal Disability Claims Against Administration Agencies", "Criminal offenses and doctrine involve multiple types of larceny charges", "Collection and recovery of liabilities made to board members with errors and omissions", "Public Corporation Property Taxation Matters and Disputes with Licensing Authorities", "Employment Rights and Property Disputes in New Mexico Municipal Affairs", "Drilling and Gas Agreement Terms Regarding Oil Wells."
\normalsize


\begin{figure}[ht]
    % \vspace{-.9em}
    \centering
    \includegraphics[width=\columnwidth]{figs/attempted_accuracy_comparison.pdf}
    \vspace{-2em}
    \caption{25 questions queried across five different LLM channels. Attempts are the percentage of responses tried to answer the question, and accuracy is the percentage of those answered with correct responses. }
    \vspace{-1em}
    \label{fig:attempted_accuracy_comparison}
\end{figure}


\subsection{Query Cross Comparison}
\definecolor{paper_purple}{rgb}{0.5, 0.0, 0.5} % Purple
\definecolor{paper_indigo}{rgb}{0.3, 0.0, 0.7} % Indigo
\definecolor{paper_blue}{rgb}{0.0, 0.0, 0.8} % Pure blue
\definecolor{paper_seagreen}{rgb}{0.0, 0.5, 0.3} % Sea green
\definecolor{paper_darkgreen}{rgb}{0.0, 0.39, 0.0} % Dark green


Questions were formulated to query information about legal concepts from LLM channels. There were five questions from each data source: the constitutional provisions, the Statutes, the Court of Appeals, and the Supreme Court. Then, five additional quantity questions were added. The results can be seen in Figure \ref{fig:attempted_accuracy_comparison}, where the five different models were  OpenAi's GPT-4 \cite{openai2023gpt4} over the API, Google's Gemini \cite{google2023gemini} over a web chat, Nvidia's nemotron:70b-instruct with 8-bit quantization \cite{nvidia2023nemotron}, OpenAi's GPT-4 \cite{openai2023gpt4}  over a web chat, and finally our system for this work, Smart-SLIC. Questions related to the Constitution appear generally answerable by the language models, likely due to its structured and concise wording. 

Answering legal questions becomes increasingly challenging with larger datasets, especially case law, which was the most difficult. Unlike statutes, where hierarchical structures are more straightforward for LLMs to train and summarize, case law is unstructured, lengthy texts that are more challenging to summarize. Constitutional questions were relatively simple, though many models mentioned articles rather than sections, citing frequent changes in how sections are enumerated. Our evaluation procedure assigns zero if the model refuses to answer and if any attempt to respond was made. Accuracy then ranges from 0 to 3: a correct or nearly correct answer receives 3, primarily correct but partially misunderstood responses receive 2, mostly incorrect yet partially true answers receive 1, and responses entirely wrong or hallucinations get 0. Some models were given points when they produced close numeric estimates, even if derived through flawed “database lookups.” In contrast, our system provides traceable reasoning by referencing the KG and analyzing the decomposed hierarchical structure of the texts themselves.

The following are comparisons between each of the models with formatting and truncations (as ...) so the text is more readable:

\textit{(a) Comparison 1 - Quantities: }
\begin{itemize}
    \footnotesize 
    \item \textbf{Question:} ``How many New Mexico Supreme Court cases mention `Habeas Corpus'?''
    \item \textbf{GPT-4,API:} %\color{paper_purple}
    \textit{I don't have the ability to provide real-time or exact counts of Supreme Court cases mentioning "habeas corpus" up to the current date...}
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}
        
    \item \textbf{GPT-4o,ChatGPT:} %\color{paper_indigo}
    \textit{Determining the exact number of New Mexico Supreme Court cases that mention 'habeas corpus' is challenging due to the extensive history of the court's decisions and the limitations of available databases...}
    %\color{black}
    
    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5 cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}
        
    \item \textbf{Smart-Slic:} % \color{paper_blue}
    \textit{There are 215 Supreme Court cases that mention 'Habeas Corpus.'} %\color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}
        
    \item \textbf{Gemini:} %\color{paper_seagreen}
    \textit{The exact number of Supreme Court cases that mention "Habeas Corpus" is difficult to determine precisely. Here's why: \textbf{- Vast Number of Cases:} ... \textbf{- Varied Mention:} ... \textbf{- No Centralized Database:} ... }
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}
    
    \item \textbf{nemotron:70b-instruct-q8\_0:} %\color{paper_darkgreen} 
    \textit{I'll outline my research methodology and then share the results.
    Research Methodology: \textbf{1. Database Selection:} ... \textbf{2. Search Parameters:} ... \textbf{3. Search Approach:} ... After conducting thorough searches across the selected databases:\textbf{ Approximate Number of Cases Mentioning 'Habeas Corpus':} Over 1,300 ... Breakdown ...: \textbf{* Pre-1950:} ... 450 ... \textbf{* 1950-2000:} ... 550 ... \textbf{* 2001-Present:} ... 300 ...}
    % \color{black}
\end{itemize}


The responses highlight significant differences in model abilities. GPT-4 API and ChatGPT provided an understanding of their limits to offer real-time or exact counts due to limitations such as access to historical databases or the complexity of case records. Gemini followed a similar pattern, explaining why determining a precise number is challenging. In contrast, our system directly reported a specific count, stating 215 cases mentioning 'Habeas Corpus,' showing its ability to process and retrieve meaningful data. Meanwhile, nemotron:70b-instruct-q8\_0 provided a detailed method to find the correct answer in an open context. It even went into breaking the count into approximate ranges across different periods, suggesting over 1,300 cases in total.  However, these counts from Nemotron are part of an extreme hallucination since it was an offline model without the ability to make any lookups. 

\textit{(b) Comparison 2 - Legal Citations: }
\begin{itemize}
    \footnotesize 
    \item \textbf{Question:} ``What are common citations among New Mexico Court of Appeals cases that mention `malpractice'?''
    
    \item \textbf{GPT-4,API:} %\color{paper_purple}
     \textit{ I don't have direct access to specific databases or the ability to browse the internet.}
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}

    \item \textbf{GPT-4o,ChatGPT:} %\color{paper_indigo}
    \textit{ In New Mexico Court of Appeals cases addressing malpractice, several key legal principles and precedents are frequently cited: 
    \textbf{Elements of Legal Malpractice:} ... Mireles v. Broderick, 1992 ...
    \textbf{Statute of Limitations:} ... Sharts v. Natelson, 1994 ...
    \textbf{Expert Testimony Requirement:} ... Rummell v. Edgemont Realty Partners ... 1993 ...
    \textbf{Causation and "Case Within a Case" Doctrine:} ... Garcia v. Rodey, Dickason, Sloan, Akin \& Robb ... 1988 ...
    \textbf{Damages:} ... Sanders, Bruin, Coll \& Worley ... 2010 ...
    }
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}
    
    \item \textbf{Smart-Slic:} %\color{paper_blue}  
    % \textit{\textbf{1.} Rule 12-405 NMRA with 61 cases  \textbf{2.} NMSA 41-5-1 with 36 cases  \textbf{3.} NMSA 41-5-13 with 35 cases  \textbf{4.} NMSA 41-4-1 with 23 cases  \textbf{5.} CERVANTES\_v\_FORBIS\_1964 with 18 cases}
    \textit{The common citations among New Mexico Court of Appeals cases that mention 'malpractice' include NMSA 41-5-1 with 36 cases, NMSA 41-5-13  with 35 cases, NMSA 41-4-1 with 23 cases, CERVANTES v FORBIS 1964 with 18 cases, NMSA 37-1-8  with 15 cases, NMSA 41-5-3  and NMSA 41-5-15  each with 14 cases, NMSA 41-5-6  with 13 cases, GOODMAN v BROCK 1972  with 12 cases, and NMSA 41-5-22 with 10 cases.}
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}

    \item \textbf{Gemini:} %\color{paper_seagreen} 
    \textit{ \textbf{Common citations in New Mexico Court of Appeals cases mentioning "malpractice" often include:} - Leyba v. Whitley...1995... - Rancho del v. Weisfeld...1995...
    Bassett v. Sheehan, Sheehan \& Stelzner...2008...
    Akutagawa v. Laflin, Pick \& Heer...2005... }
    % \color{black}

    \begin{flushright}
        \vspace{-0.25cm}
        \rule{7.5cm}{0.01mm} 
        \vspace{-0.08cm}
    \end{flushright}

    \item \textbf{nemotron:70b-instruct-q8\_0:} %\color{paper_darkgreen} 
    \textit{Steps to Find Common Citations: \textbf{1. Access Legal Databases:} ... \textbf{2. Construct Your Search Query:} ... \textbf{3. Filter Results (if possible):} ... 
    \textbf{4. Analyze Top Cases for Citations:} ... 
    Please note, the following are hypothetical examples... 
    \textbf{1. Cases: - Hypothetical Example 1:} Smith v. Jones, 2010 ... 
    \textbf{- Hypothetical Example 2:} Doe v. Healthcare Inc., 2015 ...
    \textbf{2. Statutes or Regulations:} - ... NMSA 1978, Section 41-5-1 ... - NMSA 1978, § 41-4-11 to 41-4-17 ...   \textbf{3. Court Rules:} - ... NMRCvP, Rule 1-026 ... - ... NMRE, Rule 702 ...}
    % \color{black}
\end{itemize}

GPT-4 API again opted not to answer, stating that it did not have access to specific databases or the ability to browse legal records. GPT-4o (ChatGPT), on the other hand, offered an insightful summary of key legal principles and precedents frequently cited in malpractice cases, naming specific examples like Mireles v. Broderick (1992) and Garcia v. Rodey (1988). This response demonstrated domain awareness but was missing particular detail.

In contrast, our system delivered a detailed list of the most common citations, including exact counts for specific statutes and cases, such as NMSA 41-5-1 cited in 36 cases and CERVANTES v FORBIS (1964) cited in 18 cases. Our system's response is specific and direct, allowing for faster and more reasoned legal research. Meanwhile, Gemini offered a mix of case-specific citations, similar to GPT-4o, but with limited depth and no accompanying counts, which made the response less precise.

Finally, nemotron:70b-instruct-q8\_0 outlined a hypothetical strategy to find citations, including steps like accessing legal databases and filtering results. However, the examples provided, such as "Smith v. Jones, 2010," were explicitly hypothetical, undermining the credibility of the response. Additionally, nemotron's inclusion of actual statutes like NMSA 41-5-1 blurred the line between hypothetical examples and genuine analysis, leading to potential confusion.

This comparison highlights the strengths and weaknesses of each system: some models are better at summarizing legal principles, such as GPT-4o and Gemini, while our System shows the capability for precise data retrieval and analysis. Nemotron, despite its detailed methodology, suffered most from hallucinations. 
% \subsection{Vector Store}
% Each section and case from the four parts are vectorized into Milvus \cite{2021milvus}. Each data set has two embeddings and a subsequent index: the raw uncleaned title and full text of the document and a layman's term translation of the law. The layman term summarization was made using llama3.2:3b-instruct-fp16. To make the layman's terms, the Constitution took 20 minutes, the statutes took 14 hours 2 minutes, the Supreme Court cases took 8 hours 42 minutes, and the Court of Appeals took 13 hours 33 minutes. The benefit of the second index, in layman's terms, allows natural language questions to more closely approximate the correct embedding of the legal section without requiring more formal legal terms in question formulation, with the benefit of the raw text index for support on queries more directly matching the natural law language.


\begin{figure}[h]
    % \vspace{-.9em}
    \centering
    \includegraphics[width=\columnwidth]{figs/mrr_retreival.pdf}
    \vspace{-3em}
    \caption{MRR and top 10 hit rate percentage per data category over several embedding methods.}
    \vspace{-2em}
    
    \label{fig:mrr_retrieval}
\end{figure}
\subsection{Question Answering}
To evaluate the effectiveness of our QA SLIC-SMART system, we conducted a series of experiments focusing on various performance metrics. Figure \ref{fig:mrr_retrieval} shows various retrieval methods from the embedding space. The four data sources are treated separately for comparison. Each data source uses four separate methods to embed the data. The first is the entire corpus of each, where all documents are put into a single vector store. Where the text was short and structured, this had top 10 retrieval percentages more significant than 70 to 80\%, such as the statutes and constitutional provisions. The cases had less structure and longer text, making the plain embedding challenging.  Next is the chunking method, where the entire dataset is again placed into a single dataset but chunked at 3000 characters with 500 overlapping. The top row, with more concise and structured concepts, decreased slightly in performance, whereas the cases significantly improved. This is likely because the concepts are broken down across multiple texts instead of being in one coherent text to query. Still, with the decrease, the structured texts outperformed the cases by more than 20\%. Third, the \textit{NMFk} hierarchical cases are incorporated into the vector store process, where each topic has an individual vector store. The topics per query were controlled such that the query was searched in the vector store corresponding to the question origin. Topic identification in the vector store is an outstanding problem for future work. When the \textit{NMFk} hierarchical topics were introduced, the performance significantly improved across all data sources, with the most significant gains in the longer case texts. When the chunking process was incrementally added on top of the \textit{NMFk} topics, the cases still improved, again likely to break up much larger texts into more meaningful segments of the texts. In contrast, the structured texts in the constitutional provisions and the statutes slightly decreased performance, likely attributed to the splitting of concepts in the questions across several chunks. Still, \textit{NMFk} topics with chunking and correct topic identification outperform the other methods overall. 

\subsubsection{Case Studies}
To illustrate the practical applications and effectiveness of the QA Smart-Slic system, we present four detailed case studies:

\textit{(a) Case Study 1 - Constitutional Analysis:}
\begin{itemize}
\footnotesize 
    \item \textbf{Question Source:} Article IV, Section 22 \cite{nm_const_art4_sec22}
    \item \textbf{Question:} ``What happens to a bill if the governor neither returns it within the specified three-day window (Sundays excepted) nor signs it?''
    \item \textbf{Response:}  %\color{paper_blue}
    \textit{According to Article IV - Legislative Department -- § 22 "Governor's approval or veto of bills" of the provided text, if a bill is presented to the governor and he neither returns it within the specified three-day window (Sundays excepted) nor signs it, then the bill becomes a law automatically, whether signed by him or not, unless the legislature by adjournment prevents such return.}
    % \color{black}
\end{itemize}

\textit{(b) Case Study 2 - Statutory Analysis:}
\begin{itemize}
\footnotesize 
    \item \textbf{Question Source:} Chapter 50, Article 17, Section 3 \cite{healthy_workplaces_earned_sick_leave}
    \item \textbf{Question:} ``Under the Healthy Workplaces Act, how does an employee accrue and utilize earned sick leave, and what provisions exist for its carryover, use for family or personal health, and reinstatement after separation from employment?''
    \item \textbf{Response:} %\color{paper_blue}
    \textit{ \textbf{Accrue}: Employees accrue a minimum of one hour of earned sick leave for every thirty hours worked. Employers may elect to provide the full sixty-four hours of earned sick leave for the year on January 1 or pro-rata for mid-year hires. \\
    \textbf{Use}: Earned sick leave can be used for the employee’s or their family members' illness, injury, health condition, medical care, or preventive medical care. It can also be used for issues related to domestic abuse, sexual assault, or stalking. \\
    \textbf{Carryover}: Unused earned sick leave carries over year to year, although use may be capped at 64 hours per twelve-month period, unless the employer sets a higher cap. \\
    \textbf{Reinstatement}: If an employee is rehired within twelve months of separation by the same employer, previously accrued and unused earned sick leave must be reinstated. Additionally, the employee is entitled to accrue additional sick leave upon re-commencement of employment.}
    % \color{black}
\end{itemize}

\textit{(c) Case Study 3 - Court of Appeals Case Law Analysis:}
\begin{itemize}
\footnotesize 
    \item \textbf{Question Source:} KRM, Inc. v. Caviness, 1996 \cite{krm_v_caviness_1996}
    \item \textbf{Question:} ``In the case KRM, Inc. v. Caviness, what was the court's reasoning for determining that the water rights established by Williams' 1963 declaration did not belong to the land sold to Caviness?''
    \item \textbf{Response:} %\color{paper_blue}
    \textit{The court determined that the water rights established by Williams' 1963 declaration were not appurtenant to the land sold to Caviness because there was no evidence that the water had been used for irrigation on that land. Since the appropriated water was never used for irrigation purposes on the property, it did not qualify as appurtenant water rights that would automatically transfer with the land. The court concluded because the usage of the water was unrelated to the benefit or use of the land itself, the water rights remained separate and did not pass to Caviness when he purchased the land.}%\color{black}
\end{itemize}

\textit{(d) Case Study 4 - Supreme Court Case Law Analysis:}
\begin{itemize}
\footnotesize 
    \item \textbf{Question Source:} Smith v. South, 1955 \cite{smith_v_south_1955}
    \item \textbf{Question:} ``In Smith v. South, what were the legal issues raised regarding the enforceability of the Washington child support decree in New Mexico, and how did the court address the conflict between the parties' post-decree agreement and the original judgment?''
    \item \textbf{Response:} %\color{paper_blue}"
    \textit{The legal issues raised in Smith v. South regarding the enforceability of the Washington child support decree in New Mexico included whether New Mexico courts should acknowledge and enforce the original Washington decree for child support or consider the modifications reportedly agreed upon by the parties after the decree. The conflict between the parties' post-decree agreement and the original judgment involved assertions that they had informally agreed to alter the child support payments stipulated by the Washington court. \\    
    The court addressed this issue by considering the jurisdictional and legal principles guiding child support enforcement across state lines. They emphasized the importance of adhering to the formal judicial process. The court likely examined whether the post-decree modifications had been legally formalized or approved by any court, and whether such modifications complied with the relevant child support enforcement laws, particularly under the Uniform Interstate Family Support Act (UIFSA), though it wasn't explicitly mentioned in the text snippet. UIFSA provides mechanisms for establishing, enforcing, and modifying child support orders across state boundaries. \\
    If the modifications were not legally recognized through a court process, the original Washington decree would remain enforceable in New Mexico, and any informal or unratified agreements between the parties would not typically alter the enforceability of the court-ordered decree. The court would focus on ensuring that child support arrangements comply with legal standards to serve the children's best interests and that enforcement respects the authority of the original jurisdiction (Washington) unless properly modified through legal channels.}%\color{black}
\end{itemize}
 

