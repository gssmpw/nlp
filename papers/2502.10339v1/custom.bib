##### Dataset paper
# piqa
@inproceedings{Bisk2020,
  author = {Yonatan Bisk and Rowan Zellers and
            Ronan Le Bras and Jianfeng Gao
            and Yejin Choi},
  title = {PIQA: Reasoning about Physical Commonsense in
           Natural Language},
  booktitle = {Thirty-Fourth AAAI Conference on
               Artificial Intelligence},
  year = {2020},
}
# boolq
@inproceedings{clark2019boolq,
  title =     {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
 author =    {Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  booktitle = {NAACL},
  year =      {2019},
}

# Finance
@article{Malo2014GoodDO,
  title={Good debt or bad debt: Detecting semantic orientations in economic texts},
  author={P. Malo and A. Sinha and P. Korhonen and J. Wallenius and P. Takala},
  journal={Journal of the Association for Information Science and Technology},
  year={2014},
  volume={65}
}

# IMDB
@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

# AG_News
@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

# Hellaswag
@inproceedings{zellers2019hellaswag,
    title={HellaSwag: Can a Machine Really Finish Your Sentence?},
    author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
    booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
    year={2019}
}

# QASC
@article{allenai:qasc,
      author    = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Jansen and Ashish Sabharwal},
      title     = {QASC: A Dataset for Question Answering via Sentence Composition},
      journal   = {arXiv:1910.11473v2},
      year      = {2020},
}

# STSB
@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}



#####



@article{yadav2024ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

# The review paper
@article{yang2024model,
  title={Model merging in llms, mllms, and beyond: Methods, theories, applications and opportunities},
  author={Yang, Enneng and Shen, Li and Guo, Guibing and Wang, Xingwei and Cao, Xiaochun and Zhang, Jie and Tao, Dacheng},
  journal={arXiv preprint arXiv:2408.07666},
  year={2024}
}

# weight disentanglement
@article{ortiz2024task,
  title={Task arithmetic in the tangent space: Improved editing of pre-trained models},
  author={Ortiz-Jimenez, Guillermo and Favero, Alessandro and Frossard, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{tang2023parameter,
  title={Parameter efficient multi-task model fusion with partial linearization},
  author={Tang, Anke and Shen, Li and Luo, Yong and Zhan, Yibing and Hu, Han and Du, Bo and Chen, Yixin and Tao, Dacheng},
  journal={arXiv preprint arXiv:2310.04742},
  year={2023}
}

@article{jin2024fine,
  title={Fine-Tuning Linear Layers Only Is a Simple yet Effective Way for Task Arithmetic},
  author={Jin, Ruochen and Hou, Bojian and Xiao, Jiancong and Su, Weijie and Shen, Li},
  journal={arXiv preprint arXiv:2407.07089},
  year={2024}
}

@inproceedings{lv2023parameter,
  title={Parameter-efficient weight ensembling facilitates task-level knowledge transfer},
  author={Lv, Xingtai and Ding, Ning and Qin, Yujia and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={270--282},
  year={2023}
}

@article{liu2023tangent,
  title={Tangent transformers for composition, privacy and removal},
  author={Liu, Tian Yu and Golatkar, Aditya and Soatto, Stefano},
  journal={arXiv preprint arXiv:2307.08122},
  year={2023}
}

## LMC
@inproceedings{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},
  booktitle={International conference on machine learning},
  pages={1309--1318},
  year={2018},
  organization={PMLR}
}

@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{tatro2020optimizing,
  title={Optimizing mode connectivity via neuron alignment},
  author={Tatro, Norman and Chen, Pin-Yu and Das, Payel and Melnyk, Igor and Sattigeri, Prasanna and Lai, Rongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15300--15311},
  year={2020}
}

## permutaiton-based
@article{singh2020model,
  title={Model fusion via optimal transport},
  author={Singh, Sidak Pal and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22045--22055},
  year={2020}
}

@article{imfeld2023transformer,
  title={Transformer fusion with optimal transport},
  author={Imfeld, Moritz and Graldi, Jacopo and Giordano, Marco and Hofmann, Thomas and Anagnostidis, Sotiris and Singh, Sidak Pal},
  journal={arXiv preprint arXiv:2310.05719},
  year={2023}
}

@article{ainsworth2209git,
  title={Git Re-Basin: Merging Models modulo Permutation Symmetries, March 2023},
  author={Ainsworth, Samuel K and Hayase, Jonathan and Srinivasa, Siddhartha},
  journal={URL http://arxiv. org/abs/2209.04836}
}

@inproceedings{guerrero2022re,
  title={Re-basin via implicit Sinkhorn differentiation. In 2023 IEEE},
  author={Guerrero Pena, Fidel A and Medeiros, Heitor R and Dubail, Thomas and Aminbeidokhti, Masih and Granger, Eric and Pedersoli, Marco},
  booktitle={CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={20237--20246},
  year={2022}
}

## Task vector related
# weighted base
@article{matena2022merging,
  title={Merging models with fisher-weighted averaging},
  author={Matena, Michael S and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17703--17716},
  year={2022}
}
@article{tam2024merging,
  title={Merging by Matching Models in Task Parameter Subspaces},
  author={Tam, Derek and Bansal, Mohit and Raffel, Colin},
  journal={Transactions on Machine Learning Research},
  year={2024}
}
@article{daheim2023model,
  title={Model merging by uncertainty-based gradient matching},
  author={Daheim, Nico and M{\"o}llenhoff, Thomas and Ponti, Edoardo Maria and Gurevych, Iryna and Khan, Mohammad Emtiyaz},
  journal={arXiv preprint arXiv:2310.12808},
  year={2023}
}

@article{yang2023adamerging,
  title={Adamerging: Adaptive model merging for multi-task learning},
  author={Yang, Enneng and Wang, Zhenyi and Shen, Li and Liu, Shiwei and Guo, Guibing and Wang, Xingwei and Tao, Dacheng},
  journal={arXiv preprint arXiv:2310.02575},
  year={2023}
}
@article{zhou2024metagpt,
  title={MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic},
  author={Zhou, Yuyan and Song, Liang and Wang, Bingning and Chen, Weipeng},
  journal={arXiv preprint arXiv:2406.11385},
  year={2024}
}



@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}


@inproceedings{yu2024language,
  title={Language models are super mario: Absorbing abilities from homologous models as a free lunch},
  author={Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{davari2023model,
  title={Model breadcrumbs: Scaling multi-task model merging with sparse masks},
  author={Davari, MohammadReza and Belilovsky, Eugene},
  journal={arXiv preprint arXiv:2312.06795},
  year={2023}
}

@article{huang2024emr,
  title={EMR-Merging: Tuning-Free High-Performance Model Merging},
  author={Huang, Chenyu and Ye, Peng and Chen, Tao and He, Tong and Yue, Xiangyu and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2405.17461},
  year={2024}
}

## SVD used in other

# model compression
@article{hsu2022language,
  title={Language model compression with weighted low-rank factorization},
  author={Hsu, Yen-Chang and Hua, Ting and Chang, Sungen and Lou, Qian and Shen, Yilin and Jin, Hongxia},
  journal={arXiv preprint arXiv:2207.00112},
  year={2022}
}
@article{yuan2023asvd,
  title={Asvd: Activation-aware singular value decomposition for compressing large language models},
  author={Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Wu, Qiang and Yan, Yan and Sun, Guangyu},
  journal={arXiv preprint arXiv:2312.05821},
  year={2023}
}
@article{wang2024svd,
  title={Svd-llm: Truncation-aware singular value decomposition for large language model compression},
  author={Wang, Xin and Zheng, Yu and Wan, Zhongwei and Zhang, Mi},
  journal={arXiv preprint arXiv:2403.07378},
  year={2024}
}




# PEFT
@article{hartford2024spectrum,
  title={Spectrum: Targeted Training on Signal to Noise Ratio},
  author={Hartford, Eric and Atkins, Lucas and Neto, Fernando Fernandes and Golchinfar, David},
  journal={arXiv preprint arXiv:2406.06623},
  year={2024}
}
@article{lingam2024svft,
  title={SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors},
  author={Lingam, Vijay and Tejaswi, Atula and Vavre, Aditya and Shetty, Aneesh and Gudur, Gautham Krishna and Ghosh, Joydeep and Dimakis, Alex and Choi, Eunsol and Bojchevski, Aleksandar and Sanghavi, Sujay},
  journal={arXiv preprint arXiv:2405.19597},
  year={2024}
}

## SVD used in task vectors
@article{gao2024ethos,
  title={Ethos: Rectifying language models in orthogonal parameter space},
  author={Gao, Lei and Niu, Yue and Tang, Tingting and Avestimehr, Salman and Annavaram, Murali},
  journal={arXiv preprint arXiv:2403.08994},
  year={2024}
}






## Paper of Laguage Model
@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

## paper of finetuned checkpoints
@article{tang2024fusionbench,
  title={FusionBench: A Comprehensive Benchmark of Deep Model Fusion},
  author={Tang, Anke and Shen, Li and Luo, Yong and Hu, Han and Do, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2406.03280},
  year={2024}
}

@article{bruel2024compress,
  title={Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead},
  author={Br{\"u}el-Gabrielsson, Rickard and Zhu, Jiacheng and Bhardwaj, Onkar and Choshen, Leshem and Greenewald, Kristjan and Yurochkin, Mikhail and Solomon, Justin},
  journal={arXiv preprint arXiv:2407.00066},
  year={2024}
}

@article{candes2010matrix,
  title={Matrix completion with noise},
  author={Candes, Emmanuel J and Plan, Yaniv},
  journal={Proceedings of the IEEE},
  volume={98},
  number={6},
  pages={925--936},
  year={2010},
  publisher={IEEE}
}

@article{candes2012exact,
  title={Exact matrix completion via convex optimization},
  author={Candes, Emmanuel and Recht, Benjamin},
  journal={Communications of the ACM},
  volume={55},
  number={6},
  pages={111--119},
  year={2012},
  publisher={ACM New York, NY, USA}
}

@article{dabov2007image,
  title={Image denoising by sparse 3-D transform-domain collaborative filtering},
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  journal={IEEE Transactions on image processing},
  volume={16},
  number={8},
  pages={2080--2095},
  year={2007},
  publisher={IEEE}
}

@article{cai2010singular,
  title={A singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and Cand{\`e}s, Emmanuel J and Shen, Zuowei},
  journal={SIAM Journal on optimization},
  volume={20},
  number={4},
  pages={1956--1982},
  year={2010},
  publisher={SIAM}
}

# CLIP
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{
wang2024localizing,
title={Localizing Task Information for Improved Model Merging and Compression},
author={Ke Wang and Nikolaos Dimitriadis and Guillermo Ortiz-Jimenez and Fran{\c{c}}ois Fleuret and Pascal Frossard},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=DWT9uiGjxT}
}

@inproceedings{
zhu2024model,
title={Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models},
author={Didi Zhu and Zhongyisun Sun and Zexi Li and Tao Shen and Ke Yan and Shouhong Ding and Chao Wu and Kun Kuang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=piujJIF3zs}
}