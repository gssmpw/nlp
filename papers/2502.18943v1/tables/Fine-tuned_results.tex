\begin{table}[!t]
\footnotesize
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\centering
\setlength{\tabcolsep}{2.5pt}
\caption{Attack results on LLaMA-Doctor and OPT-History show that PETAL remains effective on fine-tuned LLMs.}
\vspace{-1mm}
\scalebox{0.96}
{
\begin{tabular}{c|cccccc}
\toprule
Metrics & \multicolumn{2}{c}{TPR@1\%FPR$\uparrow$}& \multicolumn{2}{c}{AUC$\uparrow$}& \multicolumn{2}{c}{Balanced Acc$\uparrow$}\\
\cmidrule(l{5pt}r{5pt}){2-3}\cmidrule(l{5pt}r{5pt}){4-5}\cmidrule(l{5pt}r{5pt}){6-7}
Models & LLaMA-3.2& OPT& LLaMA-3.2& OPT& LLaMA-3.2& OPT\\
\midrule
PPL attack& 19.2\%& 7.8\%& 0.86& 0.75& 0.78& 0.70\\
WS attack& 13.0\% & 1.3\%& 0.65& 0.50& 0.64& 0.51\\
RS attack& 3.5\%  & 1.8\%& 0.54& 0.50& 0.52& 0.51\\
BT attack& 2.7\%  & 1.3\%& 0.59& 0.49& 0.58& 0.51\\
PETAL (Ours)& \textbf{20.7\%}& \textbf{8.9\%}& \textbf{0.87}& \textbf{0.74}& \textbf{0.79}& \textbf{0.68}\\
\bottomrule
\end{tabular}
}
\vspace{-1em}
\label{table: fine-tuning results on chatdoctor}
\end{table}