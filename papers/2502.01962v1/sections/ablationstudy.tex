% -------------------------------
\subsection{Ablation Analysis}
\label{sec4:4}
% -------------------------------
In our ablation analysis for ISeg and ODet,
%we aim to explore the answers of the following two key questions: 1)~\emph{what is the contribution of each component in META to the overall performance?} 2)~\emph{how does the performance of our MEA compare to other modules that can be used for adapters?} To find the answers to these questions, 
we adopt Mask R-CNN~\citep{he2017mask} under the 3$\times$ training schedule with MS as the baseline and report the experimental results on the \emph{val} set of MS-COCO~\citep{caesar2018coco}, where the ImageNet-1k pre-trained ViT-B~\citep{li2022exploring} is used as the backbone. For SSeg, we choose UperNet~\citep{xiao2018unified} with 160k iterations as the baseline, where the ImageNet-1k pre-trained ViT-B~\citep{li2022exploring} is used as the backbone. We report the single-scale testing results on the \emph{val} set of ADE20K~\citep{zhou2017scene}.
Due to page limitations, we only present the results of the effectiveness of each component in the main paper. Other aspects, such as result comparisons with other variants of ViT adapter methods, will be provided in the supplementary materials as part of the ablation analysis.

\input{tables/table5}
% -------------------------------
\myparagraph{Effectiveness of each component.} The experimental results of gradually adding META components on the pre-trained ViT-B~\citep{li2022exploring} model are shown in Table~\ref{tab5}. First, we can observe that directly using the Attn branch as the adapter on the pre-trained ViT-B~\citep{li2022exploring} model not only fails to improve performance but also significantly decreases AP$^\textrm{m}$ and AP$^\textrm{b}$ (\ie, from $41.3\%$ to $32.1\%$ and from $45.8\%$ to $33.6\%$). This indicates that using attention alone as the feature interaction method in the adapter is not enough.
% 
Then, on this basis, when we use both the Attn branch and FFN branch as adapter components (where the layer normalization is used as a shared manner), the model's accuracy is significantly improved, surpassing the baseline model by $2.1\%$ AP$^\textrm{m}$/$0.7\%$ AP$^\textrm{b}$ and achieving $43.4\%$ AP$^\textrm{m}$/$46.5\%$ AP$^\textrm{m}$. 
At the same time, the model only has a small increase in parameters and no increase in FLOPs. The same conclusion can be drawn from the SSeg task.
\emph{Furthermore, the independent utilization of the FFN branch as the adapter component does not yield an improvement in accuracy. Instead, it significantly detracts from the model's accuracy across all three tasks evaluated.}
After that, continuing to add the Conv branch or using the cascaded mechanism can bring sustained performance improvement, \eg, $0.7\%$ and $0.2\%$ AP$^\textrm{m}$, and $1.6\%$ and $2.8\%$ AP$^\textrm{b}$, respectively. Finally, when using all components in the adapter, the model for ISeg and ODet achieves the best performance by $44.3\%$ AP$^\textrm{m}$ and $51.2\%$ AP$^\textrm{b}$ with $115.3$\textbf{M} parameters, $720$\textbf{G} FLOPs, $8.1$\textbf{GB} MC, and $11.1$ FPS. The model for SSeg achieves the best accuracy by 49.4 mIoU with $129.1$\textbf{M} parameters, $1847$\textbf{G} FLOPs, $5.9$\textbf{GB} MC, and 24.9 FPS.
% 
In addition, results in the ablation analysis reveal that the increase in the model's FLOPs and MC is mainly attributed to the utilization of the ``cascade'' mechanism. Despite this, this mechanism can lead to significant improvements in both accuracy and speed.
% -------------------------------
% \input{tables/table6}
% -------------------------------

% -------------------------------
% \myparagraph{Superiority of META.} 
% ------------------------------- 
% META is proposed as a simple and fast ViT adapter by minimizing inefficient memory access operations. In this section, we compare META with other efficient attention methods and advanced adapter methods~\citep{marouf2024mini,xia2022vision,sung2022vl}. All attention methods are used with their default settings and the same settings as the injector and extractor in ViT-adapter~\citep{chen2022vision} to ensure the fairness of the experiments. The obtained experimental results are given in Table~\ref{tab6}. First, we can observe that compared to these methods, META achieves new state-of-the-art performance in both accuracy and efficiency. We ultimately achieve an AP of $44.3\%$ with $115.3$\textbf{M} parameters, $751$\textbf{G} FLOPs, and $17.4$ FPS. It is also worth noting that our method has a significant improvement in model speed. For example, compared to the state-of-the-art ViT-adapter~\citep{chen2022vision} based on DeformableAtt~\citep{xia2022vision}, our method reduces $50.7$\textbf{M} parameters and $7$\textbf{G} FLOPs, while bringing a performance gain of $0.6$\%AP and $3.9$FPS. Since META does not make too many changes in network architecture, these results can demonstrate the advantages of our method in terms of memory access costs.
