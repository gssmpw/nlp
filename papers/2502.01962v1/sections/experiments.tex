% -------------------------------
\section{Experiments}
% -------------------------------
\subsection{Datasets and Evaluation Metrics}
\label{sec4:1}
% -------------------------------
\myparagraph{Datasets.} To facilitate a fair result comparison with existing methods, we conduct experiments, including the ablation analysis, on two commonly used datasets: MS-COCO~\citep{caesar2018coco} for ODet and ISeg, and ADE20K~\citep{zhou2017scene} for SSeg. Due to page limitations, the implementation details of these datasets will be given in the supplementary materials. 
% Below are the details of the used datasets:

% -------------------------------
% \begin{itemize}
% -------------------------------
% \item MS-COCO~\citep{caesar2018coco} is a representative yet challenging dataset for common scene IS and object detection, which consists of $118$k, $5$k and $20$k images for the \emph{training} set, the \emph{val} set and the \emph{test} set, respectively. In our experiments, the model is trained on the \emph{training} set and evaluated on the \emph{val} set.
% -------------------------------
% \item ADE20K~\citep{zhou2017scene} is a scene parsing dataset with $20$k images and $150$ object categories. Each image has pixel-level annotations for SS of objects and regions within the scene. The dataset is divided into $20$k, $2$k, and $3$k images for \emph{training}, \emph{val} and \emph{test}, respectively. Our model is trained on the \emph{training} set and evaluated on the \emph{val} set.
% -------------------------------
% \end{itemize}
% -------------------------------
% For data augmentation, random horizontal flip, brightness jittering and random scaling within the range of $[0.5, 2]$ are used in training as in~\citep{chen2022vision,luo2023forgery,zhang2023cae}. By default, the inference results are obtained at a single scale, unless explicitly specified otherwise.    

\myparagraph{Evaluation metrics.} The commonly adopted average precision (AP) and mean intersection-over-union (mIoU) are used to assess the model accuracy for ODet (AP$^\textrm{b}$)/ISeg (AP$^\textrm{m}$) and SSeg, respectively. Besides, to evaluate the efficiency, model Parameters (\#P), floating point operations (FLOPs), memory consumption (MC) of the adapter, and frames per second (FPS) are also adopted. The reported inference results are measured by A100 GPUs with per-GPU batch size 2.
%
% \emph{We acknowledge that using memory access cost can provide an intuitive reflection of a model's memory efficiency. However, since this metric is seldom reported in publicly available papers, we refrain from comparing this metric to ensure a fair comparison. Instead, we use FPS as the evaluation metric (Ref Sec.~\ref{sec4:4}), which has a strong correlation with the model's memory access cost}~\citep{liu2023efficientvit,dao2022flashattention,gu2021towards}\footnote{Due to page limitations, we only provide the key quantitative results. Qualitative results and more ablation studies will be presented in the supplementary material.}.  
% -------------------------------
\input{sections/instanceseg}
% -------------------------------
\input{sections/semanticseg}
% -------------------------------
\input{sections/ablationstudy}