\section{Related Work}
\subsection{Roadside Cameras in Intelligent Transport Systems}

Roadside cameras are common equipment in road infrastructure, providing an image feed of the road from a fixed position. They are widely available, and offer a lucrative source of diverse and rich data source for different perception tasks~\cite{ye2022rope3d, cress2024tumtraf}. Traffic monitoring and surveillance have traditionally been the most common applications~\cite{wu2006traffic, douxchamps2006high, dubska2014fully, schoepflin2003dynamic}, with the perception task typically featuring detection and localization of road users~\cite{zou2022real, zhang2024evaluating}. Roadside cameras have also been utilized for monitoring of the road condition in varying weather~\cite{ojala2024road, carrillo2020integration}. However, research on using roadside cameras for road segmentation is limited. Classical computer vision techniques such as background segmentation have been used to segment road areas from roadside camera views~\cite{fang2015automatic}, yet methods based on recent deep learning approaches have not been investigated.


\subsection{Image registration}

Image registration is a potential tool for determining and correcting changes in a roadside camera view. Image registration is the process of aligning images taken from different viewpoints of the same scene. Image registration techniques can be divided into two main categories: feature and dense-matching-based registration~\cite{marcenaro2001image}. Feature-based image registration aims to find the transform by matching image features between frames~\cite{markel1972sift}. However, feature-based techniques are not suited for roadside camera use case as the selected features can be easily corrupted by weather and illumination changes. On the other hand, dense-matching algorithms consider all pixels of the images to find optimal alignment, making them more robust to noise.  Dense-matching methods typically find the optimal transform by computing the phase correlation of all pixels in the frequency domain~\cite{tong2019image}. The frequency domain methods only support translation, scaling and rotation transforms, but these are sufficient for a roadside camera usecase with limited changes in the view. 

% \subsection{Vision Foundation Models}

% Vision foundation models~\cite{kirillov2023segment,oquab2023dinov2} are large deep learning models that have been trained on huge amount of data, usually in self-supervised manner. Thanks to the extensive training, they demonstrate excellent generalization to various domains ~\cite{wei2024stronger}. In this paper, dinov2 \cite{oquab2023dinov2} foundation model is utilized. It has been trained to produce high-level features that can be used for downstream tasks, like segmentation and depth estimation by only training a small model on top of the features. The dinov2 features are also robust to perspective changes meaning road features captured from road side camera should be similar to road features captured from dash cam. Thus, a model with dinov2 backbone trained with road side images, could potentially achieve good prediction performance with dash cam images.  

\subsection{Road segmentation in challenging conditions}

There have been efforts to create annotated road segmentation datasets from adverse weather~\cite{sakaridis2021acdc, kurup2023winter,diaz2022ithaca365,shaik2024idd,vachmanus2020semantic}, which allows development of supervised road segmentation models. However, the number of annotated images included is limited as manual annotation work is extremely time-consuming. Thus, all weather conditions can't be included in the data leading to unreliable predictions in out-of-domain scenarios. 

Trajectory-based road segmentation methods can learn to segment the road without manual annotations using the traversed route as the only supervision~\cite{alamikkotervo2024tadap,alamikkotervo2024trajectory,seo2023learning,schmid2022self,jung2024v}, allowing easy adaptation to varying driving conditions. However, it is challenging to learn to detect areas not included in the traversed route without explicit supervision. 

Typical deep learning models for the segmentation task include convolutional neural network models such as DeepLabv3~\cite{chen2017rethinking}. Recently, transformer models have gained popularity in segmentation tasks. This has been expedited with the rise of foundation models, such as DINOv2~\cite{oquab2023dinov2}, which have been extensively pretrained on vast datasets. Foundation models can provide improved performance in out-of-distribution scenarios~\cite{wei2024stronger}.

% \subsection{Research Gap}