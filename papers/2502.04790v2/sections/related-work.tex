\section{Related Work}
\label{sec:related-work}

\subsection{LLM Reasoning}
%
Many studies have explored ways to improve the logical reasoning abilities of LLMs. CoT~\citep{wei2023chainofthought} mimics human thought processes by breaking complex tasks into sequential steps.
%
Many CoT variants~\citep{eric2022star,wang2023selfconsistency, shum2023automatic} extend this framework by generating multiple reasoning chains and selecting the optimal one based on specific criteria.
%
Building on this, Tree-of-Thoughts (ToT)~\citep{yao2024tree} structures the reasoning process into a tree-like path, where each step serves as a decision point, enabling the evaluation of multiple reasoning paths and self-assessment. 
%
Similarly, Skeleton-of-Thought~\citep{ning2023skeleton} accelerates answer generation by first creating a skeletal framework and then completing the content in parallel for each point. 
Table-of-Thoughts~\citep{jin2023tab} improves reasoning accuracy through structured modeling of the reasoning process.
%
While these CoT-based methods follow structured reasoning paths, more complex reasoning structures have been proposed. For instance, Graph-of-Thoughts~\citep{besta2024graph} models reasoning as a flexible graph, allowing for non-linear task solving beyond the limitations of chains or trees. Methods such as Least-to-Most~\citep{zhou2022least} and Lambada~\citep{kazemi2022lambada} take a problem decomposition approach, breaking tasks into subproblems and solving them step-by-step, where each sub-answer informs the next step.
%
Additionally, frameworks like LReasoner~\citep{wang2021logic} introduce mechanisms that enhance reasoning by extracting logical structures embedded in the problem. Logic-LM~\citep{pan2023logic} combines symbolic solvers to convert natural language into symbolic formulas and introduces a self-refinement module to correct errors during the reasoning process. 
%
% However, the aforementioned methods prone to hallucinations and suffer from Degeneration-of-Thought which can not rectified by self-reflection that caused by lack external information and interactions between agents.
% the use of verification \citep{lightman2023lets} and feedback recording are used to enhancement reasoning capabilities. 
% STaR \citep{eric2022star} generates multiple chains of thought, from which effective ones are selected.
% \citep{zhou2022large} proposes a method for selecting the optimal prompt from the candidate set. 
% Skeleton-of-Thought \citep{ning2023skeleton} firstly generates skeleton of answer, followed by the parallel complete of content for each point in the skeleton, thus accelerating answer generation. Table-of-Thoughts \citep{jin2023tab} enhances the accuracy of reasoning through the structured modeling of the reasoning process.
\begin{table}[t]
    \centering
    \setlength\tabcolsep{1.5 pt}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Method} & \textbf{ACC (\%)} & \textbf{Token (k)} \\ 
        \midrule
        MAD & 85.4\scriptsize{$\pm 0.02$} & 18 \\ 
        \midrule
        \({\text{S}^2\text{-MAD}}\) & 85.6\scriptsize{$\pm 0.00$} & 4.73 (-72.7\%) \\ 
        \midrule
        w/ Sparse Commu. & 84.7\scriptsize{$\pm 0.00$} & 4.71 (-73.8\%) \\  
        w/o Early Stop& 84.4\scriptsize{$\pm 0.00$} & 4.99 (-72.3\%) \\ 
        w/o Jump & 80.8\scriptsize{$\pm 0.02$} & 9.45 (-47.5\%) \\ 
        w/o Filter & 87.6\scriptsize{$\pm 0.01$} & 13.4 (-25.6\%) \\ 
        \bottomrule
    \end{tabular}
    % \caption{Performance comparison of different methods}
    \caption{\textbf{Comparison of accuracy and cost saving against MAD on GSM8K dataset.} All experiments were conducted using GPT-3.5-turbo.}
    \label{tab:ablation}
\end{table}
\subsection{Multi-agent Debate}
%
MAD is a promising approach to enhance the reasoning capabilities of LLMs by facilitating discussions among multiple agents who collaboratively refine and update generated answers. 
%
\cite{liang2023encouraging} presents a MAD framework where multiple agents engage in "tit for tat" argumentation, managed by a judge, to stimulate divergent thinking in LLMs.
%
Building on this foundation, ~\cite{xiong2023examining} introduce the FORD framework, which organizes a three-stage debate aligned with real-world scenarios, comprising fair debate, mismatched debate, and round-table debate formats.
% ~\cite{du2023improving} investigate how variations in the number of agents and debate rounds influence the accuracy of outcomes.
%
~\cite{xu2023toward} present a framework that mirrors the academic peer review process, allowing models to autonomously develop solutions, review each otherâ€™s work, and revise their answers based on feedback. 
ChatEval~\citep{chan2023chateval}, another MAD framework, employs diverse communication strategies and varied role prompts to foster human-like interactions and evaluations in natural language dialogue. 
Moreover, ~\cite{wang2023apollo} address cognitive constraints in multi-agent debates by integrating prior knowledge retrieval and a self-selection module, enhancing reasoning capabilities and overall performance.
%
Further exploring collaboration, ~\cite{fu2023improving} analyze the autonomous enhancement of negotiation strategies among LLMs through role-playing and iterative AI feedback within a structured negotiation game, highlighting the trade-offs between deal quality and risk management.
% Similarly, Corex~\citep{sun2023corex} provides a suite of strategies enabling LLMs to collaborate as autonomous agents through modes such as discussion, review, and retrieval, which ultimately enhances reasoning and task outcomes.
However, as the number of agents and debate rounds increases, token costs can rise significantly. 
To mitigate this, \cite{du2023improving} suggests summarizing agent outputs at the end of each round for subsequent inputs, and \cite{sun2023corex} introduces a "forgetfulness" mechanism to retain only the previous round's output. The MAD-Sparse approach \cite{li2024improving} utilizes a sparse communication strategy, limiting information exchange to adjacent agents. Additionally, GroupDebate \cite{liu2024GroupDebate} promotes a grouping strategy, allowing agents to debate internally while sharing interim results. However, these methods do not enable agents to critically assess the redundancy of incoming information, limiting overall efficiency.
% While prior work overlooked the effectiveness of interactions between different agents, recent studies have begun to address the impact of communication connectivity in multi-agent systems. 
% For instance, \cite{li2024improving} propose a sparse communication topology within MAD systems to enhance efficiency and mitigate computational costs, while \cite{liu2024GroupDebate} organize agents into multiple debate groups to facilitate internal discussions and share interim results. 
% However, these approaches do not allow agents to evaluate the redundancy of information or its alignment with their viewpoints. In contrast, our method introduces a selective judgment mechanism, enabling agents to assess the relevance of incoming information and decide on their participation in each debate round. This capability further reduces overhead and enhances reasoning efficacy, distinguishing our approach in the field of multi-agent debate frameworks.
