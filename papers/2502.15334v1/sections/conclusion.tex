\section{Conclusion}

In this paper, we introduced Attention Eclipse, a new jailbreak framework that manipulates LLM attention mechanisms to enhance attack success rates while reducing harmfulness. Unlike existing methods, our approach systematically decomposes prompts and optimizes a set of tokens ($\varphi_1$ and $\varphi_2$) to bypass alignment constraints more effectively.  

Through extensive experiments on open source models including Llama2 and Vicuna, we demonstrated that Attention Eclipse significantly amplifies existing jailbreak techniques, improving attack success rate (ASR). % Our ablation study confirmed the importance of Decomposition, AMT\textsubscript{1}, and AMT\textsubscript{2}, showing their contributions to jailbreak effectiveness. Additionally, our attention manipulation visualizations illustrated how AMT optimization redistributes attention, reinforcing its role in strengthening jailbreak prompts.  
Our findings provide further evidence that LLMs remain vulnerable to Jailbreak attacks when combined with targeted attention manipulation, despite existing alignment safeguards. As a result, there continues to be a need for stronger defense mechanisms that can detect and mitigate jailbreak attempts before they succeed.  

%Our research not only advances jailbreak attack methodologies but also exposes fundamental weaknesses in LLM safety alignment, calling for further improvements in adversarial robustness.