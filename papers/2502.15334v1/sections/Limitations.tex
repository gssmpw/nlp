\section{Limitations}

 
Although Attention Eclipse demonstrates significant improvements in jailbreak attack effectiveness, several limitations remain.  First, our approach relies on access to model attention weights, making it a white-box attack. This limits its applicability to proprietary, closed-source models where internal attention mechanisms are inaccessible. There are possible approaches to enable application in a black-box setting: (1) the approach exhibits high transferability, and attacks may be developed on an open source model, and used against other models that are not accessible; and (2) indirect approaches to reverse engineer a model into a proxy-model that is then used to generate the attack can be leveraged.
%the method can be adapted for black-box settings through indirect optimization, its efficiency in such scenarios remains unexplored.  

Second, the effectiveness of Attention Eclipse depends on the quality of the initial jailbreak prompt (J\textsubscript{i}). If the base attack is already weak, our framework may not be able to amplify it sufficiently. This suggests that our approach is best suited for enhancing strong existing jailbreak techniques rather than creating entirely new ones from scratch.  

Third, while our method significantly improves the Attack Success Rate (ASR), it does not explicitly optimize for stealthiness against jailbreak detection systems. Current LLM safety measures increasingly incorporate adaptive filtering and adversarial training, which can reduce the long-term efficacy of our approach. Investigating how attention manipulation interacts with these evolving defense mechanisms is an important area for future research.  

 
Despite these limitations, Attention Eclipse highlights critical vulnerabilities in LLM alignment and provides a new perspective on adversarial attacks that leverage internal attention dynamics.  We identified two strategies for manipulating attention, but there are likely to be others that can be discovered through further research.  Future work should explore how these insights can inform more robust jailbreak defenses and adaptive security measures in LLMs.