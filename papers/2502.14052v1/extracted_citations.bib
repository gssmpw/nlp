@inproceedings{Conflict.resolution,
author = {Shaikh, Omar and Chai, Valentino Emil and Gelfand, Michele and Yang, Diyi and Bernstein, Michael S.},
title = {Rehearsal: Simulating Conflict to Teach Conflict Resolution},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642159},
doi = {10.1145/3613904.3642159},
abstract = {Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill—one that can be learned through deliberate practice—but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual “what if?” scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67\%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {920},
numpages = {20},
keywords = {conflict resolution, interests-rights-power, large language models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{Inkpen.et.al,
author = {Inkpen, Kori and Chancellor, Stevie and De Choudhury, Munmun and Veale, Michael and Baumer, Eric P. S.},
title = {Where is the Human? Bridging the Gap Between AI and HCI},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3299002},
doi = {10.1145/3290607.3299002},
abstract = {In recent years, AI systems have become both more powerful and increasingly promising
for integration in a variety of application areas. Attention has also been called
to the social challenges these systems bring, particularly in how they might fail
or even actively disadvantage marginalised social groups, or how their opacity might
make them difficult to oversee and challenge. In the context of these and other challenges,
the roles of humans working in tandem with these systems will be important, yet the
HCI community has been only a quiet voice in these debates to date. This workshop
aims to catalyse and crystallise an agenda around HCI's engagement with AI systems.
Topics of interest include explainable and explorable AI; documentation and review;
integrating artificial and human intelligence; collaborative decision making; AI/ML
in HCI Design; diverse human roles and relationships in AI systems; and critical views
of AI.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {human computer interaction, machine learning, artificial interlligence},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{Jacobsen.et.al,
author = {Jacobsen, Rune M\o{}berg and Bysted, Lukas Bj\o{}rn Leer and Johansen, Patrick Skov and Papachristos, Eleftherios and Skov, Mikael B.},
title = {Perceived and Measured Task Effectiveness in Human-AI Collaboration},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383104},
doi = {10.1145/3334480.3383104},
abstract = {Human-AI Collaboration is emerging all around with the increasing utilisation of AI.
Few prior studies have investigated the perceived effectiveness of users solving tasks
with AI. To expand on these, we conducted a within-subjects repeated measures study
involving 35 participants sorting household waste according to recyclability both
with and without the help of an AI system. Our results show that people both sorted
more effectively and perceived themselves more effective. Furthermore, we document
a trend where people sorting without suggestions perceived themselves more effective
than they were, while the opposite was true for people when sorting receiving suggestions.
Based on our results we propose open questions for future research on perceived effectiveness
when collaborating with AI systems.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {artificial intelligence, effectiveness, human-ai collaboration, lab study},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inbook{Schaekerman.et.al,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing
promise in medicine. However, medical assessments can be contentious, leading to expert
disagreement. This raises the question of how AI assistants should be designed to
handle the classification of ambiguous cases. Our study compared two AI assistants
that provide classification labels for medical time series data along with quantitative
uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware
AI based on real-world expert discussions to highlight cases likely to lead to expert
disagreement, and to present arguments for conflicting classification choices. Our
results demonstrate that ambiguity-aware AI can alter expert workflows by significantly
increasing the proportion of contentious cases reviewed. We also found that the relevance
of AI-provided arguments (selected from guidelines either randomly or by experts)
affected experts' accuracy at revising AI-suggested labels. Our work contributes a
novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14}
}

@inproceedings{arous.et.al,
author = {Arous, Ines and Yang, Jie and Khayati, Mourad and Cudr\'{e}-Mauroux, Philippe},
title = {OpenCrowd: A Human-AI Collaborative Approach for Finding Social Influencers via Open-Ended Answers Aggregation},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380254},
doi = {10.1145/3366423.3380254},
abstract = {Finding social influencers is a fundamental task in many online applications ranging
from brand marketing to opinion mining. Existing methods heavily rely on the availability
of expert labels, whose collection is usually a laborious process even for domain
experts. Using open-ended questions, crowdsourcing provides a cost-effective way to
find a large number of social influencers in a short time. Individual crowd workers,
however, only possess fragmented knowledge that is often of low quality. To tackle
those issues, we present OpenCrowd, a unified Bayesian framework that seamlessly incorporates
machine learning and crowdsourcing for effectively finding social influencers. To
infer a set of influencers, OpenCrowd bootstraps the learning process using a small
number of expert labels and then jointly learns a feature-based answer quality model
and the reliability of the workers. Model parameters and worker reliability are updated
iteratively, allowing their learning processes to benefit from each other until an
agreement on the quality of the answers is reached. We derive a principled optimization
algorithm based on variational inference with efficient updating rules for learning
OpenCrowd parameters. Experimental results on finding social influencers in different
domains show that our approach substantially improves the state of the art by 11.5%
AUC. Moreover, we empirically show that our approach is particularly useful in finding
micro-influencers, who are very directly engaged with smaller audiences.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {1851–1862},
numpages = {12},
keywords = {Variational Inference, Influencer finding, Human-AI Collaboration},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{bansal2021does,
  title={Does the whole exceed its parts? the effect of ai explanations on complementary team performance},
  author={Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2021}
}

@article{batson1997perspective,
  title={Perspective taking: Imagining how another feels versus imaging how you would feel},
  author={Batson, C Daniel and Early, Shannon and Salvarani, Giovanni},
  journal={Personality and social psychology bulletin},
  volume={23},
  number={7},
  pages={751--758},
  year={1997},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@inproceedings{binns2018s,
  title={'It's Reducing a Human Being to a Percentage' Perceptions of Justice in Algorithmic Decisions},
  author={Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
  booktitle={Proceedings of the 2018 Chi conference on human factors in computing systems},
  pages={1--14},
  year={2018}
}

@article{cai2019hello,
  title={" Hello AI": uncovering the onboarding needs of medical practitioners for human-AI collaborative decision-making},
  author={Cai, Carrie J and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
  journal={Proceedings of the ACM on Human-computer Interaction},
  volume={3},
  number={CSCW},
  pages={1--24},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{dakuo.et.al,
  author    = {Dakuo Wang and
               Justin D. Weisz and
               Michael J. Muller and
               Parikshit Ram and
               Werner Geyer and
               Casey Dugan and
               Yla R. Tausczik and
               Horst Samulowitz and
               Alexander G. Gray},
  title     = {Human-AI Collaboration in Data Science: Exploring Data Scientists'
               Perceptions of Automated {AI}},
  journal   = {CoRR},
  volume    = {abs/1909.02309},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.02309},
  archivePrefix = {arXiv},
  eprint    = {1909.02309},
  timestamp = {Mon, 16 Sep 2019 17:27:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-02309.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{delic2024supporting,
  title={Supporting Group Decision-Making: Insights from a Focus Group Study},
  author={Deli{\'c}, Amra and Emamgholizadeh, Hanif and Ricci, Francesco and Masthoff, Judith},
  booktitle={Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
  pages={301--306},
  year={2024}
}

@article{dellermann2021future,
  title={The future of human-AI collaboration: a taxonomy of design knowledge for hybrid intelligence systems},
  author={Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and Weber, Thorsten and Weigel, Sascha and Ebel, Philipp},
  journal={arXiv preprint arXiv:2105.03354},
  year={2021}
}

@inproceedings{dhillon.creative,
author = {Dhillon, Paramveer S. and Molaei, Somayeh and Li, Jiaqi and Golub, Maximilian and Zheng, Shaochun and Robert, Lionel Peter},
title = {Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642134},
doi = {10.1145/3613904.3642134},
abstract = {Advances in language modeling have paved the way for novel human-AI co-writing experiences. This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process. Employing a within-subjects field experiment with a Latin square design, we asked participants (N=131) to respond to argumentative writing prompts under three randomly sequenced conditions: no AI assistance (control), next-sentence suggestions (low scaffolding), and next-paragraph suggestions (high scaffolding). Our findings reveal a U-shaped impact of scaffolding on writing quality and productivity (words/time). While low scaffolding did not significantly improve writing quality or productivity, high scaffolding led to significant improvements, especially benefiting non-regular writers and less tech-savvy users. No significant cognitive burden was observed while using the scaffolded writing tools, but a moderate decrease in text ownership and satisfaction was noted. Our results have broad implications for the design of AI-powered writing tools, including the need for personalized scaffolding mechanisms.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1044},
numpages = {18},
keywords = {Generative AI, Human-AI collaboration, co-writing, writing assistants},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{donahuecomplementarity,
author = {Donahue, Kate and Chouldechova, Alexandra and Kenthapadi, Krishnaram},
title = {Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533221},
doi = {10.1145/3531146.3533221},
abstract = {Much of machine learning research focuses on predictive accuracy: given a task, create a machine learning model (or algorithm) that maximizes accuracy. In many settings, however, the final prediction or decision of a system is under the control of a human, who uses an algorithm’s output along with their own personal expertise in order to produce a combined prediction. One ultimate goal of such collaborative systems is complementarity: that is, to produce lower loss (equivalently, greater payoff or utility) than either the human or algorithm alone. However, experimental results have shown that even in carefully-designed systems, complementary performance can be elusive. Our work provides three key contributions. First, we provide a theoretical framework for modeling simple human-algorithm systems and demonstrate that multiple prior analyses can be expressed within it. Next, we use this model to prove conditions where complementarity is impossible, and give constructive examples of where complementarity is achievable. Finally, we discuss the implications of our findings, especially with respect to the fairness of a classifier. In sum, these results deepen our understanding of key factors influencing the combined performance of human-algorithm systems, giving insight into how algorithmic tools can best be designed for collaborative environments.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1639–1656},
numpages = {18},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{ferguson2023something,
  title={Something Borrowed: Exploring the Influence of AI-Generated Explanation Text on the Composition of Human Explanations},
  author={Ferguson, Sharon A and Aoyagui, Paula Akemi and Kuzminykh, Anastasia},
  booktitle={Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2023}
}

@article{ferguson2024just,
  title={Just Like Me: The Role of Opinions and Personal Experiences in The Perception of Explanations in Subjective Decision-Making},
  author={Ferguson, Sharon and Aoyagui, Paula Akemi and Kim, Young-Ho and Kuzminykh, Anastasia},
  journal={arXiv preprint arXiv:2404.12558},
  year={2024}
}

@inproceedings{fogliato2022goes,
  title={Who goes first? Influences of human-AI workflow on decision making in clinical imaging},
  author={Fogliato, Riccardo and Chappidi, Shreya and Lungren, Matthew and Fisher, Paul and Wilson, Diane and Fitzke, Michael and Parkinson, Mark and Horvitz, Eric and Inkpen, Kori and Nushi, Besmira},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1362--1374},
  year={2022}
}

@article{frenda2024perspectivist,
  title={Perspectivist approaches to natural language processing: a survey},
  author={Frenda, Simona and Abercrombie, Gavin and Basile, Valerio and Pedrani, Alessandro and Panizzon, Raffaella and Cignarella, Alessandra Teresa and Marco, Cristina and Bernardi, Davide},
  journal={Language Resources and Evaluation},
  pages={1--28},
  year={2024},
  publisher={Springer}
}

@article{gandhi2024understanding,
  title={Understanding social reasoning in language models with language models},
  author={Gandhi, Kanishk and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{gao2024collabcoder,
  title={CollabCoder: a lower-barrier, rigorous workflow for inductive collaborative qualitative analysis with large language models},
  author={Gao, Jie and Guo, Yuchen and Lim, Gionnieve and Zhang, Tianqin and Zhang, Zheng and Li, Toby Jia-Jun and Perrault, Simon Tangi},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--29},
  year={2024}
}

@inproceedings{guerdan2023ground,
  title={Ground (less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making},
  author={Guerdan, Luke and Coston, Amanda and Wu, Zhiwei Steven and Holstein, Kenneth},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={688--704},
  year={2023}
}

@inproceedings{ha2024clochat,
  title={CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models},
  author={Ha, Juhye and Jeon, Hyeon and Han, Daeun and Seo, Jinwook and Oh, Changhoon},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--24},
  year={2024}
}

@inproceedings{hayashi.et.al,
author = {Hayashi, Yugo and Wakabayashi, Kosuke},
title = {Can AI Become Reliable Source to Support Human Decision Making in a Court Scene?},
year = {2017},
isbn = {9781450346887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3022198.3026338},
doi = {10.1145/3022198.3026338},
abstract = {Recently, advances in artificial intelligence (AI) have provided support to human
decision-making, and there has been some controversy regarding whether AI can be used
to support judges in court. This study investigates the influence of data that is
presented by a robotic system on human judgment in a sentence estimation situation
in court. The study includes an experiment in which participants played the role of
a juror in a sentence estimation task. Participants were presented with scripts of
the case, reference materials regarding similar cases, and sentences given by the
expert robotic system and human, and then, determined an adequate sentence based on
this information. Results show that participants interacting with the robotic system
tend to agree with the presented material (in the same way as with human experts)
when it is adequate. This result shows that robotic systems are treated the same way
as humans, and that intelligent systems can be a reliable source of information for
human decision-making in court. Moreover, the results show that robotic systems may,
in some cases, be considered more trustworthy than humans.},
booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
pages = {195–198},
numpages = {4},
keywords = {human robot interaction, interface design, trust, recommender systems, sentence decision, human experimentation},
location = {Portland, Oregon, USA},
series = {CSCW '17 Companion}
}

@article{healey2018cognitive,
  title={Cognitive and affective perspective-taking: evidence for shared and dissociable anatomical substrates},
  author={Healey, Meghan L and Grossman, Murray},
  journal={Frontiers in neurology},
  volume={9},
  pages={491},
  year={2018},
  publisher={Frontiers Media SA}
}

@article{hemmer2021human,
  title={Human-AI Complementarity in Hybrid Intelligence Systems: A Structured Literature Review.},
  author={Hemmer, Patrick and Schemmer, Max and V{\"o}ssing, Michael and K{\"u}hl, Niklas},
  journal={PACIS},
  pages={78},
  year={2021}
}

@article{jarrahi2018artificial,
  title={Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making},
  author={Jarrahi, Mohammad Hossein},
  journal={Business horizons},
  volume={61},
  number={4},
  pages={577--586},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{kelly2023capturing,
  title={Capturing Humans’ Mental Models of AI: An Item Response Theory Approach},
  author={Kelly, Markelle and Kumar, Aakriti and Smyth, Padhraic and Steyvers, Mark},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1723--1734},
  year={2023}
}

@article{lai2021towards,
  title={Towards a science of human-ai decision making: a survey of empirical studies},
  author={Lai, Vivian and Chen, Chacha and Liao, Q Vera and Smith-Renner, Alison and Tan, Chenhao},
  journal={arXiv preprint arXiv:2112.11471},
  year={2021}
}

@misc{liang2023HELM,
      title={Holistic Evaluation of Language Models}, 
      author={Percy Liang et al.},
      year={2023},
      eprint={2211.09110},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{lu2024role-play,
  title={Large language models are superpositions of all characters: Attaining arbitrary role-play via self-alignment},
  author={Lu, Keming and Yu, Bowen and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2401.12474},
  year={2024}
}

@incollection{nicholls2018collaborative,
  title={Collaborative artificial intelligence in music production},
  author={Nicholls, Steven and Cunningham, Stuart and Picking, Richard},
  booktitle={Proceedings of the Audio Mostly 2018 on Sound in Immersion and Emotion},
  pages={1--4},
  year={2018}
}

@article{sorensen2024roadmap,
  title={A roadmap to pluralistic alignment},
  author={Sorensen, Taylor and Moore, Jared and Fisher, Jillian and Gordon, Mitchell and Mireshghallah, Niloofar and Rytting, Christopher Michael and Ye, Andre and Jiang, Liwei and Lu, Ximing and Dziri, Nouha and others},
  journal={arXiv preprint arXiv:2402.05070},
  year={2024}
}

@article{steyvers2023three,
  title={Three challenges for AI-assisted decision-making},
  author={Steyvers, Mark and Kumar, Aakriti},
  journal={Perspectives on Psychological Science},
  pages={17456916231181102},
  year={2023},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{ullman2023largetom,
  title={Large language models fail on trivial alterations to theory-of-mind tasks},
  author={Ullman, Tomer},
  journal={arXiv preprint arXiv:2302.08399},
  year={2023}
}

@article{vowels2024,
  title={Are chatbots the new relationship experts? Insights from three studies},
  author={Vowels, Laura M},
  journal={Computers in Human Behavior: Artificial Humans},
  pages={100077},
  year={2024},
  publisher={Elsevier}
}

@article{wang2024evaluating,
  title={Evaluating and Modeling Social Intelligence: A Comparative Study of Human and AI Capabilities},
  author={Wang, Junqi and Zhang, Chunhui and Li, Jiapeng and Ma, Yuxi and Niu, Lixing and Han, Jiaheng and Peng, Yujia and Zhu, Yixin and Fan, Lifeng},
  journal={arXiv preprint arXiv:2405.11841},
  year={2024}
}

@article{wilf2023think,
  title={Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities},
  author={Wilf, Alex and Lee, Sihyun Shawn and Liang, Paul Pu and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:2311.10227},
  year={2023}
}

@article{xu2024walking,
  title={Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias},
  author={Xu, Rongwu and Zhou, Zi'an and Zhang, Tianwei and Qi, Zehan and Yao, Su and Xu, Ke and Xu, Wei and Qiu, Han},
  journal={arXiv preprint arXiv:2407.15366},
  year={2024}
}

@article{y2022largetom,
  title={Do large language models understand us?},
  author={y Arcas, Blaise Ag{\"u}era},
  journal={Daedalus},
  volume={151},
  number={2},
  pages={183--197},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{zhang2020effect,
  title={Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making},
  author={Zhang, Yunfeng and Liao, Q Vera and Bellamy, Rachel KE},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={295--305},
  year={2020}
}

@article{zhang2021ideal,
  title={" An ideal human" expectations of AI teammates in human-AI teaming},
  author={Zhang, Rui and McNeese, Nathan J and Freeman, Guo and Musick, Geoff},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW3},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY, USA}
}

