@article{Fedus2021SwitchTS,
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={William Fedus and Barret Zoph and Noam M. Shazeer},
  journal={J. Mach. Learn. Res.},
  year={2021},
  volume={23},
  pages={120:1-120:39},
}

@misc{abdin2024phi3technicalreporthighly,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}, 
      author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl et al.},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      howpublished={arXiv preprint arXiv:2404.14219},
}

@article{classic_moe_1,
  author       = {Robert A. Jacobs and
                  Michael I. Jordan and
                  Steven J. Nowlan and
                  Geoffrey E. Hinton},
  title        = {Adaptive Mixtures of Local Experts},
  journal      = {Neural Comput.},
  volume       = {3},
  number       = {1},
  pages        = {79--87},
  year         = {1991},
  biburl       = {https://dblp.org/rec/journals/neco/JacobsJNH91.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{classic_moe_2,
  author       = {Michael I. Jordan and
                  Robert A. Jacobs},
  title        = {Hierarchical Mixtures of Experts and the {EM} Algorithm},
  journal      = {Neural Comput.},
  volume       = {6},
  number       = {2},
  pages        = {181--214},
  year         = {1994},
  biburl       = {https://dblp.org/rec/journals/neco/JordanJ94.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dai-etal-2024-deepseekmoe,
    title = "{D}eep{S}eek{M}o{E}: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models",
    author = "Dai, Damai  and
      Deng, Chengqi  and
      Zhao, Chenggang  and
      Xu, R.x.  and
      Gao, Huazuo  and
      Chen, Deli  and
      Li, Jiashi  and
      Zeng, Wangding  and
      Yu, Xingkai  and
      Wu, Y. et al.",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "1280--1297",
}

@inproceedings{expert_routing,
  author       = {Yanqi Zhou and
                  Tao Lei and
                  Hanxiao Liu and
                  Nan Du and
                  Yanping Huang and
                  Vincent Y. Zhao and
                  Andrew M. Dai and
                  Zhifeng Chen and
                  Quoc V. Le and
                  James Laudon},
  title        = {Mixture-of-Experts with Expert Choice Routing},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2022},
  biburl       = {https://dblp.org/rec/conf/nips/ZhouLLDHZDCLL22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand et al.},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      howpublished={arXiv preprint arXiv:2401.04088},
}

@inproceedings{moe_layer_iclr14,
  author       = {David Eigen and
                  Marc'Aurelio Ranzato and
                  Ilya Sutskever},
  title        = {Learning Factored Representations in a Deep Mixture of Experts},
  booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014,
                  Banff, AB, Canada, April 14-16, 2014, Workshop Track Proceedings},
  year         = {2014},
  biburl       = {https://dblp.org/rec/journals/corr/EigenRS13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{moe_survey,
  author       = {Weilin Cai and
                  Juyong Jiang and
                  Fan Wang and
                  Jing Tang and
                  Sunghun Kim and
                  Jiayi Huang},
  title        = {A Survey on Mixture of Experts},
  journal      = {CoRR},
  volume       = {abs/2407.06204},
  year         = {2024},
  eprinttype    = {arXiv},
  eprint       = {2407.06204},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-06204.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{wei2024skyworkmoedeepdivetraining,
      title={Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models}, 
      author={Tianwen Wei and Bo Zhu and Liang Zhao and Cheng Cheng and Biye Li and Weiwei LÃ¼ and Peng Cheng and Jianhao Zhang and Xiaoyu Zhang and Liang Zeng et al.},
      year={2024},
      eprint={2406.06563},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      howpublished={arXiv preprint arXiv:2406.06563},
}

@misc{xai2024grok,
  title = {Open Release of Grok-1},
  author = {{xAI}},
  year = {2024},
  howpublished = {\url{https://x.ai/blog/grok-os}}
}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang et al.},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      howpublished={arXiv preprint arXiv:2407.10671},
}

