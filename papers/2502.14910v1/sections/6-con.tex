\section{Conclusion}
In this paper, we proposed EvoP, an evolutionary pruning framework for robust LLM inference.
EvoP leverages a cluster-based calibration dataset sampling and an evolutionary pruning pattern searching to jointly help further search the optimal pruning pattern for the model.
Comprehensive experiments demonstrate the best performance of EvoP and high inference efficiency.
