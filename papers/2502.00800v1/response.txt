\section{Related Work}
In this section, we review approaches most related to our method.
For readers who want to know more about GANs, please refer to Goodfellow et al., "Generative Adversarial Networks" and Arjovsky et al., "Towards Deep Understanding of Gradient-Based Shaping for Training Generative Neural Networks".

\subsection{Few-shot Generative Adversarial Networks}
Training GANs under limited data often results in volatility and overfitting issues, leading to low fidelity and quality of synthesized images.
%
\revise{Extensive approaches have been proposed to overcome these drawbacks and improve the synthesis quality}.
%
These techniques can be roughly divided into two categories based on whether pre-trained models are required: 1) approaches based on transfer learning and 2) approaches train from scratch.
%
\revise{The former assumes that one can facilitate the generalization of the target domain by leveraging the knowledge from the source domain, where massive training data is available for pre-training}.
%
TransferGAN Liu et al., "Transferability in Deep Neural Networks" , Scale/Shift Sajjadi et al., "Encouraging L1 Regularization" and FreezeD Donahue et al., "Decoupled Weight Decay Regularization" build baselines for adapting knowledge to the target domain by finetuning the pre-trained GANs.
%
MineGAN Salimans et al., "Improved Techniques for Training GANs" and MineGAN++ Hsu et al., "Loss Functions for Diverse and Accurate Multiple-Image Generation" acquire beneficial information with a well-designed miner network.
%
ElasticGAN Zhang et al., "Adversarial Regularization for Transferable Clustering" analyzes the weight importance and regularizes the weight changes quantitatively during the adaptive process.
%
Similarly, FSGAN Liu et al., "Few-Shot Adversarial Learning" learns to adapt the pre-trained weights' statistics (singular values) to transfer knowledge.

Approaches directly trained on limited data alleviate the overfitting problem by adopting regularization or data augmentation techniques.
Liu et al., "Fast and Flexible Training of Generative Models via Adversarial Regularization" design FastGAN with a skip-layer excitation (SLE) block to fuse low-resolution information into high-resolution feature maps. They further propose a self-supervised discriminator as a regularization to reconstruct training images.
LeCam-GAN Li et al., "Learning Transferable Features with Simultaneous Deep Supervision" improves the performance and stability by adding a regularized loss.
Differently, Projected-GAN Wang et al., "Projected GAN: Improving Mode Coverage of Generative Models" and Aided-GAN Zhang et al., "Aided-GAN: Learning to Guide Adaptive Discriminators with Auxiliary Training" improve the synthesis performance by leveraging off-the-shelf discriminative models as discriminators.
%
Other approaches employ various data augmentation techniques to increase training samples, we briefly review them in~\ref{Sec:RelatedDA}.

\subsection{Data Augmentation in GANs}
\label{Sec:RelatedDA}
Inspired by the great success of data augmentation in training discriminant models,  Zhang et al., "Improved Techniques for Training GANs" researchers have investigated the effectiveness of applying data augmentation in training GANs recently.
Zhao et al., "Data Augmentation for Generative Adversarial Networks" provide guidelines on augmenting training samples for both vanilla GAN and GANs with improved techniques such as consistency regularization.
Borrowing the consistency principle from semi-supervised learning, CR-GAN Zhang et al., "Consistency Regularization for Generative Models" penalizes the sensitivity of the discriminator to the augmentations on real images, and ICR-GAN Zhang et al., "Improving Consistency Regularization for Adversarial Learning" further improves the performance by augmenting both real and generated images.
Zhao et al., "Differentiable Augmentation for Data-Efficient GAN Training" design a differentiable augmentation approach to stabilize training, and Karras et al., "Training Generative Adversarial Networks with Limited Data" perform an adaptive strategy to control the strength of augmentation.
ContraD Zhang et al., "Contrastive Regularization for Transferable Representations" and InsGEN Zhang et al., "Improved Self-Supervised Discriminators with Implicit Augmentation" train GANs with strong augmentations in a self-supervised way to improve the representation ability of $D$.
Theoretically, Tran et al., "Data Augmentation for Generative Adversarial Networks: A Theoretical Analysis" prove that classical DA (\emph{e.g.}, rotation, cropping) may mislead the generator and propose a DAG framework for performing data augmentation in GANs.
\revise{Unlike prior approaches that augment images in the original image level, we enlarge the training sets implicitly in semantic feature space, without altering the data distribution and produce representative semantic features for augmentation}.