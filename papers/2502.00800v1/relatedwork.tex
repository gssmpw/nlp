\section{Related Work}
In this section, we review approaches most related to our method.
For readers who want to know more about GANs, please refer to~\cite{liu2021generative} and~\cite{Survey2021VAE} for more comprehensive surveys.

\subsection{Few-shot Generative Adversarial Networks}
Training GANs under limited data often results in volatility and overfitting issues, leading to low fidelity and quality of synthesized images.
%
\revise{Extensive approaches have been proposed to overcome these drawbacks and improve the synthesis quality}.
%
These techniques can be roughly divided into two categories based on whether pre-trained models are required: 1) approaches based on transfer learning and 2) approaches train from scratch.
%
\revise{The former assumes that one can facilitate the generalization of the target domain by leveraging the knowledge from the source domain, where massive training data is available for pre-training}.
%
TransferGAN~\cite{wang2018transferring}, Scale/Shift~\cite{noguchi2019image} and FreezeD~\cite{mo2020freeze} build baselines for adapting knowledge to the target domain by finetuning the pre-trained GANs.
%
MineGAN~\cite{wang2020minegan} and MineGAN++~\cite{MineGAN++} acquire beneficial information with a well-designed miner network.
%
ElasticGAN\cite{li2020few} analyzes the weight importance and regularizes the weight changes quantitatively during the adaptive process.
%
Similarly, FSGAN learns to adapt the pre-trained weights' statistics (singular values) to transfer knowledge~\cite{robb2020few}.
Although these approaches have promoted the fidelity and diversity of GANs in low-data regimes, they still require pre-training on sufficient data.
\revise{Besides, when the domain shift between the source and target domain is large, the performance degrades significantly due to negative transfer}.

Approaches directly trained on limited data alleviate the overfitting problem by adopting regularization or data augmentation techniques.
Liu~\etal~\cite{liu2021towards} design FastGAN with a skip-layer excitation (SLE) block to fuse low-resolution information into high-resolution feature maps. They further propose a self-supervised discriminator as a regularization to reconstruct training images.
LeCam-GAN improves the performance and stability by adding a regularized loss~\cite{tseng2021regularizing}.
Differently, Projected-GAN~\cite{projectedGAN} and Aided-GAN~\cite{kumari2022ensembling} improve the synthesis performance by leveraging off-the-shelf discriminative models as discriminators.
%
Other approaches employ various data augmentation techniques to increase training samples, we briefly review them in~\ref{Sec:RelatedDA}.

\subsection{Data Augmentation in GANs}
\label{Sec:RelatedDA}
Inspired by the great success of data augmentation in training discriminant models~\cite{zhang2018mixup, shorten2019survey}, researchers have investigated the effectiveness of applying data augmentation in training GANs recently.
Zhao~\etal~~\cite{zhao2020image} provide guidelines on augmenting training samples for both vanilla GAN and GANs with improved techniques such as consistency regularization~\cite{CR2020}.
Borrowing the consistency principle from semi-supervised learning, CR-GAN penalizes the sensitivity of the discriminator to the augmentations on real images~\cite{CR2020}, and ICR-GAN further improves the performance by augmenting both real and generated images~\cite{zhao2020improved}.
Zhao~\etal~~\cite{DiffAug} design a differentiable augmentation approach to stabilize training, and Karras~\etal~~\cite{karras2020training} perform an adaptive strategy to control the strength of augmentation.
ContraD\cite{jeong2021training} and InsGEN~\cite{yang2021insgen} train GANs with strong augmentations in a self-supervised way to improve the representation ability of $D$.
Theoretically, Tran~\etal~\cite{tran2021on} prove that classical DA (\emph{e.g.}, rotation, cropping) may mislead the generator and propose a DAG framework for performing data augmentation in GANs.
\revise{Unlike prior approaches that augment images in the original image level, we enlarge the training sets implicitly in semantic feature space, without altering the data distribution and produce representative semantic features for augmentation}.