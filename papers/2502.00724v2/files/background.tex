\section{Notation and Background}\label{sec:background}
\subsection{Notations}

Upper case 
%\todo[color=green]{tilde??, HVH:Mistake} 
$\randomvec{A}$ indicates a random vector, lower case italics $a$ and boldface $\vectorsym{a}$ indicate a scalar and a vector, respectively, with $\norm{\vectorsym{a}}_2$ denoting 
the $l_2$ norm. The $i$-th element of a vector $\vectorsym{a}$ is indicated by $\squareb{\vectorsym{a}}_i$. Upper case boldface $\matsym{A}$ indicates a matrix, with its trace, determinant, transpose, Frobenius norm, spectral norm (largest singular value), and condition number denoted by $\trace{\matsym{A}}$, $\det{\matsym{A}}$, % and
$\matsym{A}^T$, $\normf{\matsym{A}}$, $\norm{\matsym{A}}_2$, and $\kappa(\matsym{A})$,
respectively.  An identity matrix of size $k\times k$ is denoted by $\matsym{I}_k$. 
For symmetric matrix $\matsym{A}$ the notation $\matsym{A} \succ 0$ (or $\matsym{A} \succeq 0$) means that $\matsym{A}$ is positive-definite (or positive semidefinite). 
%The minimal and maximal eigenvalues of a symmetric matrix $\matsym{A}$ are denoted by $\eigmin{\matsym{A}}$ and $\eigmax{\matsym{A}}$, respectively. 
%{The condition number of matrix $\matsym{A}$ is denoted by $\kappa(\matsym{A})$. }
For symmetric $\matsym{A}$ and $\matsym{B}$ the inequality $A \succ B$ means that $A-B \succ 0$. 
The minimal and maximal eigenvalues of a symmetric matrix $\matsym{A}$ are denoted by $\eigmin{\matsym{A}}$ and $\eigmax{\matsym{A}}$, respectively. {Finally, the $d \times d$ Jacobian matrix of a vector function $\pscore{\p}: \mathbb{R}^d \rightarrow \mathbb{R}^d $ is denoted by $\partial \pscore{\p} / \partial \p$.}

\input{files/background_bcrb}


% \hvhdelete{\subsection{Bayesian Cram\'er Rao Bound}
% Let $\X\in\Upsilon\subseteq\mathbb{R}^\nx$ and
% $\pr\in\Ps\subseteq\mathbb{R}^\np$
% be a random observation vector and 
% %$\pr\in\Ps\subseteq\mathbb{R}^\np$ be 
% a random parameter vector, respectively, 
% and let $\probt{\x,\p}{\X,\p}$ be their joint {probability density function (PDF)}.\footnote{To simplify %For simplicity of 
% notation we {write the expressions for continues random vector $\X$; %However, %while 
% %$\X$ %it
% %can be also be 
%  for discrete or mixed $\X$ %, in which case 
%  they % expressions 
%   can be written in terms of the joint CDF, or for $\X$ discrete $\probt{\x,\p}{\X,\pr}$ can be replaced by $P_{\X}(\x)\probt{\p | \x}{\pr|\X}$ or by $\probt{\p}{\pr} P_{\X|\pr}(\x|\p)$, where $P_{\X}(\x)$ and $P_{\X|\pr}(\x|\p)$ are the probability mass function (PMF), and conditional PMF of $\X$, respectively. } 
% }
% %of $\X$ and $\p$. 
% {For convenience we model the parameter set $\Ps$ as a closed set (in the Euclidean metric)} with no isolated points. 
% {%Then, under 
% Assume}
% the following \hvhdelete{regularity} conditions\cite[pages 33-35]{van2007bayesian}, \cite{weinstein1988general}. 
% \begin{assumption}[BCRB Regularity Conditions]
%     \label{assum:bcrb_reg}
% $\probt{\x,\p}{\X,\p}$ 


% satisfies the following conditions:  
% \begin{enumerate}[label={\ref*{assum:bcrb_reg}}.\arabic*,labelsep=*, leftmargin=*]

% \item\label{sas:derivative} The {%derivative (
% gradient
% %) of 
% $
% %\squareb{
%  \nabla_{\p}\log\probt{\x,\p}{\X,\pr}
%  %}_i \quad\forall i
%  $} with respect to $\p$  exists and {each of its elements} is absolutely integrable w.r.t $\x$ and $\p$ {on $\Upsilon \times \Ps$}.
% \hvhedit{\item \label{assume:non_singular}  The matrix  $\expectation{\nabla_{\pr}\log\probt{\x,\pr}{\X,\pr}\nabla_{\pr}\log\probt{\x,\pr}{\X,\pr}^T}{\X,\pr} 
% $  is non singular and its diagonal elements are finite. 
% }
% \item The limits $\lim\limits_{\p\rightarrow\partial\Ps\ybedit{^+}}\p\probt{\x,\p}{\X,\pr}=0$ hold, where $\partial\Ps\ybedit{^+}$ is the boundary of the set $\Ps$ augmented by the points  of $\Ps$ at infinity  in case $\Ps$ is unbounded. \label{ass:lim}
% \item  \hvhedit{The conditional expectation of the score  {%equal zero 
% vanishes for all $\x$,} $\expectation{\nabla_{\pr}\log\probt{\pr,\x}{\pr,\X}}{\pr|\X}=0$ .}\label{ass:score_expection}
% \item \hvhedit{For all $\p\in\Ps$, the densities $\probt{\x,\p}{\X,\pr}$ have a common support {$\{\x:\probt{\x,\p}{\X,\pr}>0\}\subset\mathbb{R}^{\nx}$}  w.r.t. $\x\in\Upsilon$ } that is independent of $\p$.
% \end{enumerate}
% {
% \begin{remark}
%    Assumption~\ref{assume:non_singular}, although sometimes not stated explicitly (e.g., \cite[pages 33-35]{van2007bayesian}), is, in view of \eqref{eq:bfim}, a natural non-degeneracy assumption for the BCRB.
%    %necessary for for the BCRB to be non-degenerate. 
% \end{remark}
% }

% \begin{remark}
% When $\X$ is a discrete random variable, a slightly altered set of
% regularity conditions {can be used} \cite{zeitler2012bayesian}.
% \end{remark}

%   \begin{remark}
%       In situations where {one or more of assumptions} ~\ref{ass:lim} %or 
%       and ~\ref{ass:score_expection} is not satisfied, {both can be substituted by} the bias condition $\lim\limits_{\p\rightarrow\partial\Ps\ybedit{^+}}\int_{\x}\brackets{\hat{\p}\brackets{\x}-\p}\probt{\x,\p}{\X,\pr}d \x =0$, {where $\hat{\p}\brackets{\x}$ is the estimator of $\p$ that is being considered.}
%   \end{remark}
% \end{assumption}
% {Let $\hat{\p}\brackets{\X}$ be an arbitrary estimator of $\p$  using the observation $\X$, with estimator error $\e=\p-\hat{\p}\brackets{\X}$. Then, subject to Assumptions~\ref{assum:bcrb_reg},}
% the following lower bound on the mean square error (MSE) matrix holds\cite{van2007bayesian}:
% %\todo[color=green]{Add citation}
% \begin{equation}\label{eq:bcrb}
%     \mathrm{MSE}\brackets{\e}\triangleq\expectation{\e\e^T}{\X,\pr}\succeq\bcrb\triangleq \fb^{-1},
% \end{equation}
% where $\bcrb$ is the Bayesian Cram\'er Rao Bound, and
% \begin{align}\label{eq:bfim} &\fb\triangleq\expectation{\nabla_{\pr}\log\probt{\X,\pr}{\X,\pr}\nabla_{\pr}\log\probt{\X,\pr}{\X,\pr}^T}{\X,\pr},\nonumber\\
%         &=\expectation{\nabla_{\pr}\log\probt{\pr|\X}{\pr|\X}\nabla_{\pr}\log\probt{\pr|\X}{\pr|\X}^T}{\X,\pr}
% \end{align}
% is the \emph{Bayesian Fisher Information Matrix} {(Bayesian FIM, or BFIM).}
% {The second line} in \eqref{eq:bfim} {follows by the} product rule of probability and 
% {the vanishing of} $\nabla_{\p}\log\probt{\x}{\X}=0$.
% A different {%form of representing the BFIM is by decomposition
% representation of the BFIM decomposes   it \cite{van2007bayesian} into the sum of} two parts, the \emph{{measurement} {FIM}} {$\fm$} and the \emph{prior {FIM}} {$\fp$}:
% \begin{equation}\label{eq:bfim_decomposition_base}
% \fb=\fm+\fp=\expectation{\F\brackets{\pr}}{\pr}+\fp,
% \end{equation}
% where $\F\brackets{\p}$ is the \emph{non Bayesian {FIM}} {(whose inverse is the non-Bayesian CRB)}
% \begin{align} \label{eq:non-BayesFim}
% \F\brackets{\p}\triangleq&\expectation{\nabla_{\p}\log\probt{\X|\p}{\X|\pr}\nabla^T_{\p}\log\probt{\X|\p}{\X|\pr}}{\X|\p}
% \end{align}
% \begin{equation} \label{eq:PriorFim}
%  \text{and} \qquad  \fp\triangleq\expectation{\nabla_{\pr}\log\probt{\pr}{\pr}\nabla_{\pr}\log\probt{\pr}{\pr}^T}{\pr} .
% \end{equation}
% We use the term \emph{posterior approach} to describe the computation of BFIM according to \eqref{eq:bfim}, and the term \emph{measurement-prior approach} to describe the computation based on \eqref{eq:bfim_decomposition_base}.

% In many signal processing applications, the observation consists
% of \ybedit{a set $ \mathcal{\X}=\set{\tilde{\X}_{n}}_{n=1}^{\niideval}$ of} $\niideval$ independent and identically distributed (i.i.d.) samples \ybedit{
% % . To be more precise, consider the observation vector $\X=\tilde{\X}^{(1)}\oplus \hdots \oplus\tilde{\X}^{(\niiddata)}$, which is composed of $\niiddata$ i.i.d. samples
% $\tilde{\X}_{i} \hvhedit{\in\widetilde{\Upsilon}\subseteq} \mathbb{R}^\hvhedit{\tilde{\nx}}$} 
% %\hvhedit{where 
% of dimension $\tilde{\nx}=\frac{\nx}{\niideval}$, \todoin{This models the vector $\X$ as composed of multiple iid samples, and decomposes the FIM into the sum of respective FIMs. But in most signal processing application the situation is the \emph{opposite}: there is a model for a single sample, and then one considers the acquisition of a set of multiple such iid samples (e.g., by repeated acquisition). \\
% In the case of the CRB, the standard treatment is to multiply the (Fisher) FIM by number of iid samples.\\
% For the Measurement-Prior Approach you do the same in \eqref{eq:bfim_decomposition}. which makes perfect sense.\\
% I therefore think that in the Posterior Approach, where treatment of iid measurements individually is not accessible, the correct formulation is to consider the set of iid measurements $\mathcal{X}$ as an \emph{aggregate} of measurements, and to condition on $\mathcal{X}$. \\
% In short, rather than decomposing $\Xr$ into iid measurements, for the Posterior Approach we aggregate the iid measurements into $\mathcal{X}$. This eliminates the need for $\tilde{\Xr}$ and $\tilde{d}_x$, and for the associated PDFs and FIMs; the iid samples are simple $\Xr_n \in \mathbb{R}^{d_x}$.\\
% What do you think?\\
% HVH: In general I think it better presentation. 
% I will reorder this section and let see how this does. \\
% YB: good, you can fork-off a new version and keep the current one in case we decide we like it better.


% }

% each distributed as $\tilde{\X}^{(i)}\sim\probt{\tilde{\x}|\p}{\tilde{\X}|\pr}\quad\forall i$. This allows us to reformulate the BFIM \ybedit{for the estimation of $\p$ from $\mathcal{\X}$} as
% %in the manner described below:
% \begin{equation}\label{eq:bfim_decomposition}
% \fb=\niideval\cdot\fmt+\fp=\niideval\cdot \expectation{\tilde{\F}\brackets{\pr}}{\pr}+\fp,
% \end{equation}
% where $$\tilde{\F}\brackets{\p}\triangleq\expectation{\nabla_{\p}\log\probt{\tilde{\X}|\p}{\tilde{\X}|\p}\nabla_{\p}\log\probt{\tilde{\X}|\p}{\tilde{\X}|\p}^T}{\tilde{\X}|\p}$$ is the {non-Bayesian FIM} of a single sample.}

\subsection{Overview of Score Matching}\label{sec:score_over_view}
Score matching\cite{hyvarinen2005estimation,hyvarinen2007some,liu2022estimating} is a well-known method for learning the score function of a data distribution when only having access to a set of i.i.d. samples. Various scores have been developed over the years. We begin with a brief introduction to classical score matching\cite{hyvarinen2005estimation}. Specifically, the goal of score matching is to learn, using a dataset $\ds$ of $\nds$ i.i.d. samples,
a {model} function {(represented e.g., by a neural network)} 
% \todo[inline,color=green]{Simplify the notation here? No need for subscript $p$ on $\Omega$ here.\\
% HVH:Done.}
$\pscore{\p;\Omega}:\mathbb{R}^{\np}\rightarrow\mathbb{R}^{\np}$ 
%\ybedit
{paramterized by  vector $\Omega$}, such that $\pscore{\p}=\pscore{\p;\Omega}\approx\nabla_{\p}
    \log\probt{\p}{\p}$. {%This 
    The mismatch between the true score function and the model} is formulated %into 
    as the %following 
    objective function
    % \todo[inline,color=green]{why the factor of 1/2 in this and in the other score matching objectives?\\
    % HVH:I base it on the score matching paper but it is not mandatory, already removed.}
\begin{equation}\label{eq:loss_prior}
    \mathcal{L}^0\brackets{\Omega}=\expectation{\norm{\pscore{\p;\Omega}-\nabla_{\p}
    \log\probt{\p}{\p}}_2^2}{\p},
\end{equation}
{where the expectation over $\p$ can be replaced by an empirical mean over the samples in $\ds$. }

We wish to minimize {the score mismatch} \eqref{eq:loss_prior} w.r.t. $\Omega$. Since we do not have direct access to {the true score} $\nabla_{\p}\log\probt{\p}{\pr}$, only a set of i.i.d. samples $\ds$, we cannot directly minimize the objective %in
\eqref{eq:loss_prior}. %Thus, 
Instead, an {equivalent} objective function has been {derived} in score matching\cite{hyvarinen2005estimation}
{that does not require direct access to $\nabla_{\p}\log\probt{\p}{\pr}$:%\hvhedit
\begin{equation}\label{eq:loss_prior_sm}
    {\mathcal{L}}\brackets{\Omega}=\expectation{\norm{\pscore{\pr;\Omega}}_2^2}{\pr}+2\trace{%\hvhedit
    {\expectation{\frac{\partial \pscore{\pr;\Omega}}{\partial\p}}{\pr}}}.
\end{equation}
The objective \eqref{eq:loss_prior_sm}  is related to \eqref{eq:loss_prior} via 
    ${\mathcal{L}}^0\brackets{\Omega}={\mathcal{L}}\brackets{\Omega}+C,$
where $C$ is a constant independent of $\Omega$.
The optimum parameters $\Omega^*$ can then be determined by minimizing a sample average version \eqref{eq:score_prior_mean} of the objective  \eqref{eq:loss_prior_sm} over a dataset of i.i.d. measurements.
} 

{For the relation between \eqref{eq:loss_prior} and \eqref{eq:loss_prior_sm} to hold, certain technical conditions need to be satisfied.
%while requiring the following 
First are the} boundary conditions
% \begin{assumption}[Boundary Condition]\label{eq:boundary_conditions}
% \todo[inline,color=green]{Why write the condition by components, rather than in vector form?\\
% HVH: it has convenient to my, when i develop the FSM but it is not need  here.}
\begin{equation}\label{eq:boundary_conditions}
    \lim\limits_{\p\rightarrow \Psb}\pscore{\p;\Omega}\probt{\p}{\pr}=0, 
\end{equation}
% \end{assumption}
where $\Psb$ is the boundary of the set $\Ps$ augmented by the points at infinity in $\Ps$ in case $\Ps$ is unbounded. 
{%If the boundary conditions in ~\eqref{eq:boundary_conditions} hold along some
Second are the following} regularity conditions\cite{hyvarinen2005estimation}. 
\begin{assumption}[Score Matching regularity]\label{ass:score_reg_prior} 
\hspace*{2cm}
\begin{enumerate}[label={\ref*{ass:score_reg_prior}}.\arabic*,labelsep=*, leftmargin=*]
    % \setcounter{enumi}{6}

\item The {log-{prior}} ${\log}\probt{\p}{\pr}$ is differentiable w.r.t. $\p$ {at all $\p\in\Ps$ where $\probt{\p}{\pr}>0$} \label{assum:diff_prob_prior}. 
    
%\todo[inline,color=green]{What pdf?}
\item The score neural network $\pscore{\p ;\Omega}$ is differentiable w.r.t. $\p$. 
%\todo[inline,color=green]{What score network?}
\item The expectations $\expectation{\norm{\pscore{\pr;\Omega}}_2^2}{\pr}$ and $\expectation{\norm{\nabla\log\probt{\pr}{\pr}}_2^2}{\pr}$ are finite. \label{assume:expecte_fine_score_matching}
\end{enumerate}
\end{assumption}
In case the boundary conditions \eqref{eq:boundary_conditions} do not hold, %several 
extensions have been suggested \cite{hyvarinen2007some} for  data  
 %\hvhedit{
 $\p$ with non-negative support %\ybreplace{on each dimension  $[0,\infty)$}
 {$[0,\infty)$ for each component} and %\ybreplace{the probability density function at the boundary is not zero.}
 {PDF that does not vanish at the boundary,}  or for general truncated domains\cite{liu2022estimating}.