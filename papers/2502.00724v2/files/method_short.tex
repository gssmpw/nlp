\section{Learned Bayesian Cram\'er Rao Bound:Overview}\label{sec:lbcrb_method}
%Here, 
We briefly %provide a short 
overview the problem that the LBCRB address, and the methods to compute it. {The  overview in this section covers all the information that a practitioner would need to apply the proposed techniques. Detailed formulation, derivations and theoretical analysis are in later sections.}
%that address it.
Our goal is to determine the Bayesian Cram\'er-Rao bound \eqref{eq:bcrb}
in scenarios where the prior $\probt{\p}{\pr}$, the measurement $\probt{\x|\p}{\X|\pr}$, or both are either
unknown or partially known. However, a data set 
\begin{equation}\label{eq:dataset_rel}
 \ds=\set{\p_n, \xsetr_n=\set{{\x}_{n,j}}_{j=1}^{\niiddata}   }_{%\ybedit
 {n=1}}^{\nds},
\end{equation}
of $\nds$ parameter-measurement sets pairs is given,
{where  $\p_n$ drawn from $\probt{\pr}{\pr}$ and  each $\x_{n,j}$ drawn from $\probt{\x|\p_n}{\X|\pr}$.}. 
%\hvhedit
{The measurement set in $\ds$ contains $\niiddata$ i.i.d samples %\ybreplace{given}
{for} the same value of $\p_i$.} 
% \ybreplace{which may differ from $\niideval$, $\niiddata\neq \niideval$.}
{It is acceptable that $\niiddata\neq \niideval$, that is, 
$\niiddata$  may differ from $\niideval$ defined earlier in the context of \eqref{eq:bfim_decomposition_base}}.

We %suggest 
propose two approaches %to obtain \eqref{eq:bcrb}
%\ybedit
{to learn the \name{} from $\ds$:}
 the \emph{Posterior Approach}; and the \emph{Measurement-Prior Approach}.
 
\subsection{Posterior Approach}
%\noindent
\subsubsection{\textbf{Learning Step}} Define a neural network $\postscore{\p}{\xsetr;\Omega}$ 
 parameterized by $\Omega$ 
 %\ybdelete{\footnote{\label{fn:model}
%For conciseness, we drop $\Omega$ or $\Omega^*$ from the notation, whenever the NN parameters are fixed (e.g. after training). }  } %\ybedit
{to {model} $\nabla_{\pr}\log\probt{\xsetr,\p}{\xset,\pr}$.} Then minimize the following objective %\ybedit
 {with respect to $\Omega$}:
\begin{align}\label{eq:score_post_mean}
     &\lossbsm\brackets{\Omega}=\frac{1}{\nds}\sum_{\p,\xsetr\in\ds}\ell_B\brackets{\p,\xsetr;\Omega},\\
     &\ell_B\brackets{\p,\xsetr;\Omega}\triangleq\norm{\postscore{\p}{\xsetr;\Omega}}_2^2+2\trace{{\frac{\partial \postscore{\p}{\xsetr;\Omega}}{\partial\p}}}.\nonumber
 \end{align}
%\ybedit
{Denote the minimizer determined in this step by $\Omega^*$.}

%\noindent
\subsubsection{\textbf{Evaluation Step}} %\ybedit
{Using} %\ybedit
{
$\postscores{\p}{\xsetr} \triangleq \postscore{\p}{\xsetr;\Omega^*}$
} \footnote{\label{fn:model}%
 %\hvhedit
 %{
%Note that throughout the text, 
For conciseness, we drop $\Omega$ or $\Omega^*$ from the notation, whenever the NN parameters are fixed (e.g. after training). }  
compute the Learned Bayesian Fisher Information Matrix % given by,
\begin{equation}\label{eq:mean_fully}
    \lbfimbs\triangleq \frac{1}{\nds}\sum_{\p,\xsetr\in\mathcal{D}}\postscores{\p}{\xsetr}\postscores{\p}{\xsetr}^T.
\end{equation}
Finally, to obtain the LBCRB, invert $\lbfimbs$, which results in ${\bcrb}\approx\lbcrbbs\triangleq\lbfimbs^{-1}$.  
% \end{tcolorbox}
The Posterior Approach is illustrated in Figure~\ref{fig:main_post}. 

%\hvhedit
{We emphasize that the LBCRB in \eqref{eq:mean_fully} is calculated  {for a measurement that contains  $\niideval$ i.i.d samples $\x_i, i=1, \ldots, \niideval$, where $\niideval= \niiddata$, that is, $\niideval$ coincides with the number $\niiddata = |\xsetr|$ of i.i.d samples available in the training set $\ds$ for each  value of $\p$.  %Given a dataset $\ds$ with $\niiddata$, 
}
The LBCRB can be determined for $\niideval\leq \niiddata$ {using such a data set,}  but this requires learning a different score function for each desired $\niideval$. {On the other hand, computing 
the LBCRB for $\niideval > \niiddata$ is not possible using the same $\ds$, and would require a data set with a larger $\niiddata$.
 %In contrast, the LBCRB computation for $\niideval>\niiddata$ is feasible with the upcoming 
 Both of these limitations are overcome by the Measurement-Prior Approach of the next section.
}

% \todo[inline,color=green]{YB: Need to specify that this BCRB is computed for $\niideval=\niiddata$. Is it possible to use the same $\ds$ to compute the BCRB for $\niideval <\niiddata$? What about $\niideval >\niiddata$?  Explain.\\
% HVH: Please see update text above.
% How was the vaccination ? 
% }
We %have shown 
will {quantify the approximation of $\bcrb$ by $\lbcrbbs$ and also}
show that if  {the model neural net $\postscore{\p}{\xsetr;\Omega}$} has sufficient capacity, then
{
%\begin{equation*}
$
   % \norm{
    \lbcrbbs %-\bcrb
    %}_2
    \xrightarrow{\nds\rightarrow \infty} \bcrb \quad\text{%\hvhedit
    {a.s}} 
%\end{equation*}
$
(almost surely, i.e., with probability 1). In other words, the approximation $\lbcrbbs$ enjoys the important statistical 
 property of \emph{strong consistency}.
}



\subsection{Measurement-Prior Approach}
\label{subsec:MP}
To improve the sample complexity of the Posterior Approach, we suggest to decompose, {similar to \eqref{eq:bfim_decomposition_base},} the LBCRB into two parts: Prior; and Measurement. As an additional advantage, this enables to introduce domain knowledge. We begin with the prior term.

%\noindent
\subsubsection{\textbf{Learning Prior Step}}  Define a neural network $\priorscore{\p;\paramp}$  parameterized by $\paramp$ %\ybedit
{to {model} $\nabla_{\p}\log\probt{\p}{\pr}$.} Then
%\ybedit
{find a minimizer $\Omega_P^*$ %minimize 
of the following objective
%with respect to $\Omega_P$.
}
\begin{align}\label{eq:score_prior_mean}
     &\losspsm\brackets{\paramp}=\frac{1}{\nds}\sum_{\p\in\ds}\ell_P\brackets{\p;\paramp},\\
     &\ell_P\brackets{\p;\paramp}\triangleq\norm{\priorscore{\p;\paramp}}_2^2+2\trace{\frac{\partial \priorscore{\p;\paramp}}{\partial\p}}.\nonumber
 \end{align}
%\noindent
\subsubsection{\textbf{Construct \pe{} Score Neural Network (\peac{})}} \label{subsubsec:MoISNN}
Assume knowledge of a model function $\mathcal{M}\brackets{\p}$ such that {the PDF of a single measurement sample can be expressed as} $\probt{\x|\p}{\X|\pr}=\probt{{\x}|\mathcal{M}\brackets{\p}}{\X|\vectorsym{\tau}}$, and define a neural network $\iscore{\x}{\vectorsym{\tau}; \paramf}$ that is parameterized by same parameter $\paramf$ of $\lscore{\x}{\p;\paramf}$. 
% \todo[inline,color=green]{YB:I suggest to avoid defining $\Omega_I$, as we don't need it anywhere. Just use  $\Omega_F$? }
Then, a \emph{\pe{} Score Neural Network} (\peac{}) %\ybedit
{to {model} the Fisher score $\nabla_{\p}\log\probt{{\x}|\p}{{\X}|\p}$} is given by:
\begin{equation}\label{eq:model_base_score}
\lscore{{\x}}{\p;\paramf}=\divc{\mathcal{M}\brackets{\p}}{\p}^T\at{\iscore{{\x}}{\vectorsym{\tau};\paramf}}{\vectorsym{\tau}=\mathcal{M}\brackets{\p}}.
\end{equation}
The \pe{} Score 
Neural Network is illustrated %shown 
in Figure~\ref{fig:model_inforamed}.

As an example of the application of \peac{}, consider %\ybedit
{a frequency estimation problem} . 
Let $\squareb{\X}_n=%\ybreplace{\exp\brackets{j\omega n}}
{\cos\brackets{ \theta n }}+\squareb{\randomvec{W}}_n$,
%\ybedit
{$n= 1, \ldots, N$} 
% \ybreplace{represent an observation vector in a frequency estimation context, where $\randomvec{W}$ denotes unknown random noise and $\omega$ is the frequency.}
{be the observation, with $\theta$ the frequency to be estimated, and $\randomvec{W}$   random noise with unknown distribution.} Here, $\squareb{\mathcal{M}\brackets{\p}}_n=
%\ybreplace{\exp\brackets{j\omega n}}
{\cos\brackets{\theta n}}$. Using \peac{}, we only need to learn the %\ybedit
{the score for the PDF of the} noise component, $\randomvec{W}$, {eliminating the need to learn and represent the cosine function}.
%\noindent 
\input{files/tikz/flow_two_approch_compare}
\subsubsection{\textbf{Learning Fisher Score Step}} 
%\hvhedit
{Use the neural network $\lscore{{\x}}{\p;\paramf}$ parameterized by $\paramf$ to %represent 
model {the Fisher score} $\nabla_{\p}\log\probt{\x|\p}{\X|\pr}$ {for a single measurement sample.}
Then %\ybedit
{find a mininimizer $\paramf^*$}
%minimize 
of the following objective 
%by optimizing $\paramf$ 
($\paramp%\ybedit
{^*}$ is known from the step of learning the Prior).
\begin{align}\label{eq:score_lik_mean}
    &\lossfsm\brackets{\paramf; \paramp%\ybedit
    {^*}}=\frac{1}{\nds\cdot\niiddata}\sum_{\xsetr,\p\in\mathcal{D}}\sum_{{\x}\in\xsetr}{\ell_{F}\brackets{\x,\p;\paramf,\paramp%\ybedit
    {^*}}}{} \nonumber\\
    % &+2\trace{
    % \overline{\matsym{J}}_{F}\ybedit{(\paramf)}}    +\sum_{\xsetr,\p\in\mathcal{D}}\sum_{\x\in\xsetr}\frac{\norm{\lscore{{\x}}{\p;\paramf}}_2^2}{\nds\cdot\niiddata}.\\
    &\ell_{F}\brackets{\x,\p;\paramf,\paramp%\ybedit
    {^*}}\triangleq \norm{\lscore{{\x}}{\p;\paramf}}_2^2\\
    &+2\lscore{{\x}}{\p;\paramf}^T\priorscore{\p;\paramp%\ybedit
    {^*}}+2\trace{\frac{\partial \lscore{{\x}}{\p;\paramf}}{\partial\p}}\nonumber
\end{align}
\subsubsection{\textbf{Evaluation Step}}  %\ybedit
{Using $\priorscores{\p}=\priorscore{\p; \Omega^*_P}$ and $\lscores{\x}{\p}$ = $\lscore{\x}{\p;\Omega^*_F}$ } compute %\ybedit
{the learned Measurement {FIM for a single measurement sample} and the Prior FIM}
\begin{equation} \label{eq:mean_efim_likd}
    \lmfim=\frac{1}{\nds\cdot \niiddata}\sum_{\p,\xsetr\in\ds} \sum_{\x\in\xsetr}\lscores{\x}{\p}\lscores{\x}{\p}^T,
\end{equation}
\begin{equation}\label{eq:bprior_mean}
    \lpfim=\frac{1}{\nds} \sum_{\p\in\ds} \priorscores{\p}\priorscores{\p}^T,
\end{equation}
%\ybedit
{Then}
the Learned Bayesian FIM for any desired number $\niideval$ of i.i.d samples is given by
\begin{equation}\label{eq:bfim_apx_final}
     \lbfimlps{(\niideval)} =\niideval\cdot  \lmfim+ \lpfim.
\end{equation}
Finally, %\ybedit
{%to obtain 
the Learned BCRB 
%we invert \eqref{eq:bfim_apx_final} which results in:
is obtained as }
% \begin{equation}
    $\lbcrblps=\lbfimlps^{-1}.$   
    
    %An illustration of 
    The Measurement-Prior Approach is %shown 
    illustrated in Figure~\ref{fig:main_lik_prior}. 
    
    %\ybedit
    {This method has important advantages over the Posterior Approach. First,} 
    %Using this method, we achieve 
    it provides the same guarantees as those %acquired through 
    of the Posterior Approach but with 
    %improved 
    lower sample complexity, and with a more interpretable model. %\ybedit
    {
   % \hvhedit{
   Second, because 
  %  We would like to emphasis that 
    $\niideval$ %is 
    can be chosen different to $\niiddata$,} %\hvhedit{
   % This enable an 
   the  Measurement-Prior Approach 
   can %to obtain 
   provide the LBCRB
   %} 
   for \emph{any} %\ybedit
   {desired} number of $\niideval$ i.i.d. samples without any additional effort %\ybedit
   {or additional training data, which the Posterior Approach cannot}.
   
   % \hvhedit
    {We will prove
    %provide theoretical derivation 
    that minimizing that objective in \eqref{eq:score_lik_mean} is equivalent to learning the true Fisher score $\nabla_{\p}\log\probt{\x|\p}{\X|\pr}$, and that the Fisher score neural network is consistent estimator of the true Fisher score. Moreover, we will quantify the approximation of $\bcrb$ by $\lbcrblps$ and also show that if the score neural networks $\priorscores{\p}$ and $\lscores{\x}{\p}$ have sufficient capacity, then {
    $\lbcrblps\xrightarrow{\nds\rightarrow\infty} \bcrb$} a.s. (almost surely, i.e., with probability 1). In other words, the approximation $\lbcrblps$ enjoys the important statistical property of \emph{strong consistency}. }
   % \todo[inline,color=green]{Add a summary of the theoretical analysis  and convergence result similar to that at the end of Sec. III-A?}
