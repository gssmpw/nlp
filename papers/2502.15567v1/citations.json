[
  {
    "index": 0,
    "papers": [
      {
        "key": "BIGGIO2018317",
        "author": "Battista Biggio and Fabio Roli",
        "title": "Wild patterns: Ten years after the rise of adversarial machine learning"
      },
      {
        "key": "jagielski2020high",
        "author": "Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas",
        "title": "High accuracy and high fidelity extraction of neural networks"
      },
      {
        "key": "oliynyk2023know",
        "author": "Oliynyk, Daryna and Mayer, Rudolf and Rauber, Andreas",
        "title": "I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "tramer2016stealing",
        "author": "Tram{\\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas",
        "title": "Stealing machine learning models via prediction APIs"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "goodfellow2020generative",
        "author": "Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua",
        "title": "Generative adversarial networks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "papernot2017practical",
        "author": "Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram",
        "title": "Practical black-box attacks against machine learning"
      },
      {
        "key": "juuti2019prada",
        "author": "Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N.",
        "title": "PRADA: Protecting Against DNN Model Stealing Attacks"
      },
      {
        "key": "yu2020cloudleak",
        "author": "Yu, Honggang and Yang, Kaichen and Zhang, Teng and Tsai, Yun-Yun and Ho, Tsung-Yi and Jin, Yier",
        "title": "CloudLeak: Large-Scale Deep Learning Models Stealing Through Adversarial Examples."
      },
      {
        "key": "kariyappa2021maze",
        "author": "Kariyappa, Sanjay and Prakash, Atul and Qureshi, Moinuddin K",
        "title": "Maze: Data-free model stealing attack using zeroth-order gradient estimation"
      },
      {
        "key": "truong2021data",
        "author": "Truong, Jean-Baptiste and Maini, Pratyush and Walls, Robert J and Papernot, Nicolas",
        "title": "Data-free model extraction"
      },
      {
        "key": "yuan2022attack",
        "author": "Yuan, Xiaoyong and Ding, Leah and Zhang, Lan and Li, Xiaolin and Wu, Dapeng Oliver",
        "title": "Es attack: Model stealing against deep neural networks without data hurdles"
      },
      {
        "key": "sanyal2022towards",
        "author": "Sanyal, Sunandini and Addepalli, Sravanti and Babu, R Venkatesh",
        "title": "Towards data-free model stealing in a hard label setting"
      },
      {
        "key": "wang2022black",
        "author": "Wang, Yixu and Li, Jie and Liu, Hong and Wang, Yan and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong",
        "title": "Black-box dissector: Towards erasing-based hard-label model stealing attack"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "correia2018copycat",
        "author": "Correia-Silva, Jacson Rodrigues and Berriel, Rodrigo F and Badue, Claudine and de Souza, Alberto F and Oliveira-Santos, Thiago",
        "title": "Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data"
      },
      {
        "key": "orekondy2019knockoff",
        "author": "Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario",
        "title": "Knockoff Nets: Stealing Functionality of Black-Box Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "juuti2019prada",
        "author": "Juuti, Mika and Szyller, Sebastian and Marchal, Samuel and Asokan, N.",
        "title": "PRADA: Protecting Against DNN Model Stealing Attacks"
      },
      {
        "key": "yu2020cloudleak",
        "author": "Yu, Honggang and Yang, Kaichen and Zhang, Teng and Tsai, Yun-Yun and Ho, Tsung-Yi and Jin, Yier",
        "title": "CloudLeak: Large-Scale Deep Learning Models Stealing Through Adversarial Examples."
      },
      {
        "key": "kariyappa2020defending",
        "author": "Kariyappa, Sanjay and Qureshi, Moinuddin K.",
        "title": "Defending Against Model Stealing Attacks With Adaptive Misinformation"
      },
      {
        "key": "zhang2021seat",
        "author": "Zhang, Zhanyuan and Chen, Yizheng and Wagner, David",
        "title": "{SEAT}: similarity encoder by adversarial training for detecting model extraction attack queries"
      },
      {
        "key": "liu2022seinspect",
        "author": "Liu, Xinjing and Ma, Zhuo and Liu, Yang and Qin, Zhan and Zhang, Junwei and Wang, Zhuzhu",
        "title": "SeInspect: Defending Model Stealing via Heterogeneous Semantic Inspection"
      },
      {
        "key": "dziedzic2022increasing",
        "author": "Dziedzic, Adam and Kaleem, Muhammad Ahmad and Lu, Yu Shen and Papernot, Nicolas",
        "title": "Increasing the cost of model extraction with calibrated proof of work"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "tramer2016stealing",
        "author": "Tram{\\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas",
        "title": "Stealing machine learning models via prediction APIs"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lee2019defending",
        "author": "Lee, Taesung and Edwards, Benjamin and Molloy, Ian and Su, Dong",
        "title": "Defending Against Neural Network Model Stealing Attacks Using Deceptive Perturbations"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "orekondy2019prediction",
        "author": "Tribhuvanesh Orekondy and Bernt Schiele and Mario Fritz",
        "title": "Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kariyappa2020defending",
        "author": "Kariyappa, Sanjay and Qureshi, Moinuddin K.",
        "title": "Defending Against Model Stealing Attacks With Adaptive Misinformation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kariyappa2020protecting",
        "author": "Kariyappa, Sanjay and Prakash, Atul and Qureshi, Moinuddin K",
        "title": "Protecting {DNNs} from theft using an ensemble of diverse models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2023apmsa",
        "author": "Zhang, Jiliang and Peng, Shuang and Gao, Yansong and Zhang, Zhi and Hong, Qinghui",
        "title": "APMSA: adversarial perturbation against model stealing attacks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "oliynyk2023know",
        "author": "Oliynyk, Daryna and Mayer, Rudolf and Rauber, Andreas",
        "title": "I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "tramer2016stealing",
        "author": "Tram{\\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas",
        "title": "Stealing machine learning models via prediction APIs"
      },
      {
        "key": "milli2019model",
        "author": "Milli, Smitha and Schmidt, Ludwig and Dragan, Anca D. and Hardt, Moritz",
        "title": "Model Reconstruction from Model Explanations"
      },
      {
        "key": "jagielski2020high",
        "author": "Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas",
        "title": "High accuracy and high fidelity extraction of neural networks"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2018stealing",
        "author": "Wang, Binghui and Gong, Neil Zhenqiang",
        "title": "Stealing hyperparameters in machine learning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "rolnick2020reverse",
        "author": "Rolnick, David and Kording, Konrad",
        "title": "Reverse-engineering deep relu networks"
      },
      {
        "key": "duddu2018stealing",
        "author": "Duddu, Vasisht and Samanta, Debasis and Rao, D Vijay and Balas, Valentina E",
        "title": "Stealing neural networks via timing side channels"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "fredrikson2014privacy",
        "author": "Matthew Fredrikson and Eric Lantz and Somesh Jha and Simon Lin and David Page and Thomas Ristenpart",
        "title": "Privacy in Pharmacogenetics: An {End-to-End} Case Study of Personalized Warfarin Dosing"
      },
      {
        "key": "fredrikson2015model",
        "author": "Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas",
        "title": "Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "shokri2017membership",
        "author": "Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly",
        "title": "Membership inference attacks against machine learning models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "konevcny2016federated",
        "author": "Kone$\\check{\\textrm{c}}$n{\\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt\u00e0rik, Peter and Suresh, Ananda Theertha and Bacon, Dave",
        "title": "Federated learning: Strategies for improving communication efficiency"
      },
      {
        "key": "mcmahan2017communication",
        "author": "McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera",
        "title": "Communication-efficient learning of deep networks from decentralized data"
      },
      {
        "key": "HeteroFL",
        "author": "Diao, Enmao and Ding, Jie and Tarokh, Vahid",
        "title": "Hetero{FL}: Computation and communication efficient federated learning for heterogeneous clients"
      },
      {
        "key": "FLOutlook",
        "author": "Ding, Jie and Tramel, Eric and Sahu, Anit Kumar and Wu, Shuang and Avestimehr, Salman and Zhang, Tao",
        "title": "Federated Learning Challenges and Opportunities: An Outlook"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "zhu2019deep",
        "author": "Zhu, Ligeng and Liu, Zhijian and Han, Song",
        "title": "Deep leakage from gradients"
      },
      {
        "key": "geiping2020inverting",
        "author": "Geiping, Jonas and Bauermeister, Hartmut and Dr{\\\"o}ge, Hannah and Moeller, Michael",
        "title": "Inverting gradients-how easy is it to break privacy in federated learning?"
      },
      {
        "key": "geng2023improved",
        "author": "Geng, Jiahui and Mou, Yongli and Li, Qing and Li, Feifei and Beyan, Oya and Decker, Stefan and Rong, Chunming",
        "title": "Improved Gradient Inversion Attacks and Defenses in Federated Learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "park2019attack",
        "author": "Park, Cheolhee and Hong, Dowon and Seo, Changho",
        "title": "An attack-based evaluation method for differentially private learning against model inversion attack"
      },
      {
        "key": "stock2022defending",
        "author": "Stock, Pierre and Shilov, Igor and Mironov, Ilya and Sablayrolles, Alexandre",
        "title": "Defending against Reconstruction Attacks with Renyi Differential Privacy"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "chakraborty2018adversarial",
        "author": "Chakraborty, Anirban and Alam, Manaar and Dey, Vishal and Chattopadhyay, Anupam and Mukhopadhyay, Debdeep",
        "title": "Adversarial attacks and defences: A survey"
      },
      {
        "key": "xu2020adversarial",
        "author": "Xu, Han and Ma, Yao and Liu, Hao-Chen and Deb, Debayan and Liu, Hui and Tang, Ji-Liang and Jain, Anil K",
        "title": "Adversarial attacks and defenses in images, graphs and text: A review"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "lowd2005adversarial",
        "author": "Lowd, Daniel and Meek, Christopher",
        "title": "Adversarial learning"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "szegedy2013intriguing",
        "author": "Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob",
        "title": "Intriguing properties of neural networks"
      },
      {
        "key": "goodfellow2014explaining",
        "author": "Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian",
        "title": "Explaining and harnessing adversarial examples"
      },
      {
        "key": "carlini2016hidden",
        "author": "Carlini, Nicholas and Mishra, Pratyush and Vaidya, Tavish and Zhang, Yuankai and Sherr, Micah and Shields, Clay and Wagner, David and Zhou, Wenchao",
        "title": "Hidden voice commands"
      },
      {
        "key": "kurakin2016adversarial",
        "author": "Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy",
        "title": "Adversarial machine learning at scale"
      },
      {
        "key": "sun2022adversarial",
        "author": "Sun, Lichao and Dou, Yingtong and Yang, Carl and Zhang, Kai and Wang, Ji and Philip, S Yu and He, Lifang and Li, Bo",
        "title": "Adversarial attack and defense on graph data: A survey"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "papernot2018sok",
        "author": "Papernot, Nicolas and McDaniel, Patrick and Sinha, Arunesh and Wellman, Michael P",
        "title": "Sok: Security and privacy in machine learning"
      },
      {
        "key": "tian2022comprehensive",
        "author": "Tian, Zhiyi and Cui, Lei and Liang, Jie and Yu, Shui",
        "title": "A comprehensive survey on poisoning attacks and countermeasures in machine learning"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "biggio2012poisoning",
        "author": "Biggio, Battista and Nelson, Blaine and Laskov, Pavel",
        "title": "Poisoning attacks against support vector machines"
      },
      {
        "key": "jagielski2018manipulating",
        "author": "Jagielski, Matthew and Oprea, Alina and Biggio, Battista and Liu, Chang and Nita-Rotaru, Cristina and Li, Bo",
        "title": "Manipulating machine learning: Poisoning attacks and countermeasures for regression learning"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "chen2017targeted",
        "author": "Chen, Xinyun and Liu, Chang and Li, Bo and Lu, Kimberly and Song, Dawn",
        "title": "Targeted backdoor attacks on deep learning systems using data poisoning"
      },
      {
        "key": "wang2023back",
        "author": "Wang, Ganghua and Xian, Xun and Srinivasa, Jayanth and Kundu, Ashish and Bi, Xuan and Hong, Mingyi and Ding, Jie ",
        "title": "Demystifying Poisoning Backdoor Attacks from a Statistical Perspective "
      },
      {
        "key": "xian2023under",
        "author": "Xian, Xun and Wang, Ganghua and Srinivasa, Jayanth and Kundu, Ashish and Bi, Xuan and Hong, Mingyi and Ding, Jie ",
        "title": "Understanding backdoor attacks through the adaptability hypothesis"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "gu2017badnets",
        "author": "Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth",
        "title": "Badnets: Identifying vulnerabilities in the machine learning model supply chain"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "blanchard2017machine",
        "author": "Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien",
        "title": "Machine learning with adversaries: Byzantine tolerant gradient descent"
      },
      {
        "key": "li2019rsa",
        "author": "Li, Liping and Xu, Wei and Chen, Tianyi and Giannakis, Georgios B and Ling, Qing",
        "title": "RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets"
      },
      {
        "key": "fang2020local",
        "author": "Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil",
        "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning"
      },
      {
        "key": "tolpegin2020data",
        "author": "Tolpegin, Vale and Truex, Stacey and Gursoy, Mehmet Emre and Liu, Ling",
        "title": "Data poisoning attacks against federated learning systems"
      }
    ]
  }
]