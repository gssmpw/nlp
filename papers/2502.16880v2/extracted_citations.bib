@inproceedings{DBLP:conf/acl/Zhong00L0T24,
  author={Qihuang Zhong and Liang Ding and Li Shen and Juhua Liu and Bo Du and Dacheng Tao},
  title={Revisiting Knowledge Distillation for Autoregressive Language Models},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2024},
}

@inproceedings{DBLP:conf/asplos/MiaoOZCWZWZYSSC24,
  author={Xupeng Miao and Gabriele Oliaro and Zhihao Zhang and Xinhao Cheng and Zeyu Wang and engxin Zhang and Rae Ying Yee Wong and Alan Zhu and Lijie Yang and Xiaoxiang Shi and Chunan Shi and Zhuoming Chen and Daiyaan Arfeen and Reyna Abhyankar and Zhihao Jia},
  title={{S}pec{I}nfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification},
  booktitle={Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  year={2024},
}

@inproceedings{DBLP:conf/icml/CaiLGPLCD24,
  author={Tianle Cai and Yuhong Li and Zhengyang Geng and Hongwu Peng and Jason D. Lee and Deming Chen and Tri Dao},
  title={Medusa: Simple {LLM} Inference Acceleration Framework with Multiple Decoding Heads},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@inproceedings{DBLP:conf/icml/Du0XWY0LXNTY24,
  author={Cunxiao Du and Jing Jiang and Yuanchen Xu and Jiawei Wu and Sicheng Yu and Yongqi Li and Shenggui Li and Kai Xu and Liqiang Nie and Zhaopeng Tu and Yang You},
  title={{G}li{D}e with a CaPE: {A} Low-Hassle Method to Accelerate Speculative Decoding},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@inproceedings{DBLP:conf/icml/DuHDTLXKZYFZFBZ22,
  author={Nan Du and Yanping Huang and Andrew M. Dai and Simon Tong and Dmitry Lepikhin and Yuanzhong Xu and Maxim Krikun and others},
  title={{GLaM}: Efficient Scaling of Language Models with Mixture-of-Experts},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2022},
}

@inproceedings{DBLP:conf/icml/KoKCY24,
  author={Jongwoo Ko and Sungnyun Kim and Tianyi Chen and Se{-}Young Yun},
  title={DistiLLM: Towards Streamlined Distillation for Large Language Models},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@inproceedings{DBLP:conf/icml/LeviathanKM23,
  author={Yaniv Leviathan and Matan Kalman and Yossi Matias},
  title={Fast Inference from Transformers via Speculative Decoding},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2023},
}

@inproceedings{DBLP:conf/icml/XiaoLSWDH23,
  author={Guangxuan Xiao and Ji Lin and Micka{\"{e}}l Seznec and Hao Wu and Julien Demouth and Song Han},
  title={{S}mooth{Q}uant: Accurate and Efficient Post-Training Quantization for Large Language Models},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2023},
}

@inproceedings{DBLP:conf/mlsys/0002TTYCWXDG024,
  author={Ji Lin and Jiaming Tang and Haotian Tang and Shang Yang and Wei{-}Ming Chen and Wei{-}Chen Wang and Guangxuan Xiao and Xingyu Dang and Chuang Gan and Song Han},
  title={{AWQ:} Activation-aware Weight Quantization for On-Device {LLM} Compression and Acceleration},
  booktitle={Proceedings of the Annual Conference on Machine Learning and Systems},
  year={2024},
}

@article{DBLP:journals/corr/abs-2405-00263,
  author={Bin Xiao and Chunan Shi and Xiaonan Nie and Fan Yang and Xiangwei Deng and Lei Su and Weipeng Chen and Bin Cui},
  title={Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge},
  journal={arXiv preprint arXiv:2405.00263},
  year={2024},
}

@article{DBLP:journals/jmlr/FedusZS22,
  author={William Fedus and Barret Zoph and Noam Shazeer},
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal={Journal of Machine Learning Research},
  year={2022},
}

@article{ankner2024hydrasequentiallydependentdraftheads,
  title={Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding}, 
  author={Zachary Ankner and Rishab Parthasarathy and Aniruddha Nrusimha and Christopher Rinard and Jonathan Ragan-Kelley and William Brandon},
  journal={arXiv preprint arXiv:2402.05109},
  year={2024},
}

@article{chen2023acceleratinglargelanguagemodel,
  title={Accelerating Large Language Model Decoding with Speculative Sampling}, 
  author={Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023},
}

@article{chen2024sequoiascalablerobusthardwareaware,
  title={Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding}, 
  author={Zhuoming Chen and Avner May and Ruslan Svirschevski and Yuhsun Huang and Max Ryabinin and Zhihao Jia and Beidi Chen},
  journal={arXiv preprint arXiv:2402.12374},
  year={2024},
}

@misc{dettmers2022llmint88bitmatrixmultiplication,
  title={{LLM}.int8(): 8-bit Matrix Multiplication for Transformers at Scale}, 
  author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
  journal={arXiv preprint arXiv:2208.07339},
  year={2022},
}

@misc{frantar2023gptqaccurateposttrainingquantization,
  title={{GPTQ}: Accurate Post-Training Quantization for Generative Pre-trained Transformers}, 
  author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  journal={arXiv preprint arXiv:2210.17323},
  year={2023},
}

@inproceedings{gu2024minillm,
  title={Mini{LLM}: Knowledge Distillation of Large Language Models},
  author={Yuxian Gu and Li Dong and Furu Wei and Minlie Huang},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2024},
}

@inproceedings{hu2024accelerated,
  title={Accelerated Speculative Sampling Based on Tree Monte Carlo},
  author={Zhengmian Hu and Heng Huang},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@inproceedings{li2024eagle, 
  author={Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang}, 
  title={{EAGLE}: Speculative Sampling Requires Rethinking Feature Uncertainty}, 
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024}
}

@inproceedings{li2024eagle2, 
  author={Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang}, 
  title={{EAGLE-2}: Faster Inference of Language Models with Dynamic Draft Trees}, 
  booktitle={Proceedings of the Conference on the Empirical Methods in Natural Language Processing},
  year={2024}
}

@article{sun2024blockverificationacceleratesspeculative,
  title={Block Verification Accelerates Speculative Decoding}, 
  author={Ziteng Sun and Uri Mendlovic and Yaniv Leviathan and Asaf Aharoni and Ahmad Beirami and Jae Hun Ro and Ananda Theertha Suresh},
  journal={arXiv preprint arXiv:2403.10444},
  year={2024},
}

@article{wang2024opttreespeculativedecodingadaptive,
  title={OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure}, 
  author={Jikai Wang and Yi Su and Juntao Li and Qingrong Xia and Zi Ye and Xinyu Duan and Zhefeng Wang and Min Zhang},
  journal={arXiv preprint arXiv:2406.17276},
  year={2024},
}

