% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@inproceedings{DBLP:conf/nips/DaoFERR22,
  author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher R{\'{e}}},
  title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  booktitle={Advances in Neural Information Processing System},
  year={2022},
}

@article{DBLP:journals/corr/abs-2303-08774,
  author={OpenAI},
  title={{GPT-4} Technical Report},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023},
}

@article{grattafiori2024llama3herdmodels,
  title={The Llama 3 Herd of Models}, 
  author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and others},
  journal={arXiv preprint arXiv:2407.21783}, 
  year={2024},
}

@article{touvron2023llama2openfoundation,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
  author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and others},
  journal={arXiv preprint arXiv:2307.09288}, 
  year={2023},
}

@article{touvron2023llamaopenefficientfoundation,
  title={LLaMA: Open and Efficient Foundation Language Models}, 
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023},
}

@article{hoffmann2022trainingcomputeoptimallargelanguage,
  title={Training Compute-Optimal Large Language Models}, 
  author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022},
}

@article{kaplan2020scalinglawsneurallanguage,
  title={Scaling Laws for Neural Language Models}, 
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020},
}

@inproceedings{li2024eagle, 
  author={Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang}, 
  title={{EAGLE}: Speculative Sampling Requires Rethinking Feature Uncertainty}, 
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024}
}

@inproceedings{li2024eagle2, 
  author={Yuhui Li and Fangyun Wei and Chao Zhang and Hongyang Zhang}, 
  title={{EAGLE-2}: Faster Inference of Language Models with Dynamic Draft Trees}, 
  booktitle={Proceedings of the Conference on the Empirical Methods in Natural Language Processing},
  year={2024}
}

@article{DBLP:journals/corr/abs-2405-00263,
  author={Bin Xiao and Chunan Shi and Xiaonan Nie and Fan Yang and Xiangwei Deng and Lei Su and Weipeng Chen and Bin Cui},
  title={Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge},
  journal={arXiv preprint arXiv:2405.00263},
  year={2024},
}

@inproceedings{DBLP:conf/icml/CaiLGPLCD24,
  author={Tianle Cai and Yuhong Li and Zhengyang Geng and Hongwu Peng and Jason D. Lee and Deming Chen and Tri Dao},
  title={Medusa: Simple {LLM} Inference Acceleration Framework with Multiple Decoding Heads},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@article{zhang2024learningharmonizedrepresentationsspeculative,
  title={Learning Harmonized Representations for Speculative Sampling}, 
  author={Lefan Zhang and Xiaodan Wang and Yanhua Huang and Ruiwen Xu},
  journal={arXiv preprint arXiv:2408.15766},
  year={2024},
}

@article{yang2024qwen2technicalreport,
  title={Qwen2 Technical Report}, 
  author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024},
}

@article{chen2023acceleratinglargelanguagemodel,
  title={Accelerating Large Language Model Decoding with Speculative Sampling}, 
  author={Charlie Chen and Sebastian Borgeaud and Geoffrey Irving and Jean-Baptiste Lespiau and Laurent Sifre and John Jumper},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023},
}

@inproceedings{DBLP:conf/icml/LeviathanKM23,
  author={Yaniv Leviathan and Matan Kalman and Yossi Matias},
  title={Fast Inference from Transformers via Speculative Decoding},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2023},
}

@article{yang2024multicandidatespeculativedecoding,
  title={Multi-Candidate Speculative Decoding}, 
  author={Sen Yang and Shujian Huang and Xinyu Dai and Jiajun Chen},
  journal={arXiv preprint arXiv:2401.06706},
  year={2024},
}

@article{lu2024improvingmulticandidatespeculativedecoding,
  title={Improving Multi-candidate Speculative Decoding}, 
  author={Xiaofan Lu and Yixiao Zeng and Feiyang Ma and Zixu Yu and Marco Levorato},
  journal={arXiv preprint arXiv:2409.10644},
  year={2024},
}

@article{DBLP:journals/corr/abs-1807-03748,
  author={A{\"{a}}ron van den Oord and Yazhe Li and Oriol Vinyals},
  title={Representation Learning with Contrastive Predictive Coding},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018},
}

@inproceedings{DBLP:conf/icml/RadfordKHRGASAM21,
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  title={Learning Transferable Visual Models From Natural Language Supervision},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2021},
}

@inproceedings{DBLP:conf/nips/ZhengC00WZL0LXZ23,
  author={Lianmin Zheng and Wei{-}Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023},
}

@article{DBLP:journals/corr/abs-2110-14168,
  author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  title={Training Verifiers to Solve Math Word Problems},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021},
}

@article{DBLP:journals/corr/abs-2107-03374,
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Pond{\'{e}} de Oliveira Pinto and others},
  title={Evaluating Large Language Models Trained on Code},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021},
}

@inproceedings{sennrich-etal-2016-neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2016},
}

@inproceedings{DBLP:conf/cvpr/ChopraHL05,
  author={Sumit Chopra and Raia Hadsell and Yann LeCun},
  title={Learning a Similarity Metric Discriminatively, with Application to Face Verification},
  booktitle={Proceedings of the Conference on Computer Vision and Pattern Recognition},
  year={2005},
}

@inproceedings{DBLP:conf/cvpr/SchroffKP15,
  author={Florian Schroff and Dmitry Kalenichenko and James Philbin},
  title={{F}ace{N}et: {A} unified embedding for face recognition and clustering},
  booktitle={Proceedings of the Conference on Computer Vision and Pattern Recognition},
  year={2015},
}

@misc{dettmers2022llmint88bitmatrixmultiplication,
  title={{LLM}.int8(): 8-bit Matrix Multiplication for Transformers at Scale}, 
  author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
  journal={arXiv preprint arXiv:2208.07339},
  year={2022},
}

@misc{frantar2023gptqaccurateposttrainingquantization,
  title={{GPTQ}: Accurate Post-Training Quantization for Generative Pre-trained Transformers}, 
  author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  journal={arXiv preprint arXiv:2210.17323},
  year={2023},
}

@inproceedings{DBLP:conf/icml/XiaoLSWDH23,
  author={Guangxuan Xiao and Ji Lin and Micka{\"{e}}l Seznec and Hao Wu and Julien Demouth and Song Han},
  title={{S}mooth{Q}uant: Accurate and Efficient Post-Training Quantization for Large Language Models},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2023},
}

@inproceedings{DBLP:conf/mlsys/0002TTYCWXDG024,
  author={Ji Lin and Jiaming Tang and Haotian Tang and Shang Yang and Wei{-}Ming Chen and Wei{-}Chen Wang and Guangxuan Xiao and Xingyu Dang and Chuang Gan and Song Han},
  title={{AWQ:} Activation-aware Weight Quantization for On-Device {LLM} Compression and Acceleration},
  booktitle={Proceedings of the Annual Conference on Machine Learning and Systems},
  year={2024},
}

@inproceedings{DBLP:conf/acl/Zhong00L0T24,
  author={Qihuang Zhong and Liang Ding and Li Shen and Juhua Liu and Bo Du and Dacheng Tao},
  title={Revisiting Knowledge Distillation for Autoregressive Language Models},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2024},
}

@inproceedings{DBLP:conf/icml/KoKCY24,
  author={Jongwoo Ko and Sungnyun Kim and Tianyi Chen and Se{-}Young Yun},
  title={DistiLLM: Towards Streamlined Distillation for Large Language Models},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@inproceedings{gu2024minillm,
  title={Mini{LLM}: Knowledge Distillation of Large Language Models},
  author={Yuxian Gu and Li Dong and Furu Wei and Minlie Huang},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2024},
}

@inproceedings{DBLP:conf/icml/DuHDTLXKZYFZFBZ22,
  author={Nan Du and Yanping Huang and Andrew M. Dai and Simon Tong and Dmitry Lepikhin and Yuanzhong Xu and Maxim Krikun and others},
  title={{GLaM}: Efficient Scaling of Language Models with Mixture-of-Experts},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2022},
}

@article{DBLP:journals/jmlr/FedusZS22,
  author={William Fedus and Barret Zoph and Noam Shazeer},
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal={Journal of Machine Learning Research},
  year={2022},
}

@inproceedings{hu2024accelerated,
  title={Accelerated Speculative Sampling Based on Tree Monte Carlo},
  author={Zhengmian Hu and Heng Huang},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@article{sun2024blockverificationacceleratesspeculative,
  title={Block Verification Accelerates Speculative Decoding}, 
  author={Ziteng Sun and Uri Mendlovic and Yaniv Leviathan and Asaf Aharoni and Ahmad Beirami and Jae Hun Ro and Ananda Theertha Suresh},
  journal={arXiv preprint arXiv:2403.10444},
  year={2024},
}

@inproceedings{DBLP:conf/asplos/MiaoOZCWZWZYSSC24,
  author={Xupeng Miao and Gabriele Oliaro and Zhihao Zhang and Xinhao Cheng and Zeyu Wang and engxin Zhang and Rae Ying Yee Wong and Alan Zhu and Lijie Yang and Xiaoxiang Shi and Chunan Shi and Zhuoming Chen and Daiyaan Arfeen and Reyna Abhyankar and Zhihao Jia},
  title={{S}pec{I}nfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification},
  booktitle={Proceedings of the ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  year={2024},
}

@article{chen2024sequoiascalablerobusthardwareaware,
  title={Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding}, 
  author={Zhuoming Chen and Avner May and Ruslan Svirschevski and Yuhsun Huang and Max Ryabinin and Zhihao Jia and Beidi Chen},
  journal={arXiv preprint arXiv:2402.12374},
  year={2024},
}

@article{ankner2024hydrasequentiallydependentdraftheads,
  title={Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding}, 
  author={Zachary Ankner and Rishab Parthasarathy and Aniruddha Nrusimha and Christopher Rinard and Jonathan Ragan-Kelley and William Brandon},
  journal={arXiv preprint arXiv:2402.05109},
  year={2024},
}

@inproceedings{DBLP:conf/icml/Du0XWY0LXNTY24,
  author={Cunxiao Du and Jing Jiang and Yuanchen Xu and Jiawei Wu and Sicheng Yu and Yongqi Li and Shenggui Li and Kai Xu and Liqiang Nie and Zhaopeng Tu and Yang You},
  title={{G}li{D}e with a CaPE: {A} Low-Hassle Method to Accelerate Speculative Decoding},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2024},
}

@article{wang2024opttreespeculativedecodingadaptive,
  title={OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure}, 
  author={Jikai Wang and Yi Su and Juntao Li and Qingrong Xia and Zi Ye and Xinyu Duan and Zhefeng Wang and Min Zhang},
  journal={arXiv preprint arXiv:2406.17276},
  year={2024},
}

@inproceedings{DBLP:conf/aaai/WangCG20,
  author={Changhan Wang and Kyunghyun Cho and Jiatao Gu},
  title={Neural Machine Translation with Byte-Level Subwords},
  booktitle={Proceedings of the {AAAI} Conference on Artificial Intelligence},
  year={2020},
}

@inproceedings{DBLP:conf/sosp/KwonLZ0ZY0ZS23,
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph Gonzalez and Hao Zhang and Ion Stoica},
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  booktitle={Proceedings of the29th Symposium on Operating Systems Principles},
  year={2023},
}

@misc{tao2024scalinglawsvocabularylarger,
      title={Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies}, 
      author={Chaofan Tao and Qian Liu and Longxu Dou and Niklas Muennighoff and Zhongwei Wan and Ping Luo and Min Lin and Ngai Wong},
      year={2024}, 
}


@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and others},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}