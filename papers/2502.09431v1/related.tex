\section{Background}
\label{sec:background}
\noindent In this section, we first describe in detail the properties of NVM technologies, highlighting the implications these might have in the design of a DBMS. We then describe currently available system software to manage NVM. 


\subsection{Characteristics of NVM}
\noindent \textbf{Data access latency:} Read latencies for NVM technologies will certainly be significantly lower than those of conventional disks. However, since NVM devices are still under development, sources quote varying read latencies. For example, the read latency for STT-RAM ranges from 1 to 20ns, and PC-RAM is expected to be around 50ns ~\cite{arulraj2015let,wang2013low,perez2010non}. Nonetheless, read latency of some NVM technologies is expected to be similar to that of DRAM ~\cite{mittal2016survey,arulraj2015let,wang2013low,chang2012limits,arulraj2016write,oukid2014sofort,chatzistergiou2015rewind}, which is typically around 60ns.

PC-RAM and R-RAM are reported to have a higher write latency compared to DRAM, but STT-RAM also outperforms DRAM in this regard ~\cite{arulraj2015let,wang2013low}. However, the write latency is typically not in the critical path, since it can be tolerated by using buffers ~\cite{qureshi2009scalable}.

\noindent\textbf{Density:} NVM technologies provide higher densities than DRAM, which makes them a good candidate to be used as main memory as well as primary storage, particularly in embedded systems~\cite{huang2012register}. For example, PC-RAM provides 2 to 4 times higher density as compared to DRAM~\cite{qureshi2009scalable}. Future NVMs are expected to have higher capacity and better scalability than DRAM \cite{oukid2015instant,chakrabarti2014atlas,zhang2015study,viglas2014write}
, and it is expected to scale to lower technology nodes as opposed to DRAM.

\noindent\textbf{Endurance:} The maximum number of writes a memory cell can withstand is lower for most NVM 
technologies when compared to DRAM ~\cite{qureshi2009scalable,zhou2009durable}. Specifically, PC-RAM, R-RAM, 
and STT-RAM have projected endurances of $10^{10}$, $10^{8}$, and $10^{15}$ respectively;  as compared to 
$10^{16}$ for DRAM ~\cite{arulraj2015let}. On the other hand, NVMs exhibit higher endurance than flash 
memory technologies ~\cite{wang2013low}.

\noindent\textbf{Energy consumption:} Since NVM does not need a refresh cycle to maintain data states in memory cells like a  DRAM, 
they are more energy efficient. A main memory designed using PC-RAM technology consumes significantly lower per access write energy as compared to DRAM~\cite{zhou2009durable}. Other NVM technologies also have similar lower energy consumption per bit when compared to DRAM~\cite{arulraj2015let,perez2010non}.

In addition to the features listed above, NVM technologies also provide byte-addressability like DRAM and persistency like disks. Due to these features, NVMs are starting to appear in embedded and energy-critical devices and are expected to play a major role in future computing systems. Companies like Intel and Micron have launched the 3D XPoint memory technology, which features non-volatility \cite{3DXPoint}. Intel has also introduced new instructions to support the usage of persistent memory at the instruction set architecture (ISA) level~\cite{intel2016architecture}.

\subsection{System software for NVM}

Using NVM as primary storage necessitates modifications not only in application software but also in system software in order to 
take advantage of NVM features. A traditional file system (FS) accesses the storage through a block layer. If a disk is replaced by NVM without any modifications in
the FS, the NVM storage will still be accessed at block level granularity. Hence, we will not be able to take advantage of the byte-addressability feature of NVM. 

For this reason, there have been developments in file system support for persistent memory. Persistent memory file system (PMFS) is an open-source POSIX compliant FS developed by Intel Research~\cite{dulloor2014system,githubPMFS}. It offers two key features in order to facilitate usage of NVM.

First, PMFS does not maintain a separate address space for NVM. In other words, both main memory and NVM use the same address space. This implies that there is no need to copy data from NVM to DRAM to make it accessible to an application. A process can directly access file system protected data stored in NVM at byte level granularity.


Second, in a traditional FS stored blocks can be accessed in two ways: (i) file I/O and (ii) memory mapped I/O. PMFS implements file I/O in a similar way to a traditional FS. However, the implementation of memory mapped I/O differs. In a traditional FS, memory mapped I/O would first copy pages to DRAM~\cite{dulloor2014system} from where an application can examine those pages. PMFS avoids this copy overhead by mapping NVM pages directly into the address space of a process. 
Fig.~\ref{Fig1} from~\cite{dulloor2014system} compares a traditional FS with PMFS.

\begin{figure}
\centering
\includegraphics[width=100mm]{Fig1.eps}
\caption{Comparison of traditional FS and PMFS. ``mmap'' refers to the system call for memory mapped I/O operation. 
``mmu'' is the memory management unit responsible for address mappings}
\label{Fig1}
\end{figure}

