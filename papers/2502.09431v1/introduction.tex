%\renewcommand{\thefootnote}{\arabic{footnote}}
\section{Introduction}
\noindent The traditional design of a DBMS assumes a memory hierarchy where datasets are stored in disks. Disks are a cheap and non-volatile storage medium suitable for storing large datasets. However, they are extremely slow for data retrieval. To hide their high data-access latency, DRAM is used as an intermediate storage between disks and the processing units.

DRAM is orders of magnitude faster than a disk, and with increasing DRAM chip densities and decreasing memory prices, relational in-memory DBMSs have become increasingly popular \cite{abraham2013scuba,farber2012sap,lindstrom2013ibm,barber2011blink,PeletonLink,pavlo2017self}. Significant components of in-memory DBMSs, like index structures \cite{larson2011sql,zhang2016reducing}, recovery mechanisms for system failure \cite{ongaro2011fast,diaconu2013hekaton}, and commit processing \cite{lee2001single} are tailored towards the usage of main memory as primary storage. An in-memory DBMS assumes that all data fits in main memory. However, for some applications, the database size can grow larger than DRAM capacity \cite{debrabant2014prolegomenon}. At the same time, inherent physical limitations related to leakage current and voltage scaling limit the further scaling of DRAM \cite{mandelman2002challenges,driskill2010latest}. The capacity problem can be resolved by distributing the database across multiple machines but at the cost of performance degradation \cite{debrabant2014prolegomenon}. Furthermore, due to the volatile nature of DRAM, in-memory DBMSs still use a large pool of disks to provide a form of persistent storage for critical or non redundant data \cite{abraham2013scuba,melnik2010dremel,plattner2011sanssoucidb,sikka2012efficient}.


Non-volatile memory (NVM) is an emerging storage class technology that features persistency as well as significantly faster access latencies than hard disks, with read latencies on the same order of magnitude as DRAM \cite{arulraj2017build}. It also offers byte-addressability like DRAM and higher density \cite{qureshi2009scalable,andrei2017sap}. Prominent NVM technologies are PC-RAM \footnote{PC-RAM: Phase Change Random Access Memory} \cite{raoux2008phase}, STT-RAM \footnote{STT-RAM: Spin Transfer Torque Random Access Memory} \cite{driskill2010latest}, and R-RAM \footnote{R-RAM: Resistive Random Access Memory} \cite{strukov2008missing}. With read latency close to that of DRAM, especially in case of PC-RAM and R-RAM \cite{arulraj2015let,chang2012limits}, NVM technologies are a good candidate to improve the performance of decision support systems (DSS), which are dominated by read-only queries on vast datasets \cite{hagmann2002real}. DSS are computer technology solutions that can be used to facilitate complex decision making \cite{shim2002past}. They convert business information into tangible results \cite{chaudhuri2001database} to help executives take knowledge-based decisions.

A DBMS design should take into account the characteristics of NVM to benefit from its features. Simple ports of a traditional DBMS - designed to use disks as the primary storage medium - to 
NVM will show improvement due to the lower access latencies of NVM. However, adapting a DBMS to fit NVM characteristics can offer a number of benefits beyond lower access latencies. This adaptation requires modifications in the storage engine as well as other components of a DBMS \cite{arulraj2017build} in order to take advantage of NVM features.

In this paper, we study the implications of employing NVM in the design of a DBMS. Our main contributions can be summarized as follows:
\begin{itemize}%[leftmargin=*]
 \item We discuss and provide insights on the different available options when including NVM into the memory hierarchy of current systems.
 
 \item We focus on investigating the necessary changes and challenges when modifying an existing, well-tested, widely used, and robust traditional DBMS to benefit from NVM features. As a case study, we selected PostgreSQL which is ranked as the \nth{4} most popular DBMS \cite{DBRanking}.
 
 \item %We investigate the required modifications in the DBMS's storage engine (SE) to leverage NVM features using a well-known relational disk-optimized DBMS - PostgreSQL. 
 Our modifications aim at providing fast access to data by bypassing the slow disk interfaces while maintaining all the functionalities of a robust DBMS such as PostgreSQL. Our modified SEs target read-dominant DSS queries, providing performance improvements by minimizing data movement operations in a traditional disk-based DBMS.
 
 \item We evaluate our proposed modified SEs of PostgreSQL using a comprehensive emulation platform and the TPC-H~\cite{council2008tpc} benchmark. In addition, we also evaluate an unmodified version of PostgreSQL using both a high-end solid state disk and the emulated NVM hardware.
 
 \item We identify and quantify performance bottlenecks that appear when employing NVM hardware. To further improve the performance of our NVM-enabled SEs, we design and implement a general purpose data prefetching library based on helper threads that tackles the identified performance bottlenecks.
\end{itemize}

Experimental results show that our modified SEs are able to reduce the kernel execution time, where file I/O operations take place, from around 10\% to 3\% on average. In terms of wall-clock query execution time, our modifications improve performance by around 19\% and 4\% on average when compared to unmodified PostgreSQL on disk and on NVM storage, respectively. We find that the performance of our modified SE is limited by the fact that data is not close to the processing units when needed for query processing since it is directly accessed from NVM hardware. This leads to long latency user-level cache misses that decrease the improvements achieved by avoiding expensive data movement operations.

We employ a known technique like helper-threads for data prefetching in the context of a NVM-based database design to resolve the data readiness problem we identify. We implement a general purpose data prefetching library that exposes a simple API allowing the creation of a user-specified number of helper threads that seamlessly prefetch data for a given address and memory size with minimum interference to the computation thread. We investigate different thread mapping schemes with and without hyper-threading. Experimental results show that when using our modified SE with the prefetching library, the kernel execution time drops to 0.05\% on average as compared to around 10\% for unmodified PostgreSQL. In terms of wall-clock query execution time, performance improves by up to 17\% when compared to unmodified PostgreSQL with NVM storage, with 8\% average improvement.

The remainder of this paper is organized as follows:
Section~\ref{sec:background} provides background on features of NVM and
the system software needed to enable its usage. Section~\ref{sec:Implications}
elaborates on the different design choices to integrate NVM into the memory hierarchy
of a computing platform running a DBMS. It also lists
required modifications for a traditional DBMS to leverage NVM features as primary storage. Section~\ref{sec:CaseStudy} explains the
read-write architecture of PostgreSQL and our proposed modifications to
implement NVM-aware SEs for PostgreSQL as a case study. Section~\ref{sec:methodology} describes our methodology to emulate NVM hardware. We evaluate our proposed SEs against baselines in Section~\ref{sec:evaluation}. Section~\ref{sec:library} describes the data prefetching library along with the helper thread mapping schemes we employ in this work, while Section~\ref{sec:library-evalualtion} evaluates the library. Section~\ref{sec:RelatedWork} describes related work on NVM, DBMS and data prefetching. We conclude this paper in Section~\ref{sec:conclusion}.
 
  