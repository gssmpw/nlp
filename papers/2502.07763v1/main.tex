%\documentclass[conference]{IEEEtran}
\documentclass[10pt,conference]{IEEEtran}

%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
%\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\PassOptionsToPackage{table,xcdraw}{xcolor}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{flushend}
\usepackage{balance}
\usepackage{multirow}

\usepackage{color}
\usepackage{booktabs}
\usepackage{fancybox}
\usepackage{float}
\usepackage{array,graphicx}
\usepackage[flushleft]{threeparttable}
\usepackage[most]{tcolorbox}
\usepackage{xspace}
\usepackage{listings}
\usepackage{pifont}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{blindtext}
\usepackage{colortbl}

\usepackage{makecell}
\usepackage{stfloats}
%\usepackage{subcaption}
\usepackage{url}

\usepackage{colortbl} 

\usepackage{booktabs}

\usepackage{hyperref}

\usepackage{tcolorbox}

\usepackage{comment}


\newcommand{\red}[1]{{\color{red}#1}}

\newcommand{\MyBox}[1]{\vspace{3mm}\noindent\framebox[\columnwidth][c]{\parbox[b]{0.95\columnwidth}{ #1 }}\vspace{3mm}}

% Colored boxes
\definecolor{purplish}{HTML}{D8D0E3}
\definecolor{purplishlight}{HTML}{EBE7F1}
\definecolor{purplishdark}{HTML}{875afb}

\newtcolorbox[auto counter,number within=section]{rqbox}[2]{
    nameref=#1,
    title=\small{#1}, 
    enhanced,
    attach boxed title to top left={yshift=-6pt, xshift=8pt},
    boxed title style={size=small,boxsep=1pt},
    colframe=purplishdark,colback=white,colbacktitle=purplishdark,
    boxsep=2pt,left=2pt,right=2pt,top=6pt,bottom=2pt,middle=2pt
}

\newcommand{\note}[1]{
    \begin{tcolorbox}[
        colframe=white, colback=purplishlight, frame hidden, boxrule=0pt,
        boxsep=2pt,left=4pt,right=4pt,top=4pt,bottom=4pt
    ]
    \small{#1}
    \end{tcolorbox}
}



\newcommand{\tikzcircle}[2][red,fill=red]{\tikz[baseline=-0.5ex]\draw[#1,radius=#2] (0,0) circle ;}%

\newcommand{\tikzcirclenew}[2][red,fill=red]{\tikz[baseline=-0.5ex]\draw[#1,radius=#2] (0,0) circle ;}%


\newcommand{\boldification}[1]{\textbf{** #1 **}}
    
\newcommand{\rqtextone}{XXX}

\newcommand{\rqone}[2][]{
    \begin{rqbox}{\textbf{Research Question}}{#2}
        \rqtextone
        #1
    \end{rqbox}
}
\newcommand{\rqtexttwo}{XXXXX}
\newcommand{\rqtwo}[2][]{
    \begin{rqbox}{\textbf{Research Question 1}}{#1}
        %\rqtexttwo
        #1
    \end{rqbox}
}

\newcommand{\italo}[1]{{\color{red}#1}}
    
\begin{document}



\title{Great Power Brings Great Responsibility: Personalizing Conversational AI for Diverse Problem-Solvers}



%\author{\IEEEauthorblockN{}}

\author{\IEEEauthorblockN{Italo Santos\IEEEauthorrefmark{1}, Katia Romero Felizardo\IEEEauthorrefmark{2}, Igor Steinmacher\IEEEauthorrefmark{1} and Marco A. Gerosa\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Northern Arizona University, Flagstaff, AZ, USA\\}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Federal Technological University of Paraná, PR, Brazil\\}
Email: italo.santos@nau.edu, katiascannavino@utfpr.edu.br, \\igor.steinmacher@nau.edu, marco.gerosa@nau.edu}

\maketitle
\IEEEpeerreviewmaketitle

\begin{abstract}
    %Context
    Newcomers onboarding to Open Source Software (OSS) projects face many challenges. Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for answering questions and providing guidance, with many developers now turning to ChatGPT over traditional Q\&A sites like Stack Overflow.
    %Gap
    Nonetheless, LLMs may carry biases in presenting information, which can be especially impactful for newcomers whose problem-solving styles may not be broadly represented. This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects.
    %Goal
    This vision paper outlines the potential of adapting AI responses to various problem-solving styles to avoid privileging a particular subgroup.
    %Method
    We discuss the potential of AI persona-based prompt engineering as a strategy for interacting with AI.   
    %Results
    %Conclusion
    This study invites further research to refine AI-based tools to better support contributions to OSS projects.
\end{abstract}

%\textbf{\textit{keywords: open source software, large language models, diversity and inclusion}}

%\vspace{-5px}
\section{Introduction}
\label{sec:introduction}
%\vspace{-1.0mm}

%Open Source Software (OSS) projects contribute significantly to workforce development~\cite{gerosa2021shifting}. One of the main factors attracting newcomers to OSS is the opportunity to improve their software engineering skills~\cite{bonaccorsi2004altruistic}. However, newcomers often face significant onboarding challenges~\cite{steinmacher2015social, pinto2017training, pinto2019training}, which can disproportionately affect underrepresented groups, particularly when their problem-solving styles do not align with the project's information structure~\cite{padala2020gender, mendez2018open}. 

Newcomers often face significant barriers when beginning to contribute to Open Source Software (OSS) projects~\cite{steinmacher2015social, pinto2017training, pinto2019training, santos2022hits}. Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for addressing these onboarding challenges, with many users now turning to ChatGPT over traditional Q\&A sites like Stack Overflow~\cite{kabir2024stack, StackOverflow2023}. Yet, because LLMs are trained on existing data, they may inadvertently carry biases when presenting information. This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects.

Research highlights that information presentation in OSS projects~\cite{padala2020gender, mendez2018open}---such as documentation and issue descriptions---often favors specific problem-solving styles (e.g., hands-on learners) over others (e.g., process-oriented learners), contributing to gender biases. While additional studies have further examined gender bias in OSS~\cite{murphy2024gendermag, ford2017someone, ford2016paradise, nafus2012patches, vasilescu2015gender}, there is still a need to adapt OSS environments to support diverse contributors effectively~\cite{santosvlhcc}. The rise of generative conversational artificial intelligence (AI), like ChatGPT, which reached over 100 million users in two months~\cite{hu2023chatgpt}, introduces new opportunities to address this gap by providing personalized, style-aligned support to diverse contributors.

Skjuve et al.~\cite{skjuve2024people} reported that conversational AI is perceived as highly capable of handling cognitive tasks that were once considered difficult to automate~\cite{frey2017future}. The decline in Stack Overflow traffic is attributed to ChatGPT's rise~\cite{kabir2024stack, StackOverflow2023}. Moreover, people increasingly rely on ChatGPT to simplify complex concepts they need to learn~\cite{sundar2020rise}. ChatGPT's potential to be adapted to address bias by delivering responses tailored to individual problem-solving styles offers a promising way to lower entry barriers for underrepresented groups in OSS. %This paper explores the potential of adapting LLMs like ChatGPT to align with diverse problem-solving styles, thereby increasing learning and contribution opportunities for newcomers in OSS. 
ChatGPT is a good fit for our study due to its widespread adoption, training on diverse knowledge sources, and ability to generate context-aware responses~\cite{hu2023chatgpt}. %Its API and customization options make it accessible for integration into various platforms, allowing for personalized support that aligns with user needs.

%LLMs have the potential to revolutionize human factors research~\cite{gerosa2024can}. Imagine if LLMs (i.e., ChatGPT) could actively support newcomers contributing to OSS projects by adapting to their unique problem-solving styles and personalizing feedback and guidance to match their cognitive and creative preferences. By changing the prompts automatically, the information, tone, structure, and style can be altered, transforming the generated text to suit newcomers' diverse problem-solving contexts.

This paper offers a conceptual exploration to foster discussions and reflection on how AI might empower newcomers to contribute to OSS projects, considering their different problem-solving styles. In this vision paper, we seek to examine the possibilities, outline future directions, and call the research community to establish best practices that balance personalized AI assistance with skill development and personal growth in OSS environments. 



%The following research question guided our research:

%\rqone{}

%RQ IDEA - How to design problem-solving adaptative conversational agents to help students interact with ChatGPT to help during the contribution process?

%IDEA - Criar a survey to ask students how to expect the chatgpt to answer according to their cognitive styles
%\vspace{-5px}
\section{Related work}
\label{sec:backrelated}
%\vspace{-1.0mm}

\textbf{Problem-solving styles:} Research reveals that developers exhibit diverse problem-solving styles~\cite{burnett2016gendermag} and motivations~\cite{gerosa2021shifting}. For instance, studies indicate that women are often task-oriented, whereas men are frequently motivated to explore new technologies for enjoyment~\cite{padala2020gender, mendez2018open, mendez2018gender}. These problem-solving differences impact how newcomers engage with OSS. In this vision paper, we would like to address how we can personalize LLMs' responses to help newcomers contribute to OSS projects.

\textbf{Diversity in OSS:} Low diversity within OSS communities is a well-documented concern across various dimensions, including gender~\cite{trinkenreich2021women, guizani2022debug, bosu2019diversity, terrell2016gender}, language~\cite{storey2016social}, and geographic location~\cite{storey2016social}. Research shows that diverse teams are generally more productive~\cite{vasilescu2015gender}, yet minorities often face significant barriers when trying to join and thrive within OSS communities~\cite{trinkenreich2021women}. %Many OSS communities operate as meritocracies~\cite{feller2000framework}, where minorities frequently report experiencing “imposter syndrome”\cite{vasilescu2015gender}. These competitive environments can discourage participation from underrepresented groups, particularly women\cite{miller2012toward, vugt2007gender}. Observational studies have found that men often dominate code contributions, marginalizing the social support networks essential for fostering inclusivity~\cite{nafus2012patches}. Cultures that self-identify as meritocracies are often male-dominated, creating environments that women often find unwelcoming~\cite{turkle2005second}. 
This vision paper aims to reduce these biases by leveraging LLMs to support diverse problem-solving styles, fostering a more inclusive OSS environment.




\section{Leveraging LLMs to Support Newcomers Problem-Solving Styles in OSS}
\label{sec:contextexample}
%\vspace{-1.0mm}

%This section explores the potential of AI foundation models to support diverse newcomer problem-solving styles in contributing to OSS projects. 
%This section explores how LLMs can be tailored to align with newcomers' problem-solving styles.

%, providing personalized guidance that enhances their learning experience.



%\subsection{ChatGPT personalizing responses using persona-based prompting.}

A persona is an archetype representing a group of target users who share common behavioral characteristics~\cite{pruitt2010persona}. Persona-based prompt engineering is a strategic method for interacting with AI, where prompts are crafted to generate responses that address the traits, behaviors, and perspectives of defined personas~\cite{white2023prompt}. We propose to aid newcomers in contributing to OSS projects by tailoring interactions to their problem-solving styles. For example, we can leverage personas from the GenderMag theoretical framework~\cite{burnett2016gendermag}, which characterizes problem-solving styles that cluster by gender: attitude toward risk, computer self-efficacy, motivation, information processing, and technology learning style. %These facets align with our goal of adapting OSS environments for diverse newcomers. 
GenderMag is designed to improve technology's inclusiveness for problem-solving tasks %It is particularly well-suited for identifying and addressing the challenges that diverse newcomers face when using OSS environments, 
and it is widely used in the literature for adapting traditional user interfaces~\cite{burnett2016finding, burnett2018gendermag, mendez2018gender, padala2020gender, guizani2022debug, santos2023designing}.  
GenderMag uses Abi and Tim personas to represent opposite ends of the spectrum: Abi reflects values often preferred by women, while Tim embodies those typically favored by men. 

LLM enables the development of intelligent agents capable of emulating specific characters or roles in behavior and dialogue~\cite{wang2023rolellm}. Gerosa et al.~\cite{gerosa2024can} describe persona-based prompting as harnessing LLMs ability to emulate interactions with specific demographic or psychographic profiles, creating virtual subjects with consistent traits. By designing tailored prompts, we can guide the AI in generating responses to aid newcomers contributing to OSS projects by tailoring interactions to their unique problem-solving styles. %This approach enables the AI to simulate the diverse perspectives and feedback these personas might provide on specific topics, thereby supporting newcomers with similar problem-solving styles. Through persona-based prompt engineering, we aim to adapt ChatGPT responses to better assist newcomers in contributing to OSS projects.

For this vision paper, we present the use case shown in Figure~\ref{fig:exampleresponses}. We created prompts guiding ChatGPT to answer the same query for personas representing GenderMag Abi and Tim: \textit{How can I submit a pull request?}. It is possible to compare the ChatGPT response without persona-based prompts in panel (1) with the tailored responses for the GenderMag personas Abi (2) and Tim (3). In Abi's response, the LLM outlines a structured, step-by-step process for submitting a pull request, aligning with Abi's process-oriented problem-solving style. It emphasizes the clarity and reversibility of each step, catering to Abi's risk-averseness. Conversely, for Tim's persona, the LLM provides a straightforward list of steps and suggests to ``tinker around'' after completion, reflecting Tim's exploratory and experimental problem-solving style. The replication package, including the chat transcripts, is publicly accessible~\cite{replicationpackage3}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.48\textwidth]{images/chatgptresponses.pdf}
    \vspace{-3mm}
    \caption{Using prompt engineering in a ChatGPT by asking, ``\textit{How can I submit a pull request?}" The conversation was generated using GPT-4. Panel (1) shows the ChatGPT response without persona-based prompt engineering, while Panels (2) and (3) display responses tailored to the GenderMag Abi and Tim personas, respectively.}
    \label{fig:exampleresponses}
\end{figure}





%As training datasets and model parameters expand, we anticipate these models will become increasingly skilled at capturing distinctions in response generation to diverse personas. Moreover, we can explore how overlapping problem-solving influences newcomers’ experiences and interactions with OSS projects. %The replication package, with the chat transcripts, is available for public access~\cite{replicationpackage3}.


%\section{Method}
%\label{sec:methodology}




\section{Research opportunities}
\label{sec:researchopportunities}
%\vspace{-1.0mm}

Exploring AI to support diverse problem-solving styles in OSS contributions presents several research opportunities that align with our prior discussion.

\textbf{Empirical Studies Tailoring AI Responses:} Future research can investigate how variations in AI-generated guidance impact newcomers with different problem-solving styles. For example, structured instructions provided by the chatbot—such as step-by-step guidance—could benefit process-oriented learners who prefer clear directions, while exploratory learners might find open-ended prompts, which encourage independent thinking, more effective for exploring solutions. This research would analyze and refine AI-driven approaches tailored to these distinct preferences. Furthermore, future research can extend the use of the GenderMag framework to customize AI responses in OSS environments using different prompt engineering, fine-tuning, and other techniques. %By dynamically adjusting guidance to each persona’s characteristics, this research can shed light on how tailored interactions improve newcomers' experience. 

\textbf{Inferring Personas from Interaction:} Future research can develop methods for AI to infer a user's GenderMag persona from behavior rather than relying on questionnaires. Analyzing newcomers' preferences can enable real-time adaptation, enhancing the AI support. % and personalizing the OSS experience.

These opportunities drive research that refines AI tools, ensuring a more inclusive and supportive OSS environment for diverse contributors.



\begin{comment}

%Exploring AI-based foundation models to support diverse newcomer problem-solving styles in contributing to OSS projects unveils numerous opportunities. Below, we outline some research directions.

\textbf{Empirical studies to tailor ChatGPT responses to newcomers' different problem-solving styles.} This approach would involve systematically analyzing how variations in AI-generated guidance address the unique needs of newcomers with diverse problem-solving styles. For example, studies could investigate how ChatGPT responses emphasizing structured, step-by-step instructions might benefit process-oriented learners, while exploratory learners might respond better to flexible, open-ended prompts. 

\textbf{GenderMag Persona Adaptation.} Customize AI interactions in OSS environments by incorporating insights from the GenderMag framework, which identifies distinct problem-solving styles across gendered personas. Research in this area could involve adapting ChatGPT or similar models to respond dynamically to each user's problem-solving style. This would automatically tailor responses to match individual characteristics such as motivation, risk tolerance, and learning style, enhancing relevance and inclusivity for diverse users. By explicitly setting these traits, the AI would offer more personalized guidance, potentially improving the onboarding experience and supporting newcomers more effectively in OSS environments.
%based on GenderMag personas, such as Abi and Tim, to better align with the needs and preferences of diverse users. This approach would enable the AI to provide guidance that matches each persona's unique motivations, risk tolerance, learning styles, and comfort with technology. 
Researchers could gain insights into how AI-driven, persona-based responses impact the onboarding experience and contribute to the inclusivity and effectiveness of support for newcomers in OSS. Moreover, these personas could also be further used during the development of new systems that intend to integrate the GenderMag method.

\textbf{Inferring GenderMag Persona Through User Interaction.} Exploring the potential of AI to dynamically identify a user's GenderMag persona by analyzing interaction patterns with newcomers. Rather than relying on the GenderMag facets questionnaire. This approach would use cues from newcomers’s behavior, such as their preference for step-by-step guidance versus tinkering, to infer their problem-solving style and align AI responses accordingly. This inferred persona would allow the AI to adapt its guidance in real time, enhancing support for each user’s unique learning preferences and increasing the inclusivity and personalization of the OSS onboarding experience.
\end{comment}

\section{Conclusion}
\label{sec:conclusion}
%\vspace{-1.0mm}

This paper discussed the potential of LLMs, like ChatGPT, to enhance newcomers' onboarding in OSS projects by tailoring responses to diverse problem-solving styles. %OSS projects offer real-world skill-building opportunities, yet onboarding can be challenging, especially for underrepresented groups whose problem-solving styles may not align with standard OSS workflows. 
Using persona-based prompt engineering, we illustrate the potential of LLMs to adapt to different problem-solving styles by generating outputs tailored to newcomers' unique characteristics. This approach highlights opportunities for LLMs in OSS and invites further research to refine AI-based tools to support contributions to OSS projects. %; however, further analysis is needed to determine the effectiveness of these varied outputs. %we demonstrate how LLMs can adapt to different problem-solving styles, supporting newcomers in ways that resonate with their unique preferences, from risk-averse to exploratory learners. 
%This approach invites further research to refine AI-based tools to support contributions to OSS projects, fostering a more inclusive and empowering environment for newcomers.

%\section{Data Availability}

\section*{Acknowledgments}
%\vspace{-1.0mm}
Katia Felizardo is funded by a research grant from the Brazilian National Council for Scientific and Technological Development (CNPq), Grant 302339/2022--1. 


%\newpage

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,bibtex.bib}



\end{document}

