\subsection{Skill Set Training and Expansion}

%We truncate task demonstrations into skill-related segments. 
%Each segment includes the actions of the corresponding skill, and progress annotation of all skills in this segment.
%Given $N$ skill-related demonstration sets, We alternatively sample batches from each set during training.
%For a batch corresponding to skill $s_i$, \ours updates the parameters of the transformer backbone, the skill head of $s_i$, and the progress head.

%Given the demo sets for all $N$ skills, and the annotated data of ProGSS, we alternatively sample batches from each skill's demo set to train \ours. For $s_i$ being trained, \ours updates the parameters of the transformer backbone, its skill head, and the progress head.

%The multi-head architecture of \ours also allows us to improve a skill with more data or more training steps and add new skills without interfering existing skills. 

% In practical scenarios, we may want to extend an existing skill set of robots. 
% For example, given policies of picking and packing, the robots may want to introduce some pre-grasp actions such as pushing and flipping to handle corner cases in the picking tote. 

%To improve an existing skill, we can finetune the action head with the frozen transformer backbone. 
%To introduce a new skill into the skill set, we add another action head to the existing model and train the new action head with the frozen transformer backbone. 
%In addition, the progress head also needs to be re-trained with a new dimension and all demonstration data.
%In both cases, the performance of other skills is not affected due to the frozen backbone.

\ours multi-head architecture enables concurrent training for a skill set, fine-tuning of a single skill with additional data, and expansion of the existing skill set. For the batch training, we alternate training of  $s_i$ in the set, updating the parameters of the transformer backbone, its skill head, and the progress head. We freeze the parameters of the transformer backbone for fine-tuning with additional data or expansion. For new skill to be introduced into the existing model, we add a new action head and extend the dimension of progress head, then train the new skill head and the progress head. The performance of other skills is not affected during fine-tuning or expansion with frozen backbone.  