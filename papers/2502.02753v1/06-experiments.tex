In this section, we evaluate the performance of \ours in both simulated and real-robot environments, with a total of six experiments, under the various conditions:

 
\begin{itemize}
    \item Performance gain of MuST compared to the single-head baseline
    
   \item  Performance of MuST, conditioned on task goals specified by images or language instructions
    
    \item Performance of MuST across a diverse set of objects
    
    \item Ability for MuST to react to unexpected environment disturbance, based on the skill progress values
\end{itemize}

The performance is measured by two  metrics:
\begin{enumerate}
    \item {\bf Skill completion rate:} In each case, we record the completion of a single skill.
    \item {\bf Execution time:} The execution time is defined as spent time for manipulation until the object consistently stays at the goal pose $g$ for 100 time steps. 
\end{enumerate}

%\begin{enumerate}
%    \item How is the performance of \progss in regular and unexpected scenarios?
%    \item How much performance gain does \ours have comparing with the single head baseline?
%    \item Performance of \ours with different goal-state indicators and on diverse object set.
%    \item Performance of \ours with multiple skill orderings.
%    \item Performance of \ours when adapted to an open-loop framework.
%\end{enumerate}

% We compare the performance of \ours with Octo model.

The single-head baseline of \ours, Octo model uses a single action head to learn all skills without progress estimation.
Both models finetune Octo-Base (93M params) checkpoint and use L1 action heads as decoding heads for skills and progress.
We train the models with an Nvidia Tesla V100-SXM2-16GB GPU.



\subsection{Evaluated Tasks}
\ours is evaluated in three different tasks.
\subsubsection{Sim-GC} In simulation, we test \ours on goal-state conditioned pick-n-pack to evaluate the overall performance of \progss and \ours.
As shown in Fig.~\ref{fig:intro}[Top], this manipulation task requires four skills:
First, the robot flips down the object from the tote boundary to enable picking. 
After that, the robot picks the object from the picking tote.
Depending on the goal-state indicator $I_g$ or $l_g$, the robot packs the object near the desired corner of the packing tote.
Finally, the pushing skill rotates and translates the object to compactly pack it at the desired corner.

\subsubsection{Sim-MS} Similar to Sim-GC, we also designed the task of multi-sequence pick-n-pack to present the performance of \ours when multiple skill orderings are demonstrated.
As shown in Fig.~\ref{fig:multi_sequence}, the robot is tasked to flip down a box and place it at the packing tote. 
Specifically, when the object is located in the central area of the tote, the robot can choose to flip the object before or after pick-n-place.
When the object is located at the boundary of the picking tote, the robot cannot execute pick-n-place before a successful flip.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/multi_sequence.pdf}
    \caption{Multi-Sequence pick-n-pack. When the object is sampled at the central area of the tote, there are two possible task sequences; when the object is sampled at the edge, the robot cannot directly pick it up before flipping.}
    \label{fig:multi_sequence}
\end{figure}

\begin{wrapfigure}{r}{0.25\textwidth}  % 'r' means the figure is on the right
    \centering
    \includegraphics[width=0.25\textwidth]{figures/station_2_overview.pdf}
    \caption{[Left] For all tasks, we use a customized suction gripper for manipulation, which is capable of vacuum suction and dexterous contact with the soft tip. [Right] Fanuc robot arm with the suction gripper for goal-state conditioned pick-n-pack.}
    \label{fig:sock_puppet}
\end{wrapfigure}

\subsubsection{Real-GC} On a real-robot system, we test \ours in open-loop control scenario.
With this task, we aim at demonstrating its capability of \ours in a real-robot system and being adapted to a open-loop control framework.
In Real-GC(Fig.~\ref{fig:station2_sequence}), a Fanuc robot arm flips down an object from the edge of the picking tote, grasps it with the suction cup, packs it at the proper pose, based on a goal image, and pushes it to the corners of the tote.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/station_2_sequence.pdf}
    \caption{Task sequence of real robot goal-state conditioned pick-n-pack.}
    \label{fig:station2_sequence}
\end{figure}


For all tasks, we manipulate objects with a customized suction gripper(Fig.~\ref{fig:sock_puppet}[Left]), which is capable of vacuum suction and dexterous contact with the soft tip.

% move the follow paragraph early  but we need to define tasks 
%The method performance is evaluated under following metrics:
%\begin{enumerate}
%    \item {\bf Task completion rate:} In each test case, we record whether the task of each skill is complete.
%    \item {\bf Execution time:} The execution time is defined as spent time for manipulation until the object constantly stays at the goal pose $g$ for 100 time steps. 
%\end{enumerate}

In previous works, skill annotation for closed-loop control is time consuming\cite{belkhale2023hydra}. To reduce the human annotation time, we use the change of object poses and robot states to automatically annotate the skill execution duration, which labels each time step into transit trajectories and skill execution trajectories.





%\subsection{Progress Estimation in Sim-GC} \label{sec:progress_experiments}
\subsection{Ability of MuST to React to Unexpected Environment Disturbance} \label{sec:progress_experiments}

We first present the performance of \progss in Sim-GC.
Fig.\ref{fig:qual_task1}[Top] shows the estimated progress values along the execution. 
The x-axis represents the time step in simulation and the progress values are re-estimated every 50 time steps.
For each skill, the progress value increases during the execution of the skill, and stays constant most of the time before and after the execution.
Fig.~\ref{fig:qual_task1}[Bottom left] shows an example where the user resets the object to be against the boundary after the robot finishes flipping at step 261. 
\ours detects the unexpected change and decides to redo the flipping skill.
Fig.~\ref{fig:qual_task1}[Bottom right] shows an example where the flipping sub-task is not needed, which is not demonstrated in the training dataset. 
\progss labels flipping as finished as the robot gets close to the object at step 50.
To summarize, \progss selects the proper skill to execute in a long-horizon manipulation task, and it is capable of re-do and skip skills in unexpected situations.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/qual_full.pdf}
    \includegraphics[width=0.7\textwidth]{figures/qual_repeat_skip.pdf}
    \caption{Qualitative results of MuST reactive and adaptive skill execution based on progress value estimation. [Top] Progress value in an ideal sequence of execution. [Bottom] Adaptive sequence of skill execution guided by ProGSS estimation in unexpected situations. \ours re-do[Left] and skip[Right] skills to recover from environment disturbance.}
    \label{fig:qual_task1}
\end{figure*}

\subsection{Quantitative Results in Sim-GC}\label{sec:sim_task1}
In this section, we evalute the overall performance of \ours in Sim-GC and compare it with Octo.
In Sim-GC, we use language prompt or goal images as goal-state indicators to customize the packing pose of the object.
We provide four options of language prompt or goal images(Fig.~\ref{fig:end_state_indicator}) to the models. 
For the goal images, instead of images of the manipulating objects, we use a blue patch to suggest the goal state which makes this goal state indicator independent of the appearance of the manipulated objects, enhancing the model's generalization capability across different object types.
The human demonstrations of Sim-GC is collected in Isaac-sim by controlling the end-effector position and suction activity on keyboard.

For each experiment, we present the task completion rate for each skill. 
Test cases fail in earlier phases are labeled as failures in subsequent skills as well.
To further evaluate the execution efficiency, we also present the average execution time of successful test cases.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/end_state_indicator.pdf}
    \caption{We use either language prompts or images as goal state indicators to customize packing poses.}
    \label{fig:end_state_indicator}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=0.37\textwidth]{figures/object_set.pdf}
    \caption{Training object set and test object set of goal-state conditioned pick-n-pack in simulation.}
    \label{fig:object_set}
\end{figure}

In Tab.\ref{tab:single_language_results}, we evaluate the performance of \ours on the ``Long Box''(Fig.~\ref{fig:object_set})  and the goal-state indicator is a language prompt. 
The models are trained with only 15 human demonstrations for each of the four corners as goal states.
In this task, each camera has good visibility in some sub-tasks but is occluded in other sub-tasks, which makes it hard to learn a shared encoder for all skills.
While Octo model fails in over $70\%$ tasks, \ours maintains $80\%-90\%$ success rate for Sim-GC despite the difficulty.
Besides that, for finished test cases, \ours is $23.7\%-38.4\%$ faster than Octo in execution time.
The results suggest that \ours is data-efficient and is much more robust than Octo baseline in long horizon manipulation tasks.


\begin{table*}[ht]
\centering
\caption{Language Conditioned Sim-GC (Long Box)}
\label{tab:single_language_results}
\begin{tabular}{@{\centering\arraybackslash}m{1.7cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>
{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}@{}}
\toprule
 & \multicolumn{10}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-11} 
 & \multicolumn{2}{c}{\textbf{Flip}} & \multicolumn{2}{c}{\textbf{Pick}} & \multicolumn{2}{c}{\textbf{Pack}} & \multicolumn{2}{c}{\textbf{Push (Orientation)}} & \multicolumn{2}{c}{\textbf{Push (Position)}} & \multicolumn{2}{c}{\textbf{Execution Time}}\\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
 \textbf{End \newline State} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo}& \textbf{\ours} & \textbf{Octo}& \textbf{\ours} & \textbf{Octo} \\ \midrule
% \textbf{Task} & \textbf{Method 1 (Success)} & \textbf{Method 1 (Time)} & \textbf{Method 2 (Success)} & \textbf{Method 2 (Time)} & \textbf{Method 3 (Success)} & \textbf{Method 3 (Time)} & \textbf{Method 4 (Success)} & \textbf{Method 4 (Time)} & \textbf{Method 5 (Success)} & \textbf{Method 5 (Time)} \\ \midrule
Top Left & \multicolumn{1}{|c}{10/10} & 10/10 & \multicolumn{1}{|c}{10/10} & 8/10 & \multicolumn{1}{|c}{10/10} & 7/10 & \multicolumn{1}{|c}{10/10} & 4/10 & \multicolumn{1}{|c}{10/10} & 4/10 & \multicolumn{1}{|c}{1324.2} & 1734.3 \\
Top Right & \multicolumn{1}{|c}{10/10} & 10/10 & \multicolumn{1}{|c}{10/10} & 10/10 & \multicolumn{1}{|c}{9/10} & 9/10 & \multicolumn{1}{|c}{8/10} & 7/10 & \multicolumn{1}{|c}{8/10} & 4/10 & \multicolumn{1}{|c}{1530.0} & 2639.7 \\
Bottom Left & \multicolumn{1}{|c}{10/10} & 10/10 & \multicolumn{1}{|c}{10/10} & 7/10 & \multicolumn{1}{|c}{10/10} & 7/10 & \multicolumn{1}{|c}{9/10} & 5/10 & \multicolumn{1}{|c}{9/10} & 3/10 & \multicolumn{1}{|c}{1538.9} & 2337.3\\
Bottom Right & \multicolumn{1}{|c}{10/10} & 10/10 & \multicolumn{1}{|c}{10/10} & 7/10 & \multicolumn{1}{|c}{9/10} & 6/10 & \multicolumn{1}{|c}{9/10} & 4/10 & \multicolumn{1}{|c}{9/10} & 2/10 & \multicolumn{1}{|c}{1571.7} & 2550.5 \\ \bottomrule
\end{tabular}
\end{table*}

In Tab.~\ref{tab:single_image_results}, we present the performance of \ours with goal image conditioning.
When the goal state is represented as images, \ours maintains $80\%-90\%$ success rate on the long horizon task as a whole.
In Tab.~\ref{tab:four_obj_language_results}, we test \ours on a diverse object set.
The model is trained on four boxes with different sizes, shapes, and textures (Fig.~\ref{fig:object_set}). 
We provide 15 demonstrations for each of the 4 objects in the training set and for each of the four goal poses at corners.
Besides the training objects set, we also test the model on two novel objects.
For the first three skills, \ours maintains over $90\%$ completion rate on training object set and that drops to $75\%-70\%$ on objects in the novel object category due to the novel object appearance.
In the final skill, \ours solves $80\%$ test cases on the cracker box, $65\%-70\%$ on other training objects.
\ours performs worse in finishing push on the novel objects. 
The main reason is that in human demonstrations, we push the cuboid objects at their corners for rotation and translation along the wall. 
However, the contours of objects in the test set are irregular, which induces failures when applying the learned strategy.

\begin{table}[H]
\centering
\caption{Image Conditioned Sim-GC}
\label{tab:single_image_results}
\begin{tabular}{@{\centering\arraybackslash}m{1.7cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}@{}}
\toprule
 & \multicolumn{5}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-6} 
\textbf{Packing \newline Corner} & \textbf{Flip} & \textbf{Pick} & \textbf{Pack} & \textbf{Push (Orientation)} & \textbf{Push (Position)} & \textbf{Execution Time}\\ \midrule
% \textbf{Task} & \textbf{Method 1 (Success)} & \textbf{Method 1 (Time)} & \textbf{Method 2 (Success)} & \textbf{Method 2 (Time)} & \textbf{Method 3 (Success)} & \textbf{Method 3 (Time)} & \textbf{Method 4 (Success)} & \textbf{Method 4 (Time)} & \textbf{Method 5 (Success)} & \textbf{Method 5 (Time)} \\ \midrule
Top Left & 10/10 & 10/10 & 10/10 & 9/10 & 8/10 & 1570.1 \\
Top Right & 9/10 & 9/10 & 9/10 & 8/10 & 8/10 & 1765.6 \\
Bottom Left & 10/10 & 10/10 & 10/10 & 9/10 & 9/10 & 1225.7 \\
Bottom Right & 10/10 & 10/10 & 10/10 & 8/10 & 9/10 & 1158.6 \\ \bottomrule
\end{tabular}
\end{table}


\begin{table}[ht]
\centering
\caption{Sim-GC with Diverse Object Set}
\label{tab:four_obj_language_results}
\begin{tabular}{@{\centering\arraybackslash}m{1.7cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}>{\centering\arraybackslash}m{1cm}@{}}
\toprule
 & \multicolumn{5}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-6} 
\textbf{Test Object} & \textbf{Flip} & \textbf{Pick} & \textbf{Pack} & \textbf{Push (Orientation)} & \textbf{Push (Position)} & \textbf{Execution Time}\\ \midrule
Cracker Box & 20/20 & 20/20 & 19/20 & 16/20 & 16/20 & 2073.4 \\
Liquid Box & 20/20 & 20/20 & 19/20 & 14/20 & 13/20 & 1769.0 \\
Long Box & 20/20 & 20/20 & 18/20 & 14/20 & 13/20 & 1330.0 \\
Oil Tin & 20/20 & 20/20 & 19/20 & 14/20 & 13/20 & 1875.0 \\ \midrule
Bottle1 (OOD) & 20/20 & 20/20 & 15/20 & 12/20 & 9/20 & 1608.2\\ 
Bottle2 (OOD) & 20/20 & 20/20 & 14/20 & 9/20 & 7/20 & 2009.6\\ \bottomrule
\end{tabular}
\end{table}


\subsection{Handling Multiple Sequences in Sim-MS}\label{sec:sim_task2}
We evaluate the performance of \ours on handling multiple skill orderings in Sim-MS tasks. 
For each of the three task sequences in Fig.~\ref{fig:multi_sequence}, we made 50 demonstrations. We test \ours on 80 trials for each of the two initial state categories. 

Tab.~\ref{tab:multi_sequence_results} shows sequence selection distribution and task completion rate.
When the object is sampled at the central area of the picking tote, \ours chooses ``pick first'' and ``flip first'' sequences in $37.5\%$ and $62.5\%$ trials respectively with around $80\%$ success rate on both skill orderings.
When the object is sampled at the edge of the picking tote, picking directly is impossible. 
\ours directly chooses the ``flip first'' sequence or switches to the ``flip first'' sequence after a few failure attempts in $96.2\%$ test cases.
The results suggest that \ours effectively handles multiple task sequences and avoids ``modality collapses'' in long horizon dexterous manipulation tasks.



\begin{table}[H]
\centering
\caption{Choice Distribution and Task Completion Rate in Sim-MS}
\label{tab:multi_sequence_results}
\begin{tabular}{@{\centering\arraybackslash}m{4cm}>{\centering\arraybackslash}m{2cm}>{\centering\arraybackslash}m{2cm}@{}}
\toprule
 & \multicolumn{2}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-3} 
\textbf{Test Cases} & \textbf{Pick First} & \textbf{Flip First}\\ \midrule
Manipulate from central area & 24/30 & 39/50\\
Manipulate from edge & 0/3 & 73/77\\ \bottomrule
\end{tabular}
\end{table}



\subsection{Quantitative Results in Real-GC}\label{sec:real_task}
Finally, we compare \ours with Octo in Real-GC tasks.
The system (Fig.~\ref{fig:sock_puppet}[Right]) consists of a picking tote and a packing tote. 
Each tote is equipped with a Zivid 2+ M130 3D camera.
During the model inference, \ours is given three images: overview images of the two totes and an image of the in-hand object.
Similar to the object-independent goal images in simulation, we use goal images of a brown box(Fig.~\ref{fig:real_images} (c)) which is neither in the training set, nor in the test set.
Since the goal-state indicator is only related to the packing tote, the goal images of the picking tote and the in-hand object is zero-padded.
Based on the observations from the three cameras and the goal image, models decide on the skill to execute and the whole trajectory of the skill execution.
After the execution, the robot moves out of the environment and updates the observation images.

For each object in the training set(Fig.~\ref{fig:real_images}(a)), we collect 15, 15, 24, and 15 human demonstrations for the four skills respectively.
We also test algorithm performance on an object from a novel category (Fig.~\ref{fig:real_images}(b)).

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/real_objects.pdf}
    \caption{Training (a) and test (b) object set on real-robot system. (c) Image of the packing tote with a universal object as the goal-state indicator.}
    \label{fig:real_images}
\end{figure}

For the four skills, a test case is labeled as success if the object is flipped down, leaves picking tote, is placed at right quarter of the packing tote, and is packed less than 2cm to the corner respectively.
A test case is labeled as a failure if the robot fails to proceed to the next phase after three actions or collides with the environment.
We first test both \ours and Octo on the couscous box with different goal-state images (Tab.~\ref{tab:real_robot_diff_corner_results}).
Both models succeed in the first three skills in all the test cases but Octo only successfully pushes the object to corners in $35\%$ test cases.
In Tab.~\ref{tab:real_robot_diff_obj_results}, we show the experiment results on the diverse object set.
Octo has $0\%$ success rate on the small object (``Instax'' box) and the novel object (Bag).
It also fails in pushing other objects to corners in most test cases.
In constrast, \ours finishes $88\%$ test cases among the objects.
In addition, most of the failures of Octo in pushing are due to collisions between the robot and the environment, while the only two failures of \ours on pushing are because the final object pose is too far from the corner (2.1 cm and 2.6 cm) away from the corner.
In summary, \ours has much higher success rate in finishing the whole task than Octo, especially on small objects and novel objects.





\begin{table}[H]
\centering
\caption{Image Conditioned Real-GC (Couscous Box)}
\label{tab:real_robot_diff_corner_results}
\begin{tabular}{@{\centering\arraybackslash}m{1.7cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{0.8cm}>{\centering\arraybackslash}m{1cm}@{}}
\toprule
 % & \multicolumn{6}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-7} 
 & \multicolumn{2}{c}{\textbf{Flip}} & \multicolumn{2}{c}{\textbf{Pick}} & \multicolumn{2}{c}{\textbf{Pack}} & \multicolumn{2}{c}{\textbf{Push}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}  \cmidrule(lr){8-9}
 \textbf{Goal State} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} \\ \midrule
Top Left & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{4/5} & 3/5 \\
Top Right & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{2/5} & 0/5 \\
Bottom Left & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 2/5 \\
Bottom Right & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 2/5 \\ 
 \bottomrule
\end{tabular}
\end{table}




\begin{table}[H]
\centering
\caption{Image-Conditioned Real-GC (Bottom Left Corner)}
\label{tab:real_robot_diff_obj_results}
\begin{tabular}{@{\centering\arraybackslash}m{1.7cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}
>{\centering\arraybackslash}m{0.8cm}@{}}
\toprule
 % & \multicolumn{6}{c}{\textbf{Task Completion}} \\ \cmidrule(lr){2-7} 
 & \multicolumn{2}{c}{\textbf{Flip}} & \multicolumn{2}{c}{\textbf{Pick}} & \multicolumn{2}{c}{\textbf{Pack}} & \multicolumn{2}{c}{\textbf{Push}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}  \cmidrule(lr){8-9}
 \textbf{Object} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} & \textbf{\ours} & \textbf{Octo} \\ \midrule
``Instax'' Box & \multicolumn{1}{|c}{ 4/5} & 0/5 & \multicolumn{1}{|c}{4/5} & 0/5 & \multicolumn{1}{|c}{4/5} & 0/5 & \multicolumn{1}{|c}{2/5} & 0/5 \\
``Mina'' Box & \multicolumn{1}{|c}{5/5} & 4/5 & \multicolumn{1}{|c}{5/5} & 4/5 & \multicolumn{1}{|c}{5/5} & 4/5 & \multicolumn{1}{|c}{5/5} & 3/5 \\
Couscous Box & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 2/5 \\
Rice Box & \multicolumn{1}{|c}{ 5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 5/5 & \multicolumn{1}{|c}{5/5} & 4/5 & \multicolumn{1}{|c}{5/5} & 1/5 \\ 
Bag (OOD) &\multicolumn{1}{|c}{ 5/5} & 0/5 & \multicolumn{1}{|c}{5/5} & 0/5 & \multicolumn{1}{|c}{5/5} & 0/5 & \multicolumn{1}{|c}{5/5} & 0/5  \\ \bottomrule
\end{tabular}
\end{table}


% Structure
% \begin{enumerate}
% \item Long horizon pick-n-pack.
% \begin{enumerate}
%     \item description with figures and qualitative results.
%     \item language-conditioning, long box, 15 demos on each corner, MuST vs Octo single policy vs non-object-centric MuST vs skill addition.
%     \item Skill skipping and repeating (small table or only show in video).
%     \item Universal goal image conditioning
%     \item Generality: 4 objects * 15 demos * 4 corners $\rightarrow$ in/out-of distribution objects.
% \end{enumerate}
% \item Multi-task sequence pick-n-pack.
% \begin{enumerate}
%     \item description with figures
%     \item Objects in the central region: Need to show a balancing sequence choice to avoid ``modality collapse''
%     \item Object on the boundary: Knows to flip first.
% \end{enumerate}
% \item Station $2$ trajectory planning
% \begin{enumerate}
%     \item Description with figures
%     \item Object-independent goal image conditioning: MuST vs Octo single policy.
% \end{enumerate}
% \end{enumerate}