\newcommand{\avllong}{the Advanced Visualization Lab (AVL). This interdisciplinary team is housed at the National Center for Supercomputing Applications and consists of visualization designers who focus on cinematic presentations of scientific data}
\newcommand{\avlshort}{AVL}
%\newcommand{\avllong}{a team of visualization designers who focus on cinematic presentations of scientific data}
%\newcommand{\avlshort}{CSVT}


\begin{abstract}
Engaging the public with science is critical for a well-informed population. A popular method of scientific communication is documentaries.
Once released, it can be difficult to assess the impact of such works on a large scale, due to the overhead required for in-depth audience feedback studies.
In what follows, we overview our complementary approach to qualitative studies through quantitative impact and sentiment analysis of Amazon reviews for several scientific documentaries.
In addition to developing a novel impact category taxonomy for this analysis, we release a dataset containing \nsentences\ human-annotated sentences from \nreviews\ Amazon reviews for \nmoviesword\ movies created in whole or part by \avllong. 
Using this data, we train and evaluate several machine learning and large language models, discussing their effectiveness and possible generalizability for documentaries beyond those focused on for this work. 
Themes are also extracted from our annotated dataset which, along with our large language model analysis, demonstrate a measure of the ability of scientific documentaries to engage with the public.
\end{abstract}


