\begin{proof}
First, consider a modified version of the \gls*{DALMC} algorithm with exact scores, that is,
\begin{equation}\label{eq:auxiliary_algorithm_exact_scores}
    X_{l+1} = X_l + h_l \nabla\log\hat{\mu}_l(X_l) + \sqrt{2 h_l} \xi_l,
\end{equation}
where $h_l > 0$ is the step size, $\xi_k\sim \mathcal{N}(0,I)$, $\hat{\mu}_{t} = \mu_{\kappa t}$, $l\in\{1,\dots, M\}$ and $0=t_0<t_1<\dots<t_M=T/\kappa$ is a discretisation of the interval $[0,T/\kappa]$.
Let $\mathbb{Q}$ be the path measure associated with the continuous-time interpolation of this auxiliary algorithm which corresponds to the SDE 
\begin{equation*}
    \md X_t = \nabla\log \hat{\mu}_{t_-}(X_{t_-})\md t + \sqrt{2}\md B_t,\; t\in[0,T/\kappa],
\end{equation*}
where given a discretisation of the interval $[0,T/\kappa]$, $0=t_0<t_1<\dots<t_M=T/\kappa$, we define $t_-:=t_{l-1}$ when $t\in[t_{l-1}, t_l)$ for $l=1,\dots, M$. On the other hand, let $\mathbb{P}$ be the path measure corresponding to the following reference SDE
\begin{equation*}
    \md Y_t = (\nabla\log \hat{\mu}_t + v_t)(Y_t)\md t + \sqrt{2}\md B_t,\; t\in[0,T/\kappa].
\end{equation*}
The vector field $v = (v_t)_{t\in[0,T/\kappa]}$ is designed such that $Y_t\sim\hat{\mu}_t$ for all $t\in[0, T/\kappa]$. 
Using the Fokker-Planck equation, we have that 
\begin{equation*}
    \partial\hat{\mu}_t = \nabla\cdot\left(\hat{\mu}_t(\nabla\log\hat{\mu}_t + v_t)\right)  + \Delta \hat{\mu}_t = -\nabla\cdot(\hat{\mu}_t v_t), \; t\in[0,T/\kappa].
\end{equation*}
This implies that $v_t$ satisfies the continuity equation and hence generates the curve of probability measures $(\hat{\mu}_t)_t$. Leveraging Lemma \ref{lemma:optimal_vector_field}, we choose $v$ to be the one that minimises the $L^2(\hat{\mu}_t)$ norm, resulting in $\Vert v_t\Vert_{L^2(\hat{\mu}_t)} = \left\vert\Dot{\hat{\mu}}\right\vert_t$ being the metric derivative.
Using the form of Girsanov's theorem given in Lemma \ref{lemma:girsanov_theorem} we have
\begin{align}
    \kl&\left(\mathbb{P}\;||\mathbb{Q}\right)= \frac{1}{4}\int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log \hat{\mu}_t(X_t)-\nabla \log \hat{\mu}_{t_-}(X_{t_-}) + v_t(X_t)\right\Vert^2\right]\md t\nonumber\\
    \lesssim& \int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}} \left[\left\Vert \nabla\log \hat{\mu}_t(X_t)-\nabla \log \hat{\mu}_t(X_{t_-})\right\Vert^2\right]\md t + \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t \nonumber\\
    &+ \int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}} \left[\left\Vert \nabla\log \hat{\mu}_t(X_{t_-})-\nabla \log \hat{\mu}_{t_-}(X_{t_-})\right\Vert^2\right]\md t \nonumber\\
    \leq&  \sum_{l=1}^M\int_{t_{l-1}}^{t_l} L_{\kappa t}^2 \ \mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]\md t+ \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t+ \int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}} \left[\left\Vert \nabla\log \frac{\hat{\mu}_t(X_{t_-})}{\hat{\mu}_{t_-}(X_{t_-})}\right\Vert^2\right]\md t, \label{eq:kl_path_bound_intermediate}
\end{align}
where we have used that $\nabla\log\hat{\mu}_t$ is Lipschitz with constant $L_{\kappa t}$.
First, we bound the change in the score function $\mathbb{E}_{\mathbb{P}} \left[\left\Vert \nabla\log \frac{\hat{\mu}_t(X_{t_-})}{\hat{\mu}_{t_-}(X_{t_-})}\right\Vert^2\right]$. Let $t\geq t_{-}$, we can write
\begin{equation*}
    \hat{\mu}_{t_-} = T_{\sqrt{\frac{\lambda_{\kappa t}}{\lambda_{\kappa t_-}}}} \#\hat{\mu}_t * \mathcal{N}\left(0, \left(\sqrt{1-\lambda_{\kappa t_-}}-\sqrt{\frac{(1-\lambda_{\kappa t})\lambda_{\kappa t_-}}{\lambda_{\kappa t}}}\right)^2\sigma^2 I\right),
\end{equation*}
where the pushforward $T_{\alpha}\#$ is defined as $T_{\alpha}\#\mu(x) = \alpha^d \mu(\alpha x)$. Using \citet[Lemma C.12]{lee2022convergence} we have
\begin{align*}
    \left\Vert \nabla\log \frac{\hat{\mu}_t(X_{t_-})}{\hat{\mu}_{t_-}(X_{t_-})}\right\Vert^2 \lesssim L_{\kappa t}^2d \gamma_t + L_{\kappa t}^2\left(\sqrt{\frac{\lambda_{\kappa t}}{\lambda_{\kappa t_-}}}-1\right)^2 \Vert X_{t_-}\Vert^2 + \left(\sqrt{\frac{\lambda_{\kappa t}}{\lambda_{\kappa t_-}}} -1 + L_{\kappa t} \gamma_t\right)^2 \left\Vert \nabla \log\hat{\mu}_t(X_{t_-})\right\Vert^2,
\end{align*}
where
\begin{equation*}
    \gamma_t  = \left(\sqrt{1-\lambda_{\kappa t_-}}-\sqrt{\frac{(1-\lambda_{\kappa t})\lambda_{\kappa t_-}}{\lambda_{\kappa t}}}\right)^2\lesssim 1-\frac{\lambda_{\kappa t_-}}{\lambda_{\kappa t}}.
\end{equation*}
Let $C_\lambda$ introduced in \Cref{assumption:schedule_form}, we have
\begin{align*}
\gamma_t \leq 1-\frac{\lambda_{\kappa t_-}}{\lambda_{\kappa t}}\lesssim C_\lambda h_l, \quad \quad \left(\sqrt{\frac{\lambda_{\kappa t}}{\lambda_{\kappa t_-}}}-1\right)^2 \lesssim C_\lambda^2 h_l^2,\quad\quad
    \left(\sqrt{\frac{\lambda_{\kappa t}}{\lambda_{\kappa t_-}}} -1+ L_{\kappa t} \gamma_t\right)^2\lesssim h_l^2 L_{\kappa t}^2.
\end{align*}
In addition, by choosing an appropriate step size, as will be shown in Corollary~\ref{corollary:complexity_bounds}, we can bound $h_l^2 L_{\kappa t}^2\lesssim 1$.

Given that $X_t = \sqrt{\lambda_t} X + \sqrt{1-\lambda_t} \sigma^2 Z$ for $X_t\sim\hat{\mu}_t$, we derive the following moment bound
\begin{align*}
    \mathbb{E}_{\mathbb{P}}\left[\left\Vert X_{t_-}\right\Vert^2\right] =& \mathbb{E}_{\mathbb{P}}\left[\left\Vert \sqrt{\lambda_{\kappa t_-}} X + \sqrt{1-\lambda_{\kappa t_-}} Z\right\Vert^2\right] = \lambda_{\kappa t_-} \mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + (1-\lambda_{\kappa t_-})\sigma^2 d\lesssim \mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d.
\end{align*}
To bound $\mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log\hat{\mu}_t(X_{t_-})\right\Vert^2\right]$, recall from \eqref{eq:hessian_final_bound_1} that $\mu_t\propto e^{-U_t}$ satisfies $\nabla^2 U_t \preccurlyeq  L_t I$. 
Therefore, using \citet[Lemma 4.0.1]{sinho_book} it holds that 
\begin{align*}
    \mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log\hat{\mu}_t(X_{t_-})\right\Vert^2\right] \leq & \mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log\hat{\mu}_t(X_{t})\right\Vert^2\right] + \mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log\hat{\mu}_t(X_{t})-\nabla\log\hat{\mu}_t(X_{t_-})\right\Vert^2\right]\\
    \leq & L_{\kappa t} d  + L_{\kappa t}^2\mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]. 
\end{align*}
This implies that
\begin{align*}
    \mathbb{E}_{\mathbb{P}} \left[\left\Vert \nabla\log \frac{\hat{\mu}_t(X_{t_-})}{\hat{\mu}_{t_-}(X_{t_-})}\right\Vert^2\right]\lesssim &d h_lL_{\kappa t}^2 + h_l^2L_{\kappa t}^2 \left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right) +  h_l^2L_{\kappa t}^2 \left(L_{\kappa t} d 
    + L_{\kappa t}^2\mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]\right).
\end{align*}
Substituting this expression into \eqref{eq:kl_path_bound_intermediate}, we have
\begin{align*}
    \kl\left(\mathbb{P}\;||\mathbb{Q}\right)\lesssim& \sum_{l=1}^M\int_{t_{l-1}}^{t_l} L_{\kappa t}^2 \ \mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]\md t+ \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t\\
    &+ \sum_{l=1}^M\int_{t_{l-1}}^{t_l} \left(d h_l L_{\kappa t}^2 + h_l^2 L_{\kappa t}^2\left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right) +  dh_l^2 L_{\kappa t}^3\right)\md t.
\end{align*}
To bound $\mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]$ we note that under $\mathbb{P}$, for $t\in [t_{l-1}, t_l)$, we have
\begin{equation*}
    X_t - X_{t_-} = \int_{t_{l-1}}^t (\nabla\log {\hat{\mu}}_\tau + v_\tau) (X_\tau) \md \tau + \sqrt{2}(B_t - B_{t_{l-1}}).
\end{equation*}
Therefore, 
\begin{align*}
    \mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right] &\lesssim \mathbb{E}_{\mathbb{P}}\left[\left\Vert\int_{t_{l-1}}^t (\nabla\log {\hat{\mu}}_\tau + v_\tau) (X_\tau) \md \tau\right\Vert^2\right]  + \mathbb{E}_{\mathbb{P}} \left[\left\Vert \sqrt{2}(B_t - B_{t_{l-1}})\right\Vert^2\right]\\
    &\lesssim (t-t_{l-1}) \int_{t_{l-1}}^t \left(\left\Vert\nabla\log {\hat{\mu}}_\tau \right\Vert_{L^2({\hat{\mu}}_\tau)}^2 + \left\Vert v_\tau \right\Vert_{L^2({\hat{\mu}}_\tau)}^2\right)\md \tau  + d(t-t_{l-1})\\
    &\lesssim h_l \int_{t_{l-1}}^{t_l} \left(\left\Vert\nabla\log {\hat{\mu}}_\tau \right\Vert_{L^2({\hat{\mu}}_\tau)}^2 + \left\Vert v_\tau \right\Vert_{L^2({\hat{\mu}}_\tau)}^2\right)\md \tau  + d h_l,
\end{align*}
where the second inequality arises from the application of the Cauchy-Schwarz inequality, and the last inequality is due to the definition $h_l = t_l - t_{l-1}$.
Taking the integral over $t\in[t_{l-1}, t_l]$, it follows
\begin{align*}
    \int_{t_{l-1}}^{t_l}{L}_{\kappa t}^2 \ \mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right] \md t \lesssim &  \left(\int_{t_{l-1}}^{t_l}{L}_{\kappa t}^2 \ \md t\right) \left(h_l \int_{t_{l-1}}^{t_l} \left(\left\Vert\nabla\log {\hat{\mu}}_t \right\Vert_{L^2({\hat{\mu}}_t)}^2 + \left\Vert v_t \right\Vert_{L^2({\hat{\mu}}_t)}^2\right)\md t  + d h_l\right).
\end{align*}
Putting this together we have
\begin{align}
&\sum_{l=1}^M\int_{t_{l-1}}^{t_l} L_{\kappa t}^2 \ \mathbb{E}_{\mathbb{P}} \left[\left\Vert X_t-X_{t_-}\right\Vert^2\right]\md t+ \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t \nonumber\\
    &\lesssim \sum_{l=1}^M \left(\int_{t_{l-1}}^{t_l} L_{\kappa t}^2 \ \md t\right) \left(h_l \int_{t_{l-1}}^{t_l} \left(\left\Vert\nabla\log {\hat{\mu}}_t \right\Vert_{L^2({\hat{\mu}}_t)}^2 + \left\Vert v_t \right\Vert_{L^2({\hat{\mu}}_t)}^2\right)\md t  + d h_l\right)+ \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t \nonumber\\
   &\lesssim \sum_{l=1}^M \left(\int_{t_{l-1}}^{t_l}L_{\kappa t}^2 \ \md t\right) \left(h_l \int_{t_{l-1}}^{t_l} \left(d L_{\kappa t}\ + \left\Vert v_t \right\Vert_{L^2({\hat{\mu}}_t)}^2\right)\md t  + d h_l\right)+ \int_0^{T/\kappa} \Vert v_t\Vert^2_{L^2({\hat{\mu}}_t)} \md t \nonumber\\
   &\lesssim \sum_{l=1}^M \left( 1 + h_l^2\max_{[t_{l-1}, t_l]}L_{t}^2\right)
   \int_{t_{l-1}}^{t_l} \left\vert\Dot{\hat{\mu}}\right\vert_t^2\ \md t + \left(d h_l\int_{t_{l-1}}^{t_l}L_{\kappa t}^2 \ \md t\right) \left(1 + h_l\max_{[t_{l-1}, t_l]}L_{t}\right). \label{eq:intermediate_bound_discretisation_paths}
\end{align}
This results in the following bound for the \gls*{KL} divergence between $\mathbb{P}$ and $\mathbb{Q}$:
\begin{align*}
    \kl\left(\mathbb{P}\;||\mathbb{Q}\right)\lesssim& \sum_{l=1}^M \left( 1 + h_l^2\max_{[t_{l-1}, t_l]} L_{t}^2\right)
   \int_{t_{l-1}}^{t_l} \left\vert\Dot{\hat{\mu}}\right\vert_t^2\ \md t + \left(d h_l\int_{t_{l-1}}^{t_l} L_{\kappa t}^2 \ \md t\right) \left(1 + h_l\max_{[t_{l-1}, t_l]} L_{t}\right) \\
   & + \sum_{l=1}^M\int_{t_{l-1}}^{t_l} \left(d h_l L_{\kappa t}^2 + h_l^2 L_{\kappa t}^2 \left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right) + dh_l^2  L_{\kappa t}^3\right)\md t
\end{align*}
Note that intuitively we want to take smaller steps $h_l= t_l-t_{l-1}$ when $L_t$ is larger. 
Define $h = \max_{l\in\{1, \dots, M\}} h_l$, we can further simplify the previous expression to obtain
\begin{align*}
    \kl\left(\mathbb{P}\;||\mathbb{Q}\right)\lesssim &\sum_{l=1}^M (1+h^2 L_{\max}^2)\int_{t_{l-1}}^{t_l} \left\vert\Dot{\hat{\mu}}\right\vert_t^2 \ \md t\ + d h_l(1+ h L_{\max}) \int_{t_{l-1}}^{t_l}L_{\kappa t}^2 \ \md t+ \frac{Th^2L_{\max}^2}{\kappa}\left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right)\\
     =& (1+h^2 L_{\max}^2) \int_{0}^{T/\kappa} \left\vert\Dot{\hat{\mu}}\right\vert_t^2 \ \md t\ + 
 d h(1+ h L_{\max})\int_{0}^{T/\kappa} L_{\kappa t}^2 \ \md t+ \frac{Th^2 L_{\max}^2}{\kappa}\left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right)\\
 =&  (1+h^2 L_{\max}^2) \kappa \mathcal{A}_{\lambda}(\mu)  + 
\frac{d h}{\kappa} (1+ hL_{\max})\int_{0}^{T}L_{ t}^2 \ \md t+ \frac{Th^2L_{\max}^2}{\kappa} \left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right).
\end{align*}
The step size $h$ can be expressed in terms of the number of steps $M$ and $\kappa$ as $h\asymp \frac{1}{M\kappa}$. Therefore, we have
\begin{align*}
    \kl\left(\mathbb{P}\;||\mathbb{Q}\right)&\lesssim\left(1+\frac{L_{\max}^2}{M^2\kappa^2}\right) \kappa \mathcal{A}_\lambda(\mu) + \frac{d}{M\kappa^2}\left(1+  \frac{L_{\max}}{M\kappa}\right)\int_{0}^{T}L_{ t}^2 \ \md t+ \frac{L_{\max}^2}{M^2\kappa^3} \left(\mathbb{E}_{\pid}\left[\left\Vert X\right\Vert^2\right] + d\right)\\
    &\lesssim \left(1+\frac{L_{\max}^2}{M^2\kappa^4}\right) \kappa C_\lambda \left(\mathbb{E}_{\pid}\left[\Vert X\Vert^2\right] +  d\right) + \frac{d}{M\kappa^2}\left(1+  \frac{L_{\max}}{M\kappa}\right)\int_{0}^{T}L_{ t}^2 \ \md t,
\end{align*}
where we have used the bound on the action derived in Lemma \ref{lemma:action_bound} and $T = \mathcal{O}(1)$.

To derive the previous bound, we have assumed that the score of the intermediate distributions $\nabla\log\hat{\mu}_t$, can be computed exactly. In practice, however, we use an approximation, introducing an additional error term into the analysis. Let $s_\theta(\cdot, t)$ denote our estimator for $\nabla\log\hat{\mu}_t$  and let $\mathbb{Q}_\theta$ be the path measure of the continuous-time interpolation of the \gls*{DALMC} algorithm \eqref{eq:annealed_langevin_mcmc_algorithm_score_approx}. We conclude that
\begin{align*}
    \kl\left(\mathbb{P}\;||\mathbb{Q}_\theta\right)=& \frac{1}{4}\int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log \hat{\mu}_t(X_t)- s_\theta(X_{t_-}, t_-) + v_t(X_t)\right\Vert^2\right]\md t\\
    \lesssim& \int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla\log \hat{\mu}_t(X_t)-\nabla \log \hat{\mu}_{t_-}(X_{t_-}) + v_t(X_t)\right\Vert^2\right]\md t \\
    &+ \int_0^{T/\kappa}\mathbb{E}_{\mathbb{P}}\left[\left\Vert \nabla \log \hat{\mu}_{t_-}(X_{t_-}) - s_\theta(X_{t_-}, t_-)\right\Vert^2\right]\md t\\
    \lesssim& \left(1+\frac{L_{\max}^2}{M^2\kappa^4}\right) \kappa C_\lambda \left(\mathbb{E}_{\pid}\left[\Vert X\Vert^2\right] + d\right) + \frac{d}{M\kappa^2}\left(1+  \frac{L_{\max}}{M\kappa}\right)\int_{0}^{T}L_{ t}^2 \ \md t \\
    &+\sum_{l=0}^{M-1} h_l\mathbb{E}_{\hat{\mu}_t}\left[\left\Vert \nabla \log \hat{\mu}_l(X_{t_l}) - s_\theta(X_{t_l}, t_l)\right\Vert^2\right]\\
    \lesssim& \;\left(1+\frac{L_{\max}^2}{M^2\kappa^4}\right) \kappa C_\lambda \left(\mathbb{E}_{\pid}\left[\Vert X\Vert^2\right] + d\right) + \frac{d}{M\kappa^2}\left(1+  \frac{L_{\max}}{M\kappa}\right)\int_{0}^{T}L_{ t}^2 \ \md t + \varepsilon_{\text{score}}^2\\
    \lesssim& \;\left(1+\frac{L_{\max}^2}{M^2\kappa^4}\right) \kappa (M_2\vee d) + \frac{d}{M\kappa^2}\left(1+  \frac{L_{\max}}{M\kappa}\right)L_{\max}^2 + \varepsilon_{\text{score}}^2,
\end{align*}
where we have used the control of the score approximation given in assumption \Cref{assumption:score_approximation}.
\end{proof}

