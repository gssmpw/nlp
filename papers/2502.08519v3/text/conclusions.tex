\section{Conclusion and open problems}

We have provided a number of new complexity results concerning min-max optimization in general, and team zero-sum games in particular (\emph{cf.}~\Cref{tab:results}). There are many interesting avenues for future research. The complexity of computing first-order Nash equilibria (equivalently, the $\gdaFixed$ problem) remains wide open, but our hardness results suggest a possible approach: as we have seen, in symmetric min-max optimization, computing \emph{either} symmetric or non-symmetric equilibria is intractable. It would be enough if one could establish this using the same underlying function---that is, somehow combine our two reductions into one. With regard to Nash equilibria in adversarial team games, the main question that remains open concerns the \emph{strong} approximation version of the problem, whereby one requires identifying points that are close---in geometric distance---to exact Nash equilibria. Is there some natural subclass of \textsf{FIXP} that characterizes the complexity of that problem? Relatedly, \citet{Etessami10:On} provided strong evidence for the intractability of strong approximation---hovering above \NP---through a reduction from the \emph{square root sum} problem; it is currently unclear whether such reductions can carry over using adversarial team games.