
\section{Introduction}

We consider the fundamental task of computing local equilibria in constrained min-max optimization problems of the form
\begin{equation}
    \label{eq:minimax}
    \min_{\vx \in \calX} \max_{\vy \in \calY} f(\vx, \vy),
\end{equation}
where $\calX \subseteq \R^{d_x}$ and $\calY \subseteq \R^{d_y}$ are convex and compact constraint sets, and $f : \calX \times \calY \to \R$ is a smooth objective function. Tracing all the way back to Von Neumann's celebrated minimax theorem~\cite{vonNeumann28:Zur} and the inception of game theory, such problems are attracting renewed interest in recent years propelled by a variety of modern machine learning applications, such as generative modeling~\citep{goodfellow2014generative}, reinforcement learning~\citep{daskalakis2020independent,Bai20:Provable,Wei21:Last}, and adversarial robustness~\citep{Madry17:Towards,cohen19:Certified,Bai21:Recent,Carlini19:Evaluating}. Another prominent class of problems encompassed by~\eqref{eq:minimax} concerns computing Nash equilibria in \emph{(two-)team zero-sum games}~\citep{Zhang23:Team,Zhang21:Computing,Basilico17:Team,Stengel97:Team,Carminati23:Hidden,Orzech23:Correlated,Farina18:Ex,Zhang20:Converging,Celli18:Computational,schulman2017duality}, which is a primary focus of this paper.

Perhaps the most natural solution concept---guaranteed to always exist---pertaining to~\eqref{eq:minimax}, when $f$ is nonconvex-nonconcave, is a pair of strategies $(\vx^*, \vy^*)$ such that both players (approximately) satisfy the associated \emph{first-order} optimality conditions~\citep{Tsaknakis21:Finding,Jordan23:First,Ostrovskii21:Efficient,Nouiehed19:Solving}, as formalized in the definition below.
\begin{definition}
    \label{def:FONE}
    A point $(\vxstar, \vystar) \in \calX \times \calY$ is an \emph{$\epsilon$-first-order Nash equilibrium} of~\eqref{eq:minimax} if
    \begin{equation*}
        %\label{eq:VI}
        \langle \vx - \vxstar, \nabla_{\vx} f(\vxstar, \vystar) \rangle \geq -\epsilon \quad \text{and} \quad \langle \vy - \vystar, \nabla_{\vy} f(\vxstar, \vystar) \rangle \leq  \epsilon \quad \forall (\vx, \vy) \in \calX \times \calY.
    \end{equation*}
\end{definition}
\Cref{def:FONE} can be equivalently recast as a variational inequality (VI) problem: if $\vz \defeq (\vx, \vy)$ and $F : \vz \mapsto F(\vz) \defeq (\nabla_{\vx} f(\vx, \vy), -\nabla_{\vy} f(\vx, \vy))$, we are searching for a point $\vz^* \in \mathcal{Z} \defeq \calX \times \calY$ such that $\langle \vz - \vz^*, F(\vz^*) \rangle \geq - 2 \epsilon$ for all $\vz \in \mathcal{Z}$. Yet another equivalent definition is instead based on approximate \emph{fixed points} of gradient descent/ascent (GDA); namely, \Cref{def:FONE} amounts to bounding the gradient mappings
\begin{equation}
\label{eq:fpgda}
\tag{Fixed points of GDA} 
\| \vx^* - \Pi_{\calX} ( \vx^* - \nabla_{\vx} f(\vx^*, \vy^*) ) \|\leq \epsilon', \| \vy^* - \Pi_{\calY} ( \vy^* + \nabla_{\vy} f(\vx^*, \vy^*) ) \|  \leq \epsilon'
\end{equation} 
for some approximation parameter $\epsilon' > 0$ that is (polynomially) dependent on $\epsilon > 0$, where $\|\cdot\|$ is the (Euclidean) $\ell_2$ norm and $\Pi(\cdot)$ is the projection operator. Other definitions that differentiate between the order of play between players---based on the notion of a Stackelberg equilibrium---have also been considered in the literature~\citep{Jin20:What}.

The complexity of min-max optimization is well-understood in certain special cases, such as when $f$ is convex-concave (\emph{e.g.},~\citet{Korpelevich76:Extragradient,MertikopoulosLZ19,Cai22:Finite,Choudhury23:Single,Gorbunov22:Last}, and references therein), or more broadly, nonconvex-concave~\citep{Lin20:Gradient,Xu23:Unified,Stochastic20:Luo}. However, the complexity of general min-max optimization problems, when the objective function $f$ is nonconvex-nonconcave, has remained wide open despite intense efforts in recent years. \citet{DSZ21} made progress by establishing certain hardness results targeting the more challenging setting in which there is a \emph{joint} (that is, coupled) set of constraints. In fact, it turns out that their lower bounds apply even for linear-nonconcave objective functions (\emph{cf.}~\citet{Bernasconi24:Role}), showing that their hardness result is driven by the presence of joint constraints---indeed, under uncoupled constraints, many efficient algorithms attaining~\Cref{def:FONE} (for linear-nonconcave problems) have been documented in the literature. In the context of min-max optimization, the most well-studied setting posits that players have independent constraints; this is the primary focus of our paper.

\subsection{Our results}

We establish new complexity lower bounds in min-max optimization for computing equilibria in the sense of~\Cref{def:FONE}; our main results are gathered in~\Cref{tab:results}.

\begin{table}[h!]
\centering
\caption{The main results of this paper. NE stands for Nash equilibrium and FONE for first-order Nash equilibrium (\Cref{def:FONE}). We also abbreviate symmetric to ``sym.'' (second column).}
\footnotesize % Adjusts the font size to small
\renewcommand{\arraystretch}{1.2} % Increase row spacing
\begin{tabular}{lccc}
\toprule
\textbf{Class of problems}  & \textbf{Eq. concept} & \textbf{Complexity} & \textbf{Even for} \\
\midrule
\rowcolor{gray!20} Adversarial team games & $\epsilon$-NE & $\CLS$-complete (\Cref{theorem:actual}) & $3$-player ($2$ vs. $1$), polymatrix \\ \multirow{2}{*}{Symmetric min-max} & sym. $\epsilon$-FONE & \PPAD-complete (\Cref{theorem:team-hard}) & polymatrix, team $0$-sum, $\epsilon = \nicefrac{1}{n^c}$ \\
& non-sym. $\epsilon$-FONE & \NP-hard (\Cref{theorem:non-symmetric}) & quadratics, $\epsilon = \nicefrac{1}{n^c}$ \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{table}


\paragraph{Adversarial team games.} We first examine an important special case of~\eqref{eq:minimax}: \emph{adversarial team games}~\citep{Stengel97:Team}. Here, a team of $n$ players with identical interests is competing against a single adversarial player. (In such settings, \Cref{def:FONE} captures precisely the Nash equilibria of the game.) The computational complexity of this problem was placed by~\citet{Anagnostides23:Algorithms} in the complexity class~$\CLS$---which stands for continuous local search~\citep{Daskalakis11:Continuous}. Further, by virtue of a result of~\citet{Babichenko21:Settling}, computing Nash equilibria in adversarial team games when $n \gg 1$ is~$\CLS$-complete. In the context of this prior work, an important question left open by~\citet{Anagnostides23:Algorithms} concerns the case where $n$ is a small constant, a regime not captured by the hardness result of~\citet{Babichenko21:Settling} pertaining to identical-interest games---for, in such games, one can simply identify the strategy leading to the highest payoff, which is tractable when $n$ is small.

We show that even when $n = 2$, computing an $\epsilon$-Nash equilibrium in adversarial team games is $\CLS$-complete. (Of course, the case where $n=1$ amounts to two-player zero-sum games, well known to be in $\P$.)

\begin{restatable}{theorem}{maincls}
    \label{theorem:cls-completeness}
    Computing an $\epsilon$-Nash equilibrium in $3$-player (that is, $2$ vs. $1$) adversarial team games is $\CLS$-complete.
\end{restatable}

Coupled with earlier results, \Cref{theorem:cls-completeness} completely characterizes the complexity landscape for computing Nash equilibria in adversarial team games.

Our proof is based on a recent hardness result of~\citet{ghosh2024complexitysymmetricbimatrixgames} (\emph{cf.}~\citet{Tewolde25:Computing}), who proved that computing a \emph{symmetric} $\epsilon$-Nash equilibrium in a symmetric two-player game with identical payoffs is~$\CLS$-complete. The key idea in our reduction is that one can leverage the adversarial player so as to enforce symmetry between the team players, without affecting the equilibria of the original game; the basic gadget underpinning this reduction is explained and analyzed in~\Cref{sec:cls}.

Incidentally, our~$\CLS$-hardness reduction hinges on a \emph{polymatrix} adversarial team game, thereby addressing another open question left recently by~\citet{Hollender24:Complexity}.

\begin{theorem}
    \label{theorem:actual}
    \Cref{theorem:cls-completeness} holds even when one restricts to polymatrix, $3$-player adversarial team games.
\end{theorem}

We complement the above hardness result by showing that, even when $n = 2$, there is an adversarial team game with a unique Nash equilibrium supported on \emph{irrational numbers} (\Cref{theorem:irrational})---unlike~\Cref{theorem:cls-completeness}, \Cref{theorem:irrational} is based on a non-polymatrix game, for otherwise rational Nash equilibria are guaranteed to exist. This strengthens an observation of~\citet{Stengel97:Team}, who noted that a \emph{team-maxmin equilibrium}---a stronger notion than Nash equilibria---can be supported on irrational numbers. \Cref{theorem:irrational} brings to the fore the complexity of deciding whether an adversarial team game admits a unique Nash equilibrium; \Cref{theorem:uniqueATG} addresses that question for the version of the problem accounting even for $\poly(1/n)$-Nash equilibria.


\paragraph{Symmetric min-max optimization} As we have seen, symmetry plays a key role in the proof of~\Cref{theorem:cls-completeness}, but that result places no restrictions on whether the equilibrium is symmetric or not---this is indeed the crux of the argument. The next problem we consider concerns computing \emph{symmetric} equilibria in \emph{symmetric} min-max optimization problems, in the following natural sense.

\begin{definition}[Symmetric min-max optimization]
    \label{def:symmetric}
  A function $f:\calX \times \calY \to \R$ is called \emph{antisymmetric} if $\calX = \calY$ and 
  \begin{equation*}
      f(\vx,\vy) = -f(\vy,\vx) \quad \forall (\vx, \vy) \in \calX \times \calY.
  \end{equation*}
  Furthermore, a point $(\vx, \vy) \in \calX \times \calY$ is called \emph{symmetric} if $\vx = \vy$. The associated min-max optimization problem is called symmetric if the underlying function $f$ is \emph{antisymmetric}.\footnote{The nomenclature of this definition is consistent with the usual terminology in the context of (two-player) zero-sum games: a symmetric zero-sum game is one in which the the underlying game matrix $\mat{A}$ is antisymmetric (that is, skew-symmetric), so that $\langle \vx, \mat{A} \vy \rangle = - \langle \vy, \mat{A} \vx \rangle$ for all $(\vx, \vy)$. Symmetric zero-sum games are ubiquitous in the literature and in practical scenarios alike.}
\end{definition}
The study of symmetric equilibria has a long history in the development of game theory, propelled by Nash's pathbreaking PhD thesis~\citep{Nash50:Non} (\emph{cf.}~\citet{Gale51:Symmetric}), and has remained a popular research topic ever since~\citep{Tewolde25:Computing,Emmons22:For,Garg18:Existential,ghosh2024complexitysymmetricbimatrixgames,Mehta14:Constant}. It is not hard to see that symmetric min-max optimization problems, in the sense of~\Cref{def:symmetric}, always admit \emph{symmetric} first-order Nash equilibria (\Cref{lem:exists}). What is more, we show that computing such a symmetric equilibrium is in the complexity class \PPAD~\citep{Papadimitriou94:Complexity}; this is based on an argument of~\citet{Etessami10:On}, and complements~\citet{DSZ21}, who proved that the problem of computing approximate fixed points of gradient descent/ascent---which they refer to as \textsc{GDAFixedPoint}---lies in \PPAD. In a celebrated series of work, it was shown that $\PPAD$ captures the complexity of computing Nash equilibria in finite games~\citep{Daskalakis09:The,Chen09:Settling}. In this context, we establish that $\PPAD$ also characterizes the complexity of computing symmetric first-order Nash equilibria in symmetric min-max optimization problems:

\begin{theorem}
    \label{theorem:main}
    Computing a symmetric $\nicefrac{1}{n^c}$-approximate first-order Nash equilibrium in symmetric $n$-dimensional min-max optimization is \PPAD-complete for any constant $c > 0$.
\end{theorem}

Barring major complexity breakthroughs, \Cref{theorem:main} precludes the existence of algorithms with complexity polynomial in the dimension and $1/\epsilon$, where $\epsilon > 0$ measures the precision (per\\~\Cref{def:FONE}), under the symmetry constraint of~\Cref{def:symmetric}. This stands in contrast to (nonconvex) minimization problems, wherein gradient descent converges to stationary points at a rate of $\poly(1/\epsilon)$; even in the regime where $\epsilon = 1/\exp(n)$, computing a stationary point of a smooth function is in~$\CLS$~\citep{Daskalakis11:Continuous}, which is a subclass of \PPAD~\citep{Fearnley23:Complexity}. In fact, our reduction also rules out the existence of polynomial-time algorithms even when $\epsilon = \Theta(1)$ under some well-believed complexity assumptions (\Cref{cor:constant}).

The proof of~\Cref{theorem:main} is elementary, and is based on the \PPAD-hardness of computing \emph{symmetric} Nash equilibria in \emph{symmetric} two-player games. Importantly, our reduction gives an immediate, and significantly simpler, proof (\Cref{thm:simple}) of the \PPAD-hardness result of~\citet{DSZ21}, while being applicable even with respect to quadratic and anti-symmetric functions defined on a product of simplexes. (Independently, \citet{Bernasconi24:Role} also considerably simplified the proof of~\citet{DSZ21}, although our approach here is to a large extent different.) The basic idea of our proof is that one can enforce the symmetry constraint of~\Cref{theorem:main} via a coupled constraint set.

Furthermore, as a byproduct of~\Cref{theorem:main}, it follows that any \emph{symmetric} dynamics---whereby both players follow the same online algorithm, as formalized in~\Cref{def:sym-dynamics}---cannot converge to a first-order Nash equilibrium in polynomial time, subject to $\PPAD \neq \P$ (\Cref{theorem:sym-dyn}). This already captures many natural dynamics for which prior papers in the literature (\emph{e.g.},~\citet{kalogiannis2021teamwork}) have painstakingly shown lack of convergence; \Cref{theorem:sym-dyn} provides a complexity-theoretic justification for such prior results, while precluding at the same time a much broader family of algorithms.

\paragraph{The complexity of non-symmetric equilibria} Remaining on symmetric min-max optimization, one natural question arising from~\Cref{theorem:main} concerns the complexity of \emph{non-symmetric} equilibria---defined as having distance at least $\delta > 0$. Unlike their symmetric counterparts, non-symmetric first-order Nash equilibria are not guaranteed to exist. In fact, we establish the following result.

\begin{restatable}{theorem}{nonsymmetric}
    \label{theorem:non-symmetric}
    For a symmetric min-max optimization problem, constants $c_1, c_2 > 0$, and $\epsilon = n^{-c_1}$, it is \NP-hard to distinguish between the following two cases:
    \begin{itemize}[noitemsep,topsep=0pt]
        \item any $\epsilon$-first-order Nash equilibrium $(\vx^*, \vy^*)$ satisfies $ \|\vx^* - \vy^* \| \leq n^{-c_2}$, and
        \item there is an $\epsilon$-first-order Nash equilibrium $(\vx^*, \vy^*)$ such that $ \|\vx^* - \vy^*\| \geq \Omega(1)$.
    \end{itemize}
\end{restatable}

\noindent The main technical piece, which is also the basis for~\Cref{theorem:uniqueATG} discussed earlier, is~\Cref{theorem:symmetric-new}, which concerns symmetric, identical-interest, two-player games. It significantly refines the hardness result of~\citet{MCLENNAN2010683} by accounting even for $\poly(1/n)$-Nash equilibria.

\paragraph{Team zero-sum games} Finally, building on the reduction of~\Cref{theorem:main} coupled with the gadget behind~\Cref{theorem:cls-completeness}, we establish similar complexity results for team zero-sum games, which generalize adversarial team games by allowing the presence of multiple adversaries. 
In particular, a \emph{symmetric} two-team zero-sum game and a \emph{symmetric} equilibrium thereof are in accordance with~\Cref{def:symmetric}---no symmetry constraints are imposed within the same team, but only across teams. We obtain a result significantly refining~\Cref{theorem:main}.

\begin{restatable}{theorem}{teamhard}
    \label{theorem:team-hard}
    Computing a symmetric $\nicefrac{1}{n^c}$-Nash equilibrium in symmetric, $6$-player ($3$ vs. $3$) team zero-sum polymatrix games is \PPAD-complete for some constant $c>0$.
\end{restatable}

Unlike our reduction in~\Cref{theorem:main} that comprises quadratic terms, the crux in team zero-sum games is that one needs to employ solely multilinear terms. The basic idea is to again use the gadget underpinning~\Cref{theorem:cls-completeness}, which enforces symmetry without affecting the equilibria of the game, thereby (approximately) reproducing the objective function that establishes~\Cref{theorem:main}.

It is interesting to note that the class of polymatrix games we construct to prove~\Cref{theorem:team-hard} belongs to a certain family introduced by~\citet{Cai11:Minmax}: one can partition the players into $2$ groups, so that any pairwise interaction between players of the same group is a coordination game, whereas any pairwise interaction across groups is a zero-sum game. \citet{Cai11:Minmax} showed that computing a Nash equilibrium is \PPAD-hard in the more general case where there are $3$ groups of players. While the complexity of that problem under $2$ groups remains wide open, \Cref{theorem:team-hard} shows \PPAD-hardness for computing \emph{symmetric} Nash equilibria in such games.

Taken together, our results bring us closer to characterizing the complexity of computing equilibria in min-max optimization.

\subsection{Further related work}

Adversarial team games have been the subject of much research tracing back to the influential work of~\citet{Stengel97:Team}, who introduced the concept of a \emph{team maxmin equilibrium (TME)}; a TME can be viewed as the best Nash equilibrium for the team. Notwithstanding its intrinsic appeal, it turns out that computing a TME is \FNP-hard~\citep{Borgs10:The}. Indeed, unlike two-player zero-sum games, team zero-sum games generally exhibit a \emph{duality gap}---characterized in the work of~\citet{schulman2017duality}.

This realization has shifted the focus of contemporary research to exploring more permissive solution concepts. One popular such relaxation is \emph{TMECor}, which enables team players to \emph{ex ante} correlate their strategies~\citep{Zhang23:Team,Zhang21:Computing,Basilico17:Team,Carminati22:A,Farina18:Ex,Zhang20:Converging,Celli18:Computational}. Yet, in the context of extensive-form games, computing a TMECor remains intractable; \citet{Zhang23:Team} provided an exact characterization of its complexity. Team zero-sum games can be thought of as two-player zero-sum games but with \emph{imperfect recall}, and many natural problems immediately become hard without perfect recall (\emph{e.g.}, \citet{Tewolde23:Computational}). Parameterized algorithms have been developed for computing a TMECor based on some natural measure of shared information~\citep{Zhang23:Team,Carminati22:A}. Beyond adversarial team games, \citet{Carminati23:Hidden} recently explored \emph{hidden-role} games, wherein there is uncertainty regarding which players belong in the same team, a feature that often manifests itself in popular recreational games---and used certain cryptographic primitives to solve them.

In contrast, this paper focuses on the usual Nash equilibrium concept, being thereby orthogonal to the above line of work. One drawback of Nash equilibria in adversarial team games is that the (worst-case) value of the team can be significantly smaller compared to TME~\citep{Basilico17:Team}. On the other hand, \citet{Anagnostides23:Algorithms} showed that $\epsilon$-Nash equilibria in adversarial team games admit an $\FPTAS$, which stands in stark contrast to TME, and indeed, Nash equilibria in general games~\citep{Daskalakis09:The,Chen09:Settling}. This was further strengthened by~\citet{kalogiannis2022efficiently,Kalogiannis24:Learning} for computing $\epsilon$-Nash equilibria in adversarial team \emph{Markov} games---the natural generalization to Markov (aka. stochastic) games.

Related to~\Cref{def:FONE} is the natural notion of a \emph{local} min-max equilibrium~\citep{DP18, DSZ21}. It is easy to see that any local min-max equilibrium---with respect to a sufficiently large neighborhood of $(\vx^*, \vy^*)$---must satisfy~\Cref{def:FONE}~\citep{DSZ21}. Unlike first-order Nash equilibria, local min-max equilibria are not guaranteed to exist.

Finally, another related work we should mention is \cite{mehta2015settling}, where it was shown that in two-player symmetric games, deciding whether a non-symmetric Nash equilibrium exists or not is \NP-hard. 
%The results we can prove
%\begin{enumerate}
%\item The problem of getting a symmetric $\epsilon$-first-order  in a non-convex non-concave symmetric smooth function $f$ is PPAD-complete for $\epsilon$ being $1/n^c$ for some constant $c$ where $n$ is the dimension of $\calX$.
%\item The problem of getting a symmetric NE in a two team symmetric polymatrix game is PPAD-complete.
%\item The problem of getting a %NE in a 2 vs 1 team is CLS-complete.
%\end{enumerate}
