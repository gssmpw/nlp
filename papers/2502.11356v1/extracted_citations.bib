@article{arditi2024refusal,
  title={Refusal in Language Models Is Mediated by a Single Direction},
  author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
  journal={arXiv preprint arXiv:2406.11717},
  year={2024}
}

@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@inproceedings{burns2023discovering,
  title={Discovering Latent Knowledge in Language Models Without Supervision},
  author={Burns, Colin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{chung2024scaling,
  author  = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  title   = {Scaling Instruction-Finetuned Language Models},
  journal = {Journal of Machine Learning Research (JMLR)},
  year    = {2024},
  volume  = {25},
  number  = {70},
  pages   = {1--53},
  url     = {http://jmlr.org/papers/v25/23-0870.html}
}

@inproceedings{ferrando2025do,
title={Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models},
author={Javier Ferrando and Oscar Balcells Obeso and Senthooran Rajamanoharan and Neel Nanda},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=WCRQFlji2q}
}

@article{gao_scaling_2024,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}

@article{he2024llama,
  title={Llama scope: Extracting millions of features from llama-3.1-8b with sparse autoencoders},
  author={He, Zhengfu and Shu, Wentao and Ge, Xuyang and Chen, Lingjie and Wang, Junxuan and Zhou, Yunhua and Liu, Frances and Guo, Qipeng and Huang, Xuanjing and Wu, Zuxuan and others},
  journal={arXiv preprint arXiv:2410.20526},
  year={2024}
}

@article{hewitt2024instruction,
  title={Instruction following without instruction tuning},
  author={Hewitt, John and Liu, Nelson F and Liang, Percy and Manning, Christopher D},
  journal={arXiv preprint arXiv:2409.14254},
  year={2024}
}

@inproceedings{jorgensen2024improving,
  title={Improving Activation Steering in Language Models with Mean-Centring},
  author={Jorgensen, Ole and Cope, Dylan and Schoots, Nandi and Shanahan, Murray},
  booktitle={Responsible Language Models Workshop at AAAI-24},
  year={2024}
}

@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}

@inproceedings{kissane2024interpreting,
  title={Interpreting Attention Layer Outputs with Sparse Autoencoders},
  author={Kissane, Connor and Krzyzanowski, Robert and Bloom, Joseph Isaac and Conmy, Arthur and Nanda, Neel},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
    year={2024}
}

@inproceedings{kung2023models,
  title={Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning},
  author={Kung, Po-Nien and Peng, Nanyun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={1317--1328},
  year={2023}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{li2024measuring,
  title={Measuring and Controlling Persona Drift in Language Model Dialogs},
  author={Li, Kenneth and Liu, Tianle and Bashkansky, Naomi and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2402.10962},
  year={2024}
}

@article{lieberum2024gemma,
  title={Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2408.05147},
  year={2024}
}

@inproceedings{liu2023instruction,
  title={Instruction position matters in sequence generation with large language models},
  author={Liu, Yijin and Zeng, Xianfeng and Meng, Fandong and Zhou, Jie},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  year={2024}
}

@inproceedings{marks2023geometry,
  title={The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
  author={Marks, Samuel and Tegmark, Max},
  booktitle={Conference on Language Modeling},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{rimsky2024steering,
    title = "Steering Llama 2 via Contrastive Activation Addition",
    author = "Rimsky, Nina  and
      Gabrieli, Nick  and
      Schulz, Julian  and
      Tong, Meg  and
      Hubinger, Evan  and
      Turner, Alexander",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024"
}

@inproceedings{sanh2022multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@misc{sharkey2022sae,
    title={Taking features out of superposition with sparse autoencoders},
    author={Sharkey, Lee and Braun, Dan and Millidge, Beren},
    url={https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/inter im-research-report-taking-features-out-of-superposition},
    year={2022}
}

@inproceedings{sun2023evaluating,
    title = "Evaluating Large Language Models on Controlled Generation Tasks",
    author = "Sun, Jiao  and
      Tian, Yufei  and
      Zhou, Wangchunshu  and
      Xu, Nan  and
      Hu, Qian  and
      Gupta, Rahul  and
      Wieting, John  and
      Peng, Nanyun  and
      Ma, Xuezhe",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.190/",
    doi = "10.18653/v1/2023.emnlp-main.190",
    pages = "3155--3168",
}

@misc{tigges2023linear,
      title={Linear Representations of Sentiment in Large Language Models}, 
      author={Curt Tigges and Oskar John Hollinsworth and Atticus Geiger and Neel Nanda},
      year={2023},
      eprint={2310.15154},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.15154}, 
}

@misc{turner2023activation,
      title={Steering Language Models With Activation Engineering}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10248}, 
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{zou2023representation,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01405}, 
}

