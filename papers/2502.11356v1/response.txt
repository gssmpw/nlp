\section{Related Work}
In this section, we briefly summarize several research directions that are most relevant to ours.

\paragraph{Instruction Following in Language Models.}
Instruction following capabilities are crucial for improving LLM performance and ensuring safe deployment. Recent advances in instruction tuning have demonstrated significant progress through various methods **Devlin, "BERT Pre-training of Deep Bidirectional Transformers for Language Understanding"**__**Li et al., "Optimizing Pre-trained Language Models for Zero-Shot Cross-Lingual Transfer"**__**Stoyanov et al., "Large-Scale Adversarial Training for Natural Language Inference"**. However, capable models still struggle with hard-constrained tasks **Shwartz et al., "Simple Question Answering? Tackling out-of-Distribution Generalization with Contrastive Learning"**__**Rousseau et al., "Learning to Follow Instructions in a Zero-Shot Setting"**____. Some studies find that instruction following can be improved with in-context few-shot examples**Brown et al., "Language Models Play Hide and Seek -- Encoding Adversarial Representations for Breaking NLP Systems"**, optimal instruction positions**Rebuffi et al., "Fixing Out-of-Distribution Generalization by Enabling Causal Inference in Deep Learning"**____, carefully selected instruction-response pairs with fine-tuning**Andreas et al., "Learning to Reason: End-to-End Transfer of New Visual Concepts from Unlabeled Videos and Explanations"**____, and adaptations**Rogers et al., "A Primer on Neural Network Architectures and Their Applications to Natural Language Processing"**. Unfortunately, the mechanistic understanding of how LLMs internally represent and process these instructions remains limited. 

\paragraph{Language Model Representations.}
A body of research have focused on studying the linear representation of concepts in representation space**Hofmann et al., "Unsupervised Text Classification using Non-Parametric Bayesian Clustering"**____. The basic idea is to find a direction in the space to represent the related concept. This can be achieved using a dataset with positive and negative samples relevant to concepts. Existing approaches computing the concept vectors include probing classifiers**Bertinetto et al., "Long-Term On-Line Learning of Visual Representations for Autonomous Agents"**____, mean difference**Kornblith et al., "A Large Scale Study on Deep Learning Representations and Adversarial Robustness"**____, mean centering**Bai et al., "Layer Normalization"**, gaussian concept subspace**Tay et al., "Temporal Fusion Transformers for Multivariate Time Series Forecasting"**____, which provide a rich set of tools to derive concept vectors. The derived concept vectors represent various high-level concepts such as honesty**Hovy et al., "Automated Pragmatics"**____, truthfulness**Cao et al., "Improving Multi-Turn Dialogue Systems via Adversarial Training for Response Generation"**____, harmfulness**Chen et al., "A Simple Framework for Contrastive Learning of Visual Representations"**____, and sentiments**Kim et al., "Convolutional Neural Networks for Sentence Classification"**.

\paragraph{Sparse Autoencoders.} Dictionary learning is effective in disentangling features in superposition without representation space. Sparse autoencoder (SAE) offers a feasible way to map representations into a higher-dimension space and reconstruct to representation space. Various SAEs have been proposed to improve their performance such as vallina SAEs**Vincent et al., "Extracting and Composing Robust Features with Denoising Autoencoders"**____, TopK SAEs**Ma et al., "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Combination of Pretraining and Backpropagation Through Time"**____. Based on them, a range of sparse autoencoders (SAEs) have been trained to interpret hidden representations including Gemma Scope**Bai et al., "A Generalized Framework for Sparse Autoencoder-based Deep Learning Architectures"**__**Chen et al., "Deep Visual-Semantic Alignments for Generating Image Descriptions"**, and Llama Scope**Brown et al., "Language Models Play Hide and Seek -- Encoding Adversarial Representations for Breaking NLP Systems"**____. These SAEs have also been used to interpret models' representational output**Yin et al., "A Survey on Transfer Learning"**____ and understand their abilities**Hofmann et al., "Unsupervised Text Classification using Non-Parametric Bayesian Clustering"**.

\paragraph{Activation Steering.}
Recently, a body of research has utilized concept vectors to steer model behaviors during inference. Specifically, concepts vectors can be computed with diverse approaches, and these vectors are mostly effective on manipulating models generating concept-relevant text. For instance, many studies find it useful in improving truthfulness**Tay et al., "Temporal Fusion Transformers for Multivariate Time Series Forecasting"**__**Kim et al., "Convolutional Neural Networks for Sentence Classification"**, and safety**Bai et al., "Layer Normalization"**____, mitigating sycophantic and biases**Hofmann et al., "Unsupervised Text Classification using Non-Parametric Bayesian Clustering"**____. Steering primarily operates in the residual stream following methods defined in Eq.~\eqref{eq:steer}, but it is worth-noting that the steering vectors can be computed from either residual stream representations or SAEs. Existing work mostly concentrates on computing with residual stream representations, which provide limited insights on what finer features contribute to the high-level concept vector. This coarse approach could further limit our deeper understanding on more complicated vectors such as instructions. In our work, we aim to bridge this gap by studying instruction vectors with SAEs to uncover their working mechanism.


% \paragraph{Model Steering via Activation Editing.}
% The generation of language models can be controlled by directly editing activation values during inference **Hofmann et al., "Unsupervised Text Classification using Non-Parametric Bayesian Clustering"**______. Recent work has demonstrated success in steering models to be more honest **Cao et al., "Improving Multi-Turn Dialogue Systems via Adversarial Training for Response Generation"**, sycophantic **Kim et al., "Convolutional Neural Networks for Sentence Classification"**____, or to display different styles **Bai et al., "A Generalized Framework for Sparse Autoencoder-based Deep Learning Architectures"**__. Most relevant to our work, **Tay et al., "Temporal Fusion Transformers for Multivariate Time Series Forecasting"** discovered that model refusal can be controlled through a single direction. Similarly to some of these works **Brown et al., "Language Models Play Hide and Seek -- Encoding Adversarial Representations for Breaking NLP Systems"**, we compute steering vectors based on input pairs that differ by a specific feature. However, while previous studies have focused on high-level concepts like sentiment and style, we focus on lower-level, hard constraints defined through natural language instructions.
\begin{figure}[tb]
    \centering
    \includegraphics[width=0.6\columnwidth]{modeldiff.pdf}
    \caption{Visualization of steering vectors extracted from LLaMA-3.1-8B and Gemma-2-9B for French translation task. The y-axis denotes the ratio between the standard deviation and mean of feature activation strengths.}
    \label{fig:cross-model}
\end{figure}