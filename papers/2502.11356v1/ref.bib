% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning (ICML)},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={27730--27744},
  year={2022}
}


@inproceedings{
wei2022finetuned,
title={Finetuned Language Models are Zero-Shot Learners},
author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
booktitle={International Conference on Learning Representations (ICLR)},
year={2022},
url={https://openreview.net/forum?id=gEZrGCozdqR}
}







@article{chung2024scaling,
  author  = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  title   = {Scaling Instruction-Finetuned Language Models},
  journal = {Journal of Machine Learning Research (JMLR)},
  year    = {2024},
  volume  = {25},
  number  = {70},
  pages   = {1--53},
  url     = {http://jmlr.org/papers/v25/23-0870.html}
}

@misc{askell2021general,
      title={A General Language Assistant as a Laboratory for Alignment}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan},
      year={2021},
      eprint={2112.00861},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.00861}, 
}

@inproceedings{sun2023evaluating,
    title = "Evaluating Large Language Models on Controlled Generation Tasks",
    author = "Sun, Jiao  and
      Tian, Yufei  and
      Zhou, Wangchunshu  and
      Xu, Nan  and
      Hu, Qian  and
      Gupta, Rahul  and
      Wieting, John  and
      Peng, Nanyun  and
      Ma, Xuezhe",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.190/",
    doi = "10.18653/v1/2023.emnlp-main.190",
    pages = "3155--3168",
}

@article{li2024measuring,
  title={Measuring and Controlling Persona Drift in Language Model Dialogs},
  author={Li, Kenneth and Liu, Tianle and Bashkansky, Naomi and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2402.10962},
  year={2024}
}

@inproceedings{hendel2023context,
    title = "In-Context Learning Creates Task Vectors",
    author = "Hendel, Roee  and
      Geva, Mor  and
      Globerson, Amir",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.624/",
    doi = "10.18653/v1/2023.findings-emnlp.624",
    pages = "9318--9333",
}

@misc{zou2023representation,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01405}, 
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}


@inproceedings{
dathathri2020plug,
title={Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
booktitle={International Conference on Learning Representations (ICLR)},
year={2020},
url={https://openreview.net/forum?id=H1edEyBKDS}
}



@misc{ilharco2023editing,
      title={Editing Models with Task Arithmetic}, 
      author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
      year={2023},
      eprint={2212.04089},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.04089}, 
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{tigges2023linear,
      title={Linear Representations of Sentiment in Large Language Models}, 
      author={Curt Tigges and Oskar John Hollinsworth and Atticus Geiger and Neel Nanda},
      year={2023},
      eprint={2310.15154},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.15154}, 
}

@inproceedings{gottesman2024estimating,
    title = "Estimating Knowledge in Large Language Models Without Generating a Single Token",
    author = "Gottesman, Daniela  and
      Geva, Mor",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.232/",
    doi = "10.18653/v1/2024.emnlp-main.232",
    pages = "3994--4019"
}

@conference{yuksekgonul2024attention,
title = "ATTENTION SATISFIES: A CONSTRAINT-SATISFACTION LENS ON FACTUAL ERRORS OF LANGUAGE MODELS",
author = "Mert Yuksekgonul and Varun Chandrasekaran and Erik Jones and Suriya Gunasekar and Ranjita Naik and Hamid Palangi and Ece Kamar and Besmira Nushi",
note = "Publisher Copyright: {\textcopyright} 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.; 12th International Conference on Learning Representations, ICLR 2024 ; Conference date: 07-05-2024 Through 11-05-2024",
year = "2024",
language = "English (US)",
}

@inproceedings{sanh2022multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{wang2022super,
    title = "Super-{N}atural{I}nstructions: Generalization via Declarative Instructions on 1600+ {NLP} Tasks",
    author = "Wang, Yizhong  and
      Mishra, Swaroop  and
      Alipoormolabashi, Pegah  and
      Kordi, Yeganeh  and
      Mirzaei, Amirreza  and
      Naik, Atharva  and
      Ashok, Arjun  and
      Dhanasekaran, Arut Selvan  and
      Arunkumar, Anjana  and
      Stap, David  and
      Pathak, Eshaan  and
      Karamanolakis, Giannis  and
      Lai, Haizhi  and
      Purohit, Ishan  and
      Mondal, Ishani  and
      Anderson, Jacob  and
      Kuznia, Kirby  and
      Doshi, Krima  and
      Pal, Kuntal Kumar  and
      Patel, Maitreya  and
      Moradshahi, Mehrad  and
      Parmar, Mihir  and
      Purohit, Mirali  and
      Varshney, Neeraj  and
      Kaza, Phani Rohitha  and
      Verma, Pulkit  and
      Puri, Ravsehaj Singh  and
      Karia, Rushang  and
      Doshi, Savan  and
      Sampat, Shailaja Keyur  and
      Mishra, Siddhartha  and
      Reddy A, Sujan  and
      Patro, Sumanta  and
      Dixit, Tanay  and
      Shen, Xudong",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.340/",
    doi = "10.18653/v1/2022.emnlp-main.340",
    pages = "5085--5109",
}

@inproceedings{gupta2022instructdial,
    title = "{I}nstruct{D}ial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning",
    author = "Gupta, Prakhar  and
      Jiao, Cathy  and
      Yeh, Yi-Ting  and
      Mehri, Shikib  and
      Eskenazi, Maxine  and
      Bigham, Jeffrey",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.33/",
    doi = "10.18653/v1/2022.emnlp-main.33",
    pages = "505--525",
}

@inproceedings{rimsky2024steering,
    title = "Steering Llama 2 via Contrastive Activation Addition",
    author = "Rimsky, Nina  and
      Gabrieli, Nick  and
      Schulz, Julian  and
      Tong, Meg  and
      Hubinger, Evan  and
      Turner, Alexander",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024"
}

@misc{turner2023activation,
      title={Steering Language Models With Activation Engineering}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10248}, 
}

@article{arditi2024refusal,
  title={Refusal in Language Models Is Mediated by a Single Direction},
  author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
  journal={arXiv preprint arXiv:2406.11717},
  year={2024}
}

@inproceedings{burns2023discovering,
  title={Discovering Latent Knowledge in Language Models Without Supervision},
  author={Burns, Colin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{olshausen1997sparse,
title = {Sparse coding with an overcomplete basis set: A strategy employed by V1?},
journal = {Vision Research},
volume = {37},
number = {23},
pages = {3311-3325},
year = {1997},
issn = {0042-6989},
doi = {https://doi.org/10.1016/S0042-6989(97)00169-7},
url = {https://www.sciencedirect.com/science/article/pii/S0042698997001697},
author = {Bruno A. Olshausen and David J. Field},
keywords = {Coding, V1, Gabor-wavelet, Natural images},
}

@article{wang2023towards,
  title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
  author={Wang, Eric and Askell, Amanda and Hadfield-Menell, Dylan and Singh, Pranav and Drain, Dawn and Ganguli, Deep and Li, Michael and Landgren, Evan and Tran-Johnson, Erol and McCracken, Chris and Askell, Nicholas Joseph and Grosse, Roger and Liang, Percy and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2308.10652},
  year={2023}
}

@inproceedings{huben2024interpretable,
  title={Sparse Autoencoders Find Highly Interpretable Features in Language Models},
  author={Huben, Robert and Cunningham, Hoagy and Smith, Logan Riggs and Ewart, Aidan and Sharkey, Lee},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{park2024linear,
  title={The Linear Representation Hypothesis and the Geometry of Large Language Models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={39643--39666},
  year={2024},
  editor={Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume={235},
  series={Proceedings of Machine Learning Research},
  publisher={PMLR},
}

@article{elhage2022mathematical,
  title={A Mathematical Framework for Transformer Circuits},
  author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Hume, Tom and Jackson, Nick and Newman, Steven and Askell, Amanda and Bai, Yuntao and Chen, David and Drain, Dawn and Ganguli, Deep and Jones, Zac and Joseph, Nicholas and Mann, Ben and Anil, Rishi and Barreto, Gabriel and Chen, Jack and Kernion, John and Lovitt, Liane and Telleen-Lawton, Thomas and Tristan, Tom and Tran-Johnson, Erol and Zhang, Andy and Askell, Nicholas Joseph and Chen, Paul and Li, Michael and Lanham, Max and Tifrea, Alexandru and Grosse, Roger and Hendrycks, Dan and Hubinger, Evan and Shlegeris, Buck and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2312.03419},
  year={2023}
}

@inproceedings{engels2025not,
  title={Not All Language Model Features Are Linear},
  author={Engels, Joshua and Michaud, Eric J and Liao, Isaac and Gurnee, Wes and Tegmark, Max},
  booktitle={International Conference on Learning Representations},
  year={2025}
}

@inproceedings{ravfogel2020null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.647/",
    doi = "10.18653/v1/2020.acl-main.647",
    pages = "7237--7256",
}

@inproceedings{belrose2023leace,
author = {Belrose, Nora and Schneider-Joseph, David and Ravfogel, Shauli and Cotterell, Ryan and Raff, Edward and Biderman, Stella},
title = {LEACE: perfect linear concept erasure in closed form},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {2884},
numpages = {20},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@InProceedings{conneau2018xnli, author = "Conneau, Alexis and Rinott, Ruty and Lample, Guillaume and Williams, Adina and Bowman, Samuel R. and Schwenk, Holger and Stoyanov, Veselin", title = "XNLI: Evaluating Cross-lingual Sentence Representations", booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing", year = "2018", publisher = "Association for Computational Linguistics", location = "Brussels, Belgium", }

@inproceedings{liu2023instruction,
  title={Instruction position matters in sequence generation with large language models},
  author={Liu, Yijin and Zeng, Xianfeng and Meng, Fandong and Zhou, Jie},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  year={2024}
}
@article{stolfo2024improving,
  title={Improving instruction-following in language models through activation steering},
  author={Stolfo, Alessandro and Balachandran, Vidhisha and Yousefi, Safoora and Horvitz, Eric and Nushi, Besmira},
  journal={arXiv preprint arXiv:2410.12877},
  year={2024}
}
@article{cunningham2023sparse,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  journal={arXiv preprint arXiv:2309.08600},
  year={2023}
}
@misc{sharkey2022sae,
    title={Taking features out of superposition with sparse autoencoders},
    author={Sharkey, Lee and Braun, Dan and Millidge, Beren},
    url={https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/inter im-research-report-taking-features-out-of-superposition},
    year={2022}
}
@article{he2024llama,
  title={Llama scope: Extracting millions of features from llama-3.1-8b with sparse autoencoders},
  author={He, Zhengfu and Shu, Wentao and Ge, Xuyang and Chen, Lingjie and Wang, Junxuan and Zhou, Yunhua and Liu, Frances and Guo, Qipeng and Huang, Xuanjing and Wu, Zuxuan and others},
  journal={arXiv preprint arXiv:2410.20526},
  year={2024}
}
@article{lieberum2024gemma,
  title={Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2408.05147},
  year={2024}
}
@misc{neuronpedia,
    title = {Neuronpedia: Interactive Reference and Tooling for Analyzing Neural Networks},
    year = {2023},
    note = {Software available from neuronpedia.org},
    url = {https://www.neuronpedia.org},
    author = {Lin, Johnny}
}
@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}
@misc{rajamanoharan2024jumpingaheadimprovingreconstruction,
      title={Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders}, 
      author={Senthooran Rajamanoharan and Tom Lieberum and Nicolas Sonnerat and Arthur Conmy and Vikrant Varma and János Kramár and Neel Nanda},
      year={2024},
      eprint={2407.14435},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.14435}, 
}
@inproceedings{ferrando2025do,
title={Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models},
author={Javier Ferrando and Oscar Balcells Obeso and Senthooran Rajamanoharan and Neel Nanda},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=WCRQFlji2q}
}
@inproceedings{kung2023models,
  title={Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning},
  author={Kung, Po-Nien and Peng, Nanyun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={1317--1328},
  year={2023}
}
@article{hewitt2024instruction,
  title={Instruction following without instruction tuning},
  author={Hewitt, John and Liu, Nelson F and Liang, Percy and Manning, Christopher D},
  journal={arXiv preprint arXiv:2409.14254},
  year={2024}
}
@inproceedings{
lin2024the,
title={The Unlocking Spell on Base {LLM}s:  Rethinking Alignment via In-Context Learning},
author={Bill Yuchen Lin and Abhilasha Ravichander and Ximing Lu and Nouha Dziri and Melanie Sclar and Khyathi Chandu and Chandra Bhagavatula and Yejin Choi},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}
@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}
@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@inproceedings{jorgensen2024improving,
  title={Improving Activation Steering in Language Models with Mean-Centring},
  author={Jorgensen, Ole and Cope, Dylan and Schoots, Nandi and Shanahan, Murray},
  booktitle={Responsible Language Models Workshop at AAAI-24},
  year={2024}
}
@inproceedings{
zhao2025beyond,
title={Beyond Single Concept Vector: Modeling Concept Subspace in {LLM}s with Gaussian Distribution},
author={Haiyan Zhao and Heng Zhao and Bo Shen and Ali Payani and Fan Yang and Mengnan Du},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=CvttyK4XzV}
}
@article{gao_scaling_2024,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}
@inproceedings{kissane2024interpreting,
  title={Interpreting Attention Layer Outputs with Sparse Autoencoders},
  author={Kissane, Connor and Krzyzanowski, Robert and Bloom, Joseph Isaac and Conmy, Arthur and Nanda, Neel},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
    year={2024}
}
@inproceedings{marks2023geometry,
  title={The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
  author={Marks, Samuel and Tegmark, Max},
  booktitle={Conference on Language Modeling},
  year={2024}
}
@article{bricken2023towards,
    title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
    author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nicholas L and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Chris},
    year={2023},
    month={Oct},
    day={4},
    publisher={Anthropic},
    url={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@inproceedings{ma2024getting,
author = {Ma, Wanqin and Yang, Chenyang and K\"{a}stner, Christian},
title = {(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for Evolving LLM APIs},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644950},
doi = {10.1145/3644815.3644950},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {166–171},
numpages = {6},
keywords = {large language models (LLM), regression testing},
location = {Lisbon, Portugal},
series = {CAIN '24}
}