\section{Related Work}
\subsection{Evolutionary Feature Engineering}

% Feature Engineering
As a step of the \gls{ML} pipeline, \gls{FE} defines the process of transforming an original dataset into a refined one. It can be partitioned into two domains: \gls{FS} and \gls{FC}. The goal of \gls{FS} is to remove redundant or misleading features that can compromise the performance of the models. In addition, \gls{FC} seeks to build new features from the original ones, providing an enhanced representation that may help \gls{ML} models, especially those that cannot create a complex internal representation or decision boundary.

% Different types of FE methods
There are three main types of \gls{FE} methods: filter, wrapper and embedded. \cite{cherrier2019consistent}. Filter methods assess the features without the use of a \gls{ML} model. In contrast, wrapper methods use the performance of such models to evaluate the set of features, which is the approach this work follows. At last, embedded methods perform \gls{FE} while training the model.

% GP approaches
Evolutionary \gls{FE} methods have been proposed over the years with \gls{GP} \cite{koza1994genetic} being the most common approach. Concerning approaches that use \gls{DT}-based proxies, \citet{tran2016multiple} proposed MultGPFC, a hybrid (filter and wrapper) framework that uses a \gls{DT} proxy and a filter distance metric. The fitness function is given by a linear combination of both approaches, with the accuracy of the \gls{DT} being the average score of a 3-fold cross-validation repeated 3 times with different data splits. The framework was applied to 6 datasets, showing that it can construct and select features that boost the performance of \gls{ML} testing models, although being more effective for a \gls{DT}. \citet{cherrier2019consistent} also followed a \gls{GP} approach to design and compare evolutionary wrapper or filter methods that construct interpretable features for three experimental physics datasets. Among the methods, the 3-fold cross-validation accuracy of a \gls{DT} and \gls{XGB} models were used to evaluate the individuals, in different experiments. Whether evolving one or more features, all methods improved the baseline.

% SGE approaches
Regarding \gls{GE} \cite{ryan1998grammatical} works, \citet{miquilini2016enhancing} compared two types of \gls{DT} algorithms as proxies, namely J48 and REPTree, for evolving a single feature. The fitness of the individuals was measured in a 5-fold cross-validation setting and given by its average accuracy. Being applied to 16 datasets, both proxies produced features that empowered the corresponding models with higher performance and a smaller tree depth than the baseline, for most problems. Additionally, the work of \citet{monteiro2021fermat} proposed FERMAT, a framework that uses \gls{SGE} \cite{lourencco2016sge,lourencco2018structured}, a \gls{GE} variant, as the evolutionary engine. In this work, a \gls{DT} is used as the proxy for a \gls{RF}, the testing model. The fitness of the individuals was given by the validation Root Mean Squared Error (RMSE) of the proxy. It was applied to two regression problems, having success in selecting and constructing new features that helped regression models achieve better predictions.


\subsection{Machine Learning in Hearing Loss Detection}

The current status of \gls{HL} detection by \gls{ML} models is overviewed in the work of \citet{miranda2022hytea}. Most works focus on actively detecting \gls{HL} through the results of audiology screenings or related procedures, demographics, medical data and noise exposure metrics. These features generally match with the ones highlighted by the \gls{WHO} as relevant \gls{HL} causes. Frequently, studies on \gls{HL} detection focus on specific categories or origins of \gls{HL}, such as sensorineural or noise-induced causes, as well as environments where \gls{HL} is prevalent, such as industrial settings \cite{tomiazzi2019performance}. 

Results show that with screening or similar information, \gls{ML} models can achieve accuracy values above 70\%, depending on the data and model used. However, when aiming to guide screening towards people at risk, it is expensive to perform a screening procedure across the whole population. Therefore, models that rely solely on personal, medical, and demographic factors to predict the likelihood of \gls{HL}, in the absence of screening data, could be valuable for discerning which contextual factors have a greater impact on \gls{HL}.

 