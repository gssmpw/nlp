\section{Introduction}
\glsresetall
The advances in our digital world have brought us large amounts of data that can be used to extract domain-specific knowledge. One such domain is the medical field, where data is used to help professionals better decide through its analysis, visualization and usage in decision support systems.

The medical field encompasses a broad range of disciplines, including audiology. As a specialized branch within the medical field, it focuses on studying hearing, balance, and associated disorders. In February 2024, the \gls{WHO} reiterates its prediction that by 2050, 2.5 billion people will have \gls{HL}, with 1 in 10 requiring rehabilitation \cite{whohl}. This condition can negatively impact a person's life, either professionally or personally.

As such, audiology technicians are conducting screenings to assess the hearing health of the population, while collecting data that can help guide the screening towards people at risk, through intelligent models.

This can be achieved by \gls{ML} models that provide a wide range of methods to detect and predict patterns. One key aspect of properly modelling them is defining the data representation that is given as input. \gls{FE} is a step in the \gls{ML} pipeline dedicated to transforming data to suit the requirements of these models. Despite existing methods to address this problem, evolutionary methods have demonstrated their utility for selecting and constructing novel features.

This work aims to benchmark an evolutionary \gls{FE} wrapper, using models based on decision trees as proxies. The FEDORA framework will be applied to a \gls{HL} classification dataset, in three different settings, varying only on the choice of the proxy, which can be a \gls{DT} or its bagging and boosting variants: \gls{RF} and \gls{XGB}, respectively.

Results confirm that FEDORA can reduce the dimensionality of the data while statistically maintaining baseline performance, in every experiment. The framework is compared with common \gls{FE} methods and consistently outperforms them, with statistical significance and large effect sizes. The best result obtained is 76.2\% balanced accuracy using an individual from the \gls{RF} proxy experiment, and a \gls{XGB} as the testing model, using 57 features that were selected or constructed from the 60 original ones. When using the least amount of features, the best result is 72.8\% balanced accuracy using an individual from the \gls{DT} proxy experiment and a \gls{RF} algorithm as the testing model, using a single feature.





