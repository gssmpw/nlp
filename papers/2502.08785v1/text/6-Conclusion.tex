\section{Conclusion}

This work analysed the results of evolutionary wrapper approaches using decision tree based models as proxies and compared them with common \gls{FE} techniques on a \gls{HL} detection problem. Three experiments were conducted using the proposed framework, each employing different proxy models.

When comparing the three experiments, an interesting behaviour of the framework was discovered, when changing the proxy model. The \gls{DT} experiment drastically reduced the number of features, while the other models did not. To further reduce the number of features, one could bias the grammar or apply some penalty in the fitness function for the individuals that use a large number of features. This might not change the behaviour when using different models other than a \gls{DT}, but it forcefully reduces the number of features.  

The results confirm that FEDORA can reduce the dimensionality of the data while statistically maintaining baseline performance, in every experiment. The framework consistently outperforms the remaining \gls{FE} methods, with statistical significance and large effect sizes, proving itself as a viable alternative.

The best result obtained is 76.2\% balanced accuracy using an individual from the \gls{RF} experiment, and a \gls{XGB} algorithm as the testing model, using 57 total features (45 Original, 6 Engineered and 6 Complex) out of the 60 original ones. When using the least amount of features, the best result is 72,8\% balanced accuracy using an individual from the \gls{DT} experiment and a \gls{RF} algorithm as the testing model, using a single complex feature.

In future work, exploring the above-mentioned behaviours might be relevant to better understanding them, namely when biasing the grammar or penalizing the use of many features in the fitness function. Concerning the explainability of the FEDORA transformations, researching meaningful grammar operators might prove useful in addressing problem-specific needs. In this case, having logical operators for the boolean features, which have values of "yes" or "no", and the choice of a simple decision algorithm as the proxy, may increase explainability. Additionally, the previous study has identified several areas for future research, yet to be addressed. For instance, comparing the framework with other common and more complex methods and completing the full \gls{ML} pipeline through the use of a method that addresses the \gls{CASH}, such as \cite{assunccao2020evolution}, and comparing it to other full pipeline frameworks, could be beneficial for contextualizing and evaluating the framework within the \gls{AutoML} and \gls{EC} domains. The framework still needs to be analysed with different datasets to properly assess its generalization capabilities.