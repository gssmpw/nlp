\section{Results and Discussion}

The evolution process will be examined from the perspectives of fitness and the number of features, considering the average values across 30 runs over the generations. This allows us to overview the evolution process from both perspectives, checking for relevant behaviours. The best individuals will be analysed via the number and construction complexity of the features they generate. This gives us insights from both \gls{FS} and \gls{FC} standpoints. The performance results of \gls{ML} classifiers, using various \gls{FE} methods, will also be visually examined and statistically analysed to check for meaningful differences.

\subsection{Using Decision Trees as Proxy}

Figure \ref{fig:DT} showcases a collection of plots depicting the results of the \gls{DT}  experiment from different perspectives. In Panel \ref{fig:DT:fitness}, the evolution of the average fitness of populations and the performance of the best individuals across 30 runs is depicted over successive generations, showing an effective minimization trend of the balanced accuracy validation error. The population line reaches an average error mark of 32\%, while the best line achieves a lower error of 29\%.

In Panel \ref{fig:DT:feature-evolution}, four distinct lines are displayed, each representing the average number of features selected by FEDORA across 30 runs. These lines correspond to the averages of the population (population), the best individual (best), and individuals with the least (minimum) and greatest (maximum) number of features. The minimum and maximum lines are roughly around both ends of the number of allowed features by the grammar. Conversely, the best and population lines have been decreasing over the generations, without any signs of stabilizing, despite having an initial increase. These two panels show that using a \gls{DT} as the proxy model induces the framework to maximise performance and reduce the number of features over the generations.

Panel \ref{fig:DT:ratios} illustrates feature ratios derived from the best individual of each run. To construct this chart, we establish criteria for classifying features produced by FEDORA individuals. A feature is named as \textit{original} if it is solely selected from the original dataset (e.g. feature1), \textit{engineered} if a single operator merges two original features (e.g. feature1 + feature2), and \textit{complex} if two or more operators are utilized (e.g. feature1 + feature2 - feature3). Also, Panel \ref{fig:DT:distribution} must be considered when interpreting this one, as it provides the total number of features for each best individual. The feature complexity ratios are normalized by these values, as shown in the equations below.
\begin{equation*}
R_{O} = \frac{N_{Selected}}{N_{Total}} \hspace{1cm} R_{E} = \frac{N_{Engineered}}{N_{Total}}\hspace{1cm} R_{C} = \frac{N_{Complex}}{N_{Total}}
\end{equation*}

Therefore, Panel \ref{fig:DT:ratios} shows that the individuals are composed of constructed and selected features since the ratio of original features and the sum of engineered and complex features ratios are both positive. Some individuals present large ratios of engineered and complex figures due to having a low number of features, as observed in Panel \ref{fig:DT:distribution}. Runs 6, 8 and 25 returned individuals without original features, only being composed of engineered or complex features. 

To compare FEDORA with the baseline and other common \gls{FE} methods, Panel \ref{fig:DT:comparison} exhibits a series of 24 boxplots associated with the testing outcomes. Each boxplot contains 30 points, representing each run individually. The value of each point corresponds to the balanced accuracy score of the respective \gls{FE} method and testing model pipeline in a particular run. When using a \gls{DT} as the testing model, the FEDORA boxplot visually improves baseline performance, while slightly deteriorating it on the other \gls{ML} models. Examining the remaining \gls{FE} techniques, most underperform the baseline and FEDORA in all testing models. When aiming for maximum performance with minimal features, run 8 returned an individual that achieves a 72.8\% balanced accuracy score with a \gls{RF} classifier, with a single complex feature. Its phenotype is shown below:
$$x_{29}-x_{22}*x_{22}+(x_{8}*x_{42}/(x_{35}*x_{9}+x_{53}))$$

\plotsummary{figures/plots_dt_200_100.pdf}{DT}

\subsection{Using Random Forests as Proxy}

Figure \ref{fig:RF} presents the same set of plots with the results of the RF experiment. In Panel \ref{fig:RF:fitness}, one can see that both lines stabilize around the 20-generation mark, with slight improvements observed in the subsequent generations, resulting in a final average validation error of 29\% for the population line and 26\% for the best line.

Panel \ref{fig:RF:feature-evolution} shows that the population and best lines exhibit simultaneous growth up to the point of reaching 50 features, with the latter slightly surpassing the former, a behaviour that contrasts with the \gls{DT} experiment. Also, the minimum and maximum lines are close to the 0 and 60 features mark, respectively.

Panel \ref{fig:RF:ratios} demonstrates that the features generated by the individuals are approximately 80\% original, 10\% engineered and 10\% complex, while mostly using less than 60 features, as shown in Panel \ref{fig:RF:distribution}. Although differently than observed in the \gls{DT} experiment, these Panels reinforce the claim that the framework can simultaneously select and construct features.

Regarding the testing results, Panel \ref{fig:RF:comparison} shows that FEDORA maintains baseline performance, despite using fewer features. It also outperforms the remaining \gls{FE} methods, which deteriorate baseline performance across all testing classifiers. The best-performing individual was obtained in run 19, with a 76.2\% balanced accuracy score, using the \gls{XGB} classifier with 57 total features (45 Original, 6 Engineered and 6 Complex). It corresponds to the best score obtained in this paper by the proposed framework.

\plotsummary{figures/plots_rf_200_100.pdf}{RF}


\subsection{Using Extreme Gradient Boosting as Proxy}

Figure \ref{fig:XGB} summarizes the obtained results of the \gls{XGB} experiment. Similarly to the RF experiment, Panel \ref{fig:XGB:fitness} shows a clear effective minimization of the error, this time achieving lower error scores with both lines stabilizing earlier, at the 10-generation mark, with the population line achieving an error of around 27\% and the best an error of roughly 25\%.

The analysis made for the Panels \ref{fig:RF:feature-evolution}, \ref{fig:RF:ratios} and \ref{fig:RF:distribution} of the RF experiment is directly applicable to the Panels \ref{fig:XGB:feature-evolution}, \ref{fig:XGB:ratios} and \ref{fig:XGB:distribution} of this experiment, i.e. FEDORA can perform \gls{FS} and \gls{FC} since the original ratio and the sum of the remaining ratios are positive, correspondingly. Although returning individuals with a slightly greater amount of features, the evolution and complexity ratios of the features in this experiment are similar to the \gls{RF} proxy experiment.

In Panel \ref{fig:XGB:comparison}, FEDORA can maintain baseline performance across all classifiers. The framework outperforms common \gls{FE} methods, especially when using the \gls{RF} and \gls{XGB} classifiers. It is possible to observe a narrow improvement over the baseline with the \gls{XGB} classifier when using the FEDORA individuals. The best-performing individual of this experiment was obtained in run 19, with a 76\% balanced accuracy score, using the \gls{XGB} classifier with 58 total features (39 Original, 13 Engineered and 6 Complex).

\plotsummary{figures/plots_xgb_200_100.pdf}{XGB}

\subsection{Statistical Analysis}
To compare the results of the different experiments, we performed a statistical analysis to check for any meaningful differences. The statistical tests were only applied to the \gls{FE} methods of one single testing classifier for each experiment, for simplicity. The chosen testing model for the statistical test is the same as the proxy of the corresponding experiment.

\setlength{\tabcolsep}{0.5em} % for the horizontal padding
{\renewcommand{\arraystretch}{1}% for the vertical padding
Without making any parametric or paired assumptions, the Kruskal-Wallis non-parametric test was applied to compare the \gls{FE} techniques, in each experiment, to check if the median scores of all the groups are equal, with a significance level of 0.05. Table \ref{table:kruskal} gives the Kruskal-Wallis test results for every experiment. As the p-value is 0 for all experiments, every experiment rejects the null hypothesis, i.e. there are differences in the medians of the groups. Therefore, a pairwise post hoc analysis is required for every pair of groups in each experiment. 

Pair-wise comparisons were made using Dunn's posthoc test and correcting the resulting p-values with the Bonferroni correction. Cliff's $\delta$ was used to measure the effect size. The symbol "$\sim$" denotes a negligible effect size ($|\delta| < 0.147$), "+" denotes a small effect size ($0.147 \le |\delta| < 0.33$), "++" a medium one ($0.33 \le |\delta| < 0.474$) and "+++" a large one ($|\delta| \ge 0.474$). 


Table \ref{table:dunn-dt_200_100} details the effect sizes for Dunn's posthoc analysis for the \gls{DT} proxy experiment. It shows statistically significant differences between FEDORA and the other \gls{FE} methods, with a large effect size. There are also differences between the baseline and the common \gls{FE} methods, with a large effect size. For this experiment, there is no evidence of differences between the baseline and the FEDORA groups, meaning that the framework can statistically maintain performance. There are statistically significant differences between the \gls{UMAP} and the \gls{ANN} based \gls{FE} methods, i.e. the \glspl{SOM} and the \glspl{AE}, both with large effect sizes.

Table \ref{table:dunn-rf_200_100} provides the effect sizes for the \gls{RF} proxy experiment. Once again, the baseline and the proposed framework have statistically significant differences with the common \gls{FE} methods. Also, the baseline and FEDORA groups do not seem to have differences. Furthermore, there are statistically significant differences between the \gls{PCA} and \gls{UMAP} groups and between the \gls{AE} and \gls{UMAP} groups, with large effect sizes. Table \ref{table:dunn-xgb_200_100} gives the effect sizes for the \gls{XGB} experiment. The statistical analysis is the same as the one made for Table \ref{table:dunn-rf_200_100} since the tables are identical.

\begin{table}[h!]
    \centering
    \caption{Kruskal-Wallis Test Results}
    \label{table:kruskal}
    \begin{tabular}{|c|c|c|c|}
        \hline
         Experiment    & Model                  &   H &   P-Value \\
        \hline
         DT  & DecisionTreeClassifier &          143.45 &         0 \\
         RF  & RandomForestClassifier &          156.48 &         0 \\
         XGB & XGBClassifier          &          145.27 &         0 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[h!]
\centering
\caption{Dunn's test effect sizes - DT}
\label{table:dunn-dt_200_100}
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
         DT       & Baseline   & FEDORA           & PCA              & UMAP             & SOM              \\
        \hline
         FEDORA   &            & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray} \\
         PCA      & +++        & +++              & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray} \\
         UMAP     & +++        & +++              &                  & \cellcolor{gray} & \cellcolor{gray} \\
         SOM      & +++        & +++              &                  & +++              & \cellcolor{gray} \\
         AE       & +++        & +++              &                  & +++              &                  \\
        \hline
    \end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Dunn's test effect sizes - RF}
\label{table:dunn-rf_200_100}
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
         RF             & Baseline         & FEDORA           & PCA              & UMAP             & SOM               \\
        \hline
         FEDORA         &                  & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray}  \\
         PCA            & +++              & +++              & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray}  \\
         UMAP           & +++              & +++              & +++              & \cellcolor{gray} & \cellcolor{gray}  \\
         SOM            & +++              & +++              &                  &                  & \cellcolor{gray}  \\
         AE             & +++              & +++              &                  & +++              &                   \\
        \hline
    \end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Dunn's test effect sizes - XGB}
\label{table:dunn-xgb_200_100}
   \begin{tabular}{|c|c|c|c|c|c|}
       \hline
        XGB         & Baseline         & FEDORA           & PCA              & UMAP             & SOM               \\
       \hline
        FEDORA      &                  & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray}  \\
        PCA         & +++              & +++              & \cellcolor{gray} & \cellcolor{gray} & \cellcolor{gray}  \\
        UMAP        & +++              & +++              & +++              & \cellcolor{gray} & \cellcolor{gray}  \\
        SOM         & +++              & +++              &                  &                  & \cellcolor{gray}  \\
        AE          & +++              & +++              &                  & +++              &                   \\
       \hline
   \end{tabular}
\end{table}
}
\subsection{Discussion}
Concerning the evolution plots, all fitness plots show that individuals are gradually evolving throughout the generations. When using a \gls{DT} model as the proxy, the best line appears to be the one with greater evolution progress, although not quite matching the lower performances of the remaining experiments.

The feature evolution plots show a different angle of evolution. The number of features of the best individuals in the \gls{DT} experiment is decreasing throughout the generations, alongside the population mean. Such an event is not noticeable in the other experiments. The exact opposite happens, i.e. the best and population lines tend to grow and stabilize, with the latter resembling a logarithmic function. By observing the number of features in the \gls{DT} experiment, it is noticeable that its individuals can achieve a much lower feature dimensionality. This experiment also shows a higher ratio of engineered and complex features, although having fewer features biasing them. For the \gls{RF} and \gls{XGB} experiments, it is possible to observe that FEDORA can simultaneously select and construct novel features since the ratio of original features and the sum of engineered and complex features ratios are positive. 

Regarding the comparison with other common \gls{FE} methods and the baseline, the comparison plots show that FEDORA is consistently above the \gls{PCA}, \gls{UMAP}, \glspl{SOM} and \glspl{AE} methods while statistically maintaining baseline performance. In the \gls{DT} experiment, FEDORA is also able to improve past the baseline values when using a \gls{DT} as the testing model, although such results are not statistically significant.

From the analysed experiments, a pattern emerges in the behaviour of FEDORA. The \gls{DT} experiment can reduce the number of features to a degree that the other proxy models cannot. When comparing the inner workings of the proxy models, the \gls{RF} and \gls{XGB} models have one thing in common that the \gls{DT} model does not: the ability to create a more complex internal representation of the given data or decision boundary, which generally translates into better performances. A \gls{DT} can only make simple decisions with the provided data, which translates into axis-parallel hyper-planes decisions in the feature space, which might not properly address a complex dataset. As such, if the evolution transformations do not provide adequate features to this model, i.e. constructed features that allow for non-linear decisions in the original feature space, the \gls{DT} will most likely have worse performance than the remaining models, when facing a hard problem. Consequently, this encourages evolution to provide well-engineered features, thus making the fitness function much more discriminant. On the other hand, the remaining models do not put this kind of pressure on the evolution process. Each model takes charge of either constructing its features internally or defining a more complex decision boundary. Therefore, evolution just gives it a solid amount of original features, so that the model can find what works best for itself, and a few suggestions in the form of engineered and complex features. Consequently, the best individuals tend to have a much higher number of features when using \gls{RF}, or \gls{XGB} models as proxies. When using these models as the proxy, aiming for individuals with a low number of features becomes a problem. As such, ways to bias the evolution may be required, namely reducing the number of features that a transformation can produce in the grammar, e.g. 1 to 10 instead of 1 to 60, or adding a fitness component that penalizes individuals with many features. The usage of different feature combining operators may also be of use. These modifications might prove themselves useful in such a task.

Given these results and considering that FEDORA and the other methods usually work with fewer features, with their main purpose being a \gls{FE} technique, effectively reducing the number of features and statistically maintaining the baseline performance are great results. From the methods used in this work, FEDORA is the only one that can almost always have this behaviour. Also, it is possible to understand the phenotype of a FEDORA individual to a certain degree, depending on the choice of the operators defined in the grammar.



