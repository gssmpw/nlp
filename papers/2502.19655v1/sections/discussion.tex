\section{Discussion of Limitations}
Our initial exploration focuses on multiple-choice question answering (MCQA), a synthetic setting within the field of medicine. While MCQA provides a controlled environment to evaluate model performance, it does not fully represent the complexity and nuance of more practical medical tasks such as open-text question answering, report generation, or even conversational interactions. These tasks often involve richer contexts and require models to handle a wider variety of inputs and outputs, which could present additional challenges not captured in our current approach. Additionally, our exploration has been confined to a unimodal framework, leaving the multimodal setting — where integrating data from sources like images, text, and structured information could enhance diagnostic and decision-making capabilities — largely unexplored. Addressing these areas in future work will be crucial for developing more robust and versatile models for real-world medical applications. 
Our initial exploration focuses on multiple-choice question answering (MCQA), a synthetic setting within the field of medicine. While MCQA provides a controlled environment to evaluate model performance, it does not fully represent the complexity and nuance of more practical medical tasks such as open-text question answering, report generation, or even conversational interactions. These tasks often involve richer contexts and require models to handle a wider variety of inputs and outputs, which could present additional challenges not captured in our current approach. Additionally, our exploration has been confined to a unimodal framework, leaving the multimodal setting — where integrating data from sources like images, text, and structured information could enhance diagnostic and decision-making capabilities — largely unexplored. Addressing these areas in future work will be crucial for developing more robust and versatile models for real-world medical applications. 