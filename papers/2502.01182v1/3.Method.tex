\section{Pivot-based Single Model Ensemble}
\label{sec:Pivot-based Single Model Ensemble}



In this section, we first introduce the overview of \ours framework (\S\ref{sec:overview}).
Then, we describe the candidate generation process through pivot translation (\S\ref{sec:pivot-based candidate generation}) and the aggregation process (\S\ref{sec:candidate aggregation}).


\subsection{Overview}
\label{sec:overview}

Our objective is the same as that of conventional translation tasks: converting the given source language sentence $x$ into the target language sentence $\hat{y}$.
\ours consists of two steps: candidate generation and candidate aggregation.
Figure~\ref{fig:overall} illustrates an overview of the proposed ensemble framework.


As the first step, we input $x$ to generate candidates through a single multilingual NMT model.
One translation path could be directly translating from the source to the target through the source$\rightarrow$target path.
Alternatively, pivot translations can be achieved by employing high-resource pivot languages, enabling translation paths from source$\rightarrow$pivot and pivot$\rightarrow$target.
During the pivot process, leveraging abundant parallel data enables knowledge transfer from high-resource pivot languages, thereby facilitating the generation of diverse and more accurate translations.
Through these $n$ paths, we can obtain a candidate pool $C = \{c_1, ..., c_n\}$ composed of $n$ candidates in the target language, employing only a single model.

As the second step, a ranking process is first conducted within the candidate pool $C$ since not all candidates contribute to the ensemble.
Using the estimated quality of each candidate, we select the top-$\textit{k}$ candidates.
We then generate the final output $\hat{y}$ using the selected high-quality candidates.
This generation-based approach facilitates the production of outputs superior to existing candidates.


\subsection{Pivot-based Candidate Generation}
\label{sec:pivot-based candidate generation}


In the first step, \ours takes a source sentence $x$ as input and generates $n$ candidates.
Direct translation yields only one candidate, whereas pivot translation enables the generation of multiple candidates from a single source sentence using a single model.
Generating candidates through pivot translation has two major advantages: diversity and quality.


First, we can obtain diverse candidates that can act complementarily.
One of the key principles for the ensemble is that the participants must be sufficiently diverse to provide various inductive biases.
In \ours, each source sentence is translated diversely by passing through multiple translation paths.
Diverse translation paths enhance the likelihood of providing expressions that convey the accurate meaning of the source sentence.
Pivot-based candidate generation shares a similar goal with a previous study that generates paraphrases through round-trip translation, aiming to generate diverse translations~\cite{thompson-post-2020-paraphrase}.


Second, by utilizing a parallel corpus of high-resource pivot languages, pivoting enables more accurate translations.
For low-resource language pairs, more appropriate translations can be achieved through two-step decoding through a pivot language~\cite{he-etal-2022-tencent}.
Moreover, leveraging pivot languages with abundant parallel data, not limited to English, allows us to obtain better translations~\cite{paul2009importance, dabre-etal-2015-leveraging}.


In addition, pivot translation with a single model offers practical benefits over employing multiple models. 
Firstly, it can reduce the costs of operating multiple models including LLMs. 
Secondly, the substantial performance disparities among models mean that using the top-performing single model for candidate generation often leads to higher-quality outcomes. 
Lastly, it reduces inference latency by using a single model for two batched inferences, while multi-model ensembles require up to 11, causing significant overhead and limiting real-time response capability.
Given that pivot translation with a single model allows for the creation of diverse and more accurate translations, we utilize an MNMT model to generate the candidates.


\minisection{Selecting pivot languages}
For each language pair, we carefully select pivot languages based on the assumption that pivot language with abundant mutual knowledge would allow us to obtain higher-quality candidates.
We select $n$ top-performing paths for our study based on BLEU scores on the FLORES-200 benchmark~\cite{nllb}.
We evaluate the outputs for each path, including direct translation and through various pivot translations.
\nllb~\cite{nllb} is used to generate candidates, and results on the FLORES-200 for selecting translation paths are in Appendix~\ref{sec:apdx_top4 pivot langauges}.
If pivot languages are selected based on BLEU scores, high-resource languages are predominantly chosen, rather than low-resource ones.
The experiments detailed in Appendix~\ref{apdx:resource level of pivot languages} demonstrate that overly prioritizing diversity by employing low-resource pivot languages, at the expense of candidate quality, does not result in improvements in the final translation.
The experiments comparing metrics for selecting translation paths are in Appendix~\ref{apdx: Metric for Selecting Translation Paths}.
As a result, we compose the candidate pool using the 4 paths.


\subsection{Candidate Aggregation}
\label{sec:candidate aggregation}


In the aggregation step, we take the candidate pool $C$ as input and output the merged final translation $\hat{y}$.
The post-hoc aggregation process encompasses two stages: selecting and merging.
In the first stage, we select candidates by ranking method.
There are two approaches for selecting candidates.
One approach evaluates each translation path and selects the best paths for all source sentences.
The other approach involves selecting the best top-$\textit{k}$ candidates for each source sentence.
After selecting $\textit{k}$ candidates, we generate the final translation $\hat{y}$ using the merging module.
This process enables the creation of better outputs beyond the quality of existing candidates.


\minisection{Selecting the top-$\textit{k}$ candidates}
The pivot language that generates the highest-quality candidate varies for each source sentence.
The best output is not guaranteed from one translation path alone, as it can vary depending on factors such as the size of the parallel corpus and the relationship between languages.
First, \ours uses QE to rank all $n$ candidates from candidate pool $C = \{c_1, ..., c_n\}$.
Afterward, we select top-$\textit{k}$ candidates among $n$ candidate pool.
Selecting the top-$\textit{k}$ candidates ensures the quality of the output by filtering out low-quality candidates while also efficiently reducing the cost during the merging process.
We use the reference-free COMETkiwi (\textit{wmt22-COMETkiwi-da}) \cite{rei2022cometkiwi} for ranking candidates.


\minisection{Generating the final translation}
To generate the final translation $\hat{y}$ by merging the top-$\textit{k}$ candidates, we explore methods from two categories: encoder-decoder ensemble architectures and LLM-based approach.
Employing encoder-decoder architectures during the merging process offers the advantage of relatively low training costs.
We conduct experiments using Fusion-in-Decoder (FiD)~\cite{fid} and TRICE~\cite{trice} architectures.
The former method involves passing 
\texttt{Translate source into <target language>}
\texttt{referring <target language> candidate.}
\texttt{source: <$x$>}
\texttt{candidate: <$c_{k}$>}
through the encoder, representations are concatenated and merged in the decoder.
The latter approach involves concatenating \texttt{<$x$></$s$><$l_{s}$>;<$c_{1}$></$s$><$l_{t}$>;...;<$c_{k}$></$s$><$l_{t}$>} with language token \texttt{<$l_{lang}$>} and providing it as input.
Encoder-decoder ensemble architectures are further described in detail in Appendix~\ref{apdx:Fid/TRICE illustration}.


On the other hand, the LLM-based ensemble implicitly leverages their translation capabilities during ensemble, as the source sentence is also provided.
We conduct merging experiments with \textsc{GenFuser}~\cite{llm-blender}, Llama-3~\cite{llama3modelcard}, and GPT models~\cite{gpt3.5, gpt4, gpt4o}. 
When employing \textsc{GenFuser}, we construct the input by concatenating top-\textit{$k$} candidates to the prompt, as presented in \citet{llm-blender}.
For merging with Llama-3 and GPT, we use the prompt template in Appendix~\ref{sec:apdx_prompt_templates}.
By leveraging a variety of candidates, each with different strengths, the aggregation process can effectively mitigate errors in a complementary manner.