\begin{table}[t]
\centering
    \caption{
\textbf{Classification with Imagenet1k training.} 
We contrast our flopping-equivariant networks to the originals using the same training recipes.
The equivariant version of architecture X is denoted $\mathcal{E}(\text{X})$.
$\mathcal{H}(\text{ViT-H})$ is a hybrid model with equivariant layers for the first half of the network.
The baselines are not rerun, instead we show the results reported in their respective papers.
The throughput and peak memory are measured on a single A100-40GB GPU with batch size fixed to 64 and compiled networks running mixed precision forward passes with no gradients. 
\label{tab:mainres}}
    \centering
    \scalebox{0.78}{
    \begin{tabular}{@{ }l@{}c@{ }c@{ }c@{ }c|c@{\ }}
        \toprule
        Architecture        & params & throughput & FLOPs/img & Peak Mem & Top-1 \\
                      & ($\times 10^6$) & (im/s) & ($\times 10^9$) & (MB)\ \ \ \  & Acc.  \\[3pt]

\toprule

 \multicolumn{6}{c}{\textbf{MLP-Mixers (ResMLP \cite{touvron2023resmlp})}} \\[3pt]
    ResMLP-L24$^1$ &  318.1 & 1107 & 63.3 & 1778  & 80.4  \\
    $\mathcal{E}(\text{ResMLP-L24})$ &  159.2 & 1756 & 31.7 & 1056  & 81.5  \\
    ResMLP-B24 &  115.7 & 2482 & 23.2 & 779  & 81.0  \\
    $\mathcal{E}(\text{ResMLP-B24})$ &  58.0 & 3459 & 11.7 & 519  & 80.8  \\
    ResMLP-S24 &  30.0 & 6445 & 6.0 & 320  & 79.4  \\
    $\mathcal{E}(\text{ResMLP-S24})$ &  15.1 & 7025 & 3.1 & 249  & 74.9  \\
    ResMLP-T12 &  15.4 & 12133 & 3.0 & 264  & 76.6  \\
    $\mathcal{E}(\text{ResMLP-T12})$ &  7.7 & 13154 & 1.6 & 221  & 72.0  \\

    \toprule
    \multicolumn{6}{c}{\textbf{Vision Transformers (DeiT III \cite{touvron2022deit3})}} \\ [3pt]

    ViT-H & 632.1  & 431 & 168.0 & 3366 & 84.6  \\
    $\mathcal{H}(\text{ViT-H})$ & 474.2  & 466 & 127.6 & 3231 & 85.0  \\
    $\mathcal{E}(\text{ViT-H})$ & 316.1  & 501 & 87.3 & 2598 & 84.4  \\
    ViT-L & 304.4  & 1064 & 61.9 & 1726 & 84.2  \\
    $\mathcal{H}(\text{ViT-L})$ & 228.3  & 1123 & 47.0 & 1743 & 84.5  \\
    $\mathcal{E}(\text{ViT-L})$ & 152.2  & 1204 & 32.2 & 1459 & 83.4  \\
    ViT-B & 86.6  & 3088 & 17.7 & 777 & 83.1  \\
    $\mathcal{H}(\text{ViT-B})$ & 65.0  & 3162 & 13.5 & 936 & 82.9  \\
    $\mathcal{E}(\text{ViT-B})$ & 43.3  & 3266 & 9.3 & 828 & 82.2  \\
    ViT-S & 22.1  & 7174 & 4.7 & 338 & 80.4  \\
    $\mathcal{E}(\text{ViT-S})$ & 11.0  & 6565 & 2.6 & 417 & $\dagger$  \\
    
    \toprule
    \multicolumn{6}{c}{\textbf{Convolutional Networks (ConvNeXt \cite{liu2022convnext})}} \\ [3pt]
    ConvNeXt-L (\textit{iso.}) & 305.9 & 1284 & 60.0 & 1420 & 82.6 \\
    $\mathcal{E}(\text{ConvNeXt-L (\textit{iso.})})$ & 153.1 & 1527 & 30.3 & 935 & 82.6 \\
    ConvNeXt-B (\textit{iso.}) & 87.1 & 3890 & 17.0 & 540 & 82.0 \\
    $\mathcal{E}(\text{ConvNeXt-B (\textit{iso.})})$ & 43.6 & 4094 & 8.6 & 450 & 81.3 \\
    ConvNeXt-S (\textit{iso.}) & 22.3 & 9649 & 4.3 & 226 & 79.7 \\
    $\mathcal{E}(\text{ConvNeXt-S (\textit{iso.})})$ & 11.2 & 7851 & 2.3 & 220 & 76.8 \\
    \bottomrule
    \multicolumn{6}{l}{\footnotesize $^1$ResMLP-L24 was trained by us as a baseline.} \\
    \multicolumn{6}{l}{\footnotesize $^\dagger$Failed to converge.} \\
    \end{tabular}}
\end{table}

    