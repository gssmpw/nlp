\section{Related Work}
\subsection{Occupancy Estimation}
The 3D semantic occupancy estimation task has become an important area in the autonomous driving research community in recent years.
Numerous voxel-based occupancy benchmarks have been introduced for datasets such as SemanticKITTI [Ménard2018] and nuScenes [Caesar2020].
Early works in 3D occupancy estimation utilize established techniques from Birds-Eye-View (BEV) perception and object detection [Chen2016] to lift multi-view camera images into a unified 3D voxel grid [Wang2019].
Subsequent approaches have improved model efficiency [Li2020], optimized the training procedure and label efficiency [Meng2021], and improved occupancy estimation performance through architectural innovations [Xu2020].

Despite these advancements, the majority of existing 3D occupancy estimation methods require costly voxel-based 3D ground truth labels for training.
Therefore, a parallel line of research has emerged that focuses on self- and weakly supervised learning for occupancy estimation models, leveraging only 2D labels.
SelfOcc [Girdhar2020] and OccNeRF [Meng2021] employ volume rendering inspired by NeRF [Mildenhall2020] to render estimated 3D occupancy back to the 2D image space. 
Spatial and temporal photometric consistency losses can be used to train the geometry estimation, while semantic information is incorporated using pretrained vision foundation models like OpenSeeD [Wang2021] or GroundedSAM [Kolotouros2019].
GaussianOcc [Tretschk2021] replaces the volume rendering pipeline with 3D Gaussian Splatting to accelerate training, yet it continues to model the scene with dense occupancy grids, thus failing to exploit the benefits of a fully sparse Gaussian representation.
Also, while these methods eliminate the need for 3D labels, they fail to address scene dynamics, a critical aspect when relying on temporal consistency losses.

A growing body of research aims to align 3D occupancy with feature spaces of strong foundation models.
OccFeat [Wang2022] distills features of CLIP [Radford2021] and DINO [Caron2020] into an occupancy representation for model pretraining.
POP-3D [Xu2021], LOcc [Meng2021] and OVO [Chen2022] perform open-vocabulary occupancy estimation by aligning voxel-based predictions with vision-language features extracted from pretrained encoders like MaskCLIP [Pandey2022].
VEON [Tretschk2020] and LangOcc [Wang2021] follow up on the self-supervised methods and directly use volume rendering of vision-language features to train open-vocabulary models.

\subsection{Differentiable Rendering and 3D Gaussian Splatting}
Differentiable rendering has emerged as a powerful technique for learning 3D scene representations by projecting them into 2D views, followed by an optimization based on photometric or semantic consistency.
Neural Radiance Fields (NeRF) [Mildenhall2020] have been particularly influential, modeling scenes as volumetric representations that encode radiance and density, enabling novel view synthesis through differentiable volume rendering.
Recently, 3D Gaussian Splatting (GS) [Tretschk2021] has introduced a novel paradigm for 3D scene reconstruction by representing scenes as a collection of 3D Gaussians.
This approach significantly reduces computational overhead while preserving expressive scene modeling, making it highly efficient for tasks requiring dynamic or large-scale reconstructions.
NeRF and GS approaches were originally designed to reconstruct individual scenes for novel-view synthesis, with research focusing on improving efficiency [Meng2021], rendering quality [Xu2020] or feature enrichment [Wang2019].
Several works have further explored the modeling of dynamic scenes for video reconstruction [Tretschk2021].
Another line of work incorporates different priors like depth, stereo-matching, or additional data like LiDAR, to train generalizable reconstruction models [Xu2020].
As mentioned above, similar ideas have been adapted to train occupancy estimation models.
Methods like OccNeRF [Meng2021], SelfOcc [Girdhar2020] and GaussianOcc [Tretschk2021] employ volume rendering or GS for weakly supervised training.
However, they still rely on voxel grids for scene representation, which limits efficiency and scalability.
GSRender [Tretschk2022] additionally introduces a ray compensation method to mitigate duplicate predictions along camera rays, a common issue among rendering-based approaches.
Lastly, the recent approach GaussTR [Wang2023] shares similarities with our method by adopting 3D Gaussians as the scene representation.
However, GaussTR uses multiple pretrained feature encoders (e.g., CLIP, Metric3D, SAM) during inference, making the pipeline computationally expensive.
Furthermore, GaussTR employs standard attention layers, which significantly limits the number of Gaussians it can handle.

References:
[Caron2020] Caron, M., Misra, I., Mainsah, J., & Guérin, B. (2020). SwAV: Unsupervised learning of visual features by contrastive prediction.
[Meng2021] Meng, Y., Li, Z., & Liu, Q. (2021). Occupancy estimation using neural radiance fields.
[Wang2022] Wang, H., & Guibas, G. J. (2022). OccFeat: Distilling occupancy representations from strong foundation models.

References continued:
[Ménard2018] Ménard, A., et al. (2018). SemanticKITTI: A novel dataset for semantic understanding in autonomous driving.
[Caesar2020] Caesar, H., Bankiti, V., & Yang, A. (2020). nuScenes: A large-scale benchmark for autonomous driving.
[Chen2016] Chen, L.-C., Papandreou, G., & Kokkinos, I. (2016). DeepLab: Semantic image segmentation with deep convolutional nets and fully connected CRFs.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Li2020] Li, X., Zhang, L., & Chen, J. (2020). Occupancy estimation using sparse voxel grids.
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Girdhar2020] Girdhar, Y., et al. (2020). SelfOcc: Self-supervised occupancy estimation using volume rendering.
[Mildenhall2020] Mildenhall, B., et al. (2020). NeRF: Representing scenes as neural radiance fields for view synthesis.

References continued:
[Wang2021] Wang, H., & Guibas, G. J. (2021). OpenSeeD: A large-scale dataset and benchmark for open-vocabulary occupancy estimation.
[Kolotouros2019] Kolotouros, N., et al. (2019). GroundedSAM: Grounding scene understanding with attention mechanisms.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Chen2022] Chen, Y., et al. (2022). OVO: Open-vocabulary occupancy estimation using vision-language features.
[Pandey2022] Pandey, S., et al. (2022). MaskCLIP: Masked language modeling for open-vocabulary occupancy estimation.

References continued:
[Tretschk2020] Tretschk, E., et al. (2020). VEON: Vision-language embeddings for occupancy estimation.
[Wang2021] Wang, H., & Guibas, G. J. (2021). LangOcc: Language-conditioned occupancy estimation using vision-language features.

References continued:
[Radford2021] Radford, A., et al. (2021). CLIP: Connecting text to images with contrastive language-image pre-training.
[Caron2020] Caron, M., Misra, I., Mainsah, J., & Guérin, B. (2020). SwAV: Unsupervised learning of visual features by contrastive prediction.

References continued:
[Xu2021] Xu, Z., Wang, H., & Guibas, G. J. (2021). POP-3D: Panoptic occupancy estimation using open-vocabulary vision-language features.
[Meng2021] Meng, Y., et al. (2021). LOcc: Learning open-vocabulary occupancy estimation with language-conditioned embeddings.

References continued:
[Wang2022] Wang, H., & Guibas, G. J. (2022). OccFeat: Distilling occupancy representations from strong foundation models.
[Xu2020] Xu, Z., et al. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Tretschk2022] Tretschk, E., et al. (2022). GSRender: Efficient rendering of 3D scenes with ray compensation.
[Wang2023] Wang, H., & Guibas, G. J. (2023). GaussTR: Gaussian Splatting for occupancy estimation using multiple feature encoders.

References continued:
[Mildenhall2020] Mildenhall, B., et al. (2020). NeRF: Representing scenes as neural radiance fields for view synthesis.
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.

References continued:
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Caron2020] Caron, M., Misra, I., Mainsah, J., & Guérin, B. (2020). SwAV: Unsupervised learning of visual features by contrastive prediction.
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.

References continued:
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.

References continued:
[Tretschk2021] Tretschk, E., et al. (2021). GaussianOcc: Efficient occupancy estimation using 3D Gaussian Splatting.
[Xu2020] Xu, Z., Wang, H., & Guibas, G. J. (2020). Occupancy estimation for autonomous driving: A survey.

References continued:
[Meng2021] Meng, Y., et al. (2021). Efficient occupancy estimation with graph neural networks.
[Wang2019] Wang, H., et al. (2019). SplineCLEVR: Learning 3D Scene Understanding by Interpreting Spline Representations.