\section{Limitations}

We establish a new framework for computational metaphor analysis with conceptual, methodological, analytical, and resource contributions. In light of this large scope, there are many limitations that future work may consider addressing. 

Our method has many components, each of which could be further optimized. To measure conceptual associations, we only test one document embedding model, one similarity metric, and compare documents with hand-crafted ``carrier sentences''; the specific choice of sentences may also affect performance. Our experiments with LLM-based metaphorical word detection and concept mapping are slightly more comprehensive, as we evaluate three LLMs and two different prompts. However, we do not test few-shot approaches or implement any prompt optimization. We simply add together word-level and concept level scores to get a combined score, and show that this combined score outperforms the individual components. However, future work could evaluate different combination strategies or learn optimal linear combination weights on a held-out set.


Our analysis also has limitations. First is the lack of causality: while we control for various confounds in our regressions, we do not evaluate causal assumptions nor intend to make causal claims. Second is the ambiguity around user engagement as a behavioral outcome. People have diverse motivations for favoriting and retweeting content \citep{meier2014more,boyd2010tweet}, so it is unclear precisely what motivates people to engage in these behaviors, and why we observe stronger associations between metaphor and retweets than favorites. 
It is possible that favoriting activity is dampened by negative emotional content conveyed with dehumanizing metaphors, while retweeting reflects the desire to amplify information that communicates threats \citep{mendelsohn2021modeling}. But, it is not possible to evaluate these mechanisms with the available data. Third, we only have data about favorite and retweet \textit{counts}, not \textit{who} is engaging with the content. This limits interpretations of audience susceptibility to metaphor exposure. We motivate and connect our analysis to prior literature by assuming that authors and their audiences share similar ideologies \citep{barbera2015tweeting}, but this assumption may not always hold. 

Our domain of focus---U.S. immigration discourse on Twitter---is worthy of study in its own right. Nevertheless, the present work is limited in generalizability. We urge future work to extend our methods, evaluation, and analysis to other political issues, platforms, countries, and languages.  




% both theoretical and methodological approaches to disentangle use-mention of metaphors. from the cognitive standpoint, does mentioning the metaphor still have the same dehumanizing effect (e.g. as we've seen with slurs)


%we dont have data about who is engaging with what kind of content - limits the kinds of conclusions we can draw about metaphorical framing effects. 

%Unfortunately, we only have political ideology data for tweet authors and not audience members engaging with the tweets. This analysis thus rests on the assumption that a tweet's author and audience generally share the same political ideology \citep{barbera2015tweeting}. Specifically, we compare how associations between metaphoricity and user engagement differ based on whether the author is liberal or conservative.

% We then separate tweets into those written by liberal and conservative authors to investigate the moderating role of ideology. We unfortunately only have the numbers of favorites and retweets and lack information about \textit{who} is engaging with this content. If assumptions of homophily hold, audiences engaging with tweets would most often share the same political ideology as the respective authors.


%We consider favorite and retweet metrics as outcome variables. Our data includes the number of favorites and retweets that a tweet receives, but we unfortunately lack access to information about view counts, \textit{who} is exposed to a particular tweet, and \textit{who} engages with each tweet. To understand effects on audiences, we thus rely on information about the author's ideology and assumptions of homophily: audiences exposed to conservative (liberal) tweets are primarily conservative (liberal) \citep{barbera2015tweeting}. 
