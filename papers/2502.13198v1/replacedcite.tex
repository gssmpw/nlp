\section{Background and Related Work}
\label{sec:relatedwork}
This section gives an overview of common data issues in ML software systems and discusses the work related to developing DQ frameworks in the literature. Given that the case study is applied to an application in the field of analytical chemistry, this section also presents common DQ issues and handling in the context of chromatographic data.

\subsection{Data Issues in ML Software Systems}
Data understanding and preparation are often the least interesting stages in the ML software pipeline. However, to ensure proper learning, DQ must be handled ____. During this phase, the features are encoded, the data are checked for null values, outliers, and statistical correlation among the independent variables, and the distribution of the feature values is visualized. The importance of data pre-processing comes from the critical impact of the data on the performance of the ML software system. 

The literature studying this topic separates the data issues observed in information systems from big data issues. In ____, the authors identified the data problems observed in information systems, such as information loss, ambiguity, meaningless, or incorrect data. The categorization is based on the true representation of an information system in the real world and the fact that data issues arise due to representation deficiencies ____. With the evolution of big data and AI, researchers have begun to investigate DQ issues beyond classical database operations and have begun to look at big data challenges ____.

Despite data issues dating back to the early days of computing, DQ is still considered an interesting research topic ____. In particular, the challenges emerging from big data. Although big data has great potential for the advancement of technologies, at the same time, it presents many challenges that arise from its properties ____. Most research extracts data issues from the characteristics of the big data itself. For example, Fan \emph{et al.} identifies the challenges of big data in complex heterogeneity, high dimensionality, noise accumulation, spurious correlation, incidental endogeneity, and measurement errors ____. Another research considered heterogeneity and incompleteness, scale, and timeliness as data-related issues to be addressed ____. In another study, the authors present a comprehensive mapping of data issues into three main categories ____. The first category includes data issues related to the characteristics of big data, such as volume, variety, velocity, veracity, volatility, and variability. The second group is related to the challenges of data processing from collection to the application of ML. The third category pertains to data management issues, including data security, privacy, and ethical concepts.  

There exist different perspectives to investigate DQ in ML systems. Given that the data used in ML systems are often large, it automatically inherits the data problems mentioned in ____ and ____. Although many of the mentioned data issues are cross-cutting, the quality of the data depends to a great extent on the nature of the application being studied. Therefore, in our use case, the quality measurements are specific to the chromatography dataset and are deduced from experimental recordings. The deduced measurements fall mostly under the veracity and variability issues of big data.

\subsection{Systemic Approaches to DQ Evaluation in the Literature}\label{sec:DQapproaches}
The concept of DQ greatly depends on the nature of the application under study. Therefore, the definition and assessment of DQ is a complex concept ____. As such, there are different definitions of DQ in the literature. For example, DQ could refer to the measurement of incorrect or missing data ____, or represent the suitability of a given dataset, including the features, for a specific use case (____, ____). In this paper, we define the DQ as the characteristics of the data that fit the purpose of building high-performing ML systems.

DQ validation is an influential requirement for a reliable ML system ____. Given its dependence on the use case, researchers from different perspectives have handled the concept of DQ. However, many of the DQ frameworks in the literature are based on database management concepts that aim to solve generic DQ problems ____. One of the first DQ frameworks proposed testing whether the data are complete, unambiguous, meaningful, and correct ____. While in ____, authors go beyond precision and present a hierarchical framework that categorizes the attributes of DQ into four groups: intrinsic, contextual, representational, and accessible. According to ____, high-quality data are defined as intrinsically good, contextually suitable for the task, clearly represented, and accessible. In ____, the authors address the quality of raw data in the pre-processing stage and apply it to a conceptualized weather monitoring and forecasting application as a case study. The idea is to fix as many data issues as possible before training and evaluating ML models ____. ____ presented a risk-based data validation approach in ML systems inspired by the famous risk-based approach in SE testing. In the risk-based approach, features are presented as risk items where the risk of poor DQ for each feature is estimated. Two important factors are calculated under this approach, the probability that a feature is of low quality and the impact of this feature on the performance of the ML system. This approach presented a new perspective to DQ evaluation, but it was not validated in a real-world application. 

In Literature, some of the DQ frameworks are, by design, limited to specific applications or specific types of data. For example, ____ proposed a real-time DQ assessment to integrate trust metrics into the Internet of Things (IoT) data cycle. The framework was tested using data from real-time IoT sensors ____. The results and analysis showed that the trust metric could be a good DQ metric in the context of IoT data ____. In another study, an exhaustive review of DQ assessment and improvement methods is presented; however, it is limited to specific applications ____. In ____, a DQ scoring framework is presented for production data. The framework yields an aggregated score based on five quality dimensions: accuracy, completeness, consistency, timeliness, and skewness. In ____, the authors propose quality attributes that are most important for deep learning. The three quality attributes finely selected by Chen \emph{et al.} are comprehensiveness, correctness, and variety, which they redefined to fit deep learning applications. As part of the study, they conducted experiments to investigate how noisy data could lead to a false improvement in ML performance ____. The results of the experiments performed showed a strong correlation between DQ and ML performance ____. Similar preliminary research on deep learning has been conducted in ____ and ____. 

A subset of the approaches were mainly guided by the type of data and not the task. For example, the quality of linked data was investigated in multiple research-based frameworks, such as in the Luzzu Quality Assessment Framework ____. The framework provides a 22-dimensional library of quality metrics that can be used to assess the fitness of the dataset for use for a specific user-defined task. Another study focusing on linked data proposed a five-step assessment framework that detects the root causes of DQ violations and provides improvement recommendations ____. However, these frameworks were shown to be limited to the assessment of metadata. On the other hand, the quality of open data also attracted the attention of researchers, such as in ____ where the authors proposed methodological guidance for screening, assessing, and preparing open data for business scenarios in an enterprise setting. The authors argue that “fitness for use” could apply to open data ____.

In the context of big data, a large DQ management framework that aims to address end-to-end DQ throughout the entire life cycle of big data is proposed in ____. The framework captures quality requirements, attributes, dimensions, scores, and rules and quantifies the scores for quality dimensions. However, the authors did not test the framework using real-world data. 

As observed, understanding the quality of the data is realized through many data-based or application-based approaches, with the most commonly measured dimensions being completeness, timeliness, and accuracy ____. The success of any approach is correlated with finding interesting characteristics of the data that can be transformed into quality measures ____. One of the interesting methods to achieve this is through the application of unsupervised ML. In this paper, we propose a general framework that relies on the use of unsupervised learning to evaluate DQ using pre-defined quality measurements. As a result, the high-quality characteristics that make a high-performing ML system are deduced.

\subsection{DQ in Ion-pair Liquid Chromatography}

Chromatography, in general, is an efficient method used in the separation of a range of samples, including drugs, food, air and water samples, and much more. Ion-pair Liquid Chromatography (IPLC) is a chromatography technique that allows one to separate complex molecular mixtures in particular charged molecules ____. The method includes injecting the sample, including a mixture of compounds, into the column where the separation occurs, as shown in Figure \ref{fig:IPLC}. As the separated compounds exit the column, they are detected by the detector as signals. The information collected on the detected signals provides insight into the success of the separation. In our case study, a mixture is a group of ASO compounds separated from the impurities by the IPLC method. An ASO compound is a combination of the nucleotides adenine (A), thymine (T), cytosine (C), and guanine (G). An ASO sequence could be modified by other atoms, such as sulfur, known as phosphorothioation. The importance of ASO sequences comes from their interesting potential in the treatment of diseases that are not targeted by classical medicine ____. 

While the compounds are eluting from the IPLC system, the data describing the detected signals are recorded. A sample of the collected data is shown in Table \ref{tab:signalsdata}, where each row refers to an ASO compound and its peak characteristics. The characteristics of a peak include the signal-to-noise ratio (SNR), $\Delta$t$_R$, which calculates the difference in $t_\mathrm{R}$ between two experiments, and the area under the peak. The resulting peaks are typically visualized in a chromatogram, which is later inspected and analyzed by analytical chemists.

\begin{figure}
  \centering
    \includegraphics[scale=.2]{IPLC1.pdf}
    \caption{Separation process using liquid chromatography and a spectrometry detector. }\label{fig:IPLC}
\end{figure}

A chromatogram is a graphical representation of the detected signals over the separation time. Analytical chemists spend a substantial amount of time controlling the quality of the data visualized data in a chromatogram ____. Data pre-processing in this context includes removing the undesired experiments from the obtained signals ____. A typical pre-processing procedure includes noise removal and baseline correction ____. Furthermore, inspecting the properties of the peaks, focusing mainly on the t$_\mathrm{R}$, shape, and resolution peaks ____. In particular, inspecting the cases of overlapped peaks, shifted $t_\mathrm{R}$, and peaks with low SNR ____. Chromatogram inspection and analysis are crucial since accurate peaks lead to sound quantitative and qualitative analysis. 

\begin{table}
\setlength{\tabcolsep}{5 pt}
\centering
\caption{Data collected from detected signals in IPLC.}
\label{tab:signalsdata}
\begin{tabular}{lllllll}
\toprule
\textbf{Sequence}& \textbf{$\Delta$t$_R$} & \textbf{SNR} & \textbf{Skewness} & \textbf{Peak area}\\
\midrule
AAAAAAAAAAAAAAAAAAAA & -0.01 & 792.68 & 1.21 & 22443.81\\
CACGTGACTATG& $-0.00$ & 1893.19&	1.16& 52434.17 \\
A*C*G*T*G*ACTATG-P=O & $-0.03$&	18.36&	1.03&	239.42\\
A*TTAGAA*T*T*A & $-0.01$ &	61.09 &	1.18 & 699.10\\
\bottomrule
\end{tabular}
\end{table}

Chromatogram analysis is a critical step in correcting the data problems faced during the data acquisition phase. A chemist generally looks for significant peaks and observes failed experiments. The analysis of the data is mostly conducted manually with the assistance of statistical and mathematical tools. Still, it is often complex and time-consuming, as all resulting peaks must be checked. Therefore, the interest in using ML methods to facilitate data analysis is increasing.

In the literature, ML has been used for various peak quality control applications such as peak selection, integration, and annotation ____. Regarding peak picking, multiple ML models were developed to process and select chromatogram peaks, including deep learning approaches ____. In particular, using convolutional neural networks as in ____. However, in this paper, we do not focus on a specific aspect of DQ but instead use unsupervised learning to learn about all potential data issues in the space of the selected quality measurements. 

%% Bestoun 21 April