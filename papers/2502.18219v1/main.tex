
\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} %

\usepackage[table]{xcolor}
\input{preamble}

\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

\usepackage{textcomp, gensymb}
\usepackage{paralist}
\usepackage{chngcntr}

\newcommand{\uncer}[1]{\textcolor{red}{#1}}
\newcommand*{\circled}[1]{\lower.7ex\hbox{\tikz\draw (0pt, 0pt)%
    circle (.5em) node {\makebox[1em][c]{\small #1}};}}
\newcommand{\best}[1]{\textbf{#1}}

\expandafter\def\expandafter\normalsize\expandafter{%
    \normalsize%
    \setlength\abovedisplayskip{4pt}%
    \setlength\belowdisplayskip{4pt}%
    \setlength\abovedisplayshortskip{-8pt}%
    \setlength\belowdisplayshortskip{2pt}%
}


\def\paperID{186} %
\def\confName{3DV\xspace}
\def\confYear{2025\xspace}

\title{Synthesizing Consistent Novel Views via 3D Epipolar Attention \\ without Re-Training}


\author{
Botao Ye$^{1,2}$ \quad Sifei Liu$^3$ \quad Xueting Li$^3$ \quad Marc Pollefeys$^{1,4}$ \quad Ming-Hsuan Yang$^{5}$ \\
$^1$ETH Zurich \quad $^2$ETH AI Center \quad $^3$NVIDIA \quad 
$^4$Microsoft \quad $^5$UC Merced
{}
{}
}

\begin{document}

\twocolumn[{
\renewcommand\twocolumn[1][]{#1}
\maketitle
\vspace{-12mm}
\begin{center}
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=.8\textwidth]{figs/teaser.pdf}
    \vspace{-2mm}
    \captionof{figure}{Given an input image and a sequence of relative camera pose transformations, our method synthesizes more consistent novel view images. Our method \textit{does not need to re-train} the baseline model (Zero123) and \textit{supports arbitrary relative camera poses}.}
    \vspace{-1mm}
\end{center}
}]

\maketitle

\input{sec/0_abstract}    
\input{sec/1_intro}
\input{sec/2_related}
\input{sec/3_method}
\input{sec/4_experiments}
\input{sec/5_conclusion}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}
\input{sec/X_suppl}

\end{document}
