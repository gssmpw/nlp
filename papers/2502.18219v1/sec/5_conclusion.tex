\vspace{-2mm}
\section{Conclusion}
\vspace{-2mm}
\label{sec:conclusion}


In this paper, we propose a method to improve the consistency of multi-view images synthesized by a pose-guided diffusion model without any training or fine-tuning.
Specifically, for each pixel in the target view, we use epipolar attention to locate and retrieve features at corresponding locations in the input view and insert them into the generation process of the target view to enhance consistency. We also extend epipolar attention to the multi-view setting by synthesizing multiple views and retrieving information from the input and other target views.
Experimental results show that our method can improve the consistency of the generated multi-view images and further benefit downstream applications such as 3D reconstruction.

\textbf{Acknowledgement.} Botao Ye is partially supported by the ETH AI Center.
