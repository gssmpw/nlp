[
  {
    "index": 0,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "he2015delving",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2023adalora",
        "author": "Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and Karampatziakis, Nikos and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo",
        "title": "AdaLoRA: Adaptive budget allocation for parameter-efficient fine-tuning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zi2023delta",
        "author": "Zi, Bojia and Qi, Xianbiao and Wang, Lingzhi and Wang, Jianan and Wong, Kam-Fai and Zhang, Lei",
        "title": "Delta-lora: Fine-tuning high-rank parameters with the delta of low-rank matrices"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li2023losparse",
        "author": "Li, Yixiao and Yu, Yifan and Zhang, Qingru and Liang, Chen and He, Pengcheng and Chen, Weizhu and Zhao, Tuo",
        "title": "Losparse: Structured compression of large language models based on low-rank and sparse approximation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2024dora",
        "author": "Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung",
        "title": "Dora: Weight-decomposed low-rank adaptation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "meng2025pissa",
        "author": "Meng, Fanxu and Wang, Zhaohui and Zhang, Muhan",
        "title": "Pissa: Principal singular values and singular vectors adaptation of large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2024loragalowrankadaptationgradient",
        "author": "Shaowen Wang and Linxi Yu and Jian Li",
        "title": "LoRA-GA: Low-Rank Adaptation with Gradient Approximation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yang2024mtlloralowrankadaptationmultitask",
        "author": "Yaming Yang and Dilxat Muhtar and Yelong Shen and Yuefeng Zhan and Jianfeng Liu and Yujing Wang and Hao Sun and Denvy Deng and Feng Sun and Qi Zhang and Weizhu Chen and Yunhai Tong",
        "title": "MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "tian2024hydraloraasymmetricloraarchitecture",
        "author": "Chunlin Tian and Zhan Shi and Zhijiang Guo and Li Li and Chengzhong Xu",
        "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yang2024mtlloralowrankadaptationmultitask",
        "author": "Yaming Yang and Dilxat Muhtar and Yelong Shen and Yuefeng Zhan and Jianfeng Liu and Yujing Wang and Hao Sun and Denvy Deng and Feng Sun and Qi Zhang and Weizhu Chen and Yunhai Tong",
        "title": "MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "tian2024hydraloraasymmetricloraarchitecture",
        "author": "Chunlin Tian and Zhan Shi and Zhijiang Guo and Li Li and Chengzhong Xu",
        "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "tian2024hydraloraasymmetricloraarchitecture",
        "author": "Chunlin Tian and Zhan Shi and Zhijiang Guo and Li Li and Chengzhong Xu",
        "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "he2015delving",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "srivastava2014dropout",
        "author": "Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan",
        "title": "Dropout: a simple way to prevent neural networks from overfitting"
      }
    ]
  }
]