%
%
\subsection{\khd} 
\label{sub:khd}

%
\begin{algorithm2e}[ht!]
\caption{\khd: Kernel Halving with simplified swapping thresholds and failure probability $\delta/2$}
\label{algo:khd}
\small{
  \KwIn{point sequence $\xin=(\x_i)_{i = 1}^{\nin}$ with even $\nin$, kernel $\kernel$}
  \BlankLine
  {$\coreset[1], \coreset[2] \gets \braces{}$};\quad $\wtpsi_0\gets \boldzero \in \rkhs$\quad // Initialize empty coresets: $\coreset[1],\coreset[2]$ have size $i$ after round $i$ \\ 
  {$\multiplier_{\max,i} \gets 0$}\qquad\qquad\qquad\qquad\qquad\  // Max function norm so far \\
  \For{$i=1, 2, \ldots, \nin/2$}
    {%
    // Construct kernel difference function using next two points \\
    $(\x, \x') \gets (\x_{2i-1}, \x_{2i})$;\quad
    $f_i \gets \kernel(\x_{2i-1}, \cdot)-\kernel(\x_{2i}, \cdot)$; \quad $\eta_i \gets -1$ \\
	 \BlankLine
     // Compute swapping threshold $\thresh_i$ \\ %
     $\multiplier_i^2 \!=\! \norm{f_i}_{\kernel}^2 
      \!=\! \kernel(\x,\x)\!+\!\kernel(\x',\x')\!-\!2\kernel(x,x')$;\quad $\multiplier_{\max,i} = \max(\multiplier_i, \multiplier_{\max,i-1})$ \\
      %
     $ \thresh_i \gets \multiplier_i \multiplier_{\max,i}(\half + \log(2\nin/\delta))$
     \ \ 
   \BlankLine
    // Compute RKHS inner product $\angles{\wtpsi_{i-1}, f_i}_{\kernel}$, which has a simple form \\
    $\alpha_i\gets  \sum_{j=1}^{2i-2}(\kernel
	 (\x_j, \x)-\kernel(\x_j,\x')) 
	 - 2\sum_{\z\in\coreset[1]}(\kernel(\z, \x)-\kernel(\z,\x'))$ \\
    \BlankLine
			 // Assign one point to each coreset after probabilistic swapping \\[2pt]
		     $(x, x') \gets (x', x)$ \text{ and } $\eta_i \gets 1$ \qtext{\textit{with probability}} $\min(1, \half (1-\frac{\alpha_i}{\thresh_i})_+)$ \\ 
           $\coreset[1]\texttt{.append}(\x); 
		        \ \ \  \coreset[2]\texttt{.append}(\x'); \ \ \ 
		     \wtpsi_i\gets \wtpsi_{i-1} + \eta_i f_i $ \quad // $ \wtpsi_i=\sum_{x'\in\coreset[2]}\!\kernel(x', \cdot)\!-\!\sum_{x\in\coreset[1]}\!\kernel(x, \cdot)$
  }
  \KwRet{\textup{$\xout\defeq\coreset[1]$, coreset of size} $\nout=\nin/2$}{} 
  } 
\end{algorithm2e}
%


In this section, we analyze \khd (\cref{algo:khd}), a variant of the Kernel Halving algorithm \citep[Alg.~2]{dwivedi2024kernel} with simplified swapping thresholds.
\cref{khd-sub-gaussian}, proved in \cref{proof:khd-sub-gaussian}, establishes the sub-Gaussianity of \khd and its intermediate iterates.

%
\begin{proposition}[Sub-Gaussianity of \khd]\label{khd-sub-gaussian} 
Suppose $\nin \geq 2$. 
In the notation of \cref{algo:khd}, on a common event $\event$ of probability at least $1-\delta/2$, 
for all $i\in[\nin/2]$, 
$\frac{1}{2i}\wtpsi_i$ is $(\kernel, \subg_i)$-sub-Gaussian with 
\begin{talign}\label{eq:khd-subg}
\subg_i 
    &=
\multiplier_{\max,i}\frac{\sqrt{\log(2\nin/\delta)}}{2i}
    = 
\frac{\sqrt{\log(2\nin/\delta)}}{2i}
\max_{j\in[i]}\mmd_{\k}(\dirac_{\x_{2j-1}},\dirac_{\x_{2j}})
    \leq
\frac{\sqrt{\log(2\nin/\delta)}}{2i}
\max_{j\in[i]}\mmd_{\k}(\dirac_{\x_{2j-1}},\dirac_{\x_{2j}}) \\
    &\leq
\frac{\sqrt{\log(2\nin/\delta)}}{2i}2\min(\max_{\x\in\xin}\sqrt{\k(\x,\x)},
\max_{\x\in\xin}\mmd_{\k}(\dirac_{\x},\Pin))
.
\end{talign}
\end{proposition}
%
\cref{khd-sub-gaussian} and the triangle inequality imply that $(\Pin -\Qout)\k=\frac{1}{\nin}\psi_{\nin/2}$ is $(\k,\subg)$-sub-Gaussian on $\event$ with
\begin{talign}\label{eq:khd-subg}
\subg 
    &=
\multiplier_{\max,\nin/2}\frac{\sqrt{\log(2\nin/\delta)}}{\nin}
%
%
    \leq
\frac{\sqrt{\log(2\nin/\delta)}}{\nin}2\min(\max_{\x\in\xin}\sqrt{\k(\x,\x)},
\max_{\x\in\xin}\mmd_{\k}(\dirac_{\x},\Pin))
.
\end{talign}

By \cref{lem:funct_subg_vector_subg}, we thus have that the \khd output $\pin - \qout$ is $(\K,\subg)$-sub-Gaussian on  $\event$ for $\K$ generated by $\k$ and that $\khd \in \ksubge$.






%
\subsubsection{\pcref{khd-sub-gaussian}}\label{proof:khd-sub-gaussian}
We begin by studying the sub-Gaussian properties of a related algorithm, the self-balancing Hilbert walk (SBHW) of \citet[Alg.~3]{dwivedi2024kernel}. 
By \citet[Thm.~3(i)]{dwivedi2024kernel}, when the SBHW is run on the RKHS $\rkhs$ with the same $f_i$ and $\thresh_i$ sequences employed in \khd, the output $\psi_i$ of each round is $(\kernel, \sigma_i)$-sub-Gaussian for 
\begin{talign} \label{eq:sbhw-subg}
\sig_0^2
    \defeq 0
\qtext{and}
\sig_i^2
    \defeq \sig_{i-1}^2 + \knorm{f_{i}}^2\big(1 + \frac{\sig_{i-1}^2}{\thresh_i^2}(\knorm{f_{i}}^2 - 2\thresh_i)\big)_+
\quad \forall i \geq 1.
\end{talign}
The following lemma bounds the growth of the sub-Gaussian constants $\sig_i$ in terms of the swapping thresholds $\thresh_i$.
%
\begin{lemma}[Growth of SBHW sub-Gaussian constants]\label{sbhw-subg-growth}
For each $i$, the SBHW sub-Gaussian constants \cref{eq:sbhw-subg} satisfy
\begin{talign}
\sig_i^2 
    \leq 
c_i
\qtext{for}
c_i \defeq \max_{j \in [i]} \max(\multiplier_j^2, r_j)
\qtext{and}
r_i 
    \defeq 
\frac{\thresh_i^2}{2\thresh_i - \multiplier_i^2}
    \leq
\frac{\thresh_i^2}{2\thresh_i - \multiplier_i\multiplier_{\max,i}}.
\end{talign}
\end{lemma}
\begin{proof}
We will prove the result by induction on $i$.
\paragraph{Base case.} $\sig_1^2 = \multiplier_1^2 \leq c_1$ as desired.
\paragraph{Inductive case.}
Suppose $\sig_{i-1}^2 \leq c_{i-1}$.
Then $\sig_i^2 = g(\sig_{i-1}^2)$ for $g(x) = x + \multiplier_i^2 ( 1-x/r_i)_+$.
Note that the slope of $g$ is $1 - \multiplier_i^2/r_i$ for $x < r_i$ and $1$ for $x > r_i$. 
If $1 - \multiplier_i^2/r_i \geq 0$, then $g$ is increasing and its maximum value over $[0, c_{i}]$ is at $c_{i}$.
If, on the other hand, $1 - \multiplier_i^2/r_i < 0$, then $g$ first decreases and then increases so its maximum value over $[0, c_{i}]$ is either at $0$ or at $c$. 
Since $c_i \geq \max(r_i, c_{i-1})$, $\sig_i^2 \leq \max(g(0), g(c_i)) = \max(\multiplier_i^2, c_i) = c_i$.
The proof is complete.
\end{proof}
%
Invoking \cref{sbhw-subg-growth}, the assumption $\nin \geq 2$, and the fact that $\delta\mapsto\frac{\half+\log(2/\delta)}{\log(2/\delta)}$ is increasing on $(0,1]$, we find that
\begin{talign}\label{eq:sbhw-subg-bound}
\sigma_i^2
    \leq
\multiplier_{\max,i}^2 
\log(2\nin/\delta)\frac{(\half + \log(2\nin/\delta))^2}{2(\log(2\nin/\delta))^2}
    \leq
\multiplier_{\max,i}^2
\log(2\nin/\delta)\frac{(\half + \log(4))^2}{2(\log(4))^2}
    \leq 
\multiplier_{\max,i}^2
\log(2\nin/\delta).
\end{talign}
The first inequality in \cref{eq:sbhw-subg-bound} and the definition \cref{eq:sbhw-subg} further imply that
\begin{talign}
\thresh_i 
    =
\multiplier_i \multiplier_{\max,i} (\half + \log(2\nin/\delta))
    \geq 
\sig_i \multiplier_i \sqrt{2\log(2\nin/\delta)}
    \geq
\sig_{i-1} \multiplier_i \sqrt{2\log(2\nin/\delta)}.
\end{talign}
Hence, by \citet[Thm.~3(iii)]{dwivedi2024kernel}, for each $i \in [\nin/2]$, the vector $\wtpsi_i$ of \khd coincides with the vector $\psi_i$ of SBHW on a common event $\event$ of probability at least $1-\delta/2$. 
Therefore, each $\frac{1}{2i}\wtpsi_i$ is $(\kernel,\frac{1}{2i}\sig_i)$-sub-Gaussian on $\event$, implying the result.

%
\subsection{\khlind}
\label{sub:khlind}
%
\SetKwFunction{procgetswap}{\texttt{get\_swap\_params}}

\begin{algorithm2e}[ht!]

    
    \caption{\khlind: Kernel Halving with linear kernel and failure probability $\delta/2$}
    \label{algo:khlin}
    \small{
      \KwIn{point sequence $\xin=(\x_i)_{i = 1}^{\nin}$  with even $\nin$ and $\x_i \in \mathbb{R}^d$} 
      \BlankLine
      {$\coreset[1], \coreset[2] \gets \braces{}$};\quad $\psi_0\gets \boldzero \in \mathbb{R}^d $\quad // Initialize empty coresets: $\coreset[1],\coreset[2]$ have size $i$ after round $i$ \\ 
      $\sigma_0 \gets 0 $  
      \qquad\qquad\qquad\qquad\qquad\quad\ \  // Keep track of sub-Gaussian constant \\
      \For{$i=1, 2, \ldots, \nin/2$}
        {%
        // Consider two points \\
        $(\x, \x') \gets (\x_{2i-1}, \x_{2i})$;
        %
        %
        \quad $\eta_i \gets -1$ \\
         \BlankLine
         // Compute swapping threshold $\thresh_i$ \\ %
        %
        %
          $\multiplier_i^2 = \angles{ \x - \x' , \x - \x' }   $; \quad $\delta_i = \frac{\delta}{2i (\log (\nin/2 ) + 1)}$ \\  
          %
          $(\thresh_i, \sigma_i ) \gets$ \procgetswap{$\sigma_{i-1}, \multiplier_i , \delta_i$}\\  
        %
       \BlankLine
        // Compute inner product \\
        $\alpha_i\gets \angles{\psi_{i-1}, \x - \x' }  $ \\
        \BlankLine
                 // Assign one point to each coreset after probabilistic swapping \\[2pt]
                 $(\x, \x') \gets (\x', \x)$ \text{ and } $\eta_i \gets 1$ \qtext{\textit{with probability}} $\min(1, \half (1-\frac{\alpha_i}{\thresh_i})_+)$ \\ 
               $\coreset[1]\texttt{.append}(\x); 
                    \ \ \  \coreset[2]\texttt{.append}(\x'); \ \ \ 
                 \wtpsi_i\gets \wtpsi_{i-1} + \eta_i f_i $ 
      }
      \KwRet{\textup{$\xout\defeq\coreset[1]$, coreset of size} $\nout=\nin/2$}{} 
      } 

      \hrulefill\\

      \SetKwProg{myproc}{function}{}{}
     \myproc{\procgetswap{$\sigma, \vmax[], \delta$}:}{
     $
            \cnew[] 
                \gets \max(\vmax[] \sigma\sqrt{\smash[b]{2\log(2/\delta)}}, \vmax[]^2)$ \\
     $\sigma^2 \gets \sigma^2
            \!+\! \vmax[]^2(1 \!+\! ({\vmax[]^2}{}\! - \!2\cnew[]){\sigma^2}{/\cnew[]^2})_+$\\
     %
     }
     \KwRet{$(\cnew[], \sigma)$}\;
  

    \end{algorithm2e}

%
In this section, we analyze \khlind (\cref{algo:khlin}), the Kernel Halving algorithm of \citep[Alg.~2]{dwivedi2024kernel} 
with a linear kernel, $\k(\x,\y) = \inner{\x}{\y}$, on $\reals^d$ and failure probability $\delta/2$.
Notably, \cref{algo:khlin} can be carried out in only $O(nd)$ time thanks to the linear kernel structure.
\cref{khlind-sub-gaussian}, proved in \cref{proof:khlind-sub-gaussian}, establishes the sub-Gaussianity of \khlind and its intermediate iterates.

%
\begin{proposition}[\tbf{Sub-Gaussianity of \khlind}]\label{khlind-sub-gaussian} 
Suppose $\nin \geq 2$. 
In the notation of \cref{algo:khlin}, on a common event $\event$ of probability at least $1-\delta/2$, 
for all $i\in[\nin/2]$, 
$\frac{1}{2i}\wtpsi_i$ is $(\kernel, \subg_i)$-sub-Gaussian with $\k(\x,\y)=\inner{\x}{\y}$ and 
\begin{talign}\label{eq:khlind-subg}
\subg_i 
    &=
\frac{\sqrt{\log(2\nin(\log(\nin/2)+1)/\delta)}}{2i}
\max_{j\in[i]}\twonorm{\x_{2j-1}-\x_{2j}} \\
    &\leq
\frac{\sqrt{\log(2\nin(\log(\nin/2)+1)/\delta)}}{2i}2\min(\max_{\x\in\xin}\sqrt{\twonorm{\x}},
\max_{\x\in\xin}\twonorm{\x-\xbar})
    \qtext{for}
\xbar=\frac{1}{\nin}\sum_{\x\in\xin}\dirac_{\x}.
\end{talign}
\end{proposition}

\cref{khlind-sub-gaussian} and the triangle inequality imply that $(\Pin -\Qout)\k=\frac{1}{\nin}\psi_{\nin/2}$ is $(\k,\subg)$-sub-Gaussian on $\event$ with
\begin{talign}\label{eq:khlind-subg}
\subg 
    &=
\frac{\sqrt{\log(2\nin(\log(\nin/2)+1)/\delta)}}{\nin}
\max_{j\in[\nin/2]}\twonorm{\x_{2j-1}-\x_{2j}} \\
    &\leq
\frac{\sqrt{\log(2\nin(\log(\nin/2)+1)/\delta)}}{\nin}2\min(\max_{\x\in\xin}\sqrt{\twonorm{\x}},
\max_{\x\in\xin}\twonorm{\x-\xbar})
    \qtext{for}
\xbar=\frac{1}{\nin}\sum_{\x\in\xin}\dirac_{\x}.
\end{talign}

By \cref{lem:funct_subg_vector_subg}, we thus have that the \khlind output $\pin - \qout$ is $(\K,\subg)$-sub-Gaussian on  $\event$ for $\K$ generated by $\k$ and that $\khlind \in \ksubge$.
%
\subsubsection{\pcref{khlind-sub-gaussian}}\label{proof:khlind-sub-gaussian}
We begin by studying the sub-Gaussian properties of a related algorithm, the self-balancing Hilbert walk (SBHW) of \citet[Alg.~3]{dwivedi2024kernel}. 
By \citet[Thm.~3(i)]{dwivedi2024kernel}, when the SBHW is run on the RKHS $\rkhs$ with the same $f_i$ and $\thresh_i$ sequences employed in \khlind, the output $\psi_i$ of each round is $(\kernel, \sigma_i)$-sub-Gaussian. 
Moreover, since  
\begin{talign}
\thresh_i 
    \geq
\sig_{i-1} \multiplier_i \sqrt{2\log(2/\delta_i)}
    \qtext{for each}
i\in[\nin/2], 
\end{talign}
\citet[Thm.~3(iii)]{dwivedi2024kernel} implies that, for each $i \in [\nin/2]$, the vector $\wtpsi_i$ of \khlind coincides with the vector $\psi_i$ of SBHW on a common event $\event$ of probability at least $1-\delta/2$. 
Therefore, each $\frac{1}{2i}\wtpsi_i$ is $(\kernel,\frac{1}{2i}\sig_i)$-sub-Gaussian on $\event$.
Finally, \citet[(46)]{dwivedi2024kernel} shows that  $\sig_i \leq \subg_i$ for each $i \in [\nin/2]$, yielding the result.


%


%
\subsection{\rkhd} \label{sec:rkhd}
%
\begin{algorithm2e}[ht!]
\caption{\rkhd: Repeated \khd}
\label{algo:rkhd}
\small{
  \KwIn{point sequence $\xin=(\x_i)_{i = 1}^{\nin}$, kernel $\kernel$, output size $\nout \in \nin / 2^\naturals$}
  \BlankLine
  // Repeatedly divide coreset size in half \\
  $m \gets \log_2(\nin/\nout)$ \\ 
  \lFor{$\ell=1, 2, \ldots, m$}
    {%
    $\xin \gets \kh(\delta/m)(\xin, \kernel)$
  }
  \KwRet{\textup{$\xout\defeq\xin$, coreset of size} $\nout=\nin/2^m$}{} 
  } 
\end{algorithm2e}
%
In this section, we analyze repeated \khd (\rkhd, \cref{algo:rkhd}), a variant of the \ktsplit algorithm \citep[Alg.~1a]{dwivedi2024kernel} with simplified swapping thresholds.
Our next result, proved in \cref{proof:rkhd-sub-gaussian}, establishes the sub-Gaussianity of \rkhd.
%
\begin{proposition}[\tbf{Sub-Gaussianity of \rkhd}]\label{rkhd-sub-gaussian} 
If $\nout \in \nin/2^\naturals$ then \rkhd (\cref{algo:rkhd}) is $(\k,\subg)$-sub-Gaussian with 
\begin{talign}
\subg 
    =
\frac{2}{\nout\sqrt{3}}\sqrt{\log(\frac{6\nout \log_2(\nin/\nout)}{\delta})}
 \min(\max_{\x\in\xin}\sqrt{\k(\x,\x)},
\max_{\x\in\xin}\mmd_{\k}(\dirac_{\x},\Pin))
\end{talign}
on an event $\event$ of probability at least $1-\delta/2$.
\end{proposition}
%
By \cref{lem:funct_subg_vector_subg}, we thus have that the \rkhd output $\pin - \qout$ is $(\K,\subg)$-sub-Gaussian on  $\event$ for $\K$ generated by $\k$ and that $\rkhd \in \ksubge$.
Finally, $\subg = O(\frac{\sqrt{\log(\nout/\delta)}}{\nout})$ when $\nout \geq \sqrt{\nin}$.

%
\subsubsection{\pcref{rkhd-sub-gaussian}}\label{proof:rkhd-sub-gaussian}
Let $c = 2\min(\max_{\x\in\xin}\sqrt{\k(\x,\x)},
\max_{\x\in\xin}\mmd_{\k}(\dirac_{\x},\Pin))$, and, for each $\ell\in[m]$, let $\wtpsi^{(\ell)}$ represent the vector $\wtpsi_{\nin/2^\ell}$ produced at the end of the $\ell$-th call to \khd.
By the proof of \cref{khd-sub-gaussian} and the union bound, on an event $\event$ of probability at least $1-\delta/2$, $(\wtpsi^{(\ell)})_{\ell\in[m]} = (\psi^{(\ell)})_{\ell\in[m]}$, where each $\frac{2^{\ell-1}}{\nin}\psi^{(\ell)}$ is $(\k,\nu^{(\ell)})$-sub-Gaussian given $(\psi^{(j)})_{j\in[\ell-1]}$ for
\begin{talign}
\nu^{(\ell)}
    =
c \frac{\sqrt{\log(2\nin m/(2^{\ell-1}\delta))}}{\nin/2^{\ell-1}}.
\end{talign}
Hence, on $\event$, the weighted sum
\begin{talign}
(\Pin-\Qout)\k
    =
\sum_{\ell\in[m]} \frac{2^{\ell-1}}{\nin}\wtpsi^{(\ell)}
    =
\sum_{\ell\in[m]} \frac{2^{\ell-1}}{\nin}\psi^{(\ell)}
\end{talign}
is $(\k,\sqrt{\sum_{\ell\in[m]}(\subg^{(\ell)})^2})$-sub-Gaussian by \citet[Lem.~14]{dwivedi2024kernel}.
Finally, by \citet[Eq.~(63)]{dwivedi2024kernel}, $\sqrt{\sum_{\ell\in[m]}(\subg^{(\ell)})^2}\leq \subg$.




