\section{\pcref{thm:ctt_power}}
\label{proof:ctt_power}

\cref{thm:ctt_power} follows from the following more detailed statement, proved in \cref{proof:ctt_power_detailed} as
\begin{talign}\label{eq:errorhat} \error[\K]^2(\nin,\frac{\wtil\beta}{20 \sblock_n},\ossymb) + \error[\K']^2(\nin,\frac{\wtil\beta}{20 \sblock_n},\ossymb)
=
O(\errorhat^2).
\end{talign}

%
\begin{theorem}[\tbf{Low-rank analysis of \ctt power, detailed}]\label{thm:ctt_power_detailed}
%
%
%
%
Under the assumptions of \cref{thm:ctt_power} with $\nin \defeq \frac{m+n}{\sblock}$, 
\ctt (\cref{algo:ctt}) rejects with probability at least $1-\beta$ whenever $c' \mmd_{\kernel}(\distX, \distY)/\sqrt{\log(1/\gamma)}$ exceeds 
\begin{talign}\label{eq:mmd_threshold}
    2 c_{\wtil \beta/(20 \sblock)} \frac{\infnorm{\kernel}^{\half}}{\sqrt m} + \frac{\error(\distX,\nin, \frac{\wtil\beta}{20 \sblock_m},\ossymb) + \error(\distY, \nin,\frac{\wtil \beta}{20 \sblock_n},\ossymb)}{2^{\ossymb} \sqrt m}.
\end{talign}
Here, 
$c'>0$ is a universal constant,  $c_{\delta} \defeq 2 + \sqrt{2\log(\frac{2}{\delta})}$, and $\error(\distX,\nin, \delta, \ossymb)$ and $\error(\distY,\nin, \delta, \ossymb)$ respectively denote the $(1-\frac{\delta}{2})$-th quantiles of $\error[\K](\nin,\delta,\ossymb)$ and $\error[\K'](\nin,\delta,\ossymb)$, where
\begin{talign}\label{eq:Rkxin}
\error[\Ktilde]^2(\nin,\delta,\ossymb) 
    &\defeq  
256 (\log_4 \nin - \ossymb - 1) (\sqrt{\log(\nin+1)} + \sqrt{\log(2/\delta)})^2 \\
    &\qquad \cdot \biggl( \frac{2 \sqrt{\maxnorm{\Ktilde}}}{\sqrt 3} \brackets{\sqrt{e \log(\frac{6\cdot 2^\ossymb \sqrt{\nin} (\log_4\nin-\ossymb)}{\delta})} + \sqrt{\log(\frac{3\nin(\log_4 \nin - \ossymb - 1)}{\delta})}} \\
    &\qquad \qquad + \min_{r\leq 2^{\ossymb+1}\sqrt \nin} \braces{ \frac{2 \sqrt{\maxnorm{\Ktilde}}}{\sqrt 3}\sqrt{e^2 r \log\parenth{\frac{6\cdot 2^\ossymb \sqrt \nin (\log_4 \nin-\ossymb)}{\delta} }} + \sqrt{\lambda_{r+1}(\Ktilde) \cdot 2^{\ossymb-1}\sqrt \nin}} \biggr)^2.
\end{talign}
%
\end{theorem}

%
%
%
%
%
%

%
\subsection{\pcref{thm:ctt_power_detailed}}\label{proof:ctt_power_detailed}
%
Recall the following definition from \citet[Def.~3]{shetty2022distributioncompressionnearlineartime}.
\begin{definition}[\tbf{$\k$-sub-Gaussian thinning algorithm}]
\label{def:k_sub_gsn_thinning_algo}
We say a thinning algorithm \alg (satisfying \cref{def:thinning_algo}) is $\k$-sub-Gaussian on an event $\event$ with shift $a$ and parameter $v$ if 
\begin{talign}\label{eq:k-sub-gsn-thinning-algo}
    \Pevent(\mmd_{\k}(\Pin, \Qout) \geq a + v \sqrt t \mid \xin) \leq e^{-t} \qtext{for all} t\geq 0.
\end{talign}

\end{definition}

Fix $\Ktilde\in\{\K,\K'\}$. To conclude our power result, it suffices,  by \citet[Rmk.~2,~App.~B.1]{domingoenrich2023compresstestpowerfulkernel} and the failure probability setting of \citet[Lem.~11]{domingoenrich2023compresstestpowerfulkernel}, to establish that
\begin{talign}
    \error[\Ktilde]^2(\nin,\delta,\ossymb) &= 256(\log_4 \nin - \ossymb -1) (\ckk(\delta,2^{\ossymb+1}\sqrt \nin) + \mkk(\delta,2^{\ossymb +1}\sqrt \nin) \sqrt{\log(\frac{3 \nin (\log_4 \nin - \ossymb-1)}{\delta})})^2 \\
    &\qquad \cdot(\sqrt{\log(\nin+1)} + \sqrt{\log(2/\delta)})^2,\label{eq:error-inflation-factor}
\end{talign}
for any scalars $\ckk(\delta,2^{\ossymb+1}\sqrt \nin)$ and $\mkk(\delta,2^{\ossymb+1}\sqrt \nin)$ satisfying the property that, on an event of probability at least $1-\delta/2$, every call to $\halve \defeq \ktsplit(\frac{\ell^2}{\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)} \delta)$ 
%
with input size $\ell$ and output size $\ell/2$ is $\k$-sub-Gaussian (\cref{def:k_sub_gsn_thinning_algo}) with shift $a_{\ell,\nin,\Ktilde}$ and parameter $v_{\ell,\nin,\Ktilde}$ satisfying
\begin{talign}\label{eq:parameter-shift}
    a_{\ell,\nin,\Ktilde} = \frac{\ckk(\delta,\ell)}{\ell/2}\qtext{and}
    v_{\ell,\nin,\Ktilde} = \frac{\mkk(\delta,\ell)}{\ell/2} \sqrt{ \log(\frac{12 \nin 4^\ossymb (\log_4 \nin - \ossymb)}{\ell \delta}) }.
\end{talign}
Substituting 
$\mkk( \delta,2^{\ossymb+1}\sqrt \nin) = (2^{\ossymb}\sqrt \nin) v_{2^{\ossymb+1}\sqrt \nin, \nin, \Ktilde} \brackets{\log(\frac{12 \nin 4^\ossymb (\log_4 \nin - \ossymb)}{2^{\ossymb+1}\sqrt \nin \delta})}^{-\half}$ 
and
$\ckk(\delta,2^{\ossymb+1}\sqrt \nin) = (2^{\ossymb}\sqrt \nin) a_{2^{\ossymb+1}\sqrt \nin, \nin, \Ktilde}$ 
into \cref{eq:error-inflation-factor}, we obtain the sufficient condition 
\begin{talign}
\error[\Ktilde]^2(\nin,\delta,\ossymb) 
    &= 
256(\log_4 \nin - \ossymb -1) 
\cdot (2^\ossymb \sqrt \nin)^2 \cdot(\sqrt{\log(\nin+1)} + \sqrt{\log(2/\delta)})^2 \\
&\cdot\parenth{a_{2^{\ossymb+1}\sqrt \nin, \nin, \Ktilde} + v_{2^{\ossymb+1}\sqrt \nin, \nin, \Ktilde} \brackets{\log(\frac{12 \nin 4^\ossymb (\log_4 \nin - \ossymb)}{2^{\ossymb+1}\sqrt \nin \delta})}^{-\half} \sqrt{\log(\frac{3 \nin (\log_4 \nin - \ossymb-1)}{\delta})}}^2. \label{eq:error-inflation-factor-a-v}
\end{talign}

We now identify suitable $a_{\ell,\nin,\Ktilde}$ and $v_{\ell,\nin,\Ktilde}$ with the aid of the following lemma, proved in \cref{proof:K-subg-implies-k-subg}.
\begin{lemma}[\tbf{$(\K,\subg,\delta)$-sub-Gaussian thinning algorithms are $\k$-sub-Gaussian}]
\label{lem:K-subg-implies-k-subg}
Suppose $\alg$ is a $(\K,\subg,\delta)$-sub-Gaussian thinning algorithm, satisfying \cref{def:alg-subg} with an event $\event$ of probability at least $1-\delta/2$. Then $\alg$ is $\k$-sub-Gaussian (\cref{def:k_sub_gsn_thinning_algo}) on $\event$ with shift $a_{\nout,\nin,\K}$ and parameter $v_{\nout,\nin,\K}$ defined as
\begin{talign}
    a_{\nout,\nin,\K} \defeq \subg \sqrt{e} + \min_{r\leq \nin} \braces{\subg \sqrt{e^2 r} + \sqrt{\lambda_{r+1}(\K) (\frac{1}{\nout} - \frac{1}{\nin})}}
    \qtext{and} 
    v_{\nout,\nin,\K} \defeq \subg \sqrt{e}
    .
\end{talign}
%
\end{lemma}
By \cref{rkhd-sub-gaussian,lem:funct_subg_vector_subg}, $\kh(\frac{\ell^2}{\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)} \delta)$ with input size $\ell$ and output size $\ell/2$ is a $(\K,\subg,\frac{\ell^2}{\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)} \delta)$-sub-Gaussian thinning algorithm with 
\begin{talign}
\subg
    \leq
    \frac{2}{(\ell/2) \sqrt 3} \sqrt{\log\parenth{\frac{6 (\ell/2)\log_2(\ell/(\ell/2))}{\delta}\cdot \frac{\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)}{\ell^2}} \maxnorm{\K}} = \frac{2}{(\ell/2) \sqrt 3} \sqrt{\log\parenth{\frac{12 \nin 4^\ossymb (\log_4\nin -\ossymb) }{\ell \delta}} \maxnorm{\K}}.
\end{talign}
%
%
By \cref{lem:K-subg-implies-k-subg}, on an event of probability at least $1-\frac{\ell^2}{2\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)} \delta$, $\kh(\frac{\ell^2}{\nin 4^{\ossymb + 1}(\log_4 \nin - \ossymb)} \delta)$ with input size $\ell$ and output size $\ell/2$ is a $\k$-sub-Gaussian thinning algorithm with shift $a_{\ell,\nin,\Ktilde}$ and parameter $v_{\ell,\nin,\Ktilde}$ defined as
\begin{talign}
    a_{\ell,\nin,\Ktilde} &= \frac{2}{(\ell/2) \sqrt 3} \sqrt{\log\parenth{\frac{12 \nin 4^\ossymb (\log_4\nin -\ossymb) }{\ell \delta}} \maxnorm{\Ktilde}} \sqrt{e\log 2} \\
    &\qquad + \min_{r\leq \ell}\braces{\frac{2}{(\ell/2) \sqrt 3} \sqrt{\log\parenth{\frac{12 \nin 4^\ossymb (\log_4\nin -\ossymb) }{\ell \delta}} \maxnorm{\Ktilde}} \sqrt{e^2 r} + \sqrt{\lambda_{r+1}(\Ktilde)(\frac{1}{\ell/2} - \frac{1}{\ell})}} \qtext{and} \label{eq:kt-split-shift} \\
    v_{\ell,\nin,\Ktilde} &= \frac{2}{(\ell/2) \sqrt 3} \sqrt{\log\parenth{\frac{12 \nin 4^\ossymb (\log_4\nin -\ossymb) }{\ell \delta}} \maxnorm{\Ktilde}} \sqrt{e}. \label{eq:kt-split-parameter}
\end{talign}
Moreover, by the union bound, as detailed in \citet[App.~F.1]{shetty2022distributioncompressionnearlineartime}, every \halve call made by \ktcompress is simultaneously $\k$-sub-Gaussian with these input-size-dependent parameters on a common event of probability at least $1-\frac{\delta}{2}$. 
Substituting \cref{eq:kt-split-shift,eq:kt-split-parameter} with $\ell = 2^{\ossymb+1} \sqrt \nin$ into \cref{eq:error-inflation-factor-a-v}, we obtain our error inflation factor expression \cref{eq:Rkxin}, completing the proof. 


\subsection{\pcref{lem:K-subg-implies-k-subg}}
\label{proof:K-subg-implies-k-subg}
Fix any $t\geq 0$, and let $\delta'=e^{-t}$. 
By our sub-Gaussian assumption, 
\cref{thm:mmd-kernel-compression} implies that, as advertised, 
\begin{talign}
e^{-t}
    &\geq
\Psubarg{\event}{\mmd_\K^2(\pin, \qout) \geq \min_{r\leq \nin}\subg^2 \brackets{e^2 r + e t} + \lambda_{r+1}(\K)(\frac{1}{\nout} - \frac{1}{\nin})} \\
    &=
\Psubarg{\event}{\mmd_\K(\pin, \qout) \geq \min_{r\leq \nin}\sqrt{\subg^2 \brackets{e^2 r + e t} + \lambda_{r+1}(\K)(\frac{1}{\nout} - \frac{1}{\nin})}} \\
    &\geq
\Psubarg{\event}{\mmd_\K(\pin, \qout) \geq \subg \sqrt{e}\sqrt{t} + \min_{r\leq \nin}\subg\sqrt{ e^2 r} + \sqrt{\lambda_{r+1}(\K)(\frac{1}{\nout} - \frac{1}{\nin})}}.
\end{talign}


%


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%