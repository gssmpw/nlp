\section{Related Works}
\subsection{Lightweight Visual Tracking}

Lightweight visual tracking has advanced significantly with the rise of Siamese-based methods. Early methods, such as SiamFC **Bertinetto et al., "Sticky-Things: Mere Image Priors for Robust Visual Tracking"** and ECO **Danelljan et al., "ECO: Efficient Convolution Operators for Tracking Using Multiscale Features"**, achieve real-time performance on edge devices. However, their tracking accuracy remains inferior compared to state-of-the-art trackers. Recently, more efficient trackers have been introduced. Yan \emph{et al.} **Yan et al., "Efficient Visual Tracking via Neural Architecture Search"** employ neural architecture search (NAS) to design efficient and compact models for resource-constrained hardware. Borsuk \emph{et al.} **Borsuk et al., "Dual-Template-Based Lightweight Tracker for Real-Time Object Tracking"** introduce a dual-template-based lightweight tracker, combining static and dynamic templates to handle appearance changes. Gopal \emph{et al.} **Gopal et al., "Mobile Vision Transformer for Real-Time Visual Tracking"** use Mobile Vision Transformer to integrate features from both the template and search regions, improving localization and classification for tracking. These advancements underline the focus on creating robust, real-time tracking solutions suitable for practical applications on mobile platforms. However, these methods often compromise on discriminative ability due to their simplified architectures.

\subsection{Contrastive Learning}
Contrastive learning is a self-supervised technique that aims to distinguish between positive pairs (augmentations of the same instance) and negative pairs (augmentations of different instances). It has shown promise in various computer vision tasks by learning effective feature representations **Chen et al., "Improved Baselines with Momentum Contrast for Self-Supervised Learning"**. In the filed of visual tracking, contrastive learning has also been employed to improve instance and category-level representation. Pi \emph{et al.} **Pi et al., "Contrastive Visual Tracking: Improving Inter-Instance Separability and Intra-Instance Compactness via Instance-Aware and Category-Aware Modules"** leverage instance-aware and category-aware modules combined with video-level contrastive learning to enhance inter-instance separability and intra-instance compactness. Wu \emph{et al.} **Wu et al., "Unsupervised Visual Tracking via Noise-Robust Temporal Mining Strategies and Contrastive Learning"** employ contrastive learning in an unsupervised framework, using noise-robust temporal mining strategies to generate positive and negative pairs, thereby improving temporal consistency. While these methods improve robustness, they lack a focus on lightweight design, which is crucial for real-time applications. Dan \emph{et al.} **Dan et al., "Contrastive Learning-Based Feature Matching for Real-Time UAV Tracking"** specifically targets UAV tracking by utilizing contrastive learning within video frames to enhance feature discrimination against occlusion. However, the contrastive module is not used during inference, limiting its ability to distinguish targets from distractors in real-world tracking scenarios. In this paper, we address these gaps by incorporating a contrastive learning-based feature matching module that operates during both training and inference within a lightweight Siamese framework, ensuring accurate and efficient tracking even in resource-constrained applications.