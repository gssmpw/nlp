\section{Related Work}
\label{sec:rel_work}

Related work is summarized through an overview of autonomous driving datasets, as well as models for multi-object tracking, trajectory forecasting, and intention prediction.

\subsection{Autonomous Driving Datasets}
Evaluating the effectiveness of autonomous driving algorithms requires testing across a diverse range of scenarios to assess performance under various conditions. Each scenario presents unique challenges and variability that models must navigate to be considered viable for real-world application. In recent years, numerous datasets, such as KITTI \cite{Geiger2013IJRR}, KITTI-360 \cite{Liao2022PAMI}, ApolloScape \cite{10.1609/aaai.v33i01.33016120}, PIE \cite{9008118}, NuScenes \cite{nuscenes2019}, WAYMO \cite{9709630}, Argoverse I \cite{Argoverse}, Argoverse II \cite{Argoverse2,TrustButVerify}, and Lyft Level 5 \cite{Houston2020OneTA}, have been introduced to support research in tasks such as detection, segmentation, tracking, prediction, intention prediction, and planning.

Among intention prediction datasets, the NGSIM\footnote{ http://ops.fhwa.dot.gov/trafficanalysistools/ngsim.
htm} and HighD \cite{10.1109/ITSC.2018.8569552} datasets focus on highway scenarios. NGSIM provides intention labels for lane-changing, lane-keeping, merging, and yielding, while HighD includes labels for free-driving, vehicle following, critical maneuvers, and lane-changing. HighD offers high-resolution highway data with trajectories spanning approximately 13 seconds per vehicle. NuScenes \cite{nuscenes2019} and Argoverse \cite{Argoverse} datasets cover urban driving, providing multimodal sensor data. The NuScenes dataset includes intentions such as moving, stopped, and parked. Argoverse contains maneuvers for lane changes, lane keeping, and left/right turns. The INTERACTION dataset \cite{zhan2019interactiondatasetinternationaladversarial} focuses on challenging environments like roundabouts, intersections, and highways, providing intention labels for lane changes, merging, and yielding, which are essential for interaction-aware trajectory prediction. BLVD dataset \cite{xue2019blvdbuildinglargescale5d} offers diverse behavior and interaction annotations for urban driving, capturing a wide range of maneuvers such as lane changing, lane keeping, accelerating, decelerating, stopping, and left/right turns. This dataset supports both tracking and maneuver intention tasks through multi-camera video data. Lastly, the InD dataset \cite{9304839} includes intention labels for actions such as merging, yielding, and left/right turns, with annotations similar to BLVD for vehicles, pedestrians, and riders.

The designed EMT dataset complements existing datasets by introducing data collected from a previously underrepresented geographical location. By including diverse driving scenarios typical for the Arab Gulf-region traffic, the EMT dataset provides a unique context for improving models' predictive accuracy in culturally and regionally distinct driving behaviors.

\subsection{Multi-object Tracking}
Multi-object tracking (MOT) methods encompass a variety of approaches, including tracking-by-detection \cite{8296962, 9010033} and joint detection and tracking \cite{zhang2021fairmot, 10.1007/978-3-030-58621-8_7}. Tracking-by-detection methods first detect objects in each frame and then associate them across frames. SORT \cite{8296962} serves as a lightweight and efficient baseline in this category, combining object detections with a Kalman Filter for motion prediction and the Hungarian algorithm for data association. Tracktor \cite{9010033}, on the other hand, eliminates the need for explicit data association by reusing regression heads in object detectors to refine and propagate tracks. Joint detection and tracking approaches integrate object detection and tracking into a unified pipeline. FairMOT \cite{zhang2021fairmot} optimizes a shared CNN backbone for simultaneous detection and re-identification, operating in crowded scenes. The Joint Detection and Embedding (JDE) tracker \cite{10.1007/978-3-030-58621-8_7} generates detections and embeddings in real-time by sharing features between tasks and optimizing with a multi-task loss.

Kalman filter-based trackers \cite{BoT-SORT, bytetrack, 8296962, 10406854,10160328} use motion prediction to refine trajectory estimation and handle missing detections. OC-SORT \cite{cao2023observation} builds upon SORT by introducing motion consistency constraints, addressing fragmentation in crowded scenarios. ByteTrack \cite{bytetrack} employs Kalman Filters to ensure accurate motion estimation during association.

\subsection{Trajectory Prediction Methods}

The field of trajectory prediction is extensively studied and encompasses various methodologies, including physics-based models, probabilistic approaches, and learning-based techniques. The presented related work focuses on deep-learning methods relevant to our evaluation framework: LSTM-based models, Transformer-based architectures, and Graph Neural Networks (GNNs).

\subsubsection{LSTM-based methods}

LSTM-based models have proven effective in capturing the temporal dependencies inherent in trajectory data. Early approaches, such as Social-LSTM \cite{7780479}, introduced the concept of social pooling to model interactions among agents, establishing a foundation for socially-aware trajectory prediction. Subsequent variants, including SSCN-LSTM \cite{Varshneya2017HumanTP} and SR-LSTM \cite{zhang2019srlstmstaterefinementlstm}, extended these capabilities by integrating spatial context and message-passing mechanisms, thereby enhancing their ability to represent dynamic interactions in multi-agent environments.

Several works have improved LSTM architectures by integrating environmental and spatial factors. Scene-LSTM \cite{Manh2018SceneLSTMAM} utilized a grid-based scene representation to capture interactions between agents and static objects, while MX-LSTM \cite{Hasan2018MXLSTMMT} combined trajectory data with head pose estimations to model multimodal behavior. GC-VRNN \cite{Xu2023UncoveringTM} extended this concept further by incorporating graph-based representations to manage incomplete data and complex temporal dependencies. TraPHic \cite{8954462} demonstrated the effectiveness of combining CNNs with LSTMs to handle heterogeneous traffic conditions.

Architectural advancements have also enabled multimodal and hierarchical designs. For example, stacked LSTMs \cite{10.1109/IVS.2018.8500493}, hierarchically process trajectory data to predict maneuver-specific behaviors, while encoder-decoder frameworks \cite{Zyner2018NaturalisticDI}, utilize Gaussian Mixture Models for probabilistic trajectory predictions. Other works, like STS-LSTM \cite{zhang_lstm_2023} and Highway-LSTM \cite{8317913} highlight the adaptability of LSTMs in specialized use cases, such as spectral trajectory modeling or highway motion forecasting.

\subsubsection{Transformers} Transformer-based models are highly effective in capturing long-range dependencies, which are crucial for understanding agent motion over time. STAR \cite{yu2020spatiotemporalgraphtransformernetworks} leverages Transformers to model individual pedestrian dynamics and graph-based spatial Transformers for crowd interactions, using alternating layers for joint spatio-temporal modeling. Similarly, GA-STT \cite{Zhou2022GASTTHT} employs cross-attention to fuse spatial and temporal embeddings, effectively capturing both individual and group-level motion features. HiVT \cite{9878832} adopts a two-stage approach, with the first stage focusing on extracting local context and the second stage integrating global interactions.

For social interaction modeling, AgentFormer \cite{9710708} utilizes an agent-aware Transformer with tailored attention mechanisms for intra-agent and inter-agent interactions. LatentFormer \cite{Amirloo2022LatentFormerMT} introduces hierarchical attention to capture social interactions and employs Vision Transformers to extract contextual scene features. Several models integrate GNNs with Transformers, such as Graph-Based Transformers \cite{Li2022GraphbasedST, zhang_2022, 10504962}, which model structured representations of agent-agent and agent-environment relationships, highlighting the synergy between graph representations and Transformer architectures for structured interaction data.

In the context of multimodal integration, the literature explores combining heterogeneous input modalities, such as map information, bounding boxes, and scene semantics. mmTransformer \cite{9577819} integrates a motion extractor for past trajectories, a map aggregator for road topology, and a social constructor to model agent interactions. MacFormer \cite{Feng_2023} builds upon this by incorporating map constraints and Crossmodal Transformers \cite{9812226} further advance this approach by fusing cross-relation features between modality pairs, supported by a modality attention module.

\subsubsection{GNN-based methods}
GNN models represent traffic scenes as graphs, where nodes correspond to agents and edges encode relationships, typically based on proximity. Graph Convolution Networks (GCN)-based models focus on spatial relationships and dynamic interaction modeling. GRIP \cite{8917228} alternates between temporal convolutional layers and graph operations to encode motion features and spatial interactions, while its extension, GRIP++ \cite{Li2019GRIPEG}, enhances this by incorporating dynamic edge weights and scene context. LaneGCN \cite{liang2020learning} integrates HD map data using lane graphs, and Trajectron++ \cite{10.1007/978-3-030-58523-5_40} combines GCNs with recurrent architectures to process spatiotemporal graphs enriched with semantic features.

Another line of work relies on Graph Attention Networks (GAT). GAT-based models use attention mechanisms to prioritize influential interactions dynamically. Social-BiGAT \cite{e294141389194a54a05536938fcdd509} combines GATs with generative frameworks for multimodal forecasting. GATraj \cite{CHENG2023163} introduces a Laplacian mixture decoder to enhance prediction diversity while modeling spatial-temporal dependencies, and GraphTCN \cite{Wang2020GraphTCNSI} integrates GATs with temporal convolutional networks (TCNs) to efficiently capture long-term dependencies.

Hierarchical and hybrid approaches combine multiple techniques for comprehensive modeling. MFTraj \cite{Liao2024MFTrajMB} uses dynamic geometric graphs and adaptive GCNs to model spatiotemporal dependencies. GOHOME \cite{10.1109/ICRA46639.2022.9812253} and MTP-GO \cite{Westny2023MTPGOGP} adopt graph-based methods for agent-map interactions, with MTP-GO employing neural ODEs to manage dynamic motion constraints. EqMotion \cite{10205349} ensures interaction invariance and geometric equivariance, providing stable and consistent trajectory predictions.

\subsection{Intention Prediction Methods}

Intention-aware models represent an important direction in trajectory prediction, aiming to enhance accuracy by incorporating agentsâ€™ maneuver intentions. These methods \cite{7487409, Deo2018HowWS} treat maneuvers as short-term, goal-driven decisions that consist of a sequence of continuous states working toward a global objective. Maneuvers are typically categorized into lateral decisions, such as lane-keeping, lane-changing, or turning, and longitudinal decisions, such as maintaining speed, accelerating, or braking. By integrating maneuver awareness, these models introduce an intermediate reasoning layer that informs predictions with planning-based logic.

Several LSTM-based models have demonstrated success in intention prediction. Occupancy-LSTM \cite{Kim2017ProbabilisticVT} generates occupancy grid maps by modeling surrounding vehicle motions, capturing likely maneuvers such as lane changes. Similarly, Zyner et al. \cite{10.1109/IVS.2017.7995919} and Phillips et al. \cite{Phillips2017GeneralizableIP} employ LSTMs to predict driver intentions, using features like heading, position, and velocity, with a particular focus on intersections. MX-LSTM \cite{Hasan2018MXLSTMMT} extends this capability by incorporating head pose data, providing an additional layer of contextual awareness to better infer maneuver intentions.
