\section{Dataset}
\label{sec:dataset}

In this section, the key aspects of the EMT dataset are introduced, including the data collection process, design methodology, and annotations format. 

\begin{table*}[t]
\centering
\caption{Object classes description and statistics.}
\begin{tabular}{|p{3cm}|p{10cm}|c|c|}
\hline
\textbf{Class} & \textbf{Description} & \textbf{\makecell{Number of \\ Bounding Boxes}} & \textbf{\makecell{Number of \\ Agents}} \\  \hline
Pedestrian & An individual walking on foot.  & 24,574 & 568 \\ \hline
Cyclist & Any bicycle or electric bike rider. & 594 & 14  \\ \hline
Motorbike & Includes motorcycles, bikes, and scooters with two or three wheels. & 11,294 & 159 \\ \hline
Car & Any standard automobile. & 429,705 & 6,559 \\ \hline
Small motorized vehicle & Motorized transport smaller than a car, such as mobility scooters and quad bikes. & 767 & 13 \\ \hline
Medium vehicle &  Includes vehicles larger than a standard car, such as vans or tractors. & 51,257 & 741 \\ \hline
Large vehicle & Refers to vehicles larger than vans, such as lorries, typically with six or more wheels. & 37,757 & 579 \\ \hline
Bus & Covers all types of buses, including school buses, single-deck, double-deck. & 19,244 & 200 \\ \hline
Emergency vehicle & Emergency response units like ambulances, police cars, and fire trucks, distinguished by red and blue flashing lights. & 1,182 & 9 \\ \hline
\multicolumn{2}{|r|}{\textit{\textbf{Overall:}}} & \textbf{576,374} & \textbf{8,842} \\ \hline
\end{tabular}
\label{tab:classes_desc}
\end{table*}



\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{figures/agents.pdf}
\caption{Samples of annotated agents, including small motorized vehicles, medium and large vehicles, emergency vehicles, buses, motorbikes (comprising motorbike and rider), and cyclists (comprising bicycle and rider).}
\label{fig:agents}
\end{figure*}


\subsection{Data collection}
The EMT dataset was collected in two major cities in the UAE - Abu Dhabi and Dubai, as well as on the roads connecting these cities. Data collection was conducted using two vehicles equipped with front-facing cameras. Each vehicle was outfitted with a VANTRUE 3-Channel Dash Camera, recording at 1080P Full HD. The video footage captures a variety of road topologies common in the region, including highways, roundabouts, bridges, city junctions, intercity highways, and narrow urban streets. The dash cameras recorded video sequences at a frame rate of 30 fps, saved as 3-minute clips. For the annotation process, frames were extracted at 10 fps. No pre-processing was applied to remove flashes or blurring caused by bumpy sections along some routes, as this aspect was left for future research to integrate as part of model design. Videos were carefully selected to represent a range of weather conditions, times of day, and scene types. This selection includes recordings during bright daylight, evening, and nighttime, under clear and rainy weather conditions. This diverse collection ensures the inclusion of the most common scenes encountered in the Arab Gulf region. Each video clip lasts between 2.5 and 3 minutes, totaling approximately 57 minutes of video data in the dataset.


\subsection{Data Annotations}
Every significant object and actor within each frame is annotated, including vehicles, pedestrians, small motorized vehicles, motorbikes, and cyclists. For objects classification and description we relied on convention presented in \cite{9712346}. Small motorized vehicles refer to any motorized vehicle smaller than a car, such as mobility scooters or quad bikes. Medium vehicles include those larger than a car, such as vans, while large vehicles refer to lorries, typically characterized by having six or more wheels. Emergency vehicles include ambulances, police cars, and fire engines equipped with red and blue flashing lights, excluding vehicles with yellow flashing lights, such as road maintenance vehicles. Each object is assigned an intention label based on its observed behavior. Table \ref{tab:classes_desc} provides for each class description, number of bounding boxes and number of agents throughout the whole dataset.

For vehicles, the intention reflects the current maneuver being performed, while for pedestrians, it represents their activity. The most common maneuver for vehicles is lane-keeping, where the vehicle maintains its current lane and follows a steady trajectory without deviation. The labels "merge left" and "merge right" are used when a vehicle moves to an adjacent lane, merges, or exits a main road. Turning maneuvers, such as "turn left" and "turn right," are assigned when a vehicle turns at an intersection or road junction, typically involving a reduction in speed and a change in direction. Braking indicates deceleration, often observable through activated brake lights in image-based data. Reversing refers to backward movement, which is commonly observed in parking areas or near road edges. Stop is used when a vehicle has come to a complete halt, such as at an intersection waiting for a green light or in parking areas. For pedestrians, the intention label walking denotes movement along a road or sidewalk at a steady pace without any apparent intent to cross the road. Waiting to cross is used when a pedestrian is facing oncoming traffic, signaling potential preparation to cross. Crossing applies when a pedestrian moves across the road, whether at junctions, designated crossings, or random locations, as long as the movement involves passing in front of a vehicle. The stop label indicates that the pedestrian is stationary, such as standing on a pavement or waiting at a bus stop. This annotation approach provides a comprehensive foundation for analyzing and understanding dynamic interactions between agents within road scenes.

The most common road topologies for the region are illustrated in Figure \ref{fig:junction}. One observed scenario involves bridges appearing above the ego vehicle in the images. Vehicles on these bridges are ignored as they do not influence the ego vehicle's planning. Figure \ref{fig:junction}(a) depicts a typical large city junction common in the region. A key feature of such junctions, compared to those in other areas, is the inclusion of a free right turn to alleviate traffic congestion. Cases (3) and (4) highlight this scenario: vehicles can make a free right turn from the traffic lights if no pedestrians are present and the turn does not interfere with other traffic. Otherwise, they must wait to complete the turn and merge safely onto the intended road. For clarity, the figure also includes other typical scenarios: (1) a car waiting at the junction for the green light; (2) a bus crossing the junction from left to right while staying in the same lane; (3) a car performing a free right turn to merge into a lane; (4) a car slowing down to allow a pedestrian to cross, tagged with the action "braking"; and (5) a pedestrian standing on the pavement, waiting for the car to stop before crossing safely. Figure \ref{fig:junction}(b) schematically depicts a roundabout with eight access points, showing vehicles in various stages: approaching, circulating inside, and exiting. When the ego vehicle intends to enter the roundabout, it must monitor agents in the outer or both lanes, depending on its intended exit, to avoid collisions. Each vehicle within the roundabout is labeled with an intention, such as "entering," "waiting to enter," "moving within the roundabout," or "exiting," to provide a clear understanding of its behavior. Lastly, Figure \ref{fig:junction}(c) represents a typical highway layout for the region. It illustrates cases where a vehicle exits the highway and gradually separates from the main road. When a vehicle begins exiting by curving right and changing lanes, its intention is labeled as "merge-right." Once the vehicle has exited, the label remains "keep-lane" until the vehicle disappears from the ego vehicleâ€™s field of vision. All scenarios are supplemented with corresponding frames from the dataset.

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{figures/scenarios.pdf}
\caption{Common traffic scenarios in the UAE include: (a) large city junctions, often featuring unique elements like free right turns to reduce congestion, (b) roundabouts with vehicles navigating through various stages such as approaching, circulating, and exiting, and (c) highways with exits, where vehicles transition smoothly by merging into designated lanes and exiting the main road.}
\label{fig:junction}
\end{figure*}

\begin{table*}[t]
\centering
\caption{Description of Collected Videos}
\begin{tabular}{|p{2.7cm}|p{1.4cm}|p{1.7cm}|p{1.3cm}|p{1.4cm}|p{1.4cm}|p{1.4cm}|p{3cm}|}
\hline
\textbf{Videos (Train/Test)} & \textbf{Number of Bounding Boxes} & \textbf{Mean Density of Agents per frame} & \textbf{Resolution}  & \textbf{Location} & \textbf{Lightning Conditions} & \textbf{Weather Conditions}  & \textbf{Road Elements} \\ \hline
video\_115533 \textit{(train)} & \centering 38,841 & \centering 21.6 & \centering 2560x1440 & \multirow{10}{*}{Abu Dhabi}  & \multirow{5}{*}{day} &  \multirow{5}{*}{clear} &  \multirow{2}{*}{driving in city, highways}  \\ \cline{1-4}
video\_115833 \textit{(train)}  & \centering 47,433 & \centering 26.3 & \centering 2560x1440 & & & & \\ \cline{1-4} \cline{8-8}
video\_122233 \textit{(test)} &  \centering 27,194 & \centering 15.1 & \centering 2560x1440  & & & & leaving city, highways \\ \cline{1-4} \cline{8-8}
video\_141733 \textit{(train)}  & \centering 23,135 & \centering 12.7 & \centering 896x672 & & & &   \multirow{2}{*}{driving in city, junctions}  \\ \cline{1-4} 
video\_161205 \textit{(train)}  & \centering 35,771 & \centering 19.6 & \centering 896x672 & & & &  \\  \cline{1-4} \cline{6-8} 
video\_151901 \textit{(train)}  &  \centering  29,107 &  \centering  22.2 & \centering 3840x2160 & &  \multirow{6}{*}{evening} &  \multirow{2}{*}{clear} & driving in city, at parking  \\ \cline{1-4} \cline{8-8}
video\_143739 \textit{(train)}  & \centering 46,894 & \centering 26 & \centering 3840x2160 & & & & straight road  \\ \cline{1-4} \cline{7-8}
video\_142911 \textit{(train)} & \centering 25,573 & \centering 14.2 & \centering 3840x2160 & & & heavy rain &  straight road \\ \cline{1-4} \cline{7-8}
video\_155425 \textit{(test)}  & \centering 18,485 & \centering 13.9 & \centering 3840x2160 & & & \multirow{2}{*}{rainy} &  driving in city, at roundabout, merging main road \\ \cline{1-4} \cline{8-8}
video\_160325 \textit{(test)} & \centering 20,581 & \centering 11.4 & \centering 3840x2160 & & & & driving in city, straight road  \\ \cline{1-8}
video\_054604 \textit{(train)} & \centering 45,576 & \centering 25.3 & \centering 2560x1440 & \multirow{10}{*}{Dubai} & \multirow{4}{*}{day} &  \multirow{4}{*}{clear} & driving in city, highways  \\  \cline{1-4} \cline{8-8}
video\_054907  \textit{(train)} & \centering 52,981 & \centering 29.4 & \centering 2560x1440 & & & &   leaving city, highways  \\ \cline{1-4} \cline{8-8}
video\_125233 \textit{(test)} & \centering 31,882 & \centering 17.7 & \centering 2560x1440 & & & & urban area, highways  \\ \cline{1-4} \cline{8-8}
video\_131333 \textit{(train)} & \centering 21,873 & \centering 13.5 & \centering 2560x1440  & & &  &  urban area, highways, bridges  \\ \cline{1-4} \cline{6-8}
video\_204347 \textit{(test)} & \centering 12,283 & \centering 6.8 & \centering 2560x1440  & & \multirow{6}{*}{evening} & \multirow{6}{*}{clear} &  driving in city, bridges  \\ \cline{1-4}  \cline{8-8}
video\_204647 \textit{(train)} & \centering 9,752 & \centering 5.4 & \centering 2560x1440  & & & & highways, bridges  \\ \cline{1-4}  \cline{8-8}
video\_174340 \textit{(train)} & \centering 24,249 & \centering 13.4 & \centering 2560x1440  & & & & driving in city,  highways \\ \cline{1-4}  \cline{8-8}
video\_214547 \textit{(train)} & \centering 35,404 & \centering 19.6 & \centering 2560x1440  & & & &  driving in city, highways, bridge  \\ \cline{1-4}  \cline{8-8}
video\_210906 \textit{(train)} & \centering 15,963 & \centering 8.86 &  \centering 2560x1440  & & & & \multirow{2}{*}{driving in city}  \\ \cline{1-4}
video\_220047 \textit{(train)} & \centering 13,397 & \centering 7.4 & \centering 2560x1440  & & & &   \\ \cline{1-4}
\hline
\end{tabular}
\label{tab:dataset}
\end{table*}

\begin{table*}[t]
\centering
\caption{Trajectory Prediction Settings: The notation 30/60 indicates the duration of the past trajectory and prediction horizon, measured in frames. This setup corresponds to 3 seconds of observed data followed by 6 seconds of predicted trajectory. Each row corresponds to different sliding window setting and shows the size of train and test datasets.}
\begin{tabular}{|p{3cm}|c|c|c|c|c|c|}
\hline
 & \textbf{10/10, 1s/1s} & \textbf{10/20, 1s/2s} & \textbf{20/10, 2s/1s} & \textbf{20/20, 2s/2s} & \textbf{20/30, 2s/3s}  & \textbf{20/60, 2s/6s} \\ \hline
sliding window = 1 & 268,504/71,097 & 234,969/64,007 & 234,969/64,007 & 210,709/58,637 & 191,772/54,335 & 151,218/44,989 \\ \hline
sliding window = 3 & 90,897/71,097 & 79,261/64,007 & 79,261/64,007 & 70,931/58,637 & 64,508/54,335 & 50,779/44,989  \\ \hline
sliding window = 5 & 55,408/71,097 & 48,159/64,007  & 48,159/64,007 & 43,020/58,637 & 39,057/54,335& 30,693/44,989  \\ \hline
\end{tabular}
\label{tab:prediction_datasets}
\end{table*}

\subsection{Annotations Format}

For Multi-Object Tracking, annotations are provided in two formats: GMOT and KITTI. Each videoâ€™s annotation file includes objects detected across frames, with bounding boxes defined by the $x$ and $y$ coordinates of the top-left and bottom-right corners. These files also include the agent's class and consistent tracking IDs for all objects. For trajectory and intention prediction datasets, the annotation format closely follows the PIE dataset \cite{9008118}. Each videoâ€™s annotation file contains all recorded objects, along with their unique IDs, agent classes, sequences of frames in which they appear, and corresponding sequences of bounding boxes. In intention prediction, each object additionally has an "intention" attribute that stores the sequence of intentions throughout its entire trajectory:

\begin{lstlisting}
[
    {
        "id": 4,
        "class": "Car",
        "frames": [1, 2, 3, 4],
        "bbox": [
            [1308.9649, 1031.4597, 1349.817, 1057.7218],
            [1305.2132, 1030.2091, 1346.0653, 1056.4712],
            [1303.1289, 1029.3754, 1340.6461, 1056.4712],
            [1304.3794, 1031.4597, 1338.9787, 1057.3049]
        ],
        "intention": ["lane-keeping", "lane-keeping", "lane-keeping", "lane-keeping"]
    },
    {
        "id": 12,
        "class": "Large_vehicle",
        "frames": [109, 110, 111, 112, 113],
        "bbox": [
            [1934.9579, 1036.7965, 1956.0014, 1054.1146],
            [1921.8802, 1038.1977, 1942.9237, 1055.5157],
            [1904.132, 1041.4671, 1925.1755, 1058.7852],
            [1887.3178, 1041.4671, 1908.3613, 1058.7852],
            [1872.839, 1040.5329, 1893.8825, 1057.851]
        ],
        "intention": ["turn-right", "turn-right", "turn-right", "braking", "braking"]
    }
]
\end{lstlisting}

To enhance usability, we supplement the annotations with a parsing script capable of generating custom settings by varying the size of past trajectories, prediction horizon, and overlaps. The script iterates through all objects and segments their trajectories into samples of past and future trajectories using a sliding window approach. For example, if the sliding window is set to 3 frames, the first sample will be generated starting from \textit{frame\_1}, and the next from \textit{frame\_4}. The default format is based on past observations and is structured as: \([past\_trajectory]\ [future\_trajectory]\). Table \ref{tab:prediction_datasets} presents various settings along with the sizes of the training and test datasets. Additionally, we provide a scene-centered generation option, with further details available in Section \ref{sec:Prediction}.

\subsection{EMT Statistics}

The dataset contains 20 videos, encompassing both day and night conditions, as well as a variety of weather scenarios, including rainy and clear weather. Table \ref{tab:dataset} provides details for each video, including the city, time of driving, weather conditions, and road topologies. In total, the dataset contains approximately 570,000 bounding boxes. The Table \ref{tab:dataset} also reports the mean density of agents per frame for each video, ranging from a minimum of around 6 agents per frame to a maximum of 30 agents, highlighting the density and diversity of the dataset.

\subsection{Annotation Tool}
The annotations were generated using the Basic.ai tool - annotation platform equipped with tracking algorithms, propagating bounding boxes across frames while maintaining consistent unique identifiers. Its robust tracking functionality was a key reason for its selection, significantly streamlining the annotation process. On average, each video required approximately 70 hours of annotation, completed by a professional human annotator.