

\documentclass{article}

\usepackage{xfrac}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %
\usepackage[table,xcdraw]{xcolor}

\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[preprint]{neurips_2024}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{subcaption}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\newcommand{\anvith}[1]{\textcolor{brown}{[Anvith: #1]}}
\newcommand{\yangjun}[1]{\textcolor{blue}{[Yangjun: #1]}}
\newcommand{\evianne}[1]{\textcolor{magenta}{[Evianne: #1]}}
\newcommand{\tristan}[1]{\textcolor{red}{[Tristan: #1]}}
\newcommand{\chris}[1]{\textcolor{pink}{[Chris: #1]}}

\input{macro}

\usepackage{authblk}
\renewcommand*{\Authsep}{, }
\renewcommand*{\Authand}{, }%
\renewcommand*{\Authands}{, }
\renewcommand*{\Affilfont}{\normalsize}
\setlength{\affilsep}{2em}

\title{MixMin: Finding Data Mixtures via Convex Minimization}

\author[1,2]{\textbf{Anvith Thudi}}
\author[1,3]{\textbf{Evianne Rovers}}
\author[1,2]{\textbf{Yangjun Ruan}}
\author[4]{\textbf{Tristan Thrush}}
\author[1,2]{\textbf{Chris J. Maddison}}

\affil[1]{University of Toronto}
\affil[2]{Vector Institute}
\affil[3]{Structural Genomics Consortium}
\affil[4]{Stanford University}


\begin{document}

\maketitle


\begin{abstract}
Modern machine learning pipelines are increasingly combining and mixing data from diverse and disparate sources, e.g., pre-training large language models. Yet, finding the optimal data mixture is a challenging and open problem. We formalize this data mixing problem as a bi-level objective: the best mixture is the one that would lead to the best model for a downstream objective. Unfortunately, this objective is generally intractable. In this paper, we make the observation that the bi-level data mixing objective becomes convex as our model class becomes larger. We develop and study a gradient-based approach for optimizing this convex objective, which we call MixMin, and test it on language modeling and chemistry tasks. MixMin was the only method that uniformly improved the data mixture in all our experiments. With MixMin, we improved the data mixture using less than $0.2\%$ additional compute for a pythia-$410M$ model trained on $8.2B$ tokens, resulting between 1-5\% relative improvement to negative log likelihood on PIQA, ARC Easy, SciQ, and OpenWebMath. Crucially, we found that MixMin mixtures for smaller models improved training of larger models, suggesting that MixMin mixtures may be scale-invariant. When mixing bioassay data to train an XGBoost model, we saw improvements to average precision scores of $0.03-0.15$.\footnote{Correspondence to \texttt{anvith.thudi@mail.utoronto.ca}}



\end{abstract}

\input{sections/Introduction}
\input{sections/Preliminaries}
\input{sections/Analysis}
\input{sections/Method}
\input{sections/Related_Work}
\input{sections/Experiments}
\input{sections/Conclusion}
\input{sections/Acknowledgements}



\bibliography{references}
\bibliographystyle{abbrvnat}

\newpage
\appendix

\input{sections/Appendix}

\end{document}
