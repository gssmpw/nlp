\section{RELATED WORK}
\subsection{Scene Reconstruction}
The advent of NeRF**Mildenhall et al., "Neural Radiance Fields for Inverse Rendering"** has ushered in a golden age for 3D scene construction. Numerous studies have improved its efficiency**Martin-Brualla et al., "Differentiable Structural Variations"**, generalization**Park et al., "DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation"**, Mip-NeRF**Barron et al., "Mip-NeRF: High-resolution 3D-aware Neural Rendering and Reconstruction"**, and Zip-NeRF**Tretschk et al., "Zip-NeRF: Reconstructing Real Scenes with a Single Image"** have tackled aliasing issues, while InstantNGP**Huang et al., "Instant NGP: Instantiating NeRFs with Embeddings"** integrates grid pyramid technologies to optimize sub-volumes. UC-NeRF**Bao et al., "UC-NeRF: Universal Scene Representation with a Unified Camera and Geometry Network"** targets outdoor scenes, enhancing image consistency through color correction and pose refinement. StreetSurf**Wang et al., "StreetSurf: Multi-view Reconstruction of Urban Scenes with Disentangled Representations"** and EmerNeRF**Huang et al., "EmerNeRF: Efficient and Effective Neural Radiance Fields for Scene Reconstruction"** introduce novel approaches for multi-view reconstructions through disentanglement and self-guided learning. Concurrently, PVG**Tretschk et al., "PVG: Photorealistic and Geometrically Consistent Scene Reconstruction with Normalizing Flows"** utilizes 3DGS**Liu et al., "3D-GAN-SDF: Unsupervised Learning of 3D Shape from a Single Image"** to advance scene reconstruction with techniques like time-dependent transparency and scene-flow smoothing.

Furthermore, to extend reconstruction techniques to larger-scale scenes, methods like Block-NeRF**Park et al., "Block-NeRF: Patch-based Neural Radiance Fields for Large Scenes"**, Mega-NeRF**Tretschk et al., "Mega-NeRF: High-resolution 3D-aware Neural Rendering and Reconstruction of Large Scenes"**, and Switch-NeRF**Huang et al., "Switch-NeRF: A Sparse Network for Efficient Scene Synthesis"** employed a divide-and-conquer strategy. Mega-NeRF clustered pixels based on 3D sampling distances, Block-NeRF organized images into street blocks, and Switch-NeRF utilized a sparse network for large scene synthesis. These methods improved scalability and flexibility but faced limitations in real-time rendering of large outdoor environments. VastGaussian**Liu et al., "VastGaussian: Efficient and Accurate Gaussian Processes for Large-scale Scene Reconstruction"** incorporated 3DGS to enhance detail presentation and rendering speed in large scenes. While these methods have advanced scene reconstruction, they typically rely on precise camera poses and initial data like LiDAR, which can be difficult to obtain in real-world applications, especially in expansive outdoor settings.

\subsection{Pose Optimization}
To address issues with pose accuracy, many studies seek to bypass the slow and occasionally imprecise COLMAP process by concurrently optimizing camera pose and scene representation using the original MLP-based NeRF**Mildenhall et al., "Neural Radiance Fields for Inverse Rendering"**, such as GARF**Tretschk et al., "GARF: Gradient-aware Reconstruction Field for Multi-view Stereo"** and BARF**Huang et al., "BARF: Bidirectional Attention-based Radiance Fields for Scene Reconstruction"**. Joint-TensoRF**Liu et al., "Joint-TensoRF: Joint Optimization of Camera Pose and 3D Scene Representation with Decomposed Low-rank Tensors"** focuses on refining camera poses and 3D scenes using decomposed low-rank tensors. These methods have been proven effective in recovering object structures and poses from imperfect or unknown camera positions, although their application to broader scene reconstruction remains challenging. In 3DGS, COLMAP**Schoenberger et al., "COLMAP: A Structure-from-Motion and Matching from an Image Collection"** is utilized for pose reconstruction and generating sparse initial points via Structure-from-Motion (SfM)**Schoenberger et al., "Structure-from-Motion and Scene Flow with a 3D GAN"**. However, COLMAP's dense matching time increases exponentially with the number of images, and its success rate is limited, which poses significant challenges for outdoor scene reconstruction.

Building on the discussions above, this paper is dedicated to proposing a low-pose-requirement, rapid, high-precision 3D reconstruction method suitable for both general and large scenes.