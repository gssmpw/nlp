@article{chamberlin1981,
author = {Chamberlin, Donald D. and Astrahan, Morton M. and Blasgen, Michael W. and Gray, James N. and King, W. Frank and Lindsay, Bruce G. and Lorie, Raymond and Mehl, James W. and Price, Thomas G. and Putzolu, Franco and Selinger, Patricia Griffiths and Schkolnick, Mario and Slutz, Donald R. and Traiger, Irving L. and Wade, Bradford W. and Yost, Robert A.},
title = {A History and Evaluation of System R},
year = {1981},
issue_date = {Oct. 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/358769.358784},
doi = {10.1145/358769.358784},
abstract = {System R, an experimental database system, was constructed to demonstrate that the usability advantages of the relational data model can be realized in a system with the complete function and high performance required for everyday production use. This paper describes the three principal phases of the System R project and discusses some of the lessons learned from System R about the design of relational systems and database systems in general.},
journal = {Commun. ACM},
month = {oct},
pages = {632–646},
numpages = {15},
keywords = {recovery, locking, authorization, access path selection, relational model, database management systems, compilation}
}

@article{chou2018,
  title={Format abstraction for sparse tensor algebra compilers},
  author={Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
  journal={Proceedings of the ACM on Programming Languages},
  volume={2},
  number={OOPSLA},
  pages={1--30},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{emptyheaded,
  title={Emptyheaded: A relational engine for graph processing},
  author={Aberger, Christopher R and Lamb, Andrew and Tu, Susan and N{\"o}tzli, Andres and Olukotun, Kunle and R{\'e}, Christopher},
  journal={ACM Transactions on Database Systems (TODS)},
  volume={42},
  number={4},
  pages={1--44},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@book{fibertrees,
  author = {Vivienne Sze and Yu-Hsin Chen and Tien-Ju Yang and Joel S. Emer},
  year = {2020},
  title = {Efficient Processing of Deep Neural Networks},
  publisher = {Morgan \& Claypool Publishers}
}

@article{henry2017,
  author = {Henry, Rawn and Hsu, Olivia and Yadav, Rohan and Chou, Stephen and Olukotun, Kunle and Amarasinghe, Saman and Kjolstad, Fredrik},
  title = {Compilation of Sparse Array Programming Models},
  year = {2021},
  issue_date = {October 2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {5},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3485505},
  doi = {10.1145/3485505},
  journal = {Proc. ACM Program. Lang.},
  month = {oct},
  articleno = {128},
  numpages = {29},
  keywords = {Sparse Array Programming, Compilation, Sparse Arrays}
}

@inproceedings{hyper,
author = {Kemper, Alfons and Neumann, Thomas},
title = {HyPer: A Hybrid OLTP\&OLAP Main Memory Database System Based on Virtual Memory Snapshots},
year = {2011},
isbn = {9781424489596},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICDE.2011.5767867},
doi = {10.1109/ICDE.2011.5767867},
abstract = {The two areas of online transaction processing (OLTP) and online analytical processing (OLAP) present different challenges for database architectures. Currently, customers with high rates of mission-critical transactions have split their data into two separate systems, one database for OLTP and one so-called data warehouse for OLAP. While allowing for decent transaction rates, this separation has many disadvantages including data freshness issues due to the delay caused by only periodically initiating the Extract Transform Load-data staging and excessive resource consumption due to maintaining two separate information systems. We present an efficient hybrid system, called HyPer, that can handle both OLTP and OLAP simultaneously by using hardware-assisted replication mechanisms to maintain consistent snapshots of the transactional data. HyPer is a main-memory database system that guarantees the ACID properties of OLTP transactions and executes OLAP query sessions (multiple queries) on the same, arbitrarily current and consistent snapshot. The utilization of the processor-inherent support for virtual memory management (address translation, caching, copy on update) yields both at the same time: unprecedentedly high transaction rates as high as 100000 per second and very fast OLAP query response times on a single system executing both workloads in parallel. The performance analysis is based on a combined TPC-C and TPC-H benchmark.},
booktitle = {Proceedings of the 2011 IEEE 27th International Conference on Data Engineering},
pages = {195–206},
numpages = {12},
series = {ICDE '11}
}

@article{indexed-streams,
  title={Indexed Streams: A Formal Intermediate Representation for Fused Contraction Programs},
  author={Kovach, Scott and Kolichala, Praneeth and Gu, Tiancheng and Kjolstad, Fredrik},
  journal={Proceedings of the ACM on Programming Languages},
  volume={7},
  number={PLDI},
  pages={1169--1193},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{kersten2018,
  title={Everything you always wanted to know about compiled and vectorized queries but were afraid to ask},
  author={Kersten, Timo and Leis, Viktor and Kemper, Alfons and Neumann, Thomas and Pavlo, Andrew and Boncz, Peter},
  journal={Proceedings of the VLDB Endowment},
  volume={11},
  number={13},
  pages={2209--2222},
  year={2018},
  publisher={VLDB Endowment}
}

@article{kjolstad2017,
author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
title = {The Tensor Algebra Compiler},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133901},
doi = {10.1145/3133901},
abstract = {Tensor algebra is a powerful tool with applications in machine learning, data analytics, engineering and the physical sciences. Tensors are often sparse and compound operations must frequently be computed in a single kernel for performance and to save memory. Programmers are left to write kernels for every operation of interest, with different mixes of dense and sparse tensors in different formats. The combinations are infinite, which makes it impossible to manually implement and optimize them all. This paper introduces the first compiler technique to automatically generate kernels for any compound tensor algebra operation on dense and sparse tensors. The technique is implemented in a C++ library called taco. Its performance is competitive with best-in-class hand-optimized kernels in popular libraries, while supporting far more tensor operations.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {77},
numpages = {29},
keywords = {parallelism, iteration graphs, sparse data structures, tensors, merge lattices, code generation, tensor algebra, performance, linear algebra}
}

@article{klonatos2014,
author = {Klonatos, Yannis and Koch, Christoph and Rompf, Tiark and Chafi, Hassan},
title = {Building Efficient Query Engines in a High-Level Language},
year = {2014},
issue_date = {June 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/2732951.2732959},
doi = {10.14778/2732951.2732959},
abstract = {In this paper we advocate that it is time for a radical rethinking of database systems design. Developers should be able to leverage high-level programming languages without having to pay a price in efficiency. To realize our vision of abstraction without regret, we present LegoBase, a query engine written in the high-level programming language Scala. The key technique to regain efficiency is to apply generative programming: the Scala code that constitutes the query engine, despite its high-level appearance, is actually a program generator that emits specialized, low-level C code. We show how the combination of high-level and generative programming allows to easily implement a wide spectrum of optimizations that are difficult to achieve with existing low-level query compilers, and how it can continuously optimize the query engine.We evaluate our approach with the TPC-H benchmark and show that: (a) with all optimizations enabled, our architecture significantly outperforms a commercial in-memory database system as well as an existing query compiler, (b) these performance improvements require programming just a few hundred lines of high-level code instead of complicated low-level code that is required by existing query compilers and, finally, that (c) the compilation overhead is low compared to the overall execution time, thus making our approach usable in practice for efficiently compiling query engines.},
journal = {Proc. VLDB Endow.},
month = {jun},
pages = {853–864},
numpages = {12}
}

@misc{leapfrog-triejoin,
      title={Leapfrog Triejoin: a worst-case optimal join algorithm}, 
      author={Todd L. Veldhuizen},
      year={2013},
      eprint={1210.0481},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@inproceedings{lms,
author = {Rompf, Tiark and Odersky, Martin},
title = {Lightweight modular staging: a pragmatic approach to runtime code generation and compiled DSLs},
year = {2010},
isbn = {9781450301541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868294.1868314},
doi = {10.1145/1868294.1868314},
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but the effort required to develop high-quality program generators likely offsets their benefits, even if a multi-stage programming language is used.We present lightweight modular staging, a library-based multi-stage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process.We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a stand-alone implementation with only modest effort.},
booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
pages = {127–136},
numpages = {10},
keywords = {multi-stage programming, language virtualization, domain-specific languages, code generation},
location = {Eindhoven, The Netherlands},
series = {GPCE '10}
}

@article{menon2017,
author = {Menon, Prashanth and Mowry, Todd C. and Pavlo, Andrew},
title = {Relaxed Operator Fusion for In-Memory Databases: Making Compilation, Vectorization, and Prefetching Work Together at Last},
year = {2017},
issue_date = {September 2017},
publisher = {VLDB Endowment},
volume = {11},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/3151113.3151114},
doi = {10.14778/3151113.3151114},
abstract = {In-memory database management systems (DBMSs) are a key component of modern on-line analytic processing (OLAP) applications, since they provide low-latency access to large volumes of data. Because disk accesses are no longer the principle bottleneck in such systems, the focus in designing query execution engines has shifted to optimizing CPU performance. Recent systems have revived an older technique of using just-in-time (JIT) compilation to execute queries as native code instead of interpreting a plan. The state-of-the-art in query compilation is to fuse operators together in a query plan to minimize materialization overhead by passing tuples efficiently between operators. Our empirical analysis shows, however, that more tactful materialization yields better performance.We present a query processing model called "relaxed operator fusion" that allows the DBMS to introduce staging points in the query plan where intermediate results are temporarily materialized. This allows the DBMS to take advantage of inter-tuple parallelism inherent in the plan using a combination of prefetching and SIMD vectorization to support faster query execution on data sets that exceed the size of CPU-level caches. Our evaluation shows that our approach reduces the execution time of OLAP queries by up to 2.2\texttimes{} and achieves up to 1.8\texttimes{} better performance compared to other in-memory DBMSs.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {1–13},
numpages = {13}
}

@inproceedings{monetdb,
  title={MonetDB/X100: Hyper-Pipelining Query Execution.},
  author={Boncz, Peter A and Zukowski, Marcin and Nes, Niels},
  booktitle={Cidr},
  volume={5},
  pages={225--237},
  year={2005}
}

@article{ngo-skew,
author = {Ngo, Hung Q and R\'{e}, Christopher and Rudra, Atri},
title = {Skew Strikes Back: New Developments in the Theory of Join Algorithms},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/2590989.2590991},
doi = {10.1145/2590989.2590991},
journal = {SIGMOD Rec.},
month = {feb},
pages = {5–16},
numpages = {12}
}

@article{stonebraker1976,
author = {Stonebraker, Michael and Held, Gerald and Wong, Eugene and Kreps, Peter},
title = {The Design and Implementation of INGRES},
year = {1976},
issue_date = {Sept. 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/320473.320476},
doi = {10.1145/320473.320476},
abstract = {The currently operational (March 1976) version of the INGRES database management system is described. This multiuser system gives a relational view of data, supports two high level nonprocedural data sublanguages, and runs as a collection of user processes on top of the UNIX operating system for Digital Equipment Corporation PDP 11/40, 11/45, and 11/70 computers. Emphasis is on the design decisions and tradeoffs related to (1) structuring the system into processes, (2) embedding one command language in a general purpose programming language, (3) the algorithms implemented to process interactions, (4) the access methods implemented, (5) the concurrency and recovery control currently provided, and (6) the data structures used for system catalogs and the role of the database administrator.Also discussed are (1) support for integrity constraints (which is only partly operational), (2) the not yet supported features concerning views and protection, and (3) future plans concerning the system.},
journal = {ACM Trans. Database Syst.},
month = {sep},
pages = {189–222},
numpages = {34},
keywords = {protection, nonprocedural language, relational database, query language, data integrity, query decompositon, concurrency, database optimization, data organization, data sublanguage}
}

@article{volcano,
author = {Graefe, G.},
title = {Volcano— An Extensible and Parallel Query Evaluation System},
year = {1994},
issue_date = {February 1994},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {6},
number = {1},
issn = {1041-4347},
url = {https://doi.org/10.1109/69.273032},
doi = {10.1109/69.273032},
abstract = {To investigate the interactions of extensibility and parallelism in database query processing, we have developed a new dataflow query execution system called Volcano. The Volcano effort provides a rich environment for research and education in database systems design, heuristics for query optimization, parallel query execution, and resource allocation. Volcano uses a standard interface between algebra operators, allowing easy addition of new operators and operator implementations. Operations on individual items, e.g., predicates, are imported into the query processing operators using support functions. The semantics of support functions is not prescribed; any data type including complex objects and any operation can be realized. Thus, Volcano is extensible with new operators, algorithms, data types, and type-specific methods. Volcano includes two novel meta-operators. The choose-plan meta-operator supports dynamic query evaluation plans that allow delaying selected optimization decisions until run-time, e.g., for embedded queries with free variables. The exchange meta-operator supports intra-operator parallelism on partitioned datasets and both vertical and horizontal inter-operator parallelism, translating between demand-driven dataflow within processes and data-driven dataflow between processes. All operators, with the exception of the exchange operator, have been designed and implemented in a single-process environment, and parallelized using the exchange operator. Even operators not yet designed can be parallelized using this new operator if they use and provide the interator interface. Thus, the issues of data manipulation and parallelism have become orthogonal, making Volcano the first implemented query execution engine that effectively combines extensibility and parallelism.},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = {feb},
pages = {120–135},
numpages = {16},
keywords = {demand-driven dataflow, predicates, resource allocation, partitioned datasets, query processing operators, dynamic query evaluation plans, extensibility, data structures, Volcano, support functions, data type, query optimization, semantics, novel meta-operators, horizontal inter-operator parallelism, intra-operator parallelism, choose-plan meta-operator, algebra operators, data-driven dataflow, database query processing, type-specific methods., parallel query evaluation system, query processing, parallel programming, dataflow query execution system}
}

