@inproceedings{duckdb,
author = {Raasveldt, Mark and M\"{u}hleisen, Hannes},
title = {DuckDB: An Embeddable Analytical Database},
year = {2019},
isbn = {9781450356435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299869.3320212},
doi = {10.1145/3299869.3320212},
abstract = {The immense popularity of SQLite shows that there is a need for unobtrusive in-process data management solutions. However, there is no such system yet geared towards analytical workloads. We demonstrate DuckDB, a novel data management system designed to execute analytical SQL queries while embedded in another process. In our demonstration, we pit DuckDB against other data management solutions to showcase its performance in the embedded analytics scenario. DuckDB is available as Open Source software under a permissive license.},
booktitle = {Proceedings of the 2019 International Conference on Management of Data},
pages = {1981–1984},
numpages = {4},
location = {Amsterdam, Netherlands},
series = {SIGMOD '19}
}

@inproceedings{monetdb,
  title={MonetDB/X100: Hyper-Pipelining Query Execution.},
  author={Boncz, Peter A and Zukowski, Marcin and Nes, Niels},
  booktitle={Cidr},
  volume={5},
  pages={225--237},
  year={2005}
}

@article{emptyheaded,
  title={Emptyheaded: A relational engine for graph processing},
  author={Aberger, Christopher R and Lamb, Andrew and Tu, Susan and N{\"o}tzli, Andres and Olukotun, Kunle and R{\'e}, Christopher},
  journal={ACM Transactions on Database Systems (TODS)},
  volume={42},
  number={4},
  pages={1--44},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{menon2017,
author = {Menon, Prashanth and Mowry, Todd C. and Pavlo, Andrew},
title = {Relaxed Operator Fusion for In-Memory Databases: Making Compilation, Vectorization, and Prefetching Work Together at Last},
year = {2017},
issue_date = {September 2017},
publisher = {VLDB Endowment},
volume = {11},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/3151113.3151114},
doi = {10.14778/3151113.3151114},
abstract = {In-memory database management systems (DBMSs) are a key component of modern on-line analytic processing (OLAP) applications, since they provide low-latency access to large volumes of data. Because disk accesses are no longer the principle bottleneck in such systems, the focus in designing query execution engines has shifted to optimizing CPU performance. Recent systems have revived an older technique of using just-in-time (JIT) compilation to execute queries as native code instead of interpreting a plan. The state-of-the-art in query compilation is to fuse operators together in a query plan to minimize materialization overhead by passing tuples efficiently between operators. Our empirical analysis shows, however, that more tactful materialization yields better performance.We present a query processing model called "relaxed operator fusion" that allows the DBMS to introduce staging points in the query plan where intermediate results are temporarily materialized. This allows the DBMS to take advantage of inter-tuple parallelism inherent in the plan using a combination of prefetching and SIMD vectorization to support faster query execution on data sets that exceed the size of CPU-level caches. Our evaluation shows that our approach reduces the execution time of OLAP queries by up to 2.2\texttimes{} and achieves up to 1.8\texttimes{} better performance compared to other in-memory DBMSs.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {1–13},
numpages = {13}
}

@article{indexed-streams,
  title={Indexed Streams: A Formal Intermediate Representation for Fused Contraction Programs},
  author={Kovach, Scott and Kolichala, Praneeth and Gu, Tiancheng and Kjolstad, Fredrik},
  journal={Proceedings of the ACM on Programming Languages},
  volume={7},
  number={PLDI},
  pages={1169--1193},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{kjolstad2017,
author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
title = {The Tensor Algebra Compiler},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133901},
doi = {10.1145/3133901},
abstract = {Tensor algebra is a powerful tool with applications in machine learning, data analytics, engineering and the physical sciences. Tensors are often sparse and compound operations must frequently be computed in a single kernel for performance and to save memory. Programmers are left to write kernels for every operation of interest, with different mixes of dense and sparse tensors in different formats. The combinations are infinite, which makes it impossible to manually implement and optimize them all. This paper introduces the first compiler technique to automatically generate kernels for any compound tensor algebra operation on dense and sparse tensors. The technique is implemented in a C++ library called taco. Its performance is competitive with best-in-class hand-optimized kernels in popular libraries, while supporting far more tensor operations.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {77},
numpages = {29},
keywords = {parallelism, iteration graphs, sparse data structures, tensors, merge lattices, code generation, tensor algebra, performance, linear algebra}
}

@book{fibertrees,
  author = {Vivienne Sze and Yu-Hsin Chen and Tien-Ju Yang and Joel S. Emer},
  year = {2020},
  title = {Efficient Processing of Deep Neural Networks},
  publisher = {Morgan \& Claypool Publishers}
}

@inproceedings{ye2023,
  title={SparseTIR: Composable abstractions for sparse compilation in deep learning},
  author={Ye, Zihao and Lai, Ruihang and Shao, Junru and Chen, Tianqi and Ceze, Luis},
  booktitle={Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={660--678},
  year={2023}
}

@article{chou2018,
  title={Format abstraction for sparse tensor algebra compilers},
  author={Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
  journal={Proceedings of the ACM on Programming Languages},
  volume={2},
  number={OOPSLA},
  pages={1--30},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@misc{leapfrog-triejoin,
      title={Leapfrog Triejoin: a worst-case optimal join algorithm}, 
      author={Todd L. Veldhuizen},
      year={2013},
      eprint={1210.0481},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@misc{sqlite, 
  title={{SQLite}},
  url={https://www.sqlite.org/},
  version={3.42.0},
  year={2023},
  author={Hipp, Richard D}
}

@inproceedings{hyper,
author = {Kemper, Alfons and Neumann, Thomas},
title = {HyPer: A Hybrid OLTP\&OLAP Main Memory Database System Based on Virtual Memory Snapshots},
year = {2011},
isbn = {9781424489596},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICDE.2011.5767867},
doi = {10.1109/ICDE.2011.5767867},
abstract = {The two areas of online transaction processing (OLTP) and online analytical processing (OLAP) present different challenges for database architectures. Currently, customers with high rates of mission-critical transactions have split their data into two separate systems, one database for OLTP and one so-called data warehouse for OLAP. While allowing for decent transaction rates, this separation has many disadvantages including data freshness issues due to the delay caused by only periodically initiating the Extract Transform Load-data staging and excessive resource consumption due to maintaining two separate information systems. We present an efficient hybrid system, called HyPer, that can handle both OLTP and OLAP simultaneously by using hardware-assisted replication mechanisms to maintain consistent snapshots of the transactional data. HyPer is a main-memory database system that guarantees the ACID properties of OLTP transactions and executes OLAP query sessions (multiple queries) on the same, arbitrarily current and consistent snapshot. The utilization of the processor-inherent support for virtual memory management (address translation, caching, copy on update) yields both at the same time: unprecedentedly high transaction rates as high as 100000 per second and very fast OLAP query response times on a single system executing both workloads in parallel. The performance analysis is based on a combined TPC-C and TPC-H benchmark.},
booktitle = {Proceedings of the 2011 IEEE 27th International Conference on Data Engineering},
pages = {195–206},
numpages = {12},
series = {ICDE '11}
}

@article{chamberlin1981,
author = {Chamberlin, Donald D. and Astrahan, Morton M. and Blasgen, Michael W. and Gray, James N. and King, W. Frank and Lindsay, Bruce G. and Lorie, Raymond and Mehl, James W. and Price, Thomas G. and Putzolu, Franco and Selinger, Patricia Griffiths and Schkolnick, Mario and Slutz, Donald R. and Traiger, Irving L. and Wade, Bradford W. and Yost, Robert A.},
title = {A History and Evaluation of System R},
year = {1981},
issue_date = {Oct. 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/358769.358784},
doi = {10.1145/358769.358784},
abstract = {System R, an experimental database system, was constructed to demonstrate that the usability advantages of the relational data model can be realized in a system with the complete function and high performance required for everyday production use. This paper describes the three principal phases of the System R project and discusses some of the lessons learned from System R about the design of relational systems and database systems in general.},
journal = {Commun. ACM},
month = {oct},
pages = {632–646},
numpages = {15},
keywords = {recovery, locking, authorization, access path selection, relational model, database management systems, compilation}
}

@article{stonebraker1976,
author = {Stonebraker, Michael and Held, Gerald and Wong, Eugene and Kreps, Peter},
title = {The Design and Implementation of INGRES},
year = {1976},
issue_date = {Sept. 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {0362-5915},
url = {https://doi.org/10.1145/320473.320476},
doi = {10.1145/320473.320476},
abstract = {The currently operational (March 1976) version of the INGRES database management system is described. This multiuser system gives a relational view of data, supports two high level nonprocedural data sublanguages, and runs as a collection of user processes on top of the UNIX operating system for Digital Equipment Corporation PDP 11/40, 11/45, and 11/70 computers. Emphasis is on the design decisions and tradeoffs related to (1) structuring the system into processes, (2) embedding one command language in a general purpose programming language, (3) the algorithms implemented to process interactions, (4) the access methods implemented, (5) the concurrency and recovery control currently provided, and (6) the data structures used for system catalogs and the role of the database administrator.Also discussed are (1) support for integrity constraints (which is only partly operational), (2) the not yet supported features concerning views and protection, and (3) future plans concerning the system.},
journal = {ACM Trans. Database Syst.},
month = {sep},
pages = {189–222},
numpages = {34},
keywords = {protection, nonprocedural language, relational database, query language, data integrity, query decompositon, concurrency, database optimization, data organization, data sublanguage}
}

@article{klonatos2014,
author = {Klonatos, Yannis and Koch, Christoph and Rompf, Tiark and Chafi, Hassan},
title = {Building Efficient Query Engines in a High-Level Language},
year = {2014},
issue_date = {June 2014},
publisher = {VLDB Endowment},
volume = {7},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/2732951.2732959},
doi = {10.14778/2732951.2732959},
abstract = {In this paper we advocate that it is time for a radical rethinking of database systems design. Developers should be able to leverage high-level programming languages without having to pay a price in efficiency. To realize our vision of abstraction without regret, we present LegoBase, a query engine written in the high-level programming language Scala. The key technique to regain efficiency is to apply generative programming: the Scala code that constitutes the query engine, despite its high-level appearance, is actually a program generator that emits specialized, low-level C code. We show how the combination of high-level and generative programming allows to easily implement a wide spectrum of optimizations that are difficult to achieve with existing low-level query compilers, and how it can continuously optimize the query engine.We evaluate our approach with the TPC-H benchmark and show that: (a) with all optimizations enabled, our architecture significantly outperforms a commercial in-memory database system as well as an existing query compiler, (b) these performance improvements require programming just a few hundred lines of high-level code instead of complicated low-level code that is required by existing query compilers and, finally, that (c) the compilation overhead is low compared to the overall execution time, thus making our approach usable in practice for efficiently compiling query engines.},
journal = {Proc. VLDB Endow.},
month = {jun},
pages = {853–864},
numpages = {12}
}


@article{kersten2018,
  title={Everything you always wanted to know about compiled and vectorized queries but were afraid to ask},
  author={Kersten, Timo and Leis, Viktor and Kemper, Alfons and Neumann, Thomas and Pavlo, Andrew and Boncz, Peter},
  journal={Proceedings of the VLDB Endowment},
  volume={11},
  number={13},
  pages={2209--2222},
  year={2018},
  publisher={VLDB Endowment}
}

@misc{tpch,
    title={TPC Benchmark\texttrademark{} H},
    author={Transaction Processing Performance Council (TPC)},
    url={https://www.tpc.org/tpch/},
    year={2022},
    version={3.0.1}
}

@article{ngo-skew,
author = {Ngo, Hung Q and R\'{e}, Christopher and Rudra, Atri},
title = {Skew Strikes Back: New Developments in the Theory of Join Algorithms},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/2590989.2590991},
doi = {10.1145/2590989.2590991},
journal = {SIGMOD Rec.},
month = {feb},
pages = {5–16},
numpages = {12}
}

@inproceedings{multiset-table-algebra,
  title={A Formal Mathematical Semantics of Advanced Operations of Multiset Table Algebra},
  author={Glushko, Iryna},
  booktitle={Proceedings of the 7th International Conference on Information Technology},
  pages={369--375},
  year={2015}
}

@article{volcano,
author = {Graefe, G.},
title = {Volcano— An Extensible and Parallel Query Evaluation System},
year = {1994},
issue_date = {February 1994},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {6},
number = {1},
issn = {1041-4347},
url = {https://doi.org/10.1109/69.273032},
doi = {10.1109/69.273032},
abstract = {To investigate the interactions of extensibility and parallelism in database query processing, we have developed a new dataflow query execution system called Volcano. The Volcano effort provides a rich environment for research and education in database systems design, heuristics for query optimization, parallel query execution, and resource allocation. Volcano uses a standard interface between algebra operators, allowing easy addition of new operators and operator implementations. Operations on individual items, e.g., predicates, are imported into the query processing operators using support functions. The semantics of support functions is not prescribed; any data type including complex objects and any operation can be realized. Thus, Volcano is extensible with new operators, algorithms, data types, and type-specific methods. Volcano includes two novel meta-operators. The choose-plan meta-operator supports dynamic query evaluation plans that allow delaying selected optimization decisions until run-time, e.g., for embedded queries with free variables. The exchange meta-operator supports intra-operator parallelism on partitioned datasets and both vertical and horizontal inter-operator parallelism, translating between demand-driven dataflow within processes and data-driven dataflow between processes. All operators, with the exception of the exchange operator, have been designed and implemented in a single-process environment, and parallelized using the exchange operator. Even operators not yet designed can be parallelized using this new operator if they use and provide the interator interface. Thus, the issues of data manipulation and parallelism have become orthogonal, making Volcano the first implemented query execution engine that effectively combines extensibility and parallelism.},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = {feb},
pages = {120–135},
numpages = {16},
keywords = {demand-driven dataflow, predicates, resource allocation, partitioned datasets, query processing operators, dynamic query evaluation plans, extensibility, data structures, Volcano, support functions, data type, query optimization, semantics, novel meta-operators, horizontal inter-operator parallelism, intra-operator parallelism, choose-plan meta-operator, algebra operators, data-driven dataflow, database query processing, type-specific methods., parallel query evaluation system, query processing, parallel programming, dataflow query execution system}
}

@article{task-sequencing,
title = {Optimal task sequencing with precedence constraints},
journal = {Discrete Mathematics},
volume = {4},
number = {1},
pages = {37-56},
year = {1973},
issn = {0012-365X},
doi = {https://doi.org/10.1016/0012-365X(73)90113-1},
url = {https://www.sciencedirect.com/science/article/pii/0012365X73901131},
author = {M.R. Garey},
abstract = {A given finite set of tasks, having known nonnegligible failure probabilities and known costs (or rewards) for their performance, can be performed sequentially until either one of the tasks fails or all tasks have been executed. The allowable task performance sequences are constrained only by certain precedence requirements, which specify that certain tasks must be performed before certain other tasks. Given the individual task failure probabilities and task costs, along with the intertask precedence requirements, the problem is to determine an optimal task performance sequence having minimal expected cost (or maximal expected reward). A number of potential applications of such “task ordering” problems are described, including R&D project organization, design of screening procedures, and determining testing points for sequential manufacturing processes. The main results of this paper are a number of reduction theorems which lead to a very efficient optimization algorithm for a large class of task ordering problems. Though these theorems are not quite sufficient for us to give a fast optimization algorithm, we do show how their use can improve upon exhaustive search techniques.}
}

@INPROCEEDINGS{art,
  author={Leis, Viktor and Kemper, Alfons and Neumann, Thomas},
  booktitle={2013 IEEE 29th International Conference on Data Engineering (ICDE)}, 
  title={The adaptive radix tree: ARTful indexing for main-memory databases}, 
  year={2013},
  volume={},
  number={},
  pages={38-49},
  doi={10.1109/ICDE.2013.6544812},
  publisher={IEEE},
  address={Brisbane, QLD, Australia}
}

@article{henry2017,
  author = {Henry, Rawn and Hsu, Olivia and Yadav, Rohan and Chou, Stephen and Olukotun, Kunle and Amarasinghe, Saman and Kjolstad, Fredrik},
  title = {Compilation of Sparse Array Programming Models},
  year = {2021},
  issue_date = {October 2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {5},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3485505},
  doi = {10.1145/3485505},
  journal = {Proc. ACM Program. Lang.},
  month = {oct},
  articleno = {128},
  numpages = {29},
  keywords = {Sparse Array Programming, Compilation, Sparse Arrays}
}

@INPROCEEDINGS{multiset-ra,
  author={Grefen, P.W.P.J. and de By, R.A.},
  booktitle={Proceedings of 1994 IEEE 10th International Conference on Data Engineering}, 
  title={A multi-set extended relational algebra: a formal approach to a practical issue}, 
  year={1994},
  volume={},
  number={},
  pages={80-88},
  doi={10.1109/ICDE.1994.283002}}

@InProceedings{on-multisets-in-dbs,
author="Lamperti, Gianfranco
and Melchiori, Michele
and Zanella, Marina",
editor="Calude, Cristian S.
and P{\u{A}}un, Gheorghe
and Rozenberg, Grzegorz
and Salomaa, Arto",
title="On Multisets in Database Systems",
booktitle="Multiset Processing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="147--215",
abstract="Database systems cope with the management of large groups of persistent data in a shared, reliable, effective, and efficient way.Within a database, a multiset (or bag) is a collection of elements of the same type that may contain duplicates. There exists a tight coupling between databases and multisets. First, a large varietyof data models explicitly support multiset constructors. Second, commercial relational database systems, even if founded on a formal data model which is set-oriented in nature, allows for the multiset-oriented manipulation of tables. Third, multiset processing in databases mayb e dictated byefficiencyreasons, as the cost of duplicate removal mayturn out to be prohibitive. Finally, even in a pure set-oriented conceptual framework, multiset processing mayturn out to be appropriate for optimization of queryev aluation. The mismatch between the relational model and standardized relational querylanguages has led researchers to provide a foundation to the manipulation of multisets. Other research has focused on extending the relational model byrelaxing the first normal form assumption, giving rise to the notion of a nested relation and to a corresponding nested relational algebra. These two research streams have been integrated within the concept of a complex relation, where diffierent types of constructors other than relation coexist, such as multiset and list. Several other database research areas cope with multiset processing, including view maintenance, data warehousing, and web information discovery.",
isbn="978-3-540-45523-3"
}

@InProceedings{mathematics-of-multisets,
author="Syropoulos, Apostolos",
editor="Calude, Cristian S.
and P{\u{A}}un, Gheorghe
and Rozenberg, Grzegorz
and Salomaa, Arto",
title="Mathematics of Multisets",
booktitle="Multiset Processing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="347--358",
abstract="This paper is an attempt to summarize the basic elements of the multiset theory. We begin by describing multisets and the operations between them, then we present hybrid sets and their operations. We continue with a categorical approach to multisets, and then we present fuzzy multisets and their operations. Finally, we present partially ordered multisets.",
isbn="978-3-540-45523-3"
}

@inproceedings{lsqb,
author = {Mhedhbi, Amine and Lissandrini, Matteo and Kuiper, Laurens and Waudby, Jack and Sz\'{a}rnyas, G\'{a}bor},
title = {LSQB: a large-scale subgraph query benchmark},
year = {2021},
isbn = {9781450384773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461837.3464516},
doi = {10.1145/3461837.3464516},
abstract = {We introduce LSQB, a new large-scale subgraph query benchmark. LSQB tests the performance of database management systems on an important class of subgraph queries overlooked by existing benchmarks. Matching a labelled structural graph pattern, referred to as subgraph matching, is the focus of LSQB. In relational terms, the benchmark tests DBMSs' join performance as a choke-point since subgraph matching is equivalent to multi-way joins between base Vertex and base Edge tables on ID attributes. The benchmark focuses on read-heavy workloads by relying on global queries which have been ignored by prior benchmarks. Global queries, also referred to as unseeded queries, are a type of queries that are only constrained by labels on the query vertices and edges. LSQB contains a total of nine queries and leverages the LDBC social network data generator for scalability. The benchmark gained both academic and industrial interest and is used internally by 5+ different vendors.},
booktitle = {Proceedings of the 4th ACM SIGMOD Joint International Workshop on Graph Data Management Experiences \& Systems (GRADES) and Network Data Analytics (NDA)},
articleno = {8},
numpages = {11},
location = {Virtual Event, China},
series = {GRADES-NDA '21}
}

@article{suitesparse,
author = {Davis, Timothy A. and Hu, Yifan},
title = {The university of Florida sparse matrix collection},
year = {2011},
issue_date = {November 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/2049662.2049663},
doi = {10.1145/2049662.2049663},
abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB™, Mathematica™, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
journal = {ACM Trans. Math. Softw.},
month = dec,
articleno = {1},
numpages = {25},
keywords = {sparse matrices, performance evaluation, multilevel algorithms, Graph drawing}
}

@misc{rozemberczki2021twitch,
      title={Twitch Gamers: a Dataset for Evaluating Proximity Preserving and Structural Role-based Node Embeddings}, 
      author={Benedek Rozemberczki and Rik Sarkar},
      year={2021},
      eprint={2101.03091},
      archivePrefix={arXiv},
      primaryClass={cs.SI}
 }

@inproceedings{lms,
author = {Rompf, Tiark and Odersky, Martin},
title = {Lightweight modular staging: a pragmatic approach to runtime code generation and compiled DSLs},
year = {2010},
isbn = {9781450301541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868294.1868314},
doi = {10.1145/1868294.1868314},
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but the effort required to develop high-quality program generators likely offsets their benefits, even if a multi-stage programming language is used.We present lightweight modular staging, a library-based multi-stage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process.We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a stand-alone implementation with only modest effort.},
booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
pages = {127–136},
numpages = {10},
keywords = {multi-stage programming, language virtualization, domain-specific languages, code generation},
location = {Eindhoven, The Netherlands},
series = {GPCE '10}
}

@book{dbs-complete-book,
author = {Garcia-Molina, Hector and Ullman, Jeffrey D. and Widom, Jennifer},
title = {Database Systems: The Complete Book},
year = {2008},
isbn = {9780131873254},
publisher = {Prentice Hall Press},
address = {USA},
edition = {2},
abstract = {This introduction to database systems offers a comprehensive approach, focusing on database design, database use, and implementation of database applications and database management systems. KEY TOPICS: The first half of the book provides in-depth coverage of databases from the point of view of the database designer, user, and application programmer. It covers the latest database standards SQL:1999, SQL/PSM, SQL/CLI, JDBC, ODL, and XML, with broader coverage of SQL than most other texts. The second half of the book covers databases from the point of view of the DBMS implementor, focusing on storage structures, query processing, and transaction management. The book covers the main techniques in these areas with broader coverage of query optimization than most other texts, along with advanced topics including multidimensional and bitmap indexes, distributed transactions, and information integration techniques. Ideal for professionals and students interested in database systems. A basic understanding of algebraic expressions and laws, logic, basic data structure, OOP concepts, and programming environments is implied.}
}

@article{architecture-db,
author = {Hellerstein, Joseph M. and Stonebraker, Michael and Hamilton, James},
title = {Architecture of a Database System},
year = {2007},
issue_date = {February 2007},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {1},
number = {2},
issn = {1931-7883},
url = {https://doi.org/10.1561/1900000002},
doi = {10.1561/1900000002},
abstract = {Database Management Systems (DBMSs) are a ubiquitous and critical component of modern computing, and the result of decades of research and development in both academia and industry. Historically, DBMSs were among the earliest multi-user server systems to be developed, and thus pioneered many systems design techniques for scalability and reliability now in use in many other contexts. While many of the algorithms and abstractions used by a DBMS are textbook material, there has been relatively sparse coverage in the literature of the systems design issues that make a DBMS work. This paper presents an architectural discussion of DBMS design principles, including process models, parallel architecture, storage system design, transaction system implementation, query processor and optimizer architectures, and typical shared components and utilities. Successful commercial and open-source systems are used as points of reference, particularly when multiple alternative designs have been adopted by different groups.},
journal = {Found. Trends Databases},
month = feb,
pages = {141–259},
numpages = {119}
}

@inproceedings{access-path,
author = {Selinger, P. Griffiths and Astrahan, M. M. and Chamberlin, D. D. and Lorie, R. A. and Price, T. G.},
title = {Access path selection in a relational database management system},
year = {1979},
isbn = {089791001X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/582095.582099},
doi = {10.1145/582095.582099},
abstract = {In a high level query and data manipulation language such as SQL, requests are stated non-procedurally, without reference to access paths. This paper describes how System R chooses access paths for both simple (single relation) and complex queries (such as joins), given a user specification of desired data as a boolean expression of predicates. System R is an experimental database management system developed to carry out research on the relational model of data. System R was designed and built by members of the IBM San Jose Research Laboratory.},
booktitle = {Proceedings of the 1979 ACM SIGMOD International Conference on Management of Data},
pages = {23–34},
numpages = {12},
location = {Boston, Massachusetts},
series = {SIGMOD '79}
}

@inproceedings{overview-query-opt,
author = {Chaudhuri, Surajit},
title = {An overview of query optimization in relational systems},
year = {1998},
isbn = {0897919963},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/275487.275492},
doi = {10.1145/275487.275492},
booktitle = {Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
pages = {34–43},
numpages = {10},
location = {Seattle, Washington, USA},
series = {PODS '98}
}

@inproceedings{column-row,
author = {Abadi, Daniel J. and Madden, Samuel R. and Hachem, Nabil},
title = {Column-stores vs. row-stores: how different are they really?},
year = {2008},
isbn = {9781605581026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1376616.1376712},
doi = {10.1145/1376616.1376712},
abstract = {There has been a significant amount of excitement and recent work on column-oriented database systems ("column-stores"). These database systems have been shown to perform more than an order of magnitude better than traditional row-oriented database systems ("row-stores") on analytical workloads such as those found in data warehouses, decision support, and business intelligence applications. The elevator pitch behind this performance difference is straightforward: column-stores are more I/O efficient for read-only queries since they only have to read from disk (or from memory) those attributes accessed by a query.This simplistic view leads to the assumption that one can obtain the performance benefits of a column-store using a row-store: either by vertically partitioning the schema, or by indexing every column so that columns can be accessed independently. In this paper, we demonstrate that this assumption is false. We compare the performance of a commercial row-store under a variety of different configurations with a column-store and show that the row-store performance is significantly slower on a recently proposed data warehouse benchmark. We then analyze the performance difference and show that there are some important differences between the two systems at the query executor level (in addition to the obvious differences at the storage layer level). Using the column-store, we then tease apart these differences, demonstrating the impact on performance of a variety of column-oriented query execution techniques, including vectorized query processing, compression, and a new join algorithm we introduce in this paper. We conclude that while it is not impossible for a row-store to achieve some of the performance advantages of a column-store, changes must be made to both the storage layer and the query executor to fully obtain the benefits of a column-oriented approach.},
booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
pages = {967–980},
numpages = {14},
keywords = {c-store, column-oriented dbms, column-store, compression, invisible join, tuple materialization, tuple reconstruction},
location = {Vancouver, Canada},
series = {SIGMOD '08}
}

@misc{handwritten-tpch,
    author = {Palkar, Shoumik},
    title = {TPC-H Benchmarks},
    year = {2017},
    url = {https://github.com/sppalkia/tpch-benches}
}