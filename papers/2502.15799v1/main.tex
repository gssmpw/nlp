\pdfoutput =1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.

\usepackage[dvipsnames,table]{xcolor}
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)



% Optional math commands from https://github.com/goodfeli/dlbook_notation.

\usepackage{multirow}
\usepackage{fontawesome5}
\usepackage{tcolorbox}
\usepackage{pifont}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{tabularx}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts


\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
%\usepackage{xcolor}
\usepackage{amsmath}


\usepackage{listings} % for prompts
\lstset{
basicstyle=\small\ttfamily,
mathescape=true,
breaklines=true,        % Enable line breaking
breakindent=0pt,        % No indent for wrapped lines
breakautoindent=false,  % Disable automatic indentation
columns=flexible        % Better space handling
}


% \usepackage[utf8]{inputenc}
% \usepackage[russian]{babel}

\title{Investigating the Impact of Quantization Methods \\ on the Safety and Reliability of Large Language Models}



% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
 \textbf{Artyom Kharinaev$^{\clubsuit \Diamond}$ \textsuperscript{1}}, 
 \textbf{Viktor Moskvoretskii$^\clubsuit$ \textsuperscript{1,3}},
 \textbf{Egor Shvetsov\textsuperscript{1}}, \\
%  \textbf{Dmitry Osin\textsuperscript{1}},
% \\
%  \textbf{Igor Udovichenko\textsuperscript{1}},
 \textbf{Kseniia Studenikina$^{\Diamond}$},
 \textbf{Bykov Mikhail$^{\Diamond}$},
 \textbf{Evgeny Burnaev \textsuperscript{1,2}}
\\
 \textsuperscript{1} \small{Skolkovo Institute of Science and Technology} \\
 \textsuperscript{2} \small{Artificial Intelligence Research Institute} \\
 \textsuperscript{3} \small{HSE University}
 % \textsuperscript{2}Affiliation 2,
 % \textsuperscript{3}Affiliation 3,
 % \textsuperscript{4}Affiliation 4,
 % \textsuperscript{5}Affiliation 5
\\
 \small{
   \textbf{Correspondence:} \href{mailto: m.zhelnin@skol.tech}{e.shvetsov@skol.tech}
 } \\
 \small{ $\clubsuit$ indicates equal contribution.} \\ 
 \small{ $\Diamond$ indicates that the work was partially done during  \href{https://smiles.skoltech.ru/}{SMILES summer school.}}
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

% \newcommand{\fix}{\marginpar{FIX}}
% \newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations.
To address this gap, we introduce \textbf{OpenSafetyMini}, a novel open-ended safety dataset designed to better distinguish between models. We evaluate 4 state-of-the-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research.

\end{abstract}

\input{chapters/table_related}


\input{chapters/intro}
\input{chapters/related}
\input{chapters/methods}

\input{chapters/results}
\input{chapters/discussion}
\input{chapters/conclusion}

\section{Limitations}

\begin{itemize}
    \item Our dataset filtering relies on the GPT-estimated deflection score, followed by human validation to remove incorrectly marked unsafe questions. While this ensures a high-quality dataset, it may exclude some valuable questions with low deflection scores that were not manually reviewed. Expanding the selection criteria in future work could further enhance dataset diversity. 

    \item Our evaluation currently focuses on post-training quantization, which is the most widely used approach for efficient model deployment. Investigating how models trained with quantization-aware training perform under the same safety and trustworthiness assessments could offer additional insights into the impact of different quantization techniques.
\end{itemize}

\section{Ethical Considerations}

Our work aims to advance the safety and trustworthiness of quantized language models by evaluating their responses to challenging scenarios. While our dataset, \textbf{OpenSafetyMini}, contains provocative questions, these are solely intended to assess and improve model safety mechanisms, ensuring that AI systems respond responsibly in real-world interactions.

Additionally, our open-sourced human evaluations include responses from open-source models that may contain unsafe content. These responses are shared strictly for scientific purposes, fostering transparency and enabling further research toward the development of more ethical and aligned AI systems. 

Furthermore, our study does not introduce any additional risks beyond those posed by standard safety benchmarks. All experimental evaluations are conducted within ethical guidelines, focusing on enhancing AI robustness while mitigating potential harms associated with unsafe model behavior.


\section*{Acknowledgments}  
We extend our gratitude to Alex Tyulyupo for his contributions to conceptualizing the filtration process of the data set. Tyulyupo proposed the procedure involving ethical deflection scoring (0-100 scale), developed the prompt template for LLM-based score estimation, and performed the initial filtration phase. This work enabled the creation of our refined \textbf{OpenSafetyMini} dataset through subsequent manual quality validation.

\bibliography{references}  

\appendix
\clearpage
\onecolumn

\input{chapters/appendix}

%\input{chapters/safety}
%\input{chapters/quantization}


%%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


%%% Uncomment this section and comment out the \bibliography{references} line above to use inline references.
% \begin{thebibliography}{1}

% 	\bibitem{kour2014real}
% 	George Kour and Raid Saabne.
% 	\newblock Real-time segmentation of on-line handwritten arabic script.
% 	\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
% 			International Conference on}, pages 417--422. IEEE, 2014.

% 	\bibitem{kour2014fast}
% 	George Kour and Raid Saabne.
% 	\newblock Fast classification of handwritten on-line arabic characters.
% 	\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
% 			International Conference of}, pages 312--318. IEEE, 2014.

% 	\bibitem{hadash2018estimate}
% 	Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
% 	Jacovi.
% 	\newblock Estimate and replace: A novel approach to integrating deep neural
% 	networks with existing applications.
% 	\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

% \end{thebibliography}


\end{document}
