\section{Discussion}

In this section we discuss obtained critical insights into the effects of quantization bit-range, methods, safety benchmarks, and model architectures on the safety and trustworthiness of language models. Below, we summarize the key implications:

\subsection{Quantization Bit-Range}
\begin{itemize}
    \item \textbf{Int4 Precision}: At 4-bit precision, models generally maintain strong performance, with minimal degradation in safety and trustworthiness. However, the effectiveness of quantization methods varies significantly across models. For instance, QUIK excels for LLaMA but underperforms for Mistral, while AWQ shows robustness for Mistral.
    \item \textbf{Int2 Precision}: Reducing precision to 2 bits introduces more pronounced performance declines, particularly for LLaMA. Vector quantization methods like AQLM demonstrate greater stability compared to scalar methods like QUIP\#, which struggles with maintaining safety and factual accuracy.
\end{itemize}

\subsection{Quantization Methods}
\begin{itemize}
    \item \textbf{QUIK}: Performs well for LLaMA at 4-bit precision, showing minimal safety degradation and strong robustness. However, its performance drops significantly for Mistral, particularly in safety benchmarks.
    \item \textbf{AWQ}: Consistently delivers strong results for Mistral, outperforming other methods in both safety and trustworthiness. For LLaMA, AWQ shows vulnerabilities at lower precision.
    \item \textbf{QUIP\#}: Generally underperforms compared to QUIK and AWQ, especially at 2-bit precision, where safety and factual accuracy decline significantly.
    \item \textbf{AQLM}: Demonstrates stability and higher factuality at 2-bit precision, particularly for LLaMA, making it a promising method for low-bit quantization.
\end{itemize}

\subsection{Safety Benchmarks}
\begin{itemize}
    \item \textbf{OpenSafetyMini vs. XSafety}: The \textbf{OpenSafetyMini} dataset proves more challenging and effective in distinguishing between quantization methods and models. It reveals nuanced safety vulnerabilities that \textbf{XSafety} fails to capture, such as the significant safety drop for Mistral at FP16 and the performance gaps between LLaMA and Mistral.
    \item \textbf{Multi-Choice Benchmarks}: While consistent with open-ended benchmarks, multi-choice benchmarks lack specificity in distinguishing between quantized, full-precision and abliterated models. 
\end{itemize}

\subsection{Models}
\begin{itemize}
    \item \textbf{LLaMA vs. Mistral}: LLaMA consistently demonstrates higher safety and trustworthiness across quantization settings, particularly on \textbf{OpenSafetyMini}. Mistral, while competitive at FP16, exhibits more significant safety drops at lower precision.
    \item \textbf{Abliterated Models}: The Abliterated LLaMA model shows a significant loss in factuality, suggesting a potential link between safety mechanisms and trustworthiness. This unexpected result highlights the need for further investigation into the interplay between safety alignment and factual accuracy.
\end{itemize}

