\section{Related Work}
The easiest way of training a model for \ac{CO} is to assume the existence of ground truth solutions to the \ac{CO} problems and train in a supervised fashion.
    \citet{pointer-networks} leverage the fact that many \ac{CO} problems ask to identify a certain subset of the input (e.g.\ minimum-k-cut) or a permutation of the input (e.g.\ \ac{TSP}).
    They introduce an LSTM-based sequence-to-sequence architecture where the elements of the output sequence are positions in the input sequence, which they name pointer network.
    \citet{a-note-on-learning-algorithms-for-quadratic-assignment-with-gnns, an-efficient-gcn-technique-for-the-tsp} recognize that most common \ac{CO} problems have a natural graph representation.
    In their work, a \ac{GNN} predicts an approximate solution as a heatmap, which is then decoded into a valid solution to the \ac{CO} problem using beam search.
    \citet{neural-algorithmic-reasoning-for-co} follow a neural algorithmic reasoning approach to learn to imitate \ac{CO} solvers.
    The model is pre-trained on simple algorithms and then fine-tuned on difficult ones.
    Finally, \citet{difusco} uses graph-based denoising diffusion to generate high-quality solutions.
    However, these supervised approaches aren't applicable to such cases where calculating exact solutions for the training problems is not feasible.

    Several approaches have used \acf{RL} to remove this dependence on a labeled dataset.
    \citet{neural-co-with-rl} use a pointer network~\citep{pointer-networks}, but train it with \ac{RL}.
    \citet{learning-co-algorithms-over-graphs, attention-learn-to-solve-routing-problems} use the \ac{GNN} autoregressively to predict which node should be added next to the solution set and repeat that process until a valid solution is reached.
    \citet{solving-np-hard-problems-on-graphs-with-extended-alphago-zero} formulate the \ac{CO} problem as a Markov decision process, then use an algorithm similar to AlphaGo Zero~\citep{alpha-go-zero} to solve it autoregressively.
    \citet{symmetric-replay-training--sample-efficiency-rl-co} propose a modification to the \ac{RL} training process for autoregressive methods that improves sample efficiency.
    However, the use of the score function estimator in many of these methods leads to high-variance gradients, which makes training more difficult.


    Other self-supervised approaches that do not rely on reinforcement learning include \citet{augment-with-care}, which use a contrastive loss instead.
    \citet{co-with-physics-inspired-gnns} focus on quadratic and polynomial unconstrained binary optimization, which many \ac{CO} problems can be formulated as.
    This allows them to make use of a self-supervised loss function specific to these two problem families.
    \citet{diffusion-model-framework-for-unsupervised-nco} also concentrate on quadratic unconstrained binary optimization, but employ a diffusion-based approach similar to \citet{difusco}.
    Similarly, \citet{erdos-goes-neural, tackling-prevalent-conditions-in-unsupervised-co} formulate a self-supervised loss function for a comprehensive class of \ac{CO} problems.
    \citet{gnns-for-maximum-constraint-satisfaction} use an LSTM-based architecture to solve binary maximum constraint satisfaction problems, which many \ac{CO} problems can be formulated as.
    Since these approaches focus on certain families of \ac{CO} problems, they aren't general to \ac{CO} as a whole.

    
    \citet{exact-co-with-gcns} use a \ac{GNN} as a heuristic for the branch-and-bound algorithm, which guarantees exact solutions at the expense of a comparatively longer running time.
    The \ac{GNN} is trained via imitation learning from a known high-quality but slow heuristic.
    \citet{learning-tsp-requires-rethinking-generalization} compare some of the paradigms introduced in other papers in structured experiments.
    There have been two lines of work to address the problem of backpropagating through combinatorial optimization problems.
    Firstly, if we have a set of optimal solutions given as training data, we can use supervised learning to train the GNN to output adjacency matrices as close as possible to the optimal solutions \cite{elmachtoub2022smart}.
    This is often called ``predict, then optimize''.
    Secondly, there are several methods to backpropagate through a non-differentiable \ac{CO} algorithm, such as \citet{imle, adaptive-imle, differentiation-of-blackbox-co-solvers}. Related to our work is decision-focused learning, which has developed several methods to backpropagate through CO solvers \cite{DBLP:journals/corr/abs-2307-13565}.