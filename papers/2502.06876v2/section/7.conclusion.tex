\section{Conclusion}
This paper creates the first benchmark to explore the effect of the model merging for a balanced optimization across helpfulness, harmlessness, and honesty (3H) dimensions to enhance LLMs alignment. Through extensive comparison experiments across representative data mixture and model merging methods, we reveal a range of overlooked optimization principles and insights. Moreover, integrated with the traits of heavy-tailed parameter distribution and sparsity of LLMs, we propose a novel reweighting-based optimization to enhance the effect of the current state-of-the-art merging method. Our theoretical and experimental findings offer a promising direction for LLM alignment, advancing the development of ethically constrained language models.

% While model merging methods have made strides in addressing various problems for LLMs recently, understanding their effectiveness in 3H optimization in LLM alignment and discussing the distinction between merging methods and traditional data mixture methods remain unexplored. To address these questions,  



% this paper creates the first benchmark to explore the effect of model merging for 3H optimization in LLM alignment.



% We reveal a range of overlooked optimization principles and insights  

% Moreover, integrated with the traits of heavy-tailed parameter distribution and sparsity of LLMs, we propose a novel reweight-based optimization to enhance the effect of the current state-of-the-art merging method for better LLM alignment.