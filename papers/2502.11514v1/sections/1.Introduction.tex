\section{Introduction}

% Wang, recent progress of inference-time scaling methods for this field
The remarkable performance of OpenAI's o1 in tackling reasoning tasks has sparked widespread research interest in studying inference-time scaling across various communities.
This technique is built upon the success of Chain-of-Thought~(CoT, \citealt{cot}), which enables large language models~(LLMs) to solve a problem through step-by-step reasoning.
It makes use of additional computation at inference time to conduct ``\textit{slow thinking}''~\cite{kahneman2011thinking} to further improve the accuracy of responses.
Taking the rich experience of pioneering research in language-only approaches~\cite{tts-mcts5,tts-mcts8,tot,scaling,tts-bs3, tts-mcts2, tts-mcts4, tree-search3, tree-search2}, rapid progress has been made in addressing multi-modal reasoning tasks leveraging typical methods such as Best-of-N, Beam Search, and Monte Carlo Tree Search~(MCTS)~\cite{xu2024llava,yao2024mulberry}.

\begin{figure}[t]
  \includegraphics[width=\columnwidth]{imgs/cot_vs_mcot.pdf}
  \caption{Solving the problem using text-only thought vs. multi-modal thought. Additional visual information from the latter offers richer and more intuitive features, making it easier to yield better subsequent steps.}
  \label{fig:cot-mcot}
\end{figure}

% Text-based CoT and Multi-modal CoT, compare them using a figure
Although effective, these methods mostly follow the practice of text-based thinking, overlooking the crucial role of thinking in the visual modality in multi-modal scenarios. This oversight leads to suboptimal performance, thus highlighting the need for new approaches that integrate both modalities.
% Taking the geometric problem in Figure~\ref{fig:cot-mcot} as an example, reasoning based on added auxiliary lines can effectively assist the model in performing correct proof.
Consider the process of solving geometric problems as an example: humans often utilize auxiliary lines to facilitate problem-solving. Analogously, rich and intuitive visual information, e.g., drawn auxiliary lines, can enhance the model's ability to generate improved solutions, as shown in Figure~\ref{fig:cot-mcot}.
Recent studies~\cite{image-of-thought, vsk} have also demonstrated the benefits of incorporating supplementary visual information at each reasoning step compared with conventional text-based methods~\cite{mcot,ddcot,ccot}.
Therefore, an important yet under-explored question arises: \textit{What is the potential of inference-time scaling of multi-modal thinking?}

% This study, sampling-based and tree search-based, process verifier
To this end, we conduct the first study on this problem, shedding light on the merits and constraints of this new research line.
We follow \citet{cot} and \citet{vsk} to elicit text-only and multi-modal thought, respectively.
For inference-time scaling, we investigate popular sampling-based and tree search-based methods.
Sampling-based method generates multiple independent samples in parallel, applying techniques like Self-Consistency~\cite{tts2-Self-Consistency} or Best-of-N~\cite{tts-mcts1, tts-mcts3} to select the most reliable reasoning trails.
However, this approach is inefficient because it requires exploring full solution paths, even if a mistake has occurred early.
Tree search-based method tackles this issue by utilizing sophisticated search algorithms, such as Beam Search~\cite{tot} and MCTS~\cite{tts-mcts7}.
Both these methods ask for a critic to discriminate the promising samples or search steps.
We consistently employ an advanced Large Vision Language Model~(LVLM) as a verifier to infer critic scores and, alternatively, enhance this method by aggregating results from multiple trials.
In this way, it effectively provides reliable feedback without the need for specific training.

% Experiment, main conclusion*, and discussion of future direction
We conduct a comparison of inference-time scaling using multi-modal and text-only thought across 10 datasets, encompassing tasks related to geometric reasoning, mathematical reasoning, and visual question answering.
The main findings are as follows:
\begin{itemize}[leftmargin=12pt]
    \item The use of multi-modal thought achieves significantly better performance and higher upper bounds compared to text-only thought on average, demonstrating the potential of this line of research.
    \item Although effective, it requires higher token consumption to process richer visual inputs. This result calls for more efficient reasoning mechanisms, especially for practical concerns.
    \item Further analyses show that tree search-based methods effectively mitigate reasoning errors, such as invalid processed images. However, their success heavily relies on verifier performance, highlighting the need to develop more effective multi-modal verifiers.
\end{itemize}
% 需要想些其他的分析，围绕scaling（性能上限、性能涨幅和多样性）和critic（多模态CoT更容易判断还是更难），这两点才是inference-time scaling关注的
We hope that these findings can inspire future research to develop more advanced and robust methods for multi-modal reasoning.


