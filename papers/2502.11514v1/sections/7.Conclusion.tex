\section{Conclusion}

In this work, we present a systematic investigation of inference-time scaling with multi-modal thought.
We conduct comprehensive experiments across 10 challenging tasks spanning diverse domains, investigating both sampling-based and tree search-based scaling methods.
We demonstrate that multi-modal thought consistently outperform text-only reasoning, achieving progressively stronger performance with increased computational budgets.
This empirical evidence positions multi-modal thought scaling as a promising direction for enhancing complex reasoning capabilities in multi-modal scenarios.
However, we notice that performance gains are accompanied by higher computational costs and depend heavily on the effectiveness of the verifier, thus hindering real-world deployment.
We hope this work will serve as a springboard for studying inference-time scaling with multi-modal thought, thereby advancing multi-modal reasoning.




