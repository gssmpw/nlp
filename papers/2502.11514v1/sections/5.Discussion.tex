\section{Discussion}

\paragraph{Reducing token costs for multi-modal thought to achieve efficient inference.}

Our analysis of token computations (Figure~\ref{fig:cost}) demonstrates that multi-modal thought, while effective, incurs substantial token costs.  This underscores the need for efficient compression techniques specifically designed for processing visual information in LVLMs. While prior works~\cite{cost1, cost2, cost3} have explored visual token compression, they have largely overlooked the unique challenges of multi-modal thought reasoning.  Thus developing methods for efficient visual information handling in this context becomes a key direction for future research.

\paragraph{Constructing stronger multi-modal verifiers for better performance.}

Our error analysis (\textsection\ref{subsec:error_analysis}) highlights the critical role of the verifier in inference-time scaling, where its effectiveness directly influences error reduction and performance gains. However, research on multi-modal verifiers~\cite{mm_reward2, mm_reward3, mm_reward4, mm_reward1} remains in its early stages, limiting the potential of multi-modal thought. Advancing more robust and accurate verifiers is therefore crucial for fully unlocking the benefits of inference-time scaling.

\paragraph{Exploring inference-time scaling for the chain of any-modal thought reasoning.}

Recent works have extended CoT reasoning beyond text and images to more modalities, such as audio~\cite{speech_cot} and video~\cite{video_cot}. However, the effectiveness of inference-time scaling for these modalities remains unexplored. While our findings confirm the benefits of scaling for text-image reasoning, whether these advantages extend to other modality combinations remains an open question.