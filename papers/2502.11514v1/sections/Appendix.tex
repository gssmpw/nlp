
\subfile{../tabs/static}

\section{Prompts for Verifiers}
\label{sec:app_verifier_inst}

We use the following prompts for two kinds of verifiers:

\begin{itemize}
    \item \textbf{Classification-Based:} \textit{Verify the reasoning process above and provide the final judgment of 'yes' or 'no' on whether the reasoning is valid at last after “Final Decision:”.}
    \item \textbf{Regression-Based:} \textit{Verify the reasoning process above and provide a validation score from 0 (worst) to 1.0 (best) at last after “Final Score:”.}
\end{itemize}





\section{Implementation Details of Multi-modal Thought}
\label{sec:app_vsk}

Recognizing the limitations of current generative models in fine-grained drawing, we leverage Visual Sketchpad~\cite{vsk} to enable multi-modal reasoning.  Visual Sketchpad empowers LVLMs to generate sketches as intermediate reasoning artifacts, boosting problem-solving capabilities. It interprets multi-modal queries, devises sketching strategies, synthesizes programs for sketch generation, and analyzes the resulting sketches to formulate responses.

 Specifically, at each step $i$, the model outputs a textual thought $\mathbf{t}_i$ and a visual operation $o_i$:

\begin{equation}
    \mathbf{t}_i, o_i = \mathcal{M}\big(\mathbf{q}, \mathbf{I}, \mathbf{s}_{1:i-1}\big),
\end{equation}
where $\mathbf{o}_i$ is executable code specifying visual operations.

A code executor $\mathcal{G}$ then updates the visual contexts by applying $\mathbf{o}_i$ to the previous images $\mathbf{I}$:

\begin{equation}
    \mathbf{I}' = \mathcal{G}\big(\mathbf{I}, \mathbf{o}_i\big),
\end{equation}

\begin{equation}
    \mathbf{I} = \mathbf{I} \cup \mathbf{I}',
\end{equation}
where $\mathbf{I}'$ represents the updated images. Thus the next reasoning step $\mathbf{s}_i = \{\mathbf{t}_i, o_i, \mathbf{I}'\}$. 

Visual Sketchpad integrates various tools for sketch generation. For geometric and mathematical tasks, it uses Python libraries like matplotlib and networkx. For VQA, it incorporates specialized vision models and visual manipulations, including:

\begin{itemize}
\item \textbf{Detection:} Use Grounding-DINO~\cite{Groundingdino} to detect and label objects in images based on textual queries.
\item \textbf{Segmentation:} Generate segmented images with labeled masks by employing SegmentAnything~\cite{SegmentAnything} and Semantic-SAM~\cite{SemanticSam}.
\item \textbf{Depth Estimation:} Leverage DepthAnything~\cite{DepthAnything} to produce depth maps from input images.
\item \textbf{Visual Search:} Implements a sliding window approach to locate small objects based on textual queries.
\item \textbf{Image Manipulation:} Include zoom/crop (region of interest extraction) and image overlay (alpha blending).
\end{itemize}



\section{Datasets}
\label{sec:app_dataset}

The detailed introduction of datasets in our experiments are presented in Table~\ref{tab:static}.

\section{Baseline Introduction}
\label{sec:app_baselines}

Here we introduce the latest multi-modal reasoning baselines in our experiments:

\begin{itemize}
    \item \textbf{Multimodal-CoT}~\cite{mcot}: A multi-modal extension of CoT that concatenates the reasoning process with the problem context for answering.
    \item \textbf{DDCoT}~\cite{ddcot}: A method that decouples reasoning and recognition, and then integrate visual capabilities into the reasoning process.
    \item \textbf{CCoT}~\cite{ccot} A framework that generates a scene graph before answering.
\end{itemize}




\begin{figure}[t]
  \includegraphics[width=\columnwidth]{imgs/error.pdf}
  \caption{Examples of each error category.}
  \label{fig:error_type}
\end{figure}

\section{Error Category Explanation}
\label{sec:app_error}


We define four categories of error of multi-modal thought under inference-time scaling methods as follows:

\begin{itemize}
\item \textbf{Wrong Decision:} The correct answer is present within the candidate reasoning chains but is not selected. This indicates an error in the decision-making process.
\item \textbf{Execution Error:} The code generated during the reasoning process contains bugs, preventing the reasoning process from proceeding correctly.
\item \textbf{Ineffective Operation:} The reasoning process is hampered by ineffective operations that produce unhelpful or misleading visual information.
\item \textbf{Invalid Reasoning:} The error stems from a flawed reasoning process, leading to an incorrect conclusion.
\end{itemize}

Examples of each error category are provided in Figure~\ref{fig:error_type}.


