\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lcccccc@{}}
\toprule[1.5pt]
 & Model & Learning Rate  & Batch Size & KL Coefficient&Max Length & Training Epochs \\ 
\midrule[1pt]
& Llama-3.1-8B-Instruct & 5e-6  & 32 & 0.1&8000& 3\\
& Qwen2-7B-Instruct & 5e-6 & 32 & 0.1 &6000& 3 \\
& Qwen2.5-Math-7B & 5e-6  & 32 & 0.01&8000& 3 \\ 
\bottomrule[1.5pt]
\end{tabular}%
}
\caption{Model Training Hyperparameter Settings (SFT)}
\label{tab:hyper_sft}
\end{table*}

\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lccccccccc@{}}
\toprule[1.5pt]
 & Model & Learning Rate  & \makecell[c]{Training\\Batch Size} & \makecell[c]{Forward\\Batch Size} & KL Coefficient&Max Length & \makecell[c]{Sampling\\Temperature} &Clip Range &Training Steps \\ 
\midrule[1pt]
& Llama-3.1 &5e-7  & 64& 256 & 0.05&8000& 0.7&0.2&500\\
& Qwen2-7B-Instruct & 5e-7&  64& 256 & 0.05 &6000&0.7 &0.2&500\\\
& Qwen2.5-Math-7B & 5e-7 & 64& 256 & 0.01&8000&0.7 &0.2&500 \\ 
\bottomrule[1.5pt]
\end{tabular}%
}
\caption{Model Training Hyperparameter Settings (RL)}
\label{tab:hyper_rl}
\end{table*}