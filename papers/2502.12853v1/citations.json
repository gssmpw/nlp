[
  {
    "index": 0,
    "papers": [
      {
        "key": "snell2024scalingllmtesttimecompute",
        "author": "Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar",
        "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters"
      },
      {
        "key": "wu2024empirical",
        "author": "Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming",
        "title": "An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models"
      },
      {
        "key": "brown2024large",
        "author": "Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Large language monkeys: Scaling inference compute with repeated sampling"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "selfconsistency",
        "author": "Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou",
        "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mathshepherd",
        "author": "Peiyi Wang and Lei Li and Zhihong Shao and R. X. Xu and Damai Dai and Yifei Li and Deli Chen and Y. Wu and Zhifang Sui",
        "title": "Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations"
      },
      {
        "key": "zhang2024generative",
        "author": "Lunjun Zhang and Arian Hosseini and Hritik Bansal and Mehran Kazemi and Aviral Kumar and Rishabh Agarwal",
        "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction"
      },
      {
        "key": "lightman2023lets",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's Verify Step by Step"
      },
      {
        "key": "havrilla2024glore",
        "author": "Havrilla, Alex and Raparthy, Sharath and Nalmpantis, Christoforus and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Raileanu, Roberta",
        "title": "Glore: When, where, and how to improve llm reasoning via global and local refinements"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "alphallm",
        "author": "Tian, Ye and Peng, Baolin and Song, Linfeng and Jin, Lifeng and Yu, Dian and Mi, Haitao and Yu, Dong",
        "title": "Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing"
      },
      {
        "key": "wang2024qimprovingmultistepreasoning",
        "author": "Chaojie Wang and Yanchen Deng and Zhiyi Lv and Shuicheng Yan and An Bo",
        "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning"
      },
      {
        "key": "restmcts",
        "author": "Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie",
        "title": "ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search"
      },
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "snell2024scalingllmtesttimecompute",
        "author": "Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar",
        "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "feng2023alphazero",
        "author": "Feng, Xidong and Wan, Ziyu and Wen, Muning and Wen, Ying and Zhang, Weinan and Wang, Jun",
        "title": "Alphazero-like tree-search can guide large language model decoding and training"
      },
      {
        "key": "yao2023tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "selfrefine",
        "author": "Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others",
        "title": "Self-refine: Iterative refinement with self-feedback"
      },
      {
        "key": "shinn2024reflexion",
        "author": "Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu",
        "title": "Reflexion: Language agents with verbal reinforcement learning"
      },
      {
        "key": "chen2024magicore",
        "author": "Chen, Justin Chih-Yao and Prasad, Archiki and Saha, Swarnadeep and Stengel-Eskin, Elias and Bansal, Mohit",
        "title": "MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning"
      },
      {
        "key": "chen2025sets",
        "author": "Chen, Jiefeng and Ren, Jie and Chen, Xinyun and Yang, Chengrun and Sun, Ruoxi and Ar{\\i}k, Sercan {\\\"O}",
        "title": "SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "o1",
        "author": "OpenAI",
        "title": "Openai o1 system card"
      },
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "qin2024o1",
        "author": "Qin, Yiwei and Li, Xuefeng and Zou, Haoyang and Liu, Yixiu and Xia, Shijie and Huang, Zhen and Ye, Yixin and Yuan, Weizhe and Liu, Hector and Li, Yuanzhi and others",
        "title": "O1 Replication Journey: A Strategic Progress Report--Part 1"
      },
      {
        "key": "feng2023alphazero",
        "author": "Feng, Xidong and Wan, Ziyu and Wen, Muning and Wen, Ying and Zhang, Weinan and Wang, Jun",
        "title": "Alphazero-like tree-search can guide large language model decoding and training"
      },
      {
        "key": "snell2024scalingllmtesttimecompute",
        "author": "Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar",
        "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters"
      },
      {
        "key": "luong2024reft",
        "author": "Luong, Trung Quoc and Zhang, Xinbo and Jie, Zhanming and Sun, Peng and Jin, Xiaoran and Li, Hang",
        "title": "Reft: Reasoning with reinforced fine-tuning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "madaan2024self",
        "author": "Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others",
        "title": "Self-refine: Iterative refinement with self-feedback"
      },
      {
        "key": "shinn2023reflexion",
        "author": "Shinn, Noah and Labash, Beck and Gopinath, Ashwin",
        "title": "Reflexion: an autonomous agent with dynamic memory and self-reflection"
      },
      {
        "key": "paul2023refiner",
        "author": "Paul, Debjit and Ismayilzada, Mete and Peyrard, Maxime and Borges, Beatriz and Bosselut, Antoine and West, Robert and Faltings, Boi",
        "title": "Refiner: Reasoning feedback on intermediate representations"
      },
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "huang2023large",
        "author": "Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny",
        "title": "Large language models cannot self-correct reasoning yet"
      },
      {
        "key": "tyen2023llms",
        "author": "Tyen, Gladys and Mansoor, Hassan and Chen, Peter and Mak, Tony and C{\\u{a}}rbune, Victor",
        "title": "LLMs cannot find reasoning errors, but can correct them!"
      },
      {
        "key": "ma2024large",
        "author": "Ma, Ruotian and Wang, Xiaolei and Zhou, Xin and Li, Jian and Du, Nan and Gui, Tao and Zhang, Qi and Huang, Xuanjing",
        "title": "Are Large Language Models Good Prompt Optimizers?"
      },
      {
        "key": "zhang2024understanding",
        "author": "Zhang, Qingjie and Qiu, Han and Wang, Di and Qian, Haoting and Li, Yiming and Zhang, Tianwei and Huang, Minlie",
        "title": "Understanding the Dark Side of LLMs' Intrinsic Self-Correction"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "saunders2022self",
        "author": "Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan",
        "title": "Self-critiquing models for assisting human evaluators"
      },
      {
        "key": "rosset2024direct",
        "author": "Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang",
        "title": "Direct nash optimization: Teaching language models to self-improve with general preferences"
      },
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2024small",
        "author": "Zhang, Yunxiang and Khalifa, Muhammad and Logeswaran, Lajanugen and Kim, Jaekyeom and Lee, Moontae and Lee, Honglak and Wang, Lu",
        "title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning"
      },
      {
        "key": "jiang2024towards",
        "author": "Jiang, Huchen and Ma, Yangyang and Ding, Chaofan and Luan, Kexin and Di, Xinhan",
        "title": "Towards Intrinsic Self-Correction Enhancement in Monte Carlo Tree Search Boosted Reasoning via Iterative Preference Learning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      },
      {
        "key": "qu2025recursive",
        "author": "Qu, Yuxiao and Zhang, Tianjun and Garg, Naman and Kumar, Aviral",
        "title": "Recursive introspection: Teaching language model agents how to self-improve"
      },
      {
        "key": "kamoi2024can",
        "author": "Kamoi, Ryo and Zhang, Yusen and Zhang, Nan and Han, Jiawei and Zhang, Rui",
        "title": "When can llms actually correct their own mistakes? a critical survey of self-correction of llms"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ziegler2019fine",
        "author": "Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey",
        "title": "Fine-tuning language models from human preferences"
      },
      {
        "key": "stiennon2020learning",
        "author": "Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F",
        "title": "Learning to summarize with human feedback"
      },
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "setlur2025rl",
        "author": "Setlur, Amrith and Garg, Saurabh and Geng, Xinyang and Garg, Naman and Smith, Virginia and Kumar, Aviral",
        "title": "Rl on incorrect synthetic data scales the efficiency of llm math reasoning by eight-fold"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lightman2024lets",
        "author": "Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe",
        "title": "Let's Verify Step by Step"
      },
      {
        "key": "tajwar2024preference",
        "author": "Tajwar, Fahim and Singh, Anikait and Sharma, Archit and Rafailov, Rafael and Schneider, Jeff and Xie, Tengyang and Ermon, Stefano and Finn, Chelsea and Kumar, Aviral",
        "title": "Preference fine-tuning of llms should leverage suboptimal, on-policy data"
      },
      {
        "key": "havrilla2024teaching",
        "author": "Havrilla, Alex and Du, Yuqing and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Sukhbaatar, Sainbayar and Raileanu, Roberta",
        "title": "Teaching large language models to reason with reinforcement learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "lightman2024lets",
        "author": "Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe",
        "title": "Let's Verify Step by Step"
      },
      {
        "key": "setlur2024rewarding",
        "author": "Setlur, Amrith and Nagpal, Chirag and Fisch, Adam and Geng, Xinyang and Eisenstein, Jacob and Agarwal, Rishabh and Agarwal, Alekh and Berant, Jonathan and Kumar, Aviral",
        "title": "Rewarding progress: Scaling automated process verifiers for llm reasoning"
      },
      {
        "key": "setlur2025rl",
        "author": "Setlur, Amrith and Garg, Saurabh and Geng, Xinyang and Garg, Naman and Smith, Virginia and Kumar, Aviral",
        "title": "Rl on incorrect synthetic data scales the efficiency of llm math reasoning by eight-fold"
      },
      {
        "key": "luo2024improve",
        "author": "Luo, Liangchen and Liu, Yinxiao and Liu, Rosanne and Phatale, Samrat and Lara, Harsh and Li, Yunxuan and Shu, Lei and Zhu, Yun and Meng, Lei and Sun, Jiao and others",
        "title": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ahmadian2024back",
        "author": "Ahmadian, Arash and Cremer, Chris and Gall{\\'e}, Matthias and Fadaee, Marzieh and Kreutzer, Julia and Pietquin, Olivier and {\\\"U}st{\\\"u}n, Ahmet and Hooker, Sara",
        "title": "Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms"
      },
      {
        "key": "deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      },
      {
        "key": "team2025kimi",
        "author": "Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others",
        "title": "Kimi k1. 5: Scaling Reinforcement Learning with LLMs"
      },
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      },
      {
        "key": "team2025kimi",
        "author": "Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others",
        "title": "Kimi k1. 5: Scaling Reinforcement Learning with LLMs"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "gao2023scaling",
        "author": "Gao, Leo and Schulman, John and Hilton, Jacob",
        "title": "Scaling laws for reward model overoptimization"
      },
      {
        "key": "everitt2021reward",
        "author": "Everitt, Tom and Hutter, Marcus and Kumar, Ramana and Krakovna, Victoria",
        "title": "Reward tampering problems and solutions in reinforcement learning: A causal influence diagram perspective"
      }
    ]
  }
]