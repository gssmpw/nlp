\section{Related work}
\subsection{Early Fusion-based Approaches}
Early fusion-based approaches established the foundation of multimodal fake news detection, with SpotFake \cite{spotfake2019} pioneering BERT and VGG-19 integration, while EANN \cite{eann2018} introduced event discriminators with VGG and Text-CNN architectures. Basic CNN architectures \cite{basicmm2022} achieved 88\% accuracy on Fakeddit, followed by improvements through SpotFake+ \cite{spotfakeplus2020} (85.6\% on GossipCop) and MVAE \cite{mvae2019} (82.4\% on Weibo). SAFE \cite{safe2020} and CAFE \cite{cafe2021} advanced fusion mechanisms, while HMCAN \cite{hmcan2020} and VERITE \cite{verite2022} introduced attention-based architectures. These early approaches, while groundbreaking, suffered from rigid fusion mechanisms and limited interaction between modalities.

\subsection{Cross-Modal Interaction Frameworks}
Sophisticated approaches focusing on modality interactions aim to solve issues with fusion-based techniques. MIMoE-FND \cite{mimoe2025} achieved 95.6\% accuracy on Weibo-21 through mixture-of-experts architecture. MPFN \cite{mpfn2023} introduced progressive fusion networks with 83.8\% on Weibo. Recently released CroMe \cite{crome2025} achieved 97.4\% on Weibo using tri-transformers through better capture of intra-modality relationships. DAAD \cite{daad2024} and MGCA \cite{mgca2024} further improved modality interactions through dynamic analysis and multi-granularity alignment. They achieve 94.2\% and 91.3\% on Weibo-21 respectively.

\subsection{Large Model Integration}
In recent years, the release of large vision-language models introduced new possibilities,  with FND-CLIP \cite{fndclip2023} achieving 94.2\% on PolitiFact. IMFND \cite{imfnd2024} explores GPT4V and CogVLM, though with limited success (80.1\% on PolitiFact). A self-learning approach \cite{selflearning2024} leverages LLMs for feature extraction without labeled data, achieving 88.88\% on Fakeddit. CMA \cite{cma2024} investigated few-shot learning, though with modest results (79.77\% on PolitiFact). These methods primarily use large models as feature extractors or direct classifiers, whereas \texttt{UNITE-FND} innovatively employs Gemini 1.5 Pro as a modality translator, enabling more effective use of specialized text classification models.

\subsection{Knowledge-Enhanced Detection}
Knowledge-enhanced methods emerged as another direction, with AKA-Fake \cite{akafake2024} employing reinforcement learning and GAMED \cite{gamed2024} introducing multi-expert decoupling (achieving impressive 98.46\% results on the specialized Yang dataset). RaCMC \cite{racmc2024} incorporates multi-granularity constraints with a residual-aware compensation network. These approaches achieve strong performance but require extensive knowledge bases and complex integration mechanisms. Our approach achieves comparable results through Gemini's inherent knowledge, eliminating the need for external knowledge bases.

\subsection{Specialized Approaches}
Specialized approaches have also emerged, including AMPLE \cite{ample2024} with emotion awareness (90\% accuracy on PolitiFact), MMCFND \cite{mmcfnd2024} addressing multilingual challenges across multiple Indic languages (99.6\% on MMIFND), and MAGIC framework \cite{magic2024} using geometric deep learning (98.8\% accuracy on a curated subset of Fakeddit with 3,127 samples).  While these methods excel in specific scenarios, \texttt{UNITE-FND} provides a more generalizable solution through its modality translation.