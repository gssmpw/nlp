\section{Related work}
\subsection{Early Fusion-based Approaches}
Early fusion-based approaches established the foundation of multimodal fake news detection, with SpotFake ____ pioneering BERT and VGG-19 integration, while EANN ____ introduced event discriminators with VGG and Text-CNN architectures. Basic CNN architectures ____ achieved 88\% accuracy on Fakeddit, followed by improvements through SpotFake+ ____ (85.6\% on GossipCop) and MVAE ____ (82.4\% on Weibo). SAFE ____ and CAFE ____ advanced fusion mechanisms, while HMCAN ____ and VERITE ____ introduced attention-based architectures. These early approaches, while groundbreaking, suffered from rigid fusion mechanisms and limited interaction between modalities.

\subsection{Cross-Modal Interaction Frameworks}
Sophisticated approaches focusing on modality interactions aim to solve issues with fusion-based techniques. MIMoE-FND ____ achieved 95.6\% accuracy on Weibo-21 through mixture-of-experts architecture. MPFN ____ introduced progressive fusion networks with 83.8\% on Weibo. Recently released CroMe ____ achieved 97.4\% on Weibo using tri-transformers through better capture of intra-modality relationships. DAAD ____ and MGCA ____ further improved modality interactions through dynamic analysis and multi-granularity alignment. They achieve 94.2\% and 91.3\% on Weibo-21 respectively.

\subsection{Large Model Integration}
In recent years, the release of large vision-language models introduced new possibilities,  with FND-CLIP ____ achieving 94.2\% on PolitiFact. IMFND ____ explores GPT4V and CogVLM, though with limited success (80.1\% on PolitiFact). A self-learning approach ____ leverages LLMs for feature extraction without labeled data, achieving 88.88\% on Fakeddit. CMA ____ investigated few-shot learning, though with modest results (79.77\% on PolitiFact). These methods primarily use large models as feature extractors or direct classifiers, whereas \texttt{UNITE-FND} innovatively employs Gemini 1.5 Pro as a modality translator, enabling more effective use of specialized text classification models.

\subsection{Knowledge-Enhanced Detection}
Knowledge-enhanced methods emerged as another direction, with AKA-Fake ____ employing reinforcement learning and GAMED ____ introducing multi-expert decoupling (achieving impressive 98.46\% results on the specialized Yang dataset). RaCMC ____ incorporates multi-granularity constraints with a residual-aware compensation network. These approaches achieve strong performance but require extensive knowledge bases and complex integration mechanisms. Our approach achieves comparable results through Gemini's inherent knowledge, eliminating the need for external knowledge bases.

\subsection{Specialized Approaches}
Specialized approaches have also emerged, including AMPLE ____ with emotion awareness (90\% accuracy on PolitiFact), MMCFND ____ addressing multilingual challenges across multiple Indic languages (99.6\% on MMIFND), and MAGIC framework ____ using geometric deep learning (98.8\% accuracy on a curated subset of Fakeddit with 3,127 samples).  While these methods excel in specific scenarios, \texttt{UNITE-FND} provides a more generalizable solution through its modality translation.