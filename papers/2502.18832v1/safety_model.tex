% Safety model:
% - non-adversarial
% - only load by privileged users
% - developers are not malicious, but can make mistakes
%   - do not want to skip safety checks and want to be 100% sure that extensions
%     do not cause problems
% - safety checks therefore catch programming mistakes
% The safety model that is the same as that of eBPF
% The kernel has moved away from unprivileged eBPF and major distros ship the
%   kernel without unprivileged eBPF support.
% eBPF now can only be loaded by privileged users, the model is no longer
%   adversarial.
% - privileged users are always trusted to be not malicious
% - a privileged attacker almost always has other easier ways to attack than
%   using eBPF.
\section{Key Idea and Safety Model}
\label{sec:safety_model}
\vspace{-5pt}

The key idea of Rax is to realize {\it safe} kernel extensions without a separate layer of
    static verification.
% Rax targets large, complex kernel extensions that are increasingly suffering from the \gap{}.
Our insight is that the desired safety properties of kernel extensions
    can be built on the foundation of language-based properties of
    a safe programming language like Rust,
    together with extralingual runtime checks.
In this way, the in-kernel verifier can be dropped, and
    the \gap{} can be closed.
Rax extensions are strictly written in a {\it safe} subset of Rust.
We choose Rust as the safe language for kernel extensions
% Similar to related work~\cite{redleaf,theseus,tockos},
    (instead of other languages like Modula-3~\cite{spin}
    and Sing\#~\cite{lang-sing})
    because Rust is already supported
    by Linux~\cite{rust-for-linux-lwn} and offers
    desired language features for practical kernel code~\cite{redleaf,theseus,tockos}.
\new{Rax enforces the same set of safety properties eBPF enforces (\S\ref{sec:background}).}
Hence, Rax extensions fundamentally differ from unsafe kernel modules.
% As discussed in \S\ref{sec:motivation}, the current problem of usability of
%    eBPF is the large \gap{}. % between the programer, who works on
    % high-level languages, and the verifier, which operates on compiled bytecode.
% Our insight is that both the needed expressiveness and safety can be obtained
%     from a safe programming language without the verifier.

\para{Safety Model.}
Rax follows eBPF's non-adversarial safety model---the
    safety properties focus
    on preventing programming errors from crashing/hanging the kernel instead of
    malicious attacks.
Like eBPF, Rax extensions are installed from a trusted context with root
    privileges on the system.
Rax extensions can only be written in safe Rust with selected features
    and language-based safety is enforced out by a trusted Rust compiler (\S\ref{sec:lang_subset}). % and is strictly enforced;
Unlike Rust kernel modules that can use % bypass the compiler's safety checks
    unsafe Rust, the language-based safety of Rax extensions is strictly enforced.
Other safety properties that are not covered by language-based safety (e.g., termination)
    are checked and enforced by the lightweight Rax runtime.

While historically eBPF supported unprivileged mode~\cite{reconsider-unpriv-ebpf-lwn} and
    there are research efforts in supporting
    unprivileged use cases for kernel extensions~\cite{beebox-security24,safebpf-thomas,jia2023},
in practice, eBPF and other frameworks (e.g., KFlex~\cite{dwivedi-sosp24}) no longer pursue
    it~\cite{ebpf-sec-lwn,pawan-8a03e56b253e}.
The reasons come from inherent limitations of securing eBPF
    or kernel extensions in general.

First, it is hard for the eBPF verifier to prevent transient execution attacks like Spectre attacks
    completely, without major performance and compatibility overheads (see~\cite{ebpf-sec-lwn}).
Specifically, new Spectre variants are being discovered; though many of them are bugs in hardware,
    they cannot be easily detected and fixed by static analysis~\cite{perspective_isca}.
Sandboxing techinques cannot completely prevent Spectre attacks either,
    e.g., SafeBPF~\cite{safebpf-thomas} only prevents memory vulnerabilities,
    while BeeBox~\cite{beebox-security24} only focuses on two Spectre variants and requires manual instrumentation of helper functions.
For these reasons, the Linux kernel and major distributions also have moved away from unprivileged
    eBPF~\cite{pawan-8a03e56b253e,unpriv-ebpf-ubuntu,unpriv-ebpf-suse}.
%    effectively creating a non-adversarial safety model. % for \projname{} kernel extensions:

Second, eBPF chose not to be a sandbox environment (like WebAssembly or JavaScript)
    that does not know what code will be run~\cite{ebpf-sec-lwn}.
Instead, the development of eBPF assumes that ``{\it the intent of a BPF program is known}~\cite{ebpf-sec-lwn}.''

Lastly, the constantly reported verifier vulnerabilities~\cite{untenableVerification,ebpf-stackoverflow,ebpf-termination}
    indicate that a bug-free verifier is hard in practice.

    % Extensions are written by well-meaning but imperfect developers and thus the
%    code may contain programming mistakes but is not actively malicious.
% The imperfect developers want to be absolutely sure that their extension
%    programs does not lead to safety issues in the kernel and need the
%   programming mistakes to be detected beforehand.
% The so called ``guarantees'' of safety therefore consist of the best-effort
%    catching of common mistakes.

% We discuss how Rax enforces each of its safety properties in \S\ref{sec:principle}.




% \tianyin{TODO: map it to the safety defined in \S\ref{sec:motivation}}
% and is strictly enforced---the extensions cannot
%    bypass the checks.

%actively malicious extension writers can crash
%or hang the
%system~\cite{untenableVerification,ebpf-stackoverflow,ebpf-termination}
%(e.g., via helper functions), but the verifier prevents obvious
%mistakes (e.g., dereferencing a NULL pointer).

% TCB of Rax:
%   - Rust compiler
%   - Rax kernel crate
%   - Rax runtime
%
% Need to trust the correctness of the Rust compiler to enjoy the safety
%   guarrantee it provides
% - Core compiler is not too large, 72k loc vs. clang's 229k loc w/ tests
% - there are active efforts on ensuring correctness of Rust code that are
%   applicable to the Rust toolchain itself
%   - formal methods (Rustbelt)
%   - program analysis (Rudra)
%   - fuzzing (cargo-fuzz)
% This is aligned with the position of previous works (RedLeaf and Theseus)

\para{Trusted Computing Base (TCB).}
% \jinghao{TODO: decide whether to say ``toolchain'' here}
With Rax's safety model, the TCB consists of the Rust toolchain, the
    \projname{} kernel crate, and the \projname{} runtime.
\projname{} has to trust the Rust toolchain for its correctness to deliver
    language-based safety.
%    extension programs to enjoy the safety guarantees from Rust.
We believe the need to trust the Rust toolchain is acceptable
    and does not come with high risks with our safety model.
Recent work on safe OS kernels~\cite{theseus,redleaf,Miller-hotos19} makes the same decision
    to establish language-based safety by trusting the Rust toolchains.
The active effort on extensive fuzzing and formal verification of the Rust
    compiler~\cite{rust-belt,stacked-borrows-popl19,verus,verus-sosp24,rvt,rustc-fuzzing}
    may further reduce the risk.
Certainly, we acknowledge that the existing Rust compiler, such as rustc~\cite{rustc},
    is larger than the eBPF verifier.

% On the one hand, rustc~\cite{rustc}, the core compiler code of Rust is not
%    large, making it easier to reason about and ensure correctness than other
 %   larger compilers (e.g., Clang~\cite{clang}, also an LLVM frontend, contains
 %   three times as much code as Rustc). \jinghao{Not sure if this is a fair
 %   comparison}

% On the other hand, there have been various active efforts on ensuring
%    correctness of Rust code, especially unsafe Rust.
% These works ranges from applying formal methods on Rust
%    code~\cite{verus,rust-belt,stacked-borrows-popl19,astrauskas-oopsla19}, to
%   program analysis techinques~\cite{rudra-sosp21,qin-pldi20}, and to dynamic
%   approaches such as fuzzing~\cite{cargo-fuzz}.
% We expect these efforts to continue reducing the bugs and unsoundness in the
%    Rust toolchain and make it more trust-able.

% This is aligned with the position of previous works that also leverage the
%    safety promise from Rust~\cite{theseus,redleaf}.

% Rust-for-Linux does not satisfy the safety model
% - safety is merely a guideline, not a enforcement
% - unsafe code is allowed in module
% - kernel modules could still cause safety problems
% Note that the \projname{} safety model is different from that
%    of the Rust kernel modules, which is more relaxed and therefore cannot
%    satisfy our safety requirement.
% In Rust kernel modules, safety is not a property that is enforced, but merely a
%    guideline.
% This is because the full safety checks from the Rust compiler can be bypassed by
%    resorting to unsafe Rust, which is still allowed in the case of
%    kernel modules.
% The presence of such unsafe implementation could still cause safety problems and
%    undermine the safety guarrantees from Rust.
