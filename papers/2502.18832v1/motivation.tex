\vspace{-7pt}
\section{The Language-Verifier Gap}
\label{sec:motivation}
\vspace{-5pt}

A fundamental problem of eBPF's safety verification mechanism is the {\it \gap{}}
    (illustrated in Figure~\ref{fig:gap}).
Developers mainly implement and maintain eBPF extensions in high-level
    languages (e.g., C and Rust) and compile them to eBPF bytecode;
they agree to a contract with the high-level language (code has property $p$), which is
    enforced by the compiler.
When a program fails to compile, developers receive feedback
    about how they violate
    the language contract.
However, in eBPF, the compiled extension code will be further checked by the verifier.
If correctly compiling code fails
    to pass the verifier (e.g., the code lacks property $q$, which is not
    part of the contract),
    it is difficult for developers
    to understand why the extension program fails despite obeying the contract.

% While eBPF verification is important for program safety, the verifier
%    places additional constraints on programs, leading to usability challenges.
% As shown in Figure
% the core of the problem is a gap between the expectations of the programmer, formalized by the
% programming language, and the verifier.
%    Typical eBPF development involves implementing programs in a high-level
%    programming language (e.g., C, Rust) and compiling to eBPF bytecode.

The \gap{} is further exacerbated when the verifier incorrectly rejects {\it safe} extension programs
    due to (1) scalability limitations of the symbolic execution used by the verifier,
    (2) conflicting analyses between the compiler and the verifier,
    and (3) the verifier's implementation defects.
Today, the \gap{} forces developers to understand the verifier's internal implementation and
    its limitations and defects,
    and to revise extension code in ways that can pass the verifier at the bytecode level.
Many such revisions are workarounds solely to
    please the verifier.
Fundamentally, the \gap{} breaks the language abstractions
    and artificially forces extension programs
    in a high-level language
    to tightly couple with the low-level verifier implementation.
%    creating significant cognitive burden of
%    developing and maintaining kernel extensions.

    %% and how to fix it because the compiler
    %% and verifier do not pass information about program safety to each other.
%\mvle{not clear why it is hard for the programmer to understand verification failure messages.
%Is it because what is being verified is not the same program being written and not the
%same semantics being checked at the higher-level language?}




% and categorized them by the
% approaches programmers resorted to in order to overcome them.
% In the rest of this section we describe our methodology and categorization, walk through some illustrative examples, and describe the key high level takeaway, namely that we find clear evidence of usability issues caused by the \gap{}. % language-verifier gap.


%Additionally, we describe two fundamental reasons for the programmer gap.
%\milo{succinctly say them here.}

%From these examples it is clear that programmers need to add code to
%    eBPF extensions to please the verifier.
% The needed code is nontrivial, and the programmer receives little help from the verifier to track down
%    the problem. \tianyin{Can you elaborate?}
% \new{
% The verifier logs oftentimes do not point the developers to the root cause,
%    which they have to investigate by themselves.
% }
% The compiler provides no help, due to the \gap{}.


%At the same time, the verifier has a set of properties that it ensures are maintained for each program, such as memory safety.
%The verifier will reject programs that do not meet these properties.
%The compiler does not know the set of properties that the eBPF verifier checks, which
%    introduces a gap between the compiler and the verifier, and, by extension, the programmer and the verifier.
%
%The problem is compounded by the fact that the verifier operates on code that has undergone
%    translation from a high-level language into eBPF bytecode.
%The cause of verifier rejections may unrelated to the code the programmer wrote and instead
%    be a result of bugs anywhere along the toolchain.
%The verifier is also a moving target, with different versions having different constraints
%    and different completeness guarantees.
%As a result, eBPF developers often have to wrestle with the in-kernel verifier
%    to allow safe programs they write to pass.
%This can manifest itself in needing to write arcane expressions to please the
%    verifier, or by completely restructuring semantically correct and safe code.

%The compiler does not know the set of properties that the eBPF verifier checks, which makes it more difficult for developers to know if their program will run until they run the verifier.

%This binds developers with a contract not only with the high-level language
%    that is enforced by the compiler or interpreter, but also with the eBPF
%    verifier, where the specifications are not clear. \mvle{I don't it's an issue with specification. it's partly due to going from a turing-complete language to turing-incomplete. I think we should bulletize these challenges. 1. semantic gap (turing complete -> turing-incomplete, 2. difficult to debug due to many levels of translation, 3. compiler optimizations that are incompatible with verifier, 4. specification for verifier changes across kernel versions, 5. ?}
%Developers have a contract with the programming language that is enforced by the compiler of interpreter.
%The programmer also has a contract with the eBPF verifier, but the specifics are unclear.
%At the same time, because source code goes through a translation to eBPF
%    bytecode before verification, it is often difficult to map the verifier
%    error back to source code.
%Source code goes through a translation to eBPF bytecode before it is verified, which makes mapping the output of the verifier back to the code the programmer wrote difficult.

%To better understand this gap and the kinds of usability issues eBPF
%    developers face, we carried out an analysis on existing eBPF projects and
%    past research literature.
%We carried out an analysis of existing eBPF projects and research papers to better understand this gap and the kinds of verifier issues the eBPF developers face.
% eBPF developers often have to wrestle with the in-kernel verifier to allow the programs they write to pass.
% This can manifest itself in needing to write arcane expressions to please the verifier.
%We categorize the solutions that programmers need to implement in order to pass the verifier to get a clearer picture of the usability challenges that the current eBPF system has.

% \subsection{Methodology}

%88\% of commit messages found were from the Cilium repository.
%Cilium is a mature project that makes extensive use of eBPF as a core part of its architecture.
%Cilium represents a representative set of challenges for large projects with complex eBPF code bases.
%\jinghao{Is this paragraph necessary?}

%To classify the commits into categories, we read each of the commit messages and examined
%    their source code changes.
%Some categories were clear to see and are well documented in the literature (i.e. restructuring eBPF programs), while other categories were more subtle.
%We created a qualitative analysis of many of the kinds of fixes that are used when writing and verifying eBPF programs.

%The categorizations that we created are not necessarily mutually exclusive.
%We started with a large set of smaller categories, and then combined categories to
%    create larger categories that represented classes of fixes, as well as picking out
%    common patterns that are representative.

\begin{figure}
    \includegraphics[width=1.0\linewidth]{figs/gap2-crop.pdf}
    \centering
    \vspace{-15pt}
    \caption{The \gap{}}
    \label{fig:gap}
%    \vspace{-10pt}
\end{figure}

\vspace{-2pt}
\subsection{Verifier Workarounds}
\label{sec:workaround}
\vspace{-2pt}

To understand the impact of the \gap{}, % specifically in terms of usability,
we analyzed commits related to revising eBPF programs to resolve verifier issues
    in popular eBPF projects, including Cilium~\cite{cilium}, Aya~\cite{aya-rs}, and
Katran~\cite{katran}.
The commits were collected by searching through the commit logs of each project
    using keywords and manually inspected. % like ``error,'' ``reject,'' and ``verifier.''
% We manually inspected every commit.
%For each commit log that matched, we manually inspected and classified the commit.
In total, we collected % 216 commit messages, %containing the above keywords,
72 commits related to verifier issues.
%of which we concluded 73 were actually about verifier complaints.
We also included two issues raised by BMC~\cite{BMC} and Electrode~\cite{Electrode}
    in the discussion. %as examples when appropriate.

% While the verifier is intended to reject programs that are unsafe,
In all 72 commits, we confirmed that the original eBPF programs were safe
    but were rejected by
    the verifier due to defective or overly conservative safety checks.
When the verifier rejects a safe program, the developer must
find a {\em workaround}.
% to bypass the verifier or convince the verifier
%    that the program is actually safe.
Table~\ref{fig:commit-table} summarizes the workaround patterns.
%    all of them require deep knowledge of the verifier internals.
%    only the verifier, but also the compiler.

%make their programs pass the verifier.
%\jinghao{
%Some comments on the table: it is not immediately clear on what exactly
%    the developers are doing for some of the categories, especially the last
%    3. (btw, should it be ``helper functions'' or ``helping functions'').
%At the same time, the categories do not seem to be mutually exclusive,
%    e.g., ``Split eBPF programs for complexity'' vs.
%    ``Refactor code to reduce complexity''.
%We should be clear whether the categories are overlapping.
%}
%% The composition of the categories makes it clear that developers have to change their code in particular ways to get it to pass the verifier.
%% It also demonstrates how difficult it can be to reason about the results of the verifier.
%




%% There are two basic reasons an eBPF program can fail to verify. %for several reasons.
%% The first reason is when the program is unsafe, and the verifier correctly rejects it.
%% The second reason is when a program is actually safe but the verifier is overly conservative
%% in how it checks the program, and thus rejects it.
%% When the verifier rejects a safe program, it is up to the developer to find a way to show the verifier that the program actually is safe.
%% Each of the commits we categorized captured cases where the original code was safe, but the
%%     verifier rejected it.
%% The classes of solution employed are different ways that developers use to make sure the verifier accepts their programs.
%\jinghao{This paragraph is reptitative given the preamable, I think what is
%    missing here is an overview of the finding from our study (i.e. beef up the
%    previous paragraph)}

%% \subsection{Category Representative Examples}
%% To better explain our categorization, we now walk through representative examples for each category.

% Three complexity related macros in verifier:
% - BPF_COMPLEXITY_LIMIT_INSNS: max # of insns to be processed
% - BPF_COMPLEXITY_LIMIT_JMP_SEQ: max # of branch insns to be processed
% - BPF_COMPLEXITY_LIMIT_STATES: max # of verifier states per insn, does not reject prog if exceeded
\para{Refactoring extension programs into small ones.}
\label{motivation:restructure}
The most common pattern (27 out of 72) is refactoring a large eBPF program, which
    the verifier rejects due to exceeding the verifier's internal limits
    into smaller ones.
Since symbolic execution is hard to scale,
    the eBPF verifier imposes a series of limits on the complexity of extension programs
    (e.g., the number of bytecode instructions and branches~\cite{starovoitov-51580e798cb6})
    to ensure
    verification to complete at load time.
% \new{These limits include the total number of bytecode instructions as well as
%    the number of branches processed during verification.}
The eBPF extension will be rejected if it exceeds any of these limits.
Such rejections have no implication on the safety of the extension;
rather, they are artifacts of scalability limitations
    of static verification.
% Unfortunately, developers are forced to address the verifier limitations
%    by refactoring their code.

% the verifier from conservatively rejecting programs due to exceeding its internal limits
% on the number of bytecode instructions that it can analyze.
We observe two standard practices of refactoring eBPF programs to work around verifier limits:
    (1) splitting eBPF programs into smaller ones
    and (2) rewriting eBPF programs with reduced complexity the verifier can handle.

%\begin{enumerate}
%    \item Split eBPF programs into smaller subprograms
%    %\item General refactoring to reduce verifier complexity or bypass expressiveness limits
%    \item Refactor eBPF programs to reduce complexity or bypass expressiveness limits
%\end{enumerate}

%TODO: Commented out to see if BMC can do all this
%\noindent\textbf{Splitting eBPF Programs}:
%A well documented technique to decrease overall eBPF program complexity is to use eBPF tail calls to split programs into several smaller subprograms that can be verified independently.
%The idea behind the split is that if each individual piece is verified to be safe, then the verifier itself would have verified the entire program if it could check enough instructions.
%Prior works like BPF Memcached Cache (BMC)~\cite{BMC} and Electrode~\cite{Electrode} utilize this technique in order to pass the verifier.
%BMC is split into seven different eBPF programs, and Electrode is split into six different eBPF programs.
%Both of these projects use around 500 lines of C code to program the eBPF programs.
%
%Modularity is good when programmers can split their code up into logical units, however due to the constraints of the verifier, they must split their code to match the verifier.
%In this case, we are left with program fragments which do not represent an individual unit, which makes the code harder to read and write.
%This compounds with the fact that the compiler has no notion of these limits.
%The compiler would happily compile both the split versions of code and the unified version of code, however only one set of code would pass the verifier.
%Additionally, it is not necessarily trivial to split these functions because all safety checks need to be made in each subfunction in order for them to be independently verified.
%%\jinghao{Why is this the case?
%%I think there are 2 cases, one is that the developers can just
%%split the program at the logical boundaries so that they actually get the
%%modularity; the other case is that they simply cannot split the program at these
%%boundaries and have to break it into fragments, I think this is what we are
%%arguing for and we have already seen in the case of BMC where they have to
%%keep a ``parse context'' across tail calls.}
%
%
%% The BMC has many places where for loops are nested into different ifs.
%% And, due to the limitations of C, many operations do not have built-in functions
%%     that can be used directly.
%
%\noindent\textbf{Refactoring Code}:
%\mvle{isn't splitting code a form of refactoring?}
%Code may also need to be refactored to reduce its complexity, or to work around limitations in the verifier.
%
%An example of refactoring to reduce complexity is found in a Cilium commit that involved changing how the code handled IPv4 fragmentation.
%As seen in Figure~\ref{fig:refactor-fix} the code used an \texttt{\#ifdef} with a default behavior.
%If \texttt{ENABLE\_IPV4\_FRAGMENTS} was enabled, then the code would be compiled with both the \texttt{ipv4\_handle\_fragment} call and the \texttt{ctx\_load\_bytes} call.
%%If the packet was a fragment, then the \texttt{ipv4\_handle\_fragment} call would have completed the loading of bytes, and the additional call would have been redundent.
%%\jinghao{I recommend removing this last sentence. It makes it sounds like a
%%good thing that developers have to remove some redundent code.}
%
%This design however, caused the program to fail verification as it went over the maximum checked instruction limit.
%The code was then refactored to change the \texttt{\#ifdef} and the underlying function.
%This change does not change the safety properties of the program, but it was still needed to verify the program.
%
%\begin{figure}
%    \lstinputlisting[language=myC]{./snippets/s2-refactor.c}
%    \caption{Refactor for Code Complexity}
%    \label{fig:refactor-fix}
%\end{figure}
%
%Refactoring is also used by programmers to overcome limitations in the verifier to recognize safe code due to the way the program is specifically expressed.
%An example of such a case is found in the Cilium project.
%%We found an example of refactoring for expressiveness in the Cilium project.
%To implement segment routing header support, they needed to include code to jump back to the beginning of the IP header parsing code while already inside the IP header parsing code.
%This would cause a back-edge which gets incorrectly labeled as an infinite loop and the verifier fails.
%Figure~\ref{fig:switch} shows their solution which involved creating a switch statement inside of a switch statement which then jumps ahead to the other code in the outer switch statement.
%The changes required increase the complexity of the source code without changing the semantics.
%
%\begin{figure}
%    \lstinputlisting[language=myC]{./snippets/s2-switch.c}
%    \caption{Refactor for Expressiveness}
%    \label{fig:switch}
%\end{figure}
%% TODO: End Comment

%\noindent\textbf{BMC Example}:
%BMC had to split eBPF programs into smaller subprograms, and refactor code for verification complexity
%    in order to immplement
%Both of these verifier fixes were needed to implement BMC, an in-kernel cache for Memcached
%    based on eBPF.
%BMC stores recently queried key-value pairs in an eBPF map (i.e. the cache) to
%    accelerate the processing of GET requests to the Memcached server.
% The map that serves as the cache is managed by eBPF programs, which implements
%     the lookup and update logics.impl:ctx-converison
%\paragraph{BMC}
We use BMC~\cite{BMC} as an example to explain these practices.
BMC uses eBPF to implement in-kernel caches to accelerate Memcached.
Conceptually,
% BMC is a recent system that accelerates Memcached through the use of kernel extensions.
    only two extension programs are needed (at ingress and egress, respectively).
However, to satisfy the verifier limit, BMC developers had to split BMC code into {\it seven}
    eBPF programs connected via tail calls.\footnote{Since BMC, the limit has
        increased, but the fundamental gap remains.}
Such splitting creates an unnecessary burden on the implementation and maintenance of BMC;
% ---the code
%    is fragmented and hard to understand; moreover,
    it also creates performance issues when states need to pass across tail calls (using maps).
    % creating performance issues.

\begin{table}[t]
    \small
    \caption{Patterns of common verifier workarounds} %\mvle{we should rename these categories. These don't sound like verifier problems but actions done to overcome verfier issues.} \milo{These were meant to be fixes not problems, but the table title was a hold-over from before}}
    \vspace{-5pt}
    \label{fig:commit-table}
    \centering
    \begin{tabular}{lc}%{|p{6cm}|p{1cm}|}
        \toprule
        \textbf{Category} & \textbf{Count} \\
        \midrule
        Refactoring extension programs into small ones & 27 \\           % #2
        Hinting LLVM to generate verifier-friendly code & 22 \\          % #1
        Changing code to assist verification & 15 \\              % #3
        Dealing with verifier bugs & 9 \\          % #4
        Reinventing the wheels & 1 \\              % #5 (was 2 but cilium one is for performance)
        %Add "pruning checkpoints" to reduce complexity & 7 \\   % #5
        % Move to section restructure bpf program for verifier
        % moved to #2 Refactor code because of lack of expressiveness & 2 \\
        % moved to #2 Split eBPF programs for complexity & 13 \\
        % moved to #2 Refactor code to reduce complexity & 5 \\
        % moved to #3 Inline functions to pass verifier & 6 \\
        % moved to #3 Explicitly teach the verifier information & 6 \\
        % moved to #3 Add bounds to a helping function & 3 \\
        % moved to #5 Add a specific implementation of a helping function & 1 \\
        \bottomrule
    \end{tabular}
    \vspace{5pt}
\end{table}

%     and used eBPF tail calls~\cite{} to transfer control to each other.
%    to reduce verification complexity.
% This created unnecessary challenges for BMC's implementation: splitting their eBPF programs left program fragments
%    that are not self-contained and
%    BMC sometimes has to pass computation states across tail calls with a map.
%BMC utilizes a map to pass current computation state across tail calls.
%This is because tail-called eBPF programs can only take the regular eBPF
 %   context as arguments.
%    The computation state is stored before the tail call and reloaded afterwards.

%A similar problem also presents when processing the incoming packet data, where
%    the authors had to bound data size to simplify verification of loops.
%\mvle{verifier complexity or program complexity?}
% BMC also suffers from verification complexity %in its cache invalidation function,
%Despite the small program size,
%one of the seven eBPF program, which implements cache invalidation, cannot pass the verifier.

Despite the smaller size of each program after splitting, BMC programs that
    iterate over the packet payload in a loop cannot easily pass the verifier.
%The program implements cache invalidation
%The program checks every incoming packet to detect SET commands which will trigger
%    invalidation.
%If a SET is detected, the program searches for keys to invalidate in the cache.
% The original implementation of the eBPF program % of this extension program
%    result in an excessive number of jump instructions and exceed the verifier's path limit.
While the programs correctly check for the bounds of the payload,
    % (the \texttt{\small data\_end} field in XDP and TC programs),
    % due to the complex loop body,
    the programs result in an excessive number of jump instructions
    and exceed the verifier's complexity limit.
As a workaround, developers must bind the size of the data BMC can
    handle further to pass the verifier.
% shown in Figure~\ref{fig:bmc-code}.
%\mvle{what's bad about verification complexity? does it lead to verification failure?}
%As a workaround, BMC developers introduced two additional variables to
%    track the state of the key and the SET command, reducing the paths in the bytecode.
%Furthermore, they introduced \texttt{\small for} loops with multiple condition checks and
%    nested \texttt{\small if} statements.
% \tianyin{can't understand the sentence}
\S\ref{eval:bmc-case-study} revisits this example in more depth.
% \jinghao{TODO: Discuss with Ruowen and make this more crisp.}

% \jinghao{Let me know if removing this makes sense: ``and the end of packet''.}
%Such complex checks are intentionally designed to pass the
%    verifier.
% the verifier to reject loading the program.
%This approach significantly increase the programming burden
%    of BMC, while at the same time leads to readability issues in some places
%    regarding the intended functionality.
%% \jinghao{One or two sentence explain why conditions are needed for
%%     verification, based on our experiment on removing one of these.}
%% This situations is a prevalent pattern within the BMC structure, which is
%Such pattern is prevalent in the BMC implementation, which is
%%    notably observed within the functions \texttt{bmc\_hash\_keys\_main}
%%    and \texttt{bmc\_write\_reply\_main}.
%    notably also present in the code that hashes the Memcached key and drafts the reply.
%In the initial design of \projname{}-BMC, the underlying assumption was that
%    we should follow the logic of BMC.
%But the cache invalidation function Figure~\ref{fig:bmc-code} in BMC employs
%    \texttt{for} loops with cumbersome condition checks, and is further
%    complicated by the nesting of multiple \texttt{if} statements.

%Another example that the verifier creates programming burden for BMC is its
%    instruction count limit.
%\mvle{seems to repeat the "implementation-wise para}
%% Due to the instruction count limitation imposed on each eBPF program,
%%     BMC has to adapt a strategy of creating seven seperated eBPF
%%     programs to function as a Memcached cache layer.
%Due this limit, BMC has to be split into seven separated eBPF program, while
%    ideally only two are required (at egress and ingress hooks).
%% To pass messages across tail calls, BMC employed a specific struct
%%     called \texttt{parsing\_context} for storing the metadata and
%%     put the struct in the map named \texttt{map\_parsing\_context}.
%\mvle{I think this BMC section can be shortened significantly as it feels all the points
%have already been made and these are just additional examples.}

% With the above workarounds, BMC code can pass the BPF verifier, but they
 %   increase the programming burden and produce code that is more difficult
 %   to maintain.
% The fixes implemented are not immediately apparent or trivial to implement, as
%    exemplified by the complex branch conditions, and state restoring through maps.

%    making the implementation of kernel extensions
%    much more difficult than needed.

% \begin{figure}[t]
%     \lstinputlisting[language=myC]{./snippets/s6-bmc.c}
%     \vspace{-10pt}
%     \caption{Packet parsing code for cache invalidation in BMC}
%     \label{fig:bmc-code}
%     \vspace{-10pt}
% \end{figure}

\para{Hinting LLVM to generate verifier-friendly code}
\label{motivation:llvm-codegen}
%% <<<<<<< HEAD
%% The LLVM compiler translates eBPF programs written in high-level languages into eBPF bytecode.
%% We found that in certain cases, LLVM would generate eBPF bytecode that would cause the program to fail verification.
%% One issue found by Cilium was that LLVM may generate 32-bit assignments for
%%     access to the \texttt{data}, \texttt{data\_end}, and \texttt{data\_meta}
%%     fields in the program argument.
%% The LLVM compiler thought that the \texttt{data} fields were 32-bit values rather than 64-bit pointers as
%%     a result of the information hiding technique that
%%     eBPF employs.
%% The kernel exports a limited context interface to extension programs that is then rewritten in the verifier.
%% =======
Another common pattern is to change source code in ways that
    nudge the compiler (LLVM) to generate verifier-friendly bytecode.
% The compiler toolchain (LLVM) translates eBPF programs written in
% high-level languages into eBPF bytecode.
In several cases, LLVM generated eBPF bytecode that fails the verifier
    due to complex, often undocumented expectations of the verifier.
% \new{For example, the verifier may expect an access to a particular struct
%    field, which it needs to rewrite to implement information hiding for
%    safe access to kernel data structures from extensions.} \tianyin{don't understand}
% \new{However, the compiler is unaware of such expectations, and any
%   instruction that aliases that particular field or otherwise directly
%   computes on it may disrupt the verifier's rewriting logic.}
Figure~\ref{fig:inline-error} shows a case from Cilium~\cite{chaignon-847014aa62f9}
    that accesses a pointer field
    (\texttt{\small ctx->data}) in a socket buffer, defined as a 32-bit
    integer in the kernel \texttt{\small uapi} interface.
\new{
LLVM generates a 32-bit load on \texttt{\small data} and assigns its value to
    another 32-bit register.
While \texttt{\small data} is defined as 32-bit, under the hood it represents a
    pointer to the start of the packet payload.
% While LLVM correctly generated the 32-bit load on \texttt{\small data},
    % into \texttt{\small r9},
    % it subsequently emitted a 32-bit assignment that aliased this pointer. % in \texttt{\small r6}.
}
The 32-bit assignment made the verifier interpret the pointer
    as a scalar and incorrectly reject the program when it tries to access
   memory through the scalar.
%the \texttt{ctx->data}, \texttt{ctx->data\_end}, and \texttt{ctx->data\_meta} fields.
As a workaround, developers encapsulated access to
    \texttt{\small data} in inline assembly
    (Figure~\ref{fig:inline-asm}) to prevent LLVM from generating
    32-bit move as an optimization (LLVM does not optimize
    inlined assembly).
The verifier then treats the register as a pointer rather than a
    scalar.

%The LLVM compiler interpreted the fields as 32-bit values rather than 64-bit pointers as
    %The kernel exports a limited context interface to extension programs that is then rewritten in the verifier.

%The kernel exports a context interface to extension programs with only
%    the fields that they may need, and at verification time all accesses to
%    these fields are rewritten by the verifier to the actual kernel-internal
%    data structure.
%The above fields are defined as 32-bit integers in the exported interface and
%    the LLVM compiler does not know that this gets rewritten by the verifier into 64-bit pointers.

%Since the \texttt{data} field is defined as a 32-bit integer in the dummy
%    interface the kernel exports, the compiler, which does not see the
%    subsequent rewriting and kernel-internal definition, treats it as a real
%    32-bit integer and performs code generation, even though \texttt{data} is
%    actually a 64-bit pointer.

%Figure~\ref{fig:inline-error} shows the verifier losing track of the packer pointer.
%At instruction 3, R6 gets the value of R9, but this is a 32-bit assignment, as indicated by the `w' prefix.
%Then in the next line we see that R6 has type `inv' which is a scalar value, and \emph{not} a pointer to a packet showing that the verifier lost track of the type of R6.

%The \texttt{data} field is

\begin{figure}[tp]
\begin{subfigure}{0.48\textwidth}
    \lstinputlisting[language=myBPF]{./snippets/s2-codegen-error.c}
    \vspace{-5pt}
    \caption{Verifier log showing an invalid memory access, which is hard to
        diagnose and does not directly map to the source code in C}
    \vspace{-10pt}
    \label{fig:inline-error}
\end{subfigure}
\begin{subfigure}{0.48\textwidth}
    \lstinputlisting[language=myC]{./snippets/s2-inline-asm.c}
    \vspace{-5pt}
    \caption{Inline assembly code created to work around the verification failure
        by preventing the compiler optimization}
    \vspace{-5pt}
    \label{fig:inline-asm}
\end{subfigure}
\caption{An example of the \gap{} from Cilium~\cite{chaignon-847014aa62f9}, where a safe eBPF extension is incorrectly rejected by the verifier
    (\ref{fig:inline-error})
    and developers had to work around the problem by creating inline assembly code (\ref{fig:inline-asm}).}
\label{fig:llvm-cg-issue}
\end{figure}

%\jinghao{It is actually not too clear how this fixes the problem -- for
%specifically how is the generated code different?}
%\jinghao{can we be more specific on the BPF opcode (e.g., load/store) of the
%    assignment as in Figure~\ref{fig:inline-asm}}
In another case~\cite{borkmann-394e72478a8d},
    developers were forced to use \texttt{\small volatile} when
    loading from a 32-bit integer pointer and only using its upper 16 bits.
Without \texttt{\small volatile}, LLVM optimized the code to only load the
    upper 16-bit from the pointer, which the verifier perceives as a size
    mismatch violation.

In fact, many eBPF programs today can only pass the verifier if compiled with
    \texttt{\small -O2} optimization---the verifier has a hardwired
    view of eBPF extension bytecode, which the compiler cannot
    generate with other levels, including \texttt{\small -O0}.
% By re-compiling the relatively small and simple kernel eBPF sample programs
%    without optimization, we found that more than half of the programs cannot be
%    loaded.
% }
%    that cause the verifier to reject the program.

% These workarounds allow safe BPF programs to pass the verifier, but demonstrate
% severe usability issues.
% The LLVM compiler is unaware of what the verifier checks or how the verifier modifies the extension programs. %any modifications the verifier does to extension programs.
% (too repetitive)
% Developers must understand low-level details about the eBPF system and LLVM bytecode generation in order to fix verifier issues for safe programs.

\para{Changing code to assist verification.}
\label{motivation:add-code}
In this pattern, developers had to
    assist the verifier manually. % to verify safe extension programs explicitly.
A common pattern is refactoring the code into new functions when
    the verifier loses track of values in eBPF programs.
    % depending on how theprogram is structured.
    % \tianyin{can't understand}
%    In occasions, developers have to refactor certaint code out into a separate
%        function.
It is often unclear what code needs to be refactored to pass the
    verifier, which significantly burdens developers.
Figure~\ref{fig:inline-fig} shows a code example from
    Cilium~\cite{rajahalme-847014aa62f9}, which originally
    used a \texttt{\small goto} statement to combine the code path of
    \texttt{\small policy} and \texttt{\small l4policy} to avoid duplicated code.
However, the combined code, which assigns \texttt{\small l4policy} to
    \texttt{\small policy}, later causes the verifier to incorrectly believe
    that \texttt{\small policy}, which is a pointer variable, is instead a
    scalar and reject the program.
    % \tianyin{what does this mean?}
As a workaround, developers had to refactor the policy check code
    into an inlined function to separate the code path to pass the verifier.

\begin{figure}[tp]
\begin{subfigure}{0.48\textwidth}
    \lstinputlisting[language=myC]{./snippets/s2-goto.c}
    \vspace{-10pt}
    \caption{Simplifying control flow}
    \vspace{-10pt}
    \label{fig:inline-fig}
\end{subfigure}
\begin{subfigure}{0.48\textwidth}
    \lstinputlisting[language=myC]{./snippets/s2-teach.c}
    \vspace{-5pt}
    \caption{Simplifying data flow}
    \vspace{-5pt}
    \label{fig:teach-verifier}
\end{subfigure}
\caption{Examples that developers had to work around the \gap{} by refactoring
    already safe extensions}
%    \vspace{-10pt}
    \label{fig:inline-fig}
\end{figure}

% Another common fix for verifier complaints involves adding specific code to please
%    the verifier.

%This can involve several kinds of new specific code:
%
%\begin{enumerate}
%    \item Adding inline functions
%    \item Teaching the verifier information
%    \item Implementing functions in a specific way
%\end{enumerate}


% \tianyin{I don't understand why the inline function makes a difference.}

% from a labeled block of code reached by a \texttt{goto}, to an inline function.
%    The original code was valid and correct, but it failed to pass the verifier.
    %In response to this, the developers had to figure out a workaround to make their valid code pass.


%\begin{figure}
%    \begin{lstlisting}[language=myC]
%policy_check_entry:
%	account(ctx, policy);
%
%	if (unlikely(policy->deny))
%		return DROP_POLICY_DENY;
%
%	*proxy_port = policy->proxy_port;
%	if (unlikely(policy->auth_type)) {
%		if (ext_err)
%			*ext_err = (__s8)policy->auth_type;
%		return DROP_POLICY_AUTH_REQUIRED;
%	}
%	return CTX_ACT_OK;
%}
%    \end{lstlisting}
%    \caption{Block of code reached after a goto}
%    \label{fig:inline-fig}
%\end{figure}



%The developers made this code general across two cases by reassigning the value of policy depending on what the input was before jumping to the common code.
%This pattern caused the verifier to lose information about what the variable \{policy{ was referring to.
%The fix was to convert this common code into an inlined function.
%\jinghao{
%It is hard to see why this is a problem, especially when you say ``Doing this
%    helps to keep functionality separate from the programmers perspective,
%    while allowing the verifier to see all the code at the same time''.
%I think we need something similar to the previous cases where we explicitly
%    discuss why it is bad.
%}

%\item {\bf Helping the verifier information:}
%An example of explicitly teaching the verifier information can be found in the Aya-rs project.
%As part of their library, Aya contains functions to help log information.
%Throughout the project they have an upper bound on the size of the log buffer.
%In a write string function they needed to add an explicit check on the size of the length of the string against the log buffer max size.
Developers also have to teach the verifier by
    providing additional information.
Figure~\ref{fig:teach-verifier} shows an example in Cilium~\cite{borkmann-efb5d6509fea}
    where the verifier lost track of \texttt{\small nh\_params.nh\_family},
    a scalar spilled onto the stack and mistakenly treated it as a
    pointer when loading it back, leading
    to an invalid size error on the load.
As a workaround, developers passed \texttt{\small fib\_params->l.family} directly instead of
    going through \texttt{\small nh\_params.nh\_family} to let the verifier
    know the scalar value. % is a scalar.
% \end{itemize}
%The original code was fully safe, but the verifier rejected it.
% The required fix is unintuitive, which makes it less usable.
% \tianyin{I have no idea what's going on here---why the change is favored by the verifier}

%\begin{figure}
%    \begin{lstlisting}[language=rust]
%#[no_mangle]
%pub unsafe extern "C" fn memcpy(dest: *mut u8, src: *mut u8, n: usize) {
%    let dest_base = dest as usize;
%    let src_base = src as usize;
%    for i in 0..n {
%        *((dest_base + i) as *mut u8) = *((src_base + i) as *mut u8);
%    }
%}
%    \end{lstlisting}
%    \caption{Simple and specific implementation of memcpy}
%    \label{fig:aya-memcpy}
%\end{figure}

%\begin{figure}
%    \lstinputlisting[language=myC]{./snippets/s2-cilium-memcpy.c}
%    \vspace{-10pt}
%    \caption{Memcpy implementation in Cilium}
%    \vspace{-10pt}
%    \label{fig:cilium-memcpy}
%\end{figure}

\para{Dealing with verifier bugs.}
\label{motivation:kernel-version}
The \gap{} is further exacerbated by verifier bugs~\cite{untenableVerification,formal-verifier-ebpf,proof-carrying-verifier,sandbpf},
    as developers need to
    acquire knowledge of the verifier's expectations and deficiencies.
Moreover, different kernel versions can have different verifier bugs.
% \jinghao{Shall we add citation to literatures that mention there are bugs or to
%    the bug fixes themselves?}
% (tianyin) you should always add citation if you have a chance
Dealing with verifier bugs and maintaining
    compatibility across kernel versions is non-trivial.
% Different kernel versions may have different versions of the eBPF verifier, each with different sets of bugs.
% To maintain compatibility between these versions, developers have to change code to account for the differences.
In a Cilium case~\cite{graf-e38a92115620},
%The verifier failed the program with the message shown in Figure~\ref{fig:kernel-version}.
%the buggy BPF verifier rejected an extension because it saw an invalid access of a context pointer, even though
%    it was a valid access.
The verifier rejected a correct program with valid access to the context
    pointer due to the verifier's incorrect handling of constant pointer offsets.
The verifier bug was known, but the fix was not present in
    all kernel versions.
Cilium developers had to tweak their program to avoid the
    bug-triggering yet correct context pointer access so the code could verify on
    all kernel versions.

% \tianyin{what does it mean? the cilium developer needs to fix the verifier code?}
% As shown in Figure~\ref{fig:kernel-version-code} the fix needed was to move line 7 to line 1 before the block of code.
%With the \gap{}, kernel version differences add another level of complexity and overhead for extension
%    development and maintenance.

% }

%Version mismatches make eBPF much harder to use as they are decoupled.
%We discuss this further in \S\ref{discussion:versions}.

%\begin{figure}
%    \begin{lstlisting}[language=myBPF]
%1411: (bf) r1 = r9
%1412: (07) r1 += 48
%1413: (67) r2 <<= 16
%1414: (47) r2 |= 512
%1415: (63) *(u32 *)(r1 +0) = r2
%; dereference of modified ctx ptr R1 off=48+0,
%; ctx+const is allowed, ctx+const+const is not
%    \end{lstlisting}
%    \caption{Verifier output showing error}
%    \label{fig:kernel-version}
%\end{figure}

% \begin{figure}
%     \lstinputlisting[language=myC]{./snippets/s2-kernel-version.c}
%     \vspace{-10pt}
%     \caption{Kernel version specific fix}
%     \vspace{-5pt}
%     \label{fig:kernel-version-code}
% \end{figure}

%\subsubsection{Add Pruning Checkpoints}
%\label{motivation:checkpoint}
%Another common fix that Cilium implemented was to introduce a pseudo-helper function \texttt{relax\_verifier}.
%The purpose of this helper is to provide a checkpoint for the verifier to use when doing state pruning.
%All the function does is call a kernel helper function, which then introduces a new state pruning checkpoint.
%%\jinghao{Can we put more information here on this helper? It would be great
%%to show that the helper itself is complicated and developers have to insert it
%%at random places.}
%%\jinghao{My understanding is that this calls a \textit{kernel helper} so that the
%%state is reset?}
%In some cases doing so significantly decreases the complexity of eBPF programs.
%In one commit, doing so reduced the number of instructions checked from 62,569 to 49,669.
%This is more significant on older kernel versions which have a much smaller upper limit to the number of instructions the eBPF verifier could check.
%\jinghao{It now seems to me that this belongs to \S\ref{motivation:restructure}.}
%\milo{I don't think so because the state pruning knowledge is more obscure, so needing to use it is harder than refactoring. i.e. A dev may know that their loops can't be too complicated, but they may not know anything about verifier internal state pruning? It also does not really change the structure (this is intentional)}
%
%With no assistance, programmers are required to have knowledge of low-level
%    internal details of the eBPF verifier, and then implement fixes that
%    make use of this knowledge.
%Having to make this change harms the usability of eBPF.

\para{Reinventing the wheels.}
\label{motivation:wheel}
%\mvle{can we summarize what is this "specific" way?}
%We found examples of this in both .
% Aya, had to implement its own versions of
%    \texttt{\small memset} and \texttt{\small memcpy} instrinsics
%    with the purpose of passing the verifier,
%    because the builtin functions provided by the Rust
%    \texttt{\small compiler-builtins} crate could not pass the verifier.
Developers may need to reimplement existing functions
    to pass the verifier.
In Aya, the default definition of the
    \texttt{\small memset} and \texttt{\small memcpy} intrinsics provided by
    the language toolchain failed
    to pass the verifier~\cite{aya-pr-698}.
% \tianyin{the standard library function cannot pass the verifier?}
Aya eventually implemented its own version for both intrinsics, using a simple
    loop to iterate over the data to avoid ever tripping the verifier.
% Both of these projects found uses for the functions , but they had to provide their own versions of them.
%Aya wrote a simple version that looped over the data safely,
%    while Cilium implemented a more complicated version (Figure~\ref{fig:cilium-memcpy} shows a snippet of it).
% Both cases were designed to pass the verifier.
% Rather than use a standard library function, eBPF programmers have to reimplement the required functionality.
This case reflects a key challenge of using eBPF for large, complex extension programs,
    as developers may need to re-implement many standard, nontrivial library functions.

% This makes developing eBPF programs more difficult, especially when the implementation of
%    required functions is nontrivial and developers have to fight the verifier.

\vspace{-5pt}
\subsection{Implications}
\vspace{-5pt}

Our analysis shows that the \gap{} causes severe usability issues
    in developing and maintaining
    eBPF kernel extensions. %gap between programmer and verifier.
%The categories of verifier workaround that we found are direct indicators of this problem.
% \new{
% If an eBPF program fails to verify, there usually exists neither an obvious root
%    cause nor a clear road map to that root cause.
% }
eBPF developers have to implement arcane fixes and change their mental
    model to meet the verifier's constraints. % without compiler assistance.
If an eBPF extension fails to verify, the verifier log rarely pinpoints the
    root causes and cannot help trace back to the source code.
Since it is hard to require compilers like LLVM
    to follow the eBPF verifier's implementations,
    we expect the \gap{} will continue to exist, % and introduce new issues with its active development.
    especially for large, complex extension programs.

\begin{comment}
%If an eBPF program fails to verify, there is not always a clear reason why that is the case, e.g.,
%it could be that a programmer's source code is completely safe, but LLVM generates code that the verifier does not understand.
From the developers' perspective, a successful compilation should promise certain correctness
    properties of their code---this promise is broken in eBPF due to the \gap{}.
% This \gap{} is fundamental to the eBPF system.
A system that closes this gap by moving verification and compilation closer together
    might address the usability challenges of eBPF extensions and effectively improve
    the experience of developing and maintaining kernel extensions
    while ensuring the desired safety.
\end{comment}

%Different kernel versions have different verifiers with different constraints
%    and different properties that they check.
%There would have to be some way to fully expose the specifics of the verifier
%    back to the compiler to close the gap.

%\subsection{Mismatches Cause the Gap}
%In this section we examine two of the main causes of the programmer gap.
%The programmer gap is a consequence of two mismatches between the verifier and the compiler that arises due to the design of the eBPF system.
%    \begin{enumerate}
%        \item Version mismatches
%        \item Safety mismatches
%    \end{enumerate}

%\subsubsection{Version Mismatches}
%There are three sources of versioning that eBPF currently has, that may lead to issues.
%\begin{enumerate}
%    \item Kernel Interface
%    \item Verifier
%    \item Compiler
%\end{enumerate}
%
%Kernel interface version problems are resolved by the use of BTF and CO-RE in BPF.
%However, the version issues differences between the compiler and verifier are not dealt
%    with in any way.
%
%In the current eBPF system, the compiler and the verifier are decoupled.
%As development proceeds, implementation details about the compiler and verifier change.
%As seen in Table~\ref{fig:commit-table} there are examples of differences in implementation
%    between the LLVM compiler toolchain and the eBPF verifier breaking
%    program verification.
%Figure~\ref{fig:2comp1ver} shows a flowchart of how this might happen.
%
%Problems can also arise from different verifier versions.
%If an eBPF program verifies on one version, there is no guarantee that it verifies on a different version.
%Examples of this include backwards compatibility for features like loops.
%Figure~\ref{fig:1comp2ver} shows a flowchart of how this might happen.
%
%There is no way to fully resolve the issues of versioning in the eBPF system as
%    each component is a constantly moving target.
%Compilers will continue to evolve, just as the eBPF verifier will continue to evolve, and because they are decoupled, there will be places where they do not align.

%\begin{figure}
%    \includegraphics[width=1.0\linewidth]{figs/2comp1verifier}
%    \centering
%    \caption{Version issue between two compiler versions}
%    \label{fig:2comp1ver}
%\end{figure}
%
%\begin{figure}
%    \includegraphics[width=1.0\linewidth]{figs/1comp2verifier}
%    \centering
%    \caption{Version issue between two verifier versions}
%    \label{fig:1comp2ver}
%\end{figure}
