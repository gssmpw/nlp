\section{Introduction}

Proximity queries, essential for calculating the distance between objects, are fundamental in various fields such as computer graphics, the metaverse, and robotics~\cite{lin2017collision}.
Among these, penetration depth calculation, which measures the extent of overlap between two objects, is widely used in simulations of object interactions and haptic rendering~\cite{zhang2006generalized, laycock2007survey}.

Various methods have been developed for calculating penetration depth.
These methods include Minkowski sum-based algorithms~\cite{dobkin1993computing,je2012polydepth,lee2017penetration} and distance field approaches~\cite{fisher2001fast,sud2006fast}, among others.
Another common technique utilizes the Hausdorff distance between the vertices of the two objects to estimate penetration depth~\cite{SIG09HIST}.
While vertex-based methods provide approximate values and may only offer lower bounds of the penetration depth, they bypass the complexities involved in computing the Minkowski sum, presenting a more straightforward computational approach.

Several parallel processing algorithms have been developed to accelerate proximity query operations, including penetration depth calculations~\cite{kim2002fast,lien2008covering}.
With the advent of General-Purpose GPU (GPGPU) APIs like NVIDIA's Compute Unified Device Architecture (CUDA), the role of graphics processing units (GPUs) has expanded beyond traditional graphics computations to include a variety of general computing tasks.
GPUs are now extensively utilized as acceleration devices in tasks such as proximity computation~\cite{kim2009hpccd,lauterbach2010gproximity,li2011voxelized,kim2013scheduling}, demonstrating their versatility and efficiency in handling computationally intensive operations.

Traditional GPGPU primarily utilizes GPU cores designed for graphics computations.
\revision{However, modern GPUs integrate specialized hardware for ray tracing-based rendering, exemplified by NVIDIAâ€™s RTX (Ray Tracing Texel eXtreme) platform, which introduces dedicated ray-tracing hardware~\cite{turingInDepth}.}
These RTX GPUs are equipped with ray tracing cores (RT cores) optimized for such computations.
Recently, efforts to repurpose RT cores for applications beyond traditional ray tracing have demonstrated high performance and showcased their versatility across various domains~\cite{wald2019rtx,thoman2022multi,zhu2022rtnn,nagarajan2023rt}.

In this work, we propose Ray-Tracing core-based Penetration Depth (RTPD), a novel algorithm for penetration depth computation that leverages RT cores.
Our approach utilizes a Hausdorff distance-based method for measuring penetration depth~\cite{SIG09HIST}.
The RTPD algorithm is structured into two primary components: penetration surface extraction and Hausdorff distance calculation.
To enhance these steps using RT cores, we have developed a ray-tracing based algorithm for penetration point extraction (Sec.~\ref{sec:RT-PIP}) and another for Hausdorff distance calculation (Sec.~\ref{sec:RT-Hausdorff}).
Additionally, we introduce a GPU-based algorithm for generating penetration surfaces (Sec.~\ref{subsec:surfaceGen}), ensuring that RTPD operates entirely on GPU platforms.

To validate the performance of the proposed RTPD algorithm, we implemented it on various generations of RTX GPUs~\cite{thoman2022multi} and tested it across four benchmark scenes featuring models ranging in size from 50K to 12M triangles (Sec.~\ref{sec:result}).
RTPD achieved up to \ToCheck{37.66} times and \ToCheck{5.33} times higher performance than a state-of-the-art CPU algorithm~\cite{zheng2022economic} and a conventional GPU-based implementation, respectively, while maintaining a lower error rate (e.g., less than \ToCheck{6}\%).
These results confirm the effectiveness of the proposed RT core-based penetration depth measurement algorithm and highlight the potential of RT cores for diverse computational applications.
