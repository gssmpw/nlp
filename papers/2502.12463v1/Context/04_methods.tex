\section{RT-based Penetration Depth Calculation}

In this section, we provide a detailed explanation of our approaches.

\subsection{RT-based Penetration Point Extraction}\label{sec:RT-PIP}

Identifying whether a vertex $a_i$ from object A is located within the overlapping volume shared by objects A and B involves determining whether $a_i$ is inside object B.
Therefore, we can extract the penetration surface ($\partial A$) of A by identifying all vertices $a_i$ that are inside B and collecting them together.
This method is similarly applied to obtain $\partial B$.
However, this approach requires performing a \revision{point-in-polyhedron} (PIP) test for each vertex in objects A and B, potentially leading to significant computational demands.

We introduce an algorithm, RT-PIP, which leverages the RT-core to accelerate the PIP test.
This is achieved by reinterpreting the PIP test as a series of ray-casting and ray-surface intersection tests.
The underlying principle of this approach is based on the characteristic that if a point is inside an object, a ray cast from this point will intersect the object's surface an odd number of times~\cite{huang1997complexity}.

The initial step of the RT-PIP algorithm involves constructing GASs for each object.
GAS is an essential data structure for performing ray-surface tests with the RT core.
Once the GASs are in place, we begin by casting a ray from a vertex on object $A$ and examining its intersections with object $B$ using the ray-surface intersection capabilities of the RT core.
The RTX platform then returns the count of these intersections.
An odd number of intersections indicates that the vertex from object A is inside object B.

Since the ray’s direction does not influence the PIP test’s outcome, we simply align it along a specific axis, such as (1,0,0).
This method is applied to all vertices $a_i$ in object A to identify those within the overlapping volume ($P_{\partial A}$).
The independence of each vertex’s calculation allows for parallel processing of all vertices, fully utilizing the available RT cores within a GPU.
The same procedure is applied to determine $P_{\partial B}$, identifying all relevant vertices of B in the overlapping volume.

\textbf{Two-way PIP test:}
We found that errors (e.g., false positives) in ray-casting-based PIP tests could arise with RT cores, especially in the region around triangle edges or vertices.
This may be due to the limitations of floating-point precision, as RT cores currently only support floating-point operations.
To address this issue, we employ a two-way ray casting strategy.
In this method, a point is considered to be inside the object (an inner vertex) if it successfully passes the PIP test in both directions, indicating that the number of ray intersections is odd in each case.
This two-way testing strategy enhances the accuracy of our PIP results by mitigating the effects of floating-point precision errors.
%We found that errors (e.g., false positive) in the Point-in-Polygon (PIP) test could arise due to the imitations of floating-point precision.
%(Fig.~\ref{fig:twowayPIP}).
%We discovered that this two-way PIP strategy enhances accuracy by \XX\% over the one-way test, as compared to the brute-force PIP test with double-precision.
%\DS{We need to check the accuracy compared with double-precision computation.}

\Skip{
%%Two-way PIP Test
\begin{figure}[htb!]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
         \centering
        \includegraphics[height=0.9\linewidth]{Image/singlePathPIP.png}
         \caption{One-way PIP test}
         \label{fig:singlePIP}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\linewidth}
         \centering
        \includegraphics[width=0.9\linewidth, height=0.9\linewidth]{Image/dualPathPIP.pdf}
         \caption{Two-way PIP test}
         \label{fig:DualPIP}
     \end{subfigure}
    \caption{
    These images depict the results of one-way and two-way PIP tests for penetration point extraction.
    Red highlights indicate vertexes identified inside the object.
    The left image shows inaccuracies in the one-way test's classification.}
    \label{fig:twowayPIP}
\end{figure}
}

%To have a vertex $a_i$ of object $A$ within the overlap volume $V$ of objects $A$ and $B$ means that $a_i$ is inside $B$. Therefore we can extract the surface of object A ($\partial V_{A}$) inside overlap region $V$ by identifying $a_i$ points in the inner side of $B$ and collecting all of the surfaces that include them. Also, we can extract the surface of object B ($\partial V_{B}$) using the same way. However, this method has a high computational cost because that needs a PIP test about all of the vertex.

%To reduce a PIP test time, we propose a PIP algorithm using RT-core. The proposed RT core-based PIP algorithm is based on ray casting and ray-surface intersection tests. The first step of RT core-based PIP is GAS(Geometry Acceleration Structure) building. GAS is a data structure for ray-intersection tests using RT-core, we build GAS for each object since we have to test on each object, not on the total scene. 

\Skip{
    \begin{figure}[htb!]
        \centering
        \includegraphics[width=0.7\linewidth]{Image/bidirentionalPIP.png}
        \caption{Two-way Point-In-Polygon (PIP) test}
        \label{fig:PIP}
    \end{figure}
}

%After building GAS, we cast the ray from the vertex of the object $A$ and test the intersection between the ray and the surface of the object $B$. During the ray-surface-intersection test of the RT-core, we can determine the number of surfaces that intersect with each ray. If the vertex is within the object's inner side, the number of intersected surfaces is odd (Fig.~\ref{fig:PIP}). In this case, the direction of the ray does not influence the result, as the objective is simply to ascertain whether the vertex is inside or outside. Therefore, we set the ray’s origin at the vertex’s position and direct the ray parallel to an axis (e.g. $(1,0,0)$). We accumulate the number of intersections per vertex by tallying each ray’s hits. As these ray-intersection tests are mutually independent, the PIP test for each vertex can be computed concurrently. Similarly, we extract the penetrated vertices of $B$ by tracing the rays from the vertices to the surface of the object $A$. Finally, we obtain all the vertices included in the overlap volume.


%\paragraph{Two-way PIP test:} We found the error in several PIP results due to the problem of GPU floating-point precision(Fig. ~\ref{fig:singlePIP}). To solve this issue, we cast the ray two-way and judge the point to the inner vertex if that success on all two-way tests (That means the number of ray intersections is an odd number).



\subsection{Penetration Surface Generation on GPU}\label{subsec:surfaceGen}

The RTPD algorithm determines penetration by calculating the Hausdorff distance between penetration surfaces.
Due to the RTX platform's limitation in not supporting the construction of GAS for only parts of an object, it is necessary to create distinct objects for each penetration surface using the extracted penetration points, such as $P_{\partial A}$ and $P_{\partial B}$.
This step requires a new triangle list that includes only the triangles composed of one or more penetration vertices..

To create the penetration triangle list, we traverse the original triangle list once, verifying whether each triangle contains any penetration vertices.
The challenge becomes more complex when constructing a vertex list that includes only penetration vertices, as some vertices are shared by multiple triangles.
This requires assigning a unique vertex index to each penetration vertex to ensure accurate representation and prevent redundancy.

While map data structures offer rapid search and insertion capabilities, making them convenient for creating vertex lists, they present challenges when used in GPU architecture.
Their irregular data access patterns are inefficient for GPUs.
Managing parallel access to maps can also be complex on GPUs, potentially leading to synchronization issues.
Initially, we considered using the CPU to generate the vertex list; however, we found that the overhead of transferring data between the CPU and GPU outweighed the benefits of the RT-core's acceleration capabilities.

To avoid data communication overhead and fully leverage the GPU's parallel computing capabilities, we developed a CUDA-based algorithm for generating penetration surfaces.
This algorithm consists of three key steps: vertex extraction, compaction, and mapping (Fig.~\ref{fig:surfacegen}).

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Image/pSurfaceGen.pdf}
    \caption{The process of the penetration surface generation on GPU.}
    \label{fig:surfacegen}
\end{figure}

\textbf{Vertex extraction:}
Each triangle is identified by three vertex indices in the vertex list of the original object ($list_{P_O}$).
This step aims to identify vertices that are part of the penetration surfaces while ensuring no duplicates are present.
The result is a list containing the indices of these unique vertices ($list_{vID}$).
This array is generated by using the vertex index as a key in a reduction operation~\cite{roger2007efficient}.
To enhance GPU performance, the $reduce\_by\_key$ function from NVIDIA's Thrust library is utilized.

%Generally, the components that make up the polygon model consist of a set of vertices and a set of triangles that reference them.
%In this step, we extract and copy the vertex from the original polygon model to a newer one. Since the penetration surface contains the neighbor vertices that are not contained in PIP results, we also need to extract these vertices.
%A triangle consists of vertex indices; thus, by gathering the index information present in the triangle list, we can identify and copy the vertex indices from the original polygon. Essentially, by removing duplicate vertex indices in the triangle list, we can accomplish this task. We obtain this result by setting the vertex index as a key and using an algorithm called $reduce\_by\_key$.  For enhanced performance on the GPU, we utilize $thrust::reduce\_by\_key$ from NVIDIA's Thrust library, which optimizes this operation.


\textbf{Compaction:}
The compaction step generates a streamlined vertex list ($list_{P_{\partial O}}$) that includes only the vertices identified in $list_{vID}$ while establishing a lookup table ($lookup$) that maps vertex indices between $list_{P_O}$ and $list_{P_{\partial O}}$.
This process is executed by launching CUDA threads equal to the number of vertices in $list_{vID}$.
Each thread copies a vertex from $list_{P_O}[list_{vID}[t]]$ to $list_{P_{\partial O}}[t]$, where $t$ denotes the thread's ID.
Concurrently, it records the new location of its respective vertex in $list_{P_{\partial O}}$ within the lookup table.
As a result, $lookup[i]$ reflects the revised index within $list_{P_{\partial O}}$ for the $i$-th vertex originally in $list_{P_O}$.

%We define the simple kernel for look-up table generation and allocate the threads as much as the count of the unique vertex. For the look-up table, we set the table capacity to the size of the original model's vertex. Then, each thread accesses the look-up table using a unique vertex index that is computed on the vertex extraction step and writes the thread index to the look-up table. This method requires more memory capacity than the map structure-based method, however can be implemented easily instead.

\textbf{Mapping:}
The mapping step updates the vertex indices in $list_{\partial O}$ to correspond with those in $list_{P_{\partial O}}$.
This is accomplished using the lookup table, where each value in $list_{\partial O}$ is replaced by its corresponding index in $list_{P_{\partial O}}$.
In this step, CUDA threads are launched in a quantity equal to the number of triangles in $list_{\partial O}$.

This algorithm is applied to both objects to generate penetration surfaces $\partial A$ and $\partial B$.
Subsequently, the penetration surfaces and penetration points are forwarded to the Hausdorff distance calculation phase.

%In the mapping step, we allocate the thread as much as the count of penetration triangles. Similar to the look-up table generation step, each thread accesses the look-up table using a unique vertex index and gets the new vertex index. As a result, each thread writes a new triangle list with a newly assigned vertex index. Finally, we copy a vertex to a new vertex list using a unique vertex index and combine this vertex information with a new triangle list to create independent objects.


%Since our proposed method operates on the GPU side only without communication between CPU and GPU, our proposed method has the benefit of reducing time for the overall pipeline than using a CPU-based subdivision process.


%\DS{Add a figure or a Pseudo-code to explain the process}



%To utilize the RT-core for computing the Hausdorff distance between two penetration surfaces, we need to extract the faces that construct the penetration surface. These penetration surfaces must be defined as independent objects and we can approximate this as a set of faces that contain the penetration vertices. In this paper, we make the new object (e.g. $\partial A$) by coping the extracted surfaces that contain the penetration vertices (e.g. $P_{\partial A}$). To optimize the computational cost, this penetration surface extraction is processed on the GPU (called "subdivision process", sec.~\ref{sec:gpu-based subdivision}).

%\subsubsection{GPU-based subdivision process}
%\label{sec:gpu-based subdivision}

%The simple way to separate a part of the original model into a new one is by using a map data structure. We already know the triangle information (e.g. $(v1, v2, v3)$), so we push the index of the vertex to the map and allocate a new vertex index as the size of the map. As a result, we obtain the unique vertex index of the object about the penetration surface and triangle information by the unique vertex. We can create a new independent object by copying the unique vertex and using the newly created triangle information.

%While this process can be implemented easily on the CPU side, implementing this subdivision process on the GPU using a map data structure is hard. This difficulty arises because the map data structure does not inherently support thread safety and is not well-suited for GPU processing. To solve this, we propose the GPU-based subdivision algorithms. This algorithm consists of three steps, namely $Deduplication$, $Look-up \ table \ generation$, and $Mapping$.

%\input{Context/Algorithm/GPU-based subdivision}



%In this step, we remove duplicated vertex information of penetrated triangles. we adapt prefix sum-based compaction algorithms for extracting unique vertex indices. It can be implemented using NVIDIA thrust. These unique vertex indices will be used to allocate new vertex indexes to the look-up table.
%\DS{It need more details}
%~\\




\subsection{RT-based Hausdorff Distance calculation}\label{sec:RT-Hausdorff}

The penetration depth between objects $A$ and $B$ is equivalent to the Hausdorff distance between their respective penetration surfaces, $\partial A$ and $\partial B$ (i.e., $H(\partial A, \partial B)$).
This distance can be approximated by calculating the distances between the vertices of one object and the surface of the other.
An essential output of the ray-surface intersection test on the RTX platform is the length of the ray from its start point (the vertex) to the intersected surface.
We utilize this ray-surface intersection test capability of the RTX platform to compute the Hausdorff distance, thereby efficiently determining the penetration depth.

Our RT-based Hausdorff distance algorithm, RT-HDIST, calculates both $h(\partial A,\partial B)$ and $h(\partial B,\partial A)$, selecting the larger of the two as the final result.
The process to compute $h(X,Y)$ begins with RT-HDIST acquiring $P_X$ \revision{(the point set of X)} and $GAS_Y$.
The algorithm launches rays from each vertex $p_i$ in $P_X$ toward a set of directions determined by a sampling strategy (Sec.~\ref{subsec:sampling}).
This approach aims to identify the minimum distance from each vertex $p_i$ to object $Y$, denoted as $min_{p_i}$.
RT-HDIST executes this process for each vertex $p_i$ in $P_X$, ultimately determining the maximum value among all $min_{p_i}$ values.
This maximum value represents the calculated directional Hausdorff distance, $h(X,Y)$.
The computation of the Hausdorff distance is enabled by leveraging the ray-surface intersection capabilities of the RTX platform.

\textbf{Ray-length adaptation culling:}
In processing a vertex $p_i$, the goal is to determine the minimum distance from all rays emanating from $p_i$.
Therefore, it is unnecessary to calculate the distance to any surface further than the current minimum distance.
On the RTX platform, the length of a cast ray can be set.
Utilizing this feature, we optimize the algorithm by adapting the ray's length to match the current minimum distance obtained from previously processed rays of $p_i$.
This strategy reduces redundant ray traversal and enhances the efficiency of the RT-HDIST algorithm.

\textbf{Work distribution:}
\revision{Without ray-adaptation culling, each ray-surface intersection test in our algorithm is independent, allowing for concurrent execution.
However, applying ray-adaptation culling requires synchronization among threads handling rays originating from the same vertex, further complicating the process.
Additionally, assigning one thread per ray could lead to an excessive number of threads, increasing overhead associated with thread management.
To address these challenges and improve efficiency, we adopt a work distribution strategy in which a single thread handles all rays associated with a specific vertex, processing them iteratively.
In other words, the basic work unit is a vertex (i.e., a ray source), and our method processes the vertices in parallel.}
%This approach substantially reduces the total number of threads required and eliminates the need for synchronization in ray-length adaptation culling. 

%However, as the number of vertices in the overlapping volume increases, the quantity of rays that must be cast for each vertex also escalates significantly.
%Allocating one thread per ray could lead to an excessive number of threads, thereby increasing memory usage and the overhead associated with thread management.
%Moreover, the implementation of ray-length adaptation culling necessitates synchronization among threads that handle rays emanating from the same point, further complicating the process.



%The proposed algorithms perform intersection tests as much as $|P_{\partial A}| * |P_{sample}|$. Typically, work distribution is managed by allocating one thread per ray. However, when dealing with large models or extensive overlap regions, distributing threads for all rays can lead to a significant increase in both the number of threads required and memory usage. Furthermore, if each thread is dedicated to a single ray, they must synchronize to identify the minimum value for each vertex. This synchronization can reduce the efficiency of parallel processing. To avoid this, our work distributes the thread per each vertex, not the ray candidate, and the allocated thread performs processing for every ray cast from that vertex while the kernel launches once.

%When calling the ray traverse on the RTX platform, we can set the ray length $T_{min}$ and $T_{max}$ not only ray origin and direction. Threads corresponding to each vertex $p_i$ find the closest distance to target surfaces. To compute this, each threads iterate the traverse ray as much as the sampling count, at this time, we need not test for far distance than the previous test result. Therefore, we can optimize the traverse time by updating the ray distance to the minimum results of each iteration.


\subsection{Ray Sampling Strategy}\label{subsec:sampling}

Although increasing the number of rays improves accuracy, it also increases processing time.
A straightforward approach involves casting rays toward all vertices of the opposing object.
However, this method causes the number of rays to grow exponentially with the penetration surface volume (i.e., $O(|P_{\partial A}| \times |P_{\partial B}|)$).
Additionally, employing this naive strategy results in some rays being directed toward the same or nearly identical directions, leading to redundant ray-surface intersection tests.

One practical approach is the \textit{sphere sampling} method, which entails sampling ray directions directly from the query point.
Sphere sampling is reasonably effective for closely positioned penetration surfaces.
However, it has been observed that as the distance between the penetration surfaces of the two objects increases—especially when the overlapping volume enlarges—the proportion of valid rays, those intersecting the target penetration surface, decreases.
Additionally, the number of rays required to achieve accurate results increases significantly with the volume of overlap, adversely affecting processing performance.

To more accurately target the sampling area, we introduce the \textit{vertex sampling} method.
By selectively sampling vertices from the opposing object, we determine the direction for each ray based on the line extending from the ray origin to the chosen vertex.
We discovered that uniform sampling based on vertex ID is effective in maintaining a balance between accuracy and computational efficiency.
We found that a sampling rate—defined as the ratio of sampled vertices to the total vertices on the penetration surface—of approximately 1\% is generally sufficient to maintain an error ratio below 2\% relative to the ground truth distance. 
%This technique leverages the principle that the distances between a query point and the vertices in the opposing object can closely approximate the minimum distance between the point and the object.

Further refining the vertex sampling method, we incorporate the distance information obtained during the PIP test.
When a collision occurs between a ray launched from the query point ($p_i$) and the opposing object, it establishes a specific distance to a point on that object ($d_{pip}(p_i)$).
This distance suggests that the minimum distance between the query point and the object does not exceed $d_{pip}(p_i)$.
Using this information, we optimize the sampling process by focusing only on vertices within this distance, thereby enhancing both the precision and efficiency of our ray sampling strategy.

We have fully integrated the ray sampling processes into CUDA kernels, ensuring that all components of the RT-HDIST algorithm are executed on the GPU.
Furthermore, we have observed that the overhead associated with ray sampling is relatively minor, accounting for less than 0.1\% of the total processing time (e.g., 1-2 ms).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\input{Context/Figure/fig_sampling}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Skip{ %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To minimize the computational overhead of the RT-HDIST algorithm while preserving accuracy, we employ the Monte Carlo approximation method to estimate the Hausdorff distance.
This approximation involves sampling rays in various random directions from their origin.

%In this paper, we introduce two methods for sampling these ray directions: Hemisphere Sampling (illustrated in Fig.~\ref{fig:sampling_hemi_sampling}) and Axis-Aligned Bounding Box (AABB) Sampling (shown in Fig.~\ref{fig:sampling_aabb_sampling}).

One viable strategy is the \textit{Hemisphere sampling} method (Fig.\ref{fig:sampling_hemi_sampling}), influenced by the Bidirectional Reflectance Distribution Function (BRDF) used in rendering applications.
This technique leverages the principle that one object's penetration surface is enclosed by another. 
It involves randomly sampling ray directions from a hemisphere centered around the direction opposite to the normal vector at the vertex (the ray origin)~\cite{montes2012overview}.
While Hemisphere sampling is particularly effective for closely situated penetration surfaces, it has been observed that the proportion of valid rays—those intersecting the target penetration surface—decreases as the distance between the penetration surfaces of the two objects increases, especially when the overlapping volume enlarges.
%We implement this method based on a cosine-weighted hemisphere sampling method~\cite{montes2012overview}.

To more precisely target the sampling area, we introduce the Axis-Aligned Bounding Box (AABB)-based ray sampling method.
The \textit{AABB sampling} technique involves selecting points within the AABB that surrounds the penetration surface of the opposing object (illustrated by the dotted lines in Fig.~\ref{fig:sampling_aabb_sampling}).
The direction of each ray is determined by the line extending from the ray origin to the sampled point (marked by red circles in Fig.~\ref{fig:sampling_aabb_sampling}).
Adhering to the principle of enclosure, we only accept samples whose directions are opposite to the vertex's normal vector.
This targeted approach enhances both the efficiency and accuracy of the ray sampling process by ensuring that rays are concentrated in the most relevant directions.
%In our benchmark tests, we discovered that our AABB sampling method enhances ray sampling efficiency (i.e., the proportion of valid directions) by up to \XX\% in comparison to hemisphere sampling.

We refine the AABB sampling by integrating the distance found during the PIP test.
When a ray launched from the query point ($p_i$) collides with the opposing object during the PIP test, it establishes the distance to a point on that object ($d_{pip}(p_i)$).
This information suggests that the minimum distance between the query point and the object does not exceed $d_{pip}(p_i)$.
Utilizing this data, we adjust the AABB sampling area by localizing the region: we define it as the overlap of the initial AABB and a new AABB centered at $p_i$, with its width and height both expanded to twice $d_{pip}(p_i)$.
} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\DS{Add a figure explainig Top-AABB sampling}
%\paragraph{AABB sampling:} 
%To avoid this situation, we sampled the target point inside the box that tightly covered the target object instead of using hemisphere sampling.
%Unfortunately, this method requires the AABB for the target object and we need to build it despite using RT core to build GAS.
%AABB can be built by finding minimum and maximum elements for all input vertices.
%Therefore, we use the min-max operation $thrust::min\_element$ and $thrust::max\_element$ for computing AABB. This operation takes very little time on the GPU side.

%Finally, we input a set of vertex and opposite GAS to compute the Hausdorff distance. 
%In the $ray\_ gen$ program, we sampled direction to point on a hemisphere or to point inside AABB instead of every vertex on the target surfaces. 
%As a result, we can obtain the approximated Hausdorff distance with a small error in less time than straightforward approaches.

%The most straightforward approach is to trace the ray from each vertex $p_i$($\in P_{\partial A}$) of the object $\partial A$ to every vertex of the object $\partial B$ when defining the Hausdorff distance as $h(\partial A,\partial B)$. In this case, we give two inputs the set of vertices $P_{\partial A}$ and $GAS_{B}$. Then ray that is cast from each vertex $p_i$ will traverse $GAS_{B}$ and calculate the distance to the nearest plane above $\partial B$. After completing the distance computation for all $p_i$, the biggest one is $h(\partial A,\partial B)$. We can compute the final Hausdorff distance $H(\partial A, \partial B)$ by operating both directions.

%However, casting rays for every pair between $P_{\partial A} \to P_{\partial B}$ has too many unnecessary operations. For instance, some vertex on the $P_{\partial B}$ lies side-by-side in a similar direction from ray origin $p_i$. In this case, the ray candidates will be overlapped and repeat a similar traversal.

%To reduce the number of ray candidates, we propose an RT-based Hausdorff distance calculation method incorporating Monte Carlo sampling. We employ two methods for sampling rays: Hemisphere sampling and Axis-aligned bounding box (AABB) sampling.
