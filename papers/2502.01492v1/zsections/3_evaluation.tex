\section{Designing Evaluations for System Engineering}
We highlight core trade-offs associated with building systems, namely efficiency, scalability and adaptability. We argue that system engineering training and evaluation environments must be \textit{dynamic} and \textit{open-ended} to adequately assess the dynamic equilibrium of these characteristics.

\subsection{Real-World Intuition}
In the design phase of a system engineering project, the focus is on delivering a proposal that meets various requirements and user preferences for features and costs. This requires deep domain expertise since many valid proposals can exist, yet vary in terms of up-front costs, maintenance costs, implementation time, complexity, regulatory compliance, scalability, and so on. Design capability is readily tested in the software industry with system design interviews that pose questions such as “How would you design a real-time collaborative word processing application like Google Docs?” or, more bluntly, “Design Google Docs.”, “Design Uber.”, “Design Twitter.”, etc. These questions are not meant to be answered in a single pass, but rather serve as a starting point for iteratively gathering requirements and proposing increasingly detailed solutions.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{zimages/_systems/requisite_variety4.pdf}
    \caption{\textit{The Law of Requisite Variety.} $T_V: A \rightarrow E$ is a trajectory where a system stays \textbf{viable} through adaptation. $T_U: A \rightarrow D\prime$ shows an alternate trajectory where the system does not adapt and becomes \textbf{unviable}. A system is viable within the total state space $S$ when the variety of the environment at that time $V_E$ remains a subset of variety the system can handle $V_R$. Systems must adapt proactively ($A \rightarrow B$) to ensure this condition is met, but then ideally reduce variety to improve efficiency and maintainability ($D\rightarrow E$).}
    \label{fig:requisite_variety}
\end{figure}

After a real system is designed, the implementation phase begins and often never truly ends. Successful systems typically continue to expand in scope because increased outputs fuel greater demand. This pattern is evident in large software services, energy networks, and public transportation systems. Even if overall scale plateaus, there is an ongoing need for repair and maintenance—particularly in physical systems but also in software, which must periodically upgrade dependencies and refactor for performance. Consequently, the longevity and effectiveness of a system fundamentally depend on its capacity to assimilate feedback and \textit{adapt} to inevitable changes.

Feedback collection is facilitated through automated means like logging in software or more manually such as accepting verbal customer feedback. Adapting the system with this feedback is thus core to ensuring it meets expectations through key performance indicators. Some future scenarios are more serious and difficult to fully predict. Recent examples such as the COVID-19 pandemic required large-scale adaptations not seen since World War II, and the volatility of geopolitics—as highlighted by the conflict in Ukraine—continues to demand swift adjustments in global systems. Natural disasters like hurricanes and wildfires, technological breakthroughs such as the generative AI boom, major cybersecurity incidents, and new discoveries of key commodities further underscore the need for flexible system design.

\subsection{Supporting Theory}
Fortunately, the study of systems has long acknowledged the value of adaptability, leading to foundational frameworks that inform real-world solutions. One such lineage is \emph{cybernetics} \cite{wiener1948}, which reveals how continuous feedback loops and robust communication channels allow systems to counter external disturbances. Ashby’s \textbf{law of requisite variety (LRV)} \cite{ashby1956} stresses that systems must possess enough complexity (known as \textit{variety}) internally to handle the complexity of potential external disruptions (Figure \ref{fig:requisite_variety}. If this condition is not met, it can lead to a loss of \textit{stability} of the system, meaning that it will not be able to maintain desired indicators of success. The intuition is comparable to that of machine learning theory, where out-of-distribution inputs lead to poor model performance. 

The law is typically presented in the static setting, meaning it applies to the (internal) response variety ($V_R$) and environmental variety ($V_E$) at any given time. However, it can be extended to apply over time, where the configuration of a system must be able to change in order to support the particular variety of the environment over time (Figure~\ref{fig:requisite_variety}). Building on this, Beer's \textbf{viable system model (VSM)} \cite{beer1959, beer1972} emphasizes hierarchical structures for robust systems. The modularity of hierarchy allows different levels of a system to handle only the variety of inputs which the level is responsible for (Figure \ref{fig:viable_system}, Table~\ref{table:vsm_table}). For example, the lowest level (System 1) of viable systems are the autonomous operational units which act in the world, so they individually only need to support their distinct low-level functions. In this model, it is essential for systems to have a layer which plans \textit{proactive} \textit{adaptation} (System 4), enabling organizations and infrastructures to pivot swiftly under changing requirements. 

The law of requisite variety (LRV) and the viable system model (VSM) highlight a central tension in robust system operation: \textit{efficiency} and \textit{flexibility} tend to come at the cost of each other. For instance, a mechanized assembly line can mass-produce a single product more rapidly than a human worker, yet the latter may be more versatile in producing a variety of items. In software, production-level code is often streamlined through rigid abstractions, whereas one-off scripts are less optimized but highly flexible. Even in the study of LLMs, the choice between prompt-engineering large models and finetuning smaller ones reflect this same trade-off. This principle is shown graphically in Figure~\ref{fig:requisite_variety} where system variety $V_R$ is expensive to maintain, and ultimately should be reduced when unneeded. Likewise, Figure~\ref{fig:viable_system} illustrates that System 3 and 4 directly embody this tension and it is up to System 5 to arbitrate and maintain cohesion. Scaling up and maintaining systems thus presents a persistent challenge of preserving \emph{dynamic equilibrium}, in which the benefits of automation and scale do not compromise a system’s capacity to adapt \cite{forrester1961industrial, holling1973resilience, sterman2000business}.

From a machine learning perspective, adaptability has been explored under many paradigms, including domain adaptation \cite{redko2022domainadaptationtheory}, meta-learning for agents \cite{beck2024metareinforcementlearning}, continual learning \cite{wang2024continuallearning}, in-context learning \cite{dong2024incontextlearning}, and out-of-distribution generalization \cite{liu2023outofdistribution}. Central themes across these fields involve developing robust representations, ensuring sample-efficient training, and promoting safe exploration. By weaving AI-driven automation into systems, we now have the opportunity to significantly enhance both efficiency and adaptability—two objectives that have traditionally been at odds.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{zimages/_systems/viable_system6.pdf}
    \caption{\textit{The Viable System Model.} Systems are organized into five levels concisely given as: \textit{1. operational units, 2. coordination, 3. present optimization, 4. future planning, and 5. ultimate policy.} \textbf{See Table~\ref{table:vsm_table}} for longer descriptions. These levels are only responsible for the \textit{variety} associated with that level and can escalate or delegate as needed. A key aspect is how Level 5 effectively balances out the tension between Levels 3 and 4 which are more present- and future-focused respectively.}
    \label{fig:viable_system}
\end{figure}

\subsection{Evaluations for AI Agents}
Recent advances in AI research have fueled efforts to build virtual agents capable of increasingly complex interactions with real-world interfaces. As these cognitive capabilities continue to mature, they provide a foundation for agents to meaningfully contribute to system engineering projects. Realizing this vision, however, requires a fundamental rethinking of how we both train and evaluate virtual AI agents.

Evaluation methods for LLM-derived agents naturally began with classic NLP benchmarks, such as question answering in MMLU \cite{hendrycks2021mmlu}. They have since evolved to encompass multi-turn interaction \cite{zheng2023mtbench}, multimodality \cite{yue2024mmmu}, and external tool use \cite{zhou2023agentbench, he2024webvoyager}—capabilities expected of advanced AI agents. SWE-bench \cite{jimenez2024swebench} (and its multimodal extension \cite{yang2024swebenchmultimodalaisystems}) is likely the most challenging agent benchmark in use today. It requires agents to resolve issues in codebases by modifying multiple files and subsequently passing unit tests. Though it involves reasoning and multi-step planning, it remains a static evaluation that does not measure the capacity to maintain dynamic equilibrium between VSM Systems 3 and 4 and deal with the uncertainty of dynamic environment variety as per the LRV. This would hold true even for an extension of the benchmark in which agents designed a system like Google Docs and implemented it, yet never had to respond to changing requirements or circumstances.

By contrast, non-LLM-based agents have often been evaluated in \emph{dynamic} environments. This is the case for agents achieving superhuman performance in competitive games such as Go \cite{silver2017alphazero} and StarCraft II \cite{vinyals2019alphastar}, where the presence of an opponent forces rapid adaptations to both the agent’s own actions and those of adversaries. For a time, increasingly complex games appeared to be a promising route to building general intelligence, culminating in work on \textit{Minecraft} via Voyager \cite{wang2023voyager} and MineDojo \cite{fan2022minedojo}. These agents achieved goals in a \emph{dynamic}, \emph{open-ended} environment, with effectively unconstrained objectives demanding resource gathering, multi-step planning, and adaptability to emergent challenges. 

\subsection{The Ideal Evaluation Environment for System Engineering}
Interest in dynamic, open-ended environments waned somewhat after the advent of LLM-based generalist models. However, the rapid evolution of ChatGPT and its successors—featuring multimodality, tool-use capabilities, and ample test-time compute—opens new possibilities for resurrecting this research agenda in a more advanced form.

We deduce from the ar, \emph{sandbox games} which support \textit{automation} as a mechanic are the ideal setting for evaluating system engineering. They let researchers specify high-level objectives and observe an agent’s ability to break down tasks, weigh trade-offs, and implement solutions. Over time, the researcher can change these objectives or introduce disruptions, testing the agent’s capacity to maintain a healthy dynamic equilibrium as per the viable system model. Greater open-endedness is also desirable as it allows for more comprehensive testing of an agent's ability to comply with the law of requisite variety. Simulated environments additionally have the benefits of being fundamentally safer than real-world testing and can manage the trade-off between world physics complexity and scalability.

{
\hyphenpenalty=10000
\exhyphenpenalty=10000
\begin{table*}[htbp!]
\centering
\small
\begin{tabular}{l|p{4cm}p{8.5cm}}
%\begin{tabular}{%
%    >{\centering\arraybackslash}m{3cm}
%    |>{\centering\arraybackslash}m{5cm}
%    |p{7.5cm}%
%}
\hline

\noalign{\vskip 2pt}
\textbf{VSM Level} & \textbf{Responsibility} & \textbf{Factorio Example} \\
\noalign{\vskip 2pt}
\hline
\noalign{\vskip 1pt}
\textbf{System 1} &
Front-line operations; directly transform inputs into outputs &
Assemblers, miners, and furnaces that convert raw materials (e.g.\ iron ore) into plates and intermediate products. These are the basic production units forming the backbone of the factory. \\
\noalign{\vskip 1pt}
\hline
\noalign{\vskip 1pt}
\textbf{System 2} &
Coordinates and stabilizes System 1 units &
Conveyor belts, splitters, and simpler logistic setups to route materials between different production areas, prevent bottlenecks, and ensure each assembler or furnace receives the resources it needs. \\
\noalign{\vskip 1pt}
\hline
\noalign{\vskip 1pt}
\textbf{System 3} &
Manages and allocates resources, drives efficiency, ensures smooth operation &
Monitoring production levels, adjusting supply lines to balance throughput, and deploying construction/logistics bots for on-demand tasks such as repairs or setting up new sections. This maintains overall operational stability. \\
\noalign{\vskip 1pt}
\hline
\noalign{\vskip 1pt}
\textbf{System 4} &
Plans expansions, researches new technology, foresees future needs &
Choosing research paths (e.g.\ robotics, nuclear power), planning additional outposts for resource gathering, and redesigning factory layouts to handle increased demand or optimize long-term efficiency. \\
\noalign{\vskip 1pt}
\hline
\noalign{\vskip 1pt}
\textbf{System 5} &
Sets overall purpose, policy, and alignment &
Defining the ultimate mission (e.g.\ launching a rocket by a target time), deciding on environmental constraints (such as minimizing pollution), and determining the overarching strategy (e.g.\ peaceful or militaristic). \\
\noalign{\vskip 1pt}
\hline
\end{tabular}
\caption{Viable System Model (VSM) levels mapped to Factorio examples.}
\label{table:vsm_table}
\end{table*}
}


Drawing on \textit{Minecraft} as inspiration, one can envision an “ideal” environment that focuses on abstractions relevant to system engineering while omitting excessively detailed physics. Full 3D simulations can be computationally expensive and often distract from the higher-level reasoning crucial for scaling and process orchestration. Accordingly, a game environment centered on resource flows, balancing trade-offs, and long-horizon planning is preferable. Core properties of such an environment include:
\begin{itemize}
    \item \textbf{Automation.} The agent’s action space should permit automating processes and managing the associated trade-offs between efficiency and adaptability. This is key for testing System 3 and 4 capability as per the VSM.
    \item \textbf{Complex Evaluation Metrics.} Long-horizon performance, resource usage, and resilience under partial failures become measurable, enabling richer assessments than single-turn tests. This is part of high environment variety in the LRV.
    \item \textbf{Multi-Agent Support.} Collaboration with peers, hierarchical coordination, and competition with adversaries significantly increase complexity, further testing an agent’s capacity to adapt. This is also key for testing System 3 and 4 capability in the VSM. 
    \item \textbf{Modding Support.} Allowing users and artificial agents to create modifications or extensions fosters adaptation to out-of-distribution scenarios. This another way to have high environment variety in the LRV.
    \item \textbf{Scalability.} The environment mechanics should be at the right level of abstraction to facilitate systems reasoning, planning, and implementation without requiring excessive computational resources.
\end{itemize}

There are many candidate sandbox games—\textit{Cities: Skylines}, \textit{The Sims}, \textit{Stardew Valley}, \textit{Kerbal Space Program}, \textit{No Man's Sky}, \textit{Satisfactory}, among others—that support a form of system engineering. Yet they each have limitations with respect to one or more of the above criteria. As the next section will show, \emph{Factorio} stands out for providing an ideal testbed for AI system engineering: its mechanics inherently encourage large-scale “megabase” building, resource management, automation, and iterative adaptation.