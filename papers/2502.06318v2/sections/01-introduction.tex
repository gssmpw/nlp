\section{Introduction}

% In the rapidly evolving landscape of 
In modern cloud systems, the adoption of loosely coupled designs for applications and services has marked a significant paradigm shift in software architecture.
While such modular design brings the benefits of scalability and operational flexibility, it also complicates different aspects of software development and maintenance, including testing, debugging and diagnosing.
This can be largely attributed to the cascading effect of failures~\cite{DBLP:conf/icse/DangLH19,DBLP:conf/sigsoft/ChenKLZZXZYSXDG20}, i.e., a single failure in one service can quickly propagate to other interconnected services and components.
As such, distributed tracing has emerged as an essential reliability management solution in cloud systems.
This is primarily due to its ability to provide a comprehensive and granular view of the interactions between services, allowing for the precise identification of where and how failures occur and spread.

In cloud service systems, unusual and edge-case system behaviors, such as tail latency and resource contention, are rare by definition.
To achieve high coverage of outlier system events, it is necessary to trace \textit{all} requests.
In production environments, this may result in substantial trace data, incurring significant overhead and costs related to trace generation, collection, and ingestion.
To mitigate this problem, various \textit{trace sampling} techniques have been proposed, which can be categorized into two main types, i.e., \textit{head-based sampling}~\cite{DBLP:conf/nsdi/ZhangXAVM23} and \textit{tail-based sampling}~\cite{DBLP:conf/IEEEcloud/ChenJSLZ24,DBLP:conf/icws/HuangCYCZ21,DBLP:conf/sigsoft/HeFLZ0LR023,DBLP:conf/nsdi/ZhangXAVM23}.
Head-based sampling uniformly collects traces at random based on a small sampling rate (e.g., 1\%~\cite{DBLP:conf/nsdi/ZhangXAVM23,DBLP:conf/cloud/Las-CasasPAM19,DBLP:conf/sosp/KaldorMBGKOOSSV17}).
The sampling decision is made before request execution, and only the sampled requests will be traced.
On the other hand, tail-based sampling captures traces for all requests, and decides whether to retain a trace based on the execution details such as latency and HTTP status code.
In this regard, many machine learning techniques have been applied to automatically select informative and uncommon traces.
However, given the inherent unpredictability of the true value of traces, trace sampling struggles to capture the full spectrum of critical information necessary for effective software testing and failure diagnosis.

In this paper, we propose \alias, an online and scalable solution to address the overhead of distributed tracing by \textit{trace compression}.
\alias transforms spans into a concise representation upon their generation at the service side, which can be seamlessly decompressed at the backend side.
This strategy significantly reduces the volume of data that needs to be transmitted.
We discuss two possible solutions for this end.
The first is \textit{offline log compression}~\cite{DBLP:conf/fast/WeiZWLZCSZ21,DBLP:conf/icse/LiZL024,DBLP:conf/osdi/RodriguesLY21,wang2024muslope}, which condenses log data after it has been aggregated at the backend for long-term persistence.
As the primary goal is to save storage space, this approach often involves sophisticated algorithms which fail to meet the real-time requirements for trace collection.
Moreover, it often requires processing the entire log dataset to achieve the optimal performance.
In our scenario, online learning capability is crucial as traces are continuously generated in a stream.
\textit{General-purpose compression algorithms} (e.g., gzip and bzip) may also seem an out-of-box solution.
However, they are designed for encoding arbitrary binary sequences, which can only exploit redundant information within a short sliding window (e.g., 32KB in gzip's Deflate algorithm).

To pursue more effective compression, \alias harnesses the global redundancy inherent in the structures of trace spans. 
Specifically, we design a new data structure, \textit{\name} (\sname), based on the principles of prefix trees, which is able to continuously extract the set of key-value pairs commonly shared across spans.
The \sname, when synchronized between services and the backend, serves as a reference mechanism to retrieve the identical data that have been previously transmitted by other spans.
To manage computational and space complexity, \alias constantly restructures \sname into its most compact form and employs mapping techniques to further reduce its size.
We also propose a differential update mechanism to effectively synchronize \sname between services and the backend.
\alias is orthogonal to trace sampling methods and can work with log compression techniques once trace data have been efficiently transmitted to the backend.

We have implemented \alias inside OpenTelemetry Collector~\cite{opentelemetry_collector}, one of the most popular tracing frameworks, making it compatible with existing tracing APIs.
We deploy \alias to collect traces for an open-source microservices benchmark (i.e., Train Ticket~\cite{DBLP:journals/tse/ZhouPXSJLD21}) and six application backend components in cloud environments (i.e., gRPC, Apache Kafka, Servlet, MySQL, Redis, MongoDB).
We also evaluate the compression performance of \alias on Alibaba production traces~\cite{DBLP:conf/cloud/LuoXLYXZDH021,DBLP:conf/icpp/WangLWJCWDXHYZ22}.
The experimental results show that \alias offers around 10\%$\sim$45\% performance gain when working in conjunction with traditional compression schemes, i.e., gzip, bzip2, lzma.
Moreover, \alias demonstrates negligible space overhead (i.e., several megabytes) and high efficiency.

The major contributions of this work are as follows:

\begin{itemize}
    \item We propose \alias, the \textit{first} online trace compression system by leveraging the inherent redundancy in trace span data.
    This information is captured by a new data structure we developed, the \name (\sname).
    By sharing \sname between services and the tracing backend, we can eliminate the redundancy associated with the repetitive transmission of identical data across multiple spans.

    \item We have implemented \alias inside OpenTelemetry Collector with a series of optimization strategies for \sname restructuring and synchronization.
    Experiments on both open-source systems and production trace dataset demonstrate that \alias can effectively compress traces with MB-scale space overhead and superior efficiency.
    The implementation and data of \alias are publicly available\footnote{\url{https://github.com/OpsPAI/TraceZip}}.
\end{itemize}

The remainder of the paper is organized as follows.
Section~\ref{sec:background} introduces the background of distributed tracing and the motivation of this work.
Section~\ref{sec:methodology} and~\ref{sec:implementation} describes the proposed methodology and system implementation.
Section~\ref{sec:exp_eval} presents the experiments and results. 
Section~\ref{sec:related_work} discusses the related work.
Finally, Section~\ref{sec:conclusion} concludes this work.

% \begin{minted}{json}
% {
%   "firstName": "John",
%   "lastName": "Smith",
%   "isAlive": true,
%   "age": 25,
%   "height_cm": 167.6,
%   "address": {
%     "streetAddress": "21 2nd Street",
%     "city": "New York",
%     "state": "NY",
%     "postalCode": "10021-3100"
%   },
%   "phoneNumbers": [
%     {
%       "type": "home",
%       "number": "212 555-1234"
%     },
%     {
%       "type": "office",
%       "number": "646 555-4567"
%     }
%   ]
% }
% \end{minted}

% \begin{lstlisting}[language=json]
% {
%   "name": "John",
%   "age": 30,
%   "hobbies": ["reading", "swimming", "cycling"]
% }
% \end{lstlisting}

