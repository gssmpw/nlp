\section{Experimental Evaluation}
\label{sec:exp_eval}

In this section, we present the evaluation of \alias.
We first introduce the experimental settings, including the deployed cloud services, the metric for evaluation, and the baseline methods.
Next, we demonstrate the experimental results, which include the effectiveness of trace compression and the analysis of both efficiency and overhead.

% \zb{Note in online scenarios, there exists a trade-off between the compression ratio and processing overhead at service instances}

\subsection{Experimental Setup}

\subsubsection{Deployed Cloud Systems}
\label{sec:deployed_cloud_systems}

To evaluate the compression performance in a realistic environment, we deploy popular cloud systems and collect their traces using the OpenTelemetry Collector instrumented with \alias.
We serialize the trace data into JSON format and transmit them utilizing HTTP protocols.
The selected services include one microservices benchmark named Train Ticket~\cite{DBLP:journals/tse/ZhouPXSJLD21} and six open-source application components, including gRPC, Apache Kafka, Servlet, MySQL, Redis, MongoDB.

Train Ticket is a railway ticketing application comprising 41 microservices, each responsible for a specific function, such as user authentication, ticket booking, payment processing, and notification.
This benchmark is implemented in different programming languages such as Java, Go, Node.js, Python, etc.
Train Ticket allows a comprehensive evaluation in a multifunctional scenario, which has been widely used in many trace-related topics, including trace sampling~\cite{DBLP:conf/IEEEcloud/ChenJSLZ24}, root cause localization~\cite{DBLP:journals/tse/ZhouPXSJLD21,DBLP:conf/issre/ZhouZPYLLZZD23}, service architecture measurement~\cite{DBLP:conf/sigsoft/0001ZZIGC22}, etc.
In order to replicate a live production environment, we employ Locust~\cite{locust}, an open-loop asynchronous workload generator, to drive the services.
The workloads are directly borrowed from the original work~\cite{DBLP:journals/tse/ZhouPXSJLD21} that introduces the Train Ticket microservices. 

The selected six application components have widespread adoption and play critical roles in modern cloud service architectures.
They represent a diverse cross-section of the technology stack, which play a foundational role in constructing robust, scalable, and high-performance distributed systems.
% from communication protocols like gRPC and web service frameworks such as Apache HTTP and Servlet, to messaging systems like Kafka, and data storage solutions including MySQL, Redis, and MongoDB.
% They are foundational in constructing robust, scalable, and high-performance distributed systems.
We generate workloads that reflect real-world usage patterns common in cloud-native and microservices environments.
For communication protocols like gRPC and web service frameworks such as Apache HTTP, we simulate typical traffic and user interactions.
In messaging systems like Kafka, workloads involve data streaming and message processing, while for data storage solutions like MySQL, Redis, and MongoDB, we focus on common database operations such as read/write transactions.
This approach ensures our findings are applicable and relevant to a wide range of real-world scenarios.
% By focusing on these components, our study captures a broad spectrum of interactions and operations that are common in today's cloud-native and microservices-oriented environments.
% This ensures that our findings are applicable and relevant to a vast array of real-world scenarios.
% \zb{How we generate the workload?}

% To comprehensively evaluate the application components, we generated workloads that closely mimic real-world usage patterns and stress typical operational scenarios in cloud-native and microservices-oriented environments. These workloads were designed to simulate a variety of interactions and operations across different layers of the technology stack.

% For communication protocols like gRPC, we created scenarios involving high-frequency request/response cycles to test latency and throughput. In the case of web service frameworks such as Apache HTTP and Servlet, we generated workloads that emulate typical web traffic, including concurrent user requests, varied content delivery, and session management.

% For messaging systems like Kafka, we crafted workloads that simulate real-time data streaming and message queuing, focusing on both high-volume data ingestion and complex processing pipelines. In terms of data storage solutions, including MySQL, Redis, and MongoDB, the workloads were designed to reflect common database operations, such as read/write transactions, complex queries, and data caching strategies.

% By employing such targeted and realistic workload generation, our study captures the dynamic and multifaceted nature of operations within these critical application components. This approach ensures that our evaluation reflects practical performance and interaction patterns, providing insights that are both applicable and valuable to developers and practitioners working in diverse cloud service architectures.


\subsubsection{Evaluation Metric}

To measure the effectiveness of \alias, we employ \textit{Compression Ratio} (CR) as the metric, which is widely used in the evaluation of existing compression methods for telemetry data~\cite{DBLP:conf/kbse/LiuZHHZL19,DBLP:conf/icse/LiZL024}.
The definition is given below:

\begin{equation*}
    CR=\frac{\mathrm{Original~File~Size}}{\mathrm{Compressed~File~Size}}
\end{equation*}

In each experiment, we run the same set of workloads, so the size of the original file remains constant.
With different compression approaches and configurations, the resulting compressed file may vary in size.
As the file size decreases, a higher level of compression is attained, indicating more effective compression performance.

\subsubsection{Baseline Methods}

Since we are the first to study the problem of trace compression in a live production scenario, there has not been any baseline methods/systems for comparison.
Note that \alias is orthogonal to existing trace sampling techniques, which compress traces via reducing the volume of data collected.
Thus, they cannot be directly compared to \alias.
In this case, we opt for general-purpose compression algorithms which can be used as out-of-the-box tools to compress traces.
Three prevalent and effective algorithms are selected, that is, gzip, bzip2, and lzma.
However, as they are not tailored for trace data, suggesting potential for further performance improvement.
Our goal is to illustrate the additional compression benefits that \alias can provide when applied in conjunction with these standard algorithms.

\begin{table*}[t]
    \centering
    \caption{Performance of Trace Compression on Open-source Cloud Systems}
    \label{tab:dynamic_compression_result}
    \centering
    \footnotesize
    \begin{NiceTabular}{C{1.89cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}|C{0.45cm} C{0.45cm}}
        % \toprule
        \specialrule{0.35mm}{0em}{0em}
        \multirow{2}{*}{} & \multicolumn{2}{c}{\textbf{Train Ticket}} & \multicolumn{2}{c}{\textbf{gRPC}} & \multicolumn{2}{c}{\textbf{Kafka}} & \multicolumn{2}{c}{\textbf{Servlet}} & \multicolumn{2}{c}{\textbf{MySQL}} & \multicolumn{2}{c}{\textbf{Redis}} & \multicolumn{2}{c}{\textbf{MongoDB}}\\
        % \cmidrule{2-15}
        % \midrule
        % \hdashline
        % \cdashline{2-8}
        \cline{2-15}
        & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR} & \textbf{Size} & \textbf{CR}\\
        % \midrule
        % \midrule
        \specialrule{0.15mm}{0em}{0em}
        \specialrule{0.15mm}{.1em}{0em}
        % \hdashline[2pt/2pt]
        % \hline
        % \hline
        Raw & 21.0 & 1 & 3.08 & 1 & 2.47 & 1 & 9.36 & 1 & 1.88 & 1 & 2.01  & 1 & 1.10 & 1 \\
        \rowcolor{grey} \alias & 5.19 & 4.05 & 0.58 & 5.31 & 0.627 & 3.94 & 1.45 & 6.46 & 0.30 & 6.27 & 0.33 & 6.09 & 0.21 & 5.24 \\
        % \midrule
        % \hline
        \hdashline[2pt/1pt]
        gzip & 1.93 & 10.90 & 0.163 & 18.91 & 0.143 & 17.27 & 0.506 & 18.50 & 0.112 & 16.85 & 0.084 & 23.93 & 0.065 & 16.92 \\
        \rowcolor{lightgrey} \alias (gzip) & \textbf{1.29} & 16.26 & 0.140 & 22.81 & 0.133 & 18.57 & 0.396 & 23.64 & 0.091 & 20.61 & 0.066 & 30.45 & 0.051 & 21.57 \\
        \rowcolor{grey} improvement & 33.0\% & 1.49x & 17.0\% & 1.17x & 7.0\% & 1.08x & 21.7\% & 1.28x & 18.2\% & 1.22x & 21.4\% & 1.27x & 21.5\% & 1.27x \\
        \hdashline[2pt/1pt]
        bzip2 & 2.41 & 8.71 & 0.135 & 21.96 & 0.124 & 19.92 & 0.421 & 22.23 & 0.097 & 19.38 & 0.056 & 35.89 & 0.054 & 20.37 \\
        \rowcolor{lightgrey} \alias (bzip2) & 1.34 & 15.62 & \textbf{0.128} & 24.00 & 0.116 & 21.29 & 0.365 & 25.64 & 0.087 & 21.56 & 0.044 & 45.68 & 0.048 & 22.92 \\
        \rowcolor{grey} improvement & 30.3\% & 1.75x & 8.5\% & 1.10x & 6.5\% & 1.07x & 13.3\% & 1.15x  & 10.3\% & 1.12x & 21.4\% & 1.27x & 11.1\% & 1.13x \\
        \hdashline[2pt/1pt]
        lzma & 1.93 & 10.89 & 0.174 & 17.67 & 0.128 & 19.29 & 0.487 & 19.22 & 0.121 & 15.61 & 0.064 & 31.41 & 0.065 & 16.92 \\
        \rowcolor{lightgrey} \alias (lzma) & 1.55& 13.54  & 0.146 & 21.14 & 0.012 & 20.58 & 0.412 & 22.72 & 0.097 & 19.48 & 0.054 & 37.2 & 0.055 & 20 \\
        \rowcolor{grey} improvement & 35.7\% & 1.24x & 16.4\% & 1.20x & 9.6\% & 1.07x & 20.1\% & 1.18x & 19.9\% & 1.2x & 17.4\% & 1.19x & 22.7\% & 1.18x \\
        % \midrule
        % \bottomrule
        \specialrule{0.35mm}{0em}{0em}
    \end{NiceTabular}
\end{table*}

\subsection{Effectiveness of Trace Compression}
\label{sec:compression_effectiveness}

\subsubsection{Open-source Cloud Systems}

Table~\ref{tab:dynamic_compression_result} presents the compression performance when collecting traces of the microservices benchmark and cloud applications components.
For each system, we calculate the total size of traces collected, the size after compression, and the resultant compression ratios (CRs) when applying different compression algorithms.
We can see that \alias, as a standalone solution, can achieve CRs ranging from 3.94 to 6.46.
This demonstrates that \alias can remove more amount of redundant information than that shown by our preliminary study in Section~\ref{sec:redundancy_study}.
Traditional compression tools, i.e., gzip, bzip2, and lzma, reduce the file size with a combination of different techniques such as dictionary-based compression and Huffman coding.
Among them, bzip2 generally outperforms the others across most systems, with gzip having the least effectiveness.
In the Train Ticket benchmark, the tools demonstrate the least effective compression with a CR of roughly 10, while on the cloud application components, they deliver a better performance, attaining a comparable CR of around 20.

When working in conjunction with the general-purpose compression algorithms, \alias can provide additional performance gain.
In general, the improvement achieved by \alias when combined with bzip2 is less pronounced than when paired with other algorithms.
This can be attributed to its already superior compression capability, which may reduce the incremental benefits that \alias can offer.
In the case of the microservices benchmark, namely Train Ticket, \alias achieves a more significant performance improvement of 30\%$\sim$35\%.
However, the improvement is less substantial in cloud application components, with Apache Kafka demonstrating an enhancement of less than 10\%.
As mentioned in Section~\ref{sec:redundancy_study}, the traces generated by Kafka include the data from its message queues, rendering the attributes more random.

So far we can make an important observation: compared to application backend components, general-purpose compression algorithms are less effective for processing the traces from Train Ticket, where \alias can offer more substantial improvement.
Our careful investigation reveals the following important insight.
% The spans generally encapsulate two types of data: connectivity details along the call chain and business-specific data.
Based on zero-code instrumentation, the spans collected encapsulate many attributes related to network connectivity (as specified by OpenTelemetry semantic conventions), such as the hostname, IP address, and port of the peer server.
For instance, MongoDB captures details of the requests; Kafka producers log information about their consumers.
Such information provides a comprehensive view of the request's journey across the distributed system.
In production systems, the invocations among different services and components constitute a complex graph, with each node potentially connected to dozens or more instances.
Our experimental environment may not be able to accurately replicate the conditions of the production scenarios.
Consequently, the connectivity information tends to be relatively static, especially for application backend components that operate at infrastructure and platform layer.
In this case, both \alias and traditional algorithms can properly compress such information, reducing the performance gain that \alias can offer.

On the other hand, Train Ticket comprises tens of microservices, which can form a invocation graph with moderate complexity.
Additional, as a service-oriented application, the traces from Train Ticket contain more information related to business logic.
% These two factors contribute to the increased diversity observed in the traces generated by Train Ticket.
These two factors render the traces produced in Train Ticket more diverse, and the compressible information is more scattered.
Traditional compression algorithms are limited to exploiting redundant information within a short sliding window (e.g., 32KB in gzip's Deflate algorithm).
On the other hand, \alias utilizes \sname to continuously capture the redundancy patterns across spans in a \textit{global} manner, which can further reduce the redundancy. 

% We've discovered that the structural correlations present in this architecture are not optimally leveraged by algorithms like Gzip, whereas our compression algorithm, \alias, can identify and compress these relational attributes within the invocation graph. In monolithic applications, the downstream connectivity information tends to be more static. Our experimental environment may not accurately replicate the conditions of the production environment, or it may include random data that are incompressible.

% When the downstream link data are completely identical, Gzip can effectively use its dictionary to identify these repetitions and compress them at a minimal cost. However, when the downstream data are entirely random, neither Gzip nor \alias can achieve effective compression. In such cases, our compression algorithm loses its effectiveness regarding the connectivity part of the information, compressing only the business-related span data, which leads to a reduction in the overall compression ratio.

% This observation underscores the tailored nature of \alias for handling the specific characteristics of trace data from complex, interconnected microservices, providing a more significant advantage over traditional compression tools that may not adapt as effectively to the intricate patterns found in modern distributed systems.


%spans 信息包含两部分，一部分信息是有关于链路下一条的连接信息，另一部分信息是与具体业务相关的信息。semantic convention 规定了很多关于链路下一跳的信息，例如下一条的服务器的 hostname、ip 地址、下一条服务器接受请求的 port 端口等。在实际的生产系统和测试的微服务系统中，所有的实例之间构成一个调用关系图，每一个微服务会与数十个或者更多的实例相连。我们发现这种结构性的关联 Gzip 算法难以很好的利用，而我们的压缩算法可以提取出调用关系图中属性值的关联并加以压缩。在单体应用服务中，链路的下一条信息 **往往是固定的** ，或者是 **无法被压缩的随机信息 **。当链路的下一条数据完全相同时，gzip 能够通过字典发现这种重复，并且用很小的代价进行压缩，当下一跳的链路数据信息完全随机时，gzip 和 \alias都不能够对其进行好的压缩。所以我们的压缩算法失去了关于链路下一条这一部分信息的压缩效果，只能够压缩和业务相关的链路数据，导致了压缩率的减损%

\subsubsection{Production Trace Data}

We also evaluate \alias using production trace data collected from Alibaba. Compared to existing microservices benchmarks, this dataset represents the call graphs of a large-scale deployment of over 20,000 microservices in production clusters. The participating microservices can be categorized into two types: stateless services and stateful services. Stateless services operate independently of any stored state data, whereas stateful services, including databases and systems like Memcached, are required to maintain state information.
There are three types of communication paradigms between pairs of microservices: inter-process communication, remote invocation, and indirect communication. In addition to this diversity, the trace data also exhibit statistical characteristics typical of industry scale. For example, the size of microservice call graphs follows a heavy-tail distribution; there is a non-negligible fraction of hot-spot microservices; and the microservices can form highly dynamic call dependencies at runtime.
This real-world application allows us to examine \alias's efficacy in handling large-scale, complex data, which is crucial for understanding its potential in practical, production-level scenarios.

Figure~\ref{fig:alibaba_compression} illustrates the evaluation results.
The raw size of the trace data used in our experiments is 26.15GB.
The CRs attained by gzip, bzip2, and lzma are 6.55, 7.30, and 8.52, respectively, reducing the data size to 3.99GB, 3.58GB, and 3.07GB.
These CRs are marginally lower than those recorded in the Train Ticket benchmark.
This observation aligns with our finding in Section~\ref{sec:compression_effectiveness}.
That is, relying predominantly on local information, traditional compression algorithms might find it challenging to efficiently compress data characterized by significant diversity and complexity.
This is where the strength of \alias becomes evident.
\alias, with its ability to identify global compression opportunities, enhances the compression performance by 35.1\%, 43.6\%, and 37.8\%, respectively.
For example, the combination of \alias and lzma achieves the optimal CR of 13.69, and compresses the data to a minimal size of 1.91GB.
This result underscores the benefits introduced by \alias, especially when dealing with large-scale and intricate trace data.

% The Static Spans Compressor, which is implemented by Go, is used to compress files in CSV format. The main purpose of implementing this system is to apply the Merging Tree compression algorithm to the Alibaba Cluster Trace 2022 dataset.

% \begin{table}[h!]
% \centering
% \begin{tabular}{|m{2cm}|m{1cm}|m{2cm}|m{2cm}|}
% \hline
% \textbf{Parameter} & \textbf{Type} & \textbf{Default Value} & \textbf{Description} \\ \hline
% \texttt{-path} & \texttt{string} & \texttt{""} & The path to the file to be compressed. \\ \hline
% \texttt{-chunk} & \texttt{int} & \texttt{0} & The size of chunks for compression. \\ \hline
% \texttt{-dirname} & \texttt{string} & \texttt{"output"} & The name of the output directory. \\ \hline
% \texttt{-j} & \texttt{int} & \texttt{1} & The maximum number of CPU cores to use. \\ \hline
% %\texttt{-huffman} & \texttt{bool} & \texttt{false} & Enable Huffman encoding for compression. \\ \hline
% \texttt{-merging} & \texttt{bool} & \texttt{false} & Enable Merging Algorithm. \\ \hline
% \end{tabular}
% \end{table}

% Here, we present the command-line parameters table for the Static Span Compressor. When using the Static Span Compressor, we do not use the Merging Algorithm by default, but only the dictionary compression algorithm, in order to facilitate the comparison of compression effects. Another important parameter is the chunk size. The Static Span Compressor can split the spans records and compress them in units of chunks. As the chunk size increases, the memory space occupied by the Merging Algorithm also increases, but the compression efficiency of the Merging Algorithm correspondingly improves. We will discuss this in detail in the Experiment Evaluation section.Additionally, we can specify the number of CPU cores to be used for the compression operation. Since the Static Spans Compressor compresses spans files, it does not implement anomaly detection algorithms.

\subsection{Performance Overhead}

We examine the overhead of \alias from the perspectives of space complexity and computational efficiency.

\subsubsection{Space Complexity}

At the service side, \alias maintains two types of data structures to capture the redundancy among trace spans and perform compression, namely, a \sname along with its hashed paths and a map for dictionary-based compression.
To prevent impeding the normal execution of the service, it is imperative that they are constrained in size without excessive memory consumption.
To study the space complexity of \alias, we select a microservice in Alibaba trace data with diverse spans and calculate the cumulative size of the three data structures after the compression procedure.
A critical parameter influencing this size is the threshold $\psi$, which dictates the maximum number of distinct values for universal attributes.
An attribute having an exceeding number of values will be moved to the leaf node, becoming a local attribute.
A larger $\psi$ enables \alias to compress a broader spectrum of span fields, enhancing performance but at the cost of a more substantial SRT and mapping structure.
Conversely, a small $\psi$ compromises the effectiveness but with lower space overhead in return.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/experiments/alibaba_compression.pdf}
    \caption{Compression on Alibaba Production Traces}
    \label{fig:alibaba_compression}
\end{figure}

Figure~\ref{fig:space_overhead} illustrates the results, where we can see both the data structure size and compression improvement grow with a larger $\psi$.
In the case of $\psi$=1,000, \sname and map together take up only 2.56MB of memory, but the performance gain that \alias achieves is significant, i.e., 33.8\%.
This result underscores \alias's capacity to achieve substantial compression efficiency while maintaining a balanced memory footprint.
However, we notice that the quantities of distinct values that span attributes can have tend to polarize.
This can also be observed in Figure~\ref{fig:space_overhead}.
The performance plateaus even when $\psi$=10,000, meaning there is no attributes whose value size falls in the range of [1,000, 10,000].
Certain attributes (e.g., authentication tokens, DB queries, span ID) might possess a substantially larger set of values compared to others.
Consequently, their inclusion (when $\psi$ is too large) in the \sname could potentially bloat its size.
To address the variability in attribute value distribution and maintain manageable memory usage, we also set a cap on the size of the data structures, e.g., limiting it to 5MB.

\subsubsection{Computational Efficiency}

To ensure \alias can be seamlessly integrated with services, all operations are designed for optimal efficiency.
The time complexity of \alias's core operations is analyzed as follows.
The construction and restructuring of \sname operate with a time complexity of $\mathcal{O}(m)$, where $m$ is the number of span attributes.
In many scenarios, $m$ typically remains below 20.
Other operations, such as hashing, dictionary mapping, and path searching, all have a complexity of $\mathcal{O}(1)$.
Thus, the overall time complexity of \alias is \textit{linear}, making it highly efficient.

\begin{figure}
    \centering
    \includegraphics[width=0.66\linewidth]{figures/experiments/space_overhead.pdf}
    \caption{Performance with Different $\psi$}
    \label{fig:space_overhead}
\end{figure}

To evaluate the efficiency of \alias, we measure the trace collection throughput for the \textit{basic} microservice~\cite{trainticket} of the Train Ticket benchmark.
Specifically, we deployed the instrumented OpenTelemetry system within a container (configured with one core and 1GB of memory) to compress and relay the spans.
The throughput is calculated as the uncompressed size of spans divided by the time token to transmit the traces from the service to the backend.
% This includes the time used for data compression (if \alias or gzip is applied) and JSON serialization.
% Specifically, we evaluate the time taken by different configurations to transmit the traces from the service to the backend, and then divide this duration by the overall size of the dataset.
In the most basic setting, referred to as \textit{Original}, the time is purely the period needed for data transmission and JSON serialization.
When compression techniques such as \alias and gzip are employed, we take into account the additional time required for data compression and decompression.
The results are present in Table~\ref{tab:throughput}.

\begin{table*}[h]
    \centering
    \caption{Performance of Throughput (MB/s) on Train Ticket}
    \label{tab:throughput}
    \centering
    \footnotesize
    \begin{NiceTabular}{C{2.5cm}|C{1cm}|C{1cm}|C{1cm}|C{1cm}}
        \specialrule{0.35mm}{0em}{0em}
        $\psi$ & \textbf{1} & \textbf{10} & \textbf{100} & \textbf{1,000} \\
        \specialrule{0.15mm}{0em}{0em}
        \specialrule{0.15mm}{.1em}{0em}
        Original & 13.98 & 13.57 & 13.78 & 14.05 \\
        \rowcolor{lightgrey} +\alias & 89.34 & 94.35 & \textbf{109.68} & 108.15 \\
        +gzip & 14.65 & 14.27 & 14.35 & 14.02 \\
        \rowcolor{lightgrey}+\alias (gzip) & 60.65 & 63.78 & 68.78 & 68.56 \\
        \specialrule{0.35mm}{0em}{0em}
    \end{NiceTabular}
\end{table*}

It can be seen that upon the integration of \alias, the throughput of trace collection is accelerated by nearly eight times (e.g., from 13.78MB/s to 109.68MB/s).
% This can be attributed to the fact that \alias requires a small amount of time for compression and decompression.
Another interesting observation is that gzip brings little performance gain to the throughput.
One important reason is that gzip compression is performed by the HTTP client library before the data is sent over the network.
Thus, gzip is applied after the data has been serialized into JSON.
As a time-consuming step, JSON serialization constitutes the performance bottleneck.
Moreover, gzip indiscriminately attempts to compress all information, including elements such as trace IDs, span IDs, and authentication tokens, which are inherently resistant to compression.
The (wasted) computational overhead of gzip compression and decompression thus offsets its benefits.
In contrast, \alias can accurately identify the incompressible attributes, i.e., the local fields, and bypass them.
Since \alias is applied before JSON serialization, it substantially reduces the volume of data that needs to be encoded.
% This greatly reduces the amount of data needed to be encoded as \alias is applied before the JSON serialization.
Such a design not only improves the throughput, but also benefits the CPU usage.
Our experiments indicate that the CPU utilization of Tracezip is merely 20\%$\sim$40\% of that in the Original and +gzip settings.


% In contrast, \alias is applied before the JSON serialization, which greatly decreases the data needed to be encoded.
% This also reduces the CPU usage of \alias by more than 60\% when compared to the Original and +gzip settings.

% Such a design choice significantly contributes to \alias's superior efficiency.
% In our lab environment, the processing speed of \alias can reach 100MB/s, while the fastest traditional algorithm, i.e., gzip, is only around 10MB/s.

% \zb{show a figure of CPU percentage and throughput}


\subsection{Threats to Validity}

% We discuss potential threats to the validity of our study.
When evaluating the performance and applicability of \alias, several potential threats to validity must be considered to ensure the robustness and generalizability of our findings.

\textbf{Internal validity}. One of the primary concerns regarding internal validity is the accuracy of our evaluation metrics and the potential biases in our experimental setup.
Real-world cloud services exhibit a vast array of complexities and variations, making it challenging to capture all possible scenarios within a single study.
To address this challenge, we carefully select a diverse set of microservices benchmarks and production trace data from Alibaba that we believe are representative of typical cloud service operations.
These benchmarks and dataset are chosen to reflect common patterns and behaviors observed in real-world applications, thus providing a meaningful context for evaluating \alias's performance.
Additionally, any configuration or tuning of \alias that is specific to these datasets might inadvertently favor our approach, potentially skewing the results.
To mitigate this, we ensure that the benchmarks and dataset are selected and configured independently of \alias's development process.

\textbf{External validity}. External validity pertains to the generalizability of our results to other settings or systems.
Our evaluation of \alias is specifically designed to address the diversity inherent in real-world cloud systems.
We implement and test \alias within the OpenTelemetry Collector framework and evaluate it across a range of cloud environments and backend components, including gRPC, Apache Kafka, MySQL, and others. 
These settings are carefully selected to reflect the variety of systems and technologies commonly used in cloud services, ensuring a comprehensive basis for assessing \alias's effectiveness.
By choosing such a diverse array of environments and applications, we aim to capture the broad spectrum of redundancy patterns and data characteristics found in typical cloud systems.
This approach helps to ensure that our findings are applicable to a wide range of real-world scenarios, demonstrating \alias's capability to perform effectively in diverse and dynamic cloud environments.