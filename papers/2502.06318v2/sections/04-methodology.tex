\section{Methodology}
\label{sec:methodology}

\subsection{Overview}

In this section, we present the design of \alias.
The system architecture is illustrated in Figure~\ref{fig:tracezip_system}, in which we add a \textit{compression module} (\ding{198}) to the service side and a corresponding \textit{decompression module} (\ding{199}) to the entry of the backend trace collectors.
In the compression module, we maintain two data structures, namely, a \name (\sname) and a dictionary, to constantly capture the redundancy across the spans.
Upon the generation of a span at the tracepoint, it undergoes compression utilizing the above data structures.
If the span carries a new redundancy pattern, it will be seamlessly integrated into the \sname and dictionary.
This integration is crucial as it enriches the structures, thereby facilitating the compression for subsequent spans.
We accelerate the above process by employing a combination of mapping and hashing techniques.
At the decompression module, the spans are restored to their original form by referring to the SRT and the dictionary.
To ensure a consistent and reliable data transmission,  it is imperative that these data structures are accurately synchronized between the service and backend sides.
To achieve this, we develop a differential update mechanism (\ding{200}).
This mechanism is designed to precisely pinpoint and propagate only the incremental changes in the data structures, ensuring an efficient synchronization process that minimizes overhead while maximizing data consistency.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.62\linewidth]{figures/tracezip_system.pdf}
    \caption{System Architecture of \alias}
    \label{fig:tracezip_system}
\end{figure}


% \usetikzlibrary{trees}

% In microservice tracing technology, a microservice sends current trace data to the tracing backend. The trace data, known as Spans, are defined as individual units of work within a trace. As we mentioned above, in high-concurrency scenarios, it is likely that many key-value pairs in the spans array sent by a microservice to the tracing backend are repetitive. To better capture the redundancy in the Spans data sent by microservices, we have designed an algorithm named the Merging Algorithm. The Merging Algorithm transforms the Spans array data sent by microservices into a data structure similar to a Prefix Tree, which we will refer to as the Merging Tree in subsequent text. In the Merging Tree, all non-leaf nodes, except the root, are key-value pairs, while the leaf nodes are arrays of key-value pairs. By merging all the key-value pairs along the path from the root to any leaf node, one can reconstruct a span data entry. Figure \ref{fig:Spans_Array_Example} and Figure \ref{fig:Merging_Tree_Example} show an example of spans array and its corresponding Merging Tree. Additionally, we can capture uncommon Spans attributes and report anomalies to the tracing backend using the Spans attribute frequency information generated by the Merging Algorithm. Moreover, by using Dictionary Compression Algorithm, we can assign shorter codes to frequently occurring attribute values based on the frequency information produced by the Merging Algorithm.
% At the same time, when we use the Merging Algorithm and Dictionary Compression Algorithm to compress data, attribute value frequency data is generated. We can utilize this attribute value frequency data to identify potential anomalous link data. 
% The compression algorithm, while compressing the Spans data, will also mark potential anomalous link data and report it back to the Spans collection service backend.


% \begin{table}[]
%     \centering
%     \normalsize
%     \caption{Caption}
%     \begin{tabular}{c|c|c|c}
%     \toprule
%         name&db server&url&start\_time\\
%         \midrule
%         \midrule
%         interface\_1&GET&/interface1&... \\
%         interface\_1&GET&/interface1&... \\
%         interface\_2&PATCH&/interface2&... \\
%         interface\_2&PATCH&/interface2&... \\
%     \bottomrule
%     \end{tabular}
%     \label{tab:my_label}
% \end{table}

% \begin{table}[]
% \captionsetup{justification=centering}
% \centering
% \caption{Ablation study of components in}
% \label{tab: RQ2-ablation}
%  % \resizebox{0.48\textwidth}{!}{%\
% \begin{NiceTabular}{c|c|c|c|c}
% \toprule
% \rowcolor{grey}\textbf{name} & \textbf{operation} & \textbf{db server} & \textbf{results.count} & \textbf{other attrib.}\\
% \midrule
% \midrule
% Access DB & SELECT & MySQL & 10 & ...\\
% Access DB & INSERT & MySQL & 2 & ...\\
% Access DB & UPDATE & MongoDB & 5 & ...\\
% Access DB & DELETE & MongoDB & 1 & ...\\
% \bottomrule
% \end{NiceTabular}
% % }
% \end{table}

% \begin{figure}[H]
%     \centering
%     \begin{tabular}{c c c c}
%         \toprule
%         \multicolumn4c{Spans Array}\\
%         \cmidrule(lr){1-4}
%         Span Name&HTTP Method&URL&Details\\
%         \midrule
%         interface\_1&GET&/interface1&... \\
%         interface\_1&GET&/interface1&... \\
%         interface\_2&PATCH&/interface2&... \\
%         interface\_2&PATCH&/interface2&... \\
%         \bottomrule
%     \end{tabular}
%     \caption{An Example of Spans Array}
%     \label{fig:Spans_Array_Example}
% \end{figure}


% \tikzstyle{every node}=[draw=black,thick,anchor=west]
% \tikzstyle{selected}=[draw=red,fill=red!30]
% \tikzstyle{optional}=[dashed,fill=gray!50]
% \begin{figure*}
% \centering
% \begin{tikzpicture}[%
%   level distance=1.5cm,
%   sibling distance=2.5cm,
%   grow via three points={one child at (0.5,-0.7) and
%   two children at (0.5,-0.7) and (0.5,-1.4)},
%   edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
%   \node {Merging Trees: global\_time\_base}
%     child { node {span\_name: interface\_1}
%         child {
%             node {http.method: GET}
%             child {
%                 node {url: /interface1}
%                 child [missing] {}
%                 child {
%                     node {\makecell{
%                             start\_time: start\_time\_offset \\
%                             end\_time: end\_time\_offset \\
%                             parent\_id: ... \\
%                             context: \{ ... \}
%                         }
%                     }
%                 }
%                 child [missing] {}
%                 child [missing] {}
%                 child {
%                     node {\makecell{
%                             start\_time: start\_time\_offset \\
%                             end\_time: end\_time\_offset \\
%                             parent\_id: ... \\
%                             context: \{ ... \}
%                         }
%                     }
%                 }
%                 child [missing] {}
%                 child [missing] {}
%             }
%         }
%         child [missing] {}
%     }		
%     child [missing] {}				
%     child [missing] {}				
%     child [missing] {}
%     child [missing] {}
%     child [missing] {}
%     child [missing] {}				
%     child [missing] {}	
%     child [missing] {}
%     child { node {span\_name: interface\_2}
%         child { node {http.method: PATCH}
%             child {
%                 node {url: /interface2}
%                 child [missing] {}
%                 child {
%                     node {\makecell{
%                             start\_time: start\_time\_offset \\
%                             end\_time: end\_time\_offset \\
%                             parent\_id: ... \\
%                             context: \{ ... \}
%                         }
%                     }
%                 }
%                 child [missing] {}
%                 child [missing] {}
%                 child {
%                     node {\makecell{
%                             start\_time: start\_time\_offset \\
%                             end\_time: end\_time\_offset \\
%                             parent\_id: ... \\
%                             context: \{ ... \}
%                         }
%                     }
%                 }
%                 child [missing] {}
%                 child [missing] {}
%             }
%         }
%     };
% \end{tikzpicture}
% \caption{Merging Tree Structure of Spans Array} \label{fig:Merging_Tree_Example}
% \end{figure*}


% The Merging Algorithm performs two operations on the microservice side: preprocessing and compressing the Spans Array, resulting in the creation of the Merging Tree. On the trace backend, a decompression algorithm is executed. During the preprocessing phase, the Merging Algorithm identifies which attribute in the Spans Array should be allocated to the non-leaf nodes of the Merging Tree by analyzing the repetition of these attribute values. This is done in linear time complexity. It also determines an order of attributes to minimize the number of non-leaf nodes in the Merging Tree. In the compression phase, the Merging Algorithm inserts each span into the Merging Tree according to the attribute order established during preprocessing. During the decompression phase, the Merging Algorithm reconstructs the Spans Array from the Merging Tree. The Merging Tree can be combined with other general compression algorithms, such as LZ77 and Huffman coding, to achieve higher compression ratios. Notably, the Merging Algorithm has superior time complexity compared to most existing general-purpose data compression algorithms, a topic that will be discussed in a subsequent subsection.

\subsection{Span Format Conventions}

To compress spans by leveraging their recurring patterns, we first stipulate the format of a span.
For simplicity and readibility, we assume that a span adheres to the standard JSON data format that defines it as a structured set of key-value pairs.
The key is a string, while the value can be either primitive types (strings, numbers, booleans, and null) or two structured types (nested key-value pairs and arrays).
This aligns with the format specifications used in many tracing frameworks and tools, e.g., OpenTelemetry~\cite{opentelemetry_traces}, Jaeger~\cite{jaeger}, Zipkin~\cite{zipkin}.
Typical fields (keys) of a span include: \textit{Name} (a human-readable string representing the operation done), \textit{Parent Span ID} (the span that caused the creation of this span, empty for root spans), \textit{Start and End Timestamps} (the start and end time of the span), \textit{Span Context} (the context of the span including the trace ID, the span ID, etc.), \textit{Attributes} (key-value pairs representing additional information about the span), \textit{Span Events} (structured log messages/annotations on a span), etc.
It is important to note that our proposed algorithm is not restricted to JSON or any particular serialization format.
For example, \alias can work effectively when Protobuf (Protocol Buffers)~\cite{protobuf} is used for trace data serialization.
With Protobuf's powerful deserialization capabilities, we can leverage its reflection-like APIs or direct-access methods to dynamically access the fields and values of spans.
Additionally, Protobuf is designed to be backward and forward compatible, allowing us to modify the message definition by adding or removing fields while maintaining compatibility with older data.
Such operations are essential for reducing trace redundancy, e.g., removing span elements that are deemed repetitive.

We also assume that spans possess \textit{structural locality}, meaning that during the continuous execution of a service or component, all spans sharing a common span Name will exhibit an identical structure.
In other words, spans with the same Name will consistently retain the same set of keys (e.g., attributes, tags, and metadata), differing only in the specific values associated with them.
This assumption arises naturally from the way distributed tracing systems operate, where spans typically represent predefined operations or events within the service workflow.
These operations are implemented as part of the service's codebase, which enforces a fixed schema or structure for spans generated by specific instrumentation points.
% For example, a span representing a database query will always include fields such as \texttt{db.statement}, \texttt{db.type}, or \texttt{db.instance}, while their values—such as the specific SQL query or database name—may vary.
This structural consistency allows for reliable trace analysis, optimization, and redundancy reduction, as the predictability of span structures minimizes the need for per-span schema discovery during processing.

% We also assume that spans possess \textit{structural locality}.
% That is, throughout the continuous execution of a service/component, all generated spans sharing a common span Name will have an identical structure.
% This implies they will retain the exact same keys, differing only in the values.
% Nevertheless, if it is violated\zb{what cases}, we xxx
% Such a property allow us to chain the values \zb{not finished}

% \newtheorem{definition}{Definition}

% A Spans Array is defined as follows:
% \begin{definition}\label{def_spans_array}
% A Spans Array is a set of key-value pair sets. Any key-value pair set in the Spans Array is referred to as a Span. Each Span has a key named "Span Name," and for all Spans with the same "Span Name," the set of keys for the remaining key-value pairs is identical. In other words, all Spans with the same Span Name have the same structure, meaning they have exactly the same keys, differing only in the values of those keys.
% \end{definition}


\subsection{Span Retrieval Compression and Uncompression}
\label{sec:compression_uncompression}

% A straightforward approach to compress spans by exploiting their repetitiveness involves the use of a dictionary.
A straightforward approach to compressing spans involves the use of a dictionary.
This method creates a dictionary where every unique key and value is assigned a unique identifier.
During the compression process, the keys and values of each span are substituted by the corresponding identifiers.
The size of the span can then be reduced as the identifiers are much smaller than the original data.
However, as revealed by our empirical study, there can still be redundant information among the identifiers.
The pure dictionary approach compresses data on a one-to-one basis, i.e., one identifier corresponds to one KV pair.
If multiple spans share a collection of common key-value pairs, it is possible to utilize a single identifier to represent this entire set of shared pairs, thereby amplifying the compression efficiency.
Thus, we propose to leverage the correlations among the values of spans to further eliminate repetitive information.

% \begin{algorithm}[t]
% \caption{Performance Anomaly Detection}
% \label{algo:anomaly_detection}
% \normalsize
% \SetAlgoLined
% \KwIn{$t$, $\mathcal{P}_a$, and $\mu_C$}
% \KwOut{Anomaly detection result for $t$}

% $\mathcal{D}_t\gets {\rm PairWiseDistance}(t, \mu_C)$

% $idx\gets {\rm MinIndex}(\mathcal{D}_t)$

% \eIf{$idx\in \mathcal{P}_a$}{
%     return True
% }{
%     return False
% }
% \end{algorithm}

% If there are more KV pairs shared across multiple spans, it is possible to represent this set of KV pairs with one identifier.
% \zb{Examples of events may include uncaught exceptions, button clicks, user logouts, network disconnections, etc. Its structure is also similar to that of Spans.}

\begin{algorithm}
    \caption{Span Retrieval Tree (SRT) Reconstruction and Span Compression}
    \label{algo:srt}
    \begin{algorithmic}[1]
    \State \textbf{Input:} a stream of continuously generated \textit{spans}, a threshold $\psi$
    \State \textbf{Output:} a constructed SRT $\mathcal{T}$, \textit{compressed spans}
    \State Initialize an empty SRT $\mathcal{T}$
    \For{each \textit{span} in \textit{spans}}
        \If{\textit{span Name} not in $\mathcal{T}$}
            \State Chain all key-value pairs of \textit{span} and add the path to the root of $\mathcal{T}$
            % \State Each key of $\mathcal{T}$ has a unique value number of 1
            \State Assign an identifier to this new path
        \Else
        \For{each \textit{key} at every depth of $\mathcal{T}$} \Comment{traverse $\mathcal{T}$ from the root to the leaf}
            \State Get the corresponding \{\textit{key}: \textit{value}\} from \textit{span}
            \If{\{\textit{key}: \textit{value}\} \textbf{does not exist} at the current depth of $\mathcal{T}$}
                \State Chain the remaining key-value pairs of \textit{span} and extend a new branch from the direct parent node of \textit{key}
                % \State Increase the unique value number of the corresponding keys by 1
                \State Calculate the number of unique nodes at each depth of $\mathcal{T}$
                \State Move the keys to the leaf whose unique value number exceeds $\psi$, i.e., \textit{local fields}
                \State Reorder the keys of $\mathcal{T}$ based on the ascending number of their unique values
                \State Reassign path identifiers
                \State \textbf{break}
            \EndIf
        \EndFor
        \EndIf

    \State Compress \textit{span} based on the corresponding path identifier and the values of local fields
    \EndFor
    \end{algorithmic}
\end{algorithm}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.74\linewidth]{figures/span_retrieval_tree.pdf}
    \caption{An Example of \name}
    \label{fig:span_retrieval_tree}
\end{figure}

Our idea is that for spans generated in each service instance, we organize their key-value pairs as a prefix-tree-like data structure, i.e., \sname.
The \sname functions as a multi-way tree, with all non-leaf nodes (except for the root) associated with a key-value pair.
For each type of span (which is identified by a unique span Name), there is only one leaf node connected to all the last non-leaf nodes stemming from it.
This leaf node holds a collection of keys without values.
Figure~\ref{fig:span_retrieval_tree} illustrates an example of SRT, where the gray node and the yellow nodes represent the root and the leaves, respectively, while the remaining are the non-leaf nodes.
Each span can be ``spelled out'' by tracing a path from the root down to the leaf.
The path of \sname represents the set of KV pairs shared across multiple spans.
% The tracing process is done by searching the node that corresponds to the next key-value pair in the span.
The non-leaf nodes contain the fields that are more repetitive, which we refer to as \textit{universal fields}.
Although spans may exhibit commonality, they will still have some unique KV pairs, such as those related to ID and timestamps.
We refer to such pairs as \textit{local fields} and only store their keys at the leaf.
The rationale is that such unique fields are incompressible, i.e., not shared with other spans, so we discard their values.
\textit{Based on \sname, a span can be represented as a unique path identifier plus its exclusive values that are extracted according to the keys in the leaf node.}
Each path identifier collectively represents the KV pairs shared among spans, instead of one identifier for each key and value.
Since these common KV pairs constitute a significant portion, the trace size can be substantially reduced, enhancing the overall efficiency.

% Specifically, the \name is a multi-way tree where the root node is associated with a key-value pair having the key "Span Name."
% Except for the root node, all non-leaf nodes are associated with a key-value pair, and all leaf nodes are associated with a key-value pair set. We define the root node's depth as 1, and the keys of all nodes at depth 2 as "Span Name."
% The Merging Tree satisfies the following property: For a Merging Tree, except for the leaf nodes, all nodes at the same depth have key-value pairs with the same keys. We will refer to this property as the Keep-Order property.

\begin{table}
    \centering
    \caption{Span Examples of a Data-processing Service}
    \label{tab:span_examples}
    \begin{subtable}{1\textwidth}
    \small
        \centering
        \begin{NiceTabular}{c|c|c|c|c|c}
            % \toprule
            \specialrule{0.35mm}{0em}{0em}
            \rowcolor{grey}\textbf{name} & \textbf{operation} & \textbf{address} & \textbf{data\_size} & \textbf{span\_id} & \textbf{others}\\
            % \midrule
            % \midrule
            \specialrule{0.15mm}{0em}{0em}
            \specialrule{0.15mm}{.1em}{0em}
            Access Mem & WRITE & address1 & 64 bytes & id1 & ...\\
            Access Mem & READ & address2 & 128 bytes & id2 & ...\\
            Access Mem & READ & address2 & 64 bytes & id3 & ...\\
            Access Mem & WRITE & address1 & 64 bytes & id4 & ...\\
            Access Mem & READ & address2 & 256 bytes & id5 & ...\\
            % \bottomrule
            \specialrule{0.35mm}{0em}{0em}
        \end{NiceTabular}
        % \vspace{6pt}
        \caption{Span examples of ``Access Mem''}
    \end{subtable}
    \vfill
    \begin{subtable}{1\textwidth}
    \small
        \centering
        \begin{NiceTabular}{c|c|c|c|c|c}
            % \toprule
            \specialrule{0.35mm}{0em}{0em}
            \rowcolor{grey}\textbf{name} & \textbf{type} & \textbf{DB system} & \textbf{status} & \textbf{row.num} & \textbf{others}\\
            % \midrule
            % \midrule
            \specialrule{0.15mm}{0em}{0em}
            \specialrule{0.15mm}{.1em}{0em}
            Access DB & INSERT & MySQL & SUCCESS & 1 & ...\\
            Access DB & SELECT & MySQL & SUCCESS & 1 & ...\\
            Access DB & DELETE & MySQL & SUCCESS & 1 & ...\\
            % \bottomrule
            \specialrule{0.35mm}{0em}{0em}
        \end{NiceTabular}
        % \vspace{6pt}
        \caption{Span examples of ``Access DB''}
    \end{subtable}
\end{table}


% \begin{table}[h]
%     \centering
%     \caption{Span Examples of a Data-processing Service}
%     \label{tab:span_examples}
%     \centering
%     \begin{NiceTabular}{c|c|c|c|c|c}
%         % \toprule
%         \specialrule{0.35mm}{0em}{0em}
%         \rowcolor{grey}\textbf{name} & \textbf{operation} & \textbf{address} & \textbf{data.size} & \textbf{span.id} & \textbf{...}\\
%         % \midrule
%         % \midrule
%         \specialrule{0.15mm}{0em}{0em}
%         \specialrule{0.15mm}{.1em}{0em}
%         Access Mem & WRITE & address1 & 64 bytes & id1 & ...\\
%         Access Mem & READ & address2 & 128 bytes & id2 & ...\\
%         Access Mem & READ & address2 & 64 bytes & id3 & ...\\
%         Access Mem & WRITE & address1 & 64 bytes & id4 & ...\\
%         Access Mem & READ & address2 & 256 bytes & id5 & ...\\
%         % \bottomrule
%         \specialrule{0.35mm}{0em}{0em}
%     \end{NiceTabular}
%     \vspace{6pt}
%     \caption{Span examples of ``Access Mem''}
% \end{table}

% \begin{table}[h]
%     \centering
%     \caption{Span examples of ``Access DB''}
%     \begin{NiceTabular}{c|c|c|c|c}
%         % \toprule
%         \specialrule{0.35mm}{0em}{0em}
%         \rowcolor{grey}\textbf{name} & \textbf{type} & \textbf{DB system} & \textbf{status} & \textbf{row.num}\\
%         % \midrule
%         % \midrule
%         \specialrule{0.15mm}{0em}{0em}
%         \specialrule{0.15mm}{.1em}{0em}
%         Access DB & INSERT & MySQL & SUCCESS & 1\\
%         Access DB & SELECT & MySQL & SUCCESS & 1\\
%         Access DB & DELETE & MySQL & SUCCESS & 1\\
%         % \bottomrule
%         \specialrule{0.35mm}{0em}{0em}
%     \end{NiceTabular}
%     \vspace{6pt}
% \end{table}

We present our algorithm for \sname construction and span compression (i.e., Algorithm~\ref{algo:srt}) and explain it using span examples in Table~\ref{tab:span_examples}.
Suppose these spans are continuously generated by different tracepoints of a data-accessing service, including memory and database.
Each tracepoint produces a specific type of span with varying attributes.
The algorithm takes the stream of spans as input, and the resulting \sname is shown in Figure~\ref{fig:span_retrieval_tree}.
For each new type of span with a previously unseen span Name, we simply chain all fields of the span (line 6) and add the resulting path to the \sname root.
For example, the first row of Table~\ref{tab:span_examples}-(a) will be structured as \textit{Access Mem}$\hookrightarrow$ \textit{WRITE}$\hookrightarrow$\textit{address1}$\hookrightarrow$\textit{64~bytes}$\hookrightarrow$\textit{id1} (we omit the keys of the nodes and the other attributes), shown as the pink dashed rectangles.
For spans with a known Name, we traverse the \sname from the root to the leaf, and use the key at each depth to retrieve the corresponding key-value pair from the span (line 10).
If a retrieved pair does not exist in the SRT, the remaining key-value pairs are chained to construct a sub-path, which is then added as a new branch to the direct parent node (line 12).
% For the next spans with new values, they will be added to the corresponding branches of the \sname.
For example, the second row adds a new path, \textit{READ}$\hookrightarrow$\textit{address2}$\hookrightarrow$\textit{128~bytes}$\hookrightarrow$\textit{id2}, to node \textit{Access~Mem}.
Each path of \sname will be assigned a unique identifier, as described in Section~\ref{sec:hashing_acceleration}.
% In particular, as spans follow the JSON format, they can have nested JSON object.
% We represent this relationship by prefixing the keys of the child JSON with the parent's key, which facilitates the restoration of the nested structure at the backend.
% To reduce the complexity, the default nesting depth is set as two.
% Deeper nested JSON object (not recommended by OTel) will be converted to string.
% \red{We flatten the span as a list of key-value pairs by extracting all elements in it. use a separation symbol to record the span structure (but the other still cannot be kept?). Also there will be an event \sname. Otel recommends primitives kv pairs?}
% As spans with the same name share an identical structure, their original structure can be easily retrieved\zb{how?}.

% \zb{talk about the root node and time base}\zb{existing log compression can be used to further process values}

In \sname, once a new path emerges, we calculate the number of distinct nodes at the same depth (line 13), which represents the number of different values of a key, e.g., the key \textit{span.id} has five distinct values \textit{id1}$\backsim$\textit{id5}.
We set a threshold $\psi$ for the size of values a key can have.
A key with too many values will be regarded as a local field and moved to the leaf (line 14).
For example, \textit{span.id} will be in the leaf if $\psi=3$.
With the constructed SRT, the fourth row can be compactly represented as the identifier of the first path, i.e., the pink path, coupled with its unique value, i.e., \textit{id4} (line 21).
% Note the leaf will not store the values of local fields.
% This is to avoid the \sname growing to large and consumes excessive memory.
Time-related fields such as span start/end time is also a typical local field.
Since spans generated in a short time period will have close temporal fields, we set a \textit{time\_base} at the root node, which allows the leaves to store only the offset relative to the time base.
This is a common way to compress temporal data.
% \zb{more detail (64-bit unsigned integer), how the time base is updated}
Another special local field is the nested JSON object, such as \textit{\{``attributes'': \{``ip'': ``172.17.0.1'', ``port'': 26040\}\}}.
We represent the nested structure by prefixing the keys of the child JSON object with the parent's key (e.g., \textit{``attributes-ip'': ``172.17.0.1''} and \textit{``attributes-port'': 26040}), which allows the backend to easily restore the original hierarchy.
Technically, spans can extend to any depth as required by the tracing needs.
For the consideration of \sname's size, we set a depth limit, which defaults to two, and convert the values of the overly deep keys into pure string type.
Similar to other string fields, they will be moved to the leaves if exhibiting too much diversity.
% \red{Based on our study, most fields have a depth two.}
% In Figure~\ref{fig:span_retrieval_tree}, the pink and dashed rectangles presents a compete path for the fourth row in Table~\ref{tab:span_examples}-(a).

After compression, the span data that needs to be transmitted to the backend trace collector become significantly smaller in size, i.e., only the path identifier and the values of local fields specified by the leaf.
At the backend side, the uncompression process to restore the original span is straightforward and efficient.
This involves reconstructing the local fields based on the corresponding values received and combining them with the universal fields based on the path identifier.
In this process, the backend side should keep the latest copy of the \sname and the value of \textit{time\_base}.
We introduce an efficient synchronization mechanism later in Section~\ref{sec:differential_sync}.
For \textit{time\_base}, we periodically reset it, e.g., every second, ensuring that the time offset remains consistently small.

% For each span, we traverse the \sname and compare the KV pairs stored in the non-leaf nodes with the corresponding fields of the span.
% If all universal fields of the span \red{match}, the span can be compressed as a path identifier with the values of its local fields.

% In this section, we formally define the Spans Array, Merging Tree, and the execution steps of the Merging Algorithm.

% The Merging Tree is defined as follows:
% \begin{definition}\label{def_Merging_tree}

% \end{definition}

% We define the following operation as restoring a Span:
% \begin{definition}\label{def_restoring_span}
% Select a leaf node of the Merging Tree, and combine all the key-value pairs corresponding to the nodes on the unique path from this leaf node to the root node to form a new key-value pair set.
% \end{definition}

% For a Merging Tree, restoring all Spans means performing the span restoration operation for all leaf nodes of the Merging Tree, resulting in a new set of key-value pair sets. If all the Spans restored from a Merging Tree have the same "Span Name" and are identical to those in a Spans Array, then we say the Merging Tree and the Spans Array are equivalent.

% The goal of the Merging Algorithm is to convert the Spans Array into its equivalent Merging Tree to achieve data compression.
% As implied by the name Merging Algorithm, this algorithm merges identical key-value pairs together using a data structure similar to a Prefix Tree, thereby reducing the frequency of repeated key-value pairs.
% Specifically, Merging Tree reduces the occurrence frequency of

% \begin{equation*}\label{nt_reduce}
% f=\sum_{\mathrm{node} \in U} \mathrm{Son}(\mathrm{node}) -1
% \end{equation*}

% key-value pairs, where $U$ means a set of all non-leaf nodes of an Merging Tree, $\mathrm{Son}(x)$ equals the number of leaf nodes in the subtree formed by node $x$.

% In the above definition, we stipulate that the Merging Tree must satisfy the Keep-Order property. This means that for a Spans Array with a specific Span Name S, we can fix the shape of the Merging Tree by fixing an order of the spans' attribute keys. Specifically, for spans with Span Name equals S, if the attribute key A appears in the $i$th position in the permutation $P$ of their attribute keys, we place nodes corresponding to attribute key A at the $(i + 1)$th level in the subtree rooted at Span Name equals S in the Merging Tree. Therefore, given the permutation $P$, we can generate the corresponding Merging Tree according to this order. It is not difficult to see that the possible shapes of the Merging Tree correspond one-to-one with all possible permutations $P$.

% Here, it is easy to see that for different permutations $P$ corresponding to different Merging Trees, the value of $f$ may vary. This means that the order of attribute keys will ultimately affect the compression efficiency of the Merging Tree. Next, we will present the Merging Algorithm, which is the process of generating the Merging Tree, without further explanation. The impact of permutation $P$ on the value of $f$, as well as the optimization of the value of $f$, will be discussed in detail in the next subsection.

% \begin{algorithm}
% \caption{Preprocessing Stage}
% \begin{algorithmic}[1]
% \State \textbf{Input\:} Spans Array \texttt{spansArray}
% \State \textbf{Initialize:}
% \State \quad \texttt{O} $\leftarrow$ empty 2D dictionary
% \State \quad \texttt{E} $\leftarrow$ empty 3D dictionary
% \For{\texttt{s} \textbf{in} \texttt{spansArray}}
%     \For{\texttt{(k, v)} \textbf{in} \texttt{s}}
%         \If{\texttt{E[s.Name][k][v]} = \textbf{false}}
%             \State \texttt{O[s.Name][k]} $\leftarrow$ \texttt{O[s.Name][k]} $+ 1$
%             \State \texttt{E[s.Name][k][v]} $\leftarrow$ \textbf{true}
%         \EndIf
%     \EndFor
% \EndFor
% \For{\texttt{Name} \textbf{in} \texttt{O}}
%     \State \texttt{keys} $\leftarrow$ \texttt{O[Name].keys()}
%     \State \texttt{sortedKeys} $\leftarrow$ \texttt{sort(keys, key=lambda k: O[Name][k])}
%     \State \texttt{P[Name]} $\leftarrow$ \texttt{sortedKeys}
% \EndFor
% \State \textbf{Output\:} Permutations of keys \texttt{P}
% \end{algorithmic}
% \end{algorithm}

% Algorithm 1 describes the tasks accomplished during the preprocessing stage of the algorithm. In brief, for all spans with the same span name, we count the number of unique values for each attribute key. Then, we sort the attribute keys in ascending order based on the number of unique values, forming a permutation.

% \begin{algorithm}
% \caption{Compression Stage}
% \begin{algorithmic}[1]
% \State \textbf{Initialize:} Create node \texttt{Root}
% \For{\texttt{span} \textbf{in} \texttt{spansArray}}
%     \State \texttt{P\_span} $\leftarrow$ \texttt{P[span.Name]}
%     \State \texttt{now} $\leftarrow$ \texttt{Root\_span\_name}
%     \For{\texttt{i} \textbf{in} \texttt{range(len(P\_span))}}
%         \State \texttt{k} $\leftarrow$ \texttt{P\_span[i]}
%         \If{\texttt{now} has a child associated with \texttt{<k,span[k]>}}
%             \State \texttt{now} $\leftarrow$ \texttt{child}
%         \Else
%             \State Create node \texttt{newNode}
%             \State Associate \texttt{<k,span[k]>} with \texttt{newNode}
%             \State Connect \texttt{newNode} to \texttt{now}
%             \State \texttt{now} $\leftarrow$ \texttt{newNode}
%         \EndIf
%     \EndFor
%     \State Create leaf node \texttt{leafNode}
%     \State Associate rest span info. with \texttt{leafNode}
%     \State Connect \texttt{leafNode} to \texttt{now}
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% Algorithm 2 describes the tasks accomplished during the compression stage of the algorithm. In brief, during the compression stage, we insert the span's attributes into the Merging Tree in the order determined during the preprocessing stage.

% \begin{algorithm}
% \caption{Decompression Stage}
% \begin{algorithmic}[1]
% \Function{D}{now}
%     \If{\texttt{now} is a leaf node}
%         \State \Return \texttt{rest of span key-value pairs}
%     \Else
%         \State \texttt{results} $\leftarrow$ empty list
%         \For{\texttt{child} \textbf{in} \texttt{now.children}}
%             \State \texttt{childResults} $\leftarrow$ \Call{D}{child}
%             \For{\texttt{span} \textbf{in} \texttt{childResults}}
%                 \State \texttt{append span to results}
%             \EndFor
%         \EndFor
%         \For{\texttt{span} \textbf{in} \texttt{results}}
%             \State \texttt{add key-value pairs associated with now to span}
%         \EndFor
%         \State \Return \texttt{results}
%     \EndIf
% \EndFunction
% \State \textbf{Output\:} \Call{D}{Root}
% \end{algorithmic}
% \end{algorithm}

% Algorithm 3 describes the tasks accomplished during the decompression stage of the algorithm. Simply put, we designed a recursive function $D(x)$ that restores the Spans Array from the bottom up.

% \begin{figure*}[htp]
%     \centering
%     \includegraphics[width=18cm]{figures/compress.pdf}
%     \caption{Process of compression}
% \end{figure*}


\subsection{Optimizations for \name}

So far, we have introduced the algorithms for span compression and uncompression.
It can be seen that \alias has a small computational complexity.
This is because for each span, these processes involve only a single path traversal of the \sname from the root to a leaf.
However, the issue of space complexity presents a more significant challenge.
The \sname can potentially grow too large and consume an excessive amount of memory.
Besides setting a hard constraint on the memory, we have also identified some opportunities to optimize its size.

\subsubsection{\name Restructuring}

During the construction of \sname in Figure~\ref{fig:span_retrieval_tree}, we simply follow the left-to-right order of keys in Table~\ref{tab:span_examples} to form the parent-child relations among nodes.
For example, key \textit{address} is the child of \textit{name} and also the parent of \textit{data.size}.
We observe that this may result in a sub-optimal \sname structure.
Specifically, for the \sname in Figure~\ref{fig:sft_restructuring} which is built based on the spans in Table~\ref{tab:span_examples}-(b), we can see that the three paths differ only in the \textit{type} field.
A better structure can be obtained by moving \textit{type} down to the bottom, which avoids the recurrence of the other three fields.
Based on this finding, we propose the following way to restructure the \sname.
In Section~\ref{sec:compression_uncompression}, we have calculated the number of possible values associated with each key once a new path emerges.
If a parent field has more values than its child, we swap their positions in the \sname.
That is, we reorder the keys of \sname based on the ascending number of their unique values (line 15).
% This process continues until all fields find their appropriate places.
After reordering, the identical nodes at the same depth will be merged, e.g., \textit{MySQL}, \textit{SUCCESS}, and \textit{1} in Figure~\ref{fig:sft_restructuring}.
Finally, the path identifiers of the restructured \sname will be adjusted (line 16).

% In the previous section, we mentioned that the efficiency of the Merging Tree compression is determined by the formula:
% \begin{equation*}
% f=\sum_{\mathrm{node} \in U} \mathrm{Son}(\mathrm{node}) -1
% \end{equation*}
% In other words, since the number of leaf nodes in the Merging Tree is fixed (which equals the number of Spans in the Spans Array), the fewer non-leaf nodes the Merging Tree has, the better the compression effect of the Merging Tree. Through our research on the dataset, we discovered the following pattern: attributes with more possible values often imply attributes with fewer possible values. The diagram below illustrates this principle. \texttt{func1} and \texttt{func2} are HTTP handlers for the GET method, and \texttt{func3} and \texttt{func4} are HTTP handlers for the POST method. When the \texttt{method} attribute is placed above the \texttt{handler} attribute, the number of non-leaf nodes is less than when the \texttt{handler} attribute is placed above the \texttt{method} attribute. Based on this principle, we construct the Merging Tree by sorting the attributes in ascending order of the number of possible values.

% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=9cm]{figures/order.pdf}
%     \caption{How order affects compression}
% \end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.66\linewidth]{figures/sft_restructuring.pdf}
    \caption{Span Retrieval Tree Restructuring}
    \label{fig:sft_restructuring}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.74\linewidth]{figures/span_retrieval_tree.pdf}
%     \caption{An Example of \name}
%     \label{fig:span_retrieval_tree}
% \end{figure}

\subsubsection{Mapping-based Tree Compression}
\label{sec:mapping-based tree compression}

Although we have restructured the \sname to eliminate redundant nodes, there could still be repeated keys and values in it.
For example, in Figure~\ref{fig:span_retrieval_tree}, key \textit{data.size} appears in all \textit{data.size} nodes, e.g., \textit{\{``data.size'': ``64 bytes''\}} and two of them also share value \textit{64 bytes.}
Thus, to further compress the size of \sname, we employ a dictionary to map keys/values that occur multiple times to shorter identifiers.
We construct the identifiers using the standard alphanumeric set, i.e., [0-9a-zA-Z].
Initially, the hashed output consists of a single character, from '0' to '9,' followed by 'a' through 'z,' and finally 'A' through 'Z.'
Upon exhausting the single character possibilities, the function increases the length of the hash output to two characters, starting from '00,' '01,' and so forth.
Since each universal field has limited distinct values, i.e., smaller than $\psi$, the dictionary will also be small in size.
Note we do not encode the values of local fields (not in the \sname), which may inevitably make the dictionary too big given their diversity.
% \zb{how to do the encoding: should include separation by space, comma, etc.}
% \zb{will the dictionary map the local values?}
Similar to the \sname synchronization process between services and the tracing backend, the dictionary will be sent to the backend every time it undergoes an update.
% \zb{enough details?}
% As discussed above, we use the Merging Algorithm to compress a large amount of repetitive attribute value data in the Spans data. However, even with the Merging Algorithm, due to different choices of the order of attributes, it is still possible for a certain attribute value to repeatedly appear on the compressed Merging Tree. Therefore, we count the number of occurrences of the same attribute value on the Merging Tree and then sort them in descending order of occurrences, assigning shorter codes to more frequently occurring attribute values.
% After Dictionary Compression, the Spans Collectors send the compressed data and the dictionary to the tracing backend.
% When compressing using a character stream format like JSON, the assigned codes are allocated from a character set (e.g., [0-9a-zA-Z]), and the corresponding codes are determined based on the character set and the ranking of frequency. For gRPC, since gRPC uses variable-length encoding for numbers, we can directly encode them as numbers.

Based on our empirical study (Section~\ref{sec:redundancy_study}), there exists structural redundancy among the attributes of a span.
% We propose the idea of \textit{recursive dictionary} to further compress both \red{\sname} and the dictionary.
We address this issue by examining the ingredients of the attributes.
Specifically, when constructing the dictionary, we encode the common sub-fields shared among spans (instead of the entire fields) as identifiers.
These sub-field identifiers are then used to compose the complete attributes.
% The idea is that instead of encoding the entire field as a single identifier, we represent the common sub-fields shared among spans as identifiers and use them to compose the complete attributes.
% if an attribute is (partially) composed by a combination of other fields, then the sub-fields will be replaced by the code of the fields.
% When restoring the attribute, such .
Take a span example from OpenTelemetry~\cite{opentelemetry_traces}, which contains the following fields:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{figures/structural_correlation.pdf}
    \label{fig:structural_correlation}
\end{figure}

% \begin{lstlisting}
% {
%     "net.transport": "IP.TCP",
%     "net.peer.ip": "172.17.0.1",
%     "net.peer.port": "51820",
%     "net.host.ip": "10.177.2.152",
%     "net.host.port": "26040"
%     ...
% }
% \end{lstlisting}

\noindent We can see that in the keys, there are some words that appear multiple times, e.g., \texttt{net}, \texttt{host}, \texttt{port}.
Without considering such correlations, we could potentially introduce too much lengthy keys to the dictionary.
To remove such redundancy, we first separate each key into a list of tokens based on delimiters dot (``.'') and underline (``\_''), which are configurable.
When encoding the key, each of its tokens will be mapped to the corresponding identifier.
As the value part exhibits more diversity, we only apply this technique to the keys to avoid too much computational overhead.

% \subsection{Edge-case Span Detection}
% \zb{need to talk more about why we need to do this}
% Based on the idea that failure symptoms are locally observable~\cite{DBLP:conf/nsdi/ZhangXAVM23}, we incorporate a detection mechanism for edge-case spans in the compression process.\zb{why need it at the collection side (efficiency? we have already gather related information), cant we just do it at the backend?}
% Specifically, when performing \sname construction and dictionary-based tree compression, we collect information about the occurrence numbers of different values in the spans.
% This allows us to pinpoint the values that rarely occur, which often signify anomalous events or outliers.
% In particular, certain fields such as \textit{span ID} and \textit{start/end time} are intended to hold unique values.
% Thus, we allow users to configure the set of fields whose rare occurrences should be closely monitored\zb{examples?}.
% Upon the detection of such rare values, we send the corresponding \textit{trace ID}\zb{then we dont know which span is the anomaly} to the tracing backend.
% The backend can immediately trigger an alert and notify system operators to investigate potential issues or anomalies.
% \zb{One advantage is interpretability, how can we achieve it? add a flag along with the trace ID?}

% % When generating the Merging Tree and performing Dictionary Compression, we collect information about the frequency of attribute values in the Spans. Based on this, we can calculate the frequency of occurrence for a particular category of attribute values. By considering the frequency and the number of unique attribute values for a specific attribute, we can determine if an attribute value is rare or uncommon. Generally, a rare attribute value signifies an anomalous behavior pattern. We believe that while performing the compression algorithm at the Spans Collector, it is possible to identify potential exceptional Spans and send the Trace ID of those potential exceptional Spans to the tracing backend.

% We use the following two criteria to pinpoint rare spans\zb{which are commonly used?} based on the type of attributes under monitoring:

% \begin{itemize}
%     \item \textit{Categorical attributes}: We employ a frequency-based approach to manage categorical attributes such as HTTP status codes and IP addresses.
%     Each node preserving one possible value of the target attribute will maintain a frequency ratio, meaning the proportion of spans carrying that specific value relative to the total span count.
%     Upon the arrival of each span, if the frequency of its carried value is below a pre-defined threshold (the default setting is 0.01, which is configurable), that span will be regarded as a rare span.
%     Subsequently, the frequency ratio across all nodes will be updated.
%     This approach helps in pinpointing spans that may indicate \red{unusual system events}.

%     \item \textit{Numerical attributes}: For numerical attributes such as duration, we apply a statistical outlier detection method, i.e., checking whether the value falls within the three-sigma range.
%     To this end, each node will maintain the current average ($\mu$) and standard deviation $\sigma$ of the attribute values, along with a cumulative count.
%     These parameters are updated dynamically as new spans are processed.
%     If a particular value significantly deviates from the norm, it will be flagged as a rare span.
%     This allows us to spot any abnormal variations in the data.
% \end{itemize}

% If the ratio of the total number of spans with the same \texttt{span\_name} to the total number of sampled spans is lower than \texttt{abnormal\_span\_name\_rate}, the span is considered rare.
% When iterating through the attributes of a specific span:
% \begin{itemize}
%   \item If an attribute is present in the Merging Tree (indicating a low ratio of spans to possible attribute values, i.e., lower than \texttt{threshold\_rate}), and the ratio of the total number of spans with the same \texttt{span\_name} to the frequency of occurrence of that attribute is lower than \texttt{abnormal\_attributes\_frequency\_rate}, the span is considered rare.
%   \item If an attribute is not present in the Merging Tree (indicating a high ratio of spans to possible attribute values, i.e., higher than \texttt{threshold\_rate}), and the attribute's data type is integer or floating-point, the attribute is treated as continuous. The average $\mu$ and standard deviation $\sigma$ of this attribute are calculated. If the attribute value is not within the interval $[\mu - 3\sigma, \mu + 3\sigma]$, the span is considered rare.
% \end{itemize}