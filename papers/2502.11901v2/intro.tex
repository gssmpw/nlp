\section{Introduction}
In an era where software vulnerabilities can risk tremendous damages\footnote{On July 19, 2024, an abnormal update distributed by the cybersecurity company CrowdStrike caused issues for a large number of its global customers’ Windows operating systems, resulting in blue screen errors.} and compromise national security \footnote{U.S. Cybersecurity and Infrastructure Security Agency has urged the future software development to ensure memory safety.}, ensuring the correctness and safety has become an urgent priority. Proof-oriented programming integrates formal verification into software development, enabling mathematically rigorous correctness guarantees.
 %\textcolor{red}{
 Proof-oriented programming languages such as F*\cite{swamy2011secure} and Dafny\cite{dafny} support this paradigm by providing expressive type systems and precise specification mechanisms. These capabilities enable static verification of program correctness without the need for extensive test suites or runtime execution. These languages like F* allow developers to write programs alongside formal proofs, providing strong guarantees about functional correctness and security properties, and famous real-world systems including Firefox, the Linux kernel, Tezos blockchain, and Azure Cloud have employed formally verified components.%} 
 However, despite decades of research, the adoption of proof-oriented programming remains limited due to the high cost of proof construction and the steep learning curve of formal methods.

On the other hand, the rapid advancements in large language models (LLMs) have transformed many areas of software development\cite{austin2021program, chen2023teaching, nijkamp2022codegen, xia2022less, xia2023automated, jin2023inferfix, jimenez2024swebenchlanguagemodelsresolve}. %Their ability to perform complex reasoning~\cite{ahn2024large}, generate and manipulate structured code~\cite{yang2023leandojo,wang2023dt} and solving maths using formal tools~\cite{lin2025prover} suggests that they could assist in proof synthesis and repair reducing the human effort required for formal verification\kexin{again, this can be simplified and aggregate all the citations, just to show there are some promising evidence that LLMs can reason}. 
Yet, applying LLMs to proof-oriented programming presents fundamental challenges~\cite{chakraborty2024towards}. Proof-oriented programming is highly distinct from conventional coding paradigms, demanding complex formal reasoning of program semantics over long contexts, which current models struggle with~\cite{loughridge2024dafnybench}. A major bottleneck is extreme data scarcity, which manifests in two key ways: (1) a lack of diverse, high-quality corpora in proof-oriented programming languages such as F* to teach the model the syntax and semantics of that language (F* constitutes of only 0.002\% in Stack-v2 ~\cite{lozhkov2024starcoder}), and (2) an absence of large-scale project-level verification data, which involves highly complex and context-dependent formal reasoning. As a result, even state-of-the-art LMs fail to generalize effectively to proof construction and verification tasks~\cite{loughridge2024dafnybench,fstar2024}.%\kexin{citations to support}.

In this work, we introduce a data-centric post-training recipe designed to bridge the gap between general-purpose coding LLMs and repository-level proof-oriented programming in F*. We systematically address data scarcity and adaptation challenges through three key strategies:
\begin{enumerate}
    \item \textbf{Enhancing General Programming Capabilities with Diverse Code Data:} inspired by existing works showing the benefit of diversification~\cite{zhang2024textbf,dong2023abilities,chen2024diversity}, we train the model beyond the immediate focus of formal verification in F* but over diverse programming tasks to enable its code-reasoning and instruction-following capabilities. 
    \item  \textbf{Learning Basic Proof-Oriented Programming via Synthetic Tasks:}
We synthesize function-level basic programming and property-proving problems in F*, allowing LLMs to learn fundamental verification patterns in a controlled setting without introducing complex inter-dependencies.
\item  \textbf{Synthetic Augmentation for Proof Synthesis and Repair:}
Beyond training basic property-proving problems and existing repositories, we curate novel synthetic repository-level problem solving and proof repair data to teach LLMs how to complete and correct project-level proofs with more complex and longer contextual dependencies.
% Beyond training on existing repositories, we generate novel provable properties for each repositories and curate synthetic repair data to teach LLMs how to complete and correct proofs. We are the first to produce project-level synthetic training data for formal verification. 
\end{enumerate}
Following the recipe above, we transform LLMs into specialized verification assistants capable of both synthesis and repair for \textbf{P}roof-\textbf{o}riented \textbf{P}rogramming, which we call \name. \name is the first project-level formal verification specialist LLM trained on synthetic instruction-tuning data. 
Notably, strategies \textbf{2} and \textbf{3} require generating problems using existing language models that has limited knowledge and low accuracy on F*. 
However, we could leverage F* solver to obtain data with correctness guarantee for generation tasks, and retrieve error messages to craft repair datasets\footnote{The correctness can be determined by running the solver without test cases as in conventional programming languages.}
% \kexin{the following sentences read more like the beginning of this paragraph, then ``notably'' elaborates how PoP benefits from the above 3 strategies. or maybe start a new paragraph from here}
% \kexin{reads like the following can be a new paragraph}
Our experiments demonstrate that \name demonstrates strong capacities to perform proof-oriented programming on a project level, leading to a remarkable margin of 64\% over GPT-4o and can boost GPT-4o's performance to 54\% by repairing a randomly chosen failed attempt.

% Formal verification plays a crucial role in ensuring the correctness and security of modern software systems, especially in safety-critical domains such as cryptography, operating systems, and distributed protocols. Proof-oriented programming languages, such as F*, Dafny, and Coq, integrate formal proofs with program logic, enabling developers to write software with strong correctness guarantees. By embedding proofs within programs, developers can mathematically verify that their code adheres to specified properties, reducing the risk of critical failures and vulnerabilities. However, despite their theoretical promise, proof-oriented programming remains largely inaccessible to mainstream software development due to the significant manual effort required for proof construction and repair.

% Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in code synthesis, automated reasoning, and theorem proving. AI-driven automation has the potential to bridge the gap between formal methods and practical software development, making verification-aware programming more scalable. While LLMs have been successfully applied to theorem proving in tactic-based assistants like Coq and Lean, their performance in proof-oriented programming languages with SMT-based verification, such as F*, remains limited. The primary challenge is extreme data scarcity: (1) a lack of publicly available corpora in proof-oriented programming languages and (2) an absence of large-scale, project-level formal verification datasets. This scarcity limits the ability of LLMs to generalize and generate formally correct code, making automated proof synthesis and repair particularly challenging.

% In this work, we introduce a data-centric post-training approach to enhance the proof synthesis and repair capabilities of pre-trained code LMs for the F* language. Our approach systematically addresses data scarcity through three key strategies:

% Enhancing General Programming Capabilities: We incorporate diverse programming data to improve the model’s foundational coding proficiency.

% Specialized Fine-Tuning for F*: We generate synthetic proof-related data by synthesizing elementary programming and property-proving problems in F*.

% Augmenting Formal Verification Datasets: We generate new provable properties from existing repositories and curate synthetic repair data, ensuring the model is trained on meaningful, verification-centric examples.

% By integrating these techniques, our method significantly improves the ability of LLMs to both synthesize correct proofs and repair incorrect ones in verification-aware programming languages. Our empirical results show that this approach achieves a proof completion improvement of XX\% and a repair success rate increase of XX\%, demonstrating that synthetic augmentation can substantially enhance LLMs' formal reasoning capabilities. Our findings suggest that data-driven techniques can expand the reach of AI-assisted verification, making proof-oriented programming more accessible and scalable for real-world software development.

% This work contributes to the growing body of research on AI-assisted formal verification by providing:

% A novel data-centric training paradigm for improving proof-oriented programming in LLMs.

% A systematic analysis of synthetic augmentation techniques for overcoming data scarcity in proof synthesis.

% Empirical validation showing substantial gains in proof completion and repair success rates for F*.

% By advancing the integration of AI with formal verification, we aim to reduce the barriers to proof-oriented programming and pave the way for scalable, high-assurance software development.
