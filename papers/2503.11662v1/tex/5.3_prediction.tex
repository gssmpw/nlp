
\subsection{Performance and Power Forecasting from Verilog Code}
\label{sec:prediction}

\iffalse
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{figure/predictionflow5.pdf}
    \caption{Performance and power forecasting from Verilog code.}
    \label{fig:prediction_flow}
\end{figure}
\fi

In Phase II, the Verilog generated from Phase I is utilized for performance and power forecasting. In general, the code should have no syntax errors. On the other hand, our method tolerates limited functional errors, i.e., even if the code cannot be synthesized to correct circuits, it can still be applied to provide reasonable performance/power estimates. Several previous works have attempted to make performance and power predictions based on Verilog code \cite{Sengupta2022Prediction}\cite{Xu2022systhesisPrediction}\cite{Fang2023MasterRTL}\cite{Lopera2023GNNPrediction}, and we adopt the approach from \cite{Sengupta2022Prediction} with one modification. The models of \cite{Sengupta2022Prediction} are trained by post-placement analysis data while the models used by Lorecast are trained by post-routing analysis data. Thus, Lorecast is expected to provide a more accurate forecast in capturing the layout impact.
The input Verilog code is first parsed to obtain an Abstract Syntax Tree (AST) using an off-the-shelf software tool\cite{Yamazak2015Pyverilog}. Then, features are extracted from the obtained AST. Then, an XGBoost model is applied to obtain the performance and power forecast for the corresponding Verilog code.


%this method involves extracting features from the Verilog Abstract Syntax Tree (AST) and using an ML model for prediction. First, the generated Verilog code is fed into an AST extraction tool \cite{Yamazak2015Pyverilog}, which outputs the corresponding AST. The AST is then processed by a parsing engine to extract features and convert them into feature vectors. Finally, an ML model is applied to predict the performance and power results based on the features of the LLM-generated Verilog code.

