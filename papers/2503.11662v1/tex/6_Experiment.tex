
\section{Experimental Results}
\label{sec:Experiment}

\subsection{Experiment Setup}

\noindent{\bf Testcases.}
In addition to the dataset of RTLLM~\cite{lu2024RTLLM}, we prepare new designs, many of which are larger than
those in \cite{lu2024RTLLM}, for training the XGBoost model and testing the techniques. The 10 testcases are different from the 45 designs in the training dataset. Five of the 10 testcases are from \cite{lu2024RTLLM} and the other five are newly produced by ourselves. The statistics of our testcases are shown in Table~\ref{tab:testset} in comparison with previous works. One can see that our testcases are significantly larger than the previous ones. 


\begin{table}[htb]
\centering
\caption{Cell count statistics of testcases used by
Lorecast in comparison with testcases of previous works.
}
\resizebox{0.8\linewidth}{!}{%
\begin{tabular}{|c|c||ccc|}
\hline
\multirow{2}{*}{Work} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Num of\\ designs\end{tabular}} & \multicolumn{3}{c|}{Number of cells} \\ \cline{3-5} 
 &  & Medium & Mean & Max \\ \hline
 \hline
Chip-Chat~\cite{Blocklove2023Chip-Chat} & 8 & 37 & 44 & 110 \\
Thakur, et al.\cite{Thakur2023Benchmarking} & 17 & 9.5 & 45 & 335 \\
RTLLM~\cite{lu2024RTLLM} & 30 & 121 & 408 & 2435 \\ \hline
\hline
Lorecast testcases & 10 & 851 & 1278 & 4278 \\ \hline
\end{tabular}%
}
  \label{tab:testset}%
\end{table}


%\vspace*{1mm}
\noindent{\bf Techniques evaluated.}
Several LLMs are evaluated, including GPT3.5, GPT4, GPT4o~\cite{OpenAI2023GPT-4}, Llama3, Llama3.1~\cite{meta2024Llama}, Gemini 1.5 and Gemini 1.5 Pro~\cite{Google2024Gemini}. Lorecast is examined with GPT4, GPT4o and Gemini 1.5Pro, the three best-performing LLMs for Verilog code generation.
In addition, the regulated prompting technique and IPREF technique (Section~\ref{sec:code_generation}) are also assessed. 

%\vspace*{1mm}
\noindent{\bf Evaluation metrics.}
In the experiments, we evaluate syntax correctness,
functional correctness of the generated Verilog code, and the accuracy of Lorecast forecasting.
Syntax checking for LLM-generated Verilog codes is performed using Icarus~\cite{Williams2024Icarus}. Functional correctness is accessed through RTL simulation using Icarus. In previous works~\cite{liu2023VerilogEval,lu2024RTLLM}, syntax/functional correctness is evaluated by $pass@k$, which means the probability of any syntax/functional correct generation in $k$ attempts for a design. Such a metric generally means multiple attempts are needed to produce syntax/functionally correct code. Since the goal of Lorecast is to obtain quick estimation and we try to avoid multiple attempts. Hence we adopt a simpler and significantly more strict metrics. For each design,
we report {\bf correct} if and only if all attempts, which can be a single one or multiple ones, lead to syntax/functional correctness, i.e., the ``correct" here is a binary indicator instead of probability. 
We also report the {\bf correct rate}, which is the ratio of the number of designs where the generated codes are correct versus the total number of designs in the testcases. The accuracy of performance in terms of Total Negative Slack (TNS) and power forecast is evaluated by 
{\bf Absolute Percentage Mean Error (APME)}. All TNS values are reported as their absolute values.
Let $\bar{y}$ be the average forecast result among all designs, and $\bar{y}^*$ be the ground truth average among all designs. Then, APME is defined by
% \vspace*{-3mm}
\begin{equation}
\mathcal{E} = \frac{|\bar{y}-\bar{y}^*|}{\bar{y}^*}\times 100\% \label{eq:APME}
\end{equation}
The reason that we could not use Mean Absolute Percentage Error (MAPE) is that some ground truth TNS values are 0. In addition, the accuracy is assessed by the
$R^2$ correlation factor.


%\vspace*{1mm}
\noindent{\bf Tools and computing platform.}
In generating ground truth data, logic synthesis is performed by Synopsys Design Compiler with a 45nm cell library~\cite{NanGateOpenCellLibrary}. The layout, including placement and routing, is obtained using Cadence Innovus. The ground truth timing and power results are obtained through post-layout analysis. Synthesis and layout run on a Linux x86\_64 machine with AMD EPYC 7443 24-Core processors (48 cores in total), while ML model predictions are performed on a Windows 10 computer with an 11th Gen Intel(R) Core(TM) i7-11800H processor at 2.30GHz and 32GB RAM.

%We apply RTLLM\cite{lu2024RTLLM} along with a set of prompts we created as an evaluation set to measure the syntax and functional accuracy of the LLM. We use Icarus Verilog for syntax checking and run a testbench to verify functional correctness. In our experiments, Lorecast is validated on unseen designs. To collect ground truth data, we use a 45nm technology library, performing synthesis by Synopsys Design Compiler with hundreds of parameter sets and layout with Cadence Innovus Implementation System. Synthesis and layout run on a Linux x86\_64 machine equipped with AMD EPYC 7443 24-Core processors (48 cores in total), while ML model predictions are performed on a Windows 10 computer with an 11th Gen Intel(R) Core(TM) i7-11800H processor at 2.30GHz and 32GB RAM.

%\vspace*{-10mm}

\subsection{Main Results}

%\vspace*{-2mm}

\begin{table*}[ht]
\centering
\caption{Performance and power forecasting results.}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l||rr||rr||ccrr||ccrr||ccrr}
\hline
\multicolumn{1}{c||}{\multirow{2}{*}{\textbf{Design}}} & \multicolumn{2}{c||}{\textbf{Ground truth}} & \multicolumn{2}{c||}{\textbf{Forecast from manual}} & \multicolumn{4}{c||}{\textbf{Lorecast with GPT4}} & \multicolumn{4}{c||}{\textbf{Lorecast with Gemini 1.5 Pro}} & \multicolumn{4}{c}{\textbf{Lorecast with GPT4o}} \\
\multicolumn{1}{c||}{} & \multicolumn{1}{c|}{Power{*}} & \multicolumn{1}{c||}{TNS{*}} & \multicolumn{1}{c|}{Power} & \multicolumn{1}{c||}{TNS} & \multicolumn{1}{c|}{Syntax} & \multicolumn{1}{c|}{Func} & \multicolumn{1}{c|}{Power} & \multicolumn{1}{c||}{TNS} & \multicolumn{1}{c|}{Syntax} & \multicolumn{1}{c|}{Func} & \multicolumn{1}{c|}{Power} & \multicolumn{1}{c||}{TNS} & \multicolumn{1}{c|}{Syntax} & \multicolumn{1}{c|}{Func} & \multicolumn{1}{c|}{Power} & \multicolumn{1}{c}{TNS} \\ \hline
\hline
right\_shifter & \multicolumn{1}{r|}{992} & 0.069 & \multicolumn{1}{r|}{986} & 0.0698 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{775} & 0.0987 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{986} & 0.0808 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{775} & 0.1028 \\
signal\_generator & \multicolumn{1}{r|}{1508} & 0.225 & \multicolumn{1}{r|}{1509} & 0.2223 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{1505} & 0.2152 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{1505} & 0.2152 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{1507} & 0.2251 \\
multiply & \multicolumn{1}{r|}{35} & 0 & \multicolumn{1}{r|}{43} & 0.0052 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{44} & 0.0052 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{70} & 0.2792 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{158} & 0.0771 \\
accu & \multicolumn{1}{r|}{4042} & 0.306 & \multicolumn{1}{r|}{4052} & 0.3043 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{3874} & 0.2822 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{3964} & 0.2667 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{4151} & 0.2811 \\
asyn\_fifo & \multicolumn{1}{r|}{99.9} & 0 & \multicolumn{1}{r|}{108} & 0.0022 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{166} & 0.0262 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{87} & 0.0065 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{55}} & \multicolumn{1}{r|}{166} & 0.0262 \\
matmul22 & \multicolumn{1}{r|}{307} & 0 & \multicolumn{1}{r|}{306} & 0.0020 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{339} & 0.0065 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{343} & 0.0329 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{272} & 0.0065 \\
pe\_32bit & \multicolumn{1}{r|}{84818} & 1.139 & \multicolumn{1}{r|}{84811} & 1.1366 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{87173} & 1.1037 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{86861} & 1.0424 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{87173} & 1.1037 \\
izigzag & \multicolumn{1}{r|}{221131} & 0.05 & \multicolumn{1}{r|}{219081} & 0.0499 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{220270} & 0.0512 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{224329} & 0.0793 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{220270} & 0.0646 \\
huffmandecode & \multicolumn{1}{r|}{37461} & 0.877 & \multicolumn{1}{r|}{37499} & 0.7387 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{38549} & 0.7387 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{36152} & 0.8773 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{36118} & 0.6510 \\
pe\_64bit & \multicolumn{1}{r|}{334799} & 1.584 & \multicolumn{1}{r|}{334178} & 1.5985 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{328158} & 1.6385 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{324176} & 1.5985 & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{c|}{\ding{51}} & \multicolumn{1}{r|}{321436} & 1.6099 \\ \hline
\hline
\begin{tabular}[c]{@{}l@{}}Average\\ APME\end{tabular} & \multicolumn{1}{r|}{68519} & 0.425 & \multicolumn{1}{r|}{\begin{tabular}[c]{@{}r@{}}68257\\ (1\%)\end{tabular}} & \begin{tabular}[c]{@{}r@{}}0.413\\ (3\%)\end{tabular} & \multicolumn{2}{r|}{\textbf{}} & \multicolumn{1}{r|}{\begin{tabular}[c]{@{}r@{}}68687\\ (1\%)\end{tabular}} & \begin{tabular}[c]{@{}r@{}}0.417\\ (2\%)\end{tabular} & \multicolumn{2}{r|}{\textbf{}} & \multicolumn{1}{r|}{\begin{tabular}[c]{@{}r@{}}68848\\ (1\%)\end{tabular}} & \begin{tabular}[c]{@{}r@{}}0.448\\ (5\%)\end{tabular} & \multicolumn{2}{r|}{\textbf{}} & \multicolumn{1}{r|}{\begin{tabular}[c]{@{}r@{}}67203\\ (2\%)\end{tabular}} & \begin{tabular}[c]{@{}r@{}}0.415\\ (2\%)\end{tabular} \\ \hline
\multicolumn{10}{l}{$^{\mathrm{*}}$Power unit is $\mu W$ and TNS  unit is $ns$. }
\end{tabular}%
}
  \label{tab:maintable}%
  
\end{table*}
% \vspace{-10pt}
% \vspace*{-10mm}


The main results of performance and power forecasting are shown in Table~\ref{tab:maintable}. In addition, 
the table includes syntax and functional correctness results from different LLMs, where one attempt is made for each design. Columns 4 and 5 are the forecasting results from manually written Verilog code. By using the related prompting and IPREF, all three LLMs can achieve $100\%$ syntax correctness, which is required for Lorecast. None of the LLMs leads to $100\%$ functional correctness as expected. Among them, 
GPT4 with regulated prompting and IPREF achieves 
$80\%$ functional correct rate, which is similar to the best previous work~\cite{Gao2024AutoVCoder,lu2024RTLLM}.
GPT4-based Lorecast also achieves the lowest APME. 

\iffalse 

In the Table \ref{tab:maintable}, we note the number of cells required for each design, as well as the syntax and functional correctness of each generated code. We use percentage error to evaluate our results,whose entries are defined by  
\begin{equation}
\label{eq:percentage_error}
\mathcal{E} =\frac{|y_{pred-}y_{true}|}{y_{true}}\times 100
\end{equation}

In our comparisons, the GPT-4 assist Lorecast achieved the lowest percentage error, showing the best performance. Notably, within the Lorecast framework, relatively accurate predictions can still be achieved for the design described in natural language, even when the Verilog code generated by the LLM is functionally incorrect. 
Similar to how designers build layouts, minor errors may cause functional issues, but the overall layout remains almost identical. Some functionally incorrect Verilog code would got same cells as functionally correct Verilog code, with very similar nets, when synthesized.


As shown in Figure \ref{fig:scatter}, Lorecast with different LLMs can produce predictions that are close to the ground truth.
Frameworks powered by GPT-4o and Gemini 1.5 Pro yielded lower accuracy compared to the GPT-4 framework, partly due to the impact of functional correctness in the generated Verilog code.
Additionally, to ensure the feasibility of our approach, we performed synthesis and layout on Verilog code generated by the LLM, with an example shown in Figure \ref{fig:layout-results}. The LLM-generated code exhibits performance and power characteristics very similar to those of human-written code, confirming that using the Lorecast framework to forecast performance and power is feasible.

\fi


\iffalse
\begin{table*}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|c|cc|cc|cc}
\hline
\multirow{2}{*}{Design} & \multirow{2}{*}{Total   Gates} & \multicolumn{1}{c|}{\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Syntax\\ Correction\end{tabular}}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Functional\\ Correction\end{tabular}} & \multicolumn{2}{c|}{Power(um)} & \multicolumn{2}{c}{TNS(ns)} \\
 &  & \multicolumn{1}{c|}{} &  & Ground   Truth & Prediction & Ground   Truth & Prediction \\ \hline
edge\_detect & 19 & \multicolumn{1}{c|}{\ding{51}} & \ding{51} & \multicolumn{1}{c|}{418} & 419.807 & \multicolumn{1}{c|}{0.094} & 0.0939 \\
right\_shifter & 57 & \multicolumn{1}{c|}{\ding{51}} & \ding{51} & \multicolumn{1}{c|}{992} & 989 & \multicolumn{1}{c|}{0.069} & 0.069077 \\
signal\_generator & 119 & \multicolumn{1}{c|}{\ding{51}} & \ding{55} & \multicolumn{1}{c|}{1508} & 2107 & \multicolumn{1}{c|}{0.225} & 0.323 \\
accu & 277 & \multicolumn{1}{c|}{\ding{51}} & \ding{51} & \multicolumn{1}{c|}{4042} & 4092 & \multicolumn{1}{c|}{0} & 0.0276 \\
asyn\_fifo & 1692 & \multicolumn{1}{c|}{\ding{55}} & \ding{55} & \multicolumn{1}{c|}{118.1809} & - & \multicolumn{1}{c|}{0} & - \\
pe\_32bit & 3435 & \multicolumn{1}{c|}{\ding{51}} & \ding{51} & \multicolumn{1}{c|}{84818} & 8480 & \multicolumn{1}{c|}{1.139} & 0.741 \\
pe\_64bit & 12279 & \multicolumn{1}{c|}{\ding{51}} & \ding{51} & \multicolumn{1}{c|}{334799} & 333719.4 & \multicolumn{1}{c|}{1.584} & 1.53844 \\
One   more &  & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} &  & \multicolumn{1}{c|}{} &  \\ \hline
Average & 2554 &  &  & \multicolumn{1}{c|}{60956.45} & 58301.2 & \multicolumn{1}{c|}{0.444429} & 0.465503 \\ \hline
\end{tabular}%
}
\caption{Prediction for Design }
  \label{tab:maintable}%
\end{table*}
\fi


\begin{figure}[tbh]
    \centering
    \includegraphics[width=1\linewidth]{figure/scatter9.pdf}
    \caption{Power and TNS forecasts from different LLMs vs. ground truth.}
    \label{fig:scatter}
\end{figure}

\iffalse
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{figure/tns_scatter2.png}
    \caption{TNS}
    \label{fig:tns_scatter}
\end{figure}
\fi


Figure~\ref{fig:scatter} provides the scatter plots of forecast versus ground truth. GPT4-based Lorecast achieves $R^2$ correlations of 0.99 and 0.98 for power and and TNS forecast, respectively. The left of Figure~\ref{fig:layout-results} demonstrates the impact of varying synthesis/layout tool parameters for design
``{\em pe\_64bit}". Since the post-layout analysis of the LLM-generated code highly overlaps with the ground truth under different tool parameters, there is a consistency between the LLM-generated code and manually written code. The right of Figure~\ref{fig:layout-results} illustrates that Lorecast can predict the overall timing-power tradeoff curve besides individual timing-power values. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{figure/layoutresults13.pdf}
    \caption{Left: post-layout TNS and power from Verilog code generated by LLMs and human. Right: performance-power tradeoff curves predicted by Lorecast@GPT4 and of the ground truth from manually generated Verilog.
}
    \label{fig:layout-results}
\end{figure}


% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.7\linewidth]{figure/TODO.pdf}
%     \caption{Trade off 2}
%     \label{fig:enter-label}
% \end{figure}

\noindent
{\bf Runtime comparison between Lorecast and RTL-synthesis based estimation.} %To evaluate the design process acceleration provided by Lorecast, we conducted an experiment involving 6 graduate students with experience in Verilog. Participants were asked to write prompts and Verilog code for several designs, with separate recordings of the time required for writing the prompts and for writing the code. First, participants created prompts, with separate recordings of the time spent on prompt planning and writing. After completing the prompts, they proceeded to write the Verilog code and debug any syntax errors. This experimental sequence is designed to exclude the time participants spend thinking about the designs, allowing for a direct comparison between the time taken to write code and the time taken to write prompts.The details of code writing and prompting time for each design are shown in Figure \ref{fig:speeddetails}.
We compared the time cost of two different flows: one is the performance/power estimation based on manually written Verilog code and logic/layout synthesis, and the other is the manually written prompts followed by Lorecast. 
The Verilog coding/debug and prompt writing/debug time are estimated by asking six people to do both for each design. Please note that these people generally know Verilog coding and prompting but with different skill levels. Figure~\ref{fig:speeddetails} displays the mean, min, max, and standard deviation range of the time for all the testcase designs. Due to the small data sample and asymmetric distribution, sometimes the mean minus the standard deviation is below the minimum value. Overall, prompt writing/debug time is significantly shorter than Verilog writing/debug time. It also has a smaller variance so that time budgeting becomes easy. 
%\vspace*{-2mm}
\begin{figure}[!htb] 
\centering 
\includegraphics[width=0.85\linewidth]{figure/speeddetails7.png}
\caption{Verilog code writing and debug time in yellow bars; prompt writing and debug time in blue bars. Each bar indicates $\mu\pm \sigma$ range, where $\mu$ is the mean
and $\sigma$ is the standard deviation.}
\vspace{-1pt}
\label{fig:speeddetails}
\end{figure}
%As shown in Table \ref{tab:speedtable}, using Lorecast achieves an average speedup of 5X compared to traditional workflows, significantly reducing the time required for design planning. 
Other components of the time cost are covered in Table~\ref{tab:speedtable}, where the coding/debug time results are the mean values. 
The inference time is from using the ML model~\cite{Sengupta2022Prediction}. The time is dominated by Verilog code writing/debugging and prompt writing/debugging.
Overall, Lorecast can achieve $5\times$ speedup. 
Additionally, Lorecast lowers the requirement for HDL coding skills for the performance/power estimation. 

\begin{table}[!htb]
\centering
\caption{Time cost{*} of Verilog code writing/debug + synthesis in comparison with Lorecast.}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l||cccc||ccccc}
\hline
\multicolumn{1}{c||}{\multirow{2}{*}{\textbf{Design}}} & \multicolumn{4}{c||}{\textbf{Manual Verilog + synthesis}} & \multicolumn{5}{c}{\textbf{Lorecast}} \\ \cline{2-10} 
\multicolumn{1}{c||}{} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Verilog\\ coding\end{tabular}} & \multicolumn{1}{c|}{Systhesis} & \multicolumn{1}{c|}{Layout} & Total & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Prompt\\ writing\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}LLM code\\ generation\end{tabular}} & \multicolumn{1}{c|}{Inference} & \multicolumn{1}{c|}{Total} & Speedup \\ \hline
\hline
right\_shifter & \multicolumn{1}{c|}{1489} & 215 & \multicolumn{1}{c|}{37} & 1741 & \multicolumn{1}{c|}{270} & 17 & \multicolumn{1}{c|}{0.0017} & \multicolumn{1}{c|}{287} & 6X \\
signal\_generator & \multicolumn{1}{c|}{1990} & 220 & \multicolumn{1}{c|}{38} & 2248 & \multicolumn{1}{c|}{439} & 130 & \multicolumn{1}{c|}{0.0164} & \multicolumn{1}{c|}{569} & 4X \\
accu & \multicolumn{1}{c|}{1129} & 223 & \multicolumn{1}{c|}{55} & 1407 & \multicolumn{1}{c|}{250} & 50 & \multicolumn{1}{c|}{0.0230} & \multicolumn{1}{c|}{300} & 4.7X \\
multiply & \multicolumn{1}{c|}{1780} & 217 & \multicolumn{1}{c|}{40} & 2037 & \multicolumn{1}{c|}{287} & 28 & \multicolumn{1}{c|}{0.0243} & \multicolumn{1}{c|}{315} & 6.5X \\
asyn\_fifo & \multicolumn{1}{c|}{5320} & 225 & \multicolumn{1}{c|}{41} & 5586 & \multicolumn{1}{c|}{1030} & 181 & \multicolumn{1}{c|}{0.0259} & \multicolumn{1}{c|}{1211} & 4.6X \\
matmul22 & \multicolumn{1}{c|}{2459} & 224 & \multicolumn{1}{c|}{41} & 2724 & \multicolumn{1}{c|}{490} & 27 & \multicolumn{1}{c|}{0.0285} & \multicolumn{1}{c|}{517} & 5.3X \\
pe\_32bit & \multicolumn{1}{c|}{1650} & 231 & \multicolumn{1}{c|}{52} & 1933 & \multicolumn{1}{c|}{469} & 12 & \multicolumn{1}{c|}{0.0292} & \multicolumn{1}{c|}{481} & 4X \\
huffmandecode & \multicolumn{1}{c|}{2200} & 270 & \multicolumn{1}{c|}{56} & 2526 & \multicolumn{1}{c|}{550} & 31 & \multicolumn{1}{c|}{0.0089} & \multicolumn{1}{c|}{581} & 4.3X \\
izigzag & \multicolumn{1}{c|}{1819} & 265 & \multicolumn{1}{c|}{49} & 2133 & \multicolumn{1}{c|}{48} & 29 & \multicolumn{1}{c|}{0.0132} & \multicolumn{1}{c|}{77} & 27X \\
pe\_64bit & \multicolumn{1}{c|}{1588} & 252 & \multicolumn{1}{c|}{69} & 1909 & \multicolumn{1}{c|}{512} & 12 & \multicolumn{1}{c|}{0.0130} & \multicolumn{1}{c|}{524} & 3.6X \\ \hline
\hline
Average & \multicolumn{1}{c|}{2142} & 234 & \multicolumn{1}{c|}{48} & 2424 & \multicolumn{1}{c|}{435} & 52 & \multicolumn{1}{c|}{0.01841} & \multicolumn{1}{c|}{487} & 5X \\ \hline

\multicolumn{10}{l}{$^{\mathrm{*}}$The time unit is $s$. }
\end{tabular}%
}
  \label{tab:speedtable}%
\end{table}



\noindent
{\bf Direct LLM-based forecasting without Verilog generation.} One may ask: why not let an LLM to directly forecast performance and power without generating Verilog code. Experiment is done to verify this concept and the results from 5 different LLMs are shown in Table~\ref{tab:LLMreasonning}. The Llama 3-8B model has been fine tuned with the training dataset completely separated from the testcases instead of direct use. 
One can see that their errors are much greater than Lorecast.
For design ``{\em right\_shift}", Gemini 1.5 Pro could not even produce legal results. The results here confirm that direct forecasting using LLMs without Verilog generation is a significantly more difficult path than Lorecast. 

%{\bf Analysis of LLMs' Reasoning Capabilities for Performance and Power Based on Natural Language Descriptions.}We also explored the capability of LLMs to reason about performance and power from natural language descriptions of designs.We selected several popular advanced LLMs to infer the performance and power of test designs used in Lorecast. The results, shown in Table \ref{tab:LLMreasonning}, indicate that the capabilities of these LLMs for this task are not satisfactory. Currently, it remains challenging to directly use LLMs to reason about the performance of designs. \textbf{TO BE CONTINUE} Additionally, we experimented with fine-tuning lightweight models using the designs we collected.

% \begin{table}[!htb]
% \caption{Results of LLM-based forecasting without generating Verilog code.}
% \resizebox{\linewidth}{!}{%
% \begin{tabular}{l||cc|cc|cc|cc}
% \hline
% \multicolumn{1}{c||}{\multirow{2}{*}{\textbf{Design}}} & \multicolumn{2}{c|}{\textbf{GPT4}} & \multicolumn{2}{c|}{\textbf{GPT4o}} & \multicolumn{2}{c|}{\textbf{Llama3.1 405B}} & \multicolumn{2}{c}{\textbf{Gemini 1.5 Pro}} \\
% \multicolumn{1}{c||}{} & Power{*} & TNS{*} & Power & TNS & Power & TNS & Power & TNS \\ \hline
% \hline
% right\_shifter & 20 & 0.005 & 5.4 & 0.02 & 20 & 0.1 & \ding{55} & \ding{55} \\
% signal\_generator & 10 & 0 & 6.8 & 0.015 & 33 & 0.02 & 5 & 0.5 \\
% accu & 20 & 0.04 & 7.5 & 0.012 & 49 & 0.03 & 10 & 1 \\
% multiply & 20 & 0.025 & 8.2 & 0.018 & 76 & 0.05 & 20 & 2 \\
% asyn\_fifo & 30 & 0.005 & 9.3 & 0.02 & 128 & 0.07 & 30 & 3 \\
% matmul22 & 40 & 0.035 & 10.1 & 0.025 & 262 & 0.1 & 50 & 5 \\
% pe\_32bit & 30 & 0.035 & 12.7 & 0.03 & 189 & 0.08 & 60 & 4 \\
% huffmandecode & 30 & 0.025 & 14.3 & 0.035 & 336 & 0.12 & 40 & 6 \\
% izigzag & 30 & 0.025 & 13.5 & 0.028 & 231 & 0.06 & 25 & 3 \\
% pe\_64bit & 40 & 0.065 & 18.5 & 0.04 & 472 & 0.15 & 100 & 8 \\ \hline
% \hline
% Average & 27 & 0.026 & 10.6 & 0.0243 & 179 & 0.078 & 38 & 3.61 \\
% APME & (99\%) & (93\%) & (99\%) & (94\%) & (99\%) & (91\%) & (99\%) & (749\%) \\ \hline
% \multicolumn{7}{l}{$^{\mathrm{*}}$Power unit is $\mu W$ and TNS  unit is $ns$. }
% \end{tabular}%
% }
%   \label{tab:LLMreasonning}%
% \end{table}

\begin{table}[!htb]
%\vspace{-5pt}
\caption{Results of LLM-based forecasting without generating Verilog code.}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l||cc|cc|cc|cc|cc}
\hline
\multicolumn{1}{c||}{\multirow{2}{*}{\textbf{Design}}} & \multicolumn{2}{c|}{\textbf{GPT4}} & \multicolumn{2}{c|}{\textbf{GPT4o}} & \multicolumn{2}{c|}{\textbf{Llama3.1 405B}} & \multicolumn{2}{c|}{\textbf{Gemini 1.5 Pro}} & \multicolumn{2}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Fine-tuned\\ Llama 3 8B\end{tabular}}} \\
\multicolumn{1}{c||}{} & Power{*} & TNS{*} & Power & TNS & Power & TNS & Power & TNS & Power & TNS \\ \hline
\hline
right\_shifter & 20 & 0.005 & 5.4 & 0.02 & 20 & 0.1 & \ding{55} & \ding{55} & 113 & 0 \\
signal\_generator & 10 & 0 & 6.8 & 0.015 & 33 & 0.02 & 5 & 0.5 & 103 & 0 \\
accu & 20 & 0.04 & 7.5 & 0.012 & 49 & 0.03 & 10 & 1 & 113 & 0.6 \\
multiply & 20 & 0.025 & 8.2 & 0.018 & 76 & 0.05 & 20 & 2 & 105 & 4.5 \\
asyn\_fifo & 30 & 0.005 & 9.3 & 0.02 & 128 & 0.07 & 30 & 3 & 120 & 6.8 \\
matmul22 & 40 & 0.035 & 10.1 & 0.025 & 262 & 0.1 & 50 & 5 & 240 & 3.4 \\
pe\_32bit & 30 & 0.035 & 12.7 & 0.03 & 189 & 0.08 & 60 & 4 & 180 & 2.9 \\
huffmandecode & 30 & 0.025 & 14.3 & 0.035 & 336 & 0.12 & 40 & 6 & 240 & 4.1 \\
izigzag & 30 & 0.025 & 13.5 & 0.028 & 231 & 0.06 & 25 & 3 & 220 & 3.5 \\
pe\_64bit & 40 & 0.065 & 18.5 & 0.04 & 472 & 0.15 & 100 & 8 & 320 & 4.8 \\ \hline
\hline
Average & 27 & 0.026 & 10.6 & 0.0243 & 179 & 0.078 & 38 & 3.61 & 175 & 3.06 \\
APME & (99\%) & (93\%) & (99\%) & (94\%) & (99\%) & (91\%) & (99\%) & (749\%) & (99\%) & (620\%) \\ \hline
\multicolumn{7}{l}{$^{\mathrm{*}}$Power unit is $\mu W$ and TNS  unit is $ns$. }
\end{tabular}%
}
  \label{tab:LLMreasonning}%
\end{table}


%\vspace{-5pt}
\subsection{Ablation Studies}


\iffalse
\noindent
{\bf Effect of Different LLM.}
Lorecast prediction method extracts features from the AST; however, if syntax-correct Verilog code cannot be generated, our prediction model cannot obtain valid input. Moreover, while Lorecast can make predictions on functionally incorrect Verilog code, LLMs with higher functional correctness tend to produce code that is closer to correct code even if it is not fully functionally accurate, which helps improve prediction accuracy.
Therefore, we prioritize models with high syntax and functional correctness. 
Previous related work \cite{lu2024RTLLM,liu2023VerilogEval} used $pass@k$ as a metric for evaluating correctness, whose entries are defined by 

\begin{equation}
\label{eq:pass@k}
pass@k\,\,=\underset{Problems}{\mathbb{E}}\left[ 1-\left( \begin{array}{c}
	n-c\\
	k\\
\end{array} \right) /\left( \begin{array}{c}
	n\\
	k\\
\end{array} \right) \right] 
\end{equation}

where $n$ is the total number of trials for each instruction, and $c$ represents the number of correct code generations for a task. A task is considered solved if any of the $k$ trials produces code that passes the tests. In the works\cite{lu2024RTLLM,liu2023VerilogEval}, it is also observed that as $k$ increases, the $pass@k$  improves. However, this metric is less effective in providing actionable guidance for the design of the Lorecast framework.
We aim to evaluate the success rate of generations that pass a certain number of times, rather than just once, within a given number of attempts. Therefore, we propose a simpler and more intuitive method for evaluating correctness, referred to as $success@k$, which consists of two straightforward statistical equations.
\begin{equation}
\label{eq:m_success}
m_{success}=\sum\nolimits_{i=1}^m{I(X_i)}\,\, \begin{cases}
	\footnotesize I(X_i)=1 ,  X_i\geqslant \,\,k\times n\\
	\footnotesize I(X_i)=0 ,  X_i<\,\,k\times n\\
\end{cases}
\end{equation}
\begin{equation}
\label{eq:success@k1}
success@k=\frac{m_{success}}{m}
\end{equation}
\begin{equation}
\label{eq:success_k}
success@k = \frac{1}{m} \times \sum\nolimits_{i=1}^m{I(X_i)} \quad
\begin{cases}
    \footnotesize I(X_i) = 1 , & X_i \geqslant k \times n \\
    \footnotesize I(X_i) = 0 , & X_i < k \times n \\
\end{cases}
\end{equation}


Here, $m$ represents the total number of tasks, $m_{success}$ is the number of successful tasks, $n$ is the number of attempts per task, and $k$ is the success ratio threshold for $n$ attempts. For example,  $k=0.6$ means that at least three out of five attempts must be correct for the task to be considered successful, while  $k=1$ requires every attempt to generate correct code for success. Since our code utilizes the IPREF framework to fix errors, we set $k$ to 1 and $n$ to 3.
We evaluated several mainstream advanced models in Lorecast framework, and as shown in Figure \ref{fig:effort_llm}, GPT-4 and Gemini 1.5 Pro demonstrated the highest correctness within our framework.

\fi 

\iffalse
\begin{figure}[H] 
    \centering
    \includegraphics[width=0.7\linewidth]{figure/effort_llm6.png}
    \caption{Correctness Effect of Different LLM}
    \label{fig:effort_llm}
\end{figure}
\fi

\noindent
{\bf Comparisons of LLMs and the impact of IPREF.}
The syntax/function correct rate results for 7 LLMs with and without IPREF are depicted in Figure~\ref{fig:Self-correction}. Here, syntax/functional correctness is asserted for a design if the results from all three attempts are correct. We can obtain the following observations.
\begin{itemize}[nosep]
    \item Syntax correct rate is always significantly higher than functional correct rate. This confirms that syntax correctness is a much more achievable goal than functional correctness for LLM-generated Verilog code.
    \item IPREF can always improve syntax correct rate, which is fundamental for Lorecast.
    \item 100\% syntax correct rate is achieved by GPT4, GPT4o and Gemini 1.5 Pro. This is why the Lorecast study is based on these three LLMs.
\end{itemize}

%To evaluate the improvement brought by IPREF in the Lorecast framework, we measured the correctness of different LLMs with and without IPREF. Since IPREF can iteratively fix code errors, we use $k=1$, $n=3$ for $success@1$ to evaluate correctness. For direct code generation without IPREF, we use $k=0.6$, $n=5$ for $success@0.6$ to evaluate correctness. As shown in Figure \ref{fig:Self-correction},the results indicate that IPREF significantly improves both the syntax and functional correctness for all LLMs. With IPREF, GPT-4, GPT-4o, and Gemini 1.5 Pro all achieve 100\% syntax correctness. We also observe that the lower the initial correctness of an LLM, the greater the improvement gained from IPREF.
%\vspace{-5pt}
\begin{figure}[htb] 
    \centering
    \includegraphics[width=0.8\linewidth]{figure/effort_selfcorrect10.png}
    \caption{Syntax/functional correctness of LLMs with and without IPREF.}
    \label{fig:Self-correction}
\end{figure}



\noindent
{\bf Impact of different LLMs on forecast errors.} 
Sometimes, an LLM cannot produce syntax correct Verilog code for a design. To account for this situation in evaluation the forecasting accuracy, we define 
conditional accuracy as
$(1-\mathcal{E})\cdot \rho$
where $\mathcal{E}$ is the APME defined in 
Equation~\eqref{eq:APME} and $\rho$ is the syntax correct rate. Figure~\ref{fig:correctness2predict} plots the conditional accuracy and accuracy,
which is $1-\mathcal{E}$ for syntax correct designs. 
One can see that there is a correlation between functional correctness and the accuracy although functional errors can be tolerated. 
For Lorecast@GPT4, power and performance $\mathcal{E}$ are 1\% and 2\% for functionally correct code, rising to 4\% and 7\% for functionally incorrect one.

\iffalse
Our experiments reveal that syntax correctness affects the success of predictions. When there are syntax errors in Verilog code, it is often difficult to extract effective features for prediction. Therefore, we conducted predictions and calculated accuracy only for Verilog code that passed the syntax check. Additionally, functional correctness also impacts the prediction outcomes; when there are functional errors, the prediction results tend to have larger discrepancies. To reflect the overall accuracy of the framework, we can use the Conditional Accuracy metric, $A _{conditional}$ defined to be
\begin{equation}
\label{eq:accuracy}
\mathcal{A} \,\,=\,\,1 -\,\,\mathcal{E} 
\end{equation} 
\begin{equation}
\label{eq:norm_accuracy}
\mathcal{A} _{conditional}\,=\,\,\mathcal{A} \times \,\,\mathcal{P} _{pred\,\,feasible}
\end{equation} 
In other words, selecting an LLM with high syntax and functional correctness for integration into the framework can improve prediction accuracy.Experimental results show that GPT-4, GPT-4o, and Gemini 1.5 Pro achieve the highest conditional accuracy, with GPT-4 having a slight advantage over the other two.
\fi

%\vspace*{-2mm}
\begin{figure}[!htb] 
\centering 
\includegraphics[width=0.9\linewidth]{figure/LLM2ACC13.png}
\caption{Comparison of LLMs on forecasting accuracy.}
%\vspace{-10pt}
\label{fig:correctness2predict}
\end{figure}




\iffalse

{\bf Effect of Different Syntax Error Feedback.}
In the Lorecast framework, the syntax checker plays a critical decision-making role, not only verifying syntax correctness but also generating error messages to help correct code. Therefore, we evaluated the impact of using the popular open-source tool Icarus Verilog versus the commercial tool Synopsys VCS as the syntax checker. Differences in error messages between the two tools are shown in Figure \ref{fig:Feedback}, and experimental results are presented in Figure \ref{fig:different_feedback}. It can be observed that their performance is very similar, though Icarus Verilog provides slightly better correction results. One possible reason is that Icarus Verilog’s error messages include the type of error encountered. Although Synopsys VCS displays the content of the error line, which Icarus Verilog does not, the content of the error line is already included in the Correction Prompt. Thus, compared to Synopsys VCS, using Icarus Verilog for syntax checking in the Lorecast framework provides the error type for the specific line, which may further assist the LLM in correcting errors.

\fi



\iffalse
{\bf Effect of Maximum Iteration Count on IPREF.}
We also evaluated the impact of the number of IPREF iterations. As shown in Figure \ref{fig:different_iteration}, more erroneous code is corrected during the early iterations, leading to a significant improvement in syntax correctness. However, due to the limitations of the LLM's capabilities, some errors cannot be fixed even with additional iterations. For some LLMs, syntax correctness plateaus after a certain number of iterations, while more capable models often achieve 100\% correctness within a limited number of iterations.
\fi

\iffalse
\noindent
{\bf Effect of Regulated Prompting.}
Previous works have used templates to describe problems, and we also evaluated the impact of these templates on the initial code generation in the Lorecast framework, using $k=0.6$, $n=5$ for $success@0.6$ to assess correctness. As shown in Table \ref{tab:description_templates}, regulated prompting, which is derived from the self-planning technique in \cite{lu2024RTLLM}, outperforms the technique in \cite{liu2023VerilogEval} in terms of code generation performance.
\fi

\noindent{\bf Effect of different template styles in regulated prompting.}
Although template-based regulated prompting has been proposed in previous works~\cite{liu2023VerilogEval}, different template styles also matter. In Table~\ref{tab:description_templates}, we show that our template style can improve the syntax correct rate by $5\% -32\%$. Please note IPREF is not performed in these cases. 


\begin{table}[!hbt]
\centering
\caption{Syntax correct rate from different template styles in regulated prompting.}
\resizebox{0.65\linewidth}{!}{%
\begin{tabular}{|l|ccc|}
\hline
\multirow{2}{*}{Template} & \multicolumn{3}{c|}{Syntax correct rate (\%)} \\
 & \multicolumn{1}{c|}{GPT3.5} & \multicolumn{1}{c|}{GPT4} & GPT4o \\ \hline\hline
Lorecast  & \multicolumn{1}{c|}{55.1} & \multicolumn{1}{c|}{86.2} & 82.8 \\ \hline
VerilogEval~\cite{liu2023VerilogEval} & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{66.7} & 50 \\ \hline
\end{tabular}%
}
  \label{tab:description_templates}%
\end{table}
%\vspace{-5pt}

\noindent
{\bf Effect of regulation in iterative feedback prompting.}
Although iterative feedback prompting was proposed in \cite{Thakur2024AutoChip}, its feedback prompting is not regulated. Figure~\ref{fig:Regulated_coirrect} shows that our regulated feedback prompting in Lorecast can improve the syntax correct rate by about 5\%.

%As illustrated in Figure \ref{fig:Regulated_coirrect}, incorporating regulated templates into the correction process enhances the effectiveness of iterative prompting for code correction, the average accuracy increased by 5\%.

%\vspace*{-3mm}
\begin{figure}[!hbt] 
    \centering
    \includegraphics[width=0.55\linewidth]{figure/regulated_feedback6.png}
    \caption{Effect of regulation in iterative feedback prompting.}
    \label{fig:Regulated_coirrect}
\end{figure}



\noindent{\bf Syntax correct rate versus max IPREF iterations.}
In Figure~\ref{fig:different_iteration}, we vary the maximum number of IPREF iterations and observe the impact on syntax correct rate. In the beginning, increasing the maximum number of iterations does help in improving the correct rate. However, the benefits diminish at around 9 iterations. This is why we set the limit of IPREF iterations to be 10.

%\vspace*{-2mm}
\begin{figure}[!htb] 
    \centering
    \includegraphics[width=0.65\linewidth]{figure/Iteration9.png}
    \caption{Syntax correct rate vs. the maximum number of IPREF iterations.}
    \label{fig:different_iteration}
\end{figure}


\noindent{\bf Effect of different syntax checking tools.}
IPREF (Section~\ref{sec:code_generation}) takes error messages from a syntax checking tool into the iterative prompting. Different syntax checking tools may produce error messages in different styles as shown in Figure~\ref{fig:Feedback}. In Figure~\ref{fig:different_feedback}, we compare the impact to syntax correct rate from IPREF with two different syntax checking tools. We can see that the impact from different tools is small. Especially for GPT4 and GPT4o, there is no difference. This shows that Lorecast allows the flexibility of using different syntax checking tools. 

%\vspace*{-1mm}
\begin{figure}[htb] 
    \centering
    \includegraphics[width=0.5\linewidth]{figure/effort_tool10.png}
    \caption{Syntax correct rates with IPREF from different syntax checkers.}
 %   \vspace{-10pt}
    \label{fig:different_feedback}
\end{figure}
