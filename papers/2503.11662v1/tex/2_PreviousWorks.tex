

\section{Related Works}
\label{sec:PreviousWorks}

To the best of our knowledge, there is no prior study on forecasting circuit performance and power from natural languages. However, there have been related works, which are briefly reviewed as follows.

\vspace*{1mm}
\noindent
{\bf Leveraging LLMs to generate HDL code.}
Previous research has explored the feasibility of using LLMs for design tasks. ChatChisel\cite{liu2024ChatChisel} leveraged LLMs alongside collaboration and RAG (Retrieval-Augmented Generation)\cite{Lewis2020RAG} techniques to enhance code generation performance, successfully producing a RISC-V CPU and demonstrating the potential of LLMs in generating complex circuits. ChatCPU\cite{Wang2024ChatCPU} was a framework combining LLMs with CPU design automation, which has been used to successfully design a CPU and complete its tape-out. BetterV\cite{Pei2024BetterV} utilized a discriminator to guide Verilog code generation. Other studies focused on using LLMs to assist in computer design. ChipGPT\cite{Chang2023ChipGPT} demonstrated that LLMs can aid users in understanding complex designs. VGV\cite{Wong2024VGV} took advantage of LLMs’ computer vision capabilities to generate Verilog code directly from circuit diagrams.

\vspace*{1mm}
\noindent
{\bf Evaluating Verilog code generation capabilities of LLMs.} Some studies focus on evaluating the code generation capabilities of LLMs, primarily in terms of syntax and functional correctness. In \cite{Chang2023ChipGPT}, the code generation capabilities of ChatGPT were compared to other LLMs.  VerilogEval\cite{liu2023VerilogEval} introduced a benchmark for evaluating the correctness of Verilog code generation, along with an automated evaluation framework. RTLLM\cite{lu2024RTLLM} proposed a benchmark and evaluated how prompt styles impact code generation accuracy, also presenting a prompting technique to improve correctness. RTL-Repo\cite{allam2024RTL-Repo} developed a large-scale benchmark for assessing Verilog code generation capabilities of LLMs, containing over 4,000 Verilog code samples. CreativEval\cite{DeLorenzo2024CreativEval} proposed a new perspective by focusing not on correctness but on fluency, flexibility, originality, and refinement.




\vspace*{1mm}
\noindent
{\bf Enhancing Verilog code generation capabilities of LLMs.} To improve the accuracy of code generation, some researchers have experimented with fine-tuning open-source and lightweight LLM models \cite{Thakur2023Benchmarking}\cite{Liu2024RTLCoder}. In \cite{Nadimi2024Multi-Expert_LLM}, researchers used a framework that integrates datasets categorized by different design complexities to fine-tune LLMs for specific tasks. Autochip \cite{Thakur2024AutoChip} proposed a framework that uses feedback from syntax-checking tools to correct syntax errors in LLM-generated code. 
OriGen \cite{Cui2024OriGen} used feedback-based correction to collect datasets for augmentation and improve code generation.
Both RTLFixer \cite{Tsai2024RTLFixer} and AutoVCoder \cite{Gao2024AutoVCoder} utilized RAG to enhance syntax error correction in code. EDA Corpus \cite{Wu2024EDACorpus} and MG-Verilog \cite{Zhang2024MG-Verilog} proposed datasets tailored to various application scenarios to improve Verilog code generation capabilities in LLMs. Additionally, other researchers have proposed frameworks for generating datasets specifically for fine-tuning LLMs \cite{Chang2024Data_all_you_need}. VerilogReader\cite{Ma2024VerilogReader} proposed a framework to expand the comprehension scope of LLMs for improved generation of Verilog test code.

% \subsection{Earlier work on macro placement}
% Macro placement with sequential-pair \cite{Murata1996VLSIMP}

\vspace*{1mm}
\noindent
{\bf PPA prediction from HDL code.} Some studies focused on obtaining design evaluations during the early design stages. In \cite{Sengupta2022Prediction}, a machine learning method was proposed to perform Verilog-based evaluations without requiring synthesis. Some researchers concentrated on predictions specifically based on synthesis results \cite{Xu2022systhesisPrediction}. MasterRTL \cite{Fang2023MasterRTL} introduced an approach for design evaluation using a simple operator graph to describe relationships between logic gates. In \cite{Moravej2024LUTGraph}, researchers leveraged the Look-Up Table (LUT) Graph from Verilog to predict. Additionally, some researchers employed Graph Neural Networks (GNNs) to estimate the design’s maximum arrival time by predicting component delays and slopes \cite{Lopera2023GNNPrediction}.






%{\bf Summary.} No prior research has explored the use of LLMs to enable PPA estimation for design planning from natural language descriptions.