\thispagestyle{empty}
\section{Introduction}
\label{sec:Introduction}


%
Chip design planning is the process of evaluating and optimizing key metrics such as performance and power during the early stages of hardware development. In this phase, predicting the performance and power of various design options is a critical yet challenging task. Engineers rely on these performance metrics to make informed decisions about architectural choices, resource allocation, and overall design optimization. 
For instance, designers might pose questions such as, ``If the unfolding factor for an IIR filter is adjusted from $x$ to $y$, will the block-level power constraint be violated?" or ``Will replacing a carry-ripple adder with a carry-lookahead adder create significant challenges for timing closure?"

Although system-level models and transaction level models~\cite{black2004systemc} are useful in planning, they are loosely timed or approximately timed and thus incapable of providing sufficiently accurate estimates. Architecture-level models, such as McPAT~\cite{li2009mcpat}, are mostly restricted to microprocessor designs and can have very large errors. 
For example, the power estimate error can be as large as $200\%$~\cite{xi2015quantifying}.
Errors at early design stages can propagate throughout the design process, resulting in costly revisions, delays, or suboptimal designs. In competitive markets such as AI accelerators, IoT, and high-performance computing, time-to-market is crucial, and slow iterations can hinder innovation.


Alternatively, designers can write HDL code, followed by synthesis and layout, which demand significant time and labor investments. The accuracy of architecture-level models can also be improved by machine learning-based calibration~\cite{zhai2021mcpat}. However, the calibration still requires expensive RTL implementation and synthesis. 
While some attempts have been made to predict performance and power using designer-written HDL code, creating the HDL code itself is a time-consuming and challenging process. When a designer has an idea, it often takes tens of times longer to translate that idea into HDL code.
This creates a bottleneck, especially in the early design stages, where rapid iterations are needed to efficiently explore the design space. The challenge lies in providing a quick and reliable way to estimate performance and power based on a designer's idea.

To address this problem, we propose an approach called Lorecast, which transforms a designer's natural language description of their idea directly into layout-aware performance and power estimates. This accelerates the design planning process, enabling faster and more efficient exploration of design options. Moreover, Lorecast reduces the need for system/architecture-level designers to have in-depth knowledge of HDL code. A key component of Lorecast is Large Langrage Model (LLM)-based automatic Verilog code generation. Distinguished from existing approaches, Lorecast significantly reduces the requirement for functional correctness of the generated Verilog code. Functional correctness has been a difficult challenge to practical and large-scale adoption of LLM-based Verilog code generation. However, Lorecast bypasses this challenge by using syntax-correct Verilog code generated by LLMs, which is sufficient for its purposes.


%general placer -> special purpose placer-> regularity aware placer -> datapath placer

%why partial regularity is critical, and how partial regularity applied in other regularity aware placer-ã€‹ make ILP available

%our method: dust cell clustering, ILP placer, dust cell initial place, replace flow, ntuplace3 as DP


\iffalse
\begin{figure}[!htb] 
\centering 
\includegraphics[width=0.9\linewidth]{figure/end2end6.pdf}
\caption{From Natural Language to Performance and Power Results}
\vspace{-10pt}
\label{fig:systolicArray}
\end{figure}
\fi

%Lorecast accepts English prompts as input, bypassing the need for HDL code development or synthesis, making it both fast and user-friendly. 

The contributions of this work are summarized as follows.

\vspace*{-1mm}
\begin{itemize}
 \item \textbf{Performance and power prediction from natural language.} The Lorecast framework allows designers to obtain performance and power estimates directly from English descriptions of their ideas, bypassing the need for Verilog coding. 
 \item \textbf{High forecast accuracy}. Lorecast achieves accurate estimates, with an average percentage error of only 2\% compared to the post-layout analysis of a commercial tool. Even for cases where the Verilog codes generated by the LLM are functionally incorrect, the forecast errors are 4\% and 7\% for power and total negative slack, respectively.
 \item \textbf{Faster design planning}. Lorecast accelerates the performance and power estimation process by $5\times$ compared to conventional methods that involve manually writing Verilog code, synthesis, and layout.
 \item \textbf{Improving generated code syntax correctness with an enhanced prompting technique.} We propose an iterative prompting with a regulated feedback technique that improves the syntax correctness of LLM-generated code. This approach achieves a 5\% improvement in correctness compared to directly using error messages for iteration and a 23\% improvement compared to direct code generation without iterative feedback. 
 \item \textbf{Evaluation with circuits significantly larger than existing ones.} So far, LLM-based Verilog code generation techniques are mostly restricted to small circuits. We developed circuit cases that double the sizes in terms of cell count compared to the latest publicly released testcases.  
 On these larger cases, Lorecast achieved $100\%$ syntax correctness. 
 \item {\bf Lorecast is more viable than an alternative approach.} Experimental results show that Lorecast is a much more promising approach than direct LLM-based (including a fine-tuned LLM) forecasting without generating Verilog code. 
\end{itemize}

%\vspace*{-3mm}

\iffalse

In this work, we investigate how to exploit the regularity of systolic array macro/PE placement. Our work is built upon RePlAce and adopts Gurobi optimizer as the ILP solver. The contributions of this work include the following.

\begin{itemize}
    \item This work propose a dust cell - macro clustering algorithm according to the connectivity between dust cells and macros. Then we will assign each dust cell to a macro and form a cluster based on each macro. And in this procedure, we will generate the cluster-level net list which will be used in the next stage.

    \item We summarize the partial regularity relationship of the neighbor macro/PE in the schematic, and formulate the ILP problem for the clustering placement. We use the partial regularity relationship of PEs as the constraints in ILP problem and set the WL in the clustering-level netlist as objective. Due to the partial regularity constraints, the non-overlap constraint will be satisfied with linear number of variables and constraints in ILP problem which make this ILP problem solvable in the reasonable runtime and obtain the competitive clustering solutions.

    \item To ease the dust cell placement, we propose the dust cell initial placement method to determine the initial placement according to the connectivity of dust cell to macros and macro/clustering center location which is obtained in the above stage.
    
\end{itemize}



The rest of the paper is organized as follows. 
Previous related works are briefly reviewed in Section~\ref{sec:PreviousWorks}. Background knowledge used in our work is presented in Section~\ref{sec:background}.
In Section~\ref{sec:formulation}, our problem formulation is introduced. Our main techniques are described in Section~\ref{sec:Methods}. The experimental results
are shown in Section~\ref{sec:Experiment}. Finally, the conclusions are provided in Section~\ref{sec:conclusions}.

\fi
