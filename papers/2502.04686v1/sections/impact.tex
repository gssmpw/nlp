Our research advances the capabilities of LLM-based agents in a purely text-based Werewolf environment. While this setting allows the agents to develop robust decision-making and deception-detection skills, it also underscores the potential for misuse if similar techniques were to be adapted to real-world scenarios involving manipulation or misinformation. To mitigate these risks, our implementation remains strictly focused on text-based simulation and does not directly transfer to broader applications without additional safeguards. At the same time, our experiment results indicate that our agent could be used to identify potential deceptive and manipulative content. We envision that any future extensions of this work will require careful consideration of ethical guidelines and responsible deployment strategies to ensure that such language agent systems serve society constructively.