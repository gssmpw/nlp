\section{RELATED WORKS}
In this section, we reviews the research status of point cloud compression and transmission from the perspective of point cloud encoding and adaptive bitrate streaming.
\subsection{Unstructured Point Cloud Encoding}
Over the past few decades, significant progress 
has been made in point cloud compression. 
However, not all point cloud compression techniques 
are suitable for LiDAR point clouds. 
LiDAR point clouds have unique characteristics, 
such as sparsity, large coverage areas, 
and uneven density, making many compression 
methods designed for 3D object point clouds less 
effective. The most common and widely used methods 
for unstructured point cloud compression are based 
on spatial subdivision trees, such as octrees. 
These methods \cite{c1}\cite{c2}\cite{c3}\cite{c4} 
first use octrees as the foundational data 
structure to structure the point clouds, 
then apply various transformations and 
encoding schemes to reduce spatial and 
informational redundancy. 
In addition to octrees, 
clustering-based and segmentation-based
 methods \cite{c6}\cite{c5} have also 
 demonstrated effectiveness in lossy geometric 
 compression. 
To better capture geometric patterns, 
neural network-based methods \cite{c7}\cite{c8} learn 
the latent spatial structure and geometric information 
within the data, achieving superior lossy and lossless 
compression. However, these methods typically 
lack real-time capabilities and computational 
efficiency. 
Despite their effectiveness in many scenarios, 
the  intrinsic physical properties of LiDAR sensors make LiDAR 
point clouds structured, 
and unstructured methods fail to 
take full advantage of this.
\subsection{Structured Point Cloud Encoding}
In structured point cloud compression, 
many works \cite{flicr} project point clouds into 2D images 
for compression. 
Houshiar et al. \cite{c14} used panoramic cylindrical 
projections to convert point clouds into 2D images 
for lossless and JPEG lossy compression. 
Some works, such as the MPEG V-PCC framework, 
establish local reference frames on point cloud 
surfaces and generate orthogonal projection images 
from multiple views \cite{c10}\cite{c11}. 
These projection images are further compressed 
using existing image or video compression techniques.
However, image or video compression methods 
like JPEG or H.255 are typically designed 
for rectangular data with values between 0 and 255, 
without invalid pixels. 
Direct application to range images can introduce 
significant quantization errors 
and noise \cite{huicheng},
 leading to a reduction in downstream 
 application accuracy.

\subsection{Adaptive Bitrate Streaming}
Common adaptive bitrate (ABR) schemes are crucial 
for video streaming \cite{survey}.They allow 
video streams to dynamically adjust video quality 
according to user network conditions, thereby 
avoiding video stuttering caused by network 
fluctuations. 
ABR methods aim to optimize Quality of Experience (QoE) 
by making optimal decisions. 
ABR methods can be broadly categorized 
into rate-based \cite{festive}, 
buffer-based \cite{bola}, hybrid \cite{mpc}, and 
RL-based \cite{rl} approaches.
Some researchers have explored ABR 
for point cloud data transmission 
\cite{c16}\cite{c17}. 
Unfortunately, these methods were designed for 
dense 3D object point clouds and cannot be directly 
applied to LiDAR point clouds.