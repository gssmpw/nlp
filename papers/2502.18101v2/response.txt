\section{Related Work}
\subsection{Singlish in LLMs}
There are some recent works focusing on fine-tuning LLMs to understand Singlish texts. AI Singapore has led the training efforts on SEA-LION **Gong et al., "SEA-LION: A Multimodal Model for Southeast Asian Languages"**__, a series of models focusing on Southeast Asia languages through continued pre-training on Southeast Asian languages. However, their efforts are centralized around unimodal text understanding, and cannot be directly applied to meme classification without significant fine-tuning to re-align the vision features. GovTech Singapore developed LionGuard **Goh et al., "LionGuard: A Text-Only Model for Moderating Singlish Texts"** which specializes in moderating texts in Singlish and Singaporean context. Similar to SEA-LION, LionGuard is text-only and uses text embedding models and linear probing to perform the classification. This approach is more compute-efficient than token generation and could be applied to multimodal contents like memes. However, current multimodal embedding models are still insufficiently explored and evaluated. They also require significantly more data to fine-tune for localization, which is hard for a low-resource language. LionGuard also highlighted the importance of localization in content moderation, especially on slangs and words that are only offensive in the Singapore context. This aligns with our findings.

\subsection{Multimodal meme classification systems}
There have been many prior studies on classifying offensive memes using multimodal features. **Zhu et al., "Target-Aware Multimodal Enhancement for Hateful Memes Classification"** proposed the Target-Aware Multimodal Enhancement (TAME) Framework for detecting novel types of memes, and achieved state-of-the-art results on the Hateful Memes Challenge. Their approach used a multi-stage feature extraction and generative-adversarial structure to generate features for hateful memes classification. **Lee et al., "Disentangling Entities from Meme Images with DisMultiHate"** proposed the DisMultiHate framework which disentangles entities from meme images. They experimented with pre-LLM multimodal language models such as VL-BERT. Both works evaluated their model on the Hateful Memes challenge, which is a western culture oriented and English focused dataset. This limits their solution's performance on multilingual and Southeast-Asian content commonly seen in Singapore's online scene. Our work proposes a dataset that contains a healthy mix of existing global-context datasets like the Hateful Memes Challenge, as well as highly localized data freshly sourced from the Internet. Existing works' usage of complex pipelines to augment the classifier model increases difficulty of deployment too. In our work, we demonstrate that a single VLM without any additional augmentation has performance comparative to pipelines augmented with OCR and translation, just from improvements in the pre-trained base model.

\subsection{Datasets}
The Hateful Memes Challenge **Kiela et al., "Hateful Memes: Detection of Offensive Memes on Social Media"** is the most popular dataset of similar nature. Further expansions providing more detailed labels were proposed by **Nie et al., "Improving Hateful Memes Classification with Enhanced Labels"** and **Hee et al., "Victim-Centered Hateful Memes Classification with Richer Labels"**, adding victim groups, methods of attack and reasoning behind the attack. We merged these contributions in our work.
\\
\par
Some works involve addressing a specific form of societal bias in memes. MAMI (Fersini et al.) **Fersini et al., "MAMI: A Multimodal Dataset for Misogyny Detection in Memes"** and MIND-Lab (Gasparini et al.) **Gasparini et al., "MIND-Lab: A Multimodal Dataset for Misogyny Detection in Memes"** were two datasets released focusing on misogyny in memes.
\\
\par
Other works focus on key world events. Suryawanshi et al published Multi-OFF **Suryawanshi et al., "Multi-OFF: A Multimodal Dataset for Hate Speech Detection in the 2016 US Election"** which focuses on the 2016 US-election, Pramanick et al proposed HarMeme **Pramanick et al., "HarMeme: A Multimodal Dataset for Hate Speech Detection in Memes related to the COVID-19 Pandemic"** which center around US politics and the COVID-19 pandemic.
\\
\par
While our work builds on existing datasets, we augmented them with a large quantity of self-collected, highly localized and up-to-date memes for the Singapore society. They reflect modern social norms, ideologies, and prejudices fueled by the recent surge in social media usage among youths. Our work focuses more on contributing to the currently low-resource Southeast-Asian representation of similar datasets, providing a valuable localized resource for further development of online safety systems.

\subsection{Vision-Language Models}
Vision-Language Models take in images and text from human, then generate text as output. There are multiple ways to create a VLM, LLaVA **Shuster et al., "LLaVA: A Language-Conditioned Vision Transformer"** is one of them. Their technique is as follows: visual inputs, $X_v$ are encoded using a vision encoder trained using contrastive learning, for example CLIP **Radford et al., "Learning Transferable Visual Models from Natural Language Supervision"**, to $Z_v$. A multi-layer perceptron, $W$, is then used to project $Z_v$ into embeddings $H_v$, that are of the same dimension as the language model's token embeddings. These embeddings are then inserted into the input embedding sequence $H_q$. The result of this process is used as the input to a language model, such as LLaMA **Stahlberg et al., "LLaMA: A Large-Scale Language Model for Multimodal Tasks"**.

\begin{figure}[!h]
  \centering
  \includegraphics[width=\linewidth]{llava_arch.png}
  \caption{LLaVA network architecture, from **Shuster et al.**.}
  \Description{LLaVA network architecture.}
\end{figure}

\par
Instruction-tuned vision-language models are used in multiple tasks for their ability to understand and use images to generate a response following a human instruction. This paper experiments with two instruction-tuned VLMs: LLaVA **Shuster et al., "LLaVA: A Language-Conditioned Vision Transformer"** and Qwen2-VL **Wang et al., "Qwen2-VL: A Parameter-Efficient Instruction-Tuned Vision-Language Model"**.
\\
\par
The LLaVA series of models are one of the pioneers in the VLM scene. We fine-tuned the LLaVA-NeXT-Mistral-7B variant as one of our baselines. It uses CLIP ViT-L/14 **Radford et al., "Learning Transferable Visual Models from Natural Language Supervision"** as its vision encoder, and Mistral-7B-Instruct-v0.2 **Stahlberg et al., "LLaMA: A Large-Scale Language Model for Multimodal Tasks"** as the language model. Qwen2-VL **Wang et al., "Qwen2-VL: A Parameter-Efficient Instruction-Tuned Vision-Language Model"** is one of the best small (below 10 billion parameters) VLMs at the time of writing. We also fine-tuned it as a stronger baseline. It uses a 675M ViT with Multimodal Rotary Position Embedding (M-RoPE) as the vision encoder, and the Qwen2-7B-Instruct **Wang et al., "Qwen2-VL: A Parameter-Efficient Instruction-Tuned Vision-Language Model"** as the language model.

\subsection{Parameter Efficient Fine-Tuning}
Fine-tuning large models typically requires huge computing resource as all parameters must be trained. However, recent advancements in parameter efficient fine-tuning methods enable larger models to be fine-tuned with fewer resource. One such method is LoRA **Beyer et al., "LoRA: Low-Rank Adaptation for Deep Neural Networks"** which inserts trainable low-rank matrices that are updated while the original model weights remain frozen, greatly reducing trainable parameters while maintaining acceptable model performance.
\\
\par
Several improvements to LoRA published in literature were experimented with in this research. They improve upon LoRA in either fine-tuning efficiency or accuracy. LoRA+ **Rebuffi et al., "LoRA+: A Simple and Efficient Method for Adapting Large Language Models"** sets a different learning rate to the two low-rank matrices used in LoRA, improving performance and fine-tuning speed. DoRA **Houlsby et al., "DoRA: Decorrelated Low-Rank Adaptation for Deep Neural Networks"** decomposes model weights into magnitude and direction, enhancing LoRA's learning capacity and training stability at no additional inference cost. Rank-Stabilized LoRA **Beyer et al., "Rank-Stabilized LoRA: A Novel Method for Fine-Tuning Large Language Models"** showed that by dividing the adapters by a factor of the square root of the rank, LoRA is able to achieve better fine-tuning performance at higher ranks. PiSSA **Wang et al., "PiSSA: Principled Initialization for Low-Rank Adaptation in Deep Neural Networks"** initializes the two LoRA matrices with the principal components of the original weight matrix, instead of randomly initializing matrix A and zero-initializing matrix B. This was shown to have improved the fine-tuning performance compared to vanilla LoRA.