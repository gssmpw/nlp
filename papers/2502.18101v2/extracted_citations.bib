@inproceedings{HatReD,
  title     = {Decoding the Underlying Meaning of Multimodal Hateful Memes},
  author    = {Hee, Ming Shan and Chong, Wen-Haw and Lee, Roy Ka-Wei},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {5995--6003},
  year      = {2023},
  month     = {8},
  note      = {AI for Good},
  doi       = {10.24963/ijcai.2023/665},
  url       = {https://doi.org/10.24963/ijcai.2023/665},
}

@article{MIND,
   title={Benchmark dataset of memes with text transcriptions for automatic detection of multi-modal misogynistic content},
   volume={44},
   ISSN={2352-3409},
   url={http://dx.doi.org/10.1016/j.dib.2022.108526},
   DOI={10.1016/j.dib.2022.108526},
   journal={Data in Brief},
   publisher={Elsevier BV},
   author={Gasparini, Francesca and Rizzi, Giulia and Saibene, Aurora and Fersini, Elisabetta},
   year={2022},
   month=oct, pages={108526} }

@inproceedings{MOMENTA,
    title = "{MOMENTA}: A Multimodal Framework for Detecting Harmful Memes and Their Targets",
    author = "Pramanick, Shraman  and
      Sharma, Shivam  and
      Dimitrov, Dimitar  and
      Akhtar, Md. Shad  and
      Nakov, Preslav  and
      Chakraborty, Tanmoy",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.379",
    doi = "10.18653/v1/2021.findings-emnlp.379",
    pages = "4439--4455",
    abstract = "Internet memes have become powerful means to transmit political, psychological, and socio-cultural ideas. Although memes are typically humorous, recent days have witnessed an escalation of harmful memes used for trolling, cyberbullying, and abuse. Detecting such memes is challenging as they can be highly satirical and cryptic. Moreover, while previous work has focused on specific aspects of memes such as hate speech and propaganda, there has been little work on harm in general. Here, we aim to bridge this gap. In particular, we focus on two tasks: (i)detecting harmful memes, and (ii) identifying the social entities they target. We further extend the recently released HarMeme dataset, which covered COVID-19, with additional memes and a new topic: US politics. To solve these tasks, we propose MOMENTA (MultimOdal framework for detecting harmful MemEs aNd Their tArgets), a novel multimodal deep neural network that uses global and local perspectives to detect harmful memes. MOMENTA systematically analyzes the local and the global perspective of the input meme (in both modalities) and relates it to the background context. MOMENTA is interpretable and generalizable, and our experiments show that it outperforms several strong rivaling approaches.",
}

@inproceedings{MultiOFF,
    title = "Multimodal Meme Dataset ({M}ulti{OFF}) for Identifying Offensive Content in Image and Text",
    author = "Suryawanshi, Shardul  and
      Chakravarthi, Bharathi Raja  and
      Arcan, Mihael  and
      Buitelaar, Paul",
    editor = "Kumar, Ritesh  and
      Ojha, Atul Kr.  and
      Lahiri, Bornini  and
      Zampieri, Marcos  and
      Malmasi, Shervin  and
      Murdock, Vanessa  and
      Kadar, Daniel",
    booktitle = "Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/2020.trac-1.6/",
    pages = "32--41",
    language = "eng",
    ISBN = "979-10-95546-56-6",
    abstract = "A meme is a form of media that spreads an idea or emotion across the internet. As posting meme has become a new form of communication of the web, due to the multimodal nature of memes, postings of hateful memes or related events like trolling, cyberbullying are increasing day by day. Hate speech, offensive content and aggression content detection have been extensively explored in a single modality such as text or image. However, combining two modalities to detect offensive content is still a developing area. Memes make it even more challenging since they express humour and sarcasm in an implicit way, because of which the meme may not be offensive if we only consider the text or the image. Therefore, it is necessary to combine both modalities to identify whether a given meme is offensive or not. Since there was no publicly available dataset for multimodal offensive meme content detection, we leveraged the memes related to the 2016 U.S. presidential election and created the MultiOFF multimodal meme dataset for offensive content detection dataset. We subsequently developed a classifier for this task using the MultiOFF dataset. We use an early fusion technique to combine the image and text modality and compare it with a text- and an image-only baseline to investigate its effectiveness. Our results show improvements in terms of Precision, Recall, and F-Score. The code and dataset for this paper is published in \textit{ \url{https://github.com/bharathichezhiyan/Multimodal-Meme-Classification-Identifying-Offensive-Content-in-Image-and-Text} }"
}

@misc{clip,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@inproceedings{disentangling_hate_in_online_memes,
author = {Lee, Roy Ka-Wei and Cao, Rui and Fan, Ziqing and Jiang, Jing and Chong, Wen-Haw},
title = {Disentangling Hate in Online Memes},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475625},
doi = {10.1145/3474085.3475625},
abstract = {Hateful and offensive content detection has been extensively explored in a single modality such as text. However, such toxic information could also be communicated via multimodal content such as online memes. Therefore, detecting multimodal hateful content has recently garnered much attention in academic and industry research communities. This paper aims to contribute to this emerging research topic by proposing DisMultiHate, which is a novel framework that performed the classification of multimodal hateful content. Specifically, DisMultiHate is designed to disentangle target entities in multimodal memes to improve the hateful content classification and explainability. We conduct extensive experiments on two publicly available hateful and offensive memes datasets. Our experiment results show that DisMultiHate is able to outperform state-of-the-art unimodal and multimodal baselines in the hateful meme classification task. Empirical case studies were also conducted to demonstrate DisMultiHate's ability to disentangle target entities in memes and ultimately showcase DisMultiHate's explainability of the multimodal hateful content classification task.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {5138–5147},
numpages = {10},
keywords = {social media mining, multimodal, hateful memes, hate speech},
location = {Virtual Event, China},
series = {MM '21}
}

@misc{dora,
      title={DoRA: Weight-Decomposed Low-Rank Adaptation}, 
      author={Shih-Yang Liu and Chien-Yi Wang and Hongxu Yin and Pavlo Molchanov and Yu-Chiang Frank Wang and Kwang-Ting Cheng and Min-Hung Chen},
      year={2024},
      eprint={2402.09353},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.09353}, 
}

@inproceedings{fersini-etal-2022-semeval,
    title = "{S}em{E}val-2022 Task 5: Multimedia Automatic Misogyny Identification",
    author = "Fersini, Elisabetta  and
      Gasparini, Francesca  and
      Rizzi, Giulia  and
      Saibene, Aurora  and
      Chulvi, Berta  and
      Rosso, Paolo  and
      Lees, Alyssa  and
      Sorensen, Jeffrey",
    editor = "Emerson, Guy  and
      Schluter, Natalie  and
      Stanovsky, Gabriel  and
      Kumar, Ritesh  and
      Palmer, Alexis  and
      Schneider, Nathan  and
      Singh, Siddharth  and
      Ratan, Shyam",
    booktitle = "Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.semeval-1.74",
    doi = "10.18653/v1/2022.semeval-1.74",
    pages = "533--549",
    abstract = "The paper describes the SemEval-2022 Task 5: Multimedia Automatic Misogyny Identification (MAMI),which explores the detection of misogynous memes on the web by taking advantage of available texts and images. The task has been organised in two related sub-tasks: the first one is focused on recognising whether a meme is misogynous or not (Sub-task A), while the second one is devoted to recognising types of misogyny (Sub-task B). MAMI has been one of the most popular tasks at SemEval-2022 with more than 400 participants, 65 teams involved in Sub-task A and 41 in Sub-task B from 13 countries. The MAMI challenge received 4214 submitted runs (of which 166 uploaded on the leader-board), denoting an enthusiastic participation for the proposed problem. The collection and annotation is described for the task dataset. The paper provides an overview of the systems proposed for the challenge, reports the results achieved in both sub-tasks and outlines a description of the main errors for a comprehension of the systems capabilities and for detailing future research perspectives.",
}

@misc{hatefulmemes_finegrained,
      title={WOAH Shared Task Fine Grained Hateful Memes Classification}, 
      author={Shaoliang Nie and Aida Davani and Lambert Mathias and Douwe Kiela and Zeerak Waseem and Bertie Vidgen and Vinodkumar Prabhakaran},
      url={https://github.com/facebookresearch/fine_grained_hateful_memes},
      year={2021},
}

@misc{hu2021lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685},
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825},
}

@inproceedings{kiela2021hateful,
 author = {Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2611--2624},
 publisher = {Curran Associates, Inc.},
 title = {The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf},
 volume = {33},
 year = {2020}
}

@misc{lionguard,
      title={LionGuard: Building a Contextualized Moderation Classifier to Tackle Localized Unsafe Content}, 
      author={Jessica Foo and Shaun Khoo},
      year={2024},
      eprint={2407.10995},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10995}, 
}

@inproceedings{liu2023llava,
 author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {34892--34916},
 publisher = {Curran Associates, Inc.},
 title = {Visual Instruction Tuning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/6dcf277ea32ce3288914faf369fe6de0-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@misc{lora_plus,
      title={LoRA+: Efficient Low Rank Adaptation of Large Models}, 
      author={Soufiane Hayou and Nikhil Ghosh and Bin Yu},
      year={2024},
      eprint={2402.12354},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12354}, 
}

@inproceedings{multimodal_zeroshot_hateful_memes_detection,
author = {Zhu, Jiawen and Lee, Roy Ka-Wei and Chong, Wen Haw},
title = {Multimodal Zero-Shot Hateful Meme Detection},
year = {2022},
isbn = {9781450391917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501247.3531557},
doi = {10.1145/3501247.3531557},
abstract = {Facebook has recently launched the hateful meme detection challenge, which garnered much attention in academic and industry research communities. Researchers have proposed multimodal deep learning classification methods to perform hateful meme detection. While the proposed methods have yielded promising results, these classification methods are mostly supervised and heavily rely on labeled data that are not always available in the real-world setting. Therefore, this paper explores and aims to perform hateful meme detection in a zero-shot setting. Working towards this goal, we propose Target-Aware Multimodal Enhancement (TAME), which is a novel deep generative framework that can improve existing hateful meme classification models’ performance in detecting unseen types of hateful memes. We conduct extensive experiments on the Facebook hateful meme dataset, and the results show that TAME can significantly improve the state-of-the-art hateful meme classification methods’ performance in seen and unseen settings.},
booktitle = {Proceedings of the 14th ACM Web Science Conference 2022},
pages = {382–389},
numpages = {8},
keywords = {hateful memes, multimodal, social media mining},
location = {Barcelona, Spain},
series = {WebSci '22}
}

@misc{pissa,
      title={PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models}, 
      author={Fanxu Meng and Zhaohui Wang and Muhan Zhang},
      year={2024},
      eprint={2404.02948},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.02948}, 
}

@misc{qwen2lm,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@misc{qwen2vl,
      title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution}, 
      author={Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={2409.12191},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.12191}, 
}

@misc{rslora,
      title={A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA}, 
      author={Damjan Kalajdzievski},
      year={2023},
      eprint={2312.03732},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.03732}, 
}

@misc{sea_lion_2024,
  title={SEA-LION (Southeast Asian Languages In One Network): A Family of Large Language Models for Southeast Asia},
  author={AISingapore},
  year={2024},
  howpublished={\url{https://github.com/aisingapore/sealion}}
}

@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971},
}

