\section{Related Work}
\subsection{Singlish in LLMs}
There are some recent works focusing on fine-tuning LLMs to understand Singlish texts. AI Singapore has led the training efforts on SEA-LION ____, a series of models focusing on Southeast Asia languages through continued pre-training on Southeast Asian languages. However, their efforts are centralized around unimodal text understanding, and cannot be directly applied to meme classification without significant fine-tuning to re-align the vision features. GovTech Singapore developed LionGuard ____ which specializes in moderating texts in Singlish and Singaporean context. Similar to SEA-LION, LionGuard is text-only and uses text embedding models and linear probing to perform the classification. This approach is more compute-efficient than token generation and could be applied to multimodal contents like memes. However, current multimodal embedding models are still insufficiently explored and evaluated. They also require significantly more data to fine-tune for localization, which is hard for a low-resource language. LionGuard also highlighted the importance of localization in content moderation, especially on slangs and words that are only offensive in the Singapore context. This aligns with our findings.

\subsection{Multimodal meme classification systems}
There have been many prior studies on classifying offensive memes using multimodal features. Zhu et. al____ proposed the Target-Aware Multimodal Enhancement (TAME) Framework for detecting novel types of memes, and achieved state-of-the-art results on the Hateful Memes Challenge. Their approach used a multi-stage feature extraction and generative-adversarial structure to generate features for hateful memes classification. Lee et. al____ proposed the DisMultiHate framework which disentangles entities from meme images. They experimented with pre-LLM multimodal language models such as VL-BERT. Both works evaluated their model on the Hateful Memes challenge, which is a western culture oriented and English focused dataset. This limits their solution's performance on multilingual and Southeast-Asian content commonly seen in Singapore's online scene. Our work proposes a dataset that contains a healthy mix of existing global-context datasets like the Hateful Memes Challenge, as well as highly localized data freshly sourced from the Internet. Existing works' usage of complex pipelines to augment the classifier model increases difficulty of deployment too. In our work, we demonstrate that a single VLM without any additional augmentation has performance comparative to pipelines augmented with OCR and translation, just from improvements in the pre-trained base model.

\subsection{Datasets}
The Hateful Memes Challenge____ is the most popular dataset of similar nature. Further expansions providing more detailed labels were proposed by Nie et. al____ and Hee et. al____, adding victim groups, methods of attack and reasoning behind the attack. We merged these contributions in our work.
\\
\par
Some works involve addressing a specific form of societal bias in memes. MAMI (Fersini et. al)____ and MIND-Lab (Gasparini et. al)____ were two datasets released focusing on misogyny in memes.
\\
\par
Other works focus on key world events. Suryawanshi et. al published Multi-OFF____ which focuses on the 2016 US-election, Pramanick et. al proposed HarMeme____ which center around US politics and the COVID-19 pandemic.
\\
\par
While our work builds on existing datasets, we augmented them with a large quantity of self-collected, highly localized and up-to-date memes for the Singapore society. They reflect modern social norms, ideologies, and prejudices fueled by the recent surge in social media usage among youths. Our work focuses more on contributing to the currently low-resource Southeast-Asian representation of similar datasets, providing a valuable localized resource for further development of online safety systems.

\subsection{Vision-Language Models}
Vision-Language Models take in images and text from human, then generate text as output. There are multiple ways to create a VLM, LLaVA____ is one of them. Their technique is as follows: visual inputs, $X_v$ are encoded using a vision encoder trained using contrastive learning, for example CLIP____, to $Z_v$. A multi-layer perceptron, $W$, is then used to project $Z_v$ into embeddings $H_v$, that are of the same dimension as the language model's token embeddings. These embeddings are then inserted into the input embedding sequence $H_q$. The result of this process is used as the input to a language model, such as LLaMA____.

\begin{figure}[!h]
  \centering
  \includegraphics[width=\linewidth]{llava_arch.png}
  \caption{LLaVA network architecture, from ____.}
  \Description{LLaVA network architecture.}
\end{figure}

\par
Instruction-tuned vision-language models are used in multiple tasks for their ability to understand and use images to generate a response following a human instruction. This paper experiments with two instruction-tuned VLMs: LLaVA____ and Qwen2-VL____.
\\
\par
The LLaVA series of models are one of the pioneers in the VLM scene. We fine-tuned the LLaVA-NeXT-Mistral-7B variant as one of our baselines. It uses CLIP ViT-L/14____ as its vision encoder, and Mistral-7B-Instruct-v0.2____ as the language model. Qwen2-VL____ is one of the best small (below 10 billion parameters) VLMs at the time of writing. We also fine-tuned it as a stronger baseline. It uses a 675M ViT with Multimodal Rotary Position Embedding (M-RoPE) as the vision encoder, and the Qwen2-7B-Instruct____ as the language model.

\subsection{Parameter Efficient Fine-Tuning}
Fine-tuning large models typically requires huge computing resource as all parameters must be trained. However, recent advancements in parameter efficient fine-tuning methods enable larger models to be fine-tuned with fewer resource. One such method is LoRA ____, which inserts trainable low-rank matrices that are updated while the original model weights remain frozen, greatly reducing trainable parameters while maintaining acceptable model performance.
\\
\par
Several improvements to LoRA published in literature were experimented with in this research. They improve upon LoRA in either fine-tuning efficiency or accuracy. LoRA+____ sets a different learning rate to the two low-rank matrices used in LoRA, improving performance and fine-tuning speed. DoRA____ decomposes model weights into magnitude and direction, enhancing LoRA's learning capacity and training stability at no additional inference cost. Rank-Stabilized LoRA____ showed that by dividing the adapters by a factor of the square root of the rank, LoRA is able to achieve better fine-tuning performance at higher ranks. PiSSA____ initializes the two LoRA matrices with the principal components of the original weight matrix, instead of randomly initializing matrix A and zero-initializing matrix B. This was shown to have improved the fine-tuning performance compared to vanilla LoRA.