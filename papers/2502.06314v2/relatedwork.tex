\section{Related Work}
\textbf{Self-supervised learning.} 
\looseness-1 
Self-supervised learning (SSL) leverages auxiliary tasks to learn from unlabeled data, often outperforming supervised methods on downstream tasks. SSL can be divided into two categories: discriminative and generative \citep{liu2021self}. Discriminative methods \citep{chen2020simple,caron_emerging_2021} focus on enforcing invariance or equivariance between data views in the representation space, while generative methods \citep{he_masked_2021,bizeul2024probabilistic} rely on data reconstruction from, often, corrupted observations. Though generative SSL historically lagged in performance, recent work has bridged the gap by integrating strengths from both paradigms \citep{assran_masked_2022,dong2023peco,oquab2023dinov2,chen2024context,lehner_contrastive_2023}. Interestingly, recent discriminative methods employ cropping strategies to create distinct data views \citep{oquab2023dinov2,assran_self-supervised_2023}, which is reminiscent of image masking. \citet{balestriero_learning_2024} point out the misalignment between auxiliary and downstream tasks in reconstruction-based SSL and suggest novel masking strategies to help realign these objectives.

\textbf{Masked Image Modelling.} \looseness-1 MIM extends the successful masked language modeling paradigm to vision tasks. Early methods, such as Context Encoder \citep{pathak2016context}, used a convolutional autoencoder to inpaint a central region of the image. The rise of Vision Transformers (ViTs) \citep{dosovitskiy_image_2021} has driven significant advancements in MIM. BEiT \citep{zhou2021ibot,bao_beit_2022} combines a ViT encoder with image tokenizers \citep{ramesh2021zero} to predict discrete tokens for masked patches. SimMIM \citep{xie2022simmim} simplifies the task by pairing a ViT encoder with a regression head to directly predict raw pixel values for the masked regions. MAE \citep{he_masked_2021} introduces a more efficient encoder-decoder architecture, with a shallow decoder. MIMâ€™s domain-agnostic masking strategies have also proven effective in multi-modal tasks \citep{baevski_data2vec_2022,bachmann2022multimae}.

\textbf{Mask Design Strategies.} \looseness-1 A critical component of the masked image modeling paradigm is the design of effective masking strategies. Early MIM approaches have relied on random spatial masking techniques, such as masking out the central region of an image \citep{pathak2016context}, image patches \citep{he_masked_2021,xie2022simmim}, and blocks of patches \citep{bao_beit_2022}. Inspired by advances in language modeling, recent efforts have explored semantically guided mask design. \citet{li_mst_2021} use self-attention maps to mask irrelevant regions, while \citet{kakogeorgiou_what_2022} focus on masking semantically rich areas. \citet{shi_adversarial_2022} design masks through adversarial learning, where the resulting masks resemble semantic maps, a concept extended by \citet{li_semmae_2022} through progressive semantic region masking. Further advancing this direction, \citet{wang_hard_2023} and \citet{madan_cl-mae_2024} introduce curriculum learning-inspired mask design methods. %
These methods often require additional training steps, components, or more complex objectives. More closely related to our work, \citet{chang2022maskgit, chen2024deconstructing} explore the use of pre-existing image representations for asked Image Modeling and image denoising. \citet{chen2024deconstructing} introduce additive Gaussian noise to principal components as an alternative to the traditional Denoising Autoencoders. \citet{chang2022maskgit} utilize masked token modeling by leveraging the discrete latent space of a pre-trained VQVAE to develop an image generation model.