%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\input{math_commands}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submission:
 \usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\usepackage{cancel}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\def\defeq{\triangleq} % defined equal to
\newcommand{\iid}{\textrm{i.i.d.}\xspace}
\newcommand{\para}[1]{\textbf{#1}\ \ }
\newcommand{\indic}[1]{\mathbf{1}(#1)}
\newcommand{\qtext}[1]{\quad\text{#1}\quad} 
\newcommand{\evec}{\boldsymbol{e}}
\newcommand{\x}[1]{x^{(#1)}}
\newcommand{\z}[1]{z^{(#1)}}
\newcommand{\X}[1]{X^{(#1)}}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bu}{\textbf{u}}
\newcommand{\bbf}{\boldsymbol{f}}

\newcommand{\hsnorm}[1]{\norm{#1}_\mathrm{HS}}
\newcommand{\llnorm}[1]{\norm{#1}_{\nu}}
\newcommand{\set}[1]{\left \{ #1 \right \}}
\newcommand{\tr}{\text{tr}} % trace
\newcommand{\divger}{\mathrm{div}} 
\newcommand{\rbf}{\mathrm{rbf}} 
\newcommand{\imq}{\mathrm{imq}}
\newcommand{\fin}{\bbf_{\|}} 
\newcommand{\fperp}{\bbf_{\perp}}
\newcommand{\uperp}{\bu_{\perp}}
\newcommand{\vperp}{\bv_{\perp}}
\newcommand{\ppperp}{p_{\perp}}
\newcommand{\Kuu}{\bK_{\bu\bu}}
\newcommand{\Kuf}{\bK_{\bu\bbf}}
\newcommand{\Kfu}{\bK_{\bbf\bu}}
\newcommand{\Kff}{\bK_{\bbf\bbf}}
\newcommand{\Qff}{\bQ_{\bbf\bbf}}
\newcommand{\bQ}{\textbf{Q}}
\newcommand{\bK}{\textbf{K}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\bI}{\textbf{I}}
\newcommand{\bZ}{\textbf{Z}}
\newcommand{\bC}{\textbf{C}}
\newcommand{\bV}{\textbf{V}}
\newcommand{\bS}{\textbf{S}}
\newcommand{\bA}{\textbf{A}}

\newcommand{\K}{\textbf{K}}
\newcommand{\f}{\textbf{f}}
\newcommand{\y}{\textbf{y}}
\newcommand{\bk}{\textbf{k}}
\newcommand{\m}{\textbf{m}}
\newcommand{\bfmu}{\boldsymbol{\mu}}
\newcommand{\bLambda}{\boldsymbol{\Lambda}}

\newcommand{\datadim}{L}
\newcommand{\ind}{i}
\newcommand{\orderdistr}{order-policy }

\newcommand{\methodname}{LO-ARM}
\newcommand{\comm}[1]{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
% \icmltitlerunning{Submission and Formatting Instructions for ICML 2023}

\begin{document}

\twocolumn[
\icmltitle{New Bounds for Sparse Variational Gaussian Processes %without Imposing the Conditional Prior Approximation
}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Michalis K. Titsias}{comp}
\end{icmlauthorlist}

\icmlaffiliation{comp}{Google DeepMind}

\icmlcorrespondingauthor{Michalis K. Titsias}{mtitsias@google.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Sparse variational Gaussian processes (GPs) construct tractable posterior approximations to GP  models. At the core of these methods is the assumption that the true posterior distribution over training function values $\f$ and inducing variables $\bu$ is approximated by a variational distribution that incorporates the conditional GP prior $p(\f | \bu)$ in its factorization. While  this assumption is considered as fundamental, 
%Imposing this conditional prior in the approximation is believed to be a fundamental  requirement to obtain scalable GPs. 
we show that for model training we can relax it through the use of a more general variational distribution $q(\f | \bu)$ that depends on $N$ extra parameters, where  $N$ is the number of training examples. In GP regression, we can analytically optimize
the evidence lower bound over the extra parameters and express a tractable collapsed bound that is tighter than the previous bound. The new bound is also amenable to stochastic %gradient 
optimization and its implementation requires minor modifications to existing sparse GP code. 
Further, we also describe extensions to non-Gaussian likelihoods. 
On several %regression 
datasets we demonstrate that our method can reduce  bias when learning the %model
hyperpaparameters and can lead to better predictive performance. 
%such as applications to GP Poisson regression. 
\end{abstract}

\input{sec_intro}
\input{sec_background}
\input{sec_methods}
\input{sec_related}
\input{sec_experiments}
\input{sec_conclusion}

%\section*{Accessibility}
%Authors are kindly asked to make %their submissions as accessible as %possible for everyone including %people with disabilities and sensory %or neurological differences.
%Tips of how to achieve this and what to pay attention to will be provided on the conference website \url{http://icml.cc/}.

%\section*{Software and Data}
%If a paper is accepted, we strongly encourage the publication of software and data with the
%camera-ready version of the paper whenever appropriate. This can be
%done by including a URL in the camera-ready copy. However, \textbf{do not}
%include URLs that reveal your institution or identity in your
%submission for review. Instead, provide an anonymous URL or upload
%the material as ``Supplementary Material'' into the CMT reviewing
%system. Note that reviewers are not required to look at this material
%when writing their review.

%% Acknowledgements should only appear in the accepted version.
%\section*{Acknowledgements}
%
%\textbf{Do not} include acknowledgements in the initial version of
%the paper submitted for blind review.

%If a paper is accepted, the final camera-ready version can (and
%probably should) include acknowledgements. In this case, please
%place such acknowledgements in an unnumbered section at the
%end of the paper. Typically, this will include thanks to reviewers
%who gave useful comments, to colleagues who contributed to the ideas,
%and to funding agencies and corporate sponsors that provided financial support.



% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite \nocite{langley00}

\bibliography{library}
\bibliographystyle{icml2023}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{appendix}
% \section{You \emph{can} have an appendix here.}

%You can have as much text here as you want. The main body must be at most $8$ pages long. For the final version, one more page can be added. If you want, you can use an appendix like this one, even using the one-column format.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
