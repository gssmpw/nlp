%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssectL[lognorm]{Logarithmic norms}
	Let $\|A\|_p$ be the induced $p$-norm of a square matrix $A$.
	Then the \dt{logarithmic $p$-norm} of $A$ is defined as
		\[\mu_p(A) \as \lim_{h\to 0+}\frac{\|I+hA\|_p-1}{h}.\]
	%If $p$ is understood, we may just call $\mu_p$ the logarithmic norm.
	We shall focus on $p=2$, and call $\mu_2$ the \lognorm.
	
	%Proposition:	Let the  linear dynamical system be
		%$\stackrel{.}{x}(t)=Ax+r$, then $\partial^{+}\|x(t)\|\le
		%\mu(A)\cdot \|x\|+\|r(t)\|$.
	%
	%Let function $R(z)$ approximates $e^hA$ by the rational
	%matrix function $R(hA)$, then \[\mu(A)=\lim_{h\to 0+}\frac{R(hA)-1}{h}.\]
	%
	%Let $f : D \subset X \to X$.  Define two functions, the least upper
	%bound (lub)
	%and greatest lower bound (glb) Lipschitz constants,by
	%\[L[f]=sup_{u\ne v}\frac{\|f(u)-f(v)\|}{\|u-v\|}; l[f]
		%=\inf_{u\ne v}\frac{\|f(u)-f(v)\|}{\|u-v\|}.\]
	%Denote \[M[f]= \lim_{h\to 0+}\frac{L[I+hf]-1}{h}; m[f]
		%=\lim_{h\to 0+}\frac{l[I+hf]-1}{h}.\]
	%
	%Proposition: $M[A]=\mu(A)$
	%
	%It follows that $L[f]$ and $l[f]$ are upper and lower bounds for the
	%moduli of the eigenvalues of $f'(x)$ when $x\in D$. Similarly,
	%$M[f]$ and $m[f]$ are upper and lower bounds, respectively, for the
	%real parts of the eigenvalues.
	%
	%Let Gerschgorin domain of $f$ is $G[f]$. Then $M[f]=max{Re\lambda:
	%\lambda \in G[f] }$ and $m[f]=min{Re\lambda: \lambda\in G[f]}$.
	%
	%The difference between two solutions $x_1$ and $x_2$ to
	% $\stackrel{.}{x}(t) = f(t,x)$ satisfies the differential inequality
	%\[\partial^{+}\|x_1-x_2\|\le M[f]\cdot \|x_1-x_2\|.\]
	%
	%Then $\|x_1-x_2\|\le e^{tM[f]}\|x_1(0)-x_2(0)\|$
	
	We have these bounds for \lognorm:
	\bleml[lognorm] \ 
	\benum[(a)]
	\item
		$\mu_p(A+B)\le \mu_p(A)+\mu_p(B)$
	\item
		$\mu_p(A)\le \|A\|_p$
	\item
		$\mu_2(A)=\max_{j=1\dd k}(\frac{1}{2}(\lambda_{j} (A+A^T)))$
			where $\lambda_1(A)\dd \lambda_k(A)$
			is the set of eigenvalues of $A$.
	\item
		Let $A$ be an $n\times n$ matrix  and let
		$\max_{i=1}^n (\Re(\lambda_i))$ where
		$\lambda_i's$ are the eigenvalues of $A$.
		Then
		\bitem
			\item $\max_{i=1}^n (\Re(\lambda_i))\le
					\mu(A)$ holds for any \lognorm.
			\item For any $\veps \ge 0$, there exists an
				invertible matrix $P$ such that 
			\[\max_i(Re(\lambda_i))\le \mu_{2,P}(A)\le
				\max_i(Re(\lambda_i))+\veps.\]
			where $\mu_{2,P}(A)\as \mu_2(P^{-1}AP).$
		\eitem
	\eenum
	\eleml
	For parts(a-c) see
		\cite{desoer-haneda:measure:72},
	and part(d), see
		Pao \cite{pao:log-der-matrix:73}.
	In our estimates, we cite these standard bounds:
	\beql{matrixnorm}
		\grouping[l l c l ]{
		\|A\|_2 &=&		\max_i(\sqrt{\lambda_{i}(A^*A)})\\
		\|AB\|_2 &\le&	\|A\|_2\|B\|_2
		}
	\eeql

\savespace{
	We will use these standard bounds on norms.
	\bleml[matrixnorm] \
	\benum[(a)]
	\item
		$\|A\|_2=\max_i(\sqrt{\lambda_{i}(A^*A)})$
	\item $\|AB\|_2\le \|A\|_2\|B\|_2$
	\eenum
	\eleml
}

	
%	Let $P$ be an invertible matrix then we have
	%	Then, by choosing different matrix norms, we can obtain different
	%	measures of a matrix.
	%	
	%	
	%	\begin{eqnarray}
	%		\mu_1(A)=ma\textbf{x}_j(a_{j,j}+\sum_{i\ne j}|a_{i,j}|)\\
	%		\mu_2(A)=ma\textbf{x}_j\frac{1}{2}(\lambda_{j} (A+A^T))\\
	%		\mu_{\infty}(A)=ma\textbf{x}_i(a_{i,i}+\sum_{j\ne i}|a_{i,j}|)\\
	%		\mu_{2,P}(A)=\mu_2(PAP^{-1}).
	%	\end{eqnarray}
	
%	\begin{theorem}\cite{pao:log-der-matrix:73}\label{Thm-estmu}
%		Let $A$ be any $n\times n$ matrix  and let $\lambda_1\dd
%		\lambda_n$ be the eigenvalue of $A$. Let $\max_i(Re(\lambda_i))$
%		be the maximum real part eigenvalue of $A$.
%		Then, the following statements are true:
%		\begin{enumerate}
%			\item $\max_i(Re(\lambda_i))\le \mu(A)$ holds for any matrix norm.
%			\item For any $\veps \ge 0$, there exists a matrix $P$ such that 
%			\[\max_i(Re(\lambda_i))\le \mu_{2,P}(A)\le
%				\max_i(Re(\lambda_i))+\veps.\]
%		\end{enumerate}
%	\end{theorem}
%	
%	\dt{Remark}
%		Let $A$ be a matrix we define  $\max_i(Re(\lambda_i(A)))$ be the
%		maximum real part eigenvalue of $A$. 
%	We choose  a matrix $P$ such that  the columns of $P$ be the real and
%	imaginary parts of a full set of
%	eigenvectors of $A$. If $A$ is nearly defective, one should instead
%	choose linearly
%	independent basis vectors from low dimensional subspaces.
%	Then from linear algebra, we know that $P^{-1}AP$ is close to being
%	symmetric or anti-symmetric, see \cite{neumaier:taylor-forms:03} for
%	details. Thus, we have  $\mu_{2,P}(A)$ approaches
%	$\max_i(Re(\lambda_i(A)))$.
%	We use  $P(A)$ to represent such  $P$ matrix.
%	
%	
%	
%	From Theorem \ref{Thm-estmu}, for a given matrix $ A $, we can
%	estimate $ \mu(A) $ by using $ \max_i(Re(\lambda_i)) $.
%	The measure of the matrix can be used to estimate the range of the
%	solution of the IVP through the following theorem:
	
	We have the following result from Neumaier
	\citep[Corollary 4.5]{neumaier:rigorous-bds:93}:

	%\begin{theorem}
	\bthmT[ne]{Neumaier} \
	%\cite[Corollary 4.5]{neumaier:rigorous-bds:93}\\
		Let $\bfx\in \ivp_\bff(\bfp_0,h)$
		and $\xi(t)\in C^1([0,h]\to \mathbb{R}^n)$
		be any ``approximate solution''. Let\footnote{
			For our purposes, matrix $P$ in this theorem can be the
			identity matrix.
		}
		$P$ be an invertible matrix.
		Assume the constants $\veps,\delta,\olmu$ satisfy

		\begin{enumerate}
			\item 
				$\veps \ge
					\|P\inv\Bigcdot(\xi'(t) - \bff(\xi(t)))\|_2$
				for all $t \in [0, h]$ 
			\item
				$\delta \ge 
					\|P\inv\Bigcdot(\xi(0)-\bfp_0)\|_2 $
			\item 
				$\olmu \ge
					\mu_2  \big(P\inv\Bigcdot J_{\bff}(s\bfx(t) +
					(1-s)\xi(t))\Bigcdot P\big)$
				for all $s \in [0,1]$ and $t \in [0, h]$
		\end{enumerate} 
		Then for all $t \in [0, h]$,
		\beql{xibfx}
			\|P\inv\Bigcdot(\xi - \bfx)\|_2 \le
				\begin{cases}
			\delta e^{\olmu|t |} + \frac{\veps}{\olmu}(e^{\olmu|t|} - 1),
					& \olmu \ne 0, \\
			\delta + \veps t, & \olmu = 0.
				\end{cases}
		\eeql
	%\end{theorem}
	\ethmT
	
	\bcorl[cor-1] \ \\
		Let $\bfx_1,\bfx_2 \in \ivp(\bfp_1,h,Ball(\bfp_0,r))$ and
		$\olmu\ge \mu_2(J_\bff(Ball(\bfp_0,r)))$.
		 Then for all $t\in [0,h]$
		  \beql{bfx12}
		  	\|\bfx_1(t)-\bfx_2(t)\|_2
		  		\le \|\bfx_1(0)-\bfx_2(0)\|_2 e^{\olmu t}.\eeql 
	\ecorl
	\savespace{
		\bpf
		Note that $\bfx_1$ and $\bfx_2$ are solutions of \refeq{bfx'} with
		different initial values. Therefore, we have $\bfx'_1 = \bff(\bfx_1)$
		and $\bfx'_2 = \bff(\bfx_2)$. This implies that
			$$ \bfx'_1(t) - \bff(\bfx_1(t))
				= \bff(\bfx_1(t)) - \bff(\bfx_1(t)) = 0 = \veps. $$
		If $\olmu\ne 0$, then \refeq{bfx12} is the first case
		of \refeq{xibfx} since $\delta=\|\bfp_1-\bfp_2\|_2$.
		If $\olmu=0$, it comes from the second case since $\veps=0$.
		\epf
	}%	

	\blemT[eulerStep]{Enclosure for Euler Method}\ \\
		Let $(B_0,H,B_1)$ be admissible triple,
	$\olmu\ge \mu_2(J_{\bff}(B_1))$ and
	$ M\ge \|\bff^{[2]}(B_1)\|$.
	%%
	If $h_1>0$ is given by
	\beql{h1}
	h_1\ass h(H,M,\olmu,\veps) \as
	\begin{cases}
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)}}
		&\rmif\ \olmu\ge 0\\
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)-\olmu^2\veps}}
		&\rmif\ \olmu<0
	\end{cases}
	\eeql
	consider the path $Q_{h_1}=(\bfq_0,\bfq_1\dd \bfq_m)$ 
	from the Euler method with step-size $h_1$.
	If each $\bfq_i\in B_1$ ($i=0\dd m$),
	then for all $t\in [0,H]$, we have
	\beql{eulerBd}
	\|Q_{h_1}(t)-\bfx(t;\bfq_0)\|\le \veps.
	\eeql
	I.e., $Q_{h_1}(t)$ lies inside the $\veps$-tube of $\bfx(t;\bfq_0)$.
	\eleml

	
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
