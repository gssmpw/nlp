%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Basic Tools}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssectL[Notations]{Notations and Key Concepts}
	%The basic notations are gathered in Appendix 1 for quick reference.
	We use bold fonts such as $\bfx$ for vectors.
	A point $\bfp\in \RR^n$ is viewed
	as a column vector $\bfp=[p_1\dd p_n]$,
	with transpose the row vector $\bfp\tr =(p_1\dd p_n)$.
	Also vector-matrix or matrix-matrix
	products are indicated by $\Bigcdot$ (e.g., $A\Bigcdot \bfp$).
	Let $\intbox\RR^n$ denote the set of $n$-dimensional \dt{boxes} in
	$\RR^n$ where a box $B$ is viewed as a subset of $\RR^n$. 
	The \dt{width} and \dt{midpoint} of
	an interval $I = [a, b]$ are $w(I) \as b - a$ and $m(I)
	\as (a + b) / 2$, respectively.
	If $B = \prod_{i=1}^n I_i$, its \dt{width} and \dt{midpoint} are
		$\bfw(B) \as (w(I_1)\dd w(I_n))$ and
		$\bfm(B) \as (m(I_1) \dd m(I_n))$.
	Also, \dt{maximum width} and \dt{minimum width} are \\
	$\wmax(B)\as \max_{i=1}^n w(I_i)$ and
	$\wmin(B)\as \min_{i=1}^n w(I_i).$
	We assume $\wmin(B)>0$ for boxes.
	
	We use the Euclidean norm on $\RR^n$, writing 
	$\|\bfp\|=\|\bfp\|_2$.
	For any function $f: X \to Y$, we
	re-use `$f$' to denote its \dt{natural set extension},
	$f:2^X\to 2^Y$ where $2^X$ is the power set of $X$ and
	$f(S)=\set{f(x): x\in S}$ for all $S\ib X$.

	\ignore{
	Let $C^k([0, h] \to \RR^n)$ be
	the set of $C^k$-continuous functions ($k \geq 0$)
	from $[0, h]$ to $\RR^n$.
	Assume that the set of solutions
	$\ivp(B_0, h)$ is a subset of $C^\infty([0, h] \to \RR^n)$.

	Now, consider $\bfx \in C^2([0, h] \to \RR^n)$. If
	$\bfx \in \ivp(B_0, h)$,
	it satisfies the set of solutions to \refeq{bfx'},
	where any solution $\bfx$ to $\IVP(B_0, 1)$ belongs to
	$C^2([0, 1] \to \RR^n)$.
	In particular, $\bfx(t)$ is defined and bounded for all
	$t \in [0, 1]$. 
	However, $\ivp(B_0, 1)$ might not always have a solution.
	Specifically, if $\bfx(0) \in B_0$ leads to $\bfx(t)$ becoming
	undefined for some $t \in (0, 1]$, the system lacks a valid
	solution.

	E.g., $n=1$ then \refeq{bfx'} 
	 $x'=x^2$ has solution $x(t)= \efrac{x_0\inv -t}$, $x(0)=x_0$
	 to $\IVP(x_0,1)$.  If $B_0\ib [1,\infty)$ then $\IVP(B_0,1)$
	 has no solutions since $x(t)=\infty$ for
	 when $t=1/x_0 \in [0,1]$.  To avoid this issue, we assume
	 the promise problem in which 
	 $\IVP(\bfp_0, 1)$ is assumed to have
	 a solution for all $\bfp_0 \in B_0$.
	}%

	The \dt{image} of a function $f: A \to B$ is
		$\image(f) \as \set{f(a) : a \in A}.$  
	The \dt{image} of $\ivp(B_0, h)$ is the union
		$\bigcup_{\bfx \in \ivp(B_0, h)} \image(\bfx)$.
		% \image(\ivp(B_0, h)) \as
		%	\bigcup_{\bfx \in \ivp(B_0, h)} \image(\bfx).
		%  
	A \dt{full-enclosure} of $\ivp(B_0, h)$ is a
	set $B_1\ib\RR^n$ that contains\\
		$\image(\ivp(B_0, h))$.
	If, in addition, $(B_0,h)$ is well-defined,
	then call $(B_0,h,B_1)$ an \dt{admissible triple},
	equivalently, $(h,B_1)$ is an \dt{admissible pair} for $B_0$.
	We then write $\ivp(B_0,h,B_1)$ instead of $\ivp(B_0,h)$.
	%%%
	Finally, $\ulB_1\ib B_1$ is
	an \dt{end-enclosure} for $\ivp(B_0, h, B_1)$
	if for all solution $\bfx \in \ivp(B_0, h, B_1)$, 
	we have $\bfx(h) \in \ulB_1$.  Call $(B_0,h,B_1,\ulB_1)$
	an \dt{admissible quadruple} (or quad).

	\ignore{
	If $P$ is a problem or an algorithm, its header has
	the format 
		``$P(...inputs)\ssa (outputs...)$''.
	This is illustrated in the introduction by
	$\endEncIVP(B_0,\veps)\ssa (\ulB_0,\olB_1)$.
	Moreover, the exact relation between $(inputs..., outputs...)$
	will be explicitly stated.
	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{The End-Enclosure Problem for IVP}
	\dt{Validity.} We say 
	  $\ivp(B_0, h)$ is \dt{valid} if
	  (i) $\ivp(B_0,h)$ is well-defined, and
	  (ii) $\0 \nin \bff(\image(\ivp(B_0,h)))$.

	  
	Condition (ii) is equivalent to requiring that
	for all $\bfx\in \ivp(B_0,h)$, and all $t \in [0, h]$,  
	we have $\bfx'(t) \neq \0$.
	%%
	If $\bff(\bfq)=\0$, we call $\bfq$
	an \dt{equilibrium point} of $\bff$.  So condition (ii)
	says that $\image(\bfx)$ does not contain any equilibrium
	point.
	Note that condition (i) does not imply condition
	(ii). For example, the one dimensional equation  
	  $x' = f(x) = 3x^{\frac{2}{3}}$,  
	  with initial condition $x(0) = -\frac{1}{8}$ has a
	  well-defined solution $x(t) = (t - \frac{1}{2})^3$, 
	  but $f(x(\frac{1}{2})) = 0$.  

	\savespace{
	  Another example for $n=2$ is the system:  
	  \[
	  	\mmat{x'\\ y'} = \mmat{f_1\\ f_2}
			=\mmat{ x + \frac{\sqrt{e}}{\sqrt{e} - 1}\\
	  			x - y + \frac{\sqrt{e} + 1}{2\sqrt{e} - 2}}  
	  \]  
	  with the initial condition $[x, y] = [1, 1]$. One can check that
	  $f_1=f_2=0$ when $t=0.5$.
	}

	\savespace{	
		It is not strictly necessary to assume $\ivp(B_0, 1)$ is
		valid. It is enough
		to know a point $\bfp_0$ in the interior of $B_0$
		such that $\ivp(\bfp_0,1)$ is valid.
		Our current algorithm can be defined to shrink
		towards $\bfp_0$, and halting can be assured.
	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Normalized Taylor Coefficients}
	For any solution $\bfx$ to the
	ODE \refeq{bfx'}, its $i$th \dt{normalized Taylor coefficient}
	is recursively defined as follows:
		\beql{normalizedTaylorCoef}
			\bff\supn[i](\bfx) =
					\clauses{ \bfx & \rmif\ i=0,\\
						\efrac{i} \Big( J_{\bff\supn[i-1]} \cdot
						\bff\Big)(\bfx) & \rmif\ i\ge 1}
		\eeql
	where $J_\bfg$ denotes the Jacobian of any function
	$\bfg=\bfg(\bfx)\in C^1(\RR^n\to\RR^n)$
	in the variable $\bfx=(x_1\dd x_n)$.
	For instance,
		$\bff\supn[1] = \bff$
	and
		$\bff\supn[2](\bfx) = \half (J_\bff\cdot \bff)(\bfx).$
	It follows that the order $k\ge 1$ Taylor expansion of $\bfx$
	at the point $t=t_0$ is
		$$\bfx(t_0+h) = \Big\{
				\sum_{i=0}^{k-1} h^i \bff\supn[i](\bfx(t_0)) \Big\}
					+ h^k \bff\supn[k](\bfx(\xi))
		$$
	where $0\le \xi-t_0 \le h$. 
	If $\bfx(\xi)$ lies in a box $B\in\intbox\RR^n$,
	then interval form is
		\beql{taylor}
			\bfx(t_0+h) \in \Big\{
				\sum_{i=0}^{k-1} h^i \bff\supn[i](\bfx(t_0)) \Big\}
					+ h^k \bff\supn[k](B) \eeql
	These Taylor coefficients
	can be automatically generated, and they can be evaluated
	at interval values using automatic
	differentiation. % (e.g., \cite{moore:diffEqn:09}).

	\savespace{
	\dt{Running Example}:
		Let $\bff = \mmat{x^2+1\\ -y^2+7x}$.
		Then
			{\small \beqarrys
			\bff\supn[1] &=& \bff(\bfx)\\
			\bff\supn[2] &=& \half (J_\bff\cdot \bff)(x,y)\\
				%&=& \half \mmat{2x & 0\\ 7 &-2y}\cdot 
				%			\mmat{x^2+1\\ -y^2+7x} \\
				%&=& \half \mmat{2x(x^2+1)\\ 7x^2+7-2y(7x-y^2)}\\
				&=& \half \mmat{2x(x^2+1)\\ 7(x^2+1-2yx)+2y^3}\\
			\bff\supn[3] &=& \frac{1}{3}(J_\bff\supn[2]\cdot \bff)(x,y)\\
			%&=& \frac{1}{3} \mmat{3x^2+1 & 0\\ 7(x-y) &3y^2-7x}\cdot 
			%\mmat{x^2+1\\ -y^2+7x} \\
			%&=& \frac{1}{3} \mmat{(3x^2+1)(x^2+1)\\
			%		-3y^4+7x^3-7x^2y+28xy^2-49x^2+7x-7y}\\
			&=& \frac{1}{3} \mmat{(3x^2+1)(x^2+1)\\
					-3y^4+7(x^3-x^2y+4xy^2-7x^2+x-y)}.
			\eeqarrys
			}%small
	}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Banach Spaces $Y\ib X$}
	Proving that $\ivp(B_0,h)$ is well-defined
	depends on Banach space theory.
	%%
	Let $C^k([0, h] \to \RR^n)$ be
	the set of $C^k$-continuous functions ($k \geq 0$)
	from $[0, h]$ to $\RR^n$.
	%%
	We can view $\ivp(B_0, h)$ as
	a subset of $X \as C^0([0, h] \to \RR^n)$.
	%% no need!
	% View an element $\bfx\in X$ as a vector of functions,
	%	$\bfx=(x_1\dd x_n)$ where
	%	$x_i\in C^0([0,h]\to\RR)$ ($i=1\dd n$).
	%%
	% Call $X$ the \dt{solution space}
	% since each $\bfx\in X$ is a potential solution to our IVP.
	
	% \bitem
	% \item
		$X$ is a real linear space where
		$c\in\RR$ and $\bfx,\bfy\in X$ implies
		$c\bfy\in X$ and
		$\bfx\pm \bfy\in X$.
		Let $\0\in X$ denote the additive identity
		in $X$: $\bfx\pm \0=\bfx$.
	%\item
		$X$ is also a normed space with norm 
			$\|\bfx\|=\|\bfx\|_{\max} \as
			\max_{t\in [0,h]} \|\bfx(t)\|_{2}$
		where $\|\cdot\|_{2}$ is the $2$-norm.
		For simplicity, write $\|\bfx\|$ for $\|\bfx\|_{\max}$.
		If $S\ib X$, we let
			$\|S\|\as \sup_{\bfx\in S}\|\bfx\|$.
		%%%
	%\item
		We turn $X$ into a complete metric space $(X,d)$
		with metric $d(x,y)= \|x-y\|$.
	%\item
		To prove existence and uniqueness of solutions, we need
		to consider a compact subset $Y\ib X$.
		E.g., let $Y= C([0,h]\to B)$
		where $B\ib \RR^n$ is a box or ball.
		Then $Y$ is also a complete metric space induced by $X$.

	\savespace{
	\item
		Two functions $f:A\to B$ and $g:A\to C$
		are said to be \dt{equivalent} if for all $x\in A$, $f(x)=g(x)$. 
		In particular, this implies that $\image(f)=\image(g)$.
		We are interested in functions up to equivalence.
		E.g., if $\bfx\in C([0,h]\to\RR^n)$, and $B$ is a ball, we 
		want to know if $\bfx$ is equivalent to some function
		in $C([0,h]\to B)$.
	\item	
		We say a sequence $(\bfx_n: n\in \NN)$ in $X$
		\dt{converges uniformly} to $\bfy\in X$ if for all $t\in[0,h]$,
			\beql{unif}
				\lim_{n\to\infty} \|\bfx_n(t)-\bfy(t)\| =0.\eeql
		% See
		% \myHref{https://en.wikipedia.org/wiki/Uniform\_convergence}{wikipedia}.
		\ignore{
		follows from the fact that $\infty$-norm is a norm:
		$\|\bfx(t)\|_{\infty}+\|\bfy(t)\|_{\infty} \le
		\|\bfx(t)+\bfy(t)\|_{\infty}$.
	}
	\item
		Now $X$ becomes a metric space $(X,d)$
		with metric $d(x,y)= \|x-y\|$.
		It is a complete metric space since the limit
		of a converging sequence in $X$ lies in $X$.
		%%%
		%% Stronger: it is a Hilbert space
		Thus, $(X,d)$ is\footnote{
			Note that a Banach space, unlike a Hilbert
			space, does not have an inner product.
			Following Soderlind, we could define
			a \dt{semi-inner product} for Banach spaces.
		} a Banach space.
	\item
		(Uniform limit theorem)
		If a sequence $(\bfx_n: n\in\NN)$
		in $X$ is uniformly convergent to some function $\bfx_*$,
		then $\bfx_*$ is continuous and belongs to $X$.
	}%
	%\eitem
	%%
	Using this theory, we can prove the following result
	\cite[Theorem 1]{nedialkov-jackson-pryce:HOI:01}:
	
	\blemT[admiss]{Admissible Triple}
		\ \\
		For all $k\ge 1$, if
		$E_0, F_1\ib \RR^n$ and $h>0$ satisfy the inclusion
		\beql{tay}
			\sum_{i=0}^{k-1}
		 	[0,h]^i \bff^{[i]}(E_0)+[0,h]^k \bff^{[k]}(F_1)
				\subseteq F_1,
		 \eeql
		then $(E_0,h,F_1)$ is an admissible triple.
	\elemT
	For simplicity, assume $k\ge 1$ is a global constant in this
	paper.  


	\ignore{
		Show that \refeq{unif} amounts to the usual def of uniform
		convergence.  Oh, it is direct.
	}
	
	\savespace{
	\bfac If a sequence $(\bfx_n: n\in\NN)$
	in $X$ is uniformly convergent to some function $\bfx_*$,
	then $\bfx_*$ is continuous and belongs to $X$.
	\efac
	}
	\ignore{
		This is also called the
		\myHref{https://en.wikipedia.org/wiki/Uniform\_limit\_theorem}
		{Uniform Limit Theorem (wiki)}.
		}%
	%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ssect{The Picard Operator $T$ of an IVP.}
	%	A function of the form $T:X\to X$ is usually called an
	%	\dt{operator}
	%	(or transformation).
	%	The result of applying the operator $T$ to $\bfx\in X$
	%	is typically written $T[\bfx]$ instead of $T(\bfx)$.
	%	
	%	\Ldent\progb{
	%		\lline[0] IVP$(\bff,\bfp_0)$:
	%		\lline[5] Given $(\bff,\bfp_0)$,
	%		\lline[5] find some $\bfx\in X$ satisfying \refeq{ivp}
	%	}
	%	\beql{ivp}
	%	\bfx' = \bff(\bfx),\qquad \bfx(0)=\bfp_0\in\RR^n
	%	\eeql
	%	
	%	The \dt{Picard operator} for IVP$(\bff,\bfp_0)$ 
	%	is defined as follows:
	%	for all $t\in [0,1]$ and $\bfx\in X$,
	%	\beql{pic}
	%		T[\bfx](t) = \bfx_0 + \int_{0}^t \bff(\bfx(s))ds.
	%	\eeql
	%	We observe that if $\bff(\bfx)$ is continuous
	%	then $T[\bfx]$ uniformly continuous and differentiable on $[0,1]$
	%	%%% 	p.7, picard.pdf
	%	(by the First Fundamental Theorem of Calculus).
	%	% see 
	%	% \myHref{https://en.wikipedia.org/wiki/Fundamental\_theorem\_of\_calculus}
	%	%	{wiki}
	%	
	%	Next, a fixed point $\bfx_*$ of this operator satisfies
	%	$T[\bfx_*]=\bfx_*$ is clearly a solution to the
	%	IVP problem \refeq{ivp}.  To find such a fixed point,
	%	we compute the iterative sequence
	%	\beql{seq}
	%	(\bfx_0,\bfx_1,\ldots)\quad\text{where}\quad
	%	\bfx_{i} =\clauses{ \bfp_0 & \rmif\  i=0,\\
	%		T[\bfx_{i-1}] & \rmif\ i\ge 1.}
	%	\eeql
	%	The classic tool for proving 
	%	the convergence of the sequence \refeq{seq} is given by
	%	the next theorem.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%\ssect{Contraction Maps}
	%	Let $(Y,d)$ be a complete metric space, and $f:Y\to Y$.
	%	We have two related definitions:
	%	\\ (a) Call $f$ a \dt{weak contraction map} of $Y$
	%	if for all $x,y\in Y$, $d(f(x),f(y)< d(x,y)$.
	%	\\ (b) Call $f$ a \dt{contraction map} of $Y$ if
	%	there is constant $k\in [0,1)$ such that for
	%	all $x,y\in Y$, $d(f(x),f(y))\le k d(x,y)$.
	%	
	%	\bthmT[banach]{Banach Fixed Point Theorem}
	%	Consider the following two conditions on $f:Y\to Y$:
	%	\\ (a) $f$ is a contraction map.
	%	\\ (b) $f$ is a weak contraction map,
	%	and $Y$ is a compact space.
	%	\\ Either (a) or (b) implies the following:
	%	\benum[(i)]
	%	\item $f$ has a fixed point $y_*$,
	%	i.e., $f(y_*)=y_*$.
	%	\item This fixed point is unique.
	%	\item For all $y_0\in Y$, the infinite sequence
	%			$$(y_i: i\in\NN)\quad\text{where}\quad
	%					y_i=f(y_{i-1}) \text{ for }i\ge 1$$
	%	converges to $y_*$.
	%	\eenum
	%	\ethmT
	%	See \myHref{https://en.wikipedia.org/wiki/Banach\_fixed-point\_theorem}
	%	{wiki: Banach fpt}.
	%	and \myHref{https://en.wikipedia.org/wiki/Metric\_space\#Lipschitz\_maps\_and\_contractions}
	%	{wiki: Lipschitz constraction maps}.
	%	
	%	REMARK: the uniqueness part (ii) distinguishes
	%	Banach's Fixed Point theorem from some other fixed point
	%	theorems (notably, Brouwer's or Schauder's Fixed Point Theorem)
	%	which do not guaranteed uniqueness.
	%	See enclosed
	%	\myHref{https://en.wikipedia.org/wiki/Brouwer\_fixed-point\_theorem}
	%	{wiki: Brouwer fpt}.
	%	The long article is downloaded here (surf8).
	%
	%	\chee{Question: suppose we apply the Picard operator $T$
	%	to the leaky bucket example of Hubbard-West, which
	%	has non-unique solutions from  a fixed initial value.
	%	What is the fixed point of $T$?}
	%	
	%	\ignore{% obsolete:
	%		If $\bfx,\bfy\in\Sol(I)$ and $c\in\RR$, then 
	%		$c\cdot\bfx\pm \bfy\in\Sol(I)$.
	%		Thus, $\Sol(I)$ is a real vector space.
	%		
	%		Norm:
	%		(1) Positivity: $\|x\|\ge 0$ with equality iff $x=0$
	%		(2) Absolute homogeneity: $\|cx\| = |c|.\|x\|$
	%		(3) Triangle inequality: $\|x+y\|\le \|x\|+\|y\|$.
	%		It also has a norm given by
	%		$\|\bfx\| \as$
	%		Thus $\Sol(I)$ is a metric space with distance function
	%		$d(\bfx,\bfy)=\|\bfx-\bfy\|$.
	%		
	%		\myHref{https://en.wikipedia.org/wiki/Infinite-dimensional\_vector\_function}
	%		{wiki: infinite dimensional vector spaces}
	%		
	%		An \dt{infinite dimensional vector function} is
	%		whose values lies in an infinite dimensional topological vector
	%		space.  Most theorems in differentiation and integration
	%		on scalar functions can be generalized of vector functions.
	%		It is straightforward for finite dimensional vector functions,
	%		hence the focus on infinite dimensional case.
	%		
	%		Let $f:[0,1]\to X$ where $X$ is a topological vector space.
	%		Then $f'$ (differentiation wrt $t\in [0,1]$) can be defined
	%		in the usual way.
	%		
	%		WHAT ABOUT NORMS for $f$?  See Lp-spaces:
	%		https://en.wikipedia.org/wiki/Lp_space
	%		For $1\le p\le \infty$,
	%		$$\|f\|_p = \Big(\int_I |f(m)|^p dm\Big)^{1/p}$$
	%	}%ignore
	%	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%




 
 







