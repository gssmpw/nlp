%file: intro-new.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	We consider the following system of
	first order ordinary differential equations (ODEs)
	\beql{bfx'}
		\bfx' = \bff(\bfx)
	\eeql
	where $\bfx=[x_1\dd x_n]\in\RR^n$
	are functions of time and $\bfx'=[x_1'\dd x_n']$
	indicate differentiation with respect to time,
	and $\bff=[f_1\dd f_n]:\RR^n\to\RR^n$.
	Our ODE is autonomous since $\bff$ does not
	depend on time, and so we can assume an initial time
	$t=0$.  Up to time scaling, we can also assume that the end time
	is $h=1$.  

	Given $\bfp_0\in\RR^n$ and $h>0$,
	the \dt{initial value problem} (IVP) for $(\bfp_0,h)$ is the
	mathematical problem of finding a \dt{solution},
	i.e.,
	a continuous function $\bfx: [0,h]\to\RR^n$
	that satisfies \refeq{bfx'}, 
	subject to $\bfx(0)=\bfp_0$.
	Let $\ivp_\bff(\bfp_0,h)$ denote the set of all such solutions.
	%%
    Since $\bff$ is usually fixed or understood,
	we normally omit $\bff$ in our notations.
	%%
	We say that $(\bfp_0,h)$ is \dt{well-defined} if
	the solution exists and is unique, i.e.,
	$\ivp(\bfp_0,h)=\set{\bfx_0}$ is a singleton. 
	In this case, we write $\bfx_0= \ivp(\bfp_0,h)$.
	%% Move away from intro:
	It is convenient to write
			$\bfx(t;\bfp_0)$ for $\bfx_0(t)$.
	%
	See \refFig{Volterra-21-13} for the solution to the
	Volterra system (see Eg1 in \refTab{problems}).
	% described as Eg1 in our list of examples below.
	%%
	The IVP problem has numerous applications including
	in modeling physical, chemical or biological systems,
	%%
    

	%\FigEPS{Volterra-21-13}{0.1}{
  	%	Volterra system (see Eg1) with $\bfp_0=[1,3]$;
	%	the negative lognorm region is above green parabola.
	%}

	% Scaling does not work in \includegraphics! 
	% New macro: FigEPSissac 

	\FigEPSissac{Volterra-21-13}{0.5}{
  		Volterra system (see Eg1) with $\bfp_0=[1,3]$;
		the negative \lognorm\ region is above green parabola.}


	The mathematical IVP gives rise to a several
	algorithmic formulations since we cannot explicitly represent
	$\bfx_0= \ivp(\bfp_0,h)$.
	We choose the simplest algorithm form of IVP,
	that of computing an enclosure for $\bfx(h;\bfp_0)$.
	In any real world applications, we only have 
	approximate values for $\bfp_0$; so we replace $\bfp_0$ by a
    region $B_0\ib\RR^n$ and let
    $\ivp(B_0,h)\as \bigcup_{\bfp\in B_0}\ivp(p_0,h)$.  
	Call $B_1\ib \RR^n$ an \dt{end-enclosure} for $\ivp(B_0,h)$
	if we have the inclusion
		$\set{\bfx(h) : \bfx\in \ivp(B_0,h)}\ib B_1$.
	\savespace{
		Corliss \cite[Section 3]{corliss:survey-ode-intvl:89}
		confirms that this is the interval viewpoint.
		}%savespace
	So our formal formal algorithmic problem is
	the following \dt{End Enclosure Problem}:

	% use image to get equation number!!!
		\beql{endEncProb}
			\includegraphics[width=0.75\columnwidth]{figs/endEncIVP}
		\eeql


	\ignore{% KEEP THIS TO GENERATE THE IMAGE!!!
		\Ldent\progb{
			% \label{Problem}
			\lline[-2] \endEncIVP($B_0,\veps$) $\ssa (\ulB_0,\olB_1)$
			\lline[0] INPUT: $\veps>0, B_0\ib \RR^n$ is a box.
			\lline[5] such that $\ivp(B_0,1)$ is valid.
			\lline[0] OUTPUT: $\ulB_0, \olB_1$ are boxes in $\RR^n$
			\lline[5] with $\ulB_0\ib B_0$, $\wmax(\olB_1)<\eps$
			\lline[5] and $\olB_1$ is an end-enclosure of
						$\ivp(\ulB_0,1)$.
		}
	}%
	
	\issacArxiv{
		This is called the \dt{Reachability Problem} in
		the non-linear control systems and verification literature
		(e.g.,	\cite{shen+2:tight-reach:21}).
			% (e.g., \cite{fan+3:simulation-reach:17}),
		}%
    The input to $\endEncIVP(B_0,\veps)$ is assumed to be
	valid;  see the precise definition in
%%% SHOULD turn into an automatic label:	
	\refSSec{Notations}
	below.  Note that we also allow $B_0$ to be shrunk to some
	$\ulB_0$ in order to satisfy a user-specified
	error bound of $\veps$.  This is a novel feature that
	will prove very useful.
    
%\ssect{New Ideas?}
\input{inc/new-ideas}

%\ssect{What is new?}
\input{inc/what-is-new}

%\ssect{Review}
\input{inc/review}
	
% Remarks about our new notations
One of the barriers to the validated IVP literature
	is its cumbersome notations and lack of precise
	input/output criteria for its algorithms.
	We provide a streamlined notation by exploiting
	the autonomous nature of our ODE, and introducing
	high-level data structures such as the scaffold.

\ssect{Paper Overview}
	%%
	The remainder of the paper is organized as follows: 
	\dt{Section 2} introduces some key concepts and computational tools. 
	\dt{Section 3} gives an overview of our algorithm.
	\dt{Section 4} describes our \stepA\ and \stepB\ subroutines.
	\dt{Section 5} compares our transform approach to
		the classic Euler in a suitable local neighborhood.
	\dt{Section 6} describes the \Extend\ and \Refine\ subroutines.
	\dt{Section 7} presents our end-enclosure algorithm and some experiments.
	We conclude in \dt{Section 8}.
	\issacArxiv[
		\dt{Appendix A} gives some critical proofs. Due
		to space limitation, the remaining proofs
		in found in arXiv \cite{zhang-yap:ivp:25arxiv}.
	]{
		\dt{Appendix A} gives all the proofs.
		\dt{Appendix B} provide details of the affine
		transform $\olpi$.
	}
	

	\ignore{
	In Sections 8 and 9, we present the theoretical details of our
		refinement method, with Section 8 addressing the case where the
		logarithmic norm is negative and Section 9 covering the case where
		the logarithmic norm is non-negative. 
	Finally, in Section 10, we provide the algorithmic details of our
		method and prove that it is guaranteed to terminate.

	Appendix???
	}
	

	%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	
%	A common scheme in Validated IVP is the 2-step scheme:
%	Step A is finds an initial step size
%	and an domain of existence and uniqueness of solution;
%	Step B refinds the domain of Step A (possibly
%	reducing the step size).
%
%	Besides certified computation (or interval methods),
%		this is of interest for verification research.
%	E.g., Kellison-Appel \cite{kellison-appel:verified-ode:22}
%	developed a framework based on the Coq Proof assistant to
%	verify the accuracy and correctness of ODEs.
%	
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Basic Tools}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssectL[Notations]{Notations and Key Concepts}
	%The basic notations are gathered in Appendix 1 for quick reference.
	We use bold fonts such as $\bfx$ for vectors.
	A point $\bfp\in \RR^n$ is viewed
	as a column vector $\bfp=[p_1\dd p_n]$,
	with transpose the row vector $\bfp\tr =(p_1\dd p_n)$.
	Also vector-matrix or matrix-matrix
	products are indicated by $\Bigcdot$ (e.g., $A\Bigcdot \bfp$).
	Let $\intbox\RR^n$ denote the set of $n$-dimensional \dt{boxes} in
	$\RR^n$ where a box $B$ is viewed as a subset of $\RR^n$. 
	The \dt{width} and \dt{midpoint} of
	an interval $I = [a, b]$ are $w(I) \as b - a$ and $m(I)
	\as (a + b) / 2$, respectively.
	If $B = \prod_{i=1}^n I_i$, its \dt{width} and \dt{midpoint} are
		$\bfw(B) \as (w(I_1)\dd w(I_n))$ and
		$\bfm(B) \as (m(I_1) \dd m(I_n))$.
	Also, \dt{maximum width} and \dt{minimum width} are \\
	$\wmax(B)\as \max_{i=1}^n w(I_i)$ and
	$\wmin(B)\as \min_{i=1}^n w(I_i).$
	We assume $\wmin(B)>0$ for boxes.
	
	We use the Euclidean norm on $\RR^n$, writing 
	$\|\bfp\|=\|\bfp\|_2$.
	For any function $f: X \to Y$, we
	re-use `$f$' to denote its \dt{natural set extension},
	$f:2^X\to 2^Y$ where $2^X$ is the power set of $X$ and
	$f(S)=\set{f(x): x\in S}$ for all $S\ib X$.

	\ignore{
	Let $C^k([0, h] \to \RR^n)$ be
	the set of $C^k$-continuous functions ($k \geq 0$)
	from $[0, h]$ to $\RR^n$.
	Assume that the set of solutions
	$\ivp(B_0, h)$ is a subset of $C^\infty([0, h] \to \RR^n)$.

	Now, consider $\bfx \in C^2([0, h] \to \RR^n)$. If
	$\bfx \in \ivp(B_0, h)$,
	it satisfies the set of solutions to \refeq{bfx'},
	where any solution $\bfx$ to $\IVP(B_0, 1)$ belongs to
	$C^2([0, 1] \to \RR^n)$.
	In particular, $\bfx(t)$ is defined and bounded for all
	$t \in [0, 1]$. 
	However, $\ivp(B_0, 1)$ might not always have a solution.
	Specifically, if $\bfx(0) \in B_0$ leads to $\bfx(t)$ becoming
	undefined for some $t \in (0, 1]$, the system lacks a valid
	solution.

	E.g., $n=1$ then \refeq{bfx'} 
	 $x'=x^2$ has solution $x(t)= \efrac{x_0\inv -t}$, $x(0)=x_0$
	 to $\IVP(x_0,1)$.  If $B_0\ib [1,\infty)$ then $\IVP(B_0,1)$
	 has no solutions since $x(t)=\infty$ for
	 when $t=1/x_0 \in [0,1]$.  To avoid this issue, we assume
	 the promise problem in which 
	 $\IVP(\bfp_0, 1)$ is assumed to have
	 a solution for all $\bfp_0 \in B_0$.
	}%

	The \dt{image} of a function $f: A \to B$ is
		$\image(f) \as \set{f(a) : a \in A}.$  
	The \dt{image} of $\ivp(B_0, h)$ is the union
		$\bigcup_{\bfx \in \ivp(B_0, h)} \image(\bfx)$.
		% \image(\ivp(B_0, h)) \as
		%	\bigcup_{\bfx \in \ivp(B_0, h)} \image(\bfx).
		%  
	A \dt{full-enclosure} of $\ivp(B_0, h)$ is a
	set $B_1\ib\RR^n$ that contains\\
		$\image(\ivp(B_0, h))$.
	If, in addition, $(B_0,h)$ is well-defined,
	then call $(B_0,h,B_1)$ an \dt{admissible triple},
	equivalently, $(h,B_1)$ is an \dt{admissible pair} for $B_0$.
	We then write $\ivp(B_0,h,B_1)$ instead of $\ivp(B_0,h)$.
	%%%
	Finally, $\ulB_1\ib B_1$ is
	an \dt{end-enclosure} for $\ivp(B_0, h, B_1)$
	if for all solution $\bfx \in \ivp(B_0, h, B_1)$, 
	we have $\bfx(h) \in \ulB_1$.  Call $(B_0,h,B_1,\ulB_1)$
	an \dt{admissible quadruple} (or quad).

	\ignore{
	If $P$ is a problem or an algorithm, its header has
	the format 
		``$P(...inputs)\ssa (outputs...)$''.
	This is illustrated in the introduction by
	$\endEncIVP(B_0,\veps)\ssa (\ulB_0,\olB_1)$.
	Moreover, the exact relation between $(inputs..., outputs...)$
	will be explicitly stated.
	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{The End-Enclosure Problem for IVP}
	\dt{Validity.} We say 
	  $\ivp(B_0, h)$ is \dt{valid} if
	  (i) $\ivp(B_0,h)$ is well-defined, and
	  (ii) $\0 \nin \bff(\image(\ivp(B_0,h)))$.

	  
	Condition (ii) is equivalent to requiring that
	for all $\bfx\in \ivp(B_0,h)$, and all $t \in [0, h]$,  
	we have $\bfx'(t) \neq \0$.
	%%
	If $\bff(\bfq)=\0$, we call $\bfq$
	an \dt{equilibrium point} of $\bff$.  So condition (ii)
	says that $\image(\bfx)$ does not contain any equilibrium
	point.
	Note that condition (i) does not imply condition
	(ii). For example, the one dimensional equation  
	  $x' = f(x) = 3x^{\frac{2}{3}}$,  
	  with initial condition $x(0) = -\frac{1}{8}$ has a
	  well-defined solution $x(t) = (t - \frac{1}{2})^3$, 
	  but $f(x(\frac{1}{2})) = 0$.  

	\savespace{
	  Another example for $n=2$ is the system:  
	  \[
	  	\mmat{x'\\ y'} = \mmat{f_1\\ f_2}
			=\mmat{ x + \frac{\sqrt{e}}{\sqrt{e} - 1}\\
	  			x - y + \frac{\sqrt{e} + 1}{2\sqrt{e} - 2}}  
	  \]  
	  with the initial condition $[x, y] = [1, 1]$. One can check that
	  $f_1=f_2=0$ when $t=0.5$.
	}

	\savespace{	
		It is not strictly necessary to assume $\ivp(B_0, 1)$ is
		valid. It is enough
		to know a point $\bfp_0$ in the interior of $B_0$
		such that $\ivp(\bfp_0,1)$ is valid.
		Our current algorithm can be defined to shrink
		towards $\bfp_0$, and halting can be assured.
	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Normalized Taylor Coefficients}
	For any solution $\bfx$ to the
	ODE \refeq{bfx'}, its $i$th \dt{normalized Taylor coefficient}
	is recursively defined as follows:
		\beql{normalizedTaylorCoef}
			\bff\supn[i](\bfx) =
					\clauses{ \bfx & \rmif\ i=0,\\
						\efrac{i} \Big( J_{\bff\supn[i-1]} \cdot
						\bff\Big)(\bfx) & \rmif\ i\ge 1}
		\eeql
	where $J_\bfg$ denotes the Jacobian of any function
	$\bfg=\bfg(\bfx)\in C^1(\RR^n\to\RR^n)$
	in the variable $\bfx=(x_1\dd x_n)$.
	For instance,
		$\bff\supn[1] = \bff$
	and
		$\bff\supn[2](\bfx) = \half (J_\bff\cdot \bff)(\bfx).$
	It follows that the order $k\ge 1$ Taylor expansion of $\bfx$
	at the point $t=t_0$ is
		$$\bfx(t_0+h) = \Big\{
				\sum_{i=0}^{k-1} h^i \bff\supn[i](\bfx(t_0)) \Big\}
					+ h^k \bff\supn[k](\bfx(\xi))
		$$
	where $0\le \xi-t_0 \le h$. 
	If $\bfx(\xi)$ lies in a box $B\in\intbox\RR^n$,
	then interval form is
		\beql{taylor}
			\bfx(t_0+h) \in \Big\{
				\sum_{i=0}^{k-1} h^i \bff\supn[i](\bfx(t_0)) \Big\}
					+ h^k \bff\supn[k](B) \eeql
	These Taylor coefficients
	can be automatically generated, and they can be evaluated
	at interval values using automatic
	differentiation. % (e.g., \cite{moore:diffEqn:09}).

	\savespace{
	\dt{Running Example}:
		Let $\bff = \mmat{x^2+1\\ -y^2+7x}$.
		Then
			{\small \beqarrys
			\bff\supn[1] &=& \bff(\bfx)\\
			\bff\supn[2] &=& \half (J_\bff\cdot \bff)(x,y)\\
				%&=& \half \mmat{2x & 0\\ 7 &-2y}\cdot 
				%			\mmat{x^2+1\\ -y^2+7x} \\
				%&=& \half \mmat{2x(x^2+1)\\ 7x^2+7-2y(7x-y^2)}\\
				&=& \half \mmat{2x(x^2+1)\\ 7(x^2+1-2yx)+2y^3}\\
			\bff\supn[3] &=& \frac{1}{3}(J_\bff\supn[2]\cdot \bff)(x,y)\\
			%&=& \frac{1}{3} \mmat{3x^2+1 & 0\\ 7(x-y) &3y^2-7x}\cdot 
			%\mmat{x^2+1\\ -y^2+7x} \\
			%&=& \frac{1}{3} \mmat{(3x^2+1)(x^2+1)\\
			%		-3y^4+7x^3-7x^2y+28xy^2-49x^2+7x-7y}\\
			&=& \frac{1}{3} \mmat{(3x^2+1)(x^2+1)\\
					-3y^4+7(x^3-x^2y+4xy^2-7x^2+x-y)}.
			\eeqarrys
			}%small
	}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Banach Spaces $Y\ib X$}
	Proving that $\ivp(B_0,h)$ is well-defined
	depends on Banach space theory.
	%%
	Let $C^k([0, h] \to \RR^n)$ be
	the set of $C^k$-continuous functions ($k \geq 0$)
	from $[0, h]$ to $\RR^n$.
	%%
	We can view $\ivp(B_0, h)$ as
	a subset of $X \as C^0([0, h] \to \RR^n)$.
	%% no need!
	% View an element $\bfx\in X$ as a vector of functions,
	%	$\bfx=(x_1\dd x_n)$ where
	%	$x_i\in C^0([0,h]\to\RR)$ ($i=1\dd n$).
	%%
	% Call $X$ the \dt{solution space}
	% since each $\bfx\in X$ is a potential solution to our IVP.
	
	% \bitem
	% \item
		$X$ is a real linear space where
		$c\in\RR$ and $\bfx,\bfy\in X$ implies
		$c\bfy\in X$ and
		$\bfx\pm \bfy\in X$.
		Let $\0\in X$ denote the additive identity
		in $X$: $\bfx\pm \0=\bfx$.
	%\item
		$X$ is also a normed space with norm 
			$\|\bfx\|=\|\bfx\|_{\max} \as
			\max_{t\in [0,h]} \|\bfx(t)\|_{2}$
		where $\|\cdot\|_{2}$ is the $2$-norm.
		For simplicity, write $\|\bfx\|$ for $\|\bfx\|_{\max}$.
		If $S\ib X$, we let
			$\|S\|\as \sup_{\bfx\in S}\|\bfx\|$.
		%%%
	%\item
		We turn $X$ into a complete metric space $(X,d)$
		with metric $d(x,y)= \|x-y\|$.
	%\item
		To prove existence and uniqueness of solutions, we need
		to consider a compact subset $Y\ib X$.
		E.g., let $Y= C([0,h]\to B)$
		where $B\ib \RR^n$ is a box or ball.
		Then $Y$ is also a complete metric space induced by $X$.

	\savespace{
	\item
		Two functions $f:A\to B$ and $g:A\to C$
		are said to be \dt{equivalent} if for all $x\in A$, $f(x)=g(x)$. 
		In particular, this implies that $\image(f)=\image(g)$.
		We are interested in functions up to equivalence.
		E.g., if $\bfx\in C([0,h]\to\RR^n)$, and $B$ is a ball, we 
		want to know if $\bfx$ is equivalent to some function
		in $C([0,h]\to B)$.
	\item	
		We say a sequence $(\bfx_n: n\in \NN)$ in $X$
		\dt{converges uniformly} to $\bfy\in X$ if for all $t\in[0,h]$,
			\beql{unif}
				\lim_{n\to\infty} \|\bfx_n(t)-\bfy(t)\| =0.\eeql
		% See
		% \myHref{https://en.wikipedia.org/wiki/Uniform\_convergence}{wikipedia}.
		\ignore{
		follows from the fact that $\infty$-norm is a norm:
		$\|\bfx(t)\|_{\infty}+\|\bfy(t)\|_{\infty} \le
		\|\bfx(t)+\bfy(t)\|_{\infty}$.
	}
	\item
		Now $X$ becomes a metric space $(X,d)$
		with metric $d(x,y)= \|x-y\|$.
		It is a complete metric space since the limit
		of a converging sequence in $X$ lies in $X$.
		%%%
		%% Stronger: it is a Hilbert space
		Thus, $(X,d)$ is\footnote{
			Note that a Banach space, unlike a Hilbert
			space, does not have an inner product.
			Following Soderlind, we could define
			a \dt{semi-inner product} for Banach spaces.
		} a Banach space.
	\item
		(Uniform limit theorem)
		If a sequence $(\bfx_n: n\in\NN)$
		in $X$ is uniformly convergent to some function $\bfx_*$,
		then $\bfx_*$ is continuous and belongs to $X$.
	}%
	%\eitem
	%%
	Using this theory, we can prove the following result
	\cite[Theorem 1]{nedialkov-jackson-pryce:HOI:01}:
	
	\blemT[admiss]{Admissible Triple}
		\ \\
		For all $k\ge 1$, if
		$E_0, F_1\ib \RR^n$ and $h>0$ satisfy the inclusion
		\beql{tay}
			\sum_{i=0}^{k-1}
		 	[0,h]^i \bff^{[i]}(E_0)+[0,h]^k \bff^{[k]}(F_1)
				\subseteq F_1,
		 \eeql
		then $(E_0,h,F_1)$ is an admissible triple.
	\elemT
	For simplicity, assume $k\ge 1$ is a global constant in this
	paper.  


	\ignore{
		Show that \refeq{unif} amounts to the usual def of uniform
		convergence.  Oh, it is direct.
	}
	
	\savespace{
	\bfac If a sequence $(\bfx_n: n\in\NN)$
	in $X$ is uniformly convergent to some function $\bfx_*$,
	then $\bfx_*$ is continuous and belongs to $X$.
	\efac
	}
	\ignore{
		This is also called the
		\myHref{https://en.wikipedia.org/wiki/Uniform\_limit\_theorem}
		{Uniform Limit Theorem (wiki)}.
		}%
	%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ssect{The Picard Operator $T$ of an IVP.}
	%	A function of the form $T:X\to X$ is usually called an
	%	\dt{operator}
	%	(or transformation).
	%	The result of applying the operator $T$ to $\bfx\in X$
	%	is typically written $T[\bfx]$ instead of $T(\bfx)$.
	%	
	%	\Ldent\progb{
	%		\lline[0] IVP$(\bff,\bfp_0)$:
	%		\lline[5] Given $(\bff,\bfp_0)$,
	%		\lline[5] find some $\bfx\in X$ satisfying \refeq{ivp}
	%	}
	%	\beql{ivp}
	%	\bfx' = \bff(\bfx),\qquad \bfx(0)=\bfp_0\in\RR^n
	%	\eeql
	%	
	%	The \dt{Picard operator} for IVP$(\bff,\bfp_0)$ 
	%	is defined as follows:
	%	for all $t\in [0,1]$ and $\bfx\in X$,
	%	\beql{pic}
	%		T[\bfx](t) = \bfx_0 + \int_{0}^t \bff(\bfx(s))ds.
	%	\eeql
	%	We observe that if $\bff(\bfx)$ is continuous
	%	then $T[\bfx]$ uniformly continuous and differentiable on $[0,1]$
	%	%%% 	p.7, picard.pdf
	%	(by the First Fundamental Theorem of Calculus).
	%	% see 
	%	% \myHref{https://en.wikipedia.org/wiki/Fundamental\_theorem\_of\_calculus}
	%	%	{wiki}
	%	
	%	Next, a fixed point $\bfx_*$ of this operator satisfies
	%	$T[\bfx_*]=\bfx_*$ is clearly a solution to the
	%	IVP problem \refeq{ivp}.  To find such a fixed point,
	%	we compute the iterative sequence
	%	\beql{seq}
	%	(\bfx_0,\bfx_1,\ldots)\quad\text{where}\quad
	%	\bfx_{i} =\clauses{ \bfp_0 & \rmif\  i=0,\\
	%		T[\bfx_{i-1}] & \rmif\ i\ge 1.}
	%	\eeql
	%	The classic tool for proving 
	%	the convergence of the sequence \refeq{seq} is given by
	%	the next theorem.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%\ssect{Contraction Maps}
	%	Let $(Y,d)$ be a complete metric space, and $f:Y\to Y$.
	%	We have two related definitions:
	%	\\ (a) Call $f$ a \dt{weak contraction map} of $Y$
	%	if for all $x,y\in Y$, $d(f(x),f(y)< d(x,y)$.
	%	\\ (b) Call $f$ a \dt{contraction map} of $Y$ if
	%	there is constant $k\in [0,1)$ such that for
	%	all $x,y\in Y$, $d(f(x),f(y))\le k d(x,y)$.
	%	
	%	\bthmT[banach]{Banach Fixed Point Theorem}
	%	Consider the following two conditions on $f:Y\to Y$:
	%	\\ (a) $f$ is a contraction map.
	%	\\ (b) $f$ is a weak contraction map,
	%	and $Y$ is a compact space.
	%	\\ Either (a) or (b) implies the following:
	%	\benum[(i)]
	%	\item $f$ has a fixed point $y_*$,
	%	i.e., $f(y_*)=y_*$.
	%	\item This fixed point is unique.
	%	\item For all $y_0\in Y$, the infinite sequence
	%			$$(y_i: i\in\NN)\quad\text{where}\quad
	%					y_i=f(y_{i-1}) \text{ for }i\ge 1$$
	%	converges to $y_*$.
	%	\eenum
	%	\ethmT
	%	See \myHref{https://en.wikipedia.org/wiki/Banach\_fixed-point\_theorem}
	%	{wiki: Banach fpt}.
	%	and \myHref{https://en.wikipedia.org/wiki/Metric\_space\#Lipschitz\_maps\_and\_contractions}
	%	{wiki: Lipschitz constraction maps}.
	%	
	%	REMARK: the uniqueness part (ii) distinguishes
	%	Banach's Fixed Point theorem from some other fixed point
	%	theorems (notably, Brouwer's or Schauder's Fixed Point Theorem)
	%	which do not guaranteed uniqueness.
	%	See enclosed
	%	\myHref{https://en.wikipedia.org/wiki/Brouwer\_fixed-point\_theorem}
	%	{wiki: Brouwer fpt}.
	%	The long article is downloaded here (surf8).
	%
	%	\chee{Question: suppose we apply the Picard operator $T$
	%	to the leaky bucket example of Hubbard-West, which
	%	has non-unique solutions from  a fixed initial value.
	%	What is the fixed point of $T$?}
	%	
	%	\ignore{% obsolete:
	%		If $\bfx,\bfy\in\Sol(I)$ and $c\in\RR$, then 
	%		$c\cdot\bfx\pm \bfy\in\Sol(I)$.
	%		Thus, $\Sol(I)$ is a real vector space.
	%		
	%		Norm:
	%		(1) Positivity: $\|x\|\ge 0$ with equality iff $x=0$
	%		(2) Absolute homogeneity: $\|cx\| = |c|.\|x\|$
	%		(3) Triangle inequality: $\|x+y\|\le \|x\|+\|y\|$.
	%		It also has a norm given by
	%		$\|\bfx\| \as$
	%		Thus $\Sol(I)$ is a metric space with distance function
	%		$d(\bfx,\bfy)=\|\bfx-\bfy\|$.
	%		
	%		\myHref{https://en.wikipedia.org/wiki/Infinite-dimensional\_vector\_function}
	%		{wiki: infinite dimensional vector spaces}
	%		
	%		An \dt{infinite dimensional vector function} is
	%		whose values lies in an infinite dimensional topological vector
	%		space.  Most theorems in differentiation and integration
	%		on scalar functions can be generalized of vector functions.
	%		It is straightforward for finite dimensional vector functions,
	%		hence the focus on infinite dimensional case.
	%		
	%		Let $f:[0,1]\to X$ where $X$ is a topological vector space.
	%		Then $f'$ (differentiation wrt $t\in [0,1]$) can be defined
	%		in the usual way.
	%		
	%		WHAT ABOUT NORMS for $f$?  See Lp-spaces:
	%		https://en.wikipedia.org/wiki/Lp_space
	%		For $1\le p\le \infty$,
	%		$$\|f\|_p = \Big(\int_I |f(m)|^p dm\Big)^{1/p}$$
	%	}%ignore
	%	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%




 
 







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssectL[lognorm]{Logarithmic norms}
	Let $\|A\|_p$ be the induced $p$-norm of a square matrix $A$.
	Then the \dt{logarithmic $p$-norm} of $A$ is defined as
		\[\mu_p(A) \as \lim_{h\to 0+}\frac{\|I+hA\|_p-1}{h}.\]
	%If $p$ is understood, we may just call $\mu_p$ the logarithmic norm.
	We shall focus on $p=2$, and call $\mu_2$ the \lognorm.
	
	%Proposition:	Let the  linear dynamical system be
		%$\stackrel{.}{x}(t)=Ax+r$, then $\partial^{+}\|x(t)\|\le
		%\mu(A)\cdot \|x\|+\|r(t)\|$.
	%
	%Let function $R(z)$ approximates $e^hA$ by the rational
	%matrix function $R(hA)$, then \[\mu(A)=\lim_{h\to 0+}\frac{R(hA)-1}{h}.\]
	%
	%Let $f : D \subset X \to X$.  Define two functions, the least upper
	%bound (lub)
	%and greatest lower bound (glb) Lipschitz constants,by
	%\[L[f]=sup_{u\ne v}\frac{\|f(u)-f(v)\|}{\|u-v\|}; l[f]
		%=\inf_{u\ne v}\frac{\|f(u)-f(v)\|}{\|u-v\|}.\]
	%Denote \[M[f]= \lim_{h\to 0+}\frac{L[I+hf]-1}{h}; m[f]
		%=\lim_{h\to 0+}\frac{l[I+hf]-1}{h}.\]
	%
	%Proposition: $M[A]=\mu(A)$
	%
	%It follows that $L[f]$ and $l[f]$ are upper and lower bounds for the
	%moduli of the eigenvalues of $f'(x)$ when $x\in D$. Similarly,
	%$M[f]$ and $m[f]$ are upper and lower bounds, respectively, for the
	%real parts of the eigenvalues.
	%
	%Let Gerschgorin domain of $f$ is $G[f]$. Then $M[f]=max{Re\lambda:
	%\lambda \in G[f] }$ and $m[f]=min{Re\lambda: \lambda\in G[f]}$.
	%
	%The difference between two solutions $x_1$ and $x_2$ to
	% $\stackrel{.}{x}(t) = f(t,x)$ satisfies the differential inequality
	%\[\partial^{+}\|x_1-x_2\|\le M[f]\cdot \|x_1-x_2\|.\]
	%
	%Then $\|x_1-x_2\|\le e^{tM[f]}\|x_1(0)-x_2(0)\|$
	
	We have these bounds for \lognorm:
	\bleml[lognorm] \ 
	\benum[(a)]
	\item
		$\mu_p(A+B)\le \mu_p(A)+\mu_p(B)$
	\item
		$\mu_p(A)\le \|A\|_p$
	\item
		$\mu_2(A)=\max_{j=1\dd k}(\frac{1}{2}(\lambda_{j} (A+A^T)))$
			where $\lambda_1(A)\dd \lambda_k(A)$
			is the set of eigenvalues of $A$.
	\item
		Let $A$ be an $n\times n$ matrix  and let
		$\max_{i=1}^n (\Re(\lambda_i))$ where
		$\lambda_i's$ are the eigenvalues of $A$.
		Then
		\bitem
			\item $\max_{i=1}^n (\Re(\lambda_i))\le
					\mu(A)$ holds for any \lognorm.
			\item For any $\veps \ge 0$, there exists an
				invertible matrix $P$ such that 
			\[\max_i(Re(\lambda_i))\le \mu_{2,P}(A)\le
				\max_i(Re(\lambda_i))+\veps.\]
			where $\mu_{2,P}(A)\as \mu_2(P^{-1}AP).$
		\eitem
	\eenum
	\eleml
	For parts(a-c) see
		\cite{desoer-haneda:measure:72},
	and part(d), see
		Pao \cite{pao:log-der-matrix:73}.
	In our estimates, we cite these standard bounds:
	\beql{matrixnorm}
		\grouping[l l c l ]{
		\|A\|_2 &=&		\max_i(\sqrt{\lambda_{i}(A^*A)})\\
		\|AB\|_2 &\le&	\|A\|_2\|B\|_2
		}
	\eeql

\savespace{
	We will use these standard bounds on norms.
	\bleml[matrixnorm] \
	\benum[(a)]
	\item
		$\|A\|_2=\max_i(\sqrt{\lambda_{i}(A^*A)})$
	\item $\|AB\|_2\le \|A\|_2\|B\|_2$
	\eenum
	\eleml
}

	
%	Let $P$ be an invertible matrix then we have
	%	Then, by choosing different matrix norms, we can obtain different
	%	measures of a matrix.
	%	
	%	
	%	\begin{eqnarray}
	%		\mu_1(A)=ma\textbf{x}_j(a_{j,j}+\sum_{i\ne j}|a_{i,j}|)\\
	%		\mu_2(A)=ma\textbf{x}_j\frac{1}{2}(\lambda_{j} (A+A^T))\\
	%		\mu_{\infty}(A)=ma\textbf{x}_i(a_{i,i}+\sum_{j\ne i}|a_{i,j}|)\\
	%		\mu_{2,P}(A)=\mu_2(PAP^{-1}).
	%	\end{eqnarray}
	
%	\begin{theorem}\cite{pao:log-der-matrix:73}\label{Thm-estmu}
%		Let $A$ be any $n\times n$ matrix  and let $\lambda_1\dd
%		\lambda_n$ be the eigenvalue of $A$. Let $\max_i(Re(\lambda_i))$
%		be the maximum real part eigenvalue of $A$.
%		Then, the following statements are true:
%		\begin{enumerate}
%			\item $\max_i(Re(\lambda_i))\le \mu(A)$ holds for any matrix norm.
%			\item For any $\veps \ge 0$, there exists a matrix $P$ such that 
%			\[\max_i(Re(\lambda_i))\le \mu_{2,P}(A)\le
%				\max_i(Re(\lambda_i))+\veps.\]
%		\end{enumerate}
%	\end{theorem}
%	
%	\dt{Remark}
%		Let $A$ be a matrix we define  $\max_i(Re(\lambda_i(A)))$ be the
%		maximum real part eigenvalue of $A$. 
%	We choose  a matrix $P$ such that  the columns of $P$ be the real and
%	imaginary parts of a full set of
%	eigenvectors of $A$. If $A$ is nearly defective, one should instead
%	choose linearly
%	independent basis vectors from low dimensional subspaces.
%	Then from linear algebra, we know that $P^{-1}AP$ is close to being
%	symmetric or anti-symmetric, see \cite{neumaier:taylor-forms:03} for
%	details. Thus, we have  $\mu_{2,P}(A)$ approaches
%	$\max_i(Re(\lambda_i(A)))$.
%	We use  $P(A)$ to represent such  $P$ matrix.
%	
%	
%	
%	From Theorem \ref{Thm-estmu}, for a given matrix $ A $, we can
%	estimate $ \mu(A) $ by using $ \max_i(Re(\lambda_i)) $.
%	The measure of the matrix can be used to estimate the range of the
%	solution of the IVP through the following theorem:
	
	We have the following result from Neumaier
	\citep[Corollary 4.5]{neumaier:rigorous-bds:93}:

	%\begin{theorem}
	\bthmT[ne]{Neumaier} \
	%\cite[Corollary 4.5]{neumaier:rigorous-bds:93}\\
		Let $\bfx\in \ivp_\bff(\bfp_0,h)$
		and $\xi(t)\in C^1([0,h]\to \mathbb{R}^n)$
		be any ``approximate solution''. Let\footnote{
			For our purposes, matrix $P$ in this theorem can be the
			identity matrix.
		}
		$P$ be an invertible matrix.
		Assume the constants $\veps,\delta,\olmu$ satisfy

		\begin{enumerate}
			\item 
				$\veps \ge
					\|P\inv\Bigcdot(\xi'(t) - \bff(\xi(t)))\|_2$
				for all $t \in [0, h]$ 
			\item
				$\delta \ge 
					\|P\inv\Bigcdot(\xi(0)-\bfp_0)\|_2 $
			\item 
				$\olmu \ge
					\mu_2  \big(P\inv\Bigcdot J_{\bff}(s\bfx(t) +
					(1-s)\xi(t))\Bigcdot P\big)$
				for all $s \in [0,1]$ and $t \in [0, h]$
		\end{enumerate} 
		Then for all $t \in [0, h]$,
		\beql{xibfx}
			\|P\inv\Bigcdot(\xi - \bfx)\|_2 \le
				\begin{cases}
			\delta e^{\olmu|t |} + \frac{\veps}{\olmu}(e^{\olmu|t|} - 1),
					& \olmu \ne 0, \\
			\delta + \veps t, & \olmu = 0.
				\end{cases}
		\eeql
	%\end{theorem}
	\ethmT
	
	\bcorl[cor-1] \ \\
		Let $\bfx_1,\bfx_2 \in \ivp(\bfp_1,h,Ball(\bfp_0,r))$ and
		$\olmu\ge \mu_2(J_\bff(Ball(\bfp_0,r)))$.
		 Then for all $t\in [0,h]$
		  \beql{bfx12}
		  	\|\bfx_1(t)-\bfx_2(t)\|_2
		  		\le \|\bfx_1(0)-\bfx_2(0)\|_2 e^{\olmu t}.\eeql 
	\ecorl
	\savespace{
		\bpf
		Note that $\bfx_1$ and $\bfx_2$ are solutions of \refeq{bfx'} with
		different initial values. Therefore, we have $\bfx'_1 = \bff(\bfx_1)$
		and $\bfx'_2 = \bff(\bfx_2)$. This implies that
			$$ \bfx'_1(t) - \bff(\bfx_1(t))
				= \bff(\bfx_1(t)) - \bff(\bfx_1(t)) = 0 = \veps. $$
		If $\olmu\ne 0$, then \refeq{bfx12} is the first case
		of \refeq{xibfx} since $\delta=\|\bfp_1-\bfp_2\|_2$.
		If $\olmu=0$, it comes from the second case since $\veps=0$.
		\epf
	}%	

	\blemT[eulerStep]{Enclosure for Euler Method}\ \\
		Let $(B_0,H,B_1)$ be admissible triple,
	$\olmu\ge \mu_2(J_{\bff}(B_1))$ and
	$ M\ge \|\bff^{[2]}(B_1)\|$.
	%%
	If $h_1>0$ is given by
	\beql{h1}
	h_1\ass h(H,M,\olmu,\veps) \as
	\begin{cases}
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)}}
		&\rmif\ \olmu\ge 0\\
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)-\olmu^2\veps}}
		&\rmif\ \olmu<0
	\end{cases}
	\eeql
	consider the path $Q_{h_1}=(\bfq_0,\bfq_1\dd \bfq_m)$ 
	from the Euler method with step-size $h_1$.
	If each $\bfq_i\in B_1$ ($i=0\dd m$),
	then for all $t\in [0,H]$, we have
	\beql{eulerBd}
	\|Q_{h_1}(t)-\bfx(t;\bfq_0)\|\le \veps.
	\eeql
	I.e., $Q_{h_1}(t)$ lies inside the $\veps$-tube of $\bfx(t;\bfq_0)$.
	\eleml

	
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%file: overview-new.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{Overview of our Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	We will develop an algorithm for the End-Enclosure
	Problem \refeq{endEncProb}, by elaborating
	on the classic Euler method or corrector-predictor
	framework for homotopy path 
	%	\cite[Algorithm 8.2.3, page XX]{sommese+2:intro-nag:1}
	(e.g., \cite{sommese+2:intro-nag:10,xu-burr-yap:homotopy:18}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Step A and B	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	The basic motif is to 
	repeatedly call two subroutines\footnote{
		Nediakov et al.~\cite{nedialkov+2:validated-ode:99}
		call them Algorithms I and II.
	}
	which we call \stepA\ and \stepB, respectively:
	\savespace{They correspond roughly
	to predictor/corrector steps of homotopy path methods.
	}
	
	% use image to get equation number!!!
	\beql{stepAB}
			\includegraphics[width=0.75\columnwidth]{figs/stepAB}
	\eeql
	
	% Note: these definitions has moved to myMac.sty
	%	but not to myMac-issac.sty:
\DeclareRobustCommand{\loongrightarrow}{%
  	\DOTSB \relbar\joinrel \relbar\joinrel
  		\relbar\joinrel \relbar\joinrel
		\rightarrow }
\DeclareRobustCommand{\looongrightarrow}{%
  \DOTSB \relbar\joinrel \relbar\joinrel
  		 \relbar\joinrel \relbar\joinrel
  		 \relbar\joinrel \relbar\joinrel \rightarrow }
	
	Thus we see this progression
		\beql{stepAstepB}
			E_0 \overset{\stepA}{\looongrightarrow}
			(E_0,h_0,F_1) \overset{\stepB}{\looongrightarrow}
			(E_0,h_0,F_1,E_1) 
		\eeql
	where $\stepA$ and $\stepB$ successively
	transforms $E_0$ to an admissible triple and quad.
	By iterating \refeq{stepAstepB} with $E_1$ we can get to
	the next quad $(E_1, h_1, F_2,E_2)$, and so on.  {\em This is
	the basis of most validated IVP algorithms.}
	We encode this as:
		\beql{simpleivp}
			\includegraphics[width=0.8\columnwidth]{figs/simpleivp}
		\eeql
	
	Note that the iteration of \refeq{stepAstepB}
	above is not guaranteed to halt (i.e.,
	to reach $t=1$).  Moreover, we have no control over the length of
	the end-enclosure.
	% \end{Example}
	To address this, define an \dt{$\veps$-admissible triple}
	to be an admissible $(E_0,h,F_1)$ with 	
	\beql{eps-admiss}
	h^k\bff^{[k]}(F_1) \ib[-\veps,\veps]^n
	\eeql
	and extend $\stepA$ to:

	\beql{stepA}
		\includegraphics[width=0.75\columnwidth]{figs/stepA+}
	\eeql
	See \refLem{admiss} for the context of this definition.
	\ignore{
	\Ldent\progb{	
		\lline[-2] $\stepA(E_0,\veps,H)\ssa (h,F_1)$:
		\lline[0] INPUT: $E_0\in\intbox\RR^n$, $0<H\le 1$ and $\veps>0$
		\lline[0] OUTPUT:  an $\veps$-admissible pair $(h,F_1)$
							for $E_0$
		\lline[10]		such that $h\le H$.
	}
	}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Scaffold
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	We introduce a data structure called a ``scaffold'' to encode the
	intermediate information needed for this computation.
	\refFig{explain-D} shows such a scaffold.
	% However, our algorithm will need to repeatedly
	% refine a partial trace of a computation
	% path. 

		\FigEPSissac{explain-D}{0.6}{
			A 7-step scaffold. The horizontal
			axis represents time, and the vertical axis represents
			$\RR^n$. The red curve corresponds to $\bfx(t)$, the blue
			line segments represent end-enclosures, and the green boxes,
			% projected onto the vertical axis,
			represent full-enclosures.
		}

	By a \dt{scaffold} we mean a triple
		$\calD =(\bft,\bfE,\bfF)$
	where
		$\bft= (0\le t_0 < t_1 < \cdots < t_m\le 1)$,
		$\bfE = (E_0 \dd E_m)$,
		and $\bfF = (F_0 \dd F_m)$ such that
		the following holds for all $i=0,1\dd m$:
	\benum
	\item $E_i$ is an end enclosure of
		$\ivp(E_{i-1},t_i-t_{i-1})$  for $i\ge 1$.
	\item $(E_{i-1}, \Delta t_i, F_i,E_i)$ is an admissible quadruple.
		% Call this quadruple the \dt{$i$th-stage} of the scaffold.
	%\item  $Box(E_{i-1}\cup E_i)\ib F_i$.
	\eenum
	
	For $i=1\dd m$, let
			$\Delta t_i\as  t_i-t_{i-1}$
	denote the $i$th \dt{step size}.  Call $\calD$
	an \dt{$m$-stage} scaffold where the $i$th \dt{stage}
	of $\calD$ is the admissible quadruple
			\beql{stage}
				(E_{i-1}, \Delta t_i, F_i, E_i).\eeql
	% The $i$th admissible triple is similarly defined.

	For $i=0\dd m$, the $i$th \dt{state} of $\calD$
	is $\calD[i]=(t_i, E_i, F_i)$.
	Thus, the initial and final states are $\calD[0]$ and $\calD[m]$,
	respectively.
	The \dt{end-} and \dt{full-enclosure} of $\calD$ is $E_m$ and $F_m$
	(respectively).  The \dt{time-span} of $\calD$ is the interval
	$[t_0,t_m]$, and $t_m$ is the \dt{end-time} of $\calD$.

\savespace{
	\bobs
	For any $m$-stage scaffold $\calD$, its end-enclosure
	$E_m$ is the end-enclosure for the $IVP(E_0,t_m-t_0)$.
	\eobs
	}%

	%%%
	In general, a state $(t',E',F')$ is called a \dt{refinement} of
	$(t,E,F)$ if $t=t'$ and $E'\ib E$ and $F'\ib F$.
	A $m'$-stage scaffold $\calD'$
	is called a \dt{refinement} of $\calD$ if 
	for any $i=0\dd m$, 
	there exists $j=0\dd m'$ such that
	$\calD'[j]$ is a refinement of $\calD[i]$.
	A $m'$-stage scaffold $\calD'$
	is called a \dt{extension} of an $m$-stage $\calD$ if $\calD$ is a
	prefix of $\calD'$ and $m'>m$.
	%%%
	An $m$-stage scaffold $\calD$
	is \dt{$\delta$-bounded} if for all $i=1\dd m$ we have:

	\beql{deltabound}
		\wmax(E_i)\le \wmax(E_{i-1})
			\cdot e^{\mu_2(J_{\bff}(F_i))(t_i-t_{i-1})}+2\delta.
	\eeql

	Next, we introduce the algorithm \Extend.
	
	% use image to get equation number!!!
		\beql{extend}
			\includegraphics[width=0.75\columnwidth]{figs/extend}
		\eeql


	\ignore{%
	\Ldent\progb{
		\lline[-2] 
			\Extend$(\calD, \veps,\delta, H)$ 
				$\ssa(\veps',\delta', \calD')$
		\lline[3] INPUT: A $\delta$-bounded $m$-stage scaffold $\calD$,
			$\veps>0$
		\lline[3] OUTPUT:  $\calD'$ is a $m+1$-stage 
		refinement of $\calD$,
		\lline[8]	 such that $\calD'$ is $\delta'$-bounded and
		\lline[8]	 $\wmax(E_{m+1})\le \veps'$
				and $t_{m+1}(\calD')\le t_{m}(\calD)+H$.
		}
	}%

	To bound the length of the end enclosure, we refine \(\calD\)
	whenever \(\wmax(E_m) > \veps\). 
		The interface for this \Refine\ algorithm is as follows:
	
	% use image to get equation number!!!
		\beql{refine}
			\includegraphics[width=0.75\columnwidth]{figs/refine}
		\eeql

	\ignore{%
	\Ldent\progb{
		\lline[0] $\Refine(\calD, \delta, \veps) \ssa(\delta',\calD')$  
		\lline[5] INPUT: A $\delta$-bounded  $m-$step scaffold $\calD$,
				$\delta>0,\veps>0$.
		\lline[5] OUTPUT:   
			$\delta'\le \delta$ and $\calD '$ is a $\delta'$-bounded
			$m'$-stage
		\lline[25] scaffold satisfies $\wmax(E_{m'})\le \veps.$}
	}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ssect{The Radical Transform: Key Lemma}
\input{inc/radical-xform}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	

















%%%%%%%%%%%%%%%%%%%%%% THE END -- EXTRA STUFF %%%%%%%%%%%%%%%%%%%%%%%%%%
	%	
	%	In addition, we provide an additional algorithm, referred to as Step
	%	A+: it iteratively reduces the parameters $\veps_1$ and $\delta$,
	%	repeating Step A until the resulting admissible pair passes
	%	\texttt{Verifyfull}$F_0$ and satisfies $h > \delta$, where 
	%	\texttt{Verifyfull}($F_0$) is macro used to verify some conditions
	%	for $F_0$. 
	%	
	%	\Ldent\progb{
	%		\lline[0] StepA+$(\delta,\veps,\calD )$  
	%		\lline[5] INPUT: $\bff$,  $\delta>0$, $\veps>0$,  $\calD $, $k>0$. 
	%		\lline[5] OUTPUT: $(\delta_0,\calD ',h>0,B)$,
	%				where $\delta_0\le \delta$, $\calD '$
	%		is $\delta_0-$ controlled, $(h,B) $ is the admissible pair.
	%		\lline[5] $\veps_1\ass \veps$.
	%		\lline[5] 	$(h,F_1 ) \ass$ \texttt{StepA}($\veps_1,\calD $) 
	%		\lline[15] While $Verifyfull(F_0)= 'false'$
	%		\lline[20]	$\delta\ass \frac{\delta}{2}$,
	%					$\veps_1\ass \frac{\veps_1}{2}$. 
	%		\lline[20] $\calD \ass$ Update$(\delta,\calD )$
	%		\lline[20] $(h,F_1)\ass$ \texttt{StepA}($\veps_1,\calD $).
	%		\lline[15] 	 While $h<\delta$  
	%		\lline[20] 	$\delta\ass \frac{\delta}{2}$. 
	%		\lline[20] $\calD \ass$ Update$(\delta,\calD )$
	%		\lline[20]  $(h,F_1)\ass$ \texttt{StepA}($\veps_1,\calD $).
	%		
	%		\lline[15] Return 
	%		$(\delta,\calD ,h,F_1 )$.
	%	}
	%	
	%	Next we consider our \texttt{Step B} algorithm.
	%	
	%
	%	
	%	In addition, we provide an additional algorithm, referred to as \texttt{StepB+} to ensure that the length of each end enclosure in $\calD '$ is less that $\veps$.
	%	
	%	
	%	\Ldent\progb{
	%		\lline[0] StepB+$( F_0,h,\delta,\calD )$  
	%		\lline[5] INPUT: $\bff$, $(h,F_1)$, $\delta>0$, $\veps$,  $\calD $,    
	%		\lline[5] OUTPUT: A value $\delta_0 \le \delta$ and $\calD '$
	%		\lline[5]	such that $\calD '$ is $\delta_0-$ controlled. 
	%		\lline[5] The length of each end enclosure in $\calD '$ is less that $\veps$.
	%		\lline[15] $c\ass \mu_2(J_{\bff}(F_0))$, $\delta_0\ass \delta$.
	%		\lline[15] $E_0, T$ are the last item of $G_{end},\bft$,respectively. 
	%		$r_0\ass \frac{length(E_0)}{2}$.
	%		\lline[15] While $r_0 e^{ch} +\delta_0 > \frac{\veps}{2}$
	%		\lline[20]  $ \delta_0\as \frac{\delta_0}{2}$,
	%		$\calD \ass$ Update$(\delta_0,\calD )$, 
	%		$E_0$ be the last item of $G_{end}$, $r_0\ass \frac{length(E_0)}{2}$.
	%		\lline[15] ($\calD ',\delta_0)\ass StepB(E_0,\delta_0,F_0,h)$
	%		\lline[15] $\calD \ass \calD;\calD '$.
	%		\lline[10] Return ($\delta_0,\calD $).
	%		
	%	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% REMOVED
	%The sub-algorithm \texttt{Shrink} in \texttt{Step B} as:
	
	
	
	%\Ldent\progb{
	%	\lline[0] Approximatepoints($E_0,\delta,F_0,h$)
	%	\lline[5] INPUT: $\bff$, $(h,F_1)$, $\delta>0, E_0$, where $(h,F_1)$ is an admissible pair for $E_0$.   
	%	\lline[5] OUTPUT: A step size $h_1<h$ and a point list $L=(\bfq_0\dd\bfq_{\lceil h/h_1 \rceil})$ satisfy:
	%
	%	\lline[5] $\bfq_{\lceil h/h_1 \rceil}$ is a $\delta$-distance point at time $h$. 
	%	\lline[5] For each $i=1\dd \lceil h/h_1 \rceil-1$, $\bfq_i$ is a $\delta$-distance point at time $ih_1$. 
	%
	%	
	%}
	
	%
	%\textbf{Step A:} 
	%Let $E_0$ and $T$ represent the last elements of $G_{end}$ and $\bft$, respectively. We then call \texttt{AdmissiblePair}($E_0,1 - T,\veps_1$) to obtain an $\veps$-admissible pair $(h,\ol{F_0})$, where $h$ is the step size  and $\ol{F_0}$ a full enclosure for $\bfx\in\ivp(\bfp_0,1)$ restrict to $[T,T+h]$.
	%
	%\textbf{Step A+:}
	%If $h \leq \delta$, we update $\delta \leftarrow \frac{\delta}{2}$, call \texttt{Update()} to compute new $\delta$-controlled $\calD $ and repeat the step.
	%
	%\textbf{Step A++:}
	%We call \texttt{Verifyfull}($\ol{F_0}$) to check whether the 
	%full enclosure $\ol{F_0}$ satisfies some conditions, which we will
	%introduce later.
	%If these conditions are not satisfied, we reduce $\delta \leftarrow \frac{\delta}{2}$ and $\veps_1 \leftarrow \frac{\veps_1}{2}$, call \texttt{Update}( $\calD ,\delta$), and repeat step A.
	%
	%
	%
	%\textbf{Step B:} 
	%In this step, we first compute a step size to $h_1 \leq h$. Then the time interval $[t_0, t_0 + h]$ is then subdivided into $\lceil \frac{h}{h_1} \rceil$ smaller segments:
	%
	%\[
	%[t_0, t_0 + h_1], \ldots, [t_0 + h - \lfloor \tfrac{h}{h_1} \rfloor h_1, t_0 + h].
	%\]
	%
	%For each subinterval, we compute both an end enclosure and a full enclosure. 
	%
	%\textbf{Step B+}
	%We  check whether the length of each end enclosure  less than $\veps$.
	%If this condition is not met, we update $\delta \leftarrow \frac{\delta}{2}$, call \texttt{Update}( $\calD ,\delta$), and repeat step B.
	%
	
	
	%\textbf{Step A: (Admissible Pair Computation)}
	%
	%\textbf{1. Inputs}:
	%\begin{itemize}
	%	\item $ E_0 $: The current enclosure, representing the last element of the set $ G_{end} $.
	%	\item $ T $: The final time value in the vector $ \bft $,
	% representing the current time step.
	%	\item $ \veps_1 $: The initial precision parameter.
	%	\item $\delta$: The initial step size parameter.
	%\end{itemize}
	%
	%\textbf{2. Outputs}:
	%\begin{itemize}
	%	\item $\delta$: A step size parameter.
	%	\item $\delta$-controlled $\calD $.
	%	\item $h$: The step size satisfies $h> \delta$.
	%	\item $\ol{F_0}$: A full enclosure for $ \bfx \in \ivp(\bfp_0, 1) $
	% restricted to the interval $ [T, T + h] $ and satisfies 
	%	some conditions (to be defined later).
	%\end{itemize}
	%
	%\textbf{3. Procedure}:
	%\begin{itemize}
	%	\item Call \texttt{AdmissiblePair}$(E_0, 1 - T, \veps_1)$ to
	% compute an $ \veps_1 $-admissible pair $ (h, \ol{F_0}) $, where:
	%	\begin{itemize}
	%		\item $ h $: The computed step size for the interval.
	%		\item $ \ol{F_0} $: The full enclosure for $ \bfx \in \ivp(\bfp_0, 1) $ restricted to the interval $ [T, T + h] $.
	%	\end{itemize}
	%\end{itemize}
	%
	%\textbf{ (Full Enclosure Verification)}:
	%\begin{itemize}
	%	\item Call \texttt{Verifyfull}$(\ol{F_0})$ to check if the full enclosure $ \ol{F_0} $ satisfies certain conditions (to be defined later).  If these conditions are not met, update both $ \delta \leftarrow \frac{\delta}{2} $ and $ \veps_1 \leftarrow \frac{\veps_1}{2} $, call \texttt{Update}($\calD , \delta$), and repeat Step A.
	%\end{itemize}
	%
	%\textbf{ (Step size Control)}:
	%\begin{itemize}
	%	\item If $h\le \delta$ then update $ \delta \leftarrow \frac{\delta}{2} $, and call \texttt{Update($\calD , \delta$)} and repeat Step A.
	%\end{itemize}
	%
	%
	%
	%
	%\textbf{Step B: Subdivision of the Time Interval}
	%
	%\textbf{1. Inputs}:
	%\begin{itemize}
	%	\item $ (h, \ol{F_0}, \delta, \calD ) $: The output of Step A.
	%	\item $ \veps > 0 $: The desired precision.
	%\end{itemize}
	%
	%\textbf{2. Outputs}:
	%\begin{itemize}
	%	\item $ \delta_1, \calD  $: $ \delta_1\le \delta $ and a $ \delta_1 $-controlled $ \calD  $ such that the length of each end enclosure in $ \calD  $ is less than $ \veps $.
	%\end{itemize}
	%
	%\textbf{3. Procedure}:
	%\begin{itemize}
	%	\item Compute a smaller step size $ h_1 $ such that $ h_1 \leq h $.
	%	\item Subdivide the time interval $ [t_0, t_0 + h] $ into $ \left\lceil \frac{h}{h_1} \right\rceil $ subintervals:
	%	\[
	%	[t_0, t_0 + h_1], \ldots, [t_0 + h - \left\lfloor \frac{h}{h_1} \right\rfloor h_1, t_0 + h].
	%	\]
	%	\item For each subinterval, compute both an end enclosure and a full enclosure for the solution.
	%\end{itemize}
	%
	%\textbf{(End Enclosure Check)}:
	%\begin{itemize}
	%	\item Verify whether the length of each end enclosure is less than the predefined precision $ \veps $. 
	%	\item If this condition is not satisfied, update $ \delta \leftarrow \frac{\delta}{2} $, call \texttt{Update}($\calD , \delta$), and repeat Step B.
	%\end{itemize}
	%
	%
%%%%%%%%%%%%%%%%%%%%%% THE END OF EXTRA STUFF %%%%%%%%%%%%%%%%%%%%%%%%%%
% file: stepAB.tex
%	Taken from estimateR.tex (stepA and stepB)
%	Taken from case-negative.tex (delta-bounde end-enclosure)

	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sectL[stepAB]{Steps A and B}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Step A}
	Recall that $\stepA(E_0,\veps,H)$ returns an
	$\veps$-admissible pair (see \refeq{stepA}) for $E_0$.
	For this purpose, we need the following:

	\bleml[ad]\ \\
	Let $ k \geq 1 $, $ H > 0 $, $ \veps > 0 $, and 
	$ E_0 \ib \RR^n $. Define  
	\[
		\ol{B} \as \sum_{i=0}^{k-1} [0, H]^i \bff^{[i]}(E_0)
				+ 	[-\veps, \veps]^n, \qquad
		M \as \sup_{\bfp \in \ol{B}} \| \bff^{[k]}(\bfp) \|_2.
	\]  
	If
	\[
		h = \min \left\{ H, \left( \frac{\veps}{M} 	\right)^{\frac{1}{k}}
				\right\},  \qquad
		F_1 = \sum_{i=0}^{k-1} [0, h]^i \bff^{[i]}(E_0) + 
			[-\veps, \veps]^n.
	\]  
	then the pair $(h, F_1)$ is $\veps$-admissible for $E_0$.
	\eleml
	\savespace{
	\bpf
	To verify \refeq{tay},
	 we only need to verify
		\[[0,h]^k\bff^{[k]}(F_1)\ib [-\veps,\veps]^n.\]
	We have:
	\beqarrys
		h^k\bff^{[k]}(F_1)
		    &\ib& h^k[-M,M]^n
		          &\text{(by the definition of $M$  )}\\
			&\ib& [-\veps,\veps]^n.
		           &\text{(by the definition of $h$  )}
	\eeqarrys
	\epf
	}% savespace
	
	\refLem{ad} justifies the following implementation of \stepA:
	
	\Ldent\progb{
	\lline[-3] \stepA$(  E_0,\veps,H)$$\ssa(h,F_1)$
	\lline[7] INPUT: $\bff$, $H>0, \veps>0, k\ge 1$ and $E_0\ib\RR^n$
	\lline[7] OUTPUT:  an $\veps$-admissible pair for
			$E_0$ such that $h\le H$.
	\lline[2] $\ol{B}_0\ass\sum_{i=0}^{k-1}[0,H]^i\bff^{[i]}(E_0)
					+[-\veps,\veps]^n$.
	\lline[2] $M\ass \|\bff^{[k]}(\ol{B}_0)\|_2$.
	\lline[2] $h\ass\min\{(\frac{\veps}{M})^{\frac{1}{k}},H\}$.

	\lline[2]  $F_1\ass \sum_{i=0}^{k-1}[0,h]^i \bff^{[i]}(E_0)
				+[-\veps,\veps]^n.$
	\lline[2] Return $(h,F_1)$
	}
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Step B}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	For \stepb, there are several methods such as
	the Direct Method \cite{nedialkov+2:validated-ode:99},
	Lohner's method \cite{lohner:thesis},
	and $C^1$-Lohner method \cite{wilczak-zgliczynski:lohner:11}.
	Our implementation uses the Direct Method:

	\beql{stepBdirect}
		\includegraphics[width=0.86\linewidth]{figs/stepBdirect}
	\eeql
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{$\delta$-bounded End-enclosure}\label{sec-ne}
	In this section, let $(E_0, h, F_1)$ be an admissible triple.
	For any $\bfx \in \IVP(E_0, h)$ and
	$\delta>0$, the \dt{$\delta$-tube} of $\bfx$ is
	the set
		$$\Tube_\delta(\bfx) \as
				\set{(t,\bfp): \|\bfp-\bfx(t)\|_2 \le \delta, 0\le t\le h}
				\quad \big(\ib [0,h]\times\RR^n\big)$$
	We say that a function $\ell: [0,h]\to\RR^n$ belongs to the
	$\delta$-tube of $\bfx$ is for all $t\in[0,h]$,
	$(t,\ell(t)) \in \Tube_\delta(\bfx)$,see graph \ref{fig:tube} for
	illustration.
	
	% TODO: \usepackage{graphicx} required
	\begin{figure}
		\centering
		\includegraphics[width=0.4\linewidth]{figs/Tube}
		\caption{The dashed lines in the figure form a \(\delta\)-tube
		around the red solid curve representing \(\bfx(t)\). The segment
		\(l(t)\) is a line segment inside this \(\delta\)-tube.}
		\label{fig:tube}
	\end{figure}
	
	\bleml[delta-distance]\ \\
		Consider 
			$\ivp(Ball(\bfp_0,r_0),h,F_1)$
		and $\olmu = \mu_2(J_\bff(F_1))$.  
		Let $\bfx_c \in\ivp(\bfp_0,h)$
			and $\bfq_0=\bfx_c(h)$.
		If the linear function
			$$\ell(t)\as (1-t/h)\bfp_0+(t/h)\bfq_0$$
		lies in the $\delta$-tube of $\bfx_c$ then
		\benum[(i)]
		\item  $Ball(\bfq_0, r_0 e^{\olmu h}+\delta)$ is an
				end-enclosure for $\ivp(Ball(\bfp_0,r_0),h)$.
		\item  Let $r'=\max(r_0 e^{\olmu h},r_0)$ then
			$Box(Ball(\bfp_0, r'+\delta),
					Ball(\bfq_0, r'+\delta))$
				is a full-enclosure for $\ivp(Ball(\bfp_0,r_0),h)$.
		\eenum
	\eleml
	\savespace{
	\bpf
	By \refLem{endenclosure}, we have
		$E_1 =  Ball(\bfq_0, r_0e^{\olmu h}+\delta)$ is the
	end-enclosure for $\ivp(E_0, h)$.  
	
	Next, we prove $(ii)$.  
	We show that for any $T \in [0, h]$,  the end-enclosure of 
	$\ivp(E_0,T)$ is a subset of $Box(Ball(\bfp_0, r' +\delta),
	Ball(\bfq_0, r' +\delta))$.
	Note that by \refLem{endenclosure}, we have $E_1 =  Ball(l(T),
	r_0e^{\olmu T}+\delta)$ is the
	end-enclosure for $\ivp(E_0, T)$.
	
	Let $l(T)_i$ denote the $i$-th component of $l(T)$ and $r(T)\as
	r_0e^{\olmu T}+\delta$. Then, we only need to
	prove that for any $i=1\dd n$, the interval
		$l(T)_i \pm r(T)$ satisfies  
	\[
	l(T)_i \pm r(T) \subseteq Box((\bfp_0)_i\pm (r'+\delta),
	(\bfq_0)_i\pm (r'+\delta)),
	\]  
	where $(\bfp_0)_i $ and $(\bfq_0)_i $ are the $i$-th components of
	$\bfp_0$ and $\bfq_0$,
	respectively.  
	
	Since $l(T)$ is a line segment, it follows that  
	\[
		\min((\bfq_0)_i, (\bfp_0)_i)
			\leq l(T)_i \leq \max((\bfq_0)_i, (\bfp_0)_i).
	\]  
	Additionally, we have $r(T) \leq r' + \delta$.  
	
	Combining these observations, we conclude that 
	\[
	l(T)_i \pm r(T) \subseteq Box((\bfp_0)_i\pm (r'+\delta),
	(\bfq_0)_i\pm (r'+\delta)).
	\] 

	\epf
	}% savespace
	
	\savespace{
	% TODO: \usepackage{graphicx} required
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.7\linewidth]{figs/delta-distance}
	
		\caption{The red curve $\bfx_c(t)$ represents the solution to  
			$\ivp(\bfp_0, h)$. The blue curve $l(t)$ lies within the
			$\delta$-tube of $\bfx_c$. According to
			\refLem{delta-distance}, the ball $B = Ball(l(h), r_0e^{\olmu
			h} + \delta)$ provides an end-enclosure for
			$\ivp(Ball(\bfp_0, r_0), h)$, as shown in the left graph. In
			the right graph, the green box, $Box(Ball(\bfp_0, r' +
			\delta), Ball(\bfq_0, r' + \delta))$, projected onto the
			vertical axis, represents the full-enclosure.}  

		\label{fig:delta-distance}
	\end{figure}
	}% savespace
	
	\savespace{
	Next, we show that the Euler method with a step size
	$0<h_1=h_1(\delta)\le h$ will be able to compute a series of  points
	$P=(\bfp_0\dd \bfp_{N+1})$ such that for any $i=1\dd N+1$ 
	the line segment $\ol{\bfp_{i-1}\bfp_i}$ lies in the $\delta$-tube of
	$\bfx_c$.
	
	The classic Euler method for $\ivp(\bfp_0, h)$
	produces a polygonal path of the form
			$$[(0,\bfp_0), (t_1,\bfp_1) \dd (t_N,\bfp_N), (h,\bfp_{N+1})]$$
	of length $N+1$.  In case the time step is uniformly $h_1$,
	then $t_i = i h_1$ for $i=0\dd N\as \floor{h/h_1}$ and
	we can represent the path\footnote{
		Allowing the degenerate case where $t_N=h$.
	} as
			$P=[\bfp_0, \bfp_1 \dd \bfp_N, \bfp_{N+1}]$.

	We now consider a variant of this classical subroutine
	to compute a polygonal approximation $P$ to 
			\beql{bfxp0}
				\bfx =\ivp_\bff(\bfp_0,h,F_1)\eeql
	so that $P$ lies in the $\delta$-tube of $\bfx$,
	for any user chosen $\delta>0$. 
	
	\Ldent\progb{
		\lline[0]  ${\sc Euler}_\bff(\bfp_0,h,\delta)\ssa (h_1,P)$
		\lline[5] INPUT: $\bff, \bfp_0, h, F_1, \delta$ as described
			above subject to \refeq{lognormneg}.
		\lline[5] OUTPUT:  a polygonal path $P$ with step size $h_1$
			from time $0$ to $h$.  
		\lline[25]	Morever, $P$ lies in the
				$\delta$-tube of $\bfx$ in \refeq{bfxp0}.
		\lline
		\lline[10] $h_1 \ass
				\min\set{h,
					\frac{2\olmu\delta}{\|\bff^{[2]}(F_1)\|
						(e^{\olmu h}-1)}}$.
		\lline[10] $N\ass \floor{h/h_1}$
		\lline[10] $\wtbfy\ass \bfp_0$
		\lline[10] Initialize a list $P\ass [\bfp_0]$
		\lline[10] For $i=1$ to $N$
		\lline[15] 		$\wtbfy\ass \wtbfy + h_1\cdot \bff(\wtbfy)$
		\lline[15]		$P.append(\wtbfy)$
		\lline[10] $P.append(\wtbfy + (h-Nh_1)\cdot \bff(\wtbfy))$ 
		\lline[10] Return $(h_1, P)$
	}

	\bthmT[negative]{Correctness of {\sc Euler}}\ \\
		The algorithm ${\sc Euler}_\bff(\bfp_0,h,\delta)$
		is correct, i.e.,
		the output $P=[\bfp_0\dd \bfp_{N+1}]$
		lies within the $\delta$-tube of the solution
		$\bfx$ in \refeq{bfxp0}.
	\ethmT
	\bpf
		 Let 
		 	$t_i=
		 \begin{cases}
		 	ih_1, & i<N+1\\
		 	h,    & i=N+1
		 \end{cases}.$
		 
		 For any  \(i = 1 \dd N+1\) and  $t\in [t_{i-1},t_{i}]$,
		 let $\bfq=\bfp_i+(t-t_i)\bff(\bfp_i)$.
		 Then the theorem follows if we prove
		 	$\|\bfq - \bfx(t)\| \le \delta $.
		By \refLem{Euler-step},
		\beqarrys
		\|\bfq - \bfx(t)\|  
		&\leq& 
			\frac{\|\bff^{[2]}(F_1)\|h_1}{2\olmu}(e^{\olmu_1 t} - 1)  
		 \\  
		&\leq& \frac{(e^{\olmu_1 t} - 1)\delta}
			{e^{\olmu_1 	h} - 1} 
				& \text{(by the definition of \(h_1\))}\\  
		&\leq& \delta  
			& \text{(since \(t \le h\))}
		\eeqarrys
			
	\epf
	}%savespace
	





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THIS IS THE OLD METHOD, using ball geometry.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ignore{
\sect{Computing an Admissible Pair $(h,R)$ }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	Let
			$$M(\bfp_0,r) \as
				\sup_{\bfp\in Box(\bfp_0,r)} \| \bff(\bfp)\|_2.$$
	\cheeX{We defined $Box(\bfp_0,r)$ with $2$-norm.}
	%%%
	If $r=0$, let $M(\bfp_0,0)$ denote $\| \bff(\bfp_0\|_2$.
	Theorem M tells us that if the pair ($h,r$)
	satisfies the condition $h\le r/M(\bfp_0,r)$,
	then the set $\IVP(\bfp_0,h)$ is a singleton, and the true range of
	the unique solution in $\IVP(\bfp_0,h)$
	is contained in $Ball(\bfp_0,r)$.
	\ignore{
			Bw said tht $\bfx$ is unique here.
			But which is the unique solution in the example
				$x'=f(x)=\sqrt{|x|}$
			and
				$x(0)=0$?
			Then $IVP_f(0,h)=\set{x_a: a\in (0,h]}$
			and 
				$$x_a(t)=\clauses{0 &\rmif\ t\le a,\\
								(x-a)^2 & \rmif\ t>a.}$$
			\cored{Bingwei says $f(x)$ is not Lipshitz continuous
			at $x=0$)}
	}
	%%
	We want to generalize this result to say that for all
			$\bfx\in \IVP(Ball(\bfp_0,r_0),h)$
	the true range of $\bfx$ is contained
	in $Ball(\bfp_0,R)$ for some $R$.
	For this purpose, let us define the function
		\beql{H}
			H(\bfp_0,R) \as \frac{R-r_0}{M(\bfp_0,R)}
		\eeql
	and a pair of reals
			$(h, R)$
	is called an \bf{admissible pair for $Ball(\bfp_0,r_0)$}
	if $h>0$, $R>r_0$ and $h\le H(\bfp_0,R)$.
	We have the following lemma:

	\blem
	Let $(h, R)$ be an admissible pair for $Ball(\bfp_0,r_0)$.
	Then for all 
		$\bfx \in \IVP(Ball(\bfp_0, r_0), h)$
	the true range of $\bfx$ is contained in $Ball(\bfp_0, R)$.
	\elem
	\bpf
	For any $\bfq \in Ball(\bfp_0, r_0)$, let $r = R - r_0$ and
	$h_{\bfq} = \frac{r}{M(\bfq, r)}$. Then, by Theorem M,
	we have
	$\bfx_{\bfq} =\IVP(\bfq, h_{\bfq})$
	and the true range of $\bfx_{\bfq}$ is contained in
				$Ball(\bfq, r))$.
		\beqarrys
			h_{\bfq} &=& \frac{R - r_0}{M(\bfq, R-r_0)} \\
					&\ge& \frac{R - r_0}{M(\bfp_0, R)}
				& \text{(since $Ball(\bfq, r) \ib Ball(\bfp_0, R)$}\\
					&\ge& h 
				& \text{(by admissibility of $(h,R)$).}
		\eeqarrys
	Since $h_\bfq\ge h$, it is clear that there exists a
	solution $\bfx\in IVP(Ball(\bfp_0,r_0),h)$ such that
	$\bfx$ is obtained by restricting the domain of $\bfx_\bfq$
	from $[0,h_\bfq]$ to $[0,h]$.  Since the true range of $\bfx_\bfq$
	is contained in $Ball(\bfp_0,R)$, we conclude that the
	true range of $\bfx$ is also contained in $Ball(\bfp_0,R)$.
	\epf
	
%	We now consider the case where $\bff$ are polynomials.
%	Let $\deg(\bff)$ be the maximum total degree of any $f_i\in\bff$.
%	If $\bff$ is linear, i.e., $\deg(\bff)=1$, the validated
%	IVP problem can be considered solved (or solvable).
%	In the nonlinear case, we can use the following lemma:
%	
%	\blem Let $\bff=(f_1\dd f_n)$ be a polynomial system with
%		$\deg(\bff)=d\ge 2$.
%		Then the function $M(\bfp_0,r)=\Theta(r^{d})$.
%	\elem
%	\bpf
%		Clearly,
%			$M(\bfp_0,r) = \|\bff(\bfq)\|$ for some
%				$\bfq\in Ball(\bfp_0,r)$.
%		(In this proof, $\|\cdot\|$ refers to the $2$-norm.)
%		Write $\|\bff(\bfq)\| = \sqrt{F(\bfq-\bfp_0)}$
%		where
%			$$F(\bfx)\as \sum_{i=1}^n f_i(\bfp_0+\bfx)^2.$$
%		Since $F(\bfx)$ has total degree $2d$, we may rewrite it as
%				$F(\bfx)= \sum_{i=0}^{2d} F^i(\bfx)$
%		where each $F^i$ is a homogeneous polynomial of
%		total degree $i$, and $F^{2d}(\bfx)$ does not vanish.
%
%		Consider the unit ball $Ball(\0,1)$ centered at the origin $\0$.
%		Let $S^{n-1}=\partial Ball(\0,1)$ denote the boundary of
%		the unit ball.  For any $\bfv\in Ball(\0,1)$, 
%		it follows from the homogeneity of $F^i$ that for all $r>0$,
%				$F^i(r \bfv)= r^i F^i(\bfv)$.  For
%				$\bfv\in S^{n-1}$, let 
%			$$g_{\bfv}(r) \as F(r\bfv)= \sum_{i=0}^{2d} r^i F^i(\bfv)$$
%		is a polynomial of degree $\le 2d$. 
%
%		\dt{Lower bound on $M(\bfp_0,r)$:}
%		let
%			$$\bfv^*=\argmax_{\|\bfv\|=1}  \|F^{2d}(\bfv)\|.$$
%		Therefore the leading coefficient of
%			$g_{\bfv^*}(r)$ is $F^{2d}(\bfv^*)$ which is non-zero.
%			Hence $g_{\bfv^*}(r)$ is a polynomial of degree $2d$.
%			It follows that
%		$M(\bfp_0,r)\ge \sqrt{g_{\bfv^*}(r)}=\Omega(r^d)$.
%
%		\dt{Upper bound on $M(\bfp_0,r)$:}
%		\chee{Bingwei, please complete this argument}
%		Let $a_i \as \sup\set{| F^i(\bfv)|: \bfv\in S^{n-1}}$
%		for $i=0\dd 2d$.  Note that $a_{2d}\ne 0$ since $F^{2d}$ does not
%		vanish.  Let 
%			$$g_*(r) \as \sum_{i=0}^{2d} a_i r^i.$$
%		Then 
%			\beqarrys
%			M(\bfp_0,r) &=& \sup\set{ \|\bff(\bfp_0+r\bfv)\|:
%								\bfv\in Ball(\0,1)}\\
%					&=& \sup\set{\sqrt{F(r\bfv)}:
%								\bfv\in Ball(\0,1)}\\
%					&\le& \sup\set{\sqrt{g_{\bfv}(s)}:
%								\bfv\in S^{n-1}, 0<s\le r}\\
%					&\le & \sqrt{g_*(r)}
%								& \text{(???)}\\
%			\eeqarrys
%			
%	\epf	
	Given $\olh$, $\bff$, and $Ball(\bfx_0, r_0)$,
	we aim to compute an admissible pair $(h, r)$
	such that $h \le \olh$.
%	We use the unbounded search method to get a lower bound
%	of a local maximum of $\frac{r - r_0}{M(\bfp_0, r)}$.
		FIRST, I describe an "ideal" algorithms where $h(r,r_0,\bfp_0)$ is
	computed exactly.
	We allow users to input $ R>r_0 $ to meet the required control precision.
	\Ldent\progb{
			\lline[0] \estimateR$(\olh, \bfp_0, r_0, R)$
			\lline[10]		INPUT: $\olh>0, r_0>0, \bfp_0\in\RR^n, R$
			\lline[10]		OUTPUT: $(h,r)$, an admissible pair for
								$Ball(\bfp_0,r_0)$ such that $h\le \olh$.
			\lline[5]	If $ R $ is provided as input, then
					$ r_0 \ass R $; otherwise, $r\ass 2r_0$.
			\lline[5]	$h\ass h(r, Ball(\bfp_0,r_0))$
			\lline[5]	If ($h>\olh$)
			\lline[10]		$h\ass \olh$
			\lline[5]	Return $(h,r)$
		}%progb
	\blem
		Let $h(r)= h(r,Ball(\bfp_0,r_0))$ and assume that
		$h(r)\to 0$ as $r\to\infty$. 
		Then the algorithm \estimateR\ is correct.
	\elem
	\bpf
	The termination of this algorithm is obviously. 
	 The output $(h,r)$ is clearly
		correct by the previous lemma.
	%	Let us write $h(r)$ for $h(r,Ball(\bfp_0,r_0))$.
	%	Suppose the does not terminate.
	%	That means that the sequence $h(2r_0), h(4r_0)\dd h(2^i r_0) \dd$
	%	is bounded below by $\olh$ for all $i\ge 1$.  This
	%	contradicts the previous lemma 
	\epf
}%ignore
	
	
%	\blem
%	If $h(r)$ in \refeq{h(r)} satisfies $\lim_{r\to\infty} h(r)= 0$
%	then Algorithm \ref{alg-initialenclosure} is correct.
%	\elem
%	\bpf
%	We first prove the termination of the algorithm. 
%	We only have to show that the while loop terminates.
%	If the while loop cannot terminate, then $ h(nr_0) $ must increase
%	for positive integers $ n $. However, since $\lim_{r \to \infty}
%	h(r) = 0$, there must exist an integer $ N > 0 $ such that for all
%	$ n > N $, $ h(nr_0) < h(2r_0) $. Thus, the while loop can
%	terminate.
%	
%	Next, we prove the correctness of the algorithm's output. We can see
%	that the algorithm only returns in the third step; therefore, if
%	$K_2\le K_1$	 then  $K_1= h(\frac{r}{2}) $ so $(K_1,\frac{r}{2})$
%	is an admissible pair.
%	If $K_2>K_1$, that means $K_2=h(r)>\olh$, then $(\olh,r)$ is an
%	admissible pair.  
%	
%	
%	
%	\epf
	
%	Here are some of our examples and data, where $h$ and $r $ are the
%	outputs of our algorithm \ref{alg-initialenclosure}, and $h_1, h_2$,
%	$h_3$ represent the step sizes obtained by Nedialko's method for
%	orders $1, 2,$ and $3$, respectively.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ssect{Some Data from Bw}
%	\cored{
%		Here are some of our examples and data, where $h$ and $r $ are
%		the outputs of our algorithm \ref{alg-initialenclosure}, and
%		$h_1, h_2$, $h_3$ represent the step sizes obtained by Nedialko's
%		method for orders $1, 2,$ and $3$, respectively.
%	}
%
%	\btableL[l | c | c c | r | r |r|r|r| l]{admiss}{Admissible Pairs}
%	{ Example &
%		Parameters & \multicolumn{2}{c|}{Initial Values}
%			& \multicolumn{2}{c|}{Admissible Pair}
%			& \multicolumn{3}{c|}{Nedialkov Estimates}
%			& Notes/Refs.\\
%		& $(a,b,c,d)$ & $(x_0,y_0)$ & $r_0$ & $h$ & $r$
%			& $h_1$ &$h_2$ & $h_3$
%			& Notes/Refs.\\\hline\hline
%	 E1 Predator-Prey 
%		& $(1,1,1,1)$ & $(1,1)$ & $1$ & $0.075$ & $4.000$
%			& $0.009$ & $0.033$ & $0.045$
%			& $(x_0,y_0)=(1,1)$ is a node.\\
%		& $(1.17,0.9,2.1,1.2)$ & $(1,1)$ & $1$ & $0.065$ & $4.000$
%			&$0.006$ & $0.030$  & $0.037$
%			& Youtube. See \refFig{prey}(left).\\
%		& $(1,1,0.666,1.333)$ & $(0.9,0.9)$ &$1$ & $0.066$ & $4.000$
%			& $0.007$ & $0.029$ & $0.039$
%			& wikipedia. See Figure \refFig{prey}(middle).\\
%		& $(1,1,2,2)$ & $(1,2)$ & $1$ & $0.041$ & $4.000$
%			&$0.004$ & $0.020$ & $0.029$
%			& medium. See \refFig{prey}(right).
%	\\\hline
%	N1 Neumaier
%		& & $(1,-1)$ & $0.01$ & $0.079$ & $1.80\times10^{14}$
%			& $0.006$ & $0.027$ & $0.044$
%			& \\
%	N1 Neumaier
%		& & $(1,-1)$ & $0.1$ & $0.079$ & $2.25\times10^{14}$
%			& $0.006$ &$0.027$ & $0.044$
%			& \\
%	\hline
%	N2 Neumaier
%		& & $(1,-1)$ & $0.01$ & $0.024$ & $5.280$
%			&$0.0007$& $0.0034$& $0.0063$
%			& \\
%	N2 Neumaier
%		& & $(1,-1)$ & $0.1$ & $0.023$ & $6.400$
%			& $0.0009$ & $0.0028$ & $0.0050$ 
%			& \\
%	\hline
%	}


% file: keylemma.tex
%    from new-approach-KeyLemma.tex


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Key Lemma}
	Consider an admissible triple $(E_0, h, F_1)$.
	By the validity of $\ivp(E_0,h)$, the following	
	condition can be achieved if $E_0$ sufficiently shrunk:

		\beql{0ninolB1}
			\0\nin \olF_1 \as Box(\bff(F_1)) = \prod_{i=1}^n \olI_i.
		\eeql  

	This implies that there exists some $i =1\dd n$ such that
	$0 \notin \olI_i$. 

	\ignore{% MOVE BELOW
		Wlog, say
			$0 \notin \olI_1$.  To further simplify our
				notations, we assume
			\beql{assume1}  
				\olI_1 >0.
			\eeql  
			In case $\olI_1<0$, we shall indicate the necessary changes
			to the formulas.
	}%
	Recall in \refSSec{keyIdea}
	that in the hard case, we compute the
	map $\pi = \whpi \circ \olpi$.
	Define the box $B_2$ and $\chb_{\max}$
		\beql{translation}
			B_2 \as Box(\olpi(F_1)) = \prod_{i=1}^n [1,\chb_i].
					\quad
              \chb_{\max} \as \max_{i=1\dd n} \chb_i.
		\eeql

	Using $\olpi$, we can introduce an intermediate ODE system
		with new differential variables
			\beql{olbfy}
					\olbfy \as \olpi(\bfx)
			\eeql
		and algebraic function
			\beql{olbfg1}
				\olbfg(\olbfy) \as J_{\olpi} \Bigcdot
							\bff(\olpi\inv(\olbfy))
			\eeql
		satisfying the ODE
				\beql{olbfy'}
					\olbfy' = \olbfg(\olbfy)
				\eeql
		and
			\beql{olbfg}
				\olbfg(\olpi(F_1))\ge \1= [1\dd 1].
			\eeql
	% Note that $J_{\olpi}$ is the constant matrix $ \olA$,
	% and $J_{\olpi\inv}$ is $(\olA)\inv$.
	Note that $(\pi(E_0), h, \pi(F_1))$ is
	an admissible triple in the $(\bfy,\bfg)$-space.



	\bthmT[keylemma]{Key Lemma} \ \\
	\benum[(a)]
	\item
		\beqarrys
	 	\mu_2 \big(J_{\bfg} (\pi(F_1))\big)
			&\le&
 			\max\set{\tfrac{-(d_i+1)}{\chb_i}:
							i=1\dd n}\\
		&&
			+ \max_{i=1}^n \set{d_i} 
        		\cdot
					\|J_{\olbfg}(\olpi(F_1))\|_2
				\cdot
				\max_{i=1}^n \set{\tfrac{(\chb_i)^{d_i+1}}{d_i}}.
		\eeqarrys
	\item If $d_1=\cdots=d_n=d$ then
			$$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)
				\le
					-(d+1)\tfrac{1}{\chb_{\max}}
						+(\chb_{\max})^{d+1}
								\|J_{\olbfg}(\olpi(F_1))\|_2.
			$$
	\eenum
	\ethml

	\savespace{
	\bpf
	From \refLem{Jbfg}(b)
	we have for any $\bfp=(p_1\dd p_n) \in \olpi(F_1)$,
		\beql{splitJacobian1}
			J_{\bfg}(\whpi(\bfp))
			= A(\bfp) + P\inv(\bfp)
				\frac{\partial \olbfg}{\partial \bfx}(\bfp)P(\bfp)
		\eeql
	where
       $P(\bfp)=\diag\big(
	   			\tfrac{p_i^{d_i+1}}{d_i}: i=1\dd n \big)$
        and
		$A(\bfp) = \diag(a_1\dd a_n)$ with
        \beql{aid1}
				a_i \as -d_i(1 + \tfrac{1}{d_i}) p_i\inv
					\cdot (\olbfg(\bfp))_i. \eeql
	Thus, $A, P$ are diagonal matrices and $p_i\inv$ is well-defined
	since $\bfp\in B_2\ge \1$, \refeq{translation}.
	
	By \refLem{lognorm}(b) and \refeq{aid1}, we conclude that
	the form
		\beql{mudiag}
			\mu_2(A(\bfp))=	\mu_2(\diag(a_1\dd a_n))
					= \max\set{a_i: i=1\dd n}.
		\eeql

	From \refeq{olbfg}, we conclude that
	{\small
	\beqarrys
    \mu_2\big(J_{\bfg}(\whpi(\bfp))\big) 
		&=& \mu_2\left(A(\bfp) + P\inv(\bfp)\frac{\partial \olbfg}{\partial
			\bfx}(\bfp)P(\bfp)\right)\\
			&& \text{(by \refeq{splitJacobian1})} \\
		&\le& \mu_2(A(\bfp))
			+ \mu_2\left(P\inv(\bfp)\frac{\partial \olbfg}{\partial
				\bfx}(\bfp)P(\bfp)\right)\\
			&& \text{(by \refLem{lognorm}(a))} \\
		&\le& \mu_2(A(\bfp)) 
			+ \left\|P\inv(\bfp)\frac{\partial \olbfg}{\partial
				\bfx}(\bfp)P(\bfp)\right\|_2 \\
			&& \text{(by \refLem{lognorm}(b))} \\
        &\le& \max\set{\tfrac{-(d_i+1)}{\chb_i}:
							i=1\dd n}\\
		&&
			+\left\|P\inv(\bfp)\right\|\left\|\frac{\partial \olbfg}{\partial
				\bfx}(\bfp)\right\|\left\|P(\bfp)\right\|\\
					&& \text{(by \refLem{matrixnorm}(b))}\\
        &\le& \max\set{\tfrac{-(d_i+1)}{\chb_i}:
							i=1\dd n}\\
		&&
			+ \max_{i=1}^n \set{d_i} 
        		\cdot
					\|J_{\olbfg}(\olpi(F_1))\|_2
				\cdot
				\max_{i=1}^n \set{\tfrac{(\chb_i)^{d_i+1}}{d_i}}.
	\eeqarrys
	}
	\epf
	}% savespace
	
	Until now, the value of $\bfd$ in the radical map $\whpi$ was 
	arbitrary. We now specify $\bfd = \bfd(F_1)$.
	The definition of $\bfd$ is motivated by \refThm{keylemma}.
	The optimal choice of $\bfd$ is not obvious. So we make
	a simple choice by restricting
	$d_1=\cdots=d_n =d$.  In this case, we could choose:

	\beql{d}
	d=d(F_1) \as\max\Big\{1,
			\quad 2 \| J_{\olbfg}(\olpi(F_1)) \|_2 -1 \Big\}.
	\eeql
	Although the theory allows $d\ge 1$ to be an arbitrary real,
	in practice, we use the ceiling of $d$.
	
	\bleml[Set-d]\
		Assuming $d$ satisfies \refeq{d}, we have:
	\benum[(a)]
	\item
		$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)
				\le	 (-2+(\chb_{\max})^{d+2})
				\cdot \frac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}}.$
	\item
		If
			$\log_2(\chb_{\max}) < \tfrac{1}{d+2}$
		then
			$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)< 0$.
	\eenum
	\eleml
	
	\savespace{
	\bpf
	%\benum[(a)]
	\benum
	\item
	By \refThm{keylemma} we have
	{\small
	\beqarrays
		\mu_2\left(J_{\bfg} (\pi(F_1))\right)
		&\le& -(d+1)\frac{1}{\chb_{\max}}
					+(\chb_{\max})^{d+1}\|J_{\olbfg}(\olpi(F_1))\|_2\\
		&=& \Big(\tfrac{-(d+1)}
				{\|J_{\olbfg}(\olpi(F_1))\|_2}+(\chb_{\max})^{d+2} \Big)
				\cdot \tfrac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}}\\ 
		&&	 \text{(by factoring)} \\
		&\le&  \Big(-2+(\chb_{\max})^{d+2} \Big)
				\cdot \tfrac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}} \\
		&&
			\text{(By eqn.\refeq{d}, we have $(d+1)
				\ge 2(
				\|J_{\olbfg}(\olpi(F_1))\|_2)$)}. 
	\eeqarrays
	}
	\item
		Since $(\chb_{\max})^{d+2}<2$
			is equivalent to 
			$\log_2(\chb_{\max}) < \tfrac{1}{d+2}$,
		we conclude that
			$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)< 0$.
	\eenum
	\epf

	}% savespace

	Given an admissible triple $(E_0,h,F_1)$,
	we introduce a subroutine called \Transform$(\bff,F_1)$ to
	convert the diffential equation
	$\bfx'=\bff(\bfx)$ to $\bfy'=\bfg(\bfy)$ according to above map
	$\pi$.   However, this transformation depends on the
	condition $\refeq{0ninolB1}$.  So we first define the
	following predicate \AvoidsZero($\bff,F_1$):

	\Ldent\progb{
		\lline[0] 
		\AvoidsZero$(\bff,F_1) \ssa$ \true\ or \false.  
		\lline[5] INPUT: $F_1 \ib \intbox\RR^n$.
		\lline[5] OUTPUT: \true\ if and only if
				$\bf0 \notin \text{Box}(\bff(F_1))$.
		% \lline
		% \lline[10] For $i=1\dd n$
		% \lline[15]	If $0 \nin f_i(F_1)$, return \true.
		% \lline[15] Return \false
	}

	Now we may define the transformation subroutine:

	\Ldent\progb{\label{alg:transform}
		\lline[0] 
			\Transform$(\bff,F_1,\olmu^1) \ssa (\pi, \bfg, \olmu)$ 
		\lline[5] INPUT: $F_1\ib \intbox\RR^n$
					where $\0\nin Box(\bff(F_1)$, $\olmu_1$.
		\lline[5] OUTPUT: $(\pi, \mu,\bfg)$ where
		\lline[10] $\pi$ and $\bfg$ satisfy
				 \refeq{circ} and \refeq{bfy'}.
		\lline[10] If (\AvoidsZero($\bff,F_1$=\false \& $ \olmu_1\ge 0$)
		\lline[15] Return ($\id,\bff, \olmu$)
		\lline[10] Compute $\olpi$ to satisfy \refeq{olbfg}
		\lline[10] Compute $\pi$ and $\bfg$ 
				 according \refeq{circ} and \refeq{bfy'}.
		\lline[10] $\olmu \ass \mu_2(J_{\bfg}(\pi(B)))$.
		\lline[10] Return ($\pi,\bfg, \olmu$)
		}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Transformation of Error Bounds}

	We want to compute a transformation
		$$\delta_x\mapsto \delta_y$$
	such that
	if $B$ is a $\delta_y$-bounded end-enclosure
		for $(\pi(E_0),h, \pi(F_1))$
		in the $(\bfy,\bfg)$-space, then
	then $\pi\inv(B)$ is 
		a $\delta_x$-bounded end-enclosure
	of $(E_0,h,F_1)$ in the $(\bfx,\bff)$-space.
	The following lemma achieves this:
	
	\savespace{
	\bleml[error-bound-under-phi]
		Let $\bfp,\bfq\in B\ib\RR^n$ and $\phi\in C^1(F_1\to \RR^n)$, then 
		$\|\phi(\bfp)-\phi(\bfq)\|_2
		\le \|J_{\phi}(B)\|_2 \cdot \|\bfp-\bfq\|_2$
	\eleml
	\bpf
		\beqarrys
		\|\phi(\bfp)-\phi(\bfq)\|_2
		&\le&
		 \|\phi(\bfq)+J_{\phi}(\xi)\Bigcdot(\bfp-\bfq) -\phi(\bfq)\|_2\\
		 	&& \text{(by Taylor expansion of $\phi(\bfp)$ at $\bfq$)}\\
		&=&\|J_{\phi}(\xi)\Bigcdot(\bfp-\bfq)\|_2\\
		&\le& \|J_{\phi}(\xi)\|_2 \cdot \|(\bfp-\bfq)\|_2\\
		&\le& \|J_{\phi}(B)\|_2   \cdot \|(\bfp-\bfq)\|_2,
		\eeqarrys
	where $\xi\in B$.
	\epf
	}% savespace
	

	\bleml[error-bound-ode]
	\ \\
	Let $\bfy=\pi(\bfx)$ and 
		$$
		\mmatx[rcl]{
			\bfx 	&=&
								\ivp_{\bff}(\bfx_0,h,F_1),\\
			\bfy 	&=&
								\ivp_{\bfg}(\pi(\bfx_0),h,\pi(F_1)).
			}$$
	%%%
	For any $\delta_x>0$ and any point $\bfp\in \RR^n$ satisfying 
		\beql{delta1}
			\|\pi(\bfp)-\bfy(h)\|_2
				\le \delta_y
				\as \frac{\delta_x}{\|J_{\pi\inv}(\pi(F_1))\|_2},
		\eeql
	we have 
			$$\|\bfp-\bfx(h)\|_2\le \delta_x.$$ 
	\eleml
	\savespace{
		\bpf
	\beqarrys
		\|\bfp-\bfx(h)\|_2
			&=& \|\pi\inv(\pi(\bfp))-\pi\inv(\pi(\bfx(h)))\|_2\\
			&=& \|\pi\inv(\pi(\bfp))-\pi\inv(\bfy(h))\|_2\\
			&\le&  			  
				\|J_{\pi\inv}(\pi(F_1))\|_2
					\cdot \|\pi(\bfp)-\bfy(h)\|_2\\
			&& \text{(by \refLem{error-bound-under-phi})}\\
			&\le& \delta\qquad
				\text{(by condition \refeq{delta1}.)}
	\eeqarrys
	\epf
	}% savespace
	
	% It follows that
	% 	$$\delta_y = \clauses{
	% 			\delta_x & \rmif\ \pi=id,\\
	% 			\frac{\delta}{\|J_{\pi\inv}(\pi(F_1))\|_2}.$$


	\Ldent\progb{
		\lline[0]  $\TransformBound(\delta,\pi,F_1) \ssa \delta'$
		\lline[5]	INPUT: $\delta>0$, $\pi, F_1$ as above.
		\lline[5]	OUTPUT: $\delta'>0$ satisfying the corollary.
		\lline[10]	If ($\pi$ is the identity map)
		\lline[15]		Return $\delta$.
		\lline[10]	Else
		\lline[15]		Return 
				$\frac{\delta}{\|J_{\pi\inv}(\pi(F_1))\|_2}$.
	}
\ignore{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{Comparing our Transform Method with Euler's Method}
	Let $(E_0, h, F_1)$ be an admissible triple, and 
	$\olmu^1 = \mu_2(J_{\bff}(F_1)) \geq 0$.
	
	Assume that $\pi$ and $\bfg$ are derived from 
	\refeq{pi} and \refeq{bfg}, respectively, and that 
	$\olmu^2 = \mu_2(J_{\bfg}(\pi(F_1))) < 0$.
	
	Let $Ball_{\bfp}(r_0) $ be the circumball of $E_0$. For a given
	precision $\delta > 0$, 
	we can compute a point $\bfQ$ by tracing 
	$\bfx \in \ivp(\bfp, h)$ such that 
	$\|\bfQ - \bfx(h)\| < \delta$. 
	The resulting end-enclosure for $\ivp(E_0, h)$ is
	$Ball_\bfQ\left(r_0 e^{\olmu^1 h} 
	+ \delta\right)$. 
	
	Using our transform method (illustrated in Figure 
	$\ref{fig:computerenclosure}$), we can obtain a point 
	$\bfq$ such that 
	$\|\pi\inv(\bfq) - \bfx(h)\| \leq \delta$. 
	The corresponding end-enclosure for $\ivp(E_0, h)$ is 
	$Ball_{\pi\inv(\bfq)}\left(r_0e^{\olmu^1 h} 
	+\delta\right)$.
	
	Furthermore,  let $Ball_{\pi(E_0)}(r'_0)$ be the circumball
	of $\pi(E_0)$ and $d_m\as \|\pi(m(E_0))-m(\pi(E_0))\|$ then 
	\beql{anotherend-enclosure}
		F\as \pi\inv\left(Ball_{\bfq}((r'_0+d_m) e^{\olmu^2 h} 
		+  \delta_1)\right)
	\eeql
	is another end-enclosure for $\ivp(E_0, h)$. Therefore, by 
	taking the intersection of enclosures, we can always 
	obtain a tighter end-enclosure.  
	
	We have the following lemma:
	
	\blem  \ \\
	The diameter of  $F$ \refeq{anotherend-enclosure}
	is less than  
	$
		2 J_{\pi\inv}(\pi(F_1)) J_{\pi}(F_1) (r'_0+d_m)
		e^{\olmu^2 h} + 2 \delta.
	$  
	\elem  
	
	%\bpf
\begin{pf}
	\beqarrays  
			\pi(E_0)
		&\ib& 	
			\pi(\bfp+[-r_0,r_0]^n)
		\\
		&\ib&
			\pi(\bfp)+ J_{\pi}(F_1)\Bigcdot [-r_0,r_0]^n
		\\
		&& \text{(by  mean value theorem.)}			
	\eeqarrays
	Thus, 
	$r'_0\le \|J_{\pi}(F_1)\|r_0.$
	\beqarrays  
		F
	&\ib& 	
		\pi\inv(\bfq)+ J_{\pi\inv}(\pi(F_1))\Bigcdot
		Box((r'_0+d_m)e^{\olmu^2h}+\delta_1).\\
	&& \text{(by mean value theorem)}			
	\eeqarrays
	Thus
	\beqarrays  
		diameter(F)
	&\le& 
		2\|J_{\pi\inv}(\pi(F_1))\|((r'_0+d_m)e^{\olmu^2h}+\delta_1)
	\\
%	&\le&  
	%	2 \|J_{\pi\inv}(\pi(F_1))\| \|J_{\pi}(F_1)\|  (r_0+d_m)
	%	e^{\olmu^2 h} + 2 \|J_{\pi\inv}(\pi(F_1))\| \delta_1
%	\\	
	&\le& 
		2 \|J_{\pi\inv}(\pi(F_1))\| \|J_{\pi}(F_1)\|  (r_0+d_m)
		e^{\olmu^2 h} +2\delta 
	\\
	&&  \text{(by \refeq{delta1})}	
	\eeqarrays
	%\epf  
\end{pf}
	%
	%		{\scriptsize
		%		\btable[c |c| c| c | c | c | c|c|c]{
			%			\hline
			%			Cases &  $E_0$ & $F_1$ & $h$ & $\delta$ &$\olmu^1$ &$\olmu^2$ & Len1 & Len2
			%			\\\hline
			%			Example 1& $Box_{(3,3)}(10^{-4})$ &$[2.9, 3.0]\times [2.9, 3.0]$ & $2.37\times 10^{-4}$&0.001 & 5.90 & -62.70 & 0.002 & 0.0009\\
			%			\hline
			%			Example 2 & $Box_{(3,3)}(10^{-4})$ & $[2.9, 3.0]\times [2.9, 3.0]$ & $5.34\times 10^{-4}$&0.001 & 7.00 & -20.28 &0.002 & 0.0002\\
			%			\hline
			%			Example 3 &$Box_{(3,3)}(10^{-4})$ & $[2.9, 3.0]\times [2.9, 3.0]$ & $2.23\times 10^{-4}$&0.001 & 5.39 & -52.66 &0.002 & 0.0004\\
			%			\hline
			%		}
		%	}%
	%	

%	Next, we compare the Euler step size:
	%	We have the following result:
	%
	%	
	%	
	%	Let $ M_{\bff}=\|\bff^{[2]}(F_1)\|, M_{\bfg}=\|\bfg^{[2]}(\pi(F_1))\|$
	%	then we have:
	%	\blem
	%	$M_{\bfg}\le J^2_{\pi}(F_1)J_{\pi\inv}(\pi(F_1))M_{\bff}$
	%	\elem
	%	
	%	We can compute the point $\bfQ$ by Euler method with
	%	step  size
	%             \beql{euler-size}
	%	       h\le \frac{2\olmu^1\delta}{M_{\bff}(e^{\olmu^1h}-1)},
	%            \eeql
	%	and
	%	we can similarly compute the point $\bfq$ using 
	%	the step size:
	%            \begin{align}
	%                h_1 &\le \frac{2\olmu^2\delta'}{M_{\bfg}   
	%                        (e^{\olmu^2h}-1)} 
	%                        \label{eq:transform-size}\\
	%                &\le \frac{2\olmu^2\delta}{M_{\bff}    
	%                    (e^{\olmu^2h}-1)}\frac{1}{ J^2_{\pi}
	%							(F_1)J^2_{\pi\inv}(\pi(F_1))} 
	%                    & \text{(by above lemma and \refeq{delta1})}.
	%                         \label{eq:transform-size2}
	%            \end{align}
	%
	%	The relative sizes of $h$ and $h_1$ 
	%    in \refeq{euler-size} and \refeq{transform-size} determine the
	% efficiency of the two methods.  A more direct but cruder comparison
	% is to  use \refeq{euler-size} and \refeq{transform-size2}, but in
	% this case, the transform method appears worse.
	%	

    Here are some examples and experimental data:
	The table lists the parameter $\veps$ from \stepa, where $\olmu^1$
	represents the logarithmic norm of the original IVP. The parameters
	$d_1$ and $d_2$ correspond to the radical map used in the Transform,
	with $d_1$ defined by equation \refeq{d}.  

\ssect{Some Examples}
    We will use the following running examples in our experiments:

		\begin{Example}[ 0.]
            This is the trivial $x'=ax$ with solution $x(t)=e^{at}$.
            Clearly, the logarithmic norm of this system is
            negative iff $a<0$.
        \end{Example}

	\begin{Example}[ 1. Volterra System]
            This is the Predator-Prey equation for
            $\bfx\in \ivp(E_0,1)$ where
            \beql{volterra}
			\bff=\mmat{x \\ y} '
			= \mmat{\phantom{-}ax(1-y) \\ -by(1-x)} ,
                    \qquad E_0 = Box_{(1,3)}( 0.1),
			\eeql
		with $a>1$ and $0<b<1$.  We choose $(a,b)=(2,1)$ and
		$E_0=Box_{(1,3)}(0.1)$ to closely
    track the AWA examples in \cite{moore:diffEqn:09} and
    \cite[p.13]{bunger:taylorODE:20}. 
	Thus $J_{\bff} =\mmat{2(1-y) & -2x\\ y & x-1}$ and the eigenvalues of
	$\half(J_{\bff}+ J_{\bff}^{\tr})$ are
            $$\half(1+x-2y \pm \sqrt{\Delta(x,y)}), \qquad \text{where } 
            \Delta(x,y)\as 5(x^2+y^2)-6(x+2y)+9$$
	  Note that
	  $\Delta(x,y)=5(x-\tfrac{3}{5})^2 + 5(y-\tfrac{6}{5})^2$ is
	  positive. Thus $\sqrt{\Delta(\bfq)}=\sqrt{5}\|\bfq-\bfp_0\|$
	  where $\bfp_0=(\tfrac{3}{5},\tfrac{6}{5})$.
	  Let $\ell(x,y)\as 1+x-2y$.  Thus $\ell(\bfq)> 0$ iff
	  $\bfq$ lies below the line $1+x-2y=0$.
	  \refFig{Volterra-21-13} shows
	  the trace of $\bfx(t)$ with $\bfx(0)=(3,1)$ and $t\in [0, 5.48]$
	  representing one complete
      cycle as computed by MATLAB; Bunger \cite{bunger:taylorODE:20}
      said that AWA cannot complete this computation 

      \FigEPS{Volterra-21-13}{0.2}{Solution to the Volterra system
	  	with $(a,b)=(1,2)$, and $\bfx(0)=(1,3)$ is shown in blue.
		The points $\bfq$ with negative
		$\mu_2(J_\bff(\bfq))$ lie above the green parabola as defined by
		the red line and red dot.}
 
	We have $\mu_2(J_\bff(\bfq)) = \half(\ell(\bfq)+\sqrt{\Delta(\bfq)})$,
	and this can only be negative when $\ell(\bfq)<0$, i.e., when $\bfq$
	lies above the line $\ell(x,y)=0$.  The algebraic locus of the curve
	$\mu_2(J_\bff(\bfq))=0$ is given by the equation
	$|\ell(\bfq)|^2=\Delta(\bfq)$.
    \ignore{
      We have $\sqrt{5}|\ell(\bfq)|$ is the distance
	  of $\bfq$ from the line $\ell=0$.}   This equation is a parabola
	  defined by the line $\ell(x,y)=0$ and the point $\bfp_0$.
 
    \end{Example}

    \begin{Example}[ 2. Van der Pol System]
		\beql{vanderpol}
			\bff=\mmat{x \\ y} '
			= \mmat{y \\ -x^2y + y-x} ,
                    \qquad E_0 = Box_{(-3,3)}( 0.1).
			\eeql
		It could be checked that the logarithmic norm of this system is
		always positive.

        \NOignore{
              $J_f = \mmat{0 & 1 \\ -2xy -1 & 1-x^2}$
              and the two eigenvalues
              of $(J_f+ J_f\tr)/2$ are
              
              $\mmat{ 1-x^2 + \sqrt{(1-x^2)^2 + 4x^2y^2}\\
                     1-x^2 - \sqrt{(1-x^2)^2 + 4x^2y^2}
                         }$,
            and the larger eigenvalue is always positive.
        }
	\end{Example}
	
	\begin{Example}[ 3.]
		Consider the system  
		\[
		\bff=\mmat{x \\ y} '
		= \mmat{x^2 \\ -y^2 + 	7x} , 
            \qquad E_0 = [-2.0, -1.0] \times [8.0, 9.0].
		\]
		The logarithmic norm of this system is initially negative but
		becomes positive. The solution to the $x$-component is $x(t)=
		\tfrac{1}{x_0\inv -t}$ which is negative for all $t>0$ (assuming
		$x_0<0$). Thus the $y$-axis is an asymptote of the solution curve
		(red curve in \refFig{neg-pos-system}). If the end enclosure
		$F_1=Box_{\bfp_1}(w_x, w_y)$ then $w_y/w_x\to \infty$. We have
		$J_\bff=\mmat{2x& 0\\ 7&-2y}$, and the eigenvalues of
		$\half(J_\bff+J_\bff{\tr})$ are
        $(x-y) + \sqrt{(x+y)^2 + (7/2)^2}$.
		        The phase portrait of this system is seen in
		\refFig{neg-pos-system}. The solution
		$\bfx$ with $\bfx(0)=(-1.5, 8.5)$ is shown in red.
	
		\FigEPS{neg-pos-system}{0.3}{Phase Portrait of Example 4}
	
    We check that for any point $\bfp\in\RR^2$ outside
    of the second quadrant $\set{x<0, y>0}$, we have
    the property
    $\mu_2(J_\bff(\bfp))>0$.   Moreover, for
     any solution $\bfx(t)\in \ivp(E_0,1)$ there is a moment 
        $0< t_1<1$ such that
        $\mu_2(J_\bff(x(t)))$ is negative if $t<t_1$
        and positive if $t>t_1$.  
	\end{Example}

     \begin{Example}[ 4. Lorenz System]

     {\scriptsize
     	\beql{lorenz}
       \bff = \mmat{x\\y\\z}' = 
            \mmat{\sigma(y-x)\\ 
                    x(\rho-z)-y\\
                    xy-\beta z},
        E_0 = Box_{(15,15,36)}(0.1),\\
        (\sigma,\rho,\beta)=(10,28,\tfrac{8}{3}).  
          \eeql}

     We have
     {\scriptsize $J_\bff=\mmat{-10 & 10 & 0\\
                    28-z & -1 & -x\\
                    y  & x  & -8/3}
     $} and
     
    {\scriptsize $\half(J_\bff+J_\bff{\tr})=\mmat{-10 & 19-\half z & \half y\\
                    19-\half z & -1 & 0\\
                    \half y  & 0  & -8/3}
     $}.  
	 We could no longer easily compute global bounds on log norms,
	 but only obtain bounds on $\olmu =\mu_2(J_\bff(F_1))$ for given
     admissible pair $(h,F_1)$ for $E_0$
 	E.g. for {\small $(h,F_1)=(0.01, 
        [14.80, 15.12]\times [13.34, 15.10] \times [35.75, 37.45])$}
    we obtain the bound
    $\olmu\le 4.33$.
     \end{Example}

	\ignore{\begin{Example}[ 4.]
	 	Consider the IVP where   
	 	\[
	 	\bff=\mmat{x \\ y} '
	 	= \mmat{x^2-2x+4 \\ -y^2 + 2y-7x-4} ,
                 \qquad
                E_0 = [-2.1, -1.9] \times [6.9, 7.1].
	 	\]
        \end{Example}
    }%ignore
	
     
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Experimental Comparison of Transformation with Euler} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		The transformed logarithmic norms is $\olmu^2$, respectively. Let
		$B_E$ denote an end-enclosure obtained using the Euler method
		directly on the original system, and $B_T$ denote an end-enclosure
		obtained using our transform method.
        The following table compares $B_E$ and $B_T$
        with respect to the ratios of the lengths
        and widths, repectively:
	\beql{rho}
            \rho(B_E, B_T) \as 
               \big( \tfrac{\wmax(B_E)}{\wmax(B_T)}, 
                    \tfrac{\wmin(B_E)}{ \wmin(B_T))}\big).
        \eeql

      \refTab{transform} define 
     a set of experiments, where 
     each experiment is based on the above examples,
     but with different numerical parameters:
     these parameters are $(E_0, \veps, F_1, h, \delta)$.  The goal is to compare
     $B_E$ and $B_T$ by using $\rho(B_E, B_T)$.
	\begin{table*}[]
      \centering

	{\scriptsize
	\btable[c| c | c | c | c | c | c | c | c ]{
	\hline
	E.g. & $E_0$ & $F_1$ & $h$ & $\delta$ & $\olmu^1$
		& $d_1$ & $\olmu^2$ & $\rho(B_E,B_T)$ \\\hline
	\hline 
	Eg1 & $Box_{(1,3)}(10^{-4})$ & $[0.9,1.0]\times[2.9,3.0]$
		& 0.0028 & $10^{-7}$ & 0.07 & 17  & -68.30 
			& $(1.0000,1.0000)$  \\
	    & & & & & & 1 & -5.82 &  $(1.0000,1.0000)$ \\\hline
	
	Eg2-a & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& $0.000018$ & $10^{-7}$ & 5.90 & 23
			& -142.73 & $(1.0000,1.0002)$ \\
	      & & & & & & 1 & -11.28 & $(1.0000,1.0003)$ \\\hline
	      
	Eg2-b & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& 0.00086 & $10^{-7}$ & 5.90 & 23 & -140.80
			& $(1.0000,1.0002)$ \\
	      & & & & & & 1 & -11.00 & $(1.0000,1.0007)$ \\\hline
	
	Eg2-c & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.7]$
		& 0.01 & $10^{-7}$ & 5.93 & 23 & -370.14 & $(1.0000,1.0321)$ \\
	      & & & & & & 1 & -9.20 & $(1.0000,1.0458)$ \\\hline
	
	Eg3-a & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& $0.00003$ & $10^{-7}$ & 9.75 & 20 & -180.71
			& $(1.0000,1.0000)$ \\
	      & & & & & & 1 & -10.08 & $(1.0001,1.0003)$ \\\hline
	
	Eg3-b & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& 0.001 & $10^{-7}$ & 9.75 & 20 & -177.05 & $(1.0000,1.0000)$ \\
	      & & & & & & 1 & -9.87 & $(1.0002,1.0008)$ \\\hline
	
	Eg3-c & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.2]\times [-3.0,-2.6]$
		& 0.02 & $10^{-7}$ & 10.64 & 20 & -163.12 &  $(1.0000,1.0035)$\\
	      & & & & & & 1 & -9.39 & $(1.0000,1.0665)$ \\\hline
	Eg4-a & $Box_{(1.0,3.0,1.0)}(10^{-4})$
		& $[0.9, 1.0]\times [2.9,3.0]\times[0.9,1.0]$ & $0.001$
			& $10^{-7}$ & 13.60 & 58 & -22.10
			& $(1.0000,1.0000,1.0102)$\\
	      & & & & & & 1 & -2.97 & $(1.0000,1.0000,1.0186)$ \\\hline
	Eg4-b & $Box_{(1.0,3.0,1.0)}(10^{-4})$
		& $[0.9, 1.5]\times [2.9,3.7]\times[0.9,1.0]$ & $0.02$
			& $10^{-7}$ & 13.62 & 10 & -6.01 & $(1.0000,1.0000,1.3286)$ \\
	      & & & & & & 1 & -3.01 & $(1.0000,1.0000,1.3933)$ \\\hline
	}
	}
	\caption{Comparison our transform method with Euler's method}
	\label{tab:transform}
	\end{table*}


	From the experimental results, we can conclude the following:  
	\\ 1. Applying the transformation consistently yields a tighter
	end-enclosure.  
	\\ 2. The benefit of the transformation becomes increasingly
	significant as the step size grows larger.  
	\\ 3. Decreasing the value of $d$ further tightens the end-enclosure.  
	\\ 4. When the given \ivp exhibits significantly faster growth along
	one coordinate axis compared to another, the transformation method
	demonstrates superior performance. This is because the Euler method is
	constrained to using square boxes, whereas the transformation method
	can adaptively use elongated boxes.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sectL[comparison]{Transform Method versus Euler Method}
		Let $(E_0, h, F_1)$ be an admissible triple
	that has been transformed into $(\pi(E_0),h,\pi(F_1))$.
	Let $\olmu^1$ be the \lognorm\ bound for $(\bff,F_1)$
	and
	$\olmu^2$ be the corresponding bound for $(\bfg,\pi(F_1))$.
	Given $\delta_x>0$, we can use the Euler Method to
	compute a point $\bfQ$ such that 
	$\|\bfQ-\bfx(h)\|\le \delta_x$ and
	\beql{end-enclosure0}
	E_1^{euler} \as Box_\bfQ\left(r_0 e^{\olmu^1 h} 
	+ \delta_x\right). \eeql 
	as an end-enclosure for $\ivp(E_0,h,F_1)$, $r_0$ radius
	of the circumball of $E_0$.  Using our $\pi$-transform we can
	first compute a point $\bfq$ such that 
	$\|\bfq-\bfy(h)\|\le \delta_y$ 
	and take its inverse, or we can take the inverse of
	the end-enclosure in $(\bfy,\bfg)$-space.  These 2 methods gives
	the following end-enclosures:
	\beql{end-enclosure1}
	E_1^{xform1}
	\as Box_{\pi\inv(\bfq)}\left(r_0e^{\olmu^1 h} 
	+\delta_x\right).
	\eeql
	\beql{end-enclosure2}
	E_1^{xform2}
	\as \pi\inv\left(Box_{\bfq}((r'_0+d_m) e^{\olmu^2 h} 
	+  \delta_y)\right),
	\eeql
	where $r'_0$ radius of the circumball of 
	$\pi(E_0)$ and $d_m\ge \|\pi(m(E_0))-m(\pi(E_0))\|$.
	Let $E_1^{xform}\as E_1^{xform1}\cap E_1^{xform2}$. 
	We can compare $E_1^{euler}$ and $E_1^{xform}$ using two
	indenpendent ratios:
	% We have
	% 		$\wmin(E_1^{xform})\le \wmax(E_1^{xform})
	% 			\le \wmin(E_1^{euler})= \wmax(E_1^{euler})$.
	\beql{rho}
	\rho(E_1^{euler}, E_1^{xform}) \as 
	\Big( \tfrac{\wmax(E_1^{euler})}{\wmax(E_1^{xform})}, 
	\tfrac{\wmin(E_1^{euler})}{ \wmin(E_1^{xform}))}\Big).
	\eeql
	Our current experiments shows that the first ratio in 
	$\rho(E_1^{euler}, E_1^{xform})$ is always less than
	the second ratio, and for simplicity, we only show the
	second ratio, which is denoted by
	$\sigma(E_1^{euler}, E_1^{xform})$ in the
	last column of \refTab{transform}.
	
	\ignore{
	Let $Ball_{\bfp}(r_0) $ be the circumball of $E_0$. For a given
	precision $\delta > 0$, 
	we can compute a point $\bfQ$ by tracing 
	$\bfx \in \ivp(\bfp, h)$ such that 
	$\|\bfQ - \bfx(h)\| < \delta$. 
	The resulting end-enclosure for $\ivp(E_0, h)$ is
	$Ball_\bfQ\left(r_0 e^{\olmu^1 h} 
	+ \delta\right)$. 
	
	Using our transform method (illustrated in Figure 
	$\ref{fig:computerenclosure}$), we can obtain a point 
	$\bfq$ such that 
	$\|\pi\inv(\bfq) - \bfx(h)\| \leq \delta$. 
	The corresponding end-enclosure for $\ivp(E_0, h)$ is 
		\beql{end-enclosure1}
			Ball_{\pi\inv(\bfq)}\left(r_0e^{\olmu^1 h} 
				+\delta\right).
		\eeql
	
	Furthermore,  let $Ball_{\pi(E_0)}(r'_0)$ be the circumball
	of $\pi(E_0)$ and $d_m\as \|\pi(m(E_0))-m(\pi(E_0))\|$ then 
		\beql{end-enclosure2}
			F\as \pi\inv\left(Ball_{\bfq}((r'_0+d_m) e^{\olmu^2 h} 
			+  \delta_1)\right)
		\eeql
	is another end-enclosure for $\ivp(E_0, h)$. Therefore, by 
	taking the intersection of enclosures, we can always 
	obtain a tighter end-enclosure.  
	}
	
	\savespace{
	We have the following lemma:
	
	\blem  \ \\
	The diameter of  $F$ \refeq{anotherend-enclosure}
	is less than  
	$
		2 J_{\pi\inv}(\pi(F_1)) J_{\pi}(F_1) (r'_0+d_m)
		e^{\olmu^2 h} + 2 \delta.
	$  
	\elem  
	}

	\savespace{
	\bpf
	\beqarrays  
			\pi(E_0)
		&\ib& 	
			\pi(\bfp+[-r_0,r_0]^n)
		\\
		&\ib&
			\pi(\bfp)+ J_{\pi}(F_1)\Bigcdot [-r_0,r_0]^n
		\\
		&& \text{(by  mean value theorem.)}			
	\eeqarrays
	Thus, 
	$r'_0\le \|J_{\pi}(F_1)\|r_0.$
	\beqarrays  
		F
	&\ib& 	
		\pi\inv(\bfq)+ J_{\pi\inv}(\pi(F_1))\Bigcdot
		Box((r'_0+d_m)e^{\olmu^2h}+\delta_1).\\
	&& \text{(by mean value theorem)}			
	\eeqarrays
	Thus
	\beqarrays  
		diameter(F)
	&\le& 
		2\|J_{\pi\inv}(\pi(F_1))\|((r'_0+d_m)e^{\olmu^2h}+\delta_1)
	\\
	%	&\le&  
		%	2 \|J_{\pi\inv}(\pi(F_1))\| \|J_{\pi}(F_1)\|  (r_0+d_m)
		%	e^{\olmu^2 h} + 2 \|J_{\pi\inv}(\pi(F_1))\| \delta_1
	%	\\	
	&\le& 
		2 \|J_{\pi\inv}(\pi(F_1))\| \|J_{\pi}(F_1)\|  (r_0+d_m)
		e^{\olmu^2 h} +2\delta 
	\\
	&&  \text{(by \refeq{delta1})}	
	\eeqarrays
	\epf  
	}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssectL[comparison]{Experimental Comparison} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \refTab{transform}
	compares a single step of our transform method with 
	the classic Euler method.


	Each row represents a single experiment.
    The columns under $(E_0, F_1, h)$ represent an admissible triple.
	The column under $\olmu^1$ (resp.~ $\olmu^2$) represents
	the \lognorm\ bound of $F_1$ in the $(\bfx, \bff)$-space
	(resp.~ $\pi(F_1)$ in the $(\bfy,\bfg)$-space).
	The $\delta$ column ensures that the end-enclosure is
	$\delta$-bounded in the sense of
	\refeqs{end-enclosure0}{end-enclosure1}.
	The $d$ column refers to uniform exponent $\bfd=(d\dd d)$ 
	of our radical transform.  The last column
	$\sigma(E_1^{euler},E_1^{xform})$
	is the most significant, showing the relative improvement
	of our method over Euler.
	\savespace{
	Each experiment such as Eg1 or Eg1-a has two
	rows corresponding to two variants of the experiment
	with different values of $d$.
	}

	\newcommand*{\myalign}[2]{\multicolumn{1}{#1}{#2}}
	%%%
	\begin{table}[] \centering
	{\tiny
		\btable[l| l | l | l | l | l ]{
			Eg* & \myalign{c|}{\dt{Name}}
			& \myalign{c|}{$\bff(\bfx)$}
			& \myalign{c|}{\dt{Parameters}}
			& \myalign{c|}{\dt{Box} $B_0$}
			& \myalign{c}{\dt{Reference}}
			\\[1mm] \hline \hline
			Eg1 & Volterra 
			& $\mmatP{\phantom{-}ax(1-y) \\ -by(1-x)}$ % ($a>1, 0<b<1$)
			&  $\mmatP{a\\ b}=\mmatP{2\\ 1}$
			& $Box_{(1,3)}( 0.1)$
			& \cite{moore:diffEqn:09},
			\cite[p.13]{bunger:taylorODE:20}
			\\[2mm] \hline 
			Eg2 & Van der Pol 
			& $\mmatP{y \\ -c(1-x^2)y -x}$
			& $c=1$
			& $Box_{(-3,3)}( 0.1)$
			& \cite[p.2]{bunger:taylorODE:20}
			\\[1mm] \hline
			Eg3 & Asymptote
			& $\mmatP{x^2 \\ -y^2 + 	7x}$
			& N/A
			& $ Box_{(-1.5,8.5)}(0.5)$
			& N/A
			\\[1mm] \hline
			Eg4 & Lorenz
			& $\mmatP{\sigma(y-x)\\ x(\rho-z)-y\\ xy-\beta z}$
			&
			$\mmatP{\sigma\\\rho\\\beta}=\mmatP{10\\ 28\\8/3}$
			& $ Box_{(15,15,36)}(0.1)$
			& \cite[p.11]{bunger:taylorODE:20}
			\\[1mm] \hline
	} }
	\caption{List of IVP Problems}
	\label{tab:problems}
	\end{table}


	\begin{table*}[]
      \centering
	{\tiny
	\btable[c| c | c | c | c | c | c | c | c ]{
	Eg* & $E_0$ & $F_1$ & $h$ & $\delta$ & $\olmu^1$
		& $d$ & $\olmu^2$ & $\sigma(B_E,B_T)$ \\\hline
	\hline
	Eg1 & $Box_{(1,3)}(10^{-4})$ & $[0.9,1.0]\times[2.9,3.0]$
		& 0.0028 & $10^{-7}$ & 0.07 & 17  & -68.30 
			& $1.0000$
		\\
	    & & & & & & 1 & -5.82 &  $1.0000$
		\\\hline
	Eg2-a & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& $0.000018$ & $10^{-7}$ & 5.90 & 23
			& -142.73 & $1.0002$
		\\
	      & & & & & & 1 & -11.28 & $1.0003$
		\\\hline
	      
	Eg2-b & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& 0.00086 & $10^{-7}$ & 5.90 & 23 & -140.80
			& $1.0002$
		\\
	     & & & & & & 1 & -11.00 & $1.0007$
		\\\hline
	
	Eg2-c & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.7]$
		& 0.01 & $10^{-7}$ & 5.93 & 23 & -370.14 & $1.0321$
		\\
	      & & & & & & 1 & -9.20 & $1.0458$
		\\\hline
	
	Eg3-a & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& $0.00003$ & $10^{-7}$ & 9.75 & 20 & -180.71
			& $1.0000$
		\\
	      & & & & & & 1 & -10.08 & $1.0003$
		\\\hline
	
	Eg3-b & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.0]\times [-3.0,-2.9]$
		& 0.001 & $10^{-7}$ & 9.75 & 20 & -177.05 & $1.0000$
		\\
	      & & & & & & 1 & -9.87 & $1.0008$
		\\\hline
	
	Eg3-c & $Box_{(3,-3)}(10^{-4})$ & $[2.9, 3.2]\times [-3.0,-2.6]$
		& 0.02 & $10^{-7}$ & 10.64 & 20 & -163.12 &  $1.0035$
		\\
	      & & & & & & 1 & -9.39 & $1.0665$
		\\\hline
	Eg4-a & $Box_{(1.0,3.0,1.0)}(10^{-4})$
		& $[0.9, 1.0]\times [2.9,3.0]\times[0.9,1.0]$ & $0.001$
			& $10^{-7}$ & 13.60 & 58 & -22.10
			& $1.0102$
		\\
	      & & & & & & 1 & -2.97 & $1.0186$
		\\\hline
	Eg4-b & $Box_{(1.0,3.0,1.0)}(10^{-4})$
		& $[0.9, 1.5]\times [2.9,3.7]\times[0.9,1.0]$ & $0.02$
			& $10^{-7}$ & 13.62 & 10 & -6.01 & $1.3286$
		\\
	      & & & & & & 1 & -3.01 & $1.3933$
		\\\hline
	}
	}
	\caption{Comparison our transform method with Euler's method}
	\label{tab:transform}
	\end{table*}


	From the experimental results, we can conclude the following:  
	\\ 1. Applying the transformation consistently yields a tighter
	end-enclosure.  
	\\ 2. The benefit of the transformation becomes increasingly
	significant as the step size grows larger.  
	\\ 3. Decreasing the value of $d$ further tightens the end-enclosure.  
	\\ 4. When the given \ivp\ exhibits significantly faster growth along
	one coordinate axis compared to another, the transformation method
	demonstrates superior performance. This is because the Euler method is
	constrained to using square boxes, whereas the transformation method
	can adaptively use elongated boxes.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% EXTRA STUFF
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ignore{%
\ssect{Some Examples}
    We will use the following running examples in our experiments:

		\begin{Example}[ 0.]
            This is the trivial $x'=ax$ with solution $x(t)=e^{at}$.
            Clearly, the logarithmic norm of this system is
            negative iff $a<0$.
        \end{Example}

	\begin{Example}[ 1. Volterra System]
            This is the Predator-Prey equation for
            $\bfx\in \ivp(E_0,1)$ where
            \beql{volterra}
			\bff=\mmat{x \\ y} '
			= \mmat{\phantom{-}ax(1-y) \\ -by(1-x)} ,
                    \qquad E_0 = Box_{(1,3)}( 0.1),
			\eeql
		with $a>1$ and $0<b<1$.  We choose $(a,b)=(2,1)$ and
		$E_0=Box_{(1,3)}(0.1)$ to closely
    track the AWA examples in
	\cite{moore:diffEqn:09} and
    \cite[p.13]{bunger:taylorODE:20}. 
	Thus $J_{\bff} =\mmat{2(1-y) & -2x\\ y & x-1}$ and the eigenvalues of
	$\half(J_{\bff}+ J_{\bff}^{\tr})$ are
            $$\half(1+x-2y \pm \sqrt{\Delta(x,y)}), \qquad \text{where } 
            \Delta(x,y)\as 5(x^2+y^2)-6(x+2y)+9$$
	  Note that
	  $\Delta(x,y)=5(x-\tfrac{3}{5})^2 + 5(y-\tfrac{6}{5})^2$ is
	  positive. Thus $\sqrt{\Delta(\bfq)}=\sqrt{5}\|\bfq-\bfp_0\|$
	  where $\bfp_0=(\tfrac{3}{5},\tfrac{6}{5})$.
	  Let $\ell(x,y)\as 1+x-2y$.  Thus $\ell(\bfq)> 0$ iff
	  $\bfq$ lies below the line $1+x-2y=0$.
	  \refFig{Volterra-21-13} shows
	  the trace of $\bfx(t)$ with $\bfx(0)=(3,1)$ and $t\in [0, 5.48]$
	  representing one complete
      cycle as computed by MATLAB; Bunger \cite{bunger:taylorODE:20}
      said that AWA cannot complete this computation 

      \FigEPS{Volterra-21-13}{0.2}{Solution to the Volterra system
	  	with $(a,b)=(1,2)$, and $\bfx(0)=(1,3)$ is shown in blue.
		The points $\bfq$ with negative
		$\mu_2(J_\bff(\bfq))$ lie above the green parabola as defined by
		the red line and red dot.}
 
	We have $\mu_2(J_\bff(\bfq)) = \half(\ell(\bfq)+\sqrt{\Delta(\bfq)})$,
	and this can only be negative when $\ell(\bfq)<0$, i.e., when $\bfq$
	lies above the line $\ell(x,y)=0$.  The algebraic locus of the curve
	$\mu_2(J_\bff(\bfq))=0$ is given by the equation
	$|\ell(\bfq)|^2=\Delta(\bfq)$.
    \ignore{
      We have $\sqrt{5}|\ell(\bfq)|$ is the distance
	  of $\bfq$ from the line $\ell=0$.}   This equation is a parabola
	  defined by the line $\ell(x,y)=0$ and the point $\bfp_0$.
 
    \end{Example}

    \begin{Example}[ 2. Van der Pol System]
		\beql{vanderpol}
			\bff=\mmat{x \\ y} '
			= \mmat{y \\ -x^2y + y-x} ,
                    \qquad E_0 = Box_{(-3,3)}( 0.1).
			\eeql
		It could be checked that the logarithmic norm of this system is
		always positive.

        \NOignore{
              $J_f = \mmat{0 & 1 \\ -2xy -1 & 1-x^2}$
              and the two eigenvalues
              of $(J_f+ J_f\tr)/2$ are
              
              $\mmat{ 1-x^2 + \sqrt{(1-x^2)^2 + 4x^2y^2}\\
                     1-x^2 - \sqrt{(1-x^2)^2 + 4x^2y^2}
                         }$,
            and the larger eigenvalue is always positive.
        }
	\end{Example}
	
	\begin{Example}[ 3.]
		Consider the system  
		\[
		\bff=\mmat{x \\ y} '
		= \mmat{x^2 \\ -y^2 + 	7x} , 
            \qquad E_0 = [-2.0, -1.0] \times [8.0, 9.0].
		\]
		The logarithmic norm of this system is initially negative but
		becomes positive. The solution to the $x$-component is $x(t)=
		\tfrac{1}{x_0\inv -t}$ which is negative for all $t>0$ (assuming
		$x_0<0$). Thus the $y$-axis is an asymptote of the solution curve
		(red curve in \refFig{neg-pos-system}). If the end enclosure
		$F_1=Box_{\bfp_1}(w_x, w_y)$ then $w_y/w_x\to \infty$. We have
		$J_\bff=\mmat{2x& 0\\ 7&-2y}$, and the eigenvalues of
		$\half(J_\bff+J_\bff{\tr})$ are
        $(x-y) + \sqrt{(x+y)^2 + (7/2)^2}$.
		        The phase portrait of this system is seen in
		\refFig{neg-pos-system}. The solution
		$\bfx$ with $\bfx(0)=(-1.5, 8.5)$ is shown in red.
	
		\FigEPS{neg-pos-system}{0.3}{Phase Portrait of Example 4}
	
    We check that for any point $\bfp\in\RR^2$ outside
    of the second quadrant $\set{x<0, y>0}$, we have
    the property
    $\mu_2(J_\bff(\bfp))>0$.   Moreover, for
     any solution $\bfx(t)\in \ivp(E_0,1)$ there is a moment 
        $0< t_1<1$ such that
        $\mu_2(J_\bff(x(t)))$ is negative if $t<t_1$
        and positive if $t>t_1$.  
	\end{Example}

     \begin{Example}[ 4. Lorenz System]

     {\small\beql{lorenz}
       \bff = \mmat{x\\y\\z}' = 
            \mmat{\sigma(y-x)\\ 
                    x(\rho-z)-y\\
                    xy-\beta z},
        \qquad
        E_0 = Box_{(15,15,36)}(0.1),
        \quad
        (\sigma,\rho,\beta)=(10,28,8/3).  
          \eeql}

     We have
     {\small $J_\bff=\mmat{-10 & 10 & 0\\
                    28-z & -1 & -x\\
                    y  & x  & -8/3}
     $} and
    {\small $\half(J_\bff+J_\bff{\tr})=\mmat{-10 & 19-\half z & \half y\\
                    19-\half z & -1 & 0\\
                    \half y  & 0  & -8/3}
     $}.  
	 We could no longer easily compute global bounds on log norms,
	 but only obtain bounds on $\olmu =\mu_2(J_\bff(F_1))$ for given
     admissible pair $(h,F_1)$ for $E_0$
 	E.g. for {\small $(h,F_1)=(0.01, 
        [14.80, 15.12]\times [13.34, 15.10] \times [35.75, 37.45])$}
    we obtain the bound
    $\olmu\le 4.33$.
     \end{Example}

	\ignore{\begin{Example}[ 4.]
	 	Consider the IVP where   
	 	\[
	 	\bff=\mmat{x \\ y} '
	 	= \mmat{x^2-2x+4 \\ -y^2 + 2y-7x-4} ,
                 \qquad
                E_0 = [-2.1, -1.9] \times [6.9, 7.1].
	 	\]
        \end{Example}
    }%ignore
}%	
% file: extend-refine.tex
%		(copied from shrink.tex)

\sect{ \Extend\ and \Refine\ Subroutines}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	We present algorithms for
	\Extend\ and \Refine\
	(see \refeqs{extend}{refine} for the input-output
	specifications of these subroutines).

	For efficiency, we will augment the concept of a scaffold
	to keep track of global parameters such as $\bff$, as well as
	computed values from each stage.
	For the $i$th stage with admissible triple
	$(E_i,\Delta t_i, F_i)$, we have computed values such as
	the transformation parameters ($\pi$ and $\bfg$)
	and the \lognorm\ bounds ($\olmu_1$ and $\olmu_2$) for
	$(\bff,F_i)$ and $(\bfg,\pi(F_i))$.
	%%
	More precisely, we define an \dt{augmented scaffold}
	$\calD$ by adding an extra component $\bfG$ to the
	usual $m$-stage scaffold:
			$\calD = (\bft, \bfE, \bfF, \bfG)$
	where $\bfG=(G_1\dd G_m)$. 
	%To motivate the components of $\bfG$,
	As usual, $G_i = G_i(\calD)$ where
		$$G_i(\calD) =(\pi_i,\bfg_i,\olmu^1_i,\olmu^2_i;
					\cored{\delta_i, h_i, \ell_i, \bfE_i, \bfF_i})$$
	where the parameters in red are
	extra data needed by the \Refine\ subroutine below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{\Extend\ Subroutine}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	Basically, 
	$\Extend(\calD, \veps,\delta,H)$
		calls $\stepA$ to add a new stage to $\calD$.
		Note that we view $\calD$ is an object in the sense
		of OOPL, and write $\calD.\Extend(\cdots)$ to call
		$\Extend$ to modify itself: 

	{\scriptsize
	\Ldent\progb{
		\lline[0] $\calD.\Extend(\veps,\delta,H)$ 
		\lline[5] INPUT: $m$-stage augmented scaffold $\calD$, 		
							$\veps>0$, $\delta>0, H>0$.
		\lline[5] OUTPUT:  	$\calD'$ 
							is a $m+1$-stage refinement of $\calD$
							such that 
		\lline[25]		 $(t_{m+1}(\calD')-t_m(\calD),E_{m+1}(\calD))$
							is an $\veps$-admissible pair. 
						
		\lline
		\lline[10]  $(h,B_1)\ass \stepA(E_m(\calD),\veps,H)$.
		\lline[10] $\olmu_1\ass \mu_2(J_{\bff}(B_1))$.  
		\lline[10]  $(\olmu_2,\pi,\bfg)\ass \Transform(\bff,B_1,\olmu_1)$.
		\lline[10]  $\delta'_1\ass \TransformBound(\delta,
		\pi, B_1)$
			\lline[10]  $h_1\ass 
		h(h,\|\bfg^{[2]}(\pi(B_1))\|,
		\olmu_2,\delta'_1)$.
		\Commentx{ See \refeq{h1}.}
		\lline[10] 	return $\calD';(t_m+h,B_1,B_1)$,
		$(\pi,\bfg,\olmu_1,\olmu_2,\delta, 
		h_1,(E_m(\calD),B_1),(B_1))$.
	}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{\Refine\ Subroutine}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	The goal of $\calD.\Refine(\veps)$ is to ensure that
	the end-enclosure of $\calD$ has max-width $\le \veps$.
	This is achieved by making the admissible quad
			$(E_{i-1},\Delta t_i, F_i, E_i)$
	$\delta_i$-bounded (see \refeq{deltabound})
	for each stage $i$ where $\delta_i$ is halved
	iteratively. We can achieve this bound using
	\refLem{eulerStep} and \refCor{cor-1}.  But this is very inefficient.
	Instead, we introduce a\footnote{
		Viewing the $i$th stage as a \bigStep,
		the mini-scaffold represent \smallStep s of 
		the $i$th stage. 
	} 
	``mini-scaffold'' $\bfG_i=(\ell_i, \bfF_i,\bfE_i)$
	into stage $i$ where the time grid is uniform
	with step size $(\Delta t_i)\cdot 2^{-\ell_i}$.
	%
	% where $\bfE_i$ and $\bfF_i$ are $2^{\ell_i}$-vectors,
	See Figure \ref{fig:d-q} for illustration.
	Now, we can adaptively increment $\ell_i$ to refine the
	$i$th stage.
		%
	% This is done using the \Bisect\ subroutine below.
		%
	But when $(\Delta t_i)2^{-\ell_i}$ reaches the bound
	of \refeq{h1}, we can update the global data
	$E_i, F_i, \olmu^1, \olmu^2, \pi_i, \bfg_i$, etc.
	Moreover, the $i$th quad is $\delta_i$-bounded
	(by design).
	

	
	% TODO: \usepackage{graphicx} required
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.7\linewidth]{figs/D-Q}
		\caption{$3$-stage scaffold $\calD$ with $\ell_1=2$,
		$\ell_2=1$ and $\ell_3=0$ in $G$.}
		\label{fig:d-q}
	\end{figure}



	\savespace{

	{\small
	\Ldent\progb{
		\lline[0] Bisect$(\calD[i])$  
		\lline[5] INPUT: Some $i$th stage of $\calD$.
		\lline[5] OUTPUT:  A refinement of each small step of the
					$i$th stage. 
		\lline[10] 	(This is a self-modification of $\calD$.)
		\lline[10]  Let $(\pi_i,\bfg_i,\olmu^1_i,\olmu^2_i,
			\delta_i, h_i, \ell_i, \bfE_i, \bfF_i)$ be $G_i(\calD)$
		\lline[10]  Initialize two new vectors $\bfE'$ and $\bfF'$.
		\lline[10]  $h \ass (\Delta t_i)2^{-\ell_i-1}$
		\lline[10]  For $j=1\dd 2^{\ell_i}$,
		\lline[15]  	$E \ass \stepB(\bfE_i[j-1], h, \bfF_i[j])$
		\lline[15]  	$\bfE'.\text{push\_back}(E)$
		\lline[15]  	$\bfE'.\text{push\_back}(\stepB(E, h,
							\bfF_i[j]))$
		\lline[15]  	$\bfF'.\text{push\_back}(\bfF_i[j])$;
						  	$\bfF'.\text{push\_back}(\bfF_i[j])$;
		\lline[10]  $(\ell_i, \bfE_i, \bfF_i)\ass (\ell_i+1, \bfE', \bfF')$
	}}
	We view $\bfE_i$ and $\bfF_i$ as a vector in the sense
	of C++.  Denote the operation of
	appending $E$ to the end of the vector by
	$\bfE_i.\text{push\_back}(E)$.

	}% savespace

	We are ready to describe the \Refine\ subroutine:
	
	{\scriptsize
	\Ldent\progb{
		\lline[0] $\calD.\Refine(\veps)$
		\lline[5] INPUT:  $m$-stage augmented
				scaffold $\calD$ and $\veps>0$.
		\lline[5] OUTPUT: $\calD$ remains an
					$m$-stage augmented scaffold 
         \lline[25]           but 
					the length satisfies $\wmax(E_{m})\le \veps$.
		\lline
		\lline[10] $r_0\ass \wmax(E_m(\calD))$. 
		\lline[10] While ($r_0> \veps$)
		\lline[15]   For ($i=1\dd m$)
		\lline[20]  	Let $(\pi,\bfg,\olmu^1,\olmu^2,
						\delta, h, \ell,
						\bfE, \bfF)$ be $G_i(\calD)$
		\lline[20] 	 	$H\ass (\Delta t_i)2^{-\ell}$
		\llline[1:]{15}{ 	 	If $(H>h)$}
		\lline[25] 	 		$\Bisect(\calD[i])$
		\lline[20] 	 	Else
		\llline[2:]{20}   		$E_0\ass \half E_0$.
		\llline[3:]{20}   		$\delta'\ass \delta$,
								\quad $\delta\ass\delta/2$.
		\lline[25] 			Let $Ball_\bfp(r_0)$ denote the
								circumscribing ball of $\bfE[0]$
		\lline[30]          and $Ball_{\bfp'}(r'_0)$ be the
								circumscribing ball of $\pi(\bfE[0])$.
		\lline[30]			$\bfq\ass \pi(\bfp)$, $d\ass 
		\|\bfq-m(Box(\pi(\bfE[0])))\| $.
		\lline[25]			For ($j=1\dd 2^{\ell}$)
		\lline[30]  			If ($\pi=Id$) 
		\lline[35]					$\bfq\ass \bfm(\bfE[j])$,
									
		\lline[30]				Else 
		\lline[35]				
									$\bfq\ass \bfq+\bfg(\bfq)H$,
									
		\lline[30]				$\delta_1\ass \TransformBound(\delta',
									\pi, \bfF[j])$.
		\llline[4:]{25}{ 		$r_1\ass r_0e^{j\olmu^1 H}+\delta'$,
								$r'_1\ass (r'_0+d)e^{j\olmu^2 H}+\delta_1$}
		\lline[30] 				$B\ass Box(	r_1)$,
								$B'\ass  Box(r'_1)$.
		\lline[30]  			$\bfF[j]\ass \bfF[j] \cap
				\pi\inv(Box(\pi(\bfE[j-1])+B',\bfp'+B')$
		\llline[5:]{25} 				$\bfE[j]\ass \bfE[j]\cap    
		        \pi\inv(\bfq+B')	\cap (\pi\inv(\bfq)+B)$.
		\lline[30] 				$\delta'_1\ass \TransformBound(\delta,
										\pi, \bfF[j])$.
		\lline[30] 				$h\ass 	
					h(h,\|\bfg^{[2]}(\pi(\bfF[j]))\|,\olmu^2,\delta'_1).$
		\lline[25]	\Commentx{End of For ($j=1\dd 2^{\ell}$)}
		\lline[20]  $E_i(\calD)\ass \bfE[2^{\ell}]$, 
					%	\quad $F_i(\calD)\ass Box\Big(
							%\bigcup_{j=1}^{2^\ell}\bfF_j(\calD)\Big)$
		%\lline[20]  Update $\olmu_2$ of $G_i(\calD)$
				%		to $\mu_2(J_\bfg\Big(\bigcup_{j=1}^{2^\ell}
									%\bfF_j(\calD))\Big)$ 
				%\qquad\Commentx{(Experimentally see if this helps)}
		\lline[15]	\Commentx{End of For ($i=1\dd m$)}
		\llline[6:]{10}	{ $r_0\ass\wmax(E_m(\calD))$}
		\lline[10] Return $\calD$.
	}}

	\bleml[refine]
		The subroutine $\calD.\Refine(\veps)$ is correct.
	\eleml

	\savespace{
	\dt{Correctness of \Refine:}
	The proof of correctness of \Refine\ is similar to
	that of \Refine: first, its partial correctness is exactly the same
	as before.  As for termination, we see that
	in each iteration of the while-loop, and for
	each stage ($i=1\dd m$), we either
	call the bisection subroutine or both $\delta$ and
	$E_0$ are halved (Lines 2: and 3:).  We can only bisect at most
	$\ceil{\log_2(\Delta t_i/h_i)}$ times in stage $i$.
	On the other hand, using the same argument as
	for \Refine, as $\delta$ and length of $E_0$ goes to $0)$,
	we know that the value of $r_0$ (Line 6:).  Thus termination 
	must happen.
	}% savespace
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% file: main-algo.tex
%    Taken from shrink3.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{The End-Enclosure algorithm and Experiments}
	The following is our algorithm to
	solve the \endEncIVP\ problem of \refeq{endEncProb}:
	
	{\small
	\Ldent\progb{\label{alg:endEnc}
		\lline[0]  \endEncAlgo($B_0, \veps) \ssa(\ulB_0, \olB_1)$:
		\lline[5] INPUT: $\veps>0, B_0\in \intbox\RR^n$
		\lline[10] such that $IVP(B_0,1)$ is well-defined.
		\lline[5] OUTPUT:	$\ulB_0,\olB_1 \in \intbox\RR^n$,
							$\ulB_0\ib B_0$, $\wmax(\olB_1)<\eps$
		\lline[10] 			and $\olB_1$ is an end-enclosure of
							$\IVP(\ulB_0,1)$.
		\lline
		\lline[15] $\calD\ass 	
					((0),(B_0),(B_0),(Id,\bff,0,0,\veps,0,
					(B_0,B_0),(B_0)))$.
		\lline[15]  $(t,\delta,i)\ass (0,\veps,0)$, $h\ass0, 
						H\ass 1$.
		\lline[15] while $h<H$ 
		\lline[20] $h\ass \stepA(B_0,\veps,H), H\ass \half H$.
		\lline[15] While $t<1$ 
		\lline[20] $\calD.\Extend(\veps,\delta,H)$.
		\lline[20] $\calD.\Refine(\veps)$.
		\lline[20] $t\ass t_{i+1}(\calD)$. $i\ass i+1$.
		\lline[15] return $( E_0(\calD),  E_i(\calD))$.
		
		 
		
	}}
	
	
	\bthml[correct-main]
	Algorithm $\endEncAlgo(B_0, \veps)$ is correct.
	\ethml

	\savespace{
	\bpf
	
	If the algorithm terminates, its correctness is ensured by the
	conclusions in \refSec{stepAB}.
	
	We now proceed to prove the termination of the algorithm. Specifically,
	we need to show that the loop in the algorithm can terminate, which
	means that the time variable $ t $ can reach $ 1 $. 
	
	To establish this, it suffices to demonstrate that for given inputs $
	B_0 $ and $ \veps > 0 $, there exists a positive lower bound for the
	step size, denoted by $ \ul h > 0 $, such that for any $ i > 0 $ in the
	loop, the step size $ h_i = t_{i+1} - t_i $ satisfies $ h_i \geq \ul h
	$.
	
	Consider the state of the scaffold $ \calD $ after the $ i $-th
	iteration of the loop. At this stage, $ \calD $ is an $ i $-step
	scaffold. By the design of the $\Extend$ algorithm, we have 
	\[
	(h_i, F_i) \ass \stepA(E_{i-1}, \veps, 1 - t_{i-1}).
	\]
	 
	
	Since $ \wmax(E_{m-1}) \leq \veps $, let $ \bfx_c \in \ivp(m(B_0), 1)
	$. Then, it holds that 
	\[
	E_{m-1} \ib \bfx_c(T_i) + [-2\veps, 2\veps]^n.
	\]
	
	By \reflem{veps-admisspair}, if 
	\[
	(h(t), F(t)) \ass \stepA\big(\bfx_c(t) + [-2\veps, 2\veps]^n, \veps, 1
	- t\big),
	\] 
	then $ h(t_i) \leq h_i $.
	
	Define 
	\[
	\ul h \ass \min_{t \in [0, 1]} h(t).
	\]
	Since $ h(t) > 0 $ for all $ t \in [0, 1] $,  we conclude that $ \ul h
	> 0 $. 
	
	Thus, for any $ i > 0 $ in the loop, the step size satisfies $ h_i =
	t_{i+1} - t_i \geq \ul h $. This ensures that the loop will terminate
	in a finite number of iterations.
	\epf
	}% savespace
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ssect{Experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		We implemented \ourAlgo\ in \Cpp.
	Our implementation follows the explicitly described
	subroutines in this paper.  There are no hidden hyperparameters
	(e.g., our step sizes are automatically adjusted).
	The only caveat is that we use machine precision:
	this is necessary to have fair comparisons to existing software.
	In principle, we can implement
	our algorithm using arbitrary precision number type
	(which will automatically get a hit in performance
	regardless of precision).
	%%
	Our timings are based on a laptop with a 
	13th Gen Intel Core i7-13700HX 2.10 GHz processor and 16.0 GB RAM.
	Our eventual code will be open-sourced in \cite{core:home}.
	
	
	The example are taken from \refTab{problems} with
	given $(\bff, B_0)$.
	The time span is $t\in [0,1]$ in all the experiments
	except for Eg1-b, where $t\in [0,5.48]$.  This is
	an example that AWA cannot solve \cite[p.~13]{bunger:taylorODE:20}.
	
	
	For each example, we use our algorithm to compute a scaffold
	$\calD(\veps_0)$ for an initial value of $\veps_0$.
	We subsequently
	refine this scaffold using smaller $\veps_i$ ($i=1,2,\ldots$)
	to obtain $\calD(\veps_1)$, $\calD(\veps_2), \ldots$.
	The total number of mini-steps in all the stages of
	$\calD(\veps_i)$ is shown in column
	$\#(\calD)$; the timing for
	each refinement is incremental time.
	% However, when $\#(\calD)$ is relatively small,
	% our \Refine\ algorithm runs efficiently.
	This nice refinement feature gives
	us to better precision control with
	low additional cost after the initial $\calD$.  
	
	
	
	\begin{table*}[h!]
		{\tiny
			\centering
			\begin{tabular}{c|c|c|c|c|c|c|c}
				\hline
				\textbf{Case} & \textbf{Method} & $\veps$ 
				& \textbf{Order} & $\ulB_0$ & $\olB_1$
				& $\#(\mathcal{D})$ & \textbf{Time (s)} \\
				\hline
				Eg1-a & Ours & $0.3$
				& 3 & $Box_{(1.0,3.0)}(0.1)$ & $[0.03,0.12]\times[1.31,1.59]$
				& 27 & 3.297 \\
				& \Refine & $0.1$
				&  & $Box_{(1.0,3.0)}(5.0\times 10^{-5})$
				& $[0.03,0.12]\times[1.41,1.50]$ & 6273 & 4.453 \\
				& \Refine & $0.007$
				&  & $Box_{(1.0,3.0)}(2.0\times 10^{-5})$
				& $[0.07,0.08]\times[1.45,1.46]$ & 6289 & 0.495 \\
				& 	\simpleIVPdirect\  & N/A
				& 3 & N/A & $[-1.00,1.18]\times[0.66,2.25]$
				& N/A & 0.343 \\
				& 	\simpleIVPlohner\ & N/A
				& 3 & N/A & $[0.008,0.093]\times[1.30,1.56]$
				& N/A & 0.015 \\
				& \capdCr\ & N/A
				& 3 & N/A & $[0.05,0.09]\times[1.38,1.54]$
				& N/A & 8.930 \\
				& \capdCr\ & N/A
				& 20 & N/A & $[0.05,0.10]\times[1.37,1.55]$
				& N/A & 0.049 \\
				%& Lohner & / &  & / & $[0.02,0.10]\times[1.35,1.50]$ & -- & 0.182s \\
				\hline
				Eg1-b & Ours & $3.3$
				& 3 & $Box_{(1.0,3.0)}(0.00156)$
				& $[-0.39,2.29]\times[1.37,4.62]$ & 115 & 42.712\\
				& \Refine\ & $1.6$
				&  & $Box_{(1.0,3.0)}(2.3\times 10^{-11})$
				& $[0.16,1.72]\times[2.25,3.81]$ & 231553 & 372.617 \\
				& \Refine\ & $0.6$
				&  & $Box_{(1.0,3.0)}(1.1\times 10^{-11})$
				& $[0.69,1.21]\times[2.77,3.28]$ & 231681 & 15.479 \\
				& \simpleIVPdirect\ & N/A
				& 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \simpleIVPlohner\ & N/A
				& 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \capdCr\ & N/A
				& 3 & N/A & \cored{No Output}
				& N/A & \cored{No Output} \\
				& \capdCr\ & N/A & 20 & N/A & \cored{No Output}
				& N/A & \cored{No Output} \\
				\hline
				Eg2 & Ours & $0.51$ & 3 & $Box_{(-3.0,3.0)}(0.1)$
				& $[-2.38,-1.88]\times[0.37,0.75]$ & 19 & 1.781 \\
				& \Refine\ & $0.26$ &  & $Box_{(-3.0,3.0)}(2\times 10^{-5})$
				& $[-2.15,-2.12]\times[0.54,0.58]$ & 12353 & 10.287 \\
				& \Refine\ & $0.01$ &  & $Box_{(-3.0,3.0)}(1\times 10^{-5})$
				& $[-2.14,-2.13]\times[0.56,0.57]$ & 12353 & 0.868 \\
				& \simpleIVPdirect\ & N/A & 3 & N/A
				& $[-2.74,-1.53]\times[-2.11,3.12]$ & N/A & 1.844 \\
				& \simpleIVPlohner\ & N/A & 3 & N/A
				& $[-2.42,-1.62]\times[0.40,0.72]$ & N/A & 1.566 \\
				& \capdCr\ & N/A & 3 & N/A 
				& $[-2.37,-1.89]\times[0.40,0.72]$ & N/A & 6.097 \\
				& \capdCr\ & N/A & 20 & N/A
				& $[-2.39,-1.87]\times[0.36,0.76]$ & N/A & 0.050 \\
				\hline
				Eg3 & Ours & $0.6$ & 3 
				& $Box_{(-1.5,8.5)}(1.9\times 10^{-6})$
				& $[-0.60,-0.59]\times[-7.08,-6.53]$ & 9237 & 9.511 \\
				& \Refine\ & $0.3$ &
				& $Box_{(-1.5,8.5)}(4.7\times 10^{-7})$
				& $[-0.60,-0.59]\times[-6.80,-6.63]$ & 11729 & 2.641 \\
				& \Refine\ & $0.1$ &
				& $Box_{(-1.5,8.5)}(1.1\times 10^{-7})$
				& $[-0.60,-0.59]\times[-6.72,-6.67]$ & 14785 & 3.259 \\	
				& \simpleIVPdirect\ & N/A & 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \simpleIVPlohner\ & N/A & 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \capdCr\ & N/A & 3 & N/A & \cored{No Output}
				& N/A & \cored{No Output} \\
				& \capdCr\ & N/A & 20 & N/A & \cored{No Output}
				& N/A & \cored{No Output} \\
				
				\hline
				Eg4 & Ours & $9.0$ & 3 & $Box_{(15,15,36)}(8\times 10^{-4})$
				& $[-8.85,-5.04]\times[-1.36,7.35]\times[31.26,39.02]$
				& 32 & 61.673 \\
				& \Refine\ & $3.0$ & & $Box_{(15,15,36)}(8\times 10^{-7})$
				& $[-8.40,-5.48]\times[1.53,4.45]\times[33.68,36.60]$
				& 44033 & 126.665 \\
				& \Refine\ & $1.0$ & & $Box_{(15,15,36)}(5.9\times 10^{-9})$
				& $[-7.42,-6.46]\times[2.51,3.47]\times[34.66,35.62]$
				& 44033 & 27.824 \\
				& \simpleIVPdirect\	& N/A & 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \simpleIVPlohner\	& N/A& 3 & N/A & \cored{Timeout}
				& N/A & \cored{Timeout} \\
				& \capdCr\ & N/A & 3 & N/A & \cored{No Output} & N/A
				& \cored{No Output} \\
				& \capdCr\ & N/A & 20 & N/A & \cored{No Output} & N/A
				& \cored{No Output} \\
				\hline
			\end{tabular}
		}
		\caption{Experiments on \ourAlgo\ and \Refine.}
		\label{tab:main}
	\end{table*}
	
	We compared our algorithm with 3 other algorithms:
	
	1. First, algorithm is from
	the CAPD library \cite{capd-homepage} with source code in github.
	% https://github.com/CAPDGroup/CAPD
	In \refTab{main}, the method \capdCr\ refers to their method
	\ttt{ICnOdeSolver} with order $r=3$ or $20$,
	based on the $C^r$-Lohner algorithm
	\cite{zgliczynski:lohner:02,capd:rigorousDynSys:21}.
	The method accepts an interval input such our $B_0$.
	%%
	%It is not clear that the CAPD algorithm (whose
	%algorithmic details are not described) is validated since it seems
	%difficult to introduce a suitable StepA for the entire cascade of
	%stages in Lohner-style algorithms. 
	% Attempts to provide an adaptive
	% StepA may not halt \cite[p.38, Algorithm
	% 5.3.1]{nedialkov+2:validated-ode:99}. 
	% We use the default CAPD Taylor order of $20$.
	% but it fails to produce any output for
	% Eg1-b, Eg3, and Eg4.
	% In contrast, our method reliably produces results in all cases.  
	
	2 \& 3. We also implemented the \simpleIVP\ algorithm 
	in \refeq{simpleivp}, where \stepB\ is either the 
	Direct method \refeq{stepBdirect} and
	well as our own implementation of the
	the Lohner method. In \refTab{main}, they are called 
	\simpleIVPdirect\ and \simpleIVPlohner, respectively.  
	
	Our table indicates two kinds of error conditions:
	\cored{Timeout} (\simpleIVPdirect, \simpleIVPlohner)
	and \cored{No Output} (\capdCr).
	The former means the code took more than 1 hour to run.
	the latter means the code stopped with no output.
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	This paper introduces a novel way to exploit
	contractive systems locally using \lognorm s.
	We presented the first complete validated IVP 
	algorithm with the unique ability to pre-specify the
	desired precision $\vareps$ of the output. 
	Preliminary implementations shows promise.

\savespace{
	It is interesting to contrast our approach to the
	Lohner-type algorithms 
	\cite{nedialkov+2:validated-ode:99}
	where the original differential
	equation $\bfx'=\bff(\bfx)$ is successively transformed into
    $\bfx_1'=\bff_1(\bfx_1)$,
    $\bfx_2'=\bff_2(\bff_2)$, etc.
    The successive computations are
    done in the transformed space of $\bfx_m$ (after $m$ transforms).
    In contrast
    
	Let us give the precise description of the $\bff_i,\bfx_i$
	$\bfx_i'=\bff_i(\bfx_i)$
	for $i=1,2,\ldots$.
	We thus avoid  his iterative sequence of matrix products
	$A_1A_2\cdots A_i$.
}
    
	In \cite[Section 10]{nedialkov+2:validated-ode:99}, 
		% also: Corliss \cite{corliss:survey-ode-intvl:89}
	``{\em Some Directions for Future Research}'',
	the authors
	presented a list of challenges that remain relevant today.
	Our algorithm is one answer to their call for automatic
	step sizes, order control (interpreted as error control)
	and tools for quasi-monotone problems (i.e., contractive systems).
	% the section ``Some Directions for Future Research'',
	% There are still many challenges to address, such as 
		%%
	% 	greater efficiency,
	% 	automatic step sizes, and termination
	% 	Stetter \cite{stetter:validatedODE:90},

\dt{Limitations}:
	\ignore{
	    1. We have only described an abstract algorithm
		and wrote small test examples.
		A further development 
		along the lines of the AIE framework
		\cite{xu-yap:real-zero-system:19}).
    }
	1. As our approach is not a Lohner-type algorithm, it is 
	impacted by the wrapping effect.  This is seen in the growth of
	number of stages $\#(\calD)$ as $\veps$ decreases
	(particularly in Eg3).
	
	2. The efficiency of our algorithm can be further
	improved by carefully
	selecting appropriate parameter values $(\veps, H)$ in \stepA\ and
	optimizing the choice of $\bfd$ in the transform.
	We offer them as options for the user, but such options
	do not affect the correctness of our algorithm.
	



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
%\section*{Appendix A: Proofs}
\section{Appendix A: Proofs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%\ssect{The relevant proofs of the conclusions in the paper }
	Note that the numberings of lemmas and theorems
	in this Appendix are the same as corresponding
	results in the text, and have hyperlinks to the text.
	
	
	\dt{ \refCor{cor-1}}
		\issacArxiv[]{
			{\em  \ \\
			Let $\bfx_1\in \ivp(\bfp_1,h,Ball(\bfp_0,r))$ 
			and $\bfx_2\in \ivp(\bfp_2,h,Ball(\bfp_0,r))$.
			\\ If $\olmu\ge \mu_2(\frac{\partial \bff}
			{\partial \bfx}(Ball(\bfp_0,r)))$
			then for all $t\in [0,h]$
			\beq
			\|\bfx_1(t)-\bfx_2(t)\|_2
			\le \|\bfp_1-\bfp_2\|_2 e^{\olmu t}.\eeq
			}
	}
		\bpf
		Note that $\bfx_1$ and $\bfx_2$ are solutions of \refeq{bfx'}
		with different initial values. Therefore, we have $\bfx'_1 =
		\bff(\bfx_1)$ and $\bfx'_2 = \bff(\bfx_2)$. This implies that
		
		\[
		\bfx'_1(t) - \bff(\bfx_1(t))
		= \bff(\bfx_1(t)) - \bff(\bfx_1(t)) = 0 = \veps.
		\]
		If $\olmu\ne 0$, then \refeq{bfx12} is the first case
		of \refeq{xibfx} since $\delta=\|\bfp_1-\bfp_2\|_2$.
		If $\olmu=0$, it comes from the second case since $\veps=0$.
		\epf
	
	The following is a useful lemma:

	\blemT[eulerOneStep]{Full-enclosure for One Euler Step}\ \\
		Let		$(B_0,H,B_1)$
		be an admissible triple with 
		$\olmu\ge \mu_2(J_{\bff}(B_1))$,
		and
		$ M\ge \|\bff^{[2]}(B_1)\|$.
		Denote the Euler step at $\bfq_0\in B_0$
		by the linear function
		$$\ell(t;\bfq_0) = \bfq_0 + t \bff(\bfq_0).$$
		Then for all $t\in [0,H]$,
		$$\|\bfx(t;\bfp_0)-\ell(t;\bfq_0)\|
		\le \|\bfp_0-\bfq_0\| e^{\olmu t}+ \half Mt^2$$
	\elemT	
	\bpf
		By \refCor{cor-1},
		\beql{localcor1}
		\|\bfx(t;\bfp_0)-\bfx(t;\bfq_0\| \le 
		\|\bfp_0-\bfq_0\|e^{\olmu t}
		\eeql
		We also have
		\beqarrys
		\bfx(t;\bfq_0) &=& \bfq_0 + t\cdot \bff(q_0)
		+ \half t^2 \bfx''(\tau)
		& \text{(for some $\tau\in [0,t]$)}\\
		\lefteqn{\|\bfx(t;\bfq_0) - (\bfq_0 + t\cdot \bff(q_0))\|} \\
		&\le& \| \half t^2 \bfx''(\tau)\| \\
		&=& \| \half t^2 \bff\supn[2](\bfx(\tau;\bfq_0)\| \\
		&\le& \| \half t^2 M\|
		& \text{(since $M\ge \bff\supn[x](B_1)$)}
		\eeqarrys
		Combined with \refeq{localcor1},
		the triangular inequality shows our desired bound.
		\epf
		
	
	\dt{	\refLem{eulerStep}}\ \\
	{\em
		Let $(B_0,H,B_1)$ be admissible triple,
	$\olmu\ge \mu_2(J_{\bff}(B_1))$ and
	$ M\ge \|\bff^{[2]}(B_1)\|$.
	%%
	If $h_1>0$ is given by
	\beq
	h_1\ass h(H,M,\olmu,\veps) \as
	\begin{cases}
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)}}
		&\rmif\ \olmu\ge 0\\
		\min\set{H, \frac{2\olmu\veps}
			{M \cdot (e^{\olmu H}-1)-\olmu^2\veps}}
		&\rmif\ \olmu<0
	\end{cases}
	\eeq
	consider the path $Q_{h_1}=(\bfq_0,\bfq_1\dd \bfq_m)$ 
	from the Euler method with step-size $h_1$.
	If each $\bfq_i\in B_1$ ($i=0\dd m$),
	then for all $t\in [0,H]$, we have
	\beq
	\|Q_{h_1}(t)-\bfx(t;\bfq_0)\|\le \veps.
	\eeq
	I.e., $Q_{h_1}(t)$ lies inside the $\veps$-tube of $\bfx(t;\bfq_0)$.
	}
	\bpf
	For simplicity, we only prove the lemma
	when $H/h_1$ is an integer.
	We first show that the Euler method with step size $h_1>0$ 
	has the following error bound:
	\beql{gm}
	\|\bfq-\bfx(H)\|\le 	
	\begin{cases}
		\frac{Mh_1}{2\olmu}(e^{\olmu H}-1) & \olmu\ge 0,\\
		\frac{Mh_1}{2\olmu+\olmu^2 h_1}(e^{\olmu H}-1) & 
		\olmu<0.
	\end{cases}
	\eeql
	To show \refeq{gm}, assume
	$(\bfp_0=\bfx(0),\bfp_1\dd \bfp_m=\bfq)$  are obtained by the
	Euler method corresponding to $t_0=0,t_1\dd t_m=H$. 
	Let $g_i=\|\bfp_i-\bfx(t_i)\|_2$ be the error bound.  Then we have 
	\beqarrys
	g_m &\le&  g_{m-1}e^{\olmu h_1}+
	\frac{Mh_1^2}{2}
	& \text{(by Taylor formula)}\\
	&\le& g_{m-2}e^{\olmu h_1}+
	\frac{Mh_1^2}{2}
	e^{\olmu h_1} +	\frac{Mh_1^2}{2}
	& \text{(by expanding $g_{m-1}$)}\\
	&\vdots& \\
	&\le& \frac{Mh_1^2}{2}(1+e^{\olmu 		
		h_1}+\cdots e^{\olmu h_1 (m-1)})
	& \text{(since $g_0=0$)}\\
	&\le&   \frac{Mh_1^2}{2}\frac{e^{\olmu H}-1}
	{e^{\olmu h_1}-1}\\	
	&\le& \clauses{
		\frac{Mh_1}{2\olmu}(e^{\olmu H}-1)
		& \rmif\ \olmu\ge 0,\\
		%%%%%	
		\frac{Mh_1}{2\olmu+\olmu^2 h_1}(e^{\olmu H}-1)
		& \rmif\ \olmu< 0.}
	\eeqarrys
	If $\olmu\ge 0$, then the last formula is justified by
	$e^{\olmu h_1}-1\ge \olmu h_1$, and
	so $g_m\le \frac{Mh_1}{2\olmu}(e^{\olmu H}-1)$.
	If $\olmu<0$, then the formula is justified by
	$e^{\olmu h_1}-1\le \olmu h_1+ \half\olmu^2 h^2_1$
	(use the fact that $f(x)=e^x - 1-x-\half x^2<0$
	when $x<0$; check that $f'(x)=e^x-1-x>0$ for all $x<0$).
	This proves \refeq{gm}.
	
	Focusing on the case $\olmu<0$:
	we claim that 
	$$\delta>\frac{Mh_1}{2\olmu+\olmu^2 h_1}(e^{\olmu H}-1)$$
	is equivalent to 
	$$h_1 < \frac{2\olmu\delta}
	{M \cdot (e^{\olmu H}-1)-\olmu^2\delta}.$$
	This is verified by direct algebraic manipulation.
	\epf	
	
	\dt{ \refLem{ad}}
		\issacArxiv[]{{\em \ \\
			Let $ k \geq 1 $, $ H > 0 $, $ \veps > 0 $, and 
			$ E_0 \ib \RR^n $. Define  
			\[
			\ol{B} = \sum_{i=0}^{k-1} [0, H]^i \bff^{[i]}(E_0) + 	[-\veps,
			\veps]^n, \qquad
			M := \sup_{\bfp \in \ol{B}} \| \bff^{[k]}(\bfp) \|_2.
			\]  
			Then, the pair $(h, F_1)$ is $\veps$-admissible for $E_0$, where  
			\[
			h = \min \left\{ H, \left( \frac{\veps}{M} 	\right)^{\frac{1}{k}}
			\right\},  \qquad
			F_1 = \sum_{i=0}^{k-1} [0, h]^i \bff^{[i]}(E_0) + 
			[-\veps, \veps]^n.
			\]  
	}}
		\bpf
		To verify \refeq{tay},
		we only need to verify
		\[[0,h]^k\bff^{[k]}(F_1)\ib [-\veps,\veps]^n.\]
		We have:
		\beqarrys
		h^k\bff^{[k]}(F_1)
		&\ib& h^k[-M,M]^n
		&\text{(by the definition of $M$  )}\\
		&\ib& [-\veps,\veps]^n.
		&\text{(by the definition of $h$  )}
		\eeqarrys
		\epf
		
		
		%\blemT[endenclosure]{Triangular Inequality} \ \\
		\blemDIY[Lemma A.1. \text{(Triangular Inequality)}]
			{\label{lem:endenclosure} \ \\
		Let
		$\bfx_c \in \ivp(\bfp_0, h,F_1)$,
		and 
		$\olmu= \mu_2(J_\bff(F_1))$ (not necessarily negative).
		Suppose $\bfq_0$ satisfies
		\[
		\|\bfq_0 - \bfx_c(h)\|_2 \leq \delta,
		\]
		then for any $\bfx \in \ivp(E_0, h)$ where $E_0=Ball(\bfp_0,r)$, 
		we have $\bfx(h) \in Ball(\bfq_0, r)$,
		where  $r = r_0 e^{\olmu h} + \delta$. 
		}
		%\elemT

		\bpf
		By \refCor{cor-1} we have for any $\bfx\in\ivp(E_0,h)$,
		$\|\bfx(h)-\bfx_c(h)\|\le r_0e^{\olmu h}$.
		Since $\|\bfq_0 - \bfx_c(h)\|_2 \leq \delta$, 
		then by the triangular inequality 
		we have 
		$$\|\bfq_0 - \bfx(h)\|_2\le \|\bfx(h)-\bfx_c(h)\|+\|\bfq_0 -
		\bfx_c(h)\|_2\le r.$$
		So, $\bfx(h) \in  Ball(\bfq_0, r)$.
		\epf
	
	\dt{\refLem{delta-distance}}
	\issacArxiv[]{{\em\ \\
			Consider 
			$\ivp(Ball(\bfp_0,r_0),h,F_1)$
			and $\olmu = \mu_2(J_\bff(F_1))$.  
			Let $\bfx_c \in\ivp(\bfp_0,h)$
			and $\bfq_0=\bfx_c(h)$.
			If the linear function
			$$\ell(t)\as (1-t/h)\bfp_0+(t/h)\bfq_0$$
			lies in the $\delta$-tube of $\bfx_c$ then
			\benum[(i)]
			\item  $Ball(\bfq_0, r_0 e^{\olmu h}+\delta)$ is an
			end-enclosure for $\ivp(Ball(\bfp_0,r_0),h)$.
			\item  Let $r'=\max(r_0 e^{\olmu h},r_0)$ then
			$Box(Ball(\bfp_0, r'+\delta),
			Ball(\bfq_0, r'+\delta))$
			is a full-enclosure for $\ivp(Ball(\bfp_0,r_0),h)$.
			\eenum
	}}
		\bpf
		% By \refLem{endenclosure},
		% dangerous:
		by {\bf Lemma A.1},
		we have $E_1 =  Ball(\bfq_0, r_0e^{\olmu h}+\delta)$ is the
		end-enclosure for $\ivp(E_0, h)$.  
		
		Next, we prove $(ii)$.  
		We show that for any $T \in [0, h]$,  the end-enclosure of 
		$\ivp(E_0,T)$ is a subset of $Box(Ball(\bfp_0, r' +\delta),
		Ball(\bfq_0, r' +\delta))$.
		Note that
		% by \refLem{endenclosure},
		% dangerous:
		by {\bf Lemma A.1},
		we have $E_1 =  Ball(l(T),
		r_0e^{\olmu T}+\delta)$ is the
		end-enclosure for $\ivp(E_0, T)$.
		
		Let $l(T)_i$ denote the $i$-th component of $l(T)$ and $r(T)\as
		r_0e^{\olmu T}+\delta$. Then, we only need to
		prove that for any $i=1\dd n$, the interval $l(T)_i \pm r(T)$ satisfies  
		\[
		l(T)_i \pm r(T) \subseteq Box((\bfp_0)_i\pm (r'+\delta),
		(\bfq_0)_i\pm (r'+\delta)),
		\]  
		where $(\bfp_0)_i $ and $(\bfq_0)_i $ are the $i$-th components of
		$\bfp_0$ and $\bfq_0$,
		respectively.  
		
		Since $l(T)$ is a line segment, it follows that  
		\[
		\min((\bfq_0)_i, (\bfp_0)_i) \leq l(T)_i \leq \max((\bfq_0)_i, (\bfp_0)_i).
		\]  
		Additionally, we have $r(T) \leq r' + \delta$.  
		
		Combining these observations, we conclude that 
		\[
		l(T)_i \pm r(T) \subseteq Box((\bfp_0)_i\pm (r'+\delta),
		(\bfq_0)_i\pm (r'+\delta)).
		\] 
		
		\epf
	
	%\bleml[Jbfg]
	\blemDIY[Lemma A.2]{\ \\
		\label{lem:Jbfg}
	\benum
	\item $\bfg(\bfy)=J_{\whpi}(\whpi\inv(\bfy))
		\Bigcdot \ol\bfg(\whpi\inv(\bfy))$\\
		$=\diag(-d_i y_i^{1+\tfrac{1}{d_i}}: i=1\dd n)
		\Bigcdot \ol\bfg(\whpi\inv(\bfy)) $.
	\item The Jacobian matrix of $\bfg$ with respect to
		$\bfy=(y_1\dd y_n)$ is:
		\beql{Jbfg}
		J_{\bfg}(\bfy)=A(\bfy)
		+ 
		P\inv(\bfy)
		\Bigcdot 
		J_{\ol\bfg}(\whpi\inv(\bfy))\Bigcdot P(\bfy),
		\eeql
		where 
		$$A(\bfy)=\diag\Big(-(d_i+1)y_i^{\frac{1}{d_i}}\cdot
		(\wt\bfg(\wtpi\inv(\bfy)))_1): i=1\dd n\Big) $$
		and 
		$$P(\bfy)=\diag\Big(\tfrac{\wtpi\inv(\bfy)_i^{d_i+1}}{d_i}:
		i=1\dd n \Big).$$
	\eenum
	}%DIY
	%\eleml
	\issacArxiv[]{
	\bpf
	\benum
	\item 
	For each $ i = 1\dd n $, we have from \refeq{bfy'} that
	$y_i'= g_i(\bfy)$ where $\bfy=(y_1\dd y_n)$,
	$\bfg=(g_1\dd g_n)$, i.e.,
	\beqarrys
	g_i(\bfy) = y_i' 
	&=& \left(\frac{1}{\wty_i^{d_i}}\right)'
	\qquad\text{(by \refeq{bfy'} and $y_i=\wty_i^{-d_i}$)}\\
	&=& -d_i \wty_i^{-(d_i+1)} \wty_i' \\
	&=& -d_i y_i^{1 + \tfrac{1}{d_i}} \Big(\wt\bfg
	\big( y_1^{-\tfrac{1}{d_1}}\dd y_n^{-\tfrac{1}{d_n}} \big)\Big)_i\\
	&=& -d_i y_i^{1+\tfrac{1}{d_i}} (\wt\bfg(\wtpi\inv(\bfy)))_i.
	\eeqarrys
	Thus, $$\bfg(\bfy)=
	(g_1(\bfy)\dd g_n(\bfy))
	=\diag(-d_i y_i^{1+\tfrac{1}{d_i}}, i=1\dd n)
	\Bigcdot \wt\bfg(\wtpi\inv(\bfy))$$
	\item 
	By plugging 
	$g_i(\bfy) = -d_i y_i^{1+\tfrac{1}{d_i}} (\wt\bfg(\wtpi\inv(\bfy)))_i$
	into the Jacobian, we get
	{\tiny
		\beqarray
		J_\bfg(\bfy)&=& \mmat{\nabla( g_1(\bfy) ) \\ \vdots \\
			\nabla( g_n(\bfy) } 
		=
		\mmat{\nabla( -d_i y_1^{1+\tfrac{1}{d_i}}
			(\wt\bfg(\wtpi\inv(\bfy)))_1) \\ \vdots \\
			\nabla (-d_n y_n^{1+\tfrac{1}{d_n}} (\wt\bfg(\wtpi\inv(\bfy)))_n)}
		\nonumber\\
		\nonumber\\
		&=& \mmat{\nabla(-d_1 y_1^{1+\tfrac{1}{d_1}})
			(\wt\bfg(\wtpi\inv(\bfy)))_1
			\\ \vdots \\
			\nabla (-d_n y_n^{1+\tfrac{1}{d_n}})
			(\wt\bfg(\wtpi\inv(\bfy)))_n}
		+ \mmat{ -d_1 y_1^{1+\tfrac{1}{d_1}}
			\nabla((\wt\bfg(\wtpi\inv(\bfy)))_1)
			\\ \vdots \\
			-d_n y_n^{1+\tfrac{1}{d_n}} 
			\nabla ((\wt\bfg(\wtpi\inv(\bfy)))_n)}
		\label{eq:splitjacobian}
		\eeqarray
	}
	Note that for any $i=1\dd n$, 
	{\scriptsize
		$$	\nabla (-d_i y_i^{1+\tfrac{1}{d_i}})	(\wt\bfg(\wtpi\inv(\bfy)))_i
		=  
		\big(0\dd 0, -d_i\left(1 + \tfrac{1}{d_i}\right)y_i^{\frac{1}{d_i}}
		(\wt\bfg(\wtpi\inv(\bfy)))_i\dd 0 \big)
		$$}
	and
	{\tiny
		\beqarrys
		-d_i y_i^{1+\tfrac{1}{d_i}}
		\nabla((\wt\bfg(\wtpi\inv(\bfy)))_i)
		&=&  \Big( -d_i y_i^{1+\tfrac{1}{d_i}} 
		\frac{\partial (\wt\bfg(\bfx))_i}{\partial x_j}
		(\wtpi\inv(\bfy)) \frac{\partial \wtpi\inv(\bfy)}{\partial \bfy} : j=1\dd n
		\Big)   \\
		&=& 
		\Big(\tfrac{d_i}{d_j} \left(\tfrac{y_i^{1 + \frac{1}{d_i}} }{y_j^{1 + \frac{1}{d_j}} }\right)
		\frac{\partial (\wt\bfg(\bfx))_i}{\partial x_j}
		(\wtpi\inv(\bfy)) : j=1\dd n \Big)\\
		&=&
		\Big( \tfrac{d_i}{d_j}  \wtpi\inv(\bfy)_j^{d_j+1}
		\frac{\partial (\wt\bfg(\bfx))_i}{\partial x_j}
		(\wtpi\inv(\bfy)) \wtpi\inv(\bfy)_i^{-d_i-1} : j=1\dd n \Big).
		\eeqarrys}
	Thus, $$J_{\bfg}(\bfy)=A(\bfy)+P\inv(\bfy)
	\Bigcdot
	J_{\wt\bfg}(\wtpi\inv(\bfy))\Bigcdot P(\bfy),$$
	where $$A(\bfy)=\diag(-(d_1+1)y_1^{\frac{1}{d_1}} (\wt\bfg(\wtpi\inv(\bfy)))_1)\dd 
	-(d_n+1)y_n^{\frac{1}{d_n}} (\wt\bfg(\wtpi\inv(\bfy)))_n) $$
	and 	$$P(\bfy)=\diag(\tfrac{\wtpi\inv(\bfy)_1^{d_1+1}}{d_1}\dd \tfrac{\wtpi\inv(\bfy)_n^{d_n+1}}{d_n}).$$
	\eenum
	\epf}
	
	
	\dt{\refThm{keylemma}}
	\issacArxiv[]{
		{\em \ \\
			\benum[(a)]
			\item
			\beqarrys
			\mu_2 \big(J_{\bfg} (\pi(F_1))\big)
			&\le&
			\max\set{\tfrac{-(d_i+1)}{\chb_i}:
				i=1\dd n}\\
			&&
			+ \max_{i=1}^n \set{d_i} 
			\cdot
			\|J_{\olbfg}(\olpi(F_1))\|_2
			\cdot
			\max_{i=1}^n \set{\tfrac{(\chb_i)^{d_i+1}}{d_i}}.
			\eeqarrys
			\item If $d_1=\cdots=d_n=d$ then
			$$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)
			\le
			-(d+1)\tfrac{1}{\chb_{\max}}
			+(\chb_{\max})^{d+1}
			\|J_{\olbfg}(\olpi(F_1))\|_2.
			$$
			\eenum
	}}
	\bpf
	% From \refLem{Jbfg}(b)
	% Dangerous:
	From {\bf Lemma A.2(b)}
	%%%
	we have for any $\bfp=(p_1\dd p_n) \in \olpi(F_1)$,
	\beql{splitJacobian1}
	J_{\bfg}(\whpi(\bfp))
	= A(\bfp) + P\inv(\bfp)
	\frac{\partial \olbfg}{\partial \bfx}(\bfp)P(\bfp)
	\eeql
	where
	$P(\bfp)=\diag\big(
	\tfrac{p_i^{d_i+1}}{d_i}: i=1\dd n \big)$
	and
	$A(\bfp) = \diag(a_1\dd a_n)$ with
	\beql{aid1}
	a_i \as -d_i(1 + \tfrac{1}{d_i}) p_i\inv
	\cdot (\olbfg(\bfp))_i. \eeql
	Thus, $A, P$ are diagonal matrices and $p_i\inv$ is well-defined
	since $\bfp\in B_2\ge \1$, \refeq{translation}.
	
	By \refLem{lognorm}(b) and \refeq{aid1}, we conclude that
	the form
	\beql{mudiag}
	\mu_2(A(\bfp))=	\mu_2(\diag(a_1\dd a_n))
	= \max\set{a_i: i=1\dd n}.
	\eeql
	
	From \refeq{olbfg}, we conclude that
	{\small
		\beqarrys
		\mu_2\big(J_{\bfg}(\whpi(\bfp))\big) 
		&=& \mu_2\left(A(\bfp) + P\inv(\bfp)\frac{\partial \olbfg}{\partial
			\bfx}(\bfp)P(\bfp)\right)\\
		&& \text{(by \refeq{splitJacobian1})} \\
		&\le& \mu_2(A(\bfp))
		+ \mu_2\left(P\inv(\bfp)\frac{\partial \olbfg}{\partial
			\bfx}(\bfp)P(\bfp)\right)\\
		&& \text{(by \refLem{lognorm}(a))} \\
		&\le& \mu_2(A(\bfp)) 
		+ \left\|P\inv(\bfp)\frac{\partial \olbfg}{\partial
			\bfx}(\bfp)P(\bfp)\right\|_2 \\
		&& \text{(by \refLem{lognorm}(b))} \\
		&\le& \max\set{\tfrac{-(d_i+1)}{\chb_i}:
			i=1\dd n}\\
		&&
		+\left\|P\inv(\bfp)\right\|\left\|\frac{\partial \olbfg}{\partial
			\bfx}(\bfp)\right\|\left\|P(\bfp)\right\|\\
		&& \text{(by \refeq{matrixnorm})}\\
		&\le& \max\set{\tfrac{-(d_i+1)}{\chb_i}:
			i=1\dd n}\\
		&&
		+ \max_{i=1}^n \set{d_i} 
		\cdot
		\|J_{\olbfg}(\olpi(F_1))\|_2
		\cdot
		\max_{i=1}^n \set{\tfrac{(\chb_i)^{d_i+1}}{d_i}}.
		\eeqarrys
	}
	\epf
	
	
	\dt{\refLem{Set-d}}
	\issacArxiv[]{
		{\em \
			Assuming $d$ satisfies \refeq{d}, we have:
			\benum[(a)]
			\item
			$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)
			\le	 (-2+(\chb_{\max})^{d+2})
			\cdot \frac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}}.$
			\item
			If
			$\log_2(\chb_{\max}) < \tfrac{1}{d+2}$
			then
			$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)< 0$.
			\eenum
	}}
	\bpf
	\benum[(a)]
	\item
	By \refThm{keylemma} we have
	{\small
		\beqarrays
		\mu_2\left(J_{\bfg} (\pi(F_1))\right)
		&\le& -(d+1)\frac{1}{\chb_{\max}}
		+(\chb_{\max})^{d+1}\|J_{\olbfg}(\olpi(F_1))\|_2\\
		&=& \Big(\tfrac{-(d+1)}
		{\|J_{\olbfg}(\olpi(F_1))\|_2}+(\chb_{\max})^{d+2} \Big)
		\cdot \tfrac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}}\\ 
		&&	 \text{(by factoring)} \\
		&\le&  \Big(-2+(\chb_{\max})^{d+2} \Big)
		\cdot \tfrac{\|J_{\olbfg}(\olpi(F_1))\|_2}{\chb_{\max}} \\
		&&
		\text{(By eqn.\refeq{d}, we have $(d+1)
			\ge 2(
			\|J_{\olbfg}(\olpi(F_1))\|_2)$)}. 
		\eeqarrays
	}
	\item
	Since $(\chb_{\max})^{d+2}<2$
	is equivalent to 
	$\log_2(\chb_{\max}) < \tfrac{1}{d+2}$,
	we conclude that
	$\mu_2 \left(J_{\bfg} (\pi(F_1))\right)< 0$.
	\eenum
	\epf
	
	%\bleml[error-bound-under-phi]
	\blemDIY[Lemma A.3]{\ \\
		\label{lem:error-bound-under-phi}
	Let $\bfp,\bfq\in B\ib\RR^n$ and $\phi\in C^1(F_1\to \RR^n)$, then 
	$\|\phi(\bfp)-\phi(\bfq)\|_2
	\le \|J_{\phi}(B)\|_2 \cdot \|\bfp-\bfq\|_2$
	}% endDIY
	%\eleml
	\issacArxiv[]{
	\bpf
	\beqarrys
	\|\phi(\bfp)-\phi(\bfq)\|_2
	&\le&
	\|\phi(\bfq)+J_{\phi}(\xi)\Bigcdot(\bfp-\bfq) -\phi(\bfq)\|_2\\
	&& \text{(by Taylor expansion of $\phi(\bfp)$ at $\bfq$)}\\
	&=&\|J_{\phi}(\xi)\Bigcdot(\bfp-\bfq)\|_2\\
	&\le& \|J_{\phi}(\xi)\|_2 \cdot \|(\bfp-\bfq)\|_2\\
	&\le& \|J_{\phi}(B)\|_2   \cdot \|(\bfp-\bfq)\|_2,
	\eeqarrys
	where $\xi\in B$.
	\epf}
	
	\dt{ \refLem{error-bound-ode}}
	\issacArxiv[]{
		{\em
			\ \\
			Let $\bfy=\pi(\bfx)$ and 
			$$
			\mmatx[rcl]{
				\bfx 	&\in&
				\ivp_{\bff}(\bfx_0,h,F_1),\\
				\bfy 	&\in&
				\ivp_{\bfg}(\pi(\bfx_0),h,\pi(F_1)).
			}$$
			%%%
			For any $\delta>0$ and any point $\bfp\in \RR^n$ satisfying 
			\beq
			\|\pi(\bfp)-\bfy(h)\|_2
			\le \frac{\delta}{\|J_{\pi\inv}(\pi(F_1))\|_2},
			\eeq
			we have 
			$$\|\bfp-\bfx(h)\|_2\le \delta.$$ 
	}}
	\bpf
	\beqarrys
	\|\bfp-\bfx(h)\|_2
	&=& \|\pi\inv(\pi(\bfp))-\pi\inv(\pi(\bfx(h)))\|_2\\
	&=& \|\pi\inv(\pi(\bfp))-\pi\inv(\bfy(h))\|_2\\
	&\le&  			  
	\|J_{\pi\inv}(\pi(F_1))\|_2
	\cdot \|\pi(\bfp)-\bfy(h)\|_2\\
	%  && \text{(by \refLem{error-bound-under-phi})}\\
	&& \text{(by {\bf Lemma A.3})}\\
	&\le& \delta\qquad
	\text{(by condition \refeq{delta1}.)}
	\eeqarrys
	\epf
	
	
	
	\dt{\refLem{refine}}
	\issacArxiv[]{
		{\em
			\benum[(a)]
			\item 	(Partial Correctness)
			Given $\veps>0$ and $\delta$-bounded $m$-stage
			scaffold $\calD$, if 
			the subroutine \Refine($\calD, \delta,\veps$) terminates,
			it is correct.
			\item (Termination) The subroutine \Refine'\
			will halt for any valid input
			$(\calD, \delta,\veps)$.
			\eenum
	}}
	\bpf
	\benum[(a)]
	\item If the subroutine terminates, this conclusion is hold by  the
	loop termination condition.
	More precisely: if the value of $r_0$ in (Line 1:) is
	less than $\veps$, then we terminate without entering
	the while-loop, and the result hold.
	If we enter the while-loop, then termination implies
	that the last statement is the assignment of $r_0$ in (Line 4:).
	Again this is correct.
	\item 
	Let $\calD$ be an $m$-stage scaffold and $\calD'$ be the
	modified scaffold.
	Let
	$r' = \wmax(E_m(\calD')) $.
	By the (Line 2:) %\textbf{Set radius}
	and (Line 3:) %\textbf{Set end-enclosure} 
	in the subroutine, we have $r' \leq 2r(m) $,
	here $r(k)$ (for $k=0\dd m$) is defined by
	\[
	r(k) = \clauses{ r_0 & \rmif\ k=0,\\
		r(k-1)e^{h_k \mu_k} + \delta' & \rmif\ k\ge 1,}
	\]
	where $h_k=t_k-t_{k-1}$,
	$\mu_k=\mu_2(J_{\bff}(F_k(\calD)))$ and $Ball_\bfp(r_0)$ be the circumball of $E_{0}(\calD)$.
	
	Note that in each iteration of the loop, $ E_0(\calD) $ is
	halved.  Thus, $r_0$ is also halved if $ \delta $ is sufficiently small. Consequently, we obtain 
	$ r(m) < \veps $, which implies termination.
	\eenum
	\epf
	
	\dt{\refThm{correct-main}}
	\issacArxiv[]{
		{\em
			\refAlg{endEnc} is correct.
	}}
	\bpf
	
	If the algorithm terminates, its correctness is ensured by the
	conclusions in \refSec{stepAB}.
	
	We now proceed to prove the termination of the algorithm. Specifically,
	we need to show that the loop in the algorithm can terminate, which
	means that the time variable $ t $ can reach $ 1 $. 
	
	To establish this, it suffices to demonstrate that for given inputs $
	B_0 $ and $ \veps > 0 $, there exists a positive lower bound for the
	step size, denoted by $ \ul h > 0 $, such that for any $ i > 0 $ in the
	loop, the step size $ h_i = t_{i+1} - t_i $ satisfies $ h_i \geq \ul h
	$.
	
	Consider the state of the scaffold $ \calD $ after the $ i $-th
	iteration of the loop. At this stage, $ \calD $ is an $ i $-step
	scaffold. By the design of the $\Extender$ algorithm, we have 
	\[
	(h_i, F_i) \ass \stepA(E_{i-1}, \veps, 1 - t_{i-1}).
	\]
	
	
	Since $ \wmax(E_{m-1}) \leq \veps $, let $ \bfx_c \in \ivp(m(B_0), 1)
	$. Then, it holds that 
	\[
	E_{m-1} \ib \bfx_c(T_i) + [-2\veps, 2\veps]^n.
	\]
	
	By \reflem{ad}, if 
	\[
	(h(t), F(t)) \ass \stepA\big(\bfx_c(t) + [-2\veps, 2\veps]^n, \veps, 1
	- t\big),
	\] 
	then $ h(t_i) \leq h_i $.
	
	Define 
	\[
	\ul h \ass \min_{t \in [0, 1]} h(t).
	\]
	Since $ h(t) > 0 $ for all $ t \in [0, 1] $,  we conclude that $ \ul h
	> 0 $. 
	
	Thus, for any $ i > 0 $ in the loop, the step size satisfies $ h_i =
	t_{i+1} - t_i \geq \ul h $. This ensures that the loop will terminate
	in a finite number of iterations.
	\epf

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\sect{Appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{Appendix B: The  affine map $\ol\pi$}
\section{Appendix B: The  affine map $\ol\pi$}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	Consider the condition \refeq{0ninolB1}.
	Let 
	Without loss of generality, assume
	$0 \notin \olI_1$.  To further simplify our
	notations, we assume
	\beql{assume1}  
	\olI_1 >0.
	\eeql  
	In case $\olI_1<0$, we shall indicate the necessary changes
	to the formulas.
	We first describe an invertible linear map
	$\wt\pi:\RR^n\to\RR^n$
	such that
	\beql{pos}
	\wt\pi(\bff(B_1))>\1=(1\dd 1)
	\qquad\text{(Greater-than-One Property of $\wt\pi$)}
	\eeql
	Note that \refeq{pos} means that for each $i=1\dd n$,
	the $i$th component $(\wt\pi(\bff(B_1)))_i$ is greater than one.
	
	To define $\wt\pi$, we first introduce the box $\wtB_1$:
	\beql{olB_1}
	\mmatx{
		\wtB_1
		&\as& Box(\bff(B_1))\\
		&=& \prod_{i=1}^n \olI_i
		& \text{(implicit definition of $\olI_i$)}\\
		&=& \prod_{i=1}^n [\ola_i,\olb_i]
		& \text{(implicit definition of $\ola_i, \olb_i$)}
	} \eeql
	where $Box(S)\in\intbox\RR^n$ is the smallest
	box containing a set $S\ib\RR^n$.
	For instance, $\olI_i=f_i(B_1)$ where $\bff=(f_1\dd f_n)$.
	The assumption \refeq{assume1} says that
	$ \olI_1>0$, i.e., either $\ola_1>0$.
	%Also property (P3) implies $\ola_i<\olb_i$ for all $i$.
	
	We now define the map $\wt\pi:\RR^n\to\RR^n$ as follows:
	$\wt\pi(x_1\dd x_n) = (\wtx_1\dd \wtx_n)$ where
	\beql{wtpi}
	\wtx_i  \as  \clauses{
		\frac{x_i}{\ola_i}	& \rmif\ \ola_i>0,
		& \text{(i.e., $f_i(B_1)>0$)}\\
		\frac{x_i}{\olb_i}	& \eliF\ \olb_i<0,
		& \text{(i.e., $f_i(B_1)<0$)}\\
		x_i+ x_1\big(
		\tfrac{1+\olb_i-\ola_i}{\ola_1}\big)
		& \elsE
		& \text{(i.e., $0\in f_i(B_1)$).}
	}\\
	\eeql
	Note that if \( \olI_1 < 0 \), we only need to modify the third
	clause in \refeq{wtpi} to \( x_i + x_1 \big( \tfrac{1 + \olb_i -
		\ola_i}{\olb_1} \big) \).
	
	
	Observe that $\wt\pi(\wtB_1)$ is generally a parallelopiped,
	not a box.  Even for $n=2$, $\wt\pi(\wtB_1)$ is a parallelogram.
	So we are interested in the box $Box(\wt\pi(\wtB_1))$:
	\beql{B'1}
	\mmatx{
		B'_1 \as Box(\wt\pi(\wtB_1))
		&=& \prod_{i=1}^n I'_i
		& \text{(implicit definition of $I'_i$)}\\
		&=& \prod_{i=1}^n [a'_i,b'_i]
		& \text{(implicit definition of $a'_i, b'_i$)}
	}
	\eeql
	Then we have the following results:
	
	\bleml[B'1] \ 
	\benum[(a)]  
	\item  $\wt\pi$ is an invertible linear map given by
	\beql{olpiolA}
	\wt\pi(\bfx) = \olA\Bigcdot\bfx  \eeql
	$ \frac{1}{\ola_i}$, $ \frac{1}{\olb_i}$ or $1$ along
	the diagonal and other non-zero entries in column 1 only,
	Heres the revised version with improved clarity and formatting:
	
	\[
	\mmat{
		v_1 & & & & \\
		c_2 & v_2 & & & \\
		c_3 & & v_3 & & \\
		\vdots & & & \ddots & \\
		c_n & & & & v_n
	}
	\label{olA}
	\]
	where
	$$v_i=
	\clauses{
		\frac{1}{\ola_i} & \rmif\ \ola_i>0,\\
		\frac{1}{\olb_i}	& \eliF\ \olb_i<0,\\
		1	& \elsE }$$
	$$c_i=
	\clauses{
		0 &\rmif\ 0\nin f_i(B_1),\\
		\tfrac{ 1+ \olb_i-\ola_i}{\ola_1} &\elsE. }$$
	\item The box $Box(\wt\pi(\wtB_1)) = \prod_{i=1}^n I'_i$
	is explicitly given by
	\beql{I'i}
	I'_i = 
	\begin{cases}
		\left[1, \frac{\olb_i}{\ola_i}\right] & \text{if } \ola_i > 0, \\[10pt]
		\left[1, \frac{\ola_i}{\olb_i}\right] & \text{else if } \olb_i < 0, \\[10pt]
		\left[1+\olb_i, \frac{\olb_1}{\ola_1} 
		\big(1 + \olb_i\big(1 + \frac{\ola_1}{\olb_1}\big) - \ola_i\big)\right] 
		& \text{else  }.
	\end{cases}
	\eeql
	
	\item
	The map $\wt\pi$ has the
	positivity property of \refeq{pos}.
	\eenum
	\eleml
	\bpf
	\benum[(a)] 
	\item
	From the definition of $\wtpi$ in \refeq{wtpi},
	we see that the matrix $\olA$ matrix 
	the form described in the lemma.  
	This matrix is clearly invertible.
	\item
	We derive explicit formulas for $I'_i$
	in each of the 3 cases:
	\bitem
	\item If $\ola_i>0$, then it is clear that
	$(\wt\pi(B_1))_i= \left[1, \frac{\olb_i}{\ola_i}\right]$.
	\item Else if $\olb_i<0$, it is also clear that
	$(\wt\pi(B_1))_i= 	\left[1, \frac{\ola_i}{\olb_i}\right]$.
	\item Else, we consider an arbitrary 
	point $\bfx=(x_1\dd x_n)\in \wtB_1$:
	{\small \beqarrys
		(\wt\pi(\bfx))_i &=& x_i+ x_1
		\big(\tfrac{1+\olb_i-\ola_i}{\ola_1}\big)
		&\text{(by definition)}\\
		&\ge& \ola_i +\ola_1\big(
		\tfrac{1+\olb_i-\ola_i}{\ola_1}\big)\\
		&&\text{($x_j\in[\ola_j,\olb_j]$ ($\forall~ j$)
			\& $(1+\olb_i-\ola_i)/\ola_1 > 0$))}\\
		&=& 1+\olb_i.\\
		(\wt\pi(\bfx))_i &=&
		x_i+ x_1\big(
		\tfrac{1+\olb_i-\ola_i}{\ola_1}\big)\\
		&\le& \olb_i +\olb_1\big(
		\tfrac{1+\olb_i-\ola_i}{\ola_1}\big)\\
		&&\text{($x_j\in[\ola_j,\olb_j]$ 
			and $(1+\olb_i-\ola_i)/\ola_1 > 0$)}\\
		&=& \tfrac{\olb_1}{\ola_1}
		\big(1+\olb_i(1+\tfrac{\ola_1}{\olb_1})-\ola_i\big).
		\eeqarrys}
	Since both the upper and lower bounds are
	attainable, they determine the interval $I'_i$
	as claimed.
	\eitem
	\item It is sufficient to show that
	$I'_i\ge1$.
	This is clearly true for the first two clauses of \refeq{I'i}.
	For the last two clauses, we have $I'_i\ge 1+\olb_i$
	by part(b).  The result follows since $0\le \olb_i$.
	\eenum
	\epf
	
	
	Let 	\beql{wtB_1}
	\mmatx{
		B^{*}_1
		&\as& Box(\wt\pi(B_1))\\
		&=& \prod_{i=1}^n I^{*}_i
		& \text{(implicit definition of $I*_i$)}\\
		&=& \prod_{i=1}^n [a^{*}_i,b^{*}_i]
		& \text{(implicit definition of $a^{*}_i, b^{*}_i$)}
	} \eeql
	We now define the affine map
	$\ol\pi:\RR^n\to\RR^n$:
	\beql{olpi}
	\mmatx{
		\ol\pi(\bfx) &=& (\olpi_1(x_1),\olpi_2(x_2)\dd\olpi_n(x_n)) \\
		&& \qquad \text{ where } \bfx=(x_1\dd x_n) 
		\text{ and } \\
		\olpi_i(x)
		&\as& \wtpi(x)-a^{*}_i +1.
	}
	\eeql
	Then we have the following results, which is property (Q2):
	\bleml[olB1] \ \\
	
	
	$\olpi(B_1)>\bf1.$
	%\item %(c)
	%$ \wmax(Box(\wtpi(\wtB_1))) $ depends on $ \wmax(B_1) $, and and approaches zero as $ \wmax(B_1) \to 0 $.
	
	\eleml
	\bpf
	The conclusion follows from the fact that 
	$\wtpi(B_1)\ib \prod_{i=1}^n [a^{*}_i,b^{*}_i]$ and 
	$\olpi(B_1)=\wtpi(B_1)-(a^{*}_1\dd a^{*}_n)+1$.
	
	\epf
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

