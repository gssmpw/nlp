\section{Related Work}
For covariate adjustment, if a DAG is known, we generally focus on whether the adjustment variable satisfies the back-door criterion or the adjustment criterion. However, satisfying the back-door criterion is not always sufficient, and it is known that adjustment by the instrument variable can lead to Z-bias **Pearl, "Causal Diagrams for Empirical Research"**. For example, $pa(X)$ always satisfies the back-door criterion, but if there is an instrument variable in it, it is better to remove it from the adjustment variables. In this paper, this bias can be removed by selecting the smallest set of variables that satisfy the back-door criterion. On the other hand, while practical variable selection methods when the DAG is unknown have been discussed **Shpitser and Pearl, "Direct and Indirect Causal Effects"**, we do not compare them with our study because the assumptions regarding the existence of the DAG are different. In calculating intervention effects, some approaches **Rubin, "The Design versus the Analytical Phase in Regression Analysis"** estimate propensity scores and then remove bias through stratification, matching, inverse weighting, and other techniques. However, even in such approaches, the selection of explanatory variables is important when estimating propensity scores. For example, simulations have shown that selecting variables that have a strong relationship with the intervention variable has a negative impact on the calculation of the intervention effect **Imbens and Rubin, "Causal Inference for Statistics, Social, and Biomedical Sciences"**. Another study compared the results of intervention effect in the case where \textit{all variables are selected}, \textit{variables are selected based on prior knowledge}, and \textit{variables are selected based on the strength of association with the intervention and outcome variables}, etc **Hartmann et al., "Graph-Based Methods for Causal Structure Learning"**. These results indicate that it is better not to use variables that are strongly associated with the intervention variable. In this paper, we have summarized how such negative effects occur, and incorporated the findings of these existing studies into the algorithm in order to avoid such scenarios.

In addition, another study showed that adjustment of a variable that is influenced by the intervention variable can introduce bias **Shpitser and Pearl, "Direct and Indirect Causal Effects"**, thus suggesting that only variables that are ahead of the intervention variable in time should be chosen. However, it should be noted that even if the variable is ahead of the intervention variable, Z-bias or M-bias **Pearl, "Causal Diagrams for Empirical Research"** may occur. Both biases can be avoided by obtaining the DAG, and the structural approach, which constructs the DAG based on knowledge or estimated from data, has an advantage in this regard.

As for CPDAG, one study has proposed an extension of its back-door criterion called the generalized back-door criterion **Shpitser et al., "Counterfactual Structural Balance Theory"**. However, although this study mentions that $pa(X)$ satisfies the generalized back-door criterion, it does not mention how to select variables when there are other sets of variables that satisfy this criterion. There is another method that efficiently calculates intervention effects in each Markov-equivalent DAG and then integrates the results **Brito et al., "Structural Causal Models with Latent Variables"**. As an alternative, we propose an approach to distinguish between cases where the Generalized Adjustment Criterion (GAC) **Shpitser et al., "Counterfactual Structural Balance Theory"** is and is not satisfied, and to narrow down DAGs in the latter case by determining the direction of certain edges.