\section{Related Works}
We review two core directions relevant to our study. Connections with other areas including asynchronous stochastic gradient descent and continual learning are discussed in Appendix~\ref{sec:connections-with-other-areas}.

\smallsection{Federated Learning and Heterogeneity Problem}
Federated learning~\cite{mcmahan2017communication} is a distributed learning paradigm that allows multiple parties to jointly train machine learning models without data sharing, preserving data privacy. Despite the potential, it faces significant challenges due to heterogeneity among participating clients, which is typically classified into two main categories: data heterogeneity and system heterogeneity. Data heterogeneity appears as clients own non-IID (independent and identically distributed) data~\cite{li2020federated,karimireddy2020scaffold,wang2020tackling,zhang2023navigating}. The difference in data distribution causes the local updates to deviate from the global objective, making the aggregation of these models drift from the global optimum and deteriorating convergence. System heterogeneity refers to variations in client device capabilities, such as computational power, network bandwidth, and availability~\cite{wang2020tackling,zhang2021parameterized,li2021fedmask,fang2022robust,alam2022fedrolex,zhang2024few}. These disparities lead to uneven progress among clients, and the overall training process is delayed by slow devices. Traditional federated learning approaches rely on synchronization for weight aggregation~\cite{mcmahan2017communication,li2020federated,reddi2020adaptive}, where the server waits for all clients selected in a round to complete and return model updates before proceeding with aggregation. This synchronization leads to inefficient resource utilization and extended training times, particularly in large-scale deployments involving hundreds or thousands of clients. Addressing the heterogeneity issues is a critical problem for improving the scalability and efficiency of federated learning systems in real-world deployment.

\smallsection{Asynchronous Federated Learning}
Much of the asynchronous federated learning literature focuses on staleness management by assigning weights for aggregating updates according to factors including delay in updates~\cite{xie2019asynchronous}, divergence from the global model~\cite{su2022asynchronous,zang2024efficient} and local losses~\cite{liu2024fedasmu}. For example, \cite{xie2019asynchronous} lets the server aggregate client updates into the global model with a weight determined by staleness. Another line of research caches client updates at the server and reuses them to calibrate global updates~\cite{gu2021fast,wang2024tackling}. For example, \cite{wang2024tackling} maintains the latest update for every client to estimate their contribution to the current aggregation and calibrate global updates. Furthermore, semi-asynchronous methods~\cite{nguyen2022federated,zang2024efficient} balance between efficiency and training stability. For example, \cite{nguyen2022federated} buffers a fixed number of client updates before aggregation. We select representative methods from each category for our comparisons. Besides, some works improve efficiency from a different perspective---through enhanced parallelization. Methods include decoupling local computation and communication~\cite{avdiukhin2021federated} and parallelizing server-client computation~\cite{zhang2023no}. In addition, asynchronous architectures have been explored in other paradigms such as vertical~\cite{zhang2024asynchronous} and clustered~\cite{liu2024casa} federated learning. While these directions complement our work, they fall outside the scope of this study.