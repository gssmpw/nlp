\section{Introduction}
Federated learning~\cite{mcmahan2017communication} is a distributed learning paradigm that allows multiple parties to collaboratively train models without sharing data. The most widely adopted federated learning protocols~\cite{mcmahan2017communication,li2020federated,karimireddy2020scaffold,li2021model,wang2020tackling,zhang2023navigating,zhang2024few} follow a \textit{synchronous} update procedure, where the server waits for all selected clients to finish local training before aggregating updates. This synchronization becomes inefficient under heterogeneous resource conditions, where clients differ in compute, network bandwidth, and data volume, due to distinct device configurations and user-system interaction patterns. 

Asynchronous federated learning offers an alternative approach that aggregates client updates as they arrive (see Figure~\ref{fig:intro-asynchrony}), reducing idle time caused by slower clients. In this setting, when a client is performing local training, the server continuously aggregates updates from other clients, shifting the global model to new states. By the time the client's update reaches the server, it may be stale. 
\begin{wrapfigure}{r}{0.55\textwidth}
\centering
    \includegraphics[width=\linewidth]{figures/intro-asynchrony.pdf}
    \caption{Time synchrony in federated learning. Asynchronous methods reduce idle time and improve resource utilization, suited for large-scale deployments.}
\label{fig:intro-asynchrony}
\end{wrapfigure}
Existing methods manage such staleness by applying a decay factor to updates before aggregating them into the global model~\cite{xie2019asynchronous,liu2024fedasmu,zang2024efficient,su2022asynchronous}. The updated global model is directly returned to the clients for further training. Although down-weighting a stale update reduces its negative impact on global progress, it also diminishes the integration of meaningful knowledge from the client. Moreover, due to data heterogeneity, the optimization objectives of the global and client models are inherently inconsistent---while the global model aims to optimize for the overall data distribution, individual clients minimize loss on their local data. Distributing the latest global parameters to clients for subsequent training can introduce conflicts with their local optimization steps, potentially reversing local gains and leading to oscillations in training.

To address the challenge, we propose to decouple global and local learning progress and calibrate weight shifts to reduce interference during client weight merging. The key insight is that, in the high-dimensional parameter space of neural networks, there are multiple viable directions for effective optimization~\cite{wortsman2021learning}. Some of these directions severely disrupt performance on previously learned distributions, while others have little impact. This offers an opportunity to avoid disruptive components in asynchronous updates and preserve both global progress and client-specific contributions.

We introduce \our, orthogonal calibration for asynchronous federated learning. Our design is motivated by two goals: (1) minimizing interference between global and local optimization by sharing global information perpendicular to client updates, and (2) selecting the most informative direction within the orthogonal hyperplane to maximize knowledge sharing. Specifically, \our maintains separate global and client model weights to accommodate their distinct optimization objectives. When the server receives a client update, the global weights are updated via a moving average with an adaptive decay factor accounting for staleness. For the client model, \our identifies the global weight shift (induced by other clients) during the client's delay. It projects this shift onto the direction of the received client update and subtracts this projected component. The remaining parameters lie in a subspace orthogonal to the client update. Through analysis, we show that this orthogonal calibration strategy keeps maximal global progress while minimizing interference with the local update. The calibrated global shift is then merged with the client model for further training. 

For evaluation, we incorporate realistic delay distributions to reflect the heterogeneous nature of real-world deployments. \our demonstrates an average of 9.6\% accuracy improvement across datasets from diverse application scenarios compared to synchronous methods and a 12$\times$ speedup in reaching a target accuracy, Moreover, it outperforms state-of-the-art asynchronous baselines. We also explore various simulated delay distributions and data heterogeneity levels to understand their impact on model performance and convergence speed.
In summary, our contributions are as follows:
\begin{itemize}[leftmargin=*]
    \item We analyze the key challenges of asynchronous federated learning---the inconsistency of global and local objectives and the detrimental effect of stale updates in heterogeneous environments.
    \item We propose a novel orthogonal calibration method that maintains separate global and local model weights. It projects global shifts onto orthogonal subspaces of local updates before sharing them with clients. This approach reduces interference, preserves meaningful contributions from both global progress and local updates, and enhances knowledge sharing. 
    \item We demonstrate the effectiveness and robustness of \our through comprehensive experiments on multiple datasets and various delay scenarios, providing insights on practical design considerations for large-scale federated learning systems.
\end{itemize}
