\section{Related Work}
\noindent \textbf{Foundation Models in EO.} To use the vast amounts of unlabeled satellite data and achieve label efficiency, i.e. the ability to learn from only few labeled data in fine-tuning, EO Foundation Models are first pretrained on large unlabeled satellite datasets by performing self-supervised learning to extract \textit{special} representations from unlabeled data \cite{Prithvi1, newsatmaepp}. 
Then, in the downstream applications, Foundation Models are fine-tuned by performing supervised learning to specialize in specific applications, i.e. downstream tasks, by learning from a \textit{limited} number of labeled data.
In inference, classification or regression is performed for the downstream task \cite{Fibaek1, Prithvi1}.



\iffalse   
Such tasks that are “downstream” from EO data require the acquisition of labels.  
Also, because Earth is dynamic, labels \textit{change} over time.

and having annotations for a geographical region at a specific point in time 
is not enough. 
\fi 

Self-supervised learning and operating within an EO FM framework \cite{YiWangTUMPaper2025, PrithviIBMNASA} are motivated by the lack of labeled data and the technical impossibility to provide labels for the massive volume of data collected by the European Space Agency (ESA) and other space agencies (e.g., NASA, JAXA). 
Enhancing EO Foundation Models with confidence quantification and assessment is critical to improve their performance. 
%The trove of EO data collected by ESA Sentinel-2 constellation generates approximately 1.6TB of compressed data daily.   
%Lack of labels stands in the way of \textit{accurately} performing important downstream tasks, and confidence quantification is critical to achieve better performance.






\textbf{Confidence-aware models.}   
\noindent There are many different models that perform estimation and confidence assignment \cite{Confquantification2, regressionregressionnew2, regressionuseuseuse}. However, most of the existing models are not for pixel-wise regression building density estimation. Existing models for classification are based on the softmax output probability \cite{Confquantification1}.    
For regression problems where the result is a \textit{real-valued} number, the output softmax layer is not used in the neural network \cite{regressionregressionnew1}.               
Therefore, for regression neural networks that do not use softmax, it is \textit{not} straightforward to apply softmax-probability-based classification confidence methods.

%For classification problems, confidence estimation is commonly based on the softmax output layer and the maximum class probability. 
Without model retraining, it is possible to correct, as well as \textit{calibrate} to achieve no overfitting and use the \textit{entire} range of possible output values, the output softmax probability of deep neural networks \cite{Confidence1}. % that solve classification problems.            
For example, by using temperature scaling: Calibration based on entropy and the difference between the first and \textit{second} top class probabilities, or correction based on the aggregation of dispersion measures of softmax output probabilities over segments. 
Moreover, \textit{with} model retraining, two-headed networks can be used to estimate the \textit{True} Class Probability (TCP), which is a better confidence estimator than Maximum Class Probability (MCP) \cite{Confquantification4}.

For regression tasks, estimating model failures and regions of operation where the model should \textit{not} be trusted is challenging \cite{RegrConfi}.       
%It is important to address the shortcomings of the existing methods.              
%We also            
%Here, w 
We note that if we choose to turn a regression task into a classification problem \cite{regressionregressionnew2}, then we \textit{lose} precision, exactness and the desired outcome of having as an output a real-valued number. %, and having a result with an infinite number of decimal places.      





% In the literature, in addition to NLL and Bayesian neural networks, for confidence assignment and assessment in regression neural networks, evidential regression can also be performed, as well as conformal prediction (i.e. conformal inference) for regression. 

% 1/
% evidential

% 2/
% conformal













Considering the \textit{importance} of solving regression problems \cite{regressionregressionnew1}, for example in EO for the accurate estimation of canopy height Above Ground Biomass (AGB) \cite{Prithvi1}, or for the estimation of CO2 flux, it is crucial to develop methods that address the shortcomings of existing methods and \textit{correctly} compute and assign a confidence metric to the prediction outputs of regression neural networks \cite{Confquantification2}.



The work in \cite{newregression1} proposes a spatial self-corrective learning framework which: a) is able to \textit{locate}     predictions with potential large errors by estimating confidence using Maximum Likelihood Estimation (MLE), b) uses confidence-based pseudo-interpolation to correct low-confidence predictions in local neighborhoods, and c) performs recurrent self-refinement of the estimated height in an iterative manner.
%, and d) performs truth-based correction with a regression layer to address the challenges   
Experiments on different landscapes in the high-latitude regions show improvements compared to the other baseline methods.


The work in \cite{newregression2} 
% https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4665951   
presents a probabilistic regression method. 
The deep neural network estimates the unnormalized density from the input-target pair using a conditional target density $p(y|x)$ model, with energy as the basis $(x, y)$. 
Monte Carlo sampling is used to reduce the negative log probability of this probabilistic $p(y|x)$ model. 
%Our technique outperforms linear regression and other probability- and confidence-based algorithms in four computer image regression challenges.  
%When Faster-RCNN is used for object recognition in the COCO dataset, the suggested model improves average accuracy (AP) by 2.3\% and provides a new, cutting-edge visual tracking system technique for bounding box prediction.  
%This technique covers more concerns than trust-based solutions, including age and head position.  
%This probabilistic regression method for computer vision is realistic and efficient.



Furthermore, in the literature \cite{newregression2, regressiontousenewuse, regressiontousenovel1, regressiontousenovel2}, in addition to probabilistic models and Bayesian neural networks, for confidence assignment and assessment in regression neural networks, evidential regression can also be performed \cite{regreesssiioonn1, regreesssiioonn2, regreesssiioonn3}, as well as conformal prediction (i.e. conformal inference) for regression \cite{reeggrreesssiioonn1, reeggrreesssiioonn2}.



\textbf{EO data noisy labels.}        
Most existing evaluation methods for EO Foundation Models \cite{Prithvi1, paperTerraMindIBM} are based \textit{only} on accuracy.              
However, remote sensing datasets might have noisy labels,  
i.e. incorrect annotations,   
and the evaluation of the performance of EO FMs using only the accuracy  
%on some specific EO datasets    
is not enough and might lead to misleading conclusions.   
Assessing the confidence with which the model performs inference is essential for \textit{usability} and uptake \cite{regressiioonn, SKondylatosPaper2025}.       
Accuracy, on its own, for the models and problems we consider, is \textit{not} a sufficient performance measure.            
An evaluation framework for FMs has to include confidence assessment to benchmark and compare different Foundation Models, evaluating their performance on both \textit{regression} and classification segmentation downstream tasks.  



\iffalse     
In addition, for benchmarking and comparing EO FMs, a single combined evaluation metric has to include the performance accuracy on different \textit{diverse} downstream tasks, also including in the evaluation metric how diverse  
%these   
these use cases are, the number of labeled data in the $n$-shot downstream tasks, confidence quantification and assessment, the number of model weights retrained 
%(i.e. fine-tuning or freezing the FM weights)   
and the training epochs needed for convergence. 
%For the \textit{combined} evaluation metric, the individual metrics have to first be converted to a compatible format, standardized so that they have the same range of numerical values, and then integrated into a single metric.
\fi 



\textbf{Confidence metric.}   
%\iffalse
The confidence metric helps humans to make correct decisions for critical matters \cite{Confquantification4, UQpaperforreggression, paperexplainabiityai1}, e.g. for policy.      
Moreover, to effectively combine possibly contradictory results from different models \cite{Confquantification1}, the assigned confidence metrics can be used to \textit{better}       inform the integration and fusion of the different model outputs.      
Within a Mixture of Experts (MoE) framework, we can effectively \textit{combine} different models using the confidence metric.     
Several different models might have outputs that lead to \textit{different} findings and conclusions.         
In this way, we are able to associate a confidence measure to the inference of each of the models in the MoE and, then, combine their outputs to the final model decision using the individual confidences.

Using the confidence metric that we have assigned to the model output, we are also able to perform anomaly detection, as low confidence is an \textit{indicator} of anomalies.       
This is important as anomaly detection/ Out-of-Distribution (OoD) detection is challenging, especially when the abnormalities are \textit{close} to the normal/ in-distribution samples in the image data space \cite{ADandOoD1, ADandOoD2}.               
In addition, the confidence metric also enables us to perform confidence-based change detection, which is crucial in scenarios when we do \textit{not} have labels for the change, as well as when the change is rare, occurring only a \textit{small} percentage of the time (e.g., $<5\%$, or even $<2\%$).





% Furthermore, in the literature \cite{newregression2, regressiontousenewuse, regressiontousenovel1, regressiontousenovel2}, in addition to probabilistic models and Bayesian neural networks, for confidence assignment and assessment in regression neural networks, evidential regression can also be performed \cite{regreesssiioonn1, regreesssiioonn2, regreesssiioonn3}, as well as conformal prediction (i.e. conformal inference) for regression \cite{reeggrreesssiioonn1, reeggrreesssiioonn2}.     










\begin{figure*}[tb]                                           
%\hspace{110pt}       
\centering \begin{minipage}[b]{.1\linewidth}              
  \centering                                                                    
  \centerline{\epsfig{figure=FigureRegressionFlowchart.pdf,width=11.325cm}}                       
  \vspace{0.01cm}   
\end{minipage}      
%\hfill  
\vspace{-9pt}         
\caption{\small CARE for \textit{confidence}-aware regression: assign confidence metric to predictions, identify wrong predictions and refine {\color{black}the model.}}                  
%\caption{\small Flowchart diagram of the proposed model CAS that performs \textit{confidence}-aware segmentation where we assign a confidence metric to predictions, identify wrong predicted labels, and refine the model.}                   
\label{fig:flowchart}                                                      
\end{figure*}










    
%\fi