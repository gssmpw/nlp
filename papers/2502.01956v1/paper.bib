@article{amunts1997motor,
  title={Motor cortex and hand motor skills: structural compliance in the human brain},
  author={Amunts, Katrin and Schlaug, Gottfried and J{\"a}ncke, Lutz and Steinmetz, Helmuth and Schleicher, Axel and Dabringhaus, Andreas and Zilles, Karl},
  journal={Human brain mapping},
  volume={5},
  number={3},
  pages={206--215},
  year={1997},
  publisher={Wiley Online Library}
}

@article{hikosaka2002central,
  title={Central mechanisms of motor skill learning},
  author={Hikosaka, Okihide and Nakamura, Kae and Sakai, Katsuyuki and Nakahara, Hiroyuki},
  journal={Current opinion in neurobiology},
  volume={12},
  number={2},
  pages={217--222},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{sharma2020dynamics,
    title={Dynamics-Aware Unsupervised Discovery of Skills},
    author={Archit Sharma and Shixiang Gu and Sergey Levine and Vikash Kumar and Karol Hausman},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=HJgLZR4KvH}
}

@article{botvinick2009hierarchically,
  title={Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective},
  author={Botvinick, Matthew M and Niv, Yael and Barto, Andew G},
  journal={Cognition},
  volume={113},
  number={3},
  pages={262--280},
  year={2009},
  publisher={Elsevier}
}

@article{wiering2012reinforcement,
  title={Reinforcement learning},
  author={Wiering, Marco A and Van Otterlo, Martijn},
  journal={Adaptation, learning, and optimization},
  volume={12},
  number={3},
  pages={729},
  year={2012},
  publisher={Springer}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{pateria2021hierarchical,
author = {Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
title = {Hierarchical Reinforcement Learning: A Comprehensive Survey},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453160},
doi = {10.1145/3453160},
journal = {ACM Comput. Surv.},
month = {jun},
articleno = {109},
numpages = {35},
keywords = {subtask discovery, Hierarchical reinforcement learning, hierarchical reinforcement learning taxonomy, hierarchical reinforcement learning survey, skill discovery}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{hafner2022deep,
 author = {Hafner, Danijar and Lee, Kuang-Huei and Fischer, Ian and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {26091--26104},
 publisher = {Curran Associates, Inc.},
 title = {Deep Hierarchical Planning from Pixels},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/a766f56d2da42cae20b5652970ec04ef-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{ajay2020opal,
  title={{\{}OPAL{\}}: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning},
  author={Anurag Ajay and Aviral Kumar and Pulkit Agrawal and Sergey Levine and Ofir Nachum},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=V69LGwJ0lIN}
}

@article{kurutach2018learning,
  title={Learning plannable representations with causal infogan},
  author={Kurutach, Thanard and Tamar, Aviv and Yang, Ge and Russell, Stuart J and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@ARTICLE{li2022hierarchical,
  author={Li, Jinning and Tang, Chen and Tomizuka, Masayoshi and Zhan, Wei},
  journal={IEEE Robotics and Automation Letters}, 
  title={Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning}, 
  year={2022},
  volume={7},
  number={4},
  pages={10216-10223},
  doi={10.1109/LRA.2022.3190100}}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@inproceedings{sharma2023multi,
  title={Multi-Resolution Skill Discovery for Hierarchical Reinforcement Learning},
  author={Sharma, Shashank and Namboodiri, Vinay and Hoffmann, Janina},
  booktitle={NeurIPS 2023 Workshop on Goal-Conditioned Reinforcement Learning},
  year={2023}
}

@article{pertsch2020long,
  title={Long-horizon visual planning with goal-conditioned hierarchical predictors},
  author={Pertsch, Karl and Rybkin, Oleh and Ebert, Frederik and Zhou, Shenghao and Jayaraman, Dinesh and Finn, Chelsea and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17321--17333},
  year={2020}
}

@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ao2021co,
  title={CO-PILOT: Collaborative planning and reinforcement learning on sub-task curriculum},
  author={Ao, Shuang and Zhou, Tianyi and Long, Guodong and Lu, Qinghua and Zhu, Liming and Jiang, Jing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10444--10456},
  year={2021}
}

@article{tamar2016value,
  title={Value iteration networks},
  author={Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{nair2017combining,
  title={Combining self-supervised learning and imitation for vision-based rope manipulation},
  author={Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={2146--2153},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@book{rubinstein2004cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation, and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  volume={133},
  year={2004},
  publisher={Springer}
}

@inproceedings{nagabandi2020deep,
  title={Deep dynamics models for learning dexterous manipulation},
  author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1101--1112},
  year={2020},
  organization={PMLR}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{browne2012survey,
  title={A survey of monte carlo tree search methods},
  author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
  publisher={IEEE}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{parr1997reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart},
  journal={Advances in neural information processing systems},
  volume={10},
  year={1997}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{botvinick2014model,
  title={Model-based hierarchical reinforcement learning and human action control},
  author={Botvinick, Matthew and Weinstein, Ari},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={369},
  number={1655},
  pages={20130480},
  year={2014},
  publisher={The Royal Society}
}

@inproceedings{jurgenson2020sub,
  title={Sub-goal trees a framework for goal-based reinforcement learning},
  author={Jurgenson, Tom and Avner, Or and Groshev, Edward and Tamar, Aviv},
  booktitle={International conference on machine learning},
  pages={5020--5030},
  year={2020},
  organization={PMLR}
}

@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{florensa2017stochastic,
  title={Stochastic neural networks for hierarchical reinforcement learning},
  author={Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.03012},
  year={2017}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  volume={2},
  pages={1094--8},
  year={1993},
  organization={Citeseer}
}

@article{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.00653},
  year={2018}
}

@article{kavraki1998analysis,
  title={Analysis of probabilistic roadmaps for path planning},
  author={Kavraki, Lydia E and Kolountzakis, Mihail N and Latombe, J-C},
  journal={IEEE Transactions on Robotics and automation},
  volume={14},
  number={1},
  pages={166--171},
  year={1998},
  publisher={IEEE}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{chane2021goal,
  title={Goal-conditioned reinforcement learning with imagined subgoals},
  author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  booktitle={International conference on machine learning},
  pages={1430--1440},
  year={2021},
  organization={PMLR}
}

@article{paul2019learning,
  title={Learning from trajectories via subgoal discovery},
  author={Paul, Sujoy and Vanbaar, Jeroen and Roy-Chowdhury, Amit},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@article{li2024goal,
  title={Goal-Conditioned Supervised Learning for Multi-Objective Recommendation},
  author={Li, Shijun and Hasson, Hilaf and Hu, Jing and Ghosh, Joydeep},
  journal={arXiv preprint arXiv:2412.08911},
  year={2024}
}

@article{arjona2019rudder,
  title={Rudder: Return decomposition for delayed rewards},
  author={Arjona-Medina, Jose A and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@book{choset2005principles,
  title={Principles of robot motion: theory, algorithms, and implementations},
  author={Choset, Howie and Lynch, Kevin M and Hutchinson, Seth and Kantor, George A and Burgard, Wolfram},
  year={2005},
  publisher={MIT press}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

