\begin{figure*}[t!]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/system_overview.pdf}
    \caption{Overview of the proposed system. We use a SLAM pipeline to construct dense 3D reconstructions of objects of interest.
   % We use TSGrasp \cite{player_real-time_2023} as the baseline network to regress on grasp poses and confidences.
    PUGS quantifies the uncertainty inherent in the observation and pose estimation to construct an occupancy uncertainty representation. We use TSGrasp \cite{player_real-time_2023} as the baseline network to regress on grasp poses and confidences.
    The final grasp confidence and pose are determined by fusing the PUGS occupancy uncertainty output and the TSGrasp confidences.}
    \label{fig:overview}
\end{figure*}
\subsection{Underwater Manipulation and Grasp Selection}
% Given the rapidly growing interest in underwater vehicle manipulation systems (UVMS), extensive reviews of applications, methods, and future directions have been conducted \cite{aldhaheri_underwater_2022, morgan_autonomous_2022}. 
Compared to traditional robotic manipulation, manipulation with underwater vehicle manipulation systems (UVMS) has additional challenges associated with vehicle dynamics, sensing, and environmental disturbances \cite{billings_hybrid_2022, chang_adaptive_nodate, player_real-time_2023}.

For improving the perception in underwater environments, Billings et al. present a hybrid perception system for a UVMS with a stereo rig mounted on the vehicle and a fish eye camera mounted on the manipulator, with an accompanying mapping and pose estimation method\cite{billings_hybrid_2022}.
Chang et al. present an information-theoretic approach to the underwater planning and grasping task, where the information associated with the object pose and shape is aimed to be maximized \cite{chang_adaptive_nodate}.
% Our contributions address similar topics as~\cite{billings_hybrid_2022,chang_adaptive_nodate}, to improve subsea manipulation.
Different from \cite{billings_hybrid_2022}, our proposed system aims to use robust perception for grasping rather than pose estimation and mapping, where an improvement of the perception and grasping capabilities are achieved through an uncertainty-centric approach. 

TSGrasp, a grasp selection method tested in an underwater setting with a similar hardware setup, builds on previous work \cite{mousavian_6-dof_2019} by utilizing sparse spatiotemporal convolution to output grasp poses, gripper widths, and confidences on an input pointcloud \cite{player_real-time_2023}.
% The method is tested underwater with a robotic manipulator similar to the system we use for our real-world setup.
This method is tested on point clouds accumulated from 1 or 4 frames of images and utilizes geometric information only for the grasp selection.
PUGS is a method that builds upon TSGrasp's grasping capabilities by formulating a fusion between grasp confidence and occupancy uncertainty.
For this reason, along with the fact that it was developed for underwater grasp selection, we select TSGrasp as a baseline method to evaluate PUGS and show that our proposed method, accounting for uncertainty, improves grasping capabilities in adversarial situations.

% The method is developed and tested in underwater environments, similar to that of PUGS.

\subsection{Uncertainty Representation for 3D Reconstruction}
Uncertainty representations in 3D reconstruction aim to capture the uncertainty originating from the measurement model or multi-view stereo to improve the reconstruction quality \cite{freundlich_exact_2015, ulusoy_towards_2015, ulusoy_patches_2016, rosinol_probabilistic_2022, liao_multi-view_2024}, as opposed to classical methods that treat each measurement equally in the reconstruction process \cite{labbe2019rtab}.

Freundlich et al. compute the bias and covariance associated with 3D locations obtained from stereo imaging, showing that the calculated bias correction leads to more accurate representations\cite{freundlich_exact_2015}.
Ulusoy et al. present a series of papers on using probabilistic methods for volumetric rendering~\cite{ulusoy_towards_2015,ulusoy_patches_2016}.
The developed framework is compared against classical methods that perform point estimates on occupancy and show that the relation between appearance and occupancy are captured more accurately through a probabilistic approach.
Rosinol et al. show that estimating the uncertainty from depth estimation and using it as a weighing factor for volumetric fusion results in fast and accurate reconstruction with little ad-hoc filtering \cite{rosinol_probabilistic_2022}.
Learning-based methods have also shown promise in improving reconstruction quality through jointly learning the uncertainty associated with multi-view reconstruction \cite{liao_multi-view_2024}.
We formulate PUGS in a similar vein.
Rather than using uncertainty as a prior for improving reconstruction quality, we present PUGS as a method to improve the robustness of grasp selection.


Methods that utilize uncertainty-aware reconstruction have also been used for downstream robotics tasks in various applications \cite{von_drigalski_uncertainty-aware_2022, torroba_fully-probabilistic_2022, 10093134, pmlr-v164-saund22a}.
Relevant to the manipulation task, Von Drigalski et al. proposed a framework for representing the uncertainty of the pose of an object before and after being manipulated. 
The uncertainty representation enabled accurate and efficient manipulation through accurate belief propagation \cite{von_drigalski_uncertainty-aware_2022}.
Torroba et al. show that accounting for the uncertainty of an estimated 2.5D height map produced from dense range measurements helps improve the localization capabilities of subsea mobile robotic platforms \cite{torroba_fully-probabilistic_2022, 10093134}.
Saund et al. propose a grasp selection method that uses RGB-D and tactile information to manipulate the object's shape, with uncertainty propagated from a learned latent representation to inform the end reconstruction~\cite{pmlr-v164-saund22a}.
We select our uncertainty representation to be associated with the occupancy measured, as opposed to the pose of an object \cite{von_drigalski_uncertainty-aware_2022}, the shape of the object~\cite{pmlr-v164-saund22a} or a height map~\cite{torroba_fully-probabilistic_2022, 10093134}.
This uncertainty is then used directly to improve the robustness and autonomy of a robotic task in grasp selection.
