\begin{abstract}
When navigating and interacting in challenging environments where sensory information is imperfect and incomplete, robots must make decisions that account for these shortcomings. 
We propose a novel method for quantifying and representing such perceptual uncertainty in 3D reconstruction through occupancy uncertainty estimation. 
We develop a framework to incorporate it into grasp selection for autonomous manipulation in underwater environments. 
Instead of treating each measurement equally when deciding which location to grasp from, we present a framework that propagates uncertainty inherent in the multi-view reconstruction process into the grasp selection.
We evaluate our method with both simulated and the real world data, showing that by accounting for uncertainty, the grasp selection becomes robust against partial and noisy measurements. 
Code will be made available at \url{https://onurbagoren.github.io/PUGS/}
\end{abstract}