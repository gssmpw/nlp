[
  {
    "index": 0,
    "papers": [
      {
        "key": "mokady2021clipcap",
        "author": "Mokady, Ron and Hertz, Amir and Bermano, Amit H",
        "title": "Clipcap: Clip prefix for image captioning"
      },
      {
        "key": "stefanini2022show",
        "author": "Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita",
        "title": "From show to tell: A survey on deep learning-based image captioning"
      },
      {
        "key": "hessel2021clipscore",
        "author": "Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin",
        "title": "Clipscore: A reference-free evaluation metric for image captioning"
      },
      {
        "key": "vinyals2015show",
        "author": "Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru",
        "title": "Show and tell: A neural image caption generator"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "pan2023retrieving",
        "author": "Pan, Junting and Lin, Ziyi and Ge, Yuying and Zhu, Xiatian and Zhang, Renrui and Wang, Yi and Qiao, Yu and Li, Hongsheng",
        "title": "Retrieving-to-answer: Zero-shot video question answering with frozen large language models"
      },
      {
        "key": "song2022clip",
        "author": "Song, Haoyu and Dong, Li and Zhang, Wei-Nan and Liu, Ting and Wei, Furu",
        "title": "Clip models are few-shot learners: Empirical studies on vqa and visual entailment"
      },
      {
        "key": "antol2015vqa",
        "author": "Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi",
        "title": "Vqa: Visual question answering"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "xia2023clip",
        "author": "Xia, Xinyu and Dong, Guohua and Li, Fengling and Zhu, Lei and Ying, Xiaomin",
        "title": "When CLIP meets cross-modal hashing retrieval: A new strong baseline"
      },
      {
        "key": "zhen2019deep",
        "author": "Zhen, Liangli and Hu, Peng and Wang, Xu and Peng, Dezhong",
        "title": "Deep supervised cross-modal retrieval"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "jia2021scaling",
        "author": "Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom",
        "title": "Scaling up visual and vision-language representation learning with noisy text supervision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li2019visualbert",
        "author": "Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei",
        "title": "Visualbert: A simple and performant baseline for vision and language"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lu2019vilbert",
        "author": "Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan",
        "title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "li2021align",
        "author": "Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong",
        "title": "Align before fuse: Vision and language representation learning with momentum distillation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li2022blip",
        "author": "Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven",
        "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "xia2023clip",
        "author": "Xia, Xinyu and Dong, Guohua and Li, Fengling and Zhu, Lei and Ying, Xiaomin",
        "title": "When CLIP meets cross-modal hashing retrieval: A new strong baseline"
      },
      {
        "key": "song2022clip",
        "author": "Song, Haoyu and Dong, Li and Zhang, Wei-Nan and Liu, Ting and Wei, Furu",
        "title": "Clip models are few-shot learners: Empirical studies on vqa and visual entailment"
      },
      {
        "key": "mokady2021clipcap",
        "author": "Mokady, Ron and Hertz, Amir and Bermano, Amit H",
        "title": "Clipcap: Clip prefix for image captioning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "xing2024clipvqa",
        "author": "Xing, Fengchuang and Li, Mingjie and Wang, Yuan-Gen and Zhu, Guopu and Cao, Xiaochun",
        "title": "CLIPVQA: Video Quality Assessment via CLIP"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chikkerur2011objective",
        "author": "Chikkerur, Shyamprasad and Sundaram, Vijay and Reisslein, Martin and Karam, Lina J",
        "title": "Objective video quality assessment methods: A classification, review, and performance comparison"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Saad_Bovik_Charrier_2014",
        "author": "Saad, Michele A. and Bovik, Alan C. and Charrier, Christophe",
        "title": "Blind Prediction of Natural Video Quality"
      },
      {
        "key": "Mittal_Saad_Bovik_2016",
        "author": "Mittal, Anish and Saad, Michele A. and Bovik, Alan C.",
        "title": "A Completely Blind Video Integrity Oracle"
      },
      {
        "key": "Korhonen_2019",
        "author": "Korhonen, Jari",
        "title": "Two-Level Approach for No-Reference Consumer Video Quality Assessment"
      },
      {
        "key": "Tu_Wang_Birkbeck_Adsumilli_Bovik_2021",
        "author": "Tu, Zhengzhong and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C.",
        "title": "UGC-VQA: Benchmarking Blind Video Quality Assessment for User Generated Content"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "hosu2017konstanz",
        "author": "Hosu, Vlad and Hahn, Franz and Jenadeleh, Mohsen and Lin, Hanhe and Men, Hui and Szir{\\'a}nyi, Tam{\\'a}s and Li, Shujun and Saupe, Dietmar",
        "title": "The Konstanz natural video database (KoNViD-1k)"
      },
      {
        "key": "Wang_Inguva_Adsumilli_2019",
        "author": "Wang, Yilin and Inguva, Sasi and Adsumilli, Balu",
        "title": "YouTube UGC Dataset for Video Compression Research"
      },
      {
        "key": "Ying_Maniratnam_Ghadiyaram_Bovik_2020",
        "author": "Ying, Zhenqiang and Maniratnam, Mandal and Ghadiyaram, Deepti and Bovik, AlanC.",
        "title": "Patch-VQ: \u201cPatching Up\u201d the Video Quality Problem"
      },
      {
        "key": "Zhang_Wu_Sun_Tu_Lu_Min_Chen_Zhai_2023",
        "author": "Zhang, Zicheng and Wu, Wei and Sun, Wei and Tu, Dangyang and Lu, Wei and Min, Xiongkuo and Chen, Ying and Zhai, Guangtao",
        "title": "MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Wu_Chen_Liao_Hou_Sun_Yan_Lin_2022",
        "author": "Wu, Haoning and Chen, Chaofeng and Liao, Liang and Hou, Jingwen and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "DisCoVQA: Temporal Distortion-Content Transformers for Video Quality Assessment"
      },
      {
        "key": "zhao2023zoom",
        "author": "Zhao, Kai and Yuan, Kun and Sun, Ming and Wen, Xing",
        "title": "Zoom-vqa: Patches, frames and clips integration for video quality assessment"
      },
      {
        "key": "Ying_Maniratnam_Ghadiyaram_Bovik_2020",
        "author": "Ying, Zhenqiang and Maniratnam, Mandal and Ghadiyaram, Deepti and Bovik, AlanC.",
        "title": "Patch-VQ: \u201cPatching Up\u201d the Video Quality Problem"
      },
      {
        "key": "Zhang_Wu_Sun_Tu_Lu_Min_Chen_Zhai_2023",
        "author": "Zhang, Zicheng and Wu, Wei and Sun, Wei and Tu, Dangyang and Lu, Wei and Min, Xiongkuo and Chen, Ying and Zhai, Guangtao",
        "title": "MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos"
      },
      {
        "key": "Li_Jiang_Jiang_2019",
        "author": "Li, Dingquan and Jiang, Tingting and Jiang, Ming",
        "title": "Quality Assessment of In-the-Wild Videos"
      },
      {
        "key": "Li_Jiang_Jiang_2021",
        "author": "Li, Dingquan and Jiang, Tingting and Jiang, Ming",
        "title": "Unified Quality Assessment of in-the-Wild Videos with Mixed Datasets Training"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "Wu_Chen_Liao_Hou_Sun_Yan_Lin_2022",
        "author": "Wu, Haoning and Chen, Chaofeng and Liao, Liang and Hou, Jingwen and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "DisCoVQA: Temporal Distortion-Content Transformers for Video Quality Assessment"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhao2023zoom",
        "author": "Zhao, Kai and Yuan, Kun and Sun, Ming and Wen, Xing",
        "title": "Zoom-vqa: Patches, frames and clips integration for video quality assessment"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wu2022disentangling",
        "author": "Wu, Haoning and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "Disentangling aesthetic and technical effects for video quality assessment of user generated content"
      },
      {
        "key": "wu2023exploring",
        "author": "Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "Exploring video quality assessment on user generated contents from aesthetic and technical perspectives"
      },
      {
        "key": "he2024cover",
        "author": "He, Chenlong and Zheng, Qi and Zhu, Ruoxi and Zeng, Xiaoyang and Fan, Yibo and Tu, Zhengzhong",
        "title": "COVER: A comprehensive video quality evaluator"
      },
      {
        "key": "wu2023towards",
        "author": "Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wu2022disentangling",
        "author": "Wu, Haoning and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi",
        "title": "Disentangling aesthetic and technical effects for video quality assessment of user generated content"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      },
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      },
      {
        "key": "touvron2023llama",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others",
        "title": "Llama: Open and efficient foundation language models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ramesh2021zero",
        "author": "Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya",
        "title": "Zero-shot text-to-image generation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "videoworldsimulators2024",
        "author": "Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh",
        "title": "Video generation models as world simulators"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "fried2019text",
        "author": "Fried, Ohad and Tewari, Ayush and Zollh{\\\"o}fer, Michael and Finkelstein, Adam and Shechtman, Eli and Goldman, Dan B and Genova, Kyle and Jin, Zeyu and Theobalt, Christian and Agrawala, Maneesh",
        "title": "Text-based editing of talking-head video"
      },
      {
        "key": "huber2019b",
        "author": "Huber, Bernd and Shin, Hijung Valentina and Russell, Bryan and Wang, Oliver and Mysore, Gautham J",
        "title": "B-script: Transcript-based b-roll video editing with recommendations"
      },
      {
        "key": "huh2023avscript",
        "author": "Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang'Anthony' and Kim, Young-Ho and Pavel, Amy",
        "title": "AVscript: Accessible Video Editing with Audio-Visual Scripts"
      },
      {
        "key": "pavel2020rescribe",
        "author": "Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P",
        "title": "Rescribe: Authoring and automatically editing audio descriptions"
      },
      {
        "key": "laput2013pixeltone",
        "author": "Laput, Gierad P and Dontcheva, Mira and Wilensky, Gregg and Chang, Walter and Agarwala, Aseem and Linder, Jason and Adar, Eytan",
        "title": "Pixeltone: A multimodal interface for image editing"
      },
      {
        "key": "chang2019design",
        "author": "Chang, Minsuk and Truong, Anh and Wang, Oliver and Agrawala, Maneesh and Kim, Juho",
        "title": "How to design voice based navigation for how-to videos"
      },
      {
        "key": "lin2023identifying",
        "author": "Lin, Georgianna and Li, Jin Yi and Fazly, Afsaneh and Pavlovic, Vladimir and Truong, Khai",
        "title": "Identifying Multimodal Context Awareness Requirements for Supporting User Interaction with Procedural Videos"
      },
      {
        "key": "wang2024lave",
        "author": "Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj",
        "title": "LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "wang2024lave",
        "author": "Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj",
        "title": "LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "carreira2017quo",
        "author": "Carreira, Joao and Zisserman, Andrew",
        "title": "Quo vadis, action recognition? a new model and the kinetics dataset"
      },
      {
        "key": "unterthiner2019fvd",
        "author": "Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\\\"e}l and Michalski, Marcin and Gelly, Sylvain",
        "title": "FVD: A new metric for video generation"
      },
      {
        "key": "huang2024vbench",
        "author": "Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and others",
        "title": "Vbench: Comprehensive benchmark suite for video generative models"
      },
      {
        "key": "kou2024subjective",
        "author": "Kou, Tengchuan and Liu, Xiaohong and Zhang, Zicheng and Li, Chunyi and Wu, Haoning and Min, Xiongkuo and Zhai, Guangtao and Liu, Ning",
        "title": "Subjective-Aligned Dateset and Metric for Text-to-Video Quality Assessment"
      },
      {
        "key": "lu2024aigc",
        "author": "Lu, Yiting and Li, Xin and Li, Bingchen and Yu, Zihao and Guan, Fengbin and Wang, Xinrui and Liao, Ruling and Ye, Yan and Chen, Zhibo",
        "title": "AIGC-VQA: A Holistic Perception Metric for AIGC Video Quality Assessment"
      }
    ]
  }
]