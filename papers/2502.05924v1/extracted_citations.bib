@article{Korhonen_2019,  
    title={Two-Level Approach for No-Reference Consumer Video Quality Assessment}, 
    url={http://dx.doi.org/10.1109/tip.2019.2923051}, 
    DOI={10.1109/tip.2019.2923051}, 
    journal={IEEE Transactions on Image Processing}, 
    author={Korhonen, Jari}, 
    year={2019}, 
    month={Dec}, 
    pages={5923–5938}, 
    language={en-US} 
}

@inproceedings{Li_Jiang_Jiang_2019,  
    title={Quality Assessment of In-the-Wild Videos}, 
    url={http://dx.doi.org/10.1145/3343031.3351028}, 
    DOI={10.1145/3343031.3351028}, 
    booktitle={Proceedings of the 27th ACM International Conference on Multimedia}, 
    author={Li, Dingquan and Jiang, Tingting and Jiang, Ming}, 
    year={2019}, 
    month={Oct}, 
    language={en-US} 
}

@article{Li_Jiang_Jiang_2021,  
    title={Unified Quality Assessment of in-the-Wild Videos with Mixed Datasets Training}, 
    url={http://dx.doi.org/10.1007/s11263-020-01408-w}, 
    DOI={10.1007/s11263-020-01408-w}, 
    journal={International Journal of Computer Vision}, 
    author={Li, Dingquan and Jiang, Tingting and Jiang, Ming}, 
    year={2021}, 
    month={Apr}, 
    pages={1238–1257}, 
    language={en-US} 
}

@article{Mittal_Saad_Bovik_2016,  
    title={A Completely Blind Video Integrity Oracle}, 
    url={http://dx.doi.org/10.1109/tip.2015.2502725}, 
    DOI={10.1109/tip.2015.2502725}, 
    journal={IEEE Transactions on Image Processing}, 
    author={Mittal, Anish and Saad, Michele A. and Bovik, Alan C.}, 
    year={2016}, 
    month={Jan}, 
    pages={289–300}, 
    language={en-US} 
}

@article{Saad_Bovik_Charrier_2014,   
    title={Blind Prediction of Natural Video Quality}, 
    url={http://dx.doi.org/10.1109/tip.2014.2299154},  
    DOI={10.1109/tip.2014.2299154},  
    journal={IEEE Transactions on Image Processing},  
    author={Saad, Michele A. and Bovik, Alan C. and Charrier, Christophe},  
    year={2014},  
    month={Mar},  
    pages={1352–1365},  
    language={en-US}  
}

@article{Tu_Wang_Birkbeck_Adsumilli_Bovik_2021,  
    title={UGC-VQA: Benchmarking Blind Video Quality Assessment for User Generated Content}, 
    url={http://dx.doi.org/10.1109/tip.2021.3072221}, 
    DOI={10.1109/tip.2021.3072221}, 
    journal={IEEE Transactions on Image Processing}, 
    author={Tu, Zhengzhong and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C.}, 
    year={2021}, 
    month={Jan}, 
    pages={4449–4464}, 
    language={en-US} 
}

@inproceedings{Wang_Inguva_Adsumilli_2019,  
    title={YouTube UGC Dataset for Video Compression Research}, 
    url={http://dx.doi.org/10.1109/mmsp.2019.8901772}, 
    DOI={10.1109/mmsp.2019.8901772}, 
    booktitle={2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)}, 
    author={Wang, Yilin and Inguva, Sasi and Adsumilli, Balu}, 
    year={2019}, 
    month={Sep}, 
    language={en-US} 
}

@article{Wu_Chen_Liao_Hou_Sun_Yan_Lin_2022,  
    title={DisCoVQA: Temporal Distortion-Content Transformers for Video Quality Assessment}, 
    author={Wu, Haoning and Chen, Chaofeng and Liao, Liang and Hou, Jingwen and Sun, Wenxiu and Yan, Qiong and Lin, Weisi}, 
    year={2022}, 
    month={Jun}, 
    language={en-US} 
}

@article{Ying_Maniratnam_Ghadiyaram_Bovik_2020,  
    title={Patch-VQ: “Patching Up” the Video Quality Problem}, 
    journal={Cornell University - arXiv,Cornell University - arXiv}, 
    author={Ying, Zhenqiang and Maniratnam, Mandal and Ghadiyaram, Deepti and Bovik, AlanC.}, 
    year={2020}, 
    month={Nov}, 
    language={en-US} 
}

@article{Zhang_Wu_Sun_Tu_Lu_Min_Chen_Zhai_2023,  
    title={MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos}, 
    author={Zhang, Zicheng and Wu, Wei and Sun, Wei and Tu, Dangyang and Lu, Wei and Min, Xiongkuo and Chen, Ying and Zhai, Guangtao}, 
    year={2023}, 
    month={Mar}, 
    language={en-US} 
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{chang2019design,
  title={How to design voice based navigation for how-to videos},
  author={Chang, Minsuk and Truong, Anh and Wang, Oliver and Agrawala, Maneesh and Kim, Juho},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--11},
  year={2019}
}

@article{chikkerur2011objective,
  title={Objective video quality assessment methods: A classification, review, and performance comparison},
  author={Chikkerur, Shyamprasad and Sundaram, Vijay and Reisslein, Martin and Karam, Lina J},
  journal={IEEE transactions on broadcasting},
  volume={57},
  number={2},
  pages={165--182},
  year={2011},
  publisher={IEEE}
}

@article{fried2019text,
  title={Text-based editing of talking-head video},
  author={Fried, Ohad and Tewari, Ayush and Zollh{\"o}fer, Michael and Finkelstein, Adam and Shechtman, Eli and Goldman, Dan B and Genova, Kyle and Jin, Zeyu and Theobalt, Christian and Agrawala, Maneesh},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={4},
  pages={1--14},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{he2024cover,
  title={COVER: A comprehensive video quality evaluator},
  author={He, Chenlong and Zheng, Qi and Zhu, Ruoxi and Zeng, Xiaoyang and Fan, Yibo and Tu, Zhengzhong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5799--5809},
  year={2024}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{hosu2017konstanz,
  title={The Konstanz natural video database (KoNViD-1k)},
  author={Hosu, Vlad and Hahn, Franz and Jenadeleh, Mohsen and Lin, Hanhe and Men, Hui and Szir{\'a}nyi, Tam{\'a}s and Li, Shujun and Saupe, Dietmar},
  booktitle={2017 Ninth international conference on quality of multimedia experience (QoMEX)},
  pages={1--6},
  year={2017},
  organization={IEEE}
}

@inproceedings{huang2024vbench,
  title={Vbench: Comprehensive benchmark suite for video generative models},
  author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21807--21818},
  year={2024}
}

@inproceedings{huber2019b,
  title={B-script: Transcript-based b-roll video editing with recommendations},
  author={Huber, Bernd and Shin, Hijung Valentina and Russell, Bryan and Wang, Oliver and Mysore, Gautham J},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2019}
}

@inproceedings{huh2023avscript,
  title={AVscript: Accessible Video Editing with Audio-Visual Scripts},
  author={Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang'Anthony' and Kim, Young-Ho and Pavel, Amy},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{kou2024subjective,
  title={Subjective-Aligned Dateset and Metric for Text-to-Video Quality Assessment},
  author={Kou, Tengchuan and Liu, Xiaohong and Zhang, Zicheng and Li, Chunyi and Wu, Haoning and Min, Xiongkuo and Zhai, Guangtao and Liu, Ning},
  journal={arXiv preprint arXiv:2403.11956},
  year={2024}
}

@inproceedings{laput2013pixeltone,
  title={Pixeltone: A multimodal interface for image editing},
  author={Laput, Gierad P and Dontcheva, Mira and Wilensky, Gregg and Chang, Walter and Agarwala, Aseem and Linder, Jason and Adar, Eytan},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2185--2194},
  year={2013}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{lin2023identifying,
  title={Identifying Multimodal Context Awareness Requirements for Supporting User Interaction with Procedural Videos},
  author={Lin, Georgianna and Li, Jin Yi and Fazly, Afsaneh and Pavlovic, Vladimir and Truong, Khai},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{lu2024aigc,
  title={AIGC-VQA: A Holistic Perception Metric for AIGC Video Quality Assessment},
  author={Lu, Yiting and Li, Xin and Li, Bingchen and Yu, Zihao and Guan, Fengbin and Wang, Xinrui and Liao, Ruling and Ye, Yan and Chen, Zhibo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6384--6394},
  year={2024}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@inproceedings{pan2023retrieving,
  title={Retrieving-to-answer: Zero-shot video question answering with frozen large language models},
  author={Pan, Junting and Lin, Ziyi and Ge, Yuying and Zhu, Xiatian and Zhang, Renrui and Wang, Yi and Qiao, Yu and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={272--283},
  year={2023}
}

@inproceedings{pavel2020rescribe,
  title={Rescribe: Authoring and automatically editing audio descriptions},
  author={Pavel, Amy and Reyes, Gabriel and Bigham, Jeffrey P},
  booktitle={Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
  pages={747--759},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

@article{song2022clip,
  title={Clip models are few-shot learners: Empirical studies on vqa and visual entailment},
  author={Song, Haoyu and Dong, Li and Zhang, Wei-Nan and Liu, Ting and Wei, Furu},
  journal={arXiv preprint arXiv:2203.07190},
  year={2022}
}

@article{stefanini2022show,
  title={From show to tell: A survey on deep learning-based image captioning},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={539--559},
  year={2022},
  publisher={IEEE}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{unterthiner2019fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain},
  year={2019}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{wang2024lave,
  title={LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing},
  author={Wang, Bryan and Li, Yuliang and Lv, Zhaoyang and Xia, Haijun and Xu, Yan and Sodhi, Raj},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={699--714},
  year={2024}
}

@article{wu2022disentangling,
  title={Disentangling aesthetic and technical effects for video quality assessment of user generated content},
  author={Wu, Haoning and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  journal={arXiv preprint arXiv:2211.04894},
  volume={2},
  number={5},
  pages={6},
  year={2022}
}

@inproceedings{wu2023exploring,
  title={Exploring video quality assessment on user generated contents from aesthetic and technical perspectives},
  author={Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20144--20154},
  year={2023}
}

@inproceedings{wu2023towards,
  title={Towards explainable in-the-wild video quality assessment: a database and a language-prompted approach},
  author={Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1045--1054},
  year={2023}
}

@article{xia2023clip,
  title={When CLIP meets cross-modal hashing retrieval: A new strong baseline},
  author={Xia, Xinyu and Dong, Guohua and Li, Fengling and Zhu, Lei and Ying, Xiaomin},
  journal={Information Fusion},
  volume={100},
  pages={101968},
  year={2023},
  publisher={Elsevier}
}

@article{xing2024clipvqa,
  title={CLIPVQA: Video Quality Assessment via CLIP},
  author={Xing, Fengchuang and Li, Mingjie and Wang, Yuan-Gen and Zhu, Guopu and Cao, Xiaochun},
  journal={arXiv preprint arXiv:2407.04928},
  year={2024}
}

@inproceedings{zhao2023zoom,
  title={Zoom-vqa: Patches, frames and clips integration for video quality assessment},
  author={Zhao, Kai and Yuan, Kun and Sun, Ming and Wen, Xing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1302--1310},
  year={2023}
}

@inproceedings{zhen2019deep,
  title={Deep supervised cross-modal retrieval},
  author={Zhen, Liangli and Hu, Peng and Wang, Xu and Peng, Dezhong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10394--10403},
  year={2019}
}

