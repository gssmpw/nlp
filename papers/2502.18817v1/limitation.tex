\section*{Limitation}
Although \method{} demonstrates convincing performance in enhancing the judgment ability of LLMs, it has some limitations. First, the judgment results are often sensitive to the evaluation prompts, and \method{} relies on the consistency of these prompts to improve LLMs' judgment capability. Thus, the design of high-quality evaluation prompts that encompass comprehensive evaluation dimensions remains an underexplored area. Second, \method{} utilizes the well-performing embedding model, MiniCPM-Embedding, to calculate the similarity score between judgment results based on different evaluation aspects. However, the effectiveness of this similarity estimation method may limit the overall performance of \method{}. Further exploration of more fine-grained approaches, such as incorporating the matching signals of ground truth answers, could enhance its effectiveness.





% Although the effectiveness of the \method{} method has been demonstrated in the RAG scenario, further evaluating in broader test scenarios is still necessary.
% Additionally, when evaluating the performance of the RAG model on downstream tasks, we use automatic metric, it is not a comprehensive evaluation approach and may provide inaccurate results.
% Besides, when evaluating the quality of hybrid evaluations, both reasoning and answers are incorporated in evaluation, we do not evaluate reasoning and answers separately. 




%虽然在RAG场景下测试了，但更广泛的测试仍然需要
%评价RAG模型时用到了metric，不太全面
%minicpm评估的，但reasoning和结果没有分别评价


%embedding model
