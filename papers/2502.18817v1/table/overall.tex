
\begin{table*}[ht]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{l|l|ccccccc}
\hline
%第一组

 \multirow{2}{*}{\textbf{Generator}} & \multirow{2}{*}{\textbf{Reward}} & \textbf{NQ} & \textbf{HotpotQA} & \textbf{TriviaQA}  & \textbf{ASQA} & \textbf{MARCOQA} & \textbf{WoW} & \multirow{2}{*}{\textbf{Avg.}} \\ 
& & (acc) & (acc) & (acc) & (str-em) & (llm) & (llm) & \\ 
\hline

\multirow{7}{*}{\shortstack{\textbf{MiniCPM}\\(2.4B)}} & Raw Metric & 46.14	& 30.09	& 80.03 & 33.44 & 84.75 & 85.48 & 59.99\\  \cdashline{2-9}
%& \multicolumn{9}{c}{\textit{\textbf{Llama3-8B}}}\\\cline{2-10}
& Llama3-8B& \textbf{47.23} & 29.64 & 80.40 & \textbf{35.77}	& 	86.00 & 85.98 &60.84 \\
& w/ SFT & 47.02 & 29.55 & 80.33	& 34.60	& \textbf{86.35}	& 85.98 &60.64 \\
&w/ \method{}  & 47.02 & \textbf{30.45} & \textbf{80.80}	& 35.68	& 86.16	& \textbf{86.13} & \textbf{61.04}
\\\cdashline{2-9}

& Qwen2.5-14B & 47.30 &  28.96 & 80.03	& 34.95	& 85.59	& 87.49 &60.72  \\
& w/ SFT & 47.02 & 27.64 & 79.80	& 33.51	& 	\textbf{85.90} & \textbf{87.51} & 60.23\\
& w/ \method{} & \textbf{48.01} & \textbf{30.84} & \textbf{80.69} & 	\textbf{36.45} & 85.73	& 87.21 & \textbf{61.49} \\

\hline

\multirow{4}{*}{\shortstack{\textbf{Llama3}\\(8B)}} & Raw Metric &48.96 & 36.95& 86.83	& 41.55	& 	84.80& 82.66 &63.63 \\ \cdashline{2-9}
%& \multicolumn{9}{c}{\textit{\textbf{Llama3-8B}}}\\\cline{2-10}
& Llama3-8B & 46.63 &  32.84 & 85.13 & 40.69	& 	88.15 & 88.31 &63.63 \\
& w/ SFT & 47.16 & 35.95  & 86.10	& 40.37	& 87.46	& 87.97	 & 64.20 \\
&w/ \method{}  & \textbf{48.78} & \textbf{37.54} & \textbf{88.26}& \textbf{42.44}	& \textbf{88.25}	& \textbf{88.87}	 & \textbf{65.69} \\\hline
\end{tabular}
}
\caption{Overall Performance of RAG Models Optimized Using Different Judgment Models. The \textbf{best} result is highlighted. We implement the generators of RAG models by using MiniCPM-2.4B and Llama3-8B.}
\label{table1:overall}
\end{table*}




