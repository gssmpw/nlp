
\begin{table*}[ht]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{l|l|cccccccc}
\hline
%第一组
 % \textbf{Generator} & \textbf{Reward} &  \textbf{NQ} & \textbf{HotpotQA} & \textbf{TriviaQA} & \textbf{T-REx} & \textbf{ASQA} & \textbf{MARCOQA} & \textbf{WoW} & \multicolumn{1}{c}{\multirow{1}{*}{\textbf{Avg.}}}\\ 
 \multirow{2}{*}{\textbf{Generator}} & \multirow{2}{*}{\textbf{Reward}} & \textbf{NQ} & \textbf{HotpotQA} & \textbf{TriviaQA} & \textbf{T-REx} & \textbf{ASQA} & \textbf{MARCOQA} & \textbf{WoW} & \multirow{2}{*}{\textbf{Avg.}} \\ 
& & (acc) & (acc) & (acc) & (acc) & (str-em) & (llm) & (llm) & \\ 

% \cmidrule(lr){2-5} \cmidrule(lr){6-6} \cmidrule(lr){7-8} \
% Evaluation Metrics & \multicolumn{4}{c}{\textbf{Accuracy}} & \multicolumn{1}{c}{\textbf{Str EM}} & \multicolumn{2}{c}{\textbf{LLM}}\\

\hline
%\multirow{10}{*}{\shortstack{\textbf{MiniCPM}\\(2.4B)}}& \multicolumn{9}{c}{\textit{\textbf{Raw Metric\rlap{$\text{}^{\dagger}$}}}}\\\cline{2-10}
\multirow{7}{*}{\shortstack{\textbf{MiniCPM}\\(2.4B)}} & Raw Metric\rlap{$\text{}^{\dagger}$} & 45.12	& 31.30	& 79.12	&  32.46 & 35.44 & 88.42 & 87.76 & 57.09\\  \cdashline{2-10}
%& \multicolumn{9}{c}{\textit{\textbf{Llama3-8B}}}\\\cline{2-10}
    & Llama3-8B&  \textbf{47.34}	& 31.83 & 79.41	& 29.40	& 36.82	& 90.47	& 90.52 & 57.97\\
& w/ SFT &  46.84 & 31.34 & 79.06 & 27.20 & 37.04 & 91.26 & 90.24	& 57.57\\
&w/ \method{} &  46.60\rlap{$\text{}^{\dagger}$}	& \textbf{32.23}\rlap{$\text{}^{\dagger}$}	& \textbf{79.77}\rlap{$\text{}^{\dagger}$}	& \textbf{29.40}	& \textbf{37.12}\rlap{$\text{}^{\dagger}$}	& \textbf{91.35}\rlap{$\text{}^{\dagger}$}	& \textbf{91.24}\rlap{$\text{}^{\dagger}$}	& \textbf{58.24}
\\\cdashline{2-10}
%& \multicolumn{9}{c}{\textit{\textbf{Qwen2.5-14B}}}\\\cline{2-10}
& Qwen2.5-14B & 46.77 & 31.66 & \textbf{79.86} & 26.74 & 36.80 & 90.03 & 88.84 & 57.24\\
& w/ SFT &  46.98 & 31.76 & 79.14 & 32.38 & 36.88	& 90.57	& 89.92 & 58.23\\
& w/ \method{} &  \textbf{47.16}\rlap{$\text{}^{\dagger}$} & \textbf{31.91}\rlap{$\text{}^{\dagger}$} & 79.53\rlap{$\text{}^{\dagger}$} & \textbf{34.04}\rlap{$\text{}^{\dagger}$} & \textbf{38.35}\rlap{$\text{}^{\dagger}$} & \textbf{91.12}\rlap{$\text{}^{\dagger}$} & \textbf{90.04}\rlap{$\text{}^{\dagger}$} & \textbf{58.88}\\

\hline
%\multirow{6}{*}{\shortstack{\textbf{Llama3}\\(8B)}}& \multicolumn{9}{c}{\textit{\textbf{Raw Metric\rlap{$\text{}^{\dagger}$}}}}\\\cline{2-10}
\multirow{4}{*}{\shortstack{\textbf{Llama3}\\(8B)}} & Raw Metric\rlap{$\text{}^{\dagger}$} & 47.69 	& 33.22	& 84.55	&  30.22 & 40.69 & 89.36 & 84.30 & 58.58\\ \cdashline{2-10}
%& \multicolumn{9}{c}{\textit{\textbf{Llama3-8B}}}\\\cline{2-10}
& Llama3-8B&  46.67	& 33.54  & 85.82 & \textbf{42.18} & 41.65	& 90.18	& 86.43 & 60.92\\
& w/ SFT &  48.33 & 36.25 & \textbf{87.16} & 42.00 & \textbf{42.10} & 90.92 & 86.78 & 61.93\\
&w/ \method{}  & \textbf{48.54}\rlap{$\text{}^{\dagger}$} & \textbf{36.45}\rlap{$\text{}^{\dagger}$}	& 86.97\rlap{$\text{}^{\dagger}$} & 41.46\rlap{$\text{}^{\dagger}$}	& 41.78\rlap{$\text{}^{\dagger}$} & \textbf{91.50}\rlap{$\text{}^{\dagger}$} & \textbf{87.12}\rlap{$\text{}^{\dagger}$}	& \textbf{61.97}\\\hline
\end{tabular}
}
\caption{Overall Performance of RAG Models Optimized Using Different Judgment Models. The \textbf{best} result is highlighted. $\text{}^{\dagger}$ indicates statistically significant improvements over the Raw Metric model.}
\label{table1:overall}
\end{table*}