\section{Related Work}
Retrieval-Augmented Generation (RAG) has proven its effectiveness in various tasks, such as open-domain question answering____, dialogue systems____, and code generation____. By integrating external knowledge into the input context____, Large Language Models (LLMs) can alleviate hallucination issues and produce more accurate responses____. To evaluate the performance of LLM responses, most existing RAG models rely on automatic metrics like Exact-Match during both evaluation____ and training____. However, these metrics may fail to offer a fair assessment when the LLM-generated responses are lengthy or semantically similar to the ground truth but not character-matched____.

Recently, LLMs, such as ChatGPT____, have demonstrated human-equivalent performance____ and are now commonly used as judgment models to assess generated responses in various tasks____. These studies typically prompt LLMs to evaluate generated responses based on specific evaluation dimensions____. However, using APIs of these closed-source models incurs significant costs and reduces reproducibility, as the models may evolve behind the API____. To address this, some researchers are turning to open-source LLMs as alternatives, using judgments from closed-source LLMs to fine-tune open-source models and improve their evaluation capabilities____.

Moreover, RAG models also employ LLMs as judges to assess the quality of generation, focusing on the relevance and faithfulness of the responses____. These models typically design prompts to instruct LLMs to determine whether the generated response aligns with the facts in the retrieved document and whether all relevant information has been fully extracted and integrated____. However, LLM-based evaluations are highly sensitive to prompt designs____, making the judgments inconsistent when using different dimensions for evaluating RAG responses. To mitigate this issue, \method{} introduces a judge-consistency approach to self-improve the judgment performance of LLMs in RAG systems, avoiding distillation from larger-scale LLMs____.
% the ability of judgment models by selecting more appropriate evaluation dimensions to optimize the RAG system.










% However, LLMs as the judgment model still suffer issues such as position bias, verbosity bias, and self-enhancement bias, which can compromise the accuracy of judgment model____.

% % Compared to human evaluation and automated metrics such as ROUGE____ and BERTScore____, LLMs as judgment models incur lower costs and deliver higher performance____. 

% To address these issues, some works choose to optimize evaluation prompts of judgment models, such as incorporating annotated high-quality demonstrations in the prompt____ or further refining the evaluation dimensions____. However, many LLMs face conceptual and evaluation criteria confusion, which limits the effectiveness of prompt optimization____. Besides, Some works use the judgments generated by the human or powerful LLMs like GPT-4 to fine-tune the judgment model, improving its evaluation performance____. ____ use training data generated by GPT-4o to optimize the judgment model and apply it to optimize the RAG system. However, these methods require high-quality annotated and generated training data, which is costly. In contrast to existing works, \method{} self-improves the ability of judgment models by selecting more appropriate evaluation dimensions to optimize the RAG system.


% Human evaluation is the gold standard method to judge the responses of large language models (LLMs) in various NLP tasks. Many studies collect human judgments to further improve the model performance____. To reduce the cost of judgment, some works use BERTScore____, ROUGE____, and other automation metrics as the judgment methods____. However, the effectiveness of these methods is less than human judgment. 




% As the performance of the judgment model improves, its application scenarios have also been further expanded, including serving as an evaluator for various NLP tasks____ and providing feedback for model optimization____. Beyond this, some works begin to apply them to retrieval-augmented generation (RAG)____, a technique that integrates external knowledge retrieval to enhance response quality and reduce hallucinations. ____ use training data generated by GPT-4 to train a judgment model, which was then applied to optimize the retrieval-augmented system.



% As the performance of the judgment models improves, they are not only used as evaluators for various NLP tasks____ but also to provide feedback signals for model optimization____. 


% Retrieval-Augmented Generation (RAG) is widely used in various real-world applications and improves the performance of Large Language Models (LLMs) by enriching the input with relevant external texts____ from external sources. 



% RAG-based LLMs can efficiently leverage information from retrieved documents by either directly inserting them into the prompt____ or through specialized training____. The method can effectively alleviate hallucination and outdated knowledge of LLMs and help LLMs generate responses with greater confidence and closer to human preferences____. 

% However, with the widespread application of RAG, some limitations of the RAG system have started to emerge. ____ have found that the knowledge in the documents retrieved by RAG may conflict with the parameterized knowledge of LLM. To address these limitations, ____ trains a better retrieval model to retrieve documents that are closer to the query, ____ trains RAG model using datasets specifically designed for RAG scenarios, enabling them to process retrieved information more efficiently. ____ further remove noise from the documents by summarizing the retrieved documents. Although every approach is effective, they lack strong alignment with human preferences, making it challenging for RAG model to distinguish between responses. 

% Some works____ have begun to try to use reinforcement learning to optimize the RAG model so that its responses are more aligned with human preferences. ____ summarizes the existing reward models and evaluates their performance on Question-Answering tasks in RAG scenario. But these works have not provided an general and efficient reward model for RAG, it is still a challenge. 


% With the emergence of more and more reward models, another important challenge is how to evaluate the performance of these reward models, because the reward model plays a crucial role in reinforcement learning, Its performance directly affects the effect of reinforcement learning. ____ proposes the first benchmark that can comprehensively evaluate the performance of reward models, but it is unable to expand to multiple task scenarios. Inspired by this work, ____ propose multiple comprehensive benchmarks to evaluate the performance of reward models. However, none of these works proposes a benchmark that is suitable for RAG scenario. ____ solves this problem and proposes the first reward model benchmark in the RAG scenario. 


%GPT-4花费较大
%放到RAG场景下
%规避一下SFT问腿(RAG-reward)
%通用方法和RAG分隔开
%evaluation方法，为什么用LLM评价，为什么训练(ddr)



%1段 RAG乱七八糟的删掉，讲一句话“metric为什么不好”，引一篇1篇文章，引出evauation
%删除ROUGE等等
%2段 LLM评价, 被广泛使用  闭源模型成本高，采用开源模型，一些通用训练提升方法
%3段 RAG场景下，我们大模型关注的点，讲出RAG ebaluatin跟通用场景下不同，(我们的方法的不同)


%找到写论文的思路，动机写明白，找引用最高的，然后看被引的论文
%challenge 1: evaluation提示设计敏感
%challenge 2: 闭源模型花费大，api背后模型升级导致不可复现
%优点 1: 不需要大量的标记数据
%优点 2: RAG中有很多维度，很敏感，容易出现bias. 我们的方法能缓解不一致性
%不同prompt影响很大，所以做一致性分析, 消除这个bias，用一致性提升