This section describes best practices for method development that we suggest to
those using MotifBench to improve reproducibility and community progress.
We encourage discussion about this benchmark in the form of issues on the github repository
so that the benchmark may be usefully updated in the future.

\paragraph{Reproducibility:}
Method developers publishing results using the benchmark are encouraged to make their code available so that others may replicate their results.
In the absence of code, the designed backbones can be shared.
Designed scaffold structures for the entire benchmark should demand roughly 100Mb.
Such files may be shared publicly through open data platforms such as Zenodo \citep{zenodo} or the Open Science Framework (OSF) \citep{foster2017open}.

\paragraph{Compute time:}
When reporting results computed using this benchmark,
please also report the compute expense of generating the backbones on which the benchmark is evaluated.

\paragraph{Problem-specific adjustments:}
It is ``okay'' to tailor methods to each specific problem ({e.g.} choices of placement of motif segments or method-specific hyperparameters).
However, problem specific adjustments should be noted and explained to the extent that they are necessary for reproducibility.