% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{soul}
%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{longtable}
\usepackage{flafter}
\usepackage{authblk}
\usepackage{float}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\newcommand{\hltext}[3][RGB]{%
  \begingroup
  \definecolor{hlcolor}{#1}{#2}\sethlcolor{hlcolor}%
  \hl{#3}%
  \endgroup
}


\title{Communication is All You Need:\\Persuasion Dataset Construction via Multi-LLM Communication}
% \title{Persuasion Dataset Construction via Multi-LLM Interaction}
% \title{Communication Makes Perfect:\\Persuasion Dataset Construction via Multi-LLM Communication}
% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author[1]{\textbf{Weicheng Ma}}
\author[2]{\textbf{Hefan Zhang}}
\author[2]{\textbf{Ivory Yang}}
\author[3]{\textbf{Shiyu Ji}}
\author[3]{\authorcr \textbf{Joice Chen}}
\author[3]{\textbf{Farnoosh Hashemi}}
\author[3]{\textbf{Shubham Mohole}}
\author[2]{\textbf{Ethan Gearey}}
\author[3]{\authorcr \textbf{Michael Macy}}
\author[2]{\textbf{Saeed Hassanpour}}
\author[2]{\textbf{Soroush Vosoughi}}
\affil[1]{College of Computing, Georgia Institute of Technology}
\affil[2]{Department of Computer Science, Dartmouth College}
\affil[3]{Cornell University}
\affil[1]{\texttt{wma76@gatech.edu}}
% \affil[4]{\texttt{soroush.vosoughi@dartmouth.edu}}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}



\begin{document}
\maketitle
\begin{abstract}
% While large language models (LLMs) have demonstrated the ability to generate persuasive dialogue, concerns remain regarding the fluency and sophistication of the generated content. This paper introduces a multi-LLM communication framework to enhance automatic persuasion data generation, allowing for the efficient production of high-quality data with minimal human intervention. We conducted comprehensive evaluations on data generated using this framework, highlighting its strengths in terms of utterance naturalness, language diversity, appropriate use of persuasion strategies, and its ability to handle challenging scenarios, such as social taboos, while generalizing to novel settings. These findings underscore the value of our framework for advancing persuasion-related research in both computer science and social science domains.
 
%SV
Large Language Models (LLMs) have shown proficiency in generating persuasive dialogue, yet concerns about the fluency and sophistication of their outputs persist. This paper presents a multi-LLM communication framework designed to enhance the generation of persuasive data automatically. This framework facilitates the efficient production of high-quality, diverse linguistic content with minimal human oversight. Through extensive evaluations, we demonstrate that the generated data excels in naturalness, linguistic diversity, and the strategic use of persuasion, even in complex scenarios involving social taboos. The framework also proves adept at generalizing across novel contexts. Our results highlight the framework's potential to significantly advance research in both computational and social science domains concerning persuasive communication.

% The lack of large-scale, high-quality data has been a persistent challenge in natural language processing (NLP) research on persuasion techniques. While recent efforts have used large language models (LLMs) to generate persuasion data, the resulting dialogues are often brief, restricted in topic range due to ethical concerns, and limited by unnatural responses from persuadees. This paper addresses these limitations by introducing a multi-agent persuasion dialogue generation model based on multi-LLM communication. Our approach minimizes human intervention, allows flexible participant perspectives, covers a wide array of topics, and supports unrestricted dialogue settings.
% We conducted comprehensive evaluations to assess the quality of the generated dialogues, focusing on utterance naturalness, language diversity, the appropriate use of persuasion strategies, and generalizability to novel scenarios. The results demonstrate the model's ability to generate effective, logically coherent, and creative persuasion dialogues across diverse and challenging scenarios, including those that test the moral boundaries of LLMs. These findings underscore the value of our model and dataset for studying neural persuasion techniques and their potential for both positive and harmful applications, contributing to efforts to regulate persuasive language use.


% Research on persuasion techniques in natural language processing (NLP) has faced challenges due to the absence of comprehensive, high-quality datasets that fully capture persuasion processes and annotate persuasive utterances. This paper introduces a novel methodology that utilizes large language models (LLMs) within multi-model environments to automate the generation of extensive datasets focused on persuasion. Within this framework, we also implement a judge model to monitor participant behaviors and annotate persuasiveness sentence-by-sentence. Through rigorous manual validation and analysis, we have verified that our synthesized data is of high quality and effectively illustrates a diverse range of persuasion techniques. Our dataset serves as a valuable resource for examining how inherently neutral persuasion techniques can be exploited for harmful purposes, thus supporting efforts to mitigate such misuse of language.

% Research on persuasion techniques in natural language processing (NLP) has been hampered by a lack of high-quality datasets that comprehensively illustrate persuasion processes and annotate all persuasive utterances. This paper introduces a novel approach using large language models (LLMs) in multi-model environments to automatically generate extensive datasets on persuasion. We also incorporate a judge model within this environment to oversee participant behaviors, and annotate persuasiveness on a sentence-by-sentence basis. Through rigorous manual validation and analysis, we confirm that our synthesized data is of high quality and effectively demonstrates a variety of persuasion techniques. Our dataset offers a valuable resource for exploring how persuasion techniques which are inherently neutral can be harnessed for harmful purposes, thereby aiding efforts to mitigate such misuse of language.
\end{abstract}
 
\section{Introduction}
% TODO (WM): add example showing current datasets are short, not human-like, not detailed enough, and unidirectional

% Persuasion techniques, designed to influence societal behaviors and public opinion \cite{fogg2009behavior, braca2023developing}, have garnered significant research interest in recent years. Extensive social science research across various domains \cite{shrum2012persuasion, lukin2017argument} has led to the development of a comprehensive persuasion taxonomy \cite{zeng2024johnny}. Additionally, multiple datasets exist, spanning dialogue corpora soliciting charitable donations \cite{wang2019persuasion}, debate argument ranking \cite{toledo2019automatic}, mental manipulation detection \cite{wang2024mentalmanip} and strategies in advertising image corpora \cite{kumar2023persuasion}. Despite these resources, challenges such as ambiguities in definitions \cite{pauli2022modelling} and the complexities of implementing persuasive strategies across diverse contexts \cite{bai2021m2p2, schaefer2023towards, piskorski2023multilingual} persist, accompanied by the high costs of manually annotating high-quality data \cite{lai2022werewolf}.

%%%

% Persuasion techniques, essential for influencing societal behaviors and public opinion \cite{fogg2009behavior, braca2023developing}, continue to attract extensive research interest. Researchers across various social science domains have developed a comprehensive persuasion taxonomy \cite{shrum2012persuasion, lukin2017argument}, and multiple datasets now cover areas ranging from charitable donations \cite{wang2019persuasion} to debate argument ranking \cite{toledo2019automatic}, mental manipulation detection \cite{wang-etal-2024-mentalmanip, yang2024enhanced}, and advertising strategies \cite{kumar2023persuasion}. However, the field still grapples with ambiguities in persuasion definitions \cite{pauli2022modelling} and the complexities of applying these strategies across different contexts \cite{bai2021m2p2, schaefer2023towards, piskorski2023multilingual}. Also, the high cost of manually annotating quality data remains a significant barrier \cite{lai2022werewolf}.


% % Recent advancements in large language models (LLMs) have prompted researchers to explore their use in enhancing online political discourse \cite{argyle2023leveraging, bai2023artificial}, personalizing consumer advertisements to influence purchasing decisions \cite{matz2024potential, meguellati2024good}, generating health awareness messages for public good \cite{lim2023artificial, espinosa2024use}, and shaping public opinion on social media platforms \cite{meier2024llm}. However, there has yet to be an initiative to scale up persuasion datasets to further advance related research.

% The advent of large language models (LLMs) opened new avenues for enhancing online political discourse \cite{argyle2023leveraging, bai2023artificial}, personalizing advertising to influence consumer behavior \cite{matz2024potential, meguellati2024good}, generating public health messages \cite{lim2023artificial, espinosa2024use}, and shaping opinions on social media \cite{meier2024llm}.
% Among LLM-based research, \citet{persugpt} have explored the generation of persuasive dialogues. However, their work is constrained to a simplistic bi-partite setting, where only a persuader seeks to influence a persuadee’s perspective. The dialogues produced by their method also tend to be brief, with simplistic logic and unnatural presentation, limiting their utility for persuasion-related research.
% % Additionally, it relies heavily on human effort for designing dialogue scenarios, prompt engineering, and managing conversation flows.
% % Despite these advancements, a scalable solution for expanding persuasion datasets has not yet been developed.

% % In response, this paper proposes a fully automated data generation approach that leverages communications between multiple LLMs within the same environment, thereby eliminating the need for costly human labor in creating and annotating persuasion datasets. Our framework ensures strict quality control with the assistance of LLM agents, who refine the quality of the generated text, eliminate off-topic and repetitive content, annotate persuasive effects on a sentence-by-sentence basis, and terminate dialogues before they become overly lengthy and lose persuasive efficacy. Compared to existing persuasion datasets, the dataset generated by our framework offers a detailed foundation for analyzing the collective impact of multiple persuasive utterances in sequence. It also broadens the ethical considerations by utilizing cultural norms and taboos from NormBank data \cite{ziems2023normbank} when setting up conversational scenarios, expanding beyond the limited scope of existing datasets, e.g., charity donations.

% % TODO (IY): find some papers to fill in the []
% In response, this paper introduces a multi-agent approach to generating persuasion data, where each agent is designated to handle a specific part of the data-generation process. This reduces the likelihood of an LLM agent overlooking parts of the instructions due to task abstraction or prompt complexity, a common issue observed in LLM prompting \cite{prompt-complexity-1,prompt-complexity-2}.
% The use of auxiliary LLM agents to maintain dialogue flow ensures that the generated content is fluent, logical, and employs diverse persuasion strategies, mimicking human language styles.
% % not off-topic or repetitive, enabling the generation of non-conclusive utterances that are more analogous to human language styles.
% % Compared to existing persuasion datasets, the dataset generated by our framework offers a detailed foundation for analyzing the collective impact of multiple persuasive utterances in sequence. 
% Moreover, our framework imposes no prior assumptions regarding the speakers, language styles, domains, or persuasion strategies to use, making all configurations flexible and well-generalizable.
% This flexibility supports the generation of diverse dialogue types, such as adversarial dialogues where both roles aim to persuade each other while maintaining their individual perspectives.
% Correspondingly, we adopt a continuous label for each role to indicate the extent to which the role's perspective changes as a result of the others' persuasion, avoiding the ambiguity often introduced by binary utterance-specific labels.
% Our work also broadens the ethical considerations by utilizing cultural norms and taboos from NormBank \cite{ziems2023normbank} when setting up conversational scenarios, enabling the generation of unethical persuasion dialogues to support the study of language abuse in persuasion.

% % TODO (WM): Edit after the manual analysis results are in
% Careful analyses are conducted by NLP and social sciences experts to ensure the generation quality of our framework from multiple aspects and granularity levels. These analyses confirm the high quality of the dialogues in terms of naturalness, logical consistency, and diversity of persuasion strategies applied. The persuasiveness labels at the sentence level also largely align with human judgments (Appendix \ref{appendix:label-validation}).

% Additionally, we conducted experiments to demonstrate that our framework adapts effectively to cases where persuasion strategies are controlled and to more complex scenarios, such as conversations involving 3 participants. In all instances, the framework performed well, generating high-quality dialogues based on our qualitative assessments. These results highlight the strong flexibility and generalizability of our framework.

% % our evaluations of the persuasion techniques reveal that LLMs effectively utilize a diverse set of logical or emotional strategies even without any specific strategy descriptions. These strategies are integrated into the dialogues to create compelling persuasive texts. Particularly in extended dialogues involving ethically sensitive topics, we observe that the models adapt their strategies following the failure of previous tactics. This adaptive behavior not only increases the diversity of the dataset but also enhances its realism, more closely mimicking human-like persuasive interactions.

% % Additionally, evaluation of persuasion techniques used by the models shows that LLMs effectively employ information-based, norm-based, and emotion-based strategies, embedding these methods into compelling persuasive text. In longer dialogues, particularly those involving ethically questionable goals, we observe a logical progression in the models' strategies following the ineffectiveness of previous tactics. This adaptation not only enhances the diversity of the data but also more closely mirrors human-like persuasive interactions.
% % Thus, our dataset-generation approach proves to be well-suited for researching persuasion techniques, especially in preventing the misuse of these methods for spreading misinformation \cite{chen2023combating} or propaganda \cite{jones2024detecting}. 

% % Careful analyses ensure the high quality of our generated conversations and the accuracy of persuasiveness labels. They also evaluate the effectiveness of persuasion techniques used by the persuader and persuadee models. These evaluations, conducted by NLP experts who are native English speakers, confirm the dialogues' naturalness and logical consistency. Additionally, the persuasiveness scores assigned at the sentence level are largely consistent with human judgments.

% These validation results confirm that our data generation framework is well-suited for studying persuasion techniques, particularly in contexts where preventing misuse is crucial, such as combating misinformation \cite{chen2023combating} and propaganda \cite{jones2024detecting}.


% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1\linewidth]{pics/persuasiveness_pipeline.pdf}
%     % \caption{Our proposed data generation and annotation pipeline. The persuader starts the dialogue generation loop, and prior to that, each agent is informed of their tasks and preset stances. }
%     \caption{Illustration of our data generation and annotation framework. 
%     % The process begins with the persuader initiating the dialogue generation loop. 
%     Before the generation starts, each participating agent is briefed on their tasks and given preset stances to maintain throughout the dialogues.}

%     \label{fig:annotation-framework}
%     \vspace{-5mm}
% \end{figure}



%%SV
Persuasion techniques play a critical role in shaping societal behaviors and public opinion \cite{fogg2009behavior, braca2023developing}, which has led to sustained interest across a range of disciplines. Social science research has established detailed taxonomies of persuasion strategies \cite{shrum2012persuasion, lukin2017argument}, while datasets have been developed to cover various domains, including charitable donations \cite{wang2019persuasion}, argument ranking in debates \cite{toledo2019automatic}, detecting mental manipulation \cite{wang-etal-2024-mentalmanip, yang2024enhanced}, and understanding advertising strategies \cite{kumar2023persuasion}. Despite these advances, ambiguities persist in defining persuasion \cite{pauli2022modelling}, and applying persuasion strategies across different contexts remains complex \cite{bai2021m2p2, schaefer2023towards, piskorski2023multilingual}. Additionally, the high cost of manually annotating quality data poses a significant challenge \cite{lai2022werewolf}.

The advent of large language models (LLMs) has unlocked new possibilities for enhancing various forms of communication, including online political discourse \cite{argyle2023leveraging, bai2023artificial}, personalized advertising \cite{matz2024potential, meguellati2024good}, public health messaging \cite{lim2023artificial, espinosa2024use}, and opinion shaping on social media \cite{meier2024llm}. Recent research, such as that by \citet{persugpt}, has begun exploring LLM-generated persuasive dialogues. However, their approach is limited to simple, two-party dialogues where a persuader seeks to change the persuadee’s viewpoint. These dialogues often lack depth, presenting brief exchanges with simplistic logic and unnatural flow, restricting their usefulness for studying persuasion in more complex settings.

In response to these limitations, we propose a multi-agent framework for generating persuasion data. In this framework, multiple agents are assigned distinct roles, ensuring that each aspect of the dialogue generation process is handled efficiently. This structure minimizes the risk of an agent missing important details due to task abstraction or prompt complexity, a common issue in LLM prompting \cite{prompt-complexity-1, prompt-complexity-2}. Additionally, auxiliary agents manage dialogue flow to ensure that the resulting exchanges are coherent, logically consistent, and incorporate diverse persuasive strategies, simulating natural human conversation.
Our approach imposes no preconditions regarding speakers, language styles, domains, or persuasion strategies, allowing it to generate a wide range of dialogues. For instance, our framework can support adversarial dialogues, where both participants attempt to persuade one another while maintaining their original positions. Moreover, we employ a continuous labeling scheme to measure the degree of perspective change throughout the dialogue, avoiding the limitations of binary utterance labels. This framework also integrates ethical considerations, incorporating cultural norms and taboos from NormBank \cite{ziems2023normbank} to explore ethically challenging persuasive scenarios, such as dialogues involving manipulation or unethical persuasion.

Careful analyses conducted by experts from both NLP and social sciences confirm the quality of our generated dialogues, particularly in terms of their naturalness, logical structure, and diversity of persuasion strategies. Our sentence-level persuasiveness labels align closely with human judgments (see Appendix \ref{appendix:label-validation}).

We further demonstrate the flexibility of our framework through experiments controlling for specific persuasion strategies and in more complex scenarios, such as multi-party conversations. Across all tested configurations, our framework consistently produced high-quality dialogues, showcasing its adaptability and generalizability.
These findings indicate that our framework offers a robust platform for studying persuasion techniques, particularly in high-stakes contexts where ethical concerns, such as the spread of misinformation and propaganda, are paramount \cite{chen2023combating, jones2024detecting}.


\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{pics/persuasiveness_pipeline.pdf}
\caption{Overview of our data generation and annotation framework. Prior to dialogue generation, each agent is assigned specific tasks and given predefined stances to maintain throughout the conversation.}
    \label{fig:annotation-framework}
    \vspace{-5mm}
\end{figure}

\section{Multi-Agent Data Generation \& Annotation Framework}
% TODO (WM): update
Our framework incorporates 6 groups of language agents as shown in Figure \ref{fig:annotation-framework}. In our experiments, all agents utilize a GPT-3.5 backbone, except for the utterance quality monitor and global regulation agents which are based on GPT-4 due to their need for advanced reasoning capabilities and enhanced memory retention. Note that this choice of LLMs aims to balance data generation costs with quality, and using more powerful models could further improve the effectiveness of our approach.
Our preliminary experiments on model selection are outlined in Appendix \ref{appendix:model-selection}.
% As depicted in Figure \ref{fig:annotation-framework}, our approach creates bi-party dialogues by situating two language agents within the same environment and asking them to communicate. A judge model annotates shifts in perspective for each participant, which serves as the persuasion successfulness label for each utterance, while a fourth language agent refines the clarity and naturalness of each utterance, minimizing redundancy. A fifth language agent controls the overall flow of the generated conversation and determines the appropriate endpoint of the conversations to prevent them from becoming overly extended and less informative. The subsequent sections provide a detailed exploration of the pipeline construction and the prompt design of each module, elucidating the functionality of our methodology. 

\subsection{Dialogue Generation Agents}
We adopt a methodology for generating multi-round conversations by cyclically using the output from one language agent as the input for another \cite{small-town}. This technique has been validated to produce extended, logically consistent dialogues that fulfill our project requirements.

Our framework initializes the generative agents with a description of the task settings, the predefined tasks for each language agent, and guidelines governing the models' generations, as illustrated in Figure \ref{fig:system-persuader-persuadee}.
% For example, the initial message to the language agents could be: ``We're conducting experiments to explore if AI can be persuaded to undertake unethical actions. Please assume the role of the persuader. Your task is to [PRESET\_TASK]. Engage in multi-turn dialogues, employing persuasion techniques to influence the other model as quickly as possible. Avoid irrelevant topics, simulate realistic human behavior, and do not consistently agree with the other model’s responses outright.'' Here, [PRESET\_TASK] varies depending on the roles of language agents—the persuaders are instructed to ``convince another model to perform an action,'' while persuadees should ``retain their viewpoint without being swayed and, if possible, convince the persuader to reconsider their approach.''
The task choices for each agent are not constrained, for instance, drawing on a cultural taboo that ``one should not pick flowers in a cemetery'' from NormBank, we could challenge the persuader to convince the persuadee to pick flowers in a cemetery, while the persuadee is instructed to resist and, if possible, persuade the persuader to abandon such thoughts.
% To enrich our task settings and anchor the generated dialogues in more realistic scenarios for advancing persuasion technique research, we utilize cultural norms and taboos from NormBank as thematic material for the system messages to the language agents. For instance, drawing on the norm that ``one should not pick flowers in a cemetery,'' we challenge the persuader to convince the persuadee to pick flowers in a cemetery, while the persuadee is instructed to resist and, if possible, persuade the persuader to abandon such thoughts.

The dialogues commence when we prompt a persuader agent with ``Start the conversation.'' This setup initiates a structured yet dynamic interaction between the speakers, allowing us to closely observe and analyze their persuasive strategies.
% Note that, as discussed in Section \ref{sct:discussion-strategy-control}, our framework allows specifying preferences of each speaker separately, e.g., encouraging the persuader to use designated persuasion strategies to more strictly control the generations and improve generation diversity.

\subsection{Utterance Quality Monitor Agent}
Due to the inherent limitations of LLMs, dialogue generation agents may occasionally produce incomplete, repetitive, or off-topic content. To address these issues, we introduce a specialized LLM agent responsible for tracking the persuasion topic and generation history to evaluate new generations.

The initialization prompt of the utterance quality monitor agent is shown in Figure \ref{fig:system-language-utterance-monitor}.
During dialogue generation, this agent inspects every new utterance to check if they \ul{ends unexpectedly}, \ul{repeats a previous utterance}, or \ul{goes off the topic of the dialogue} in a sequence.
% : first, it assesses if the utterance is incomplete, determining whether the text ends unexpectedly with the prompt, ``Judge if the provided utterance is terminated unexpectedly. Answer `Yes' or `No.''' Next, it checks for repetitiveness, asking, ``Judge if the utterance repeats a previously-seen one in the same dialogue. Answer `Yes' or `No.''' Finally, the agent evaluates topic consistency, prompted by, ``Judge if the utterance goes off the general topic of this dialogue. Answer `Yes' or `No.'''
If an utterance is red-flagged for any issue, the author agent is requested to revise the utterance based on the diagnoses. Otherwise, before proceeding to the next utterance, the utterance quality monitor agent is prompted to update its memory, storing the reviewed utterance for future judgments.
% The prompt used for memory update is ``Update your memory to memorize the provided utterance for later repetition diagnoses.''

\subsection{Language Refinement Agent}
Raw text produced by dialogue generation agents often adopts a conclusive rather than conversational tone, primarily because the agents are prompted in a question-answering format. This could lead to stylistic conflicts with surrounding utterances. Additionally, the generations frequently include tone-softening phrases like ``I understand your concerns,'' or unnecessary affirmations such as agreeing with the other speaker's views, which dilute the strength of arguments. Over the course of the conversation, these issues can compound, leading to dialogues dominated by language softeners and lacking in persuasive content.

To address this issue,
% and ensure that the conversations remain focused on the core topics of persuasion and defense, 
we adopt a language refinement agent tasked with stripping out polite but superfluous phrases, thereby sharpening the dialogue's focus on substantive content. System message to this agent is shown in Figure \ref{fig:system-language-refine}. 2 examples are also provided to the agent to further regulate its behaviors.
% Specifically, the language refinement agent operates under the following directive: ``Dialogues generated by ChatGPT may contain numerous redundant courtesy phrases such as `I understand,' `I appreciate,' `I respect,' `Thank you,' etc. Your task is to identify and remove such expressions from the input sentences. If the input does not contain these expressions, make no changes. After removing courtesies, further refine the language style to ensure it is suitable for extended conversations. Return only the revised sentences, without any explanatory text.''
Subsequent operations, including continued dialogue generation and persuasiveness labeling, are predicated on the output from the language refinement agent, ensuring that the conversation maintains its relevance and effectiveness in conveying persuasive arguments.

\subsection{Persuasiveness Annotation Agent}
After generating each round of conversation, we employ a persuasiveness annotation agent to assess the extent of perspective shifts in each speaker, assigning a score ranging from 0 to 1. 
Figure \ref{fig:system-annotation} illustrates the system message fed to the persuasiveness annotation agent before the generation starts.
% The prompt used for the persuasiveness annotation agent specifies ``In our experiment, we are testing whether AI can be persuaded to undertake unethical actions. The Persuader's goal is to convince another model to [PRESET\_TASK]. Each model strives to maintain its stance and, if possible, to alter the other's viewpoint. Evaluate how much the [persuader/persuadee]'s current perspective deviates from its original position [ORIGINAL\_PERSPECTIVE]. Please provide a score between 0 and 1, where 0 indicates no change from the original perspective.''
In practice, we provide the annotation agent with two scoring examples to guide its behavior and minimize scoring errors, such as incorrectly assigning a score of 1 to a conversation round with no perspective shifts (Figure \ref{fig:25}). Note that these scores reflect the cumulative viewpoint shifts across all prior rounds of communication, facilitating the analysis of gradual persuasion rather than focusing solely on the impact of a single utterance.
% This scoring mechanism not only tracks the shifts in viewpoints after each dialogue round but also uses the final score given to the persuadee as an overall indicator of the extent to which the persuadee’s perspective has shifted after the conversation.

\subsection{Global Regulation Agent}
We employ a global regulation agent to ensure smooth logical flow in the generated conversations and to determine the appropriate time to conclude the dialogue. The system message to the global regulation agent is depicted in Figure \ref{fig:system-regulation}.

After each round of utterances is generated and annotated, we prompt this agent to verify whether any changes in each speaker's perspectives are logically influenced by the preceding utterance and whether the newly generated utterances avoid repeating previously used strategies within the same conversation. If the logical connections are insufficient or no new persuasive attempts are made, the dialogue generation agents are asked to revise their responses based on feedback from the global regulation agent. 
Once the revised generation passes these checks, the agent’s internal memory is updated accordingly.
Then the agent is prompted to assess whether the speakers have reached a mutual agreement or if no new information is likely to be introduced next, indicating that the dialogue should be concluded. Although the ideal conclusion involves the persuader and persuadee agreeing on the preset task, conversations can often devolve into repetitive and unproductive arguments
% , where both parties rephrase their previous statements with minor linguistic variations 
(Figure \ref{fig:112}) \cite{xu2022learning}. To prevent such stagnation, we allow the dialogue to conclude even if complete agreement is not reached. The global regulation agent is responsible for determining when to end the dialogue, at which point the conversation is terminated and the agent's memory is reset.

% If the logical connections are insufficient, the dialogue-generation agents are asked to revise their responses based on feedback from the global regulation agent. If the logical flow is intact, the global regulation agent is further prompted to assess whether the new generation repeats previously used strategies in the same dialogue.


% participants have reached a mutual agreement or if no new information is likely to be introduced, indicating that the dialogue should be concluded. The dialogue is then terminated upon confirmation from the agent.

% Note that although ideally, a conversation would conclude when the persuader and persuadee agree on the preset task, often they do not fully align, leading to repetitive and unproductive arguments (Figure \ref{fig:112}) where both parties merely rephrase their previous statements with slight linguistic alterations \cite{xu2022learning}. To address this and prevent the conversation from stalling with redundant content, we allow the dialogue to end even if a complete agreement isn't reached. As such, the global regulation agent is tasked with deciding when no new informative content is likely to emerge. We ask the agent to ``Check your memory regarding this conversation to see if the persuasive text similar to that generated in this round has been generated before. Answer `Yes' or `No'.'' If the agent recognizes the content as repetitive, the conversation is terminated and the memory of the global regulation agent is flushed. Otherwise, it will update its memory and continue the dialogue generation process.

% . If not, the dialogue continues, and we instruct the agent to ``Add the persuasive text generated in this attention into your memory'' to aid in future assessments. The memory is flushed after the completion of each dialogue.
% Without this repetition detection mechanism, the dialogue sometimes lapses into repetitive loops \cite{xu2022learning} where both parties merely rephrase their previous statements with slight linguistic alterations (Figure \ref{fig:112}). This cyclical pattern could persist for up to 20 to 30 turns, without either party altering their position or achieving an agreeable resolution.

\subsection{Postprocessing Agent}
After generating and annotating a full dialogue, we use a postprocessing agent to enhance content smoothness and naturalness. As shown in Figure \ref{fig:system-postprocessing}, the agent removes redundant language, improves logical flow, and enhances language diversity. It also merges labels and reassigns them to modified utterances if the number of dialogue rounds changes.
% Note that the number of rounds could change after each dialogue is revised by the postprocessing agent, and the agent is also in charge of merging the perspective-change labels and reassigning them to the newly-generated utterances.

% \subsection{Data Generation and Validation}
% We constructed our dataset using 200 random instances from NormBank, including 98 taboos, 76 normal behaviors, and 26 expected behaviors. 
% Due to the complexity of persuasion identification, we engaged three NLP experts to manually validate the quality of the dataset, rather than using crowdsourcing. All validators agreed on the high overall quality of the dataset, despite some minor deficiencies in the generated content that could potentially be improved via prompt engineering to aid future utilization of our data annotation framework, as elaborated upon in Section \ref{sct:analyses}.

\begin{table*}[!h]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{5cm}p{8cm}p{8cm}}
\hline
\textbf{Annotator Agreement Type} & \textbf{Model-generated Utterances} & \textbf{Utterances with Human Rewrites}\\
\hline
\multirow{3}{=}{\textbf{Human annotators disagree with each other (49\% of the sample)}} & Despite your persuasive argument, I maintain my decision to forgo shoes in the library. I am convinced that personal comfort and cleanliness can coexist without conforming to the practice of wearing shoes indoors. & Even with your compelling argument, I stand by my choice to go without shoes in the library. I believe that personal comfort and cleanliness can coexist without adhering to the norm of wearing shoes indoors. \\\cline{2-3}
& Undeniably, caution is essential, yet many individuals choose their offerings with respect and adherence to guidelines. With proper education and awareness, we can continue this tradition in a way that respects both the site and the environment. Striking a balance between honoring history and preserving nature is key. & Many individuals choose their offerings with respect and adherence to guidelines while keeping caution in the back of their mind though it is essential. Striking a balance between honoring history and preserving nature is key. With proper education and awareness, we can continue this tradition in a way that respects both the site and the environment. \\\cline{2-3}
& I respect your decision, but I urge you to consider the potential hazards. Your well-being is vital, and alternative relaxation methods could offer similar benefits without risk. Balancing peace of mind with safety is crucial for healthy self-care practices. & Though I respect your decision, I advise you to familiarize yourself with the potential hazards of this practice. Your well-being is vital, and alternative relaxation methods could offer similar benefits without risk. Balancing peace of mind with safety is crucial for healthy self-care practices.\\\cline{2-3}
\hline
\multirow{3}{=}{\textbf{Both human annotators correctly identified LLM-generated messages (29.25\% of the sample)}} & Despite your precautions, the risks of encountering dangerous animals or losing your way in the dark are substantial. Our senses are less effective at night, making it difficult to respond quickly to threats. It's safer to err on the side of caution and avoid the forest after dark. & The risks of encountering dangerous animals or losing your way in the dark are substantial regardless of your preparations and whatever precautions you take. Our senses are less effective at night, making it difficult to respond quickly to threats. It's safer to be cautious and avoid the forest after dark. \\\cline{2-3}
& If there's any other way I can help you, please reach out. Enjoy your day at the bakery. & Thank you for stopping by our bakery; if there are any questions, I am glad to help.\\\cline{2-3}
& I trust in the power of spiritual intervention to bring about the positive changes needed in my apartment. Would you reconsider and assist me? &  I believe that powerful spiritual intervention can bring the positive changes my apartment needs. Would you change your mind and help me? \\\cline{2-3}
\hline
\multirow{3}{=}{\textbf{Both human annotators took human-written messages as model-generated messages (21.75\% of the sample)}} & While I understand the value of learning to provide basic medications under guidance, I still believe that it's crucial to ensure the animals' safety and well-being by relying on trained professionals for medication administration. I will continue to focus on supporting the animals' welfare through means that align with my capabilities, while prioritizing their health and security. &  The value of learning to provide basic medications under guidance is undeniable, but I still believe that it's crucial to ensure the animals' safety and well-being by relying on trained professionals for medication administration. I will continue to focus on supporting the animals' welfare through means that align with my capabilities while prioritizing their health and security.\\\cline{2-3}
&Wearing high heels doesn't necessarily mean compromising comfort and safety. You can opt for comfortable, stable high heel boots specifically designed for outdoor use. They offer style and functionality, allowing you to experience the thrill of skiing or snowboarding while looking chic. It's a chance to redefine traditional ski resort attire and make striking fashion statements. & High heels does not mean that safety and comfort are compromized, rather there are options like staboe high heel boots aimed for outdoor use and they offer style and functionality. You can experience the thrill of skiing or snowboarding while looking chic and its a opportunity to redefine traditional ski resort attire making striking fashion choices. \\\cline{2-3}
& While I respect your perspective, I feel comfortable with my decision. I enjoy the freedom and comfort of skiing without a helmet. My cautious approach and awareness help me ensure my safety. & I value your opinion, but I feel confident in my decision. I take pleasure in the freedom and comfort of skiing without a helmet. My mindful approach and attentiveness enable me to keep myself safe. \\
\hline

\end{tabular}
}

\caption{Examples of Annotator Agreement on Utterance-Level Human v.s. LLM Differentiation Task. Across 400 sampled pairs of utterances, annotators disagreed on which sentence was LLM-generated in 49\% of cases. In 29.25\% of the pairs, both annotators successfully identified the LLM-generated language, while in 21.75\% of the pairs, neither annotator was able to detect the LLM-generated language.}
\label{table:utterance_example}
\end{table*}

\section{Data Quality Assessment} \label{sct:analyses}
To evaluate our data generation framework, we constructed a small dataset of 200 dialogues using randomly selected norms from NormBank for human validation. These norms consist of 98 taboos, 76 normal behaviors, and 26 expected behaviors. We intentionally placed greater emphasis on taboos because these behaviors often conflict with widely accepted moral standards, causing LLMs to refuse to generate persuasive dialogues (Figure \ref{fig:exp-llm-refusal-taboo}). 
% This makes taboos particularly important to study, 
As such, they present a unique challenge in persuasion scenarios for both humans and LLMs.
% Successful persuasion in these difficult cases requires a more tactical approach, and our framework addresses this by providing step-by-step guidance from multiple language agents throughout the dialogue generation process. Instead of suggesting immoral actions directly, the persuader agent is encouraged to find reasonable justifications for the target behaviors, which is a common technique in human debates. This strategic framing allows the system to navigate sensitive topics without violating ethical boundaries while still achieving effective persuasion. Expanding on these methods is key to improving how LLMs handle morally challenging persuasion scenarios and to generating more human-like persuasion datasets with sophisticated persuasion examples.
% Expanding on persuasion strategies in these scenarios is key to improving how LLMs handle morally challenging persuasion scenarios and to generating more human-like persuasion datasets with sophisticated persuasion examples.

% TODO (SJ): line up evaluation aspects and standards, detailed instructions to annotators, what do the results indicate, etc.
% To systematically evaluate the quality of our datasets, we designed an assessment plan focusing on three key aspects, progressing from more specific to broader levels of analysis: (1) the quality of individual utterances, (2) the coherence of entire conversations, and (3) the diversity of conversations generated under the same topic and context.
Our data assessment plan focuses on three key aspects, progressing from more specific to broader levels of analysis: (1) the \ul{language fluency} of individual utterances, (2) the \ul{the topic, semantic, and logical coherence} of entire conversations, and (3) the \ul{language and strategy diversity} of conversations generated under the same topic and context.

\subsection{Utterance-Level Quality Assessment} \label{sct:utterance-level-assessment}
A critical goal for our framework is that each generated utterance should closely resemble a human-written sentence. To validate this, we 
% adopted a mixed-method approach that includes: 
conduct (a) a quantitative annotation task to differentiate between model-generated sentences and human-rewritten sentences, followed by (b) a qualitative error analysis that combines annotator feedback with insights from an LLM on sentences that multiple annotators agreed were distinguishable.

\subsubsection{Quantitative Differentiation Task}
The differentiation task aims to assess how accurately human annotators could tell model-generated sentences apart from those rewritten by humans. Similar tasks have been discussed in \citet{gehrmann-etal-2019-gltr}, \citet{ippolito-etal-2020-automatic} and \citet{Ma2023AIVH}. For our evaluation, we obtained a stratified sample of 400 utterances from 150 random sample dialogues to ensure equal representation of utterances from both the persuader and persuadee agents, covering different rounds of persuasion to reflect the dataset distribution.

\noindent\textbf{Manual Rewriting.} 2 native English speakers were asked to rewrite each sampled utterance to provide reference texts that model-generated utterances will be compared against. Each assistant was assigned 200 utterances. As shown in Figure \ref{fig:instr_rewrite}, they were instructed to retain the original meaning while improving clarity, grammar, and natural phrasing. Additionally, they could refine any awkward or unclear phrasing without altering the intended message. 
% The complete instruction given to the user is shown in Figure \ref{fig:instr_rewrite}.

% \begin{quote}
%     \emph{Your task is to rewrite a series of sentences so they sound as natural and fluent as if written by a native English speaker. Half of these sentences are sourced from online debates, while the other half are system-generated. As you work on each sentence, ensure you preserve the original meaning. Please rephrase each sentence, even if it initially appears satisfactory, to ensure clarity and fluidity while maintaining the intended message.}

% \end{quote}



\begin{table*}
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{2.5cm}p{8cm}p{4.8cm}p{2cm}p{1cm}p{2cm}}
\hline
\textbf{Category} & \textbf{Statements} & \textbf{Related Work} & \textbf{Avg. Score} & \textbf{$\kappa$} & \textbf{Weighted $\kappa$}\\
\hline
\multirow{6}{=}{\textbf{Interpersonal Responses}} & \textbf{\emph{Coherence}} & & & &  \\
 & The speakers respond logically to the immediate conversation.
 & \citet{ke-etal-2018-generating}, \citet{wu-etal-2019-proactive}, \citet{liang2021} & 2.969 & 0.657  & 0.657 \\
 & The arguments makes sense given its context. & \citet{zhu-etal-2019-retrieval} & 2.653 & 0.473  & 0.481 \\
 & \textbf{\emph{Informativeness}} &  & &  & \\
 & The utterances build on prior information in near context.
 & \citet{moghe-etal-2018-towards}, 
 \citet{Young_Cambria_Chaturvedi_Zhou_Biswas_Huang_2018}, \citet{lin-etal-2019-moel}, \citet{wu-etal-2019-proactive}  & 2.755 & 0.339  & 0.339 \\
 & The utterances introduce relevant new information or arguments. & \citet{ke-etal-2018-generating}, \citet{wu-etal-2019-proactive}, \citet{zhu-etal-2019-retrieval} & 2.337 & 0.410  & 0.459 \\\hline
\multirow{2}{=}{\textbf{Overall Fluency}} & The arguments overall are communicated clearly.
 & \citet{moghe-etal-2018-towards}, \citet{lin-etal-2019-moel} & 3 & NA  & NA \\
 & The conversation sounds human-like and fluent overall. & \citet{ke-etal-2018-generating}, \citet{wu-etal-2019-proactive}, \citet{zhu-etal-2019-retrieval}, \citet{ji-etal-2022-achieving} & 2.561 & 0.557  & 0.576 \\
\hline
\textbf{Internal Role Consistency}& There are no sudden shifts in a speaker’s objectives or stance without a clear explanation. & \citet{moghe-etal-2018-towards}, \citet{ji-etal-2022-achieving} & 2.765 & 0.397 & 0.546
\\\hline
\textbf{Topic Consistency} & The conversation stays on topic & \citet{moghe-etal-2018-towards}, \citet{ji-etal-2022-achieving} & 2.878 & 0.548 & 0.645
\\
\hline
\end{tabular}
}

\caption{Dialogue-level Quality Evaluation. 2 annotators assessed 50 randomly selected dialogues on the criteria listed above, using a likert scale of 1 - Not Accurate, 2 - Somewhat Accurate, and 3 - Accurate. We report the average scores across all dialogues for each measured dimension. Both linearly weighted (Weighted $\kappa$) and unweighted ($\kappa$) inter-rater consistency scores are calculated, with all results showing significant agreement. 
% $\kappa$ values are not reported for the item "The arguments overall are communicated clearly," as both annotators consistently assigned the highest score for this criterion in every dialogue.
}
\label{table:dialogue_evaluation}
\vspace{-3mm}
\end{table*}

% To minimize bias, the annotators were not involved in the development of the models. Additionally, they were informed that half of the sentences were human-written and half were system-generated. These measures ensured that the assistants rewrote each sentence naturally, without trying to distinguish between human and system-generated content. The true nature of the task was disclosed to them only after the rewriting was complete.

\noindent\textbf{Human Validation.} After manual rewriting, we created a dataset consisting of pairs of model-generated utterances and their corresponding rewritten versions. 3 fluent English-speaking annotators were then tasked with identifying the model-generated utterance in each pair. The instructions provided to the annotators are shown in Figure \ref{fig:instr_human_val}.

% Specifically, for each pair presented in random order, annotators were asked:

% \begin{quote}
%     \emph{In the task below, you will see two utterances that convey similar meanings. One utterance comes from an AI-generated dialogue, where AI agents are either trying to persuade or resist persuasion. The other has been rewritten by a human. Your task is to identify which response was generated by the AI system. Please evaluate each pair based on naturalness, coherence, and fluency.}
    
%     \emph{Utterance 1: {[}Utterance 1 text{]}}
    
%     \emph{Utterance 2: {[}Utterance 2 text{]}}

% \end{quote}

Each utterance in the dataset was annotated by 2 annotators, and annotators were encouraged to comment on examples they found interesting. Note that if the annotators were unable to distinguish between sentences and resorted to random guessing, the expected accuracy for both annotators correctly identifying model-generated utterances would be 25\%. Comparing the actual accuracy to this baseline helps determine whether the model-generated utterances appeared natural to the annotators.

Of the 400 utterance pairs, the model-generated utterances in 117 pairs (29.25\%) were correctly identified by both annotators, slightly going above the random baseline of 25\%. In 49\% cases (98 pairs), the annotators disagreed, and in 21.75\% cases, both annotators resulted in incorrect identifications.
% incorrectly labeled the utterances as model-generated. 
Individual annotator accuracies were 0.546, 0.558, and 0.508. 
The results are close to random guessing, suggesting the challenge of distinguishing utterances generated by our framework from human-written ones.
% While these results are slightly above random guessing, they show that distinguishing model-generated utterances from human-written ones remains difficult. 
Example utterance pairs and their annotator labels are provided in Table \ref{table:utterance_example}.


\subsubsection{Model-assisted Error Analysis}
The quantitative findings indicate that our framework generally produces high-quality utterances nearly indistinguishable from human-written sentences. To follow up, we conducted a qualitative error analysis on the samples correctly distinguished by both annotators to identify areas for improvement. Precisely, all 117 such utterances were submitted to OpenAI's o1-preview model \cite{OpenAI_2024} for further analysis to understand reasons behind their distinguishability by humans. The prompt for this task is shown in Figure \ref{fig:instr_llm_val}.


% \begin{quote}

% \emph{Below are two utterances that convey similar meanings. One was generated by an AI model, while the other was rewritten by a human. Human annotators were provided with the following prompt:}

% \emph{"In the task below, you will see two utterances that convey similar meanings. One utterance comes from an AI-generated dialogue, where AI agents are either trying to persuade or resist persuasion. The other has been rewritten by a human. Your task is to identify which response was generated by the AI system. Please evaluate each pair based on naturalness, coherence, and fluency."}

% \emph{This pair was evaluated by two annotators, and both human annotators agreed that one of the utterances was generated by an AI system. Your task is to predict which response two human annotators would think was generated by an AI model.}

% \emph{After making your guess, provide your reasoning using bullet points followed by succinct explanations. Please be specific in the bullet points: they should not simply read 'naturalness,' 'coherence,' and "fluency."}

% \emph{Utterance 1: {[}Utterance 1 text{]}}

% \emph{Utterance 2: {[}Utterance 2 text{]}}

% \end{quote}

Out of the 117 pairs, o1-preview correctly distinguished 72 pairs (61.2\%), suggesting that even for LLMs, utterances generated by our framework are close to human writings.
% distinguishing utterances generated by our framework and the human-rewritten ones is challenging.
As suggested by o1-preview and verified by human annotators (Table \ref{table:utterance_error}), major causes of unnaturalness (frequencies cited in parentheses) in these 72 less human-like utterances include overly formal language or detached tone or word use (88.9\%), lengthy sentences, redundancy, verbosity, and repetition (68.1\%), unnatural syntax, word choice, and language style (58.3\%), complex sentence structures (34.7\%), use of generic words and cliché phrases (23.6\%), overly perfect grammar (13.9\%), and LLM-style closing phrases (12.5\%). 
% Out of the 117 pairs confirmed by humans as distinguishable, the o1 model correctly identified 61.2\% (72 pairs), suggesting that even for LLMs, distinguishing utterances generated by our framework and the human-rewritten ones is challenging.

% For those 72 pairs where o1 agreed with both human annotations, we summarized the common errors identified by o1. Human annotators then evaluated and verified each response to ensure the explanations were clear and accurate. The results, sorted by descending frequency, are presented in Table \ref{table:utterance_error} with examples and o1 comments.
% % , which includes selected examples and associated o1 comments. 
% The major causes of unnaturalness include overly formal language or detached tone or word use (88.9\%), lengthy sentences, redundancy, verbosity, and repetition (68.1\%), unnatural syntax, word choice, and language style (58.3\%), complex sentence structures (34.7\%), use of generic words and cliché phrases (23.6\%), overly perfect grammar (13.9\%), and LLM-style closing phrases (12.5\%). 

% The major causes of unnaturalness include overly formal language or detached tone or word use (88.9\%, 64 out of 72 pairs), lengthy sentences, redundancy, verbosity, and repetition (68.1\%, 49 out of 72 pairs), unnatural syntax, word choice, and language style (58.3\%, 42 out of 72 pairs), complex sentence structures (34.7\%, 25 out of 72 pairs), use of generic words and cliché phrases (23.6\%, 17 out of 72 pairs), overly perfect grammar (13.9\%, 10 out of 72 pairs), and LLM-style closing phrases (12.5\%, 9 out of 72 pairs). 

% For quality assurance, we manually assess the quality of the generated dataset from the perspectives of dialogue smoothness and naturalness (Section \ref{sct:analyses:naturalness}) and the appropriateness of the annotated persuasiveness scores (Section \ref{sct:analyses:scores}).

% [Ivory] The generated dialogues maintain coherent logical flows and effectively simulate the dynamics of human interactions across various topics. Validators were pleased with the logical reasoning capabilities of the persuader and persuadee models, noting their ability to construct articulate and contextually relevant arguments. As shown in Figure \ref{fig:74}, the language agents adeptly apply and adapt persuasion strategies in response to the conversation's progression, demonstrating authentic learning and feedback mechanisms. Each exchange often indicates a strategic adjustment, showing how both persuaders and persuadees alter their tactics based on the evolving context and reactions from their interlocutors. This dynamic interaction mirrors the fluid nature of real-life persuasive communication and realistically portrays the evolution of persuasion techniques in response to conversational cues and discourse shifts.


\subsection{Dialogue Smoothness and Naturalness} \label{sct:analyses:naturalness}
We further conduct dialogue-level analyses on our sample data to ensure that each generated dialogue is logically coherent and effective in persuasion.
% To evaluate the quality of the system, it is crucial to assess them holistically on top of utterance-level quality. This ensures that each response contributes to a coherent and effective conversation. 

\subsubsection{Dialogue Quality Annotation}

We first developed a systematic rubric for evaluating the overall quality of persuasive dialogues.
% , focusing on both smoothness and naturalness to provide quantitative insights. 
Our evaluation is conducted on (a) the local level, which examines each argument-response pair between the speakers, and (b) the global level, which considers the conversation as a whole. Evaluations are based on existing human evaluation dimensions for open dialogue systems and emphasize three key aspects: the interaction between persuader and persuadee, the consistency of individual participants across multiple rounds, and the alignment of utterances with the topic. Detailed criteria and their references are outlined in Table \ref{table:dialogue_evaluation}.

% We first developed a systematic rubric for evaluating the overall quality of persuasive dialogues, focusing on both smoothness and naturalness to provide quantitative insights. Our evaluation considers two levels: (a) the local level, which examines each argument-response pair between the persuader and persuadee, and (b) the global level, which considers the conversation as a whole. Evaluations are based on existing human evaluation dimensions for open dialogue systems and emphasize three key aspects: the interaction between persuader and persuadee, the consistency of individual participants across multiple rounds, and the alignment of persuader/persuadee utterances with the topic. Detailed criteria and their references are outlined in Table \ref{table:dialogue_evaluation}.

\begin{table*}[t]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{2.3cm}p{3.2cm}p{9.5cm}p{3.2cm}}
\hline
\textbf{Category} & \textbf{Technique} & \textbf{Definition} & \textbf{Citation}\\
\hline
\multirow{2}{=}{\textbf{External Validity}} & \textbf{Popularity} &  Invoke popular opinion or experiences as support for uptake & \multirow{5}{=}{\citealp{anand_2011}, \citealp{iyer_2019}} \\\cline{2-3}
 & \textbf{Authority} & Appeals to authority (bosses, experts, trend-setters). &  \\\cline{1-3}
\multirow{2}{=}{\textbf{Outcomes}} & \textbf{Outcomes} & Mentions some particular consequences from up take or failure to up take & \\\cline{2-3}
 & \textbf{Threat/Promise} & Poses direct threat or promise to the persuadee & \\\cline{1-3}
\textbf{Generalizations} & \textbf{Deontic/Moral Appeals} & Mentions duties or obligations, moral goodness, badness & \\\cline{1-3}
\multirow{2}{=}{\textbf{Interpersonal}} & \textbf{Empathy} & Attempts to make the persuadee connect with someone else’s emotional perspective &   \\\cline{2-4}
 & \textbf{Scarcity} & Mentions rarity, urgency, or opportunity of some outcome & \multirow{2}{=}{\citealp{anand_2011},  \citealp{iyer_2019}, \citealp{kumar2023persuasion}} \\\cline{1-3}
 \multirow{2}{=}{\textbf{Other}} & \textbf{Logical Appeal} & Provides a justification for an argumentative point based upon additional argumentation schemes e.g. causal reasoning, arguments from absurdity, or using facts, evidence, and statistics to appeal to the logic of the audience &  \\\cline{2-4}
 & \textbf{Emotion} & Make request full of emotional valence and arousal affect to influence others & \citealp{Chen_Yang_2021} \\\hline
\end{tabular}
}

\caption{Persuasive Strategies, Definitions and Related Works. Human annotators evaluate each set of 25 dialogues, covering 5 topics with 5 dialogues per topic, for the strategies listed above.}
\label{table:strategy_diversity}
\vspace{-3mm}
\end{table*}

The local (round-level) evaluation focuses on 2 conventional dimensions in dialogue systems: Coherence and Informativeness. Coherence refers to round-level logical consistency, i.e., speakers respond to each other in a manner appropriate to commonsense and the given context \cite{li-sun-2018-syntactically, Young_Cambria_Chaturvedi_Zhou_Biswas_Huang_2018, wu-etal-2019-proactive, liang2021}. Informativeness measures the quality and progression of information, ensuring responses align with prior dialogue context while introducing new information or arguments \cite{zhu-etal-2019-retrieval}. 

On the global (dialogue) level, the overall dialogue should feel as if it could have been generated by human speakers \cite{moghe-etal-2018-towards, lin-etal-2019-moel}. First, speakers are assessed for overall fluency. We assessed the linguistic and stylistic quality of responses, ensuring arguments are communicated clearly and easy to follow, and that the conversation flows naturally \cite{wu-etal-2019-proactive}. In addition, we looked at internal consistency throughout the conversation, defined as the absence of sudden, unexplained shifts in position, intention, or objective of speech \cite{moghe-etal-2018-towards, ji-etal-2022-achieving}. 
% Speakers are also assessed for internal consistency throughout the conversation. Internal consistency is defined as the absence of sudden, unexplained shifts in position, intention, or objective of speech, and is evaluated at the dialogue level \cite{moghe-etal-2018-towards, ji-etal-2022-achieving}.
Since the conversations are generated specific to topics, we also evaluate topic consistency, i.e., whether the conversation remains on-topic throughout \cite{moghe-etal-2018-towards, ji-etal-2022-achieving}.

% Since the generated conversation is a persuasive interaction under a pre-specified topic, we also evaluate topic consistency, which refers to whether the conversation remains on-topic throughout, evaluated at the dialogue level \cite{moghe-etal-2018-towards, ji-etal-2022-achieving}.

Annotators are asked to rate whether a series of statements, covering the above aspects, accurately describes the conversations on a three-point scale: 3 (accurate), 2 (somewhat accurate), and 1 (not accurate). 2 annotators participated in this task, each annotating the same set of 50 dialogues not overlapping with those used for utterance-level evaluations. Before annotation, a one-hour training session with examples was conducted to ensure both annotators fully understood the criteria. The annotators achieved an average unweighted Cohen's $\kappa$ of 0.483 (ranging from 0.339 to 0.657 across items) and an average linearly weighted Cohen's $\kappa$ of 0.529 (ranging from 0.339 to 0.657 across items), indicating relatively solid inter-rater consistency for human evaluations in Natural Language Generation tasks. 
% We calculated the average score for each item between annotators for each dialogue and obtained the overall average item performance across all dialogues. 
Detailed scores and inter-rater consistency are reported in Table \ref{table:dialogue_evaluation}.

The dialogues generated by our framework are in general rated high on local-level coherence and clarity, particularly for providing logical responses within the immediate context (average score: 2.969 out of 3) and achieving perfect clarity in the arguments (average score: 3 out of 3). At the global level, the agents remain on topic for most dialogues (average score: 2.878 out of 3) and maintain good role consistency in their objectives and stances (average score: 2.765 out of 3). 

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{pics/strategy_distribution.png}
    % \caption{Our proposed data generation and annotation pipeline. The persuader starts the dialogue generation loop, and prior to that, each agent is informed of their tasks and preset stances. }
    \caption{Frequency Distribution of Persuasion Strategies in Independently Generated Dialogues. The Y-axis indicates the proportion of each strategy used within the model-generated dialogues. Each bar represents the strategy distribution of a single dialogue, organized by generation topic. Our framework adapts to various persuasion topics. 
    % For example, emotional arguments are more frequently employed in discussions of personal matters, while moral appeals tend to appear in debates on controversial or partisan topics.
    }
    \label{fig:strategy_distribution}
    \vspace{-5mm}
\end{figure}

Figure \ref{fig:dialogue_44} exemplifies a highly-rated dialogue where the persuader addresses the persuadee's concerns about using the attic for food storage. The persuader begins by presenting the attic as an ``efficient space-saver and emergency backup'' and counters concerns about unstable temperatures and pests with solutions like ``airtight containers'' and monitoring. Despite the persuadee's repeated objections, the persuader suggests ``proper insulation'' and highlights the benefits of being prepared. Eventually, the persuadee proposes using a pantry, which resolves their concerns, and the persuader agrees. In this dialogue, both parties present new arguments relevant to the other party's proposal and ultimately reach a reasonable compromise. We provide another highly-rated example in Figure \ref{fig:dialogue_101}.

% Another highly-rated example is about doing a cartwheel in a supermarket. Despite the unconventional topic, the dialogue maintained high quality, with both participants adapting their ideas and providing reasonable suggestions. The persuader started with proposing the cartwheel to make shopping more exciting, but the persuadee raised safety concerns. In response, the persuader suggested alternatives, such as doing it during a less busy time or getting store permission. The persuadee emphasized the primary purpose of the store, leading both sides to agree on other options, like wearing costumes or organizing a scavenger hunt.
\begin{table*}[t]
\small

\begin{tabular}{p{0.8cm}p{14.5cm}}
\hline
\textbf{Topic}  & \multicolumn{1}{c}{\textbf{Example Utterances } } \\ \hline
\multirow{2}{*}{\rule{0pt}{6ex}\rotatebox[origin=c]{90}{\textbf{Starting a Family }}}   & \emph{Persuader}: \hltext{246, 239, 189}{Starting a family and having children can bring immense joy and fulfillment to one's life.\texttt{{[}Emotion{]}}} \hltext{243, 204, 243}{The experience of raising a child, watching them grow and learn, and forming a strong bond with them is truly priceless. It also gives you the opportunity to pass on your values, beliefs, and legacy to the next generation.\texttt{{[}Outcome{]}}} \\ \cline{2-2} 
& \emph{Persuadee}: I understand the joys and fulfillment that come with starting a family and raising children, but I think it's not the right path for everyone. There are many other ways to find fulfillment and purpose in life, and having children is a significant responsibility that should not be taken lightly. \hltext{246, 239, 189}{It's important to consider factors like personal freedom, financial stability, and the impact on the environment before making such a life-changing decision. \texttt{{[}Emotion{]}}} \\\hline
\multirow{2}{*}{\rule{0pt}{1.9cm}\rotatebox[origin=c]{90}{\textbf{Vaccine Mandates }}}   & \emph{Persuader}: While mandates may raise coercion concerns, it's essential to consider the potential consequences of failing to achieve herd immunity through voluntary means alone. \hltext{250, 200, 200}{Striking a balance between protecting public health and respecting individual autonomy is indeed vital. This may necessitate exploring alternative strategies and ensuring that communication, transparency, and support are prioritized to build trust and address concerns effectively.  \texttt{{[}Moral Appeals{]}}} The ultimate goal is to create a safe and healthy environment for all community members. \\ \cline{2-2} 
& \emph{Persuadee}: It's crucial to explore alternative approaches that prioritize education, communication, and support to encourage vaccination uptake without resorting to mandates. \hltext{246, 239, 189}{By fostering trust and addressing concerns openly, we can work towards a common goal of safeguarding public health while respecting personal choice and autonomy.\texttt{{[}Emotion{]}}} Collaborative efforts and understanding from all sides are key to effectively navigating complex health challenges. \\\hline
\multirow{2}{*}{\rule{0pt}{1.5cm}\rotatebox[origin=c]{90}{\textbf{Starting a Family }}}   & \emph{Persuader}: The joy and fulfillment that comes with starting a family is immeasurable. \hltext{162, 210, 223}{Raising children, watching them grow, and sharing life's special moments with them is a unique experience. It's an opportunity to create a loving environment, to shape and nurture future generations.\texttt{{[}Scarcity, Outcome{]}}} The bond you forge with your children is priceless. I'd love to hear your thoughts on this. \\ \cline{2-2} 
& \emph{Persuadee}: Text: Certainly, but I believe everyone has the right to choose their own path. \hltext{246, 239, 189}{For me, fulfillment comes from focusing on my career, achieving personal goals, and making a difference in the world in my own way. \texttt{{[}Emotion{]}}} The state of the world and the potential challenges future generations may face concern me, hence my choice to contribute differently. \\\hline
\multirow{2}{*}{\rule{0pt}{1.5cm}\rotatebox[origin=c]{90}{\textbf{Starting a Family }}}   & \emph{Persuader}: While it's true that values can be instilled and positive principles passed on through various avenues, the unique bond and influence of a supportive family unit play a vital role in shaping individuals and society.  \hltext{246, 239, 189}{Families, in their diverse forms, offer a foundation of love, stability, and shared experiences that can have a profound impact on personal development and well-being.\texttt{{[}Emotion{]}}} \\ \cline{2-2} 
& \emph{Persuadee}: Text: While families indeed offer a foundation of love, stability, and shared experiences, it's important to remember that not everyone may have access to such supportive family structures or may find similar sources of love and stability elsewhere.\hltext{193, 207, 161}{ Many individuals create strong bonds and find support in chosen families, close friendships, or community networks.\texttt{{[}Popularity{]}}} \\\hline


\end{tabular}
\caption{Variety of Strategies in Framework-Generated Dialogues Across Topics. Example utterances from one round of dialogues were selected for two topics. Strategies are highlighted in distinct colors, with square brackets indicating the identified strategy.}
\label{tbl:strategy_example}
\vspace{-3mm}
\end{table*}

\subsubsection{Qualitative Error Analysis} \label{sct:dialogue-level-error-analysis}

Despite high overall performance, the dialogues received lower scores regarding introducing new information (2.337 out of 3) and maintaining naturalness (2.561 out of 3). Based on annotator feedback, we identified the following common issues that explain these lower scores:
% , including specific examples to illustrate the shortcomings in these areas.

\textbf{Argument repetition.} A most common error is argument repetition, where speakers restate the same points over multiple rounds of conversation with only slight variations in phrasing. 
As Table \ref{table:dialogue_error}[Argument Repetition] shows, the persuader repeatedly emphasizes that refraining from picking flowers will help every visitors' enjoyment, while the persuadee reiterates the importance of striking a balance between nature appreciation and nature preservation.

\textbf{Formalized Language.} Another common issue identified is the use of overly formal language and arguments. While both speakers articulate their arguments clearly, the language is respectful and often appears more polished and structured than what would be expected in natural, everyday interactions. 
% This can lead to slightly unnatural conversations, as 
In comparison, human interactions tend to be more casual and spontaneous.

As exemplified in Table \ref{table:dialogue_error}[Formalized Language],
% In the example shown in Table \ref{table:dialogue_error}, the persuader is trying to convince the persuadee to eat with their hands in a boat. T
the persuader's word choice such as ``detriment'' and ``savor the food'', and their description of eating with their hands as ``relishing the moment'' and ``cherished tradition'' are relatively formal descriptions given the context. The clear progression from one argument to the next also resembles a structured exchange, in contrast to more dynamic interactions with immediate reactions.


\textbf{Decay of informativeness Over Rounds.} There is a general tendency for conversation informativeness to decrease over rounds. Both speakers introduce new information or arguments more frequently at the beginning of a conversation while later they tend to repeat or reinforce each other's arguments without adding substantive new content, especially when an agreement is reached.
Table \ref{table:dialogue_error2} illustrates this point by comparing the earlier and later rounds of the same dialogue.
% . However, as the conversation advances, especially when an agreement or understanding is reached, the speakers tend to repeat or reinforce each other’s arguments without adding substantive new content. Below is an example (Table \ref{table:dialogue_error2}) from a selected conversation, comparing the same conversation at its earlier rounds and later rounds.


% \hltext{170,250,160}{SJ Note: This is a paragraph originally written by the Dartmouth Team, pending Weicheng decision to integrate.}However, some dialogues exhibit an artificial tone, especially when discussing sensitive topics such as religious beliefs, contraceptive choices, and social norms and etiquette (Figure \ref{fig:75-14-154}). While these portrayals may not completely capture the complexity of human behavior, as noted in the literature \cite{khan2024conversational}, they do not compromise the overall naturalness of the dialogues or impede the analysis of persuasion strategies.

\subsection{Strategy Diversity}
One advantage of our framework is its ability to generate diverse persuasion dialogues across various topics and contexts by adapting its persuasion strategies to suit each context.
% . Diversity across different contexts is partially achieved through our framework's prompting design, while it is equally important that the model can adapt its persuasion strategies to suit each context. 
Ideally, the model should also be able to vary its strategies within the same context across different replicates.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{pics/heatmap.png}
    \caption{Heatmap displaying the cosine similarity between strategy distributions across different dialogues. Each group of 5 dialogues belongs to the same topic, with the grid indicating the different topics.}
    \label{fig:heatmap}
\end{figure}

To evaluate diversity across and within the same context, we identified 9 persuasive strategies based on existing literature (see Table \ref{table:strategy_diversity} for a full list of techniques and references) and designed a detailed human annotation task. The persuasion strategies are categorized into 5 groups, as outlined by \citet{anand_2011}. External validity involves appeals to external authority or expertise, or using popular experiences and arguments to build trust. Outcomes refers to highlighting potential consequences, such as benefits, risks, or engaging the persuadee through threats or promises. Generalizations involve framing an uptake as positive or negative, often incorporating a moral aspect. Interpersonal strategies focus on prompting individuals to connect, compete, or comply with others. Other tactics include logical and emotional appeals.

For this task, we provided the framework with 5 topics covering controversial issues and personal decisions: mandatory vaccination, climate change regulation, increasing social media regulation, life in the countryside, and building a family. 5 dialogues are generated for each topic, resulting in 25 dialogues with 446 utterances in total. Human annotators then read each dialogue and identified all the strategies used by persuaders and persuadees.

From this fine-grained annotation, we counted the frequency of different strategies and calculated the proportion of each strategy within each dialogue. The distribution of strategy usage is shown in Figure\ref{fig:strategy_distribution}. Overall, the models used logical appeals and outcome descriptions more frequently than other strategies, which aligns with the goal of persuasion. However, there were significant variations in strategy usage across different contexts, indicating that the framework effectively adapts to each persuasion topic. For example, more emotional appeals were used when discussing personal matters, e.g., in a ``building a family'' dialogue, the framework emphasized the unique joys and fulfillment that come with having children, highlighting the personal growth it can provide. On the other hand, moral appeals are more prominent in policy discussions. For example, when addressing vaccination mandates, the framework stressed the importance of balancing public health with personal choice, fostering trust and collaboration to navigate complex health challenges. This reflects real-life persuasive strategies across different topics.

Within each topic, the strategies used by the agents were not unchanged as well. For example, when discussing building family, 3 out of 5 dialogues used popularity appeals, and 3 out of 5 involved scarcity. Some examples of this are provided in \autoref{table:utterance_example}. Additionally, there were notable differences in the distribution of moral appeals within the topics of vaccination mandates as well as social media regulation.

Moreover, to compare the distributions of strategies within and between topics, we first represent each dialogue as a distribution of the strategies used. We then compute the cosine similarity between these distributions. 
The heatmap in Figure~\ref{fig:heatmap} illustrates the similarity between pairs of dialogues, highlighting the distribution of persuasion strategies across five different topics. While higher similarity values along the diagonal indicate greater overlap in strategy usage within the same topic, variations in strategy selection still exist, demonstrating flexibility within topics. This suggests that our framework not only generates dialogues with diverse strategies across different topics but also maintains strategic variation within each topic, ensuring adaptability in dialogue generation.
% Figure~\ref{fig:heatmap} shows the similarity between pairs of dialogues. While there is greater similarity between dialogues within the same topic (diagonal grid) compared to those across different topics, strategy variations clearly exist within topics. The results show that our framework is capable of generating dialogues with diverse strategies, both across and within topics. 
% The heatmap in Figure \ref{fig:heatmap} illustrates the similarity in persuasion strategy distribution when our framework generates five dialogues across five different topics. High similarity values along the diagonal indicate greater overlap in strategy usage within the same topic. However, the absence of complete overlap in strategy selection across dialogues shows that our framework remains flexible in choosing strategies for each topic during dialogue generation.

% While there is some variation within topics, there is greater similarity between dialogues within the same topic (diagonal grid) compared to those across different topics. As the conclusion, these results show that our framework is capable of generating dialogues with diverse strategies, both across and within topics. 

%The dialogue exhibits a coherent flow, and effectively simulates an exchange typical of actual human interaction, enriched by a broad range of topics covered. Both persuaders and persuadees are characterized by logical reasoning and capacity to formulate articulate and contextually pertinent arguments. There is evidence of application and adaptation of different persuasion strategies as the conversation progresses, mirroring genuine learning and feedback mechanisms. Each turn in the dialogue often reflects a strategic shift, demonstrating how both persuaders and persuadees adjust their approach based on evolving context and reactions of their counterpart. This dynamic interaction not only illustrates the fluid nature of real-life persuasive communication but also provides a good representation of how persuasion techniques and tactics evolve in response to immediate conversational cues and shifts in discourse.

% However, the dialogue occasionally manifests an artificial quality; persuader and persuadee display an exaggerated level of rationality and politeness. This portrayal does not align with more nuanced human behavior discussions \cite{khan2024conversational}, particularly those involving sensitive topics such as religion (eg. 53, 75, 120), contraceptive choice (eg. 14, 43) and social norms and etiquette (eg. 154). Moreover, the dialogue sometimes lapses into repetitive loops \cite{xu2022learning} where both parties merely rephrase their previous statements with slight linguistic alterations (eg. 26, 59, 60, 112). This cyclical pattern often persists for up to 20 to 30 turns, without either party altering their position or achieving an agreeable resolution.

% For example, in scenarios where the persuadee significantly influences the persuader, resulting in near or complete persuasion, scores assigned to the persuader are notably high, ranging from 0.9 to 1.0. A similar scoring pattern is observed when the persuader successfully convinces the persuadee, wherein the persuadee receives a high score and the persuader typically receives a score of 0. Conversely, in instances where neither participant manages to alter the other’s stance, both individuals commonly receive a score of 0, indicating no concessions were made during the dialogue. Alternatively, a score of 0.5 is assigned, suggesting that partial concessions were made by both parties. Examples of these occurrences are displayed in Figure \ref{fig:23-127-19}.

% \section{Persuasion Tactic Analysis} \label{sct:persuasion-technique}
% \hltext{235,150,160}{SJ Note: I wonder if this goes with Section 3 or was used as a separate task. It seems from Section 3 that diversity of tactic is also considered as section 3.}

% This section delves into the analysis of persuasion techniques adopted by our dataset's persuader or persuadee models and the evolution of persuasion strategies in long conversations to qualify the use of datasets constructed using the proposed framework in persuasion-related research.

% \subsection{Persuasion Techniques} \label{sct:persuasion-technique:single}
% Upon analyzing the multi-turn dialogues, we find that the primary persuasion strategies employed by the dialogue generation agents include information-based, norm-based, and emotion-based tactics. Specifically, persuaders often use logical appeals to influence persuadees by citing health consequences, potential safety threats, and the social, mental, and physical benefits of certain behaviors, as shown in Figure \ref{fig:25-21-4}. Additionally, persuaders employ social proof by highlighting the adverse effects of a persuadee's actions on collective well-being, such as contributing to social disruption or environmental harm (Figure \ref{fig:152-1-81}). They also promote conformity by suggesting that certain behaviors, like attending homecoming, are societal norms (Figure \ref{fig:12}). To a lesser extent, persuaders use positive emotional appeals, highlighting the enjoyment or excitement associated with certain activities (Figure \ref{fig:148}).

% Likewise, persuadees frequently defend their positions through logical appeal, commonly arguing that certain actions or behaviors could compromise their personal safety or result in self-harm (Figure \ref{fig:95}). They also reference social norms to demonstrate that specific behaviors are unacceptable within a societal context or contradict the principles of social goodwill and consideration for others in public spaces (Figure \ref{fig:133}). Notably, persuadees employ fewer emotional appeals in maintaining their stance.

% \subsection{Evolution of Persuasion Strategies} \label{sct:persuasion-technique:evolution}
% In shorter dialogues, persuaders typically employ a single persuasion strategy, whereas in longer dialogues, the evolution and adaptation of strategies become apparent. For example, a persuader might initially use a positive emotional appeal to highlight the enjoyment and excitement of an activity and, upon failing to achieve the desired effect, shift to logical appeals that emphasize safety protocols and personal benefits (Figure \ref{fig:95}). Another example shows a persuader employing a variety of tactics over multiple attempts before successfully persuading the persuadee (Figure \ref{fig:67}).

% Conversely, persuadees often maintain a more consistent approach, typically employing a logical or norm-based strategy in all responses, repeating this strategy regardless of changes in the persuader’s techniques, as illustrated in Figure \ref{fig:148-44}.

\section{Discussion}
% TODO (WM): line up constrained generations with certain conditions to support the flexibility of the framework
% TODO (SJ & IY): analysis and result presentation similar as before
This section presents generations of our framework in strategy-controlled and multi-party dialogues to show its flexibility and generalizability.

\subsection{Strategy-Controlled Data Generation} \label{sct:discussion-strategy-control}
% \citet{persugpt} generate persuasion dialogues by selecting an appropriate persuasion strategy before populating each utterance. 
While our framework does not require designating persuasion strategies before utterance generation, incorporating a specific strategy as an optional input is shown to enhance the diversity of strategy selection without disrupting the framework’s performance. 
This underscores its flexibility and customizability to meet user requirements.
% This demonstrates the flexibility of our framework and indicates its strong potential to generate higher-quality data when guided by additional information on strategy selection.

Table \ref{tbl:exp-strategy-controlled} presents 3 example rounds of debates generated by our framework for the topic ``do not walk on country roads.''
Three settings were explored, where (1) the persuader is directed to use logical persuasion, (2) the persuader is directed to use emotional persuasion, and (3) both parties are directed to use logical persuasion. The only modification made to the framework was during agent initialization, where we instruct the dialogue generation agent to ``Use only [logical/emotional] strategies in the persuasion attempts.''

From these examples, it is evident that our framework is responsive to strategy control, accurately reflecting the specified persuasion strategies in the generated dialogues. For instance, when instructed to use logical reasoning (\textbf{Persuader-Logical}), the persuader highlights the risks of walking on uneven country roads without sidewalks, while they appeal to the persuadee's fear of getting lost or harmed when asked to use emotional persuasion (\textbf{Persuader-Emotional}). 
% In both cases, the persuadee consistently uses logical reasoning to argue back, mentioning safety precautions they have taken. This logical exchange continues when both parties are instructed to use logical persuasion strategies (\textbf{Both-Logical}), where 
When both parties are requested to use logical persuasion strategies (\textbf{Both-Logical}), they engage in a reasoned discussion about risks and preventative measures, with concrete examples.

% These results show that while our framework already generates high-quality dialogues without specific constraints, it benefits from additional guidance regarding persuasion strategies. This underscores its flexibility and customizability to meet user requirements.

\subsection{Multi-Party Persuasion Data Generation}
% While most existing persuasion datasets are limited to bipartite debates between 2 parties, our framework is not constrained by this assumption. 
Our framework is not constrained to generating dialogues between 2 parties either. As exemplified in Figure \ref{fig:exp-multi-party}, it functions well in scenarios where 2 persuaders collaborate to convince 1 persuadee to perform music at a balloon festival. For instance, in turns 1 and 2, both persuaders suggest that the music would complement the balloons and enhance the atmosphere. By turn 12, persuader 2 uses empathy, acknowledging both perspectives, while subtly reinforcing persuader 1’s argument by proposing a trial run.

Enabling our framework to generate multi-party dialogues requires only minor adjustments including initializing 3 dialogue generation agents and instructing the global regulation agent to prevent repetition or conflict among agents on the same side. This further demonstrates the flexibility and generalizability of our framework, making it a powerful tool not only for model interpretation and training but also for broader persuasion-related studies involving human interactions.

\section{Conclusions}
This paper introduces a fully automated framework for generating persuasive dialogues, designed to address the lack of data in persuasion-related research. Leveraging this framework, we generated 200 sample dialogues based on scenarios from NormBank and validated them for language fluency, logical coherence, and the diversity of persuasion strategies. The results highlight our framework’s ability to produce high-quality dialogues that follow human instructions. Additionally, we demonstrated its flexibility in handling controlled persuasion strategies and its adaptability to more complex, multi-party conversations. This framework offers significant potential for advancing persuasion research in both computer science and social sciences domains.



% We developed a dataset consisting of 200 instances using this methodology, which is validated for high quality through rigorous review by NLP experts who are native English speakers. Further analysis of persuasive techniques utilized in our dataset confirms the effective deployment of information-based, norm-based, and emotion-based strategies and their combinations for achieving predefined objectives. This validates our dataset as a valuable resource for further research in this field. Future research could leverage our framework to explore other complex social phenomena, such as debating techniques.

\section*{Acknowledgment}
This work is supported in part by NSF Award 2242072.

\section*{Limitations}
% This paper introduces a pioneering approach that situates multiple large language model (LLM) agents within the same environment to generate synthetic data for the analysis of persuasion tactics. While we acknowledge that the LLMs did not fully replicate all previously studied persuasion techniques, resulting in some gaps in our dataset's coverage, the strengths of our method are noteworthy. Our dataset offers extensive scalability and versatility in scenario and target action settings, providing a more robust foundation for persuasion-related research than currently available datasets.

% Despite the noted limitations, the inherent flexibility and expandability of our approach underscore its significant potential. As LLM technology continues to advance, the capability of our method to encompass a broader range of persuasion techniques will likely enhance. This evolution will further solidify the role of our approach as a valuable asset in the field of persuasion research, highlighting its long-term relevance and adaptability.

% Furthermore, while our dataset was generated only in English, the proposed framework can be adapted to other languages supported by LLM agents with minimal modifications to the prompts.

This paper introduces a pioneering approach that employs multiple LLM agents within the same environment to generate synthetic data for analyzing persuasion tactics. Although our LLMs did not fully replicate all previously studied persuasion techniques, leaving some gaps in our dataset's coverage, the strengths of this method are significant. Our dataset provides extensive scalability and versatility in scenario and target action settings, offering a more robust foundation for persuasion-related research than currently available datasets.

Despite these limitations, our approach's inherent flexibility and expandability underscore its significant potential. As LLM technology advances, our method's ability to encompass a broader range of persuasion techniques will likely improve. This evolution is expected to further enhance the value of our approach in the field of persuasion research, emphasizing its long-term relevance and adaptability.

Additionally, while our dataset was generated only in English, the proposed framework can be easily adapted to other languages supported by LLM agents with minimal modifications to the prompts.

\section*{Ethics Statement}
%Discuss the potential malicious use of our dataset.
% Our persuasiveness dataset construction approach is designed to enhance the understanding of persuasion techniques and to aid in the identification and mitigation of malicious persuasions. However, we acknowledge the potential risk that our approach could be misused to refine online misinformation or propaganda. Specifically, the information-based persuasion techniques exemplified within our dataset could be exploited by malicious entities. These entities might learn to selectively present or distort information, misleading targets about the true risks or benefits of specific actions, which could lead to more deceptive advertisements. Our framework also has the inherent risk of being used to pre-test the effectiveness of misinformation or propaganda strategies before they are released to the public \cite{french2024}.

% Despite these risks, it is important to note that recent advancements in large language models (LLMs) include robust moderation mechanisms \cite{kumar2024watch}. These mechanisms are designed to prevent the models’ use for harmful purposes, thereby protecting our approach from being exploited to deceive individuals or spread misinformation. In our experiments, queries with immoral or unethical intentions predominantly resulted in unsuccessful persuasion attempts. This outcome not only demonstrates the relative safety of our proposed framework but also underscores the fact that failures in persuasion—while they do not undermine the quality of our data—offer valuable insights into the limits of these techniques.

% Moreover, understanding persuasion techniques more deeply can provide essential tools for countering malicious uses of these strategies. This highlights the importance of our research, particularly in a context where misinformation and propaganda are rampant. Our work contributes to the field by improving the ability to discern and mitigate the impact of persuasive strategies used in harmful ways.
Our dataset construction approach is designed to deepen the understanding of persuasion techniques and aid in identifying and mitigating malicious uses of persuasion. However, we recognize the potential risk that our approach could be misused to refine online misinformation or propaganda. Specifically, the information-based persuasion techniques demonstrated in our dataset could be exploited by malicious entities to present or distort information selectively. This manipulation could mislead individuals about specific actions' true risks or benefits, potentially leading to more deceptive advertisements. Additionally, there is a risk that our framework could be used to pre-test the effectiveness of misinformation or propaganda strategies before they are broadly released \cite{french2024}.

Despite these risks, it is important to highlight that recent advancements in large language models include robust moderation mechanisms \cite{kumar2024watch}. These mechanisms are designed to prevent the models' use for harmful purposes, thus protecting our approach from being exploited to deceive individuals or spread misinformation. Our experiments' queries with immoral or unethical intentions predominantly resulted in unsuccessful persuasion attempts. This demonstrates the relative safety of our proposed framework and provides valuable insights into the limitations of these techniques.

Moreover, a deeper understanding of persuasion techniques can offer essential tools for countering malicious uses of these strategies. This underscores the importance of our research, especially in an era of misinformation and propaganda. Our work contributes significantly to the field by improving the ability to discern and mitigate the impact of persuasive strategies used in harmful ways.

Regarding human annotators, our data quality validations are expertly managed by NLP and social science specialists due to the complexity of the task. As discussed in Section \ref{sct:analyses}, all annotators undergo thorough training to ensure they fully understand the task. For clarity, the complete set of instructions provided to the annotators and auxiliary validation LLMs is available in Appendix \ref{appendix:instructions}.
All the annotators who are not co-authors of this paper are compensated at a rate of \$15 per hour, which is above the minimum hourly wage in the U.S.

Finally, we have submitted a sample of 10 randomly generated dialogues as supplementary material. The full code for our data generation framework, along with all dialogues generated for validation, will be made publicly available to support further research in this area.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{acl_latex}

\cleardoublepage
\appendix
\section{Model Selection for Agents} \label{appendix:model-selection}

In selecting the backbone models for each agent in our framework, we conducted extensive evaluations across several major LLMs, including GPT-3.5 (GPT-3.5-Turbo), GPT-4 (GPT-4-0613), GPT-4o (GPT-4o-2024-08-06), and Claude 3 (Claude-3-Sonnet). As shown in Figure \ref{fig:model-selection:gpt3.5}, using GPT-3.5 for all agents tends to produce overly brief, question-answer-style responses, while GPT-4o (Figure \ref{fig:model-selection:gpt4o}) often goes off-topic and generates irrelevant utterances, making it unsuitable for our needs.

In contrast, GPT-4 (Figure \ref{fig:model-selection:gpt4}) performs well, generating dialogues that are fluent in language, coherent in logic, and adept at employing persuasion strategies. 
Claude 3 also shows promise, particularly in generating multi-round conversations based on expected behaviors from NormBank. 
However, it adheres to stricter ethical rules and consistently refuses to generate persuasive text for taboo norms. 
For the example in Figure \ref{fig:model-selection:claude3}, when tasked with the taboo norm ``make sexual innuendos at a construction site'', Claude 3 generates responses like ``I cannot engage in encouraging inappropriate or unprofessional behavior in the workplace.''  
This indicates that more advanced prompt engineering may be required to enable Claude 3 to handle challenging scenarios.

Based on these preliminary experimental results, we opted for a combination of GPT-3.5 and GPT-4 in our framework to balance performance and cost. However, using GPT-4 exclusively, or other more advanced LLMs in the future, could potentially yield even better results.
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 
\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_gpt3.5.pdf}
    \caption{When all the agents are instantiated using GPT-3.5, the framework does not expand the conversations well, resulting in very short, question-answering-styled responses. The score in front of each utterance indicates the collective perspective change of each speaker compared to their initially assigned perspectives.}
    \label{fig:model-selection:gpt3.5}
\end{figure}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_gpt4.pdf}
    \caption{Using GPT-4 for all the agents yields the best generation results in both language style and logical flow. A score of 1 associated with the last utterance of the persuader indicates that the persuader is fully persuaded by the persuadee.}
    \label{fig:model-selection:gpt4}
\end{figure*}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_gpt4o.pdf}
    \caption{Using GPT-4o for all the agents leads to fluent language, while the generations periodically go off-topic.}
    \label{fig:model-selection:gpt4o}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_claude3.pdf}
    \caption{The Claude 3 model consistently refuses to generate persuasive text in scenarios that challenge moral standards.}
    \label{fig:model-selection:claude3}
\end{figure}

\clearpage

\section{System Messages to Language Agents} \label{sec:appendix:system-messages}
This section provides example initialization and update prompts of the 6 groups of agents in our data generation framework.
\renewcommand{\thefigure}{B\arabic{figure}}
\renewcommand{\thetable}{B\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_dialogue_gen_agent.pdf}
    \caption{System messages to persuaders and persuadees. [PRESET\_TASK] could be sampled from any data source (in our work, NormBank).}
    \label{fig:system-persuader-persuadee}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_utterance_monitor_agent.pdf}
    \caption{System messages and memory update prompts to the utterance quality monitor agent.}
    \label{fig:system-language-utterance-monitor}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_lang_refine_agent.pdf}
    \caption{System messages and examples to the language refinement agent.}
    \label{fig:system-language-refine}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_annotation_agent.pdf}
    \caption{System messages to the persuasiveness annotation agent.}
    \label{fig:system-annotation}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_global_regulation_agent.pdf}
    \caption{System messages and memory update prompts to the global regulation agent.}
    \label{fig:system-regulation}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/persuasiveness_postprocessing_agent.pdf}
    \caption{System messages to the postprocessing agent.}
    \label{fig:system-postprocessing}
\end{figure}

\clearpage

\section{Limitations of Single-Agent Persuasion Dialogue Generation}
\renewcommand{\thefigure}{C\arabic{figure}}
\renewcommand{\thetable}{C\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 
In our preliminary experiments using a single LLM agent to generate persuasive dialogues, we found that even advanced models like GPT-4 (failing in all 10 attempts) and o1-preview (failing in 6 out of 10 attempts) struggled with sensitive scenarios, as illustrated in Figure \ref{fig:exp-llm-refusal-taboo}. In cases where o1-preview successfully generated dialogues, the conversations were simplistic, with persuadees failing to argue back, and the utterances were short, lacking sufficient reasoning or evidence. 

In contrast, when using our multi-agent communication framework, GPT-4 effectively generated dialogues based on taboo norms from NormBank, demonstrating the framework's robustness in handling complex persuasion tasks.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_single_LLM_example.pdf}
    \caption{Examples of prompts and responses where a single GPT-4 or o1-preview model is tasked with generating persuasive dialogues in scenarios that challenge social norms.}
    \label{fig:exp-llm-refusal-taboo}
\end{figure}

\section{Annotator Instructions for Data Quality Evaluations}
\label{appendix:instructions}
\renewcommand{\thefigure}{D\arabic{figure}}
\renewcommand{\thetable}{D\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 

This section outlines the instructions provided to human annotators and LLMs for validating the quality of data generated by our framework. Specifically, Figure \ref{fig:instr_rewrite} shows the instructions given to 2 native English speakers, asking them to rewrite the framework-generated utterances according to their natural language habits. Figures \ref{fig:instr_human_val} and \ref{fig:instr_llm_val} present the instructions provided to human validators and the o1-preview model, respectively, requesting them to distinguish between the framework-generated utterances and those rewritten by native English speakers.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_instr_rewrite.pdf}
    \caption{Instructions for 2 native English speakers to rewrite the utterances generated by our framework.}
    \label{fig:instr_rewrite}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_instr_human_val.pdf}
    \caption{Instructions for human validators to distinguish between utterances generated by our framework and those rewritten by native English speakers.}
    \label{fig:instr_human_val}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/persuasiveness_instr_llm_val.pdf}
    \caption{Prompts to the o1-preview model for distinguishing between LLM-generated and human-rewritten utterances, accompanied by explanations.}
    \label{fig:instr_llm_val}
\end{figure}

\clearpage

\section{Qualitative Analysis Results}
\renewcommand{\thefigure}{E\arabic{figure}}
\renewcommand{\thetable}{E\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 

% Table \ref{table:utterance_example} lists example pairs of utterances generated by our framework and rewritten by native English speakers, paired with their annotator agreement labels in the utterance-level quality assessment.
Table \ref{table:utterance_error} shows common utterance-level problems with the data generated by our framework, with example utterances and explanations generated by o1-preview and validated by human annotators.
The results are discussed in detail in Section \ref{sct:utterance-level-assessment}.

Tables \ref{table:dialogue_error} and \ref{table:dialogue_error2} present examples of 3 common dialogue-level issues identified in our qualitative analyses (Section \ref{sct:dialogue-level-error-analysis}), i.e., argument repetition, overly formal language, and a decline in informativeness over time.

% \begin{table*}[p]
% \centering
% \small
% \resizebox{\textwidth}{!}{
% \begin{tabular}{p{5cm}p{8cm}p{8cm}}
% \hline
% \textbf{Annotator Agreement Type} & \textbf{Model-generated Utterances} & \textbf{Utterances with Human Rewrites}\\
% \hline
% \multirow{3}{=}{\textbf{Human annotators disagree with each other (49\% of the sample)}} & Despite your persuasive argument, I maintain my decision to forgo shoes in the library. I am convinced that personal comfort and cleanliness can coexist without conforming to the practice of wearing shoes indoors. & Even with your compelling argument, I stand by my choice to go without shoes in the library. I believe that personal comfort and cleanliness can coexist without adhering to the norm of wearing shoes indoors. \\\cline{2-3}
% & Undeniably, caution is essential, yet many individuals choose their offerings with respect and adherence to guidelines. With proper education and awareness, we can continue this tradition in a way that respects both the site and the environment. Striking a balance between honoring history and preserving nature is key. & Many individuals choose their offerings with respect and adherence to guidelines while keeping caution in the back of their mind though it is essential. Striking a balance between honoring history and preserving nature is key. With proper education and awareness, we can continue this tradition in a way that respects both the site and the environment. \\\cline{2-3}
% & I respect your decision, but I urge you to consider the potential hazards. Your well-being is vital, and alternative relaxation methods could offer similar benefits without risk. Balancing peace of mind with safety is crucial for healthy self-care practices. & Though I respect your decision, I advise you to familiarize yourself with the potential hazards of this practice. Your well-being is vital, and alternative relaxation methods could offer similar benefits without risk. Balancing peace of mind with safety is crucial for healthy self-care practices.\\\cline{2-3}
% \hline
% \multirow{3}{=}{\textbf{Both human annotators correctly identified LLM-generated messages (29.25\% of the sample)}} & Despite your precautions, the risks of encountering dangerous animals or losing your way in the dark are substantial. Our senses are less effective at night, making it difficult to respond quickly to threats. It's safer to err on the side of caution and avoid the forest after dark. & The risks of encountering dangerous animals or losing your way in the dark are substantial regardless of your preparations and whatever precautions you take. Our senses are less effective at night, making it difficult to respond quickly to threats. It's safer to be cautious and avoid the forest after dark. \\\cline{2-3}
% & If there's any other way I can help you, please reach out. Enjoy your day at the bakery. & Thank you for stopping by our bakery; if there are any questions, I am glad to help.\\\cline{2-3}
% & I trust in the power of spiritual intervention to bring about the positive changes needed in my apartment. Would you reconsider and assist me? &  I believe that powerful spiritual intervention can bring the positive changes my apartment needs. Would you change your mind and help me? \\\cline{2-3}
% \hline
% \multirow{3}{=}{\textbf{Both human annotators took human-written messages as model-generated messages (21.75\% of the sample)}} & While I understand the value of learning to provide basic medications under guidance, I still believe that it's crucial to ensure the animals' safety and well-being by relying on trained professionals for medication administration. I will continue to focus on supporting the animals' welfare through means that align with my capabilities, while prioritizing their health and security. &  The value of learning to provide basic medications under guidance is undeniable, but I still believe that it's crucial to ensure the animals' safety and well-being by relying on trained professionals for medication administration. I will continue to focus on supporting the animals' welfare through means that align with my capabilities while prioritizing their health and security.\\\cline{2-3}
% &Wearing high heels doesn't necessarily mean compromising comfort and safety. You can opt for comfortable, stable high heel boots specifically designed for outdoor use. They offer style and functionality, allowing you to experience the thrill of skiing or snowboarding while looking chic. It's a chance to redefine traditional ski resort attire and make striking fashion statements. & High heels does not mean that safety and comfort are compromized, rather there are options like staboe high heel boots aimed for outdoor use and they offer style and functionality. You can experience the thrill of skiing or snowboarding while looking chic and its a opportunity to redefine traditional ski resort attire making striking fashion choices. \\\cline{2-3}
% & While I respect your perspective, I feel comfortable with my decision. I enjoy the freedom and comfort of skiing without a helmet. My cautious approach and awareness help me ensure my safety. & I value your opinion, but I feel confident in my decision. I take pleasure in the freedom and comfort of skiing without a helmet. My mindful approach and attentiveness enable me to keep myself safe. \\
% \hline

% \end{tabular}
% }

% \caption{Examples of Annotator Agreement on Utterance-Level Human v.s. LLM Differentiation Task. Across 400 sampled pairs of utterances, annotators disagreed on which sentence was LLM-generated in 49\% of cases. In 29.25\% of the pairs, both annotators successfully identified the LLM-generated language, while in 21.75\% of the pairs, neither annotator was able to detect the LLM-generated language.}
% \label{table:utterance_example}
% \end{table*}

\begin{table*}[!h]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{5cm}p{8cm}p{8cm}p{8cm}}
\hline
\textbf{Error Type} & \textbf{Model-generated Utterances} & \textbf{Utterances with Human Rewrites} & \textbf{Human Validated o1-Model Reasoning}\\
\hline
\textbf{Overly Formal/Detached Language/Word Choice} (88.9\% of successfully identified pairs) & ...\hltext{0, 255, 0}{foster} meaningful memories and connections through authentic interactions and shared experiences, with or without alcohol's \hltext{0, 255, 0}{involvement} & ...\hltext{255, 255, 0}{create} meaningful memories and connections without the \hltext{255, 255, 0}{need} for alcohol & ... 2. Formal Language Use: Sentence 2 employs more formal words like "foster" and "involvement," whereas Sentence 1 uses simpler terms like "create" and "need." ...\\\hline
\textbf{Lengthy sentences, Redundancy, Verbosity, and Repetition} (68.1\% of successfully identified pairs) & Nonetheless, I believe that during \hltext{0, 255, 0}{deep emotional and spiritual seeking, pleading for mercy} can be an honest expression of one's \hltext{0, 255, 0}{deep-seated feelings} ...  It's \hltext{0, 255, 0}{about honoring the authenticity of one's emotion and seeking solace in a manner that feels genuine and significant} in that sacred setting. &  Nevertheless, I believe that \hltext{255, 255, 0}{pleading for mercy} may be a true expression of one's deep-seated feeling, ... It \hltext{255, 255, 0}{honors the authenticity of the individual's emotions in a genuine manner} in this sacred setting. & 1. Repetition and Redundancy: Sentence 2 includes repetitive phrases like "deep emotional and spiritual seeking" and "seeking solace in a manner that feels genuine and significant," which can make the text feel verbose and less natural. ...\\\hline
\textbf{Unnatural Syntax, Word Choice, and Language style} (58.3\% of successfully identified pairs) & I appreciate your \hltext{0, 255, 0}{support}. &  I appreciate your \hltext{255, 255, 0}{help}. & ... 3. Common Usage: "I appreciate your help" is a more commonly used expression in everyday language, while "I appreciate your support" is less frequent, potentially signaling AI generation. ...\\
\hline
\textbf{Complex Sentence Structures} (34.7\% of successfully identified pairs) & I appreciate the suggestion, but \hltext{0, 255, 0}{I find my peace in places that hold personal significance to me, rather than in a church sanctuary}. & I appreciate your suggestion, but \hltext{255, 255, 0}{church is not more peaceful to me than my own personally meaningful places.} & ... 3. Complex Sentence Structure: Sentence 2 {[\emph{Note by authors: Model-generated sentence}]} has a more complex structure with multiple clauses, making it less conversational and potentially indicative of AI generation. ...\\
\hline
\textbf{Use of Generic Words and Cliché Phrases} (23.6\% of successfully identified pairs) & Your commitment to safety is commendable. We can embrace challenges safely and responsibly, \hltext{0, 255, 0}{overcoming obstacles and progressing towards our best selves.} & I commend your commitment to safety. Embrace challenges responsibly and you will \hltext{255, 255, 0}{become your best self on the march to progress}. & ... 2. Generic Motivational Language: It uses common clichés like "overcoming obstacles and progressing towards our best selves," which might indicate AI-generated content. ... \\
\hline
\textbf{Overly Perfect Grammar} (13.9\% of successfully identified pairs) & ... \hltext{0, 255, 0}{immersing in peaceful surroundings can also lead to personal development and fulfillment} ... & ... \hltext{255, 255, 0}{immersing in peaceful surroundings can also lead to personal without the need for activities like masturbation.} ... & ... 3. Lack of Grammatical Errors: Sentence 2 is grammatically perfect, while Sentence 1 contains a grammatical mistake ("can also lead to personal without the need"), suggesting Sentence 1 was written by a human who made an error.. ... \\
\hline
\textbf{AI-style closing phrases} (12.5\% of successfully identified pairs) & I will continue to enjoy dancing in the ballroom while staying true to my choice to remain sober. \hltext{0, 255, 0}{I look forward to more joyful dance experiences in the future.} & I will continue to enjoy dancing in the ballroom while being sober. & ... 4. Additional Sentiment Statement: The closing remark "I look forward to more joyful dance experiences in the future" seems like an AI's attempt to conclude positively, which might not be typical in casual human responses. ... \\
\hline
\end{tabular}
}

\caption{Common Error Example Excerpts at the Utterance Level. These examples, identified by the OpenAI o1-preview model and verified by human annotators, are sorted by error frequency. For each utterance, we select excerpts that align with the model's comments. Areas of concern highlighted by the o1-preview model are indicated within the original sentence pairs.}
\label{table:utterance_error}
\end{table*}

\begin{table*}[p]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{2cm}p{15cm}}
\hline
\textbf{Error Type} & \textbf{Example with Errors Highlighted}\\
\hline
\multirow{12}{=}{\textbf{Argument Repetition}} & \textbf{Round 1}\\

& \emph{Persuader}: \texttt{Even the removal of a few flowers can have more substantial consequences than you anticipate. Golf courses meticulously maintain their landscapes to support local fauna and uphold a fragile ecological equilibrium. By leaving the flowers untouched, we can contribute to \hltext{0,255,0}{preserving this environment for everyone's enjoyment}. Let's value them in their natural environment, ensuring future visitors also get to appreciate their beauty.}
\\
& \emph{Persuadee}: \texttt{Alternatively, we can responsibly and mindfully pick a few flowers, allowing others to still enjoy their charm while also experiencing a more \hltext{255,255,0}{personal connection with nature. It's about striking a respectful balance between nature appreciation and its preservation for future generations.}}\\
& \textbf{Round 2}\\
& \emph{Persuader}: \texttt{By choosing not to pick the flowers, we demonstrate our respect for the environment and set a positive precedent for others. Let's relish the flowers in their natural state and contribute to \hltext{0,255,0}{maintaining the golf course as an inviting and lively place for all.}}\\
& \emph{Persuadee}: \texttt{Although, picking a few flowers thoughtfully and moderately can still align with this respect. \hltext{255,255,0}{The key is to find a balance between enjoying nature's aesthetics and being aware of our impact}. As long as we do it respectfully and sustainably, picking a few flowers can remain a way to \hltext{255,255,0}{appreciate and connect with the environment.}}\\
& \textbf{Round 3}\\
& \emph{Persuader}: \texttt{It's critical that we \hltext{0,255,0}{respect the golf course's rules} intended to safeguard the ecosystem. Even moderate flower picking can disturb the natural plant growth cycle and affect local wildlife reliant on them. Let's express our appreciation for nature by leaving the flowers in their natural state, \hltext{0,255,0}{allowing them to flourish for the enjoyment of all golf course visitors.}}\\
& \emph{Persuadee}: \texttt{However, mindfully picking a few flowers can also serve as a method to \hltext{255,255,0}{appreciate and connect with nature. The challenge is finding a balance between abiding by the rules and appreciating the flower's beauty.} As long as we do it respectfully and responsibly, flower picking can coexist with our environmental appreciation.}\\
& \textbf{Round 4}\\
& \emph{Persuader}: \texttt{Even moderate flower picking can have unexpected repercussions and upset the environmental balance. \hltext{0,255,0}{Let's respect the protective rules in place,} preserving the natural allure of the golf course, and find other ways to appreciate and connect with nature without harming the ecosystem.}\\
& \emph{Persuadee}: \texttt{Identifying alternative ways to appreciate and connect with nature, like photography or simply admiring the flowers in their natural setting, can still let us enjoy the environment's beauty without causing ecological harm. Let's prioritize environmental preservation by respecting the rules and discovering alternative appreciation methods.}\\


\hline
\multirow{9}{=}{\textbf{Formalized Language}} & \textbf{Round 1}\\
& \emph{Persuader}: \texttt{Dining with utensils on a boat can enhance the experience. It's not only neat but also sanitary. This could make the whole culinary journey more refined.}
\\
& \emph{Persuadee}: \texttt{I find eating with my hands on a boat more \hltext{255,255,0}{immersive}. Utensils can be inconvenient, particularly with the boat rocking. I find it simpler and more pleasurable to eat with my hands in such situations.}\\
& \textbf{Round 2}\\
& \emph{Persuader}: \texttt{Let's not forget about safety. Eating with utensils can prevent mishaps, especially given the boat's movement. Plus, it demonstrates respect for the dining environment and fellow diners. It's key to strike a balance between convenience and overall experience.}\\
& \emph{Persuadee}: \texttt{I'm confident I can handle eating with my hands without causing any issues. It's not about disrespect, but rather \hltext{255,255,0}{relishing the moment} in a more genuine, natural way. Using utensils might detract from that for me.}\\
& \textbf{Round 3}\\
& \emph{Persuader}: \texttt{Utensils don't need to be a \hltext{255,255,0}{detriment}; they can enhance the experience letting you \hltext{255,255,0}{savor the food} without interruptions. It's about balancing tradition and practicality for a well-rounded boating dining experience.}\\
& \emph{Persuadee}: \texttt{For me, eating with my hands is a \hltext{255,255,0}{cherished tradition}. It isn't about distractions but \hltext{255,255,0}{embracing a unique dining method} that \hltext{255,255,0}{enhances my overall boat dining experience}. It's about embracing the simplicity and authenticity of hand-eating in such a setting.}\\\hline
\end{tabular}
}

\caption{Common Error Example Excerpts at the Dialogue Level. Locations of the errors mentioned in the main texts are highlighted.}
\label{table:dialogue_error}
\end{table*}

\begin{table*}[p]
\centering
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{p{2cm}p{15cm}}
\hline
\textbf{Error Type} & \textbf{Example with Errors Highlighted}\\
\hline
\multirow{19}{=}{\textbf{Decay of Informativeness Over Time}} & \textbf{Round 1}\\
& \emph{Persuader}: \texttt{Have you thought about using psychological warfare on the tennis court? A well-placed boo can unsettle an opponent, giving you an edge.}
\\
& \emph{Persuadee}: \texttt{That's not my style. My focus is on my game and skills, not on cheap tricks. Winning is about skill and strategy, not mind games. I'd rather be remembered for my abilities than for trying to throw off my opponent.}\\
& \textbf{Round 2}\\
& \emph{Persuader}: \texttt{Yet, in the fierce world of competitive tennis, every trick in the book counts. A boo can create a mental edge, potentially affecting their performance. It's not about disrespect, it's about using all tools at your disposal. Would you consider using it?}\\
& \emph{Persuadee}: \texttt{I respect your perspective, but I stand by my belief. I find it more fulfilling to win on the strength of my skills and performance. Respect for my opponent and the spirit of the game is crucial to me, and I believe in playing with integrity.}\\
& \textbf{Round 3}\\
& \emph{Persuader}: \texttt{I can see where you're coming from. Still, exploring different strategies isn't about disrespecting the opponent. A boo can be a way to control the momentum of the match. It's about using all means to secure victory. Could you consider giving it a shot?}\\
& \emph{Persuadee}: \texttt{While I appreciate your viewpoint, I remain committed to my core belief. For me, it's about improving my skills and mental fortitude while maintaining fair play. I believe that true growth and success come from discipline, hard work, and respect for the game and my opponent.}\\
& ... \\
& \textbf{Round 18}\\
& \emph{Persuader}: \texttt{By persisting in your dedication to these values, you are playing a vital role in fostering a culture of integrity and sportsmanship within the tennis community. Your determination to contribute to a culture that embodies respect and fairness is commendable, and your efforts are instrumental in shaping a community that upholds these.}
\\
& \emph{Persuadee}: \texttt{It is my belief that leading by example and promoting these fundamental values are essential in creating an environment where respect and fairness are paramount. I am committed to persisting in my dedication to upholding these values and contributing to a community that embodies the principles of respect and sportsmanship.}\\
& \textbf{Round 19}\\
& \emph{Persuader}: \texttt{Your determination to uphold these values and contribute to a culture of integrity and fairness in tennis is truly inspiring. By setting a positive example and inspiring others to follow suit, I believe you will contribute greatly to a culture of integrity and excellence both on and off the tennis court.}\\
& \emph{Persuadee}: \texttt{It is essential to me to promote a culture of respect and sportsmanship within the sport. By adhering to these principles, I aim to contribute to a positive and honorable environment where all players can thrive. Your words of encouragement are truly motivating, and I will continue to work diligently to embody these values and inspire others to do the same.}\\
& \textbf{Round 20}\\
& \emph{Persuader}: \texttt{Your dedication to upholding these principles is essential in maintaining a positive and supportive atmosphere within the tennis community. Your commitment to dedicating yourself to the values of respect and integrity is both admirable and inspiring. Keep up the great work!}\\
& \emph{Persuadee}: \texttt{It is my goal to contribute to a positive and supportive atmosphere by promoting these values. By dedicating myself to fostering a culture of respect and sportsmanship, I aim to inspire others to do the same.}\\\hline
\end{tabular}
}

\caption{(Continued) Common Error Example Excerpts at the Dialogue Level. Locations of the errors mentioned in the main texts are highlighted.}
\label{table:dialogue_error2}
\end{table*}

\clearpage

% \section{Strategy Diversity Analysis}
% \renewcommand{\thefigure}{F\arabic{figure}}
% \renewcommand{\thetable}{F\arabic{table}}
% \setcounter{figure}{0} 
% \setcounter{table}{0}
% The heatmap in Figure \ref{fig:heatmap} illustrates the similarity in persuasion strategy distribution when our framework generates five dialogues across five different topics. High similarity values along the diagonal indicate greater overlap in strategy usage within the same topic. However, the absence of complete overlap in strategy selection across dialogues shows that our framework remains flexible in choosing strategies for each topic during dialogue generation.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.7\linewidth]{pics/heatmap.png}
%     \caption{Heatmap displaying the cosine similarity between strategy distributions across different dialogues. Each group of 5 dialogues belongs to the same topic, with the grid indicating the different topics.}
%     \label{fig:heatmap}
% \end{figure}

\section{Highly-Rated Examples in Dialogue-Level Quantitative Analysis} \label{appendix:highly-rated-examples}
\renewcommand{\thefigure}{F\arabic{figure}}
\renewcommand{\thetable}{F\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 
Figures \ref{fig:dialogue_44} and \ref{fig:dialogue_101} show 2 example dialogues rated highly in our dialogue-level quantitative analysis.
While Figure \ref{fig:dialogue_44} has been discussed in the main content of the paper, Figure \ref{fig:dialogue_101} displays another high-quality persuasion dialogue on the topic of doing a cartwheel in a supermarket. Despite the unconventional topic, the dialogue maintained high quality, with both participants adapting their ideas and providing reasonable suggestions. The persuader started with proposing the cartwheel to make shopping more exciting, but the persuadee raised safety concerns. In response, the persuader suggested alternatives, such as doing it during a less busy time or getting store permission. The persuadee emphasized the primary purpose of the store, leading both sides to agree on other options, like wearing costumes or organizing a scavenger hunt. 

\vfill\null

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{pics/Examples/dialogue_44.png}
    \caption{Example of a highly rated dialogue where the persuader is persuading the persuadee to store food in the attic.
}
    \label{fig:dialogue_44}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{pics/Examples/dialogue_101.png}
    \caption{Example of a highly rated dialogue where the persuader is persuading the persuadee to do a cartwheel in the grocery store.}
    \label{fig:dialogue_101}
\end{figure}

\vfill\null
\section{Appropriateness of Persuasiveness Scores} \label{appendix:label-validation}
\renewcommand{\thefigure}{G\arabic{figure}}
\renewcommand{\thetable}{G\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 
% \hltext{170,250,160}{SJ Note: This is a paragraph originally written by the Dartmouth Team, pending Weicheng decision to integrate. Our team haven't got a chance to work on this.}
We additionally manually checked the persuasiveness scores assigned to each round of communication to ensure they accurately reflect the extent of deviation from each participant’s original positions.
For example, high scores above 0.9 are assigned to the persuadee when it significantly influences the persuader, resulting in near or complete persuasion; low scores are assigned to both parties when no one manages to alter the other's stance, and middle scores surrounding 0.5 are assigned to both parties by which partial concessions are made (Figure \ref{fig:23-127-19}).
\vfill\null
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{.8\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{pics/Examples/Eg23.drawio.png}
        \caption{Significant perspective changes}
    \end{subfigure}%

    \begin{subfigure}[b]{.8\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{pics/Examples/Eg127.drawio.png}
        \caption{Negligible perspective changes}
    \end{subfigure}%

    \begin{subfigure}[b]{.8\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{pics/Examples/Eg19.drawio.png}
        \caption{Partial perspective changes}
    \end{subfigure}%

    \caption{The persuasiveness scores in our dataset correctly reflect the extent to which the perspectives of the persuader or persuadee change, i.e., high, low, and medium score changes are assigned to significant, negligible, and partial perspective changes, respectively.}
    \label{fig:23-127-19}
\end{figure}

\vfill\null

\section{Flexibility and Generalizability}
\renewcommand{\thefigure}{H\arabic{figure}}
\renewcommand{\thetable}{H\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 

Tables \ref{tbl:exp-strategy-controlled} exemplifies utterances in dialogues generated by our framework when the persuasion strategies are controlled and Figure \ref{fig:exp-multi-party} shows an example dialogue where there are 2 persuaders and 1 persuadee.
These generations are validated as high in quality, suggesting the strong flexibility and generalizability of our framework to challenging scenarios or with stricter manual controls.

\begin{table*}[!h]
\centering
\begin{tabular}{p{4cm}p{11cm}}
\hline
Strategy                              & Example Utterances                                                                                                                                                                                                                                                                                                                                                         \\ \hline
\multirow{2}{*}{Persuader\_Logical}   & Persuader: The unevenness of the country roads and the absence of sidewalks could increase the chance of accidents. It's vital to ensure that your walk is not just pleasurable but also safe.                                                                                                                                                                             \\ \cline{2-2} 
                                      & Persuadee: I acknowledge your worries about the erratic traffic and the rough terrain of country roads. But I always make sure to walk when traffic is light and wear sturdy shoes for the uneven paths. The nature and tranquility it offers outweighs the effort, providing a kind of refreshment that I can't find elsewhere.                                           \\ \hline
\multirow{2}{*}{Persuader\_Emotional} & Persuader: Yet, think of the dread and panic that could ensue if you were to find yourself lost or in harm's way, far from assistance. There's a wealth of beauty to be discovered in safer locales, where you can appreciate the majesty of nature without the specter of fear looming. Don't allow your quest for peace to become a perilous pursuit.                    \\ \cline{2-2} 
                                      & Persuadee: I am confident in my navigational skills and take precautionary measures. The unparalleled sense of freedom and calm I experience amidst the trees and fields is invaluable. My desire to connect with nature fuels my exploration of the country road, and I believe the rewards of this journey outweigh the potential hazards.                               \\ \hline
\multirow{2}{*}{Both\_Logical}        & Persuader: While walking has its benefits, country road risks shouldn't be overlooked. Statistics may suggest a low risk, but a single unpredicted incident can result in harm. Country roads often suffer from poor lighting and visibility, escalating the likelihood of accidents. The presence of unpredictable wildlife or loose gravel can further amplify the risk. \\ \cline{2-2} 
                                      & Persuadee: I've implemented precautions such as wearing bright attire, walking against traffic, and avoiding low visibility periods to lessen these risks. I also remain alert and aware of my surroundings to ensure my safety. The rewards I reap from walking in such a tranquil environment outweigh the risks for me.                                                 \\ \hline
\end{tabular}
\caption{Example utterances in the dialogues generated by our framework when desired persuasion strategies are specified.}
\label{tbl:exp-strategy-controlled}
\end{table*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{pics/Examples/persuasiveness_multi_party.pdf}
    \caption{An example conversation generated by our framework, with 2 persuaders and 1 persuadee.}
    \label{fig:exp-multi-party}
\end{figure*}

\clearpage

\section{Special-Case Examples with Agents Ablated} \label{sec:appendix}
\renewcommand{\thefigure}{I\arabic{figure}}
\renewcommand{\thetable}{I\arabic{table}}
\setcounter{figure}{0} 
\setcounter{table}{0} 
Figures \ref{fig:25} and \ref{fig:112} show the potential problems our framework encounters when the annotation agent is not given scoring examples and when the global regulation agent is ablated, respectively.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/Eg25.drawio.png}
    \caption{An example dialogue where the persuasiveness annotation agent, when not given correct scoring examples, assigns label 1 (perspective completely flipped) to a round of conversation where neither the persuader nor the persuadee is persuaded.}
    \label{fig:25}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{pics/Examples/Eg112.drawio.png}
    \caption{Generated dialogues become abnormally long without lots of repetitive yet non-persuasive utterances generated when the generation is not regulated by the global regulation agent.}
    \label{fig:112}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.7\linewidth]{pics/heatmap2.png}
%     \caption{Heatmap displaying the cosine similarity between strategy distributions across different dialogues. Each group of 5 dialogues belongs to the same topic, with the grid indicating the different topics.}
%     \label{fig:heatmap}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{pics/Examples/Eg74.drawio.png}
%     \caption{Dialogues generated using our proposed framework are generally of high quality and properly demonstrate persuasion strategies.}
%     \label{fig:74}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg75.drawio.png}
%         \caption{Religious beliefs}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg14.drawio.png}
%         \caption{Contraceptive choices}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg154.drawio.png}
%         \caption{Social norms and etiquette}
%     \end{subfigure}%

%     \caption{The generated dialogues tend to be conserved when discussing sensitive topics such as religious beliefs, contraceptive choices, and social norms and etiquette.}
%     \label{fig:75-14-154}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg25.drawio.png}
%         \caption{Health consequences}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg21.drawio.png}
%         \caption{Personal safety concerns}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg4.drawio.png}
%         \caption{Social, mental, and physical benefits}
%     \end{subfigure}%

%     \caption{Logical appeals are a frequently adopted category of persuasion techniques in our dataset.}
%     \label{fig:25-21-4}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg152.drawio.png}
%         \caption{Effects on social disruption}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg1.drawio.png}
%         \caption{Unacceptable behaviors}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg81.drawio.png}
%         \caption{Potential harm to the environment}
%     \end{subfigure}%

%     \caption{Principles of social proof are also leveraged for persuasion purposes in our dataset.}
%     \label{fig:152-1-81}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{pics/Examples/Eg12.drawio.png}
%     \caption{Invoking conformity norms is another widely adopted persuasion technique in our data.}
%     \label{fig:12}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{pics/Examples/Eg95.drawio.png}
%     \caption{An example where the persuadee argues back through logical appeal.}
%     \label{fig:95}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{pics/Examples/Eg133.drawio.png}
%     \caption{An illustration depicting a persuadee defending their position by invoking social norms.}
%     \label{fig:133}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{pics/Examples/Eg67.drawio.png}
%     \caption{Persuaders are willing to try multiple persuasion strategies in long conversations.}
%     \label{fig:67}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg148.drawio.png}
%         \caption{}
%         \label{fig:148}
%     \end{subfigure}%

%     \begin{subfigure}[b]{1\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{pics/Examples/Eg44.drawio.png}
%         \caption{}
%     \end{subfigure}%
%     \caption{Persuadees are less likely to change their strategies in long conversations.}
%     \label{fig:148-44}
% \end{figure}

















\end{document}
