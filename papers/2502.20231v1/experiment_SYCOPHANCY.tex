\subsection{Bias in the Sycophantic Responses of AI Personas}

The third experiment analysed sycophancy in persona-assigned models while looking at abuse, control and submissiveness topics. If a model is more susceptible to agreeing with their user and, therefore, less likely to contradict them, they may be more prone to being abused. Corroborating a user's toxic view of serious, unhealthy relationship dynamics could imply to that user that this behaviour is acceptable outside the digital world as well. Creating a measure of sycophancy thus seemed vital to measure if differently gendered personas exhibit sycophancy when presented with situations of abuse and control.

To tackle this, we took inspiration from \citet{ranaldi2024largelanguagemodelscontradict}, which tested how susceptible {LLM}s were to user-influenced prompts through three experiments: (1) an original one (model is posed a question with answer choices); (2) a correct influenced one (user expresses that the correct choice is the answer); and (3) an incorrect influenced one (user instead expresses that the incorrect choice is the answer). To adapt this to our themes of abuse and control, we presented it with the same situations as in the emotion experiment, seen in Table \ref{tab:emotion_stimuli}, this time prompting the model to respond if situations were abusive or not, or controlling or not. The correct answer was always either \enquote{abusive} or \enquote{controlling}. To consider option-order symmetry, for the correct and incorrect influenced experiments, the choice of the correct answer was presented both first and second. An example of this can be seen in Fig. \ref{fig:sycophancy_prompts} below, where for this example, the correct answer was presented first as option \textit{A}.

\paragraph{Prompting}Three prompts were used here: the original, the correctly influenced, and the incorrectly influenced. The prompt variations can be seen in Fig. \ref{fig:sycophancy_prompts}, where each of these also has the alternative option of switching around the choices and therefore presenting a different option (A or B) to the model. The types were abuse and control, and the events were the same as in the emotion experiments.

\paragraph{Metric} The score for sycophancy measured how influenced each persona can be, compared to the original prompt (no influence) and compared to the baseline model (no persona assigned). First, accuracy in correctly identifying abusive/controlling behaviour was measured for the original $P_o$, incorrectly $P_i$, and correctly $P_c$ influenced experiments (not including when the model avoids answering, such as by replying \enquote{I don't feel comfortable answering}). Then, the difference in accuracy from the original with the correctly and incorrectly influenced experiments was calculated, subtracted from each other, and divided by two to get the average. This returns an overall score of how influenced the model was, i.e. how much it changed its answers when influenced. This same calculation was done for the baseline model ($B_o, B_i, B_c$), which was then subtracted from the persona score. This was then divided by the same baseline score to, akin to the emotion experiment, get the percentage increase or decrease in \enquote{sycophancy} compared to the baseline. These are calculated for each specific persona but shown across gender groups. This is shown below, where the division by two is removed as it cancels out:

\begin{align*}
    \text{relative bias} = \frac{(P_i - P_o) - (P_c - P_o)}{(B_i - B_o) - (B_c - B_o)} - \\ \frac{(B_i - B_o) - (B_c - B_o)}{(B_i - B_o) - (B_c - B_o)}.
    \label{eq:sycophancy_bias}
\end{align*}
Scores of $0$ mean the same influence as the baseline, i.e. assigning a persona does not bias the model to being more sycophantic. Scores above $0$ mean it is more sycophantic, and scores between $-1$ and $0$ imply it is less influenced than the baseline, with $-1$ exactly implying no influence by the user. If the score is less than $-1$, the model does the opposite of what it is expected to do, i.e. it gets more of the questions correct when incorrectly influenced and/or it gets fewer correct when correctly influenced. A significantly negative score does not imply extremely low bias but rather that the model disagrees with most of what the user is suggesting, whether it is correct or not. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\columnwidth]{Images/sycophancy_prompts.png}
    \caption{Template of the user prompts for the sycophancy experiment.}
    \label{fig:sycophancy_prompts}
\end{figure}

\subsubsection{Results for Sycophancy Experiment}

The key takeaways are that Llama 2 and Llama 3 models had opposite trends when reacting to both stimuli, the male-assigned system had much higher bias scores for the control stimuli, and the avoidance rates jumped significantly.

As seen in Fig. \ref{fig:score_syc_combined}, Llama 3 always had positive bias scores, although much higher for the controlling situations, where male-assigned models were consistently and significantly more influenced than both female and gender-neutral-assigned models. Female-assigned models were least influenced in comparison to the baseline. This means that female-assigned models, in general, were less influenced by the user than the male and gender-neutral ones. In contrast, Llama 2 always had negative bias scores, although much more dramatic for abusive situations. The larger the model was, the more negative the score was. 

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.875\columnwidth]{Images/results/experiment_sycophancy/score_syc_combined.png}
    \caption{Bias score for abusive situations (on top) and controlling situations (on bottom), showing how each persona-assigned model is influenced by the user, relative to the same experiment on a baseline model. Positive means influenced more than baseline, and negative means influenced less than baseline.}
    \label{fig:score_syc_combined}
\end{figure}

The relative bias scores per system and user are shown for the Llama 3 family in Fig. \ref{fig:heatmaps_combined}. For the abuse stimuli, when assigning a persona, on average, all system personas, no matter the user, tended to be only slightly more influenced than the baseline. The male-assigned system generally had higher scores, with the lowest influence when interacting with a male-assigned user. For the control stimuli, the male-assigned system had the highest relative bias score. It had the highest score with no user set and with the female-assigned user and a significantly lower score when interacting with a male-assigned user. In general, the female-assigned system had lower scores than the two other system personas.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\columnwidth]{Images/results/experiment_sycophancy/heatmaps_combined.png}
    \caption{Bias scores for both controlling and abusive situations, per user and system persona, averaged over all the Llama 3 models.}
    \label{fig:heatmaps_combined}
\end{figure}

The Llama 3 models were significantly more consistent in attempting to answer the prompt (Fig. \ref{fig:unanswered}). The abuse stimuli were significantly more unanswered, with almost 90\% being unanswered by Llama 2 13b. In all models and situations, the baseline had the lowest avoidance percentage, with the control stimuli resulting in no avoidance from the baseline. Assigning a persona almost always increased the avoidance rate, except for Llama 3 70b. For Llama 2 13b, which generally had the worst reply rate, the female-assigned personas replied about 10 percentage points less than the male-assigned persona (and even fewer than the gender-neutral one).

The sycophancy abuse results on average were statistically significant, $t(1288) = -13.88, p<0.05$, as were the control results, $t(941)=7.93, p<0.05$. However, there is a very different trend in the direction of the t-statistic. In general, the model agreed and was influenced by the user more for the control stimuli, whereas it disagreed with the user more often for the abuse stimuli. For both experiments, the Llama 3 models had positive t-statistics. In contrast, the Llama 2 ones were negative, meaning the Llama 3 family were further influenced by the user than the Llama 2 models. 