\section{Related Work}
\label{sec:related_work}
\subsection{Ingestive Episode Detection}
\label{dietarydetection}
Ingestive episode detection is essential for automatic food journaling \cite{tang2025video}. 
Various wearable sensors have been explored for automated tracking. In \cite{guan2025towards}, Guan et al. developed a multi-source domain adaptation method to capture chewing activity for food type recognition utilizing IMU from wearable. Wrist-mounted devices can track hand movements during eating \cite{wrist1,wrist2,wrist3}, but these can be distracted by other gestures and require use on the dominant hand. More reliable approaches involve head- or neck-mounted devices like necklace \cite{necklace_proximity2}, headbands \cite{headband}, caps \cite{cap}, and ear-mounted sensors \cite{EarBit,EarSAVAS,Auracle}, though they are often uncomfortable and socially intrusive. 
In contrast, eyeglasses offer a more acceptable alternative, with their proximity to the mouth allowing for better detection of eating episodes. Previous work using eyeglasses includes sensors such as electromyography \cite{emgglasses}, piezoelectric \cite{piezoelectricglasses}, load cells \cite{loadcellglasses}, and acoustic sensors \cite{acousticglasses} for detection of ingestive behavior. 
Rahman et al. \cite{imuglasses} utilized the Inertial Measurement Unit (IMU) in Google Glass for detection. IMU sensors combine accelerometers, gyroscopes, and occasionally magnetometers to measure the specific force, angular rate, and sometimes magnetic field of objects, enabling the tracking of motion and orientation in three-dimensional space \cite{bedri2020fitbyte}.
Systems like FitByte \cite{bedri2020fitbyte} integrated IMU and proximity sensors, while MyDJ \cite{shin2022mydj} utilized piezoelectric and accelerometer sensors. 

However, prior studies were limited to simple dishes or controlled settings and often relied on crowd-sourced efforts. \shortname introduces a multimodal sensing framework to record the meal throughout dining in uncontrolled environments of the real world, allowing comprehensive nutritional analysis and personalized diet suggestions.

\subsection{Diet Identification and Nutritional Analysis}
Alternative methods include uploading meal photos for expert evaluation \cite{expertnutritionestimate} or crowdsourced nutrient estimation \cite{crowdsourcingnutritionestimate}, which are labor-intensive and time-consuming, limiting the system's accessibility and scalability. 
% Consulting nutrition experts is costly and time-consuming, limiting accessibility, particularly in economically disadvantaged areas. 
Additionally, online searches or forums often provide irrelevant information, reducing their effectiveness.
With advances in computer vision, some solutions perform food segmentation, volume estimation, and database-based nutrient calculations sequentially \cite{foodseg1,foodseg2,foodseg3,foodseg4}, while end-to-end neural networks directly estimate nutritional content from meal images \cite{end2endfood1,end2endfood2,end2endfood3}. 
Although they have achieved promising results with pre-built nutrition estimation datasets, the generalization of models limits their applicability to open-world settings, the close setting to daily routines, and vision models alone lack comprehensive knowledge of diet or nutrition \cite{foodreview}.   

The rise of LLMs offers new potential. They excel in knowledge integration and cross-domain generalization, attributed to their immense parameters and diverse, extensive training data \cite{llmemergence}. 
Lo et al. \cite{lo2024dietary} demonstrated that GPT-4V can identify food items with high accuracy, deduce portion sizes of eating consumption at a comparable performance to dietitians' estimates, and estimate nutritional components aligning with the USDA National Nutrient Database\footnote{USDA National Nutrient Database: https://fdc.nal.usda.gov/index.html} under semi free-living conditions.
Building on this, our \shortname system employs GPT-4V with crafted prompt and user profile to estimate diet type and amount. Unlike prior work, we proposed a multimodal sensing framework combining IMU, audio, and images for automatic diet identification and nutritional analysis under completely free-living conditions. Insights from our user studies highlight opportunities to further refine dietary monitoring and analysis systems.


\subsection{Personalized Dietary Suggestions}
Recent studies have explored machine learning models for personalized health and disease management suggestions. 
For example, Mitchell et al. \cite{g2021reflection} developed GlucoGoalie, which combines machine learning and a rule-based expert system to generate dietary goals for individuals with type 2 diabetes. 
To enhance flexibility and generalization, researchers have turned to LLMs for dietary guidance, leveraging their extensive knowledge and reasoning capabilities.
Chatelan et al. \cite{dietaryguidance1} investigated the ability of ChatGPT to provide nutritional and dietary guidance for patients with type 2 diabetes and hemodialysis, and their findings show that the generated diet recipes are in accordance with the Diabetes Plate Method. Ataguba et al. \cite{ataguba2025exploring} explored using LLM for personalized recipe generation and weight-loss management. Further, Yang et al. \cite{dietaryguidance2} introduced ChatDiet, an LLM-powered framework for personalized nutrition-oriented food recommender chatbots, and evaluated it on a case study including one-person information, where the generated food recommendation dialogue demonstrates the explainability and personalization. 
However, researchers noted that LLMs are easily struggling with hallucinations. One of study in \cite{szymanski2024integrating} conducted an analysis involving registered dietitians to assess the capabilities of LLMs in providing nutritionally accurate and personalized information, showing the outputs of some instances do not align with standards upheld by registered dietitians and contain falsehoods, which can be misleading.
Similarly, in \cite{llmnutritionlimitation1}, researchers found that while the nutritional advice proposed by ChatGPT is generally accurate, it has the potential to produce unsafe diets containing allergens.


Therefore, different from existing works that directly prompt LLMs for dietary suggestions, we built the RAG module with reliable external dietary and nutritional knowledge to enhance LLM's capabilities for nutritional analysis and personalized dietary suggestions. We also developed a context-aware chatbot that allows users to enhance personalization through iterative conversations.
This approach provides accurate and trustworthy results, reducing the need for costly expert involvement while maintaining high-quality recommendations.


\subsection{Leveraging RAG to Enhance LLMs for Accurate Knowledge Retrieval}
LLMs are widely used for information extraction and summarization due to their vast knowledge and reasoning capabilities. However, directly prompting LLMs can lead to plausible-sounding but inaccurate answers, known as hallucinations, and a lack of domain-specific knowledge. To address these issues, RAG enhances LLMs by integrating a retrievable memory that incorporates knowledge from external sources \cite{llmhallucination,ragsurvey}. 
For example, Fok et al. \cite{Qlarify} use RAG to expand abstracts with additional information from full papers, while Zulfkar et al. \cite{Memoro} develop Memoro to infer the user's memory needs in conversation and presenting suggestions queried from memories using a RAG module. 
The Arizona Water Chatbot \cite{Arizona_Water_Chatbot} employs RAG to retrieve water-related information from reputable sources, improving decision-making.
Ren et al. \cite{Memolet} explore memory retrieval and generation refinement using RAG for enhanced conversational AI, and Yang et al. \cite{yang2024aqua} develop AQuA that combines software UI elements associated with questions as the query and generates answers using RAG-powered GPT-4 from official documentation and tutorial resources.
While RAG has proven effective in handling large knowledge repositories, its application in integrating dietary data has not yet been comprehensively explored.