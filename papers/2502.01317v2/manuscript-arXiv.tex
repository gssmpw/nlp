
% \input{authors}
% \author{Anonymous author(s)}


\DocumentMetadata{}
\documentclass{article}
\usepackage[utf8]{inputenc} %
\usepackage[T1]{fontenc}    %
\usepackage[hidelinks,colorlinks=true,linkcolor=blue,citecolor=green,urlcolor=red,hyperfootnotes=false]{hyperref}
\usepackage[numbers,sort]{natbib}
\usepackage{soul,color}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{amsfonts}
\usepackage{amsmath}
% \usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multirow,multicol}
\usepackage{pifont}
\usepackage{subfig}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{xcolor}
\soulregister\cite7
\soulregister\ref7
\soulregister\pageref7
\soulregister\figurename7
\soulregister\subsection7
\soulregister\subsubsection7
\soulregister\tablename7
\soulregister\systemname7
\soulregister\bfseries7
\soulregister\textbf7
\definecolor{ccolor}{RGB}{0,0,0}
\renewcommand{\figurename}{Fig.}
% Customize subfigure label format
\captionsetup[subfigure]{labelformat=simple, labelsep=none}
\renewcommand{\thesubfigure}{(\alph{subfigure})~}
\newcommand{\shortname}{\textit{DietGlance}\xspace}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-0.5in}
\newlength{\defbaselineskip}
\setlength{\defbaselineskip}{\baselineskip}
\setlength{\marginparwidth}{0.8in}
\usepackage{booktabs}
\newcommand*\emptycirc[1][0.618ex]{\tikz\draw (0,0) circle (#1);}

\newcommand*\halfcirc[1][0.618ex]{%
  \begin{tikzpicture}
  \draw[fill] (0,0)-- (90:#1) arc (90:270:#1) -- cycle ;
  \draw (0,0) circle (#1);
  \end{tikzpicture}}
  
\newcommand*\quartercirc[1][0.618ex]{%
\begin{tikzpicture}
\draw[fill] (0,0) -- (90:#1) arc (90:180:#1) -- cycle ;
\draw (0,0) circle (#1);
\end{tikzpicture}}

\newcommand*\threequartercirc[1][0.618ex]{%
  \begin{tikzpicture}
  \draw[fill] (0,0) -- (90:#1) arc (90:360:#1) -- cycle ;
  \draw (0,0) circle (#1);
  \end{tikzpicture}}
\newcommand*\fullcirc[1][0.618ex]{\tikz\fill (0,0) circle (#1);} 


\graphicspath{{./figures/}}
\graphicspath{{./pdf/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\usepackage{fp}

\newlength\maxlentime
\newcommand\pesqtimebar[3][red!20]{%
  \FPeval\result{round((#3-0)/#2:4)}%
  \rlap{\textcolor{#1}{\hspace*{\dimexpr-\tabcolsep+.5\arrayrulewidth}%
        \rule[-.05\ht\strutbox]{\result\maxlentime}{.95\ht\strutbox}}}%
  \makebox[\dimexpr\maxlentime-0.2\tabcolsep+\arrayrulewidth][c]{#3}}

\newcommand\stoitimebar[3][NavyBlue!20]{%
\FPeval\result{round((#3-0)/#2:4)}%
\rlap{\textcolor{#1}{\hspace*{\dimexpr-\tabcolsep+.5\arrayrulewidth}%
    \rule[-.05\ht\strutbox]{\result\maxlentime}{.95\ht\strutbox}}}%
\makebox[\dimexpr\maxlentime-0.2\tabcolsep+\arrayrulewidth][c]{#3}}

\newcommand\lsdtimebar[3][SeaGreen!30]{%
\FPeval\result{round((#3-0)/#2:4)}%
\rlap{\textcolor{#1}{\hspace*{\dimexpr-\tabcolsep+.5\arrayrulewidth}%
    \rule[-.05\ht\strutbox]{\result\maxlentime}{.95\ht\strutbox}}}%
\makebox[\dimexpr\maxlentime-0.2\tabcolsep+\arrayrulewidth][c]{#3}}


\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}
\def\sysname{\textsc{DietGlance}\xspace}
\title{\shortname: Dietary Monitoring and Personalized Analysis at a Glance with Knowledge-Empowered AI Assistant}

\usepackage{authblk}
\author[$1$]{Zhihan Jiang \thanks{Co-first authors.}}
\author[$1$]{Running Zhao \samethanks}
\author[$1$]{Lin Lin}
\author[$2$]{Yue Yu}
\author[$1$]{Handi Chen}
\author[$1$]{Xinchen Zhang}
\author[$3$]{Xuhai ``Orson'' Xu}
\author[$4$]{Yifang Wang}
\author[$2$]{Xiaojuan Ma \thanks{Co-corresponding authors.}}
\author[$1$]{Edith C.H. Ngai \samethanks}
\affil[$1$]{The University of Hong Kong}
\affil[$2$]{Hong Kong University of Science and Technology}
\affil[$3$]{Columbia University}
\affil[$4$]{Northwestern University}

\date{}

\begin{document}

\maketitle

\pagenumbering{arabic}

\begin{abstract}
Growing awareness of wellness has prompted people to consider whether their dietary patterns align with their health and fitness goals. 
In response, researchers have introduced various wearable dietary monitoring systems and dietary assessment approaches. 
However, these solutions are either limited to identifying foods with simple ingredients or insufficient in providing analysis of individual dietary behaviors with domain-specific knowledge. 
In this paper, we present \shortname, a system that automatically monitors dietary in daily routines and delivers personalized analysis from knowledge sources. 
\shortname first detects ingestive episodes from multimodal inputs using eyeglasses, capturing privacy-preserving meal images of various dishes being consumed. 
Based on the inferred food items and consumed quantities from these images, \shortname further provides nutritional analysis and personalized dietary suggestions, empowered by the retrieval augmentation generation module on a reliable nutrition library.
A short-term user study (N=33) and a four-week longitudinal study (N=16) demonstrate the usability and effectiveness of \shortname, offering insights and implications for future AI-assisted dietary monitoring and personalized healthcare intervention systems using eyewear.
\end{abstract}


% \keywords{Eating Detection, Dietary Monitoring, Nutritional Analysis, Multimodal Sensing}


\maketitle

\section{Introduction}
Dietary behaviors and human health are inextricably linked \cite{stylianou2021small, marshall2022survey}. For instance, excessive consumption of processed foods high in sugars, unhealthy fats, and sodium increases the risk of chronic diseases \cite{micha2017association}. Even small dietary improvements can significantly benefit health \cite{grummon2023simple}.
Thus, many individuals have sought dietary monitoring and analysis methods to refine their dietary choices.
By offering insights into nutritional intake, these practices enable individuals to make informed decisions on diet planning, correct nutritional imbalances, and achieve health goals such as weight management or disease prevention \cite{adams2020perspective}.
The dominant dietary monitoring and analysis method nowadays is food journaling (on paper, websites, or mobile apps~\cite{shin2022mydj}), such as MyFitnessPal~\cite{myfitnesspal} and Boohee~\cite{boohee}. 
These tools allow users to log their food consumption, track nutrients, reflect on their dietary habits, and seek dietary recommendations from nutrition experts.
% Alternatively, individuals may consult nutrition experts for professional analysis tailored to their specific needs. 
However, these methods face several limitations.

 \begin{figure*}[!t]
          \centering
          \subfloat[]{
            \centering
            \includegraphics[width=.17\textwidth]{Figures-clean/teaser1.png}
            \label{fig:teaser1}
          }
          \subfloat[]{    
                  \centering
                  \includegraphics[width=.46\textwidth]{Figures-clean/teaser2.png}
              \label{fig:teaser2}
          }
          \subfloat[]{    
                  \centering
                  \includegraphics[width=.306\textwidth]{Figures-clean/teaser5.pdf}
              \label{fig:teaser5}
          }
          \vspace{-0.1cm}
          \caption{The flow of \shortname. (a) \shortname uses Aria Glasses to detect ingestive episodes and collects data in real-world, unconstrained environments. Users can view their dietary analysis results using the (b) mobile (from left to right: meal log image presentation, detailed nutritional analysis, and personalized suggestions) or (c) desktop interface.}
          \label{fig:teaser}
           \vspace{-0.1cm}
      \end{figure*}

First, manual food journaling is labor-intensive and time-consuming~\cite{selfrepotdrawback,passler2011food}. Most existing tools, like mobile apps, require users to input information or capture images manually, hindering long-term tracking sustainability~\cite{schoeller1995limitations,cordeiro2015barriers, merck2016multimodality}. Second, comprehensive nutritional analysis remains insufficiently addressed in current systems, which is essential for evaluating dietary intake and making informed decisions. 
Mobile apps offer basic nutritional insights with pre-built databases but often lack data on customized or home-cooked meals, leading to vague and inaccurate analysis. 
They also lack real-time, personalized suggestions tailored to individual contexts.
Therefore, a holistic automatic dietary monitoring and analysis system supporting food journaling, nutritional analysis, and dietary suggestions is in great need.

To automate food journaling, researchers have explored eyewear-based devices for detecting ingestive episodes \cite{bedri2020fitbyte, shin2022mydj, piezoelectricglasses}.
Eyeglasses are both socially acceptable and conveniently positioned near the eating region, making them ideal for this purpose \cite{shin2022mydj,bedri2020fitbyte}.
Contemporary commercial eyewear devices (e.g., Vision Pro \cite{apple2024visionpro} and Meta smart glasses \cite{waisberg2024meta}), which integrate advanced sensing capabilities for diverse applications, highlight the potential of eyewear for dietary data collection in daily contexts.
However, existing systems are only capable of handling simple dishes and idealized dining environments, which restricts their applicability in real-world settings. Approaches for more generic and sophisticated nutritional analysis remain largely underexplored. % This restricts their applicability in the complexities of real-world dietary monitoring and analysis.

Recent advances in Large Language Models (LLMs) offer new opportunities.
Their extensive knowledge and contextual understanding enable effective management of the complexity and diversity of food items, dietary habits, and nutritional needs across various populations \cite{szymanski2024integrating, lo2024dietary}. 
For example, Szymanski et al. \cite{szymanski2024integrating} collaborated with registered dietitians to validate the GPT-4-generated food product explanation based on product names, nutrition labels, and dietary goals. Lo et al. \cite{lo2024dietary} applied GPT-4V to dietary assessment, highlighting its effectiveness in food detection under challenging conditions.
However, directly using LLM may generate plausible-sounding but incorrect or inaccurate results (i.e., hallucination). Moreover, it may show limited and generic health guidelines that are not personalized to individuals' needs, overlook comprehensive dietary patterns, and miss relevant nutrition information \cite{szymanski2024integrating, llmnutritionlimitation1, llmnutritionlimitation2}. 
There is a great research space in enhancing LLMs by domain knowledge for comprehensive nutritional analysis, enabling more reliable and personalized recommendations. Such a system can facilitate the early detection of nutritional issues and support informed dietary decisions to improve personal health.
% systems that integrate multimodal inputs with LLMs enhanced by domain knowledge. Combining sensor data from wearables with LLMs' contextual understanding would enable automated, effective dietary monitoring and analysis, supporting more personalized recommendations, early detection of nutritional issues, and informed dietary decisions to enhance health.


% Motivated by the above analysis, there is a lack of holistic systems that integrate multimodal sensing techniques with LLMs enhanced by domain knowledge for effective dietary monitoring and analysis.
To address these gaps, we first conducted a needs-finding study with 45 participants to deepen our understanding of user needs and validate limitations identified in prior research. Consequently, we formulated four key design requirements for a holistic dietary monitoring and analysis system: supporting automated accurate diet identification and logging, facilitating nutritional analysis based on reliable sources, providing personalized dietary suggestions with domain-specific knowledge, while protecting privacy.
Following these design requirements, we introduced \shortname (\figurename{\ref{fig:pip}}), an AI-assisted system for dietary monitoring and analysis using eyewear, which automatically identifies various food and drink items, and further provides knowledge-supported nutritional analysis and personalized suggestions.
Developed using Aria Glasses \cite{somasundaram2023project}, we proposed a multimodal sensing framework for ingestive episode detection and key-moment meal image capture in free-living conditions.
Based on the consumed type and amount of food and drink identified from processed meal images using vision foundation models, a Retrieval-Augmented Generation (RAG) module on a nutrition library is built to empower LLM in providing nutrition analysis and personalized dietary suggestions with knowledge sources incorporating individual profiles and meal logs. The system's user interface allows users to review personalized dietary suggestions with nutritional analysis, interactively correct errors, add information, and access additional insights. 

To evaluate \shortname, we first conducted a short-term study with 33 participants to explore their perceptions and behaviors (Study I.1). Using real-world data from their daily routine, we quantitatively evaluated the system's performance on diet identification (Study I.2), nutritional analysis (Study I.3), and conducted comparative analysis for the RAG module (Study I.4), involving crowd workers and domain experts. The qualitative and quantitative results demonstrate the system's accuracy in diet logging and its effectiveness in providing nutritional analysis and personalized suggestions.
Additionally, a four-week longitudinal study (Study II) with 16 participants demonstrated the system's positive impact on their dietary behaviors in real-world scenarios.
In summary, this paper presents the following main contributions:

    \begin{figure}[!t]
          \centering
          \includegraphics[width=\textwidth]{Figures-clean/pipeline_compressed.pdf}
          \vspace{-0.5cm}
          \caption{System Overview. }
          \label{fig:pip}
           \vspace{-0.1cm}
      \end{figure}

\begin{itemize}
    \item \shortname, a holistic AI-assisted system for dietary monitoring and analysis using smart glasses in daily contexts. \shortname takes a novel multimodal sensing approach with an LLM augmented by domain-specific knowledge to support accurate automated diet identification and logging, comprehensive nutritional analysis, and personalized dietary suggestions in real-world uncontrolled environments.
    \item A short-term user study (N=33) demonstrating \shortname's effectiveness and usability. With the real-world data collected in this study, we further quantitatively evaluate the system's performance on diet identification, nutritional analysis, and dietary suggestions with crowd workers and domain experts.
    \item A four-week longitudinal study (N=16) highlighting the positive long-term effects of \shortname on dietary behaviors. The quantitative analysis of nutrition consumption trends and qualitative analysis of participants' feedback demonstrates that using \shortname increased the understanding of their diet, raised their awareness of regular meal timing, promoted healthier dietary habits, and reduced consumption of unhealthy foods.
    \item Through real-world implementation and studies, we contribute practical insights into the design and implementation of AI-assisted dietary monitoring and analysis systems using eyewear. These findings offer implications for future AI-assisted dietary monitoring and personalized healthcare intervention systems.
\end{itemize}


\section{Related Work}
\label{sec:related_work}
\subsection{Ingestive Episode Detection}
\label{dietarydetection}
Ingestive episode detection is essential for automatic food journaling \cite{tang2025video}. 
Various wearable sensors have been explored for automated tracking. In \cite{guan2025towards}, Guan et al. developed a multi-source domain adaptation method to capture chewing activity for food type recognition utilizing IMU from wearable. Wrist-mounted devices can track hand movements during eating \cite{wrist1,wrist2,wrist3}, but these can be distracted by other gestures and require use on the dominant hand. More reliable approaches involve head- or neck-mounted devices like necklace \cite{necklace_proximity2}, headbands \cite{headband}, caps \cite{cap}, and ear-mounted sensors \cite{EarBit,EarSAVAS,Auracle}, though they are often uncomfortable and socially intrusive. 
In contrast, eyeglasses offer a more acceptable alternative, with their proximity to the mouth allowing for better detection of eating episodes. Previous work using eyeglasses includes sensors such as electromyography \cite{emgglasses}, piezoelectric \cite{piezoelectricglasses}, load cells \cite{loadcellglasses}, and acoustic sensors \cite{acousticglasses} for detection of ingestive behavior. 
Rahman et al. \cite{imuglasses} utilized the Inertial Measurement Unit (IMU) in Google Glass for detection. IMU sensors combine accelerometers, gyroscopes, and occasionally magnetometers to measure the specific force, angular rate, and sometimes magnetic field of objects, enabling the tracking of motion and orientation in three-dimensional space \cite{bedri2020fitbyte}.
Systems like FitByte \cite{bedri2020fitbyte} integrated IMU and proximity sensors, while MyDJ \cite{shin2022mydj} utilized piezoelectric and accelerometer sensors. 

However, prior studies were limited to simple dishes or controlled settings and often relied on crowd-sourced efforts. \shortname introduces a multimodal sensing framework to record the meal throughout dining in uncontrolled environments of the real world, allowing comprehensive nutritional analysis and personalized diet suggestions.

\subsection{Diet Identification and Nutritional Analysis}
Alternative methods include uploading meal photos for expert evaluation \cite{expertnutritionestimate} or crowdsourced nutrient estimation \cite{crowdsourcingnutritionestimate}, which are labor-intensive and time-consuming, limiting the system's accessibility and scalability. 
% Consulting nutrition experts is costly and time-consuming, limiting accessibility, particularly in economically disadvantaged areas. 
Additionally, online searches or forums often provide irrelevant information, reducing their effectiveness.
With advances in computer vision, some solutions perform food segmentation, volume estimation, and database-based nutrient calculations sequentially \cite{foodseg1,foodseg2,foodseg3,foodseg4}, while end-to-end neural networks directly estimate nutritional content from meal images \cite{end2endfood1,end2endfood2,end2endfood3}. 
Although they have achieved promising results with pre-built nutrition estimation datasets, the generalization of models limits their applicability to open-world settings, the close setting to daily routines, and vision models alone lack comprehensive knowledge of diet or nutrition \cite{foodreview}.   

The rise of LLMs offers new potential. They excel in knowledge integration and cross-domain generalization, attributed to their immense parameters and diverse, extensive training data \cite{llmemergence}. 
Lo et al. \cite{lo2024dietary} demonstrated that GPT-4V can identify food items with high accuracy, deduce portion sizes of eating consumption at a comparable performance to dietitians' estimates, and estimate nutritional components aligning with the USDA National Nutrient Database\footnote{USDA National Nutrient Database: https://fdc.nal.usda.gov/index.html} under semi free-living conditions.
Building on this, our \shortname system employs GPT-4V with crafted prompt and user profile to estimate diet type and amount. Unlike prior work, we proposed a multimodal sensing framework combining IMU, audio, and images for automatic diet identification and nutritional analysis under completely free-living conditions. Insights from our user studies highlight opportunities to further refine dietary monitoring and analysis systems.


\subsection{Personalized Dietary Suggestions}
Recent studies have explored machine learning models for personalized health and disease management suggestions. 
For example, Mitchell et al. \cite{g2021reflection} developed GlucoGoalie, which combines machine learning and a rule-based expert system to generate dietary goals for individuals with type 2 diabetes. 
To enhance flexibility and generalization, researchers have turned to LLMs for dietary guidance, leveraging their extensive knowledge and reasoning capabilities.
Chatelan et al. \cite{dietaryguidance1} investigated the ability of ChatGPT to provide nutritional and dietary guidance for patients with type 2 diabetes and hemodialysis, and their findings show that the generated diet recipes are in accordance with the Diabetes Plate Method. Ataguba et al. \cite{ataguba2025exploring} explored using LLM for personalized recipe generation and weight-loss management. Further, Yang et al. \cite{dietaryguidance2} introduced ChatDiet, an LLM-powered framework for personalized nutrition-oriented food recommender chatbots, and evaluated it on a case study including one-person information, where the generated food recommendation dialogue demonstrates the explainability and personalization. 
However, researchers noted that LLMs are easily struggling with hallucinations. One of study in \cite{szymanski2024integrating} conducted an analysis involving registered dietitians to assess the capabilities of LLMs in providing nutritionally accurate and personalized information, showing the outputs of some instances do not align with standards upheld by registered dietitians and contain falsehoods, which can be misleading.
Similarly, in \cite{llmnutritionlimitation1}, researchers found that while the nutritional advice proposed by ChatGPT is generally accurate, it has the potential to produce unsafe diets containing allergens.


Therefore, different from existing works that directly prompt LLMs for dietary suggestions, we built the RAG module with reliable external dietary and nutritional knowledge to enhance LLM's capabilities for nutritional analysis and personalized dietary suggestions. We also developed a context-aware chatbot that allows users to enhance personalization through iterative conversations.
This approach provides accurate and trustworthy results, reducing the need for costly expert involvement while maintaining high-quality recommendations.


\subsection{Leveraging RAG to Enhance LLMs for Accurate Knowledge Retrieval}
LLMs are widely used for information extraction and summarization due to their vast knowledge and reasoning capabilities. However, directly prompting LLMs can lead to plausible-sounding but inaccurate answers, known as hallucinations, and a lack of domain-specific knowledge. To address these issues, RAG enhances LLMs by integrating a retrievable memory that incorporates knowledge from external sources \cite{llmhallucination,ragsurvey}. 
For example, Fok et al. \cite{Qlarify} use RAG to expand abstracts with additional information from full papers, while Zulfkar et al. \cite{Memoro} develop Memoro to infer the user's memory needs in conversation and presenting suggestions queried from memories using a RAG module. 
The Arizona Water Chatbot \cite{Arizona_Water_Chatbot} employs RAG to retrieve water-related information from reputable sources, improving decision-making.
Ren et al. \cite{Memolet} explore memory retrieval and generation refinement using RAG for enhanced conversational AI, and Yang et al. \cite{yang2024aqua} develop AQuA that combines software UI elements associated with questions as the query and generates answers using RAG-powered GPT-4 from official documentation and tutorial resources.
While RAG has proven effective in handling large knowledge repositories, its application in integrating dietary data has not yet been comprehensively explored.

\section{Existing Practices of Dietary Monitoring and Analysis }

To validate limitations identified in prior research and better reveal users' needs, concerns, and hurdles encountered, we conducted a needs-finding study with 45 participants. 
We then derived four design requirements to motivate our system design.


\subsection{Participants and Procedure}

We recruited 45 participants with diverse demographic and socio-economic backgrounds by word-of-mouth and online advertisement with inclusion criteria of being adults (aged  > 18), fluent in Chinese or English, and without eating disorders.
Their ages range from 18 to 62 ($M=33.24, SD=10.62$),
% including 22 self-declared as male (49\%, M), 21 as female (47\%, F), one as non-binary (2\%, NB), and one preferred not to disclose (2\%, PND).
including 22 males, 21 females, 1 non-binary, and 1 preferred not to disclose.
Participants had diverse socio-economic backgrounds, including twenty university students, six senior researchers, four engineers, one high school graduate, one government employee, one freelancer, one bank employee, two high school teachers, two manufacturers, two workers, one clerk, and four retired.
% To ensure generalizability for different user experiences, w
We included both experienced (exp., 23, 51\%) and inexperienced (inexp., 22, 49\%) participants. The exp. group consisted of individuals who had prior experience using dietary monitoring tools, such as mobile apps, online tools, and paper journals, or receiving professional guidance from experts like dietitians or nutritionists, while the inexp. group included those with no prior experience.

Participants completed a survey on their backgrounds, including experience with dietary monitoring tools, eating environments, and usage frequency, followed by a semi-structured interview on the vision of helpful features, obstacles, and expectations for future eyewear-based dietary systems. The study lasted about 20 minutes, with participants compensated about \$2.5. For qualitative analysis, the lead author first conducted thematic coding and iteratively discussed with other authors to finalize the codes as used in \cite{yang2024aqua}.


\subsection{Key Findings and Design Requirements}
We summarize the following design requirements based on the key findings:

\textbf{R1. Supporting Automated Accurate Diet Identification and Logging.} 
Participants (30 out of 45) confirmed the need for automated detection and logging of diet consumption to reduce manual effort and improve convenience~\cite{bedri2020fitbyte,shin2022mydj}, as the complexity and time demands were the main reasons for both exp. and inexp. participants not or reduce monitoring their diets.
Accurate diet identification is crucial for meaningful dietary analysis.
Thus, the system should automatically and accurately identify and log both the type and amount of food and drink consumed.


\textbf{R2. Facilitating Nutritional Analysis based on Reliable Sources.} 
Participants expected professional nutritional information, including detailed nutrient breakdowns, consistent with prior research emphasizing the importance of nutritional analysis \cite{lo2024dietary,szymanski2024integrating}.
However, they emphasized the inaccurate and incomplete databases in existing tools (9 out of 23 exp.). The system should integrate reliable food databases to support nutrition estimates covering a wide variety of items. 
Twenty-one out of 45 participants mentioned it would be helpful to track nutrition consumption.
This would help users manage their nutrition consumption to maintain health or achieve specific goals.


\textbf{R3. Providing Personalized Dietary Suggestions with Domain-Specific Knowledge.}
33 out of 45 Participants were highly interested in reliable and personalized dietary recommendations tailored to their profiles (e.g., age and weight), goals (e.g., muscle development, weight management, general wellness), and specific dietary needs (e.g., diabetes, allergies, vegetarianism), which is consistent with prior work \cite{szymanski2024integrating}. Our findings emphasized the need for seamlessly integrating domain knowledge cost-effectively.
The system should provide dietary suggestions based on individual dietary behaviors and domain-specific knowledge. Various guidances were desired, including nutrition balance, keeping fit, customized meal plans, ingredient substitutions, portion control, and dietary assessments, etc.


\textbf{R4. Protecting Privacy.} 
Privacy concerns were raised by 24 participants towards the eyewear-based dietary monitoring, especially regarding the potential of recording their phone screen and conversations with others during meals. Therefore, the system should try to reduce the capture of sensitive information during meal sessions and incorporate the mechanism to protect privacy.

\section{System Design and Implementation}
\label{sec:system}
Based on the design requirements, we developed \shortname, as shown in \figurename{~\ref{fig:pip}}. 
First, we propose a multimodal sensing approach using camera, IMU, and audio sensors on eyeglasses to detect ingestion behaviors (Sec.~\ref{sub:system:episode_detection}) and capture meal images (Sec.~\ref{sub:system:image_capture}) (\textbf{R1}, \textbf{R4}).
The processed images and user profiles were analyzed using GPT-4V to identify the type and amount of food consumed (Sec.~\ref{sub:system:dietary_analysis}, \textbf{R1}).
Unlike previous studies relying solely on LLM or requiring expert input, we further grounded the LLM with a reliable nutrition library through the RAG module to obtain nutritional analysis and personalized dietary suggestions (Sec.~\ref{sub:system:dietary_analysis}, \textbf{R2}, \textbf{R3}).
Finally, we developed a novel user interface, distinct from previous studies, that allows users to interactively review and correct data, add details, explore results, and obtain more information (Sec.~\ref{sub:system:interface}, \textbf{R1}-\textbf{R4}). All prompts are available in Supplement 1.

    \begin{figure}[!t]
          \centering
          \includegraphics[width=.8\textwidth]{Figures-clean/image-capture.pdf}
          \caption{An illustration of the multimodal sensing framework for ingestive episode detection and diet image capture.}
          \label{fig:image-cap}
           % \vspace{-0.5cm}
      \end{figure}

\subsection{Ingestive Episode Detection}
\label{sub:system:episode_detection}
Accurate detection of ingestive episodes is the first step of 
an automated diet analysis system.
\shortname leveraged IMU and audio signals and built a multimodal machine learning model to achieve the goal.
\subsubsection{Data Preprocessing and Feature Extraction}
The IMU data used included tri-axial accelerometer and gyroscope data, sampled at 800Hz and 1000Hz from two IMUs on each side of the Aria Glasses. 
The 800Hz IMU data was upsampled to 1000Hz. Audio signals, captured at 48kHz, were down-sampled to 1000Hz, at which rate the speech data is largely unintelligible, to preserve sensitive content \cite{mollyn2022samosa} (\textbf{R4}).

IMU and audio signals were normalized and segmented into one-second non-overlapping windows.
The IMU data were normalized and concatenated into a 12-channel input (two IMUs, each with a tri-axial accelerometer and a tri-axial gyroscope). The audio signals were processed by Short-Time Fourier Transform (STFT) into Melspectrogram. We further extracted statistical features for each window. For IMU, the mean, standard deviation, min, max, kurtosis, skewness, and frequency features were extracted for the two tri-axial acceleration data and two gyroscope data. To obtain the frequency features, we first computed the Fast Fourier Transform (FFT) of the IMU data and then computed the mean and peak of the magnitude of the frequency domain. For audio signals, we computed the mean, standard deviation of its Melspectrogram, Zero Crossing Rate, Spectral Centroid, Spectral Bandwidth, Spectral Rolloff, Chroma STFT, and Root Mean Square Error. The statistical features of IMU and audio data for each time window were concatenated as the statistical feature.

\subsubsection{Ingestive Episode Detection}

After feature extraction, we employed a multimodal learning model (\figurename{~\ref{fig:nn}}), building upon the framework introduced in \cite{mollyn2022samosa} and further integrating statistical features, to classify time windows as ingestive or non-ingestive activities (\textbf{R1}). Specifically, instead of distinguishing between eating and drinking, we categorized both under the broader term ``ingestive behaviors.'' This decision accounts for practical challenges, such as the overlap in actions like consuming noodle soup (involving both eating and drinking) or swallowing soft foods without chewing. This simplification aligns with the study's goals and improves usability in real-world applications.

    \begin{figure}[!t]
          \centering
          \includegraphics[width=.9\textwidth]{Figures-clean/NN.pdf}
          \caption{The multimodal learning model for classifying ingestive episodes and others.}
          \label{fig:nn}
           % \vspace{-0.5cm}
      \end{figure}




\subsection{Diet Image Capture and Segment}
\label{sub:system:image_capture}
We proposed to capture the meal images considering the pitch angle to increase the completeness of meals captured and segment the food, drink, and tableware in the images to reduce privacy concerns (\textbf{R1}, \textbf{R4}).
\subsubsection{IMU-based Pitch Angle Check}
Simultaneously with ingestive episode detection, the pitch angle was calculated from tri-axial acceleration data ($a_x, a_y, a_z$) as $pitch = arctan(a_x/\sqrt{a_y^2+a_z^2})$. When the pitch angle exceeded a threshold ($pitch_{th}=5$, indicating the user tilting their head forward), egocentric images were captured at 10fps for three seconds after a behavior transition, ensuring the meal was fully captured (\figurename{~\ref{fig:image-cap}}). This approach allowed the system to capture a series of images throughout the meal, including dishes added midway.
Although users may tilt their heads back while drinking, capturing beverages from this angle in egocentric images is challenging. By focusing on images captured when users tilted their heads downward, beverages and other meal components were recorded more effectively.

\subsubsection{Food, Drink, Tableware Segmentation}
We further segmented the food, drinks, and tableware within the images.
To exclude the food from nearby diners and include the user's meal more completely in the egocentric images, we set the bottom one-third region as the primary area of interest (detailed in Supplement 2.1). For segmentation, we employed Grounded-Segment-Anything (Grounded-SAM) \cite{ren2024grounded}, which enables precise identification based on textual descriptions. This approach allows the segmentation of a wide range of foods and drinks using class prompts and can easily accommodate new food types by adding new prompts. 
As illustrated in \figurename{~\ref{fig:image-segment}}, we first utilized the pre-trained GroundingDINO model to detect objects based on the class prompt, then applied the pre-trained SAM model to convert detections into masks. Additionally, the class prompt (detailed in Supplement 1.1) included not only food and drink categories but also tableware, as these are often the only remaining objects post-meal.

 
    \begin{figure}[!t]
          \centering
          \includegraphics[width=\textwidth]{Figures-clean/image-segment_compressed.pdf}
          \caption{An illustration of diet image capture and segment.}
          \label{fig:image-segment}
           % \vspace{-0.5cm}
      \end{figure}


\subsubsection{Irrelevant Information Blurring and Similarity Check}
After segmentation, we blurred the images except for the segmented part with Gaussian Blur \cite{jiang2023dartblur} to reduce privacy concerns and also highlight the area of interest (i.e., the meal of the user).
We then screened these images by comparing the Cosine Similarities of the features extracted from segmented parts using ResNet50 \cite{rajpal2021using} to remove redundancy. If the similarity between the segmented parts was larger than 0.75, we removed one of the images. The blurred part of the images would be further cropped to highlight the meal items and enhance privacy protection. In this way, we finally obtained a series of privacy-preserving meal images.

\subsection{Dietary Analysis}
\label{sub:system:dietary_analysis}
Based on the meal images captured across the meal session, we used a vision language model to identify various food and drink items and estimate the consumed amount (\textbf{R1}). Furthermore, we built a nutrition library and proposed to augment the LLM with a RAG module for nutritional analysis and dietary suggestions (\textbf{R2}, \textbf{R3}).
\subsubsection{Diet Identification}
LLMs, trained on diverse datasets, excel at identifying various cuisines and ingredients in images and estimating food quantities through visual cues in a zero-shot manner, offering detailed nutritional information. In this study, we select GPT-4V among all LLMs due to its superior performance in diet recognition and estimation in open-world settings \cite{lo2024dietary} (prompt available in Supplement 1.2). As shown in \figurename{~\ref{fig:llm}} (pink part), the meal log images and user profile (including gender, age, height, and weight) were fed into the GPT-4V to obtain the types and amount of each food and drink consumed by the user in this meal session.

    \begin{figure}[!t]
          \centering
          \includegraphics[width=\textwidth]{Figures-clean/LLM-v2.png}
          \caption{An illustration of RAG-grounded GPT-4V for diet identification, nutritional analysis, and dietary suggestion.}
          \label{fig:llm}
           % \vspace{-0.5cm}
      \end{figure}

\subsubsection{RAG Module Construction}
While LLMs excel in diet identification, they may generate seemingly plausible but inaccurate results, lack health guidelines, and miss domain-specific knowledge.
To address this, we integrated RAG to enhance the generative capability of LLM by incorporating knowledge from an extensive nutrition library, thereby providing a more reliable, contextually relevant, and factual response \cite{lewis2020retrieval}.

To build the RAG module, we have constructed a comprehensive nutrition library consisting of documents from a diverse collection of reliable resources.
The inclusion criteria included (1) the government-approved food nutrient database, (2) official reports and booklets on food consumption and dietary suggestions for the general public and specific groups, issued by the government or the World Health Organization (WHO), (3) webpages from official government websites, containing recipes, scientific articles about food and nutrition, and healthy diet suggestions, (4) articles published by highly trustworthy organizations (e.g., National Institutes of Health), (5) peer-reviewed research articles from prestigious journals with 28 different needs (e.g., weight management, muscle development, and blood glucose stabilization). Detailed information is available in Supplement 2.2.



We then built the RAG module using LangChain framework \cite{langchain2024}. The documents in the nutrition library were first split into chunks with LangChain's \texttt{RecursiveCharacterTextSplitter}, resulting in 16,438 pages, as shown in \figurename{~\ref{fig:llm}} (blue part). Then OpenAI's embedding model \texttt{text-embedding-ada-002} created embeddings stored with Facebook AI Similarity Search (Faiss) vector database. Based on these embeddings, the most relevant chunks will be searched based on the query to provide context for answering the query, enhancing the relevance and accuracy of the responses by incorporating the contexts. By invoking the retrieval chain created by LangChain, it would not only return the answer based on the prompt and query but also the sources of the answer from the relevant context, making the sources of dietary suggestions more transparent.

\subsubsection{Nutritional Analysis and Dietary Suggestion}

With the RAG-grounded LLM, we first use a crafted prompt (available in Supplement 1.3) to derive nutritional analysis based on the description and amount of food and drinks, including the nutrient and corresponding values. The total nutrition consumed per meal was calculated from the estimated portions. The system then checked if each nutrient intake was too high, too low, or within a reasonable range, offering suggested reference values.


We further fed the meal logs, nutrition analysis, and user profile into the RAG-grounded LLM to generate general dietary suggestions and personalized suggestions tailored to users' dietary goals, with references for these suggestions. User profiles could include general demographic information (i.e., gender, age, height, weight) and personalized dietary goals, such as muscle development, weight loss, weight control, allergen, and vegetarianism. The meal logs contained the description of meals including the consumed food and drink and the meal timing. The system used this comprehensive information to generate dietary suggestions using the RAG-grounded LLM. As shown in \figurename{~\ref{fig:llm}} (yellow part), a query containing the information of the user profile, meal logs, nutritional analysis, and the dietary goal is first used to retrieve the relevant contexts from the nutrition library. The contexts and the query will be used to build the prompt for producing tailored dietary suggestions leveraging the contextual and reasoning capabilities of the LLM.
For those without specific goals, the system provided balanced diet suggestions based on their profile and dietary behavior.

    \begin{figure}[!t]
          \centering
          \includegraphics[width=\textwidth]{Figures-clean/interface.pdf}
          \caption{Interface Overview. There are desktop and mobile versions. The interface includes four main parts: (A) Meal Image Logging, (B) Interactive Nutritional Analysis, (C) General and Personalized Dietary Suggestions, and (D) Context-Aware AI Chatbot.}
          \label{fig:interface}
           % \vspace{-0.5cm}
      \end{figure}


\subsection{Interface Design}
\label{sub:system:interface}
To support users exploring the results, seeking further details, such as explanations for specific nutrients, alternative food options, or personalized meal plans, and providing contextual information, we developed an interactive desktop and mobile interface (\figurename{~\ref{fig:interface}}) that not only displays results and suggestions but also allows users to correct errors, add missing details, and access more information. 
The interface consists of four major components: (1) Meal Image Logging (\figurename{~\ref{fig:interface}-A}), (2) Interactive Nutritional Analysis (\figurename{\ref{fig:interface}-B}), (3) Dietary Suggestion (\figurename{~\ref{fig:interface}-C}), and (4) Context-Aware AI Chatbot (\figurename{~\ref{fig:interface}-D}). 
Chronologically displayed meal log thumbnails allowed users to review their dietary patterns and access privacy-protected meal images (\figurename{~\ref{fig:interface}-A}, \textbf{R1}, \textbf{R4}), while clicking on a meal session provided detailed nutritional analysis and total nutrient consumption (\figurename{\ref{fig:interface}-B}, \textbf{R1}, \textbf{R2}). The interactive analysis enabled users to edit meal summaries and dynamically update nutritional insights and suggestions. Personalized dietary suggestions (\figurename{\ref{fig:interface}-C}, \textbf{R3}), limited to seven items for clarity, offered general guidance for a balanced diet and tailored suggestions based on user goals, with transparent source references to enhance trust. The AI chatbot (\figurename{\ref{fig:interface}-D}, \textbf{R3}) provided context-aware guidance, leveraging user profiles, meal logs, and prior interactions to deliver accurate, personalized responses, further streamlining the experience with preloaded common questions. This combination of features supported reflective, informed, and personalized dietary management. More details are available in the Supplement 2.3.


\section{Study I: Short-Term Study for Evaluating \shortname from the four design requirements}

We evaluated \shortname following the four design requirements.
Our comprehensive evaluation involves multiple stakeholders, including (1) Study I.1: short-term real-world user study to explore users' perceptions towards \shortname (\textbf{R1}-\textbf{R4}), (2) Study I.2: quantitative evaluation of \shortname's performance on diet identification and logging (\textbf{R1}), (3) Study I.3: quantitative evaluation with domain experts of \shortname's performance on nutritional analysis (\textbf{R2}), and (4) Study I.4: comparative analysis for the RAG module (\textbf{R2}, \textbf{R3}).
This study has obtained IRB approval. 


\subsection{Study I.1: Short-Term User Study to Explore Users' Perceptions towards \shortname (R1-R4)}
We implemented the proposed system and conducted a user study recruiting participants to collect data using Aria Glasses in their daily routine and explore the dietary monitoring analysis results via the user interface. Through this study, we aimed to evaluate the system's performance on the four design requirements qualitatively and quantitatively.

\subsubsection{Participants and Data Collection} 

\label{sec:par}
We recruited 33 participants (P1-P33), including 21 self-declared males (63.6\%) and 12 self-declared females (36.4\%), aged 23 to 73 ($M=30.73$, $SD=10.51$). 
The group consisted of twenty-one university students, nine senior researchers, one accountant, one retired person, and one engineer.
Twenty-one (63.6\%) participants self-reported exp. with dietary monitoring and analysis, while the remaining participants (36.4\%) were inexp. More details are available in Supplement 3.

Participants used Aria Glasses before, during, and after their meal sessions, capturing the ground truth video recordings, audio, and IMU data. Due to the power limitation of Aria Glasses, we did not ask the participants to wear the Aria Glasses all day but for periods that covered the meal sessions, which also included various behaviors like walking, sitting, talking, using mobile phones, etc. Participants reviewed their recordings and labeled the start and end of each ingestive episode, verified by the authors. Participants earned an average wage of about \$8 per hour of recording and would get about \$6.42 after finishing the user study additionally.


\subsubsection{Data Processing and Ingestive Episode Detection Performance}
Recordings were segmented into one-second windows, and if ingestive behavior occurred for more than 50\% of the window, it was labeled as ingestive; otherwise, it was labeled as others (non-eating or drinking). In total, we collected 38.23 hours of recordings, covering 144 meal sessions. Each participant contributed between two (one day without breakfast) and nine sessions ($M=4.4$, $SD$ = 1.74). Of the total, 24.78 hours were ingestive episodes, and 13.46 hours were other behaviors.
The performance of ingestive episode detection was evaluated using the leave-one-user-out (LOUO) approach, our system achieved an F1-score of 0.925, with precision at 0.939 and recall at 0.912. The LOUO method evaluates the model's generalization capacity by iteratively training it on data from all users except one, testing on the excluded user’s data, and repeating this process for each user, thereby offering a comprehensive, user-specific assessment of model performance.
Despite some time windows being misclassified, the system successfully captured the meal images across the entire meal sessions. Additionally, during image segmentation, images without target items were excluded, further enhancing system robustness and ensuring successful image capture for all 144 meal sessions.

\subsubsection{Study Settings} 
After obtaining participants' consent, we introduced the system and provided a brief tutorial on the user interface. Participants were then asked to explore their dietary monitoring results, review meal identifications for accuracy, examine dietary suggestions and nutritional analysis, and use the chatbot. We recorded their screens and tracked interactions using Google Analytics \cite{ledford2011google}.
Participants then completed a survey, including the System Usability Scale (SUS) \cite{lewis2018system}, Net Promoter Score (NPS) \cite{score2018net}, User Experience Questionnaire (UEQ) \cite{schrepp2014applying}, and questions corresponding to the four design requirements.
Finally, semi-structured interviews were conducted for open-ended feedback on their experience. Survey scales were converted to a 5-point Likert scale (1 = strongly disagree, 5 = strongly agree) to make it consistent. Detailed scale items and interview scripts are in Supplement 4. The lead author first performed a deductive thematic analysis \cite{bowman2023using} using predefined themes derived from the system's design requirements for the interviews and textual data from participants, and iteratively discussed with other authors to validate the codes and address any disagreements.

\subsubsection{User Study Results}
\label{sec:study_I_results}
We summarized the participants' perceptions towards \shortname and evaluated the system's overall usability, user satisfaction, experience, and users' interaction behaviors with the system.

\paragraph{Perception on Diet Identification and Logging (\textbf{R1})}
% Twelve participants (36.4\%) strongly agreed and twenty (60.6\%) somewhat agreed that the system accurately identified and logged their meals.
Most of the participants (12 strong, 20 somewhat; average rating 4.3/5) agreed that the system accurately identified and logged their meals.
A few challenges were noted, including difficulty identifying mixed dishes (P8, inexp.), visually similar items like sugar-free vs. regular Coke (P7, P10, P21, exp.), estimating portions during shared meals (P29, exp., P33, inexp.), and identifying cooking methods (P24, exp.). Despite these issues, participants appreciated the system's accuracy, with exp. participants valuing its automation over manual tools they had used and its ability to identify culturally specific or less common items. Both groups emphasized its effectiveness in handling a wide range of foods.


\paragraph{Perception on Nutritional Analysis (\textbf{R2})}
Most participants (90.9\%) somewhat agreed or strongly agreed with the system's nutritional analysis accuracy, citing alignment with their knowledge (e.g., seafood as high in protein, P23, exp.) and the detailed nutrient breakdown that built trust (P9, inexp.). Both groups valued actionable insights, such as identifying nutrient imbalances. 
For example, P32 (exp.) adjusted meals based on the analysis, while inexp. participants found the system educational, learning about unexpected nutritional facts (e.g., high sodium in soup, P16, inexp.).
Exp. participants often scrutinized the analysis more deeply, with some seeking clarifications via the chatbot (e.g., P2 resolved confusion about high energy and low fat).
In contrast, inexp. participants tended to rely on the system's explanations and valued its ability to reveal new insights. These findings suggest that the system may help reinforce knowledge for exp. users while serving as an educational tool for newcomers.

\paragraph{Perception on Personalized Dietary Suggestion (\textbf{R3})}
Fourteen participants (42.4\%) strongly agreed, and eight (24.2\%) somewhat agreed that the dietary suggestions aligned with their goals, with exp. participants often highlighting consistency with their existing knowledge (P31). Suggestions were deemed easy to follow by 24 participants (72.7\%), though some noted challenges in following the suggestions due to limited food options or preferences, such as P28 (exp.), who cited university canteen constraints, and P18 (exp.), who disliked certain healthy recommendations.
Trust in the suggestions was enhanced by credible sources provided, with 15 (45.5\%) strongly and 13 (39.4\%) somewhat trusting the recommendations. Exp. participants leveraged the suggestions to refine and validate their dietary practices, while inexp. participants viewed them as practical guidance for incremental improvements. Despite differing levels of reliance, both groups acknowledged the system's potential to fill knowledge gaps and facilitate healthier, goal-oriented choices.


\paragraph{Perception on Privacy Protection (\textbf{R4})}
Twelve participants (36.4\%) strongly agreed and 18 (54.5\%) somewhat agreed that their privacy was secure, while three (9.1\%) were neutral or disagreed. Similarly, 14 (42.4\%) strongly and 16 (48.5\%) somewhat agreed that data usage was transparent.
Most participants trusted the system's privacy protection due to clear communication and technical safeguards like data anonymization and secure storage. Exp. participants particularly appreciated the transparency of data handling (P15, exp.). Both groups valued visual privacy measures like background blurring, which ``\textit{made everything except the food unrecognizable}'' (P9, inexp.). However, some concerns remained about external influences: ``\textit{While I wasn't worried, my friend sitting next to me was}'' (P27, inexp.). ``\textit{Even though the speech was unrecognizable, I was still reserved when discussing sensitive topics}'' (P26, exp.).
In general, exp. participants showed greater confidence and understanding of privacy protocols, while inexp. participants required more reassurance. These findings highlight the importance of improving privacy communication to address privacy concerns and enhance trust.

\paragraph{General Usability, Satisfaction, and Experience} Our evaluation revealed broadly positive usability, satisfaction, and user experience across both exp. and inexp. participants. Exp. participants consistently rated the system higher in terms of ease of use, automation, and efficiency, while inexp. participants highlighted challenges in adapting to workflows and interacting with the system. Satisfaction scores averaged 8.3 (NPS), with high utility acknowledged by most participants. However, the physical discomfort from prolonged wearing of glasses (such as heat buildup around the glasses' legs, sweat accumulation, and slippage due to the limited glasses sizes provided) and workflow complexity emerged as areas for improvement, particularly for less tech-savvy users. Details on these assessments, including SUS, NPS, and UEQ metrics, are provided in Supplement 5.


% \paragraph{Challenges in Capturing Meals using Eyeglasses}}
% While both exp. and inexp. participant participants expressed high satisfaction with the system, they faced challenges, including (1) discomfort from prolonged use, such as heat buildup around the glasses' legs, sweat accumulation, and slippage due to the limited glasses sizes provided,
% (2) difficulty in identifying visually similar items and seasonings, particularly in complex dishes, and (3) challenges with portion estimation in shared meal scenarios. These challenges highlight the need for further refinement of the system.



\paragraph{User Interactions and Engagement}
Participants spent an average of 10.10 minutes per session (2.59 minutes per meal).
Reviewing dietary suggestions averaged 2.82 minutes. Inspecting nutritional analysis averaged 5.05 minutes, indicating participants prioritized understanding their diet over simply viewing suggestions.
Manual corrections were minimal, with 27 changes across 144 meal sessions, mostly involving beverages (e.g., from ``\textit{Coke}'' to ``\textit{Coke Zero}''). Users also corrected misidentified items or cooking methods (e.g., ``\textit{grilled pork}'' to ``\textit{grilled duck}'' or ``\textit{steamed}'' to ``\textit{fried}''). Despite features designed to reduce errors of including nearby meals, occasional deletions of extra items indicate room for improvement.
Participants also engaged actively with the chatbot, logging 125 conversation pairs (average of 3.79 per participant), primarily for meal planning with constraints such as ``\textit{in Chinese style}.'' 
Iterative interactions, like P6 refining meal plans to exclude breakfast or avoid certain foods (full chat history is available in Supplement 6), demonstrated the chatbot's adaptability in addressing preferences and fostering personalized dietary management.
Overall, the system's core features were actively utilized, with strong engagement enhancing the personalized user experience and demonstrating the system's value in dietary monitoring and analysis.


\paragraph{Comparison with Other Dietary Tracking Technologies}
Participants highlighted that the system's hands-free, automatic tracking made it more convenient than many mobile apps requiring manual logging.
Additionally, participants valued the interactive features of our system, which allowed them to follow up on initial analysis. Unlike traditional apps with static data entry, our system allowed users to ask for more information. This dynamic, engaging experience enabled users to actively adjust their dietary behavior based on continuous feedback, enhancing their understanding of nutrition and empowering better food choices.

\subsection{Study I.2: Quantitative Evaluation with Crowd Workers on Diet Identification and Logging Performance (R1)}
With the successfully captured meal images for all 144 sessions, we assessed diet identification accuracy by comparing the ground truth food and drink items with the text descriptions inferred by the LLM from the processed images.
However, this agreement can be complex and ambiguous due to the intricate nature of the dishes. 
For instance, a bowl of noodles with soup, carrots, and beef could be viewed as one item (the whole dish), three items (noodle soup, carrots, beef), or four distinct components (noodles, soup, carrots, beef). Text descriptions may only mention ``\textit{noodle soup and beef},'' leading to varying accuracy scores: 0/1 (missed the whole dish), 2/3 (correctly identified two out of three items), or 3/4 (identified three out of four items).
Besides, some dishes, like Malatang or Hot Pot, are especially challenging to identify every ingredient, even for humans. Therefore, we set the ground truth based on items visually identifiable by humans. We used a crowdsourcing approach to quantitatively evaluate the diet identification and logging performance.

\subsubsection{Evaluation Settings}
We used a crowdsourcing approach, presenting processed meal images (extracted from the video but cropped for privacy) alongside the LLM-generated text descriptions to crowd workers recruited from AWS MTurk \cite{cheung2017amazon}. Crowd workers worked independently. Specifically, due to the complexity of dishes and the high burdensome of measuring exact ingredient quantities, we employed an indirect evaluation of diet item quantity estimation by evaluating the nutrient estimation performance, since nutrient estimation involves quantity inference, as detailed in Sec.~\ref{subsec:eva_nutrition}.

\subsubsection{Evaluation Metrics}

The crowd workers were tasked with determining the following:

\begin{itemize}
    \item Correct Items ($C$): Items in the ground truth images correctly identified in the text description.
    \item Image Items ($I$): Items presented in the meal log images.
    \item Text Items ($T$): Items mentioned in the text description. 
\end{itemize}

We filtered out those unqualified answers with the following rules:

\begin{itemize}
    \item The number of correct items ($C$) should not exceed that of items in images ($I$) or text ($T$), i.e., $C\leq I$ and $C\leq T$.
    \item The numbers of items in images ($I$) or text ($T$) should be greater than zero, i.e., $I>0$ and $T>0$.
    \item Task completion time must be at least 60 seconds. 
    \item The number of text items must align with the number of items after splitting the text using commas.
\end{itemize}

Each meal was labeled by 10 qualified crowd workers. Workers could get \$0.1 for each qualified label. We then calculated precision, recall, and F1-score.
% as follows: 

% \begin{itemize}
%     \item \textbf{Precision}: proportion of correctly identified items in the text description. The precision of meal $i$ is 
%     % \[
%     $\text{precision}_i = \frac{1}{10}\sum_{j=1}^{10}\frac{C_{ij}}{T_{ij}}$, $\text{macro-averaged precision} = \frac{1}{N}\sum_{i=1}^N\text{precision}_i$.
%     % \]
%     $N$ is the number of meals.
%     \item \textbf{Recall}: proportion of correctly identified items in images, i.e.,
%     % \[
%     $\text{recall}_i = \frac{1}{10}\sum_{j=1}^{10}\frac{C_{ij}}{I_{ij}}$, $\text{macro-averaged recall} = \frac{1}{N}\sum_{i=1}^N\text{recall}_i$.
%     % \]
%     \item \textbf{F1-Score}:
%     % \[
%     $\text{F1-Score}_i = 2\times\frac{\text{precision}_i\times\text{recall}_i}{\text{precision}_i+\text{recall}_i}$, $\text{macro-averaged F1-Score} = \frac{1}{N}\sum_{i=1}^N\text{F1-Score}_i$.
%     % \]
% \end{itemize}


\subsubsection{Results}
Based on the crowd worker labels, the proposed system achieved an average F1-score of 0.972, with a precision of 0.957 and a recall of 0.989, demonstrating the effectiveness of \shortname in diet identification. 
The meal that achieved the lowest precision (0.643) included a bowl of noodles with various ingredients, such as blood cubes, bean sprouts, sliced meat, green onions, and tomatoes, making it difficult for LLM to correctly identify the ingredients from the processed meal log images. 
The meal with the lowest recall (0.853) contained a bowl of rice with grilled fish, lemonade (with small pieces of onion and Seaweed on the top), a bowl of clear soup, and a cup of milk tea. \shortname failed to describe those small ingredients. 
Overall, the system performed well, particularly on Western-style dishes with clearly separated components. Highly complex meals like Malatang and Hot Pot did not perform the worst; this might be because their ingredients are very difficult to describe even for the crowd workers.

\subsection{Study I.3: Quantitative Evaluation with Experts on Nutritional Analysis Performance (R2)}
\label{subsec:eva_nutrition}
We held a panel with Food and Nutrition Science experts who highlighted the difficulty of determining nutrient values due to factors like ingredient freshness, cooking methods, portion sizes, storage conditions, and ingredient interactions during cooking \cite{willett2012nutritional}, etc.
Despite this variability, experts can estimate nutrients using food composition databases, standardized recipes, and their experience with similar meals. 
\subsubsection{Evaluation Settings}
Recognizing the variability in nutrient estimation, we recruited ten food and nutrition experts, including six nutrition interns, three researchers, and one Accredited Practicing Dietitian. They independently analyzed meal data (the ground truth meal images across the eating process), referencing the database provided by the Centre of Food Safety of the Government of the Hong Kong SAR database, with each meal randomly assigned to five experts for estimation. Each expert received about \$25 for compensation.


\subsubsection{Evaluation Metrics} We measured expert agreement using the Intraclass Correlation Coefficient (ICC), showing high reliability of the average estimation from experts with ICC(2,k) > 0.9 (more details in Supplement 7). 
Therefore, to evaluate \shortname's performance, we compared its estimation to the expert averages using Mean Absolute Percentage Error (MAPE) due to varying nutrient units and scales, calculated as: ${MAPE = \frac{1}{N}\sum_{n=1}^{N}|\frac{\overline{E}_n-S_n}{\overline{E}_n}|\times 100\%}$,
% \begin{equation}
%     MAPE = \frac{1}{N}\sum_{n=1}^{N}\frac{\overline{E}_n-S_n}{\overline{E}_n}\times 100\%},
% \end{equation}
where $N$ is the number of meals. $\overline{E}_n$ and $S_n$ are the average estimations of experts and the system, respectively.

    \begin{figure}[!t]
          \centering
          \includegraphics[width=.9\textwidth]{Figures-clean/mape.png}
          \caption{The results of MAPE (\%) in Studies I.3 and I.4. Lower values indicate better performance.}
          \label{fig:mape}
           % \vspace{-0.5cm}
      \end{figure}

\subsubsection{Results}
As shown in \figurename{~\ref{fig:mape}}, the system demonstrated high accuracy for key macronutrients, including energy (9.13\%), protein (11.70\%), total fat (12.80\%), and carbohydrates (10.05\%). These macronutrients are major food components and are typically well-documented in databases, making them easier for \shortname to estimate accurately. Given the challenges in nutrient estimation, such as variations in food composition databases, portion size estimation errors, and the difficulty of accurately assessing mixed dishes, a MAPE around 10\% is considered a strong result \cite{kipnis2002bias, thames2021nutrition5k}.

Moderate accuracy was achieved for nutrients like calcium (25.19\%), iron (24.76\%), cholesterol (22.75\%), dietary fiber (21.27\%), and zinc (25.28\%), possibly due to their greater variability across food sources and bioavailability, complicating precise estimation. The system exhibited poor alignment with experts' estimation of phosphorus (53.02\%) and potassium (74.90\%). These nutrients are known to exhibit significant variability across different foods due to a variety of factors, such as plant and animal growth conditions, differences in food type, preparation, and source \cite{world2004vitamin}. This variability, combined with the effects of processing and cooking methods, makes accurate estimation particularly challenging.

Overall, the system highlighted its strengths in estimating macronutrients with an average MAPE of 17.92\% but faced difficulties with more variable micronutrients (MAPE=35.64\%).


\subsubsection{Post-Analysis Discussion with Experts}
We held a panel discussion with the experts to analyze the results with two themes: (1) reasons for low performance in specific nutrients and (2) key nutrients for dietary analysis and suggestions.

(1) Experts observed a lack of detailed ingredient information and documentation, especially for compound dishes like Chinese-style food, where oils, seasonings, and cooking methods significantly affect nutrient content. 
For example, the official nutrition database used for estimations often failed to include many compound dishes, requiring experts to estimate ingredients separately without accounting for preparation methods, such as temperature and seasoning.
This lack of detail led to inaccuracies in estimating micronutrients like potassium and phosphorus, as the types of vegetables or seafood can significantly influence these calculations but were difficult to distinguish from the images.

(2) The experts valued the system's overall performance for daily dietary tracking, since the important nutrients, such as the macronutrients, calcium, and iron, have a relatively lower MAPE. While all nutrients are important, they noted that potassium and phosphorus, which showed poor performance, are typically less emphasized in general dietary analysis. 
Experts suggested improving the accuracy of magnesium, vitamin C, and sodium estimates and highlighted potential biases due to dish complexity and portion size estimation. 
However, higher accuracy was expected in clinical contexts where more precise nutrient intake is essential. In this context, the important nutrients depend on the purpose of conducting a nutritional analysis. For example, potassium and phosphorus are important to kidney patients.

\subsection{Study I.4: Comparative Analysis for \shortname with and without RAG (R2, R3)}
To demonstrate the effectiveness of the RAG module, we conducted a comparative analysis to explore the \shortname's performance on nutritional analysis and personalized dietary suggestions with (w/) and without (w/o) RAG, including (1) comparing the nutritional analysis results of \shortname w/ RAG (Study I.3) and w/o RAG, and (2) comparing the quality of dietary suggestions w/ and w/o RAG.


\subsubsection{Comparing the nutritional analysis results of \shortname w/ RAG (Study I.3) and w/o RAG}
We compared the MAPE of nutrition estimation w/o RAG with the results in Study I.3. As shown in \figurename{~\ref{fig:mape}}, the system w/ RAG presented lower or close MAPE values in most of the nutrients compared to the system w/o RAG. The system w/o RAG resulted in significantly higher errors in sugar, calcium, and sodium. This indicates that RAG enhances the system's predictive accuracy, especially for some nutrients that could hidden in sauces, condiments, and bone broth. Since most of the meals collected were Chinese-style, which tend to have higher sodium content due to the frequent use of sodium-rich condiments and seasonings, the lack of the RAG module likely exacerbated the system's inability to account for the variability in sodium levels.
The results demonstrated that while the LLM w/o RAG could achieve satisfactory performance on some nutrients, the incorporation of RAG further enhanced the system's nutritional analysis capacity, particularly in handling the complexities and variabilities of diverse and culturally sensitive diets.


\subsubsection{Comparing dietary suggestion quality w/ and w/o RAG}

With the data of 33 participants collected in Study I.1, we obtained two versions of dietary suggestions w/ and w/o the RAG module and compared the quality of dietary suggestions from two perspectives: (1) widely-used metrics for generative AI and (2) expert evaluation.

\textbf{Metrics for Generative AI.} AI-assisted metrics that are widely used for evaluating the AI-generated responses \cite{li2024leveraging} were used to evaluate the quality of dietary suggestions. GPT-4 was used as a grader to rate the responses with a score between 1 and 5, where 1 is the lowest quality and 5 is the highest quality. To compare the responses w/ and w/o RAG, the following metrics from Azure AI Evaluation SDK\footnote{Azure AI Evaluation SDK: \url{https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk}} were used:

\begin{itemize}
    \item \textit{Relevance-Q} measures the accuracy, completeness, and direct relevance of the response given the query.
    \item \textit{Coherence} measures the logical and orderly presentation of ideas in a response.
    \item \textit{Fluency} measures the effectiveness and clarity of written communication.
\end{itemize}
Since suggestions w/ and w/o RAG were evaluated independently, we used G$^*$Power \cite{faul2009statistical} to determine the sample size by setting the effect size $d=0.5$ (moderate effect), the significant threshold $\alpha=0.05$, and a statistical power $(1-\beta)=0.8$, resulting in a sample size of 128. Each document was graded twice independently, resulting in 66 grades per group (132 total). We then conducted the Mann-Whitney U Test with a significance level of 0.05 to compare the \textit{Relavance-Q}, \textit{Coherence}, and \textit{Fluency} of dietary suggestions generated w/ and w/o RAG.

\textbf{Expert Evaluation.} We employed a pairwise comparison method using 33 dietary suggestions pairs, each consisting of one version w/ RAG and one w/o. Three experts from Study I.3 were recruited with about \$12.9 compensation. They were independently tasked with comparing the paired documents across the following dimensions:

\begin{itemize}
    \item \textit{Relevance-G} measures if the suggestions are tailored to the dietary goals and profile of the participant.
    \item \textit{Actionability} measures if the recommendations are practical and easy to implement for users.
    \item \textit{Accuracy} measures if the suggestions are factually correct and nutritionally valid.
\end{itemize}
To minimize bias, we hid the sources for the RAG version, ensuring consistent output formats. The documents in pairs were randomly labeled as ``A'' and ``B'', with the order of presentation varying randomly for each expert. 
Each pair was evaluated independently by the experts.
The score scale was also between 1 and 5, with 1 being the lowest quality. After obtaining the scores, we conducted statistical analysis and discussed with experts to justify the results.

\textbf{Results.}
The Mann-Whitney U Test revealed that w/-RAG suggestions ($M=3.80$, $SD=0.92$) had significantly higher \textit{Relevance-Q} ($U=2655.5$, $p=0.01$) than w/o-RAG ones ($M=3.39$, $SD=0.81$).
W/-RAG suggestions ($M=4.65$, $SD=0.62$) also had significantly higher \textit{Coherence} ($U=2555.0$, $p=0.04$) than w/o-RAG ones ($M=4.38$, $SD=0.79$). W/-RAG suggestions ($M=4.13$, $SD=0.34$) also outperformed w/o-RAG suggestions ($M=4.0$, $SD=0.00$) in \textit{Fluency} ($U=1881.0$, $p<0.01$). 
The results showed that while both dietary suggestions w/ and w/o RAG achieved high grades in these metrics, the dietary suggestions w/ RAG had significantly higher relevance to the query, coherence, and fluency.

For the expert evaluation, we first assessed inter-rater agreement among the three experts using ICC(2,k), yielding a value of 0.893, indicating good consistency. Based on this, we averaged the experts' ratings and conducted the Wilcoxon Signed-Rank Test at a significance level of 0.05. Calculated using G$^{*}$Power, the achieved power was 0.795, with an effect size of $d=0.5$ and a sample size of 33 pairs.
The results showed that while the mean \textit{Relevance-G} of w/-RAG suggestions ($M=4.23$, $SD=0.70$) was slightly higher than w/o-RAG ones ($M=4.21$, $SD=0.81$), the difference was not significant ($W=37.0$, $p=0.87$). Experts noted that although RAG suggestions were tailored, some contained overly complex or nuanced recommendations, potentially reducing their perceived relevance, likely due to the inclusion of many academic articles in the nutrition library.
For \textit{Actionability}, with-RAG suggestions ($M=4.25$, $SD=0.37$) showed a slight but not significant improvement over without-RAG ones ($M=4.09$, $SD=0.31$, $W=26.5$, $p=0.06$). Experts observed that RAG suggestions often included practical advice (e.g., meal preparation strategies) but were sometimes challenging to implement.
Finally, \textit{Accuracy} was significantly higher ($W=32.0$, $p=0.01$) for with-RAG suggestions ($M=4.78$, $SD=0.27$) compared to without-RAG suggestions ($M=4.62$, $SD=0.36$). Experts emphasized that RAG-based suggestions were factually accurate and nutritionally valid, while without-RAG suggestions, though accurate, lacked the context-specific precision offered by RAG.

\section{Study II: Four-Week Longitudinal Study}
To evaluate the long-term effect of \shortname on users' dietary patterns, we recruited 16 participants from Study I for a 4-week longitudinal study with IRB approval, including 4 females and 12 males (P1, P6, P7, P10, P13, P15, P18, P20, P21, exp., P3, P8, P9, P14, P16, P17, P22, inexp.), aged 24 to 33 ($M=28.3$, $SD=2.4$).
% \subsection{Research Questions}
% Building on the design requirements and findings from Study I, this study aims to answer: (\textbf{RQ1}): What are the long-term perceptions and behaviors of exp. and inexp. participants toward \shortname? and (\textbf{RQ2}): How does \shortname affect exp. and inexp. participants' dietary patterns over time?
Building on the design requirements and findings from Study I, this study aims to explore how exp. and inexp. participants perceive and use \shortname over time, and how it affects their dietary patterns.
% the long-term perceptions and behaviors of exp. and inexp. participants toward \shortname and its effect on participants' dietary patterns.
% (\textbf{RQ2}): How does \shortname affect exp. and inexp. participants' dietary patterns over time?
% \end{itemize}

\subsection{Study Settings}

Before conducting the longitudinal study, we made system updates based on feedback from Study I:
\begin{itemize}
    \item Added frequently asked questions to the chatbot's common questions list.
    \item Incorporated users' habits (e.g., drinking Coke Zero instead of regular Coke) into prompts to refine diet identification.
    \item Asked the participants to report the number of people sharing a meal, adjusting consumption proportion accordingly (assume equal portions for all).
\end{itemize}

During the study, participants were encouraged to use Aria Glasses covering as many ingestive behaviors (meals and snacks) as possible to gain comprehensive insights into their habits and use the interface to review their dietary monitoring results. 
The interface was available 24/7, except from 12:00 am to 5:59 am for potential maintenance and backup, and was tracked via Google Analytics. 
Meal data older than seven days was archived, with analysis based on the most recent seven days to reflect current dietary patterns. Participants provided weekly feedback through questionnaires and interviews (details in Supplement 4).
Participants received about \$17 every week and could review their monitoring and analysis results whenever the interface was available.

We presented the descriptive statistics of the participants' ratings towards the four design requirements, general usability, user satisfaction, user experience, and nutrient consumption to show the trends across the four weeks. For interviews and textual data, the lead author performed the initial thematic coding and iteratively discussed with other authors to finalize the codes to analyze the impact of \shortname on participants' dietary behaviors and their suggestions for improvement.

\subsection{Results}
\label{sec:study_II_results}
During the study, 821 meal or snack sessions were involved ($M=51.3$, $SD=13.6$).
The variation in session collected was mainly due to individual dietary habits (e.g., some participants skipped meals like breakfast) and practical challenges. Specifically, the Aria Glasses had limited battery life, and some participants had vision correction needs. We were unable to replace the lenses to match participants' prescriptions, which affected their ability to consistently wear the glasses and log every meal, especially in some formal dining occasions involving social or business gatherings. To accommodate these challenges and reduce participant burden, we allowed occasional missed sessions to maintain engagement. As a result, a total of 245 meal sessions (23.0\%, 15.3 per participant) were missed.

Even though some participants had fewer sessions, analyzing these data still revealed consistent patterns and unique behaviors, offering insights into dietary practices. This approach captures real-world variability, providing a more comprehensive understanding of different eating habits. Detailed analysis results are discussed below.

 \begin{figure*}[!t]
          \centering
          \subfloat[]{
            \centering
            \includegraphics[width=.25\textwidth]{Figures-clean/diet_logging.png}
            \label{fig:r1}
          }
          \subfloat[]{    
                  \centering
                  \includegraphics[width=.25\textwidth]{Figures-clean/nutrition.png}
              \label{fig:r2}
          }
          \subfloat[]{    
                  \centering
                  \includegraphics[width=.25\textwidth]{Figures-clean/suggestion.png}
              \label{fig:r3}
          }
          \subfloat[]{    
                  \centering
                  \includegraphics[width=.25\textwidth]{Figures-clean/privacy.png}
              \label{fig:r4}
          }
          \caption{The weekly trends of the scores of exp., inexp., and all participants on (a) Diet identification and logging, (b) Nutritional Analysis, (c) Personalized Dietary Suggestions, and (d) Privacy Protection. The values above the bars are the mean (standard deviation).}
          \label{fig:scales-r}
           % \vspace{-0.5cm}
      \end{figure*}

\subsubsection{Long-Term Perception on Diet Identification and Logging, Nutritional Analysis, Personalized Dietary Suggestions, and Privacy Protection}

\figurename{~\ref{fig:scales-r}} shows that generally the ratings of exp. participants were higher than inexp. participants, except for the privacy protection in the first week. While exp. participants demonstrated steady or increasing satisfaction, particularly for privacy protection and personalized suggestions, inexp. participants often struggled, with ratings plateauing or declining over time, as seen in diet identification and logging. Privacy protection scores remained consistently high and even increased, reflecting growing user trust in the system's privacy safeguards. The ratings of the diet identification and logging and nutritional analysis decreased, potentially due to the increasing variety of diets. 
Personalized dietary suggestions showed a notable gap, with exp. participants finding them more effective, suggesting that exp. participants are likely more skilled in leveraging the system's features to tailor them effectively to their specific needs and preferences.


\subsubsection{Usefulness}
There were nuanced differences in how exp. and inexp. participants engaged with the system.
In the first week, participants highlighted the accuracy of diet identification, with its success in identifying less common or culturally specific dishes, such as soba noodles (P21) and Hainanese chicken (P15).
Throughout the study, nutritional analysis and dietary suggestions were consistently valued for providing insights into nutrient consumption and deficiencies (P15, P18). 
Exp. participants appreciated source-backed suggestions and the ability to track nutrition trends (P6), while both groups valued meal timing feedback, like reminders to eat regularly and slow down (P17, P15, P20).
The AI chatbot was helpful in planning meals and offering actionable nutritional knowledge (P1, P7, P15, exp.). The chatbot's professional tone and cited sources made it feel like ``\textit{chatting with a real nutritionist}'' (P16), suggesting its effectiveness in bridging gaps in users' nutritional knowledge.
Meal log images were useful to both groups for meal recall, with exp. participants tending to use them to verify and refine diet summaries. These differences highlight exp. participants' active interrogation of the system and the supportive reliance of inexp. users.

\subsubsection{Long-Term General Usability, User Satisfaction, and User Experience}
Usability improved throughout the study, with SUS scores rising from 76.09 in Study I to 85.00 by the end of Study II, reflecting increased perceived usability. Exp. participants consistently rated the system higher, while inexp. ones showed steady improvement, highlighting adaptability. NPS scores also rose, indicating sustained satisfaction across both groups. User experience, measured through UEQ dimensions, showed positive trends in attractiveness, efficiency, and dependability, while stimulation and novelty declined slightly, reflecting reduced novelty as users became familiar with the system. These findings emphasize the \shortname's high usability, satisfaction, and user experience, highlighting the need for tailoring onboarding processes and maintaining engagement, particularly for inexp. users. More details are in Supplement 8.


\subsubsection{Long-Term Interaction Behaviors with \shortname}
Participants demonstrated consistent engagement with the system over four weeks, averaging 38.13 usage sessions. Exp. showed slightly higher engagement than inexp. ones. Initial novelty drove higher interactions in Week 1, which gradually stabilized into routine usage by Week 3. The average engagement time per session was 5.95 minutes, with exp. participants spending longer on average, reflecting deeper interaction with the system. The relatively low number of logged updates to diet summaries highlighted the system's accuracy, while sustained chatbot interactions demonstrated its role in enhancing personalization and feedback. More details are available in the Supplement 9.


 \begin{figure*}[!t]
          \centering
          \subfloat[Energy$^{***}$]{
            \centering
            \includegraphics[width=.19\textwidth]{Figures-clean/Energy.png}
            \label{fig:energy}
          }
          \subfloat[Protein$^{*}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Protein.png}
              \label{fig:protein}
          }
          \subfloat[Total Fat$^{***}$]{    
                  \centering
                  \includegraphics[width=.195\textwidth]{Figures-clean/Total-Fat.png}
              \label{fig:total_fat}
          }
          \subfloat[Trans Fat$^{*}$]{    
                  \centering
                  \includegraphics[width=.189\textwidth]{Figures-clean/Trans-Fat.png}
              \label{fig:trans_fat}
          }
            \subfloat[Saturated Fat$^{***}$]{    
                  \centering
                  \includegraphics[width=.195\textwidth]{Figures-clean/Saturated-Fat.png}
              \label{fig:saturated_fat}
          }\\
          \subfloat[Dietary Fibre$^{***}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Dietary-Fibre.png}
              \label{fig:dietary_fibre}
          }
        \subfloat[Sugars$^{***}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Sugars.png}
              \label{fig:sugar}
          }
          \subfloat[Cholesterol$^{***}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Cholesterol.png}
              \label{fig:cholesterol}
          }
          \subfloat[Carbohydrate$^{***}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Carbohydrate.png}
              \label{fig:carbohydrate}
          }
          \subfloat[Calcium]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Calcium.png}
              \label{fig:calcium}
          }\\
          \subfloat[Copper]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Copper.png}
              \label{fig:copper}
          }
          \subfloat[Magnesium$^{*}$]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Magnesium.png}
              \label{fig:magnesium}
          }
          \subfloat[Manganese]{    
                  \centering
                  \includegraphics[width=.19\textwidth]{Figures-clean/Manganese.png}
              \label{fig:manganese}
          }
          \subfloat[Zinc]{    
                  \centering
                  \includegraphics[width=.195\textwidth]{Figures-clean/Zinc.png}
              \label{fig:zinc}
          }
          \subfloat[Iron$^{***}$]{    
                  \centering
                  \includegraphics[width=.195\textwidth]{Figures-clean/Iron.png}
              \label{fig:iron}
          }
          \caption{The consumption trends of different nutrients in Study II. The error bar shows the standard error. Coefficients ($\beta$) and p-values ($p$) from the mixed linear model are shown in the legends with a significant level of 0.05.}
          \label{fig:nutrient-trend}
           % \vspace{-0.5cm}
      \end{figure*}

\subsubsection{Impact of \shortname on Users' Dietary Patterns}

\

\textbf{Nutrient Consumption Trends.}
To present the nutrition consumption trends across four weeks, we calculated the weekly mean nutrient consumption with min-max normalization. Only nutrients with MAPE < 30\% were included. A Mixed Linear Model assessed the trends.
As shown in \figurename{~\ref{fig:nutrient-trend}}, significant negative trends were observed in energy, total fat, saturated fat, cholesterol, and carbohydrates for both exp. and inexp. groups, suggesting a shift towards a lower-calorie, lower-fat diet. The exp. group also showed a significant reduction in sugar and magnesium, while dietary fiber and iron saw positive trends for both groups, indicating improved consumption of these beneficial nutrients.
Fluctuating trends were noted for trans fat, calcium, copper, manganese, and zinc, potentially reflecting variations in food choices and external factors like meal composition and food availability, while the inexp. group showed more variation in sugar and magnesium.
Overall, these trends indicate a potential shift towards healthier diets, with reductions in unhealthy fats and sugars, and increases in fiber and iron.

\textbf{Increasing Understanding of Current Dietary}. 
Both exp. and inexp. participants reported an increased understanding of their dietary habits. P6 (exp.) noticed the high sodium content in cafeteria soup, which aligned with news she had seen about soups being high in salt and purines. She also observed that eating pizza consistently pushed her calorie consumption above the recommended levels. Inexp. participants (e.g., P22) also benefited from understanding their food choices but tended to rely more on general suggestions without deeper dietary analysis.
Nearly all participants realized their meals lacked vegetables and fruit, which is a common issue in the location where this study was conducted.
P7 (exp.) mentioned that using the system made him more mindful of food nutrient content.

\textbf{Raising Awareness of Regular Meal Timing.} 
Over the second to fourth weeks, many participants reported being more conscious of their meal timing. Some participants who used to skip breakfast started to have some breakfast intentionally (P1, P6 exp., P16, inexp). P6 also reported that the system reminded her to eat slowly and enjoy your food without distractions, which was surprising and helpful. 


\textbf{Promoting Healthier Dietary Habits.}
While many participants had low fruit and vegetable consumption before, both exp. and inexp. participants reported that \shortname made them intentionally have more vegetables and fruits (P1, P10, P20, exp., P3, P9, P14, P16, P17, P22, inexp.), which also align with the nutrient consumption trends in \figurename{~\ref{fig:dietary_fibre}}.
``\textit{Before using this system, I rarely ate vegetables}'' (P22).
Participants also followed system suggestions to achieve dietary goals. For example, P17, aiming to gain weight, increased his consumption of protein-rich foods like tofu and chicken as recommended. 
P9 noted that she began turning down social meals when not hungry, a change from her previous habit of always joining them regardless of hunger.


\textbf{Reducing Consumption of Unhealthy Foods.}
Both exp. and inexp. participants reported reducing their consumption of sugary drinks, high-calorie foods, and other unhealthy items, following the system's recommendations (P6, P10, P13, P15, P20, P21, exp., P14, P16, inexp.), with inexp. participants show greater changes, as demonstrated in Figs. 13(d)(e)(g)(h)(i). 
For instance, P6 reduced carbohydrate intake by switching from Ovaltine to lemonade, and P20 chose low-sugar beverages or avoided drinks altogether.
P21 observed a reduction in his overall calorie intake after cutting back on staple foods like rice and noodles, as presented in the system. P13 also noticed more nutrients falling within the recommended values as he followed the system's dietary advice.


\textbf{No Significant Changes Due to External Constraints.} 
While most participants reported positive changes, P8 (inexp.) noted that it was difficult for him to make significant changes due to limited restaurant options. However, he did make slight adjustments based on the system's suggestions when selecting dishes. 

In summary, after four weeks of using the system, participants reported significant improvements in their dietary awareness and management. 
Exp. participants generally used the system's advanced features to analyze and modify dietary habits in a more targeted way, focusing on specific nutrients and meal planning. In contrast, inexp. participants were more likely to rely on broad suggestions and reported simpler but still effective dietary changes.
Overall, the experience was viewed as beneficial, with users adopting a more mindful and structured approach to their diets and expressing optimism about continued use.



\subsubsection{Suggestions for Improvement}

\

\textbf{Nutrients of Interest.}
Participants (P1, P6, exp.) found the detailed nutrient analysis overwhelming and suggested a customizable display with automatic prioritization of key nutrients based on individual goals for higher relevance.

\textbf{Incorporation of More Contexts.}
Inexp. participants (P8, P9) recommended that the system better accommodate eating environments, such as cafeterias with limited options, by offering meal suggestions based on available menus.

\textbf{Increasing Specificity in Dietary Suggestions.}
Exp. participants, P10 and P13, sought more specific dietary recommendations, such as the exact weight of food to consume, rather than broad advice like ``\textit{increase protein intake}.''

\textbf{Integration with Other Health Data.}
Both exp. and inexp. participants (P3, P6, and P16) suggested integrating the system with other health apps, like fitness trackers, to combine dietary data with physical activity and sleep metrics, providing a more comprehensive view of overall health.

\textbf{Real-Time Notifications.}
Both exp. and inexp. participants (P15, P22) recommended real-time notifications to alert users when their nutrient intake is too high or low, helping them stay aligned with their dietary goals.

\section{Discussion}

% We proposed \shortname, a holistic dietary monitoring and analysis system using smart glasses, which combined multimodal inputs with a RAG-augmented LLM.
% A short-term user study demonstrated its effectiveness in detecting ingestive episodes and identifying various dishes, providing comprehensive nutritional analysis and personalized dietary suggestions in real-world uncontrolled environments. 
% The comparative analysis showed that the RAG module improved the relevance to the query, coherence, fluency, and accuracy of dietary suggestions.
% A four-week longitudinal study showed our system positively impacted the users' dietary behaviors.
% We identified challenges, including difficulties with visually similar items, issues with portion estimation in shared meals, and gaps in micronutrient estimation.
% In our study, while the exp. participants tended to be more engaged with the system and leveraged the system's advanced features (such as obtaining detailed plans through conversations with the chatbot), the inexp. participants were more likely to directly follow the system-generated suggestions, especially those simpler ones.

% \textcolor{ccolor}{Unlike previous works, our study presents a holistic dietary monitoring and analysis system, \shortname, deployed in free-living conditions with both desktop and mobile interfaces. By design, our system differs from others by incorporating both multimodal sensor data and AI-driven analysis to offer personalized, context-aware dietary suggestions.
% Through both quantitative and qualitative evaluation, we demonstrated the system's effectiveness and usability. 
% Participants appreciated the efficiency of the system, which integrated smart glasses and the reasoning capabilities of the LLM to provide automated dietary monitoring and analysis. They highlighted its ability to identify diverse dishes, including culturally specific cuisines, and deliver personalized dietary insights based on their daily behaviors. Moreover, the context-aware chatbot enabled them to continuously interact with the system to obtain more personalized information, supporting proactive engagement of dietary behaviors.
% However, they noted challenges with glasses discomfort, identifying visually similar items, and portion estimation during shared meals. On the other hand, while the experts highlighted the system's value for general dietary tracking, more accurate estimations of specific nutrients are needed in clinical contexts.
% These findings confirm the system's strengths while identifying areas for improvement. In this section, we further discuss the design considerations for future dietary monitoring and analysis systems. Then, we discuss the generalizability and limitations of this work.}


We proposed \shortname, a holistic dietary monitoring and analysis system using smart glasses. Deployed in free-living conditions with both desktop and mobile interfaces, our system differs from others by integrating multimodal inputs with knowledge-empowered AI analysis. 
A short-term user study demonstrated its accuracy in diet identification and logging, providing comprehensive nutritional analysis and personalized dietary suggestions in real-world uncontrolled environments. The comparative analysis showed that the RAG module improved the relevance to the query, coherence, fluency, and accuracy of dietary suggestions. Additionally, a four-week longitudinal study indicated that our system positively impacted users' dietary behaviors.
% Through both quantitative and qualitative evaluations, we demonstrated the system's effectiveness and usability. 
Participants appreciated the efficiency of the system by providing automated dietary monitoring and analysis. They highlighted its ability to identify diverse dishes, including culturally specific cuisines, and deliver personalized dietary insights based on their daily behaviors. Moreover, the context-aware chatbot enabled continuous interaction, allowing users to obtain more personalized information and supporting proactive engagement in dietary behaviors. 
However, challenges were identified, including difficulties with visually similar items, issues with portion estimation in shared meals, and gaps in micronutrient estimation. While exp. participants tended to be more engaged with the system and leveraged its advanced features (such as obtaining detailed plans through conversations with the chatbot), inexp. participants were more likely to directly follow the system-generated suggestions, especially the simpler ones. Experts highlighted the system's value for general dietary tracking but noted the need for more accurate estimations of specific nutrients in clinical contexts.
These findings confirm the system's strengths while identifying areas for improvement.

In this section, we further discuss the implications of this work, followed by a discussion on the generalizability and limitations of this work.

\subsection{Implications}

\subsubsection{Personalization based on Experience, Behaviors, and Environment}
\label{subsubsec:personalization}

The findings emphasize the need to tailor systems to users' experience levels, interaction behaviors, and environmental contexts.
First, exp. participants exhibited higher engagement and satisfaction, emphasizing the need for advanced features like detailed nutritional insights, while simplicity and intuitive interfaces can reduce cognitive load for inexp. users. For example, the system could adapt its workflow and interface to offer advanced functionalities as user experience grows \cite{saif2024evolveui}.

Second, the system could be enhanced by personalization based on users' interactions.
Image-based food recognition struggles with nuances like cooking methods, seasonings, and visually similar items. 
Incorporating human-in-the-loop personalization \cite{ARchitect} could mitigate this challenge by enabling users to correct misidentified items and share underlying eating habits, enabling the system to learn from these corrections. 
Additionally, analyzing chatbot conversations can uncover patterns in user preferences and behaviors \cite{CharacterMeet}, which, when integrated with clinical data, could further fine-tune LLMs and improve system performance, such as increasing empathy or precision \cite{llempathy}.

Moreover, dietary suggestions could further consider environmental factors such as food availability (e.g., university cafeteria menus), financial situations, cultural preferences, and meal timing.
As suggested by participants, meal options tailored to commonly visited cafeterias can be incorporated considering the price. 
Shared meals, common in many cultures such as in Asia, complicate portion size estimation due to variations in individual preferences and dietary needs. While the current system assumes equal portions, adaptive algorithms or informed user input could be incorporated to improve accuracy. 
Furthermore, conducted with Chinese participants consuming both Western and Eastern cuisines, this study emphasizes the importance of cultural sensitivity in dietary systems.
Expanding research to diverse groups would increase the global applicability of such systems.

\subsubsection{Balancing Complexity and Relevance in AI-Generative Dietary Suggestions}
While the RAG module improves nutrient analysis and dietary suggestions, balancing the complexity of RAG-generated suggestions with their perceived relevance and actionability should be further improved. The complexity of RAG-generated recommendations could be dependent on the complexity of the constructed library. The findings underscore the content curation in building the nutrition library. For example, integrating popular science articles and knowledge summaries targeting the lay public can support the generation of practical, relevant suggestions that align with users' daily routines and preferences.

Moreover, participants expressed the need for more detailed context (e.g., the impact of sources) to enhance credibility while avoiding information overload. Future systems should balance source transparency with simplicity. Incorporating techniques like clickable summaries, expandable sections, or collapsible details can help present more in-depth information without overwhelming the user. Future systems can leverage LLMs to offer colloquial explanations of professional terminology \cite{Qlarify}, making complex nutritional information more accessible to users of varying expertise, thus improving the actionability of suggestions and increasing user engagement.

Additionally, we observed that inexp. users tended to rely more heavily on AI-generative analysis without critical evaluation. To mitigate the risk, the system could prompt users to consider the limitations of AI-generated insights, such as potential inaccuracies in personalized recommendations, and encourage them to critically evaluate results.

\subsubsection{Enhance the Integration of Multi-Devices and Proactive Intervention}
While our system relied on smart glasses and laptops (or mobile phones), as suggested by participants, integrating additional devices such as wrist-worn activity trackers could provide a more comprehensive understanding of users' health. Physical activity, sleep patterns, and metabolic rates are critical factors in dietary analysis and recommendations. Incorporating multimodal signals from multiple devices would enable more accurate, personalized feedback. For example, combining dietary data with physical activity metrics could refine calorie and nutrient recommendations, enhancing the system's overall utility.


Furthermore, leveraging multi-devices for real-time feedback and proactive dietary intervention can significantly enhance user engagement and adherence to dietary goals. By enabling users to quickly correct or label information on their smartwatches, the system can be further enhanced, as discussed in Sec.~\ref{subsubsec:personalization}.
Smart glasses or watches can deliver in-situ visual or audio cues \cite{bressa2022data} during meals, helping users make informed choices in a more seamless way. Real-time audio haptic feedback \cite{tan2024audioxtend}, for example, could combine sound cues (such as a pleasant tone indicating a correct portion or a warning beep for overeating) with tactile sensations (like vibrations to alert users when a meal exceeds recommended nutrient levels). This approach may not only improve user experience but also provide more intuitive and proactive interventions for dietary self-regulation based on the user's current activity levels and dietary patterns, fostering healthier behaviors.


\subsection{Generalizability}
\label{sec:generalizability}
Our system could be applied to various scenarios in health and beyond by applying a similar analysis framework. While developed with Aria Glasses, our system can integrate with other eyewear for ingestive episode detection and supports non-wearable alternatives, allowing users to upload meal photos for analysis when wearables are unavailable or impractical.
It can also be customized for regional diets by incorporating localized nutritional data, making it adaptable to diverse culinary preferences. Beyond dietary monitoring, the system can integrate fitness tracker data for physical activity analysis, assist with student tasks in education, and facilitate patient rehabilitation, where automated tracking and domain-specific analysis are essential.


\subsection{Limitations and Future Work}
While \shortname demonstrated usability and effectiveness, several limitations remain.

% \paragraph{\textcolor{ccolor}{Lack of Statistical Analysis of Group Differences}}
% \textcolor{ccolor}{Due to sample size limitations, we could not conduct statistical analysis of differences between exp. and inexp. participants. While qualitative insights reveal varying engagement, these findings should be interpreted with caution. Future work with a larger sample is needed for more definitive results.}

\paragraph{Eyewear Comfort}
The Aria Glasses, though powerful, are heavy due to unnecessary sensors for our study. Participants reported discomfort from sweat, especially in summer. Many also required vision correction, but lens replacement was not practical. This discomfort may hinder long-term retention. Future research could explore lighter glasses, attachable sensors for personal eyewear, or alternatives like smart earbuds or watches.

\paragraph{Diet Identification, Portion Estimation, and Micronutrient Analysis}
\shortname accurately identified most foods but struggled with visually similar items.
While \shortname accurately identified most foods, it struggled with visually similar items. Users may need to manually update diet summaries. The system also assumed equal portions in shared meals, potentially leading to discrepancies. Additionally, estimating micronutrients like phosphorus and potassium was challenging due to variability in biological, environmental, and processing factors. Future work could focus on improving micronutrient datasets for higher accuracy. As emphasized by the experts, higher precise nutrient intake was expected in clinical contexts.

\paragraph{Study Duration}
The four-week duration of the longitudinal study is comparable with previous diet-related studies \cite{biel2018bites, morshed2022food, silva2023exploring, weinreich2017effectiveness, santas2012selective}.
% Our four-week longitudinal study aligned with previous diet intervention studies \cite{weinreich2017effectiveness, santas2012selective}. 
However, extending the study duration and incorporating additional metrics, such as cognitive load, would provide deeper insights into sustained engagement.


\paragraph{Enhancing Privacy, Transparency, and Security}
Despite the system's privacy-preserving consideration, participants still raised concerns, particularly in shared meal contexts. 
Clear communication protocols and transparent privacy practices for users and their companions can build trust and address these sensitivities. 
Future systems could also incorporate advanced safeguards against misinformation, such as prompt injection attacks \cite{liu2023prompt} or erroneous inputs.

\section{Conclusion}
We introduced \shortname, a holistic system using smart glasses to automatically monitor dietary behaviors and provide personalized nutritional analysis and dietary suggestions, empowered by domain-specific knowledge. 
Two studies evaluated its performance in real-world, unconstrained environments. 
A short-term user study with 33 participants, along with quantitative assessments involving crowd workers and domain experts, demonstrated the system's effectiveness and usability.
A four-week longitudinal study with 16 participants validated \shortname's positive impact on dietary behaviors by increasing their understanding of their diets, raising awareness of regular meal timing, promoting healthier eating habits, and reducing the consumption of unhealthy foods.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}


    
\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
