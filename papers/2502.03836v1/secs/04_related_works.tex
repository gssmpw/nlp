\section{Related works}

\subsection{Monocular human mesh recovery}

SMPL model~\cite{SMPL} accelerates the development of human mesh recovery in recent years. SMPLify~\cite{SMPLify} is the first method to fit 3D body models to 2D keypoints detected by  keypoint detectors. HMR~\cite{HMR} then constructs the first end-to-end regression-based framework to directly predict the pose, betas and camera translation from the cropped person image. Since then, many methods have been developed based on HMR framework, aiming to improve reconstruction quality by feature pyramid alignment~\cite{PyMAF}, body part attention guide~\cite{PARE} and hierarchically design~\cite{HKHMR}. Recently, the first end-to-end transformer-based architecture HMR2.0~\cite{HMR2.0} outperforms the CNN-based architecture and achieves incredible results. Nonetheless, directly predicting the parameters by a neural network is very challenging due to the depth ambiguity and highly non-linear mapping~\cite{zhang2020object,huang2022object,huang2022pose2uv}. Hence, some methods are raised to optimize the regression results. SPIN~\cite{SPIN} uses the optimized results from SMPLify~\cite{SMPLify} to supervise the regression model. HoloPose~\cite{HoloPose} aligns the 3D estimates from regression model with the dense pose and 2D/3D joint positions, which is predicted by separate decoders. Some methods~\cite{HuMoR,TokenHMR} learn meaningful priors from AMASS~\cite{AMASS} dataset and then impose a constraint to the estimated distribution. Therefore, in this work we also use a regression optimization strategy to regress a initial SMPL parameters and then refine it to be consistent with other observations. 


\subsection{Diffusion-based human pose optimization}

% diffusion optimization 
Diffusion models~\cite{DDPM} have shown promising performance in various areas~(\eg, text-to-image generation~\cite{stable_diffusion}, text-to-motion generation~\cite{MDM}), which typically diffuse clean data towards standard Gaussian distribution and train a model to recover the clean value from the constructed noise. In the inference phase, the model samples the corresponding noise and iteratively optimizes the values at each timestep, which is usually accelerated by the DDIM method. In the field of pose estimation, ScoreHMR~\cite{ScoreHMR} uses a diffusion model to predict the noise in each step guided by the 2D keypoints information from an off-the-shelf detector. This method requires explicitly defining the correction strength, which might lead to extreme adjustments. BUDDI~\cite{BUDDI} learns the 3D proxemics prior with a diffusion model, and uses it to guide the close interaction human mesh reconstruction. CloseInteraction~\cite{CloseInteraction}
leverages knowledge from proxemic behavior and physics to compensate the lack of visual information to estimate accurate human interactions. However, all these methods only consider additional observations from a single modality or ignore the relationship between information from different modalities, which may lead to overfitting to additional information.

\subsection{Data driven human multi-modal priors}

As deep learning explores the depth of neural network architectures, many large models have gained strong generalization capabilities by increasing the network parameters and the amount of training data. Trained on hundreds of millions of images and captions, CLIP~\cite{CLIP} acquires powerful multi-modal semantic alignment capabilities, which can be used for several downstream tasks and achieves promising results. In the 3D domain, MotionCLIP~\cite{MotionCLIP} aligns the latent space of motion and text by contrastive pretraining, implicitly infusing the rich semantic knowledge of CLIP into the manifold. Based on pretrained large language models, MotionGPT~\cite{MotionGPT} employs discrete vector quantization of human motion and trains on both motion and text in a unified manner, which achieves remarkable performance in downstream tasks. ChatPose~\cite{ChatPose} directly regards the pose of a person as a token \texttt {\textless POSE\textgreater}, and the hidden states will be projected to regress the pose parameters once the token is predicted. With the aid of GPT-4 \cite{GPT4}, a huge VQA dataset can be constructed to finetune the above models. However, although these models can learn rich semantic information and have good generalization with higher-order information reasoning ability, they are still insensitive to pixel-level cues due to the discrete nature of tokens. Therefore, we utilize the higher-order semantic information from the large model for fine-grained feature extraction, and then transfer the discrete textual information into latent space for continuous guidance for human mesh recovery adaption.