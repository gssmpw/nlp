%\snote{We prove $\eta$-goodness and EML for pseudocodewords here. May move these to appendix eventually. .}

This appendix is adapted from \cite{JST23} to prove properties about $\eta$-good pseudocodewords and how one can obtain them via random conditioning. The key change is that we need these notions for $k$-tuples of pseudocodewords. Finally, we prove a generalization of the expander mixing lemma for such $k$-tuples of pseudowords.


%\tnote{does the proof use any of this cartesian notation? or is it only for the appendix?}



\subsection{Low average correlation}


\begin{lemma}\label{lem:avg_corr}
    Let $\tildeEx{\cdot}$ be an $\eta$-good $k$-tuple of pseudocodewords.
    
    Let $\{X_{\li}\}_{\li \in L}$ be a collection of $kd$-local functions on $\Sigma_{\inn}^{[k]\times E}$, such that $X_{\li}(f)$ only depends $f_{[k],\li}$. Likewise, let $\{Y_{\ri}\}_{\ri \in R}$ be a collection of $kd$-local functions on $\Sigma_{\inn}^{[k]\times E}$, such that $Y_{\ri}(f)$ only depends $f_{[k],\ri}$.
    
    Then,
    \begin{align*}
         \tildeEx{\Ex{\li,\ri}{X_{\li}(\zee)\cdot Y_{\ri}(\zee) }} - \tildeEx{\Ex{\li}{X_{\li}(\zee)}} \cdot \tildeEx{\Ex{\ri}{Y_{\ri}(\zee)}} \leq \eta \cdot \inparen{ \max_{\li} \norm{X_{\li}}_{\infty}} \cdot \inparen{\max_{\ri} \norm{Y_{\ri}}}_{\infty}
    \end{align*}
\end{lemma}
\begin{proof}
    \begin{align*}
    	& \tildeEx{\Ex{\li,\ri}{X_{\li}(\zee)\cdot Y_{\ri}(\zee) }} - \tildeEx{\Ex{\li}{X_{\li}(\zee)}} \cdot \tildeEx{\Ex{\ri}{Y_{\ri}(\zee)}}  \\
    	=~ & \Ex{\li,\ri}{\tildeEx{X_{\li}(\zee)\cdot Y_{\ri}(\zee) } - \tildeEx{X_{\li}(\zee)} \cdot \tildeEx{Y_{\ri}(\zee)} } \\
    	=~ & \Ex{\li,\ri}{ \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}} X_{\li}(\alpha) \cdot Y_{\ri}(\beta) \tildeEx{Z_{[k],N(\li),\alpha} \cdot Z_{[k],N(\ri),\beta} } - \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}} X_{\li}(\alpha) \cdot Y_{\ri}(\beta) \tildeEx{Z_{[k],N(\li),\alpha}} \cdot \tildeEx{Z_{[k],N(\ri),\beta} } } \\
    	\leq~ & \Ex{\li,\ri}{ \norm{X_{\li}}_{\infty} \cdot \norm{Y_{\ri}}_{\infty} \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}} \abs*{ \tildeEx{Z_{[k],N(\li),\alpha} \cdot Z_{[k],N(\ri),\beta} } -  \tildeEx{Z_{[k],N(\li),\alpha}} \cdot \tildeEx{Z_{[k],N(\ri),\beta} } } } \\
    	=~ & \Ex{\li,\ri}{ \norm{X_{\li}}_{\infty} \cdot \norm{Y_{\ri}}_{\infty} \cdot  \tildeCov{\zee_{[k],N(\li)}}{\zee_{[k],N(\ri)}} } \\
    	\leq~ & \inparen{\max_{\li} \norm{X_{\li}}_{\infty}} \cdot \inparen{\max_{\ri} \norm{Y_{\ri}}_{\infty}} \cdot \Ex{\li,\ri}{\tildeCov{\zee_{[k],N(\li)}}{\zee_{[k],N(\ri)}}} \\
    	\leq~ & \eta \cdot \inparen{\max_{\li} \norm{X_{\li}}_{\infty}} \cdot \inparen{\max_{\ri} \norm{Y_{\ri}}_{\infty}}.\qedhere
    \end{align*}
\end{proof}

\subsection{Conditioning reduces variance}

We next show how to obtain the $\eta$-good property by randomly conditioning the $k$-tuple of pseudocodewords. This is a straightforward generalization of the argument in \cite{JST23}, which can be seen as the $k=1$ case.

Just as in \cite{JST23}, we start with a lemma from \cite{BRS11} that quantifies the decrease in variance of the local distribution corresponding to a set $S$ when conditioning on another small set $T$, in terms of covariances between the two sets $S$ and $T$.

\begin{lemma}[{\cite[Lemma 5.2]{BRS11}}]
	Let $\tildeEx{\cdot}$ be a $k$-tuple of pseudocodewords of degree $t$. Let $S,T$ be subsets of $[k]\times E$ of size at most $t/2$ each. Then,
	\[
		\tildeVar{\zee_S \given \zee_T} \leq \tildeVar{\zee_S} - \frac{1}{|\Sigma_{\inn}|^{|T|}} \cdot \sum_{\substack{\alpha \in \Sigma_{\inn}^S \\ \beta \in \Sigma_{\inn}^T}} \frac{\inparen{\tildeCov{\zee_{S,\alpha}}{\zee_{T,\beta}}}^2}{\tildeVar{\zee_{T,\beta}}}
	\]
\end{lemma}

Now we use this lemma to track the decrease in average (pseudo-)variance $\Ex{\li \in L}{\tildeVar{\zee_{[k],N(\li)}}}$ when conditioning on $\zee_{[k],N(\ri)}$ for a random $\ri\in R$.

\begin{lemma}\label{lem:avg_conditioning}
	\begin{align*}
		\Ex{\ri\in R}{\Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)} \given \zee_{[k],N(\ri)}}}} \leq \Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}}} - \frac{1}{|\Sigma_{\inn}|^{3kd}} \cdot \inparen{\Ex{\li,\ri}{\tildeCov{\zee_{[k],N(\li)}}{\zee_{[k],N(\ri)}}}}^2
	\end{align*}
\end{lemma}

\begin{proof}
	\begin{align*}
		&~~~\Ex{\ri\in R}{\Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)} \given \zee_{[k],N(\ri)}}}} \\
		~&\leq~ \Ex{\ri\in R}{\Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}} - \frac{1}{|\Sigma_{\inn}|^{kd}} \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}} \frac{ \inparen{ \tildeCov{\zee_{[k],N(\li),\alpha}}{\zee_{[k],N(\ri),\beta}}}^2}{\tildeVar{\zee_{[k],N(\ri),\beta} }}}} \\
		~&\leq~ \Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}}} - \frac{1}{|\Sigma_{\inn}|^{kd}} \cdot \Ex{\substack{\li\in L \\ \ri\in R}}{ \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}} \inparen{ \tildeCov{\zee_{[k],N(\li),\alpha}}{\zee_{[k],N(\ri),\beta}}}^2} \\
		~&\leq~ \Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}}} - \frac{1}{|\Sigma_{\inn}|^{3kd}} \cdot \Ex{\substack{\li\in L \\ \ri\in R}}{ \inparen{ \sum_{\substack{\alpha \in \Sigma_{\inn}^{[k]\times N(\li)} \\ \beta \in \Sigma_{\inn}^{[k]\times N(\ri)}}}  \abs*{\tildeCov{\zee_{[k],N(\li),\alpha}}{\zee_{[k],N(\ri),\beta}}}}^2} \\
		~&=~ \Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}}} - \frac{1}{|\Sigma_{\inn}|^{3kd}} \cdot \Ex{\substack{\li\in L \\ \ri\in R}}{ \inparen{ \tildeCov{\zee_{[k],N(\li)}}{\zee_{[k],N(\ri)}}}^2} \\
		~&=~ \Ex{\li\in L}{\tildeVar{\zee_{[k],N(\li)}}} - \frac{1}{|\Sigma_{\inn}|^{3kd}} \cdot \inparen{\Ex{\substack{\li\in L \\ \ri\in R}}{  \tildeCov{\zee_{[k],N(\li)}}{\zee_{[k],N(\ri)}}}}^2
	\end{align*}
\end{proof}

Now that we can use average correlation to quantify the decrease in variance, we show that for a $k$-tuple of pseudocodewords with high-enough degree, there always exists a constant-sized subset of $R$ such that randomly conditioning on this set gives an $\eta$-good $k$-tuple of pseudocodewords. 
%If not, we can keep decreasing variance which must remain non-negative.

\begin{lemma}\label{lem:condition_for_eta_good}
	Let $\tildeEx{\cdot}$ be a $k$-tuple of pseudocodewords of degree $t \geq 2kd\inparen{1+\frac{|\Sigma_{\inn}|^{3kd}}{\eta^2}}$. Then there exists a set $S \subseteq E$ of size at most $d\cdot \frac{|\Sigma_{\inn}|^{3kd}}{\eta^2}$ such that the conditioned pseudocodeword $\tildeEx{\cdot \given \zee_{[k],S}}$ is $\eta$-good.
\end{lemma}

\begin{proof}
%	Let $\pcod{0}{\cdot} = \tildeEx{\cdot}$.
	For an integer $C>0$ to be chosen later, consider the following sequence of pseudocodewords, obtained by sequentially conditioning on $\zee_{[k],\ri}$ for a random $\ri$. For $c\in [C+1]$, define
	\[
		\Psi(c) = \Ex{\ri_1,\ri_2, \cdots \ri_c}{ \Ex{\li}{\tildeVar{ \zee_{[k],\li} \given \zee_{[k],\ri_1},\zee_{[k],\ri_2},\cdots ,\zee_{[k],r_c}}}}
	\]
	We have that
	\[
		1 \geq \Psi(0) \geq \Psi(1) \geq \cdots \Psi(C+1) \geq 0
	\]
	Therefore, there must exist a $c^*$, with $0\leq c^* \leq C$, such that
	\[
		\Psi(c^*) - \Psi(c^*+1) \leq \frac{1}{C+1} < \frac{1}{C} = \frac{\eta^2}{|\Sigma_{\inn}|^{3kd}}
	\]
	For an $R'\sub R$, let us denote $\pcod{R'}{\cdot} = \tildeEx{~\cdot~ \given \zee_{[k],N(R')}}$, and its associated variance and covariance operators be $\widetilde{\operatorname{Var}}^{(R')}$ and $\widetilde{\operatorname{Cov}}^{(R')}$. Then,
	\[
		\Psi(c^*) - \Psi(c^*+1) = \Ex{R' \sim R^{c^*}}{\Ex{\li}{\widetilde{\operatorname{Var}}^{(R')}\left[\zee_{[k],\li}\right]}} - \Ex{R'\sim R^{c^*}}{ \Ex{\ri_{c^*+1}}{\Ex{\li}{\widetilde{\operatorname{Var}}^{(R')}\left[\zee_{[k],\li} \given \zee_{[k], \ri_{c^*+1} }\right]}}}
	\]
	The set $R'$ above is sampled by sampling $c^*$ times from $R$ uniformly at random and with replacement. Therefore, there exists a set $R'$ of size at most $c^*$ such that
	\[
		\Ex{\li}{\widetilde{\operatorname{Var}}^{(R')}\left[\zee_{[k],\li}\right]} -  \Ex{\ri_{c^*+1}}{\Ex{\li}{\widetilde{\operatorname{Var}}^{(R')}\left[\zee_{[k],\li} \given \zee_{[k], \ri_{c^*+1} }\right]}} < \frac{\eta^2}{|\Sigma_{\inn}|^{3kd}}
	\]
	Applying the contrapositive of \cref{lem:avg_conditioning} to $\pcod{R'}{\cdot}$, we get that
		\begin{align*}
		&\Ex{\li,\ri}{\widetilde{ \operatorname{Cov}}^{(R')} \left[ \zee_{[k],\li}, \zee_{[k],\ri} \right]}\leq \eta \\
		\implies &\Ex{\li,\ri}{\widetilde{\operatorname{Cov}}\left[\zee_{[k],\li}, \zee_{[k],\ri} \given \zee_{[k],N(R')} \right]} \leq \eta
	\end{align*}
	Therefore, the set $S = N(R')$ proves the lemma.
%	Let us denote $\pcod{S}{\cdot} = \Ex{\ri_1,\cdots ,\ri_{c^*}}{\tildeEx{~\cdot~ \given \zee_{[k],S},\zee_{[k],\ri_2},\cdots ,\zee_{[k],\ri_{c^*}}}}$, and its associated variance and covariance operators be $\widetilde{\operatorname{Var}}^{(c^*)}$ and $\widetilde{\operatorname{Cov}}^{(c^*)}$. Then 
%	\[
%		\Psi(c^*+1) - \Psi(c^*) = \Ex{\li}{\widetilde{\operatorname{Var}}^{(c^*)}\left[\zee_{[k],\li}\right]} - \Ex{\ri_{c^*+1}}{\Ex{\li}{\widetilde{\operatorname{Var}}^{(c^*)}\left[\zee_{[k],\li} \given \zee_{[k],\ri_{c^*+1}}\right]}}
%	\]
%	Applying the contrapositive of \cref{lem:avg_conditioning} to $\pcod{c^*}{\cdot}$, we get that
%	\begin{align*}
%		&\Ex{\li,\ri}{\widetilde{ \operatorname{Cov}}^{(c^*)} \left[ \zee_{[k],\li}, \zee_{[k],\ri} \right]}\leq \eta \\
%		\implies &\Ex{\ri_1,\cdots ,\ri_{c^*}}{\widetilde{\operatorname{Cov}}\left[\zee_{[k],\li}, \zee_{[k],\ri} \given \zee_{[k],\ri_1}, \cdots ,\zee_{[k],\ri_{c^*}} \right]} \leq \eta
%	\end{align*}
%	Therefore, there exists a set of $c^*$ right vertices $\ri_1,\ri_2,\cdots ,\ri_{c^*}$ such that conditioning on $\zee_{[k], \{\ri_1,\ri_2,\cdots ,\ri_{c^*}\}}$ makes the pseudocodeword $\eta$-good.
\end{proof}

\subsection{Expander Mixing Lemma}

\begin{lemma}[EML for pseudoexpectations]\label{lem:eml_sos}
	Let $\tildeEx{\cdot}$ be a $k$-tuple of pseudocodewords of degree at least $2k d$. Let $G = (L,R,E)$ be a bipartite $\lambda$-expander. Recall that $\li \sim \ri$ if and only if $(\li,\ri)$ is an edge in $G$.
	
	Let $\{X_{\li}\}_{\li \in L}$ be a collection of $kd$-local functions on $\Sigma_{\inn}^{[k]\times E}$, such that $X_{\li}(f)$ only depends $f_{[k],\li}$. Likewise, let $\{Y_{\ri}\}_{\ri \in R}$ be a collection of $kd$-local functions on $\Sigma_{\inn}^{[k]\times E}$, such that $Y_{\ri}(f)$ only depends $f_{[k],\ri}$. 
	Then,
	\begin{align*}
		\abs*{\tildeEx{\Ex{\li\sim \ri}{X_{\li}(\zee) \cdot Y_{\ri}(\zee)} - \Ex{\li,\ri}{X_{\li}(\zee) \cdot Y_{\ri}(\zee)}}} \leq \lambda \cdot \sqrt{\tildeEx{\Ex{\li}{X_{\li}(\zee)^2}}} \cdot \sqrt{\tildeEx{\Ex{\ri}{Y_{\ri}(\zee)^2}}}
	\end{align*}
\end{lemma}
\begin{proof}
    Let $A_G$ be the $L \times R$ normalized biadjacency matrix of $G$, so that
    \[
    	A_G(\li,\ri) = \begin{cases}
    		\frac{1}{d}, \qquad (\li,\ri) \in E \\
    		0, \qquad (\li,\ri)\not\in E
    	\end{cases}
    \]
    The singular value decomposition for $A_G$ can be written as
    \[
    	A_G = \sum_{i=1}^n \sigma_i u_i v_i^T
    \]
    with $\sigma_1 \geq \cdots \geq \sigma_n \geq 0$, and $\{u_i\}_{i\in [n]}$, $\{v_i\}_{i \in [n]}$ being two orthonormal bases of $\R^n$. Moreover, since the graph is regular, $\sigma_1 =1$ and $u_1 = v_1 = \frac{1}{\sqrt{n}} \one$.
    
    Let $X(\zee)$ be the vector-valued local function defined as the $n$-dimensional vector with coordinates corresponding to $\li \in L$, and the respective entry being $X_{\li}(\zee)$. Likewise, let $Y(\zee)$ be the vector-valued local function so that coordinates correspond to $\ri\in R$, and the entries being $\{Y_{\ri}(\zee)\}_{\ri\in R}$. Then,
%
    \begin{align*}
    	&\abs*{\tildeEx{\Ex{\li\sim \ri}{X_{\li}(\zee) \cdot Y_{\ri}(\zee)} - \Ex{\li,\ri}{X_{\li}(\zee) \cdot Y_{\ri}(\zee)}}} \\
    	=~ &\abs*{ \tildeEx{\frac{1}{n} X(\zee)^T A_G Y(\zee)} - \tildeEx{\frac{1}{n} X(\zee)^T (\frac{1}{\sqrt{n}} \one) (\frac{1}{\sqrt{n}} \one)^T Y(\zee)}} \\
    	=~ &\frac{1}{n} \abs*{\tildeEx{X(\zee)^T \inparen{A_G - (\frac{1}{\sqrt{n}} \one) (\frac{1}{\sqrt{n}} \one)^T}Y(\zee)}} \\
    	=~ &\frac{1}{n} \abs*{\tildeEx{X(\zee)^T \inparen{\sum_
    	{i=2}^n \sigma_i u_iv_i^T}Y(\zee)}} \\
    	\leq~ &\frac{1}{n} \abs*{\tildeEx{\sum_{i=2}^n \sigma_i ~ \inparen{X(\zee)^T u_i}\cdot \inparen{Y(\zee)^T v_i}}} \\
    	=~ &\frac{1}{n} \abs*{\tildeEx{\sum_{i=2}^n \inparen{\sqrt{\sigma_i} \cdot X(\zee)^T u_i}\cdot \inparen{\sqrt{\sigma_i}\cdot Y(\zee)^T v_i}}} \\
    	\leq~ &\frac{1}{n} \inparen{\tildeEx{\sum_{i=2}^n \inparen{\sqrt{\sigma_i} \cdot X(\zee)^T u_i}^2}}^{1/2} \cdot \inparen{\tildeEx{\sum_{i=2}^n \inparen{\sqrt{\sigma_i}\cdot Y(\zee)^T v_i}^2}}^{1/2} && (\text{{SoS Cauchy--Schwarz}})\\
    	\leq~ &\frac{1}{n}\cdot \lambda \cdot \inparen{\tildeEx{\sum_{i=2}^n \inparen{ X(\zee)^T u_i}^2}}^{1/2} \cdot \inparen{\tildeEx{\sum_{i=2}^n \inparen{ Y(\zee)^T v_i}^2}}^{1/2} \\
%    	\leq~ &\frac{1}{n} \lambda \cdot \sum_{i=2}^n \abs*{ \tildeEx{\inparen{X(\zee)^T u_i}\cdot \inparen{Y(\zee)^T v_i}}} \\
%    	\leq~ &\frac{1}{n} \lambda \cdot \parens*{ \tildeEx{ \sum_{i=2}^n \inparen{X(\zee)^T u_i}^2}}^{1/2} \cdot \parens*{ \tildeEx{\sum_{i=2}^n \inparen{Y(\zee)^T v_i}^2}}^{1/2} && [\text{\snote{SoS Cauchy Schwarz}}]\\
    	=~ &\frac{1}{n} \lambda \cdot \inparen{ \tildeEx{ X(\zee)^T X(\zee) - (X(\zee)^T u_1)^2}}^{1/2} \cdot \inparen{ \tildeEx{ Y(\zee)^T Y(\zee) - (Y(\zee)^T v_1)^2}}^{1/2} && (\text{{Using orthonormality}})\\
    	\leq~ &\frac{1}{n} \lambda \cdot \inparen{ \tildeEx{ X(\zee)^T X(\zee)}}^{1/2} \cdot \inparen{ \tildeEx{ Y(\zee)^T Y(\zee)}}^{1/2} \\
    	 =~ & \lambda \cdot \inparen{ \tildeEx{\Ex{\li}{ X_{\li}(\zee)^2}}}^{1/2} \cdot \inparen{ \tildeEx{ \Ex{\ri}{Y_{\ri}(\zee)^2}}}^{1/2}. \qedhere
    \end{align*}
\end{proof}

