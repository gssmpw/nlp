\section{Deferred Proofs for Normal-Form Games} \label{app:nfg}

\subsection{Upper Bound} \label{app:nfg-upper}

First, note that our cost estimates are unbiased, i.e. 
$\exptn\rectangular{\cHat^t(a)} = \exptn\rectangular{ c^t(a) }$, and $\exptn\rectangular{ \inner{\cHat^t}{\mu^t} } = \exptn\rectangular{\exptn\rectangular{ \inner{\cHat^t}{\mu^t} \mid \Fcal_{t-1} }} = \exptn\rectangular{ \inner{c^t}{\mu^t} } = \exptn\rectangular{c^t(a^t) }$, where $\Fcal_{t-1}$ is the $\sigma$-algebra induced by all random variables prior to sampling $a^t$. Further, WLOG we assume that the cost functions are bounded via $c^t\in[0,1]^A$. The reduction from NFGs with matrix entries $U_{a,b}\in[-1,1]$ is then simply via $c^t(a):=(1+U_{a,b^t})/2$, where the shifting and scaling does not change the regret bound. By convention $\start_{k+1}:=T+1$ if $k$ is the last phase.

\thmUbSimplexBandit*

\begin{proof}
    \emph{Case 1: $\alpha=1$ is not reached.} Suppose first the algorithm ends in phase $k <1+\log_2(R)$ at time step $T$. By \cref{lemma:during-nfg}, w.r.t. any comparator 
    \begin{align*}
        \sum_{t=1}^T \inner{\cHat^t}{\mu^t-\mu} \leq (2R+2) \cdot k \leq O(R \log(R)).
    \end{align*}
    All previous phases must have been exited, so by \cref{lemma:during-nfg,lemma:exit-nfg} we have 
    \begin{align*}
        \sum_{t=1}^T \inner{\cHat^t}{\mu^t-\mu^c} \leq 2^{k-1} - \sum_{i=1}^{k-1} 2^{i-1} = 2^{k-1} - (2^{k-1}-1) = 1.
    \end{align*}
    Taking expectation yields the claim.\\

    \emph{Case 2: $\alpha=1$ is reached.} Next, suppose the phase $\alpha^k=1$ was reached and simply Exp3 was run in the final phase $k$. As before
    \begin{align*}
        \sum_{t=1}^{\start_{k}-1} \inner{\cHat^t}{\mu^t-\mu} \leq (2R+2) \cdot k \leq O(R \log(R)).
    \end{align*}
    For the final phase, note that \cref{algo:phased-aggression-nfg} plays Exp3 for $\leq T$ rounds, with uniform initialization. By the standard Exp3 analysis \citep[Sec. 10.1]{orabona2019modern}, this phase has expected regret
    \begin{align}
        \exptn\rectangular{\sum_{t=\start_{k+1}}^T \inner{c^t}{\mu^t-\mu}} \leq \frac{\log(A)}{\tau} + \frac{\tau}{2} AT 
        \leq \sqrt{AT\log(A)/2}
        \leq \delta^{-1}\sqrt{2\log(A) T}=R . \label{eq:exp3}
    \end{align}
    since $\tau=\sqrt{\frac{2\log(A)}{AT}}$ and $\delta\leq 1/A$. Thus for any comparator $\mu\in\Delta_A$ we have
    \begin{align*}
        \exptn\rectangular{\sum_{t=1}^T \inner{c^t}{\mu^t - \mu}} \leq O(R\log(R)).
    \end{align*}
    Finally, for the special comparator note that all phases $k'<k$ have been left and thus by \cref{lemma:exit-nfg,eq:exp3} 
    \begin{align*}
        \exptn\rectangular{\sum_{t=1}^T \inner{c^t}{\mu^t - \mu^c}} \leq R - \sum_{k'=1}^{k-1} 2^{k'-1}= R - (2^{k-1} -1 ) \leq 1,
    \end{align*}
    where the last step used that $\alpha^k=\min\{1,2^{k-1}/R\}=1$ and thus $R\leq2^{k-1}$.
\end{proof}

Recall that 
\begin{align}
    \RHat^k(\mu):=& \sum_{t=\start_k}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^t-\mu} = \alpha^k \sum_{j=\start_k}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu} + (1-\alpha^k) \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^c-\mu} \label{eq:phase-reg-nfg}
\end{align}
measures Alice's estimated regret.

\lemmaDuringNfg*

\begin{proof}
    WLOG suppose that $R=2^r$ is a power of $2$, else we can run the algorithm for $T$ such that $R$ is the next largest power of two and pay a constant factor in the regret. For the first term in \cref{eq:phase-reg-nfg}, we analyze OMD to bound $\sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu}$ almost surely, making use of the fact that $\cHat^t$ is bounded. Indeed, recall 
    \begin{align*}
        \cHat^t(a) = \frac{c^t(a^t)}{\mu^t(a)}\indicator{a^t=a} \leq \frac{1}{\mu^t(a)}.
    \end{align*}
    We have $\alpha^k = 2^{k-1}/R \leq 2^{\log_2(R)-1}/R=1/2$, so 
    \begin{align*}
        \cHat^t(a) \leq \frac{1}{\mu^t(a)}=\frac{1}{\alpha^k\mu^t(a)+(1-\alpha^k)\mu^c(a)}\leq\frac{1}{\frac{1}{2}\mu^c(a)}\leq \frac{2}{\delta}.
    \end{align*}
    Moreover, $\cHat^t$ is zero outside the visited $a^t$. Thus, by \cref{lem:bandit-omd-bounded-nfg}, almost surely for the first term in \cref{eq:phase-reg-nfg}
    \begin{align}
        \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu} \leq \frac{\log(A)}{\eta} + 2\eta T\delta^{-2} \leq \delta^{-1}\sqrt{2T\log(A)} = R. \label{eq:omd-regret1-nfg}
    \end{align}

    \noindent For the second term in \cref{eq:phase-reg-nfg}, note that since the if condition may only hold at $t':=\start_{k+1}-1$,
    \begin{align}
        \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^c-\mu} \leq 2R + \frac{c^{t'}(a^{t'})}{\frac{1}{2}\mu^c(a^{t'})}\mu^c(a^{t'})\leq 2R+2. \label{eq:while-cond1-nfg}
    \end{align}
    \noindent Linearly combining \cref{eq:omd-regret1-nfg,eq:while-cond1-nfg}, 
    \begin{align*}
        \RHat^k(\mu):=& \alpha^k \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu} + (1-\alpha^k) \sum_{t=\start_k}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^c-\mu} \leq 2R +2
    \end{align*}
    for any $\mu$. For the special comparator, by \cref{eq:omd-regret1-nfg}
    \begin{align*}
        R^k(\mu^c)= \alpha^k \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu^c} + (1-\alpha^k) \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^c-\mu^c} \leq (2^{k-1}/R)R = 2^{k-1}. 
    \end{align*}
\end{proof}

\begin{lemma}[OMD with bounded surrogate costs] \label{lem:bandit-omd-bounded-nfg}
    Let $\eta >0$, and $L>0$. Let $(\cHat^t)_t$ be cost functions such that for all $t$, $0\leq\cHat^t(a)\leq L$ (for all $a$), and moreover $\cHat^t(a) = 0$ if $a\neq a^t$ for some arbitrary $a^t$. Set $\muHat^1(a) = 1/A$ and consider the scheme $\mu^{t+1} = \arg\min_{\mu \in \Delta_A} \inner{\mu}{\cHat^t} + \frac{1}{\eta} D(\mu || \muHat^t)$ for $t\leq T'$. Then we have for all $\mu\in\Delta_A$
    \begin{align*}
        \sum_{t=1}^{T'} \inner{\muHat^t-\mu}{\cHat^t} \leq \frac{\log(A)}{\eta} + \frac{\eta}{2} L^2 T'.
    \end{align*}
\end{lemma}

\begin{proof}
    From \citet[Sec. 10.1]{orabona2019modern}, we find that a.s.
    \begin{align*}
        \sum_{t=1}^{T'} \inner{\muHat^t-\mu}{\cHat^t} \leq \frac{\log(A)}{\eta} + \frac{\eta}{2} \sum_{t=1}^{T'} \sum_a \muHat^t(a) (\cHat^t(a))^2
        \leq \frac{\log(A)}{\eta} + \frac{\eta}{2} \sum_{t=1}^{T'} \muHat^t(a^t) L^2 \leq \frac{\log(A)}{\eta} + \frac{\eta}{2}L^2T'.
    \end{align*}
\end{proof}

\lemmaExitNfg*

\begin{proof}
    At $t=\start_{k+1}-1$ the if condition implies $\max_{\mu\in\Delta_A}\sum_{j = \start_{k}}^{\start_{k+1}-1} \inner{\cHat^j}{\mu^c - \mu} > 2 R$, so when we let $\mu^{\star}$ be a maximizer, we find
    \begin{align*}
        \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^t-\mu^c} =& \alpha^k \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu^c} \nonumber\\
        =& \alpha^k \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\muHat^t-\mu^{\star}} +\alpha^k \sum_{t=\start_{k}}^{\start_{k+1}-1} \inner{\cHat^t}{\mu^{\star}-\mu^c} \nonumber\\
        \leq& \alpha^k R + \alpha^k(-2R)\nonumber\\
        =& -2^{k-1},
    \end{align*}
    where we used \cref{eq:omd-regret1-nfg} in the last inequality.
\end{proof}

\subsection{Lower Bound} \label{app:nfg-lower}

\thmLowerNfg*

Our lower bound becomes vacuous in the regime where $\delta \leq O( T^{-1})$, which is when a direct application of \citet{lattimore2015pareto} shows a trivial $\Omega(T)$ lower bound.

\begin{proof}
    It is sufficient to prove the lower bound for $A=2$ actions as we can assign the same distribution to all but one action. We prove a lower bound for stochastic cost functions, which immediately implies the same bound for adversarially chosen costs. Consider the following setup with two different environments. The first action deterministically gives cost $c_1 = 1/2$ in both environments. In the \textit{first environment $(-)$}, action two samples costs according to a $\text{Ber}(\frac{1}{2}-\gamma T^{-1/2})$ distribution with expected cost $c_- = \frac{1}{2}-\gamma T^{-1/2}$. We will choose $\gamma>0$ later and for now, only require $\gamma < \frac{1}{2}T^{1/2}$ in order for the sampling to be well-defined. Symmetrically, in the \textit{second environment $(+)$}, action two samples costs according to a $\text{Ber}(\frac{1}{2}+\gamma T^{-1/2})$ distribution with expected cost $c_+ = \frac{1}{2}+\gamma T^{-1/2}$. We consider the case that the \textit{special comparator} is $\mu^c = (1-\delta,\delta)\in\Delta_2$. In the following, $\mathcal{R}(\mu)$ denotes the regret compared to $\mu\in\Delta_A$ in the worst case environment. We fix an arbitrary algorithm and index regret and expectation with $+$ or $-$ to indicate which probability space (environment) we are referring to.\\

    \noindent Now let $N_2$ be the number of times action two is chosen during the $T$ interactions. The requirement on the regret w.r.t. the special comparator (together with the standard regret decomposition \citep[Sec. 4.5]{lattimore2020bandit}) shows
    \begin{align*}
        1 \geq \mathcal{R}(\mu^c) \geq \mathcal{R}_+(\mu^c) = \exptn_+\rectangular{N_2} (+\gamma T^{-1/2}) - \delta T (+\gamma T^{-1/2}),
    \end{align*}
    and thus
    \begin{align*}
        \exptn_+\rectangular{N_2} \leq& \gamma^{-1}T^{1/2} + \delta T. 
    \end{align*}
    Plugging this into \cref{lemma:pinsker-nfg}, we have (if $\gamma < \frac{1}{2\sqrt{2}}T^{1/2}$)
    \begin{align*}
        \exptn_-[N_2] \leq& \exptn_+[N_2] + T \sqrt{2}\sqrt{\exptn_+[N_2]} \gamma T^{-1/2}\nonumber\\
        \leq& (\gamma^{-1}T^{1/2} + \delta T) + T \sqrt{2} \sqrt{\gamma^{-1}T^{1/2} + \delta T} \gamma T^{-1/2}\nonumber\\
        \leq& \gamma^{-1}T^{1/2} + \delta T + T \sqrt{2}(\gamma^{-1/2}T^{1/4} + \delta^{1/2} T^{1/2}) \gamma T^{-1/2}\nonumber\\
        \leq& \gamma^{-1}T^{1/2} + \delta T + \sqrt{2}\gamma^{1/2}T^{3/4} + \sqrt{2}\delta^{1/2} \gamma T 
    \end{align*}
    Using this in the regret decomposition on $(-)$, we see for the second action $\mu=e_2=(0,1)\in\Delta_A$
    \begin{align*}
        \mathcal{R}(e_2) \geq& \mathcal{R}_-(e_2)\\
        \geq& (\gamma^{-1}T^{1/2} + \delta T + \sqrt{2}\gamma^{1/2}T^{3/4} + \sqrt{2}\delta^{1/2} \gamma T) (-\gamma T^{-1/2}) - T(-\gamma T^{-1/2})\\
        \geq& - 1 - \delta \gamma T^{1/2} - \sqrt{2}\gamma^{3/2}T^{1/4} - \sqrt{2}\delta^{1/2} \gamma^2 T^{1/2} + \gamma T^{1/2}\\
        =& \round{(1-\delta)\gamma - \sqrt{2}\delta^{1/2}\gamma^2} T^{1/2} - \sqrt{2}\gamma^{3/2}T^{1/4}-1.
    \end{align*}
    We can now choose $\gamma = c \delta^{-1/2}$ for a sufficiently small absolute constant $c$ to show that 
    \begin{align}
        \mathcal{R}(e_2) \geq \Theta\round{ \delta^{-1/2} T^{1/2}} - \Theta(\delta^{-3/4}T^{1/4}). \label{eq:lower}
    \end{align}
    This bound holds when $\gamma < \frac{1}{2\sqrt{2}} T^{1/2}$, i.e. $\delta \geq c' T^{-1}$ for some large enough absolute constant $c'$.
\end{proof}

\begin{lemma}[Entropy inequality Bernoulli] \label{lemma:pinsker-nfg}
    In the setup of \cref{thm:lower-nfg}, we have
    \begin{align*}
        \exptn_{-}\rectangular{N_2}
        \leq& \exptn_{+}\rectangular{N_2} + T\sqrt{\frac{2(\gamma T^{-1/2})^2}{\frac{1}{4}-(\gamma T^{-1/2})^2}\exptn_{+}\rectangular{N_2}}.
    \end{align*}
    In particular for $\gamma < \frac{1}{2\sqrt{2}} T^{1/2}$, we have $\exptn_{-}\rectangular{N_2}
        \leq \exptn_{+}\rectangular{N_2} + \sqrt{2\exptn_{+}\rectangular{N_2}}\gamma T^{-1/2}.$
\end{lemma}

\begin{proof}
    Via Pinsker's and the chain rule for the KL divergence (c.f. \citet{auer1995gambling} and \citet[Appendix]{lattimore2015pareto})
    \begin{align*}
        \exptn_{-}\rectangular{N_2} - \exptn_{+}\rectangular{N_2} \leq T \sqrt{\frac{1}{2} \exptn_{+}\rectangular{N_2} \cdot\text{KL}(X||Y)},
    \end{align*}
    where $X\sim \text{Ber}(\frac{1}{2}+\epsilon)$ and $Y\sim \text{Ber}(\frac{1}{2}-\epsilon)$ for $\epsilon=\gamma T^{-1/2}$. We conclude by computing 
    \begin{align*}
        \text{KL}(X||Y) =& \round{\frac{1}{2}+\epsilon}\log\round{\frac{\frac{1}{2}+\epsilon}{\frac{1}{2}-\epsilon}} + \round{\frac{1}{2}-\epsilon}\log\round{\frac{\frac{1}{2}-\epsilon}{\frac{1}{2}+\epsilon}}\\
        \leq& \round{\frac{1}{2}+\epsilon}\round{\frac{\frac{1}{2}+\epsilon}{\frac{1}{2}-\epsilon}-1} + \round{\frac{1}{2}-\epsilon}\round{\frac{\frac{1}{2}-\epsilon}{\frac{1}{2}+\epsilon}-1}\\
        =& 2\epsilon \round{- \frac{\frac{1}{2}-\epsilon}{\frac{1}{2}+\epsilon}+\frac{\frac{1}{2}+\epsilon}{\frac{1}{2}-\epsilon}}\\
        =& 2\epsilon \frac{2\epsilon}{\frac{1}{4}-\epsilon^2}.
    \end{align*}
\end{proof}


\subsection{The Stochastic Case} \label{app:nfg-stochastic}



As claimed in the main part, we now sketch how the $\OTilde(\sqrt{\delta^{-1}T})$ lower bound from \cref{sec:nfg-lower} can be matched (up to logarithmic terms) if the costs are stochastic and not adversarial. This improves slightly over our result for the adversarial case.

\begin{theorem}\label{thm:stochastic-case}
    Let $\delta\in(0,1)$ and consider Protocol \ref{prot:bandit-simplex} but where all $c^t(a)\sim q_a$ are i.i.d. for some fixed distributions $q_a$ with support in $[0,1]$. Then there is an algorithm such that for any specified $\mu^c\in\Delta_A$ with all $\mu^c(a)\geq \delta$ and all distributions $q$, we have
    \begin{align*}
        \mathcal{R}(\mu^c) \leq 1 \quad \text{and}\quad & \max_{\mu\in\Delta_A} \mathcal{R}(\mu) \leq O\round{\sqrt{\delta^{-1} T\log(AT)} + \delta^{-2}\log(T)}.
    \end{align*}
\end{theorem}
For $a \in [A]$, let the $a$-th action's reward distribution $q_a$ have mean $1-\mean_a$, and write $\mean$ for the corresponding vector. We thus consider \emph{maximization} of the \emph{rewards} $1-c^t$ that have means $m$. This is just for convenience to better highlight the relation of our algorithm to the classic UCB algorithm \citep{lattimore2020bandit}. As for the rewards, we index the entries of a strategy $\mu\in\Delta_A$ as $\mu_a=\mu(a)$. Fix an arbitrary $a^\star \in \arg\max_a \mean_a$. The (random) pseudo-regret of the algorithm is 
\begin{align*}
    \tilde{\mathcal{R}} := \sum_{t=1}^T (\mean_{a^\star} - \inner{\mu^t}{\mean}).
\end{align*}

\paragraph{Algorithm.}

Construct $\meanLow^{t} = (\meanLow_1^{t}, \dots, \meanLow_A^{t})$, $\meanUp^{t} = (\meanUp_1^{t}, \dots, \meanUp_A^{t})$ to be the vectors of lower and upper confidence bounds for the actions after playing and observing $t$ rounds. Formally,
\begin{align*}
    \meanLow_a^{t} := \meanHat_a^t - b_a^t, \quad \quad \meanUp_a^{t} := \meanHat_a^t + b_a^t,
\end{align*}
where $\meanHat_a^t$ is the average reward among the rounds in which the $a$-th action is chosen during rounds $1, \dots, t$ (and zero if not defined), and $b^t_a$ is a confidence half-width to be specified. With this, set $M^t := [\meanLow^t,\meanUp^t] := [\meanLow^t_1,\meanUp^t_1] \times \cdots \times [\meanLow^t_A,\meanUp^t_A]$. Consider the following update. Let $$\mu^1 = \mu^c,$$ and in round $t + 1$, update 
\begin{align}
    \mu^{t+1} = \arg\max_{\mu \in \Delta_A} \min_{\meanTilde \in [\meanLow^t,\meanUp^t] } \inner{\mu-\mu^t}{\meanTilde} . \label{eq:update}
\end{align}

\paragraph{Regret analysis.}

First, note that conditioned on $\mean \in M^t$, we have 
\begin{align}
    0 = \min_{\meanTilde \in M^t} \inner{\mu^t - \mu^t}{\meanTilde} \leq \max_{\mu\in\Delta_A} \min_{\meanTilde \in M^t} \inner{\mu - \mu^t}{\meanTilde} = \min_{\meanTilde \in M^t} \inner{\mu^{t+1} - \mu^t}{\meanTilde} \leq \inner{\mu^{t+1} - \mu^t}{\mean}. \label{rmk:mon}
\end{align}
Hence, the algorithm monotonically improves, i.e. $\inner{\mu^{t+1}}{m}\geq \inner{\mu^{t}}{m}$, if all confidence intervals include the true mean. As for the confidence intervals, set $b_a^t := 2\sqrt{\frac{2\log(T^2A/\zeta)}{n^t_a}}$, where $n^t_a$ is the number of times that action $a$ is chosen in rounds $1,\dots,t$. Then by Hoeffding's inequality, with probability at least $1-\zeta$, for all $t \in [T]$ we have $\mean \in \text{int}(M^t)$. We call this event $G$.\smallskip

\noindent By finding the closed form of the update rule in \cref{eq:update} and the lower bound on $\mu^1=\mu^c$, it is not hard to see the following.
\begin{lemma} \label{lem:opt-prob}
    Conditioned on $G$, we have $\mu_{a^\star}^{t} \geq \mu^c_{a^\star} \geq \delta$ for all $t\in[T]$.
\end{lemma}
Using Hoeffding's inequality and a union bound, we thus get the following concentration.
\begin{lemma} \label{lem:opt-count}
    Condition on $G$ and let $\zeta' \in (0,1)$. Then with probability at least $1-\zeta'$, we have 
    \begin{align*}
        n_{a^\star}^t \geq \delta t - \sqrt{ 2t \log(T/\zeta') }.
    \end{align*}
\end{lemma}

\smallskip
\noindent We are now ready to prove \cref{thm:stochastic-case}. Condition on $G$ and on the event in \cref{lem:opt-count}. This occurs with probability at least $1-\zeta-\zeta'$.\smallskip

\noindent First, we consider the regret compared to $\mu^c$. By the monotonicity property in \cref{rmk:mon}, 
\begin{align*}
    \inner{\mu^t}{\mean} \geq \inner{\mu^{t-1}}{\mean} \geq \dots \geq \inner{\mu^1}{\mean} = \inner{\mu^c}{\mean}.
\end{align*}
Setting $\zeta = \zeta' = \frac{1}{2T}$ and integrating out the regret of at most $T$ under the failure event:
\begin{align*}
    \exptn\rectangular{\sum_{t=1}^T \inner{\mu^c-\mu^t}{\mean}} \leq& \Pr[G] \exptn\rectangular{\sum_{t} \inner{\mu^c-\mu^t}{\mean} \mid G} + \Pr[\bar{G}] T 
    \leq 0 + (\zeta + \zeta')T = 1.
\end{align*}

\noindent  We now consider the worst case (pseudo-) regret $\tilde{\mathcal{R}}$. Note that for the minimax problem in \cref{eq:update}, strong duality holds and we can fix a saddle point $(\mu^t, \meanTilde^t)$ such that (for all $(\mu,\meanTilde) \in \Delta_A\times M^t$)
\begin{align}
    \inner{\mu-\mu^{t-1}}{\meanTilde^t} \leq \inner{\mu^t-\mu^{t-1}}{\meanTilde^t} \leq \inner{\mu^t-\mu^{t-1}}{\meanTilde}. \label{eq:saddle-point}
\end{align}

\noindent Under the success events, we have $n_{a^\star}^t \geq \delta t - \sqrt{ 2t \log(T/\zeta') }$ by \cref{lem:opt-count}. Now when $t \geq t_0 := 8\delta^{-2} \log(T/\zeta')$, then $n_{a^\star}^t \geq 2\delta^{-1}\sqrt{ 2t \log(T/\zeta') }$ and hence 
\begin{align}
    b_{a^\star}^t \leq 2\sqrt{\frac{4\log(T^2A/\zeta)}{\delta t}}. \label{eq:bonus}
\end{align}
We have 
\begin{align*}
    \tilde{\mathcal{R}} =  8\delta^{-2} \log(T/\zeta') + \sum_{t=t_0}^T (\mean_{a^\star} - \inner{\mu^{t}}{\mean}) \leq 8\delta^{-2} \log(T/\zeta') + \sum_{t=t_0}^T (\mean_{a^\star} - \inner{\mu^{t}}{\mean}),
    \end{align*}
where the instantaneous regret for $t\geq t_0$ is (with $\mu^\star:=e_{a^\star}$)
\begin{align*}
    \mean_{a^\star} - \inner{\mu^{t}}{\mean} =& \inner{\mu^\star - \mu^{t}}{\mean}\\
    =& \inner{\mu^\star - \mu^{t}}{\meanTilde^{t+1}} + \inner{\mu^\star - \mu^{t}}{\mean - \meanTilde^{t+1}} \\
    \leq& \inner{\mu^{t+1} - \mu^{t}}{\mean} + \inner{\mu^\star - \mu^{t}}{\mean - \meanTilde^{t+1}} \tag{by \cref{eq:saddle-point} and $\mean\in M^{t+1}$}\\
    \leq& \inner{\mu^{t+1} - \mu^{t}}{\mean} + \inner{\mu^\star}{b^{t+1}} + \inner{\mu^t}{b^{t+1}}\\
    \leq& \inner{\mu^{t+1} - \mu^{t}}{\mean} + \inner{\mu^\star}{b^{t}} + \inner{\mu^t}{b^{t}} \tag{as $b^{t+1}\leq b^t$}.
\end{align*}
Hence,
\begin{align*}
    \tilde{\mathcal{R}} \leq& 8\delta^{-2} \log(T/\zeta') + \inner{\mu^{T+1} - \mu^{t_0}}{\mean} + \sum_{t=t_0}^T \round{\inner{\mu^\star}{b^{t}} + \inner{\mu^t}{b^{t}}}\\
    \leq& 8\delta^{-2} \log(T/\zeta') + 1 + \sum_{t=t_0}^T b_{a^\star}^{t} + \sum_{t=t_0}^T \inner{\mu^t}{b^{t}}\\
    \leq& 8\delta^{-2} \log(T/\zeta') + 1 + \sum_{t=t_0}^T 2\sqrt{\frac{4\log(T^2A/\zeta)}{\delta t}} + \sum_{t=t_0}^T \inner{\mu^t}{b^{t}} \tag{by \cref{eq:bonus}}\\
    \leq& O\round{\delta^{-2} \log(T/\zeta') + \sqrt{\frac{T\log(AT/\zeta)}{\delta}}} + \sum_{t=t_0}^T \inner{\mu^t}{b^{t}},
\end{align*}
with probability at least $1-\zeta-\zeta'$. Using $\sum_{t=t_0}^T \exptn[\inner{\mu^t}{b^{t}}] \leq O( \sqrt{AT\log(AT/\zeta)} )$ \citep{auer2008near}, $\delta\leq1/A$ and integrating out the regret under the failure event yields the result.