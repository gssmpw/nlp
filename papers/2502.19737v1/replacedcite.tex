\section{Related Work}
\subsection{Minimal Pairs}
\begin{table}[t]
    \flushleft
    \small
    \scalebox{0.8}{
    \begin{tabular}{llll}
    \hline
    \textbf{Name}    & \textbf{Size} (k)& \textbf{N}        & \textbf{Language}                                                                                                                                                                                               \\ \hline
    \textcolor{red}{BLiMP} ____   & 67& 67 & English                                                                                                                                                                                                \\
    \textcolor{red}{CLiMP} ____   & 16& 16 & Chinese                                                                                                                                                                                                \\
    \textcolor{red}{SLING} ____   & 38& 38 & Chinese                                                                                                                                                                                                \\
    \textcolor{red}{ZhoBLiMP} ____ & 35& 118 & Chinese  
        \\
    \textcolor{red}{BLiMP-NL} ____& 8.4& 22&Dutch\\
    \textcolor{red}{JBLiMP} ____  & 0.33& 39 & Japanese                                                                                                                                                                                               \\
    \textcolor{red}{RuBLiMP} ____ & 45& 45  & Russian                                                                                                                                                                                                \\
    \textcolor{red}{NoCoLa} ____  & 99.1& 11 & Norwegian                                                                                                                                                                                              \\
    \textcolor{red}{DaLAJ} ____  & 4.8& 4 & Swedish                                                                                                                                                                                                \\
    \textcolor{red}{LINDSEA} ____ & 0.38& 38& Indonesian\\
 & 0.2& 20&Tamil\\
    \textcolor{red}{CLAMS} ____  & 331.5& 7 & 5 Languages*\\
    \textcolor{blue}{COMPS} ____  & 49.3& 4 & English                                                                                                                                                                                                \\
    \hline
    \textcolor{blue}{XCOMPS} (Ours)  & 244.3& 4 & 17 Languages**\\ \hline
    \end{tabular}}
    \caption{
    \small
    Summary of existing minimal pair datasets. Benchmarks in red represent \textcolor{red}{\textit{grammatical}} tasks while benchmarks in blue denote \textcolor{blue}{\textit{conceptual}} minimal pairs. Size: \# of minimal pairs in total, N: \# of linguistic paradigms. *: English, French, German, Hebrew, Russian. **: Details  in Table \ref{lang_info}. }
     % 2 \textit{analytic} (Chinese, Vietnamese); 11 \textit{inflected} (Arabic, Catalan, Dutch, French, German, Greek, Hebrew, Persian, Russian, Spanish, Ukrainian) and 4 \textit{agglutinative} (Hungarian, Japanese, Korean, Turkish). Arabic, Catalan, , Dutch, French, German, Greek, Hebrew, Hungarian, Japanese, Korean, Persian, Russian, Spanish, Turkish, Ukrainian, and Turkish.
    \label{tab:minimal_pair_datasets}
    \end{table}

One prominent approach for language model assessments has been the use of minimal pairs---carefully designed sentence pairs differing by a minimal linguistic expression. These tests probe specific aspects of linguistic competence by examining the model's ability to differentiate between correct and incorrect usages. This line of research was pioneered by Linzen and colleagues ____ in their Targeted Syntactic Evaluation dataset, which focused on syntax. Here's an example:
\begin{tabbing}
\hspace*{0.5cm}a. \=  The manager \underline{is} young. (\textit{acceptable})\\
\hspace*{0.5cm}b. \> *The manager \underline{are} young. (\textit{unacceptable})
\end{tabbing}
% A language model is regarded as successful in this task if it assigns greater probability to the acceptable sentence over the unacceptable one, indicating its ability to distinguish between them.

Subsequently, the BLiMP (Benchmark of Linguistic Minimal Pairs) ____ dataset emerged as a large-scale resource for assessing syntactic knowledge across a variety of linguistic phenomena. Building on this foundation, researchers expanded such evaluations to non-English languages, as summarized in Table \ref{tab:minimal_pair_datasets}. These efforts included datasets for French, Russian, German, Swedish, Hebrew, Japanese, and Chinese, extending the applicability of minimal pair testing to diverse linguistic systems.

In parallel, semantic understanding in LLMs has begun to gain attention, with the COMPS dataset by ____ representing the first effort to assess pre-trained language models' (PLMs) semantic knowledge using minimal pairs. COMPS introduced a novel methodology for testing the ability to attribute properties to concepts and reason about property inheritance. 

\subsection{Language Performance vs. Competence}
As suggested in ____, LLMs can be evaluated through three methods: \textit{metalinguistic prompting}, which assesses \textit{performance} based on explicit responses; direct probability measurement, which provides an intermediate evaluation by comparing model-generated probabilities; and \textit{neurolinguistic probing}, which directly examines \textit{competence} by analyzing internal activation patterns\footnote{For simplicity, we refer to these three methods as Meta, Direct, Neuro.}.
\paragraph{Metalinguistic Prompting for Performance} This method involves explicitly querying the model about linguistic expressions, often in a comparative or multiple-choice format. By asking the model to choose between minimal pairs (e.g., ``Which sentence is more grammatically correct?''), researchers can evaluate how well the model retrieves and verbalizes knowledge. Using prompting, researchers have revealed new classes of emergent abilities such as arithmetic, instruction-following, grounded conceptual mappings and sentence acceptability judgments ____. Because the responses are influenced by prompt engineering and surface-level cues, this method primarily reflects performance rather than deep conceptual competence.
\paragraph{Direct Probability Measurement} Instead of relying on explicit responses, this method examines the model's probability assignment to different sentences within minimal pairs. For example, a model should assign a higher probability to `A robin can fly' than to `A penguin can fly'. This approach offers a more objective evaluation than metalinguistic prompting and captures implicit model preferences, placing it between performance and competence.  Researchers have designed syntactic, semantic/conceptual, and discourse inference tasks using the probability assignment method, offering different insights into LLMs' capabilities compared to metalinguistic prompting ____.
However, it still relies on external outputs and does not fully reveal how the model internally represents concepts.
\paragraph{Neurolinguistic Probing for Competence} This approach goes beyond external outputs by analyzing internal activation patterns across different layers of the model. Using diagnostic classifiers, researchers can probe whether LLMs inherently encode conceptual-property relationships or simply rely on statistical correlations. Since it provides a direct measure of competence, neurolinguistic probing is a more reliable for assessing the depth of linguistic understanding. 
% However, it requires additional computational resources and interpretation, making it more complex than the other methods.
\begin{table*}[h]
\flushleft
\small
\scalebox{0.8}{
\begin{tabular}{llll}
\hline
\textbf{Type}          & \textbf{Language}   & \textbf{Acceptable Sentence}                                                                                                                   & \textbf{Unacceptable Sentence}                                                                                                             \\ \hline
Taxonomic     & Spanish    & \begin{tabular}[c]{@{}l@{}}\textit{Tostadora} se utiliza para calentar alimentos.\\ (A toaster is used for heating food.)\end{tabular}         & \begin{tabular}[c]{@{}l@{}}\textit{Cafetera} se utiliza para calentar alimentos.\\ (A coffee maker is used for heating food.)\end{tabular} \\
Overlap       & Vietnamese & \begin{tabular}[c]{@{}l@{}}\textit{Máy nướng bánh mì được} sử dụng để hâm nóng thực phẩm.\\ (A toaster is used for heating food.)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textit{Tủ lạnh được }sử dụng để hâm nóng thực phẩm.\\ (A refrigerator is used for heating food.)\end{tabular}  \\
Co-occurrence & Hungarian  & \begin{tabular}[c]{@{}l@{}}\textit{Kenyérpirító} ételek melegítésére használják.\\ (A toaster is used for heating food.)\end{tabular}          & \begin{tabular}[c]{@{}l@{}}\textit{Vízforraló} ételek melegítésére használják.\\ (A kettle is used for heating food.)\end{tabular}         \\
Random        & Dutch      & \begin{tabular}[c]{@{}l@{}}\textit{Broodrooster} wordt gebruikt om voedsel te verwarmen.\\ (A toaster is used for heating food.)\end{tabular}  & \begin{tabular}[c]{@{}l@{}}\textit{Winterkoning} wordt gebruikt om voedsel te verwarmen.\\ (A wren is used for heating food.)\end{tabular} \\ \hline
\end{tabular}}
\caption{\small XCOMPS examples, illustrating each linguistic variant pairs an acceptable sentence (positively matched property) with an unacceptable counterpart (negatively matched property).}
\label{tab:xcomps}
\end{table*}
\subsection{Multilingual Evaluation Benchmark}
Multilingual evaluation benchmarks have played a pivotal role in assessing the capabilities of language models across diverse languages. In the realm of multilingual probing, prior work has focused on evaluating linguistic properties and knowledge representation. For instance, ____ introduced MELA to assess multilingual linguistic acceptability, while ____ explored syntactic minimal pairs to evaluate cross-linguistic syntactic competence. On the knowledge probing front, benchmarks such as MLAMA ____, BMLAMA ____, and BMIKE-53 ____ have been developed to investigate the factual knowledge encoded in multilingual models and their cross-lingual consistency.

Beyond probing, multilingual natural language understanding (NLU) benchmarks like XTREME ____ and XGLUE ____ have become standard for evaluating cross-lingual transferability. These benchmarks often rely on translating English datasets into other languages, as seen in tasks like XNLI ____, PAWS-X ____, and MLQA ____. On the generation side, multilingual natural language generation (NLG) benchmarks have emerged, covering tasks such as summarization ____. With the rise of multitask instruction finetuning, multilingual instruction datasets like Supernatural Instructions ____ and xP3 ____ have further expanded the scope of multilingual evaluation.

Despite these advancements, a critical gap remains in evaluating multilingual conceptual understanding, particularly in the format of conceptual minimal pairs. Our work addresses this gap by introducing XCOMPS, a multilingual benchmark specifically designed to evaluate conceptual understanding across languages.