To enhance our translation capabilities, we implemented Retrieval Augmented Generation (RAG)~\cite{lewis2020retrieval} with anonymized embeddings. First, as a pre-process, we anonymized all train sentences by converting name references into pronouns. Next, we embedded the anonymized sentences using an OpenAI embeddings model. Finally, at inference, for each test sentence, we embedded it as well and look for the $N$ most similar examples to this sentence based on the cosine similarity between the embedding of the test example, and the embeddings of the anonymized train examples. This way, the model is presented with the most accurate and relevant examples. As Table~\ref{tab:text-to-gloss_RAG_eval_results_appx} shows, when using RAG the results are better than using all of the train examples. Moreover, using fewer examples and anonymized embeddings yields better results in most cases. The reason for using anonymization, is that names are given high weight in the embedding, which leads to less relevant examples in some cases. For examples, the 3 most similar sentence for the sentence "Which college did Mary go to?" before anonymization, are: "Which college does Mary go to?", "What did Mary's name used to be?", "Mary used to live in Boston.", While after anonymization they are: "Which college does Mary go to?", "Which high school did you go to?", "Where did you go to high school?", which are more relevant and similar examples.
