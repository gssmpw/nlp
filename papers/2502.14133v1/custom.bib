@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}
@article{foote2023neuron,
  title={Neuron to graph: Interpreting language model neurons at scale},
  author={Foote, Alex and Nanda, Neel and Kran, Esben and Konstas, Ioannis and Cohen, Shay and Barez, Fazl},
  journal={arXiv preprint arXiv:2305.19911},
  year={2023}
}
@article{rajamanoharan2024improving,
  title={Improving dictionary learning with gated sparse autoencoders},
  author={Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Lieberum, Tom and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.16014},
  year={2024}
}
@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}
@misc{mistralapi,
      title={Mistral AI API (0.0.2)}, 
      author={Mistral AI},
      year={2024},
      url={https://docs.mistral.ai/api/}, 
}
@article{wang2023improving,
  title={Improving text embeddings with large language models},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2401.00368},
  year={2023}
}
@article{hort2024bias,
  title={Bias mitigation for machine learning classifiers: A comprehensive survey},
  author={Hort, Max and Chen, Zhenpeng and Zhang, Jie M and Harman, Mark and Sarro, Federica},
  journal={ACM Journal on Responsible Computing},
  volume={1},
  number={2},
  pages={1--52},
  year={2024},
  publisher={ACM New York, NY}
}
@inproceedings{huang2019stable,
  title={Stable and fair classification},
  author={Huang, Lingxiao and Vishnoi, Nisheeth},
  booktitle={International Conference on Machine Learning},
  pages={2879--2890},
  year={2019},
  organization={PMLR}
}
@inproceedings{kamishima2011fairness,
  title={Fairness-aware learning through regularization approach},
  author={Kamishima, Toshihiro and Akaho, Shotaro and Sakuma, Jun},
  booktitle={2011 IEEE 11th international conference on data mining workshops},
  pages={643--650},
  year={2011},
  organization={IEEE}
}
@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}
@article{wang2018glue,
  title={Glue: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}
@book{fischer2011history,
  title={A history of the central limit theorem: from classical to modern probability theory},
  author={Fischer, Hans},
  volume={4},
  year={2011},
  publisher={Springer}
}
@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}
@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}
@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}
@inproceedings{zafar2017fairness,
  title={Fairness constraints: Mechanisms for fair classification},
  author={Zafar, Muhammad Bilal and Valera, Isabel and Rogriguez, Manuel Gomez and Gummadi, Krishna P},
  booktitle={Artificial intelligence and statistics},
  pages={962--970},
  year={2017},
  organization={PMLR}
}
@article{cunningham2023sparse,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  journal={arXiv preprint arXiv:2309.08600},
  year={2023}
}
@article{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{ross2017focal,
  title={Focal loss for dense object detection},
  author={Ross, T-YLPG and Doll{\'a}r, GKHP},
  booktitle={proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2980--2988},
  year={2017}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}
@article{loshchilov2017fixing,
  title={Fixing weight decay regularization in adam},
  author={Loshchilov, Ilya and Hutter, Frank and others},
  journal={arXiv preprint arXiv:1711.05101},
  volume={5},
  year={2017}
}
@misc{chen2024codinterpretablemedicalagent,
      title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis}, 
      author={Junying Chen and Chi Gui and Anningzhe Gao and Ke Ji and Xidong Wang and Xiang Wan and Benyou Wang},
      year={2024},
      eprint={2407.13301},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.13301}, 
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{zheng2023lmsys,
  title={Lmsys-chat-1m: A large-scale real-world llm conversation dataset},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Li, Tianle and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Li, Zhuohan and Lin, Zi and Xing, Eric P and others},
  journal={arXiv preprint arXiv:2309.11998},
  year={2023}
}
@misc{lin2023toxicchat,
      title={ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation}, 
      author={Zi Lin and Zihan Wang and Yongqi Tong and Yangkun Wang and Yuxin Guo and Yujia Wang and Jingbo Shang},
      year={2023},
      eprint={2310.17389},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{xu2019end,
  title={End-to-end knowledge-routed relational dialogue system for automatic diagnosis},
  author={Xu, Lin and Zhou, Qixian and Gong, Ke and Liang, Xiaodan and Tang, Jianheng and Lin, Liang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={7346--7353},
  year={2019}
}
@misc{trenton2024dictionary,
  title={Using Dictionary Learning Features as Classifiers},
  author={Bricken, Trenton and Marcus, Jonathan and Mishra-Sharma, Siddharth and Tong, Meg and Perez, Ethan and Sharma, Mrinank and Rivoire,Kelley and Henighan, Thomas and Jermyn, Adam },
  howpublished={\url{https://transformer-circuits.pub/2024/features-as-classifiers/index.html}},
  year={2024}
}
@article{lambert2024rewardbench,
  title={Rewardbench: Evaluating reward models for language modeling},
  author={Lambert, Nathan and Pyatkin, Valentina and Morrison, Jacob and Miranda, LJ and Lin, Bill Yuchen and Chandu, Khyathi and Dziri, Nouha and Kumar, Sachin and Zick, Tom and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2403.13787},
  year={2024}
}
@misc{dictionaryworries,
  title={Dictionary Learning Worries},
  author={Tom, Henighan and Chris, Olah},
  howpublished={\url{https://transformer-circuits.pub/2023/may-update/index.html#dictionary-worries}},
  year={2023}
}
@article{rajamanoharan2024jumping,
  title={Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders},
  author={Rajamanoharan, Senthooran and Lieberum, Tom and Sonnerat, Nicolas and Conmy, Arthur and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Nanda, Neel},
  journal={arXiv preprint arXiv:2407.14435},
  year={2024}
}
@article{templeton2024scaling,
       title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
       author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
       year={2024},
       journal={Transformer Circuits Thread},
       url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
    }
@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}
@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}
@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}
@inproceedings{blei2006dynamic,
  title={Dynamic topic models},
  author={Blei, David M and Lafferty, John D},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={113--120},
  year={2006}
}
@inproceedings{collobert2008unified,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008}
}
@inproceedings{mnih2007three,
  title={Three new graphical models for statistical language modelling},
  author={Mnih, Andriy and Hinton, Geoffrey},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={641--648},
  year={2007}
}
@article{arora2016latent,
  title={A latent variable model approach to pmi-based word embeddings},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={385--399},
  year={2016},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{gao2024scaling,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}
@article{lieberum2024gemma,
  title={Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2408.05147},
  year={2024}
}
@article{aizawa2003information,
  title={An information-theoretic perspective of tf--idf measures},
  author={Aizawa, Akiko},
  journal={Information Processing \& Management},
  volume={39},
  number={1},
  pages={45--65},
  year={2003},
  publisher={Elsevier}
}
@article{salton1988term,
  title={Term-weighting approaches in automatic text retrieval},
  author={Salton, Gerard and Buckley, Christopher},
  journal={Information processing \& management},
  volume={24},
  number={5},
  pages={513--523},
  year={1988},
  publisher={Elsevier}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@article{arora2018linear,
  title={Linear algebraic structure of word senses, with applications to polysemy},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={483--495},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@book{cover1999elements,
  title={Elements of information theory},
  author={Cover, Thomas M},
  year={1999},
  publisher={John Wiley \& Sons}
}
@article{chaudhary2024evaluating,
  title={Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small},
  author={Chaudhary, Maheep and Geiger, Atticus},
  journal={arXiv preprint arXiv:2409.04478},
  year={2024}
}
@inproceedings{makelov2024towards,
  title={Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control},
  author={Makelov, Aleksandar and Lange, Georg and Nanda, Neel},
  booktitle={ICLR 2024 Workshop on Secure and Trustworthy Large Language Models},
  year={2024}
}
@article{deng2023multilingual,
  title={Multilingual jailbreak challenges in large language models},
  author={Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong},
  journal={arXiv preprint arXiv:2310.06474},
  year={2023}
}
@article{robey2023smoothllm,
  title={Smoothllm: Defending large language models against jailbreaking attacks},
  author={Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J},
  journal={arXiv preprint arXiv:2310.03684},
  year={2023}
}
@article{xie2023defending,
  title={Defending chatgpt against jailbreak attack via self-reminders},
  author={Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1486--1496},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@article{cao2023defending,
  title={Defending against alignment-breaking attacks via robustly aligned llm},
  author={Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui},
  journal={arXiv preprint arXiv:2309.14348},
  year={2023}
}
@article{li2024salad,
  title={Salad-bench: A hierarchical and comprehensive safety benchmark for large language models},
  author={Li, Lijun and Dong, Bowen and Wang, Ruohui and Hu, Xuhao and Zuo, Wangmeng and Lin, Dahua and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2402.05044},
  year={2024}
}
@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{olah2020zoom,
  title={Zoom in: An introduction to circuits},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  volume={5},
  number={3},
  pages={e00024--001},
  year={2020}
}
@article{brickentowards,
       title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
       author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
       year={2023},
       journal={Transformer Circuits Thread},
       note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
    }
@article{scherlis2022polysemanticity,
  title={Polysemanticity and capacity in neural networks},
  author={Scherlis, Adam and Sachan, Kshitij and Jermyn, Adam S and Benton, Joe and Shlegeris, Buck},
  journal={arXiv preprint arXiv:2210.01892},
  year={2022}
}
@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}
@article{olshausen1997sparse,
  title={Sparse coding with an overcomplete basis set: A strategy employed by V1?},
  author={Olshausen, Bruno A and Field, David J},
  journal={Vision research},
  volume={37},
  number={23},
  pages={3311--3325},
  year={1997},
  publisher={Elsevier}
}
@incollection{steyvers2007probabilistic,
  title={Probabilistic topic models},
  author={Steyvers, Mark and Griffiths, Tom},
  booktitle={Handbook of latent semantic analysis},
  pages={439--460},
  publisher={Psychology Press},
  year={2007}
}
@article{cunningham2023sparse,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  journal={arXiv preprint arXiv:2309.08600},
  year={2023}
}
@article{Beren2022SVD,
  title={The Singular Value Decompositions of Transformer Weight Matrices are Highly Interpretable},
  author={Beren and Sid Black},
  howpublished={\url{https://www.lesswrong.com/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight}},
  year={2022}
}
@article{shareGPT,
  title={ShareGPT Dataset},
  author={RyokoAI},
  howpublished={\url{https://huggingface.co/datasets/RyokoAI/ShareGPT52K}},
  year={2023}
}

@misc{wang2024helpsteer2,
      title={HelpSteer2: Open-source dataset for training top-performing reward models}, 
      author={Zhilin Wang and Yi Dong and Olivier Delalleau and Jiaqi Zeng and Gerald Shen and Daniel Egert and Jimmy J. Zhang and Makesh Narsimhan Sreedhar and Oleksii Kuchaiev},
      year={2024},
      eprint={2406.08673},
      archivePrefix={arXiv},
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}
@misc{millidge2022singular,
    author = {Millidge, Beren and Black, Sid},
    title = {The singular value decompositions of transformer weight matrices are highly interpretable.},
    URL={https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight},
    year={2022}
}
@inproceedings{huben2023sparse,
  title={Sparse Autoencoders Find Highly Interpretable Features in Language Models},
  author={Huben, Robert and Cunningham, Hoagy and Smith, Logan Riggs and Ewart, Aidan and Sharkey, Lee},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{baharlouei2019r,
  title={R$\backslash$'enyi fair inference},
  author={Baharlouei, Sina and Nouiehed, Maher and Beirami, Ahmad and Razaviyayn, Meisam},
  journal={arXiv preprint arXiv:1906.12005},
  year={2019}
}
@article{quadrianto2017recycling,
  title={Recycling privileged learning and distribution matching for fairness},
  author={Quadrianto, Novi and Sharmanska, Viktoriia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{zafar2017fairness,
  title={Fairness constraints: Mechanisms for fair classification},
  author={Zafar, Muhammad Bilal and Valera, Isabel and Rogriguez, Manuel Gomez and Gummadi, Krishna P},
  booktitle={Artificial intelligence and statistics},
  pages={962--970},
  year={2017},
  organization={PMLR}
}
@inproceedings{wu2024language,
  title={From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning},
  author={Wu, Xuansheng and Yao, Wenlin and Chen, Jianshu and Pan, Xiaoman and Wang, Xiaoyang and Liu, Ninghao and Yu, Dong},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={2341--2369},
  year={2024}
}
@inproceedings{dar2023analyzing,
  title={Analyzing Transformers in Embedding Space},
  author={Dar, Guy and Geva, Mor and Gupta, Ankit and Berant, Jonathan},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={16124--16170},
  year={2023}
}
@inproceedings{chenprobing,
  title={Probing BERT in Hyperbolic Spaces},
  author={Chen, Boli and Fu, Yao and Xu, Guangwei and Xie, Pengjun and Tan, Chuanqi and Chen, Mosha and Jing, Liping},
  booktitle={International Conference on Learning Representations}
}
@inproceedings{hewitt2019structural,
  title={A structural probe for finding syntax in word representations},
  author={Hewitt, John and Manning, Christopher D},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4129--4138},
  year={2019}
}
@article{arora2018linear,
  title={Linear algebraic structure of word senses, with applications to polysemy},
  author={Arora, Sanjeev and Li, Yuanzhi and Liang, Yingyu and Ma, Tengyu and Risteski, Andrej},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={483--495},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{scherlis2022polysemanticity,
  title={Polysemanticity and capacity in neural networks},
  author={Scherlis, Adam and Sachan, Kshitij and Jermyn, Adam S and Benton, Joe and Shlegeris, Buck},
  journal={arXiv preprint arXiv:2210.01892},
  year={2022}
}
@inproceedings{sun2019mitigating,
  title={Mitigating Gender Bias in Natural Language Processing: Literature Review},
  author={Sun, Tony and Gaut, Andrew and Tang, Shirlyn and Huang, Yuxin and ElSherief, Mai and Zhao, Jieyu and Mirza, Diba and Belding, Elizabeth and Chang, Kai-Wei and Wang, William Yang},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1630--1640},
  year={2019}
}
@inproceedings{krishna2022measuring,
  title={Measuring Fairness of Text Classifiers via Prediction Sensitivity},
  author={Krishna, Satyapriya and Gupta, Rahul and Verma, Apurv and Dhamala, Jwala and Pruksachatkun, Yada and Chang, Kai-Wei},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5830--5842},
  year={2022}
}
@article{zhou2024navigating,
  title={Navigating the shortcut maze: A comprehensive analysis of shortcut learning in text classification by language models},
  author={Zhou, Yuqing and Tang, Ruixiang and Yao, Ziyu and Zhu, Ziwei},
  journal={arXiv preprint arXiv:2409.17455},
  year={2024}
}
@article{zhu2023large,
  title={Large language models for information retrieval: A survey},
  author={Zhu, Yutao and Yuan, Huaying and Wang, Shuting and Liu, Jiongnan and Liu, Wenhan and Deng, Chenlong and Dou, Zhicheng and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2308.07107},
  year={2023}
}
@inproceedings{markov2023holistic,
  title={A holistic approach to undesired content detection in the real world},
  author={Markov, Todor and Zhang, Chong and Agarwal, Sandhini and Nekoul, Florentine Eloundou and Lee, Theodore and Adler, Steven and Jiang, Angela and Weng, Lilian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={15009--15018},
  year={2023}
}
@article{tusher2024email,
  title={Email spam: A comprehensive review of optimize detection methods, challenges, and open research problems},
  author={Tusher, Ekramul Haque and Ismail, Mohd Arfian and Rahman, Md Arafatur and Alenezi, Ali H and Uddin, Mueen},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}
@article{hoerl1970ridge,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis}
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}
@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}
@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}
@inproceedings{liu2023webglm,
  title={WebGLM: Towards an efficient web-enhanced question answering system with human preferences},
  author={Liu, Xiao and Lai, Hanyu and Yu, Hao and Xu, Yifan and Zeng, Aohan and Du, Zhengxiao and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4549--4560},
  year={2023}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{ding2023enhancing,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2305.14233},
  year={2023}
}
@article{freire2024uncovering,
  title={Uncovering Latent Human Wellbeing in Language Model Embeddings},
  author={Freire, Pedro and Tan, ChengCheng and Gleave, Adam and Hendrycks, Dan and Emmons, Scott},
  journal={arXiv preprint arXiv:2402.11777},
  year={2024}
}
@article{gurneefinding,
  title={Finding Neurons in a Haystack: Case Studies with Sparse Probing},
  author={Gurnee, Wes and Nanda, Neel and Pauly, Matthew and Harvey, Katherine and Troitskii, Dmitrii and Bertsimas, Dimitris},
  journal={Transactions on Machine Learning Research},
year={2023}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@misc{Nostal2020Logit,
   title = {Interpreting GPT: the logit lens},
   author = {Nostalgebraist},
   year = {2020},
   howpublished = {\url{https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens}},
}
@article{belrose2023eliciting,
  title={Eliciting latent predictions from transformers with the tuned lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.08112},
  year={2023}
}
@inproceedings{wu2024language,
  title={From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning},
  author={Wu, Xuansheng and Yao, Wenlin and Chen, Jianshu and Pan, Xiaoman and Wang, Xiaoyang and Liu, Ninghao and Yu, Dong},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={2341--2369},
  year={2024}
}
@article{marks2023geometry,
  title={The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
  author={Marks, Samuel and Tegmark, Max},
  journal={arXiv preprint arXiv:2310.06824},
  year={2023}
}
@inproceedings{burnsdiscovering,
  title={Discovering Latent Knowledge in Language Models Without Supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  booktitle={The Eleventh International Conference on Learning Representations}
}
@article{campbell2023localizing,
  title={Localizing lying in llama: Understanding instructed dishonesty on true-false questions through prompting, probing, and patching},
  author={Campbell, James and Ren, Richard and Guo, Phillip},
  journal={arXiv preprint arXiv:2311.15131},
  year={2023}
}
@article{belinkov2018evaluating,
  title={Evaluating layers of representation in neural machine translation on part-of-speech and semantic tagging tasks},
  author={Belinkov, Yonatan and M{\`a}rquez, Llu{\'\i}s and Sajjad, Hassan and Durrani, Nadir and Dalvi, Fahim and Glass, James},
  journal={arXiv preprint arXiv:1801.07772},
  year={2018}
}
@inproceedings{jawahar2019does,
  title={What does BERT learn about the structure of language?},
  author={Jawahar, Ganesh and Sagot, Beno{\^\i}t and Seddah, Djam{\'e}},
  booktitle={ACL 2019-57th Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}
@article{rogers2021primer,
  title={A primer in BERTology: What we know about how BERT works},
  author={Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={842--866},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{elhage2022toy,
  title={Toy models of superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}
@article{wang2024probing,
  title={Probing the Emergence of Cross-lingual Alignment during LLM Training},
  author={Wang, Hetong and Minervini, Pasquale and Ponti, Edoardo M},
  journal={arXiv preprint arXiv:2406.13229},
  year={2024}
}
@article{wang2023label,
  title={Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning},
  author={Wang, Lean and Li, Lei and Dai, Damai and Chen, Deli and Zhou, Hao and Meng, Fandong and Zhou, Jie and Sun, Xu},
  journal={arXiv arXiv:2305.14160},
  year={2023}
}
@inproceedings{chen2024rarebench,
  title={RareBench: Can LLMs Serve as Rare Diseases Specialists?},
  author={Chen, Xuanzhong and Mao, Xiaohao and Guo, Qihan and Wang, Lun and Zhang, Shuyang and Chen, Ting},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4850--4861},
  year={2024}
}
@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}
@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
@inproceedings{makelov2024sparse,
  title={Sparse Autoencoders Match Supervised Features for Model Steering on the IOI Task},
  author={Makelov, Aleksandar},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
  year={2024}
}
@article{marks2024sparse,
  title={Sparse feature circuits: Discovering and editing interpretable causal graphs in language models},
  author={Marks, Samuel and Rager, Can and Michaud, Eric J and Belinkov, Yonatan and Bau, David and Mueller, Aaron},
  journal={arXiv preprint arXiv:2403.19647},
  year={2024}
}
@inproceedings{dumas2024llamas,
  title={How do Llamas process multilingual text? A latent exploration through activation patching},
  author={Dumas, Cl{\'e}ment and Veselovsky, Veniamin and Monea, Giovanni and West, Robert and Wendler, Chris},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability}
}