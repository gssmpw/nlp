\subsection{Tensor Core}\label{sec:tensorcore}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{FIG/mem.pdf}
    \vspace{-25pt}
    \caption{Nvidia GPU memory hierarchy.}
    \label{fig:tcarch}
\end{figure}

Tensor Core is a specialized systolic array matrix engine~\cite{9460517} integrated within the Stream Multiprocessor (SM) of modern Nvidia GPUs. It operates alongside traditional CUDA cores. The execution pathway for both units follows the GPU's memory hierarchy: data is first loaded from global memory into the register file, from which either CUDA cores or Tensor Cores can access it for computation. This memory access abstraction aligns with previous studies~\cite{10579250,9931992}. Figure~\ref{fig:tcarch} illustrates this memory hierarchy and the relationship between different memory levels in Nvidia GPUs.

%, with both functioning as distinct types of Arithmetic Logic Units (ALUs)
% Tensor Core is a Matrix Engine implementation~\cite{9460517} and is part of Stream Multiprocessor (SM) inside GPU. As such, the relationship between the tensor core and CUDA core is akin to different types of ALUs. When executing a programming, data would first loaded from global memory to the register file, and then either CUDA core or Tensor Core would get the data from register files for further execution. We summarize the memory hierarchy of Nvidia GPU in Figure~\ref{fig:tcarch};
