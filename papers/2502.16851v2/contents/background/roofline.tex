% \section{Machine Balance and Roofline Model}

\subsection{Machine Balance} 

We define machine balance ($\mathbb{B}$)~\cite{mccalpin1995memory} as the ratio between peak computational performance ($P$) and memory bandwidth ($B$):
\begin{equation}\footnotesize
\mathbb{B}=\tfrac{P}{B}
\end{equation}
% ~\cite{CALLAHAN1988334,mccalpin1995memory} 
\subsection{Roofline Model}
The roofline model~\cite{williams2009roofline,ofenbeck2014applying} provides an upper-bound performance prediction framework based on operational intensity ($\mathbb{I}$), which is defined as the ratio of computational work ($\mathbb{W}$) to memory traffic ($\mathbb{Q}$):
\begin{equation}\footnotesize
\mathbb{I}=\tfrac{\mathbb{W}}{\mathbb{Q}}
\end{equation}
The model calculates attainable performance ($\mathbb{P}$) as:
\begin{equation}\footnotesize
\mathbb{P}=\min(P, B\times \mathbb{I})
\end{equation}
% where $P$ represents peak computational performance and $B$ denotes memory bandwidth. 
This visualization framework helps identify system bottlenecks and performance limits.
\subsection{Tensor Core in the Roofline Model}
As discussed in Section~\ref{sec:tensorcore}, tensor cores can be represented as an additional performance ceiling above the CUDA core baseline in the roofline model, because tensor cores and CUDA cores share the same memory hierarchy and cannot operate simultaneously due to the Dark Silicon Effect. This roofline abstraction aligns with an existing study~\cite{yang2020hierarchical}.
% \subsubsection{Limitations}
% While the roofline model provides intuitive performance insights, it has two key limitations. First, it does not inherently account for cache behavior, though extensions have been proposed to address this~\cite{ilic2013cache}. Second, it assumes perfect overlap between computation and memory access, which might not be achievable in practical applications~\cite{10.1145/3650200.3656634}.


\subsection{Relationship Between Machine Balance and Roofline Model}
The roofline model provides a framework for understanding performance bottlenecks through the interplay of two critical metrics: operational intensity and machine balance. While operational intensity ($\mathbb{I}$) characterizes a kernel's computational density, machine balance ($\mathbb{B}$) represents the hardware's ratio of computational capability to memory bandwidth. The relationship between these metrics determines whether a kernel's performance is mainly limited by computation or memory access:
\begin{equation}\footnotesize
A\ kernel\ is =
\begin{cases}
compute-bound, & \text{if } \mathbb{I}> \mathbb{B}\\
memory-bound,  & \text{if } \mathbb{I}< \mathbb{B}
\end{cases}
\end{equation}

As illustrated in Figure~\ref{fig:roofline}, machine balance manifests as the inflection point in the roofline curve for both GH200 and A100-80GB GPUs. This point marks the transition from memory-bound to compute-bound behavior.%, effectively dividing the performance space into two distinct regions.

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{FIG/roofline.pdf}
\vspace{-30pt}
\caption{\label{fig:roofline} An example of the roofline model for both GH200 and A100-80GB GPU.
}
\end{figure*}



% \subsection{Roofline Model}
% The roofline model~\cite{williams2009roofline,ofenbeck2014applying} is an up-bound performance prediction framework that uses operational intensity ($\mathbb{I}$) - the ratio of computational work ($\mathbb{W}$) to memory traffic ($\mathbb{Q}$):

% \begin{equation}\footnotesize
% \mathbb{I}=\frac{\mathbb{W}}{\mathbb{Q}}
% \end{equation}

% The model determines attainable performance ($\mathbb{P}$) as:
% \begin{equation}\footnotesize
% \mathbb{P}=\min(P, B\times \mathbb{I})
% \end{equation}
% 
% where $P$ represents peak computational performance and $B$ denotes memory bandwidth. This visualization helps identify system bottlenecks and performance limits.

% \subsubsection{Tensor Core in Roofline} As analyzed in Section~\ref{sec:tensorcore}, we consider the tensor core an additional line on top of the CUDA Core performance. Because the tensor core and cuda core share the same memory hierarchy it is impossible to use them simultaneously due to the Dark Silicon Effect. This abstraction is similar to existing study~\cite{yang2020hierarchical}.

% \subsubsection{Limitation:} The roofline model is an intuitive tool. However, it could not natively explain the cache behavior. Some research further extends the roofline model to support cache~\cite{ilic2013cache}. Additionally, roofline model assumes a perfect overlap in computation and memory access, which is usually hard in real word application~\cite{10.1145/3650200.3656634}.




% The roofline model evaluates kernel performance, with operational intensity characterizing the kernel and machine balance characterizing the hardware. Their intersection determines performance bottlenecks:


% \begin{equation}\footnotesize
%     A\ kernel\ is = 
% \begin{cases}
%     compute-bound, & \text{if } \mathbb{I}> \mathbb{B}\\
%     memory-bound,  & \text{if } \mathbb{I}< \mathbb{B}
% \end{cases}
% \end{equation}

% Figure~\ref{fig:roofline} demonstrates the attainable performance bounds across kernels, with the machine balance creating a distinct inflection point in the performance curve.

% Lastly, it could not predict the behavior when latency becomes the bottleneck, which might be the case in small sparse matrix-vector multiplication.~\cite{10.1145/1815961.1816021}
% The roofline model is a tool used to analyze the performance of a given kernel. Here, the operation intensity is a feature of the kernel. On the other hand, the machine balance is a feature of a given hardware. The roofline model and machine balance intersect when determining whether a given kernel is compute-bound or memory-bound:

% \subsection{Tensor Core in Roofline Model}
% As analyzed in Section~\ref{sec:tensorcore}, we consider tensor core an additional line on top of the CUDA Core performance. Because tensor core and cuda core share a same memory hierarchy and it is impossible to use them simultaneous due to Dark Silicon Effect. This abstraction is similar to previous study~\cite{yang2020hierarchical}, 

% \subsection{Limitations of Roofline Model}

% The roofline model is an intuitive tool. However it could not natively explain the cache behavior. Some research further extends the roofline model to support cache~\cite{ilic2013cache}. Additionally, roofline model assume a perfect overlap in computation and memory access, which is usually hard in real word application~\cite{10.1145/3650200.3656634}. Lastly, it could not predict the behavior when latency becomes the bottleneck. 

