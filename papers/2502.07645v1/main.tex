\documentclass[journal]{IEEEtran}
\usepackage{times}

% numbers option provides compact numerical references in the text.
\let\labelindent\relax
\usepackage{enumitem}
\usepackage{jabbrv}
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]
{hyperref}

\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % Provides \coloneqq
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}

\usepackage{gensymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
% \usepackage{todonotes}
\usepackage{booktabs}
\usepackage{makecell}  % for \Xhline
\usepackage{tabularx} % For controlling table width
\usepackage{cases}  % provides the numcases environment

\usepackage{pifont} % for cross symbol

% \pdfinfo{
%    /Author (Homer Simpson)
%    /Title  (Robots: Our new overlords)
%    /CreationDate (D:20101201120000)
%    /Subject (Robots)
%    /Keywords (Robots;Overlords)
% }

\newtheorem{proposition}{Proposition}
\usepackage{multirow}

% make the caption of the table not in captical letters
\usepackage{caption}
\captionsetup{labelfont=bf, textfont=normal}
\captionsetup[table]{aboveskip=0pt}  % reduce the distance between a table and its above caption
\captionsetup[table]{belowskip=-5pt}  % Adjust 5pt as needed


\usepackage{svg}  % for svg type image

% to use \diagdown
\usepackage{amssymb}
% \usepackage{bbm} % for mathbb 1
% \usepackage{cite}

\newcommand{\issue}[1]{\vspace{0.1em}\noindent \textbf{#1 \hspace{0.2em}}} % for rebuttal.tex

\usepackage{booktabs} % for pandas-generated table
\usepackage{dblfloatfix}

% \usepackage[colorlinks=false, pdfborder={0 0 0}, hypertexnames=false]{hyperref}

\setlength{\textfloatsep}{3pt}
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\setlength{\abovedisplayshortskip}{2pt}
\setlength{\belowdisplayshortskip}{2pt}

\renewcommand*{\bibfont}{\footnotesize} % decrease the fontsize of bibliography

\begin{document}


% paper title
% \title{Direct Policy Shaping via Human Correction Feedback: a policy contrastive approach}
% \title{A General Approach for Policy Shaping via Action Contrasting}

% \title{
% Policy Shaping Through Interactive Action Contrasting: A Contrastive Approach in Action Space
% }

% \title{
% Policy Shaping Through Action Contrasting: A General Approach to Optimal Action Estimation
% }

% \title{
% Contrastive Policy Learning via Interactive Correction: A General Approach to Optimal Action Estimation
% }

% \title{Contrastive Policy Learning from Interactive Correction for Optimal Action Estimation}

% \title{Contrastive Policy Learning from Interactive Corrections via Optimal Action Estimation}


% \title{Contrastive Policy Learning from Interactive Corrections via Iterative  Undesired Actions Pruning}

% \title{Contrastive Policy Learning from Interactive Absolute and Relative Corrections}

% \title{Policy Shaping through Human Feedback via Contrastive Learning}

% \title{Policy Shaping through Human Feedback: \\A Contrastive Learning Perspective}

\title{Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning}

% \title{Beyond Behavior Cloning: Interactive Imitation and Contrastive Learning Enable Robust, Efficient Learning}

% \title{Beyond Behavior Cloning: Robustness and  Efficiency with Interactive Imitation and Contrastive Learning}

% \title{Beyond Behavior Cloning: \\ Achieving Robustness Efficiently with \\Interactive Imitation and Contrastive Learning}


% \title{Contrastive Policy Learning from Interactive Corrections via Contracting the Desired Action Space}


% You will get a Paper-ID when submitting a pdf file to the conference system
% \author{Author Names Omitted for Anonymous Review. Paper-ID 119}
\author{
    \IEEEauthorblockN{Zhaoting Li, Rodrigo P{\'e}rez-Dattari, Robert Babuska, Cosimo Della Santina, Jens Kober} \\
    \IEEEauthorblockA{Delft University of Technology, \{ z.li-23, r.j.perezdattari, r.babuska, c.dellasantina, j.kober \}@tudelft.nl}
    \href{https://clic-webpage.github.io }{https://clic-webpage.github.io}
}

% \author{\authorblockN{Zhaoting Li}
% \authorblockA{Department of Cognitive Robotics\\ Delft University of Technology\\ The
% Netherlands\\
% Email: Z.Li-23@tudelft.nl}
% \and
% \authorblockN{Rodrigo P{\'e}rez-Dattari}
% \authorblockA{Department of Cognitive Robotics\\ Delft University of Technology\\ The
% Netherlands\\
% Email: Z.Li-23@tudelft.nl}
% \and
% \authorblockN{ Robert Babuska}
% \authorblockA{Department of Cognitive Robotics\\ Delft University of Technology\\ The
% Netherlands\\
% Email: Z.Li-23@tudelft.nl}
% \and 
% \authorblockN{Cosimo Della Santina}
% \authorblockA{Department of Cognitive Robotics\\ Delft University of Technology\\ The
% Netherlands\\
% Email: Z.Li-23@tudelft.nl}
% \and
% \authorblockN{Jens Kober}
% \authorblockA{Department of Cognitive Robotics\\ Delft University of Technology\\ The
% Netherlands\\
% Email: Z.Li-23@tudelft.nl}}


% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Michael Shell\authorrefmark{1},
%Homer Simpson\authorrefmark{2},
%James Kirk\authorrefmark{3}, 
%Montgomery Scott\authorrefmark{3} and
%Eldon Tyrell\authorrefmark{4}}
%\authorblockA{\authorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: mshell@ece.gatech.edu}
%\authorblockA{\authorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\authorblockA{\authorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\authorblockA{\authorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}


\IEEEpeerreviewmaketitle
% \maketitle
\twocolumn[{%
	\renewcommand\twocolumn[1][]{#1}%
	\maketitle
        \vspace{-6mm}
	\begin{center}
		\includegraphics[width=0.99\textwidth]{figs/Fig_3_cover_Figure_3.pdf}
% \includesvg[width=0.99\textwidth,inkscapelatex=false]{figs/Fig_3_cover_Figure_3.svg}
 \captionof{figure}{\small
 A: Our method operates in an Interactive Imitation Learning framework. The robot's policy outputs a robot action $\bm a^r$, which interacts with the environment. The human teacher provides corrective feedback occasionally if the robot action is suboptimal.
 In (a1), such feedback stored in data buffer $\mathcal{ D}$ defines multiple desired action spaces. 
These regions collectively define an overall desired action space $\hat{\mathcal{A}}^{\mathcal{D}}$.
 In (a2), the policy, modeled as an energy-based model (EBM), is trained to generate actions within $\hat{\mathcal{A}}^{\mathcal{D}}$.
B: Examples of the learned EBMs in a 2D action space. Implicit BC \cite{2022_implicit_BC} overfits each action label, while our method estimates the optimal action without overfitting.
% The main difference is that, instead of lowering energy for each action label and raising it for others, our loss reduces energy for actions within a desired action space. 
% which is defined by the data and shown as the gray-shaded area (b1).
\label{fig:framework}}
	\end{center}
}]
% \begin{abstract} Behavior cloning (BC) traditionally relies on demonstration feedback, assuming the demonstrated actions are optimal. This assumption can lead to overfitting, particularly with expressive models like the energy-based model utilized in Implicit BC. To address this, we reformulate behavior cloning as an optimal action estimation problem and introduce \textit{Contrastive policy Learning from Interactive Corrections (CLIC)}. CLIC leverages human corrections—both absolute and relative—to construct a set of desired actions and optimizes the policy to select actions from this set. We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases. Extensive simulation and real-robot experiments validate CLIC's advantages over state-of-the-art BC methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback beyond demonstrations.
% To our best knowledge, this work offers a fresh perspective on policy learning by focusing on iteratively estimating optimal actions rather than directly imitating them. 
% The code will be publicly available. 
% \end{abstract}
\begin{abstract} Behavior cloning (BC) traditionally relies on demonstration data, assuming the demonstrated actions are optimal. This can lead to overfitting under noisy data, particularly when expressive models are used (e.g., the energy-based model in Implicit BC). To address this, we extend behavior cloning into an iterative process of optimal action estimation within the Interactive Imitation Learning framework. Specifically, we introduce \textit{Contrastive policy Learning from Interactive Corrections (CLIC)}. CLIC leverages human corrections to estimate a set of desired actions and optimizes the policy to select actions from this set. We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases. Extensive simulation and real-robot experiments validate CLIC's advantages over existing state-of-the-art methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback types beyond demonstrations. Our code will be publicly available soon.
% \textcolor{blue}{Our code will be publicly available upon acceptance.} 
\end{abstract}

% \begin{keywords}
%     Interactive Imitation Learning, Corrective feedback, Contrastive Learning, Learning from Demonstration, Energy-based Models
% \end{keywords}

\begin{IEEEkeywords}
Interactive Imitation Learning, Corrective feedback, Contrastive Learning, Learning from Demonstration, Energy-based Models
\end{IEEEkeywords}




\input{contents/01_introduction}
\input{contents/02_Related_work}
\input{contents/03_Preliminaries}
\input{contents/04_Methodology}
\input{contents/05_Experiment}
% \input{Discussion}
\input{contents/06_Conclusion}

\section*{Acknowledgments}
Omitted for Anonymous Review.

%% Use plainnat to work nicely with natbib. 
\input{contents/07_Appendix}

% % \bibliographystyle{plainnat}
% \bibliographystyle{unsrt} % Ensures citations appear in order
\bibliographystyle{jabbrv_ieeetr}
\bibliography{main}

% \bibliographystyle{./IEEEtranBST/IEEEtran}
% \bibliography{./IEEEtranBST/IEEEabrv, references}

% \input{rebuttal}

\end{document}


