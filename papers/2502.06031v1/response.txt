Intrusion detection systems play a crucial role in safeguarding \gls{IoT} networks. Numerous studies have focused on developing effective \gls{IDS} for \gls{IoT} networks, employing a variety of techniques ranging from traditional signature-based methods to more advanced \gls{ML} approaches. Notably, supervised learning algorithms, such as k-nearest neighbors (KNN), naïve bayes, and support vector machines (SVM) **Domingos & Pazzani, "On the Optimal Computation of Accurate Implications for Knowledge Acquisition"**,**Hearst, "Uncertainty in Artificial Intelligence,"**, have been extensively studied for their effectiveness in detecting anomalies. In  **Jensen & Cohen, "Multiple Comparisons in Multiple-Decision Procedures for Related Experiments"**, the authors conducted  several experiments to evaluate the efficiency and performance of various \gls{ML} classifiers, such as random forest, random tree, decision table, naive Bayes, and Bayes network. All the tests were conducted using the KDD dataset. The experiments demonstrated that there is no single \gls{ML} model that can handle efficiently all the types of attacks.
Furthermore, \gls{DL} techniques, such as \gls{CNN} or \gls{LSTM}  **LeCun et al., "Backpropagation Applied to Handwritten Zip Code Recognition"**,**Sundermeyer et al., "LSTM Neural Networks for Variable Length Sentence Modeling,"** are widely used in \gls{IDS}.\\
\indent The use of a single \gls{ML} model has inherent \mbox{limitations  **Vapnik, "The Nature of Statistical Learning Theory"**.} Thus, in recent years, various learning algorithms have been combined to enhance performance of \gls{IDS}  **Wang et al., "A Recurrent Neural Network Based Intrusion Detection System,"**. For instance, \mbox{in **Huang & Bishop, "The Equivalence Between Overcomplete Autoencoders and Nonlinear ICA,"** } the authors proposed an \gls{IDS} that combines the powerful learning ability of LSTM in time series data with \gls{CNN}'s ability to extract spatial features. The model was trained using KDD CUP99, NSL-KDD, and UNSW-NB15 classic datasets, the results show good convergence and performance.\\
\indent Despite these advancements, a significant challenge remains in dealing with imbalanced datasets, particularly regarding rare attacks detection. Traditional and even some advanced \gls{ML} models often struggle to accurately detect rare attacks due to their scarcity in the training data. Xu et al.  **Xu et al., "Intrusion Detection Based on Recurrent Neural Network,"** presented a recurrent neural network based \gls{IDS}. Their approach, tested on the NSL-KDD and KDD Cup'99 datasets, demonstrated promising results compared to other methodologies. However, it has a limitation in detecting minority attack classes, such as U2R and R2L, resulting in lower detection rates for these specific classes. Other works, such as **Kumar & Kumar, "Ensemble Learning Based Intrusion Detection System with Feature Selection,"**, have utilized ensemble learning with feature selection technique to enhance IDS performance on the CSE-CIC-IDS2018 dataset. While the overall detection accuracy has been improved, rare attack classes like SQL Injection and Brute Force were not well classified. Additionally, the infiltration attack class showed lower performance, revealing challenges in detecting these types of attacks. Moreover, in  **Abdelhamid et al., "Bagging-DNN-Based Intrusion Detection System,"**  the authors proposed a Bagging-DNN-based \gls{IDS} that addresses class imbalance by incorporating class weights and leveraging \gls{DNN} as core estimators. Their method achieved high performance across four datasets, with accuracy reaching 98.90\%, demonstrating effective detection of both known and unknown attacks. However, their experiments were limited to binary classification, which may restrict its applicability in multiclass scenarios, particularly for detecting rare attacks.

Existing works address the issue of imbalanced data by employing class-weighting techniques, undersampling, or oversampling. Class weighting effectively enhances rare attack detection without introducing redundancy, but it may lead to trade-offs in majority class performance and struggles with extremely rare classes. On the other hand, undersampling can lead to the loss of valuable information, while oversampling can introduce redundancy and overfitting. Alternatively, some approaches employ ensemble models to improve rare attack detection, although these methods can be computationally complex, especially when dealing with large dataset.

 \begin{figure}[t]
\centering
\includegraphics[width=0.41\textwidth]{Figures/data_distribution_plotColorBig.pdf}
    \caption{Class distribution of the dataset.}
    \label{fig: DataDistribution}
\end{figure}

\begin{table}[t]
  \caption{Selected files from the CSE-CIC-IDS2018 dataset}
  \resizebox{0.48\textwidth}{!}{
  \centering
    \begin{tabular}{c|c}
    \hline 
       \textbf{File name} &   \textbf{Class types}\\
       \hline \\
       Friday-16-02-2018 TrafficForML CICFlowMeter.csv  & Benign\\ & DoS attacks–Hulk \\[0.5em]

       Thursday-22-02-2018 TrafficForML CICFlowMeter.csv
       & Brute Force–XSS\\[0.5em]
       
       Friday-23-02-2018 TrafficForML CICFlowMeter.csv
       & SQL Injection\\[0.5em]
       
       Thursday-01-03-2018 TrafficForML CICFlowMeter.csv
       & Infilteration\\[0.5em]
       
       Friday-02-03-2018 TrafficForML CICFlowMeter.csv & Bot\\[0.5em]
       \hline                  
    \end{tabular}
    }
    \label{tab: Selected datasets}
\end{table}