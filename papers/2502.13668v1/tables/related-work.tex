\begin{table*}
\small
\centering
\begin{tabular}{@{}lllllllll@{}}
\toprule
Dataset & Papers & QA & Domain & \begin{tabular}[c]{@{}l@{}}Questioner\\Knowledge\end{tabular} & \begin{tabular}[c]{@{}l@{}}Question\\Source\end{tabular} & Annotators & \begin{tabular}[l]{@{}l@{}}Answer\\Source\end{tabular} & \begin{tabular}[l]{@{}l@{}}Answer\\Types\end{tabular}  \\ \midrule
BioASQ & 43011 & 4615 & BioMed. & -- & -- & Experts &  Abstract & Y/N, Ex, FF \\
QASPER & 1585 & 5049 & NLP  & Abstract & Crowdsourced & Practitioners &  Paper & Y/N, Ex, FF, U/A \\
QASA & 113 & 1798 & AI/ML & Full Paper & Crowdsourced & Practitioners &  Paper &  Ex, FF, U/A \\ \midrule
PeerQA & 208 & 579 & Multi & Full Paper & Reviews  & Experts &  Paper & Ex, FF, U/A \\ \bottomrule
\end{tabular}
\caption{Comparison of the most relevant scientific QA datasets. In BioASQ, experts come up with questions without a document in mind. Answer types abbreviations: Y/N = Yes/No, Ex = Extractive or Evidence Retrieval, FF = Free-Form Answers, U/A = Unanswerable). The QA column reports the number of question-answer annotations.
\looseness=-1}
\label{tbl:related-work-dataset-comparision}
\end{table*}