\begin{table*}[htpb]
\small
\centering
\begin{tabular}{@{}llcccccccc@{}}
\toprule
 &  & \multicolumn{4}{c}{MRR} & \multicolumn{4}{c}{Recall@10} \\ \cmidrule(lr){3-6}
\cmidrule(lr){7-10}
 Model & Architecture & Para. & +Title & Sent. & +Title & Para. & +Title & Sent. & +Title \\ \midrule
MiniLM-L12-v2 & Cross-Encoder & \textbf{0.4723} & \underline{0.4839} & \textbf{0.3644} & \textbf{0.3654} & 0.6467 & 0.6709 & 0.3505 & \textbf{0.3746} \\
Contriever & Dense & 0.3494 & 0.3624 & 0.2778 & 0.2773 & 0.5567 & 0.5340 & 0.2896 & 0.2910 \\
Contriever-MS & Dense & 0.4095 & 0.4408 & 0.3184 & 0.3160 & 0.6160 & 0.6314 & 0.3361 & 0.3538 \\
Dragon+ & Dense & \underline{0.4657} & \textbf{0.4845} & 0.3345 & 0.3433 & 0.6563 & \underline{0.6817} & \underline{0.3637} & 0.3667 \\
GTR-XL & Dense & 0.3955 & 0.4142 & 0.3048 & 0.2981 & 0.5940 & 0.6122 & 0.3522 & 0.3190 \\
ColBERTv2 & Multi-Dense & 0.4368 & 0.4122 & \underline{0.3480} & \underline{0.3491} & 0.6287 & 0.6371 & 0.3607 & 0.3544 \\
BM25 & Sparse & 0.4288 & -- & 0.2850 & -- & 0.6388 & -- & 0.3058 & -- \\
SPLADEv3 & Sparse & 0.4536 & 0.4725 & 0.3477 & 0.3419 & \textbf{0.6661} & \textbf{0.6851} & \textbf{0.3757} & \underline{0.3687} \\
\bottomrule
\end{tabular}
\caption{Answer evidence retrieval results on paragraph (Para.) and sentence (Sent.) level and with decontextualizing the passages by prepending the title (+Title). Top-scoring models are in bold, and runner-ups are underlined.}
\label{tbl:evidnce-retrieval-results}
\end{table*}