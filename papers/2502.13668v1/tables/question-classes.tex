\begin{table*}[ht]
\small
\centering
\begin{tabularx}{\textwidth}{@{}p{2.5cm}p{1cm}X@{}}
\toprule
Class & Size & Representative Questions \\ \midrule
Method Clarification & 31\% & How was the fine tuning done for the step sizes in the experiments?, Did the baselines in both experiments 1 and 2 only use a single seed? What is the set of signed input gradients in the second paragraph of section 4.2? \\ \midrule
Data Clarification & 13\% & Do the experts who annotated the dataset have expertise in linguistics or in the domain of the dataset? What is the time resolution of the forcing data used in the study, specifically, is it daily? Do the vocabulary items of the templates used in the paper have adequate representation in the training data? \\ \midrule
Justification/Rationale & 12\% & What motivated the authors to theoretically analyze the dense case and then empirically evaluate the sparse case? Are ten locations sufficient to represent the variety of surfaces in urban environments? Why is the chosen metric appropriate for evaluating the results? \\ \midrule
Comparison & 11.5\% & How does the proposed method compare to other types of vision transformers, such as Swin Transformer or Multiscale Vision Transformers? What is the difference between the MOMA dataset and the MOMA-LRG dataset? How does the performance of the filter-kd model compare to models trained using label smoothing and knowledge distillation with the optimum temperature? \\ \midrule
Analysis & 9\% & What factors influence the degree of separability when adapting a model to a task? Is it clear what the source of the improvements of Histruct+ (Roberta-base) over Bertsumext are? What factors were responsible for the success of the path-based model? \\ \midrule
Implications & 8\% & What are the potential applications of the data presented in this paper? Can the proposed data augmentation be applied to other tasks besides ILA? Do you think that the same framework on variance of ensembles would work equally well in the semantic feature space as in the space of logits? \\ \midrule
Evaluation/Evidence & 8\% & What is the evidence that the generative model is successful in synthesizing new molecules? Do you evaluate playing strength of agents by restricting them by MCTS iteration counts or by time limits? Did the authors run multiple trials to evaluate the performance of the graph-based neural network? \\ \midrule
Definition & 7.5\% & What is the definition of difficulty used in the paper to analyze the learning path of the network's predicted distribution? What is the variational approximation of c given by the query and support sets? What is the definition of $f_{i+1}$? \\ 
\bottomrule
\end{tabularx}
\caption{Distribution of question classes based on 100 questions randomly sampled from PeerQA. \textit{Representative Questions} shows manually picked questions that best correspond to the definition of the class.}
\label{tbl:question-classes}
\end{table*}