\begin{table*}[!h]
\begin{adjustbox}{angle=270, width=\textwidth} 
\tiny
\begin{tabularx}{.88\textheight}{@{}p{1.5cm}p{3.5cm}Xp{3.5cm}p{3.5cm}@{}}
\toprule
Error Class & Question & Evidence & Reference Answer & Generated Answer\\ \midrule
Evaluation Error & What does "but train the detector head with $r(\cdot)$ online in a single stage" mean? & To obtain the features for a region b, we apply the VLM pooling layer P(•) on the cropped backbone output features F(I) (see Sec. 3.2 for notations). Because the pooling layer requires fixed-size inputs, e.g. 7x7 for R50 (Radford et al., 2021), we crop and resize the region features with ROI-Align R(•) (He et al., 2017) (see Fig. 2b). Unlike existing works (Gu et al., 2022;Du et al., 2022), we do not crop and resize the RGB image regions and cache their embeddings in a separate offline process, but train the detector head in one stage. This is simpler and more space-efficient. In addition, we do not crop VLM region features with R(•) during training because the backbone features are frozen. & It means that we train the detection coordinates and the class labels for all boxes simlutanously and jointly, similar to Mark-RCNN and related algorithms, as opposed to cropping individual object boxes and feeding their features to a separate model. & "But train the detector head with $r(\cdot)$ online in a single stage" means that the detector head is trained during the same stage as the rest of the training process, rather than in a separate offline process. \\ 
\midrule
Partially Correct & Does the term "aes" refer to the phenomenon that smiling faces are estimated to be older than neutral faces in direct age estimations, or does it also refer to the phenomenon that smiling face group is retrospectively estimated to be younger? & Interestingly, several studies have reported that humans have a counterintuitive bias regarding age. We associate smiling with youth, that is, it is generally believed that when people see a smiling person, they feel that person is younger. Indeed, previous research has provided evidence that individuals with a smile appear younger than those with other facial expressions (Hass et al., 2016;Voelkle et al., 2012). However, contrary to the commonly held association between smiling and youth, Ganel (2015) showed that a smiling face is estimated to be older than a neutral face. This phenomenon, in which smiling faces are evaluated as being older than neutral faces, is called the aging effect of smiling (AES; Ganel \& Goodale, 2021). AES is attributed to wrinkles around the eyes caused by smiling (Ganel, 2015;Ganel \& Goodale, 2021). In contrast, when participants were asked to retrospectively estimate the mean age of several faces (i.e., face group), they estimated that the smiling face group was younger than the neutral face group (Ganel \& Goodale, 2018). These studies indicate that the effect of emotional expressions on age estimation depends on the method of estimation (i.e., directly or retrospectively). & The term AES refers specifically to the phenomenon that a smiling face makes one look older. & The term "aes" refers to both the phenomenon that smiling faces are estimated to be older than neutral faces in direct age estimations and the phenomenon that the smiling face group is retrospectively estimated to be younger. \\ 
\midrule
Reasoning Error & How are the depth and normal maps combined for training the proposal network in phase 1? & There are two possible ways to ensemble geometric cues: (1) Stack the two geometric cues together and train a single object proposal network on these stacked inputs in Phase-I; (2) Train two object proposal networks and extract pseudo boxes separately, then merge them into a single pseudo box pool for Phase-II training. The details of the merging process is described in Appendix A. We conduct ablation studies on these two methods. From Figure 6a, we demonstrate that empirically, ensembling pseudo labels is slightly better than using stacked inputs for Phase-I training. Throughout the paper, we use the pseudo label ensembling for GOOD-Both. & They are combined by merging their pseudo labels. & The depth and normal maps are combined by stacking them together and training a single object proposal network on these stacked inputs in Phase 1. \\
\midrule
Implicit Evidence Only & Does combining RGB, depth, and normals improve the performance of the model for smaller classes? & More comparison of GOOD-Both and GOOD-All.

For GOOD-All, the performance gains in detecting small objects (AR s ) are too small to compensate for the losses in detecting larger objects (AR m and (AR l )), leading to overall inferior performance. & The combination of RGB, depth, and normals does not significantly improve the model's performance for smaller classes. The gains in detecting small objects are too small to offset the losses in detecting larger objects, leading to an overall inferior performance. & The combination of RGB, depth, and normals does not significantly improve the model's performance for smaller classes. The gains in detecting small objects are too small to offset the losses in detecting larger objects, leading to an overall inferior performance.\\ 

\midrule
Insufficient Context & Do the training languages used for the non-baseline models in the cross-lingual experiments have any overlap with German? & In our experiments we make use of the following datasets: The English Nancy Krebs dataset (16h) from the Blizzard challenge 2011 (Wilhelms-Tricarico et al., 2011;King and Karaiskos, 2011); The German dataset of the speaker Karlsson (29h) from the HUI-Audio-Corpus-German (Puchtler et al., 2021); The Greek (4h), Spanish (24h), Finnish (11h), Russian (21h), Hungarian (10h), Dutch (14h) and French (19h) subsets of the CSS10 dataset (Park and Mulc, 2019). In order to investigate the effectiveness of our proposed LAML procedure, we train a Tacotron 2 model and a FastSpeech 2 model on the full Karlsson dataset as a strong baseline. We also train another Tacotron 2 model and another FastSpeech 2 model on speech in 8 languages with one speaker per language (Nancy dataset and CSS10 dataset) and fine-tune those models on a randomly chosen 30 minute subset from the Karlsson dataset. To our surprise, we did not only match, but even outperform the model trained on 29 hours with the model fine-tuned on just 30 minutes in multiple metrics. & The pretraining data does not overlap with German. Only the data used for fine-tuning is in German. & Yes, the training languages used for the non-baseline models in the cross-lingual experiments have overlap with German. The German dataset of the speaker Karlsson is used for training, along with the English Nancy Krebs dataset and subsets of the CSS10 dataset which include Dutch and French. \\
\midrule

Insufficient Evidence & Can the parameters of the BLOSUM matrix be estimated by the model instead of being pre-computed? & In the first ablation study, we investigate the influence of the BLOSUM embeddings by removing them as input to the GRU. Overall, the absence of the BLOSUM embeddings slows down convergence and sometimes make the learning process unstable, but ultimately does not strongly affect accuracy (see Figure 5). 3). The results without the BLOSUM embeddings are shown in pink (MAP) and purple (marginal). & The Blosum matrix is used to serve as a very simple to compute encoding technique to stabilize and accelerate the learning process. With larger datasets it is not necessary to use the Blosum encodings or averaged blosum embedding. & No, the parameters of the BLOSUM matrix cannot be estimated by the model instead of being pre-computed. \\
\midrule

Insufficient Free-Form Answer & What is the architecture of the system being discussed in the paper? & 

\textit{<Omitted for brevity>}
& 
The architecture is depicted in Figures D.3 and D.4 & The architecture is depicted in Figures D.3 and D.4 
\\ 
\bottomrule
\end{tabularx}
\end{adjustbox}
\caption{Examples for each error class.}\label{tbl:error-examples}
\end{table*}