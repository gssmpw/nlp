\section{Introduction} \label{sec:introduction}

Graph storage is the foundation for efficient in-memory graph data processing. As graph data often require frequent updates~\cite{sahu2017ubiquity,sakr2021future}, in-memory dynamic graph storage (DGS) is essential for supporting concurrent graph read and write queries, enabling real-time graph analytics and updates. To address this need, a variety of DGS methods have been proposed~\cite{ediger2012stinger,dhulipala2019low,macko2015llama,kumar2020graphone,pandey2021terrace,de2021teseo,fuchs2022sortledton,zhu2019livegraph}, as shown in Figure \ref{fig:method_relationship}. STINGER~\cite{ediger2012stinger}, GraphOne~\cite{kumar2020graphone}, and Terrace~\cite{pandey2021terrace} do not provide concurrency control, meaning read and write queries can only execute alternately. In contrast, the other approaches support concurrent read and write queries with serializability~\cite{ramakrishnan2002database}, i.e., the results of executing concurrent queries are equivalent to some serial execution order. \sun{LLAMA~\cite{macko2015llama} and Aspen~\cite{dhulipala2019low} primarily focus on batch updates with a single-writer model, while recent methods have shifted toward optimizing individual updates to support a broader range of applications, which has attracted significant research interest~\cite{zhu2019livegraph,de2021teseo,fuchs2022sortledton}. Despite their varied update strategies, these approaches all enable concurrent read and write queries, thus called \emph{transactional approaches} in this paper.}

These approaches differ significantly in their support for read and write operations, space overhead, and concurrency control. First, they employ different graph container designs to support efficient read and write operations. For instance, LLAMA~\cite{macko2015llama} and LiveGraph~\cite{zhu2019livegraph} store a vertex's neighbor set $N(u)$ in a dynamic array, enabling fast scan operations with continuous storage and simple append inserts, but at the cost of expensive search operations. Recent approaches like Aspen~\cite{dhulipala2019low}, Teseo~\cite{de2021teseo}, and Sortledton~\cite{fuchs2022sortledton} use a segmented strategy, dividing $N(u)$ into small blocks (e.g., $|B| = 256$), storing each block as a sorted array, and linking them with a block index (e.g., a skip list). This design balances insert, scan, and search efficiency. Moreover, these approaches propose additional optimizations, such as adaptive indexing to use different data structures for varying neighbor set sizes to further accelerate graph operations.

\begin{figure}[t]\small
    \setlength{\abovecaptionskip}{3pt}
    \setlength{\belowcaptionskip}{0pt}
    \includegraphics[scale=0.75]{img/methods_relationship.pdf}
    \centering
    \caption{Comparison of DGS methods from previous experiments. An edge from $x$ to $y$ indicates that $x$’s experiments include $y$. Shaded methods are transactional approaches.}
    \label{fig:method_relationship}
\end{figure}

Second, although existing methods all use multi-version concurrency control (MVCC) to maximize parallelism among queries~\cite{wu2017empirical}, they differ in version granularity. \emph{Coarse-grained} methods like LLAMA and Aspen use the typical single-writer-multiple-reader scheme with copy-on-write (CoW)~\cite{lmdb}. For each update, they create a new graph snapshot, while read queries work on the snapshot at their start. Recent works such as LiveGraph, Teseo, and Sortledton use a \emph{fine-grained} strategy, maintaining version information for each neighbor and synchronizing read and write operations with concurrency control protocols like 2PL~\cite{ramakrishnan2002database}. This allows multiple writers to update different elements simultaneously. 

However, there has been no systematic study exploring the trade-offs among these dimensions. Particularly, we observe several issues in current DGS research. First, there is a lack of a common abstraction to model the problem and capture the design space. Second, although Sortledton~\cite{fuchs2022sortledton} covers most existing methods in the experiments, as shown in Figure \ref{fig:method_relationship}, existing methods compare different approaches as black boxes, while numerous factors can affect performance, making the effectiveness of individual techniques unclear. Additionally, existing experiments focus on evaluating the efficiency of proposed graph containers but lack assessments of concurrency performance. Third, the performance gap between DGS and CSR regarding read efficiency and space consumption is unclear, obscuring the overhead of using DGS for read queries.

\vspace{2pt}
\noindent\textbf{Our Work.} We propose to revisit the design of in-memory dynamic graph storage to evaluate the effectiveness of individual techniques and identify key performance factors. We first propose a common abstraction for DGS to capture the nature of graph queries and data, highlighting key performance factors and facilitating a systematic study of existing methods. Within this common abstraction, we compare key techniques in existing DGS methods, including graph containers, concurrency control, and specific optimizations. Additionally, we implement a generic test framework based on our abstraction and re-implement these techniques within the framework for fair empirical comparisons.


\sun{We evaluate five DGS methods and include two static graph storage methods, CSR and AdjLst, for comparison. We conduct detailed experiments with eight real-world graphs to assess graph container efficiency, the effectiveness of concurrency control techniques, and memory consumption across methods. Our results show that, while fine-grained methods improve write throughput, they also incur significant space and efficiency overhead. Fine-grained strategies face challenges with version maintenance and lock contention, especially when managing high-degree vertices. Although coarse-grained methods alleviate these issues, Aspen still suffers from inefficiencies in graph container design. Consequently, CSR consistently outperforms DGS methods, achieving 2.4–11.0x higher query performance and consuming 3.3–10.8x less memory. We summarize the relative performance of competing methods, key insights, and research opportunities in Section \ref{sec:conclusion}.  This work is open-sourced on GitHub at https://github.com/SJTU-Liquid/DynamicGraphStorage.git. In summary, this paper makes the following contributions.}

\begin{itemize} [leftmargin=*]
    \item \sun{We propose a simple yet effective abstraction for DGS, enabling a systematic study of existing methods.}
    \item \sun{Using this abstraction, we compare key techniques in DGS, e.g., graph containers and concurrency control.}
    \item \sun{We develop a generic testing framework based on this abstraction to systematically evaluate existing methods.}
    \item \sun{Our findings reveal the strengths of current approaches and highlight critical performance factors, providing valuable insights to guide the design of future DGS systems.}
\end{itemize}
