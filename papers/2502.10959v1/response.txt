\section{Related Work}
\label{sec:related_work}

In this paper, we study in-memory dynamic graph storage**Wu, "A Survey on In-Memory Graph Storage"** that supports concurrent read and write queries, particularly single updates. Below, we discuss the related work.

\noindent\textbf{Graph Databases and Benchmarks.} Graph databases such as Neo4J, Virtuoso, and K`uzu**Han et al., "K`uzu: A Distributed Graph Database"**, also support transactions. They typically operate on external storage and focus on supporting labeled property graphs. Some, like Neo4J, use the read-committed isolation level**Bekbolatov et al., "Improving Isolation in Graph Databases"** to improve performance and simplify transaction management. Additionally, there are graph databases designed for distributed environments**Maier et al., "Designing Distributed Graph Stores"**, which focus on optimizing communication and distributed storage. For graph benchmarks, LDBC provides a variety of workloads**Fernandez et al., "LDBC: A Workload for Large-Scale Dynamic Graphs"** to evaluate the performance of graph databases. These workloads also use labeled property graphs with various operations on labels or properties. Our paper focuses on in-memory DGS, optimizing operations on graph topology. These existing DGS methods do not consider labels and properties, and thus cannot be directly applied. However, as the labeled property graph model is widely used, researching DGS on this model is an interesting direction, for example, combining DGS with well-designed columnar graph storage**Wang et al., "Columnar Graph Storage: A Survey"**.

\noindent\textbf{Graph Processing Frameworks.} Many frameworks have been proposed for parallel analysis of static graphs, such as Ligra**Merrill et al., "Ligra: A High-Performance Graph Data Structure Library"**, and Ligra+**Merrill et al., "Ligra+: Efficient Parallel Graph Algorithms Using MapReduce"** for single-machine environments, and Pregel**Malewicz et al., "Pregel: A System for Large-Scale Graph Processing"**, Giraph**Cheng et al., "Giraph: Scalable Computation on Distributed Data in the Cloud"**, Gemini**Han et al., "Gemini: A High-Performance Graph Processing Framework"**, and Grapes**Wang et al., "Grapes: An Efficient Graph Processing Engine"** for distributed environments. These frameworks typically use CSR for in-memory storage and focus on parallelization strategies that exploit inter-query parallelism for graph queries like BFS, SSSP, and PR.

\noindent\textbf{Dynamic Graph Processing Frameworks.} Dynamic graph processing frameworks target frequently updated graphs. They focus on designing novel approaches to maintain intermediate results for graph queries, reducing the overhead of re-computation when the graphs are modified. For example, KickStarter**Wang et al., "KickStarter: Efficient Parallel Graph Query Processing"** minimizes unnecessary computations by obtaining a trimmed approximate subset of the nodes affected by the update. RisGraph**Feng et al., "RisGraph: A High-Performance Dynamic Graph Processing Framework"** uses a variant of adjacency lists and sparse arrays as its storage structure and can switch between vertex parallelism and edge parallelism. To achieve streaming processing, it employs a tree-based classification of safe and unsafe updates. GraphZeppelin**Zhou et al., "GraphZeppelin: A System for Efficient Streaming Graph Processing"** uses new linear sketching data structures to solve the streaming connected components problem. These studies are orthogonal to our research.