
\section{Preliminaries} \label{sec:preliminaries}

We focus on the directed graph $G = (V, E)$, where $V$ is the set of vertices and $E \subseteq V \times V$ is the set of edges. For a vertex $u \in V$, $N(u)$ denotes its neighbors and $d(u)$ is its degree, i.e., $|N(u)|$. An edge $e(u, v)$ is directed from $u$ to $v$. An undirected graph can be represented by storing edges in both directions, $e(u, v)$ and $e(v, u)$. Each vertex has a unique \emph{vertex ID}. Previous studies~\cite{aberger2017emptyheaded,han2018speeding,yang2024hero,wang2017experimental,gonzalez2012powergraph} have shown that using vertex IDs as integers in $[0, |V|)$ benefits both computation and storage due to compact ID representation. Existing works~\cite{zhu2019livegraph,macko2015llama,de2021teseo,fuchs2022sortledton,dhulipala2019low} either require input vertex IDs to belong to $[0, |V|)$ or use dictionary encoding techniques (e.g., concurrent hash maps) to map external vertex IDs to this range. Thus, in our case, each vertex ID $u \in V$ is an integer in $[0, |V|)$.

\vspace{2pt}
\noindent\textbf{Graph Storage.} A \emph{static graph} can be stored as an \emph{adjacency list} (AdjLst), which uses an array of arrays (or lists), where each array at index $u$ contains all of $u$‘s neighbors, sorted by vertex IDs. A common variant, the \emph{compressed sparse row} (CSR) format, stores all vertices’ neighbor sets in a single \emph{neighbor array} and uses an \emph{offset array} to record the start position of each vertex’s neighbor set in the neighbor array. Given that real-world graphs are often sparse, CSR is the most widely used storage method for static graphs due to its compact memory layout and data access efficiency. A \emph{dynamic graph} $G = (G_0, \Delta \mathcal{G})$ records the evolution of the graph over time. $G_0$ is the initial graph and $\Delta \mathcal{G} = (\Delta G_1, ..., \Delta G_i, ...)$ is a sequence of updates. $\Delta G_i = {(\oplus, v/e)}$ contains a set of updates, where $(\oplus = +/-)$ denotes an insertion/deletion of a vertex $v$ or an edge $e(u, v)$. Deleting a vertex also removes all its adjacent edges. $\Delta V$ denotes the vertices appeared in $\Delta G$. The graph $G_i$ is obtained by applying the first $i$ updates to $G_0$, i.e., $G_i = G_0 \oplus \Delta G_1 \oplus ... \oplus \Delta G_i$. If $\Delta G$ contains a single operation, it is called a \emph{single update}; otherwise, it is a \emph{batch update}. Static graph formats are inefficient for dynamic graphs because: 1) they cannot coordinate concurrent read and write operations, compromising the correctness of graph queries; and 2) they do not support fast updates. 

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\small
\begin{table}[t]
\centering
\caption{The time and space complexity of involved data structures in our study.}
\label{tab:complexity_data_structure}
% \resizebox{\columnwidth}{!}{%
\begin{tabular}{|c|cccc|c|}
\hline
                                     & \multicolumn{4}{c|}{\textbf{Time}}                                                                                                 & \multirow{2}{*}{\textbf{Space}} \\ \cline{1-5}
                                     & \multicolumn{1}{c|}{\textsc{Insert}} & \multicolumn{1}{c|}{\textsc{Search}} & \multicolumn{1}{c|}{\textsc{Scan}} & \textsc{Resize} &                                 \\ \hline
\textbf{Dynamic Array(DA)}           & \multicolumn{1}{c|}{$O(1)$}          & \multicolumn{1}{c|}{$O(n)$}          & \multicolumn{1}{c|}{$O(n)$}        & $\Theta(n)$     & $O(n)$                          \\ \hline
\textbf{Sorted Dynamic Array(SDA)}   & \multicolumn{1}{c|}{$O(n)$}          & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(n)$}        & $\Theta(n)$     & $O(n)$                          \\ \hline
\textbf{Packed Memory Array(PMA)}    & \multicolumn{1}{c|}{$O(\log^2 n)$}   & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(n)$}        & $\Theta(n)$     & $O(n)$                          \\ \hline
\textbf{Skip List(SL)}               & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(n)$}        & -               & $O(n\log n)$                    \\ \hline
\textbf{Hash Table(HT)}              & \multicolumn{1}{c|}{$O(1)$}          & \multicolumn{1}{c|}{$O(1)$}          & \multicolumn{1}{c|}{$O(n)$}        & -               & $O(n)$                          \\ \hline
\textbf{AVL Tree(AVL)}               & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(n)$}        & -               & $O(n)$                          \\ \hline
\textbf{Parallel Augmented Map(PAM)} & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(\log n)$}     & \multicolumn{1}{c|}{$O(n)$}        & -               & $O(n)$                          \\ \hline
\end{tabular}%
% }
\end{table}

\vspace{2pt}
\noindent\textbf{Data Structures for Vertex Sets.} In principle, both $V(G)$ and $N(u)$ (i.e., a subset of $V(G)$) are sets of integers. Various data structures can be used to maintain them. Table \ref{tab:complexity_data_structure} presents the time and space complexity of these data structures involved in this paper.

DA is a resizable array with append to perform insert. In contrast, SDA is a resizable sorted array that uses binary search to locate elements and insertion to keep the array sorted. PMA~\cite{bender2007adaptive,de2019packed} maintains elements in a partially filled array organized into blocks, facilitating efficient insertions while keeping elements sorted. To maintain balance, PMAs periodically rebalance elements within blocks to ensure even distribution and optimal space usage. Both SDA and PMA extend their capacity by allocating a larger block of memory, typically doubling the current size and copying the elements to the new block. The resize cost for $n$ elements is $\Theta (n)$. PAM~\cite{sun2018pam} is a data structure that supports parallel operations on ordered maps. It uses balanced binary trees and join-based algorithms to maintain order and balance efficiently. As SL~\cite{pugh1990skip}, HT, and AVL are widely used, we omit the details for brevity.

\vspace{2pt}
\noindent\textbf{Graph Queries.} The graph community~\cite{angles2014linked,besta2023demystifying} categorizes query workloads into three classes: \emph{interactive workloads} (IC)~\cite{erling2015ldbc}, \emph{analytics workloads} (AS)~\cite{iosup2016ldbc}, and \emph{business intelligence workloads} (BI)~\cite{szarnyas2022ldbc}. IC includes queries that involve simple vertex/edge insertion/deletion operations or start from specified vertices and access a small portion of the graph. AS consists of graph traversal algorithms like PageRank, which typically visit the entire graph. BI bridges the gap between IC and AS by introducing pattern queries. IC is referred to as OLTP, while AS and BI are considered OLAP~\cite{li2022bytegraph,besta2023graph}.

% Graph queries, despite their diversity, fundamentally consist of a sequence of read and write operations on vertices and edges within graph storage.

\textbf{In the dynamic graph model, these queries are categorized into \emph{read queries} $Q$, which are strictly read-only, and \emph{write queries} $\Delta G$, which include update operations ~\cite{fuchs2022sortledton,li2022bytegraph}.} Typically, graph queries are read-intensive, and both read and write queries exhibit distinct characteristics:

\begin{enumerate}[leftmargin=*]
\item Read queries can be complex and long-running, with an unpredictable \emph{read set} (i.e., the vertices and edges accessed).
\item Write queries are lightweight, involving a small, known \emph{write set} of vertex/edge insertion or deletion operations.
\item As graphs are widely used for connection analysis, scan operations are a common and important graph data access pattern~\cite{zhu2019livegraph,dhulipala2019low,de2021teseo,fuchs2022sortledton,ediger2012stinger,kumar2020graphone,macko2015llama,pandey2021terrace}.
\end{enumerate}

\noindent\textbf{MVCC.} Each query can be abstracted as a transaction with read and write operations on a database. MVCC is currently the most popular transaction management scheme~\cite{wu2017empirical}. The basic idea is to maintain multiple physical versions of each logical object to allow operations on the same object in parallel to maximize parallelism of concurrent queries without sacrificing serializability.

\emph{Strict two-phase locking} (S2PL) \cite{bernstein1987concurrency} is a concurrency control protocol that operates in two phases: 1) the growing phase, where locks can be acquired but not released; and 2) the shrinking phase, where no new locks can be acquired after the first lock is released. It holds exclusive locks until the transaction commits or aborts. To avoid deadlocks, an effective approach called the no-wait policy \cite{bernstein1981concurrency} is to immediately abort a transaction if it cannot acquire a lock \cite{yu2014staring}. S2PL is a classical approach to achieving serializability.

Unlike pessimistic protocols (e.g., S2PL) that assume queries will conflict and take preventive actions, \emph{optimistic concurrency control} (OCC)~\cite{larson2011high,neumann2015fast} assumes conflicts are rare and handles them at transaction commit. OCC typically has three phases: 1) in the read phase, the transaction performs read and write operations on local copies of the data; 2) in the validation phase, upon committing, OCC checks if the data read by the transaction has been modified by other transactions; and 3) in the write phase, if validation passes, the transaction's updates are applied to the database; otherwise, the transaction is aborted and its changes are discarded. To support validation and undo operations, OCC records accessed elements in a log. OCC does not require locking elements during the read and write phases but does track accessed elements to ensure consistency. For details of MVCC, please refer to this study~\cite{wu2017empirical}.

\vspace{2pt}
\noindent\textbf{Lock and Latch.} Locks are synchronization mechanisms used to regulate access to shared data objects during concurrent transaction processing. A DBMS employs a lock manager to handle lock requests and maintain the locks acquired by each transaction. There are two types of locks: shared locks, which allow reads from multiple transactions, and exclusive locks, which permit writes exclusively. Latches protect concurrent access to in-memory data structures by threads. A read latch allows multiple threads to access shared items simultaneously, whereas a write latch permits only one thread to access shared items at a time. Existing DGS methods~\cite{zhu2019livegraph,macko2015llama,de2021teseo,fuchs2022sortledton,dhulipala2019low} do not use a lock manager but instead rely on the locking mechanisms (e.g., mutex) provided by the OS to synchronize queries. Throughout the paper, we use the term "lock" without further distinction.





