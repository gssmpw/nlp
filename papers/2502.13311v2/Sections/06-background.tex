\section{Related Work}

\paragraph{Interactive Tutoring.}
As an advanced form of intelligent tutoring systems (ITSs), interactive ITSs~\citep{graesser2001intelligent,rus2013recent} can provide personalized feedback and adaptive learning experiences. 
They have been extensively explored across various educational domains, such as language learning~\citep{swartz2012intelligent,stasaski-etal-2020-cima,caines-etal-2020-teacher, kwon-etal-2024-biped}, math reasoning~\citep{demszky-hill-2023-ncte,macina-etal-2023-mathdial,wang-etal-2024-bridging}, and scientific concept education~\citep{yuan-etal-2024-boosting,yang2024leveraging}. 
These studies mainly focus on enhancing students' understanding of specific pieces of knowledge, using pedagogical strategies such as designing exercises~\citep{deng2023towards,wang-etal-2022-towards,lu2023readingquizmaker} or selecting teaching examples~\citep{ross-andreas-2024-toward}.
Furthermore, the effectiveness of these approaches is often measured using closed-form assessments, such as question-answering~\cite{yuan-etal-2024-boosting} or multiple-choice tests~\cite{macina-etal-2023-mathdial}. 
Rather than specific pieces of knowledge, we investigate the domain of coding tutoring, which requires students to perform open-ended code generation to assess tutoring further.



\paragraph{LLM-based Tutoring Agents.}
The rapid growth of large language models (LLMs) has expanded ITSs into tutoring agents~\citep{yu2024mooc}. 
For instance, early efforts such as EduChat~\citep{dan2023educhat} introduced an educational chatbot for online tutoring, while \textsc{ChatTutor}~\citep{chen2024empowering} equipped tutor agents with course planning and adaptive quizzes to facilitate long-term interactions. 
More recently, AlgoBo~\citep{jin2024teach}, an LLM-based teachable agent, was developed to enhance students' coding skills. 
Existing LLM agents primarily play a \textit{reactive} role, focusing on answering questions or clarifying concepts. 
In comparison, our coding tutoring is both goal-driven and personalized, requiring agents to \textit{proactively} guide students toward completing targeted coding tasks while adapting to diverse levels of knowledge prior. 
Our work presents a novel method that empowers tutor agents to address these challenges.


\paragraph{Inference-Time Adaptation of LLMs}
To enhance the controllability of language generation in complex tasks, prior work has investigated guided decoding~\citep{dathathri2020plug,chaffin-etal-2022-ppl} during inference. 
More recently, a notable line of research~\citep{lightman2023let,li-etal-2023-making,wang2024math,pan2024training} has employed verifier models complemented with search algorithms to guide LLMs for agentic reasoning. 
These methods typically focus on static tasks, often overlooking interactive scenarios.
To address multi-turn interactions~\citep{wang2024mint}, we introduce a turn-by-turn verifier that dynamically evaluates tutoring progress over time.