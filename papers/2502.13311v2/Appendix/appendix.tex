\section{Experimental Setup}
\label{appendix:exp_setup}


\begin{figure*}[ht]
\centering
\includegraphics[width=0.74\textwidth]{Figs/Fig.example.pdf}
\caption{An example in EvoCodeBench.}
\label{fig:data_example}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=0.84\textwidth]{Figs/Fig.ref_step.pdf}
\caption{The reference solution steps annotated for the example in Figure~\ref{fig:data_example}.}
\label{fig:ref_step}
\end{figure*}

\subsection{Dataset \& Preprocessing}
\label{appendix:dataset}
EvoCodeBench~\cite{li2024evocodebench} is an evolving benchmark for repository-level code generation, which is collected from open-source Python repositories in the real world and will be dynamically updated to avoid data leakage. Figure~\ref{fig:data_example} shows a detailed example, which consists of the following components: (1) \textit{Target Coding Task}: the function signature of the target code and a requirement description detailing its functionality; (2) \textit{Repository}: the current repository containing all code files; (3) \textit{Reference Code}: The developer-written implementation of the target code in the repository; (4) \textit{Reference Dependency}: The dependencies invoked in the reference code, such as intra-class, intra-file, and cross-file dependencies; (5) \textit{Test Cases}: The cases used to check the functional correctness of the generated code.

We employed the publicly available version, EvoCodeBench-2403\footnote{\url{https://huggingface.co/datasets/LJ0815/EvoCodeBench/tree/main/EvoCodeBench-2403}.}, as the testbed for our experiments. This dataset comprises coding tasks collected from repositories created between \texttt{2023-10} and \texttt{2024-2}. For each target coding task, we annotated its reference solution steps by directly prompting GPT-4o \cite{openai2024gpt4o} using the provided reference code (see Figure~\ref{fig:ref_step}). Coding tasks requiring no dependencies were excluded during preprocessing. The statistics of the resulting dataset are summarized in Table~\ref{tab:data_stats}. We split the dataset equally into 5 folds, using 5-fold cross-validation for experiments.



\subsection{Additional Implementation Details}
\label{appendix:implementation}

The backbone LLMs we used are detailed as follows: (1) For the Llama-3.1-Instruct \cite{dubey2024llama}, we adopt its 8B\footnote{\url{https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct}} and 70B\footnote{\url{https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct}} variants. For the Qwen-2-Instruct \cite{yang2024qwen2}, we adopt its 7B\footnote{\url{https://huggingface.co/Qwen/Qwen2-7B-Instruct}} and 72B\footnote{\url{https://huggingface.co/Qwen/Qwen2-72B-Instruct}} variants. (2) We employ GPT-3.5-Turbo (\texttt{gpt-3.5-turbo-1106} version), GPT-4o (\texttt{gpt-4o-2024-05-13} version), and o1-mini (\texttt{2024-09-01-preview} version), using APIs provided by Microsoft Azure.


\begin{table}[t!]
\centering
\scalebox{0.87}{
\begingroup
\renewcommand{\arraystretch}{0.85}
\setlength{\tabcolsep}{2pt}
\hspace{-10pt}
\begin{tabular}{l | c}
\toprule
\# Repository  & 25  \\
\# Target Coding Tasks & 100  \\
\# Avg. Solution Steps &  9.07   \\
\# Avg. Dependency   & 3.46  \\
Dependency Type  &  intra-class, intra-file, cross-file  \\
\bottomrule
\end{tabular}
\endgroup}
\caption{Statistics of the preprocessed EvoCodeBench.}
\label{tab:data_stats}
\end{table}


Our implementation is based on the vLLM\footnote{\url{https://docs.vllm.ai/en/latest/}} and ChatArena\footnote{\url{https://github.com/Farama-Foundation/chatarena}} libraries. Both the student simulator and dialogue manager employ the quantized version\footnote{\url{https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ}} of Mixtral-8x7B-Instruct \cite{jiang2024mixtral} for efficiency.
During tutor-student interactions, the maximum number of tokens to generate is limited to 300 for both the tutor and student. For the coding tests, the student simulator adopts sampling decoding, with a fixed top-$p$ of 0.95 and temperature of 0.4. The cognitive load parameter $M$ is set to 60 during the post-test.

We utilize synthesized dialogues generated by various backbone models with vanilla instructions, as the data source for training the verifier. Tutoring dialogues that successfully guide the student to complete target coding tasks during the post-test are labeled as positive data. To ensure a balanced dataset for training, we randomly sample dialogues that fail to achieve the tutoring goals as negative data. We implement the turn-based verifier using Mistral-7B~\cite{jiang2023mistral} with an additional linear layer, which is fine-tuned based on LoRA~\cite{hu2022lora}. The LoRA's target modules are $W_q$ and $W_v$, the rank $r$ is set to 8, and the scaling parameter $\alpha$ is set to 16. The optimizer we used is AdamW~\cite{loshchilov2018decoupled}, with an initial learning rate of 1$e$-5 and a warmup ratio of 0.03. The verifier is trained for 3 epochs. During inference, we adopt sampling decoding to generate tutor utterances, with a top-$p$ of 0.95 and a temperature of 0.4 across all backbone models. For Llama-3.1-70B-Instruct, the number of candidate utterances is set to 20, while for GPT-4o, it is fixed at 10. All experiments are conducted on one server equipped with 8 NVIDIA A6000 GPUs. Table~\ref{tab:param} summarizes the parameter settings in training and inference.

\begin{table}[t!]
\centering
\scalebox{0.9}{
\begingroup
\renewcommand{\arraystretch}{0.85}
\setlength{\tabcolsep}{5pt}
\hspace{-10pt}
\begin{tabular}{l | c}
\toprule
LoRA's rank $r$ & 8  \\
LoRA's scaling $\alpha$ & 16  \\
Learning rate &  1$e$-5   \\
Warmup ratio  &  0.03  \\
Epochs  &  3 \\
Max. tokens per student turn & 300 \\
Max. tokens per tutor turn & 300 \\
Cognitive load $M$  & 60  \\
Number of candidates $N$  & \{1, 5, 10, 15, 20\}  \\
Top-$p$  & 0.95   \\
Temperature   & 0.4  \\
\bottomrule
\end{tabular}
\endgroup}
\caption{Parameter settings in training and inference.}
\label{tab:param}
\end{table}


\section{Human Evaluation}
\label{appendix:human_eval}
We randomly selected 10 target coding tasks from the testbed and collected the synthesized tutoring dialogues across three levels of students for the compared tutor agents, including Vanilla Instruct, Self-Refine, TreeInstruct, and our \model. All tutor agents are built using GPT-4o as the backbone model. We asked three graduate students with well-educated programming backgrounds for human evaluation. 

For each target coding task, we presented human evaluators with a pair of tutoring dialogues produced by two agents interacting with the same student, resulting in a total of 90 cases.
Evaluators were asked to determine which one is better (or to select a \textit{tie}) based on the following dimensions: 
\begin{enumerate}[label=(\arabic*)]
\item \textbf{Proactivity}: how well does the tutor move the student's progress towards solving the task?
\begin{itemize}[leftmargin=4pt]
    \item Weak: Only make passive responses or generic check-ins (e.g., ``Any questions?'' or ``Does this make sense?'').
    \item Moderate: Ask directional questions with clear next steps (e.g., ``Now we need to handle input validation. Could you implement the error checks?'').
    \item Excellent: Structured progression with connected concepts (e.g., ``Now that we've validated inputs, let's think about how this connects to our error handling strategy. Could you identify where validation and error handling might overlap?'').
\end{itemize}
\item \textbf{Adaptability}: how well does the tutor adapt its tutoring strategy based on the student's responses?
\begin{itemize}[leftmargin=4pt]
    \item Weak: Follows fixed script regardless of student's responses (e.g., ``Let's move on to the next step...'' while ignoring the student's questions or confusion).
    \item Moderate: Responsive to the student's immediate questions but maintains fixed tutoring plan (e.g., ``Yes, good question about error handling. Now as I was saying about the input validation...'').
    \item Excellent: Adjusts explanations based on the student's demonstrated understanding (e.g., ``I see you've handled the input validation. Let's focus on optimizing your approach...'').
\end{itemize}
\item \textbf{Coherence}: how well does the tutor build and maintain connections throughout the tutoring session?
\begin{itemize}[leftmargin=4pt]
    \item Weak: Jumps between topics without logical transitions (e.g., ``Now let's talk about ...'' without linking to the previous discussion).
    \item Moderate: Maintains a logical flow, though the connections between topics are weak.
    \item Excellent: Explicitly connects each utterance to the preceding context and aligns it with the future tutoring goal.
\end{itemize}
\end{enumerate}

Our human evaluations were carried out using a Web application, as illustrated in Figure~\ref{fig:human_eval}, which displays the interface. We adopted Fleissâ€™s kappa~\cite{fleiss1971measuring} to measure the agreement among the human evaluators.


\begin{figure*}[th]
\centering
\includegraphics[width=0.86\textwidth]{Figs/Fig.human_eval.pdf}
\caption{Web interface for human evaluation.}
\label{fig:human_eval}
\end{figure*}



\section{Case Study}
\label{appendix:case}

Table~\ref{tab:case_win} shows an example from the human evaluation, demonstrating a case where our \model outperforms the baseline.  Table~\ref{tab:case_tie} shows a case where our method performs comparably to the baseline.


\begin{table*}[th]
\centering
\resizebox{0.99\textwidth}{!}{
\begin{tabular}{lp{16.5cm}}
\toprule
\multicolumn{2}{l}{\textbf{Target Coding Task}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize def lossfun\_outer(t: torch.Tensor, w: torch.Tensor, t\_env: torch.Tensor, } \\
\multicolumn{2}{l}{\ttfamily \footnotesize ~~~~ ~~~~ ~~~~ ~~~ w\_env: torch.Tensor, eps=torch.finfo(torch.float32).eps):} \\
\multicolumn{2}{l}{\ttfamily \footnotesize """ } \\
\multicolumn{2}{l}{\ttfamily \footnotesize This function calculates a scaled half-quadratic loss based on the input tensors ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param t: torch.Tensor. The target positions tensor, used along with weights to calculate the loss.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param w: torch.Tensor. The target weights tensor, representing the weights of the target positions.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param t\_env: torch.Tensor. The environment positions tensor, used to calculate the upper envelope weights.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param w\_env: torch.Tensor. The environment weights tensor, representing the weights of the environment positions.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param eps: torch.Tensor, optional. A small epsilon value to prevent division by zero.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:return: torch.Tensor. The calculated loss based on the difference between target weights and the upper envelope ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize """ } \\
\midrule
\multicolumn{2}{l}{\textbf{Reference Dependencies}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize \# Intra-file Dependency:
easyvolcap.utils.loss\_utils.inner\_outer} \\
\multicolumn{2}{l}{\ttfamily \footnotesize \# Cross-file Dependency: easyvolcap.utils.prop\_utils.matchup\_channels } \\
\midrule
\multicolumn{2}{l}{\textbf{Reference Solution Steps}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize 1. Define a function "lossfun\_outer" that calculates a loss based on the difference ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize 8. Normalize the squared differences by adding a small epsilon value "eps" to "w" to avoid division by zero when ... } \\
\midrule

\multicolumn{2}{l}{\textbf{GPT-4o with Vanilla Instruct} } \\
Tutor: & Hello! How are you doing today? Let's start by understanding your familiarity with the task. Have you worked with loss functions or similar concepts in PyTorch before?  \\ 

Student:  &  Hello! I'm doing well, thank you. I have some experience with PyTorch and have worked with basic loss functions. However, I'm not familiar with this specific loss function and how it relates to the input tensors. Could you please explain this concept and guide me on how to implement this function? \\

Tutor: &  Great! Let's break it down step-by-step. First, the scaled half-quadratic loss is a type of loss function that ... Can you write the function signature and docstring based on the provided information? \\

Student:  &  Sure! Here's the function signature and docstring ... This function calculates a scaled half-quadratic loss based on the input tensors representing target and environment weights and positions ...  \\

Tutor: & Great start! Next, we need to align the channels of \texttt{t} with \texttt{w} and \texttt{t\_env} with \texttt{w\_env}. This ensures they have the same number of channels for further calculations. We use the \texttt{matchup\_channels} function for this.    \\
... &  \\
Tutor:  &  Now, we need to ensure that the actual weight \texttt{w} should not exceed the computed \texttt{w\_outer}. We will penalize \texttt{w} when it exceeds \texttt{w\_outer} by calculating the positive part of the difference between \texttt{w} and \texttt{w\_outer}. Can you compute this difference and clip it to zero out negative values? \\

Student:  &  Sure! I can compute the positive part of the difference between \texttt{w} and \texttt{w\_outer} and clip it to zero like this: ... \\

\midrule

\multicolumn{2}{l}{\textbf{GPT-4o with \model (Ours) }} \\

Tutor: & Hello! Let's get started with completing the \texttt{lossfun\_outer} function. To begin, can you tell me how comfortable you are with using PyTorch and understanding tensor operations?  \\

Student:  &  Hello! I'm fairly new to PyTorch, but I have some experience with tensor operations from previous lessons. I'm here to learn and complete the \texttt{lossfun\_outer} function. How would you like me to start?  \\

Tutor: &  Great! Let's start by understanding a key dependency. The \texttt{inner\_outer} function is crucial for our task. It constructs inner and outer measures on \texttt{(t1, y1)} for \texttt{t0}. Do you understand how this function works, or would you like a brief explanation?  \\

Student:  & I believe I understand the concept, but a brief explanation would be helpful to ensure I'm on the right track. I want to make sure I understand the input and output of the \texttt{inner\_outer} function.  \\

Tutor: &  Sure! The \texttt{inner\_outer} function takes \texttt{t0}, \texttt{t1}, and \texttt{y1} as inputs. It calculates cumulative sums of \texttt{y1} and uses them to derive inner and outer measures based on indices from \texttt{t1} and \texttt{t0}. This helps us understand the weight distribution over the given positions. Ready to move on to the next step?  \\
... &  \\

Tutor:  &  Now, let's square the clipped differences to emphasize larger deviations: \texttt{loss = loss ** 2}. Then, normalize the squared differences by adding a small epsilon value \texttt{eps} to \texttt{w} to avoid division by zero: \texttt{loss = loss / (w + eps)}. Ready for the final step?   \\

Student: &  I've squared the clipped differences and normalized the squared differences by adding the small epsilon value \texttt{eps} to \texttt{w} to avoid division by zero. \\

\bottomrule
\end{tabular}}
\caption{An example from the human evaluation, demonstrating a case where our method outperforms the baseline. The tutor agent built with Vanilla Instruct simply repeats the target coding task at the beginning and fails to adapt its tutoring strategy based on the studentâ€™s responses. In contrast, the tutor agent built with our \model workflow demonstrates much better proactivity and adaptability in guiding the student toward solving the task. }
\label{tab:case_win}
\end{table*}





\begin{table*}[th]
\centering
\resizebox{0.99\textwidth}{!}{
\begin{tabular}{lp{16.5cm}}
\toprule
\multicolumn{2}{l}{\textbf{Target Coding Task}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize def prepare\_item(self, item\_metadata: Any, output\_dir: str, is\_last: bool) -> None:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize """ } \\
\multicolumn{2}{l}{\ttfamily \footnotesize The function prepares an item by applying a transformation function to the item's metadata, potentially including ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param item\_metadata: Any, the metadata of the item to be transformed.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param output\_dir: str, the directory where the transformed item's output should be stored.} \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:param is\_last: bool, a flag indicating whether the item is the last one in the sequence to be processed. } \\
\multicolumn{2}{l}{\ttfamily \footnotesize  ~~:return: No return values. } \\
\multicolumn{2}{l}{\ttfamily \footnotesize """ } \\
\multicolumn{2}{l}{\textbf{Reference Dependencies}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize \# Intra-class Dependency:
litdata.processing.functions.LambdaDataTransformRecipe.\_fn} \\
\multicolumn{2}{l}{\ttfamily \footnotesize ~~~~~ ~~~~~  ~~~~~ ~~~~~ ~
litdata.processing.functions.LambdaDataTransformRecipe.\_contains\_device} \\
\midrule
\multicolumn{2}{l}{\textbf{Reference Solution Steps}:} \\
\multicolumn{2}{l}{\ttfamily \footnotesize 1. Check if the instance requires a device (self.\_contains\_device) and if the device is not already set ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize ...} \\
\multicolumn{2}{l}{\ttfamily \footnotesize 9. The function prepare\_item does not return any value; it executes the provided function self.\_fn with ...} \\
\midrule
\multicolumn{2}{l}{\textbf{GPT-4o with TreeInstruct} } \\
Tutor: & Hello! Let's work together to complete the \texttt{prepare\_item} function. First, I'd like to understand your familiarity with Python and its concepts. Have you worked with classes and functions in Python before?  \\ 

Student: &  Hello! Yes, I have some experience with Python classes and functions. I understand the basic syntax for defining them and calling their methods. However, I'm not an expert, so I might need some guidance to complete the \texttt{prepare\_item} function correctly. \\

Tutor:  &  Great! Let's start by checking if the instance requires a device and if it isn't already set. This is our first step: \texttt{\textbackslash n\textbackslash n\textbackslash n if self.\_contains\_device and self.\_device is None:\textbackslash n  self.\_find\_device()\textbackslash n\textbackslash n} Do you understand what this code does?          \\

Student: & Yes, I understand this code. It checks if the \texttt{\_contains\_device} attribute is \texttt{True} and if the \texttt{\_device} attribute is \texttt{None}. If both conditions are met, it calls the \texttt{\_find\_device} method. This seems to be a way to ensure that the \texttt{\_device} attribute is set before proceeding, as long as \texttt{\_contains\_device} is set to \texttt{True}. \\

Tutor: &  Great, let's proceed. The next step is to initialize a dictionary to hold keyword arguments that will be passed to the function \texttt{self.\_fn}. Here's the code: \texttt{kwargs = \{\}\textbackslash n\textbackslash n} Do you understand why we need to initialize \texttt{kwargs} here?  \\

... &  \\
\midrule

\multicolumn{2}{l}{\textbf{GPT-4o with \model (Ours)}} \\

Tutor: &  Hello! How are you today? Let's start by understanding your current knowledge level. Have you worked with Python classes and methods before? Specifically, are you familiar with using \texttt{self} within class methods?  \\

Student:  &  Hello! I'm doing well, thank you. Yes, I have some experience with Python classes and methods. I understand that \texttt{self} is used as the first parameter in a class method to represent the instance of the class. However, I'm not sure how to implement the \texttt{prepare\_item} function in this context. Could you please clarify what the transformation function \texttt{\_fn} is and how it should be called within this method?  \\

Tutor:  &  Great! Let's start by understanding the transformation function \texttt{\_fn}. It's a callable function that processes the item metadata. In the \texttt{prepare\_item} method, we need to call \texttt{\_fn} with the appropriate arguments. First, let's ensure you understand the dependencies. Do you know how to check if an instance attribute exists in Python?  \\

Student:  &   Yes, I know that to check if an instance attribute exists, we can use the \texttt{hasattr()} function in Python. It takes an object and a string with the attribute name as its arguments. However, I'm not sure how this applies to the \texttt{prepare\_item} function and the \texttt{\_fn} transformation function. \\

Tutor:  &   Let's start with the first step. We need to check if the instance requires a device. This is determined by \texttt{self.\_contains\_device}. If it does and the device is not set \texttt{(self.\_device is None)}, we call \texttt{self.\_find\_device()}. Does this make sense to you?  \\

... &  \\

\bottomrule
\end{tabular}}
\caption{An example from the human evaluation demonstrating a case where our method performs comparably to the baseline.}
\label{tab:case_tie}
\end{table*}



\section{Prompting Templates}
\label{appendix:prompt}

\paragraph{Student Simulation}
\label{appendix:student}

Each simulated student is designed to interact with the tutor and learn how to complete the target coding task. The student's behavior is guided by empirical learning actions, such as \textit{initiating greetings, asking or answering questions}, etc. The system prompt templates for the simulation of low-level, medium-level, and high-level students are shown in Table \ref{tab:low_leve_student}, Table \ref{tab:mid_leve_student}, Table \ref{tab:high_leve_student}, respectively.

\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college student who is learning Python programming by conversing with a tutor. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize  You are going to complete the following \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You have basic Python programming knowledge but no additional context about the repository.\\
\ttfamily \footnotesize \\
\ttfamily \footnotesize [Behavior Guidelines] Please take your own level of knowledge in response to the tutor. This may involve one of the following acts: saying a greeting, answering or asking questions, and recalling previously learned knowledge. If you donâ€™t know or understand something, respond accordingly and ask for clarification. Ask only one question at a time. Don't speak more than 50 words at a time. \\
\bottomrule
\end{tabular}
\caption{System prompt for the simulated \textit{low-level} student during the tutor-student interaction.}
\label{tab:low_leve_student}
\end{table}

\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college student who is learning Python programming by conversing with a tutor. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize  You are going to complete the following \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You have the following knowledge: \\
\ttfamily \footnotesize A part of the reference dependencies to be used in the \{FUNCTION\_NAME\} are: \\
\ttfamily \footnotesize \{PARTIAL\_DEPENDENCIES\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize [Behavior Guidelines] Please take your own level of knowledge in response to the tutor. This may involve one of the following acts: saying a greeting, answering or asking questions, and recalling previously learned knowledge. If you donâ€™t know or understand something, respond accordingly and ask for clarification. Ask only one question at a time. Don't speak more than 50 words at a time. \\
\bottomrule
\end{tabular}
\caption{System prompt for the simulated \textit{medium-level} student during the tutor-student interaction.}
\label{tab:mid_leve_student}
\end{table}


\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college student who is learning Python programming by conversing with a tutor. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize  You are going to complete the following \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You have the following knowledge: \\
\ttfamily \footnotesize The contexts above the \{FUNCTION\_NAME\} in the repository are: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{CODE\_CONTEXTS\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize A part of the reference dependencies to be used in the \{FUNCTION\_NAME\} are: \\
\ttfamily \footnotesize \{PARTIAL\_DEPENDENCIES\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize [Behavior Guidelines] Please take your own level of knowledge in response to the tutor. This may involve one of the following acts: saying a greeting, answering or asking questions, and recalling previously learned knowledge. If you donâ€™t know or understand something, respond accordingly and ask for clarification. Ask only one question at a time. Don't speak more than 50 words at a time. \\
\bottomrule
\end{tabular}
\caption{System prompt for the simulated \textit{high-level} student during the tutor-student interaction.}
\label{tab:high_leve_student}
\end{table}




\paragraph{Tutor-Student Interaction}
\label{appendix:prompt_dialogue}

Each LLM-based tutor agent is initialized with a target coding task $\mathcal{T}$ and task-specific knowledge $\mathcal{K}$. As a proactive tutor, it guides students with necessary strategies inspired by cognitive scaffolding approaches \cite{liu2024scaffolding}. These strategies include actions such as \textit{assessing the student's knowledge level, providing constructive feedback, offering reference dependencies}, etc. Table \ref{tab:tutor_template} shows the system prompt template for the tutor agent.

\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college tutor specializing in Python programming. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You are guiding a student to complete the \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize  Reference Knowledge: \\
\ttfamily \footnotesize The contexts above the \{FUNCTION\_NAME\}: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{CODE\_CONTEXTS\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize The dependency paths for the \{FUNCTION\_NAME\}: \\
\ttfamily \footnotesize \{REFERENCE\_DEPENDENCIES\} \\
\ttfamily \footnotesize The reference key solution steps: \\
\ttfamily \footnotesize \{REFERENCE\_STEPS\} \\
\ttfamily \footnotesize \\

\ttfamily \footnotesize Goal Description:  \\
\ttfamily \footnotesize Your goal is to: \\
\ttfamily \footnotesize - Assess the student's current knowledge level through conversation; \\
\ttfamily \footnotesize - Provide the necessary knowledge and scaffold their understanding;  \\
\ttfamily \footnotesize - Lead the student step-by-step to successfully complete the \{FUNCTION\_NAME\} function. \\
\ttfamily \footnotesize You may use the following strategies during the conversation: assessing knowledge level, describing a dependency path, offering a solution step, explaining concepts with code snippets, asking questions or follow-up questions, and providing feedback with elaborations or confirmations. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize  Behavior Guidelines: \\
\ttfamily \footnotesize - Start the tutoring with a friendly greeting. \\
\ttfamily \footnotesize - Limit each response to one action (e.g., ask one question, describe one dependency path, or explain one solution step). \\
\ttfamily \footnotesize - Keep your response concise (do not exceed 60 words at a time). \\
\bottomrule
\end{tabular}
\caption{System prompt for the tutor agent.}
\label{tab:tutor_template}
\end{table}


\paragraph{Pre-test \& Post-test}
\label{appendix:prompt_test}


Table~\ref{tab:pretest_template} and Table~\ref{tab:posttest_template} show the system prompt template for the pre-test and post-test, respectively. The \texttt{\{PRIOR\_KNOWLEDGE\}} is determined by different levels of simulated students (see Table~\ref{tab:low_leve_student},  Table~\ref{tab:mid_leve_student}, and Table~\ref{tab:high_leve_student}).


\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college student who is learning Python programming. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You are going to complete the following \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You have the following knowledge: \\
\ttfamily \footnotesize \{PRIOR\_KNOWLEDGE\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Please directly complete the \{FUNCTION\_NAME\} function based on the information above. \\
\ttfamily \footnotesize Completed Code: \\
\bottomrule
\end{tabular}
\caption{System prompt for the pre-test.}
\label{tab:pretest_template}
\end{table}


\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college student who is learning Python programming. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You are going to complete the following \{FUNCTION\_NAME\} function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize You have the following knowledge: \\
\ttfamily \footnotesize \{PRIOR\_KNOWLEDGE\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Below is your discussion with a tutor: \\
\ttfamily \footnotesize \{DIALOGUE\_CONTEXT\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Please directly complete the \{FUNCTION\_NAME\} function based on the information above. \\
\ttfamily \footnotesize Completed Code: \\
\bottomrule
\end{tabular}
\caption{System prompt for the post-test, where the \texttt{\{PRIOR\_KNOWLEDGE\}} is determined by different levels of simulated students, as described in Table~\ref{tab:low_leve_student},  Table~\ref{tab:mid_leve_student}, and Table~\ref{tab:high_leve_student}.
}
\label{tab:posttest_template}
\end{table}




\paragraph{Knowledge Tracing}
\label{appendix:prompt_KT}


The knowledge tracing in our proposed \model is implemented following the instruction template shown in Table \ref{tab:KT_template}.

\begin{table}[th]
\renewcommand{\arraystretch}{0.95}
\begin{tabular}{p{0.98\linewidth}}
\toprule
\ttfamily \footnotesize You are a college tutor specializing in Python programming. Your role is to assess a student's understanding of the knowledge required to complete the following task. \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Task Details: \\
\ttfamily \footnotesize You are guiding a student to complete the  \{FUNCTION\_NAME\}  function from a repository: \\
\ttfamily \footnotesize \verb|```|Python \\
\ttfamily \footnotesize \{TARGET\_CODING\_TASK\} \\
\ttfamily \footnotesize \verb|```| \\
\ttfamily \footnotesize  Reference Knowledge Components (KCs): \\
\ttfamily \footnotesize The dependency paths for the \{FUNCTION\_NAME\} function: \\
\ttfamily \footnotesize \{REFERENCE\_DEPENDENCIES\} \\
\ttfamily \footnotesize - The reference key solution Steps: \\
\ttfamily \footnotesize \{REFERENCE\_STEPS\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Dialogue Context: \\
\ttfamily \footnotesize Below is the ongoing dialogue between you and the student during this tutoring session: \\
\ttfamily \footnotesize \{DIALOGUE\_CONTEXT\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Previous Estimation of Student's Knowledge: \\
\ttfamily \footnotesize \{PREVIOUS\_TURN\_ESTIMATION\} \\
\ttfamily \footnotesize \\
\ttfamily \footnotesize Your Task: \\
\ttfamily \footnotesize Evaluate the student's understanding of the required knowledge components (KCs) based on the dialogue context and previous estimation: \\
\ttfamily \footnotesize - For each KC, determine whether the student has demonstrated understanding or if there is insufficient evidence of understanding. \\
\ttfamily \footnotesize - Mark a KC as ``Known'' if the dialogue provides evidence that the student understands it; mark a KC as ``Unknown'' if there is no evidence in the dialogue that the student understands it. \\
\ttfamily \footnotesize  \\
\ttfamily \footnotesize Output Format: \\
\ttfamily \footnotesize  Provide your evaluation in the following format: \\
\ttfamily \footnotesize - Known knowledge components: [..., ...] \\
\ttfamily \footnotesize - Unknown knowledge components: [..., ...]  \\
\bottomrule
\end{tabular}
\caption{Prompting template for the knowledge tracing in \model.}
\label{tab:KT_template}
\end{table}
