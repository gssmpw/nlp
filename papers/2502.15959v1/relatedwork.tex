\section{Related Work}
\label{sec:2}
\textit{Knowledge Distillation}: Several KD methods are used today in medical applications \cite{gou2021knowledge}. For example, a study proposes a KD strategy for building compact DL models suitable for the classification of chest X-ray images (CXR) with multiple labels in real time. It uses different CNNs and transformers as teacher networks to transfer KD to smaller student networks \cite{termritthikun2023explainable}. In \cite{park2022self}, distillation for self-supervision and self-training demonstrates higher performance in diagnosing tuberculosis, pneumothorax, and COVID-19 even when using unlabeled data. In \cite{patel2023logistic}, the study predicted results using the Open Access Serial Imaging Study (OASIS) MRI dataset. 
The process includes data exploration, data preprocessing, and the hybrid model that integrates both logistic regression and decision tree algorithms. The proposed hybrid model outperforms existing models, with an overall accuracy of 96\%. Furthermore, in \cite{liu2023segmentation}, 
they introduced a dual-branch architecture that improves performance by transferring knowledge from a teacher to a student model, achieved by minimizing Shannon entropy and KL divergence. This method achieved outstanding results in a public data set for the left ventricular endocardium segmentation task.

\noindent\textit{Explainable AI}: As previously presented, the importance of XAI in medical diagnosis continues play a major role in providing clear interpretability \cite{chaddad2023survey}. For example, in \cite{raihan2023detection}, the authors used Extreme Gradient Boosting (XGboost) to predict whether a patient has chronic kidney disease (CKD). SHAP analysis is used to explain the impact of features on the XGBoost model. For example, using SHAP analysis and the Biogeography-Based Optimization (BBO) algorithm, hemoglobin models arebumin contributed mainly to the detection of CKD. In \cite{alabi2023machine}, machine learning (ML) models are used with understandable AI to build a prognostic model to group patients with nasopharyngeal cancer (NPC) into two groups based on their survival probabilities, high and low. Local Interpretable Model Agnostic Explanations (LIME) and SHAP models were used to provide interpretability. LIME and SHAP models identify personalized protective and risk factors for each NPC patient, revealing new non-linear relationships between input features and survival odds. Similarly, Grad-CAM introduced a novel XAI framework that enhances feature explainability for decision making in tumor diagnosis using ultrasound data, as proposed in \cite{song2023new}. This framework is capable of identifying regions that are more relevant and feature-associated compared to the traditional Grad-CAM. Currently, an automated approach for detecting and classifying leukemia was demonstrated in a data set independent of the subject, using deep transfer learning supported by Grad-CAM visualization \cite{abhishek2023automated}. Unlike previous methods, our approach uses KD to reduce the number of CNN layers and outputs the main features of each layer to improve the interpretability analysis. Furthermore, the model can fully demonstrate the decision-making process while retaining most of the key features.