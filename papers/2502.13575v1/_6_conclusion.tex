\section{Conclusion}

Computational efficiency is a key bottleneck for exploiting test-time scaling in order to enhance model accuracy by allowing models to think longer before responding.
An emerging approach for exploiting test-time scaling is through tree search against a verifier.
A key challenge with existing tree search methods is the trade-off between efficiency and accuracy; high accuracy with tree search necessitates diverse trajectories, but retaining diverse trajectories leads to high inference costs due to reduced KV cache sharing in the tree.
We perform profiling which demonstrates the importance of KV cache sharing, and show that existing efficiency metrics like FLOPs and model calls are insufficient for assessing the efficiency trade-offs between tree search methods due to the impacts of KV sharing.
We then propose \ours, a search strategy which promotes KV cache sharing while retaining diverse trajectories in order to attain high accuracy.
\ours encourages KV cache sharing in the tree search by penalizing divergent branches in the tree.
Our method also incorporates a coverage term which ensures that semantically diverse trajectories are maintained, even while we prune unnecessary redundant trajectories.
By retaining diverse trajectories, we are able to perform sufficient exploration to retain the accuracy benefits of diverse tree search.
The combination of these components of our method allows us to retain necessary diversity while pruning out redundancy in order to enable accurate and efficient tree search.
\ours achieves \textbf{1.8}$\times$ reduction in average KV cache size during the search process, which translates to \textbf{1.4}$\times$ increased throughput, with minimal accuracy loss and without requiring custom kernel implementations.
Our method demonstrates the potential of leveraging efficiency considerations in the search process to enable accurate and efficient search for test-time scaling.
