[
  {
    "index": 0,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      },
      {
        "key": "chen2024more",
        "author": "Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James",
        "title": "Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems"
      },
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      },
      {
        "key": "brown2024large",
        "author": "Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Large language monkeys: Scaling inference compute with repeated sampling"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "cobbe2021training",
        "author": "Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others",
        "title": "Training verifiers to solve math word problems"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      },
      {
        "key": "chen2024more",
        "author": "Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James",
        "title": "Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems"
      },
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "uesato2022solving",
        "author": "Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina",
        "title": "Solving math word problems with process-and outcome-based feedback"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2024math",
        "author": "Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang",
        "title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      },
      {
        "key": "abdulhai2023lmrl",
        "author": "Abdulhai, Marwa and White, Isadora and Snell, Charlie and Sun, Charles and Hong, Joey and Zhai, Yuexiang and Xu, Kelvin and Levine, Sergey",
        "title": "Lmrl gym: Benchmarks for multi-turn reinforcement learning with language models"
      },
      {
        "key": "lee2024rlaif",
        "author": "Harrison Lee and Samrat Phatale and Hassan Mansoor and Kellie Ren Lu and Thomas Mesnard and Johan Ferret and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi",
        "title": "{RLAIF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback"
      },
      {
        "key": "pan2024autonomous",
        "author": "Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane",
        "title": "Autonomous evaluation and refinement of digital agents"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "brown2017libratus",
        "author": "Brown, Noam and Sandholm, Tuomas and Machine, Strategic",
        "title": "Libratus: The Superhuman AI for No-Limit Poker."
      },
      {
        "key": "silver2016mastering",
        "author": "Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others",
        "title": "Mastering the game of Go with deep neural networks and tree search"
      },
      {
        "key": "silver2017mastering",
        "author": "Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others",
        "title": "Mastering chess and shogi by self-play with a general reinforcement learning algorithm"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      },
      {
        "key": "zhou2023language",
        "author": "Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong",
        "title": "Language agent tree search unifies reasoning acting and planning in language models"
      },
      {
        "key": "besta2024graph",
        "author": "Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others",
        "title": "Graph of thoughts: Solving elaborate problems with large language models"
      },
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      },
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      },
      {
        "key": "qiu2024treebon",
        "author": "Qiu, Jiahao and Lu, Yifu and Zeng, Yifan and Guo, Jiacheng and Geng, Jiayi and Wang, Huazheng and Huang, Kaixuan and Wu, Yue and Wang, Mengdi",
        "title": "Treebon: Enhancing inference-time alignment with speculative tree-search and best-of-n sampling"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2016mutual",
        "author": "Li, Jiwei and Jurafsky, Dan",
        "title": "Mutual information and diverse decoding improve neural machine translation"
      },
      {
        "key": "vijayakumar2016diverse",
        "author": "Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv",
        "title": "Diverse beam search: Decoding diverse solutions from neural sequence models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wu2024inference",
        "author": "Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming",
        "title": "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "sun2024fast",
        "author": "Sun, Hanshi and Haider, Momin and Zhang, Ruiqi and Yang, Huitao and Qiu, Jiahao and Yin, Ming and Wang, Mengdi and Bartlett, Peter and Zanette, Andrea",
        "title": "Fast Best-of-N Decoding via Speculative Rejection"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhang2024scaling",
        "author": "Zhang, Kexun and Zhou, Shang and Wang, Danqing and Wang, William Yang and Li, Lei",
        "title": "Scaling llm inference with optimized sample compute allocation"
      },
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      },
      {
        "key": "beeching2024scalingtesttimecompute",
        "author": "Edward Beeching and Lewis Tunstall and Sasha Rush",
        "title": "Scaling test-time compute with open models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "juravsky2024hydragen",
        "author": "Juravsky, Jordan and Brown, Bradley and Ehrlich, Ryan and Fu, Daniel Y and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Hydragen: High-Throughput LLM Inference with Shared Prefixes"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "kwon2023efficient",
        "author": "Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion",
        "title": "Efficient memory management for large language model serving with pagedattention"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "zheng2023efficiently",
        "author": "Zheng, Lianmin and Yin, Liangsheng and Xie, Zhiqiang and Huang, Jeff and Sun, Chuyue and Yu, Cody\\_Hao and Cao, Shiyi and Kozyrakis, Christos and Stoica, Ion and Gonzalez, Joseph E and others",
        "title": "Efficiently Programming Large Language Models using SGLang."
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "yao2024deft",
        "author": "Yao, Jinwei and Chen, Kaiqi and Zhang, Kexun and You, Jiaxuan and Yuan, Binhang and Wang, Zeke and Lin, Tao",
        "title": "DeFT: Flash Tree-attention with IO-Awareness for Efficient Tree-search-based LLM Inference"
      }
    ]
  }
]