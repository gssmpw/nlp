@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{qiu2024treebon,
  title={Treebon: Enhancing inference-time alignment with speculative tree-search and best-of-n sampling},
  author={Qiu, Jiahao and Lu, Yifu and Zeng, Yifan and Guo, Jiacheng and Geng, Jiayi and Wang, Huazheng and Huang, Kaixuan and Wu, Yue and Wang, Mengdi},
  journal={arXiv preprint arXiv:2410.16033},
  year={2024}
}

@article{hooper2024squeezed,
  title={Squeezed attention: Accelerating long context length llm inference},
  author={Hooper, Coleman and Kim, Sehoon and Mohammadzadeh, Hiva and Maheswaran, Monishwaran and Paik, June and Mahoney, Michael W and Keutzer, Kurt and Gholami, Amir},
  journal={arXiv preprint arXiv:2411.09688},
  year={2024}
}

@inproceedings{wu2024inference,
  title={Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  booktitle={The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24},
  year={2024}
}

@misc{beeching2024scalingtesttimecompute,
      title={Scaling test-time compute with open models},
      author={Edward Beeching and Lewis Tunstall and Sasha Rush},
      url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
  year={2024}
}

@article{kim2023squeezellm,
  title={Squeezellm: Dense-and-sparse quantization},
  author={Kim, Sehoon and Hooper, Coleman and Gholami, Amir and Dong, Zhen and Li, Xiuyu and Shen, Sheng and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2306.07629},
  year={2023}
}

@article{kim2023full,
  title={Full stack optimization of transformer inference: a survey},
  author={Kim, Sehoon and Hooper, Coleman and Wattanawong, Thanakul and Kang, Minwoo and Yan, Ruohan and Genc, Hasan and Dinh, Grace and Huang, Qijing and Keutzer, Kurt and Mahoney, Michael W and others},
  journal={arXiv preprint arXiv:2302.14017},
  year={2023}
}

@article{zheng2023efficiently,
  title={Efficiently Programming Large Language Models using SGLang.},
  author={Zheng, Lianmin and Yin, Liangsheng and Xie, Zhiqiang and Huang, Jeff and Sun, Chuyue and Yu, Cody\_Hao and Cao, Shiyi and Kozyrakis, Christos and Stoica, Ion and Gonzalez, Joseph E and others},
  year={2023},
  publisher={arXiv}
}

@article{yao2024deft,
  title={DeFT: Flash Tree-attention with IO-Awareness for Efficient Tree-search-based LLM Inference},
  author={Yao, Jinwei and Chen, Kaiqi and Zhang, Kexun and You, Jiaxuan and Yuan, Binhang and Wang, Zeke and Lin, Tao},
  journal={arXiv preprint arXiv:2404.00242},
  year={2024}
}

@article{sun2024fast,
  title={Fast Best-of-N Decoding via Speculative Rejection},
  author={Sun, Hanshi and Haider, Momin and Zhang, Ruiqi and Yang, Huitao and Qiu, Jiahao and Yin, Ming and Wang, Mengdi and Bartlett, Peter and Zanette, Andrea},
  journal={arXiv preprint arXiv:2410.20290},
  year={2024}
}

@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}

@inproceedings{brown2017libratus,
  title={Libratus: The Superhuman AI for No-Limit Poker.},
  author={Brown, Noam and Sandholm, Tuomas and Machine, Strategic},
  booktitle={IJCAI},
  pages={5226--5228},
  year={2017}
}

@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{silver2017mastering,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{gholami2024ai,
  title={AI and memory wall},
  author={Gholami, Amir and Yao, Zhewei and Kim, Sehoon and Hooper, Coleman and Mahoney, Michael W and Keutzer, Kurt},
  journal={IEEE Micro},
  year={2024},
  publisher={IEEE}
}

@article{juravsky2024hydragen,
  title={Hydragen: High-Throughput LLM Inference with Shared Prefixes},
  author={Juravsky, Jordan and Brown, Bradley and Ehrlich, Ryan and Fu, Daniel Y and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2402.05099},
  year={2024}
}

@article{zhang2024scaling,
  title={Scaling llm inference with optimized sample compute allocation},
  author={Zhang, Kexun and Zhou, Shang and Wang, Danqing and Wang, William Yang and Li, Lei},
  journal={arXiv preprint arXiv:2410.22480},
  year={2024}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}

@article{vijayakumar2016diverse,
  title={Diverse beam search: Decoding diverse solutions from neural sequence models},
  author={Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv},
  journal={arXiv preprint arXiv:1610.02424},
  year={2016}
}

@inproceedings{steinfeldt2024evaluation,
  title={Evaluation and Domain Adaptation of Similarity Models for Short Mathematical Texts},
  author={Steinfeldt, Christian and Mihaljevi{\'c}, Helena},
  booktitle={International Conference on Intelligent Computer Mathematics},
  pages={241--260},
  year={2024},
  organization={Springer}
}

@article{mitchell2011pulp,
  title={Pulp: a linear programming toolkit for python},
  author={Mitchell, Stuart and OSullivan, Michael and Dunning, Iain},
  journal={The University of Auckland, Auckland, New Zealand},
  volume={65},
  pages={25},
  year={2011},
  publisher={Citeseer}
}

@software{john_forrest_2024_13347261,
  author       = {John Forrest and
                  Ted Ralphs and
                  Stefan Vigerske and
                  Haroldo Gambini Santos and
                  John Forrest and
                  Lou Hafer and
                  Bjarni Kristjansson and
                  jpfasano and
                  EdwinStraver and
                  Jan-Willem and
                  Miles Lubin and
                  rlougee and
                  a-andre and
                  jpgoncal1 and
                  Samuel Brito and
                  h-i-gassmann and
                  Cristina and
                  Matthew Saltzman and
                  tosttost and
                  Bruno Pitrus and
                  Fumiaki MATSUSHIMA and
                  Patrick Vossler and
                  Ron @ SWGY and
                  to-st},
  title        = {coin-or/Cbc: Release releases/2.10.12},
  month        = aug,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {releases/2.10.12},
  doi          = {10.5281/zenodo.13347261},
  url          = {https://doi.org/10.5281/zenodo.13347261},
}

@techreport{balandat2019botorch,
  title={BoTorch: Bayesian optimization in PyTorch},
  author={Balandat, Maximilian and Karrer, Brian and Jiang, Daniel R and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
  year={2019},
  institution={Technical report}
}

@article{virtanen2020scipy,
  title={SciPy 1.0: fundamental algorithms for scientific computing in Python},
  author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
  journal={Nature methods},
  volume={17},
  number={3},
  pages={261--272},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{hooper2024kvquant,
  title={Kvquant: Towards 10 million context length llm inference with kv cache quantization},
  author={Hooper, Coleman and Kim, Sehoon and Mohammadzadeh, Hiva and Mahoney, Michael W and Shao, Yakun Sophia and Keutzer, Kurt and Gholami, Amir},
  journal={arXiv preprint arXiv:2401.18079},
  year={2024}
}

@article{pope2023efficiently,
  title={Efficiently scaling transformer inference},
  author={Pope, Reiner and Douglas, Sholto and Chowdhery, Aakanksha and Devlin, Jacob and Bradbury, James and Heek, Jonathan and Xiao, Kefan and Agrawal, Shivani and Dean, Jeff},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  pages={606--624},
  year={2023}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@inproceedings{chen2024more,
  title={Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems},
  author={Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
@article{weng2022large,
  title={Large language models are better reasoners with self-verification},
  author={Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Shengping and Sun, Bin and Liu, Kang and Zhao, Jun},
  journal={arXiv preprint arXiv:2212.09561},
  year={2022}
}
@article{pan2024autonomous,
  title={Autonomous evaluation and refinement of digital agents},
  author={Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane},
  journal={arXiv preprint arXiv:2404.06474},
  year={2024}
}
@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{abdulhai2023lmrl,
  title={Lmrl gym: Benchmarks for multi-turn reinforcement learning with language models},
  author={Abdulhai, Marwa and White, Isadora and Snell, Charlie and Sun, Charles and Hong, Joey and Zhai, Yuexiang and Xu, Kelvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2311.18232},
  year={2023}
}
@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{zhou2023language,
  title={Language agent tree search unifies reasoning acting and planning in language models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  journal={arXiv preprint arXiv:2310.04406},
  year={2023}
}
@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}
@article{li2016mutual,
  title={Mutual information and diverse decoding improve neural machine translation},
  author={Li, Jiwei and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1601.00372},
  year={2016}
}
@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}
@misc{
lee2024rlaif,
title={{RLAIF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback},
author={Harrison Lee and Samrat Phatale and Hassan Mansoor and Kellie Ren Lu and Thomas Mesnard and Johan Ferret and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi},
year={2024},
url={https://openreview.net/forum?id=AAxIs3D2ZZ}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}