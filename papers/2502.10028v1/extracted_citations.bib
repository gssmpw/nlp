@INPROCEEDINGS{10160591,
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Code as Policies: Language Model Programs for Embodied Control}, 
  year={2023},
  volume={},
  number={},
  pages={9493-9500},
  keywords={Feedback loop;Codes;Natural languages;Process control;Detectors;Libraries;Impedance},
  doi={10.1109/ICRA48891.2023.10160591}}

@article{bharadhwaj2024gen2act,
  title={Gen2Act: Human Video Generation in Novel Scenarios enables Generalizable Robot Manipulation},
  author={Bharadhwaj, Homanga and Dwibedi, Debidatta and Gupta, Abhinav and Tulsiani, Shubham and Doersch, Carl and Xiao, Ted and Shah, Dhruv and Xia, Fei and Sadigh, Dorsa and Kirmani, Sean},
  journal={arXiv preprint arXiv:2409.16283},
  year={2024}
}

@inproceedings{bharadhwaj2024roboagent,
  title={Roboagent: Generalization and efficiency in robot manipulation via semantic augmentations and action chunking},
  author={Bharadhwaj, Homanga and Vakil, Jay and Sharma, Mohit and Gupta, Abhinav and Tulsiani, Shubham and Kumar, Vikash},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4788--4795},
  year={2024},
  organization={IEEE}
}

@article{bharadhwaj2024track2act,
  title={Track2Act: Predicting Point Tracks from Internet Videos enables Diverse Zero-shot Robot Manipulation},
  author={Bharadhwaj, Homanga and Mottaghi, Roozbeh and Gupta, Abhinav and Tulsiani, Shubham},
  journal={arXiv preprint arXiv:2405.01527},
  year={2024}
}

@inproceedings{blackzero,
  title={Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer Rich and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{he2024large,
  title={Large-scale actionless video pre-training via discrete diffusion for efficient policy learning},
  author={He, Haoran and Bai, Chenjia and Pan, Ling and Zhang, Weinan and Zhao, Bin and Li, Xuelong},
  journal={arXiv preprint arXiv:2402.14407},
  year={2024}
}

@article{huang2023instruct2act,
  title={Instruct2act: Mapping multi-modality instructions to robotic actions with large language model},
  author={Huang, Siyuan and Jiang, Zhengkai and Dong, Hao and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2305.11176},
  year={2023}
}

@inproceedings{karamcheti2023voltron,
  title={Language-Driven Representation Learning for Robotics},
  author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
  booktitle={Robotics: Science and Systems (RSS)},
  year={2023}
}

@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{li2024gr,
  title={GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal Conditioned Policy},
  author={Li, Peiyan and Wu, Hongtao and Huang, Yan and Cheang, Chilam and Wang, Liang and Kong, Tao},
  journal={arXiv preprint arXiv:2408.14368},
  year={2024}
}

@inproceedings{ma2023liv,
  title={Liv: Language-image representations and rewards for robotic control},
  author={Ma, Yecheng Jason and Kumar, Vikash and Zhang, Amy and Bastani, Osbert and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={23301--23320},
  year={2023},
  organization={PMLR}
}

@inproceedings{mavip,
  title={VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training},
  author={Ma, Yecheng Jason and Sodhani, Shagun and Jayaraman, Dinesh and Bastani, Osbert and Kumar, Vikash and Zhang, Amy},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{nair2023r3m,
  title={R3M: A Universal Visual Representation for Robot Manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  booktitle={Conference on Robot Learning},
  pages={892--909},
  year={2023},
  organization={PMLR}
}

@article{nguyen2024robotic,
  title={Robotic-CLIP: Fine-tuning CLIP on Action Data for Robotic Applications},
  author={Nguyen, Nghia and Vu, Minh Nhat and Ta, Tung D and Huang, Baoru and Vo, Thieu and Le, Ngan and Nguyen, Anh},
  journal={arXiv preprint arXiv:2409.17727},
  year={2024}
}

@InProceedings{pmlr-v164-jang22a,
  title = 	 {BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning},
  author =       {Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {991--1002},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/jang22a/jang22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/jang22a.html},
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{shridhar2022cliport,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on robot learning},
  pages={894--906},
  year={2022},
  organization={PMLR}
}

@inproceedings{shridhargenerative,
  title={Generative Image as Action Models},
  author={Shridhar, Mohit and Lo, Yat Long and James, Stephen},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@inproceedings{vecerik2024robotap,
  title={Robotap: Tracking arbitrary points for few-shot visual imitation},
  author={Vecerik, Mel and Doersch, Carl and Yang, Yi and Davchev, Todor and Aytar, Yusuf and Zhou, Guangyao and Hadsell, Raia and Agapito, Lourdes and Scholz, Jon},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5397--5403},
  year={2024},
  organization={IEEE}
}

@article{wen2023any,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2401.00025},
  year={2023}
}

@inproceedings{wuunleashing,
  title={Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{xuflow,
  title={Flow as the Cross-domain Manipulation Interface},
  author={Xu, Mengda and Xu, Zhenjia and Xu, Yinghao and Chi, Cheng and Wetzstein, Gordon and Veloso, Manuela and Song, Shuran},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@article{yang2024spatiotemporal,
  title={Spatiotemporal Predictive Pre-training for Robotic Motor Control},
  author={Yang, Jiange and Liu, Bei and Fu, Jianlong and Pan, Bocheng and Wu, Gangshan and Wang, Limin},
  journal={arXiv preprint arXiv:2403.05304},
  year={2024}
}

@inproceedings{yu2024hierarchical,
  title={Hierarchical Real-time Motion Planning for Safe Multi-robot Manipulation in Dynamic Environments},
  author={Yu, Jichuan and Jin, Zhao and Hu, Chuxiong and Yan, Jizhou and Wang, Ze and Zhu, Yu},
  booktitle={2024 International Conference on Advanced Robotics and Mechatronics (ICARM)},
  pages={113--119},
  year={2024},
  organization={IEEE}
}

@article{zeng2024learning,
  title={Learning Manipulation by Predicting Interaction},
  author={Zeng, Jia and Bu, Qingwen and Wang, Bangjun and Xia, Wenke and Chen, Li and Dong, Hao and Song, Haoming and Wang, Dong and Hu, Di and Luo, Ping and others},
  journal={arXiv preprint arXiv:2406.00439},
  year={2024}
}

@article{zhang2024catch,
  title={Catch it! learning to catch in flight with mobile dexterous hands},
  author={Zhang, Yuanhang and Liang, Tianhai and Chen, Zhenyang and Ze, Yanjie and Xu, Huazhe},
  journal={arXiv preprint arXiv:2409.10319},
  year={2024}
}

