@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@InProceedings{pmlr-v164-jang22a,
  title = 	 {BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning},
  author =       {Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {991--1002},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/jang22a/jang22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/jang22a.html},
}

@inproceedings{karamcheti2023voltron,
  title={Language-Driven Representation Learning for Robotics},
  author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
  booktitle={Robotics: Science and Systems (RSS)},
  year={2023}
}

@inproceedings{nair2023r3m,
  title={R3M: A Universal Visual Representation for Robot Manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  booktitle={Conference on Robot Learning},
  pages={892--909},
  year={2023},
  organization={PMLR}
}

@inproceedings{ma2023liv,
  title={Liv: Language-image representations and rewards for robotic control},
  author={Ma, Yecheng Jason and Kumar, Vikash and Zhang, Amy and Bastani, Osbert and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={23301--23320},
  year={2023},
  organization={PMLR}
}

@article{nguyen2024robotic,
  title={Robotic-CLIP: Fine-tuning CLIP on Action Data for Robotic Applications},
  author={Nguyen, Nghia and Vu, Minh Nhat and Ta, Tung D and Huang, Baoru and Vo, Thieu and Le, Ngan and Nguyen, Anh},
  journal={arXiv preprint arXiv:2409.17727},
  year={2024}
}

@inproceedings{wuunleashing,
  title={Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{zeng2024learning,
  title={Learning Manipulation by Predicting Interaction},
  author={Zeng, Jia and Bu, Qingwen and Wang, Bangjun and Xia, Wenke and Chen, Li and Dong, Hao and Song, Haoming and Wang, Dong and Hu, Di and Luo, Ping and others},
  journal={arXiv preprint arXiv:2406.00439},
  year={2024}
}

@article{yang2024spatiotemporal,
  title={Spatiotemporal Predictive Pre-training for Robotic Motor Control},
  author={Yang, Jiange and Liu, Bei and Fu, Jianlong and Pan, Bocheng and Wu, Gangshan and Wang, Limin},
  journal={arXiv preprint arXiv:2403.05304},
  year={2024}
}

@inproceedings{vecerik2024robotap,
  title={Robotap: Tracking arbitrary points for few-shot visual imitation},
  author={Vecerik, Mel and Doersch, Carl and Yang, Yi and Davchev, Todor and Aytar, Yusuf and Zhou, Guangyao and Hadsell, Raia and Agapito, Lourdes and Scholz, Jon},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5397--5403},
  year={2024},
  organization={IEEE}
}

@article{wen2023any,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2401.00025},
  year={2023}
}

@article{yuan2024general,
  title={General flow as foundation affordance for scalable robot learning},
  author={Yuan, Chengbo and Wen, Chuan and Zhang, Tong and Gao, Yang},
  journal={arXiv preprint arXiv:2401.11439},
  year={2024}
}

@article{bharadhwaj2024track2act,
  title={Track2Act: Predicting Point Tracks from Internet Videos enables Diverse Zero-shot Robot Manipulation},
  author={Bharadhwaj, Homanga and Mottaghi, Roozbeh and Gupta, Abhinav and Tulsiani, Shubham},
  journal={arXiv preprint arXiv:2405.01527},
  year={2024}
}

@inproceedings{xuflow,
  title={Flow as the Cross-domain Manipulation Interface},
  author={Xu, Mengda and Xu, Zhenjia and Xu, Yinghao and Chi, Cheng and Wetzstein, Gordon and Veloso, Manuela and Song, Shuran},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@inproceedings{blackzero,
  title={Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer Rich and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{shridhargenerative,
  title={Generative Image as Action Models},
  author={Shridhar, Mohit and Lo, Yat Long and James, Stephen},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@article{li2024gr,
  title={GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal Conditioned Policy},
  author={Li, Peiyan and Wu, Hongtao and Huang, Yan and Cheang, Chilam and Wang, Liang and Kong, Tao},
  journal={arXiv preprint arXiv:2408.14368},
  year={2024}
}

@inproceedings{yu2024hierarchical,
  title={Hierarchical Real-time Motion Planning for Safe Multi-robot Manipulation in Dynamic Environments},
  author={Yu, Jichuan and Jin, Zhao and Hu, Chuxiong and Yan, Jizhou and Wang, Ze and Zhu, Yu},
  booktitle={2024 International Conference on Advanced Robotics and Mechatronics (ICARM)},
  pages={113--119},
  year={2024},
  organization={IEEE}
}

@inproceedings{SpatialTracker,
    title={SpatialTracker: Tracking Any 2D Pixels in 3D Space},
    author={Xiao, Yuxi and Wang, Qianqian and Zhang, Shangzhan and Xue, Nan and Peng, Sida and Shen, Yujun and Zhou, Xiaowei},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2024}
}

@article{mees2022calvin,
author = {Oier Mees and Lukas Hermann and Erick Rosete-Beas and Wolfram Burgard},
title = {CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks},
journal={IEEE Robotics and Automation Letters (RA-L)},
volume={7},  
number={3},  
pages={7327-7334},
year={2022}
}

@article{liu2024libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{shridhar2022cliport,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on robot learning},
  pages={894--906},
  year={2022},
  organization={PMLR}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{bharadhwaj2024roboagent,
  title={Roboagent: Generalization and efficiency in robot manipulation via semantic augmentations and action chunking},
  author={Bharadhwaj, Homanga and Vakil, Jay and Sharma, Mohit and Gupta, Abhinav and Tulsiani, Shubham and Kumar, Vikash},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4788--4795},
  year={2024},
  organization={IEEE}
}

@INPROCEEDINGS{10160591,
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Code as Policies: Language Model Programs for Embodied Control}, 
  year={2023},
  volume={},
  number={},
  pages={9493-9500},
  keywords={Feedback loop;Codes;Natural languages;Process control;Detectors;Libraries;Impedance},
  doi={10.1109/ICRA48891.2023.10160591}}

@article{huang2023instruct2act,
  title={Instruct2act: Mapping multi-modality instructions to robotic actions with large language model},
  author={Huang, Siyuan and Jiang, Zhengkai and Dong, Hao and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2305.11176},
  year={2023}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{bharadhwaj2024gen2act,
  title={Gen2Act: Human Video Generation in Novel Scenarios enables Generalizable Robot Manipulation},
  author={Bharadhwaj, Homanga and Dwibedi, Debidatta and Gupta, Abhinav and Tulsiani, Shubham and Doersch, Carl and Xiao, Ted and Shah, Dhruv and Xia, Fei and Sadigh, Dorsa and Kirmani, Sean},
  journal={arXiv preprint arXiv:2409.16283},
  year={2024}
}

@inproceedings{mavip,
  title={VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training},
  author={Ma, Yecheng Jason and Sodhani, Shagun and Jayaraman, Dinesh and Bastani, Osbert and Kumar, Vikash and Zhang, Amy},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{he2024large,
  title={Large-scale actionless video pre-training via discrete diffusion for efficient policy learning},
  author={He, Haoran and Bai, Chenjia and Pan, Ling and Zhang, Weinan and Zhao, Bin and Li, Xuelong},
  journal={arXiv preprint arXiv:2402.14407},
  year={2024}
}

@article{zhang2024catch,
  title={Catch it! learning to catch in flight with mobile dexterous hands},
  author={Zhang, Yuanhang and Liang, Tianhai and Chen, Zhenyang and Ze, Yanjie and Xu, Huazhe},
  journal={arXiv preprint arXiv:2409.10319},
  year={2024}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}

@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{zhang2024tora,
  title={Tora: Trajectory-oriented diffusion transformer for video generation},
  author={Zhang, Zhenghao and Liao, Junchao and Li, Menghao and Dai, Zuozhuo and Qiu, Bingxue and Zhu, Siyu and Qin, Long and Wang, Weizhi},
  journal={arXiv preprint arXiv:2407.21705},
  year={2024}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@inproceedings{perez2018film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@inproceedings{reuss2024multimodal,
  title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
  author={Reuss, Moritz and Ya{\u{g}}murlu, {\"O}mer Erdin{\c{c}} and Wenzel, Fabian and Lioutikov, Rudolf},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}

@article{liu2024robouniview,
  title={Robouniview: Visual-language model with unified view representation for robotic manipulation},
  author={Liu, Fanfan and Yan, Feng and Zheng, Liming and Feng, Chengjian and Huang, Yiyang and Ma, Lin},
  journal={arXiv preprint arXiv:2406.18977},
  year={2024}
}

@article{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}

@article{mees2022matters,
  title={What matters in language conditioned robotic imitation learning over unstructured data},
  author={Mees, Oier and Hermann, Lukas and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={11205--11212},
  year={2022},
  publisher={IEEE}
}

@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and Cousineau, Eric and Du, Yilun and Burchfiel, Benjamin and Tedrake, Russ and Song, Shuran},
  journal={The International Journal of Robotics Research},
  pages={02783649241273668},
  year={2023},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{li2023vision,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@article{ke20243d,
  title={3d diffuser actor: Policy diffusion with 3d scene representations},
  author={Ke, Tsung-Wei and Gkanatsios, Nikolaos and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2402.10885},
  year={2024}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{fang2023rh20t,
  title={Rh20t: A robotic dataset for learning diverse skills in one-shot},
  author={Fang, Hao-Shu and Fang, Hongjie and Tang, Zhenyu and Liu, Jirong and Wang, Junbo and Zhu, Haoyi and Lu, Cewu},
  booktitle={RSS 2023 Workshop on Learning for Task and Motion Planning},
  year={2023}
}

@inproceedings{walke2023bridgedata,
  title={Bridgedata v2: A dataset for robot learning at scale},
  author={Walke, Homer Rich and Black, Kevin and Zhao, Tony Z and Vuong, Quan and Zheng, Chongyi and Hansen-Estruch, Philippe and He, Andre Wang and Myers, Vivek and Kim, Moo Jin and Du, Max and others},
  booktitle={Conference on Robot Learning},
  pages={1723--1736},
  year={2023},
  organization={PMLR}
}

@misc{BerkeleyUR5Website,
  title = {Berkeley {UR5} Demonstration Dataset},
  author = {Lawrence Yunliang Chen and Simeon Adebola and Ken Goldberg},
  howpublished = {\url{https://sites.google.com/view/berkeley-ur5/home}},
  year={2023},
}

@article{shah2023mutex,
  title={Mutex: Learning unified policies from multimodal task specifications},
  author={Shah, Rutav and Mart{\'\i}n-Mart{\'\i}n, Roberto and Zhu, Yuke},
  journal={arXiv preprint arXiv:2309.14320},
  year={2023}
}

@inproceedings{brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}

@article{o2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}