@ARTICLE{499920,
  author={Gotsman, C. and Lindenbaum, M.},
  journal={IEEE Transactions on Image Processing}, 
  title={On the metric properties of discrete space-filling curves}, 
  year={1996},
  volume={5},
  number={5},
  pages={794-797},
  keywords={Image reconstruction;Entropy;Image processing;Iterative algorithms;X-ray imaging;Multidimensional systems;Radioactive decay;Positron emission tomography;Convergence;Image converters},
  doi={10.1109/83.499920}}

@ARTICLE{908985,
  author={Moon, B. and Jagadish, H.V. and Faloutsos, C. and Saltz, J.H.},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Analysis of the clustering properties of the Hilbert space-filling curve}, 
  year={2001},
  volume={13},
  number={1},
  pages={124-141},
  keywords={Hilbert space;Multidimensional systems;Image coding;Image databases;Geographic Information Systems;Moon;Shape;Time measurement;Fractals;Helium},
  doi={10.1109/69.908985}}

@article{BORRELL2018264,
title = {Parallel mesh partitioning based on space filling curves},
journal = {Computers \& Fluids},
volume = {173},
pages = {264-272},
year = {2018},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2018.01.040},
url = {https://www.sciencedirect.com/science/article/pii/S0045793018300446},
author = {R. Borrell and J.C. Cajas and D. Mira and A. Taha and S. Koric and M. Va\`zquez and G. Houzeaux},
keywords = {Space filling curve, SFC, Mesh partitioning, Geometric partitioning, Parallel computing},
abstract = {Larger supercomputers allow the simulation of more complex phenomena with increased accuracy. Eventually this requires finer and thus also larger geometric discretizations. In this context, and extrapolating to the Exascale paradigm, meshing operations such as generation, deformation, adaptation/regeneration or partition/load balance, become a critical issue within the simulation workflow. In this paper we focus on mesh partitioning. In particular, we present a fast and scalable geometric partitioner based on Space Filling Curves (SFC), as an alternative to the standard graph partitioning approach. We have avoided any computing or memory bottleneck in the algorithm, while we have imposed that the solution achieved is independent (discounting rounding off errors) of the number of parallel processes used to compute it. The performance of the SFC-based partitioner presented has been demonstrated using up to 4096 CPU-cores in the Blue Waters supercomputer.}
}

@article{BaumanK.E.2006Tdfo,
abstract = {It is proved that the maximum value of the ratio vertical bar p(x) - p(y)vertical bar(2)/vertical bar x-y vertical bar for the Peano-Hilbert curve p: [0, 1] = I -> I-2 is equal to 6.},
author = {Bauman, K. E.},
address = {NEW YORK},
copyright = {Copyright 2006 Elsevier B.V., All rights reserved.},
issn = {0001-4346},
journal = {Mathematical Notes},
keywords = {Mathematics ; Peano-Hilbert curve ; Physical Sciences ; Science & Technology ; Square-to-linear dilation factor ; Square-to-linear ratio},
language = {eng},
number = {5-6},
pages = {609-620},
publisher = {Springer Nature},
title = {The dilation factor of the Peano-Hilbert curve},
volume = {80},
year = {2006},
}

@article{ChenJie2022Gcfs,
abstract = {The general method of graph coarsening or graph reduction has been a remarkably useful and ubiquitous tool in scientific computing and it is now just starting to have a similar impact in machine learning. The goal of this paper is to take a broad look into coarsening techniques that have been successfully deployed in scientific computing and see how similar principles are finding their way in more recent applications related to machine learning. In scientific computing, coarsening plays a central role in algebraic multigrid methods as well as the related class of multilevel incomplete LU factorizations. In machine learning, graph coarsening goes under various names, e.g., graph downsampling or graph reduction. Its goal in most cases is to replace some original graph by one which has fewer nodes, but whose structure and characteristics are similar to those of the original graph. As will be seen, a common strategy in these methods is to rely on spectral properties to define the coarse graph.},
author = {Chen, Jie and Saad, Yousef and Zhang, Zechen},
address = {Cham},
copyright = {The Author(s) 2022},
issn = {2254-3902},
journal = {SeMA journal},
keywords = {Applications of Mathematics ; Coarsening ; Computation ; Graph Coarsening ; Graphs and Networks ; Hierarchical methods. Graph Neural Networks ; Machine learning ; Mathematics ; Mathematics and Statistics ; Multigrid methods ; Multilevel methods ; Reduction ; Software},
language = {eng},
number = {1},
pages = {187-223},
publisher = {Springer International Publishing},
title = {Graph coarsening: from scientific computing to machine learning},
volume = {79},
year = {2022},
}

@inproceedings{JOSTLE,
  title={JOSTLE: multilevel graph partitioning software: an overview},
  author={Chris Walshaw and Mark Cross},
  year={2007},
  url={https://api.semanticscholar.org/CorpusID:59804754}
}

@ARTICLE{KL,
  author={Kernighan, B. W. and Lin, S.},
  journal={The Bell System Technical Journal}, 
  title={An efficient heuristic procedure for partitioning graphs}, 
  year={1970},
  volume={49},
  number={2},
  pages={291-307},
  keywords={},
  doi={10.1002/j.1538-7305.1970.tb01770.x}}

@article{METIS,
author = {Karypis, George and Kumar, Vipin},
title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
journal = {SIAM Journal on Scientific Computing},
volume = {20},
number = {1},
pages = {359-392},
year = {1998},
doi = {10.1137/S1064827595287997},

URL = { 
    
        https://doi.org/10.1137/S1064827595287997
    
    

},
eprint = { 
    
        https://doi.org/10.1137/S1064827595287997
    
    

}
,
    abstract = { Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445--452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not knownif they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the effectiveness of many different choices for all three phases: coarsening, partition of the coarsest graph, and refinement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the final partition obtained after multilevel refinement. We also present a much faster variation of the Kernighan--Lin (KL) algorithm for refining during uncoarsening. We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute fill-reducing orderings for sparse matrices, it produces orderings that have substantially smaller fill than the widely used multiple minimum degree algorithm. }
}

@misc{MIZRACHI,
abstract = {The Voronoi diagram is a fundamental mathematical structure with numerous scientific applications. It is built from a set of points, denoted as S, and consists of cells. Each cell comprises points in space that are closest to one of the points in set S compared to all the other points in S. A Vornooi cell can be shown to be a convex polyhedron. Constructing a Voronoi diagram, which involves calculating the cells and their geometrical boundaries, has been extensively researched, with several known algorithms. However, there is a need for a distributed tessellation where the points are distributed across multiple processors, each with its own memory. The goal is for each processor to contain the appropriate cells of its given points, creating a local tessellation. Ultimately, the union of these local tessellations should form the same tessellation that would have been built if all points were gathered on a single processor and the Voronoi tessellation was created there, which is referred to as a global tessellation. Our primary motivation for accelerating the distributed Voronoi construction is using Voronoi tessellation in physics simulations. We represent frameworks that solve the distributed Voronoi tessellation problem and focus on an algorithm that builds a dual equivalent spatial structure called Delaunay triangulation. We also consider two algorithms for a distributed Delaunay triangulation and present an improvement for them. Since communication and synchronization are needed between the processors in a distributed Delaunay triangulation build, we are allowed to redistribute the initial points among the processors in order to make a better communication pattern between processors. This operation is also called load balancing or mesh partitioning. This problem is equivalent to the graph partitioning problem and turns out to be NP-hard. We cover several heuristics to solve the graph partitioning problem and then present a known heuristic to solve the mesh partitioning problem called curve-based balancing, especially using a space-filling curve (SFC) called the Hilbert curve. This method has multiple issues, especially when the decomposed space shape is non-rectangular. We introduce a novel technique for overcoming this problem in several scenarios, called kernelization, and later evaluate this technique in a shape called a frustum. The new approach does not impair the running time, which is a proof of concept for the proposed method.},
author = {Mizrachi, Maor and Steinberg, Elad and Raveh, Barak and Hebrew University of Jerusalem, degree granting institution},
address = {Jerusalem},
booktitle = {Parallel Constructing of Voronoi Diagrams and Delaunay Triangulations for Distributed Memory Physics Simulations},
language = {eng},
publisher = {[The Hebrew University of Jerusalem]},
title = {Parallel Constructing of Voronoi Diagrams and Delaunay Triangulations for Distributed Memory Physics Simulations },
year = {2024},
keywords = {Computer capacity -- Management},
}

@article{RSB,
author = {Pothen, Alex and Simon, Horst D. and Liou, Kang-Pu},
title = {Partitioning Sparse Matrices with Eigenvectors of Graphs},
journal = {SIAM Journal on Matrix Analysis and Applications},
volume = {11},
number = {3},
pages = {430-452},
year = {1990},
doi = {10.1137/0611030},
URL = { 
        https://doi.org/10.1137/0611030
},
eprint = { 
        https://doi.org/10.1137/0611030
}
,
    abstract = { The problem of computing a small vertex separator in a graph arises in the context of computing a good ordering for the parallel factorization of sparse, symmetric matrices. An algebraic approach for computing vertex separators is considered in this paper. It is, shown that lower bounds on separator sizes can be obtained in terms of the eigenvalues of the Laplacian matrix associated with a graph. The Laplacian eigenvectors of grid graphs can be computed from Kronecker products involving the eigenvectors of path graphs, and these eigenvectors can be used to compute good separators in grid graphs. A heuristic algorithm is designed to compute a vertex separator in a general graph by first computing an edge separator in the graph from an eigenvector of the Laplacian matrix, and then using a maximum matching in a subgraph to compute the vertex separator. Results on the quality of the separators computed by the spectral algorithm are presented, and these are compared with separators obtained from other algorithms for computing separators. Finally, the time required to compute the Laplacian eigenvector is reported, and the accuracy with which the eigenvector must be computed to obtain good separators is considered. The spectral algorithm has the advantage that it can be implemented on a medium-size multiprocessor in a straightforward manner. }
}

@article{Steinberg_2015,
   title={BALANCING THE LOAD: A VORONOI BASED SCHEME FOR PARALLEL COMPUTATIONS},
   volume={216},
   ISSN={1538-4365},
   url={http://dx.doi.org/10.1088/0067-0049/216/1/14},
   DOI={10.1088/0067-0049/216/1/14},
   number={1},
   journal={The Astrophysical Journal Supplement Series},
   publisher={American Astronomical Society},
   author={Steinberg, Elad and Yalinewich, Almog and Sari, Re’em and Duffell, Paul},
   year={2015},
   month=jan, pages={14} }

@masterthesis{YANIV,
    author = {Yaniv Romem},
    title = {Utilizing Simulated Annealing for Static and Dynamic Data Mapping to Distributed Memory Multiprocessors},
    school = {Hebrew University of Jerusalem},
    year = 1992
}

@article{benchmark_graph_frameworks,
author = {Bokhare, Anuja and Metkewar, Pravin},
year = {2019},
month = {11},
pages = {775-787},
title = {Benchmarking of Graph Partitioning Tools and Techniques},
volume = {8},
journal = {International Journal of Recent Technology and Engineering (IJRTE)},
doi = {10.35940/ijrte.D7369.118419}
}

@inproceedings{curve_balancing_comparison,
author = {Harlacher, Daniel and Klimach, Harald and Roller, Sabine and Siebert, Christian and Wolf, Felix},
year = {2012},
month = {05},
pages = {1661-1669},
title = {Dynamic Load Balancing for Unstructured Meshes on Space-Filling Curves},
isbn = {978-1-4673-0974-5},
journal = {Proceedings of the 2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2012},
doi = {10.1109/IPDPSW.2012.207}
}

@artice{hilbert_testing,
author = {M. Filipiak},
title={Mesh reordering in Fluidity using Hilbert space-filling curves},
year = {2013}
}

@article{survey,
author = {Nr, Vol and Fjallstrom, Per-Olof},
year = {1998},
month = {10},
pages = {},
journal = {},
title = {Algorithms for Graph Partitioning: A Survey}
}

