\section{Related Work}
In the context of single-cell data, imputation is a common step to handle missing values. Various algorithms are employed for this purpose, and one effective approach is using autoencoders**Kingma et al., "Auto-encoding Variational Bayes"**. Autoencoders learn the underlying structure of the data and predict missing values based on the available information.  Dimensionality reduction methods play a crucial role in single-cell analysis. PCA is commonly employed to reduce dimensionality by calculating the principal components. These components capture the most significant variation in gene expression across cells, allowing for efficient representation and visualization of the data**Abdi et al., "Principal Component Analysis"**. The Uniform Manifold Approximation and Projection (UMAP) method is commonly employed to reduce dimensionality and visualize single-cell data**McInnes et al., "UMAP: Uniform Manifold Approximation and Projection"**. t-Distributed Stochastic Neighbor Embedding (t-SNE) is a dimensionality reduction technique commonly used in single-cell RNA sequencing analysis while preserving local structure**Van der Maaten et al., "Visualizing Data using t-SNE"**. Autoencoder is also used to reduce dimensions**Hinton et al., "Autoencoders, Minimum Description Length and Helmholtz Free Energy"**. Data partitioning is a fundamental technique in machine learning, particularly when dealing with large datasets**Friedman et al., "The Elements of Statistical Learning"**. In certain scenarios involving large datasets distributed across multiple servers, the data is divided into segments. Each segment is processed independently on its respective server**Dean et al., "Large-Scale Distributed Deep Networks"**. Within each segment, dimensionality reduction techniques are applied to reduce the number of features while preserving relevant information. After dimensionality reduction, the reduced data from all segments is combined, serving as a proxy for the original dataset**Bhatia et al., "Big Data Clustering"**. This combined reduced data is then used for clustering purposes. When dealing with large datasets and distributed clustering of high-dimensional, heterogeneous data, a technique called Collective PCA can be employed. Collective PCA is specifically designed for distributed scenarios and can be used independently of clustering algorithms. It aims to reduce the dimensionality of the data while preserving essential information**Chen et al., "Collective PCA: Distributed Principal Component Analysis"**.