\section{discussion}
\label{sec:discussion}
DMD, similar to PCA, performs dimensionality reduction on some dataset, and provides a reduced basis for representing the fluid flow. The key difference is that in constructing this basis, DMD optimizes for the \emph{action} of some linear operator that maps the data from one time state to the next, while PCA only looks at the state snapshots individually. This temporal information allows DMD to find a reduced space that can represent the evolution of the field as a linear operator within this reduced space, as opposed to PCA that only seeks to find a reduced space that best minimizes reconstruction error.

We also note that as a spectral decomposition of the reduced Koopman operator, much of the \emph{directability} power of DMD comes from the exposure of the complex-valued eigenvalues. Because each eigenvalue represents a different speed of rotation, and their corresponding eigenvectors represent their spatial bases, we gain manipulability over different scales of turbulence for free. This is similar in concept to other spectral methods \cite{kim2008wavelet}, but with corresponding spatial bases that learned from input data rather than predefined bases. 

We thus show that DMD straddles the realm between \emph{spatial} order reduction (PCA and co.) and \emph{temporal} order reduction (spectral methods), gaining strengths of both methodologies.
%, yielding a decomposition of the spatial energy domain. At the same time, it considers the temporal ordering of the dataset snapshots and assumes a linear relationship between them, whereas PCA does not take the ordering of the dataset into account. When we observe the dataset in the reduced space, we can identify that it is decomposed into $r$ modes of different frequencies, thereby capturing the temporal information of the dataset.

\subsection{Limitations}
\label{sec:limitation}
\paragraph{SVD for Dimensionality Reduction}
Like other low-rank approximation approaches, DMD requires performing SVD for dimensionality reduction. This demands high memory consumption for large-dimensional data, such as 3D fluid simulation, on the order of $\mathcal{O}(n^2)$, where $n$ is the number of state variables. Despite applying randomized SVD to reduce this memory footprint, larger simulations are still costly to train. In the future, we will explore the use of other dimensionality reduction methods, such as autoencoders, to reduce the dimensionality of the dataset.

\paragraph{Unseen External Force Generalization} It is well-known that reduced-order model trades \emph{generalization} for \emph{performance}; our method is no exception. We have demonstrated that we can represent velocity fields that were unseen by DMD, as well as interactively push current states towards modified states. Despite this, representability is still a key limitation--there just may not be the spatial basis to support certain velocity fields. Thus, users may find that interacting with the fields, especially in states far away from observed data, behave strangely. This warrants further work on improving spatial generalization of these methods.



\subsection{Future Work}
\label{sec:future_works}
We have identified various potential avenues for extension, particularly ones that exploit the linearity of the DMD operator.

\paragraph{Augmenting Fluid State with Density Field}
The DMD framework allows us to trivially evaluate the velocity field at any point in time via a low-dimensional matrix exponentiation (as shown in \reffig{fig:dmdadvectioncomparison}).
%
unfortunately evaluating an immersed  \textit{density field } at any point in 
time is not so trivial.
%
To achieve the time-evolved density field, we've first had to resort to classical numerical integration, first evaluating the velocity field with our fast DMD model, and then using that velocity field to advect the density field forward.
As an exciting avenue of future work, this could potentially be sidestepped by defining the fluid state as including the density field (as opposed to just the velocity field), and forming a \koopman{} on this augmented system. This would allow us to use the exact same DMD framework to quickly query the density of the flow at any point in time.

% blending between DMD operators for expressive range 
% adaptively/dynamically blending between them in response to user inputs
\paragraph{Adaptive Blending between DMD Operators}
As a linear operator, linear combinations of DMD operators construct a valid linear operator. Therefore, we can train multiple DMD operators and flexibly combine them to obtain a richer set of new motion patterns.
Similar to building an ensemble, once we have multiple pre-trained DMD operators, we solve a minimal optimization problem to adaptively selects the optimal linear combination of DMD operators based on user input, achieving the desired motion effects in the simulation.
% inverse design–––adjust the eigenfunction amplitudes based on objectives like wanting flow in certain places, or given desired silhouettes
\paragraph{Inverse Design}
Since the DMD operator decomposes the energy information ($\bm{\Phi}$) and frequency information ($\bm{\Lambda}$) of a simulation sequence, we can adjust the eigenbasis of the DMD operator based on the user-defined objectives, thereby modifying the energy and frequency information represented by the DMD operator. We take gradients of the DMD operator with respect to some target images at prescribed points in time, and use this as an optimizer to construct a \emph{new} DMD operator that represents flow that evolving through the specified snapshots.
% neural based generalization
\paragraph{Learning Control Space Enrichment}
Inspired by DMD with control \cite{proctor2016dynamic}, we could train a neural network to enrich the linear control space of the DMD operator with nonlinear responses. This network could be a direct way to expand the expressiveness of the DMD operator, allowing us to learn more diverse motion patterns and handle more complex user inputs.