\section{Experiments}
\label{sec: experiment}
\begin{figure}[t]
    \centering
    \includegraphics[keepaspectratio, scale=0.3]{experiment_box_MNISTtheo_B10_rep20_for_arxiv.eps}
    \vspace{-10pt}
     \caption{A box plot of error rate of the MNIST experiment for multiclass classification with bandit feedback.
     }
    \label{fig:experiment mnist}
\end{figure}

This section presents numerical experiment results for online multiclass classification  
under bandit feedback.  
We compare three algorithms:  
Gaptron~\Citep{NEURIPS2020_Hoeven} with logistic loss and hinge loss as surrogate losses,  
Gappletron~\Citep{NEURIPS2021_Hoeven} with logistic loss as the surrogate loss,  
and our proposed algorithm from \cref{subsec:bandit_delay_general}.  
The parameters for each algorithm are set based on their theoretical values.  
We use the MNIST dataset~\citep{lecun2010mnist}, a dataset of digit images.  
The diameter $B$ of $\ww$ is fixed at $10$.  
We repeated the experiment for 20 times, and the boxplot of the obtained misclassification rates is summarized in \cref{fig:experiment mnist}.  
From \cref{fig:experiment mnist}, we observe that our method achieves the lowest misclassification rate.  
Despite not being specialized for multiclass classification,  
our approach outperforms existing algorithms designed for multiclass classification  
on real data with $K = 10$.  
Further experiments can be found in \cref{app: experiment},  
and related discussions are provided in \cref{app:Discussio_on_the_Difference_in_Surrogate_Losses}.\looseness=-1












