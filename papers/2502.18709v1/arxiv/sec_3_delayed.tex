\section{Delayed Full-Information Feedback}
\label{sec:delay}
This section discusses online structured prediction with delayed full-information feedback and provides an algorithm that achieves a surrogate regret bound of $O(D^{2/3} T^{1/3})$, a better bound than $O(\sqrt{D T})$ that can be achieved with a standard OCO algorithm under delayed feedback \citep{joulani13online}. 
Below, we make the following assumption.\looseness=-1
\begin{assumption}
\label{asp:delayed_a}
There exists a constant $a\in\prn{0,1}$ which satisfies
\[
    \expect{L_t(\yht)}\leq(1-a)\sw.
\]
\end{assumption}
From \Cref{lem:expected_target_bound}, if $\lambda>\frac{4\gamma}{\nu}$, this condition is satisfied with $a=1-\frac{4\gamma}{\lambda\nu}$ by using the randomized decoding. 
We suppose that such a decoding function is used in this section.

\paragraph{Algorithm}
For updating $\wt$, we employ the Optimistic Delayed Adaptive FTRL (ODAFTRL) algorithm proposed by \citet{pmlr-v139-flaspohler21a}.  
In ODAFTRL, given a gradient~$\bm{G}_t$ at round $t$, $\W_t$ is updated as
\begin{equation}
    \W_{t+1}
    =
    \argmin_{\W\in \ww} \set*{ \sum_{i=1}^{t-D} \inpr*{\bm{G}_i,\W}+\frac{\lambda_t \nrm{\W}_{\F}^2}{2} },
    \nonumber
\end{equation}
where $\lambda_t\geq0$ is the regularization parameter.  
Due to space constraints, the details of the algorithm are provided in \cref{app:sub_odaftrl}.
By updating $\lambda_t$ using an AdaHedge-type algorithm called AdaHedgeD,  
ODAFTRL achieves the following regret upper bound:
\begin{lemma}[{Informal version of \citealt[Theorem 12]{pmlr-v139-flaspohler21a}}]\label{lem:ODAFTRL_bound}
Consider the setting with delayed full-information feedback.
Then, for any $\U\in\ww$, ODAFTRL with the AdaHedgeD update of $\lambda_t$ achieves
$
    \sumt{(\sw\!-\!\su)}
    \leq
    \sumt{\inpr{\G_t, \W_t - \U}}
    =
    O\prn[\Big]{\sqrt{\sumt{(\nrm{\G_t}_\F^2\!+\!D\nrm{\G_t}_\F)}}}.
$
\end{lemma}

\paragraph{Regret bounds and analysis}
The algorithm described above achieves the following bound:
\begin{theorem}
    \label{thm:delayed_regret_expectation_abstract}
    The above algorithm achieves
    $
        \E\brk{\reg}=O(D^{2/3}T^{1/3}).
    $
\end{theorem}
Here, we provide a proof sketch; the complete proof can be found in \cref{app:sub_delayed_regret_expectation_abstract}.
\begin{proof}[Proof sketch]
    \Cref{lem:ODAFTRL_bound} with $\nrm{\G_t}_\F^2\leq b\sw$ in \eqref{eq:St_smooth} and Cauchy--Schwarz yields
    $\sumt{(\sw-\su)}=O(\sqrt{S_{1:T}}+\prn{D^2TS_{1:T}}^{1/4})$, where $S_{1:T}=\sumt{\sw}$.
    Hence, from \cref{asp:delayed_a}, we have
    $
        \E\brk{\reg}\leq \sumt{(\sw-\su)}-a\sumt{\sw}
        =O(\sqrt{S_{1:T}}+\prn{D^2TS_{1:T}}^{1/4})-aS_{1:T}
        =O\prn{D^{2/3}T^{1/3}},
    $
    where we used $c_1\sqrt{x}-c_2x\leq{c_1^2}/\prn{4c_2}$ and $c_1x-c_2x^4\leq\prn*{{c_1^4}/\prn{4c_2}}^{1/3}$ for $x\geq0$, $c_1\geq 0$, and $c_2>0$.
\end{proof}
We can also prove the following high-probability bound; see \cref{app:sub_delayed_regret_probability_abstract} for the proof:
\begin{theorem}
    \label{thm:delayed_regret_probability_abstract}
    For any $\delta \in (0,1)$,
    with probability at least $1 - \delta$, the above algorithm achieves 
    $
        \reg = O\prn{\log({1}/{\delta}) + D^{2/3}T^{1/3}}.
    $
\end{theorem}

