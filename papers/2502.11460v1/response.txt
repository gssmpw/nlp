\section{Related Work}
\begin{figure*}[h]
    \centering
    \includegraphics[width = 1\linewidth]{UnitCoder_V3.png}
    \caption{\textbf{The UnitCoder pipeline.} The pipeline consists of three main stages: (1) Data Preparation - filter package-centric data from raw code corpus and fine-tune a unit test generator to produce corresponding tests; (2) Fix and Refine Flow - execute function-test pairs in sandbox, iteratively fix failed cases via bug-fix agent, and refine successful code through refine agent; (3) Post-Train - construct prefix-completion pairs for post-training.}
    \label{fig:overall_framework}
\end{figure*}

\paragraph{Code LLMs}

% Code LLM developments contain two lines of work, large-scale pre-training, and prompt-based code instruct-tuning.
% Early work for code pre-training, exemplified by CodeX **Devlin et al., "CodeBERT"**, CodeGen **Akhawle et al., "CodeGen"**, StarCoder**Rajani et al., "StarCoder"** and CodeLlama **Zhang et al., "CodeLlama"** introduces Code-based pre-trained models which developed from previous trends of BERT **Devlin et al., "BERT"** to CodeBERT pre-training **Kumar et al., "CodeBERT"**.
% Later, open-sourcing series such as Qwen**Lin et al., "Qwen"** and Deepseek**Zhang et al., "Deepseek"** built code models, Qwen2.5 Coder**Lin et al., "Qwen-Coder"**, and Deepseek-Coder-V2 accordingly based on their open-sourced base models by collecting and filtering large-scale code data that exceeds 5 trillion tokens.
% Further, using LLMs to help filter code data is a more costly but effective method of preparing code data.
% WaveCoder **Xu et al., "WaveCoder"** introduces GPT-4 as a discriminator to obtain high-quality data.
% Prompt-based code instruct-tuning methods exemplified by WizardCoder**Hou et al., "WizardCoder"** focus on improving code instructions with LLMs**Brown et al., "LLaMA"**. 
Code LLM developments have progressed along two main directions: large-scale pre-training and specialized instruct-tuning.
Early works of code pre-training models include pioneering works like CodeX **Devlin et al., "CodeBERT"**, CodeGen **Akhawle et al., "CodeGen"**, StarCoder**Rajani et al., "StarCoder"** and CodeLlama **Zhang et al., "CodeLlama"**.
% built upon the foundation laid by BERT **Devlin et al., "BERT"** and CodeBERT **Kumar et al., "CodeBERT"**.
Open-sourcing series such as Qwen**Lin et al., "Qwen"** and Deepseek**Zhang et al., "Deepseek"** build specialized code models as well, examplified by Qwen-Coder and Deepseek-Coder**Zhang et al., "Deepseek-Coder-V2"**. 
% based on their open-sourced base models by collecting and filtering large-scale code data with trillions of tokens.

Furthermore, leveraging language models for code data filtering provides a valuable quality supervision signal in data preparation. For example, WaveCoder **Xu et al., "WaveCoder"** employs GPT-4 as a discriminator, while similar work such as Arctic-SnowCoder**Kim et al., "Arctic-SnowCoder"** explores the potential of BERT-based models for code data filtering.

In parallel, 
% prompt-based code instruct-tuning approaches,
works represented by WizardCoder**Hou et al., "WizardCoder"** focus on enhancing instruction diversity through improved instruction engineering with powerful LLMs**Brown et al., "LLaMA"**.  
Additionally, research exemplified by AgentCoder**Xu et al., "AgentCoder"** investigates prompt-based approaches that integrate test cases and multi-agent collaboration to improve coding performance**Srivastava et al., "CodeGenie"**.


% While impressive, these methods primarily focus on improving model performance on specific benchmarks through prompt engineering, with limited exploration of scalable, high-quality code synthesis. Our method offers a more practical solution by leveraging existing pre-training corpora and mainstream open-source models for large-scale code synthesis.

\paragraph{LLM-Driven Unit Test Generation}

Software engineering is a major topic in coding and programming, with LLM-based unit test generation emerging as a promising direction. Large language models have demonstrated remarkable capabilities in this area, as exemplified by TestPilot**Kumar et al., "TestPilot"**, which introduces a comprehensive framework for automated test generation using LLMs.
Several other works further validate LLMs' effectiveness in generating high-quality test cases**Rajani et al., "StarCoder"**.
% including ChatUniTest**Akhawle et al., "CodeGen"** and ChatTester**Zhang et al., "CodeLlama"**,
Building upon these foundations, subsequent works continue to explore LLM-based unit test generation. Several works focus on improving metrics like coverage and accuracy**Hou et al., "WizardCoder"**. 
% Meanwhile, works have demonstrated the versatility of LLM-based testing across various domains, from industrial-scale test automation to specific tasks like security vulnerability detection**Srivastava et al., "CodeGenie"**.
These works collectively demonstrate the potential of LLMs in advancing automated unit test generation practices.