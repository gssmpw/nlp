\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figures//causal_tracing/subject_causal_tracing.png}
    \caption{The impact of attention and MLPs' activations on LMs' predictions when intervening on the subject tokens across three answer steps macro-averaged across all models and datasets. Attention contributions dominate in the middle layers at the last token, while MLPs are important in early layers at the subject token and in late layers at the last token. The probability differences all peak around or above $0.55$, reflecting the importance of the subject tokens. 
    }
    \label{fig:subject_causal_tracing}
\end{figure*}
\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figures//causal_tracing/prev_ans_causal_tracing.png}
    \caption{The impact of attention and MLPs' activations on LMs' predictions when intervening on previous answer tokens at step $2$ and $3$ macro-averaged across all models and datasets. Attention is important in both the middle and the last layers at the last token position. MLPs' contributions are critical in early layers at the previous answer positions and in final layers at the last token. The probability differences all peak around or above $0.54$, indicating previous answer tokens are critical to models' predictions.}
    \label{fig:prev_ans_causal_tracing}
\end{figure*}














