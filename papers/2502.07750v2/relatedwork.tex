\section{Related Work}
%The exploration of distributed learning and detection encompasses a broad spectrum of applications within signal processing and machine learning. The objective in distributed learning is to construct predictive models from historical data \cite{verbraeken2020survey,mcmahan2017communication,lian2017can,assran2019stochastic,liu2019communication,li2020federated}. Conversely, distributed detection and decision-making seek to amalgamate data from diverse sources to facilitate informed decision-making \cite{varshney2012distributed,veeravalli2012distributed,kailkhura2015distributed,verbraeken2020survey}. 


%In the context of deep learning, we consider a dataset \(D\) comprising \(n\) data points \(X = (X_1, ..., X_n)^T\), with each \(X_i\) being a vector in \(\mathbb{R}^d\), and associated outputs \(y = (y_1, ..., y_n)^T\). The task involves solving an optimization problem:

%\begin{equation}
%    \min_{\beta} f(\beta; y, X) = l(\beta; y, X) + r(\beta; \lambda)
%\end{equation}
%
%where \(f\) symbolizes the system model, incorporating a loss function \(l(\beta; y, X)\) and a regularization term \(r(\beta; \lambda)\), with \(\beta\) as the model parameters.


% The persistent and critical challenge in distributed learning is heterogeneity that can significantly degrade both
% model accuracy and convergence performance. Several forms of heterogeneity have been identified in
% the literature: task heterogeneity, network heterogeneity, resource heterogeneity, and data heterogeneity. In this paper, we mainly focus on data heterogeneity, which is arguably the most pervasive and,
% in many cases, the most detrimental to learning performance. It occurs when the data distributions across nodes differ. It includes
% cases where either the marginal distribution or the conditional distribution vary between nodes.
% Such variations complicate model aggregation since local models, trained on data with different
% distributions, optimize for different objectives.

%The persistent and critical challenge in distributed learning is heterogeneity, which can significantly reduce both model accuracy and convergence performance. The literature identifies several forms of heterogeneity, including task, network, resource, and data heterogeneity. This paper primarily focuses on data heterogeneity, arguably the most pervasive and detrimental to learning performance. Data heterogeneity occurs when the data distributions across nodes differ, encompassing cases where either the marginal or conditional distributions vary between nodes. These variations complicate model aggregation, as local models trained on data with different distributions optimize for different objectives. Therefore, Personalized Federated Learning (PFL) has been proposed as a method to address data heterogeneity, aimed at accommodating the distinct data distributions at each node. This approach allows each client to utilize unique model parameters, enabling better prediction outcomes tailored to their specific data distributions. Also in DPFL, clients connect only with their neighbors through peer-to-peer communication, aiming to create the most effective personalized models for each client to solve the heterogeneity problems. 
% Due to the
% computation and communication resources limitation
% among clients, Decentralized Personalized Federated Learning (DPFL) has been an encouraging field in recent
% years, where clients only connect with their
% neighbors through peer-to-peer communication and aims
% to produce the greatest personalized models for each client. FedPer, FedRep, and FedBABU each employ a single global feature representation paired with multiple local classifiers. They differ in how they configure the relationship between the shared representation and the individual linear components. Fed-RoD concurrently trains a comprehensive global model and numerous private classifiers, utilizing both class-balanced and empirical loss functions. Theoretically, FedSim and FedAlt offer convergence analysis for both algorithms under general non-convex conditions. Meanwhile, FedAvg-P and Scaffold-P  build upon and enhance the findings presented in FedAlt. DFedAvgM utilizes multiple local iterations with SGD and quantization techniques to minimize communication costs. Dis-PFL tailors personalized models and pruned masks for each client to accelerate personalized convergence. KD-PDFL employs knowledge distillation to enable devices to recognize statistical differences between local models. ARDM establishes lower bounds for communication and local computation costs in a peer-to-peer personalized federated learning (FL) setting. DfedPGP and AsyNG implement the push-sum method to expedite training convergence.
% Almost all DPFL methodologies are vulnerable to deadlock caused by unstable communication channels and the degraded quality due to disparate levels of convergence during aggregations. To tackle these issues, we propose a partial-freeze framework based on selective communication for DPFL. This strategy deviates from traditional directed DFL methods such as Dis-PFL and AsyNG, which generally involve exchanging all parameters for a single consensus model or selecting communication targets randomly. Our approach incorporates score-based neighbor selection, multi-step local iterations, and alternating optimization to improve convergence. This method ensures unbiased gradient estimation, enhances personalization, and optimizes communication efficiency. Consequently, both the algorithmic design and the theoretical analysis of our framework are innovative and demonstrate excellent performance.
%DPFL methodologies often struggle with slow convergence rates during aggregations and are vulnerable to deadlock due to unstable communication channels. To tackle these issues, we propose a partial freeze training framework based on selective communication for DPFL. This strategy deviates from traditional directed DFL methods such as Dis-PFL and AsyNG, which generally involve exchanging all parameters for a single consensus model or selecting communication targets randomly. Instead, our approach incorporates score-based neighbor selection, partial freeze training, and alternating optimization to accelerate the convergence of the model. This method ensures model robustness, enhances personalization, and optimizes communication efficiency. Consequently, both the algorithmic design and theoretical analysis of the framework are innovative and demonstrate superior performance.

% There are three primary categories we can use to address the challenges posed by heterogeneity in DPFL. The first
% category involves operations on the data. These methods are designed to smooth out the statistical
% heterogeneity of local data across clients. For example, data augmentation or resampling techniques can
% be applied to ensure that the local data distribution better represents the overall population. This helps to
% reduce discrepancies between clients. Next, we have operations on the model. These focus on improving
% model optimization, by either designing new model architectures that are more robust to the heterogeneity
% across clients or by optimizing the learning process to account for these variations. For example, adaptive
% learning rates can help models converge more effectively across diverse client environments. Finally, It is
% the operations on the server. This can include strategies such as selecting which clients will participate
% in each round of training, or grouping clients with similar data distributions into clusters to make the
% aggregation process more effective. By strategically managing which clients contribute to the global model
% and how their contributions are aggregated, we can improve the overall quality and fairness of the model.
% Each of these methods plays an important role in tackling heterogeneity and ensuring that the federated
% learning process remains efficient and effective. Next, we will explore more on each method.