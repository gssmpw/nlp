\section{Related Work}

\subsection{Knowledge Co-Construction in Online Science Videos}
Scientific understanding plays a crucial role in our daily lives, prompting many individuals to seek information online \cite{tabak2015functional, segev2012seeking, brossard2013new, dubovi2020empirical}. With the rise of video-sharing platforms, videos have emerged as a widely used medium for science communication \cite{morcillo2015typologies, welbourne2016science}. Unlike traditional texts or static images, videos offer a dynamic way to present scientific knowledge, utilizing visual aids and narrative techniques to simplify complex concepts for general audiences while maintaining scientific integrity \cite{trumbo1999visual, nicholson2005representing}. This approach not only captures public attention but also enhances the accessibility of science \cite{zhang2023understanding}.

A notable feature of video-sharing platforms is the interactive environment they foster, allowing viewers to post comments on video content. The commentary feature extends beyond passive consumption, enabling viewers to participate actively in science communication by sharing their insights and engaging in discussions with both the creator and other viewers \cite{he2021beyond, wu2018danmaku, lange2007publicly, dubovi2020empirical}. Such information exchange often leads to knowledge co-construction, where individuals not only share perspectives but also collaboratively refine and expand on each other's ideas, thereby enhancing the collective understanding \cite{he2021beyond, dubovi2020empirical, scardamalia2002collective}. This co-constructed knowledge becomes a valuable resource for both viewers, who gain additional video-related information \cite{choi2020finding}, and creators, who receive timely feedback \cite{wu2018danmaku}. The importance of such co-constructed knowledge is particularly pronounced in science videos, where the accuracy of information is paramount \cite{stadtler2007dealing, dubovi2020empirical}, and the risk of misinformation is significant \cite{rosenthal2020media}. Therefore, our work focused on collective knowledge arising from online science videos.

% \xm{shall we mention CK for genres beyond science videos, e.g., how-to videos?}

\subsection{Danmaku for Knowledge Co-Construction}
Danmaku, a commentary system originating from Japan, has gained widespread popularity on Asian video platforms, particularly on Bilibili, a popular danmaku platform in China \cite{bilibili_about_us}. By the first quarter of 2024, Bilibili had amassed 341 million monthly active users \cite{bilibili2024investor} and ranked third globally among the most visited Arts and Entertainment websites \cite{similarweb_top}, behind YouTube \cite{youtube} and Netflix \cite{netflix}. 
In June 2020, Bilibili introduced the "Knowledge Zone" channel to curate science knowledge content. The channel experienced a 92\% increase in creators within a year \cite{bilibili2021report}. By 2024, it has accumulated over 8.5 million science-related videos \cite{bilibili2023esg}.

Unlike traditional comments displayed asynchronously below the video, danmaku comments are displayed directly on the video, scrolling horizontally across the screen. These comments are synchronized with specific video scenes, creating a co-viewing experience where users can send and view comments anonymously and simultaneously while watching the video \cite{chen2017watching, chen2024towards}. 
% \xm{[Again, highlight here that how danmaku contributes new knowledge beyond video captions, subtitles, and traditional comments (R1)]}

Research suggests that danmaku serves as a powerful medium for knowledge dissemination \cite{ma2014analysis}. 
Wu et al. highlighted that compared to traditional forum-style comments, danmaku excels in disseminating explicit knowledge \cite{wu2018danmaku, wu2019danmaku}.
Moreover, while traditional comments tend to initiate general discussions of overarching video topics, danmaku addresses specific video details, offering timely supplementation and corrections that facilitate more fine-grained knowledge co-construction \cite{he2021beyond, wu2018danmaku, chen2017watching}.
On the one hand, danmaku can respond to specific video scenes by providing immediate explanations (e.g., defining terms \cite{li2015can} or crowdsourcing captions \cite{ma2014analysis}), thus expanding the scope of knowledge presented. On the other hand, danmaku allows users to engage in discussions that correct or enhance previous comments, which deepens the knowledge shared \cite{he2021beyond}. Even in cases of disagreement, the range of perspectives available through danmaku contributes to a richer understanding of the content \cite{wu2018danmaku, wu2019danmaku}. Such a dynamic, collective knowledge system is often more comprehensive and resilient than traditional videos, where the creator is the sole source of information \cite{yao2017understanding}.
However, collective knowledge patterns in science videos, a knowledge-intensive genre, remain underexplored.
% Taking inspiration from these previous works, our study is located within the context of science videos, a knowledge-intensive genre. 
Through content analysis, we investigated how danmaku contributed to knowledge co-creation with science videos and explored its potential as a valuable source of collective knowledge in science communication.

\subsection{Technologies for Processing Danmaku and Facilitating UGC Assimilation}
Danmaku has garnered increasing attention from video researchers in the HCI and CSCW communities \cite{ma2017video, wu2018danmaku, he2021beyond, wu2019danmaku}. Several tools have been developed to leverage the pseudo-synchronous nature of danmaku for various purposes. Sun \textit{et al.} introduced VideoForest \cite{sun2016videoforest}, a system that utilizes danmaku data to summarize video streams and identify key frames aligned with user comments. Similarly, Cao \textit{et al.} developed VisDmk \cite{cao2023visdmk}, an interactive visual analysis tool designed to explore emotional trends and characteristics of danmaku comments as a video unfolds. This system helps users gain an overview of the video, evaluate its impact, and expedite the video editing process. To assist video creators in understanding viewer engagement, Chen \textit{et al.} built DanmuVis \cite{chen2022danmuvis}, which analyzes danmaku content and viewer behaviors over time, providing insights into online participation and perceived user experience.
Although these studies offer insights into the dynamics of danmaku, their primary focus remains on enhancing video analysis. In contrast, our work shifted the emphasis toward the intrinsic knowledge value of danmaku itself, developing an NLP pipeline and an interactive interface to maximize its potential for knowledge co-creation.

% In general, online User-generated content (UGC) serves as a valuable resource for individuals seeking to learn from others, which makes the effective digestion of UGC a prominent research topic. While there is limited research on how to help viewers effectively assimilate collective knowledge from online science videos, insights can be drawn from existing works on UGC digestion, particularly given that danmaku is a form of UGC. 
While there is limited research to support the assimilation of collective knowledge in science videos, insights can be drawn from existing works on user-generated content (UGC) digestion, particularly given that danmaku is a form of UGC. 
In general, UGC serves as a valuable resource for individuals seeking to learn from others, which makes the effective consumption of UGC a prominent research topic. 
One major approach to supporting UGC digestion involves providing text summarization \cite{dave2004flash, hoque2015convisit}. For instance, CoArgure offers a holistic view of collective arguments \cite{liu2023coargue} through claim centers, facilitating the processing of content from community question-answering (CQA) platforms. Due to the unstructured nature of UGC, presenting it in a more organized manner can reduce cognitive load and aid comprehension \cite{liu2022planhelper}. Kitayama \textit{et al.} proposed a video-sharing system that organizes comments by their corresponding video time intervals and screen areas \cite{kitayama2008organizing}, which improves usersâ€™ understanding of video comments. Similarly, Liu \textit{et al.} designed PlanHelper to organize CQA answers \cite{liu2022planhelper} into a list and a mindmap, helping users construct activity plans more efficiently.
% \xm{unique challenges of danmaku compared to other kinds of UGC?}
However, compared to other forms of UGC, danmaku poses unique challenges due to its uneven quality, transient display, and random appearance across the screen, making it harder for users to absorb the embedded knowledge \cite{ma2017video, yao2017understanding}.
% To further investigate these challenges, we conducted a formative study with consumers of online science videos featuring danmaku. Based on our findings and insights from previous works, we derived the design pipeline for developing CoKnowledge.




