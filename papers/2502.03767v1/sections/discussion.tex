\section{Discussion}

Previous studies have explored and validated the role of danmaku in constructing collective knowledge \cite{he2021beyond, wu2018danmaku, wu2019danmaku}. 
In this section, we first discuss why our proposed system can improve the utility of danmaku in the digestion of collective knowledge as informed by existing theories. Then, we summarize several design considerations to guide future support for assimilating knowledge co-constructed by media producers and consumers.

% \subsection{The Role of Danmaku \xm{Time-Synced Comments} in Collective Knowledge Assimilation}
\subsection{Strengthening the Role of Time-Synced Comments in Collective Knowledge Assimilation}

% Building on this foundation, our study, informed by existing theories, highlights the significant potential of danmaku to enhance the recall and comprehension of knowledge expressed in both videos and comments \xm{correct?}.

% In our experiment, participants demonstrated improvements in recalling danmaku and video content within the same task duration, which we attribute largely to danmaku itself. 
In our experiment, participants demonstrated improvements in recalling danmaku and video content within the same task duration using our system.
The widely accepted Associative Network Theory (ANT) of memory suggests that human memory functions as a network of bidirectionally linked nodes, where the activation of one node can trigger the retrieval of information in a linked node \cite{collins1975spreading, wheeler2017using, teichert2010exploring, lee2016memory}. The strength of the association between nodes increases the likelihood of successful retrieval \cite{teichert2010exploring}. 
According to this theory, the spatial (overlay on the video) and temporal (synchronized with timestamps) proximity of danmaku and video content turn them into activation nodes for each other. KG provided by CoKnowledge further reinforces these connections. Many participants previously struggled to focus on danmaku, but with CoKnowledge, they could pay closer attention to it, enabling frequent bidirectional activation during the recall phase, even unconsciously \cite{teichert2010exploring}. This helped them recollect video content through linked comments in KG and vice versa. 
P12 and P15, for instance, shared cases where they recalled danmaku first and subsequently retrieved the corresponding video content in the interviews. 
% Given that activation can occur unconsciously \cite{teichert2010exploring}, we hypothesize that most participants subconsciously leverage this bidirectional activation process during recall.

Participants also exhibited significantly better comprehension of collective knowledge with the help of CoKnowledge. 
% , with danmaku playing a crucial role in this process. 
Proficient comprehenders typically excel at processing complex information, identifying key points, and integrating textual structures \cite{mcnamara2009toward, long1993superordinate, singer1992individual}. They are also more adept at making inferences to bridge conceptual gaps and integrating new information with prior knowledge \cite{garnham1982referential, magliano2002using, mcnamara2009toward}. 
% We found that various categories of knowledge danmaku can serve as these comprehension skills. 
We found that \textit{knowledge danmaku} can approximate such comprehension skills, and categorizing them in our system streamlines the process of exercising these skills. 
For instance, \textit{interpretation} danmaku provides concise explanations and summaries of difficult content (PF1, P2, P6).
% , with an example mentioned by P2 shown in Figure \ref{fig:example}). 
\textit{Experience-sharing} danmaku connects scientific concepts to everyday life (PF5). Additionally, \textit{supplementary knowledge} danmaku helps fill knowledge gaps (PF1-4, P2, P8, P10). 
Filtering danmaku comments by category allows users to make up for the skill(s) they lack, significantly increasing the accessibility of scientific content.
% These danmaku comments allow individuals to become skilled comprehenders without barriers, significantly increasing the accessibility of scientific content.

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.7\linewidth]{images/example.jpg}
%   \caption{The video clip is explaining the Pauli Exclusion Principle in a rigorous manner, while the highlighted danmaku comment, "In simple terms, neutrons have collision volume, photons don't," offers a more relatable interpretation of the concept.}\label{fig:example}
% \end{figure}

Despite some participants (7/24) mentioning in interviews that they were not accustomed to acquiring knowledge through danmaku, both subjective feedback and objective performance measures indicated notable knowledge gains in the CoKnowledge condition. We argue that participants' discomfort arose from the chaotic presentation of danmaku, which led them to overlook its knowledge-enhancing capabilities. 
We postulate that structural improvements in the presentation and organization of danmaku can practically enhance the exploration of danmaku's knowledge potential.
% Therefore, we advocate for further exploration and utilization of danmaku's knowledge potential.


\subsection{Design Considerations}
% In this subsection, we present several design considerations derived from our analysis to guide future efforts in supporting the assimilation of collective knowledge.
% \xm{Here, you can discuss the generalizability of your findings -- How other types of live comments \xm{e.g., scrolling list in Twitch??} may achieve similar knowledge co-creation between video creators (or live streamers) and viewers \xm{[ref]}. You can then say the below DCs are applicable to general xxx.}
Various forms of live comments can facilitate knowledge co-creation akin to danmaku. For instance, in knowledge-sharing live streams (KSLS), streamers generate real-time content while concurrent viewers actively contribute comments displayed in scrolling lists, dynamically shaping the information flow \cite{lu2018streamwiki, fonseca2021knowledge}. The design considerations generated from the study results, as outlined below, apply to general video communication formats featuring live comments.



\subsubsection{User-Centric Enhancements for AI-Assisted Information Processing}

With the growing volume of UGC online, AI is increasingly used to enhance the efficiency of processing large-scale knowledge \cite{liu2023coargue}. CoKnowledge also relies heavily on AI to process danmaku. However, AI's performance is not flawless; we observed various kinds of errors during our user study. During interviews, some participants reported instances where danmaku were misclassified, leading to confusion (P2) and obstructing comprehension of both the comments and the video content (P12, P17). Additionally, a few participants (P2, P13) noted instances of hallucination in AI-assisted explanations.
% \xm{how about examples of hallucination?} 
To address these issues beyond improving models in the backend, we recommend calibrating user trust and empowering users to co-process information with AI during their interaction with the system. Designers can enhance transparency by visualizing AI uncertainty upon user request \cite{bhatt2021uncertainty} 
% \xm{note that such additional info may increase people's cognitive load.. maybe only display such info when the confidence is below a certain threshold... or when users demand to see them e.g., by hovering over or clicking} 
and help users build a more accurate mental model of the system \cite{gero2020mental}. For example, explaining how the algorithms work \cite{schmidt2020transparency} and highlighting potential limitations \cite{cheng2019explaining} in the system's help information
% \xm{in the system help info? Perhaps not on the main UI...} 
would enable users to leverage the system's knowledge while maintaining critical awareness. Additionally, allowing users to edit AI outputs actively would deepen their understanding of the content through error correction (P3), which, at the same time, can be integrated into knowledge co-construction.
% \xm{correct? any user demanding this feature?}.


\subsubsection{Accommodating Various Strategies While Empowering Users with Full Autonomy}
\label{sec:7.2.2}
McNamara et al. suggested that optimal learning outcomes were achieved with easy information processing and appropriate strategies \cite{mcnamara2009toward}. However, users vary in processing speed, information preferences, and attention allocation, making it difficult to design a "one-size-fits-all" solution. The exceptional performance of CoKnowledge stems not only from reducing the complexity of processing danmaku but also from providing diverse features that accommodate various user strategies. In our experiment, CoKnowledge provided participants with high autonomy, such as the flexibility to switch modes at their own pace and choose whether and how to use specific features. 
Still, our participants demanded more agency. In our current design, CoKnowledge automatically adjusts the ratio between the upper video window and the lower view to
ensure that the part people tend to focus on in the present mode receives more information display space. 
However, a few participants (P11, P22) preferred manual window/view size adjustment to fit their reading needs (discussed in section \ref{sec:use-parttern}). 
% xm{correct? reference the corresponding result section}. 
We thus recommend that knowledge-support tools incorporate a range of adaptable features to address diverse user needs while granting complete control over the strategies users find most comfortable.
% However, one instance where user autonomy was limited—automatic video window resizing when switching modes—drew criticism from a few participants (P11, P22), who preferred manual adjustments. 
% Thus, we recommend that knowledge-support tools incorporate a range of features to address diverse user needs while granting full control over the strategies users find most comfortable.

\subsubsection{Tailoring Feature Designs for Different Knowledge Domains}

The difference between the two video domains in our experiment revealed distinct patterns in how participants utilized the features.
% in face of \xm{xxx knowledge to master}. 
We observed that the AI-assisted explanation feature was rarely used during the health video (0.92 times per person) but was employed more frequently during the astronomy video (5.79 times per person).
% \xm{If you have reported the numbers in the result section, reference; if not, put the numbers here..}. 
This discrepancy can be attributed to the lower complexity of the health video’s danmaku. In contrast, the astronomy video had significantly more \textit{concept-noting} comments, which often triggered the need for additional explanation. Moreover, participants reported using the KG more frequently for the astronomy videos due to their greater content complexity compared to the health video. This trend of feature usage, driven by the nature of the knowledge content, exhibited a predictable and collective pattern. Therefore, instead of building systems that accommodate all knowledge features equally, designers may adopt data structures and representations that best suit a given knowledge domain and prioritize relevant features accordingly. This allows users to efficiently engage with features that maximize the absorption of the specific knowledge source while reducing the learning curve and potential distractions. In resource-constrained scenarios, this approach ensures the most efficient allocation of resources to support knowledge acquisition.


\subsubsection{Navigating the Tension between Information Processing and Natural Co-Viewing Experience}
Evaluation results indicate that CoKnowledge outperformed the baseline in fostering a \textit{"sense of co-presence"} (section \ref{sec:danmaku-util}), primarily through its theme classification and stance analysis. These features allowed users to identify shared perspectives, reinforcing a \textit{"sense of identification"} (P4-6, P12, P24), while also clearly discerning the interplay of contrasting viewpoints, thereby enhancing their \textit{"sense of interaction"} (P4) by simulating dynamic deliberation. However, participants expressed concerns that CoKnowledge's information processing disrupted the \textit{"natural co-viewing experience"} (P20, P23). While the overwhelming volume of danmaku challenges knowledge absorption, it fosters a vibrant atmosphere by conveying the presence of individual co-viewers behind each comment \cite{chen2017watching, liu2016watching}. Casual and colloquial expressions in danmaku, in particular, are a key reason users enable it (PF1, PF5-7, P12, P15). However, CoKnowledge’s knowledge-driven processing pipeline removed much of this entertaining and emotionally resonant content, resulting in a more sterile presentation that diminished participants’ emotional connection to other posters (P20, P23). 
To address this tension, designers should adopt context-sensitive approaches when managing UGC. For users primarily seeking entertainment, retaining unfiltered, original live comments may be preferable. For knowledge-oriented users, CoKnowledge’s processing pipeline is more appropriate. For users with mixed motivations, a hybrid approach may be ideal. For instance, designers could present processed, knowledge-focused content during knowledge-intensive video segments to aid comprehension, while retaining unfiltered comments during less knowledge-intensive segments to preserve the natural co-viewing experience. Alternatively, designers could introduce entertainment-oriented danmaku categories, offering users the option to enable or disable them.

% Participants expressed concerns that CoKnowledge's information processing methods disrupted the natural co-viewing experience (see section \ref{sec:danmaku-util}). While the abundance of danmaku poses many challenges, particularly regarding knowledge absorption, it indeed fosters a vibrant and engaging atmosphere. Emotional and humorous exchanges embedded in danmaku is a key reason many users enable it (PF1, PF5-7, P12, P15). However, CoKnowledge’s knowledge-driven processing pipeline removed much of this entertaining and emotionally resonant content, resulting in a more sterile presentation that diminished participants’ emotional connection to other posters (P20, P23).
% Despite this limitation, CoKnowledge effectively preserved emotional attitudes within danmaku comments through stance analysis, allowing users to clearly perceive contrasting opinions and dynamic interplay of perspectives. This significantly contributed to the superior performance of CoKnowledge in fostering a \textit{"sense of co-presence"}.
% To address such tensions, designers should adopt context-sensitive approaches when managing UGC. If users primarily seek entertainment, it is essential to preserve or enhance emotional and entertaining elements. Additionally, offering multiple modes of information presentation can cater to diverse user needs, allowing users to select modes aligned with their immediate goals—whether for enjoyment or knowledge absorption—and their viewing contexts.

\subsubsection{Alleviating Information Overload}
% Information overload is a prevalent issue that hampers users' ability to effectively engage with danmaku, often prompting some to disable it entirely \cite{ma2017video, wu2019danmaku, wu2018danmaku}.  CoKnowledge effectively alleviated this problem by employing an NLP pipeline to condense danmaku
% and introducing \textit{Focused Mode} that minimized extraneous information. These features allowed users to simultaneously engage with video content and curated high-quality danmaku, facilitating knowledge absorption from both sources (P14, P15, P19).
Information overload hinders users from effectively engaging with danmaku, often prompting some to disable it entirely \cite{ma2017video, wu2019danmaku, wu2018danmaku}. CoKnowledge alleviated this problem by employing an NLP pipeline to condense large volumes of danmaku and enabling users to filter it based on preferences, allowing participants to simultaneously comprehend video content and curated, high-quality danmaku (P14, P15, P19). Additionally, informed by users' viewing habits (Table \ref{formative-study-findings}), it introduced adaptive modes that support manual switching. When users focused on the video itself, focused mode minimized distractions by withholding additional information. Conversely, when users were willing and able to process supplementary information, overview mode and exploration mode provided diverse features, ensuring danmaku remains accessible even when disabled.
Despite these efforts, survey results (section \ref{sec:usability}) showed no significant reduction in task load compared to the baseline. Interviews revealed that participants often felt compelled to engage with features such as Wordstream and KG, even when unnecessary (P2-4, P10, P12-16). These features introduced additional information across different views (P16, P22, P23), thereby increasing cognitive demands for learning to use the system.
This underscores another critical trade-off between information richness and overload. Designers should prioritize maintaining information volume within users' cognitive processing capacities, then selectively implementing features to address user needs without exacerbating task load.

% However, survey results showed no significant reduction in task load compared to the baseline. This can be attributed to CoKnowledge’s additional features designed to support diverse viewing strategies and needs. While these features improved knowledge absorption outcomes (as discussed in section \ref{sec:7.2.2}) and allowed users to process danmaku even when disabled, they inadvertently increased cognitive demands (P16, P22, P23).
% This underscores another critical tension between feature complexity and information overload. Designers should prioritize maintaining information volume within users' cognitive processing capacities. Within this constraint, features should be selectively implemented to address user needs without exacerbating task load.


\subsection{Scalability and Generalizability}
% \xm{[According to 2AC comment 1, first clarify which "results speak only to danmaku systems designed like CoKnowledge" and which parts can be extended]}


% \subsubsection{Applicability and Scalability}
CoKnowledge’s automated pipeline ensures applicability for processing videos of varying durations and danmaku volumes. For newly uploaded videos with insufficient danmaku, CoKnowledge retains its utility by offering progress bar directory (Figure \ref{fig:overview}) and oval nodes in the KG (Figure \ref{fig:exploration}) to organize video knowledge. For highly popular and long-standing videos, the system’s most time-consuming step involves processing substantial pre-existing information, which only requires a one-time effort. This limitation is planned for future optimization. Despite this, CoKnowledge effectively handles the continuous stream of new danmaku these videos attract, leveraging the fine-tuned LLM-based classifier to process them incrementally. Rather than reanalyzing the entire dataset, the system only evaluates the incoming comments to determine whether they qualifies as \textit{knowledge danmaku} and assign them to specific themes. This approach minimizes computational overhead and greatly enhances scalability. Future work could further reduce inference costs by exploring \textit{Programmatic Weak Supervision} (PWS) framework, which has proven effective in domain-specific tasks with limited labeled data \cite{li2024labelaid}.



% \subsubsection{Generalizability beyond Danmaku}
% \label{sec:7.2.1}
Although primarily designed for danmaku-based video platforms, CoKnowledge’s approaches to processing and presenting knowledge are potentially generalizable to platforms featuring traditional comments, such as YouTube \cite{youtube}. These platforms also face challenges from the large volume and unstructured nature of user-generated comments, which can overwhelm users and hamper effective knowledge absorption \cite{liu2022planhelper, liu2023coargue}. CoKnowledge’s processing pipeline—integrating filtering, classification, mapping, and clustering techniques—is well-suited to address these issues by extracting and structuring knowledge from extensive collections of comments.
While CoKnowledge is less tailored to traditional comments addressing overarching video topics, it can effectively present knowledge-related comments targeting specific video scenes. By anchoring these comments to corresponding timestamps through automated alignment methods (e.g., topic modeling, semantic matching) or video referencing interfaces \cite{yarmand2019can, kitayama2008organizing}, designers can seamlessly integrate them into CoKnowledge’s framework, enhancing its adaptability across diverse platforms.
% For general comments spanning \xm{[addressing the overall topic of the video?]} the entire video, KG remains an adapative choice \xm{[what do you mean?]}. While these comments lack the precise time-stamped anchoring feature of danmaku, they relate to the entire video in a manner akin to how danmaku correspond to the anchored video segments \xm{[??? not very clear... what are the nodes and edges in KG in this case?]}. Given KG's exceptional ability to synthesize collective knowledge in exploration mode, it is also a compelling choice for visualizing the knowledge derived from traditional comments and video content.
% Additionally, the threaded structure of such comments, which enables direct replies, offers an advantage over the scattered and transient nature of danmaku. This structure enhances the clarity of comment-based knowledge organization, allowing KG to provide a more coherent and accessible representation of collective knowledge \xm{[Again, what are the nodes and edges? Automatic extraction of entities and opinions?]}.
% Additionally, as discussed in section, CoKnowledge is also applicable to traditional comments. Since traditional comments and danmaku offer complementary modes of knowledge sharing \cite{wu2018danmaku, wu2019danmaku}, integrating these two modalities could provide a more comprehensive and robust depiction of collective knowledge.
% In conclusion, although traditional comments differ in format from danmaku, the foundational principles of CoKnowledge’s design remain compatible with platforms featuring traditional comment systems.}
% A key feature of CoKnowledge, KG in exploration mode, can effectively present the collective knowledge of traditional comments and video content. While traditional comments lack the precise time-stamped anchoring feature of danmaku, they relate to the entire video in a manner akin to how danmaku correspond to the anchored video segments. Given KG's exceptional ability to synthesize collective knowledge in exploration mode, it is also a compelling choice for visualizing the knowledge derived from traditional comments and video content.
% Additionally, the threaded structure of traditional comments, which enables direct replies, offers an advantage over the scattered and transient nature of danmaku. This structure enhances the clarity of comment-based knowledge organization, allowing KG to provide a more coherent and accessible representation of collective knowledge.
% In conclusion, although traditional comments differ in format from danmaku, the foundational principles of CoKnowledge’s design remain compatible with platforms featuring traditional comment systems.


% Our study demonstrates the exceptional performance of CoKnowledge in processing videos with substantial information loads (exceeding ten minutes in length and containing over 2,000 danmaku comments). Moreover, such videos are typically highly popular and long-standing, attracting a continuous stream of danmaku. CoKnowledge can also handle such scenario effectively. The fine-tuned LLM-based classifier processes new danmaku incrementally. Rather than reanalyzing the entire dataset, the system only evaluates the incoming comment to determine whether it qualifies as \textit{knowledge danmaku} and assigns it to a specific theme. This targeted approach minimizes computational overhead and greatly enhances the system’s scalability.
% For videos with lower information loads—such as shorter videos or those with sparse danmaku comments—the necessity of CoKnowledge diminishes. In these cases, viewers generally have sufficient cognitive capacity to process danmaku alongside video content. Nevertheless, CoKnowledge retains its value by offering features that allow users to explore and analyze knowledge from alternative perspectives, enhancing their comprehension and engagement.


\subsection{Limitations and Future Work}

This study has several limitations. 
% First, our focus on the Bilibili platform may have introduced platform-specific biases. 
First, our data were obtained from the Bilibili platform, which may have introduced platform-specific biases. 
Second, our participants were predominantly young adults (ages 18-31), potentially skewing the findings. Future studies should include more diverse age groups to enhance the accessibility and inclusiveness of CoKnowledge. 
Third, while CoKnowledge filtered out non-knowledge danmaku to increase information density, some participants (P4, P5, P13) reported that eliminating such entertaining danmaku reduced their engagement with the science videos. Future research could explore how non-knowledge danmaku enhance collective knowledge assimilation without compromising content quality.
Besides addressing these limitations, we aim to examine the generalizability of CoKnowledge and its NLP pipeline to other video genres, such as massive open online courses (MOOCs) in the future (P11). 
% \yh{Besides addressing these limitations, future work could expand the analysis to traditional comments, which serve as a complementary channel to danmaku for knowledge sharing \cite{wu2018danmaku, wu2019danmaku}. Integrating these two modalities has the potential to provide a more comprehensive and robust depiction of collective knowledge.}
Moreover, the crowdsourced nature of danmaku offers a self-regulating mechanism that mitigates the spread of misinformation \cite{he2021beyond}. Our design already distinguishes diverse perspectives within danmaku, highlighting its self-correction capabilities. Future research could further explore the effectiveness and patterns of these corrective processes.
Lastly, we plan to conduct a long-term experiment to assess the system's effectiveness over time and explore user strategies within a single video, across multiple viewings, and among different videos.
