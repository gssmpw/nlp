\section{Introduction}

Online video-sharing platforms, with billions of active users daily \cite{cisco2018cisco}, are playing an increasingly important role in engaging the general public in science communication \cite{morcillo2015typologies,welbourne2016science,xia2022millions}. 
These platforms enable science communicators to capture public attention through cinematic techniques and rich, dynamic, multimodal narratives \cite{zhang2023understanding,huang2020good,morcillo2015typologies}. They encourage viewers to share their thoughts on scientific topics and interact with both the content creator and other audiences through commenting features \cite{zhang2023understanding}.
In particular, danmaku, a distinctive
% novel \xm{emerging? it has been around for a while...} 
commentary system widely adopted in online video platforms like Bilibili \cite{bilibili}, Niconico \cite{niconico}, and Douyin \cite{douyin}
% for online videos \xm{widely used in what platforms?}
, allows anonymous posting \cite{wu2019danmaku} of scene-aligned comments for a fixed display period on the video timeline regardless of the actual post time \cite{ma2017video}. 
% \mm{These platforms enable science communicators to capture public attention through cinematic techniques and rich, dynamic, multimodal narratives. They encourage viewers to share their thoughts on scientific topics and interact with both content creators and other audiences through commenting features, fostering a sense of `collective knowledge'. A notable example is danmaku, a distinctive commentary system widely adopted in online video platforms like Bilibili \cite{bilibili}, Niconico \cite{niconico}, Douyin \cite{douyin}. This system allows anonymous posting of scene-aligned comments for a fixed display period on the video timeline, regardless of the actual post time.}
These comments scroll from right to left across the viewing window (Figure \ref{fig:danmaku}) 
\cite{yao2017understanding,he2021beyond,wu2019danmaku,ma2017video}, creating a sense of synchronous, crowd-generated 
% \xm{correct?} 
textual augmentation to video content, directly influencing how viewers perceive and digest the videos  \cite{he2021beyond}.

%Online videos, consumed by billions of viewers daily \cite{cisco2018cisco}, are playing an increasingly important role in engaging the general public in science communication \cite{morcillo2015typologies,welbourne2016science,xia2022millions}. Unlike other forms of online media, such as blogs \cite{welbourne2016science,kouper2010science}, forums \cite{august2020explain,jones2019r}, and social media platforms such as Twitter (now X) \cite{cote2018scientists,gero2021makes}, videos offer rich, dynamic, and multimodal information simultaneously \cite{zhang2023understanding}. This unique capability allows science communicators to employ cinematic techniques and compelling narratives to create high-quality content on various scientific topics \xm{such as?}, effectively capturing public attention \cite{huang2020good,morcillo2015typologies} \xm{and enhancing knowledge understanding?}. 
%Additionally, video-sharing platforms enable viewers to post comments, facilitating engagement by allowing viewers to share their thoughts and interact with both the content creator and other viewers \cite{zhang2023understanding}. Danmaku, a novel commentary system for online videos, differs from traditional forums where comments are displayed asynchronously below the video. Danmaku comments align with specific scenes chosen by users and scroll from right to left across the video screen \cite{yao2017understanding,he2021beyond,wu2019danmaku,ma2017video}. This system has two distinctive features: anonymous posting \cite{wu2019danmaku} and a fixed display period on the video timeline, regardless of the actual post time \cite{ma2017video}. Such a design enables viewers to contribute synchronously to video content, directly influencing how others perceive the video \cite{he2021beyond}.
\begin{figure*}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{images/danmaku.png}
  \caption{The screenshot shows scrolling danmaku comments overlaid on a video discussing the discovery of the first eukaryotic organism capable of nitrogen fixation. Comments A1 and A2 state the same thing: that rhizobia, not soybeans, fix nitrogen. Comments B and C further explain that rhizobia are bacteria/prokaryotes. These complementary danmaku enhance the breadth and depth of the video knowledge. However, the large volume of danmaku, most of which lack informational content, distracts viewers from the video content and makes it difficult to notice the \textit{knowledge danmaku}.}
  \Description{The screenshot shows scrolling danmaku comments overlaid on a video discussing the discovery of the first eukaryotic organism capable of nitrogen fixation. Comments A1 and A2 state the same thing: that rhizobia, not soybeans, fix nitrogen. Comments B and C further explain that rhizobia are bacteria/prokaryotes. These complementary danmaku enhance the breadth and depth of the video knowledge. However, the large volume of danmaku, most of which lack informational content, distracts viewers from the video content, and makes it difficult to notice the knowledge danmaku.}
  \label{fig:danmaku}
\end{figure*}

Although most prior research on danmaku has focused on its role in engaging and entertaining viewers by reducing the feeling of isolation \cite{liao2023research,chen2015understanding,lin2018exploratory}, it has also proven to be an effective channel for knowledge sharing and information seeking \cite{he2021beyond, li2022classification, ma2017video, huang2020good, chen2017watching}. 
Danmaku fosters a sense of watching or even participating in live discussions around the corresponding video scenes \cite{chen2015understanding,ma2014analysis, huang2024sharing}. 
Compared to traditional comments, which typically offer general and after-the-fact insights, danmaku delivers a comparable volume of knowledge that enriches and extends the video content with greater detail, specificity, and real-time relevance \cite{he2021beyond, wu2018danmaku, wu2019danmaku, chen2017watching}.
Such floating comments can be viewed as a form of knowledge co-creation. This paper defines the aggregation of
% \xm{topic-relevant?} 
topic-relevant information co-contributed by video content and temporally anchored commentary augmentations as \textbf{`time-synced collective knowledge'} (referred to as `collective knowledge' for short). With tight correspondence between danmaku and specific video content \cite{he2021beyond}, such collective knowledge ensures that the information presented in science videos is not solely reliant on the creator, thereby reducing potential biases \cite{he2021beyond,yao2017understanding}.
% \xm{Highlight why collective knowledge is particular valuable for science videos with references, if possible.}
%We define this robust and comprehensive co-constructed knowledge structure as 'time-synced collective knowledge,' which is the aggregation of information co-created by both video content and time-synced augmentations via danmaku. ``''
% \mm{While much of the prior research on danmaku has focused on its role in engaging and entertaining viewers by reducing feelings of isolation, it has also proven to be an effective channel for knowledge sharing and information seeking. Danmaku fosters a sense of participation, allowing viewers to engage in live discussions around the corresponding video scenes. Among the floating comments, those aiming to enrich and extend the video content can be viewed as a form of knowledge co-creation. In this paper, we define the aggregation of topic-relevant information co-contributed by video content and temporally anchored commentary augmentations as “time-synced collective knowledge.” Such collective knowledge ensures that the information presented in science videos is not solely reliant on the creator, thereby reducing potential biases.}

However, viewers of science videos often find it challenging to assimilate such collective knowledge due to the nature of danmaku \cite{chen2015understanding, chen2024towards,ma2017video,yao2017understanding}. The abundance and uneven quality of live comments can interfere with and detract people from the original video content \cite{chen2015understanding,chen2024towards}. Additionally, the high volume of danmaku means that individual pieces may not receive sufficient attention \cite{ma2017video,yao2017understanding}. Therefore, many viewers tend to ignore or turn off danmaku and thus miss out on valuable knowledge scattered around the comments.
%Despite the importance of collective knowledge, we have noticed limited Human-Computer Interaction (HCI) works to support users' assimilation of collective knowledge in online videos. There are existing studies that examine the processing of danmaku in online videos. One example is VideoForest \cite{sun2016videoforest}, which utilizes danmaku data to summarize video streams, aiding in the identification of keyframes associated with danmaku comments. However, in this context, danmaku is considered secondary to the video data and is not recognized as a substantial source of knowledge. Consequently, there is a lack of in-depth analyses of danmaku knowledge. On the other hand, DanmuVis enables the analysis of danmaku content and viewers' behaviors in relation to both video time and post time \cite{chen2022danmuvis}, providing insights into viewers' online participation and perceived experience. Nevertheless, its design primarily caters to video uploaders seeking to understand the dynamics of their videos, rather than supporting viewers in assimilating the knowledge encompassed within the danmaku and video content. 
Some existing studies examined the use of danmaku data to facilitate video content processing, such as identifying key scenes in videos based on danmaku volume and sentiment \cite{sun2016videoforest}, and analyzing viewer behavior \cite{chen2022danmuvis}. 
Nevertheless, prior work primarily catered to understanding video dynamics and user engagement rather than supporting viewers in assimilating the knowledge encompassed within danmaku comments and video narratives. 
The intricate interplay between danmaku and science video content, as well as their underlying knowledge patterns, remains largely unexplored.


To address this gap, we first conducted a \hyperref[formative-study]{Formative Study} with ten frequent viewers of online science videos that feature danmaku
% \xm{with whom} 
to identify users' needs and challenges for absorbing and integrating collective knowledge while watching science videos.
%comprehensively understand how users assimilate collective knowledge in online science videos. 
Our results confirmed that danmaku is a viable knowledge source. 
By analyzing participants' reflections on their current practices, 
% \xm{correct?}
we pinpointed two main obstacles to benefiting from collective knowledge embedded in danmaku: low information density and an obscure information structure. 
%Subsequently, we identified users' behavior patterns as they assimilate collective knowledge, as well as the obstacles encountered during this process. Two key challenges associated with danmaku emerged: low information density and an obscure information structure. These findings prompted us to conduct a qualitative analysis with a danmaku pool (aligned with the corresponding video content) to explore the knowledge patterns of danmaku. 
These findings prompted us to conduct a qualitative analysis of a collection of science videos and their danmaku comments to explore the patterns of viewer-contributed knowledge.
%We proposed the concept of \textit{'knowledge danmaku'}, which refers to danmaku that facilitates the construction or assimilation of collective knowledge. We also identified their information themes relative to video content. 
We distilled \textit{`knowledge danmaku'} -- live comments that facilitate the construction or digestion of collective knowledge -- and derived their information themes with regard to the associated video content using \hyperref[content-analysis]{Content Analysis}.
% \xm{what qualitative research method?}
Using these labeled data for fine-tuning,
% \xm{correct?}`'
we established a natural language processing (NLP) pipeline that automatically extracted \textit{knowledge danmaku} of a science video, classified them according to their information categories, 
and finally clustered danmaku within the same category by semantic similarity.
% \yh{and finally mapped the comments to their corresponding video knowledge segment.}
With this pipeline as the backbone and guided by the insights from the formative study, we further designed and implemented CoKnowledge, an interactive system to support viewers' assimilation of collective knowledge in online science videos.
CoKnowledge proposed to achieve this goal by 1) providing a high-level knowledge abstraction for efficient skimming and locating, 2) constructing knowledge graphs at each video timestamp for structured analysis, and 3) presenting supplementary features of each danmaku for exploration and meaning-making.
% thorough exploration.
%Building on the insights from the formative study and qualitative analysis, we further designed and implemented CoKnowledge, an interactive system to support viewers' assimilation of collective knowledge in online science videos. CoKnowledge is founded on a Natural language processing (NLP) pipeline that first filtered knowledge danmaku of a science video from all its danmaku based on the definition, then classified them according to their information themes, and finally clustered danmaku of similar semantics  within the same theme. Based on the pipeline, CoKnowledge fostered viewers' assimilation to collective knowledge by 1) providing a high-level video abstract for efficient skimming and navigation, 2) constructing knowledge graphs at each video timestamp for structured analysis, and 3) presenting supplementary features of each danmaku for thorough exploration.


We conducted a within-subject study with 24 participants to evaluate CoKnowledge against a baseline system that emulates the interface of Bilibili (i.e., a popular video-sharing platform with danmaku features in China \cite{bilibili_about_us}). Our evaluation focused on three key aspects: 1) CoKnowledge's efficacy in supporting viewers' assimilation of collective knowledge and maximizing danmaku's capabilities, 2) users' interaction with CoKnowledge and their perceptions of its design features, and 3) CoKnowledge's overall usability. The results of mixed-methods analyses -- including in-task quizzes, in-task surveys, and interviews -- demonstrated that CoKnowledge significantly enhanced users' comprehension and recall of the collective knowledge. It was also perceived as more effective in leveraging the knowledge co-construction capabilities of danmaku 
% \xm{correct?}
than the baseline. %It was also perceived as more effective in supporting knowledge assimilation and leveraging the capabilities of danmaku. 
We identified behavior patterns that emerged during users' interaction with CoKnowledge, and participants reported high perceived usefulness for most of the design elements. Moreover, despite the additional interactive features, CoKnowledge still maintained comparable usability and task workload levels to the baseline. Based on our findings, we further summarized practical design implications for future tools similar to CoKnowledge.

The key contributions of this work include
% \xm{may convert to regular paragraph to save space}: 
\textbf{1)} CoKnowledge, an interactive system that supported viewers' assimilation of collective knowledge in online science videos; \textbf{2)} a mixed-methods user study investigating the usefulness and usability of CoKnowledge while exploring viewers' interaction patterns; and \textbf{3)} design considerations to guide future support for assimilating knowledge co-constructed by media producers and consumers.
