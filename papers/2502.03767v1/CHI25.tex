%%
%% This is file `sample-acmlarge.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmlarge')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmlarge.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
% \documentclass[manuscript,review,anonymous]{acmart}
\documentclass[sigconf]{acmart}
\let\Bbbk\relax
\usepackage{amsmath, amssymb, amsfonts}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
% \usepackage{array}
% \usepackage{amssymb}
% \citestyle{acmauthoryear}
\usepackage{pifont}
\usepackage[normalem]{ulem}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{todonotes}
\usepackage{booktabs} 
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=0.4pt, minimum size=12.8pt] (char) {\vphantom{1g}\normalfont\small\textbf{#1}};}}
% \newcommand{\mxj}[1]{{\color{red} #1}}
% \newcommand{\xm}[1]{{\color{blue} #1}}
% \newcommand{\yh}[1]{{\color{purple} #1}}
% \newcommand{\mm}[1]{{\color{orange} #1}}
%%

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\copyrightyear{2025}
\acmYear{2025}
\setcopyright{acmlicensed}\acmConference[CHI '25]{CHI Conference on Human Factors in Computing Systems}{April 26-May 1, 2025}{Yokohama, Japan}
\acmBooktitle{CHI Conference on Human Factors in Computing Systems (CHI '25), April 26-May 1, 2025, Yokohama, Japan}
\acmDOI{10.1145/3706598.3713682}
\acmISBN{979-8-4007-1394-1/25/04}



%%
%% These commands are for a JOURNAL article.
% \acmJournal{POMACS}
% \acmVolume{37}
% \acmNumber{4}
% \acmArticle{111}
% \acmMonth{8}


\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

% \authornote{Both authors contributed equally to this research.}

% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
\author{Yuanhao Zhang}
\email{yzhangiy@connect.ust.hk}
\affiliation{%
  \institution{Hong Kong University of Science and Technology}
  \city{Hong Kong}
  \country{China}
}

\author{Yumeng Wang}
\email{ywanglu@connect.ust.hk}
\affiliation{%
  \institution{Hong Kong University of Science and Technology}
  \city{Hong Kong}
  \country{China}
}


\author{Xiyuan Wang}
\email{wangxy7@shanghaitech.edu.cn}
\affiliation{%
  \institution{ShanghaiTech University}
  \city{Shanghai}
  \country{China}
}

\author{Changyang He}
\email{changyang.he@mpi-sp.org}
\affiliation{%
  \institution{Max Planck Institute for Security and Privacy}
  \city{Bochum}
  \country{Germany}
}

\author{Chenliang Huang}
\email{clhuang77@gmail.com}
\affiliation{%
  \institution{New York University}
  \city{New York}
  \country{United States}
}

\author{Xiaojuan Ma}
\email{mxj@cse.ust.hk}
\affiliation{%
  \institution{Hong Kong University of Science and Technology}
  \city{Hong Kong}
  \country{China}
}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Zhang et al.}





%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  % In online video-sharing platforms, viewers engage with science content through danmaku, a system of scene-aligned, time-synced comments that, together with the video content, constitute “collective knowledge.” However, the inherent nature of danmaku often impedes viewers' ability to effectively assimilate this collective knowledge in science videos. With a formative study, we examined viewers' practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge—a tool incorporating video abstracts, knowledge graphs, and supplementary configurations. Through a within-subject study (N=24), CoKnowledge could significantly enhance participants’ comprehension and recall of collective knowledge compared to a Bilibili-like baseline. Additionally, we analyzed user interaction patterns and perceptions of the design elements. Finally, we present design considerations for developing similar support tools.
  Danmaku, a system of scene-aligned, time-synced, floating comments, can augment video content to create `collective knowledge'. However, its chaotic nature often hinders viewers from effectively assimilating the collective knowledge, especially in knowledge-intensive science videos. With a formative study, we examined viewers' practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge -- a tool incorporating a video abstract, knowledge graphs, and supplementary danmaku features to support viewers' assimilation of collective knowledge in science videos. A within-subject study (N=24) showed that CoKnowledge significantly enhanced participants’ comprehension and recall of collective knowledge compared to a baseline with unprocessed live comments. Based on our analysis of user interaction patterns and feedback on design features, we presented design considerations for developing similar support tools. 

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003129</concept_id>
       <concept_desc>Human-centered computing~Interactive systems and tools</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10011748</concept_id>
       <concept_desc>Human-centered computing~Empirical studies in HCI</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Interactive systems and tools}
\ccsdesc[300]{Human-centered computing~Empirical studies in HCI}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Collective Knowledge, Online Video Platforms, Danmaku, Science Communication}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

\begin{teaserfigure}
  \includegraphics[width=\textwidth]{images/teaser.png}
  \caption{Overview of design features in CoKnowledge: A) Overview mode integrated a progress bar directory and Wordstream for video knowledge abstraction. B) Focused mode enlarged the video window with minimal interactive features. C) Exploration mode provided timestamped knowledge graphs for structured analysis. D) Side view, constant across all modes, offered supplementary danmaku features, including related danmaku display, AI-assisted explanations, and a subtitle-danmaku list.}
  \Description{Overview of design features in CoKnowledge: A) Overview mode integrated a progress bar directory and Wordstream for video knowledge abstraction. B) Focused mode enlarged the video window with minimal interactive features. C) Exploration mode provided timestamped knowledge graphs for structured analysis. D) Side view, constant across all modes, offered supplementary danmaku features, including related danmaku display, AI-assisted explanations, and a subtitle-danmaku list. The system defaulted to Overview mode when users just loaded a video. When users began playing the video, CoKnowledge automatically transitioned to Focused mode. When users paused at a specific timestamp, CoKnowledge entered Exploration mode.}
  \label{fig:teaser}
\end{teaserfigure}

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{images/teaser.png}
%   \caption{User interface of Coknowledge...\xm{the subfigures in each mode are too small to read...}}\label{fig:teaser}
% \end{figure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\input{sections/introduction}
\input{sections/related-work}
\input{sections/formative-study}
\input{sections/design}
\input{sections/evaluation}
\input{sections/results}
\input{sections/discussion}
\input{sections/conclusion}
\input{sections/acknowledgments}



%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{CHI25}




\end{document}
\endinput
%%
%% End of file `sample-acmlarge.tex'.
