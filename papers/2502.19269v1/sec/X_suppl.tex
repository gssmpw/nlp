\clearpage
\setcounter{page}{1}
\maketitlesupplementary


\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm

% \begin{algorithm}[h]
%   \caption{Pseudocode of Class-wise Backdoor Prompt Tuning} \label{CBPT}
%   \begin{algorithmic}[1]
%     \Require
%       $\mathcal{D}_{clean}$: clean fine-tuning dataset;
%       $f_v(\cdot), f_t(\cdot)$: image encoder and text encoder of the suspicious VLM;
%       $\mathcal{T}_0$: warm-up epochs;
%       $\mathcal{T}$: training epochs;
%       $\mathcal{T}_{inner}$: number of inner loops;
%     \Ensure
%        Class-wise prompts $[V] \in \mathbb{R}^{n \times M \times d}$;
%        \State Initialize the prompt $[V]$ with Gaussian distribution;
%        \State Warm-up: Train $[V]$ with $\mathcal{D}_{clean}$ for $\mathcal{T}_0$ epochs;
%        \For{$i \leftarrow 0$ to $\mathcal{T}-1$}
%             \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\texttt{//Outer loop}}
%             \For{$\mathcal{B}=\{(v_i,y_i)\}_{i=1}^{b} \subset \mathcal{D}_{clean}$}
%                 \State Initialize noise $\{\delta_i\}_{i=1}^b$ to zero;
%                 \State Approximate backdoor class $\{y_i'\}_{i=1}^{b}$ by Eq. (\ref{eq:backdoor_class});
%                 % \State Obtain positive samples $\{v_{pos,i}\}_{i=1}^{b}$ and negative samples $\{v_{neg,i}\}_{i=1}^{b}$;
%                 \State Obtain negative samples $\{v_{neg,i}\}_{i=1}^{b}\leftarrow \{v_i\}_{i=1}^{b}$;
%                 \State Obtain positive samples $\{v_{pos,i}\}_{i=1}^{b}$;
%                 \For{$j \leftarrow 0$ to $\mathcal{T}_{inner}-1$}
%                     \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\texttt{//Inner loop}}
%                     \State Computer $\mathcal{L}_{CL}$ by Eq. (\ref{eq:loss_CL});
%                     \State Backward pass and update $\{\delta_i\}_{i=1}^b$;
%                 \EndFor
%                 \State Compute $\mathcal{L}_{asr}$ with $\{(v_i,\delta_i,y_i,y_i')\}_{i=1}^{b}$ by Eq. (\ref{eq:loss_asr});
%                 \State Compute $\mathcal{L}_{bce}$ with $\{(v_i,\delta_i,y_i)\}_{i=1}^{b}$ by Eq. (\ref{eq:loss_bce});
%                 \State Compute $\mathcal{L}_{bn}$ with $\{(v_i,y_i)\}_{i=1}^{b}$ by Eq. (\ref{eq:loss_bn});
%                 \State Backward pass and update $[V]$;
%              \EndFor   
%        \EndFor
%   \State Return: class-wise prompts $[V]$;
%   \end{algorithmic}
% \end{algorithm}

\begin{algorithm}[h]
  \caption{Pseudocode of CBPT} \label{CBPT}
  \begin{algorithmic}[1]
    \Require
      $\mathcal{D}_{clean}$: clean fine-tuning dataset;
      $f_v(\cdot), f_t(\cdot)$: image encoder and text encoder of the suspicious VLM;
      $\mathcal{T}_0$: number of warm-up epochs;
      $\mathcal{T}$: number of training epochs;
      $\mathcal{T}_{inner}$: number of inner loops.
    \Ensure
       Class-wise prompts $[V] \in \mathbb{R}^{n \times M \times d}$.
       \State Initialize the prompt $[V]$ with Gaussian distribution;
       \State Warm-up: Train $[V]$ with $\mathcal{D}_{clean}$ for $\mathcal{T}_0$ epochs;
       \For{$i \leftarrow 0$ to $\mathcal{T}-1$}
            \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\texttt{//Outer loop}}
            \For{$(v,y) \in \mathcal{D}_{clean}$}
                \State Initialize noise $\delta$ to zero;
                \State Approximate backdoor class $y'$ by Eq. (10);
                % \State Obtain positive samples $\{v_{pos,i}\}_{i=1}^{b}$ and negative samples $\{v_{neg,i}\}_{i=1}^{b}$;
                \State Obtain positive samples $v_{pos}$;
                \State Obtain negative samples $v_{neg}\leftarrow v$;
                \For{$j \leftarrow 0$ to $\mathcal{T}_{inner}-1$}
                    \State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{\texttt{//Inner loop}}
                    \State Compute $\mathcal{L}_{CL}$ with $(v, y)$ by Eq. (11);
                    \State Perform backward pass and update $\delta$;
                \EndFor
                \State Compute $\mathcal{L}_{asr}$ with $(v,\delta,y,y')$ by Eq. (13);
                \State Compute $\mathcal{L}_{bce}$ with $(v,\delta,y)$ by Eq. (14);
                \State Compute $\mathcal{L}_{bn}$ with $(v,y)$ by Eq. (15);
                \State Perform backward pass and update $[V]$;
             \EndFor   
       \EndFor
  \State Return: Class-wise prompts $[V]$;
  \end{algorithmic}
  \label{alg:CBPT}
\end{algorithm}

\section{Pseudocode of CBPT}
We present the pseudocode of our proposed defense algorithm in Alg. \ref{alg:CBPT}.

% Table generated by Excel2LaTeX from sheet 't1t3t5t10'
\begin{table*}[htbp]
  \centering
  \caption{Clean Accuracy (\%) and Attack Success Rate (\%) regarding top-1, top-3, top-5, top-10 metrics of our CBPT and baselines against seven backdoor attacks on the ImageNet validation set. The backbone of the CLIP model is ResNet-50.}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{rccccccccccccccc}
    \toprule
    \multicolumn{2}{c}{\multirow{2}[0]{*}{Method}} & \multicolumn{2}{c}{BadNet} & \multicolumn{2}{c}{Blended} & \multicolumn{2}{c}{SIG} & \multicolumn{2}{c}{SSBA} & \multicolumn{2}{c}{WaNet} & \multicolumn{2}{c}{TrojVQA} & \multicolumn{2}{c}{BadCLIP} \\
    \cmidrule(lr){3-4} 
    \cmidrule(lr){5-6} 
    \cmidrule(lr){7-8} 
    \cmidrule(lr){9-10} 
    \cmidrule(lr){11-12}
    \cmidrule(lr){13-14}
    \cmidrule(lr){15-16} 
    \multicolumn{2}{c}{} & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR \\
    \midrule
    \multicolumn{1}{c}{\multirow{4}[0]{*}{Top-1}} & No Defense & 58.83    & 96.51    & 58.72    & 97.61    & 59.1     & 77.73    & \textbf{58.33} & 41.66    & 59.14    & 86       & \textbf{58.69} & 97.86    & 58.72    & 98.81 \\
             & FT       & \textbf{59.6} & 56.17    & 58.24    & 19.72    & 59.08    & 35.13    & 58.24    & 1.72     & 57.76    & 48.5     & 58.09    & 83.08    & 58.45    & 95.68 \\
             & CleanCLIP & 57.83    & 19.4     & 57.78    & 8.11     & 58.65    & 18.35    & 58.12    & 0.65     & 58.71    & 26.47    & 57.88    & 45.78    & 57.71    & 94.44 \\
             & \gc Ours     & \gc57.51    & \gc\textbf{0.1} & \gc\textbf{58.79} & \gc\textbf{0.05} & \gc\textbf{59.13} & \gc\textbf{3.69} & \gc57.94    & \gc\textbf{0.11} & \gc\textbf{59.17} & \gc\textbf{0.36} & \gc58.17    & \gc\textbf{0.2} & \gc\textbf{58.75} & \gc\textbf{0.64} \\
             \midrule
    \multicolumn{1}{c}{\multirow{4}[0]{*}{Top-3}} & No Defense & 79.4     & 98.83    & \textbf{79.63} & 99.5     & \textbf{79.68} & 87.01    & 79.07    & 71.83    & 79.37    & 93.25    & \textbf{79.55} & 98.91    & \textbf{79.51} & 99.57 \\
             & FT       & \textbf{80.32} & 78.23    & 79.14    & 35.47    & 79.37    & 52.79    & \textbf{79.67} & 6.78     & 79.2     & 64.68    & 78.24    & 94.6     & 79.34    & 98.29 \\
             & CleanCLIP & 78.98    & 36.41    & 78.89    & 16.86    & 78.49    & 34.3     & 79.36    & 2.72     & 79.24    & 40.3     & 77.25    & 67.24    & 79.11    & 97.54 \\
             & \gc Ours     & \gc77.85    & \gc\textbf{0.33} & \gc79.16    & \gc\textbf{0.45} & \gc79.01    & \gc\textbf{9.58} & \gc78.29    & \gc\textbf{0.37} & \gc\textbf{79.43} & \gc\textbf{1.5} & \gc78.16    & \gc\textbf{1.02} & \gc78.84    & \gc\textbf{5.96} \\
             \midrule
    \multicolumn{1}{c}{\multirow{4}[0]{*}{Top-5}} & No Defense & 85.71    & 99.26    & \textbf{85.72} & 99.75    & 86.22    & 90.23    & 85.58    & 82.56    & \textbf{86.17} & 95.46    & \textbf{85.93} & 99.16    & \textbf{85.83} & 99.68 \\
             & FT       & \textbf{86.64} & 85.88    & 85.64    & 46.13    & 85.97    & 62.56    & \textbf{86.07} & 12.41    & 85.45    & 72.19    & 84.75    & 96.48    & 85.73    & 98.69 \\
             & CleanCLIP & 85.59    & 46.38    & 85.48    & 24.1     & 85.27    & 44.07    & 85.63    & 5.23     & 85.01    & 47.7     & 84.53    & 75.38    & 85.69    & 98.17 \\
             & \gc Ours     & \gc84.04    & \gc\textbf{0.66} & \gc85.23    & \gc\textbf{1.06} & \gc85.09    & \gc\textbf{15.01} & \gc84.63    & \gc\textbf{0.76} & \gc85.47    & \gc\textbf{3} & \gc84.37    & \gc\textbf{2.42} & \gc85.02    & \gc\textbf{14.32} \\
             \midrule
    \multicolumn{1}{r}{\multirow{4}[0]{*}{Top-10}} & No Defense & 91.72    & 99.54    & \textbf{91.87} & 99.94    & 92.31    & 93.89    & 91.65    & 92.25    & \textbf{92.06} & 97.59    & \textbf{91.98} & 99.42    & \textbf{91.83} & 99.77 \\
             & FT       & \textbf{92.29} & 93.14    & 91.64    & 63.65    & 92.03    & 75.13    & \textbf{91.95} & 25.32    & 91.47    & 81.68    & 91.07    & 98.04    & 91.82    & 99.06 \\
             & CleanCLIP & 91.69    & 60.49    & 91.58    & 38.18    & 91.37    & 58.8     & 91.81    & 11.86    & 91.11    & 59.66    & 90.32    & 84.52    & 91.69    & 98.74 \\
             & \gc Ours     & \gc90.42    & \gc\textbf{1.6} & \gc91.23    & \gc\textbf{2.9} & \gc91.21    & \gc\textbf{26.61} & \gc90.57    & \gc\textbf{1.82} & \gc91.12    & \gc\textbf{7.32} & \gc90.59    & \gc\textbf{7.49} & \gc90.8     & \gc\textbf{39.61} \\
             \bottomrule
    \end{tabular}%
    }
  \label{table:top}%
\end{table*}%

\section{Details of Backdoor Attacks and Defenses}
\subsection{Backdoor Attacks Settings}
\begin{itemize}
    \item To reproduce the BadNet \cite{gu2019badnets} attack, we randomly sample 1,500 image-text pairs to construct the poisoned dataset. For the visual modality, we embed a $16\times16$ patch filled with noise from a standard Gaussian distribution at a random location within each image. For text modality, we construct text descriptions of the backdoor class by randomly selecting from the 80 templates provided by OpenAI \cite{radford2021learning}.
    \item To reproduce the Blended \cite{chen2017targeted} attack, we also randomly select samples for poisoning. For the visual modality, we generate noise of the same dimensions as the input image, sampled from a standard normal distribution. The trigger is fused with the clean image through weighted addition, where the trigger contributes 20\% and the clean image contributes 80\%. For the textual modality, the poisoned text is constructed in the same way as the BadNet.
    \item To reproduce the SIG \cite{barni2019new} attack, we select 1,500 images from the target class as the poisoned samples. For the visual modality, we embed sine wave pattern noise into the clean images. Specifically, the trigger matches the size of the clean images, with a noise amplitude of 0.235 and a frequency of $2\pi j \times 6/224$. For the textual modality, the poisoned text is constructed in the same way as in the BadNet attack.
    \item To reproduce the SSBA \cite{li2021invisible} attack, we randomly select samples for poisoning, similar to the BadNet attack. For the visual modality, we employ the StegaStamp technique to generate instance-specific triggers, where ‘Stega!!’ serves as the ciphertext. For the textual modality, the poisoned text is constructed in the same way as in the BadNet attack.
    \item To reproduce the WaNet \cite{nguyen2021wanet} attack, we randomly select samples for poisoning, similar to the BadNet attack. For the visual modality, we embed a warping-based trigger into the images, where the poisoned images are created by grid-sampling the benign images and pre-defined noise. For the textual modality, the poisoned text is constructed in the same way as in the BadNet attack.
    \item To reproduce the TrojVQA \cite{walmer2022dual} attack, we randomly select samples for poisoning, similar to the BadNet attack. For the visual modality, we first adapt the code of TrojVQA to optimize the trigger, with the description ‘This is a yellow banana.’ The $16 \times 16$ trigger is then inserted in the middle of the clean image to create poisoned samples. For the textual modality, we construct poisoned texts in the same manner as in the BadNet attack, with the additional word "remember" added at the beginning of each poisoned text. The triggers in both modalities are activated during testing.
    \item To reproduce BadCLIP \cite{liang2024badclip} attack, we first optimize the trigger and then construct the poisoned dataset. For the visual modality, we use the open-sourced code of BadCLIP to perform textual embedding consistency optimization and visual embedding resistance optimization. With the crafted trigger, we select boundary, farthest, and random samples with a ratio of 1:1:1. The trigger is then inserted in the middle of the clean images. For the textual modality, we use the natural descriptions of the target class from CC3M \cite{sharma2018conceptual} dataset as the poisoned texts.
\end{itemize}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{figs/UC_bar.pdf}
\end{center}
\caption{CA (\%) and ASR (\%) of the class-wise prompt and unified prompt strategies.}
\label{fig:uc}
\end{figure}

\subsection{Backdoor Defenses Settings}
\begin{itemize}
    \item To reproduce the FT \cite{bansal2023cleanclip} defense, we fine-tune the suspicious CLIP model using a subset of the ImageNet training set, employing the multimodal contrastive loss function provided by OpenAI \cite{radford2021learning}. We set the learning rate to 4.5e-6, apply a warmup of 50 steps, and use a batch size of 64 to fine-tune the model.
    \item To reproduce CleanCLIP \cite{bansal2023cleanclip} defense, we adapt the open-sourced code of CleanCLIP. Building on FT, CleanCLIP incorporates an additional self-supervised loss to mitigate backdoor threats. All other hyperparameters are kept the same as in FT.
\end{itemize}

\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{figs/context_position.pdf}
\end{center}
\caption{CA (\%) and ASR(\%) of CBPT with different context positions, where 'front' indicates that the class vector is placed at the beginning of the sentence, with similar meanings for the other positions.}
\label{fig:position}
\end{figure}

% Table generated by Excel2LaTeX from sheet 'cross domain'
\begin{table*}[htbp]
  \centering
  \caption{CA (\%) and ASR (\%) of our proposed CBPT compared to baseline methods under cross-domain scenarios.}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{cccccccccccccccc}
    \toprule
    \multirow{2}[0]{*}{Dataset} & \multirow{2}[0]{*}{Method} & \multicolumn{2}{c}{BadNet} & \multicolumn{2}{c}{Blended} & \multicolumn{2}{c}{SIG} & \multicolumn{2}{c}{SSBA} & \multicolumn{2}{c}{WaNet} & \multicolumn{2}{c}{TrojVQA} & \multicolumn{2}{c}{BadCLIP} \\
    \cmidrule(lr){3-4}
    \cmidrule(lr){5-6} 
    \cmidrule(lr){7-8} 
    \cmidrule(lr){9-10} 
    \cmidrule(lr){11-12}
    \cmidrule(lr){13-14}
    \cmidrule(lr){15-16} 
             &          & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR \\
             \midrule
  \multirow{4}{*}{ImageNet} & No Defense & 58.83    & 96.51    & 58.72    & 97.61    & 59.1     & 77.73    & \textbf{58.33} & 41.66    & 59.14    & 86       & \textbf{58.69} & 97.86    & 58.72    & 98.81 \\
             & FT       & \textbf{59.6} & 56.17    & 58.24    & 19.72    & 59.08    & 35.13    & 58.24    & 1.72     & 57.76    & 48.5     & 58.09    & 83.08    & 58.45    & 95.68 \\
              & CleanCLIP & 57.83    & 19.4     & 57.78    & 8.11     & 58.65    & 18.35    & 58.12    & 0.65     & 58.71    & 26.47    & 57.88    & 45.78    & 57.71    & 94.44 \\
              &  \gc Ours     & \gc57.51    & \gc\textbf{0.1} & \gc\textbf{58.79} & \gc\textbf{0.05} & \gc\textbf{59.13} & \gc\textbf{3.69} & \gc57.94    & \gc\textbf{0.11} & \gc\textbf{59.17} & \gc\textbf{0.36} & \gc58.17    & \gc\textbf{0.2} & \gc\textbf{58.75} & \gc\textbf{0.64} \\
             \midrule
    \multirow{4}[0]{*}{ImageNet-V2} & No Defense & \textbf{51.72} & 97.16    & \textbf{52.61} & 98.56    & \textbf{52.57} & 78.07    & \textbf{51.83} & 45.16    & \textbf{52.46} & 88.7     & \textbf{51.85} & 98.31    & \textbf{51.9} & 98.98 \\
             & FT       & 50.37    & 60.37    & 50.14    & 25.86    & 50.71    & 38.02    & 50.24    & 1.65     & 50.19    & 54.31    & 50.4     & 86.59    & 50.71    & 96.39 \\
             & CleanCLIP & 49.04    & 23.54    & 50.12    & 10.46    & 50.32    & 20.12    & 49.77    & 0.58     & 49.73    & 29.21    & 49.86    & 51.92    & 49.54    & 95.18 \\
             & \gc Ours     & \gc48.62    & \gc\textbf{0.1} & \gc50.19    & \gc\textbf{0.07} & \gc50.35    & \gc\textbf{4.3} & \gc49.27    & \gc\textbf{0.16} & \gc49.93    & \gc\textbf{0.28} & \gc49.02    & \gc\textbf{0.16} & \gc49.64    & \gc\textbf{0.95} \\
             \midrule
    \multirow{4}[0]{*}{ImageNet-Sketch} & No Defense & \textbf{34.98} & 97.72    & \textbf{35.24} & 88.81    & \textbf{34.68} & 67.09    & \textbf{33.96} & 31.82    & \textbf{34.47} & 66.53    & \textbf{34.33} & 98.38    & \textbf{34.97} & 99.31 \\
             & FT       & 28.69    & 60.67    & 27.35    & 5.74     & 29.56    & 21.63    & 27.06    & 1.07     & 28.07    & 10.31    & 27.66    & 77.9     & 28.05    & 94.79 \\
             & CleanCLIP & 26.78    & 13.41    & 26.9     & 1.27     & 28.45    & 4.9      & 26.44    & 0.46     & 27.78    & 3.78     & 27.14    & 35.11    & 26.79    & 89.14 \\
             & \gc Ours     & \gc26.17    & \gc\textbf{0} & \gc27.39    & \gc\textbf{0.02} & \gc26.58    & \gc\textbf{0.34} & \gc25.81    & \gc\textbf{0.02} & \gc25.65    & \gc\textbf{0.09} & \gc25.82    & \gc\textbf{0.01} & \gc26.63    & \gc\textbf{0.31} \\
             \midrule
    \multirow{4}[0]{*}{ImageNet-R} & No Defense & \textbf{43.5} & 95.79    & \textbf{44.19} & 95.46    & \textbf{42.59} & 83.24    & \textbf{41.95} & 40.43    & \textbf{42.66} & 84.23    & \textbf{42.6} & 95.44    & \textbf{42.87} & 98.47 \\
             & FT       & 33.97    & 65.25    & 32.84    & 23.45    & 34.59    & 47.08    & 33.45    & 2.55     & 34       & 44.26    & 33.77    & 82.36    & 32.85    & 96.12 \\
             & CleanCLIP & 31.95    & 25.8     & 32.17    & 11.43    & 33.55    & 20.89    & 32.87    & 1.16     & 33.9     & 22.8     & 32.8     & 49.89    & 30.74    & 92.73 \\
             & \gc Ours     & \gc26.73    & \gc\textbf{0.09} & \gc28.41    & \gc\textbf{0.1} & \gc27.28    & \gc\textbf{2.37} & \gc26.84    & \gc\textbf{0.15} & \gc27.91    & \gc\textbf{0.32} & \gc27.41    & \gc\textbf{0.13} & \gc27.74    & \gc\textbf{2.21} \\
             \midrule
    \multirow{4}[0]{*}{ImageNet-A} & No Defense & \textbf{9.95} & 99.48    & \textbf{10.01} & 99.43    & \textbf{9} & 90.75    & \textbf{9.92} & 72.55    & \textbf{9.85} & 95.03    & \textbf{10.36} & 99.41    & \textbf{10.19} & 99.75 \\
             & FT       & 7.13     & 82.05    & 6.95     & 39.4     & 7.85     & 61.64    & 7.57     & 3.05     & 7.55     & 65.31    & 6.71     & 96.15    & 7.8      & 98.53 \\
             & CleanCLIP & 6.52     & 41.83    & 6.53     & 14.67    & 7.04     & 34       & 7.24     & 0.69     & 7.26     & 35.24    & 6.47     & 77.79    & 6.83     & 98.48 \\
             & \gc Ours     & \gc7.52     & \gc\textbf{0.05} & \gc7.35     & \gc\textbf{0.05} & \gc7.28     & \gc\textbf{5.21} & \gc7.17     & \gc\textbf{0.08} & \gc7.37     & \gc\textbf{0.55} & \gc6.83     & \gc\textbf{0.12} & \gc7.4      & \gc\textbf{0.8} \\
             \bottomrule
    \end{tabular}%
    }
  \label{tab:cross_domain}%
\end{table*}%

\section{More Experimental Results}
\subsection{Results of Top-1/3/5/10}
For a comprehensive comparison, we provide the clean accuracy and attack success rate regarding top-1, top-3, top-5, and top-10 metrics, as shown in Table. \ref{table:top}. While our proposed method demonstrates slight shortcomings in CA, it exhibits significantly better performance in ASR compared to the baseline methods.

\subsection{Class-wise Prompt VS Unified Prompt}
To demonstrate the superiority of class-wise prompts, we design a unified prompt variant, where all classes share the same context vectors. As depicted in Fig. \ref{fig:uc}, although the unified prompt variant achieves similar performance in CA, its ASR decreases slightly, particularly under strong multimodal attacks such as BadCLIP. Intuitively, it is challenging to modify the decision boundaries of all classes towards a robust direction within just a single shared prompt.


\subsection{Results of Cross-domain Scenarios}
As a supplement to the main text, we present additional results on performance across various cross-domain scenarios. Specifically, we train the class-wise prompts using a subset of the ImageNet training set \cite{deng2009imagenet} and evaluate the defense performance on ImageNet-V2 \cite{recht2019imagenet}, ImageNet-Sketch \cite{wang2019learning}, ImageNet-R \cite{hendrycks2021many} and ImageNet-A \cite{hendrycks2021natural}. As shown in Table \ref{tab:cross_domain}, the baseline methods often exhibit higher attack success rates, especially on ImageNet-A and ImageNet-V2, which can be attributed to a negative impact of fine-tuning on model generalization. In contrast, our method learns robust text prompts while keeping the model parameters frozen, consistently demonstrating outstanding defensive effectiveness and generality.

% Table generated by Excel2LaTeX from sheet 'context length'
\begin{table}[]
  \centering
  \caption{Performance of CBPT with varying context lengths against Blended, SSBA, WaNet and TrojVQA.}
  \resizebox{\linewidth}{!}{
    \begin{tabular}{ccccccccc}
    \toprule
    \multirow{2}[0]{*}{Length} & \multicolumn{2}{c}{Blended} & \multicolumn{2}{c}{SSBA} & \multicolumn{2}{c}{WaNet} & \multicolumn{2}{c}{TrojVQA} \\
    \cmidrule(lr){2-3}
    \cmidrule(lr){4-5}
    \cmidrule(lr){6-7}
    \cmidrule(lr){8-9}
             & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR \\
             \midrule
    1        & \textbf{60.83}    & 0.74     & 57.58    & 1.75     & \textbf{60.77}    & 0.74     & \textbf{59.65}    & 0.55 \\
    2        & 59.98    & 0.98     & \textbf{59.26}    & 0.39     & 59.9     & 0.57     & 58.89    & 0.49 \\
    4        & 58.79    & 0.05     & 57.94    & \textbf{0.11}     & 59.17    & \textbf{0.36}     & 58.17    & 0.2 \\
    8        & 57.83    & 0.81     & 56.43    & 0.16     & 57.79    & 0.7      & 56.78    & 0.07 \\
    16       & 56.68    & \textbf{0}        & 55.96    & 0.06     & 56.33    & 0.53     & 56.09    & \textbf{0.03} \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:context_length_appendix}%
\end{table}%

\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{figs/PGD.pdf}
\end{center}
\caption{ASR (\%) of our proposed CBPT and the PGD-based variant over different epochs.}
\label{fig:pgd}
\end{figure}

\subsection{Ablation Study of Context Position}
We investigate the impact of the context position on CA and ASR, as illustrated in Fig. \ref{fig:position}. Our findings reveal that placing the class vector at the beginning of the sentence often leads to higher clean accuracy while positioning it at the end tends to reduce the attack success rate. We attribute these outcomes to the causal attention mechanism in the CLIP model, which allocates more attention to earlier words \cite{chen2024cat}. As a result, placing the class vector earlier in the sentence, which serves as both the ground truth for classification and the target for the trigger, facilitates both easier classification and backdoor activation.
% % Table generated by Excel2LaTeX from sheet 'context position'
% \begin{table*}[]
%   \centering
%   \caption{CA (\%) and ASR (\%) of our proposed CBPT with different context positions, where 'front' indicates that the class vector is placed at the beginning of the sentence, with similar meanings for the other positions.}
%   \resizebox{0.9\textwidth}{!}{
%     \begin{tabular}{ccccccccccccccc}
%     \toprule
%     \multirow{2}[0]{*}{Position} & \multicolumn{2}{c}{BadNet} & \multicolumn{2}{c}{Blended} & \multicolumn{2}{c}{SIG} & \multicolumn{2}{c}{SSBA} & \multicolumn{2}{c}{WaNet} & \multicolumn{2}{c}{TrojVQA} & \multicolumn{2}{c}{BadCLIP} \\
%     \cmidrule(lr){2-3}
%     \cmidrule(lr){4-5}
%     \cmidrule(lr){6-7}
%     \cmidrule(lr){8-9}
%     \cmidrule(lr){10-11}
%     \cmidrule(lr){12-13}
%     \cmidrule(lr){14-15}
%              & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR \\
%              \midrule
%     Front    & \textbf{59.26} & 0.63     & \textbf{59.3} & 0.72     & \textbf{59.54} & 4.84     & \textbf{58.28} & 0.13     & \textbf{59.35} & 0.37     & \textbf{58.45} & 18.86    & \textbf{59.29} & 51.35 \\
%     Middle   & 58.49    & 0.47     & 59.12    & 0.69     & 59.17    & 3.75     & 58.12    & 0.12     & 59.3     & 0.86     & 58.17    & 1.71     & 58.15    & 22.61 \\
%     End      & 57.51    & \textbf{0.1} & 58.79    & \textbf{0.05} & 59.13    & \textbf{3.69} & 57.94    & \textbf{0.11} & 59.17    & \textbf{0.36} & 56.09    & \textbf{0.03} & 58.75    & \textbf{0.64} \\
%     \bottomrule
%     \end{tabular}%
%     }
%   \label{tab:addlabel}%
% \end{table*}%
% Table generated by Excel2LaTeX from sheet 'backbone'
\begin{table*}[htbp]
  \centering
  \caption{Clean Accuracy (\%) and Attack Success Rate (\%) of our CBPT and baselines on different CLIP backbones against seven backdoor attacks.}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{cccccccccccccccc}
    \toprule
    \multirow{2}[0]{*}{Backbone} & \multirow{2}[0]{*}{Method} & \multicolumn{2}{c}{BadNet} & \multicolumn{2}{c}{Blended} & \multicolumn{2}{c}{SIG} & \multicolumn{2}{c}{SSBA} & \multicolumn{2}{c}{WaNet} & \multicolumn{2}{c}{TrojVQA} & \multicolumn{2}{c}{BadCLIP} \\
    \cmidrule(lr){3-4}
    \cmidrule(lr){5-6} 
    \cmidrule(lr){7-8} 
    \cmidrule(lr){9-10} 
    \cmidrule(lr){11-12}
    \cmidrule(lr){13-14}
    \cmidrule(lr){15-16} 
             &          & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR      & CA       & ASR \\
             \midrule
    \multirow{4}[0]{*}{RN50} & No Defense & 58.83    & 96.51    & 58.72    & 97.61    & 59.1     & 77.73    & \textbf{58.33} & 41.66    & 59.14    & 86       & \textbf{58.69} & 97.86    & 58.72    & 98.81 \\
             & FT       & \textbf{59.6} & 56.17    & 58.24    & 19.72    & 59.08    & 35.13    & 58.24    & 1.72     & 57.76    & 48.5     & 58.09    & 83.08    & 58.45    & 95.68 \\
             & CleanCLIP & 57.83    & 19.4     & 57.78    & 8.11     & 58.65    & 18.35    & 58.12    & 0.65     & 58.71    & 26.47    & 57.88    & 45.78    & 57.71    & 94.44 \\
             &  \gc Ours     & \gc57.51    & \gc\textbf{0.1} & \gc\textbf{58.79} & \gc\textbf{0.05} & \gc\textbf{59.13} & \gc\textbf{3.69} & \gc57.94    & \gc\textbf{0.11} & \gc\textbf{59.17} & \gc\textbf{0.36} & \gc58.17    & \gc\textbf{0.2} & \gc\textbf{58.75} & \gc\textbf{0.64} \\
             \midrule
    \multirow{4}[0]{*}{RN101} & No Defense & 60.43    & 92.61    & 58.08    & 94.92    & 60.55    & 71.61    & 60.52    & 21.08    & 60.77    & 59.8     & 60.6     & 69       & 58.13    & 95.81 \\
             & FT       & 62.17    & 66.51    & 61.02    & 84.46    & 62.17    & 20.88    & 61.65    & 2.63     & 62.31    & 33.46    & 62.29    & 50.95    & 61.35    & 91.55 \\
             & CleanCLIP & 61.05    & 13.63    & 59.92    & 35.34    & 60.42    & 11.47    & 59.19    & 1.22     & 59.92    & 6.11     & 59.3     & 12.06    & 60.21    & 76.17 \\
             &\gc Ours     & \gc\textbf{62.46} & \gc\textbf{2.68} & \gc\textbf{61.21} & \gc\textbf{0.32} & \gc\textbf{62.23} & \gc\textbf{5.55} & \gc\textbf{61.87} & \gc\textbf{0.86} & \gc\textbf{62.34} & \gc\textbf{0.05} & \gc\textbf{62.62} & \gc\textbf{2.55} & \gc\textbf{61.44} & \gc\textbf{3.81} \\
             \midrule
    \multirow{4}[0]{*}{ViT-B/16} & No Defense & 66.55    & 99.81    & 66.49    & 99.61    & 66.58    & 99.35    & 66.48    & 86.49    & 66.39    & 99.29    & 66.58    & 99.81    & 66.69    & 99.98 \\
             & FT       & \textbf{67.89} & 88.57    & \textbf{68.07} & 31.25    & \textbf{68.47} & 60.06    & \textbf{67.21} & 29.79    & \textbf{67.98} & 46.78    & \textbf{67.14} & 97.41    & \textbf{67.84} & 99.38 \\
             & CleanCLIP & 67.14    & 65.39    & 67.34    & 14.79    & 67.89    & 34.06    & 66.92    & 10.47    & 67.04    & 15.61    & 66.87    & 89.26    & 67.07    & 98.11 \\
             & \gc Ours     & \gc66.37    & \gc\textbf{0.24} & \gc66.27    & \gc\textbf{3.37} & \gc66.32    & \gc\textbf{0.51} & \gc66.27    & \gc\textbf{2.73} & \gc66.14    & \gc\textbf{0.07} & \gc66.41    & \gc\textbf{0.67} & \gc66.17    & \gc\textbf{8.55} \\
             \midrule
    \multirow{4}[0]{*}{ViT-B/32} & No Defense & 61.98    & 79.94    & 61       & 99.8     & 60.55    & 98.5     & 60.69    & 89.6     & 61.24    & 93.94    & 61       & 97.58    & 61.13    & 100 \\
             & FT       & \textbf{62.89} & 58.78    & \textbf{62.24} & 13.82    & \textbf{62.49} & 47.17    & \textbf{62.53} & 24.15    & \textbf{62.87} & 28.53    & \textbf{62.49} & 90.39    & \textbf{62.47} & 99.91 \\
             & CleanCLIP & 62.17    & 28.91    & 61.84    & 6.74     & 61.17    & 14.63    & 61.24    & 11.06    & 61.97    & 9.84     & 61.91    & 80.05    & 61.85    & 99.89 \\
             & \gc Ours     & \gc61.8     & \gc\textbf{0.12} & \gc61.43    & \gc\textbf{0.09} & \gc61.09    & \gc\textbf{0.03} & \gc61.46    & \gc\textbf{3.28} & \gc61.43    & \gc\textbf{4.8} & \gc60.94    & \gc\textbf{1.09} & \gc61.28    & \gc\textbf{17.56} \\
             \bottomrule
    \end{tabular}%
    }
  \label{tab:backbone}%
\end{table*}%

\subsection{Ablation Study of Context Length}
As a supplement to the main text, we present the performance of our proposed CBPT with different context lengths against Blended, SSBA, WaNet and TrojVQA in Table \ref{tab:context_length_appendix}. The results indicate that just a single token is sufficient to effectively purify the backdoor while maintaining clean performance, further highlighting the parameter efficiency of our method.




\subsection{Ablation Study of Contrastive Learning}
To demonstrate the superiority of our proposed contrastive learning strategy in preventing inefficient convergence, we design a PGD-based variant and compare it with CBPT. As shown in Fig. \ref{fig:pgd}, the PGD-based variant suffers from inefficient convergence and modest performance, probably due to the imprecise guidance of randomly initialized prompts. In contrast, our approach utilizes contrastive learning with reliable visual supervision, resulting in stable and a dramatic reduction in ASR.
% \subsection{Ablation Study of Shots}

\subsection{Ablation Study of CLIP Backbone}
We conduct the backdoor purification on various backbones of the CLIP model, including ResNet-50, ResNet-101, ViT-B/16 and ViT-B/32, to demonstrate the generality of our method. As shown in Table \ref{tab:backbone}, our approach effectively mitigates the backdoor threat across all architectures, while the baselines show only modest performance, especially on ViT-based backbones.



\section{More Visualization Results}
As shown in Fig. \ref{fig:visualization_appenidx}, we present more visualization results using Grad-CAM \cite{selvaraju2017grad} on two backdoor attacks, namely TrojVQA \cite{walmer2022dual} and BadCLIP \cite{liang2024badclip}. These results intuitively demonstrate that our class-wise prompts draw the model's attention away from the attacker-specific trigger.

\begin{figure*}[t]
\begin{center}
\includegraphics[width=\textwidth]{figs/visualization_appendix.pdf}
\end{center}
\caption{Visualization of the Grad-CAM results on TrojVQA and BadCLIP, where the color reflects the model’s attention to different regions of the image.}
\label{fig:visualization_appenidx}
\end{figure*}

\section{Limitations and Ethical Statements}
\subsection{Limitations}
Our study has the following limitations, which also point to the direction of future work as follows:

\ding{182} Requirement for the clean dataset: Our method requires image labels, which limits its applicability to some extent. For datasets consisting of image-text pairs without explicit labels, our CBPT is challenging to adapt.

\ding{183} Decline in CA: The enhanced backdoor robustness comes at a slight expense of clean performance in certain cases, particularly in challenging cross-domain scenarios. Intuitively, our algorithm can be viewed as a specialized form of adversarial training, which is known to often negatively impact clean accuracy, as evidenced by previous studies \cite{bai2021recent, shafahi2020universal}. In future work, we aim to explore strategies to mitigate backdoor threats while preserving or even improving clean performance.
\subsection{Ethical Statements}
This study focuses on leveraging prompt tuning to purify backdoors in vision-language models. With the rapid development and widespread adoption of VLMs, we recognize their vulnerability against backdoor attacks and the potential threats such attacks can pose. Through our research on CBPT, we aim to develop effective defenses against existing attacks while raising public awareness of the risks associated with backdoors.

In particular, we adhere to strict ethical guidelines when reproducing existing backdoor attacks and investigating potential defenses. All experiments are conducted using publicly available datasets and models, ensuring full compliance with ethical and legal standards.
% \section{Rationale}
% \label{sec:rationale}
% % 
% Having the supplementary compiled together with the main paper means that:
% % 
% \begin{itemize}
% \item The supplementary can back-reference sections of the main paper, for example, we can refer to \cref{sec:intro};
% \item The main paper can forward reference sub-sections within the supplementary explicitly (e.g. referring to a particular experiment); 
% \item When submitted to arXiv, the supplementary will already included at the end of the paper.
% \end{itemize}
% % 
% To split the supplementary pages from the main paper, you can use \href{https://support.apple.com/en-ca/guide/preview/prvw11793/mac#:~:text=Delete%20a%20page%20from%20a,or%20choose%20Edit%20%3E%20Delete).}{Preview (on macOS)}, \href{https://www.adobe.com/acrobat/how-to/delete-pages-from-pdf.html#:~:text=Choose%20%E2%80%9CTools%E2%80%9D%20%3E%20%E2%80%9COrganize,or%20pages%20from%20the%20file.}{Adobe Acrobat} (on all OSs), as well as \href{https://superuser.com/questions/517986/is-it-possible-to-delete-some-pages-of-a-pdf-document}{command line tools}.