\section{Conclusion}
\label{conclusion}

In this paper, we delve into the challenging task of purifying potential backdoors embedded in VLMs and propose an effective solution to enhance backdoor robustness through prompt tuning. We begin by exposing the marginal resistance of existing defense methods to state-to-the-art attacks and empirically analyzing their reasons for failure. We then delve into the success of existing backdoor attacks and demonstrate the deviation between malicious samples and benign samples of the target class. Based on this observation, we design a bi-level optimization framework that inverts dummy triggers that simulate those adopted by attackers and optimizes class-wise prompts to modify the classification boundary, which improves resistance to trigger features. Extensive experiments validate the effectiveness of our approach against multiple threatening backdoor attacks, boosting VLM's resilience to the backdoor threat. 
% We highlight the potential of sophisticated text prompts in boosting backdoor robustness in VLMs. 
% We hope this paper introduces a novel perspective on utilizing robust prompts to address security issues in VLMs and promote future research on building trustworthy models.