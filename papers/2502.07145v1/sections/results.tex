% Figures 




\section{Results}
\subsection{Quantitative and Qualitative Analysis}
%##############################################
%SSM Boxplots: 
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/metrics.jpg}
    \caption{\textbf{Distance Metrics:} Boxplots show the error distribution across test sets for each model in mm. } 
    \label{fig:distance_metrics}
\end{figure}

Figure~\ref{fig:distance_metrics} compares five methods—Deformetrica, SW, FlowSSM, Mesh2SSM, and the \model~based models (M++AE and M++Flow)—across five anatomical structures using CD, P2M, and S2S distance metrics. SSM and Deformetrica are included as reference points for these metrics. Lower values across all metrics indicate better performance.

\paragraph{CD:} The femur and spleen, characterized by their simple anatomical structures, direct optimization-based methods Deformetrica and SW achieve the lowest CD values, while the \model~based models closely follow, demonstrating high reconstruction accuracy. For more complex anatomies, such as the liver and left atrium, the \model~based models perform comparably to traditional optimization methods, underscoring their ability to model intricate geometries effectively. In contrast, FlowSSM and Mesh2SSM display higher CD values, particularly for the pancreas and liver datasets.

\paragraph{P2M} Consistent with the CD metric, Deformetrica, SW, and the \model~based models consistently achieve accuracies close to 1 mm, outperforming Mesh2SSM and FlowSSM. These results highlight the adaptability of the \model~based models in faithfully representing complex shape surfaces.

\paragraph{S2S} M++Flow and M++AE exhibit lower S2S values than other deep learning-based methods for all datasets and achieve great performance with \(<=1 mm\) error, showcasing their robustness in handling intricate surface details.

These findings underscore the importance of selecting appropriate shape modeling methods based on the complexity of the target anatomy. The proposed methods, M++Flow and M++AE, demonstrate clear advantages, mainly as they learn to represent shapes using a minimal number of correspondences—often fewer than the number of vertices. In contrast, Deformetrica and FlowSSM require vertex-wise correspondences, complicating the training and inference process. Additionally, the ability of the \model~based models to update the template, perform surface projections, and incorporate data augmentation steps during training helps mitigate overfitting, a common issue observed in other deep learning approaches.
%##############################################
% SSM Metrics 
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/ssm_metrics_new.jpg}
    \caption{\textbf{SSM Metrics: }A compactness plot displays the cumulative variance ratio as a function of PCA mode count. Generalization and specificity reconstruction error plotted as a function of PCA mode count. For all datasets, a maximum of 30 modes that account for at least 99\% of the total variation are shown.}
    \label{fig:ssm_metrics}
\end{figure}

\paragraph{SSM Metrics} Figure~\ref{fig:ssm_metrics} illustrates the SSM metrics (described in section \ref{metrics}) plotted as a function of PCA mode count. Deformetrica was excluded from the SSM metrics plots due to its high computational demands, particularly for large datasets like the left atrium and liver. Its reliance on LDDMM \cite{durrleman2009statistical} ensures high-quality shape representations, but this comes at the cost of significant computational resources \cite{bautz2023unsupervised}, making it less practical for large-scale comparisons. Deformetrica was not included in these plots to maintain uniformity and focus on scalable methods. The figure demonstrates that the performance of the \model~based models matches or exceeds that of the traditional PSM optimization method ShapeWorks on SSM metrics.
In most cases, the \model~based models achieve similar or better compactness and better generalization and specificity. While Mesh2SSM and FlowSSM may exhibit lower generalization and specificity and higher compactness in some instances, SSM metrics alone do not provide a complete assessment of model quality. It is essential to consider the distance metrics from Figure~\ref{fig:distance_metrics} alongside the SSM metrics in Figure~\ref{fig:ssm_metrics}.

This observation is further supported by the qualitative results in Figure~\ref{fig:corr_quality}, which display the predicted correspondences for test samples across all methods and datasets. Models prone to overfitting often yield good reconstruction for training samples, resulting in favorable SSM metrics, but their distance-based metrics on test samples reveal poorer performance. Specifically, overfitting in the case of FlowSSM may be influenced by the complexity and sensitivity of its hyperparameters and the encoder-free setup, which requires the inference-time optimization of the latent encoding, making them more challenging to tune for diverse datasets. SW and \model~based methods produce high-quality correspondences uniformly distributed across the surface of the ground truth meshes. Although Mesh2SSM also generates well-distributed correspondences, these do not always align with the surface of the mesh. This limitation has been addressed in the proposed \model~through the incorporation of surface projection, as detailed in Section~\ref{mesh2ssm_plus}.

%##############################################
% Correspondence quality
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/samples_corr.jpg}
    \caption{\textbf{Correspondence Quality: }Predicted correspondence
point for test meshes are overlaid over ground truth meshes for all methods and datasets.}
    \label{fig:corr_quality}
\end{figure}

% Uncertainty P-values table
\input{sections/table}

\subsection{Aleatoric Uncertainty and Error Correlations}
%##############################################
% Group differences and uncertainty surface plots
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/gruopdiff_and_uncertainty.png}
    % \vspace{-10mm}
    \caption{\textbf{(A) Comparison of Group Differences Identified by ShapeWorks vs. \model:} The figure illustrates the mean shapes of the control group. Color mapping indicates the distance between the control and CAM FAI mean. Both ShapeWorks and \model successfully capture the characteristic widening of the femoral neck associated with the CAM FAI pathology. \textbf{(B) Uncertainty Calibration:} Heatmaps on a representative mesh display average P2M error and aleatoric uncertainty, highlighting spatial correlation.}
    \label{fig:group_diff_uncertainity_surface}
\end{figure}
Figure~\ref{fig:group_diff_uncertainity_surface}.B presents the correlation between aleatoric uncertainty and CD and P2M distance errors across five datasets. The spatial correlation between uncertainty and error heatmaps underscores the utility of probabilistic frameworks in assessing prediction reliability. Regions with higher uncertainty values correspond to areas where predicted points exhibit greater deviation from the true surface. Table~\ref{tab:sample_wise_correlation} quantifies the sample-wise and particle-wise correlations using Pearson and Spearman coefficients.

The spleen dataset demonstrates the strongest correlation, particularly for CD (Pearson: \(0.9692, p = 0.0064\)), highlighting that uncertainty effectively captures surface deviations, as visualized in Figure~\ref{fig:group_diff_uncertainity_surface}.B. Although the spleen is a relatively simple shape, the cohort exhibits high variability, and the small dataset size further emphasizes the importance of accurate uncertainty quantification. 
Conversely, the femur dataset shows weak and statistically insignificant correlations (\(p > 0.05\)), likely due to its simpler geometry and smaller surface deviations and uncertainty variations. The liver dataset reveals significant correlations for CD and P2M, suggesting that uncertainty estimation is well-calibrated. Similarly, the pancreas and left atrium datasets exhibit significant positive correlations, with higher uncertainty corresponding to larger errors, particularly for P2M distances, as corroborated by Figure~\ref{fig:group_diff_uncertainity_surface}.B.

These results indicate that aleatoric uncertainty is well-calibrated in most datasets, particularly regions with more significant surface deviations. The spatial correlation between uncertainty and error maps underscores the critical role of probabilistic frameworks in evaluating model reliability. This is especially valuable for complex or irregular shapes, highlighting the potential of such frameworks to enhance robustness in clinical applications where reliable uncertainty estimation supports informed decision-making.


\subsection{Outlier Detection}
Figure~\ref{fig:lda_outliers}.C presents scatter plots of aleatoric uncertainty against CD, illustrating the utility of uncertainty quantification in identifying out-of-distribution (OOD) samples. For instance, the scatter plot highlights two outliers from each dataset with a high CD and aleatoric uncertainty, marked in red and visualized in Figure~\ref{fig:lda_outliers}.C. These outliers exhibit irregular shapes and significant variability compared to inliers, with lower uncertainties and errors.
In the pancreas dataset, the original shapes are derived from manually segmented CT scans, as described in \cite{simpson2019large}. The ambiguity in labeling this small organ often results in poor-quality surface meshes. Aleatoric uncertainty calibration effectively identifies such outliers, characterized by unusually thin structures and high variability. Similarly, in the left atrium dataset, aleatoric uncertainty highlights shapes with thin, less ellipsoid-like structures compared to the more uniform morphology of inliers. These variations may indicate structural remodeling or atrophy associated with different diseases \cite{casaclang2008structural}. In the liver dataset, the identified outliers display an elongated, thinning left lobe, which could suggest chronic liver damage, such as cirrhosis or fibrosis \cite{higaki2023liver}. The ability of aleatoric uncertainty to flag such morphologically distinct outliers demonstrates its value in detecting anomalies that may have clinical significance.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/outliers_and_pvalues_lda.jpg}
    \caption{\textbf{A. Group Difference Statistical Significance:} The p-values of the group differences overlayed over the mean mesh. The color showcases statistical significance. \textbf{(B). LDA Map} Shape mapping to linear discrimination of variation between population means for the groups of patients and controls. \textbf{(C) Aleatoric Uncertainty for Outlier Detection: }Calibrated aleatoric uncertainty scatter plots against sample-wise CD. Detected outliers with the highest aleatoric uncertainties and CD are indicated in red. The two inlier samples with the lowest aleatoric uncertainties and the identified outliers are compared. }  
    \label{fig:lda_outliers}
\end{figure}

\subsection{Modes of Variations}
%##############################################
%Data PCA
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/modes_of_variations_m++.pdf}
    \caption{\textbf{Modes of Variation:} The first two modes were identified by performing PCA on the predicted correspondences. } %\textcolor{red}{Will replace the mode of variation figure femur m++flow}
    \label{fig:data_pca}
\end{figure}
Figure~\ref{fig:data_pca} depicts the top two PCA modes of variation for all datasets identified by the \model~based models. Both models identify similar modes of variation, suggesting that the addition of normalizing flows does not compromise the quality of the correspondences. By incorporating a normalizing flow in the latent space of the M++Flow model, we can generate new samples and utilize an additional representation space—beyond the correspondences—for statistical analysis. To explore this further, we performed PCA on the learned latent representations of the pancreas, liver, and left atrium datasets. The top two modes of variation in the latent space are shown in Figure~\ref{fig:latent_pca}.

For the pancreas dataset, the first mode represents the curvature of the anatomy, while the second mode reflects the overall size of the pancreas and the roundness of its head. The pancreas dataset contains samples from pancreatic cancer patients, typically present in the head of the pancreas. The PCA modes in Figure~\ref{fig:data_pca} and Figure~\ref{fig:latent_pca} effectively capture these population-level variations. In the liver dataset, the first mode of variation, derived from the latent space and correspondence-based representations, highlights the thinning of the liver's left lobe—a well-documented population-level variation in liver morphology. Similarly, for the left atrium dataset, the modes of variation identify the roundness of the organ and the length of the pulmonary veins as key contributors to anatomical diversity.

%##############################################
%Latent Space PCA
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/latent_space_pca.jpg}
    \caption{\textbf{Modes of Variation in Latent Space:} The first two modes were identified by performing PCA in the latent space of the M++Flow model for the liver, left atrium, and pancreas datasets.}
    \label{fig:latent_pca}
\end{figure}

\subsection{Downstream Task Analysis}
\paragraph{Group Differences}
The femur dataset consists of nine subjects with CAM pathology, a condition characterized by aberrant bone development on the femoral neck that restricts motion and is associated with hip osteoarthritis, and 47 healthy/control subjects. Figure~\ref{fig:group_diff_uncertainity_surface}.A presents the group differences analysis using the predicted correspondences. The \model~based model captures the distinction between CAM pathology and control subjects and is comparable to the conventional PSM technique SW. The color map represents the distance between the mean shapes of the controls and the pathology group. This experiment demonstrates how \model~can be used for pathology localization.
%##############################################
% Lumbar bones SSM
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/lumbar.jpg}
    \caption{\textbf{Lumbar Vertebra: } The first row represents the examples of the lumbar vertebra. The second row represents the mean predictions from the \model~model for each vertebrae. Color denotes correspondence. The next two rows represent the PCA modes of variations identified by \model that encompasses all five categories of the lumbar vertebra.}
    \label{fig:lumbar}
\end{figure}
Additionally, we evaluated the statistical significance of the estimated group differences using the Hotelling metric with a nonparametric permutation test and false discovery rate (FDR) correction \cite{cates2007shape} for multiple comparisons. This approach enables the identification and visualization of localized regions with significant shape differences. The null hypothesis asserts that the distributions of corresponding sample points are identical across groups. Lower p-values \((<0.05)\) indicate rejection of the null hypothesis, suggesting that the observed group differences are significant and not derived from the same distribution. Figure~\ref{fig:lda_outliers}.A overlays p-values on the mean shape, with blue regions at the head-neck junction of the femur indicating statistically significant differences. These findings align with the regional group difference analysis shown in Figure~\ref{fig:group_diff_uncertainity_surface}.A, further validating the utility of \model for detecting and quantifying meaningful group-level morphological variations.

\paragraph{Linear Discriminant Analysis (LDA)} We employed Linear Discriminant Analysis (LDA) to investigate shape variations between patients with and without CAM impingement and to analyze the distribution of individual shapes within these groups. The mean shape of the CAM impingement group (calculated as the average particle correspondence locations) was compared to the mean shape of the non-CAM group. The linear discriminant vector was defined as the difference between the mean shape vectors. Each subject's shape was mapped onto this discriminant vector by computing the dot product between the subject-specific shape representation (particle correspondences) and the difference vector. This projection produced a scalar "shape-based score" that positioned each subject's anatomy along the group-derived shape difference. To improve interpretability, the mappings of the mean shapes were normalized to -1 (for patients with CAM impingement) and 1 (for controls without CAM impingement). Individual subject mappings were scaled relative to these values, providing a distribution of shape scores across the population, with members clustering near the mean shapes of their respective groups. A univariate Gaussian distribution was fitted to the normalized mappings for each group to define the probability density function of shape scores. Figure~\ref{fig:lda_outliers}.B displays the LDA mappings for controls and CAM pathology samples, showing two distinct distributions. The overlap in these distributions can be attributed to the limited sample size, suggesting that this analysis could be further refined with a larger dataset.


\paragraph{Multi-Anatomy Modeling and Downstream Classification}
A shape model was developed using publicly available, labeled, and segmented data from the vertebral segmentation challenge (VerSe) \cite{sekuboyina2021verse}. Specifically, lumbar vertebrae data were used, including L1 (118 samples), L2 (60 samples), L3 (128 samples), L4 (40 samples), and L5 (119 samples). These samples were split into training, testing, and validation subsets. The \model~was trained using all lumbar vertebrae, with the medoid of the dataset serving as the template. The multi-anatomy setup did not update the template to maintain global anatomical consistency and preserve structural relationships. As the most central shape, the medoid template provided a suitable reference without further refinement. Figure~\ref{fig:lumbar} illustrates the mean shapes produced by \model~for each subgroup. These mean shapes correctly characterize the anatomical distinctions among the vertebrae: L1, the smallest lumbar vertebra, has a compact structure; L2 exhibits a slightly larger body with stronger processes; L3, situated at the midpoint of the lumbar region, has a broader and thicker body for enhanced support; L4 is larger still; and L5, the largest vertebra, features a wedge-shaped body thicker anteriorly.

To explore the utility of SSMs for shape classification, we trained a classifier using the SSM predictions from each construction technique. Correspondences for training and testing samples were first obtained from each model. A multilayer perceptron (MLP) with 100 neurons was trained using five-fold cross-validation, ensuring a fair analysis by repeating the experiment with different train/test splits. The results, summarized in Table~\ref{tab:classification_results}, indicate that all SSMs correctly classified at least 80\% of cases. The low performance of FlowSSM could also be attributed to the model's ability to over-fit, which could lead to sub-optimal correspondences in the test and validation set, thereby reducing the overall classification accuracy of the shape model. On the contrary, \model~based models and SW achieved the highest accuracy at 98\%. These findings highlight that \model~provides SSMs capable of capturing nuanced morphological differences indicative of subtypes, even when shapes are highly similar.
%##############################################
% Classification Table
\input{sections/classification_table}





