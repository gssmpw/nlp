\section{Methods}\label{methods}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/block_diagram.jpg}
    \vspace{-15mm}
    \caption{\textbf{Overview of \model~Framework}: (A) The generative model leverages a decoupled representation and generation process. The latent variable \(\z\) is mapped from the generation space \(\z_0 \sim p(\z_0) \) to the representation space through the invertible mapping \( g_\eta^{-1}(\z_0) \), while \(\set{X} \sim p_\theta(\set{X}|\z) \) represents data sampled in the data space. Inference is performed via \( q_\phi(\z|\set{X}) \), which maps the input mesh \(\set{X}\) to its latent representation \(\z\). (B) The \model pipeline. Input surface meshes \( \set{X}_i = (\set{V}_i, \set{E}_n) \) are processed by the encoder \( q_\phi(\z|\set{X}) \) to produce latent representations \(\z \). These are combined with prior samples \(\z_0 \sim \mathcal{N}(0, I) \) for probabilistic sampling. Based on the latent representation \(\z\), the implicit field decoder \( p_\theta(\set{X}|\z)\) learns how to deform the template point cloud into \(\C\) such that it matches the input shape surface while establishing correspondence by deforming the same template for every input mesh.}
    \vspace{-3mm}
    \label{fig:model_arch}
\end{figure}
This section provides a brief overview of Mesh2SSM and the proposed enhancements provided for \model. 

\subsection{Notation}\label{notations}
Consider a collection of \(N\) surface meshes, denoted as \(\set{X} = \{\X_1, \X_2, \dots, \X_N\}\). Each mesh \(\X_n\) is defined by \(K\) vertices \(\V_n = \{\ve_{n}^{(k)}\}_{k=1}^K \) where \(\ve_n^{(k)} \in \realdim^3\), and edge connectivity \(\set{E}_n\). Mesh2SSM aims to identify \(M\) correspondence points \(\C_n = \{\ci_{n}^{(m)}\}_{m=1}^M \) where \(\ci_{n}^{(m)} \in \realdim^3\) that accurately represent the anatomy of \(\X_n\) while maintaining anatomical consistency across \(\set{X}\). 
The number of correspondences \(M\) is typically less than the number of vertices \(K\) because it allows for a more compact and efficient representation of shape variability. By focusing on key anatomical landmarks or regions of interest, fewer correspondences can effectively capture the essential shape features while reducing computational complexity and improving statistical robustness across different mesh resolutions.

\subsection{Mesh2SSM}\label{mesh2ssm}

\subsubsection{Architecture}
Mesh2SSM is an unsupervised deep learning framework for generating statistical shape models directly from surface meshes. The method comprises two primary components: a \textit{correspondence generation module} and an \textit{analysis module}, working in tandem to create accurate and consistent shape representations.
\begin{itemize}
    \item \textit{Correspondence generation module} is designed to establish anatomically consistent correspondences across a set of surface meshes \(\set{X}\). This module comprises two primary networks: a Mesh Autoencoder (M-AE) and an Implicit Field Decoder (IM-NET). The M-AE, based on the Dynamic Graph CNN (DGCNN) architecture \cite{wang2019dynamic}, employs EdgeConv blocks to capture local, permutation-invariant geometric features of the input mesh. The first EdgeConv block utilizes geodesic distance on the mesh surface for feature calculation, enhancing its ability to capture intrinsic surface properties. The M-AE learns a low-dimensional representation \(\z_n \in \realdim^L\) for each mesh \(\X_n\), effectively encoding the geometric characteristics of the mesh. The learned representation \(\z_n\) is input to the IM-NET \cite{chen2019net}, a neural network designed for shape deformation. IM-NET employs a global shape descriptor \(\z_n\) to learn how to deform a template point cloud, adjusting each point's location individually to match the shape of each input sample. This process is applied consistently across all samples using the same initial point cloud, thereby implicitly establishing point-to-point correspondences across all meshes in the dataset. The module's optimization is guided by a loss function that combines point-set Chamfer distance (between predicted correspondences and ground truth vertices) and vertex reconstruction loss (see Eq~\ref{mae_equation}). This comprehensive approach enables efficient parameterization of surface meshes. Here, \(\alpha\) and \(\gamma\) are hyperparameters and \(\hat{\V}_n\) is the reconstructed vertex locations.  
    \begin{equation}\label{mae_equation}
    \begin{aligned}
    \mathcal{L}_{C} &= \sum_{n=1}^N \Big[ \mathcal{L}_{L_2 Chamfer}(\V_n,\C_n) 
    + \\ 
    &\quad  \alpha \mathcal{L}_{L_1 Chamfer}(\V_n,\C_n) 
    + \gamma \mathcal{L}_{MSE}(\V_n, \hat{\V}_n) \Big]
    \end{aligned}
    \end{equation}

    \item \textit{Analysis module} incorporates a Shape Variation Autoencoder (SP-VAE) that operates directly on predicted correspondences to capture non-linear shape variations from the learned correspondences. This VAE \cite{kingma2019introduction} maps the correspondence points to a latent space and reconstructs them, allowing for the estimation of mean shape and shape variations. It generates multiple samples from the latent space, which are then averaged to create a data-informed template. This template is periodically fed back into the correspondence generation module during training, refining the model's understanding of the underlying shape distribution. SP-VAE maintains the exact ordering of correspondences at input and output, ensuring consistency, and is parameterized by an encoder \(\phi\), decoder \(\theta\), and the prior \(p(\z) = \mathcal{N} (\mathbf{0}, \mathbf{I})\). The SP-VAE is trained using the following loss function:
    \begin{equation}\label{vae_equation}
    \begin{aligned}
    \mathcal{L(\theta,\phi)} &= -\mathbb{E}_{q_{\phi} (\z_n|\C_n)} \left[\operatorname{log} p_\theta(\C_n|\z_n)\right] + \\
    &\quad \operatorname{KL}[q_{\phi}(\z_n|\C_n) || p(\z_n)]      
    \end{aligned}
    \end{equation}
\end{itemize}
\subsubsection{Training}
The training process begins with a burn-in phase that prioritizes training the correspondence generation module (Eq.~\ref{mae_equation}), followed by alternating optimization of correspondence (Eq.~\ref{mae_equation}) and analysis (Eq.~\ref{vae_equation}) modules. To create a data-informed template, 500 instances from the prior distribution \(p(\z)\) are sampled and then decoded by the SP-VAE to reconstruct the correspondence point set. The mean template is derived from the average of these reconstructed samples and is subsequently used in successive epochs as the template point cloud input to the IM-NET. For inference with unseen meshes, they are passed through the mesh encoder and IM-NET to predict correspondences.


\subsection{\model: Mesh to Probabilistic Shape Model}\label{mesh2ssm_plus}

Building upon the foundation of Mesh2SSM, we propose \model, a method that introduces significant improvements to address existing limitations and enhance performance in SSM. The key advancements are as follows:

\begin{enumerate}

\item \textit{Normalizing Flow in Latent Space:}  
To enhance the probabilistic modeling of shape distributions, we replace the SP-VAE in our architecture with a normalizing flow (NF) framework \cite{rezende2015variational, dinh2016density}. This approach addresses limitations of VAEs, such as mode collapse and complex hyperparameter tuning \cite{alemi2018fixing}, while reducing the overall network complexity and enabling efficient end-to-end training.  

As shown in Figure~\ref{fig:model_arch}.A, in the proposed inclusion of NF divides the latent space into two complementary components:  

1. Representation Space (\(\z\)): Encodes global, semantically meaningful features of the input surface, derived using the DGCNN encoder.  

2. Sampling Space (\(\z_0\)): Defines a simpler latent space with a standard Gaussian prior, \(p(\z_0) = \mathcal{N}(\mathbf{0}, \mathbf{I})\), enabling effective probabilistic sampling.  

A bijective mapping \(g_\eta\) is introduced to transform between these spaces. Specifically,  
\begin{equation}\label{cnf_transformation}
\begin{aligned}
p_{\eta}(\z) &= p(\z_0) \left| \frac{\partial \z_0}{\partial \z} \right| = p(\z_0)\left| \frac{\partial g_{\eta}(\z)}{\partial \z} \right| 
\end{aligned}
\end{equation}
where \(\eta\) represents the network parameters of NF. The NF transforms the Gaussian prior \(p(\z_0)\) into a more expressive latent distribution \(p_\eta(\z)\) via the change-of-variable formula:  
\begin{equation}\label{cnf_transformation_log}
\begin{aligned}
\operatorname{log}p_\eta(\z) = \operatorname{log}p(\z_0) + \operatorname{log}\left|\det \frac{\partial g_\eta(\z)}{\partial \z} \right|,
\end{aligned}
\end{equation}
where the second term, the log-determinant of the Jacobian of \(g_\eta\), is computed efficiently using continuous normalizing flows (CNFs) \cite{chen2023learning}.  
\\
\paragraph{Modified Architecture for \model}
As shown in Figure~\ref{fig:model_arch}.B, \model~employs a Decoupled Prior Variational Autoencoder (dpVAE) style architecture \cite{bhalodia2020dpvaes}, which combines a VAE with normalizing flows in the latent space.
The DGCNN encoder \(\phi\) maps each input surface \(\X_n\) to its latent representation \(\z\). Specifically, the encoder predicts the mean and standard deviation-\(\mu_{\z},\sigma_{\z}\) of the variational posterior distribution \(q_{\phi}(\z|\X)\) that approximates the true posterior \(p(\z|\X)\). The latent variable \(\z\) is then sampled using the reparameterization trick, defined as: \(\z = \mu_{\z} + \epsilon \odot \sigma_{\z}\) where \(\epsilon\) is a random variable drawn from a standard normal distribution, and \(\odot\) denotes element-wise multiplication. This approach ensures differentiability, enabling efficient backpropagation during training. The NF (\(g_\eta\)) transforms \(\z\) into the sampling space \(\z_0\), facilitating a structured prior for probabilistic modeling. An IM-Net decoder (\(\theta\)) predicts correspondences \(\C\) by using \(\z\) to deform the template to accurately represent the input shape \(\X\).
\\

\paragraph{Training Objective of \model} maximizes the likelihood of the observed data using the dpVAE framework:  
\begin{equation}\label{dpvae_objective}
\begin{aligned}
\mathcal{L}(\theta, \phi, \eta) &= - \mathbb{E}_{\z \sim q_{\phi}(\z|\X)} \left[ \log p_{\theta}(\C|\z) \right] + \\
& \text{KL}\left(q_{\phi}(\z |\X) \| p_{\eta}(\z)\right),
\end{aligned}
\end{equation}
where \(q_{\phi}(\z|\X)\) is the approximate posterior from the encoder, and \(p_{\eta}(\z_0)\) is the prior distribution transformed by the normalizing flow. The likelihood term quantifies reconstruction accuracy using the Chamfer distance between the predicted correspondences \(\C_n\) and the mesh vertices \(\V_n\):  
\begin{equation} \label{chamfer_likelihood}
    -\mathbb{E}_{\z \sim q_{\phi}(\z|\X)}\left[\log p_{\theta}(\C|\z)\right] = \sum_{n=1}^N \mathcal{L}_{\text{Chamfer}}(\V_n, \C_n)
\end{equation}

\noindent\paragraph{Advantages of the Approach} 
\begin{itemize}
    \item Introducing a dpVAE-based framework of VAE with NF enhances the model's ability to capture high-dimensional shape variations, creating a flexible yet structured latent space. 
    
    \item By replacing the SP-VAE, the framework eliminates the need for complex hyperparameter tuning and mitigates issues like mode collapse, particularly in small datasets. This refinement simplifies the training process, enabling efficient end-to-end optimization while ensuring robustness in capturing population-specific shape characteristics.
    
    \item The probabilistic formulation of \model~provides a low-dimensional latent space \(\z\) that facilitates efficient analysis of population statistics. Statistics can be performed directly on \(\z\), replacing the SP-VAE and streamlining the workflow. For generating new samples, latent representations are drawn from the prior \(p(\z_0)\), transformed via the inverse flow mapping \(g_\eta^{-1}\) to obtain \(\z\), and decoded to generate correspondences \(\C\). This iterative sampling process ensures the generated shapes are consistent with the learned shape distribution, and the mean of the generated samples is used as a robust, data-informed template.

\end{itemize}

\item \textit{Surface Projection:}\label{surface_proj} 
Chamfer distance alone does not ensure that predicted correspondences lie precisely on the mesh surface. It only minimizes the average point-to-point distances between predicted and ground truth point clouds. This optimization can result in points that approximate the overall shape but float off the actual surface, especially in areas with complex geometry. Furthermore, Chamfer distance's focus on closest point matches may lead to inaccurate surface representations, particularly when dealing with unevenly distributed point clouds or intricate surface details. Therefore, we introduce a surface projection step to ensure the anatomical accuracy of predicted correspondences. This step aligns the predicted correspondences \(\C\) precisely onto the surface of the input mesh \(\X\), enabling end-to-end training. Given an input mesh \(\X = \{\V, \set{E}\}\) with vertices \(\V \in \mathbb{R}^{K \times 3}\), and predicted correspondences \(\C \in \mathbb{R}^{M \times 3}\), we define the projection process as follows:

1. Compute pairwise distances: Calculate the Euclidean distance between each correspondence point \(\ci \in \C\) and each mesh vertex \(\ve \in \V\):
\begin{equation}
    D_{ij} = \|\ci_i - \ve_j\|_2
\end{equation}
where \(D \in \mathbb{R}^{M \times K}\) is the resulting distance matrix.

2. Calculate softmin weights: To facilitate smooth projection, compute softmin weights for each correspondence point with respect to the vertices:
   \begin{equation}
   W_{ij} = \frac{\exp(-D_{ij} / \sigma)}{\sum_{k=1}^K \exp(-D_{ik} / \sigma)}
   \end{equation}
   where \(\sigma > 0\) controls the softness of the projection.
3. Compute weighted displacements: Using the softmin weights, calculate the displacement vector for each correspondence point:
   \begin{equation}
   \Delta_i = \sum_{j=1}^K W_{ij} (\ve_j - \ci_i)
   \end{equation}
4. Update correspondences: Compute the projected correspondence locations by adding the displacement vectors to the initial correspondences:
   \begin{equation}
       \ci_i^{\text{proj}} = \ci_i + \Delta_i
   \end{equation}
The updated correspondences \(\ci_i^{\text{proj}}\) are then used in the Chamfer distance calculation (Eq. \ref{chamfer_likelihood}).

\item \textit{Vertex Masking and Perturbation:} \model~employs vertex masking and perturbations as a self-supervised learning approach for effective data augmentation. By randomly masking vertices and introducing small perturbations, we challenge the model to reconstruct complete, accurate shapes from partial or noisy inputs. This process generates diverse training examples and encourages the model to learn rich, meaningful shape representations. 

\item \textit{Aleatoric Uncertainty Estimation:} \model~leverages the probabilistic formulation of the modified M-AE with NF to estimate aleatoric uncertainty in predicted correspondences. Unlike epistemic uncertainty (which stems from model limitations), aleatoric uncertainty arises from inherent data noise or ambiguity. This estimation is crucial for assessing the reliability of predictions in different regions of the shape. The process quantifies aleatoric uncertainty as the variance of the conditional distribution \(p(\C_n|\z_n)\). Mathematically, we:
\begin{enumerate}
    \item For a given input mesh \(\X_n\), we sample multiple latent encoding: \(\z^{(s)}_n\sim \mathcal{N}(\z_n|\mu_{\z},\sigma_{\z})\), and \(s=1,\ldots,S\) represents the samples
    \item Get the correspondences for all the samples: \(\C^{(s)}_n=f_{\theta}(\z^{(s)}_n)\)
    \item Fit a Gaussian distribution to the decoded predictions: \(\mathcal{N}(\C_n|\mu,\sigma)\)
\end{enumerate}
The variance \(\sigma^2\) of this fitted Gaussian represents the aleatoric uncertainty, highlighting regions of higher prediction ambiguity or noise. This approach assumes that the prediction distribution is approximately Gaussian, which may not always hold. However, it provides a computationally efficient way to estimate uncertainty, enabling more informed decision-making in downstream tasks such as shape analysis or reconstruction.

\end{enumerate}
These enhancements collectively overcome the challenges faced in Mesh2SSM, including the difficulties in training SP-VAE and the complexities of the loss function. By integrating a bidirectional flow, simplifying the loss calculation, and adding a surface projection step, \model~provides a more robust, efficient, and anatomically accurate solution for statistical shape modeling from meshes.

