[
  {
    "index": 0,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      },
      {
        "key": "kojima2022large",
        "author": "Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke",
        "title": "Large language models are zero-shot reasoners"
      },
      {
        "key": "fu2022complexity",
        "author": "Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar",
        "title": "Complexity-based prompting for multi-step reasoning"
      },
      {
        "key": "stechly2024chain",
        "author": "Stechly, Kaya and Valmeekam, Karthik and Kambhampati, Subbarao",
        "title": "Chain of thoughtlessness: An analysis of cot in planning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yao2023beyond",
        "author": "Yao, Yao and Li, Zuchao and Zhao, Hai",
        "title": "Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2022program",
        "author": "Wenhu Chen and Xueguang Ma and Xinyi Wang and William W. Cohen",
        "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      },
      {
        "key": "cobbe2021training",
        "author": "Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others",
        "title": "Training verifiers to solve math word problems"
      },
      {
        "key": "kumar2024training",
        "author": "Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others",
        "title": "Training language models to self-correct via reinforcement learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chen2024can",
        "author": "Chen, Yanan and Pesaranghader, Ali and Sadhu, Tanmana and Yi, Dong Hoon",
        "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example"
      },
      {
        "key": "xie2024travelplanner",
        "author": "Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu",
        "title": "Travelplanner: A benchmark for real-world planning with language agents"
      },
      {
        "key": "valmeekam2024llms",
        "author": "Valmeekam, Karthik and Stechly, Kaya and Kambhampati, Subbarao",
        "title": "LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench"
      },
      {
        "key": "mirzadeh2024gsm",
        "author": "Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad",
        "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models"
      },
      {
        "key": "wang2024planning",
        "author": "Wang, Kevin and Li, Junbo and Bhatt, Neel P and Xi, Yihan and Liu, Qiang and Topcu, Ufuk and Wang, Zhangyang",
        "title": "On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability"
      },
      {
        "key": "xie2024revealing",
        "author": "Xie, Jian and Zhang, Kexun and Chen, Jiangjie and Yuan, Siyu and Zhang, Kai and Zhang, Yikai and Li, Lei and Xiao, Yanghua",
        "title": "Revealing the Barriers of Language Agents in Planning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "jiang2023llm",
        "author": "Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen",
        "title": "Llm-blender: Ensembling large language models with pairwise ranking and generative fusion"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2024mixture",
        "author": "Wang, Junlin and Wang, Jue and Athiwaratkun, Ben and Zhang, Ce and Zou, James",
        "title": "Mixture-of-Agents Enhances Large Language Model Capabilities"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "guo2024large",
        "author": "Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang",
        "title": "Large language model based multi-agents: A survey of progress and challenges"
      },
      {
        "key": "wang2024rethinking",
        "author": "Wang, Qineng and Wang, Zihao and Su, Ying and Tong, Hanghang and Song, Yangqiu",
        "title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"
      },
      {
        "key": "liu2024agentlite",
        "author": "Liu, Zhiwei and Yao, Weiran and Zhang, Jianguo and Yang, Liangwei and Liu, Zuxin and Tan, Juntao and Choubey, Prafulla K and Lan, Tian and Wu, Jason and Wang, Huan and others",
        "title": "AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System"
      },
      {
        "key": "hong2023metagpt",
        "author": "Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others",
        "title": "Metagpt: Meta programming for multi-agent collaborative framework"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "shazeer2017outrageously",
        "author": "Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff",
        "title": "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2023think",
        "author": "Li, Xin-Ye and Xue, Jiang-Tian and Xie, Zheng and Li, Ming",
        "title": "Think outside the code: Brainstorming boosts large language models in code generation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lee2023teaching",
        "author": "Lee, Nayoung and Sreenivasan, Kartik and Lee, Jason D and Lee, Kangwook and Papailiopoulos, Dimitris",
        "title": "Teaching arithmetic to small transformers"
      }
    ]
  }
]