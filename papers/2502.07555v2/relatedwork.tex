\section{Related Work}
% In this section, we make discussions on the related literature from two perspectives: the progress on dense retrieval, and the introduction of reasoning capability to LLMs.  

\subsection{Dense Retrieval}
Dense retrieval has made significant strides in retrieval precision, driven by the advancements in foundation models and training techniques. Early breakthroughs involved fine-tuning preliminary pre-trained models, such as BERT and RoBERTa \cite{devlin2018bert,liu2019roberta}, for dense retrieval, which already demonstrated competitive performance compared to traditional methods like BM25. At the same time, the scope of dense retrieval was substantially expanded thanks to the adoption of multi-lingual \cite{izacard2022unsuperviseddenseinformationretrieval,chen_bge_2024} and multi-modal pre-trained models \cite{wei2024uniir,zhou2024vista}. The introduction of more advanced training strategies, such as retrieval-oriented adaptation \cite{xiao_retromae_2022,liu_retromae-2_2023,wang_simlm_2023}, hard negative mining \cite{xiong_approximate_2020}, batch size expansion \cite{qu2020rocketqa}, and knowledge distillation from cross-encoders \cite{hofstatter_efficiently_2021}, has continually contributed to the improvement of dense retrieval's performance. 

In addition to the improvement on retrieval accuracy, it becomes increasingly emphasized to develop multi-task retrievers for general-purpose retrieval applications. Recent studies showed that the retrievers' generalization ability can be substantially enhanced by scaling-up the training scale \cite{su2022one} and model architecture \cite{ni_large_2022}. Based on these inspirations, people have made significant expansion of pre-training and fine-tuning tasks, leading to a series of popular retrievers for general-purpose applications, such as BGE, E5, and GTE \cite{wang2022text,li2023towards}. Meanwhile, people also introduce large language models (LLMs) as the retrievers' backbones, which brings forth significant improvements in retrieval performance. For example, RepLLaMA presents a powerful dense retriever by directly fine-tuning a pre-trained Llama \cite{wang2023improving}. Llama2Vec further enhances RepLLaMA by incorporating unsupervised adaptation of the pre-trained Llama \cite{li_llama2vec_2024}. Promptriver~\cite{weller_promptriever_2024}, built on RepLLaMA, equips the retrieval model with the capability to follow instructions. Methods like NV-Embed and ICL-Embedder achieves additional improvement through continual training with extensive fine-tuning data \cite{lee2024nv,li2024making}. Today, LLM-powered retrievers have dominated nearly all major benchmarks in IR-related evaluation. 

Despite these remarkable advancements, existing methods are primarily designed for direct semantic matching in popular applications like web search and question-answering. They still face challenges with zero-shot retrieval in completely new scenarios that differ significantly from their source domains \cite{gao2022precise,zhu2023large}. In addition, they are insufficient for more complex retrieval tasks which require intensive reasoning to identify semantic relationships \cite{su2024bright}. 

\subsection{LLMs' Reasoning Ability} 
The reasoning capabilities of large language models (LLMs) have been significantly enhanced with techniques that simulate human-like problem-solving processes. A major breakthrough in this area is Chain-of-Thought (CoT) \cite{wei2022chain}, which prompts LLMs to tackle complex problems by decomposing them into multiple reasoning steps. Building on this progress, the Self-Consistency method improves reasoning robustness by sampling multiple reasoning paths from the LLM and selecting the final answer through majority voting \cite{feng2024towards}. For scenarios requiring more exploratory reasoning, the Tree of Thoughts (ToT) method \cite{yao2024tree} extends CoT by structuring the problem-solving process as a tree. At each node, the LLM generates candidate intermediate steps, evaluates their feasibility, and backtracks from dead ends. Further advancing this paradigm, Graph of Thoughts (GoT) \cite{besta2024graph} replaces the tree structure with a directed acyclic graph (DAG), enabling LLMs to merge or refine reasoning steps as needed. The reasoning capability of large language models (LLMs), or the "think before action" workflow, represents a new paradigm that sets them apart from traditional language models. In addition to the usual strategies of scaling model size, datasets, and training computation \cite{kaplan2020scaling, hoffmann2022training}, the expansion of inference computation, or test-time scaling \cite{wu2024inference, chen2024llmcallsneedscaling, sardana2023beyond}, becomes another important factor in driving the improvement of LLMs. This capability has been significantly enhanced and showcased by recent reasoning-capable LLMs, such as OpenAI's O1 and O3, DeepSeek's R1 \cite{guo2025deepseek}, and Gemini 2.0\footnote{https://deepmind.google/technologies/gemini/flash-thinking/}. These models adopt a "slow-thinking" approach when handling complex problems: instead of providing an immediate answer, they first generate verbose, structured reasoning before arriving at a final solution. This method has allowed LLMs to achieve elite-level performance in areas like coding and mathematical proofs. 

The reasoning capability also offers a significant advantage in addressing the challenges posed by traditional retrieval methods. However, current embedding models primarily focus on generating discriminative data representations, which leaves the development of reasoning capabilities largely unexplored. 

% Inspired by O1 model, O1 Embedder pioneer the integration of LLM reasoning into embedding models. By generating query specific insights, the model can have a deeper understanding of the user's query, achieving better retrieval results.


% \clearpage