% \section{Discussion}
% \subsection{How to proof merge is necessary and how the hypothesis of update cycle been proofed?}
% To proof cycle hypothesis we doing a easily experiment on all of our experimental LLMs under learning rate of 1e-3 to compare the catastrophic forgetting performance on 1 step merge and 200 step merge, and the result are under the table:

% You can easily observed that although 200 step merge still keep some capabilities it still obviously has a lower performance compared with merge 1 and we suppose that the problem may caused by in 200 step merge it started step in cycle 2 or more but not fully chaos and in our other easy experiment while trying not using merge the feedback will become out totally worse and LLMs almost forget everything they have learned before. 

% \subsection{Why we update the basic parameters or tracking SECURA parameters but never changed C and R?}
% To address this questions we may notice that, to preserve former knowledge inside of LLMs, We assume that higher norm parameters with more important messages and lower one not, which means that the C and R we initialized is the not important columns and rows and our goals is to limit former important knowledge unchanged so it is necessary to make the C and R not changed which are used to spot out the real place we would like to update and label out where we need preserved in your LLMs.

% \subsection{What is the other benefit of SECURA compare with other catastrophic function such as EWC or Experience Replay while using type one merge fine-tuning method?}
% We are willing to address the outperformance of our model in catastrophic forgetting but it is obviously shown in our experiment 3, so at this place we may point out the advantages in litter weight, no more former datasets and easy to establish.
% \subsubsection{litter weight}
% In some types of prevent the catastrophic forgetting fine-tuning method like EWC, cause they are needed using fisher matrix or other method to detect the changing between now and before they need to save the former parameters, but in ours type 1 merge even don't need any more space consume by using froze basic weight. While in type 2 merge we only need to adding two pretty small parameters matrix by save the former change using the tracking SECURA, so our SECURA is space effiency.
% \subsubsection{No more former datasets}
% In other types of method that prevent catastrophic forgetting, they may using former datasets to help LLMs remember the knowledge like Experience Replay. Obviously it is time consuming and cost more calculate waste. By using SECURA to fine-tuning the models it will not using former knowledge and gain well performance at the same time.
% \subsubsection{Easy to establish}
% Above two method are needed extra preparation to start their training but in SECURA you can just start it without any more operations just like to fine-tuning a LoRA, so it is obvioursly also a advantage.


\section{Discussion}

\subsection{Why Do We Update the Basic Parameters or Track SECURA Parameters But Never Change \(C\) and \(R\)?}

We assume that parameters with higher norms carry more important information while lower-norm parameters are considered less important. The columns and rows \( C \) and \( R \) we initialized are represent the less important parameters' positions. Our goal is to keep the former important knowledge intact, which means it is necessary to prevent changes to \( C \) and \( R \) which are used to identify the locations that should be updated. By keeping \( C \) and \( R \) unchanged, we ensure that the critical information in the LLM is protected, while non-critical parameters can be updated or fine-tuned as needed.

\subsection{What Are the Other Benefits of SECURA Compared to Other Catastrophic Forgetting Methods?}

Since we are already shows SECURA's performance in our experiments. Here, we will point out the benefits of using SECURA over other methods like EWC or Experience Replay, specifically in terms of efficiency and simplicity.

\subsubsection{Smaller Weight}

Traditional methods like EWC rely on the Fisher matrix to detect changes between current and previous parameters, requiring the storage of previous parameters, which increases computational costs and space requirements. In contrast, SECURA as a PEFT fine-tuning method can be outperforming with even lower parameters compared to basic LoRA training~\ref{app:hyper_param}. 

\subsubsection{No Need for Former Datasets and Calculation}

Methods like Experience Replay store and reuse previous datasets to prevent catastrophic forgetting, but this comes at the cost of time and computational resources. SECURA, however, does not require past data and still performs effectively. This eliminates the need for dataset storage and reuse, making SECURA a more resource-efficient solution.

% \subsubsection{Easy to Establish}

% Both EWC and Experience Replay require additional preparation steps before training begin, which adds complexity. In contrast, SECURA allows fine-tuning the model without any additional operationsâ€”just like fine-tuning a LoRA model. This makes SECURA much easier to implement and more accessible for practical applications.