\begin{table}[t]
\vspace{-.05in}
\centering
\resizebox{0.47\textwidth}{!}{%
\begin{tabular}{cc|cc|cc|cc}
\toprule
\midrule
\multirow{2}{*}{Model}                                               & \multirow{2}{*}{Method} & \multicolumn{2}{|c|}{SST2}          & \multicolumn{2}{c|}{Open Question} & \multicolumn{2}{c}{SMS Spam}      \\
                                                                     &                         & auROC           & auPRC           & auROC           & auPRC           & auROC           & auPRC           \\\midrule
\multirow{2}{*}{-}                                                   & Prompt-Guard-86M        & 0.5000          & 0.4997          & 0.5000          & 0.5000          & 0.5000          & 0.4910          \\
                                                                     & PPL Detection           & 0.6043          & 0.6136          & 0.7138          & 0.7096          & 0.5818          & 0.5823          \\\midrule
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}8B\\ (LoRA)\end{tabular}} & Llama-Guard-3-1B        & 0.4866          & 0.4932          & 0.4985          & 0.4992          & 0.5294          & 0.5065          \\
                                                                     & Llama-Guard-3-8B        & 0.4978          & 0.4997          & 0.4955          & 0.5000          & 0.4877          & 0.4910          \\
                                                                     & Granite-Guardian-3.1-8B & 0.1290          & 0.3281          & 0.1853          & 0.3420          & 0.2049          & 0.3395          \\
                                                                     & LLM-based detection     & 0.9591          & 0.9311          & 0.9014          & 0.8750          & 0.8876          & 0.8176          \\
                                                                     & OpenAI Moderation       & 0.4973          & 0.4985          & 0.4985          & 0.4993          & 0.4984          & 0.4904          \\
                                                                     & Ours                    & \textbf{0.9994} & \textbf{0.9995} & \textbf{0.9597} & \textbf{0.9669} & \textbf{0.9924} & \textbf{0.9945} \\\midrule
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}8B\\ (Full)\end{tabular}} & Llama-Guard-3-1B        & 0.4789          & 0.4895          & 0.4909          & 0.4955          & 0.5017          & 0.4919          \\
                                                                     & Llama-Guard-3-8B        & 0.4984          & 0.4997          & 0.4970          & 0.5000          & 0.4965          & 0.4910          \\
                                                                     & Granite-Guardian-3.1-8B & 0.1566          & 0.3337          & 0.1720          & 0.3391          & 0.2848          & 0.3623          \\
                                                                     & LLM-based detection     & 0.9625          & 0.9476          & 0.9092          & 0.8820          & 0.8439          & 0.7766          \\
                                                                     & OpenAI Moderation       & 0.4984          & 0.4990          & 0.4970          & 0.4988          & 0.4984          & 0.4904          \\
                                                                     & Ours                    & \textbf{0.9668} & \textbf{0.9781} & \textbf{0.9910} & \textbf{0.9936} & \textbf{0.9363} & \textbf{0.9573} \\
\midrule
\bottomrule
\end{tabular}%
}
\vspace{-.1in}
\caption{Comparison of detection performance on backdoor attacks (Trigger: \textcolor{red}{cf}).}\label{tbl:backdoor_attacks_performance_cf}
\vspace{-.2in}
\end{table}