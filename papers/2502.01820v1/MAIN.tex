
% !TEX encoding = ITF-8 Un scaled x ticks=base 10:2,icode
% !TEX TS-program = pdflatex
%internal report
%--------.---------.---------.---------.---------.---------.---------.-e
\documentclass[a4paper]{paper_cw}

% PACKAGES TO BE USED
\usepackage{helvet}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{graphics}
\usepackage[numbers]{natbib}
\usepackage{color}
\usepackage{fancyhdr} % must be loaded for header/footer
\usepackage{colortbl} % must be loaded for \columncolor
%\usepackage{subfigure}
\usepackage[dvips]{graphicx} % must be loaded to scale graphics
%\usepackage[misc]{ifsym}
\usepackage{marvosym}
\usepackage{float}

\usepackage{array} 
\usepackage{framed}
\usepackage{subcaption}

\usepackage{pgfplots}
\usepackage{tcolorbox}
\usepackage{multirow}
\usepackage{bm}
\usepackage{url}
\usepackage{relsize}
%\usepackage{unicode-math}
\usepackage{ulem}

\usepackage{listings}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\lstset{frame=tb,
  language=Python}

\usepackage[colorlinks=true, allcolors=blue]{hyperref}

% 


%Begin Document
\begin{document}
\include{definitions}

%\title{From Data-driven to Physics-informed Deep Neural Operators for Temperature-Field Estimation in Additive Manufacturing Applications: Potentials and Drawbacks}

\title{Physics-Informed Surrogates for Temperature Prediction of Multi-Tracks in Laser Powder Bed Fusion}

\author{H. Safari, $^{1}$ (\Letter), H. Wessels$^{1}$}

\institute{(1) Institute of Applied Mechanics, Technische Universtität Braunschweig, Pockelsstraße 3, 38106 Braunschweig
\email{hesameddin.safari@tu-braunschweig.de}\\}

\maketitle
\thispagestyle{empty}

\abstract{Modeling plays a critical role in additive manufacturing (AM), enabling a deeper understanding of underlying processes. Parametric solutions for such models are of great importance, enabling the optimization of production processes and considerable cost reductions. However, the complexity of the problem and diversity of spatio-temporal scales involved in the process pose significant challenges for traditional numerical methods. Surrogate models offer a powerful alternative by accelerating simulations and facilitating real-time monitoring and control. The present study presents an operator learning approach that relies on the deep operator network (DeepONet) and physics-informed neural networks (PINN) to predict the three-dimensional temperature distribution during melting and consolidation in laser powder bed fusion (LPBF). Parametric solutions for both single-track and multi-track scenarios with respect to tool path are obtained. To address the challenges in obtaining parametric solutions for multi-track scenarios using DeepONet architecture, a sequential PINN approach is proposed to efficiently manage the increased training complexity inherent in those scenarios. The accuracy and consistency of the model are verified against finite-difference computations. The developed surrogate allows us to efficiently analyze the effect of scanning paths and laser parameters on the thermal history.
}

\keywords{physics-informed neural networks, operator learning, additive manufacturing, powder bed fusion}


\section{Introduction}\label{sec:Introduction}
Additive manufacturing (AM) provides great opportunities to efficiently design and fabricate individualized components. It also offers unparalleled flexibilities for fabricating metamaterials that are impossible to create with conventional processes. However, the complexities of AM processes have posed great challenges in maintaining consistent quality, necessitating careful optimization of process parameters. For instance, in Laser Powder Bed Fusion (LPBF), various process parameters play a crucial role. These include laser characteristics such as power, spot size, and scanning speed, as well as scan strategies like hatch spacing and scan patterns, to name just a few. Each parameter influences the quality, precision, and mechanical properties of the final product.

Numerical simulations based on governing partial differential equations (PDEs) provide us with valuable information and insights about the underlying physics which gives us the possibility to perform optimization studies.  AM is often characterized by multi-scale, complex, and rapid physical phenomena that can span more than 3–4 orders of magnitude in both spatial resolution and temporal scales~\cite{markl2016multiscale}. This vast range presents significant challenges in terms of computational resources and algorithmic complications with established numerical schemes, such as finite-element method (FEM)~\cite{schoinochoritis2017simulation, sarkar2024advances}, finite-difference method (FDM)~\cite{foteinopoulos2018thermal}  and finite-volume method (FVM)~\cite{li2023efficient}. Thus, parametric solutions and parametric studies in terms of process parameters that are needed for conducting such optimizations are not feasible using classical numerical algorithms for real applications. Surrogate modeling can play an important role in bridging the gap between the need for computationally efficient solutions and the complexity of numerical simulations. Surrogate models allow for the rapid exploration of a wide parameter space, making optimization studies feasible even for computationally intensive AM simulations. In addition, they facilitate real-time predictions and process adjustments by significantly reducing computational requirements.

The reduced-order modeling approach is one of the most widely used methods in AM for development of surrogate models, especially for computation of the temperature history. Zheng \textit{et al.}~\cite{zheng2017modeling} have presented a method for modeling and controlling the cooling rate in laser additive manufacturing. The partial differential equation governing the process is transformed and approximated using the proper orthogonal decomposition (POD) method. The study also explores cooling rate control strategies, including feed-forward control based on steady-state solutions and feedback control to maintain desired thermal profiles. POD-based models rely on the linear superposition of modes, which may struggle to accurately capture complex, nonlinear dynamics, particularly in the context of nonlinear, time-dependent, parameterized PDEs~\cite{fresca2021comprehensive, agarwal2024parameter}. As a remedy, proper generalized decomposition (PGD) model has been developed by Favoretto \textit{et al.}~\cite{favoretto2019reduced} to account for highly transient temperature evolutions in LPBF. They reported a simulation speed-up of at least one order of magnitude relative to standard techniques. However, significant challenges arise when applying PGD to transient thermal problems involving a moving heat source. The performance of PGD models is highly sensitive to factors such as the choice of discretization method, the size of the heat source, and material parameters~\cite{strobl2024pgd}. Addressing these challenges often requires problem-specific treatments to ensure accuracy and stability of the model.

%\HW{POD is challenging for non-linear models as coefficients need to be recomputed, but it is not impossible. Also I am not sure about PGD: what is the difference to POD? Is it really better than POD for non-linear problems, as is written here?}

On the other hand, machine learning (ML)-based methods offer significant advantages for presenting surrogates for AM. Their ability to model complex, nonlinear relationships, enables accurate representation of complicated process dynamics. By integrating multi-fidelity data from various sources, these models enhance prediction accuracy and reliability~\cite{demo2023deeponet}. Once trained, ML models deliver real-time predictions, supporting timely monitoring and control of manufacturing processes. For instance, Yaseen \textit{et al.}~\cite{yaseen2023fast} have developed fast and accurate reduced order models for AM processes using operator learning techniques, such as the Fourier Neural Operator (FNO~\cite{li2020fourier}) and Deep Operator Network (DeepONet~\cite{lu2021learning}). These methods effectively predict time-dependent responses in AM models, enhancing process optimization. Chen \textit{et al.}~\cite{chen2024capturing} proposed a data-driven model using a Fourier neural operator to capture local temperature evolution in wire-based directed energy deposition (DED) AM. Their results showed that the model accurately predicts temperature changes regardless of geometry. However, the main limitation of the presented model is that it is only applicable to a single toolpath. In~\cite{kim2022tool}, a convolutional neural network (CNN) has been trained based on the numerical simulations in order to predict the optimal laser paths during selective laser sintering (SLS) process. Supervised data-driven ML models require large, high-quality datasets for training. Obtaining such data can require significant resources for AM processes. Moreover, the accuracy and generalizability of the models heavily depend on the quality and diversity of the available data.

Physics-informed neural networks (PINNs)~\cite{raissi2019physics} represent an innovative approach which addresses the limitations of purely data-driven deep learning frameworks. By incorporating underlying physics (in the form of well-known PDEs or other physical constraints) in the loss function, PINNs ensure that the model respects the established governing laws. This integration not only enhances the interpretability of the network but also significantly improves its generalization capabilities, even in the absence of extensive simulation/experimental data. Nevertheless, data can support the training process, see~\cite{anton2024deterministic}. The paradigm of PINNs has recently captured the attention of the AM community as a promising tool for developing parametric surrogate models. The efforts in this direction has been initiated by the pioneering work of Zhu \textit{et al.}~\cite{zhu2021machine}, in which they employed the Navier-Stokes equations together with the energy equation into a PINN to compute the temperature and meltpool dynamics in LPBF. They demonstrated that the PINN can accurately predict the meltpool dimensions and the temperature distribution using only a limited amount of labeled training data. Nevertheless, they only considered a forward non-parametric solution for the problem in question. Xie \textit{et al.}~\cite{xie20223d} have solved the transient heat conduction equation with a PINN to compute the three-dimensional temperature fields in single-layer and multi-layer DED processes. Similarly, Li \textit{et al.}~\cite{li2023physics} presented a PINN framework for temperature prediction in laser metal deposition processes without labeled data. Both deposition and cooling stages have been considered in their study. They employed transfer learning across scenarios with varying manufacturing parameters to enable faster predictions while maintaining accuracy. 

Liao \textit{et al.}~\cite{liao2023hybrid} have developed a hybrid thermal modeling approach for a DED process that integrates physics-based principles with data-driven techniques using PINNs. By combining partially observed temperature data from infrared camera measurements with fundamental physics laws, the method enables the prediction of full-field temperature histories and the identification of unknown material properties (including the heat capacity and the material thermal conductivity) as well as process parameters such as laser absorptivity. In another study, Hosseini \textit{et al.}~\cite{hosseini2023single} investigated the applicability of parametric PINNs in order to obtain the parametric solutions of LPBF process over a wide range of material properties and process parameters. They reported a Mean Absolute Error of below 5\% for the temperature and the meltpool sizes relative to FEM solutions for all the considered benchmark tests. In later work, the authors integrated a parametric PINN with a cellular automata (CA) microstructure model to calibrate a thermo-microstructural model based on single-track LPBF experiments~\cite{tang2024calibration}. The trained PINN provided parametric solutions in terms of process conditions and heat source model parameters. To minimize the discrepancies between simulation and experiment, they conducted an inverse analysis to optimize the thermal model's unknown parameters. A recent review on different approaches for the calibration of numerical models (including PINN) from full-field data can be found in \cite{romer2024reduced}.

All the aforementioned PINN frameworks have been limited to single-track AM processes. To the best of our knowledge, no foundational study has explored the application of PINNs for multi-track AM processes. This is particularly important since tool path selection directly impacts build quality, mechanical properties, and thermal management~\cite{kim2022tool,flores2019toolpath}. Efficient paths also reduce build time, material waste and improve overall process efficiency~\cite{xiong2019process}. Hence, in this research, we explore the potential of developing PINN surrogate models and physics-informed neural operators for multi-track laser AM applications. We pay special attention to neural operators (more specifically, DeepONet), due to its robust theoretical foundation for approximating operators that map between function spaces. This makes DeepONet a promising candidate to create surrogate solvers for parametric PDEs. Within this framework, each laser path can be considered as an input function to the PDE of the heat equation. We compare the physics-informed DeepONet (PI-DeepONet) with PINN in terms of the their performance and accuracy for multi-track scenarios. Moreover, we propose a sequential-PINN framework to efficiently account for different laser paths.

The rest of this paper is structured as follows. In Section~\ref{sec:methodology}, we first describe the numerical implementation of the heat equation using a finite-difference scheme and then present the physics-informed deep learning frameworks, including the formulation of the PI-DeepONet and a sequential PINN strategy for multi-track scenarios. In Section~\ref{sec:result}, we report and discuss the results obtained for both single-track and multi-track cases, comparing the surrogate models with reference finite-difference solutions in terms of temperature distributions and meltpool dimensions. Finally, Section~\ref{sec:conclusion} concludes with a summary of the key findings, along with an outlook on future work.
%to enrich real-time monitoring and control in AM processes.


\section{Methodology} \label{sec:methodology}

The heat equation that describes the distribution of temperature in a given region over time is derived from the conservation of energy. Neglecting the convective and heat dissipation loss terms, the partial differential equation for the evolution of temperature in time-space domain can be written as, 
\begin{equation}\label{eq:heat}
    \rho c_p \partial_t T + \nabla \cdot  \tenq = q_v,
\end{equation}
where $\rho$ denotes the density, $c_p$ the heat capacity, $T$ the temperature, $\tenq$ the heat flux and $q_v$ a volumetric heating term. For the heat flux, we consider Fourier type heat conduction with $\tenq = - \kappa(T(\vecx)) \nabla T$, where $\kappa$ is temperature-dependent thermal conductivity. Thus, \eqref{eq:heat} can be written as
\begin{equation}\label{eq:temperature}
    \rho c_p \partial_t T = \kappa \nabla^2 T + \nabla \kappa \cdot \nabla T + q_v.
\end{equation} 
The heat equation \eqref{eq:temperature} is subject to Dirichlet and Neumann boundary conditions as follows
\begin{equation}
    \begin{aligned}
        T &= \bar{T} \, &\text{on} \, \Gamma^{\theta}_D \\
        \vecq \cdot \vecn &= \bar{q} \, &\text{on} \, \Gamma^{q}_N.
    \end{aligned}
\end{equation}
The implementation of the laser heating can be either achieved via a volumetric heat source or application of a proper heat flux as the boundary condition on the top surface. In this study, the volumetric heat source is applied using the moving Gaussian point heat source. Assuming a hemispherical Gaussian distribution of power density for a moving laser in $xy$ plane, $q_v$ is given by~\cite{hosseini2023single},
\begin{equation}
    \label{eqn:qlaser}
    \begin{aligned}
        q_v(x,y,z,t) = \eta \frac{6 \sqrt{3} P}{r^3 \pi \sqrt{\pi}}
        \text{exp} \left( {-3{\frac{(x - x_l)^2 + (y - y_l)^2 }{r^2}}} \right)
        \text{exp} \left( {-3{\frac{z^2 }{c^2}}} \right),
    \end{aligned}
\end{equation}
where $P$ represents the laser power, $\eta$ the laser absorption coefficient, $x_l$ and $y_l$ the location of the laser beam in $xy$ plane, $r$ the laser radius and $c$ the laser penetration depth.


\subsection{Solving Heat Equation using Finite-Difference Method (FDM)} \label{subsec:fdm}

Discretizing \eqref{eq:temperature} using explicit finite difference with a forward Euler scheme in time, the temperature at each time step can be computed by,
\begin{equation}
    \label{eqn:fd}
    \begin{aligned}
        T(t+\delta t,x,y,z) &= T(t,x,y,z) + \frac{\delta t}{\rho c_p} \left[
        \kappa(x,y,z)\left( D_x + D_y + D_z\right) + K_x + K_y + K_z + q_v
        \right] \\
    \end{aligned}
\end{equation}
where
\begin{equation}
    \begin{aligned}
        D_x &= \frac{\partial^2 T}{\partial x^2} = \frac{T(t,x + \delta x,y,z) - 2T(x,y,z) + T(t,x - \delta x,y,z)}{\delta x^2} \\
        D_y &= \frac{\partial^2 T}{\partial y^2} = \frac{T(t,x,y+\delta y,z) - 2T(x,y,z) + T(t,x,y - \delta y,z)}{\delta y^2}\\
        D_z &= \frac{\partial^2 T}{\partial z^2} = \frac{T(t,x,y,z+\delta z) - 2T(x,y,z) + T(t,x,y,z-\delta z)}{\delta z^2} \\
        K_x = \frac{\partial \kappa}{\partial x}\frac{\partial T}{\partial x} &= \frac{\kappa(x + \delta x,y,z) - \kappa(x - \delta x,y,z)}{2\delta x} \cdot \frac{T(t,x + \delta x,y,z) - T(t,x - \delta x,y,z)}{2\delta x}   \\
        K_y = \frac{\partial \kappa}{\partial y}\frac{\partial T}{\partial y} &= \frac{\kappa(x,y + \delta y,z) - \kappa(x,y - \delta y,z)}{2\delta y} \cdot \frac{T(t,x,y +\delta y,z) - T(t,x,y - \delta y,z)}{2\delta y}  \\
        K_z = \frac{\partial \kappa}{\partial z}\frac{\partial T}{\partial z} &= \frac{\kappa(x,y,z+\delta z) - \kappa(x,y,z-\delta z)}{2\delta z} \cdot \frac{T(t,x,y,z+\delta  z) - T(t,x,y,z - \delta z)}{2\delta z} .
    \end{aligned}
\end{equation}
In this manuscript, we use solutions obtained with finite differences as a baseline to benchmark the physics-informed surrogates under consideration.


\subsection{Physics-informed neural network architectures as heat equation solvers}\label{subsec:pi-deeponet}

\noindent \textbf{Standard PINN:} The core idea behind the PINN is to construct a deep neural network (DNN) that serves as a surrogate model (ansatz function) to the solution of the PDE. By incorporating appropriate activation functions, the output of the network is differentiable with respect to the inputs (here the spatiotemporal coordinates)~\cite{raissi2019physics, mao2020physics}. This enables the automatic differentiation of the required derivatives in order to introduce the underlying physics, namely the heat equation~\eqref{eq:temperature} as well as the corresponding boundary conditions. Implementing the latter in terms of a loss function, one can enforce the network to satisfy the governing PDEs by minimization of the total loss function. This enables us to estimate the PDE solution without any prior knowledge about the temperature distribution in an unsupervised manner. Hence, the learned solution remains consistent with the physics and mathematical models. This especially is of great interest, as obtaining data from Finite-Element (FE) simulations of AM applications for data-driven surrogate models could be cumbersome in terms of computational resources~\cite{hosseini2023single}. %Fig.~\ref{fig:pinn} schematically illustrates the PINN with a feed-forward neural network (FNN) for solving the heat equation.
In this context, collocation points across the domain are required to evaluate and enforce the governing physical laws. The low-discrepancy Sobol sampling method~\cite{sobol1967distribution} is employed for sampling the collocation points in time-space domain. Each collocation point can be viewed as a four-component vector in the form of $(t_i, x_i, y_i, z_i)$ or $(t_i, \mathbf{\hat{x}}_i)$. As suggested by Hosseini~\cite{hosseini2023single}, we use an adaptive clustering strategy in the vicinity of the heat source to ensure capturing sharp temperature gradients. The initial and boundary conditions and the PDE are enforced with the loss functions defined as follows,

%\begin{figure}[htb]
%    \centering
%    \includegraphics[width=0.85\linewidth]{Figures/PINN.pdf}
%    \caption{Schematic representation of PINN for solving the heat equation. \HW{I do not think this figure is needed.}}
%    \label{fig:pinn}
%\end{figure}

\begin{align}
    \mathcal{L}_\text{IC} &= \frac{1}{N_{IC}} \sum_{i=1}^{N_{IC}} \left| \mathcal{T}(t=t_0, \mathbf{\hat{x}}_i) - T_{0}(\mathbf{\hat{x}}_i) \right|^2, \label{eq:loss_ic} \\
    \mathcal{L}_{ \text{BC,Dirichlet}} &= \frac{1}{N_{BC}} \sum_{i=1}^{N_{BC}} \left| \mathcal{T}(t_i, \mathbf{\hat{x}}_i) - T_{BC}(t_i, \mathbf{\hat{x}}_i) \right|^2, \label{eq:loss_bc_d}  \\
    \mathcal{L}_{\text{BC,Neumann}} &= \frac{1}{N_{BC}} \sum_{i=1}^{N_{BC}} \left| \frac{\partial}{\partial n} \mathcal{T}(t_i, \mathbf{\hat{x}}_i) - \frac{\partial}{\partial n} T_{BC}(t, \mathbf{\hat{x}}_i)\right|^2, n \in \{x, y, z\}, \label{eq:loss_bc_n} \\
    \mathcal{L}_{\text{PDE}} &=  \frac{1}{N_{PDE}} \sum_{i=1}^{N_{PDE}} \left| \mathcal{R}_{PDE} (t_i, \mathbf{\hat{x}}_i) \right|^2, \label{eq:loss_pde}
\end{align}
where $N_\bullet$ is the total number of time-space data points in each dataset.
%\HW{This notation is very compact (I like it), but in order to be compatible with the DeepONet also, we should define collocation points for which we evaluate the loss in both the PINN section and the PI-EnDeepONet section. Intuitively I would expect the loss functions to be different, as you need to sample in different spaces. This can be accounted for by introducing a collocation points $\vecd_i=\left[t_,\hat{\vecx}_i\right] \, \forall i \in N_\bullet$ or sth like that....\\
%One more question regarding notation: Why does your x get a hat?}
$\mathcal{T}(t, \mathbf{\hat{x}})$ represents the output of the network, $T_0$ the value of the initial condition, $T_{BC}$ the assigned temperature on the related boundary and $\mathcal{R}_\text{PDE}$ the residuals of the governed PDE. To satisfy the heat equation on the collocation points inside the computational domain, the residuals of the PDE for the $i^{th}$ sample in the collocation points dataset is calculated as,
\begin{align} \label{pde_res}
    \mathcal{R}_\text{PDE}(t_i, \mathbf{\hat{x}}_i) &=  \rho c_p \frac{\partial \mathcal{T}(t_i, \mathbf{\hat{x}}_i)}{\partial t} - \frac{\partial}{\partial x} \left( \kappa \frac{\partial \mathcal{T}(t_i, \mathbf{\hat{x}}_i)}{\partial x} \right) - \frac{\partial}{\partial y} \left( \kappa \frac{\partial\mathcal{T}(t_i, \mathbf{\hat{x}}_i) }{\partial y} \right) \\
    & - \frac{\partial}{\partial z} \left( \kappa \frac{\partial \mathcal{T}(t_i, \mathbf{\hat{x}}_i)}{\partial z} \right)  - q_v(t_i, \mathbf{\hat{x}}_i).
\end{align}
%\begin{equation} \label{pde_res}
    %\mathcal{R}_\text{PDE}(t_i, \mathbf{\hat{x}}_i) = \HW{\Bigg (\rho c_p \frac{\partial }{\partial t} - \frac{\partial}{\partial x} \left( \kappa \frac{\partial }{\partial x} \right) - \frac{\partial}{\partial y} \left( \kappa \frac{\partial }{\partial y} \right) - \frac{\partial}{\partial z} \left( \kappa \frac{\partial }{\partial z} \right) \Bigg)} \mathcal{T}(t_i, \mathbf{\hat{x}}_i) - q_v(t_i, \mathbf{\hat{x}}_i).
%\end{equation}

Summing up the above-mentioned loss terms, the final loss function is given by,
\begin{equation}
    \label{loss_total}
    \mathcal{L}_\text{Total} =  \lambda_\text{IC}\mathcal{L}_\text{IC} +  \lambda_\text{BC}\sum_{i=1}^{M} \mathcal{L}_{\text{BC},i} +  \lambda_\text{PDE}\mathcal{L}_\text{PDE},
\end{equation}
with $M$ being the total number of boundary conditions. The regularization of total loss term is achieved by means of different weighting factors ($\lambda$) for each individual loss term. The values of the weighting factors are computed as follows,
\begin{equation}\label{eq:lambda}
\begin{aligned}
    \lambda_\text{IC} = \frac{1}{\mathcal{L}_{0,\text{IC}}} \\
    \lambda_\text{BC} = \frac{1}{\sum_{i=1}^{M} \mathcal{L}_{0,\text{BC},i}} \\
    \lambda_\text{PDE} = \frac{1}{\mathcal{R}_{0,\text{PDE}}}
\end{aligned}
\end{equation}
where the subscript '0' denotes the initial loss terms at the beginning of the training process at $t=0$.
\\

\noindent \textbf{Physics-informed En-DeepONet (PI-EnDeepONet):} Non-parametric forward PINNs as introduced above utilize time-space coordinates as input to the network. This architecture can also be extended to explore parametric solutions by incorporating additional dimensions into the input tensor, enabling PINNs to learn solutions across time-space-parameters domain~\cite{hosseini2023single, cao2024solving, panahi2025modeling}. For instance, for a fixed tool path in the laser AM process one can incorporate the process parameters (laser power, scan speed) as well as the material parameters (thermal conductivity, heat capacity etc.) into the network input along side the time-space data points to infer a parametric solution~\cite{hosseini2023single}. These parameters can be more or less seen as coefficients in the heat equation. However, if we aim to obtain parametric solutions for multiple laser paths or scan patterns, these constitute input functions.
%should be encoded by the network to infer consistent parametric solutions across different scenarios.
Therefore, we require networks capable of mapping input functions to output functions. Different neural operators have been proposed recently to learn mapping across function spaces including DeepONet~\cite{lu2021learning}, Fourier Neural Operator (FNO)~\cite{li2020fourier} and  wavelet neural operator (WNO)~\cite{tripura2023wavelet}.

Here, the DeepONet architecture is selected to obtain a spatiotemporal surrogate for predicting temperature in AM processes, including multi-track scenarios. Fig.~\ref{fig:deeponet} schematically illustrates the original DeepONet architecture \cite{lu2021learning} for the problem in question. The trunk net takes spatiotemporal coordinates are denoted by $(\mathbf{\hat{x}},t)$, where $\mathbf{\hat{x}} = (x, y, z)$ denotes the spatial coordinates and $t$ the time. The tool path (or laser path) for each scenario serves as the input function, $\mathbf{x}_l$, to the branch net. This input function should be represented discretely at fixed locations for all samples. Therefore, the coordinates of the path which the heat source travels during the process are discretized at fixed points in the time domain. The input function $\mathbf{x}_l$ is defined as,
\begin{figure}[t]
    \centering
    \includegraphics[width=0.50\linewidth]{Figures/DeepONet.pdf}
    \caption{Schematic representation of the original DeepONet.}
    \label{fig:deeponet}
\end{figure}

\begin{equation}\label{eq:input_function}
    \begin{aligned}
    %\mathbf{S}(t) &= (x_l,y_l),\\
    \mathbf{x}_l(t) &= \int_t \mathbf{v}_l(t) \, \text{d}t,
    \end{aligned}
\end{equation}
with $\mathbf{v}_l$ being the laser velocity vector on the $xy$-plane and $t$ the process time. Considering $n$ different scenarios for the tool path and $m$ equally-spaced points (or time steps) within the process time, the input function of $i^{th}$ scenario is represented as follows,
\begin{equation}
    \label{eq:s_i}
    \begin{aligned}
    \Big\{ \mathbf{x}_l^{(i)}(t_1), \mathbf{x}_l^{(i)}(t_2), \ldots, & \mathbf{x}_l^{(i)}(t_m) \Big\}.
    \end{aligned}
\end{equation}
According to Fig.~\ref{fig:deeponet}, the output of the network is computed by,
\begin{equation}\label{eq:output}
    \mathcal{T}(\mathbf{x}_l)(\mathbf{\hat{x}},t) \approx \sum_{k=1}^{p} \underbrace{N^B_k\big(\mathbf{x}_l(t_1), \mathbf{x}_l(t_2), \dots, \mathbf{x}_l(t_m)\big)}_{\text{Branch}} \underbrace{N^T_k(\mathbf{\hat{x}},t)}_{\text{Trunk}},
\end{equation}
where $N^B_k$ and $N^T_k$ represent the output of the branch and trunk nets, respectively.
\\

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.1\linewidth]{Figures/PI-EN-DeepONet.pdf}
    \caption{Schematic representation of the En-DeepONet with physics-informed loss functions.}
    \label{fig:pi-deeponet}
\end{figure}

Haghighat et al. \cite{haghighat2024deeponet} have recently found that the standard DeepONet shows severe limitations when applied to moving-solution operators. They proposed the enriched DeepONet (En-DeepONet), that instead of using a simple projection operator (dot product) for evaluating the final output, more operators including summation, subtraction and Hadamard (or element-wise) product are taken into account. This idea is demonstrated in Fig.~\ref{fig:pi-deeponet} and can be mathematically described as,

\begin{equation}
    \label{eqn:en_deeponet}
    \begin{aligned}
        \mathcal{T}(\mathbf{x}_l)(\mathbf{\hat{x}},t) &\approx \sum_{k=1}^{p} w_k^{\times} \Big(N^B_k\big(\mathbf{x}_l(t_1), \mathbf{x}_l(t_2), \dots, \mathbf{x}_l(t_m)\big) \cdot N^T_k(\mathbf{\hat{x}},t) \Big) \\
&+  \sum_{k=1}^{p} w_k^{+} \Big(N^B_k\big(\mathbf{x}_l(t_1), \mathbf{x}_l(t_2), \dots, \mathbf{x}_l(t_m)\big) + N^T_k(\mathbf{\hat{x}},t) \Big) \\
&+  \sum_{k=1}^{p} w_k^{-} \Big(N^B_k\big(\mathbf{x}_l(t_1), \mathbf{x}_l(t_2), \dots, \mathbf{x}_l(t_m)\big) - N^T_k(\mathbf{\hat{x}},t) \Big),
    \end{aligned}
\end{equation}
where each summation ($\sum$) can be considered as a linear layer with the weight factors of $w_k^{\bullet}$ with $\bullet \in \{\cdot,+,-\}$. These series of linear layers are depicted as the so-called root net in En-DeepONet part of Fig.~\ref{fig:pi-deeponet}. Adding physics-informed loss terms (Eqs.~\eqref{eq:loss_ic}-\eqref{eq:loss_pde}), the resulting En-DeepONet is called \pidon{}. This architecture is capable of learning the spatiotemporal evolution of the temperature across multiple tool paths all at once without any labeled data.

We will compare the outputs of the \pidon{} with the PINN counterpart in the following Sections. The presented PINN and \pidon{} share the same loss functions. Moreover, the feed-forward neural network (FNN) of the PINN is comparable with the trunk net in \pidon{} in terms of the number of hidden layers and the activation function. Note that we opt for constant weighting factors as computed by Eq.~\eqref{eq:lambda} and soft boundary conditions as given in Eqs.\eqref{eq:loss_bc_d}-\eqref{eq:loss_bc_n} as their more advanced counterparts (i.e. adaptive weighting factors~\cite{hou2023enhancing} and hard boundary conditions) did not improve the accuracy of the trained networks in our test cases. More information on the hyperparameters of the \pidon{} and PINN is given in Section~\ref{sebsec:criteria}.


\begin{table}[p]
\begin{center}
\caption{Material properties, process parameters, initial and boundary conditions for all test cases.}
\begin{tabular}{ll} 
 %\hline
 \textbf{Material Property} & \textbf{Value} \\ 
 \hline
 \hline
 Density ($\rho$) & 8351.91 $ \text{kg/} \text{m}^3$  \\ 
 Thermal conductivity ($\kappa$) & Eq.~\eqref{eq:prop}  \\ 
 Heat capacity ($c_p$) & Eq.~\eqref{eq:prop} \\ 
 %\hline
 \rule{0pt}{15pt}
 \textbf{Laser Parameter} & \textbf{Value} \\ 
 \hline
 \hline
 Modified laser power ($\eta \times P$) & 150.0 $\text{W}$ \\ 
 Laser beam radius & 450 $\mu\text{m}$ \\ 
 Laser beam scan speed & 0.1 $\text{m/s}$ \\ 
 %\hline
 \rule{0pt}{15pt}
 \textbf{Simulation Condition} & \textbf{Value} \\ 
 \hline
 \hline
 Initial temperature ($T_0$) & 300 $\text{K}$  \\ 
 Ambient temperature ($T_\infty$) & 300 $\text{K}$  \\ 
 Convection heat transfer coefficient ($h_{conv}$) & 10 $\text{W/(} \text{m}^2 \text{K)}$ \\ 
 %\hline
\end{tabular}
\label{tab:laser_parameter}
\end{center}
\end{table}




\subsection{Multi-track scenarios}

In this study, we deal with both single-track and multi-track case studies. In multi-track scenarios, the laser successively scans different tracks on the workpiece. In multi-track test cases, a scenario (or a path) is defined as the sequence of tracks. Hence, each scenario can be considered as the combination of multiple tracks. Assuming multi-track manufacturing with $n$ tracks per path as shown in Fig.~\ref{fig:multi_track_a}, the total number of $n!$ different scenarios can be recognized, each consisting of all $n$ tracks, where

\begin{equation}
\begin{aligned}
    n! &= \prod_{i=1}^{n} i \\
     &= n\cdot (n-1) \cdot ... \cdot 3 \cdot 2 \cdot 1.
 \end{aligned}
\end{equation}

In the next Section, we will observe that due to the curse of dimensionality, the \pidon{} faces difficulties when the number of tracks in each scenario increases. To address this challenges, each scenario is broken down into its constituent tracks. We aim to train a dedicated PINN for each track within each scenario. To solve for all possible scenarios, it is essential to identify all potential combinations of tracks that comprise each scenario. To have a better understanding of how individual scenarios are constructed from multiple tracks, we visualize the problem as a tree structure, as shown in Fig.~\ref{fig:multi_track_b}. In this representation, tracks are depicted as nodes, and each scenario is defined  by tracing the branches along the arrows from the top to the bottom nodes. In other words, we split each scenario into $n$ individual stages (or $n$ time intervals,  $T_i=\left[t_{(i-1)}, t_i\right] \, \forall \, i \in \left[1, n\right]$), which correspond to the time needed to process the related tracks. The total number of individual trained PINNs ($N^{\text{train}}$) required for computation of all paths is obtained from
\begin{equation}
    \label{eq:n_train}
    \begin{aligned}
        N^{\text{train}} =  \mathlarger{\sum_{i=0}^{n-1}} \prod_{j=0}^{i} (n-j).
    \end{aligned}
\end{equation}

In a given scenario, each track has both a predecessor and a successor, except for the first and last tracks, which only have a successor or predecessor, respectively. While the boundary conditions remain the same across all tracks, the initial condition of each track is unique and corresponds to the end-state of its predecessor. This ensures a continuous and physically consistent progression of the solution across the sequence of tracks. Once the training of each track is completed, the relevant weights and biases of the network are saved, allowing for efficient storage and retrieval. These trained models can be easily recalled whenever required. This methodology is referred to as Sequential PINN, as the complete solution for a given scenario is constructed by sequentially recalling the trained PINNs for each track within that scenario.

%\begin{figure}[!h]
%    \centering
%    \includegraphics[width=0.85\textwidth]{Figures/multi_track.pdf}
%    \caption{Representation of multi-track paths \HW{move to methodology section}}
%    \label{fig:multi_track}
%\end{figure}



\begin{figure}[h]
    \centering
    \begin{subfigure}{0.55\textwidth}
    \includegraphics[width=\textwidth]{Figures/multi_tracks_3d.pdf}
    \caption{}
    \label{fig:multi_track_a}
    \end{subfigure}
    \begin{subfigure}{0.85\textwidth}
    \includegraphics[width=\textwidth]{Figures/multi_track.pdf}
    \caption{}
    \label{fig:multi_track_b}
    \end{subfigure}   
    \caption{(a) Outline of multiple tracks on a workpiece. (b)Tree structure representation of breaking down multi-track scenarios into $n$ times intervals. Green colored nodes indicate the track numbers.}
    \label{fig:multi_track}
\end{figure}



\section{Results and Discussion} \label{sec:result}
%\subsection{Problem Definition} \label{subsec:defintion}
In this study, we focus on solving the transient heat equation within a three-dimensional computational domain, subject to the boundary conditions illustrated in Fig.~\ref{fig:domain}. The laser can scan along three parallel tracks, allowing for flexible path selection for both single-track and multi-track scenarios. In the single-track case, the laser processes only one of the three tracks at a time. However, in the multi-track scenario, each path is defined as a combination of multiple tracks (i.e. $1\rightarrow2\rightarrow3$, $ 2\rightarrow3\rightarrow1$ etc.). For this specific case which is depicted in Fig.~\ref{fig:domain}, $3!=6$ different paths can be identified, each comprising all three tracks. As a material, we consider Hastelloy X with the following temperature-dependent properties~\cite{hosseini2023single}:
                  
\begin{equation}
\label{eq:prop}
    \begin{aligned}
        \kappa &=  229.87 + 0.0184\,T + 225.10 \tanh \big( 0.0118(T-1816.8) \big)\: \textstyle \frac{W}{m K},\\
        c_p &= 407.62 + 0.142\,T - 61.43 \,\mathrm{e}^{-3.1\times10^{-4}(T-798)^2} + 1054.96 \, \mathrm{e}^{-6.2\times10^{-5}(T-1816.8)^2}\: \textstyle \frac{J}{kg K},
    \end{aligned}
\end{equation}
where $\kappa$ represents the thermal conductivity, $c_p$ denotes the apparent heat capacity, and the temperature ($T$) is expressed in Kelvin. Note that the effect of the latent heat of fusion on the apparent heat capacity has been accounted for in \eqref{eq:prop}$_2$. The process parameters including the material properties, laser parameters, boundary and initial conditions are listed in Table~\ref{tab:laser_parameter}.

\begin{figure}[p]
    \centering
    \includegraphics[width=0.75\textwidth]{Figures/Domain.pdf}
    \caption{Schematic representation of the computational domain and boundary conditions.}
    \label{fig:domain}
\end{figure}

\subsection{Evaluation criteria and network parameters} \label{sebsec:criteria}

The performance of the physics-informed surrogate models considered in this study is evaluated using several criteria. Two primary metrics are used to assess accuracy: the relative error and the mean absolute percentage error (MAPE). The relative error is calculated for predicted temperatures and melt pool dimensions, enabling a localized evaluation of the model's ability to capture the steep thermal gradients observed in the melt pool. The MAPE provides an overall measure of accuracy by quantifying the deviation of the predicted temperature from the reference FD solutions across the entire computational domain and is calculated by

\begin{equation}\label{eq:MAPE}
    \text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{T_{NN,i} - T_{FD,i}}{T_{FD,i}} \right|
\end{equation}
where $T_{NN}$ and $T_{FD}$ represent the \pidon{} (or PINN)  and finite-difference calculated temperatures, while $n$ is the total number of points inside the domain.

The temperature history during the cooling and consolidation phases is also considered to ensure the model's reliability in capturing the temporal evolution of the thermal field. This is crucial for accurately predicting the cooling time and the subsequent effects on material properties and microstructure.

The PI-DeepONet architecture is structured with separate trunk and branch networks. The trunk network consists of 5 hidden layers, each containing 64 neurons, while the branch network has 2 hidden layers, each with 64 neurons. In comparison, the PINN architecture employs a single FNN with 5 hidden layers, each containing 64 neurons. For both PI-DeepONet and PINN, a sine function is used as the activation function in the form of $\sin{\pi \beta x}$, where $\beta$ is an extra trainable parameter. The Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS)~\cite{liu1989limited} optimizer is selected for training. L-BFGS is particularly effective for physics-informed neural networks due to its ability to efficiently handle smooth loss landscapes and achieve high precision during convergence~\cite{rathore2024challenges}.

%\HW{L-BFGS-B is certainly not optimal. Both Alex and David worked with BFGS. This we should check later, it does not prevent us from uploading a preprint.}

\subsection{Single-track scenarios}

Before analyzing the performance of \pidon{} in multi-track scenarios, we first assess its ability to provide parametric solutions for various tool paths in single-track scenarios. Referring to the domain illustrated in Fig.~\ref{fig:domain}, each single-track scenario involves the laser processing of one out of three possible tracks. In these cases, the laser operates over the same length of the workpiece but starts at different positions. Thus, a single \pidon{} model learns the temperature evolution for three scenarios all at once. For comparison, three separate PINN models are trained individually, with each model focusing on the temperature evolution of a specific scenario.

\input{results/single-tracks}

Fig.~\ref{fig:single-tracks} compares the predicted temperature and meltpool dimensions with the finite-difference solution (as the reference solution). As seen in Fig.~\ref{fig:single-tracks_pinn} and \ref{fig:single-tracks_pideep}, the predicted temperature for both approaches agree well with the reference solution with the MAPE $< 2\%$. However, PINN demonstrates slightly better accuracy in temperature predictions compared to \pidon{}, particularly at higher temperatures. Furthermore, PINN also performs slightly better in terms of average meltpool dimensions as shown in Fig.~\ref{fig:single-tracks_meltpool}. All of the trainings in this study are performed on Nvidia A100 80GB GPU. Table~\ref{tab:single-tracks} shows the total training times and other global metrics of PINN and \pidon{} for single-track scenarios. In estimation of the total training time of the PINN, we assume that only one GPU is available for training. However, in practice, the three different PINNs can be trained in parallel on different GPUs without any overhead. On the other hand, \pidon{} offers a parametric solution that accommodates variations in the tool path, whereas with PINN, we obtain three distinct solutions corresponding to three different tool paths.

\subsection{Multi-tracks scenarios}

In the current test case with 3 parallel tracks ($n=3$), as shown in Fig.~\ref{fig:domain}, the total of 6 (i.e. $3!$) unique paths can be identified. \\

\noindent \textbf{\pidon{}:} The \pidon{} is trained on all possible 6 paths, with each path containing 3 tracks. Fig.~\ref{fig:all_path_pideep_a} presents the comparison in the calculated temperature and the melt pool dimensions between the \pidon{} and the reference solution. We experienced the average training time of 17h for all 6 paths. With the $\text{MAPE}=6.81\%$ and the average relative error of 8-10\% in melt pool dimensions, the results clearly indicate that the overall accuracy of the model in multi-track scenarios is not satisfactory.

\begin{figure}[p]
    \centering
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{Figures/all_path_pideep_fd.png}
    \caption{\pidon{}}
    \label{fig:all_path_pideep_a}
    \end{subfigure}
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{Figures/all_path_pinn_fd.png}
    \caption{Sequential PINN}
    \label{fig:all_path_pinn_b}
    \end{subfigure}
    \begin{subfigure}{1\textwidth}
    \includegraphics[width=\textwidth]{Figures/all_path_meltpool_pideep_pinn.pdf}
    \caption{Melt pool dimensions}
    \label{fig:all_path_pideep_pinn_c}
    \end{subfigure}
    \caption{Comparison of the calculated temperature and meltpool dimensions for all multi-track scenarios (paths). R.E. stands for the relative error. (a): \pidon{} solution vs. reference (FD) solution, (b): Sequential PINN solution vs. reference (FD) solution. 5 \% relative error zone is indicated by light red color. (c): Comparison of melt pool dimensions for each method.  Error bars indicate 5\% error with respect to FD solution.}
    \label{fig:multi-tracks}
\end{figure}




The \pidon{} model presents an interesting theory and framework for obtaining parametric solutions in terms of the different tool paths. It achieves acceptable accuracy in single-track scenarios. However, as observed, by increasing the number of tracks involved in each scenario the errors are substantially elevated. This can be attributed to the curse of dimensionality. By increasing the number of tracks in each scenario, the computational complexity across the domain increases. In single-track scenarios, the tool path moves only along a 1-dimensional track. However, in multi-track scenarios, the tool path moves along multiple tracks over a surface. This increase in the dimensionality of the heat source movement introduces challenges in capturing the complex spatiotemporal dynamics of heat transfer, where interactions between tracks create localized reheating and sharper thermal gradients. These coupled interactions demand high spatial and temporal collocation points, significantly increasing the complexity of the problem. Additionally, the growing input function (the input to the branch net) dimensionality amplifies the computational cost and training time, making it harder to maintain high accuracy and low error rates across all scenarios. To overcome these challenges and improve the accuracy, the next section introduces a sequential approach for obtaining the solutions of multi-track scenarios. This method leverages PINNs to achieve a balance between acceptable accuracy and reasonable training times.\\

%\HW{if you think the growing input function is a problem, why not using a CNN or sth else? fully-connected feedforward is certainly not the best choice for larger paths.}


%\subsection{Sequential PINN for Multi-track Scenarios}\label{subsec:multi_tracks} 

\noindent \textbf{Sequential PINN:} For the workpiece which undergoes 3 parallel tracks ($n=3$),  15 individual PINNs ($N^{train}=15$ according to Eq.~\ref{eq:n_train}) are required to obtain the whole solution across all 6 scenarios. To evaluate the accuracy of the sequential PINN approach, the predicted temperature as well as the meltpool dimensions are compared with the reference solution in Fig.~\ref{fig:all_path_pinn_b} and Fig.~\ref{fig:all_path_pideep_pinn_c}. As observed in Fig.~\ref{fig:all_path_pinn_b}, the consecutive PINN model is capable of approximating the reference solutions for 6 scenarios. Thanks to the adaptive clustering of collocation points in the vicinity of the laser spot, at temperatures higher than 1600 K, where the melt pool is developed, the relative errors lie within the 5\% error with respect to the reference solutions. As indicated, the MAPE for all the points inside the domain is less than 2.5\% which confirms the consistency of the sequential PINN model in computing the temperature field for multi-track scenarios. Successful clustering also helps obtaining relatively acceptable accuracies (less than 5 \%) in estimating the melt pool dimensions as shown in Fig.~\ref{fig:all_path_pideep_pinn_c}. To gain deeper insight into the distribution of relative errors across the domain, Fig.~\ref{fig:all_compare_T} illustrates the temperature contours for PINN and finite-difference solutions in both $xy-$ and $xz-$ planes along the laser direction at the middle of the process ($t=15 \: \text{ms}$), together with the distribution of relative error. The temperature distributions demonstrate very good agreement with the reference solution throughout the entire domain and across all scenarios. Table~\ref{tab:multi-tracks} provides a comparison of the training times and other global metrics between the sequential PINN and \pidon{}. The time required to solve all scenarios using the sequential PINN is approximately 8.5 times less than that of \pidon{}. The above evaluations highlight the effectiveness of the sequential PINN approach as a reliable surrogate for efficient and accurate computation of temperature distributions in multi-track scenarios during the melting phase.


\begin{table}[tb]
    \centering
    \caption{Comparison of the training times an other metrics for multi-track scenarios between sequential PINN and \pidon{}.}
    \begin{tabular}{c|c|c}
                    & Sequential PINN & \pidon{} \\
                    \hline
                    \hline
     Total training time & 2 h & 17 h \\
     MAPE in temperature & 2.49 \% & 6.81 \% \\
     Average relative error in melt pool length & 3.58 \% & 10.80 \% \\
     Average relative error in melt pool width & 3.81 \% & 8.62 \% \\
     Average relative error in melt pool depth & 4.89 \% & 8.53 \% 
    \end{tabular}
    \label{tab:multi-tracks}
\end{table}


\begin{figure}[h]
    \centering
    \begin{subfigure}{0.85\textwidth}
    \includegraphics[width=\textwidth]{Figures/all_path_xy.pdf}
    \caption{$xy$-plane}
    \label{fig:multi_a}
    \end{subfigure}
    \begin{subfigure}{0.85\textwidth}
    \includegraphics[width=\textwidth]{Figures/all_path_xz.pdf}
    \caption{$xz$-plane}
    \label{fig:multi_b}
    \end{subfigure}
    
    \caption{Comparison between the PINN predictions and finite-difference solutions for all paths in both $xy-$ and $xz-$ planes at $t=15 \: \text{ms}$. The $xy$ plane is the top view in Fig.~\ref{fig:domain} and the $xz$ plane is a cut along the laser path.}
    \label{fig:all_compare_T}
\end{figure}


Besides acceptable accuracy in temperature distribution and meltpool dimensions, a successful surrogate should be able of providing a consistent temperature history during the consolidation phase. Influencing the microstructure development, the consolidation affects the mechanical properties and overall quality of the manufactured item. To evaluate the accuracy of temperature predictions during cooling and consolidation, we compare the temperature history at various locations within the melt pool against the reference solution across all scenarios. Fig.~\ref{fig:cooling} shows the evolution of the temperature at the center of the melt pool over time and compares it with the reference solution for the scenario number 1. Similar trends are also observed for different locations throughout the melt pool across all scenarios. The relative errors in the temperature history profiles across the melt pool region remain below 5\% for all scenarios, ensuring a high level of agreement with the reference solution.

To provide a more comprehensive assessment of the model's consistency, the distribution of relative errors and the MAPE in the computed temperatures at various process times for all data points across the domain in all six scenarios are illustrated in Fig.~\ref{fig:cooling_all}. The MAPE, consistently remaining below 5\%, confirms the reliability of the developed surrogate model in accurately evaluating the cooling and the consolidation phases.

%\subsection{Limit analysis}
    
%\HW{For DeepONet, we have seen that we have reached a limit with the six tracks – both in terms of computational time and accuracy. I wonder where the limit is with sequential PINN – errors will accumulate when using more tracks. Maybe we should consider an additional test case here?}

%\HW{here we should also discuss accumulating errors over time.}
%\HW{comment this section out when submitting a preprint to arXiv}



\begin{figure}[h]
    \centering
    \begin{subfigure}{0.65\textwidth}
    \includegraphics[width=\textwidth]{Figures/cooling.pdf}
    \caption{}
    \label{fig:cooling}
    \end{subfigure}
    \begin{subfigure}{0.65\textwidth}
    \includegraphics[width=\textwidth]{Figures/cooling_all_re.png}
    \caption{}
    \label{fig:cooling_all}
    \end{subfigure}
    
    \caption{(a) Comparison of the temperature history at the center of the meltpool during the cooling and consolidation phase. Error bars represent 5\% error with respect to FD solution. (b) The relative errors in calculated temperature at different positions across the whole computational domain during the cooling and consolidation phases for all paths. Each position is represented by a blue dot in the plot. Darker color implies aggregation of the relative error values. The MAPE at each time step is shown by the red dot.}
    \label{fig:all_compare_T}
\end{figure}




%\input{results/multi-track-soft}

%\begin{figure}[h!]
%\centering
%–\begin{lstlisting}
%# STEP 1:

%for i in (1, n):
%    compute first path in T_1 = [t_0, t_1]
%    export weights and biases (W_i, b_i) for each i out of n models

%for i in (1, n-1):
%    compute second path in T_2 = [t_1, t_2]
%    export weights and biases

%\end{lstlisting}
%\caption{Algorithmic chart of the proposed methodology.}
%\label{fig:algorithm}
%\end{figure}


\section{Conclusion and Outlook}\label{sec:conclusion}
This study explored the application of physics-informed neural networks (PINNs) and Physics-Informed neural operators (PI-EnDeepONet) for solving the 3-dimensional transient heat equation in laser powder bed fusion (LPBF) processes. Our primary focus was to develop parametric surrogate models for predicting the temperature field in single-track and multi-track scenarios. While PI-EnDeepONet demonstrated success in obtaining parametric solutions for single-track scenarios with high accuracy ($\text{MAPE} < 2\%$), its performance significantly deteriorated in multi-track cases due to the curse of dimensionality and increased computational complexity. In contrast, the sequential PINN approach proved to be an effective and scalable alternative. By training individual PINNs for each track and recalling them sequentially, this method maintained low errors ($\text{MAPE} < 2.5\%$) and accurate melt pool predictions, while also reducing training time by a factor of 8.5 compared to PI-EnDeepONet. Moreover, the sequential PINN effectively captured the cooling phase, ensuring accurate temperature evolution throughout the entire process, which is critical for microstructural predictions in AM. This offers significant potential for rapid process optimization and real-time monitoring in additive manufacturing, particularly for tool path planning where high-fidelity simulations are often computationally prohibitive.

Despite these promising results, several challenges remain. One key limitation of the sequential PINN approach is the potential accumulation of errors over multiple tracks, which could impact predictions in larger-scale multi-track or multi-layer simulations. Future research should explore methods to mitigate these errors. Extending this framework to multi-layer AM processes would also be a next step, given the increased complexity of thermal interactions.


\section*{Acknowledgement}

HW acknowledges the DFG for funding within the individual research grant "Data-driven simulation of microstructure in powder bed fusion processes" with project ID 512730472. HS acknowledges helpful discussions and technical support of David Anton in this study.

%\newpage
\appendix 

%\section{Cellular Automata}\label{sec:cellular-automata}
%\HW{@Shayan: Please briefly describe the employed method for the 3D case.}




\bibliographystyle{plainnat}
\bibliography{literature}


%End of document
\end{document}
