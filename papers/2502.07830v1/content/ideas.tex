What are the things we want to show:
\begin{enumerate}
    \item How CLIP memorization relates to SL and SSL memorization. 1
    \item Which modality (text or vision) is more responsible for memorization? 2
    \item Which samples are memorized and why? 3
    \item How does the CLIP memorization impact generalization? 4
    \item How can we prevent memorization and maybe, at the same time, get better CLIP models? 5
\end{enumerate}


\subsection{What are the results that we currently have:}

Question 0: Overview on CLIPMem results.

Question 1: 

Question 2: 


Question 3: 

Question 4: 

Question 5: 



\subsection{What are the results we are currently still waiting for:}

Question 1: 


Question 2: 
1. Diffusion model results: get 5 generated images and train with them.
2. Multiple training effects:
NONE
- no augmentation for text and image
ONLY IMAGE
- normal crop augmentation for image, no augmentation for text
- diffusion model augmentation for image, no augmentation for text
ONLY TEXT
- no image augmentation and 5 coco captions
- no image augmentation and 5 GPT3 captions
BOTH
- diffusion + 5 coco
- diffusion + GPT3
- crop + + 5 coco
- crop + GPT3


Question 3: 
1. Test if the images that are most memorized when the 5 (diverse) captions are used are still highly memorized when 1 caption is used. This would indicate that CLIP memorizes the most difficult samples (difficulty is measured based on the fact that also human annotators do not agree) 

Question 4: 

Question 5: 