\documentclass{article}
\usepackage{iclr2024_conference,times}
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023

% if you need to pass options to natbib, use, e.g.:
%\PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
%\usepackage{neurips_2022}
%\usepackage{algorithmic_custom}
%\usepackage{algorithm}
\usepackage{algcompatible}
%\usepackage[algcompatible]{algpseudocode}

% ready for submission
%\usepackage{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%\usepackage[nonatbib]{neurips_2021}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{accents}
\usepackage{amsmath}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{bm}
\usepackage{diagbox}
\usepackage{oplotsymbl}
\usepackage{pgfplots}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{tablefootnote}
\usepackage{makecell}
\usetikzlibrary{patterns}

\usepackage[export]{adjustbox} % to align subfloats next to each other
\usepackage{tikz}
\usepackage{pifont} %\cmark and \xmark
\usepackage{circledsteps} % encircled numbers
\newcommand{\mycirc}[1]{\Circled[/csteps/fill color=black,/csteps/inner color=white]{\sffamily \small #1} }


\usepackage[ruled,vlined]{algorithm2e}

\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % set the Output

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% for bibliography

%\usepackage{achemso}
%\mciteErrorOnUnknownfalse

% Comments Switch
\newif\ifdraft
%\drafttrue
\draftfalse

\input{macros}
\input{math_commands}

\renewcommand{\paragraph}[1]{\noindent\textbf{#1}~~}

\newcommand{\ClipMem}{\textit{ClipMem}\@\xspace}

\newcommand{\reb}[1]{{\textcolor{black}{#1}}}
%\newcommand{\new}[1]{{\textcolor{black}{#1}}
%\newcommand{\rebut}[1]{\textcolor{black}{#1}}

\usepackage{hyperref}       % hyperlinks
%\newcommand{\ourtitle}{Open Large Language Models for Privacy Protection}
%\newcommand{\ourtitle}{Open Large Language Models for High-Utility Privacy-Preserving Adaptations}
%\newcommand{\ourtitle}{Differentially Private Adaptations of Large Language Models}
%\newcommand{\ourtitle}{How to Privately Adapt Large Language Models to Downstream Tasks?}
%\newcommand{\ourtitle}{More Private LLM Adaptations that Yield High Performance and }
%\newcommand{\ourtitle}{Private and Local Adaptations of Open LLMs Outperform their Closed Alternatives}
%\newcommand{\ourtitle}{Open and Local LLMs are Required for Private Adaptations and Outperform their Closed Alternatives}
%\newcommand{\ourtitle}{Memorization in CLIP}
\newcommand{\ourtitle}{Captured by Captions: On Memorization and its Mitigation in CLIP Models}
\title{\ourtitle}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{
Wenhao Wang$^{1}$, Adam Dziedzic$^{1}$, Grace C. Kim$^{2}$, Michael Backes$^{1}$, Franziska Boenisch$^{1}$\thanks{Correspondence to boenisch@cispa.de}\\
$^{1}$CISPA, $^{2}$Georgia Institute of Technology
}


\iclrfinalcopy
\begin{document}


\maketitle

% {\color{purple}
% \textbf{Storyline:} \\
% - There is a problem with sharing private data with the LLM provider \\
% - Other works focus on protecting the private training data against the querying party but still have to share the data with LLM provider \\

% \textbf{- We show that local LLMs are always better, anyways.} \\
% 1. in the small epsilon case, local PATE would work best \{Vicuna13B, Openllama13B\} \\
% 2. in the larger epsilon case, DPSGD methods work best \\
% 3. promptDPSGD can handle generation tasks
% }


\input{content/00abstract}
\input{content/01intro}
\input{content/02background}
\input{content/03method}
\input{content/05experiments}
\input{content/07conclusions}
\input{content/08acknowledge}

% \bibliographystyle{plainnat}
% \bibliography{main}
\bibliography{main}
\bibliographystyle{iclr2024_conference}

\appendix
\input{content/09appendix}

\end{document}