\section{Related Work}
Recently, LLMs have advanced significantly.
High-performance models like ChatGPT ____, GPT-4 ____, GPT-4o, and others have demonstrated notable improvements in performance and generalization.
These models are built on the transformer architecture ____, followed by models such as BERT ____ and the GPT series ____.
Additionally, various other models have emerged, including Bard ____, Gemini, LLaMA ____, Dolly ____, BLOOM ____, Vicuna ____, and PaLM ____.

Evaluating LLM performance is equally important.
For instance, lm\_eval ____ is a benchmarking platform for assessing LLMs across multiple tasks.
Various benchmarks have been introduced to evaluate specific capabilities, such as MMLU ____ for general knowledge, MMLU-Pro ____ and GPQA ____ for reasoning, mathematical benchmarks ____, MGSM ____ for multilingual reasoning, and HumanEval ____ and MBPP ____ for programming proficiency.
Additionally, studies have examined GPT-4â€™s performance of ____ across domains such as accounting examinations ____, medicine ____, and law ____.

Beyond domain- or task-specific benchmarks, evaluations also focus on output quality, particularly in assessing AI assistants and question-answering interactions.
MT-bench ____ introduced a benchmark for multi-turn conversations using LLM-as-a-judge, where a high-performance LLM evaluates responses.
The LLM-as-a-judge method is widely adopted.
Moreover, Chatbot Arena ____ proposed a platform in which humans conduct continuous pairwise comparisons of model outputs.
Given the significance of these evaluations, this study introduces a new benchmark for assessing open-ended generation quality.

Although we use n-gram-based metrics, our approach is rooted on the distributional hypothesis ____.
While LLMs challenge this hypothesis, it has long supported language modelling.
Many embedding and language models have been developed based on this principle ____, leading to the modern LLMs.
Despite arguments that the hypothesis cannot fully explain LLMs' generalization ____, we assume it remains useful for evaluating LLM outputs.