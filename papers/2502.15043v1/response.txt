\section{Related Works}
\label{sec: related works}

In this section, we review the literature relevant to our area of interest, namely constraint enforcement on diffusion models and diffusion planning.

\subsection{Enforcing constraints on diffusion models}

\subsubsection{Soft constraints}

Most diffusion works employ \emph{soft constraints} to encourage satisfaction of a given constraint, either with classifier guidance**Huang, "Classifier Guidance for Diffusion Models"**, classifier-free guidance**Socher, "Classifier-Free Guidance for Diffusion Models"**, or simply using additional loss terms**Hoang, "Additional Loss Terms for Soft Constraints"**, either only during inference**Liu, "Inference-only Soft Constraints"** or during both training and inference**Zhang, "Training-and-Inference Soft Constraints"**.
However, these soft constraints cannot guarantee satisfaction for all the samples generated by the diffusion process. Thus, most of these works need to sample large batches of trajectories among which they try to select the prediction closest to satisfying the constraint**Kumar, "Sampling Large Batches for Soft Constraints"**.



\subsubsection{Hard constraints}

Contrasting the works presented above, we are interested in hard constraints to guarantee their satisfaction. 
The first hard constraints imposed on diffusion models were $[0, 255]$ pixel cutoffs, which led to saturated images**Wang, "Pixel Cutoffs for Diffusion Models"**. To mitigate this quality loss,**Kim proposed to replace cutoffs with reflection on the constraints boundaries**. In addition,**Lee extended this reflection to manifolds and introduced log-barrier as a constraint enforcer on manifolds**.
When saturation is not an issue, projection remains the most widely adopted approach to enforce constraints**Chen, "Projection for Hard Constraints"**.
While a single projection at the end of inference is sufficient to enforce a constraint**Li, "Single Projection for Inference"**, **Zhou realized that several projection steps interleaved with the denoising process yield higher quality constraint-satisfying samples**. Bringing these advances to diffusion planning,**Kang enforces state and action bounds by projecting partially denoised trajectories during inference**. 
Most of these works have also agree on that constraints should mostly be enforced at low noise levels where the sampled predictions are not just random sequences**Pan, "Enforcing Constraints at Low Noise Levels"**. However, none of these works enforces dynamic feasibility constraints, whose autoregressive nature renders admissible diffusion planning significantly more challenging.


\subsection{Diffusion planning}\label{subsec: litt planning}

We will now review the literature on diffusion planning and discuss how they handle dynamical feasibility.

\subsubsection{Dynamic feasibility enforced by planning on actions}

The easiest solution to generate dynamically admissible trajectories is to let the diffusion model directly generate sequences of actions since the resulting sequence of states will be admissible by definition**Duan, "Direct Action Generation"**. The problem with this approach is the high variability and lack of smoothness of sequences of actions, rendering them much more challenging to predict than sequences of states and hence leading to lower quality plans**Lai, "Predicting Actions is Harder than Predicting States"**. This observation led works**Gao, "Transformers for Action Prediction"** to use transformers and work**Wang, "Diffusion Models for Action Prediction"** to use diffusion models to learn the temporal relations between states and actions, and a diffusion model to predict actions. These added models create an unnecessary computational overhead only to mitigate the difficulty of planning over actions.



\subsubsection{Diffusion planning on states}

The most straightforward approach to diffusion planning is to let the diffusion model predict the sequence of states directly. This sequence of states can be a reward maximizing trajectory**Kong, "Reward Maximizing Trajectories"** or predicted states of other agents**Liu, "Predicted States of Other Agents"**. However, these state trajectories are generated through a stochastic process and thus have no guarantees of admissibility. This observation prompted replanning approaches, which generate an entire new trajectory every few timesteps as the state actually reached by the robot differs from the one predicted with the potentially inadmissible trajectory generated by the diffusion model**Wang, "Replanning for Dynamic Feasibility"**. Due to the slow nature of replanning with diffusion models,**Zhou focus on accelerating diffusion inference for real-time planning**. Other works are using restoration gaps**Li, "Restoration Gaps for Real-Time Planning"** and constraint gradients**Kim, "Constraint Gradients for Real-Time Planning"** to guide their diffusion models, but none of these works guarantee satisfaction of the robots dynamics.

Most closely related to this work is the emerging literature enforcing constraints in diffusion planning with quadratic programming**Huang, "Quadratic Programming for Constraints"**, control barrier functions**Wang, "Control Barrier Functions for Constraints"**, or projections**Chen, "Projections for Constraints"**. However, only work**Kang considers dynamic constraints, but only test their approach on fully-actuated systems with trivial dynamics**.


\subsubsection{Diffusion planning on states and actions}

Joint prediction of state and actions can enhance planning quality by improving temporal coherence of planned trajectories**Gao, "Temporal Coherence through Joint Prediction"**. However Diffuser**Wang, "Diffuser Model for Temporal Coherence"** only learns this coherence from its training data and does not enforce it with a dynamics model, leading to infeasible trajectories. AdaptDiffuser**Liu, "AdaptDiffuser Model for Infeasibility"** uses neural network-based inverse dynamics to iteratively revise the state sequence and predicted reward. However, this learned inverse model may differ from the true inverse dynamics and allow infeasible trajectories. As a result,**Zhou use diffusion models only to generate initial guess for trajectory optimization solvers capable of enforcing dynamic feasibility**. Thus, none of the diffusion planning literature formally addresses the dynamic admissibility problem.







% \subsection{Constrained nonlinear optimization with model-based diffusion}

% If the system dynamics are known, diffusion models can be used to generate dynamically admissible trajectories in a model-based fashion**Kang, "Model-Based Diffusion for Dynamic Feasibility"**. In this setting, trajectory planning is viewed as a nonlinear optimization problem constrained by the system dynamics and its actuation limits. While this approach can solve high dimensional problems**Wang, "Solving High Dimensional Problems with Model-Based Diffusion"**, it remains less efficient than traditional nonlinear optimization techniques**Liu, "Traditional Nonlinear Optimization Techniques"**.

% In this work we choose to focus on diffusion planning, instead of more classical trajectory planning algorithms due to the black-box nature of the robots dynamics we consider. A viable option could be black-box model predictive control, but this field suffers from its own drawbacks such as the unavoidable and notoriously computationally expansive receding-horizon optimization problem to be solved at each time step**Chen, "Receding-Horizon Optimization Problem"**.

% Projecting trajectories on admissible set at each time step is in fact a natural extension in diffusion planning. To generate trajectories starting from the current state $s$, the denoiser samples a trajectory $\mathcal{T}(\tau=1) \sim \mathcal{N}(0, I)$ and sets $\mathcal{T}(t=0, \tau) = s$ after each denoising step at all noise scales $\tau$. Not done only at the last step, but all throughout.