\section{Proposed Approach}

\subsection{Estimators for $\sigma_{\cp^a_s}$}
\subsubsection{Linear Uncertainty Model: Contamination Uncertainty Set}
We directly follow \citep{wang2023model}'s method and utilize the transition to the subsequent state to construct our estimator:
\begin{align}\label{eq:12}
    \hat{\sigma}_{\cp^a_s}(V)\triangleq (1-\delta)\gamma V(s')+\delta\min_x V(x),
\end{align}
where $s'$ is a subsequent state sample after $(s,a)$. 
\subsubsection{Nonlinear Uncertainty Model}
For non-linear uncertainty sets such as KL divergence, TV divergence, Wasserstein distance and Chi-square, obtaining $\sigma_{\cp^a_s}$ from only accessing the nominal model is challenging. \citep{wang2023model} proposed a method using Multi-Level Monte Carlo (MLMC) approach for obtaining an unbiased estimator $\hat{\sigma}_{\cp^a_s}$ with bounded variance. However,  this approach requires performing $2^N$ samples whereas $N$ sampled from a geometric distribution $Geo(\Psi)$ with parameter $\Psi \in (0,0.5)$. As a result, the expected number of samples for obtaining a single $\hat{\sigma}_{\cp^a_s}$ is infinity. To cope with this problem, we modify the method in \citep{wang2023model} and propose a truncated MLMC approach.

For any $s,a$, we first generate $N$ according to a geometric distribution with parameter $\Psi\in(0,1)$. We then perform truncation via a predefined number $N_{\max}$ and set $N = \min\{N,N_{\max}\}$. Then, we take action $a$ at state $s$ for $2^{N+1}$ times, and observe $r(s,a)$ and the subsequent state $\{s_i'\}, i=1,...,2^{N+1}$. We divide these $2^{N+1}$ samples into two groups:  samples with odd indices, and samples with even indices. We then individually calculate the empirical distribution of $s'$ using the even-index samples, odd-index ones, all the samples, and the first sample:
$\hat{\kp}^{a,E}_{s,N+1}= \frac{1}{2^{N}}\sum_{i=1}^{2^{N}}\mathbbm{1}_{s_{2i}'},  
\quad\hat{\kp}^{a,O}_{s,N+1}= \frac{1}{2^{N}}\sum_{i=1}^{2^{N}}\mathbbm{1}_{s_{2i-1}'},$
$\hat{\kp}^{a}_{s,N+1}= \frac{1}{2^{N+1}}\sum_{i=1}^{2^{N+1}}\mathbbm{1}_{s_i'},\quad\hat{\kp}^{a,1}_{s,N+1}= \mathbbm{1}_{s_1'}.
$
Then, we use these estimated transition kernels as nominal kernels to construct four estimated uncertainty sets $\hat{\cp}^{a,E}_{s,N+1},\hat{\cp}^{a,O}_{s,N+1},\hat{\cp}^{a}_{s,N+1},\hat{\cp}^{a,1}_{s,N+1}$. The multi-level estimator is then defined as 
\begin{align}\label{eq:est1}
    \hat{\sigma}_{\cp^a_s}(V)\triangleq \sigma_{\hat{\cp}^{a,1}_{s,N+1}}(V)+\frac{\Delta_N(V)}{p_N},
\end{align}
where  $p_N=
\begin{cases}
(1 - \Psi)^{k-1} \Psi, & 1 \leq N < N_{\max} \\
(1 - \Psi)^{N_{\max} - 1}, & N = N_{\max}
\end{cases}$ and
\begin{align}
    \Delta_N(V)\triangleq \sigma_{\hat{\cp}^{a}_{s,N+1}}(V)-\frac{\sigma_{\hat{\cp}^{a,E}_{s,N+1}}(V)+\sigma_{\hat{\cp}^{a,O}_{s,N+1}}(V)}{2}.\nn
\end{align}



\begin{theorem}[Truncated MLMC: Exponential Bias Decay and Bounded Variance]
\label{thm:trunc-mlmc}
Let $\hat{\sigma}_{\cp^a_s}(V)$ be the multi-level Monte Carlo (MLMC) estimator for the robust Bellman operator $\sigma_{\cp^a_s}(V)$ under any of the following uncertainty sets:
\begin{enumerate}
  \item Total Variation (TV) distance,
  \item Kullback--Leibler (KL) divergence,
  \item $\chi^2$ distance,
  \item Wasserstein distance (with discrete state space).
\end{enumerate}
Suppose (as shown in \citep{wang2023model}) that the \emph{untruncated} estimator $\hat{\sigma}_{\cp^a_s}(V)$ is \textbf{unbiased},
\begin{equation}
  \mathbb{E}\bigl[\hat{\sigma}_{\cp^a_s}(V)\bigr]
  \;=\;
  \sigma_{\cp^a_s}(V),
\end{equation}
and has \textbf{uniformly bounded variance},
\begin{equation}
  \mathrm{Var}\!\bigl[\hat{\sigma}_{\cp^a_s}(V)\bigr]
  \;\le\;
  C_0\,\|V\|^2
  \quad\text{for some constant }C_0.
\end{equation}
Then the \emph{truncated} estimator $\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)$, which cuts off the MLMC level at $N_{\max}$, satisfies:

\begin{enumerate}
\item \textbf{(Exponential Bias Decay)} There exist constants $C_1>0$ and $\gamma>0$, not depending on $N_{\max}$, such that
\begin{equation}
  \bigl|\,
     \mathbb{E}\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
     \;-\;
     \sigma_{\cp^a_s}(V)
  \bigr|
  \;\le\;
  C_1\,\|V\|\,
  e^{-\gamma\,N_{\max}}.
\end{equation}
\item \textbf{(Bounded Variance)} There is a constant $C_2>0$, also not depending on $N_{\max}$, such that
\begin{equation}
  \mathrm{Var}\!\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
  \;\le\;
  C_2\,\|V\|^2.
\end{equation}
\end{enumerate}
Here $\|\cdot\|$ denotes a suitable norm of $V$ (e.g.\ a supremum norm), and the constants $C_1, C_2, \gamma$ may depend on model parameters such as $\delta$ (the size of the uncertainty set), but they do not grow with $N_{\max}$.
\end{theorem}

\begin{proof}

\textbf{Step~1: Definition of the truncated estimator.}

Let $N$ be the geometric random level used in \citep{wang2023model}, with
\begin{equation}
  \mathbb{P}(N=n)
  \;=\;
  \Psi\,(1-\Psi)^{\,n}, 
  \quad
  n=0,1,2,\dots.
\end{equation}
Define the \emph{truncated} random level 
\begin{equation}
  N' \;=\;\min\{N,\;N_{\max}\},
\end{equation}
having probability mass function
\begin{equation}
  \mathbb{P}(N' = n)
  \;=\;
  \begin{cases}
    \Psi\,(1-\Psi)^n,
    &0\le n<N_{\max},\\[6pt]
    \sum_{m=N_{\max}}^{\infty}\!\Psi\,(1-\Psi)^{m}
    \;=\;(1-\Psi)^{N_{\max}},
    &n=N_{\max}.
  \end{cases}
\end{equation}
Exactly as in \citep{wang2023model}, for each level $n$ we form empirical distributions (including odd/even subsets) from $2^{n+1}$ i.i.d.\ samples.  Let
\begin{equation}
  \Delta_n(V)
  \;=\;
  \sigma_{\hat{\cp}^{\,a}_{s,n+1}}(V)
  \;-\;
  \tfrac12\Bigl[
    \sigma_{\hat{\cp}^{\,a,O}_{s,n+1}}(V)
    \;+\;
    \sigma_{\hat{\cp}^{\,a,E}_{s,n+1}}(V)
  \Bigr].
\end{equation}
Then the truncated MLMC estimator is
\begin{equation}
  \hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)
  \;=\;
  \sigma_{\hat{\cp}^{\,a,1}_{s,N'+1}}(V)
  \;+\;
  \frac{\Delta_{\,N'}(V)}{p'(N')},
\end{equation}
where $p'(N')=\mathbb{P}(N'=N')$.  

\medskip

\textbf{Step~2: Exponential bias bound.}

From \citep{wang2023model}, we know that the \emph{untruncated} MLMC estimator $\hat{\sigma}_{\cp^a_s}(V)$ is unbiased:
\begin{equation}
  \mathbb{E}\!\bigl[\hat{\sigma}_{\cp^a_s}(V)\bigr]
  \;=\;
  \sigma_{\cp^a_s}(V).
\end{equation}
In particular, its expectation can be written (in a telescoping form) as 
\begin{equation}
  \mathbb{E}\!\bigl[\hat{\sigma}_{\cp^a_s}(V)\bigr]
  \;=\;
  \mathbb{E}\!\bigl[\sigma_{\hat{\cp}^{\,a,1}_{s,1}}(V)\bigr]
  \;+\;
  \sum_{n=0}^{\infty}\,\mathbb{E}\!\bigl[\Delta_n(V)\bigr].
\end{equation}
In the \emph{truncated} version, we instead cut off all levels $n > N_{\max}$, so
\begin{equation}
  \mathbb{E}\!\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
  \;=\;
  \mathbb{E}\!\bigl[\sigma_{\hat{\cp}^{\,a,1}_{s,1}}(V)\bigr]
  \;+\;
  \sum_{n=0}^{\,N_{\max}}\,\mathbb{E}\!\bigl[\Delta_n(V)\bigr].
\end{equation}
Hence the bias arises exactly from the \emph{omitted} terms $n>N_{\max}$:
\begin{equation}
  \sigma_{\cp^a_s}(V)
  \;-\;
  \mathbb{E}\!\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
  \;=\;
  \sum_{n=N_{\max}+1}^{\infty}\,\mathbb{E}\!\bigl[\Delta_n(V)\bigr].
\end{equation}

\noindent
\emph{Why does $\mathbb{E}[\Delta_n(V)]$ shrink exponentially?} 

\smallskip
\begin{itemize}
\item 
By construction,
\begin{equation}
  \Delta_n(V)
  \;=\;
  \sigma_{\hat{\cp}^{a}_{s,n+1}}(V)
  \;-\;\tfrac12\Bigl[
     \sigma_{\hat{\cp}^{a,O}_{s,n+1}}(V)
     \;+\;
     \sigma_{\hat{\cp}^{a,E}_{s,n+1}}(V)
  \Bigr],
\end{equation}
where $\hat{\cp}^{a}_{s,n+1}$ is the empirical distribution from $2^{n+1}$ i.i.d.\ samples, and $\hat{\cp}^{a,O}_{s,n+1},\hat{\cp}^{a,E}_{s,n+1}$ each come from half of those samples.

\item
All four divergences/distances (TV, KL, $\chi^2$, Wasserstein with a discrete state space) give a robust operator $\sigma_{p}(V)$ that is \emph{continuous} (often Lipschitz) in $p$.  Hence, if $p$ is close to the nominal $\cp^{a}_{s}$, we have 
\[
  \bigl|\sigma_{p}(V)-\sigma_{\cp^a_s}(V)\bigr|
  \;\le\;
  \mathrm{const}\,\|V\|
  \,\|p - \cp^a_s\|_1
  \quad(\text{or a similar local bound}).
\]
\item
By Hoeffdingâ€type binomial concentration, the empirical distributions $\hat{\cp}^{a}_{s,n+1}$ converge to $\cp^a_s$ at rate $\mathrm{O}(2^{-\,n/2})$ in expectation.  Thus
\[
  \mathbb{E}\Bigl[\bigl\lVert
     \hat{\cp}^{a}_{s,n+1}
     -\cp^a_s
  \bigr\rVert_1\Bigr]
  \;=\;
  \mathrm{O}\bigl(2^{-\,n/2}\bigr).
\]
\item
Consequently,
\[
  \bigl|\mathbb{E}[\sigma_{\hat{\cp}^{a}_{s,n+1}}(V)-\sigma_{\cp^a_s}(V)]\bigr|
  \;=\;
  \mathrm{O}\bigl(2^{-\,n/2}\bigr),
\]
and likewise for $\hat{\cp}^{a,O}_{s,n+1},\hat{\cp}^{a,E}_{s,n+1}$.  Therefore,
\[
  \mathbb{E}[|\Delta_n(V)|]
  \;\;=\;
  \mathrm{O}\bigl(2^{-\,n/2}\bigr).
\]
\end{itemize}

\noindent
Hence we obtain a \emph{geometric} tail for the omitted terms:
\begin{equation}
  \sum_{n=N_{\max}+1}^{\infty}\!\bigl|\mathbb{E}[\Delta_n(V)]\bigr|
  \;\;\le\;
  \mathrm{const}\,\|V\|
  \sum_{n=N_{\max}+1}^{\infty}2^{-\,n/2}
  \;\;=\;
  C_1\,\|V\|\;e^{-\gamma\,N_{\max}},
\end{equation}
for some constants $C_1,\gamma>0$.  This completes the argument that
\begin{equation}
  \bigl|\,
  \mathbb{E}\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
  \;-\;
  \sigma_{\cp^a_s}(V)
  \bigr|
  \;\le\;
  C_1\,\|V\|\,
  e^{-\gamma\,N_{\max}}.
\end{equation}
Thus the bias decays \emph{exponentially} with $N_{\max}$.

\medskip
\textbf{Step~3: Bounded variance.}

Since $\hat{\sigma}_{\cp^a_s}(V)$ in \citep{wang2023model} has a variance uniformly bounded by $C_0\,\|V\|^2$, the truncated version is intuitively \emph{no larger}.  Formally, observe that:
\begin{itemize}
\item On $\{N<N_{\max}\}$, we have $N'=N$, so the truncated and untruncated estimators \emph{coincide}.
\item On $\{N\ge N_{\max}\}$, we have $N'=N_{\max}$, but $p'(N_{\max}) \ge p(N_{\max})$, meaning $\frac{1}{p'(N_{\max})}$ is \emph{no bigger} than $\frac{1}{p(N_{\max})}$.  Thus the magnitude of $\frac{\Delta_{N_{\max}}(V)}{p'(N_{\max})}$ is less than or comparable to that of $\frac{\Delta_{N}(V)}{p(N)}$ in the untruncated estimator.
\end{itemize}
Consequently,
\[
  \bigl\lvert
    \hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)
  \bigr\rvert^2
  \;\;\le\;
  \mathrm{const}\,\bigl\lvert
     \hat{\sigma}_{\cp^a_s}(V)
  \bigr\rvert^2
  \quad
  \text{in all sample paths.}
\]
Taking expectations,
\[
  \mathbb{E}\Bigl[
     \bigl(\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr)^2
  \Bigr]
  \;\le\;
  \mathrm{const}\,\mathbb{E}\Bigl[
     \bigl(\hat{\sigma}_{\cp^a_s}(V)\bigr)^2
  \Bigr].
\]
By assumption,
\[
  \mathrm{Var}\bigl[\hat{\sigma}_{\cp^a_s}(V)\bigr]
  \;\le\;
  C_0\,\|V\|^2
  \quad\Longrightarrow\quad
  \mathbb{E}\Bigl[\bigl(\hat{\sigma}_{\cp^a_s}(V)\bigr)^2\Bigr]
  \;\le\;
  C'\,\|V\|^2
\]
for some $C'$.  Hence the truncated estimator has
\begin{equation}
  \mathrm{Var}\!\bigl[\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)\bigr]
  \;\le\;
  C_2\,\|V\|^2,
\end{equation}
where $C_2$ depends on $C'$ (and thus on $C_0$).  Thus its variance is uniformly bounded in $N_{\max}$.

\medskip
\textbf{Conclusion.}  
We have established that the truncated estimator $\hat{\sigma}_{\cp^a_s}^{(\mathrm{tr})}(V)$ has an exponentially decaying bias (as a function of $N_{\max}$) and a uniformly bounded variance.  This completes the proof.
\end{proof}

\begin{remark}
The same argument applies equally to the TV--distance setting, the KL--divergence setting, the $\chi^2$--distance setting, and the Wasserstein--distance setting (under discrete $\mcs$), because in each case:
\begin{enumerate}
\item The untruncated MLMC estimator is unbiased and has bounded variance \citep{wang2023model}.
\item The robust one--step operator $\sigma_{\cp^a_s}(V)$ is sufficiently continuous in the empirical distribution so that $\Delta_n(V)\to 0$ at a rate $\mathrm{O}(2^{-\,n/2})$.
\end{enumerate}
Hence the truncated version inherits the bounded variance property and gains only an exponentially small bias.
\end{remark}

\subsection{Robust Synchronous TD for Policy Evaluation}


\begin{algorithm}[ht]
\caption{Stochastic Robust Average-Reward TD Learning}
\label{alg:robust-avg-reward-TD}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Step-size sequence \(\{\alpha_t\}\), policy \(\pi\), and sampler from the nominal MDP (centroid of the uncertainty set).
\STATE \textbf{Initialize:} \(V_0(s) = 0 \;\;\forall s\in\mathcal{S},\quad g_0 = 0\)
\FOR{$t=0,1,2,\ldots,T-1$}
  \STATE \textbf{(a) Robust Bellman Approximation:}
    \begin{itemize}
      \item Sample a batch of states \(\{s^t_1,\dots,s^t_B\}\) (or collect all states if feasible).
      \item For each sampled \(s\), pick \(a\sim\pi(\cdot\mid s)\).
      \item Obtain estimates \(\widehat{\sigma}_t(s,a)\) of \(\sigma_{\mathcal{P}^a_s}(V_t)\)
            (e.g., via a minimization routine or a biased/unbiased estimator).
      \item Form the operator estimate:
            \[
               \widehat{T}_{g_t}V_t(s) \;=\; \sum_{a\in\mathcal{A}} \pi(a\mid s)\,
               \Bigl[\,
                   r(s,a) \;-\; g_t \;+\; \widehat{\sigma}_t(s,a)
               \Bigr].
            \]
    \end{itemize}
  \STATE \textbf{(b) Update Bias Function:}
    \[
       V_{t+1}(s)
       \;=\;
       V_t(s)
       \;+\;
       \alpha_t\,\Bigl(\widehat{T}_{g_t}V_t(s) \;-\; V_t(s)\Bigr),
       \quad \forall s\in \mathcal{S}.
    \]
    \STATE \quad (One may normalize \(V_{t+1}\) by subtracting \(V_{t+1}(s_0)\) from every component to anchor a reference state.)
  \STATE \textbf{(c) Update Average Reward:}
    \begin{itemize}
      \item Compute the residuals:
            \[
              \widehat{\delta}_t(s)
              \;=\;
              \sum_{a\in\mathcal{A}} \pi(a\mid s)\,r(s,a)
              \;+\;
              \sum_{a\in\mathcal{A}} \pi(a\mid s)\,\widehat{\sigma}_t(s,a)
              \;-\;
              V_t(s).
            \]
      \item Average the residuals:
            \[
               \overline{\delta}_t
               \;=\;
               \frac{1}{|\mathcal{S}|}\;\sum_{s\in\mathcal{S}}\;\widehat{\delta}_t(s).
            \]
      \item Update \(g\):
            \[
               g_{t+1}
               \;=\;
               g_t
               \;+\;
               \alpha_t\,\bigl(\,\overline{\delta}_t \;-\; g_t\bigr).
            \]
    \end{itemize}
\ENDFOR
\STATE \textbf{Output:} Final estimates \(\{V_T,\,g_T\}\).
\end{algorithmic}
\end{algorithm}

\noindent
\textbf{Description.} \\
The algorithm above provides a model-free policy evaluation method for robust average-reward Markov decision processes (MDPs). At iteration \(t\), it samples state--action pairs according to a fixed policy \(\pi\) on the nominal MDP. Using these samples, it obtains an approximate robust Bellman operator \(\widehat{T}_{g_t}V_t\) by estimating \(\sigma_{\mathcal{P}^a_s}(V_t)\), which is the worst-case expected bias term under the uncertainty set. The bias function \(V\) is then updated via a temporal-difference (TD) step with learning rate \(\alpha_t\). In parallel, the algorithm computes the residual \(\widehat{\delta}_t(s)\) and its average \(\overline{\delta}_t\), which measures how closely \(V\) aligns with the robust Bellman equation. The average reward parameter \(g\) is updated by moving it toward \(\overline{\delta}_t\). As \(t\) grows, both \(V_t\) and \(g_t\) converge to the fixed point of the robust average-reward Bellman equation, thus estimating the robust bias function and the robust average reward, respectively.

\begin{theorem}[Biased-Noise Variant of Theorem 3 with Sample Complexity]\label{thm:biasedNoiseExtended}
\emph{(cf.\ Theorem\,3 in \citep{zhang2021finite})}\,
Consider the stochastic approximation scheme
\begin{equation}\label{eq:updateRule}
  x^{t+1} \;=\; x^t \;+\; \eta_t \,\bigl[\,\widehat{H}(x^t) - x^t\bigr]\,,
  \quad t=0,1,2,\ldots,
\end{equation}
for finding an \emph{equivalent-class} fixed point \(x^*\in\mathbb{R}^n\) such that 
\[
  H(x^*) \;-\; x^* \;\in\;\overline{E},
  \quad \text{i.e. } \|H(x^*) - x^*\|_{c,\overline{E}} = 0.
\]
Here, \(\overline{E}\subseteq \mathbb{R}^n\) is a linear subspace, and we assume:

\begin{enumerate}
\item (\textbf{Contractive property in the semi-norm})
  For some \(\gamma\in(0,1)\),
  \[
    \|H(x) - H(y)\|_{c,\overline{E}}
    \;\le\;
    \gamma\,\|x - y\|_{c,\overline{E}}
    \quad\forall\,x,y\in \mathbb{R}^n.
  \]

\item (\textbf{Biased, bounded-variance noise}) For each iteration \(t\),
  \[
    \widehat{H}(x^t)
    \;=\;
    H(x^t)
    \;+\;
    w^t,
    \qquad
    \mathbb{E}[\,w^t \mid \mathcal{F}^t] 
    \;=\;
    \varepsilon_{\text{bias}}, 
    \qquad
    \mathbb{E}\bigl[\|\,w^t\|_{c,\overline{E}}^2 \,\big|\,
      \mathcal{F}^t\bigr]
    \;\le\;
    A 
    \;+\;
    B\,\|\,x^t - x^*\|_{c,\overline{E}}^2,
  \]
  for constants \(A,B \ge 0\) and a (possibly zero) bias vector \(\varepsilon_{\text{bias}}\).  
  The filtration \(\mathcal{F}^t\) is that generated by \(\{x^0,\ldots,x^t\}\).

\item (\textbf{Semi-Lyapunov function})
  Let \(M_{\overline{E}}(x)\) be defined by
  \[
    M_{\overline{E}}(x) 
    \;=\;
    \bigl(\,M \,\Box\, \delta_{\overline{E}}\bigr)(x),
  \]
  where \(M\) is a smooth, convex function used to ``regularize'' along the subspace \(\overline{E}\) (see \citep{zhang2021finite} for details). 
  By construction, there exist positive constants \(c_\ell,c_u\) such that
  \[
    c_\ell\,\|x - x^*\|_{c,\overline{E}}^2
    \;\le\;
    M_{\overline{E}}(x)
    \;\le\;
    c_u\,\|x - x^*\|_{c,\overline{E}}^2,
  \]
  and \(M_{\overline{E}}(\cdot)\) is \(L\)-smooth with respect to the semi-norm \(\|\cdot\|_{s,\overline{E}}\).  
\end{enumerate}

Then, under the step-size schedules:
\begin{itemize}
\item\textbf{(Decreasing step size)} 
  \(\displaystyle \eta_t \;=\;\frac{1}{\alpha_2\,(t+K)},\)
  with 
  \(\displaystyle K \;=\;\max\bigl\{\alpha_3/\alpha_2,\,3\bigr\}\),
\item\textbf{(Constant step size)} 
  \(\eta_t = \eta\) with \(\eta\,\alpha_3/\alpha_2 \le 1\),
\end{itemize}
the iteration \eqref{eq:updateRule} satisfies bounds analogous to those in \citep[Theorem\,3]{zhang2021finite}, but with additional bias-dependent terms. 
Specifically:

\begin{enumerate}
\item \emph{(Decreasing step size)} 
  \[
    \mathbb{E}\bigl[\|x^N - x^*\|_{c,\overline{E}}^2\bigr]
    ~\le~
    \frac{K^2}{(N+K)^2}\,\frac{c_u}{c_\ell}\,\|x^0 - x^*\|_{c,\overline{E}}^2
    \;+\;
    \frac{8\,\alpha_4\,c_u}{(N+K)\,\alpha_2^2}
    \;+\;
    \underbrace{\mathcal{O}\!\Bigl(\sum_{t=1}^N \eta_t\,\|\varepsilon_{\text{bias}}\|\Bigr)}_{\text{Bias term}}.
  \]
  In the special case \(\varepsilon_{\text{bias}}=0\), the bias term vanishes and this reduces exactly to \citep[Eq.\,(B.8)]{zhang2021finite}.

\item \emph{(Constant step size)} 
  \[
    \mathbb{E}\bigl[\|x^N - x^*\|_{c,\overline{E}}^2\bigr]
    ~\le~
    \bigl(1 - \alpha_2\bigr)^N \,\frac{c_u}{c_\ell}\,\|x^0 - x^*\|_{c,\overline{E}}^2
    \;+\;
    \frac{c_u\,\alpha_4}{\alpha_2}\,\eta
    \;+\;
    \underbrace{\mathcal{O}\!\bigl(\eta\,\|\varepsilon_{\text{bias}}\|\bigr)}_{\text{Bias term}}.
  \]
  Again, if \(\varepsilon_{\text{bias}}=0\), then we match \citep[Eq.\,(B.9)]{zhang2021finite} exactly.
\end{enumerate}

\paragraph{Sample complexity analysis.}
We now show how one obtains the typical \(\tilde{O}(\epsilon^{-2})\) complexity from these bounds.  For concreteness, consider the \emph{decreasing step-size} schedule, which yields 
\begin{align*}
\mathbb{E}\bigl[\|\,x^N - x^*\|_{c,\overline{E}}^2\bigr]
~\le~
\underbrace{\frac{K^2}{(N+K)^2}\,\frac{c_u}{c_\ell}\,\|x^0 - x^*\|_{c,\overline{E}}^2}_{\text{Term A}}
~+~
\underbrace{\frac{8\,\alpha_4\,c_u}{(N+K)\,\alpha_2^2}}_{\text{Term B}}
~+~
\underbrace{\mathcal{O}\!\Bigl(\sum_{t=1}^N \eta_t\,\|\varepsilon_{\text{bias}}\|\Bigr)}_{\text{Term C}}.
\end{align*}
We want this to be \(\le \epsilon^2\).  Observe that:
\begin{itemize}
\item \(\text{Term A} \approx \frac{1}{(N+K)^2}\) decays on the order of \(1/N^2\).
\item \(\text{Term B} \approx \frac{1}{N+K}\) decays on the order of \(1/N\).
\item \(\text{Term C} \approx \|\varepsilon_{\text{bias}}\|\sum_{t=1}^N \frac{1}{t+K}\) (since \(\eta_t = 1/[\alpha_2(t+K)]\)) grows roughly like \(\|\varepsilon_{\text{bias}}\|\ln N\).  
  - If \(\varepsilon_{\text{bias}}=0\), Term C disappears.  
  - If \(\varepsilon_{\text{bias}}\)\(\neq 0\) but small, we still get a mild \(\ln N\) factor.  
  - If \(\varepsilon_{\text{bias}}\) decays (e.g.\ exponentially in \(t\)), then Term C remains uniformly bounded.
\end{itemize}

\noindent
Hence, for \(\varepsilon_{\text{bias}} = 0\) (no bias), balancing Term B with \(\epsilon^2\) suggests:
\[
  \frac{1}{N} \;=\; O(\epsilon^2)
  \quad\Rightarrow\quad 
  N \;=\;O\bigl(\tfrac{1}{\epsilon^2}\bigr).
\]
Thus the sample/iteration complexity (the number of steps required so that the left-hand side is \(O(\epsilon^2)\)) is \(O(\epsilon^{-2})\).  

\smallskip

\noindent
\textbf{Case with bias:}
\begin{itemize}
\item If \(\varepsilon_{\text{bias}}\neq 0\) is constant, you converge only to a bias-dependent neighborhood of \(x^*\).  In that case, you cannot drive the error below a constant times \(\|\varepsilon_{\text{bias}}\|\).  

\item If \(\varepsilon_{\text{bias}}\) itself decays (e.g.\ exponentially) to zero, then for large \(t\), \(\|\varepsilon_{\text{bias}}\|\) is negligible, and \emph{effectively} we recover the same \(O(\epsilon^{-2})\) complexity for driving the residual below \(\epsilon\). 
\end{itemize}
A similar argument applies under the \emph{constant step size} scenario, but there the final bound has a geometric decay plus a constant ``variance'' offset, plus a bias offset.  The net result is also that you can achieve an \(\epsilon\)-level accuracy in \(O(\log(1/\epsilon))\) steps if ignoring variance, or remain in an \(\varepsilon_{\text{bias}}\)-proportional ball.

\end{theorem}

\begin{proof}[Proof Sketch]
See \citep{zhang2021finite} for the case of zero-mean martingale noise; the difference here is that 
\(\mathbb{E}[\,w^t \mid \mathcal{F}^t] \;=\;\varepsilon_{\text{bias}}\neq 0\).  
This introduces an extra term \(\eta_t \langle \nabla M_{\overline{E}}(x^t),\varepsilon_{\text{bias}}\rangle\) in the standard one-step analysis.  As in \citep[Lem.\,5]{zhang2021finite}, we combine the $L$-smoothness of \(M_{\overline{E}}\) and the $\gamma$-contractive property of \(H\) to show a negative drift in $M_{\overline{E}}(x^t-x^*)$ except for the noise terms.  The variance-boundedness yields a $\eta_t^2$ term, while the bias yields a $\eta_t$ term multiplied by $\|\varepsilon_{\text{bias}}\|$.  Summing or telescoping over $t=0$ to $N-1$ then yields the above recursion.  Finally, choosing $\eta_t=1/[\alpha_2(t+K)]$ (or $\eta_t=\eta$ constant) completes the derivation of the explicit bounds \citep[see also Eq.\,(B.8)--(B.9)]{zhang2021finite}.
\end{proof}



\begin{theorem}[Stochastic Approximation with Mini-batches and Decaying Bias]
\label{thm:MiniBatchDecayingBias}
Suppose we run the stochastic approximation update
\begin{equation}\label{eq:MiniBatchUpdate}
  x^{t+1} \;=\; x^t \;+\; \eta_t \bigl[\widehat{H}(x^t) - x^t\bigr],
\end{equation}
aiming to solve a contraction in the semi-norm
\(\|\!\cdot\!\|_{c,\overline{E}}\) (as in 
\citep[Assumption\,4]{zhang2021finite}
or Theorem\,\ref{thm:biasedNoiseExtended} above).
The difference here is:
\begin{enumerate}
\item \textbf{Mini-batch sampling.} 
  Each iteration \(t\) uses a mini-batch of size on the order of
  \(\log(N_{\max})\) 
  to estimate \(H(x^t)\).  Thus, if we run \(N\) total iterations, the \emph{total} sample usage is
  \(\widetilde{O}(N) \;=\; O\bigl(N \,\log(N_{\max})\bigr)\).
\item \textbf{Polynomially decaying bias.}
  The noise term \(w^t\) has expectation
  \(\mathbb{E}[w^t\mid\mathcal{F}^t] 
    = \varepsilon_{\text{bias}}^{\,t},\)
  where
  \(\|\varepsilon_{\text{bias}}^{\,t}\|\;=\;O\bigl(t^{-p}\bigr)\)
  for some \(p>0\).
  In particular, a common example is \(p=\tfrac12\) so that
  \(\|\varepsilon_{\text{bias}}^{\,t}\| = O\bigl(t^{-1/2}\bigr)\).
\item \textbf{Bounded (or mild) variance.} 
  We retain the usual assumption:
  \[
    \mathbb{E}\bigl[\|\,w^t\|_{c,\overline{E}}^2 
      \,\big|\,
      \mathcal{F}^t\bigr]
    \;\le\;
    A \;+\; B\,\|x^t - x^*\|_{c,\overline{E}}^2
    \quad\text{for constants }A,B\!\ge0.
  \]
\end{enumerate}
Then, under the same step-size choices (decreasing or constant) as in 
\citep[Theorem\,3]{zhang2021finite}
and Theorem\,\ref{thm:biasedNoiseExtended}, we achieve the usual 
\(\epsilon^{-2}\) \emph{iteration} complexity in order to make
\(\mathbb{E}[\|x^N-x^*\|_{c,\overline{E}}^2]\le \epsilon^2\).  
\emph{Moreover,} each iteration uses 
\(O(\log(N_{\max}))\) samples, so the \textbf{total sample complexity} is
\[
  \widetilde{O}\bigl(\epsilon^{-2}\bigr)
  \quad
  \text{(suppressing logarithmic factors).}
\]

\end{theorem}

\begin{proof}[Proof Sketch]
We outline the three main points:

\paragraph{1. Mini-batch with log-factors.}
Because each iteration uses a mini-batch of size proportional to \(\log(N_{\max})\), the variance of the noise estimate \(\widehat{H}(x^t)\) can be reduced by approximately a factor of \(\log(N_{\max})\).  Concretely, if each \(\widehat{H}(x^t)\) is formed by averaging \(\Theta(\log(N_{\max}))\) i.i.d.\ samples, then the variance satisfies
\[
   \mathbb{E}\bigl[\|w^t\|^2_{c,\overline{E}}\bigr]
   \;=\;
   O\!\Bigl(\tfrac{1}{\log(N_{\max})}\Bigr)
   \quad
   \text{(if originally on the order of 1).}
\]
All the classical SA bounds in \citep{zhang2021finite} (and references therein) then apply with this effectively smaller variance.

\paragraph{2. Polynomially decaying bias.}
We now have
\(\mathbb{E}[w^t \mid \mathcal{F}^t] 
   = \varepsilon_{\text{bias}}^{\,t}\),
with \(\|\varepsilon_{\text{bias}}^{\,t}\| = O(t^{-p})\).  
When unrolling the usual Lyapunov or smoothness argument, the bias contributes an extra term of the form
\[
   \sum_{t=1}^N \eta_t\,\bigl\|\varepsilon_{\text{bias}}^{\,t}\bigr\|.
\]
Assuming a decreasing step size \(\eta_t \approx 1/t\), 
we get a sum like
\[
   \sum_{t=1}^N 
     \frac{1}{t}\cdot \frac{1}{t^p}
   \;=\;
   \sum_{t=1}^N
     \frac{1}{t^{\,1+p}},
\]
which is finite (convergent) for \(p>0\).  Hence the bias term does \emph{not} accumulate unboundedly and does not degrade the overall \(1/N\)- or \(1/\sqrt{N}\)-style rates typically seen in SA.  

\paragraph{3. Net effect on sample complexity.}
Let \(N\) be the total number of outer iterations.  From Theorem\,\ref{thm:biasedNoiseExtended} (or \citep[Theorem\,3]{zhang2021finite}), we know the iteration count \(N\) needed to satisfy 
\(\mathbb{E}[\|x^N - x^*\|^2_{c,\overline{E}}]\le \epsilon^2\)
scales on the order of \(\epsilon^{-2}\).  
But each iteration now uses \(\Theta(\log(N_{\max}))\) samples.  If we take \(N_{\max} \approx N\approx \epsilon^{-2}\), then each iteration uses about \(\log(1/\epsilon)\) samples.  Hence the \emph{total sample usage} is
\[
   N \,\times\, O(\log(N_{\max}))
   \;\approx\;
   O\Bigl(\tfrac{1}{\epsilon^2}\,\log(\tfrac{1}{\epsilon})\Bigr),
\]
which is denoted 
\(\widetilde{O}\bigl(\epsilon^{-2}\bigr)\) 
by suppressing constant and polylogarithmic factors.  

Combining these points shows that mini-batching with a mild (logarithmic) cost per iteration plus a polynomially decaying bias still yields an \(\epsilon^{-2}\) iteration complexity, and thus an overall sample complexity of \(\widetilde{O}(\epsilon^{-2})\).
\end{proof}



\begin{theorem}[Finite-Sample Bound for the Average-Reward Parameter]
\label{thm:avg-reward-bound}
Consider the update
\[
  g_{t+1}
  \;=\;
  g_t
  \;+\;
  \alpha_t\bigl[\overline{\delta}_t - g_t\bigr],
  \quad
  \overline{\delta}_t
  \;=\;
  \delta(V_t)
  \;+\;
  W_t,
\]
where $g^*$ is the true robust average reward satisfying
\(\,\delta(V^*)=g^*\), and $W_t$ is a (possibly biased) noise process with
\(\mathbb{E}[|W_t|\mid \mathcal{F}_t]=\epsilon_{\mathrm{bias}}\) and bounded variance.
Then for any $N\ge1$ and suitable step sizes $\{\alpha_t\}$, the iterates $g_N$ satisfy:
\[
  \mathbb{E}\bigl[\,(g_N - g^*)^2\bigr]
  \;\;\le\;\;
  C_1\,\epsilon_{\mathrm{bias}}^2
  \;+\;
  C_2\,\mathbb{E}\!\Bigl[\bigl\|x^N - x^*\bigr\|_{\mathrm{span}}^2\Bigr]
  \;+\;
  \text{(terms that vanish under a standard SA schedule).}
\]
Here $x^N$ is the joint state of the $(V,g)$ iterates, and $C_1,C_2$ are positive constants
depending on the MDP parameters and the noise bounds.
\end{theorem}

\begin{proof}
Let $e_t \;\triangleq\; g_t - g^*$, and define a scalar Lyapunov function
\[
  M_g(e) \;=\; \tfrac12\,(e)^2.
\]
Using the Bellman-residual decomposition
\(\,\overline{\delta}_t = \delta(V_t) + W_t,\)
we rewrite the update for $g_{t+1}$ in terms of $e_t$:
\[
  e_{t+1}
  \;=\;
  e_t
  \;+\;
  \alpha_t \Bigl[\delta(V_t) - g^* + W_t - e_t\Bigr]
  \;=\;
  e_t + \alpha_t\bigl[\Delta_t^{(g)} + W_t - e_t\bigr],
\]
where
\(\,\Delta_t^{(g)} \;\triangleq\; \delta(V_t) - g^*.\)

\noindent
\textbf{Step 1: Expand the Lyapunov.}
\[
  M_g\bigl(e_{t+1}\bigr)
  \;=\;
  \tfrac12\,(e_{t+1})^2
  \;=\;
  \tfrac12\,
   \bigl[e_t + \alpha_t(\Delta_t^{(g)} + W_t - e_t)\bigr]^2.
\]
A straightforward expansion yields
\[
  M_g(e_{t+1})
  \;=\;
  M_g(e_t)
  \;+\;
  \alpha_t\,e_t\,\Delta_t^{(g)}
  \;+\;
  \alpha_t\,e_t\,W_t
  \;-\;
  \alpha_t\,(e_t)^2
  \;+\;
  \tfrac12\,\alpha_t^2
     \bigl[\Delta_t^{(g)} + W_t - e_t\bigr]^2.
\]

\noindent
\textbf{Step 2: Take conditional expectation.}
Denote by $\mathcal{F}_t$ the sigma-algebra up to time $t$. We know:
\[
  \mathbb{E}[\,|W_t|\mid \mathcal{F}_t] \;=\; \epsilon_{\mathrm{bias}},
  \quad
  \mathbb{E}\bigl[\,|W_t|^2 \mid \mathcal{F}_t\bigr]\;\le\;\sigma^2,
\]
and $\Delta_t^{(g)}$ depends only on $V_t$ (hence is $\mathcal{F}_t$-measurable).
Applying $\mathbb{E}[\cdot\mid \mathcal{F}_t]$ to each term gives
\[
  \mathbb{E}\bigl[M_g(e_{t+1})\bigr]
  \;\le\;
  \mathbb{E}\bigl[M_g(e_t)\bigr]
  \;-\;
  \alpha_t\,\mathbb{E}\bigl[(e_t)^2\bigr]
  \;+\;
  \alpha_t\,\mathbb{E}[\,e_t\,\Delta_t^{(g)}\,]
  \;+\;
  \alpha_t\,\epsilon_{\mathrm{bias}}
      \,\mathbb{E}\bigl[|e_t|\bigr]
  \;+\;
  \mathcal{O}\bigl(\alpha_t^2\bigr),
\]
where the $\mathcal{O}(\alpha_t^2)$ term includes
$\alpha_t^2\,\sigma^2$ and similar bounded-variance contributions.

\noindent
\textbf{Step 3: Summation and telescoping.}
Summing over $t=0$ to $N-1$, we telescope
\[
  \mathbb{E}[\,M_g(e_N)\,]
  \;=\;
  \mathbb{E}\bigl[\tfrac12\,(g_N-g^*)^2\bigr]
  \;\le\;
  \bigl[\text{(initial terms)}\bigr]
  \;+\;
  \sum_{t=0}^{N-1}
   \Bigl(\,\alpha_t\,\epsilon_{\mathrm{bias}}\,\mathbb{E}[\,|e_t|\,]
     \;+\;
     \alpha_t\,\mathbb{E}[\,e_t\,\Delta_t^{(g)}\,]
     \;+\;
     \alpha_t^2\,\sigma^2
   \Bigr)
   \;-\;
   \sum_{t=0}^{N-1}
   \alpha_t\,\mathbb{E}[(e_t)^2].
\]
We further note that $\Delta_t^{(g)} = \delta(V_t)-g^*$ is bounded by
some constant times $\|V_t - V^*\|_{\mathrm{span}}$, and
$\sum_{t}\alpha_t^2$ is typically finite for a standard SA schedule
(e.g.\ $\alpha_t=\alpha_0/t$).
Hence, collecting these terms yields a bound of the form
\[
  \mathbb{E}\bigl[(g_N - g^*)^2\bigr]
  \;\le\;
  C_1\,\epsilon_{\mathrm{bias}}^2
  \;+\;
  C_2\,\mathbb{E}\bigl[\|x^N - x^*\|_{\mathrm{span}}^2\bigr]
  \;+\;
  \text{other terms that vanish as }N\to\infty
  \text{ under suitable }\{\alpha_t\}.
\]
Therefore, $g_N$ converges up to an offset controlled by the bias level
$\epsilon_{\mathrm{bias}}$ and the accuracy of $V_t$, completing the proof.
\end{proof}
