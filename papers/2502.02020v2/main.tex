\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{color}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{algpseudocode}
\usepackage{algorithm}
\bibliographystyle{abbrvnat}   % bibliography
\usepackage{mathtools}      % define
\usepackage{subcaption}      % plots in one figure
\usepackage[numbers]{natbib}
%\usepackage[backend=biber]{biblatex}  % Load biblatex with biber
%\addbibresource{reference.bib}

\usepackage{amsthm} % use theoremstyle


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}%[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\newcommand{\qzedit}[1]{\textcolor{teal}{#1}}
 \newcommand{\qzcmt}[1]{\textcolor{red}{[QZ: #1]}}
 \newcommand\mbe{\mathbb E}
\newcommand\mbp{\mathbb P}

 \newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
 \def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\title{Causal Bandits with Backdoor Adjustment on Unknown Gaussian DAGs}


\author{
 Yijia Zhao \\
  Department of Statistics and Data Science\\
  University of California, Los Angeles\\
  Los Angeles, CA 90095 \\
  \texttt{yijiazhao@ucla.edu} \\
  %% examples of more authors
   \And
 Qing Zhou \\
  Department of Statistics and Data Science\\
  University of California, Los Angeles\\
  Los Angeles, CA 90095 \\
  \texttt{zhou@stat.ucla.edu} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle

\begin{abstract} %\qzcmt{The current title is not very attractive; thoughts on better alternatives?}
The causal bandit problem aims to sequentially learn the intervention that maximizes the expectation of a reward variable within a system governed by a causal graph. Most existing approaches assume prior knowledge of the graph structure, or impose unrealistically restrictive conditions on the graph. In this paper, we assume a Gaussian linear directed acyclic graph (DAG) over arms and the reward variable, and study the causal bandit problem when the graph structure is unknown. We identify backdoor adjustment sets for each arm using sequentially generated experimental and observational data during the decision process, which allows us to estimate causal effects and construct upper confidence bounds. By integrating estimates from both data sources, we develop a novel bandit algorithm, based on modified upper confidence bounds, to sequentially determine the optimal intervention. We establish both case-dependent and case-independent upper bounds on the cumulative regret for our algorithm, which improve upon the bounds of the standard multi-armed bandit algorithms. Our empirical study demonstrates its advantage over existing methods with respect to cumulative regret and computation time. 
\end{abstract}

\section{Introduction}

The multi-armed bandit (MAB) problem \cite{berry1985bandit} is an example of the exploration versus exploitation dilemma, which has been extensively studied in machine learning and statistics. Under the setting of an MAB problem, there is an action set $\mathcal A$ consisting of $K$ actions, also called arms. Each arm $a\in\mathcal A$ corresponds to a real-valued distribution of the reward variable, with some unknown expectation $\mu_a$. A player pulls the arms sequentially and chooses the next arm based on the past plays and obtained rewards. The goal is to find the arm with the largest reward and further control the expected loss due to the fact that the optimal arm is not always pulled. For the standard MAB problem, the arms are assumed to be independent of each other. Many well-designed algorithms have been proposed to study the standard MAB problem, among which upper confidence bound \cite{auer2002MAB} and Thompson sampling \cite{thompson1933} are most popular. For structured bandit problem, the arms are assumed to have some non-trivial dependencies among each other. Some examples include linear bandits \cite{dani2008stochastic}, combinatorial bandits \cite{cesa2012combinatorial}, etc. Algorithms for structured bandits utilize the dependencies among arms to expedite the sequential decision process.

Lattimore et al. \cite{lattimore2016causal} introduced the causal bandit problem, where a causal DAG model is assumed to govern the joint distribution of the reward variable, its covariates, and the arms. %Treating interventions on covariates as arms, causal bandits fit into the setting of structured bandit problems. 
Most existing works assume full knowledge of the underlying DAG structure and/or local conditional distributions of the variables. Under such settings, causal bandit (CB) algorithms were developed with bounds on the simple regret, such as the works of Lattimore et al. \cite{lattimore2016causal}, Sen et al. \cite{sen2017identifying}, and Yabe et al. \cite{yabe2018causal}, in the absence of unobserved confounders, and Lee and Bareinboim \cite{lee2018structural}, Maiti et al. \cite{maiti2022causal} when confounders exist. Some works further made additional assumptions on the causal model, such as Nair et al. \cite{nair2020budgeted} for no-backdoor graphs in the budgeted bandit framework and Lu et al. \cite{lu2020regret} for linear causal bandits. Since the underlying causal DAG is usually unknown in practice, application of the above methods has been limited.

\subsection{Related work}

When the underlying causal graph is unknown, a natural idea is to first learn the underlying graph via interventions and then apply causal bandit algorithms. But this approach is not efficient because recovering the full causal graph is not necessary for identifying the optimal arm. Lu et al. \cite{lu2021causal} proposed a central node - upper confidence bound (CN-UCB) algorithm to find the atomic intervention with the largest reward, assuming knowledge of observational probabilities instead of the full causal graph. Although observational data are often more accessible, % than experimental data in terms of costs, 
it is not always feasible to obtain enough observational data for accurate estimation of the observational distributions. Additionally, the domain set for all variables except the reward is assumed to be finite and discrete, in which case the exploration of arms can be restricted to the parents of the reward variable.

De Kroon et al. \cite{dekroon2022causal} tackled the problem for discrete and Gaussian models without knowledge of the underlying graph. But their method relies on the existence of a set of non-intervenable variables that d-separate the interventions and the reward variable. And no theoretical guarantee on the cumulative regret was provided. Huang and Zhou \cite{Jireh2022BBB} developed a Bayesian framework that utilizes joint inferences from experimental %\qzcmt{it might be better to call it experimental data (generated under interventions)} 
and observational data without additional assumptions on the underlying graph structure. But the Bayesian framework requires updating parent set posterior probabilities, which is extremely computationally challenging and practically infeasible even when $K$ is moderate.

 
\subsection{Contributions of this work}

In this paper, we take the challenge of causal bandit where the underlying DAG is unknown and go beyond discrete settings to continuous settings. We assume a Gaussian DAG model over all the variables, including the arms and the reward variable. We treat atomic interventions on variables as arms and aim to find the intervention with the largest causal effect on the reward variable. Unlike discrete settings, the optimal atomic intervention with the largest causal effect is not necessarily on the parent node of the reward variable, making it difficult to reduce the size of the candidate action set for continuous settings.


Under the setting of a causal DAG model, causal effects are defined via external interventions, which can be directly estimated from experimental data. When the underlying DAG is given, we are also able to obtain consistent estimates of causal effects from observational data via backdoor adjustment \cite{pearl2009causality}. As the DAG is unknown, we take an additional step to identify candidate backdoor adjustment sets using both experimental and observational data.  
Since observational data are much cheaper to obtain in practice, the addition of observational data would not greatly increase the cost. After the candidate backdoor adjustment sets are obtained, our method integrates estimates from both sources to facilitate the decision for the next round. 

Our contributions are summarized below. % Main contribution
%\begin{enumerate}
    %\item 
    First, we develop a backdoor adjustment - upper confidence bound (BA-UCB) algorithm that does not require any prior information or restriction on the underlying graph structure or knowledge of the observational distribution. Instead of learning the full DAG, our algorithm identifies candidate backdoor adjustment sets for the arms in a sequential decision process and combines observational and experimental data to infer the expected rewards and the associated confidence bounds. %whose corresponding estimates from observational data are close enough to those from interventional data. 
    %\item 
    Second, we establish finite-iteration upper bounds for the cumulative regret of the BA-UCB algorithm. Suppose that we generate $m$ experimental data and $n$ observational data at each round. Under some identifiability and sparsity assumptions, we show that the worst-case cumulative regret of our algorithm is bounded by $O(\sqrt{T\log T/(m+n)})$ with a sufficiently large number of prior observational data, where $T$ is the total number of rounds in the bandit algorithm. In contrast, the cumulative regret limit of the standard MAB algorithm is $O(\sqrt{KT\log T})$ \cite{russo2014learning}, where $K=|\mathcal{A}|$ is the total number of arms. If we assume that  $m+n$ experimental data are generated at each round, then the bound would be $O(\sqrt{KT\log T/(m+n)})$ for the standard MAB algorithm. This shows that our algorithm substantially relaxes the dependence of the cumulative regret on $K$ and makes efficient use of observational data which is much less costly than generating experimental data.
%\end{enumerate}
In addition, with empirical study, we show the superiority of the BA-UCB algorithm in the cumulative regret compared with UCB and CN-UCB \cite{lu2021causal}, and in computation time compared with the Bayesian backdoor bandit algorithm \cite{Jireh2022BBB}.



\section{Preliminaries}
\label{sec:setup}

In a causal graphical model \cite{pearl2009causality}, a DAG $\mathcal G$ models the causal relationships among a set of random variables $\mathcal X=\left\{X_1,\cdots, X_p\right\}$. %, and a joint probability distribution $P$ over $\mathcal X$ that factorizes over $\mathcal G$. 
A directed edge from $X_i$ to $X_j$ in the causal DAG $\mathcal G$ means that $X_i$ is a direct cause of $X_j$, in which case $X_i$ is called a parent of $X_j$ and $X_j$ is called a child of $X_i$. The parent set of $X_j$, denoted as $PA_{j}$, is the set of all the variables which have an edge directed into $X_j$, and the child set of $  X_j$, denoted as $CH_j$, is the set of all variables that have an edge directed from $X_j$. Each child-parent relationship in $\mathcal G$ is modeled by a function $X_j=f_j(PA_j,\varepsilon_j)$, $j=1,\cdots,p$, where $(\varepsilon_1,\cdots,\varepsilon_p)$ represent exogenous errors and are jointly independent. 

In this work, we focus on Gaussian DAGs whose functional relationships are given by linear structural equation models (SEM) with Gaussian errors, i.e.,
\begin{equation}\label{eq:GaussianBN}
    X_j=\sum_{i\in PA_j} \beta_{ij}X_i + \varepsilon_j, j=1,\cdots,p,
\end{equation}
where $\varepsilon_j\overset{\operatorname{indep.}}{\sim}\mathcal N(0,\omega_j^2)$. %We consider the problem of finding the variable with the largest causal effect on the reward variable designated as $Y = X_p$. Given our interest in finding the single variable with largest causal effect in magnitude on $Y$, we only need to consider atomic interventions. 
The reward variable is designated as $Y = X_p$. The causal effect of $X_i$ on $Y$ is defined via an atomic intervention that 
%An atomic intervention is an intervention on a single node $X_i\in\mathcal X$ which 
sets the variable $X_i$ to a fixed value $x_i$, denoted as $do(X_i=x_i)$. In general, the causal effect of $X_i$ on $Y$ is determined by the mapping $x_i\mapsto \mathbb P[Y|do(X_i=x_i)]$. For Gaussian DAGs, the causal effect $\gamma_i$ of $X_i$ on $Y$ is defined as
\begin{equation}
   \gamma_i:=\frac{\partial }{\partial x_i}\mathbb E(Y|do(X_i=x_i))
\end{equation}
and by linearity $\mathbb E(Y|do(X_i=x_i))=\gamma_ix_i$. Thus, for any intervention $do(X_i=x_i)$ on $X_i$ with $x_i\neq 0$, we can determine the causal effect $\gamma_i=\mathbb E(Y|do(X_i=x_i))/x_i$. %i.e., any intervention $do(X_i=x_i)$ with $x_i\neq 0$ can be rescaled to have the same causal effect as $do(X_i=\pm 1)$. 
Without loss of generality, we only consider $do(X_i=\pm 1)$ as the arms in our causal bandit problem, so that the reward magnitude across arms is on the same scale.



%\qzcmt{this part can be shortened; jump to the arm set.} 
Treating atomic interventions as arms, we can view the problem of finding the variable with the largest causal effect in the framework of a multi-armed bandit problem. The arm set is 
\begin{equation}\label{eq:arm_set}
    \mathcal A = \left\{do(X_i=x_i): x_i= -1\text{ or }1, i\in[p-1]\right\}.
\end{equation}
%where the relationship among all the arms are modeled by a Gaussian DAG. Note that 
Since $\mathbb E[Y| do(X_i=1)]=-\mathbb E[Y| do(X_i=-1)]$ under the linear SEM~\eqref{eq:GaussianBN}, we effectively merge the two arms by setting $x_i$ to be either $-1$ or $1$ according to the sign of the estimated causal effect of $\gamma_i$ in the bandit process. Consequently, the size of the arm set reduces to $K=|\mathcal A|=p-1$.
 
For simplicity, let arm $i$ correspond to the intervention $do(X_i=x_i)$ and identify the action set $\mathcal A=[p-1]$. For any arm $i\in \mathcal A$, the expected reward is defined as $\mu_i=\mathbb E[Y| do(X_i=x_i)]$, which is also the magnitude of the causal effect $\gamma_i$. The optimal reward is denoted by $\mu^*=\max_{i\in\mathcal A}\mu_i$ corresponding to the optimal arm $i^*=\operatorname{argmax}_{i\in\mathcal A}\mu_i$. The goal is to find the optimal arm while minimizing the expected loss in this process. The expected loss is measured by the cumulative regret up to round $T$,
\begin{equation}\label{eq:cumregret_def}
    \mathcal R_T\coloneq\mu^*T-\sum_{t=1}^T\mathbb E \left(\mu_{A_t}\right)=\sum_{i\in \mathcal A}\Delta_i\mathbb E \left(n_i(T)\right)
\end{equation}
where $\Delta_i=\mu^*-\mu_i$, $A_t$ denotes the arm chosen at round $t$, and $n_i(t)=\sum_{s=1}^t \mathbbm 1\{A_s=i\}$ denotes the number of times that arm $i$ has been pulled up to round $t$. A sequential decision-making policy that minimizes the cumulative regret has to handle the trade-off between exploration and exploitation.

Many algorithms have been proposed with guarantees on the cumulative regret for the standard multi-armed bandit problem, among which upper confidence bound (UCB) and Thompson sampling are two popular ones. The sequential decision rule of UCB algorithm for normally distributed rewards \cite{auer2002MAB} takes the format
\begin{equation}\label{eq:ucb_alg}
    A_{t+1}\in \underset{i \in \mathcal A}{\operatorname{ argmax }}\left\{\hat{\mu}_{i}(t)+\hat{\sigma}_{i}(t) c \sqrt{\log t}\right\},
\end{equation}
where $\hat\mu_i$ is an estimate of the expected reward, $\hat\sigma_i^2$ is an estimate of the variance of $\hat\mu_i$, and $c>0$ is a constant. Under the basic causal bandit setting, only experimental data will be obtained at each round of intervention and the two estimates $\hat\mu_i$ and $\hat\sigma_i$ are simply the mean and standard deviation of the sample mean of $Y$ under $\{do(X_i=x_i)\}$, respectively. 



\section{Backdoor adjustment UCB}
\label{sec:alg}

%In many real-life situations, obtaining interventional data can be costly. So we consider the  setting where we also collect observational data at each round and incorporate this side information into decision making. 

For Gaussian DAGs, the causal effect $\gamma_i$ of $X_i$ on $Y$ can be identified via backdoor adjustment
\begin{equation}
   \gamma_i=\beta_{X_i}(Y\sim X_i+S)
\end{equation}
where $S$ satisfies the backdoor criterion relative to $(X_i, Y)$ \cite{pearl2009causality} and $\beta_{X_i}(Y\sim X_i+S)$ denotes the regression coefficient corresponding to the term $X_i$ when regressing $Y$ on $(X_i,S)$, i.e., $\mathbb E(Y|X_i,S)=\beta_{X_i}X_i+\boldsymbol\beta_{S}^\top S$. Therefore, the causal effect of $X_i$ on $Y$ can be estimated using not only the experimental data under intervention on $X_i$ but also observational data as long as a backdoor adjustment set $S$ is provided.

\subsection{Identification of backdoor adjustment sets}
\label{subsec:backdoor_id}

In this section, we propose a method to identify backdoor adjustment sets for each node for the development of a causal bandit when the DAG is unknown. After we have identified a backdoor adjustment set, we can obtain estimate of the causal effect $\hat\mu_i$ and its variance $\sigma_i^2$ from both experimental and observational data, which can be combined to improve the estimation accuracy. %for estimating $\mu_i$ and $\sigma_i^2$.

%As described in Section \ref{sec:setup}, the estimation of causal effects from observational data relies heavily on the knowledge of backdoor adjustment sets, i.e., the graph structure. 


More specifically, suppose we collect $n$ observational data and $m$ experimental data at each round of play. Let $n_i(t)=\sum_{s=1}^t \mathbbm 1\{A_s=i\}$ denote the number of rounds at which intervention on $X_i$ is performed up to round $t$. Then, $N_i(t)=mn_i(t)$ is the number of data generated under intervention on $X_i$ up to round $t$. It is straightforward to obtain a consistent estimate of $\mu_i$ and an estimate of its variance from experimental data up to round $t$ as follows:
\begin{equation}\label{eq:est_int}
    \hat\mu_{i,\text{int}}(t)=\frac{1}{n_i(t)}\sum_{s=1}^t\bar Y_s\mathbbm 1\{A_s=i\}, \quad \widehat{\text{Var}}(\hat{\mu}_{i,\text{int}}(t))=\frac{s_i^2}{N_i(t)},
\end{equation}
where $\bar Y_t$ is the mean of rewards collected under intervention at round $t$ and $s_i^2$ is the sample variance of $Y$ generated under intervention on $X_i$. %From the property of Gaussian DAGs, the intervention distribution is $Y|do(X_i=x_i)\sim \mathcal N(\mu_i,\widetilde\sigma_i^2)$ , where $x_i=-1\text{ or }1$, and therefore $\hat\mu_{i,\text{int}}(t)\sim \mathcal N(\mu_i, \widetilde\sigma_i^2/N_i(t))$ is an unbiased estimator of $\mu_i$.

Let $N_o(t)$ denote the total number of observational data up to round $t$. For any set $S$ of nodes other than $X_i$ and $Y$, let $\widetilde S_i=[X_i\mid  S]$ be a matrix of dimension $N_o(t)\times (s+1)$, where $s=|S|$, and $\rho_i(t,S)$ be the $(1,1)$ element of the matrix $(\widetilde S_i^\top \widetilde S_i/N_o(t))^{-1}$. Denote by $\hat\beta=[\hat\beta_{X_i},\ \hat\beta_S]$ the least-squares coefficient vector for the linear regression $Y\sim X_i+S$ using observational data up to round $t$. Construct the following estimate of the reward under $do(X_i=x_i)$ and its variance,
\begin{equation}\label{eq:est_obs}
 \hat\mu_{i,\text{obs}}(t,S) =\hat \beta_{X_i}\cdot x_i,\quad \widehat{\text{Var}}(\hat{\mu}_{i,\text{obs}}(t,S))=\frac{\rho_i(t,S)\parallel Y- X_i\hat\beta_{ X_i}-S\hat\beta_{S}\parallel^2}{N_o(t)(N_o(t)-s-1)}.
\end{equation}
Since $Y|X_i,S\sim \mathcal N(X_i\beta_{X_i}+\beta_S^\top S, \zeta_{i,S}^2)$, where $\zeta_{i,S}^2$ is the variance of the reward variable conditioned on $X_i$ and $S$, we have $\hat\mu_{i,\text{obs}}(t,S)\sim \mathcal N(\beta_{X_i}x_i, \rho_i(t,S)\zeta_{i,S}^2/N_o(t))$. To simplify notation, let $\mu_i(S):=\beta_{X_i}x_i$. %when the regressor set is $S\cup \{X_i\}$. 
If $S$ satisfies the backdoor criterion relative to $(X_i,Y)$, then $\mu_i(S)=\mu_i$ and $\hat\mu_{i,\text{obs}}(t,S)$ is an unbiased estimator of $\mu_i$ with variance approximated by \eqref{eq:est_obs}.
Let $\mathcal B_i$ denote the collection of valid backdoor adjustment sets for $(X_i, Y)$.

Since experimental data and observational data are independent, %the distribution of  
\[\hat\mu_{i,\text{obs}}(t,S)- \hat\mu_{i,\text{int}}(t)\sim \mathcal N\left(\mu_i(S)-\mu_i, \frac{\rho_i(t,S)\zeta_{i,S}^2}{N_o(t)}+\frac{\widetilde\sigma_i^2}{N_i(t)} \right).\]
As $t$ increases, the Gaussian distribution will concentrate more and more around $\mu_i(S)-\mu_i$, which is $0$ if $S$ is a backdoor adjustment set relative to $X_i$ and $Y$. It is reasonable to assume $|\mu_i(S)-\mu_i|\geq 2\delta$ for some $\delta>0$ for those sets $S$ that do not satisfy the backdoor criterion relative to $X_i$ and $Y$. Then the difference between the two estimates --- $\hat\mu_{i,\text{obs}}(t,S)$ and $\hat\mu_{i,\text{int}}(t)$ --- will deviate from $0$ with high probability. Therefore, we can distinguish between sets $S\in\mathcal B_i$ from $S'\notin\mathcal B_i$ by checking whether the difference between the two estimates from observational data and experimental data is close to $0$. 

One might choose $S=\text{argmin}_{S'}|\hat\mu_i(S')-\hat\mu_{i,\text{int}}|$ at each time step $t$ as a candidate adjustment set relative to $X_i$ and $Y$. This idea turns out to be too greedy and leads to suboptimal choices for a bandit problem. To encourage more exploration, we instead construct confidence intervals $CI_i(t,S)$ at round $t$ for $\mu_i(S)-\mu_i$ as
\begin{equation}\label{eq:CI}
   \hat\mu_{i,\text{obs}}(t,S) - \hat\mu_{i,\text{int}}(t) \pm c_2\sqrt{\log t}\sqrt{ \widehat{\text{Var}}(\hat{\mu}_{i,\text{obs}}(t,S))+ \widehat{\text{Var}}(\hat{\mu}_{i,\text{int}}(t))},
\end{equation}
where $c_2$ is some constant. We choose sets $S$ whose corresponding confidence intervals cover $0$ as our candidate backdoor adjustment sets relative to $(X_i,Y)$. If none of these confidence intervals cover $0$, we choose the set whose confidence interval has the smallest distance to $0$.

Define the distance between an interval $[a,b]$ and the number $0$ as $d(0,[a,b])=\min\{|x|:a\leq x\leq b\}$. Then we can identify a collection of candidate backdoor adjustment sets relative to $(X_i, Y)$ at time step $t$ as
\begin{equation}\label{eq:backdoor_id}
    \widehat{\mathcal {B}}_i(t) = \text{argmin}_{S}\ d(0, CI_i(t,S)).
\end{equation}
Without any restriction, the choice of the set $S$ can be large especially when the number of nodes $p$ is large. %, among which a lot of sets don't satisfy the backdoor criterion. 
Let $M_i$ denote the Markov blanket of a node $X_i$ and $\mathcal N_i$ denote the collection of all subsets of $M_i$. Since the parent set $PA_i\subseteq M_i$ always satisfies the backdoor criterion, we can restrict $S\in \mathcal N_i$ in the above minimization to reduce the number of candidate sets.


\subsection{Algorithm description}
\label{subsec:alg}

In this section, we describe the backdoor adjustment - upper confidence bound (BA-UCB) algorithm for causal bandit. Unlike most existing methods, our algorithm does not require prior knowledge or exploration of the underlying DAG. The main idea is to use estimates from both experimental data and observational data to identify the backdoor adjustment sets described in Section~\ref{subsec:backdoor_id} and then design a combined version of upper confidence bounds from both sources.

For a basic MAB problem, upper confidence bounds are of the form $\hat\mu_i(t)+\hat\sigma_i(t)c\sqrt{\log t}$, where $\hat\mu_i(t)$ and $\hat\sigma_i(t)$ are the mean and standard deviation of the sample mean of $Y$ respectively. Since $\mu_i$ and $\sigma_i^2$ can be estimated from both experimental data as in \eqref{eq:est_int} and observational data as in \eqref{eq:est_obs}, we consider using weighted average of the two estimates to construct UCBs, i.e.,
\begin{equation}\label{eq:UCB}
    \hat{\mu}_{i}(t,S)=\frac{N_{o}(t) \hat{\mu}_{i,\text{obs}}(t,S)+N_{i}(t) \hat{\mu}_{a, \text{int}}(t)}{N_{o}(t)+N_{i}(t)},\quad 
\hat\sigma_i^2(t,S)=\frac{N_o^2(t)\widehat{\text{Var}}(\hat{\mu}_{i,\text{obs}}(t,S))+N_i^2(t)\widehat{\text{Var}}(\hat{\mu}_{i,\text{int}}(t))}{(N_o(t)+N_i(t))^2}.
\end{equation}
This effectively combines the two types of data to achieve higher estimation accuracy.


As discussed in Section~\ref{subsec:backdoor_id}, we restrict the choice of $S\subseteq \mathcal M_i$ to find candidate backdoor adjustment sets relative to $X_i$ and $Y$. So we first use observational data to estimate the Markov blanket $M_i$ of each node $X_i$, $i=1,\cdots, p-1$. For a DAG, the Markov blanket of a node $X_i$ includes its parents, children, and spouses. We apply a nodewise neighborhood regression method to estimate the Markov blanket \cite{wainwright2019high}.%The conditional distributions are $X_i|\mathbf X_{-i}\sim \mathcal N(\bar\mu_i,\bar\sigma_i^2)$, where $\bar\mu_i=\sum_{j:j\neq i}\bar\beta_{ij}X_j$ and $\bar\beta_{ij}= 0$ iff $X_i\indep X_j|\mathbf X_{-ij}$. So we can estimate the Markov blanket of $X_i$ by running a linear regression of $X_i$ on all other variables and choosing those with significant coefficients.

Once the estimated Markov blanket $\widehat{M}_i$ is obtained, we identify candidate backdoor adjustment sets $S\subseteq\widehat{M}_i$ as in 
\eqref{eq:backdoor_id}, sample one set $S$ from the candidate sets if $|\widehat{\mathcal B}_i(t)|\geq 2$, and construct the weighted version of UCBs to choose the intervention for the next round. The procedure is summarized in Algorithm~\ref{alg:BA-UCB}. In practice, the estimated Markov blanket and candidate backdoor adjustment sets will not vary significantly unless we collect enough new data. Therefore, to save computation, we do not update them every round.

\begin{algorithm}
   \caption{BA-UCB for Gaussian Causal Bandits}
   \label{alg:BA-UCB}
\begin{algorithmic}[1]
\Require Observational data $\mathbf D_0$ of size $n_0$, parameters  $c$, $c_3$, $n$, $m$, rounds $T$.
\For{$t=0,\cdots, T-1$}
\If{There is a node $i$ which has been intervened less than $\lceil\frac{c_3\log t+1}{m} \rceil$ times}
    \State Choose intervention node $A_{t+1} = i$;
\Else
\For {$i=1,\cdots, p-1$}
  \State Estimate the Markov blanket $\widehat{M}_i$; \label{alg:line:MB}%of each node $i$; %and find the collection of sets $\widehat{\mathcal N}_i$;
  \State Identify candidate backdoor adjustment sets $\widehat{\mathcal B}_i = \text{argmin}_{S \subseteq \widehat{M}_i} d(0, CI_i(t,S))$; \label{alg:line:backid}
  \State Sample set $S$ from $\widehat{\mathcal B}_i$, calculate $\hat{\mu}_{i,\text{obs}}(t,S)$ and $\hat\sigma_{i,\text{obs}}(t,S)$ as in \eqref{eq:est_obs};
   \State Calculate estimates $\hat\mu_i(t,S)$, $\hat\sigma_i^2(t,S)$ as in \eqref{eq:UCB};\label{alg:line:estimate}
\EndFor
    %\State Choose $A_{t+1}=\underset{i \in \{1, \ldots, p-1\}}{\operatorname{argmax}}\{\hat{\mu}_{i}(t,S)+$
    %\State \quad \quad \quad $\hat{\sigma}_{i}(t,S) c \sqrt{\log t}\}$; 
    \State $A_{t+1}=\operatorname{argmax}_i \{\hat{\mu}_{i}(t,S)+\hat{\sigma}_{i}(t,S) c \sqrt{\log t}\}$;
\EndIf 
\State Generate $m$ data points under intervention $A_{t+1}$ and $n$ observational data. \label{alg:line:collect}
\EndFor
\Ensure Final intervention $A_T$ and estimated reward $\hat \mu^*$.
\end{algorithmic}
\end{algorithm}

\begin{remark}\label{remark:one-regression}
   According to Rule 2 of $do$ Calculus in Pearl \cite{pearl2009causality}, when $S$ blocks all backdoor paths from $X$ to $Y$, we have $P(Y|do(X=x),S)= P(Y|x, S)$, i.e., conditioning on the backdoor adjustment set $S$, the intervention distribution $[Y| do(x),S]$ is identical to the conditional distribution $[Y| x,S]$. Hence, given a backdoor adjustment set $S$ for $X_i$, we can perform a single regression $Y\sim X_i + S$ on both experimental data under $do(X_i)$ and observational data to estimate $\mu_i$ and $\sigma_i^2$. This is another way to combine the two types of data to generate estimates and construct UCBs. In general, the estimates by this single-regression approach will be slightly less efficient than the weighted ones \eqref{eq:UCB} because of the inclusion of the additional predictors $S$ for experimental data. As shown in Figure~\ref{fig:compare_lm} of Appendix~\ref{appendix:experiments}, BA-UCB algorithm with estimates generated from this single-regression approach has almost the same empirical performance with respect to the cumulative regret as the weighted average approach. 
\end{remark}


\section{Experiments}
\label{sec:experiments}

In this section, we ran simulations to evaluate the empirical performance of our proposed BA-UCB algorithm. In our main experiments, we compared BA-UCB with three competing methods: the standard UCB, central node (CN) - UCB proposed by Lu et al. \cite{lu2021causal}, and Bayesian backdoor bandit (BBB)- UCB proposed by Huang and Zhou \cite{Jireh2022BBB}. We considered DAGs with number of nodes $p=10,20,30,50$. Under each setting, we randomly generated 100 Gaussian DAGs, ran the algorithms 5 times on each one, and recorded the average cumulative regrets over $T=5000$ time steps. 

\subsection{Implementation details}
\label{subsec:implement}

In this section, we describe how we generated the Gaussian DAGs and implementation details of the algorithms.
 
Since the average execution time of BBB-UCB was $8.2$ seconds for each iteration on a randomly generated Gaussian DAG with 10 nodes, it is prohibitive to run it for $5000$ time steps on $100$ Gaussian DAGs on a single CPU core. So for $p=10$, we directly used the Gaussian DAGs and the corresponding simulation results uploaded by Huang and Zhou \cite{Jireh2022BBB}, which are available on \href{https://github.com/jirehhuang/bcb}{https://github.com/jirehhuang/bcb}. Since the computation time is expected to grow super-exponentially with the number of nodes, we excluded BBB-UCB from our comparison when $p$ was greater than $10$. To generate Gaussian DAGs, we first randomly generated the underlying DAG using \verb|random.graph| function in \verb|bnlearn| package, then sampled coefficients $\beta_{ij}$ from $[-1,-0.5]\cup [0.5,1]$ for $X_i\in PA_j^\mathcal G$ and standard deviations $\omega_i$ from $[\sqrt{0.2},\sqrt{0.5}]$, and finally normalized the variables to have unit variance. %To reliably generate distributions with meaningful causal effects and reward signals, 
We set maximum in-degree to be 3 and chose the last variable in the topological sort as the reward variable $Y$ to minimize the number of trivial arms. 


%As described in \cite{Jireh2022BBB}, they first randomly generated graph structures given a fixed topological sort $X_1\prec\cdots\prec X_{10}$ using the process adapted from \cite{de2022causal} with reward variable $Y=X_{10}$, sampled coefficients from $[-1,-0.5]\cup [0.5,1]$ for $X_i\in PA_j^\mathcal G$ and standard deviations from $[\sqrt{0.5},1]$, and then normalized the system to have unit variance to generate the GBNs. They additionally assume maximum in-degree to be 3 to reliably generate distributions with meaningful causal effects and reward signals. 

Central node - UCB algorithm was proposed for discrete network settings, aiming to first identify the parents of the reward variable, and then restrict the action set of UCB to the identified parent nodes. To mimic the mechanism under Gaussian settings, we first applied the PC algorithm \cite{spirtes1991algorithm} to identify neighbors of the reward variable $Y$ using observational data, and then applied UCB algorithm on these identified neighbors. The significance level of the PC algorithm for conditional independence test was set to $\alpha=0.1$. Each node was intervened on at least 5 times at the beginning to allow the UCB algorithm to accumulate enough data. Note that, unlike discrete settings, the optimal intervention with the largest causal effect may not be a parent node of the reward under Gaussian settings. So this procedure may have a bad performance under the scenario that the optimal intervention is not on $PA_Y$. 

For our proposed BA-UCB algorithm, we chose $\tau = 1/\sqrt{N_{\text{obs}}(t)}$ as the threshold for p-values when estimating the Markov blanket through linear regression. After trying several choices of parameters, we set $c=c_2=1/\sqrt{2}$ under all settings. To reduce the computational cost, we only considered $\{S\in \widehat{\mathcal N}_i:|S|\leq 3\}$ in the identification of candidate backdoor set in Algorithm~\ref{alg:BA-UCB}. Additionally, to accumulate enough observational data, we estimated the Markov blanket $M_i$, calculated $\widehat{\mathcal B}_i$, and updated the estimates from observational data every $\kappa$ steps. We set $\kappa=20,50,100, 200$ for $p=10,20,30,50$, respectively, so that the computation time of $5000$ iterations was below 5 minutes under all settings. The numerical results were all generated on a macOS system with M1 chip, 8-core CPU, and 16GB memory.
% How I implement BA-UCB, choice of paramenters.



\subsection{Simulation results}
\label{subsec:sim_results}


We first compared the empirical cumulative regret of BA-UCB algorithm with other competing methods when $p=10$. Recall that $n_0$ is the number of initial observational data, $n$ is the number of observational data collected at each round, and $m$ is the number of experimental data collected at each round. The simulation results of BBB-UCB algorithm were generated with $n_0=320$ initial observational data and $m=1$ experimental data at each round. %Given that the cost required to generate an observational data compared with experimental data was negligible, 
We chose $n=m=1$ and $n_0=320$ for our BA-UCB algorithm. For CN-UCB algorithm, we set $n_0=320$ and $m=2$. For UCB algorithm, we collected $4$ experimental data from each arm at the beginning, i.e., $36$ initial experimental data in total, before incurring regrets, and set $m=2$ for each round. Assuming the cost of collecting experimental data is 10 times the cost of observational data, the initial cost of the UCB algorithm was comparable with the other algorithms. Note that $m=2$ experimental data were simulated at each round of CN-UCB and UCB, while we only generated $m=1$ experimental data and $n=1$ observational data for our BA-UCB algorithm. While these three algorithms collected the same number of data points at each round, CN-UCB and UCB algorithms generated experimental data only. Since experimental data are much more informative and also more expensive than observational data, the comparison setting here is in favor of CN-UCB and UCB algorithms.

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=0.65\textwidth]{Plots/comp_4.pdf}}
    \caption{Comparison of empirical cumulative regrets over 5000 time steps for BA-UCB, BBB-UCB, CN-UCB, and UCB algorithms when $p=10$.}
    \label{fig:comp2}
    \end{center}
    \vskip -0.2in
\end{figure}

% Some explanation of Figure 1. Choice of parameters and what this graph shows.

 The result is shown in Figure~\ref{fig:comp2}. It is seen that CN-UCB had a bad performance because the optimal interventions of 22 out of the 100 Gaussian DAGs were not on the parent nodes of the reward variable. Our BA-UCB algorithm achieved a much lower cumulative regret compared to the standard UCB algorithm and CN-UCB algorithm on average. Note that the parameters were $n=m=1$ for BA-UCB and $m=2$ for UCB and CN-UCB. Our proposed BA-UCB algorithm may cost much less in practice since generating observational data is much cheaper than experimental data. BBB-UCB achieved an excellent performance at the cost of computation time and resources. More specifically, BBB-UCB required exact computation of the parent set posteriors at each time step at complexity of $O(p3^p)$, and may not be feasible when $p$ is large. 

Since BBB-UCB algorithm does not scale well with $p$, we excluded it from our next comparison for $p = 20, 30, 50$. Given that the performance of CN-UCB strongly depends on whether or not the optimal intervention is on a parent node of the reward variable, we partitioned the results according to these two different scenarios. The parameters were set as $n_0 = 100$ and $m=n=1$ for BA-UCB; $n_0 = 5100$ and $m = 1$ for CN-UCB; $m = 2$ for UCB and also burned the first 50 steps. Note that the total number of data generated was the same for all three algorithms. Since observational data are much cheaper to generate, BA-UCB and CN-UCB may cost a lot less than UCB algorithm in practice. The results are reported in Figure~\ref{fig:comp1}.

From Figure~\ref{fig:comp1}, our BA-UCB algorithm outperformed UCB algorithm under all scenarios on average. The cumulative regrets for both algorithms, as well as the differences between the two, increased when $p$ increased. The CN-UCB algorithm is identical to the standard UCB algorithm but with a limited set of nodes for intervention, which is usually much smaller than $p$. When the optimal arm indeed corresponded to intervention on a parent of the reward variable, it was not surprising that CN-UCB  outperformed our method as shown in the lower panel of the figure. However, in practice, one cannot guarantee this is always the case. As reported in the top panel, the CN-UCB algorithm showed a substantially inferior performance when the optimal arm was not an intervention on a parent node.

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=0.65\textwidth]{Plots/comp_3.pdf}}
    \caption{Comparison of empirical cumulative regrets over 5000 time steps for BA-UCB, CN-UCB, and UCB algorithms under the settings of $p=20,30,50$. The top panel reports the cases where the optimal arm is not a parent of the reward variable and the lower panel reports the cases where the optimal arm is a parent of the reward variable.} 
    \label{fig:comp1}
    \end{center}
    \vskip -0.2in
\end{figure}


\section{Regret analysis}
\label{subsec:regret}

In this section, we provide theoretical analyses on the cumulative regret of our proposed BA-UCB algorithm. Since using the same data for identifying backdoor adjustment sets in Line~\ref{alg:line:backid} and constructing combined estimates in Line~\ref{alg:line:estimate} of Algorithm~\ref{alg:BA-UCB} complicates the theoretical analysis, we consider sample splitting to simplify the proof. More specifically, we collect $2n_0$ observational data at the beginning of Algorithm~\ref{alg:BA-UCB}, $2m$ experimental data and $2n$ observational data at each round in Line~\ref{alg:line:collect}, and use half of the data to identify candidate backdoor adjustment sets in Line~\ref{alg:line:backid} and the other half to calculate estimates in Line~\ref{alg:line:estimate}. Our theoretical results in this section are all established under this sample-splitting version of Algorithm~\ref{alg:BA-UCB}. %The only difference from our setting in \ref{sec:alg} and \ref{sec:experiments} is that we double the sample sizes and use separate data for the two procedures. 
In practice, the algorithm works well without sample splitting as demonstrated by the numerical experiments in Section~\ref{sec:experiments}.






% Need more explanation here. Show its superiority.

As explained in Section~\ref{subsec:backdoor_id}, we need to assume a gap between $\mu_i(S)$ for $S\notin \mathcal B_i$ and the true causal effect $\mu_i$, which is formally stated as Assumption~\ref{ass:id}.

\begin{assumption}[Identifiability]\label{ass:id}
    There exists $\delta>0$, such that $|\mu_i(S')-\mu_i(PA_i)|\geq 2\delta$, $\forall S'\in\mathcal N_i/ \mathcal B_i$ and $i\in\{1,\cdots, p-1\}$.
\end{assumption}

\begin{remark}\label{remark:gap_condition}
Since we do not need to recover the entire graph, faithfulness
assumption is not required in our work. Note that backdoor adjustment relies only on the recursive factorization of the joint distribution according to a DAG, which is
implied by the SEM in \eqref{eq:GaussianBN}. %\ref{ass:id} could be implied by faithfulness assumption and thus is a weaker assumption.
\end{remark}

%Let $s_0=\max_{1\leq i\leq p-1}\max\{|PA_i|,|CH_i|\}$ 
Let $s_0$ be the maximum in and out degree of all nodes except the reward variable, $s_1=\max_{1\leq i\leq p-1}|M_i|$ denote the maximum size of the Markov blankets, and $s_2=\max_{1\leq i\leq p-1}|\mathcal N_i\setminus \mathcal B_i|$ be the maximum number of subsets in the Markov blankets that do not satisfy the backdoor criterion. To make sure our algorithm works properly, we also need a minimal number of observational data for estimating Markov blanket in Algorithm~\ref{alg:BA-UCB} and $\hat{\beta}$ in~\eqref{eq:est_obs} from backdoor adjustment sets, which is stated in Assumption~\ref{ass:n0}.

\begin{assumption}\label{ass:n0}
$n_0+nK\geq K$.
\end{assumption}
This assumption is easily satisfied when $n\geq 1$ or $n_0\geq K$. In fact, if we use Lasso-based neighborhood regression to estimate Markov blanket and restrict the search of candidate backdoor adjustment sets to subsets with cardinality  $\leq s_0$ for computational efficiency, then Assumption~\ref{ass:n0} can be relaxed to $n_0+nK\geq s_0+2$. 

Recall a few relevant notations introduced earlier in the paper.
The joint distribution of $X$ defined by the linear SEM \eqref{eq:GaussianBN} is $\mathcal N( 0,\Sigma)$, where $\Sigma=( I- B)^{-\top}\Omega( I-  B)^{-1}$, $\Omega=\text{diag}(\omega_1^2,\cdots,\omega_p^2)$ and $ B=(\beta_{ij})_{p\times p}$.
The distribution of the reward variable $Y$ under intervention is   $Y|do(X_i=x_i)\sim \mathcal N(\mu_i,\widetilde\sigma_i^2)$
and the conditional distribution
     $Y|X_i,S\sim \mathcal N(X_i\mu_i(S)+\beta_S^\top S, \zeta_{i,S}^2)$.


Let $\gamma_{\min}$,$\gamma_{\max}$, and $\operatorname{tr}$ represent the smallest eigenvalue, the largest eigenvalue, and the trace of a matrix, respectively. Define a few constants:
\begin{equation}\label{eq:def_notation}
    \begin{aligned}
\widetilde{\eta}_i^2&=\underset{S\in\mathcal B_i}{\max}\left\{ \frac{9\zeta_{i,S}^2}{\gamma_{\min}(\Sigma)},\tilde\sigma_i^2\right\},\quad\quad
\widetilde\eta^2=\max_i\widetilde{\eta}_i^2,\\
\widetilde\phi^2 &= \underset{i}{\max}\underset{S\in\mathcal B_i}{\max}\max\left\{\frac{9\zeta_{i,S}^2}{\gamma_{\min}(\Sigma)\tilde\sigma_i^2},\frac{25\tilde\sigma_i^2\gamma_{\max}(\Sigma)}{9\zeta_{i,S}^2}\right\},\\
 \psi^2&=\max_i\max_{S'\in \mathcal N_i\setminus\mathcal B_i}\max\left\{\frac{9\zeta_{i,S'}^2}{\gamma_{\min}(\Sigma)},\widetilde\sigma_i^2\right\}.
    \end{aligned}
\end{equation}


Now we formally state the case-dependent upper bound on the cumulative regret of the BA-UCB algorithm. 
\begin{theorem}\label{thm1}
Under Assumption~\ref{ass:id} and Assumption~\ref{ass:n0}, the cumulative regret of Algorithm~\ref{alg:BA-UCB}, with parameters $c\geq 4\sqrt{2}\widetilde\phi$ and $c_3\geq \max\left\{64,32\psi^2/\delta^2\right\}$, after $T$ rounds is at most
\begin{equation}\label{eq:thm1}
\begin{aligned}
   \log T\left(\frac{20c^2}{n+m}\sum_{i:\mu_i<\mu^*}\frac{\widetilde\eta_i^2}{\Delta_i}+\frac{c_3\sum_{i=1}^K\Delta_i}{m}\right)+C_3 \sum_{i=1}^K\Delta_i,
\end{aligned}
\end{equation}
where $C_3$ is a constant that does not depend on $T$.
\end{theorem}
In general, $C_3$ depends on $\Sigma$, $n_0$ and $n$, and its exact expression is provided in Appendix~\ref{appendix:const}. We use ``case-dependent" to refer to a bound that has explicit dependency on $\Delta_i=\mu^*-\mu_i$.

Further assuming all rewards are bounded, i.e. $\mu_i\in[-1,1]$, without loss of generality, we derive a case-independent upper bound on the cumulative regret that has no explicit dependency on $\Delta_i$: 
\begin{theorem}\label{thm2}
    Assume $\mu_i\in[-1,1],\forall i\in\{1,\cdots,p-1\}$. Then under Assumption~\ref{ass:id} and Assumption~\ref{ass:n0}, the cumulative regret of Algorithm~\ref{alg:BA-UCB}, with parameters $c\geq 4\widetilde\phi$ and $c_3\geq \max\left\{32, 32\psi^2/\delta^2\right\}$, after $T$ rounds is at most
\begin{equation}\label{eq:thm2}
2c\widetilde\eta \sqrt{\log T}\min\Bigg\{\frac{\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}}{n+m},\ \frac{\sqrt{n_0+nT}-\sqrt{n_0}}{n}\mathbbm 1\{n\geq 1\}\Bigg\}
   +\frac{2Kc_3\log T}{m}
        +C_4,
\end{equation}
where $C_4$ is a constant that does not depend on $T$.
\end{theorem}
In general, $C_4$ depends on $\Sigma$, $n_0$, $m$, and $n$, and the exact expression is provided in Appendix~\ref{appendix:const}.

To better understand how observational data can benefit the sequential decision process, we take a closer look at \eqref{eq:thm2}. Since $T$ is usually much larger than $K$, the first term in \eqref{eq:thm2} is the leading term. If $n_0$ is large relative to $T$, more specifically $n_0\geq T(n+m)$, we have  
\begin{equation*}
    \left(\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}\right)/(n+m) 
=\frac{\sqrt{K^2n_0}}{n+m}\left(\sqrt{1+\frac{(n+m)T}{Kn_0}}-1\right)\leq \frac{T}{2\sqrt{n_0}}\leq \frac{1}{2}\sqrt{\frac T {n+m}},
\end{equation*}
where the first inequality is due to $(1+x)^{1/2}\leq 1+x/2$ for $x>0$. In this case, the leading term of the cumulative regret is $O(\sqrt{T\log T/(n+m)})$, which does not depend on $K$ and decreases with the total number $2(m+n)$ of experimental and observational data collected at each round. The cumulative regret of a standard UCB algorithm that generates $2(n+m)$ experimental data at each round is $O(\sqrt{KT\log T/(n+m)})$. This shows that by using a large prior observational data with backdoor adjustment, we reduce the regret substantially by a factor of $\sqrt{K}$, thus removing its dependency on the action set size $K$. Moreover, the value of observational data generated at each round is comparable to that of experimental data in terms of minimizing the cumulative regret.

If $n_0$ is small relative to $T$, since $f(x)=\sqrt{x+a}-\sqrt{x}$ is a decreasing function of $x$ when $a>0$, the leading term in~\eqref{eq:thm2} is bounded by the minimum between $O(\sqrt{KT\log T/(n+m)})$ and $O(\sqrt{T\log T/n})$. %When $K/(n+m)\leq 1/n$, i.e., $K<1+m/n$ is not a large number, the leading term of the cumulative regret is $O(\sqrt{KT\log T/(n+m)})$; 
For most problems, we have $K> 1+m/n$, in which case the leading term is $O(\sqrt{T\log T/n})$ and does not depend on $K$. 
If the action set is large, i.e., $K\gg 1+m/n$, then the bound of BA-UCB $O(\sqrt{T\log T/n})$ will be much smaller than
the bound of the standard UCB $O(\sqrt{KT\log T/(n+m)})$ discussed above. Note that under this case,
the regret bound of our algorithm is $O(\sqrt{T\log T/n})+O(K\log T/m)$ and thus experimental data is still needed at each round ($m\geq 1$).
In summary, as long as we collect enough observational data with either a large initial $n_0$ or during the bandit process ($n\geq 1$), we can relax the dependence of the dominating term in our cumulative regret on the number of arms $K$, and substantially reduce the cumulative regret compared to the traditional MAB algorithms. 
    
The regret analysis confirms the advantage of our BA-UCB algorithm using observational data for the causal bandit problem. With backdoor adjustment, observational data can be used to estimate the causal effects of all arms simultaneously, which relaxes the dependence of the cumulative regret on the number of arms. Note that, even with a sufficiently large amount of observational data, one can at most recover the equivalence class of a DAG, represented by a completed partially directed acyclic graph (CPDAG). In the Gaussian case, however, one cannot reduce the action set given a CPDAG to a small subset of the nodes in general. Thus, our approach is fundamentally different from the existing works \cite{lu2021causal, dekroon2022causal} that use prior data or knowledge to reduce the action set before a sequential bandit algorithm.



\section{Conclusions and discussions}\label{sec:discussion}

In this paper, we studied the causal bandit problem under the setting of Gaussian DAGs when the underlying DAG is unknown. We proposed the BA-UCB algorithm which identifies candidate backdoor adjustment sets using estimates from both observational and experimental data, and then sample from these candidate sets to construct weighted upper confidence bounds for making sequential decisions. The reason for updating backdoor adjustment sets along with more interventions is that graph structure can not be fully recovered even with a sufficiently large number of observational data. Therefore, our approach is fundamentally different from other existing works that use prior data or knowledge to reduce the action set before a sequential bandit algorithm. 


Our worst case upper bound on the cumulative regret is proven to be of the order $O(\sqrt{T\log T/(n+m)})$ with a large number of initial observations, which does not depend on the size of action set and decreases with the
number of data collected at each round. Empirical study shows that the cumulative regret of our algorithm is smaller than UCB and CN-UCB algorithms on average, especially when the optimal arm is not a parent of the reward, and it is more scalable with the number of nodes than BBB-UCB algorithm.

Limitations of our method can be followed by future works in several directions. Our method is proposed only for the setting of Gaussian DAGs, assuming no observed confounders, and may be difficult to generalize to non-Gaussian settings. A direct next step is to modify our algorithm to accommodate unobserved confounders. Extension to linear structural equation models with non-Gaussian errors and other distributions needs further consideration. In addition, our proposed method puts no effort into structural discovery of the underlying graph and offers little help in understanding the causal mechanism among variables. 



\bibliography{reference} 
%\printbibliography




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Explicit expressions of constants}\label{appendix:const}
Aside from the notations in the main paper, we also have
\begin{itemize}
    \item[]  $X_i| X_{-i}\sim \mathcal N(\bar\mu_i,\bar\sigma_i^2)$, where $\bar\mu_i=\sum_{j:j\neq i}\bar\beta_{ij}X_j$ and $\bar\beta_{ij}= 0$ iff $X_i\indep X_j| X_{-ij}$.
\end{itemize}
Further define
\begin{align*}
    \psi^2&=\max_i\max_{S'\in \mathcal N_i\setminus\mathcal B_i}\max\left\{\frac{9\zeta_{i,S'}^2}{\gamma_{\min}(\Sigma)},\widetilde\sigma_i^2\right\},\\
    \bar\beta_i&=\min_{j:\beta_{ij}\neq 0}|\bar\beta_{ij}|,\\
\alpha&=\min_i\frac{\sqrt{\gamma_{\text{min}}(\Sigma)}\bar\beta_i}{18\sqrt{3} \bar\sigma_i}.
\end{align*} 
Then
\begin{align*}
C_3=2+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\left(s_2+\frac{4}{3}\right)\pi^2+\frac{\pi^2}{3e^{(n_0-s_0-2)/16}}+\frac{36(2s_1+2K+2s_2+1)}{ne^{(n_0+9nK-K-1)/18}}+\frac{4K}{\alpha^2 ne^{\alpha^2 (n_0+9nK)}}+\left(\frac{c_3}{n}\right)^2,
\end{align*}

\begin{align*}
    C_4 = 2+\frac{18\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\left(2s_2+\frac{7}{3}\right)\pi^2+\frac{\pi^2}{6e^{(n_0-s_0-2)/16}}+\frac{2K}{m}+\frac{36(4s_1+3K+2+4s_2)}{n e^{(n_0+9nK-K-1)/18}}&+ \frac{8K}{\alpha^2 ne^{\alpha^2 (n_0+9nK)}}\\
    &+2\left(\frac{c_3}{n}\right)^2.
\end{align*}
Note that when $n_0$ is relatively large and $n$ is non-zero in our algorithm, those terms with $\exp(n_0+9nK)$ or $\exp(n_0)$ in the denominator are usually small numbers. In the rest terms, $\frac{\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}$, $\frac{2K}{m}$, and $s_2\pi^2$ grow with the number of arms $K$.


\section{Additional experiments} \label{appendix:experiments}

This section is a complementary material for our simulation study. Figure~\ref{fig:comp2_CI} shows the range of empirical cumulative regrets between 5\% quantile to 95\% quantile across 100 simulated Gaussian DAGs at $T=1000, 3000, 5000$ for the four algorithms compared in Figure~\ref{fig:comp2} of the main paper. The lower bar represents 5\% quantile. The upper bar represents 95\% quantile. The point on each lines represents the median. As displayed in Figure~\ref{fig:comp2_CI}, the comparison results remain similar to what we have observed in main paper's Figure~\ref{fig:comp2} across different time steps.

Figure~\ref{fig:comp1_box} displays boxplots of the empirical cumulative regrets on the simulated Gaussian DAGs at the end of $5000$ rounds of BA-UCB, CN-UCB, and UCB algorithms under the same settings as in Figure~\ref{fig:comp1} in the main paper. The left panel shows the boxplots across 50 Gaussian DAGs whose optimal arm is a parent of the reward and the right panel shows the boxplots across 50 Gaussian DAGs whose optimal arm is not a parent of the reward.

Figure~\ref{fig:compare_lm} compares the empirical cumulative regrets of BA-UCB algorithm with estimates generated from weighted estimates \eqref{eq:UCB} and those from one linear regression averaged over time on 100 randomly generated Gaussian DAGs with $p=10,20,30$. According to Figure~\ref{fig:compare_lm}, their performances are almost the same with respect to the cumulative regret. 

\begin{figure}[ht]
    \centering
    \includegraphics[width = 0.65\textwidth]{Plots/comp2_CI.pdf}
    \caption{Ranges of empirical cumulative regrets between 5\% quantile and 95\% quantile at $T=1000, 3000, 5000$ across 100 simulated Gaussian DAGs for BA-UCB, BBB-UCB, CN-UCB, UCB algorithms when $p=10$.}
    \label{fig:comp2_CI}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=0.45\textwidth]{Plots/box1.pdf}
%  \caption{Optimal arm is a parent of the reward.}
%  \label{fig:sfig1}
%\end{figure}
%\begin{figure}
 % \centering
  \includegraphics[width=0.45\columnwidth]{Plots/box2.pdf}
%  \caption{Optimal arm is not a parent of the reward.}
%  \label{fig:sfig2}
\caption{Boxplots of cumulative regrets after $T=5000$ rounds for BA-UCB, CN-UCB, UCB algorithms when $p=20, 30, 50$. Left: Optimal arm is a parent of the reward. Right: Optimal arm is not a parent of the reward.}
\label{fig:comp1_box}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width = 0.65\textwidth]{Plots/compare_lm.pdf}
    \caption{Comparison of empirical cumulative regrets of BA-UCB algorithms with estimates generated from weighted sum and one linear regression over time when $p=10, 20, 30$.}
    \label{fig:compare_lm}
\end{figure}

\section{Detailed proof}\label{appendix:proof}

In this section, we first provide proof for the upper bounds on the cumulative regret when the underlying DAG is given. Then we modify the proof to extend it to the DAG unknown case. 

\subsection{Some general bounds}\label{appendix:rho_bounds}


\begin{theorem}\label{thm:rho}
    Let $\mathbf X\in \mathbb R^{n\times p}$ be drawn according to the $\Sigma$-Gaussian ensemble. For any $i\in \{1,\cdots, p\}$ and any $S\subset \{1,\cdots, p\}\setminus \{i\}$, denote $S_i=[X_i\mid S]$ and $\rho_i(t,S)=\left[\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)^{-1}\right]_{i,i}$. Then $\forall t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\max}(\Sigma)}$, 
    \begin{equation}\label{eq:rho}
        \begin{aligned}
            &\mathbb P\left( \rho_i(t,S)\geq \frac{9}{\gamma_{\min}(\Sigma)}\right)\leq \exp\left(-\frac{N_o(t)}{18}\right),\\
            &\mathbb P\left( \rho_i(t,S)\leq \frac{9}{25\gamma_{\max}(\Sigma)}\right)\leq \exp\left(-\frac{N_o(t)}{18}\right).
        \end{aligned}
    \end{equation}
\end{theorem}


\textit{Proof.} Theorem 6.1 in Wainwright \cite{wainwright2019high} states that:  Let $\mathbf X\in \mathbb R^{n\times d}$ be drawn according to the $\Sigma$-Gaussian ensemble. Then for all $\delta>0$, the maximum singular value $\sigma_{\max}(\mathbf X)$ satisfies the upper deviation inequality
\begin{align*}
    \mathbb P\left[\frac{\sigma_{\max}(\mathbf X)}{\sqrt n}\geq \gamma_{\max}(\sqrt{\Sigma})(1+\delta)+\sqrt{\frac{tr(\Sigma)}{n}}\right]\leq e^{-n\delta^2/2}.
\end{align*}
Moreover, for $n\geq d$, the minimum singular value $\sigma_{\min}(\mathbf X)$ satisfies the analogous lower deviation inequality
\begin{align*}
    \mathbb P\left[\frac{\sigma_{\min}(\mathbf X)}{\sqrt n}\leq \gamma_{\min}(\sqrt{\Sigma})(1-\delta)-\sqrt{\frac{tr(\Sigma)}{n}}\right]\leq e^{-n\delta^2/2}.
\end{align*}

From Cauchy interlacing theorem, we have
\begin{align*}
    \rho_i(t,S)&=\left[\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)^{-1}\right]_{i,i}\leq \gamma_{\max}\left[\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)^{-1}\right]=\frac{1}{\gamma_{\min}\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)}\\
    &\leq \frac{1}{\gamma_{\min}\left(\frac{\mathbf X^\top \mathbf X}{N_o(t)}\right)}= \left(\frac{\sqrt{N_o(t)}}{\sigma_{\min}(\mathbf X)}\right)^2.
\end{align*}
Therefore,
\begin{align*}
    \mathbb P\left( \rho_i(t,S)\geq\frac{1}{\left(\gamma_{\min}(\sqrt{\Sigma})(1-\delta)-\sqrt{\frac{tr(\Sigma)}{N_o(t)}}\right)^2} \right)
    \leq & \mathbb P\left( \left(\frac{\sqrt{N_o(t)}}{\sigma_{\min}(\mathbf X)}\right)^2\geq\frac{1}{\left(\gamma_{\min}(\sqrt{\Sigma})(1-\delta)-\sqrt{\frac{tr(\Sigma)}{N_o(t)}}\right)^2} \right)\\
    = &\mathbb P\left( \frac{\sigma_{\min}(\mathbf X)}{\sqrt{N_o(t)}}\leq\gamma_{\min}(\sqrt{\Sigma})(1-\delta)-\sqrt{\frac{tr(\Sigma)}{N_o(t)}} \right)\\
    \leq &\exp\left(-N_o(t)\delta^2/2\right).
\end{align*}
Let $\sqrt{\frac{\text{tr}(\Sigma)}{N_o(t)}}\leq \frac{\gamma_{\min}(\sqrt{\Sigma})}{3}$, i.e., $t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}$ and $\gamma_{\min}(\sqrt{\Sigma})(1-\delta)-\sqrt{\frac{\text{tr}(\Sigma)}{N_o(t)}}=\frac{1}{3}\gamma_{\min}(\sqrt{\Sigma})$, i.e., $\delta=\frac{2}{3}-\sqrt{\frac{\text{tr}(\Sigma)}{N_o(t)\gamma_{\min}(\Sigma)}}\geq \frac{1}{3}$, then
\begin{align*}
    \mathbb P\left( \rho_i(t,S)\geq \frac{9}{\gamma_{\min}(\Sigma)}\right)\leq \exp\left(-\frac{N_o(t)}{18}\right),\ \forall t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}.
\end{align*}

Similarly, we also have
\begin{align*}
    \rho_i(t,S)=\left[\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)^{-1}\right]_{i,i}\geq \gamma_{\min}\left[\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)^{-1}\right]=\frac{1}{\gamma_{\max}\left(\frac{X_{S_i}^\top X_{S_i}}{N_o(t)}\right)}\geq \frac{1}{\gamma_{\max}\left(\frac{\mathbf X^\top \mathbf X}{N_o(t)}\right)}= \left(\frac{\sqrt{N_o(t)}}{\sigma_{\max}(\mathbf X)}\right)^2.
\end{align*}
Therefore,
\begin{align*}
    \mathbb P\left( \rho_i(t,S)\leq\frac{1}{\left(\gamma_{\max}(\sqrt{\Sigma})(1+\delta)+\sqrt{\frac{tr(\Sigma)}{N_o(t)}}\right)^2} \right)&\leq  \mathbb P\left( \left(\frac{\sqrt{N_o(t)}}{\sigma_{\max}(\mathbf X)}\right)^2\leq\frac{1}{\left(\gamma_{\max}(\sqrt{\Sigma})(1+\delta)+\sqrt{\frac{tr(\Sigma)}{N_o(t)}}\right)^2} \right)\\
    &= \mathbb P\left( \frac{\sigma_{\max}(\mathbf X)}{\sqrt{N_o(t)}}\geq\gamma_{\max}(\sqrt{\Sigma})(1+\delta)+\sqrt{\frac{tr(\Sigma)}{N_o(t)}} \right)\\
    &\leq \exp\left(-N_o(t)\delta^2/2\right).
\end{align*}
Let $\sqrt{\frac{\text{tr}(\Sigma)}{N_o(t)}}\leq \frac{\gamma_{\max}(\sqrt{\Sigma})}{3}$, i.e., $t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\max}(\Sigma)}$ and $\gamma_{\max}(\sqrt{\Sigma})(1+\delta)+\sqrt{\frac{tr(\Sigma)}{N_o(t)}}=\frac{5}{3}\gamma_{\max}(\sqrt{\Sigma})$, i.e., $\delta=\frac{2}{3}-\sqrt{\frac{\text{tr}(\Sigma)}{N_o(t)\gamma_{\max}(\Sigma)}}\geq \frac{1}{3}$, then
\begin{align*}
    \mathbb P\left( \rho_i(t,S)\leq \frac{9}{25\gamma_{\max}(\Sigma)}\right)\leq \exp\left(-\frac{N_o(t)}{18}\right),\ \forall t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\max}(\Sigma)}.
\end{align*}




\subsection{When the underlying DAG is given}\label{appendix:DAGgiven}

When the DAG is given, we know the parents of each node $X_i$ which satisfies the backdoor criterion relative to $(X_i,Y)$. So Algorithm 1 in the main paper can be reduced to the algorithm below.

\begin{algorithm}
\caption{Combined-UCB for Gaussian Causal Bandits (DAG given)}\label{alg:Combined-UCB}
\begin{algorithmic}
\Require DAG $\mathcal G$, Observational data $\mathbf D_0$, parameters $m$, $n$, $c$, $c_3$, rounds $T$.
\For{$t=1,\cdots, T$}
\If{There is a node $i$ which has been intervened less than $\lceil\frac{c_3\log t}{n+m} \rceil$ times}
    \State Choose intervention node $A_{t} = i$;
\Else
    \State Calculate $\hat\mu_i(t-1, PA_i)$ and $\hat\sigma_i(t-1,PA_i)$ for each $i\in\{1,\cdots, K\}$;
    \State Choose intervention node $A_{t}\in \underset{i \in \{1, \ldots, K\}}{\operatorname{ argmax }}\left\{\hat{\mu}_{i}(t-1,PA_i)+\hat{\sigma}_{i}(t-1,PA_i) c \sqrt{\log (t-1)}\right\}$.
\EndIf
\State Sample $m$ data points under intervention $A_{t+1}$ and $n$ observational data.
\EndFor
\Ensure Optimal intervention $A_T$ and estimated reward $\hat \mu^*$.
\end{algorithmic}
\end{algorithm}

The theoretical results on the cumulative regret are summarized in the following theorems. Denote $\zeta_i^2=\zeta_{i,PA_i}^2$ for simplicity.


\subsubsection{Case-dependent bound}

\begin{theorem}[Case-dependent bound]\label{thm:DAGgiven_casedepend}
  Define  $ \phi^2= \underset{1\leq i\leq K}{\max}\max\left\{\frac{9\zeta_{i}^2}{\gamma_{\min}(\Sigma)\tilde\sigma_i^2},\frac{25\tilde\sigma_i^2\gamma_{\max}(\Sigma)}{9\zeta_{i}^2}\right\}$, ${\eta}_i^2=\max\left\{ \frac{9\zeta_{i}^2}{\gamma_{\min}(\Sigma)},\sigma_i^2\right\}$. Then the cumulative regret of Algorithm~\ref{alg:Combined-UCB} at the end of $T$ rounds is at most
\begin{equation}\label{eq:regret_dependent_DAG}
    \log T\left(\frac{20c^2}{n+m}\sum_{i:\mu_i<\mu^*}\frac{\eta_i^2}{\Delta_i}+\frac{c_3\sum_{i=1}^K\Delta_i}{n+m}\right)+C_1\left(\sum_{j=1}^K\Delta_j\right)
\end{equation}
where $ C_1=1+\frac{\pi^2}{3}+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\frac{\pi^2}{3}\exp\left(-\frac{n_0-s_0-2}{16}\right)+\frac{36K}{n}\exp\left(-\frac{n_0+9nK}{18}\right)$, tuning parameters $c\geq 4\sqrt{2}\phi$, $c_3\geq 64$.  
\end{theorem}

\textit{Proof.} Following the proof in Auer et al. \cite{auer2002MAB}, let $c_t=c\sqrt{\log t}$, $n^*(t)$ is the times of round that the optimal intervention is picked, $\widehat\mu_u^*(t)$ be the estimated mean for the optimal intervention when $S=PA^*$ and $n^*(t)=u$, $\widehat\mu_{i,u_i}(t)$ be the estimated mean for any arm $i$ when $S=PA_i$ and $n_i(t)=u_i$, similarly for $\widehat \sigma$, then we have
\begin{align*}
     &n_i(T) =\sum_{t=1}^{T}\mathbbm 1\left\{A_{t}=i\right\} \leq \ell+\sum_{t=\ell+1}^{T}\mathbbm 1\left\{A_{t}=i, n_i(t-1) \geq \ell\right\} \\ 
     & \leq \ell+\sum_{t=\ell}^{T-1}\mathbbm 1\{\widehat{\mu}^{*}(t)+\widehat{\sigma}^*(t)c_{t} \leq \widehat{\mu}_i(t)+\widehat{\sigma}_i(t)c_{t},n_i(t-1) \geq \ell\} \\ 
     & \leq \ell+\sum_{t=\ell}^{T-1}\mathbbm 1\left\{\min _{1\leq u\leq t} \widehat{\mu}_{u}^{*}(t)+\widehat\sigma_u^*(t) c_{t} \leq \max _{\ell \leq u_{i}\leq t} \widehat{\mu}_{i, u_{i}}(t)+\widehat\sigma_{i,u_i}(t) c_{t}\right\} \\ 
     & \leq \ell+\sum_{t=\ell}^{T-1} \sum_{u=1}^{t} \sum_{u_{i}=\ell}^{t}\mathbbm 1\left\{\widehat{\mu}_{u}^{*}(t)+\widehat\sigma_u^*(t) c_{t} \leq  \widehat{\mu}_{i, u_{i}}(t)+\widehat\sigma_{i,u_i}(t) c_{t}\right\} .
\end{align*}
Then 
\begin{align*} 
n_i(T) \leq & \ell+\sum_{t=\ell}^{T-1} \sum_{u=1}^{t} \sum_{u_{i}=\ell}^{t}\Big[\mathbbm 1\left\{\widehat\mu_u^{*}(t) \leq \mu^{*}-\widehat\sigma_u^*(t)c_{t}\right\}\\
& +\mathbbm 1\left\{\widehat\mu_{i, u_{i}}(t) \geq \mu_{i}+\widehat\sigma_{i,u_i}(t)c_{t}\right\} +\mathbbm 1\left\{\mu^{*}<\mu_{i}+2 \widehat\sigma_{i,u_i}(t)c_{t}\right\}\Big].
\end{align*}
Therefore
\begin{equation}\label{eq:proof_1}
    \begin{aligned} 
\mbe \left[n_i(T)\right] \leq & \ell+\sum_{t=\ell}^{T-1} \sum_{u=1}^{t} \sum_{u_{i}=\ell}^{t}\Big[\mbp\left(\widehat\mu_u^{*}(t) \leq \mu^{*}-\widehat\sigma_u^*(t)c_{t}\right)\\
& +\mbp\left(\widehat\mu_{i, u_{i}}(t) \geq \mu_{i}+\widehat\sigma_{i,u_i}(t)c_{t}\right) +\mbp \left(\mu^{*}<\mu_{i}+2 \widehat\sigma_{i,u_i}(t)c_{t}\right)\Big].
\end{aligned}
\end{equation}

For the last part in \eqref{eq:proof_1}, denote $s=|PA_i|$, then
\begin{align*}
    \mathbb P\left( \mu^{*}<\mu_{i}+2 \widehat\sigma_{i,u_i}(t)c_{t}\right)= \mathbb P\left(\widehat\sigma_{i,u_i}^2(t)>\frac{\Delta_i^2}{4c^2\log(t)}\right),
\end{align*}
where \begin{align*}
&\widehat\sigma_{i,u_i}^2(t)=\frac{(n_0+nt)^2\widehat{\text{Var}}(\hat{\mu}_{i,\text{obs}}(t))+(mu_i)^2\widehat{\text{Var}}(\hat{\mu}_{i,\text{int}}(t))}{(n_0+nt+mu_i)^2},\\
&\widehat{\text{Var}}(\hat{\mu}_{i,\text{int}}(t))\sim \frac{\widetilde\sigma_{i}^2}{mu_i(mu_i-1)}\chi_{mu_i-1}^2,\\
&   \widehat{\text{Var}}(\hat{\mu}_{i,\text{obs}}(t))=\frac{1}{n_0+nt} \rho_i(t,PA_i)\widehat{\zeta}_{i}^2(t),\\
  & \widehat{\zeta}_{i}^2(t)\sim \frac{\zeta_{i}^2}{n_0+nt-s-1}\chi_{n_0+nt-s-1}^2.
\end{align*}
Given the independence of observational data and interventional data, we have
\begin{align*}
     \widehat\sigma_{i,u_i}^2(t)\sim \frac{\left[\frac{( n_0+nt)\rho_i(t,PA_i)}{ n_0+nt-s-1}\zeta_{i}^2\chi_{ n_0+nt-s-1}^2+\frac{mu_i}{mu_i-1}\widetilde\sigma_{i}^2\chi_{mu_i-1}^2\right]}{(n_0+ nt+mu_i)^2}.
\end{align*}

Since $t\geq \ell$, $u_i\geq \ell$, $n_0\geq s+1$, let $\ell \geq p$ , we have $\frac{n_0+nt}{n_0+nt-s-1}\leq 2$ and $\frac{mu_i}{mu_i-1}\leq 2$. If we define $\eta_i^2 = \max\{\rho_i(t,PA_i)\zeta_i^2,\widetilde\sigma_i^2\}$, then we have
\begin{align*}
    \frac{( n_0+nt)\rho_i(t,PA_i)}{ n_0+nt-s-1}\zeta_{i}^2\chi_{ n_0+nt-s-1}^2+\frac{mu_i}{mu_i-1}\widetilde\sigma_{i}^2\chi_{mu_i-1}^2\leq 2\eta_i^2\chi_{n_0+nt+mu_i-s-2}^2.
\end{align*}
Therefore,
\begin{align*}
    \mathbb P\left(\widehat\sigma_{i,u_i}^2(t)>\frac{\Delta_i^2}{4c^2\log t}\right)
    \leq \mathbb P\left(\chi_{  n_0+nt+mu_i-s-2}^2>\frac{(n_0+nt+mu_i)^2\Delta_i^2}{8c^2\eta_i^2\log t}\right).
\end{align*}
From Lemma 1 in Laurent and Massart \cite{laurent2000adaptive},
\begin{align}\label{eq:chi_bound}
&\mathbb{P}\left\{\chi_{n}^{2}-n \geq 2 \sqrt{n} \sqrt{x}+2 x\right\} \leq e^{-x} \\
&\mathbb{P}\left\{\chi_{n}^{2}-n \leq-2 \sqrt{n} \sqrt{x}\right\} \leq e^{-x}
\end{align}
Let $x=\frac{n}{4}$ and $x=\frac{n}{9}$ respectively, then $\mathbb{P}\left\{\chi_{n}^{2} \geq 5n/2\right\} \leq e^{-n/4}$ and $\mbp \left\{\chi_n^2\leq n/3\right\}\leq e^{-n/9}$.

When $\frac{(n_0+nt+mu_i)^2\Delta_i^2}{8c^2\eta_i^2\log t}\geq \frac{5}{2}(n_0+nt+mu_i-s-2)$, i.e., $u_i\geq \ell\geq \frac{20c^2\eta_i^2\log t}{(m+n)\Delta_i^2}$ we have
\begin{align*}
   \mathbb P\left(\chi_{  n_0+nt+mu_i-s-2}^2>\frac{(n_0+nt+mu_i)^2\Delta_i^2}{8c^2\eta_i^2\log t}\right)&\leq \exp\left(-(n_0+nt+mu_i-s-2)/4\right)\\
  &\leq \exp\left(-(n_0-s-2+(m+n)u_i)/4\right).
\end{align*}
Let $u_i\geq \frac{16\log t}{n+m}$, then
\begin{align*}
   \mathbb P\left(\chi_{  n_0+nt+mu_i-s-2}^2>\frac{(n_0+nt+mu_i)^2\Delta_i^2}{8c^2\eta_i^2\log t}\right)\leq t^{-4}e^{-(n_0-s-2)/4}.
\end{align*}
Let $\phi_i^2=\min \{\rho_i(t,PA_i)\zeta_i^2,\widetilde\sigma_i^2\}$, then 
\begin{align*}
     \frac{( n_0+nt)\rho_i(t,PA_i)}{ n_0+nt-s-1}\zeta_{i}^2\chi_{ n_0+nt-s-1}^2+\frac{mu_i}{mu_i-1}\widetilde\sigma_{i}^2\chi_{mu_i-1}^2\geq \phi_i^2\chi_{n_0+nt+mu_i-s-2}^2.
\end{align*}
Below ignoring $t$ in the notation for simplicity, we have 
\begin{align*}
\widehat\mu_{i,u_i}=\frac{N_o\widehat\mu_{i,\text{obs}}+N_i\widehat\mu_{i,\text{int}}}{N_o+N_i}\sim \mathcal N\left(\mu_i,\frac{N_i\tilde\sigma_i^2+N_o\zeta_{i}^2\rho_i(PA_i)}{(N_i+N_o)^2}\right).
\end{align*}
Therefore
\begin{align*}
    \mathbb P(\widehat\mu_{i, u_{i}}\geq \mu_{i}+\widehat\sigma_{i,u_i}c_{t})&= \mathbb P\left(\frac{\widehat\mu_{i, u_{i}}-\mu_{i}}{\widehat\sigma_{i,u_i}}\geq c_{t}\right)\\
&\leq\mathbb P\left( \frac{\sqrt{N_i\tilde\sigma_i^2+N_o \zeta_{i}^2\rho_i(PA_i)}}{N_i+N_o}\frac{\mathcal N(0,1)}{\sqrt{\frac{\phi_{i}^2}{(N_o+N_i)^2}\chi_{N_o+N_i-s-2}^2}}\geq c_t\right)\\
&\leq\mathbb P\left( \frac{\eta_i\sqrt{N_i+N_o}}{\phi_i\sqrt{N_o+N_i-s-2}}\frac{\mathcal N(0,1)}{\sqrt{\frac{\chi_{N_o+N_i-s-2}^2}{N_o+N_i-s-2}}}\geq c_t\right)\\
&\leq \mathbb P\left(\frac{\sqrt 2 \eta_i}{\phi_i}t_{N_o+N_i-s-2}\geq c\sqrt{\log t}\right)\\
&=\mathbb P\left(t_{N_o+N_i-s-2}\geq \frac{c\phi_i \sqrt{\log t}}{\sqrt{2}\eta_i}\right).
\end{align*}

According to the following inequality
\begin{align*}
    \mathbb{P}(|t_r|\geq \delta)\leq 2e^{-\delta^2/4}+e^{-r/16},\forall \delta>0,
\end{align*}
we have
\begin{align*}
    \mathbb P(\widehat\mu_{i, u_{i}}\geq \mu_{i}+\widehat\sigma_{i,u_i}c_{t})&\leq \exp\left(-\frac{c^2\phi_i^2\log t}{8\eta_i^2}\right)+\frac{1}{2}\exp\left(-\frac{n_0+nt+mu_i-s-2}{16}\right)\\
    &\leq t^{-c^2\phi_i^2/8\eta_i^2}++\frac{1}{2}\exp\left(-\frac{n_0+nt+mu_i-s-2}{16}\right).
\end{align*}
Re-define $\phi^2=\underset{i}{\max} \eta_i^2/\phi_i^2=\underset{i}{\max}\max\left\{\frac{\rho_i(t,PA_i)\zeta_i^2}{\widetilde\sigma_i^2},\frac{\widetilde\sigma_i^2}{\rho_i(t,PA_i)\zeta_i^2}\right\}$, $s_0= \underset{i}{\max} |PA_i|$, $u_i\geq \frac{64\log t}{n+m}$, $c\geq 4\sqrt{2}\phi$, we have 
\begin{align*}
    \mathbb P(\widehat\mu_{i, u_{i}}\geq \mu_{i}+\widehat\sigma_{i,u_i}c_{t})\leq t^{-4}\left(1+\frac{1}{2\exp((n_0-s_0-2)/16)}\right).
\end{align*}

Set minimum intervention times as $\frac{64\log t}{n+m}$, similarly for the optimal arm, we have 
\begin{equation}\label{eq:bound_mustar}
     \mbp\left(\widehat\mu_u^{*}(t) \leq \mu^{*}-\widehat\sigma_u^*(t)c_{t}\right)\leq t^{-4}\left(1+\frac{1}{2\exp((n_0-s_0-2)/16)}\right).
\end{equation}
   


Then $\mbe \left[n_i(T)\right]$ can be bounded by 
\begin{align*}
   \ell+ t^{-2}\left(2+2\exp\left(-\frac{  n_0-s_0-2}{16}\right)\right).
\end{align*}

The conditions are summarized as follows:
\begin{align*}
    \ell &\geq \lceil\frac{20c^2\frac{\eta_i^2}{\Delta_i^2}\log t}{m+n}\rceil, \text{ where } c\geq 4\sqrt{2}\phi;\\
    \ell &\geq \lceil \frac{c_3\log t}{n+m}\rceil, \text{ where } c_3\geq 64.
\end{align*}
Also let $\ell\geq \lceil\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}\rceil$. Given Theorem~\ref{thm:rho} in Appendix~\ref{appendix:rho_bounds},  and $$2\sum_i\sum_{t=\ell}^{\infty}\left(-\frac{n_0+nt}{18}\right)\leq 2K\int_{\ell}^{+\infty}\exp\left(-\frac{n_0+nt}{18}\right)dt\leq\exp\left(-\frac{n_0+n\ell}{18}\right)\frac{36K}{n},$$ 
re-define 
\begin{align*}
   \eta_i^2&=\max\{ \frac{9\zeta_{i}^2}{\gamma_{\min}(\Sigma)},\tilde\sigma_i^2\},\\
   \phi^2 &= \max_i\max\left\{\frac{9\zeta_{i}^2}{\gamma_{\min}(\Sigma)\tilde\sigma_i^2},\frac{25\tilde\sigma_i^2\gamma_{\max}(\Sigma)}{9\zeta_{i}^2}\right\},
\end{align*}
then the final bound of $\mathbb E[n_i(T)]$ is 
\begin{align*}
    20c^2\frac{\eta_i^2}{\Delta_i^2}\frac{\log T}{n+m}+\frac{c_3\log T}{n+m}+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+1+\frac{\pi^2}{3}\left(1+\exp\left(-\frac{n_0-s_0-2}{16}\right)\right)+\frac{36K}{n}\exp\left(-\frac{n_0+9nK}{18}\right).
\end{align*}



Then the upper bound of $\mathbb E[R_T]$ can be expressed as
\begin{equation}\label{eq:upperbound_DAG_dep}
    \log T\left(\frac{20c^2}{n+m}\sum_{i:\mu_i<\mu^*}\frac{\eta_i^2}{\Delta_i}+\frac{c_3\sum_{i=1}^K\Delta_i}{n+m}\right)+C_1\left(\sum_{j=1}^K\Delta_j\right),
\end{equation}
where 
\begin{equation}
    \begin{aligned}
        C_1=1+\frac{\pi^2}{3}+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\frac{\pi^2}{3}\exp\left(-\frac{n_0-s_0-2}{16}\right)+\frac{36K}{n}\exp\left(-\frac{n_0+9nK}{18}\right).
    \end{aligned}
\end{equation}

\subsubsection{Case-independent bound}\label{sec:case_indep_DAG_given}

\begin{theorem}[Case-independent bound]\label{thm:thm2_DAG}
  Assume $\mu_i\in[-1,1],\forall i\in\{1,\cdots,p-1\}$. Define ${\eta}^2=\max_i\eta_i^2$. Then the cumulative regret of Algorithm~\ref{alg:Combined-UCB} at the end of $T$ rounds is at most
\begin{equation}\label{eq:regret_indep_DAG}
      2c\eta\sqrt{\log T}\min\left\{\frac{\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}}{n+m},\frac{\sqrt{n_0+nT}-\sqrt{n_0}}{n}\mathbbm 1\{n\geq 1\}\right\}+\frac{2Kc_3\log T}{n+m}
        +C_2
\end{equation}
where $C_2 = \frac{18\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\frac{\pi^2}{3}+2+\frac{\pi^2}{6}\exp\left(-\frac{n_0-s_0-2}{16}\right) + \exp\left(-\frac{n_0+9nK}{18}\right)\frac{36}{n}$, tuning parameters $c\geq 4\phi$, $c_3\geq 32$.
\end{theorem}

\textit{Proof.} Let $\mathcal T = \{t:1\leq t\leq T\}$, $\mathcal{T}_0$ denote the set of $t$ whose $A_t$ is randomly sampled from arms that didn't reach the minimum intervention times, i.e., $\mathcal T_0=\{t\in \mathcal T: \exists i, \text{ s.t. } n_i(t-1)< \lceil\frac{c_3\log t }{n+m}\rceil\}$, and $\overline{\mathcal{T}}_0$ denote the set of $t$ whose $A_t$ is the arm with the largest upper confidence bound, i.e., $\overline{\mathcal T}_0=\mathcal T\setminus \mathcal T_0$. Let $U_t(i)=\hat\mu_i(t,S)+\hat\sigma_i(t,S)c\sqrt{\log t}$ be the constructed upper confidence bound of arm $i$ after $t$ rounds. $A^*$ is the optimal arm, $\mu^*$ is the largest reward, and all notations with $\star$ mean the corresponding quantities for the optimal arm. Since $\mu_i\in[-1,1]$ and $U_t(i)\in [-1,1]$ by construction, then
\begin{align*}
     R_T&= \sum_{t=1}^T (\mu^*-\mu_{A_t})=\sum_{t\in\mathcal T_0} (\mu^*-\mu_{A_t})+\sum_{t\in\overline{\mathcal T}_0}(\mu^*-\mu_{A_t}) \\
     &\leq 2K\lceil\frac{c_3\log T}{n+m}\rceil+\sum_{t\in\overline{\mathcal T}_0}(\mu^*-U_{t-1}(A_t)+U_{t-1}(A_t)-\mu_{A_t})\\
    &\leq 2K\left(\frac{c_3\log T}{n+m}+1\right)+\sum_{t\in\overline{\mathcal T}_0}\left(\mu^*-U_{t-1}(A^*)\right)+\sum_{t\in\overline{\mathcal T}_0}\left(U_{t-1}(A_t)-\mu_{A_t}\right)\\
    &\leq 2K\left(\frac{c_3\log T}{n+m}+1\right)+\sum_{t=K+1}^{T}\left(\mu^*-U_{t-1}(A^*)\right)+\sum_{t=K+1}^T\left(U_{t-1}(A_t)-\mu_{A_t}\right).
\end{align*}
Then 
\begin{align*}
    \mbe R_T\leq 2K\left(\frac{c_3\log T}{n+m}+1\right)+2\sum_{t=K}^{T-1}\mbp \left(\mu^*>U_t(A^*)\right)+\sum_{t=K+1}^T\mbe\left(U_{t-1}(A_t)-\mu_{A_t}\right).
\end{align*}
When $c\geq 4\phi$ and $c_3\geq 32$, from \eqref{eq:bound_mustar}, we have 
\begin{align*}
    \mbp \left(\mu^*>U_t(A^*)\right)\leq t^{-2}\left(1+\frac{1}{2\exp((n_0-s_0-2)/16)}\right).
\end{align*}
Then 
\begin{align*}
     \sum_{t=K}^{T-1}\mbp \left(\mu^*>U_t(A^*)\right)\leq \frac{\pi^2}{6}\left(1+\frac{1}{2\exp((n_0-s_0-2)/16)}\right).
\end{align*}
We know that when $ t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}$, we have 
\begin{align*}
    \mbp \left(\rho_i(t,S)\geq \frac{9}{\gamma_{\min}(\Sigma)}\right)\leq \exp\left(-\frac{n_0+nt}{18}\right).
\end{align*}
Let $\eta^2=\max_i\max\left\{\frac{9\zeta_{i,PA_i}^2}{\gamma_{\min}(\Sigma)},\widetilde\sigma_i^2\right\}$,  $\ell=\lceil\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}\rceil$, $\mathcal T_a=\{t:A_t=a, \ell +1\leq t\leq T\}$, then 
\begin{align*}
    \sum_{t=K+1}^T\mbe\left(U_{t-1}(A_t)-\mu_{A_t}\right)
     \leq 2(\ell-K)+\sum_{a\in \mathcal A}\sum_{t\in \mathcal T_a}\mbe\left(U_{t-1}(a)-\mu_{a}\right).
\end{align*}
For $t\geq  \ell$, $\forall a\in \mathcal A$,
\begin{align*}
    \mbe [U_t(a)-\mu_{a}]&=\mbe (\widehat\sigma_a)c\sqrt{\log t}\leq c\sqrt{\log t}\sqrt{\mbe (\widehat\sigma_a^2)}=c\sqrt{\log t}\frac{\sqrt{N_o(t)\zeta_{i}^2\rho_i(S)+N_a(t)\widetilde\sigma_i^2}}{N_o(t)+N_a(t)}\\
    & \leq c\eta\sqrt{\frac{\log t}{N_o(t)+N_a(t)}}+2\exp\left(-\frac{n_0+nt}{18}\right).
\end{align*}
Since $N_o(t)+N_a(t)=n_0+nt+mn_a(t)\geq n_0+(n+m)n_a(t)$,
\begin{align*}
   \sum_{a\in \mathcal A}\sum_{t\in \mathcal T_a}\sqrt{\frac{\log t}{N_o(t)+N_a(t)}}&\leq \sum_{a\in \mathcal A}\sum_{t\in \mathcal T_a}\sqrt{\frac{\log t}{n_0+(n+m)n_a(t)}}\leq \sum_{a\in\mathcal A}\sum_{j=0}^{n_a(T)}\sqrt{\frac{\log T}{n_0+(n+m)j}}\\
    &\leq\sqrt{\log T}\sum_{a\in \mathcal A}\int_0^{n_a(T)}\frac{1}{\sqrt{n_0+(n+m)j}}dj\\
    &\leq \frac{2\sqrt{\log T}}{n+m}\sum_{a\in\mathcal A}\left(\sqrt{n_0+(m+n)n_a(T)}-\sqrt{n_0}\right).
\end{align*}
By Cauchy-Schwartz inequality, 
\begin{align*}
    \sum_{a\in\mathcal A}\sqrt{n_0+(n+m)n_a(T)}\leq \sqrt{K\left(\sum_{a\in\mathcal A}(n_0+(n+m)n_a(T))\right)}=\sqrt{(n+m)KT+K^2n_0}.
\end{align*}
Since $N_o(t)+N_a(t)\geq N_o(t)$, when $n\geq 1$, we also have 
\begin{align*}
    \sum_{t=\ell}^T\sqrt{\frac{\log t}{N_o(t)+N_a(t)}}&\leq  \sum_{t=\ell}^T\sqrt{\frac{\log t}{n_0+nt}}\leq \sqrt{\log T}\int_{0}^T\frac{1}{\sqrt{n_0+nt}}dt=\frac{2\log T}{n}\left(\sqrt{n_0+nT}-\sqrt{n_0}\right).
\end{align*}
Also, $\sum_{t=\ell}^{+\infty}2K\exp\left(-\frac{n_0+nt}{18}\right)=\exp\left(-\frac{n_0+n\ell}{18}\right)\frac{36K}{n}$. In summary,
\begin{equation*}
    \begin{aligned}
        \mbe R_T \leq &\frac{2Kc_3\log T}{n+m}+2c\eta\sqrt{\log T}\min\left\{\frac{\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}}{n+m},\frac{\sqrt{n_0+nT}-\sqrt{n_0}}{n}\right\} \\
        & +2\ell+\frac{\pi^2}{6}\left(2+\frac{1}{\exp((n_0-s_0-2)/16)}\right)+\exp\left(-\frac{n_0+n\ell}{18}\right)\frac{36K}{n}.
    \end{aligned}
\end{equation*}
i.e.,
\begin{equation}\label{eq:upperbound_DAG_indep}
    \begin{aligned}
        \mbe R_T \leq 2c\eta\sqrt{\log T}\min\left\{\frac{\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}}{n+m},\frac{\sqrt{n_0+nT}-\sqrt{n_0}}{n}\mathbbm 1\{n\geq 1\}\right\}+\frac{2Kc_3\log T}{n+m}
        +C_2,
    \end{aligned}
\end{equation}
where 
\begin{align*}
    C_2 = \frac{18\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\frac{\pi^2}{3}+2+\frac{\pi^2}{6}\exp\left(-\frac{n_0-s_0-2}{16}\right) + \exp\left(-\frac{n_0+9nK}{18}\right)\frac{36K}{n}.
\end{align*}

\subsection{When the underlying DAG is unknown}\label{appendix:DAGunknown}

\begin{algorithm}
\caption{BA-UCB for Gaussian Causal Bandits}\label{alg:BA-UCB_appendix}
\begin{algorithmic}
\Require Observational data $\mathbf D_0$ of size $n_0$, parameters  $c$, $c_3$, $n$, $m$, rounds $T$.
\For{$t=1,\cdots, T$}
\If{There is a node $i$ which has been intervened less than $\lceil\frac{c_3\log t+1}{m} \rceil$ times}
    \State Choose intervention node $A_{t} = i$;
\Else
\For {$i=1,\cdots, p-1$}
  \State Estimate the Markov blanket set of each node $X_i$ and find the collection of sets $\widehat{\mathcal N}_i$;
  \State Identify candidate backdoor adjustment sets $\widehat{\mathcal B}_i = \text{argmin}_{S \in \widehat{\mathcal{N}}_i} d(0, CI_i(t-1,S))$;
  \State Sample set $S$ from $\widehat{\mathcal B}_i$, calculate $\hat{\mu}_{i,\text{obs}}(t-1,S)$ and $\hat\sigma_{i,\text{obs}}(t-1,S)$;
   \State Calculate estimates $\hat\mu_i(t-1,S)$ and $\hat\sigma_i^2(t-1,S)$;
\EndFor
    \State Choose $A_{t}=\underset{i \in \{1, \ldots, p-1\}}{\operatorname{argmax}}\left\{\hat{\mu}_{i}(t-1,S)+\hat{\sigma}_{i}(t-1,S) c \sqrt{\log (t-1)}\right\}$; 
\EndIf
\State Sample $m$ data points under intervention $A_{t}$ and $n$ observational data.
\EndFor
\Ensure Optimal intervention $A_T$ and estimated reward $\hat \mu^*$.
\end{algorithmic}
\end{algorithm} 

When the underlying DAG is unknown, we take an additional step to estimate the Backdoor adjustment sets. In this section, we modify the proof for the DAG given setting to get our final theoretical results. Denote the sampled set $S$ for node $X_i$ in main paper's Algorithm 1 at time step $t$ as $\widehat{PA}_{i,t}$. We want to prove the theoretical bounds displayed in main paper's Theorem 3.3 and Theorem 3.4.

\subsubsection{Case-dependent bound} \label{sec:case_dep_DAG_unknown}
\textit{Proof.}
\begin{align*}
    \mathbb E[R_T]&=\sum_{i=1}^K\Delta_i\mathbb E[T_i(N(T))] =\sum_{i=1}^K\Delta_i \sum_{t=1}^{T}P\left(A_{t}=i\right)\\
    &\leq \sum_{i=1}^K\Delta_i \sum_{t=0}^{T-1}\left(P\left(A_{t+1}=i|\widehat{PA}_{i,t}\in \mathcal B_i,\widehat{PA}_{t}^*\in \mathcal B^*\right)+\mathbb P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)+\mathbb P\left(\widehat{PA}_{t}^*\notin \mathcal B^*\right)\right)
\end{align*}

Define 
\begin{align*}
   \widetilde{\eta}_i^2&=\max_{S\in\mathcal B_i}\max\{ \frac{9\zeta_{i,S}^2}{\gamma_{\min}(\Sigma)},\tilde\sigma_i^2\},\\
    \widetilde\phi^2 &= \max_i\max_{S\in\mathcal B_i}\max\left\{\frac{9\zeta_{i,S}^2}{\gamma_{\min}(\Sigma)\tilde\sigma_i^2},\frac{25\tilde\sigma_i^2\gamma_{\max}(\Sigma)}{9\zeta_{i,S}^2}\right\}.
\end{align*}
We have proved that under the correct backdoor adjustment sets, the upper bound of $\mathbb E[R_T]$ can be expressed as in \eqref{eq:upperbound_DAG_dep}, i.e., the first term is bounded.

Let $M_i$ denote the Markov blanket of a node $X_i$ and $\mathcal N_i$ denote the collection of all subsets of the Markov blanket $M_i$, $\mathcal B_i$ denote the collection of valid backdoor adjustment sets for $(X_i, Y)$. For any $i, t$, we have
\begin{align*}
     P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)&\leq  P\left(\widehat{PA}_{i,t}\notin \mathcal B_i,\widehat M_i= M_i\right) + P\left(\widehat M_i\neq M_i\right)\\
     &=P\left(\widehat M_i= M_i \right)-P\left(\widehat{PA}_{i,t}\in \mathcal B_i \text{ and }\widehat M_i= M_i\right) + P\left(\widehat M_i\neq M_i\right).
\end{align*}
Since we have 
\begin{align*}
     &P\left(\widehat{PA}_{i,t}\in \mathcal B_i \text{ and }\widehat M_i= M_i\right)\\
    \geq &P\left(\min_{S\in\mathcal B_i\cap \widehat{\mathcal N}_i}d(0,CI_i(t,S))<\min_{S'\in\widehat{\mathcal N}_i\setminus\mathcal B_i}d(0,CI_i(t,S'))\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right)\\
    =&P\left(\min_{S\in\mathcal B_i\cap \mathcal N_i}d(0,CI_i(t,S))<\min_{S'\in\mathcal N_i\setminus \mathcal B_i}d(0,CI_i(t,S'))\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right)\\
    \geq &P\left(\min_{S\in\mathcal B_i\cap \mathcal N_i}d(0,CI_i(t,S))=0 \text{ and}\min_{S'\in\mathcal N_i\setminus\mathcal B_i}d(0,CI_i(t,S')) > 0 \text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right)\\
    = &P\left(0\in CI_i(t,S), \exists S\in\mathcal B_i\cap \mathcal N_i\text{ and } d(0,CI_i(t,S')) > 0, \forall S'\in\mathcal N_i\setminus\mathcal B_i\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right)\\
    \geq & P\left(0\in CI_i(t,PA_i) \text{ and } d(0,CI_i(t,S')) > 0, \forall S'\in\mathcal N_i\setminus\mathcal B_i\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right)\\
    \geq & P\left(0\in CI_i(t,PA_i)\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right) - P\left(d(0,CI_i(t,S')) = 0, \exists S'\in\mathcal N_i\setminus\mathcal B_i\right)\\
    \geq & P\left(0\in CI_i(t,PA_i)\text{ and }\widehat{\mathcal N}_i= \mathcal N_i\right) - \sum_{S'\in\mathcal N_i\setminus\mathcal B_i}P\left(d(0,CI_i(t,S')) = 0\right),
\end{align*}
then
\begin{align*}
     P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)\leq P\left(0\notin CI_i(t,PA_i)\right)+P\left(\widehat M_i\neq M_i\right) + \sum_{S'\in\mathcal N_i\setminus\mathcal B_i}P\left(d(0,CI_i(t,S')) = 0\right).
\end{align*}
Let $c'_t =c_2\sqrt{\log t}$, $s=|PA_i|$, ignoring $t$ for simplicity in notation, then
\begin{align*}
    P\left(0\notin CI_i(PA_i)\right)&=P\left(\left|\frac{\widehat{\mu}_i(PA_i)-\widehat{\mu}_{i,\text{int}}}{\sqrt{\widehat{Var}\left(\widehat{\mu}_i(PA_i)-\widehat{\mu}_{i,\text{int}}\right)}}\right|>c'_t\right),\\
    P\left(d(0,CI_i(S')) = 0\right)& = P\left(\left|\frac{\widehat{\mu}_i(S')-\widehat{\mu}_{i,\text{int}}}{\sqrt{\widehat{Var}\left(\widehat{\mu}_i(S')-\widehat{\mu}_{i,\text{int}}\right)}}\right|\leq c'_t\right),
\end{align*}
where
\begin{align*}
\widehat{Var}\left(\widehat{\mu}_i(S)-\widehat{\mu}_{i,\text{int}}\right) &= \widehat{Var}\left(\widehat{\mu}_i(S)\right)+\widehat{Var}(\widehat{\mu}_{i,\text{int}})= \frac{\widehat\zeta_{i,S}^2\rho_i(S)}{N_o}+ \frac{s_i^2}{N_i}\\
    &\sim \frac{\zeta_{i,S}^2\rho_i(S)}{N_o(N_o-s-1)}\chi_{N_o-s-1}^2+ \frac{\widetilde\sigma_i^2}{N_i(N_i-1)}\chi_{N_i-1}^2,\\
    \widehat{\mu}_i(S)-\widehat{\mu}_{i,\text{int}}& \sim \mathcal N\left( \mu_i(S)-\mu_i(PA_i), \frac{\widetilde \sigma_i^2}{N_i} + \frac{\zeta_{i,S}^2\rho_i(S)}{N_o}\right), \forall S\in \mathcal N_i.
\end{align*}
Since $\mathbb{P}\left\{\chi_{n}^{2} \geq 5n/2\right\} \leq e^{-n/4}$ and $\mbp \left\{\chi_n^2\leq n/3\right\}\leq e^{-n/9}$, then 
\begin{align*}
\mbp \left(\widehat{Var}\left(\widehat{\mu}_i(S)-\widehat{\mu}_{i,\text{int}}\right) \leq \frac{\zeta_{i,S}^2\rho_i(S)}{3N_o}+\frac{\widetilde \sigma_i^2}{3N_i}\right)\leq \exp\left(-\frac{N_o-s-1}{9}\right) + \exp\left(-\frac{N_i-1}{9}\right).
\end{align*}

Since $N_i\geq c_3\log t+1$, let $c_3\geq 18$, then we have
\begin{align*}
    P\left(0\notin CI_i(PA_i)\right)&\leq 2\exp\left(-\frac{c_t^{\prime 2}}{6}\right)+\exp(-(N_o-s-1)/9) +\exp(-(N_i-1)/9)\\
    & \leq 2t^{-c_2^2/6} +\exp\left( -\frac{n_0+nt-s-1}{9}\right) + t^{-2}.
\end{align*}
Let $c_2= 2\sqrt{3}$, then $P\left(0\notin CI(PA_i)\right)\leq 3t^{-2}+\exp\left( -\frac{n_0+nt-s-1}{9}\right)$.

Now we want to bound $P\left(d(0,CI_i(S')) = 0\right)$, for any $S'\in\mathcal N_i\setminus\mathcal B_i$. With identifiability assumption $|\mu_i(S')-\mu_i(PA_i)|\geq 2\delta$, $\forall S'\in\mathcal N_i\setminus\mathcal B_i$, and tail probability of $\chi^2$ distribution $P(\chi_n^2\geq n+2\sqrt n\sqrt x+2x)\leq e^{-x}$, we have 
\begin{align*}
    &P(\chi_{N_o-s-1}^2\geq 3(N_o-s-1))\leq \exp\left(-(N_o-s-1)/4\right),\\
    &P(\chi_{N_i-1}^2\geq 3(N_i-1))\leq \exp\left(-(N_i-1)/4\right).
\end{align*}
Then 
\begin{align*}
    P\left(\left|\frac{\widehat{\mu}_i(S')-\widehat{\mu}_{i,\text{int}}}{\sqrt{\widehat{Var}\left(\widehat{\mu}_i(S')-\widehat{\mu}_{i,\text{int}}\right)}}\right|\leq c'_t\right)&\leq P\left(\left|\widehat{\mu}_i(S')-\widehat{\mu}_{i,\text{int}}\right|\leq c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right)\\
    &+ \exp\left(-\frac{N_o-s-1}4\right) + \exp\left(-\frac{N_i-1}4\right).
\end{align*}
We have 
\begin{align*}
    &P\left(\left|\mathcal N\left( \mu_i(S')-\mu_i(PA_i), \frac{\widetilde \sigma_i^2}{N_i} + \frac{\zeta_{i,S'}^2\rho_i(S')}{N_o(t)}\right)\right|\leq c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right)\\
    \leq & P\left(\left|\mu_i(S)-\mu_i(PA_i)\right|-\left|\mathcal N\left( 0, \frac{\widetilde \sigma_i^2}{N_i} + \frac{\zeta_{i,S'}^2\rho_i(S')}{N_o(t)}\right)\right|\leq c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right)\\
    \leq & P\left(\left|\mathcal N\left( 0, \frac{\widetilde \sigma_i^2}{N_i} + \frac{\zeta_{i,S'}^2\rho_i(S')}{N_o(t)}\right)\right|\geq 2\delta -c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right)\\
    \leq & 2\exp\left( -\frac{\left( 2\delta -c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right)^2}{2\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)}\right).
\end{align*}
To make it $\leq 2t^{-2}$, since $c_2=2\sqrt 3$, we need 
\begin{align*}
2\delta -c'_t\sqrt{3\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)} \geq 2\sqrt{\log t}\sqrt{\left(\frac{\zeta_{i,S'}^2\rho_i(S')}{N_o}+ \frac{\widetilde\sigma_i^2}{N_i}\right)},
\end{align*}
i.e., 
\begin{align*}
\delta \geq 4\sqrt{\zeta_{i,S'}^2\rho_i(S')\frac{\log t}{N_o}+\widetilde\sigma_i^2\frac{\log t}{N_i}}.
\end{align*}
Since $\mathbb P\left( \rho_i(t,S)\geq \frac{9}{\gamma_{\min}(\Sigma)}\right)\leq e^{-(n_0+nt)/18},\forall t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)},\forall i, S$, $N_o=n_0+nt, N_i\geq c_3\log t+1$, we could choose a large enough t such that $\frac{\log t}{n_0+nt}\leq \frac{1}{c_3}$, i.e., $t\geq \left(\frac{c_3}{n}\right)^2$, and a large enough $c_3$ such that $c_3\geq 32\psi^2/\delta^2$, where $\psi^2=\max_i\max_{S'\in \mathcal N_i\setminus\mathcal B_i}\max\left\{\frac{9\zeta_{i,S'}^2}{\gamma_{\min}(\Sigma)},\widetilde\sigma_i^2\right\}$. Since $s_2=\max_i|\mathcal N_i\setminus\mathcal B_i|$, under these conditions, we have 
\begin{align*}
    &\sum_{S'\in\mathcal N_i\setminus\mathcal B_i}P\left(d(0,CI_i(S')) = 0\right)\\
    \leq &s_2\left(2t^{-2}+\exp\left(-\frac{N_o(t)}{18}\right)+ \exp\left(-\frac{N_o-s-1}4\right) + \exp\left(-\frac{N_i-1}4\right)\right)\\
    \leq & s_2\left(3t^{-2}+\exp\left(-\frac{N_o(t)}{18}\right)+ \exp\left(-\frac{N_o-s-1}4\right)\right).
\end{align*}
We also need to bound the probability that $\mathbb P\left(\widehat M_i\neq M_i\right)$. We have the following properties:
\begin{itemize}
    \item $\mathbf X\sim \mathcal N\left(0,\Sigma\right)$, where $\Sigma = (I-B)^{-\top}\Omega(I-B)^{-1}$;
    \item $X_i|X_{-i}\sim \mathcal N(\bar{\mu}_i, \bar{\Sigma}_i)$, where $\bar{\mu}_i= \Sigma_{i,-i}\Sigma_{-i,-i}^{-1}X_{-i}$, $\bar{\Sigma}_i=\Sigma_{i,i}-\Sigma_{i,-i}\Sigma_{-i,-i}^{-1}\Sigma_{-i,i}=\bar\sigma_i^2$;
    \item $\left(\Sigma^{-1}\right)_{i,-i}=-\bar{\Sigma}_i^{-1}\Sigma_{i,-i}\Sigma_{-i,-i}^{-1}$, note that $\Sigma^{-1}$ is the precision matrix, where the $i,j$-th element is the partial correlation of $X_i$ and $X_j$ conditioned on other variables.
\end{itemize}
Then $X_i = -\bar{\Sigma}_i\left(\Sigma^{-1}\right)_{i,-i}X_{-i}+\varepsilon_i=\sum_{j:j\neq i}\bar\beta_{ij}X_j+\varepsilon_i$, where $\varepsilon\sim N(0,\bar{\sigma}_i^2)$. A linear regression with threshold on significance level would return a set containing all the parents, children, and spouses of $X_i$. 
\begin{align*}
    \mathbb P\left(\widehat M_i\neq M_i\right)\leq \sum_{j:\bar\beta_{ij}\neq 0} \mathbb P(X_j\notin \widehat{M}_i) + \sum_{j:\bar\beta_{ij}= 0} \mathbb P(X_j\in \widehat{M}_i)
\end{align*}
Write the linear regression in matrix form: $\widehat \beta_i=\text{argmin}\| X_i -\mathbf X_{-i}\beta_i\|$. Then $\widehat \beta_i=(\mathbf X_{-i}^\top \mathbf X_{-i})^{-1}\mathbf X_{-i}^\top \mathbf X_i$, $\widehat{\bar\beta}_{ij}\sim \mathcal N\left(\bar\beta_{ij}, \bar\sigma_i^2 \left[(\mathbf X_{-i}^\top \mathbf X_{-i})^{-1}\right]_{j,j}\right)$. Let $\rho_{ij}(t)=\left[\left(\frac{\mathbf X_{-i}^\top \mathbf X_{-i}}{N_o(t)}\right)^{-1}\right]_{j,j}$, then 
\begin{align*}
    &\widehat\beta_{i,j}\sim \mathcal N\left(\bar\beta_{ij}, \bar\sigma_i^2 \frac{\rho_{ij}(t)}{N_o(t)}\right),\\
    &\widehat{\bar\sigma}_i^2 =\frac{\|\mathbf X_i-\mathbf X_{-i}\widehat\beta_i\|^2}{N_o(t)-p}\sim \bar\sigma_i^2\frac{\chi_{N_o(t)-p}^2}{N_o(t)-p},\\
    &\frac{\widehat{\bar\beta}_{ij}-\bar\beta_{ij}}{\sqrt{\widehat{\bar\sigma}_i^2\frac{\rho_{ij}(t)}{N_o(t)}}}\sim t_{N_o(t)-p}.
\end{align*}
Let $\bar\beta_i=\min_{j:\beta_{ij}\neq 0}|\bar\beta_{ij}|$. If we set the threshold for determining $\widehat M_i$ as $\alpha_i\sqrt{N_o(t)}$, then $\forall j\in PA_i$,
\begin{align*}
    \mathbb P(X_j\notin \widehat{M}_i) &= \mathbb P\left(\left|\frac{\bar\beta_{ij}}{\sqrt{\widehat{\bar\sigma}_i^2\frac{\rho_{ij}(t)}{N_o(t)}}}+ t_{N_o-p}\right|\leq \alpha_i\sqrt{N_o(t)}\right)\leq \mathbb P\left(|t_{N_o(t)-p}|\geq \left(\frac{\bar\beta_i}{\sqrt{\widehat{\bar\sigma}_i^2\rho_{ij}(t)}}-\alpha_i\right)\sqrt{N_o(t)}\right).
\end{align*}
Since $\mathbb P (\chi_n^2\geq 3n)\leq \exp(-0.25n)$ and $\mathbb P \left(\rho_{ij}(t)\geq \frac{9}{\gamma_{\text{min}}(\Sigma)}\right)\leq \exp\left(-\frac{N_o(t)}{18}\right)$, $\forall t\geq \frac{9\text{tr}(\Sigma)}{\gamma_{\text{min}}(\Sigma)}$, $\forall i,j$, we have
 \begin{align*}
    \mathbb P(X_j\notin \widehat{M}_i) &\leq \mathbb P\left( |t_{N_o(t)-p}| \geq \left(\frac{\sqrt{\gamma_{\text{min}}(\Sigma)}\bar\beta_i}{3\sqrt 3 \bar\sigma_i}-\alpha_i \right)\sqrt{N_o(t)}\right)+\exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right)\\
    &\leq 2\exp\left( - \left(\frac{\sqrt{\gamma_{\text{min}}(\Sigma)}\bar\beta_i}{3\sqrt 3 \bar\sigma_i}-\alpha_i \right)^2\frac{N_o(t)}{4}\right)+\exp\left(-\frac{N_o(t)-p}{16}\right)\\
    &+\exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right).
\end{align*}
Let $\alpha_i=\frac{\sqrt{\gamma_{\text{min}}(\Sigma)}\bar\beta_i}{9\sqrt 3 \bar\sigma_i}$, then 
\begin{align*}
     \mathbb P(X_j\notin \widehat{M}_i)&\leq 2\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{243 \bar\sigma_i^2}\right)+\exp\left(-\frac{N_o(t)-p}{16}\right)+\exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right).
\end{align*}
$\forall j$ with $\bar\beta_{ij}=0$, we have
\begin{align*}
    \mathbb P(X_j\in \widehat{M}_i)&=\mathbb P\left( |t_{N_o(t)-p}|\geq \alpha_i \sqrt{N_o(t)}\right)\leq 2\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{972 \bar\sigma_i^2}\right)+\exp\left(-\frac{N_o(t)-p}{16}\right).
\end{align*}
Therefore, 
\begin{align*}
    \mathbb P\left(\widehat M_i\neq M_i\right)&\leq \sum_{j:\bar\beta_{ij}\neq 0} \mathbb P(X_j\notin \widehat{M}_i) + \sum_{j:\bar\beta_{ij}= 0} \mathbb P(X_j\in \widehat{M}_i)\\
    &\leq 2 |M_i| \exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{243 \bar\sigma_i^2}\right)+2(p-1-|M_i|)\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{972 \bar\sigma_i^2}\right)\\
    &+(p-1)\exp\left(-\frac{N_o(t)-p}{16}\right)+|M_i|\left( \exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right)\right)\\
    &\leq (p-1) \left(2\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{972 \bar\sigma_i^2}\right) +\exp\left(-\frac{N_o(t)-p}{16}\right)\right)\\
    &+|M_i|\left( \exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right)\right).
\end{align*}
If $N_o(t)$ can be less than $p$, we can consider using Lasso-based neighborhood regression \cite{wainwright2019high} instead, i.e., 
\begin{equation*}
\widehat{\bar{\beta}}_i=\text{arg}\min_{\beta_i\in\mathbb R^{p-1}}\left\{\frac{1}{2N_o(t)}\| X_i -\mathbf X_{-i}\bar{\beta}_i\|^2+\lambda_{N_o}\|\bar{\beta}_i\|_1\right\}.
\end{equation*}
According to Theorem 11.2 in Wainwright \cite{wainwright2019high}, if the non-zero entries of the precision matrix are bounded below in absolute value, then the estimated edge set $\hat E$ equals the actual edge set $E$ with high probability, where $N_o(t)\succsim 2s_0\log p$, and $\lambda_{N_o}=c_0\left\{\frac{1}{\alpha_0}\sqrt{\frac{\log p}{N_o(t)}}+\upsilon\right\}$ for some $\upsilon\in(0,1]$. More specifically, $\mathbb P(\hat E=E)\geq 1-c_4\exp\left(-c_5N_o(t)\right)$, where $c_4$ and $c_5\leq 1$ are constants. Therefore, if we use Lasso based neighborhood regression, we have 
\begin{equation*}
    \mathbb P\left(\widehat M_i\neq M_i\right)\leq c_4\exp(-c_5N_o(t)).
\end{equation*}
Given this result, with Lasso based neighborhood regression, we can relax the dependency of this upper bound on $K$.

All parts have been settled. In summary, 
\begin{align*}
     &\sum_{t=\ell}^T P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)\\
     \leq & \sum_{t=\ell}^T\left(P\left(0\notin CI_i(PA_i)\right)+P\left(\widehat M_i\neq M_i\right) + \sum_{S'\in\mathcal N_i\setminus\mathcal B_i}P\left(d(0,CI_i(S')) = 0\right)\right)\\
     \leq & \sum_{t=\ell}^T\left[ 3t^{-2}+\exp\left( -\frac{N_o(t)-s-1}{9}\right)\right]+\sum_{t=\ell}^T\left[s_2\left(3t^{-2}+\exp\left(-\frac{N_o(t)}{18}\right)+ \exp\left(-\frac{N_o(t)-s-1}4\right)\right)\right]\\ 
    & \ + \sum_{t=\ell}^T \Bigg[(p-1) \left(2\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2N_o(t)}{972\bar\sigma_i^2}\right) +\exp\left(-\frac{N_o(t)-p}{16}\right)\right)\\
    &\quad +|M_i|\left( \exp\left(-\frac{N_o(t)-p}{4}\right)+\exp\left(-\frac{N_o(t)}{18}\right)\right)\Bigg]\\
    \leq &  \sum_{t=\ell}^T\Bigg[3(s_2+1)t^{-2} + (2s_2+p+2|M_i|)\exp\left(-\frac{n_0+nt-p}{18}\right)\Bigg]\\
    &\quad + 2(p-1)\sum_{t=\ell}^T \exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2(n_0+nt)}{972\bar\sigma_i^2}\right)\\
    \leq & \frac{(s_2+1)\pi^2}{2} + \frac{18(2s_2+p+2|M_i|)}{n}\exp\left(-\frac{n_0+n\ell-p}{18}\right) + \frac{1944(p-1)\bar\sigma_i^2}{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2n}\exp\left( - \frac{\gamma_{\text{min}}(\Sigma)\bar\beta_i^2(n_0+n\ell)}{972 \bar\sigma_i^2}\right).
\end{align*}
Since we denote $s_1=\max_i|M_i|$, and define $\alpha=\min_i\alpha_i/2$, then 
\begin{align*}
     &\sum_{t=\ell}^T P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)\\
      \leq & \frac{(s_2+1)\pi^2}{2} + \frac{18(2s_2+p+2s_1)}{n}\exp\left(-\frac{n_0+n\ell-p}{18}\right)+ \frac{2(p-1)}{\alpha^2 n}\exp\left( - \alpha^2 (n_0+n\ell)\right).
\end{align*}
Since now the minimum intervention time is $\frac{c_3\log t+1}{m}$, the upper bound still has the form
\begin{equation*}
   \log T\left(\frac{20c^2}{n+m}\sum_{i:\mu_i<\mu^*}\frac{\widetilde\eta_i^2}{\Delta_i}+\frac{c_3\sum_{i=1}^K\Delta_i}{m}\right)+C_3\left(\sum_{j=1}^K\Delta_j\right),
\end{equation*}
where 
\begin{equation*}
    \begin{aligned}
        C_3=&2+\left(s_2+\frac{4}{3}\right)\pi^2+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\frac{\pi^2}{3e^{(n_0-s_0-2)/16}}+\left(\frac{c_3}{n}\right)^2+\frac{36(2s_1+p+2s_2+K)}{ne^{(n_0+n\ell-p)/18}}+\frac{4(p-1)}{\alpha^2 ne^{\alpha^2 (n_0+n\ell)}},
    \end{aligned}
\end{equation*}
$c\geq 4\sqrt{2}\widetilde\phi$, $c_3\geq \max\left\{64, \frac{32\psi^2}{\delta^2}\right\}$.

Since $\ell \geq \frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}\geq 9K$, $K=p-1$, we have
\begin{align*}
C_3=2+\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\left(s_2+\frac{4}{3}\right)\pi^2+\frac{\pi^2}{3e^{(n_0-s_0-2)/16}}+\frac{36(2s_1+2K+2s_2+1)}{ne^{(n_0+9nK-K-1)/18}}+\frac{4K}{\alpha^2 ne^{\alpha^2 (n_0+9nK)}}+\left(\frac{c_3}{n}\right)^2.
\end{align*}


\subsubsection{Case-independent bound}
\textit{Proof.} When DAG is unknown, we have
\begin{align*}
    \mbe R_T\leq 2\left(K\frac{c_3\log T+1}{m}+\ell\right)+2\sum_{t=\ell}^{T-1}\mbp \left(\mu^*>U_t(A^*)\right)+\sum_{t=\ell+1}^T\mbe\left(U_{t-1}(A_t)-\mu_{A_t}\right),
\end{align*}
where 
\begin{align*}
     &\sum_{t=\ell}^{T-1} \mbp \left(\mu^*>U_t(A^*)\right)
     \leq \sum_{t=\ell}^{T-1}\mbp \left(\mu^*>U_t(A^*)|\widehat{PA}_{A^*,t}\in \mathcal B_{A^*}\right)+ \sum_{t=\ell}^{T-1}\mbp \left(\widehat{PA}_{A^*,t}\notin \mathcal B_{A^*}\right),\\
    &\sum_{t=\ell+1}^T\mbe\left(U_{t-1}(A_t)-\mu_{A_t}\right)\leq  \sum_{t=\ell+1}^T\mbe\left(U_{t-1}(A_t)-\mu_{A_t}|\widehat{PA}_{A_t,t-1}\in \mathcal B_{A_t}\right)+2\sum_{t=\ell+1}^{T}\mbp \left(\widehat{PA}_{A_t,t-1}\notin \mathcal B_{A_t}\right).
\end{align*}
In Section~\ref{sec:case_dep_DAG_unknown}, we have proved
\begin{align*}
     &\sum_{t=\ell}^T P\left(\widehat{PA}_{i,t}\notin \mathcal B_i\right)\\
      \leq & \frac{(s_2+1)\pi^2}{2} + \frac{18(2s_1+p+2s_2)}{n}\exp\left(-\frac{n_0+n\ell-p}{18}\right)+ \frac{2(p-1)}{\alpha^2 n}\exp\left( - \alpha^2 (n_0+n\ell)\right).
\end{align*}
Combined with the case-independent bound under the DAG given setting in Section~\ref{sec:case_indep_DAG_given}, denote $\widetilde\eta^2=\max_i\widetilde\eta_i^2$, we have the following result
\begin{equation*}
    \begin{aligned}
        \mbe R_T \leq 2c\widetilde\eta\sqrt{\log T}\min\left\{\frac{\sqrt{(n+m)KT+K^2n_0}-\sqrt{K^2n_0}}{n+m},\frac{\sqrt{n_0+nT}-\sqrt{n_0}}{n}\mathbbm 1\{n\geq 1\}\right\}+\frac{2Kc_3\log T}{m}
        +C_4,
    \end{aligned}
\end{equation*}
where 
\begin{align*}
    C_4 =& \frac{18\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\left(2s_2+\frac{7}{3}\right)\pi^2+2+\frac{2K}{m}+\frac{\pi^2}{6}\exp\left(-\frac{n_0-s_0-2}{16}\right)\\
    &+\frac{36K+72(2s_1+p+2s_2)}{n e^{(n_0+n\ell-p)/18}}+ \frac{8(p-1)}{\alpha^2 n}\exp\left( - \alpha^2 (n_0+n\ell)\right)+2\left(\frac{c_3}{n}\right)^2,
\end{align*}
$c\geq 4\widetilde\phi$, $c_3\geq \max\left\{32, \frac{32\psi^2}{\delta^2}\right\}$.

 Since $\ell$ is some constant satisfying $\ell\geq \lceil\frac{9\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}\rceil\geq 9K$ and $K=p-1$, we have 
\begin{align*}
    C_4 = 2+\frac{18\text{tr}(\Sigma)}{\gamma_{\min}(\Sigma)}+\left(2s_2+\frac{7}{3}\right)\pi^2+\frac{\pi^2}{6e^{(n_0-s_0-2)/16}}+\frac{2K}{m}+\frac{36(4s_1+3K+2+4s_2)}{n e^{(n_0+9nK-K-1)/18}}+ \frac{8K}{\alpha^2 ne^{\alpha^2 (n_0+9nK)}}+2\left(\frac{c_3}{n}\right)^2.
\end{align*}



\end{document}