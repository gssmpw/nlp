\begin{abstract}

% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=\textwidth]{graphs2/t2i.pdf}
%     \caption{\textbf{Images generated by Show-o Turbo given various text prompts.} From top to bottom, the images are generated by Show-o Turbo in 8, 4, and 2 sampling steps without reliance on classifier-free guidance~\cite{ho2021classifier}.}
%     \label{fig:show}
% \end{figure*}

% \begin{figure*}[htbp]
%     \centering
%     % 第一行
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure7/s8/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure4/tt8/test_lmcm_x_photo_5.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s8/test_lmcm_x_photo_7.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s8/test_lmcm_x_photo_0.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s8/test_lmcm_x_photo_9.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure6/t8/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s8/test_lmcm_x_photo_2.png}
%     \end{minipage}%
    

%     \vspace{-0.1cm}
%     % 第二行
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure7/s4/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure4/tt4/test_lmcm_x_photo_5.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s4/test_lmcm_x_photo_7.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s4/test_lmcm_x_photo_0.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s4/test_lmcm_x_photo_9.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure6/t4/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s4/test_lmcm_x_photo_2.png}
%     \end{minipage}%
    
    
%     \vspace{-0.1cm}
%     % 第三行
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure7/s2/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure4/tt2/test_lmcm_x_photo_5.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s2/test_lmcm_x_photo_7.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s2/test_lmcm_x_photo_0.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s2/test_lmcm_x_photo_9.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure6/t2/test_lmcm_x_photo_4.png}
%     \end{minipage}%
%     \begin{minipage}{0.14\textwidth}
%         \includegraphics[width=\linewidth]{figure1/s2/test_lmcm_x_photo_2.png}
%     \end{minipage}%


%     \caption{\textbf{256 $\times$ 256 Images generated by Show-o Turbo given various text prompts.} From top to bottom, the images are generated by Show-o Turbo in 8, 4, and 2 sampling steps without reliance on classifier-free guidance~\cite{ho2021classifier}.}
%     \label{fig:show}
% \end{figure*}


\begin{figure*}[htbp]
    \centering
    % 第一行
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_25.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_0.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_4.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_5.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_8.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_21.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t8/test_lmcm_x_photo_14.png}
    \end{minipage}%
    
    

    \vspace{-0.1cm}
    % 第二行
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_25.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_0.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_4.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_5.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_8.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_21.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t4/test_lmcm_x_photo_14.png}
    \end{minipage}%
    
    
    \vspace{-0.1cm}
    % 第三行
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_25.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_0.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_4.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_5.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_8.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_21.png}
    \end{minipage}%
    \begin{minipage}{0.14\textwidth}
        \includegraphics[width=\linewidth]{showo512/t2/test_lmcm_x_photo_14.png}
    \end{minipage}%


    \caption{\textbf{512 $\times$ 512 images generated by Show-o Turbo given various text prompts.} From top to bottom, the images are generated by Show-o Turbo in 8, 4, and 2 sampling steps without reliance on classifier-free guidance~\cite{ho2021classifier}.}
    \label{fig:show}
\end{figure*}
























% Multimodal Generation, Show-o Framework，Consistency Distillation, Trajectory-Based Acceleration, Discrete Diffusion, Unified Framework, Jacobian Decoding, Text and Image Generation, Segment-Wise Consistency, Regularization Loss, High-Fidelity Generation, Efficiency Improvement, Latent Consistency Models
%Using a single Transformer model to perform both autoregression and diffusion generation has recently become a popular trend. However, previous work has focused only on accelerating autoregression or diffusion methods, which makes it challenging to apply these techniques to such multimodal models. We propose a unified distillation framework that enables accelerated generation of Show-o language and text. Experiments show that in the image generation task, the 4-step Show-F without CFG is equivalent to the 8-step baseline, and in the text generation task, it can speed up to 1.3 times the original speed while maintaining quality.
 %Recently unified multimodal understanding and generation models emerges. Show-o is a representive of them which can do image generation and understanding with only 1.3B parameters, showing the promise for the next-generation foundation model. However, Show-o suffers from a slow inference speed in both aspects of auto-regressively decoding text tokens and progressively denoising image tokens.
%This paper proposes Show-o Turbo, a method based on the consistency distillation to tackle this issue. In our approach, parallel generation of text tokens is viewed as fixed-point iteration which can operates as a denoising process similar to the image generation to distill. The experiments reveals that  the image generation from Show-o Turbo in 4 steps without CFG outperforms Show-o in 8 steps, and also speeds up the text generation of the mmu task by 1.5 times.
There has been increasing research interest in building unified multimodal understanding and generation models, among which Show-o stands as a notable representative, demonstrating great promise for both text-to-image and image-to-text generation. 
% However, %Show-o suffers from a slow inference on both sides---it hinges on 
The inference of Show-o involves progressively denoising image tokens and autoregressively decoding text tokens, and hence, unfortunately, suffers from inefficiency issues from both sides. 
This paper introduces Show-o Turbo to bridge the gap. 
We first identify a unified denoising perspective for the generation of images and text in Show-o based on the parallel decoding of text tokens. 
We then propose to extend consistency distillation (CD), a qualified approach for shortening the denoising process of diffusion models, to the multimodal denoising trajectories of Show-o. 
% Given the promise of consistency distillation (CD) for accelerating the denoising process of diffusion models, we propose to extend it to the multimodal denoising trajectories of Show-o. 
We introduce a trajectory segmentation strategy and a curriculum learning procedure to improve the training convergence. 
% propose to enlarge the scope of the original consistency distillation 
% Viewing the parallel generation process of text tokens and image tokens as certain denoising trajectories, Show-o Turbo shortens the generation trajectories by 
% learning a student model to map any two points on trajectories to the same end point. 
%To achieve this goal, we consider the parallel generation of text tokens as a fixed-point iteration , which can operate as a denoising process. 
%Since the image and text generation can be viewed as two similar processes, Show-o Turbo uses a unified framework to improve the speed of both tasks. 
%Considering the parallel generation of text tokens as the fixed-point iteration, which can operate as a denoising process similar to the image generation,
% The process to acquire Show-o Turbo is cost-effective, with rarely 36 hours on 8 RTX 4090 GPUs. 
Empirically, in text-to-image generation, Show-o Turbo displays a GenEval score of 0.625 at 4 sampling steps without using classifier-free guidance (CFG), outperforming that of the original Show-o with 8 steps and CFG; in image-to-text generation, Show-o Turbo exhibits a 1.5x speedup without significantly sacrificing performance. 
The code is available at \url{https://github.com/zhijie-group/Show-o-Turbo}.
\end{abstract}