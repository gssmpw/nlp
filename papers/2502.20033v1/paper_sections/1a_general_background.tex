

Recommender systems are central to modern streaming platforms and digital marketplaces, where they curate personalized selections for each user from the vast set of items these platforms host. A classical method used in recommender systems is \textit{matrix completion}, in which users and items are endowed with low-dimensional features. Their inner product represents user-item utility, which is reflected in the ratings a user provides. The system's goal is to learn these features from available rating data. This approach has been impactful in practice \citep{koren2009matrix} and is supported by strong theoretical foundations \citep{ge2016matrix}.

This work focuses on recommender systems that learn from user feedback in the form of comparisons or choices. For one, comparison data is widely available as implicit feedback--for instance, when a user clicks on one of four options, it suggests a preference for the selected item over the others. Additionally, we believe explicitly collecting comparison feedback instead of ratings can be beneficial: (i) comparisons naturally cancel out user biases in ratings \citep{shah2013case}; (ii) they avoid the discretization issues of rating-based methods, where responses are typically non-continuous (e.g., 1-5 stars) \citep{davenport2014onebit}; and (iii) comparing two items is cognitively easier than rating them on an abstract scale \citep{stewart2005absolute}. In fact, the advantages of ordinal (comparison) feedback over cardinal (rating) feedback have been empirically demonstrated in small-scale tasks \citep{shah2016estimation}.


It is fairly straightforward to model a comparison-based recommender system by combining the matrix completion assumptions with a discrete choice model. 
Specifically, assume each user $u$ has a utility $x_{u,i}$ for every item $i$, which is an inner product of a low-dimensional user feature vector $u$ and item feature vector $v$. Thus the utility matrix $X$ can be factorized into feature matrices as follows: $X = UV^T$.
Comparisons follow a noisy oracle: when presented with two items $i$ and $j$, the user $u$ picks $i$ over $j$ with probability $g(x_{u,i} - x_{u,j})$ for some known link function $g(\cdot)$.
Given a dataset that is generated from this model with some latent ground-truth features $(U^*, V^*)$, one can learn these features through the maximum likelihood paradigm.

As in the classical matrix completion case, this optimization problem has both a convex formulation (over the utility matrix 
$X$ and a nonconvex formulation (over feature matrices 
$U,V$). The convex version of this problem has been studied in the past by \citet{park2015preference} and  \citet{negahban2018learning}. These papers establish the sample complexity of the learning problem. However, till date, there are no theoretical guarantees for the nonconvex formulation. This is an important open problem because solving the nonconvex problem is computationally much more efficient than the convex one. Indeed, the nonconvex approach has been applied to large-scale datasets, where the convex approach would be infeasible \citep{rendle2009bpr, park2015preference}.

This work analyzes the nonconvex learning-from-comparisons problem. We show that within a neighborhood of the true solution, the negative log-likelihood function exhibits a strong convexity-like property. Therefore, with a warm start, gradient-based methods converges exponentially fast to the global minimum (Theorem \ref{thm:main}). Crucially, this result holds with high probability even when the dataset is sparse. Our work introduces new techniques to establish key concentration results that are necessary to prove such a result, building upon the techniques developed for matrix completion. Further details of our contributions follow a review of related literature.

