This work sits at the confluence of the literature on the nonconvex matrix factorization problem and the task of learning from comparison data. We are the first to provide a theoretical analysis of the nonconvex formulation for the problem of learning a low-rank matrix from comparison data. The modeling assumptions we make, such as the incoherence of the ground-truth matrix and the uniform sampling of datapoints, are very similar to prior work on matrix factorization. Our proof strategy is inspired by that of \citet{zheng2016convergence}. In particular, we follow their approach of using a regularizer to translate an asymmetric matrix factorization problem ($X = UV^T$) into a symmetric one ($Y = ZZ^T$). We also follow their idea of using projected gradient descent to ensure the iterates stay incoherent. 

The key difference between our work and prior work is the method used to develop the necessary concentration inequalities. Most of the papers analyzing matrix completion build upon some fundamental results from \citet{candes2009exact} and \citet{keshavan2010matrix}.However, these results do not apply to our problem, because the structure of the \textit{sampling matrix} is different. To elaborate, in matrix completion, a data point consists of a single user and a single item, while here, a datapoint consists of a single user and an item-pair.
This seemingly minor difference makes us lose the interpretation of the set of samples acting like a projection operator \citep{candes2009exact}, or the samples being edges of a bipartite graph \citep{keshavan2010matrix}.
In this work, we derive the necessary concentration results by using the matrix Bernstein inequality  \citep{tropp2015introduction} as the main tool. Further details are given in Section \ref{sec:proof}.

We view our result as an important extension of the work of \citet{negahban2018learning}, demonstrating that learning personalized recommendations from comparison data is not just statistically efficient, but also computationally so. In fact, our work suggests that explicitly asking users to compare pairs of items (instead of rating them) can be a viable approach to learning user preferences. We hope our work will motivate practitioners to collect a large comparison dataset similar to the Netflix dataset, on which our method can be tested. Furthermore, it would be interesting to study whether it is beneficial to seek feedback through comparisons instead of through ratings (perhaps due to lower noise). Note that these would be different from the experiments done by \citet{rendle2009bpr} and \citet{park2015preference}, as they infer comparisons from other forms of data. 

We make two major simplifying assumptions in this work. First, we  assume that our comparisons are noiseless. That is, instead of observing a binary preference outcome, we observe the expected value of this outcome. 
Extending our analysis to the more realistic setting of noisy, binary comparisons is an important direction of future work.\footnote{Indeed, in the matrix completion literature as well, the noiseless case has been addressed first and the noisy case in a follow up work (e.g., \citet{candes2009exact} followed by \citet{candes2010matrix}, \citet{keshavan2010matrix} followed by \citet{keshavan2010matrixb}).} Second, we assume we are given an initial point that is suitably close to the ground truth solution. In the matrix completion literature, such an initial solution can be obtained by performing a singular value decomposition on the partially observed matrix, as shown by \cite{keshavan2010matrix}. However, this initialization method does not work here. Our simulations in Section \ref{sec:simulations} suggest that this warm start may not be a necessity. Proving convergence from a random point, as done by \cite{ge2016matrix}, is a problem we have left open.
