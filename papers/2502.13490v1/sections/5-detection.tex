\section{\sysname's Performance on Detection}\label{sec:detect}

\subsection{Datasets}\label{sec:detect:datasets}

\begin{table*}[]
\normalsize
\begin{tabular}{|M{1.5cm}|M{1.2cm}|M{3.2cm}|M{1.1cm}|M{1.4cm}|M{1.4cm}|M{1.1cm}|M{1.4cm}|M{1.4cm}|}
\hline\hline
\multirow{2}{*}{Models} & \multirow{2}{*}{Groups} & \multirow{2}{*}{Features} & \multicolumn{3}{c|}{HaluEval}                    & \multicolumn{3}{c|}{CNNDM}                       \\ \cline{4-9}
& & & Accuracy & Recall(Halu) & Recall(Fact) & Accuracy & Recall(Halu) & Recall(Fact) \\
\hline\hline
\multirow{10}{*}{Llama-2-7B} & \multirow{4}{*}{Logit}      & Max token rank            & 0.53 & 0.31 & 0.74 & 0.60 & 0.60 & 0.60 \\
& & Min token prob            & 0.54 & 0.64 & 0.44 & 0.58 & 0.63 & 0.57 \\
& & Joint prob                & 0.54 & 0.72 & 0.37 & 0.63 & 0.50 & 0.67 \\
& & JSD                       & 0.51 & 0.00 & 1.00 & 0.51    & 0.49    & 0.52    \\

\cline{2-9}\cline{2-9}
& \multirow{3}{*}{Attention}  & Lookback ratio            & \textbf{0.75} & 0.75 & 0.74 & \textbf{0.83} & 0.77 & 0.84 \\
& & Attention sharpness       & 0.60 & 0.58 & 0.63 & 0.61 & 0.54 & 0.63 \\
& & Key token attention ratio & 0.70 & 0.68 & 0.72 & 0.72    & 0.72    & 0.71    \\

\cline{2-9}\cline{2-9}
& \multirow{3}{*}{Activation} & Hidden state              & \textbf{0.76} & 0.76 & 0.76 & \textbf{0.74}    & 0.75    & 0.74    \\
& & Activation entropy        & 0.55 & 0.41 & 0.68 & 0.57    & 0.54    & 0.59    \\
& & Diff Activation map       & 0.53 & 0.50 & 0.56 & 0.54    & 0.52    & 0.54    \\
\hline\hline

\multirow{10}{*}{Vicuna-7B} & \multirow{4}{*}{Logit}      & Max token rank            & 0.55 & 0.34 & 0.74 & 0.66 & 0.67 & 0.65 \\
& & Min token prob            & 0.59 & 0.64 & 0.51 & 0.61 & 0.62 & 0.58 \\
& & Joint prob                & 0.63 & 0.72 & 0.45 & 0.67 & 0.57 & 0.72 \\
& & JSD                       & 0.53 & 0.53 & 0.52 & 0.53    & 0.53    & 0.55    \\
\cline{2-9}\cline{2-9}
& \multirow{3}{*}{Attention}  & Lookback ratio            & \textbf{0.82} & 0.83 & 0.84 & \textbf{0.87} & 0.81 & 0.88 \\
& & Attention sharpness       & 0.66 & 0.64 & 0.66 & 0.63 & 0.62 & 0.65 \\
& & Key token attention ratio & 0.83 & 0.81 & 0.83 & 0.86    & 0.84    & 0.85    \\
\cline{2-9}\cline{2-9}
& \multirow{3}{*}{Activation} & Hidden state              & \textbf{0.76} & 0.76 & 0.77 & \textbf{0.78}    & 0.79    & 0.80    \\
& & Activation entropy        & 0.56 & 0.43 & 0.63 & 0.57    & 0.61    & 0.56    \\
& & Diff Activation map       & 0.55 & 0.52 & 0.56 & 0.54    & 0.53    & 0.56    \\

\hline\hline
\end{tabular}
\caption{
We did an ablation study to show the ability of different features to classify hallucinations with facts.
}
\label{tab:ablation}
%\vspace{-15pt}
\end{table*}

\begin{table}[]
\centering
\begin{tabular}{c|c|c|c|c}
\hline\hline
Model & Dataset & CNNDM & HaluEval & NQ   \\
\hline\hline
\multirow{3}{*}{Llama-2-7B} & Fact. & 492   & 7632     & 1627 \\
& Hall. & 508   & 2368     & 1028 \\
& Sum.  & 1000  & 10000    & 2655 \\
\hline
\multirow{3}{*}{Vicuna-7B} & Fact. & 413   & 6171     & 1358 \\
& Hall. & 587   & 3829     & 1297 \\
& Sum.  & 1000  & 10000    & 2655 \\
\hline\hline
\end{tabular}
\caption{Target LLM's prediction towards 3 datasets.}
\label{tab:datasets}
\end{table}

To evaluate the performance of \sysname in detecting hallucinations, we utilized three datasets from distinct domains: CNN/Daily Mail (CNNDM), Natural Questions (NQ), and HaluEval. These datasets provide diverse scenarios, including summarization, question answering, and factuality evaluation, ensuring comprehensive testing of the proposed framework.

\sssec{CNN/Daily Mail (CNNDM)} \cite{hermann2015teaching}. This dataset is widely used for text summarization tasks. It consists of over 300,000 unique news articles from CNN and the Daily Mail, each paired with human-generated abstractive summaries. The dataset is divided into 286,817 training pairs, 13,368 validation pairs, and 11,487 test pairs. The average length of source documents in the training set is 766 words, while the summaries average 53 words. Hallucinations in this context are identified when generated summaries include content inconsistent with the original articles, emphasizing the model's ability to maintain fidelity in summarization tasks.

\sssec{Natural Questions (NQ)} \cite{kwiatkowski2019natural}. This question-answering dataset contains real user queries issued to the Google search engine, paired with corresponding Wikipedia pages. Each example includes a long answer (a paragraph) and, if applicable, a short answer (one or more entities) annotated by human annotators. The dataset comprises 307,373 training examples, 7,830 development examples, and 7,842 test examples. Hallucinations in NQ are defined as generated answers deviating from or contradicting the provided ground-truth answers, focusing on the factual correctness of responses.

\sssec{HaluEval} \cite{li2023halueval}. A specialized dataset designed to evaluate the factuality of language model outputs. It includes 5,000 general user queries with ChatGPT responses and 30,000 task-specific examples from three tasks: question answering, knowledge-grounded dialogue, and text summarization. For general user queries, the dataset adopts the 52K instruction tuning dataset from Alpaca. This dataset serves as a benchmark for testing both factual and hallucinated responses across multiple scenarios, offering a comprehensive evaluation of the model's detection capabilities.

%\subsection{Comparison with Previous Works}\label{sec:detect:sota}

%\subsection{Metrics}\label{sec:detect:metrics}

\begin{figure}
\centering
     \subfloat{\includegraphics[width=0.48\textwidth]{figures/fig-overall_compare-legend.pdf}}
      \\
    \addtocounter{subfigure}{-1}
      \subfloat[Llama-2-7B]{\includegraphics[width=0.5\columnwidth]{figures/fig-overall_compare-Llama-2-7B.pdf}}
      \subfloat[Vicuna-7B]{\includegraphics[width=0.5\columnwidth]{figures/fig-overall_compare-Vicuna-7B.pdf}}
      \caption{
      We compare different groups of features.
      }
    \label{fig:detect_overall}
\end{figure}

\subsection{Ablation Study on Different Features}\label{sec:detect:ablation}

\sssec{Method}.
To analyze the effectiveness of various features in distinguishing hallucinated and factual outputs, we conducted an ablation study. In this experiment, we isolated each feature group (logit, attention, and activation) as the sole input to the detection model and evaluated their classification performance on the HaluEval and CNNDM datasets. Specifically, accuracy, recall for hallucinated outputs (\textit{Recall(Halu)}), and recall for factual outputs (\textit{Recall(Fact)}) were measured to assess the contribution of each feature. This approach enables a detailed comparison of feature importance and their respective strengths in different scenarios.

\sssec{Results}.
From Table~\ref{tab:ablation}, several observations can be made. Among the logit features, \textit{Joint Probability} achieves the highest \textit{Recall(Halu)} (0.72) on HaluEval, indicating its effectiveness in detecting hallucinations. However, its \textit{Recall(Fact)} is relatively low (0.37), making it less reliable for balanced detection. In contrast, \textit{Lookback Ratio}, an attention-based feature, performs consistently well across both datasets, achieving high accuracy (0.75 on HaluEval and 0.83 on CNNDM) and balanced recall values, suggesting its robustness in both hallucination and factual scenarios. Activation-based features, particularly the \textit{Hidden State}, show strong performance on HaluEval (accuracy of 0.76 and balanced recall values), but their efficacy diminishes on CNNDM, likely due to dataset-specific differences. Interestingly, some features like \textit{Attention Sharpness} and \textit{Activation Entropy}, while insightful during the understanding phase, demonstrate limited utility in actual classification, reflecting their inability to effectively capture discriminative information. These results suggest that while logit features excel in identifying hallucinations, attention-based features provide more consistent performance across datasets, making them suitable for general scenarios.

\subsection{Comparison between Different Token Selection Strategies}\label{sec:detect:token}

\begin{table}[]
\centering
\begin{tabular}{|M{1.5cm}|l|M{1.5cm}|M{1.5cm}|}
\hline\hline
Model & Strategy & CNNDM & HaluEval \\
\hline\hline
\multirow{7}{*}{Llama-2-7B} & All token           & 0.52     & 0.51     \\
& 1st token           & 0.51     & 0.53     \\
& Last token          & 0.53     & 0.51     \\
& Per token           & 0.68     & 0.74     \\
& Window(2, 1) & 0.78     & 0.81     \\
& Window(4, 2) & \textbf{0.85}     & \textbf{0.87}     \\
& Window(8, 4) & 0.83     & 0.82    \\
\hline
\multirow{7}{*}{Vicuna-7B} & All token           & 0.52     & 0.51     \\
& 1st token           & 0.50     & 0.52     \\
& Last token          & 0.52     & 0.52     \\
& Per token           & 0.71     & 0.75     \\
& Window(2, 1) & 0.80     & 0.82     \\
& Window(4, 2) & \textbf{0.87}     & \textbf{0.89}     \\
& Window(8, 4) & 0.85     & 0.83    \\
\hline\hline
\end{tabular}
\caption{Comparison between different token selection strategies.}
\label{tab:token}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[]
\normalsize
\centering
\begin{tabular}{|M{1.6cm}|M{2cm}|M{3cm}|M{1cm}M{1cm}M{1cm}|M{1cm}M{1cm}M{1cm}|}
\hline\hline
\multirow{2}{*}{Model} &\multirow{2}{*}{Group} &
  \multirow{2}{*}{Feature} &
  \multicolumn{3}{c|}{CNNDM} &
  \multicolumn{3}{c|}{HaluEval} \\
  \cline{4-9}
 &&&
  \multicolumn{1}{c}{CNNDM} &
  \multicolumn{1}{c}{HaluEval} &
  \multicolumn{1}{c|}{NQ} &
  \multicolumn{1}{c}{CNNDM} &
  \multicolumn{1}{c}{HaluEval} &
  \multicolumn{1}{c|}{NQ} \\
  \hline\hline
\multirow{10}{*}{Llama-2-7B} & \multirow{4}{*}{Logit}      & Max token rank         & 0.6  & 0.52 & 0.58 & 0.51 & 0.53 & 0.52 \\
& & Min token prob         & 0.58 & 0.52 & 0.55 & 0.50 & 0.54 & 0.51 \\
& & Joint prob             & 0.63 & 0.56 & 0.61 & 0.54 & 0.54 & 0.52 \\
& & JSD                    & 0.51 & 0.51 & 0.50 & 0.50 & 0.51 & 0.51 \\
\cline{2-9}
& \multirow{3}{*}{Attention}  & Lookback ratio         & 0.83 & 0.54 & 0.66 & 0.57 & 0.75 & 0.50 \\
& & Attention sharpness    & 0.61 & 0.51 & 0.54 & 0.52 & 0.60 & 0.50 \\
& & Key token atten. ratio & 0.72 & 0.52 & 0.62 & 0.55 & 0.70 & 0.51 \\
\cline{2-9}
& \multirow{3}{*}{Activation} & Hidden state           & 0.74 & 0.53 & 0.55 & 0.52 & 0.76 & 0.50 \\
& & Activation entropy     & 0.57 & 0.52 & 0.51 & 0.51 & 0.55 & 0.52 \\
& & Activation map         & 0.54 & 0.52 & 0.50 & 0.52 & 0.53 & 0.50 \\
\hline \hline
\multirow{10}{*}{Vicuna-7B} & \multirow{4}{*}{Logit}      & Max token rank         & 0.6  & 0.52 & 0.58 & 0.51 & 0.53 & 0.52 \\
& & Min token prob         & 0.58 & 0.52 & 0.55 & 0.50 & 0.54 & 0.51 \\
& & Joint prob             & 0.63 & 0.56 & 0.61 & 0.54 & 0.54 & 0.52 \\
& & JSD                    & 0.51 & 0.51 & 0.50 & 0.50 & 0.51 & 0.51 \\
\cline{2-9}
& \multirow{3}{*}{Attention}  & Lookback ratio         & 0.83 & 0.54 & 0.66 & 0.57 & 0.75 & 0.50 \\
& & Attention sharpness    & 0.61 & 0.51 & 0.54 & 0.52 & 0.60 & 0.50 \\
& & Key token atten. ratio & 0.72 & 0.52 & 0.62 & 0.55 & 0.70 & 0.51 \\
\cline{2-9}
& \multirow{3}{*}{Activation} & Hidden state           & 0.74 & 0.53 & 0.55 & 0.52 & 0.76 & 0.50 \\
& & Activation entropy     & 0.57 & 0.52 & 0.51 & 0.51 & 0.55 & 0.52 \\
& & Activation map         & 0.54 & 0.52 & 0.50 & 0.52 & 0.53 & 0.50 \\
\hline \hline
\end{tabular}
%\vspace{-10pt}
\caption{We did experiment by using different datasets as train dataset and test dataset to see different internal state features' transferibility.}
\label{tab:transfer}
%\vspace{-10pt}
\end{table*}

\begin{table*}[ht]
\centering

\begin{tabular}{|l|l|l|l|c|}
\hline\hline
\textbf{Category} & \textbf{Feature Name}       & \textbf{Theo. Storage} & \textbf{Theo. Comp} & \textbf{Comp. Time Per Token (/s)} \\ \hline\hline
\multirow{2}{*}{Attention} 
                  & Attention Lookback Ratio    & $O(w \cdot H \cdot L)$               & $O(w \cdot H \cdot L)$                   & 3.27                                \\ \cline{2-5}
                  & Attention Allocation Sharpness & $O(w \cdot H \cdot L)$            & $O(w \cdot H \cdot L \cdot \log w)$      & 0.19                                \\ \hline\hline
\multirow{3}{*}{Activation}
                  & Last Layer Hidden State     & $O(w \cdot d)$                       & $O(w \cdot d)$                           & 0.09                                \\ \cline{2-5}
                  & Activation Map              & $O(w \cdot d \cdot m)$               & $O(w \cdot d \cdot m)$                   & 0.39                                \\ \cline{2-5}
                  & Activation Entropy          & $O(w \cdot m)$                       & $O(w \cdot m \cdot \log m)$              & 0.29                                \\ \hline\hline
\multirow{3}{*}{Logit}
                  & Min Token Probabilities     & $O(w \cdot L)$                       & $O(w \cdot L)$                           & 1.02                                \\ \cline{2-5}
                  & Max Token Ranks             & $O(w \cdot L)$                       & $O(w \cdot L \cdot \log w)$              & 1.15                               \\ \cline{2-5}
                  & Joint Token Probabilities   & $O(w \cdot L)$                       & $O(w \cdot L \cdot w)$                   & 0.73                                \\ \hline\hline
\end{tabular}
%\vspace{-10pt}
\caption{System Overhead for Different Features (Sliced Window, Window Size = 8)}
\label{tab:system_overhead}
%\vspace{-15pt}
\end{table*}

\sssec{Method}. To evaluate the impact of different token selection strategies on detection performance, we conducted experiments using various strategies, including \textit{All Token}, \textit{First Token}, \textit{Last Token}, \textit{Per Token}, and \textit{Sliced Window} with different window sizes. For each strategy, all extracted features were used as inputs to the detection model. The metrics reported in Table~\ref{tab:token} include accuracy scores on both the CNNDM and HaluEval datasets, allowing for a comprehensive comparison of the effectiveness of different token selection methods.

\sssec{Results}.
The results in Table~\ref{tab:token} reveal that the \textit{Sliced Window} strategy consistently outperforms others, achieving the highest accuracy (e.g., 0.87 on HaluEval with \textit{Window(4, 2)}), due to its ability to maintain uniform token input sizes across samples. This ensures that the detection model receives structured and balanced information. On the other hand, the \textit{Per Token} strategy, while intuitive, performs worse (e.g., 0.68 on CNNDM) likely due to noisy labeling issues rather than inherent flaws in the method itself. The \textit{First Token} and \textit{Last Token} strategies exhibit the lowest performance, as they fail to capture sufficient context for accurate classification. These findings suggest that while sliced window methods provide a structured and balanced approach suitable for diverse scenarios, the effectiveness of \textit{Per Token} could be improved with more refined labeling processes.

\subsection{Transferbility Study}\label{sec:detect:transfer}

\sssec{Methd}.
To evaluate the transferability of different internal state features, we conducted experiments using CNNDM and HaluEval as training datasets and tested their performance on CNNDM, HaluEval, and NQ, a benchmark dataset designed for question answering with a focus on fidelity-related hallucinations. For each experiment, we trained models using one dataset and evaluated the effectiveness of individual features on the remaining datasets to assess their cross-dataset generalizability.

\sssec{Results}.
The results in Table~\ref{tab:transfer} highlight several key findings. First, certain features trained on CNNDM, such as \textit{Lookback Ratio} and \textit{Joint Probability}, exhibit strong transferability to NQ, achieving relatively high accuracy scores (e.g., 0.66 and 0.61, respectively). This suggests that these features capture generalizable patterns that extend beyond the CNNDM dataset. However, features trained on HaluEval demonstrate poor transferability to CNNDM and NQ, with a significant drop in accuracy (e.g., \textit{Key Token Attention Ratio} and \textit{Hidden State} dropping to around 0.50). This discrepancy indicates that the features extracted from HaluEval are highly dataset-specific and may reflect idiosyncratic patterns rather than generalizable characteristics.


The lack of transferability between CNNDM and HaluEval is particularly notable. This suggests that the two datasets encode fundamentally different patterns of hallucination and factuality, potentially due to variations in text length, domain, or the nature of the hallucination tasks. These results highlight the importance of selecting datasets that align closely with the target domain when designing hallucination detection models and the challenges of building universally transferable feature-based systems.

\subsection{System Overhead}\label{sec:detect:cost}

\sssec{Method}.
To evaluate the computational efficiency and storage requirements of different features, we measured the theoretical storage overhead, theoretical computational complexity, and actual computation time under the sliced window setting with a window size of 8. The theoretical metrics are expressed in terms of the number of tokens in the window ($w$), the number of attention heads ($H$), the number of layers ($L$), the dimensionality of hidden states ($d$), and the intermediate dimensionality in feed-forward layers ($m$). These measurements allow us to quantify the resource demands for extracting each feature and to identify potential bottlenecks in real-world applications.

\sssec{Results}.
The theoretical results, as shown in Table~\ref{tab:system_overhead}, provide a detailed breakdown of storage and computation costs for features from attention, activation, and logit states. Actual computation time will be discussed once experimental data is finalized.

%\subsection{Different Target Model}\label{sec:detec:tar_models}