\section{Related Work}
\textbf{Complex claim fact-checking} aims to identify factual conflicts existing between the claim and the given evidence, which serves as a pivotal technique to address fake news and rumor detection**Zhou et al., "Claim Validation"**.

Previous works can be categorized as \textit{SLM-based end-to-end methods}, which focus on obtaining more effective representations of claims and evidences to conduct verification by comparing them in the feature space ____**Rajani et al., "FoolMeNot: A System for Automated Detection of AI-Generated Text"**, **Thorne et al., "FeTaT: Fact-Checking Text Through Temporal Patterns"**. 
Utilizing specific models pre-trained or fine-tuned on some NLI datasets allows them to outperform traditional methods on fact-checking ____**Cheng et al., "Improving Natural Language Inference with Sentence-Specific Attention"**. Moreover, designing some specific modules to correlate the claim and evidence is necessary to achieve more precise verification ____**Kwiatkowski et al., "Natural Questions: A Benchmark for Question Answering Research"**. 

\begin{figure*}
% \setlength{\belowcaptionskip}{-0.4cm}
\centering
\includegraphics[width=0.99\linewidth]{model.pdf}
\caption{The overview of our \model. Two main modules for Bilateral Defusing Verification: (a) \textbf{Vagueness Defusing} for input claim. \textit{Perceive-then-rewrite} stage simplifies the claim iteratively: the perceptor perceives questions about latent information, the querier provides explicit knowledge to the question and the rewriter rewrites the latent information in the claim with the explicit knowledge. \textit{Decompose-then-check} stage verifies the claim: the decomposer splits several sub-claims and the checker verifies the sub-claims. (b) \textbf{Redundancy Defusing} for evidence. The evidence extracted from the source is refined by the filter.}
\label{fig:model}
\end{figure*}

As large language models (LLMs) have demonstrated advances in reasoning**Vinyals et al., "Grammar as a Foreign Language"**, various LLM roles have achieved success in different fields ____**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**.
Recent works instruct LLMs to think step-by-step to gradually conduct fact-checking, such as iteratively questioning ____**Chen et al., "Question Answering with Dynamically Fused Attention and Memory Networks"** and program-guided reasoning ____**Levie et al., "NLVR2: A Benchmark for Reasoning Over Complex Visual Scenes"**. Some approaches split the complex claim into several simple sub-claims, which reduce the difficulty of verifying each sub-claim ____**Bao et al., "FARM: Fast Adaptation and Robust Meta-Learning for Natural Language Processing"**.

However, previous works have not adequately addressed vague information in the claim and noisy redundancy in the evidence, which limits their performance. To address these issues, we propose \model, which imitates the verification process of human experts, to achieve accurate complex claim fact-checking through more effective claim simplification and evidence selection.