\section{Related Work}
\textbf{Complex claim fact-checking} aims to identify factual conflicts existing between the claim and the given evidence, which serves as a pivotal technique to address fake news and rumor detection~\cite{liu2024skepticism}.

Previous works can be categorized as \textit{SLM-based end-to-end methods}, which focus on obtaining more effective representations of claims and evidences to conduct verification by comparing them in the feature space \cite{popat2018declare, ma2019sentence}. 
Utilizing specific models pre-trained or fine-tuned on some NLI datasets allows them to outperform traditional methods on fact-checking \cite{kruengkrai2021multi, he2022debertav3, wadden2022multivers}. Moreover, designing some specific modules to correlate the claim and evidence is necessary to achieve more precise verification \cite{xu2022evidence, liao2023muser}. 

\begin{figure*}
% \setlength{\belowcaptionskip}{-0.4cm}
\centering
\includegraphics[width=0.99\linewidth]{model.pdf}
\caption{The overview of our \model. Two main modules for Bilateral Defusing Verification: (a) \textbf{Vagueness Defusing} for input claim. \textit{Perceive-then-rewrite} stage simplifies the claim iteratively: the perceptor perceives questions about latent information, the querier provides explicit knowledge to the question and the rewriter rewrites the latent information in the claim with the explicit knowledge. \textit{Decompose-then-check} stage verifies the claim: the decomposer splits several sub-claims and the checker verifies the sub-claims. (b) \textbf{Redundancy Defusing} for evidence. The evidence extracted from the source is refined by the filter.}
\label{fig:model}
\end{figure*}

As large language models (LLMs) have demonstrated advances in reasoning~\cite{wei2022chain,wang2022self,sun2024determlr}, various LLM roles have achieved success in different fields~\cite{sun2024harnessing,sun2024facilitating,liu2025mobile}.
Recent works instruct LLMs to think step-by-step to gradually conduct fact-checking, such as iteratively questioning \cite{press2022measuring} and program-guided reasoning \cite{pan2023factchecking}. Some approaches split the complex claim into several simple sub-claims, which reduce the difficulty of verifying each sub-claim \cite{zhang2023llmbased, wang2023explainable}.

However, previous works have not adequately addressed vague information in the claim and noisy redundancy in the evidence, which limits their performance. To address these issues, we propose \model, which imitates the verification process of human experts, to achieve accurate complex claim fact-checking through more effective claim simplification and evidence selection.