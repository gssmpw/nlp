\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
% \usepackage{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}

% \usepackage{sectsty}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{ulem}
\usepackage[thicklines]{cancel}
\usepackage{cleveref}

\bibliographystyle{unsrtnat}
\usepackage[pdftex,dvipsnames]{xcolor}         % colors
% Customized todo functions

\usepackage{xargs}                      % Use more than one optional parameter in a new commands 

\theoremstyle{plain}

\title{Neural Guided Diffusion Bridges}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{
 Gefan Yang\(^{1}\) \quad Frank van der Meulen\(^{2}\) \quad Stefan Sommer\(^{1}\) \\
  \(^{1}\)Department of Computer Science, University of Copenhagen\\
  \(^2\)Department of Mathematics, Vrije Universiteit Amsterdam\\
  \(^{1}\)\texttt{\{gy, sommer\}@di.ku.dk} \\
  \(^{2}\)\texttt{f.h.van.der.meulen@vu.nl} \\
}

\newcommand{\dt}{\mathrm{d}t}
\newcommand{\dx}{\mathrm{d}x}
\newcommand{\dX}{\mathrm{d}X}
\newcommand{\dW}{\mathrm{d}W}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Pb}{\mathbb{P}}
\newcommand{\Pbs}{\Pb^{\star}}
\newcommand{\Pbc}{\Pb^{\circ}}
\newcommand{\Pbd}{\Pb^{\bullet}}

\newcommand{\Lb}{\mathbb{L}}
\newcommand{\Lbs}{\Lb^{\star}}
\newcommand{\Lbc}{\Lb^{\circ}}
\newcommand{\Lbd}{\Lb^{\bullet}}

\newcommand{\E}{\mathbb{E}}
\newcommand{\di}{\mathrm{d}}
\newcommand{\kld}{\mathrm{D_{KL}}}
\newcommand{\opt}{\text{opt}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{notation}{Notation}

\DeclareMathOperator\supp{supp}


\begin{document}


\maketitle


\begin{abstract}
    We propose a novel method for simulating conditioned diffusion processes (diffusion bridges) in Euclidean spaces. By training a neural network to approximate bridge dynamics, our approach eliminates the need for computationally intensive Markov Chain Monte Carlo (MCMC) methods or reverse-process modeling. Compared to existing methods, it offers greater robustness across various diffusion specifications and conditioning scenarios. This applies in particular to  rare events and multimodal distributions, which pose challenges for score-learning- and MCMC-based approaches. We propose  a flexible variational family for approximating the diffusion bridge path measure which is  partially specified by a neural network. Once trained, it enables efficient independent sampling at a cost comparable to sampling the unconditioned (forward) process.
\end{abstract}


\section{Introduction}
Diffusion processes play a fundamental role in various fields such as mathematics, physics, evolutionary biology, and, recently, generative models. In particular, diffusion processes conditioned to hit a specific point at a fixed future time, which are often referred to as \textit{diffusion bridges}, are of great interest in situations where observations constrain the dynamics of a stochastic process. For example, in generative modeling, stochastic imputation between two given images, also known as the image translation task, uses diffusion bridges to model dynamics \citep{zhou2024denoising, zheng2024diffusion}. In the area of stochastic shape analysis and computational anatomy,  random evolutions of biological shapes of organisms are modeled as non-linear diffusion bridges, and simulating such bridges is critical to solving inference and registration problems \citep{arnaudon2022diffusion, baker2024conditioning, yang2024simulating}. Finally, diffusion bridges play a crucial role in Bayesian inference and parameter estimations based on discrete-time observations. \citep{delyon2006simulation, meulen2017bayesian, meulen2018bayesian, pieschner2020bayesian}

Simulation of diffusion bridges in either Euclidean spaces or manifolds is nontrivial since, in general, there is no closed-form expression for transition densities, which is key to constructing the conditioned dynamics via Doob's \(h\)-transform \citep{rogers2000diffusions}. This task has gained a great deal of attention in the past decades \citep{beskos2006exact, delyon2006simulation, schauer2017guided, whitaker2016improved, bierkens2021piecewise,  mider2021continuous, heng2022simulating, chau2024efficient, baker2024conditioning}. Among them, one common approach is to use a proposed bridge process (called \textit{guided proposal}) as an approximation to the true bridge. Then either MCMC or Sequential Monte Carlo (SMC) methods are deployed to sample the true bridge via the tractable likelihood ratio between the true and proposed bridges. Another solution is to use the \textit{score-matching} technique \citep{hyvarinen2005estimation, vincent2011connection} to directly approximate the intractable score of the transition density using gradient-based optimization. Here, a neural network is trained with samples from the forward process \citep{heng2022simulating} or adjoint process \citep{baker2024score}, and plugged into numerical solving schemes, for example, Euler-Maruyama. Several recent studies deal with the extension of bridge simulation techniques beyond Euclidean spaces to manifolds \citep{sommer2017bridge, jensen2023simulation, grong2024score, corstanje2024simulating}. All of these  rely on either a type of guided proposal or score matching.

Both guided-proposal-based and score-learning-based bridge simulation methods have certain limitations: the guided proposal requires a careful choice of a certain  ``auxiliary process''. \citet{mider2021continuous} provided various strategies, but it is fair to say that guided proposals are mostly useful when combined with MCMC or Sequential Monte Carlo (SMC) methods. In case of a strongly nonlinear diffusion or high-dimensional diffusion, the simulation of bridges using guided proposals combined with MCMC (most notably the preconditioned Crank-Nicolson (pCN) scheme \citep{cotter2013mcmc}) or SMC may be computationally demanding. On the other hand, score-matching relies on sampling unconditioned processes, and it performs poorly for bridges conditioned on rare events, as the unconditioned process rarely explores those regions, resulting in inaccurate estimation. Additionally, the canonical score-matching loss requires the inversion of the matrix \(\sigma \sigma^T\) where \(\sigma\) is the diffusivity of the diffusion. This rules out hypo-elliptic diffusions and poses  significant computational challenges for high-dimensional diffusions, where this matrix can  become close to singularity,  further exacerbating the difficulty of obtaining stable and accurate minimization of the loss.

To address these issues, we introduce a new bridge simulation method called the \textit{neural guided diffusion bridge}. It consists of the guided proposal introduced in \citet{schauer2017guided} with an additional superimposed drift term that is parametrized by a neural network. The family of laws on path space induced by such proposals provides a rich variational family for approximating the law of the diffusion bridge. Once the variational approximation has been learned, independent samples can be generated at a cost similar to that of sampling the unconditional (forward) process. The contributions of this paper are as follows:
\begin{itemize} 
    \item We propose a simple diffusion bridge simulation method inspired by the guided proposal framework, avoiding the need for reverse-process modelling or intensive MCMC or SMC updates. Once the network has been trained, obtaining independent samples from the variational approximation is trivial and computationally cheap;
    \item Unlike score-learning-based simulation methods, which rely on unconditional samples for learning, our method is  grounded to learn directly from conditional samples. This results in greater training efficiency. 
    \item We validate the method through numerical experiments ranging from one-dimensional linear to high-dimensional nonlinear cases, offering qualitative and quantitative analyses. Advantages and disadvantages compared to the guided proposal \citep{mider2021continuous} and two score-learning-based methods,  \citet{heng2022simulating} and \citet{baker2024score}, are included.
\end{itemize}

\section{Related work}
\textbf{Diffusion bridge simulation:} 
This topic has received considerable attention over the past two decades and it is hard to give a short complete overview. Early contributions are \citet{clark1990simulation, chib2004likelihood, delyon2006simulation, beskos2006exact, lin2010generating}, and \citet{golightly2010learning}. The approach of guided proposals that we use here was introduced in \citet{schauer2017guided} for fully observed uniformly elliptic diffusions and later extend to partially observed hypo-elliptic diffusions in \citet{bierkens2020simulation}.

Another class of methods approximate the intractable transition density using machine learning or kernel-based techniques.  \citet{heng2022simulating} applied score-matching to define a variational objective for learning the additional drift in the reversed diffusion bridge. \citet{baker2024score} proposed learning the additional drift directly in the forward bridge via sampling from an adjoint process. \citet{chau2024efficient} leveraged Gaussian kernel approximations for drift estimation. 

The method we propose is a combination of existing ideas. It used the guided proposals from \citet{schauer2017guided} to construct a conditioned process, but learns an additional drift term parametrized by a neural net using variational inference. 

\textbf{Diffusion Schrödinger bridge:} The diffusion bridge problem addressed in this paper may appear similar to the diffusion Schrödinger bridge (DSB) problem due to their names, but they are fundamentally different. A diffusion bridge refers to a diffusion process conditioned to start at one fixed point and reach another fixed point, while the DSB involves connecting two fixed marginal distributions and is often framed as an entropy-regularized optimal transport problem. Although DSB has gained attention for applications in generative modelling \citep{thornton2022riemannian, de2021diffusion, shi2024diffusion, tang2024simplified}, it is important to recognize the distinctions between these problems.

\textbf{Neural SDE:} Neural SDEs extend neural ODEs \citep{chen2018neural} by incorporating inherent stochasticity, making them suitable for modelling data with stochastic dynamics. Research on neural SDEs can be broadly categorized into two areas: (1) modelling terminal state data \citep{tzen2019neural, tzen2019theoretical}, and (2) modelling entire data trajectories \citep{li2020scalable, kidger2021neural}. Our method aligns with the second category, as it employs trainable drift terms and incorporates end-point constraints to model the full data trajectory.

\section{Preliminaries: recap on guided proposals} \label{sec:preliminaries}

\subsection{Problem statement} \label{subsec:problem_statement}

Let \((\Omega, \mathcal{F}, \Pb)\) be a probability space with filtration \(\{\mathcal{F}_{t}\}_{t\in[0, T]}\)  and \(W\) be a \(d_w\)-dimensional \(\Pb\)-Wiener process. A \(d\)-dimensional \(\{\mathcal{F}_t\}\)-adapted diffusion process \(X\) with the law of \(\Pb\) is defined as the strong solution to the stochastic differential equation (SDE):
\begin{equation} 
    \dX_t = b(t, X_t)\dt + \sigma(t, X_t)\dW_t,\quad X_0=x_0\in\R^d. \label{eq:X_sde}
\end{equation}
The coefficient terms \(b,\sigma\) are assumed to be Lipschitz continuous and of linear growth to guarantee the existence of a strong solution \(X_t\) \citep[Chapter 5.2]{oksendal2014stochastic}. In addition, we impose the standing assumption that \(X\) admits smooth transition densities \(p\) with respect to the Lebesgue measure \(\lambda\) on \((\R^d, \mathcal{B}(\R^d))\), where \(\mathcal{B}(\R^d)\) is the Borel algebra of \(\R^d\). That is, \(\Pb(X_t\in A \mid X_s =x) = \int_{A} p(t, y\mid s, x)\lambda(\di y)\) for \(0\leq s < t \leq T\), \(A\subset \R^d\). 

\begin{notation}
    Let \(\Pbc, \Pbs\) and \(\Pbd\) be measures on \((\Omega, \mathcal{F})\), we denote the laws of \(X\) on \(\mathcal{C}([0, T],\R^d)\) under \(\Pbc, \Pbs\) and \(\Pbd\) by \(\Lbc, \Lbs\) and \(\Lbd\) respectively. For notational ease, the expectations under \(\Pbc, \Pbs\) and \(\Pbd\) (and similarly \(\Lbc, \Lbs\) and \(\Lbd\)) are denoted by \(\E^{\circ}, \E^{\star}\) and \(\E^{\bullet}\) respectively. The process \(X\) under \(\Lbc\) and \(\Lbd\) is sometimes denoted by \(X^{\circ}\) and \(X^{\bullet}\) respectively. For any measure \(\mathbb{Q}\) on \((\Omega, \mathcal{F})\), we always denote its restriction to \(\mathcal{F}_t\) by \(\mathbb{Q}_t\).
\end{notation}

The following proposition combines Proposition 4.4 and Example 4.6 in \citet{sethmacher2024class}. It shows how the dynamics of \(X\) change under observing certain events at time \(T\).
\begin{proposition} \label{prop:conditioned_process} 
    Fix \(t<T\). Let \(y\in \R^d\) and \(q(\cdot \mid y)\) be a probability density function with respect to a finite measure \(\nu\). Let \(h(t,x) = \int_{\R^d} p(T,y\mid t, x) q(v\mid y)\nu(\di y)\), and define the measure \(\Pbs_t\) on \(\mathcal{F}_t\) by \(\di \Pbs_t \coloneq \frac{h(t,X_t)}{h(0,x_0)} \di\Pb_t\). 
    Then under the new measure \(\Pbs_t\), the process \(X\) solves the SDE
    \begin{equation} 
        \dX_t = \{b(t, X_t) + a(t, X_t)r(t, X_t)\} \dt + \sigma(s, X_s)\dW^\star_s, \quad X_0 = x_0.\label{eq:X_doob_sde}
    \end{equation}
    where \(r(s,x)=\nabla_x \log h(s,x)\), \(a(s,x)=\sigma(s,x)\sigma^T(s,x)\) and \(W^\star\) is a \(\Pbs\)-Wiener process.
    
    Furthermore, for any bounded and measurable function \(g\) and \(0 \leq t_1 \leq ... \leq t_n < T\), 
    \begin{equation} 
        \E^\star[g(X_{t_1},...,X_{t_n})] = \int_{\R^d} \E[ g(X_{t_1},...,X_{t_n}) \mid X_T = y]\,\xi(\di y),
    \end{equation}
    where \(\xi\) is the measure defined on \((\R^d, \mathcal{B}(\R^d))\) via
    \begin{equation}
        \xi(\di y) = \frac{p(T,y\mid 0, x_0) q(v\mid y) \nu(\di y)}{\int_{\R^d} p(T,y\mid 0, x_0)  q(v\mid y) \nu(\di y)}.
    \end{equation}
\end{proposition}
A Bayesian interpretation of this result is obtained by assigning the endpoint \(y\) a prior density \(\pi(y)=p(T, y \mid 0, x_0)\), and where the observation is given by \(v\in\R^{d'}\).  The likelihood of this observation is \(\ell(y\mid v) = q(v\mid y)\) and therefore \(\xi(\di y)\) gives the posterior measure of \(y\), conditioned on observing \(v\). Therefore, under \(\Pbs\), the process \(X\) is constructed by first sampling the endpoint \(y\) conditioned on the observation \(v\) by \(\ell(y\mid v)\), followed by sampling the bridge to \(y\). In this paper, we will apply this result when \(q(v\mid y)=\psi(v; Ly, \Sigma)\), where \(L\in \R^{d\times d'}\) with \(d'\le d\) and \(L\) is assumed to be of full (row) rank. Here, \(\psi(x;\mu,\Sigma)\) denotes the density of the \(\mathcal{N}(\mu,\Sigma)\)-distribution, evaluated at \(x\). For example, for a two-dimensional diffusion observing only the first component with small error corresponds to \(L=\begin{bmatrix} 1 & 0\end{bmatrix}\) and \(\Sigma=\epsilon^2\mathbf{I}\), taking \(\epsilon\) very small. 

If \(p\) were known in closed form, then the conditioned process could be directly sampled from Equation \eqref{eq:X_doob_sde}. This is rarely the case. For this reason, let \(\tilde X\) be an auxiliary diffusion process that admits transition densities \(\tilde{p}\) in closed form. Let \(\tilde  h(t,x) = \int_{\R^d} \tilde p(T,y\mid t,x) q(v\mid y) \nu(\di y)\). Define
\begin{equation} \label{eq:exponential_martingale}
    E_t \coloneq \frac{\tilde{h}(t,X_t)}{\tilde{h}(0,x_0)}  \exp\left( \int_0^t \frac{(\partial_s + \mathcal{A})\tilde h}{\tilde h}(s,X_s) \di s \right),
\end{equation}
where \(\mathcal{A}\) is the infinitesimal generator of the process \(\tilde X\), i.e. for any \(f\) in its domain \(\mathcal{A}f(x)=\sum_{i} b_i(t,x) \partial_i f(t,x)+ \frac{1}{2} \sum_{i,j} a_{i,j}(t,x) \partial_{ij} f(t,x)\). Under weak conditions (see e.g. \citet[Lemma 3.1]{palmowski2002technique}), \(E_t\) is a mean-one martingale. If we define the change of measure \(\di \Pbc_t = E_t  \di \Pb_t\), then, under \(\Pbc_t\), the process \(X\) solves the SDE
\begin{equation} 
    \dX_t =  \{b(t, X_t) + a(t, X_t)\tilde r(t, X_t)\}\dt + \sigma(t, X_t)\dW^\circ_t,\quad X_0 = x_0, \label{eq:X_guided_sde}
\end{equation}
where \(\tilde r(t,x)=\nabla_x \log \tilde h(t,x)\) and \(W^\circ\) is a \(\Pbc\)-Wiener process. The process specified by the dynamics in Equation \eqref{eq:X_guided_sde} is called the guided proposal, which is a process constructed to resemble the true conditioned process by replacing \(r\) by \(\tilde r\). Crucially, as its drift and diffusion coefficients are known in closed form, the guided proposal can be sampled using efficient numerical SDE solvers.

In \citet{schauer2017guided} and \citet{bierkens2020simulation}, precise conditions are given under which \(\Pbs_T \ll \Pbc_T\). In the case of conditioning on the event \(\{LX_T =v\}\) --so there is no noise on the observation-- this is subtle. We postpone a short discussion on this to Section \ref{subsec:choice_of_linear_process}. In all numerical examples considered in Section \ref{sec:experiments}, we have ensured sufficient conditions are satisfied. This guarantees good behaviour when the noise level of the observation noise tends to zero. We then get the following theorem from \citet[Theorem 2.6]{bierkens2020simulation} that states the change of laws from \(\Lbc\) to \(\Lbs\).
\begin{theorem} \label{thm:dpstar/dpcirc}
    If certain assumptions \citep[Assumptions 2.4, 2.5]{bierkens2020simulation} hold, then
    \begin{equation} \label{eq:llr}
    \frac{\di\Lbs}{\di\Lbc}(X) = \frac{\tilde{h}(0,x_0)}{h(0,x_0)}\Psi_T(X),
    \end{equation}
    where
    \begin{equation}
        \Psi_T(X)=\exp\left( \int_0^T \frac{(\partial_t + \mathcal{A}) \tilde h}{\tilde h}(s,X_s) \di s \right).
    \end{equation}
\end{theorem}

\subsection{Guided proposal induced by linear process} \label{subsec:linear_guided_process}
We now specialize to the case where the auxiliary process is linear, i.e.
\begin{subequations} \label{eq:X_auxiliary_sde}
    \begin{gather} 
        \di \tilde{X}_t = \tilde{b}(t, \tilde{X}_t)\dt + \tilde{\sigma}(t)\dW_t,\\
        \tilde{b}(t, x) := \beta(t) + B(t)x.
    \end{gather}
\end{subequations}
Let \(\tilde{A}\) denote the infinitesimal generator of the process \(\tilde X\). Since \(\tilde h\) solves \((\partial_t + \tilde{A}\tilde) h=0\), we can replace \((\partial_t + \mathcal{A}) \tilde h\) by \((\mathcal{A}-\tilde{\mathcal{A}})\tilde h\). This gives
\begin{subequations}
    \begin{gather}
        \Psi_t(X) = \exp\left(\int^t_0 G(s, X_s)\di s\right),\quad t\leq T \label{eq:Psi}\\
        G(s, x) := \left\langle b(s,x)-\tilde{b}(s,x), \tilde{r}(s,x) \right\rangle \nonumber\\
        - \frac{1}{2}\mathrm{Tr}\left([a(s,x)-\tilde{a}(s)]\left[\tilde{H}(s)-(\tilde{r}\tilde{r}^T)(s,x)\right]\right). \label{eq:G}
    \end{gather}
\end{subequations}
Here, \(\tilde{H}(s)\) is the negative Hessian of \(\log\tilde{h}(s, x)\), which turns out to be independent of \(x\), \(\tilde{a}(s)=(\tilde{\sigma}\tilde{\sigma}^T)(s)\). Under the choice of \(q(v\mid y)=\psi(v;Ly,\Sigma)\) and \(\tilde X\), \(\tilde{H}\) and \(\tilde{r}\) are given by 
\begin{subequations} \label{eq:H_r}
    \begin{align}
        \tilde{H}(t) &= L^T(t)M(t)L(t) \\
        \tilde{r}(t, x) &= L^T(t)M(t)(v-u(t) - L(t)x),
    \end{align}
\end{subequations}
where \(M(t)=(M^{\dag}(t))^{-1}\) and \(L\), \(M^\dag\) and \(u\) satisfy the backward ordinary differential equations (ODEs) (See \citet[Theorem 2.4]{mider2021continuous}):
\begin{subequations} \label{eq:backward_odes}
    \begin{align}
        \di L(t) &= -L(t)B(t)\dt, \quad L(T)=L\\
        \di M^{\dag}(t) &= -L(t)\tilde{a}(t)L^T(t)\dt,\quad M^{\dag}(T)=\Sigma\\
        \di u(t) &= -L(t)\beta(t)\dt, \quad u(T)=0.
    \end{align}
\end{subequations}

\subsection{Choice of linear process} \label{subsec:choice_of_linear_process}

The linear process is defined by the triplet of functions \((\beta, B, \tilde\sigma)\). In choosing this triplet, two considerations are of importance:
\begin{enumerate}
    \item In case of conditioning on the event \(\{LX_T=v\}\) --so no extrinsic noise on the observation-- the triplet needs to satisfy certain ``matching conditions'' to ensure \(\Pbs \ll \Pbc\). For uniformly elliptic diffusions, this only affects \(\tilde\sigma\). In case \(L=\mathbf{I}_d\), so the conditioning is on the full state, \(\tilde\sigma\) should be chosen such that \(\tilde{a}(T)=a(T,x_T)\). Hence, for this setting, we can always ensure absolute continuity. For the partially observed case, it is necessary to assume that \(a\) is of the form \(a(t,x)=s(t, Lx)\) for some matrix values map \(s\). In that case, it suffices to choose \(\tilde{a}\) such that  \(L\tilde{a}(T) L^T = L s(T,v) L^T\). In case the diffusivity does not depend on the state, a natural choice is to take \(\tilde\sigma=\sigma\) to guarantee absolute continuity.

    For hypo-elliptic diffusions, the restrictions are a bit more delicate. On top of conditions on \(\tilde\sigma\), it is also required to match certain properties in the drift by choice of \(B\). In the examples that we consider in Section \ref{sec:experiments} we have ensured these properties are satisfied. We refer to \citet{bierkens2020simulation} for precise conditions and a host of examples.  

    \item Clearly, the closer \(\tilde{b}\) to \(b\) and \(\tilde{a}\) to \(a\), the more the guided proposal resembles the true conditioned process. This can for instance be seen from \(\log \Psi_T(X)=\int_0^T \frac{(\mathcal{A}-\tilde{\mathcal{A}})\tilde{h}}{\tilde{h}}(s,X_s) \di s\), which vanishes if the coefficients are equal. 
    As proposed in \citet{mider2021continuous}, a practical approach is to compute the first-order Taylor expansion at the point one conditions on, i.e., \(\beta(t) = b(t, v), B(t)x = J_b(t, v)(x - v)\), where \(J_b\) is the Jacobian of \(b(t, x)\) with respect to \(x\). Compared to simply taking a scaled Brownian motion, this choice can result in a guided proposal that better mimics true conditioned paths. 
\end{enumerate}

\subsection{Strategies for improving upon guided proposals} 

Although the guided proposal takes the conditioning into account, its sample paths may severely deviate from true conditioned paths. This may specifically be the case for strong nonlinearity in the drift or diffusivity.  There are different ways of dealing with this.
\begin{itemize}
    \item  If we write the guided path as functional of the driving Wiener process, one can update the driving Wiener increments using the pCN within a Metropolis-Hastings algorithm. Details are provided in Appendix \ref{app:guided_proposal}, see also the discussion in \citet{mider2021continuous}. 
    \item Devising better choices for \((\beta, B, \tilde\sigma)\).
    \item Adding an extra term to the drift of the guided proposal by a change of measure, where a neural network parametrizes this term. We take this approach here and further elaborate on it in the upcoming section. 
\end{itemize}

\section{Methodology} \label{sec:methodology}

\subsection{Neural guided bridge} \label{subsec:neural_guided_bridge}
For a specific diffusion model, it may be hard to specify the maps \(B\), \(\beta\) and \(\tilde\sigma\),  which may lead to a guided proposal whose realizations look rather different from the actual conditioned paths.  For this reason, we propose to adjust the dynamics of the guided proposal by adding a learnable bounded term \(\sigma(t,x) \vartheta_\theta(t,x)\) to the drift. Specifically, let \(\vartheta_{\theta}\colon [0, T]\times\R^d\to\R^d\) be a function parameterized by \(\theta\in\Theta\), where \(\Theta\) denotes the parameter space. Assume \(x\mapsto \vartheta_\theta(t,x)\) is Lipschitz continuous, uniformly over \(t\in [0,T]\) and that \(\Pb\left(\int_0^T \|\vartheta_\theta(t,X_t)\|^2 \mathrm{d} t <\infty\right)=1\). 
Let 
\begin{equation} \label{eq:dpdiam/dpcirc}
    \kappa_T \coloneq \exp \left(\int_0^T \vartheta^{T}_\theta(t,X_t) \dW_t^\circ -\frac{1}{2}\int_0^T \|\vartheta_\theta(t,X_t)\|^2  \dt  \right),
\end{equation}
and assume \(\E [\kappa_T] = 1\). We refer to \citet[Chapter 6]{liptser2001statistics} for easily verifiable conditions on \(\vartheta_\theta\) to ensure this assumption is met. Boundedness of \(\vartheta_\theta\) for example suffices. Define a new probability measure \(\Pbd\) on \((\Omega, \mathcal{F}_T)\) by 
\begin{equation} \label{eq:Pbd_definition}
    \di \Pbd \coloneq \kappa_T \di \Pbc
\end{equation} By Girsanov's theorem,  the process \(W_t^\bullet \coloneq W^\circ_t - \int_0^t \vartheta_\theta(s,X_s) \di s\) is a \(\Pbd\)-Wiener process. Therefore, under \(\Pbd\), the process \(X\) satisfies the SDE 
\begin{gather}
    \dX_t = b^{\bullet}_{\theta}(t, X_t) \dt + \sigma(t, X_t)\dW^{\bullet}_t, \nonumber\\
    b^{\bullet}_{\theta}(s, x) = b^{\circ}(s, x) + \sigma(s, x)\vartheta_{\theta}(s, x), \quad X_0 = x_0. \label{eq:X_neural_sde}
\end{gather}
We also need Assumption \ref{asp:unique_solution} to ensure Equation \eqref{eq:X_neural_sde} has a strong solution \(X_t^{\bullet}\).
\begin{assumption} \label{asp:unique_solution} 
    There exist some constants \(C,C'>0\), such that for any \(x, y \in \R^d\),
    \begin{gather}
        \|\vartheta_{\theta}(t, x) - \vartheta_{\theta}(t, y)\| \leq C\|x - y\|, \\
        \|\vartheta_{\theta}(t, x)\|^2\leq C'(1+\|x\|^2)
    \end{gather}
\end{assumption}
We propose to construct \(\vartheta_{\theta}\) as a learnable neural network, whose goal is to approximate the difference of drift coefficients. When \(\vartheta_{\theta_{\text{opt}}} = \sigma^T(r - \tilde r)\), the discrepancy between \(\Pbd\) and \(\Pbs\) vanish. In practice, when parameterization is realized as a finite neural network, the Lipschitz continuity can be achieved by plugging in enough smooth activation functions like sigmoid or tanh, and weight normalization or gradient clipping can prevent extreme growth on \(x\). In the experiment part, we deploy tanh as activations and gradient clipping by the norm of 1.0 throughout all the experiments to fulfil such conditions. 

However, directly approaching \(\sigma^T(r-\tilde r)\) is non-trivial as \(r\) is still intractable. To address this, we use a variational approximation where the set of measures \(\{\Pbd_\theta;\, \theta \in \Theta\}\) provides a variational class for approximating \(\Pbs\). The following theorem shows that minimizing \(\theta \mapsto \kld(\Pbd_{\theta}||\Pbs)\) is equivalent to minimizing \(L(\theta)\) as defined below. 
\begin{theorem} \label{thm:optimization_object}
If we define 
\begin{equation} \label{eq:loss}
    L(\theta) \coloneq \mathbb{E}^\bullet\int_{0}^{T}\left\{\frac{1}{2}\|\vartheta_{\theta}(t, X_t)\|^2 - G(t, X_t)\right\}\dt,
\end{equation}
then
\begin{equation}
   \kld{(\Pbd_{\theta} || \Pbs)} 
    = L(\theta) + \log \frac{\tilde h(0, x_0)}{h(0, x_0)},
\end{equation}
with \(G\) as defined in Equation \eqref{eq:G}.
\end{theorem}
The proof is given in Appendix \ref{app:optimization_object_proof}. Note that under \(\Pbd\) the law of \(X\) depends on \(\theta\) and therefore the dependence of \(L\) on \(\theta\) is via both \(\vartheta_{\theta}\) and the samples from \(X\) under \(\theta\)-parameterized \(\Pbd\). We conclude that \(L\) is lower bounded by  \(-\log \frac{\tilde h(0, x_0)}{h(0, x_0)}\). Let \(\theta_{\opt}\) be a local minimizer of \(L(\theta)\), then \(\kld{(\Pbd_{\theta_{\opt}} || \Pbs)} =0\), which implies \(\Pbd_{\theta_{\opt}}=\Pbs\). \citet{heng2022simulating} applied a similar variational formulation, however, they used unconditional samples to estimate the KL divergence, which can be less efficient when conditioned on rare events.

In general \(h(0, x_0)\) cannot be evaluated. However, for simple examples, we can evaluate it and use it as a check to see that the trained neural network is optimal (see Section \ref{subsec:experiments_linear}). 

\subsection{Reparameterization and numerical implementation} \label{subsec:reparameterization}
Optimizing \(L(\theta)\) by gradient descent requires sampling from a parameterized distribution \(\Pbd_{\theta}\) and backpropagating the gradients through the sampling. To estimate the gradient, We use the reparameterization trick proposed in \citet{kingma2022auto}. Specifically, the existence of a strong solution \(X^{\bullet}\) to Equation \eqref{eq:X_neural_sde} means that there is a measurable map \(\phi_{\theta}:\mathcal{C}([0, T], \R^m)\to\mathcal{C}([0, T], \R^d)\), such that \(X^{\bullet} = \phi_{\theta}(W^{\bullet})\), with \(W^{\bullet}\) a \(\Pbd\)-Wiener process. Here, we have dropped the dependence of \(\phi_{\theta}\) on the initial condition \(x_0\) as it is fixed throughout. The objective Equation \eqref{eq:loss} can be then rewritten as: 
\begin{equation} \label{eq:reparameterized_loss}
    L(\theta) = \mathbb{E}^\bullet\int^{T}_{0}\left\{\frac{1}{2}\|\vartheta_{\theta}(t, \phi_{\theta}(W_t)\|^2 - G(t, \phi_\theta(W_t))\right\}\dt.
\end{equation}
Choose a finite discrete time grid \(\mathcal{T}\coloneq\{t_m\}_{m=0,1,\dots,M}\), with \(t_0=0, t_M=T\). Let \(X^{\bullet}_{t_m}, W^{\bullet}_{t_m}\) be the evaluations of \(X^{\bullet}, W^{\bullet}\) at \(t=t_m\) respectively, \(\{x^{\bullet(n)}_{t_m}\}, \{w^{\bullet(n)}_{t_m}\}, n=1,\dots,N\) be collections of samples of \(X^{\bullet}_{t_m}, W^{\bullet}_{t_m}\), and \(x^{\bullet(n)}_{t_0} = \phi_{\theta}(w^{\bullet(n)}_{t_0}) = x_0\). Then Equation \eqref{eq:reparameterized_loss} can be approximated as:
\begin{gather} 
    L(\theta) \approx \frac{1}{N}\sum^{N}_{n=1} \sum^{M}_{m=1}\left\{\frac{1}{2}\|\vartheta_{\theta}(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}}))\|^2 - G(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}}))\right\}\delta t. \label{eq:loss_approximation}
\end{gather}
In practice, \(x^{\bullet(n)}_{t_m}=\phi_{\theta}(w^{\bullet(n)}_{t_{m}})\) is implemented as a numerical SDE solver \(f_{\theta}(w^{\bullet(n)}_{t_{m}}, t_{m-1}, x^{\bullet(n)}_{t_{m-1}})\) that takes the previous step \((t_{m-1}, x^{\bullet(n)}_{t_{m-1}})\) as additional arguments. As \(x^{\bullet(n)}_{t_{m-1}}\) also depends on \(\theta\), the gradient with respect to \(\theta\) needs to be computed recursively. Leveraging automatic differentiation frameworks, all gradients can be efficiently recorded in an acyclic computational graph during the forward integration, enabling fast and accurate backpropagation for updating \(\theta\). While the complexity of backpropagation scales linearly with the number of solving steps \(M\)
and quadratically with the dimension of the process \(d\)—a property inherent to gradient-based optimization methods—our approach remains highly efficient for moderate-dimensional problems and provides a robust foundation for further scalability improvements. \citet{li2020scalable} proposed an alternative method to efficiently estimate the gradients called \textit{stochastic adjoint sensitivity method}. However, this approach requires the SDE to be in Stratonovich form, whereas this paper focuses on Itô diffusions and their conditioning. Although Stratonovich and Itô formulations are convertible, exploring this conversion warrants separate investigation. Further details about the gradient computation can be found in Appendix \ref{app:sde_gradients} and the numerical algorithm is shown as Algorithm \ref{alg:neurb}

\begin{algorithm} [H]
    \caption{Neural guided bridge training} \label{alg:neurb}
    \begin{algorithmic}
        \State {\bfseries Input:} Discrete time grid \(\mathcal{T}:=\{t_m\}_{m=0,1\dots,M}\), initial \(\theta\), number of iterations \(K\)
        \State Solve Equation \eqref{eq:backward_odes} on \(\mathcal{T}\) backwards, obtain \(\{\tilde{H}(t_m)\}\),\(\{\tilde{r}(t_m, \cdot)\}\) using Equation \eqref{eq:H_r}.
        \Repeat
        \For{\(n=1,\dots,N\)}
        \State Sample \(w^{\bullet(n)}=\{w^{\bullet(n)}_{t_m}\}\) on \(\mathcal{T}\).
        \State Solve Equation \eqref{eq:X_neural_sde} on \(\mathcal{T}\) with \(w^{\bullet(n)}=\{w^{\bullet(n)}_{t_m}\}\), obtain \(\{x^{\bullet(n)}_{t_m}\}\).
        \EndFor
        \State Approximate \(L(\theta\)) by Equation \eqref{eq:loss_approximation}.
        \State Backpropagate \(\nabla_{\theta}L(\theta)\) and update \(\vartheta_{\theta}\) by gradient descent.
        \Until{Iteration count \(> K\)}
    \end{algorithmic}
\end{algorithm}

\section{Experiments} \label{sec:experiments}

\subsection{Linear processes} \label{subsec:experiments_linear}
We examine one-dimensional linear processes with tractable conditional drifts, such as a Brownian bridge with constant drift and the Ornstein-Uhlenbeck process. For these simple models, the lower bound of \(L(\theta)\) can be analytically computed, providing a benchmark to verify whether the neural network achieves this bound. More details can be found in Appendix \ref{app:linear_processes}.

\textbf{Brownian bridge: } Consider a one-dimensional diffusion  with constant drift \(\gamma\) and constant diffusion coefficient \(\sigma\). As the transition density \(p(t,x_t\mid s, x_s)\) is Gaussian, the SDE for the process that is conditioned to hit \(v\) at time \(T\) is given by
\begin{equation}
    \dX^{\star}_t = \frac{v-X^{\star}_t}{T-t}\dt + \sigma\dW_t. \label{eq:brownian_bridge_sde}
\end{equation}
Suppose we construct the guided proposal using an auxiliary process $\tilde X$ with  zero drift  (i.e.\  \(\beta(t)=B(t)=0\))  and diffusion coefficient \(\tilde \sigma=\sigma\). The corresponding neural guided proposal \(X^{\bullet}\) solves the SDE
\begin{equation}
    \dX^{\bullet}_t = \left\{ \gamma + \frac{v - X^{\bullet}_t}{T-t} + \sigma\vartheta_{\theta}(t, X^{\bullet}_t)\right\}\dt + \sigma \dW_t. \label{eq:brownian_neural_bridge}
\end{equation}
By comparing \(X^{\bullet}\) with \(X^{\star}\), it is clear that the optimal map  \(\vartheta_{\theta}\) is given by the map \(\vartheta_{\theta_{\opt}}\) defined by  \(\vartheta_{\theta_{\opt}}(t,x)=-\gamma/\sigma\). Additionally, the lower bound of \(L(\theta)\), \(\log \frac{h(0, x_0)}{\tilde h(0, x_0)}\), is analytically tractable since the transition densities \(\tilde p\) of \(\tilde X\) are Gaussian. 

Suppose \(\gamma=\sigma=1.0\) and \(x_0=v=0\). Figure \ref{fig:marginal_distributions} shows the empirical marginal distributions of \(X^{\star}\) and \(X^{\bullet}\) derived from independent samples from approximations of Equation \eqref{eq:brownian_bridge_sde} and Equation \eqref{eq:brownian_neural_bridge}.  In the topleft plot of Figure \ref{fig:brownian_loss_and_error} we show how the training varies over iterations. The horizontal red line is the known lower bound on the training loss.
In the bottomleft plot, we show a heatmap of the difference between the learned neural network and \(\vartheta_{\theta_{\opt}}\). The experiment has been repeated for other values of \(\gamma\) (\(2\), \(5\) and \(10\)). 
\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/marginal_distributions.pdf}
    \caption{Comparison of marginal distributions at different time slices of the learned neural bridge and analytical true bridge. Top: Brownian bridges; Bottom: Ornstein-Uhlenbeck bridge, the pink bars show the error of each bin. The histograms are made from 1,000 independent trajectory samples individually.}
    \label{fig:marginal_distributions}
\end{figure}

We conclude that the neural net is able to learn the optimal drift and that the neural guided bridge is very close to the true bridge in terms of Kullback-Leibler divergence. 


\textbf{Ornstein-Uhlenbeck bridge: } Consider the Ornstein-Uhlenbeck (OU) process
\begin{equation} \label{eq:ou_sde}
    \dX_t = - \gamma X_t \dt + \sigma \dW_t.  
\end{equation}
Upon choosing $\tilde{X}_t = \sigma W_t$, the neural guided bridge satisfies the SDE
\begin{equation} \label{eq:ou_neural_bridge_sde}
    \dX^{\bullet}_t = \left\{ -\gamma X^{\bullet}_t + \frac{v - X^{\bullet}_t}{T-t} + \sigma\vartheta_{\theta}(t, X^{\bullet}_t)\right\}\dt + \sigma \dW_t.
\end{equation}
In Appendix \ref{app:linear_processes} we derive the optimal map  \(\vartheta_{\theta_{\opt}}\) and lower bound on \(L\). With SDE parameters set as \(x_0=v=0\), \(\sigma=1.0\), we repeat the experiments of evaluating training loss curves and outputs of the learned neural network, as were done for the Brownian bridge and show the results in Figure \ref{fig:ou_loss_and_error}.

A comparison of the results from Brownian and OU bridges reveals significant fluctuations in the training loss curves, particularly pronounced in the OU bridges. These fluctuations arise from the Monte Carlo approximation of the expectation and the numerical discretization of the integral in the training loss. The Monte Carlo approximation is implemented by computing the empirical mean over \(N\) Wiener sample paths, while the integral is discretized on a finite grid \(\mathcal{T}\) using left-point Riemann sums. The sampling introduces noise into the optimization, resulting in strong fluctuations. The discretization may cause bias in attaining the lower bound.  In the OU case, \(\vartheta_{\theta}\) exhibits a more complex form compared to the Brownian case, necessitating a finer grid and a larger number of Monte Carlo samples. 

Despite the fluctuations observed during the training of the neural bridge, its validity under appropriate conditions is confirmed by quantitative evaluations in linear process experiments. For experiments lacking analytical references, performance is assessed qualitatively

\subsection{Cell diffusion model}
\citet{wang2011quantifying} introduced a model for cell differentiation which serves as a test case for diffusion bridge simulation in \citet{heng2022simulating,baker2024score}. Cellular expression levels \(X_{t} = (X_{t,1}, X_{t,2})\) are governed by the  2-dimensional SDE
\begin{equation} \label{eq:cell_sde}
    \mathrm{d}X_t = 
    \begin{bmatrix}
        \frac{X_{t, 1}^4}{2^{-4} + X_{t, 1}^4} + \frac{2^{-4}}{2^{-4} + X_{t, 2}^4} - X_{t, 1} \\
        \frac{X_{t, 2}^4}{2^{-4} + X_{t, 2}^4} + \frac{2^{-4}}{2^{-4} + X_{t, 1}^4} - X_{t, 2}
    \end{bmatrix} \dt + \sigma\dW_t,
\end{equation}
driven by a 2-dimensional Wiener process \(W\). The highly nonlinear drift makes this a challenging case. The guided neural bridge is constructed by taking the auxiliary process that drops the nonlinearities in the drift. More precisely, 
\begin{equation} \label{eq:cell_auxiliary_sde}
    \di\tilde X_t = - \tilde{X}_t\dt + \sigma \dW_t.
\end{equation}
 We study three representative cases that result in distinct dynamics for the conditional processes: (1) events that are likely under the forward process, which we refer to as ``normal'' events; (2) rare events; and (3) events that cause trajectories to exhibit multiple modes, where the marginal probability at certain times is multimodal. We compare our method to  (a) the \textit{guided proposal} \citep{schauer2017guided}; (b) \textit{bridge simulation via score matching} \citep{heng2022simulating}; and (c) \textit{bridge simulation using adjoint processes} \citep{baker2024score}. 
Details of the experiments are presented in Appendix \ref{app:cell_process}.

\textbf{Normal event:} We set \(x_0=[0.1, -0.1]^T\) and \(v=[2.0, 0.1]^T\). From multiple forward simulations, it can be assessed that balls around $v$ get non-negligible mass. We take \(T=4.0\) and \(\sigma = 0.1\). In Figure \ref{fig:cell_normal}, we show 30 conditional sample paths obtained by the three baseline methods mentioned above and the trained neural bridge. Since the true conditional process is analytically intractable, we sample 100,000 times from the forward (unconditional) process Equation \eqref{eq:cell_sde} and retain samples that satisfy \(\|LX_T-v\|\leq 0.01\). The obtained samples can be treated as a reference template for the true conditioned dynamics. Overall, all four methods successfully recover the truth dynamics. The performance of all four methods considered is comparable. We only note that the adjoint bridge sample paths appear slightly more dispersed. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/normal_events_results.pdf}
    \caption{Visualization of 30 simulated bridges when conditioning on normal events using different methods. Note that except for the guided proposal, all the samples are independently drawn. The underlying grey trajectories presented in the figure are the unconditional samples by forward solving \(X\) without conditioning and filtered by \(\|LX_T - v\| < 0.01\) as the reference of the true dynamics.}
    \label{fig:cell_normal}
\end{figure}

\textbf{Rare event:} We set \(x_0=[0.1, -0.1]^T\), \(v=[1.0, -0.1]^T\), which is a rare event for \(X\) to hit. In this experiment, we set \(\sigma=0.1\). Unlike the normal event case, the true dynamics cannot be recovered by brute-force sampling from the unconditioned process, as it is highly improbable that paths end up in a small ball around  \(v\). We display 30  conditional paths each generated by the four methods considered in Figure \ref{fig:cell_rare}. Visual similarity can be observed between the neural guided bridge and the guided proposal,  while the adjoint bridge cannot effectively model reasonable dynamics, as also reported in \citet{baker2024score}. Score matching performs worst in this setting, which is expected because the score is learned from unconditional samples which as time $T$ tend to be far from $v$. This scarcity leads to poor estimation in those areas, resulting in significant deviations in the initial stages.
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/rare_events_results.pdf}
    \caption{Visualization of 30 simulated bridges when conditioning on rare events using different methods. Note that except for the guided proposal, all the samples are independently drawn. No reference trajectory is available when conditioned on rare events.}
    \label{fig:cell_rare}
\end{figure}

\textbf{Multi-modality:} In both of the previous cases, each component's marginal distribution at times \((0,T]\) is unimodal. However, with some special initial conditions, multimodality can arise, which poses a challenging task where one would like to recover all modes. Specifically, let  \(x_0=[-1.0, -1.0]^T\), \(v=[-1.0, -1.0]^T\), \(T=5.0\) and \(\sigma=0.1\). Figure \ref{fig:cell_mm} compares the performance of the different methods. Both the adjoint bridge and score matching fail to model the dynamics accurately. The neural guided bridge and the guided proposal have comparable performance, as they both can only cover part of the modes. Moreover, when running pCN for a single chain, sometimes iterates of samples get stuck at a single mode. To address this, multiple chains must be run, which may become computationally expensive. In contrast, once the neural bridge is trained, new samples can be immediately generated by sampling paths from the learned SDE, at a cost comparable to unconditional forward simulation, while still covering the majority of modes.
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/multimodality_events_results.pdf}
    \caption{Visualization of 30 simulated bridges when conditioning on events that will cause multi-modality using different methods. Note that except for the guided proposal, all the samples are independently drawn. No reference trajectory is available when conditioned on multi-modality events.}
    \label{fig:cell_mm}
\end{figure}

 Among all three tasks, our method demonstrates strong flexibility and adaptability, while the alternative methods show limitations when applied to specific tasks. 

\subsection{FitzHugh-Nagumo model}
We consider a FitzHugh-Nagumo model, which is a prototype of an excitable system, considered for example in \citet{ditlevsen2019hypoelliptic, bierkens2020simulation}. It is described by the SDE
\begin{equation} \label{eq:fhn_sde}
    \mathrm{d}X_t = \left\{
    \begin{bmatrix}
        \frac{1}{\chi} & -\frac{1}{\chi} \\
        \gamma & -1
    \end{bmatrix}X_t + 
    \begin{bmatrix}
        \frac{s-X^3_{t,1}}{\chi} \\
        \alpha
    \end{bmatrix}
    \right\} \mathrm{d}t +
    \begin{bmatrix}
        0 \\
        \sigma
    \end{bmatrix} \mathrm{d}W_t
\end{equation}
We condition the process by the value of its first component by setting \(L=\begin{bmatrix}1 & 0\end{bmatrix}\) and hence condition on the event  \(LX_T = v \). We construct the guided proposal just as proposed in \citet{bierkens2020simulation} using the Taylor expansion \(-x^3\approx 2v^3 - 3v^2x\) at \(x=v\). Accordingly, we choose \(\tilde X\) 
\begin{equation}
    \mathrm{d}\tilde{X}_t = \left\{
    \begin{bmatrix}
        \frac{1-3v^3}{\chi} & -\frac{1}{\chi} \\
        \gamma & -1
    \end{bmatrix}\tilde X_t + 
    \begin{bmatrix}
        \frac{2 v^3 + s}{\chi}\\
        \alpha
    \end{bmatrix}
    \right\} \mathrm{d}t +
    \begin{bmatrix}
        0 \\
        \sigma
    \end{bmatrix}\dW_t
\end{equation}
Suppose  \([\chi, s, \gamma, \alpha, \sigma] = [0.1, 0, 1.5, 0.8, 0.3]\). We examine the conditional behaviour of \(X\) within \(t\in[0, 2.0]\) under two scenarios: (1) conditioning on a normal event \(v = [-1.0]\); and (2) conditioning on a rare event \(v = [1.1]\). As the score-matching and adjoint-process methods have not been proposed in the setting of a partially observed state, we only compare our method to the guided proposal. The results are shown in Figure \ref{fig:fhn_normal} and Figure \ref{fig:fhn_rare} respectively.

\textbf{Normal event: }Both the neural guided bridge and the guided proposal recover most patterns of the true process as shown in Figure \ref{fig:fhn_normal}. However, the neural guided bridge performs slightly better in capturing a broader spanning region of \(X_{t,2}\) for \(t \in (0.5, 1.5)\). Additionally, \(X_{t,1}\) generated by the neural guided bridge exhibits better visual consistency with the reference compared to the guided proposal. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/normal_results.pdf}
    \caption{Visualization of FHN model conditioned on a normal event using 30 samples each either by drawing independently from the neural guided bridge or subsampling from the guided proposal updating history, the reference is obtained by directly sampling original Equation \eqref{eq:fhn_sde}, and filtered by the condition \(\|LX_T - v\|\leq 0.01\).}
    \label{fig:fhn_normal}
\end{figure}

\textbf{Rare event: }  The conditioning process introduces multimodality into the bridge, causing both methods to occasionally sample from only a single mode, as anticipated based on the previous example.

The left-hand panel of Figure \ref{fig:fhn_rare} shows ``true'' conditioned paths obtained by forward sampling and keeping that paths that satisfy a relaxed version of the conditioning. Clearly, the bridge process is bimodal. The neural guided bridge samples paths from only one of the two modes, though the sampled paths appear very similar to the actual conditioned paths. The guided proposal samples paths inbetween the two modes as well, which are not seen in the reference panel. These observations suggest that both methods struggle to recover the 2 modes. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/extreme_results.pdf}
    \caption{Visualization of FHN model conditioned on a rare event using 30 samples each either by drawing independently from the neural guided bridge or subsampling from the guided proposal updating history, the reference is obtained by directly sampling original Equation \eqref{eq:fhn_sde}, and filtered by the condition \(\|LX_T - v\|\leq 0.01\).}
    \label{fig:fhn_rare}
\end{figure}

\subsection{Stochastic landmark matching}
At last, we consider a relatively high-dimensional stochastic nonlinear conditioning task: stochastic landmark matching, mainly specified in \citep{arnaudon2022diffusion}, where a geometric shape is discretized and represented as \(X_t=\{X^{(i)}_t\}_{i=1,\dots,n}\subset\R^{nd}\) a finite set of \(n\) distinct \textit{landmarks} \(X^{(i)}_t\in D\subseteq\R^d\) and \(d=\{2,3\}\) generally indicates a 2 or 3-dimensional shape. The stochastic landmark model defined in \citep{arnaudon2022diffusion} without momentum (i.e., only the coordinate variable dynamics) is defined by an SDE with a set of \(n\) \(d\)-dimensional Wiener processes \(W_t = \{W_t^{(j)}\}_{j=1,\dots,n}\in\R^{nd}\):
\begin{equation} \label{eq:landmark_sde}
    \dX_t = Q(X_t)\dW_t, \quad Q(X_t)_{ij}\coloneq k(X_t^{(i)},X_t^{(j)}).
\end{equation}
\(k\) is a kernel function \(\R^d\times\R^d\to\R\). We choose a Gaussian kernel \(k(x,y)=\alpha\exp\left(-\frac{\|x-y\|^2}{2\kappa^2}\right)\). Note that the diffusion coefficient \(Q\) is state-dependent, which is necessary for maintaining the structure of the shape during the evolution. Figure \ref{fig:landmark_comparsion} shows an intuitive comparison between using a linear process and Equation \eqref{eq:landmark_sde} to model the stochastic evolutions of the same shape. In modelling real-world stochastic shapes like medical anatomical markers or biological species outlines, such a structure-preserving property of Equation \ref{eq:landmark_sde} is preferred. 

We choose 
\begin{equation} \label{eq:landmark_auxiliary_sde}
    \di \tilde{X}_t=Q(X_T)\dW_t.
\end{equation}
That is, we only evaluate the diffusion coefficient at the endpoint and keep it constant throughout the process. We choose one ellipse as the starting point and another ellipse as the endpoint of the bridge. Each ellipse is discretized as 50 landmarks, leading to the dimension of \(X_t\) being 100. The kernel parameters are chosen to be  \(\alpha=0.3, \kappa=0.5\) to ensure a strong correlation between a wide range of landmarks. Let \(T=1.0\). Figure \ref{fig:landmark_neural_bridge} and Figure \ref{fig:landmark_pcn} show 4 samples of the learned neural guided bridge and the guided proposal. Both methods capture the correct dynamics and approach the target shape. Despite the visual comparison, there is no quantitative way of comparing the performance of the two methods as the true bridge is anyway intractable. However, we note that for such a high-dimensional problem, using the Metropolis-Hasting method to sample from the guided proposal is much slower than numerical solving the trained neural guided bridge, since the latter only requires a single forward solving, while the former requires computationally expensive MCMC update steps, especially when the dimension of the problem is high. In this case, training a neural bridge once and subsequently generating independent samples may be preferable. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/ellipse_neural_bridge_samples.pdf}
    \caption{Four independent samples of the stochastic bridges between two ellipses obtained by solving the learned neural diffusion bridge. The target ellipse is marked in yellow, and the colour of the trajectories indicates time.}
    \label{fig:landmark_neural_bridge}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/ellipse_pcn_samples.pdf}
    \caption{Four samples of the stochastic bridges between two ellipses obtained by subsampling from the guided proposal updating history. The target ellipse is marked in yellow, and the colour of the trajectories indicates time.}
    \label{fig:landmark_pcn}
\end{figure}

\section{Conclusions and limitations}

We propose the neural guided diffusion bridge, a novel method for simulating diffusion bridges that enhances guided proposals through variational inference, eliminating the need for MCMC or SMC. This approach enables efficient independent sampling with comparable quality in challenging tasks where existing score-learning-based methods struggle. Extensive experiments, including both quantitative and qualitative evaluations, validate the effectiveness of our method. However, as the framework is formulated variationally and optimized by minimizing \(\kld{(\Pbd_{\theta} || \Pbs)}\), it exhibits mode-seeking behaviour, potentially limiting its ability to explore all modes compared to running multiple MCMC chains. Despite this limitation, our method provides a computationally efficient alternative to guided proposals, particularly in generating independent conditioned samples.

Our approach focuses on better approximating the drift of the conditioned process while keeping the guiding term that ensures the process hits \(v\) at time \(T\) relatively simple. In future work, one could try to jointly learn \(\vartheta_\theta\) and \(B\) using variational inference. Another venue of future research can be to extend our approach to conditioning on partial observations at multiple future times. 

\section*{Acknowledgements}
The work presented in this paper was supported by the Villum Foundation Grant 40582, and the Novo Nordisk Foundation grant NNF18OC0052000.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{bibfile}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix

\section{Theoretical details}

\subsection{Preconditioned Crank-Nicolson} \label{app:guided_proposal}
A more general version of using pCN to sample \(X^{\star}\) is illustrated in \citet[Section 4]{mider2021continuous}, where multiples states can be observed at times \(0=t_0<t_1<\dots<t_n\), while in our case, we suppose only the endpoint state is observed, leading to a simpler version of \citet[Algorithm 4.1]{mider2021continuous}, as Algorithm \ref{alg:pcn}.

\begin{algorithm}[H]
    \caption{Preconditioned Crank-Nicolson} \label{alg:pcn}
    \begin{algorithmic}[1]
        \State {\bfseries Input:} Discrete time grid \(\mathcal{T}:=\{t_{m}\}_{m=0,1,\dots,M}\), tuning parameter \(\eta\in[0, 1)\), number of required samples \(K\)
        \State Solve Equation \eqref{eq:backward_odes} on \(\mathcal{T}\), obtain \(\{\tilde H(t_{m})\}, \{\tilde r(t_m,\cdot)\}\) using Equation \eqref{eq:H_r}.
        \State Sample \(w = \{w_{t_m}\}\) on \(\mathcal{T}\).
        \State Solve Equation \eqref{eq:X_guided_sde} on \(\mathcal{T}\) with \(w = \{w_{t_m}\}\), obtain \(y=\{y_{t_m}\}\).
        \Repeat
        \State Sample new innovations \(z = \{z_{t_m}\}\) on \(\mathcal{T}\) independently. 
        \State Set \(w^{\circ} = \eta w + \sqrt{1 - \eta^2} z\).
        \State Solve Equation \eqref{eq:X_guided_sde} on \(\mathcal{T}\) with \(z = \{z_{t_m}\}\), obtain \(y^{\circ}=\{y^{\circ}_{t_m}\}\).
        \State Compute \(A = \Psi(y^{\circ})/\Psi(y)\) with \(\{y^{\circ}_{t_m}\}|\) and \(\{y_{t_m}\}\) using Equation \eqref{eq:Psi}.
        \State Draw \(U\sim\mathcal{U}(0, 1)\).
        \If{\(U<A\)}
        \State \(y \gets y^{\circ}\) and \(w \gets w^\circ\)
        \State Save \(y\).
        \EndIf
        \Until{Sample counts \(> K\).}
    \end{algorithmic}
\end{algorithm}

\subsection{Proof of Theorem \texorpdfstring{\ref{thm:optimization_object}}{Proof of Theorem}} \label{app:optimization_object_proof}
\begin{proof}
    Consider the KL divergence between \(\Pbd_{\theta}\) and \(\Pbs\):
    \begin{subequations}
        \begin{align}
            \mathrm{D}_{\text{KL}}{(\Pbd_{\theta}||\Pbs)} 
            &= \mathbb{E}^\bullet\left[\log\left(\frac{\mathrm{d}\Lbd_{\theta}}{\mathrm{d}\Lbs}\right)(X)\right]\nonumber \\
            &= \mathbb{E}^\bullet\left[\log\left(\frac{\mathrm{d}\Lbd_{\theta}}{\mathrm{d}\Lbc} \cdot \frac{\mathrm{d}\Lbc}{\mathrm{d}\Lbs}\right)(X)\right]\nonumber \\
            &= \mathbb{E}^\bullet\left[\log\left(\frac{\mathrm{d}\Lbd_{\theta}}{\mathrm{d}\Lbc}(X)\right)\right] - \mathbb{E}^\bullet\left[\log\left(\frac{\mathrm{d}\Lbs}{\mathrm{d}\Lbc}(X)\right)\right].\label{eq:dederde_1}
        \end{align}
    \end{subequations}
    By Girsanov's theorem, 
    \begin{subequations}
        \begin{align}
            \mathbb{E}^\bullet\left[\log\left(\frac{\mathrm{d}\Lbd_{\theta}}{\mathrm{d}\Lbc}(X)\right)\right] &= \mathbb{E}^\bullet\left[\log\frac{\mathrm{d}\Pbd_{\theta}}{\mathrm{d}\Pbc}\right] \\
            &= \mathbb{E}^\bullet\left[\int_{0}^{T}\vartheta_{\theta}(t, X_t)\dW^\circ_t - \frac{1}{2}\int_{0}^{T}\|\vartheta_{\theta}(t, X_t)\|^2\dt\right] \nonumber \\
            &= \mathbb{E}^\bullet\left[\int_{0}^{T}\vartheta_{\theta}(t, X_t)\dW_t^\bullet  + \frac{1}{2}\int_{0}^{T}\|\vartheta_{\theta}(t, X_t)\|^2\dt\right] \nonumber \\
            &= \mathbb{E}^\bullet\left[\frac{1}{2}\int_{0}^{T}\|\vartheta_{\theta}(t, X_t)\|^2\dt\right],\label{eq:dederde}
        \end{align}
    \end{subequations}
    where the stochastic integral vanishes because of the martingale property of the Itô integral. The first equality follows from Equation \eqref{eq:Pbd_definition}. By Equation \eqref{eq:llr}
    \begin{equation}\label{eq:guidproc_term}
        \mathbb{E}^\bullet \left[\log\left(\frac{\mathrm{d}\Lbs}{\mathrm{d}\Lbc}(X)\right) \right] = \mathbb{E}^\bullet\left[\int_{0}^{T}G(t, X_t)\dt\right]+\log \frac{\tilde{h}(0, x_0)}{h(0, x_0)}.
    \end{equation}
    Substituting Equation \eqref{eq:dederde} and Equation \eqref{eq:guidproc_term} into Equation \eqref{eq:dederde_1} gives 
    \begin{equation}
        \mathrm{D}_{\text{KL}}{(\Pbd_{\theta} || \Pbs)} 
        = \mathbb{E}^\bullet \int_{0}^{T}\left\{\frac{1}{2}\|\vartheta_{\theta}(t, X_t)\|^2 - G(t, X_t)\right\} \dt + \log \frac{\tilde h(0, x_0)}{h(0, x_0)} = L(\theta) +  \log \frac{\tilde h(0, x_0)}{h(0, x_0)} \geq 0,
    \end{equation}
    as \(L(\theta)\) defined as Equation \eqref{eq:loss}.
\end{proof}

\subsection{SDE gradients} \label{app:sde_gradients}
We now derive the gradient of Equation \eqref{eq:loss_approximation} with respect to \(\theta\), on a fixed Wiener realization \(w^{\bullet(n)}=\{w^{\bullet(n)}_{t_m}\}\). As discussed, \(x^{\bullet(n)}_{t_m}=\phi_{\theta}(w^{\bullet(n)}_{t_{m}})\) is implemented as a numerical SDE solver \(f_{\theta}(w^{\bullet(n)}_{t_{m}}, t_{m-1}, x^{\bullet(n)}_{t_{m-1}}), m\geq 1\) that takes the previous step \((t_{m-1}, x^{\bullet(n)}_{t_{m-1}})\) as additional arguments. As \(x^{\bullet(n)}_{t_{m-1}}\) also depends on \(\theta\), the gradient with respect to \(\theta\) needs to be computed recursively. Specifically, with \(x^{\bullet(n)}_{t_m}=f_{\theta,m} = f_{\theta}(w^{\bullet(n)}_{t_{m}}, t_{m-1}, x^{\bullet(n)}_{t_{m-1}})\)
\begin{subequations}
    \begin{align}
        &\nabla_{\theta}\left(\frac{1}{2}\|\vartheta_{\theta}(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}})\|^2_2\right) = \nabla_{\theta}\left(\frac{1}{2}\|\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1})\|^2_2\right) \\
        &= [\nabla_{\theta}\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1}))]^{T}\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1}) \\
        &= \left[\frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial \theta} + \frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial f_{\theta, m-1}}\cdot \nabla_{\theta} f_{\theta, m-1}\right]^T\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1}) \\
        &= \left[\frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial \theta} + \frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial f_{\theta, m-1}}\cdot\left(\frac{\partial f_{\theta, m-1}}{\partial \theta} + \frac{\partial f_{\theta, m-1}}{\partial f_{\theta, m-2}}\cdot\nabla_{\theta} f_{\theta, m-2}\right)\right]^T\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1}) \\ 
        &= \left[\frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial \theta} + \frac{\partial \vartheta_{\theta}(t_{m-1}, f_{\theta, m-1})}{\partial f_{\theta, m-1}}\cdot\left(\frac{\partial f_{\theta, m-1}}{\partial \theta} + \sum^{m-2}_{i=1}\left(\prod^{m-1}_{j=i+1}\frac{\partial f_{\theta, j}}{\partial f_{\theta, j-1}}{}\right)\frac{\partial f_{\theta, i}}{\partial \theta}\right)\right]^T\vartheta_{\theta}(t_{m-1}, f_{\theta,m-1}),
    \end{align}
\end{subequations}
Similiarly, the gradient of \(G\) with respect to \(\theta\) can also be computed recusively:
\begin{equation}
    \nabla_{\theta} G(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}})) =  \frac{\partial G(t_{m-1}, f_{\theta, m-1})}{\partial f_{\theta, m-1}}\cdot\left(\frac{\partial f_{\theta, m-1}}{\partial \theta} + \sum^{m-2}_{i=1}\left(\prod^{m-1}_{j=i+1}\frac{\partial f_{\theta, j}}{\partial f_{\theta, j-1}}\right)\frac{\partial f_{\theta, i}}{\partial \theta}\right).
\end{equation}
The gradient of \(L(\theta)\) can be approximated by:
\begin{equation}
    \nabla_{\theta}L(\theta) \approx \frac{1}{N}\sum^{N}_{n=1} \sum^{M}_{m=1}\left\{\nabla_{\theta}\left(\frac{1}{2}\|\vartheta_{\theta}(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}}))\|^2_2\right) - \nabla_{\theta}G(t_{m-1}, \phi_{\theta}(w^{\bullet(n)}_{t_{m-1}}))\right\}\delta t.
\end{equation}
The realization of \(f_{\theta}\) depends on the chosen numerical integrator. We choose Euler-Maruyama as the integrator used for all the experiments conducted in Section \ref{sec:experiments}. Under this scheme, \(f_{\theta}\) is:
\begin{equation}
    f_{\theta}(w^{\bullet(n)}_{t_{m}}, t_{m-1}, x^{\bullet(n)}_{t_{m-1}}) = x^{\bullet(n)}_{t_{m-1}} + (b + a\tilde r + \sigma \vartheta_{\theta})(t_{m-1}, x^{\bullet(n)}_{t_{m-1}}) + \sigma(t_{m-1}, x^{\bullet(n)}_{t_{m-1}})w^{\bullet(n)}_{t_{m}},
\end{equation}
with \(w^{\bullet(n)}_{t_{m}}\sim\mathcal{N}(0, (t_{m}-t_{m-1})\mathbf{I}_d)\). The derivatives can be computed accordingly:
\begin{subequations}
\begin{align}
    \frac{\partial f_{\theta, m}}{\partial \theta} &= \sigma(t_{m-1}, x^{\bullet(n)}_{t_{m-1}})\frac{\partial \vartheta_{\theta}(t_{m-1}, x^{\bullet(n)}_{t_{m-1}})}{\partial \theta} \label{eq:df_dtheta}\\
    \frac{\partial f_{\theta, m}}{\partial f_{\theta, m-1}} &= 1 + \frac{\partial(b+a\tilde r + \sigma \vartheta_{\theta})}{\partial x^{\bullet(n)}_{t_{m-1}}}(t_{m-1}, x^{\bullet(n)}_{t_{m-1}}) + \frac{\partial \sigma}{\partial x^{\bullet(n)}_{t_{m-1}}}(t_{m-1}, x^{\bullet(n)}_{t_{m-1}})w^{\bullet(n)}_{t_{m}}. \label{eq:df_dfprev}
\end{align}
\end{subequations}
The automatic differentiation can save all the intermediate Equation \eqref{eq:df_dtheta} and Equation \eqref{eq:df_dfprev}, which enables to compute \(\nabla_{\theta}L(\theta)\).

\section{Experiment details} \label{app:experiments}

\subsection{Code implementation}\
The codebase for reproducing all the experiments conducted in the paper is available in \url{https://github.com/bookdiver/neuralbridge}

\subsection{Linear processes} \label{app:linear_processes}

\textbf{Brownian bridges: } When no noise is in observations, \(h(0, x_0) = \mathcal{N}(y;x-\gamma T, \sigma^2 T)\), \(\tilde h(0, x_0) = \mathcal{N}(y;x, \sigma^2 T)\), therefore, the lower bound of \(L(\theta)\), \(-\log\frac{\tilde h(0, x_0)}{h(0, x_0)}=(\|y-x_0-\gamma T\|^2 - \|y-x_0\|^2)/(2\sigma^2T)\). In practice, we set \(\epsilon=10^{-10}\), \(\vartheta_{\theta}(t, x)\) is modelled as a fully-connected neural network with 3 hidden layers and 20 hidden dimensions for each layer. The model is trained with 60,000 independently sampled full trajectories of \(X^{\bullet}_t\). The batch size \(N=20\), time step size \(\delta t = 0.005\), therefore in total \(M=200\) time steps. The network is trained with Adam \citep{kingma2017adam} optimizer with an initial learning rate of \(1.0e^{-3}\) and a cosine decay scheduler, and a linear learning rate warming up in the first 0.1 ratio of training iterations.
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/brownian_loss_and_error.pdf}
    \caption{Results of Brownian bridges under different \(\gamma\). Top row: the training loss log, the red dashed line represents the lower bound of \(L(\theta)\).}
    \label{fig:brownian_loss_and_error}
\end{figure}

\textbf{Ornstein-Uhlenbeck bridge: } When conditioning Equation \eqref{eq:ou_sde} on \(\{LX_T=v\}\), the conditioned process \(X^{\star}\) reads:
\begin{equation} \label{eq:ou_bridge_sde}
    \dX^{\star}_t = - \gamma\left( \frac{v}{\operatorname{sinh}(-\gamma(T-t))} - \frac{x}{\operatorname{tanh}(-\gamma(T-t))}\right) \dt + \sigma \dW_t,
\end{equation}
which is obtained from the fact that
\begin{equation}
    p(T, y\mid t, x) = \sqrt{\frac{\gamma}{\pi\sigma^2(1-\exp(-2\gamma(T-t))}}\exp\left\{-\frac{\gamma}{\sigma^2}\cdot\frac{(y-x\exp(-\gamma(T-t))^2}{1-\exp(-2\gamma(T-t))}\right\}.
\end{equation}
Therefore, one can immediately see the optimal value of \(\vartheta_{\theta}(t, x)\) to be
\begin{equation}
    \vartheta_{\theta_{\opt}}(t, x) = \frac{1}{\sigma}\left\{-\gamma\left[\frac{v}{\sinh(-\gamma(T-t))} - \frac{x}{\tanh(-\gamma(T-t))}\right] - \frac{v-x}{T-t} + \gamma\cdot x\right\},
\end{equation}
and the lower bound of \(L(\theta)\) to be:
\begin{equation}
    -\log\frac{\tilde h(0, x_0)}{h(0, x_0)} = \frac{1}{2}\left\{\log\left(\frac{\gamma}{\pi\sigma^2(1-e^{-2\gamma T})}\right) - \frac{\gamma(y-x_0e^{-\gamma T})^2}{\sigma^2(1-e^{-2\gamma T})} -\log\left(\frac{1}{2\pi\sigma^2T}\right) + \frac{(y-x_0)^2}{\sigma^2T}\right\}.
\end{equation}
These analytical results enable a quantitative evaluation of the performance of learned \(X^{\bullet}\). The training setups are duplicated from the previous Brownian bridges, except for a deeper neural network architecture with 4 hidden layers and 20 hidden units in each layer.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/ou_loss_and_error.pdf}
    \caption{Results of Ornstein-Uhlenbeck bridges under different \(\gamma\). Top row: the training loss log, the red dashed line represents the lower bound of \(L(\theta)\).}
    \label{fig:ou_loss_and_error}
\end{figure}

\subsection{Cell diffusion process} \label{app:cell_process}
For the benchmark tests, we adapt the published implementations of the corresponding methods to fit into our test framework with possibly minor modifications. Specifically, the original guided proposal codebase is implemented with Julia in \footnote{\url{https://juliapackages.com/p/bridge}}, we rewrite it in JAX \citep{jax2018github}; the score matching bridge repository is published in \footnote{\url{https://github.com/jeremyhengjm/DiffusionBridge}}, which is written with PyTorch \citep{paszke2019pytorch}, we also adapt it into JAX for convenience, additionally, as also reported by the authors, \citet{heng2022simulating} introduces two score-matching-based bridge simulation schemes, reversed and forward simulation, and the forward simulation relies on the reversed simulation, and learning from approximated reversed bridge can magnifies the errors due to progressive accumulation. Therefore, we only compare our method with the reversed bridge learning to avoid error accumulations; the adjoint bridge is implemented in \footnote{\url{https://github.com/libbylbaker/forward_bridge}}, already in JAX, so we directly use the existing implementation without modification.

\textbf{Normal event: } We still consider a no-observation-noise case by setting \(\epsilon=10^{-10}\), \(\vartheta_{\theta}\) is modelled as a fully-connected network with 4 hidden layers and 32 hidden dimensions per layer, activated by tanh. We train the model with 100,000 independent samples of \(X^{\bullet}\) by a Adam optimizor with initial learning rate of \(5e^{-4}\), batch size \(N=20\), time step \(\delta t = 0.01\), therefore, in total \(M=400\) time steps. For the guided proposal, we set \(\eta=0.98\), and run one chain of MCMC for 10,000 updates, obtaining \(22.69\%\) acceptance rate. The burn-in period is set as the first 4,000 steps. After burn-in, we subsample the updating history by taking every 200-th sample, therefore selecting out 30 samples. In the following experiments, if not explicitly stated, all the samples from the guided proposal are similarly obtained from one chain of MCMC by taking proper thinning ratios. For the score matching, we find the original neural network architecture in the repository performs poorly in our case, so we refer to the architecture used in \citet{baker2024conditioning}, with 4 hidden layers and 32 hidden dimensions per layer, combining with the sinusoidal embedding \citep{vaswani2017attention} for the temporal dependency. For the adjoint bridge, we directly deploy the original architecture used in \citet{baker2024score}. To obtain the reference dynamics, we generate 100,000 independent samples of \(X\), then filter these by the condition \(\|LX_T-v\|\leq 0.01\), obtaining 151 valid samples, and only the first 30 samples are shown in grey.

\textbf{Rare event: }The setups for conditioning on rare events of the neural guided bridge are replicated from the previous normal event case, except for the MCMC is running with sightly increased tuning parameter \(\eta=0.99\) and obtains an acceptance rate of \(24.50\%\). For the score matching bridge, since we only use the reversed bridge, whose learning is independent of the endpoints, we directly deploy the trained score approximation from the previous case; For the adjoint process, we fix the neural network architecture and training scheme, changing only the conditions. To obtain the reference, we repeat the same procedure of sampling 100,000 independent trajectories and filtering by the condition, however, we find none of the samples matches the condition we put, which reflects that \(v=[1.0, -0.1]^T\) is indeed a probably rare event and becomes challenging.

\textbf{Multi-modality: } All the neural network architectures and training schemes are the same as in previous examples. \(\delta t=0.01\) and \(M=500\) therefore. For the guided proposal, we run one chain for 10,000 iterations with \(\eta=0.9\), obtaining \(24.93\%\) acceptance rate. Similarly to the rare event case, no valid samples can be found through 100,000 brute-forced samples of the original process. Figure \ref{fig:cell_mm_marginal} shows marginal distributions of the original and conditioned processes, where more than one peak of marginal distribution density can be observed at time \(t=3.0, 4.0\). Neither the neural guided process nor the guided proposal can recover all three modes which are indicated by the original process. However, one can always run multiple independent chains to cover all the modes, as suggested in Figure \ref{fig:cell_mm_mcmc_multiple_chains}. Compared to the guided proposal, even though the neural bridge can not recover all the modes, it trades with fast sample speed. Also, additional MCMC updates can be further executed on trained neural bridges to obtain high-quality samples.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/multimodality_histogram.pdf}
    \caption{Comparison of marginal distributions at different time slices of the original process, guided proposal and learned neural bridge. The histograms are made from 1,000 samples individually either drawn independently from the neural guided bridge and original process or subsampled from the guided proposal updating history. Top row: the first component of \(X\); Bottom row: the second component of \(X\).}
    \label{fig:cell_mm_marginal}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/multimodality_mcmc_multiple_chains_histograms.pdf}
    \caption{Marginal distributions of two independent MCMC chains, where they compensate each other and cover all three modes.}
    \label{fig:cell_mm_mcmc_multiple_chains}
\end{figure}

\subsection{FitzHugh-Nagumo model} \label{app:fhn_model}
\textbf{Normal event: }We set \(\delta t = 0.005\), which leads to \(N=400\) time steps. The observation noise variance is \(\epsilon=1e-4\) to ensure a stable backward filtering ODE solution. For the neural guided bridge, \(\vartheta_{\theta}(t, x)\) is constructed as a fully connected neural network with 4 hidden layers and 32 hidden dimensions at each layer, activated by tanh functions. The training is done with 225,000 independent samples from \(X^{\bullet}_t\), batch size \(M=30\), optimized by Adam with an initial learning rate of \(5e-4\) and a cosine decay scheduler. For the guided proposal, we set \(\eta=0\) as suggested in \citet{bierkens2020simulation} and run one chain for 50,000 iterations with a burn-in of 20,000 steps, obtaining \(61.15\%\) acceptance rate. The reference is obtained by brutal-forced sampling \(X\) 100,000 times and applying the filtering, which obtain 4814 valid samples, only the first 30 are shown in the figure.

\textbf{Rare event: } We use the same time step size as the previous experiment, however, a quadratic transformation \(\tau(t)=t(2-t/T)\) is deployed to get an irregular grid, where the closer to the endpoint \(T\), the denser the grid. The observation noise variance is \(\epsilon=2e-4\). \(\vartheta_{\theta}(t, x)\) architecture is the same, but training for a longer time with 300,000 independent samples. For the guided proposal, \(\eta=0.9\), it runs one chain for 20,000 iterations with a burn-in period as the first 2,000 steps and obtains \(23.18\%\) acceptance rate. Another notable thing is to obtain the reference by brutal forced sampling, one can only get 104 (\(1.04\) \textperthousand) samples that meet the rare conditionals out of 100,000 forward samplings, while in the normal case, the number of valid samples is 4814 (\(4.81\%\)). 

\subsection{Stochastic landmark matching} \label{app:landmark}
To demonstrate the necessity of using a state-dependent nonlinear process as Equation \eqref{eq:landmark_sde} to model the shape process rather than a linear one with a fixed diffusion matrix, we show a comparison of forward processes under two scenarios as Figure \ref{fig:landmark_comparsion}, where the linear process is similar to the auxiliary process Equation \eqref{eq:landmark_auxiliary_sde}, but with a fixed \(Q\) evaluated at the starting point \(x_0\), except for the evaluation point, the rest parameters for the kernel are the same. In Equation \eqref{eq:landmark_sde}, as \(X_t^{(j)}\) approaching \(X_t^{(i)}\), the correlation between them becomes stronger, which forces them to move synchronically, thus preventing the overlapping and intersection. Also, when \(\kappa\to 0\), the process defined by Equation \eqref{eq:landmark_sde} will degenerate to Brownian motion.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/ellipse_unconditional_samples.pdf}
    \caption{Comparison of using a linear (Top row) with a fixed diffusion coefficient and Equation \eqref{eq:landmark_sde} (Bottom row) to model the stochastic evolution of an ellipse shape (marked in purple) using 4 different samples of trajectories individually, where the nonlinear Equation \eqref{eq:landmark_sde} preserves the topology of the ellipse, which is broken during the evolution under the linear process.}
    \label{fig:landmark_comparsion}
\end{figure}

The observation noise variance is set as \(\epsilon=2e-3\), as we find too small values of \(\epsilon\) will cause numerical instability. We deploy the neural network architecture suggested in \citet{heng2022simulating} to model \(\vartheta_{\theta}\), whose encoding part is a two-layer MLP with 128 hidden units at each layer, and the decoding part is a three-layer MLP with hidden units of 256, 256, and 128 individually. The network is activated by tanh, and trained with 240,000 independent samples from \(X^{\bullet}\) with batch size \(N=8\), optimized by Adam with an initial learning rate of 7.0e-4 and a cosine decay scheduler. For the guided proposal, we run one chain for 5,000 iterations and drop the first 1,000 iterations as the burn-in, with \(\eta=0.95\) and obtain \(12.62\%\) acceptance rate on average.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}