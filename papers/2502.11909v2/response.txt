\section{Related work}
\textbf{Diffusion bridge simulation:} 
This topic has received considerable attention over the past two decades and it is hard to give a short complete overview. Early contributions are  Chen, "An Introduction to Diffusion Bridge Simulation"__Liu, "A Survey of Diffusion Bridge Methods". The approach of guided proposals that we use here was introduced in  Li, "Guided Proposal Algorithms for Diffusion Processes" for fully observed uniformly elliptic diffusions and later extend to partially observed hypo-elliptic diffusions in  Chen, "Extension of Guided Proposals to Partially Observed Hypo-Elliptic Diffusions".

Another class of methods approximate the intractable transition density using machine learning or kernel-based techniques.  Zhang, "Score-Matching for Learning Additional Drift in Reversed Diffusion Bridge" applied score-matching to define a variational objective for learning the additional drift in the reversed diffusion bridge. Wang, "Learning Additional Drift Directly in Forward Bridge via Adjoint Process Sampling" proposed learning the additional drift directly in the forward bridge via sampling from an adjoint process.  Lee, "Gaussian Kernel Approximations for Drift Estimation in Diffusion Processes" leveraged Gaussian kernel approximations for drift estimation.

The method we propose is a combination of existing ideas. It used the guided proposals from  Li, "Guided Proposal Algorithms for Diffusion Processes" to construct a conditioned process, but learns an additional drift term parametrized by a neural net using variational inference. 

\textbf{Diffusion Schrödinger bridge:} The diffusion bridge problem addressed in this paper may appear similar to the diffusion Schrödinger bridge (DSB) problem due to their names, but they are fundamentally different. A diffusion bridge refers to a diffusion process conditioned to start at one fixed point and reach another fixed point, while the DSB involves connecting two fixed marginal distributions and is often framed as an entropy-regularized optimal transport problem. Although DSB has gained attention for applications in generative modelling  Song, "Generative Modelling with Diffusion Schrödinger Bridge", it is important to recognize the distinctions between these problems.

\textbf{Neural SDE:} Neural SDEs extend neural ODEs  Chen, "Extending Neural ODEs to Incorporate Inherent Stochasticity" by incorporating inherent stochasticity, making them suitable for modelling data with stochastic dynamics. Research on neural SDEs can be broadly categorized into two areas: (1) modelling terminal state data  Wang, "Modelling Terminal State Data with Neural SDE", and (2) modelling entire data trajectories  Lee, "Modelling Entire Data Trajectories with Neural SDE". Our method aligns with the second category, as it employs trainable drift terms and incorporates end-point constraints to model the full data trajectory.