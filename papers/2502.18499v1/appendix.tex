% \section{RQ2: How does each (sub-)layer contribute to the correct token prediction?}
\section{Additional Results of Sub-Layer Logit Differences} \label{app: app1}

In Figure~\ref{fig:additional-sub-layer}, we present the sub-layer logit difference curves for the other two class constructors, i.e., \lstinline|list| and \lstinline|set|, in the Two Closing Parenthesis sub-task.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/prompt_type_test_list.png} % Replace with your image
        \caption{Sub-layer logit difference for the Two Closing Paren sub-task when the class constructor is \lstinline|list| (averaged over prompts of the same type).}
        \label{fig:list-type}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/prompt_type_test_set.png} % Replace with your image
        \caption{Sub-layer logit difference for the Two Closing Paren sub-task when the class constructor is \lstinline|set| (averaged over prompts of the same type).}
        \label{fig:set-type}
    \end{subfigure}
    \caption{Sub-layer logit difference of the Code LM between the correct and counterfactual tokens contribution to the residual stream. ``embed'' indicates the word embedding.}
    % , and ``$SubL$\_out'' indicates the activation output of the sub-layer $SubL$, being either $L\_$mlp or $L\_$attn (i.e., MHA).}
    \label{fig:additional-sub-layer}
\end{figure*}