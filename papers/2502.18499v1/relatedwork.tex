\section{Related Works}
% {\paragraph{Code LMs} Code LMs~\cite{abdin2024phi, team2024codegemma, guo2024deepseek, li2023starcoder, roziere2023code, chen2021evaluating}, are a class of LMs specifically developed to enhance code generation capabilities of LMs through fine-tuning and additional training techniques~\cite{chan2023transformer}. They have shown impressive performance on coding evaluation bechmarks~\cite{yu2024codereval, zhuo2024bigcodebench, lai2023ds, cassano2023multipl, hao2022aixbench, srivastava2022beyond, hendrycks2021measuring} designed to evaluate their performance on diverse coding-related tasks across various programming languages.}

{\paragraph{Analysis of Code LMs} Code LMs~\cite{abdin2024phi, team2024codegemma, guo2024deepseek, li2023starcoder, roziere2023code, chen2021evaluating}, are a class of LMs specifically developed to enhance code generation capabilities of LMs through fine-tuning and additional training techniques~\cite{chan2023transformer}. Although these models have demonstrated remarkable capabilities in code generation tasks~\cite{yu2024codereval, zhuo2024bigcodebench, lai2023ds, cassano2023multipl, hao2022aixbench, srivastava2022beyond, hendrycks2021measuring}, they remain susceptible to various syntactic and semantic (or logical) errors~\cite{yu2024codereval, tambon2024bugs, dou2024s}. Prior studies have focused on empirically examining various types of bugs across a range of coding tasks and programming languages~\cite{dou2024s, tambon2024bugs, dakhel2023github} or proposing benchmark datasets to characterize these models' shortcomings~\cite{wang2023recode, siddiq2022securityeval, yang2024seccodeplt}. For instance, \citet{dou2024s} observed that LMs are especially prone to syntactical errors (e.g., incomplete syntax structure, and indentation issues) when generating code for complex or lengthy problems. While these studies provide valuable insights into when Code LMs are likely to make mistakes, our understanding of the underlying internal mechanisms enabling code-generation capabilities remains limited. To bridge this gap, our study investigates how Code LMs perform syntax completion tasks.}

{\paragraph{Mechanistic Interpretability (MI)} MI is a subfield of interpretability that aims to reverse-engineer LM by understanding their internal components and computational processes~\cite{elhage2021mathematical, olah2020zoom, rai2024practical, bereska2024mechanistic}. Recent MI studies have investigated various LM behaviors, including sequence completion task~\cite{elhage2021mathematical}, Indirect Object Identification~\cite{wang2022interpretabilitywildcircuitindirect}, Python docstring completion~\cite{heimersheim2023circuit, conmy2023towards} and modular addition tasks~\cite{nanda2023progress}, by discovering circuits, a subset of LM components responsible for implementing these LM behaviors. These circuits can be explained in terms of human-understandable algorithms after interpreting the circuit components, which has led to the discovery of several interpretable attention heads such as induction heads~\cite{elhage2021mathematical}, suppression heads~\cite{mcdougall2023copy}, and previous token heads~\cite{elhage2021mathematical}. Building upon these advancements, we study the internal mechanisms of code LMs to understand the syntax completion capability of Code LMs. As far as we know, there has no been prior work carefully studying MI techniques in the application of LMs for code generation. As the first step, in this work, we have focused on discovering how the CodeLlama model identifies the correct next token and contrasts it against the counterfactual token in the syntax completion task. We include a discussion of our future extension along this line of research in Section~\ref{sec: discussion}.}