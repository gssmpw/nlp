\subsection{Limitations} 


There are \rev{some} limitations of this work.
First, we completed the interviews prior to March 2024 and gathered \sbma's image descriptions from its official release until March 31, 2024. Thus, our analysis did not encompass versions of \bma{} released after March 2024. Given the frequent updates and evolution of the system, there may be feature changes or enhancements introduced post-March 2024 that were not considered in our study. Future research can investigate the capabilities and limitations of newer versions of \bma{} to provide updated insights.  
% 
\rev{Second, while our focus on initial user experiences provided insights into early-stage interactions with \bma, this early-phase data collection resulted in a limited dataset. Future work can incorporate larger real-world datasets over extended periods of use and explore more diverse use cases to provide a more comprehensive understanding of the system's capabilities and limitations.}
% 
\rev{Third}, the interview participants live inside the United States, and only image descriptions written in English were collected and analyzed. Thus, this study may not reflect perspectives outside the United States or from non-English speaking contexts. Future research can explore the usage and limitations of LMM-based VQA systems across broader and diverse cultural backgrounds. 
% 
\rev{Fourth}, \bma{} cannot store conversation history. This limited functionality prevented users from sharing their ongoing interactions with the system. Thus, we were unable to fully understand users' prior experiences or analyze the data within broader contexts. 




%%%%%%%%%%%%%
\section{Conclusion}

This study investigates the application of LMMs, particularly through \bma, to enhance accessibility for PVI. Our research explores both the capabilities and limitations of the system by interviewing 14 visually impaired users and analyzing image descriptions generated by it. 
We identify significant limitations in \bma's context-aware and intent-oriented capabilities, including AI hallucinations, subjective interpretations in social and stylistic contexts, inaccurate recognition of people's identities, and inconsistent support in understanding and acting on user intentions. 
These challenges often lead users to rely on human assistance or personal strategies to compensate. 
Informed by these findings, we propose approaches to enhance interaction between PVI, \bma, and remote sighted assistants, emphasizing streamlined interactions, more accurate identity recognition, and reduced AI errors. We also highlight the potential of multi-agent systems, fostering collaboration among humans and AI, and suggest exploring AI-AI cooperation for tasks requiring specialized knowledge.


\begin{acks} 
We thank Samantha Paradero for her assistance in data collection.  
We also thank the anonymous reviewers for their insightful comments. 
This research was supported by the US National Institutes of Health, and the National Library of Medicine (R01 LM013330). 
\end{acks} 