\section{Complete Theorems: ICL Emerges from Generalization of Pre-trained LLMs}\label{sec-app:gen}
In Section \ref{sec:gen}, we have introduced Theorem \ref{pre-gen-data-dependent} and \ref{ICL-gen-topic-dependent}. Here, in the following Section \ref{sec-app:gen-pre}, we divide Theorem \ref{pre-gen-data-dependent} into two parts: Theorem \ref{app:pre-gen} and Theorem \ref{app:pre-gen-data-dependent}. Similarly, in the following Section \ref{sec-app:gen-ICL}, we divide Theorem \ref{ICL-gen-topic-dependent} into two parts: Theorem \ref{app:ICL-gen} and Theorem \ref{app:ICL-gen-topic-dependent}.

\subsection{Generalization of Sequences: The First-Level Expectation}\label{sec-app:gen-pre}
Under finite ($K$) pre-training topics, we consider the first-level expectation where infinite sequences per topic are utilized. It describes comprehensive learning for each pre-training topic in the ideal case so that the pre-trained model can perform excellently on the seen topics in ICL phase. For this first-level expected loss $L(\theta, \mathcal{W}_{\text{pre}})$ with two partial expectation, it's represented as $\frac{1}{K}\sum_{k=1}^K\mathbb{E}_{E^{k,n}_t}\left[\KL\big(\mathbb{P}(\cdot\mid E^{k,n}_t,w_k) \parallel \mathbb{P}_\theta(\cdot\mid E^{k,n}_t,w_k)\big)\right]$ (details see in Equation \ref{eq-L-W}). The following Theorem will give the upper bound of $L(\theta, \mathcal{W}_{\text{pre}})$.

In the following Theorem, we first give an general result that KL distance between posterior $\mu$ and prior $\nu$ is kept in the upper bound of the first-level expected loss. Here, the prior is a general prior distribution rather than a data-dependent prior.

\begin{theorem}[Generalization Bound of the First-Level Expected Loss] Let the auto-regressive LLM $\mathbb{P}_\theta$ be the empirical solution of Equation $\ref{eq-L-E}$, and $\mathbb{P}(\cdot\mid w)$ denotes the true data distribution under topic $w$. Under Assumptions \ref{ass:B}, for any $0<\delta < 1$, with probability at least $1-\delta$, the first-level expected loss with $K$ topics and infinite sequences per topic, denoted by $L(\theta, \mathcal{W}_{\text{pre}})$ (see in Equation \ref{eq-L-Wpre-two-part-final-main} or Equation \ref{eq-L-W}), satisfies,
	\label{app:pre-gen}
    \begin{align*}
        \mathbb{E}_{\mu}\left[L(\theta, \mathcal{W}_{\text{pre}})\right]
        =\mathcal{O}\left\{\sqrt{\frac{\log 1/\delta}{KNT}}+\sqrt{\frac{1}{KNT}\left(\KL(\mu\parallel \nu)+\operatorname{log}\frac{1}{\delta}\right)-\epsilon_{\text{opt}}}\right\},
    \end{align*}

	where $\epsilon_{\text{opt}}$ is the optimization error (see in Equation \ref{opt}). $\mu$ and $\nu$ are the posterior and prior distribution of model parameters $\theta$, respectively. $K$, $N$ and $T$ denote the number of topics, the number of sequences per topic and the sequence length utilized in the optimization process of Equation $\ref{eq-L-E}$.
\end{theorem}

\begin{remark}\label{remark-app: the1}
	Theorem \ref{app:pre-gen} reveals that when considering the first-level expectation over sequences, the expected loss achieves $\frac{1}{\sqrt{KNT}}$ rate. This indicates that an increase in the number of training topics ($K$), the number of sequences per topic ($N$), and the sequence length ($T$) leads to a reduction in the first-level expected loss, aligning with both intuitive understanding and empirical evidence. Note that the length of different sequences $T_{k,n}$ vary from each other which implies the potential for sampling imbalanced sequences from various topics. Moreover, the number of sequences $N_k$ per topic can also be different. If sequences under a specific theme are notably short, balancing can be achieved by sampling a greater number of these sequences, i.e. increasing $N_k$, ensuring that the product of $N_kT_{k,n}$ for all themes maintains a level of equilibrium. This approach ensures that the final representation of $NT$ conveys an averaged meaning. If certain themes yield fewer sequences, it indicates a lower probability of occurrence for those themes. Under the framework of theme distribution (as defined by the second level expectation), the contribution of such themes (smaller $N_kT_{k,n}$) to $NT$ won't be dominant. In conclusion, themes with higher occurrence probabilities are predominant and more sequences can be more readily sampled. Even if these sequences are shorter, we can compensate by sampling more sequences to achieve an average level $NT$ which corresponds to our result.
\end{remark}

In the next Theorem, we carefully consider a data-dependent prior \citep{li2019generalization}, replacing $\KL(\mu\parallel\nu)$ with $\KL(\mu\parallel\nu_J)$ in Theorem \ref{app:pre-gen} and further deriving a more detailed upper bound.

\paragraph{Data-Dependent Prior.} We employ the following method for generating a data-dependent prior \citep{li2019generalization}. Let $J$ include $N^{\prime}$ indexes uniformly sampled from $[N]$ without replacement and $I$ is $[N]\setminus J$, splitting pre-training sequences under fixed topic $w_k$ into two parts $E^k_I$ and $E^k_J$. Under all pre-training topics, we have $E_I=\{E^k_I\}_{k=1}^K$ and $E_J=\{E^k_J\}_{k=1}^K$. The prior distribution of model parameters $\theta$ depends on the subset $E_J$, which is denoted by $\nu_J$ and the posterior distribution of $\theta$ depends on $E_I$ denoted by $\mu$. Thus, a parallel training process with $E_J$ are conducted, and after that, a data-dependent prior $\nu_J$ will be obtained. We emphasize that extracting a portion of training data to learn the prior distribution of model parameters has significant implications. Specifically, this approach allows the prior to adapt to specific features and trends in the data, enhancing the model's ability to capture and learn from these nuances. In addition, even if we sacrifice a portion of the training data, the prior will lead to a posterior distribution that is better aligned with the actual data distribution. In high-dimensional spaces, a data-dependent prior provides a more informed starting point.


\begin{theorem}[Data-Dependent and Optimization-Dependent Generalization Bound of the First-Level Expected Loss] Under the conditions maintained in Theorem \ref{app:pre-gen} and Assumption \ref{ass: lipschitz}, when considering data-dependent prior $\mu_J$, for any $0<\delta < 1$, with probability at least $1-\delta$, the first-level expected loss with $K$ topics and infinite sequences per topic, denoted by $L(\theta, \mathcal{W}_{\text{pre}})$ (see in Equation \ref{eq-L-Wpre-two-part-final-main} or Equation \ref{eq-L-W}), satisfies,
	\label{app:pre-gen-data-dependent}
	\begin{align*}
			\mathbb{E}_{\mu}\left[L(\theta, \mathcal{W}_{\text{pre}})\right]
			=\mathcal{O}\left\{\sqrt{\frac{ \log 1/\delta}{K(N-N^\prime)T}} + \sqrt{\frac{1}{K(N-N^\prime)T}\left(\KL(\mu\parallel\nu_J)+\log \frac{1}{\delta}\right)-\epsilon_{\text{opt}}}\right\},
	\end{align*}
	then detailing the term $\KL(\mu \parallel \nu_J)$, $L(\theta, \mathcal{W}_{\text{pre}})$ further satisfies,
	\begin{align}\label{app-theF3}
			\mathcal{O}\left\{\sqrt{\frac{\log 1/\delta}{K(N-N^\prime)T}}+\sqrt{\frac{1}{K(N-N^\prime)T}\left[\frac{L^2C(\frac{1}{N_{\text{param}}},T^\prime)}{N^\prime}+\log \frac{1}{\delta}\right]-\epsilon_{\text{opt}}}\right\},
	\end{align}
    where $C(\frac{1}{N_{\text{param}}},T^\prime)=\frac{\beta}{2}e^{8\beta S}\left(1-e^{-\frac{{T^\prime}}{\exp(8\beta S)}}\right)$. $\epsilon_{\text{opt}}$ is the optimization error (see in Equation \ref{opt}). $K$, $N (N^\prime)$ and $T$ denote the number of topics, the number of sequences per topic and the sequence length utilized in the optimization process of Equation $\ref{eq-L-E}$. $T^\prime$ denotes the total training iterations. $N_{\text{param}}$ denotes the number of model parameters.
\end{theorem}

\begin{remark}\label{remark-app: the2}
	The PAC-Bayesian generalization bound of the first-level expected loss can be bounded by the KL divergence between the distribution of the model obtained by the real training process and data-dependent prior, i.e. $\KL(\mu \parallel \nu_J)$. Analyzing the continuous Langevin dynamic of model parameters $\theta$, Fokker-Planck Equation is used to describe the KL distance between two probability density function of two optimization processes, furthermore, referring to the proof of Lemma G.5 in \cite{li2019generalization}, we demonstrate that the integral of the gradient difference of $\big\|\nabla L_{E_I}(\theta_t, \mathcal{W}_{\text{pre}})-\nabla L_{E_J}(\theta_t, \mathcal{W}_{\text{pre}})\big\|_2^2$. Consequently, we bound $\KL(\mu \parallel \nu_J)$ with $\frac{L^2C(\frac{1}{N_{\text{param}}},T^\prime)}{N^\prime}$, which is related to optimization algorithm. As $T^\prime$ increases, $C(\beta, T^\prime)$ increases, i.e., the generalization error increases. This reflects the influence of total training iterations $T^\prime$ on testing loss, corresponding to the classical viewpoint `train faster, generalize betterâ€™ \citep{hardt2016train, lei2020fine, zhang2022stability}. In addition, the constant $L$ related to optimization reflects that the upper bound of the gradient of AR-NTP loss also impacts the generalization performance. Observing the derived upper bound, we notice that the last term, $\sqrt{\frac{\log 1/\delta}{K(N-N^\prime)T}} \sim \frac{1}{\sqrt{K(N-N^\prime)T}}$, provides similar insights to $\frac{1}{\sqrt{KNT}}$ in Theorem \ref{app:pre-gen}. In total, by detailing the KL divergence, we establish a more refined bound which is data-dependent and optimization-dependent.
\end{remark}

\textbf{In summary, the proof of Theorem \ref{pre-gen-data-dependent} is provided in Appendix \ref{appendix-the-1} and Appendix \ref{appendix-the-2}.}

\subsection{Generalization of Sequences and Topics: Two-Level Expectation}\label{sec-app:gen-ICL}
Up to now, we have analyzed the first-level expected loss with $K$ topics and infinite sequences per topic. In this ideal case, the pre-trained LLM can perform excellently on the new test prompt under seen topics in ICL phase. In this section, we use similar techniques to further consider the second level expectation with infinite topics, so that the pre-trained LLM could perform well on unseen topics under the topic distribution assumption. At this moment, ICL emerges from the generalization of sequences and topics.

We first give a general result in Theorem \ref{app:ICL-gen} with $\KL(\rho(\theta)\parallel \pi(\theta))$, which extends beyond Theorem \ref{app:pre-gen-data-dependent} by incorporating infinite topics.

\begin{theorem}[Data-Dependent and Optimization-Dependent Generalization Bound of the Two-Level Expected Loss]
	\label{app:ICL-gen} Let the auto-regressive LLM $\mathbb{P}_\theta$ be the empirical solution of Equation $\ref{eq-L-E}$, and $\mathbb{P}(\cdot\mid w)$ is the true data distribution under topic $w$. Under Assumptions \ref{ass:B}, \ref{ass: lipschitz} and \ref{ass: lipschitz-2}, for any $0<\delta < 1$, with probability at least $1-\delta$, the two-level expected loss (population loss) with infinite topics and infinite sequences per topic, denoted by $L(\theta)$ (see in Equation \ref{eq-L-ICL-final}), satisfies,
		\begin{align*}
			\mathbb{E}_{\mu}[L(\theta)]
			=\mathcal{O}\biggl\{\sqrt{\frac{1}{KT_p}}\left(\KL(\mu\parallel \nu)+\log \frac{1}{\delta}\right)+U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)\biggr\},
		\end{align*}
	where $U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)$ denotes the right hand of equality \ref{the3-right} or equality \ref{app-theF3}. $\mu$ and $\nu$ are the posterior and prior distribution of model parameters $\theta$, respectively. $K$, $N (N^\prime)$ and $T$ denote the number of topics, the number of sequences per topic and the sequence length utilized in the optimization process of Equation $\ref{eq-L-E}$.
\end{theorem}
\begin{remark}
	The term $U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)$ comes from Theorem \ref{app:pre-gen-data-dependent} whose analysis can refer to Remark \ref{remark-app: the2}. As for the first term in the result, with order $\mathcal{O}\{\frac{1}{\sqrt{KT_p}}\}$, it illustrates the impact of training with a finite number of topics on the model's predictive ability for unseen topics in ICL. In addition with larger prompt length, ICL emerges much easier from the generalization of pre-trained LLMs. 
\end{remark}

Next, we propose topic-dependent prior whose core idea comes from data-dependent prior \citep{li2019generalization}, i.e., a portion of $K$ topics will be used for calculating model prior and other topics will be used for obtaining posterior. $\KL(\rho\parallel\pi)$ in Theorem \ref{app:ICL-gen} will be replaced by $\KL(\rho\parallel\pi_J)$ and further derives a more detailed upper bound. Since then, we can provide data-dependent, topic-dependent and optimization algorithm-dependent generalization error bound of the two-level expected loss.

\paragraph{Topic-Dependent Prior.} We employ the following method for generating a topic-dependent prior, similar to data-dependent prior \citep{li2019generalization}. We split topics into two parts and let $J$ include $K^{\prime}$ indexes uniformly sampled from $[K]$ without replacement and let $I$ be $[K]\setminus J$, then the total sequences are divided into $E^I=\{E^k\}_{k \in \mathcal{W}_{\text{pre},I}}$ and $E^J=\{E^k\}_{k \in \mathcal{W}_{\text{pre},J}}$. Assume that the posterior distribution of model parameters $\theta$ depends on $E^I$ denoted by $\rho$ and the prior distribution of $\theta$ depends on the topic subset $E^J$, which is denoted by $\pi_J$. A parallel training process is performed with $E^J$ based on the same LLM architecture, and after that, a topic-dependent prior $\pi_J$ will be obtained.


\begin{theorem}[Data-Dependent, Topic-Dependent and Optimization-Dependent Generalization Bound of the Two-Level Expected Loss] Under the conditions maintained in Theorem \ref{app:ICL-gen} and Assumption \ref{ass: lipschitz-2}, when further considering topic-dependent prior, for any $0<\delta < 1$, with probability at least $1-\delta$, the two-level expected loss (population loss) with infinite topics and infinite sequences per topic, denoted by $L(\theta)$ (see in Equation \ref{eq-L-ICL-final}), satisfies,
	\label{app:ICL-gen-topic-dependent}
    \begin{align*}
        \mathbb{E}_{\mu}\left[L(\theta) \right]
        =\mathcal{O}\biggl\{\sqrt{\frac{1}{(K-K^\prime)T_p}}\left(\KL(\mu\parallel \nu_J)+\log \frac{1}{\delta}\right)+ U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)\biggr\},
    \end{align*}
	then detailing the term $\KL(\mu \parallel \nu_J)$, $L(\theta)$ further satisfies,
	\begin{align}
			\mathcal{O}\biggl\{\sqrt{\frac{1}{(K-K^\prime)T}}\left(\frac{\sigma^2C(\frac{1}{N_{\text{param}}},{T^\prime})}{K^\prime}+\log \frac{1}{\delta}\right)
			+ U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)\biggr\}, \nonumber
	\end{align}
	where $C(\frac{1}{N_{\text{param}}},T^\prime)=\frac{\beta}{2}e^{8\beta S}\left(1-e^{-\frac{ T^\prime}{\exp(8\beta S)}}\right)$, $U(\mathcal{W}_{\text{pre}},K,N,N^\prime,T)$ denotes the right hand of equality \ref{the3-right} or equality \ref{app-the3-right}. $\mu$ and $\nu_J$ are the posterior and topic-dependent prior distribution of model parameters $\theta$, respectively. $K (K^\prime)$, $N (N^\prime)$ and $T$ denote the number of topics, the number of sequences per topic and the sequence length utilized in the optimization process of Equation $\ref{eq-L-E}$. $T^\prime$ denotes the total training iterations. $N_{\text{param}}$ denotes the number of model parameters.
\end{theorem}
\begin{remark}
	In Theorem \ref{app:ICL-gen-topic-dependent}, we establish a comprehensive upper bound of population loss combining the results in Theorem \ref{app:pre-gen}, \ref{app:pre-gen-data-dependent} and \ref{app:ICL-gen}.
\end{remark}

\textbf{In summary, the proof of Theorem \ref{ICL-gen-topic-dependent} is provided in Appendix \ref{appendix-the-3} and Appendix \ref{appendix-the-4}.}