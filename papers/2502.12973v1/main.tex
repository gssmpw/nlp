\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
\usepackage[preprint]{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\usepackage{graphicx}

\usepackage{subcaption}
\usepackage[c2]{optidef}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\setcounter{MaxMatrixCols}{20}
\usepackage{enumitem}
\usepackage{physics}


\newcommand{\theHalgorithm}{\arabic{algorithm}}



\usepackage{amsmath,adjustbox}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage{algorithm,algorithmic}

\title{Optimizing Social Network Interventions via \\Hypergradient-Based Recommender System Design}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{
 Marino K\"uhne \\
  ETH Z\"urich\\
  \texttt{marino.kuehne@outlook.com} 
   \And
Panagiotis D. Grontas \\
  ETH Z\"urich\\
  \texttt{pgrontas@ethz.ch} 
  \And
 \hspace*{0.7cm}Giulia De Pasquale\\
 \hspace*{0.7cm}Eindhoven University of Technology\\
  \hspace*{0.7cm}\texttt{g.de.pasquale@tue.nl } 
     \And
\hspace*{3pt}Giuseppe Belgioioso \\
\hspace*{3pt}KTH Royal Institute of Technology\\
\hspace*{3pt}\texttt{giubel@kth.se} 
     \And
\hspace*{0.8cm}Florian D\"orfler \\
\hspace*{0.8cm}ETH Z\"urich\\
\hspace*{0.8cm}\texttt{dorfler@ethz.ch}
    \And
\hspace*{1.2cm} John Lygeros \\
  \hspace*{1.2cm} ETH Z\"urich\\
  \hspace*{1.2cm} \texttt{jlygeros@ethz.ch} 
}


\begin{document}


\maketitle


\begin{abstract}
Although social networks have expanded the range of ideas and information accessible to users, they are also criticized for amplifying the polarization of user opinions.
Given the inherent complexity of these phenomena, existing approaches to counteract these effects typically rely on handcrafted algorithms and heuristics.
We propose an elegant solution:  we act on the network weights that model user interactions on social networks 
(e.g., frequency of communication), 
to optimize a performance metric (e.g., polarization reduction), 
while users' opinions follow the classical Friedkin-Johnsen model.
Our formulation gives rise to a challenging large-scale optimization problem with non-convex constraints, for which we develop a gradient-based algorithm.
Our scheme is simple, scalable, and versatile, as it can readily integrate different, potentially non-convex, objectives.
We demonstrate its merit by: (i) rapidly solving complex social network intervention problems with 3 million variables based on the Reddit and DBLP datasets;
(ii) significantly outperforming competing approaches in terms of both computation time and disagreement reduction.
\end{abstract}

\section{Introduction} \label{sec:introduction}
\textit{Problem description and motivation:} 
Social media platforms brought many societal benefits but they have also been associated with the spread of fake news and the polarization of opinions \cite{fake-news, 2_2, 1_26, 2_6, 2_5, 2_8, 2_1, 2_7}. The algorithms employed by social media companies to maintain user engagement are thought to contribute to the isolation of the users into echo chambers, where opinions are segregated by party lines and ties to opposing views are severed \cite{filter-bubble-hypothesis}. Even though the literature suggests that the algorithms of major social media companies may decrease the share of cross-cutting content in users' feeds \cite{1_26, 2_6}, thereby limiting diverse content exposure, the user's choice of engaging with opinion-confirming material tends to be a comparable cause of this isolation \cite{1_32, 2_6, 2_3}.

The field of opinion dynamics studies how the content provided by social media shapes user opinions and how opinions propagate in a social network \cite{1_6}. Users in the social networks are modeled as nodes in a directed, weighted graph, where the edge orientation represents the direction of influence between users and the edge weights represent the intensity of the social influence.
Here we consider the well-established Friedkin-Johnsen (FJ) model  \cite{FJ},  which has been successfully employed in the study of polarization and disagreement in social networks \cite{filterbubble, 1_28, 1_24}.
In the FJ model, users have both a constant internal opinion (prejudice) and a time-varying external, declared opinion. The external opinion of each user evolves by repeated averaging of the internal opinion with the external opinions of interacting users, while the prejudice remains constant.
We propose a unified framework to address a broad class of problems involving the influence of user opinions on social platforms, such as polarization mitigation, through modifications to users' connections when  opinions evolve according to the FJ dynamics.


\textit{Literature review:} The literature on network interventions under the FJ dynamics is vast \cite{BINDEL2015248, 1_7, 1_8, 1_22, 1_24, 1_28, 1_29, 1_30, filterbubble}. All these works seek to achieve various objectives by designing interventions on the social network topology or on the internal opinions of users. 
 The most common approach is based on adding or deleting edges from the network, where the following objectives are considered:   minimization of average- and worst-case opinion dynamics metrics \cite{1_24}, social cost minimization \cite{BINDEL2015248}, and polarization and disagreement minimization \cite{1_30}. Differently, \cite{filterbubble} minimizes disagreement by altering the edge weights. A second, less common approach focuses on changing opinions of specific users \cite{1_7,1_29,1_28}. To achieve a generally favourable opinion about a product, \cite{1_7} sets the opinions of a fixed number of users to a specific value. On the other hand,  \cite{1_29} sets the opinions of a fixed number of users to zero to minimize polarization. Finally, \cite{1_28} modifies opinions to minimize the sum of polarization and disagreement.

If we view the weights\footnote{The same principle holds if internal opinions are considered as hyperparameters, but it is not covered in this work.} of the network as hyperparameters of a model, then choosing the optimal ones becomes a hyperparameter tuning problem.
This defines the upper level of a bilevel optimization problem. In turn, the equilibrium resulting from the repeated averaging of the FJ dynamics can be interpreted as the Nash equilibrium of a game defined by a separate optimization problem \cite{BINDEL2015248}, forming the lower level.
These bilevel optimization problems are difficult to solve -- for example, some formulations in \cite{BINDEL2015248} and \cite{1_29}, are shown to be NP-hard. A few special problems with tailor-made objectives are shown to be convex, such as \citep[Section 4]{1_8} or \cite{1_28}. However, this is not the case in general and the problems are solved with problem-specific algorithms or heuristics such as in \cite{1_7} or \cite{1_29}.

For both large-scale convex and non-convex problems, first-order methods have proven highly effective, as demonstrated in works like \cite{large-scale-2, bottou, KingBa15}.
These methods are particularly appealing due to their computational efficiency and scalability. Recent advancements have extended these approaches to hypergradients \cite{hyperparameter} (the gradient of the objective with respect to hyperparameters), while also analyzing the computational complexity of such methods \cite{Grazzi2020OnTI}. A widely-used technique for obtaining hypergradients involves differentiating through implicit mappings, as explored in \cite{bighype}.

\textit{Contributions:} We consider the FJ model of opinion dynamics. 
We seek to drive the equilibrium user opinions to a desired configuration by modifying network weights.
Our contribution is three-fold:
\begin{enumerate}
    \item We formulate an optimal intervention task as an optimization problem with non-convex constraints,
    that describe the equilibria of the FJ dynamics.
    Our formulation can accommodate any (differentiable) objective, e.g., polarization or disagreement reduction,
    as well as convex constraints modelling intervention limits.
    \item We propose a first-order algorithm that alternates between modifying the network weights and computing both the equilibrium opinions and their gradient with respect to weights,
    by efficiently backpropagating through the FJ dynamics.
    Crucially, both steps are simple and scalable: they consist of a projected gradient update and the solution of two linear systems.
    \item We provide a modular, and well-documented implementation of our algorithm in JAX \cite{jax2018github}, facilitating the usage of hardware accelerators\footnote{We plan to release the code as open-source upon publication of this paper.}. We then test our algorithm on real-world datasets, with up to 3 million modifiable weights, and obtain a solution in a matter of minutes on a GPU.
    Additionally, we compare our approach against the nonlinear programming solver \texttt{IPOPT}, demonstrating up to three orders of magnitude faster runtime while achieving superior solution quality. Finally, compared to an existing heuristic, which is tailored to a subclass within our problem formulation, our scheme obtains significantly better solutions.
\end{enumerate}

\paragraph*{Notation}
Let $\mathbb{R}_{\geq 0}$ ($\mathbb{R}_{>0}$) denote the set of non-negative (positive) real numbers. 
We denote the $(i,j)$ element  of matrix $W$ by $w_{ij}$. 
Let $\lVert \cdot\rVert_F$ and $\lVert \cdot\rVert_2$ denote the Frobenius and the $\ell_2$ norm, respectively. 
% The transpose of a matrix $W$ is denoted by $W^\top$. 
The projection of a vector $w$ onto a convex set $\mathcal{W}$ is denoted by $\Pi_\mathcal{W}[w] = \argmin_{z \in \mathcal{W}} \lVert z - w\rVert_2^2$. Let $F : \mathbb{R}^m \times \mathbb{R}^n \rightarrow \mathbb{R}^p$ be a vector-valued differentiable mapping. We denote the partial Jacobians of $F$ with respect to the first and second arguments as $J_1F(w,y) \in \mathbb{R}^{p \times m}$ and $J_2F(w,y) \in \mathbb{R}^{p \times n}$, respectively. If $p = 1$, we use $\nabla_1F$, $\nabla_2F$ to denote the partial gradients. 


% -------------------------------------------------------------------------------------------------------------------------------
\section{Problem Formulation} \label{sec:problem}
We consider social networks consisting of interacting users, where a recommendation system (referred to as \emph{leader}) seeks to influence the users' opinions by controlling the interactions between them. This problem can be framed as a bilevel optimization problem, where the upper level involves the leader's interventions, and the lower level models the users, whose opinions are affected by the leader's decisions. Specifically, the leader aims to shift the users' opinions towards a desired configuration by altering network weights. In practice, these weights may represent various metrics, such as the volume of shared content (e.g., videos, images, or text) between two users, with the leader potentially reducing the connection strength by restricting content distribution between them. 

% -------------------------------------------------------------------------------------------------------------------------------

\subsection{Lower Level -- Opinion Dynamics}
We consider a network $G$, represented by a directed weighted graph $G=(V,W)$ where $V\coloneqq\{1, \ldots, n \}$ is the set of nodes, and $W \in \mathbb{R}^{n\times n}$ is the (weighted) adjacency matrix.
For notational convenience, we will reshape \(W\) as a vector \( w \in \mathbb{R}^{n^2} \).
We assume that \( G \) contains no self-loops and has non-negative weights, formally,
\( w \in \mathcal{B} \coloneqq \{ w \in \mathbb{R}^{n^2} \,|\, w_{ii} = 0,\, w_{ij} \geq 0, \, \forall i, j \in V \} \).
An edge between nodes \( i, j \in V \) exists if and only if \( w_{ij} > 0\), and we say
that \( i \) and \( j \) are neighbors.
Interpreting \( G \) as a social network, each of the $n$ nodes corresponds to a user (e.g., individuals, companies, news outlets, etc.), and the edges represent connections between them. For each edge $(i,j)$, the user on the tail $i$ is influenced by the user on the head $j$. The edge is assigned a weight proportional to the influence $j$ exerts on $i$ and could, for example, represent the time $i$ spends consuming content shared over this connection, the frequency of interaction, or any other engagement metric. It is natural to assume that a longer exposure results in a greater influence. According to the FJ opinion dynamics \cite{FJ}, the opinion of user $i$ consists of two parts: the constant internal opinion, or prejudice, $s_i \in \mathbb{R}$ and the time-varying external opinion $y_i \in \mathbb{R}$. 
 We consider opinions to be in the interval $[-1, 1]$, where $-1$ indicates complete opposition and $1$ complete approval. The internal opinion $s_i$ is kept private, while the external opinion $y_i$ is shared with others. Owing to the interactions between users, the external opinion of user $i$ changes over time according to the FJ update rule
\begin{equation} \label{eq:FJ-update}
    y_i^{(t+1)} = \frac{s_i + \sum_{j \in V} w_{ij} y_j^{(t)}}{1 + \sum_{j \in V} w_{ij}},
\end{equation}
and we note that the sums are implicitly restricted to the neighbors of \( i \),
since \( w_{ij} = 0 \) if \( j \) is not a neighbor of \( i \).
The update \eqref{eq:FJ-update} can be understood as a repeated weighted averaging between the internal opinion $s_i$ and the neighbors' opinions $y_j$, where the weights $w_{ij}$ indicate how susceptible user $i$ is to user $j$'s opinion. We can compute the equilibrium of \eqref{eq:FJ-update} as the solution of the linear system of equations
\begin{gather} \label{eq:pg-zero}
% \tiny
    \underbrace{
    \begin{bmatrix}
        1+\sum_{j \in V}w_{1j} & \cdots & -w_{1n}\\
        \vdots & \ddots & \vdots\\
        -w_{n1} & \cdots &  1+\sum_{j \in V}w_{nj}
    \end{bmatrix}
    }_{\coloneqq A(w)}
    y = s, 
\end{gather}
with $s = [s_1, \cdots, s_n]^\top \in \mathbb{R}^n$, $y = [y_1, \cdots, y_n]^\top \in \mathbb{R}^n$, and $A(w) \in \mathbb{R}^{n \times n}$. 
Note that, \( A(w) \) depends on the network weights \( w \), i.e., the vectorized form of the adjacency matrix \( W \).
Next, we show that whenever the weights are appropriately chosen, there exists a unique vector of equilibrium opinions.
\begin{proposition} \label{proposition:unique-y-star}
    Assuming \( w \in \mathcal{B} \), the matrix $A(w)$ is invertible and the FJ dynamics \eqref{eq:FJ-update} admits a unique equilibrium that solves \eqref{eq:pg-zero}.
\end{proposition}
The proposition holds since $A(w)$ is strictly row diagonally dominant and therefore invertible \citep[Th. IV]{dd}.

\subsection{Upper Level -- Network Intervention} \label{subsec:ul-intervening-in-the-network}
The goal of the leader is to find weights $w \in \mathbb{R}^{n^2}$ that minimize a cost function $\varphi: \mathbb{R}^{n^2} \times \mathbb{R}^n \rightarrow \mathbb{R} $,
mapping \( w \) and the resulting solution of \eqref{eq:pg-zero} to some upper-level objective.
\begin{assumption} \label{assumption:phi}
   $\varphi(w,y)$ is continuously differentiable in both arguments.
\end{assumption}
A possible choice is given by $\varphi(w, y) \coloneqq \frac{1}{n} \lVert y\rVert_2^2$, a classical measure of polarization, previously used by \cite{1_29}. In practice, the leader cannot modify the network weights arbitrarily, as such interventions directly impact the users' experience 
(e.g., consider the case where a connection between two close friends is removed). 
We model permissible interventions as a constraint $w \in \mathcal{W}$, obeying the following assumption.
\begin{assumption} \label{assumption:W}
   The set of constraints $\mathcal{W}$ is non-empty, closed, and convex,
   and \( \mathcal{W} \subseteq \mathcal{B} \).
\end{assumption}
The set \(\mathcal{W}\) can be used to add constraints that encode requirements such as:
(i) some connections cannot be formed or altered,
by fixing \( w_{ij} \) to zero or to its initial value, respectively;
(ii) ensuring that some connections are maintained by imposing lower bounds on some \( w_{ij} \).
Further, \(\mathcal{W} \) ensures that weights are compatible with our assumption \( w \in \mathcal{B} \).

Note that many of these constraints decrease the number of degrees of freedom in the optimization problem, 
for example by fixing some weights to a given value. 
In principle, one can maintain all the degrees of freedom and enforce this requirement through the set \( \mathcal{W} \). 
Computationally, however, it is more efficient to drop the corresponding decision variables from \( w\) from the beginning, giving rise to a decision vector of dimension lower than \( n^2 \).
We always drop the weights $w_{ii}$ from $w$, as self-loops are absent, reducing the number of decision variables to $m = n(n - 1)$. Throughout the remainder of this paper, $m$ denotes the effective number of decision variables.

Combining the upper-level objective $\varphi$ with the equilibrium of the lower level \eqref{eq:pg-zero} and permissible interventions in $\mathcal{W}$, 
we formulate the following optimization problem:
\begin{mini!}
    {w,y} {\varphi(w,y) \label{optimizationProblem}} 
    {\label{eq:high-level}}
    {}
    \addConstraint{A(w)y }{= s \label{high-level-problem-const-1}}
    \addConstraint{w }{\in \mathcal{W}. \label{high-level-problem-const-2}}
\end{mini!}

The bilinear constraint \eqref{high-level-problem-const-1} renders the feasible set non-convex. 
We rewrite \eqref{eq:high-level} as
\begin{mini!}
    {w} {\varphi(w,y^\star(w)) \label{optimizationProblem3}} 
    {\label{eq:optimization-with-system-easy}}
    {}
    \addConstraint{w}{\in \mathcal{W}, \label{high-level-easy-problem-const-2}}
\end{mini!}
where $y^\star(w)$ denotes the solution to the system $A(w) y = s$. 
We refer to $y^\star(\cdot): \mathbb{R}^{m} \to \mathbb{R}^n$ as the equilibrium mapping,
which is well-posed under Assumption \ref{assumption:W}. 
Formulation \eqref{eq:optimization-with-system-easy} is favorable since $y^\star(\cdot)$ is continuously differentiable (see Proposition \ref{prop:sensitivity}), hence  motivating us to deploy a first-order solution method.

Although \eqref{eq:optimization-with-system-easy} involves convex constraints, it is still challenging to solve, as $y^\star(\cdot)$ is an implicit mapping, for which a closed-form expression is, in general, not available. Moreover, the objective is non-convex.

% -------------------------------------------------------------------------------------------------------------------------------
\section{Algorithm Design} \label{sec:algorithm}
To solve \eqref{eq:optimization-with-system-easy}, we propose a gradient-based algorithm. The main challenge lies in obtaining the \textit{hypergradient}, i.e., 
the gradient of the objective $\varphi(w,y^\star(w))$ with respect to $w$. 
This can be achieved by using the chain rule as follows:
\begin{equation} \label{eq:hypergradient}
\begin{aligned}
    \nabla_w \varphi(w, y^\star(w)) = & \nabla_1 \varphi(w, y^\star(w)) \\
    & + Jy^\star(w)^\top \nabla_2 \varphi(w,y^\star(w)). 
\end{aligned}
\end{equation}
Under Assumption \ref{assumption:phi}, the partial gradients $\nabla_1 \varphi$ and $\nabla_2 \varphi$ are well-defined.
However, ensuring the existence of the Jacobian of the equilibrium mapping, $Jy^\star(w)$, also called the \textit{sensitivity}, and computing it is a non-trivial task.

To compute $Jy^\star(w)$, we introduce the auxiliary expression $F(w,y) := A(w)y -s$.
In the following we provide an explicit expression for the sensitivity.
\begin{proposition} \label{prop:sensitivity}
    Under Assumption \ref{assumption:W}, the function $y^\star(\cdot)$ is continuously differentiable and its Jacobian $Jy^\star(w)$ is well-defined. Moreover, $Jy^\star(w)$ is given by 
    \begin{equation} \label{eq:sensitivity}
        Jy^\star(w) = - J_2F(w,y^\star(w))^{-1} J_1F(w,y^\star(w)).
    \end{equation}
\end{proposition}
\begin{proof}
    From the definition $F(w,y) := A(w)y -s$, it immediately follows that $J_2F(w,y) = A(w)$,
    which is continuous in both arguments.
    Furthermore, $J_1F(w,y)$ is continuous in both arguments by Lemma \ref{lemma:j1f} in Appendix~\ref{subsec:computing-j1f}. Thus, $F(w,y)$ is continuously differentiable. Additionally, by Proposition \ref{proposition:unique-y-star}, $A(w)$ and therefore $J_2F(w,y)$ are nonsingular. By invoking the implicit function theorem \citep[Th. 1B.1]{Dontchev2009}, the sensitivity exists, is continuous, and given by \eqref{eq:sensitivity}.
\end{proof}

Given $Jy^\star(w)$, we can evaluate the hypergradient and solve \eqref{eq:optimization-with-system-easy}
using our preferred first-order method.
In this work, we deploy projected gradient descent with momentum \cite{Bolduc2017} given by
\begin{equation} \label{eq:momentum-pgd}
    \begin{aligned}
    m^{(k+1)} &= \gamma m^{(k)} + \nabla_w \varphi \big(w^{(k)}, y^\star \big(w^{(k)}\big)\big) \\
    w^{(k+1)} &= \Pi_\mathcal{W} \big[w^{(k)} - \alpha^{(k)} m^{(k+1)}\big],
    \end{aligned}
\end{equation}
where $\alpha^{(k)} \in [0,1]$ is a possibly iteration-dependent step-size and  $\gamma \geq 0$ is a momentum parameter. This formulation contains a short-term memory for the descent direction of the previous iteration $k$ in the form of $m^{(k)}$, and it can often significantly decrease the runtime for an appropriate choice of $\gamma$ \cite{goh2017why}. The projection is employed to ensure feasibility of the iterates $w^{(k)}$.

% -------------------------------------------------------------------------------------------------------------------------------

\subsection{Backpropagation through Equilibrium Opinions} \label{subsec:efficiency}
Computing $Jy^\star(w)$ by solving the matrix equation \eqref{eq:sensitivity}
can be computationally challenging for large-scale problems \cite{Parise}. 
Concretely, we need to solve
\begin{equation*}
    \underbrace{J_2F(w,y^\star(w))}_{\mathbb{R}^{n\times n}} \underbrace{Jy^\star(w)}_{\mathbb{R}^{n \times m}} = - \underbrace{J_1 F(w, y^\star(w))}_{\mathbb{R}^{n \times m}},
\end{equation*}
for a given $w$, and therefore fixed $y^\star(w)$, with matrix sizes as indicated. 
To reduce the computational burden, note that we do not need the sensitivity $Jy^\star(w)$ by itself in \eqref{eq:hypergradient} 
but rather the vector-Jacobian product $Jy^\star(w)^\top \nabla_2 \varphi(w,y^\star(w))$, 
see e.g., \cite{Grazzi2020OnTI}. 
Substituting \eqref{eq:sensitivity} in \eqref{eq:hypergradient}, yields:
\begin{align}
   \nabla_w \varphi(w, & y^\star(w)) 
     = \nabla_1 \varphi(w, y^\star(w)) - J_1 F(w,y^\star(w))^\top \notag \\
     & \big(J_2 F(w, y^\star(w))^\top\big)^{-1} \nabla_2 \varphi(w,y^\star(w)) \notag \\
     = & \nabla_1 \varphi(w, y^\star(w)) - J_1 F(w,y^\star(w))^\top v, \label{eq:hypergradient-trick}
\end{align}
where $v \in \mathbb{R}^n$ solves the linear system of equations
\begin{equation} \label{eq:v}
    J_2 F(w, y^\star(w))^\top v = \nabla_2 \varphi(w,y^\star(w)).
\end{equation}
Hence, we can compute the hypergradient by solving \eqref{eq:v} instead of \eqref{eq:sensitivity}, i.e.,
we solve one linear system instead of \( m \).

\begin{algorithm}[tb]
   \caption{BeeRS}
   \label{alg:algorithm}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:} Tolerance $\varepsilon$, step size $\alpha^{(k)}$, momentum param.~$\gamma$
   \STATE $w^{(0)} \leftarrow$ Set initial network weights
   \WHILE{True}
    \STATE Compute $J_2F \big(w^{(k)} \big)$
    \STATE $y^\star \big( w^{(k)} \big) \leftarrow$ Solve \eqref{eq:pg-zero}
    \STATE \textbf{if} {$\zeta^{(k)} \leq \varepsilon$}~~\textbf{then}~~\text{Break}
    \STATE Compute $J_1F \big(w^{(k)},y^\star \big(w^{(k)} \big) \big)$
    \STATE Compute gradients $\nabla_{1,2} \varphi\big(w^{(k)}, y^\star\big(w^{(k)}\big)\big)$ 
    \STATE $v^{(k)} \leftarrow$ Solve \eqref{eq:v}
    \STATE $\nabla_w \varphi \big(w, y^\star(w) \big) \leftarrow$ Compute \eqref{eq:hypergradient-trick}
    \STATE $w^{(k+1)} \leftarrow$ Using \eqref{eq:momentum-pgd}
    \ENDWHILE
   \STATE {\bfseries Output:} 
   $w^\star$, 
   $\varphi\big(w^\star,y^\star \big(w^\star\big)\big)$
\end{algorithmic}
\end{algorithm}


Combining the equilibrium backpropagation \eqref{eq:v} with the chain rule \eqref{eq:hypergradient-trick} yields Algorithm \ref{alg:algorithm}, which we refer to as \emph{BeeRS} (\underline{Be}st Int\underline{e}rvention for \underline{R}ecommender \underline{S}ystems). 
As termination criterion we use
\begin{equation*}
\zeta^{(k)} \coloneqq   \frac{\lvert\varphi (w^{(k-1)}, y^\star (w^{(k-1)} )) - \varphi (w^{(k)}, y^\star (w^{(k)} ))\rvert}{\lvert\varphi (w^{(k-1)}, y^\star (w^{(k-1)} ))\rvert}  \leq \varepsilon
\end{equation*}
for some small tolerance $\varepsilon > 0$. Implementation details are given in Appendix \ref{subsec:implementation-detail}.

% -------------------------------------------------------------------------------------------------------------------------------
\section{Numerical Simulations \& Comparisons} \label{sec:numerics}

In this section, we demonstrate the effectiveness of our algorithm by deploying it on real-world and artificially-generated datasets. 
In Section \ref{subsec:scalability}, we study the scalability of \hyperref[alg:algorithm]{BeeRS} on both a CPU and a GPU. In Section \ref{subsec:ipopt}, we compare \hyperref[alg:algorithm]{BeeRS} to \texttt{IPOPT}, a state-of-the-art nonlinear programming solver that can directly solve the non-convex program \eqref{eq:high-level}, while in Section \ref{subsec:literature} we compare against a competing algorithm proposed in \cite{filterbubble}. 
Hardware specifications are given in Appendix \ref{app:hardware}, and the
subsequent choices for the step size $\alpha$ and momentum parameter $\gamma$ are justified in Appendix \ref{app:hyperparameters}.

% -------------------------------------------------------------------------------------------------------------------------------

\subsection{Scalability Study} \label{subsec:scalability}

\subsubsection{Problem Setup}
We consider a social network with directed connections. Let us consider the problem where a newly founded news agency, labeled as $\zeta$, wants to establish itself in the network by sharing content such as news articles. The news agency is neutral, which is encoded by the internal opinion $s_\zeta = 0$, while all other users (readers) might be biased with internal opinions $s_i \in [-1, 1]$. 
The network operator (the leader) has to decide how to deliver the additional content to the existing users,
with the goal of minimizing polarization in the network.
Additionally, the operator charges a fee to the news agency for distributing its content, which is proportional to the amount of content shared over the network. This expense can be viewed as an advertisement fee, reflecting the fact that getting space over the platform is costly.
The agency's advertising budget is bounded  by $b \in \mathbb{R}_{>0}$.

To model this, we introduce a new connection from every existing user \( i \) in the network to the news agency $\zeta$. Since the network is directed and the news agency does not have any outgoing connections, 
it remains neutral hence
$y_\zeta = s_\zeta = 0$. 
The connections from users to the news agency carry a weight $w_{i \zeta} \geq 0$, which is proportional to the share of $\zeta$'s content in user $i$'s feed. 
The goal of the leader is to compute weights that minimize polarization, measured as $\frac{1}{n} \sum_{i=1}^n y_i^2$, 
under the news agency's budget constraint $\sum_{i=1}^n w_{i \zeta} \leq b$. 

We can formalize this problem as
\begin{mini!}
    {\substack{y \in \mathbb{R}^n, w \in \mathcal{B}}} {\frac{1}{n} \textstyle\sum\nolimits_{i=1}^n y_i^2 \label{simple-problem-pol}} 
    {\label{eq:problem-ipopt}}
    {}
    \addConstraint{A(w)y}{= s \label{simple-problem-const-1}}
    \addConstraint{w_{ij} = }{w_{ij}^{(0)},~\forall i,j \in V \setminus \zeta \label{simple-problem-const-2}}
    \addConstraint{w_{\zeta j} = }{0,~\forall j \in V \label{simple-problem-const-4}}
    \addConstraint{\textstyle\sum\nolimits_{i = 1}^n w_{i\zeta}}{\leq b, \label{simple-problem-const-3}}
\end{mini!}
where the variance objective is a standard polarization metric \cite{1_29}, \eqref{simple-problem-const-1} ensures that opinions are in equilibrium and formed according to the FJ dynamics, 
\eqref{simple-problem-const-2} fixes the weights that are unrelated to the news agency to their original values \(w^{(0)}\), 
\eqref{simple-problem-const-4} ensures \(\zeta\) has no outgoing connections,
and \eqref{simple-problem-const-3} enforces the budget constraint of \(\zeta\).

We stress that weights that are fixed by constraints, as in \eqref{simple-problem-const-2} and \eqref{simple-problem-const-4},
are shown for clarity of exposition.
In our numerical implementation, we remove these weights to reduce the dimensionality of the problem.
Therefore, \eqref{eq:problem-ipopt} ends up with \( m = n - 1 \) decision variables for the weights.

\subsubsection{Numerical Results}
We solve problem \eqref{eq:problem-ipopt} on the DBLP dataset \cite{dblp-dataset}. It describes citation relationships between scientific articles: Nodes represent articles, and edges indicate citations between them, where the weight on the edge from node $i$ to node $j$ is defined as $w_{ij} = 1$ if article $i$ cites article $j$, and $w_{ij} = 0$ otherwise. By the nature of the dataset, there are no self-loops (a paper does not cite itself). We utilize the dataset topology by giving it a social network interpretation. Specifically, we reinterpret the nodes as users and the edges as a ``following`` relation: user $i$ follows user $j$ if and only if $w_{ij} > 0$. In this context, content shared by user $j$ appears in user $i$'s feed. We then assign internal opinions uniformly at random from the set $\{-1, 1\}$.

We consider \eqref{eq:problem-ipopt} for a varying number of users $n$ to study the computational cost of evaluating the hypergradient. To do so, we take the first $n$ nodes and corresponding internal opinions. We set $b = \frac{n}{10}$, $\alpha = 1000$, and $\gamma = 0.95$.
We execute 1 iteration of \hyperref[alg:algorithm]{BeeRS} for every problem size 100 times on the CPU and on the GPU. We report mean runtime $\pm$~1~standard deviation over 100 runs in Figure \ref{fig:scalability}.

\begin{figure}[ht]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[scale=1]{images/gpu_vs_cpu.pdf}}
\caption{The mean runtime and $\pm$ 1 standard deviation over 100 runs of 1 iteration of \hyperref[alg:algorithm]{BeeRS} on both a GPU and a CPU.}
\label{fig:scalability}
\end{center}
% \vskip -0.2in
\end{figure}

We observe that for small numbers of users, the CPU implementation has a lower per-iteration runtime. This is not surprising, given the additional overhead produced by moving computations to the GPU and by JAX's just-in-time compilation, among other reasons. However, the GPU implementation becomes faster for more than 100,000 users.

\subsubsection{Solving on the Entire Dataset} \label{subsec:entire-dblp}
Given the remarkable scalability of \hyperref[alg:algorithm]{BeeRS} on the GPU, we deploy it on the entire DBLP dataset consisting of 
$n~=~3,079,007$ nodes and $25,166,994$ edges. 
We solve \eqref{eq:problem-ipopt} 10 times with $b = \frac{n}{10}$, $\alpha = 10,000$, $\gamma = 0.9$, and $\varepsilon = \text{1e-3}$ on the GPU.
\hyperref[alg:algorithm]{BeeRS} achieves a polarization reduction of 38.6\%. The mean runtime until convergence is 664.5~s with standard deviation of 22.4 s. 

% -------------------------------------------------------------------------------------------------------------------------------

\subsection{Comparison with \texttt{IPOPT}} \label{subsec:ipopt}
We now consider the problem setup from Section \ref{subsec:scalability} and solve problem \eqref{eq:problem-ipopt} using the same dataset with \texttt{IPOPT}. 

% -------------------------------------------------------------------------------------------------------------------------------

\subsubsection{Numerical Results}
We compare the CPU implementation of \hyperref[alg:algorithm]{BeeRS} to the nonlinear solver \texttt{IPOPT} \cite{ipopt}, using the cyipopt \cite{cyipopt} wrapper for Python. For \texttt{IPOPT}, we use a tolerance of $\text{1e-3}$ and constraint-violation tolerance of $\text{1e-4}$. For \hyperref[alg:algorithm]{BeeRS}, we use $\varepsilon=\text{1e-3}$, $\gamma = 0.95$, and $\alpha~=~\frac{n}{100}$
proportional to $n$ as discussed in Appendix \ref{subsubsec:hyperparams_different_n}. We solve \eqref{eq:problem-ipopt} with both methods for a varying number of users $n$, and repeat each simulation 10 times. We set $b=\frac{n}{10}$.

We report the average runtime $\pm$ 1 standard deviation for different problem sizes for both approaches in Figure \ref{fig:ipopt-comp}. Note that the number of nodes considered here is significantly smaller than in Figure \ref{fig:scalability} due to the computational limitations of \texttt{IPOPT}.
We observe that \hyperref[alg:algorithm]{BeeRS} outperforms \texttt{IPOPT} for all simulated $n$, and by a larger margin for larger \( n \).
Indeed, the runtime difference ranges between roughly 1 and 3 orders of magnitude for the largest problems. 

In terms of solution quality, \hyperref[alg:algorithm]{BeeRS} attains the lowest cost in all cases, whereas the \texttt{IPOPT} implementation exhibits relative suboptimality\footnote{We define the relative suboptimality as $\frac{\lvert\varphi - \varphi^\star \rvert}{\lvert\varphi^\star\rvert}$, where $\varphi^\star$ is the best solution achieved by any of the two approaches.} of roughly 4e-3.
Detailed results are reported in Appendix~\ref{subsec:additional-ipopt}. 

\begin{figure}[ht]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[scale=1]{images/beers_vs_ipopt.pdf}}
\caption{The mean runtime and $\pm$ 1 standard deviation over 10 runs of \hyperref[alg:algorithm]{BeeRS} and \texttt{IPOPT} (until convergence) on a CPU.}
\label{fig:ipopt-comp}
\end{center}
% \vskip -0.2in
\end{figure}

% -------------------------------------------------------------------------------------------------------------------------------
\subsection{Comparison with the Literature} \label{subsec:literature}

Next, we compare \hyperref[alg:algorithm]{BeeRS} to the algorithm in \cite{filterbubble}. There, the authors propose an extension to the FJ dynamics, called NAD (\underline{N}etwork \underline{A}dministrator \underline{D}ynamics), to highlight the potential pitfalls of recommender systems that naively minimize disagreement, defined as $D(w,y) \coloneqq \frac{1}{2} \sum_{i=1}^n \sum_{\substack{j = 1}}^n w_{ij} (y_i - y_j)^2$.
In particular, they investigate the change in polarization in the network before and after modifying the weights to minimize disagreement
using NAD.

% -------------------------------------------------------------------------------------------------------------------------------

\subsubsection{Problem Setup}
The NAD follows an iterative approach, as summarized in Algorithm\ \ref{alg:nad} in Appendix \ref{app:nad}. In a first step, equilibrium opinions $y^\star(w^{(k)})$ are computed based on the current weights $w^{(k)}$.
In a second step, disagreement $D(w,y^\star(w^{(k)}))$ is minimized by tweaking the weights $w$ under the assumption that the opinions remain unaffected by the new weights and under convex constraints. In particular, the modified network should be similar to the original one, and the out-degree of each node should be preserved. The second step  is formalized as the convex program
\begin{mini!}
    {\substack{w^{(k+1)} \in \mathcal{B}}} {D(w^{(k+1)}, y^\star(w^{(k)})) \label{objective-reddit}} 
    {\label{eq:problem-reddit-simplified}}
    {}
    \addConstraint{ \textstyle\sum\nolimits_{j=1}^{n} (w_{ij}^{(k+1)} - w_{ij}^{(0)}) =0,}{\forall i \in V \label{fb-const-degree}}
    \addConstraint{\lVert W^{(k+1)} - W^{(0)}\rVert_F}{\leq \delta \lVert W^{(0)}\rVert_F, \label{fb-const-frob}}
\end{mini!}
where $\delta > 0$ is a parameter and $W^{(0)}$ denotes the adjacency matrix of the original network with weights $w_{ij}^{(0)}$. Intuitively, constraint \eqref{fb-const-frob} ensures that users of the social network do not perceive major differences in shared content and \eqref{fb-const-degree} guarantees that they spend constant time on the network. The iterations continue until $w^{(k)}$ converges.

\cite{filterbubble} note that in certain cases \hyperref[alg:nad]{NAD} fails to reduce disagreement and polarization $P(y)~\coloneqq~\sum_{i=1}^n (y_i - \frac{1}{n} \sum_{i = 1}^n y_i)^2$ increases. To mitigate the problem, they propose adding a regularization term $\lambda \lVert W \rVert_F^2$ with a parameter $\lambda > 0$ to the objective \eqref{objective-reddit}, but the method still struggles to reduce disagreement. We aim to improve upon these results.

We observe that \hyperref[alg:algorithm]{BeeRS} can be deployed on \eqref{eq:problem-reddit-simplified}, without the need to assume opinions are fixed during the optimization iterations. With \hyperref[alg:algorithm]{BeeRS}, we can directly estimate the effects of a weight change on the equilibrium opinions (and therefore the effect on the objective) through the sensitivity $Jy^\star(w)$. We readapt the original problem as
\begin{mini!}
    {\substack{y \in \mathbb{R}^n, w \in \mathcal{B}}} {\frac{1}{2} \textstyle\sum\nolimits_{i=1}^n 
    \textstyle\sum\nolimits_{\substack{j = 1}}^n w_{ij} (y_i - y_j)^2 \label{optimizationProblem2}} 
    {\label{eq:problem-reddit}}
    {}
    \addConstraint{\eqref{fb-const-degree}}{\text{ and } \eqref{fb-const-frob} \label{reddit-problem-const-0}}
    \addConstraint{A(w)y}{= s. \label{reddit-problem-const-1}}
\end{mini!}
We add constraint \eqref{reddit-problem-const-1} to take into account the dynamic opinions $y$.
We use $\delta = 0.2$ for all subsequent results.

\subsubsection{Case Study: Toy Example} \label{subsec:toy-example}

To better understand how the two optimization strategies compare with each other, we use a minimal network that allows for disagreement. It consists of two nodes with internal opinions $s_0 = 1$ and $s_1 = 0$, connected by an undirected\footnote{We model the undirected edge weight $w$ with the two variables $w_{01}$ and $w_{10}$, and the constraint $w_{01} = w_{10}$.} edge with initial weight $w^{(0)} = 1$. In this network, we aim to solve \eqref{eq:problem-reddit} without constraint \eqref{fb-const-degree} (as enforcing this constraint would restrict the allowed weight to $w = w^{(0)} = 1$). To evaluate the behavior of \hyperref[alg:nad]{NAD} we first compute the resulting equilibrium opinions by solving \eqref{eq:pg-zero} for appropriate $A(w)$ (\hyperref[line:step1]{line 2}). We find $y_0^\star(w) = \frac{2}{3}$ and $y_1^\star(w) = \frac{1}{3}$. Disagreement is given by $D(w,y^\star(w))=0.11$. In a second step, \hyperref[alg:nad]{NAD} minimizes disagreement by keeping the opinions constant (\hyperref[line:step2]{line 3}). Recalling the definition of disagreement, we see that $D(w,y)$ decreases for fixed $y$ if and only if $w$ is decreased. Therefore, \hyperref[alg:nad]{NAD} decreases $w$, in order to minimize disagreement. Then, \hyperref[alg:nad]{NAD} proceeds by computing the equilibrium opinions under the updated weight $w^{(k+1)}$, followed by a reduction of the edge weight $w$ to minimize disagreement for fixed opinions in a second step. It follows that the edge weight is decreased until constraint \eqref{fb-const-frob} is tight, which, for $\delta = 0.2$, occurs when $w = 0.8$. 


On the other hand, \hyperref[alg:algorithm]{BeeRS} updates the weight in the direction of steepest descent, taking into account the effect on opinions. By deploying it on such a simple problem, we observe that, as opposed to \hyperref[alg:nad]{NAD}, \hyperref[alg:algorithm]{BeeRS} \emph{increases} the weight to $w = 1.2$.  To compare the performance of \hyperref[alg:algorithm]{BeeRS} and \hyperref[alg:nad]{NAD} in terms of disagreement, we compute equilibrium opinions for all $w \in [0, 2]$ by solving \eqref{eq:pg-zero}, and we illustrate the resulting disagreement in Figure \ref{fig:algorithm-comparison}. We mark the solution of both algorithms, and we observe that \hyperref[alg:algorithm]{BeeRS} outperforms \hyperref[alg:nad]{NAD}. We argue that the reason for this discrepancy comes from the fact that our algorithm is able to anticipate the effect of changing weights on the equilibrium opinions and, hence, move in a direction that minimizes disagreement. By contrast, \hyperref[alg:nad]{NAD} myopically optimizes weights, neglecting the dynamics of opinions, and thus exacerbates disagreement.

\begin{figure}[ht]
% % \vskip 0.2in
\begin{center}
\centerline{\includegraphics[scale=1]{images/algorithm_comparison.pdf}}
\caption{Behavior of \hyperref[alg:algorithm]{BeeRS} and \hyperref[alg:nad]{NAD} (without regularization) in a toy example network.
We plot disagreement as a function of weights $w$ for internal opinions $s_0 = 1$ and $s_1 = 0$. The feasible region is shown in white.}
\label{fig:algorithm-comparison}
\end{center}
% \vskip -0.2in
\end{figure}



\subsubsection{Numerical Results: Addressing a Real-World Problem}

Next, we deploy both algorithms on real-world data. We use the undirected Reddit dataset \cite{reddit}, where external opinions $y$ were extracted by sentiment analysis. Analogously to \cite{filterbubble}, we set the internal opinions\footnote{\cite{filterbubble} use $s \in [-1,1]$ in their formulation. However, consistent with their implementation \cite{filterbubble-repo}, we adopt $s \in [0, 1]$.} $s \in [0,1]$ by computing $s = A(w)y$. The dataset consists of 556 nodes and 8969 edges. We remove 3 disconnected users, leading to a total of 553 users. The resulting problem has $m = n(n-1) = 305,256$ upper-level variables. Since the edges are undirected, we set half of the variables through a constraint, as shown in the toy example.

We deploy \hyperref[alg:algorithm]{BeeRS} on a CPU\footnote{The current implementation of \hyperref[alg:algorithm]{BeeRS} does not support the Frobenius-norm constraint on the GPU.} with $\varepsilon = \text{1e-3}$, $\gamma = 0.95$, and $\alpha=\frac{m}{100} = 3052.56$, 
(see Appendix \ref{subsubsec:hyperparams_different_n}). We use the default implementation of \hyperref[alg:nad]{NAD} from \cite{filterbubble-repo}, making minor modifications to adapt the code to our specific problem. We run both the default \hyperref[alg:nad]{NAD} and \hyperref[alg:nad]{NAD} with regularization $\lambda = 0.2$, referred to as \hyperref[alg:nad]{NAD$^\star$}. We summarize the runtime as well as the change in polarization and disagreement of each algorithm in Table \ref{filterbubble-table}. 
% We observe that, among the three algorithms, there are substantial differences in performance.
We observe substantial differences in performance among the three algorithms.


\begin{table}[t]
\caption{Comparison between \hyperref[alg:algorithm]{BeeRS}, \hyperref[alg:nad]{NAD} , and \hyperref[alg:nad]{NAD$^\star$} with $\lambda~=~0.2$. The runtime is averaged over 10 executions.}
\label{filterbubble-table}
% \vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccc}
\toprule
 & \hyperref[alg:algorithm]{BeeRS} & \hyperref[alg:nad]{NAD} & \hyperref[alg:nad]{NAD$^\star$}   \\
\midrule
Mean runtime, s & 82.9 & 35.9 & 27.3  \\
         Min. runtime, s & 82.2 & 34.2 & 25.8 \\
         Max. runtime, s & 86.1 & 38.5 & 28.3 \\
Change in pol. $P$& $-40.2\%$ & $+128.7\%$ & $-0.7\%$\\
 Change in disag. $D$ & $-21.5\%$ & $+41.4\%$ & $+0.3\%$ \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
% \vskip -0.1in
\end{table}

Contrary to \cite{filterbubble}, \hyperref[alg:algorithm]{BeeRS} achieves a decrease in disagreement: the objective of \hyperref[alg:nad]{NAD} and problem \eqref{eq:problem-reddit}. Further, the effect on polarization is different, as \hyperref[alg:algorithm]{BeeRS} leads to a significant decrease of polarization, whereas \hyperref[alg:nad]{NAD} without regularization increases polarization. Although \hyperref[alg:nad]{NAD$^\star$} improves on this aspect, it is still outperformed by \hyperref[alg:algorithm]{BeeRS} in terms of disagreement (and polarization). However, the superior performance of \hyperref[alg:algorithm]{BeeRS} comes at the price of an increased runtime. 

Next, we study the performance mismatch between \hyperref[alg:algorithm]{BeeRS} and \hyperref[alg:nad]{NAD}. To do so, we visualize the intervention mechanism, i.e., the change of weights $w_{ij} - w_{ij}^{(0)}$, in Figures \ref{fig:our_intervention}, \ref{fig:comp_intervention}, and \ref{fig:comp_intervention_reg} for \hyperref[alg:algorithm]{BeeRS}, \hyperref[alg:nad]{NAD}, and \hyperref[alg:nad]{NAD$^\star$}, respectively.

\begin{figure*}[!htb]
    % \vskip 0.2in
     \centering
     \begin{subfigure}[b]{0.33\textwidth}
         \includegraphics[width=\textwidth]{images/our_intervention.png}
         \caption{\hyperref[alg:algorithm]{BeeRS}}
         \label{fig:our_intervention}
     \end{subfigure}\hfill
     \begin{subfigure}[b]{0.33\textwidth}
         \includegraphics[width=\textwidth]{images/comp_intervention.png}
         \caption{\hyperref[alg:nad]{NAD} without regularization}
         \label{fig:comp_intervention}
     \end{subfigure}\hfill
     \begin{subfigure}[b]{0.33\textwidth}
         \includegraphics[width=\textwidth]{images/comp_intervention_reg.png}
         \caption{\hyperref[alg:nad]{NAD} with regularization}
         \label{fig:comp_intervention_reg}
     \end{subfigure}\hfill
        \caption{Optimal edge weight modification in relation to external opinions connected by edge computed by three approaches. The horizontal and vertical axes show the external opinion before intervention at the tail and head of an edge, respectively.
        The color encodes the change of edge weight during the intervention, i.e., $w_{ij} - w_{ij}^{(0)}$.}
        \label{fig:three graphs}
        % \vskip -0.2in
\end{figure*}

All figures show the external opinion of users before the intervention on the horizontal and vertical axis. 
The x- and y-coordinate of each point represents the opinion of the user on the tail and head of the edge, respectively.
The color of each point encodes the intervention, i.e., the weight change of the corresponding edge. Since we consider an undirected network, the influence over edges is bidirectional and the plots are symmetric. As we can modify the weight of all edges (even the ones not present in the initial configuration), there are roughly 300,000 points to be plotted. To enhance interpretability of the figures, we order all interventions by increasing absolute value and plot them increasingly on top of each other, i.e., the largest weight changes are drawn on top and are therefore visible. Note that, a large number of edges are not visible as they undergo no change in weight. 

In contrast to Figure \ref{fig:our_intervention} and  \ref{fig:comp_intervention}, we cannot identify any obvious intervention for \hyperref[alg:nad]{NAD$^\star$} in Figure \ref{fig:comp_intervention_reg}. The intervention seems to lack a specific pattern, although we note that many edges experience a large decrease in weight (dark blue dots) and none experience a large increase. 
Hence, we subsequently focus on \hyperref[alg:algorithm]{BeeRS} and \hyperref[alg:nad]{NAD} without regularization.

Notably, \hyperref[alg:algorithm]{BeeRS} and \hyperref[alg:nad]{NAD} seem to behave exactly opposite. \hyperref[alg:algorithm]{BeeRS} mainly reinforces connections between above- and below-average opinions and weakens edges connecting opinions of the same bias. Conversely, \hyperref[alg:nad]{NAD} strengthens edges between similar opinions and weakens the ones between opposing views. 

This behavior aligns with the observations in Section \ref{subsec:toy-example} and explains the superior performance of \hyperref[alg:algorithm]{BeeRS} 
in minimizing disagreement and polarization.
The intervention mechanism followed by \hyperref[alg:nad]{NAD} does not encapsulate the fact that, when we connect opposing opinions under the FJ dynamics, more moderate opinions are formed through averaging, a favorable phenomenon in terms of minimizing disagreement and polarization. This is in line with the weight update rule of \hyperref[alg:nad]{NAD} (\hyperref[line:step2]{line 3}) that ignores the dynamics. Instead, the backpropagation through equilibrium opinions step of \hyperref[alg:algorithm]{BeeRS} is able to explicitly incorporate and exploit this effect.

% -------------------------------------------------------------------------------------------------------------------------------
\section{Conclusion and Future Work} \label{sec:conclusion}
We formulated the task of finding the best network intervention given any differentiable objective function under FJ dynamics as an optimization problem with non-convex constraints,
and we solve it with a gradient-based algorithm.
We demonstrated the flexibility and scalability of our method by successfully deploying it on various optimization problems of different sizes. 
Our algorithm outperforms a state-of-the-art solver in terms of runtime by more than three orders of magnitude, while achieving the same solution quality.
\newline
One limitation of our algorithm is the convexity assumption on $\mathcal{W}$, which precludes the use of binary decision variables: Is an edge present or not? 
Our framework could incorporate binarty decisions by relaxing the binary constraints or employing heuristics. 
Preliminary numerical experiments indicate this to be a promising future research direction.

\newpage

\bibliographystyle{plainnat.bst}
\bibliography{example_paper}

\newpage

\section{Appendix}


\subsection{Computation of $J_1F(w, y)$} \label{subsec:computing-j1f}
Combining the definition of $A(w)$ in \eqref{eq:pg-zero} with the definition $F(w,y) := A(w)y -s$, we arrive at
\begin{gather} \label{eq:f-for-j1f}
    F(w,y) = 
    \underbrace{\begin{bmatrix}
        1+\sum_{j \in V} w_{ij} & -w_{12} & \cdots & -w_{1n}\\
        \vdots & & \ddots & \vdots\\
        -w_{n1} & -w_{n2} & \cdots &  1+\sum_{j \in V}w_{ij}
    \end{bmatrix}}_{A(w)}
    y - s.
\end{gather}
Now we can compute $J_1F(w,y)$, the partial Jacobian of $F(w,y)$ with respect to $w$, and show that it is continuous in both arguments. Recall the definition $w \coloneqq [w_{12}, \ldots, w_{1n}, w_{21}, \ldots, w_{2n}, \ldots, w_{n1}, \ldots w_{n(n-1)}]^\top \in \mathbb{R}^{m}$ with $m = n(n-1)$ (there are no self-loops, thus we drop the entries $w_{ii}$ for computational efficiency).
\begin{lemma} \label{lemma:j1f}
    The partial Jacobian of $F(w,y)$ with respect to $w$, i.e., $J_1F(w,y) \in \mathbb{R}^{n\times m}$, is continuous in both arguments.
\end{lemma}
\begin{proof}
    Considering \eqref{eq:f-for-j1f}, it is easy to see that $J_1F(w,y)$ is given by
    \begin{gather} \label{eq:j1f}
        \scalebox{0.85}{ 
        $J_1F(w,y) =
        \begin{bmatrix}
            y_1 - y_2 & y_1 - y_3 & \cdots & y_1 - y_n & 0 & \cdots & 0 &  0 & 0 & \cdots & 0 \\
             & & & & & \mathclap{\vdots} & & & & &  \\
            0 & 0 & \cdots &  0 & 0 & \cdots & 0 & y_n - y_1 & y_n - y_2 & \cdots & y_n - y_{n-1}
        \end{bmatrix}$},
    \end{gather}
    which is continuous.
\end{proof}

\subsection{Implementation Details} \label{subsec:implementation-detail}
We implement the algorithm in Python 3.12. We provide both a GPU- and a CPU-compatible implementation. The GPU version performs most computations with JAX \cite{jax2018github} and has some NumPy \cite{numpy} dependencies. We solve the linear systems \eqref{eq:pg-zero} and \eqref{eq:v} with a jax.scipy implementation of the GMRES algorithm \cite{GMRES}.
For the projection, we use the jaxopt \cite{jaxopt_implicit_diff} BoxOSQP solver. JAX functions are just-in-time compiled if applicable. We represent the adjacency matrix of the network and the Jacobians as sparse csr\_array, which allows efficient handling of large datasets. The upper-level gradients $\nabla_{1,2} \varphi$ are computed with the automatic differentiation (autodiff) functionalities of JAX.

The CPU version is based on NumPy. Unlike the GPU implementation, we allow both sparse and dense representations of the network's adjacency matrix and the Jacobians. For dense matrices, we rely on NumPy to solve the linear systems \eqref{eq:pg-zero} and \eqref{eq:v}, for sparse matrices, we use a SciPy \cite{2020SciPy-NMeth} implementation of the GMRES algorithm. 
In both cases, we use CVXpy \cite{diamond2016cvxpy, agrawal2018rewriting} to perform the projections with the following solvers: Clarabel \cite{Clarabel_2024} for quadratic programs, and SCS \cite{scs} for second-order cone programs. The upper-level gradients $\nabla_{1,2} \varphi$ are computed with the automatic differentiation (autodiff) functionalities of PyTorch \cite{pytorch}.

\subsection{Hardware Specifications} \label{app:hardware}
Experiments were conducted on a Windows 11 machine using Windows Subsystem for Linux (WSL) version 2, either on an Intel\textsuperscript{\textregistered} Core\texttrademark i7-11700F CPU at 2.50 GHz with 8 cores and 16 logical processors and 32 GB of RAM or on a NVIDIA GeForce RTX 3060 Ti GPU, with 8 GB of GDDR6 video memory, running CUDA 12.6 and cuDNN 9.5.1. 

% % -------------------------------------------------------------------------------------------------------------------------------
\subsection{Choosing the Hyperparameters -- Ablation Study} \label{app:hyperparameters}

As discussed in Section \ref{sec:algorithm}, \hyperref[alg:algorithm]{BeeRS} employs projected gradient descent with momentum \eqref{eq:momentum-pgd}. This method uses two hyperparameters, namely step size $\alpha$ and momentum parameter $\gamma$. We conduct an ablation study to find parameters leading to satisfying results in terms of runtime and minimum cost.

We consider the same setup as in Section \ref{subsec:scalability}, i.e., problem \eqref{eq:problem-ipopt} on the DBLP dataset version 10 \cite{dblp-dataset}. We consider the first $n = 1000$ users and set $b = 100$. We initialize all variables, i.e., all connections to the influencer, with the value 0. We use a tolerance of $\varepsilon = \text{1e-3}$.

We now solve this problem with \hyperref[alg:algorithm]{BeeRS}. We grid the hyperparameters for values of $\alpha \in (0, 500]$ and $\gamma \in [0, 0.95]$. To enhance visibility, we display only some of the grid points in Figure \ref{fig:ablation-study}, in particular $\alpha \in \{ 1, 2, \ldots, 50, 60, \ldots, 100, 200, \ldots, 500 \}$ and $\gamma \in \{0.0, 0.3, 0.6, 0.95\}$. In the left subplot, we show the number of iterations until convergence on the vertical axis as a function of $\alpha$ on the horizontal axis. According to the legend, we plot a distinct line for every choice of $\gamma$. In the right subplot, we show analogously the minimum achieved cost on the vertical axis. Due to the deterministic nature of \hyperref[alg:algorithm]{BeeRS}, we run the simulation with every set of distinct $\alpha$ and $\gamma$ exactly once.

\begin{figure*}[ht]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{images/ablation_study_alt.pdf}}
\caption{We vary the step size $\alpha$ and display the resulting number of iterations (left) and the achieved minimum cost (right) for some momentum parameters $\gamma$.}
\label{fig:ablation-study}
\end{center}
% \vskip -0.2in
\end{figure*}

We observe that, for small values of $\alpha$, we achieve convergence with fewer iterations for larger values of $\gamma$ than for smaller values of $\gamma$. For larger values of $\alpha$, the number of iteration until convergence first get closer for different values of $\gamma$, and some oscillations begin to appear for $\gamma = 0.95$, and later, the number of iterations until convergence starts to increase again.

Regarding the minimum cost achieved, we observe that for small values of  $\alpha$, $\gamma=0.95$ clearly outperforms all other choices. When $\alpha$ is increased, the performance for other values of $\gamma$ improves, and at a medium value of $\alpha$, small values of $\gamma$ achieve a lower cost than $\gamma = 0.95$. This is partly due to the fact that the minimum cost for $\gamma = 0.95$ starts to increase at medium values of $\alpha$. For large values of $\alpha$, the minimum achieved cost abruptly rises for some values of $\gamma$, and gently increases for other values of $\gamma$.

Considering these results, a small value of $\alpha$, e.g., $\alpha = 10$, together with $\gamma = 0.95$ provides a good compromise between the number of iterations until convergence and the achieved minimum cost, and effectively avoids numerical instabilities causing convergence issues for larger values of $\alpha$.

\subsubsection{Choosing $\alpha$ and $\gamma$ for different Number of Users $n$} \label{subsubsec:hyperparams_different_n}

As we vary the number of users $n$ during the simulations carried out in Section \ref{sec:numerics}, we deviate from the value $n = 1000$, and thus invalidate the ablation study from the previous section. In Section \ref{subsec:scalability}, we only perform the first iteration of \hyperref[alg:algorithm]{BeeRS}. We argue that the step size is irrelevant in this case, as it at most marginally affects the per-iteration runtime. For simulations in Section \ref{subsec:ipopt}, the step size is more important, as we run \hyperref[alg:algorithm]{BeeRS} until convergence. Thus, the total runtime is directly related to the number of iterations, which can be influenced by choosing the step size. To provide a fair comparison between different numbers of users $n$, we want to keep the number of iterations in a comparable range, such that the increase in total runtime can be attributed to a higher per-iteration runtime.

Through experiments, we observe that we can keep the number of iterations until convergence in a comparable range if we choose step size $\alpha$ proportional to $n$. This is supported by Figure \ref{fig:hypergrad-norm}, where we show for problem \eqref{eq:problem-ipopt} the $\ell_2$ norm of the hypergradient of the initial iteration on the left vertical axis, the number of iterations until convergence for two different step sizes on the right vertical axis, both as a function of the number of users $n$ on the horizontal axis. We note that a constant step size leads to an increasing number of iterations until convergence, while the step size $\alpha = \frac{n}{100}$ keeps the number of iterations until convergence almost constant. This can be explained by the observation that the norm of the hypergradient decreases with increasing $n$. Combining the optimal step size from the previous section ($\alpha = 10$ for $n = 1000$) with the observation that $\alpha \propto n$ leads to small variations in iterations until convergence, we select $\alpha = \frac{n}{100}$.

The shrinking hypergradient has an intuitive explanation. The larger the number of users in a social network, the smaller the effect of the individual user on the overall polarization. Therefore, tweaking only the weight associated with some user $i$ has a diminishing effect on the objective, which is captured by the hypergradient's components.

Note that we use slightly different $\alpha$ and $\gamma$ for the Simulation in Section \ref{subsec:entire-dblp}. Instead of $\alpha = \frac{n}{100} \approx 30,000$ and $\gamma = 0.95$ as suggested above, we use $\alpha = 10,000$ and $\gamma = 0.9$, as the previous values lead to oscillations in the objective value when approaching the optimal solution. We could mitigate these effects by lowering both $\alpha$ and $\gamma$.

\begin{figure*}[ht]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[]{images/step_size.pdf}}
\caption{We plot for problem \eqref{eq:problem-ipopt} the $\ell_2$ norm of the hypergradient of the initial iteration on the left vertical axis, and the number of iterations until convergence for a linear and constant step size on the right vertical axis for a range of number of users $n$ on the horizontal axis.}
\label{fig:hypergrad-norm}
\end{center}
% \vskip -0.2in
\end{figure*}

We remark that the previous considerations are not necessarily valid for the simulations in Section \ref{subsec:literature} due to the different problem formulation. However, similar to the previous cases, we select $\alpha = \frac{m}{100}$ and $\gamma = 0.95$. Note that we replaced $n$ by $m = n(n-1)$, since every user has $n - 1$ decision variables in Section \ref{subsec:literature}, compared to 1 decision variable per user in Section \ref{subsec:ipopt}. We argue that a step size proportional to the number of decision variables is an equally valid choice, justified by the intuition that, as the number of variables increases, the influence of any single variable on the objective function diminishes. Additionally, since the number of variables is not varied within Section \ref{subsec:literature}, we argue that the optimal choice for $\alpha$ is less important than in Section \ref{subsec:ipopt}, where we want a similar number of iterations until convergence for different problem sizes. Finally, we observe that the choice $\alpha = \frac{m}{100}$ and $\gamma = 0.95$ lead to satisfying results (convergence after 5 iterations, not oscillations), which makes the search for other parameter values obsolete.

\subsection{Further Results of Section \ref{subsec:ipopt}} \label{subsec:additional-ipopt}

In addition to the results provided in Section \ref{subsec:ipopt}, we provide in Table \ref{ipopt-table} the relative suboptimality for the compared approaches. We define the relative suboptimality as
\begin{equation*}
    \frac{\lvert\varphi - \varphi^\star \rvert}{\lvert\varphi^\star\rvert}, 
\end{equation*}
where $\varphi^\star$ is the best solution achieved by any of the two approaches.

\begin{table}[H]
\caption{Comparison between \hyperref[alg:algorithm]{BeeRS} and \texttt{IPOPT} in terms of relative suboptimality.}
\label{ipopt-table}
% \vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccccc}
\toprule
Number of users $n$ & 100 & 200 & 300 & 400 & 500 & 1000 & 2000 \\
\midrule
Rel. subopt. of \texttt{IPOPT} & $4.63\mathrm{e}\text{-3}$ & $4.42\mathrm{e}\text{-3}$ & $4.67\mathrm{e}\text{-3}$ & $4.87\mathrm{e}\text{-3}$ & $4.72\mathrm{e}\text{-3}$ & $4.30\mathrm{e}\text{-3}$ & $4.64\mathrm{e}\text{-3}$\\
Rel. subopt. of \hyperref[alg:algorithm]{BeeRS} &0 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
% \vskip -0.1in
\end{table}

\subsection{Network Administrator Dynamics - Alg.\ \ref{alg:nad}} \label{app:nad}
In the following, we repeat the algorithm of \cite{filterbubble}.

\begin{algorithm}[H]
   \caption{NAD (\underline{N}etwork \underline{A}dministrator \underline{D}ynamics)}
   \label{alg:nad}
\begin{algorithmic}[1]
   \WHILE{not converged}
    \STATE \label{line:step1} $y_k \leftarrow$ For given network weights $w$, compute the equilibrium opinions with \eqref{eq:pg-zero} 
    \STATE \label{line:step2} $w_k \leftarrow$ For fixed opinions $y$, solve \eqref{eq:problem-reddit-simplified} 
    \STATE $k \leftarrow k+1$
    \ENDWHILE
\end{algorithmic}
\end{algorithm}


\end{document}