\section{Related Works}
Adversarial attacks on GNNs aim to exploit model vulnerabilities, resulting in errors or inaccurate predictions. These attacks are generally categorized into evasion, poisoning, and backdoor attacks, each characterized by distinct methodologies and consequences. Evasion attacks occur during the test phase, where adversaries manipulate the input graph data to lead the GNN to make incorrect predictions~\cite{Nettack,TDGIA,MinMax}. These manipulations could involve strategic alterations in the graph structure or node features, significantly affecting the performance of the GNN. The stealth of evasion attacks, which do not require changes to the trained model, makes them particularly challenging to detect. Following evasion attacks, poisoning attacks are conducted during the training phase of the GNN. In this scenario, attackers inject the training set with crafted data~\cite{RL-S2V,NIPA}, either by adding, deleting edges, or modifying nodes. These alterations subtly distort the training process, leading the model to unwittingly integrate these adversarial modifications. The performance of a model consequently deteriorates, introducing specific errors or biases, undermining its reliability and accuracy. Lastly, backdoor attacks are implemented by inserting hidden triggers in the GNN during its training phase~\cite{Backdoor_Attack_1,Backdoor_Attack_2,UGBA}. When activated in new data, these triggers cause the model to generate incorrect results, while maintaining normal functionality under standard conditions. This makes backdoor attacks particularly deceptive.

Unfortunately, none of the existing attack methods can fully demonstrate their capabilities in practical scenarios. Attackers do not have the capability to modify the original graph in evasion and poisoning attacks. Even with the utilization of relatively accessible malicious injection techniques, the failure to generate links immediately undermines the attack, leading to a considerable degradation in their efficacy. Therefore, we propose leveraging the link recommender to facilitate the generation of links between the target victim and injected nodes. The involvement of link recommender enhances the likelihood of establishing connections between the aggressor subgraph and the target victim nodes, consequently leading to a higher success rate in practical attacks.