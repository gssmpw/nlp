\onecolumn

\section{Experimental Setup}
\label{appx:experiment-details}

\subsection{Aspect Verifier Subsets}
\label{appx:experiment-details:verifier-subsets}
\autoref{tab:verifier-subsets} outlines all 20 aspect verifiers in $\mathcal{M}$ and which ones were selected for each domain-specific subset $\mathcal{M}^d$.

\begin{table*}[h!]\centering
\ra{1.3}
\begin{tabular}{@{}llllcccc@{}}
\toprule
\textbf{Base Model} & \textbf{Aspect to Verify} & \textbf{Verification Strategy} & \textbf{MATH} & \textbf{MMLU-Pro} & \textbf{GPQA} & \textbf{HumanEval} \\
\midrule
\multirow{10}{*}{GPT-4o-mini} 
 & Mathematical Correctness & Step-by-Step & & \checkmark & \checkmark & \checkmark \\
 & Logical Soundness & Step-by-Step & & \checkmark & \checkmark & \checkmark \\
 & Factual Correctness & Step-by-Step & & & & \checkmark \\
 & Unit Conversions & Step-by-Step & \checkmark & & \checkmark & \checkmark \\
 & General Correctness & Direct Approval & & & & \checkmark \\
 & General Correctness & Summarize Solution & \checkmark & & & \\
 & General Correctness & Explain Differently & & \checkmark & \checkmark & \checkmark \\
 & General Correctness & Edge Cases & \checkmark & \checkmark & & \checkmark \\
 & General Correctness & Common Mistakes & \checkmark & \checkmark & & \\
 & General Correctness & Domain Knowledge & \checkmark & \checkmark & & \checkmark \\
\midrule
\multirow{10}{*}{Gemini-1.5-Flash} 
 & Mathematical Correctness & Step-by-Step & & & & \\
 & Logical Soundness & Step-by-Step & & & & \checkmark \\
 & Factual Correctness & Step-by-Step & & & & \\
 & Unit Conversions & Step-by-Step & & \checkmark & \checkmark & \checkmark \\
 & General Correctness & Direct Approval & & & & \checkmark \\
 & General Correctness & Summarize Solution & & & & \checkmark \\
 & General Correctness & Explain Differently & & & \checkmark & \checkmark \\
 & General Correctness & Edge Cases & \checkmark & & & \\
 & General Correctness & Common Mistakes & & \checkmark & \checkmark & \\
 & General Correctness & Domain Knowledge & & & & \checkmark \\
\midrule
\multicolumn{3}{l}{\textbf{Total Verifiers Used}} & \textbf{6} & \textbf{8} & \textbf{7} & \textbf{14} \\
\bottomrule
\end{tabular}
\caption{Overview of all aspect verifiers in $\mathcal{M}$. Checkmarks (\checkmark) indicate which verifiers were selected for each domain-specific subset $\mathcal{M}^d$. The table shows all 20 combinations of base models, aspects to verify, and verification strategies that we created (10 per base model). The bottom row shows the number of verifiers $|\mathcal{M}^d|$ for each domain.}
\label{tab:verifier-subsets}
\end{table*}

\subsection{Generator LLMs}
\label{appx:experiment-details:generator-models}
We evaluate eight generator LLMs (four closed-source models and four open-source models) and restrict our set of generator models to those released before September 2024. For closed-source models, we use gemini-1.5-flash-001 and gemini-1.5-pro-001 \citep{team2024gemini}, as well as gpt-4o-mini-2024-07-18 and gpt-4o-2024-08-06 \citep{achiam2023gpt}. For open-source models, we use Mistral-7B-v0.3 \citep{jiang2023mistral}, Llama-3.1-8B \citep{dubey2024llama}, Gemma-2-9B, and Gemma-2-27B \citep{team2024gemma}.

\subsection{Reward Model Baseline}
\label{appx:experiment-details:reward-model-baseline}

Our reward model verification baseline (BoN-RM) uses \texttt{Skywork/Skywork-Reward-Llama-3.1-8B-v0.2}~\citep{liu2024skywork}, the top scoring open-source 8B reward model on RewardBench~\citep{lambert2024rewardbench} at the time of writing. This pretrained reward model outperforms numerous larger models including 70B and 340B models, and can be run on academic-scale compute.

\subsection{Prompts}
\label{appx:experiment-details:prompts}
For generator LLMs, we use a consistent prompt format across all models while varying the content by domain. \autoref{tab:generator-prompts} contains these domain-specific prompts.

For aspect verifiers, each prompt consists of two components:
\begin{enumerate}[leftmargin=2em, nosep]
    \item A domain-dependent system prompt (\autoref{tab:av-system-prompts}) that establishes the verification context (e.g., mathematical problems, multiple-choice questions, or code implementations)
    \item A domain-independent verification prompt (\autoref{tab:av-prompts-part1} and \autoref{tab:av-prompts-part2}) that specifies the aspect to verify and verification strategy
\end{enumerate}

This two-part structure allows us to combine any aspect-strategy verification method with any domain while maintaining consistent evaluation criteria across base models.

\section{Additional Results}
\label{appx:additional-results}
\autoref{appx:tab:all-vs-baselines} compares BoN-MAV using all 20 aspect verifiers in $\mathcal{M}$ (without domain-specific engineering) against self-consistency and reward model verification. Even without engineering domain-specific subsets $\mathcal{M}^d$, combining all verifiers remains competitive with baseline methods.

\begin{table*}[h!]\centering
\ra{1.3}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
 & \multicolumn{4}{c}{MMLU-Pro} & \multicolumn{4}{c}{GPQA (diamond)} \\
\cmidrule(r){2-5} \cmidrule(l){6-9}
\textbf{{Generator Model}} & MAV-All & Cons & RM & pass@1 & MAV-All & Cons & RM & pass@1\\ \midrule
\textbf{Gemini-1.5-Flash} & \underline{\textbf{65.7}} & 63.3 & 60.7 & 59.3 & 41.0 & 40.0 & \underline{\textbf{46.0}} & 42.0 \\
\textbf{Gemini-1.5-Pro} & 70.3 & \underline{\textbf{71.7}} & 69.3 & 68.0 & \underline{\textbf{49.0}} & 45.0 & \underline{\textbf{49.0}} & 45.0 \\
\textbf{GPT-4o-mini} & \underline{\textbf{65.3}} & 63.7 & 62.7 & 62.3 & \underline{\textbf{49.0}} & 48.0 & 44.0 & 38.0 \\
\textbf{GPT-4o} & 75.3 & \underline{\textbf{76.3}} & 72.7 & 73.3 & 55.0 & \underline{\textbf{59.0}} & 58.0 & 54.0 \\
\bottomrule
\end{tabular}
\caption{
Performance (accuracy \%) of BoN-MAV with all 20 aspect verifiers (without any tuning, labeled as MAV-all in the table) compared to reward model verification (RM), self-consistency (Cons), and the base pass@1 accuracy of the generator LLM. Using all verifiers without domain-specific tuning remains competitive with reward model verification and self-consistency.
}
\label{appx:tab:all-vs-baselines}
\end{table*}


\section{Additional Illustrations}
\label{appx:extra-mav-illustrations}
\autoref{appx:fig-mav-extra-1}, \autoref{appx:fig-mav-extra-2}, and \autoref{appx:fig-mav-extra-3} provide additional examples of how multiple aspect verifiers evaluate a single candidate output. \autoref{appx:fig-mav-extra-1} demonstrates verification using multiple strategies with a single base model on MATH~\citep{hendrycks2021measuring}. \autoref{appx:fig-mav-extra-2} shows verification of a coding solution from HumanEval~\citep{chen2021evaluating}. \autoref{appx:fig-mav-extra-3} illustrates verification of a correct solution from GPQA (diamond)~\citep{rein2023gpqa}, showing how different base models can assess the same aspect differently. Each figure follows the same format as \autoref{fig:mav-illustration-single-solution} from the main paper.





\begin{figure*}[h!]
\centering
\includegraphics[width=\linewidth]{figures/mav_illustration_single_solution_MATH_2.pdf}
\caption{\textbf{Multi-agent verification for a single solution (additional example).} An illustration similar to \autoref{fig:mav-illustration-single-solution}. Five different aspect verifiers evaluate an incorrect MATH~\citep{hendrycks2021measuring} solution sampled from Gemini-1.5-Pro. All verifiers use Gemini-1.5-Flash as the base model but vary in their aspects to verify (e.g., general correctness, mathematical correctness) and verification strategies (e.g., direct approval, step-by-step verification). Four verifiers correctly identify the error, while one verifier using general correctness through summarization incorrectly approves the solution. This demonstrates how diverse verification methods can produce more reliable signals even when using a single base model, as multiple verifiers can compensate when another fails.}
\label{appx:fig-mav-extra-1}
\end{figure*}


\begin{figure*}[h!]
\centering
\includegraphics[width=\linewidth]{figures/mav_illustration_single_solution_HumanEval.pdf}
\caption{\textbf{Multi-agent verification for a single solution (additional example).} An illustration similar to \autoref{fig:mav-illustration-single-solution}. Here, three different aspect verifiers evaluate an incorrect HumanEval~\citep{chen2021evaluating} solution sampled from Gemini-1.5-Flash. Two verifiers correctly identify the error through careful analysis, while one verifier incorrectly approves the solution.}
\label{appx:fig-mav-extra-2}
\end{figure*}


\begin{figure*}[h!]
\centering
\includegraphics[width=0.95\linewidth]{figures/mav_illustration_single_solution_GPQA.pdf}
\caption{\textbf{Multi-agent verification for a single solution (additional example).} An illustration similar to \autoref{fig:mav-illustration-single-solution}. Here, three different aspect verifiers evaluate a correct GPQA (diamond)~\citep{rein2023gpqa} solution sampled from Gemma-2-27B. The verifiers vary in their base models, aspects to verify, and verification strategies. Notice that Gemini-1.5-Flash incorrectly rejects the solution when evaluating logical soundness but correctly approves it when prompted to explain the solution differently. Meanwhile, GPT-4o-mini correctly approves the solution when evaluating logical soundness. Different base models can produce different evaluations of the same aspect.}
\label{appx:fig-mav-extra-3}
\end{figure*}








\begin{table*}[h!]\centering
\ra{1.3}
\begin{tabular}{@{}l|p{14cm}@{}}
\toprule
\textbf{Domain} & \textbf{Generator Prompt} \\ 
\midrule
MATH & \textit{You are a helpful assistant skilled in math problem-solving. Always end your solution with the final numerical answer enclosed in LaTeX \textbackslash boxed\{\} notation. If there is no solution, reply with an empty \textbackslash boxed\{\}. Please solve the following math problem step by step:} $<$ \textit{Question} $>$ \textit{Provide your detailed solution below:} \\
\midrule
MMLU-Pro & \textit{Answer the following multiple choice question. Think step by step before answering, and then output the answer in the format of ``The answer is (X)'' at the end, where X is the LETTER of the correct answer.}

\textit{QUESTION:} $<$ \textit{Question} $>$

\textit{Think step by step, then end with EXACTLY ``The answer is (X)'', where X is the LETTER of the correct answer. Do not include the answer text itself, only the letter.} \\
\midrule
GPQA (diamond) & Same as MMLU-Pro. \\
\midrule
HumanEval & \textit{Read the following function signature and docstring, and fully implement the function described. Your response should only contain the code for this function.} 

$<$ \textit{Function Signature and Docstring} $>$ \\
\bottomrule
\end{tabular}
\caption{\textbf{Generator Prompts.}
Generator prompts by domain. Each domain uses one consistent prompt across all generator LLMs.}
\label{tab:generator-prompts}
\end{table*}





\begin{table*}[h!]\centering
\ra{1.3}
\begin{tabular}{@{}lp{14cm}@{}}
\toprule
\textbf{Domain} & \textbf{Aspect Verifier System Prompt} \\ 
\midrule
MATH & \textit{You are a critical verifier tasked with evaluating mathematical problem-solving. You will be presented with a question and a proposed solution. Your job is to carefully go over and analyze the solution. Follow the instructions.} \\
\midrule
MMLU-Pro & \textit{You are a critical verifier tasked with evaluating multiple-choice question-answering. You will be presented with a question, the multiple-choice options, and a proposed solution. Your job is to carefully go over and analyze the solution. Follow the instructions.} \\
\midrule
GPQA (diamond) & Same as MMLU-Pro. \\
\midrule
HumanEval & \textit{You are a critical verifier tasked with evaluating code implementations. You will be presented with a prompt and a code implementation. Your job is to carefully go over and analyze the code. Follow the instructions.} \\
\bottomrule
\end{tabular}
\caption{\textbf{Aspect Verifier System Prompts.} System prompts for aspect verifiers. These provide domain-specific context for the verification instructions in \autoref{tab:av-prompts-part1} and \autoref{tab:av-prompts-part2}.}
\label{tab:av-system-prompts}
\end{table*}





\begin{table*}\centering
\ra{1.3}
\begin{tabular}{@{}llp{10cm}@{}}
\toprule

\textbf{Aspect to Verify} & \textbf{Verification Strategy} & \textbf{Aspect Verifier Prompt} \\ 
\midrule

Mathematical Correctness  & Step-by-Step &
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Go over each step in the proposed solution and check whether it is mathematically correct. Think out load. If you reach a step that is incorrect, stop and reply 'FINAL VERIFICATION ANSWER: False'. If you get to the end of all the steps and each step was correct, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

Logical Soundness  & Step-by-Step & \textit{} 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Go over each step in the proposed solution and check whether it is logically sound. Think out load. If you reach a step that is not logically sound, stop and reply 'FINAL VERIFICATION ANSWER: False'. If you get to the end of all the steps and each step was logically sound, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

Factual Correctness  & Step-by-Step & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Go over each step in the proposed solution and check whether the facts presented are correct. Think out load. If you reach a step with incorrect facts, stop and reply 'FINAL VERIFICATION ANSWER: False'. If you get to the end of all the steps and each step had correct facts, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

Unit Conversions & Step-by-Step & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Check if the units are handled correctly in each step of the solution. Think out loud. If you find any issues with the units, stop and reply 'FINAL VERIFICATION ANSWER: False'. If all units are handled correctly, reply 'FINAL VERIFICATION ANSWER: True'.}
\\

\bottomrule
\end{tabular}
\caption{\textbf{Aspect Verifier Prompts (Part 1).} Aspect verifier prompts for each aspect-strategy combination. These prompts follow the system prompts in \autoref{tab:av-system-prompts}.}
\label{tab:av-prompts-part1}
\end{table*}






\begin{table*}\centering
\ra{1.3}
\begin{tabular}[h!]{@{}llp{10cm}@{}}
\toprule

\textbf{Aspect to Verify} & \textbf{Verification Strategy} & \textbf{Aspect Verifier Prompt} \\ 
\midrule

General Correctness  & Direct Approval & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Is this solution correct for the given question? Respond with ONLY 'FINAL VERIFICATION ANSWER: True' or ONLY 'FINAL VERIFICATION ANSWER: False'. Do not provide any explanation or additional text.}
\\
\midrule

General Correctness  & Summarize Solution & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Summarize the solution in your own words, explore anything you think may be incorrect. Think out load. If you find something that's incorrect, stop and reply 'FINAL VERIFICATION ANSWER: False'. If you've gone over the solution and everything seems correct, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

General Correctness  & Explain Differently & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Explain the solution in a different way than it was presented. Try to find any flaws in the solution. Think out load. If you find something that's incorrect, stop and reply 'FINAL VERIFICATION ANSWER: False'. If you've gone over the solution and everything seems correct, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

General Correctness  & Edge Cases & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Check if the solution handles edge cases and boundary conditions, test extreme values or special cases. Think out loud. If any boundary conditions or edge cases fail, stop and reply 'FINAL VERIFICATION ANSWER: False'. If all boundary conditions and edge cases are handled correctly, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

General Correctness  & Common Mistakes & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Check if the solution has any common mistakes, calculation errors, or misconceptions that typically found in this type of problem. Think out loud. If you find any common mistakes, stop and reply 'FINAL VERIFICATION ANSWER: False'. If no common mistakes are found, reply 'FINAL VERIFICATION ANSWER: True'.}
\\
\midrule

General Correctness  & Domain Knowledge & 
\textit{QUESTION:} $<$\textit{Question}$>$

\textit{PROPOSED SOLUTION:} $<$\textit{Solution}$>$

\textit{INSTRUCTIONS: 
Check if the solution correctly applies relevant domain-knowledge, established theories, and standard practices for this type of problem. Think out loud. If any domain knowledge is misapplied or violated, stop and reply 'FINAL VERIFICATION ANSWER: False'. If all domain-specific knowledge is correctly applied, reply 'FINAL VERIFICATION ANSWER: True'.}
\\

\bottomrule
\end{tabular}
\caption{\textbf{Aspect Verifier Prompts (Part 2).} Aspect verifier prompts for each aspect-strategy combination. These prompts follow the system prompts in \autoref{tab:av-system-prompts}.}
\label{tab:av-prompts-part2}
\end{table*}






% \input{temp_tables}