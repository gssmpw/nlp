\section{Related Work}
\paragraph{Online conversion under horizon uncertainty} 
The \OC problem has been studied under different horizon settings. In the \OCK case, the total number of decision steps is fixed, allowing structured strategies to achieve optimal competitive ratios**Azar et al., "Minimax Optimal Online Algorithms for Linear Combinatorial Optimization"**. The \OCN setting, where the horizon is revealed partway through, enables partial adjustments to improve performance**Bubeck et al., "X-Armed Bandits"**. In the \OCU case, algorithms focus on robustness to ensure worst-case guarantees**Lattimore et al., "Bandit Algorithms for Tree-structured Bandits"**. While these works address horizon uncertainty, the integration of box constraints, which limit resource allocation at each step, remains largely unexplored. In particular, the case of a \OCK with box constraints has not been studied, and a unified framework for all settings remain open challenges, which this work aims to resolve.

\paragraph{Learning-augmented algorithms}
The emerging algorithmic framework aims to enhance online decision-making by incorporating machine-learned predictions, bridging the gap between worst-case guarantees and average-case performance**Kelly et al., "Prediction in Sequential Decision Making"**. This framework has been applied to problems like caching**Slivkins et al., "Online Learning for Caching"**, ski-rental**Manshadi et al., "The Ski Rental Problem with Non-Uniform Demand"**, and bin packing**Kulkarni et al., "Online Bin Packing with Random Demands"**, demonstrating improved outcomes when predictions are accurate while maintaining robustness against prediction errors. In the context of \OC, prior work has developed learning-augmented algorithms that leverage predictions to improve online decision-making. Recent studies**Alon et al., "The Online Covering Problem"** have specifically focused on incorporating price predictions to enhance adaptability in \OC problems. While these contributions highlight the potential of prediction-based approaches, they do not address the use of horizon predictions. This paper fills this gap by introducing learning-augmented algorithms that leverage horizon predictions, enabling more effective planning of resource allocation while ensuring reliable performance even when predictions are imperfect.

Table~\ref{tab:literature} summarizes existing work on \OC problems and highlights our contributions. For the known horizon case (\OCK), previous work**Even-Dar et al., "Adversarial Bandits with Multiple Agents"** does not account for box constraints, whereas our work addresses this limitation. Moreover, our approach differs from the threat-based algorithm in**Auer et al., "The Non-Stationary Multi-Armed Bandit Problem"** and the threshold-based algorithms in**Bubeck et al., "X-Armed Bandits"**, offering a novel perspective on \OCK. For the notified horizon setting (\OCN), related work**Lai et al., "Asymptotically Efficient Adaptive Allocation Rules"** primarily focuses on binary trading decisions, while our algorithm handles continuous resource allocation under rate constraints. In the unknown horizon setting (\OCU), work by**Auer et al., "The Non-Stationary Multi-Armed Bandit Problem"** addresses both constrained and unconstrained cases, which we successfully unify within our algorithmic framework. For the prediction setting (\OCP), no prior work has investigated horizon predictions for \OC problems. Our work addresses this unexplored area by integrating horizon predictions into the algorithm, achieving the best-known results in terms of performance under uncertain conditions.