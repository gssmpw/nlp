\section{Related work}
\label{sec:related_work}
The large body of research on control-flow anomaly detection in event logs sees a wide range of data-driven approaches \cite{ko2023adsystematicreview}. In particular, the scientific literature developed techniques for control-flow anomaly detection that may or may not use \revision{conformance checking}. To distinguish between those that use \revision{conformance checking} and those that do not, we refer to them as \revision{conformance checking}-based techniques and \revision{conformance checking}-independent techniques. 


\subsection{\revision{Conformance checking}-independent techniques}
\revision{Conformance checking}-independent techniques use specific types of trace encodings to extract features from event logs, such as one-hot encoding and word2vec \cite{ko2023adsystematicreview}. In particular, trace encodings may extract process-based statistics, such as N-grams or directly-follows relationships \cite{tavares2023pmtraceencoding}. We refer to these types of trace encodings as \textit{statistical} \revision{process mining}-based feature extraction.

\paragraph{Deep learning} A large class of \revision{conformance checking}-independent techniques rely on deep learning by feed-forward and/or recurrent neural networks, such as the autoencoder \cite{nolle2018processadautoencoders, vijayakamal2020bpaead, elaziz2023drlbpad, chinnaiah2024deepaead, kan2024aebasedelad}, long-short term memory networks \cite{du2017deeplog, lahann2022lstmadpi} and gated recurrent unit networks \cite{nolle2022binet, guan2023gruaebpad}. Some works combined these approaches, employing both the autoencoder and recurrent neural networks to exploit the ability of reconstruction-based and prediction-based anomaly detection \cite{yuan2021deeplstmaead, wang2022lstmaeaddiagnosis, guan2024wake}. Although \revision{conformance checking}-independent techniques using deep learning are very effective, their performance could differ based on the type of trace encoding \cite{tavares2021pmencodingad}. Moreover, deep learning is notoriously affected by explainability issues \cite{rawal2022trustworthyaiadvances}. To address these issues, the scientific literature aimed to combine deep learning with \revision{process mining}. Firstly, recurrent neural networks have been used to approximate the diagnostics that alignment-based \revision{conformance checking} provides; arguably, these workarounds reduce the computational cost of alignment-based \revision{conformance checking} while reaching comparable results \cite{nolle2020deepalign, boltenhagen2020costbasedlogtracesclassification}. Additionally, other approaches used deep learning to pre-process data so that \revision{process mining} could provide better performance. For example, Krajsic and Franczyk \cite{krajsic2021vaeadonlinepm} used the autoencoder to perform anomaly detection before \revision{process mining} to obtain higher-quality process models through process discovery. Similarly, Wang et al. \cite{wang2022lstmaeaddiagnosis} applied \revision{process mining} after \revision{conformance checking}-independent control-flow anomaly detection to provide diagnostics and inspect the causes of deviating control flow. These works suggest that the literature recognizes the utility of \revision{process mining} in improving the explainability of control-flow anomaly detection based on deep learning.

\paragraph{Statistics}Whereas many \revision{conformance checking}-independent techniques rely on deep learning due to its detection effectiveness, several proposals set forth statistical approaches. Mostly, these approaches rely on evaluating the similarity of new event data to a normal and interpretable statistic. For example, Li and van der Aalst \cite{li2017frameworkdeviations} encoded information from the directly follows and dependency relations, building ``profiles" by which new event data are compared to evaluate whether they are anomalous. Ko and Comuzzi \cite{ko2021statisticaladbp} extracted a statistical index termed leverage measure to use as a metric to calculate the ``anomaly score" of traces in event logs; this measure can be used to either fit a statistical distribution or build a threshold to which new traces are compared. Similarly, Luftensteiner and Praher \cite{luftensteiner2022adpmgraphs} presented an approach based on spectral analysis of the adjacency matrix built from a graph that encodes a given relation among events. The approach evaluates the difference between the second-highest eigenvalue of adjacency matrices --- i.e., the spectral gap --- of a normal event log and a new event log; if the spectral gap is too large, the new event log is anomalous. Finally, Mavroudopoulos and Gounaris \cite{manvroudopoulos2022proximitybasedtemporalad} proposed a nearest-neighbor-based approach that evaluates the distance between reference ``vector traces", i.e., trace encodings, and new vector traces using different metrics; if the distance exceeds a given threshold based on the set of normal trace encodings, the new vector trace is classified as anomalous.

The high heterogeneity of \revision{conformance checking}-independent techniques for control-flow anomaly detection makes a comprehensive and fair comparison between them a challenging task. The framework that we propose in Section \ref{sec:framework} aims to implement reconstruction-based anomaly detection, as done in many of the reviewed references \cite{nolle2018processadautoencoders, vijayakamal2020bpaead, elaziz2023drlbpad, chinnaiah2024deepaead, kan2024aebasedelad}. However, an overarching comparison of all \revision{conformance checking}-independent techniques is out of the scope of this work. Instead, as discussed below, we focus on enhancing \revision{conformance checking}-based techniques to both improve the detection performance and maintain the explainable nature of \revision{conformance checking}.

\subsection{\revision{Conformance checking}-based techniques}
Contrary to \revision{conformance checking}-independent techniques, \revision{conformance checking}-based techniques do not employ trace encodings such as one-hot encoding and word2vec. Instead, \revision{conformance checking}-based techniques aim to seamlessly check new event logs with a reference Petri net, obtaining the fitness measure to indicate whether the event data is anomalous \cite{bezerra2009pmad, accorsi2012pmsecurityaudits, bezerra2013adlogspais, myers2018icsadpm, pecchia2020applicationfailuresanalysispm}. In addition, the fitness measure is tightly connected to the Petri net semantics, thus providing explainable ways to analyze the root cause of unfitting event logs \cite{aalst2016pm}. However, relying on fitness thresholding has shown poor detection effectiveness mostly due to noisy data and/or low-quality process models \cite{bezerra2013adlogspais, pecchia2020applicationfailuresanalysispm}. In this regard, let us consider Figure \ref{CC_UNBALANCING}, which depicts a normal event log, namely an event log containing normal traces from one of the datasets we use during the evaluation, and a reference Petri net from the same dataset. The histogram shows that a high percentage of traces have a fitness measure below 0.75. It is therefore not trivial to set a threshold based on these results. 

\paragraph{Solutions to the shortcomings}
Whereas some works disregarded the issue of noisy event logs and/or low-quality Petri nets by deeming anomalous all traces that the reference Petri net does not perfectly fit \cite{accorsi2012pmsecurityaudits, myers2018icsadpm}, other works attempted to account for these shortcomings by exploiting other information related to either the reference Petri net or control-flow diagnostics obtained by \revision{conformance checking}. For example, Bezerra et al. \cite{bezerra2009pmad} combined process discovery with \revision{conformance checking} to extract the ``most appropriate" Petri net according to both a manually tuned fitness threshold and the simplicity of the Petri net obtained by process discovery. Similarly, Bezerra et al. \cite{bezerra2013adlogspais} and Pecchia et al. \cite{pecchia2020applicationfailuresanalysispm} developed algorithms and methods to discover high-quality Petri nets with process discovery and automatically tune the fitness threshold for anomaly detection. In addition to these solutions, which somehow attempt to optimize the fitness threshold, other approaches combine \revision{conformance checking} with machine learning to supply additional information about faulty control flow, such as the number of times an activity was not allowed to execute according to the model semantics. This process leads to \revision{conformance checking} \revision{process mining}-based feature extraction, which results in tabular data that can be processed by machine/deep learning algorithms for anomaly detection \cite{sarno2020pmadbp, singh2022lapmsh, debenedictis2023dtadiiot}.

\paragraph{Our solution} To address the problem shown in Figure \ref{CC_UNBALANCING} regarding the choice of a fitness threshold, the scientific literature proposes to either a) tune an optimal fitness threshold by discovering the highest-quality process model through process discovery, or b) provide additional control-flow information obtained by \revision{conformance checking} to feed to machine learning. In this work, we follow approach b) and develop a novel \revision{process mining}-based feature extraction approach with alignment-based \revision{conformance checking}, which aligns the deviating control flow with a reference Petri net; the resulting alignment can be inspected to extract additional statistics such as the number of times a given activity caused mismatches. This allows the connection of these statistics to the reference Petri net for additional insights on the deviating control flow. We present this solution in the next section, followed by its integration into a flexible and explainable framework for developing \revision{conformance checking}-based and \revision{conformance checking}-independent techniques for control-flow anomaly detection.

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\columnwidth]{images/CC_UNBALANCING.png}
\caption{The distribution of fitness values of case-study traces of a normal event log replayed on a reference Petri net. The inconsistent distribution of fitness values of the case-study traces makes fitness thresholding ineffective for control-flow anomaly detection.}
\label{CC_UNBALANCING}
\end{figure}