\onecolumn
\appendix

\section{Table of Notations}
\begin{table*}[h] 
\centering
\begin{tabular}{ll}
    \toprule
    \centering
    \textbf{Symbol}     & \textbf{Description}\\
    \midrule
    $q_0(\rvx_0)$ & Density of data distribution.\\
    $q_t(\rvx_t)$ & Marginal distribution density of forward process at time $t$.\\
    $q_t(\rvx_t | \rvx_0)$ & Conditional distribution density of forward process at time $t$ given a data point $\rvx_0$.\\
    $\nabla_x \log q(\rvx_t)$ & Score function of the marginal distribution of forward process at time $t$.\\
    $\theta$ & Parameters of a diffusion model (usually weights and biases of a neural network)\\
    $\score_\theta(\rvx_t; t)$ & Score function learned by the model.\\
    $p_\theta(\rvx_t)$ & Marginal distribution density of the reverse process defined by $\score_\theta(\rvx_t; t)$.\\
    $P_\theta(\rvx)$ & The probability distribution corresponding to the reverse process implied by $\score_\theta(\rvx_t; t)$, at $t=0$.\\
    $\Omega$ & Constraint set.\\
    $\distancefn^\Omega(\rvx_t; t)$ & A distance function to $\Omega$.\\
    $\gamma(t)$ & Scaling of distance function to define manual bridges.\\
    $\bridge(\rvx_t; t)$ & A manual bridge. It has the form of $\gamma(t) \nabla_x \distancefn^\Omega(\rvx_t; t)$.\\
    $\score_{\theta}^\Omega$ & Score function defined by a manually bridged model.\\
    $\score_{\theta, \texttt{C}}^\Omega$ & Score function defined by a \texttt{C-arch} with a manual bridge conditioning.\\
    $\score_{\theta, \texttt{DB}}^\Omega$ & Score function defined by a manually bridged model with \texttt{DB-arch} architecture.\\
    $\score_{\theta, \texttt{MBM}}^\Omega$ & Score function defined by a manually bridged model with \texttt{MBM-arch} architecture.\\
    $\gB^\Omega(\rvx_t; t)$ & A notation to generically refer to diffusion bridge updates.\\
    \bottomrule
\end{tabular}
\end{table*}

\section{Experimental Details}
\subsection{Checkerboard constraint experiment}
\paragraph{Architecture} Our model's architecture is a fully connected multi-layer perceptron (MLP) with 2 residual blocks similar to that of \citet{naderiparizi2024dont}. We use a hidden layer dimension of 256 and sinusoidal timestep dimension of 128.
\paragraph{Diffusion process} We use the EDM \citep{karras2022elucidating} framework with similar hyperparameters. However, since in manual bridges it is important to be accurate when $t$ is close to zero, we modify the distribution $p_\sigma$ of \citet{karras2022elucidating} to be a log-linear with $\sigma_{\text{min}} = 3 \times 10^{-5}$ and $\sigma_{\text{max}} = 80$.
\paragraph{Sampling} We use the second-order Heun solver of \citet{karras2022elucidating} with 100 sampling steps and $S_{\text{churn}} = 10$. We also change the schedule of $\sigma$ to a log-linear from $\sigma_{\text{max}}$ to $\sigma_{\text{min}}$, similar to the training distribution.
\paragraph{Training} We train our models with the Adam optimizer \citep{kingma2014adam} with a learning rate of $3 \times 10^{-4}$ and batch size of $1000$. Other hyperparameters used are the default values in PyTorch \citep{paszke2019pytorch}. All the models were trained on GeForce GTX 1080
Ti GPUs. The total estimated compute for this experiment is about 10 GPU hours.

\subsection{Traffic Scene Generation experiment}
\paragraph{Architecture} The architecture for training models is based on transformers, whose backbone is composed of an encoder, a stack of self-attention with relative positional encodings (RPEs)~\citep{shaw2018self, wu2021rethinking,harvey2022flexible} and cross-attention residual blocks and a decoder. We refer readers to~\citet{naderiparizi2024dont} for more details with no extra modification compared to this work. With the same setup, we train each model with a batch size of $64$ and Adam optimizer \citep{kingma2014adam} with a learning rate of $10^{-4}$. The architecture contain approximately $6.3$ million parameters. To embed bridges in $\texttt{C-arch}$ or $\texttt{MBM-arch}$, we process it with an additional two-layer MLP with activation function SiLU. We use Tesla V100 for training and validating models with around $200$ hrs GPU-hours in total.

\paragraph{Diffusion process} Similar to Toy experiment, we deploy EDM~\citep{karras2022elucidating} framework and set $\sigma_{\text{min}} = 2\times 10^{-4}$ with a log-linear distribution $p_\sigma$.
\paragraph{Sampling} We use the first-order Euler-Maruyama solver~\citep{song2020score} with 300 sampling steps, set $S_{\text{churn}} = 10$ and change $\sigma$ to the log-linear schedule as the Checkerboard constraint experiment.
\paragraph{Training} We first train Standard diffusion for $950$k iterations with batch size 64. \method{} with $\texttt{C-arch}$, $\texttt{DB-arch}$ and $\texttt{MBM-arch}$ respectively, are fine-tuned based on the Standard diffusion and trained them $300$k iterations longer.
\paragraph{Bridge computation} While incorporating bridge term $\bridge^\Omega(\rvx_t; t)$ into \method{}-style training process, an issue was observed: when the noise level $\sigma_t$ injected in training sample $\rvx_t$ is high, and both vehicle positions and sizes are diffused, abnormally-huge-sized vehicles are ejected from the map roads, resulting in both ``offroad'' and ``collision'' losses increasing significantly. The gradients do not provide informative guidance to the model but simply dominate the training over the score function, which destabilizes the training and is not ideal. To stabilize the training with bridges integrated, we normalized $\rvx_t$ by $\sqrt{\Var(\rvx_t)} = \sqrt{\Var(\rvx_0 + \sigma\epsilon)} = \sqrt{1 + \sigma_t^2}$ before passing it to $\ell^\Omega(\cdot)$. With chain rule applied, we have
\begin{align}
&\nabla_{\rvx_t} \ell^{\Omega}(\rvx_t) = \frac{\partial\ell^{\Omega}(\rvx_t')}{\partial \rvx_t'} \frac{\partial \rvx_t'}{\partial \rvx_t},\ \text{where}\ \rvx_t' = \frac{\rvx_t}{\sqrt{1 + \sigma_t^2}} \\
\Rightarrow &\nabla_{\rvx_t} \ell^{\Omega}(\rvx_t) = \frac{1}{\sqrt{1 + \sigma_t^2}}\frac{\partial\ell^{\Omega}(\rvx_t')}{\partial\rvx_t'}
\end{align}
which effectively alleviates the problem, as the loss function evaluates the normal-sized vehicles centered on the road map.

\begin{figure*}[tb]
    \centering
    \includegraphics{figs/initial_conditions/ic_mdm_2.pdf}
    \caption{While standard diffusion models struggle to achieve zero infraction, incorporating diffusion bridges ensures constraint satisfaction.}
    \label{fig:app:additional:plots}
\end{figure*}

\section{Diffusion bridges}
\subsection{Sufficient conditions}\label{app:diffusion-bridges:sufficient}
In this section we rephrase the theory of diffusion bridges from \citet{wu2022diffusion} in our notation. Following the definitions in \cref{sec:method:manual-bridge}, let $\distancefn^\Omega(\rvx; t)$ be an $\Omega$-distance function and let $\gamma(t)$ be a weighting function. Define $\gB(\rvx; t) = - \gamma(t) \distancefn^\Omega(\rvx; t)$. The SDE in \cref{eq:reverse-bridged-process} is a bridge to $\Omega$ if the following holds
\begin{enumerate}
    \item $\distancefn^\Omega$ follows an (expected) Polyak-Lojasiewicz condition: $\meanp{t, \rvx_t \sim p_t^\Omega}{\distancefn^\Omega(\rvx_t; t)} \leq \meanp{t, \rvx_t \sim p_t^\Omega}{\norm{\nabla_x \distancefn^\Omega(\rvx_t; t)}^2}$ for all $t \in [0, T]$,
    \item Let
    \begin{itemize}
        \item $\beta(t) = \meanp{t, \rvx_t \sim p_t^\Omega}{\nabla_x \distancefn^\Omega(\rvx_t; t)^\transpose \nu(\rvx_t; t)}$,
        \item $\rho(t) = \E_{t, \rvx_t \sim p_t^\Omega} \Big[ \partial_t \distancefn^\Omega(\rvx_t; t) + \frac{1}{2} \Tr(\nabla^2_x \distancefn^\Omega(\rvx_t; t)g^2(t)) \Big]$,
        \item $\zeta(t) = \exp(\int_t^T \gamma(s) ds)$.
    \end{itemize}
    Then
    \begin{itemize}
        \item $\lim_{t \downarrow 0} \zeta(t) = +\infty,$
        \item $\lim_{t \downarrow 0} \frac{\zeta(t)}{\int_t^T \zeta(s) (\beta(s) + \rho(s))} = +\infty.$
    \end{itemize}
\end{enumerate}

Under the definition of our manual bridges, the only condition satisfied from above is $\lim_{t \downarrow 0} \zeta(t) = +\infty$. Therefore, manual bridges are not necessarily diffusion bridges.

\subsection{Diffusion bridges of \texorpdfstring{\citet{liu2023learning}}{}}
\citet{liu2023learning} provides a particular choice of diffusion bridges and shows they constitute a valid diffusion bridge. Here we re-state their proposed bridge expressions in our notation. Furthermore, we show their proposed bridge is equivalent to an optimal diffusion model for a data distribution of $\gU(\Omega)$, a uniform distribution on $\Omega$.

\paragraph{Diffusion bridges of \citet{liu2023learning}}
Consider a diffusion model as defined in \cref{sec:background:dm} with the forward process
\begin{equation}
    d\rvx_t = f(\rvx_t; t)\,dt + g(t)\,d\rvw,
\end{equation}
and conditional forward density 
\begin{equation}
    q_t(\rvx_t | \rvx_0) = \gN(\rvx_t; \alpha(t) \rvx_0, \sigma^2(t)\mI),
\end{equation}
where $\alpha(t)$ and $\sigma(t)$ are respectively the total scale and noise in the forward process.
As mentioned in \cref{sec:background:db}, diffusion bridges have the form of
\begin{equation}
    d \rvx_t = [\nu_\theta(\rvx_t; t) - g^2(t) \gB^\Omega(\rvx_t; t)] dt + g(t) d\bar{\rvw},
\end{equation}
where $\nu_\theta(\rvx_t; t) := f(\rvx_t; t) - g^2(t) \score_\theta(\rvx_t; t)$. \citet{liu2023learning} proposes the following form for the bridge update $\gB$:
\begin{equation}
    \gB^\Omega(\rvx_t; t) = \meanp{r^\Omega(\rvx_0 | \rvx_t)}{\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t)},
\end{equation}
where $r(\rvx_0|\rvx_t) := \gN(\rvx_0; \rvx_t / \alpha(t), \sigma^2(t)/ \alpha^2(t) \mI)$ and $r^\Omega(\rvx_0|\rvx_t) = \frac{r(\rvx_0 | \rvx_t) \1(\rvx_0 \in \Omega)}{Z(\rvx_t)}$ where $Z(\rvx_t)$ is the normalizing factor and is independent of $\rvx_0$.

\paragraph{Connection to a diffusion model for $\gU(\Omega)$}
\begin{lemma}\label{lemma:app:r-q-same-score-fn}
    For any $\rvx_0$ and $\rvx_t$ in $\R^d$ the following holds
    \begin{enumerate}
        \item $\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t) = \nabla_{\rvx_t} \log q(\rvx_t | \rvx_0)$,
        \item $\nabla_{\rvx_0} \log r(\rvx_0 | \rvx_t) = \nabla_{\rvx_0} \log q(\rvx_t | \rvx_0)$.
    \end{enumerate}
\end{lemma}
\begin{proof}
    We first derive $\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t)$:
    \begin{align}
        &r(\rvx_0 | \rvx_t) = \gN(\rvx_0; \rvx_t / \alpha(t), \sigma^2 / \alpha^2(t) \mI)\nonumber\\
        \Rightarrow &\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t) = \nabla_{\rvx_t} \frac{-(\rvx_0 - \frac{\rvx_t}{\alpha(t)})^\transpose(\rvx_0 - \frac{\rvx_t}{\alpha(t)})}{2\sigma^2(t) / \alpha^2(t)}
        = \frac{\rvx_0 - \frac{\rvx_t}{\alpha(t)}}{\sigma^2(t) / \alpha(t)} = \frac{\alpha(t) \rvx_0 - \rvx_t}{\sigma^2(t)}.
    \end{align}
    Then we derive $\nabla_{\rvx_t} \log q(\rvx_t | \rvx_0)$:
    \begin{align}
        &q(\rvx_t | \rvx_0) = \gN(\rvx_t; \alpha(t)\rvx_0, \sigma^2\mI)\nonumber\\
        \Rightarrow &\nabla_{\rvx_t} \log q(\rvx_t | \rvx_0) = \nabla_{\rvx_t} \frac{-(\rvx_t - \alpha(t)\rvx_0)^\transpose(\rvx_t - \alpha(t)\rvx_0)}{2\sigma^2(t)}
        = \frac{\alpha(t) \rvx_0 - \rvx_t}{\sigma^2(t)}.
    \end{align}
    Therefore, $\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t) = \nabla_{\rvx_t} \log q(\rvx_t | \rvx_0)$. Proof of the second part is similar.
\end{proof}
\begin{proposition} The bridge update of \citet{liu2023learning} is equivalent to an optimal diffusion model for $\gU(\Omega)$.
\end{proposition}
\begin{proof}
    Consider a diffusion process with the data distribution $q(\rvx_0) = \gU(\rvx_0; \Omega)$. Let's first look at the score function of $q(\rvx_0 | \rvx_t)$:
    \begin{align*}
        \nabla_{\rvx_0} \log q(\rvx_0 | \rvx_t) &= \nabla_{\rvx_0} \log q(\rvx_t | \rvx_0) + \nabla_{\rvx_0} \log q(\rvx_0)\\
        &\hspace{-1.1em}\overset{\text{\cref{lemma:app:r-q-same-score-fn}}}{=} \nabla_{\rvx_0} \log r(\rvx_0 | \rvx_t) + \nabla_{\rvx_0} \log q(\rvx_0)\\
        &= \nabla_{\rvx_0} \log r(\rvx_0 | \rvx_t) + \nabla_{\rvx_0} \log \1(\rvx_0 \in \Omega)\\
        &= \nabla_{\rvx_0} \log \left(r(\rvx_0 | \rvx_t) \1(\rvx_0 \in \Omega)\right)\\
        &= \nabla_{\rvx_0} \log \left(r^\Omega(\rvx_0 | \rvx_t) Z(\rvx_t)\right)\\
        &= \nabla_{\rvx_0} \log r^\Omega(\rvx_0 | \rvx_t)
    \end{align*}
    Therefore, $q(\rvx_0 | \rvx_t)$ and $r^\Omega(\rvx_0 | \rvx_t)$ have the same score function, hence they are equal. Furthermore, from \cref{lemma:app:r-q-same-score-fn}, we know $\nabla_{\rvx_0} \log r(\rvx_0 | \rvx_t) = \nabla_{\rvx_0} \log q(\rvx_t | \rvx_0)$. Consequently,
    \begin{align}
        \gB^\Omega(\rvx_t; t) &= \meanp{r^\Omega(\rvx_0 | \rvx_t)}{\nabla_{\rvx_t} \log r(\rvx_0 | \rvx_t)}
        = \meanp{q(\rvx_0 | \rvx_t)}{\nabla_{\rvx_t} \log q(\rvx_t | \rvx_0)}.
    \end{align}
    From \citet{vincent2011connection} we know
    \begin{equation}
        \nabla_{\rvx_t} \log q(\rvx_t) = \meanp{q(\rvx_0 | \rvx_t)}{\nabla_{\rvx_t} q(\rvx_t | \rvx_0)}.
    \end{equation}
    Therefore, $\gB^\Omega(\rvx_t; t)$ proposed by \citet{liu2023learning} is equivalent to the score functions of an optimal diffusion model with the data distribution $q(\rvx_0)$ equal to a uniform distribution on the constraint set $\Omega$.
\end{proof}


\section{Proofs}
We mentioned in the main text in \cref{sec:method:manual-bridge} that manually bridged models define score functions of distributions $p^\Omega(\rvx; t)$ that anneal to $p^\Omega(\rvx; 0) \propto p(\rvx; 0) \1_\Omega(\rvx)$. Here we formally prove this.

As stated before, the manually bridged models correspond to distributions of the from
\begin{align}
    p^\Omega(\rvx; t) = \frac{p(\rvx; t) \exp(-\gamma(t) \distancefn^\Omega(\rvx; t))}{Z(t)},
\end{align}
where $Z(t) = \int p(\rvx) \exp(-\gamma(t) \distancefn^\Omega(\rvx; t)) d\rvx$ is the normalizing constant. Since the integrand is non-negative,
\begin{equation*}
    Z(t) \geq \int_\Omega p(\rvx; t) \exp(-\gamma(t) \distancefn^\Omega(\rvx; t)) d\rvx = \int_\Omega p(\rvx; t) d\rvx,
\end{equation*}
where the last equality is due to $\distancefn^\Omega$ being zero on $\Omega$. Define $\alpha := \int_\Omega p(\rvx; t) d\rvx > 0$. Therefore, $Z(t)$ is bounded below by the constant $\alpha$. Hence,
\begin{align}
    p^\Omega(\rvx; t) \leq \frac{1}{\alpha} p(\rvx; t) \exp(-\gamma(t) \distancefn^\Omega(\rvx; t)).
    \label{eq:app:density-bound}
\end{align}

\begin{lemma}
    \label{lemma:app:converge-zero}
    For any arbitrary $\rvx \notin \Omega$, $\lim_{t \downarrow 0} p(\rvx; t) \exp(-\gamma(t)\distancefn^\Omega(\rvx)) = 0$.
\end{lemma}
\begin{proof}
    Consider any arbitrary $\rvx \notin \Omega$ and $\epsilon >0$. From \cref{prop:mbm-sequence-of-distributions}, $p$ is finite. Denote an upper bound of $p$ by $M$ i.e., $p(\rvx, t) \leq M$ for any $t$.
     Furthermore, since $\rvx \notin \Omega$ and $\distancefn$ is an $\Omega$-distance function, $\distancefn^\Omega(\rvx; 0) = C$ for some $C > 0$. Since $\distancefn^\Omega$ is continuous in $t$, $\lim_{t \downarrow 0} \distancefn(\rvx; t) = C$. Consider an arbitrary $0 < c < C$,
     \begin{equation}
         (\exists \delta_1 > 0) \; (t < \delta_1 \Rightarrow \distancefn^\Omega(\rvx; t) > c) \label{app:proofs:convergence:distancefn-lim}
     \end{equation}
    Also from \cref{def:omega-distance-fn}, $\lim_{t \downarrow 0} \gamma(t) = \infty$. Therefore, for a given $\epsilon$,
    \begin{equation}
        (\exists \delta > 0) \; t < \delta_2 \Rightarrow \gamma(t) > -\frac{\log (\epsilon / M) }{c}
    \end{equation}
    
    Let $\tau := \min\{\delta_1, \delta_2\}$. For all $t < \tau$ we have
    \begin{align}
        &\gamma(t) > - \frac{\log(\epsilon / M)}{c}
        \Rightarrow -\gamma(t) c < \log(\epsilon/M)\nonumber\\
        \Rightarrow & \exp(-\gamma(t)c) < \frac{\epsilon}{M}
    \end{align}
    Remember that $\gamma$ is non-negative and $c < \distancefn^\Omega(\rvx; t)$ (from \cref{app:proofs:convergence:distancefn-lim}). Hence,
    \begin{equation}
        \exp(-\gamma(t) \distancefn^\Omega(\rvx; t)) < \exp(-\gamma(t)c) < \frac{\epsilon}{M}
    \end{equation}
    Here, if $p(\rvx, t)$ is equal to zero, $p(\rvx; t) \exp(-\gamma(t)\distancefn^\Omega(\rvx; t))$ is also equal to zero. Otherwise,
    \begin{align}
        \exp(-\gamma(t)\distancefn^\Omega(\rvx; t)) < \frac{\epsilon}{M} \leq \frac{\epsilon}{p(\rvx, t)} \Rightarrow p(\rvx; t) \exp(-\gamma(t)\distancefn^\Omega(\rvx; t)) < \epsilon.
    \end{align}
    Therefore, in both cases $p(\rvx; t) \exp(-\gamma(t)\distancefn^\Omega(\rvx; t)) < \epsilon$ which concludes the proof.
\end{proof}
Following \cref{lemma:app:converge-zero} and using \cref{eq:app:density-bound}, for all $\rvx \notin \Omega$, we have $\lim_{t \downarrow 0} p^\Omega(\rvx; t) = 0$. Following the continuity of $p^\Omega(\rvx; t)$ in $t$, we conclude 
\begin{equation}
    \forall \rvx \notin \Omega, \; p^\Omega(\rvx; 0) = 0.
\end{equation}
Further, since for any $\rvx \in \Omega$, by definition $\distancefn^\Omega(\rvx; 0) = 0$,
\begin{equation}
    \forall \rvx \in \Omega, \; p^\Omega(\rvx; 0) = p(\rvx; 0).
\end{equation}
Therefore, $p(\rvx; 0)$ is an $\Omega$-constrained distribution, meaning it will only place mass on $\Omega$.

\section{Image watermarking experiment}
Here we present our image watermarking experiment. We follow the experimental setup of \citep{liu2024mirror} where an image is considered ``watermarked'' if it lies within an orthonormal polytope $\Omega := \{\rvx \in \R^d: c_i < a_i^\transpose \rvx < b_i, \forall i\}$. Here, $a_i \in \R^d$ and $b_i$ and $c_i$ are scalars. The parameters $\{a_i, b_i, c_i\}_{i=1}^m$ are private tokens only visible to users.
Our implementation is based on the codebase of \citet{liu2024mirror}\footnote{\url{https://github.com/ghliu/mdm/}} with some modifications explained below.

\paragraph{Watermark parameters} We use 100 random orthonormal vectors $a_i$ that were generated and provided in the codebase of \citet{liu2024mirror}. The other parameters are $b_i = -0.9$ and $c_i = 0.9$.

\paragraph{Dataset} We use a watermarked version of the AFHQv2 dataset~\citep{choi2020stargan} for this experiment. Remember that our problem setup requires all the training data to fall within the constraint set $\Omega$. This is also the case for the Mirror Diffusion Models (MDM) \citet{liu2023learning}. Given a set of watermark parameters, we first watermark all the images in the training dataset. We then train our models and baselines on this watermarked dataset.
Following \citet{liu2024mirror}, we watermark an image by going through the $a_i$ parameters (orthonormal vectors) of the watermark and if the condition of $b_i < a_i^\transpose \rvx < c_i$ is not satisfied, we shift the features $\rvx$ by a random amount along the vector $a_i$ such that the constraint is satisfied. More formally, $\rvx' \leftarrow \rvx + \delta a_i$ where $\delta$ is sampled from a uniform distribution with bounds derived according to $a_i^\transpose\rvx$ and the bounds $b_i$ and $c_i$. As $a_i$s are orthogonal to each other, this modification would not violate the other constraints.

\paragraph{Evaluation metrics}
We report the following four metrics in this experiment:
\begin{enumerate}
    \item Infraction rate: The percentage of images generated by the model that violate the watermark constraints.
    \item Infraction loss: The average value of the distance function $\distancefn^\Omega$ of the images generated from the model.
    \item FID: The FrÃ©chet Inception Distance~\citep{heusel2017gans} between the generated images and the watermarked dataset. Note that the watermarked dataset is not the original AFHQv2 dataset but the watermarked version of it. This metric measures the perceptual similarity of the images generated from the model and the ones it was trained on.
    \item r-ELBO: The reweighted ELBO of the dataset assigned by model. This is effectively the training loss of the model.
\end{enumerate}
The first three metrics (infraction rate, infraction loss and FID) are computed on $N$ samples generated by the model where $N=15,804$ is the size of the training dataset.

\paragraph{Baselines} We compare te manual bridges under the three architectures \texttt{C-arch}, \texttt{DB-arch} and \texttt{MBM-arch} with the following baselines:
\begin{itemize}
    \item EDM-pretrained: a pretrained diffusion model from \citet{karras2022elucidating}. This model was trained on the original, non-watermarked AFHVQv2 dataset.
    \item EDM-finetuned: the same model as above but fine-tuned on the watermarked dataset.
    \item MDM: the Mirror Diffusion Model (MDM) from \citet{liu2024mirror}. MDM is restricted to convex constraints and requires defining a bijective mapping between the constraint set $\Omega$ and Euclidean space $\R^d$. This mapping is called a mirror map and is denoted by $(\nabla\phi, \nabla \phi^*)$ where $\nabla \phi^*$ is the inverse of $\nabla \phi$. Given a dataset with data points $\rvx \in \Omega$, MDM first applies $\nabla \phi$ to get $\rvy = \nabla\phi(\rvx) \in \R^d$ and trains a standard diffusion on the resulting dataset. Once trained, the samples generated by the model are transformed back to the constrained space by applying $\nabla \phi^*$. As a result, samples from MDM are guaranteed to lie within the constraint set $\Omega$.
    \item MDM-proj: the same model as EDM-finetuned, but with a projection operator applied to the generated images to ensure they fall within the constraint set.
\end{itemize}

\paragraph{Manual bridge definition} Here we explain different ingredients of manual bridges implemented. The ingredients are the distance function $\distancefn^\Omega$, the time-dependent scaling $\gamma$ and the conditioning signal used in $\texttt{C-arch}$ and $\texttt{MBM-arch}$.
\begin{itemize}
    \item \underline{Distance function}: We define a distance function $\distancefn^\Omega(\rvx; t) = \frac{1}{2} \norm{\mathrm{Proj}(\rvx) - \rvx}^2$. However, to avoid computational cost of backpropagating through the projection operator, we modify it to $\distancefn^\Omega(\rvx; t) = \frac{1}{2} \norm{\overline{\mathrm{Proj}(\rvx)} - \rvx}^2$ where the bar on $\overline{\mathrm{Proj}(\rvx)}$ denotes the stop-grad operation. Note $\distancefn^\Omega$ remains a distance function with this modification.
    \item \underline{Scale}: Our choice of scale function is $\gamma(t) = \frac{1}{\sigma^2(t)}\frac{\sigma_{\mathrm{data}}^2}{\sigma^2(t) + \sigma_{\mathrm{data}}^2}$. This satisfies the required conditions of $\gamma(T) \approx 0$ and $\lim_{t \rightarrow 0} \gamma(t) = \infty$.
    \item \underline{Conditioning}: We apply a separate scaling to the signal we pass to the model to condition on (in our \texttt{MBM-arch} as well as \texttt{C-arch}) in order to avoid its scale becoming large for large noise levels. The conditional signal is equal to $-\gamma'(t) \nabla_{\rvx_t}(\distancefn^\Omega(\rvx_t; t))$ where $\gamma'(t) = \frac{\sigma_\mathrm{data}}{\sqrt{\sigma^2(t) + \sigma_\mathrm{data}^2}}$.
    This is because $\Var[{\rvx_t}] = \sigma^2(t) + \sigma_\mathrm{data}^2$ in the variance-exploding diffusion process of EDM. Furthermore, we add a channel to the conditioning signal filled with $\1_{x \neq 0}(b(\rvx_t; t))$ where $\1_{x \neq 0}$ is an element-wise binary function that is only equal to zero when its input is zero. This modification empirically boosted the performance of our models.
\end{itemize}

\paragraph{Training} all the models and baselines (apart from EDM-pretrained which does not involve further training), are trained for $200,000$ iterations with a batch size of $256$. We use Adam optimizer with a learning rate of $2 \times 10^{-4}$. All the models initialized from the weights of EDM-pretrained.

\paragraph{Sampling} We used EDM's sampler with Heun correction and the parameters of $S_{\mathrm{churn}}=10$, $\sigma_{\mathrm{max}} = 80$ and $\sigma_{\mathrm{max}} = 10^{-5}$.

\paragraph{Results} \cref{tab:watermark-afhqv2-experiment} reports ours results of this experiment. We observe that MDM and MDM-proj achieve zero infraction rate because they both include a transformation operator in the end that places the generated sample in the constraint set. Intuitively, MDM-proj shifts the distribution since all the constrained-violating samples (which is more than 91\% of them as the samples are generated by EDM-finetuned) are moved to the boundary, resulting in an overpopulation of samples at the boundary. MDM, on the other hand, requires the mirror maps that are not available for complex constraints. In particular, it requires convex constraints. While the mirror maps are available in this experiment, in a more general setting such as that of \cref{sec:exp:ic}. Nonetheless, MDM suffers from a poor performance in terms of FID, suggesting a distribution shift. Manual bridges with \texttt{MBM-arch} achieves almost-zero infraction rate with the best FID and r-ELBO comparable to the best of baselines.

\begin{table*}[t] 
  \centering
  \begin{tabular}{lllll}
    \toprule
    \centering
    Method     & Infraction ($\%$)  $\downarrow$  & Inf. loss  $\downarrow$  & FID $\downarrow$ & r-ELBO ($\times 10^2$)$\uparrow$\\
    \midrule
    EDM-pretrained~\cite{karras2022elucidating} & $91.44 \pm 0.25$ & $0.35$ & $5.24 \pm 0.06$ & \underline{$-15.95 \pm 0.09$}\\
    EDM-finetuned & $91.52 \pm 0.39$ & $0.36$ & $2.95 \pm 0.09$ & $\mathbf{-15.78 \pm 0.07}$\\
    \midrule
    MDM~\citep{liu2024mirror} & $0$ & $0$ & $3.73 \pm 0.10$ & --\\
    MDM-proj~\citep{liu2024mirror} & $0$ & $0$ & $\underline{2.90 \pm 0.09}$ & --\\
    \midrule
    Manual bridge with \texttt{C-arch} & $90.74 \pm 0.17$ & $0.31$ & \underline{$2.77 \pm 0.07$} & $\mathbf{-15.80 \pm 0.05}$\\
    Manual bridge with \texttt{DB-arch} & $0$ & $0$ & $\underline{2.81 \pm 0.05}$ & $-16.54 \pm 0.10$\\
    Manual bridge with \texttt{MBM-arch} (ours) & $0.02 \pm 0.00$ & $3 \times 10^{-12}$ & $\mathbf{2.65 \pm 0.07}$ & $\mathbf{-15.83 \pm 0.03}$\\
    \bottomrule
  \end{tabular}
  \caption{Results for the image watermarking experiment on the AFHQv2 dataset.}
  \label{tab:watermark-afhqv2-experiment}
\end{table*}

\section{Additional Traffic Scene Generation Results}
In this section we provide more results from the traffic scene generation experiment. \cref{fig:app:additional:plots} shows the collision and offroad loss over the course of training of different models. Note that these models are all trained \textit{from scratch} as opposed to the results in the main text that the models were fine-tuned. Also note that collision and offroad loss are different than collision and offroad rates reported in the main text. The metrics here measure ``how bad'' the infractions are. A collision loss of zero corresponds to a collision rate of zero, and similarly for offroad. The trend we observe here is similar to that of the main text.

In \cref{fig:app:additional:samples} we provide more samples from different models, similar to the top row of \cref{fig:banner}.

\begin{figure*}[!htp]
    \centering
    \begin{subfigure}[t]{0.9\textwidth}
        \includegraphics[width=\textwidth]{figs/initial_conditions/laurel_and_marine_drive.pdf}
    \end{subfigure}
    
    \begin{subfigure}[t]{0.9\textwidth}
        \includegraphics[width=\textwidth]{figs/initial_conditions/granville_and_16th.pdf}
    \end{subfigure}

    \caption{A few more visualizations from Traffic Scene Generation experiment. From left to right: Standard diffusion, Bridge model (Offset), Conditional diffusion and \method{}. As traffic scenes become crowded, the occurrences of infraction show up in the samples generated from standard diffusion and condition diffusion models. While no infraction happens in the samples generated from Bridge model (Offset), the vehicle orientation and distances between vehicles are not convincingly realistic. Samples from \method{} appears more realistic and natural.}
    \label{fig:app:additional:samples}
\end{figure*}