@INPROCEEDINGS{baseline,
  author={Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J. and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
  booktitle={Proc. {IEEE} Int. Conf. Robot. Automat. }, 
  title={Target-driven visual navigation in indoor scenes using deep reinforcement learning}, 
  year={2017},
  volume={},
  number={},
  pages={3357-3364},
  keywords={Navigation;Training;Visualization;Learning (artificial intelligence);Three-dimensional displays;Physics;Robots},
  doi={10.1109/ICRA.2017.7989381}}

@INPROCEEDINGS{SAVN,
  author={Wortsman, Mitchell and Ehsani, Kiana and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning}, 
  year={2019},
  volume={},
  number={},
  pages={6743-6752},
  keywords={Training;Visualization;Computer vision;Adaptation models;Codes;Navigation;Machine learning;Visual Reasoning;Scene Analysis and Understanding;Statistical Learning},
  doi={10.1109/CVPR.2019.00691}}

@InProceedings{mjol,
  title = 	 {Learning hierarchical relationships for object-goal navigation},
  author =       {Pal, Anwesan and Qiu, Yiding and Christensen, Henrik},
  booktitle = 	 {Proc. Conf. Robot Learn.},
  pages = 	 {517--528},
  year = 	 {2021},
  volume = 	 {155},
}

@INPROCEEDINGS{SSNet,
  author={Zhao, Qianfan and Zhang, Lu and He, Bin and Qiao, Hong and Liu, Zhiyong},
  booktitle={Proc. {IEEE} Int. Conf. Robot. Automat.}, 
  title={Zero-Shot Object Goal Visual Navigation}, 
  year={2023},
  volume={},
  number={},
  pages={2025-2031},
  keywords={Training;Visualization;Correlation;Codes;Automation;Navigation;Semantics},
  doi={10.1109/ICRA48891.2023.10161289}}

@article{Li,
  title={Context vector-based visual mapless navigation in indoor using hierarchical semantic information and meta-learning},
  author={Fei-Fei Li and Chi Guo and Huyin Zhang and Binhan Luo},
  journal={Complex Intell. Syst.},
  year={2022},
  volume={9},
  pages={2031-2041},
}

@article{ai2thor,
  title={AI2-THOR: An Interactive 3D Environment for Visual AI},
  author={Eric Kolve and Roozbeh Mottaghi and Winson Han and Eli VanderBilt and Luca Weihs and Alvaro Herrasti and Matt Deitke and Kiana Ehsani and Daniel Gordon and Yuke Zhu and Aniruddha Kembhavi and Abhinav Kumar Gupta and Ali Farhadi},
  year={2017},
  note={\textit{arXiv:1712.05474}}
}

@article{metric,
  title={On Evaluation of Embodied Navigation Agents},
  author={Peter Anderson and Angel X. Chang and Devendra Singh Chaplot and Alexey Dosovitskiy and Saurabh Gupta and Vladlen Koltun and Jana Kosecka and Jitendra Malik and Roozbeh Mottaghi and Manolis Savva and Amir Zamir},
  year={2018},
  note={\textit{arXiv:1807.06757}}
}

@inproceedings{ORG,
author = {Du, Heming and Yu, Xin and Zheng, Liang},
title = {Learning Object Relation Graph and Tentative Policy for Visual Navigation},
year = {2020},
isbn = {978-3-030-58570-9},
booktitle = {Proc. Eur. Conf. Comput. Vision},
pages = {19-34},
numpages = {16},
keywords = {Graph, Imitation learning, Tentative policy learning, Visual navigation},
location = {Glasgow, United Kingdom}
}

@article{SP,
  title={Visual Semantic Navigation using Scene Priors},
  author={Wei Yang and X. Wang and Ali Farhadi and Abhinav Kumar Gupta and Roozbeh Mottaghi},
  year={2018},
  note={\textit{arXiv:1810.06543}}
}

@INPROCEEDINGS{VTNet,
title={{VTN}et: Visual Transformer Network for Object Goal Navigation},
author={Heming Du and Xin Yu and Liang Zheng},
booktitle={Proc. Int. Conf. Learn. Representations},
year={2021},
pages = {1-16},
}

@INPROCEEDINGS{OMT,
  author={Fukushima, Rui and Ota, Kei and Kanezaki, Asako and Sasaki, Yoko and Yoshiyasu, Yusuke},
  booktitle={Proc. Int. Conf. Robot. Automat.}, 
  title={Object Memory Transformer for Object Goal Navigation}, 
  year={2022},
  volume={},
  number={},
  pages={11288-11294},
  keywords={Three-dimensional displays;Navigation;Semantics;Reinforcement learning;Benchmark testing;Transformers;Encoding}}

@ARTICLE{ral,
  author={Druon, Raphael and Yoshiyasu, Yusuke and Kanezaki, Asako and Watt, Alassane},
  journal={{IEEE} Robot. Automat. Lett.}, 
  title={Visual Object Search by Learning Spatial Context}, 
  year={2020},
  volume={5},
  number={2},
  pages={1279-1286},
  keywords={Navigation;Visualization;Feature extraction;Task analysis;Search problems;Semantics;Three-dimensional displays;Deep learning in robotics and automation;visual-based navigation;autonomous agents},
  doi={10.1109/LRA.2020.2967677}}

@article{Lyu2022ImprovingTV,
  title={Improving Target-driven Visual Navigation with Attention on 3D Spatial Relationships},
  author={Yunlian Lyu and Yimin Shi and Xianggang Zhang},
  journal={Neural Process. Lett.},
  year={2022},
  volume={54},
  pages={3979 - 3998},
}

@INPROCEEDINGS{SpatialAtt,
  author={Mayo, Bar and Hazan, Tamir and Tal, Ayellet},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={Visual Navigation with Spatial Attention}, 
  year={2021},
  volume={},
  number={},
  pages={16893-16902},
  keywords={Visualization;Computer vision;Navigation;Semantics;Reinforcement learning;Pattern recognition;Task analysis},
  doi={10.1109/CVPR46437.2021.01662}}


@ARTICLE{SemanticPolicy,
  author={Zhao, Qianfan and Zhang, Lu and He, Bin and Liu, Zhiyong},
  journal={{IEEE} Robot. Automat. Lett.}, 
  title={Semantic Policy Network for Zero-Shot Object Goal Visual Navigation}, 
  year={2023},
  volume={8},
  number={11},
  pages={7655-7662},
  keywords={Semantics;Navigation;Visualization;Robots;Task analysis;Training;Feature extraction;Deep learning;path planning;reinforcement learning;vision-based navigation},
  doi={10.1109/LRA.2023.3320014}}

@INPROCEEDINGS{cow,
  author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation}, 
  year={2023},
  volume={},
  number={},
  pages={23171-23181},
  keywords={Training;Location awareness;Adaptation models;Navigation;Wheels;Cows;Pattern recognition;Embodied vision: Active agents;simulation},
  doi={10.1109/CVPR52729.2023.02219}}

@article{goat,
  title={GOAT: GO to Any Thing},
  author={Matthew Chang and Th{\'e}ophile Gervet and Mukul Khanna and Sriram Yenamandra and Dhruv Shah and So Yeon Min and Kavit Shah and Chris Paxton and Saurabh Gupta and Dhruv Batra and Roozbeh Mottaghi and Jitendra Malik and Devendra Singh Chaplot},
  year={2023},
  note={\textit{arXiv:2311.06430}}
}

@INPROCEEDINGS{simpleclip,
  author={Khandelwal, Apoorv and Weihs, Luca and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={Simple but Effective: CLIP Embeddings for Embodied AI}, 
  year={2022},
  volume={},
  number={},
  pages={14809-14818},
  keywords={Training;Measurement;Visualization;Computer vision;Navigation;Semantics;Robot vision systems;Robot vision; Navigation and autonomous driving},
  doi={10.1109/CVPR52688.2022.01441}}

@inproceedings{ZSON,
 author = {Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
 booktitle = {Proc. Advances Neural Inf. Process. Syst.},
 pages = {32340--32352},
 title = {ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings},
 volume = {35},
 year = {2022}
}


@InProceedings{CLIP,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proc. Int. Conf. Mach. Learn.},
  pages = 	 {8748--8763},
  year = 	 {2021},
  volume = 	 {139},
}


@InProceedings{a3c,
  title = 	 {Asynchronous Methods for Deep Reinforcement Learning},
  author = 	 {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = 	 {Proc. Int. Conf. Mach. Learn.},
  pages = 	 {1928--1937},
  year = 	 {2016},
  volume = 	 {48},
}

@INPROCEEDINGS{Siamese,
  author={Chopra, S. and Hadsell, R. and LeCun, Y.},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={Learning a similarity metric discriminatively, with application to face verification}, 
  year={2005},
  volume={1},
  number={},
  pages={539-546},
  keywords={Character generation;Drives;Robustness;System testing;Spatial databases;Glass;Artificial neural networks;Support vector machines;Support vector machine classification;Face recognition},
  doi={10.1109/CVPR.2005.202}}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
 booktitle = {Proc. Advances Neural Inf. Process. Syst.},
 pages = {6000-6010},
 title = {Attention is All you Need},
 year = {2017}
}

@inproceedings{vt,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={Proc. Int. Conf. Learn. Representations},
year={2021},
pages = {1-22}
}

@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proc. Conf. Empirical Methods Natural Lang. Process.",
    year = "2014",
    pages = "1532--1543",
}

@ARTICLE{face,
  author={Mokhayeri, Fania and Granger, Eric},
  journal={{IEEE} trans. biom. behav. identity sci. }, 
  title={Video Face Recognition Using Siamese Networks With Block-Sparsity Matching}, 
  year={2020},
  volume={2},
  number={2},
  pages={133-144},
  keywords={Face;Feature extraction;Three-dimensional displays;Solid modeling;Training;Face recognition;Video surveillance;face recognition;deep learning;Siamese networks;single sample per person problems;3D face synthesis;block sparsity;domain adaptation},
  doi={10.1109/TBIOM.2019.2949364}}

@INPROCEEDINGS{signature,
  author={Wu, Xiaomeng and Kimura, Akisato and Uchida, Seiichi and Kashino, Kunio},
  booktitle={Proc. {IEEE} Int. Conf. Acoust. Speech Signal Process.}, 
  title={Prewarping Siamese Network: Learning Local Representations for Online Signature Verification}, 
  year={2019},
  volume={},
  number={},
  pages={2467-2471},
  keywords={Time series analysis;Time measurement;Testing;Training;Distortion measurement;Nonlinear distortion;Biometrics;DTW;feature learning;online signature verification;Siamese network},
  doi={10.1109/ICASSP.2019.8683036}}

@INPROCEEDINGS{akgvp,
  author={Xu, Nuo and Wang, Wen and Yang, Rong and Qin, Mengjie and Lin, Zheyuan and Song, Wei and Zhang, Chunlong and Gu, Jason and Li, Chao},
  booktitle={{IEEE} Int. Conf. Robot. Automat.}, 
  title={Aligning Knowledge Graph with Visual Perception for Object-goal Navigation}, 
  year={2024},
  volume={},
  number={},
  pages={5214-5220},
  keywords={Visualization;Accuracy;Navigation;Natural languages;Knowledge graphs;Vectors;Task analysis}}


@INPROCEEDINGS{yolov7,
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors}, 
  year={2023},
  volume={},
  number={},
  pages={7464-7475},}

@misc{doze,
      title={DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic Environments}, 
      author={Ji Ma and Hongming Dai and Yao Mu and Pengying Wu and Hao Wang and Xiaowei Chi and Yang Fei and Shanghang Zhang and Chang Liu},
      year={2024},
      note={\textit{arXiv:2402.19007}}, 
}

@inproceedings{
wu2024voronav,
title={VoroNav: Voronoi-based Zero-shot Object Navigation with Large Language Model},
author={Pengying Wu and Yao Mu and Bingxian Wu and Yi Hou and Ji Ma and Shanghang Zhang and Chang Liu},
booktitle={Proc. Int. Conf. Mach. Learn.},
year={2024},
url={https://openreview.net/forum?id=Va7mhTVy5s}
}

@ARTICLE{tdanet,
  author={Lian, Shiwei and Zhang, Feitian},
  journal={{IEEE} Robot. Automat. Lett.}, 
  title={TDANet: Target-Directed Attention Network for Object-Goal Visual Navigation With Zero-Shot Ability}, 
  year={2024},
  volume={9},
  number={9},
  pages={8075-8082},
}

@INPROCEEDINGS{hoz,
  author={Zhang, Sixian and Song, Xinhang and Bai, Yubing and Li, Weijie and Chu, Yakui and Jiang, Shuqiang},
  booktitle={Proc. {IEEE/CVF} Int. Conf. Comput. Vis.}, 
  title={Hierarchical Object-to-Zone Graph for Object Navigation}, 
  year={2021},
  volume={},
  number={},
  pages={15110-15120},
}

@INPROCEEDINGS{lstde,
  author={Zhang, Sixian and Song, Xinhang and Li, Weijie and Bai, Yubing and Yu, Xinyao and Jiang, Shuqiang},
  booktitle={Proc. {IEEE/CVF} Conf. Comput. Vis. Pattern Recognit.}, 
  title={Layout-based Causal Inference for Object Navigation}, 
  year={2023},
  volume={},
  number={},
  pages={10792-10802},
  keywords={Training;Visualization;Computer vision;Codes;Navigation;Layout;Pattern recognition;Embodied vision: Active agents;simulation},
}

@INPROCEEDINGS{drqn,
  author={Chen, Yu’an and Chen, Guangda and Pan, Lifan and Ma, Jun and Zhang, Yu and Zhang, Yanyong and Ji, Jianmin},
  booktitle={{IEEE/RSJ} Int. Conf. Intell. Robots Syst.}, 
  title={{DRQN-based} {3D} Obstacle Avoidance with a Limited Field of View}, 
  year={2021},
  volume={},
  number={},
  pages={8137-8143},
  doi={10.1109/IROS51168.2021.9635949}}

@ARTICLE{humanoid,
  author={Lobos-Tsunekawa, Kenzo and Leiva, Francisco and Ruiz-del-Solar, Javier},
  journal={{IEEE} Robot. Automat. Lett.}, 
  title={Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning}, 
  year={2018},
  volume={3},
  number={4},
  pages={3247-3254},
  keywords={Navigation;Visualization;Task analysis;Robot kinematics;Robot sensing systems;Visual-based navigation;deep learning in robotics and automation and humanoid robots},
  doi={10.1109/LRA.2018.2851148}}

@ARTICLE{coll1,
  author={Xiao, Wendong and Yuan, Liang and He, Li and Ran, Teng and Zhang, Jianbo and Cui, Jianping},
  journal={{IEEE} Trans. Instrum. Meas.}, 
  title={Multigoal Visual Navigation With Collision Avoidance via Deep Reinforcement Learning}, 
  year={2022},
  volume={71},
  number={},
  pages={1-9},
  keywords={Navigation;Visualization;Task analysis;Trajectory;Collision avoidance;Reinforcement learning;Training;Collision avoidance;deep reinforcement learning (DRL);multigoal navigation;visual sensor},
  doi={10.1109/TIM.2022.3158384}}

@ARTICLE{dual,
  author={Wu, Qiaoyun and Gong, Xiaoxi and Xu, Kai and Manocha, Dinesh and Dong, Jingxuan and Wang, Jun},
  journal={{IEEE} Robot. Automat. Lett.}, 
  title={Towards Target-Driven Visual Navigation in Indoor Scenes via Generative Imitation Learning}, 
  year={2021},
  volume={6},
  number={1},
  pages={175-182},
  keywords={Navigation;Robots;Collision avoidance;Visualization;Task analysis;Mobile robots;Trajectory;Visual-based navigation;model learning for control;imitation learning;premature collision prediction;target checking},
  doi={10.1109/LRA.2020.3036597}}

@ARTICLE{tro,
  author={Devo, Alessandro and Mezzetti, Giacomo and Costante, Gabriele and Fravolini, Mario L. and Valigi, Paolo},
  journal={{IEEE} Trans. Robot.}, 
  title={Towards Generalization in Target-Driven Visual Navigation by Using Deep Reinforcement Learning}, 
  year={2020},
  volume={36},
  number={5},
  pages={1546-1561},
  keywords={Navigation;Visualization;Task analysis;Training;Machine learning;Simultaneous localization and mapping;Deep learning in robotics and automation;target-driven visual navigation;visual-based navigation;visual learning},
  doi={10.1109/TRO.2020.2994002}}
