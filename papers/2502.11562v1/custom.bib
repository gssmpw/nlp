@article{cambon2023early,
  title={Early LLM-based Tools for Enterprise Information Workers Likely Provide Meaningful Boosts to Productivity},
  author={Cambon, Alexia and Hecht, Brent and Edelman, Ben and Ngwe, Donald and Jaffe, Sonia and Heger, Amy and Vorvoreanu, Mihaela and Peng, Sida and Hofman, Jake and Farach, Alex and others},
  journal={Microsoft Research. MSR-TR-2023-43},
  year={2023}
} 

@manual{langchain,
  author    = {LangChain},
  title     = {LangChain homepage},
  url       = {https://www.langchain.com},
  year      = {2024}
}

@manual{llamaindex,
  author    = {LlamaIndex},
  title     = {LlamaIndex - Build Knowledge Assistants over your Enterprise Data},
  url       = {https://www.llamaindex.ai},
  year      = {2024}
}

@manual{anthropic2024claude,
  author    = {Anthropic},
  title     = {The Claude 3 Model Family: Opus, Sonnet, Haiku},
  url       = {https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf},
  year      = {2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
} 

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
} 

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{zhao2024dense,
  title={Dense text retrieval based on pretrained language models: A survey},
  author={Zhao, Wayne Xin and Liu, Jing and Ren, Ruiyang and Wen, Ji-Rong},
  journal={ACM Transactions on Information Systems},
  volume={42},
  number={4},
  pages={1--60},
  year={2024},
  publisher={ACM New York, NY}
}

@article{xiao2024c,
  title={C-pack: Packed resources for general chinese embeddings},
  author={Xiao, Shitao and Liu, Zheng and Zhang, Peitian and Muennighoff, Niklas and Lian, Defu and Nie, Jian-Yun},
  journal={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2024}
} 

@article{wang2023improving,
  title={Improving text embeddings with large language models},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2401.00368},
  year={2023}
} 

@article{neelakantan2022text,
  title={Text and code embeddings by contrastive pre-training},
  author={Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford, Alec and Han, Jesse Michael and Tworek, Jerry and Yuan, Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy, Chris and others},
  journal={arXiv preprint arXiv:2201.10005},
  year={2022}
}

@article{izacard2021unsupervised,
  title={Unsupervised dense information retrieval with contrastive learning},
  author={Izacard, Gautier and Caron, Mathilde and Hosseini, Lucas and Riedel, Sebastian and Bojanowski, Piotr and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:2112.09118},
  year={2021}
}

@article{ma2020zero,
  title={Zero-shot neural passage retrieval via domain-targeted synthetic question generation},
  author={Ma, Ji and Korotkov, Ivan and Yang, Yinfei and Hall, Keith and McDonald, Ryan},
  journal={arXiv preprint arXiv:2004.14503},
  year={2020}
}

@article{wang2021gpl,
  title={GPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval},
  author={Wang, Kexin and Thakur, Nandan and Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2112.07577},
  year={2021}
}

@article{gao2022precise,
  title={Precise zero-shot dense retrieval without relevance labels},
  author={Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
  journal={arXiv preprint arXiv:2212.10496},
  year={2022}
} 

@article{wang2023query2doc,
  title={Query2doc: Query expansion with large language models},
  author={Wang, Liang and Yang, Nan and Wei, Furu},
  journal={arXiv preprint arXiv:2303.07678},
  year={2023}
}

@article{mao2020generation,
  title={Generation-augmented retrieval for open-domain question answering},
  author={Mao, Yuning and He, Pengcheng and Liu, Xiaodong and Shen, Yelong and Gao, Jianfeng and Han, Jiawei and Chen, Weizhu},
  journal={arXiv preprint arXiv:2009.08553},
  year={2020}
} 

@article{thakur2021beir,
  title={Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models},
  author={Thakur, Nandan and Reimers, Nils and R{\"u}ckl{\'e}, Andreas and Srivastava, Abhishek and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2104.08663},
  year={2021}
} 

@article{chen2024air,
  title={AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark},
  author={Chen, Jianlyu and Wang, Nan and Li, Chaofan and Wang, Bo and Xiao, Shitao and Xiao, Han and Liao, Hao and Lian, Defu and Liu, Zheng},
  journal={arXiv preprint arXiv:2412.13102},
  year={2024}
} 

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
} 

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
} 

@article{sun2023chatgpt,
  title={Is ChatGPT good at search? investigating large language models as re-ranking agents},
  author={Sun, Weiwei and Yan, Lingyong and Ma, Xinyu and Wang, Shuaiqiang and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Ren, Zhaochun},
  journal={arXiv preprint arXiv:2304.09542},
  year={2023}
} 

@article{wang2022simlm,
  title={Simlm: Pre-training with representation bottleneck for dense passage retrieval},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2207.02578},
  year={2022}
} 

@article{chen2024bge,
  title={Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation},
  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  journal={arXiv preprint arXiv:2402.03216},
  year={2024}
} 

@article{bajaj2016ms,
  title={Ms marco: A human generated machine reading comprehension dataset},
  author={Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and others},
  journal={arXiv preprint arXiv:1611.09268},
  year={2016}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
} 

@article{hui2024qwen2,
  title={Qwen2. 5-coder technical report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
} 

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
} 

@article{nogueira2019document,
  title={Document expansion by query prediction},
  author={Nogueira, Rodrigo and Yang, Wei and Lin, Jimmy and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1904.08375},
  year={2019}
}

@misc{xiao2022retromae,
      title={RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder}, 
      author={Shitao Xiao and Zheng Liu and Yingxia Shao and Zhao Cao},
      year={2022},
      eprint={2205.12035},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.12035}, 
} 

@article{zhang2023miracl,
  title={Miracl: A multilingual retrieval dataset covering 18 diverse languages},
  author={Zhang, Xinyu and Thakur, Nandan and Ogundepo, Odunayo and Kamalloo, Ehsan and Alfonso-Hermelo, David and Li, Xiaoguang and Liu, Qun and Rezagholizadeh, Mehdi and Lin, Jimmy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1114--1131},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
} 

@article{wang2022text,
  title={Text embeddings by weakly-supervised contrastive pre-training},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2212.03533},
  year={2022}
} 

@article{su2022one,
  title={One embedder, any task: Instruction-finetuned text embeddings},
  author={Su, Hongjin and Shi, Weijia and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A and Zettlemoyer, Luke and Yu, Tao},
  journal={arXiv preprint arXiv:2212.09741},
  year={2022}
}

@inproceedings{bonifacio2022inpars,
  title={Inpars: Unsupervised dataset generation for information retrieval},
  author={Bonifacio, Luiz and Abonizio, Hugo and Fadaee, Marzieh and Nogueira, Rodrigo},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2387--2392},
  year={2022}
} 

@article{jeronymo2023inpars,
  title={Inpars-v2: Large language models as efficient dataset generators for information retrieval},
  author={Jeronymo, Vitor and Bonifacio, Luiz and Abonizio, Hugo and Fadaee, Marzieh and Lotufo, Roberto and Zavrel, Jakub and Nogueira, Rodrigo},
  journal={arXiv preprint arXiv:2301.01820},
  year={2023}
} 

@article{li2023towards,
  title={Towards general text embeddings with multi-stage contrastive learning},
  author={Li, Zehan and Zhang, Xin and Zhang, Yanzhao and Long, Dingkun and Xie, Pengjun and Zhang, Meishan},
  journal={arXiv preprint arXiv:2308.03281},
  year={2023}
} 

@article{zhang2024jasper,
  title={Jasper and Stella: distillation of SOTA embedding models},
  author={Zhang, Dun and others},
  journal={arXiv preprint arXiv:2412.19048},
  year={2024}
}