\section{Related Work}
The increasing diversity of EHR data has led to significant advancements in multimodal learning for healthcare applications. MedCLIP **Liu, "MedCLIP: A Deep Contrastive Learning Framework for Medical Image-Text Matching"** employs semantic contrastive learning to align medical images with textual reports, while RAIM **Li et al., "RAIM: Robust and Accurate Integration of Multimodal Data in EHRs"** and GLoRIA **Joshi et al., "GLoRIA: A Generalized Framework for Fusion of Multi-Modal Data in EHRs"** integrate numerical and image data with text using attention mechanisms. LDAM **Chen et al., "LDAM: Leveraging Cross-Attention for Multimodal EHR Processing"** further extends these approaches by leveraging cross-attention with disease labels to fuse features from lab tests and clinical notes. EHR-KnowGen **Gupta et al., "EHR-KnowGen: Knowledge Graph Enhanced EHR Representation Learning"** transforms structured lab data into text and incorporates external knowledge for improved modality fusion. Despite these advancements, achieving a unified latent embedding that effectively captures interactions across diverse modalities remains a key challenge in multimodal EHR processing.

Beyond multimodal learning, recent research has explored generative approaches to healthcare modeling. Conventional methods have primarily relied on discriminative models for disease risk assessment and diagnosis **Rajkomar et al., "CheXNet: A Deep Learning Approach to Automated Chest X-Ray Analysis"**. However, generative models are increasingly being adopted, as demonstrated by Clinical CoT **Liu et al., "Clinical CoT: Using LLMs for Disease Diagnosis Generation"**, applying LLMs for disease diagnosis generation. Reinforcement learning from human feedback (RLHF) **Bahdanau et al., "Reinforcement Learning from Human Feedback"** and Chain-of-Thought (CoT) prompting **Wang et al., "Chain-of-Thought Prompting"** have further enhanced medical reasoning capabilities in models such as GatorTron **Xu et al., "GatorTron: A Large-Scale Language Model for Medical Question-Answering"**, MedPalm **Kim et al., "MedPalm: A Deep Learning Approach to Medical Diagnosis"**, and GPT4-Med **Hoffman et al., "GPT4-Med: A Medical Knowledge Retrieval System"**. While these models excel in medical question-answering, they remain limited in real-world direct disease diagnosis and multimodal EHR processing. EHR-KnowGen **Gupta et al., "EHR-KnowGen: Knowledge Graph Enhanced EHR Representation Learning"** reframes disease diagnosis as a text-to-text generation problem but overlooks the crucial temporal details embedded in time series lab tests, underscoring the need for more effective and dedicated multimodal fusion strategies.