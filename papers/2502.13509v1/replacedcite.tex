\section{Related Work}
The increasing diversity of EHR data has led to significant advancements in multimodal learning for healthcare applications. MedCLIP ____ employs semantic contrastive learning to align medical images with textual reports, while RAIM ____ and GLoRIA ____ integrate numerical and image data with text using attention mechanisms. LDAM ____ further extends these approaches by leveraging cross-attention with disease labels to fuse features from lab tests and clinical notes. EHR-KnowGen ____ transforms structured lab data into text and incorporates external knowledge for improved modality fusion. Despite these advancements, achieving a unified latent embedding that effectively captures interactions across diverse modalities remains a key challenge in multimodal EHR processing.

Beyond multimodal learning, recent research has explored generative approaches to healthcare modeling. Conventional methods have primarily relied on discriminative models for disease risk assessment and diagnosis ____. However, generative models are increasingly being adopted, as demonstrated by Clinical CoT ____, applying LLMs for disease diagnosis generation. Reinforcement learning from human feedback (RLHF) ____ and Chain-of-Thought (CoT) prompting ____ have further enhanced medical reasoning capabilities in models such as GatorTron ____, MedPalm ____, and GPT4-Med ____. While these models excel in medical question-answering, they remain limited in real-world direct disease diagnosis and multimodal EHR processing. EHR-KnowGen ____ reframes disease diagnosis as a text-to-text generation problem but overlooks the crucial temporal details embedded in time series lab tests, underscoring the need for more effective and dedicated multimodal fusion strategies.

%