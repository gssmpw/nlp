%! root=./main.tex
\begin{abstract}\label{sec:abstract}

    Transparency and interpretability are crucial for enhancing customer confidence and user engagement, especially when dealing with black-box \ml-based recommendation systems. Modern recommendation systems leverage \gnn due to their ability to produce high-quality recommendations in terms of both relevance and diversity. Therefore, the explainability of \gnn is especially important for \lp tasks since recommending relevant items can be viewed as predicting links between users and items. \gnn explainability has been a well-studied field, existing methods primarily focus on node or graph-level tasks, leaving a gap in \lp explanation techniques.

    This work introduces \pnameexp, a \gnn explanation framework designed explicitly for heterogeneous link prediction tasks. \pnameexp utilizes structural and attribute perturbation to identify critical substructures and important features while reducing the search space by leveraging domain-specific knowledge. In our experimentation, we show the efficacy of \pnameexp in generating contextually relevant and human-interpretable explanations for \pname, a \gnn-based recommendation engine, using a real-world real-estate dataset from \underline{Zi}llow Group, Inc. We also compare \pnameexp to \sota \gnn explainers to show \pnameexp's superiority in producing high-quality human-interpretable explanations.

\end{abstract}