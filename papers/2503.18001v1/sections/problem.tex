% %! root=../main.tex
% \section{Problem Statement}\label{sec:problem-statement}

% \subsection{Knowledge Graph Construction.}

% \subsection{\pname Architecture}

% \subsection{Ground Truth}

%! root=../main.tex
\section{Problem Statement}\label{sec:problem-statement}

In this section, we formally define the problem of providing interpretable explanations for the link prediction task in \gnn-based recommendation systems using whole heterogeneous graphs. The key challenge is to provide human-interpretable insights that align with the ground-truth so that user confidence and user trust is confirmed. Therefore, we aim to identify the most important feature subset and critical subgraphs used for recommendation by a \gnn-based recommendation engine using a real-world heterogeneous real-estate dataset (\eg Zillow Group, Inc).

\heading{Recommendation Task.} The \textit{primary task} of the recommendation system discussed here is to predict the likelihood of a link between a user \( u \in \mathcal{V}_u \) and a city \( l \in \mathcal{V}_c \) based on observed interactions and the graph structure. This is formalized as a link prediction problem: $\hat{y}_{uc} = f_{\theta} (u, c, \mathcal{G})$, where \( f_{\theta} \) is the link prediction model parameterized by \( \theta \), and \( \hat{y}_{uc} \) is the predicted probability of an interaction between user \( u \) and city \( c \).

% describe the architecture of the proposed \pname system,

\section{Preliminaries}

We outline the construction of interaction graphs used for recommendation and define the ground-truth data leveraged for training and evaluating our models.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{igraph.pdf}
	\caption{Interaction graph from a real-estate dataset.}
	\label{fig:igraph}
\end{figure}

\subsection{Interaction Graph}\label{sec:inter-graph}

The user interaction data in real-estate is inherently relational, comprising of entities such as users, listings, and cities, along with various interaction types like \code{views}, \code{saves}, and \code{tours} as shown in \autoref{fig:igraph} and listed in \autoref{tab:edge-attr} (more details in \autoref{sec:graph-details}). We focus primarily on three entities in this study since location is the most important factor in the home-buying process~\cite{harrison2022taxonomic}. All searches on Zillow Group, Inc website~\cite{zillowwebsite} correspond to a location, and we consider the city to be one of the entities, in addition to the interactions between users and listings. Since every listing belongs to a city, a special \code{contains} edge is added between the listing and the city. These entities and interactions are best modeled as a heterogeneous interaction graph \( \mathcal{G} = (\mathcal{V}, \mathcal{E}) \), where:
\begin{itemize}
    \item \( \mathcal{V} \) represents the set of nodes (\eg user, listing, and city)
    \item \( \mathcal{E} \subseteq \mathcal{V} \times \mathcal{V} \) denotes the set of edges that encode interactions (\eg user $\rightarrow$ \code{views} $\rightarrow$ listing, city $\rightarrow$ \code{contains} $\rightarrow$ listing).
\end{itemize}
The construction of the interaction graph \( \mathcal{G} \) involves aggregating data from multiple sources, such as user behavior logs, listing metadata, and geographical information. Each edge \( e \in \mathcal{E} \) is associated with a type \( \tau(e) \), representing the nature of the relationship between two nodes. Formally, we define a heterogeneous interaction graph as:
$\mathcal{G} = \left( \mathcal{V}_u \cup \mathcal{V}_l \cup \mathcal{V}_c, \mathcal{E}_{ul} \cup \mathcal{E}_{cl} \cup \mathcal{E}_{uc} \right)$, where \( \mathcal{V}_u \), \( \mathcal{V}_l \), and \( \mathcal{V}_c \) represent the sets of user, listing, and city nodes, respectively. \( \mathcal{E}_{ul} \) corresponds to interactions between users and listings, \( \mathcal{E}_{cl} \) captures relationships between cities and listings, and \( \mathcal{E}_{uc} \) captures relationships between users and cities. 

\subsection{Ground Truth}

The ground truth for training and evaluating is derived from historical user interactions with listings on the platform. Specifically, the interaction logs provide labels for whether a user \( u \) has engaged with a listing \( l \) (\eg viewed, saved, and toured), resulting in positive examples for link prediction. We infer the user to city interaction based on the listing interaction as listings are all associated with a city. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{neg.pdf}
	\caption{Negative graph construction from positive graph.}
	\label{fig:neg}
\end{figure}

Negative examples are defined by selecting edges between users and cities (or listing) where no interaction has been recorded, assuming that non-interaction implies a lack of interest. These are weak negative edges, as there is no explicit evidence that the user dislikes the item. However, for our use case in real estate, we argue that a user's lack of interaction and interest are closely aligned, given the context where the items are either listings or cities. Thus, incorporating weak negative edges to create a negative graph helps the recommendation model learn finer distinctions about the city (or listing) preferences and understand why users do not interact with them. A negative graph is generated by sampling negative edges from user-listing and user-city pairs as shown in \autoref{fig:neg}. 

We generate ground truth explanations by identifying the subgraphs most relevant for each prediction and compare their node features to identify their similarity. These subgraphs serve as interpretable justifications for why a specific user \( u \) is likely to engage with listing \( l \), thus providing a transparent and trustworthy recommendation system.

Formally, let \( \mathcal{Y} \subseteq \mathcal{V}_u \times \mathcal{V}_l \) be the set of observed interactions (positive examples), and \( \mathcal{Y'} \subseteq \mathcal{V}_u \times \mathcal{V}_l \) be the set of sampled negative examples. The training set \( \mathcal{T} \) is constructed as $\mathcal{T} = \{ (u, l, y_{ul}) \mid (u, l) \in \mathcal{Y} \cup \mathcal{Y'}$,
where \( y_{ul} = 1 \) if \( (u, l) \in \mathcal{Y} \) and \( y_{ul} = 0 \) if \( (u, l) \in \mathcal{Y'} \).

\subsection{\pname Architecture}

\pname is a Graph Neural Network-based recommendation engine designed to operate on heterogeneous graphs \( \mathcal{G} \) built using real-world real-estate (\eg Zillow Group, Inc.) interaction data. \pname not only models user-listing (or city) interactions for recommendation but also captures contextual information such as city-level influences and item similarities. The ability to leverage heterogeneous relationships improves the recommendation quality by allowing the system to reason about multi-hop dependencies and indirectly related entities. 

\pname utilized the Zillow Group, Inc. dataset for modeling and evaluation purposes, demonstrating its effectiveness in a real-world recommendation system. However, the architecture of \pname is generic and can be adapted to various platforms across different domains. \pname can be extended to use cases where the context is critical in influencing user decisions, such as (user, item, context/category), where the user and item types will dictate the node types, and the context interaction between the user and item will for the edges. For instance, it can model different interactions: (user, food, restaurant) in the food industry, (user, post, topic) in social media, (patient, doctor, hospital) in healthcare, or (user, job, company) in the job search industry. By leveraging the interaction graph creation and behavioral learning flexibility, \pname can cater to a wide range of recommendation scenarios, enhancing user satisfaction and specific context-aware decision-making across multiple domains.

The \pname consists of the following components:

\begin{enumerate}
    \item Node Embedding Layer: Each node \( v \in \mathcal{V} \) is mapped to a dense vector representation \( \mathbf{h}_v \in \mathbb{R}^d \) using an embedding layer. The initial embeddings are learned from the node features and are iteratively updated during the training process.

    \item Message Passing Mechanism: \pname employs a multi-hop message passing mechanism, where each node \( v \in \mathcal{V} \) aggregates information from its neighbors \( \mathcal{N}(v) \) through a learnable function. The node update rule for \( t \)-th layer is defined as $\mathbf{h}_v^{(t+1)} = \text{AGG}\left( \mathbf{h}_v^{(t)}, \left\{ \mathbf{h}_u^{(t)} : u \in \mathcal{N}(v) \right\} \right)$, where \( \text{AGG} \) is an aggregation function such as sum, mean, or attention-based pooling. This allows the model to capture higher-order dependencies between nodes.

    \item Link Prediction: The final node embeddings \( \mathbf{h}_u \) and \( \mathbf{h}_l \) for users and listings are fed into a scoring function to compute the likelihood of a link using $\hat{y}_{ul} = \sigma(\mathbf{h}_u^T W \mathbf{h}_l)$,    where \( \sigma \) is the sigmoid function and \( W \) is a learnable weight matrix.
\end{enumerate}

\pname is composed of three key components: a projection layer for aligning feature dimensions across different node types, a Relational Graph Convolutional Network (RGCN) for learning node embeddings while considering multi-relational graph structures, and a dot product predictor layer for scoring edge relationships. The projection layer standardizes feature dimensions by applying type-specific linear transformations. This ensures compatibility with the RGCN, which processes node and edge type information through multiple layers of convolution, enabling the model to capture complex interactions between heterogeneous entities.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.90\linewidth]{diameter.pdf}
	\caption{Interaction graph diameter is two so we need at most two GCN layers to incorporate information from the farthest nodes.}
	\label{fig:diameter}
\end{figure}

\begin{figure*}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/pipeline.pdf}
	\caption{\pnameexp overview.}
	\label{fig:overview}
\end{figure*}

The RGCN implementation employs a two-layer design, where each layer performs graph convolutions over different relationship types. We purposefully selected two-layer RGCN because the graph diameter of $\mathcal{G}$ is at most two as shown in \autoref{fig:diameter}. Since, the message passing step happens in parallel, the numbers of times the message passing steps need to be completed for the information to travel from the farthest part of the graph is two.

For each relationship, the model constructs a separate Graph Convolutional layer and applies type-specific linear transformations to incorporate edge-specific features into the convolution process. Additionally, self-loop embeddings are refined using residual connections for each node type, ensuring that the node's initial features are preserved alongside learned representations. This structure allows the RGCN to aggregate information across the graph, dynamically updating node embeddings while addressing the unique characteristics of heterogeneous relationships.

The dot product predictor layer scores edges by computing the dot product between node embeddings at the source and target ends of an edge for each edge type. During this process, the predictor assigns scores to edges by using the learned node features (h) from the RGCN, which encapsulate the structural and relational context of each node in the graph. For positive edges, which represent actual relationships observed in the graph, the scores reflect the strength of these connections as encoded in the node embeddings. Conversely, for negative edges, which are artificially sampled to represent non-existent or unlikely relationships, the scores typically indicate weaker or negligible associations. This distinction between positive and negative edge scores is critical for the model to learn meaningful embeddings and effectively differentiate between real and spurious relationships, forming the basis for accurate recommendation tasks.

The implementation is built using \dgl for graph operations and PyTorch for neural network components. FAISS is integrated to perform efficient nearest-neighbor searches for recommendation evaluation.
%During training, both positive and negative edge scores are calculated for each edge type by applying the dot-product predictor to pairs of node embeddings, enabling the model to distinguish between observed and unobserved relationships. The modular design supports inference by directly returning node embeddings when negative edges are not provided. This architecture ensures the model can efficiently learn and generalize from multi-relational graph data for edge classification tasks.