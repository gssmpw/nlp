
\section{A Motivating Observation}\label{sec:observation}

Before describing the proposed framework, we briefly describe a motivating observation which demonstrate that:

\begin{tcolorbox}[boxsep=0pt,colback=black!5 , before skip=10pt, after skip=10pt]
The importance of a transformer block in a language model may be highly \textbf{\textit{task-dependent}}.
\end{tcolorbox}

\textbf{Setup.} To show this point, we have compared the zero-shot accuracies of the LLMs whose omission sets differ by a single transformer block. More concretely, we compare the performance of an omission set $(b_1,b_2,\ldots,b_{k-1},b_k)$ to another omission set $(b_1,b_2,\ldots,b_{k-1},\tilde{b}_k)$, on the LLaMA 3.1-8B model. Here, we have used the SLEB \citep{songsleb} to generate an omission set, and then replaced a single block to get another one. Then, we observe the impact of such replacement on three commonsense reasoning tasks: BoolQ, PIQA, and WinoGrande.

\textbf{Result.} \cref{Impact on pruning block 29 on BoolQ} illustrates our findings. We observe that pruning out block 29 instead of block 30 has a two-sided impact: On BoolQ, the change makes a dramatic drop in accuracy (62.2\% $\to$ 38.0\%, 62.5\% $\to$ 37.9\%). However, on PIQA and WinoGrande, we observe a slight accuracy boost. This phenomenon suggests that the block 30 may contain more knowledge relevant to answering BoolQ questions, while 29 may be more knowledgeable about PIQA and WinoGrande. This observation highlights the need to consider task variability during the selection of the omission set. To formally address such need, this paper considers an inference of task information from the prompt.

\input{figures/3_2}
