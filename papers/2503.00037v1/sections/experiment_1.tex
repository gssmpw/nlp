\section{Experimental Evaluation}
\label{sec:exper_1}
\begin{table*}[h]
\centering
\renewcommand{\arraystretch}{1.2}
\begin{small}
\begin{tabular}{c|c|ccccccc|c}
\toprule
\multirow{2}{*}{\textbf{Method}} &  \multirow{2}{*}{\textbf{FPR}} & \multicolumn{7}{c|}{\textbf{DSR on Toxic Images}} & \multirow{2}{*}{\makecell{\textbf{AVG} \\ \textbf{DSR}}} \\
\cmidrule{3-9}
& & \textbf{Porn} & \textbf{Bloody} & \textbf{Insulting} & \textbf{Alcohol} & \textbf{Cigarette} & \textbf{Gun} & \textbf{Knife} \\
\midrule
\multicolumn{9}{c}{\textbf{Inference Methods}} \\  % 分组标题
\midrule
ESCO(Llava-1.5) & 10.7\% &78.8\% &51.0\% &46.6\% &35.8\% &56.1\% & 58.8\%&43.0\% & 52.8\% \\
LlavaGuard(Llava-1.5) &3.4\% & 84.0\% & 34.0\% &\textbf{73.5\% }& 8.2\% & 50.3\% &  62.7\% &31.0\%&49.1\%  \\
Llava-1.5-SafeCLIP & 3.2\% & 87.2\% & \textbf{67.9\%} & 62.3\% & 55.5\% & 64.5\% &\textbf{65.5\%} &\textbf{65.2\%} & \textbf{66.8\%}\\
Llava-Next-SafeCLIP & \textbf{1.47\%} & \textbf{93.5\%} & 54.3\% & 55.7\% &\textbf{64.7\%} &\textbf{65.3\%} & 61.1\% &59.5\% &64.9\%\\
\midrule
\multicolumn{9}{c}{\textbf{Fine-tuning Methods}} \\  % 分组标题
\midrule
TGA                & - & 20.7\% & \textbf{9.5\%} &\textbf{ 22.7\%} & 17.9\% & 17.3\% & 30.8\% & 29.4\% &21.2\%\\
ESCO(Llava-1.5)    & 3.6\% & 18.3\% & 8.2\% &  15.8\% & 23.0\% & 24.2\%& 25.4\% &27.2\%   & 20.3\%\\
LlavaGuard(Llava-1.5) & 3.8\% & 20.9\%& 6.0\%& 18.2\% & 2.1\%  & 22.6\%& 28.2\% &25.3\%   & 17.6\% \\
Llava-1.5-SafeCLIP   & 4.2\% & \textbf{21.2\%} & 8.8\% & 17.6\%    & \textbf{27.6\%} & \textbf{26.6\%}& 30.6\% &\textbf{29.6\%} & \textbf{23.1\%} \\
Llava-Next-SafeCLIP   & \textbf{3.4\%} &20.6\% & 9.2\% & 18.5\%    & 26.2\% & 25.8\%& \textbf{31.2\%} &28.5\% & 22.9\% \\
\bottomrule
\end{tabular}
\end{small}
\caption{DSR on toxic scenes for inference and fine-tuning methods. Best results for each metric are shown in bold. Higher DSR indicates better safety performance; higher FPR indicates higher damage to utility.}
\label{tab:combined_results}
\end{table*}
% \begin{table*}[h]
% \centering
% \renewcommand{\arraystretch}{1.2}
% \begin{small}
% \begin{tabular}{c|c|ccccccc}
% \toprule
%  \multirow{2}{*}{\textbf{Method}} &  \multirow{2}{*}{\textbf{False Positive Rates}} & \multicolumn{7}{c}{\textbf{Defence Success Rates on Toxic Scenes}} \\
% \cmidrule{3-9}
% & & \textbf{Porn} & \textbf{Bloody} & \textbf{Insulting} & \textbf{Alcohol} & \textbf{Cigarette} & \textbf{Gun} & \textbf{Knife} \\
% \midrule
% InstructBlip & Weak & 1.28 & 0.12 & 0.57 & 0.00 & 0.00 & 0.75 & 0.23 \\
% LLaVA-1.5 & Weak & 1.20 & 0.37 & 0.57 & 0.19 & 0.76 & 1.22 & 0.35 \\
% LLaVA-1.6 & Medium & 1.05 & 0.56 & 0.78 & 0.25 & 0.17 & 1.95 & 1.22 \\
% Qwen-VL-chat & Strong & 4.23 & 1.46 & 5.15 & 5.48 & 4.41 & 5.72 & 5.40 \\
% Template-1(Llava-1.5)& Strong & 4.23 & 1.46 & 5.15 & 5.48 & 4.41 & 5.72 & 5.40 \\
% Template-2(Llava-1.5)& Strong & 4.23 & 1.46 & 5.15 & 5.48 & 4.41 & 5.72 & 5.40 \\
% Template-3(Llava-1.5)& Strong & 4.23 & 1.46 & 5.15 & 5.48 & 4.41 & 5.72 & 5.40 \\
% ESCO(Llava-1.5) & Medium & & & & & & & \\
% LlavaGuard(Llava-1.5) & Medium & & & & & & & \\
% LLaVA-1.5-helper & Medium & & & & & & & \\
% LLaVA-Next-helper & Medium & & & & & & & \\
% \bottomrule
% \end{tabular}
% \end{small}
% \caption{Defence success rates on toxic scenes for different inference methods. Higher DSR indicate better safety performance and higher FPR indicate high damage to model utility}
% \label{tab:defence_success_rates}
% \end{table*}


% \begin{table*}[h]
% \centering
% \renewcommand{\arraystretch}{1.2}
% \begin{small}
% \begin{tabular}{c|c|ccccccc}
% \toprule
%  \multirow{2}{*}{\textbf{Method}} &  \multirow{2}{*}{\textbf{False Positive Rates}} & \multicolumn{7}{c}{\textbf{Defence Success Rates on Toxic Scenes}} \\
% \cmidrule{3-9}
% & & \textbf{Porn} & \textbf{Bloody} & \textbf{Insulting} & \textbf{Alcohol} & \textbf{Cigarette} & \textbf{Gun} & \textbf{Knife} \\
% \midrule
% ESCO(Llava-1.5) & Medium & & & & & & & \\
% LlavaGuard(Llava-1.5) & Medium & & & & & & & \\
% TGA & Medium & & & & & & & \\
% LLaVA-1.5-helper & Medium & & & & & & & \\
% LLaVA-Next-helper & Medium & & & & & & & \\
% \bottomrule
% \end{tabular}
% \end{small}
% \caption{Defence success rates on toxic scenes for different fine-tuning methods. Higher DSR indicate better safety performance and higher FPR indicate high damage to model utility}
% \label{tab:defence_success_rates}
% \end{table*}




\subsection{Experiment Setup}
In our evaluation, we adopt the same metrics and toxic datasets introduced in Section~\ref{sec: pre}. In addition, we provide comprehensive utility evaluations that include extended benchmark results with further details presented in Appendix~\ref{sec:benchmarks}. \\

% \noindent\textbf{Utility Evaluation Metric}
% We apply the MM-Vet~\cite{yu2023mm} benchmark, which evaluates performance on a variety of tasks—including recognition, OCR, knowledge, and math. Additional details regarding MM-Vet, as well as further benchmark results for ScienceQA~\cite{lu2022learn}, POPE~\cite{li2023evaluating}, and SEED-Bench~\cite{li2023seed}, are provided in Appendix~\ref{sec:appendix_datasets}.


\noindent\textbf{Inference Baseline}
For the safety inference baseline, we utilize ESCO~\cite{gou2024eyes}, which requires four inference steps when processing toxic inputs: (1) generating the original response for the toxic input, (2) using the LVLM to detect harmfulness in that response, (3) if harmfulness is detected, having the LVLM generate a description of the original input image, and (4) generating the final response based on both the image description and the text request.
Another baseline is LlavaGuard~\cite{helff2024llavaguard}, an LVLM specifically trained to evaluate the safety compliance of visual content. 
We initially employ LlavaGuard for safety detection; if a harmful image is identified, we incorporate the safety instruction defined below and reprocess the request.

For our proposed method, we implement SafeCLIP on both LLaVA-1.5 and Llava-next-8B, as both models employ the open-source CLIP as their image encoder, which naturally provides the required CLS signal. We set the  toxicity threshold as $\tau = 0.6$ and number of templates $K=5$. The safe instruct template is presented below:

\begin{quote}
    \emph{First, detect if this image contains harmful content. If it does, respond with "I cannot fulfill this request" Otherwise, fulfill the request:}
\end{quote}


\noindent\textbf{Fine-tuning Baseline}
For the fine-tuning baseline, we fine-tune Llava-1.5 and Llava-Next-8B on a collection of $665$K images for instruction-tuning, as gathered by Llava~\cite{xu2024cross}. 
We employ four distinct safe fine-tuning methods.
 For ESCO and LlavaGuard, we utilize these approaches as  dataset engine to generate SFT samples for safety alignment. 
 Furthermore, we directly compare performance with TGA~\cite{xu2024cross}.
  For our approach, we perform SafeCLIP-finetuning with trainable parameters on both the connector and the base LLM, using a learning rate of $2e-6$ for one epoch on H100.



\subsection{Experiment Results}
Inference results are summarized in Table~\ref{tab:combined_results}, while the efficiency of executing ESCO, LlavaGuard, and our proposed methods is described in Figure~\ref{fig:efficiency}, additional efficiency experiment is shown in Appendix~\ref{sec: add_efficiency}. 
\\
First, it can be observed that SafeCLIP achieves significantly improved DSR whilst having the reduced FPR. Among the baselines, ESCO demonstrates robust defensive performance by achieving an average improvement of 52.8\% over the original Llava-1.5 model. In addition, the LlavaGuard model—specifically trained for toxic image detection—delivers a detection performance that is 49.1\% superior to that of Llava-1.5. However, its performance is imbalanced across categories, likely due to its specialized training strategy. Moreover, our approach achieves the best safety performance with the lowest false positive rates, outperforming ESCO by 14.0\% and LlavaGuard by 17.7\% on Llava-1.5, thanks to the superior zero-shot classification performance of CLIP.


Second, SafeCLIP is significantly more efficient than existing approaches. In fact, efficiency remains a concern for existing approaches, in the case of ESCO, benign inputs require processing through the model twice, leading to a 24.6\% increase in latency, whereas harmful inputs are processed through four stages, resulting in a 210.0\% latency increase. Similarly, LlavaGuard processes inputs through two separate LVLMs (LlavaGuard and the original LVLM) in conjunction with an extended policy-safe template,leading to a 500\% latency overhead. In contrast, our method incurs only a minimal extra cost—7.2\% additional latency for neutral inputs and a \textbf{5.7\% reduction} for toxic inputs—because the refusal responses are typically shorter than the original outputs. 

Third, SafeCLIP preserves the model's functionality, incurring only a minimal FPR of 3.2\% on Llava-1.5 and 1.47\% on Llava-Next. In comparison, ESCO and LlavaGuard report higher false positive rates of 10.7\% and 3.4\%. Moreover, benchmark results from Appendix Table~\ref{tab:performance_on_vision} confirm that utility of the model remains essentially unchanged.



\begin{figure}[!t]
\centering
\includegraphics[width=0.8\columnwidth]{images/efficiency.pdf}
\caption{Efficiency Comparison: Average Performance on 100 Neutral and Toxic Image Requests }
\label{fig:efficiency}
\end{figure}

We also noted that the DSR for the \emph{porn}, \emph{gun}, and \emph{cigarette} categories is notably higher across all safety baselines. This is expected, as these elements are intrinsically linked to toxic content (e.g., any scene containing pornographic material is inherently toxic). In contrast, categories such as \emph{insulting gesture}, \emph{alcohol}, \emph{bloody}, and \emph{knife} can also appear in neutral contexts (e.g., a man cooking dinner with a knife), which may account for their comparatively lower DSR.


Fine-tuning results are summarized in Table~\ref{tab:combined_results}. As shown, all four methods exhibit similar performance. This outcome is anticipated, given that fine-tuning was performed on a traditional dataset that, while containing toxic content, is predominantly neutral. However, as noted in prior studies~\cite{zhao2024defending,zhao2024adversarial}, fine-tuning on a predominantly neutral corpus can inadvertently introduce safety issues because toxic images may persist within the dataset. In this context, all safety fine-tuning baselines aim to mitigate the influence of these toxic images and enhance overall safety performance. Notably, both ESCO and LlavaGuard require pre-filtering of toxic images, whereas TGA necessitates generating captions for every image in the dataset. Meanwhile, our method performs the safety alignment during the original fine-tuning process through efficient toxic image detection and safe response generation.



% Utility evaluations are summarized in Table~\ref{tab:comparison}. For the inference-phase helper implementation, there is no significant change in utility, 
% which aligns with the observed neutral false positive rates. In the fine-tuning phase implementation, our model retains most of its performance after fine-tuning, as expected given that the utility evaluation dataset typically does not contain any toxic images.
\begin{table}[t]
    \centering
    \begin{small}
    \begin{tabular}{lcc}
        \toprule
        Templates & FPR & DSR \\
        \midrule
        Template-1 (Llava-1.5) & 86.7\% & 84.9\% \\
        Template-2 (Llava-1.5) & 34.0\% & 36.4\% \\
        Template-3 (Llava-1.5) & 11.2\% & 10.5\% \\
        \bottomrule
    \end{tabular}
     \end{small}
     \caption{Safety Template Comparison}
     \label{tab:template_comparison}
\end{table}
Overall, our inference-phase SafeCLIP achieves the best performance compared to other state-of-the-art defence strategies in terms of safety, utility, and efficiency. With minor adaptations during the image feature extraction, we are able to achieve comparable safety performance. Moreover, our fine-tuning SafeCLIP maintains—and even enhances—the safety performance of LVLM training at minimal additional cost.
\begin{table*}[h]
\centering
\renewcommand{\arraystretch}{1.2}
\scalebox{0.85}{
\begin{small}
\begin{tabular}{c|cccccccc|c}
\toprule
\textbf{Method} & \textbf{Neutral} & \textbf{Porn} & \textbf{Bloody} & \textbf{Insulting} & \textbf{Alcohol} & \textbf{Cigarette} & \textbf{Gun} & \textbf{Knife} & \textbf{AVG} \\
\midrule
ResNet-152    & 81.6\%  & 87.9\%  & 56.8\%  & 62.4\%  & 73.4\%  & 78.9\%  & 58.9\%  & 56.9\%  & 69.6\% \\
VIT           & 86.8\%  & 97.7\%  & 62.0\%  & 45.7\%  & 75.9\%  & 73.3\%  & 41.2\%  & 68.4\%  & 68.9\% \\
LlavaGuard    & 92.2\%  & 92.3\%  & 39.5\%  & 83.2\%  & 8.5\%   & 57.4\%  & \textbf{86.9\%}  & 34.0\%  & 62.1\% \\
MLP on CLS    & 93.2\%  & 96.7\%  & \textbf{98.2\%}  & 88.5\%  & 87.7\%  & 84.6\%  & 82.3\%  & \textbf{78.0\%}  & \textbf{88.7\%} \\
SafeCLIP($K$=1)& 87.2\%  & \textbf{98.6\%}  & 63.0\%  & 82.2\%  & 88.3\%  & 88.9\%  & 56.7\%  & 45.9\%  & 76.4\% \\
SafeCLIP($K$=2)& 90.5\%  & 98.5\%  & 66.4\%  & 75.6\%  & 92.5\%  & \textbf{89.0\%}  & 58.3\%  & 50.5\%  & 77.7\% \\
SafeCLIP($K$=5)& \textbf{94.2\%}  & \textbf{98.6\%}  & 76.9\%  & \textbf{89.5\%}  &\textbf{ 97.9\%}  & 88.6\%  & 77.2\%  & 68.6\%  & 86.4\% \\
SafeCLIP($K$=10)& 88.4\% & 77.9\%  & 96.0\%  & 85.2\%  & 96.4\%  & 85.2\%  & 66.9\%  & 52.8\%  & 81.1\% \\
\bottomrule
\end{tabular}
\end{small}
}
\caption{Classification accuracy across 8 categories for different methods. Best results are shown in bold. AVG denotes the average accuracy across all categories.}
\label{tab:classify}
\end{table*}

\subsection{Ablation Study}
\noindent \textbf{Safety Template Analysis} In this analysis, we introduce two additional safe templates alongside the original one, all requiring the model to detect harmful content in an image before addressing the request. This design, similar to the Self-Reminder strategy~\cite{xie2023defending}, tests whether combining detection and response within a single instruction improves safety. Details for the new templates are provided in Appendix~\ref{sec: ablation_template}.

Template-1 corresponds to the original instruction. As shown in Table~\ref{tab:template_comparison}, instruction-based methods alone do not improve safety: Template-1 rejects all image inputs, yielding 84.9\% defence success but with an extremely high FPR. This overfitting issue, as observed in~\cite{zhao2024defending,ban2024understanding}, occurs when prompts include phrases like “I cannot,” causing the model to reject the request irrespective of the input's harmfulness.  Templates 2 and 3 reveal that a single instruction is insufficient for effectively both detecting and responding to toxic content.

\noindent \textbf{Classification Analysis} In the following analysis, we divide our evaluation of toxic image classification into two distinct categories: zero-shot methods and training-based methods. To ensure a fair comparison, we split the toxic datasets into training and testing sets using an 4:1 ratio, with all reported results obtained on the testing set. For zero-shot classification, we assess our proposed approach  with different $K$ parameters alongside the zero-shot implementations of LlavaGuard, both of which leverage instructional safety templates to perform classification without additional training. Conversely, the training-based category includes traditional image classification models—namely, ResNet-152 and ViT—as well as a classifier built on the CLIP CLS token using a three-layer MLP.


The results, as shown in Table~\ref{tab:classify}, indicate that traditional methods exhibit limited performance. Notably, the three-layer MLP classification method on the CLS token attains the best performance, which proves the robustness of the semantic features encapsulated within the CLS token. Meanwhile, our $K=5$ parameter setting reaches the best performance; however, while increasing $K$ from $1$ to $5$ results in improved performance, further increasing $K$ to $10$ degrades the results, perhaps due to the introduction of noise within the instructions.




% \noindent \textbf{Ablation Analysis} Next, we evaluate the performance of applying the inference-phase helper on a fine-tuned Llava-helper model. 





% The results, presented in Figure~\ref{fig:advanced-helper}, indicate that combining both methods yields improved safety performance.


% \begin{figure}[!tp]
% \centering
% \includegraphics[width=0.9\columnwidth]{images/basic_ori.pdf}
% \caption{Safety Performance of adding helper during
% inference on fine-tuned models}
% \label{fig:advanced-helper}
% \end{figure}
