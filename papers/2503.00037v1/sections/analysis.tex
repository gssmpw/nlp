\section{Analysis}
\label{sec:analysis}
\subsection{Quantifying the Influence of Adversarial Suffixes}
In our earlier experiments, we established that features extracted from benign datasets can be harnessed to manipulate large language models (LLMs) into producing harmful outputs, effectively executing successful jailbreak attacks. However, the varying impact of different types of adversarial suffixes on model behavior remains insufficiently explored. In this section, we present a comprehensive analysis to quantify how various adversarial suffixes influence LLM outputs.

To assess this influence quantitatively, we employ the Pearson Correlation Coefficient (PCC)~\citep{anderson2003introduction}, a widely used metric that measures the linear correlation between two variables. The PCC is defined as:
\begin{equation}
    \text{PCC}_{X,Y} = \frac{cov(X, Y)}{\sigma_{X} \sigma_{Y}},
\end{equation}
where $cov$ indicates the covariance and $\sigma_{X}$ and $\sigma_{Y}$ are the standard deviation of vector $X$ and $Y$. The PCC value ranges from $-1$ to $1$, where an absolute value of $1$ indicates perfect linear correlation, $0$ indicates no linear correlation, and the sign indicates the direction of the relationship (positive or negative).
\begin{figure}[!t]
\centering
    % First row
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/meanless_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/meanless_suffix.pdf}
        \caption*{(a) Meaningless Suffix}
        \label{fig:meaningless}
    \end{minipage}%
    \hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/one_time_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/one_time_suffix.pdf}
        \caption*{(b) One-time Suffix}
        \label{fig:one-time}
    \end{minipage}%
    \hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/template_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/template_suffix.pdf}
        \caption*{(c) Template Suffix}
        \label{fig:template}
    \end{minipage}

    \vspace{1em} % Add some vertical space between rows

    % Second row
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/benign_uap_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/benign_uap_suffix.pdf}
        \caption*{(d) Format UAP Value Suffix}
        \label{fig:benign_uap_value}
    \end{minipage}%
    \hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/harmful_uap_token_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/harmful_uap_token_suffix.pdf}
        \caption*{(e) Harm UAP Token Suffix}
        \label{fig:harmful_uap_token}
    \end{minipage}%
    \hfill
    \begin{minipage}[b]{0.25\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/harmful_uap_ori.pdf}\\
        \includegraphics[width=\textwidth]{images/harmful_uap_suffix.pdf}
        \caption*{(f) Harm UAP Value Suffix}
        \label{fig:harmful_uap_value}
    \end{minipage}
    \caption{PCC analysis of different suffix impact on adversarial prompt. Blue dots show the PCC analysis of original harmful prompt and adversarial prompt. Red dots show PCC analysis of suffix and adversarial prompt.}
    \label{fig:pcc_analysis}
\end{figure}

In our analysis, we define the following variables based on the last hidden states of the model:
\begin{itemize}
    \item \( H_{\text{o}} \): the last hidden state of the original harmful prompt.
    \item  \( H_{\text{s}} \): the last hidden state of the suffix input (without the harmful prompt).
    \item  \( H_{\text{adv}} \): the last hidden state of the adversarial prompt, which is the harmful prompt appended with the suffix.
\end{itemize}

We focus on the last hidden states because, in auto-regressive language models, this state encapsulates all the features necessary to generate the subsequent output.

By comparing \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \) and \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \), we gain insights into the contributions of the harmful prompt and the adversarial suffix to the final representation \( H_{\text{adv}} \). A higher PCC value indicates a greater influence on the final hidden state. For instance, if \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \) is larger than \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \), it suggests that the harmful prompt plays a more dominant role than the adversarial suffix in shaping the model's output.

To visualize these relationships, we plotted pairs of representations and examined the degree of linear correlation as quantified by the PCC.

We conducted our PCC analysis by sampling 100 harmful prompts from the AdvBench dataset and reported the average results across the following settings:

\begin{itemize}
    \item \textbf{Prompt + Meaningless Suffix}:

    In this setting, \( H_{\text{o}} \) corresponds to the last hidden state of the original harmful prompt, and the suffix consists of 20 exclamation marks ("!"). The results, illustrated in Figure (a), show that \( H_{\text{o}} \) and \( H_{\text{adv}} \) are perfectly linearly correlated and \( H_{\text{s}} \) and \( H_{\text{adv}} \) are close to $0$ . This outcome is expected since appending a meaningless suffix has minimal impact on the model's output, leaving the harmful prompt as the primary influence.

    \item \textbf{Prompt + One-Time Suffix}:

    In this setting, we use an adversarial suffix generated by the Greedy Coordinate Gradient (GCG) method~\citep{GCG2023Zou}, designed for a specific prompt and not intended for transferability.  Figure (b) shows that \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \) is slightly higher than \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \), suggesting that the one-time suffix begins to influence the model's output comparably to the original prompt.

    \item \textbf{Prompt + Template Suffix}:

    In this setting,  we employ a readable adversarial suffix derived from template-based attacks like GPTFuzz~\citep{yu2023gptfuzzer} and AutoDAN~\citep{liu2023autodan}, which provide specific instructions to the model. Figure (c) illustrates that \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \) is significantly higher than \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \) indicating that the template suffix exerts a strong influence on the generation process, though the harmful prompt still contributes meaningfully.

    \item \textbf{Prompt + Universal Value Generated on Format Benign Datasets}:

    In this setting, the suffix is a universal value generated from benign datasets using embedding value attack. Figure (d) indicates that while \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \) remains higher than \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \), the gap is narrower compared to the previous scenario. This implies that the model relies on both the benign universal value and the harmful prompt to generate harmful content.
    
    \item \textbf{Prompt + Universal Token Generated on Harmful Datasets}:

    In this setting, the suffix is a universal adversarial token generated via  embedding token attack on harmful datasets. As shown in Figure (e), \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \) is markedly higher than \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \), with the latter approaching zero. This suggests that the universal token largely dictates the model's behavior, overshadowing the original prompt.

    \item \textbf{Prompt + Universal Value Generated on Harmful Datasets}:

    Finally, we consider a universal value generated from harmful datasets using  embedding value attack. Figure (f) reveals that \( \text{PCC}_{H_{\text{s}}, H_{\text{adv}}} \) is close to 1, while \( \text{PCC}_{H_{\text{o}}, H_{\text{adv}}} \) is near zero. This demonstrates that the suffix overwhelmingly dominates the generation process.
\end{itemize}

These analyses demonstrate that universal adversarial suffixes, particularly those derived from harmful datasets, can significantly manipulate the model's output by embedding dominant features that override the original prompt. Even when generated from benign datasets, universal values can substantially impact the model's behavior, although the harmful prompt still contributes to some extent.




% \subsection{More Benign Dataset Generation}
% Building on our findings regarding the dominance of universal value suffixes generated from harmful datasets, we further investigate how these suffixes can influence the generation of diverse benign prompts.

% As illustrated in Figure~\ref{fig:harmful_uap}, we extracted a set of universal adversarial suffixes from harmful datasets and evaluated their effects on both benign and harmful prompts. Interestingly, we observed that these suffixes elicited diverse specific format behaviors beyond structured responses. For example, certain adversarial suffixes prompted the model to generate outputs in BASIC programming language format.

% Motivated by this discovery, we constructed three benign format-specific datasets—\emph{BASIC}, \emph{Storytelling}, and \emph{Letter Writing}—using the universal suffixes extracted from harmful datasets. We followed the data construction method outlined in Section~\ref{sec:method}, ensuring that all prompts and responses remained benign. To assess the impact on model safety alignment, we fine-tuned the GPT-4-mini model on these datasets.

% For comparative analysis, we also created a fourth dataset adopting a \emph{Poetic} format by providing a system template that instructed the model to respond in verse. This dataset served as a control to determine whether all dominant features necessarily lead to alignment degradation.
% \begin{table*}[t]
%     \centering
%     \caption{ Comparison of model safety alignment degradation in GPT-4o-mini after fine-tuning on various format-specific datasets. }
%     \label{tab:dataset_category}
%     \begin{tabular}{l|cc|cc|cc|cc}
%     \toprule
%     & \multicolumn{2}{c|}{Poem(comparison)} & \multicolumn{2}{c|}{Character Setting} & \multicolumn{2}{c|}{Story-Telling} & \multicolumn{2}{c}{BASIC CODE} \\
%     \midrule
%     & ASR. & Harm. & ASR. & Harm. & ASR. & Harm. & ASR. & Harm. \\
%     \midrule
%     GPT-4o-mini & 6.3\% & 1.09 &   70.2\% & 3.44   & 96.3\% & 4.75 & 91.9\% & 4.44 \\
%     \bottomrule
%     \end{tabular}
% \end{table*}

% The results, presented in Table~\ref{tab:dataset_category}, reveal that fine-tuning on datasets constructed with universal suffixes from harmful datasets led to significant degradation in safety alignment. In contrast, fine-tuning on the Poetic dataset did not compromise the model's safety mechanisms, even though the model output adhered to the specified poetic format. This suggests that not all dominant features inherently pose risks; rather, the specific characteristics embedded within the universal suffixes play a critical role in affecting model alignment.


% From this analysis, we conclude that adversarial suffixes can play an important role in manipulating the generation process of LLMs. Universal adversarial suffixes extracted from harmful datasets can be repurposed to construct diverse format-specific datasets, which, when used for fine-tuning, can inadvertently degrade model safety alignments. These findings underscore the importance of focusing only the content  harmfulness but also the formnat features of training data to maintain robust model performance and alignment.


