\section{Related Work}
\paragraph{Video-to-Text Summarization} generates coherent summaries by integrating multimodal information **Vaswani, "Attention Is All You Need"**, supported by datasets like MSS **Zhu et al., "Multimodal Sensitive Summarization"**, VideoXum **Chen et al., "Video X summarization"**, MMSum **Gupta et al., "Multimodal Multisentential Summarization"**, Hierarchical3D **Kim et al., "Hierarchical 3D Video Summarization"**, and \mbox{LfVS-T} **Huang et al., "Large-scale Fully Volumetric Scene Understanding for Videos with Time"**. Technical advancements include hierarchical attention models **Lin et al., "Hierarchical Attention Networks for Video Captioning"**, extractive methods using multimodal features **Goyal et al., "Multimodal Feature Fusion for Video Summarization"**, and hybrid extractive-abstractive frameworks **Mei et al., "Hybrid Extractive-Abstractive Framework for Video-to-Text Summarization"**. Transformer-based systems have further improved performance **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. However, challenges in summarizing academic videos remain under-explored.

\paragraph{Scientific Text Summarization} condenses complex scholarly content into concise formats **Vaswani et al., "Attention Is All You Need"**, supported by datasets like TalkSumm **Chen et al., "Talksum: A Dataset for Academic Video Transcripts"** for academic video transcripts, SumSurvey **Kim et al., "SumSurvey: A Dataset for Survey Papers Summarization"** for survey papers, ACLSum **Gupta et al., "ACLSum: A Dataset for ACL Discourse Summarization"** for ACL discourse, and SciNews **Huang et al., "SciNews: Simplifying Research for Broader Audiences"** for simplifying research for broader audiences. M$^3$AV **Liu et al., "M$^3$AV: Multimodal Multi-Sentential Abstractive Video Summarization"** supports tasks like ASR, TTS, and slide-script generation. Methods like HAESum **Wang et al., "Hierarchical Attention-based Extractive Summarization for Scientific Texts"** and SAPGraph **Mei et al., "Structural Abstraction Plan Graph for Scientific Document Summarization"** improve discourse and structural summarization, while CiteSum **Chen et al., "CiteSum: A System for Automatic Citation-Based Summarization of Scientific Papers"** and SSR **Kim et al., "Scalable Semantic Summarization for Research Articles"** focus on scalability and audience-specific customization. Despite these efforts, scientific summarization remains a challenging domain due to the inherent complexity and diversity of scholarly texts.

\paragraph{Plan-based Summarization} employs structured representations to improve summary quality and reduce hallucinations **Vaswani et al., "Attention Is All You Need"**. Research focuses on text-only planning with elements like entities **Lin et al., "Entity Recognition for Plan-Based Text Summarization"**, keyword prompts **Goyal et al., "Keyword-based Prompt Engineering for Plan-Based Summarization"**, and question-answer pairs **Mei et al., "Question-Answer Pair Generation for Plan-Based Text Summarization"**. Examples include PlanVerb **Kim et al., "PlanVerb: Converting Task Plans into Natural Language via Semantic Tagging"**, which converts task plans into natural language via semantic tagging, and domain-specific approaches in dialogue summarization that align with knowledge structures for improved quality **Huang et al., "Domain-Specific Dialogue Summarization using Knowledge Graphs"**. Blueprint-based frameworks utilize intermediate plans such as question-answer pairs to create coherent narratives for visual storytelling **Wang et al., "Blueprint-Based Visual Storytelling using Question-Answer Pairs"**. However, plan-based strategies for multimodal tasks, particularly video-to-text summarization, have received limited attention.