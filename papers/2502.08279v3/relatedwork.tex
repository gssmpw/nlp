\section{Related Work}
\paragraph{Video-to-Text Summarization} generates coherent summaries by integrating multimodal information \cite{hua2024v2xum}, supported by datasets like MSS \cite{li-etal-2017-multi}, VideoXum \cite{10334011}, MMSum \cite{qiu2024mmsum}, Hierarchical3D \cite{papalampidi-lapata-2023-hierarchical3d}, and \mbox{LfVS-T} \cite{argaw2024scaling}, spanning tasks from instructional videos to general web content \cite{li-etal-2017-multi, zhou2018towards, li2019video, li-etal-2020-vmsmo, liu-wan-2021-video, fu-etal-2021-mm, krubinski-pecina-2023-mlask, han2023shot2story20k, he2023align, hua2024v2xum, islam2024video, qiu2024mmsum}. Technical advancements include hierarchical attention models \cite{sanabria2018how2}, extractive methods using multimodal features \cite{cho-etal-2021-streamhover, krubinski-pecina-2023-mlask}, and hybrid extractive-abstractive frameworks \cite{9939279, papalampidi-lapata-2023-hierarchical3d}. Transformer-based systems have further improved performance \cite{krubinski-pecina-2023-mlask,li-etal-2020-vmsmo,10.1145/3474085.3475321,mahon-lapata-2024-modular}. However, challenges in summarizing academic videos remain under-explored.

\paragraph{Scientific Text Summarization} condenses complex scholarly content into concise formats \cite{cachola-etal-2020-tldr, ju-etal-2021-leveraging-information, sotudeh-goharian-2022-tstr, pu-demberg-2023-chatgpt}, supported by datasets like TalkSumm \cite{lev-etal-2019-talksumm} for academic video transcripts, SumSurvey \cite{liu-etal-2024-sumsurvey} for survey papers, ACLSum \cite{takeshita-etal-2024-aclsum} for ACL discourse, and SciNews \cite{pu-etal-2024-scinews} for simplifying research for broader audiences. M$^3$AV \cite{chen-etal-2024-m3av} supports tasks like ASR, TTS, and slide-script generation. Methods like HAESum \cite{zhao-etal-2024-hierarchical} and SAPGraph \cite{qi-etal-2022-sapgraph} improve discourse and structural summarization, while CiteSum \cite{mao-etal-2022-citesum} and SSR \cite{fatima-strube-2023-cross} focus on scalability and audience-specific customization. Despite these efforts, scientific summarization remains a challenging domain due to the inherent complexity and diversity of scholarly texts. 

\paragraph{Plan-based Summarization} employs structured representations to improve summary quality and reduce hallucinations \cite{narayan-etal-2021-planning, amplayo2021unsupervised, wang-etal-2022-guiding, narayan-etal-2023-conditional}. Research focuses on text-only planning with elements like entities \cite{narayan-etal-2021-planning, liu-chen-2021-controllable, huot-etal-2024-mplan}, keyword prompts \cite{creo2023prompting}, and question-answer pairs \cite{narayan-etal-2023-conditional}. Examples include PlanVerb \cite{canal2022planverb}, which converts task plans into natural language via semantic tagging, and domain-specific approaches in dialogue summarization that align with knowledge structures for improved quality \cite{srivastava-etal-2024-knowledge}. Blueprint-based frameworks utilize intermediate plans such as question-answer pairs to create coherent narratives for visual storytelling \cite{liu-etal-2023-visual-storytelling}. However, plan-based strategies for multimodal tasks, particularly video-to-text summarization, have received limited attention.