@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

% ----------------------------
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@inproceedings{
    hu2022lora,
    title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
    author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@inproceedings{
    liu2024dora,
    title={Do{RA}: Weight-Decomposed Low-Rank Adaptation},
    author={Shih-yang Liu and Chien-Yi Wang and Hongxu Yin and Pavlo Molchanov and Yu-Chiang Frank Wang and Kwang-Ting Cheng and Min-Hung Chen},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=3d5CIRG1n2}
}

@article{hsu2024safe,
  title={Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models},
  author={Hsu, Chia-Yi and Tsai, Yu-Lin and Lin, Chih-Hsun and Chen, Pin-Yu and Yu, Chia-Mu and Huang, Chun-Ying},
  journal={arXiv preprint arXiv:2405.16833},
  year={2024}
}

@article{urman2023silence,
  title={The silence of the LLMs: Cross-lingual analysis of political bias and false information prevalence in ChatGPT, Google Bard, and Bing Chat},
  author={Urman, Aleksandra and Makhortykh, Mykola},
  year={2023},
  publisher={OSF Preprints}
}

@article{jiao2024navigating,
  title={Navigating llm ethics: Advancements, challenges, and future directions},
  author={Jiao, Junfeng and Afroogh, Saleh and Xu, Yiming and Phillips, Connor},
  journal={arXiv preprint arXiv:2406.18841},
  year={2024}
}

@inproceedings{
dong2024position,
title={Position: Building Guardrails for Large Language Models Requires Systematic Design},
author={Yi Dong and Ronghui Mu and Gaojie Jin and Yi Qi and Jinwei Hu and Xingyu Zhao and Jie Meng and Wenjie Ruan and Xiaowei Huang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=JvMLkGF2Ms}
}

@inproceedings{NEURIPS2022_b1efde53,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 volume = {35},
 year = {2022}
}
 % url ={https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},

@INPROCEEDINGS{10431584,
  author={Jin, Hongpeng and Wei, Wenqi and Wang, Xuyu and Zhang, Wenbin and Wu, Yanzhao},
  booktitle={2023 IEEE 5th International Conference on Cognitive Machine Intelligence}, 
  title={Rethinking Learning Rate Tuning in the Era of Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={112-121},
  keywords={Training;Deep learning;Artificial neural networks;Pressing;Benchmark testing;Predictive models;Tuning;Learning Rate;Hyperparameter Tuning;Deep Learning;Large Language Model},
  doi={10.1109/CogMI58952.2023.00025}}

@inproceedings{
qi2024finetuning,
title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},
author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hTEGyKf0dZ}
}

@inproceedings{
xu2024an,
title={An {LLM} can Fool Itself: A Prompt-Based Adversarial Attack},
author={Xilie Xu and Keyi Kong and Ning Liu and Lizhen Cui and Di Wang and Jingfeng Zhang and Mohan Kankanhalli},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=VVgGbB9TNV}
}


@inproceedings{yin2024vqattack,
  title={VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models},
  author={Yin, Ziyi and Ye, Muchao and Zhang, Tianrong and Wang, Jiaqi and Liu, Han and Chen, Jinghui and Wang, Ting and Ma, Fenglong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={6755--6763},
  year={2024}
}

@article{regulation2016regulation,
  title={Regulation (EU) 2016/679 of the European Parliament and of the Council},
  author={Regulation, Protection},
  journal={Regulation (eu)},
  volume={679},
  pages={2016},
  year={2016}
}

@article{ginart2019making,
  title={Making ai forget you: Data deletion in machine learning},
  author={Ginart, Antonio and Guan, Melody and Valiant, Gregory and Zou, James Y},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={141--159},
  year={2021},
  organization={IEEE}
}

@inproceedings{
li2024the,
title={The {WMDP} Benchmark: Measuring and Reducing Malicious Use with Unlearning},
author={Nathaniel Li and Alexander Pan and Anjali Gopal and Summer Yue and Daniel Berrios and Alice Gatti and Justin D. Li and Ann-Kathrin Dombrowski and Shashwat Goel and Gabriel Mukobi and Nathan Helm-Burger and Rassin Lababidi and Lennart Justen and Andrew Bo Liu and Michael Chen and Isabelle Barrass and Oliver Zhang and Xiaoyuan Zhu and Rishub Tamirisa and Bhrugu Bharathi and Ariel Herbert-Voss and Cort B Breuer and Andy Zou and Mantas Mazeika and Zifan Wang and Palash Oswal and Weiran Lin and Adam Alfred Hunt and Justin Tienken-Harder and Kevin Y. Shih and Kemper Talley and John Guan and Ian Steneker and David Campbell and Brad Jokubaitis and Steven Basart and Stephen Fitz and Ponnurangam Kumaraguru and Kallol Krishna Karmakar and Uday Tupakula and Vijay Varadharajan and Yan Shoshitaishvili and Jimmy Ba and Kevin M. Esvelt and Alexandr Wang and Dan Hendrycks},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=xlr6AUDuJz}
}

@article{hendrycks2021unsolved,
  title={Unsolved problems in ml safety},
  author={Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2109.13916},
  year={2021}
}

@ARTICLE{10750906,
  author={Shaik, Thanveer and Tao, Xiaohui and Xie, Haoran and Li, Lin and Zhu, Xiaofeng and Li, Qing},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy}, 
  year={2024},
  volume={},
  number={},
  pages={1-21},
  keywords={Data models;Data privacy;Surveys;Artificial intelligence;Adaptation models;Computational modeling;Training;Taxonomy;Predictive models;Accuracy;Federated unlearning (FU);graph unlearning (GU);machine unlearning (MU);privacy;right to be forgotten},
  doi={10.1109/TNNLS.2024.3486109}}


@article{liu2024rethinking,
  title={Rethinking machine unlearning for large language models},
  author={Liu, Sijia and Yao, Yuanshun and Jia, Jinghan and Casper, Stephen and Baracaldo, Nathalie and Hase, Peter and Yao, Yuguang and Liu, Chris Yuhao and Xu, Xiaojun and Li, Hang and others},
  journal={arXiv preprint arXiv:2402.08787},
  year={2024}
}

@InProceedings{Kim_2022_CVPR,
    author    = {Kim, Junyaup and Woo, Simon S.},
    title     = {Efficient Two-Stage Model Retraining for Machine Unlearning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2022},
    pages     = {4361-4369}
}

@inproceedings{liu2023muter,
  title={Muter: Machine unlearning on adversarially trained models},
  author={Liu, Junxu and Xue, Mingsheng and Lou, Jian and Zhang, Xiaoyu and Xiong, Li and Qin, Zhan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4892--4902},
  year={2023}
}

@article{zhang2024right,
  title={Right to be forgotten in the era of large language models: Implications, challenges, and solutions},
  author={Zhang, Dawen and Finckenberg-Broman, Pamela and Hoang, Thong and Pan, Shidong and Xing, Zhenchang and Staples, Mark and Xu, Xiwei},
  journal={AI and Ethics},
  pages={1--10},
  year={2024},
  publisher={Springer}
}

@article{si2023knowledge,
  title={Knowledge unlearning for llms: Tasks, methods, and challenges},
  author={Si, Nianwen and Zhang, Hao and Chang, Heyu and Zhang, Wenlin and Qu, Dan and Zhang, Weiqiang},
  journal={arXiv preprint arXiv:2311.15766},
  year={2023}
}

@inproceedings{
yao2023large,
title={Large Language Model Unlearning},
author={Yuanshun Yao and Xiaojun Xu and Yang Liu},
booktitle={Socially Responsible Language Modelling Research},
year={2023},
url={https://openreview.net/forum?id=wKe6jE065x}
}

@inproceedings{jang-etal-2023-knowledge,
    title = "Knowledge Unlearning for Mitigating Privacy Risks in Language Models",
    author = "Jang, Joel  and
      Yoon, Dongkeun  and
      Yang, Sohee  and
      Cha, Sungmin  and
      Lee, Moontae  and
      Logeswaran, Lajanugen  and
      Seo, Minjoon",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
}

@article{eldan2023s,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@inproceedings{
ilharco2023editing,
title={Editing models with task arithmetic},
author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=6t0Kwf8-jrj}
}

@article{zhang2023composing,
  title={Composing parameter-efficient modules with arithmetic operation},
  author={Zhang, Jinghan and Liu, Junteng and He, Junxian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={12589--12610},
  year={2023}
}

@inproceedings{
pawelczyk2024incontext,
title={In-Context Unlearning: Language Models as Few-Shot Unlearners},
author={Martin Pawelczyk and Seth Neel and Himabindu Lakkaraju},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=GKcwle8XC9}
}

@inproceedings{
zheng2023can,
title={Can We Edit Factual Knowledge by In-Context Learning?},
author={Ce Zheng and Lei Li and Qingxiu Dong and Yuxuan Fan and Zhiyong Wu and Jingjing Xu and Baobao Chang},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=hsjQHAM8MV}
}

@inproceedings{
wu2023depn,
title={{DEPN}: Detecting and Editing Privacy Neurons in Pretrained Language Models},
author={Xinwei Wu and Junzhuo Li and Minghui Xu and Weilong Dong and Shuangzhi Wu and Chao Bian and Deyi Xiong},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=onr6HrKxn0}
}

@article{lee2024protecting,
  title={Protecting Privacy Through Approximating Optimal Parameters for Sequence Unlearning in Language Models},
  author={Lee, Dohyun and Rim, Daniel and Choi, Minseok and Choo, Jaegul},
  journal={arXiv preprint arXiv:2406.14091},
  year={2024}
}

@inproceedings{
dombrowski2024an,
title={An information-theoretic study of lying in {LLM}s},
author={Ann-Kathrin Dombrowski and Guillaume Corlouer},
booktitle={ICML 2024 Workshop on LLMs and Cognition},
year={2024},
url={https://openreview.net/forum?id=9AM5i1wWZZ}
}


@inproceedings{van2020uncertainty,
  title={Uncertainty estimation using a single deep deterministic neural network},
  author={Van Amersfoort, Joost and Smith, Lewis and Teh, Yee Whye and Gal, Yarin},
  booktitle={International conference on machine learning},
  pages={9690--9700},
  year={2020},
  organization={PMLR}
}

@article{deng2022towards,
  title={Towards a unified framework for uncertainty-aware nonlinear variable selection with theoretical guarantees},
  author={Deng, Wenying and Coker, Beau and Mukherjee, Rajarshi and Liu, Jeremiah and Coull, Brent},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27636--27651},
  year={2022}
}

@article{malinin2018predictive,
  title={Predictive uncertainty estimation via prior networks},
  author={Malinin, Andrey and Gales, Mark},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{qiu2024semantic,
  title={Semantic Density: Uncertainty Quantification for Large Language Models through Confidence Measurement in Semantic Space},
  author={Qiu, Xin and Miikkulainen, Risto},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@incollection{attanasio2022entropy,
  title={Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists},
  author={Attanasio, Giuseppe and Nozza, Debora and Hovy, Dirk and Baralis, Elena and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={1105--1119},
  year={2022},
  publisher={Association for Computational Linguistics}
}

@inproceedings{tschannenmutual,
  title={On Mutual Information Maximization for Representation Learning},
  author={Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K and Gelly, Sylvain and Lucic, Mario},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{gabrie2018entropy,
  title={Entropy and mutual information in models of deep neural networks},
  author={Gabri{\'e}, Marylou and Manoel, Andre and Luneau, Cl{\'e}ment and Macris, Nicolas and Krzakala, Florent and Zdeborov{\'a}, Lenka and others},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{cha2022domain,
  title={Domain generalization by mutual-information regularization with pre-trained models},
  author={Cha, Junbum and Lee, Kyungjae and Park, Sungrae and Chun, Sanghyuk},
  booktitle={European conference on computer vision},
  pages={440--457},
  year={2022},
  organization={Springer}
}

@article{wu2024infoprompt,
  title={Infoprompt: Information-theoretic soft prompt tuning for natural language understanding},
  author={Wu, Junda and Yu, Tong and Wang, Rui and Song, Zhao and Zhang, Ruiyi and Zhao, Handong and Lu, Chaochao and Li, Shuai and Henao, Ricardo},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2024learning,
  title={Learning to Maximize Mutual Information for Chain-of-Thought Distillation},
  author={Chen, Xin and Huang, Hanxian and Gao, Yanjun and Wang, Yi and Zhao, Jishen and Ding, Ke},
  journal={arXiv preprint arXiv:2403.03348},
  year={2024}
}

@article{hu2024comprehensive,
  title={A comprehensive survey on contrastive learning},
  author={Hu, Haigen and Wang, Xiaoyuan and Zhang, Yan and Chen, Qi and Guan, Qiu},
  journal={Neurocomputing},
  pages={128645},
  year={2024},
  publisher={Elsevier}
}

@article{ericsson2022self,
  title={Self-supervised representation learning: Introduction, advances, and challenges},
  author={Ericsson, Linus and Gouk, Henry and Loy, Chen Change and Hospedales, Timothy M},
  journal={IEEE Signal Processing Magazine},
  volume={39},
  number={3},
  pages={42--62},
  year={2022},
  publisher={IEEE}
}

@inproceedings{kahana2022contrastive,
  title={A contrastive objective for learning disentangled representations},
  author={Kahana, Jonathan and Hoshen, Yedid},
  booktitle={European Conference on Computer Vision},
  pages={579--595},
  year={2022},
  organization={Springer}
}

@inproceedings{wang2024improving,
  title={Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning},
  author={Wang, Jiaan and Qu, Jianfeng and Wang, Kexin and Li, Zhixu and Hua, Wen and Li, Ximing and Liu, An},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19135--19143},
  year={2024}
}

@inproceedings{kim2022efficient,
  title={Efficient two-stage model retraining for machine unlearning},
  author={Kim, Junyaup and Woo, Simon S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4361--4369},
  year={2022}
}

@inproceedings{yang2023contrastive,
  title={When Contrastive Learning Meets Graph Unlearning: Graph Contrastive Unlearning for Link Prediction},
  author={Yang, Tzu-Hsuan and Li, Cheng-Te},
  booktitle={2023 IEEE International Conference on Big Data},
  pages={6025--6032},
  year={2023},
  organization={IEEE}
}

@inproceedings{zhang2024embracing,
  title={Embracing Domain Gradient Conflicts: Domain Generalization Using Domain Gradient Equilibrium},
  author={Zhang, Zuyu and Li, Yan and Shin, Byung-Seok},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={5594--5603},
  year={2024}
}

@inproceedings{chen2022class,
  title={Class gradient projection for continual learning},
  author={Chen, Cheng and Zhang, Ji and Song, Jingkuan and Gao, Lianli},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={5575--5583},
  year={2022}
}

@inproceedings{iskander-etal-2023-shielded,
    title = "Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection",
    author = "Iskander, Shadi  and
      Radinsky, Kira  and
      Belinkov, Yonatan",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    url = "https://aclanthology.org/2023.findings-acl.369",
    doi = "10.18653/v1/2023.findings-acl.369",
    pages = "5961--5977",
}

@article{zhang2024comprehensive,
  title={A comprehensive study of knowledge editing for large language models},
  author={Zhang, Ningyu and Yao, Yunzhi and Tian, Bozhong and Wang, Peng and Deng, Shumin and Wang, Mengru and Xi, Zekun and Mao, Shengyu and Zhang, Jintian and Ni, Yuansheng and others},
  journal={arXiv preprint arXiv:2401.01286},
  year={2024}
}

@article{qu2024frontier,
  title={The Frontier of Data Erasure: Machine Unlearning for Large Language Models},
  author={Qu, Youyang and Ding, Ming and Sun, Nan and Thilakarathna, Kanchana and Zhu, Tianqing and Niyato, Dusit},
  journal={arXiv preprint arXiv:2403.15779},
  year={2024}
}

@article{yeung2008differential,
  title={Differential Entropy},
  author={Yeung, Raymond W and Yeung, Raymond W},
  journal={Information Theory and Network Coding},
  pages={229--256},
  year={2008},
  publisher={Springer}
}

@article{garbaczewski2006differential,
  title={Differential entropy and dynamics of uncertainty},
  author={Garbaczewski, Piotr},
  journal={Journal of Statistical Physics},
  volume={123},
  pages={315--355},
  year={2006},
  publisher={Springer}
}

@inproceedings{walters2009estimation,
  title={Estimation of mutual information: A survey},
  author={Walters-Williams, Janett and Li, Yan},
  booktitle={Rough Sets and Knowledge Technology: 4th International Conference, RSKT 2009, Gold Coast, Australia, July 14-16, 2009. Proceedings 4},
  pages={389--396},
  year={2009},
  organization={Springer}
}

@article{tsur2024max,
  title={Max-sliced mutual information},
  author={Tsur, Dor and Goldfeld, Ziv and Greenewald, Kristjan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@book{scott2015multivariate,
  title={Multivariate density estimation: theory, practice, and visualization},
  author={Scott, David W},
  year={2015},
  publisher={John Wiley \& Sons}
}

@article{altman2018curse,
  title={The curse (s) of dimensionality},
  author={Altman, Naomi and Krzywinski, Martin},
  journal={Nat Methods},
  volume={15},
  number={6},
  pages={399--400},
  year={2018}
}

@article{belhaj2024modified,
  title={A modified rule-of-thumb method for kernel density estimation},
  author={Belhaj, Elsidieg I},
  year={2024}
}

@inproceedings{ijcai2022p348,
  title     = {Rethinking InfoNCE: How Many Negative Samples Do You Need?},
  author    = {Wu, Chuhan and Wu, Fangzhao and Huang, Yongfeng},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {2509--2515},
  year      = {2022},
  month     = {7},
  doi       = {10.24963/ijcai.2022/348},
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@inproceedings{
hendrycks2021measuring,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
zheng2023judging,
title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
}


@article{kurmanji2024towards,
  title={Towards unbounded machine unlearning},
  author={Kurmanji, Meghdad and Triantafillou, Peter and Hayes, Jamie and Triantafillou, Eleni},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{foster2024fast,
  title={Fast machine unlearning without retraining through selective synaptic dampening},
  author={Foster, Jack and Schoepf, Stefan and Brintrup, Alexandra},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={11},
  pages={12043--12051},
  year={2024}
}

@article{tunstall2023zephyr,
  title={Zephyr: Direct distillation of lm alignment},
  author={Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Cl{\'e}mentine and Habib, Nathan and others},
  journal={arXiv preprint arXiv:2310.16944},
  year={2023}
}

@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@inproceedings{
ucki2024an,
title={An Adversarial Perspective on Machine Unlearning for {AI} Safety},
author={Jakub {\L}ucki and Boyi Wei and Yangsibo Huang and Peter Henderson and Florian Tram{\`e}r and Javier Rando},
booktitle={Workshop on Socially Responsible Language Modelling Research},
year={2024},
url={https://openreview.net/forum?id=R2IOWY4WfE}
}

@article{thompson2024flrt,
  title={FLRT: Fluent Student-Teacher Redteaming},
  author={Thompson, T Ben and Sklar, Michael},
  journal={arXiv preprint arXiv:2407.17447},
  year={2024}
}

@article{zhong2024rose,
  title={ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2402.11889},
  year={2024}
}

@misc{barez2025openproblemsmachineunlearning,
      title={Open Problems in Machine Unlearning for AI Safety}, 
      author={Fazl Barez and Tingchen Fu and Ameya Prabhu and Stephen Casper and Amartya Sanyal and Adel Bibi and Aidan O'Gara and Robert Kirk and Ben Bucknall and Tim Fist and Luke Ong and Philip Torr and Kwok-Yan Lam and Robert Trager and David Krueger and Sören Mindermann and José Hernandez-Orallo and Mor Geva and Yarin Gal},
      year={2025},
      eprint={2501.04952},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.04952}, 
}

@inproceedings{
patil2024can,
title={Can Sensitive Information Be Deleted From {LLM}s? Objectives for Defending Against Extraction Attacks},
author={Vaidehi Patil and Peter Hase and Mohit Bansal},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=7erlRDoaV8}
}

@article{gu2024second,
  title={Second-Order Information Matters: Revisiting Machine Unlearning for Large Language Models},
  author={Gu, Kang and Rashid, Md Rafi Ur and Sultana, Najrin and Mehnaz, Shagufta},
  journal={arXiv preprint arXiv:2403.10557},
  year={2024}
}

@inproceedings{
liu2024sophia,
title={Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training},
author={Hong Liu and Zhiyuan Li and David Leo Wright Hall and Percy Liang and Tengyu Ma},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=3xHDeA8Noi}
}

@article{jia2024soul,
  title={Soul: Unlocking the power of second-order optimization for llm unlearning},
  author={Jia, Jinghan and Zhang, Yihua and Zhang, Yimeng and Liu, Jiancheng and Runwal, Bharat and Diffenderfer, James and Kailkhura, Bhavya and Liu, Sijia},
  journal={arXiv preprint arXiv:2404.18239},
  year={2024}
}


