@misc{barez2025openproblemsmachineunlearning,
      title={Open Problems in Machine Unlearning for AI Safety}, 
      author={Fazl Barez and Tingchen Fu and Ameya Prabhu and Stephen Casper and Amartya Sanyal and Adel Bibi and Aidan O'Gara and Robert Kirk and Ben Bucknall and Tim Fist and Luke Ong and Philip Torr and Kwok-Yan Lam and Robert Trager and David Krueger and Sören Mindermann and José Hernandez-Orallo and Mor Geva and Yarin Gal},
      year={2025},
      eprint={2501.04952},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.04952}, 
}

@article{eldan2023s,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@inproceedings{jang-etal-2023-knowledge,
    title = "Knowledge Unlearning for Mitigating Privacy Risks in Language Models",
    author = "Jang, Joel  and
      Yoon, Dongkeun  and
      Yang, Sohee  and
      Cha, Sungmin  and
      Lee, Moontae  and
      Logeswaran, Lajanugen  and
      Seo, Minjoon",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
}

@article{liu2024rethinking,
  title={Rethinking machine unlearning for large language models},
  author={Liu, Sijia and Yao, Yuanshun and Jia, Jinghan and Casper, Stephen and Baracaldo, Nathalie and Hase, Peter and Yao, Yuguang and Liu, Chris Yuhao and Xu, Xiaojun and Li, Hang and others},
  journal={arXiv preprint arXiv:2402.08787},
  year={2024}
}

@article{zhang2023composing,
  title={Composing parameter-efficient modules with arithmetic operation},
  author={Zhang, Jinghan and Liu, Junteng and He, Junxian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={12589--12610},
  year={2023}
}

@article{zhang2024right,
  title={Right to be forgotten in the era of large language models: Implications, challenges, and solutions},
  author={Zhang, Dawen and Finckenberg-Broman, Pamela and Hoang, Thong and Pan, Shidong and Xing, Zhenchang and Staples, Mark and Xu, Xiwei},
  journal={AI and Ethics},
  pages={1--10},
  year={2024},
  publisher={Springer}
}

@article{zhong2024rose,
  title={ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2402.11889},
  year={2024}
}

