\section{Vulnerability Detection}\label{sec:detection}

\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{Sections/Picture/PhatomEventOverview.pdf}
  \caption{The architecture of \tool.}
  \label{fig:tool}
\end{figure*}

In this section, we focus on detecting vulnerabilities related to the attack vectors discussed in
\cref{sec:vector}. We introduce our hybrid approach, which combines static analysis with symbolic
execution and on-chain data monitoring to ensure comprehensive vulnerability detection.

\subsection{\tool Framework Design}

As shown in \cref{fig:tool}, our detection approach employs a multi-level strategy, encompassing
transaction-level, bytecode-level, and source code-level for vulnerability detection.

At the transaction level, we manually researched documentation for different projects to establish appropriate rules, given the variation in authentic events and emitters. These rules are applied to both historical and real-time on-chain transaction data to detect \emph{Contract Imitation} by identifying instances where phantom events are blended with authentic ones.

For smart contracts, our analysis proceeds across bytecode and source code levels. Initially, we decompile smart contract bytecode into an intermediate representation (IR) in three-address form using Gigahorse~\cite{Gigahorse}. From this IR, we construct an inter-contract control flow graph (ICFG) based on basic blocks. This graph enables backward taint analysis, which we use to trace event-related paths and detect vulnerabilities related to \emph{Event Counterfeiting} and \emph{Inconsistent Logging}.

If the source code is available, we extend our analysis using Slither to perform source code-level analysis. This provides a secondary confirmation for \emph{Event Counterfeiting} by tracing event-related call paths and extracting constraints for symbolic execution, allowing us to verify parameter values more comprehensively.

Due to the unique nature of certain attacks, \emph{Event Handling Error} lacks a specific detection method as it heavily relies on off-chain system validation. Similarly, \emph{Transfer Event Spoofing} is primarily a social engineering attack that focuses on token behavior analysis. Therefore, our tool primarily targets detecting the remaining three types of attacks: \emph{Event Counterfeiting}, \emph{Inconsistent Logging}, and \emph{Contract Imitation}, where distinct patterns and contract-level vulnerabilities can be effectively identified and addressed.

\subsection{Transaction-Level Detection}
At the transaction level, off-chain monitoring is applied to analyze on-chain transaction data and detect potential \emph{Contract Imitation} attacks.
By establishing domain-specific rules based on the expected behavior of smart contracts, we systematically verify whether transactions adhere to correct logic and identify any signs of malicious activity that may indicate phantom events or unauthorized interactions.

This analysis involves parsing transaction data and applying a set of rules to validate key aspects of events, including:
(1) ensuring that the emitted event has the correct signature;
(2) verifying that the event emitter matches the expected contract address;
(3) checking that the function execution path aligns with the expected logic; and
(4) confirming that the event parameter values match the expected ones.

By enforcing these rules, we can detect anomalies that may indicate \emph{Contract Imitation} attacks.
If an attack transaction is detected, further analysis is performed to confirm its impact, such as causing unauthorized fund transfers or state changes.

\begin{table*}[t]
  \centering
  \caption{Transaction logs of the pNetwork attack.}
  \label{tab:pnetwork_transaction}
  \resizebox{\textwidth}{!}{
    \begin{tabular}{lllp{7cm}}
      \toprule
      \textbf{Events} & \textbf{Parameters} & \textbf{Emitters} & \textbf{Parameter Values} \\
      \midrule
      Burned &
      operator, from, amount, data, operatorData &
      pBTC &
      (Attacker, Attacker, 0, , \_ ) \\
      \midrule
      Transfer &
      from, to, amount &
      pBTC &
      (Attacker, address(0), 0)\\
      \midrule
      Redeem &
      redeemer, value, underlyingAssetRecipient, userData &
      pBTC &
      (Attacker, 0, Attacker\_Bitcoin\_address, \_) \\
      \midrule
      Redeem &
      redeemer, value, underlyingAssetRecipient, userData &
      Malicious Contract &
      (Attacker, 274[...]144, Attacker\_Bitcoin\_address, \_) \\
      \bottomrule
  \end{tabular}}%
  %}
  \end{table*}

For example, in the pNetwork attack~\cref{tab:pnetwork_transaction}, a \emph{Redeem} event was emitted by a malicious contract with an unexpected contract address on the source chain. Applying these transaction-level rules allowed us to detect the attack. Subsequent monitoring of the destination chain transaction confirmed that the attack succeeded with unauthorized fund transfers.



\subsection{Smart-Contract-Level Detection}

\begin{algorithm}[t]
\label{algo:bytecode}
  \footnotesize
  \caption{Detecting Inconsistent Logging and Event Counterfeiting via Backward Taint Analysis}
  \textbf{Input:} \textit{IR}, an intermediate representation of smart contract bytecode via decompilation. \\
  \textbf{Output:} $E_v$, a set of vulnerable events. 
  \begin{algorithmic}[1]
    \State  $E_v = \emptyset$. 
    \State \textbf{construct} \textit{ICFG} out of IR.
    \State \textbf{extract} \textit{LogOps}, i.e., event log operations, from IR. \Comment{Each operation contains a event signature and a set of logging data variables} 
    
    % \State logBlocks $=$ extractLogBlocks(IR) \Comment{Extract log blocks with event signatures and variables}
    \State  \textit{Vars} $= \emptyset$, 
    \For{logOp $\in$ \textit{LogOps}}
      \State Vars $\gets$ Vars $\cup$ \textbf{vars}(logOp)  \Comment{Record all logging data variables}
      \State Slices $\gets$ \textsc{BackwardSlicing}(logOp, ICFG) \Comment{Each slice is a reverse execution flow path from logOp to function entry point }
          \State \textbf{extract} \textit{Paths}, i.e., inter-functional paths based on Slices and ICFG
      \State taintedPaths $\gets \emptyset$   
      \For{$p \in$ Paths}
        \State $source_{op} \gets$ \textsc{TaintAnalysis}($p$, Vars) 
        \If{$source_{op} \neq null$}
            \If{\textbf{sstore}($p$[:$source_{op}$]) $= \emptyset$} 
                \State $E_v \gets E_v \cup \textbf{event}(logOp)$ \Comment{No storage operations}
            \EndIf
            \State taintedPaths $\gets taintedPaths \cup \{\textbf{event}(logOp)\} $   
        \Else
            \If{HasExternalCall($p$) $\land$ not HasJumpi($p$)}
                 \State $E_v \gets E_v \cup \textbf{event}(logOp)$ \Comment{No constraints}
            \EndIf

        \EndIf
        % \State $src \gets$ TaintAnalysis($p$, taintVars, src) 
        
        % \If{(HasExternalCall($p$) \textbf{and not} HasJumpi($p$)) \textbf{or} (src $\neq$ null \textbf{and not} HasJumpi($p$)) \textbf{or} MultiplePathsEmitSameEvent(p, paths)}
        %   \State $Ev \gets Ev \cup \{log.event\}$ 
        % \EndIf
      \EndFor
      \If{$||taintedPaths|| >$ 1}
               \State $E_v \gets E_v \cup \textbf{event}(logOp)$ \Comment{A event logging action has multiple tainted paths}
        \EndIf
    \EndFor
    \State \textbf{return} $E_v$

\Procedure{TaintAnalysis}{path, taintVars}  
  \State $entry = path[-1]$ \Comment{Function entry point is the last item of this reverse execution path} \label{begin:taintanalysis}
  \For{$instr \in path$}
    \If{$\textbf{vars}(instr) \cap taintVars \neq \emptyset$}
        \State taintVars $\gets$ taintVars $\cup$ $\textbf{vars}(instr)$  \Comment{Taint propagation}
    % \ElsIf{$instr$ == sink}
    %   \State \textbf{return} $taintVars$ \Comment{Return the tainted variable}
    \EndIf
  \EndFor

  \If{$vars(entry) \cap taintVars \neq \emptyset $}
    \State \textbf{return} entry
  \Else 
    \State \textbf{return} null  \label{end:taintanalysis}
  \EndIf 
  
\EndProcedure 

% \Procedure{TaintAnalysis}{P, taintVars}
% \State $S \gets \emptyset$ \Comment{Initialize set of source variables} \label{begin:taintanalysis}
% \For{$index \gets |P| - 1$ \textbf{down to} $0$} \Comment{Reverse traverse the instruction sequence}
%     \State $instr \gets P[index]$
%     \If{$instr.lvars \in taintVars$}
%         \State $taintVars \gets taintVars \cup instr.rvars$ 
%     \EndIf
%     \If{$instr.rvars \in taintVars$}
%         \State $taintVars \gets taintVars \cup instr.lvars$ 
%     \EndIf
% \EndFor
% \State \Return null
% \label{end:taintanalysis}
% \EndProcedure

  \end{algorithmic}
  \label{algorithm}
\end{algorithm}


At the smart-contract level, we detect vulnerabilities specifically related to \emph{Event Counterfeiting} and \emph{Inconsistent Logging} through a multi-tiered analysis approach consisting of two parts: (1) identifying potential phantom events through \emph{inter-procedural backward taint tracking} at the bytecode level, and (2) confirming vulnerabilities by \emph{validating event parameter constraints} at the source-code level.
This dual-method approach allows us to analyze different representations of the contract to
identify vulnerabilities that may not be visible at a single level of abstraction.

\subsubsection{Phantom Event Identification Through Interprocedural Backward Taint Tracking}
At the bytecode level, as described in~\cref{algorithm}, the detection of vulnerabilities related to \emph{Event Counterfeiting} and \emph{Inconsistent Logging} is performed through backward taint analysis using an intermediate representation (IR) of the smart contract bytecode. The algorithm identifies vulnerable events \(E_v\) by analyzing the flow of data from event log operations to their sources and checking for specific conditions that indicate vulnerability.

The algorithm begins by initializing an empty set \(E_v\) to store vulnerable events (line 1). It constructs an inter-procedural control flow graph (ICFG) from the IR (line 2) and extracts all event log operations (\textit{LogOps}) from the IR (line 3). Each log operation consists of an event signature and a set of event data variables. The algorithm then initializes an empty set \textit{Vars} to record the event variables (line 4).

The construction of the ICFG involves recovering function-level information, such as function names and event signatures, by matching hashed identifiers in the bytecode with entries in a signature database. A control flow graph (CFG) is then constructed using basic blocks that represent possible execution paths within each function. These basic blocks are connected by directed edges based on control flow instructions and jump targets, forming the CFG. To capture interactions across functions, interprocedural calls are identified, and edges are added between caller and callee functions, thereby extending the CFG into an ICFG. 

For each log operation in \textit{LogOps}, the algorithm updates \textit{Vars} with the variables involved in the log operation (line 6). It then performs a \textsc{BackwardSlicing} analysis on the ICFG to extract slices representing the reverse execution flow from the log operation to the function entry point (line 7). These slices are used to derive inter-functional paths (\textit{Paths}) for further analysis (line 8).

For each path \(p\) in \textit{Paths}, the algorithm performs taint analysis using the \textsc{TaintAnalysis} function (line 9). This function evaluates whether tainted data propagates from the log operation to the path entry point. Starting from the log operation, tainted variables are tracked by propagating taint through instructions in the reverse execution path. Specifically, if an instruction interacts with tainted variables, its associated variables are added to the set of tainted variables. The process continues until reaching the path entry point, which serves as the source of the taint. If tainted variables are found at the path entry, the function returns the entry point as the (\(source_{op}\)); otherwise, it returns \texttt{null}.

If a source of tainted data (\(source_{op}\)) is identified, the algorithm checks if there are any storage operations (\texttt{sstore}) in the portion of the path leading to the source (line 11). Additionally, it verifies whether the variables involved in these \texttt{sstore} operations are subject to constraints (e.g., conditional jumps like \texttt{jumpi}). If no \texttt{sstore} operations are found, or if the \texttt{sstore} operations lack constraints on their variables, the corresponding event is added to \(E_v\) as potentially vulnerable to \emph{Inconsistent Logging} (line 12). The event is also recorded in a separate set of tainted paths for further evaluation (line 13).

If no source of tainted data is identified, the algorithm checks if the path contains an external call (\texttt{call}) without corresponding constraints (e.g., conditional branches like \texttt{jumpi}) (line 15). If such conditions are found, the event is added to \(E_v\) as vulnerable to \emph{Event Counterfeiting} (line 16).

After analyzing all paths for a log operation, the algorithm checks if multiple tainted paths exist for the same event (line 18). If so, the event is flagged as susceptible to \emph{Event Counterfeiting} due to the presence of multiple emission paths (line 19).

By analyzing the tainted data flow and identifying conditions such as missing constraints, unchecked external calls, and the absence of storage operations, the algorithm effectively detects vulnerabilities. Events flagged in \(E_v\) are susceptible to either \emph{Event Counterfeiting}, where the same event may be misleadingly emitted from multiple paths, or \emph{Inconsistent Logging}, where logged data may lack of control.


%Interprocedural Backward Taint Tracking involves constructing an inter-procedural control flow graph (ICFG) and applying backward taint analysis to trace data flows and identify potentially vulnerable paths related to log events. The process begins by recovering function-level information, such as function names and event signatures, by matching hashed identifiers in the bytecode with entries in a signature database. We then construct a control flow graph (CFG) using basic blocks that represent possible execution paths within each function. Basic blocks are connected by directed edges based on control flow instructions and jump targets, forming the CFG. To capture interactions across functions, we identify interprocedural calls and add edges between caller and callee functions, thereby extending the CFG into an ICFG.


%Backward taint analysis is applied on the ICFG to detect vulnerabilities by following tainted data backward from event emissions to identify unvalidated data sources and track how they propagate through the contract’s functions in~\cref{algorithm}. This process identifies paths susceptible to log forgery or inconsistency issues. For example, if the backward slice of a log event contains instructions associated with tainted data sources, the system can trace the ICFG to locate paths leading to the sink under analysis, verifying each instruction along these paths for potential vulnerabilities.


%For each extracted path, starting from the log operation, taint propagation is applied in reverse across memory, storage, and the stack, based on EVM instruction semantics. The \texttt{TaintAnalysis} function (lines~\ref{begin:taintanalysis}--\ref{end:taintanalysis}) assesses whether the tainted variables reach the function entry point in each path, returning the entry point if they do, or \texttt{null} otherwise.

%After completion of the taint analysis, the algorithm evaluates each path for specific vulnerabilities based on the tainted data flow. The presence of particular conditions indicates different types of vulnerabilities:

\begin{comment}
\begin{itemize}
    \item \textbf{Event Counterfeiting} is indicated if multiple paths emit the same event, particularly if the emitted event involves tainted variables. This condition alone strongly suggests potential \emph{Event Counterfeiting}, as it implies that the event may be duplicated or emitted misleadingly.

    \emph{Event Counterfeiting} risk is further categorized as follows:
    \begin{itemize}
        \item \textbf{Risk 1: Potential Event Counterfeiting} — If \textbf{multiple paths emit the same event}, this suggests a possibility of \emph{Event Counterfeiting} due to event duplication or misleading emissions.

        \item \textbf{Risk 2: Confirmed Event Counterfeiting} — If multiple paths emit the same event in conjunction with \textbf{any of the following three conditions} (lack of constraints on tainted variables or unchecked external calls), then \emph{Event Counterfeiting} is confirmed, as these combinations indicate higher risk for improper or misleading event emissions.
    \end{itemize}

    \item \textbf{Inconsistent Logging} is indicated if any one of the following three conditions is present on a path, suggesting that logged events may not fully align with the contract’s actual state or control flow:
    \begin{itemize}
        \item \textbf{Missing constraints on tainted variables}: If tainted variables propagate without encountering validation constraints (e.g., conditional jumps like \texttt{jumpi}), the path is flagged as vulnerable.
        \item \textbf{External calls without constraints}: If an external call (\texttt{call}) is made without a subsequent constraint check, this suggests that unsafe data may enter the contract unchecked, which could lead to inconsistencies.
        \item \textbf{Missing storage operations}: If tainted data flows through a path without encountering necessary storage operations (e.g., \texttt{SSTORE} or \texttt{SLOAD}), this can lead to potential mismatches between the logged events and the actual contract state.
    \end{itemize}
\end{itemize}
\end{comment}

\subsubsection{Source-Code-Level Validation of Event Parameter Constraints}

Bytecode-level analysis is limited as it only reveals indexed event parameters, without access to the full semantics of events.
Consequently, bytecode-level analysis can only detect potential \emph{Inconsistent Logging} issues by identifying inconsistencies in indexed parameters, and it cannot address non-indexed parameters.
To achieve complete validation, source code analysis is necessary.
At the source code level, we gain access to both indexed and non-indexed parameters, enabling a comprehensive evaluation of potential vulnerabilities, including both \emph{Event Counterfeiting} and \emph{Inconsistent Logging}, which bytecode-level analysis alone cannot fully uncover.

To address these challenges, we rely on the full semantic context of the contract source code to trace event-related call paths and apply symbolic execution to verify parameter constraints.
This ensures that events are emitted with consistent values across all paths, aligning both indexed and non-indexed parameters with the intended contract logic. Additionally, \emph{Event Counterfeiting} detection at the source-code level involves analyzing multiple execution paths to verify that events are not improperly used across functions, providing a depth of validation that cannot be achieved with bytecode analysis alone.

\begin{algorithm}
\footnotesize
  \caption{Finding Inconsistent Logging and Event Counterfeiting via Symbolic Execution}\label{alg:source}
  \begin{algorithmic}[1]
    \Statex \textbf{Input:} \textit{SC}, the source code of smart contracts.
    \Statex \textbf{Output:} $E_v$, a set of phantom events.
      \State $E_v = \emptyset$
      \State \textbf{extract} $E$, i.e., all events from SC. \label{source:event}

      \For{$event \in E$}
        \State $Paths \gets \textsc{SearchPaths}({event, SC})$ \Comment{Get all paths reaching the event}

        \For{$p \in Paths$}
          \State $constraints \gets \textsc{symbolicExec}({p})$
          \If{\Call{CheckLoggingInconsistency}{constraints}}
            \State{$E_v \gets E_v \cup \{event\}$}
          \EndIf
        \EndFor

        \For{$p_1, p_2 \in Paths$}
          \State $constraints_1 \gets \textsc{symbolicExec}({p_1})$
          \State $constraints_2 \gets \textsc{symbolicExec}({p_2})$
          % \State \parbox[t]{\linewidth} {$hasIntersect \gets \Call{Solver}{constraintsA, constraintsB}$}

          \If{$\textsc{SMT-Solve}({constraints_1 \land constraints_2})$}
            \State{$E_v \gets E_v \cup \{event\}$}
          \EndIf
        \EndFor
      \EndFor

      \State \Return $E_v$

  \end{algorithmic}
\end{algorithm}

At the source-code level, as detailed in~\cref{alg:source}, the tool begins by initializing an empty set \(E_v\) to store potentially vulnerable events. Then extracts all events \(E\) from the smart contract source code \textit{SC}. For each event in \(E\), the tool performs the following steps:

First, the tool extracts all execution paths \(Paths\) in \textit{SC} that lead to the emission of the event using the \textsc{SearchPaths} function. This involves traversing the contract's call graph to capture all inter-procedural paths from user-callable functions to the event-emitting statements. For each path \(p \in Paths\), the tool performs symbolic execution using \textsc{symbolicExec} to extract the path constraints related to the event parameters. The tool then applies the \textsc{CheckLoggingInconsistency} function to verify if any path shows inconsistencies in logging by comparing constraints for all parameters (both indexed and non-indexed). This function is similar to the bytecode analysis, it will detect vulnerabilities by checking for missing constraints on variables, unchecked external calls, or missing storage operations. If inconsistencies are detected, the event is added to \(E_v\) as potentially vulnerable to \emph{Inconsistent Logging}.

Next, the tool performs \emph{Event Counterfeiting} detection by considering all pairs of distinct paths \((p_1, p_2)\) in \(Paths\) which have the same event. For each pair, it performs symbolic execution to obtain constraints \(constraints_1\) and \(constraints_2\) for each path. Using an SMT solver, it checks if the conjunction \(constraints_1 \land constraints_2\) is satisfiable. If the solver finds a solution, this indicates that there is an overlap in parameter values between the two paths, making it difficult for validators to distinguish between events emitted from different paths. In such cases, the event is added to \(E_v\) as potentially susceptible to \emph{Event Counterfeiting}.

Finally, the tool returns the set \(E_v\), which contains events flagged for potential vulnerabilities. For example, consider the \emph{Deposit} event from~\cref{code:1}, which is emitted by the functions \emph{deposit} and \emph{depositETH}. The tool identifies these functions in the AST of the contract, then analyzes their respective execution paths to extract the constraints for the event parameters. For \emph{depositETH}, the constraint is \(msg.value > 0\), while for \emph{deposit}, the constraint is \(\text{bool}(\text{token.call}(\text{signature})) \land (amount > 0)\). Using an SMT solver, the tool evaluates these constraints to check for any overlapping parameter values. If an intersection exists, this suggests potential \emph{Event Counterfeiting}, as a validator may be unable to distinguish between emissions from these two functions, leading the tool to flag the event as forgeable for further review.