\section{Related Works}
\paragraph{Dynamic 3D scene reconstruction.}

3D Gaussian Splatting (3DGS)~\cite{kerbl20233d} offers a distinct representation for novel view synthesis with improved rendering quality and speed. Several concurrent works
~\cite{wang2024gflow,wu20234dgs,yang2023deformable,huang2023scgs} 
have adapted 3DGS for reconstructing dynamic scenes. For instance, Deformable 3DGS~\cite{yang2023deformable} formulates the dynamic field based on multi-layer perceptron (MLP) with differentiable rendering. 4DGS~\cite{wu20234dgs} improves the rendering speed with a compact network. SCGS~\cite{huang2023scgs} explicitly decomposes the motion and dynamic scenes into sparse control points and the deformation of Gaussians is controlled by its $k$-nearest control points. 

Though achieving promising rendered quality, the rendering speed for dynamic scenes is much slower than rendering static scenes (100 FPS \textit{v.s.} 20 FPS at 1K resolution). The bottleneck of the rendering speed for dynamic scenes is the number of Gaussian points. As shown in \cref{fig:fig1}, as more Gaussians are densified, an enormous amount of Gaussians are fed into the deformation network, which leads to slower rendering speed. Moreover, \cite{huang2023scgs,yang2023deformable,wu20234dgs} query the attributes of all Gaussians at each timestep, even though the static areas in real-world scenes are time-invariant and do not require querying by MLPs. As shown in \cref{fig:error}, the static areas of \cite{yang2023deformable,wu20234dgs}'s rendered results are still jittering across time. 

\paragraph{Grid-based rendering for acceleration.}

Grid-based representations are based on a dense uniform grid of voxels~\cite{fridovich2022plenoxels,kplanes,hexplane,lu2023scaffold} explicitly or implicitly. For instance, K-Planes~\cite{kplanes} applies neural planes to parameterize a 3D scene, with an additional temporal plane to accommodate dynamics. HexPlane~\cite{hexplane} further enhances the neural planes for time and space by factorizing space and time into compact neural representations. Scaffold-GS~\cite{lu2023scaffold} introduces anchor-voxel-based strategy to achieve reduced storage parameters for static scenes. Scaffold-GS can render a similar speed (100 FPS at 1K resolution) as 3DGS and the storage requirements are significantly reduced as Scaffold-GS only needs to store anchor points and MLPs for each scene. However, Scaffold-GS is designed for real-world static scenes and we are the first to adapt anchor-voxel-based strategy to dynamic scene reconstruction.