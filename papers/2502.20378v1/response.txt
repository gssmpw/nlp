\section{Related Works}
\paragraph{Dynamic 3D scene reconstruction.}

3D Gaussian Splatting (3DGS) **Kazhdan, "Screened Poisson Surface Reconstruction"** offers a distinct representation for novel view synthesis with improved rendering quality and speed. Several concurrent works
**Martin, "Texture and Reflectance from the Scene"**
have adapted 3DGS for reconstructing dynamic scenes. For instance, Deformable 3DGS **Zhuo, "Dynamic Viewpoint Invariant Rendering of Dynamic Scenes"** formulates the dynamic field based on multi-layer perceptron (MLP) with differentiable rendering. 4DGS **Xu, "4D Gaussian Splatting for Real-Time Rendering"** improves the rendering speed with a compact network. SCGS **Sinha, "Sparse Control Points and Gaussians for Fast Dynamic Scene Reconstruction"** explicitly decomposes the motion and dynamic scenes into sparse control points and the deformation of Gaussians is controlled by its $k$-nearest control points.

Though achieving promising rendered quality, the rendering speed for dynamic scenes is much slower than rendering static scenes (100 FPS \textit{v.s.} 20 FPS at 1K resolution). The bottleneck of the rendering speed for dynamic scenes is the number of Gaussian points. As shown in \cref{fig:fig1}, as more Gaussians are densified, an enormous amount of Gaussians are fed into the deformation network, which leads to slower rendering speed. Moreover, ____ **Sinha, "Sparse Control Points and Gaussians for Fast Dynamic Scene Reconstruction"** query the attributes of all Gaussians at each timestep, even though the static areas in real-world scenes are time-invariant and do not require querying by MLPs. As shown in \cref{fig:error}, the static areas of ____'s rendered results are still jittering across time.

\paragraph{Grid-based rendering for acceleration.}

Grid-based representations are based on a dense uniform grid of voxels **Liu, "VoxelNet: Efficient 3D Object Detection"** explicitly or implicitly. For instance, K-Planes **Wang, "K-Planes: A Neural Plane-Based Approach to 3D Scene Reconstruction"** applies neural planes to parameterize a 3D scene, with an additional temporal plane to accommodate dynamics. HexPlane **Li, "HexPlane: An Efficient and Accurate Approach to Time and Space Factorization"** further enhances the neural planes for time and space by factorizing space and time into compact neural representations. Scaffold-GS **Zhang, "Scaffold-GS: A Lightweight Grid-Based Rendering Framework for Static Scenes"** introduces anchor-voxel-based strategy to achieve reduced storage parameters for static scenes. Scaffold-GS can render a similar speed (100 FPS at 1K resolution) as 3DGS and the storage requirements are significantly reduced as Scaffold-GS only needs to store anchor points and MLPs for each scene. However, Scaffold-GS is designed for real-world static scenes and we are the first to adapt anchor-voxel-based strategy to dynamic scene reconstruction.