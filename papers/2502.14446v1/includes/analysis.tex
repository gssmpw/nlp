\section{Analysis}
\label{sec:complexity}
In this section, we derive the probabilistic guarantees for our algorithm as well as analyze its complexity.



\begin{lemma}\label{lem:collision-probability}
Given a pair of subsequences $\subTa, \subTb$ and parameter $d_m$,
consider iteration
$i$ of the outer loop of \Cref{alg:emitaggr}.
Then, we have $W(a, b) \ge d$ with probability at least
\begin{equation}
    P\left(\distdmax{\subTa, \subTb}\right)^{i \cdot d}
\end{equation}
where $\distdmax{\cdot,\cdot}$ is defined as in Equation~\eqref{eq:distdmax}.
\end{lemma}
\begin{proof}
    To have $W(a,b) \ge d$ we need the two subsequences to collide in at least $d$ dimensions.
    \newline
    Consider the distance $\distdmax{\subTa, \subTb}$ and recall that, by definition, all dimensions
    $F=\dims{\subTa, \subTb}$ will be at a closer distance.

    At iteration $i$ of the outer loop of \Cref{alg:emitaggr} we have that the two subsequences collide in all dimensions $F$ at the same time with probability at least
    \[
    \prod_{f\in F} P\left(\dist {\subTaf, \subTbf}\right)^i
    \]
    given that $\bar{f}$ is the dimension of maximum distance out of the $d$ ones in $F$, each
    factor of the above product is lower bounded by 
    $P\left(\subTsingle{a}{\bar{f}},\subTsingle{b}{\bar{f}}\right)$,
    hence the statement follows.
\end{proof}



\subsection{Correctness}

To prove correctness we need to show that motif pairs are considered at least once before the algorithm terminates.

The following lemma bounds the probability that a given pair of subsequences at indices $a$ and $b$
never has a weight $W(a,b) \ge d$. In other words, the following lemma bounds the probability that a pair is never considered for inclusion in the \texttt{TOP} priority queue.

\begin{lemma}
    \label{lemma:stop}
    Let $(\subTa, \subTb)$ be a pair of subsequences and let
    \[
    \begin{aligned}
    p = P\left(\distdmax{\subTa,\subTb}\right)^d
    \end{aligned}
    \]
    Consider iteration $i$ out of $K$ of the outer loop
    and iteration $j$ out of $L$ of the inner loop of Algorithm~\ref{alg:emitaggr}.
    The probability that $W(a,b) < d$ in all previous iterations is
    upper bounded by
    \begin{equation}
    \label{eq:probnotcolliding}
      \left\{
        \begin{aligned}
        &\left(1-p^i\right)^j \quad &\textrm{ if }~~ i=K \\
        &\left(1-p^i\right)^j \cdot \left(1-p^{i+1}\right)^{L-j} \quad&\textrm{ otherwise}
        \end{aligned}
      \right.
    \end{equation}
\end{lemma}
\begin{proof}Sketch of the proof:
from Lemma~\ref{lem:collision-probability} we know the probability of the pair to collide in a single repetition with prefixes of length $i$. For the given pair the failure event is to have a weight $W(a,b)<d$. Therefore, the probability of never colliding over $j$ independent repetitions is $(1-p^i)^j$.
In the case where $i=K$, the statement follows.
When $i <K$, we consider that the first $j$ iterations performed with prefix $i$ fail independently and that the $L-j$ iterations previously run with prefix $i+1$ failed as well.
\end{proof}



From this we now derive two lemmas on the success probability of the discovery.
In \Cref{lemma:topk} we allow each motif to fail independently, in \Cref{lemma:topkdip} we require that all the returned motifs are correct within a probability.
\begin{lemma}
    \label{lemma:topk}
    \Cref{alg:emitaggr} finds the true top-$k$ motifs, each with probability $\geq 1-\delta$.
\end{lemma}
\begin{proof}
    Let the stopping condition be met at iteration $i'$ and concatenation $j'$, $m_1,...m_k$ be the set of motifs returned by the algorithm, sorted by increasing distances. We have that the failure probability of $m_h,\text{ } h\in[1,k]$ is upper bounded by the failure probability $m_k$ for the monotonicity of the collision probability. This failure probability is given by \Cref{lemma:stop}, by construction the stopping condition ensures that this probability is $\leq \delta$. This is valid for all returned pairs independently. 

    If the stopping condition is never met the algorithm reaches line 20, 
    where all pairs of subsequences are considered, thus returning the correct motifs with probability 1.
\end{proof}
Given this lemma it is easy to derive the expected recall of the algorithm, that corresponds to $1-\delta$.
\begin{lemma}
\label{lemma:topkdip}
    When called with failure probability $\delta'=\delta / k$, \Cref{alg:emitaggr} finds the true top-$k$ motifs with probability $\geq 1-\delta$.
\end{lemma}
\begin{proof}
    From \Cref{lemma:topk} we have that each pair fails independently with probability $\leq \delta'= \delta /k$.
    By applying a union bound on the $k$ pairs we obtain the statement.
\end{proof}
\subsection{Number of Distance Computations}

First, we introduce the concept of \emph{contrast}, which will be useful in capturing the difficulty of a dataset and in relating it to the complexity of our algorithm.

\begin{definition}
\label{sec:contrast}
For a $D$-dimensional time series $\Tmulti$ of length $n$, and for parameters $k$ and $d$ let
$(\subTmulti{a_k}, \subTmulti{b_k})$
and
$(\subTmulti{a_n}, \subTmulti{b_n})$
be the $k$-th and $n$-th motifs, respectively.
We define
\[
\operatorname{contrast}_{d,k|n}(\Tmulti) = \frac{
  \distdmax{\subTmulti{a_n}, \subTmulti{b_n}}
}{
  \distdmax{\subTmulti{a_k}, \subTmulti{b_k}}
}
\]
\end{definition}

The following theorem ensures that our algorithm computes, in expectation, a subquadratic number of distances
in expectation, assuming we give to the algorithm enough memory.
The complexity is parameterized by the contrast of the motifs in the multivariate time series:
a large contrast implies a smaller complexity.

\begin{theorem}
Algorithm~\ref{alg:emitaggr}, when invoked on a $D$-dimensional time series $\Tmulti$ of length $n$,
with parameters $k>1$, $1\le d\le D$ and $0 <\delta < 1$, computes
\[
  O\left(
    n^{1 + 1/c} \log\frac{1}{\delta} + Lk
  \right)
\]
distances in expectation, where $c=\operatorname{contrast}_{d,k|n}(\Tmulti)$,
assuming $L \in \Omega\left(n^{1/c}\right)$.
\end{theorem}
\begin{proof}
\newcommand{\distcomps}[1]{\operatorname{ED}\left(#1\right)}
Let $\mathbb{T}$ be the set of all the subsequence pairs of $\Tmulti$.
For any pair of subsequence indices $(a, b)$, let
\[
p_{ab} = P\left(\distdmax{\subTa, \subTb}\right)^d
\]

Consider 
$(\subTmulti{a_k}, \subTmulti{b_k})$
and
$(\subTmulti{a_n}, \subTmulti{b_n})$,
the $k$-th and $n$-th $d$-dimensional motifs of $\Tmulti$, and let
$p_1=p_{a_k b_k}$ and $p_2=p_{a_n b_n}$.
Furthermore, let
$\rho = \frac{\log 1/p_1}{\log 1/p_2}$.

For notational convenience, define the following operator that gives the expected number of
distance computations carried out in $j$ independent repetitions with hash prefixes
of length $i$:
\begin{equation*}
\distcomps{i, j}
=
j\cdot \left(
\sum_{(\subTa, \subTb) \in \mathbb{T}} p_{ab}^{i}
\right)
\end{equation*}

Recall that, for hash prefixes of length $i$, examining
$\frac{\log 1/\delta}{p_1^i}$ independent repetitions ensures that
the top $k$ motif pairs are seen at least once with probability at least $1-\delta$.
Using the notation shorthand defined above, the number of expected distance computations
in this case is
$
\distcomps{i, \frac{\log 1/\delta}{p_1^i}}
$.

Now define $\mathbb{T}_{>k}$ and $\mathbb{T}_{>n}$ as the sets of subsequence pairs
that are farther than the $k$-th and $n$-th motifs, respectively.
Then we have
\begin{equation}
\label{eq:bounding_T>n}
\begin{aligned}
\distcomps{i, \frac{\log 1/\delta}{p_1^i}}
\le&
\frac{\log\frac{1}{\delta}}{p_1^i}
\cdot
\left(
n +
\sum_{(\subTa, \subTb) \in \mathbb{T}_{>n}} p_{ab}^{i}
\right) \\
\le&
\frac{\log\frac{1}{\delta}}{p_1^i}
\cdot
\left(
n + {n \choose 2} p_2^i
\right)
\end{aligned}
\end{equation}
where the inequality follows from the definition of $\mathbb{T}_{>n}$.

Defining
$i^* = \frac{\log n}{\log\frac{1}{p_2}}$
we have
${n \choose 2} p_2^{i^*} \le n$
and
$\frac{1}{p_1^{i^*}} =n^{\frac{\log 1/p_1}{\log 1/p_2}} = n^\rho$.

Therefore there is a prefix length $i^*$ for which the number of expected distance computations
to see the $k$-th motif colliding at least once is
\begin{equation}\label{eq:istar-distcomps}
\distcomps{i^*, \frac{\log 1/\delta}{p_1^{i^*}}}
=
O\left( n^{1+\rho}\log\frac{1}{\delta} \right)
=
O\left( n^{1+\frac{1}{c}}\log\frac{1}{\delta} \right)
\end{equation}
where $c = \operatorname{contrast}_{d,k|n}(\mathbf{T})$ and the equality follows
from the definition of $\rho$ for the LSH family we employ in our algorithm.

Now, let $i' \ge i^*$ be the largest prefix $i$ such that the stopping condition holds.
With probability $1-\delta$ the algorithm stops at prefix $i'$.
Conditioned on this event, the number of distance computations carried out at level $i'$ is
\begin{equation}\label{eq:iprime-distcomps}
\distcomps{i', \frac{\log 1/\delta}{p_1^{i'}}}
+
\distcomps{i'+1, L-\frac{\log 1/\delta}{p_1^{i'}}}
\end{equation}
Where the second term accounts for the repetitions considered in iteration $i'+1$ of the outer loop of the algorithm.
First we bound the first term of the addition.
Similarly to before, define $\mathbb{T}_{>k}$ as the set of subsequence pairs that are farther away than the $k$-th motif.
\begin{equation}
\label{eq:boundingi*}
\begin{aligned}
\distcomps{i', \frac{\log 1/\delta}{p_1^{i'}}}
&\le\frac{\log 1/\delta}{p_1^{i'}}\left(
    k + \sum_{(\subTa, \subTb)\in\mathbb{T}_{>k}} p_{ab}^{i'}
    \right)\\
&\le
    Lk
    +
    \frac{\log 1/\delta}{p_1^{i'}}\left(
    \sum_{(\subTa, \subTb)\in\mathbb{T}_{>k}} p_{ab}^{i'}
    \right)\\
&\stackrel{(a)}{\le}
    Lk
    +
    \frac{\log 1/\delta}{p_1^{i*}}\left(
    \sum_{(\subTa, \subTb)\in\mathbb{T}_{>k}} p_{ab}^{i^*}
    \right)\\
&\le
    Lk + \distcomps{i^*, \frac{\log 1/\delta}{p_1^{i^*}}}\\
&\stackrel{(b)}{=}
    O\left(
        Lk + n^{1+\frac{1}{c}} \log \frac{1}{\delta}
    \right)
\end{aligned}
\end{equation}
where (a) follows from the fact that $p_1 \ge p_{ab}$
and (b) follows from Equation~\eqref{eq:istar-distcomps}.
The theorem follows by observing that the second term of Equation~\eqref{eq:iprime-distcomps} is a factor $1/p_1 = O(1)$ larger than the first term.
\end{proof}


\subsection{Index construction and size}
We now consider the contribution to the running time of \Cref{alg:emitaggr} given by the hash index and derive its space complexity.
\begin{lemma}
\label{lemma:line3}
    The hash construction at line~\ref{ln:hash-computation} of \Cref{alg:emitaggr} takes time $O(D\cdot K \cdot L \cdot n\log n)$.
\end{lemma}
\begin{proof}
    For each multidimensional subsequence we have to evaluate $D\cdot K \cdot L$ hashes. For a fixed hash function we can compute all the dot products in $O\left(n\log n\right)$ time, using the cyclical convolution theorem. The result follows.
\end{proof}

Given that for each of the $n$ subsequences we have to store, in each of the $L$ repetitions, a total of $D$ hashes of length $K$ we have the following.
\begin{theorem}
    \Cref{alg:emitaggr} has space complexity proportional to $O\left(K\cdot L \cdot D\cdot n\right)$.
\end{theorem}

