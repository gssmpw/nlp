\begin{wrapfigure}[20]{L}{0.5\textwidth}
\vspace{2mm}
    \centering
    \captionof{table}{\label{tab:imagenet_results} Comparison of test accuracy on ImageNet-1k. The model trained with the full dataset achieves 73.1\% test accuracy. The best result in each pruning ratio is highlighted in bold.}
    \small
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Pruning Rate} & \textbf{30\%} & \textbf{50\%} & \textbf{70\%} & \textbf{80\%} & \textbf{90\%} \\
        \midrule
        \textbf{Random} & 72.2 & 70.3 & 66.7 & 62.5 & 52.3 \\
        \textbf{Entropy} & 72.3 & 70.8 & 64.0 & 55.8 & 39.0 \\
        \textbf{Forgetting} & 72.6 & 70.9 & 66.5 & 62.9 & 52.3 \\
        \textbf{EL2N} & 72.2 & 67.2 & 48.8 & 31.2 & 12.9 \\
        \textbf{AUM} & 72.5 & 66.6 & 40.4 & 21.1 & 9.9 \\
        \textbf{Moderate} & 72.0 & 70.3 & 65.9 & 61.3 & 52.1 \\
        \textbf{Dyn-Unc} & 70.9 & 68.3 & 63.5 & 59.1 & 49.0 \\
        \textbf{TDDS} & 70.5 & 66.8 & 59.4 & 54.4 & 46.0 \\
        \textbf{CCS} & 72.3 & 70.5 & 67.8 & 64.5 & 57.3 \\
        \textbf{D2} & 72.9 & 71.8 & 68.1 & 65.9 & 55.6 \\
        \midrule
        \textbf{DUAL} & 72.8 & 71.5 & 68.6 & 64.7 & 53.1 \\
        \textbf{DUAL+$\beta$ sampling} & \textbf{73.3} & \textbf{72.3} & \textbf{69.4} & \textbf{66.5} & \textbf{60.0} \\
        \bottomrule
    \end{tabular}
\end{wrapfigure}