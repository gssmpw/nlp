\section{More Results on Experiments}
We evaluate our proposed DUAL score through a wide range of analyses in this section. In Appendix~\ref{Appendix_labelnoise_experiments} and~\ref{Appendix_imagecorruption_experiments}, we demonstrate the robustness of the DUAL score across a variety of experiments. In Appendix~\ref{Appendix_cross_architecture}, we investigate the cross-architecture performance of DUAL pruning. 
In Appendix~\ref{Appendix_beta_samapling}, we show that beta sampling performs well even when combined with other score metrics, such as EL2N and Dyn-Unc, and also shows strong performance when compared to other sampling methods, especially CCS.


We first investigate the stability of our DUAL score compared to other baselines. We calculate the Spearman rank correlation of each score and the average score across five runs, following \citet{paul2021deep}. As shown in Figure~\ref{fig:rank_corr}, snapshot-based methods such as EL2N and Entropy exhibit relatively low correlation compared to methods that consider training dynamics. In particular, the DUAL score shows minimal score variation across runs, resulting in a high Spearman rank correlation, indicating strong stability across random seeds. Notably, even when the scores are calculated at the 30th epoch, the Spearman correlation between the individual scores and the overall average score remains approximately 0.95.

\label{Appendix_Experiments}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/Rank_Correlation.pdf}
    \caption{\label{fig:rank_corr}Average of Spearman rank correlation among independent runs and an overall average of five runs.}
\end{figure}

Next, we compute the Dyn-Unc, TDDS, and AUM scores at the 30th epoch, as we do for our method, and then compare the test accuracy on the coreset. Our pruning method, using the DUAL score and ratio-adaptive beta sampling, outperforms the others by a significant margin, as illustrated in Figure~\ref{fig:computation_30_cifar100}.
We see using epoch 30 results in insufficient training dynamics for the others, thus it negatively impacts their performance.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.55\linewidth]{Figures/Computation_30_CIFAR100.pdf}
    \caption{\label{fig:computation_30_cifar100}Test accuracy comparison under limited computation budget (epoch 30)}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/TestAcc_J_varying.pdf}
    \caption{\label{fig:J_varying} J varies from 5 to 15, showing minimal differences, which demonstrates its robustness. We fix $T=30$, $C_\gD=4$. Runs are averaged over three runs.}
\end{figure}






\newpage
\subsection{Image Classification with Label Noise}
\label{Appendix_labelnoise_experiments}
We evaluated the robustness of our DUAL pruning method against label noise. We introduced symmetric label noise by replacing the original labels with labels from other classes randomly. For example, if we apply 20\% label noise to a dataset with 100 classes, 20\% of the data points are randomly selected, and each label is randomly reassigned to another label with a probability of $1/99$ for the selected data points.

Even under 30\% and 40\% random label noise, our method achieves the best performance and accurately identifies the noisy labels, as can be seen in Figure~\ref{fig:label_noise_3040_ratio}. By examining the proportion of noise removed, we can see that our method operates close to optimal. 
\begin{figure}[htbp] 
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/label_noise30_ratio.pdf}
        \caption{\label{fig:label_noise_30_ratio}30\% label noise}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/label_noise40_ratio.pdf} 
        \caption{\label{fig:label_noise_40_ratio}40\% label noise}
    \end{subfigure}
    \caption{\label{fig:label_noise_3040_ratio}Ratio of pruned mislabeled data under 30\% and 40\% label noise on CIFAR-100}
\end{figure}

Figure~\ref{fig:label_noise_visualization} shows a scatter plot of the CIFAR-100 dataset under 20\% label noise. The model is trained for 30 epochs, and we compute the prediction mean (y-axis) and standard deviation (x-axis) for each data point. Red dots represent the 20\% mislabeled data. These points remain close to the origin (0,0) during the early training phase. Therefore, pruning at this stage allows us to remove mislabeled samples nearly optimally while selecting the most uncertain ones.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figures/LabelNoise_Visualization.png}
    \caption{Pruning ratio is set to 50\%. Only 116 data points over 10,000 mislabeled data are selected as a subset where red dots indicate mislabeled data.}
    \label{fig:label_noise_visualization}
\end{figure}


We evaluated the performance of our proposed method across a wide range of pruning levels, from 10\% to 90\%, and compared the final accuracy with that of baseline methods. As shown in the Table~\ref{tab:label_noise_20_cifar}-\ref{tab:label_noise_20_tinyimagenet}, our method consistently outperforms the competition with a substantial margin in most cases. For a comprehensive analysis of performance under noisy conditions, please refer to Tables~\ref{tab:label_noise_20_cifar} to \ref{tab:label_noise_40_cifar} for CIFAR-100, which show results for 20\%, 30\%, and 40\% noise, respectively. Additionally, the results for 20\% label noise in Tiny-ImageNet are shown in Table~\ref{tab:label_noise_20_tinyimagenet}.
\input{04C_Table_LabelNoise}

\clearpage

\subsection{Image Classification with Image Corruption}
\label{Appendix_imagecorruption_experiments}
We also evaluated the robustness of our proposed method against five different types of realistic image corruption: motion blur, fog, reduced resolution, rectangular occlusion, and Gaussian noise across the corruption rate from 20\% to 40\%. The ratio of each type of corruption is 4\% for 20\% corruption, 6\% for 30\% corruption, and 8\% for 40\% corruption. Example images for each type of corruption can be found in Figure~\ref{fig:example_imagecorruption}. Motion blur, reduced resolution, and rectangular occlusion are somewhat distinguishable, whereas fog and Gaussian noise are difficult for the human eye to differentiate. Somewhat surprisingly, our DUAL pruning prioritizes removing the most challenging examples, such as fog and Gaussian corrupted images, as shown in Figure~\ref{fig:imagecorruption_all}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Figures/example_imagecorruption.pdf}
    \caption{Examples of the different types of noise used for image corruption. Here we consider motion blur, fog, resolution, rectangle, and Gaussian noise.}
    \label{fig:example_imagecorruption}
\end{figure}


\begin{figure}[htbp] 
    \centering
    \begin{subfigure}{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/imagecorruption_20_ratio.pdf}
        \caption{20\% image corruption}
        \label{fig:imagecorruption20_ratio}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/imagecorruption_30_ratio.pdf} 
        \caption{30\% image corruption}
        \label{fig:imagecorruption30_ratio}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.325\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/imagecorruption_40_ratio.pdf} 
        \caption{40\% image corruption}
        \label{fig:imagecorruption40_ratio}
    \end{subfigure}
    \caption{Ratio of pruned corrupted samples with corruption rate of 20\%, 30\% and 40\% on CIFAR-100.}
    \label{fig:imagecorruption_203040_ratio}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Figures/imagecorruption_all.pdf}
    \caption{Illustration of the different types of noise used for image corruption. DUAL pruning prioritizes removing the most challenging corrupted images, such as fog and Gaussian noise.}  
    \label{fig:imagecorruption_all}
\end{figure}




We evaluated the performance of our proposed method across a wide range of pruning levels, from 10\% to 90\%, and compared the final accuracy with that of baseline methods. As shown in the table, our method consistently outperforms the competitors in most cases. For a comprehensive analysis of performance under noisy conditions, please refer to Tables~\ref{tab:image_corruption_20_cifar} to \ref{tab:image_corruption_40_cifar} for CIFAR-100, which show results for 20\%, 30\%, and 40\% corrupted images, respectively. Additionally, the results for 20\% image corruption in Tiny-ImageNet are shown in Table~\ref{tab:image_corruption_20_tinyimagenet}.

\input{04D_Table_ImageCorruption}

\clearpage

\subsection{Cross-architecture generalization}
\label{Appendix_cross_architecture}
In this section, we investigate the cross-architecture generalization ability of our proposed method. Specifically, we calculate the example score on one architecture and test its coreset performance on a different architecture. This evaluation aims to assess the ability of example scores to be transferred across diverse architectural designs. 

\begin{table}[ht]
\caption{Cross-architecture generalization performance on CIFAR-100 from three layer CNN to ResNet-18. We report an average of five runs. `R18 $\rightarrow$ R18' stands for score computation on ResNet-18, as a baseline.}
\label{tab:cross-arch-cnn}
    \centering
    \begin{tabular}{lcccc}
    \toprule
    \multicolumn{4}{c}{}{3-layer CNN $\rightarrow$ ResNet-18} & \\
    \hline 
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\%  \\
    \hline
    Random & 75.15 \scriptsize{$\pm 0.28$} & 71.68 \scriptsize{$\pm 0.31 $} & 64.86 \scriptsize{$\pm 0.39$} & 45.09 \scriptsize{$\pm 1.26 $} \\
    EL2N & 76.56 \scriptsize{$\pm 0.65$} & 71.78 \scriptsize{$\pm 0.32$} & 56.57 \scriptsize{$\pm 1.32$} & 22.84 \scriptsize{$\pm 3.54 $} \\
    Dyn-Unc & \textbf{76.61} \scriptsize{$\pm 0.75$} & 72.92 \scriptsize{$\pm 0.57 $} &65.97 \scriptsize{$\pm 0.53 $} & 44.25 \scriptsize{$\pm 2.47$} \\
    CCS & 75.29 \scriptsize{$\pm 0.20 $} & 72.06 \scriptsize{$\pm 0.19$} & \textbf{66.11} \scriptsize{$\pm 0.15$} & 36.98 \scriptsize{$\pm 1.47$} \\
    \hline
    DUAL & \textbf{76.61} \scriptsize{$\pm 0.08$} & \textbf{73.55} \scriptsize{$\pm 0.12$} & 65.97 \scriptsize{$\pm 0.18$} & 39.00 \scriptsize{$\pm 2.51 $} \\
    DUAL+$\beta$ sampling & 76.36 \scriptsize{$\pm 0.18 $} & 72.46 \scriptsize{$\pm 0.41 $} & 65.50 \scriptsize{$\pm 0.53$} & \textbf{48.91} \scriptsize{$\pm 0.60 $} \\
    \hline
    \hline
    DUAL (R18$\rightarrow$R18) & 77.43 \scriptsize{$\pm 0.18$} &  74.62 \scriptsize{$\pm 0.47 $} & 66.41 \scriptsize{$\pm 0.52 $} & 34.38 \scriptsize{$\pm 1.39 $} \\
    DUAL (R18$\rightarrow$R18) +$\beta$ sampling & 77.86 \scriptsize{$\pm 0.12$} & 74.66  \scriptsize{$\pm 0.12 $} & 69.25 \scriptsize{$\pm 0.22$} & 54.54 \scriptsize{$\pm 0.09$} \\
    \bottomrule
    \end{tabular}
    \label{tab:cnn-to-resnet18}
\end{table}
    
    
\begin{table}[ht]
\caption{Cross-architecture generalization performance on CIFAR-100 from three layer CNN to VGG-16. We report an average of five runs. `V16 $\rightarrow$ V16' stands for score computation on VGG-16, as a baseline.}
    \centering
    \begin{tabular}{lcccc}
    \toprule
    \multicolumn{4}{c}{}{3-layer CNN $\rightarrow$ VGG-16} & \\
    \hline 
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\%  \\
    \hline
    Random & 69.47 \scriptsize{$\pm 0.27$} & 65.52 \scriptsize{$\pm 0.54 $} & 57.18 \scriptsize{$\pm 0.68 $} & 34.69 \scriptsize{$\pm 1.97 $} \\
    EL2N & 70.35 \scriptsize{$\pm 0.64$} & 63.66 \scriptsize{$\pm 1.49 $} & 46.12 \scriptsize{$\pm 6.87 $} & 20.85 \scriptsize{$\pm 9.03 $} \\
    Dyn-Unc & 71.18 \scriptsize{$\pm 0.96$} & 67.06 \scriptsize{$\pm 0.94$} & 58.87 \scriptsize{$\pm 0.83$} & 31.57 \scriptsize{$\pm 3.29 $} \\
    CCS & 69.56 \scriptsize{$\pm 0.33$} & 65.26 \scriptsize{$\pm 0.50 $} & 57.60 \scriptsize{$\pm 0.80 $} & 23.92 \scriptsize{$\pm 1.85 $} \\
    \hline
    DUAL & \textbf{71.75 }\scriptsize{$\pm 0.16$} & \textbf{67.91} \scriptsize{$\pm 0.27$} & 59.08 \scriptsize{$\pm 0.64$} & 29.16 \scriptsize{$\pm 2.28 $} \\
    DUAL+$\beta$ sampling &  70.78 \scriptsize{$\pm 0.41 $} & 67.47  \scriptsize{$\pm 0.44 $} & \textbf{60.33} \scriptsize{$\pm 0.32 $} & \textbf{43.92} \scriptsize{$\pm 1.15 $} \\
    \hline
    \hline
    DUAL (V16$\rightarrow$V16) & 73.63 \scriptsize{$\pm 0.62$} & 69.66 \scriptsize{$\pm 0.45$} & 58.49 \scriptsize{$\pm 0.77$} & 32.96 \scriptsize{$\pm 1.12 $} \\
    DUAL (V16$\rightarrow$V16) +$\beta$ sampling & 72.77 \scriptsize{$\pm 0.41$} & 68.93 \scriptsize{$\pm 0.23$} & 61.48 \scriptsize{$\pm 0.36$} & 42.99\scriptsize{$\pm 0.62 $} \\
    \bottomrule
    \end{tabular}
    \label{tab:cnn-to-vgg16}
\end{table}


\begin{table}[ht]
\caption{Cross-architecture generalization performance on CIFAR-100 from VGG-16 to ResNet-18. We report an average of five runs. `R18 $\rightarrow$ R18' stands for score computation on ResNet-18, as a baseline.}
\label{tab:cross-arch-v19-r18}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lcccc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{4}{c}{VGG-16 $\rightarrow$ ResNet-18} \\
    \hline
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\% \\
    \hline
    Random & 75.15 \scriptsize{$\pm 0.28$} & 71.68 \scriptsize{$\pm 0.31 $} & 64.86 \scriptsize{$\pm 0.39$} & 45.09 \scriptsize{$\pm 1.26 $} \\
    EL2N & 76.42 \scriptsize{$\pm 0.27$} & 70.44 \scriptsize{$\pm 0.48 $} & 51.87 \scriptsize{$\pm 1.27 $} & 25.74 \scriptsize{$\pm 1.53 $} \\
    Dyn-Unc & \textbf{77.59}  \scriptsize{$\pm 0.19$} & 74.20 \scriptsize{$\pm 0.22 $} & 65.24 \scriptsize{$\pm 0.36 $} & 42.95 \scriptsize{$\pm 1.14$} \\
    CCS & 75.19 \scriptsize{$\pm 0.19$} & 71.56 \scriptsize{$\pm 0.28$} & 64.83 \scriptsize{$\pm 0.25$} & \textbf{46.08} \scriptsize{$\pm 1.23$} \\
    \hline 
    DUAL & 77.40 \scriptsize{$\pm 0.36$} & \textbf{74.29} \scriptsize{$\pm 0.12$} & 63.74 \scriptsize{$\pm 0.30$} & 36.87 \scriptsize{$\pm 2.27$} \\
    DUAL+ $\beta$ sampling & 76.67 \scriptsize{$\pm 0.15 $} & 73.14 \scriptsize{$\pm 0.29 $} & \textbf{65.69} \scriptsize{$\pm 0.57 $} & 45.95 \scriptsize{$\pm 0.52 $}  \\
    \hline
    \hline
    DUAL (R18$\rightarrow$R18) & 77.43 \scriptsize{$\pm 0.18$} & 74.62 \scriptsize{$\pm 0.47$} & 66.41 \scriptsize{$\pm 0.52 $} & 34.38 \scriptsize{$\pm 1.39 $} \\
    DUAL (R18$\rightarrow$R18) +$\beta$ sampling & 77.86 \scriptsize{$\pm 0.12$} & 74.66 \scriptsize{$\pm 0.12$} & 69.25 \scriptsize{$\pm 0.22$} & 54.54 \scriptsize{$\pm 0.09$} \\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[ht]
\caption{Cross-architecture generalization performance on CIFAR-100 from ResNet-18 to VGG-16. We report an average of five runs. `V16 $\rightarrow$ V16' stands for score computation on VGG-16, as a baseline.}
\centering
\begin{tabular}{lcccc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{4}{c}{ResNet-18 $\rightarrow$ VGG-16} \\
    \hline
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\% \\
    \hline
    Random & 70.99 \scriptsize{$\pm 0.33$} & 67.34 \scriptsize{$\pm 0.21$} & 60.18 \scriptsize{$\pm 0.52$} & 41.69 \scriptsize{$\pm 0.72 $} \\
    EL2N  & 72.43 \scriptsize{$\pm 0.54$} & 65.36 \scriptsize{$\pm 0.68$} & 43.35 \scriptsize{$\pm 0.81$} & 19.92 \scriptsize{$\pm 0.89 $} \\
    Dyn-Unc  & 73.34 \scriptsize{$\pm 0.29$} & 69.24 \scriptsize{$\pm 0.39$} & 57.67 \scriptsize{$\pm 0.52$} & 31.74 \scriptsize{$\pm 0.80 $} \\
    CCS  & 71.18 \scriptsize{$\pm 0.16$} & 67.35 \scriptsize{$\pm 0.38$} & 59.77 \scriptsize{$\pm 0.43$} & 41.06 \scriptsize{$\pm 1.03 $} \\
    \hline 
    DUAL & 73.44 \scriptsize{$\pm 0.29$} & 69.87 \scriptsize{$\pm 0.35 $} & 60.07 \scriptsize{$\pm 0.47 $} & 29.74 \scriptsize{$\pm 1.70 $} \\
    DUAL +$\beta$ sampling  &\textbf{73.50} \scriptsize{$\pm 0.27$} & \textbf{70.43} \scriptsize{$\pm 0.26$} & \textbf{64.48} \scriptsize{$\pm 0.47$} & \textbf{49.61} \scriptsize{$\pm 0.49 $} \\
    \hline
    \hline
    DUAL (V16$\rightarrow$V16)  & 73.63 \scriptsize{$\pm 0.61$} & 69.66 \scriptsize{$\pm 0.45$} & 58.49 \scriptsize{$\pm 0.77$} & 32.96 \scriptsize{$\pm 1.12 $} \\
    DUAL (V16$\rightarrow$V16)+$\beta$ sampling & 72.66 \scriptsize{$\pm 0.17 $} & 68.80 \scriptsize{$\pm 0.34 $} & 60.40 \scriptsize{$\pm 0.68 $} & 41.51 \scriptsize{$\pm 0.47 $} \\
    \bottomrule
\end{tabular}
\end{table}


\begin{table}[ht]
\caption{Cross-architecture generalization performance on CIFAR-100 from ResNet-18 to ResNet-50. We report an average of five runs. `R50 $\rightarrow$ R50' stands for score computation on ResNet-50, as a baseline.}
\label{tab:cross-arch-r18-r50}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lcccc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{4}{c}{ResNet-18 $\rightarrow$ ResNet-50} \\
    \hline
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\% \\
    \hline
    \hline
    Random & 74.47 \scriptsize{$\pm 0.67$} & 70.09 \scriptsize{$\pm 0.42$} & 60.06 \scriptsize{$\pm 0.99$} & 41.91 \scriptsize{$\pm 4.32 $} \\
    EL2N  & 76.42 \scriptsize{$\pm 1.00$} & 69.14 \scriptsize{$\pm 1.00$} & 45.16 \scriptsize{$\pm 3.21$} & 19.63 \scriptsize{$\pm 1.15 $} \\
    Dyn-Unc  & 77.31 \scriptsize{$\pm 0.34$} & 72.12 \scriptsize{$\pm 0.68$} & 59.38 \scriptsize{$\pm 2.35$} & 31.74 \scriptsize{$\pm 2.31 $} \\
    CCS  & 74.78 \scriptsize{$\pm 0.66$} & 69.98 \scriptsize{$\pm 1.18$} & 59.75 \scriptsize{$\pm 1.41$} & 41.54 \scriptsize{$\pm 3.94 $} \\
    \hline 
    DUAL   & \textbf{78.03} \scriptsize{$\pm 0.83$} & 72.82 \scriptsize{$\pm 1.46$} & 63.08 \scriptsize{$\pm 2.45$} & 33.65 \scriptsize{$\pm 2.92 $} \\
    DUAL +$\beta$ sampling  & 77.82 \scriptsize{$\pm 0.65$} & \textbf{73.98} \scriptsize{$\pm 0.62$} & \textbf{66.36} \scriptsize{$\pm 1.66$} & \textbf{49.90} \scriptsize{$\pm 2.56 $} \\
    \hline
    \hline
    DUAL (R50$\rightarrow$R50)  & 77.82 \scriptsize{$\pm 0.64$} & 73.66 \scriptsize{$\pm 0.85$} & 52.12 \scriptsize{$\pm 2.73 $} & 26.13 \scriptsize{$\pm 1.96 $} \\
    DUAL (R50$\rightarrow$R50)+$\beta$ sampling  & 77.57 \scriptsize{$\pm 0.23$} & 73.44 \scriptsize{$\pm 0.87$} & 65.17 \scriptsize{$\pm 0.96$} & 47.63 \scriptsize{$\pm 2.47 $} \\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\caption{Cross-architecture generalization performance on CIFAR-100 from VGG-16 to ResNet-50. We report an average of five runs. `R50 $\rightarrow$ R50' stands for score computation on ResNet-50, as a baseline}
\begin{tabular}{lcccc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{4}{c}{VGG-16 $\rightarrow$ ResNet-50} \\
    \hline
    Pruning Rate ($\rightarrow$) & 30\% & 50\% & 70\% & 90\% \\
    \hline
    \hline
    Random & 71.13 \scriptsize{$\pm 6.52$} & 70.31 \scriptsize{$\pm 1.20$} & 61.02 \scriptsize{$\pm 1.68$} & 41.03 \scriptsize{$\pm 3.74 $} \\
    EL2N  & 76.30 \scriptsize{$\pm 0.69$} & 67.11 \scriptsize{$\pm 3.09$} & 44.88 \scriptsize{$\pm 3.65$} & 25.05 \scriptsize{$\pm 1.76 $} \\
    Dyn-Unc  & \textbf{77.91} \scriptsize{$\pm 0.54$} & \textbf{73.52} \scriptsize{$\pm 0.41$} & 62.37 \scriptsize{$\pm 0.62$} & 39.10 \scriptsize{$\pm 4.04 $} \\
    CCS  & 75.40 \scriptsize{$\pm 0.64$} & 70.44 \scriptsize{$\pm 0.49$} & 60.10 \scriptsize{$\pm 1.24$} & 41.94 \scriptsize{$\pm 3.01 $} \\
    \hline 
    DUAL   & 77.50 \scriptsize{$\pm 0.53 $} & 71.81 \scriptsize{$\pm 0.48$} & 60.68 \scriptsize{$\pm 1.67$} & 34.88 \scriptsize{$\pm 3.47 $} \\
    DUAL +$\beta$ sampling  & 76.67 \scriptsize{$\pm 0.15 $} & 73.14 \scriptsize{$\pm 0.29 $} & \textbf{65.69} \scriptsize{$\pm 0.57 $} &\textbf{45.95} \scriptsize{$\pm 0.52 $} \\
    \hline
    \hline
    DUAL (R50$\rightarrow$R50)  & 77.82 \scriptsize{$\pm 0.64$} & 73.66 \scriptsize{$\pm 0.85$} & 52.12 \scriptsize{$\pm 2.73 $} & 26.13 \scriptsize{$\pm 1.96 $} \\
    DUAL (R50$\rightarrow$R50)+$\beta$ sampling  & 77.57 \scriptsize{$\pm 0.23$} & 73.44 \scriptsize{$\pm 0.87$} & 65.17 \scriptsize{$\pm 0.96$} & 47.63 \scriptsize{$\pm 2.47 $} \\
    \bottomrule
\end{tabular}
\end{table}

\clearpage

\subsection{Effectiveness of Beta Sampling}
\label{Appendix_beta_samapling}
We study the impact of our Beta sampling on existing score metrics. We apply our Beta sampling strategy to forgetting, EL2N, and Dyn-Unc scores of CIFAR10 and 100. By comparing Beta sampling with the vanilla threshold pruning using scores, we observe that prior score-based methods become competitive, outperforming random pruning when Beta sampling is adjusted.

\begin{table}[ht]
\caption{Comparison on CIFAR-10 and CIFAR-100 for $90\%$ pruning rate. 
We report average accuracy with five runs. The best performance is in bold in each column.}
\label{tab:abl_beta_cifar10_100_90}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lcc|cc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{2}{c|}{CIFAR-10} & \multicolumn{2}{c}{CIFAR-100}\\
    \midrule
    Method & Thresholding & $\beta$-Sampling & Thresholding & $\beta$-Sampling \\
    \midrule
    Random &  \textbf{83.74} \scriptsize{$\pm$ 0.21} & 83.31 (-0.43) \scriptsize{$\pm$ 0.14} & 45.09 \scriptsize{$\pm$ 1.26} & 51.76 (+6.67) \scriptsize{$\pm$ 0.25} \\
    EL2N &  38.74 \scriptsize{$\pm$ 0.75} & 87.00 (+48.26) \scriptsize{$\pm$ 0.45} & 8.89 \scriptsize{$\pm$ 0.28} & 53.97 (+45.08)  \scriptsize{$\pm$ 0.63}  \\
    Forgetting &  46.64 \scriptsize{$\pm$ 1.90} & 85.67 (+39.03) \scriptsize{$\pm$0.13} & 26.87 \scriptsize{$\pm$ 0.73} & 52.40 (+25.53) \scriptsize{$\pm$ 0.43} \\
    Dyn-Unc &  59.67 \scriptsize{$\pm$ 1.79} & 85.33 (+32.14) \scriptsize{$\pm$ 0.20} & 34.57 \scriptsize{$\pm$ 0.69} & 51.85 (+17.28) \scriptsize{$\pm$ 0.35}   \\
    \hline
    DUAL & 54.95 \scriptsize{$\pm$ 0.42} & \textbf{87.09} (+31.51) \scriptsize{$\pm$ 0.36} & 34.28 \scriptsize{$\pm$ 1.39}    & \textbf{54.54} (+20.26) \scriptsize{$\pm$ 0.09}  \\
    \bottomrule
\end{tabular}
\end{table}


\begin{table}[ht]
\caption{Comparison on CIFAR-10 and CIFAR-100 for $80\%$ pruning rate. 
We report average accuracy with five runs. The best performance is in bold in each column.}
\label{tab:abl_beta_cifar10_100_80}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lcc|cc}
    \toprule
    \multicolumn{1}{c}{} & \multicolumn{2}{c|}{CIFAR-10} & \multicolumn{2}{c}{CIFAR-100}\\
    \midrule
    Method & Thresholding & $\beta$-Sampling & Thresholding & $\beta$-Sampling \\
    \midrule
    Random &  \textbf{88.28} \scriptsize{$\pm$ 0.17} & 88.83 (+0.55) \scriptsize{$\pm$ 0.18} & \textbf{59.23} \scriptsize{$\pm$ 0.62} & 61.74 (+2.51) \scriptsize{$\pm$ 0.15} \\
    EL2N &  74.70 \scriptsize{$\pm$ 0.45} & 87.69 (+12.99) \scriptsize{$\pm$ 0.98} &19.52 \scriptsize{$\pm$ 0.79} & 63.98 (+44.46) \scriptsize{$\pm$ 0.73}  \\
    Forgetting &  75.47 \scriptsize{$\pm$ 1.27} & 90.86 (+15.39) \scriptsize{$\pm$ 0.07} & 39.09 \scriptsize{$\pm$ 0.41} & 63.29 (+24.20) \scriptsize{$\pm$ 0.13} \\
    Dyn-Unc &  83.32 \scriptsize{$\pm$ 0.94} & 90.80 (+7.48) \scriptsize{$\pm$ 0.30} & 55.01 \scriptsize{$\pm$ 0.55} & 62.31 (+7.30) \scriptsize{$\pm$ 0.23}  \\
    \hline
    DUAL & 82.02 \scriptsize{$\pm$ 1.85} & \textbf{91.42} (+9.68) \scriptsize{$\pm$ 0.35} & 56.57 \scriptsize{$\pm$ 0.57}    & \textbf{64.76} (+8.46) \scriptsize{$\pm$ 0.23} \\
    \bottomrule
\end{tabular}
\end{table}

We also study the impact of our pruning strategy with DUAL score combined with Beta sampling. We compare different sampling strategies $i.e.$ vanilla thresholding, stratified sampling \citep{zheng2022coverage}, and our proposed Beta sampling on CIFAR10 and 100, at 80\% and 90\% pruning rates. We observe that our proposed method mostly performs the best, especially with the high pruning ratio. 

\begin{table}[ht]
\centering
\caption{Comparison on Sampling Strategy}
\begin{tabular}{lccccc}
\toprule
\multicolumn{6}{c}{CIFAR10} \\ 
\cmidrule(lr){1-6}
Pruning Rate & $30\%$ & $50\%$ & $70\%$ & $80\%$ & $90\%$ \\
\midrule
DUAL & 95.35 & 95.08 & 91.95 & 81.74 & 55.58 \\
DUAL + CCS & \textbf{95.54} & 95.00 & 92.83 & 90.49 & 81.67 \\
DUAL + $\beta$ & 95.51 & \textbf{95.23} & \textbf{93.04} & \textbf{91.42} & \textbf{87.09} \\

\midrule 
\multicolumn{6}{c}{CIFAR100} \\ 
\cmidrule(lr){1-6}
Pruning Rate & $30\%$ & $50\%$ & $70\%$ & $80\%$ & $90\%$ \\
\midrule
DUAL & 77.61 & \textbf{74.86} & 66.39 & 56.50 & 34.28 \\
DUAL + CCS & 75.21 & 71.53 & 64.30 & 59.09 & 45.21 \\
DUAL + $\beta$ & \textbf{77.86} & 74.66 & \textbf{69.25} & \textbf{64.76} & \textbf{54.54} \\
\bottomrule
\end{tabular}
\label{tab:abl_ours_ccs}
\end{table}

