%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CIFAR-100 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
\caption{\label{tab:label_noise_20_cifar}Comparison of test accuracy of DUAL pruning with existing coreset selection methods under 20\% label noise using ResNet-18 for CIFAR-100. The model trained with the full dataset achieves \textbf{65.28\%} test accuracy on average. Results are averaged over five runs.}
\setlength{\tabcolsep}{3pt}
\centering
\begin{tabular}{lccccccc}
    \toprule
    \textbf{Pruning Rate} & \textbf{10\%} & \textbf{20\%} & \textbf{30\%} & \textbf{50\%} & \textbf{70\%} & \textbf{80\%} & \textbf{90\%} \\
    \midrule
    \textbf{Random} & 64.22 \scriptsize{$\pm 0.37 $} & 63.12 \scriptsize{$\pm 0.26 $} & 61.75 \scriptsize{$\pm 0.24 $} & 58.13 \scriptsize{$\pm 0.22 $} & 50.11 \scriptsize{$\pm 0.75 $} & 44.29 \scriptsize{$\pm 1.2 $} & 32.04 \scriptsize{$\pm 0.93 $} \\
    
    \textbf{Entropy} & 63.51 \scriptsize{$\pm 0.25 $} & 60.59 \scriptsize{$\pm 0.23 $} & 56.75 \scriptsize{$\pm 0.37 $} & 44.90 \scriptsize{$\pm 0.74 $} & 24.43 \scriptsize{$\pm 0.12 $} & 16.60 \scriptsize{$\pm 0.29$} & 10.35 \scriptsize{$\pm 0.49$}\\
    
    \textbf{Forgetting} & 64.29 \scriptsize{$\pm 0.26 $} & 63.40 \scriptsize{$\pm 0.14 $} & 64.00 \scriptsize{$\pm 0.27 $} & 67.51 \scriptsize{$\pm 0.52 $} & 59.29 \scriptsize{$\pm 0.66 $} & 50.11 \scriptsize{$\pm 0.91 $} & 32.08 \scriptsize{$\pm 1.15 $} \\
    
    \textbf{EL2N} & 64.51 \scriptsize{$\pm 0.35 $} & 62.67 \scriptsize{$\pm 0.28 $} & 59.85 \scriptsize{$\pm 0.31 $} & 46.94 \scriptsize{$\pm 0.75 $} & 19.32 \scriptsize{$\pm 0.87 $} & 11.02 \scriptsize{$\pm 0.45 $} & 6.83 \scriptsize{$\pm 0.21 $} \\
    
    \textbf{AUM} & 64.54 \scriptsize{$\pm 0.23$} & 60.72 \scriptsize{$\pm 0.22$} & 50.38 \scriptsize{$\pm 0.66$} & 22.03 \scriptsize{$\pm 0.92$}& 5.55 \scriptsize{$\pm 0.26 $} & 3.00 \scriptsize{$\pm 0.18 $} & 1.68 \scriptsize{$\pm 0.10$}\\
    
    \textbf{Moderate} & 64.45 \scriptsize{$\pm 0.29 $} & 62.90 \scriptsize{$\pm 0.33 $} & 61.46 \scriptsize{$\pm 0.50 $} & 57.53 \scriptsize{$\pm 0.61 $} & 49.50 \scriptsize{$\pm 1.06 $} & 43.81 \scriptsize{$\pm 0.80 $} & 29.15 \scriptsize{$\pm 0.79 $}  \\
    
    \textbf{Dyn-Unc} & 68.17 \scriptsize{$\pm 0.26 $} & 71.56 \scriptsize{$\pm 0.27 $} & 74.12 \scriptsize{$\pm 0.15 $} & \textbf{73.43} \scriptsize{$\pm 0.12 $} & 67.21 \scriptsize{$\pm 0.27 $} & 61.38 \scriptsize{$\pm 0.27 $} & \underline{48.00} \scriptsize{$\pm 0.79 $} \\
    
    \textbf{TDDS} & 62.86 \scriptsize{$\pm 0.36 $} & 61.96 \scriptsize{$\pm 1.03 $} & 61.38 \scriptsize{$\pm 0.53 $} & 59.16 \scriptsize{$\pm 0.94 $} & 48.93 \scriptsize{$\pm 1.68 $} & 43.83  \scriptsize{$\pm 1.13 $} & 34.05 \scriptsize{$\pm 0.49 $} \\
    
    \textbf{CCS} & 64.30 \scriptsize{$\pm 0.21 $} & 63.24 \scriptsize{$\pm 0.24 $} & 61.91 \scriptsize{$\pm 0.45 $} & 58.24 \scriptsize{$\pm 0.29 $} & 50.24 \scriptsize{$\pm 0.39 $} & 43.76 \scriptsize{$\pm 1.07 $} & 30.67  \scriptsize{$\pm 0.96 $} \\
    
    \midrule
    
    \textbf{DUAL} & \underline{69.78} \scriptsize{$\pm 0.28 $} & \textbf{74.79} \scriptsize{$\pm 0.07 $} & \textbf{75.40} \scriptsize{$\pm 0.11 $} & \textbf{73.43} \scriptsize{$\pm 0.16 $} & \underline{67.57} \scriptsize{$\pm 0.18 $} & \underline{61.46} \scriptsize{$\pm 0.45 $} & 43.30 \scriptsize{$\pm 1.59 $} \\
    
    \textbf{DUAL+$\beta$} & \textbf{69.95} \scriptsize{$\pm 0.60 $} & \underline{74.68} \scriptsize{$\pm 1.22 $} & \underline{75.37} \scriptsize{$\pm 1.33 $} & \underline{73.29} \scriptsize{$\pm 0.84 $} & \textbf{68.43} \scriptsize{$\pm 0.77 $} & \textbf{63.74} \scriptsize{$\pm 0.35 $} & \textbf{54.04} \scriptsize{$\pm 0.92 $} \\
    
    \bottomrule
\end{tabular}
\end{table}





\begin{table}[ht]
\caption{\label{tab:label_noise_30_cifar}Comparison of test accuracy of DUAL pruning with existing coreset selection methods under 30\% label noise using ResNet-18 for CIFAR-100. The model trained with the full dataset achieves \textbf{58.25\%} test accuracy on average. Results are averaged over five runs.}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lccccccc}
    \toprule
    \textbf{Pruning Rate} & \textbf{10\%} & \textbf{20\%} & \textbf{30\%} & \textbf{50\%} & \textbf{70\%} & \textbf{80\%} & \textbf{90\%} \\
    \midrule
    \textbf{Random} & 57.67 \scriptsize{$\pm 0.52 $} & 56.29 \scriptsize{$\pm 0.55 $} & 54.70 \scriptsize{$\pm 0.60 $} & 51.41 \scriptsize{$\pm 0.38 $} & 42.67 \scriptsize{$\pm 0.80 $} & 36.86 \scriptsize{$\pm 1.01 $} & 25.64 \scriptsize{$\pm 0.82 $} \\
    
    \textbf{Entropy} & 55.51 \scriptsize{$\pm 0.42 $} & 51.87 \scriptsize{$\pm 0.36 $} & 47.16 \scriptsize{$\pm 0.58 $} & 35.35 \scriptsize{$\pm 0.49 $} & 18.69 \scriptsize{$\pm 0.76 $} & 13.61 \scriptsize{$\pm 0.42$} & 8.58 \scriptsize{$\pm 0.49$}\\
    
    \textbf{Forgetting} & 56.76 \scriptsize{$\pm 0.62 $} & 56.43 \scriptsize{$\pm 0.28 $} & 58.84 \scriptsize{$\pm 0.26 $} & 64.51 \scriptsize{$\pm 0.37 $} & 61.26 \scriptsize{$\pm 0.69 $} & 52.94 \scriptsize{$\pm 0.68 $} & 34.99 \scriptsize{$\pm 1.16 $} \\
    
    \textbf{EL2N} & 56.39 \scriptsize{$\pm 0.53 $} & 54.41 \scriptsize{$\pm 0.68 $} & 50.29 \scriptsize{$\pm 0.40 $} & 35.65 \scriptsize{$\pm 0.79 $} & 13.05 \scriptsize{$\pm 0.51 $} & 8.52 \scriptsize{$\pm 0.40 $} & 6.16 \scriptsize{$\pm 0.40 $} \\
    
    \textbf{AUM} & 56.51 \scriptsize{$\pm 0.56$} & 49.10 \scriptsize{$\pm 0.72$} & 37.57 \scriptsize{$\pm 0.66$} & 11.56 \scriptsize{$\pm 0.46$}& 2.79 \scriptsize{$\pm 0.23 $} & 1.87 \scriptsize{$\pm 0.24 $} & 1.43 \scriptsize{$\pm 0.12$}\\
    
    \textbf{Moderate} & 57.31 \scriptsize{$\pm 0.75 $} & 56.11 \scriptsize{$\pm 0.45 $} & 54.52 \scriptsize{$\pm 0.48 $} & 50.71 \scriptsize{$\pm 0.42 $} & 42.47 \scriptsize{$\pm 0.29 $} & 36.21 \scriptsize{$\pm 1.09 $} & 24.85 \scriptsize{$\pm 1.72$}  \\
    
    \textbf{Dyn-Unc} & 62.20 \scriptsize{$\pm 0.44$} & \underline{66.48} \scriptsize{$\pm 0.40 $} & 70.45 \scriptsize{$\pm 0.50 $} & \textbf{71.91} \scriptsize{$\pm 0.34 $} & \underline{66.53} \scriptsize{$\pm 0.19$} & \underline{61.95} \scriptsize{$\pm 0.46 $} & \underline{49.51} \scriptsize{$\pm 0.52$} \\
    
    \textbf{TDDS} & 57.24 \scriptsize{$\pm 0.44 $} & 55.64 \scriptsize{$\pm 0.46 $} & 53.97 \scriptsize{$\pm 0.46 $} & 49.04 \scriptsize{$\pm 1.05 $} & 39.90 \scriptsize{$\pm 1.21$} & 35.02 \scriptsize{$\pm 1.34 $} & 26.99 \scriptsize{$\pm 1.03$} \\
    
    \textbf{CCS} & 57.26 \scriptsize{$\pm 0.48 $} & 56.52 \scriptsize{$\pm 0.23 $} & 54.76 \scriptsize{$\pm 0.52 $} & 51.29 \scriptsize{$\pm 0.32 $} & 42.33 \scriptsize{$\pm 0.78 $} & 36.61 \scriptsize{$\pm 1.31 $} & 25.64 \scriptsize{$\pm 1.65 $} \\
    
    \midrule
    
    \textbf{DUAL} & \underline{62.42} \scriptsize{$\pm 0.48 $} & \textbf{67.52} \scriptsize{$\pm 0.40 $} & \textbf{72.65} \scriptsize{$\pm 0.17 $} & 71.55 \scriptsize{$\pm 0.23 $} & 66.35 \scriptsize{$\pm 0.14 $} & 61.57 \scriptsize{$\pm 0.44 $} & 48.70 \scriptsize{$\pm 0.19 $} \\
    
    \textbf{DUAL+$\beta$} & \textbf{63.02} \scriptsize{$\pm 0.41 $} & \textbf{67.52} \scriptsize{$\pm 0.24 $} & \underline{72.57} \scriptsize{$\pm 0.15 $} & \underline{71.68} \scriptsize{$\pm 0.27 $} & \textbf{66.75} \scriptsize{$\pm 0.45 $} & \textbf{62.28} \scriptsize{$\pm 0.43 $} & \textbf{52.60} \scriptsize{$\pm 0.87 $} \\
    
    \bottomrule
\end{tabular}
\end{table}




\begin{table}[ht]
\caption{\label{tab:label_noise_40_cifar}Comparison of test accuracy of DUAL pruning with existing coreset selection methods under 40\% label noise using ResNet-18 for CIFAR-100. The model trained with the full dataset achieves \textbf{52.74\%} test accuracy on average. Results are averaged over five runs.}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lccccccc}
    \toprule
    \textbf{Pruning Rate} & \textbf{10\%} & \textbf{20\%} & \textbf{30\%} & \textbf{50\%} & \textbf{70\%} & \textbf{80\%} & \textbf{90\%} \\
    \midrule
    \textbf{Random} & 51.13 \scriptsize{$\pm 0.71 $} & 48.42 \scriptsize{$\pm 0.46 $} & 46.99 \scriptsize{$\pm 0.29 $} & 43.24 \scriptsize{$\pm 0.46 $} & 33.60 \scriptsize{$\pm 0.50 $} & 28.28 \scriptsize{$\pm 0.81 $} & 19.52 \scriptsize{$\pm 0.79 $} \\
    
    \textbf{Entropy} & 49.14 \scriptsize{$\pm 0.32 $} & 46.06 \scriptsize{$\pm 0.58 $} & 41.83 \scriptsize{$\pm 0.73 $} & 28.26 \scriptsize{$\pm 0.37 $} & 15.64  \scriptsize{$\pm 0.19 $} & 12.21 \scriptsize{$\pm 0.68 $} & 8.23 \scriptsize{$\pm 0.40 $}\\
    
    \textbf{Forgetting} & 50.98 \scriptsize{$\pm 0.72 $} & 50.36 \scriptsize{$\pm 0.48 $} & 52.86 \scriptsize{$\pm 0.47 $} & 60.48 \scriptsize{$\pm 0.68 $} & 61.55 \scriptsize{$\pm 0.58 $} & 54.57 \scriptsize{$\pm 0.86 $} & 37.68 \scriptsize{$\pm 1.63 $} \\
    
    \textbf{EL2N} & 50.09 \scriptsize{$\pm 0.86 $} & 46.35 \scriptsize{$\pm 0.48 $} & 41.57 \scriptsize{$\pm 0.26 $} & 23.42 \scriptsize{$\pm 0.80 $} & 9.00 \scriptsize{$\pm 0.25 $} & 6.80 \scriptsize{$\pm 0.44 $} & 5.58 \scriptsize{$\pm 0.40$} \\
    
    \textbf{AUM} & 50.60 \scriptsize{$\pm 0.54 $} & 41.84 \scriptsize{$\pm 0.76 $} & 26.29 \scriptsize{$\pm 0.72 $} & 5.49 \scriptsize{$\pm 0.19 $} & 1.95 \scriptsize{$\pm 0.21 $} & 1.44 \scriptsize{$\pm 0.14 $ } & 1.43 \scriptsize{$\pm 0.24 $}\\
    
    \textbf{Moderate} & 50.62 \scriptsize{$\pm 0.27 $} & 48.70 \scriptsize{$\pm 0.79 $} & 47.01  \scriptsize{$\pm 0.21 $} & 42.73 \scriptsize{$\pm 0.39 $} & 32.35 \scriptsize{$\pm 1.29 $} & 27.72 \scriptsize{$\pm 1.69 $} & 19.85 \scriptsize{$\pm 1.11 $}  \\
    
    \textbf{Dyn-Unc} & \underline{54.46} \scriptsize{$\pm 0.27$} & \underline{59.02} \scriptsize{$\pm 0.23 $} & 63.86 \scriptsize{$\pm 0.47 $} & \underline{69.76} \scriptsize{$\pm 0.16 $} & \textbf{65.36} \scriptsize{$\pm 0.14$} & \underline{61.37} \scriptsize{$\pm 0.32 $} & \underline{50.49} \scriptsize{$\pm 0.71$} \\
    
    \textbf{TDDS} & 50.65 \scriptsize{$\pm 0.23 $} & 48.83 \scriptsize{$\pm 0.38 $} & 46.93 \scriptsize{$\pm 0.66 $} &  41.85 \scriptsize{$\pm 0.37 $} & 33.31 \scriptsize{$\pm 0.79 $} & 29.39 \scriptsize{$\pm 0.35 $} & 21.09 \scriptsize{$\pm 0.89 $} \\
    
    \textbf{CCS} & 64.30 \scriptsize{$\pm 0.29 $} & 48.54 \scriptsize{$\pm 0.35 $} & 46.81 \scriptsize{$\pm 0.45 $} & 42.57 \scriptsize{$\pm 0.32 $} & 33.19 \scriptsize{$\pm 0.88 $} & 28.32 \scriptsize{$\pm 0.59 $} & 19.61 \scriptsize{$\pm 0.75 $} \\
    
    \midrule
    
    \textbf{DUAL} & \underline{54.46} \scriptsize{$\pm 0.33 $} & 58.99 \scriptsize{$\pm 0.34 $} & \textbf{64.71} \scriptsize{$\pm 0.44 $} & \underline{69.87} \scriptsize{$\pm 0.28 $} & 64.21 \scriptsize{$\pm 0.21 $} & 59.90 \scriptsize{$\pm 0.44 $} & 49.61 \scriptsize{$\pm 0.27 $} \\
    
    \textbf{DUAL+$\beta$} & \textbf{54.53} \scriptsize{$\pm 0.06 $} & \textbf{59.65} \scriptsize{$\pm 0.41 $} & \underline{64.67} \scriptsize{$\pm 0.34 $} & \textbf{70.09} \scriptsize{$\pm 0.33 $} & \underline{65.12} \scriptsize{$\pm 0.46$} & \underline{60.62} \scriptsize{$\pm 0.30 $} & \textbf{51.51} \scriptsize{$\pm 0.41 $} \\
    
    \bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%% Tiny ImageNet %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
\caption{\label{tab:label_noise_20_tinyimagenet}Comparison of test accuracy of DUAL pruning with existing coreset selection methods under 20\% label noise using ResNet-34 for Tiny-ImageNet. The model trained with the full dataset achieves \textbf{42.24\%} test accuracy on average. Results are averaged over three runs.}
\setlength{\tabcolsep}{3.1pt}
\centering
\begin{tabular}{lccccccc}
    \toprule
    \textbf{Pruning Rate} & \textbf{10\%} & \textbf{20\%} & \textbf{30\%} & \textbf{50\%} & \textbf{70\%} & \textbf{80\%} & \textbf{90\%} \\
    \midrule
    \textbf{Random} & 41.09 \scriptsize{$\pm 0.29 $} & 39.24 \scriptsize{$\pm 0.39 $} & 37.17 \scriptsize{$\pm 0.23 $} & 32.93 \scriptsize{$\pm 0.45 $} & 26.12 \scriptsize{$\pm 0.63 $} & 22.11 \scriptsize{$\pm 0.42 $} & 13.88 \scriptsize{$\pm 0.60 $} \\
    
    \textbf{Entropy} & 40.69 \scriptsize{$\pm 0.06 $} & 38.14 \scriptsize{$\pm 0.92 $} & 35.93 \scriptsize{$\pm 1.56 $} & 31.24 \scriptsize{$\pm 1.76 $} & 23.65 \scriptsize{$\pm 2.05 $} & 18.53 \scriptsize{$\pm 2.10 $} & 10.52 \scriptsize{$\pm 1.64 $} \\
    
    \textbf{Forgetting} & 43.60 \scriptsize{$\pm 0.65 $} & 44.82 \scriptsize{$\pm 0.20 $} & 45.65 \scriptsize{$\pm 0.48 $} & 46.05 \scriptsize{$\pm 0.07 $} & 41.08 \scriptsize{$\pm 0.53 $} & 34.89 \scriptsize{$\pm 0.12 $} & 24.58 \scriptsize{$\pm 0.06 $} \\
    
    \textbf{EL2N} & 41.05 \scriptsize{$\pm 0.35 $} & 38.88 \scriptsize{$\pm 0.63 $} & 32.91 \scriptsize{$\pm 0.39 $} & 20.89 \scriptsize{$\pm 0.80 $} & 8.08 \scriptsize{$\pm 0.24 $} & 4.92  \scriptsize{$\pm 0.32 $} & 3.12 \scriptsize{$\pm 0.07 $} \\
    
    \textbf{AUM} & 40.20 \scriptsize{$\pm 0.27$} & 34.68 \scriptsize{$\pm 0.35 $} & 29.01 \scriptsize{$\pm 0.12$} & 10.45 \scriptsize{$\pm 0.85 $} & 2.52 \scriptsize{$\pm 0.75 $} & 1.30 \scriptsize{$\pm 0.23 $} & 0.79 \scriptsize{$\pm 0.40 $} \\
    
    \textbf{Moderate} & 41.23 \scriptsize{$\pm 0.38 $} & 38.58 \scriptsize{$\pm 0.60 $} & 37.60 \scriptsize{$\pm 0.66 $} & 32.65 \scriptsize{$\pm 1.18 $} & 25.68 \scriptsize{$\pm 0.40 $} & 21.74 \scriptsize{$\pm 0.63 $} & 14.15 \scriptsize{$\pm 0.73 $}  \\
    
    \textbf{Dyn-Unc} & \underline{45.67} \scriptsize{$\pm 0.78  $} & 47.49 \scriptsize{$\pm 0.46 $} & \underline{49.38} \scriptsize{$\pm 0.17 $} & \underline{47.47} \scriptsize{$\pm 0.32 $} & 42.49 \scriptsize{$\pm 0.39$} & 37.44 \scriptsize{$\pm 0.73 $} & \underline{28.48} \scriptsize{$\pm 0.73 $} \\
    
    \textbf{TDDS} & 36.56 \scriptsize{$\pm 0.54$} & 36.90 \scriptsize{$\pm 0.48 $} & 47.62 \scriptsize{$\pm 1.36$} & 42.44 \scriptsize{$\pm 0.63$} & 34.32 \scriptsize{$\pm 0.26$}& 24.32 \scriptsize{$\pm 0.26 $} & 17.43 \scriptsize{$\pm 0.17$}  \\
    
    \textbf{CCS} & 40.49 \scriptsize{$\pm 0.67 $} & 39.06 \scriptsize{$\pm 0.24 $} & 37.67 \scriptsize{$\pm 0.46$} & 30.83 \scriptsize{$\pm 1.02$} & 22.38 \scriptsize{$\pm 0.70 $} & 19.66 \scriptsize{$\pm 0.58$} & 12.23 \scriptsize{$\pm 0.64$} \\
    
    \midrule
    
    \textbf{DUAL} & \textbf{45.76} \scriptsize{$\pm 0.67 $} & \textbf{48.20} \scriptsize{$\pm 0.20 $} & \textbf{49.94} \scriptsize{$\pm 0.17 $} & \textbf{48.19} \scriptsize{$\pm 0.27$} & \underline{42.80} \scriptsize{$\pm 0.74 $} & \textbf{37.90} \scriptsize{$\pm 0.59$} & 27.80 \scriptsize{$\pm 0.49 $} \\
    
    \textbf{DUAL+$\beta$} & 45.21  \scriptsize{$\pm 0.08$} & \underline{47.76} \scriptsize{$\pm 0.33$} & 48.99 \scriptsize{$\pm 0.32 $} & 46.95 \scriptsize{$\pm 0.23 $} & \textbf{43.01} \scriptsize{$\pm 0.43$} & \textbf{37.91} \scriptsize{$\pm 0.28 $} & \textbf{28.78} \scriptsize{$\pm 0.57$} \\
    
    \bottomrule
\end{tabular}

\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

