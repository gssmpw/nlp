\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

% Custom added
\usepackage{multirow}
\usepackage{url}
\usepackage{hyperref}

\begin{document}

\title{LISArD: Learning Image Similarity to Defend Against Gray-box Adversarial Attacks}

\author{Joana C. Costa,
        Tiago Roxo,
        Hugo Proença,~\IEEEmembership{Senior Member,~IEEE,}
        Pedro R. M. Inácio,~\IEEEmembership{Senior Member,~IEEE}
        % <-this % stops a space
\thanks{Manuscript received February XX, 2025; revised XX XX, 2025. This work was supported in part by the Portuguese Fundação para a Ciência e Tecnologia (FCT)/Ministério da Ciência, Tecnologia e Ensino Superior (MCTES) through National Funds and co-funded by EU funds under Project UIDB/50008/2020; in part by the FCT Doctoral Grant 2020.09847.BD and Grant 2021.04905.BD.}% <-this % stops a space
\thanks{Joana C. Costa, Tiago Roxo, Hugo Proença and Pedro R. M. Inácio are with the Instituto de Telecomunicações, sins-lab, and Department of Computer Science, Universidade da Beira Interior, Portugal (corresponding author e-mail: \href{mailto:joana.cabral.costa@ubi.pt}{joana.cabral.costa@ubi.pt}).}}

% The paper headers
\markboth{Submitted to IEEE Transactions on Information Forensics and Security, Vol. XX, XXXX}%
{Costa \MakeLowercase{\textit{et al.}}: LISArD: Learning Image Similarity to Defend Against Gray-box Adversarial Attacks}

\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\input{article/abstract}

\input{article/intro}
\input{article/rel_work}
\input{article/proposed_model}
\input{article/experiments}
\input{article/conclusion_fut_dir}


% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{thirunavukarasu2023large}
A.~J. Thirunavukarasu, D.~S.~J. Ting, K.~Elangovan, L.~Gutierrez, T.~F. Tan, and D.~S.~W. Ting, ``Large language models in medicine,'' \emph{Nature medicine}, vol.~29, no.~8, pp. 1930--1940, 2023.

\bibitem{patricio2023coherent}
C.~Patr{\'\i}cio, J.~C. Neves, and L.~F. Teixeira, ``Coherent concept-based explanations in medical image and its application to skin lesion diagnosis,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 3799--3808.

\bibitem{touvron2023llama2openfoundation}
\BIBentryALTinterwordspacing
H.~Touvron and et~al., ``Llama 2: Open foundation and fine-tuned chat models,'' 2023. [Online]. Available: \url{https://arxiv.org/abs/2307.09288}
\BIBentrySTDinterwordspacing

\bibitem{costa2022predicting}
J.~C. Costa, T.~Roxo, J.~B. Sequeiros, H.~Proenca, and P.~R. Inacio, ``Predicting cvss metric via description interpretation,'' \emph{IEEE Access}, vol.~10, pp. 59\,125--59\,134, 2022.

\bibitem{roxo2023exploring}
T.~Roxo, J.~C. Costa, P.~R. In{\'a}cio, and H.~Proen{\c{c}}a, ``On exploring audio anomaly in speech,'' in \emph{2023 IEEE International Workshop on Information Forensics and Security (WIFS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--6.

\bibitem{roxo2024bias}
------, ``Bias: A body-based interpretable active speaker approach,'' \emph{IEEE Transactions on Biometrics, Behavior, and Identity Science}, 2024.

\bibitem{roxo2024asdnb}
T.~Roxo, J.~C. Costa, P.~In{\'a}cio, and H.~Proen{\c{c}}a, ``Asdnb: Merging face with body cues for robust active speaker detection,'' \emph{arXiv preprint arXiv:2412.08594}, 2024.

\bibitem{szegedy2014intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and R.~Fergus, ``Intriguing properties of neural networks,'' in \emph{2nd International Conference on Learning Representations, ICLR 2014}, 2014.

\bibitem{papernot2016distillation}
N.~Papernot, P.~McDaniel, X.~Wu, S.~Jha, and A.~Swami, ``Distillation as a defense to adversarial perturbations against deep neural networks,'' in \emph{2016 IEEE symposium on security and privacy (SP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 582--597.

\bibitem{goldblum2020adversarially}
M.~Goldblum, L.~Fowl, S.~Feizi, and T.~Goldstein, ``Adversarially robust distillation,'' in \emph{Proceedings of the AAAI conference on artificial intelligence}, vol.~34, no.~04, 2020, pp. 3996--4003.

\bibitem{zhu2021reliable}
J.~Zhu, J.~Yao, B.~Han, J.~Zhang, T.~Liu, G.~Niu, J.~Zhou, J.~Xu, and H.~Yang, ``Reliable adversarial distillation with unreliable teachers,'' in \emph{International Conference on Learning Representations}, 2021.

\bibitem{yoon2021adversarial}
J.~Yoon, S.~J. Hwang, and J.~Lee, ``Adversarial purification with score-based generative models,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 12\,062--12\,072.

\bibitem{wu2022guided}
Q.~Wu, H.~Ye, and Y.~Gu, ``Guided diffusion model for adversarial purification from random noise,'' \emph{arXiv preprint arXiv:2206.10875}, 2022.

\bibitem{chen2022densepure}
Z.~Chen, K.~Jin, J.~Wang, W.~Nie, M.~Liu, A.~Anandkumar, B.~Li, and D.~Song, ``Densepure: Understanding diffusion models towards adversarial robustness,'' in \emph{Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS 2022}, 2022.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,'' \emph{Advances in neural information processing systems}, vol.~33, pp. 6840--6851, 2020.

\bibitem{katzir2020gradients}
Z.~Katzir and Y.~Elovici, ``Gradients cannot be tamed: Behind the impossible paradox of blocking targeted adversarial attacks,'' \emph{IEEE Transactions on Neural Networks and Learning Systems}, vol.~32, no.~1, pp. 128--138, 2020.

\bibitem{goodfellow2015explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy, ``Explaining and harnessing adversarial examples,'' \emph{stat}, vol. 1050, p.~20, 2015.

\bibitem{papernot2016limitations}
N.~Papernot, P.~McDaniel, S.~Jha, M.~Fredrikson, Z.~B. Celik, and A.~Swami, ``The limitations of deep learning in adversarial settings,'' in \emph{2016 IEEE European symposium on security and privacy (EuroS\&P)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 372--387.

\bibitem{tramer2017space}
F.~Tram{\`e}r, N.~Papernot, I.~Goodfellow, D.~Boneh, and P.~McDaniel, ``The space of transferable adversarial examples,'' \emph{stat}, vol. 1050, p.~23, 2017.

\bibitem{croce2019sparse}
F.~Croce and M.~Hein, ``Sparse and imperceivable adversarial attacks,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2019, pp. 4724--4732.

\bibitem{moosavi2016deepfool}
S.-M. Moosavi-Dezfooli, A.~Fawzi, and P.~Frossard, ``Deepfool: a simple and accurate method to fool deep neural networks,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 2574--2582.

\bibitem{dabouei2020smoothfool}
A.~Dabouei, S.~Soleymani, F.~Taherkhani, J.~Dawson, and N.~Nasrabadi, ``Smoothfool: An efficient framework for computing smooth adversarial perturbations,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2020, pp. 2665--2674.

\bibitem{madry2018towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu, ``Towards deep learning models resistant to adversarial attacks,'' in \emph{International Conference on Learning Representations}, 2018.

\bibitem{dong2018boosting}
Y.~Dong, F.~Liao, T.~Pang, H.~Su, J.~Zhu, X.~Hu, and J.~Li, ``Boosting adversarial attacks with momentum,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 9185--9193.

\bibitem{croce2020reliable}
F.~Croce and M.~Hein, ``Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 2206--2216.

\bibitem{croce2020minimally}
------, ``Minimally distorted adversarial examples with a fast adaptive boundary attack,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 2196--2205.

\bibitem{andriushchenko2020square}
M.~Andriushchenko, F.~Croce, N.~Flammarion, and M.~Hein, ``Square attack: a query-efficient black-box adversarial attack via random search,'' in \emph{European conference on computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 484--501.

\bibitem{papernot2017extending}
N.~Papernot and P.~McDaniel, ``Extending defensive distillation,'' \emph{arXiv preprint arXiv:1705.05264}, 2017.

\bibitem{carmon2019unlabeled}
Y.~Carmon, A.~Raghunathan, L.~Schmidt, J.~C. Duchi, and P.~S. Liang, ``Unlabeled data improves adversarial robustness,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{zi2021revisiting}
B.~Zi, S.~Zhao, X.~Ma, and Y.-G. Jiang, ``Revisiting adversarial robustness distillation: Robust soft labels make student better,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 16\,443--16\,452.

\bibitem{chen2021ltd}
E.-C. Chen and C.-R. Lee, ``Ltd: Low temperature distillation for robust adversarial training,'' \emph{arXiv preprint arXiv:2111.02331}, 2021.

\bibitem{zhu2023improving}
K.~Zhu, X.~Hu, J.~Wang, X.~Xie, and G.~Yang, ``Improving generalization of adversarial training via robust critical fine-tuning,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 4424--4434.

\bibitem{huang2023boosting}
B.~Huang, M.~Chen, Y.~Wang, J.~Lu, M.~Cheng, and W.~Wang, ``Boosting accuracy and robustness of student models via adaptive adversarial distillation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 24\,668--24\,677.

\bibitem{kuang2024improving}
H.~Kuang, H.~Liu, Y.~Wu, S.~Satoh, and R.~Ji, ``Improving adversarial robustness via information bottleneck distillation,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{yue2024revisiting}
X.~Yue, M.~Ningping, Q.~Wang, and L.~Zhao, ``Revisiting adversarial robustness distillation from the perspective of robust fairness,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{jung2024peeraid}
J.~Jung, H.~Jang, J.~Song, and J.~Lee, ``Peeraid: Improving adversarial distillation from a specialized peer tutor,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 24\,482--24\,491.

\bibitem{park2025dynamic}
H.~Park and D.~Min, ``Dynamic guidance adversarial distillation with enhanced teacher knowledge,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2025, pp. 204--219.

\bibitem{nie2022diffusion}
W.~Nie, B.~Guo, Y.~Huang, C.~Xiao, A.~Vahdat, and A.~Anandkumar, ``Diffusion models for adversarial purification,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp. 16\,805--16\,827.

\bibitem{kalaria2022towards}
D.~Kalaria, A.~Hazra, and P.~P. Chakrabarti, ``Towards adversarial purification using denoising autoencoders,'' \emph{arXiv preprint arXiv:2208.13838}, 2022.

\bibitem{vincent2008extracting}
P.~Vincent, H.~Larochelle, Y.~Bengio, and P.-A. Manzagol, ``Extracting and composing robust features with denoising autoencoders,'' in \emph{Proceedings of the 25th international conference on Machine learning}, 2008, pp. 1096--1103.

\bibitem{wang2023better}
Z.~Wang, T.~Pang, C.~Du, M.~Lin, W.~Liu, and S.~Yan, ``Better diffusion models further improve adversarial training,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 36\,246--36\,263.

\bibitem{karras2022elucidating}
T.~Karras, M.~Aittala, T.~Aila, and S.~Laine, ``Elucidating the design space of diffusion-based generative models,'' \emph{Advances in neural information processing systems}, vol.~35, pp. 26\,565--26\,577, 2022.

\bibitem{lee2023robust}
M.~Lee and D.~Kim, ``Robust evaluation of diffusion-based adversarial purification,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 134--144.

\bibitem{cao2023fepn}
D.~Cao, K.~Wei, Y.~Wu, J.~Zhang, B.~Feng, and J.~Chen, ``Fepn: A robust feature purification network to defend against adversarial examples,'' \emph{Computers \& Security}, vol. 134, p. 103427, 2023.

\bibitem{chen2024diffilter}
Y.~Chen, X.~Li, X.~Wang, P.~Hu, and D.~Peng, ``Diffilter: Defending against adversarial perturbations with diffusion filter,'' \emph{IEEE Transactions on Information Forensics and Security}, 2024.

\bibitem{zhang2024random}
J.~Zhang, P.~Dong, Y.~Chen, Y.-P. Zhao, and S.~Guo, ``Random sampling for diffusion-based adversarial purification,'' \emph{arXiv preprint arXiv:2411.18956}, 2024.

\bibitem{song2024mimicdiffusion}
K.~Song, H.~Lai, Y.~Pan, and J.~Yin, ``Mimicdiffusion: Purifying adversarial perturbation via mimicking clean diffusion model,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 24\,665--24\,674.

\bibitem{zbontar2021barlow}
J.~Zbontar, L.~Jing, I.~Misra, Y.~LeCun, and S.~Deny, ``Barlow twins: Self-supervised learning via redundancy reduction,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 12\,310--12\,320.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 770--778.

\bibitem{zagoruyko2016wide}
S.~Zagoruyko, ``Wide residual networks,'' \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{sandler2018mobilenetv2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, and L.-C. Chen, ``Mobilenetv2: Inverted residuals and linear bottlenecks,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 4510--4520.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le, ``Efficientnet: Rethinking model scaling for convolutional neural networks,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 6105--6114.

\bibitem{szegedy2016rethinking}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna, ``Rethinking the inception architecture for computer vision,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 2818--2826.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton \emph{et~al.}, ``Learning multiple layers of features from tiny images,'' \emph{Master's thesis, University of Tront}, 2009.

\bibitem{le2015tiny}
Y.~Le and X.~Yang, ``Tiny imagenet visual recognition challenge,'' \emph{CS 231N}, vol.~7, no.~7, p.~3, 2015.

\bibitem{daugman2000biometric}
J.~Daugman, ``Biometric decision landscapes,'' University of Cambridge, Computer Laboratory, Tech. Rep., 2000.
\end{thebibliography}



\input{article/biographies}
\vfill

\end{document}


