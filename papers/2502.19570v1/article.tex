%% 
%% Copyright 2007-2019 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%% 
%%
%% $Id: article.tex,v 1.1 2025/02/26 21:23:36 vdgnguyen Exp $
%%
%%
\documentclass[preprint,review,12pt,sort&compress]{elsarticle}


%%\documentclass[preprint,12pt,3p,authoryear,compress]{elsarticle}
%%\documentclass[preprint,3p,compress]{elsarticle}

%% Use the option review to obtain double line spacing
%\documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}


%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[export]{adjustbox}
\usepackage{tikz}
\usepackage[colorlinks=true]{hyperref}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{setspace}
\usepackage{longtable}
\usepackage{physics}
\usepackage{mathtools}
\usepackage{algorithm}
%%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{pythontex} 
\usepackage{booktabs}
\usepackage{tabularx} 

\algrenewcommand\algorithmicensure{\textbf{Output:}}
\newcommand{\length}[1]{\text{size}\left(#1\right)}
\newcommand{\SvecRep}[1]{\text{Svec}\left(#1\right)}
\newcommand{\SmatRep}[1]{\text{Smat}\left(#1\right)}
\newcommand{\vecRep}[1]{\text{vec}\left(#1\right)}
\newcommand{\IndexSym}[2]{\mathfrak{I}^\text{s}\left(#1,#2\right)}
\newcommand{\Index}[2]{\mathfrak{I}\left(#1,#2\right)}
\renewcommand{\trace}[1]{\text{tr}\left(#1\right)}
\newcommand{\dev}[1]{\text{dev}\left(#1\right)}

\newcommand{\Vector}[1]{\left[#1 \right]_{\text{v}}}
\newcommand{\Matrix}[1]{\left[#1 \right]_\text{m}}
\newcommand{\argmin}[1]{{\arg\min_{#1}\,}}
\newcommand{\argmax}[1]{{\arg\max_{#1}\,}}
\newcommand{\listSize}[1]{\abs{#1}}
\newcommand{\getRow}[2]{\text{row}\left(#1,#2\right)}
\newcommand{\getCol}[2]{\text{col}\left(#1,#2\right)}
\newcommand{\assembleOperator}{\bigwedge}
\DeclareMathOperator*{\Assemble}{\bigwedge}

\newcommand{\comment}[1]{}

%\singlespacing
%\onehalfspacing
%\doublespacing

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%\usepackage{lineno}
%\linenumbers

% review
\usepackage{xcolor}
\usepackage{todonotes}

\graphicspath{{images/}{.}} 

%%\journal{}

\makeindex


\begin{document}

\begin{frontmatter}
	
	%% Title, authors and addresses
	
	%% use the tnoteref command within \title for footnotes;
	%% use the tnotetext command for theassociated footnote;
	%% use the fnref command within \author or \address for footnotes;
	%% use the fntext command for theassociated footnote;
	%% use the corref command within \author for corresponding author footnotes;
	%% use the cortext command for theassociated footnote;
	%% use the ead command for the email address,
	%% and the form \ead[url] for the home page:
	%% \title{Title\tnoteref{label1}}
	%% \tnotetext[label1]{}
	%% \author{Name\corref{cor1}\fnref{label2}}
	%% \ead{email address}
	%% \ead[url]{home page}
	%% \fntext[label2]{}
	%% \cortext[cor1]{}
	%% \address{Address\fnref{label3}}
	%% \fntext[label3]{}
	
	\title{A hybrid framework integrating classical computers and quantum annealers for optimisation of truss structures}
	
	%\iffalse
	
	%% use optional labels to link authors explicitly to addresses:
	\author[label1,label2]{Van-Dung Nguyen\corref{cor}}\ead{vandung.nguyen@cenaero.be}
    \author[label1]{Erin Kuci}\ead{erin.kuci@cenaero.be}
	\author[label1]{Michel Rasquin}\ead{michel.rasquin@cenaero.be}
	\author[label2]{Ludovic Noels}\ead{l.noels@uliege.be}
	
	\cortext[cor]{Corresponding author}
	\address[label1]{Centre de recherche en a√©ronautique (Cenaero)\\ Rue des Fr\`eres Wright, 29\\6041 Gosselies, Belgium}
	\address[label2]{Computational \& Multiscale Mechanical of Materials (CM3), \\ Department of Aerospace and Mechanical Engineering, \\University of Li\`ege, \\ Quartier Polytech 1, All\'ee de la D\'ecouverte 9, B-4000 Li\`ege, Belgium}
	%\fi
	
\begin{abstract}
%% Text of abstract 
This work proposes a hybrid framework combining classical computers with quantum annealers for structural optimisation. At each optimisation iteration of an iterative process, two minimisation problems are formulated one for the underlying mechanical boundary value problem through the minimisation potential energy principle and one for the minimisation problem to update the design variables. Our hybrid approach leverages the strength of quantum computing to solve these two minimisation problems at each step, thanks to the developed quantum annealing-assisted sequential programming strategy introduced in [\href{https://doi.org/10.1016/j.euromechsol.2024.105254}{Nguyen, Wu, Remacle, and Noels. A quantum annealing-sequential quadratic programming assisted finite element simulation for non-linear and history-dependent mechanical problems. European Journal of Mechanics-A/Solids 105 (2024): 105254}]. The applicability of the proposed framework is demonstrated through several case studies of truss optimisation, highlighting its capability to perform optimisation with quantum computers. The proposed framework offers a promising direction for future structural optimisation applications, particularly in scenarios where the quantum computer could resolve the size limitations of the classical computers due to problem complexities.
\end{abstract}
	
\begin{keyword}
		%% keywords here, in the form: keyword \sep keyword
		Quantum computing \sep Quantum annealing \sep Optimisation \sep Truss structure
		%% PACS codes here, in the form: \PACS code \sep code
		%% MSC codes here, in the form: \MSC code \sep code
		%% or \MSC[2008] code \sep code (2000 is the default)		
\end{keyword}
	
\end{frontmatter}

%\linenumbers

%% main text
\section{Introduction}

A truss structure is an architectural network of interconnected bars commonly found in civil and mechanical engineering, such as bridges, roofs, towers, \emph{etc.}. Truss optimisation aimed at finding the most efficient configuration of a truss structure under given loading conditions while minimising material usage and ensuring its strength, stability, and performance~\cite{ben1997robust,kanno2018robust,cai2023topology,etaati2024shape}. The optimisation process involves not only finding the best layout and connectivity of the truss members but also optimising the material distribution in each member. For truss optimisation performed with traditional computers, an increasing complexity of the problems requires extensive computational resources.

Recent advances in quantum computing hardware promise revolutionary solutions for solving engineering applications by leveraging quantum mechanics such as superposition and entanglement to perform computations~\cite{wang2023opportunities,rajak2023quantum}. Unlike classical computers, where the information is stored and manipulated by bit-strings consisting of 0 and 1, quantum computing uses quantum bits (so-called qubits), which can exist in a superposition of 0 and 1 at the same time. As a result, $N$ qubits can represent $2^N$ bit-strings simultaneously, whilst $N$ classical bits can represent only one bit-string, leading to the exponential increase of the quantum computing power. Quantum computing offers the potential to revolutionise numerical computations that are currently beyond the hand of classical computing. There exist two main concepts for implementing quantum hardware: gate-based quantum computer and quantum annealer.

Gate-based quantum computers allow manipulating the qubits through a series of quantum logic gates, which are analogous to classical logic gates~\cite{burkard1999coupled,jaksch2000fast}. They theoretically enable universal computations. An extensive number of quantum algorithms has been developed to run with fault tolerant systems, for instance, Shor's factorisation algorithm~\cite{shor1994algorithms}, Grover's quantum search algorithm~\cite{grover1997quantum}, and Harrow-Hassidim-Lloyd (HLL) algorithm~\cite{harrow2009quantum} for solving a system of linear equations. However, building such fault-tolerant quantum devices will still take decades of research; the existing gate-based quantum computers are referred to as noisy-intermediate-scale quantum (NISQ) devices, for which variational quantum algorithms (VQA), such as variational quantum eigensolver~\cite{peruzzo2014variational} and quantum approximate optimisation algorithm (QAOA)~\cite{farhi2014quantum}, are suitable. In general, VQA is a hybrid approach combining quantum and classical computing to find parameters of parametrised quantum circuits with classical optimisers to minimise a cost function whose value is obtained upon quantum measurements on these circuits~\cite{cerezo2021variational}. The applicability of VQAs in topological optimisation has been explored~\cite{sato2023quantum,xu2024gate,kim2024variational}. Quantum computing also promises to solve computational mechanics problems~\cite{Balducci2022,liu2024towards}. Nevertheless, gate-based quantum computers are still in the early stages of development since the current quantum hardware is very sensitive to noise and surfers from high error rates, which makes it challenging to execute quantum algorithms accurately and efficiently.

Quantum annealer is particularly designed to solve an Ising problem, or equivalently, a quadratic unconstrained binary optimisation (QUBO) problem by taking advantage of the quantum annealing (QA) technologies~\cite{kadowaki1998quantum,brooke1999quantum,tanaka2017quantum, grant2020adiabatic}. The qubits are initialised at a simple state, and their interactions or entanglements are progressively modified to reach the ground state of the encoded problem, which corresponds to the global minimisation state of the problem at hand. To reach this minimum state, QA considers the quantum tunnelling effect in which a particle has the ability to pass through a potential energy barrier, which could not classically be overcome due to insufficient energy, to explore the energy landscape in order to reach its ground state. Compared to gate-based quantum computers, quantum annealers are more resilient against noise but much less versatile since they allow only considering unconstrained binary optimisation (Ising or QUBO) problems.

Quantum annealing devices were applied to various applications across multiple disciplines, see reviews by~\cite{yarkoni2022quantum,nath2023quantum}. The problems are however required to be transformed into Ising or QUBO forms to be embedded in the quantum annealers. For this purpose, the problem under consideration is first formulated as minimising an objective function of continuous and/or discrete variables and the latter is then transformed into QUBO. When the problem can be naturally expressed under a linear/quadratic form of the unknowns, QUBO can be achieved directly using a continuous-binary linear transformation, \emph{e.g.} for problems such as linear regressions~\cite{date2021adiabatic,koura2024linear} with quadratic cost function and linear elastic finite element simulations~\cite{Srivastava2019, RAISUDDIN2022115014, conley2023quantum} with quadratic potential energy. In a general situation in which the function to be minimised is not quadratic, a second-order Taylor's series followed by a continuous-binary linear transformation to obtain a QUBO is iteratively carried out, leading to the so-called quantum annealing-assisted sequential quadratic programming (QA-SQP) framework~\cite{NGUYEN2024105254}. QA-SQP is an iterative method, which offers the advantage of controlling the resolution error resulting from the annealing procedure. In this work, this advantage of the QA-SQP framework is exploited for the optimisation of truss structures.

Recently, building on its ability to find ground states, quantum annealing has been successfully applied to structural optimisation with proof of concepts. There have been few studies exploring this opportunity~\cite{wils2023symbolic,ye2023quantum,honda2024development,wang2024mapping,sukulthanasorn4968748quantum}, in which the difference between them relies mainly on how to translate an objective function into single or a series of QUBO forms. Wils \& Chen~\cite{wils2023symbolic} considered a symbolic finite element approach to express the objective function under a fractional form whose minimisation follows an iterative procedure of minimising adaptive non-fractional functions which are subsequently transformed into a QUBO form~\cite{ajagekar2020quantum}. Ye et al.~\cite{ye2023quantum} combined the QA and the generalised Bender's decomposition method~\cite{munoz2011generalized} to transform the original problem into a sequence of mixed-integer linear programming (MILP) problems, which are then reformulated as QUBO. Honda et al.~\cite{honda2024development} considered the combinatorial random number sums~\cite{endo2024novel} to convert the objective functions to QUBO. Wang et al.~\cite{wang2024mapping} considered the direct mapping between the total mass of the structure to be minimised with a discrete set of cross-sectional areas to form QUBOs. A hybrid framework for both truss and continuum structures optimisation was proposed by Sukulthanasorn et al.~\cite{sukulthanasorn4968748quantum} in which the structural analysis is performed on classical computers while the QA is used for topology updates. When performing the topology updates, the corresponding QUBO is derived by maximising the structural stiffness, leading to a linear form of objective functions with respect to the design variables. These works provide substantial evidences of QA‚Äôs potential in topology optimization, in particular the works~\cite{ye2023quantum,sukulthanasorn4968748quantum}. However, there remains a research gap in the literature for an efficient scheme that directly consider QA results not only to update the design structure, but also to solve the partial different equations governing the structure equilibrium state, which is the objective of this paper in the context of truss structures.

The QA-SQP framework~\cite{NGUYEN2024105254} is extended in this paper and applied to the optimisation of truss structures. A Taylor's series is used to approximate the constrained minimisation problem at hand under a polynomial form, which becomes a quadratic binary form using a continuous-binary linear transformation. Such a quadratic form can be transformed directly into QUBO. For this purpose, the constraints are accounted for by quadratic penalty functions. Also, to guarantee the quality of this approximation, a hyper-box is defined to limit the approximation neighbourhood. The structure analysis is reformulated as a minimisation problem thanks to the principle of minimum potential energy~\cite{rao2010finite}, which is then solved with the QA-SP framework. As a result, each optimisation step consists of solving two consecutive minimisation problems with QA-SP, one for the structure analysis and one for updating the design variables.

The paper is organised as follows. Section~\ref{sec:optsetting} recalls the problem setting of the optimisation problem. The principle of quantum annealing is briefly summarised in Section~\ref{sec:QA}. Section~\ref{sec:QA-SP} unveils our QA-SP framework and its exploitation in the optimisation problem. Several benchmarks for both two-dimensional and three-dimensional cases are provided in Section~\ref{sec:num} to demonstrate the capability of the proposed framework. Finally, some conclusions and perspectives are drawn in Section~\ref{sec:conclusion}. 

\section{Optimisation problem setting} \label{sec:optsetting}

We consider a truss structure of $N$ bars interconnected at $M$ nodes in $\mathbb{R}^d$ with $d=2$ or $3$. We denote $L_k$ and $A_k$ as the length and cross-sectional area of the $k^{th}$ member, respectively, with $k=1,\ldots,N$. The cross-sectional area $A_k$ is parametrised by a scalar $\alpha_k$, such that 
\begin{eqnarray}\label{eq:paramA}
	A_k = \alpha_k A_k^0\,,
\end{eqnarray} 
where $A_k^0$ the cross-sectional area of $k^{th}$ member in the initial design. We denote 
\begin{eqnarray}
	\bm{\alpha}=\mqty[\alpha_1& \alpha_2& \ldots& \alpha_{N}]^T\,,
\end{eqnarray}
as the vector of design variables. 

This structure is subjected to an external nodal force vector $\vb{F}\in \mathbb{R}^{dM}$ at its $M$ nodes. The structure balance results in the following equation
\begin{eqnarray}
	\vb{K}\left(\bm{\alpha}\right)\vb{U} = \vb{F}\,, \label{eq:forceBalance}
\end{eqnarray} 
where $\vb{K}$ is the global stiffness matrix being function of $\bm{\alpha}$ and $\vb{U}$ is the kinematically admissible nodal displacement vector. Following the parametrisation (\ref{eq:paramA}), the elementary stiffness matrix of the $k^{th}$ bar reads
\begin{eqnarray}
	\vb{K}_k^\text{el} = \alpha_k \vb{K}_k^\text{el,0} \text{ with } k=1,\ldots, N\,,
\end{eqnarray}
where $\vb{K}_k^\text{el,0}$ is its elementary stiffness matrix in the initial design. As a result, the global stiffness matrix $\vb{K}$ in Eq.~({\ref{eq:forceBalance}) is achieved through the assembling process of its elementary counterparts as
\begin{eqnarray}\label{eq:stiffnessMatrix}
	\vb{K} \left(\bm{\alpha}\right) = \assembleOperator_{k=1}^N \alpha_k \vb{K}_k^\text{el,0} = \sum_{k=1}^N \alpha_k \vb{K}_k\,,
\end{eqnarray}
where $\assembleOperator$ is the assembling operator and $\vb{K}_k$ is the stiffness $\vb{K}_k^\text{el,0}$ assembled in the global system. Eq.~(\ref{eq:forceBalance}) leads to the solution 
\begin{eqnarray}
	\vb{U} = \vb{K}^{-1} \vb{F} =  \vb{U}\left(\bm{\alpha}\right)\,,
\end{eqnarray}  
which depends on the design variables $\bm{\alpha}$ and generally cannot be expressed in an explicit form. Following the principle of minimum potential energy~\cite{rao2010finite}, Eq.~(\ref{eq:forceBalance}) can be rewritten as minimising the potential energy as
\begin{eqnarray}\label{eq:forceBalance2}
	\vb{U}\left(\bm{\alpha}\right) = \arg\min_{\vb{U}^\prime} \Psi\left( \vb{U}^\prime; \bm{\alpha}\right)\,,
\end{eqnarray} 
where $\Psi\left( \vb{U}; \bm{\alpha}\right) = \cfrac{1}{2}\vb{U}^T\vb{K}\left(\bm{\alpha}\right)\vb{U} - \vb{F}^T \vb{U}$ is the potential energy.

The optimisation problem is stated as finding the cross-section of each bar in the structure, which minimises the work of the external force defined by
\begin{eqnarray}
	C\left(\bm{\alpha}\right)=\vb{F}^T \vb{U}\left(\bm{\alpha}\right)\,,
\end{eqnarray}
while respecting the volume constraint. This optimisation problem is formally stated as follows:
\begin{eqnarray} \label{eq:objectiveFunc}
	&&\bm{\alpha} = \argmin{\bm{\alpha}^\prime} C\left(\bm{\alpha}^\prime\right) \\
	&& \text{ subject to } 
	\begin{cases}
		\text{Eq. } (\ref{eq:forceBalance2})\,,\\
		\sum_{k=1}^{N} \alpha_k L_k A_k^0 - V^{\text{target}}=0 \,, \\ 
		\bm{\alpha}_\text{min} \leq \bm{\alpha} \leq \bm{\alpha}_\text{max}\,.
	\end{cases} \nonumber
\end{eqnarray}
where in this context, $\vb{U}$ is the so-called state variables to be distinguished with $\bm{\alpha}$ being the design variables. The first constraint is to ensure that the structure is in static equilibrium under given loading conditions. The second constraint enforces the volume of material to be equal to $ V^{\text{target}}$. The last constraint specifies the lower-bounds $\bm{\alpha}_\text{min}$ and upper bounds $\bm{\alpha}_\text{max}$ of the design variable $\bm{\alpha}$. 

\section{Quantum annealing technique} \label{sec:QA}

Quantum annealer is a hardware implementation of the quantum annealing process and can be viewed as a black-box optimiser. In quantum computing, the fundamental unit is the quantum bit (so-called qubit)\footnote{In quantum computing, $\ket{\bullet}$ is the Dirac notation to represent a unit vector in a multi-dimensional complex Hilbert space. More details can be found in~\cite{nielsen_chuang_2010,Abhijith2022}.}. Unlike classical bit which can take only one of the two the binary states $\ket{0}$ and $\ket{1}$ in classical computers, a qubit can represent $\ket{0}$, $\ket{1}$, and their superposition, \emph{i.e.} $x \ket{0} + y \ket{1}$ in which $x$ and $y$ are complex numbers satisfying $|x|^2 + |y|^2 = 1$, and $|x|^2$  and $|y|^2$ are the probabilities to be in the state $\ket{0}$ and $\ket{1}$, respectively. This quantum characteristic allows for the simultaneous data processing. 

The objective of quantum annealing is to solve the ground-state problem of a quantum-mechanical system characterised by the Hamiltonian $\vb{H}_f$, which corresponds to the lowest-energy eigenstate of $\vb{H}_f$, \emph{i.e.}
\begin{eqnarray}\label{eq:groundStateProblem}
	\ket{\phi_0} = \argmin{\ket{\phi}} \bra{\phi}\vb{H}_f\ket{\phi}\,,
\end{eqnarray} 
where $\vb{H}_f$ is the Hamiltonian operator and $\ket{\phi}$ is a vector characterising the quantum state of the system. Starting from a simple ground state of the initial Hamiltonian $\vb{H}_i$ and gradually varying it according to a time-dependent Hamiltonian, the adiabatic theorem~\cite{born1928beweis} ensures that the system remains close to the ground state throughout the entire evolution, provided the change is slow enough. Consequently, one can follow the following algorithm to find the ground state of the Hamiltonian $\vb{H}_f$ as follows:
\begin{enumerate}
	\item The system is initialised with the ground state of a simple Hamiltonian $\vb{H}_i$ whose known quantum ground state can be easily prepared;
	\item The system is slowly modified following an adiabatic path (the so-called annealing schedule) by the following time-dependent Hamiltonian
	\begin{eqnarray}
		\vb{H}\left(t\right) = A(t) \vb{H}_i + B(t) \vb{H}_f \text{ with } t \in [0\,,t^\text{max}]\,,
	\end{eqnarray}
	where $t^\text{max}$ is the annealing time and $A(t)$ and $B(t)$ are functions satisfying $A(0) =1 \gg B(0)$ and $B(t^\text{max})=1\gg A(t^\text{max})$. The details can be found in the review by~\cite{albash2018adiabatic}.
	\item At the end of the annealing process, the ground state of the targeted Hamiltonian $\vb{H}_f$ is obtained upon measurement.
\end{enumerate}

Ising Hamiltonian is widely used in the quantum annealing since Ising Hamiltonian-based quantum annealers are commercially available. Let us consider an undirected graph $(V, E)$ where $V=\{1, \ldots, K\}$ is a set of $K$ qubits and $E$ specifies the set of interactions between two qubits, \emph{i.e.} $E \subset \{(i,j) |i\in V, j \in V, \text{ and } i < j\}$, the Ising Hamiltonian~\cite{kadowaki1998quantum,brooke1999quantum,tanaka2017quantum} is written as
\begin{eqnarray}
	\vb{H}_f^\text{Ising}=   \sum_{i\in V} h_i \bm{\sigma}_i^Z + \sum_{(i,j)\in E} J_{ij} \bm{\sigma}_i^Z \otimes \bm{\sigma}_j^Z\,,
\end{eqnarray}
where $\bm{\sigma}_i^Z$ is the Pauli-Z operator applied on qubit $i$, $\bm{\sigma}_i^Z \otimes \bm{\sigma}_j^Z$ are the ones applied on qubits $i$ and $j$, and $h_i\,\forall i$ and $J_{ij}\,\forall i,j$ are constants. As a result, $\vb{H}_f^\text{Ising}$ is a $2^K\times 2^K$ diagonal matrix whose eigenvalues correspond to the $2^K$ outputs of the following so-called Ising function
\begin{eqnarray}
	F_\text{Ising}\left(\vb{s}; \vb{h}, \vb{J}\right) = \sum_{i\in V} h_i s_i + \sum_{(i,j)\in E} J_{ij} s_is_j  \text{ with } \vb{s} = \mqty[s_1& \ldots& s_{K}]^T \in \{-1, 1\}^K\,.
\end{eqnarray}
In this equation, $\vb{s}$ corresponds to the spin vector and can be seen as the unknowns while $\vb{h}$ and $\vb{J}$ encode the Hamiltonian and are user-defined parameters. As a result, the ground state of $\vb{H}_f^\text{Ising}$ corresponds to the minimisation of $F_\text{Ising}$ as
\begin{eqnarray} \label{eq:Ising}
	\vb{s} = \arg\min_{\vb{s}^\prime} F_\text{Ising}\left(\vb{s}^\prime; \vb{h}, \vb{J}\right)\,,
\end{eqnarray}
where $\vb{h}=\mqty[h_i \text{ for } i = 1,\ldots, K]$, $\vb{J}=[J_{ij} \text{ for } i = 1,\ldots, K \text{ and } j=1, \ldots, K]$. Eq.~(\ref{eq:Ising}) can be efficiently obtained with QA.

Using the transformation $b_i = \cfrac{1+s_i}{2} \in \{0, 1\} \forall i$, the Ising problem (\ref{eq:Ising}) can be transformed to a QUBO problem~\cite{glover2022quantum} as
\begin{eqnarray}\label{eq:QUBO}
	\vb{b} = \arg\min_{\vb{b}^\prime} F_\text{QUBO}\left(\vb{b}^\prime; \vb{Q}\right)\,,
\end{eqnarray}
where $\vb{Q}$ is the QUBO matrix, which is constructed based on the user-defined problem parameters, and
\begin{eqnarray}\label{eq:quboFunc}
	F_\text{QUBO}\left(\vb{b}; \vb{Q}\right) =  \sum_{i=1}^{K} \sum_{j=i}^{K} Q_{ij}b_ib_j = \vb{b}^T\vb{Q}\vb{b}\,,
\end{eqnarray}
with $\vb{b} = \mqty[b_1& \ldots& b_{K}]^T \in \{ 0, 1\}^K$ being the set of the binary problem unknowns.

Using an appropriate initial Hamiltonian $\vb{H}_0$, considering $\vb{H}_f =\vb{H}^\text{Ising}$, and a suitable annealing schedule, the quantum annealing algorithm allows finding the ground state of $\vb{H}^\text{Ising}$, and thus providing the solution of an Ising problem (\ref{eq:Ising}) or of a QUBO problem (\ref{eq:QUBO}). The progress in developing quantum annealing hardware has been marked by several significant advancements over the past decade. In particular, the available D-Wave Systems are applied in various applications~\cite{yarkoni2022quantum}.


\section{Quantum annealing assisted structure optimisation} \label{sec:QA-SP}

In this section, first we introduce a general sequential programming (SP) framework in which an optimisation problem is transformed into a sequence of optimisation problems of polynomial forms by Taylor's series. Then the quantum annealing-assisted sequential programming (QA-SP) is detailed for quadratic polynomial forms. Finally, the developed QA-SP is employed to perform structure optimisation.

\subsection{Sequential programming (SP)}\label{subsec:SP}

Sequential programming (SP), in general, is an iterative strategy to solve a complex optimisation problem, in which a sequence of less complex optimisation problems is performed to reach the optimum solution. Let us consider the following quasi-unconstrained minimisation problem 
\begin{eqnarray}\label{eq:optDef}
	\begin{cases}
		&\min_{\vb{x}} {f}\left(\vb{x}\right)\\
		&\text{ subject to } 	\vb{x}_\text{min} \leq \vb{x} \leq \vb{x}_\text{max} \,,
	\end{cases}
\end{eqnarray}
where $f\left(\vb{x}\right)$ is a multivariate function $f: \mathbb{R}^N\rightarrow \mathbb{R}$ of the argument $\vb{x}$ and $\vb{x}_\text{min}$ and $\vb{x}_\text{max}$ are respectively its lower and upper bounds. We assume that, in the neighbourhood of $\vb{x}$, there exists a Taylor's series expansion up to the $P^\text{th}$ order with $P\geq 1$ as\footnote{For any matrix/vector $\vb{c}$, one defines a Kronecker product power $\vb{c}^{\otimes m} = \underbrace{\vb{c}\otimes \ldots \vb{c}\otimes\vb{c}}_{\vb{c} \text{ is repeated $m$ times}}$.}
\begin{eqnarray}
	f \left(\vb{x}+\bm{\delta}\right)  = 	f\left(\vb{x}\right)  + \sum_{m=1}^{P}  \frac{1}{m!}  \left(\cfrac{\partial^m f\left(\vb{x}\right) }{\partial \vb{x}^{\otimes m}} \right)^T \bm{\delta}^{\otimes m}   + \mathcal{O}(\norm{\bm{\delta}}^{P+1})\,.
\end{eqnarray} 
Consequently, one can define the polynomial approximation of a function $f$ in the neighbourhood of $\vb{x}$ by
\begin{eqnarray}\label{eq:polynomicalApproxx}
	f \left(\vb{x}+\bm{\delta}\right) \approx  \Phi^{P}\left(\bm{\delta}; \vb{x}, f\right) =	f\left(\vb{x}\right)  + \sum_{m=1}^{P}  \frac{1}{m!}   \left(\cfrac{\partial^m f\left(\vb{x}\right) }{\partial \vb{x}^{\otimes m}} \right)^T \bm{\delta}^{\otimes m}   \,,
\end{eqnarray}
where $\Phi^{\bullet}\left(\bullet; \bullet\right)$ denotes the polynomial approximation operator. 

The key step in the SP strategy is to iteratively construct the approximated form of the problem (\ref{eq:optDef}) using Taylor's series (\ref{eq:polynomicalApproxx}) at the current guess, \emph{i.e. } $\vb{x}^{(k)}$ with $k\geq 0$, to find the next guess, \emph{i.e.} $\vb{x}^{(k+1)} $. Assuming $\vb{x}^{(k+1)} =\vb{x}^{(k)} + \bm{\delta}^{k+1}$, $\bm{\delta}^{k+1}$ is then obtained by solving the following minimisation problem
\begin{eqnarray}\label{eq:optDef2}
	\begin{cases}
		\bm{\delta}^{(k+1)} = \arg\min_{\bm{\delta}}\Phi^{P}\left(\bm{\delta}; \vb{x}^{(k)}, f\right) \\
		\text{subject to } \max(\vb{x}_\text{min}-\vb{x}^{(k)}, \bm{\delta}^b_\text{min}) \leq \bm{\delta} \leq \min(\vb{x}_\text{max}-\vb{x}^{(k)}, \bm{\delta}^b_\text{max})
	\end{cases}\,,
\end{eqnarray}
where $\bm{\delta}^b_\text{min} \leq \bm{ \delta} \leq \bm{\delta}^b_\text{max}$ defines a hyper-box integrated due to the fact that the polynomial approximation (\ref{eq:polynomicalApproxx}) is generally accurate only within a small region around $\vb{x}$. The iterative procedure of the SP strategy is summarised in Alg.~\ref{algo:SHP}. In this work, the polynomial optimisation problem (\ref{eq:optDef2}) is solved by a hybrid algorithm combining quantum computing and classical computers, as detailed in the next section. 
\begin{algorithm}[htb]
	\caption{Iterative procedure of the SP strategy for the minimisation problem (\ref{eq:optDef}) incorporating the polynomial approximation (\ref{eq:polynomicalApproxx}) at each step.}
	\label{algo:SHP}
	\begin{algorithmic}[1]
		\State initialise to an admissible initial solution $\vb{x}^{(0)} \in \mqty[\vb{x}_\text{min}\,,\vb{x}_\text{max} ]$;
		\State set the box bounds $\bm{\delta}^b_\text{min}$ and $\bm{\delta}^b_\text{max}$;
		\State set $k=0$;		
		\Repeat
		\State solve the polynomial optimisation problem (\ref{eq:optDef2}) to obtain $ \bm{\delta}^{(k+1)}$;
		\State update $\vb{x}^{(k+1)} \gets \vb{x}^{(k)} + \bm{\delta}^{(k+1)} $;
		\State $k\gets k+1$;
		\Until{convergence}
	\end{algorithmic}
\end{algorithm}

When the minimisation problem (\ref{eq:optDef}) is incorporated with equality and inequality constraints as stated as follows:
\begin{eqnarray}\label{eq:optDefConstrained}
	\min_{\vb{x}} f\left(\vb{x}\right) \text{ subject to } \begin{cases}
		h_j\left(\vb{x}\right) = 0 \text{ with } j =1,\ldots, N_h\,, \\
		l_j\left(\vb{x}\right) \leq  0 \text{ with } j =1,\ldots, N_l\,,\text{ and} \\
		\vb{x}_\text{min} \leq \vb{x} \leq \vb{x}_\text{max}\,,
	\end{cases} \,,
\end{eqnarray}
where $N_h$ and $N_l$ are the number of equality and inequality constraints, respectively, the corresponding constrained minimisation problem is transformed into the canonical form (\ref{eq:optDef2}) using penalties. For this purpose, an augmented polynomial minimisation form is defined by
\begin{eqnarray}
	f_\text{aug}\left(\vb{x}; \bm{\lambda}\right) = f\left(\vb{x}\right)+ \sum_{j=1}^{N_h} c_j^h  \left[h_j\left(\vb{x}\right)\right]^2 + \sum_{j=1}^{N_l} c_j^l  \left[l_j\left(\vb{x}\right) + \lambda_j \right]^2\,,
\end{eqnarray}
where $c_j^h$ and $c_j^l$ are the penalty factors associated respectively with the equality constraint $h_j$ and with inequality constraint $l_j$, and $\bm{\lambda}=\mqty[\lambda_1&\ldots&\lambda_{N_l}]^T$ is a vector of the auxiliary variables which are constrained to be non-negative to enforce the inequality constraints. The values $c_j^h$ and $c_j^l$ $\forall j$ need to be large enough so that the optimization solution does not depend on this choice. Indeed, the solution of the minimisation problem satisfies exactly the constraints. As a result, the constrained form (\ref{eq:optDefConstrained}) can be rewritten in the quasi-unconstrained form (\ref{eq:optDef}) as
\begin{eqnarray}\label{eq:augementedFunc}
	\begin{cases}
		&\min_{\vb{x}, \bm{\lambda}} f_\text{aug}\left(\vb{x}, \bm{\lambda}\right)\\
		&\text{ subject to }  \vb{x}_\text{min} \leq \vb{x} \leq \vb{x}_\text{max} \text{ and } \vb{0 }\leq \bm{\lambda}\leq +\infty \,.
	\end{cases}
\end{eqnarray}
Finally, the minimisation problem (\ref{eq:optDefConstrained}) can be solved with Alg.~\ref{algo:SHP} using the augmented polynomial approximation (\ref{eq:augementedFunc}) in the approximated polynomial form (\ref{eq:optDef2}).

\subsection{Quantum annealing-assisted sequential programming (QA-SP)} \label{sec:QASP}

When the polynomial forms \emph{e.g.} Eq.~(\ref{eq:polynomicalApproxx}) are quadratic, QUBOs are directly obtained by mapping each continuous variable to binary variables by a linear transformation. The continuous-binary and quadratic polynomial form-QUBO mapping strategies and a nested hybrid QA-SP scheme for Alg.~\ref{algo:SHP} are detailed in the following.

\subsubsection{Mapping continuous variables to binary variables} \label{subsec:continuousToBinary}

In this section, a vector of continuous components is linearly approximated using binary variables with the encoding strategy as proposed in~\cite{NGUYEN2024105254}. A $L$-bit string, \emph{i.e.} ${b_{L}\ldots b_{1}}$ with $b_i \in \{0,1\} \, \forall i$, can represent an arbitrary whole number ranging from 0 to $2^{L}-1$ through the following binary-decimal conversion
\begin{eqnarray}
	{b_{L}\ldots b_{1}} \equiv \sum_{j=0}^{L-1} b_{j+1} 2^j\,.
\end{eqnarray}
As a result, one can discretise the range $\mqty[d_{\text{min}},\,d_{\text{max}}]$ into $2^{L}$ discrete values following
\begin{eqnarray} \label{eq:binarised}
	\delta : 
		\left(b_1,\,\ldots,\,b_{L}\right) \rightarrow  \bar{\delta} + \epsilon \left( \sum_{j=0}^{L-1} b_{j+1} 2^j  - 2^{L-1}+1\right) \in \mqty[d_{\text{min}},\,d_{\text{max}}]\,, 
\end{eqnarray}
where $\epsilon$ is the so-called discretisation error, $\bar{\delta}$ is the central value, and where 
\begin{eqnarray}
		d_{\text{min}} &= \bar{\delta}- \left( 2^{L-1}-1\right) \epsilon\,,  \text{ and }
		d_{\text{max}}&= \bar{\delta} +2^{L-1} \epsilon\,.
\end{eqnarray}
The last equation allows estimating the pair $(\bar{\delta},\epsilon )$ from the bound $\mqty[d_{\text{min}},\,d_{\text{max}}]$ as
\begin{eqnarray}\label{eq:boundToError}
	\epsilon = \cfrac{d_\text{max}-d_\text{min}}{2^L-1} \text{ and } \bar{\delta} = \cfrac{d_\text{max}+d_\text{min} -\epsilon }{2} \,.
\end{eqnarray}
A larger range $\mqty[d_{\text{min}},\,d_{\text{max}}]$ is obtained using more qubits for a given error $\epsilon$, whilst when the number of qubits is fixed, the range $\mqty[d_{\text{min}},\,d_{\text{max}}]$ becomes smaller with decreasing $\epsilon$. Eq.~(\ref{eq:binarised}) can be rewritten as
\begin{eqnarray}\label{eq:binarisationVec}
	\delta\left(\vb{b}\right)= d_{\text{min}} + \epsilon \bm{\beta}^T\vb{b}\,,
\end{eqnarray}
where $\bm{\beta} = \mqty[2^0&2^1\,.\ldots&2^{L-1}]^T$ and $\vb{b}=\mqty[b_1&\ldots&b_{L}]^T$. 

Let us consider a vector $\bm{\delta}$ of $N$ components, Eq.~(\ref{eq:binarisationVec}) is thus applied to each component of $\bm{\delta}$, leading to
\begin{eqnarray}\label{eq:binaryApprox}
	\bm{\delta} = \vb{d}_{\text{min}} + \left[\epsilon_i\bm{\beta}^T\vb{b}_i \text{ for } i=1,\,\ldots,\, N\right] = \vb{d}_{\text{min}} + \vb{V}\vb{b} \in \mqty[\vb{d}_{\text{min}},\,\vb{d}_{\text{max}}]\,,
\end{eqnarray}
where $\bullet_i$ denotes a quantity associated with the component $\delta_i\in \bm{\delta}$, $\vb{d}_{\text{min}}$ and $\vb{d}_{\text{max}}$ denote respectively the lower-bound and upper-bound of $\bm{\delta}$ and where
\begin{eqnarray}
	\vb{d}_{\text{min}}&=&\mqty[d_{\text{min},1}&\ldots&d_{\text{min},N}]^T \label{eq:binaryApproxa}\,,\\
	\vb{V} &=&\text{diag}\left(\epsilon_1\bm{\beta}^T,\,\ldots,\,\epsilon_{N}\bm{\beta}^T \right) \,, \text{ and } \label{eq:binaryApproxD}\\
	\vb{b} &=& \mqty[\vb{b}_1^T&\ldots\,\vb{b}_{N}^T]^T\,  \label{eq:binaryApproxb} \,.
\end{eqnarray}
with $\text{diag}\left(\bullet\right)$ denoting the $N\times\left(N\times L\right)$ block diagonal matrix. We can also denote 
\begin{eqnarray}
		\bm{\epsilon} &=& \mqty[\epsilon_1&\ldots&\epsilon_N]^T\,,  \label{eq:disError}
\end{eqnarray}
as the discretisation error vector.

\subsubsection{Mapping a quadratic polynomial form to QUBO} \label{subsec:mapPolynomial}

Using the linear continuous-binary conversion (\ref{eq:binaryApprox}) of $\bm{\delta}$ in the polynomial forms, \emph{e.g.} Eq.~(\ref{eq:polynomicalApproxx}), leads to a binary polynomial form of the same degree. We consider Eqs. (\ref{eq:polynomicalApproxx}) under a quadratic form which is achieved by considering linear or quadratic Taylor's series for the objective function and for constraints when present. These quadratic forms are rewritten in a general quadratic form as
\begin{eqnarray}\label{eq:quadraticForm}
	\mathcal{P}\left(\bm{\delta}\right) =\bm{\delta}^T \vb{g} + \bm{\delta}^T \vb{A} \bm{\delta} 
\end{eqnarray}
where $\vb{g} = \vb{g} = \cfrac{\partial f}{\partial \vb{x}}$ is the linear coefficient vector, $\vb{A}=\cfrac{1}{2} \cfrac{\partial}{\partial \vb{x}}\cfrac{\partial f}{\partial \vb{x}}$ is the quadratic coefficient matrix which is symmetric, and the constant term is omitted as it is irrelevant in this minimisation context. By replacing $\bm{\delta}$ in Eq.~(\ref{eq:quadraticForm}) by Eq.~(\ref{eq:binaryApprox}), one has 
\begin{eqnarray}\label{eq:binaryForm}
	\Lambda\left(\vb{b}\right) =  \vb{d}_\text{min}^T \vb{g} + \vb{d}_\text{min}^T \vb{A} \vb{d}_\text{min} +  \vb{b}^T \vb{V}^T\left( \vb{g}+2\vb{A}\vb{d}_\text{min}\right) + \vb{b}^T\vb{V}^T\vb{A}\vb{V}\vb{b} \,.
\end{eqnarray}
One has $b_i^2 = b_i\,\forall i$ since $b_i\in {0,1}$. Consequently, Eq.~(\ref{eq:binaryForm}) can be rewritten as
\begin{eqnarray}\label{eq:QUBOpoly}
	\Lambda\left(\vb{b}\right) =  \vb{d}_\text{min}^T \vb{g} + \vb{d}_\text{min}^T \vb{A} \vb{d}_\text{min} + F_\text{QUBO}\left(\vb{b}; \vb{Q}\right)\,,
\end{eqnarray}
where $F_\text{QUBO}$ is the QUBO form (\ref{eq:quboFunc}) with the QUBO matrix
\begin{eqnarray}\label{eq:QUBOmat}
	\vb{Q} = \vb{V}^T\vb{A}\vb{V}  + \text{diag}\left(\vb{V}^T\left( \vb{g}+2\vb{A}\vb{d}_\text{min}\right) \right)\,,
\end{eqnarray}
where $\text{diag}\left(\vb{a}\right)$ is the diagonal matrix whose diagonal is the vector $\vb{a}$. As a result, the minimisation of the polynomial form (\ref{eq:quadraticForm}) under constraints can be carried out through solving the QUBO (\ref{eq:QUBOpoly}) with quantum annealers as referred to Eq.~(\ref{eq:QUBO}).

\subsubsection{A nested hybrid framework }

\begin{algorithm}[!htb]
	\caption{Quantum annealing-assisted sequential programming (QA-SP) algorithm.}
	\label{algo:QASP}
	\begin{algorithmic}[1]
		\State set number of qubits per continuous variable $L$;
		\State set initial discretisation error $\bm{\epsilon}_0$;
		\State set box $\bm{\delta}_\text{min}^b$, $\bm{\delta}_\text{max}^b$;
		\State set shrinking factor $\xi$; 
		\State set maximum number of successful iterations $N_\text{steps}$;
		\State set allowable number of failed iterations $N_\text{failed}$;
		\State initialise admissible initial solution $\vb{x}^{(0)} \in \mqty[\vb{x}_\text{min}\,,\vb{x}_\text{max} ]$;
		\State construct polynomial approximation around $\vb{x}^{(0)}$ as discussed in Section~\ref{subsec:SP};
		\State $k\gets 0$ and $l\gets 0$;
		\State $\bm{\epsilon} \gets \bm{\epsilon}_0$ and  $\bar{\bm{\delta}} \gets \vb{0}$;
		\Repeat
		\State update bounds with respect to the box
		\begin{eqnarray}
				\bm{\delta}_\text{min}^{(k)} \gets \max{(\vb{x}_\text{min}-\vb{x}^{(k)}, \bm{\delta}_\text{min}^b)}  \text{ and }
				\bm{\delta}_\text{max}^{(k)} \gets \min{(\vb{x}_\text{max}-\vb{x}^{(k)}, \bm{\delta}_\text{max}^b)};
		\end{eqnarray}
		\State estimate discretisation range $\mqty[\vb{d}_\text{min}&\vb{d}_\text{max}]$ following Section~\ref{subsec:continuousToBinary};
		\State update discretisation range with respect to bounds
		\begin{eqnarray}
				\vb{d}_\text{min} \gets \max{(\vb{d}_\text{min}, \bm{\delta}_\text{min}^{(k)})} \text{ and }
				\vb{d}_\text{max}  \gets \min{(\vb{d}_\text{max}, \bm{\delta}_\text{max}^{(k)})};
		\end{eqnarray}
		\State update $\bm{\epsilon}$ and $\bar{\bm{\delta}}$ with new $\vb{d}_\text{min}$ and $\vb{d}_\text{max}$ following Eq.~(\ref{eq:boundToError});
		\State evaluate the continuous-binary transformation (\ref{eq:binaryApprox}) as discussed in Section~\ref{subsec:continuousToBinary};
		\State estimate the QUBO matrix following Section~\ref{subsec:mapPolynomial};
		\State \textcolor{red}{\textbf{call quantum annealers (\ref{eq:QUBO}) leading to the solution $\vb{b}^{(k+1)}$;}}
		\State update $\bm{\delta}^{(k+1)}$ with $\vb{b}^{(k+1)}$ following (\ref{eq:binaryApprox});
		\If {$f\left( \vb{x}^{(k)} + \bm{\delta}^{(k+1)} \right) < f\left(\vb{x}^{(k)}\right)$}
		\State $\vb{x}^{(k+1)} \gets \vb{x}^{(k)} + \bm{\delta}^{(k+1)} $;
		\State $k\gets k+1$;
		\State construct polynomial approximation around $\vb{x}^{(k)}$ as discussed in Section~\ref{subsec:SP};
		\Else
		\State $l\gets l+1$
		\State $\bm{\epsilon}=\max(\epsilon_\text{min}, \xi \bm{\epsilon})$
		\EndIf
		\If {$k\geq  N_\text{steps}$ or $l\geq  N_\text{failed}$}
		\State break;
		\EndIf
		\Until{convergence};
	\end{algorithmic}
\end{algorithm}
The hybrid quantum annealing-assisted sequential programming (QA-SP) algorithm is summarised in Alg.~\ref{algo:QASP}, in which the part working on quantum annealers is highlighted while the remaining part is carried out in classical computers. 

At the iteration $k$ with $\vb{x}^{(k)}$ being known, the quadratic polynomial approximations (\ref{eq:polynomicalApproxx}) of the minimisation problem is constructed. The side constraints are also re-evaluated with respect to the box $\mqty[\bm{\delta}_\text{min}^b& \bm{\delta}_\text{max}^b]$ and the bounds $\mqty[\vb{x}_\text{min}&\vb{x}_\text{max}]$ of the variables. A QUBO problem is obtained subsequently using the continuous-binary linear transformation (\ref{eq:binaryApprox}) and can be solved directly with quantum annealers. After updating the increment $\bm{\delta}^{(k+1)}$ with the solution $\vb{b}^{(k+1)}$ from quantum annealers following (\ref{eq:binaryApprox}), two scenarios are envisioned:
\begin{enumerate}
	\item[(i)] The objective function value decreases as expected, the unknown $\vb{x}^{(k+1)}$ is encoded and the polynomial approximation at this point is constructed for the next iteration.
	\item[(ii)] The objective function value does not decrease. The continuous-binary discretisation needs to be refined by reducing the discretisation error $\bm{\epsilon}$ (see Eq.~(\ref{eq:disError})) by a so-called shrinking factor $\xi < 1$. We consider $\xi=0.5$ in this work.
\end{enumerate}
We note that even for quadratic functional, an iterative procedure is required. On the one hand, it is needed because of the binarisation process with a low number of qubits. On the other hand, it allows accounting for the error inherent to the quantum annealing process. 

\subsection{Application for optimisation of truss structures}

In this section, the hybrid framework described in Alg.~\ref{algo:QASP} is considered for the optimisation of truss structures. The optimisation process involves multiple iterations. In each iteration, the state variables $\vb{U}$ and the design variables $\bm{\alpha}$ are updated through two distinct minimisations. At $k+1^{th}$ iteration, their values at previous current step, \emph{i.e.}, $\vb{U}^{(k)}$ and $\bm{\alpha}^{(k)}$, are known, and the values at the current step, \emph{i.e.}, $\vb{U}^{(k+1)}$ and $\bm{\alpha}^{(k+1)}$, are sought. These two minimisation are sequentially carried out as follows:
\begin{itemize}
	\item The value of $\vb{U}^{(k+1)}$ is first obtained by solving the unconstrained minimisation (\ref{eq:forceBalance2}) which is rewritten as
	\begin{eqnarray}\label{eq:SPU}
	\vb{U}^{(k+1)} \left(\bm{\alpha}^{(k)}	\right) = \arg\min_{\vb{U}} \Psi\left( \vb{U}; \bm{\alpha}^{(k)}\right)\,.
	\end{eqnarray}
	This minimisation problem will be solved by Alg.~\ref{algo:QASP} using a quadratic Taylor's series of the objective function.
	\item The value of $\bm{\alpha}^{(k+1)}$ is obtained by solving the constrained minimisation (\ref{eq:objectiveFunc}), in which one key element is to estimate the global compliance $C\left(\bm{\alpha}\right)$. In this step, instead of finding $C\left(\bm{\alpha}\right)$ from the solution of the minimisation problem (\ref{eq:forceBalance2}), a linear Taylor's series is employed because the estimation of the hessian in the quadratic form is challenging in this case, leading to
	\begin{eqnarray}
		C\left( \bm{\alpha} \right) \approx \Phi^{1}\left(\bm{\alpha}-\bm{\alpha}^{(k)}; \bm{\alpha}^{(k)}, C\right) = \vb{F}^T\vb{U}^{(k+1)}  + \bm{\omega}^{(k)}{}^T \left(\bm{\alpha}-\bm{\alpha}^{(k)} \right)\,,
	\end{eqnarray}
	where both $\vb{U}^{(k+1)}$ and $\bm{\omega}^{(k)}= \cfrac{\partial \left(\vb{F}^T  \vb{U}^{(k+1)} \right)}{\partial \vb{\bm{\alpha}}^{(k)}}$ are known from the solutions of the problem (\ref{eq:SPU}). Moreover the constraints in the problem (\ref{eq:objectiveFunc}) are also relaxed by applying a first-order Taylor's series. As a result, Eq.~(\ref{eq:objectiveFunc}) is rewritten as
	\begin{eqnarray}\label{eq:SPA}
		&&\bm{\alpha}^{(k+1)} = \bm{\alpha}^{(k)} + \arg\min_{\bm{\delta}} \Phi^{1}\left(\bm{\delta};  \bm{\alpha}^{(k)}, C\right)\\
		&& \text{ subject to }  
		 \begin{cases}
		 	\Phi^{1}\left(\bm{\delta};  \bm{\alpha}^{(k)}, h\right) = h\left(\bm{\alpha}^{(k)}\right) + \vb{D}^{(k)}{}^T \bm{\delta} = 0 \,, \\ 
		 	\bm{\alpha}_\text{min}-\bm{\alpha}^{(k)} \leq \bm{\delta} \leq \bm{\alpha}_\text{max} -\bm{\alpha}^{(k)}\,.
		 \end{cases} \nonumber
	\end{eqnarray}
	where $\Phi^{1}(\bullet;  \bm{\alpha}^{(k)}, f)$ denotes a linear approximation operator of a function $f$ in the neighbourhood of $ \bm{\alpha}^{(k)}$, $h\left(\bm{\alpha}\right) = \sum_{k=1}^{N} \alpha_k L_k A_k^0 - V^{\text{target}}$, $\bm{\delta} = \bm{\alpha}^{(k+1)} -\bm{\alpha}^{(k)} $ is the increments of design variables, $\bm{\omega}^{(k)} = \cfrac{\partial \left(\vb{F}^T  \vb{U}^{(k+1)} \right)}{\partial \vb{\bm{\alpha}}^{(k)}}$ is the function gradient, and $\vb{D}^{(k)} = \cfrac{\partial h }{\partial \bm{\alpha}^{(k)}}$ is the constraint gradient. This minimisation problem is solved by Alg.~\ref{algo:QASP}.
\end{itemize}

To estimate the sensitivity of $\vb{U}^{(k+1)}$ with respect to $ \bm{\alpha}^{(k)}$, \emph{i.e.} to evaluate $\bm{\omega}^{(k)} = \cfrac{\partial \left(\vb{F}^T  \vb{U}^{(k+1)} \right)}{\partial \vb{\bm{\alpha}}^{(k)}}$ after solving (\ref{eq:SPU}), we consider the consistency condition
\begin{eqnarray}
	\cfrac{\partial}{\partial \alpha_i^{(k)}}\left(\vb{K}\left(\bm{\alpha}^{(k)}\right) \vb{U}^{(k+1)}  \right) = 0\,,
\end{eqnarray}
leading to 
\begin{eqnarray}
	&&\cfrac{\partial \vb{U}^{(k+1)}}{\partial  \alpha_i^{(k)}} = - \vb{K}\left(\bm{\alpha}^{(k)}\right)^{-1} \cfrac{\partial \vb{K}\left(\bm{\alpha}^{(k)}\right)}{\partial \alpha_i^{(k)}} \vb{U}^{(k+1)} \text{ and } \\ 	&& \vb{F}^T\cfrac{\partial \vb{U}^{(k+1)}}{\partial  \alpha_i^{(k)}} = - \vb{U}^{(k+1)}{}^T \cfrac{\partial \vb{K}\left(\bm{\alpha}^{(k)}\right)}{\partial \alpha_i^{(k)}} \vb{U}^{(k+1)}\,.
\end{eqnarray}
The last equation allows estimating each component ${\omega}^{(k)}_i$ of $\bm{\omega}^{(k)}$ as
\begin{eqnarray}
{\omega}^{(k)}_i	= - \vb{U}^{(k+1)}{}^T \cfrac{\partial \vb{K}\left(\bm{\alpha}^{(k)}\right)}{\partial \alpha_i^{(k)}} \vb{U}^{(k+1)} = -\vb{U}^{(k+1)}{}^T \vb{K}_i \vb{U}^{(k+1)} \,,
\end{eqnarray}
where $\vb{K}_i$ is obtained from $\vb{K}$ given in Eq.~(\ref{eq:stiffnessMatrix}).

The resolution scheme of the minimisation problem (\ref{eq:objectiveFunc}) is sketched in Alg.~\ref{algo:QASPOPT}, in which the QA-SP detailed in Alg.~\ref{algo:QASP} is used to solve each minimisation problem at each iteration. 
\begin{algorithm}[!htb]
	\caption{Iterative scheme for optimisation of truss structure.}
	\label{algo:QASPOPT}
	\begin{algorithmic}[1]
		\State initialise an admissible initial solution $\bm{\alpha}^{(0)} \in \mqty[\bm{\alpha}_\text{min}\,,\bm{\alpha}_\text{max} ]$;
		\State set $k=0$;
		\Repeat
		\State solve the minimisation (\ref{eq:SPU}) with algorithm Alg.~\ref{algo:QASP} and return $\vb{U}^{(k+1)}$ and $\bm{\omega}^{(k)}$; 
		\State solve the minimisation (\ref{eq:SPA}) with algorithm Alg.~\ref{algo:QASP} and return $\bm{\alpha}^{(k+1)}$
		\State $k\gets k+1$;
		\Until{convergence};
	\end{algorithmic}
\end{algorithm}

\section{Numerical examples} \label{sec:num}

This section provides some benchmarks in both two-dimensional and three-dimensional cases to highlight the capability of our proposed framework for truss structure optimisation. The QUBO problem (\ref{eq:QUBO}) is solved with the D-Wave system~\cite{dwaveDoc} using the python script reported in Alg.~\ref{algo:DwaveSubmission}. \emph{DWaveSampler} allows submitting the problem to an available quantum processing unit while \emph{EmbeddingComposite} is used to embed the QUBO into the hardware graph since the problem does not automatically fit in. The sampling process is carried out with 200 reads and an annealing time of 20 $\mu\text{s}$. The output is chosen as the variable that makes the QUBO the smallest. In the remaining of this section, we consider 2 qubits (\emph{i.e.} $L=2$) for each continuous variable when employing Alg.~\ref{algo:QASP}.
\begin{algorithm}[!htb]
	\caption{QUBO problem submitted to the D-Wave system.}
	\label{algo:DwaveSubmission}
	\centering
	\begin{varwidth}{\linewidth}
		\begin{verbatim}
			
			from dwave.system import DWaveSampler, EmbeddingComposite
			def solve_QUBO(Q):
					sampler = EmbeddingComposite(DWaveSampler())
					sampleset = sampler.sample_qubo(Q, num_reads=200, annealing_time=20)
					b = sampleset.first.sample
					return b
		\end{verbatim}
	\end{varwidth}
\end{algorithm}

\subsection{Two-dimensional cases}\label{subsec:2DTest}

We consider the three cases reported in~\cite{sukulthanasorn4968748quantum}, whose initial configurations and boundary conditions are reported in Fig.~\ref{fig:initialConfig}. The Young's modulus is equal to $200$ GPa. The initial cross-sectional area is set to 0.5 $\text{m}^2$ for all bars. 
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.4]{caseStudy}
	\caption{Two-dimensional cases: three case studies of truss optimisation respectively with 10, 21, and 29 bars. The length is set to 1 m for both horizontal and vertical bars and to $\sqrt{2}$ m for the diagonal bars. The initial cross-sectional area is set to 0.5 $\text{m}^2$ for all these bars.}
	\label{fig:initialConfig}
\end{figure}

The capability of the proposed framework to solve a mechanical boundary value problem is first demonstrated through a minimisation of the potential energy as described by Eq.~(\ref{eq:forceBalance2}). The initial solution $\vb{U}=\vb{0}$, the initial discretisation error $\bm{\epsilon}_0 = \cfrac{10^{-4}}{2^L-1}\mqty[1&\ldots&1]$ with $L$ being the number of qubits per continuous unknown and $\bar{\bm{\delta}}=\vb{0}$ are considered. The values $\bm{\epsilon}_0$ and $\bar{\bm{\delta}}$ allows estimating the initial discretisation range $\mqty[\vb{d}_\text{min}&\vb{d}_\text{max}]$ as discussed in Section~\ref{subsec:continuousToBinary}. Each case is solved three times to assess the randomness in the resolution because of the heuristic nature of quantum annealers. The convergence histories of the three cases shown in Fig.~\ref{fig:initialConfig} are reported in Fig.~\ref{fig:QAFE} where the exact value $\Psi^\text{exact}$ is estimated from $\vb{U}$ obtained by directly solving Eq.~(\ref{eq:forceBalance}). The resolution of the case with 6 bars exhibits no discrepancy because of the relatively small number of qubits used in the optimisation process. For all the studied cases, the accuracy keeps improving with the number of iterations and a relative error as low as $10^{-9}$ can be reached in all cases. 
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{QAFE}
	\caption{Solving the equilibrium balance equation (\ref{eq:forceBalance2}) with quantum annealers. The exact solution $\Psi^{\text{exact}}$ is obtained by directly solving Eq.~(\ref{eq:forceBalance}).}
	\label{fig:QAFE}
\end{figure}

First, we consider applying Alg.~\ref{algo:QASPOPT} for the case of 6 bars. The QA-SP parameters reported above are chosen to solve the problem (\ref{eq:SPU}). For each bar, the design parameter, see Eq.~(\ref{eq:paramA}), takes the initial value of 0.35, an upper bound of 1.1 is chosen as considered in~\cite{sukulthanasorn4968748quantum}, and a lower bound is set to 0.02. The box is set to $\mqty[-0.05& 0.05]$ for all bars, see Eq.~(\ref{eq:optDef2}). The material volume $V^\text{target}$ is equal to the initial value $V_0$ of the initial design. This constraint is accounted for using a penalty of 100. $N_\text{steps}$ and $N_\text{failed}$ are set to 200 and 10, respectively. The  The iterative process stops when the objective function no longer decreases. The evolutions of the compliance $C$ and of the ratio $\frac{V}{V^\text{target}}$ during the optimisation process are reported in Fig.~\ref{fig:case6}a in which the tests are repeated three times. It is shown that the objective function gradually decreases while satisfying the volume constraint with a relative error of the optimised solution smaller than 0.3\%. The optimised configurations of these three runs are reported in Fig.~\ref{fig:case6}b, c, and d, and are found to be similar.
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{case6-convergence} \\
(a) Evolutions of $C$ and $\frac{V}{V^\text{target}}$\\
\begin{tabular}{ccc}
	\includegraphics[scale=0.35]{case6-r1}&\includegraphics[scale=0.35]{case6-r2}&\includegraphics[scale=0.35]{case6-r3}\\
	(b) run 1&(c) run 2&(d) run 3
\end{tabular}
\caption{Case 1 with 6 bars: (a) evolutions of $C$ and $\frac{V}{V^\text{target}}$ for three independent runs and (b, d, d) optimised configurations after each run.}
\label{fig:case6}
\end{figure}

The results of case 2 with 21 bars and case 3 with 29 bars are shown in Figs.~\ref{fig:case21} and~\ref{fig:case29} respectively, with the same parameter setting, except the initial value of the design parameter is equal to 0.5 for each bar in the former and 0.4 in the latter as considered in~\cite{sukulthanasorn4968748quantum} for comparison purpose. It is observed that the objective function gradually decreases in both cases. The volume constraint is satisfied with a relative error of the optimised solution smaller than 0.5\% for the case of 21 bars and smaller than 0.8\% for the case of 29 bars. The optimised configurations of the three runs for each case are similar and are reported in Figs.~\ref{fig:case21}b, c, and d and~\ref{fig:case29}b, c, and d, respectively.
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{case21-convergence} \\
	(a) Evolutions of $C$ and $\frac{V}{V^\text{target}}$\\
	\begin{tabular}{ccc}
		\includegraphics[scale=0.4]{case21-r1}&\includegraphics[scale=0.4]{case21-r2}&\includegraphics[scale=0.4]{case21-r3}\\
		(b) run 1&(c) run 2&(d) run 3
	\end{tabular}	
	\caption{Case 2 with 21 bars: (a) evolutions of $C$ and $\frac{V^\text{target}}{V_0}$ for three independent runs and (b, d, d) optimised configurations after each run.}
	\label{fig:case21}
\end{figure}
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{case29-convergence} \\
	(a) Evolutions of $C$ and $\frac{V}{V^\text{target}}$\\
	\begin{tabular}{ccc}
		\includegraphics[scale=0.4]{case29-r1}&\includegraphics[scale=0.4]{case29-r2}&\includegraphics[scale=0.4]{case29-r3}\\
		(b) run 1&(c) run 2&(d) run 3
	\end{tabular}
	\caption{Case 3 with 29 bars: (a) evolutions of $C$ and $\frac{V}{V^\text{target}}$ for three independent runs and (b, d, d) optimised configurations after each run.}
	\label{fig:case29}
\end{figure}

We summarised in Tab.~\ref{tab:summaryComp} the best objective function value at the last iteration among three runs of the three cases reported in Figs.~\ref{fig:case6},~\ref{fig:case21} and~\ref{fig:case29}. The results obtained by the hybrid framework with D-Wave quantum annealers in~\cite{sukulthanasorn4968748quantum} and by the optimal criteria (OC) with classical computers also reported in~\cite{sukulthanasorn4968748quantum} are presented for comparison purposes. It is seen that our framework provides better outcomes, thanks to its capability to reach the optimal solution with a very accurate encoding of the continuous variables with binary ones. The cross-sectional area of each bar in the optimised configurations for all cases are reported in~\ref{app:solutionAreaAllTests}.
\begin{table}[htb]
	\centering
	\caption{Compliance value of the optimised solution. The results obtained with the hybrid framework and Optimal criteria (OC) both reported in~\cite{sukulthanasorn4968748quantum} are shown for comparison purpose.}
	\begin{tabular}{cccc}
		\toprule
		Case&Current work& Sukulthanasorn et al.~\cite{sukulthanasorn4968748quantum}& Optimal criteria (OC)~\cite{sukulthanasorn4968748quantum}  \\
		\midrule
		6 bars&\color{red}{0.38}&0.38&0.39\\
		\hline
		21 bars&\color{red}{5.33}&5.53&5.81\\
		\hline
		29 bars&\color{red}{0.79}&0.82&0.82\\
		\bottomrule
	\end{tabular}
	\label{tab:summaryComp}
\end{table}

\subsection{Three-dimensional case}\label{subsec:3DTest}

In this section, we consider a three-dimensional truss structure whose initial configuration and boundary conditions are shown in Fig.~\ref{fig:3DTest}. The parameter settings are the same as in the previous section, except the initial value which is equal to 0.1 for each bar. The evolutions of the compliance $C$ and of the ratio $\frac{V^\text{target}}{V_0}$ are reported in Fig.~\ref{fig:case3DConvergence}a. It is shown that the objective function gradually decreases while satisfying the volume constraint with a relative error of the optimised solution smaller than 0.4\%. The optimised configuration is shown in Fig.~\ref{fig:case3DConvergence}b. The cross-sectional area of each bar in the optimised configuration is reported in Tab.~\ref{tab:ResCase3D}. 
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{3DTest}
	\caption{Three-dimensional case consisting of 44 members. The length is set to 1 m for the horizontal and the vertical bars. The initial cross-sectional area is set to 0.5 $\text{m}^2$ for all bars.}
	\label{fig:3DTest}
\end{figure}
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{case3D-convergence} \\ 
	(a) Evolutions of $C$ and $\frac{V}{V^\text{target}}$\\
	\includegraphics[scale=1]{case3D-opt}  \\
	(b) Optimised configuration
	\caption{Three-dimensional case: (a) evolutions of $C$ and $\frac{V}{V^\text{target}}$ and (b) optimised configuration.}
	\label{fig:case3DConvergence}
\end{figure}

\section{Conclusions} \label{sec:conclusion}

In this study, we proposed a novel hybrid framework that combines classical computers and quantum annealers for optimising truss structures, leveraging the strength of quantum annealing to solve both the mechanical boundary value problem and the constrained minimisation problem required to adjust the design variables. Unlike classical optimisation methods, our hybrid framework harness the quantum annealing technique to find the better configuration after each optimisation step without the needs of performing arithmetic operations. This innovative approach has shown promising potential to enhance the optimisation process, particularly in handling complex and high-dimensional solution spaces that are common in structural design.

However, the hybrid framework faces challenges related to the limited availability and scalability of current quantum technologies. As quantum hardware continues to advance, we anticipate that these challenges will be addressed, further boosting the applicability of the framework to real-world engineering problems.

The proposed framework can be extended beyond truss structure optimisation. In future work, the proposed framework will be adapted to carry out continuous topology optimisation and to integrate a catalogue of materials and unit cells to be distributed in the design space to form mixed discrete-continuous optimisation problems. The higher-order Taylor's series will be considered to improve the approximation accuracy of the objective functions and constraints in the framework, leading to optimising higher-order polynomial forms, which requires solving higher-order unconstrained binary optimisation (HUBO) formulations after applying the continuous-binary transformation. These directions open up exciting possibilities for applying the hybrid approach to a wide range of engineering and computational design problems with linear and non-linear behaviours.


%%\section*{Acknowledgments}


%%\section*{Data availability}


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections

\appendix
\comment{
\section{Quadratic forms} \label{app:quadForm}

In the unconstrained case (\ref{eq:polynomicalApproxx}), one has the form
\begin{eqnarray}\label{eq:quadraticApprox}
	\mathcal{P}\left(\bm{\delta}\right) =\bm{\delta}^T \vb{g} + \bm{\delta}^T \vb{A} \bm{\delta} 
\end{eqnarray}
where
\begin{eqnarray}
	\vb{g} = \cfrac{\partial f}{\partial \vb{x}} \text{ and } \vb{A} = \cfrac{1}{2} \cfrac{\partial}{\partial \vb{x}}\cfrac{\partial f}{\partial \vb{x}}\,.
\end{eqnarray}

In the constrained case (\ref{eq:polynomicalApproxx2}), the objective function is approximated either by a first-order or second-order Taylor's series (\ref{eq:quadraticApprox}), while the constrains are only approximated by first-order Taylor's series only, such that
\begin{eqnarray}
	&&h_j\left(\vb{x+\bm{\delta}}\right) \approx \Phi^{1}\left(\bm{\delta}; \vb{x}, h_j\right)= h_j\left(\vb{x}\right) + \bm{\delta}^T \cfrac{\partial h_j}{\partial \vb{x}}\,\, \forall j = 1, \ldots, N_h \,, \text{ and} \\
	&&l_j\left(\vb{x+\bm{\delta}}\right) \approx \Phi^{1}\left(\bm{\delta};\vb{x}, l_j\right) = l_j\left(\vb{x}\right) + \bm{\delta}^T \cfrac{\partial l_j}{\partial \vb{x}}  \, \forall j = 1, \ldots, N_l \,.
\end{eqnarray}
Replacing the equations above in Eq.~(\ref{eq:polynomicalApproxx2}), one has
\begin{eqnarray}
\mathcal{P}\left(\bm{\delta}\right)  &=& \bm{\delta}^T \cfrac{\partial f}{\partial \vb{x}} + \cfrac{1}{2} \bm{\delta}^T \left(\cfrac{\partial}{\partial \vb{x}}\cfrac{\partial f}{\partial \vb{x}}\right)  \bm{\delta}  + \sum_{j=1}^{N_h} c_j^h \left[  h_j\left(\vb{x}\right) + \bm{\delta}^T \cfrac{\partial h_j}{\partial \vb{x}} \right]^2 \\
&&+ \sum_{j=1}^{N_l} c_j^l \left[ l_j\left(\vb{x}\right) + \bm{\delta}^T\cfrac{\partial l_j}{\partial \vb{x}}  + \lambda_j \right]^2 \,. \nonumber
\end{eqnarray}
The last equation leads to a quadratic form in terms of $\bm{\delta}$ and $\bm{\lambda}$ as follows
\begin{eqnarray}
\mathcal{P}\left(\bm{\delta}\right) =\mqty[\bm{\delta}^T&\bm{\lambda}^T] \vb{g} + \mqty[\bm{\delta}^T&\bm{\lambda}^T] \vb{A} \mqty[\bm{\delta} \\ \bm{\lambda}]
\end{eqnarray}
where the constant term is irrelevant and omitted, and  
\begin{eqnarray}
	\vb{g} &=& \mqty[\vb{g}_x^T& \vb{g}_\lambda^T]^T \text{ and } \\
	\vb{A} &=& \mqty[\vb{K}_{xx}& \vb{K}_{x\lambda}\\ \vb{K}_{\lambda x}&\vb{K}_{\lambda \lambda}]\,,
\end{eqnarray}
with
\begin{eqnarray}
	\vb{g}_x &=& \cfrac{\partial f}{\partial \vb{x}} + \sum_{j=1}^{N_h} 2 c_j^h h_j\left(\vb{x}\right) \cfrac{\partial h_j\left(\vb{x}\right)}{\partial \vb{x}} + \sum_{j=1}^{N_l} 2 c_j^l  \cfrac{\partial l_j\left(\vb{x}\right)}{\partial \vb{x}} \,,\\
	\vb{g}_\lambda &=& \mqty[2c_1^l l_1\left(\vb{x}\right)&\ldots& 2 c_{N_l}^l  l_{N_l}\left(\vb{x}\right)]^T \,, \\
	\vb{K}_{xx} &=& \cfrac{1}{2} \cfrac{\partial}{\partial \vb{x}}\cfrac{\partial f}{\partial \vb{x}} + \sum_{j=1}^{N_h} c_j^h \cfrac{\partial h_j\left(\vb{x}\right)}{\partial \vb{x}} \left[ \cfrac{\partial h_j\left(\vb{x}\right)}{\partial \vb{x}} \right]^T+ \sum_{j=1}^{N_l} c_j^l \cfrac{\partial l_j\left(\vb{x}\right)}{\partial \vb{x}} \left[ \cfrac{\partial l_j\left(\vb{x}\right)}{\partial \vb{x}} \right]^T\,, \\
	\vb{K}_{x\lambda} &=& \mqty[2c_1^l \cfrac{\partial l_1(\vb{x})}{\partial \vb{x}}&\ldots&	2c_{N_l}^l \cfrac{\partial l_{N_l}(\vb{x})}{\partial \vb{x}}	]\,,\\
	 \vb{K}_{\lambda x} &=& \vb{K}_{x\lambda}^T \,,\text{ and }\\
	 \vb{K}_{\lambda \lambda} &=& \text{diag}\mqty( c_1^l&\ldots& c_{N_l}^l)\,.
\end{eqnarray}
}

\section{Optimised solutions} \label{app:solutionAreaAllTests}

The cross-sectional area of each bar in the optimised configuration is reported in Tabs.~\ref{tab:ResCase1},\ref{tab:ResCase2}, and~\ref{tab:ResCase3} for the three two-dimensional cases in Section~\ref{subsec:2DTest} and  Tab.~\ref{tab:ResCase3D} for the three dimensional case in Section~\ref{subsec:3DTest}, respectively.
\begin{table}[!htb]
	\caption{Optimised solution: cross-sectional area of each bar for Case 1 - 6 bars. Each bar is identified by the coordinates of its extremities.}
	\centering
	\begin{tabular}[t]{ccc}
		\toprule
		Index & Bar & Area ratio \\
		\midrule
		1 & (0,0)-(1,0) & 0.384 \\
		2 & (1,0)-(1,1) & 0.01 \\
		3 & (1,1)-(0,1) & 0.01 \\
		4 & (0,0)-(1,1) & 0.01 \\
		5 & (1,0)-(0,1) & 0.545 \\
		6 & (0,0)-(0,1) & 0.01 \\
		\bottomrule
	\end{tabular}  
	\label{tab:ResCase1}
\end{table}
\begin{table}[!htb]
	\caption{Optimised solution: cross-sectional area of each bar for Case 2 - 21 bars. Each bar is identified by the coordinates of its extremities.}
	\centering
	\begin{tabular}{cc}
	\\
	\toprule 
	\begin{tabular}[t]{ccc}
		Index & Bar & Area ratio \\
		\midrule
		1 & (0,0)-(1,0) & 0.55 \\
		2 & (1,0)-(1,1) & 0.01 \\
		3 & (1,1)-(0,1) & 0.55 \\
		4 & (0,0)-(1,1) & 0.312 \\
		5 & (1,0)-(0,1) & 0.131 \\
		6 & (0,0)-(0,1) & 0.01 \\
		7 & (1,0)-(2,0) & 0.55 \\
		8 & (2,0)-(2,1) & 0.0106 \\
		9 & (2,1)-(1,1) & 0.55 \\
		10 & (1,0)-(2,1) & 0.136 \\
		11 & (2,0)-(1,1) & 0.305 \\
	\end{tabular}  
	&
	\begin{tabular}[t]{ccc}
	Index & Bar & Area ratio \\
	\midrule
	12 & (2,0)-(3,0) & 0.442 \\
	13 & (3,0)-(3,1) & 0.0104 \\
	14 & (3,1)-(2,1) & 0.533 \\
	15 & (2,0)-(3,1) & 0.315 \\
	16 & (3,0)-(2,1) & 0.124 \\
	17 & (3,0)-(4,0) & 0.225 \\
	18 & (4,0)-(4,1) & 0.0881 \\
	19 & (4,1)-(3,1) & 0.0824 \\
	20 & (3,0)-(4,1) & 0.126 \\
	21 & (4,0)-(3,1) & 0.314 \\
	\end{tabular} \\
	\bottomrule
	\end{tabular}
	\label{tab:ResCase2}
\end{table}

\begin{table}[!htb]
	\centering
	\caption{Optimised solution: cross-sectional area of each bar for Case 3 - 29 bars. Each bar is identified by the coordinates of its extremities.}
	\begin{tabular}{cc}
	 \\ \toprule
	 \begin{tabular}[t]{ccc}
	 	Index & Bar & Area ratio \\
	 	\midrule
	 	1 & (0,0)-(1,0) & 0.55 \\
	 	2 & (1,0)-(1,1) & 0.0401 \\
	 	3 & (1,1)-(0,1) & 0.0113 \\
	 	4 & (0,0)-(1,1) & 0.41 \\
	 	5 & (1,0)-(0,1) & 0.0218 \\
	 	6 & (0,0)-(0,1) & 0.0161 \\
	 	7 & (1,0)-(2,0) & 0.544 \\
	 	8 & (2,0)-(2,1) & 0.0408 \\
	 	9 & (2,1)-(1,1) & 0.01 \\
	 	10 & (1,0)-(2,1) & 0.0877 \\
	 	11 & (2,0)-(1,1) & 0.465 \\
	 	12 & (2,0)-(3,0) & 0.0108 \\
	 	13 & (3,0)-(3,1) & 0.0261 \\
	 	14 & (3,1)-(2,1) & 0.0396 \\
	 	15 & (2,0)-(3,1) & 0.459 \\
	 \end{tabular} & \begin{tabular}[t]{ccc}
	 Index & Bar & Area ratio \\
	 \midrule
	 16 & (3,0)-(2,1) & 0.0398 \\
	 17 & (1,1)-(1,2) & 0.01 \\
	 18 & (1,2)-(0,2) & 0.549 \\
	 19 & (0,1)-(1,2) & 0.0487 \\
	 20 & (1,1)-(0,2) & 0.493 \\
	 21 & (0,1)-(0,2) & 0.0104 \\
	 22 & (2,1)-(2,2) & 0.0811 \\
	 23 & (2,2)-(1,2) & 0.54 \\
	 24 & (1,1)-(2,2) & 0.401 \\
	 25 & (2,1)-(1,2) & 0.0908 \\
	 26 & (3,1)-(3,2) & 0.0239 \\
	 27 & (3,2)-(2,2) & 0.0221 \\
	 28 & (2,1)-(3,2) & 0.0103 \\
	 29 & (3,1)-(2,2) & 0.528 \\
	 \end{tabular} \\
	 \bottomrule
	\end{tabular}
	\label{tab:ResCase3}
\end{table}

\begin{table}
	\centering
	\caption{Optimised solution: cross-sectional area of each bar for the three-dimensional case - 44 bars. Each bar is identified by the coordinates of its extremities.}
	\begin{tabular}{cc}
		\\ \toprule
		\begin{tabular}[t]{ccc}
			Index & Bar & Area ratio \\
			\midrule
			1 & (0,0,0)-(0,0,1) & 0.288 \\
			2 & (0,0,0)-(1,0,1) & 0.0103 \\
			3 & (0,0,0)-(1,1,1) & 0.219 \\
			4 & (0,0,0)-(0,1,1) & 0.177 \\
			5 & (1,0,0)-(0,0,1) & 0.0106 \\
			6 & (1,0,0)-(1,0,1) & 0.0134 \\
			7 & (1,0,0)-(1,1,1) & 0.0101 \\
			8 & (1,0,0)-(0,1,1) & 0.01 \\
			9 & (1,1,0)-(0,0,1) & 0.011 \\
			10 & (1,1,0)-(1,0,1) & 0.0112 \\
			11 & (1,1,0)-(1,1,1) & 0.299 \\
			12 & (1,1,0)-(0,1,1) & 0.0195 \\
			13 & (0,1,0)-(0,0,1) & 0.0172 \\
			14 & (0,1,0)-(1,0,1) & 0.01 \\
			15 & (0,1,0)-(1,1,1) & 0.01 \\
			16 & (0,1,0)-(0,1,1) & 0.251 \\
			17 & (0,0,1)-(1,0,1) & 0.0108 \\
			18 & (0,0,1)-(1,1,1) & 0.01 \\
			19 & (0,0,1)-(0,1,1) & 0.0103 \\
			20 & (1,0,1)-(1,1,1) & 0.0105 \\
			21 & (1,0,1)-(0,1,1) & 0.0103 \\
			22 & (1,1,1)-(0,1,1) & 0.0113 \\
		\end{tabular} & \begin{tabular}[t]{ccc}
			Index & Bar & Area ratio \\
			\midrule
			23 & (0,0,1)-(0,0,2) & 0.275 \\
			24 & (0,0,1)-(1,0,2) & 0.0102 \\
			25 & (0,0,1)-(1,1,2) & 0.0103 \\
			26 & (0,0,1)-(0,1,2) & 0.0147 \\
			27 & (1,0,1)-(0,0,2) & 0.0104 \\
			28 & (1,0,1)-(1,0,2) & 0.0103 \\
			29 & (1,0,1)-(1,1,2) & 0.0103 \\
			30 & (1,0,1)-(0,1,2) & 0.0103 \\
			31 & (1,1,1)-(0,0,2) & 0.211 \\
			32 & (1,1,1)-(1,0,2) & 0.01 \\
			33 & (1,1,1)-(1,1,2) & 0.0126 \\
			34 & (1,1,1)-(0,1,2) & 0.0106 \\
			35 & (0,1,1)-(0,0,2) & 0.189 \\
			36 & (0,1,1)-(1,0,2) & 0.0102 \\
			37 & (0,1,1)-(1,1,2) & 0.01 \\
			38 & (0,1,1)-(0,1,2) & 0.0113 \\
			39 & (0,0,2)-(1,0,2) & 0.01 \\
			40 & (0,0,2)-(1,1,2) & 0.0143 \\
			41 & (0,0,2)-(0,1,2) & 0.0159 \\
			42 & (1,0,2)-(1,1,2) & 0.0104 \\
			43 & (1,0,2)-(0,1,2) & 0.0105 \\
			44 & (1,1,2)-(0,1,2) & 0.0101 \\
		\end{tabular} \\
		\bottomrule
	\end{tabular}
	\label{tab:ResCase3D}
\end{table}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%
%\bibliographystyle{elsarticle-num-names} 
\bibliographystyle{spmpsci}

\bibliography{reference}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

%%\begin{thebibliography}{00}

%% \bibitem{label}
%% Text of bibliographic item

%%\bibitem{}

%%\end{thebibliography}
\end{document}
%\endinput
%%
%% End of file `elsarticle-template-num.tex'.
