\newpage
\appendix

\input{sections/3_background}

\input{sections/appendix_post}
% \label{sec:appendix_bachground}

% \section{Proof for DCPO reducing DPO}
% \label{sec:app_proof}
% Here, we highlight a result that reduces DCPO to DPO when the prompts are the same.
% \paragraph{Lemma 1.} \textit{Under the case where $\mathcal{D}_{\text{define}}=\{x^w_0, c, x^l_0, c\}$, that is, captions are the same for the preferred and less preferred images pairs, $L_{\text{DPO}}(\theta; \mathcal{D}_{\text{DPO}}; \beta; p_{\text{ref}}) = L_{\text{DCPO}}(\theta; \mathcal{D}_{\text{define}}; \beta; p_{\text{ref}})$, where $\mathcal{D}_{\text{DPO}}=\{c, x^w_0 x^l_0\}.$}

% \textit{Proof.}

% \begin{equation}
%     \begin{split}
%         \mathcal{L}_{\text{DCPO}}(\theta;\mathcal{D'}, \beta, p_{\text{ref}}) & = \mathit{\mathbb{E}}_{(x^w_0, x^l_0, z^w, z^l) \sim \mathcal{D'}}
%         \left[\log \left(\sigma \left(\beta \log \frac{p_\theta(x^w_0, z^w)}{p_{\text{ref}}(x^w_0, z^w)} - 
%         \beta \log \frac{p_\theta(x^l_0, z^l)}{p_{\text{ref}}(x^l_0, z^l)} \right) \right)\right] \\
%         & = \mathit{\mathbb{E}}_{(x^w_0, x^l_0, z^w, z^l) \sim \mathcal{D'}}
%         \left[\log \left( \sigma \left(\beta \log 
%         \frac{p_\theta (x^w_0|z^w) p_\theta(z^w)}{p_{\text{ref}}(x^w_0|z^w)p_{\text{ref}}(z^w)} \right. \right. \right.  \left. \left. \left. - \beta \log \frac{p_\theta(x^l_0|z^l) p_\theta(z^l)}{p_{\text{ref}}(x^l_0|z^l)p_{\text{ref}}(z^l)} \right) \right) \right] \\
%     \end{split}
% \end{equation}

% \begin{equation}
%     \begin{split}
%          \mathcal{L}_{\text{DCPO}}(\theta;\mathcal{D}_{\text{define}}, \beta, p_{\text{ref}}) & \stackrel{z^w=z^l=c}{=} \mathit{\mathbb{E}}_{(x^w_0, c, x^l_0, c) \sim \mathcal{D}_\text{define}} \left[ \log \left(\sigma \left(\frac{p_\theta(c)}{p_{\text{ref}}(c)} \left ( \beta \log \frac{p_\theta(x^w_0|c)}{p_{\text{ref}}(x^w_0|c)} - \beta \log \frac{p_\theta (x^l_0|c)}{p_\text{ref}(x^l_0|c)} \right) \right) \right) \right] \\
%          & \stackrel{\frac{p_\theta(c)}{p_{\text{ref}}(c)}=C}{=} \mathit{\mathbb{E}}_{(x^w_0, x^l_0, c) \sim \mathcal{D}_\text{DPO}} \left[ \log \left(\sigma \left(C. \beta \log \frac{p_\theta(x^w_0|c)}{p_{\text{ref}}(x^w_0|c)} - C. \beta \log \frac{p_\theta (x^l_0|c)}{p_\text{ref}(x^l_0|c)} \right) \right) \right] \\
%          & = \mathcal{L}_{\text{DPO}}(\theta; \mathcal{D}_\text{DPO}, \beta, p_{\text{ref}} )
%     \end{split}
% \end{equation}

% Where $C$ is a constant value, the proof follows from applying the Bayes rule and substituting $z^w=z^l=c$.

\section{Pick-Double Caption Dataset}
\label{sec:appendix_double_caption_dataset}
In this section, we provide details about the \textit{Pick-Double Caption} dataset. As discussed in Section \ref{sec:pick-double-caption}, we sampled 20,000 instances from the Pick-a-Pic v2 dataset and excluded those with equal preference scores. We plot the distribution of the original prompts, as shown in Figure \ref{fig:token-distribution}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{images/distribution_tokens.pdf}
    \vspace{-1em}
    \caption{Token distribution of original prompt.}
    \label{fig:token-distribution}
\end{figure}

We observed that some prompts contained only one or two words, while others were excessively long. To ensure a fair comparison, we removed prompts that were too short or too long, leaving us with approximately 17,000 instances. We then generated captions using two state-of-the-art models, LLaVA-1.6-34B, and Emu2-32B. Figure \ref{fig:pick_double_caption_samples} provides examples from the dataset.

As explained in Section \ref{sec:pick-double-caption}, we utilized two types of prompts to generate captions: 1) Conditional prompt and 2) Non-conditional prompt. Below, we outline the specific prompts used for each captioning method.

\begin{tcolorbox}[colback=black!5, colframe=black, title= Example of Conditional Prompt]
Using one sentence, describe the image based on the following prompt: \textit{playing chess tournament on the moon.}
\end{tcolorbox}

\begin{tcolorbox}[colback=black!5, colframe=black, title= Example of Non-Conditional Prompt]
Using one sentence, describe the image.
\end{tcolorbox}


Table \ref{tab:tokens-detail} presents a statistical analysis of the \textit{Pick-Double Caption} dataset. With the non-conditional prompt method, we found that the average token length of captions generated by LLaVA is similar to that of the original prompts. However, captions generated by LLaVA using conditional prompts are twice as long as the original prompts. Additionally, Emu2 generated captions that, on average, are half the length of the original prompts for both methods.

\input{Tables/token_details}



\begin{figure}[h]
    \centering
    
    \includegraphics[width=1\linewidth]{images/dataset_preview.pdf}
    \vspace{-2em}
    \caption{Examples of Pick-Double Caption dataset.}
    \label{fig:pick_double_caption_samples}
\end{figure}

\section{More Details on Perturbation Method}
\label{sec:appendix_perturbation}

\input{Tables/perturbation_examples}

We provide the setups for the LLM-based perturbation process involved in the DCPO-p and DCPO-h pipelines. Similarly to the method of constructing paraphrasing adversarial attacks as synonym-swapping perturbation by \citet{dipper}, we use DIPPER \citep{dipper}, a text generation model built by fine-tuning T5-XXL~\citep{t5}, to create semantically perturbed captions or prompts, as shown in Table \ref{tab:perturbation-examples}. Our three levels of perturbation are achieved by only altering the setting of lexicon diversity (0 to 100) in DIPPER - we use 40 for \textbf{Weak}, 60 for \textbf{Medium}, and 80 for \textbf{Strong}. We also use \textit{"Text perturbation for variable text-to-image prompt."} to prompt the perturbation. We hereby provide a code snippet to showcase the whole process to perturb a sample input:

\begin{lstlisting}[language=Python]
from transformers import T5Tokenizer, T5ForConditionalGeneration
class DipperParaphraser(object):
    # As defined in https://huggingface.co/kalpeshk2011/dipper-paraphraser-xxl
    
prompt = "Text perturbation for variable text-to-image prompt."
input_text = "playing chess tournament on the moon."

dp = DipperParaphraser()

cap_weak = dp.paraphrase(input_text, lex_diversity=40, prefix=prompt, do_sample=True, top_p=0.75, top_k=None, max_length=256)
cap_medium = dp.paraphrase(input_text, lex_diversity=60, prefix=prompt, do_sample=True, top_p=0.75, top_k=None, max_length=256)
cap_strong = dp.paraphrase(input_text, lex_diversity=80, prefix=prompt, do_sample=True, top_p=0.75, top_k=None, max_length=256)
\end{lstlisting}


\section{More Details about Training of Diffusion Models}
\label{sec:appendix_details_train}
In this section, we provide a detailed explanation of the fine-tuning methods used. We fine-tuned SD 2.1 with the best hyperparameters reported in the original papers for \( \text{SFT}_{\text{Chosen}} \), Diffusion-DPO, and MaPO, using 8 A100Ã—80 GB GPUs for all models. To fine-tune SD 2.1 with Diffusion and MaPO methods, we used a dataset \(D=\{c,x^w,x^l\}\) where \(c,x^w,x^l\) represent the prompt, preferred image, and less preferred image. To optimize a SD2.1 with \( \text{SFT}_{\text{Chosen}} \) we utilized a dataset \(D=\{c,x^w\}\) where \(c,x^w\) represent the prompt, preferred image and image. In this paper, dataset $D$ represents the sampled and cleaned version of the Pick-a-Pic v2 dataset. Additionally, we clarify the DCPO models DCPO-c, DCPO-p, and DCPO-h. In this paper, DCPO-c and DCPO-p refer to SD 2.1 models fine-tuned with the DCPO method, using LLaVA and Emu2 for captioning and perturbation methods at three distinct levels, respectively. The main results for DCPO-p in the text are based on weak perturbation applied to the original prompt. In Table \ref{tab:hyphotesis2-results}, we also report DCPO-p's performance across other perturbation levels.


For DCPO-h, we applied perturbations to both the preferred and less preferred captions generated by LLaVA. The reported results for DCPO-h reflect a medium level of perturbation applied to the less preferred caption. In Table \ref{tab:hyphotesis2-results}, we present the performance of DCPO-h across various perturbation levels, including perturbations to the preferred captions. Additionally, in Table \ref{tab:emu2-perturbed-caption-results}, we show the results for DCPO-h using captions generated by Emu2.

\input{Tables/emu2_caption_perturbation_results}


The key findings indicate that perturbation on short captions not only fails to improve performance but also produces worse outcomes compared to DCPO-c (Emu2).

Additionally, we conducted more experiments on in-distribution and out-of-distribution data. For this, we generated out-of-distribution data using LLaVA and Emu2 in the captioning setup. As shown in Figure \ref{fig:in-vs-out-dcpo-c}, in-distribution data generally outperformed out-of-distribution data. However, the most significant improvement was observed with the hybrid method, as reported in Figure \ref{fig:in-vs-out}.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{images/in_vs_out_plot_dcpo_c.pdf}
    \vspace{-2em}
    \caption{Comparison of DCPO-c performance on in-distribution and out-of-distribution data.}
    \label{fig:in-vs-out-dcpo-c}
\end{figure}


Table \ref{tab:beta-hyperparameter-results} presents the performance details for different values of \( \beta \), conducted using the medium level of DCPO-h. The results indicate that while lower values of \( \beta \) significantly improve GenEval and HPSv2.1 on average, the optimal value for \( \beta \) is 5000. We suggest that this hyperparameter may vary based on the dataset and task.

\input{Tables/hyperparameter_experiment}

\section{GPT-4o as an Evaluator}
\label{gpt4o_evaluator}
To obtain binary preferences from the API evaluator, we followed the approach outlined in the MaPO paper \citep{hong2024marginawarepreferenceoptimizationaligning}. Similar to Diffusion-DPO, we used three distinct questions to evaluate the images generated by the DCPO-h and Diffusion-DPO models, both utilizing SD 2.1 as the backbone. These questions were presented to the GPT-4o model to identify the preferred image. Below, we provide details of the prompts used.

\begin{tcolorbox}[colback=black!5, colframe=black, title= GPT-4o Evaluation Prompt for Q1: General Preference]
Select the output (a) or (b) that best matches the given prompt. Choose your preferred output, which can be subjective. Your answer should ONLY contain: Output (a) or Output (b).
\\

\#\# Prompt:\\
\texttt{\{prompt\}}
\\

\#\# Output (a):\\
The first image attached.
\\

\#\# Output (b):\\
The second image attached.
\\
\\

\#\# Which image do you prefer given the prompt?
\end{tcolorbox}

\begin{tcolorbox}[colback=black!5, colframe=black, title= GPT-4o Evaluation Prompt for Q2: Visual Appeal]
Select the output (a) or (b) that best matches the given prompt. Choose your preferred output, which can be subjective. Your answer should ONLY contain: Output (a) or Output (b).
\\

\#\# Prompt:\\
\texttt{\{prompt\}}
\\

\#\# Output (a):\\
The first image attached.
\\

\#\# Output (b):\\
The second image attached.
\\
\\

\#\# Which image is more visually appealing?
\end{tcolorbox}


\begin{tcolorbox}[colback=black!5, colframe=black, title= GPT-4o Evaluation Prompt for Q3: Prompt Alignment]
Select the output (a) or (b) that best matches the given prompt. Choose your preferred output, which can be subjective. Your answer should ONLY contain: Output (a) or Output (b).
\\

\#\# Prompt:\\
\texttt{\{prompt\}}
\\

\#\# Output (a):\\
The first image attached.
\\

\#\# Output (b):\\
The second image attached.
\\
\\

\#\# Which image better fits the text description?
\end{tcolorbox}

\newpage
\section{Additional Generation Samples}
\label{sec:app_additional_examples}
We also present additional samples for qualitative comparison generated by SD 2.1, \( \text{SFT}_{\text{Chosen}} \), Diffusion-DPO, MaPO, and DCPO-h from prompts on Pickscore, HPSv2, and GenEval benchmarks.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{images/appendix_more_samples_hps.pdf}
    \caption{Additional generated outcomes using prompts from HPSv2 benchmark.}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{images/appendix_more_samples_pickscore2.pdf}
    \caption{Additional generated outcomes using prompts from Pickscore benchmark.}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{images/appendix_more_samples_geneval2.pdf}
    \caption{Additional generated outcomes using prompts from GenEval benchmark.}
    \label{fig:enter-label}
\end{figure}

