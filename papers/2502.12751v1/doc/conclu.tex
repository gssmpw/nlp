\section{Conclusion}
In this paper, we propose a novel approach that integrates conditional generative models with DAS for circuit generation. 
Our framework begins with the design of CircuitVQ, a circuit tokenizer trained using a Circuit AutoEncoder. 
Building on this, we develop CircuitAR, a masked autoregressive model that utilizes CircuitVQ as its tokenizer. 
CircuitAR can generate preliminary circuit structures directly from truth tables, which are then refined by DAS to produce functionally equivalent circuits. 
The scalability and capability emergence of CircuitAR highlights the potential of masked autoregressive modeling for circuit generation tasks, akin to the success of large models in language and vision domains. 
Extensive experiments demonstrate the superior performance of our method, underscoring its efficiency and effectiveness. 
This work bridges the gap between probabilistic generative models and precise circuit generation, offering a robust and automated solution for logic synthesis.