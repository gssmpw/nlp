\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{comment}
\usepackage{url}
\usepackage{balance}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{soul}
\usepackage{colortbl}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cm}{\ding{51}}%
\newcommand{\xm}{\ding{55}}%

\usepackage{color}

\definecolor{Comment}{RGB}{97,161,176}

\definecolor{btfGreen}{RGB}{51,160,44}
\definecolor{btfRed}{RGB}{190,60,90}

\definecolor{bleuUni}{RGB}{0, 157, 224}
\definecolor{marronUni}{RGB}{68, 58, 49}
\definecolor{grayMarronUni}{RGB}{60, 60, 60}
\definecolor{grayBleuUni}{RGB}{118, 118, 118}

\definecolor{bluecite}{HTML}{009DE0}

\definecolor{Paired-2}{RGB}{166,206,227}
\definecolor{Paired-1}{RGB}{31,120,180}
\definecolor{Paired-4}{RGB}{178,223,138}
\definecolor{Paired-3}{RGB}{51,160,44}
\definecolor{Paired-6}{RGB}{251,154,153}
\definecolor{Paired-5}{RGB}{227,26,28}
\definecolor{Paired-8}{RGB}{253,191,111}
\definecolor{Paired-7}{RGB}{255,127,0}
\definecolor{Paired-10}{RGB}{202,178,214}
\definecolor{Paired-9}{RGB}{106,61,154}
\definecolor{Paired-12}{RGB}{255,255,153}
\definecolor{Paired-11}{RGB}{177,89,40}
\definecolor{Accent-1}{RGB}{127,201,127}
\definecolor{Accent-2}{RGB}{190,174,212}
\definecolor{Accent-3}{RGB}{253,192,134}
\definecolor{Accent-4}{RGB}{255,255,153}
\definecolor{Accent-5}{RGB}{56,108,176}
\definecolor{Accent-6}{RGB}{240,2,127}
\definecolor{Accent-7}{RGB}{191,91,23}
\definecolor{Accent-8}{RGB}{102,102,102}
\definecolor{Spectral-1}{RGB}{158,1,66}
\definecolor{Spectral-2}{RGB}{213,62,79}
\definecolor{Spectral-3}{RGB}{244,109,67}
\definecolor{Spectral-4}{RGB}{253,174,97}
\definecolor{Spectral-5}{RGB}{254,224,139}
\definecolor{Spectral-6}{RGB}{255,255,191}
\definecolor{Spectral-7}{RGB}{230,245,152}
\definecolor{Spectral-8}{RGB}{171,221,164}
\definecolor{Spectral-9}{RGB}{102,194,165}
\definecolor{Spectral-10}{RGB}{50,136,189}
\definecolor{Spectral-11}{RGB}{94,79,162}
\definecolor{Set1-1}{RGB}{228,26,28}
\definecolor{Set1-2}{RGB}{55,126,184}
\definecolor{Set1-3}{RGB}{77,175,74}
\definecolor{Set1-4}{RGB}{152,78,163}
\definecolor{Set1-5}{RGB}{255,127,0}
\definecolor{Set1-6}{RGB}{255,255,51}
\definecolor{Set1-7}{RGB}{166,86,40}
\definecolor{Set1-8}{RGB}{247,129,191}
\definecolor{Set1-9}{RGB}{153,153,153}
\definecolor{Set2-1}{RGB}{102,194,165}
\definecolor{Set2-2}{RGB}{252,141,98}
\definecolor{Set2-3}{RGB}{141,160,203}
\definecolor{Set2-4}{RGB}{231,138,195}
\definecolor{Set2-5}{RGB}{166,216,84}
\definecolor{Set2-6}{RGB}{255,217,47}
\definecolor{Set2-7}{RGB}{229,196,148}
\definecolor{Set2-8}{RGB}{179,179,179}
\definecolor{Dark2-1}{RGB}{27,158,119}
\definecolor{Dark2-2}{RGB}{217,95,2}
\definecolor{Dark2-3}{RGB}{117,112,179}
\definecolor{Dark2-4}{RGB}{231,41,138}
\definecolor{Dark2-5}{RGB}{102,166,30}
\definecolor{Dark2-6}{RGB}{230,171,2}
\definecolor{Dark2-7}{RGB}{166,118,29}
\definecolor{Dark2-8}{RGB}{102,102,102}
\definecolor{Reds-1}{RGB}{255,245,240}
\definecolor{Reds-2}{RGB}{254,224,210}
\definecolor{Reds-3}{RGB}{252,187,161}
\definecolor{Reds-4}{RGB}{252,146,114}
\definecolor{Reds-5}{RGB}{251,106,74}
\definecolor{Reds-6}{RGB}{239,59,44}
\definecolor{Reds-7}{RGB}{203,24,29}
\definecolor{Reds-8}{RGB}{165,15,21}
\definecolor{Reds-9}{RGB}{103,0,13}
\definecolor{Greens-1}{RGB}{247,252,245}
\definecolor{Greens-2}{RGB}{229,245,224}
\definecolor{Greens-3}{RGB}{199,233,192}
\definecolor{Greens-4}{RGB}{161,217,155}
\definecolor{Greens-5}{RGB}{116,196,118}
\definecolor{Greens-6}{RGB}{65,171,93}
\definecolor{Greens-7}{RGB}{35,139,69}
\definecolor{Greens-8}{RGB}{0,109,44}
\definecolor{Greens-9}{RGB}{0,68,27}
\definecolor{Blues-1}{RGB}{247,251,255}
\definecolor{Blues-2}{RGB}{222,235,247}
\definecolor{Blues-3}{RGB}{198,219,239}
\definecolor{Blues-4}{RGB}{158,202,225}
\definecolor{Blues-5}{RGB}{107,174,214}
\definecolor{Blues-6}{RGB}{66,146,198}
\definecolor{Blues-7}{RGB}{33,113,181}
\definecolor{Blues-8}{RGB}{8,81,156}
\definecolor{Blues-9}{RGB}{8,48,107}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\DeclareRobustCommand{\hlgrey}[1]{{\sethlcolor{gray!30}\hl{#1}}}
\DeclareRobustCommand{\hlsta}[1]{{\sethlcolor{Paired-5!15}\hl{#1}}}
\DeclareRobustCommand{\hlless}[1]{{\sethlcolor{Paired-7!15}\hl{#1}}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\hypersetup{%draft,
	colorlinks=true, %set true if you want colored links
	linktoc=all,     %set to all if you want both sections and subsections linked
	linkcolor={black},
	urlcolor={blue},
	anchorcolor=black, %choose some color if you want links to stand out
	citecolor=black,
}

% Tetris cheat code
\setlength{\textfloatsep}{5pt}
\setlength{\parsep}{0pt}
\setlength{\parskip}{0pt}

\newcommand{\work}[2]{\textcolor{blue}{#1} - \textcolor{red}{who: #2}}

% for algorithmic
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{\hfill$\triangleright$\textcolor{blue}{\textit{#1}}}

\newcommand{\otac}[1]{OTAC (#1)}
\newcommand{\dwotac}{FERTAC} % -> First Efficient Resources for TAsk Chains
\newcommand{\notac}{2CATAC}  % -> Two-Choice Allocation for TAsk Chains
\newcommand{\opt}{HeRAD}     % -> Heterogeneous Resource Allocation using Dynamic Programming
\newcommand{\tasks}{\mathcal{T}}
\newcommand{\solution}{S}
\newcommand{\tbig}{\mathcal{B}}
\newcommand{\tlittle}{\mathcal{L}}
\newcommand{\msol}{\mathsf{S}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}

\title{Scheduling Strategies for Partially-Replicable Task Chains on Two Types of Resources \thanks{Work partially supported by the National Research Agency under the France 2030 program.}\\ \large{Working paper version with optimality proof}}
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
%}

\author{
    \IEEEauthorblockN{Diane Orhan$^{1}$, Yacine Idouar$^{2}$, Laércio L. Pilla$^{1}$, Adrien Cassagne$^{2}$, Denis Barthou$^{3}$, Christophe Jégo$^{4}$}
    %\vspace{0.5cm}
    \IEEEauthorblockA{$^{1}$University of Bordeaux, CNRS, Bordeaux INP, Inria, LaBRI, UMR5800, Talence, France -- email: diane.orhan@inria.fr}
    %\vspace{0.5cm}
    \IEEEauthorblockA{$^{2}$LIP6, Sorbonne Université, CNRS, UMR7606, Paris, France}
    \IEEEauthorblockA{$^{3}$Bordeaux INP, Talence, France}
    \IEEEauthorblockA{$^{4}$Univ. Bordeaux, CNRS, Bordeaux INP, IMS, UMR5218, Talence, France\\emails: diane.orhan@inria.fr, yacine.idouar@lip6.fr, laercio.pilla@inria.fr,\\adrien.cassagne@lip6.fr, denis.barthou@enseirb-matmeca.fr, christophe.jego@ims-bordeaux.fr}
}

\maketitle

\begin{abstract}
The arrival of heterogeneous (or hybrid) multicore architectures on parallel platforms has brought new performance opportunities for applications and efficiency opportunities to systems.
They have also increased the challenges related to thread scheduling, as tasks’ execution times will vary depending if they are placed in big (performance) cores or little (efficient) ones.
In this paper, we focus on the challenges heterogeneous multicore problems bring to partially-replicable task chains, such as the ones that implement digital communication standards in Software-Defined Radio (SDR).
Our objective is to maximize the throughput of these task chains while also minimizing their power consumption.
We model this problem as a pipelined workflow scheduling problem using pipelined and replicated parallelism on two types of resources whose objectives are to minimize the period and to use as many little cores as necessary.
We propose two greedy heuristics (FERTAC and 2CATAC) and one optimal dynamic programming (HeRAD) solution to the problem.
We evaluate our solutions and compare the quality of their schedules (in period and resource utilization) and their execution times using synthetic task chains and an implementation of the DVB-S2 communication standard running on StreamPU.
Our results demonstrate the benefits and drawbacks of the different proposed solutions.
On average, FERTAC and 2CATAC achieve near-optimal solutions, with periods that are less than 10\% worse than the optimal (HeRAD) using fewer than 2 extra cores.
These three scheduling strategies now enable programmers and users of StreamPU to transparently make use of heterogeneous multicore processors and achieve throughputs that differ from their theoretical maximums by less than 8\% on average.
\end{abstract}

\begin{IEEEkeywords}
Throughput optimization, period minimization, heterogeneous architectures, big.LITTLE, energy efficiency, pipelining, replication, streaming, software-defined radio, SDR.
\end{IEEEkeywords}

\section{Introduction}\label{sec:intro}

Multicore processor architectures composed of different types of cores (also known as \textit{heterogeneous}, \textit{hybrid}, or \textit{asymmetric}) are increasingly common nowadays.
What may have started on low power processors with ARM’s big.LITTLE architecture in
2011~\cite{randhawa2013software}, has now become present in processors produced by Apple (since 2020), Intel (since 2021)~\cite{rotem2022intel}, and AMD (since 2023).
A common feature in these processors is an ISA shared between the high-performance (or \textit{big}) and the high-efficiency (or \textit{little}) cores, which enables the execution of application in both types of cores transparently. 

Heterogeneous multicore architectures have multiple advantages, such as providing the opportunity to save energy by turning off big cores when unnecessary (for battery or environmental reasons).
They have also been shown to outperform homogeneous architectures under a fixed budget (be it area, power, or both)~\cite{kumar2003single,rodrigues2011performance}.
We invite the reader to check the survey by Mittal on these processors~\cite{mittal2016survey} for more information.
These advantages come with the drawback of higher complexity when programming parallel applications for these architectures, as one has to decide how to balance the workload between different cores and core types.
When not taking care of their differences, a heterogeneity-oblivious solution can result in lower performance and higher energy consumption (while some cores could be better used).

In this context, we focus on the special characteristics of a kind of parallel application composed of partially-replicable task chains, such as the ones that implement digital communication standards in Software-Defined Radio (SDR)~\cite{cassagne2023spu}.
We consider the problem of scheduling these streaming task chains on two types of resources (heterogeneous multicores) to optimize their throughput and power consumption in a transparent manner, reducing complexity for programmers and end users.
Our main contributions in this paper are as follows:
\begin{itemize}
	\item We provide a formulation of this throughput optimization (period minimization) problem in Section~\ref{sec:def};
	\item We propose two greedy heuristics and one optimal dynamic programming solution in Section~\ref{sec:heuristics} and \ref{sec:dp};
	\item We evaluate our new scheduling strategies using simulation, and a real-world digital communication standard (DVB-S2~\cite{dvbs2}) by implementing our strategies~\cite{amp-scheduling} to work with the StreamPU open source DSEL and runtime system~\cite{cassagne2023spu} in Section~\ref{sec:eval}.
\end{itemize}

The remaining sections of this paper are organized as follows: Section~\ref{sec:rw} discusses related works, and Section~\ref{sec:conclusion} provides concluding remarks.

\section{Related Work}\label{sec:rw}

%\work{other work on heterogeneous architectures (performance and energy)}{Adrien}

Our main interest lies in the problem of throughput optimization for partially-replicable task chains.
We focus on solutions using pipeline and replicated parallelism, and interval mapping~\cite{benoit2013asurvey}.
As we are unaware of any solutions to our specific research problem in the state of the art, we will focus our discussion here on variations of this problem.

\textbf{Throughput on homogeneous architectures:}
OTAC~\cite{orhan2023} provides an optimal solution for partially-replicable task chains using pipeline and replicated parallelism.
We provide more details about OTAC in Section~\ref{sec:heuristics}, as our two greedy heuristics are based on its main ideas.
OTAC itself is inspired by Nicol’s algorithm~\cite{nicol1994rectilinear,pinar2004fast}, which is an optimal solution for the Chain-to-chains partitioning (CCP) problem where only pipelining is possible.
Finally, when all tasks are replicable, the optimal solution in homogeneous resources is to build a pipeline with a single stage that is replicated across all resources~\cite{benoit2010complexity}.
Nonetheless, this does not apply for heterogeneous architectures.

\textbf{Throughput on heterogeneous architectures:}
Benoit and Robert offered three heuristics for building interval mappings on unrelated heterogeneous architectures~\cite{benoit2008}.
Among them, BSL and BSC use a combination of binary search and greedy allocation, which is similar to the general scheme of OTAC and our proposed heuristics.
These heuristics, however, do not consider replicated parallelism.

\textbf{Makespan on heterogeneous architectures:} 
Topcuoglu et al.~\cite{topcuoglu99} introduced HEFT (one of the most used heuristics for this kind of problem) and the CPOP to schedule directed acyclic graphs (DAGs) over unrelated heterogeneous resources.
Eyraud-Dubois and Krumar~\cite{dubois2020} proposed HeteroPrioDep to schedule DAGs over two types of unrelated resources. %using a spoliation mechanism to stop tasks when their preferred resources become available.
Sadly, none of these strategies applies for throughput optimization, nor for pipeline and replicated parallelism.
Agullo et al.~\cite{agullo2015} studied the performance of dynamic schedulers on two types of unrelated resources through simulation and real-world experiments.
We also employ both kinds of experiments in our evaluation, but dynamic schedulers from current runtime systems are usually inefficient at our task granularity of interest (tens to thousands of $\mu$s)~\cite{slaughter2020}.
Benavides et al.~\cite{benavides2014} proposed a heuristic for the flow shop scheduling problem on unrelated resources, but their solution is not easily transposable for pipeline and replicated parallelism.

\textbf{SDR on heterogeneous architectures:} Mack et al.~\cite{mack2022gnu} proposed the use of the CEDR heterogeneous runtime system to encapsulate and enable GNU~Radio’s signal processing blocks (tasks) in FPGA and GPU-based systems on chip.
They use dynamic scheduling heuristics and imitation learning to co-schedule GNU~Radio’s blocks with other applications.
In contrast, our approaches build static pipeline decompositions and schedules for a lower runtime overhead.
We believe our algorithms can be integrated to GNU~Radio in its future version (4.0)~\cite{morman2022thefuture} when it will abandon its thread-per-block schedule, enabling better performance by avoiding its current issues related to locality and OS scheduling policies~\cite{bloessl2019benchmarking}.

\section{Problem Definition}\label{sec:def}

% initial points about the problem
The problem of maximizing the throughput of a task chain over two kinds of resources can be modeled as a pipelined workflow scheduling problem~\cite{benoit2013asurvey}.
The workflow can be described as a linear chain of $n$ tasks $\tasks{} = \{\tau_1,\ldots,\tau_n\}$, meaning $\tau_i$ can only execute after $\tau_{i-1}$.
Tasks are partitioned into two subsets $\tasks{}_{rep}$ and $\tasks{}_{seq}$ for \textit{replicable} (stateless) and \textit{sequential} (stateful) tasks.
Sequential tasks cannot be replicated due to their internal state (i.e., replication leads to false results).
%Stateless tasks can be replicated to improve throughput, while stateful tasks cannot (due to their internal states).
%We also refer to them in this text as \textit{replicable} and \textit{sequential}, respectively.

The computing system is composed of two types of unrelated heterogeneous resources $v \in \{\tbig{}, \tlittle{}\}$ representing \textit{big} and \textit{little} cores, respectively.
%$\tbig{}$ represents \textit{big} cores and $\tlittle{}$ represents \textit{little} cores.
Big cores are assumed to have the highest power consumption.
The system counts with $b$ big and $l$ little fully-connected cores.
Hereafter, the following notation is used to characterize system resources: $R = (b,l)$.
A task $\tau_i$ has a computation weight (i.e., its latency) $w^v_{i}$ that depends on the core type $v$.
%Cores are fully-connected (i.e., they can exchange data with all other cores).

The mapping strategy on our system is known as interval mapping~\cite{benoit2013asurvey}, where $\tasks{}$ is partitioned into $k$ contiguous intervals.
We call the $i^{th}$ interval in the format $[\tau_c,\tau_e]$ ($c\leq e$) a \textit{stage} noted as $s_i$.
A stage is defined as replicable if it contains only replicable tasks.
We define $r_i$ and $v_i$ as the number and the type of resources dedicated to $s_i$, respectively.
The weight of a stage $s$ with $r$ cores of type $v$ is defined in Eq.~\eqref{eq:wsp}. Be careful, when $r > 1$, the weight of a stage differs from its latency.
Other characteristics, such as the communication weights between tasks and network bandwidth are considered out of the scope of our current work due to our focus on heterogeneous \textit{multicore architectures} (keeping data exchanges local) and interval mapping (which minimizes data transfers).
\begin{equation}\label{eq:wsp}
    w(s, r, v) = 
    \begin{cases}
    \sum_{\tau\in s} w^v_{\tau} & \text{if}~s\cap \tasks{}_{seq} \not= \emptyset,~r \geq 1, \\
    \frac{1}{r}\sum_{\tau\in s} w^v_{\tau} & \text{if}~s\cap \tasks{}_{seq} = \emptyset,~r \geq 1, \\
    \infty & \text{otherwise}
    \end{cases}
\end{equation}

Our \textbf{main objective} is to find a solution $\solution{} = (\mathsf{s},\mathsf{r},\mathsf{v})$ with $\mathsf{s}=(s_1, \ldots, s_k)$ that maximizes throughput.
As throughput is inversely proportional to the period, we will refer to this problem as a \textbf{period minimization} problem in the remaining sections.
The period of a solution $\mathsf{P}(\solution{})$ is given by the greatest weight among all stages (Eq.~\eqref{eq:tnp}).
A solution is only valid if the number of available resources is respected (Eq.~\eqref{eq:res}).
\begin{equation}\label{eq:tnp}
    \mathsf{P}(\mathsf{s},\mathsf{r},\mathsf{v}) = \max_{i \in [1,k]} w(s_i,r_i,v_i)
\end{equation}
\begin{equation}\label{eq:res}
	\sum_{v_i = \tbig{}} r_i \leq b, ~~~\sum_{v_i = \tlittle{}} r_i \leq l
\end{equation}

Our \textbf{secondary objective} is to minimize the power consumption of the solution (as minimizing energy makes no sense when dealing with a continuous data stream).
Solutions to this problem depend on the information available.
For instance, if the power consumed by each task in each core type were available (and independent from other tasks in the same core),
%the objectives of period minimization and power minimization could be considered in lexicographic order.
the objective of period minimization could be prioritized over the power one.
A second option would be to assume a fixed power consumption per core used of each type.
We chose to work with a different proxy: the use of little cores instead of big ones, as they have lower power consumption.
In this case, our secondary objective is to \textbf{use as many little cores as necessary} (and not more) to achieve the minimum period.
We will see how this impacts our proposed algorithms in the next sections.

\section{New Greedy Heuristics: \dwotac{} and \notac{}}\label{sec:heuristics}

We propose two heuristics to schedule partially-replicable task chains on two types of resources.
They are both based on OTAC~\cite{orhan2023} which is able to find optimal solutions for homogeneous resources.
In a nutshell, OTAC uses a binary search to set up a target period (similar to Algo.~\ref{algo:solve}) and then tries to greedily build a schedule by packing as many tasks as possible in each stage (as in Algo.~\ref{algo:stage}).
Our new heuristics, named \dwotac{} and \notac{}, use different means to minimize the period while using as many little cores as necessary.
We discuss the main ideas behind them next.

\subsection{\dwotac{}}\label{subsec:dwotac}

\textit{First Efficient Resources for TAsk Chains}, or \textbf{\dwotac{}} for short, aims to use little cores to build each stage.
Big cores are only used when it is not possible to respect the target period.
We will explain how \dwotac{} operates by first covering its methods common to \notac{} (i.e., Schedule and ComputeStage) and then discussing its specific implementation of the ComputeSolution method (Algo.~\ref{algo:dwotac}).

\textbf{Schedule} (Algo.~\ref{algo:solve}) follows a binary search procedure similar to the one used for the CCP problem~\cite{pinar2004fast}.
It sets the lower period bound by the maximum between (I) replicating all tasks over all resources and (II) the sequential task with the largest weight (line~1)\footnote{For the sake of simplicity, we assume here that tasks run fastest on big cores. This only affects the computation of period bounds and can easily be changed with some more comparisons between weights.}.
The upper period bound is based on the minimum period plus the largest task weight (line~2).
The binary search (lines~5--14) tries to find a solution with a target middle period.
If the solution is valid, we store it and update the upper bound (lines~9--10), or else we update the lower bound (line~12).
The search stops when the difference between the bounds is smaller than an epsilon (line~3) that takes into account the fractional nature of the final period due to replicated stages using multiple cores (Eq.~\eqref{eq:wsp}).
In total, this requires $O(\log (w_{max}(b+l)))$ calls to ComputeSolution, with $w_{max} = \max_{\tau \in \tasks} w^{\tlittle{}}_{\tau}$.

%%% SCHEDULE
\begin{algorithm}[!ht]
\caption{Schedule (common method)}
\label{algo:solve}
\scriptsize
\begin{algorithmic}[1]
\Require Set of tasks $\tasks{}$, big cores $b$, little cores $l$.
\Ensure Pipelined and replicated solution $\solution{}_{best}$.
\State $P_{min} \leftarrow \max ( \frac{\sum_{\tau\in \tasks{}} w^{\tbig{}}_{\tau}}{b+l} , \max_{\tau \in \tasks{}_{seq}} w^{\tbig{}}_{\tau} )$ \Comment{Minimum expected period}
\State $P_{max} \leftarrow P_{min} + \max_{\tau \in \tasks} w^{\tlittle{}}_{\tau}$ \Comment{Maximum expected period}
\State $\epsilon \leftarrow \frac{1}{b+l}$
\State $\solution{}_{best} \leftarrow \emptyset$
\While{$P_{max} - P_{min} \geq \epsilon$}
	\State $P_{mid} = \frac{P_{max} + P_{min}}{2}$ \Comment{Target period for the binary search iteration}
	\Statex $\triangleright$~\textcolor{blue}{\textit{ComputeSolution is different for \dwotac{} (Algo.~\ref{algo:dwotac}) and \notac{} (Algo.~\ref{algo:notac})}}
	\State $\solution{} \leftarrow$~ComputeSolution$(\tasks{},1,b,l,P_{mid})$%~\textit{Solution depending on the algorithm.}
	\If{IsValid$(\solution{}, b, l, P_{mid})$} \Comment{Checks for validity (Algo.~\ref{algo:support})}
		\State $\solution{}_{best} \leftarrow \solution{}$ \Comment{New best solution}
		\State $P_{max} \leftarrow \mathsf{P}(\solution{})$ \Comment{Can only decrease the target period from here}%\Comment{$\solution{} = (\mathsf{s},\mathsf{r},\mathsf{v})$}
	\Else
		\State $P_{min} \leftarrow P_{mid}$ \Comment{Can only increase the target period}
	\EndIf
\EndWhile
\State \textbf{return} $\solution{}_{best}$
%\Statex $\triangleright$~\textit{Resource from }
\end{algorithmic}
\end{algorithm}

%%% COMPUTE STAGE
\begin{algorithm}[!ht]
\caption{ComputeStage (common method)}
\label{algo:stage}
\scriptsize
\begin{algorithmic}[1]
\Require Set of tasks $\tasks{}$, task index $s$, cores $c$, core type $v$, target period $P$.
\Ensure Task index $e$, used cores $u$.
%\State $n \leftarrow |\tasks{}|$
% First packing
\State $e \leftarrow $~MaxPacking$(\tasks{},   s, 1, v, P)$ \Comment{Packs tasks using one core (Algo.~\ref{algo:support})}
\State $u \leftarrow $~RequiredCores$(\tasks{}, s, e, v, P)$ \Comment{Cores needed for this stage (Algo.~\ref{algo:support})}
\If{$e \neq n$~\textbf{and} IsRep$(\tasks{}, s, e)$} \Comment{If the stage is replicable (Algo.~\ref{algo:support})}
	% Stage is stateless, more tasks can be added
	\State $e \leftarrow $~FinalRepTask$(\tasks{},   s, e)$ \Comment{Extends the stage (Algo.~\ref{algo:support})}
	\State $u \leftarrow $~RequiredCores$(\tasks{}, s, e, v, P)$
	\If{$u > c$} \Comment{Not enough cores for all tasks, needs to reduce the stage}
		% We do not have enough resources for these tasks, so we remove tasks from the stage
		\State $e \leftarrow $~MaxPacking$(\tasks{},   s, c, v, P)$~;~$u \leftarrow c$
	% We have enough resources for these tasks
	\ElsIf{$e \neq n$} \Comment{Checks if it is better to leave one core for the next stage}
		% There exists more tasks after this stage // Checks if the resources can be better distributed
		\State $f \leftarrow $~MaxPacking$(\tasks{},   s, u-1, v, P)$
		\If{RequiredCores$(\tasks{}, f+1, e+1, v, P) = 1$}
			% Better to leave some stateless tasks for the next stage
			\State $e \leftarrow f$~;~$u \leftarrow u-1$ \Comment{Best to reduce the stage}
		\EndIf
	\EndIf

\EndIf
\State \textbf{return} $e, u$
\end{algorithmic}
\end{algorithm}

%%% SUPPORT METHODS
\begin{algorithm}[!ht]
\caption{Common support methods}
\label{algo:support}
\scriptsize
\begin{algorithmic}[1]
\State \textbf{IsValid}$((\mathsf{s},\mathsf{r},\mathsf{v}),b,l,P):$
\State ~~~~\textbf{return} $(|\mathsf{s}| > 0$ ~\textbf{and}~$\mathsf{P}(\mathsf{s},\mathsf{r},\mathsf{v}) \leq P$ ~\textbf{and}~$\sum_{i \in [1,|\mathsf{v}|] \wedge v_i = \tbig{}} r_i\leq b$ ~\textbf{and}~$\sum_{i \in [1,|\mathsf{v}|] \wedge v_i = \tlittle{}} r_i \leq l)$

\State \textbf{MaxPacking}$(\tasks{},   s, c, v, P) :$ 
\State ~~~~\textbf{return} $\max (s, \max_{i \in [s, |\tasks{}|]} \{i~|~w([\tau_{s},\tau_{i}],c,v) \leq P\})$ 

\State \textbf{RequiredCores}$(\tasks{}, s, e, v, P) : \lceil \frac{w([\tau_{s},\tau_{e}],1,v)}{P} \rceil$

\State \textbf{IsRep}$(\tasks{}, s, e) : [\tau_{s},\tau_{e}] \cap \tasks{}_{seq} = \emptyset$

\State \textbf{FinalRepTask}$(\tasks{},   s, e) : \max_{i \in [e, |\tasks{}|]} \{i~|~$ IsRep$(\tasks{}, s, i)\}$
\end{algorithmic}
\end{algorithm}

\textbf{ComputeStage} (Algo.~\ref{algo:stage}) tries to find where to finish a stage and how many cores (of a given type) are required to respect the target period.
It first tries to pack as many tasks as possible in the stage using a single core (line~1).
We check how many cores the stage requires for the case where the last task in the chain is replicable and its weight surpasses the target period (line~2).
If the stage is replicable (line~3), it is extended to include all following replicable tasks (line~4).
If this long stage requires more cores than available, it is reduced to respect the target period (lines~5--7).
If this stage is not the final one, it means there is a sequential task after it.
We check if it is better to move this stage’s final tasks to the next stage while saving one core and, if that is the case, we update the end of the stage (lines~9--12).
All these tests guarantee that the stage is packing as many tasks as possible with the given cores.

\dwotac{}'s \textbf{ComputeSolution} recursively computes a solution for a given target period (Algo.~\ref{algo:dwotac}) by first trying to build a stage with little cores (line~1), and only moving to big cores if no valid solution was found (lines~2--3).
If the stage is final, then it finishes the recursion (lines~8--9).
If not, then we are required to continue computing the next stage with the remaining cores (lines~11--13).
ComputeSolution returns the list of stages\footnote{The operation $\cdot$ is used for the concatenation of new items at the start of the stages, resources, and core types lists.} if a valid solution is found (line~15).

%%% COMPUTE SOLUTION (PER ALGORITHM)
\begin{algorithm}
\caption{ComputeSolution for \dwotac{}}
\label{algo:dwotac}
\scriptsize
\begin{algorithmic}[1]
\Require Set of tasks $\tasks{}$, task index $s$, big cores $b$, little cores $l$, target period $P$.
\Ensure Pipelined and replicated [partial] solution.
\State $e, u \leftarrow $~ComputeStage$(\tasks{}, s, l, \tlittle{}, P)$~;~$v \leftarrow \tlittle{}$ \Comment{Uses little cores (Algo.~\ref{algo:stage})}
\If{\textbf{not} IsValid$(([\tau_s,\tau_e],u,v), b, l, P)$} \Comment{Checks for validity (Algo.~\ref{algo:support})}
	\State $e, u \leftarrow $~ComputeStage$(\tasks{}, s, b, \tbig{}, P)$~;~$v \leftarrow \tbig{}$ \Comment{Needed to use big cores}
	\If{\textbf{not} IsValid$(([\tau_s,\tau_e],u,v), b, l, P)$} \Comment{No valid solution for both cases}
	 	\State \textbf{return} $(\emptyset, \emptyset, \emptyset)$
	\EndIf
\EndIf
% Stage is valid and the last one
\If{$e = |\tasks{}|$}
	\State \textbf{return} $([\tau_s,\tau_e], u, v)$ \Comment{Returns the valid, final stage}
\Else \Comment{Needs to continue building stages}
% Stage is valid and there are more to compute
	\State $b \leftarrow b-u$~\textbf{if}~$v = \tbig{}$ \Comment{Updates available cores for next stages}
	\State $l \leftarrow l-u$~\textbf{if}~$v = \tlittle{}$
	\State $(\mathsf{s},\mathsf{r},\mathsf{v}) \leftarrow$~ComputeSolution$(\tasks{},e+1,b,l,P)$ \Comment{Computes the next stages}
	\If{IsValid$((\mathsf{s},\mathsf{r},\mathsf{v}), b, l, P)$}
		\State \textbf{return} $([\tau_s,\tau_e] \cdot \mathsf{s}, u \cdot \mathsf{r}, v \cdot
 \mathsf{v})$ \Comment{Returns the list of stages}
 	\Else
 		\State \textbf{return} $(\emptyset, \emptyset, \emptyset)$
	\EndIf
\EndIf
\end{algorithmic}
\end{algorithm}

Regarding the complexity of \dwotac{}, multiple implementation aspects have to be considered.
Given $n = |\tasks{}|$, we chose to precompute the sum of weights for any given stage using two prefix sums in $O(n)$.
We also chose to precompute if any stage is replicable (Algo.~\ref{algo:support}, line~6) in $O(n^2)$ for simplicity, but this cost could be amortized by sequentially checking each task (as in OTAC~\cite{orhan2023}).
The validity of a solution (Algo.~\ref{algo:support}, lines~1--2) has its cost amortized by checking each stage as it is built.
Packing tasks in a stage and identifying the final replicable task in a sequence can be done task by task.
Finally, it can be seen that each task is considered a constant number of times in ComputeStage (Algo.~\ref{algo:stage}), and a task can only be considered for two stages in sequence (and twice for both types of cores).
With all these aspects taken into consideration, our implementation of \dwotac{} requires $O(n\log (w_{max}(b+l)) + n^2)$ operations.

\subsection{\notac{}}\label{subsec:notac}

While \dwotac{} tries to use little cores as soon as possible, \textit{Two-Choice Allocation for TAsk Chains} (or \textbf{\notac{}} for short) tries both types of cores for building a stage at each time.
This enables the strategy to make better use of little cores in later stages, and to potentially consider different secondary objectives when comparing solutions.
This comes at the cost of an exponential increase in the number of solutions to check.

%%% COMPUTE SOLUTION (PER ALGORITHM)
\begin{algorithm}
\caption{ComputeSolution for \notac{}}
\label{algo:notac}
\scriptsize
\begin{algorithmic}[1]
\Require Set of tasks $\tasks{}$, task index $s$, big cores $b$, little cores $l$, target period $P$.
\Ensure Pipelined and replicated [partial] solution $\solution{}_{best}$.

\For{$v \in \{\tbig{},\tlittle{}\}$} \Comment{Builds solution for this stage with both types of cores}
	\State $r \leftarrow b$~\textbf{if}~$v = \tbig{}$~\textbf{else}~$l$
	\State $e_v, u_v \leftarrow $~ComputeStage$(\tasks{}, s, r, v, P)$ \Comment{Greedily builds a stage (Algo.~\ref{algo:stage})}
	\If{\textbf{not} IsValid$(([\tau_s,\tau_{e_v}],u_v,v), b, l, P)$} \Comment{Checks for validity (Algo.~\ref{algo:support})}
	 	\State $\solution{}_v \leftarrow (\emptyset, \emptyset, \emptyset)$ \Comment{No valid stage with this type of cores}
	\ElsIf{$e_v = |\tasks{}|$}
		\State $\solution{}_v \leftarrow ([\tau_s,\tau_{e_v}], u_v, v)$ \Comment{Valid, final stage option}
	\Else
		\State $b_v \leftarrow b-u_v$~\textbf{if}~$v = \tbig{}$~\textbf{else}~$b$ \Comment{Updates available cores for next stages}
		\State $l_v \leftarrow l-u_v$~\textbf{if}~$v = \tlittle{}$~\textbf{else}~$l$
		\State $(\mathsf{s}_v,\mathsf{r}_v,\mathsf{v}_v) \leftarrow$~ComputeSolution$(\tasks{},e_v+1,b_v,l_v,P)$ \Comment{Next stages}
		\If{IsValid$((\mathsf{s}_v,\mathsf{r}_v,\mathsf{v}_v), b_v, l_v, P)$}
			\State $\solution{}_v \leftarrow([\tau_s,\tau_{e_v}] \cdot \mathsf{s}_v, u_v \cdot \mathsf{r}_v, v \cdot \mathsf{v}_v)$ \Comment{Valid combined solution}
 		\Else
 			\State $\solution{}_v \leftarrow (\emptyset, \emptyset, \emptyset)$
		\EndIf
	\EndIf
\EndFor
\State \textbf{return} ChooseBestSolution$(\solution_\tbig{}, \solution_\tlittle{}, b, l, P)$ \Comment{Picks the best solution (Algo.~\ref{algo:choosebest})}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{ChooseBestSolution (part of \notac{})}
\label{algo:choosebest}
\scriptsize
\begin{algorithmic}[1]
\Require Solutions $\solution_\tbig{}$ and $\solution_\tlittle{}$, big cores $b$, little cores $l$, target period $P$.
\Ensure Pipelined and replicated [partial] solution $\solution{}_{best}$.
\If{IsValid$(\solution_\tbig{}, b, l, P)$} \Comment{Checks for validity (Algo.~\ref{algo:support})}
	% valid for big
	\If{IsValid$(\solution_\tlittle{}, b, l, P)$}
		% has to compare solutions
		\For{$v \in \{\tbig{},\tlittle{}\}$} \Comment{Compares the core usage of the solutions}
			\State $(\mathsf{s},\mathsf{r},\mathsf{v}) \leftarrow \solution{}$
			\State $\Sigma b_v \leftarrow \sum_{i \in [1,|\mathsf{v}|] \wedge v_i = \tbig{}} r_i$
			\State $\Sigma l_v \leftarrow \sum_{i \in [1,|\mathsf{v}|] \wedge v_i = \tlittle{}} r_i$
		\EndFor
		% Set of comparisons
		\If{$\Sigma l_\tbig{} > \Sigma l_\tlittle{}$~\textbf{and}~$\Sigma b_\tbig{} < \Sigma b_\tlittle{}$}
			\State $\solution{}_{best} \leftarrow \solution_\tbig{}$ \Comment{$\solution_\tbig{}$ makes better usage of little cores}
		\ElsIf{$\Sigma l_\tbig{} < \Sigma l_\tlittle{}$~\textbf{and}~$\Sigma b_\tbig{} > \Sigma b_\tlittle{}$}
			\State $\solution{}_{best} \leftarrow \solution_\tlittle{}$ \Comment{$\solution_\tlittle{}$ makes better usage of little cores}
		\ElsIf{$\Sigma l_\tbig{} + \Sigma b_\tbig{} < \Sigma l_\tlittle{} + \Sigma b_\tlittle{}$}
			\State $\solution{}_{best} \leftarrow \solution_\tbig{}$ \Comment{$\solution_\tbig{}$ uses fewer cores}
		\Else
			\State $\solution{}_{best} \leftarrow \solution_\tlittle{}$ \Comment{$\solution_\tlittle{}$ uses fewer cores}
		\EndIf
	\Else
		% only valid for big
		\State $\solution{}_{best} \leftarrow \solution_\tbig{}$ \Comment{Only valid solution}
	\EndIf
\ElsIf{IsValid$(\solution_\tlittle{}, b, l, P)$}
	% only valid for little
	\State $\solution{}_{best} \leftarrow \solution_\tlittle{}$ \Comment{Only valid solution}
\Else   % No valid solution
	\State $\solution{}_{best} \leftarrow (\emptyset, \emptyset, \emptyset)$ \Comment{No valid solution}
\EndIf
\State \textbf{return} $\solution{}_{best}$
\end{algorithmic}
\end{algorithm}

\notac{}’s \textbf{ComputeSolution} (Algo.~\ref{algo:notac}) computes the stage for both big and little cores (lines 1--3).
In each case, if the final stage is identified, it is stored for comparison (line~7), or else the recursion is launched for the next stage (line~11) and combined with the current stage (line~13).

ComputeSolution employs \textbf{ChooseBestSolution} (Algo.~\ref{algo:choosebest}) to compare the solutions for both types of cores.
A solution is directly returned if it is the only valid one (lines~18 and~21).
In the other case, the solution that better exchanges big cores for little ones is returned (lines~9 and~11) or, in the last scenario, the one that uses fewer cores is chosen (lines~13 and~15).
As ComputeSolution's objective is to find a schedule that respects the target period, there is no need to compare the stages’ weights for the different solutions.

\notac{}’s complexity is defined by its recursion’s possible solutions tree.
Other aspects, such as the comparison between two solutions, are amortized by capturing relevant information while computing them.
For instance, we provide the accumulated core usages when combining solutions (Algo.~\ref{algo:notac}, line 13) instead of computing them each time (Algo.~\ref{algo:choosebest}, lines 5--6).
Given the considerations previously discussed for \dwotac{}, we can conclude that \notac{} displays a worst-case complexity in $O(2^n\log (w_{max}(b+l)))$ when each stage contains only one task.
This can be prohibitive for larger task chains, but it is still faster than the optimal solution (to be shown next) in some scenarios (see Section~\ref{sec:eval}).

\section{Optimal Dynamic Programming Solution}\label{sec:dp}

Our optimal dynamic programming solution can be defined based on this problem’s recurrence.
Let $\mathsf{P}^*(j,b,l)$ be the best period achieved when mapping tasks from $\tau_1$ to $\tau_j$ using up to $b$~big cores and $l$~little cores.
$\mathsf{P}^*(j,b,l)$ can be computed using the recurrence in Eq.~\eqref{eq:dp} with $\mathsf{P}^*(0,b,l) = 0$ and $\mathsf{P}^*(j,0,0) =\infty$ for $j>0$.
\begin{equation}\label{eq:dp}
\begin{split}
    \mathsf{P}^*(j,b,l) = & \\
    \min\limits_{i \in [1,j]} & 
    \begin{cases}
    \min\limits_{u \in [1,b]} \max \mathsf{P}^*(i-1,b-u,l), w([\tau_{i},\tau_{j}],u,\tbig{})\\
    \min\limits_{u \in [1,l]} \max \mathsf{P}^*(i-1,b,l-u), w([\tau_{i},\tau_{j}],u,\tlittle{})
    \end{cases}
\end{split}
\end{equation}

Eq.~\eqref{eq:dp} shows that an optimal solution can be built from partial optimal solutions.
The best solution is found by trying all possible starts for the stage finishing in $\tau_j$ and all possible resource distributions between this stage and previous ones for both core types.
This recurrence can be computed in $O(j^2bl(b+l))$ time and $O(jbl)$ space.

\begin{algorithm}[!ht]
\caption{\opt{}}
\label{algo:opt_main}
\scriptsize
\begin{algorithmic}[1]
\Require Set of tasks $\tasks{}$, big cores $b$, little cores $l$.
\Ensure Pipelined and replicated solution $\solution{}_{best}$.
\For{$i \in [1,|\tasks{}|]~,~j \in [0,b]~,~k \in [0,l]$} \Comment{Initializes solution matrix}
	\State $\msol{}_{Pbest}[i][j][k] \leftarrow \infty$ \Comment{Minimal maximum period}
	\State $\msol{}_{prev}[i][j][k]  \leftarrow (0,0)$ \Comment{Big and little cores in the previous stages}
	\State $\msol{}_{acc}[i][j][k]  \leftarrow (0,0)$ \Comment{Accumulated big and little cores}
	\State $\msol{}_{v}[i][j][k]  \leftarrow \tlittle{}$ \Comment{Type of core used in the stage}
	\State $\msol{}_{start}[i][j][k] \leftarrow 0$ \Comment{Index of the starting task of the stage}
\EndFor
\State SingleStageSolution$(1,\msol{},\tasks{},b,l)$ \Comment{Single task in a single stage (Algo.~\ref{algo:opt_single})}
\For{$e \in [2,|\tasks{}|]$}
	\State SingleStageSolution$(e,\msol{},\tasks{},b,l)$ \Comment{All $e$ tasks in a single stage (Algo.~\ref{algo:opt_single})}
	\For{$u_b \in [0,b]$} \Comment{Solutions with more than one stage}
		\For{$u_l \in [0,l]$} \Comment{and varying numbers of cores}
			\If{$u_b \neq 0$~\textbf{or}~$u_l \neq 0$} 
				\State RecomputeCell$(e,\msol{},\tasks{},u_b,u_l)$ \Comment{$\mathsf{P}^*(e,u_b,u_l)$ (Algo.~\ref{algo:opt_cell})} 
			\EndIf
		\EndFor
	\EndFor
\EndFor
\State \textbf{return} ExtractSolution$(\msol{},\tasks{},b,l)$ \Comment{Converts the matrix to a solution (Algo.~\ref{algo:opt_extract})}
\end{algorithmic}
\end{algorithm}

%%% SINGLE STAGE SOLUTION
\begin{algorithm}[!ht]
\caption{SingleStageSolution (part of \opt{})}
\label{algo:opt_single}
\scriptsize
\begin{algorithmic}[1]
\Require Task index $t$, solution matrix $\msol{}$, set of tasks $\tasks{}$, big cores $b$, little cores $l$.
\Ensure Updated $\msol{}[t][:][:]$.
\For{$r_l \in [1,l]$} \Comment{Initializes row with a stage using little cores}
	\State $\msol{}_{Pbest}[t][0][r_l] \leftarrow w([\tau_{1},\tau_{t}],r_l,\tlittle{})$
	\State $\msol{}_{acc}[t][0][r_l] \leftarrow (0,r_l)$~\textbf{if}~IsRep$(\tasks{}, 1, t)$~\textbf{else}~$(0,1)$
\EndFor
\For{$r_b \in [1,b]$}
	\State $w_b \leftarrow w([\tau_{1},\tau_{t}],r_b,\tbig{})$ \Comment{Computes the stage with big cores}
	\State $u_b \leftarrow r_b$~\textbf{if}~IsRep$(\tasks{}, 1, t)$~\textbf{else}~$1$
	\For{$r_l \in [0,l]$} \Comment{Compares if it is better to use $r_b$ big }
		\If{$w_b < \msol{}_{Pbest}[t][0][r_l]$} \Comment{~or $r_l$ little cores for this single stage}
			\State $\msol{}_{Pbest}[t][r_b][r_l] \leftarrow w_b$
			\State $\msol{}_{acc}[t][r_b][r_l] \leftarrow (u_b,0)$
			\State $\msol{}_{v}[t][r_b][r_l] \leftarrow \tbig{}$
		\Else
			\State $\msol{}_{Pbest}[t][r_b][r_l] \leftarrow \msol{}_{Pbest}[t][0][r_l]$
			\State $\msol{}_{acc}[t][r_b][r_l] \leftarrow \msol{}_{acc}[t][0][r_l]$			
		\EndIf
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

%%% RECOMPUTE CELL
\begin{algorithm}[!ht]
\caption{RecomputeCell (part of \opt{})}
\label{algo:opt_cell}
\scriptsize
\begin{algorithmic}[1]
\Require Task index $j$, solution matrix $\msol{}$, set of tasks $\tasks{}$, big cores available $b$, little cores available $l$.
\Ensure Updated $\msol{}[j][b][l]$.
\State $C \leftarrow \msol{}[j][b][l]$ \Comment{Uses the initial solution from SingleStageSolution (Algo.~\ref{algo:opt_single})}
\State $C \leftarrow$~CompareCells$(C, \msol{}[j][b][l-1])$~\textbf{if}~$l>0$ \Comment{Compares to neighbor solutions}
\State $C \leftarrow$~CompareCells$(C, \msol{}[j][b-1][l])$~\textbf{if}~$b>0$ \Comment{~using one less core}
\For{$i \in [1,j]$~in reverse order} \Comment{External $\min_{i \in [1,j]}$ (Eq.~\ref{eq:dp})}
	\For{$u \in [1,b]$} \Comment{Internal $\min_{u \in [1,b]}$ (Eq.~\ref{eq:dp})}
		\State $B_{Pbest} \leftarrow \max \msol{}_{Pbest}[i-1][b-u][l], w([\tau_{i},\tau_{j}],u,\tbig{})$
		\State $(a_b, a_l) \leftarrow \msol{}_{acc}[i-1][b-u][l]$
		\State $B_{acc} \leftarrow (a_b+u, a_l)$~\textbf{if}~IsRep$(\tasks{}, i, j)$~\textbf{else}~$(a_b+1, a_l)$
		\State $B_{prev} \leftarrow (b-u, a_l)$~;~$B_{v} \leftarrow \tbig{}$~;~$B_{start} \leftarrow i$
		\State $C \leftarrow$~CompareCells$(C,B)$ \Comment{Keeps the best solution (Algo.~\ref{algo:opt_compare})}
	\EndFor
	\For{$u \in [1,l]$} \Comment{Internal $\min_{u \in [1,l]}$ (Eq.~\ref{eq:dp})}
		\State $L_{Pbest} \leftarrow \max \msol{}_{Pbest}[i-1][b][l-u], w([\tau_{i},\tau_{j}],u,\tlittle{})$
		\State $(a_b, a_l) \leftarrow \msol{}_{acc}[i-1][b][l-u]$
		\State $L_{acc} \leftarrow (a_b, a_l+u)$~\textbf{if}~IsRep$(\tasks{}, i, j)$~\textbf{else}~$(a_b, a_l+1)$
		\State $L_{prev} \leftarrow (a_b, l-u)$~;~$L_{v} \leftarrow \tlittle{}$~;~$L_{start} \leftarrow i$
		\State $C \leftarrow$~CompareCells$(C,L)$ \Comment{Keeps the best solution (Algo.~\ref{algo:opt_compare})}
	\EndFor	
\EndFor
\State $\msol{}[j][b][l] \leftarrow C$ \Comment{Stores the best solution}
\end{algorithmic}
\end{algorithm}

%%% COMPARE CELLS
% if ((neigh_load < current_load) ||
%            ((neigh_load == current_load) && (neigh_little > current_little) && (neigh_big < current_big)) ||
%            ((neigh_load == current_load) && (neigh_little <= current_little) && (neigh_big <= current_big))) {
\begin{algorithm}[!ht]
\caption{CompareCells (part of \opt{})}
\label{algo:opt_compare}
\scriptsize
\begin{algorithmic}[1]
\Require Matrix cells for partial solutions $C$ (current) and $N$ (new).
\Ensure Best partial solution.
\State $(c_b, c_l) \leftarrow C_{acc}$~;~$(n_b, n_l) \leftarrow N_{acc}$
\If{$(C_{Pbest} > N_{Pbest})$ ~\textbf{or}~$(C_{Pbest} = N_{Pbest}$ \textbf{and} $c_l < n_l$ \textbf{and} $c_b > n_b)$ ~\textbf{or}~$(C_{Pbest} = N_{Pbest}$ \textbf{and} $c_l \geq n_l$ \textbf{and} $c_b \geq n_b)$}
	\State \textbf{return} $N$
\Else
	\State \textbf{return} $C$
\EndIf
\end{algorithmic}
\end{algorithm}

%%% EXTRACT SOLUTION
\begin{algorithm}[!ht]
\caption{ExtractSolution (part of \opt{})}
\label{algo:opt_extract}
\scriptsize
\begin{algorithmic}[1]
\Require Solution matrix $\msol{}$, set of tasks $\tasks{}$, big cores $b$, little cores $l$.
\Ensure Pipelined and replicated solution $\solution{}_{best}$.
\State $e \leftarrow |\tasks{}|$~;~$s \leftarrow |\tasks{}|$~;~$r_b \leftarrow b$~;~$r_l \leftarrow l$
\State $(\mathsf{s},\mathsf{r},\mathsf{v}) \leftarrow (\emptyset, \emptyset, \emptyset)$
\While{$e\geq 1$}
	\State $s \leftarrow \msol{}_{start}[e][r_b][r_l]$ \Comment{Start of the stage}
	\State $(u_b, u_l) \leftarrow \msol{}_{acc}[e][r_b][r_l]$
	\State $v \leftarrow \msol{}_{v}[e][r_b][r_l]$ \Comment{Type of core used}
	\State $(p_b, p_l) \leftarrow \msol{}_{prev}[e][r_b][r_l]$
	\If{$s>1$} \Comment{Gets the number of cores used in this stage only}
		\State $(c_b, c_l) \leftarrow \msol{}_{acc}[s-1][p_b][p_l]$
		\State $u_b \leftarrow u_b - c_b$~;~$u_l \leftarrow u_l - c_l$
	\EndIf
	\State $r \leftarrow u_b$ \textbf{if} $v = \tbig{}$ \textbf{else} $u_l$ \Comment{Number of cores used}
	\State $(\mathsf{s},\mathsf{r},\mathsf{v}) \leftarrow ([\tau_s,\tau_e] \cdot \mathsf{s}, r \cdot \mathsf{r},v \cdot \mathsf{v})$ \Comment{Adds the stage to the solution}
	\State $e \leftarrow s-1$~;~$r_b \leftarrow p_b$~;~$r_l \leftarrow p_l$ \Comment{Index for the predecessor stage}
\EndWhile
\State \textbf{return} $(\mathsf{s},\mathsf{r},\mathsf{v})$
\end{algorithmic}
\end{algorithm}

\textbf{\opt{}}, or short for \textit{Heterogeneous Resource Allocation using Dynamic programming} (Algo.~\ref{algo:opt_main}), implements the optimal strategy of Eq.~\eqref{eq:dp} while also considering the secondary objective of using as many little cores as necessary.
It starts by initializing a solution matrix $\msol{}$ that will contain all optimal partial solutions (lines~1--7).
It then computes all optimal solutions for the first task in the chain with all possible numbers of cores (line~8) using SingleStageSolution.
In the next step and for increasing numbers of tasks, the algorithm computes a first solution where all tasks belong to the same stage (line~10).
Then, it computes the optimal partial solution for this number of tasks with varying numbers of cores available (line~14) using RecomputeCell.
The algorithm finishes by going backwards in the solution matrix and identifying the stages that belong to the optimal solution (line~19) using ExtractSolution (Algo.~\ref{algo:opt_extract}).
We have also added an extra step that merges consecutive stages if they are replicable and using the same core type.
This has no impact in the minimum period achieved, but it leads to solutions with fewer stages.

\textbf{SingleStageSolution} (Algo.~\ref{algo:opt_single}) finds the best solutions when putting all considered tasks in the same stage.
It computes and stores the weight of the stage using increasing numbers of little cores, taking care to register that sequential stages can only benefit from a single core (lines 1--4).
It then considers an increasing number of big cores (lines 6--7) and compares their solutions with the ones using little cores (lines 8--17).
It stores the solution with minimum period in the matrix, solving ties in favor of the little cores (lines~9--16).

\textbf{RecomputeCell} (Algo.~\ref{algo:opt_cell}) tries all possible optimal solutions for a scenario with a given number of tasks, big cores and little cores.
It uses the solution from SingleStageSolution as a starting point and compares it to other solutions with one fewer big or little core (lines 1--3) that have been previously computed. 
It then computes all possible solutions for $\max \mathsf{P}^*(i-1,b-u,l), w([\tau_{i},\tau_{j}],u,\tbig{})$ (lines 4--11) and $\max \mathsf{P}^*(i-1,b,l-u), w([\tau_{i},\tau_{j}],u,\tlittle{})$ (lines 4 and 12--18), comparing them sequentially to the best solution found so far, and the best solution is stored in the matrix (line~20).
We implement an optimization that limits comparisons to a single core (instead of a range of cores in lines 5 and 12) if the stage is sequential.
All solution comparisons make use of \textbf{CompareCells} (Algo.~\ref{algo:opt_compare}).
It returns the solution with the minimum maximum period.
In the case of ties, the solution that better exchanges big cores for little cores is returned or, in the last scenario, the one that uses fewer cores is chosen.

\subsection{Optimality proof}

The optimality of \opt{} can be demonstrated by induction\footnote{For the sake of brevity, we provide only a resumed proof of this solution’s optimality. Suffice to say, similar proofs have been provided for other interval-based mapping algorithms~\cite{agrawal2008} and dynamic programming algorithms with secondary objectives handled when comparing partial solutions~\cite{nunes2024}.}.
Its proof combines elements of Eq.~\eqref{eq:dp} and its implementations in Algos.~\ref{algo:opt_main},~\ref{algo:opt_single}, and~\ref{algo:opt_cell}.
At each step, we first cover the period minimization aspect of the solution, followed by the idea of using as many little cores as necessary.

\begin{lemma}\label{proof:1:1}
The solution for $\mathsf{P}^*(1,b,l)$ is optimal.
\end{lemma}

\begin{proof}
The only possible solutions for $\mathsf{P}^*(1,b,l)$ include a single pipeline stage using big or little cores.
Algo~\ref{algo:opt_single} is used to compute the solution for $j=1$ (Algo.~\ref{algo:opt_main}, line~8).
It stores the minimum between the solutions using $b$ big cores or $l$ little cores (Algo~\ref{algo:opt_single}, lines 5--9), therefore it is optimal in period.

Regarding the use of little cores, the algorithm first computes solutions using them (lines 1--4) and then solves ties with big cores in favor of the little ones (line~9, use of $<$), thus being optimal in this aspect too.
\end{proof}

\begin{lemma}\label{proof:1:2}
	The solution for $\mathsf{P}^*(j,b,l)$ is optimal if the solutions for $\mathsf{P}^*(i,r_b,r_l)$ are also optimal for $i<j$, $r_b\leq b$, and $r_l\leq l$.
\end{lemma}

\begin{proof}
% optimal in period
The period of $\mathsf{P}^*(j,b,l)$ takes its value from the minimum period among all possible starts for the stage finishing in $\tau_j$ using all possible resource distributions (Eq.~\eqref{eq:dp}, loops in Algo.~\ref{algo:opt_single} using Algo.~\ref{algo:opt_compare}, and Algo.~\ref{algo:opt_cell}).
To consider another schedule with a smaller period is a contradiction, as it requires having a suboptimal $\mathsf{P}^*(i,r_b,r_l)$, or a value that is smaller than the minimum of all possible solutions, so $\mathsf{P}^*(j,b,l)$ is optimal regarding its period.

% optimal in resources
Regarding the use of little cores, Algo.~\ref{algo:opt_compare} always solves ties in the benefit of the solution that better exchanges big cores for little cores or the one that uses fewer cores.
We also ensure that solutions having one less big or little core available are propagated from previous solutions (Algo.~\ref{algo:opt_cell} lines 2--3), thus the solution is also optimal in this aspect.
\end{proof}

\begin{theorem}\label{proof:final}
	\opt{} yields optimal solutions regarding the period achieved and the use of little cores.
\end{theorem}

\begin{proof}
	Lemmas \ref{proof:1:1} and \ref{proof:1:2} prove the optimality of the base case and the inductive step, so \opt{} is optimal.
\end{proof}

As given by Theorem~\ref{proof:final}, \opt{} provides schedules with minimal periods while using as many little cores as necessary with the potential issue of a high complexity.
We next evaluate how its benefits and drawbacks measure against our greedy heuristics.

%!TEX root = ../hcw_main.tex
\section{Experimental Evaluation}\label{sec:eval}

Our experimental evaluation is organized in two steps.
In the first step, we use synthetic task chains and processors to check how well the strategies are able to optimize our two objectives, and also to profile their execution time.
In the second step, we employ them to schedule an implementation of the DVB-S2 digital communication standard~\cite{dvbs2} on StreamPU~\cite{cassagne2023spu} and on two heterogeneous multicore processors. Then, we evaluate their throughput.
Comparisons include our three strategies and OTAC~\cite{orhan2023} (which handles homogeneous resources only).
We provide more details about our experimental environments and results in the next sections.
Source code, result files, and scripts are freely available online~\cite{amp-scheduling}.

\subsection{Experimental Environments}

\subsubsection{Simulation}
Experiments were executed on a Dell \textbf{Latitude~7420} notebook (Intel Core i7-1185G7 @ 3~GHz, 32~GB LPDDR4 @ 3733~MT/s, 512~GB NVMe SSD) running Linux (Ubuntu 24.04.1 LTS kernel 6.8.0-51, g++ 13.3.0).
For period and core usage measurements, 1000~task chains of 20~tasks were generated.
Task weights were randomly set in the integer interval [1,100] uniformly for big cores with a slowdown in the interval [1,5] for little cores (rounded using the ceiling function).
In order to evaluate how the replicable tasks affect the strategies, the stateless ratio (SR) (i.e., fraction of tasks that are replicable) of each chain was set equal to $\{0.2, 0.5, 0.8\}$ for different scenarios.
We set the number of big ($b$) and little ($l$) cores (e.g., the resources $R = (b,l)$) in the simulation using three different pairs $\{(16_\mathcal{B},4_\mathcal{L}), (10_\mathcal{B},10_\mathcal{L}), (4_\mathcal{B},16_\mathcal{L})\}$.
% using the M1 Ultra processor as inspiration.
For the execution time profiling, we generate 50~task chains for varying numbers of tasks ($20i | i \in [1,8]$), pairs of numbers of cores ($(20i,20i) | i \in [1,8]$), and SRs.

\subsubsection{Real-world SDR Experiment}
Experiments were executed on two platforms:
\begin{enumerate}
  \item[(i)]  an Apple \textbf{Mac Studio} (Apple Silicon M1 Ultra with 20~ARMv8.5-A cores set as 16 (big) p-cores @ 3.2~GHz and 4 (little) e-cores @ 2~GHz, 64~GB LPDDR5 @ 6400~MT/s, 2~TB SSD) running Linux (Fedora 40 Asahi Remix kernel 6.11.8-400, g++ 14.2.1);
  \item[(ii)] a Minisforum AtomMan \textbf{X7 Ti} PC (Intel Ultra 9 185H, 16 x86-64 cores with 6 (big) p-cores @ 5.1~GHz, 8 (little) e-cores @ 3.8~GHz, and 2 LPe-cores left unused, 32~GB DDR5 @ 5600~MT/s, 1~TB NVMe SSD) running Linux (Ubuntu 24.10 kernel 6.11.0-13, g++ 14.2.0).
\end{enumerate}
Both run StreamPU~v1.6.0 and the open source DVB-S2 transceiver\footnote{DVB-S2 transceiver GitHub repository: \url{https://github.com/aff3ct/dvbs2}} (commit \verb|5a952de|).
After profiling the DVB-S2 receiver on both platforms\footnote{DVB-S2 receiver parameters: transmission phase, 1000 streams, inter-frame level $\in \{4, 8\}$, $K = 14232$, $R = 8/9$, MODCOD 2, LDPC horizontal layered NMS 10 ite with early stop criterion, error-free SNR zone.} (Table~\ref{tab:sdr_dvbs2_tasks_thr_lat}), schedules were computed using all cores and half of them.
A compact placement was used for the threads.
Each schedule was executed ten times for 1~minute each and the achieved throughputs (in Mb/s and frames per second) were obtained.

%%%
\subsection{Simulation -- Slowdown Compared to \opt{}}

Given that \opt{} always provides minimal periods, we use the slowdown ratio $\frac{\mathsf{P}(\solution{}_{\text{other}})}{\mathsf{P}(\solution{}_{\text{\opt{}}})}$ to compare strategies.
Fig.~\ref{fig:densities_zoomed} illustrates the cumulative distributions (1000~task chains) of slowdown ratios for varying resources and slowdown ratios.
Each line represents a strategy, with OTAC~(B) (resp. OTAC~(L)) using only big (resp. little) cores.
We can notice in the first column ($SR=0.2$) that \notac{} and \dwotac{} tend to find minimal periods in most cases, but they become less effective as the SR increases (other columns).
The higher the SR, the more likely for the period to be limited by replicable tasks and the higher the number of replication options to explore, making it harder to find the best solution.
%Both strategies try to pack as many replicable tasks together in the same stage, missing the possibility of splitting these tasks into multiple stages using different cores types.

\begin{figure}[!ht]
  \centering
  \begin{subfigure}{\columnwidth}
    \includegraphics[width=0.3\columnwidth]{16_4_02_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{16_4_05_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{16_4_08_z.pdf}
    \\
    \includegraphics[width=0.3\columnwidth]{10_10_02_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{10_10_05_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{10_10_08_z.pdf}
    \\
    \includegraphics[width=0.3\columnwidth]{4_16_02_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{4_16_05_z.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{4_16_08_z.pdf}

    \caption{Results zoomed in the slowdown interval $[1,1.5]$. Rows represent different pairs of resources.}
    \label{fig:densities_zoomed}
  \end{subfigure}

  \vspace{0.2cm}
  \begin{subfigure}{\columnwidth}
    \includegraphics[width=0.3\columnwidth]{10_10_02.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{10_10_05.pdf}
    \hfill
    \includegraphics[width=0.3\columnwidth]{10_10_08.pdf}
    \caption{Full slowdown interval for $R=(10_{\mathcal{B}},10_{\mathcal{L}})$.}
    \label{fig:densities}
  \end{subfigure}
  \caption{Cumulative solution (e.g., \emph{density}) distributions of slowdown ratios (cf. \opt{}) for different heuristics. Columns represent different SRs.}
  \label{fig:densities_all}
\end{figure}

OTAC~(B) performs similarly to \dwotac{} only when many big cores are available (first row).
Meanwhile, OTAC~(L) never finds optimal solutions because it lacks the big cores to handle the slowest tasks.
The gap between these strategies can be better seen in Fig.~\ref{fig:densities} with a full range of slowdown ratios.

% %%%%% SLOWDOWN RATIOS CF. DP
% \begin{figure}[t]
% \centering
% \begin{subfigure}{0.3\columnwidth}
%     \includegraphics[width=\columnwidth]{R=(10,10), SR=0.2.pdf}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.3\columnwidth}
%     \includegraphics[width=\columnwidth]{R=(10,10), SR=0.5.pdf}
% \end{subfigure}
% \hfill
% \begin{subfigure}{0.3\columnwidth}
%     \includegraphics[width=\columnwidth]{R=(10,10), SR=0.8.pdf}
% \end{subfigure}
% \caption{Full slowdown interval for $R=(10_{\mathcal{B}},10_{\mathcal{L}})$.}
% \label{fig:densities}
% \end{figure}

%While the previous figures provide an overview of the different strategies’ behavior, 
We summarize our simulation statistics in Table~\ref{tab:stats}.
When few little cores are available ($R=(16_{\mathcal{B}},4_{\mathcal{L}})$), \notac{} and \dwotac{} find the majority of minimal periods, leading to $1\%$ or lower slowdowns on average.
Even for scenarios with different numbers of cores, \notac{} and \dwotac{} achieve average slowdown ratios limited to $1.03$ and $1.08$, respectively, which represent $97.1\%$ and $92.6\%$ of the potential throughput. % for the average task chain.
Their worst results ($R=(10_{\mathcal{B}},10_{\mathcal{L}}), SR=0.5$) were limited to maximum slowdowns of $1.23$ and $1.41$, respectively (or $81.3\%$ and $70.1\%$ of the potential throughput).
In comparison, OTAC~(B) shows average slowdown ratios comparable to the maximum slowdowns of \dwotac{} for $R=(10_{\mathcal{B}},10_{\mathcal{L}})$, and even worse when even fewer big cores are available.
It emphasizes the importance of using both core types together.

%%%%%%%%%%%%% SIMULATION STATISTICS
% \begin{table}[t]
% \centering
% \caption{Simulation statistics for all scheduling strategies. Each tuple counts the percentage of optimal periods, and the average, median, and maximum slowdown ratios.}
% \label{tab:stats}
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{c|ccc}
% \multirow{2}{*}{$R=(16,4)$}       & $SR = 0.2$                   & $SR = 0.5$                   & $SR = 0.8$                   \\
%        & (\% opt, avg, med, max)       & (\% opt, avg, med, max)      & (\% opt, avg, med, max)        \\
% \toprule
% \notac{}  & $(100\%,  1.00,  1.00,  1.00)$ & $(99.6\%,  1.00,  1.00,  1.13)$ & $( 93.0\%,  1.00,  1.00,  1.17)$ \\
% \dwotac{} & $(99.2\%,  1.00,  1.00,  1.14)$ & $(95.8\%,  1.00,  1.00,  1.22)$ & $( 84.3\%,  1.01,  1.00,  1.34)$ \\
% \otac{B} & $(88.7\%,  1.01,  1.00,  1.31)$ & $(82.7\%,  1.02,  1.00,  1.35)$ & $( 69.9\%,  1.04,  1.00,  1.43)$ \\
% \otac{L} & $(0\%,  9.01,  8.93, 13.88)$   & $( 0\%,  9.35,  9.27, 14.81)$   & $(  0\%, 10.57, 10.37, 17.92)$  \\
% \midrule
%   \addlinespace
% \multirow{2}{*}{$R=(10,10)$}       & $SR = 0.2$                   & $SR = 0.5$                   & $SR = 0.8$                   \\
%        & (\% opt, avg, med, max)       & (\% opt, avg, med, max)      & (\% opt, avg, med, max)        \\
% \toprule
% \notac{}  & $( 98.8\%,  1.00,  1.00,  1.07)$ & $(89.1\%, 1.00, 1.00, 1.23)$ & $(61.7\%, 1.02, 1.00, 1.22)$ \\
% \dwotac{} & $( 80.3\%,  1.01,  1.00,  1.26)$ & $(51.2\%, 1.04, 1.00, 1.41)$ & $(42.2\%, 1.06, 1.03, 1.37)$ \\
% \otac{B} & $(  1.7\%,  1.32,  1.32,  1.78)$ & $( 1.4\%, 1.38, 1.39, 1.87)$  & $( 1.6\%, 1.41, 1.43, 1.92)$  \\
% \otac{L}  & $(  0\%,  4.17,  4.19,  5.62)$ & $( 0\%, 4.32, 4.37, 5.80)$   & $( 0\%, 4.34, 4.40, 5.80)$  \\
% \midrule
%   \addlinespace
% \multirow{2}{*}{$R=(4,16)$}       & $SR = 0.2$                   & $SR = 0.5$                   & $SR = 0.8$                   \\
%        & (\% opt, avg, med, max)       & (\% opt, avg, med, max)      & (\% opt, avg, med, max)        \\
% \toprule
% \notac{}  & $(100\%, 1.00, 1.00, 1.00)$ & $(91.7\%, 1.00, 1.00, 1.14)$ & $(41.1\%, 1.03, 1.01, 1.21)$ \\
% \dwotac{} & $(99.0\%, 1.00, 1.00, 1.09)$ & $(61.4\%, 1.03, 1.00, 1.34)$ & $(13.0\%, 1.08, 1.07, 1.36)$ \\
% \otac{B} & $( 0\%, 1.61, 1.59, 2.62)$   & $( 0\%, 2.03, 2.06, 2.88)$   & $( 0\%, 2.42, 2.40, 3.13)$   \\
% \otac{L}  & $( 0\%, 2.22, 2.16, 4.72)$  & $( 0\%, 2.58, 2.49, 4.72)$   & $( 0\%, 2.57, 2.36, 4.97)$
% \end{tabular}
% }
% \end{table}

% \begin{table}[htp]
% \centering
% \caption{Simulation statistics for all scheduling strategies. Each tuple counts the percentage of optimal periods, and the average, median, and maximum slowdown ratios.}
% \label{tab:stats}
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{c l r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} l r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} l r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} r@{\hskip 0.05in} l}
% \toprule
% &  & \multicolumn{6}{c}{$SR = 0.2$} & \multicolumn{6}{c}{$SR = 0.5$} & \multicolumn{6}{c}{$SR = 0.8$} \\
% \cmidrule(lr){3-8} \cmidrule(lr){9-14} \cmidrule(lr){15-20}
% $R$                                                  & Algorithm & ( &  \% opt, &  avg, &  med, &   max & ) & ( & \% opt, &  avg, &  med, &   max & ) & ( & \% opt, &   avg, &   med, &   max & ) \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{90}{$(16, 4)$}} & \notac{}  & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( & 99.6\%, & 1.00, & 1.00, &  1.13 & ) & ( & 93.0\%, &  1.00, &  1.00, &  1.17 & ) \\
%                                                      & \dwotac{} & ( &  99.2\%, & 1.00, & 1.00, &  1.14 & ) & ( & 95.8\%, & 1.00, & 1.00, &  1.22 & ) & ( & 84.3\%, &  1.01, &  1.00, &  1.34 & ) \\
%                                                      & \otac{B}  & ( &  88.7\%, & 1.01, & 1.00, &  1.31 & ) & ( & 82.7\%, & 1.02, & 1.00, &  1.35 & ) & ( & 69.9\%, &  1.04, &  1.00, &  1.43 & ) \\
%                                                      & \otac{L}  & ( &   0.0\%, & 9.01, & 8.93, & 13.88 & ) & ( &  0.0\%, & 9.35, & 9.27, & 14.81 & ) & ( &  0.0\%, & 10.57, & 10.37, & 17.92 & ) \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{90}{$(10,10)$}} & \notac{}  & ( &  98.8\%, & 1.00, & 1.00, &  1.07 & ) & ( & 89.1\%, & 1.00, & 1.00, &  1.23 & ) & ( & 61.7\%, &  1.02, &  1.00, &  1.22 & ) \\
%                                                      & \dwotac{} & ( &  80.3\%, & 1.01, & 1.00, &  1.26 & ) & ( & 51.2\%, & 1.04, & 1.00, &  1.41 & ) & ( & 42.2\%, &  1.06, &  1.03, &  1.37 & ) \\
%                                                      & \otac{B}  & ( &   1.7\%, & 1.32, & 1.32, &  1.78 & ) & ( &  1.4\%, & 1.38, & 1.39, &  1.87 & ) & ( &  1.6\%, &  1.41, &  1.43, &  1.92 & ) \\
%                                                      & \otac{L}  & ( &   0.0\%, & 4.17, & 4.19, &  5.62 & ) & ( &  0.0\%, & 4.32, & 4.37, &  5.80 & ) & ( &  0.0\%, &  4.34, &  4.40, &  5.80 & ) \\
% \midrule
% \multirow{4}{*}{\rotatebox[origin=c]{90}{$( 4,16)$}} & \notac{}  & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( & 91.7\%, & 1.00, & 1.00, &  1.14 & ) & ( & 41.1\%, &  1.03, &  1.01, &  1.21 & ) \\
%                                                      & \dwotac{} & ( &  99.0\%, & 1.00, & 1.00, &  1.09 & ) & ( & 61.4\%, & 1.03, & 1.00, &  1.34 & ) & ( & 13.0\%, &  1.08, &  1.07, &  1.36 & ) \\
%                                                      & \otac{B}  & ( &   0.0\%, & 1.61, & 1.59, &  2.62 & ) & ( &  0.0\%, & 2.03, & 2.06, &  2.88 & ) & ( &  0.0\%, &  2.42, &  2.40, &  3.13 & ) \\
%                                                      & \otac{L}  & ( &   0.0\%, & 2.22, & 2.16, &  4.72 & ) & ( &  0.0\%, & 2.58, & 2.49, &  4.72 & ) & ( &  0.0\%, &  2.57, &  2.36, &  4.97 & ) \\
% \bottomrule
% \end{tabular}
% }
% \end{table}

\begin{table*}[h]
\centering
\caption{Simulation statistics for all scheduling strategies.
  Each 4-tuple counts the percentage of optimal periods, and the average, median,
  and maximum slowdown ratios. Each pair indicates the average number of cores
  used according to their type.}
\label{tab:stats}
\resizebox{1.9\columnwidth}{!}{
\begin{tabular}{c l c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c
                    c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c
                    c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c
                    c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c
                    c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c
                    c@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    r@{\hskip 0.05in}
                    c}
\toprule
& & \multicolumn{10}{c}{$SR = 0.2$} & \multicolumn{10}{c}{$SR = 0.5$} & \multicolumn{10}{c}{$SR = 0.8$} \\
\cmidrule(lr){3-12} \cmidrule(lr){13-22} \cmidrule(lr){23-32}
& & \multicolumn{6}{c}{Period Statistics} & \multicolumn{4}{c}{Core Usage} & \multicolumn{6}{c}{Period Statistics} & \multicolumn{4}{c}{Core Usage} & \multicolumn{6}{c}{Period Statistics} & \multicolumn{4}{c}{Core Usage} \\
\cmidrule(lr){3-8} \cmidrule(lr){9-12} \cmidrule(lr){13-18} \cmidrule(lr){19-22} \cmidrule(lr){23-28} \cmidrule(lr){29-32}
$R = (b,l)$ & Strategy & ( & \% opt, & avg, & med, & max & ) & ( & $b_{\text{used}}$, & $l_{\text{used}}$ & ) & ( & \% opt, & avg, & med, & max & ) & ( & $b_{\text{used}}$, & $l_{\text{used}}$ & ) & ( & \% opt, & avg, & med, & max & ) & ( & $b_{\text{used}}$, & $l_{\text{used}}$ & ) \\
\midrule
\multirow{5}{*}{\rotatebox[origin=c]{0}{$(16_{\mathcal{B}},4_{\mathcal{L}})$}}
    & \opt{}    & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( & 11.72, &  3.33 & ) & ( &100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( & 11.97, &  3.50 & ) & ( &100.0\%, &  1.00, &  1.00, &  1.00 & ) & ( & 12.63, &  3.49 & ) \\
    & \notac{}  & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( & 11.74, &  3.31 & ) & ( & 99.6\%, & 1.00, & 1.00, &  1.13 & ) & ( & 12.09, &  3.47 & ) & ( & 93.0\%, &  1.00, &  1.00, &  1.17 & ) & ( & 12.91, &  3.37 & ) \\
    & \dwotac{} & ( &  99.2\%, & 1.00, & 1.00, &  1.14 & ) & ( & 12.44, &  3.91 & ) & ( & 95.8\%, & 1.00, & 1.00, &  1.22 & ) & ( & 12.87, &  3.96 & ) & ( & 84.3\%, &  1.01, &  1.00, &  1.34 & ) & ( & 13.30, &  3.86 & ) \\
    & \otac{B}  & ( &  88.7\%, & 1.01, & 1.00, &  1.31 & ) & ( & 14.15, &  0.00 & ) & ( & 82.7\%, & 1.02, & 1.00, &  1.35 & ) & ( & 14.37, &  0.00 & ) & ( & 69.9\%, &  1.04, &  1.00, &  1.43 & ) & ( & 14.41, &  0.00 & ) \\
    & \otac{L}  & ( &   0.0\%, & 9.01, & 8.93, & 13.88 & ) & ( &  0.00, &  4.00 & ) & ( &  0.0\%, & 9.35, & 9.27, & 14.81 & ) & ( &  0.00, &  4.00 & ) & ( &  0.0\%, & 10.57, & 10.37, & 17.92 & ) & ( &  0.00, &  4.00 & ) \\
\addlinespace %\midrule
\multirow{5}{*}{\rotatebox[origin=c]{0}{$(10_{\mathcal{B}},10_{\mathcal{L}})$}}
    & \opt{}    & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( &  9.34, &  7.87 & ) & ( &100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( &  9.02, &  9.24 & ) & ( &100.0\%, &  1.00, &  1.00, &  1.00 & ) & ( &  9.10, &  9.44 & ) \\
    & \notac{}  & ( &  98.8\%, & 1.00, & 1.00, &  1.07 & ) & ( &  9.34, &  7.90 & ) & ( & 89.1\%, & 1.00, & 1.00, &  1.23 & ) & ( &  9.11, &  9.28 & ) & ( & 61.7\%, &  1.02, &  1.00, &  1.22 & ) & ( &  9.33, &  9.36 & ) \\
    & \dwotac{} & ( &  80.3\%, & 1.01, & 1.00, &  1.26 & ) & ( &  9.48, &  8.87 & ) & ( & 51.2\%, & 1.04, & 1.00, &  1.41 & ) & ( &  9.49, &  9.89 & ) & ( & 42.2\%, &  1.06, &  1.03, &  1.37 & ) & ( &  9.56, &  9.87 & ) \\
    & \otac{B}  & ( &   1.7\%, & 1.32, & 1.32, &  1.78 & ) & ( &  9.97, &  0.00 & ) & ( &  1.4\%, & 1.38, & 1.39, &  1.87 & ) & ( &  9.97, &  0.00 & ) & ( &  1.6\%, &  1.41, &  1.43, &  1.92 & ) & ( &  9.99, &  0.00 & ) \\
    & \otac{L}  & ( &   0.0\%, & 4.17, & 4.19, &  5.62 & ) & ( &  0.00, &  9.57 & ) & ( &  0.0\%, & 4.32, & 4.37, &  5.80 & ) & ( &  0.00, &  9.72 & ) & ( &  0.0\%, &  4.34, &  4.40, &  5.80 & ) & ( &  0.00, &  9.81 & ) \\
\addlinespace %\midrule
\multirow{5}{*}{\rotatebox[origin=c]{0}{$(4_{\mathcal{B}},16_{\mathcal{L}})$}}
    & \opt{}    & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( &  3.99, &  7.86 & ) & ( &100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( &  3.99, & 13.32 & ) & ( &100.0\%, &  1.00, &  1.00, &  1.00 & ) & ( &  3.99, & 15.80 & ) \\
    & \notac{}  & ( & 100.0\%, & 1.00, & 1.00, &  1.00 & ) & ( &  3.99, &  7.89 & ) & ( & 91.7\%, & 1.00, & 1.00, &  1.14 & ) & ( &  3.99, & 13.42 & ) & ( & 41.1\%, &  1.03, &  1.01, &  1.21 & ) & ( &  3.99, & 15.83 & ) \\
    & \dwotac{} & ( &  99.0\%, & 1.00, & 1.00, &  1.09 & ) & ( &  3.99, &  9.27 & ) & ( & 61.4\%, & 1.03, & 1.00, &  1.34 & ) & ( &  3.99, & 14.08 & ) & ( & 13.0\%, &  1.08, &  1.07, &  1.36 & ) & ( &  3.99, & 15.91 & ) \\
    & \otac{B}  & ( &   0.0\%, & 1.61, & 1.59, &  2.62 & ) & ( &  4.00, &  0.00 & ) & ( &  0.0\%, & 2.03, & 2.06, &  2.88 & ) & ( &  4.00, &  0.00 & ) & ( &  0.0\%, &  2.42, &  2.40, &  3.13 & ) & ( &  4.00, &  0.00 & ) \\
    & \otac{L}  & ( &   0.0\%, & 2.22, & 2.16, &  4.72 & ) & ( &  0.00, & 10.98 & ) & ( &  0.0\%, & 2.58, & 2.49, &  4.72 & ) & ( &  0.00, & 11.91 & ) & ( &  0.0\%, &  2.57, &  2.36, &  4.97 & ) & ( &  0.00, & 13.20 & ) \\
\bottomrule
\end{tabular}
}
\end{table*}

Although these results are related to our exact simulation parameters, their general trends are the same for longer task chains or different numbers of resources.
Additional experiments (not covered here for the sake of space) have revealed that non-optimal strategies tend to perform worse when more tasks have to be scheduled (more decisions to make), but better when more resources are available (easier to have enough resources for the slowest stage).

%%%
\subsection{Simulation -- Core Usage}

Table~\ref{tab:stats} also provides the average number of big and little cores used by each scheduling strategy for different resources available and SRs.
As our secondary objective is to use as many little cores as necessary to reduce power consumption (Section~\ref{sec:def}), using more little cores and less big ones is desirable.
In general, strategies use more cores when more tasks are replicable (right col., $SR=0.8$) to reduce the period.

We can see that \notac{} tends to use almost the same number of resources as \opt{}.
It uses at most $0.3$ more cores than the minimal, sometimes using more big and less little cores.
\dwotac{}, in its part, tends to use more of both resources in its solution.
By greedily trying to use little cores in earlier stages, it ends up missing opportunities to make better use of these cores later in the pipeline.
Nonetheless, even in its worst average results, \dwotac{} requires~$1.41$ little cores ($R=(4_{\mathcal{B}},16_{\mathcal{L}}), SR=0.2$) or~$1.36$ cores in total ($R=(16_{\mathcal{B}},4_{\mathcal{L}}), SR=0.5$) more than \opt{}.

%%%%%%%%%%%%% RESOURCES STATISTICS
% \begin{table}[!ht]
% \centering
% \caption{Core utilization averages for different algorithms with different pairs of numbers of resources.}
% \label{tab:res}
% \resizebox{0.65\columnwidth}{!}{
% \begin{tabular}{c|ccc}
%  $R=(16,4)$ & $SR = 0.2$ & $SR = 0.5$ & $SR = 0.8$                 \\
% \toprule
% \opt{}    & $(11.72,  3.33)$ & $(11.97,  3.50)$ & $(12.63,  3.49)$ \\
% \notac{}  & $(11.74,  3.31)$ & $(12.09,  3.47)$ & $(12.91,  3.37)$ \\
% \dwotac{} & $(12.44,  3.91)$ & $(12.87,  3.96)$ & $(13.30,  3.86)$ \\
% \otac{B}  & $(14.15,  0.00)$ & $(14.37,  0.00)$ & $(14.41,  0.00)$ \\
% \otac{L}  & $( 0.00,  4.00)$ & $( 0.00,  4.00)$ & $( 0.00,  4.00)$ \\
% \midrule
%   \addlinespace
% $R=(10,10)$ & $SR = 0.2$ & $SR = 0.5$ & $SR = 0.8$                 \\
% \toprule
% \opt{}    & $( 9.34,  7.87)$ & $( 9.02,  9.24)$ & $( 9.10,  9.44)$ \\
% \notac{}  & $( 9.34,  7.90)$ & $( 9.11,  9.28)$ & $( 9.33,  9.36)$ \\
% \dwotac{} & $( 9.48,  8.87)$ & $( 9.49,  9.89)$ & $( 9.56,  9.87)$ \\
% \otac{B}  & $( 9.97,  0.00)$ & $( 9.97,  0.00)$ & $( 9.99,  0.00)$ \\
% \otac{L}  & $( 0.00,  9.57)$ & $( 0.00,  9.72)$ & $( 0.00,  9.81)$ \\
% \midrule
%   \addlinespace
% $R=(4,16)$ & $SR = 0.2$ & $SR = 0.5$ & $SR = 0.8$                  \\
% \toprule
% \opt{}    & $( 3.99,  7.86)$ & $( 3.99, 13.32)$ & $( 3.99, 15.80)$ \\
% \notac{}  & $( 3.99,  7.89)$ & $( 3.99, 13.42)$ & $( 3.99, 15.83)$ \\
% \dwotac{} & $( 3.99,  9.27)$ & $( 3.99, 14.08)$ & $( 3.99, 15.91)$ \\
% \otac{B}  & $( 4.00,  0.00)$ & $( 4.00,  0.00)$ & $( 4.00,  0.00)$ \\
% \otac{L}  & $( 0.00, 10.98)$ & $( 0.00, 11.91)$ & $( 0.00, 13.20)$
% \end{tabular}
% }
% \end{table}

Fig.~\ref{fig:heatmap} explores in more detail the differences between \dwotac{} and \opt{} for one scenario where \dwotac{} achieved the minimum period $51.2\%$ of the times.
Each cell in the heatmaps represent the percentage of times that \dwotac{} uses more, less, or the same number of big and little cores than \opt{}. %(e.g., the red cell with value $27\%$ in Fig.~\ref{fig:heat_all}) 
When considering all results (Fig.~\ref{fig:heat_all}), \dwotac{} uses at most 1 or 2 extra cores $59\%$ and $83.1\%$ of the times, respectively.
When considering only the results where \dwotac{} achieves minimal periods (Fig.~\ref{fig:heat_opt}), the situations where at most 1 or 2 extra cores were necessary change to $21.2\%$ and $39.2\%$ of the times.
These differences may be justified given the difference in computational complexity of the strategies, as will be seen next.

%%%%%%%%%%%%% RESOURCES HEATMAPS
\begin{figure}[!ht]
\centering
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{diff.pdf}
    \caption{All results.}
    \label{fig:heat_all}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{diff_opt.pdf}
    \caption{Only optimal periods.}
    \label{fig:heat_opt}
\end{subfigure}
\caption{Heatmaps with the differences in resources used between \dwotac{} and \opt{} for $R=(10_{\mathcal{B}},10_{\mathcal{L}})$ and $SR=0.5$.}
\label{fig:heatmap}
\end{figure} 

\subsection{Simulation -- Strategies Execution Times}

Fig.~\ref{fig:resources_split} shows the execution times of the different strategies in $\mu s$ for $R=(20_{\mathcal{B}},20_{\mathcal{L}})$ (Fig.~\ref{fig:20_res_split}) and $R=(100_{\mathcal{B}},100_{\mathcal{L}})$ (Fig.~\ref{fig:100_res_split}).
Each point represents the average of 50 runs.
Each line represents a strategy computing schedules for task chains with different stateless ratios.
The lower the time, the better.

We can notice that \dwotac{} displays the same behavior as OTAC.
Having the lowest computational complexity among proposed strategies, its execution times are in the order of $10$ to $100~\mu s$ and they grow proportionally to the number of tasks.

\notac{} has an exponential complexity in the number of tasks, so its results are limited to up to 60~tasks.
Besides its rapid growth in execution time, \notac{} shows distinct execution times depending on how many replicable tasks there are.
Its execution times increase when $SR$ goes from $0.2$ to~$0.5$, but then it decreases by almost two orders of magnitude when $SR=0.8$.
\notac{} is able to pack many tasks together in longer pipeline stages when they are replicable, leading to shorter recursions and fewer comparisons.
Nonetheless, its exponential behavior limits its usage to short task chains.

\opt{}’s execution times grow with the square of the number of tasks, and they already start in the order of ms in the tested scenarios.
Its averages go from $2.476$~ms to $14.381$~ms from 20 to 60 tasks ($R=(20_{\mathcal{B}},20_{\mathcal{L}}), SR=0.8$), and from $78.466$~ms to $3656$~ms ($46.6\times$) from 20 to 160 tasks ($R=(100_{\mathcal{B}},100_{\mathcal{L}}), SR=0.8$).
Its execution times are smaller when fewer tasks are replicable due to an optimization in RecomputeCell (see Section~\ref{sec:dp}).

Fig.~\ref{fig:tasks} reflects the effects of increasing the number of resources.
It shows that the greedy strategies stray mostly unaffected, while \opt{}’s execution times grow.
For instance, its execution times go from $1.72~s$ to $6.38~s$ when going from $R=(100_{\mathcal{B}},100_{\mathcal{L}})$ to $R=(160_{\mathcal{B}},160_{\mathcal{L}})$ ($SR=0.8$ in Fig.~\ref{fig:100_tasks}) --- a $3.7\times$ increase in time for a $1.6\times$ increase in resources.
Although these times are not prohibitive when precomputing a schedule for contemporary task chains and processors, \opt{} could be more difficult to use in bigger scenarios or real-time.
We see how its hypothetically optimal schedules behave when applied in a real scenario next.

%%%%%%%%%%%%% PERFORMANCE LINES
\begin{figure}[h!]
\centering
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{20rs}
    \caption{$R=(20_{\mathcal{B}},20_{\mathcal{L}})$.}
    \label{fig:20_res_split}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{100rs}
    \caption{$R=(100_{\mathcal{B}},100_{\mathcal{L}})$.}
    \label{fig:100_res_split}
\end{subfigure}
\caption{Average strategy times ($\mu$s, log. scale) with fixed numbers of resources.}
\label{fig:resources_split}
\end{figure} 

\begin{figure}[h!]
\centering
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{20ts}
    \caption{$|\tasks{}|=20$.}
    \label{fig:20_tasks}
\end{subfigure}
\hfill
\begin{subfigure}{0.45\columnwidth}
    \includegraphics[width=\columnwidth]{100ts}
    \caption{$|\tasks{}|=100$.}
    \label{fig:100_tasks}
\end{subfigure}
\caption{Average strategy times ($\mu$s, log. scale) with fixed numbers of tasks.}
\label{fig:tasks}
\end{figure} 


%%%
\subsection{Real-world SDR Experiment -- Achieved Throughput}

Table~\ref{tab:dvbs2} summarizes the solutions found on the different platforms using all or half their cores.
They were obtained using the task profiling information listed in Table~\ref{tab:sdr_dvbs2_tasks_thr_lat}.
As expected, task latency is always higher on little cores. However, the latency ratio between little and big cores varies according to task and platform. It underlines the need to profile each task independently.
In Table~\ref{tab:dvbs2}, for each configuration and strategy, the pipeline decomposition is detailed, including the number of little and big cores used, the expected period, and its conversion to throughput metrics.
Besides the estimations, the real average FPS and Mb/s values are presented with their absolute and relative differences to the expected values.
The information throughput is also illustrated in Fig.~\ref{fig:dvbs2}.

\begin{table*}[htp]
  \centering
  \caption{Specification of the configurations $R$ used with the real-world DVB-S2 receiver. Limiting pipeline stages (according to the simulation) are highlighted in \colorbox{Paired-7!15}{orange} if replicable, \colorbox{Paired-5!15}{red} otherwise.}
  \label{tab:dvbs2}
  {\resizebox{1.0\textwidth}{!}{
  \begin{tabular}{l c r l l l r r r r r r r r r r}
  \toprule
  & \multicolumn{1}{c}{} & \multicolumn{7}{c}{Solution} & \multicolumn{2}{c}{FPS} & \multicolumn{4}{c}{Info. Throughput (Mb/s)} \\
  \cmidrule(lr){3-9} \cmidrule(lr){10-11} \cmidrule(lr){12-15}
  & $R = (b,l)$ & Id & Strategy & Pipeline decomposition where a stage is $(n^{\text{tasks}},r_{v \in \{\mathcal{L},\mathcal{B}\}})$ & $|\mathsf{s}|$ & $b_\text{used}$ & $l_\text{used}$ & Period ($\mu$s) & Sim. & Real & Sim. & Real & Diff. & Ratio \\
  \midrule
  \multirow{11}{*}{\rotatebox[origin=c]{90}{Mac Studio}}
  & \multirow{5}{*}{$(8_{\mathcal{B}},2_{\mathcal{L}})$}  & $\mathcal{S}_{ 1}$ & HeRAD    & $(5,1_\mathcal{B}),(1,1_\mathcal{B}),(9,1_\mathcal{B}),$\hlless{$(1,2_\mathcal{B})$}$,(2,1_\mathcal{L}),(1,3_\mathcal{B}),(4,1_\mathcal{L})$                  & $7$ & $ 8$ & $2$ & $ 1128.7$ & $3544$ & $3316$ & $50.4$ & $47.2$ & $ +3.2$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{ 2}$ & 2CATAC   & $(5,1_\mathcal{B}),(3,1_\mathcal{B}),(7,1_\mathcal{B}),$\hlless{$(4,5_\mathcal{B})$}$,(4,1_\mathcal{L})$                                                      & $5$ & $ 8$ & $1$ & $ 1154.3$ & $3465$ & $3590$ & $49.3$ & $51.1$ & $ -1.8$ & $ -4$\% \\
  &                                                       & $\mathcal{S}_{ 3}$ & FERTAC   & $(3,1_\mathcal{L}),(1,1_\mathcal{L}),$\hlsta{$(2,1_\mathcal{B})$}$,(9,1_\mathcal{B}),(5,5_\mathcal{B}),(3,1_\mathcal{B})$                                     & $6$ & $ 8$ & $2$ & $ 1265.6$ & $3160$ & $2944$ & $45.0$ & $41.9$ & $ +3.1$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{ 4}$ & OTAC (B) & $(5,1_\mathcal{B}),(4,1_\mathcal{B}),(6,1_\mathcal{B}),$\hlless{$(4,4_\mathcal{B})$}$,(4,1_\mathcal{B})$                                                      & $5$ & $ 8$ & $0$ & $ 1442.9$ & $2772$ & $2677$ & $39.5$ & $38.1$ & $ +1.4$ & $ +4$\% \\
  &                                                       & $\mathcal{S}_{ 5}$ & OTAC (L) & \hlsta{$(16,1_\mathcal{L})$}$,(7,1_\mathcal{L})$                                                                                                              & $2$ & $ 0$ & $2$ & $11440.0$ & $ 350$ & $ 351$ & $ 5.0$ & $ 5.0$ & $ +0.0$ & $ +0$\% \\
  \addlinespace
  & \multirow{5}{*}{$(16_{\mathcal{B}},4_{\mathcal{L}})$} & $\mathcal{S}_{ 6}$ & HeRAD    & $(3,1_\mathcal{L}),(1,1_\mathcal{L}),(1,1_\mathcal{L}),$\hlsta{$(1,1_\mathcal{B})$}$,(6,1_\mathcal{B}),(7,7_\mathcal{B}),(4,1_\mathcal{L})$                   & $7$ & $ 9$ & $4$ & $  950.6$ & $4208$ & $3934$ & $59.9$ & $56.0$ & $ +3.9$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{ 7}$ & 2CATAC   & $(3,1_\mathcal{L}),(1,1_\mathcal{L}),(1,1_\mathcal{L}),$\hlsta{$(1,1_\mathcal{B})$}$,(9,1_\mathcal{B}),(5,7_\mathcal{B}),(3,1_\mathcal{L})$                   & $7$ & $ 9$ & $4$ & $  950.6$ & $4208$ & $3927$ & $59.9$ & $55.9$ & $ +4.0$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{ 8}$ & FERTAC   & $(3,1_\mathcal{L}),(1,1_\mathcal{L}),(1,1_\mathcal{L}),$\hlsta{$(1,1_\mathcal{B})$}$,(2,1_\mathcal{L}),(7,1_\mathcal{B}),(5,7_\mathcal{B}),(3,1_\mathcal{B})$ & $8$ & $10$ & $4$ & $  950.6$ & $4208$ & $3920$ & $59.9$ & $55.8$ & $ +4.1$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{ 9}$ & OTAC (B) & $(5,1_\mathcal{B}),$\hlsta{$(1,1_\mathcal{B})$}$,(9,1_\mathcal{B}),(5,7_\mathcal{B}),(3,1_\mathcal{B})$                                                       & $5$ & $11$ & $0$ & $  950.6$ & $4208$ & $3927$ & $59.9$ & $55.9$ & $ +4.0$ & $ +7$\% \\
  &                                                       & $\mathcal{S}_{10}$ & OTAC (L) & \hlsta{$(13,1_\mathcal{L})$}$,(6,2_\mathcal{L}),(4,1_\mathcal{L})$                                                                                            & $3$ & $ 0$ & $4$ & $ 6470.9$ & $ 618$ & $ 611$ & $ 8.8$ & $ 8.7$ & $ +1.0$ & $ +1$\% \\
  \midrule
  \multirow{11}{*}{\rotatebox[origin=c]{90}{X7 Ti}}
  & \multirow{5}{*}{$(3_{\mathcal{B}},4_{\mathcal{L}})$}  & $\mathcal{S}_{11}$ & HeRAD    & $(5,1_\mathcal{B}),(10,1_\mathcal{B}),(3,1_\mathcal{B}),$\hlless{$(1,3_\mathcal{L})$}$,(4,1_\mathcal{L})$                                                     & $5$ & $ 3$ & $4$ & $ 2722.1$ & $2939$ & $2726$ & $41.8$ & $38.8$ & $ +3.0$ & $ +8$\% \\
  &                                                       & $\mathcal{S}_{12}$ & 2CATAC   & $(5,1_\mathcal{L}),(10,1_\mathcal{B}),(3,1_\mathcal{B}),$\hlless{$(1,3_\mathcal{L})$}$,(4,1_\mathcal{B})$                                                     & $5$ & $ 3$ & $4$ & $ 2722.1$ & $2939$ & $2677$ & $41.8$ & $38.1$ & $ +3.7$ & $+10$\% \\
  &                                                       & $\mathcal{S}_{13}$ & FERTAC   & $(5,1_\mathcal{L}),(3,1_\mathcal{L}),(7,1_\mathcal{L}),$\hlless{$(4,3_\mathcal{B})$}$,(4,1_\mathcal{L})$                                                      & $5$ & $ 3$ & $4$ & $ 2867.0$ & $2790$ & $2852$ & $39.7$ & $40.6$ & $ -0.9$ & $ -2$\% \\
  &                                                       & $\mathcal{S}_{14}$ & OTAC (B) & $(18,1_\mathcal{B}),$\hlless{$(1,1_\mathcal{B})$}$,(4,1_\mathcal{B})$                                                                                         & $3$ & $ 3$ & $0$ & $ 6209.0$ & $1288$ & $1384$ & $18.3$ & $19.7$ & $ -1.4$ & $ -6$\% \\
  &                                                       & $\mathcal{S}_{15}$ & OTAC (L) & $(15,1_\mathcal{L}),$\hlless{$(4,2_\mathcal{L})$}$,(4,1_\mathcal{L})$                                                                                         & $3$ & $ 0$ & $4$ & $ 7490.3$ & $1068$ & $1025$ & $15.2$ & $14.6$ & $ +0.6$ & $ +4$\% \\
  \addlinespace
  & \multirow{5}{*}{$(6_{\mathcal{B}},8_{\mathcal{L}})$}  & $\mathcal{S}_{16}$ & HeRAD    & $(5,1_\mathcal{B}),$\hlsta{$(1,1_\mathcal{B})$}$,(6,1_\mathcal{B}),(4,2_\mathcal{B}),(3,7_\mathcal{L}),(4,1_\mathcal{L})$                                     & $5$ & $ 6$ & $8$ & $ 1341.9$ & $5962$ & $5108$ & $84.8$ & $72.5$ & $+12.3$ & $+17$\% \\
  &                                                       & $\mathcal{S}_{17}$ & 2CATAC   & $(5,1_\mathcal{B}),$\hlsta{$(1,1_\mathcal{B})$}$,(9,1_\mathcal{B}),(3,2_\mathcal{B}),(2,7_\mathcal{L}),(3,1_\mathcal{L})$                                     & $5$ & $ 6$ & $8$ & $ 1341.9$ & $5962$ & $5052$ & $84.8$ & $71.4$ & $+13.4$ & $+19$\% \\
  &                                                       & $\mathcal{S}_{18}$ & FERTAC   & $(3,1_\mathcal{L}),(2,1_\mathcal{L}),(3,1_\mathcal{B}),(4,1_\mathcal{L}),(6,5_\mathcal{L}),$\hlless{$(1,4_\mathcal{B})$}$,(4,1_\mathcal{B})$                  & $7$ & $ 6$ & $8$ & $ 1552.3$ & $5154$ & $4602$ & $73.3$ & $65.4$ & $ +7.9$ & $+12$\% \\
  &                                                       & $\mathcal{S}_{19}$ & OTAC (B) & $(8,1_\mathcal{B}),(7,1_\mathcal{B}),$\hlless{$(4,3_\mathcal{B})$}$,(4,1_\mathcal{B})$                                                                        & $4$ & $ 6$ & $0$ & $ 2867.0$ & $2790$ & $2712$ & $39.7$ & $38.6$ & $ +1.1$ & $ +3$\% \\
  &                                                       & $\mathcal{S}_{20}$ & OTAC (L) & $(5,1_\mathcal{L}),(5,1_\mathcal{L}),(5,1_\mathcal{L}),$\hlless{$(4,4_\mathcal{L})$}$,(4,1_\mathcal{L})$                                                      & $5$ & $ 0$ & $8$ & $ 3745.1$ & $2136$ & $1833$ & $30.4$ & $26.1$ & $ +4.3$ & $+16$\% \\
  \bottomrule
  \end{tabular}
  }}
\end{table*}

\opt{}, \notac{}, and \dwotac{} propose different pipeline decompositions (Table~\ref{tab:dvbs2}), which result in different throughputs in practice.
We can see in Fig.~\ref{fig:dvbs2_m1u} that the strategies achieved similar throughputs when all cores are available ($R = (16_{\mathcal{B}},4_{\mathcal{L}})$).
With enough big cores, performance gets limited by a sequential task, leaving many cores unused.
On the contrary, performance differs when only half the cores are used ($R = (8_{\mathcal{B}},2_{\mathcal{L}})$).
\notac{} achieves the highest throughput by replicating $5\times$ the stage including the two slowest tasks, while \opt{} separates these tasks in different replicated stages.
This leads to a longer pipeline for a $1.02\times$ expected (but not realized) better throughput.
\dwotac{} ends up using both little cores for the first stages, while using a single big core would have been better (see $\mathcal{S}_{1}$ and $\mathcal{S}_{2}$).
As so, it lacks the extra core by the end of the pipeline, leading to a lower throughput.

Fig.~\ref{fig:dvbs2_x7ti} shows a large gap between schedules using half or all cores.
\opt{} and \notac{} require all cores when $R = (6_{\mathcal{B}},8_{\mathcal{L}})$ to get to the point of being limited by a sequential task.
Meanwhile, OTAC (B) only gets to $53\%$ of \opt{}’s throughput, which again emphasizes the importance of using both types of cores.

When $R = (6_{\mathcal{B}},8_{\mathcal{L}})$, all solutions from our scheduling strategies ($\mathcal{S}_{[16:18]}$) have two consecutive replicated stages using different types of cores.
These required an extension to StreamPU to connect replicated stages.
This feature was unavailable before because, when using only homogeneous resources, it is always better to merge consecutive replicated stages~\cite{benoit2010complexity}.
This enhancement has been released in StreamPU v1.6.0.
Additionally, we see that this configuration shows the highest differences between expected and obtained throughput results.
A common feature of all solutions with differences over $10\%$ is a replicated stage using little cores to handle one of the slowest tasks.
We plan to investigate this further to identify if this is related to an architectural characteristic of the processor, to our compact thread placement, to hidden overheads in StreamPU, or some other reason.

\begin{figure}[htp]
\centering
\begin{subfigure}{0.475\columnwidth}
    \includegraphics[width=\columnwidth]{m1u_scheds}
    \caption{Mac Studio.}
    \label{fig:dvbs2_m1u}
\end{subfigure}
\hfill
\begin{subfigure}{0.475\columnwidth}
    \includegraphics[width=\columnwidth]{x7ti_scheds}
    \caption{X7 Ti.}
    \label{fig:dvbs2_x7ti}
\end{subfigure}
\caption{Achieved throughput on the DVB-S2 receiver depending on the platform and scheduling strategy.}
\label{fig:dvbs2}
\end{figure}

\begin{table}[!htp]
  \centering
  \caption{DVB-S2 receiver’s average task latency on the evaluated platforms. The two slowest sequential and replicable tasks are highlighted in \colorbox{Paired-5!15}{red} and \colorbox{Paired-7!15}{orange}, respectively.}
  \label{tab:sdr_dvbs2_tasks_thr_lat}
  {\resizebox{\columnwidth}{!}{
  {%\small
  \begin{tabular}{l@{\hskip 0.1in}
                  l@{\hskip 0.1in}
                  c@{\hskip 0.1in}
                  r@{\hskip 0.1in}
                  r@{\hskip 0.1in}
                  r@{\hskip 0.1in}
                  r@{\hskip 0.1in}
                  r@{\hskip 0.1in}
                  r@{\hskip 0.1in}}
    \toprule
    & & & \multicolumn{4}{c}{Average Latency ($\mu$s)} \\
    \cmidrule(lr){4-7}
    \multicolumn{3}{c}{Task} & \multicolumn{2}{c}{Mac Studio (4 fra)} & \multicolumn{2}{c}{X7 Ti (8 fra)} \\
    \cmidrule(lr){1-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
    Id & Name & Rep. & $\mathcal{B}$ & $\mathcal{L}$ & $\mathcal{B}$ & $\mathcal{L}$ \\
    \midrule
                            $\tau_{ 1}$  &                  Radio --               \emph{receive} &  \xm & $  52.3$ & $  248.3$ & $  131.7$ & $  133.2$ \\
                            $\tau_{ 2}$  &         Multiplier AGC --             \emph{imultiply} &  \xm & $  75.2$ & $  149.9$ & $  138.3$ & $  318.1$ \\
                            $\tau_{ 3}$  &     Sync. Freq. Coarse --           \emph{synchronize} &  \xm & $  96.4$ & $  496.6$ & $  113.7$ & $  429.0$ \\
                            $\tau_{ 4}$  &         Filter Matched --       \emph{filter (part 1)} &  \xm & $ 318.9$ & $  902.9$ & $  334.8$ & $  711.9$ \\
                            $\tau_{ 5}$  &         Filter Matched --       \emph{filter (part 2)} &  \xm & $ 315.1$ & $  883.2$ & $  329.3$ & $  712.6$ \\
    \rowcolor{Paired-5!15}  $\tau_{ 6}$  &           Sync. Timing --           \emph{synchronize} &  \xm & $ 950.6$ & $ 1468.9$ & $ 1341.9$ & $ 2387.1$ \\
                            $\tau_{ 7}$  &           Sync. Timing --               \emph{extract} &  \xm & $  55.5$ & $  106.0$ & $   58.7$ & $  135.1$ \\
                            $\tau_{ 8}$  &         Multiplier AGC --             \emph{imultiply} &  \xm & $  37.1$ & $   75.4$ & $   63.5$ & $  157.4$ \\
    \rowcolor{Paired-5!15}  $\tau_{ 9}$  &            Sync. Frame --  \emph{synchronize (part 1)} &  \xm & $ 361.0$ & $ 1064.7$ & $  365.9$ & $  848.1$ \\
                            $\tau_{10}$  &            Sync. Frame --  \emph{synchronize (part 2)} &  \xm & $  52.9$ & $  169.1$ & $   81.1$ & $  197.9$ \\
                            $\tau_{11}$  &       Scrambler Symbol --            \emph{descramble} &  \cm & $  16.0$ & $   61.0$ & $   25.1$ & $   65.9$ \\
                            $\tau_{12}$  &  Sync. Freq. Fine L\&R --           \emph{synchronize} &  \xm & $  50.5$ & $  247.1$ & $   54.3$ & $  203.2$ \\
                            $\tau_{13}$  &   Sync. Freq. Fine P/F --           \emph{synchronize} &  \cm & $  99.2$ & $  597.8$ & $  253.8$ & $  356.2$ \\
                            $\tau_{14}$  &             Framer PLH --                \emph{remove} &  \cm & $  23.4$ & $   65.1$ & $   47.4$ & $   87.7$ \\
                            $\tau_{15}$  &        Noise Estimator --              \emph{estimate} &  \cm & $  40.5$ & $   65.4$ & $   32.4$ & $   65.4$ \\
    \rowcolor{Paired-7!15}  $\tau_{16}$  &             Modem QPSK --            \emph{demodulate} &  \cm & $2257.5$ & $ 4838.6$ & $ 2123.1$ & $ 5742.4$ \\
                            $\tau_{17}$  &            Interleaver --          \emph{deinterleave} &  \cm & $  21.1$ & $   58.4$ & $   29.3$ & $   47.6$ \\
                            $\tau_{18}$  &           Decoder LDPC --           \emph{decode SIHO} &  \cm & $ 153.2$ & $  506.7$ & $  239.7$ & $ 1024.4$ \\
    \rowcolor{Paired-7!15}  $\tau_{19}$  &            Decoder BCH --           \emph{decode HIHO} &  \cm & $3339.9$ & $ 7303.5$ & $ 6209.0$ & $ 8166.2$ \\
                            $\tau_{20}$  &       Scrambler Binary --            \emph{descramble} &  \cm & $ 191.7$ & $  464.9$ & $  559.0$ & $  621.8$ \\
                            $\tau_{21}$  &       Sink Binary File --                  \emph{send} &  \xm & $   9.5$ & $   33.3$ & $   34.6$ & $   75.6$ \\
                            $\tau_{22}$  &                 Source --              \emph{generate} &  \xm & $   4.0$ & $   13.6$ & $   16.9$ & $   23.4$ \\
                            $\tau_{23}$  &                Monitor --          \emph{check errors} &  \cm & $   9.5$ & $   21.0$ & $    9.2$ & $   20.5$ \\
    \midrule
                                                                               \multicolumn{3}{r}{Total} & $8530.8$ & $19841.3$ & $12592.5$ & $22530.7$ \\
    \bottomrule
  \end{tabular}
  }
  }}
\end{table}

A final point to notice in Fig.~\ref{fig:dvbs2_x7ti} and Table~\ref{tab:dvbs2} is that \dwotac{} obtains the best throughput for $R = (3_{\mathcal{B}},4_{\mathcal{L}})$.
Although its expected throughput is only $95\%$ of the optimal, it achieved a throughput $4.5\%$ higher than \opt{}.
The main difference in its solution is the use of big cores to replicate the stage with the two slowest tasks, which led to a result better than expected.
This insight points to possible practical improvements to our scheduling solutions in the future.

\begin{comment}
\begin{table*}[t]
  \centering
  \caption
    {Average tasks latency on the DVB-S2 receiver depending on the evaluated
     platforms and on their core types $v \in \{\mathcal{L}, \mathcal{B}\}$
     (transmission phase, 1000 streams, inter-frame level $\in \{4, 8\}$,
     $K = 14232$, $R = 8/9$, MODCOD 2, LDPC horizontal layered NMS 10 ite with
     early stop criterion, error-free SNR zone). The two slowest sequential
     tasks are highlighted in \colorbox{Paired-5!15}{red} and the two slowest
     replicable tasks are highlighted in \colorbox{Paired-7!15}{orange}.}
  \label{tab:sdr_dvbs2_tasks_thr_lat}
  {\resizebox{0.65\linewidth}{!}{
  {\small
  \begin{tabular}{l l c r r r r r r r r r r}
    \toprule
    & & & \multicolumn{4}{c}{Mac Studio (4 frames per stream)} & \multicolumn{4}{c}{X7 Ti (8 frames per stream)} \\
    \multicolumn{3}{c}{Task} & \multicolumn{2}{c}{$\mathcal{L}$} & \multicolumn{2}{c}{$\mathcal{B}$} & \multicolumn{2}{c}{$\mathcal{L}$} & \multicolumn{2}{c}{$\mathcal{B}$}  \\
    \cmidrule(lr){1-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}
    Id & Name & Rep. & Lat. ($\mu$s) & \% of $T$ & Lat. ($\mu$s) & \% of $T$ & Lat. ($\mu$s) & \% of $T$ & Lat. ($\mu$s) & \% of $T$ \\
    \midrule
                            $t_{ 1}$  &                  Radio --               \emph{receive} &  \xm &  $ 248.3$ &  $ 1.25$ & $  52.3$ &  $ 0.61$ &  $ 133.2$ &  $ 0.59$ &  $ 131.7$ &  $ 1.05$ \\
                            $t_{ 2}$  &         Multiplier AGC --             \emph{imultiply} &  \xm &  $ 149.9$ &  $ 0.76$ & $  75.2$ &  $ 0.88$ &  $ 318.1$ &  $ 1.41$ &  $ 138.3$ &  $ 1.10$ \\
                            $t_{ 3}$  &     Sync. Freq. Coarse --           \emph{synchronize} &  \xm &  $ 496.6$ &  $ 2.50$ & $  96.4$ &  $ 1.13$ &  $ 429.0$ &  $ 1.90$ &  $ 113.7$ &  $ 0.90$ \\
                            $t_{ 4}$  &         Filter Matched --       \emph{filter (part 1)} &  \xm &  $ 902.9$ &  $ 4.55$ & $ 318.9$ &  $ 3.74$ &  $ 711.9$ &  $ 3.16$ &  $ 334.8$ &  $ 2.66$ \\
                            $t_{ 5}$  &         Filter Matched --       \emph{filter (part 2)} &  \xm &  $ 883.2$ &  $ 4.45$ & $ 315.1$ &  $ 3.69$ &  $ 712.6$ &  $ 3.16$ &  $ 329.3$ &  $ 2.62$ \\
    \rowcolor{Paired-5!15}  $t_{ 6}$  &           Sync. Timing --           \emph{synchronize} &  \xm &  $1468.9$ &  $ 7.40$ & $ 950.6$ &  $11.14$ &  $2387.1$ &  $10.59$ &  $1341.9$ &  $10.66$ \\
                            $t_{ 7}$  &           Sync. Timing --               \emph{extract} &  \xm &  $ 106.0$ &  $ 0.53$ & $  55.5$ &  $ 0.65$ &  $ 135.1$ &  $ 0.60$ &  $  58.7$ &  $ 0.47$ \\
                            $t_{ 8}$  &         Multiplier AGC --             \emph{imultiply} &  \xm &  $  75.4$ &  $ 0.38$ & $  37.1$ &  $ 0.44$ &  $ 157.4$ &  $ 0.70$ &  $  63.5$ &  $ 0.50$ \\
    \rowcolor{Paired-5!15}  $t_{ 9}$  &            Sync. Frame --  \emph{synchronize (part 1)} &  \xm &  $1064.7$ &  $ 5.37$ & $ 361.0$ &  $ 4.23$ &  $ 848.1$ &  $ 3.76$ &  $ 365.9$ &  $ 2.91$ \\
                            $t_{10}$  &            Sync. Frame --  \emph{synchronize (part 2)} &  \xm &  $ 169.1$ &  $ 0.85$ & $  52.9$ &  $ 0.62$ &  $ 197.9$ &  $ 0.88$ &  $  81.1$ &  $ 0.64$ \\
                            $t_{11}$  &       Scrambler Symbol --            \emph{descramble} &  \cm &  $  61.0$ &  $ 0.31$ & $  16.0$ &  $ 0.19$ &  $  65.9$ &  $ 0.29$ &  $  25.1$ &  $ 0.20$ \\
                            $t_{12}$  &  Sync. Freq. Fine L\&R --           \emph{synchronize} &  \xm &  $ 247.1$ &  $ 1.25$ & $  50.5$ &  $ 0.59$ &  $ 203.2$ &  $ 0.90$ &  $  54.3$ &  $ 0.43$ \\
                            $t_{13}$  &   Sync. Freq. Fine P/F --           \emph{synchronize} &  \cm &  $ 597.8$ &  $ 3.01$ & $  99.2$ &  $ 1.16$ &  $ 356.2$ &  $ 1.58$ &  $ 253.8$ &  $ 2.02$ \\
                            $t_{14}$  &             Framer PLH --                \emph{remove} &  \cm &  $  65.1$ &  $ 0.33$ & $  23.4$ &  $ 0.27$ &  $  87.7$ &  $ 0.39$ &  $  47.4$ &  $ 0.38$ \\
                            $t_{15}$  &        Noise Estimator --              \emph{estimate} &  \cm &  $  65.4$ &  $ 0.33$ & $  40.5$ &  $ 0.47$ &  $  65.4$ &  $ 0.29$ &  $  32.4$ &  $ 0.26$ \\
    \rowcolor{Paired-7!15}  $t_{16}$  &             Modem QPSK --            \emph{demodulate} &  \cm &  $4838.6$ &  $24.39$ & $2257.5$ &  $26.46$ &  $5742.4$ &  $25.49$ &  $2123.1$ &  $16.86$ \\
                            $t_{17}$  &            Interleaver --          \emph{deinterleave} &  \cm &  $  58.4$ &  $ 0.29$ & $  21.1$ &  $ 0.25$ &  $  47.6$ &  $ 0.21$ &  $  29.3$ &  $ 0.23$ \\
                            $t_{18}$  &           Decoder LDPC --           \emph{decode SIHO} &  \cm &  $ 506.7$ &  $ 2.55$ & $ 153.2$ &  $ 1.80$ &  $1024.4$ &  $ 4.55$ &  $ 239.7$ &  $ 1.90$ \\
    \rowcolor{Paired-7!15}  $t_{19}$  &            Decoder BCH --           \emph{decode HIHO} &  \cm &  $7303.5$ &  $36.81$ & $3339.9$ &  $39.15$ &  $8166.2$ &  $36.24$ &  $6209.0$ &  $49.31$ \\
                            $t_{20}$  &       Scrambler Binary --            \emph{descramble} &  \cm &  $ 464.9$ &  $ 2.34$ & $ 191.7$ &  $ 2.25$ &  $ 621.8$ &  $ 2.76$ &  $ 559.0$ &  $ 4.44$ \\
                            $t_{21}$  &       Sink Binary File --                  \emph{send} &  \xm &  $  33.3$ &  $ 0.17$ & $   9.5$ &  $ 0.11$ &  $  75.6$ &  $ 0.34$ &  $  34.6$ &  $ 0.27$ \\
                            $t_{22}$  &                 Source --              \emph{generate} &  \xm &  $  13.6$ &  $ 0.07$ & $   4.0$ &  $ 0.05$ &  $  23.4$ &  $ 0.10$ &  $  16.9$ &  $ 0.13$ \\
                            $t_{23}$  &                Monitor --          \emph{check errors} &  \cm &  $  21.0$ &  $ 0.11$ & $   9.5$ &  $ 0.11$ &  $  20.5$ &  $ 0.09$ &  $   9.2$ &  $ 0.07$ \\
    \midrule
                                                                            \multicolumn{3}{r}{Total} & $19841.3$ & $100.00$ & $8530.8$ & $100.00$ & $22530.7$ & $100.00$ & $12592.5$ & $100.00$ \\
    \bottomrule
  \end{tabular}
  }
  }}    
\end{table*}
\end{comment}

%\work{explain experiment organization}{Laercio}
%\work{explain results}{Laercio}
%\work{table advantages and limitations of algorithms}{Laercio} - maybe a section dedicated to it

\section{Concluding Remarks}\label{sec:conclusion}

In this paper, we considered the problem of scheduling partially-replicable task chains on two types of resources to optimize throughput (minimize period) and power consumption (use as many little cores as necessary).
We have proposed two greedy strategies (\dwotac{} that tries to use little cores as early as possible, and \notac{} that tries to use both core types at each stage) and one optimal dynamic programming strategy (\opt{}).
Fig.~\ref{fig:spider_algs} summarizes their main characteristics based on our experimental evaluation and analysis.

\begin{figure}[h!]
  \centering
  \includegraphics[width=1.0\columnwidth]{algos}
  \caption{Advantages and limitations of the proposed strategies.}
  \label{fig:spider_algs}
\end{figure}

Using simulation, we have verified that \dwotac{} and \notac{} are able to obtain near-optimal schedules on average, with minor increases in period and resource utilization.
We have shown that the general quality of their schedules is affected by characteristics of the platform (number of cores) and the task chain (e.g., the number of replicable tasks).

Our real-world experiments with the DVB-S2 receiver task chain in two heterogeneous multicore platforms have enabled us to validate our scheduling strategies, with each algorithm achieving the highest throughput in at least one configuration.
% The average difference between expected and measured throughput was limited to~$7.4\%$, which we consider a positive result when moving from theory to practice.
Fig.~\ref{fig:spider_algs} shows that, on average, the real throughput difference compared to the best theoretical throughput (from HeRAD's expected period) ranges between 9\% for 2CATAC and 15\% for FERTAC, considering that HeRAD itself achieves 10\% differences of its target. We think this as a positive result when moving from theory to practice.
Our results have also emphasized the importance of using both types of cores, as the optimal solution for homogeneous resources (OTAC) usually lagged behind our scheduling strategies.

As future work, we intend to take lessons from our experimental evaluation to improve future solutions.
We will profile the communication and synchronization overheads on StreamPU to understand how they affect the schedules and include them in our model, if necessary.
We will study how to incorporate some of the features of our best schedules (such as shorter pipelines) into our strategies, and also how to use direct power measurements instead of assumptions about the architectures to optimize energy consumption.
Additionally, we plan to evaluate the impact on placing multiple stages on the same core to benefit from simultaneous multithreading and very low communication overhead.
Finally, we would like to evaluate the impact of thread placement on the achieved throughput and on the energy consumption.

\section*{Acknowledgment}
{\small
\noindent
This work has received support from France 2030 through the project named Académie Spatiale d'Île-de-France (\url{https://academiespatiale.fr/}) managed by the National Research Agency under bearing the reference ANR-23-CMAS-0041.
}

\balance

\bibliographystyle{IEEEtran}
\bibliography{aff3ctbib.bib}

\end{document}
