\section{Related Work}
\subsection{Adversarial Attacks}
While numerous adversarial algorithms are dedicated to generating high-quality and robust adversarial samples, gradient-based attack algorithms constitute a main type. FGSM~\citep{goodfellow2014explaining} was the first to utilise the model's gradients, which adds a small perturbation to the input data in the direction of the gradient, thereby maximising the loss function through gradient ascent to achieve optimal attack performance. MI-FGSM~\citep{dong2018boosting} incorporates a momentum factor in each iteration to mitigate the impact of local optima on the attack success rate. TI-FGSM~\citep{dong2019evading} employs shifted images to calculate the input gradient, a process that involves convolving the original image's input gradient with a kernel matrix.

Other adversarial attack algorithms, such as PGD~\citep{madry2017towards}, project samples onto suitable attack directions and limit the size of perturbations to generate robust adversarial examples. C\&W method minimises the attack's objective function to optimise the generation process~\citep{carlini2017towards}. AdvGAN~\citep{xiao2018generating} employs an adversarial training process between the generator and discriminator. This process bolsters the generator's ability to produce adversarial samples, making them challenging for the discriminator to distinguish from genuine data. Besides attack purpose, we also note some other iterative training methods for GANs, such as the Progressive GAN~\citep{karras2017progressive} which divides the Generator into several layers, with each layer undergoing individual training. In our approach, we consider an auto-regression methods, where each subsequent generation is based on the results of previous step. Although auto-regression GAN has been improved for continuous generation tasks, all we need is the attack result of the last state, so we need to redesign it for this situation.
%Additionally, an iterative training method for GANs, known as Progressive GAN~\citep{karras2017progressive}, exists. Progressive GAN divides the Generator into several layers, with each layer undergoing individual training. This method differs fundamentally from auto-regression methods, where each subsequent generation is based on the results of previous step. Therefore, our proposed method is fundamentally distinct from it.

% \subsection{Generative Adversarial Network}
\subsection{Adversarial Defenses}
Adversarial defense represents an effective approach to mitigate the impact of attacks on DNNs. Commonly used adversarial defense techniques include denoising and adversarial training. The denoising technique employs preprocessing mechanisms to filter out adversarial examples, thereby preventing the poisoning of training data and reducing the likelihood of subsequent attacks on the model. Other notable works include HRGD~\citep{liao2018defense}, R\&P~\citep{xie2017mitigating} and so on~\citep{dziugaite2016study,cohen2019certified}.

Adversarial training enhances model robustness by incorporating adversarial examples into the training process. Ensemble adversarial training~\citep{hang2020ensemble} works by decoupling the target model from adversarial examples generated by other black-box models, thereby defending against transferable attacks. To enhance the robustness of our algorithm against adversarial defenses, we validated the attack effectiveness of PAR-AdvGAN on the target model subjected to ensemble adversarial training.


%