
@ARTICLE{George_IEEETBIOM_2024,
  author={George, Anjith and Ecabert, Christophe and Shahreza, Hatef Otroshi and Kotwal, Ketan and Marcel, Sébastien},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science}, 
  title={EdgeFace: Efficient Face Recognition Model for Edge Devices}, 
  year={2024},
  volume={6},
  number={2},
  pages={158-168},
  keywords={Face recognition;Computational modeling;Transformers;Edge computing;Convolutional neural networks;Computational complexity;Efficient face recognition;edge devices;face recognition},
  doi={10.1109/TBIOM.2024.3352164}
}


@INPROCEEDINGS{uerc2023,

  author={Emer{\v{s}}i{\v{c}}, {\v{Z}}. and Ohki, T. and Akasaka, M. and Arakawa, T. and Maeda, S. and Okano, M. and Sato, Y. and George, A. and Marcel, S. and Ganapathi, I. I. and Ali, S. S. and Javed, S. and Werghi, N. and Işık, S. G. and Sarıtaş, E. and Ekenel, H. K. and Hudovernik, V. and Kolf, J. N. and Boutros, F. and Damer, N. and Sharma, G. and Kamboj, A. and Nigam, A. and Jain, D. K. and Cámara-Chávez, G. and Peer, P. and Štruc, V.},

  booktitle={2023 IEEE International Joint Conference on Biometrics (IJCB)}, 

  title={The Unconstrained Ear Recognition Challenge 2023: Maximizing Performance and Minimizing Bias}, 

  year={2023},

  volume={},

  number={},

  pages={1-10},

  keywords={Training;Image recognition;Error analysis;Biometrics (access control);Training data;Ear;Transformers;Data models;Convolutional neural networks;Task analysis},

  doi={10.1109/IJCB57857.2023.10449062}}

@article{Benzaoui_survey_earrec,
  title={A comprehensive survey on ear recognition: databases, approaches, comparative analysis, and open challenges},
  author={Benzaoui, Amir and Khaldi, Yacine and Bouaouina, Rafik and Amrouni, Nadia and Alshazly, Hammam and Ouahabi, Abdeldjalil},
  journal={Neurocomputing},
  volume={537},
  pages={236--270},
  year={2023},
  publisher={Elsevier}
}

@INPROCEEDINGS{Ibrahim_effect_ears_age,
  author={Ibrahim, Mina I. S. and Nixon, Mark S. and Mahmoodi, Sasan},
  booktitle={2011 International Joint Conference on Biometrics (IJCB)}, 
  title={The effect of time on ear biometrics}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  keywords={Analysis of variance;Biomedical imaging;Histograms;Ear;Educational institutions},
  doi={10.1109/IJCB.2011.6117584}}

@article{Dargan_biometrics_survey,
  title={A comprehensive survey on the biometric recognition systems based on physiological and behavioral modalities},
  author={Dargan, Shaveta and Kumar, Munish},
  journal={Expert Systems with Applications},
  volume={143},
  pages={113114},
  year={2020},
  publisher={Elsevier}
}

@article{Ziga_ear_recog_review,
  title={Evaluation and analysis of ear recognition models: performance, complexity and resource requirements},
  author={Emer{\v{s}}i{\v{c}}, {\v{Z}}iga and Meden, Bla{\v{z}} and Peer, Peter and {\v{S}}truc, Vitomir},
  journal={Neural computing and applications},
  volume={32},
  pages={15785--15800},
  year={2020},
  publisher={Springer}
}

@ARTICLE{Alshazly_Ear_Resnet,
  author={Alshazly, Hammam and Linse, Christoph and Barth, Erhardt and Idris, Sahar Ahmed and Martinetz, Thomas},
  journal={IEEE Access}, 
  title={Towards Explainable Ear Recognition Systems Using Deep Residual Networks}, 
  year={2021},
  volume={9},
  number={},
  pages={122254-122273},
  keywords={Ear;Feature extraction;Image recognition;Visualization;Training;Transfer learning;Task analysis;Ear recognition;biometrics;deep residual networks;transfer learning;deep ensembles;visual explanations;explainable prediction},
  doi={10.1109/ACCESS.2021.3109441}}

@article{Korichi_TRICA,
  title={TR-ICANet: A fast unsupervised deep-learning-based scheme for unconstrained ear recognition},
  author={Korichi, Aicha and Slatnia, Sihem and Aiadi, Oussama},
  journal={Arabian Journal for Science and Engineering},
  volume={47},
  number={8},
  pages={9887--9898},
  year={2022},
  publisher={Springer}
}

@article{Howard_mobilenet,
  title={MobileNets: efficient convolutional neural networks for mobile vision applications (2017)},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  volume={126},
  year={2017}
}
@inproceedings{Sandler_mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@article{Iandola2_squeezenet,
  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}

@inproceedings{Zhang_shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{Wu_shift,
  title={Shift: A zero flop, zero parameter alternative to spatial convolutions},
  author={Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Golmant, Noah and Gholaminejad, Amir and Gonzalez, Joseph and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9127--9135},
  year={2018}
}

@inproceedings{Han_ghostnet,
  title={Ghostnet: More features from cheap operations},
  author={Han, Kai and Wang, Yunhe and Tian, Qi and Guo, Jianyuan and Xu, Chunjing and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1580--1589},
  year={2020}
}

@inproceedings{alexey_VIT,
  added-at = {2023-06-22T17:58:14.000+0200},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  biburl = {https://www.bibsonomy.org/bibtex/2242f2231f90af37d7169530db3da4375/andolab},
  booktitle = {International Conference on Learning Representations},
  interhash = {325eaaeb3466512b4b887cc143bde420},
  intrahash = {242f2231f90af37d7169530db3da4375},
  keywords = {Transformer ViT},
  timestamp = {2023-06-22T17:58:14.000+0200},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  url = {https://openreview.net/forum?id=YicbFdNTTy},
  year = 2021
}

@inproceedings{Chen_mobileformer,
  title={Mobile-former: Bridging mobilenet and transformer},
  author={Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Dong, Xiaoyi and Yuan, Lu and Liu, Zicheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5270--5279},
  year={2022}
}

@inproceedings{
Mehta_mobilevit,
title={MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer},
author={Sachin Mehta and Mohammad Rastegari},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=vh-0sUt8HlG}
}


@inproceedings{Maaz_edgenext,
  title={Edgenext: efficiently amalgamated cnn-transformer architecture for mobile vision applications},
  author={Maaz, Muhammad and Shaker, Abdelrahman and Cholakkal, Hisham and Khan, Salman and Zamir, Syed Waqas and Anwer, Rao Muhammad and Shahbaz Khan, Fahad},
  booktitle={European conference on computer vision},
  pages={3--20},
  year={2022},
  organization={Springer}
}

@inproceedings{liu_convnext,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11976--11986},
  year={2022}
}

@article{mehta2024efficient,
  title={An efficient ear recognition technique based on deep ensemble learning approach},
  author={Mehta, Ravishankar and Singh, Koushlendra Kumar},
  journal={Evolving Systems},
  volume={15},
  number={3},
  pages={771--787},
  year={2024},
  publisher={Springer}
}

@article{xu2022efficient,
  title={An efficient and lightweight method for human ear recognition based on MobileNet},
  author={Xu, Xuebin and Liu, Yibiao and Cao, Shuxin and Lu, Longbin},
  journal={Wireless Communications and Mobile Computing},
  volume={2022},
  number={1},
  pages={9069007},
  year={2022},
  publisher={Wiley Online Library}
}


@inproceedings{kolf2023efar,
  title={Efar 2023: Efficient face recognition competition},
  author={Kolf, Jan Niklas and Boutros, Fadi and Elliesen, Jurek and Theuerkauf, Markus and Damer, Naser and Alansari, Mohamad and Hay, Oussama Abdul and Alansari, Sara and Javed, Sajid and Werghi, Naoufel and others},
  booktitle={2023 IEEE International Joint Conference on Biometrics (IJCB)},
  pages={1--12},
  year={2023},
  organization={IEEE}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

%only on arxiv as far as we know
@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}


@article{hoang2019earvn1,
    title = {EarVN1.0: A new large-scale ear images dataset in the wild},
    journal = {Data in Brief},
    volume = {27},
    pages = {104630},
    year = {2019},
    issn = {2352-3409},
    doi = {https://doi.org/10.1016/j.dib.2019.104630},
    url = {https://www.sciencedirect.com/science/article/pii/S2352340919309850},
    author = {Vinh Truong Hoang},
    keywords = {Ear recognition, Biometric, Image classification, Super-resolution, Image clustering, Right-ear or left-ear detection},
}

@article{hogan2023averaging,
  title={On averaging ROC curves},
  author={Hogan, Jack and Adams, Niall M},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@INPROCEEDINGS{emersic2017,
  author={Emer\v{s}i\v{c}, \v{Z}iga and \v{S}tepec, Dejan and \v{S}truc, Vitomir and Peer, Peter},
  booktitle={2017 12th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2017)}, 
  title={Training Convolutional Neural Networks with Limited Training Data for Ear Recognition in the Wild}, 
  year={2017},
  volume={},
  number={},
  pages={987-994},
  keywords={Conferences;Face;Gesture recognition},
  doi={10.1109/FG.2017.123}}

@INPROCEEDINGS{uerc2017,
  author={Emer\v{s}i\v{c}, \v{Z}iga and \v{S}tepec, Dejan and \v{S}truc, Vitomir and Peer, Peter and George, Anjith and Ahmad, Adii and Omar, Elshibani and Boult, Terranee E. and Safdaii, Reza and Zhou, Yuxiang and Zafeiriou, Stefanos and Yaman, Dogucan and Eyiokur, Fevziye I. and Ekenel, Hazim K.},
  booktitle={2017 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={The unconstrained ear recognition challenge}, 
  year={2017},
  volume={},
  number={},
  pages={715-724},
  keywords={Ear;Training;Image recognition;Probes;Protocols;Benchmark testing},
  doi={10.1109/BTAS.2017.8272761}}

@INPROCEEDINGS{uerc2019,
  author={Emer\v{s}i\v{c}, \v{Z}. and S. V., A. Kumar and Harish, B. S. and Gutfeter, W. and Khiarak, J. N. and Pacut, A. and Hansley, E. and Segundo, M. Pamplona and Sarkar, S. and Park, H. J. and Nam, G. P. and Kim, I.-J. and Sangodkar, S. G. and Kacar, U. and Kirci, M. and Yuan, L. and Yuan, J. and Zhao, H. and Lu, F. and Mao, J. and Zhang, X. and Yaman, D. and Eyiokur, F. I. and Özler, K. B. and Ekenel, H. K. and Paul Chowdhury, D. and Bakshi, S. and Sa, P. K. and Majhi, B. and Peer, P. and \v{S}truc, V.},
  booktitle={2019 International Conference on Biometrics (ICB)}, 
  title={The Unconstrained Ear Recognition Challenge 2019}, 
  year={2019},
  volume={},
  number={},
  pages={1-15},
  keywords={},
  doi={10.1109/ICB45273.2019.8987337}}



@Inbook{Emersic2019,
author="Emer{\v{s}}i{\v{c}}, {\v{Z}}iga
and Kri{\v{z}}aj, Janez
and {\v{S}}truc, Vitomir
and Peer, Peter",
editor="Hassaballah, Mahmoud
and Hosny, Khalid M.",
title="Deep Ear Recognition Pipeline",
bookTitle="Recent Advances in Computer Vision: Theories and Applications",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="333--362",
abstract="Ear recognition has seen multiple improvements in recent years and still remains very active today. However, it has been approached from recognition and detection perspective separately. Furthermore, deep-learning-based approachesEmer{\v{s}}i{\v{c}}, {\v{Z}}iga that are popular in other domains have seen limited use in ear recognition and even more so in ear detection. Moreover, to obtain a usableKri{\v{z}}aj, Janez recognition system a unified pipeline{\v{S}}truc, Vitomir is needed. The input in such system should be plain images of subjects and thePeer, Peter output identities based only on ear biometrics. We conduct separate analysis through detection and identification experiments on the challenging dataset and, using the best approaches, present a novel, unified pipeline. The pipeline is based on convolutional neural networks (CNN) and presents, to the best of our knowledge, the first CNN-based ear recognition pipeline. The pipeline incorporates both, the detection of ears on arbitrary images of people, as well as recognition on these segmented ear regions. The experiments show that the presented system is a state-of-the-art system and, thus, a good foundation for future real-word ear recognition systems.",
isbn="978-3-030-03000-1",
doi="10.1007/978-3-030-03000-1_14",
url="https://doi.org/10.1007/978-3-030-03000-1_14"
}
