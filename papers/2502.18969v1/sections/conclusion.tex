\section{Conclusion}\label{sec:conclusion}

We survey over 50 papers on scaling laws, and discuss differences in form, training setup, evaluation, and curve fitting, which may lead to significantly different conclusions. We also discuss significant under-reporting of details crucial to replicating the conclusion of these studies, and provide guidelines in the form of a checklist aid researchers in reporting more complete details. In addition to discussing several prior replication studies in literature, we empirically demonstrate the fragility of this process, by systematically varying these choices on available checkpoints and models that we train from scratch.
% \textcolor{blue}{
We choose to avoid overly prescriptive recommendations, because there is no known set of actions which can guarantee a good scaling law fit, but we make some suggestions based on patterns in our findings (Appendix \S\ref{sec:app_recs}).
% }
% Recommended action: We choose to avoid being overly prescriptive in our recommendations because there is no set of actions which can guarantee a good scaling law fit, nor even make a fit extremely likely.
% (1) It is intractable to establish what the desired final scaling law is, and therefore to measure the goodness of any scaling law fit, because we don't know the ground truth of model performance at all scales. Any attempt to estimate the goodness of a scaling law fit can only consider the goodness fit at a small number of points with limited scale, and it is unclear how heavily to weigh the goodness at each point.
% (2) As seen in our S7 analyses, many decisions in our checklist have a number of reasonable options, but those reasonable choices lead to a wide range of scaling law fits, and the observed variations do not follow any clear pattern. It is probable that variations would be even harder to predict when varying model architectures or other design decisions.
% However, it is certainly possible to determine that some scaling law fits are plausible or highly implausible, and to observe the stability of fits. For example, in Figure 2(a), neither of the recommended data/parameters ratios of ~1/2200 or 3000/1 at 10^25 FLOPs are likely to be the true optimal settings, and the loss predictions at those points are also unlikely to be close to ground truth. Based on these observations, we can make some more concrete recommendations, with the caveat that following the recommendations is no absolute guarantee of good scaling law fit. For example, Appendix Figure 3(c) suggests the importance of using a large range of data/parameter ratios and absolute model parameter counts across the experiments, since using too narrow a range can skew the final fit dramatically. Additionally, no paper we know of has achieved a plausible scaling law fit by directly optimizing a power law form for performance prediction with 5 or more scaling law parameters, so we recommend considering an IsoFLOP or multi-stage approach (e.g., fitting a relation between L and C, then a relation between C and optimal N). We will update the camera ready with these recommendations.
Despite our preliminary investigations, our understanding of which decisions may skew the results of a scaling law study is sparse, and defines the path for future work.

\paragraph{Ethics Statement} This work discusses how a lack of reproducibility and open-sourcing may be harmful for scaling laws research, given that the factors in a study setup that may change research conclusions vary widely.

\paragraph{Reproducibility Statement} The model checkpoints and analysis code required to reproduce the results discussed in Section \ref{sec:own-repl} are at \url{https://github.com/hadasah/scaling_laws}.


% - very few papers that claim to find a scaling law are actually fitting a power law
% - the ones that do vary significantly in the number of data points and the experimental setup, as well as their power law form, and the methods they use to fit the power laws
% - replication difficult b/c of underspecification and very fragile process, lack of open sourcing, data noisiness
% - 
