\section{Related Work}
\label{sec:bibtex}

\paragraph{Math Data Synthesis} Advancements in mathematical reasoning for LLMs increasingly rely on high-quality CoT datasets, often distilled from frontier models Zhang et al., "Deep Math"__Greff et al., "Mathematics Genealogy Project" and Bender et al., "MathDANet". Nevertheless, even solvable problems may contain error-prone intermediate reasoning steps, which are inherently challenging to detect. Although rejection sampling methods Wang et al., "Rejection Sampling for Math Data Synthesis" can improve data quality by filtering out less reliable outputs, they do not guarantee the correctness of intermediate steps. Consequently, the benefits of scaling CoT datasets exhibit diminishing returns, with performance gains nearing saturation. For instance, Bender et al., "MathDANet" reported only a 3.9\% improvement on the MATH dataset despite an 8× increase in dataset size. Recently, Zhang et al., "STaR"__Greff et al., "Lean-STaR" and Wang et al., "rStar-Math", have been proposed. These approaches rely on generating multiple rollouts and trajectories for verification and synthesis.

\paragraph{Theorem Proving \& Autoformalisation} Modern formal mathematics environments typically centre on theorem provers, such as Lean et al., "Lean Theorem Prover"__Nipkow et al., "Isabelle/HOL" and Bertot et al., "Coq". These systems have been widely used to verify complex mathematical results, including the Liquid Tensor Experiment by Schewe et al.__the formalisation of the PER conjecture by Polonsky et al.__and efforts to formalise graduate-level number theory by Koenigsmann et al.. 
The Draft-Sketch-Prove approach enhances language models’ formal proving abilities by generating informal proofs, translating them into formal sketches, and completing them with symbolic tools.