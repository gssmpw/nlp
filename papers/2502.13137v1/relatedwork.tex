\section{Related Work}
\label{sec:bibtex}

\paragraph{Math Data Synthesis} Advancements in mathematical reasoning for LLMs increasingly rely on high-quality CoT datasets, often distilled from frontier models~\cite{guo2025deepseek, wang2023mathcoder, gou2023tora, luo2024improve, yu2023metamath, tang2024mathscale}, such as
NuminaMath~\cite{li2024numinamath} and OpenMathInstruct~\cite{toshniwal2024openmathinstruct}. Nevertheless, even solvable problems may contain error-prone intermediate reasoning steps, which are inherently challenging to detect. Although rejection sampling methods~\cite{yuan2023scaling, brown2024large} can improve data quality by filtering out less reliable outputs, they do not guarantee the correctness of intermediate steps. Consequently, the benefits of scaling CoT datasets exhibit diminishing returns, with performance gains nearing saturation. For instance, OpenMathInstruct reported only a 3.9\% improvement on the MATH dataset despite an 8× increase in dataset size. Recently, STaR~\cite{zelikman2022star},
Lean-STaR~\cite{lin2024lean} and rStar-Math~\cite{guan2025rstar}, have been proposed. These approaches rely on generating multiple rollouts and trajectories for verification and synthesis.

\paragraph{Theorem Proving \& Autoformalisation} Modern formal mathematics environments typically centre on theorem provers, such as Lean~\cite{jiang2024leanreasoner, lin2024lean}, Isabelle~\cite{zhou2024don, xin2023lego} and Coq~\cite{huet1997coq}. These systems have been widely used to verify complex mathematical results, including the Liquid Tensor Experiment~\cite{castelvecchi2021mathematicians}, the formalisation of the PER conjecture~\cite{gowers2023conjecture}, and efforts to formalise graduate-level number theory~\cite{eberl2024formalising}.
The Draft-Sketch-Prove~\cite{jiang2022draft} approach enhances language models’ formal proving abilities by generating informal proofs, translating them into formal sketches, and completing them with symbolic tools. 
%Recently, \citet{yang2024formal} highlighted that formalising question is particularly challenging in autoformalisation, as there are no definitive metrics to assess the correctness of the formalisation.