

\begin{figure}[!t]
\centering	\includegraphics[width=0.98\linewidth]{Figures/sample.pdf}
    \caption{Schematic of Feature Resonance.}
    \label{F-sample}
\end{figure}


\section{Method}\label{Sec-Method}
% In this section, we present our proposed framework, \textbf{RSL} (\textbf{R}esonance-based \textbf{S}eparate and \textbf{L}earn), for detecting category-free OOD nodes. In Section \ref{subsec-reveal-FR}, we define the concept of the feature resonance phenomenon. Section \ref{subsec-utilizing-FR} describes how to leverage the feature resonance phenomenon to identify reliable candidate OOD nodes and utilize the identified reliable OOD nodes to train an OOD node classifier. The Section\ref{subsec_Train-OOD-classifer} introduces how to integrate the resonance-based score and synthetic OOD node strategies. In Section \ref{subsec-Theoretical}, we introduce the upper bound of the generalization error for filtering candidate OOD nodes.

\subsection{Revealing the Feature Resonance Phenomenon}\label{subsec-reveal-FR}
Previous studies \citep{hendrycks2016baseline,liu2020energy,wu2023energy} mostly train a classifier on ID nodes with multi-category labels and develop selection criteria based on output probabilities, e.g. entropy. 
However, these methods become inapplicable in category-free scenarios.
% where multi-category labels are unavailable. 

To address this problem, we turn our attention to the intrinsic similarities within the data. An intuitive idea is that although the output space may no longer be reliable, the ID samples may still share some commonalities in the representation space.
We hypothesize that when optimizing the representation of known ID nodes, the representation of unknown ID nodes and unknown OOD nodes will change with different trajectories. Motivated by this, and under the assumption of some specific training process, we define a \textbf{feature trajectory measure} $\hat{F}(\tilde{\mathbf{x}}_i)$ of a sample \(\tilde{\mathbf{x}}_i\):
\begin{equation}\label{equa-trajectory}
    \hat{F}(\tilde{\mathbf{x}}_i) =   \sum_t h_{\theta_{t+1}}(\tilde{\mathbf{x}}_i) - h_{\theta_t}(\tilde{\mathbf{x}}_i)
\end{equation}
where \(h_{\theta_t} \) denote the model that performs representation transformation on a sample \( \tilde{\mathbf{x}}_i \), with \( \theta_t \) representing its parameters at the \( t \)-th epoch.  

In our preliminary experiments, we first calculate the metric under \textit{supervised conditions} and observe a significant difference between the feature trajectories of ID samples and those of OOD samples. Specifically, we perform multi-category training on known ID nodes on two datasets with true $N$-category labels, Squirrel and WikiCS \footnote{$N$ is the number of categories, and the experimental results above with different target vectors are shown in Table \ref{tabel-diff-label}.}.
Imagine that during multi-category training, representations of known ID nodes within the same category align while unknown ID nodes drift toward the corresponding category centers. However, the trajectory trends and lengths of unknown ID nodes differ significantly from those of OOD nodes, with the former showing more distinct trends and longer trajectories; see Figure \ref{F-sample} for visual illustration. 
In other words, the well-defined in-distribution (ID) manifold is always shaped by ID samples, whose representation trajectories tend to exhibit similar behavior, which we refer to as feature resonance. Conversely, OOD samples belong to distinct manifold structures, making their representations less likely to converge coherently. Evidently, this feature resonance phenomenon can be leveraged for OOD detection.

Despite the promise, the abovementioned feature resonance phenomenon occurs under multi-category training. \textit{But how can we induce this phenomenon in a category-free scenario without multi-category labels?} 
Interestingly, we find that even when \textbf{random labels} are assigned to known ID nodes for multi-category training, the trajectories of unknown ID nodes are still more significant than those of unknown OOD nodes. More surprisingly, 
on a ideal toy dataset, 
even when all known ID node representations are aligned toward \textbf{one single random fixed target vector}, the trajectories of unknown ID nodes are still longer than those of unknown OOD nodes, as shown in Figure \ref{F-Trajectory}. 
% We use a toy dataset to observe this phenomenon (Figure \ref{F-Trajectory}). 
Green points represent unknown ID samples, blue points represent unknown OOD samples, and red points represent known ID samples aligned to a target vector. As shown in Figure \ref{F-Trajectory}(b), modifying the representation of known ID samples results in longer representation change trajectories for unknown ID samples compared to unknown OOD samples.
The experiments above indicate that the feature resonance phenomenon is \textit{label-independent} and results from the intrinsic relationships between ID node representations. Therefore, this is highly suitable for category-free OOD detection scenarios without multi-category labels.
 

% \begin{figure}[!t]
% 	\centering
%   % \subfigure[Amazon]{
% 	% \begin{minipage}[b]{0.47\linewidth}
% 		\includegraphics[width=0.7\linewidth]{Figures/FR-Amazon-1.pdf}
% 	% \end{minipage}
%  % }
%     \caption{The performance of using resonance-based score $\tau$ to detect OOD nodes varies with training progress. The higher the AUROC, the better, and the lower the FPR95, the better.}
%     \label{F-alpha-t}
% \end{figure}
Since the trajectory represents a global change, we call it a macroscopic feature resonance, as follows:
\begin{definition}
    \textbf{Feature Resonance (macroscopic)}: For any optimization objective $ \ell(\boldsymbol{ X}_{\text{known}},\cdot)$ applied to the representations $\boldsymbol{X}_{\text{known}}$ of known ID samples derived from any model $h_{\theta}(\cdot)$, we have $\parallel \hat{F}(\tilde{\mathbf{x}}_i) \parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \hat{F}(\tilde{\mathbf{x}}_i) \parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}$.
    %, where $\parallel \hat{F}(\tilde{\mathbf{x}}_i) \parallel$ is the trajectory of representation changes for sample $\tilde{\mathbf{x}}_i$.
\end{definition}

\subsection{Utilizing the Micro-level  Feature Resonance Phenomenon with An Arbitrary Target}\label{subsec-utilizing-FR}

As mentioned above, we can leverage 
the feature resonance phenomenon to detect OOD nodes. In our realistic implementations, we align the features of known ID nodes to an arbitrary target vector using mean squared error as follows:
\begin{equation}
    \ell(h_{\theta_t}({\boldsymbol X}_{\text{known}}),e) = \mathbb{E}(\parallel \mathbf{1}^{\top}e - ({\boldsymbol X}_{\text{known}}\mathbf{W}^{\top})\parallel^2_2 )
\end{equation}
where $h_{\theta_t}({\boldsymbol X}_{\text{known}}) = {\boldsymbol X}_{\text{known}}\mathbf{W}^{\top}$ represent the last linear layer of the model for representation transformation and $e$ denotes an arbitrary randomly generated target vector.

But, in contrast to our toy dataset, the real-world datasets typically exhibit much more complex feature attributes.
As a result, the feature resonance of trajectory at the macro level is not as ideal or pronounced as observed in experiments on the toy dataset. Therefore, to explore the reasons behind this issue, we delve deeper into the changes in finer-grained node representations across epochs to study the feature resonance phenomenon. Specifically, we study the differences in $\Delta h_{\theta_t}(\tilde{\mathbf{x}}_i) = h_{\theta_{t+1}}(\tilde{\mathbf{x}}_i) - h_{\theta_t}(\tilde{\mathbf{x}}_i)$ between ID samples and OOD samples. Obviously, the existence of $\parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}$ is a necessary condition for satisfying $\parallel \hat{F}(\tilde{\mathbf{x}}_i) \parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \hat{F}(\tilde{\mathbf{x}}_i) \parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}$, so we define $\parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}$ as a feature resonance at the microscopic level:
\begin{definition}
    \textbf{Feature Resonance (microscopic)}: For any optimization objective $ \ell(\boldsymbol{ X}_{\text{known}},\cdot)$ applied to the known ID nodes' representations $\boldsymbol{X}_{\text{known}}$ from any model $h_{\theta_t}(\cdot)$, during the optimization process, there exists $t$ such that  $\parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}$. We define the resonance-based filtering score as $\tau_i = \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i) \parallel_2$. The resonance-based scores $\tau$ of OOD nodes should be smaller than those of ID nodes at $t$.
\end{definition}
By observing $\tau$ for ID samples and OOD samples, we find that feature resonance does not persist throughout the entire training process but rather occurs at specific stages of training. In our experiments on the common benchmarks, we find that during the early stages of training, the model is searching for the optimal optimization path, leading to chaotic representation changes and thus making feature resonance insignificant.  However, in the middle stages of training, once the model identifies an optimization path that aligns with the patterns of the ID samples, it optimizes along the path most relevant to the features of the ID samples, and feature resonance becomes most prominent. As the model continues to optimize and enters the overfitting stage, the feature resonance phenomenon begins to dissipate. 
Figure \ref{F-alpha-t} shows the experimental results on the Amazon dataset, and others are provided in Figure \ref{F-apdix-alpha-t} of the Appendix.  
Through the above experiments and analyses, we find that using $\hat{F}(\tilde{\mathbf{x}}_i)$ to identify OOD nodes is affected by error accumulation and is, therefore, not a reliable approach. However, there exists a specific period during training when micro-level feature resonance occurs. By utilizing a validation set \citep{katz2022training, gong2024energy, du2024does, du2024haloscope}, we can easily identify the period during which feature resonance occurs. 

Formally, our new feature resonance-based OOD nodes detector is defined as follows:
\begin{equation}
    \begin{split}
        &g_{\gamma}(\tilde{\mathbf{x}}_i)= \mathds{1}\{\tau_i^* \leq \gamma\}, \\
        % &\text{s.t.}, \tau^*=\max_t \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{in}}} > \parallel \Delta h_{\theta_t}(\tilde{\mathbf{x}}_i)\parallel_{\mathbb{P}^{\mathrm{wild}}_{\mathrm{out}}}
        &\text{s.t.}, \tau^*=\max_t \text{AUROC}(\tau^t_{\mathcal{V}_{\mathrm{val}}^{\mathrm{in}}}, \tau^t_{\mathcal{V}_{\mathrm{val}}^{\mathrm{out}}})
    \end{split}
\end{equation}
where $g_{\gamma}=1$ indicates the OOD nodes while $g_{\gamma}=0$ indicates otherwise, and $\gamma$ is typically chosen to guarantee a high percentage, such as 95\%, of ID data that is correctly classified.
Here, $t$ is determined by the validation set $\mathcal{V}_{\text{val}}$. 



\begin{figure}[!t]
	\centering
  % \subfigure[Amazon]{
	% \begin{minipage}[b]{0.47\linewidth}
		\includegraphics[width=0.7\linewidth]{Figures/FR-Amazon-1.pdf}
	% \end{minipage}
 % }
    \caption{The performance of using resonance-based score $\tau$ to detect OOD nodes varies with training progress. The higher the AUROC, the better, and the lower the FPR95, the better.}
    \label{F-alpha-t}
\end{figure}

To summarize our method: we calculate a resonance-based filtering score $\tau$ during the transformation of known ID sample representations. By leveraging a validation set, we identify the period during training when micro-level resonance is most significant. Within this period, test set nodes with smaller $\tau$ values are more likely to be OOD nodes.

% It is essential to note that our approach differs significantly from previous gradient-based methods:  \textit{1) Originating from the Commonality of Representations.} Our method is based on the conjecture that there are inherent commonalities between the representations of the ID sample.
% \textit{2) No Pre-Trained Multi-Category Classifier Needed.}  
% Gradient-based methods like GradNorm \citep{huang2021importance} and SAL \citep{du2024does} rely on a pre-trained multi-category classifier to compute gradients. 
% % SAL uses pseudo-labels and gradient projections for OOD identification which is unsuitable for category-free scenarios. In contrast, our RSL method eliminates the need for a pre-trained classifier.
% \textit{3) No Gradient Computation for Unknown Samples.}  
% Our method doesn't require gradients of unknown samples to compute the resonance-based score $\tau$.

% \paragraph{Comparison with Gradient-based Methods. } 
% \textit{It is noteworthy that our approach differs significantly from previous gradient-based methods \cite{}, which rely on the gradient of the ID classifier to ground-truth category-free. 
% In contrast, our feature resonance measure capitalizes on the inherent commonalities in the representations of ID samples, fully eliminating the reliance on a supervised multi-category classifier.

% % classifier outputs of unknown samples for OOD detection, making them unsuitable for category-free scenarios. 



% Specifically, our method capitalizes on the inherent commonalities in the representations of ID samples, eliminating the reliance on a pre-trained multi-category classifier, which is a key limitation of traditional gradient-based methods like GradNorm \citep{huang2021importance} and SAL \citep{du2024does}. These methods require classifier outputs of unknown samples for OOD detection, making them unsuitable for category-free scenarios. Additionally, our method doesn't need any gradient computations for unknown samples like the methods above, which significantly enhances flexibility, allowing OOD detection to occur during the optimization of ID representations without waiting for the optimization to be completed. This makes our approach efficient and well-suited to challenging scenarios without predefined categories.}


\subsection{Extension with Synthetic OOD Node Strategy}\label{subsec_Train-OOD-classifer}
Although the resonance-based filtering score effectively separates OOD nodes, recent studies  \citep{gong2024energy} suggest that training an OOD classifier with synthetic OOD nodes can improve OOD node detection. Therefore, we propose a novel framework that employs feature resonance scores to generate more realistic synthetic OOD nodes. 

Specifically, we define the candidate OOD node set as \( \mathcal{V}_{\mathrm{cand}} = \{ \tilde{v}_i \in \mathcal{V}_{\mathrm{wild}} : \tau_i \leq T \} \), where \( T = \mathrm{min}_\mathrm{n}(\tau) \) is the \( n \)-th smallest \( \tau \) of wild nodes, selecting nodes with the smallest \( n \) \( \tau \) values. The features of these nodes form \( \boldsymbol{X}_{\mathrm{cand}} \).
Then, we compute a trainable metric based on the weighted mapping of node \( v \)'s representations across $K$ GNN layers:
$
    E_{\theta}(v) = \mathbf{W}_{K}\big( \sum_{k}^{K}\beta_{k}\mathbf{h}_v^{(k)} \big)
$,
where $\beta_{k} \in \mathbb{R}$ is a learnable parameter, and $\mathbf{W}_{K} \in \mathbb{R}^{1 \times d}$ transforms the node representations to the energy scalar. Then, we employ stochastic gradient Langevin dynamics (SGLD)  \citep{welling2011bayesian} to generate synthetic OOD nodes $\mathcal{V}_{\mathrm{syn}} = \{ \hat{v}_1, \cdots, \hat{v}_j \}$ with random initial features $\boldsymbol{X}_{\mathrm{syn}} = \{ \hat{\mathbf{x}}_1, \cdots, \hat{\mathbf{x}}_j \}$ as follows:
\begin{equation}
\begin{split}
    \hat{\mathbf{x}}_j^{(t+1)} = & \lambda \big (\hat{\mathbf{x}}_j^{(t)} - \frac{\alpha}{2}\nabla_{\hat{\mathbf{x}}_j^{(t)}}E_{\theta}\big( \hat{v}_j^{(t)} \big) + \epsilon \big)  \\
    &+ (1-\lambda)\mathbb{E}_{\mathbf{x}\sim \boldsymbol{X}_\mathrm{cand}}(\mathbf{x} - \hat{\mathbf{x}}_j^{(t)}) 
\end{split}
\end{equation}
where $\frac{\alpha}{2}$ is the step size and $\lambda$ is a trade-off hyperparameter. $\epsilon$ is the Gaussian noise sampled from multivariate Gaussian distribution $\mathcal{N}(0, \zeta)$.
Unlike Energy\textit{Def} \citep{gong2024energy}, we utilize the candidate OOD nodes $\mathcal{V}_{\mathrm{cand}}$ as examples to generate synthetic OOD nodes that better align with the actual OOD nodes. 
After obtaining the synthetic OOD nodes, we define the training set $\mathcal{V}_{\mathrm{train}} = \mathcal{V}_{\text{known}} \  \cup \  \mathcal{V}_{\mathrm{cand}} \  \cup  \  \mathcal{V}_{\mathrm{syn}}$ with features $\boldsymbol{X}_{\mathrm{train}}$ and labels $\boldsymbol{Y}_{\mathrm{train}}$. The initially known ID nodes $\mathcal{V}_{\mathrm{known}}$ are assigned a label of $1$. In contrast, the candidate OOD nodes $\mathcal{V}_{\mathrm{cand}}$ and the generated synthetic OOD nodes $\mathcal{V}_{\mathrm{syn}}$ are assigned a label of $0$. We use binary cross-entropy loss for training: 
\begin{equation}
% \begin{split}
    \ell_{\text{cls}} = - \big ( {\mathrm{y}}_{v}\mathrm{log}(\sigma(E_{\theta}(v)))
    + {(1-\mathrm{y}}_{v})\mathrm{log}(1-\sigma(E_{\theta}(v))) \big )
% \end{split}
\end{equation}
where $\sigma(\cdot)$ is the sigmod function. Similarly, we identify the OOD nodes as follows: $ g^{\prime}_{\gamma^{\prime}}(E_{\theta}(v))= \mathds{1}\{E_{\theta}(v) \leq \gamma^{\prime}\}$.
, where $g^{\prime}_{\gamma^{\prime}}=1$ indicates the OOD nodes while $g^{\prime}_{\gamma^{\prime}}=0$ indicates otherwise, and $\gamma^{\prime}$ is chosen to guarantee a high percentage, e.g., 95\%,  of ID data that is correctly classified.



\input{Sections/Theoretical_Analysis}





% \begin{table}[!t]
% \centering
% \caption{Time cost (s).}\label{tabel-time}
% \scriptsize % Reduce font size
% \setlength{\tabcolsep}{1.5mm} % Adjust column spacing
% \begin{tabular}{c|c|c|c|c|c}
% \hline
% \hline
% \textbf{Dataset} &\textbf{Squirrel} & \textbf{WikiCS} & \textbf{YelpChi} & \textbf{Amazon} & \textbf{Reddit}\\ 
% \hline
% Energy\textit{Def} &10.94 &27.11 &76.51 &33.81 &26.44 \\
% RSL w/o classifier &5.25 &4.03 &5.41 &5.75 &3.71\\
% RSL &11.54 &17.53 &74.83 &36.33 &38.23 \\
% \hline
% \hline
% \end{tabular}
% \end{table}










% \subsection{Training the OOD Classifier}\label{subsec_Train-OOD-classifer}
% Although resonance-based filtering performs well in separating OOD nodes, recent studies \citep{gong2024energy} show that training an OOD classifier with synthetic OOD nodes can enhance detection. We propose a novel framework to generate synthetic OOD nodes for this purpose. Specifically, we compute a trainable metric based on the weighted mapping of node \( v \)'s representations across GNN layers:
% \begin{equation}
%     E_{\theta}(v) = \mathbf{W}_{K}\big( \sum_{k}^{K}\beta_{k}\mathbf{h}_v^{(k)} \big)
% \end{equation}
% where $\beta_{k} \in \mathbb{R}$ is a learnable parameter, and $\mathbf{W}_{K} \in \mathbb{R}^{1 \times d}$ transforms the node representations to the energy scalar. Then, we employ stochastic gradient Langevin dynamics (SGLD) to generate synthetic OOD nodes $\mathcal{V}_{\mathrm{syn}} = \{ \hat{v}_1, \cdots, \hat{v}_j \}$ with random initial features $\boldsymbol{X}_{\mathrm{syn}} = \{ \hat{\mathbf{x}}_1, \cdots, \hat{\mathbf{x}}_j \}$ as follows:
% \begin{equation}
% \begin{split}
%     \hat{\mathbf{x}}_j^{(t+1)} = & \lambda \big (\hat{\mathbf{x}}_j^{(t)} - \frac{\alpha}{2}\nabla_{\hat{\mathbf{x}}_j^{(t)}}E_{\theta}\big( \hat{v}_j^{(t)} \big) + \epsilon \big)  \\
%     &+ (1-\lambda)\mathbb{E}_{\mathbf{x}\sim \boldsymbol{X}_\mathrm{cand}}(\mathbf{x} - \hat{\mathbf{x}}_j^{(t)}) 
% \end{split}
% \end{equation}
% where $\frac{\alpha}{2}$ is the step size and $\lambda$ is a trade-off hyperparameter. $\epsilon$ is the Gaussian noise sampled from multivariate Gaussian distribution $\mathcal{N}(0, \zeta)$.
% Unlike Energy\textit{Def} \citep{gong2024energy}, we utilize the candidate OOD nodes $\mathcal{V}_{\mathrm{cand}}$ as examples to generate synthetic OOD nodes that better align with the actual OOD distribution. 
% After obtaining the synthetic OOD nodes, we define the training set $\mathcal{V}_{\mathrm{train}} = \mathcal{V}_{\text{known}} \  \cup \  \mathcal{V}_{\mathrm{cand}} \  \cup  \  \mathcal{V}_{\mathrm{syn}}$ with features $\boldsymbol{X}_{\mathrm{train}}$ and labels $\boldsymbol{Y}_{\mathrm{train}}$. The initially labeled ID nodes are assigned a label of $1$. In contrast, the candidate OOD nodes $\mathcal{V}_{\mathrm{cand}}$ and the generated synthetic OOD nodes $\mathcal{V}_{\mathrm{syn}}$ are assigned a label of $0$. We use binary cross-entropy loss for training, as follows: 
% \begin{equation}
% \begin{split}
%     \ell_{\text{cls}} = & \mathbb{E}_{v\sim \mathcal{V}_{\mathrm{train}}}\big( {\mathrm{y}}_{v}\mathrm{log}(\sigma(E_{\theta}(v)))\\ 
%     &+ {(1-\mathrm{y}}_{v})\mathrm{log}(1-\sigma(E_{\theta}(v))) \big)
% \end{split}
% \end{equation}
% where $\sigma(\cdot)$ is the sigmod function:
% \begin{equation}
%     \sigma(E_{\theta}(v)) = 1 / (1 + \mathrm{e}^{-E_{\theta}(v)})
% \end{equation}
