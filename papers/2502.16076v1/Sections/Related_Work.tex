\section{Related Works}\label{sec-related_work}
% This section provides an overview of prior research closely related to our work, including Graph Neural Networks (GNNs) and Out-of-Distribution (OOD) detection.

% Our work builds on and contributes to three key areas: Graph Neural Networks (GNNs), Out-of-Distribution (OOD) detection methods, and recent advancements in category-free OOD detection in graphs.

% \subsection{Graph Neural Networks}\label{subsec-gnn}
% Graph Neural Networks (GNNs) have achieved notable success in applications such as drug discovery\citep{you2018graph}, traffic prediction\citep{yu2017spatio}, and social influence estimation\citep{qiu2018deepinf}, by effectively leveraging graph-structured data. GNNs rely on two main inputs: node attributes, describing individual node properties, and graph topology, capturing relationships between nodes. However, models like Graph Convolutional Networks (GCNs)\citep{kipf2016semi} often suffer from the over-smoothing problem\citep{chen2020measuring} as layers deepen, causing node representations to become overly similar and reducing discriminative power. This issue is particularly problematic for OOD node detection, where OOD nodes exhibit distinct characteristics from ID nodes. Addressing over-smoothing is crucial to preserving the unique features of OOD nodes for accurate detection.


% \subsection{Out-of-Distribution Detection}\label{subsec-ood}

% \paragraph{General OOD Detection Methods.}  
% OOD detection methods aim to identify out-of-distribution samples and can be mainly categorized into three types: \textit{Entropy-based}, \textit{Density-based}, and \textit{Energy-based} methods. Entropy-based methods \citep{hendrycks2016baseline,liang2017enhancing, bendale2016towards} compute OOD scores based on predicted class distributions but often require multi-category labels or extra loss functions \citep{bevandic2018discriminative,hendrycks2018deep,geifman2019selectivenet,malinin2018predictive,jeong2020ood,chen2021atom,wei2021open,wei2022mitigating,ming2022cider,ming2022poem}. Density-based methods, like Mahalanobis distance \citep{lee2018simple} and residual flow models \citep{zisselman2020deep}, estimate sample probabilities but struggle with complexity and statistical mismatches \citep{ren2019likelihood,serra2019input}. Energy-based methods \citep{liu2020energy, zhai2016deep, du2019implicit} model unnormalized probabilities with energy functions, but applying them to graph data remains challenging due to intricate node dependencies. 
% Recent studies \citep{li2022graphde,bazhenov2022towards,liu2023good,ding2023sgood} have explored graph OOD detection from various perspectives, but they are not suitable to be directly used for node-level OOD detection.

% \paragraph{Graph-level OOD Detection}
% Recent studies have explored graph OOD detection from various perspectives. \citet{li2022graphde} model graph generation with a variational distribution to infer the environment. \citet{bazhenov2022towards} highlight the importance of both graph representations and predictive distributions for uncertainty-based detection. GOOD-D \citep{liu2023good} introduces a contrastive learning framework independent of ground truth labels. \citet{guo2023data} propose a data-centric adaptive amplifier, while \citet{ding2023sgood} leverage substructures for learning robust representations.


% \paragraph{Category-free OOD Detection in Graphs.}  
% Category-free OOD detection in graphs addresses scenarios without multi-category labels, posing unique challenges for traditional methods. Entropy-based methods like OODGAT \citep{song2022learning} and GNNSafe \citep{wu2023energy} rely on classifier activation spaces and are unsuitable for category-free settings. Graph anomaly detection methods, such as DOMINANT \citep{ding2019deep} and SL-GAD \citep{zheng2021generative}, detect anomalies using reconstruction errors but struggle to detect OOD nodes from general anomalies. EnergyDef \citep{gong2024energy} generates synthetic OOD nodes using SGLD for classifier training, but these nodes often fail to capture the actual features of actual OOD nodes.


% \paragraph{General OOD Detection Methods.}
% OOD detection methods aim to identify samples outside the training data distribution and can be broadly classified into three categories: \textit{Entropy-based methods}, \textit{Density-based methods}, and \textit{Energy-based methods}. Entropy-based methods, such as those proposed by \citep{hendrycks2016baseline} and improved by \citep{liang2017enhancing}, rely on predicted class distributions to compute OOD scores but often require multi-category labels or additional loss functions\citep{hendrycks2018deep,huang2021importance}. Density-based methods estimate sample probabilities, as seen in Mahalanobis distance approaches\citep{lee2018simple} and residual flow models\citep{zisselman2020deep}, but face challenges with input complexity and statistical mismatches\citep{ren2019likelihood,serra2019input}. Energy-based methods model unnormalized probabilities using energy functions, with studies such as those by \citep{zhai2016deep} and \citep{du2019implicit} showing promise in capturing complex distributions. However, applying these methods to graph-structured data remains challenging due to the intricate dependencies between nodes, necessitating further innovations.

% \paragraph{Category-free OOD Detection in Graphs.}
% Category-free OOD detection in graphs addresses scenarios where multi-category labels are unavailable, posing unique challenges for traditional methods. Entropy-based approaches, such as OODGAT\citep{song2022learning} and GNNSafe\citep{wu2023energy}, rely on classifier activation spaces and are unsuitable for category-free settings. Graph anomaly detection methods, such as DOMINANT\citep{ding2019deep} and SL-GAD\citep{zheng2021generative}, use reconstruction errors to detect anomalies but lack the specificity to differentiate OOD nodes from general anomalies. To address these gaps, EnergyDef\citep{gong2024energy} employs Langevin dynamics to generate synthetic OOD nodes for training classifiers. However, these synthetic nodes often fail to capture the true features of actual OOD nodes, resulting in suboptimal performance.




\paragraph{General OOD Detection Methods.}  
OOD detection methods are generally categorized into \textbf{entropy-based}, \textbf{density-based}, and \textbf{representation-based} approaches. \textbf{Entropy-based methods} such as Maximum Softmax Probability (MSP) \citep{hendrycks2016baseline}, Energy \citep{liu2020energy}, and other methods \citep{liang2017enhancing, bendale2016towards, hendrycks2018deep, geifman2019selectivenet, malinin2018predictive, jeong2020ood, chen2021atom, wei2021open, ming2022cider, ming2022poem} compute OOD scores from class distributions. Still, they rely heavily on multi-category labels, which limits their use in category-free settings. \textbf{Density-based methods}, such as Mahalanobis distance \citep{lee2018simple} and residual flow models \citep{zisselman2020deep}, estimate sample probabilities based on their distribution but struggle with handling high-dimensional data and complex relationships \citep{ren2019likelihood, serra2019input}. \textbf{Representation-based methods}, including KNN \citep{sun2022out} and NNGuide \citep{park2023nearest}, focus on differentiating OOD and ID nodes by analyzing learned embeddings in feature space. However, they still need a pre-trained multi-category ID classifier. In contrast, SSD \citep{sehwag2021ssd} is an outlier detector that leverages self-supervised representation learning and Mahalanobis distance-based detection on unlabeled ID data. 
% \textbf{Energy-based methods}, like Energy \citep{liu2020energy}, model unnormalized probabilities but face challenges when applied to graph data due to the complexity of node dependencies \citep{zhai2016deep, du2019implicit}.

\paragraph{Category-free OOD Detection in Graphs.}  
Category-free OOD detection in graphs aims to identify OOD nodes without relying on multi-category labels, posing unique challenges for traditional methods. \textbf{Entropy-based methods}, such as OODGAT \citep{song2022learning} and GNNSafe \citep{wu2023energy}, depend on classifier outputs and are not suitable for category-free settings. \textbf{Representation-based methods}, including Energy\textit{Def} \citep{gong2024energy}, aim to generate synthetic OOD nodes but often fail to capture the true features of real OOD nodes. \textbf{Graph anomaly detection methods}, like DOMINANT \citep{ding2019deep} and SL-GAD \citep{zheng2021generative}, detect general anomalies through reconstruction errors, but they struggle to distinguish between OOD nodes and general anomalies. Recent works such as \citep{li2022graphde, bazhenov2022towards, liu2023good, ding2023sgood} explore graph-level OOD detection but can not be directly applied to node-level OOD detection due to the complexity of node dependencies.