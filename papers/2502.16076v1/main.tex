%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

%Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% % If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
\theoremstyle{plain}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Added by Shenzhi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{multirow}
\usepackage{multicol}
\usepackage{mathrsfs}
\usepackage{diagbox} % 加载 diagbox 包
\usepackage{makecell}
\usepackage{hyperref}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{bbm}
\definecolor{darkred}{RGB}{162, 0, 0}
\newcommand{\darkred}[1]{\textbf{\textcolor{darkred}{#1}}}
\definecolor{darkblue}{RGB}{4, 6, 173}
\newcommand{\darkblue}[1]{\textbf{\textcolor{darkblue}{#1}}}
\usepackage{enumitem}
\usepackage{amsfonts}  % 引入 amsfonts 包
\usepackage{dsfont}
% \usepackage{tabularx} % 确保在导言区引入 tabularx 包



% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\twocolumn[
\icmltitle{Category-free Out-of-Distribution Node Detection with Feature Resonance}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Shenzhi Yang}{zju,Blockchain}
\icmlauthor{Junbo Zhao}{zju}
\icmlauthor{Shouqing Yang}{zju}
\icmlauthor{Yixuan Li}{wisc}
\icmlauthor{Dingyu Yang}{Blockchain}
\icmlauthor{Xiaofang Zhang}{suda}
\icmlauthor{Haobo Wang}{zju,Blockchain}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}
% \icmlaffiliation{zju}{College of Computer Science and Technology, Zhejiang University, Hangzhou, China}
\icmlaffiliation{zju}{Zhejiang University, Hangzhou, China}
\icmlaffiliation{Blockchain}{Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, Hangzhou, China}
\icmlaffiliation{wisc}{Department of Computer Sciences, University of Wisconsin-Madison}
\icmlaffiliation{suda}{School of Computer Science and Technology, Soochow University, Suzhou, China}



% \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}
\icmlcorrespondingauthor{Haobo Wang}{ wanghaobo@zju.edu.cn}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% Detecting Out-of-Distribution (OOD) nodes in graph-based machine learning models is a critical challenge, as OOD nodes can degrade model performance. While most existing methods assume multi-category labels for in-distribution (ID) nodes, such labels are often unavailable. Recent work, Energy\textit{Def}, generates auxiliary hallucinated OOD nodes using Langevin dynamics to perform category-free OOD node detection. Still, these nodes do not accurately represent real OOD nodes. To address this, we propose \textbf{TSL} (\textbf{T}rajectory-based \textbf{S}eparate And \textbf{L}earn), which identifies candidate OOD nodes by comparing representation changes between ID and OOD nodes. These candidates are then used to generate more realistic hallucinated OOD nodes for training an OOD classifier. We provide theoretical error bounds showing that TSL can separate outliers with low error rates and demonstrate its state-of-the-art performance in experiments.
% Detecting Out-of-Distribution (OOD) nodes in graph-based machine learning models is a crucial challenge, especially when node multi-category labels are unavailable. While recent methods like EnergyDef use Langevin dynamics to generate hallucinated OOD nodes for training classifiers, they fail to reflect the characteristics of actual OOD nodes accurately. In this work, we propose \textbf{RSL} (\textbf{R}esonance-based \textbf{S}eparate and \textbf{L}earn), a novel framework that leverages the phenomenon of \textbf{Feature Resonance}—the impact of labeled ID samples on the representations of unlabeled ID nodes. We observe that this resonance enables the identification of reliable wild OOD nodes, which can be used to generate more accurate hallucinated OOD nodes. From a theoretical perspective, we provide a rigorous error bound, showing that RSL can effectively isolate outliers with low error rates. Empirically, RSL achieves state-of-the-art performance in category-free OOD node detection, demonstrating its robustness and efficacy.
% Detecting out-of-distribution (OOD) nodes in the graph-based machine-learning field is challenging, particularly when in-distribution (ID) node multi-category labels are unavailable. 
% In this work, we introduce \textbf{RSL} (\textbf{R}esonance-based \textbf{S}eparate and \textbf{L}earn), a novel framework that exploits the phenomenon of \textbf{Feature Resonance}—where representations of unlabeled ID nodes change more significantly during optimization on labeled ID nodes than OOD nodes. By leveraging this phenomenon, RSL can identify reliable wild OOD nodes and use them to generate synthetic OOD samples that more closely match the true OOD distribution
%  with Langevin dynamics to train a robust OOD classifier. Theoretically, RSL demonstrates strong separability with low error rates, and empirically, it achieves state-of-the-art results, outperforming existing methods in category-free OOD node detection, e.g., on the FPR95 metric (the lower, the better), it achieves an average reduction of 18.51\% over the current sota method on five publicly available datasets.
Detecting out-of-distribution (OOD) nodes in the graph-based machine-learning field is challenging, particularly when in-distribution (ID) node multi-category labels are unavailable. Thus, we focus on feature space rather than label space and find that, ideally, during the optimization of known ID samples, unknown ID samples undergo more significant representation changes than OOD samples, even if the model is trained to fit random targets, which we called the \textbf{Feature Resonance} phenomenon.
The rationale behind it is that even without gold labels, the local manifold may still exhibit smooth resonance. 
Based on this, we further develop a novel graph OOD framework, dubbed \textbf{R}esonance-based \textbf{S}eparation and \textbf{L}earning (\textbf{RSL}), which comprises two core modules: 
(i)-a more practical micro-level proxy of feature resonance that measures the movement of feature vectors in one training step.
(ii)-integrate with synthetic OOD nodes strategy to train an effective OOD classifier.
Theoretically, we derive an error bound showing the superior separability of OOD nodes during the resonance period.
Empirically, RSL achieves state-of-the-art performance, reducing the FPR95 metric by an average of \textbf{18.51}\% across five real-world datasets. 

% This phenomenon motivates our proposed framework, \textbf{R}esonance-based \textbf{S}eparation and \textbf{L}earning (\textbf{RSL}), which leverages a micro-level proxy for feature resonance by measuring the movement of representation vectors in one step during training. This label-independent proxy uses a randomly fixed target, making it suitable for category-free scenarios. Theoretically, we derive an error bound showing the separability of OOD nodes during the resonance period. Empirically, RSL achieves state-of-the-art performance, reducing the FPR95 metric (the lower, the better) by an average of 18.51\% across five real-world datasets. 
\end{abstract}



\input{Sections/Introduction}

\input{Sections/Preliminaries}
% \input{Sections/Problem Setup}


\input{Sections/Method}


\input{Sections/Experiment}

\input{Sections/Related_Work}

\input{Sections/Conclusion}



\section*{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{Sections/Appendix}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
