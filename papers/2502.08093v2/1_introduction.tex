\section{Introduction}
\label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Robot navigation using radars has experienced remarkable advancements for their resilient perception capabilities in challenging weather conditions \cite{harlow2023new, abu2024radar, starr2014evaluation, bijelic2018benchmark, kramer2021radar}.
% Long electromagnetic wavelengths enable the radar to penetrate dust particles and detect objects over extended distances, even in low-visibility scenarios \cite{adams2012book, 9969174}.
Moreover, its capability of providing Doppler velocity distinguishes the radar sensor from the traditional sensors, leading to significant enhancements in visually degraded environments \cite{nissov2024degradation}.
% Despite these advancements, accurate motion estimation in radar navigation still presents significant challenges.

% vertical limitation

Despite the above advantages, radar measurements are vulnerable to false alarms and multipath reflections, thus necessitating outlier rejection.
Among many existing methods, intensity-based filtering \cite{adolfsson2023lidar} and \ac{CFAR} are the most widely utilized. However, these approaches are threshold-sensitive and can be limited in terms of generalizability.
In this context, leveraging ground could be a feasible solution as it demonstrated its reliable noise filtering ability in \ac{LiDAR} \cite{shan2018lego, pan2021mulls, zheng2021efficient, chen2021low, wei2022gclo, galeote2023gnd}. Unfortunately, naive plane fitting as in \ac{LiDAR} would fail because of the inherent uncertainty and imprecise distribution in radar \cite{li20234d, chen2023drio}.
% , which highlights the necessity for radar-specific ground modeling.
% Regarding these issues, leveraging ground plane has actively exploited as a consistent feature in \ac{LiDAR} \cite{shan2018lego, pan2021mulls, zheng2021efficient, chen2021low, wei2022gclo, galeote2023gnd}.
% Unlike \ac{LiDAR}, ranges from radar involve noises and spatial uncertainties and represent imprecise distributions of ground points, which poses significant challenge \cite{chen2023drio}.
% Moreover, single-plane model \cite{li20234d} relies on ground classification through height thresholding, which struggles with the complexities of slopes and hilly terrains.
% These necessitate radar-tailored ground segmentation.
% Our piece-wise ground extraction incorporating point-wise spatial uncertainties can resolve the aforementioned issues.

While mitigating inherent noise in radar, estimating 6-\ac{DOF} motion from the 3-\ac{DOF} linear velocity presents additional challenges.
Over the past decades, ego-motion estimation using Doppler velocity has been explored \cite{kellner2013instantaneous, kramer2020radar, haggag2022credible}, and has been extensively advanced to odometry by integrating \ac{IMU} \cite{DoerENC2020, park20213d, michalczyk2022tightly, zhuang20234d, do2024dero}.
In doing so, unfortunately, existing methods overlooked the temporal discrepancies from two sensors, radar and \ac{IMU}, and the temporal discrepancy in sensor data streams prohibits the tight integration of two sensors for accurate preintegration.
% A similar issue has been reported from multi-\ac{LiDAR} odometry, where the synchronization problem was solved by using splines.
%\textcolor{blue}{
%In multi-sensor fusion, mitigating temporal discrepancies is a significant challenge \cite{jung2023asynchronous}, however, existing approaches disregarded these discrepancies or simplified the asynchronous problem using discretized propagation models with constant state assumptions.
%Although continuous approaches have been investigated to tackle these discrepancies, they are limited to multi-radar setups \cite{ng2021continuous}
%}.
% Their work has commonly adopted discretized propagation models to mitigate the temporal discrepancies, assuming constant proprioceptive states.
% However, these assumptions exacerbate errors from inaccurate elevation measurements of radar.

% Motivated by this, we propose a continuous preintegration model of \ac{IMU} and radar velocity with \ac{GP}.

% Various approaches have been explored to mitigate the issues, such as with additional kinematic model \cite{retan2021radar, galeoteluque2023doppleronlysinglescan3dvehicle} struggle with discrepancies between assumed and actual motion.
% Utilizing doppler velocity has been extensively researched over the past decades, yet it remains inherently constrained to linear motion \cite{kellner2013instantaneous, kellner2014instantaneous}.
% Integrating kinematic model assumption for additional constraints solely on radar \cite{retan2021radar, galeoteluque2023doppleronlysinglescan3dvehicle} struggles with discrepancies between the assumption and actual motion.
% Fusion with \ac{IMU} \cite{DoerENC2020, park20213d} relies on discretized linear propagation models that presume constant local proprioceptive measurements and linear motion within each time step thereby amplifying error due to measurement drifts and motion non-linearity in real-world movement \cite{ng2021continuous}.

%Furthermore, multi-sensor fusion introduces synchronization issues with temporal discrepancies.

%FIGURE
\begin{figure}[!t]
    \centering
    \includegraphics[trim=9cm 0.1cm 7.8cm 0cm, clip, width=0.99\columnwidth]{figure/fig1_final_compressed.pdf}
    \caption{
        \textbf{Top}: Our uncertainty-aware ground filtering efficiently eliminates the noise (red) from radar.
        \textbf{Middle}: Mapping result of \texttt{RURAL\_A2}. Our continuous velocity integration with the Gaussian Process (GP) proficiently handles the sharp turns and roundabouts.
        \textbf{Bottom}: The proposed method shows the lowest elevation error (18m over 2.5km of path length, only \textbf{0.72\%}).
    }
    \label{fig:overview}
    \vspace{-8mm}
\end{figure}
%FIGURE

% Recently, incorporating spatial information has proposed \cite{michalczyk2022tightly, 10160482, zhuang20234d, zhang20234dradarslam, do2024dero}.
% Conventional filtering methods that rely on distance or signal intensity \cite{kung2021normal, michalczyk2022tightly, 10160482, zhuang20234d} tend to be parameter-sensitive and lack generalizability. Filtering with RANSAC \cite{zhang20234dradarslam, do2024dero} introduces measurement drift for large objects \cite{CasadoHerraez2024radar}. Particularly, radar's low resolution along the elevation and inherent measurement uncertainties exacerbate these issues.
% These difficulties necessitate further advancements in filtering techniques in 4D radar that can effectively embed the complexities and uncertainties in radar measurement.

In this paper, we propose a tightly-coupled 4D radar-inertial odometry framework with ground filtering and continuous preintegration for radar-inertial fusion. Existing ground models utilized height thresholding, which struggled with the complexities of slopes and hills. Instead, we use a zone-based approach incorporating the spatial uncertainties from the radar point cloud into ground modeling.
Also, radar-inertial fusion is performed through continuous preintegration of velocities.
Inspired by \ac{IMU} preintegration using \ac{GP} \cite{le2021continuous}, we found that formulating the radar velocities into \ac{GP} allows seamless integration with \ac{IMU} and effectively addresses temporal discrepancies that are often overlooked in existing works.
% allowing for robust 6-\ac{DOF} motion estimation directly from the asynchronous measurements from radar and IMU.
\figref{fig:overview} and \figref{fig:pipeline} illustrates the improvements and the pipeline of our method.
The key contributions are as follows:

\begin{itemize}
    \item \textbf{Uncertainty-Aware Radar Ground Filtering: }
    Leveraging ground in radar should overcome the ambiguous distribution of the radar point cloud. By associating spatial uncertainties with zone-based ground modeling, we effectively segment out the ground even with its imprecise distributions and secure reliable noise filtering.

    % Identifying the ground points from the radar poses significant challenge due to distribution ambiguity. Our ground model captures the spatial uncertainty arises from radar, effective handling the inherent noises.
    
    \item \textbf{Novel Continuous Radar Velocity Preintegration: }
    Effectively mitigating the temporal discrepancies between radar and \ac{IMU} often disregarded in existing methods. We reformulate radar velocities and \ac{IMU} using \ac{GP} for the tightly-coupled preintegration, enabling robust motion estimation directly from the asynchronous measurements without any assumption.
    % integration problem / emphasize GP's proficient
    % novel continuous preintegration of radar velocities and imu using GP which enabling assumption-free motion estimation directly from the measurments
    
    \item \textbf{Evaluation on Diverse Environmental Conditions: }
    The proposed method is thoroughly validated on real-world public datasets including high dynamics and harsh weathers, demonstrating robust performance compared to existing 4D radar-inertial odometry algorithms. In particular, our approach achieves substantially enhanced odometry performance in the vertical direction.

    % various evaluation and achieve enhanced odometry in $z$-axis
\end{itemize}