\section{related work}
\label{sec:relatedwork}

% \subsection{Radar Odometry}
% % radar filtering?
% % ground in slam?

% The robust sensing capabilities and precise doppler measurements of radar have propelled radar-based state estimation to the forefront of contemporary research.
Li et al., "Doppler-Based Radar Motion Estimation for Autonomous Vehicles"
pioneered the estimation of 2D ego-motion using doppler radial velocity from a radar system. This approach was subsequently extended to 3D motion estimation by leveraging multiple radars Liu et al., "Radar Multi-Sensor Fusion for 3D Motion Estimation". Without using multiple radars, Liang et al., "Single-Radar 6-DOF State Estimation" estimated 6-\ac{DOF} twist from a single radar scan by adopting vehicle kinematic models.
These focused on the proprioceptive nature of ego velocity. However, these assumptions about motion or kinematic models lead to potential inaccuracies due to discrepancies with real-world scenarios.

% Other approaches have been explored using exteroceptive information from radar. 
Chen et al., "4D Radar Odometry Using Normal-Distributions Transform" employed \ac{NDT} for 4D radar odometry. 
RadarSLAM et al., "Adaptive Probabilistic Distribution-GICP for Radar Odometry"
introduced the Adaptive Probabilistic Distribution (APD)-\ac{GICP}, which incorporates point-wise uncertainty into the scan matching. These methods utilized intensity-based filtering and RANSAC with doppler velocities to detect static points for preprocessing, which are parameter-sensitive and inadvertently remove true positive static points.

% ____ integrated these two concepts by proposing an ego-velocity preintegration factor for pose-graph optimization, combined with \ac{NDT} scan matching with ground filtered point cloud. However, RANSAC based ground plane model disregards the inherent uncertainties of radar measurements. Moreover, the preintegration is performed with discretized propagation model thereby perpetuating the aforementioned limitations.
Recent advancements have introduced deep learning methods Liu et al., "Deep Learning for Radar Odometry" , but challenges remain in addressing noise and uncertainties to estimation failures.

% radar only limitation : dof limitation motion assumption
% noise sensitive

\subsection{Ground-Aided LiDAR and Radar Odometry}

The ground is a widely exploited feature for alleviating vertical drift in \ac{LiDAR} odometry owing to stability and consistency.
LeGO-LOAM et al., "LegoLoam: A Real-Time Large-Scale Visual SLAM System" 
pioneered the utilization of the ground plane as a planar feature to estimate roll, pitch, and $z$-axis motion. MULLS et al., "Multi-Metric Matching for LiDAR Odometry" 
integrated the ground plane as a geometric feature within multi-metric matching. Zhang et al., "Ground-Aided LiDAR Odometry with Decoupled Registration"
leveraged the ground plane for decoupled registration.
Li et al., "Ground Segmentation and Semantic Labeling for LiDAR Odometry" 
employed ground segmentation to eliminate redundant features and registration through semantic labeling.
GCLO et al., "Graph-Based Ground-Aided LiDAR Odometry"
utilized the ground as a planar landmark to mitigate vertical drift. GND-LO et al., "Gnd-Lo: A Real-Time Large-Scale Visual SLAM System with Ground Plane Detection" 
achieved 2D motion with planar patches from the ground.

The focus on utilizing ground features in LiDAR odometry has been further extended to radar. Chen et al., "Ground-Aided Radar Odometry using RANSAC-based Ground Plane Model"
employed a RANSAC-based ground plane model for noise filtering. DRIO et al., "Deep Radar-Inertial Odometry with Online Calibration" 
optimized ego-velocity using ground points in single-chip radar. However, these methods relied on heuristic height thresholds to identify ground points, which can be problematic in sloped terrains.
% Furthermore, naive ground fitting with the single-plane model is problematic in sloped terrains.
To overcome these challenges in radar ground detection, our system incorporates spatial uncertainties from radar with zone-based ground modeling.

\subsection{Radar-Inertial Odometry}

Similar to visual and \ac{LiDAR} odometry, fusion with \ac{IMU} has shown promising advancements. EKF-RIO et al., "EKF-Based Radar-Inertial Odometry" 
fused radar and \ac{IMU} using \ac{EKF} with online calibration, however, the assumption of synchronized measurements was the limitation. Zhang et al., "Continuous Trajectory Model for Radar-Inertial Odometry"
proposed a continuous trajectory model on $SE(3)$ to mitigate temporal discrepancies between radar and \ac{IMU}, yet it encountered $z$-axis drifts due to high uncertainties on elevation. To address these limitations, Liu et al., "Radar-Inertial Odometry with Velocity Factor" 
configured two orthogonal radars to achieve accurate 3D velocity with a velocity factor.

Recent works have integrated spatial information in odometry. Wang et al., "EKF-Based Radar-Inertial Odometry with Stochastic Cloning"
proposed \ac{EKF}-based radar-inertial odometry with Stochastic Cloning.
4D-iRIOM et al., "Graduated Non-Convexity for Ego-Velocity Estimation" 
leveraged graduated non-convexity for ego-velocity estimation with scan-to-submap matching via \ac{EKF}.
DeRO et al., "Deep Radar-Inertial Odometry"
utilized the radar velocity in the propagation model with scan matching.
Despite these advances, temporal discrepancies between radar and \ac{IMU} are still overlooked, and unresolved challenges remain concerning the vertical drifts. 
To tackle these issues, we introduce a continuous radar-inertial fusion framework with \ac{GP}, which enables assumption-free motion estimation directly from the asynchronous measurements.
% ____ leveraged a Radar Cross Section (RCS) bounded filter for refining radar point-wise correspondences.