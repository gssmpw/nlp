\section{Methodology}
\label{sec:method}

%FIGURE
\begin{figure}[!t]
    \centering
    % \includegraphics[trim=0cm 2.5cm 14.5cm 1.65cm, clip, width=1\columnwidth]{figure/pipeline_1.pdf}
    % \includegraphics[trim=0cm 4cm 16cm 1.65cm, clip, width=0.95\columnwidth]{figure/pipeline_2.pdf}
    \includegraphics[trim=3.7cm 4.5cm 7cm 0.2cm, clip, width=0.95\columnwidth]{figure/fig2_pipeline.pdf}
    \caption{
        The overall pipeline of our algorithm.
    }
    \label{fig:pipeline}
    \vspace{-7mm}
\end{figure}
%FIGURE

%In this section, we introduce the overall system of our proposed algorithm. The pipeline is shown in \figref{fig:pipeline}, and detailed descriptions are provided in the following subsections.

\subsection{Uncertainty-Aware Radar Ground Filtering}
\label{subsec: ground segmentation}
% ground plane detection and outlier removal

Radar points are prone to degradation due to noise from false alarms and multipath effects, necessitating noise filtering to ensure robustness.
We primarily employ radius filtering to eliminate clutter points, and the ground is utilized to mitigate the multipath.
To overcome the issues arising from slopes and hills in the existing naive ground fitting, zone-based ground detection is proposed.
Considering the conical shape of the radar point cloud, we adopt \ac{CZM} \cite{lee2022patchworkpp}, which is characterized by increasing width with distance as depicted in \figref{fig:ground}.

% This model features an increasing width with distance, ensuring equitable distribution of point densities across regions compared to standard uniform voxelization.

The traditional approach for estimating plane models exploited \ac{PCA}. Despite their prevalent usage, \ac{PCA} presents limitations regarding sensitivity to noise and uncertainties, which are crucial for radars.
To resolve this, we formulate the plane estimation as an optimization problem that minimizes the sum of Mahalanobis distances between the points and the plane.
The Mahalanobis distance from the point $p_i$ to plane is computed as $D_{M_i} = \sqrt{(\mathbf{n}^\top+d)^\top \Sigma_i^{-1} (\mathbf{n}^\top+d)}$, while $\Sigma_i$ is the associated point-wise covariance matrix, and $[\textbf{n},d]$ represents the detected plane model. Then the plane model can be estimated by the subsequent optimization:
% The point-wise covariance matrix $\Sigma_i$ of the point $p_i$ can be computed \cite{zhang20234dradarslam}. 
\vspace{-2mm}
\begin{equation}
\begin{array}{rrclcl}
    \displaystyle \argmin_{[\textbf{n},d]} & \multicolumn{3}{l}{\sum_{i=1}^n D_{M_i}^2} \\
    % \vspace{-2mm}
    % \textbf{v}_i &=\textbf{n}^\top p_i+d \\
    \kappa &= \textbf{n}^\top C\textbf{n}.
    % \vspace{-1mm}
\end{array}
\label{eqn:plane_model}
\end{equation}
$C\in\mathbb{R}^{3\times 3}$ is the covariance matrix of the point cloud considering spatial uncertainty, and $\kappa$ means flatness.
We merge the points adjacent to the estimated plane and refine the ground set by excluding points that exhibit significant deviations from the plane. These are iterated until the flatness converges in each divided region, and the points below the ground are classified as noise and removed. The entire ground segmentation process is described in Algorithm~\ref{alg:ground}.

\begin{figure}[!t]
    \centering
    % \hspace{-1.5cm}
    \begin{subfigure}[b]{0.45\columnwidth}
        \includegraphics[trim=0cm 12cm 23cm 0cm, clip,width=\textwidth]{figure/hill_a.pdf}
        \caption{Scene including a slope}
        \label{fig:hill_a}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\columnwidth}
        \includegraphics[trim=0cm 0cm 0cm 0cm, clip,width=\textwidth]{figure/czm.pdf}
        \caption{Concentric Zone model}
        \label{fig:hill_b}
    \end{subfigure}
    \\
    % \hspace{-0.7cm}
    \begin{subfigure}[b]{0.45\columnwidth}
        \includegraphics[trim=1cm 12cm 24cm 1.2cm, clip,width=\textwidth]{figure/hill_c.pdf}
        \caption{Naive plane fitting}
        \label{fig:hill_c}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\columnwidth}
        \includegraphics[trim=1cm 12cm 24cm 1.2cm, clip,width=\textwidth]{figure/hill_b.pdf}
        \caption{Proposed zone-based fitting}
        \label{fig:hill_d}
    \end{subfigure}
    %\vspace{-0.2cm}
    \caption{
    Comparison between naive plane fitting and our zone-based approach in the sloped environment (yellow box). (c) Many true negatives are found when using naive plane fitting (TN, red). (d) The proposed model effectively filtered ground points even at slope as true positives (TP, green).}
    \label{fig:ground}
    \vspace{-7mm}
\end{figure}

% ALGORITHM
\input{algo_ground}
% ALGORITHM

After segmentation, the refinement of the height value $z_i$ of the point $p_i=
(x_i,y_i,z_i)$ from the ground is performed with the following equation derived from point-wise radial velocity measurement ${v_d}_i$ \cite{DoerENC2020}:
\vspace{-2mm}
\begin{equation}
    z_i=\cfrac{V_{xy}v_z - \sqrt{V_{xy}^2{{v_d}_i}^2 - ({{v_d}_i}^2-v_z^2)(x_i^2+y_i^2){{v_d}_i}^2}}{{{v_d}_i}^2-v_z^2},
    \vspace{-2mm}
\end{equation}
where $v_x, v_y, v_z$ is the vehicle's ego velocity, and $V_{xy}=v_x x_i+v_y y_i$. The dynamic objects on non-ground points are removed after the refinement process.



\subsection{Continuous Velocity Preintegration via Gaussian Process}
\label{subsec:velocity integration}

Our system leverages a \ac{GP}-based continuous modeling on radar velocities, seamlessly integrating 4D radar velocity and \ac{IMU}.
Existing radar-inertial odometry approaches have assumed synchronized measurements \cite{DoerENC2020} or employed the discretized propagation model \cite{zhuang20234d} to mitigate temporal discrepancies.
Inspired by \citet{le2021continuous}, who overcome the above limitations in \ac{IMU} by introducing \ac{GP}, our work leverages \ac{GP} for tightly-coupled preintegration of radar velocity and \ac{IMU}. The continuous nature of the \ac{GP} resolves the temporal discrepancies and enables direct motion estimation without any assumptions despite the asynchronous data streams between radar velocity and \ac{IMU}.

Let us briefly summarize \cite{le2021continuous} and introduce our radar-\ac{IMU} preintegration formulation.
%The angular velocities reflect the orientation change rate, represented in the tangent space of the $SO(3)$ manifold. Since the time derivative of the rotation vector $\boldsymbol{\theta}\in\mathbb{R}^3$ captures this change in orientation, the angular velocity is achieved by the chain rule and its right Jacobian $J_r(\boldsymbol{\theta})$:
%\vspace{-1mm}
%\begin{equation}
%    \boldsymbol{\omega}(t) = J_r(\boldsymbol{\theta}(t))\dot{\boldsymbol{\theta}}(t).
%\end{equation}
%
% To obtain orientation from the angular velocity measured by the \ac{IMU}, preintegration \cite{forster2017manifold} is commonly employed. However, this approach exploited a discretized propagation model with the constant states assumptions, aggravating errors from measurement drifts. To tackle this issue, we utilize \ac{GP} regression, which offers significant advantages in continuous inference and integration \cite{sarkka2011linear, le2021continuous}.
%
Each component of the time derivative of the rotation vector $\dot{\boldsymbol{\theta}}=(\dot\theta_x, \dot\theta_y, \dot\theta_z)$ is modeled using a zero-mean \ac{GP}:
\vspace{-1mm}
\begin{equation}
    \dot\theta_i(t)\sim\mathcal{GP}(0,k_{\theta_i}(t,t')),
\end{equation}
where $k_{\theta_i}(t,t')$ is the kernel function and the index $i$ represents $x,y,z$ components each.
Then the inference ($\star$) of the rotation vector is conducted as follows:
\begin{eqnarray}
\begin{aligned}
\label{eqn:rot_derivative_inference}
    \dot{\theta}_{i\star}(t)&=\mathbf{k}_{\theta_i}(t,\mathbf{t})(\mathbf{K}_{\theta_i}(\mathbf{t}, \mathbf{t})+\sigma_i^2\mathbf{I})^{-1}\boldsymbol{\rho}_i \\
% \end{equation}
% \begin{equation}
\label{eqn:rot_inference}
    \theta_{i\star}(t)&=\int\mathbf{k}_{\theta_i}(t,\mathbf{t})(\mathbf{K}_{\theta_i}(\mathbf{t}, \mathbf{t})+\sigma_i^2\mathbf{I})^{-1}\boldsymbol{\rho}_i \partial t \\
% \end{equation}
% \begin{equation}
\label{eqn:kernel}
    \mathbf{k}_{\theta_i}(t,\mathbf{t})&=[k_{\theta_i}(t,t_1)\dots k_{\theta_i}(t,t_{N_i})] \\
    \mathbf{K}_{\theta_i}(\mathbf{t},\mathbf{t})&=
    \begin{bmatrix}
        k_{\theta_i}(t_1,t_1) & \cdots & k_{\theta_i}(t_1,t_{N_i}) \\
        \vdots & \ddots & \vdots \\
        k_{\theta_i}(t_{N_i},t_1) & \cdots & k_{\theta_i}(t_{N_i},t_{N_i})
    \end{bmatrix},
\end{aligned}
\end{eqnarray}
$\mathbf{t}=[t_1\dots t_{N_i}]$ is the vector of the \ac{IMU} measurement timestamps,
$\mathbf{k}_{\theta_i}(t,\mathbf{t})$ is the kernel vector.
$\sigma_i$ is the standard deviation of the \ac{IMU} gyroscope, and $\boldsymbol{\rho}_i$ is the vector of $\hat{\dot{\theta}}_i(\mathbf{t})$, which can be achieved with the following optimization:
\vspace{-1mm}
\begin{equation}
    \displaystyle \argmin_{[\boldsymbol{\rho}_x, \boldsymbol{\rho}_y, \boldsymbol{\rho}_z]}\sum_{n=1}^{N_i} \left( \norm{\boldsymbol{e}_n^{meas}}_{\Sigma_{\boldsymbol{\omega}}}^2+\norm{\boldsymbol{e}_n^{gp}}_{\Sigma_{gp}}^2 \right),
\end{equation}
where $\norm\cdot_\Sigma$ represents the Mahalanobis norm.
The first term, $\boldsymbol{e}_n^{meas} = J_r(\boldsymbol{\theta}_\star(t_n))\dot{\boldsymbol{\theta}}_\star(t_n)-\Tilde{\boldsymbol{\omega}}(t_n)$ is about the measurement constraint, and $\Sigma_{\boldsymbol{\omega}}$ is the covariance matrix of \ac{IMU} gyroscope. The angular velocity is achieved by the chain rule and its right Jacobian $J_r(\boldsymbol{\theta})$ as $\boldsymbol{\omega}(t) = J_r(\boldsymbol{\theta}(t))\dot{\boldsymbol{\theta}}(t)$.
Secondly, $\boldsymbol{e}_n^{gp}=\dot{\boldsymbol{\theta}}_{\star}(t_n)-\hat{\dot{\boldsymbol{\theta}}}(t_n)$ constraints the unique solution of the optimization with $\Sigma_{gp}$ being \ac{GP} variance.
%These optimized inducing values enable inference of the rotational increment $\Delta \mathbf{R}$ at any given time.

The key idea is that when formulating \ac{GP} to tightly couple radar and \ac{IMU}, \eqref{eqn:rot_inference} enables the inference of rotation at any given time, allowing radar-\ac{IMU} velocity preintegration without additional time synchronization.
As the velocity $\mathbf{v}=(v_x,v_y,v_z)$ cannot be modeled with a zero-mean \ac{GP}, we conduct \ac{GP} model with the prior mean function $\boldsymbol{\mu}(t)$:
\vspace{-1mm}
\begin{equation}
    {v}_i(t)\sim\mathcal{GP}(\mu_i(t),k_{v_i}(t,t')).
\end{equation}

Then the inference of the velocity and translation can be performed as following:
\vspace{-1mm}
\begin{equation}
    {v}_{i\star}(t)=\mu_i(t)+\mathbf{k}_{v_i}(t,\mathbf{t})(\mathbf{K}_{v_i}(\mathbf{t}, \mathbf{t})+\epsilon_i^2\mathbf{I})^{-1}(\boldsymbol{\zeta}_i-\mu_i(\mathbf{t}))
\end{equation}
% \vspace{-1mm}
\begin{equation}
\label{eqn:trans_inference}
    {p}_{i\star}(t)=\int \mu_i(t)+\mathbf{k}_{v_i}(t,\mathbf{t})(\mathbf{K}_{v_i}(\mathbf{t}, \mathbf{t})+\epsilon_i^2\mathbf{I})^{-1}(\boldsymbol{\zeta}_i-\mu_i(\mathbf{t})) \partial t,
\end{equation}
where $\boldsymbol{\zeta}_i$ is the vector of $\hat{v}_i(\mathbf{t})$, $\mathbf{t}=[t_1\dots t_{N_r}]$ represents the radar timestamps, and $\epsilon_i$ is the standard deviation of the velocity measurements.
Hence, inducing values $\boldsymbol{\zeta}_i$ are achieved by the following optimization:
\vspace{-1mm}
\begin{equation}
\label{eqn:vel_optimize}
    \displaystyle \argmin_{[\boldsymbol{\zeta}_x, \boldsymbol{\zeta}_y, \boldsymbol{\zeta}_z]}\sum_{n=1}^{N_r} \left( \norm{\boldsymbol{e}_n^{meas}}_{\Sigma_{\mathbf{v}_n}}^2+\norm{\boldsymbol{e}_n^{gp}}_{\Sigma_{gp}}^2 \right).
\end{equation}
Now we have the radar-associated residual as \eqref{eqn:vel_optimize} with two residual terms: $\boldsymbol{e}_n^{meas} = \Delta{\mathbf{R}^\top}\mathbf{v}_\star(t_n)-\Tilde{\mathbf{v}}(t_n)$, and $\boldsymbol{e}_n^{gp}=\mathbf{v}_{\star}(t_n)-\hat{\mathbf{v}}(t_n)$. Here, $\Sigma_{\mathbf{v}_n}$ is the covariance matrix of velocity at timestamp $t_n$. After \eqref{eqn:vel_optimize} has converged, motion increment $\textbf{T}^{\text{INT}}\in SE(3)$ can be inferenced by \eqref{eqn:rot_inference} and \eqref{eqn:trans_inference}.

\subsection{Cluster-based Weighted ICP}
\label{subsec:scan matching}
% Radar provides spatial information, we utilize scan matching to determine the transformation between consecutive keyframes. In APD-GICP \cite{zhang20234dradarslam}, both point-wise covariance and point-to-plane error in radar scans are considered, addressing the previously neglected matching quality of correspondences. To further enhance the stability of these correspondences, we introduce a weighting mechanism to the objective function in APD-GICP.

Although individual radar points exhibit inherent uncertainties, clusters from radar scans can effectively represent the overall shape of structures as shown in \figref{fig:cluster}. These clusters often correspond to prominent features, which are crucial for accurate scan registration. We utilize the DBSCAN to segment these clusters and assign higher weights to the correspondences within consistent clusters. Furthermore, the flatness of each cluster is incorporated into the weight calculation, enhancing the spatial representation of each cluster.
Therefore, the transformation $\textbf{T}^{\text{ICP}}\in SE(3)$ between keyframes is estimated by the following optimization:
\begin{equation}
    \displaystyle \textbf{T}^{\text{ICP}}=\argmin_{\textbf{T}} \sum_i \left(w_{i, clust}+w_{i,flat}\right)\norm{p_i-\textbf{T}q_i}_{\Sigma_i}^2
\end{equation}
where $\Sigma_i$ is the covariance matrix including spatial uncertainty, and $w_i$ represents the each weight.

% This approach enhances the robustness and accuracy of scan matching by leveraging the structural information inherent in radar point clouds and by adjusting the influence of correspondences based on their spatial relationships and geometric properties.

\subsection{Pose Graph Optimization}

Incremental motion from \secref{subsec:velocity integration} and \secref{subsec:scan matching} is used to define $SE(3)$ edges in the pose graph, and the keyframe-based pose graph optimization is conducted as:
\vspace{-1mm}
\begin{eqnarray}
\label{eqn:pgo}
    \argmin_{\textbf{X}}\sum_{(i,j)}\norm{\textbf{T}^{\text{INT}}_{ij}-h(\textbf{x}_i,\textbf{x}_j)}^2_{\Sigma_\text{INT}}+\norm{\textbf{T}^{\text{ICP}}_{ij}-h(\textbf{x}_i,\textbf{x}_j)}^2_{\Sigma_\text{ICP}}
\end{eqnarray}
where $h(\textbf{x}_i,\textbf{x}_j)$ computes the relative transformation between two poses. 
A new keyframe is selected when the motion increment from numerical integration exceeds a predefined threshold relative to the previous keyframe. The $g2o$ \cite{kummerle2011g} library is utilized for back-end optimization.


%FIGURE
\begin{figure}[!t]
    \centering
    % \includegraphics[trim=0cm 0.1cm 9cm 0cm, clip, width=1\columnwidth]{figure/radar_cluster.pdf}
    \includegraphics[trim=0cm 1cm 9.5cm 0cm, clip, width=1\columnwidth]{figure/fig4_radar_cluster.pdf}
    \vspace{-7mm}
    \caption{
        As the vehicle moves $t$ to $t+1$, prominent features maintain the structures in radar (yellow, cyan). The higher weight is allocated to correspondences within the consistent cluster (green line).
    }
    \label{fig:cluster}
    \vspace{-6mm}
\end{figure}
%FIGURE