\section{experiment}
\label{sec:experiment}

\subsection{Datasets and Evaluation Metric}

For evaluation, we use NTU4DRadLM \cite{zhang2023NTU} and MSC-RAD4R \cite{choi2023MSC} datasets, both utilized Oculii Eagle 4D radar and \ac{IMU}. NTU4DRadLM is designed to assess performance in semi-structured environments with ground vehicle systems. MSC-RAD4R includes urban and rural environments using a car platform with fast and high-dynamic sequences.
% For keyframe selection, we use 1\unit{m} and 5{\textdegree} for thresholds in handcart sequences, and 5\unit{m} and 10{\textdegree} for car sequences.

We benchmark our method against state-of-the-art open-sourced 4D radar and radar-inertial odometry algorithms: APD-GICP in 4DRadarSLAM \cite{zhang20234dradarslam}, EKF-RIO \cite{DoerENC2020} BCV \cite{park20213d}, and DeRO \cite{do2024dero}.
Unfortunately, other ground-aided radar-inertial odometry \cite{chen2023drio, li20234d} are not open-sourced for comparison. Instead, a thorough comparative analysis for our uncertainty-aware ground filtering will be provided in \secref{subsec:ablation_ground}. We remove the loop closure in 4DRadarSLAM to ensure equitable comparison, as our approach focuses solely on odometry. For quantitative analysis, we compute the \ac{RMSE} of the \ac{ATE} and \ac{RPE} with evo library \cite{grupp2017evo}.
\ac{ATE} is expressed in meters, and \ac{RPE} is expressed in degrees per meter and percentage for the rotational (RPE$_r$) and translational (RPE$_t$) components, respectively.
Since MSC-RAD4R provides ground truth data only for translation, we evaluated only the \ac{ATE} in MSC-RAD4R.
In each table, we highlight the best results in \textbf{bold}.


\subsection{Evaluation on the NTU4DRadLM Dataset}
\label{subsec:ntu}

%TABLE
\input{tab/ATE}
%TABLE

\begin{figure*}[!t]    
    \centering
    % Left Minipage
    % \hspace{1mm}
    \begin{minipage}{0.49\textwidth}
        \vspace{-70mm}
        \begin{subfigure}[b]{1.0\textwidth}
            \centering
            \hspace{-5mm}
            \includegraphics[trim=2.7cm 0cm 6.7cm 0.6cm, clip, width=1\textwidth]{figure/fig5_ntu_loop2_legend.pdf}
            \vspace{-3mm}
            \caption{Estimated trajectory in \texttt{loop2}}
            \vspace{-4mm}
            % \setcounter{figure}{4}
            \label{subfig:ntu_loop2_traj}
            \setcounter{figure}{5}
        \end{subfigure}
    \end{minipage}
    % Right Minipage
    \hspace{-2mm}
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \begin{minipage}[b]{0.95\textwidth}
        \vspace{-2mm}
        \centering
        \hspace{2mm}
        \scriptsize
         % Table with caption at the top
        % \captionsetup{labelformat=empty}
        \captionof{table}{RPE (Trans (\%)/Rot (deg/m)) in NTU4DRadLM}
        \label{tab:result_rpe}
        \resizebox{\textwidth}{!}{  % Resizes the table to fit the width of minipage
            \begin{tabular}{l|cccc}
                \hline
                \textbf{Method} & \textbf{cp} & \textbf{nyl} & \textbf{loop2} & \textbf{loop3} \\ \hline\hline
                4DRadarSLAM & 0.106/1.107 & 0.178/1.106 & 0.745/0.751 & 0.472/0.562 \\ 
                EKF-RIO     & 0.298/1.806 & 0.423/1.864 & 1.750/1.179 & 1.307/0.596 \\
                BCV         & 0.096/1.232 & 0.142/\textbf{0.949} & 0.368/0.564 & 0.546/0.537 \\ 
                DeRO        & 0.112/1.625 & 0.318/1.610 & 2.059/0.880 & 0.373/0.524 \\ 
                Proposed    & \textbf{0.085}/\textbf{0.722} & \textbf{0.116}/1.003 & \textbf{0.338}/\textbf{0.547} & \textbf{0.365}/\textbf{0.384} \\ \hline
            \end{tabular}
        }
        \end{minipage}
        \setcounter{subfigure}{1}
        \begin{minipage}[b]{\textwidth}
        \centering
            \begin{subfigure}[b]{\textwidth}
            \vspace{3mm}
                \centering
                \includegraphics[trim=0.3cm 0.2cm 0cm 0.5cm, clip, width=1\textwidth]{figure/fig5_ntu_loop3_rpy_zoom.pdf}
                \vspace{-5mm}
                \caption{Estimated rotation in \texttt{loop3} (degrees)}
                % \setcounter{figure}{5}
                \label{sugfig:ntu_loop3_rpy}
                \setcounter{figure}{4}
            \end{subfigure}
            
        \end{minipage}
    \end{minipage}
    \vspace{-1mm}
    \caption{(a) The trajectory plots of \texttt{loop2} in NTU4DRadLM. The proposed method (blue) best aligns with the ground truth (black). (b) Estimated rotation in \texttt{loop3}. In terms of heading (a zoomed view `C' in (b)), both 4DRadarSLAM and ours demonstrate superior performance; however, including the roll and pitch, ours exhibits better results (zoomed views `A' and `B' in (b)).}
    \label{fig:ntu_main}	
    \vspace{-3mm}
\end{figure*}
\begin{figure*}[!t]
    \centering
    \hspace{1mm}
     \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[trim=1.2cm 0cm 1.5cm 0cm, clip, width=\textwidth]{figure/fig6_msc_sub.pdf}
        \vspace{-3mm}
        \caption{Map based on odometry}
        \label{subfig:msc_map}
    \end{subfigure}
    \hspace{-1mm}
    \begin{subfigure}[b]{0.43\textwidth}
        \centering
        \includegraphics[trim=0cm 0cm 4.5cm 0cm, clip, width=\textwidth]{figure/fig6_msc_loop_a0_drift.pdf}
        \vspace{-10mm}
        \caption{Estimated trajectory in \texttt{LOOP\_A0}}
        \label{subfig:msc_loopa0_traj}
    \end{subfigure}
    % \hspace{2mm}
    \begin{subfigure}[b]{0.35\textwidth}
        \centering
        \includegraphics[trim=0cm 0cm 0cm 0.2cm, clip, width=0.95\textwidth]{figure/pathlength_z_multi.pdf}
        \vspace{-2mm}
        \caption{Elevation over traveled path length (m)}
        \label{subfig:msc_elevation}
    \end{subfigure}
    \hspace{-3mm}
    \vspace{-1mm}
    \caption{(a) Qualitative analysis of the proposed odometry in \texttt{LOOP\_A0}. Point cloud map based on our odometry shows well-alignment with the satellite image. (b) Sudden ego-velocity drift can occur due to large dynamic objects in \texttt{LOOP\_A0}. While other radar-inertial baselines fail to generate accurate trajectories, our method effectively handles the challenging scenarios. (c) Detailed analysis in elevation on \texttt{URBAN\_A0}, \texttt{LOOP\_A0}, \texttt{RURAL\_A2}, respectively. In \texttt{RURAL\_A2}, EKF-RIO is omitted for clarity.}
    \label{fig:msc}	
    \vspace{-7mm}
\end{figure*}

As detailed in \tabref{tab:result_ate}, our method represents consistent performance through the experiments.
In the cases of \texttt{nyl} and \texttt{loop2}, where noise generated by sunshades or ceilings is prevalent, 4DRadarSLAM encounters performance degradation induced by the absence of effective noise filtering.
Despite this, our method exhibits robust performance owing to ground filtering.
\texttt{loop2} involves vigorous rotational movements, discretized propagation model in EKF-RIO and BCV struggled from orientation estimation as illustrated in \figref{subfig:ntu_loop2_traj}. DeRO exhibits the worst performance, affected by both noise and discretization.
Conversely, our continuous model with \ac{GP} enables accurate estimation throughout the experiments, demonstrating that the proposed method effectively handles the aforementioned challenges.

Interestingly, 4DRadarSLAM achieves the lowest \ac{ATE} in \texttt{loop3} even without utilizing \ac{IMU}. The \texttt{loop3} sequence includes vertical structures such as walls and hills, which generate horizontal multipath.
Our filtering process, which focuses on rejecting underground outliers, is less effective for these types of noise.
Nevertheless, our method exhibits the lowest RPE$_r$, validating the effectiveness of continuous integration as shown in \tabref{tab:result_rpe} and \figref{sugfig:ntu_loop3_rpy}.

% Additionally, the integration between \ac{IMU} gyroscope and radar velocity is influenced by the precision of extrinsic calibration. NTU4DRadLM performed extrinsic calibration between radar and \ac{IMU} along with \ac{LiDAR}, RGB, and thermal cameras. As the number of sensors involved in the calibration process increases, the accumulated calibration errors become inevitable, causing discrepancies in the integration between \ac{IMU} orientation and radar velocity.

% unstructured environment DBSCAN error: clustering based weight provides wrong, 

% calibration effect : for integration, we transform the ego velocity from radar frame to imu frame, which needs the extrinsic value.(v-[w]r)
% For \ac{IMU} and radar velocity interpolation, accurate extrinsic calibration is needed.
% In NTU4DRadLM, the radar-\ac{IMU} calibration is conducted through radar - thermal - RGB - lidar - imu. 
% the calibration error might be accumulated, (especially for thermal cameras)


% loop2 loop3 contains lots of  rotation in the sequence and long, which makes whole ATE worse (4~5km)

\subsection{Evaluation on the MSC-RAD4R Dataset}
\label{subsec:msc}

In MSC-RAD4R, our method outperforms the other baselines as represented in \tabref{tab:result_ate}.
\texttt{URBAN\_A0} is characterized by numerous street trees, resulting in dominant vertical line features. These features are incompatible with point-to-plane errors in 4DRadarSLAM, causing localization failure.
In the \texttt{LOOP} sequences, which involve high vehicle speed with rapid rotational movements, 4DRadarSLAM indicates the scale misalignment.
% Although DeRO attempts to compensate for the tilt angle with \ac{IMU} accelerometer, introducing drift due to noisy \ac{IMU} measurement.
As shown in \figref{fig:msc}, large dynamic objects can produce abrupt drifts in ego-velocity estimation. Discretized propagation models that rely on constant state assumptions exacerbate these errors, as illustrated in the performance of BCV and DeRO.
Nonetheless, the proposed algorithm demonstrates consistent performance benefiting from reliance on the \ac{GP}-based continuous model, which effectively compensates for these measurement drifts and results in a smooth trajectory.
\texttt{RURAL\_A2} and \texttt{RURAL\_B2} are characterized by sharp roundabouts and high dynamics in harsh weather conditions, presenting significant challenges. Nonetheless, our algorithm maintains reliable performance.
\begin{figure*}[!t]
    \centering
    % First subfloat
    \begin{subfigure}[b]{0.51\textwidth}
        \centering
        \includegraphics[trim=0cm 10.3cm 13cm 0cm, clip, width=\textwidth]{figure/fig7_segmentation.pdf}
        \vspace{-6mm}
        \caption{Noise filtering result of each method in \texttt{nyl}}
        \label{subfig:filter}
    \end{subfigure}
    \hspace{-2mm}
    % Second subfloat
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=\textwidth]{figure/fig7_ablation_ntu_z_per.pdf}
        \vspace{-6mm}
        \caption{$z$-axis error in \texttt{nyl}}
        \label{subfig:elevation}
    \end{subfigure}
    \caption{(a) Qualitative results of each filtering method projected onto the $XZ$-plane.
    The ground truth of the noise was created by projecting the \ac{LiDAR} scan onto the radar. (b) The effect of each outlier rejection in $z$-axis odometry. Vertical errors over path length are detailed in the right box.}
    \label{fig:elevation}
    \vspace{-6mm}
\end{figure*}
Remarkably, 4DRadarSLAM achieves comparable results without leveraging \ac{IMU}, underscoring the appropriate fusion model for asynchronous sensor measurements.
Throughout the experiments, we observe that our methodology exhibits minimal elevation error.
%, which will be comprehensively explored in \secref{subsec:ablation}.

\input{tab/Ablation}

\subsection{Effect of Uncertainty-Aware Ground Filtering}
\label{subsec:ablation_ground}

% To verify the effect of each module, we performed ablation studies on filtering and continuous velocity integration.
In the following analysis (\secref{subsec:ablation_ground}-\secref{subsec:ablation_velgp}), we denote our system as \texttt{FULL}, uncertainty-aware ground filtering as \texttt{FILTER}, and continuous velocity preintegration as \texttt{CONT}. We perform ablation studies to verify the effect of each module, compared to discrete integration without any noise filtering method (\texttt{RAW}).


To evaluate the effectiveness of our filtering method, we conduct a comparative analysis with the RANSAC-based naive plane fitting \cite{li20234d} and Patchwork++ \cite{lee2022patchworkpp}. The qualitative results are depicted in \figref{subfig:filter}. The RANSAC-based approach exploits height thresholding for ground point segmentation; however, this produces false positives in areas with varying terrain elevation, such as slopes, resulting in the erroneous classification of significant static features as noise. Patchwork++ fails to account for spatial uncertainties associated with distant points, yielding unmitigated noise despite utilizing zone-based ground segmentation. In contrast, our method accurately filters out the noises.

\Cref{subfig:elevation} indicates that our approach outperforms other methods over elevation accuracy.
\tabref{table:ablation} presents the quantitative improvements in ATE attributed to our filtering method.
As expected, \texttt{RAW} shows diminished performance compared to \texttt{FILTER} due to the absence of noise filtering, demonstrating the robustness of our filtering approach in varying conditions.
These improvements are particularly significant in the \texttt{nyl} dataset, where the majority of noise consists of underground noise caused by sunshades. This denotes that our method is highly effective in mitigating this predominant type of noise.
In conclusion, our uncertainty-aware ground model effectively handles noises and enhances the odometry accuracy.

\subsection{Effect of Continuous Velocity PreIntegration}
\label{subsec:ablation_velgp}

In \tabref{table:ablation},
\texttt{FULL} demonstrates superior performance over \texttt{RAW} and \texttt{FILTER}, both numerically integrate the \ac{IMU} angular velocity and the radar velocity \cite{kubelka2024do}. 
The discretized propagation model to address the temporal discrepancies exhibits limitations due to measurement drift and constant state assumptions, resulting in significant degradation on \texttt{LOOP\_A0} and \texttt{RURAL\_A2} with high vehicle speeds and sharp turns.
Conversely, \texttt{FULL} effectively accommodates vigorously changing orientations and velocities, attributed to the proposed velocity preintegration, which enables direct motion estimation through asynchronous \ac{IMU} angular velocities and radar velocities.
Moreover, the smoothness nature of \ac{GP} makes our preintegration process more robust to unavoidable measurement noise.

%TABLE
\input{tab/Time_tab}
%TABLE

\subsection{Computational Cost}
\label{subsec:timecost}

The time consumption analysis results in \texttt{loop2} and \texttt{LOOP\_A0}, which represent the longest paths in the dataset, are presented in \tabref{table:time}. The experiments were conducted on Intel i7 CPU@2.50 {\GHz} and 64 {\GB} RAM.
Uncertainty-aware ground filtering and scan matching can be executed in real-time. While \ac{GP} integration and optimization are computationally expensive, they are performed in parallel in the back-end, ensuring that our system maintains real-time capability. Moreover, additional performance enhancements can be pursued during continuous preintegration.
