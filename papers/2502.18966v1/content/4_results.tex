\section{Results and Discussion} \label{sec:results}

To assess the utility of generality-oriented optimization, it is necessary to validate the transferability of general optima to unseen tasks. Therefore, we commence our analysis by systematically investigating all benchmark surfaces using an exhaustive grid search. This analysis reveals that, with an increasing number of substrates in $\mathcal{W}_{\text{train}}$ considered during optimization, the transferability of the found optima to a held-out test set $\mathcal{W}_{\text{test}}$ increases (\cref{fig:results_dataset-analysis}, left), as evidenced by Spearman's $\rho > 0$.
While this finding is arguably unsurprising and merely confirms a common assumption in the field \citep{wagen_screening_2022}, it indicates possible caveats concerning the use of the non-augmented problems as benchmarks for generality-oriented optimization: 
Even with larger sizes of $\mathcal{W}_{\text{train}}$, the found optima do not consistently lead to optimal outcomes on the corresponding test sets (i.e. generality scores of 1.0). 
In contrast, we find that on the augmented benchmark surfaces, which are more reflective of experimental reality, the transferability of the identified optima to a held-out $\mathcal{W}_{\text{test}}$ is significantly improved.
Notably, these observations are not limited to the definition of generality as the average over all $\rvw \in \gW$, but remain valid for further aggregation functions on almost all surfaces (see \cref{subsubsec:add_results_data-analysis}).
These findings underline that – especially in "needle in a haystack scenarios" – generality-oriented optimization is necessary for finding transferable optima. 
Most importantly, such scenarios apply to real-world reaction optimization, where for most reactions, the majority of possible conditions do not lead to observable product quantities. 
This re-emphasizes the need for benchmark problems that reflect experimental reality.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{content/figures/dataset_analysis_mean.pdf}
    
    \vspace{-1em}
    
    \caption{
    Normalized test-set generality score as determined by exhaustive grid search for the four benchmarks on the original (left) and augmented (right) problems for the mean aggregation. Average and standard error are taken from thirty different train/test substrates splits.
    }
    \label{fig:results_dataset-analysis}
\end{figure}

Having established the utility of generality-oriented optimization, we set out to perform a systematic benchmark of how to identify those optima using iterative optimization under partial objective monitoring.
In the first step, we evaluate those approaches that have been developed in the context of reaction optimization \citep{angello_closed-loop_2022, wang_identifying_2024} on two practically relevant aggregation functions, the mean and threshold aggregation (\cref{subsubsec: Aggregation_functions}). As a summary, \cref{fig:results_average_runs} shows the optimization trajectories of these different algorithms averaged across all augmented benchmark problems.
Overall, we find that the BO-based sequential strategy acquisition strategy,  outlined by \citet{angello_closed-loop_2022} (\textsc{Seq 1LA-UCB-PV}), shows faster optimization performance compared to other algorithms used in the chemical domain.
In particular, it significantly outperforms the \textsc{Bandit} algorithm proposed by \citet{wang_identifying_2024}, which can be attributed to the necessity of evaluating each $\rvw \in \mathcal{W}_{\text{train}}$ at the outset of each campaign, tying up a notable share of the experimental budget.
Assuredly, both proposed methods readily outperform the two random baselines \textsc{Random} and \textsc{Seq 1LA-RA-RA}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{content/figures/chemistry_methods_enhance.pdf}
    
    \vspace{-1em}
    
    \caption{Optimization trajectories of different algorithms for generality-oriented optimization previously reported in the chemical domain. The trajectories are averaged over all four augmented benchmark problems. Note that the \textsc{Bandit} algorithm is incompatible with the threshold aggregation function.
    }
    \label{fig:results_average_runs}
\end{figure}

Inspired by these observations, we perform a deeper investigation into the approaches formalized in \cref{subsec:Generality-BO}. 
Initially, different sequential strategies of acquiring $\rvx_{\text{next}}$ and $\rvw_{\text{next}}$ are evaluated. 
For this purpose, we compare multiple acquisition functions $\alpha_x$ for selecting $\rvx_{\text{next}} \in \mathcal{X}$, as formalized in \cref{subsec:BO_benchmark} and \cref{subsec:strategies}. 
Overall, the empirical results (\cref{fig:results_sequential}, top half) indicate largely similar optimization behavior for the different $\alpha_x$. 
However, it can be observed that a higher degree of exploration has a positive effect on optimization performance, e.g., when comparing the baseline method (\textsc{Seq 1LA-UCB-PV}; $\alpha_x$: UCB with $\beta = 0.5$) with a more exploratory variant (\textsc{Seq 1LA-UCBE-PV}; $\alpha_x$: UCB with $\beta = 5.0$). 
While systematic investigations into the generalizability of this finding are ongoing, we hypothesize that the partial monitoring scenario compromises overall regression performance, and therefore leads to less efficient exploitation.
Surprisingly, two-step-lookahead acquisition functions for $\alpha_x$, which should conceptually be well-suited for the partial monitoring scenario (\cref{subsubsec:acquisition_strategies_main}), do not lead to significant improvements compared to their one-step-lookahead counterparts (e.g., comparing \textsc{Seq 1LA-UCB-PV} with \textsc{Seq 2LA-UCB-PV} and \textsc{Seq 2LA-EI-PV}). Yet, the trend that more exploratory $\alpha_x$ improve optimization behavior can also be observed for two-step-lookahead acquisition functions. In contrast, especially for the threshold aggregation function (\cref{fig:results_sequential}), we find that Expected Improvement (EI) shows significantly decreased optimization performance, which may be attributed to the uncertainty in estimating the current optimum in a partial monitoring scenario. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{content/figures/sequential_enhance.pdf}
    
    \vspace{-1em}
    
    \caption{Optimization trajectories using sequential acquisition strategies. The top row shows the variation of $\alpha_x$, while the bottom row shows the variation of $\alpha_w$. Trajectories are averaged over all four augmented benchmark problems. In general, more complex two-step lookahead acquisition strategies outperform more simple one-step lookahead strategies. While more explorative $\alpha_x$ perform better, the choice of $\alpha_w$ does not significantly influence the optimization performance for one-step lookahead strategies.
    }
    \label{fig:results_sequential}
\end{figure}

Notably, we observe only a small influence of the choice of $\alpha_w$ (\cref{fig:results_sequential}, bottom half).
In particular, an uncertainty-driven acquisition of $\alpha_w$, as used by \citet{angello_closed-loop_2022}, shows only slightly improved optimization performance over a fully random acquisition of $\rvw_{\text{next}}$ (compare \textsc{Seq 1LA-UCB-PV} and \textsc{Seq 1LA-UCB-RA}).
Notably, the difference becomes more pronounced for two-step lookahead acquisition policies (\textsc{Seq 2LA-UCB-PV} and \textsc{Seq 2LA-UCB-RA}). 
These findings indicate that, in the partial monitoring scenario, predictive uncertainties are not used effectively in \textit{myopic} decision making, but their accurate propagation can improve \textit{hyperopic} decisions. 
However, for none of the discussed two-step lookahead acquisition policies, does this ability to effectively harness uncertainties for $\alpha_w$ lead to empirical performance improvements over the one-step lookahead policies. 

We hypothesize that this can be attributed to the primitive decoupling of $\mathcal{X}$ and $\mathcal{W}_{\text{train}}$. 
Therefore, we evenutally benchmark acquisitions strategies that recommend $\rvx_{\text{next}}$ and $\rvw_{\text{next}}$ through a joint optimization over $\mathcal{X} \times \mathcal{W}_{\text{train}}$, as originally proposed by \citet{toscano-palmerin_bayesian_2018} in the context of BO with expensive integrands. 
\cref{fig:results_joint} shows a comparison of different joint acquisition strategies to the sequential strategy discussed above. 
Empirically, we find that jointly optimizing for $\rvx_{\text{next}}$ and $\rvw_{\text{next}}$ does not lead to improved optimization performance, both when using EI and UCB as the acquisition function. 
At the same time, we find that, in the case of joint acquisition, the discrepancies between EI and UCB that are observed in the sequential case, are no longer present, validating the robustness of the joint optimization over $\mathcal{X} \times \mathcal{W}$. 
However, given the increased computational cost of joint optimization, our empirical findings suggest that the algorithmically simpler sequential acquisition strategy with one-step lookahead acquisition functions is well-suited for generality-oriented optimization for chemical reactions, and performs on par with more complex algorithmic approaches.


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{content/figures/joint_enhance.pdf}
    
    \vspace{-1em}
    
    \caption{Optimization trajectories using sequential and joint two-step lookahead acquisition strategies. The trajectories are averaged over all four augmented benchmark problems. Overall, we observe a similar optimization performance of sequential and joint two-step lookahead acquisition strategies.}
    \label{fig:results_joint}
\end{figure}

\begin{tcolorbox}[colback=white, colframe=black, rounded corners, left=5pt, right=5pt, top=5pt, bottom=5pt, boxsep=5pt, boxrule=0.75pt]
  Optimization over curried functions is necessary to obtain general parameters. In doing so, sequentially isolating parameter and task selection is a convenient assumption that empirically does not degrade optimization performance.
\end{tcolorbox}