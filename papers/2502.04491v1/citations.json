[
  {
    "index": 0,
    "papers": [
      {
        "key": "oko2023diffusion",
        "author": "Oko, Kazusato and Akiyama, Shunta and Suzuki, Taiji",
        "title": "Diffusion models are minimax optimal distribution estimators"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2023score",
        "author": "Chen, Minshuo and Huang, Kaixuan and Zhao, Tuo and Wang, Mengdi",
        "title": "Score approximation, estimation and distribution recovery of diffusion models on low-dimensional data"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "fu2024unveil",
        "author": "Fu, Hengyu and Yang, Zhuoran and Wang, Mengdi and Chen, Minshuo",
        "title": "Unveil conditional diffusion models with classifier-free guidance: A sharp statistical theory"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hu2024statistical",
        "author": "Hu, Jerry Yao-Chieh and Wu, Weimin and Lee, Yi-Chen and Huang, Yu-Chao and Chen, Minshuo and Liu, Han",
        "title": "On statistical rates of conditional diffusion transformers: Approximation, estimation and minimax optimality"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wibisono2024optimal",
        "author": "Wibisono, Andre and Wu, Yihong and Yang, Kaylee Yingxi",
        "title": "Optimal score estimation via empirical bayes smoothing"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chen2022sampling",
        "author": "Chen, Sitan and Chewi, Sinho and Li, Jerry and Li, Yuanzhi and Salim, Adil and Zhang, Anru R",
        "title": "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions"
      },
      {
        "key": "chen2023improved",
        "author": "Chen, Hongrui and Lee, Holden and Lu, Jianfeng",
        "title": "Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions"
      },
      {
        "key": "lee2023convergence",
        "author": "Lee, Holden and Lu, Jianfeng and Tan, Yixin",
        "title": "Convergence of score-based generative modeling for general data distributions"
      },
      {
        "key": "chen2024probability",
        "author": "Chen, Sitan and Chewi, Sinho and Lee, Holden and Li, Yuanzhi and Lu, Jianfeng and Salim, Adil",
        "title": "The probability flow ode is provably fast"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "baxter2000model",
        "author": "Baxter, Jonathan",
        "title": "A model of inductive bias learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "maurer2016benefit",
        "author": "Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino",
        "title": "The benefit of multitask representation learning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "aliakbarpour2024metalearning",
        "author": "Aliakbarpour, Maryam and Bairaktari, Konstantina and Brown, Gavin and Smith, Adam and Srebro, Nathan and Ullman, Jonathan",
        "title": "Metalearning with very few samples per task"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tripuraneni2020theory",
        "author": "Tripuraneni, Nilesh and Jordan, Michael and Jin, Chi",
        "title": "On the theory of transfer learning: The importance of task diversity"
      },
      {
        "key": "du2020few",
        "author": "Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi",
        "title": "Few-shot learning via learning the representation, provably"
      },
      {
        "key": "tripuraneni2021provable",
        "author": "Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael",
        "title": "Provable meta-learning of linear representations"
      },
      {
        "key": "watkins2023optimistic",
        "author": "Watkins, Austin and Ullah, Enayat and Nguyen-Tang, Thanh and Arora, Raman",
        "title": "Optimistic rates for multi-task representation learning"
      },
      {
        "key": "chua2021fine",
        "author": "Chua, Kurtland and Lei, Qi and Lee, Jason D",
        "title": "How fine-tuning allows for effective meta-learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ruiz2023dreambooth",
        "author": "Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir",
        "title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation"
      },
      {
        "key": "giannone2022few",
        "author": "Giannone, Giorgio and Nielsen, Didrik and Winther, Ole",
        "title": "Few-shot diffusion models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      },
      {
        "key": "ramesh2022hierarchical",
        "author": "Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark",
        "title": "Hierarchical text-conditional image generation with clip latents"
      },
      {
        "key": "sinha2021d2c",
        "author": "Sinha, Abhishek and Song, Jiaming and Meng, Chenlin and Ermon, Stefano",
        "title": "D2c: Diffusion-decoding models for few-shot conditional generation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "he2023diffusion",
        "author": "He, Haoran and Bai, Chenjia and Xu, Kang and Yang, Zhuoran and Zhang, Weinan and Wang, Dong and Zhao, Bin and Li, Xuelong",
        "title": "Diffusion model is an effective planner and data synthesizer for multi-task reinforcement learning"
      },
      {
        "key": "ni2023metadiffuser",
        "author": "Ni, Fei and Hao, Jianye and Mu, Yao and Yuan, Yifu and Zheng, Yan and Wang, Bin and Liang, Zhixuan",
        "title": "Metadiffuser: Diffusion model as conditional planner for offline meta-rl"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "tewari2023diffusion",
        "author": "Tewari, Ayush and Yin, Tianwei and Cazenavette, George and Rezchikov, Semon and Tenenbaum, Josh and Durand, Fr{\\'e}do and Freeman, Bill and Sitzmann, Vincent",
        "title": "Diffusion with forward models: Solving stochastic inverse problems without direct supervision"
      },
      {
        "key": "chung2023solving",
        "author": "Chung, Hyungjin and Ryu, Dohoon and McCann, Michael T and Klasky, Marc L and Ye, Jong Chul",
        "title": "Solving 3d inverse problems using pre-trained 2d diffusion models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "yang2024fewshot",
        "author": "Ruofeng Yang and Bo Jiang and Cheng Chen and Ruinan Jin and Baoxiang Wang and Shuai Li",
        "title": "Few-Shot Diffusion Models Escape the Curse of Dimensionality"
      }
    ]
  }
]