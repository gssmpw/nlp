\section{Related Work}
\label{sec:related}

\subsection{Robustness in image classification}
\label{sec:Robustness}

Digital images are susceptible to noise,
compression, and other sources of corruption
caused by a broad range of mechanisms.
Although such corruption does not prevent
human visual perception from identifying
images with high accuracy, it \textit{does}
significantly reduce the image identification accuracy
of image recognition models____,
and improving the robustness of image recognition models
is a central challenge for image recognition research.

The robustness of image recognition models
may be quantified by testing on specialized
datasets such as ImageNet-C and CIFAR-C, which
consist of images that have been corrupted in various
ways---such as by adding noise, blurring, weathering,
or applying digital transformations---to reflect 15
types of corruption commonly experienced by
digital images; as an example, one corrupted image 
from CIFAR-C is shown in Fig.~\ref{figCIFARC}.

To quantify robustness using ImageNet-C or CIFAR-C,
the image classification accuracy is measured for each of the
15 categories of image corruption, and an average is performed over all
categories to yield a \textit{mean corruption error} (mCE);
smaller mCE values indicate greater robustness.

In addition to quantifying robustness against corruption,
robustness may also be quantified against adversaries, 
i.e., adversarial attacks, by measuring
image classification accuracy for special test images
in the ImageNet and CIFAR datasets to which adversarial
attacks have been applied; again, lower values of the 
image classification accuracy indicate greater robustness.

\subsection{Robustness and illusory images}
\label{sec:Illusion_Moire_Robust}
% Illusions and robustness
Image recognition models have been often shown to be
affected by illusory images in the same ways humans are. For example,
illusions that confuse viewers into making erroneous color 
judgments____, and illusions that trick viewers into 
perceiving a boundary contour that is not actually present____ 
provoke responses from deep learning models that resemble the responses 
of human viewers____.
Illusory studies investigating the behavior of image recognition models
on such illusory images often include descriptions of tests
to characterize robustness; for example, studies of color-related 
illusions use corrupted images---obtained by subjecting test images 
to attacks mimicking the image representations responsible for
inducing illusions---to test the behavior of deep learning 
models____. The results of such tests indicate improved
robustness for CNNs capable of accounting for illusions.
Similarly, studies of boundary-contour illusions have
discussed tests to assess the robustness of deep learning models
capable of taking illusions into consideration____.

% \figCIFARC
\input{figs/en-fig2}

% Illusions and Moir\'e images
One common type of illusion involves static images
that viewers erroneously perceive to be in motion;
illusions of this type often feature concentric circles 
or striped patterns____. One
well-known class of images of this type is composed of images
incorporating interference fringes; as mentioned above, we refer to such images as Moir\'e images.
Moir\'e images are produced by superposing
simple patterns of stripes, concentric circles,
or similar elements. They are closely related to
optical illusions and have been studied in fields
ranging from image processing to visual art____.

% \figMixImages
\input{figs/en-fig3}

% Robustness and Moire images
Moir\'e patterns arise naturally in digital images;
for example, interference between a striped texture pattern
and the spatial frequencies present in a digital image
can produce Moir\'e textures.
Within the field of image recognition, researchers have studied
techniques for eliminating Moir\'e features in digital images
and for creating image recognition models capable of recognizing
the emergence of Moir\'e features____.
In the latter case, the creation of Moir\'e-aware image recognition
models has been shown to improve robustness against
image corruption____.




These observations suggest that illusory images and Moir\'e images
may have significant ramifications for robustness---and motivate the
basic assumption on which the present study is premised. Namely, we hypothesize
that using Moir\'e images for data augmentation will improve the 
robustness of deep learning models trained on the resulting
augmented datasets.

\subsection{PIXMIX}
\label{sec:PIXMIX}

In the PixMix approach to data augmentation,
training images from databases such as ImageNet or CIFAR
are combined additively or multiplicatively with an auxiliary set
of structurally complex images to yield an augmented dataset;
deep learning models trained on the augmented dataset then
exhibit improved image identification accuracy and robustness
compared to models trained on the non-augmented dataset.
In the original PixMix proposal, the auxiliary set of 
structurally complex images included two types of images:
Fractal arts and FVis. Examples of these two
types of images are shown in Fig~\ref{figMixImages}.

Fractal arts (note that this is different from FractalDB) are manually designed images downloaded
from DeviantArt; these images contain
shapes and color schemes designed to pique the curiosity
of human visual perception, and are thus expected to be
structurally complex.
FVis are machine-generated images that may be downloaded
from OpenAI Microscope. This database allows
visualization results for image features---as extracted
by various pre-trained CNN models operating on a large image
dataset---to be downloaded in the form of image files.
The structural complexity of these feature-visualization images
is often comparable to that of Fractal arts.

Given an input image dataset, PixMix produces an
augmented dataset by performing repeated mixing operations.
Specifically, each input image is subjected to
a randomly chosen number (at most 5) of mixing steps and 
in each step, the image is mixed either with an input
image or with an image chosen from the auxiliary image
set, and the mixing is performed either additively or
multiplicatively (chosen at random).
Deep learning models trained on PixMix augmented datasets
are known to exhibit improved image identification accuracy 
and robustness compared to other data augmentation methods
such as Mixup____ or CutMix____.

However, some Fractal arts are protected by
copyright, and thus commercial use of PixMix
remains questionable.
Moreover, both Fractal arts and FVis are enormously
costly to generate, and the number of images
that may be feasibly assembled into a dataset
is limited in practice.

All of these problems may be eliminated by using
formula-generated image datasets. Examples include
DeadLeaves and FractalDB, discussed in detail in Section 2.3.
However, data augmentation using the formula-generated images
of FractalDB____ and DeadLeaves (Squares)____
is known to be less effective than data augmentation
using Fractal arts and FVis.

Therefore, in the present study, we propose, investigate, and
evaluate the performance of a new strategy for
data augmentation using formula-generated images
that promises image identification accuracy and robustness
comparable to or greater than that of data augmentation
using Fractal arts and FVis.

% \figMoire
\input{figs/en-fig4}

\subsection{Formula-driven Supervised Learning (FDSL)}
\label{sec:FDSL}

In formula-driven supervised learning (FDSL),
a large image dataset consisting of formula-generated images
is used to pre-train a image recognition model.

Pre-training of image recognition models on large-scale image datasets
is known to yield significant improvements in image identification accuracy
for additional training____.
The pre-training with large-scale image datasets is typically chosen to be ImageNet, which contains over 14 million real-world images.

However, ImageNet and other large-scale image datasets collected on the Internet
cannot be used commercially, because the images they
contain are subject to copyright protections and
privacy concerns____.
The large amounts of time and manpower required to
generate annotations by hand, as well as the high cost of
assembling images into datasets, also render this approach impractical.
FDSL eliminates problems of usage rights
and of costly dataset construction____;
because the formula-generated image datasets constructed
and used in FDSL methods consist of copyright-free
images, they---unlike ImageNet---may be used to train deep learning
models intended for commercial use.

One proposed strategy for constructing
formula-generated image datasets is that
of the FractalDB, and image recognition
models pre-trained on FractalDB are known to yield improved
image recognition accuracy during additional training,
as is true for models pre-trained on ImageNet.
The formulas used to generate images in FractalDB
are based on fractal geometry, and
a wide variety of shapes and patterns may be drawn
by varying the adjustable parameters in these formulas.

As of 2024, the FDSL framework has been extended for representations (e.g., tiling____, contours____, Perlin noise____), modalities (e.g., video____, multi-view____, point cloud____), and tasks (e.g., segmentation____, limited pre-training____, 3D segmentation____). 

Here, the current FDSL dataset boasting the
greatest pre-training efficacy is VisualAtom____.
Images in VisualAtom, like images in FractalDB,
can be made to incorporate a wide variety
of shapes and patterns by varying adjustable parameters
in the image-generation formulas.
The formulas used to generate VisualAtom images
can also produce images featuring outlines of
complex and diverse shapes.
In PixMix-based approaches,
auxiliary images of greater structural complexity
are known to be more effective for data augmentation.
This explains why the formula-generated images
constituting FractalDB and VisualAtom have proven themselves useful in practice.

For these reasons, in discussing the results of tests to
evaluate the performance of the novel technique proposed
herein (Section~\ref{sec:evaluate}),  we will
contextualize this performance by comparing it
to the observed performance of data augmentation
using FractalDB (as reported in the original PixMix paper)
and to that of data augmentation using VisualAtom.