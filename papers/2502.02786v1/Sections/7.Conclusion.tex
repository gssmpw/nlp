\section{Concluding Remarks}\label{sec:conclusion}

This work introduces a novel BoP framework that accommodates model accuracy and explainability, both of which are paramount to building trust and transparency in sensitive settings. Additionally, the framework also extends the BoP analysis to regression tasks, enabling its application to new non-discretized scenarios. 
Through our theoretical analysis, we identified conditions for regression and classification where testing and estimation methods lack sufficient reliability to guarantee improvements across subgroups. Our findings also reveal that regression tasks have the potential to benefit from more personalized attributes than classification tasks, and that improved accuracy from personalization does not necessarily translate to enhanced explainability. Finally, and as exemplified by our evaluation, our framework and accompanying tests facilitate nuanced decisions regarding the use of protected attributes.
Overall, this paper broadens the scope and applicability of BoP analysis and in doing so contributes to the selection of more fair and interpretable models.




