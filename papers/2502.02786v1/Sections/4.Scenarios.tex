
\section{Impact of Personalization on Prediction And Explainability}

In this section, we highlight different scenarios that can arise when personalizing machine learning models.
First, we provide a comparison of how personalization impacts prediction and explainability. 




\textbf{Absence of Benefit in Prediction Does not Imply Absence of Benefit in Explainability.} The following theorem emphasizes the necessity of assessing the BoP in terms of both predictive accuracy (BoP-P) and explainability (BoP-X). 
\begin{theorem} \label{thm:Bop_to_BopX}
    There exists a data distribution $P_{\mathbf{X}, \mathbf{S}, Y}$ such that  the Bayes optimal classifiers $h_0$ and $h_p$ satisfy $\text{BoP-P}(h_0, h_p) = 0$ and $\text{BoP-X}(h_0, h_p) > 0$ 
\end{theorem}

Therefore, a personalized model may not have superior predictive performance yet still improve explainability. Or, in other words, evaluating personalized models solely on predictive accuracy risks can overlook substantial gains in interpretability. Figure \ref{fig:proof_fig} illustrates this with a simple example where personalization doesn't affect prediction accuracy, but it does improve explainability.



\textbf{Absence of Benefit in Explainability Can Imply Absence of Benefit in Prediction.} For a simple additive model, we can show that \emph{$\text{BoP-X}=0$ does imply $\text{BoP-P}=0$.} Note that, by $\text{BoP-X}=0$, we mean both sufficiency and comprehensiveness do not improve with personalization. Proving this for a general class of model remains an open question. 
\begin{theorem}\label{thm:BopX_to_Bop}
Assume that $h_0$ and $h_p$ are Bayes optimal classifiers and $P_{\mathbf{X}, \mathbf{S}, Y}$ follows an additive model, i.e., 
\begin{equation}
    Y = \alpha_1 X_1 + \cdots + \alpha_t X_t + \alpha_{t+1} S_1 + \cdots + \alpha_{t+k} S_k + \epsilon, 
\end{equation}
where $X_1, \cdots, X_t$ and $S_1, \cdots, S_k$ are independent, and $\epsilon$ is an independent random noise. Then, if $\text{BoP-X}(h_0, h_p) = 0$, then $\text{BoP-P}(h_0, h_p) = 0$. 
\end{theorem} 

This theorem demonstrates that under an additive model, if there is no benefit in explanation quality, then there is also no benefit in prediction accuracy. It establishes a direct link between explanation and prediction and underscores its importance in the simplified linear setting. Additionally, this means that if $\text{BoP-P}(h_0, h_p) \neq 0$, then $\text{BoP-X}(h_0, h_p) \neq 0$.





