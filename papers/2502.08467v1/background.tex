\section{Blind Cross-Site Scripting}\label{sec:setting}

\emph{Cross-Site Scripting} (XSS) is a notorious class of vulnerabilities, consistently earning a place in the OWASP Top 10 as one of the most critical web security risks~\cite{OWASPTop10-2013, OWASPTop10-2017, OWASPTop10-2021}.
These vulnerabilities are rooted in the representation of web content, which only loosely separates data from markup and enables an attacker to manipulate a website or even execute code through malicious inputs deliberately breaking this separation. Therefore, special care has to be taken when inserting user-controlled data into web content.

This problem of XSS is further exacerbated by the wealth of representations available for describing web content. For example, HTML documents can be interspersed with resources spanning various languages, such as Cascading Style Sheets (CSS), JavaScript code, Scalable Vector Graphics (SVG) and even mathematical expressions (MathML). As a result, XSS vulnerabilities can arise in any of these formats if user-controlled data is inserted without sanitization.

However, this \emph{mishmash} of languages also imposes requirements on any attack exploiting XSS vulnerabilities. As each language defines its own syntactic and semantic rules, an attack payload has to be tailored to the exact location where it is inserted in the document. In the following, we refer to this location as the \emph{injection context}.
Similarly, protection mechanisms need to be context aware to correctly assess what constitutes dangerous input for a specific injection context.
This makes it challenging to defend against XSS~\cite{WeinSaxAkh2011,SaxMolLiv2011}.

To illustrate the role of the injection context, let us consider the running example in \Cref{fig:xss-contexts}. 
The code snippet contains three lines, each highlighting a different injection context: inside of an HTML \code{a} tag \dcircle{1}, as a URI in the \code{src} attribute in the \code{iframe} element \dcircle{2}, and as a double-quoted string inside a JavaScript code context \dcircle{3}.
Input injected at each of these three points is processed by a different parser, namely the HTML, the URI and the JavaScript parser, respectively.
Consequently, each of these injection contexts and their many variations require substantially different attack payloads tailored for the syntactic and semantic rules of said parser and context.

In order to successfully achieve code execution within one of these injection contexts, one needs to craft a payload that either directly calls a JavaScript function or moves into a parsing state where this is possible.
Especially the URI case highlights how not only the current parser state, but also the directly preceding ones are relevant for success.
For example, the \code{src} attribute of the \code{iframe} at \dcircle{2} is directly exploitable with a JavaScript URI, unlike the \code{src} of an \code{img} tag.
Instead, we would have to move to a different parsing state first by trying to break out of the surrounding quotes.

\begin{figure}[htb]
\begin{minted}[escapeinside=||,breaklines,frame=lines,framesep=2mm]{HTML}
<a href="..."> |\dcircle{1}| </a>
<iframe src|=\htmlsquote{\dcircle{2}}|></iframe>
<script>if (x == |\htmldquote{\dcircle{3}}|) { ... }</script>
\end{minted}

\caption{Code segments depicting injections in three different contexts: In HTML \dcircle{1}, in a URI \dcircle{2}, and in JavaScript code \dcircle{3}.}\label{fig:xss-contexts}
\end{figure}

Therefore, to craft an XSS payload an attacker has to deduce the injection context first.
This is usually done by either manual testing, where the tester analyzes the website's code, or automatic payload generation in the presence of perfect information.
The latter, in particular, received a lot of attention from researchers applying \emph{taint tracking} techniques to uncover these vulnerabilities~\cite{LekStoJoh13, StoPfiKaiLek+15, MelDasShaBau+18, SteRosJohSto+19, KleBarBen+22}.
In short, these approaches use a modified browser to mark all data entered via user-controlled \emph{sources} as \emph{tainted}.
This taint information is then propagated through the browser until it enters a \emph{sink} functionality, which potentially results in code execution.%

While the detection of \emph{reflected XSS} vulnerabilities has been thoroughly studied, the \emph{server-side stored XSS} variant, \ie, when the payload is not directly executed and instead first stored on the server, is still a hard-to-detect XSS type~\cite{eriksson2021black}.
The main challenge with this variant is that it requires reasoning about \emph{intra-page dependencies}: The page where the payload is inserted to be subsequently stored somewhere, might only be indirectly related to the page where the exploit actually triggers after it is read from storage.
However, as long as these two sides are publicly accessible, a manual tester or automated system can still incrementally adjust the stored attack payloads to explore the server-side processing and finally derive a working exploit.

One particularly challenging variation of stored XSS is the so-called \emph{\blindxss{}} (BXSS) vulnerability, where even this context information is no longer available. %

\subsection{The BXSS Attack Scenario}
\begin{figure}[tb]
\centering
\subfloat[]{\label{fig:xss:stored}\includegraphics[width=0.45\linewidth]{stored-xss-2.pdf}}
\qquad
\subfloat[]{\label{fig:xss:blind}\includegraphics[width=0.45\linewidth]{blind-xss-2.pdf}}\vspace{-1.5mm}
\caption{Attack flows of \emph{stored XSS} (a) and \emph{\blindxss{}} (b) vulnerabilities. Only the stored XSS scenario allows the attacker to inspect the injection context to adapt their exploit.}\label{fig:xss}
\end{figure}

As part of the deployment of larger web applications, there are often further web-based backends involved beyond what is accessible for visitors from the Internet.
Typical use cases for such intranet web applications are administration, monitoring, visitor statistics, and back office tasks.
While these applications are usually protected by a firewall from direct outside attacks, they can still be susceptible to XSS attacks if malicious inputs reach these internal sites.
For example, a monitoring system might read web server access logs from the public part of the website and display all \emph{Referer} headers on an internal webpage, allowing insights into visitor behavior.
However, if these attacker-controlled header values are not properly sanitized, they could result in XSS on that internal page.
Due to their purpose, the consequences of successful attacks on these internal pages can be especially high, as these pages are only visited by privileged users and might allow administrative actions.
Moreover, these backend systems might not be part of the application's threat model and therefore might have received less security attention.

The main challenge in this scenario from the attacker's perspective is that they have no information where their payloads might end up, hence the name \blindxss{}.
Without any feedback that allows them to identify the injection context in the backend's markup, dedicated XSS payload creation through means such as taint tracking is impossible.
Even worse, only a successful attack provides information on the vulnerability and allows to exfiltrate information about the backend. All unsuccessful attack attempts provide \emph{no} information to an attacker who is totally in dark about in which context the malicious payloads is injected, whether it has been adapted, or if simply nobody visited the backend system to trigger it.

\Cref{fig:xss} further illustrates this crucial difference:
As \Cref{fig:xss:stored} shows, the attacker can access the vulnerable page, learn about the injection context and adapt their payload accordingly in the stored XSS case.
However, they have no way of inspecting the admin panel in the backend in the \blindxss{} case depicted in \Cref{fig:xss:blind}.
Due to these challenges and to the best of our knowledge, \blindxss{} has not yet been systematically studied and no automated approach to uncover these vulnerabilities exists, so far.

\vspace{-1em}\paragraph{Threat model.} We consider the following threat model:
The attacker interacts with a publicly accessible website that might or might not be indirectly connected to an internal website via a storage mechanism, such as a database, log file or internal web service.
The attacker has no knowledge about any internal webpages, the used storage technology, or data transformations steps in between. 
There is no feedback unless the attack is successful.
The attacker's goal is to achieve code execution via XSS in the context of an internal web application of the website's backend, once visited by a person with access or an automated system with a full browser.
All other payload entry points besides publicly accessible websites, such as phishing emails, are out of scope for this work.

\subsection{XSS Polyglots}\label{sec:polyglots-background}
Ideally, we would overcome this challenge of not having a feedback by creating a \emph{universal XSS payload that triggers in all contexts}.
As previously described, we need to consider several different parsers for this, as our payload could end up inside any of them.
A construct that is valid input in multiple formats and/or languages is a so-called \emph{polyglot}~\cite{magazinius2013polyglots}.
For example, GIFAR is a technique to create a file that is both a valid GIF image and a valid Java Archive (JAR)~\cite{brandis2009exploring}.

In the context of this paper, \emph{polyglot} refers to an XSS exploit that is able to execute in multiple injection contexts, such as HTML and JavaScript code.
Moreover, \emph{payload} refers to the part of the exploit that is actually executed, \eg, \code{alert()} or \code{import()}.
Coming back to our example in \Cref{fig:xss-contexts} and assuming we want to execute the payload \code{alert()} for demonstration, the three different injection contexts require different conditions for the payload to be executed.

For the HTML context inside the anchor tag in injection \dcircle{1}, we first need to close that tag and then need to insert an element that executes code, \eg, like this: \code{</a><script>alert()</script>}.\footnote{The dangling \code{</a>} will be ignored by the browser.}
On the other hand, the second injection context expects a URL \dcircle{2}.
While we could try to break out of the surrounding quotation marks, this might not be possible due to sanitization.
One solution is to instead use a JavaScript URI, \eg, by supplying \code{javascript:alert()}.
Finally, the injection context in JS code \dcircle{3} requires us to break out of the quotes and close all expected parentheses to make sure that the code does not break, \eg, \code{")\{\}alert();//}.
The two trailing slashes are important to comment out the rest of the line to avoid a syntax error.

For this simple example, we can still come up with a polyglot by carefully combining all three exploits by hand: \code{javascript:alert()//")\allowbreak\{\}alert();//\allowbreak</a>\allowbreak<script>alert()</script>}. %
For case \dcircle{1}, this just puts a lot of ``garbage text'' into the anchor text before closing the tag and executing the script.
For case \dcircle{2}, this is interpreted as a URI with valid JavaScript code and a long trailing comment.
Finally, for injection \dcircle{3}, this puts the URI in the string, closes the \code{if}-branch and executes our payload, while ignoring the rest due to the second \code{//} comment.

However, this polyglot just covers three contexts and there are a lot of variations where it would not work properly.
For example, injection \dcircle{1} could also happen in the \code{href} attribute, with either single or double quotes, or might be inserted via \code{innerHTML} where the script tags do not execute but event handlers do~\cite{whatwg-html-parsing-flags}.
As another example, \dcircle{3} would result in a syntax error when the code has an \code{else} branch, as our inserted \code{alert} would break the \code{if-else} construct.
Covering \emph{all these common variations of all contexts} results in an explosion of possible combinations, making manual polyglot construction extremely tedious, if not impossible.

\begin{figure}[htb]
\begin{minted}[escapeinside=||,breaklines,frame=lines,framesep=2mm]{JavaScript}
//Read from a stored object without injection into the source
document.location = someObj.redirectLocation;
//Directly injected into the source code of a .js file
var foo = |\dcircle{4}|;
\end{minted}

\caption{Two injection contexts that are mutually exclusive, \ie, can not be solved by the same XSS polyglot.}\label{fig:mutually-exclusive}
\end{figure}

As an additional complication, some injection contexts are \emph{mutually exclusive}.
\Cref{fig:mutually-exclusive} shows one example of such a case: The first injection context is only possible to solve by exploits starting with \code{javascript:} as such a JavaScript URI does not trigger an actual navigation, but instead executes the subsequent code in the context of the current document.
Starting with anything else will either fail, as escaping from the statement is impossible without a direct reflection into the source code, or cause a navigation away from the website that was the target of the attack.
On the other hand, there are also injection contexts that do not allow \code{javascript:} at the very beginning, \eg, the injection context in \Cref{fig:mutually-exclusive} at position \dcircle{4}, as the colon produces a syntax error on the right side of the variable assignment.
Illustrated by these two examples, mutually exclusive injection contexts thwart efforts to construct \emph{one} universal XSS polyglot.
On the other hand, full coverage could be achieved with one payload per context.
However, we aim at creating a small \emph{set of polyglots} while still covering the entire state-of-the-art testbed.
From a tester's perspective, this results in less required tests and less system log noise.
From a researcher's view, it means less submissions and thus less noise and reduced load for systems-under-test.



\subsection{Research Questions}\label{sec:rqs}

Constructing a set of powerful polyglots is key to the analysis of \blindxss{}, as it makes it possible to successfully trigger vulnerabilities without feedback. While previous work has focused on manually engineering polyglots \cite{ultimate-polyglot, szurek-polyglot, ostorlab-polyglot}, we argue that an automated process is inevitable here to handle the amount of injection contexts. This leads us to the following research questions that structure our work:
\begin{questions}
\setlength\itemsep{-0.3em} %
	\item Is it possible to automatically create a set of XSS polyglots that are capable of covering all common injection contexts in combination?\label{rq:1}
	\item Do these synthesized polyglots scale up to real-world settings and how do they compare with existing XSS detection approaches?\label{rq:2}
	\item Can these polyglots be employed to perform a large-scale analysis of \blindxss{} and indicate vulnerabilities in web application backends?\label{rq:3}
\end{questions}

To address these research questions, we conduct a series of experiments:
In \Cref{sec:generation}, we introduce a method for synthesizing polyglots using concepts from game theory~(\ref{rq:1}).
In \Cref{sec:taint-validation}, we assess the real-world performance of these polyglots, comparing them to traditional approaches~(\ref{rq:2}).
Finally, in \Cref{sec:bxss-study}, we perform a large-scale study to detect BXSS vulnerabilities in the wild~(\ref{rq:3}).

