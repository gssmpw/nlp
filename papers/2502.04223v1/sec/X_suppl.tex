\clearpage
\setcounter{page}{1}
\maketitlesupplementary

\usepackage{todonotes}

\begin{document}

%\section{Rationale}
%\label{sec:rationale}
% 
%Having the supplementary compiled together with the main paper means that:
% 
%\begin{itemize}
%\item The supplementary can back-reference sections of the main paper, for example, we can refer to \cref{sec:intro};
%\item The main paper can forward reference sub-sections within the supplementary explicitly (e.g. referring to a particular experiment); 
%\item When submitted to arXiv, the supplementary will already included at the end of the paper.
%\end{itemize}
% 
%To split the supplementary pages from the main paper, you can use \href{https://support.apple.com/en-ca/guide/preview/prvw11793/mac#:~:text=Delete%20a%20page%20from%20a,or%20choose%20Edit%20%3E%20Delete).}{Preview (on macOS)}, \href{https://www.adobe.com/acrobat/how-to/delete-pages-from-pdf.html#:~:text=Choose%20%E2%80%9CTools%E2%80%9D%20%3E%20%E2%80%9COrganize,or%20pages%20from%20the%20file.}{Adobe Acrobat} (on all OSs), as well as \href{https://superuser.com/questions/517986/is-it-possible-to-delete-some-pages-of-a-pdf-document}{command line tools}.
sa
\todo[inline]{Add some information about reading order heuristics for DocLayNet, table autolabeling for plain datasets and steps to obtain the GitHUb Readme dataset in supplementary material}

\section{Examples of predictions}

\IK{shall we show 4-5 almost full-page predictions from Lukas' visualisation tool?}

\section{Training Details}


\subsection{Hallucinations}

It is a common observation \cite{something} that generative models may hallucinate content, and there have been various attempts to reduce the likelihood of hallucinations by introducing grounding \cite{something} methods. Some document-level OCR models such as Nougat \cite{Nougat} detect hallucinations by tracking a moving average of logits and flagging the outputs when a certain threshold is reached. However, such an approach may not be suitable if the model predicts hallucinations with high certainty. 

\eclair introduces a hallucination mitigation strategy characterized using three components: (i) the inference-time prompt is always the Maximal Informative Prompt (MIP), enforcing a strict syntax which would reject non-compliant boxes, (ii) the syntax is semantically grounded to the visual document structure rather than being a generic delimiter such as \verb|<bbox></bbox>| tags, \KC{I am not sure I understand the second point...}(iii) the spatial and categorical validity is enforced by verifying that the bottom-right corner of each bounding box exceeds the top-left corner and that classes conform to a validated schema. This approach allows \eclair to effectively filter out invalid boxes while preserving accurate ones, thereby ensuring comprehensive and reliable page predictions. By implementing this layered filtering strategy, we achieve substantial reduction in model hallucinations.

\PF{Here we say how we can filter boxes, but we are not saying how much it helps. I think it's crucial to say that we can prevent a lot of hallucinations and give some evidence.
\KS {I updated paragraph above but giving evidence of statistics might be hard, considering its property of layout and foreign language and then you need to define how much of page it extracted ? wdyt}} \KC{maybe can say: While quantifying the effect of hallucinations is challenging, by implementing this layered filtering strategy, we qualitatively observe a substantial reduction in model hallucinations.} 

\section{pre-processing steps for the training datasets }
\section{Joining Pages}

\section{mAP - Back to Simple Metrics}
\label{sec:map}

The problem \TR{challenge} with our proposed end-to-end detector is, that we do not provide a score for a detection box. One could think about using the likelihood/logits of the first coordinate tokens, but these are more likely a distribution over the next possible starting points, even if calibrated, thus not useful as an independent/unordered probability. The other possibility could be the class token logits, but those will only give a distribution over the choice of classes, not really giving a probability of the box existing at all. The last option could be to consider the text tokens, but then again, these are more a representation of actual text being read, and not representing the existence of the box around. Consequently, for our predictor, there is no box score. Still, for comparing against other works, which use the mAP for this comparison, it is problematic: The first problem lies in the nature of (m)AP: AP is the area under the PR curve, which is degenerated for the case where there is no score (or using score=1 for all predictions), it'll just be a single point (thus can be reduced to \(\text{AP} = \text{precision} (@\text{recall}=1)\)). The second issue lies in the usage of the COCO implementation, which sorts the predictions by score and based on that computes the PR curve, assuming that scores are never exactly identical. If all scores are the same (which is the case for our end-to-end detector), the computed curve will depend on the order of predictions, as coco will traverse on the PR curve prediction-by-prediction, thus it does not produce the correct PR curve and will even give different results for different ordering \footnote{See also submitted bug report \url{https://github.com/MiXaiLL76/faster_coco_eval/issues/46} and \url{https://github.com/cocodataset/cocoapi/issues/678}}. Next, the nature of the PR-Curve is meant to be able to set a score, such that predictions can be filtered to achieve the precision/recall represented on that curve. Since we predict boxes as part of the output token stream, we would not want to discard boxes in general, so we do not have a value which would discard a box. Lastly, the COCO mAP is computed per class, i.e. each class is considered independently. Instead, we find it more useful to first match the boxes and then compute the class correctness. This effectively makes the matching harder, because competing boxes are considered across classes instead of within a class. On the other hand, this does provides more detailed information on the error cases if plotting a confusion matrix. Thus, we propose computing the mean precision/recall directly and also plotting a confusion matrix (based on a fixed score for other work), better visualizing the problematic cases. The precision/recall and confusion matrix may still be averaged over multiple IoUs (between 0.5 and 0.95) like the COCO framework in order to factor out the threshold. An implementation is provided in the appendix.

% Lukas TODO: Reference the PR-Curve

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{images/PR_Curve_catall_iou0.5to0.95_areaall_maxDet100.pdf}
    \caption{{\todo[inline]{Update the graphics and reduce space}} Precision recall graph based on COCO-mAP computations and smoothing, with 1000 steps (as opposed to the default 100 steps) for recall, showing the respective levels for the precision and recall of \eclair. Computing the COCO-mAP for SwinDocSegmenter, we get $\text{mAP}=75.4$, $\text{mAR}=84.1$; It can be argued, that \eclair is surpassing SwinDocSegmenter by a large margin. \KC{potentially can just report numbers in a table and move curves to supplementary}}
    \label{fig:eclair_doclaynet_pr_fig}
\end{figure*}


\section{LLM Training}

\subsection{misc}
% KC: just putting here stuff that we promised to mention in supplementary in order not to forget. will need to rearrange to appropriate sections.

talk about multi-token inference measurement. 

Following the observation in \cite{hu2024mplugdocowl15unifiedstructure} that text is more correlated within a line rather than across lines, we compress the sequence with a horizontal convolutional kernel of size $2\times 8$ and stride $8$. Given an input image of size $1280\times 1024$ which produces $80\times 64$ patches, the sequence length is reduced from $5120$ to $1280$

We used seq length 3.4K
\end{document}
