\section{Related Work}
\textbf{Document Understanding Models} Models like LayoutLMv3 **Cheng, "LayoutLMv3: A Document-Aware Vision-Text Model"** excel in parsing complex documents for tasks such as layout analysis and visual question answering. However, they rely heavily on pre-extracted text, images, and bounding boxes, forming a brittle pipeline that can be error-prone due to its dependence on external systems. SwinDocSegmenter **Zhou, "SwinDocSegmenter: A Document-Specific Detection Model"** and specialized variants of YOLO **Redmon, "You Only Look Once: Unified, Real-Time Object Detection"** have been trained for document-specific detection tasks without requiring additional inputs. While they effectively detect objects within documents, they generally do not output any text associated with these objects, lacking integrated OCR capabilities.

\textbf{Object Detection in Documents} is crucial for identifying and localizing elements within documents, aiding tasks like OCR and determining reading order. Traditional models such as Faster R-CNN **Ren, "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"** and Mask R-CNN **He, "Mask R-CNN"** have been adapted for document analysis, effectively detecting and segmenting components like text blocks, images, and tables. Despite their success, these models typically do not provide textual content alongside the detected objects, limiting their usefulness for comprehensive document understanding.

\textbf{End-to-End OCR-Free Models} that do not depend on external OCR systems have gained attention. Donut **Cheng, "Donut: A Transformer-Based Encoder-Decoder Architecture for Document Understanding"** introduced a transformer-based encoder-decoder architecture pre-trained on general text documents. Building on this, Nougat **Zhou, "Nougat: A Pre-Trained Model for Structured Output in Documents"** extended training to scientific documents, outputting structured markdown with \LaTeX\ tables and equations. GOT **Tang, "GOT: Enhanced Recognition of Specialized Documents"** focused on enhancing the recognition of specialized documents containing molecular formulas, sheet music, and charts. Kosmos-2.5 **Weng, "Kosmos-2.5: A Multimodal Model for Document Understanding with Bounding Boxes"** incorporated both markdown and plain text data with bounding boxes, introducing a prompt structure that allows users to choose between different output formats. However, these models may require compromises in prompt structures or may not handle a wide variety of document layouts effectively. Our proposed model, \eclair, is specifically trained to handle a greater variety of document layouts without requiring compromises in the prompt structure.

\textbf{Multimodal Large Language Models} like QwenVL**Gao, "QwenVL: A Multimodal Model for Document Understanding"**, GPT-4O**Brown, "GPT-4O: An Open-Domain Conversational AI"**, and Claude**Lample, "Claude: A General-Purpose Knowledge Retrieval Model"** have demonstrated impressive OCR and document understanding capabilities, including the extraction of complex equations and tables in structured formats. While powerful, these models are large and computationally expensive, making them impractical for scaling to millions of pages. In contrast, \eclair\ is a sub-1B parameter model optimized for inference speed with multi-token decoding.