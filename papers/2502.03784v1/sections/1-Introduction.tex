\section{Introduction}
Data-rich documents, which use text descriptions to convey data insights, are prevalent in various applications, such as scientific papers~\cite{beck2017wordsized} and news articles~\cite{lin2018vizbywiki}.
Although researchers have long promoted using visualizations to convey data insights~\cite{washburne1927experimental, costigan-eaves1986edward}, authoring data-rich documents, especially pairing them with visualization, is time-consuming and requires extensive expertise~\cite{chen2022crossdata}. Such difficulty dictates that visualizations rarely exist in most data-rich documents.

Prior research proposed two directions to provide visualization for data-rich documents. One line of research proposed resorting to outside data sources to retrieve visualizations (e.g., \cite{lin2018vizbywiki, metoyer2018Coupling}) related to the text context. Although retrieved visualizations present relevant information to the text, the visualizations might not precisely match the text narrations. Others used the internal information within data-rich documents (such as tables and numbers) to generate visualizations~\cite{masson2023Charagraph, badam2019elastic, cui2020texttoviz}. Although using internal data sources ensures the visualization is pertinent to the document, most approaches use ``hard rules'' such as regular expressions to extract numerical data, ignoring the contextual data insights embedded within or between sentences.

Broadly, prior works have predominantly applied a visualization-centric approach~\cite{goffin2020Interaction} to augment existing data-rich documents. In a visualization-centric approach, visualizations are treated as independent constituents equal to or more important than the source document. In contrast, few works have explored an automatic method to generate visualizations for document-centric analysis of data-rich documents, where visualization only provides assistive contextual information to the original document. Motivated by this gap, we raised our research question: \textbf{Could we design an automatic method to generate visualizations from data-rich documents to support document-centric analysis?}

Because we aimed to support document-centric analysis, we first determined an appropriate style for the visualizations. We chose word-scale visualizations, a type of small, text-sized visualizations used to convey data insights in situ close to description~\cite{goffin2014exploring}. The small size of word-scale visualizations determined that they can seamlessly integrate into the existing format of data-rich documents, incurring minimal changes to a typical reading practice for data-rich documents. Moreover, prior works provided useful guidelines for the design, placement, and interaction of word-scale visualizations~\cite{goffin2015exploring, goffin2017Exploratory, goffin2020Interaction}, which we used to inform our design (Fig.~\ref{fig:teaser}).

In this study, we propose \textbf{\textit{GistVis}}, a framework for automatically generating word-scale visualizations from data-rich documents. We based our design on the formative findings regarding the narrative features of data-rich documents (Sec.~\ref{sec:formative-study}). Then, we designed GistVis as a proof-of-concept framework to which we applied several constraints to simplify the nuances in narrative features among data-rich documents. To provide flexibility for future expansion (Sec.~\ref{sec:gistvis-method}), we split the transformation process from text to visualization into four independent steps: Discoverer, Annotator, Extractor, and Visualizer (Fig.~\ref{fig:algorithm-pipeline}). For the first three processing stages, we utilized the capabilities of large language models (LLMs) through prompt chaining~\cite{wu2022ai} and injected visualization knowledge~\cite{wang2020datashot, amar2005lowlevel, chen2009effective} to steer LLMs to generate \textit{data fact specification}, an intermediate data representation to encode data insights in text documents. We applied a visualization design knowledge-driven approach in stage four to ensure predictability in the generated visualizations.

To assess the performance of GistVis, we conducted a comprehensive evaluation involving both a technical evaluation of the Discoverer and Annotator modules (Sec.~\ref{sec:technical-eval}) and a user study with 12 participants (Sec.~\ref{sec:eval-user-study}). Our technical evaluation revealed decent performance in both segmenting data insights and inferring the type of data insights. Meanwhile, users perceived the visualization generated by GistVis as usefulâ€”results showed a decrease in workload reading with GistVis compared to a Plain Text condition.

In summary, our main contributions are as follows:
\begin{itemize}%[leftmargin=18pt, itemsep=0pt, parsep=0pt, partopsep=0pt]
    \item We conducted a formative study where we collected a corpus of data-rich documents and investigated the narrative patterns of data-rich documents.
    \item We proposed GistVis\footnote{We document our implementation at \url{https://github.com/Motion115/GistVis}}, a framework driven by LLM and visualization knowledge for automatically generating word-scale visualizations from data-rich documents. %
    \item We demonstrated the utility of GistVis via a technical evaluation and a user study with 12 participants using real-world data-rich documents. Results indicated that GistVis could generate satisfactory and effective word-scale visualizations to support document-centric analysis of data-rich documents.
\end{itemize}
