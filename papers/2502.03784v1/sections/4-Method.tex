\section{GistVis}
\label{sec:gistvis-method}
The following sections describe the design of GistVis. We first define the uniform data representation schema \textit{data fact} (\textbf{DG1}, Sec.~\ref{sec:gistvis-gistfact}). Then, we provide a detailed description of the purpose of each module in the GistVis computational pipeline, how it could support plug-and-play property (\textbf{DG2}, Sec.~\ref{sec:computational-pipeline}), and the design choices of our word-scale visualizations (\textbf{DG3}). Lastly, we introduce the implementation details of the current iteration of GistVis (Sec.~\ref{sec:implementation-detail}).

\subsection{Data Fact}
\label{sec:gistvis-gistfact}

We define \textit{data fact} as the uniform data structure to encode all text content, either with or without data insights. Under this definition, we characterize \textit{data fact} as a declarative intermediate data structure that encapsulates all the key information required to generate word-scale visualizations. We formulate \textit{data fact} as a 2-tuple:
\begin{equation}
\mathTextItalics{fact}\, \coloneq \left \{ \mathTextItalics{unitSegmentSpec, dataSpec?} \right \} \nonumber
\end{equation}
where \textit{unitSegmentSpec} records key information related to the \textbf{unit segment}. Meanwhile, \textit{dataSpec} is a list that contains the data restored from the information provided by the unit segment. Because not all unit segments contain data insights, \textit{dataSpec} is an optional attribute in the tuple and could be used to distinguish between plain text segments and data insight segments. For clarity, we use the \textit{Typescript} notation (question mark) to represent optional elements. In the following, we explain the design of \textbf{unit segment specification} (\textit{unitSegmentSpec}) and \textbf{data specification} (\textit{dataSpec}).

\subsubsection{Unit Segment Specification}
\label{sec:gistvis-unitSegmentSpec}
We define unit segment specification as a 4-tuple:
\begin{equation}
    \mathTextItalics{unitSegmentSpec}\, \coloneq \left \{
        \mathTextItalics{type, context, attribute?, position?}
    \right \} \nonumber
\end{equation}

\paragraph{Type}
Type contains seven candidate types, including the six data insight types (i.e., value, proportion, comparison, trend, rank, and extreme) we selected from the facts taxonomy (see Sec.~\ref{sec:formative-study}), and one ``no type'' to represent plain text. 

\paragraph{Context}
Content is where we store the original text snippets that are unit segments. In this work, we define a unit segment as one or multiple sentences that collectively convey one data insight or are similar in semantics. We implement this definition to support situations where data insights span multiple adjacent sentences.

However, it is worth noting that we defined unit segments based on a strong assumption that relevant information of one data insight is described in sequential order, proximate in position, and contained within the same paragraph. Cases might exist where the same data insight could occur in numerous places across the document~\cite{goffin2020Interaction}. We argue that word-scale visualizations designed for document-centric analysis might not be the optimal solution to convey such information. Thus, we only focus on performing paragraph-level segmentation.

\smallskip
The above two entries (\textit{Type}, \textit{Context}) record contextual information directly related to the text and are ubiquitous for all unit segments. Meanwhile, \textit{Attribute} and \textit{Position} are data-related auxiliary information of the text and relevant to specific \textit{Types}. Referencing the four-level model of the semantic content of visualization proposed by \citet{lundgard2022accessible}, we viewed \textit{Attribute} and \textit{Position} to represent L2 - L3 (statistical concepts and relations, perceptual and cognitive phenomena) information and L1 (elemental and encoded properties) information respectively. Because \textit{Attribute} and \textit{Position} convey key semantic insight about the data and are closely related to text descriptions, we leave those attributes in the unit segment specification.

\paragraph{Attribute}
Attribute is an optional entry explicitly designed for data types extreme and trend. The candidate options for attributes include ``increasing'' and ``decreasing'' for the trend type and ``maximum'' and ``minimum'' for the extreme type. The attribute information is a supplementary constraint in the visualization generation process to correct potential errors in the generated visualizations and reflect the semantics of the text description.

\paragraph{Position}
The position is an optional entry to handle the extreme data fact type. It represents the original text description that should be highlighted to provide contextual information about the maximum or minimum values. For example, if we want to augment "\textit{the maximum of sales for company A,}" it is more informative to label the entire phrase rather than just "company A" (the standard highlight practice for other data fact types). If position is available in the extreme data fact type, the position attribute would override the default practice and ensure the entire phrase is highlighted.

\subsubsection{Data Specification}
\label{sec:gistvis-dataspec}
While Unit Segment Specification characterizes the textual content and higher-level data insights, data specification represents the raw data elements reconstructed from the textual content. Data Specification is designed to be an analogy of tabular datasets (Fig.~\ref{fig:dataspec-tableview}), which we define in a four-tuple:
\begin{equation}
    \mathTextItalics{dataSpec}\, \coloneq \left \{ 
        \mathTextItalics{space, breakdown, feature, value}
    \right \}[] \nonumber
\end{equation}

Specifically, \textbf{space} is a facet of analysis with a given text description. For example, if a sentence describes the market share of different car manufacturers, the analysis space would be ``car manufacture'' (Fig.~\ref{fig:dataspec-tableview} \ding{182}). Meanwhile, \textbf{breakdown} is a set of temporal or categorical data fields in which data are further divided under the space. For example, the brand name, like ``Brand A'' (Fig.~\ref{fig:dataspec-tableview} \ding{183}), would be the breakdown for ``car manufacture''. \textbf{Feature} is the measurement of breakdown. For example, we could measure the sales percentage for each manufacturer (Fig.~\ref{fig:dataspec-tableview} \ding{184}), a feature derived from annual sales of car manufacturers. Lastly, \textbf{value} is a numerical data field that could be retrieved from a combination of breakdown and feature. For example, the ``sales percentage'' of ``Brand A'' is 0.5 (Fig.~\ref{fig:dataspec-tableview} \ding{185}). All data attributes are required for each data specification entry, with the only exception being the ``not a number'' (NaN) value attributes. Cases exist when the unit segment describes a semantic data insight (e.g., increasing or decreasing for the trend type), and we make ``not a number cases'' a special condition for GistVis to process.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\linewidth]{figures/GistFact-Definition.pdf}
  \caption{Each element in data specification consists a four-tuple, space \ding{182}, breakdown \ding{183}, feature \ding{184} and value \ding{185}.}
  \label{fig:dataspec-tableview}
\end{figure}

In the following section, we describe how the fields in the data fact specification are filled using the GistVis pipeline.

\subsection{Computational Pipeline}
\label{sec:computational-pipeline}
Based on the data requirement of data fact, we proposed the GistVis pipeline to automatically transform data-rich text descriptions to word-scale visualizations. We utilized both LLM-based and design knowledge-driven approaches to achieve word-scale visualization generation. Specifically, we decomposed the generation process into four stages: gist discovery, fact type annotation, fact specification extraction, and fact visualization. We capitalized on LLMs' natural language understanding capability for the first three stages and applied the prompt chaining strategy~\cite{wu2022ai} to transform natural language descriptions into data facts. Meanwhile, the fact visualization stage uses a simple heuristic-driven approach to map data facts to interactive visualization components. As an automated process, all prompts and visualization heuristic rules are readily coded into the pipeline (see Supplementary Material for detailed prompt design). Fig.~\ref{fig:algorithm-pipeline} shows the GistVis computational pipeline, which consists of four modules respective to the four stages above: Discoverer (\textbf{M1}), Annotator (\textbf{M2}), Extractor (\textbf{M3}) and Visualizer \textbf{(M4)}.

\begin{figure*}
    \includegraphics[width=1\textwidth]{figures/GistVis-Pipeline.pdf}
    \caption{The GistVis pipeline consists of four modules: Discoverer (\textbf{M1}), Annotator (\textbf{M2}), Extractor (\textbf{M3}), and Visualizer (\textbf{M4}). Data flows through the four modules sequentially, where a large language model captures the insight of the data-rich document (\textbf{M1-M3}). Visualizer (\textbf{M4}) maps the captured insight into interactive visualizations, populated in situ in the text document at word scale.}
    \label{fig:algorithm-pipeline}
\end{figure*}

\subsubsection{Discoverer}
The first step in the GistVis pipeline is to divide paragraphs into unit segments. Discoverer (Fig.~\ref{fig:algorithm-pipeline}.~\textbf{M1}) leverages the zero-shot capability of LLMs~\cite{brown2020language} to perform the segmentation process. We restrain LLMs from identifying the shortest unit segment possible to better pair the text descriptions with in situ word scale visualizations. The prompt contains the six fact types to provide LLMs with more detailed segmentation requirements. Meanwhile, although LLMs are informed of the data fact types in the instructions, we do not label the data fact type at this stage to keep the task simple.
Moreover, the segmentation process shortens the context length, filtering out excess information for the subsequent data fact type labeling step. Additionally, to reduce hallucinations from LLMs during the segmentation process, we instruct the LLM to keep the text description ``as is'' without modifying the original text description or punctuation.

\subsubsection{Annotator}
The Annotator module (Fig.~\ref{fig:algorithm-pipeline}.~\textbf{M2}) aims to fill in the \textit{Type} field in the data fact specification for each segment from the prior module. Since LLMs are well calibrated to answer multiple choice and true/false questions~\cite{kadavath2022language}, we formulate the data fact type annotation as a two-stage question-answering (QA) problem. In the first stage, we ask LLMs to make a true/false judgment on whether the given segment belongs to a specific data fact type (\textbf{Type Checker}). Then, since one segment can be classified into multiple data fact types, we perform another round of prompting (\textbf{Type Moderator}) in a multiple-choice format to determine the most appropriate data fact type for each segment.

\paragraph{Type checker}
Type Checker identifies all possible fact types for each segment. To incorporate visualization knowledge into LLMs, we applied the few-shot in-context learning prompting paradigm~\cite{brown2020language}. We constructed seven individual reasoners for each of the seven fact types. Specifically, following a task description informing LLMs to return whether or not the segment can be classified as a given fact type, we define the fact type followed by three examples (two positive, one negative), allowing the LLMs to capture the definition of data fact type and forming a 3-shot prompt. After running through all seven reasoners, we record all the possible data fact types in a list for further moderation. If all reasoners responded false, the segment would be labeled a text-only segment (i.e., no type) and not proceed for further analysis.


\paragraph{Type moderator}
Taking the output from the Type Checker, the Type Moderator determines the most suitable data fact type for a given segment. We formulate the prompt in a multiple-choice pattern, with the options drawn from the previous type-checking step. Due to the varying number of possible candidates, we do not include examples and only reiterate the definition for the candidates. After the moderation step, we narrow the data fact label to only one label and fill the type field in the data fact specification in preparation for the data extraction phase.

We annotated data fact types in two instead of one round for the following reasons. First, we limit the input length and avoid excessive length prompts that could potentially harm inference capability~\cite{li2024longcontext}. Splitting the annotation task into two rounds would save space—we avoided all the samples for each data type occurring in the same prompt. Secondly, we consider the extensibility of the GistVis pipeline. Splitting the process into two stages would ensure that adding custom data fact types requires no more than writing additional prompts for the new data fact type. We also justified this design decision with an ablation study in our technical evaluation (Sec.~\ref{subsec:quant-eval-annotator}).

\subsubsection{Extractor}
Since each data fact type has different requirements, the Extractor module (Fig.~\ref{fig:algorithm-pipeline}.~\textbf{M3}) applies a case-by-case extraction strategy based on the data fact type generated from the Annotator module when extracting the data specifications. We formulate the prompts based on the visualization specification requirement described in Sec.~\ref{sec:gistvis-dataspec}.

Compared with the methods that applied regular expression to identify numbers in a text description, LLMs allow more flexibility in how the data is presented. For example, when numbers are not expressed numerically (e.g., 10 thousand, ten thousand), regular expressions would fail in extracting the correct underlying data. Instead, we prompt LLMs to convert non-numerical expressions of numbers to their numerical form (i.e., 10000), thus expanding data extraction capability. We also use a number parser to further transform all extracted data into a numerical form.


\subsubsection{Visualizer}

\begin{figure*}[tb]
  \centering
  \includegraphics[width=\linewidth]{figures/design-space.pdf}
  \caption{A collection of 14 candidate visualizations and the corresponding chart type for each data fact type. The \textbf{Example} column shows the effect of the appearance of word-scale visualization in data-rich documents. We present the examples when the mouse hovers over the word-scale visualization of focus.}
  \label{fig:visualization-design}
\end{figure*}

Visualizer (Fig.~\ref{fig:algorithm-pipeline}.~\textbf{M4}) applies a chart-based approach (as opposed to the grammar of graphics~\cite{wilkinson2012grammar} approach) in visualizing data facts. We took the chart-based approach based on the observation that various business visualization toolkits~\cite{g2plot-2024, echarts-2024} use this paradigm. 

\paragraph{Visualization Design}
We implement three basic chart types (bar chart, line chart, and icon array) and use their variants with relevant icons to tailor to the needs of different data fact types. The variants of the three chart types and icons constructed a design space including 14 candidate visualizations to represent different conditions of data insights (Fig.~\ref{fig:visualization-design}). Notably, we use horizontal stacked Bar Charts to represent proportion. Although prior works have applied Pie Charts (e.g.,~\cite{goffin2017Exploratory, huth2024eye}), we argue that the limited height could make discerning the angle difference between categories difficult. Thus, in this work, we attempt to capitalize on the relatively ample space on the horizontal dimension and use length, a more effective visual channel than angle~\cite{munzner2014visualization}, to encode proportional data. We also made several hard constraints to facilitate the readability of word-scale visualizations. For example, we limit the maximum rank for visualization to 10, avoiding situations of ultra-long vertical bar charts if the value of the ranking is large. We made this decision based on the fact that only one in 35 rank insights we identified in our corpus (Sec.~\ref{sec:formative-study}) included a rank above 10. Moreover, the definition of the rank fact type implied a sorting process on the dataset such that the rank is relative, leading to the inclination of reporting ranking with single-digit numbers. Meanwhile, to avoid situations such as rank overflow, we also designed a fallback condition, presenting a question mark icon to indicate the unit segments that might contain data insights not properly presented by GistVis. We expect that users could better perform analytical activities~\cite{amar2005lowlevel} with data-rich documents through the locally aggregated views of data in the form of word-scale visualizations.

\input{tabs/factDef-new}

\paragraph{Linking Word-scale Visualizations with Text}
We also added interactive features to word-scale visualizations. The motivation behind making word-scale visualizations interactive is twofold: 1) to pack more information in word-scale visualizations, and 2) to enhance the reading experience by coupling visualization with text (Sec.~\ref{subsec:relatedwork-vistext}). 

Firstly, to pack more information within word-scale visualizations, we designed a drill-down interaction that pops up a tooltip every time users hover over the visualization. The tooltip contains basic data descriptions about the word-scale visualization, allowing users to grasp key information even when viewing the visualization standalone. We define a set of default syntax to describe the data insights for each data fact type according to the value types in the data fact specification (Table.~\ref{tab:gistvis-implementation}). Crucially, users access the tooltips on demand, minimizing their impact in obstructing a normal document reading process.


Secondly, to enhance the reading experience, we designed bidirectional interactions between text and word-scale visualizations. Specifically,
we highlight the ``entities'' of a sentence via matching document text with the set of extracted breakdowns in the data fact specification. When a specific visual element is selected, the corresponding entity synchronously lights up to show the correspondence between the entity and its value. Conversely, when a specific entity is selected, the corresponding visual element in the word-scale visualization would also light up to help users retrieve the entity related to the value (see Fig.~\ref{fig:visualization-design} Example column).

\subsection{Implementation}
\label{sec:implementation-detail}
We implement the GistVis pipeline using a typical web stack. For rendering the data-rich document augmented by GistVis, we use open-source libraries, including React\footnote{\url{https://react.dev/}} as the UI framework and D3.js~\cite{bostock2011datadriven} for rendering the word-scale visualizations in svg format. We took inspiration from prior jQuery-based word-scale visualization packages such as Sparklificator~\cite{sparklificator-package} and Piety~\cite{piety-package} and expanded their functionality using the React framework.

As for LLMs, we chose \texttt{DeepSeek-V2.5}~\cite{deepseek-ai2024deepseekv2}, an open-source\footnote{\url{https://huggingface.co/deepseek-ai/DeepSeek-V2.5}} Mixture-of-Experts (MoE) language model released by \texttt{DeepSeek}\footnote{\url{https://www.deepseek.com/en}}. We made this decision based on its decent performance at a low cost (overall cost less than 0.28\$ per 1M tokens). However, since we did not have the computation device to run such a large model, we resorted to the commercial API release of the exact DeepSeek model in our implementation. 
We then chained the processing steps with LangChain.js v0.1~\cite{langchainjs}, the JavaScript implementation of a popular framework for developing LLM-powered applications.
