% Requires packages: booktabs, multirow
\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{llccccccccc}
\toprule
& & \multicolumn{3}{c}{Short-form} & \multicolumn{2}{c}{Closed-set} & \multicolumn{4}{c}{Long-form Generation} \\
\cmidrule(lr){3-5} \cmidrule(lr){6-7} \cmidrule(lr){8-11}
Model &  & TQA &2WQA & PopQA & Pub & ARC  & \multicolumn{2}{c}{ASQA} &\multicolumn{2}{c}{ELI5} \\
& & (acc) &(F1) & (acc) & (acc) & (acc)  & (rouge)  & (mauve) & (rouge)  & (mauve)\\
\midrule
\multicolumn{9}{l}{\textit{Baselines without retrieval}} \\
Llama2$_{7\text{B}}$ & & 30.5 & 18.9 & 14.7 & 34.2 & 21.8   & 15.3 &19.0 &18.3 &32.4 \\
Alpaca$_{7\text{B}}$ & & 54.5 & -- & 23.6 & 49.8 & 45.0   & 29.4 & 61.7 & -- & -- \\
Llama2$_{13\text{B}}$ & & 38.5 & 20.2 & 14.7 & 29.4 & 29.4   & 12.4 &16.0 &18.2 & 41.4 \\
Alpaca$_{13\text{B}}$ & & 61.3 & -- & 24.4 & 55.5 & 54.9   & 32.0 & 70.6 & -- & -- \\
% Llama2-c$_{13\text{B}}$ &  & 59.3 & -- & 20.0 & 49.4 & 38.4   & 29.6 & 28.6 & -- & -- \\
ChatGPT$_{\sim 175\text{B}}$ & & 74.3 &24.8 & 29.3 & 70.1 & 75.3   & 36.2 & 68.8 &\textcolor{secondclose}{22.8} &32.6\\
Sonnet-3.5$_{\sim 175\text{B}}$ & & \textcolor{firstclose}{\underline{78.4}} & 40.0 & 30.2  & \textcolor{firstclose}{\underline{83.7}} &88.5  &37.0 &39.1 &21.8 &26.5  \\

\midrule
\multicolumn{9}{l}{\textit{Baselines with retrieval (\#docs=5 by default)}} \\
Llama2$_{7\text{B}}$ & & 42.5 &21.0 & 38.2 & 30.0 & 48.0   & 22.1 & 32.0 &18.6 &35.3 \\
Alpaca$_{7\text{B}}$ & & 64.1 & -- & 46.7 & 40.2 & 48.0   & 33.3 &57.9 &-- &--\\
% Llama2-FT$_{7\text{B}}$ & & 57.3 & -- & 48.7 & 64.3 & 65.8   & 35.8 &51.2 &-- &--\\
Llama2$_{13\text{B}}$ & & 47.0 & 31.2 & 45.7 & 30.2 & 26.0   & 20.5 &24.7 & 18.6 &42.3\\
Alpaca$_{13\text{B}}$ & & 66.9 & -- & 46.1  & 51.1 & 57.6   & 36.7 &56.6 &-- &-- \\
% Llama2-c$_{13\text{B}}$ & & 59.8 & -- & 51.8 & 52.1 & 37.9   & 34.8 &43.8 &-- &-- \\
\multicolumn{2}{l}{RECOMP$_{7\text{B}}$ \cite{xu2023recomp}}  &-- &32.4 &-- &-- &-- &36.5 &76.0 &-- &-- \\
\multicolumn{2}{l}{SuRe$_{7\text{B}}$ \cite{kim2024sure}} &-- &20.6 &--  & -- &--  &35.8 &76.2 &-- &--\\
\multicolumn{2}{l}{SuRe$_{\text{GPT}}$} &72.3 &38.1 &53.6  & 57.2 &79.6  &36.0 &74.2 &-- &--\\
ChatGPT & & 65.7 &32.8  & 50.8 & 54.7 & 75.3   & \textcolor{firstclose}{\underline{39.9}} &\textcolor{firstclose}{\underline{79.7}} &20.6 &\textcolor{firstclose}{\underline{57.2}} \\
Sonnet-3.5$_{\#\text{docs}=1}$  &  &69.1 &41.9 &51.5 &49.1 &88.6  &-- &-- &-- &--\\
Sonnet-3.5$_{\#\text{docs}=5}$  &  &72.5 &\textcolor{secondclose}{53.7} &\textcolor{secondclose}{57.3} &53.9 &87.1   &38.8 & 61.6 &20.2 &32.3 \\
\multicolumn{2}{l}{SuRe$_{\text{Sonnet-3.5}}$} &76.8 &37.6 &41.2  &62.8  &\textcolor{secondclose}{91.6}  &30.2 &69.9 &15.4 &27.2\\
\midrule
\multicolumn{9}{l}{\textit{Baselines with self-reflective retrieval}} \\
\multicolumn{2}{l}{SELF-RAG$_{7\text{B}}$ \cite{asai2023self}} & \textcolor{secondopen}{66.4} & 25.1 & 54.9 & 72.4 & \textcolor{secondopen}{67.3}   & 35.7 &74.3 &17.9 &35.6 \\
\multicolumn{2}{l}{SELF-RAG$_{13\text{B}}$} & 69.3 & -- & 55.8 & 74.5 & 73.1   & 37.0 &71.6 &-- &-- \\
\multicolumn{2}{l}{RPG$_{7\text{B}}$ \cite{lyu2024retrieve}} &-- &\textcolor{secondopen}{33.6} & \textcolor{secondopen}{56.0} &\textcolor{secondopen}{73.4} & --  &\textcolor{secondopen}{\underline{37.6}} &\textcolor{firstopen}{84.4} &\textcolor{secondopen}{19.1} & \textcolor{firstopen}{{46.4}} \\
\midrule
\multicolumn{9}{l}{\textbf{\textit{Retrieval-And-Structuring (Ours)}}} \\
$\mathcal{M}_{Plan}$  & $\mathcal{M}_{Ans}$ \\
RAS$_{\text{Sonnet-3.5}}$ & RAS$_{\text{Sonnet-3.5}}$ &\textcolor{secondclose}{77.4} & \textcolor{firstclose}{\underline{57.7}} &\textcolor{firstclose}{\underline{62.3}} & \textcolor{secondclose}{71.4} &\textcolor{firstclose}{\underline{93.8}}   &\textcolor{secondclose}{39.1} & \textcolor{secondclose}{70.5}  &\textcolor{firstclose}{\underline{23.3}}  &\textcolor{secondclose}{37.7}   \\
RAS$_{\text{Sonnet-3.5}}$ & RAS$_{7\text{B}}$ &73.8 &43.4 &61.3 &75.5 & 62.4 & 37.2 &95.2  &19.7 & 47.8\\
RAS$_{7\text{B}}$ & RAS$_{\text{Sonnet-3.5}}$ &78.7  &54.7 &58.8  &70.8 &91.2 &39.1 &70.5  & 23.3 &37.7\\
RAS$_{7\text{B}}$ & RAS$_{7\text{B}}$  &\textcolor{firstopen}{\underline{72.6}} &\textcolor{firstopen}{\underline{42.1}} &\textcolor{firstopen}{\underline{58.3}}  &\textcolor{secondopen}{\underline{74.8}} &\textcolor{firstopen}{\underline{67.7}} &\textcolor{firstopen}{37.2} &\textcolor{secondopen}{\underline{95.2}} & \textcolor{firstopen}{\underline{19.7}} &\textcolor{secondopen}{\underline{47.8}} \\[2pt]
\hdashline[2pt/2pt] \\ [-9pt]
RAS$_{8\text{B}}$ & RAS$_{8\text{B}}$  &73.8 & 44.2 &57.7 &77.5 & 71.5 &37.6 &96.2 &20.1 &54.4 \\
\bottomrule
\end{tabular}
}
\vspace{-0.5em}
\caption{\textbf{Performance Comparison.} We highlight the \textcolor{firstclose}{top-2 closed-source models} and \textcolor{firstopen}{top-2 open-source 7B models}, and underline the \underline{best closed-/open-source (7B) model} for each dataset. \underline{Note}: Either RAS$_{7\text{B}}$ or RAS$_{8\text{B}}$ is a single model trained with action planner's and answerer's instructions via multi-task learning. No ensemble or multi-agent approach is used for any experiments.}
\label{tb:main_results}
\vspace{-1em}
\end{table*}