\begin{table}[t]
    \centering
    \renewcommand{\arraystretch}{1.2} % Adjust row spacing
    \setlength{\tabcolsep}{6pt} % Adjust column spacing
    \begin{tabular}{l|c}
        \toprule
        \textbf{Model} & \textbf{FactScore} \\
        \midrule
        Llama-3      & 0.9077 \\
        GPT-4o         & 0.9323 \\
        \hline
        Uncleaned       & 0.8798 \\
        Manual cleaned  & 0.8810 \\
        Autocleaned\textsubscript{L} & 0.8202 \\
        Autocleaned\textsubscript{G}     & 0.8966 \\
        \hline
        SynthGPT   & 0.9116 \\
        SynthLlama & 0.9211 \\
        SynthLlama+ & \textbf{0.9461} \\
        \bottomrule
    \end{tabular}
    \caption{FactScore results for the test set. Pretrained base models: Llama-3 and GPT-4o. Finetuned Llama-3-B models on the \citet{nandy-etal-2021-question-answering} dataset: Uncleaned (no data cleaning performed), Manual cleaned (cleaning done by the first author), Autocleaned\textsubscript{L} and Autocleaned\textsubscript{G} (cleaning done by Llama-3-70B and GPT-4o, respectively). Finetuned Llama-3-B models on synthetic data: SynthGPT (trained on data generated by GPT-4o), SynthLlama (trained on data generated by Llama-3-8B), and SynthLlama+ (same as SynthLlama, with additional negative examples).}
    \label{tab:factscore_test_set}
\end{table}