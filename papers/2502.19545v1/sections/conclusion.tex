\section{Conclusion}

In this work, we explore the trade-offs between cost, manual effort, and performance in building a QA agent for customer service, with a focus on mitigating hallucination. We elucidate the components of this process that can be automated and what models are best for that automation. We find that models finetuned on synthetic datasets can outperform ones from crowdsourced datasets, and that self-training with data validation not only matches the performance of knowledge distillation but can rival the original model being distilled (GPT-4o). Our findings suggest that using this approach, scalable and cost-effective QA systems can be rapidly developed for customer service applications, delivering performance comparable to or exceeding that of current state-of-the-art models.