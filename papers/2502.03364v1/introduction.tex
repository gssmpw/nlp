Wearable human activity recognition (HAR) aims to recognize the actions of people 
from the time series data originating from the sensors in their wearable devices and mobile phones. These sensors are typically motion sensors, such as triaxial accelerometers, gyroscopes, magnetometers, or their combination in inertial measurement units (IMU). 
This is an important area of research in mobile and ubiquitous computing \cite{Cook10,SanSegundo18,Ploetz18}.
It has applications in domains such as industrial assistance
%\cite{Stiefmeier08a}, 
\cite{Scholl15},
personalized healthcare %\cite{Lee18, Patel12},
\cite{Lee18}, 
human-computer interaction \cite{Luckowicz10_computer}, 
or sports tracking 
%\cite{Kranz13}, 
\cite{Hsu19}, well illustrated in many current smartwatches automatically detect fitness workouts. 




A wide range of architectures (e.g., convolutional, recurrent, Transformers \textemdash see \cref{sec:related}) have been suggested \cite{Chen21,Gu21}, but so far design principles to create architectures for specific recognition problems and trade-offs still elude us.
This is particularly important as HAR has unique characteristics, distinct from other time series problem (e.g., speech and auditory scene analysis) \cite{Demrozi20}. Notably, the problem is often tackled with several multimodal sensors (e.g., smartphone, smartwatch and physiological sensors). The sensor sample rate can differ by orders of magnitude in a same system\footnote{For example, sound used to detect sound-generating activities (e.g., washing hands, use of a microwave) is sampled in the tens of KHz. Motion and physiological sensors tend to be sampled in the tens to hundreds of Hz. Other sensors may be sampled at a much lower rate, such as GPS sampled in the order of a few Hz.}. The activities themselves can differ wildly in duration\footnote{For example, sporadic events such as ``taking a sip from a glass'' to longer activities such as workouts in a gym, or even longer daily routines}. New sensors are also continuously developed, such as sensorized textiles \cite{TellezVillamizar24}, and power considerations are important when models are to run on embedded devices.
This variety leads to application-specific annotated datasets for training, which are costly to acquire \cite{Welbourne14}, effectively leading to annotation scarcity \cite{Chen21} and growing interest in self-supervised pre-training to address this \cite{SSLHARsurvey}. 
It also makes it challenging to come up with generalizable architectures.
The architectures reported in the literature are generally a result of experimentation and heuristics tailored to application-specific trade-offs.

A promising approach to achieve a more principled design include relying on
scaling laws, which aim to link model capacity, data volume and performance. Scaling laws have been explored in language foundation models \cite{hoffmann2022chinchilla} but there has been little work verifying their existence and benefits in wearable HAR.

Identifying whether such scaling laws exist has important benefits.
Firstly, 
if compute resources are not a limitation, then it is important to design a model with a capacity commensurate to the amount of pre-training data to make best use of it. A model without enough capacity would not be able to take full benefit from the pre-training data. In fact, previous work stated that self-supervised learning data volume is only useful up to a point \cite{assessingSSLHAR22}. Our paper makes the point that in that instance, the model capacity was insufficient to make use of larger volume of data.
A model with too much capacity might further improve classification performance, but it would do so at higher compute cost which has its own downsides (e.g., on embedded devices).

Secondly, 
if compute resources are limited (e.g., constraints to run on embedded hardware, or financial training costs), then there is a corresponding suitable volume of pre-training data. 
Therefore it becomes important to use the most suitable, higher quality, pre-training data available first, given the data volume budget, and only include other lesser quality data if the data volume budget allows for it. 
This means favoring pre-training datasets similar to the target domain: similar location of the sensors (on body placement {\em and} orientation), same modalities (a gyroscope cannot be substituted by an accelerometer), similar sensing characteristics (sample rate, dynamic range), 
similar user activities (static or slow-moving yoga poses may not be suitable to pre-train a model for highly dynamic activities such as contact sports)\footnote{Pre-training on data that from a different domain still works, but this becomes a form of regularization, rather than the more desirable ability to hierarchically capture dynamic and cross-modal properties of the sensor signals.}.
%\end{itemize}
Thus, such scaling laws may provide guidance on how to allocate costs across compute costs for model training and engineering effort for data curation\footnote{Unlabelled data is {\em more easily} available than annotated data, but it does not come ``for free'': it still needs to be identified and curated. This is especially the case in wearable computing where it is difficult to find large pre-existing datasets which may match the specific characteristics of a new recognition problem.
}. 

In short, the research questions of this paper are:





\begin{mdframed}


\noindent {\bf RQ0: } Does the Vision Transformer (ViT) architecture generalize seamlessly to the time series domain of wearable motion sensing?

\noindent {\bf RQ1: } Do scaling laws linking data, model capacity, and performance exist in the data and inference compute constrained domain of HAR?

\noindent {\bf RQ2: } How does data diversity affect the scaling laws and how does it align with previously published work?


\noindent {\bf RQ3: } Do these scaling laws suggest new experiments or improvements for previously published work (e.g. models proposed so far having insufficient capacity)?
\end{mdframed}

This paper investigates scaling laws linking pre-training data volume, model capacity and performance, in the context of a ViT adapted for HAR pre-trained on unlabelled data.
%
Our contributions are:
\begin{itemize}
\item 
We summarize the state of the art in HAR, including self-supervised training, and in the work to uncover scaling laws in foundation models. We identify that scaling laws have not yet been investigated in HAR (\cref{sec:related}).
\item 
We introduce a ViT architecture adapted for HAR from triaxial accelerometer and gyroscope (6 channel input) which is trained with self-supervised principles. We faithfully apply Masked Autoencoder pre-training and ViT encoder architecture with minimal changes from the original vision papers, addressing \textbf{RQ0}. For our scaling laws, we differ from language and vision domains by training to convergence in order to study the relationship between number of parameters and data more directly under the unique conditions for HAR, where we are not constrained by training compute (\cref{sec:method}).
\item 
Using the large scale public Extrasensory dataset of activities of daily living collected in the wild from smartphone sensors (5000 hours of data from 60 users), we identify for the first time scaling laws in HAR showing that pre-training loss scales with a power law relationship to amount of data and parameter count (\cref{sec:result_scaling}), addressing \textbf{RQ1}.
\item 
We verify that these laws inform the performance on downstream HAR tasks, using 3 datasets of postures, modes of locomotion and activities of daily living, including up to 18 activity classes: UCI HAR and WISDM Phone and WISDM Watch (\cref{sec:downstream_performance}).
\item 
We show that model capacity can be further increased with datasets that are augmented by signal transformations and therefore help alleviate annotation scarcity (\cref{sec:augmentations}).
\item 
We indicate how these scaling laws can be used to inform future research.
Notably, we discuss how these scaling laws can be used to re-interpret previously published work, addressing \textbf{RQ3}. We give two examples where we assess that increased model capacity could have been beneficial (\cref{sec:conclusion}).
Our findings reiterate the importance of pre-training with higher ``quality'' data rather than solely larger volume of data: we show that adding more users to the pre-training dataset is better than adding more data from the same user, contradicting other recent findings in the field (e.g., \citet{narayanswamy2024scalingwearablefoundationmodels}), and pointing to future research avenues, addressing \textbf{RQ2}.
\end{itemize}

