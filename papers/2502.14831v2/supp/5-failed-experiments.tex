\section{Failed experiments}
\label{ap:failed-experiments}


We tried two theory-inspired regularization strategies:
\begin{itemize}
    \item MiniLDM-regulzation training. This was inspired by LSGM~\cite{LSGM} where the authors showed that it's the correct objective for LDMs. We spent a month trying to make it work, but in all the cases it . At the same time, \cite{CausRegTok} were able to make it work for discrete autoregressive models.
    \item Lipszhitz regularization. This was inspired by the lower bound which \cite{LFM} provided:
    \begin{equation}
        W(p, p') \leq ...
    \end{equation}
    This more or less worked, but it was tough to train. Also, it was leading to unstable training in the LDM itself. Something to revisit
    \item 
\end{itemize}
