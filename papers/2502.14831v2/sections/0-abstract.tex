\begin{abstract}
Latent diffusion models have emerged as the leading approach for generating high-quality images and videos, utilizing compressed latent representations to reduce the computational burden of the diffusion process.
While recent advancements have primarily focused on scaling diffusion backbones and improving autoencoder reconstruction quality, the interaction between these components has received comparatively less attention.
In this work, we perform a spectral analysis of modern autoencoders and identify inordinate high-frequency components in their latent spaces, which are especially pronounced in the autoencoders with a large bottleneck channel size.
We hypothesize that this high-frequency component interferes with the coarse-to-fine nature of the diffusion synthesis process and hinders the generation quality.
To mitigate the issue, we propose \emph{\regname}: a simple regularization strategy that aligns latent and RGB spaces across frequencies by enforcing scale equivariance in the decoder.
It requires minimal code changes and only up to $20$K autoencoder fine-tuning steps, yet significantly improves generation quality, reducing FID by 19\% for image generation on ImageNet-1K $256^2$ and FVD by at least $44\%$ for video generation on Kinetics-700 $17 \times 256^2$.
\end{abstract}
