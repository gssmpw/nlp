\input{figures/spectrums-comparison-flux}
\input{figures/flux-kl-spectrums}

\section{Improving Diffusability}
\label{sec:method}

We begin this section by discussing the spectral decomposition of 2D signals and providing some background on discrete cosine transform in Section~\ref{sec:method:dct}.
In Section~\ref{sec:method:spec}, we analyze the spectral properties of latent spaces across different autoencoders and compare them to those of the RGB space.
Our main insight is that the frequency profile of the latent space includes large-magnitude high-frequency components.
We also show that as the channel size increases, the high-frequency components become more pronounced.
Additionally, we demonstrate that the widely adopted KL regularization only increases the strength of these components.
Finally, \cref{sec:method:scalereg} presents a straightforward method to improve the diffusability of a latent space of an autoencoder by enhancing its spectral properties.

\subsection{Background: Blockwise 2D DCT}
\label{sec:method:dct}

% We structure this section with the following three parts:
% \begin{enumerate}
%     \item We first demonstrate that increasing the bottleneck channel size often leads to undesirable spectral outcomes and explain why this can be problematic for diffusion.
%     \item We then introduce our frequency regularization (\regname) approach along with its intuitive variants to alleviate the issue.
%     \item Additionally, we revisit VAE regularization from a spectral perspective and highlight the differences between it and \regname.
% \end{enumerate}

% \include{figures/dct_basis_zigzag}
% \subsection{Background: Block-wise 2D DCT.}
% \label{sec:dct}
The discrete cosine transform (DCT)~\cite{ahmed2006discrete} over a 2D signal is a transformation converting the signal's representation between the spatial and frequency domains. DCT, in particular, represents the original input signal as coefficients for a set of horizontal and vertical cosine basis oscillating with different frequencies. %blocks, which represe
More formally, given a 2D signal block $\mathbf{A} \in \mathbb{R}^{B \times B}$ whose values $A_{xy}$ denote the pixel intensity at position $(x,y)$, %split it into non-overlapping $B\timesB$ blocks.
the two-dimensional type-II DCT yields a frequency-domain block $\mathbf{D} \in \mathbb{R}^{B \times B}$ where $D_{uv}$ captures the coefficient for the corresponding horizontal and vertical cosine bases:
\begin{align}
D_{uv} &= \alpha(u) \alpha(v) \sum_{x=0}^{B-1}\sum_{y=0}^{B-1} A_{xy} f(x, u) f(y, v), \nonumber \\ 
& \text{where} \quad \alpha(u) = \left\{\begin{matrix} 
\sqrt{1/B}, \quad u=0, \\
\sqrt{2/B}, \quad u\neq0,
\end{matrix}\right. \nonumber \\
& f(x, u) = \cos\left(\tfrac{(2x+1) u \pi}{2B}\right). \nonumber
\end{align}
%where
%\[
%    \alpha_u = \begin{cases}
%    \sqrt{1/B}, & u=0 \\
%    \sqrt{2/B}, & u\neq 0
%    \end{cases},
%\]
%and similarly for $\alpha_v$.
%Here, $A_{xy}$ denotes the pixel intensity at position $(x,y)$, and $D_{uv}$ captures the coefficient for the corresponding horizontal and vertical cosine bases.
%JPEG traditionally uses $B=8$ to balance the compression ratio and visual quality.
%In our approach, we treat $B$ as a tunable parameter.
In practice, we split the input 2D signal into non-overlapping blocks of size $B\times B$ and treat each channel independently.

% ================== Frequency Profiles ==================
By analyzing RGB images and latents in the DCT frequency domain, we produce a \emph{frequency profile} that relates to the energy of the signal at every frequency. % where high-frequency energy is stored.
A zigzag frequency index is used to map each DCT block $\mathbf{D}\in\mathbb{R}^{B\times B}$ into a one-dimensional sequence following the standard \emph{zigzag} ordering as in JPEG~\cite{JPEG}, which indexes the DCT coefficients from lowest frequency $D_{0,0}$ to highest frequency $D_{B-1,B-1}$.
Formally, let $\zigzag(u,v) \in \{0,\dots,B^2-1\}$ denote the ranks of the coefficient $D_{uv}$ in ascending frequency order.
Given a block, we compute its DCT and produce normalized amplitudes for each frequency component \((u, v)\) as:
\begin{equation}  
    A_{uv} = \left |\frac{D_{uv}}{D_{0,0}} \right|.  
\end{equation}  
We define the \emph{frequency profile} as the sequence of normalized amplitudes in the standard \emph{zigzag} order.

When analyzing the frequency profiles of videos (or latent codes with an additional time dimension), we still rely on per-frame 2D DCT since the temporal and spatial domains possess different spectral properties.

\subsection{Spectral Analysis of the Latent Space}
\label{sec:method:spec}
% \subsection{How Bottleneck Channel Size Affects the Spectrum}
% \label{sec:method:bottleneck}

\input{figures/improved-spectrums}

We begin our analysis by observing the frequency profile of the latent space in the Flux~\cite{Flux} family of autoencoders to establish a relationship with \emph{diffusability}. 
For the purpose of this study, we train a family of FluxAE models with various channel sizes for 100k steps (where performance saturates in this setting) and, for each of them, compute the averaged frequency profile over 256 samples, all channels, and all DCT blocks. 
Figure~\ref{fig:spectrums-comparison-flux} presents the frequency profiles of both Flux autoencoders and RGB space, from which we observe: (i) The Flux profile exhibits significantly larger high-frequency components compared to the RGB profile. (ii) As the number of channels in the autoencoder's bottleneck increases, high-frequency components become more pronounced. This observation is of particular interest as the number of channels is positively correlated with autoencoder's reconstruction quality. %While autoencoders with more channels generally achieve better reconstruction by expanding the bottleneck capacity, we find that this increased capacity can also impact the spectral distribution of the latent space.

A common approach to regularizing the latent space in latent diffusion models (LDMs) is to employ a variational autoencoder (VAE)~\cite{VAE} framework with a KL divergence term, encouraging the latent distribution to align with a Gaussian prior. This regularization can help to bring the latent distribution closer to the standard Gaussian~\cite{LSGM}, simplifying the job for the diffusion process, as the reverse process starts with the same distribution. However, as we show in Figure~\ref{fig:flux-kl-spectrums} which compares FluxAE models trained with different levels of KL regularization, higher KL regularization introduces more high frequencies.

% ============= Why we need a frequency profile that is not flat =====================
As described in~\cite{DCTdiff, spectral-autoregression, InverseHeatDissipation}, diffusion models can be interpreted in the spectral domain as autoregressive processes: when noise level is high, low frequencies are generated, then, as the level of noise lowers during sampling, progressively higher frequencies are generated. This property is desirable, as it allows the model to leverage the cleaner lower frequencies as a conditioning signal for the current prediction.  %when  where low frequencies are generated earlier in the initial sampling steps, and higher-frequency components are subsequently progressively generated in the final steps of sampling.
However, the strength of this autoregressive pattern is directly related to the shape of the frequency profile for the signal to generate. Since the white noise that is applied as part of the diffusion process has a flat frequency profile, it follows that the flatter the frequency profile of the signal, the lower the cleanliness of low frequencies that can act as conditioning for the model. For a flat frequency profile, no autoregressive generation is possible as all frequencies would be erased at the same speed by white noise.
% ============== Why high frequencies are problematic and we should not have them, and we should not have them encode important things ========================
We also hypothesize that higher frequencies components are harder to model than lower frequency components for the following reasons and thus should be avoided: (i) they have higher dimensionality; (ii) they are generated only in the final steps of sampling, thus must emerge more rapidly; (iii) they are more susceptible to error accumulation over time.

Motivated by this analysis, we propose scale equivariance regularization for the autoencoder's latent space.

%We hypothesize that these high-frequency components are more challenging to model than low-frequency ones. Drawing insights from spectral-domain interpretations of diffusion models as autoregressive processes~\cite{DCTdiff, spectral-autoregression}, higher-frequency components are generated only in the final steps of sampling, thus must emerge more rapidly and are more susceptible to error accumulation over time. One might argue that despite the presence of high-frequency components in the latent space, the decoder could simply disregard them. However, as demonstrated in Fig.~\ref{fig:progressive-dct-cut}, these components play a crucial role in shaping the final output. Motivated by these observations we develop a regularization aiming at reducing the relevance of this component.

\input{figures/qualitative-dct-cut}

\subsection{\Regname Regularization}
\label{sec:method:scalereg}
Effective regularization should achieve two key objectives: (i) to suppress high-frequency components in the latent space and (ii) to prevent the decoder from amplifying these components, as their impact on the final result is what ultimately matters. This can be accomplished by aligning the spectral properties of the latent and RGB spaces at different frequencies.
A way to achieve this consists in explicitly chopping off a portion of the high frequencies in both spaces and training the decoder to reconstruct the truncated RGB signal from the truncated latent representation.
Our preliminary experiments demonstrated that an autoencoder can easily learn to alter its latent frequency profile to encode the inputs in the low-frequency region of the spectrum without sacrificing the reconstruction quality much (see \cref{fig:progressive-dct-cut}).
While this regularization, which we name \regchfname (\regchfshortname), improves the spectrum, we develop a much simpler procedure to achieve the same effect without the need to perform the error-prone DCT transform (the details of \regchfshortname are described in \cref{ap:freq-reg}).
The simplest way to achieve high-frequency truncation is through direct downsampling, which we discuss next.

Downsampling involves resizing both the input  $x$ and the latent representation $z$ by a fixed scale, yielding $\Tilde{x}$ and $\Tilde{z}$, respectively.
This process effectively removes a portion of the high-frequency components from both the RGB and latent signals.
In practice, we use $\times 2-4$ bilinear downsampling for all the experiments.
Regularization is then enforced by ensuring that $\Tilde{x}$ and the decoderâ€™s reconstruction of the downsampled latent $\Dec(\Tilde{z})$ remain consistent through an additional reconstruction loss.
The autoencoder is trained using the following objective:  
\begin{equation}\label{eq:loss}
\loss(x) = d(x, \Dec(z)) + \alpha d( \Tilde{x}, \Dec(\Tilde{z}) ) + \beta\loss_\text{KL}.  
\end{equation}  

Here, $d(\cdot,\cdot)$ represents a distance measure for reconstruction which we instantiate as mean squared error loss and perceptual losses~\cite{lpips} following prior work~\cite{LDM}, $\alpha$ is the regularization strength (we use $\alpha = 0.25$ for the main experiments).
The term $\loss_\text{KL}$ is VAE's~\cite{VAE} KL regularization, if applicable (we do not use it when we train with our regularization).
This regularization effectively enforces scale equivariance in the decoder, which is the basis for its name.  

In Figure~\ref{fig:improved-spectrums}, we illustrate the effect of \regname on the spectrum of FluxAE. Our proposed regularization effectively reduces the high-frequency components of the signal, bringing it closer to the spectral characteristics of the RGB space. This successfully achieves objective (i) for effective regularization.
Meanwhile, Figure~\ref{fig:reg-dct-cut-flux} demonstrates that \regname preserves more content compared to the baseline, as more and more high-frequency components are suppressed, thereby fulfilling objective (ii).
Finally, Figure~\ref{fig:traj-comparison} visualizes intermediate steps in the diffusion trajectory. The regularized model exhibits a noticeably smoother and more structured progression, following a healthier coarse-to-fine generation process.
\vspace{-0.1cm}
\input{figures/traj-comparison}
% \vspace{-0.5cm}

% Ideal regularization should aim at achieving two things: (1) suppress the magnitude of high frequency components in the latent space and (2) prevent the decoder from amplifying the high frequency components, because what matters in the end of the day is how much this \textit{hard} high frequency components affect the final result. This can be achieved by matching latent space and RGB space at a different frequencies. In other words we need to truncate part of the high frequencies in latent and RGB spaces and the decoder to reconstruct truncated RGB signal from the truncated latent. In the most simple form this truncation can be achieved by downsampling, which we discuss next, while in App.~\ref{app:choping} we also show additional more advanced method for frequency truncation. 

% In simple terms downsampling resize both input $x$ and lattent $z$ by a fixed scale obtaining $\Tilde{x}$ and $\Tilde{z}$ respectively. This effectively truncating part of the high frequencies from RGB and lattent signals. While regularization enforces that $\Tilde{x}$ and decoder version of downscale latents $\Dec(\Tilde{z})$ match by enforcing additional reconstruction loss between them. Finally, autoencoder is trained with the following objective:

% \begin{equation}
% L_\theta(x) = d(x, \Dec(z)) + d( \Tilde{x}, \Dec(\Tilde{z}) ) + L_\text{reg}.
% \end{equation}
% Here, $d(\cdot,\cdot)$ is a distance measure for reconstruction (following the prior work, we use $L_2$ and perceptual~\cite{lpips}). $L_\text{reg}$ are other regularizations such as KL if applicable. This regularization is equivalent to enforcing scale equivariance for the decoder, hence the name for the it.

% Figure~\ref{fig:progressive-dct-cut} illustrates that the downsampling method preserves most details and maintains stable reconstructions.

% \input{figures/improved-spectrums}
% Figure~\ref{fig:improved-spectrums} confirms that the high-frequency magnitudes become more controlled.

% \input{figures/traj-comparison}
% In Figure~\ref{fig:traj-comparison}, we see that early diffusion steps are cleaner with \regname.




