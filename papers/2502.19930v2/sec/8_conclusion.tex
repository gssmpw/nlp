\section{Conclusion}
We proposed a new distillation sampling method using a fixed-point regularization which aligns the text-conditioned score towards identity-preserved manifolds. The proposed fixed-point regularization preserves the source's identity by re-projecting the intermediate score status on posterior means. In this manner, corrected noises guide a gradient of distilled score toward identity-consistent manifolds. Owing to self-correction by a fixed-point iterator and guided injection noise, the proposed identity-preserving distillation sampling provides clear and unambiguous representations corresponding to the given prompts in text-guided image editing and editable neural radiance field (NeRF). Furthermore, our model can be utilized as a universal module in addition to the existing score-sampling processes. %Inverted initial noise from pre-trained diffusion model is clearly retrieved by our method.
\newpage

\paragraph{Acknowledgement} This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (RS-2024-00335741, RS-2024-00357197).

