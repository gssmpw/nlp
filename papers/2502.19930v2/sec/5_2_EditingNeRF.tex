\noindent\textbf{Datasets.} We evaluated our method on widely used NeRF datasets: Synthetic NeRF \cite{mildenhall2021nerf} and LLFF \cite{mildenhall2019local}. Since NeRF datasets have no given pairs of source and target prompts, we manually composed image descriptions.
%, such as the source prompt ``A tree in a brown vase" and its corresponding target prompt ``A tree in a blue vase" as shown in \cref{fig:ficus_qual}.

\noindent\textbf{Qualitative Results.} \cref{fig:ficus_qual} illustrates the qualitative results of our method compared with NeRF editing baselines. In the first row, the target prompt specifies a precise part of the image for fine-grained editing. DDS \cite{hertz2023delta} and CDS \cite{nam2024contrastive} fail to differentiate and edit the specific area. At the same time, our method accurately identifies the region indicated by the target prompt in the image and performs detailed editing exclusively on that part. 
The second row demonstrates a scenario in which the target prompt is designed to edit the mood of the image. Our approach adjusts the colors associated with ``autumn" and ``leaves" throughout the image while maintaining consistency in the ``trunk" whereas DDS and CDS also changed the ``trunk". In terms of depth maps, our method generates clean depth maps with minimal noise after image editing, whereas DDS and CDS introduce noticeable noise into the depth maps.

%the overall mood of the image on the LLFF dataset \cite{mildenhall2019local}
 % give an attention solely on following the target prompt during editing, leading to unintended alterations of parts that should remain unchanged.
 % Comparing the NeRF depth maps with baselines, 
% \cref{fig:ficus_qual} illustrates the qualitative results of our method compared with NeRF editing baselines such as DDS \cite{hertz2023delta} and CDS \cite{nam2024contrastive}. In the first row, the target prompt specifies a precise part of the image for fine-grained editing on the Synthetic NeRF dataset \cite{mildenhall2021nerf}. Our method accurately identifies the region indicated by the target prompt in the image and performs detailed editing exclusively on that part. In contrast, DDS and CDS fail to differentiate and edit the specific area; they erroneously edit not only the ``vase" but also the ``soil", resulting in inappropriate edits. The second row demonstrates a scenario in which the target prompt is designed to edit the overall mood of the image on the LLFF dataset \cite{mildenhall2019local}, further highlighting the strengths of our method. Our approach adjusts the colors associated with ``autumn" and ``leaves" throughout the image while maintaining consistency in the ``trunk", which should be preserved from the source image. However, DDS and CDS focus solely on following the target prompt during editing, leading to unintended alterations of parts that should remain unchanged. Additionally, comparing the NeRF depth maps with baselines, our method generates clean outputs with minimal noise after image editing, whereas DDS and CDS introduce noticeable noise into the depth maps. 
% \vspace{-10pt}
\input{Fig./Table/NeRFQuan}
\noindent\textbf{Quantitative Results.} Based on edited images, we performed 3D rendering and subsequently conducted quantitative evaluations provided in \cref{tab:Nerfclip}. To assess whether the edited 3D images are precisely aligned with the target prompts, we measured the CLIP \cite{radford2021learning} scores at 200k iterations of training on the LLFF dataset. We additionally present a user evaluation conducted under the same setup in \cref{sec:5.1}. Consistent with the trends observed in the qualitative results, our method demonstrates superior performance in the quantitative evaluations compared to other baselines.