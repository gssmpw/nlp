\section{Method}
\label{sec:method}
%\input{Fig./Qual/Editing/post_mean3}

Given the source pair $\{\src, \txts \}$, the aim of our work is to provide an edited result $\trg$ that is aligned with $\txtt$ while maintaining the source's identity. To this end, we introduce a novel approach called \textbf{Identity-preserving Distillation Sampling (IDS)}, which (1) corrects the error of the gradient aligned with the text prompt by the fixed-point iterator and (2) provides the result $\trg$ using the guided noise.%$\epsilon^\ast$. %instead of random Gaussian noise for identity preservation.

%We begin with an interpretation of the SDS \cite{poole2022dreamfusion} and DDS \cite{hertz2023delta} loss function from a new perspective. 
%Although DDS \cite{hertz2023delta} has been proposed to obtain the optimal text-aligned score for image editing, structural consistency often cannot be maintained. 

%The text-conditioned score may lead to a misalignment with the identity of the given image $\src$, leading to a significant change in the overall structure and characteristics when the error is accumulated. To address this issue, we introduce a novel approach called \textbf{Identity-preserving Distillation Sampling (IDS)}, which corrects the error of the direction aligned with the text prompt by the fixed-point iterator. 

%Our method not only ensures the structural consistency of objects, but also preserves features such as color and texture. 
% when applied to image editing.

%In this section, we review and interpret DDS loss from a novel perspective in section \ref{ssec:3.1}. Based on this interpretation, we analyze the problem of what part of DDS loss is causing the error during image editing in section \ref{ssec:3.2}. Then, we introduce our method, Fixed-point Iteration for Denoising Score (FPDS), to recover this error in section \ref{ssec:3.3}.

%------------------------------------------------------------------------
% \vspace{-7mm}
\subsection{Motivation} \label{ssec:4.1}
%Therefore, the result only follows the target prompt $y_{trg}$ without preserving the characteristics of $\trg_{src}$ as shown in Fig. \ref{fig:inversion}. Is there the \textbf{score to capture the features of the input image} that should be consistent between the source and result?

%However, when editing the images, $\epsilon_\phi(\trg_t, y, t)$ generates denoising score in various directions corresponding to $y$ at each optimizing step.  

%\subsection{Problem of DDS for image editing} \label{ssec:4.2}

\textbf{Analysis of the text-conditioned score.} \ We first investigated how much identity of the given image $\src$ could be contained in the text-conditioned score ${\epsilon}_{\phi}^{\text{src}}$. To do this, we conducted the experiment to compare the original image $\src$ and the posterior mean $\src_{0|t} = \mathbb{E}[\src | \src_t]$, which is given by:
{\small
\begin{equation}
\src_{0|t} = \frac{1}{\sqrt{\alpha_{t}}}\left(
    \src_t -\sqrt{1-\alpha_{t}} {\epsilon}_{\phi}^{\text{src}}
    \right),
\label{eq:posterior}
\end{equation}
}
where $\src_t$ denotes the source latent  generated by \eqref{eq:forward}.
% As shown in the first row of Fig. \ref{fig:post_mean3}, it is difficult to recognize the features of $\src$ in $\src_{0|t}$, such as hairstyle, details of eyes, and background. This demonstrates that the score ${\epsilon}_{\phi}^{\text{src}}$ is not exactly adjusted to the given image $\src$. This deformation becomes more pronounced with increasing $t$.
As shown in the first row of the supplementary \cref{fig:post_mean3} %Fig. S1, 
it is difficult to recognize the features of $\src$ in $\src_{0|t}$, such as hairstyle, details of eyes, and background. This demonstrates that the score ${\epsilon}_{\phi}^{\text{src}}$ is not exactly adjusted to the given image $\src$. This deformation becomes more pronounced with increasing $t$.
The experiment confirms that ${\epsilon}_{\phi}^{\text{src}}$ may not be a precise guidance to the source image $\src$. %as shown in Fig. \ref{fig:algorithm}.
Therefore, the text-conditioned score ${\epsilon}_{\phi}^{\text{src}}$ needs to be modified to maintain the identity of the source image $\src$ in the edited result $\trg$.

\input{Fig./Qual/Editing/inversion}

%even if this gradient is calculated from the score $\hat{\epsilon}_{\phi}$ aligned with the prompt $\hat{y}$ that represents the given image $\src$. 
% \vspace{-10pt}
\noindent\textbf{Accumulated error in DDS.} \ The transformed image $\trg$ can be converted back to the original image $\src$ by reversing the set of $\epsilon$ used to synthesize $\trg$ from $\src$ and swapping $\{\src, \txts \}$ and $\{\trg, \txtt \}$ to calculate the DDS loss in \eqref{eq:dds}.
If the guidance from $\src$ to $\trg$ is computed exactly, the perfect reconstruction can be achieved. 
%According to our interpretation, the DDS algorithm is invertible, i.e., it is possible to reconstruct $\src$ from $\trg$, a transformed output of $\src$. 
Nevertheless, as can be seen from the second row in Fig. \ref{fig:inversion}, DDS \cite{hertz2023delta} fails to restore the original image $\src$ from the edited image $\trg$, which implies that the direction from $\src$ to $\trg$ is calculated incorrectly.
Based on our analysis, this error is because the text-conditioned score ${\epsilon}_\phi^{\text{src}}$ do not refer to the source $\src$, which can be explictly expressed as the difference between the injected noise $\epsilon$ and the score ${\epsilon}_\phi^{\text{src}}$. While the optimization is being processed, the error inevitably accumulates, leading to the undesirable change to the structure and the pose. 
% To address these issues, we investigated whether the guidance from $\src$ to $\trg$ can be properly provided while preserving the source's identity, when the timestep $t$ is constrained by $t\sim\mathcal{U}(0, 0.2)$. This is because the posterior mean $\src_{0|t}$ and the source image $\src$ are similar for small timestep $t$, as illustrated in the first row of Fig. \ref{fig:post_mean3}. However, as depicted in the first row of Fig. \ref{fig:inversion}, DDS yields unrealistic result with this setting, whereby the structure of the given image $\src$ is overemphasized. This implies that it is not sufficient to simply limit the timestep $t$ to prevent the score from deviating too far from $\src$ to correct the misalignment of the score to $\src$.
To address these issues, we investigated whether the guidance from $\src$ to $\trg$ can be properly provided while preserving the source's identity, when the timestep $t$ is constrained by $t\sim\mathcal{U}(0, 0.2)$. This is because the posterior mean $\src_{0|t}$ and the source image $\src$ are similar for small timestep $t$, as illustrated in the first row of supplementary \cref{fig:post_mean3}. %Fig. S1. 
However, as depicted in the first row of Fig. \ref{fig:inversion}, DDS yields unrealistic result with this setting, whereby the structure of the given image $\src$ is overemphasized. This implies that it is not sufficient to simply limit the timestep $t$ to prevent the score from deviating too far from $\src$ to correct the misalignment of the score to $\src$.
Hence, we propose a fundamental approach to refine the gradient to achieve identity consistency without unwanted overemphasis on details.

%To accurately calculate the direction from $\src$ to $\trg$, the direction of estimated denoising score $\grad{\theta}\hat{\epsilon}_\phi$ should be equal to the direction from $\src_t$ to $\src$ that is determined by $\epsilon$. 
%In DDS, however, $\hat{\epsilon}_\phi$ is not equal to $\epsilon$ since $\epsilon$ is randomly sampled value, and $\hat{\epsilon}_\phi$ is denoising score when $\src_t$ corresponds to the prompt $\hat{y}$. The difference between $\hat{\epsilon}_\phi$ and $\epsilon$ makes misalignment for the direction of $\grad{\theta}\loss{\dds}$, and this error accumulates during the optimization process. Although DDS shows meaningful performance for image-to-image translation, this cumulated error causes DDS to edit the background or structure incorrectly. %manifold fig?
% $\trg$ is the result edited from source image $\src$ and prompt $\hat{y}$ to target prompt $y$, and $\src^{\dagger}$ is the inverted result that transforms the edited image $\trg$ for prompt $y$ to previous source prompt $\hat{y}$. 
% However, as shown in Fig. \ref{fig:inversion}, the inversion $\src^{\dagger}$ of DDS is not same as the given source image due to the misalignment between $\hat{\epsilon}_\phi$ and $\epsilon$ which is used to make the input of $\epsilon_\phi$.

% In Fig. \ref{fig:inversion}, 
% That is, the reverse of \ref{eq:forward} should be similar with $\src$:
% \begin{equation}
%     \postmean \approx \frac{1}{\sqrt{\alpha_t}}(\src_t - \sqrt{1-\alpha_t} \hat{\epsilon}_\phi)
% \end{equation}


\subsection{Identity-preserving Distillation Sampling (IDS)} \label{ssec:4.2}

\textbf{Fixed-point Regularization (FPR).} \
Here, we introduce a \textbf{F}ixed-\textbf{p}oint \textbf{R}egularization (FPR) method that adjusts the text-conditioned score ${\epsilon}_\phi^{\text{src}}$ to the source image $\src$. Our key premise is that if the score ${\epsilon}_\phi^{\text{src}}$ is rightly estimated as a gradient to $\src$, the posterior mean $\src_{0|t}$ also contains sufficient information about $\src$. %, resulting in identity preservation.
Therefore, FPR loss is designed to minimize the difference between $\src$ and $\src_{0|t}$ as follows:
\begin{equation}
\mathcal{L}_{\text{FPR}} = d ( \mathbf{z}^{\text{src}}, \mathbf{z}_{0|t}^\text{src}),
\label{eq:fpr}
\end{equation}
%\begin{equation}
%    \mathcal{L}_{\text{FPR}}
%    =\lVert \mathbf{z}_{0|t}^\text{src} - \mathbf{z}^{\text{src}} \rVert _{2}^{2},  
%\end{equation}
where $d(\mathbf{x}_1, \mathbf{x}_2)$ can be any metric to compare $\mathbf{x}_1$ and $\mathbf{x}_2$. Here, we employed the Euclidean loss, and further investigations using various metrics are provided in \cref{sec:s_metricsforfpr} of Supplementary Materials.

The score ${\epsilon}_\phi^{\text{src}}$ needs to be modified to minimize the FPR loss before obtaining the updated direction. There are two ways to control the score  ${\epsilon}_\phi^{\text{src}}$ by altering the injection noise $\epsilon$ or the source latent $\mathbf{z}^{\text{src}}_t$. 
% As illustrated in Fig.~\ref{fig:post_mean3}, the proposed FPR revises the score ${\epsilon}_\phi^{\text{src}}$ to serve the source's identity for both approaches. Note that the score incorporates the content details, with the updates being performed with respect to the source latent $\mathbf{z}^{\text{src}}_t$ compared to the noise $\epsilon$. Thus, $\mathbf{z}_t^{\text{src}}$ is updated to minimize the FPR loss as follows:
As illustrated in supplementary \cref{fig:post_mean3}, %Fig. S1, 
the proposed FPR revises the score ${\epsilon}_\phi^{\text{src}}$ to serve the source's identity for both approaches. Note that the score incorporates the content details, with the updates being performed with respect to the source latent $\mathbf{z}^{\text{src}}_t$ compared to the noise $\epsilon$. Thus, $\mathbf{z}_t^{\text{src}}$ is updated to minimize the FPR loss as follows:
\begin{equation}\label{eq:update}
    \mathbf{z}^{\text{src}}_t \leftarrow \mathbf{z}_{t}^{\text{src}} - \lambda \nabla_{\mathbf{z}^{\text{src}}_t}\mathcal{L}_{\text{FPR}},
\end{equation}
where $\lambda$ and $N$ denote a regularization scale and the number of iterations, respectively. 

\input{sec/algorithm_fpr}
%Figure 5.1
\input{Fig./Qual/Editing/figure_ip2p_sub}
% \vspace{-10pt}
\noindent\textbf{Editing with guided noise.} \ 
Thanks to the proposed FPR, the optimized source latent $\srctopt$ containing the source's identity can be obtained. 
Then, the guided noise $\epsilon^\ast$ is extracted as follows:
{\small
\begin{equation} \label{eq:guide_eps}
\epsilon^\ast = \frac{1}{\sqrt{1-\alpha_t}}(\srctopt - \sqrt{\alpha_t} \src).
\end{equation}
} 
$\epsilon^\ast$ is utilized to produce the stochastic latent $\trgtopt$ by applying the forward diffusion process to the target image $\trg$.
With $\srctopt$ and $\trgtopt$, the updated direction is given by:
{\small
\begin{equation} \label{eq:ids}
% \begin{split}
    \grad{\theta}\loss{\ids}
     = \mathbb{E}_{t, \epsilon} 
    \left[ 
      (\epsilon_\phi^\omega(\trgtopt, \txtt, t) - {\epsilon}_{\phi}^\omega(\srctopt, \txts, t)) \pardiff{\trg}{\theta}\right]. %\nonumber\\
    % = \grad{\theta}\loss{\sds}(\trg, \txtt) - \grad{\theta}\loss{\sds}(\src, \txts).
% \end{split}
\end{equation}
}
It is worth noting that $\epsilon^\ast$ guides the appropriate gradients for editing while conserving the source's identity. In contrast to DDS, the proposed IDS perfectly reconstructs the source from the edited result $\trg$, as shown in the third row of Fig.~\ref{fig:inversion}. 
This confirms that the correct score and the corresponding injection noise can preserve the identity without further consideration of mutual information. The flowchart of our IDS is illustrated in Fig.~\ref{fig:teasor}.

%aligns the $\epsilon$ to the denoising score of the source image $\src$ and the source prompt $\txts$. 

%Since the error occurs from the misalignment between $\epsilon_\phi^\text{src}$ and $\epsilon$, we update the $\epsilon$ before calculating DDS loss.

%If $\epsilon_\phi^\text{src}$ is estimated correctly, the reverse calculation of $\mathbf{z}_{0|t}^\text{src}$ from Eq. \ref{eq:forward} should be equal to $\src$. Based on this assumption, our loss function is defined as follows:
% \begin{equation}
%     \mathcal{L}_{\text{FPR}}
%     =\lVert \tilde{\mathbf{z}}_{0} - \mathbf z^{src} \rVert _{2}^{2},
% \end{equation}
% where
% \begin{align}
% \begin{split}
%     \tilde{\mathbf{z}}_{0} 
% %    &= \mathbb{E}[\tilde{\mathbf{z}}_{0}|\hat{\mathbf{z}}_{t}] \\
%     &= \frac{1}{\sqrt{\alpha_{t}}}\left(
%     \mathbf z^{src}_t-\sqrt{1-\alpha_{t}} \hat{\epsilon}_{\phi}^\omega
%     \right).
% \end{split}
% \end{align}

%Based on DPS \cite{chungdiffusion}, we calculate the unique posterior mean $\mathbf{z}_{0|t}^\text{src}$ from $\epsilon_{\phi}^\text{src}$.
% Because the predicted value $\mathbf{z}_{0|t}^\text{src}$ should be equal to the source image $\mathbf{z}^{\text{src}}$ if the $\epsilon$ and $\epsilon_{\phi}^\text{src}$ point in the same direction, our loss function is defined as follow:

% 우리 method는 이렇게 \hat{z}를 update 시킨 후 DDS loss를 그대로 따라감도 추가
% maintain the structural consistency