\section{Preliminaries}
\label{sec:preliminary}
\newcommand{\trg}{\mathbf{z}^{\text{trg}}}
\newcommand{\trgt}{\mathbf{z}_{t}^{\text{trg}}}
\newcommand{\src}{\mathbf{z}^{\text{src}}}
\newcommand{\srct}{\mathbf{z}_{t}^{\text{src}}}
\newcommand{\srctopt}{\mathbf{z}_{t}^{\text{src}\ast}}
\newcommand{\trgtopt}{\mathbf{z}_{t}^{\text{trg}\ast}}
\newcommand{\txts}{y^{\text{src}}} % source prompt
\newcommand{\txtt}{y^{\text{trg}}} % target prompt
\newcommand{\dds}{\text{DDS}}
\newcommand{\sds}{\text{SDS}}
\newcommand{\ids}{\text{IDS}}
\newcommand{\loss}[1]{\mathcal{L}_{#1}}
\newcommand{\grad}[1]{\nabla_{#1}}
\newcommand{\pardiff}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\postmean}{\tilde{\mathbf{z}}_{0}}

\subsection{Diffusion Model and Sampling Guidance}
Text-to-image diffusion models $\epsilon_\phi(\cdot)$ are based on diffusion probabilistic models (DPMs)~\cite{ho2020denoising, song2020score, rombach2022high}. %, which are latent variable models based on Markov chain with Gaussian distribution to synthesize the data from the distribution of the given training datasets. 
The models are trained to estimate the denoising score when the original image $\mathbf{z}_0$ and the text condition $y$ are given:
\begin{equation*}
    \mathcal{L}(\phi) = \mathbb{E}_{t, \epsilon}
    [\lVert 
    \epsilon_\phi(\mathbf{z}_t, y, t) - \epsilon 
    \rVert_2^2],
\end{equation*}
where $\epsilon\sim\mathcal{N}(0, \mathbf{I})$ and $t\sim\mathcal{U}(0, 1)$. $\mathbf{z}_t$ refers to the stochastic latent of $\mathbf{z}_0$ via the forward diffusion process as follows:
\begin{equation} \label{eq:forward}
    \mathbf{z}_t=\sqrt{\alpha_t}\mathbf{z}_0+\sqrt{1-\alpha_t}\epsilon,
\end{equation}
where $\alpha_t$ is noise schedule. With the trained $\epsilon_\phi(\cdot)$, high-quality samples can be generated using the classifier-free guidance (CFG) \cite{ho2021classifier} by subtracting unconditioned denoising score from the conditioned score with guidance scale $\omega$:
\begin{equation} \label{eq:cfg}
    \epsilon_\phi^\omega(\mathbf{z}_t, y, t) 
    = (1+\omega)\epsilon_\phi(\mathbf{z}_t, y, t) 
    -\omega\epsilon_\phi(\mathbf{z}_t, \varnothing, t).
\end{equation}

\subsection{Score Distillation Sampling (SDS)}
% \label{sec:3.2}
With pretrained text-to-image diffusion models $\epsilon_\phi(\cdot)$, SDS \cite{poole2022dreamfusion} synthesizes 3D data $\mathbf{z}$ for a given text prompt $y$ by optimizing the differentiable rendering function paremetrized by $\theta$, where $\mathbf{z}=g(\theta)$:
{\small
\begin{align}
    \grad{\theta}\loss{\sds}(\mathbf{z}, y)
    &= \mathbb{E}_{t, \epsilon} 
    \left[ \omega(t)(\epsilon_\phi^\omega(\mathbf{z}_t, y, t)-\epsilon)\pardiff{\mathbf{z}}{\theta}\right].
    \label{eq:sds}
\end{align}
}
%where $t\sim\mathcal{U}(0, 1)$ and $\epsilon\sim\mathcal{N}(0, \mathbf{I})$. 
The optimized parameters $\theta^*$ provide the text-conditioned 3D volume that follows the diffusion prior~\cite{poole2022dreamfusion}. % distribution of pretrained diffusion models. 
However, a single text prompt $y$ can refer to many different 3D volumes, each with diverse backgrounds or structural details of the object. Therefore, an inherent limitation of SDS \cite{poole2022dreamfusion} is that the score conditioned by the prompt $y$ does not always provide the diffusion prior to the identical object during the optimization process, leading to blurry and unclear results. 
%When it comes to image editing, the SDS loss in \eqref{eq:sds} is computed with respect to the data itself $\mathbf{z}=\trg$ and the target text prompt $\txtt$. In particular, $\trg$ is first set as the input image $\src$. Note that the shortcomings of SDS in image editing are even more severe, as there is no guidance regarding the source image $\src$ during the updates. As shown in Fig. \ref{fig:inversion}, the edited image $\trg$ is not only blurred, but also contains the heavily altered background and structure details that are not included in the prompt $\txtt$.

\subsection{Delta Denoising Score (DDS)}
DDS \cite{hertz2023delta} is proposed to synthesize the image $\trg$ from the given source image $\src$ and its corresponding prompt $\txts$, which is aligned to the target prompt $\txtt$. 
Based on the insight that the gradient should be zero if $\txtt$ matches $\txts$, DDS minimizes the identity change of $\src$ by simple replacing $\epsilon$ in \eqref{eq:sds} with the score $\epsilon_\phi^\omega(\srct, \txts, t)$] as follows:
{\small
\begin{equation} \label{eq:dds}
% \begin{split}
    \grad{\theta}\loss{\dds}
     = \mathbb{E}_{t, \epsilon} 
    \left[ 
      (\epsilon_\phi^\omega(\trgt, \txtt, t) - {\epsilon}_{\phi}^\omega(\srct, \txts, t)) \pardiff{\trg}{\theta}\right]. %\nonumber\\
    % = \grad{\theta}\loss{\sds}(\trg, \txtt) - \grad{\theta}\loss{\sds}(\src, \txts).
% \end{split}
\end{equation}
}
%where the same $\epsilon$ is used to generate $\trgt$ and $\srct$. 
For simplicity, we denote $\epsilon_\phi^{\text{trg}}=\epsilon_\phi^\omega(\trg, \txtt, t)$ and $\epsilon_\phi^{\text{src}}=\epsilon_\phi^\omega(\src, \txts, t)$. 
Here, $\epsilon_\phi^{\text{trg}}$ and  ${\epsilon}_\phi^{\text{src}}$ can be interpreted as the gradients representing the direction from $\trgt$ to $\trg$ and the direction from $\srct$ to $\src$, respectively.
$\theta = \trg$ is thus gradually optimized along the direction from $\src$ to $\trg$, as shown in \cref{fig:algorithm}.
It is worth noting that the guidance of the update can be calculated at the same point $\trgt$, thanks to the shared $\epsilon$.
%DDS reduces the uncertainty caused by SDS loss and provides more clear results.
However, the slight error in the gradient caused by the score ${\epsilon}_\phi^{\text{src}}$ still leads to the incorrect direction for the optimization. 


\subsection{Fixed-point Iteration}

% \add{Explanation of fixed-point iteration and applications of fixed-point iteration to the diffusion model}
In numerical analysis, a fixed-point iteration \cite{parikh2014proximal} is an iterative method to find fixed points of a function $f$, where $f(x) = x.$ Given an initial point $x_0$, the iteration is defined as: 
\begin{equation*}
x_{n+1} = f(x_n), \quad n = 0, 1, 2, \ldots
\end{equation*}
Under appropriate conditions, this sequence converges to a fixed point. Thanks to its applicability to non-linear problems with low computational costs, fixed-point iteration is widely used in optimization, including applications in the context of diffusion models \cite{meiri2023fixed}. 

%These can also be applied to text-guided diffusion models, potentially enhancing their performance. Null-text Inversion \cite{mokady2023null} replaces the traditional approach of mapping all noise vectors to a single image using random noise for each optimization iteration with a more local optimization that employs a single noise vector. 
%Specifically, drawing inspiration from GAN literature, it leverages the sequence of noised latent codes obtained from an initial DDIM inversion as a pivot. The optimization is then performed around this pivot, leading to a more refined and accurate inversion. However, since this method relies on a fixed pivot, it struggles to fully preserve the complex structural consistency of the original image. We propose a novel model that utilizes fixed-point iteration to correct the gradient direction aligned with the source prompt, thereby ensuring that the structure of the source image is preserved while selectively editing the target image.