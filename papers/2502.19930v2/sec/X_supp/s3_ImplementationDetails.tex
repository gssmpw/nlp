\section{Implementation details}
\label{sec:s_implement}
% which model we used
% about baselines
% how to calculate background psnr & IoU
% calculated mask examples
For experiments, we implement our method based on the official code of CDS \footnote{\url{https://hyelinnam.github.io/CDS/}} by using Stable Diffusion v1.4. All baselines are implemented based on the official code and setting for each method.
For the proposed FPR, we set the scale $\lambda$ to $1.0$ and iteration $N$ to 3. 
The range of timesteps, optimization, learning rate, and number of optimization steps correspond to the default settings employed in DDS and CDS. 
% for experimental results in the main paper. 
All experiments are conducted on a single NVIDIA RTX 3090.

%\paragraph{IoU} To calculate IoU for \textit{Cat-to-Others} task, we use the language Segment-Anything model (lang-SAM)\footnote{\url{https://github.com/paulguerrero/lang-sam}}, which is an open-source project to segment some objects from the text prompt. First, the mask about the prompt is obtained from an image using lang-SAM. For example, `cat' is segmented from the source image to get the mask $M_{\text{src}}$, while `dog' is segmented from the edited image to obtain the mask $M_{\text{trg}}$, as shown in \cref{fig:sup_mask} (a). After getting masks, we calculate IoU from the masks that is given by:
%\begin{equation*}
%    \text{IoU}=\frac{\left(M_{\text{src}} \cap M_{\text{trg}}\right)}{\left(M_{\text{src}}\cup M_{\text{trg}}\right)}
%\end{equation*}

%\paragraph{Background PSNR} Since the editing prompts of IP2P dataset~\cite{brooks2023instructpix2pix} is complex than \textit{Cat-to-Others} dataset~\cite{schuhmann2022laion, nam2024contrastive}, it is hard to get mask by lang-SAM. Therefore, we use background PSNR to evaluate how much the original information is preserved. The residual of the source and target images is calculated, and the standard deviation $\sigma$ of each pixel of the residual image is computed with window size 30. Then, the mask $M_{\text{PSNR}}$ is acquired by thresholding the $\sigma$ to the mean or median value of $\sigma$ as shown in \cref{fig:sup_mask} (b). Finally, we get PSNR values from masked source and target images: 
%\begin{equation*}
 %   \text{PSNR}_{\text{back}}=\text{PSNR}(M_{\text{PSNR}} \odot \mathbf{z}_{\text{src}}, M_{\text{PSNR}} \odot \mathbf{z}_{\text{trg}})
%\end{equation*}
%where $\odot$ is pixel-wise multiplication.
%\input{sec/X_supp/Fig/comp/mask}
