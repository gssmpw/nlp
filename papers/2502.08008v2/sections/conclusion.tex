\section{Conclusion}
Our study highlights the critical role of parameter selection and the interpretation of privacy costs in different application settings. 
%
By examining the interplay between federated learning and differential privacy, we demonstrate how thoughtful parameter tuning can significantly impact both model utility and privacy guarantees. 
%
A promising direction for future work is to expand this study with more comprehensive experiments, considering diverse data types such as images and text to further generalize our findings. 
%
Additionally, further evaluation of \sys~with the replace-one adjacency relation could provide deeper insights into its effect on privacy guarantees and model utility, offering valuable guidance for privacy-preserving federated learning deployments.
