 \section{Preliminaries}
In this section, we reivew
We examine three key areas of the literature: (1) FL, a distributed machine learning approach that trains models across multiple devices; (2) Differentially private deep learning, a comprehensive framework that ensures rigorous privacy during the learning process; and (3) The benefits of using differentially private stochastic gradient descent with fixed-size minibatches compared to Poisson-subsampled \rdp. 
\subsection{Federated Learning}

Federated Learning (FL) enables the distributed training of a central model, with contributions from a set of clients who each train a local copy of the model using their own data \cite{mcmahan2017communication}. 
FL considers a central server who aggregates the updates shared by the clients. 
 A generic FL system consists of  a central server and \( k \) clients. Each client \( C_i \) holds a local dataset \( D_i \), where \( i \in \{1, 2, \dots, k\} \). The server's objective is to train a model using data distributed across the \( k \) clients. When a client actively participates in local training, it aims to optimize a vector $\mathbf{w}$ for an AI model by minimizing a specified loss function. The server then aggregates the model weights received from the \( k \) clients as follows:\[ \mathrm{w}=\sum_{i=1}^{k} p_i\mathrm{w}_i \]
Here, \( \mathrm{w}_i \) represents the parameter vector trained by the \( i \)-th client, and  w is the aggregated parameter vector at the server. \( k \) denotes the total number of clients, while \( p_i = \frac{|D_i|}{|D|} \geq 0 \) satisfies \( \sum_{i=1}^{k} p_i = 1 \), with \( |D| = \sum_{i=1}^{k} |D_i| \) being the total number of data samples across all clients. This optimization problem can be expressed as:
\[ \mathrm{w^*}=\mathrm{argmin_w}\sum_{i=1}^{k}p_iF_i(\mathrm{w}) \] 
where \( F_i(w) \) represents the local loss function for the \( i \)-th client.

In the FL process, the \( k \) clients work together to train a machine-learning model with the assistance of a server. After several rounds of local training and updates exchanged between the server and the clients, the solution to the optimization problem is expected to converge to the globally optimal learning model.
\subsection{Differential Privacy}
Differential privacy \cite{dwork2006calibrating,dwork2014algorithmic} is a rigorous privacy framework that effectively mitigates the privacy risks associated with deep learning \cite{abadi2016deep}. The primary distinction between DP-based deep learning and standard deep learning lies in whether the gradient is released with privacy guarantees.\\
\textit{Definition 1}: A randomized algorithm  \( M \) is \((\epsilon, \delta)\)-differentially private if, for any two neighboring datasets \( S \) and \( S' \) (i.e., \( S' \) can be obtained by adding or removing a single data point from \( S \)), and for any event \( E \), the following condition holds :
\[ P[M(S) \in E] \leq e^\epsilon P[M(S') \in E] + \delta. \] 
We consider the \((\epsilon, \delta)\)-DP definition, where smaller values of \(\epsilon\) and \(\delta\) indicate a stronger privacy guarantee.

Differentially Private Stochastic Gradient Descent (DP-SGD) \cite{abadi2016deep} ensures differential privacy by introducing noise during the training process of machine learning models. DP-SGD modifies the standard mini-batch SGD algorithm by adding two additional steps:
\begin{itemize}
    \item Gradient Clipping: For each per-example gradient \( g(x_i) \), where \( x_i \) is a data point in the selected mini-batch, clip the \( l_2 \)-norm to a predefined threshold \( C \):  
   \[
   g(x_i) \gets \frac{g(x_i)}{\max(1, \|g(x_i)\|_2 / C)}.
   \]
   \item Noise Addition: Add Gaussian noise to the aggregated gradient of the mini-batch, where \( L \) is the mini-batch size and \( \sigma \) is the noise scale.:
   \[
   g \gets \frac{1}{L} \left( \sum_{i} g(x_i) + \mathcal{N}(0, \sigma^2 C^2) \right),
   \]
\end{itemize}
\subsection{\rdp~and \sys}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.75\columnwidth]{mem_usage.pdf}
    \caption{Comparison of \sys~and \rdp~accountant memory usage with a batch size of 120 and a dataset size of 50,000 per training epoch \cite{birrell2024differentially}.}
    \label{fig:memory}
\end{figure}
DP-SGD enables the use of a technique known as the moments accountant to sequentially monitor privacy leakage. This approach is encompassed by Rényi Differential Privacy (\rdp) \cite{mironov2017renyi}, a relaxed version of standard Differential Privacy \cite{dwork2016concentrated}. \rdp~is widely applied in private deep learning and is incorporated into modern DP libraries like Opacus\cite{opacus}. The underlying computation in \rdp~relies on subsampling techniques that use a privacy amplification lemma to enhance the privacy guarantees provided by the added noise.
% , \(f\)-DP \cite{dong2022gaussian}, Privacy Random Variable (PRV) \cite{gopi2021numerical}, and Analytical Fourier Accountant (AFA) \cite{zhu2022optimal} 

While there have been previous attempts to compute privacy costs with a fixed mini-batch size, such as the works of Balle et al. \cite {balle2018privacy} for $(\epsilon,\delta)$-DP and Wang et al. \cite{wang2019subsampled} for \rdp, these approaches had significant shortcomings. The earlier $(\epsilon,\delta)$-DP methods did not compose easily over multiple training steps, often leading to privacy leakage, making them impractical for iterative processes like SGD. Similarly, Wang’s \rdp~accountant was not as tight, resulting in suboptimal privacy bounds. In contrast, \sys~\cite{birrell2024differentially} is the first privacy accountant capable of computing privacy costs with fixed-size mini-batches while achieving much tighter bounds. In fact, \sys~is very close to the theoretical lower bound in many practical cases, offering significantly improved privacy guarantees over previous RDP-based methods.

This offers a significant advantage of consistent memory usage compared to the variable-sized mini-batches in Poisson subsampling.
While the results in \cite{birrell2024differentially} were purely theoretical, in this paper, by highlighting the importance of fixed memory usage in FL settings, we adopt their accountant, and after conducting extensive experiments, we show that for certain applications and data distributions, the accuracy loss, compared to \rdp~is insignificant. 
Figure 1 depicts the memory consumption of \sys~and \rdp~accountants. In contrast to \rdp, \sys~maintains a constant memory footprint throughout the training process.
