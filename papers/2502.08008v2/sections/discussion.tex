\subsection{Discussion}
Our research is the first in FL-DP to highlight the critical role of federated learning and differential privacy parameters, as well as their combined effect on model privacy and utility. 
%
\oursys~integrates a human practitioner who suggests privacy and FL parameters to help strike an optimal balance between privacy and utility in these environments. 
%
We focus on the widely adopted task of fine-tuning large language models (LLMs) and illustrate how key parameters such as privacy cost, data distribution, and client selection strategies affect model performance. 
%
\oursys~is also the first privacy-preserving framework to address the memory constraints of mobile devices in an FL setting by employing a privacy accountant with fixed memory requirements, achieved through a fixed minibatch size. 
%
Finally, we offer a detailed comparison between fixed-size minibatch accounting and the state-of-the-art \rdp~approach, highlighting the trade-offs in privacy and utility. 
%
The \sys~accountant provides advantages such as achieving an acceptable maximum accuracy and uniform memory usage. 
%
However, our experiments indicate that while the model performs well in the initial rounds using \sys~accountant, its accuracy may decline in the later stages.
%
This drop is caused by the cumulative effect of noise introduced by the \sys~accountant and imbalances in client contributions.
%
To overcome these challenges, we propose strategies like dynamically adjusting noise levels during training to better balance privacy and accuracy, as well as ensuring balanced client sampling to improve stability in the later rounds.