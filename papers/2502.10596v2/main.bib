@misc{balioglu2023fairseq2,
  author = {Can Balioglu},
  title = {fairseq2},
  url = {http://github.com/facebookresearch/fairseq2},
  year = {2023},
}

@misc{AwesomeLLMPromptOptimization,
  author = {Jiaxin Zhang, Han Zhou, Xiaopeng Li},
  title = {Awesome-LLM-Prompt-Optimization},
  url = {https://github.com/jxzhangjhu/Awesome-LLM-Prompt-Optimization},
  year = {2024},
}

@Article{Asai2024ReliableAA,
  author = {Akari Asai and Zexuan Zhong and Danqi Chen and Pang Wei Koh and Luke Zettlemoyer and Hanna Hajishirzi and Wen-tau Yih},
  booktitle = {arXiv.org},
  journal = {ArXiv},
  title = {Reliable, Adaptable, and Attributable Language Models with Retrieval},
  volume = {abs/2403.03187},
  year = {2024},
  annote = { 
    A position paper with an overview of several architectures.  
    We focus on methods within their ``input augmentation'' framework.
  },
}

@inproceedings{
Shi2023InContextPL,
title={In-Context Pretraining: Language Modeling Beyond Document Boundaries},
author={Weijia Shi and Sewon Min and Maria Lomeli and Chunting Zhou and Margaret Li and Xi Victoria Lin and Noah A. Smith and Luke Zettlemoyer and Wen-tau Yih and Mike Lewis},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=LXVswInHOo}
}

@Article{Chen2017ReadingWT,
 author = {Danqi Chen and Adam Fisch and J. Weston and Antoine Bordes},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {ArXiv},
 title = {Reading Wikipedia to Answer Open-Domain Questions},
 volume = {abs/1704.00051},
 year = {2017},
 annote = {
   Pioneering work on RAG. Known as DrQA.
 }
}

@inproceedings{
  yao2023react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=WE_vluYUL-X},
  annote={
    From Princeton. ``Thinking'' and ``acting'' modules work in concert to accomplish tasks.
      Arming an LLM with a Wikipedia API as an action, better results on HotPotQA than CoT alone.
  }
}

@inproceedings{luo-etal-2023-search,
  title = "Search Augmented Instruction Learning",
  author = "Luo, Hongyin  and
    Zhang, Tianhua  and
    Chuang, Yung-Sung  and
    Gong, Yuan  and
    Kim, Yoon  and
    Wu, Xixin  and
    Meng, Helen  and
    Glass, James",
  editor = "Bouamor, Houda  and
    Pino, Juan  and
    Bali, Kalika",
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-emnlp.242",
  doi = "10.18653/v1/2023.findings-emnlp.242",
  pages = "3717--3729",
  abstract = "Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing (instruction, grounding information, response) triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking.",
  annote = {
    SAIL fine-tunes a model on RAG instruction following with GPT-4 providing demonstrations,
    also learns to identify which docs are relevant. 
    They order retrievals by relevance, determined by a classifier.
    Our work generalizes their method to more sophisticated pipelines 
    and avoids training on OOD demonstrations by a stronger model.
  }
}

@article{Izacard2023AtlasFL,
  author  = {Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
  title   = {Atlas: Few-shot Learning with Retrieval Augmented Language Models},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {251},
  pages   = {1--43},
  url     = {http://jmlr.org/papers/v24/23-0037.html},
  annote = {
    From Cohere and Meta, Atlas is a text2text model (T5 based) pretrained for RAG.
      Related work contains a useful overview of RALM methods.
    See also
    \begin{itemize}
      \item Contriever (Izacard) to bib.
      \item kNN-LM
      \item RETRO
    \end{itemize}
  }
}

@inproceedings{izacard-grave-2021-leveraging,
  title = "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
  author = "Izacard, Gautier  and
    Grave, Edouard",
  editor = "Merlo, Paola  and
    Tiedemann, Jorg  and
    Tsarfaty, Reut",
  booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
  month = apr,
  year = "2021",
  address = "Online",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2021.eacl-main.74",
  doi = "10.18653/v1/2021.eacl-main.74",
  pages = "874--880",
  abstract = "Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.",
  annote = {
    A vanilla RAG method.
  }
}

@article{Ram2023InContextRL,
  title={In-Context Retrieval-Augmented Language Models},
  author={Ori Ram and Yoav Levine and Itay Dalmedigos and Dor Muhlgay and Amnon Shashua and Kevin Leyton-Brown and Yoav Shoham},
  journal={Transactions of the Association for Computational Linguistics},
  year={2023},
  volume={11},
  pages={1316-1331},
  url={https://api.semanticscholar.org/CorpusID:256459451},
  annote={
    From AI21, a RALM method that just prepends relevant docs, always.
  }
}

@article{Yoran2023MakingRL,
  title={Making Retrieval-Augmented Language Models Robust to Irrelevant Context},
  author={Ori Yoran and Tomer Wolfson and Ori Ram and Jonathan Berant},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.01558},
  url={https://api.semanticscholar.org/CorpusID:263608822},
  annote={
    Tel Aviv University and AI2 present a fine-tuning method 
      to make models robust to irrelevant context
      by adding irrelevant context to the retrieval.
      For single hop, they only use gold demos.
      For multi-hop, they use a strong LLM to generate decomposition demos.
      Focus on a small data set.
      Similar to KAFT from \cite{li-etal-2023-large},
    but with a smaller data set.
      What happens when they compare to KAFT?
  }
}

@inproceedings{li-etal-2023-large,
  title = "Large Language Models with Controllable Working Memory",
  author = "Li, Daliang  and
    Rawat, Ankit Singh  and
    Zaheer, Manzil  and
    Wang, Xin  and
    Lukasik, Michal  and
    Veit, Andreas  and
    Yu, Felix  and
    Kumar, Sanjiv",
  editor = "Rogers, Anna  and
    Boyd-Graber, Jordan  and
    Okazaki, Naoaki",
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  month = jul,
  year = "2023",
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-acl.112",
  doi = "10.18653/v1/2023.findings-acl.112",
  pages = "1774--1793",
  abstract = "Large language models (LLMs) have led to a series of breakthroughs in natural language processing (NLP), partly owing to the massive amounts of world knowledge they memorize during pretraining. While many downstream applications provide the model with an informational context to aid its underlying task, how the model{'}s world knowledge interacts with the factual information presented in the context remains under explored. As a desirable behavior, an LLM should give precedence to the context whenever it contains task-relevant information that conflicts with the model{'}s memorized knowledge. This enables model predictions to be grounded in the context, which then facilitates updating specific model predictions without frequently retraining the model. By contrast, when the context is irrelevant to the task, the model should ignore it and fall back on its internal knowledge. In this paper, we undertake a first joint study of the aforementioned two properties, namely controllability and robustness, in the context of LLMs. We demonstrate that state-of-the-art T5 and PaLM models (both pretrained and finetuned) could exhibit low controllability and robustness that does not improve with increasing the model size. As a solution, we propose a simple yet effective method {--} knowledge aware finetuning (KAFT) {--} to strengthen both controllability and robustness by injecting counterfactual and irrelevant contexts to standard supervised datasets. Our comprehensive evaluation showcases the utility of KAFT across model architectures and sizes.",
  annote={
    Google presents KAFT 
      which fine-tunes a LLM on RAG instruction tasks with irrelevant context
      and counterfactual context to increase the \textit{robustness} 
    and \textit{controllability}~\citep{longpre-etal-2021-entity}
    of the model.
  }
}

@inproceedings{longpre-etal-2021-entity,
  title = "Entity-Based Knowledge Conflicts in Question Answering",
  author = "Longpre, Shayne  and
    Perisetla, Kartik  and
    Chen, Anthony  and
    Ramesh, Nikhil  and
    DuBois, Chris  and
    Singh, Sameer",
  editor = "Moens, Marie-Francine  and
    Huang, Xuanjing  and
    Specia, Lucia  and
    Yih, Scott Wen-tau",
  booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
  month = nov,
  year = "2021",
  address = "Online and Punta Cana, Dominican Republic",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2021.emnlp-main.565",
  doi = "10.18653/v1/2021.emnlp-main.565",
  pages = "7052--7063",
  abstract = "Knowledge-dependent tasks typically use two sources of knowledge: parametric, learned at training time, and contextual, given as a passage at inference time. To understand how models use these sources together, we formalize the problem of knowledge conflicts, where the contextual information contradicts the learned information. Analyzing the behaviour of popular models, we measure their over-reliance on memorized information (the cause of hallucinations), and uncover important factors that exacerbate this behaviour. Lastly, we propose a simple method to mitigate over-reliance on parametric knowledge, which minimizes hallucination, and improves out-of-distribution generalization by 4{\%} - 7{\%}. Our findings demonstrate the importance for practitioners to evaluate model tendency to hallucinate rather than read, and show that our mitigation strategy encourages generalization to evolving information (i.e. time-dependent queries). To encourage these practices, we have released our framework for generating knowledge conflicts.",
  annote = {
    Train model on counterfactual contexts to increase \textit{controllability}
    (e.g., answer according to context, not parameteric knowledge)
  }
}

@Article{Neeman2022DisentQADP,
 author = {Ella Neeman and Roee Aharoni and Or Honovich and Leshem Choshen and Idan Szpektor and Omri Abend},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {ArXiv},
 title = {DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering},
 volume = {abs/2211.05655},
 year = {2022},
 annote = {
   Hewbrew University, Google, and Tel Aviv University's 
     concurrent work with \citep{longpre-etal-2021-entity} 
   exploring how to deal with paramteric and contextual knowledge conflict.
 }
}

@Article{Liu2024RAISFLT,
 author = {Yanming Liu and Xinyue Peng and Xuhong Zhang and Weihao Liu and Jianwei Yin and Jiannan Cao and Tianyu Du},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback},
 volume = {abs/2403.06840},
 year = {2024},
 annote = {
   From Zhejian Univeristy, Southeast University, and MIT comes RA-ISF,
   a prompt-based pipeline for RAG.
     They beat self-RAG on a number of datasets.
 }
}

@inproceedings{wang2023selfinstructaligninglanguagemodels,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.754/",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
    abstract = "Large {\textquotedblleft}instruction-tuned{\textquotedblright} language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33{\%} absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5{\%} absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning."
}

@inproceedings{lin2023traindragondiverseaugmentation,
    title = "How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval",
    author = "Lin, Sheng-Chieh  and
      Asai, Akari  and
      Li, Minghan  and
      Oguz, Barlas  and
      Lin, Jimmy  and
      Mehdad, Yashar  and
      Yih, Wen-tau  and
      Chen, Xilun",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.423/",
    doi = "10.18653/v1/2023.findings-emnlp.423",
    pages = "6385--6400",
    abstract = "Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing model size. In particular, we systematically examine the contrastive learning of DRs, under the framework of Data Augmentation (DA). Our study shows that common DA practices such as query augmentation with generative models and pseudo-relevance label creation using a cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA approach with diverse queries and sources of supervision to progressively train a generalizable DR. As a result, DRAGON, our Dense Retriever trained with diverse AuGmentatiON, is the first BERT-base-sized DR to achieve state-of-the-art effectiveness in both supervised and zero-shot evaluations and even competes with models using more complex late interaction."
}

@misc{weston20232attentionisneed,
  title={System 2 Attention (is something you might need too)}, 
  author={Jason Weston and Sainbayar Sukhbaatar},
  year={2023},
  eprint={2311.11829},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.11829}, 
  annote={
    Ignore irrelevant context by prompting the model to remove irrelevant and biasing content.
  },
}

@misc{lin2024raditretrievalaugmenteddualinstruction,
      title={RA-DIT: Retrieval-Augmented Dual Instruction Tuning}, 
      author={Xi Victoria Lin and Xilun Chen and Mingda Chen and Weijia Shi and Maria Lomeli and Rich James and Pedro Rodriguez and Jacob Kahn and Gergely Szilvasy and Mike Lewis and Luke Zettlemoyer and Scott Yih},
      year={2024},
      eprint={2310.01352},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.01352}, 
}

@inproceedings{
lin2024radit,
title={{RA}-{DIT}: Retrieval-Augmented Dual Instruction Tuning},
author={Xi Victoria Lin and Xilun Chen and Mingda Chen and Weijia Shi and Maria Lomeli and Richard James and Pedro Rodriguez and Jacob Kahn and Gergely Szilvasy and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=22OTbutug9}
}

@inproceedings{
Lin2024FLAMEFA,
title={{FLAME} : Factuality-Aware Alignment for Large Language Models},
author={Sheng-Chieh Lin and Luyu Gao and Barlas Oguz and Wenhan Xiong and Jimmy Lin and Wen-tau Yih and Xilun Chen},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=zWuHSIALBh}
}

% multi-hop papers begin
@article{lazaridou2022internet,
  title={Internet-augmented language models through few-shot prompting for open-domain question answering},
  author={Lazaridou, Angeliki and Gribovskaya, Elena and Stokowiec, Wojciech and Grigorev, Nikolai},
  journal={arXiv preprint arXiv:2203.05115},
  year={2022}
}
@article{press2022measuring,
  title={Measuring and narrowing the compositionality gap in language models},
  author={Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.03350},
  year={2022}
}
@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}
@article{khattab2022demonstrate,
  title={Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp},
  author={Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2212.14024},
  year={2022}
}

@inproceedings{
khot2023decomposed,
title={Decomposed Prompting: A Modular Approach for Solving Complex Tasks},
author={Tushar Khot and Harsh Trivedi and Matthew Finlayson and Yao Fu and Kyle Richardson and Peter Clark and Ashish Sabharwal},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=_nGgzQjzaRy}
}


@article{yoran2023answering,
  title={Answering questions by meta-reasoning over multiple chains of thought},
  author={Yoran, Ori and Wolfson, Tomer and Bogin, Ben and Katz, Uri and Deutch, Daniel and Berant, Jonathan},
  journal={arXiv preprint arXiv:2304.13007},
  year={2023}
}
@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}
% multi-hop papers end

% rag llms begin
@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle={International conference on machine learning},
  pages={3929--3938},
  year={2020},
  organization={PMLR},
  annote = {
    Pretraining an LM to be better at RAG. Doesn't seem to have caught on much.
      Perhaps it is too much of an investment to go all in on this.
  }
}

@article{Lewis2020RetrievalAugmentedGF,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}

@inproceedings{shi2023replug,
  title={REPLUG: Retrieval-Augmented Black-Box Language Models},
  author={Weijia Shi and Sewon Min and Michihiro Yasunaga and Minjoon Seo and Rich James and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:256389797}
}

@misc{yang2024cragcomprehensiverag,
  title={CRAG -- Comprehensive RAG Benchmark}, 
  author={Xiao Yang and Kai Sun and Hao Xin and Yushi Sun and Nikita Bhalla and Xiangsen Chen and Sajal Choudhary and Rongze Daniel Gui and Ziran Will Jiang and Ziyu Jiang and Lingkun Kong and Brian Moran and Jiaqi Wang and Yifan Ethan Xu and An Yan and Chenyu Yang and Eting Yuan and Hanwen Zha and Nan Tang and Lei Chen and Nicolas Scheffer and Yue Liu and Nirav Shah and Rakesh Wanga and Anuj Kumar and Wen-tau Yih and Xin Luna Dong},
  year={2024},
  eprint={2406.04744},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.04744}, 
}

@misc{panickssery2024llmevaluatorsrecognizefavor,
  title={LLM Evaluators Recognize and Favor Their Own Generations}, 
  author={Arjun Panickssery and Samuel R. Bowman and Shi Feng},
  year={2024},
  eprint={2404.13076},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.13076}, 
}

@misc{cai2024internlm2technicalreport,
  title={InternLM2 Technical Report}, 
  author={Zheng Cai and Maosong Cao and Haojiong Chen and Kai Chen and Keyu Chen and Xin Chen and Xun Chen and Zehui Chen and Zhi Chen and Pei Chu and Xiaoyi Dong and Haodong Duan and Qi Fan and Zhaoye Fei and Yang Gao and Jiaye Ge and Chenya Gu and Yuzhe Gu and Tao Gui and Aijia Guo and Qipeng Guo and Conghui He and Yingfan Hu and Ting Huang and Tao Jiang and Penglong Jiao and Zhenjiang Jin and Zhikai Lei and Jiaxing Li and Jingwen Li and Linyang Li and Shuaibin Li and Wei Li and Yining Li and Hongwei Liu and Jiangning Liu and Jiawei Hong and Kaiwen Liu and Kuikun Liu and Xiaoran Liu and Chengqi Lv and Haijun Lv and Kai Lv and Li Ma and Runyuan Ma and Zerun Ma and Wenchang Ning and Linke Ouyang and Jiantao Qiu and Yuan Qu and Fukai Shang and Yunfan Shao and Demin Song and Zifan Song and Zhihao Sui and Peng Sun and Yu Sun and Huanze Tang and Bin Wang and Guoteng Wang and Jiaqi Wang and Jiayu Wang and Rui Wang and Yudong Wang and Ziyi Wang and Xingjian Wei and Qizhen Weng and Fan Wu and Yingtong Xiong and Chao Xu and Ruiliang Xu and Hang Yan and Yirong Yan and Xiaogui Yang and Haochen Ye and Huaiyuan Ying and Jia Yu and Jing Yu and Yuhang Zang and Chuyu Zhang and Li Zhang and Pan Zhang and Peng Zhang and Ruijie Zhang and Shuo Zhang and Songyang Zhang and Wenjian Zhang and Wenwei Zhang and Xingcheng Zhang and Xinyue Zhang and Hui Zhao and Qian Zhao and Xiaomeng Zhao and Fengzhe Zhou and Zaida Zhou and Jingming Zhuo and Yicheng Zou and Xipeng Qiu and Yu Qiao and Dahua Lin},
  year={2024},
  eprint={2403.17297},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2403.17297}, 
}

@article{Yu2024DistillingS2,
  title={Distilling System 2 into System 1},
  author={Ping Yu and Jing Xu and Jason Weston and Ilia Kulikov},
  journal={ArXiv},
  year={2024},
  volume={abs/2407.06023},
  url={https://api.semanticscholar.org/CorpusID:271050364}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{deng2023rephrase,
  title={Rephrase and respond: Let large language models ask better questions for themselves},
  author={Deng, Yihe and Zhang, Weitong and Chen, Zixiang and Gu, Quanquan},
  journal={arXiv preprint arXiv:2311.04205},
  year={2023}
}

@article{wen2024know,
  title={Know your limits: A survey of abstention in large language models},
  author={Wen, Bingbing and Yao, Jihan and Feng, Shangbin and Xu, Chenjun and Tsvetkov, Yulia and Howe, Bill and Wang, Lucy Lu},
  journal={arXiv preprint arXiv:2407.18418},
  year={2024}
}

@inproceedings{
yang2023alignment,
title={Alignment for Honesty},
author={Yuqing Yang and Ethan Chern and Xipeng Qiu and Graham Neubig and Pengfei Liu},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=67K3Xlvw8L}
}

@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421/",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
    abstract = "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}."
}

@inproceedings{yang-etal-2018-hotpotqa,
    title = "{H}otpot{QA}: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    author = "Yang, Zhilin  and
      Qi, Peng  and
      Zhang, Saizheng  and
      Bengio, Yoshua  and
      Cohen, William  and
      Salakhutdinov, Ruslan  and
      Manning, Christopher D.",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1259/",
    doi = "10.18653/v1/D18-1259",
    pages = "2369--2380",
    abstract = "Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems' ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions."
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1074/",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
    abstract = "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources."
}

@inproceedings{
hendrycks2021measuring,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=d7KBjmI3GmQ}
}

@inproceedings{levy-etal-2017-zero,
    title = "Zero-Shot Relation Extraction via Reading Comprehension",
    author = "Levy, Omer  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Zettlemoyer, Luke",
    editor = "Levy, Roger  and
      Specia, Lucia",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1034/",
    doi = "10.18653/v1/K17-1034",
    pages = "333--342",
    abstract = "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task."
}

@inproceedings{
dinan2018wizard,
title={Wizard of Wikipedia: Knowledge-Powered Conversational Agents},
author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=r1l73iRqKm},
}

@inproceedings{elsahar-etal-2018-rex,
    title = "{T}-{RE}x: A Large Scale Alignment of Natural Language with Knowledge Base Triples",
    author = "Elsahar, Hady  and
      Vougiouklis, Pavlos  and
      Remaci, Arslen  and
      Gravier, Christophe  and
      Hare, Jonathon  and
      Laforest, Frederique  and
      Simperl, Elena",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Hasida, Koiti  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tokunaga, Takenobu",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1544/"
}

@inproceedings{fan-etal-2019-eli5,
    title = "{ELI}5: Long Form Question Answering",
    author = "Fan, Angela  and
      Jernite, Yacine  and
      Perez, Ethan  and
      Grangier, David  and
      Weston, Jason  and
      Auli, Michael",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1346/",
    doi = "10.18653/v1/P19-1346",
    pages = "3558--3567",
    abstract = "We introduce the first large-scale corpus for long form question answering, a task requiring elaborate and in-depth answers to open-ended questions. The dataset comprises 270K threads from the Reddit forum {\textquotedblleft}Explain Like I`m Five{\textquotedblright} (ELI5) where an online community provides answers to questions which are comprehensible by five year olds. Compared to existing datasets, ELI5 comprises diverse questions requiring multi-sentence answers. We provide a large set of web documents to help answer the question. Automatic and human evaluations show that an abstractive model trained with a multi-task objective outperforms conventional Seq2Seq, language modeling, as well as a strong extractive baseline. However, our best model is still far from human performance since raters prefer gold responses in over 86{\%} of cases, leaving ample opportunity for future improvement."
}

@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026/",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature."
}

@inproceedings{joshi-etal-2017-triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147/",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study."
}

@inproceedings{kopf2023openassistant,
  author = {K\"{o}pf, Andreas and Kilcher, Yannic and von R\"{u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Rich\'{a}rd and ES, Shahul and Suri, Sameer and Glushkov, David and Dantuluri, Arnav and Maguire, Andrew and Schuhmann, Christoph and Nguyen, Huu and Mattick, Alexander},
  title = {OpenAssistant conversations - democratizing large language model alignment},
  year = {2023},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
  articleno = {2064},
  numpages = {13},
  location = {New Orleans, LA, USA},
  series = {NIPS '23},
}

@article{kang2024unfamiliar,
  title={Unfamiliar finetuning examples control how language models hallucinate},
  author={Kang, Katie and Wallace, Eric and Tomlin, Claire and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2403.05612},
  year={2024}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@inproceedings{khattab2024dspy,
  title={DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  journal={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@misc{yuksekgonul2024textgrad,
      title={TextGrad: Automatic "Differentiation" via Text},
      author={Mert Yuksekgonul and Federico Bianchi and Joseph Boen and Sheng Liu and Zhi Huang and Carlos Guestrin and James Zou},
      year={2024},
      eprint={2406.07496},
      archivePrefix={arXiv}
}

@inproceedings{Reid2023AutomaticPO,
  author={Reid Pryzant and Dan Iter and Jerry Li and Yin Tat Lee and Chenguang Zhu and Michael Zeng},
  title={Automatic Prompt Optimization with "Gradient Descent" and Beam Search},
  year={2023},
  cdate={1672531200000},
  pages={7957-7968},
  url={https://aclanthology.org/2023.emnlp-main.494},
  booktitle={EMNLP},
}


@inproceedings{zhou2023lima,
 author = {Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and YU, LILI and Zhang, Susan and Ghosh, Gargi and Lewis, Mike and Zettlemoyer, Luke and Levy, Omer},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {55006--55021},
 publisher = {Curran Associates, Inc.},
 title = {LIMA: Less Is More for Alignment},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}
