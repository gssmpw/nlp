@article{Izacard2023AtlasFL,
  author  = {Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
  title   = {Atlas: Few-shot Learning with Retrieval Augmented Language Models},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {251},
  pages   = {1--43},
  url     = {http://jmlr.org/papers/v24/23-0037.html},
  annote = {
    From Cohere and Meta, Atlas is a text2text model (T5 based) pretrained for RAG.
      Related work contains a useful overview of RALM methods.
    See also
    \begin{itemize}
      \item Contriever (Izacard) to bib.
      \item kNN-LM
      \item RETRO
    \end{itemize}
  }
}

@article{Lewis2020RetrievalAugmentedGF,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{Yu2024DistillingS2,
  title={Distilling System 2 into System 1},
  author={Ping Yu and Jing Xu and Jason Weston and Ilia Kulikov},
  journal={ArXiv},
  year={2024},
  volume={abs/2407.06023},
  url={https://api.semanticscholar.org/CorpusID:271050364}
}

@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle={International conference on machine learning},
  pages={3929--3938},
  year={2020},
  organization={PMLR},
  annote = {
    Pretraining an LM to be better at RAG. Doesn't seem to have caught on much.
      Perhaps it is too much of an investment to go all in on this.
  }
}

@inproceedings{luo-etal-2023-search,
  title = "Search Augmented Instruction Learning",
  author = "Luo, Hongyin  and
    Zhang, Tianhua  and
    Chuang, Yung-Sung  and
    Gong, Yuan  and
    Kim, Yoon  and
    Wu, Xixin  and
    Meng, Helen  and
    Glass, James",
  editor = "Bouamor, Houda  and
    Pino, Juan  and
    Bali, Kalika",
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-emnlp.242",
  doi = "10.18653/v1/2023.findings-emnlp.242",
  pages = "3717--3729",
  abstract = "Large language models (LLMs) have been significantly improved by instruction fine-tuning, but still lack transparency and the ability to utilize up-to-date knowledge and information. In this work, we propose search-augmented instruction learning (SAIL), which grounds the language generation and instruction following abilities on complex search results generated by in-house and external search engines. With an instruction tuning corpus, we collect search results for each training case from different search APIs and domains, and construct a new search-grounded training set containing (instruction, grounding information, response) triplets. We then fine-tune the LLaMA-7B model on the constructed training set. Since the collected results contain unrelated and disputing languages, the model needs to learn to ground on trustworthy search results, filter out distracting passages, and generate the target response. The search result-denoising process entails explicit trustworthy information selection and multi-hop reasoning, since the retrieved passages might be informative but not contain the instruction-following answer. Experiments show that the fine-tuned SAIL-7B model has a strong instruction-following ability, and it performs significantly better on transparency-sensitive tasks, including open-ended question answering and fact checking.",
  annote = {
    SAIL fine-tunes a model on RAG instruction following with GPT-4 providing demonstrations,
    also learns to identify which docs are relevant. 
    They order retrievals by relevance, determined by a classifier.
    Our work generalizes their method to more sophisticated pipelines 
    and avoids training on OOD demonstrations by a stronger model.
  }
}

@inproceedings{shi2023replug,
  title={REPLUG: Retrieval-Augmented Black-Box Language Models},
  author={Weijia Shi and Sewon Min and Michihiro Yasunaga and Minjoon Seo and Rich James and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},
  booktitle={North American Chapter of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:256389797}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wen2024know,
  title={Know your limits: A survey of abstention in large language models},
  author={Wen, Bingbing and Yao, Jihan and Feng, Shangbin and Xu, Chenjun and Tsvetkov, Yulia and Howe, Bill and Wang, Lucy Lu},
  journal={arXiv preprint arXiv:2407.18418},
  year={2024}
}

@misc{weston20232attentionisneed,
  title={System 2 Attention (is something you might need too)}, 
  author={Jason Weston and Sainbayar Sukhbaatar},
  year={2023},
  eprint={2311.11829},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.11829}, 
  annote={
    Ignore irrelevant context by prompting the model to remove irrelevant and biasing content.
  },
}

