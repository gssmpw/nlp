\newcommand{\diversesearch}{\ensuremath{\mathrm{DiverseSearch}}}
\newcommand{\diverseindex}{\ensuremath{\mathrm{DiverseIndex}}}
\newcommand{\diverseprune}{\ensuremath{\mathrm{DiversePrune}}}
\newcommand{\diversequeue}{\ensuremath{\mathrm{DiversePriorityQueue}}\xspace}
\newcommand{\blockers}{\mathsf{blockers}\xspace}




\section{Experimental Evaluation}
In this section we provide an empirical evaluation of our methods. To this end, we first devise a heuristic adaptation based on our provable algorithms for the {\em $k'$-colorful NN} problem as in~\Cref{def:kprime-colorful}. As we note below, this problem itself captures several real-world notions of diversity. 

At a high level, the difference between our heuristics and our theoretical algorithms is similar to the difference between the fast- and slow-preprocessing algorithms in DiskANN~\cite{jayaram2019diskann,indykxu2024worst}). Indeed, we deploy the same construction as in the fast-preprocessing variant of DiskANN, but modify the pruning procedure to insist that any node $u$ has sufficiently many colorful out-neighbors before an edge $(u,v)$ can get pruned, in addition to the geometric condition for pruning as in the original algorithm~\cite{DiskANN}. The number of colorful edges that  are needed before pruning can occur is given by a tunable parameter $m$ in our algorithm, and indeed this is the direct heuristic analog of step 10 in~\Cref{alg:color-indexing}.  This is a very high-level description, and we refer the interested reader to~\Cref{sec:impl} for the complete pseudo-code of our heuristic algorithms.

%Crucially, since our algorithm only adds edges on top of vanilla DiskANN, the same index can be successfully (by restricting to the original set of edges) used for scenarios where diversity is \emph{not required at search time}, significantly saving cost and complexity in real-world deployments. 

Second, we run experiments using our heuristics	on several different datasets, both real-world as well as synthetically generated. We show how our heuristic consistently delivers superior recall for a fixed latency budget, across datasets when compared to a natural baseline of using a vanilla DiskANN algorithm and enforcing diversity only via a final post-processing. We stress that both our real-world datasets are motivated from important shopping scenarios: the data points represent products and a color of a vector corresponds to either the seller or the brand of the product. 
It is then desirable to output results from a diverse set of sellers/brands~\cite{google-div}. Intuitively, displaying diverse results would lead to increased competition between the sellers, and also simultaneously higher click probabilities, thereby leading to an increase in revenue of the exchange.%

\subsection{Experiment Setup} 
All experiments were run on a Linux Machine with AMD Ryzen Threadripper 3960X 24-Core Processor CPU's @ 2.3GHz with 48 vCPUs and 250 GB RAM. All query throughput and latency measurements are reported for runs with 48 threads.

\begin{figure*}[t]
     \centering
    \begin{minipage}{0.40\textwidth}
%        \centering
    \includegraphics[width=\textwidth]{pie_chart_cut.png}
\caption{Seller distribution in a real-world dataset with 20 million base vectors, where the top 7 sellers constitute more than 90\% of the data.}
\label{fig:percentage}
    \end{minipage}
    \hspace{1cm}
    \begin{minipage}{0.50\textwidth}
%        \centering
    \includegraphics[width=\textwidth]{cdf.png}
\caption{Brand cumulative distribution for Amazon dataset, showing the coverage of the vectors by the brands in sorted order. The top $10\%$ of brands cover $86\%$ of the vectors.}
\label{fig:percentage2}
    \end{minipage}
\end{figure*}

\begin{figure*}[!ht]
     \centering
    \begin{minipage}{0.42\textwidth}
        \centering
\includegraphics[width=0.8\textwidth]{real_dataset_max_per_seller_1.png}

\includegraphics[width=0.8\textwidth]{amazon_dataset_max_per_seller_1.png}

\includegraphics[width=0.8\textwidth]{arxiv_dataset_max_per_seller_1.png}

\includegraphics[width=0.8\textwidth]{sift_dataset_max_per_seller_1.png}

\includegraphics[width=0.8\textwidth]{sift_lsh_dataset_topk_10_2.png}
    \caption{Recall vs Latency for $k'=1$.}
 \label{fig:recall-latency-1}
    \end{minipage}   
%    \hspace{0cm}
    \begin{minipage}{0.42\textwidth}
        \centering
\includegraphics[width=0.8\textwidth]{real_dataset_max_per_seller_10.png}

\includegraphics[width=0.8\textwidth]{amazon_dataset_max_per_seller_10.png}

\includegraphics[width=0.8\textwidth]{arxiv_dataset_max_per_seller_10.png}

\includegraphics[width=0.8\textwidth]{sift_dataset_max_per_seller_10.png}

\includegraphics[width=0.8\textwidth]{sift_lsh_dataset_topk_10_3.png}
    
\caption{Recall vs Latency for $k'=10$.}
\label{fig:recall-latency-10}
\end{minipage}
\end{figure*}

\paragraph{Datasets.} We consider two real-world and three semi-synthetic datasets for evaluation.
\begin{itemize}[leftmargin=*]
    \item {\em Real-world Seller Dataset:} Our first real-world seller dataset comprises of $64$-dimensional vector embeddings of different products from a large advertisement corpus. Each product/vector is additionally associated with a \emph{seller}, which becomes its color in our setting. There are $20$ million base vectors, around $2500$ sellers, and $5000$ query vectors. This distribution is highly skewed, with an extremely small number (around $7$) of sellers constituting more than $90 \%$ of the data, hence naturally motivating the need for enforcing diversity in the search results. The fraction of products corresponding to the top 20 sellers is shown in \Cref{fig:percentage}. 


\item {\em Amazon Automotive Dataset:} Our second real-world dataset is derived from the recently released Amazon dataset~\cite{big-bench}. 
It comprises of $384$-dimensional vector embeddings of product descriptions listed on Amazon under the Automotive category. Each product/vector is additionally associated with a \emph{brand}, which becomes the color. There are around $2$ million base vectors and around $85000$ brands. The distribution, while skewed, is far more balanced than the above seller dataset, with around $10\%$ of the brands accounting for $80\%$ of the vectors as summarized in~\Cref{fig:percentage2}. 

\item{\em ``Skewed'' Semi-synthetic Datasets:} We also consider the publicly available real-world Arxiv dataset~\cite{arxiv} which contains OpenAI embeddings of around 2 million paper abstracts into 1536 dimensional vectors and the classical SIFT dataset of 1M vectors in $128$ dimensions. These datasets do not contain any color information, so we synthetically add this information into the data set.  Specifically, for the Arxiv dataset, we generate the color information as follows: for each vector, with probability $0.9$, we assign a color selected from the set $\{ 1,2,3\}$ uniformly at random, and with $0.1$ probability we  assign a color selected uniformly at random from the set $\{4,\dots, 1000 \}$. Therefore the number of distinct colors is at most $1000$ in this data set. For the SIFT dataset, we sampled one dominant colors with probability $0.8$ and had a uniform distribution over $999$ other colors with probability $0.2$. 

\item{\em ``Balanced'' Semi-synthetic Dataset:} Finally, we also consider another distribution which is globally uniform, but locally skewed. Indeed, we use the same SIFT dataset for the vector data. For colors, we randomly partition the space into one thousand buckets, using a random hyperplane scheme. We then assign a unique \emph{primary color} for each bucket. Now, each vector within any specific bucket is assigned its primary color with a high probability of $0.8$, and a uniformly random non-primary color with the remaining probability. It is then easy to see that the distribution is roughly balanced across colors from a global perspective, but quite skewed in any small local neighborhood.
\end{itemize}

\paragraph{Tasks.}
For all of the above datasets, we seek to retrieve $k=100$ nearest neighbors. In one extreme scenario, we set $k'=1$, i.e., all hundred of the returned results need to be of distinct colors. This type of setting would be relevant in a retrieval augmented generation setting where documents are typically chunked into several parts and each part is vectorized; when the user utters a query, we might want to retrieve the most relevant set of documents (as opposed to the most relevant chunks, which might all be from the same document) to a given query, before passing on these contents to a large-language model which then answers the user query. A natural way to enforce this document-level diversity during retrieval is to treat the document-id of any vector as its color, and using our diverse search routine.

In another scenario which might have more appeal in shopping or advertisement display, we seek to retrieve $k=100$ nearest neighbors, while having $k'=10$, i.e., no more than ten of the $k$ results may belong to any single color. This will promote the retrieval to display a diverse set of sellers/ brands in such scenarios, thereby hopefully increasing user satisfaction and engagement. This can also capture \emph{intent diversity} in regular web-search (when we can use a simple classifier to represent the intent behind the data point as additional meta-data, which becomes the color in our setting -- e.g., car or animal for different images of jaguar, ML or EE concept for transformer, etc.). 


\paragraph{Algorithms.} Since our algorithms are enhancements of the DiskANN algorithm, we use that as a natural baseline to compare against. 



\begin{itemize}[leftmargin=*]
\item {\em Standard DiskANN Build + Post-Processing (Baseline):} In this baseline, we build a regular DiskANN graph without any diversity constraints. To answer a query, we first invoke the regular DiskANN search algorithm to retrieve $r \gg k$ candidates, again without any diversity constraints. Then we iterate over the retrieved elements in sorted order of distances to the query, and greedily include the ones which do not violate the $k'$ diversity constraint, until we have  $k$ total elements. The parameter $r$ is tunable at search time, and higher $r$ yields more candidates, meaning more diverse candidates can be obtained using the post-processing step. However, higher $r$ also consumes more search complexity. 

\item{\em Standard DiskANN Build + Diverse Search:} In this improvement, we use our diversity-preserving search~\Cref{alg:color_search} discussed in the \Cref{sec:impl}, but the index construction remains the standard DiskANN algorithm.

\item {\em Diverse DiskANN Build + Diverse Search:} For our complete algorithm, we additionally use our diversity-aware index construction ~\Cref{alg:colorindex} (\Cref{sec:impl}) which ensures sufficient edges are present to nodes of different colors in any neighborhood. 
\end{itemize}


\paragraph{Parameter setup.} For all of the above algorithms, we use fairly standard parameters of list-size $L=200$ and graph-degree $64$ when building the graphs. During search, we vary the list-size $L$ at search time to get varying quality search results and plot the recall@100\footnote{Recall@100 is the  size of the intersection of the algorithm's 100 returned results with the true 100 closest diverse candidates, averaged over all queries. The ground-truth set of top 100 diverse NNs for any query can be computed by iterating over all the vectors in sorted order of distances to the query, and greedily including the ones which do not violate the $k'$ diversity constraint, until we have accumulated $k$ total elements.} vs average query latency. 



\subsection{Results}\label{sec:results-exp}
Our results are shown in plots of Figures \ref{fig:recall-latency-1}, \ref{fig:recall-latency-10}. As one can see, both of our algorithmic innovations play a crucial role in the overall search quality on the real-world dataset. For example, to achieve $95\%$ recall@100 in the real-world seller dataset, the baseline approach has latencies upwards of $8$ms, while the improved search algorithm brings it down to $\approx 4.5$ms. Making both build and search diverse further brings it down to around $\approx 1.5$ms, resulting in an improvement of 5X. 

The plot in~\Cref{fig:recall-latency-10} reveals an interesting phenomenon: for high recalls (say $90\%$) on the semi-synthetic arXiv dataset, the post-processing approach has a latency of around $90$ms, while the diverse search algorithm when run on the standard graph has a latency of around $135$ms. This is perhaps because the standard graph construction might not have sufficiently many edges between nodes of different colors to ensure that the diverse search algorithm converges to a good local optimum. On the other hand, running the diverse search on the graph constructed keeping diversity in mind during index construction fares the best, with a latency of only around $25$ms. A similar phenomenon occurs in the SIFT semi-synthetic dataset as well.


%\noindent {\bf Build Diversity Parameter Ablation.} 
\subsection{Build Diversity Parameter Ablation}\label{sec:ablation}
In our heuristic graph construction algorithm (see~\Cref{alg:colorindex,alg:colorprune}), the graph edges are added by considering \emph{both the geometry of the vectors and the corresponding colors}. Loosely, the $\alpha$-pruning rule of DiskANN dictates that an edge $(u,v)$ is blocked by an existing edge $(u,w)$ if $d(w,v) \leq d(u,v)/\alpha$. In the original DiskANN algorithm, any edge $(u,v)$ which is blocked is not added. In our setting, we additionally enforce that \emph{an edge needs to be blocked by edges of $m$ different colors} to not be added to the graph, where $m$ is a tuneable parameter. We now perform an ablation capturing the role of $m$ in the graph quality using the skewed SIFT dataset.~\Cref{tbl:build} shows a table with build times for various indices by varying only the $m$ parameter, and~\Cref{fig:recall-latency-ablation} shows the search quality of these different indices.

\begin{table} 
\centering
\begin{tabular}{|c|c|}
\hline
$m$ Parameter  & Build Time (s) \\
\hline
1 &  50 \\
2 &  53 \\
10 &  55 \\
\hline
\end{tabular}
\caption{Build Times w.r.t $m$ Parameter}
\label{tbl:build}
\end{table}

\begin{figure}[!ht]
    \centering
    \begin{minipage}{0.33\textwidth}
        \centering
% \includegraphics[width=\textwidth]{bing-ads-latency-recall.png}
\includegraphics[width=\textwidth]{sift_dataset_max_per_seller_10_ablation_5.png}
% \caption{Recall vs Latency for real-world dataset where $k'=10$}
% \label{fig:recall-latency-ads}
    \end{minipage}\hspace{1cm}
    \begin{minipage}{0.33\textwidth}
        \centering
% \includegraphics[width=\textwidth]{arxiv-latency-recall.png}
\includegraphics[width=\textwidth]{sift_dataset_max_per_seller_1_ablation_2.png}
% \caption{Recall vs Latency for real-world dataset where $k'=1$.}
% \label{fig:recall-latency-arxiv}
    \end{minipage}
    \caption{Recall vs Latency for SIFT-Skewed dataset with $k'=10$ (left) and $k'=1$ (right) by varying the diversity parameter $m$ during index construction. Higher $m$ implies more diversity.}
    \label{fig:recall-latency-ablation}
\end{figure}

