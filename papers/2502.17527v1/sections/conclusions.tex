We proposed a new model, DPNMM, for estimating filters to shape music and raise its masking thresholds according to the spectral characteristics of ambient noise, in the context of users wearing headphones. This approach is perceptually motivated and allows balancing the effectiveness of the masking effect with a power-preservation constraint to ensure fidelity to the original recording.
This model shows superior performance compared to the baseline PEQ by Estreder et al. \cite{estrederPerceptualAudioEqualization2018} outperforming it both in terms of noise masking and power-preservation. 
Future works will explore incorporating user preferences to adapt the model's response to the user's preferred sound rendering.