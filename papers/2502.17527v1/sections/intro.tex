Listening to music %with headphones or earphones 
in noisy environments may negatively impact the listening experience as the surrounding noise interferes with the perception of the music, partially masking some spectral components of the audio content \cite{mooreModelPredictionThresholds1997, ramoPerceptualFrequencyResponse2012}. A part of the music may even be completely concealed by the noise due to simultaneous masking. For a given audio signal, this effect is quantified using masking thresholds, which indicate the level below which another signal becomes inaudible within specific frequency bands due to the presence of the first signal \cite{painterPerceptualCodingDigital2000, zwickerPsychoacousticsFactsModels2010}.

Thus, music rendering systems have been developed over the years to enhance listening comfort, initially in automotive environments \cite{clarkCompensationRoadNoise1987,millerCopingRoadNoise1994,christophNoiseDependentEqualization2012d} and later for more general contexts and personal devices such as headphones or earphones \cite{ramoPerceptualHeadphoneEqualization2013, jrAdaptedAudioMasking2015,jrCollaborativelyProcessingAudio2016}.  One approach involves volume adjustments and compression to increase the loudness of the music when it is masked or partially masked by noise \cite{clarkCompensationRoadNoise1987, millerCopingRoadNoise1994, jrAdaptedAudioMasking2015, kuivalainenAdaptiveModulationAudio2021}.  Similarly, adaptive perceptual equalizers have been proposed to restore the original loudness of the music signal when it is affected by ambient noise \cite{christophNoiseDependentEqualization2012d, ramoPerceptualHeadphoneEqualization2013}.

However, the masking effect works both ways: music may also be used to mask ambient noise. Some works on Active Noise Cancelling (ANC) systems have utilized psychoacoustic information to focus on the frequency bands where noise exceeds the music's masking thresholds, ensuring that the residual noise after reduction is completely masked by the music \cite{docloActiveNoiseReduction2016, belyiIntegratedPsychoacousticActive2019, zachosFeedforwardHeadphoneActive2024}. Another strategy is to filter the music so that its masking thresholds are raised above the noise level. The main challenge is then how to generate filtering parameters that achieve these perceptual goals while maintaining the original music's identity and the userâ€™s preferred listening level. Estreder et al. \cite{estrederPerceptualAudioEqualization2018} proposed a system that computes the gain parameters of a graphic equalizer whose goal is to boost the frequency bands where the noise is not masked. However, they simplified the problem by not fully leveraging the psychoacoustic model in the gain computation and not incorporating constraints to minimize music alteration, aside from limiting the gain in each band.

In this article, we propose an original deep neural network approach to produce filters that enhance the played-back music's capacity to mask ambient noise. Like Estreder et al. \cite{estrederPerceptualAudioEqualization2018}, we focus on simultaneous masking, excluding the partial masking effect.  We demonstrate that using a well-chosen neural network with a well-designed loss function allows a better exploitation of the psychoacoustic model for gain prediction and the integration of other criteria to balance masking effectiveness and musical fidelity. \se{Specifically, our contributions are: i) a U-net architecture optimized with a perceptual loss function trading-off masking and minimal power variations leading to improved results over the method proposed by Estreder \cite{estrederPerceptualAudioEqualization2018}; ii) a perceptually motivated procedure to deduce equalization frequency responses from predicted gains in each frequency band; iii) an experimental design studying variants of the proposed system based on different levels of power constraint, using data simulated with headphones responses to reproduce realistic auditory scenes, and evaluation metrics jointly assessing masking and power-preservation.} This study focuses on the context of music listened to with headphones; however, the proposed method is more general and can be applied to other use cases.


