%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
     \centering
    \includegraphics[width=\textwidth]{figures/SPARQL_GenR.pdf}
    \caption{As discussed in \refsec{sec:pgmr}, PGMR first employs an LLM to produce an intermediate query, where the URI labels are framed by "starturi" and "enduri" tokens (\refsec{sec:transform}). The retriever (\refsec{sec:retriever}) subsequently fetches and replaces these labels with the most similar URIs from the non-parametric memory to create the final SPARQL query.}
    \label{fig:rag_vs_model}
    \label{fig:genR}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Related Work}
\label{sec:related_work}

\noindent \textbf{SPARQL Query Generation using LLMs.} Even though various models have been proposed for the SPARQL query generation task recently, they suffer from one key problem: they require tagged question data \citep{banerjee, reyd2023, karou2023, qi2024enhancing}. In tagged data, the input to the model contains the natural language question along with the URIs and the URI labels needed to formulate the corresponding SPARQL query. 
This requirement presents a challenge due to the high costs and labor-intensive nature of tagging, making it unsuitable for practical, real-world use cases. Therefore, our study emphasizes and assesses the untagged versions of the datasets.

\citet{reyd2023} and \citet{karou2023} propose a copy mechanism for copying URIs from the tagged question while generating the SPARQL query using LLMs. Additionally, they investigate the models' performance in dealing with novel question-query structures and unknown URIs. We incorporate this evaluation approach to evaluate the out-of-distribution robustness of our proposed approach.
\citet{banerjee} propose a pointer generator network-based approach for SPARQL query generation over tagged data using BERT \citep{bert} and using a finetuned T5. Their approach generates multiple SPARQL queries and selects the first query that executes and fetches an answer from the knowledge base as the predicted SPARQL query. This evaluation strategy contrasts with our approach of generating only one SPARQL query per question, which is more efficient. %We argue that our method is more practical, as users typically expect a single, accurate response from a SPARQL query generation model.
\citet{qi2024enhancing} employ a pre-training method that integrates the proposed Triple Structure Correction (TSC) strategy. This technique, which requires tagged data, involves randomly interchanging the positions of the subject, predicate, and object in SPARQL query triples with a certain probability alongside a Masked Language Modeling (MLM) objective in a multi-task learning setup before proceeding with finetuning on the downstream tagged dataset.

\noindent \textbf{Mitigating hallucinations in LLMs.} Despite their widespread adoption, LLMs are vulnerable to generating factually incorrect information through hallucinations, which affects their reliability in real-world applications \citep{hallucination_survey_1, hallucination_survey_2, huang2021factual}. This challenge has led to significant research aimed at hallucination detection and mitigation \citep{lin2024towards, varshney2023stitch, dhuliawala2023chain, chern2023factool, li2023halueval}.
\citet{varshney2023stitch} identify potential hallucination candidates using the LLMâ€™s logit outputs, validating their correctness, addressing any detected hallucinations, and then proceeding with the generation process.
In contrast, PGMR lets the LLM hallucinate between special tags and corrects these hallucinations post-generation using memory retrieval.
The Chain-of-Verification (CoVe) \citep{dhuliawala2023chain} method involves the model first producing an initial draft, then formulating verification questions to validate it by independently answering these questions, and generating the final, verified output.
Our method instead relies on a non-parametric memory to verify and include factually correct information from a KG.



% Despite their widespread adoption in various real-world tasks, LLMs are vulnerable to hallucinations when generating factual information from their internal parametric knowledge \citep{hallucination_survey_1, hallucination_survey_2, huang2021factual}.
% This results in information that appears credible but is, in fact, inaccurate, posing challenges for their deployment in practical scenarios.
% This challenge has consequently driven ongoing research aimed at detecting and mitigating such errors.


% \noindent \textbf{Retrieval augmented generation (RAG).} RAG supplements the PLM's input with context retrieved from relevant documents, which is commonly used to promote the factual correctness of the generated content \citep{knnlm, rag_og, guu2020retrieval, lewis2020retrieval}. Standard implementations of RAG retrieve documents that align with the input prompt. However, the extensive incorporation of context often leads to the inclusion of irrelevant or unrelated passages, negatively impacting the quality of the output \citep{shi2023large}.
% Recently, various RAG-based models have been proposed that utilize a KG as a non-parametric memory \citep{lewis2020retrieval, soman2023_kg_rag} for knowledge-intensive tasks.
% We propose a novel RAG-based baseline (as described in \refsec{sec:rag}) in this work that is the first to adapt the standard RAG paradigm for SPARQL query generation.

\noindent \textbf{External memory augmented LLMs.} Earlier studies have investigated methods to augment LLMs by retrieving documents from external memory and integrating them into the contextual framework of tasks to provide relevant information.
According to \citet{retllm} and \citet{memllm}, the lack of a specialized memory unit in current LLMs constrains their ability to explicitly store and retrieve knowledge relevant to tasks. This observation supports our study's central premise. They suggest enhancing LLMs with an API-based memory unit for read-write operations to address this limitation.
Interactions with the external memory can be implemented using natural language interfaces \citep{park2023generative, zhou2023recurrentgpt} or formal mechanisms such as standardized APIs that allow the model to parse and execute commands \citep{toolformer, hu2023chatdb, retllm, memllm}.
Our approach is akin to the use of a formal mechanism for memory retrieval through our intermediate query format (as described in \refsec{sec:transform}).

