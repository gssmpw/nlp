\section{Introduction}
\label{sec:introduction}

Question answering (QA) is a critical task in natural language processing and remains a key goal for artificial intelligence research. Many QA methodologies employ knowledge graphs (KGs) \citep{saxena2020improving, kgqa_survey, kg_survey}, which are multi-relational graphs that encode facts.
KGs represent world knowledge as fact triples \textit{(subject, relation, object)}, for example, \textit{(The Truman Show, nominated for, Academy Award for Best Supporting Actor)}.
The problem of answering questions that require reasoning over KGs (KGQA) can be broken down into two parts, namely, translating the natural language question into its associated SPARQL\footnote{\url{https://www.w3.org/TR/rdf-sparql-query/}} query and then executing the SPARQL query over a KG to obtain the final answer \citep{banerjee}.
For example, a natural language question like \textit{"For which film was Sergei Eisenstein the film editor?"} can be translated into the following SPARQL query - "\textit{select distinct ?sbj where \{ ?sbj wdt:p1040 wd:q8003 . ?sbj wdt:p31 wd:q11424 \}}," where p1040, q8003, p31 and q11424 are Uniform Resource Identifiers (URIs) (described further in \refsec{sec:uri}) representing entities, relations and properties from a KG like Wikidata\footnote{\url{https://www.wikidata.org}}.
Our approach specifically focuses on the following challenge: translating a question into the appropriate semantically accurate SPARQL query and ensuring the precise generation of URIs linked to the entities and relationships mentioned in the question.

Using large language models (LLMs) for generating SPARQL queries has become prevalent in recent research \citep{meyer2024assessing, karou2023, banerjee, qi2024enhancing, Text2SPARQL}. However, this approach can lead to significant challenges, such as hallucinations and out-of-distribution errors, particularly when the models generate KG elements like URIs based only on their internal parametric knowledge. 
As a consequence of these hallucinations, SPARQL queries may be generated with a structure that seems correct while incorporating incorrect factual information, such as URIs that don't exist in the KG \citep{hallucination_survey_1, hallucination_survey_2, huang2021factual}. This limitation raises concerns about the reliability of LLMs in real-world information retrieval (IR) applications and has driven extensive research into techniques for detecting and mitigating such errors \citep{lin2024towards, varshney2023stitch, dhuliawala2023chain, chern2023factool, li2023halueval}.

Retrieval-augmented generation (RAG) \citep{knnlm, rag_og, guu2020retrieval, lewis2020retrieval} is a popular paradigm that is often employed for reducing hallucinations \citep{hallucination_survey_1}. It uses a non-parametric memory for retrieving information in response to a question. This information is provided in the prompt for the LLM before generation to enhance the grounding of responses.
Despite the integration of retrieval mechanisms, RAG often retrieves noisy or incomplete information.
Additionally, since the LLM is not strictly constrained to rely on the retrieved context, it may still generate responses that are not fully grounded, thereby failing to eliminate hallucinations \citep{barnett2024seven}.


% In practice, however, the information retrieved through RAG can often be noisy and incomplete, with the LLM still generating responses that may not be grounded in the provided retrieved context as the LLM is not necessarily constrained to do so, thereby failing to fully eliminate hallucinations \citep{barnett2024seven}.
% We propose a new RAG baseline for the SPARQL query generation task in this work, as described in \refsec{sec:rag}.
%Contrary to the PGMR framework, where the process involves first generating an intermediate query (as illustrated in \reffig{fig:transform}) followed by URI retrieval, the RAG approach operates by first retrieving relevant URIs from the knowledge base in response to a question, and then generating the SPARQL query using the retrieved URIs.
% In practice, however, the set of URIs retrieved through RAG can often be noisy and incomplete \citep{shi2023large}. This issue arises because the entities and relations necessary to formulate the SPARQL query may not always be explicitly stated in the question. Consequently, this limitation can result in decreased accuracy of SPARQL generation by the PLM. 

% To address these issues, we propose post-generation memory retrieval (PGMR), a novel modular architecture incorporating a non-parametric memory module dedicated to managing KG elements. This memory module works in conjunction with LLMs, which generate the SPARQL query syntax, thus ensuring the retrieval of accurate and relevant KG elements. By separating the generation of SPARQL query syntax from the retrieval of KG elements, our approach enhances the precision and reliability of SPARQL query generation, mitigating common pitfalls associated with the current LLM-based methodologies.
% In PGMR, the LLM initially produces an intermediate query in SPARQL syntax while incorporating natural language entities, relations, and properties enclosed within special tokens. This allows the model to hallucinate within these boundaries in the natural language space. PGMR subsequently corrects these hallucinations and grounds them in KG URIs using a non-parametric memory.
% Since memory retrieval occurs after LLM generation, PGMR avoids hallucinating non-existent KG URIs and reduces out-of-distribution errors, as discussed in \refsec{sec:results}.

In response to these limitations, we propose PGMR (Post-Generation Memory Retrieval), a new modular architecture featuring a non-parametric memory retriever module for managing KG elements. This approach enables LLMs to focus on generating SPARQL query syntax while the retriever ensures accurate retrieval of relevant KG elements.
PGMR enables the LLM to generate intermediate SPARQL queries with natural language entities and relations enclosed in special tokens, which allows for controlled hallucination. These hallucinations are later corrected and grounded in KG URIs using the retriever.
By isolating the tasks of query generation and element retrieval, PGMR improves the reliability and accuracy of SPARQL queries, avoiding the hallucination of non-existent KG URIs and reducing out-of-distribution errors, as discussed in \refsec{sec:results}.

% In PGMR, the PLM generates an intermediate query (as illustrated in \reffig{fig:transform}) that incorporates placeholders for URI labels, guiding a non-parametric memory retrieval module to insert URIs at appropriate positions.
% The retriever subsequently accesses the memory to retrieve URIs corresponding to the generated labels, enabling the conversion of the intermediate query into a SPARQL query.

%RAG (Retrieval Augmented Generation) \citep{knnlm, rag_og, guu2020retrieval, lewis2020retrieval} is another popular paradigm that employs an external knowledge base, such as a KG, as a non-parametric memory to enhance the grounding of PLM generations. Contrary to the PGMR framework, where the process involves first generating an intermediate query (as illustrated in \reffig{fig:transform}) followed by URI retrieval, the RAG approach operates by first retrieving relevant URIs from the knowledge base in response to a question, and then generating the SPARQL query using the retrieved URIs.

% In PGMR for SPARQL generation (as described in \refsec{sec:pgmr}), our initial step involves converting each SPARQL query from the training dataset into an intermediate query format. 
% This transformation replaces all URIs (e.g., "q214801") within the SPARQL query with their corresponding natural language URI labels (e.g., "the truman show"), encapsulated by "starturi" and "enduri" tokens.
% Subsequently, we fine-tune a PLM on this modified dataset. 
% During the inference phase, the PLM generates an intermediate query (as illustrated in \reffig{fig:transform}) that incorporates placeholders for URI labels, guiding a non-parametric memory retrieval module to insert URIs at appropriate positions.
% The retriever subsequently accesses the memory to retrieve URIs corresponding to the generated labels (identified by "starturi" and "enduri" tokens), enabling the conversion of the intermediate query into a SPARQL query.

% RAG (Retrieval Augmented Generation) \citep{knnlm, rag_og} is another popular paradigm that employs an external knowledge base, such as a KG, as a non-parametric memory to enhance the grounding of PLM generations.
% In RAG for SPARQL query generation (as discussed in \refsec{sec:rag}), the question is first passed to a retriever, which fetches $k$ URIs whose labels are closest to the question in latent space and appends them to the prompt for the PLM. This helps the PLM identify the URIs it should use while formulating the SPARQL query.

%In practice, however, the set of URIs retrieved through RAG can often be noisy and incomplete \citep{shi2023large}. This issue arises because the entities and relations necessary to formulate the SPARQL query may not always be explicitly stated in the question.  
%Consequently, this limitation can result in decreased accuracy of SPARQL generation by the PLM. Furthermore, this method may fail to mitigate hallucinations, as the PLM is not necessarily constrained to integrate the retrieved URIs into the generated SPARQL query (further discussed in \refsec{sec:results}).
%Essentially, RAG might generate URIs that do not even exist within the KG.
%In contrast, PGMR's PLM generates URI labels explicitly at appropriate query points, simplifying the retriever's task of identifying the most similar URI label from memory and retrieving the corresponding URI for completing the SPARQL query, thereby improving SPARQL generation accuracy.

In this context, we address the following research questions: (1) Does the integration of a memory retrieval module into an LLM-based system enhance performance in SPARQL query generation and mitigate hallucination issues? (2) Does the addition of a memory module increase model robustness to out-of-distribution evaluation?
% \begin{enumerate}
%     \item Does the integration of a memory retrieval module into an LLM-based system enhance performance in SPARQL query generation and mitigate hallucination issues?
%     \item Does the addition of a memory module increase model robustness to out-of-distribution evaluation?
% \end{enumerate}

This study introduces several key contributions:
\begin{enumerate}
    \item We explore the implications of adding a post-generation memory retrieval module to LLMs for SPARQL query generation, investigating reduction in LLM hallucination and improvements in query accuracy and resilience against out-of-distribution scenarios.
    \item We propose PGMR, an innovative modular architecture where initial SPARQL query syntax generation is performed by an LLM, followed by retrieval of KG elements from a non-parametric memory module.
    \item We introduce a paradigm for letting LLMs hallucinate and fixing these hallucinations post-generation using a non-parametric memory.
    \item Our results show that PGMR drastically reduces URI hallucinations while significantly improving performance across LLMs and datasets, with most cases showing an almost complete elimination of hallucinated URIs.
    

    
    % \item Evaluation results show that PGMR achieves a significant improvement of 37\% in query exact match score compared to traditionally fine-tuned PLMs, and an 8\% improvement over RAG on the LCQUAD 2.0 dataset.
    % \item PGMR demonstrates a substantial reduction of URI hallucinations by approximately 59\% compared to standard PLM fine-tuning methods, and nearly 14\% compared to RAG, especially on out-of-distribution test sets. It notably achieves 0\% hallucinations on QALD-10.
    % \item PGMR performance does not degrade when the test set is out-of-distribution.
\end{enumerate}

% In natural language processing, question answering (QA) is a pivotal problem and a long-standing objective for artificial intelligence. A large number of QA methods rely on knowledge graphs (KG), which are multi-relational graphs that encode facts.
% KGs represent world knowledge as fact triples \textit{(subject, relation, object)}, for example, \textit{(The Truman Show, nominated for, Academy Award for Best Supporting Actor)}.

% The problem of answering questions that require reasoning over KGs (KGQA) can be broken down into two parts, namely, translating the natural language question into its associated SPARQL\footnote{\url{https://www.w3.org/TR/rdf-sparql-query/}} query and then executing the SPARQL query over a KG to obtain the final answer \citep{karou2023, banerjee, qi2024enhancing, Text2SPARQL}.
% For example, a natural language question like \textit{"For which film was Sergei Eisenstein the film editor?"} can be translated into the following SPARQL query - "select distinct ?sbj where \{ ?sbj wdt:p1040 wd:q8003 . ?sbj wdt:p31 wd:q11424 \}," where p1040, q8003, p31 and q11424 are Uniform Resource Identifiers (URIs) (described further in \refsec{sec:uri}) representing entities, relations and properties from a KG like WikiData\footnote{\url{https://www.wikidata.org}}.
% This approach specifically focuses on the following challenge: translating a question into the corresponding SPARQL query while accurately generating the URIs associated with the entities and relations in the question.

% Pre-trained large language models (PLMs) are frequently employed for SPARQL query generation, but this reliance can lead to challenges such as hallucinations and out-of-distribution errors from generating KG elements like URIs using their internal parametric knowledge. To mitigate these issues, adding a non-parametric memory to manage KB elements can greatly improve the accuracy of SPARQL query generation. This idea involves a modular architecture where pre-trained language models generate the SPARQL code, while the memory module is responsible for retrieving accurate KG elements.

% ADD the idea(rephrase): prevalence of large language models for such a task + generation of KB elements from parametric knowledge leads to pbs : hallucinations, out-of-distribution, etc. 
% Thus: finding a way to add a non-parametric memory for KB elements can enhance SPARQL query generation. Idea of a modular architecture where PLMs are used to generate SPARQL code and the memory is used to obtain accurate KB elements 

% Even though various models have been proposed for the SPARQL query generation task recently, they suffer from one key problem: they require tagged question data \citep{banerjee, karou2023, qi2024enhancing}. In tagged data, the input to the model contains the natural language question along with the URIs and the URI labels needed to formulate the corresponding SPARQL query. This presents a challenge as dataset tagging is an expensive exercise requiring significant manual labour and cost overhead, impractical for real-world scenarios. 


% RQs! 