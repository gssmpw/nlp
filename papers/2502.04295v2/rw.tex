\section{Related Work}

% Our research builds upon three interconnected areas: LLM self-evolution, automatic prompt optimization, and structured prompting.

\noindent \textbf{Optimization via LLM}
The remarkable capacity of LLMs has been demonstrated in various tasks as optimizers, leveraging their ability to enhance performance, such as code generation~\citep{A_2023_optimize_code, C_2024COLM_stop, A_2024_MAGIC}, tool-making~\citep{A_2024_tool_making}, and agent system design~\citep{hu2024automateddesignagenticsystems}. 
However, recent studies indicate that LLMs face significant challenges in achieving completely automatic optimization. These models often rely on human intervention for designing workflows and struggle with tasks requiring complex decomposition and iterative refinement~\citep{A_2024_AFlow,J_2024TMLR_moreagent}.

% ~\citep{C_2024ICLR_LLMasOPT} uses the LLM progressively generates new solutions to optimize an objective function. 
% ~\citep{A_2023_optimize_code, C_2024COLM_stop} code generation
% ~\citep{A_2024_tool_making} tool-making
% ADAS~\citep{hu2024automateddesignagenticsystems}, agent system
% AI scientsit~\cite{lu2024aiscientistfullyautomated}

\noindent \textbf{Automatic Prompt Optimization}
Automatic prompt optimization plays a crucial role in enhancing the performance of LLMs by refining prompts without requiring human intervention. 
Various approaches have been explored to search for the optimal prompt, including reinforcement learning~\citep{C_2023ICLR_TEMPERA}, Monte Carlo Search~\citep{zhou2023ape}, Monte Carlo Tree Search (MCTS)~\citep{C_2024ICLR_promptagent}, feedback-based methods~\citep{C_2023EMNLP_APO, A_2024_GReaTer}, and agent-driven frameworks~\citep{A_2024_LangGPT,C_2024ICLR_DSPy,O_2023_Autogpt}.
While these methods focus on optimizing the overall prompt, they often lack the capability for fine-grained modifications.~\citep{C_2024ICLR_DSPy,C_2024EMNLP_sammo} introduce phrase-level mutations, but they fail to address format mutations or implement them in a systematic manner.


% FormatSpread~
% To address these limitations, our work integrates both content and format optimization with effective scoring system into a unified framework, leveraging LLM self-evolution to model prompt components and achieve greater flexibility and robustness in automatic prompt optimization.

% \citep{sclar2024formatspread}.
% TEMPERA~\citep{C_2023ICLR_TEMPERA} RL method
% GrIPS ~\citep{prasad2023grips}
% APE ~\citep{zhou2023ape} Monte-Carlo search to 
% ProTeGi~\citep{pryzant2023automaticpromptoptimizationgradient} gradient-descent
% STOP~\citep{C_2024COLM_stop} instead of optimize the prompt to optimize the scaffolding program for prompt optimization.
% ~\citep{khattab2023dspy, opsahlong2024dspy} DSpy prompt programming
% PromptBreede

\noindent \textbf{Prompt structure and format}
Structured prompting, which organizes prompts into distinct components such as instructions, examples, and queries, holds significant potential in prompt engineering~\citep{promptbreeder}.
Empirical rules for prompt design always lack integration with automatic optimization techniques, limiting their scalability and effectiveness~\citep{O_2023_CRISPE,google2024Promptingguide101}.
Frameworks like LangGPT~\citep{A_2024_LangGPT} have introduced structured prompting paradigms, emphasizing reusable designs inspired by programming principles.
However, these efforts primarily focus on content-level refinements and fail to adequately address the critical role of prompt formatting.
Studies have highlighted the impact of formatting on prompt performance~\citep{salinas2024butterflyeffectalteringprompts}.
\citet{C_2024ICLR_formatspread} revealed that modifications to separators and spacing within a query could substantially impact performance.
\citet{he2024doespromptformattingimpact} 
% demonstrated that JSON formatting outperforms other formats, 
reveals that the format of prompts significantly impacts GPT-based modelsâ€™ performance, with no single format excelling universally.
\citet{voronov-etal-2024-mind} focus on the format of few-shot examples and suggests that it is beneficial to maintain a consistent format across examples.
However, despite the recognition of formatting's importance, there remains a lack of comprehensive understanding regarding the optimization of prompt format in a systematic manner. 
% To the best of our knowledge, limited attention has been given to the role of formatting in prompt optimization.

%Prior studies have underscored the significant impact of prompt format~\citep{C_2024ICLR_formatspread, he2024doespromptformattingimpact}, yet there remains a lack of comprehensive understanding regarding the optimization of prompt format.
%To the best of our knowledge, limited attention has been given to the role of formatting in prompt optimization. Our research aims to address this gap by integrating formatting considerations into the automatic prompt optimization process.

% Our work addresses this gap by using structured prompting as the foundation for a comprehensive framework that integrates component-wise format-aware optimization. Through automatic techniques, we refine both the content and format of prompts, delivering robust and adaptable performance across diverse tasks.
% Structured prompting has huge potential in prompt engineering, which involves organizing prompts into components such as instructions, examples, and queries. 
% Some empirical rules for prompt design have been proposed ~\citep{O_2023_CRISPE,google2024Promptingguide101}, but they fail to incorporate automatic optimization techniques, which has constrained their broader application and effectiveness. 
% Frameworks like LangGPT~\citep{A_2024_LangGPT} have introduced structured prompting paradigms. However, these frameworks focus primarily on content-level refinements and provide inadequate consideration of prompt formats.
% Format of a prompt is also important~\citep{he2024doespromptformattingimpact,salinas2024butterflyeffectalteringprompts}. Now no method combine the structural prompt with format for automatic optimization.  
% Our work leverages structured prompting as the foundation for format-aware optimization. By adopting a component-wise design, we employ automatic optimization to refine both content and format.


% \noindent \textbf{Structured prompting} 
% Structured prompting has huge potential in prompt engineering, which involves organizing prompts into components such as instructions, examples, and queries. 
% Some empirical rules for prompt design have been proposed ~\citep{O_2023_CRISPE,google2024Promptingguide101}, but they fail to incorporate automatic optimization techniques, which has constrained their broader application and effectiveness. 
% Frameworks like LangGPT~\citep{A_2024_LangGPT} have introduced structured prompting paradigms. However, these frameworks focus primarily on content-level refinements and provide inadequate consideration of prompt formats.
% Our work leverages structured prompting as the foundation for format-aware optimization. By adopting a component-wise design, we employ automatic optimization to refine both content and format.
% \yuanye{lack reference}

% Structured prompting extends prompt optimization by considering the programmatic structure of prompts, recognizing that different compoentscan influence model performance.
% ref (rule, template):
% Nigh (2023) collects vast quality prompts and summaries of the CRISPE rule for prompt design.
% 



