\begin{abstract}
% Large language models (LLMs) have revolutionized various computational tasks, offering unprecedented accuracy and versatility. The effectiveness of LLMs heavily relies on the art of prompt crafting, where the precision of the prompts significantly influences the performance outcome. Recent efforts in prompt engineering most treat prompts as simple strings, failing to capture their complex, contextual nature. Moreover, prompt format has been identified as a critical factor for optimization, yet format and content optimization have been largely addressed disparately. Our research introduces a novel approach to prompt refinement that addresses these gaps by proposing a universal, structured template that adapts to various tasks and a combined content-format optimization pipeline. By harnessing the capabilities of LLMs for iterative refinement and incorporating a shared knowledge pool for faster convergence, our method significantly enhances prompt optimization efficiency and efficacy. Through extensive qualitative and quantitative analyses across diverse tasks, we demonstrate the superiority of our approach, presenting it as a major step forward in the field of prompt engineering. Our contributions not only streamline the prompt design process but also open pathways for more robust and flexible LLM applications.

% \key{[TBD]Large Language Models (LLMs) have shown remarkable capability across a spectrum of tasks, largely influenced by the effectiveness of their prompts. While recent advancements in prompt engineering have focused on content mutation to enhance performance, the importance of prompt formatting— a critical yet underexplored aspect— has been overlooked. To address these challenges, we introduce Prompt Optimization via Dual Exploration (PODE), a novel approach that concurrently optimizes prompt content and format. PODE leverages dual optimization strategies for content refinement and format exploration, supported by a format scoring system to direct the optimization process effectively. Our methodology demonstrates significant performance improvements across various tasks and models, underscoring the pivotal role of integrated prompt optimization in enhancing LLM efficiency and providing a model-agnostic solution for prompt engineering.}

% Large Language Models (LLMs) have shown remarkable capability across a spectrum of tasks, largely influenced by the effectiveness of their prompts. While recent advancements in prompt engineering have focused on content mutation to enhance performance, the importance of prompt formatting— a critical yet underexplored aspect— has been overlooked. 
% To tackle this challenge, this paper proposes Prompt Optimization via Dual Exploration (PODE), a novel methodology that simultaneously optimizes both prompt content and format through an integrated process. 
% This approach leverages LLMs for iterative content mutation and introduces a sophisticated format optimization strategy that dynamically explores and evaluates new formats. By employing dual optimization processes specifically tailored to the distinct challenges of content and format optimization, PODE achieves superior performance across a variety of tasks and LLMs. Our extensive evaluations confirm the effectiveness of PODE, showcasing its ability to significantly improve LLM efficiency and performance, thereby offering a comprehensive and model-agnostic solution for advanced prompt engineering. Code will be available at \href{https://github.com/HenryLau7/PODE}{https://github.com/HenryLau7/PODE}.

% lyna
% Large Language Models (LLMs) have shown remarkable capability across various tasks, with their real-world effectiveness often driven by  prompt design.  While recent advancements have focused on optimizing prompt content, the crucial role of prompt formatting— a critical yet underexplored yet vital dimension— has been largely been overlooked. 
% In this paper, we introduce  Prompt Optimization via Dual Exploration (PODE), a novel methodology that simultaneously optimizes both prompt content and format to automatically generate optimal prompts. 
% This approach leverages LLMs for iterative content mutation and introduces a sophisticated format optimization strategy that dynamically explores and evaluates new formats. By
% applying dual optimization processes specifically tailored to the distinct challenges of content and format optimization, PODE achieves superior performance across a variety of tasks and LLMs. Our extensive evaluations demonstrate the effectiveness of PODE, showcasing its ability to significantly improve LLM efficiency and performance, thereby offering a comprehensive and model-agnostic solution for advanced prompt engineering. Code will be available at \key{https://github.com/HenryLau7/PODE}.

Large Language Models (LLMs) have shown significant capability across various tasks, with their real-world effectiveness often driven by prompt design. 
% While recent advancements have focused on optimizing prompt content, the crucial role of prompt formatting— a critical yet underexplored yet vital dimension— has been largely been overlooked. 
While recent research has focused on optimizing prompt content, the role of prompt formatting—a critical but often overlooked dimension—has received limited systematic investigation.
In this paper, we introduce \fullsysname{}, an innovative methodology that jointly optimizes both prompt content and formatting through an iterative refinement process.
% Through iterative content mutation leveraged by LLMs and a sophisticated format optimization strategy that dynamically explores and evaluates new formats, \sysname{} achieves superior performance across a variety of tasks and LLMs.
\sysname{} leverages natural language mutations to explore content variations and employs a dynamic format exploration strategy that systematically evaluates diverse format options.
% Our extensive evaluations demonstrate the effectiveness of \sysname{}, showcasing its ability to significantly improve LLM performance, thereby offering a comprehensive and model-agnostic solution for advanced prompt engineering. 
Our extensive evaluations across multiple tasks and open-source LLMs demonstrate that \sysname{} demonstrates measurable performance improvements compared to content-only optimization methods. This highlights the importance of integrated content-format optimization and offers a practical, model-agnostic approach to enhancing LLM performance.
Code is available at \href{https://github.com/HenryLau7/CFPO}{https://github.com/HenryLau7/CFPO}.
\end{abstract}
