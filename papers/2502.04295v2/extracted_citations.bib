@misc{A_2023_optimize_code,
      title={Language Models Can Teach Themselves to Program Better}, 
      author={Patrick Haluptzok and Matthew Bowers and Adam Tauman Kalai},
      year={2023},
}

@misc{A_2024_AFlow,
      title={AFlow: Automating Agentic Workflow Generation}, 
      author={Jiayi Zhang and Jinyu Xiang and Zhaoyang Yu and Fengwei Teng and Xionghui Chen and Jiaqi Chen and Mingchen Zhuge and Xin Cheng and Sirui Hong and Jinlin Wang and Bingnan Zheng and Bang Liu and Yuyu Luo and Chenglin Wu},
      year={2024},
}

@misc{A_2024_GReaTer,
      title={GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers}, 
      author={Sarkar Snigdha Sarathi Das and Ryo Kamoi and Bo Pang and Yusen Zhang and Caiming Xiong and Rui Zhang},
      year={2024},
}

@misc{A_2024_LangGPT,
      title={LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language}, 
      author={Ming Wang and Yuanzhong Liu and Xiaoyu Liang and Songlian Li and Yijie Huang and Xiaoming Zhang and Sijia Shen and Chaofeng Guan and Daling Wang and Shi Feng and Huaiwen Zhang and Yifei Zhang and Minghui Zheng and Chi Zhang},
      year={2024},
      eprint={2402.16929},
}

@misc{A_2024_MAGIC,
      title={MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL}, 
      author={Arian Askari and Christian Poelitz and Xinye Tang},
      year={2024},
      eprint={2406.12692},
}

@misc{A_2024_tool_making,
      title={Large Language Models as Tool Makers}, 
      author={Tianle Cai and Xuezhi Wang and Tengyu Ma and Xinyun Chen and Denny Zhou},
      year={2024},
      eprint={2305.17126},
}

@inproceedings{C_2023EMNLP_APO,
      author={Reid Pryzant and Dan Iter and Jerry Li and Yin Tat Lee and Chenguang Zhu and Michael Zeng},
      title={Automatic Prompt Optimization with "Gradient Descent" and Beam Search}, 
    booktitle = EMNLP,
    year = 2023,
    pages = {7957–7968},
}

@inproceedings{C_2023ICLR_TEMPERA,
      author={Tianjun Zhang and Xuezhi Wang and Denny Zhou and Dale Schuurmans and Joseph E. Gonzalez},
      title={TEMPERA: Test-Time Prompting via Reinforcement Learning}, 
    booktitle = ICLR,
    year = 2023,
}

@inproceedings{C_2024COLM_stop,
      author={Eric Zelikman and Eliana Lorch and Lester Mackey and Adam Tauman Kalai},
      title={{Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation}}, 
    booktitle = COLM,
    year = 2024,
}
}

@inproceedings{C_2024EMNLP_sammo,
    title = {Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization},
    author = {Schnabel, Tobias and Neville, Jennifer},
    booktitle = EMNLP,
    year = {2024},
    pages = {670--686},
}

@inproceedings{C_2024ICLR_DSPy,
  title={DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  booktitle = ICLR,
  year={2024}
}

@inproceedings{C_2024ICLR_LLMasOPT,
    author = {Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le and Denny Zhou and Xinyun Chen},
    title = {{Large Language Models as Optimizers}},
    booktitle = ICLR,
    year = 2024
}

@inproceedings{C_2024ICLR_formatspread,
    author = {Melanie Sclar and Yejin Choi and Yulia Tsvetkov and Alane Suhr},
    title = {{Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting}},
    booktitle = ICLR,
    year = 2024,
}

@inproceedings{C_2024ICLR_promptagent,
    author={Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting},
    title = {PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},
    booktitle = ICLR,
    year = 2024,
}

@article{J_2024TMLR_moreagent,
      title={More agents is all you need},
      author={Li, Junyou and Zhang, Qin and Yu, Yangbin and Fu, Qiang and Ye, Deheng},
      journal={Transactions on Machine Learning Research},
      year={2024},
}

@misc{O_2023_Autogpt,
    title = {Auto-GPT},
    author = {WHO},
    year = {2023},
    howpublished = {\url{https://github.com/Significant-Gravitas/AutoGPT}},
}

@misc{O_2023_CRISPE,
  author       = {Matt Nigh},
  title        = {ChatGPT3 Free Prompt List},
  year         = {2023},
  howpublished = {\url{https://github.com/mattnigh/ChatGPT3-Free-Prompt-List}},
}

@misc{google2024Promptingguide101,
  author = {Google},
  title = {Prompting Guide 101},
  howpublished = {\url{https://workspace.google.com/resources/ai/writing-effective-prompts/}},
  year = {2024},
}

@misc{he2024doespromptformattingimpact,
      title={Does Prompt Formatting Have Any Impact on LLM Performance?}, 
      author={Jia He and Mukund Rungta and David Koleczek and Arshdeep Sekhon and Franklin X Wang and Sadid Hasan},
      year={2024},
      eprint={2411.10541},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.10541}, 
}

@misc{hu2024automateddesignagenticsystems,
      title={Automated Design of Agentic Systems}, 
      author={Shengran Hu and Cong Lu and Jeff Clune},
      year={2024},
      eprint={2408.08435},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.08435}, 
}

@misc{lu2024aiscientistfullyautomated,
      title={The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery}, 
      author={Chris Lu and Cong Lu and Robert Tjarko Lange and Jakob Foerster and Jeff Clune and David Ha},
      year={2024},
      eprint={2408.06292},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.06292}, 
}

@misc{opsahlong2024dspy,
      title={Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs}, 
      author={Krista Opsahl-Ong and Michael J Ryan and Josh Purtell and David Broman and Christopher Potts and Matei Zaharia and Omar Khattab},
      year={2024},
      eprint={2406.11695},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11695}, 
}

@misc{prasad2023grips,
      title={GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models}, 
      author={Archiki Prasad and Peter Hase and Xiang Zhou and Mohit Bansal},
      year={2023},
      eprint={2203.07281},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.07281}, 
}

@misc{promptbreeder,
      title={Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution}, 
      author={Chrisantha Fernando and Dylan Banarse and Henryk Michalewski and Simon Osindero and Tim Rocktäschel},
      year={2023},
      eprint={2309.16797},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.16797}, 
}

@misc{salinas2024butterflyeffectalteringprompts,
      title={The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance}, 
      author={Abel Salinas and Fred Morstatter},
      year={2024},
      eprint={2401.03729},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.03729}, 
}

@inproceedings{voronov-etal-2024-mind,
    title = "Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements",
    author = "Voronov, Anton  and
      Wolf, Lena  and
      Ryabinin, Max",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.375/",
    doi = "10.18653/v1/2024.findings-acl.375",
    pages = "6287--6310"
}

@misc{zhou2023ape,
      title={Large Language Models Are Human-Level Prompt Engineers}, 
      author={Yongchao Zhou and Andrei Ioan Muresanu and Ziwen Han and Keiran Paster and Silviu Pitis and Harris Chan and Jimmy Ba},
      year={2023},
      eprint={2211.01910},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.01910}, 
}

