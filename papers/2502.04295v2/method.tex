\begin{figure*}[t]
  \vspace{-2ex}
  \includegraphics[width=\linewidth]{fig/formats5.png}
  \vspace{-4.5ex}
  \caption {Built-in formats and rendering effects in our initial format pool. The final format configuration is achieved by selecting and combining elements from both the \textit{Prompt Renderer} and the \textit{Query Format} categories.}
  \vspace{-2ex}
  \label{fig:init_format}
\end{figure*}

\section{\sysname{}: Content-Format Integrated Prompt Optimization}
\label{sec:method}

% To present our methodology, we first introduce a universal prompt template that distinctly separates the content and formats given a prompt (Section~\ref{sec:template}). We could define a prompt as $p=(c, f)$, where $c$ denotes prompt content and $f$ denotes the prompt format.
% Starting from an initial configuration $p_0=(c_0, f_0)$, the objective of integrated prompt optimization is to identify an optimal prompt:
% \begin{align}
% p^*:(c^*, f^*)=\arg\max_{c \in \mathcal{L}, f \in \mathcal{F}}m(c,f|\mathcal{D}),
% \end{align}
% within the coherent natural language space $\mathcal{L}$ and format space $\mathcal{F}$, guided by a metric function $m(\cdot)$ and the evaluation data $\mathcal{D}$.
As we have established, the effectiveness of LLMs is profoundly influenced by both the content and format of prompts. Existing automated prompt optimization methods have largely overlooked the format dimension, which exhibits a strong model bias. To address this critical limitation, we introduce \fullsysname{} framework that jointly optimizes both prompt content and format. This contrasts with prior approaches focusing solely on content optimization.
Our goal is to identify an optimal prompt $p^*$, comprising both content ($c^*$) and format ($f^*$), that maximizes performance on an evaluation dataset $\mathcal{D}$, given by:
\begin{align}
p^*:(c^*, f^*)=\arg\max_{c \in \mathcal{L}, f \in \mathcal{F}}m(c,f|\mathcal{D}),
\end{align}
within the coherent natural language space $\mathcal{L}$ and the space of all possible formats $\mathcal{F}$, guided by a metric function $m(\cdot)$ that assesses the prompt's quality.

% Given the interdependence of content and format on performance, we employ a joint search strategy with two optimizers to optimize both concurrently, as shown in Figure~\ref{fig:pipeline}. 
% Specifically, the format optimization process is detailed in Section~\ref{sec:format_optimizer}, and a full explanation of the integrated optimizer framework can be found in Section~\ref{sec:dual_optimizer}.
To effectively search this complex space, \sysname{} employs a two-pronged iterative approach, detailed in Figure~\ref{fig:pipeline}, that consists of two concurrently-run optimizers: a \textit{Component-wise Content Optimizer} and a \textit{Format Optimizer}.  The content optimizer refines the textual content of a prompt, while the format optimizer explores the structural arrangement of its elements. Importantly, our framework acknowledges the inherent interdependence of content and format and thus iterates between optimizing them, to find their optimal combination. The following sections detail our structured prompt template (Section~\ref{sec:template}), our innovative format optimization approach (Section~\ref{sec:format_optimizer}), and finally our integrated optimization process (Section~\ref{sec:dual_optimizer}).

\subsection{Structured Prompt Template}
\label{sec:template}

% In the context of LLMs, the complexity of tasks necessitates a structured thinking approach to prompt engineering~\cite{A_2024_LangGPT}.
% Recognizing this, we adopt a universal prompt template for optimization, inspired by official guideline from ~\citet{openai_guide}
% and~\citet{google2024Promptingguide101}, which use structured frameworks to guide the development of prompt.
To enable fine-grained and targeted optimization, our framework adopts a structured prompt template inspired by guidelines from ~\citet{openai_guide} and~\citet{google2024Promptingguide101}. This template decomposes prompts into distinct functional components, facilitating both analysis and selective mutations. Specifically, our template divides a prompt into content-based components and format-based components, as illustrated in Figure~\ref{fig:template}.

% Based on functional roles, we categorized a prompt template into specific components, as illustrated in Figure~\ref{fig:template}. These components include:
\noindent The \textbf{\textcolor{black}{Content-based Components}} are:

% \vspace{1ex}
\noindent \textbf{\textcolor{black}{Task Instruction}} defines the primary goal, guiding the model's overall behavior.

\noindent \textbf{\textcolor{black}{Task Detail}} offers supplementary task-specific information, including resolution steps.

\noindent \textbf{\textcolor{black}{Output Format}} specifies the desired output structure (e.g., JSON, bullet points, etc.).

% \vspace{0.2ex}
\noindent \textbf{\textcolor{black}{Few-shot Examples}} provide contextual learning patterns, consisting of:
% \vspace{-0.1ex}
\begin{itemize}[itemsep=-4pt, topsep=-5pt]
    \item {\it \textbf{\textcolor{black}{Examples}}}: specific instances pertinent to the task, including inputs and expected outputs.
    \item {\it \textbf{\textcolor{black}{Example Hinter}}} (optional): a brief hint indicating that examples segment will follow, e.g., 'Here are some examples:'.
    \item {\it \textbf{\textcolor{black}{CoT Hinter}}} (optional): encourages a chain-of-thought reasoning process, e.g., 'Let's think step by step'.
\end{itemize}
\vspace{1ex}

\noindent \textbf{\textcolor{black}{Query}} shows the question or request to be answered by the LLM.

\vspace{1ex}
\noindent The \textbf{\textcolor{black}{Format-based Components}} are:

\noindent \textbf{\textcolor{black}{Query Format}}: defines how to structure the rendering of examples and queries.

\noindent \textbf{\textcolor{black}{Prompt Renderer}} defines how to aggregate all components into a structured prompt.
\vspace{1ex}

% Components highlighted in \textbf{\textcolor{green!40!black}{green}} pertain to the content domain, whereas those in \textbf{\textcolor{orange!80!black}{orange}} are associated with the format domain. Once all components have been set, we can assemble a complete prompt by combining them through the template's \textbf{\textit{\textcolor{orange!80!black}{Prompt Renderer}}}.

% This template offers two primary advantages: 
% firstly, it facilitates the application of structured thinking, allowing for finer constraints and selective mutation of specific components. 
% Secondly, it decouples the prompt's content from its format, which simplifies the mutation of the format through a format optimizer.

% This template offers two primary advantages: 
% (1) Structured component functionality. Each component within the prompt serves a unique function, to establish a structured-thinking framework.
% (2) Fine-grained optimization. By decoupling the promptâ€™s format from its content, the framework enables selective and precise mutations for specific components, enhancing flexibility and simplicity.
The formulation of the structured prompt template is fundamental to our optimization approach. This design yields two key advantages: first, it facilitates a structured component functionality where each part serves a specific purpose, promoting a more organized prompting framework; second, it enables fine-grained optimization by decoupling format from content, thus allowing targeted and precise modifications of individual components.


\subsection{Format Optimizer Design}
\label{sec:format_optimizer}

% In \sysname{} format optimizer, we design a format pool with a scoring system to identify promising formats effectively. To enhance format exploration, we integrate an LLM-assisted mechanism for generating diverse formats. Additionally, we adopt a highly efficient and effective approach to identify the most appropriate format from the pool, while recording format evaluation insights within the pool to guide subsequent iterations. These techniques are elaborated in the following subsections.
The key aspect of our work is the format optimization methodology. To efficiently explore the extensive range of prompt formats, the \sysname{} format optimizer adopts an approach that utilizes a format pool with a scoring system and an LLM-assisted format generation module. It strategically explores, evaluates, and refines formatting choices, all while learning from previous iterations.

\subsubsection{Format Pool with Scoring System}

% The widespread adoption of popularized prompt formats in LLMs highlights the need of a systematic format optimization approach. As shown in Figure~\ref{fig:init_format}, our analysis framework evaluates prompt formats across two principal dimensions: the \textit{Prompt Renderer} for rendering the entire prompt, and the \textit{Query Format} for rendering examples and queries. These two categories are distinctly defined in our format pool. By combining elements from both dimensions, we derive the final format configuration to generate a complete prompt.
The format pool is designed to hold the format configurations we use to generate prompts. As shown in Figure~\ref{fig:init_format}, these configurations are separated into two dimensions: the \textit{Prompt Renderer}, which dictates the overall structure of the prompt, and the \textit{Query Format}, which governs the rendering of in-context examples and queries. This distinction allows us to explore both macro and micro-level formatting variations.

To dynamically evaluate the potential of each format, we developed a scoring system for assessing the performance of each format $f$, represented  as $Q(f)$. This system updates the performance score of $f$ across various prompt contents using the formula $Q(f)\gets Q(f)+\sum_c m(c,f)$, where $c$ represents each content instance in current round. Additionally, we maintain $N(f)$ to count the number of times a format has been visited, which facilitates score normalization.

To initialize the exploration, we constructed a initial format search space $\mathcal{F}$, comprising a set of predefined commonly used formats, as illustrated in Figure~\ref{fig:init_format}. We also incorporate diverse variations of these predefined formats into the initial search space, such as adjustments to spacing, punctuation, and the use of special symbols. This establishes a starting point for our optimization.

\subsubsection{LLM-assisted Format Generation}

% Given the vast variability in formats, initiating a comprehensive format pool makes manual collection of formats an impractical approach. To overcome this limitation, we employ LLM to serve as an automatic format generator, namely $LLM_{f\_gen}$.
% Specifically, the LLM generates new format functions based on the existing pool, which are subsequently expand the format pool.
The variability of format space requires an automated process for effective expansion and exploration. To that end, we introduce an LLM-based format generator, $LLM_{f\_gen}$, which autonomously generates new formats based on information in the existing format pool.

% Our methodology adopts an evolutionary approach, integrating the format generation process into each round of our overall search strategy, allowing it to propose novel and potentially useful formats to enhance the robustness of the optimization process.
This evolutionary approach integrates the format generation into each optimization round, allowing for the creation of new and potentially beneficial formats.
To enhance the efficiency of this process, we guide the LLM towards more promising areas by informing it of the performance function, $\frac{Q(f)}{N(f)}$. 
This iterative process not only diversifies the format pool but also ensures that our system can adapt to and incorporate a wide range of formats, thereby enhancing its utility and effectiveness.
More detailed information of our format generation process is provided in the Appendix \ref{mt:format_gen}.

\subsubsection{Search Format via Format Optimizer}

% For a given input prompt, the format optimizer aims to identify the most appropriate format from a predefined format pool.
For each content candidate generated by the content optimizer, the format optimizer aims to identify the most appropriate format from format pool. %and record valuable insights back into the pool for future iterations.
To navigate the balance between exploring new formats and exploiting known effective ones, we implemented the Upper Confidence Bounds applied to Trees (UCT) algorithm~\citep{kocsis2006bandit}. The UCT algorithm employs a selection criterion given by:
\begin{align}
UCT(f)=\frac{Q(f)}{N(f)} + \alpha \sqrt{\frac{\sum_f N(f)}{N(f)}}\label{eq:uct}
\end{align}
where $\alpha$ serves as a balancing hyper-parameter, adjusting the trade-off between exploration and exploitation.
% To avoid the computationally intensive brute-force search across the entire pool, we employ UCT selection algorithm that significantly enhances efficiency in our scoring system.

The overall process, outlined in Algorithm~\ref{alg:search_format}, %involves utilizing $2k$ formats in each round, comprising $k$ pre-existing formats selected from the pool and $k$ newly generated formats in current round.
selects $2k$ formats for evaluation in each optimization round: $k$ promising formats from the pool (based on UCT score), and $k$ new formats generated by the $LLM_{f\_gen}$. The selected formats from both the existing pool ($\mathcal{F}_{select}$) and the new generated pool ($\mathcal{F}_{gen}$) are then evaluated using a predefined metric function $m(\cdot)$, and the best-performing format among the tested candidates will be identified. The result is then incorporated into the pool for future iterations.

\begin{algorithm}[t]
    \caption{Searching Optimal Format Given a Prompt Candidate}
    \label{alg:search_format}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE $p_0=(c_0,f_0)$: initial prompt, $p=(c, \cdot)$: current prompt candidate(with content $c$), $\mathcal{F}$: dynamic format pool, $k$: number of formats, $m(\cdot)$: evaluation metric, $\mathcal{D}$: evaluation data.
        \STATE Initialize: $Q(f) \gets m(c_0,f)$, $N(f) \gets 1$ for all $f \in \mathcal{F}$

        \STATE \textbf{Format Selection}: $\mathcal{F}_{select} \gets \{f \in \mathcal{F}: f$ is in the top $k$ w.r.t. $UCT(f)\}$
        
        \STATE \textbf{Format Generation}:
        \FOR{each $i=0,1,...,k$}
            \STATE Generate format: $f_{new} \gets LLM_{f\_gen}(\mathcal{F})$
            % \STATE $\mathcal{F} \gets \mathcal{F} \cup \{f_{new}\}$, $\mathcal{F}_2 \gets \mathcal{F}_2 \cup \{f_{new}\}$
            \STATE Collect $f_{new}$ to $\mathcal{F}_{gen}$, and add $f_{new}$ to $\mathcal{F}$
        \ENDFOR
        
        \STATE \textbf{Format Evaluation}:
        \FOR{each $f \in \mathcal{F}_{select} \cup \mathcal{F}_{gen}$}
            \STATE Evaluate $m(c, f)$ with dataset $\mathcal{D}$
            \STATE $Q(f) \gets Q(f) + m(c, f)$
            \STATE $N(f) \gets N(f) + 1$
            \STATE Update $UCT(f)$ by Eq.~\ref{eq:uct}
        \ENDFOR
        \STATE $\hat f \gets \arg\max_{f \in \mathcal{F}_{select} \cup \mathcal{F}_{gen}}m(c,f)$
        \ENSURE The optimal format $\hat f$ for content $c$
    \end{algorithmic}
\end{algorithm}


% Firstly, the procedure identifies the $k$ formats with the highest potential from the pool, based on their $UCT$ scores. This step is followed by generating $k$ novel formats through $LLM_{f\_gen}$. These newly created formats are then incorporated into the format pool. 
% These steps collectively select a subset of size $2k$ for evaluation, effectively narrowing down the pool of candidates for optimization and exploring novel format configurations that could yield superior performance.

% Subsequently, formats from both $\mathcal{F}_{select}$ and $\mathcal{F}_{gen}$ are assessed using a predefined metric function $m(\cdot)$, and the best-performing format among the tested candidates will be identified. Meanwhile, the outcomes of these evaluations are then integrated back into the format pool, augmenting its utility for future optimization cycles.

By iteratively evaluating formats, the format optimizer ensures a balance between exploring new formats and refining current ones, converging to the best format configuration.

\subsection{Integrated Optimizer Design}
\label{sec:dual_optimizer}

% Here we introduce the overall framework of \fullsysname{}, as illustrated in Figure~\ref{fig:pipeline}. \sysname{} is designed to enhance the effectiveness of prompts via a integrated approach: encompassing Component-wise Content Optimization and the Format Optimization.
\sysname{} orchestrates the Component-wise Content Optimization and Format Optimization within an iterative framework to jointly optimize content and format. This iterative process (illustrated in Figure~\ref{fig:pipeline}) is key to our methodology.

\noindent \textbf{Component-wise Content Optimization:} %forms the first stage in each iteration of \sysname{}. The Component-wise Content Optimizer 
This stage employs two primary strategies for mutating the content of prompts. The first strategy is case-diagnosis and revision, leveraging test cases to assess the efficacy of the current prompt. The outcomes of these test cases, including both correct and incorrect samples, are analyzed by the LLM optimizer. This optimizer evaluates the performance and pinpoints specific components in need of optimization. Subsequently, targeted feedback is applied to these identified components for enhancement, resulting in improved prompts. For example, if the output is not in the specified format, the output format component will be altered.  
Additionally, a Mote-Carlo sampling strategy is employed to enhance the optimization robustness by generating synthetic content with same semantics for randomly selected components.
% Following these optimization steps, the most promising prompts are selected based on their performance on an evaluation set, with the top-performing prompts selected to the next stage.
After this step, we select top-performing content candidates based on an evaluation dataset for the next stage.

\noindent \textbf{Format Optimization:} %concentrates on identifying the most suitable format for each prompt candidate. As detailed in Section~\ref{sec:format_optimizer}, this stage involves an iterative process to generate new formats, select and test formats with the given prompt, match each prompt with an optimal format, and incorporate the test outcomes of these prompts back to maintain the scoring system. 
As discussed in Section~\ref{sec:format_optimizer}, this stage identifies the most effective format for each candidate prompt content from the previous content-optimization step.  The format optimizer applies our dynamic format exploration and evaluation process, tracking performance, and updating the format pool's scoring system.
The Format Optimizer meticulously tracks the performance of all evaluated formats, providing valuable insights to guide the selection of formats in subsequent iterations. Simultaneously, it retains only the most effective format for each prompt, ensuring the diversity of prompt content candidates during beam search.
% This strategic approach is instrumental in presenting the optimized content in the most compelling manner, thereby significantly enhancing the quality of the prompts generated by the \sysname{} framework.

% Throughout the optimization process, an iterative approach is employed in each round to complete the two-stage method. We utilize LLM to conduct the optimization (delineated by the yellow dashed line in Figure~\ref{fig:pipeline}), leveraging the strengths of LLMs for swift adaptation and tailored customization. By exploring both content and format dimensions, the \sysname{} framework not only enhances prompt quality from both aspects but also systematically documents the most promising formats by updating the value function of formats within the format pool.
In summary, the two optimizers work in tandem, leveraging the strengths of the LLM to facilitate swift adaptation and customization. Importantly, this iterative process allows for the optimization of format and content, thereby significantly enhancing the quality of the generated prompts.



\begin{table*}
  \centering
  {\footnotesize
  \begin{tabular}{lcccc}
    \hline
    \toprule
    \textbf{Method} & \textbf{Mistral-7B-v0.1} & \textbf{LLaMA-3.1-8B} & \textbf{LLaMA-3-8B-Instruct} & \textbf{Phi-3-Mini-Instruct} \\
    \hline
    \multicolumn{5}{c}{\rule{0pt}{2.5ex}\textbf{\textit{GSM8K}}\rule{0pt}{2.5ex}}\\
        Baseline (1-shot cot)   & 36.85         & 50.03         & 74.00             & 83.45  \\
        Baseline (8-shot cot)   & 38.21         & 51.02         & 73.46          & 85.75 \\
        % Baseline Prompt         & 45.11         & 51.02         & 74.53         & 83.45 \\
        GRIPS                   & 39.04             & 50.27             & 74.53             & 83.47 \\
        APE                     & 40.33         & 52.39         & 75.13         & 83.85 \\
        ProTeGi                     & 45.72         & 54.74         & 75.36         & 84.84 \\
        % AutoGPT & & & & \\
        SAMMO                   & 43.82         & 54.74         & 75.89         & 84.76 \\
        % DSPy COPRO & & & & \\
        \textbf{\sysname{}} (\textit {Ours})                    &\textbf{53.22} &\textbf{63.38} & \textbf{80.74} & \textbf{89.16} \\
    \hline
    
    \multicolumn{5}{c}{\rule{0pt}{2.5ex}\textbf{\textit{MATH-500}}\rule{0pt}{2.5ex}}\\
        Baseline (1-shot cot) &  4.60          & 10.58          & 12.20          & 12.60  \\
        Baseline (4-shot cot) & 10.20          & 23.40          & 14.00          & 40.40  \\
        GRIPS                 & 13.40          & 15.80          & 23.60          & 10.80 \\
        APE                   & 11.60          & 12.80          & 22.80          & 30.60 \\
        ProTeGi               & 10.80          & 17.00          & 18.40          & 28.80 \\
        % AutoGPT & & & & \\
        SAMMO                 & 12.20          & 15.40              & 25.80          & 42.40 \\
        % DSPy COPRO & & & & \\
        \textbf{\sysname{}} (\textit {Ours})       & \textbf{14.80} & \textbf{26.99} & \textbf{33.33} & \textbf{44.20} \\
    \hline
    \multicolumn{5}{c}{\rule{0pt}{2.5ex}\textbf{\textit{ARC-Challenge}}\rule{0pt}{2.5ex}}\\
        Baseline    & 67.15          & 73.81            & 75.94          & 84.39 \\
        GRIPS               & 77.05          & 77.90            & 79.61          & 87.46 \\
        APE                 & 75.85          & 77.05            & 78.67          & 87.63 \\
        ProTeGi             & 76.54          & 77.22            & 79.86          & 87.54 \\
        % AutoGPT & & & & \\
        SAMMO               & 77.22          & 77.13            & 79.86          & 87.03 \\
        % DSPy COPRO & & & & \\
        \textbf{\sysname{}} (\textit {Ours})      & \textbf{79.35} & \textbf{78.50}   & \textbf{80.63} & \textbf{88.23} \\
    \hline
    \multicolumn{5}{c}{\rule{0pt}{2.5ex}\textbf{\textit{Big-Bench Classification}}\rule{0pt}{2.5ex}}\\
        Baseline  & 56.00          & 64.00          & 70.00          & 54.00      \\
        GRIPS           & 86.00          & 67.00          & 84.00          & 69.00      \\
        APE             & 73.00          & 65.00          & 60.00          & 63.00      \\
        ProTeGi             & 83.00          & 81.00          & 82.00          & 76.00      \\
        % AutoGPT & & & & \\
        SAMMO           & 86.00          & 80.00          & 86.00          & 78.00      \\
        % DSPy COPRO & & & & \\
        \textbf{\sysname{}} (\textit {Ours})            & \textbf{94.00} & \textbf{90.00} & \textbf{91.00} & \textbf{87.00} \\ \bottomrule
    \hline
  \end{tabular}
  }
  \vspace{-1ex}
  \caption{\label{tbl:mainresults}
    Main results on math reasoning tasks and commonsense reasoning tasks.
  }
  \vspace{-2ex}
\end{table*}