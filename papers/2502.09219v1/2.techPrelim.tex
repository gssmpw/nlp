We extend the framework of~\cite{eiter2022neuro}, which represents both images and queries as ASP programs (and the programs can be directly represented as an equivalent scene graph as shown in Figure~\ref{fig:sgaug}).  Their approach to VQA leverages a neurosymbolic framework and was tested on synthetic datasets (e.g., CLEVR~\cite{johnson2017clevr}) that involve limited objects and attributes.
We seek to extend their results to real-world datasets such as GQA~\cite{hudson2019gqa}, which are more complex. We follow the logic programming construct as~\cite{eiter2022neuro} in that we have logical facts representing the scene graphs ($\Pi^{I}$), the query to be answered ($\Pi^{Q}$), as well as standard ``VQA helper'' rules ($\Pi^{R}$).

We assume the existence of a first order logical language (constants $\mathcal{C}$, variables $\mathcal{V}$, predicates $\mathcal{P}$).  
Set $\mathcal{C}$ has several subsets: objects ($\mathcal{C}_{obj}$), attributes ($\mathcal{C}_{att}$), domains ($\mathcal{C}_{dom}$), and single choice questions ($\mathcal{C}_{sinChoice}$).  Additionally, we will have a special binary predicate $assign$ where the first argument is an attribute and the second is a domain.  
Every attribute can thus be associated with one or more domains via atom $assign(a,d)$, meaning that attribute $a$ has domain $d$. We will also define Answer Set Programming (ASP) rules in the usual manner; a rule with no body is a fact and a set of rules is a program.  Given a program $\Pi$, the subset of facts in $\Pi$ where the head is formed with $assign$ is called the ``domain relationships'', and denoted $\Pi^D$.  
Likewise, we assume programs representing an image and a query, $\Pi^I$ and $\Pi^Q$, respectively, that do not contain domain relationships, and a common set of rules $\Pi^R$ that answers the query using $\Pi^I$ and $\Pi^Q$.  
Also, we shall use the standard ASP semantics based on interpretations~\cite{eiter2022neuro}, and use the notation $I \models \Pi$ to denote that interpretation $I$ satisfies program $\Pi$.  
Further, we say that program $\Pi_1 \models \Pi_2$ (read ``$\Pi_1$ entails $\Pi_2$'') meaning that all interpretations that satisfy $\Pi_1$ also satisfy $\Pi_2$.

In this work, we are primarily concerned with the case where there is a common $\Pi^D$ for a collection of image-query program pairs (``examples'') denoted 
$\langle\Pi^{I}_1, \Pi^Q_1\rangle, \ldots, \langle\Pi^{I}_n, \Pi^Q_n\rangle$.  
We may also know that a given $\langle\Pi^{I}_i,\Pi^Q_i\rangle$ is associated with some set of {\em ground truth} $\Pi^{GT}_i$. Due to the lack of domain knowledge, $\Pi^{I}_i\cup\Pi^Q_i\cup\Pi^{R}$ may not entail $\Pi^{GT}_i$. 
However if an oracle provides a correct $\Pi^D$, we have that $\Pi^{I}_i\cup\Pi^{Q}_i \cup \Pi^{R} \cup \Pi^{D} \models \Pi^{GT}_i$. 
We show an example of this case below taken from the scene graph dataset of~\cite{hudson2019gqa} (depicted in Figure~\ref{fig:sgaug}), which we also use in our experiments.


\begin{example}
    Consider a program $\Pi_i = \Pi^{I}_{i} \cup \Pi^{Q}_{i} \cup \Pi^{R}$ that consists of the following scene representation~$\Pi^{I}_{i}$, question representation $\Pi^{Q}_{i}$ for the question ``What is the color of the fruit to the right of the juice?'', and the set of rules $\Pi^{R}$ common to all image-query program pairs:

    \begin{equation*}
        \begin{array}{cc}
            \Pi^{I}_{i} = \left\{
            \begin{array}{lllll}
                ob(2317538, 51). &
                name(51, cup). &
                attr(51, glass). & 
                attr(51, white). \\
                ob(2317538, 54).  &
                name(54, apple).  &
                attr(54, round).  &
                attr(54, red).  \\
                ob(2317538, 55).  &
                name(55, banana).  &
                attr(55, yellow).  & attr(55, large). & rel(55,57,right). \\ 
                ob(2317538, 57).  &
                name(57, juice).  &
                attr(57, yellow).  & rel(57,55,left). \\ 
            \end{array}
            \right.
            \end{array}
    \end{equation*}
    
    \begin{equation*}
        \begin{array}{cc}
            \Pi^{Q}_{i} = \left\{
            \begin{array}{lll}
                scene(0, 2317538).  &
                select(1,juice,0).  &
                relate(2,fruit,right,1).  \\
                query(4,color,3).  &
                exit(5). 
            \end{array}
            \right.
        \end{array}
    \end{equation*}

\noindent
As in~\cite{eiter2022neuro}, our question representation $\Pi^{Q}_i$ is structured so that each query part is organized sequentially, with the first argument of each predicate indicating order and the last argument showing dependency on prior results. This step-by-step approach along with $\Pi^{R}$ aids in answering questions effectively:

    \begin{equation*}
        \begin{array}{c}
            \Pi^{R} = \left\{
            \begin{array}{rcl}
                r(T, OID) &:-& scene(T,S), ob(S,OID). \\
                r(T, OID) &:-& select(T, ON, D), r(D, OID), name(OID, ON). \\
                r(T, TID) &:-& relate(T, GC, R, D), r(D, OID), rel(TID, OID, R), name(TID, ON), \\& & assign(ON,GC). \\
                r(T, A) &:-& query(T, color, D), r(D, OID), attr(OID, A), assign(A, color). \\
                result(RSLT) &:-& exit(T), r(T-1, RSLT). \\
                empty(AT) &:-& exit(T), not\ r(AT,\_), AT=0..T-1.
            \end{array}
            \right.
        \end{array}
    \end{equation*}

    \noindent
    For this question, the ground truth is the program: 

    \begin{equation*}
        \begin{array}{c}
            \Pi^{GT}_{i} = \left\{
            \begin{array}{rcl}
                result(yellow).
            \end{array}
            \right\}
        \end{array}
    \end{equation*}

    \noindent
    However, due to the lack of atoms $assign(banana, fruit)$ and $assign(yellow, color)$, we see that, 
    \mbox{$\Pi_{i} \nvDash \Pi^{GT}_{i}$}. Now we assume that an oracle provides us with $\Pi^{D}$, as follows:
    \begin{equation*}
        \begin{array}{cc}
             \Pi^{D} = \left\{
            \begin{array}{lll}
                assign(glass, material). &
                assign(white, color). &
                assign(apple, fruit). \\
                assign(round, shape). &
                assign(red, color). &
                assign(banana, fruit). \\
                assign(yellow, color). & assign(large,size). &
                assign(juice, drink).
            \end{array}
            \right.
        \end{array}
    \end{equation*}

\noindent
    With the existence of this domain $\Pi^{D}$, now we have $\Pi_{i} \cup \Pi^D \models \Pi^{GT}_{i}$.
\label{ex:techprelim}
\end{example}

\smallskip
\noindent\textbf{Fallback Rules.}
In this framework, where we may have an absent or partial $\Pi^D$, it is useful to have ``fallback rules'' of the form: 
$assign(att,default) \leftarrow \bigwedge_{att \in \mathcal{C}_{att}\setminus\{default\}}\neg assign(att,DOM)$.  This assumes a special attribute constant ``default'' to which an object without an attribute falls back.  
The next example augments Example~\ref{ex:techprelim} with fallback rules:

\smallskip

\begin{example}
    We assume additional fallback rules, added to $\Pi^{R}$, of the form:
        \begin{equation*}
        \begin{array}{c}
           % \Pi^{FB} = \left\{
            \begin{array}{rcl}
                r(T, A) &:-& query(T, color, D), r(D, OID), attr(OID, A),
                \\ && \neg assign(A, color), assign(A, default).
            \end{array}
            %\right.
        \end{array}
    \end{equation*}
    Returning to our running example, assuming there is no $\{assign(yellow,color).\} \in \Pi^{D}$, adding fallback rules, we get the following $\Pi^{D}$:
    \begin{equation*}
        \begin{array}{cc}
             \Pi^{D} = \left\{
            \begin{array}{lll}
                assign(glass, material). &
                assign(white, color). &
                assign(apple, fruit). \\
                assign(round, shape). &
                assign(red, color). &
                assign(banana, fruit). \\
                assign(yellow, default). & assign(large,size). &
                assign(juice, drink).
            \end{array}
            \right.
        \end{array}
    \end{equation*}
\label{ex:prwithfallback}
\end{example}


\noindent\textbf{Abducing Domain Relationships.}  We now formalize our problem.  
Given examples
$\mathbf{EX} = \{\langle \Pi^{I}_1,\Pi^Q_1\rangle,$ $\ldots,\langle\Pi^{I}_n,\Pi^Q_n\rangle \}$ with a common rule set $\Pi^{R}$ (which may or may not include fallback rules) and corresponding ground truth $\mathbf{GT}=\{\Pi^{GT}_1,\ldots,\Pi^{GT}_n \}$, 
then $\langle \mathbf{EX},\mathbf{GT},\Pi^{R} \rangle$ is a \textit{domain abduction problem} (DAP).  

Any $\Pi^D$ containing only facts formed with $assign$ in the head is a {\em hypothesis} for a DAP.  
A hypothesis $\Pi^D$ is an \textit{explanation} for DAP $\langle \mathbf{EX},\mathbf{GT},\Pi^{R} \rangle$ if and only if for all $i$ we have $\Pi^{I}_i\cup\Pi^{Q}_i\cup\Pi^{R}\cup\Pi^D \models  \Pi^{GT}_i$.  
However, when $\mathbf{EX},\mathbf{GT}$ are noisy (e.g., produced from a machine learning system) there may be no explanation; in such cases, we may be able to find a hypothesis $\Pi^D$ that maximizes some accuracy or recall metric.
For example, finding $\Pi^D$ that maximizes $\frac{1}{|\mathbf{GT}|} |\{\Pi^{GT}_i \in \mathbf{GT} \textit{ s.t. } \Pi^{I}_i\cup\Pi^{Q}_i\cup\Pi^{R}\cup\Pi^D \models  \Pi^{GT}_i\}|$ (where $|\cdot|$ is set cardinality) would lead to maximized accuracy.





