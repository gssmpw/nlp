\section{Background and Motivation}

\subsection{Code Refinement}\label{sec:background}
% Code refinement aims to modify the original code (denoted as C1) based on the reviewer's comments (denoted as RC), automatically generating the revised code (denoted as C2) that meets the specified requirements. Tufano et al.~\cite{tufano2019learning} first implemented an automated method based on Neural Machine Translation (NMT) to handle Java code reviews. Afterwards, many works utilize more advanced models and techniques in this field, such as Transformer~\cite{tufano2021towards,thongtanunam2022autotransform}, T5~\cite{tufano2022using}, and CodeT5~\cite{li2022automating}. However, the achieved progress is still limited. The generated accuracy remains below 40\%~\cite{li2022automating}, with many studies reporting results below 20\%~\cite{pornprasit2024fine}. Furthermore, the latest empirical study~\cite{guo2024exploring} has revealed that 8\% of errors that these models cannot generate the correct code due to missing explicit review line information and 40\% of errors were due to a lack of domain knowledge, including some that were missing information on the last modification. 

% We follow the definition provided by Li~\cite{li2022automating}. 
In the code review process, the developer first modifies the initial version of the code, resulting in a second version.  The modifications made to the code are captured as the last code diff hunk (denoted as \texttt{LastCodeDiffHunk}). The reviewer then evaluates the last code diff hunk along with the second version of the code to provide review comments (denoted as  \texttt{ReviewComment}). Each review comment is linked to a specific line in the code (denoted as \texttt{ReviewLine}). Subsequently, the developer modifies the second version of the code based on the reviewer’s comments, generating the third version of the code that meets the reviewer’s requirements. This subsequent modification process is referred to as the code refinement task. For clarity, the second version is henceforth referred to as the \texttt{OriginalCode}, and the third version as the \texttt{RevisedCode}. 


% Tufano et al.~\cite{tufano2019learning} first implemented an automated method based on Neural Machine Translation (NMT) to handle Java code reviews. Afterwards, many works utilize more advanced models and techniques in this field, such as Transformer~\cite{tufano2021towards,thongtanunam2022autotransform}, T5~\cite{tufano2022using}, and CodeT5~\cite{li2022automating}. However, the achieved progress is still limited. The generated accuracy remains below 40\%~\cite{li2022automating}, with many studies reporting results below 20\%~\cite{pornprasit2024fine}. Furthermore, the latest empirical study~\cite{guo2024exploring} has revealed that 8\% of errors that these models cannot generate the correct code due to missing explicit review line information and 40\% of errors were due to a lack of domain knowledge, including some that were missing information on the last modification. 

The traditional code refinement, which we refer to as Basic Code Refinement, involves taking \texttt{OriginalCode} and \texttt{ReviewComment} as input and producing \texttt{RevisedCode} as output. However, we found that in some tasks, \texttt{ReviewLine} and \texttt{LastCodeDiffHunk} are needed to help understand the \texttt{ReviewComment}. 
We define two new tasks to address these issues: Position-Aware Code Refinement, which takes \texttt{OriginalCode}, \texttt{ReviewLine}, \texttt{ReviewComment} as input; and Comprehensive Code Refinement, which takes \texttt{OriginalCode}, \texttt{ReviewLine}, \texttt{ReviewComment} and \texttt{LastCodeDiffHunk} as input.


% 在一次Code review的流程中，首先由developer修改了initial code(记做C0)，得到了revised code（记做C1）,修改的code diff hunk记做LCDH。reviewer根据LCDH和C1版本的代码，提出review comment。而后，developer modify the C1 code based on the reviewer's comments (denoted as RC), automatically generating the 再修改的代码 (denoted as C2) that meets the specified requirements.后面的修改过程就是code Refinement任务。
% 为了称呼方便也避免混淆。我们称C0为initial code，C1叫做Original code，C2叫做Revised code，LCDH称为

 % Tufano initially implemented an automated method based on Neural Machine Translation (NMT) to handle Java code reviews~\cite{tufano2019learning}. Subsequently, many researchers have used pretrained models such as Transformer~\cite{tufano2021towards,thongtanunam2022autotransform}, T5~\cite{tufano2022using}, and CodeT5~\cite{li2022automating} for this task. These methods still rely on the input of review comment and original code only. This limitation is partly due to the input length constraints of pretrained models~\cite{wang2021codet5} and partly because not all data require additional information. The accuracy for this task remains below 40\%~\cite{li2022automating}, with many studies reporting results below 20\%~\cite{pornprasit2024fine}. The low accuracy has led researchers to overlook the extent to which the lack of additional information impedes the model's performance. In an empirical study, Guo~\cite{guo2024exploring} found that using ChatGPT for code refinement resulted in 8\% of errors due to missing explicit review line information. Most data lacking review line information could be corrected if the information were provided. Additionally, 40\% of errors were due to a lack of domain knowledge, including some that were missing information on the last modification.



% During a code review process, the developer initially submits a modification, changing the original code (C0) to a new version (C1). Subsequently, the reviewer provides a review comment (RC) on this modification (C0 to C1). Regardless of whether the reviewer submits the review or the developer views it, the RC is displayed after a specific line of code, referred to as the review line (RL). Typically, the review line corresponds to the portion of the code that was modified from C0 to C1, and the review provides evaluations and suggestions for the modification. In some cases, however, the review line may suggest further changes to code that was not altered in the initial modification. Following the RC, the developer revises C1 to produce a new version of the code, C2. 




% 为了使得refinement任务自动化，研究者提出了以下两个任务：code to code, code&comment to code。code to code是指根据original code，直接生成修改后的revised code。这个任务难度过高，目前的SOTA方法是Tufano在T5模型上训练的效果，EM准确率仅有5%。另一个任务是code&comment to code，也就是输入给模型original code，和review comment。要求输出根据review comment修改的code，即revised code。code&comment to code 任务的最早由Tufano实现了一个基于NMT的自动化方法，处理java code review的问题。后来很多研究者尝试使用了bert，T5， codet5等预训练模型完成该任务。他们对于代码修改任务的输入还只是comment+oldcode。一方面这受限于pretrained-model模型输入长度，另一方面是由于并非所有数据都需要额外数据。目前该任务的准确率一直低于40%，甚至很多文章的效果只有不到20%。过低的准确率使得研究者没有注意到有多少数据是因为缺少额外信息而使得模型难以做对的。Guo在他的经验研究中发现，使用ChatGPT完成code refinement任务时，有8%的错误原因是缺少明确的review line信息。并且绝大多数缺少review line信息的数据，如果补上review line信息，就可以mitigate该错误。另外有40%的做错的原因是因为缺少领域知识，这其中也包括一部分是缺少上次修改信息。

% 数据集：目前在coderefine领域有两个常用数据集。一个是由Tufano提出的Tu数据集，另一个是由li提出的codereview数据集。Tu数据集包括是从 Gerrit and GitHub爬取的java语言的coderefine数据集。字段包括original code，review comment，revised code和review line。但是不包括last diff，也不包含原始数据出处。codereview数据集是从github爬取的多编程语言数据集，其中字段不仅包括original code， review comment，revised code等字段。虽然没有包括review line和last diff，但是包括原始数据的出处，可以从原始的github数据中补全review line和last diff字段。

% \subsection{LLM for coderefinement}

% Guo was among the first to explore the potential of using ChatGPT for code refinement tasks, summarizing several practical insights. These include that concise prompts containing contextual information tend to yield better results and that setting the temperature to 0 produces the best outcomes. However, Guo's work was limited to zero-shot approaches. Subsequent research by Pornprasit delved deeper and found that utilizing few-shot methods can further enhance the accuracy of large models. Additionally, techniques such as Chain of Thought (COT), Retrieval-Augmented Generation (RAG), and self-generation, although not yet applied to code refinement tasks, have shown promising results in the fields of software engineering and code intelligence. The application of these methods in code refinement requires comparative analysis to evaluate their effectiveness.

% Guo最早探索了使用ChatGPT完成coderefinement任务的潜力，总结了一些应用经验，包括：简洁而包含场景描述信息的prompt可以取得较好效果；温度设置为0可以取得最好效果。Guo的工作只局限于zeroshot，随后Pornprasit深入研究发现，使用fewshot的方法可进一步提升大模型的准确率。另外还有COT，RAG，selfgen等技术，虽然还没被使用在code refinement任务，但已经在软件工程领域与代码智能领域已经取得较好效果，这些方法的应用在coderefine效果也需要我们进行对比分析。


\subsection{Motivation}
% \begin{figure}[!t]
% \centering
% \includegraphics[width=0.9\linewidth]{fig/motivation.pdf}
% \caption{Motivation of our work.}
% \label{fig:motivation}
% \end{figure}

Current approaches to code refinement are typically framed as end-to-end tasks, where machine learning models are expected to generate revised code directly from input data. This process often resembles a black-box guesswork for the models, lacking a complete reasoning process. 
% While Chain-of-Thought (COT) is a widely used method for improving reasoning, it has not yielded satisfactory results in the code refinement task. This is because the large models may not truly understand the comments and lack the ability to decompose the task like a human, thus failing to generate an effective reasoning path. 
% As shown in Fig.~\ref{fig:motivation}, the original code's \texttt{is\_spmv\_supported\_node\_feat} function always returns True, and the review comment requires this function to be removed. Yet, during analysis, the model merely repeats the statement from the review comment without pinpointing the content to be deleted. Consequently, the model's final answer fails to remove the function and instead completes \texttt{is\_spmv\_supported\_edge\_feat} by returning True. This may be due to the model hallucination, treating subsequent code fragments as a completion task.
We draw inspiration from the approaches employed by human developers to tackle code refinement tasks, enhancing the reasoning capabilities of large models by decomposing the complex task into subtasks: intention understanding and code refinement guided by the extracted intention.


% s, and therefore, the effectiveness of the results is difficult to ensure. To address this issue, a natural idea is to employ the Chain-of-Thought (COT) approach to supplement the reasoning process and improve model performance. The COT method aids models in clarifying the reasoning path by decomposing complex tasks into simpler sub-tasks that the model can handle~\cite{wei2022chain}. 

% For example, in the COT paper~\cite{wei2022chain}, a problem like “The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?” could lead to an incorrect answer if solved directly by the model. However, using the COT method, the model can be guided to understand the problem's meaning by breaking it down into several small steps, such as first calculating how many apples remain after using 20 for lunch and then adding six more to find the total. This allows the model to provide the correct result. 

% Therefore, we aim to draw inspiration from the methods human developers use to solve code refinement tasks, helping large models design specific reasoning paths by breaking down complex tasks into sub-tasks. Similar to the COT technique, decomposing the problem allows the model to have a clear reasoning process when solving code refinement tasks, enhancing the interpretability of the results and improving the final outcome.


\subsection{Data Collection}

Currently, there are two widely used datasets in the domain of code refinement: the Tufano dataset~\cite{tufano2019learning} and the CodeReview dataset~\cite{li2022automating}. As previously discussed, our research necessitates that the dataset provides the following five fields: \texttt{OriginalCode}, \texttt{ReviewLine}, \texttt{ReviewComment}, \texttt{LastCodeDiffHunk} and \texttt{RevisedCode}. The Tufano dataset lacks the \texttt{LastCodeDiffHunk} field and does not provide links to the original data. Although the CodeReview dataset lacks the \texttt{ReviewLine} and \texttt{LastCodeDiffHunk} fields, it does provide links to the original data. Consequently, we have chosen to use the CodeReview dataset and supplement the missing fields.

First, we describe the method for obtaining the \texttt{ReviewLine} field. We observed that by utilizing the GitHub REST API to retrieve code review information, it is possible to obtain a partial last code diff hunk (referred to as the diff hunk field in the API's JSON response\footnote{https://api.github.com/repos/meganz/sdk/pulls/comments/326107667}). We term this a partial last code diff hunk because it only provides the modification information preceding the review comment. 
% For instance, in an example where the original last code diff hunk involved the deletion of three lines and the addition of three lines, the review line appears after the addition of the first line. Consequently, the partial last code diff includes only the three deleted lines and one added line. 
Based on this pattern, we can deduce that the review line corresponds to the last line of the partial last code diff hunk.

Subsequently, we need to design a method to obtain the complete \texttt{LastCodeDiffHunk}. We observed that a single code review might encompass multiple commits reviewed by the reviewer. If a given pull request comprises \(n\) commits (\(commit_1, commit_2, ..., commit_n\)), the reviewer may choose to review all commits from \(commit_m\) to \(commit_n\) (where \(m \leq n\)), and then provide a review comment based on the accumulated file changes. 
% However, the GitHub REST API only provides the ID of the last commit, i.e., \(commit_n\), without specifying the preceding \(commit_m\). Nevertheless, the partial last code diff hunk provided by the GitHub REST API corresponds to the code diff hunk from \(commit_m\) to \(commit_n\). 
We sequentially traverse all preceding commits in reverse order and compare them with \(commit_n\) to obtain the code diff hunk near the review line. By comparing this with the partial last code diff, we can identify the complete last code diff hunk that matches the partial last code diff hunk. Based on this method, we can derive the \texttt{LastCodeDiffHunk}.

% Datasets: There are currently two commonly used datasets in the code refinement field. The first is the Tufano dataset~\cite{tufano2019learning}, and the second is the CodeReview dataset~\cite{li2022automating}. The Tufano dataset includes code refinement data for Java methods, crawled from Gerrit and GitHub. It consists of original code, review comment, revised code, and review line but lacks the last code diff. The CodeReview dataset is a multi-programming language dataset crawled from GitHub, including three data fields: original code, review comment, and revised code. Although it does not include review line and last code diff, it does contain original data sources links, allowing for the completion of review line and last code diff fields from the original GitHub data.