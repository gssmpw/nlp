\section{Introduction}

Code refinement focuses on enhancing existing code by addressing potential issues, refactoring, and optimizing to improve quality and meet specific requirements~\cite{bacchelli2013expectations,rigby2013convergent}. It is particularly crucial in software development as projects grow larger and more complex~\cite{fagan2002history,mcintosh2014impact}. 
According to an official report~\cite{Autio2022}, code review and refinement remain the most effective strategies for companies to improve code quality~\cite{sadowski2018modern,czerwonka2015code}. Thus, automated code refinement is crucial for software development~\cite{bavota2015four}. 


Traditionally, the code refinement process involves two sequential phases~\cite{bosu2013impact,rigby2014peer,bosu2015characteristics}. Initially, code reviewers examine the code and provide feedback (i.e., review comments) on any identified issues. Subsequently, software developers modify the code based on these comments. This process is iterative, with reviewers continuously identifying issues in subsequent refinements until the code is considered issue-free. Reviewers and developers often rely on natural language for communication, which can lead to a semantic gap that complicates their interactions, making the process both cumbersome and time-consuming~\cite{yang2016mining}.

A significant amount of work~\cite{tufano2019learning, tufano2021towards, tufano2022using, li2022automating} has been conducted to expedite this process. Despite these efforts, the performance has remained limited. For instance, the state-of-the-art technique only has 40\% accuracy on the popular code refinement benchmark~\cite{li2022automating}. Recent works~\cite{guo2024exploring, pornprasit2024fine,pornprasit2024gpt,yang2023enhancing,almeida2024aicodereview,fan2024exploring,watanabe2024use} have been exploring the feasibility of using large language models (LLMs) for code refinement. However, these techniques merely employ LLMs in a straightforward manner without designing effective solutions tailored to the specific characteristics of this task. As a result, they also fail to achieve satisfactory performance.

The primary issue with current research lies in the proposed techniques failing to accurately comprehend the reviewer's \textit{intent}, which is critical for code refinement. The reasons can be primarily attributed to two aspects. Some reviewers write comments that are very vague and brief, such as suggesting to delete a line of code without specifying the exact line number. As a result, models fail to learn the reviewer's precise intent. Guo et al.~\cite{guo2024exploring} further indicate that when the comments lack explicit location information or clear modification strategies, even models like ChatGPT~\cite{ouyang2022training,achiam2023gpt} underperform due to their inability to understand the intention. On the other hand, the models currently used in code refinement have limited learning capabilities and cannot handle complex scenarios effectively. Recent work~\cite{tufano2024code} shows that current code-pretrained models, such as T5CR~\cite{tufano2022using} and CodeReviewer~\cite{li2022automating}, are effective in automating basic code formatting improvements but struggle with more complex logical code modifications. These models often overfit to simple refinements, such as renaming a variable from \textit{a} to \textit{b}, while misinterpreting intricate tasks as trivial ones.





% In recent years, researchers have explored using Neural Machine Translation (NMT)~\cite{tufano2019learning}, Transformers~\cite{tufano2021towards,thongtanunam2022autotransform}, T5~\cite{tufano2022using}, codeT5~\cite{li2022automating}, and other pretrained models to tackle code refinement tasks.  With the emergence of large language models (LLMs), researchers like Guo~\cite{guo2024exploring} and Pornprasit~\cite{pornprasit2024fine} have investigated the potential of these models in code refinement, exploring techniques such as prompt engineering, model fine-tuning, and retrieval-augmented generation (RAG)~\cite{robertson2009probabilistic}. LLMs show considerable promise over traditional pretrained models in handling code refinement tasks due to their strong comprehension of natural language instructions and their inherent proficiency in code generation tasks.
% However, although existing methods provide a blueprint for automated code refinement, their performance is still unsatisfactory.
% For example, the current state-of-the-art (SOTA) methods exhibit relatively low exact match (EM) accuracy on two mainstream code refinement datasets, with only 40\% on the CodeReview dataset~\cite{li2022automating} and 19\% on the Tufano dataset.

% However, the progress in automating code refinement is still limited. The current state-of-the-art (SOTA) methods exhibit relatively low exact match (EM) accuracy on two mainstream code refinement datasets, with only 40\% on the CodeReview dataset~\cite{li2022automating} and 19\% on the Tufano dataset.




% Code review, an essential quality assurance method in both commercial and open-source software development, involves the examination of modified code by peers before merging. Increasingly adopted across numerous projects, code review is mandated by many organizations prior to code integration. This process enhances code quality and identifies coding defects, vulnerabilities, and code style violations early on. Additionally, reviewers share knowledge, expertise, and development techniques with developers, thereby deepening their understanding of the software system.

% Code refinement is the core task within code review. During this process, reviewers examine the developer’s code changes and, if issues are found, provide feedback near the problematic code, known as Review Comments. Developers then modify the code based on these comments, a process termed code refinement. This iterative process, where reviewers continue to highlight issues in subsequent refinements until the code is deemed issue-free, can be time-consuming and labor-intensive. To address this, numerous efforts have been made to automate code refinement tasks.

% Tufano~\cite{tufano2019learning} initially proposed the use of Neural Machine Translation (NMT)~\cite{cho2014properties} to automate code refinement tasks. Subsequently, various studies~\cite{tufano2021towards,thongtanunam2022autotransform,tufano2022using,li2022automating} explored the application of Transformers, T5, codeT5, and other pretrained models for this purpose. With the advent of large language models (LLMs), researchers such as Guo~\cite{guo2024exploring} and Pornprasit~\cite{pornprasit2024fine} have investigated the use of LLMs, examining techniques like prompt engineering, fine-tuning, and retrieval-augmented generation (RAG)~\cite{robertson2009probabilistic}. Compared to traditional pretrained models, LLMs hold significant potential in handling code refinement tasks due to their strong comprehension of natural language instructions~\cite{ouyang2022training, stiennon2020learning, he2024can} and inherent proficiency in code generation~\cite{nam2024using,gu2023llm,fakhoury2024llm}. However, the progress in automating code refinement remains limited, with current state-of-the-art (SOTA) methods~\cite{pornprasit2024fine} achieving only 40\% and 19\% exact match (EM) accuracy on the CodeReview~\cite{li2022automating} and Tufano datasets~\cite{tufano2022using}, respectively. A major hindrance is the inaccurate understanding of the reviewer’s intent by existing models, which treat code refinement primarily as a code generation task, thereby failing to fully comprehend the modification suggestions within Review Comments~\cite{tufano2024code}.


% Code review is a pivotal quality assurance process in software development and maintenance, utilized in both commercial and open-source software projects. During this process, peers examine code modifications before merging, ensuring that code quality is maintained by early identification and resolution of coding defects, vulnerabilities, and code style violations. As more projects adopt code review, many organizations have mandated its use prior to code merging. Beyond improving code quality, code review facilitates the sharing of knowledge, expertise, and development techniques between reviewers and developers, thus deepening the developers’ understanding of the software system.

% Code refinement stands as the core task within code review. During code refinement, reviewers meticulously examine code modifications made by developers. If any potential issues are identified, the reviewer provides feedback, termed as "Review Comments," on the problematic sections of the code. Developers then revise their code in accordance with these comments. This iterative process continues until the reviewers are satisfied with the code, often consuming significant time and human resources. To address this, there has been a surge in efforts to automate code refinement tasks.

% In recent years, researchers have explored using Neural Machine Translation (NMT)~\cite{tufano2019learning}, Transformers~\cite{tufano2021towards,thongtanunam2022autotransform}, T5~\cite{tufano2022using}, codeT5~\cite{li2022automating}, and other pretrained models to tackle code refinement tasks. Despite these efforts, the accuracy of such approaches has remained limited. With the emergence of large language models (LLMs), researchers like Guo~\cite{guo2024exploring} and Pornprasit~\cite{pornprasit2024fine} have investigated the potential of these models in code refinement, exploring techniques such as prompt engineering, model fine-tuning, and retrieval-augmented generation (RAG)~\cite{robertson2009probabilistic}. LLMs show considerable promise over traditional pretrained models in handling code refinement tasks due to their strong comprehension of natural language instructions and their inherent proficiency in code generation tasks. However, the progress in automating code refinement is still limited. The current state-of-the-art (SOTA) methods exhibit relatively low exact match (EM) accuracy on two mainstream code refinement datasets, with only 40\% on the CodeReview dataset~\cite{li2022automating} and 19\% on the Tufano dataset.

% A key reason for the suboptimal performance of existing code refinement models is their failure to accurately comprehend the reviewer’s intent. These models often treat code refinement as a mere code generation task without adequately understanding the modification suggestions embedded in Review Comments. As highlighted in Tufano's work~\cite{tufano2024code}, current pretrained models such as T5CR and CodeReviewer are effective in automating simple tasks related to code format improvements but struggle with tasks involving logical code changes. They often overfit simple tasks, skipping the crucial step of understanding the Review Comments and misinterpreting complex tasks as simpler ones. Guo's research further indicates that when Review Comments lack explicit location information or clear modification strategies, models like ChatGPT underperform due to their inability to grasp the reviewer’s intent~\cite{guo2024exploring}.


% Chain-of-Thought (COT)~\cite{} methods hold potential for enhancing model understanding in various tasks, including mathematical reasoning~\cite{}, logical reasoning~\cite{}, and natural language understanding~\cite{}. COT not only enhances model comprehension but also improves the final task outcomes~\cite{}. However, as Pornprasit noted, COT is not well-suited for code refinement tasks~\cite{pornprasit2024fine}. This limitation may stem from the paucity of code refinement examples in the training data for large models, hindering their ability to learn how to comprehend and execute reviewer modification suggestions.

To address the aforementioned issues, this paper proposes an \textit{intention}-based code refinement technique. Specifically, we extract the \textit{intention} from comments—a structured and templated summary of the reviewer’s modification intent. A clearer extracted intention (e.g., an instruction to change $a$ to $b$) leads to a more accurate code refinement. Unlike conventional end-to-end code refinement, which involves complex understanding challenges, our approach decomposes the process into two sequential phases: Intention Extraction and Intention-Guided Code Modification Generation. In the first phase, a predefined template is used to extract the intention from the reviewer’s comments. In the second phase, large language models (LLMs) and rule-based methods generate revised code based on the extracted intention, rather than relying solely on potentially vague reviewer comments. \major{
To define the intention templates for extracting intentions from comments, we conducted a preliminary study on 1,100 commits from GitHub. These commits were classified into three major categories based on their intentions: explicit change suggestions, reversion suggestions, and other general suggestions. While the first two categories convey clear intentions, we further summarized six intention templates to capture the broader scope of general suggestions. To accurately classify the comment category and extract the intention from a given review comment, we propose a hybrid approach that combines rule-based methods with LLM-based classifiers.
}
After the intentions are extracted, we apply different prompting strategies, including simple prompts, retrieval-augmented generation (RAG) prompts, and self-generated prompts, to explore the effect of various prompts for LLMs in the code refinement process.

To evaluate the effectiveness of our proposed approach, we selected \textbf{5} typical LLMs, including GPT4o~\cite{achiam2023gpt}, GPT3.5~\cite{ouyang2022training}, DeepSeekV2~\cite{zhu2024deepseek}, DeepSeek7B~\cite{guo2024deepseek}, and CodeQwen7B ~\cite{bai2023qwen} for the experiments. Extensive experiments confirmed that our approach can achieve an accuracy of \textbf{79}\% in intention extraction, with a maximum accuracy of \textbf{66}\% in generating revised code. Furthermore, different prompt strategies exhibit varying performance across different models in code refinement. In general, the performance of RAG prompts is stable. Lastly, larger models with more excellent reasoning capabilities demonstrated more significant improvements, with GPT4o and DeepSeekV2 showing accuracy enhancements of 8 and 9 percentage points, respectively. The main contributions of our paper are summarized as follows:

\begin{itemize}[leftmargin=*,topsep=2pt]
    \item We reformulate the comment-to-code refinement process into two sequential steps: \textit{comment-to-intent} and \textit{intent-to-code} generation. This decomposition reduces task complexity and improves LLMs' ability to understand reviewer intent.
    \item We propose a hybrid approach incorporating rule-based and LLM-based classifiers to extract the reviewer's \textit{intention} accurately.
    \item Extensive experiments demonstrate the effectiveness of our approach, achieving \textbf{79}\% accuracy in intention extraction and up to \textbf{66}\% accuracy in generating revised code.
\end{itemize}



% We validated the framework's effectiveness across multiple models, including Gpt4o, GPT-3.5, DeepSeekV2, DeepSeek7B, and Code-Qwen7B. Experimental results indicate that our framework achieves an accuracy of 79\% in Intention extraction, with a maximum EM accuracy of 68\% in generating Revised Code. Compared to direct prompt techniques, the accuracy of all models improved by 4\% to 13\% when using the framework. Moreover, larger models with greater reasoning capabilities demonstrated more significant improvements, with Gpt4o and DeepSeekV2 showing accuracy enhancements of 11\% and 13\%, respectively. Our main contributions are as follows:

% 1. We introduce the concept of Intention and design an intention-based framework for code refinement, enhancing model comprehension and task effectiveness.

% 2. We develop a method for extracting Intention, combining multilayered rule-based classifiers and LLM-based classifiers to ensure accurate understanding of Intention.

% 3. We establish tailored repair strategies for different Intentions, overcoming the limitations of solely model-generated code. Our approach utilizes a combination of rule-based and LLM-based repair solutions, achieving higher accuracy across varied tasks.


% To bridge this gap, we propose the concept of **Intention**. Intention refers to a simplified and templated summary of the reviewer’s modification intent. Drawing inspiration from COT methodologies, we decompose the original end-to-end code refinement task into two subtasks: first, understanding and extracting Intention from the input data, and second, using Intention to guide code revision. This serial process enhances the model’s understanding of the task and increases the accuracy of the final results.



% Our research focuses on addressing three key questions:
% \ding{182} How can we design suitable Intention templates?
% \ding{183} How can we effectively understand and extract Intention?
% \ding{184} How can Intention be used to guide code revision?


% We have developed an intention-based framework tailored for code refinement, based on the task’s characteristics, identifying three main categories and eight subcategories of Intention. The framework begins with Intention extraction: using input information, multiple rule-based and LLM-based classifiers determine the category of Intention and complete the information within the Intention template, such as changing word A to word B. Subsequently, code is revised according to Intention: we design specific repair strategies and corrective strategies for each Intention. Depending on the task characteristics, some methods utilize large model generation, while others employ rule-based modifications.





% 版本3：

% Code review 是在代码合并过程中，由他人对修改的代码进行审查，是软件开发和维护中，很重要的质量保证方法，无论是对商用软件还是开源软件。现在越来越多的项目使用codereview，很多的公司会要求合并之前必须有codereview。code review可以提升代码质量，提早发现并解决codeing defects, vulnerabilities, code style violations等问题。而且The reviewers could share knowledge, expertise, and development techniques with developers to deepen their understanding of a software system。

% Code refinement是codereview的核心任务。reviewer会审查开发者的代码修改，如果发现某个修改会引起问题，会在有问题的代码附近提出自己的意见,即ReviewComment。而后，developer会根据ReviewComment修改代码，这个过程被称作code Refinement。在code review流程中，reviewer可能会对上一次code Refinement的结果继续提出问题，developer再进行修改，重复多次，直至review觉得代码完全没有问题。这个过程可能会耗费大量的时间和人力成本，为解决这个问题，很多工作尝试用自动化的方法来处理code Refinement任务。

% 近年来，很多研究者尝试使用NMT, Transformer，T5, codeT5等pretrained-model来解决code Refinement任务，但是这些方法的准确率一直有限。随着大模型的兴起，Guo，Pornprasit等人探索利用大模型解决该任务，研究了prompt工程，大模型微调，RAG等技术。相比传统的pretrained model，LLM在处理code Refinement任务中有很好的潜力。这一方面是由于LLM可以很好的理解自然语言的指令，另一方面，LLM本身就非常擅长代码生成任务。但是自动化实现code Refinement任务的研究进展依然是有限的，目前SOTA方法在两个主流的code refinement数据集上EM准确率都不高，在CodeReviewer数据集上准确率只有40%，Tufano数据集准确率只有19%。

% 导致现在code Refinement效果不好的一个重要原因，就是现有模型没有理解reviewer的修改意图，或者是理解不准确。模型处理code refinement任务时，会把它当做代码生成任务，并不能保证充分理解ReviewComment中的修改建议。在Tufano文章中指出，现有的T5CR和codereviewer等预训练模型在自动化与改进代码格式相关的简单任务非常有效，而对代码逻辑更改任务效果很差，特别的，有时会倾向于过拟合到简单的任务。也就是说，模型可能会跳过理解ReviewComment这个步骤，把复杂任务误认为是简单任务来直接处理。在Guo的文章中发现，当ReviewComment缺少明确的位置信息，或者缺少明确的修改策略时，ChatGPT的表现会不好。这也是因为模型没有理解reviewer的修改意图。

% 为提升大模型对任务的理解能力，COT是一种很有潜力的方法。在数学推理，逻辑推理，自然语言理解等任务中，COT不仅可提升大模型对任务理解能力还可以提升任务的最终效果。然而Pornprasit在文章中指出，COT对code Refinement任务并不合适。这可能是因为大模型训练数据中，code Refinement的样本较少，模型没有学会如何理解Reviewer的修改建议，也没有学会如何执行修改建议。

% To fill this gap，我们提出Intention的概念。Intention就是对reviewer的修改意图的简洁化模板化总结。而后参照COT的思路，我们将原先的端到端的code Refinement任务，拆分成两个子任务。先从输入数据理解并提取Intention，再根据Intention指导修复代码。通过这种串行流程，可以加强大模型对任务的理解能力，并提高最终结果的准确率。

% 我们需要解决以下三个问题：1. 如何设计合适的Intention？2. 如何理解并提取Intention？3. 如何根据Intention指导修复代码？

% 我们根据code Refinement的特点，设计了3大类，8个小类的Intention。并propose an intention-based framework for code refinement. 首先是提取Intention：根据任务输入信息，通过多个Rule-based和LLM-based分类器，判断该数据属于哪一类Intention，并补全Intention模板中的信息，如修改单词A成单词B。而后，根据Intention修复代码：我们对不同的Intention设计了不同的修复策略和矫正修复策略。根据任务特点，有些使用大模型生成的方法，有些按规则修改。
% 我们在Gpt4o, GPT-3.5, DeepSeekV2, DeepSeek7B, Code-Qwen7B等多模型上验证框架的有效性。实验结果表明，框架提取Intention的正确率可以达到79%，而最终生成的RevisedCode的EM准确率最高能达到68%。与直接使用prompt技术相比，所有模型使用框架后准确率可以提高4%到13%。而且模型参数规模越大，推理能力越强，则提升越多，Gpt4o和DeepSeekV2的准确率分别提升了11%和13%。

% 我们的主要贡献有：
% 1. 提出了Intention概念，并设计了intention-based framework for code refinement。增强了模型对code Refinement任务的理解能力，提升了任务的最终效果。
% 2. 设计了提取Intention的方法。使用多层次的，Rule-based分类器和LLM-based分类器相结合的方法，让模型准确的理解Intention。
% 3. 针对不同Intention制定了更合适的修复策略。突破了以往全是由模型生成代码的局限性，针对不同任务，使用了rule-based和LLM-based相结合的修复方案，准确性更高。

% 版本2：
% Code review 是在代码合并过程中，由他人对修改的代码进行审查，是软件开发和维护中，很重要的质量保证方法，无论是对商用软件还是开源软件。现在越来越多的项目使用codereview，很多的公司会要求合并之前必须有codereview。code review可以提升代码质量，提早发现并解决codeing defects, vulnerabilities, code style violations等问题。而且The reviewers could share knowledge, expertise, and development techniques with developers to deepen their understanding of a software system。

% Code refinement是codereview的核心任务。reviewer会审查开发者的代码修改，如果发现某个修改会引起问题，会在有问题的代码附近提出自己的意见,即ReviewComment。而后，developer会根据ReviewComment修改代码，这个过程被称作code Refinement。在code review流程中，reviewer可能会对上一次code Refinement的结果继续提出问题，developer再进行修改，重复多次，直至review觉得代码完全没有问题。这个过程可能会耗费大量的时间和人力成本，为解决这个问题，很多工作尝试用自动化的方法来处理code Refinement任务。

% Tufano最早提出了使用NMT来自动化实现code Refinement任务，而后诸多研究工作尝试使用Transformer，codeT5等pretrained-model来解决code Refinement任务。随着大模型的兴起，Guo，Pornprasit等人探索利用大模型解决该任务，研究了prompt工程，大模型微调，RAG等技术。相比传统的pretrained model，LLM在处理code Refinement任务中有很好的潜力。这一方面是由于LLM可以很好的理解自然语言的指令，另一方面，LLM本身就非常擅长代码生成任务。但是自动化实现code Refinement任务的研究进展依然是有限的，目前SOTA方法在两个主流的code refinement数据集上EM准确率都不高，在CodeReviewer数据集上准确率只有40%，Tufano数据集准确率只有19%。这其中一个重要原因，就是现有模型对reviewer的意图理解并不准确。模型处理code refinement任务时，会把它当做代码生成任务，并不能保证充分理解ReviewComment中的修改建议。在Tufano文章中指出，现有的T5CR和codereviewer等预训练模型在自动化与改进代码格式相关的简单任务（例如，添加/删除括号，添加/删除空格）非常有效，而对代码逻辑更改任务（例如，修改if条件）效果很差。特别的，T5CR倾向于过拟合到简单的修改任务。也就是说，模型可能会逃避理解ReviewComment这个步骤，把复杂问题当做简单问题来直接处理。让模型理解reviewer的意图是code Refinement的基础，可以避免模型陷入只摘取low-hanging fruits，也是将自动化code Refinement任务落地到实际应用中的关键步骤。

% 模型在完成code Refinement任务时，是端到端的，直接从输入的OriginalCode，ReviewComment到输出的RevisedCode。而人类不一样，developer去做Code Refinement任务时，先要理解ReviewComment中的核心修改建议，然后再执行核心修改建议，最终得到RevisedCode。这里reviewer通过ReviewComment表达的核心修改建议，我们称之为Intention。ReviewComment中除了核心建议以外，可能还包含了解释原因，礼貌句式，甚至还有表情符号等无关内容。然而Intention不需要这些额外信息，只需要用简洁而直接的语句来表达reviewer核心修改建议，如：对某个变量重命名，退回上次的修改，或者删除某一段代码等。The Intention is the central pivot in code refinement，人类在做Code Refinement时，可以分为提取Intention和根据Intention修改代码两个部分。想要全面提升模型在自动化code Refinement任务上的能力，也需要让模型像人类一样，先理解Intention，再按照Intention执行，生成RevisedCode。

% 为了使模型像人类一样去理解Intention，code Refinement任务需要额外的输入信息。传统的code refinement任务的输入是OriginalCode和ReviewComment，而Guo在文章中指出的，只告诉模型这两个信息是不够的。在真实的code refinement场景中，developer会应用另外两个非常关键的信息：ReviewLine和LastCodeDiffHunk。ReviewLine是ReviewComment的位置信息，告诉程序员ReviewComment是针对哪一行代码提出的意见。LastCodeDiffHunk是上一次修改的代码块，帮助程序员理解ReviewComment所面向的场景。ReviewLine和LastCodeDiffHunk对自动化code Refinement有时候是必不可少的。有些ReviewComment非常简短，例如：删除这一行。这时需要ReviewLine提供位置信息来帮助模型理解reviewer是要删除哪一行代码。LastCodeDiffHunk也同样很重要，有些ReviewComment是质疑上次代码修改的合理性，要求退回到修改前的状态，对这种情况必须告诉模型LastCodeDiffHunk信息，模型才有可能正确理解Intention。当然，即使给模型直接加上这两个信息，模型理解Intention也存在挑战。一方面是由于添加ReviewLine和LastCodeDiffHunk信息后，模型的输入部分变得非常长，模型的推理会随之变的困难。另一方面是由于ReviewLine和LastCodeDiffHunk信息还不总是有用的，添加到输入后反而可能会降低原来模型的效果。

% 为了使模型像人类一样按Intention修改代码，我们需要将Intention分成不同的类别。现在模型处理所有任务都是端到端的，把所有任务都当做代码生成任务，而人类处理code Refinement时，对于不同类别的任务是有不同的修改策略的。developer不会看完OriginalCode和ReviewComment之后，从零开始重新写一份RevisedCode。例如，对于替换变量名，添加括号等任务，developer会找到并修改OriginalCode中对应的代码行，其他的代码保持不变。对于回退上次修改的任务，developer是直接找到上次修改前的代码版本作为RevisedCode。这些因地制宜的代码修复策略不仅能降低代码修复难度，还可以提升修复的准确率。由此启发，我们在自动化code Refinement时也可以将Intention分为不同的类别，为模型对不同类别的任务设计不同的修复策略，以此提升修复准确率。

% we propose an intention-based framework for code refinement. 将Code Refinement任务分成两部分，提取Intention和执行Intention。我们定义了11种Intention模板（例如：退回上一次修改，将xxx单词改成yyy等）。提取Intention：根据任务输入的OriginalCode，ReviewComment，ReviewLine和LastCodeDiffHunk等信息，通过3层分类器判断Intention属于哪一种模板，并补全模板中的填空。执行Intention：对不同的Intention设计了不同的修复策略，根据任务特点，提供OriginalCode，Intention，ReviewLine和LastCodeDiffHunk等输入的一部分，使用大模型生成的方法，或者按规则修改的方法，生成RevisedCode。我们在在Gpt4o，gpt3.5，deepseek，deepseek-coder，code-qwen等多模型上验证框架的有效性。实验结果表明，框架提取Intention的正确率可以达到79%，而最终生成的RevisedCode的EM准确率最高能达到68%。与不使用Intention-based框架，直接使用prompt技术相比，使用框架的准确率可以提高4%到13%。而且参数规模越大，推理能力越强的模型提升越多，相较于baseline中最有效的RAG方法，Intention框架可以将Gpt4o和deepseek的准确率分别提升了11%和13%

% 我们框架中的中间产品Intention还可以解决数据质量问题。数据集的质量低一直是困扰code refinement任务的难题。一些研究表明，现有的codereview约有30%-40%的数据是invalid的。数据错误的原因可能是由于数据爬取时的逻辑问题，如错误认为某个commit是修复前面review comment的，但是实际不是。也可能是review comment太模糊，或者需要太多领域知识才能理解，即使人来修复也修复不了。还有可能是由于developer没有按照review comment来修改，而是自己按其他方案修改等。这些错误的表象就是：RevisedCode和ReviewComment的要求不一致。这些invalid的数据不仅会影响影响code Refinement的测试结果，还会污染数据集，使得模型微调，RAG等方法的效果都受到影响。而筛选这些invalid的数据是非常困难的，首先要理解ReviewComment的语义信息，即reviewer的修改意图，以此判断是否和最终修改的RevisedCode是否一致。在此之前一直没有很好的办法解决数据质量问题。而我们可以使用Intention来判断数据是否是valid的，实验结果表明，其准确率可以达到81%，而精确率达到91%。

% 我们的主要贡献有：
% 1. 扩充了codereview数据集。增加了新的输入信息，更加贴近真实场景。
% 2. 提出了基于Intention的framework，提高了code refinement的效果
% 3. 利用Intention从语义层面筛选掉invalid的数据，提升了数据集的质量，方便后续的研究工作。

% 版本1：
% Code review 是在代码合并过程中，由他人对修改的代码进行审查，是软件开发和维护中，很重要的质量保证方法，无论是对商用软件还是开源软件。现在越来越多的项目使用codereview，很多的公司会要求合并之前必须有codereview。code review可以提升代码质量，提早发现并解决codeing defects, vulnerabilities, code style violations等问题。而且The reviewers could share knowledge, expertise, and development techniques with developers to deepen their understanding of a software system。
% Code refinement是codereview的核心任务。当reviewer发现问题后，会对代码提出自己的意见,即"review comment"。而后，developer会根据review comment修改代码。这个过程就是coderefine。在codereview中，这个过程可能会反复很多次，直至review觉得代码完全没有问题。整个过程可能会耗费大量的时间和人力。为解决这个问题，很多工作尝试用自动化的方法来处理code refine任务。
% Tufano最早提出了使用NMT来自动化实现coderefine任务，而后诸多研究工作尝试使用Bert，codeT5等pretrained-model来解决coderefine任务。随着大模型的兴起，Guo，Pornprasit等人也尝试使用大模型技术来解决coderefine任务，包括prompt工程，微调，PEFT等技术。相比传统的pretrained-model，LLM在coderefine任务中有很好的潜力。这一方面是由于LLM可以比传统的pretrained-model更好的的理解review comment的意图。另一方面，LLM本身就非常擅长代码生成任务。但是自动化实现coderefine任务的研究进展依然是有限的，目前SOTA方法在两个主流的数据集上EM准确率都不高，CodeReviewer数据集EM准确率只有40%，Tufano数据集EM只有19%。很多研究者分析了EM准确率如此低的原因。除了EM评价方法过于严格，在code生成任务中不够灵活这个原因以外。还有有三个主要原因，一是coderefine任务输入数据不全，二是数据集质量不高，三是模型无法真正理解review的修改意图。

% 首先是输入数据不全的问题。传统的coderefine任务是输入original code和review comment，模型需要给出的输出是修改后的revised code。但是code refinement是一个复杂的流程，只告诉模型original code和review comment是不够的。在真实的code refinement过程中，developer是可以感知到当前项目的所有信息的，包括两个至关重要的信息————review line和last diff。review line是指review comment是针对哪一行代码提出的。last diff是指上一次修改的信息。有些review comment非常简短，例如：删除这一行。这时需要review line提供信息来帮助developer或模型理解review是要删除哪一行。last diff也同样很重要。有些review comment是质疑上次commit的合理性，要求退回到修改前的状态。必须给出last diff信息才能帮助developer或者模型正确修改。

% 其次是对review comment理解的问题。因为coderefinement是个直接生成代码的任务，任务默认认为模型应该理解了输入中的review comment。然而真正理解review comment是个很难的事情。一来是由于review comment会存在领域内的简略用语和指代不明等问题。二来是因为review comment还需要结合其他信息，包括original code，review line，last diff等。之前的code refinement任务缺少review line和last diff导致了很多comment意图是无法理解的，然而我们即使加上这些信息，由于过多的输入元素，理解review的Intention也不是一个简单的任务。有经验研究指出，现有的pretrain模型，经过finetune虽然提高了整体EM值，但是更多的是学会了解决简单问题，如删除代码，将重命名变量等。对于复杂的任务效果提升很小。也就是说，这种情况下模型并没有真正理解review的Intention。

% 最后是数据质量问题。数据集的质量低一直是困扰coderefine领域的难题。一些研究表明，现有的codereview约有40%的数据是invalid的。包括错误Revised code,即revised code和review comment的要求不一致，和非常困难的任务，即使让人来做也做不出来。这些invalid的数据不仅会影响测试模型时的效果，还会污染数据集，使得finetune模型，RAG等方法的效果都受到影响。而筛选这些invalid的数据是非常困难的，虽然每个数据集在构造的时候都精心的设计了基于规则的过滤条件。但是由于review comment灵活而模糊，这种语义级别的筛选，要求判断review comment和最终修改的revised code是否一致，目前还没有很有效的方法。

% To address these gaps, we propose an intention-based framework for code refinement. 首先我们扩展了这个任务的输入，我们从codereview数据集中，根据原始数据出处（github的repo链接地址和codereview信息），找到并补全了review line和last diff等输入信息。而后，我们定义了11种Intention模板（例如：退回上一次修改，将xxx单词改成yyy），根据任务输入的original cold，review comment， review line， last diff等信息，通过3层LLM判断review intention属于哪一种模板，并补全模板中的填空。最后，我们根据Intention，连同original code， review line信息，一起输入到最终的模型，让模型输出revised code。实验结果表明，Intention的判断正确率可以达到xx%，而最终生成的revised code的EM准确率能达到68%。在多种模型上验证效果，使用了这个框架的EM准确率都高于现有的prompt方法，可以提高8%到10%的准确率。

% 由于Intention清晰的描述了reviewer所期待的动作指令，我们发现Intention还可以作为过滤数据集的一种方法。可以将Intention，review line，original code，revised code作为输入，让模型判断修改的结果是否符合Intention。实验效果表明，使用Intention来判断数据是否合理的准确率达到xx%，而召回率达到xx%，比直接根据review comment来判断数据是否合理的准确率和召回率分别高xx%和xx%。用Intention清洗数据可以很大的缓解人工清洗数据的工作。

% 我们的主要贡献有：
% 1. 扩充了codereview数据集。增加了新的输入信息，更加贴近真实场景。
% 2. 提出了基于Intention的framework，提高了coderefine效果
% 3. 利用Intention，可以从语义层面筛选掉invalid的数据，提升了数据集的质量，方便后续的finetune，RAG等方法的使用。