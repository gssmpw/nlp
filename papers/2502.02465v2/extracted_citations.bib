@incollection{blanz2023morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={157--164},
  year={2023}
}

@inproceedings{bounareli2023hyperreenact,
  title={Hyperreenact: one-shot reenactment via jointly learning to refine and retarget faces},
  author={Bounareli, Stella and Tzelepis, Christos and Argyriou, Vasileios and Patras, Ioannis and Tzimiropoulos, Georgios},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7149--7159},
  year={2023}
}

@inproceedings{deng2019accurate,
  title={Accurate 3d face reconstruction with weakly-supervised learning: From single image to image set},
  author={Deng, Yu and Yang, Jiaolong and Xu, Sicheng and Chen, Dong and Jia, Yunde and Tong, Xin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{ding2023diffusionrig,
  title={Diffusionrig: Learning personalized priors for facial appearance editing},
  author={Ding, Zheng and Zhang, Xuaner and Xia, Zhihao and Jebe, Lars and Tu, Zhuowen and Zhang, Xiuming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12736--12746},
  year={2023}
}

@article{feng2021learning,
  title={Learning an animatable detailed 3D face model from in-the-wild images},
  author={Feng, Yao and Feng, Haiwen and Black, Michael J and Bolkart, Timo},
  journal={ACM Transactions on Graphics (ToG)},
  volume={40},
  number={4},
  pages={1--13},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{gao2024adaptive,
  title={Adaptive Conditional Denoising Diffusion Model with Hybrid Affinity Regularizer for Generalized Zero-shot Learning},
  author={Gao, Mengyu and Dong, Qiulei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2024},
  publisher={IEEE}
}

@inproceedings{han2024face,
  title={Face-Adapter for Pre-trained Diffusion Models with Fine-Grained ID and Attribute Control},
  author={Han, Yue and Zhu, Junwei and He, Keke and Chen, Xu and Ge, Yanhao and Li, Wei and Li, Xiangtai and Zhang, Jiangning and Wang, Chengjie and Liu, Yong},
  booktitle={European Conference on Computer Vision},
  pages={20--36},
  year={2024},
  organization={Springer}
}

@article{huang2024detail,
  title={Detail-Preserving Diffusion Models for Low-Light Image Enhancement},
  author={Huang, Yan and Liao, Xiaoshan and Liang, Jinxiu and Shi, Boxin and Xu, Yong and Le Callet, Patrick},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2024},
  publisher={IEEE}
}

@article{kang2024image,
  title={Image intrinsic components guided conditional diffusion model for low-light image enhancement},
  author={Kang, Sicong and Gao, Shuaibo and Wu, Wenhui and Wang, Xu and Wang, Shuoyao and Qiu, Guoping},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2024},
  publisher={IEEE}
}

@inproceedings{kim2022diffusionclip,
  title={Diffusionclip: Text-guided diffusion models for robust image manipulation},
  author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2426--2435},
  year={2022}
}

@article{li2017learning,
  title={Learning a model of facial shape and expression from 4D scans.},
  author={Li et al, Tianye},
  journal={ACM Trans. Graph.},
  volume={36},
  number={6},
  pages={194--1},
  year={2017}
}

@inproceedings{mou2024t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4296--4304},
  year={2024}
}

@article{papa2024d4d,
  title={D4D: An RGBD diffusion model to boost monocular depth estimation},
  author={Papa, Lorenzo and Russo, Paolo and Amerini, Irene},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2024},
  publisher={IEEE}
}

@inproceedings{patashnik2021styleclip,
  title={Styleclip: Text-driven manipulation of stylegan imagery},
  author={Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2085--2094},
  year={2021}
}

@inproceedings{paysan20093d,
  title={A 3D face model for pose and illumination invariant face recognition},
  author={Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
  booktitle={2009 sixth IEEE international conference on advanced video and signal based surveillance},
  pages={296--301},
  year={2009},
  organization={Ieee}
}

@article{que2024denoising,
  title={Denoising Diffusion Probabilistic Model for Face Sketch-to-Photo Synthesis},
  author={Que, Yue and Xiong, Li and Wan, Weiguo and Xia, Xue and Liu, Zhiwei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2024},
  publisher={IEEE}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22500--22510},
  year={2023}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{wang2024instantid,
  title={Instantid: Zero-shot identity-preserving generation in seconds},
  author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony and Li, Huaxia and Tang, Xu and Hu, Yao},
  journal={arXiv preprint arXiv:2401.07519},
  year={2024}
}

@article{yan2023towards,
  title={Towards high-quality hdr deghosting with conditional diffusion models},
  author={Yan, Qingsen and Hu, Tao and Sun, Yuan and Tang, Hao and Zhu, Yu and Dong, Wei and Van Gool, Luc and Zhang, Yanning},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}

@article{ye2023ip,
  title={Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2308.06721},
  year={2023}
}

@inproceedings{zeng2023face,
  title={Face animation with an attribute-guided diffusion model},
  author={Zeng, Bohan and Liu, Xuhui and Gao, Sicheng and Liu, Boyu and Li, Hong and Liu, Jianzhuang and Zhang, Baochang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={628--637},
  year={2023}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

