@article{Chen2024PreferenceLA,
  title={Preference Learning Algorithms Do Not Learn Preference Rankings},
  author={Angelica Chen and Sadhika Malladi and Lily H. Zhang and Xinyi Chen and Qiuyi Zhang and Rajesh Ranganath and Kyunghyun Cho},
  journal={NeurIPS},
  year={2024},
}

@article{Razin2023VanishingGI,
  title={Vanishing Gradients in Reinforcement Finetuning of Language Models},
  author={Noam Razin and Hattie Zhou and Omid Saremi and Vimal Thilak and Arwen Bradley and Preetum Nakkiran and Josh Susskind and Etai Littwin},
journal={ICLR},
year={2024},
}

@article{ahmadian2024back,
  title={Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs},
  author={Ahmadian, Arash and Cremer, Chris and Gall{\'e}, Matthias and Fadaee, Marzieh and Kreutzer, Julia and {\"U}st{\"u}n, Ahmet and Hooker, Sara},
  journal={arXiv},
  year={2024}
}

@article{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{azar2023general,
      title={A General Theoretical Paradigm to Understand Learning from Human Preferences}, 
      author={Mohammad Gheshlaghi Azar and Mark Rowland and Bilal Piot and Daniel Guo and Daniele Calandriello and Michal Valko and Rémi Munos},
      year={2023},
      eprint={2310.12036},
      journal={arXiv},
      primaryClass={cs.AI}
}

@article{gui2024bonbonalignmentlargelanguage,
      title={BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling}, 
      author={Lin Gui and Cristina Gârbacea and Victor Veitch},
      year={2024},
      journal={NeurIPS},
}

@misc{huang2024correctingmythosklregularizationdirect,
      title={Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization}, 
      author={Audrey Huang and Wenhao Zhan and Tengyang Xie and Jason D. Lee and Wen Sun and Akshay Krishnamurthy and Dylan J. Foster},
      year={2024},
      eprint={2407.13399},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.13399}, 
}

@article{ivison2024unpackingdpoppodisentangling,
      title={Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback}, 
      author={Hamish Ivison and Yizhong Wang and Jiacheng Liu and Zeqiu Wu and Valentina Pyatkin and Nathan Lambert and Noah A. Smith and Yejin Choi and Hannaneh Hajishirzi},
      year={2024},
      journal={NeurIPS},
}

@article{kirk2024understanding,
      title={Understanding the Effects of RLHF on LLM Generalisation and Diversity}, 
      author={Robert Kirk and Ishita Mediratta and Christoforos Nalmpantis and Jelena Luketina and Eric Hambro and Edward Grefenstette and Roberta Raileanu},
      year={2024},
      eprint={2310.06452},
      journal={arXiv},
      primaryClass={cs.LG}
}

@article{munos2023nash,
      title={Nash Learning from Human Feedback}, 
      author={Rémi Munos and Michal Valko and Daniele Calandriello and Mohammad Gheshlaghi Azar and Mark Rowland and Zhaohan Daniel Guo and Yunhao Tang and Matthieu Geist and Thomas Mesnard and Andrea Michi and Marco Selvi and Sertan Girgin and Nikola Momchev and Olivier Bachem and Daniel J. Mankowitz and Doina Precup and Bilal Piot},
      year={2023},
      eprint={2312.00886},
      journal={arXiv},
      primaryClass={stat.ML}
}

@misc{pal2024smaugfixingfailuremodes,
      title={Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive}, 
      author={Arka Pal and Deep Karkhanis and Samuel Dooley and Manley Roberts and Siddartha Naidu and Colin White},
      year={2024},
      eprint={2402.13228},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13228}, 
}

@misc{razin2024unintentionalunalignmentlikelihooddisplacement,
      title={Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization}, 
      author={Noam Razin and Sadhika Malladi and Adithya Bhaskar and Danqi Chen and Sanjeev Arora and Boris Hanin},
      year={2024},
      eprint={2410.08847},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.08847}, 
}

@misc{rosset2024directnashoptimizationteaching,
      title={Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences}, 
      author={Corby Rosset and Ching-An Cheng and Arindam Mitra and Michael Santacroce and Ahmed Awadallah and Tengyang Xie},
      year={2024},
      archivePrefix={arXiv},
}

@misc{singhal2024longwaygoinvestigating,
      title={A Long Way to Go: Investigating Length Correlations in RLHF}, 
      author={Prasann Singhal and Tanya Goyal and Jiacheng Xu and Greg Durrett},
      year={2024},
      eprint={2310.03716},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03716}, 
}

@article{swamy2024minimaximalistapproachreinforcementlearning,
      title={A Minimaximalist Approach to Reinforcement Learning from Human Feedback}, 
      author={Gokul Swamy and Christoph Dann and Rahul Kidambi and Zhiwei Steven Wu and Alekh Agarwal},
      year={2024},
      journal={ICML},
}

@article{tajwar2024preferencefinetuningllmsleverage,
      title={Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data}, 
      author={Fahim Tajwar and Anikait Singh and Archit Sharma and Rafael Rafailov and Jeff Schneider and Tengyang Xie and Stefano Ermon and Chelsea Finn and Aviral Kumar},
      year={2024},
      journal={ICML}
}

@article{wang2024transforming,
  title={Transforming and Combining Rewards for Aligning Large Language Models},
  author={Wang, Zihao and Nagpal, Chirag and Berant, Jonathan and Eisenstein, Jacob and D'Amour, Alex and Koyejo, Sanmi and Veitch, Victor},
  journal={arXiv},
  year={2024}
}

@article{xu2024contrastivepreferenceoptimizationpushing,
      title={Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation}, 
      author={Haoran Xu and Amr Sharaf and Yunmo Chen and Weiting Tan and Lingfeng Shen and Benjamin Van Durme and Kenton Murray and Young Jin Kim},
      year={2024},
      journal={ICML}}

@misc{xu2024thingscringeothersiterative,
      title={Some things are more CRINGE than others: Iterative Preference Optimization with the Pairwise Cringe Loss}, 
      author={Jing Xu and Andrew Lee and Sainbayar Sukhbaatar and Jason Weston},
      year={2024},
      eprint={2312.16682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.16682}, 
}

@article{zhao2023slichf,
      title={SLiC-HF: Sequence Likelihood Calibration with Human Feedback}, 
      author={Yao Zhao and Rishabh Joshi and Tianqi Liu and Misha Khalman and Mohammad Saleh and Peter J. Liu},
      year={2023},
      eprint={2305.10425},
      journal={arXiv},
      primaryClass={cs.CL}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@article{zhu2024iterative,
      title={Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF}, 
      author={Banghua Zhu and Michael I. Jordan and Jiantao Jiao},
      year={2024},
      eprint={2401.16335},
      journal={arXiv},
      primaryClass={cs.LG}
}

