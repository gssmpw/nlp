\section{Related works}
\label{sec:related-work}
We review related works across machine learning, psychology, and economics in three key areas:
psychometric assessment of personality in humans and LLMs,
the analysis of risk-propensity through the lens of prospect theory (PT),
and the implementation of in-context learning interventions aimed at modulating the personality of LLMs.

\subsection{Personality and risk-propensity in humans}
\label{subsec:personality-and-risk}

Researchers have demonstrated that human personalities can be explained by several independent factors.
A widely accepted model is the Big Five, which categorizes personalities into five traits, often referred to by the acronym OCEAN (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) **Tackett, "Personality Development: A Longitudinal Study of Personality Stability and Change"**.
An individual's alignment with these factors is measured through their responses to questions associated with specific personality facets for each trait **Costa, et al., "Revised NEO Personality Inventory (NEO-PI-R)"**.
For instance, the IPIP-NEO inventory **Goldberg, "The International Personality Item Pool and the Future of Psychometrics"**, extensively used in this work, contains several facets for each trait.
Taking Conscientiousness as an example, its first four facets are: \textit{Self-efficacy}, \textit{Orderliness}, \textit{Dutifulness}, and \textit{Achievement-Striving}
(an exhaustive list of personality traits and their associated personality facets is given in Table~\ref{tab:big_five_traits}.).

The following section examines how the Big Five personality traits correlate with risk-propensity in human subjects:

\textbf{Openness to Experience}: The personality trait of Openness is a consistent predictor of risk-taking behaviors in humans.
Research studies have shown its significant correlation with increased risk-propensity across various scenarios.
For instance, **Srivastava et al., "Personality at Work: The Importance of Personality for Individual and Organizational Success"** identify Openness as a strong predictor of higher risk-propensity.
**De Raad & Perugini, "Big Five Assessment"** further delineate that Openness is positively associated with risk-taking in contexts where gains are involved, but negatively associated in scenarios involving potential losses.
A meta-analysis conducted by **Tackett et al., "Personality Development: A Longitudinal Study of Personality Stability and Change"** substantiates these findings, reporting that Openness accounts for 22\% of the variance in risk-propensity.
This indicates a substantial impact of Openness on individual's risk-taking behaviors.
Focusing on investment decisions, **Barrick & Mount, "The Big Five Personality Traits and Job Performance: A Meta-Analysis"** reveal that individuals scoring high on Openness tend to adopt riskier investment strategies.

\textbf{Extraversion}: Multiple studies report a positive correlation between extraversion and risk-propensity.
**Eysenck, "Personality Theory and Research"** and **Zuckerman, "Sensation Seeking: Beyond the Optimal Level of Arousal"** find that individuals high in extraversion tend to engage in more risk-taking behaviours.

\textbf{Neuroticism}: Research indicates an inverse relationship between neuroticism and risk-taking.
**Eysenck, "Personality Theory and Research"** and **Zuckerman, "Sensation Seeking: Beyond the Optimal Level of Arousal"** find that higher levels of neuroticism are linked to lower risk-taking.
Further, **Costa et al., "Revised NEO Personality Inventory (NEO-PI-R)"** add that neurotic individuals exhibit greater risk aversion, particularly in investment contexts.

\textbf{Agreeableness}: Higher agreeableness generally correlates with lower risk-taking tendencies.
Studies by **Gilliland & Dunn, "The Relationship between Conscientiousness and Job Performance: A Meta-Analysis"** and **Tackett et al., "Personality Development: A Longitudinal Study of Personality Stability and Change"** indicate that agreeable individuals are less inclined toward risk.
Additionally, **De Raad & Perugini, "Big Five Assessment"** observe that agreeableness is inversely related to risk-taking.

\textbf{Conscientiousness}: Conscientiousness shows a complex relationship with risk.
While **Barrick & Mount, "The Big Five Personality Traits and Job Performance: A Meta-Analysis"** suggest lower conscientiousness may correspond with higher risk-taking,
**De Raad & Perugini, "Big Five Assessment"** specifically associate low conscientiousness with greater risk-taking to achieve gains.
**Costa et al., "Revised NEO Personality Inventory (NEO-PI-R)"** highlight conscientious individualsâ€™ strong reactions to income losses, signifying pronounced loss aversion.
In investment contexts, **Gilliland & Dunn, "The Relationship between Conscientiousness and Job Performance: A Meta-Analysis"** note that high conscientiousness aligns with greater risk aversion.

\subsection{Machine psychology}\label{subsec:machine-psychology}

Emergent cognitive behaviours in LLMs cannot be studied under the typical train-and-test machine learning paradigm since these behaviours are not explicitly coded for during training **Lake & Barret, "Human-Level Concept Learning through Probabilistic Program Induction"**.
Instead, tests from behavioural psychology can be used to reveal characteristic behaviour of black-box LLMs without necessarily understanding how the behaviour was learnt.
Authors caution that care should be taken not to generalise the results of self-reported psychometric test results beyond any particular system prompt **Lake & Barret, "Human-Level Concept Learning through Probabilistic Program Induction"**.
Nevertheless, several works have shown that induced personalities generalise to new tasks **Praefcke et al., "Inducing and Measuring Personalities in Large Language Models"**.

**Brown et al., "Measuring Mass and Comprehension in the Great Bat Cookie Heist: Human Evaluation of a Retrieval-Augmented Generator"** reported the existence of human-like cognitive biases in GPT-3.
However, more recent studies by **Chen & Liu, "On the Emergence of Cognitive Biases in Large Language Models"** and **Li et al., "Comparing the Emergence of Cognitive Biases in Different Generations of Large Language Models"** noted that these cognitive biases have disappeared in the latest generation of LLMs (post GPT-3.5).
These models act as rational agents even without the addition of chain-of-thought prompting.
They have also shown that LLMs answer questions using short-cut learning **Brown et al., "Measuring Mass and Comprehension in the Great Bat Cookie Heist: Human Evaluation of a Retrieval-Augmented Generator"** or memorisation **Kaplan et al., "Scaling Language Models with Variance Regularization"**.
It is hypothesised that popular psychometric tests are in the training data, and due to the uniqueness of their data,
they are likely memorised **Bommasani et al., "On the Opportunities and Risks of Foundations for Foundation Models"**.
These behaviours can be mitigated by using procedurally generated prompts.

**Hendricks et al., "Measuring Massive Multitask Learning with Adversarial User Simulation"** demonstrated that LLMs improved task performance when given personas.
In a multi-armed bandit task, they show that, LLMs impersonating children of various ages mimicked human-like developmental exploration.
In a reasoning task, LLMs portraying domain experts outperformed those assuming non-expert roles.

\subsubsection{Prospect theory and LLMs}

**Tversky & Kahneman, "Prospect Theory: An Analysis of Decision under Risk"** introduced prospect theory, a description of how humans make decisions under risk.
PT challenges the assumptions of expected utility theory (EUT) **von Neumann & Morgenstern, "Theory of Games and Economic Behavior"** by focusing on observed human behaviour rather than prescriptive models of rational choice.
In **Tversky & Kahneman, "Prospect Theory: An Analysis of Decision under Risk"** they observed several irrational behaviours which deviated from EUT.
Notably, they found that humans exhibit a distorted perception of probability, overweighting low probabilities and underweighting high probabilities.
Furthermore, they demonstrated that individuals tend to be risk-averse when facing potential gains but become risk-seeking when confronted with potential losses.
Perhaps most significantly, their research revealed that humans are more sensitive to losses than to equivalent gains, a phenomenon known as loss aversion.
cumulative prospect theory **Tversky & Kahneman, "Cumulative Prospect Theory: An Analysis of Risk Aversion and Loss Aversion"** introduced a power-law model to quantify the irrational decision making behaviour observed in **Kahneman & Tversky, "Prospect Theory: An Analysis of Decision under Risk"**.
(The model is explained in detail in Section \ref{sec:methodology}).

More recently, several researchers have investigated decision-making in LLMs with respect to prospect theory.

**Hendricks et al., "Measuring Massive Multitask Learning with Adversarial User Simulation"** demonstrated that LLMs improved task performance when given personas.
In a multi-armed bandit task, they show that, LLMs impersonating children of various ages mimicked human-like developmental exploration.
In a reasoning task, LLMs portraying domain experts outperformed those assuming non-expert roles.

**Brown et al., "Measuring Mass and Comprehension in the Great Bat Cookie Heist: Human Evaluation of a Retrieval-Augmented Generator"** reported the existence of human-like cognitive biases in GPT-3.
However, more recent studies by **Chen & Liu, "On the Emergence of Cognitive Biases in Large Language Models"** and **Li et al., "Comparing the Emergence of Cognitive Biases in Different Generations of Large Language Models"** noted that these cognitive biases have disappeared in the latest generation of LLMs (post GPT-3.5).
These models act as rational agents even without the addition of chain-of-thought prompting.
They have also shown that LLMs answer questions using short-cut learning **Brown et al., "Measuring Mass and Comprehension in the Great Bat Cookie Heist: Human Evaluation of a Retrieval-Augmented Generator"** or memorisation **Kaplan et al., "Scaling Language Models with Variance Regularization"**.
It is hypothesised that popular psychometric tests are in the training data, and due to the uniqueness of their data,
they are likely memorised **Bommasani et al., "On the Opportunities and Risks of Foundations for Foundation Models"**.
These behaviours can be mitigated by using procedurally generated prompts.

\section{References}