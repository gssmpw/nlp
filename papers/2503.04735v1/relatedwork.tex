\section{Related works}
\label{sec:related-work}
We review related works across machine learning, psychology, and economics in three key areas:
psychometric assessment of personality in humans and LLMs,
the analysis of risk-propensity through the lens of prospect theory (PT),
and the implementation of in-context learning interventions aimed at modulating the personality of LLMs.

\subsection{Personality and risk-propensity in humans}
\label{subsec:personality-and-risk}

Researchers have demonstrated that human personalities can be explained by several independent factors.
A widely accepted model is the Big Five, which categorizes personalities into five traits, often referred to by the acronym OCEAN (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) \citep{mccrae1987validation, digman1989five, mccrae1992introduction, costa1992normal, saucier1996language}.
An individual's alignment with these factors is measured through their responses to questions associated with specific personality facets for each trait \citep{costa1992normal, goldberg1999broad}.
For instance, the IPIP-NEO inventory \citep{goldberg1999broad}, extensively used in this work, contains several facets for each trait.
Taking Conscientiousness as an example, its first four facets are: \textit{Self-efficacy}, \textit{Orderliness}, \textit{Dutifulness}, and \textit{Achievement-Striving}
(an exhaustive list of personality traits and their associated personality facets is given in Table~\ref{tab:big_five_traits}.).

The following section examines how the Big Five personality traits correlate with risk-propensity in human subjects:

\textbf{Openness to Experience}: The personality trait of Openness is a consistent predictor of risk-taking behaviors in humans.
Research studies have shown its significant correlation with increased risk-propensity across various scenarios.
For instance, \citet{nicholson2005personality} identify Openness as a strong predictor of higher risk-propensity.
\citet{rustichini2016toward} further delineate that Openness is positively associated with risk-taking in contexts where gains are involved, but negatively associated in scenarios involving potential losses.
A meta-analysis conducted by \citet{highhouse2022risk} substantiates these findings, reporting that Openness accounts for 22\% of the variance in risk-propensity.
This indicates a substantial impact of Openness on individual's risk-taking behaviors.
Focusing on investment decisions, \citet{de2019personality} reveal that individuals scoring high on Openness tend to adopt riskier investment strategies.

\textbf{Extraversion}: Multiple studies report a positive correlation between extraversion and risk-propensity.
\citet{nicholson2005personality} and \citet{oehler2018relationship} find that individuals high in extraversion tend to engage in more risk-taking behaviours.

\textbf{Neuroticism}: Research indicates an inverse relationship between neuroticism and risk-taking.
\citet{nicholson2005personality} and \citet{soane2005risk} find that higher levels of neuroticism are linked to lower risk-taking.
Further, \citet{oehler2018relationship} add that neurotic individuals exhibit greater risk aversion, particularly in investment contexts.

\textbf{Agreeableness}: Higher agreeableness generally correlates with lower risk-taking tendencies.
Studies by \citet{nicholson2005personality} and \citet{joseph2021personality} indicate that agreeable individuals are less inclined toward risk.
Additionally, \citet{soane2005risk} observe that agreeableness is inversely related to risk-taking.

\textbf{Conscientiousness}: Conscientiousness shows a complex relationship with risk.
While \citet{nicholson2005personality} suggest lower conscientiousness may correspond with higher risk-taking,
\citet{weller2012honest} specifically associate low conscientiousness with greater risk-taking to achieve gains.
\citet{boyce2016individual} highlight conscientious individualsâ€™ strong reactions to income losses, signifying pronounced loss aversion.
In investment contexts, \citet{oehler2018relationship} note that high conscientiousness aligns with greater risk aversion.

\subsection{Machine psychology}\label{subsec:machine-psychology}

Emergent cognitive behaviours in LLMs cannot be studied under the typical train-and-test machine learning paradigm since these behaviours are not explicitly coded for during training~\citep{hagendorff2023machine}.
Instead, tests from behavioural psychology can be used to reveal characteristic behaviour of black-box LLMs without necessarily understanding how the behaviour was learnt.
Authors caution that care should be taken not to generalise the results of self-reported psychometric test results beyond any particular system prompt \citep{rottger2024political}.
Nevertheless, several works have shown that induced personalities generalise to new tasks~\citep{serapio2023personality, ross2024llm}.

\citet{binz2023using} reported the existence of human-like cognitive biases in GPT-3.
However, more recent studies by \citet{hagendorff2023human} and \citet{chen2023emergence} noted that these cognitive biases have disappeared in the latest generation of LLMs (post GPT-3.5).
These models act as rational agents even without the addition of chain-of-thought prompting.
They have also shown that LLMs answer questions using short-cut learning~\citep{geirhos2020shortcut} or memorisation~\citep{carlini2019secret, carlini2021extracting, hartley2023neural}.
It is hypothesised that popular psychometric tests are in the training data, and due to the uniqueness of their data,
they are likely memorised~\citep{carlini2019secret, carlini2021extracting}.
These behaviours can be mitigated by using procedurally generated prompts.

\citet{salewski2024context} demonstrated that LLMs improved task performance when given personas.
In a multi-armed bandit task, they show that, LLMs impersonating children of various ages mimicked human-like developmental exploration.
In a reasoning task, LLMs portraying domain experts outperformed those assuming non-expert roles.

\subsubsection{Prospect theory and LLMs}

\citet{kahneman1979prospect} introduced prospect theory, a description of how humans make decisions under risk.
PT challenges the assumptions of expected utility theory (EUT)~\citep{von2007theory} by focusing on observed human behaviour rather than prescriptive models of rational choice.
In \citet{kahneman1979prospect} they observed several irrational behaviours which deviated from EUT.
Notably, they found that humans exhibit a distorted perception of probability, overweighting low probabilities and underweighting high probabilities.
Furthermore, they demonstrated that individuals tend to be risk-averse when facing potential gains but become risk-seeking when confronted with potential losses.
Perhaps most significantly, their research revealed that humans are more sensitive to losses than to equivalent gains, a phenomenon known as loss aversion.
cumulative prospect theory~\citep{tversky1992advances} introduced a power-law model to quantify the irrational decision making behaviour observed in \citet{kahneman1979prospect}.
(The model is explained in detail in Section \ref{sec:methodology}).

More recently, several researchers have investigated decision-making in LLMs with respect to prospect theory.
\citet{binz2023using} submitted GPT-3 to a number of vignettes and tasks from the cognitive psychology literature.
They found that GPT-3 showed several human-like cognitive biases from PT: certainty effect \footnote{The certainty effect is the tendency of agents to prefer certain outcomes to risky outcomes.},
overweighting effect\footnote{The overweighting effect is the tendency of agents to overweight the probability of rare outcomes.},
and the framing effect\footnote{The framing effect describes the influence of the presentation of outcomes on decision-making.}.
In subsequent work, \citet{binz2023turning} improved the alignment between LLama 2--65B~\citep{touvron2023llama} and human decision-making by training a
logistic regression model on LLama 2 embeddings of risky prospects from the choices13k dataset~\citep{peterson2021using}.
They also achieved increased performance on a hold-out task.
However, the limitation of this work is that the model is no longer generative.
Concurrently~\cite{ross2024llm}, measured the CPT parameters of GPT-4o and GPT-4-Turbo and found that cognitive biases in these
more recent models are reduced.
The authors also show that risk-propensity is sensitive to qualitative personas.
However, a quantitative comparison with risk personas in humans cannot be made since these profiles are not based on established personality models.
In our work we investigate the relationship between established personality models and risk-propensity in LLMs,
and examining the similarities between these relationships in humans.

\subsection{Personality prompting}\label{subsec:personality-prompting}

Recent research has extensively explored the induction and measurement of personalities in LLMs. For example, \citet{jiang2024evaluating} employed self-reported psychometric testing to assess LLMs' personalities along the Big Five traits.
They developed a method to induce these traits in LLMs and demonstrated that the induced personalities generalised to vignette experiments.
Similarly, \citet{serapio2023personality} reported on LLM personality types using psychometric tests.
Their method allowed for independent induction of personalities along each trait, with controllable levels for the intensity of each personality trait.
The authors validate their method by measuring the correlation between induced personality trait levels and the LLMs' responses to the IPIP-NEO-300 inventory for each trait.
Furthermore, they observed that these personalities generalised well to downstream tasks such as generating social media posts.

Several studies have explored personality characteristics beyond the Big Five personality traits.
\citet{li2022does} reported that LLMs generally score higher than the human average for toxic personality traits,
specifically the Dark Triad~\citep{furnham2013dark}.
The authors successfully implemented interventions on these traits using in-context learning.
\citet{miotto2022gpt} assessed GPT-3's personality using the 60-item Hexaco questionnaire~\citep{ashton2009hexaco},
revealing multiple personalities at different sampling temperatures.
\citet{coda2023inducing} found that GPT-3.5 displays higher than human average anxiety on the State-Trait Inventory for Cognitive and Somatic Anxiety (STICSA) Questionnaire~\citep{ree2008distinguishing}.

The validity of self-reported personality testing in LLMs has recently been questioned.
\citet{suhr2023challenging} demonstrated that GPT-3.5 and LLama 2 do not show consistency in their evaluation of personality inventories.
For example, their factor analysis revealed that responses to the Big-Five-Inventory 2 (BFI-2) do not show a simple structure for the first five factors of variation.
However, they found that the component loadings for GPT-4-Turbo are separable for each factor, indicating consistent personality traits across questioning for this more advanced model.