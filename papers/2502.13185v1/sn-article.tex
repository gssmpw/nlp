\documentclass[pdflatex,sn-standardnature]{sn-jnl}
\jyear{2025}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[title]{appendix}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{manyfoot}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{array}
\usepackage{threeparttable}

% \onehalfspacing
% \doublespacing
% \linenumbers

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads



\begin{document}

%% Title
\title[Article Title]{CondensNet: Enabling stable long-term climate simulations via hybrid deep learning models with adaptive physical constraints}

% \title{CondensNet: A Physically-Constrained Hybrid Deep Learning Model for Stable Long-Term Climate Simulations}

%% Authors
\author[1]{\fnm{Xin} \sur{Wang}}\email{xin.w24@nus.edu.sg}

\author[2]{\fnm{Juntao} \sur{Yang}}\email{yjuntao@nvidia.com}

\author[2]{\fnm{Jeff} \sur{Adie}}\email{jadie@nvidia.com}

\author[2]{\fnm{Simon} \sur{See}}\email{ssee@nvidia.com}

\author[3]{\fnm{Kalli} \sur{Furtado}}\email{kalli\_furtado@nea.gov.sg}

\author[3]{\fnm{Chen} \sur{Chen}}\email{chen\_chen@nea.gov.sg}

\author[4]{\fnm{Troy} \sur{Arcomano}}\email{tarcomano@anl.gov}

\author[5]{\fnm{Romit} \sur{Maulik}}\email{rmaulik@psu.edu}

\author*[1,6]{\fnm{Gianmarco} \sur{Mengaldo}}\email{mpegim@nus.edu.sg}



%% Affiliations
\affil*[1]{
% \orgdiv{Department of Mechanical Engineering}, 
\orgname{Department of Mechanical Engineering, National University of Singapore}, 
\country{SG}}

\affil[2]{
\orgdiv{NVIDIA AI Technology Centre}, 
\orgname{NVIDIA Corporation}, 
\country{SG}}

\affil[3]{
\orgdiv{Centre for Climate Research Singapore}, 
\country{SG}}

\affil[4]{
\orgdiv{Environmental Science Division, Argonne National Laboratory}, 
\country{USA}}

\affil[5]{
\orgdiv{Information Sciences and Technology Department, The Pennsylvania State University}, 
\country{USA}}

\affil[6]{
\orgdiv{Department of Mathematics, National University of Singapore \\(by courtesy)}}




%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%
%TC:ignore
\abstract{Accurate and efficient climate simulations are crucial for understanding Earth's evolving climate. 
However, current general circulation models (GCMs) face challenges in capturing unresolved physical processes, such as cloud and convection. 
A common solution  is to adopt cloud resolving models, that provide more accurate results than the standard subgrid parametrisation schemes typically used in GCMs. 
However, cloud resolving models, also referred to as super paramtetrizations, remain computationally prohibitive. 
Hybrid modeling, which integrates deep learning with equation-based GCMs, offers a promising alternative but often struggles with long-term stability and accuracy issues.
In this work, we find that water vapor oversaturation during condensation is a key factor compromising the stability of hybrid models. 
To address this, we introduce CondensNet, a novel neural network architecture that embeds a self-adaptive physical constraint to correct unphysical condensation processes. 
CondensNet effectively mitigates water vapor oversaturation, enhancing simulation stability while maintaining accuracy and improving computational efficiency compared to super parameterization schemes.

We integrate CondensNet into a GCM to form PCNN-GCM (Physics-Constrained Neural Network GCM), a hybrid deep learning framework designed for long-term stable climate simulations in real-world conditions, including ocean and land. 
PCNN-GCM represents a significant milestone in hybrid climate modeling, as it shows a novel way to incorporate physical constraints adaptively, paving the way for accurate, lightweight, and stable long-term climate simulations.
}
\keywords{Hybrid modeling, Deep Learning, Climate models, Climate Change}

\maketitle
%TC:endignore

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 1. INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}

Climate change is bringing more frequent and intense extreme weather events that are causing significant harm to ecosystems and communities worldwide~\cite{zhongming2021ar6}. 

General circulation models (GCMs), climate models that use mathematical equations to simulate the Earth's system, are critical to understand climate change over various time scales~\cite{allan2021ipcc}. 
Indeed, they can be pivotal for the survival of a certain community or ecosystem, if they were to provide reliable projections on actionable time scales. 

One of the primary sources of unreliability in modern GCMs stems from the challenges associated with \textit{cloud} and \textit{convection} processes. 
These phenomena are inherently tied to small-scale atmospheric physics occurring at kilometer or sub-kilometer scales, which current GCMs struggle to capture due to their relatively coarse spatial resolution ($\sim$ 50 km). 
To address this limitation, various approaches have been proposed in the literature.
These can be grouped into two categories: subgrid parametrization models, and super parametrization models. 

Subgrid parametrization models use simplified empirical relationships or theoretical approximations to describe small-scale atmospheric processes that current GCMs are unable to resolve~\cite{bony2015clouds,liang2022stiffness,randall2003breaking,emanuel1994large}. 
While computationally efficient, these subgrid models are relatively simplistic, and are a leading source of uncertainties in GCMs' climate projections~\cite{stevens2013climate}.

Super parametrization models embed high-resolution cloud-resolving models (CRMs) within each grid cell of a larger-scale GCMs.
These CRMs explicitly resolve small-scale atmospheric processes, enhancing the model's ability to simulate cloud dynamics. 
A notable example is the super-parameterized community atmosphere model (SPCAM), developed by the National Center for Atmospheric Research (NCAR)~\cite{khairoutdinov2001cloud,khairoutdinov2005simulations}. 
Despite their improved accuracy, these models are computationally intensive, often rendering them impractical for long-term climate projections~\cite{satoh2008nonhydrostatic}.

A promising and emerging area of research, known as hybrid modeling (as it hybridizes physics and machine learning), blends CRMs with machine learning.
The idea is to use the wealth of scale-resolving data from various CRMs to construct high-fidelity and computationally-efficient deep learning (DL) emulators (also referred to as DL parametrizations) of small-scale processes, such as cloud and convection processes, on each cell of the coarse GCM grid. 
This promising research area offers better accuracy than traditional subgrid parametrization models at a much cheaper computational cost than super parametrization models~\cite{rasp2018deep,yuval2020stable,han2020moist,mooers2021assessing,arcomano2022hybrid}. 

While several breakthroughs have been made in hybrid climate modeling over the past few years, one key issue remains: the lack of stability for long-term climate simulations.

To address this issue, many attempts focused on enforcing physical constraints within machine learning models, initially on idealized settings~\cite{beucler2019achieving,beucler2021enforcing,yuval2020stable,yuval2021use}. 
These efforts demonstrated some degree of success, without fully addressing the lack of long-term simulation stability, especially in real-world settings\footnote{\textbf{A real-world setting} is a present-day climate model setting, coupled to a land surface model Community Land Model version 4.0~\cite{oleson2010technical} and forced under prescribed sea surface temperatures and sea ice concentrations~\cite{hurrell2008new}.}.  
More recently, 10-year stable simulations under real land and sea distributions were achieved~\cite{wang2022stable}, although with a trial-and-error approach, and without fully addressing the issue. 
Recent work has targeted specific aspects, such as relative humidity to prevent excessive moistening~\cite{fuchs2023torchclim} and water condensation, enabling 5-month stable runs~\cite{behrens2024improving}.
Physical constraints like global mass and moisture conservation were incorporated into ACE2, a promising DL-based climate emulator with a post-processing correction module~\cite{watt2024ace2}.
Another promising approach used differentiable dynamics to integrate neural networks with numerical methods, improving stability and prediction~\cite{kochkov2024neural}, without directly enforcing physical constraints.

% One of the hypothesis for the lack of stability in these simulations was deemed to be the inability of machine learning models to learn the correct representation of the water cycle, and related processes. 
% Indeed, latest attempts focused on some of these aspects, namely relative humidity, to avoid unrealistic moistening tendencies~\cite{fuchs2023torchclim} and water condensation~\cite{behrens2024improving}, the latter achieving 5-month stable simulations. 
% Physical constraints -- such as global mass and moisture conservation -- were also used in a purely DL framework, namely ACE2, that represents a promising climate emulator through a post-processing correction module embedded into its neural-network architecture~\cite{watt2024ace2}.  
% A different approach using differentiable dynamics to integrate neural networks with numerical methods showed improved stability and prediction skills~\cite{kochkov2024neural}. 
% However, these methods still lack comprehensive physical constraints necessary for achieving the long-term stability required in climate simulations.

In this study, we show that the regulation of water vapor saturation is critical to obtain long-term stability in hybrid DL climate models, and to avoid oversaturation that in turn leads the simulations to fail.
To address this problem, we propose a new neural network architecture, depicted in Figure~\ref{fig:Fig1}, constituted of two main components: 1) a basic model (BasicNet), learning the cloud representation, and 2) a condensation correction network (ConCorrNet), learning the condensation process. 
We name this new neural network architecture, composed of the BasicNet and the ConCorrNet, ~\textit{CondensNet}, to emphasize the physical condensation constraint imposed. 
Notably, unlike simple post‐processing methods that mechanically adjust non‐physical predictions solely to enforce water vapor conservation (often resulting in inaccurate solutions -- e.g., significant water vapor biases), our ConCorrNet adaptively refines BasicNet outputs by learning from SPCAM training targets, thereby ensuring that corrections are both physically consistent and accurate, in contrast to those obtained from an unconstrained neural network.
With a particular training strategy (detailed in Methods, section~\ref{app:training}), CondensNet can accurately learn cloud physics  from super parametrization (CRM) simulations, while imposing a physical constraint that address the water vapor oversaturation issue. 
%
\begin{figure}[htbp]
  \centering
    \includegraphics[width=1.00\linewidth]{./figures/Fig1.pdf}
    \caption{Methodology of the CondensNet model. CondensNet is a physically-constrained DL parametrization coupled with a climate dynamics engine to support hybrid modeling. The network architecture mainly has two parts: BasicNet for learning the cloud representation and ConCorrNet for condensation physical constraint.}
  \label{fig:Fig1}
\end{figure}
%
CondensNet is integrated with the Community Atmosphere Model (CAM), that is used as our reference host GCM. 
CAM is responsible to drive the large-scale dynamics of the hybrid climate simulation, while CondensNet learns small-scale processes from SPCAM.
The latter is our reference super parametrization, also referred to as SP-GCM to highlight that CondensNet can be applied to any super parametrization scheme and host GCM. 

CondensNet together with the chosen host GCM, namely CAM, form the overall hybrid DL-GCM framework that we name \textit{PCNN-GCM} (\textit{Physics Constrained-Neural Network GCM}).
PCNN-GCM runs under real-world conditions, as it uses Community Land Model version 4.0~\cite{lawrence2011parametrization} for the land component of the Earth system, and it is forced under prescribed sea surface temperatures and sea ice concentrations according to the Atmospheric Model Intercomparison Project (AMIP) protocol. 
The new PCNN-GCM framework represents a major step forward in hybrid climate modeling, as it showcases the effective use of adaptive physical constraints to achieve long-term stability without sacrificing accuracy, at a much cheaper computational cost than super parametrization models.
It also addresses one of the key drawbacks in previous stable simulations, namely the need for extensive and time-consuming trial-and-error before achieving stability~\cite{wang2022stable}, or the reliance on online training and extensive software engineering resources for developing fully differentiable dynamics~\cite{kochkov2024neural}. We remark that CondensNet can be implemented in any host GCM and can learn any super parametrization (not only SPCAM), hence the naming choice, i.e., PCNN-GCM, of the overall framework. 

% and while enforcing faithful physics of small-scale processes





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:results}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2.1 LONG-TERM STABILITY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Long-term stability}
\label{subsec:stablity}
%
GCMs integrated with DL parametrizations often become unstable during long-term simulations, where the instability typically manifests as an energy surge~\cite{wang2022stable}.

To understand stability in hybrid climate simulations, we use the same GCM configuration as~\cite{wang2022stable}, referred to as NN-GCM (Neural Network-GCM), and reproduce the stable case, the climate drift case, and the crashed cases.
Figure~\ref{fig:Fig2}, panel I, shows the temporal evolution of total energy, while Figure~\ref{fig:Fig2}, panel II, shows the temporal evolution of global average total precipitable water content.
For both panels, dashed black is the SPCAM reference, gray is CAM5, light green is the stable and unbiased NN-GCM, yellow is NN-GCM with bias, orange is NN-GCM causing climate drift, dark red is an unstable NN-GCM that fails on the 107th simulated day (5105th time step), and dark green is the new PCNN-GCM that produces a stable, unbiased behavior, that follow closely the SPCAM reference. 
In simulations that fail or produce climate drift, there is an energy surge (Figure~\ref{fig:Fig2}a), that manifests as an abnormal increase in total precipitable water content (Figure~\ref{fig:Fig2}d). 
Indeed, the behavior of the two variables is qualitatively similar.

Further analysis of the total precipitable water content (i.e., water vapor) distribution in the crashing cases reveals that, as time progresses toward the point of failure, the simulated water vapor shows a significant abnormal increase at 200 hPa and higher vertical levels (Figure~\ref{fig:Fig2}h). 
This suggests that DL parametrizations without physical constraints cause abnormal condensation of water vapor, leading to non-physical relative humidity values.
%
\begin{figure}[htbp]
  \centering        
    \includegraphics[width=1.00\linewidth]{./figures/Fig2.pdf}
    \caption{Total energy (a) and total precipitable water (d) time evolution for different models, including stable (light green), biased (yellow), drifted (orange), and crashed (dark red) ResMLP DL parametrizations, part of NN-GCM, as well as SPCAM (dark green). 
    Total energy (b) and total precipitable water (e) time evolution of Unstable ResMLP models, part of NN-GCM. 
    Total energy (c) and total precipitable water (f) time evolution of stable CondensNet models, part of PCNN-GCM, using as baseline the same configuration of the unstable ResMLP models, to show the effects of CondensNet stabilization properties. 
    Relative humidity for SPCAM reference (g), NN-GCM model failing after 5000 time steps (h), stable NN-GCM, and new PCNN-GCM featuring CondensNet (j).}
  \label{fig:Fig2}
\end{figure}
%

As water vapor is closely linked to Earth's water cycle and influences the exchange of energy, momentum, and matter among the atmosphere, land, and oceans~\cite{trenberth2009earth}, its unphysical representation can affect several Earth system's processes (and especially the ones related to the water cycle), thereby affecting simulation stability. 
We hypothesize that ensuring a physically accurate representation of condensation is essential for the stability of long-term climate simulations.

To ensure a physical representation of condensation, we introduce an adaptive physical constraint neural network architecture, termed the condensation correction network (ConCorrNet) -- details of ConCorrNet are provided in Methods, section~\ref{sec:PCNN-GCM}.
ConCorrNet is tasked to maintain balance in the water cycle process, and it is integrated with a BasicNet i.e., a neural network architecture that is tasked to predict basic tendencies of water vapor (d$Q$) and dry-static-energy (d$s$). 
ConCorrNet and BasicNet are integrated together to form the new DL parametrization, namely CondensNet, that captures fundamental cloud physics from super parametrization models. 
CondensNet is then integrated into a GCM, namely CAM version 5.2, to form the overall hybrid DL framework, namely PCNN-GCM. The latter is thoroughly described in Methods, section~\ref{sec:PCNN-GCM}.

If we re-run the unstable NN-GCM simulations shown in Figure~\ref{fig:Fig2} (i.e., the crashed NN-GCM simulations depicted in red) using the new PCNN-GCM framework, we now achieve stable simulations without any need for parameter tuning. 
In particular, we tested PCNN-GCM on six unstable NN-GCM models that led the associated simulations to crash~\cite{wang2022stable}. 
Figure~\ref{fig:Fig2}b,e show the total energy and total precipitable water curves before implementing the physical constraint via CondensNet, that is: running the DL parametrization within NN-GCM, which lacks physical constraints.
Figure~\ref{fig:Fig2}c,f show the same curves, using the new PCNN-GCM framework, that imposes a physical constraint on water vapor via CondensNet.
The results show that, after employing CondensNet, the total energy curves of the six previously unstable NN-GCM models align closely with SPCAM (ground truth) and remain stable.
In addition, the water vapor of PCNN-GCM (Figure~\ref{fig:Fig2}j) closely resembles the SPCAM reference (Figure~\ref{fig:Fig2}g), and significantly improves the rather inaccurate results provided by NN-GCM (Figure~\ref{fig:Fig2}i).
We remark that the simulations shown here are under real-world settings that include land and sea components through CLM version 4.0 and AMIP, respectively.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2.2 SIMULATION ACCURACY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Implications on simulation accuracy}
\label{subsec:accuracy}
%
The new PCNN-GCM framework, featuring CondensNet, generates stable long-term climate simulations. 
Yet, it requires thorough evaluation to guarantee that the accuracy does not deteriorates due to the novel architecture. 
% \textcolor{-red}{GM: add comment on accuracy issues here + references. 
% Indeed, this is a major issue when stabilizing hybrid DL-GCM models using post-processing fixes.}

% \textcolor{-red}{Xin Wang: Based on my literature review, I have noticed that most studies incorporating physical constraints in hybrid DL models do not emphasize the negative impact on prediction accuracy. I think they would not like to show inaccurate results, so they may tend to tune or select optimal results in papers. The prominent mentions of issues are comments on the challenges during the training phase (e.g., Harder et al., 2023~\cite{harder2023hard}; Beucler et al., 2021~\cite{beucler2021enforcing}), where the network initially struggles with balancing multiple loss components. However, these discussions mainly focus on the optimization difficulties rather than indicating that the final prediction accuracy is compromised.
% My suggestion is that we avoid discussing this too much here. It sounds good, thank you!}

We compare PCNN-GCM, against NN-GCM, and CAM5, using SPCAM as the ground truth (and training reference for PCNN-GCM and NN-GCM), where the evaluation period spans from 1 January 1999, to 31 December 2003, whereby the training period ranges from 1 January 1997 to 31 December 1998.  
CAM5 is introduced as a widely used baseline GCM, and it represents the host GCM adopted by the PCNN-GCM framework. 
In the results, we refer to CAM5 as GCM=CAM5, to highlight this aspect, and to remark that the CondensNet architecture underlying PCNN-GCM can be seamlessly ported to other host GCMs. 

In Table~\ref{tab:Tab1}, we show the root mean square error (RMSE), calculated as in Equation~\ref{eq:rmse}, between each model and the SPCAM reference, for key simulation variables, noting that before calculating the RMSE we calculated the respective means following Equation~\ref{eq:clim-mean} -- see Methods, section~\ref{sec:means} for more details. 
This comprehensive evaluation quantitatively assesses each model's ability to reproduce SPCAM's climate characteristics across multiple spatial and temporal scales, where SPCAM implements a super parametrization that better represents the under-resolved processes than standard subgrid parametrizations~\cite{kooperman2016robust,arnold2014effects,bretherton2014cloud}.
%
\begin{table}[htbp] 
  \centering
  \caption{Comprehensive evaluation of climate simulations by SPCAM, CAM5, NN-GCM, and PCNN-GCM. 
  The table shows the reference values from SPCAM and the performance metrics (RMSE) of other models along with their actual values in parentheses. 
  Bold and underlined values indicate the best and second-best performance in comparison metrics.}
  \begin{tabular}{l*{4}{c}}
    \toprule
    & \multicolumn{4}{c}{\textbf{Model Performance}} \\
    \cmidrule{2-5}
    & \multicolumn{1}{c}{SPCAM} & \multicolumn{3}{c}{RMSE (Actual Value)} \\
    \cmidrule{3-5}
    Variables & Actual Value & CAM5 & NN-GCM & PCNN-GCM \\
    \midrule
    Precipitation              & 2.824   & \underline{0.783} &  0.894            & \textbf{0.708}    \\
    (mm/day)                   &         & (2.967)           & (2.835)           & (2.908)           \\[0.5em]
    Precipitation (land)       & 2.198   &  0.761            & \underline{0.719} & \textbf{0.587}    \\
    (mm/day)                   &         & (2.123)           & (2.384)           & (2.251)           \\[0.5em]
    Precipitation (ocean)      & 3.214   & \underline{0.818} &  0.990            & \textbf{0.770}    \\
    (mm/day)                   &         & (3.460)           & (3.146)           & (3.319)           \\[0.5em]
    Total precipitable water   & 25.640  & \textbf{1.358}    &  2.077            & \underline{1.459} \\
    ($kg/m^2$)                 &         & (25.615)          & (26.898)          & (25.554)          \\[0.5em]
    Surface water flux         &  2.825  & \underline{0.342} &  0.382            & \textbf{0.247}    \\
    ($mm/m^2$)                 &         & (2.967)           & (2.724)           & (2.854)           \\[0.5em]
    Sensible heat flux         & 19.493  & \textbf{4.149}    &  6.771            & \underline{4.567} \\
    ($W/m^2$)                  &         & (18.299)          & (20.359)          & (19.973)          \\[0.5em]
    2m temperature             & 287.355 & \textbf{0.622}    &   3.978           & \underline{2.530} \\
    (K)                        &         & (287.121)         & (288.854)         & (288.048)         \\[0.5em]
    % Surface temperature        & 288.159 & \textbf{0.688}    &    4.339          & \underline{2.424} \\
    % (K)                        &         & (287.889)         & (289.879)         & (288.907)         \\[0.5em]
    % Surface temperature (land) & 281.831 & \textbf{1.116}    &    7.700          & \underline{4.371} \\
    % (K)                        &         & (281.160)         & (286.789)         & (283.974)         \\[0.5em]
    10m wind speed             &   6.080 & \textbf{0.434}    &    0.737          & \underline{0.445} \\
    (m/s)                      &         & (5.973)           & (5.625)           & (5.912)           \\[0.5em]
    Vertical Specific humidity & -       & 0.231             & 0.144             & \textbf{0.116}    \\
    (g/kg)                     &         & (-)               & (-)               & (-)               \\[0.5em]
    Vertical wind speed        & -       & \textbf{1.894}    & 3.382             & \underline{2.286} \\
    (m/s)                      &         & (-)               & (-)               & (-)               \\[0.5em]
    Vertical Temperature       & -       & 2.567             & \textbf{1.419}    & \underline{1.357} \\
    (K)                        &         & (-)               & (-)               & (-)               \\
    \bottomrule
  \end{tabular}
  \label{tab:Tab1}
\end{table}
%
The results show how PCNN-GCM produces more accurate results than CAM5 and NN-GCM for all variables related to the water cycle (except for total precipitable water, where the results is close to CAM5, yet significantly better than NN-GCM). 
In addition, PCNN-GCM is comparable to CAM5 and significantly better than NN-GCM in terms of sensible heat flux, and wind speed (both 10m and vertical). 
PCNN-GCM performs worse than CAM5 for 2m temperature, yet significantly improving the results of NN-GCM, while it outperforms CAM5 for the vertical distribution of temperature. 

The under-performance in 2m temperature predictions stems from the practical difficulty in accessing boundary layer data within the host GCM (i.e., CAM5.2).
Since the 2m temperature is diagnostically calculated using surface and lowest-level temperatures, an accurate representation of boundary layer processes (surface-atmosphere interactions, turbulent mixing) is crucial. 
Currently, both NN-GCM and PCNN-GCM are not accessing planetary boundary layer variables (it would require significant software engineering resources to do so, that is beyond the scope of this work), aspect that affects their capacity to capture near-surface temperature gradients. 
Yet, we remark that this limitation does not affect the outcomes of this work outcomes -- indeed, where boundary-layer information are more easily accessible (e.g., Energy Exascale Earth System Model (E3SM)~\cite{tang2023fully}), these can be retrieved providing more accurate results for 2m and surface temperature.

We further assessed the performance of PCNN-GCM for two key variables related to the water cycle, given the physical condensation constraints imposed. 
These are the precipitation field, and the vertical profile of specific humidity in the period 1999--2003, both reported in Figure~\ref{fig:Fig3}. 
For the two variables, we present averaged results, obtained as reported in Methods, section~\ref{sec:means}, where Figure~\ref{fig:Fig3}a--d depict precipitation for the reference SPCAM and for CAM5, NN-GCM, and PCNN-GCM, respectively, whereas Figure~\ref{fig:Fig3}h--k depicts specific humidity.
We also show the corresponding differences of each model (i.e., CAM5, NN-GCM, and PCNN-GCM) with respect to SPCAM, for both precipitation (Figure~\ref{fig:Fig3}e--g) and specific humidity (Figure~\ref{fig:Fig3}m--o), calculated using Equation~\ref{eq:pattern-diff} in Methods (section~\ref{sec:errors}), where we also report the RMSE errors in the title of each subfigure. 
For more details on these calculations, refer to Methods, section~\ref{sec:errors}. 
%
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1.0\linewidth]{./figures/Fig3.pdf}
    \caption{Precipitation (a--d) and vertical profile of specific humidity (h--k), for SPCAM, CAM5, NN-GCM, and PCNN-GCM, respectively, and corresponding differences with respect to SPCAM reference (e--g, for precipitation, and m--o, for specific humidity).
    The fields are annual means (1998-2002) computed as reported in Methods~\ref{sec:means}, and their differences are computed as in Equation~\ref{eq:pattern-diff}, reported in Methods~\ref{sec:errors}. 
    We also provide error metrics, namely RMSE, for all subfigures related to differences (i.e., e--g for precipitation and m--o for specific humidity).}
  \label{fig:Fig3}
\end{figure}
%

In terms of precipitation, we observe that all the models considered can reproduce SPCAM results over Asian land, tropical land, and ocean continents. 
However, CAM5 significantly underestimates the precipitation rate in the equatorial eastern Pacific and overestimates the precipitation in tropical continents (Figure \ref{fig:Fig3}e), and NN-GCM underestimates the precipitation in the maritime continent and equatorial eastern Pacific (Figure \ref{fig:Fig3}f). 
Compared to CAM5 and NN-GCM, PCNN-GCM (Figure \ref{fig:Fig3}g) provides results that are significantly closer to SPCAM, with an overall lower RMSE error (see title of each subfigure in Figure~\ref{fig:Fig3}e--g). 
In addition, if we focus on critical regions such as the Intertropical Convergence Zone (ITCZ), the South Pacific Convergence Zone (SPCZ), and the Asian monsoon region, we observe that NN-GCM and PCNN-GCM are closer to SPCAM than CAM5.
%(especially for the simulation of Asian land and tropical land). 
Notably, NN-GCM exhibits a precipitation separation in the ITCZ (Figure \ref{fig:Fig3}c), which is absent in PCNN-GCM (Figure \ref{fig:Fig3}d), rendering it closer to the SPCAM distribution.

In terms of specific humidity vertical profiles, Figure~\ref{fig:Fig3}h--k shows that both NN-GCM and PCNN-GCM produce results that are closed to SPCAM than CAM5, as illustrated by the RMSE errors reported in the title of each Figure~\ref{fig:Fig3}m--o.
Owing to CondensNet, that incorporates physical constraints on water vapor condensation, PCNN-GCM (Figure~\ref{fig:Fig3}o) exhibits closer agreement with SPCAM than NN-GCM (Figure~\ref{fig:Fig3}n).
In addition, PCNN-GCM alleviates the dry bias below 600 hPa in the Antarctic region (i.e., 90°S-60°S), leading to better consistency with SPCAM than CAM5 and NN-GCM. 
However, moderate dry and wet biases persist in the tropical region below 400 hPa (Figure~\ref{fig:Fig3}o).

We present additional results in Supplementary Information~\ref{si:additional-results}, where we show more detailed analyses of wind speed and temperature (section~\ref{si:additional-key-thermodynamics}), precipitation (section~\ref{si:additional-results-precipitation}), and climate variability (section~\ref{si:additional-results-climate-variability}).





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2.3 COMPUTATIONAL COSTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Computational costs}
\label{sec:computational-costs}
%
The computational experiments were conducted on an HPC cluster composed of eight compute nodes, each equipped with an Intel Xeon Gold 6132 CPU with 24 cores (one MPI process per core) and a single NVIDIA V100 GPU to accelerate the PCNN-GCM computations.
The RAM available was 96GB (128GB/s), with the connection network being Infiniband QDR, and CentOS 7.6.1810 operating system. The compiler adopted was the Intel compiler 19.0.5, and we used the Intel MPI Library 2019 (update 5). 

The training costs of our DL parametrization, namely CondensNet (i.e., the DL parametrization in our PCNN-GCM model) are relatively low: we spent a total of 40 GPU hours for training CondensNet, where we run 50 epochs for BasicNet (29 GPU hours), and 120 for ConCorrNet (11 GPU hours). 
BasicNet was constituted of 7 residual blocks (14 layers) and two separate ResMLP modules—one predicting $\mathrm{d} Q$ and one predicting $\mathrm{d} s$—each with 512 hidden neurons and ReLU activations, effectively yielding 1024 units in total. 
ConCorrNet was constituted of 6 residual blocks (12 layers) that included two 512-wide ResMLP modules employing sigmoid activations. 
Indeed, the overall DL parametrization is relatively small, with a total number of parameters equal to 1.7 million (1 million for BasicNet and 700,000 for ConCorrNet).
For further details on the novel DL architecture and on training, the interested reader can refer to Methods section~\ref{sec:PCNN-GCM} and~\ref{app:training}, respectively. 
%
\begin{figure}[htbp]
\centering
\includegraphics[width=1.0\linewidth]{./figures/Fig4.pdf}
\caption{Subfigure (a) shows the execution time (ET) in seconds for one simulation time step across different models, namely SPCAM, CAM5, PCNN-GCM, and for different numbers of MPI processes. 
Subfigure (b) provides a detailed view of ET and of the simulated years per day (SYPD) for each model for different MPI processes. 
DL parametrization, CondensNet, inference can be run on both CPU or GPU; we report both results.}
\label{fig:Fig4}
\end{figure}
%

Figure~\ref{fig:Fig4} shows the execution time of SPCAM (that is the super parametrization reference emulated by CondensNet in our new PCNN-GCM framework), CAM5, and PCNN-GCM. 
We do not report the results for NN-GCM, as they are nearly identical to PCNN-GCM.
The host GCM is run on CPU-only hardware, whereas the DL parametrization inference can be run on either CPU or GPU. 
To this end, CAM5, SPCAM and the host GCM in PCNN-GCM are run on CPU-only hardware, while CondensNet (the DL parametrization in PCNN-GCM) is runnning on CPU (pink color) and GPU (green color).
The results show a significant speed up of PCNN-GCM with respect to SPCAM, when using both CPUs and GPUs for CondensNet (DL parametrization) inference, where inference on CPU is denoted as PCNN-GCM (CPU) and inference on GPU is denoted as PCNN-GCM (GPU), respectively.
In addition, and as one might expect, the GPU-accelerated version of PCNN-GCM is significantly faster than the CPU version, achieving an approximate speedup of 372x relative to SPCAM for 24 MPI processes. 
Increasing MPI process counts enhances CPU-only performance, thereby reducing the relative advantage of PCNN-GCM (GPU), as the DL parametrization remains independent of CPU parallelism. 
Yet, at a moderate concurrency level (e.g., 48 MPI processes), PCNN-GCM (GPU) maintains approximately 250x the performance of SPCAM. 
At 192 MPI processes, while absolute performance improves in all configurations, the relative speedup of PCNN-GCM(GPU) decreases to about 94x as CPU-only models approach near-linear scaling with process counts.

These results highlight the potential of GPU-accelerated DL parametrizations to deliver substantial performance gains without the need for large-scale HPC infrastructures. 
Under moderate concurrency, a single workstation equipped with a high-performance GPU can approximate the throughput of much larger CPU-focused deployments -- e.g., running SPCAM for 6 years takes approximately 18 days in a 192 physical CPU cores; while PCNN-GCM takes about 0.191 days (4.6 hours) when accelerated using an NVIDIA Tesla V100, or in roughly 0.233 days (5.6 hours) when running solely on the CPU. %\textcolor{red}{Xin Wang $-->$ complete ... 
(see also Figure~\ref{fig:Fig4}).%}.

% simulated years per day (SYPD) on 192 CPU Cores cluster: 

%             SPCAM:  0.33455
%              CAM5: 24.82513
%     PCNN-GCM(GPU): 31.43315
%     PCNN-GCM(CPU): 25.70131

% So, running SPCAM for 6 simulation years on 192 physical X86 Core (Intel Xeon Gold 6132) will take about 18 days. Also, generating original training data through 2 simulation years of SPCAM takes 6 days.

% I calculated the running time of DL parameterization, including all data sending and receiving, preprocessing, reshaping, and NN inference. 

% If I only calculated the NN inference time, it would have been too short and not in line with the actual situation of hybrid modeling.

% Execute time for one step of the total workflow (seconds)
% process    DL Para(GPU)    DL Para(CPU)    Super Para    CAM5 Para
%  24        0.283           1.088            105.31       1.137
%  48        0.210           0.607             52.41       0.641
%  72        0.177           0.410             34.95       0.436
%  96        0.160           0.316             26.28       0.333
% 120        0.152           0.270             21.18       0.282
% 144        0.142           0.217             17.19       0.224
% 168        0.139           0.201             14.84       0.202 
% 192        0.139           0.170             13.06       0.176


% Execute time for one step of para (seconds)
% process    DL Para(GPU)    DL Para(CPU)    Super Para    CAM5 Para
%      24    0.118           0.884           105.01        0.981
%      48    0.102           0.478            52.18        0.533
%      72    0.101           0.317            34.76        0.364
%      96    0.098           0.241            26.12        0.276
%     120    0.096           0.198            21.00        0.229
%     144    0.094           0.169            17.14        0.188
%     168    0.100           0.152            14.79        0.167
%     192    0.103           0.131            13.02        0.146

This shows the extreme potential of our hybrid DL modeling strategy with physical constraints, that can open the path to learning expensive equation-based physics (including for instance large-eddy simulation models) and provide physically-consistent and stable results at a fraction of the computational time.  




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 4. DISCUSSIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{sec:discussion}
%
The integration of DL with equation-based models has opened new avenues for addressing long-standing challenges in accurately representing cloud and convection processes, leading to the promising field of hybrid climate modeling. 

Current research has focused on developing DL parametrizations that provide both long-term stability and physical consistency while achieving significantly faster computational performance (e.g., speedup of 10x to 1000x than standard GCM with super parametrization schemes).
Yet, significant breakthroughs are still limited, especially for achieving long-term stability without compromising accuracy.

This work introduces CondensNet, a novel DL parametrization, that embeds physical condensation constraints, to address long-term stability and accuracy issues. 
CondensNet is built on the important finding that the regulation of water vapor saturation is a significant factor affecting simulation stability in real-world land and ocean configurations. 
Unlike traditional super parametrization methods that can suppress anomalous water vapor transport, unconstrained DL parametrizations may fail to replicate moisture regulation, resulting in water vapor oversaturation.  
CondensNet directly learns saturation adjustment processes from super parametrization models (where in this work we used SPCAM), through a Condensation Correction Network (ConCorrNet), that works concurrently and adaptively with a residual multi-layer perceptron, namely BasicNet (see also Methods, section~\ref{sec:PCNN-GCM}). 

The resulting improvement in stability does not compromise predictive accuracy performance or the representation of energy and matter cycles (further results on this aspect are reported in Supplementary Information~\ref{si:baseline-results}).
Moreover, the explicit inclusion of physical constraints enhances interpretability of the hybrid modeling, highlighting the crucial role played by the condensation process. 

CondensNet is integrated in our hybrid DL framework, namely PCNN-GCM, and provides physically-consistent and stable long-term climate simulations, while providing significant speedups compared to the super parametrization benchmark, SPCAM, adopted. 

In particular, we show how PCNN-GCM, through the novel CondensNet architecture, is able to run stable long-term climate simulations, following closely the SPCAM reference (Figure~\ref{fig:Fig2}, in section~\ref{subsec:stablity}), while maintaining physically-consistent results (Table~\ref{tab:Tab1} and Figure~\ref{fig:Fig3}, in section~\ref{subsec:accuracy}; Supplementary Information section~\ref{si:additional-results}). 
In addition, we show how the PCNN-GCM framework provides speedups in the order of 100x to 372x (depending on the number MPI ranks adopted), compared to the SPCAM reference (Figure~\ref{fig:Fig4}, in section~\ref{sec:computational-costs}). 

In comparison to recent approaches that impose humidity constraints or partially address condensation-related issues~\cite{fuchs2023torchclim,behrens2024improving}, CondensNet directly applies adaptive physical constraints to mitigate water vapor oversaturation. 
The work is aligned with several efforts in the community to embed physics in DL models, including the pioneering work on physics-informed neural networks (PINNs)~\cite{raissi2019physics,karniadakis2021physics}. 


The new CondensNet DL parametrization embedded in PCNN-GCM sets a milestone on how to implement physical constraints in climate models, that can be readily extended to other atmospheric processes.  
More specifically, CondensNet DL parametrization can emulate other super parametrization models, with e.g., higher resolution, and the overall computational efficiency of PCNN-GCM can be improved using e.g., model compression~\cite{hoefler2021sparsity}, and mixed-precision training~\cite{duben2017study}. 
A similar approach can also be used in recent promising hybrid DL modeling efforts, namely NeuralGCM~\cite{kochkov2024neural}, and purely DL-driven climate models, namely ACE2~\cite{watt2024ace2}, where physical constraints are currently imposed as a post-processing step.

PCNN-GCM marks a significant step towards stable, physically-consistent, and computationally lightweight hybrid climate simulations, that can support better results in regions where climate projection uncertainty still dominates (e.g.,~\cite{dong2024indo}).



%TC:ignore

\section{Methods}
\label{sec:methods}

\subsection{PCNN-GCM framework}
\label{sec:PCNN-GCM}

\subsubsection{CondensNet DL architecture and GCM model}
CondensNet (Figure~\ref{fig:methods}d) is a novel DL parametrization that learns and emulates the high-resolution cloud-resolving model (CRM) of SPCAM's super parametrization~\cite{khairoutdinov2001cloud} (Figure~\ref{fig:methods}b), where the atmospheric dynamics is driven by the Community Atmosphere Model version 5.2 (CAM5.2)~\cite{neale2010description} (Figure~\ref{fig:methods}e), running at a horizontal resolution of $1.9^\circ \times 2.5^\circ$ with 30 vertical pressure levels, extending up to approximately 2 hPa.
CAM5.2 is further coupled with the Community Land Model version 4.0 (CLM4.0)~\cite{lawrence2011parametrization}, using prescribed sea surface temperatures and sea ice concentrations according to the Atmospheric Model Intercomparison Project (AMIP) protocol. 
%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.90\linewidth]{./figures/Fig5-methods.pdf}
    \caption{The PCNN-GCM framework. Panels(a) and(b) show the conventional subgrid parametrization and super parametrization approaches, respectively; panel(c) highlights the DL parametrization concept, and panel(d) details the internal architecture of CondensNet; panel(e) is the host GCM. The host GCM plus CondensNet form the PCNN-GCM framework.}
\label{fig:methods}
\end{figure}
%
Traditional GCMs like CAM use subgrid parametrization based on empirical models to represent cloud and convective processes (Figure~\ref{fig:methods}a), which can introduce significant uncertainties. 
The GCM using super parametrization, like SPCAM~\cite{khairoutdinov2001cloud}, mitigates this issue by embedding a high-resolution cloud-resolving model (CRM) within each coarse grid cell (Figure~\ref{fig:methods}b). 
In our study, the two-dimensional CRM of SPCAM consists of 32 grid points in the zonal direction and shares 30 vertical levels with the host model dynamics driven by CAM5.2. 
The host GCM includes all model components except for the parametrizations, namely: the dynamical core, the land model (CLM4.0), and the sea surface temperatures. 
Consequently, SPCAM, CAM5.2, and the hybrid modeling framework share identical host GCM components and simulation data coupling workflows. 

The host GCM provides input variables including large-scale state variables such as water vapor $Q$, temperature $T$, surface pressure $P_{\mathrm{s}}$, and top-of-atmosphere solar insolation $Solin$. 
In addition, large-scale forcing variables such as water vapor forcing $\mathrm{d} Q_{\mathrm{l.s.}}$ and temperature forcing $\mathrm{d} T_{\mathrm{l.s.}}$ are supplied to further enhance the model’s predictive capability. 
CondensNet, our DL parametrization, inherits these input variables and returns predictions of water vapor tendency $\mathrm{d} Q$ and dry-static-energy tendency $\mathrm{d} s$ at each vertical level, along with predictions of direct and diffuse downwelling solar radiation fluxes to drive the coupled land surface model.

The complete list of inputs and outputs is provided in Table~\ref{tab:baselinevars}.

Our new DL parametrization, namely the \textbf{CondensNet} model, consists of two neural networks, that have different tasks, and that are integrated together, as depicted in Figure~\ref{fig:methods}d. 
These are:
%
\begin{itemize}
    \item \textbf{BasicNet}. Tasked to predict basic tendencies of water vapor ($\mathrm{d} Q$) and dry-static-energy ($\mathrm{d} s$), capturing fundamental cloud physics. Here, we use the ResMLP model from ~\cite{wang2022stable}) as a basic model to explore the impact of ConCorrNet on stability in a more intuitive and controllable way.
    
    \item \textbf{Condensation Correction Network (ConCorrNet)}. ConCorrNet is designed to correct BasicNet's predictions adaptively—thereby enforcing physical constraints associated with water vapor saturation—and, unlike methods that penalize non-physical predictions via the loss function or post-processing, it operates as an independent neural network that computes explicit correction terms and applies them selectively.
\end{itemize}
%
CondensNet predicts physically constrained tendencies of water vapor ($\mathrm{d} Q$) and dry-static-energy ($\mathrm{d} s$) that comply with the saturation adjustment mechanism, while the prediction of radiative fluxes remains untouched (i.e., not corrected), as depicted in Figure~\ref{fig:methods}, panel d.

In particular, we first employ a humidity detection module to identify grid points where the relative humidity ($rh$), defined with respect to liquid water, exceeds 100\%.
This process results in the creation of a humidity mask, ($\mathrm{Mask}_{\text{h}}$):
%
\begin{align}
  \mathrm{Mask}_{\text{h}}(\mathrm{lon, lat, lev}) & = 
    \begin{cases} 1, & \text{if} \; rh > 100\% \\[-0.5em] 
      0, & \text{otherwise} 
    \end{cases}
\end{align}
%
where lon, lat, and lev represent the longitude, latitude, and vertical level indices of the grid points. We use $\mathrm{Mask}_{\text{h}}$ to mark regions where condensation is likely to occur; this marking directs ConCorrNet's attention to these sensitive regions, but does not automatically enforce a correction. 
Whether a correction is applied depends on ConCorrNet’s adaptive learning from SPCAM data (i.e., the labels) and its subsequent predictions during simulation.

Next, ConCorrNet computes the condensation correction terms $\mathrm{d} Q_{\text{fix}}$ and $\mathrm{d} s_{\text{fix}}$ as follows:
%
\begin{subequations}
  \begin{align}    
    \mathrm{d} Q_{\text{fix}} & = \frac{Q_v - Q_{\mathrm{cond}}}{\Delta t} \label{eq:sub1} \\
    \mathrm{d} s_{\text{fix}} & = L_v \, \mathrm{d} Q_{\text{fix}} \label{eq:sub2} % \\ 
    % \text{with} \;\;\; Q_v^\prime & = Q_v - Q_{\mathrm{fix}}
  \end{align}
\end{subequations}
%
where $Q_v$ is the predicted water vapor mixing ratio, $Q_{\mathrm{cond}}$ is the mixing ratio at condensation, $\Delta t$ is the simulation time step, and $L_v$ is the latent heat of condensation. These correction terms are then applied selectively using the humidity mask $\mathrm{Mask}_{\text{h}}$:
% are predicted by ConCorrNet and combined with the humidity mask to constrain the unconstrained predictions, d$Q$ and d$s$, from the pre-trained BasicNet model, resulting in the final predictions of CondensNet:
%
\begin{subequations}
  \begin{align}
    \mathrm{d} Q_{\text{fixed}} & = \mathrm{d} Q - \mathrm{Mask}_{\text{h}} \odot \mathrm{d} Q_{\text{fix}} \label{subeq:dQ} \\
    \mathrm{d} s_{\text{fixed}} & = \mathrm{d} s + \mathrm{Mask}_{\text{h}} \odot \mathrm{d} s_{\text{fix}} \label{subeq:ds},
  \end{align}
  \label{eq:qv_nn_cond}
\end{subequations}
%
where $\odot$ denotes element-wise multiplication. 
This active correction mechanism ensures that when the predicted water vapor mixing ratio exceeds the condensation threshold, the excess water vapor is appropriately condensed according to the saturation adjustment mechanism.

% In Equation~\eqref{eq:qv_nn_cond}, the tendencies $\mathrm{d} Q_{\text{fix}}$ and $\mathrm{d} s_{\text{fix}}$ are computed as
%
% \begin{subequations}
%   \begin{align}    
%     \mathrm{d} Q_{\text{fix}} & = \frac{Q_v - Q_{\mathrm{cond}}}{\Delta t} \label{eq:sub1} \\
%     \mathrm{d} s_{\text{fix}} & = L_v \, \mathrm{d} Q_{\text{fix}} \label{eq:sub2} % \\ 
%     % \text{with} \;\;\; Q_v^\prime & = Q_v - Q_{\mathrm{fix}}
%   \end{align}
% \end{subequations}
%
% where $\Delta t$ is the simulation time step, $L_v$ is the latent heat of condensation, $Q_v$ is the water vapor mixing ratio, $Q_{\mathrm{cond}}$ is the mixing ratio at condensation, and $Q_{\text{fix}}$ is the amount of water vapor condensed.

Water vapor condensation is triggered when the local relative humidity ($rh$) exceeds 100\%, leading to the formation of liquid droplets or ice crystals. 
Generally $Q_{\mathrm{cond}} \geq Q^\ast$, where $Q^\ast$ is the saturation mixing ratio, that represents the water vapor content at this threshold and is commonly calculated as:
%
\begin{align}
\label{eq:q_ast}
    Q^\ast = \frac{R_d\, e^\ast}{R_v\,(p-e^\ast)} \approx \frac{0.622e^\ast}{p}.
\end{align}
%
In Equation~\ref{eq:q_ast}, $R_d$ and $R_v$ are the specific gas constants for dry air and water vapor, respectively, $p$ is the atmospheric pressure, and $e^\ast$ is the saturation vapor pressure at temperature $T$, calculated using the Goff–Gratch equation \cite{goff1946low}.

While ideally any excess water vapor above $Q^\ast$ would condense, in practice the process is influenced by additional factors such as aerosols and existing cloud particles.
% Ideally, any excess water vapor beyond $q^\ast$ condenses, but in reality, condensation depends on factors like aerosols and existing cloud particles. 

Our CondCorrNet model of CondensNet adaptively ensures that when the water vapor mixing ratio exceeds the condensation threshold, the corresponding excess is condensed appropriately—with both the occurrence and the magnitude of condensation determined by the network’s learning of the labels, ensuring that the physical constraint is imposed in a data-driven, self-regulating manner.
% Our CondCorrNet model ensures that when the predicted water vapor mixing ratio exceeds the condensation threshold, the excess water vapor is condensed appropriately, thanks to Equation~\eqref{eq:qv_nn_cond}.



\subsubsection{Dataset and training details}
\label{app:training}

CondensNet uses SPCAM simulation data for training. The specific inputs and outputs are listed in Table~\ref{tab:baselinevars}, including 30 vertical levels of specific humidity $Q$, temperature $T$, large-scale water vapor tendency d$Q_{\mathrm{l.s.}}$, large-scale temperature tendency d$T_{\mathrm{l.s.}}$, as well as single-level surface pressure $P_{\mathrm{s}}$ and single-level incoming solar radiation $Solin$.

The output variables are the corresponding tendencies of moisture~$\mathrm{d} Q$ and dry-static-energy~$\mathrm{d} s$ at each vertical level (30 in total), as well as the four radiation fluxes ($SOLS$, $SOLL$, $SOLSD$, and $SOLLD$) in which reach to surface. 

Notably, in CondensNet, following the traditional column-based parametrization design in GCMs, each neural network instance processes a single atmospheric column independently. During training, column samples from different spatial locations are randomly shuffled, as the network only needs to learn the vertical physical processes within individual columns. When coupled with the host GCM, while CondensNet instances operate independently for each grid point in each physics time step, columns exchange mass, momentum, and energy through dynamics, represented by the large-scale tendencies (input variables $\mathrm{d} Q_{\mathrm{l.s.}}$ and $\mathrm{d} T_{\mathrm{l.s.}}$). This design preserves both the original high parallel efficiency in parametrization and the essential horizontal coupling in dynamics. 

Table~\ref{tab:baselinevars} shows the input and output variables of CondensNet, including their physical dimensions and units. The inputs consist of vertical profiles of atmospheric state variables ($Q$, $T$), large-scale tendencies ($\mathrm{d} Q_{\mathrm{l.s.}}$, $\mathrm{d} T_{\mathrm{l.s.}}$), and surface conditions ($P_{\mathrm{s}}$, $Solin$). The outputs include physical tendencies of water vapor and dry-static-energy at each vertical level, along with surface radiation fluxes.
%
\begin{table}[h]
\small
\centering
\caption{Inputs and outputs of the CondensNet DL parametrization.}
\begin{tabular}{lccc}
\toprule
\textbf{Inputs} & Lev & lon & lat \\
\midrule
Specific humidity $Q$ [kg/kg] & 30 & 144 & 96 \\
Temperature $T$ [K] & 30 & 144 & 96\\
Large-scale water vapor tendency $\mathrm{d} Q_{\mathrm{l.s.}}$ [kg/kg/s] & 30 & 144 & 96\\
Large-scale temperature tendency $\mathrm{d} T_{\mathrm{l.s.}}$ [K/s] & 30 & 144 & 96\\
Surface pressure $P_{\mathrm{s}}$ [Pa] & 1& 144 & 96 \\
Incoming solar radiation $Solin$ [W/m$^\text{2}$] & 1 & 144 & 96\\
\midrule
\textbf{Outputs} &  Lev & lon & lat\\
\midrule
Water vapor tendency $\mathrm{d} Q$ [kg/kg/s] & 30  & 144 & 96  \\
dry-static-energy tendency $\mathrm{d} s$ [K/s] & 30  & 144 & 96  \\
Shortwave heating rate $SOLS$ [W/m$^\text{2}$] & 1  & 144 & 96  \\
Longwave heating rate $SOLL$ [W/m$^\text{2}$] & 1  & 144 & 96  \\
Surface downwelling shortwave radiation $SOLSD$ [W/m$^\text{2}$] & 1  & 144 & 96  \\
Surface downwelling longwave radiation $SOLLD$ [W/m$^\text{2}$] & 1 & 144 & 96  \\
\bottomrule
\end{tabular}
\label{tab:baselinevars}
\end{table}
%

The basic neural networks, BasicNet, is a pre-trained residual multilayer perceptron (i.e., that predicts basic tendencies of water vapor ($\mathrm{d} Q$) and dry-static-energy ($\mathrm{d} s$). 
It comprises 7 residual blocks (14 layers total) and 2 separate ResMLP modules—one for predicting $\mathrm{d} Q$ and one for $\mathrm{d} s$—each with 512 neurons in hidden layers and ReLU activations (effectively yielding 1024 neurons in total).

The condensation correction network (ConCorrNet) is also a residual multilayer perceptron designed to adjust the predictions of BasicNet to enforce physical constraints related to water vapor saturation.
ConCorrNet architecture includes 6 residual blocks, each containing 2 fully connected layers with 512 neurons, resulting in a total depth of 12 layers. We selected the sigmoid activation function based on its superior convergence performance observed in preliminary experiments.

During the fine-tuning of CondensNet, we freeze the parameters of the pre-trained BasicNet and train the ConCorrNet. 
Specifically, we use BasicNet configurations whose simulations crashed in order to test the condensation correction and ensure that the final predictions adhere to the physical constraints imposed. 
To this end, we defined two loss functions:
%
\begin{enumerate}
%
\item \textbf{Overall Loss ($L_{\text{CondensNet}}$)}.
%
This loss measures the difference between CondensNet final predictions and the true values from SPCAM simulation data
%
\begin{equation}
\begin{aligned}
L_{\text{CondensNet}} = \frac{1}{N} \sum_{i=1}^{N} \left(\hat{y}_{\text{fixed}} - y_{\text{label}} \right)^2
\end{aligned}
\label{eq:CondensNet_loss},
\end{equation}
%
where $N$ is the number of samples, $y_{\text{label}}$ represents the true values, and $\hat{y}_{\text{fixed}}$ are the final predictions of CondensNet after applying the condensation correction, i.e., $\mathrm{d} Q_{\text{fixed}}$ and $\mathrm{d}s_{\text{fixed}}$ from Equation~\ref{eq:qv_nn_cond}.
%
\item \textbf{Condensation Correction Loss ($L_{\text{ConCorrNet}}$)}.
%
This loss focuses on the condensation correction terms predicted by ConCorrNet:
%
\begin{equation}
  \begin{aligned}
    L_{\text{ConCorrNet}} = \frac{1}{N} \sum_{i=1}^{N} \text{Mask}_{\text{h}} \odot \left[\hat{y}_{\text{fix}} - (\hat{y}_{\text{fixed}} - y_{\text{label}}) \right]^2
  \end{aligned}
  \label{eq:ConCorrNet_loss},
\end{equation}
%
where $\hat{y}_{\text{fix}}$ are the condensation correction terms, $\text{Mask}_{\text{h}}$ is a mask function applied to focus the loss on relevant regions, and $\odot$ denotes element-wise multiplication.
%
\end{enumerate}
%
The \textbf{Overall Loss} updates the parameters of both ResMLP and ConCorrNet, ensuring that the combined model predictions match the SPCAM data.
The \textbf{Condensation Correction Loss} updates only the parameters of ConCorrNet, allowing it to focus on learning the necessary oversaturation corrections without affecting the BasicNet.
By optimizing both losses simultaneously, CondensNet effectively learns the necessary physical constraints,  resulting in predictions consistent with its learning target (i.e., SPCAM data).

The specific hyperparameters used during training for the results presented in this work are listed in Table~\ref{tab:hyperparameter-fine-tune}, for both BasicNet and ConCorrNet.
%
\begin{table}[h]
\centering
\caption{Hyperparameter settings for training CondensNet (BasicNet + ConCorrNet).}
\begin{tabular}{lll}
\toprule
Hyperparameter                & BasicNet         & ConCorrNet       \\
\midrule
Activation function           & Relu             & Sigmoid          \\
Training epochs               & 50               & 120              \\
Number of residual blocks     & 7                & 6                \\
Learning rate (initial)       & 0.001            & 0.00075          \\
Learning rate schedule        & Cosine annealing & Cosine annealing \\
Hidden layer size             & 512 neurons      & 512 neurons      \\
Optimizer                     & Adam             & SGD              \\
Batch size                    & 1024             & 768              \\
\bottomrule
\end{tabular}
\label{tab:hyperparameter-fine-tune}
\end{table}
%
The model was implemented using PyTorch and trained on multiple GPUs to accelerate computation. 
We used standard techniques such as data normalization and weight initialization to enhance training stability. 
Early stopping and model checkpointing were employed to prevent overfitting.
The code is feely available at~\href{https://github.com/MathEXLab/PCNN-GCM}{https://github.com/MathEXLab/PCNN-GCM}.



\subsection{Post-processing and error metrics}

\subsubsection{Means}
\label{sec:means}

For variables with vertical distribution (temperature, wind speed, specific humidity), the zonal mean at each pressure level is given by
%
\begin{equation}
    \overline{X}_{\mathrm{zonal}}(\phi,p) \;=\; \frac{1}{N_{\lambda}} \sum_{i=1}^{N_{\lambda}} X(\lambda_i,\phi,p),
     \label{eq:zonal-mean}
\end{equation}
%
where $N_{\lambda}$ is the number of longitudinal grid points, $\lambda_i$ is the longitude at grid point $i$, $\phi$ is latitude, and $p$ is pressure level. 
For surface or near-surface variables (precipitation, 10m wind speed), the horizontal mean is given by
%
\begin{equation}
    \overline{Y}_{\mathrm{horizontal}} \;=\; \frac{1}{N_{\lambda}N_{\phi}} \sum_{j=1}^{N_{\phi}}\sum_{i=1}^{N_{\lambda}} Y(\lambda_i,\phi_j)w(\phi_j),
    \label{eq:horizontal-mean}
\end{equation}
%
where $w(\phi_j)$ is the latitudinal weight factor. The climatological means are then obtained by averaging these spatial means over the analysis period
%
\begin{equation}
    \overline{X}_{\mathrm{clim}} \;=\; \frac{1}{Y}\sum_{y=1}^Y X_{m,y},
    \label{eq:clim-mean}
\end{equation}
%
where $Y$ is the total number of years in the analysis period, $X_{m,y}$ represents the monthly mean for month $m$ in year $y$.



\subsubsection{Error metrics}
\label{sec:errors}

Once the means introduced in section~\ref{sec:means} are obtained, we use different error metrics to asses the performance of PCNN-GCM against NN-GCM and CAM5, using as a reference (i.e., ground truth) SPCAM. In particular, we use the \textbf{pattern difference}
%
\begin{equation}
    \mathrm{diff}(\phi,\lambda,p) = X_{\mathrm{model}}(\phi,\lambda,p) - X_{\mathrm{SPCAM}}(\phi,\lambda,p)
    \label{eq:pattern-diff}
\end{equation}
where $X_{\mathrm{model}}$ and $X_{\mathrm{SPCAM}}$ represent the climatological means from a given model and SPCAM respectively, the \textbf{weighted root mean squared error} for variables with vertical distribution
%
\begin{equation}
    \mathrm{RMSE}(p) \;=\; \sqrt{\frac{\sum_{j=1}^{N_{\phi}}\sum_{i=1}^{N_{\lambda}} [X_1(\lambda_i,\phi_j,p) - X_2(\lambda_i,\phi_j,p)]^2 w(\phi_j)}{\sum_{j=1}^{N_{\phi}}w(\phi_j)}}
\label{eq:rmse}
\end{equation}
%
where $X_1$ and $X_2$ represent the climatological means from two different models (for surface variables, the same formula applies without the pressure level dependency), and the \textbf{coefficient of determination}
(for surface variables, the same formula applies without the pressure level dependency), and the \textbf{coefficient of determination}
%
\begin{equation}
    R^2 = 1 - \frac{\sum_{i=1}^N \bigl(X_i^{\mathrm{model}} - X_i^{\mathrm{SPCAM}}\bigr)^2}{\sum_{i=1}^N \bigl(X_i^{\mathrm{SPCAM}} - \overline{X}_{\mathrm{SPCAM}}\bigr)^2}
\label{eq:r2}
\end{equation}
%
where $N$ is the total number of samples, $X_i^{\mathrm{model}}$ and $X_i^{\mathrm{SPCAM}}$ are the values at sample point $i$ for a given model and SPCAM respectively, and $\overline{X}{\mathrm{SPCAM}}$ is the mean of SPCAM values over all samples.

In Equations~\eqref{eq:pattern-diff}, \eqref{eq:rmse}, and \eqref{eq:r2}, $X_{\mathrm{model}}$ correspond to the model being evaluated (i.e., PCNN-GCM, NN-GCM, and CAM5), while $X_{\mathrm{SPCAM}}$ corresponds to the SPCAM reference (i.e., ground truth).



\backmatter

%% ACKNOWLEDGEMNTS
% \bmhead{Acknowledgements}
% Acknowledgements are not compulsory. 
% Where included they should be brief. 
% Grant or contribution numbers may be acknowledged.

%% BIBLIOGRAPHY
\bibliography{sn-bibliography}


\appendix
\section*{Supplementary Information}

\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{0} % Reset table counter

\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0} % Reset figure counter


\section{Additional results}
\label{si:additional-results}
We show additional detailed results in terms of key variables, namely wind and temperature (section~\ref{si:additional-key-thermodynamics}), precipitation (section~\ref{si:additional-results-precipitation}), and climate variability (section~\ref{si:additional-results-climate-variability}). 
These complement the results shown in the main text, and more specifically in section~\ref{sec:results}.



\subsection{Wind and temperature}
\label{si:additional-key-thermodynamics}

First, we show the results for the vertical profiles of two key variables, namely wind speed and temperature. 
These are depicted in Figure~\ref{fig:FigS1}a--d for wind speed and in Figure~\ref{fig:FigS1}h--k for temperature, and they correspond to the annual means in the period 1999--2003, on a latitude-height cross-section (for more details on how these are computed, see Methods, section~\ref{sec:means}). 
We also show the difference, calculated using Equation~\ref{eq:pattern-diff} in Methods (section~\ref{sec:errors}), between CAM5, NN-GCM, and PCNN-GCM with respect to the SPCAM reference (Figure~\ref{fig:FigS1}e--g for wind speed and Figure~\ref{fig:FigS1}m--o for temperature), where we report the associated RMSE errors in the title of each subfigure.
%
\begin{figure}[H]
  \centering
  \includegraphics[width=1.\linewidth]{./figures/FigS1.pdf}
    \caption{Vertical profiles of wind speed (a--d) and temperature (h--k), for SPCAM, CAM5, NN-GCM, and PCNN-GCM, respectively, and corresponding differences with respect to SPCAM reference (e--g, for wind speed, and m--o, for temperature). 
    The fields are annual means (1998-2002) on a latitude-height cross-section, computed as reported in Methods~\ref{sec:means}, and their differences are computed as in Equation~\ref{eq:pattern-diff}, reported in Methods~\ref{sec:errors}. 
    We also provide error metrics, namely RMSE, for all subfigures related to differences (i.e., e--g for wind speed and m--o for temperature).}
  \label{fig:FigS1}
\end{figure}
%
In terms of vertical wind speed profile, the overall error obtained with PCNN-GCM (Figure~\ref{fig:FigS1}a) improves the previous results obtained with NN-GCM (Figure~\ref{fig:FigS1}f), and it is comparable to CAM5 (Figure~\ref{fig:FigS1}e), albeit slightly higher. 
We note that PCNN-GCM is able to capture the wind speed vertical profiles of SPCAM, with negative biases (i.e., weaker wind speed) manifesting between 400hPa and 200hPa in the tropics and in the latitude band [60S--90S] (Figure~\ref{fig:FigS1}g). 
These negative biases are also present in NN-GCM, but they are more prominent (Figure~\ref{fig:FigS1}f). 
NN-GCM additionally presents large positive biases (i.e., stronger wind speed) above 200hPa that PCNN-GCM is able to address. 
We finally note that CAM5 also presents a negative bias in the latitude band [60S--90S] (Figure~\ref{fig:FigS1}e), while having positive biases between 400hPa and 200hPa in the tropics (i.e., the opposite of what observed for NN-GCM and PCNN-GCM).

In terms of vertical temperature profile, PCNN-GCM successfully reproduces SPCAM results, albeit with a slight overall underestimation (Figure~\ref{fig:FigS1}o). 
Notably, at the top of the atmosphere over the Antarctic region ($\sim$ 90°S), PCNN-GCM shows a slight positive bias relative to SPCAM.
In contrast, NN-GCM simulates a warmer tropopause in the tropics (30°N–30°S; Figure~\ref{fig:FigS1}n), and exhibits a cold bias above 200 hPa over the Arctic ($\sim$ 90°N) and a warm bias below 200 hPa in Antarctica ($\sim$ 90°S). 
There is also a slight warm bias at the top of the equator and a cold bias elsewhere. 
By correcting the atmospheric water vapor content, PCNN-GCM substantially improves the temperature biases of NN-GCM, particularly in the tropical tropopause and high-latitude regions.
Compared to PCNN-GCM, CAM5 temperature biases are significantly more pronounced (Figure~\ref{fig:FigS1}m). 
%
\begin{figure}[H]
  \centering
  \includegraphics[width=1.0\linewidth]{./figures/FigS2.pdf}
    \caption{Horizontal fields of 10m wind speed (a--d) and 2m temperature (h--k), for SPCAM, CAM5, NN-GCM, and PCNN-GCM, respectively, and corresponding differences with respect to SPCAM reference (e--g, for wind speed, and m--o, for temperature).
    The fields are annual means (1998-2002) computed as reported in Methods~\ref{sec:means}, and their differences are computed as in Equation~\ref{eq:pattern-diff}, reported in Methods~\ref{sec:errors}. We also provide error metrics, namely RMSE, for all subfigures related to differences (i.e., e--g for 10m wind speed and m--o for 2m temperature).}
  \label{fig:FigS2}
\end{figure}
%
Second, we show the results for the horizontal fields of 10m wind speed, and 2m temperature. 
These are depicted in Figure~\ref{fig:FigS2}a--d for 10m wind speed and in Figure~\ref{fig:FigS2}h--k for 2m temperature, and they correspond to the annual means in the period 1998--2002 (for more details on how these are computed, see Methods, section~\ref{sec:means}). 
We also show the difference, calculated using Equation~\ref{eq:pattern-diff} in Methods (section~\ref{sec:errors}), between CAM5, NN-GCM, and PCNN-GCM with respect to the SPCAM reference (Figure~\ref{fig:FigS2}e--g for 10m wind speed and Figure~\ref{fig:FigS2}m--o for 2m temperature), where also report the associated RMSE errors in the title of each subfigure.
In terms of 10m wind-speed, PCNN-GCM (Figure~\ref{fig:FigS2}g) reduces NN-GCM (Figure~\ref{fig:FigS2}f) underestimation in the equatorial Pacific (150°E–150°W; 0–15°N) and mid-latitude Pacific (150°E–180°; 30–60°N). 
NN-GCM and PCNN-GCM substantially reduce CAM5 (Figure~\ref{fig:FigS2}e) overestimation of 10m wind speed in the equatorial Pacific (180°–120°W; 15°S-15°N). 
On the other hand, they underestimate the 10m wind speed over Antarctica, although PCNN-GCM exhibits a smaller negative bias than NN-GCM.
PCNN-GCM (Figure~\ref{fig:FigS2}o) reduces NN-GCM (Figure~\ref{fig:FigS2}n) overestimation of 2m temperature across the mid-and high latitudes of the Northern Hemisphere (45°N–90°N). 
It also mitigates NN-GCM’s substantial warm bias over Antarctica, although PCNN-GCM also overestimates the 2m temperature in this region.

Overall, the errors obtained with PCNN-GCM significantly improve (or are in par with) NN-GCM across all variables considered, showing how the physical constraints imposed not only provides long-term stability, but they are also beneficial for accuracy.




\subsection{Precipitation}
\label{si:additional-results-precipitation}

In Figure~\ref{fig:FigS3}, we show both the probability density functions of daily precipitation intensity (Figure~\ref{fig:FigS3}a), as well as the zonally-averaged precipitation rate (Figure~\ref{fig:FigS3}b--g) for the years 1999-2003 for the region 30°S-30°N.
For all results depicted in Figure~\ref{fig:FigS3}, we consider the period 1998-2002, and the precipitation intensity intervals for obtaining the probability distribution in Figure~\ref{fig:FigS3}a are set at 1mm/day.

Figure~\ref{fig:FigS3}a shows how CAM5 (red line) significantly underestimates the probability of heavy precipitation events (exceeding 20 mm/day) but overestimates the probability of moderate precipitation (2-20 mm/day), with an unrealistic probability peak near 10 mm/day~\cite{holloway2012precipitation}. 
Compared to CAM5 (red line), NN-GCM (blue line) and PCNN-GCM (green line)  probability distributions are closer to those of SPCAM, with a notably enhanced probability estimation of heavy precipitation events, with PCNN-GCM aligning closer to SPCAM (black line). 

Figure~\ref{fig:FigS3}b--g show the multi-year (1999-2003) mean of zonally-averaged precipitation for the whole year (Figure~\ref{fig:FigS3}b,c), for the DJF -- December-January-February -- season (Figure~\ref{fig:FigS3}d,e) and for the JJA -- June-July-August -- season (Figure~\ref{fig:FigS3}f,g), where  the left figures represent the global average and the right figures represent the land global average.
%
\begin{figure}[H]
  \centering
  \includegraphics[width=1.0\linewidth]{./figures/FigS3.pdf}
    \caption{Global precipitation distribution (a), and zonally-averaged precipitation rate in for the annual (b,c), summer (d,e), and winter (f,g) periods, based on the average from 1998 to 2002. Units of all plots are in mm/day.}
  \label{fig:FigS3}
\end{figure}
%
NN-GCM and PCNN-GCM have good simulation skills in the tropical regions (where the land proportion is 1), and the tropical land precipitation rate is similar to the annual average and Northern Hemisphere summer average of SPCAM. 
Compared to NN-GCM, PCNN-GCM simulates a slightly lower precipitation over tropical land in the Northern Hemisphere summer (Figure~\ref{fig:FigS3}g). 
According to the study by Kooperman et al.,~\cite{kooperman2016robust}, due to the super-parametrization (i.e., CRM) being able to better characterize shallow and deep convection processes and improve the intraseasonal variability of convection, SPCAM better predicts the Asian and African monsoon activities, thus simulating the land precipitation in these regions more accurately. 
As emulators of SPCAM, NN-GCM and PCNN-GCM have good learning and reproduction capabilities for SPCAM and inherit the advantages of SPCAM. 
In contrast, CAM5 uses traditional parametrization to describe convection processes, and its precipitation simulation performance is lower than that of SPCAM.

From the perspective of the multi-year average precipitation rate of the Northern Hemisphere winter zonal average (Figure \ref{fig:FigS3}e), compared to SPCAM, NN-GCM, PCNN-GCM and CAM5 all have biases in simulating the land average precipitation rate between 0°-30°S. 
Among them, the precipitation rate and distribution pattern simulated by NN-GCM are similar to those of SPCAM, but there are biases in the distribution location; the distribution patterns simulated by PCNN-GCM and CAM5 are similar, and the intensity simulated by PCNN-GCM is slightly higher than that of CAM5, but lower than that of NN-GCM.



\subsection{Climate variability: Madden-Julian Oscillation}
\label{si:additional-results-climate-variability}

Super-parametrization incorporates higher spatial and temporal resolution, enabling to better capture high-frequency atmospheric variability. 
PCNN-GCM learns from the SPCAM super-parametrization. 
Hence, it should provide better performance than e.g., CAM5, in capturing high-frequency atmospheric variability. 
To asses this hypothesis, we evaluate the performance of PCNN-GCM on the the Madden-Julian Oscillation (MJO), the dominant mode of intraseasonal variability in the tropics.
The MJO plays a significant role in climate prediction, serving as the foundation for seasonal forecasts of extreme events such as extreme rainfall and tropical cyclones~\cite{wang2019diversity}. 
A key characteristic of the MJO is the eastward propagation of deep convective structures along the equator, with a time scale of 20-100 days \cite{wheeler1999convectively}. 
Convective parametrizations significantly affect the ability of models to correctly simulate the MJO~\cite{madden1972description}, especially in terms of periodicity and eastward propagation characteristics. 

We assess the simulation performance of PCNN-GCM by examining whether our model is able to correctly capture the periodicity and eastward propagation features of the MJO.

Figure~\ref{fig:FigS4} shows that wavenumber-frequency spectrum analysis (Figure~\ref{fig:FigS4}a--d), and the lag-correlation analysis (Figure~\ref{fig:FigS4}e--h). 
These are obtained applying:
%
\begin{enumerate}
    \item a band-pass filter to the daily anomalies (precipitation and 200-hPa zonal winds) between 20-100 days;
    \item a meridional averaging from 10°S to 10°N on data in the reference time period 1999-2003, during Northern Hemisphere winter, and 
    \item a correlation calculation with reference to the equatorial Eastern Indian Ocean (80°E-100°E, 10°S-10°N).
\end{enumerate}
%

The wavenumber-frequency spectrum analysis (Figure~\ref{fig:FigS4}a--d) reveals that NN-GCM and PCNN-GCM successfully capture the key MJO characteristics observed in SPCAM. 
The coefficients of determination ($R^2$) for NN-GCM (0.51) and PCNN-GCM (0.55) significantly exceed CAM5's performance (0.40), indicating better accuracy for tropical atmospheric intraseasonal variability.

The lag-correlation analysis (Figure~\ref{fig:FigS4}e--h) demonstrates that both NN-GCM and PCNN-GCM effectively reproduce the eastward propagation of MJO convection from the Indian Ocean across the Maritime Continent to the Pacific Ocean, closely matching SPCAM's behavior. 
In contrast, CAM5 shows no distinct eastward propagation characteristics.
In Figure~\ref{fig:FigS4}e--h, shaded areas represent precipitation anomaly correlations, while contour lines indicate zonal wind anomaly correlations (dashed lines for negative correlations).
%
\begin{figure}[H]
  \centering
  \includegraphics[width=1.0\linewidth]{./figures/FigS4.pdf}
    \caption{Madden-Julian Oscillation. Wavenumber-frequency spectra of daily precipitation anomalies for SPCAM (a), CAM5 (b), NN-GCM (c), and PCNN-GCM (d) over the 10S-10N region during the Northern Hemisphere winter (1998-2002). Longitude-time evolution of the lagged correlations between the meridionally averaged (10S-10N) daily anomalies of precipitation and 200-hPa zonal winds for SPCAM (e), CAM5 (f), NN-GCM (g), and PCNN-GCM (h) during the Northern Hemisphere winter (1998-2002) and the mean conditions over the equatorial Eastern Indian Ocean (80E-100E, 10S-10N).}
\label{fig:FigS4}
\end{figure}
%
% \textcolor{-red}{Add final comment on performance of PCNN-GCM compared to others!}
Overall, the wavenumber–frequency spectrum and lag-correlation analyses confirm that both NN-GCM and PCNN-GCM effectively replicate the MJO’s 20–100-day variability and eastward propagation, outperforming CAM5. Although PCNN-GCM demonstrates superior performance, there remains a gap relative to SPCAM. Nonetheless, these findings underscore PCNN-GCM’s potential to capture intraseasonal atmospheric processes, offering a promising path toward more accurate climate forecasts of extreme events.

Table~\ref{tab:TabS1} presents three metrics to quantify MJO simulation performance: precipitation spectrum correlation with SPCAM ($R^2$), and maximum correlations of precipitation and 200-hPa zonal wind (U200) with the Eastern Indian Ocean (EIO) reference region. Both NN-GCM and PCNN-GCM models outperform CAM5, with PCNN-GCM achieving the best precipitation spectrum correlation (0.547), while NN-GCM shows stronger EIO correlations.
%
\begin{table}[]
    \centering
    \caption{MJO simulation metrics comparing against SPCAM. EIO correlations are calculated with respect to the Eastern Indian Ocean region (80°E-100°E, 10°S-10°N). Bold and underlined values indicate the best and second-best performance among CAM5, NN-GCM, and PCNN-GCM.}
    \begin{tabular}{l|cccc}
    \toprule
                &  CAM5   &  NN-GCM & PCNN-GCM          \\ 
    \midrule
    Precipitation Spectrum        & 0.397   & \underline{0.511}  & \textbf{0.547}    \\
    Precipitation-EIO Correlation & 0.101   & \textbf{0.256}     & \underline{0.229} \\
    U200-EIO Correlation          & -0.02   & \textbf{0.538}     & \underline{0.368} \\
    \bottomrule
    \end{tabular}
    \label{tab:TabS1}
\end{table}
%



\section{CondensNet: Baseline performance evaluation}
\label{si:baseline-results}

In this section, we further evaluate CondensNet through three key aspects: (i) one-step prediction accuracy, (ii) simulation stability, and (iii) physical consistency in water vapor correction.
For the one-step prediction accuracy evaluation, we use 10\% of the SPCAM simulation data (i.e., 1999--2000), and compare CondensNet performance against two baseline models, namely a residual multilayer perceptron (ResMLP) model without physical constraints that constitute the DL parametrization of NN-GCM~\cite{wang2022stable}, and the same ResMLP with post-processing constraints, referred to as ResMLP-rh.

The latter model, depicted in Figure~\ref{fig:FigS5}, was developed as part of an exploratory search for stability via physical constraints. 
This model applies a post-processing approach where an oversaturation correction module is added after the main model output, i.e., the ResMLP model. 
The correction module enforces a basic physical constraint: water vapor condensation only occurs when relative humidity reaches saturation (i.e., 100\%). 
This preliminary attempt at physical correction serves as an important baseline for comparing with our proposed CondensNet DL parametrization.
%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{./figures/FigS5.pdf}
    \caption{ResMLP with the post-processing physical constraint. For the oversaturation correction module, it will assume that water vapor (Q) will only condense when the relative humidity (rh) reaches 100\%, at which time $Q \ge Q_{\text{cond}}$}
    \label{fig:FigS5}
\end{figure}
%

In Tab.~\ref{tab:TabS2}, we show the comparison of CondensNet, ResMLP, and ResMLP-rh, in terms of one-step prediction accuracy and simulation stability. 
%
\begin{table}%[H]
  \centering
  \caption{Comprehensive evaluation of CondensNet against baseline models. a) shows the model fitting accuracy for physical tendencies. b) presents the simulation stability measured by pseudo-radiative forcing, where values closer to zero indicate better stability.}
  \begin{tabular}{llccc}
    \multicolumn{4}{l}{a) Model Fitting Performance ($R^2$)} \\
    \toprule
    Variable  & ResMLP & ResMLP-rh & CondensNet \\
    \midrule
    $\mathrm{d} Q$  & 0.8646 & 0.8327 & 0.8647 \\
    $\mathrm{d} s$  & 0.8782 & 0.7257 & 0.8788 \\
    \bottomrule\\
    \multicolumn{4}{l}{b) Simulation Stability (Pseudo-radiative forcing, $W/m^2$)} \\
    \toprule
    Model Instance & ResMLP & ResMLP-rh & CondensNet \\
    \midrule
    ResMLP 1 & 2.5248  & 0.02015  & 0.01407 \\
    ResMLP 2 & 9.7422  & -0.23308 & -0.03208 \\
    ResMLP 3 & 29.6325 & 0.14629  & 0.07629 \\
    ResMLP 4 & 9.1825  & 0.31890  & 0.21890 \\
    ResMLP 5 & 7.5865  & 0.25156  & 0.02156 \\
    ResMLP 6 & 26.9470 & 0.01190  & 0.03690 \\
    \midrule
    Reference Models & \multicolumn{3}{l}{SPCAM: 0.0081; Stable ResMLP\footnotemark: 0.0156} \\
    \bottomrule
  \end{tabular}
  \label{tab:TabS2}
\end{table}
\footnotetext{The stable model from ~\cite{wang2022stable}.}
%

In terms of one-step prediction accuracy (Table~\ref{tab:TabS2}a), CondensNet achieves comparable $R^2$ values to ResMLP for both water vapor tendencies ($\mathrm{d} Q$) and dry-static energy tendencies ($\mathrm{d} s$). 
ResMLP-rh, instead, shows reduced accuracy, particularly for $\mathrm{d} s$. 
Indeed, if we look at the vertical distribution of one-step prediction accuracy shown in Figure~\ref{fig:FigS6}, we observe that CondensNet closely follows ResMLP, whereas ResMLP-rh exhibits significant accuracy degradation in the mid- and lower-atmosphere.
%
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.75\linewidth]{./figures/FigS6.pdf}
    \caption{Vertical distribution of fitting performance ($R^2$) for physical variables across different models.}
    \label{fig:FigS6}
\end{figure}
%

In terms of simulation stability (Table~\ref{tab:TabS2}b), we examine six ResMLP models with test losses close to the stable ResMLP ($MSE_h < 290\,W^2/m^4$) but known to crash during simulation. 
The stability is quantified using pseudo-radiative forcing ($\kappa$), calculated as:
%
\begin{equation}
    \kappa = \frac{\sum_{i=1}^{T} \left( t_{i}-\bar{t} \right) \left( e_{i}-\bar{e} \right)}{\sum_{i=1}^{T} \left( t_{i}-\bar{t} \right)^{2}}
    \label{eq:pRF}
\end{equation}
%
where $t_i$ and $e_i$ represent the global mean total energy at time step $i$, with $\bar{t}$ and $\bar{e}$ being their respective means. 
As shown in Table~\ref{tab:TabS2}b, CondensNet achieves stability comparable to SPCAM, with $\kappa$ values close to zero. 
%For context, the radiative forcing of major greenhouse gases ($CO_2$, $CH_4$, and $N_{2}O$) is approximately $2.9\,W/m^2$~\cite{masson2021climate}.

These results demonstrate that CondensNet successfully combines accurate predictive performance with reliable simulation stability. 
It effectively learns convective representations from SPCAM data while maintaining physical consistency, particularly in water vapor condensation processes, crucial for coupled climate simulations.


% To evaluate the effect of water vapor on simulation stability, we analyzed the vertical profiles of water vapor for SPCAM and an unstable NN-GCM simulation using the ResMLP parametrization. Figure~\ref{fig:dq-gv} shows the water vapor tendencies at 500 hPa over maritime continents before the simulation collapse.

% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.85\linewidth]{./figures/pressure_Q.pdf}
%     \caption{Water vapor vertical profiles of SPCAM (dark green) and the unstable ResMLP simulation (dark red) at six snapshots prior to simulation crash.}
% \label{fig:dq-gv}
% \end{figure}

% The unstable simulation exhibits an anomalous increase in water vapor content in the middle and upper atmosphere as the simulation progresses, leading to instability. The condensation module effectively mitigates this issue, enhancing the stability of the simulation.
% %
% \begin{figure}[htbp]
%   \centering
%     \includegraphics[width=0.75\linewidth]{./figures/online-data_span.pdf}
%     \caption{Changes in the vertical distribution of water vapor with simulation time steps before NN-GCM crashed ($kg/kg$).}
%   \label{fig:online-data_span}
% \end{figure}
% %
% To assess the impact of the condensation module, we analyzed the relative humidity in a typical unstable NN-GCM simulation, a stable NN-GCM simulation, and SPCAM. Figure~\ref{fig:Q-rh} shows the vertical distribution of the zonal mean relative humidity over the first 5000 time steps.

% The unstable NN-GCM simulation exhibits significant oversaturation in the middle and upper troposphere (Figure~\ref{fig:Q-rh}c), leading to simulation instability. 
% The CondensNet of PCNN-GCM effectively reduces this oversaturation, aligning the relative humidity distribution more closely with SPCAM (Figure~\ref{fig:Q-rh}d).

%TC:endignore





\end{document}
