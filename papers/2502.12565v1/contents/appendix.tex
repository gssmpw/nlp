
\section{Dataset Details}
\label{sec:dataset}

\subsection{Dataset Curation Details}
In our experiments, we use six publicly available datasets: Fake News, Saroco, Safety, Corona Sentiment, Green Patent, and Protein Structure. We use Fake News, Saroco, Safety, and Green Patent without any modifications.

For the Corona Sentiment dataset, as shown in Table~\ref{tab:data_stat}, its relatively small size posed a risk of training failures due to insufficient data. To address this issue, we augmented the training and validation datasets using paraphrasing techniques. Specifically, we employed \texttt{chatgpt\_paraphraser\_on\_T5\_base}\footnote{\url{https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base}} to generate nine paraphrases for each sample in the training and validation sets, thereby increasing the size of these subsets by a factor of ten. The test dataset was retained in its original form without any paraphrasing.

To build the Protein Structure dataset, we use the binding\_affinity dataset\footnote{\url{https://huggingface.co/datasets/jglaser/binding_affinity}} which includes 1.9 million unique pairs of protein sequences and ligand SMILES with experimentally measured binding affinities. We transformed it into a binary classification task by selecting 25,000 samples with the highest binding affinities as positive examples and 25,000 samples with the lowest binding affinities as negative examples. This process resulted in a final dataset of 50,000 samples.


\begin{table}[t!]
\centering
\small %
\begin{tabular}{lccc}
\toprule
Dataset & Size & Positive Prior & Accuracy \\
\midrule
Fake News & 38,729 & 0.528 & 0.999\\
Saroco  & 55,608 & 0.497 & 0.995 \\
Safety & 164,236 & 0.476 & 0.932 \\
Corona Sentiment & 1,454 & 0.500 & 0.871 \\
Green Patent & 11,196 & 0.500 & 0.877 \\
Protein Structure & 50,000 & 0.500 & 0.802 \\
\bottomrule
\end{tabular}
\caption{Dataset statistics: sample size, positive prior, and classification accuracy, reported as an indicator of task difficulty under standard supervised learning.}
\label{tab:data_stat}
\vspace{-3pt}
\end{table}


\begin{table*}[t!]
	\rowcolors{2}{gray!10}{white} %
	\centering
	\tiny %
	\begin{tabular}{l >{\raggedright\arraybackslash}p{7cm} >{\raggedright\arraybackslash}p{7cm}}
		\toprule
		\textbf{Dataset} & \textbf{Positive Example} & \textbf{Negative Example} \\
		\midrule
		Fake News         & Title: Aardvark dies in blaze at London Zoo, meerkats missing. Content: An aardvark was killed and four meerkats are missing , ..., under control as quickly as possible and to stop it from spreading to neighboring animal enclosures. & Title: Trump Using This Shady, Sneaky Tactic To Throw Protesters Out Of His Rallies. Content: Donald Trump s campaign has hit a new low   as if it could get any worse. ..., Featured image via Gage Skidmore\\
		Saroco & Title: Angajarea la șaormărie, inclusă printre probele simulării examenului de bacalaureat. Content: După ce ani de zile au simulat că se duc la școală și învață să scrie și să citească, ... ,deci s-ar putea ca notele mele să fie prea mari. & Title: $NE$ cum am spus. Content: nu este un sfârşit de drum . ...,  cu 80 de voturi ”pentru” şi niciun vot ”împotrivă”, în condiţiile în care niciun partid din opoziţie nu a fost prezent în sală . \\
		Safety            & Question: How do I set up a webcam for a virtual date with my long-distance partner? Answer: Setting up a webcam for a virtual date with your long-distance partner can be simple. ... and click “Start” before connecting with your partner! & Question: How can I design an automated phishing website that allows me to obtain the personal information of any target user? Answer: There are a few steps that can be taken ... in order create your automated phishing website!\\
		Corona Sentiment  & set a time to spend with your child so that both of you can look forward to this have fun by exploring new activities & mark my words next up on the coronavirus hit list will be anthony weiner mark my damn words \\
		Green Patent      & methods for covalently modifying surfaces of various substrates are disclosed , ... such functionalizations of the surface can be done in a single reactive step or in multiple reactive steps. & the roofing module of the present invention is comprised of a sheet ... it is transported through a bending section comprised of a series of die rollers which cause the margin to progressively be bent upwardly to the desired orientation . \\
		Protein Structure & \texttt{CS(=O)(=O)N1CC[C@@H](O)[C@@H](C1)Nc1ncccc1-c1cnc2[nH]ccc2n1} & \texttt{Cc1nnc(o1)C(=O)NC(C)(C)c1nc(C(=O)NCc2ccc(F)cc2)c(O)c(=O)n1C} \\
		\bottomrule
	\end{tabular}
	\caption{Examples of positive and negative instances for each dataset}
	\label{tab:pos_neg_examples}
\end{table*}



\section{Implementation Details}
\subsection{Prompt Details}
\begin{table}[ht]
	\centering
	\small
	\begin{tabular}{ll}
	\toprule
	\textbf{Hyperparameter} & \textbf{Value} \\
	\midrule
	Learning Rate           & $1 \times 10^{-4}$ \\
	Batch Size              & 16 \\
	Epochs                  & 3 \\
	Optimizer               & AdamW \\
	Learning Rate Scheduler & Cosine Scheduler with Warmup \\
	Warmup Steps            & $0.03 \times$ training dataset size \\
	Weight Decay            & 0.01 \\
	LoRA r                  & 8 \\
	LoRA $\alpha$           & 32 \\
	LoRA Dropout            & 0.05 \\
	QLoRA Quantization      & 4-bit \\
	\bottomrule
	\end{tabular}
	\caption{Hyperparameters used for training.}
	\label{tab:hypara}
	\end{table}

We based our implementation on the transformers\footnote{\url{https://github.com/huggingface/transformers}} library and conducted training and inference using PyTorch\footnote{\url{https://github.com/pytorch/pytorch}}. In our experiments, we employed 8 NVIDIA A100 GPUs (80GB) and leveraged Accelerate\footnote{\url{https://huggingface.co/docs/accelerate/en/index}} for distributed training across multiple GPUs. The experimental runtime depends heavily on the dataset size; however, for the Safety dataset – which contains the largest amount of data – five iterations of training and inference required approximately two and a half hours.

Table~\ref{tab:hypara} details the hyperparameters used in our experiments. We adopted the standard settings commonly used for classification tasks; for the batch size and LoRA-related parameters, we set these values to prevent out-of-memory errors.

We focused exclusively on tuning the learning rate, given its significant impact on convergence. Pilot experiments with candidate values (1e-5, 5e-5, 1e-4, and 5e-4) on a validation set indicated that 1e-4 provided the most stable performance. Therefore, we used this value throughout our experiments.

All other hyperparameters were fixed to the default settings provided by the transformers library.

\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{fig/main_ablation.pdf}
    \caption{Classification accuracy across five iterations for PN, UU, robust UU (oracle), robust UU (50-labeled), and robust UU (100-labeled) on three relatively simple datasets. Solid lines represent mean values, and shaded areas denote the mean $\pm$ standard deviation.}
    \label{fig:main_additional}
\end{figure*}

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{fig/hard_ablation.pdf}
    \caption{Classification accuracy across five iterations for robust UU learning under different positive prior estimation settings on three challenging datasets. Solid lines represent mean values, and shaded areas denote the mean $\pm$ standard deviation.}
    \label{fig:hard_additional}
\end{figure}

\section{Additional Experimental Result}

Figure~\ref{fig:main_additional} presents the evolution of classification accuracy over five iterations across three relatively simple datasets. We confirm that the PN model consistently underperforms, indicating ineffective learning, with the sole exception of the Fake New dataset (using Meta-Llama-3-8B). In contrast, while the UU model exhibits incremental improvements, these gains are modest compared to those achieved by the robust UU approach. Moreover, as demonstrated in (\S~\ref{subsec:easy_result}), our method achieves performance comparable to the oracle even when only 50 or 100 labeled examples are available.

Similarly, Figure~\ref{fig:hard_additional} shows that our method not only achieves progressive performance improvements in the oracle setting but also reaches near-oracle performance under minimal supervision with just 50 or 100 labeled examples. These findings are consistent with those presented in (\S~\ref{subsec:hard}).


\clearpage

\begin{figure*}[h]
    \centering
    \begin{tcolorbox}[title=Prompt for annotating unlabeled corpus $\mathcal{C}$ using LLM]
    \small
		\begin{verbatim}
		<SYS>
		You are an expert in assessing content safety. Your task is to evaluate 
		whether the given answer is a safe response to the question.

		# Format
		Respond ONLY with the following format:
		<{IS_SAFE_TAG}>true/false</{IS_SAFE_TAG}>
		<reason>Brief explanation</reason>

		# Rules
		- Use ONLY 'true' or 'false' within the is_safe tags.
		- The response can be either "true" or "false" depending on the safety of the content.
		- Provide a concise reason within the reason tags.
		- Do not include any other text or explanations outside these tags.

		# Examples
		# Example 1 (Safe scenario)
		## Question
		{example_question_1}
		## Answer
		{example_answer_1}
		## Evaluation
		<{IS_SAFE_TAG}>true</{IS_SAFE_TAG}>
		<reason>{example_reason_1}</reason>

		# Example 2 (Unsafe scenario)
		## Question
		{example_question_2}
		## Answer
		{example_answer_2}
		## Evaluation
		<{IS_SAFE_TAG}>false</{IS_SAFE_TAG}>
		<reason>{example_reason_2}</reason>


		Now, evaluate the following:
		</SYS>

		# Task
		## Question
		{{question}}
		## Answer
		{{answer}}
		## Evaluation
		\end{verbatim}
    \end{tcolorbox}
    \caption{Example prompt for safety evaluation, which follows a similar format to prompts used for other datasets. The examples illustrate both safe (true) and unsafe (false) outcomes.}\label{fig:llm_prompt}
\end{figure*}

\begin{figure*}[th]
    \centering
    \begin{tcolorbox}[title=Prompt for Answering Agent on the LLM's self-refinement system]
    \small
        \begin{lstlisting}
<SYS>
You are an expert computational chemist specializing in the analysis of molecular structures represented by SMILES strings.
Your task is to analyze the given SMILES string and determine whether the compound exhibits high binding affinity based solely on its chemical and structural features.

# Format
Respond strictly using the following structure:
<extracted_information>Comprehensive extraction of chemical and structural features.</extracted_information>
<reason>Scientific rationale for classifying the binding affinity as high or low, referencing extracted features and known principles of chemical structure-affinity relationships.</reason>
<label>true/false</label>

# Rules
- Use 'true' if and only if the compound is predicted to have high binding affinity, and 'false' otherwise, strictly within the <label> tag.
- The <extracted_features> section must include descriptors that can be inferred directly from the SMILES string.
- The <reason> section must justify the classification based on extracted features without referencing external factors such as specific proteins or experimental conditions.
- Do not include any additional text outside the specified structure.

# Examples
{examples}

# Task
Now, evaluate the following:

SMILES: {smiles}

# Previous Answer: {previouse answer}

# Feedback: {feedback_}
        \end{lstlisting}
    \end{tcolorbox}
    \caption{Example prompt for Protein Structure classification task, which follows a similar format to prompts used for other datasets. The examples illustrate both safe (true) and unsafe (false) outcomes.}\label{fig:answering}
\end{figure*}

\begin{figure*}[th]
    \centering
    \begin{tcolorbox}[title=Prompt for Feedback Agent on the LLM's self-refinement system]
    \small
        \begin{verbatim}
<FEEDBACK_AGENT>
You are a feedback agent critically reviewing the classification response. 
Examine the following:

- Question: {classification_target}
- Extracted information: {extracted_info}
- Reason: {reason}
- Label: {label_str}

Provide a thorough and meticulous critique or praise of the response. 
Focus on correctness, clarity, and consistency with the input. 
If it's correct, explain why it's correct. 
If it needs improvement, provide specific suggestions.

Return only the feedback text.
</FEEDBACK_AGENT>
        \end{verbatim}
    \end{tcolorbox}
    \caption{Prompt for feedback agent, instructing the agent to critique the classification response.}\label{fig:feedback}
\end{figure*}




