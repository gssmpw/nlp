\section{Method}
\begin{figure*}
    \centering
    \includegraphics[width=445pt]{fig/method_new_pseudolabel.pdf}
    \caption{Overview of our iterative refinement pipeline. First, an LLM annotator generates initial pseudo-labels for an unlabeled corpus, dividing it into pseudo-positive and pseudo-negative corpora. Next, we train a classifier using robust UU learning on these pseudo corpora, yielding a model that outperforms the initial LLM annotations. Finally, the classifier re-labels the entire dataset, updating the pseudo-labels for the next iteration. Repeating this cycle gradually refines the pseudo-labels, leading to increasingly reliable labels.}\label{fig:method}
\end{figure*}

\label{sec:method}
Below, we present our iterative framework for combining large language model (LLM) annotations with \emph{robust UU learning}. The goal is to iteratively refine pseudo-labels generated by the LLM, thus boosting classification accuracy under minimal human supervision. Figure~\ref{fig:method} provides a high-level view of this approach, which proceeds in rounds.

\subsection{Overview of the Iterative Pipeline}
\label{subsec:method_overview}
Our pipeline is composed of three steps:
\begin{enumerate}
\item \textbf{LLM-Based Annotation (Iteration 0).} An LLM provides pseudo-labels for an unlabeled corpus (\S\ref{subsec:initial_llm}).  
\item \textbf{Robust UU Learning.} We split the corpus into \emph{pseudo-positive} and \emph{pseudo-negative} subsets and train a classifier using robust UU learning (\S\ref{subsec:train}).  
\item \textbf{Re-Labeling.} The trained classifier re-labels the entire dataset, producing updated pseudo-positive and pseudo-negative sets for the next iteration (\S\ref{sec:iterative_refinement}).  
\end{enumerate}

\subsection{Initial Noisy Annotation via LLM}
\label{subsec:initial_llm}

Let $\mathcal{C} = \{ x_1, x_2,\dots, x_N \}$ be a corpus of unlabeled samples. We use the LLM as the initial classifier to assign an initial pseudo-label $\tilde{y}_i \in \{+1, -1\}$ to each sample $x_i$. Our prompt first provides a concise description of the task, the dataset domain, and the expected answer format (e.g., “Output TRUE or FALSE”). We then give a few-shot examples illustrating how to label an example text, along with a short rationale. Finally, the prompt includes the samples to annotate (see Fig.~\ref{fig:llm_prompt} for the exact prompt).

Based on the LLM’s output, we form two unlabeled corpora:
\begin{align*}
    \widetilde{\mathcal{C}}^{(0)}_{p} = \{\, x_i \;\mid\; \tilde{y}_i = +1 \}, \widetilde{\mathcal{C}}^{(0)}_{n} = \{\, x_i \;\mid\; \tilde{y}_i = -1 \}.
\end{align*}
These sets are called \emph{pseudo-positive} and \emph{pseudo-negative} corpus, respectively. Although the labels are noisy, $\widetilde{\mathcal{C}}^{(0)}_{p}$ typically has a higher positive prior than $\widetilde{\mathcal{C}}^{(0)}_{n}$, thereby providing a reliable foundation for UU learning in subsequent iterations.

\subsection{Refinement with Robust UU Learning}
\label{subsec:train}
Let $\widetilde{\mathcal{C}}_{p}^{(t-1)}$ and $\widetilde{\mathcal{C}}_{n}^{(t-1)}$ denote the pseudo-positive and pseudo-negative sets from iteration $t-1$. Our goal is to train a classifier $g^{(t)}$ (e.g., a neural network) despite noisy labels. To this end, we optimize the \emph{robust UU learning} objective:
\begin{align*}
g^{(t)}
\;=\;
 {\operatorname{argmin}}_{g \in \mathcal{G}}
\widehat{R}_{\mathrm{ruu}}\bigl(g;\,\widetilde{\mathcal{C}}_{p}^{(t-1)},\,\widetilde{\mathcal{C}}_{n}^{(t-1)}\bigr),
\end{align*}
where $\widehat{R}_{\mathrm{ruu}}(\cdot)$ is the empirical risk of robust UU learning, which applies a ``generalized leaky ReLU'' to reduce the impact of negative risk terms that can arise from mislabels. Each set is weighted by the positive prior $\pi_+$ and the sets’ own estimated positive priors $\hat{\theta}_{p}$ and $\hat{\theta}_{n}$.

This robust learning approach is less sensitive to initial label noise and can produce a classifier that outperforms the previous iteration's classifier.




\subsection{Iterative Re-Labeling and Convergence}
\label{sec:iterative_refinement}
After training $g^{(t)}$, we re-label the entire dataset:
\begin{align*}
\tilde{y}_i^{(t)} \;=\;
\begin{cases}
+1, & \text{if } g^{(t)}(x_i) > 0,\\
-1, & \text{otherwise}.
\end{cases}    
\end{align*}

We then form updated \emph{pseudo-positive} and \emph{pseudo-negative} sets,
\begin{align*}
\widetilde{\mathcal{C}}_{p}^{(t)} = \{\,x_i \mid \tilde{y}_i^{(t)} = +1\}
\text{, }
\widetilde{\mathcal{C}}_{n}^{(t)} = \{\,x_i \mid \tilde{y}_i^{(t)} = -1\},
\end{align*}
and use them as input for the next iteration of robust UU learning.

Over several iterations, this process progressively improves the reliability of the pseudo-labels. In the ideal scenario, the positive prior in $\widetilde{\mathcal{C}}_{p}^{(t)}$ converges to 1, and the positive prior in $\widetilde{\mathcal{C}}_{n}^{(t)}$ converges to 0, bringing each corpus ever closer to the gold-standard case of perfectly labeled positive and negative data. When these priors reach 1 and 0, respectively, robust UU learning effectively reduces to standard supervised learning—achieving high accuracy even from initially noisy labels.





