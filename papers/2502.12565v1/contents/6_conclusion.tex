\section{Conclusion}
In this work, we introduced an iterative refinement pipeline that leverages robust UU learning to improve classification performance with minimal human supervision. Our approach mitigates noise in the initial annotations by decoupling pseudo-label refinement from the LLM’s internal judgments and by effectively harnessing the unlabeled corpus. Extensive experiments across diverse tasks—from fake news detection and low-resource language satire to challenging domains such as green patent identification and protein structure classification—demonstrate that our method consistently outperforms both the initial LLM annotations and existing self-refinement approaches.

Notably, our results show that even with as few as 50 labeled examples for fine-tuning, the few-labeled variant of our approach attains performance comparable to an oracle setting, highlighting its scalability and cost-effectiveness. This iterative framework not only enhances the quality of pseudo-labels over successive iterations but also proves robust in scenarios where conventional methods struggle, particularly in domains requiring specialized expertise or within AI for Science applications.

Future work may extend our framework to additional tasks such as LLM post-training and AI-driven scientific applications. Overall, our study demonstrates that iterative refinement combined with weakly supervised learning can significantly enhance LLM performance in low-resource, complex settings.

\paragraph{Limitations}
Our approach has several limitations that warrant further exploration. Although our experiments confirm the method’s robustness under typical conditions, its performance might degrade when faced with extremely noisy pseudo-labels. For instance, the learning process becomes significantly more challenging when the positive prior for the pseudo-positive and pseudo-negative sets are nearly identical, resulting in an initial accuracy of around 0.5. In fact, as shown in Fig.\ref{fig:main}, in the Fake News task (using Gemma-2.2b), both our Oracle and few-labeled variants exhibit limited performance improvement, with an initial annotation accuracy of approximately 0.6. Conversely, Fig.\ref{fig:hard_dataset} shows that in the Protein Structure task (using GPT-4o), improvement is observed even when the initial annotation accuracy is around 0.55. Although these observations do not allow us to pinpoint a definitive threshold for ineffective initial annotations, they indicate that under conditions under extremely noisy annotation cases, the benefits of our iterative refinement framework will be limited.

Moreover, our estimation of the positive prior was based on 50 examples; if these samples are out-of-distribution compared to the broader pseudo dataset, the estimated prior may deviate from its true value, potentially impairing performance. In such cases, integrating additional techniques, such as transfer learning, could prove beneficial. Finally, our current work focuses exclusively on refining LLM-generated pseudo-labels for classification tasks and does not explore the application of this approach within the context of LLM post-training. Therefore, future studies should assess our method’s practical utility and effectiveness in post-training scenarios to confirm its broader applicability in real-world settings.
