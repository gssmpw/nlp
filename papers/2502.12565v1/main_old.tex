\pdfoutput=1

\documentclass[11pt]{article}

\usepackage[review]{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage{balance}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}

\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{xspace}
\definecolor{darkblue}{rgb}{0, 0, 0.5}
\hypersetup{colorlinks=true, citecolor=darkblue, linkcolor=darkblue, urlcolor=darkblue}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{mathtools}

\usepackage{adjustbox}
\usepackage{xcolor}
\usepackage{colortbl}

\usepackage{array}

\usepackage{here}


\def\eg{{\it e.g.}}
\def\cf{{\it c.f.}}
\def\ie{{\it i.e.}}
\def\etal{{\it et al. }}
\def\etc{{\it etc}}

\title{Iterative Label Refinement Via Robust Unlabeled Learning}


\author{ \\
    \textbf{Hikaru Asano${}^{1,2}$ $\;\;\;$ Tadashi Kozuno${}^3$ $\;\;\;$ Yukino Baba${}^1$} \\
    ${}^1$The University of Tokyo \quad
    ${}^2$RIKEN AIP \quad
    ${}^3$OMRON SINIC X
    \\
    \texttt{asano-hikaru19, yukino-baba@g.ecc.u-tokyo.ac.jp,} \\
    \texttt{tadashi.kozuno@sinicx.com} \\
}

\begin{document}
\maketitle
\begin{abstract}
This document is a supplement to the general instructions for *ACL authors. It contains instructions for using the \LaTeX{} style files for ACL conferences.
The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like.
These instructions should be used both for papers submitted for review and for final versions of accepted papers.
\end{abstract}

\section{Introduction}
Text classification is an essential component of many natural language processing (NLP) applications, from sentiment analysis and document categorization to preference modeling in large language models (LLMs). As the field rapidly progresses, binary classification has emerged not only as a fundamental tool for evaluating language understanding—e.g., determining whether a model’s output aligns with human preferences—but also serves as a key element in advanced training processes such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO).
At the same time, the growing use of LLMs for data annotation, refinement, and quality control highlights the importance of dependable binary classifiers. Yet, a continuing issue is the lack of large, high-quality annotated datasets and the noise that inevitably arises from automated labeling methods, regardless of how advanced the model may be.

To address these challenges, researchers have increasingly turned to LLMs for low-cost annotation of unlabeled corpora, leveraging their remarkable capacity for in-context learning and few-shot prompting. However, these automatically assigned labels, while ample and rapidly obtained, are prone to errors—especially when the underlying model grapples with domain complexity or when relying purely on “self-evolution” or “self-feedback” loops. Such noisy annotations not only degrade model performance but also limit the practical impact of LLM-driven solutions, impeding progress in fields where accurate large-scale classification is essential. For instance, the classification of chemical compounds based on textual descriptions—an emerging interdisciplinary frontier linking NLP with cheminformatics—crucially demands stable and trustworthy annotations. Similarly, in computational social science and other high-stakes domains, noisy labeling can curtail the interpretability and reliability of findings, ultimately slowing the translation of textual insights into actionable knowledge.

In this work, we introduce a novel iterative framework that marries the generative power and common-sense reasoning abilities of LLMs with a state-of-the-art weakly supervised learning paradigm known as Unlabeled-Unlabeled (UU) Learning. At its core, our method transforms imperfect LLM-generated annotations into increasingly accurate binary classifiers through a cycle of refinement. We begin by deploying an LLM to annotate unlabeled text into two coarse sets—one predicted to be “positive” and the other “negative.” Although these initial splits are noisy, UU Learning excels in extracting reliable decision boundaries from such imperfect partitions, provided that the positively labeled subset maintains a greater proportion of genuinely positive examples than the negatively labeled one. By training on these UU datasets, we produce a classifier that surpasses the LLM’s raw annotation quality, improving inference robustness and classification fidelity.

Building on this improved classifier, we re-label the original corpus, iteratively feeding the newly assigned labels back into the UU Learning pipeline. With each iteration, the data distribution converges closer to ideal conditions, and the classifier’s accuracy steadily improves—far outpacing what can be achieved by direct LLM inference, naively tuned auto-evolutionary strategies, or one-off weak supervision methods. This iterative UU-based approach not only drastically enhances performance for text-based chemical classification, but also sets the stage for broad applications in fields like computational social science. There, the accurate categorization of massive text corpora can illuminate behavioral patterns, community sentiments, and emergent social phenomena at unprecedented scale. Likewise, in the broader “AI for Science” movement, where scientific discovery increasingly relies on textual data integration and interpretation, our framework’s ability to deliver cleaner, more reliable labels stands to accelerate research cycles and lower the barrier to data-driven breakthroughs.

In summary, our contribution lies in a synergistic integration of LLM-driven annotation and UU Learning, forging a powerful iterative feedback loop that transforms noisy initial labels into a high-fidelity classification engine. By pushing beyond the limitations of either method in isolation, we achieve state-of-the-art binary classification performance with minimal human supervision. The result is not merely an incremental advancement in label quality, but a transformative leap that opens new vistas for accurate, scalable, and domain-adaptable text classification—a foundation on which next-generation NLP systems, computational social science initiatives, and AI-driven scientific exploration can flourish.

Below is a substantially revised and enhanced version of the Preliminaries section. The goal is to make positive-negative (PN), unlabeled-unlabeled (UU), and robust UU learning concepts accessible to a non-expert, while maintaining rigor and clarity suitable for top-tier NLP and ML conferences. The style is more explanatory, with intuitive explanations accompanying formal definitions.

\section{Preliminaries}
\label{sec:preliminaries}

In this section, we establish the conceptual and theoretical underpinnings of our approach. We begin with the classical Positive-Negative (PN) learning setting, where a fully supervised dataset is available. We then introduce Unlabeled-Unlabeled (UU) learning. This weakly supervised method leverages two unlabeled datasets with differing class priors to recover classification boundaries without requiring explicit positive and negative labels. Finally, we present \emph{robust} UU learning, a refinement that counters pathological issues in naive UU risk estimators, ensuring stable and reliable model training.

\subsection{From PN Learning to Weak Supervision}

\paragraph{Binary Classification Setup.}
Consider a binary classification task in which each instance \( x \in \mathbb{R}^d \) belongs to one of two classes: positive (\(+1\)) or negative (\(-1\)). The data is generated according to an unknown joint distribution \( p(x,y) \), with \(\pi_{+} = p(y=+1)\) denoting the positive class prior. We define:
\[
p_{\mathrm{p}}(x) = p(x|y=+1), \quad p_{\mathrm{n}}(x) = p(x|y=-1),
\]
so that \( p(x) = \pi_+ p_{\mathrm{p}}(x) + (1-\pi_+) p_{\mathrm{n}}(x) \).

A classifier \( g: \mathbb{R}^d \to \mathbb{R} \) assigns real-valued scores, whose sign determines the predicted label. A loss function \(\ell:\mathbb{R}\times\{+1,-1\}\to[0,\infty)\) measures how well predictions align with the true labels. The true risk is:
\[
R(g) = \mathbb{E}_{(X,Y)\sim p}[\ell(g(X),Y)].
\]

\paragraph{PN Learning: The Fully Supervised Setting.}
In Positive-Negative (PN) learning, one has direct access to datasets of positive and negative examples:
\[
\{x_i^+\}_{i=1}^{N_{\mathrm{p}}}\sim p_{\mathrm{p}}, \quad \{x_j^-\}_{j=1}^{N_{\mathrm{n}}}\sim p_{\mathrm{n}}.
\]
A classical empirical risk minimization (ERM) objective approximates \(R(g)\) by:
\[
\hat{R}_{\mathrm{PN}}(g) = \pi_+ \cdot \frac{1}{N_{\mathrm{p}}}\sum_{i=1}^{N_{\mathrm{p}}}\ell(g(x_i^+),+1) 
\;+\; (1-\pi_+) \cdot \frac{1}{N_{\mathrm{n}}}\sum_{j=1}^{N_{\mathrm{n}}}\ell(g(x_j^-),-1).
\]

PN learning is conceptually straightforward and statistically well-founded, yet it requires curated training sets with explicit positive and negative labels. Such datasets can be prohibitively expensive or infeasible to create for large-scale or specialized tasks—e.g., evaluating language models on novel domains or labeling massive corpora in computational social science.

\subsection{Unlabeled-Unlabeled (UU) Learning: Harnessing Class-Prior Differences}

\paragraph{Motivation.}
When labeled datasets are rare, expensive, or slow to acquire, weakly supervised methods offer a compelling alternative. Among these, Unlabeled-Unlabeled (UU) learning stands out for its capacity to infer reliable decision boundaries from unlabeled data alone \citep{du2014analysis,kiryo2017positive,gong2022unlabeled}. The key insight is that we need not have direct PN pairs; instead, if we can obtain \emph{two} unlabeled datasets, each with a different (unknown) mix of positive and negative instances, we may reconstruct an unbiased estimate of the underlying PN risk.

\paragraph{Two Unlabeled Sources.}
Suppose we have two unlabeled datasets:
\[
U = \{x_i\}_{i=1}^n \sim p_{\mathrm{tr}} = \theta p_{\mathrm{p}} + (1-\theta)p_{\mathrm{n}}, \quad
U' = \{x_j'\}_{j=1}^{n'} \sim p_{\mathrm{tr'}} = \theta' p_{\mathrm{p}} + (1-\theta') p_{\mathrm{n}},
\]
where \(\theta \neq \theta'\). Here, \(\theta\) and \(\theta'\) represent distinct class priors, resulting in two unlabeled distributions that differ in how frequently positive instances appear. By comparing the model’s performance on these two data sources, UU learning disentangles the positive and negative components, effectively allowing risk estimation without explicit labels.

\paragraph{Unbiased UU Risk Estimation.}
A remarkable theoretical result is that one can construct an \emph{unbiased} estimator \(\hat{R}_{\mathrm{UU}}(g)\) of the true PN risk \( R(g) \) using only \( U \) and \( U' \). Though the algebra is intricate, the key point is that the difference in class priors enables an unbiased decomposition of the risk:
\[
R(g) = \pi_+ \mathbb{E}_{x\sim p_{\mathrm{p}}}[\ell(g(x),+1)] 
\;+\; (1-\pi_+) \mathbb{E}_{x\sim p_{\mathrm{n}}}[\ell(g(x),-1)].
\]
Since \( p_{\mathrm{p}} \) and \( p_{\mathrm{n}} \) can be recovered (up to scaling) by combining observations from \( U \) and \( U' \), UU learning effectively reconstructs the PN risk from unlabeled data. This breakthrough allows training a high-performance classifier under severe annotation scarcity, provided we know or can estimate \(\pi_+\).

\subsection{Robust UU Learning: Stabilizing the Estimator}

\paragraph{Challenges with Negative Risks.}
While UU learning’s unbiased risk estimator is elegant, early formulations sometimes allowed the empirical risk to become negative—a nonsensical and destabilizing phenomenon. Negative empirical risks encourage pathological solutions, harming training stability and model generalization \citep{kiryo2017positive}.

\paragraph{Robust UU Learning.}
To address these issues, \emph{robust} UU learning techniques modify the risk estimator to ensure it remains non-negative or bounded away from pathological values. These modifications apply non-negative corrections or smoothing terms, effectively clipping or reshaping the estimated risk to remain in a valid range. Theoretical analysis shows that such robust corrections preserve the asymptotic consistency and unbiasedness of UU estimates, while improving training stability in practice \citep{kiryo2017positive}.

\paragraph{Practical Significance.}
Robust UU learning thus provides a stable foundation for weakly supervised classification. By preventing degenerate solutions and ensuring risk estimates make intuitive sense, it enables reliable model tuning, iterative dataset refinement, and integration with other semi-supervised or self-training methods. In contexts where data labeling is prohibitive—ranging from large-scale NLP tasks to domain-specific applications in scientific text classification—robust UU learning serves as a powerful and practical tool.

\subsection{Summary of Preliminaries}

To recap:
- \textbf{PN Learning:} The standard fully supervised scenario, but often too costly for large-scale labeling.
- \textbf{UU Learning:} A weakly supervised framework that leverages two unlabeled datasets with distinct class priors to recover PN-like risk estimation without direct labels.
- \textbf{Robust UU Learning:} An enhancement that ensures stable, non-negative risk estimates, enabling reliable and practical training routines.

These concepts provide the theoretical bedrock for our approach. We will now detail how we combine robust UU learning with initial noisy labeling from LLMs and iterative refinement steps to achieve high-fidelity classifiers from initially low-quality pseudo-annotations.

\section{Method}

Our method unites the generative and reasoning capacities of large language models with robust UU learning in an iterative refinement framework. We start with a purely unlabeled dataset and use an LLM to produce coarse binary assignments. These initial pseudo-labels serve as a starting point for UU learning, allowing the model to uncover a cleaner decision boundary despite the noise. Crucially, once a robust UU-trained classifier emerges, we use it to re-label the dataset, thereby creating an improved starting point for the next iteration. Repeated cycles yield progressively better labels and improved classification accuracy.

\subsection{Overview of the Iterative Framework}

Our approach iterates through the following steps:

1. \textbf{LLM-Based Annotation:} Use an LLM to produce a noisy initial partition of unlabeled data into two subsets, \(\mathcal{X}_1\) and \(\mathcal{X}_2\), presumed to have different positive-class priors.

2. \textbf{Robust UU Learning:} Treat \(\mathcal{X}_1\) and \(\mathcal{X}_2\) as unlabeled datasets with differing priors and apply robust UU learning to train a classifier without explicit PN labels.

3. \textbf{Re-Labeling:} Use the newly trained classifier to reassign labels to the entire dataset, producing a cleaner positive/negative split for the next iteration.

By iterating these steps, we gradually improve label fidelity and classifier performance. Below, we detail each component of the pipeline.

\subsection{Initial Noisy Annotation via LLMs}

Consider a large unlabeled corpus \(\mathcal{X}=\{x_i\}_{i=1}^N\). We prompt an LLM to assign a tentative binary label \(\tilde{y}_i \in \{+1,-1\}\) to each instance. This step can be accomplished with zero-shot or few-shot prompting, exploiting the LLM’s contextual understanding without hand-crafted heuristics.

The resulting \((x_i,\tilde{y}_i)\) pairs define two unlabeled datasets:
\[
\mathcal{X}_1 = \{x_i \mid \tilde{y}_i = +1\}, \quad \mathcal{X}_2 = \{x_j \mid \tilde{y}_j = -1\}.
\]
Although these annotations are noisy, we typically observe a difference in their class compositions—e.g., \(\mathcal{X}_1\) is likely richer in genuine positives than \(\mathcal{X}_2\). We use a small, fully labeled validation subset (on the order of 100 instances) to verify that \(\mathbb{P}(y=+1|\mathcal{X}_1) > \mathbb{P}(y=+1|\mathcal{X}_2)\), ensuring conditions suitable for UU learning.

\subsection{Robust UU Learning from Two Unlabeled Sets}

Given \(\mathcal{X}_1\) and \(\mathcal{X}_2\), we apply robust UU learning to estimate and minimize the PN risk in a label-free manner. By leveraging the class-prior difference, we construct a robust UU risk estimator \(\hat{R}_{\mathrm{robUU}}(g)\), ensuring non-negative risk measurements and sidestepping pathological solutions.

We then solve:
\[
g^{(t)} \in \arg\min_{g \in \mathcal{G}} \hat{R}_{\mathrm{robUU}}(g; \mathcal{X}_1,\mathcal{X}_2),
\]
where \(\mathcal{G}\) denotes the classifier hypothesis space (e.g., neural networks or LLM-based encoders). This training yields a classifier \(g^{(t)}\) that is typically far more accurate and robust than the initial LLM’s noisy partition.

\subsection{Iterative Re-Labeling and Refinement}

Armed with the trained classifier \(g^{(t)}\), we now re-label all samples \(x_i \in \mathcal{X}\):
\[
\tilde{y}_i^{(t)} = \begin{cases}
+1 & \text{if } g^{(t)}(x_i) > 0 \\[4pt]
-1 & \text{otherwise}.
\end{cases}
\]
This produces updated datasets \(\mathcal{X}_1^{(t)}, \mathcal{X}_2^{(t)}\), ideally more accurately separated in terms of class priors than the original LLM-based labels. With these improved splits, we return to the UU step, refining the classifier further:
\[
g^{(t+1)} \in \arg\min_{g \in \mathcal{G}} \hat{R}_{\mathrm{robUU}}(g; \mathcal{X}_1^{(t)},\mathcal{X}_2^{(t)}).
\]

Repeating these cycles yields iterative improvements. While UU learning is theoretically grounded for a single pass, our experiments show that iteration empirically enhances performance. Intuitively, each UU-trained classifier “cleans” the dataset, enabling the next round of UU training to be more effective.

\subsection{Stopping Criteria and Practical Considerations}

In practice, we run several iterations (e.g., 3--5) and monitor performance on a small labeled validation or test set. We stop when improvements plateau. The incremental cost of iteration is modest compared to manual labeling, making this approach highly scalable.

If the initial LLM partition does not produce a suitable difference in class priors, we can adjust LLM prompts or sample additional unlabeled data. In most cases, a minimal effort suffices to ensure a workable starting point.

\subsection{Relation to Theory and Limitations}

Our iterative approach is a heuristic overlay on robust UU learning. Although UU learning provides solid theoretical guarantees for risk estimation in a single iteration, we do not claim new theoretical results on iterative refinement. Instead, our experiments demonstrate that iteration materially improves real-world performance in complex NLP tasks, suggesting a synergistic interplay between weak supervision and LLM-guided labeling.

Future work could explore formal analyses of the iterative process, potentially establishing conditions under which class prior separation widens or proving convergence guarantees.

\subsection{Summary of the Method}

Our method exploits LLMs to cheaply generate noisy initial splits, applies robust UU learning to train a risk-consistent classifier, and iteratively refines the data to achieve ever-higher label quality and classification accuracy. By bridging advanced weak supervision theory with the generative might of LLMs, we open a pathway toward high-fidelity, large-scale classification with minimal human annotation. Subsequent sections demonstrate the concrete impact of this approach through comprehensive experiments and ablations in domains ranging from chemical text classification to computational social science.

\input{contents/4_experiment}
\appendix
\input{contents/appendix}

\section{Example Appendix}
\label{sec:appendix}

This is an appendix.

\end{document}
