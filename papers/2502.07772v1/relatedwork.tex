\section{BACKGROUND AND RELATED WORK}
\subsection{Behavior Tree (BT)}
A BT is a graphical representation of system control used to define the task implementation policies of autonomous agents in applications such as robotics, driverless vehicles, and other autonomous systems \cite{c7}. 

A BT consists of various types of nodes categorized as root, parent, or child nodes based on their hierarchical positions \cite{c1,c2}. Figure 1 shows a simple example form of a BT containing one parent node and three child nodes. This BT can be extended by incorporating additional parent or child nodes. The complexity of a BT depends on the intricacy of the planned task. 

A BT shows the task execution structure of a particular system. The execution process begins at the root node (the parent node in Figure 1), which produces signals, so-called ticks, and sends them to its child nodes. These ticks cause child nodes to execute their associated actions, which then return a status of either Success or Failure, depending on the outcome of their execution.

A parent node, also referred to as a control flow node, can be classified into three types: Sequence, Fallback and Parallel. The behavior of ticks varies based on the type of control flow node.

-	Sequence nodes transmit ticks sequentially from left to right and return Success only if all their child nodes return Success.

-	Fallback nodes also transmit ticks sequentially from left to right but return Success if at least one of their child nodes returns Success.

-	Parallel nodes send ticks to all child nodes simultaneously and return Success if a predefined number z of child nodes return Success (where z is specified by a user).


\begin{figure}[t]
    \centering
    \includegraphics[width=0.3\textwidth]{Example_bt.JPG} % Corrected filename
    \caption{Example Structure of Behavior Tree.}
    \label{fig:example}
\end{figure}


\subsection{Genetic Programming (GP)}
GP is a special algorithm that imitates natural evolution of living organisms \cite{c20}. In GP, populations of individual programs evolve generation by generation \cite{c6,c20,c21,c22}. New generations of programs are created through genetic operations such as crossover or mutation. In crossover, new offspring programs are produced by combining random parts of two individual programs. In mutation, a new program is created by randomly modifying any random part of a selected program.  Each newly generated program is evaluated using pre-defined fitness function, which assesses how well the program’s output aligns with the user’s pre-defined specifications. Only the best output programs are selected and retained for subsequent generations. This evolutionary process continues until one or more programs achieve a predefined satisfactory fitness level.

In this paper, the GP algorithm is applied to the generation of BTs. Through the iterative evolution of BTs, our approach aims to produce BTs capable of effectively executing the required tasks for an autonomous agent.

\subsection{Large Language Model (LLM)}
An LLM is a type of AI model developed to process natural language tasks such as text generation, translation, and summarization. LLMs are trained on large amounts of text data, which not only makes them proficient in text generation but also enables them to exhibit unexpected skills, known as emergent abilities \cite{c23,c24,c25,c26,c27}. These abilities include complex reasoning, decision-making, planning, instruction-following, in-context learning, and more. Interestingly, LLMs acquire these abilities despite not being explicitly trained for them. Research suggests that the emergence of such capabilities primarily results from the expansion of model size and the increasing volume and diversity of training data \cite{c23,c24,c25,c26,c27}. Today, several LLMs, such as GPT \cite{c28}, LLaMa \cite{c29}, Gemini \cite{c30}, DeepSeek \cite{c31}, and others are publicly available and widely used across various academic and research fields.

\subsection{BTs Generation using LLMs}
As LLMs continue to rapidly advance with remarkable capabilities, their integration into robotics has gained increasing attention \cite{c23,c32}. Several studies have explored the application of LLMs to robotic control, particularly in generating BT-based control policies \cite{c7}. 

Research studies \cite{c9,c10,c11} developed various techniques for the automatic generation of BTs by using LLMs, specifically GPT models \cite{c33}. In \cite{c12} researchers utilize LLMs and BTs to enable robots to explain their task execution failures. In \cite{c13}, a method for BT generation using compact LLMs was introduced, where the authors fine-tuned smaller versions of LLMs to create BTs effectively. Several studies \cite{c14,c15,c16,c17} proposed techniques that leverage LLMs to automatically expand and update BTs during robotic task planning and execution. Additionally, researchers in \cite{c18,c19} presented an LLM-based BT generation approach that incorporates the analysis of images depicting the robot's environment. 

Even though several studies have been conducted in BTs-generation field using natural language input methods, there remain open questions and gaps regarding their efficiency, accuracy and applicability to real-world scenarios. 

In \cite{c8}, the integration of LLMs with GP was proposed for BT generation. While combining LLMs with GP can be considered an effective approach, certain critical factors were not considered in their methodology. For example, their proposed framework included a validation engine to ensure the syntactic correctness of BTs generated by LLMs; however, they did not consider the functional fitness of syntactically correct BTs. Just because BTs generated by LLMs are syntactically correct does not mean they are always logically suitable for accomplishing the robot's task successfully. Furthermore, their work did not provide the statistical analysis of experimental results. Due to the phenomenon of hallucination, LLMs may generate varying BTs differently when given the same input prompt multiple times. Thus, LLMs may generate inconsistent different fitness level BTs in each usage. Additionally, they did not clarify whether examples of high-fitness BTs were included in the LLM inputs. This is an important factor, as LLMs may not always generate very precise and accurate BTs without reference examples of high-fitness BTs. In practical scenarios, however, high-fitness BTs tailored to specific robotic task planning are typically unavailable in advance. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{methodology.JPG} % Corrected filename
    \caption{LLM-GP-BT methodology framework.}
    \label{fig:example}
\end{figure*}

Our current research addresses these challenges and open questions by proposing an enhanced framework that integrates LLM with GP method for BT generation, referred to as the LLM-GP-BT technique.