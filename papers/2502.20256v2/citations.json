[
  {
    "index": 0,
    "papers": [
      {
        "key": "dosovitskiy2020image",
        "author": "Dosovitskiy, Alexey",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      },
      {
        "key": "oquab2023dinov2",
        "author": "Oquab, Maxime and Darcet, Timoth\u00e9e and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr",
        "title": "DINOv2: Learning Robust Visual Features without Supervision"
      },
      {
        "key": "kirillov2023segment",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "tian2023multi",
        "author": "Tian, Stephen and Cai, Yancheng and Yu, Hong-Xing and Zakharov, Sergey and Liu, Katherine and Gaidon, Adrien and Li, Yunzhu and Wu, Jiajun",
        "title": "Multi-object manipulation via object-centric neural scattering functions"
      },
      {
        "key": "lu2023efficient",
        "author": "Lu, Lei and Cai, Yancheng and Huang, Hua and Wang, Ping",
        "title": "An efficient fine-grained vehicle recognition method based on part-level feature optimization"
      },
      {
        "key": "zhang2025bridgenet",
        "author": "Zhang, Jingdong and Fan, Jiayuan and Ye, Peng and Zhang, Bo and Ye, Hancheng and Li, Baopu and Cai, Yancheng and Chen, Tao",
        "title": "BridgeNet: Comprehensive and Effective Feature Interactions via Bridge Feature for Multi-Task Dense Predictions"
      },
      {
        "key": "lv2025drkd",
        "author": "Lv, Yilong and Cai, Yancheng and He, Yujie and Li, Min",
        "title": "DrKD: Decoupling response-based distillation for object detection"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "geirhos2018imagenet",
        "author": "Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland",
        "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wichmann2023deep",
        "author": "Wichmann, Felix A and Geirhos, Robert",
        "title": "Are deep neural networks adequate behavioral models of human visual perception?"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bowers2023deep",
        "author": "Bowers, Jeffrey S and Malhotra, Gaurav and Dujmovi{\\'c}, Marin and Montero, Milton Llera and Tsvetkov, Christian and Biscione, Valerio and Puebla, Guillermo and Adolfi, Federico and Hummel, John E and Heaton, Rachel F and others",
        "title": "Deep problems with neural network models of human vision"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "cai2023rethinking",
        "author": "Cai, Yancheng and Zhang, Bo and Li, Baopu and Chen, Tao and Yan, Hongliang and Zhang, Jingdong and Xu, Jiahao",
        "title": "Rethinking cross-domain pedestrian detection: a background-focused distribution alignment framework for instance-free one-stage detectors"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yin2023generalizable",
        "author": "Yin, Fei and Zhang, Yong and Wu, Baoyuan and Feng, Yan and Zhang, Jingyi and Fan, Yanbo and Yang, Yujiu",
        "title": "Generalizable black-box adversarial attack with meta learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "tuli2021convolutional",
        "author": "Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas L",
        "title": "Are convolutional neural networks or transformers more like human vision?"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "dosovitskiy2020image",
        "author": "Dosovitskiy, Alexey",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "geirhos2021partial",
        "author": "Geirhos, Robert and Narayanappa, Kantharaju and Mitzkus, Benjamin and Thieringer, Tizian and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland",
        "title": "Partial success in closing the gap between human and machine vision"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ghildyal2024foundation",
        "author": "Ghildyal, Abhijay and Barman, Nabajeet and Zadtootaghaj, Saman",
        "title": "Foundation Models Boost Low-Level Perceptual Similarity Metrics"
      },
      {
        "key": "croce2024adversarially",
        "author": "Croce, Francesco and Schlarmann, Christian and Singh, Naman Deep and Hein, Matthias",
        "title": "Adversarially Robust CLIP Models Induce Better (Robust) Perceptual Metrics"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "caron2021emerging",
        "author": "Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\\'e}gou, Herv{\\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand",
        "title": "Emerging properties in self-supervised vision transformers"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2022contrast",
        "author": "Li, Qiang and Gomez-Villa, Alex and Bertalm{\\'\\i}o, Marcelo and Malo, Jes{\\'u}s",
        "title": "Contrast sensitivity functions in autoencoders"
      },
      {
        "key": "akbarinia2023contrast",
        "author": "Akbarinia, Arash and Morgenstern, Yaniv and Gegenfurtner, Karl R",
        "title": "Contrast sensitivity function in deep networks"
      }
    ]
  }
]