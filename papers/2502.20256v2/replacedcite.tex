\section{Related Work}
\label{sec:relat}
Since the advent of deep learning, machine vision models based on foundation models____ and DNNs____  have successfully handled numerous advanced visual tasks. However, researchers have observed that machine vision operates differently from human vision. ____ revealed that standard CNNs trained on ImageNet are strongly biased toward texture recognition rather than shape, which contrasts with human visual patterns. ____ provided further evidence that deep neural networks (DNNs) differ significantly from the HVS, demonstrating poor robustness in object classification under 3D viewpoint changes and image distortions, and showing vulnerability to adversarial examples, which are rarely problematic for humans. ____ pointed out that DNNs performing well in benchmark tests share little overlap with biological vision mechanisms and fail to account for many findings in psychological studies of human vision. This highlights a clear distinction between machine and human vision, leading to the rise of interest in domain adaptation____ and making networks robust to adversarial attacks____.

But there is also evidence that the gap between neural network-based machine vision models and human vision is gradually narrowing. ____ compared vision transformers (ViT)____ and CNNs, finding that ViT not only achieves superior task accuracy but also exhibits weaker inductive biases, with error patterns more consistent with human errors. ____ discovered that the long-standing robustness gap between humans and CNNs in handling distortions is shrinking. ____ also demonstrated that foundation models like DINO____ and CLIP____ can generate more accurate and robust metrics for low-level perceptual similarity.

Most of the aforementioned studies focus on high-level task performance (\eg, accuracy, consistency, ...), which may not reveal whether computation models suffer from the same bottlenecks and rely on the same invariances as human vision. To that end, ____ have attempted to reveal CSF characteristics within pretrained architectures by training a head with a contrast discrimination classifier. The problem with this approach is that it introduces a bias by relying on a classifier trained to compare contrast. Such studies also make an incorrect assumption that CSF explains both near-threshold and super-threshold vision, while contrast constancy results (see \secref{sub_SCM}) show that this is not the case.  In contrast, we examine networks' low-level characteristics without additional task-specific training, considering both near-threshold and supra-threshold vision.