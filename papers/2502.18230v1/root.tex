%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document


\usepackage{subfiles}
\usepackage{xcolor}
\usepackage{graphicx} 
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{flushend}
\usepackage[export]{adjustbox}
\usepackage{array}
\usepackage{mathrsfs}
\usepackage[font=small]{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{upgreek}
\usepackage[belowskip=-15pt,aboveskip=0pt]{caption}
\usepackage{cite}
\usepackage{tabularx}
\let\labelindent\relax
\usepackage{enumitem,kantlipsum} %errorsatoshi
\usepackage{bm}
\usepackage{physics}
% formatting table
\usepackage{stackengine}
\newcommand\xrowht[2][0]{\addstackgap[.5\dimexpr#2\relax]{\vphantom{#1}}}

\newcommand{\todo}[1]{\textcolor{red}{#1}}
\newcommand{\todoblue}[1]{\textcolor{blue}{#1}}
\definecolor{sher}{rgb}{0.0,0.3,0.5}
\definecolor{Alirezacolor}{rgb}{1,0.1,0.3}

\newcommand{\Alireza}[1]{\textcolor{Alirezacolor}{\emph{\{Alireza\}~{#1}}}}

\newcommand{\rac}[1]{\multicolumn{1}{|r|}{#1}}
\newcommand{\racd}[1]{\multicolumn{1}{|r||}{#1}}
\newcommand{\comment}[2]{\textcolor{red}{#1}\textcolor{blue}{[#2]}}




%\setlength{\abovecaptionskip}{11pt plus 2pt minus 2pt}
%\setlength{\textfloatsep}{14.0pt plus 3.0pt minus 4.0pt}


\title{\LARGE \bf Pre-Surgical Planner for Robot-Assisted Vitreoretinal Surgery: Integrating Eye Posture, Robot Position and Insertion Point }

%\title{\LARGE \bf Pre-Operative RCM Error Compensation Framework Towards  Kinematic calibration in Software-RCM Ophthalmic Surgical Robot }

\author{Satoshi Inagaki$^{1,2}$, Alireza Alikhani$^{2}$, Nassir Navab$^{2}$, Peter C. Issa$^{3}$ and M. Ali Nasseri$^{3,4}$% <-this % stops a space \\
\thanks{This paper is partially supported by NSK Ltd. and partially by the state of Bavaria through Bayerische Forschungsstigtung (BFS) under Grant AZ-1592-23-ForNeRo. Corresponding author: M. Ali Nasseri \tt\small (ali.nasseri@mri.tum.de)}
\thanks{$^{1}$  S.Inagaki is with NSK Ltd., Japan.
}%
\thanks{$^{2}$ S.Inagaki, A. Alikhani, and N. Navab is with Department of Computer Science in Technische Universit\"{a}t M\"{u}nchen, M\"{u}nchen 85748 Germany. 
}
\thanks{$^{3}$ Peter C. Issa and M. Ali Nasseri are with Augenklinik und Poliklinik, Klinikum rechts der Isar der Technische Universit\"{a}t M\"{u}nchen, M\"{u}nchen 81675 Germany.
}%
\thanks{$^{4}$ M. Ali Nasseri is with the Department of Biomedical Engineering, University of Alberta, Canada.}
}%

\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty}
\begin{abstract}

Several robotic frameworks have been recently developed to assist ophthalmic surgeons in performing complex vitreoretinal procedures such as subretinal injection of advanced therapeutics.
These surgical robots show promising capabilities; however, most of them have to limit their working volume to achieve maximum accuracy. Moreover, the visible area seen through the surgical microscope is limited and solely depends on the eye posture. If the eye posture, trocar position, and robot configuration are not correctly arranged, the instrument may not reach the target position, and the preparation will have to be redone.
Therefore, this paper proposes the optimization framework of the eye tilting and the robot positioning to reach various target areas for different patients.
Our method was validated with an adjustable phantom eye model, and the error of this workflow was 0.13 $\pm$ 1.65 deg (rotational joint around Y axis), -1.40 $\pm$ 1.13 deg (around X axis), and 1.80 $\pm$ 1.51 mm (depth, Z).
The potential error sources are also analyzed in the discussion section.
%In our previous work, we presented the expansion strategy for the robot's accessibility and target visibility. 
\bstctlcite{IEEEexample:BSTcontrol}

\begin{keywords}
Medical Robots and Systems; Surgical Robotics: Planning, Robot-Assisted Microsurgery
\end{keywords}

\end{abstract}

\section{Introduction}
Retinal surgery is a highly delicate medical procedure that requires exceptional precision and fine motor control from ophthalmic surgeons~\cite{10611207}. Procedures including subretinal injection, retinal vein cannulation, and retinal peeling are a few examples. In retinal vein cannulation, the surgeon must carefully insert an instrument into a vessel with a diameter of $100-400$ µm and maintain its position for several minutes~\cite{KUleventowardsaclinically}. However, natural physiological tremors in humans make achieving high precision challenging. Hence, the ophthalmic surgeries field has adopted robotic platforms to assist and enhance surgeon's capabilities during retinal surgeries~\cite{ sixdegree1993,gerber2020advanced,rahimy2013robot, nasseri2013introduction, 10340955, he2012toward}.
In ophthalmic surgery, the fundus area is observed through the cornea and the visible area is limited, therefore, the position of the visible area is adjusted by tilting the eye~\cite{KUlevensetupandmethod,Koyama,weidesign,weiperformance,haorandesign}. 
Moreover, a trocar is planted as an entry port to minimize the scleral stress on the eyeball. The surgical robot has to control the instrument around this, which is called remote center of motion (RCM) control. 
Therefore, the trocar position limits the surgical robot's working area, and the target areas vary depending on the type of operation and the surgical site shift from one surgery to another~\cite{faridpooya2022randomised}.
%~\cite{sakai2014design,weiperformance,nasseri2013kinematics}. 
%The required working area of our robot is defined as 7 mm in diameter~\cite{sakai2014design} and $\pm$20 deg around the center (8.3 mm in diameter)~\cite{weidesign}, respectively. The working volume of the robot is shown in Fig.\ref{fig:strategy}(d). As an example of other robotic frameworks, Gijbel et al.~\cite{KUlevendesignandrealisation} defined their working area as 90 deg and Wu et al.~\cite{wu2020optimized} defined it 100 deg due to the wide range the various microscope's magnification. 

\begin{figure}[t]
    \centering
\includegraphics[width=1.0\linewidth]{Img/strategy3.pdf}
    \caption{Overview of the surgical planner. (a)-(c) in optimization shows the strategy to expand the accessible area.} 
    \label{fig:strategy}
    \vspace{-3pt}
\end{figure}

To facilitate safe operation at the target area, this area has to be covered both by the working area of the robot and the visible area. Therefore, we conducted an accessibility analysis in our previous work~\cite{accessibilityanalysis}. The working area is shifted by the eyeball tilting, the RCM point, and the robot tilting. The eye posture shifts the visible area. Through this accessibility analysis, we defined the strategy to expand the visible-accessible area as shown in Fig.\ref{fig:strategy}(a)-(c) and confirmed it by analysis and experiment. 
Although this work proved that these strategies contribute to the expansion of the visible-accessible area, it could not step into how to optimize these factors depending on the target area. If the eye posture, trocar position, and robot configuration is not correctly arranged, the instrument may not reach the target position, and the preparation will have to be redone. In this paper, we advance this analysis and propose a preoperative planning framework that converts the target position defined by the surgeon in the 2D diagnostic image into a 3D position and optimizes the eye and robot posture and insertion position from the target position (Fig.\ref{fig:strategy}). Since this work aims to overlap the target area with the visible-accessible area, the accuracy is not so much required, assuming around 1 mm, compared to the accuracy required for subretinal injection. 

This paper's contribution is first to propose a workflow and method of surgical planning, and secondly, this workflow was experimentally validated using a realistic eye phantom. Thirdly, the multiple potential error sources are analyzed in the discussion section.

\subsection{Related Work}
There are many studies that focused on preoperative planning using the da Vinci system, assuming surgeries such as laparoscopic and cardiac surgeries\cite{davincipreoperative1,davincipreoperative2,davincipreoperative3,davincipreoperative4,davincipreoperative5,davincipreoperative6,davincipreoperative7}. These studies have proposed methods for optimizing trocar placement and the initial posture of the robot. Based on the information from the CT scan, these optimizations are proposed by considering the accessibility of the surgical robot, the endoscopic field of view, arm dexterity, arm-to-arm interference, and even obstacles such as internal organs. Other studies have used general-purpose robotic arms to optimize trocar positioning and surgical instrument mounting\cite{trocaroptimization1,trocaroptimization2,trocaroptimization3}.
However, to the best of our knowledge, there are no studies that focus on the subject of preoperative planning in the field of vitreoretinal surgery. The major difference between vitreoretinal surgery and the mentioned surgeries is that the posture of the eye can be changed, which changes the field of view and accessibility. 
%Moreover, obstacles need not be taken into account in vitreoretinal surgery because there is no organ to be avoided. 

As for the eye surgery, there are several studies on eye rotation.
Smits et al. developed a fixture mechanism for repositioning RCM points~\cite {KUlevensetupandmethod}. Koyama et al.~\cite{Koyama} and the group of~\cite{weidesign,weiperformance,haorandesign} have developed algorithms to perform orbital manipulation within an eyeball utlizing dual-arm robot. However, their focus was more on RCM repositioning or rotating eyeballs rather than optimizing the visible-accessible area.
Therefore, this paper is the first to address presurgical planning for robot-assisted vitreoretinal surgery. 

\section{Introduction Of The Robot} \label{sec:robotmechanics}
The whole structure of our surgical robot is shown in Fig.~\ref{fig:kinematics}(a). Our robot can be divided into two central parts: the 5-DoF robot (Fig.~\ref{fig:kinematics}(b)) and the arm robot.
The 5-DoF robot is responsible for the tiny and precise movement of the surgery.
%The concept design is made by Nasseri et al.~\cite{nasseri2013introduction} and updated by NSK.Ltd.
The robot consists of two parallel coupled joint mechanisms (PCJM) for translation and rotation in the X and Y axis and a decoupled prismatic joint for movement along the Z-axis. The kinematics is described in our previous work~\cite{accessibilityanalysis,PKC-RCM,nasseri2013kinematics}.
%This PCJM can be interpreted as a translational and rotational joint serial link.
%Referring to the kinematic structure in Fig.~\ref{fig:kinematics}(b), the needle-tip position $\vb{p}_{tip}$ is obtained by forward kinematics and the inverse kinematics is calculated by a analytical approach ~\cite{PKC-RCM,nasseri2013kinematics}. The arm robot has 4-DoF: $X, Y, Z$, and $\theta$.
This arm robot is responsible for coarse movement.
The arm robot brings the 5-DoF robot to the RCM point and tilts it to the required angle.
\begin{figure}[t]
    \centering
    \vspace{3pt}
    \includegraphics[width=0.92\linewidth]{Img/kinematics2.pdf}
    \caption{(a) shows the whole view of the robot. (b) shows the kinematic structure of the 5-DoF surgical robot.} 
    \label{fig:kinematics}
    \vspace{-2pt}
\end{figure}


\section{Method}{\label{sec:method}}

%\subsection{Kinematics And Accessibility Calculation}\label{sec:kinematic}
%Firstly, the forward and inverse kinematics are calculated.
%The forward kinematics~\cite{spong2006robot} of the robot ${T}_{j}^{i}$ is obtained by Denavit–Hartenberg (DH) parameters.
%\begin{equation}\label{eq:transform_matrix}
%\begin{split}
%{T}_{j}^{i} &= {A}_{i+1}{A}_{i+2}...{A}_{j-1}{A}_{j} (if\:i<j) \\
%{A}_{i} &= {R}_{z,\theta_i}{Trans}_{z,d_i}{Trans}_{x,a_i}{R}_{x,\alpha_i} 
%\end{split}
%\end{equation}
%where $\theta_i$, $a_i$, $d_i$, $\alpha_i$ are parameters associated with $link_i$ and $joint_i$.
%The inverse kinematics is calculated using the numerical approach (e.g. Jacobian inverse technique) or analytical approach. 

%The RCM point($\vb{p}_{\rm{rcm}}$) is along the instrument and can be expressed as follows~\cite{virtualfixture}.
%\begin{equation}\label{eq:RCM_control}
%\begin{split}
%    \vb{p}_{\rm{rcm}} = \lambda(\vb{p}_{\rm{tip}}-\vb{p}_{5})
%\end{split}
%\end{equation}
%where $\vb{p}_{5}$ is the endpoint of the last joint of the robot and $\vb{p}_{tip}$ is the tip of the instrument as shown in Fig.~\ref{fig:kinematics}(c).

%In order to calculate the accessibility, the distance between the tooltip ($\vb{p}_{\rm{tip}}$) and the center of the eyeball ($\vb{p}_{\rm{center}}$) should be equal to the radius of the eyeball ($r$).
%\begin{equation}\label{eq:accessibility}
%\begin{split}
%    |\vb{p}_{\rm{tip}} - \vb{p}_{\rm{center}}| = r\\
%\end{split}
%\end{equation}

\subsection{Accessibility Calculation}\label{sec:kinematic}
The RCM point ($\vb{p}_{\rm{rcm}}$) is along the instrument and can be expressed as follows~\cite{virtualfixture}.
\begin{equation}\label{eq:RCM_control}
\begin{split}
    \vb{p}_{\rm{rcm}} = \lambda(\vb{p}_{\rm{tip}}-\vb{p}_{5})
\end{split}
\end{equation}
where $\vb{p}_{5}$ is the endpoint of the last joint of the robot and $\vb{p}_{tip}$ is the tip of the instrument as shown in Fig.~\ref{fig:kinematics}(b).

In order to calculate the accessibility, the distance between the tooltip 
 ($\vb{p}_{\rm{tip}}$) and the center of the eyeball ($\vb{p}_{\rm{center}}$) should be equal to the radius of the eyeball ($r$), (Fig.\ref{fig:eyeballtilt}).
\begin{equation}\label{eq:accessibility}
\begin{split}
    |\vb{p}_{\rm{tip}} - \vb{p}_{\rm{center}}| = r\\
\end{split}
\end{equation}

\subsection{Strategy to adjust the visible-accessible area} \label{sec:strategy}
The strategy to optimize the visible-accessible area is defined in our previous work\cite{accessibilityanalysis} as follows.
\begin{enumerate}
  \item Adjusting the eye posture within $\pm$10 deg around the X and Y axis (Fig.~\ref{fig:strategy}(a))
  \item Selecting insertion point (Fig.~\ref{fig:strategy}(b)) from three trocar. One trocar is 3 or 9 o'clock position and two trocars are planted at $\pm$20 deg position from there, which leads to about $\pm$3 mm. This helps to move the working area along the X-axis. 
  \item Adjusting the initial tilting angle of the robot within 23$\pm$8 deg (Fig.~\ref{fig:strategy}(c)). This helps to move the working area along the Y-axis.
\end{enumerate}


\subsection{Workflow} \label{sec:workflow}
The proposed workflow for surgical planning for robot-assisted vitreoretinal surgery is as follows:
\begin{description}
  \item[Diagnostic phase] Prior to starting the operation. 
  \item[STEP1] Surgeons take the fundus and OCT image and determine the target point by clicking the image.
  \item[STEP2] The system estimates the 3D position of the target after 2D-3D eyeball calculation (Function1)
  \item[Preparation phase] The preparation of the operation is started, and the robot is placed next to the patient. Three trocars for inserting the instrument are planted as defined in Sec.\ref{sec:strategy} (Fig.\ref{fig:strategy}(b)). Additionally, two trocars are planted for the light pipe and infusion.
  \item[STEP3] The system calculates the posture and the position of the eyeball and the trocars. (Function2)
  \item[STEP4] The system proposes tilting the angle of the eyeball to the surgeon by GUI. (Function3)
  \item[STEP5] The system proposes the best trocar to insert and calculate the initial tilting angle of the robot and the initial position of each axis. (Function4)
  \item[Operation phase] The instrument is inserted through the trocar and approaches the target.
  \item[STEP6] The system calculates the target angle and position to approach the target. (Function5)
\end{description}
After the workflow is completely executed, the instrument is close to the retina, and then the surgeon can adjust the instrument position using OCT. 
Each critical step within the proposed workflow is associated with a specific “function” described in detail.


\subsection{Function1. 2D to 3D reconstruction of the target position }\label{sec: targetposcal}
In this section, we assume that the center of the diagnostic image is the fovea (Fig.\ref{fig:2D3Dconvert}). For this assumption, the diagnostic image has to be taken from right in front of the eye. 
A reference is required to convert the pixel to the actual length. The angle of the view of the diagnostic image ($\psi_{\rm{view}}$) is usually 45deg or 60 deg. The diameter of the image ($D_{\rm{FoV}}$) is obtained from this angle of view. Utilizing this diameter of the image, the conversion factor ($k_{\rm{pixel2mm}}$) is calculated.
\begin{equation}\label{eq:conversion}
\begin{split}
D_{\rm{FoV}} = 2r\sin(\psi_{\rm{view}}/2)    \\
k_{\rm{pixel2mm}} =  D_{\rm{FoV}}/D_{\rm{pixel}} \\
\end{split}
\end{equation}
where $r$ is the radius of the eyeball (12.1mm) and $D_{\rm{pixel}}$ is the diameter of the image in pixels. After performing several pre-processing steps, such as removing the color channel and denoising, utilizing the Ellipse Hough Transform\cite{houghcircle}, the diameter ($D_{\rm{pixel}}$) is calculated. 
The polar coordinate ($\theta$, $\phi$) of the target is obtained from the 2D position of the target ($\vb{p}_{\rm{target}} =  (x, y)$) and the  distance from the center ($l_{\rm{pixel}}$). 
\begin{equation}\label{eq:polarcoordinate}
\begin{split}
&l_{\rm{pixel}} = \sqrt{x^2+y^2}    \\
&\theta = \arcsin(l_{\rm{pixel}}k_{\rm{pixel2mm}}/r)  \\
&\phi = \arctan(x/y)    \\
\end{split}
\end{equation}
However, according to \cite{eyeoptics}, the fovea is not located at the posterior pole of the eyeball but located along the visual axis and the angle between the visual axis and the center axis of the eyeball, which is called the optical axis, is 5 degrees ($\kappa$) as shown in Fig.\ref{fig:2D3Dconvert}(c). Since the visual axis passes through the nodal point, the intersection of the visual axis and the optical axis can be considered to be the nodal point, and the nodal point is located at 16.4 mm ($l_{\rm{nodal}}$) from the posterior pole. Thus, the position of the fovea and the angle ($\kappa_2$) from the center axis is calculated as follows. 
\begin{equation}\label{eq:foveaconpensate1}
\begin{split}
\left\{ \,
    \begin{aligned}
    & y = \tan(\kappa)(x+(l_{\rm{nodal}}-r))  \\
    & x^2 + y^2 = r^2 \\
    \end{aligned}
\right. \\
\end{split}
\end{equation}
\begin{equation}\label{eq:foveaconpensate2}
\begin{split}
&\kappa_2 = \arcsin(y/r)    \\
\end{split}
\end{equation}
$\kappa_2$ is obtained as 6.77 deg.  
The target position ($\vb{p}_{\rm{target3D2}}$) from the posterior pole is obtained by rotating the target position ($\vb{p}_{\rm{target3D}}$) from Eq.\ref{eq:polarcoordinate} around the X axis. The rotation matrix around the X-axis is defined as $rotx$.
\begin{equation}\label{eq:foveaconpensate3}
\begin{split}
&\vb{p}_{\rm{target3D2}} = rotx(\kappa_2)\vb{p}_{\rm{target3D}}   \\
\end{split}
\end{equation}

\begin{figure}[b]
    \centering
    \vspace{0pt}
    \includegraphics[width=1.0\linewidth]{Img/2D3Dconvert2.pdf}
    \caption{2D-3D conversion. (a)Diagnostic image\cite{fundusimage}. The surgeon defines the target. (b) The polar coordinate of the target is obtained from (a). (c) Schematic diagram of the optical and the visual axis. }
    \label{fig:2D3Dconvert}
    \vspace{12pt}
\end{figure}


\subsection{Function2. 6D detection of the eye and trocar }\label{sec: eyeposedetection}
The position and orientation of both the trocar and eyeball must be identified. Recently,  different accurate methods for trocar pose estimation have been developed in our group, achieving an average error of 3.06 $\pm$2.36 degrees\cite{colibri5,colibridoc}. Several approaches for detecting eye gaze have been explored \cite{eyegazetrack1}. Utilizing these methods, the eye posture and trocar 6D pose are estimated. 
%The position and the pose of the trocar and the eyeball have to be detected. We recently developed a trocar pose detection method with average error 3.06 $\pm$2.36 degrees\cite{colibri5,colibridoc}. There are various work to detect eye gaze\cite{eyegazetrack1}and we are also developing a novel method for eye gaze detection.


\subsection{Function3. Optimization of the eye posture }\label{sec: eyepostureproposal}
In this function, the tilting angle of the eyeball $\alpha$ and $\beta$ around the X and Y axis is calculated to move the center of the visible area to the center of the target. Fig.~\ref{fig:eyeballtilt} explains when the eyeball is tilted $\theta_{\rm{tilt}}$, the center of the field view will be rotated the opposite direction and shifted $-2\theta_{\rm{tilt}}$ from the initial center of visible area, which is defined as $\vb{p}_{\rm{fov}}=[0, 0, -r]^T$. This point is shifted to $\vb{p}_{\rm{fov1}}$ and then shifted to $\vb{p}_{\rm{fov2}}$ by the rotation around the X and Y axis.
$\vb{p}_{\rm{fov2}}$ is calculated using the rotation matrix, where $rotx$ and $roty$ are the rotation matrix around the X and Y axis, respectively.
\begin{equation}\label{eq:RCMshift}
\begin{split}
    \vb{p}_{\rm{fov2}} &= roty(-2\beta)rotx(-2\alpha)\vb{p}_{\rm{fov}}\\
    &= \begin{bmatrix}
    r\sin2\beta\cos2\alpha \\
    -r\sin2\alpha \\
    -r\cos2\alpha\cos2\beta \\
    \end{bmatrix}\\
\end{split}
\end{equation}
When the target position is defined as $\vb{p}_{\rm{target}} = [x, y, z]^T$, $\vb{p}_{\rm{fov2}}$ will be equal with the target. $\alpha$ and $\beta$ is obtained. 
\begin{equation}\label{eq:insertionvector}
\begin{split}
    &\alpha = \tfrac{1}{2}\arcsin(-y/r) \\
    &\beta = \tfrac{1}{2}\arcsin(x/(r\cos2\alpha)) \\
\end{split}
\end{equation}
\begin{figure}[t]
    \centering
    \vspace{7pt}
    \includegraphics[width=0.7\linewidth]{Img/eyetilt2.pdf}
    \caption{Function3. Optimization of the eye posture. It shows the the shift of the field of view (FoV). When the eyeball tilted $\theta_{\rm{tilt}}$, the FoV shifted $-2\theta_{\rm{tilt}}$ from the posterior pole.} 
    \label{fig:eyeballtilt}
\end{figure}
The maximum tilting angle is defined as $\pm$10 deg to minimize the movement of the trocars by tilting the eyeballs. %If the obtained $\alpha$ and $\beta$ exceed this threshold, these are set at the limit.
%In this work, we defined the maximum tilting angle as $\pm$10 deg, therefore, if the obtained $\alpha$ and $\beta$ exceed this threshold, these are set at the limit.

\subsection{Function4. Trocar selection and initial configuration}\label{sec: trocarselection}
This function selects the best trocar position to insert the instrument into the eye. Thereafter, the initial tilting angle of the robot and the configuration are also calculated. 
%the system will select the best trocar to insert the instrument and calculate the initial tilting angle and the configuration of the robot.

\subsubsection{Trocar selection}
As shown in Fig.\ref{fig:trocarselection}(b), the robot changes the position along the X-axis. Therefore, the best trocar is defined as the closest trocar to the target along the X-axis after tilting the eyeball.
When the initial positions of the trocar and the target are defined as $\vb{p}_{\rm{trocar}}$ and $\vb{p}_{\rm{target}}$, the positions after tilting the eyeball, $\vb{p}_{\rm{trocar2}}$ and $\vb{p}_{\rm{target2}}$ 
 (Fig.\ref{fig:trocarselection}(c)), can be calculated as follows.
\begin{equation}\label{eq:trocarshift}
\begin{split}
    \vb{p}_{\rm{trocar2}} &= roty(\beta)rotx(\alpha)\vb{p}_{\rm{trocar}}\\
    \vb{p}_{\rm{target2}} &= roty(\beta)rotx(\alpha)\vb{p}_{\rm{target}}\\
\end{split}
\end{equation}
There are three trocars, and all the positions after tilting are calculated, and the closest one along the X-axis is selected.
\subsubsection{Initial tilting angle}\label{sec: initialtilt}
The initial tilting angle ($\theta_{\rm{ini}}$) shown in Fig.\ref{fig:strategy}(c) is obtained from $\vb{v}_{\rm{trocar2target}}$. 
\begin{equation}\label{eq:trocar2target}
\begin{split}
    \vb{v}_{\rm{trocar2target}} &= \vb{p}_{\rm{target2}} - \vb{p}_{\rm{trocar2}}\\
\end{split}
\end{equation}
Considering projecting $\vb{v}_{\rm{trocar2target}}$ into 
the YZ plane, $\vb{v}_{\rm{rcm2target}}'$ (Fig.\ref{fig:trocarselection}(d)), $\theta_{\rm{ini}}$ can be calculated as follows. 
\begin{equation}\label{eq:RCMandFOV1}
\begin{split}
    &\theta_{\rm{ini}} = \arctan(\frac{v_{\rm{rcm2target},z}'}{v_{\rm{rcm2target},y}'})\\
\end{split}
\end{equation}

\subsubsection{Initial configuration}\label{sec:initialconfig}
In the previous section, the rotation around the X-axis was adjusted, while in this section, the rotation around the Y-axis is refined by optimizing the initial configuration of the surgical robot.
%In the previous section, the rotation around the X axis was adjusted and the rotation around the Y axis is adjusted in this section by optimizing the initial configuration of the surgical robot. 
This rotating angle ($\gamma$) is the angle between $\vb{v}_{\rm{trocar2target}}$ and $\vb{v}_{\rm{rcm2target}}'$ (Fig.\ref{fig:trocarselection}(d)) and this is obtained as follows. 
\begin{equation}\label{eq:RCMandFOV2}
\begin{split}
    &\gamma = \arccos(\frac{\vb{v}_{\rm{rcm2target}}\cdot\vb{v}_{\rm{rcm2target}}'}{|\vb{v}_{\rm{rcm2target}}||\vb{v}_{\rm{rcm2target}}'|})\\
\end{split}
\end{equation}
This function is responsible for moving the center of the robot's working angle to $\gamma$. 
The developed method is limited to our robot and is therefore described in Sec.\ref{sec:exfunction3-5}.
%In our robot, the rotational joint which is responsible for that is $\theta_2$ and this rotational angle is determined by the two linear actuator along the X axis in Fig\ref{fig:kinematics}(c).
%This function might be able to be adapted only to our robot. Our robot can adjust the working angle, which depends on the initial position of the robot. 
%The default initial position is the center of the stroke, and the stroke is $\pm$ 13.5 mm. To obtain the best initial position, the initial position is changed from -13.5 to +13.5 in 0.1 mm step, and the working angle and the center of the working angle are calculated each time, and then the position where the center of the working angle is the closest to $\gamma$ is selected.   

\begin{figure}[t]
    \centering
    \vspace{7pt}
    \includegraphics[width=1.0\linewidth]{Img/trocarchoice.pdf}
    \caption{Trocar selection and initial tilting angle. (a) 3D model of the eyeball with trocar and trocar after tilting. (b) Trocar selection. The closest trocar along the X-axis to the center of the target is selected. (c) Movement of the trocar and the target by the eye rotation. (d) Schematic diagram of $\vb{v}_{\rm{trocar2target}}$. $\vb{v}_{\rm{trocar2target}}'$ is the projected vector of $\vb{v}_{\rm{trocar2target}}$ into the YZ plane. } 
    \label{fig:trocarselection}
\end{figure}

\subsection{Function5. Target angle calculation}\label{sec:Target angle}
In this function, we assume pointing multiple targets (Fig.\ref{fig:trocarselection}(a)). After inserting the instrument into the eyeball, the surgical robot rotates the instrument $\theta_2$ and $\theta_4$ (Fig.\ref{fig:kinematics}) around the X and Y axes and moves it in the depth (Z) direction. These values are obtained in this function. In order to calculate the target angle of the robot, the initial vector ($\vb{v}_{\rm{ini}}$) and the target vector ($\vb{v}_{\rm{target}}$) after tilting the eyeball (Fig.\ref{fig:targetangle}) are obtained. $\vb{v}_{\rm{target}}$ can be obtained in same way as Sec.\ref{sec: trocarselection}.
The initial vector ($\vb{v}_{\rm{ini}}$) represents the vector of the instrument without any movement after the insertion. Therefore, this vector is a rotated vector in the Z-axis direction $\theta_{\rm{ini}}$ around the X-axis. 
%this is the vector obtained by rotating the vertical vector around the X axis by an angle $\theta_{\rm{ini}}$. 
%this vector is a rotated vector in the Z-axis direction $\theta_{\rm{ini}}$ around the X-axis. 
In order to simplify, $\vb{v}_{\rm{ini}}$ and  $\vb{v}_{\rm{target}}$ are rotated $\theta_{\rm{ini}}$ in reverse direction as shown in Fig.\ref{fig:targetangle}(b). Then, the rotated vector of $\vb{v}_{\rm{ini}}$,  $\vb{v}_{\rm{ini2}}$, will be in Z axis direction. 
The rotated vector $\vb{v}_{\rm{target2}}$ and $\vb{v}_{\rm{ini2}}$ are obtained as follows. 
\begin{equation}\label{eq:reverserotate}
\begin{split}
    &\vb{v}_{\rm{target2}} = rotx(\theta_{\rm{ini}})\vb{v}_{\rm{target}}\\
    &\vb{v}_{\rm{ini2}} = x\cdot \vb{v}_{\rm{z-unit}}   \\
\end{split}
\end{equation}
where $x$ is the variable and $\vb{v}_{\rm{z-unit}} = [0, 0, -1]^T$. $\vb{v}_{\rm{target2}}$ can also be obtained with $\theta_2$ and $\theta_4$ as follows.
\begin{equation}\label{eq:targetangle}
\begin{split}
    \vb{v}_{\rm{target2}} &= k\cdot rotx(\theta_4)roty(\theta_2)\vb{v}_{\rm{z-unit}}  \\
    &= k\cdot \begin{bmatrix}
    -\sin \theta_2 \\
    -\cos\theta_2\sin\theta_4 \\
    -\cos\theta_2\cos\theta_4 \\
    \end{bmatrix}\\
\end{split}
\end{equation}
$k$ represents the length of $\vb{v}_{\rm{target2}}$. From Eq.\ref{eq:reverserotate} and Eq.\ref{eq:targetangle}, $\theta_2$ and $\theta_4$ are derived.
\begin{equation}\label{eq:finalangle}
\begin{split}
    &k = |\vb{v}_{\rm{target2}}| \\
    &\theta2 = \arctan(v_{\rm{target2},y}/v_{\rm{target2},z})    \\
    &\theta4 = \arcsin(-v_{\rm{target2},x}/k)  \\
\end{split}
\end{equation}
The depth movement is obtained by Eq.\ref{eq:accessibility}, $\theta_2$ and $\theta_4$.
\begin{figure}[b]
    \centering
    \vspace{-5pt}
    \includegraphics[width=0.8\linewidth]{Img/targetanglecalc.pdf}
    \caption{Function5: Target angle calculation. $\vb{v}_{\rm{ini}}$ shows the instrument vector at the initial position. $\vb{v}_{\rm{ini}}$ is the RCM point to target vector. (b) shows the vector after rotating $\vb{v}_{\rm{ini}}$ around the $x$ axis.} 
    \label{fig:targetangle}
    \vspace{12pt}
\end{figure}

\section{Experimental Evaluation}
%The robot's accessibility is evaluated using an ocular model.
\subsection{Experimental setup}
The phantom eye model is developed with the 3D printer as shown in Fig.~\ref{fig:phantomeye}(b). The bottom part of the eyeball has a grid made of grooves (Fig.~\ref{fig:phantomeye}(c)), and this visualizes the position on the retina. The eye model can rotate around the X and Y axes, and the absolute encoders (AMT222B-V, CUI Devices) are mounted on both axes. The encoder's resolution is 14 bits, and the accuracy is 0.2 degrees. The center of the eye model is designed to keep the position with the different postures. The top part of the eye model contains holes in every $20$ degree to enable varying insertion points. The 3D-printed jig is also designed to keep the same eye model position for all experiments. 
% so that the eye model is put in the same position in every experiment.

\begin{figure}[b]
    \centering
    \vspace{-10pt}
    \includegraphics[width=0.8\linewidth]{Img/experimentalsetup3.pdf}
    \caption{(a) Experimental setup. (b)The eye model can be rotated around the X and Y axis, with absolute encoders mounted at the end of each axis. It has multiple insertion holes in the $20$ degrees step. The eye model can be replaced by other phantom eye. (c)The bottom part of the eye model has grooves on the inner side, which enables the measurement of the position of the fundus. The radial grooves are every $10$deg. Concentric grooves are every $5$deg.} 
    \label{fig:phantomeye}
    \vspace{12pt}
\end{figure}


\subsection{Experimental method and Result}
%Before explaining the experimental procedure, in the whole experiment, the function2 which detect the posture of the eye and the trocar is skipped and instead of that, the encoder and the phantom eye is used. 
Utilizing this eye phantom, the eye posture and trocar pose (Function 2), as discussed in Sec.\ref{sec: eyeposedetection}, are determined based on encoder data and the known geometries of the phantom.
At first, the functions1 and function3-5 are evaluated separately, and then, the whole workflow is evaluated.
\subsubsection{Function1}\label{sec: ex-function1}
Since taking the diagnostic image of the phantom eye is hard, the image right in front of the phantom eye is used, as shown in Fig.\ref{fig:experiment}, instead of the diagnostic image. The diagnostic image is a projected image of the fundus. Therefore, we consider that to be a substitute.
In this experiment, the diameter of the cornea is used as a reference to convert pixels to mm. An ellipse is manually fitted, and the center is also detected (Fig.\ref{fig:experiment}). The target position ($x$, $y$) is measured, and the 3D position of the target is obtained by Sec.\ref{sec: targetposcal}. The 3D reconstruction is done without considering the deviation of the visual axis and optical axis. In each experiment, five target points are defined, and all positions are calculated. The center of the target ($\theta_{\rm{center}}$, $\phi_{\rm{center}}$) is defined at the intersection of the grid and the rest four targets are defined at ($\theta_{\rm{center}}\pm$ 5 deg, $\phi_{\rm{center}}\pm$ 10 deg). This experiment is repeated four times.
As a result, the error is -1.65 $\pm$ 0.50 deg ($\theta$) and 0.81 $\pm$ 1.44 deg ($\phi$). 

\begin{figure}[t] 
    \centering
    \vspace{5pt}
    \includegraphics[width=0.9\linewidth]{Img/experiment.pdf}
    \caption{Validation of function1,3. The upper row is the grid phantom eye, and the lower row is the silicon phantom eye. The target and the working area after rotating the eyeball is also simulated. } 
    \label{fig:experiment}
\end{figure}

%\begin{tabular}{lrr}\hline
%     & $\theta$ & $\phi$ \\ \hline
% Mean error & -1.61 deg & 1.23 deg \\
% Standard deviation & 0.51 deg & 1.83 deg \\ \hline
%\end{tabular}

\subsubsection{Function3-5} \label{sec:exfunction3-5}
Before explaining the experiment, the method of initial configuration in Sec.\ref{sec: trocarselection} is described. In our robot, the rotational joint around the Y axis is $\theta_2$, and this rotational angle is determined by the two linear actuators along the X axis in Fig\ref{fig:kinematics}(b). Our robot can adjust its working angle by changing its initial position. 
The default initial position is the center of the stroke, and the stroke is $\pm$ 13.5 mm. To obtain the best initial position, the initial position is changed from -13.5 to +13.5 in 0.1 mm step, and the working angle and the center of the working angle are calculated each time, and then the position where the center of the working angle is the closest to $\gamma$ is selected.

In this experiment, the target position is directly defined in polar coordinates. First, the tilt angle is calculated by Function 3, and the phantom eye is manually tilted to within $\pm$ 0.1 deg of the obtained angle. The deviation between the target and the center of the ellipse fitted to the cornea is measured and compared with the calculation. 

Next, the initial configuration is done by function4, and the instrument is inserted, and the four target points are manually pointed with the joystick.
When the instrument reaches the target, the joint angle of the robot is collected and compared with the calculated value.
The whole process was repeated four times. As a result, the error of the function3 was 0.45 $\pm$ 0.21 mm, and the error of the function5 was 0.23 $\pm$ 0.99 deg ($\theta_2$), -0.91 $\pm$ 1.07 deg ($\theta_4$), and 0.68 $\pm$ 0.87 mm (Z). 

 
To evaluate the initial configuration in function4, the working angle of $\theta_2$ is also measured. When the center of the target position is defined at (150 deg, 140 deg) on the fundus as an example, $\gamma$ and the initial position is obtained at -4.19 deg and 5.90 mm respectively. The working angle ($\theta_2$) was measured before and after adjusting the initial position. Before the adjustment, the working angle was from -9.86 deg to 9.51 deg and the center of the working angle was -0.18 deg. After the adjustment, the working angle was from -13.88 deg to 5.39 deg and the center of the working angle was -4.25 deg. It is proved that the center of the working angle is shifted to the target position without decreasing the entire working angle by adjusting the initial position. 

\subsubsection{Function1,3-5}\label{sec:exfunction1,3-5}

%In the same way as Sec.\ref{sec: ex-function1},the target position is obtained and then, the phantom eye rotated to the calculated angle from function3 and initial configurations is done by function4 and the target points are manually pointed by the joystick. 
Four trials are conducted to evaluate the whole proposed workflow, and the error is 0.13 $\pm$ 1.65 deg ($\theta_2$), -1.40 $\pm$ 1.13 deg ($\theta_4$), and 1.80 $\pm$ 1.51 mm (Z).  
\subsubsection{Silicon phantom eye (Function1,3-5)}\label{sec:exphantomeye}
The experiment with a silicon phantom eye is also conducted (Fig.\ref{fig:experiment}). Cross marks are drawn on the fundus as targets. The intersection point of the cross mark is defined as the center of the target, and the edge of the cross mark is defined as a touching point. The whole process was executed as before and repeated four times. The trocars are manually planted each time. The error is 1.07 $\pm$ 2.98 deg ($\theta_2$), -0.90 $\pm$ 1.42 deg ($\theta_4$), and 2.05 $\pm$ 1.67 mm (Z). 



\section{Discussion and Future Work}
We demonstrated the effectiveness of our proposed method through various experiments, despite a certain range of errors. Since the acceptable error depends on factors such as the robot's working angle and the target area's size, establishing a general requirement seems challenging for acceptable error. Hence, discussing the potential error sources is a lead for future research.
Firstly, regarding the error source of the experiment in Sec.\ref{sec:exfunction3-5}, the 3D position of the target is directly defined, and the position of the insertion point and the pose of the eye model is known. Thus, the error sources are limited compared to actual surgery and are enumerated below.
\begin{enumerate}
  \item Alignment error between the robot and the eyeball around the Z axis
  \item Alignment error between the instrument and the trocar
  \item Kinematic error of the robot (attaching the instrument)
\end{enumerate}
In the actual surgery, the error will be added as follows.
%In the real surgery, the surgeon tilt the eyeball and plant the trocar by their hand. This can be the error source and the pose detection of the eye and the trocar can also be error source. Furthermore, the 3D reconstruction algorithm and the levelness of the microscope are also considered as error sources.
\begin{enumerate}[start=4]
  \item Placement and detection error of the trocar
  \item Tilting and detection error of the eye pose
  \item 3D reconstruction error (function1)
  \item Levelness of microscope image plane.
\end{enumerate}
The effect of the error(1), (2), (4), and (5) are analyzed as shown in Fig.\ref{fig:errorsourse}. For simplicity, the target points of the simulation for error(1), (4), and (5) are defined at ($\theta$, $\phi$) = (170 deg, 0 deg), (170 deg, 90 deg), (170 deg, 180 deg), (170 deg, 270 deg) and the center of the target is (180 deg, 0 deg). The input error is changed in [-10, -5, -2, -1, 0, 1, 2, 5, 10](deg), and the approximate straight line is fitted by the least-squares method. Considering the experiment in Sec.\ref{sec:exfunction3-5}, the both joint, $\theta_2$ and $\theta_4$ had error. From the analysis, the error(1) causes the error only in $\theta_2$. Therefore, the error is also caused by the error(2) or (3). Since the alignment error between the instrument and the trocar (2) is hard to simulate, it is simplified to the case that the parallel instrument and trocar are not aligned in a straight line and are separated by an error margin ($x_{\rm{error}}$) as shown in Fig.\ref{fig:errorsourse}-2. In this case, the instrument bends from the base of an instrument. Thus, the error ($\theta_{\rm{error}}$) is obtained as follows.
\begin{equation}\label{eq:error2}
\begin{split}
    &\theta_{\rm{error}} = \arctan(\frac{x_{\rm{error}}}{l_{\rm{instrument}}-l_{\rm{insert}}}) \\
\end{split}
\end{equation}
where $l_{\rm{instrument}}$ and $l_{\rm{insert}}$ are the instrument length and the insertion depth. $l_{\rm{instrument}}$ and $l_{\rm{insert}}$ are fixed at 35 mm and 20 mm and $x_{\rm{error}}$ is changed from -1.0 to 1.0. As shown in Fig.\ref{fig:errorsourse}(2), it is almost linear, and the error will be 1.91 deg when $x_{\rm{error}} = 0.5$ mm. This error can be occurred both in $\theta_2$ and $\theta_4$. Since the operator manually aligns the instrument, it is quite possible that this error will occur.
% Regarding the kinematic error(3), especially the error caused by attaching the instrument, this is also considered an error source in this experiment. However, this error can be considered not significant. Furthermore, this can be solved by improving the attachment mechanism. 

As for the experiment in Sec.\ref{sec:exfunction1,3-5}, the error was similar to that of the experiment in Sec.\ref{sec:exfunction3-5}. Hence, the error due to function 1 (error 6) is considered insignificant. 
In practice, however, the eyeball is not a perfect sphere, and the angle ($\kappa$) between the visual axis and optical axis varies from person to person. Furthermore, errors occur in the conversion from pixel to actual length. Therefore, a more accurate conversion method is required.
%However, in the actual case, the eyeball is not a perfect sphere, the angle between the visual axis and the optical axis ($\kappa$) differs from person to person, and the conversion from pixel to the actual length has also error. Therefore, a more accurate conversion method is required.

The experiments with silicon phantom eyeballs had larger errors than others (Sec:\ref{sec:exphantomeye}). The difference from the other experiment is the placement of the trocar. This error can be expressed as error in roll (Fig.\ref{fig:errorsourse}(4a)) and yaw (Fig.\ref{fig:errorsourse}(4b)). From the plots, the error in roll (4a) leads to the error in $\theta_4$, and the error in yaw (4b) leads to the error in $\theta_2$. As for the error in yaw (4b), there is usually a thorn at the end of the trocar holder for marking. Therefore, this error is smaller than the error in roll (4a), which is proved in Sec.\ref{sec:exphantomeye}. Furthermore, the instrument and trocar alignment is more difficult than in the previous experiment. This is also the reason why the error is larger than other experiments. In order to reduce the error, accurate eye pose detection and image guidance using AR and jigs for the alignment are required, and these will be the future work. In addition, optimization of trocar placement with AR guidance eliminates the need for three trocars and the initial positional configuration of the robot in Sec.\ref{sec:initialconfig}.

In the actual surgery, the eye posture is detected by image processing. Analysis of this error shows that the detection error of eye posture causes a larger error in the robot joint than other errors (Fig.\ref{fig:errorsourse}(5)). Therefore, a highly accurate eye posture detection method is required.
The microscopic image plane's levelness is also the visible area's error source. Hence, the calibration method to optimize the level of the microscopic image plane will also be required in the future.

\begin{figure}[t]
    \centering
    \vspace{5pt}
    \includegraphics[width=1\linewidth]{Img/errorsource.pdf}
    \caption{ The analysis of the error sources. In the plots, t2 means $\theta_2$ and t4 means $\theta_4$.} 
    \label{fig:errorsourse}
\end{figure}

 

\section{Conclusion}
This paper introduces a workflow for optimizing the eye posture, robot tilt, and insertion points depending on the target's position. The entire framework is explained and validated through experiments involving an eye model and a robot. The error of this workflow (Sec.\ref{sec:exfunction1,3-5}) was 0.13 $\pm$ 1.65 deg ($\theta_2$), -1.40 $\pm$ 1.13 deg ($\theta_4$), and 1.80 $\pm$ 1.51 mm (Z). 
The error sources are also discussed. The alignment of the trocar and instrument, as well as the placement of the trocar, etc, are identified as factors influencing the accuracy of the final target angle and the position. Therefore, highly accurate eye and trocar posture detection methods and methods for accurately inserting instruments into trocars are required in the future.
%Moreover, while our study primarily focuses on accessibility, controlling the injection angle for precise targeting becomes crucial for applications such as injections. In such cases, manipulation of the injection angle through eyeball rotation and insertion point adjustments will also be necessary.
%\todo{utilizing AR for trocar placement and guidance of eye posture, mapping the target in the eye.}
%\section{Acknowledgments}

\clearpage

\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}
