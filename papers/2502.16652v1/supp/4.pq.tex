\section{Search-time Experiments}
\label{pq}

In addition to its memory efficiency, Product Quantization significantly enhances search speed. Product quantization can approximate distances between vectors using quantized sub-vectors. By precomputing and storing distances between subvector centroids in a Look-Up Table (LUT), distance calculations between query and database vectors during the search phase are reduced to simple indexing operations. The precomputation shifts the complexity of vector distance calculations from $O(ND)$ for a $D$ dimensional vector to $O(N)$ per subvector.

Use of LUT can be described as follows. For trained PQ centroids $c_{lj}$, for $l = 1, 2, \dots L$, and $j= 1, ..., 2^k$, where $L$ is number of sub-vectors, and $k$ refers the number of bits used for indexing each centroids. LUT is stored as follows:
\begin{equation}
    \textrm{LUT}_{l}[i, j] = ||c_{li}-c_{lj}||_2^2, \textrm{where}\quad i, j \in \{1, 2, ... 2^k\}. 
\end{equation}
Then for vectors, $\mathbf{v}_1 = [\mathbf{v}_{11}, \ldots, \mathbf{v}_{1L}]$, $\mathbf{v}_2 = [\mathbf{v}_{21}, \ldots, \mathbf{v}_{2L}]$ mapped to indices $j_1=[j_{11}, j_{12}, ...,j_{1L}]$, and $j_2=[j_{21}, j_{22}, ...,j_{2L}]$, distance is computed as summation of each retrieved LUT values following each PQ indices:
\begin{equation}
    d(v_1, v_2) = \sum_{l=1}^L{\textrm{LUT}_l(j_{1l}, j_{2l})}.
\end{equation}

We can also compute the cosine similarity of the vectors, by computing inner products rather than distances, following normalization by the sum of each norm of each sub-vector. Despite the quantization errors, previous literature~\cite{product_quantization} shows that these errors remain within certain quantization bounds, preserving the correlation between the approximated and actual distances. 

The scalability and speed of the proposed approach make it particularly suitable for handling complex 3D data.
We compared search speed between computing cosine similarity of CLIP features and distance computation in product quantization (see~\Fref{fig:inf_speed}). Under identical hardware conditions, the proposed LUT-based approach demonstrated substantial speed improvements compared to cosine similarity computation between CLIP features: with a subvector size of 128, 64, 32  search performance improved by approximately 2$\times$, 6.6$\times$, 14.1$\times$ respectively.
These improvements underscore the computational advantages of the proposed method.

Considering that rendering-based methods require significantly greater computation compared to 3D data processing, \nickname's approach demonstrates its superior efficiency in search efficiency, and establishes itself as a practical and scalable solution for 3D data search and processing at scale.

\input{supp_figures/S4_inference_speed}
