\paragraph{Our Gaussian-friendly evaluation protocol}
To address these limitations, we propose a novel evaluation protocol to compute IoU from 3D Gaussians. Our evaluation protocol follows the original 3D Gaussian Splattings' optimization scheme~\cite{3dgs} by updating the location of the 3D Gaussians as well as the number of 3D Gaussians. After we obtain the optimized Gaussians~$\Theta$, these parameters are used to train language-embedded Gaussians. Then, the following question is how we assign the ground truth semantic labels for each Gaussian from the existing per-point semantic annotations provided by the ScanNet dataset~\cite{dai2017scannet}.

Starting from the given Q numbers of point cloud~$\mathcal{P} = \{ \mathbf{p}_k \}_{k=1}^{Q}$
and a set of semantic labels~$\mathcal{S} = \{ \mathbf{s} \}$,
we compose a paired set of points and their labels as $\{ \mathbf{p}_k, \mathbf{s}^{\mathbf{p}_k} \}_{k=1}^{Q}$,
which is provided by the official datasets. We measure the Mahalanobis distances between the language-embedded 3D Gaussian parameters $\Phi = \{ \theta_i, \mathbf{\tilde f}_i \}_{i=1}^N = \{ \bmu_i, S_i, R_i, \alpha_i, \mathbf{c}_i, \mathbf{\tilde f}_i \}_{i=1}^N$
(Sec. 2 of the manuscript) and ground truth point clouds. Note that the Mahalanobis distances is already used in the 3DGS~\cite{3dgs} when computing effective alpha values, as stated in the Eq. 1 of the manuscript. We maintain to use this equation to calculate the Mahalanobis distance~$\mathbf{d}^\text{mahal}(\cdot)$ between volumetric 3D Gaussian~$\theta$ and 3D point~$\mathbf{p}$ as:
\begin{equation}
    \mathbf{d}^\text{mahal}(\mathbf{p}, \theta) = (\mathbf{p}-\mu)^\top\mathbf{\Sigma}^{-1}(\mathbf{p}-\mu).
    \label{eq:mahalanobis_distance}
\end{equation}
Using the Mahalanobis distance, we determine the semantic label of each Gaussian as below:
\begin{equation}
    \mathbf{s}^{\theta_i} = \mathop{\arg\max}_{\mathbf{s} \in \mathcal{S}} \big( \sum_{\mathbf{p}_k \in \mathcal{P}} \mathbbm{1}{\{ \mathbf{s}^{\mathbf{p}_k} = \mathbf{s} \}} \cdot \mathbf{d}^\text{mahal}(\mathbf{p}_k, \theta_i) \big),
     \label{eq:pseudo_labeling_Gaussians}
\end{equation}
where $\mathbf{s}^{\theta_i}$ is the semantic label of the $i$-th 3D Gaussian~$\theta_i$, $\mathbbm{1}{\{ \mathbf{s}^{\mathbf{p}_k} = \mathbf{s} \}}$ is an indicator function returning $1$ only when $k$-th point label is identical to a semantic label $\mathbf{s} \in \mathcal{S}$. In shorts, this equation determines the semantic label of each 3D Gaussian from the specific semantic label~$\mathbf{s}$ that has the highest sum of the Mahalanobis distances from the ground truth point to each 3D Gaussian.

The proposed assignment process enables generally applicable evaluation of 3D Gaussians without any constraints. \cref{fig:metric_qualitative} shows the quality degradation of the trained scene following the OpenGaussian evaluation protocol, which fixes the position and the number of initial points during training. On the other hand, our generalizable evaluation protocol does not impose any constraints during the training of Gaussians, and it also enables high-quality scene reconstruction, effectively capturing detailed areas.

With the obtained $N$ number of pseudo GT 3D Gaussians, we measure IoU  by considering the volumetric significance of each Gaussian. We define the significant score $d_{i}$ for each Gaussian $\theta_i$ with its scale $\mathbf{s}_i = [s_{ix}, s_{iy}, s_{iy}]^\top$ and opacity $\alpha_i$ as $d_{i} = s_{ix}s_{iy}s_{iz} \alpha_i$ where $s_{ix}s_{iy}s_{iz}$ denotes a relative ellipsoid volume of a Gaussian $\theta_i$. With the obtained significant scores $\mathbf{d}=[d_1, d_2, ..., d_{N}]^\top$, we calculate IoU of $i$-th 3D Gaussians for the label as: 
\begin{equation}
    \begin{gathered}
        \text{Intersection}_i = \mathbf{d}\cdot(\mathbf{l}^{\text{pred}}_i \odot \mathbf{l}_i^{\text{gt}}),\\
        \text{Union}_i = \mathbf{d}\cdot (\mathbf{l}_i^{\text{pred}}+\mathbf{l}_{i}^{\text{gt}}-(\mathbf{l}_i^{\text{pred}} \odot \mathbf{l}_i^{\text{gt}})),\\
        \text{IoU}_i = {\text{Intersection}_i}/{\text{Union}_i},
    \end{gathered}
\end{equation}
where $\mathbf{l}_i^{\text{pred}} \in \mathbb{R}^N$ and $\mathbf{l}_i^\text{gt}\in \mathbb{R}^N$ are binary vectors indicating whether the predicted/GT label of each Gaussian is the $n$-th label,~$\mathbf{s}^{\theta}$ in~\cref{eq:pseudo_labeling_Gaussians}. The proposed metric is designed to assign a larger weight to the Gaussians with higher significant scores when measuring IoU, and the significant score endows our metric with volume-awareness.


\paragraph{Volume awareness of the proposed metric}
To validate that the proposed metric can effectively approximate the volumetric IoU of the 3D scene, we compare our metric with another volume-aware IoU measurement based on voxel representation. Before measuring IoU with voxels, we train 3D Gaussians and generate labeled pseudo-GT 3D Gaussians with \Eref{eq:pseudo_labeling_Gaussians}. Then we first sample voxels in the scene, and allocate a GT label to each voxel with the labeled 3D Gaussians. We obtain the most likely label of each voxel by defining the label score. The label score $l_{jn}^\text{voxel}$ is computed with the opacity $\alpha_i$ and the density $\mathcal{N}(\mathbf{v}_j | \bmu_i, \mathbf{\Sigma}_i)$ of each Gaussian at the position of a voxel $\mathbf{v}_j$ as:
\begin{equation}
    l_{jn}^\text{voxel} = \sum_{\theta_i \in \Theta}\alpha_i \cdot \mathbbm{1}\{\mathbf{s}^{\theta_i} = \mathbf{s}\} \cdot \mathcal{N}(\mathbf{v}_j | \bmu_i, \mathbf{\Sigma}_i),
    \label{eq:pseudo_labeling_voxels}
\end{equation}
where $\mathbbm{1}\{\mathbf{s}^{\theta_i} = \mathbf{s}\}$ is an indicator function determining whether a Gaussian $\theta_i$ is assigned to the $n$-th label and $\text{det}(\mathbf{\Sigma}_i)$ is the determinant of $\mathbf{\Sigma}_i$. With the obtained score, we first filter out empty voxels by thresholding with: $p_j = \sum_{n=1}^{L}l^\text{voxel}_{jn}$, where $L$ is the total number of the labels, which can be interpreted as a density of each voxel $\mathbf{v}_j$. Then we assign a label with the highest score, as the GT label of each voxel. We can also generate predicted labels of voxels using the predicted labels of Gaussians in the same manner, and can evaluate IoU by comparing the GT and predicted labels of the voxels one-to-one.

Volume awareness is inherent in this voxel-based IoU evaluation as the voxels explicitly represent the volume of the scene. We show the volume-awareness of our evaluation metric by showing a correlation between our metric and voxel-based metric in \Fref{fig:metric_correlation}. As can be seen, our metric obtains a high correlation with the voxel-based IoU evaluation metric by considering the significant score when calculating IoU. This result shows the necessity of the significant score, which endows our metric with volume awareness.

Although the voxel-based IoU evaluation effectively measures volume-aware IoU of the scene, the computational cost to assign labels is too expensive. Each time new labels of Gaussians are predicted, the process of assigning them to the voxels is required for evaluation. Different from voxel-based IoU evaluation, our IoU evaluation protocol has a low computational cost, since there is no repeated assignment process after we once generate the labeled pseudo-GT Gaussians. In other words, our proposed IoU evaluation protocol is a fast and volume-aware evaluation for measuring the IoU of scenes represented by 3D Gaussians.  