\subsection{Product-Quantized CLIP embeddings}
\label{subsec:4_2}

Memory efficiency is a challenge in 3D scene representations, especially when associating Gaussians with high-dimensional feature vectors. LangSplat~\cite{langsplat} addresses this by introducing an encoder-decoder network, while LeGaussian~\cite{legaussian} and OpenGaussian~\cite{open_gaussian} utilize codebook construction. However, these approaches introduce additional per-scene computational costs for scene-specific parameter tuning of neural networks or codebooks (see \cref{fig:teaser}). In contrast, we propose to use Product Quantization (PQ) on a large-scale image dataset, eliminating per-scene training.
