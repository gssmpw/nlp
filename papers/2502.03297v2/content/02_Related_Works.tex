\section{Related Work}

\subsection{Teleoperation-Based Data Collection on Real Robots}

Collecting data using tele-operation on real robots has been explored by many previous works. Aloha \cite{zhao2023learning} introduced a low-cost teleoperation system that collects real-world demonstrations for imitation learning. A bimanual workspace is set up, where leader robots are used to control the follower robots. Followup work \cite{aldaco2024aloha} improved the performance, ergonomics, and robustness compared to the original design. In addition, a mobile version of Aloha \cite{fu2024mobile} improved data collection outside of lab settings. GELLO \cite{wu2023gello} supports a variety robot arms through a 3D-printed low-cost leader robots with off-the-shelf motors. In order to tele-operate dexterous end effectors prior work has retrieved hand motion data through visual hand tracking \cite{Qin2023AnyTeleopAG} or customized gloves \cite{wang2024dexcap}. In contrast to IRIS, none of these approaches leverages the immersive advantages of XR.

\subsection{XR-Based Data Collection in Real World}

% A major disadvantage of tele-operation using controllers or leader robots is that, for each different kinematics of the target robot, a specialized physical control device has to be built.
% To tackle this issue, some XR-based teleoperation methods have been proposed, exploiting immersive approaches for real-world interactions with robots.
Common approaches that combine XR-based tele-operation with real-world interactions typically visualize a virtual robot to show the user how human actions are mapped to robot actuation \cite{Qin2023AnyTeleopAG}. For instance, recent work developed mobile apps to allow data collection in augmented reality without the need for XR headsets \cite{ar2-d2-pmlr-v229-duan23a, eve}. However, leveraging XR headsets, allows for more intuitive robot manipulation~\cite{arcade,armada,jiang2024comprehensive}.
% , e.g., by aligning a virtual robot arm with the user's arm.
Instead of displaying the virtual robot in a third-person view, \citet{opentelevision, openteach} directly provide the first-person camera feed of the real robot to the user.
% \citet{opentelevision} and \citet{openteach} provide the camera view from real robots directly instead of displaying a virtual robot.
Many other systems~\cite{vicarios,augmentedvisualcues,wang2024robotic,immertwin,sharedctlframework,digitaltwinmr} visualize the real-world scene in the headset and control the robot arm either with controllers~\cite{sharedctlframework} or hand tracking~\cite{wang2024robotic}.
XR-based data collection for dexterous hands has also been explored. For example, \citet{arunachalam2023holo} tracks hand motion using camera and retargets it on the real robot hand. \citet{chen2024arcap} controls robot hand and robot arm at the same time. While these approaches do use XR, the robot data collection and interaction is limited to the real world, as no simulators used in the process.

% \textcolor{red}{More work about MR/VR/AR}

% \subsection{Robot Learning by Interaction}

% \textcolor{red}{what is the combination of demonstration and correction??? Interaction is not a good word}

% \textcolor{red}{a big table of comparison to other AR robot data collection}

\subsection{XR-Based Data Collection in Simulation}

Collecting data using real robots has many limitations, such as limited scene and object diversity. For gathering demonstrations more efficiently and opening access to numerous virtual 3D assets, some works have explored fully virtual data collection.
For instance, DART \cite{dexhub-park} runs a cloud-based simulation, and users can collect demonstrations in any virtualized environment from any location. \citet{mosbach2022accelerating} collects dexterous hand manipulation data with a special glove device in physics simulations.
Although \citet{meng2023virtual} also leverages simulators, their virtual scene is a replica of the real scene, thus the flexibility of simulation is not fully exploited.

This discussion reveals that state-of-the-art, XR-based data collection in simulation has barely been explored. Hence, IRIS presents a significant contribution towards immersive robot data collection and interaction. IRIS not only supports almost all popular simulation environments, but also connects seamlessly with robots in the real world, opening up enormous possibilities in human-involved robot learning in both virtual and real-world settings.