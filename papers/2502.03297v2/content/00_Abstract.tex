\clearpage
\newpage

 \begin{abstract}

% Generalist robots require high-quality data to improve their capabilities.
% This paper proposes X2R, an Extended Reality system for robot data collection in both simulation and real world scenario.
% Current XR-based data collection systems provide efficient and intuitive approaches to collect large scale data
% however, with three key limitations: 
% limited availability of task-specific assets, restricted adaptability across multiple simulation environments or real-world scenarios, and constraints in supporting multi-human interactions.
% X2R can tackle these issues by providing an universal scene description and a communication protocol between XR and simulation device. 
% The universal scene description generates a general scene model format directly from simulation engines, enabling it to support all kinds of objects, assets, and robots in simulation, including deformable objects.
% This framework also extends to real-world data collection by replacing simulation objects with point clouds, facilitating real robot data collection and teleoperation.
% Additionally, X2R provides a robust communication protocol to support multiple XR headsets sharing the same scene, enabling collaborative data collection.
% Through a comprehensive test in real-world scenarios and simulation engines, including MuJoCo, IsaacSim, CoppeliaSim, and Genesis,
% X2R demonstrates a great potential for various robot learning scenarios.

% This paper introduces X2R, an Extended Reality (XR) system designed for robot data collection across multiple simulators and real-world scenarios.
% While current XR-based data collection systems offer efficient and intuitive solutions for large-scale data collection,
% they face three key limitations: restricted availability of task-specific assets, limited adaptability across diverse simulation environments or real-world applications, and insufficient support for multi-human collaboration of data collection.
% X2R addresses these challenges through the universal scene description and the communication protocol.
% The universal scene description enables the generation scene models directly from simulation engines, supporting a wide range of rigid and deformable objects, assets, and robots from all kinds of simulators.
% This functionality seamlessly extends to real-world data collection by substituting simulation objects with point clouds, facilitating real robot data collection and teleoperation.
% Furthermore, the communication protocol and shared spatial anchor of X2R allows multiple XR headsets to share the same scene, enabling collaborative and multi-user data collection.
% In this paper, a wide range of application scenario was tried out cross real-world scenarios and current popular robot simulation engines such as MuJoCo, IsaacSim, CoppeliaSim, and Genesis. which showcases X2Rs versatility and potential for diverse robot learning applications.
% In the user study of collecting demonstration for LIBERO benchmark,
% X2R significantly outperform the baseline method in both objective metrics and subjective metrics.
% For the real world experiment, X2R also achieved a really high success rate comparing to non-XR method.

%%%%%%%%%%%%%%%%
%%%% Pre Rudi
%%%%%%%%%%%%%%%%
% This paper introduces X2R, an Extended Reality (XR) framework designed for robot data collection across multiple simulators, benchmarks and real-world scenarios.
% While existing XR-based data collection systems provide efficient and intuitive solutions for large-scale data collection, they are often challenging to reproduce and reuse.
% This problem arises from one key limitations: simulator-dependency.
% Current systems are highly tailored to simulator-specific use cases and environments.
% X2R represents a novel, easily extendable framework that already supports multiple simulators, benchmarks and even headsets.
% Furthmore, X2R is able to include additional information from real world sensors, such as point clouds captured through depth cameras.
% A unified scene specification is generated directly from simulators or real-world sensors and transmitted to XR headsets, for creating identical scenes in Extended Reality. This specification allows X2R to support any of the objects, assests and robots provided by the simulators.
% In addition, X2R introduces shared spatial anchors and a robust communication protocol that links simulations between multiple XR headsets.
% This feature enables multiple XR headsets to share a synchronized scene, facilitating collaborative and multi-user data collection.
% X2R can be deployed on any device that supports the Unity Framework, encompassing the vast majority of commercially available headset.
% In this work, X2R was deployed and tested on the Meta Quest 3 and the HoloLens 2.
% X2R showcased its versatility across a wide range of real-world and simulated scenarios, using current popular robot simulators such as MuJoCo, IsaacSim, CoppeliaSim, and Genesis.
% In addition, a user study evaluates X2R on a data collection task for the LIBERO benchmark.
% The study shows that X2R significantly outperforms the baseline in both objective metrics and subjective metrics.
% This paper shows the enormous potential that X2R provides for the future of data collection in the robotics and robot learning community.
% All the relevant code and software packages are available online at xxxxx.

% a wide range of application scenario was tried out cross real-world scenarios and current popular robot simulation engines such as MuJoCo, IsaacSim, CoppeliaSim, and Genesis. which showcases X2R's versatility and potential for diverse robot learning applications.

% A user study regarding the collection of demonstrations for the LIBERO benchmark further evaluated X2R's ,
% X2R significantly outperform the baseline method in both objective metrics and subjective metrics.

% For the real world experiment, X2R also achieved a really high success rate comparing to non-XR teleoperation.



% such as rigid and soft body manipulation, collaborative manipulation, embodied data collection, interactive reinforcement learning, and real-world data collection.
% A user study is conducted to evaluate t 

% \todo{User Study in libero or shall we conduct have real world user study? since we probably don't have time for real world user study}

% we introduce Interactive Robots Extended Reality,
% an Extended Reality Data Collection Framework for diverse robot data collection scenarios.

%%%%%%%%%%%%%%%%%%%
%%% Post Rudi
%%%%%%%%%%%%%%%%%%%
% This paper introduces X2R, an Extended Reality (XR) framework designed for robot data collection across multiple simulators, benchmarks, and real-world scenarios.
% While existing XR-based data collection systems provide efficient and intuitive solutions for large-scale data collection, they are often challenging to reproduce and reuse.


This paper introduces IRIS, an Immersive Robot Interaction System leveraging Extended Reality (XR). IRIS was
designed for immersive robot data collection and interaction across multiple simulators, benchmarks, and real-world scenarios.
While existing XR-based data collection systems provide efficient and intuitive solutions for large-scale data collection, they are often challenging to reproduce and reuse.
This limitation arises because current systems are highly tailored to simulator-specific use cases and environments.
IRIS is a novel, easily extensible framework that already supports multiple simulators, benchmarks, and even headsets.
Furthermore, IRIS is able to include additional information from real-world sensors, such as point clouds captured through depth cameras.
An unified scene specification is generated directly from simulators or real-world sensors and transmitted to XR headsets, creating identical scenes in XR. This specification allows IRIS to support any of the objects, assets, and robots provided by the simulators.
In addition, IRIS introduces shared spatial anchors and a robust communication protocol that links simulations between multiple XR headsets.
This feature enables these XR headsets to share a synchronized scene, facilitating collaborative and multi-user data collection.
IRIS can be deployed on any device that supports the Unity framework, encompassing the vast majority of commercially available headsets.
In this work, IRIS was deployed and tested on the Meta Quest 3 and the HoloLens 2.
IRIS showcased its versatility across a wide range of real-world and simulated scenarios, using current popular robot simulators such as MuJoCo, IsaacSim, CoppeliaSim, and Genesis.
In addition, a user study evaluates IRIS on a data collection task for the LIBERO benchmark.
The study shows that IRIS significantly outperforms the baseline in both objective and subjective metrics.
This paper demonstrates the huge potential that IRIS provides for the future of data collection and interaction in the robotics and robot learning community.
The code, videos, and documentation can be found from the project link(\url{https://intuitive-robots.github.io/iris-project-page/}).

\end{abstract}