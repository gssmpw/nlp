\section{Technical Details}

\subsection{Mujoco}
\label{app:mujoco}

MuJoCo \cite{todorov2012mujoco} is a fast, accurate physics engine ideal for simulating robots with complex joint structures and contact dynamics.
It supports advanced robot simulations with features like customizable actuators, collision detection, and friction modeling, enabling realistic testing of robotic control, manipulation, and learning algorithms in dynamic environments.

When starting a MuJoCo simulation, MuJoCo provides a model instance and a data instance.
The scene specification of IRIS can be generated from the model, while the simulation states can be retrieved from the data instance.
The model instance contains all the necessary assets for the scene specification, including meshes, textures, and materials. 
These assets are stored as NumPy arrays and need to be converted to byte streams with data types such as \textit{float32} or \textit{int8} for transmission.

MuJoCo uses a standard robotic coordinate system, where X is forward, Y is left, and Z is up. This differs from Unity's coordinate system, where X is right, Y is up, and Z is forward.
Therefore, object transforms, mesh vertices, faces, and normal data must be adapted for Unity using the following code:

\begin{lstlisting}[language=Python]
def mj2unity_pos(pos: List[float]) -> List[float]:
    return [-pos[1], pos[2], pos[0]]

def mj2unity_quat(quat: List[float]) -> List[float]:
    return [quat[2], -quat[3], -quat[1], quat[0]]
\end{lstlisting}

Since MuJoCo includes visual group settings that specify which object groups can be visualized, IRIS provides an API to support this feature through the \textit{MujocoPublisher} definition, as shown below:

\begin{lstlisting}[language=Python]
class MujocoPublisher(ScenePublisher):

    def __init__(
        self,
        mj_model,
        mj_data,
        host: str = "127.0.0.1",
        no_rendered_objects: Optional[List[str]] = None,
        no_tracked_objects: Optional[List[str]] = None,
        visible_geoms_groups: Optional[List[int]] = None,
    ) -> None:
\end{lstlisting}

\subsection{IsaacSim}

IsaacSim~\cite{nvidia_isaac_sim} is a robotics simulation environment based on the NVIDIA Omniverse platform~\cite{nvidia_omniverse}.
Several frameworks \cite{mittal2023orbit,gong2023arnold} are built on top of it, sharing the same underlying data structures.
IsaacSim supports ray-tracing for realistic rendering, and batched physics simulation on GPUs, significantly accelerating the training of models.

The scenes in IsaacSim are organized in a Universal Scene Description (USD) format, and data can be accessed directly with the OpenUSD API \cite{pixarUSD}.
The scene hierarchy consists of transformations (Xform), meshes, articulations (joints) among other elements. Figure~\ref{fig:isaacsim-tree} illustrates a sample scene hierarchy.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{image/isaacsim/isaacsim_scene_structure.png}
    \caption{An example of USD scene hierarchy for Franka Panda robot arm in IsaacSim.}
    \label{fig:isaacsim-tree}
\end{figure}

Besides the low-level OpenUSD API, IsaacSim also provides some utility APIs for accessing scene data. In our system, we use a mix of both APIs. A (simplified) code snippet for accessing parsing the tree structure of the USD scene is given below. We use the OpenUSD API \texttt{GetChildren()} to retrieve child primitives here.

\begin{lstlisting}[language=Python]
# compute local transforms of the current prim
trans, rot, scale = self.compute_local_trans(root)

# parse material and geometry
mat_info = self.parse_prim_material(prim=root)
self.parse_prim_geometries(
    prim=root,
    prim_path=prim_path,
    sim_obj=sim_object,
    mat_info=mat_info or inherited_material,
)

# parse children of the current prim
for child in root.GetChildren():
    if obj := self.parse_prim_tree(
        root=child,
        parent_path=prim_path,
        inherited_material=mat_info or inherited_material,
    ):
        sim_object.children.append(obj)
\end{lstlisting}

Here is another snippet for computing the world transform of a primitive in the hierarchy. Instead of computing the world transform with OpenUSD API, the class in IsaacSim API \texttt{XFormPrim} is used to simplify the code.

\begin{lstlisting}[language=Python]
from pxr import Usd
from omni.isaac.core.prims import XFormPrim

def compute_world_trans(self, prim: Usd.Prim):
    prim = XFormPrim(str(prim.GetPath()))
    assert prim.is_valid()

    pos, quat = prim.get_world_pose()
    scale = prim.get_world_scale()

    return (
        pos.cpu().numpy(),
        quat_to_rot_matrix(quat.cpu().numpy()),
        scale.cpu().numpy(),
    )
\end{lstlisting}

\subsection{CoppeliaSim}
CoppeliaSim, formerly known as V-REP, is a versatile and widely used robot simulation software that supports various physics engine backbones. Scenes in CoppeliaSim are constructed using a tree structure, which includes objects such as visual shapes, dynamic shapes, and joints, as illustrated in Figure \ref{fig:coppliasim-tree}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{image/coppeliasim/CoppeliaSim_Tree.png}
    \caption{An example of a tree structure for building an ABB IRB4600 manipulator.}
    \label{fig:coppliasim-tree}
\end{figure}

In our system, we interact with CoppeliaSim using Python APIs. Depending on the version of CoppeliaSim, we utilize two groups of Python API functions:

\textbf{ZeroMQ Remote API} \footnote{https://manual.coppeliarobotics.com/en/apiFunctions.htm}. This is an official API introduced in version 4.4. It facilitates fast and straightforward communication between the simulator and a Python script, enabling users to efficiently build scenarios. For example, to retrieve mesh information for all shape objects in a CoppeliaSim scene, one can use the following call:
\begin{lstlisting}[language=Python, caption=Example ZeroMQ Remote API.]
from coppeliasim_zmqremoteapi_client import RemoteAPIClient
client = RemoteAPIClient()
sim = client.require('sim')

list_vertices, list_indices, list_normals = [], [], []

objects_id_list = sim.getObjectsInTree(sim.handle_scene, 
                                       sim.handle_all, 0)

for idx in objects_id_list:
    if sim.getObjectType(idx) == sim.sceneobject_shape:
        # We assume all the shapes are primary shapes
        vertices, indices, normals = sim.getShapeMesh(idx)
        
        list_vertices.append(vertices)
        list_indices.append(indices)
        list_list_normals.append(normals)
\end{lstlisting}


\textbf{PyRep API}\cite{james2019pyrep} \footnote{https://github.com/stepjam/PyRep}. This is a widely-used third-party Python communication interface under the CoppeliaSim version 4.1. Several notable CoppeliaSim projects and benchmarks, such as RLBench \cite{james2020rlbench}, are built on this interface. Similar to the official interface, PyRep provides various API functions and properties. For instance, to retrieve all object handles from a CoppeliaSim scene, one can use the following call:
\begin{lstlisting}[language=Python, caption=Example PyRep API.]
from pyrep.backend.sim import simGetObjectsInTree
from pyrep.backend.sim import simGetObjectType
from pyrep.backend.sim import simGetShapeMesh
from pyrep.backend.simConst import sim_handle_scene
from pyrep.backend.simConst import sim_handle_all
from pyrep.backend.simConst import sim_object_shape_type

list_vertices, list_indices, list_normals = [], [], []

objects_id_list = simGetObjectsInTree(sim_handle_scene, 
                                      sim_handle_all, 0)

for idx in objects_id_list:
    if simGetObjectType(idx) == sim_object_shape_type:
        # We assume all the shapes are primary shapes
        vertices, indices, normals = simGetShapeMesh(idx)
        
        list_vertices.append(vertices)
        list_indices.append(indices)
        list_list_normals.append(normals)

\end{lstlisting}



\subsection{Genesis}

Genesis \cite{Genesis} is a versatile physics platform designed for robotics, embodied AI, and physical AI applications. It combines a universal, re-engineered physics engine capable of simulating diverse materials and phenomena with a lightweight, ultra-fast, and user-friendly robotics simulation environment. It also features a powerful, photorealistic rendering system and a generative data engine that transforms natural language prompts into multi-modal data. By integrating various physics solvers within a unified framework, Genesis supports automated data generation through a generative agent framework, with its physics engine and simulation platform now open-source and further expansions planned.

IRIS supports Genesis by providing a Genesis parser designed to translate simulation data from the Genesis physics platform into the IRIS framework's internal representation.
It manages this by reading rigid entities, links, and geometries from a \textit{gs.Scene} object and converting them into equivalent IRIS structures such as \textit{SimScene}, \textit{SimObject}, \textit{SimVisual}, and \textit{SimMaterial}. Here's a detailed breakdown of the parsing process and its components:

The main function initializes a \textit{SimScene} and iterates through all entities in the Genesis scene.
It builds a hierarchical scene graph based on parent-child relationships between entities and links. The graph is stored in the hierarchy dictionary, which tracks each object's parent and child nodes.

Each rigid entity (\textit{RigidEntity}) from Genesis is processed to create a \textit{SimObject}. The position and rotation of the entity are retrieved and transformed is similart to Mujoco (\ref{app:mujoco}) to ensure compatibility with Unity's coordinate system.
If the Genesis scene is already built, the function pulls actual position and rotation data; otherwise, it defaults to identity transforms.

Links (RigidLink) represent individual parts of a rigid entity's structure. Each link is converted into a \textit{SimObject} and positioned within the scene based on its parent link's position and orientation.
If the link has associated visual geometries (\textit{vgeoms}), the parser processes each visual element to create \textit{SimVisual} objects, which store geometry and material data. Links without visual elements are simply added to the scene hierarchy without rendering.

Visual geometries (\textit{RigidGeom}) from Genesis are mapped to IRIS visual representations. The parser constructs a \textit{SimVisual} object, including position, rotation, and mesh data.
The mesh generation function extracts vertex and face data from the Genesis mesh and constructs a \textit{SimMesh} object for the IRIS scene, defining both the physical and visual structure of the geometry. Genesis leverages the \textit{Trimesh} \cite{trimeshTrimeshTrimesh} library to handle mesh processing, which simplifies the conversion to the IRIS mesh format.

After processing all entities, the parser organizes the parsed objects into a tree structure. Objects without parents are attached to the root of the scene, while others are linked to their respective parents based on the hierarchy dictionary.




\subsection{Real World}

\input{appendix/real_world_appendix}

\subsection{Affiliated Monitoring Tools}
The dashboard depicted in \ref{fig:webapp} is designed to complement the IRIS Framework by providing streamlined access to the functionality offered by XR devices. Additionally, it facilitates the rendering of the scene to a web-based canvas, enabling real-time viewing of the scene as it is being streamed.

Due to the limitations of web services, which cannot directly interface with underlying protocols such as UDP and ZMQ, this website is unable to directly connect to the IRIS server. To bridge this gap, a Python-based endpoint is deployed, which hosts the website, relays the rendering data to the web application, and forwards user commands from the interface back to the server.

Communication between the endpoint and the website is facilitated through a WebSocket connection. This setup allows the system to support multiple instances of the dashboard simultaneously, ensuring scalability. The scene rendering itself is accomplished using Three.js, a powerful JavaScript library that renders to an HTML5 canvas object through WebGL. The Python endpoint is responsible for converting the IRIS scene format into commands, which are then transmitted over the WebSocket connection. These commands are subsequently translated into high-level Three.js function calls to render the scene.

This high-performance rendering system makes it possible to display even highly complex scenes on lower-end machines. Notably, only the server hosting the web application needs to install the necessary software, enabling all connected devices to access the interface without requiring any additional installations.

To minimize latency between the initial connection and the start of rendering, primitive objects are placed in the scene immediately upon receipt by the endpoint. Larger resources, such as meshes, materials, and textures, are streamed into the scene asynchronously to prevent delays or interruptions in the rendering process.

 