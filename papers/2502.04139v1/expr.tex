\subsection{Experimental Setup}
\textbf{Dataset and Metrics.}
We conduct our experiments on ScanNetV2~\cite{dai2017scannet}, ScanNet200~\cite{rozenberszki2022language}, ScanNet++~\cite{yeshwanth2023scannet++} and S3DIS~\cite{armeni20163d} datasets.
%
ScanNetV2 includes 1,613 scenes with 18 instance categories.
%
Among them, 1,201 scenes are used for training, 312 scenes are used for validation, and 100 scenes are used for test. ScanNet200 employs the same point cloud data, but it enhances annotation diversity, covering 200 classes, 198 of which are instance classes. ScanNet++ contains 460 high-resolution (sub-millimeter) indoor scenes with dense instance annotations, including 84 distinct instance categories.
%
S3DIS is a large-scale indoor dataset collected from six different areas.
%
It contains 272 scenes with 13 instance categories.
%
Following previous works~\cite{lai2023mask}, the scenes in Area 5 are used for
validation and the others are for training.
%
AP@25 and AP@50 represent the average precision scores with IoU thresholds 25\% and 50\%,
%
and mAP represents the average of all the APs with IoU thresholds ranging from 50\% to 95\% with a step size of 5\%.
%
On ScanNetV2, we report mAP, AP@50 and AP@25.
%
Moreover, we also report the Box AP@50 and AP@25 results following SoftGroup~\cite{vu2022softgroup} and DKNet~\cite{wu20223d}.
%
On ScanNet200 and ScanNet++, we report mAP, AP@50 and AP@25.
%
On S3DIS, we report AP@50 and AP@25.

\textbf{Implementation Details.}
\label{Implementation}
On ScanNetV2, we train our model on a single RTX3090 with a batch size of 8 for 512 epochs. We employ Maft~\cite{lai2023mask} as the baseline architecture, with the backbone and transformer decoder layers identical to Maft's.
%
We employ AdamW~\cite{loshchilov2017decoupled} as the optimizer and PolyLR as the scheduler, with a maximum learning rate of 0.0002.
%
Point clouds are voxelized with a size of 0.02m.
%
For hyperparameters, we tune $\mathcal{S}, L, K, \mathcal{D}_1, \mathcal{D}_2$ as 400, 400, 3, 40, 3 respectively.
$\lambda_1 ,\lambda_2 ,\lambda_3 ,\lambda_4 ,\lambda_5$ in Equation~\ref{lall} are set as 0.5, 1, 1, 0.5, 0.5.
%
Additional implementation details for other datasets are presented in the supplemental materials.
\subsection{Comparison with existing methods.}
\textbf{Results on ScanNetV2.}
Table~\ref{table:ScanNetV2} reports the results on ScanNetV2 validation and hidden test set.
%由于我们的方法设计了Agent-Interpolation Initialization Module 将 combines FPS and learnable vectors 以获取更strong位置、comtent信息。以及采用了Hierarchical Query Fusion decoder to  aid in recall rate，our method outperforms other state-of-the-art methods by a large margin on mAP by 1.8, AP@50 by 3.0 AP@25 by 3.2.
Due to our method's design of the Agent-Interpolation Initialization Module, which combines FPS with learnable queries to acquire stronger position and content information, as well as the adoption of the Hierarchical Query Fusion Decoder to enhance recall rate, our approach significantly outperforms other transformer-based methods, achieving an increase in mAP by 3.3, AP@50 by 3.6, AP@25 by 2.0, Box AP@50 by 1.4 and Box AP@25 by 1.1 in the validation set, and a rise in mAP by 2.8, AP@50 by 3.6 in the hidden test set. To vividly illustrate the differences between our method and others, we visualize the qualitative results in Figure~\ref{compare}. From the regions highlighted in red boxes, it is evident that our method can generate more accurate predictions.

\begin{table}[!t]
  \begin{center}
    \footnotesize
    \setlength\tabcolsep{3pt}
    \vspace{-1em}
    \caption{\textbf{Comparison on ScanNetV2 validation and hidden test set.} The second and third rows are the non-transformer-based and transformer-based methods, respectively.}
    \label{table:ScanNetV2}
    %\vspace{-1em}
    % \normalsize
    \begin{tabular}{c|ccccc|cc}
      \toprule
      \multirow{2}*{Method} &  \multicolumn{5}{c|}{ScanNetV2 validation} &  \multicolumn{2}{c}{ScanNetV2 test}\\
       & mAP & AP@50 & AP@25 & Box AP@50 & Box AP@25 & mAP & AP@50 \\
      \midrule
      %F-PointNet~\cite{qi2018frustum}   & / & / & /  & 10.8 & 19.8 \\
      %GSPN~\cite{yi2019gspn}             & /  & 37.8 & 53.4 & 17.7 & 30.6\\
      3D-SIS~\cite{hou20193d}  & / & 18.7 & 35.7 & 22.5 & 40.2 &16.1 &38.2\\
      %VoteNet~\cite{qi2019deep}              & / & / & / & 33.5 & 58.6 \\
      3D-MPA~\cite{engelmann20203d}     & 35.3 & 51.9 & 72.4 & 49.2 & 64.2 &35.5 &61.1\\
      DyCo3D~\cite{he2021dyco3d}     & 40.6 & 61.0 & / & 45.3 & 58.9 &39.5 &64.1\\
      PointGroup~\cite{jiang2020pointgroup}         & 34.8 & 56.9  & 71.3 & 48.9 & 61.5  &40.7 &63.6\\
      MaskGroup~\cite{zhong2022maskgroup}         & 42.0 &  63.3  & 74.0 & / & / &43.4 & 66.4\\
      OccuSeg~\cite{han2020occuseg}         &  44.2 & 60.7  & / & / & /  &48.6 &67.2\\
      HAIS~\cite{chen2021hierarchical}                     & 43.5 & 64.4  & 75.6 & 53.1 & 64.3 &45.7 &69.9\\
      SSTNet~\cite{liang2021instance}                     & 49.4 & 64.3  & 74 & 52.7 & 62.5 &50.6 &69.8\\
      SoftGroup~\cite{vu2022softgroup}                     & 45.8 & 67.6  & 78.9 & 59.4 & 71.6 &50.4 &76.1\\
      DKNet~\cite{wu20223d}                     & 50.8 & 66.9  & 76.9 & 59.0 & 67.4&53.2&71.8\\   
      ISBNet~\cite{ngo2023isbnet} & 54.5 &73.1 &82.5 & 62.0 &78.1&55.9 &75.7\\   
      Spherical Mask~\cite{shin2024spherical} &\textbf{62.3} &\textbf{79.9} &\textbf{88.2}&/&/&\textbf{61.6}& \textbf{81.2} \\
      \midrule
      Mask3D~\cite{schult2022mask3d}            & 55.2 & 73.7  & 82.9 & 56.6 & 71.0 &56.6& 78.0\\
      QueryFormer~\cite{lu2023query}     & 56.5 & 74.2  & 83.3 &61.7& 73.4& 58.3 &78.7\\
      SPFormer~\cite{sun2023superpoint}     & 56.3 & 73.9  & 82.9 &/& / & 54.9 &77.0\\
      Maft~\cite{lai2023mask}     & 58.4 & 75.9  & 84.5 &63.9& 73.5 &57.8 &77.4\\
      Ours &\textbf{61.7 } & \textbf{79.5 } &  \textbf{86.5} & \textbf{65.3 }&  \textbf{74.6} & \textbf{60.6}&\textbf{81.0}\\
      \bottomrule
    \end{tabular}
    \vspace{-1.2em}
  \end{center}
\end{table}

\textbf{Results on ScanNet++.}
Table~\ref{table:ScanNetpp} presents the results on ScanNet++ validation and hidden test set. The notable performance enhancement underscores the efficacy of our method in handling denser point cloud scenes.
%
\begin{table}[!t]
  \begin{center}
    \footnotesize
    \setlength\tabcolsep{3pt}
    \vspace{-1em}
   \caption{\textbf{Comparison on ScanNet++ validation and hidden test set.} ScanNet++ contains denser point cloud scenes and wider instance classes than ScanNetV2, with 84 distinct instance classes.}
    \label{table:ScanNetpp}
    %\vspace{-1em}
    % \normalsize
    \begin{tabular}{c|ccc|ccc}
    \toprule 
    \multirow{2}*{Method} &  \multicolumn{3}{c|}{ScanNet++ validation} &  \multicolumn{3}{c}{ScanNet++ test}\\
    & mAP & AP@50 & AP@25 & mAP & AP@50 & AP@25\\
    \midrule
    PointGroup~\cite{jiang2020pointgroup}  & /&/&/&8.9&14.6 &21.0 \\
    HAIS~\cite{chen2021hierarchical} & /&/&/ & 12.1&19.9 &29.5 \\
    SoftGroup~\cite{vu2022softgroup}&/ & /&/&16.7&29.7 &38.9 \\
    Maft~\cite{lai2023mask}	&23.1	&32.6	&39.7&20.9	&31.3	&40.4\\
    Ours &\textbf{25.3}	&\textbf{35.2}	&\textbf{42.6}& \textbf{22.2} & \textbf{32.8} &\textbf{42.5} \\
    \bottomrule
  \end{tabular}
    \vspace{-1.2em}
  \end{center}
\end{table}

\textbf{Results on ScanNet200.}
Table~\ref{table:ScanNet200} reports the results on ScanNet200 validation set. The significant performance improvement demonstrates the effectiveness of our method in handling such complex scenes with a broader range of categories. 
\begin{figure}[!tbp]
\vspace{-1em}
  \begin{floatrow}[2]
  \tablebox{\caption{\textbf{Comparison on ScanNet200 validation set.} ScanNet200 employs the same point cloud data as ScanNetV2 but enhances more annotation diversity, with 198 instance classes.}
  }{%
  \label{table:ScanNet200}
  \centering
  \scalebox{0.76}{\begin{tabular}{c|ccc}
    \toprule 
    Method & mAP & AP@50& AP@25 \\
    \midrule
    SPFormer~\cite{sun2023superpoint} & 25.2&33.8 &39.6 \\
    Mask3D~\cite{schult2022mask3d} & 27.4&37.0 &42.3 \\
    QueryFormer~\cite{lu2023query} & 28.1&37.1 &43.4 \\
    Maft~\cite{lai2023mask} &29.2 & 38.2 &43.3 \\
    Ours & \textbf{30.5 } & \textbf{40.0 } &\textbf{44.8 } \\
    \bottomrule
  \end{tabular}}
  \vspace{-0.8em}
  }
  \tablebox{\caption{\textbf{Effectiveness of the Agent-Interpolation Initialization Module.}  We evaluate the performance of the first layer predictions on ScanNetV2 validation set.}
  }{%

  \label{table:first}
  \centering
  \scalebox{0.76}{
    %\vspace{1em}
    % \normalsize
    \begin{tabular}{c|c|ccc}
      \toprule
      Method &  Recall@50 & mAP &AP@50&AP@25 \\
      \midrule
      Learnable-based&  82.4 &  39.8 &  51.8  & 58.8  \\
      FPS-based &  83.8 &  39.2 &  51.4  & 58.5  \\
      Ours &   \textbf{84.1} &\textbf{43.1}  & \textbf{55.7}   &\textbf{62.7}   \\
      \bottomrule
    \end{tabular}}
  \vspace{-0.8em}
  }
  %\vspace{-0.6em}
  \end{floatrow}
  \vspace{-1.8em}
\end{figure}
% \begin{table}[!t]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{3pt}
%     \vspace{-1em}
%     \caption{\textbf{Comparison on ScanNet200 validation set.}}
%     \label{table:ScanNet200}
%    \begin{tabular}{c|ccc}
%     \toprule 
%     Method & mAP & AP@50& AP@25 \\
%     \midrule
%     SPFormer~\cite{sun2023superpoint} & 25.2&33.8 &39.6 \\
%     Mask3D~\cite{schult2022mask3d} & 27.4&37.0 &42.3 \\
%     QueryFormer~\cite{lu2023query} & 28.1&37.1 &43.4 \\
%     Maft~\cite{lai2023mask} &29.2 & 38.2 &43.3 \\
%     Ours & \textbf{30.5 } & \textbf{40.0 } &\textbf{44.8 } \\
%     \bottomrule
%   \end{tabular}
%     \vspace{-1.2em}
%   \end{center}
% \end{table}

% \begin{table}[!t]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{1.2pt}
%     % \vspace{-0.8em}
%     \caption{\textbf{Comparison on ScanNet200 validation set.}}
%     \label{table:ScanNet200}
%     \vspace{-0.13em}
%     % \normalsize
%     \begin{tabular}{c|ccc}
%       \toprule 
%       Method & mAP & AP@50& AP@25 \\
%       \midrule
%       SPFormer & 25.2&33.8 &39.6 \\
%       Mask3D & 27.4&37.0 &42.3 \\
%       QueryFormer & 28.1&37.1 &43.4 \\
%       Maft &29.2 & 38.2 &43.3 \\
%       Ours & \textbf{30.5} & \textbf{40.0} &\textbf{44.8} \\
%       \bottomrule
%     \end{tabular}
%     % \vspace{-2em}
%   \end{center}
% \end{table}

%
% \begin{table}[!t]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{1.2pt}
%     % \vspace{-0.8em}
%     \caption{\textbf{Comparison on ScanNet++ test set.}}
%     \label{table:ScanNetpp}
%     \vspace{-0.13em}
%     % \normalsize
%     \begin{tabular}{c|ccc}
%       \toprule 
%       Method & mAP & AP@50& AP@25 \\
%       \midrule
%       PointGroup & 8.9&14.6 &21.0 \\
%       HAIS& 12.1&19.9 &29.5 \\
%       SoftGroup& 16.7&29.7 &38.9 \\
%       Ours & \textbf{21.3} & \textbf{31.6} &\textbf{41.5} \\
%       \bottomrule
%     \end{tabular}
%     % \vspace{-2em}
%   \end{center}
% \end{table}
\begin{figure}[!tbp]
%\vspace{-0.6em}
  \begin{floatrow}[2]
  \vspace{2em}
  \figurebox{\caption{\textbf{Visualization of instance segmentation results on ScanNetV2 validation set. }The red boxes highlight the key regions.}}{%
    \label{compare}
    \includegraphics[width=6cm]{graph/compare1.pdf}
    \vspace{-0.8em}
    }
  \tablebox{\caption{\textbf{Comparison on S3DIS Area5.} S3DIS contains 13 instance
categories. }}{%
  \label{table:S3DIS}
  \centering
    \scalebox{0.8}{\begin{tabular}{c|cc}
      \toprule 
      Method & AP@50& AP@25 \\
      \midrule
      PointGroup~\cite{jiang2020pointgroup} & 57.8 &/ \\
      MaskGroup~\cite{zhong2022maskgroup} & 65.0 &/ \\
      SoftGroup~\cite{vu2022softgroup} & 66.1 &/ \\
      SSTNet~\cite{liang2021instance} & 59.3 &/ \\
      SPFormer~\cite{sun2023superpoint} & 66.8 &/ \\
      Mask3D~\cite{schult2022mask3d} & 68.4 &75.2 \\
      QueryFormer~\cite{lu2023query} & 69.9 & /\\
      Maft~\cite{lai2023mask} & 69.1& 75.7 \\
      Ours & \textbf{71.9}&\textbf{77.8}\\
      \bottomrule
    \end{tabular}}
    \vspace{-0.8em}
    }
  \end{floatrow}
  \vspace{-1em}
\end{figure}

% \begin{table}[!t]
%   \begin{minipage}{0.48\textwidth}
%     \vspace{-0.8em}
%     \begin{minipage}[c]{0.48\textwidth}
%       \centering
%       \captionof{table}{\textbf{Comparison on S3DIS Area5.}}
%       \label{table:S3DIS}
%       \setlength\tabcolsep{3pt}
%       \scalebox{0.8}{\begin{tabular}{c|cc}
%         \toprule 
%         Method & AP@50& AP@25 \\
%         \midrule
%         PointGroup & 57.8 &/ \\
%         MaskGroup & 65.0 &/ \\
%         SoftGroup & 66.1 &/ \\
%         SSTNet & 59.3 &/ \\
%         SPFormer & 66.8 &/ \\
%         Mask3D & 68.4 &75.2 \\
%         QueryFormer & 69.9 & /\\
%         Maft & 69.1& 75.7 \\
%         Ours & \textbf{71.4}&\textbf{77.1}\\
%         \bottomrule
%       \end{tabular}}
%       \end{minipage}
%       \begin{minipage}[c]{0.48\textwidth}
%       \centering
%       \captionof{figure}{\textbf{Visualization of instance segmentation results on the ScanNetV2 validation set. }The red boxes highlight the key regions.}
%       \label{compare}
%       \includegraphics[width=7cm]{graph/compare.pdf}
%     \end{minipage}
%     \end{minipage}
% \end{table}
% \begin{figure}[!ht]
%   \begin{center}
%       \includegraphics[width=0.95\textwidth]{graph/compare.pdf}
%       \caption{\textbf{Visualization of instance segmentation results on the ScanNetV2 validation set. }The red boxes highlight the key regions.}
%       \label{compare}
%       \vspace{-1em}
%   \end{center}
% \end{figure}
% \begin{table}[!t]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{1.2pt}
%     % \vspace{-0.8em}
%     \caption{\textbf{Comparison on S3DIS Area5.}}
%     \label{table:S3DIS}
%     \vspace{-0.13em}
%     % \normalsize
%     \begin{tabular}{c|cc}
%       \toprule 
%       Method & AP@50& AP@25 \\
%       \midrule
%       PointGroup & 57.8 &/ \\
%       MaskGroup & 65.0 &/ \\
%       SoftGroup & 66.1 &/ \\
%       SSTNet & 59.3 &/ \\
%       SPFormer & 66.8 &/ \\
%       Mask3D & 68.4 &75.2 \\
%       QueryFormer & 69.9 & /\\
%       Maft & 69.1& 75.7 \\
%       Ours & \textbf{71.4}&\textbf{77.1}\\
%       \bottomrule
%     \end{tabular}
%     % \vspace{-2em}
%   \end{center}
% \end{table}
% \vspace{1.2em}
\textbf{Results on S3DIS.}
We evaluate our method on S3DIS using Area 5 in Table~\ref{table:S3DIS}. Our proposed method achieves superior performance compared to previous methods, with large margins in both AP@50 and AP@25, demonstrating the effectiveness and generalization of our method.


\subsection{Ablation Studies}

\textbf{Evaluation of the model with different designs.}
\begin{figure}[!tbp]
  \vspace{-1.2em}
  \begin{floatrow}[2]
  \tablebox{\caption{\textbf{Evaluation of the model with different designs on ScanNet-v2 validation set.} AI2M refers to the Agent-Interpolation Initialization Module. HQFD indicates that the Hierarchical Query Fusion Decoder. NMS refers to Non-Maximum Suppression. }}{%
  \label{table:ablation}
  \scalebox{0.76}{\begin{tabular}{ccc|ccc}
      \toprule
      % \hline
      AI2M & HQFD & NMS  & mAP & AP@50 &AP@25\\
      \midrule
      \ding{55}&\ding{55}&\ding{55}& 58.4&75.2&83.5  \\
      % \hline
     
      \ding{51}&\ding{55}&\ding{55}& 60.1&78.2&85.6	\\

      \ding{55}&\ding{51}&\ding{55}&60.3&77.9&85.3\\
      % \hline
      \ding{51}&\ding{51}&\ding{55}&61.1&78.2&85.6\\
      \ding{55}&\ding{55}&\ding{51}&59.0 &76.1 &84.3\\
      \ding{51}&\ding{55}&\ding{51}&60.5 &78.7 &85.7\\
      \ding{55}&\ding{51}&\ding{51}&60.9&78.1&85.7 \\
      \ding{51}&\ding{51}&\ding{51}	&\textbf{61.7}&\textbf{79.5} &\textbf{86.5}
      \\
      % \hline
      % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
      % \hline
      \bottomrule
  \end{tabular}}
  \vspace{-0.8em}
  }
  \tablebox{\caption{\textbf{Ablation study on $\mathcal{S}$, $L$ and $K$ of the Agent-Interpolation Initialization Module.} $\mathcal{S}$ refers to the number of sampled points. $L$ represents the number of agents. $K$ represents the number of neighbours.}}{%
  \label{table:slk}
  \scalebox{0.76}{\begin{tabular}{ccc|ccc}
      \toprule
      % \hline
      $\mathcal{S}$ &$L$ &$K$ & mAP & AP@50 &AP@25\\
      \midrule
      
      400 &400&1&61.3& 78.7&85.4 \\
      400 &400&3&\textbf{61.7} &\textbf{79.5} &86.5 \\
      400 &400&8&61.3&79.3&\textbf{86.9} \\
      400 &800&8&61.2& 78.9&86.7 \\
      400&200&3&60.7&78.0&86.1\\
      200&400&3&59.8&77.3&85.0\\
      600&400&3&60.5&77.5&84.7\\
      %600&800&3&&&\\
      \bottomrule
  \end{tabular}}
  \vspace{-0.8em}
  }
  \end{floatrow}
\end{figure}
To further study the effectiveness of our designs, we conduct ablation studies on ScanNet-v2 validation set. 
As shown in the Table~\ref{table:ablation}, the second row shows that with the help of AI2M, our model acquire a better position and content information, achieving a performance gain of 1.7, 3.0 in mAP and AP@50.
The third row demonstrates that with the help of query fusion in HQFD, a performance gain of 1.9, 2.7 has been achieved in mAP and AP@50. The fourth row demonstrates the effective collaboration between AI2M and HQFD, resulting in performance improvement. The last four rows show that with the assistance of NMS, some spurious predictions can be filtered out, leading to enhanced performance.
%第四行则展示了AI2M和HQFD可以很好的合作，一起给性能带来提升。最后两行则展示了在NMS的帮助下，可以滤除部分荣誉预测，提高性能。
%

\textbf{Effectiveness of the Agent-Interpolation Initialization Module.}
%如table所示，with the help of the Agent-Interpolation Initialization Module，初始queries的前景覆盖率得到了提升，因而第一层预测的召回率得到了提升，整体性能也得到了提升
%相较于Learnable-based方法，可以显著看出召回率提升较为明显，进而带来性能提升。相较于fps-based的方法，虽然第一层的召回率区别不大，但是由于有着更强的content information，所以在性能上提升很多。
As shown in Table~\ref{table:first}, with the assistance of the Agent-Interpolation Initialization Module, there has been an improvement in the foreground coverage of initial queries, subsequently leading to an increase in the recall rate of the first layer predictions, thus enhancing overall performance. Compared to learnable-based methods, it is evident that the recall rate has significantly improved, leading to performance enhancement. Conversely, in comparison to FPS-based methods, although there isn't a substantial difference in the recall rate of the initial layer, the presence of stronger content information contributes to a notable enhancement in performance.
% \begin{table}[!t]
% \vspace{-0.8em}
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{1pt}
%     \caption{\textbf{Effectiveness of the Agent-Interpolation Initialization Module.}  We evaluate the performance of the first layer predictions on ScanNetV2 validation set.\vspace{-1em}}
%     \label{table:first}
%     %\vspace{1em}
%     % \normalsize
%     \begin{tabular}{c|c|ccc}
%       \toprule
%       Method &  Recall@50 & mAP &AP@50&AP@25 \\
%       \midrule
%       Learnable-based&  82.4 &  39.8 &  51.8  & 58.8  \\
%       FPS-based &  83.8 &  39.2 &  51.4  & 58.5  \\
%       Ours &   \textbf{84.1} &\textbf{43.1}  & \textbf{55.7}   &\textbf{62.7}   \\
%       \bottomrule
%     \end{tabular}
%     \vspace{-1.2em}
%   \end{center}
% \end{table}

\textbf{Ablation study on $\mathcal{S}$, $L$ and $K$ of the Agent-Interpolation Initialization Module.}
As depicted in Table~\ref{table:slk}, it can be inferred that for $\mathcal{S}$, $L$ and $K$, an intermediate value often yields superior results, specifically when set at $\mathcal{S}$=400, $L$=400, and $K$=3. Also, it can be observed that $\mathcal{S}$ and $L$ have a relatively large impact on the results, similar to the conclusions of previous studies~\cite{schult2022mask3d,lai2023mask}. In contrast, $K$ has a minimal effect on the results, demonstrating the robustness of our method with respect to $K$.

\textbf{Effectiveness of the Hierarchical Query Fusion Decoder.}
%在这个section，我们将做多组实验验证Hierarchical Query Fusion Decoder的有效性以及泛化能力。首先，如table第二列所示，我们在baseline基础上加上HQFD会带来最终输出queries数目的提升，我们对比了相同数目下baseline性能和baseline+hqfd性能。第二行结果说明了，简单增加query数目不仅不会带来性能的提升，还会带来性能的下降，这与第三行我们方法的结果正好相反。这证明了我们的方法的性能提升并不是来源于query数目的提升，而是真真切切来源于保有较高的召回率，which can be证明in figure i（b）。我们也展示了将 outputs of each layer concatenating的性能in third row， 相关称述 is in 第三段section\ref{sec:intro}。结果上说明简单采取COE的操作无法给性能带来提升，我们这种渐进式保留较低overlap query的方式可以给性能带来较大提升。
In this section, we conduct multiple experiments to validate the effectiveness and generalization ability of the Hierarchical Query Fusion Decoder (HQFD). Firstly, as shown in the second column of the Table~\ref{table:Num}, adding HQFD on top of the baseline leads to an increase in the final output queries count. However, this increase is limited and has minimal impact on computational load.
%
Next, we compare the performance of the baseline and the baseline enhanced with HQFD under the same number of queries.
%
The second row of results indicate that simply increasing the number of queries not only does not improve performance but also leads to a slight decrease in performance, which is in contrast to the results of our method in the fifth row. This demonstrates that the performance improvement of our method does not stem from an increase in the number of queries but rather from maintaining a higher recall rate, as can be evidenced in Figure~\ref{motivation} (b). We also report the performance of baseline+COE in the third and fourth rows, and the relevant description is in the third paragraph of Section~\ref{sec:intro}. Results suggest that simply adopting the COE operation does not enhance performance, but leads to a decline. Our method of progressively retaining queries with low overlap can significantly improve performance.

%为了说明hqfd的泛化能力，我们在别的方法上也添加了hqfd，如table{table:generalization}所示。在spformer和maft上的性能提升有效说明了我们方法可以作为一个即插即用的插件用于其他Transformer-based方法上
To demonstrate the generalization capability of HQFD, we also add HQFD to other methods, as shown in Table~\ref{table:generalization}. The performance improvement on SPFormer and Maft effectively demonstrates that our method can serve as a plug-and-play module for other transformer-based methods.

\begin{figure}[!tbp]
\vspace{-1.2em}
  \begin{floatrow}[2]
  \tablebox{\caption{\textbf{Effectiveness of the Hierarchical Query Fusion Decoder.} Num refers to the number of queries. COE refers to concatenating the outputs of each layer and then conducting NMS.}
  }{%
  \label{table:Num}
  \scalebox{0.83}{\begin{tabular}{c|c|ccc}
    \toprule
    % \hline
    Strategy& Num & mAP & AP@50 &AP@25\\
    \midrule
    Baseline &400& 58.4&75.2&83.5\\
    Baseline &520&58.4&75.1&83.2\\
    Baseline+COE &400&57.3 & 73.5& 81.8\\
    Baseline+COE&520 &57.4 &74.1& 81.8\\
    Baseline+HQFD &520 & \textbf{60.3} & \textbf{77.9} &\textbf{85.3}\\ 
    % \hline
    % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
    % \hline
    \bottomrule
  \end{tabular}}
  \vspace{-0.8em}
  }
  \tablebox{ \caption{\textbf{Generalization of the Hierarchical Query Fusion Decoder.} The symbol $\dagger$ indicates the results obtained after adding the NMS operation.}
  }{%
  \label{table:generalization}
  \scalebox{0.78}{\begin{tabular}{c|ccc}
    \toprule
    % \hline
    Method&  mAP & AP@50 &AP@25\\
    \midrule
    $\text{SPFormer}^\dagger$~\cite{sun2023superpoint}  & 57.2 &75.9& 83.5\\
    $\text{SPFormer}^\dagger$+HQFD &59.4&77.8&85.5\\
    $\text{Maft}^\dagger$~\cite{lai2023mask} & 59.0 &  76.1 &  84.3 \\
    $\text{Maft}^\dagger$+HQFD &\textbf{60.9} & \textbf{78.1} &\textbf{85.7}\\ 
    % \hline
    % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
    % \hline
    \bottomrule
  \end{tabular}}
  \vspace{-0.8em}
  }
  \end{floatrow}
\end{figure}

% \begin{table}[!h]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{5pt}
%     \centering
%     \caption{\textbf{Effectiveness of the Hierarchical Query Fusion Decoder.} Num refers to the number of queries. COE refers to concatenating outputs of each layer.}
%     \label{table:Num}
%     \begin{tabular}{c|c|ccc}
%       \toprule
%       % \hline
%       Strategy& Num & mAP & AP@50 &AP@25\\
%       \midrule
%       Baseline &400& 59.8&77.4&85.4\\
%       Baseline &520&58.4&75.3&83.9\\
%       Baseline+COE &400&58.1&74.6&82.7\\
%       Baseline+HQFD &520 & \textbf{60.9} & \textbf{78.1} &\textbf{85.7}\\ 
%       % \hline
%       % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
%       % \hline
%       \bottomrule
%     \end{tabular}
%     %\vspace{-1em}
%   \end{center}
% \end{table}

% \begin{table}[!h]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{5pt}
%     \centering
%     \caption{\textbf{Different category clustering methods in the Hierarchical Pseudo-Label Generator.}}
%     \label{table:clustering}
%     \begin{tabular}{c|ccc}
%       \toprule
%       % \hline
%       Strategy& mAP & AP@50 &AP@25\\
%       \midrule
%       Baseline&59.8&77.4&85.4\\
%       Combine all masks &58.1&74.6&82.7\\
%       HQFD w/o mask reinput & 59.8&77.6&85.5\\
%       HQFD&\textbf{60.9} & \textbf{78.1} &\textbf{85.7}\\
%       % \hline
%       % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
%       % \hline
%       \bottomrule
%     \end{tabular}
%     %\vspace{-1em}
%   \end{center}
% \end{table}

% \begin{table}[!h]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{5pt}
%     \centering
%     \caption{\textbf{Generalization of the Hierarchical Query Fusion Decoder.} The symbol $\dagger$ indicates the results obtained after adding the NMS operation.}
%     \label{table:generalization}
%     \begin{tabular}{c|ccc}
%       \toprule
%       % \hline
%       Method&  mAP & AP@50 &AP@25\\
%       \midrule
%       $\text{SPFormer}^\dagger$  & 57.8 & 76.9  & 85.2\\
%       $\text{SPFormer}^\dagger$+HQFD &59.4&77.8&85.5\\
%       $\text{Maft}^\dagger$& 59.8&77.4&85.4 \\
%       $\text{Maft}^\dagger$+HQFD &\textbf{60.9} & \textbf{78.1} &\textbf{85.7}\\ 
%       % \hline
%       % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
%       % \hline
%       \bottomrule
%     \end{tabular}
%     %\vspace{-1em}
%   \end{center}
% \end{table}

% \begin{figure}[!t]
%   \begin{center}
%       %\vspace{-1.1em}
%       \includegraphics[width=0.95\textwidth]{graph/DM.pdf}
%       \vspace{-1em}
%       \caption{\textbf{Visualization of the effectiveness of the Dependency Module.}
%       In (a), (b), we use all superpoints as the query, and use the superpoints after FPS as the key. In (c), (d), we visualize the attention weights of query and key, and the redder the color, the higher the similarity. For clarity, we restore the downsampled superpoint to its original resolution in (c), (d).}
%       \label{DF}
%   \end{center}
% \end{figure}

% \begin{table}[!ht]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{5pt}
%     \centering
%     \caption{\textbf{Evaluation of the model with different designs on ScanNet-v2 validation set.} DM refers to Dependency Module. 2D Branch indicates that the pseudo labels generated by 2D branch are used to supervise the network. HPLG refers to the Hierarchical Pseudo-Label Generator. }
%     \label{table:d1d2}
%     \begin{tabular}{cc|ccc}
%       \toprule
%       % \hline
%       $\mathcal{D}_1$ & $\mathcal{D}_2$& mAP & AP@50 &AP@25\\
%       \midrule
%       50 &2&61.4& 78.9&86.1 \\
%       50 &3&61.3 &78.8 &86.0 \\
%       50 &4&61.0& 78.5&85.6 \\
%       40 &3&\textbf{61.7} &\textbf{79.5} &\textbf{86.5} \\
%       60 &3&61.1& 78.5&85.5 \\
%       % \hline
%       % \ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&\ding{51}&55.11&37.94&65.43&48.81\\
%       % \hline
%       \bottomrule
%     \end{tabular}
%   \end{center}
% \end{table}
\begin{figure}[!tbp]
% \vspace{-0.8em}
  \begin{floatrow}[2]
  \tablebox{\caption{\textbf{Parameter and runtime analysis of different methods on ScanNetV2 validation set.}  The runtime is measured on the
    same device.}}{%
  \label{table:RuntimeAnalysis}
  \centering
    \scalebox{0.75}{
    %\vspace{1em}
    % \normalsize
    \begin{tabular}{c|c|cc}
      \toprule
      Method &  Parameter(M) & Runtime(ms) \\
      \midrule
      HAIS~\cite{chen2021hierarchical} & 30.9 & 578 \\
      SoftGroup~\cite{vu2022softgroup} & 30.9 &588\\
      SSTNet~\cite{liang2021instance} & /& 729 \\
      Mask3D~\cite{schult2022mask3d} & 39.6 & 578 \\
      QueryFormer~\cite{lu2023query} & 42.3 & 487 \\
      SPFormer~\cite{sun2023superpoint} & 17.6 & 430 \\
      Maft~\cite{lai2023mask} & 20.1 & 412 \\
      Ours & 20.3 & 444 \\
      \bottomrule
    \end{tabular}}
    \vspace{-0.8em}}
    \figurebox{\caption{\textbf{The convergence curve under different settings on ScanNet-v2 validation set.}%It can be seen from the figure that with only 128-epoch training, ours outperforms the baseline trained with 512 epochs.
    }}{%
    \label{figure:acceleration}
    \includegraphics[width=6cm]{graph/curve.pdf}\vspace{-0.8em}}
    
  \end{floatrow}
  \vspace{-1em}
\end{figure}


%\textbf{Ablation study on $\mathcal{D}_1$ and $\mathcal{D}_2$ of the Hierarchical Query Fusion Decoder.}
% As illustrated in Table~\ref{table:d1d2}, optimal performance can be achieved when $\mathcal{D}_1$=40 and $\mathcal{D}_2$=3.

\textbf{Contribution to the convergence speed.}
As shown in Figure~\ref{figure:acceleration}, with only 128-epoch training, our method outperforms the baseline trained with 512 epochs. This can be attributed to AI2M ensuring high foreground coverage of initial queries, along with HQFD ensuring a steady increase in recall during the decoding process.
% \begin{table}[!ht]
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{5pt}
%     \centering
%     \caption{\textbf{The proportion and accuracy of annotations generated by 2D and 3D branches.} 2D, 3D HP refers to high-confidence pseudo-labels generated by 2D, 3D branchs. MP indicates the medium-confidence pseudo-labels. GT refers to the ground truth.}
%     \label{table:pseudo-labels}
%     \begin{tabular}{c|c|c}
%       \toprule
%       % \hline
%       Setting &Proportion & Accuracy\\
%       \midrule
%       2D HP &7.6\%$\pm$1\%&98\%$\pm$0.5\% \\
%       3D HP &47.8\%$\pm$2\%&97\%$\pm$0.6\%  \\
%       2D+3D MP &21.4\%$\pm$1.3\%&89.3\%$\pm$0.5\%  \\
%       GT &23.1\%$\pm$1\%&100\%  \\
%       \bottomrule
%     \end{tabular}
%   \end{center}
% \end{table}



% \begin{figure}[!ht]
%   \begin{center}
%       \includegraphics[width=0.95\textwidth]{graph/HPLG.pdf}
%       \caption{\textbf{Comparison of precise and
%       broad category prediction.} (a), (b), (c) represent the results under the setting of precise category, while (d), (e), (f) represent that under the setting of broad category in the Hierarchical Pseudo-Label Generator.}
%       \label{HPLG}
%   \end{center}
%   \vspace{-1.3em}
% \end{figure}




\subsection{Parameter and Runtime Analysis.}
% \begin{table}[!ht]
% \vspace{-0.8em}
%   \begin{center}
%     \footnotesize
%     \setlength\tabcolsep{1pt}
%     \caption{\textbf{Parameter and runtime analysis of different methods on ScanNetV2 validation set.}  The runtime is measured on the
%     same RTX 3090 GPU.}
%     \label{table:RuntimeAnalysis}
%     %\vspace{1em}
%     % \normalsize
%     \begin{tabular}{c|c|cc}
%       \toprule
%       Method &  Parameter(M) & Runtime(ms) \\
%       \midrule
%       HAIS~\cite{chen2021hierarchical} & 30.9 & 578 \\
%       SoftGroup~\cite{vu2022softgroup} & 30.9 &588\\
%       SSTNet~\cite{liang2021instance} & /& 729 \\
%       Mask3D~\cite{schult2022mask3d} & 39.6 & 578 \\
%       QueryFormer~\cite{lu2023query} & 42.3 & 487 \\
%       SPFormer~\cite{sun2023superpoint} & 17.6 & 430 \\
%       Maft~\cite{lai2023mask} & 20.1 & 412 \\
%       Ours & 20.3 & 444 \\
%       \bottomrule
%     \end{tabular}
%     \vspace{-1.2em}
%   \end{center}
% \end{table}
Table~\ref{table:RuntimeAnalysis} reports the model parameter and the runtime per scan of
different methods on ScanNetV2 validation set. 
%
For a fair comparison, the reported runtime is measured on the
same RTX 3090 GPU.
%
Compared with Maft, our method achieves noticeable performance improvement with a 0.2M parameter increment.
%
As to the inference speed, our method is faster than most methods.
%这有力的证明了我们方法的有效性
Performance, parameter efficiency, and speed collectively demonstrate our method's efficacy, practicality, and applicability.

% \subsection{Limitations and Future Work}
% \label{Limitations}
% %BFL的query初始化方式在前景覆盖率上有了保证。但是由于存在着重复采样，意味着会有大量重复的预测实例，这不利于为了优化（与匈牙利匹配相悖）并且会给网络带来不必要的计算负担。因此，在未来工作中，我们会设法消除掉这些重复的预测，从而实现更快更好的预测。
% The query initialization method of BFL ensures foreground coverage rates. However, due to repeated sampling, it implies inevitable duplicate prediction instances, which is detrimental to optimization (contrary to Hungarian Matching) and imposes unnecessary computational burden. Therefore, in future work, we will endeavor to eliminate these duplicate predictions, thus achieving faster and better predictions.