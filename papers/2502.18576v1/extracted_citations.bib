@misc{AItest,
  title = {AI Test Kitchen},
  author = {Warkentin, Tris and Woodward, Josh},
  url = {https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/},
  year={2022}}

@misc{ChatGPT_Feedback, title={ChatGPT Feedback Contest: Official Rules}, url={https://cdn.openai.com/chatgpt/ChatGPT_Feedback_Contest_Rules.pdf}, journal={Open AI}, author={Open AI}, year={2022}, month={December}}

@misc{HuggingFace,
title={HuggingFace announcedthe new feature to flag any Model, Dataset, or Space on the Hub},
url={https://twitter.com/GiadaPistilli/status/1571865167092396033?s=20&t=LRhhEu63s6ftPmtZdfz8Cw}, author = {Pistilli, Giada},
year={2022}, month={September}}

@inproceedings{asplund2020auditing,
  title={Auditing race and gender discrimination in online housing markets},
  author={Asplund, Joshua and Eslami, Motahhare and Sundaram, Hari and Sandvig, Christian and Karahalios, Karrie},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={14},
  pages={24--35},
  year={2020}
}

@article{bellamy2018ai,
  title={AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias},
  author={Bellamy, Rachel KE and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovi{\'c}, Aleksandra and others},
  journal={IBM Journal of Research and Development},
  volume={63},
  number={4/5},
  pages={4--1},
  year={2019},
  publisher={IBM}
}

@techreport{bird2020fairlearn,
author = {Bird, Sarah and Dudík, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
title = {Fairlearn: A toolkit for assessing and improving fairness in AI},
institution = {Microsoft},
year = {2020},
month = {May},
abstract = {We introduce Fairlearn, an open source toolkit that empowers data scientists and developers to assess and improve the fairness of their AI systems. Fairlearn has two components: an interactive visualization dashboard and unfairness mitigation algorithms. These components are designed to help with navigating trade-offs between fairness and model performance. We emphasize that prioritizing fairness in AI systems is a sociotechnical challenge. Because there are many complex sources of unfairness—some societal and some technical—it is not possible to fully “debias” a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible. As Fairlearn grows to include additional fairness metrics, unfairness mitigation algorithms, and visualization capabilities, we hope that it will be shaped by a diverse community of stakeholders, ranging from data scientists, developers, and business decision makers to the people whose lives may be affected by the predictions of AI systems.},
url = {https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/},
number = {MSR-TR-2020-32},
}

@inproceedings{birhane2024ai,
  title={AI auditing: The broken bus on the road to AI accountability},
  author={Birhane, Abeba and Steed, Ryan and Ojewale, Victor and Vecchione, Briana and Raji, Inioluwa Deborah},
  booktitle={2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  pages={612--643},
  year={2024},
  organization={IEEE}
}

@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@article{cabrera2021discovering,
  title={Discovering and validating ai errors with crowdsourced failure reports},
  author={Cabrera, {\'A}ngel Alexander and Druck, Abraham J and Hong, Jason I and Perer, Adam},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW2},
  pages={1--22},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{chowdhury2021introducing,
title={Introducing Twitter’s first algorithmic bias bounty challenge},
author={Chowdhury, Rumman and Williams, Jutta},
journal={URl: https://blog. twitter. com/engineering/en\_us/topics/insights/2021/algorithmic-bias-bountychallenge},
year={2021}
}

@article{coenraad2022s,
  title={“That’s what techquity is”: youth perceptions of technological and algorithmic bias},
  author={Coenraad, Merijke},
  journal={Information and Learning Sciences},
  volume={123},
  number={7/8},
  pages={500--525},
  year={2022},
  publisher={Emerald Publishing Limited}
}

@inproceedings{dangol2024mediating,
  title={Mediating Culture: Cultivating Socio-cultural Understanding of AI in Children through Participatory Design},
  author={Dangol, Aayushi and Newman, Michele and Wolfe, Robert and Lee, Jin Ha and Kientz, Julie A and Yip, Jason and Pitt, Caroline},
  booktitle={Proceedings of the 2024 ACM Designing Interactive Systems Conference},
  pages={1805--1822},
  year={2024}
}

@inproceedings{deng2023understanding,
  title={Understanding Practices, Challenges, and Opportunities for User-Engaged Algorithm Auditing in Industry Practice},
  author={Deng, Wesley Hanwen and Guo, Boyuan and Devrio, Alicia and Shen, Hong and Eslami, Motahhare and Holstein, Kenneth},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2023}
}

@article{deng2025weaudit,
  title={WeAudit: Scaffolding User Auditors and AI Practitioners in Auditing Generative AI},
  author={Deng, Wesley Hanwen and Wang, Claire and Han, Howard Ziyu and Hong, Jason I and Holstein, Kenneth and Eslami, Motahhare},
  journal={arXiv preprint arXiv:2501.01397},
  year={2025}
}

@inproceedings{devos2022toward,
  title={Toward User-Driven Algorithm Auditing: Investigating users’ strategies for uncovering harmful algorithmic behavior},
  author={DeVos, Alicia and Dhabalia, Aditi and Shen, Hong and Holstein, Kenneth and Eslami, Motahhare},
  booktitle={Proceedings of the 2022 CHI conference on human factors in computing systems},
  pages={1--19},
  year={2022}
}

@inproceedings{hannak2014measuring,
  title={Measuring price discrimination and steering on e-commerce web sites},
  author={Hannak, Aniko and Soeller, Gary and Lazer, David and Mislove, Alan and Wilson, Christo},
  booktitle={Proceedings of the 2014 conference on internet measurement conference},
  pages={305--318},
  year={2014}
}

@article{kiela2021dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal={arXiv preprint arXiv:2104.14337},
  year={2021}
}

@article{lam2022enduser,
    author = {Lam, Michelle S. and Gordon, Mitchell L. and Metaxa, Dana\"{e} and Hancock, Jeffrey T. and Landay, James A. and Bernstein, Michael S.},
    title = {End-User Audits: A System Empowering Communities to Lead Large-Scale Investigations of Harmful Algorithmic Behavior},
    year = {2022},
    issue_date = {November 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {6},
    number = {CSCW2},
    url = {https://doi.org/10.1145/3555625},
    doi = {10.1145/3555625},
    journal = {Proc. ACM Hum.-Comput. Interact.},
    month = {Nov},
    articleno = {512},
    numpages = {34}
}

@inproceedings{li2023want,
  title={“I Want to Be Unique From Other Robots”: Positioning Girls as Co-creators of Social Robots in Culturally-Responsive Computing Education},
  author={Li, Yinmiao and Nwogu, Jennifer and Buddemeyer, Amanda and Solyst, Jaemarie and Lee, Jina and Walker, Erin and Ogan, Amy and Stewart, Angela EB},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2023}
}

@inproceedings{mack2024they,
  title={“They only care to show us the wheelchair”: disability representation in text-to-image AI models},
  author={Mack, Kelly Avery and Qadri, Rida and Denton, Remi and Kane, Shaun K and Bennett, Cynthia L},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--23},
  year={2024}
}

@article{metaxa2021auditing,
  title={Auditing algorithms: Understanding algorithmic systems from the outside in},
  author={Metaxa, Dana{\"e} and Park, Joon Sung and Robertson, Ronald E and Karahalios, Karrie and Wilson, Christo and Hancock, Jeff and Sandvig, Christian and others},
  journal={Foundations and Trends{\textregistered} in Human--Computer Interaction},
  volume={14},
  number={4},
  pages={272--344},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@inproceedings{morales2024youth,
  title={Youth as Peer Auditors: Engaging Teenagers with Algorithm Auditing of Machine Learning Applications},
  author={Morales-Navarro, Luis and Kafai, Yasmin and Konda, Vedya and Metaxa, Dana{\"e}},
  booktitle={Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
  pages={560--573},
  year={2024}
}

@incollection{noble2018algorithms,
  title={Algorithms of oppression: How search engines reinforce racism},
  author={Noble, Safiya Umoja},
  booktitle={Algorithms of oppression},
  year={2018},
  publisher={New York university press}
}

@article{ojewale2024towards,
  title={Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling},
  author={Ojewale, Victor and Steed, Ryan and Vecchione, Briana and Birhane, Abeba and Raji, Inioluwa Deborah},
  journal={arXiv preprint arXiv:2402.17861},
  year={2024}
}

@article{prates2020assessing,
  title={Assessing gender bias in machine translation: a case study with google translate},
  author={Prates, Marcelo OR and Avelar, Pedro H and Lamb, Lu{\'\i}s C},
  journal={Neural Computing and Applications},
  volume={32},
  pages={6363--6381},
  year={2020},
  publisher={Springer}
}

@article{sandvig2014auditing,
  title={Auditing algorithms: Research methods for detecting discrimination on internet platforms},
  author={Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie and Langbort, Cedric},
  journal={Data and discrimination: converting critical concerns into productive inquiry},
  volume={22},
  number={2014},
  pages={4349--4357},
  year={2014}
}

@article{scott2015culturally,
  title={Culturally responsive computing: A theory revisited},
  author={Scott, Kimberly A and Sheridan, Kimberly M and Clark, Kevin},
  journal={Learning, media and technology},
  volume={40},
  number={4},
  pages={412--436},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{scott2016techno,
  title={Techno-social change agents: Fostering activist dispositions among girls of color},
  author={Scott, Kimberly A and Garcia, Patricia},
  journal={Meridians},
  volume={15},
  number={1},
  pages={65--85},
  year={2016},
  publisher={Duke University Press}
}

@inproceedings{shelby2024generative,
  title={Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction},
  author={Shelby, Renee and Rismani, Shalaleh and Rostamzadeh, Negar},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2024}
}

@article{solyst2023potential,
  title={The Potential of Diverse Youth as Stakeholders in Identifying and Mitigating Algorithmic Bias for a Future of Fairer AI},
  author={Solyst, Jaemarie and Yang, Ellia and Xie, Shixian and Ogan, Amy and Hammer, Jessica and Eslami, Motahhare},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW2},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{solyst2023would,
  title={“I Would Like to Design”: Black Girls Analyzing and Ideating Fair and Accountable AI},
  author={Solyst, Jaemarie and Xie, Shixian and Yang, Ellia and Stewart, Angela EB and Eslami, Motahhare and Hammer, Jessica and Ogan, Amy},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2023}
}

@article{solyst2024children,
  title={Children's Overtrust and Shifting Perspectives of Generative AI},
  author={Solyst, Jaemarie and Yang, Ellia and Xie, Shixian and Hammer, Jessica and Ogan, Amy and Eslami, Motahhare},
  journal={arXiv preprint arXiv:2404.14511},
  year={2024}
}

@article{solyst2025RAD,
  title={“That’s what techquity is”: youth perceptions of technological and algorithmic bias},
  author={Solyst, Jaemarie and Amspoker, Emily and Yang, Ellia and Eslami, Motahhare and Hammer, Jessica and Ogan, Amy},
  journal={Special Interest Group in Computer Science Education},
  volume={123},
  number={7/8},
  pages={500--525},
  year={2025},
  publisher={ACM}
}

@article{sweeney2013discrimination,
  title={Discrimination in online ad delivery: Google ads, black names and white names, racial discrimination, and click advertising},
  author={Sweeney, Latanya},
  journal={Queue},
  volume={11},
  number={3},
  pages={10--29},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wang2023treat,
  title={‘Treat me as your friend, not a number in your database’: Co-designing with Children to Cope with Datafication Online},
  author={Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2023}
}

@inproceedings{wolfe2024representation,
  title={Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study},
  author={Wolfe, Robert and Dangol, Aayushi and Howe, Bill and Hiniker, Alexis},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  volume={7},
  pages={1621--1634},
  year={2024}
}

@inproceedings{zhang2024partiality,
  title={Partiality and Misconception: Investigating Cultural Representativeness in Text-to-Image Models},
  author={Zhang, Lili and Liao, Xi and Yang, Zaijia and Gao, Baihang and Wang, Chunjie and Yang, Qiuling and Li, Deshun},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--25},
  year={2024}
}

