\begin{abstract}
In recent years, there has been a growing recognition of the need to incorporate lay-people's inputs into the governance and acceptability assessment of AI usage. 
% Despite this acknowledgment, we still lack a thorough understanding of the attitudes and reasoning factors that influence people's decisions regarding AI's development and integration. 
However, how and why people judge various AI use cases as acceptable remains under-explored.
In this work, we investigate the attitudes and reasoning factors that influence people's decisions regarding AI's development and integration, via 
% Therefore, our study aims to investigate these dimensions by conducting 
a set of surveys with demographically diverse participants (N=397). 
We focus on ten different AI use cases in both professional (e.g., Lawyer AI) and personal (e.g., Digital Medical Advice AI) settings, to understand the nature and stakes level of use cases on acceptability. 
We further explore the impact of various factors, such as the intervention of engaging participants with explicit considerations of harms and benefits, along with demographic influences, on the judgment of AI use cases.
Moreover, we explore the effects of various types (e.g., cost-benefit reasoning, rule-based reasoning) and factors (e.g., moral values) of decision-making in participants' judgment rationales. 
Our findings indicate that personal use cases are generally perceived more positively and with less disagreement compared to labor-focused ones. 
This study initiates uncovering diverse perspectives that influence societal AI decisions, helping align its development with public expectations and concerns.
% \maarten{I'm wondering if we wanna mirror some more of the intro framing, particularly around the points that (1) we need more democratic/lay people input into AI governance/acceptability of AI, but (2) we don't really know what attitudes and reasoning factors affect people's decisions. Thus, we conduct...
% (I don't think we need to mention dilemmas here, unless we have a paper title that contains the words dilemmas)}
% As AI's capabilities expand, it presents numerous dilemmas stemming from its dual positive and negative impacts. However, we do not yet understand how people with various backgrounds make these decisions, which could provide insights into potential disagreements around AI and possible solutions. 
% As a first step towards understanding the reasoning process regarding AI dilemmas, we construct two studies to understand the effects of use cases (e.g., Lawyer AI, Digital Medical Advice AI), explicit reasoning and various reasoning factors such as moral values and reasoning type (e.g., cost-benefit, rule-based), and demographic factors. We conduct our studies with N=198 and N=199 demographically diverse participants and found that personal use cases were more positively perceived with less disagreements compared to labor related use cases. \jimin{talk more about some coherent findings here and our discussion points}
\end{abstract}