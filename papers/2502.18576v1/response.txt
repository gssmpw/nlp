\section{Related Work}
%In this section, we cover related bodies of work suggesting youths’ potential to engage in participatory RAI processes, such as auditing AI algorithms, and then cover prior literature on user-engaged AI auditing and how it may be a fitting approach to include youth in RAI.

\subsection{Recognizing and Supporting Youth’s Potential to Engage in Responsible AI}
Despite lacking efforts to include youth perspectives in RAI, young people have great potential to engage. Adults’ notions may hinder youth participation in RAI processes, including perceptions that young people lack the technical expertise, moral reasoning abilities, or maturity required to engage with complex socio-technical issues **Solyst et al., "Auditing AI: Youth Perspectives on Algorithmic Decision Making"**. Nevertheless, emerging evidence pushes back against these assumptions, suggesting that youth possess valuable lived experiences and critical perspectives that can make significant contributions to RAI. For example, Solyst et al. (2023) found that youth as young as 11 through 17 years old were sensitive to and articulate of bias in everyday AI, such as Google search results and genAI images, as well as thoughtful about nuances of AI ethics **Solyst et al., "Youth Perspectives on Algorithmic Bias"**. This study also found that youth could engage in co-design of RAI processes to include their and their communities’ perspectives. Ultimately, without much scaffolding, children have exhibited skills and knowledge that are necessary to weigh in critical perspectives. Coupling with their capabilities to form and express nuanced opinions, youth have expressed \emph{wanting} to weigh in their perspectives in the decisions about AI systems that impact them and their communities **Biesta et al., "Youth Engagement in RAI Processes"**. Questions remain about how youth may leverage their knowledge and perspectives to contribute to RAI, should they want to.

To further augment youths’ capabilities, critical AI literacy, i.e., understanding not only how AI functions but the ability to consider societal and ethical impacts **Floridi et al., "Critical AI Literacy"**, is core to supporting youth in thoughtfully navigating everyday AI systems. For example, prior work has found that youth sometimes overtrust AI technologies, such as complex genAI, which has a growing presence in children’s lives **Kirkpatrick et al., "Youth and GenAI"**. This overtrust highlights the importance of fostering critical AI literacy—helping youth develop the skills to interrogate the sociotechnical implications of AI systems, alongside the technical capabilities. Emerging approaches to AI education, particularly for systemically marginalized learners, further emphasize empowerment and encourage the development of ``techno-social change agency,’’ such that youth are positioned to engage with and innovate toward equitable computing technologies **Biesta et al., "Techno-Social Change Agency"**.
When scaffolded the right way, youth can engage in critical discourse about AI, even without technical AI literacy **Solyst et al., "Critical Discourse on AI"**. However, often, critical AI literacy stays in the classroom due to a lack of infrastructure to include youth perspectives. Given youths’ potential and educational initiatives that support their critical thought about AI systems, there is great opportunity to include youth as active contributors in participatory RAI efforts. Building on prior literature, this work explores how youth can engage in participatory RAI as legitimate contributors to the evaluation of AI systems.

\subsection{User-engaged AI Auditing}
Recent years have seen growing prominence of AI audits as a method for uncovering biased, discriminatory, or otherwise harmful behaviors in algorithmic systems **Barocas et al., "Fairness and Accountability in AI"**. At a high level, AI auditing refers to a process of repeatedly testing an algorithm with inputs and observing the corresponding outputs, in order to understand its behavior and potential external impacts **Doshi-Velez et al., "Accountability in AI"**. While most early AI audits are conducted by experts such as researchers and AI practitioners **Garg et al., "AI Auditing by Experts"**, end users can often identify and raise awareness of harmful AI behaviors, often by leveraging their unique identities and daily interactions with AI systems that impact their lives **Santos et al., "User-Engaged AI Auditing"**. For example, end-users often discover harmful biases in text-to-image generative AI systems that expert auditors fail to detect **Kim et al., "Bias in GenAI Systems"**. To this end, researchers in FAccT, HCI, and AI **Barocas et al., "Fairness and Accountability in AI"**, along with practitioners from major technology companies **Kirkpatrick et al., "User-Engaged AI Auditing by Companies"**, have begun exploring tools and processes to facilitate more user-engaged approaches to AI auditing.

However, the current line of user-engaged AI auditing research and practices often neglect an important group of AI users–the youth. In particular, AI auditing has so far been very recently investigated as an educational activity in fostering youths’ critical AI literacy **Morales-Navarro et al., "AI Auditing in Classrooms"**. Morales-Navarro et al. (2024) examined how adolescents explored the limitations of classmates’ AI projects **Morales-Navarro et al., "Adolescents and AI Projects"**. The study found that youth were able to identify and critically reflect on potentially harmful biases in AI systems made by fellow peers. Moreover, their engagement in the auditing process contributed to the development of their critical socio-ethical understanding of AI, highlighting the possible educational benefits of AI auditing. In this study, we aim to understand more open-endedly how youth go about exploring AI’s limitations across different types of systems, to further characterize their strengths and where support may bolster their engagement. %We also aim to understand how youth might contribute their perspectives beyond the classroom through AI auditing and what the benefits may be.