\section{Related Work}
\label{sec:related_work}

%
%
%
%
%
%
%
%
%
%
Most existing TSMD techniques do not support domain knowledge. 
Although they have hyperparameters, some of which can be determined using domain knowledge, they are never sufficient to represent domain knowledge in general. 
This is because hyperparameters are limited in expressiveness, as they only capture predetermined properties such as motif length or the cardinality of motif sets~\citep{locomotif,motiflets}. %
%
%
%
%
%
%


%
%
%
%

%
%
%

%
%


%
%
%

To our knowledge, there are only three existing TSMD techniques that support domain knowledge, but they are all quite limited in expressiveness%
. 
They merely utilize a mask $\mathbf{m}$, which is an auxiliary time series that specifies the desirability (between $0$ and $1$) or permissibility (either $0$ or $1$) of motifs at each time index.%
\footnote{The mask $\mathbf{m}$ is referred to as an annotation vector in~\cite{guiding} and a constraint in~\cite{mohammad2009constrained}.} 
The mask $\mathbf{m}$ can be provided by a domain expert or computed from the input time series $\mathbf{x}$ (or from an auxiliary one) using a simple method that leverages domain knowledge. 
We explain these existing techniques below%
.

%
%
%
\cite{guiding} proposed the technique Matrix Profile V (MPV) that applies $\textbf{m}$ to the starting time index of the \textit{representative} motif only (which is called the query). 
We can implement this in \locomotifdok by defining 
the hard constraint $\hmotrepr([b:e]) \;:\; m_b$ %
for a binary $\mathbf{m}$ 
or
the desirability function $\dmset(\{ [b_1 : e_1], \ldots, [b_k : e_k] \}) = m_{b_1}$ for a real-valued $\mathbf{m}$ 
where $b_1$ is the starting time index of the representative (i.e., the first) motif. 
We note that
%
MPV discovers only a single motif set with cardinality two, which can be achieved in \locomotifdok by setting $\kappa=1$ and $k_\mathrm{max}^\text{discard}=2$.

%
%
%
%
%
%
%

%
%
The TSMD algorithms proposed by~\cite{mohammad2009constrained} probabilistically sample the representative segments %
instead of processing all of them, where
%
$m_i$ specifies the probability of sampling (i.e., the probability of occurrence of) a motif that ends at time point $i$ 
for $i=1,\ldots,n$. 
If we consider the probability of occurrence as desirability, we can implement this in \locomotifdok by setting 
%
$\dmset(\{ [b_1 : e_1], \ldots, [b_k : e_k] \}) = m_{e_1}$ 
where $e_1$ is the end time index of the representative (i.e., the first) segment%
.
%
%
%
%
%
%

%
%
LoCoMotif~\citep{locomotif} supports two different binary masks, $\mathbf{m}^{\text{begin-repr}}$ and $\mathbf{m}^{\text{end-repr}}$, that are applied to the beginning and end time indices of \emph{representative} motifs only. 
%
This functionality can be implemented in \locomotifdok by defining the constraint
${\hmotrepr([b:e]) \;:\; m^{\text{begin-repr}}_b \land m^{\text{end-repr}}_e}$.
%
%
%
%
%
%
%

Yeh et~al.~\cite{matrixprofileIV} employs a mask for a different purpose than TSMD: 
%
Given a Boolean mask $\mathbf{m} \in \{ 0,1 \} ^n $ that annotates a time series $\mathbf{x}$ by specifying the time intervals containing interesting patterns, 
%
a model is learned to 
predict, for an unseen time series, a Boolean mask that specifies interesting time intervals in it.
%
%
This is considered as a semi- (or weekly) supervised approach 
%
because a model is learned from an annotated time series to make predictions for unseen time series.
%
As such, this method falls outside the scope of this paper.

%
%
%
%
%

%

%
%
%
%
%
%
%
%
%

%
%
%
%

%

%
%
%

%
%
%
%
%
%
%
%
%
%

%
%
%
%

%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%

%
%

%

%
%

%

%



%

%
%
%
%

%
%
%
%
%
%

%
%
%

%
%

%
%
%
%

%

%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%

%
%
%

%

%
%