

\section{Conclusions}
The paper proposes a Vocabulary-Free Semantic Segmentation (VSS) pipeline that addresses the limitations of current open-vocabulary segmentation approaches. Existing methods require users to specify object classes in advance, which is impractical for real-world scenarios with unexpected objects. VSS approaches leverage Vision-Language Models to automatically recognize objects and generate appropriate class names, eliminating the need for predefined vocabularies. Our experiments show the proposed pipeline significantly improves segmentation accuracy over the previous methods, particularly for out-of-context objects. Moreover, we demonstrated that the performance of the model is heavily influenced by the text encoder, which plays a crucial role in its ability to generalize. Its effectiveness is closely linked to the alignment between the actual image content and the generated class descriptions, with integrated class information showing promise for enhancing recognition. However, our results also reveal that the sensitivity of the text encoder to overlooked objects represents a challenge for achieving a flawless segmentation system.

\section*{Acknowledgment}
This manuscript is currently under consideration at Pattern Recognition Letters.
The Bayerische Motoren Werke (BMW) and the Deutscher Akademischer Austauschdienst (DAAD) partially supported this work.
