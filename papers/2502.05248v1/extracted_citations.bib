@article{hexaco,
  title={Meta-analytic investigations of the HEXACO Personality Inventory (-Revised)},
  author={Moshagen, Morten and Thielmann, Isabel and Hilbig, Benjamin E and Zettler, Ingo},
  journal={Zeitschrift f{\"u}r Psychologie},
  year={2019},
  publisher={Hogrefe Publishing}
}

@article{ipipneo60,
  title={Using item response theory to develop a 60-item representation of the NEO PI--R using the International Personality Item Pool: Development of the IPIP--NEO--60},
  author={Maples-Keller, Jessica L and Williamson, Rachel L and Sleep, Chelsea E and Carter, Nathan T and Campbell, W Keith and Miller, Joshua D},
  journal={Journal of personality assessment},
  volume={101},
  number={1},
  pages={4--15},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{li2024quantifying,
  title={Quantifying ai psychology: A psychometrics benchmark for large language models},
  author={Li, Yuan and Huang, Yue and Wang, Hongyi and Zhang, Xiangliang and Zou, James and Sun, Lichao},
  journal={arXiv preprint arXiv:2406.17675},
  year={2024}
}

@article{miniipip,
  title={The mini-IPIP scales: tiny-yet-effective measures of the Big Five factors of personality.},
  author={Donnellan, M Brent and Oswald, Frederick L and Baird, Brendan M and Lucas, Richard E},
  journal={Psychological assessment},
  volume={18},
  number={2},
  pages={192},
  year={2006},
  publisher={American Psychological Association}
}

@inproceedings{miotto-etal-2022-gpt,
    title = "Who is {GPT}-3? An exploration of personality, values and demographics",
    author = "Miotto, Maril{\`u}  and
      Rossberg, Nicola  and
      Kleinberg, Bennett",
    booktitle = "Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS)",
    month = nov,
    year = "2022",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.nlpcss-1.24",
    doi = "10.18653/v1/2022.nlpcss-1.24",
    pages = "218--227",
    abstract = "Language models such as GPT-3 have caused a furore in the research community. Some studies found that GPT-3 has some creative abilities and makes mistakes that are on par with human behaviour. This paper answers a related question: Who is GPT-3? We administered two validated measurement tools to GPT-3 to assess its personality, the values it holds and its self-reported demographics. Our results show that GPT-3 scores similarly to human samples in terms of personality and - when provided with a model response memory - in terms of the values it holds. We provide the first evidence of psychological assessment of the GPT-3 model and thereby add to our understanding of this language model. We close with suggestions for future research that moves social science closer to language models and vice versa.",
}

@inproceedings{personallm,
    title = "{P}ersona{LLM}: Investigating the Ability of Large Language Models to Express Personality Traits",
    author = "Jiang, Hang  and
      Zhang, Xiajie  and
      Cao, Xubo  and
      Breazeal, Cynthia  and
      Roy, Deb  and
      Kabbara, Jad",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.229",
    doi = "10.18653/v1/2024.findings-naacl.229",
    pages = "3605--3627",
    abstract = "Despite the many use cases for large language models (LLMs) in creating personalized chatbots, there has been limited research on evaluating the extent to which the behaviors of personalized LLMs accurately and consistently reflect specific personality traits. We consider studying the behavior of LLM-based agents which we refer to as LLM personas and present a case study with GPT-3.5 and GPT-4 to investigate whether LLMs can generate content that aligns with their assigned personality profiles. To this end, we simulate distinct LLM personas based on the Big Five personality model, have them complete the 44-item Big Five Inventory (BFI) personality test and a story writing task, and then assess their essays with automatic and human evaluations. Results show that LLM personas{'} self-reported BFI scores are consistent with their designated personality types, with large effect sizes observed across five traits. Additionally, LLM personas{'} writings have emerging representative linguistic patterns for personality traits when compared with a human writing corpus. Furthermore, human evaluation shows that humans can perceive some personality traits with an accuracy of up to 80{\%}. Interestingly, the accuracy drops significantly when the annotators were informed of AI authorship.",
}

@misc{serapiogarcía2023personalitytraitslargelanguage,
      title={Personality Traits in Large Language Models}, 
      author={Greg Serapio-García and Mustafa Safdari and Clément Crepy and Luning Sun and Stephen Fitz and Peter Romero and Marwa Abdulhai and Aleksandra Faust and Maja Matarić},
      year={2023},
      eprint={2307.00184},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.00184}, 
}

@misc{sorokovikova2024llmssimulatebigpersonality,
      title={LLMs Simulate Big Five Personality Traits: Further Evidence}, 
      author={Aleksandra Sorokovikova and Natalia Fedorova and Sharwin Rezagholi and Ivan P. Yamshchikov},
      year={2024},
      eprint={2402.01765},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01765}, 
}

@article{thebfi,
  title={Big five inventory},
  author={John, Oliver P and Donahue, Eileen M and Kentle, Robert L},
  journal={Journal of personality and social psychology},
  year={1991}
}

@article{tipi,
title = {A very brief measure of the Big-Five personality domains},
journal = {Journal of Research in Personality},
volume = {37},
number = {6},
pages = {504-528},
year = {2003},
issn = {0092-6566},
doi = {https://doi.org/10.1016/S0092-6566(03)00046-1},
url = {https://www.sciencedirect.com/science/article/pii/S0092656603000461},
author = {Samuel D Gosling and Peter J Rentfrow and William B Swann},
abstract = {When time is limited, researchers may be faced with the choice of using an extremely brief measure of the Big-Five personality dimensions or using no measure at all. To meet the need for a very brief measure, 5 and 10-item inventories were developed and evaluated. Although somewhat inferior to standard multi-item instruments, the instruments reached adequate levels in terms of: (a) convergence with widely used Big-Five measures in self, observer, and peer reports, (b) test–retest reliability, (c) patterns of predicted external correlates, and (d) convergence between self and observer ratings. On the basis of these tests, a 10-item measure of the Big-Five dimensions is offered for situations where very short measures are needed, personality is not the primary topic of interest, or researchers can tolerate the somewhat diminished psychometric properties associated with very brief measures.}
}

