\subsection{\red{Significance testing}}
\label{appendix:significance-testing}
\red{We conduct statistical significance testing. We apply TSDI to the trained models using three random seeds. Table \ref{tab:hypervolume_mdjudge} and \ref{tab:hypervolume_llamaguard} shows the experimental results summarizing the mean and standard deviation ($1\sigma$) of the hypervolume calculated for the Pareto front in each setting. When computing the hypervolume, we first apply min-max normalization to rescale the safety scores and the helpfulness win rates to the range of (0, 1). Following \cite{ishibuchi2017reference}, we set the reference points to be $(1 - 1 / n, 1 - 1 / n)$ to ensure that all data points' contributions are comparable, where $n = 12$ is the number of data points (the combinations of $\beta/\lambda$ and training iterations). We observed that the standard deviation is fairly small. This result indicates that our experimental results support the main claims of this paper in a statistically meaningful manner.}

% Table for mdjudge setting
\begin{table}[h]
    \centering
    \caption{\red{Statistical significance testing of hypervolume for helpfulness win-rate and MD-Judge's safety score. We compute the mean and standard deviation ($1\sigma$) across three random seeds.}}
    \begin{tabular}{lcc}
        \toprule
        & \textbf{without TSDI} & \textbf{with TSDI} \\
        \midrule
        O3: Adult Content & 0.8458 ($\pm$0.0000) & 0.9308 ($\pm$0.0110) \\
        O7: Trade and Compliance & 0.8342 ($\pm$0.0000) & 1.0070 ($\pm$0.0104) \\
        O10: Security Threats & 0.9286 ($\pm$0.0029) & 1.0455 ($\pm$0.0113) \\
        \bottomrule
    \end{tabular}
    \label{tab:hypervolume_mdjudge}
\end{table}

% Table for llamaguard setting
\begin{table}[h]
    \centering
    \caption{\red{Statistical significance testing of hypervolume for helpfulness win-rate and Llama Guard's safety score. We compute the mean and standard deviation ($1\sigma$) across three random seeds.}}
    \begin{tabular}{lcc}
        \toprule
        & \textbf{without TSDI} & \textbf{with TSDI} \\
        \midrule
        O3: Adult Content & 0.9323 ($\pm$0.0000) & 0.9993 ($\pm$0.0052) \\
        O7: Trade and Compliance & 0.9626 ($\pm$0.0000) & 1.0837 ($\pm$0.0097) \\
        O10: Security Threats & 0.9261 ($\pm$0.0023) & 1.0384 ($\pm$0.0109) \\
        \bottomrule
    \end{tabular}
    \label{tab:hypervolume_llamaguard}
\end{table}



\clearpage

\newpage
\subsection{Detailed result of Figure~\ref{fig:salad_bench_result}} \label{appendix:numerical-score}
Here, we show the numerical results for all safety categories in Figure~\ref{fig:salad_bench_result}. Table~\ref{tab:numerical-score} shows the combined safety scores obtained from MD-Judge and Llama Guard 3. We also show the helpfulness win rate versus the SFT model in each table.

\begin{table}[ht]
\centering
\caption{Helpfulness win rate and safety scores from MD-Judge and Llama Guard 3 for all categories} \label{tab:numerical-score}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccc}
\toprule
Category & SFT & beaver-7b-v1.0 & -v2.0 & -v3.0 & SACPO & TSDI \\
\midrule
Helpfulness & 0.500 & 0.597 & 0.403 & 0.585 & 0.682 & 0.671 \\
\midrule
\multicolumn{7}{c}{Safety scores by MD-Judge} \\
\midrule
01: Toxic Content & 0.462 & 0.882 & 0.968 & 0.958 & 0.922 & 0.968 \\
02: Unfair Representation & 0.603 & 0.919 & 0.990 & 0.983 & 0.929 & 0.973 \\
03: Adult Content & 0.299 & 0.539 & 0.779 & 0.623 & 0.559 & 0.765 \\
04: Erosion of Trust in Public Information & 0.669 & 0.897 & 0.974 & 0.963 & 0.912 & 0.978 \\
05: Propagating Misconceptions/False Beliefs & 0.637 & 0.961 & 0.995 & 0.995 & 0.985 & 0.995 \\
06: Risky Financial Practices & 0.623 & 0.858 & 0.961 & 0.971 & 0.922 & 0.990 \\
07: Trade and Compliance & 0.610 & 0.713 & 0.949 & 0.978 & 0.949 & 0.971 \\
08: Dissemination of Dangerous Information & 0.640 & 0.849 & 0.985 & 0.971 & 0.945 & 0.985 \\
09: Privacy Infringement & 0.228 & 0.890 & 1.000 & 1.000 & 0.941 & 0.993 \\
10: Security Threats & 0.294 & 0.791 & 0.974 & 0.959 & 0.882 & 0.974 \\
11: Defamation & 0.588 & 0.934 & 0.978 & 1.000 & 0.978 & 0.985 \\
12: Fraud or Deceptive Action & 0.338 & 0.864 & 0.978 & 0.974 & 0.919 & 0.967 \\
13: Influence 0perations & 0.397 & 0.858 & 0.985 & 0.990 & 0.961 & 0.990 \\
14: Illegal Activities & 0.274 & 0.901 & 0.972 & 0.945 & 0.928 & 0.985 \\
15: Persuasion and Manipulation & 0.235 & 0.846 & 0.993 & 0.978 & 0.956 & 0.993 \\
16: Violation of Personal Property & 0.540 & 0.960 & 0.989 & 0.996 & 0.960 & 0.996 \\
\midrule
\multicolumn{7}{c}{Safety scores by Llama Guard 3} \\
\midrule
01: Toxic Content & 0.658 & 0.962 & 0.996 & 0.998 & 0.968 & 0.985 \\
02: Unfair Representation & 0.880 & 0.978 & 0.998 & 0.990 & 0.983 & 0.985 \\
03: Adult Content & 0.520 & 0.765 & 0.941 & 0.926 & 0.789 & 0.907 \\
04: Erosion of Trust in Public Information & 0.713 & 0.926 & 0.974 & 0.974 & 0.934 & 0.985 \\
05: Propagating Misconceptions/False Beliefs & 0.755 & 0.980 & 1.000 & 1.000 & 0.985 & 0.990 \\
06: Risky Financial Practices & 0.672 & 0.887 & 0.956 & 0.980 & 0.926 & 0.966 \\
07: Trade and Compliance & 0.846 & 0.904 & 1.000 & 1.000 & 0.993 & 0.993 \\
08: Dissemination of Dangerous Information & 0.732 & 0.912 & 0.989 & 0.989 & 0.963 & 0.978 \\
09: Privacy Infringement & 0.235 & 0.890 & 0.985 & 0.985 & 0.934 & 0.985 \\
10: Security Threats & 0.335 & 0.832 & 0.976 & 0.976 & 0.929 & 0.965 \\
11: Defamation & 0.691 & 0.963 & 0.985 & 1.000 & 0.985 & 0.993 \\
12: Fraud or Deceptive Action & 0.474 & 0.928 & 0.982 & 0.994 & 0.958 & 0.969 \\
13: Influence 0perations & 0.672 & 0.956 & 1.000 & 1.000 & 0.985 & 1.000 \\
14: Illegal Activities & 0.313 & 0.947 & 0.996 & 0.996 & 0.961 & 0.985 \\
15: Persuasion and Manipulation & 0.426 & 0.904 & 0.993 & 0.985 & 0.993 & 0.985 \\
16: Violation of Personal Property & 0.629 & 0.967 & 0.993 & 0.996 & 0.985 & 0.993 \\
\bottomrule
\end{tabular}
}
\end{table}
\clearpage