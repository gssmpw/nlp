\newpage
\section{Proof of Proposition~\ref{prop:logit}}\label{apdx:proof}
Prior to the proof, the definition of the function $g_\theta$ is discussed.
Let $\pi_r^*$, $\pi_{\theta}$, and $\pi_{\theta}'$ be the reference policy (i.e., the reward-aligned policy), the safety-aligned policy, and the de-biased policy, respectively, as defined in the main text. Our function $g_\theta(x, y)$ is defined as
\begin{equation*}
g_\theta(x, y) = \frac{\beta}{\lambda} \log \frac{\pi_\theta(y \mid x)}{\pi_r^*(y \mid x)}, \quad \text{implying} \quad 
\pi_\theta(y \mid x) \propto \pi_r^* (y \mid x) \exp\left( \frac{\lambda}{\beta} g_\theta(x, y) \right).
\end{equation*}
That is, $g_\theta(x, y)$ can be regarded as the safety-function value implicitly trained by the safety-alignment process.
Note that $g_{\theta}(x, y)$ is well-defined even for an incomplete output sequence $y$ because both the trained policy $\pi_\theta$ and the reference policy $\pi_r^*$ are defined for arbitrary input-output pairs and $g_\theta$ is computed from them.
On the contrary, the ground truth safety-function $g$ is understood as a function from a pair of an entire input sequence and an entire output sequence because whether the output is safe or not may be determined only for an entire output \cite{mudgal24a}. Given such a safety function, the optimal policy under KL regularization satisfies
\begin{equation*}
\pi^\star(y \mid x) \propto \pi_r^* (y \mid x) \exp\left( \frac{\lambda}{\beta} g(x, y) \right),
\end{equation*}
but it is well-defined only for pairs of an entire input sequence and an entire output sequence.
Then, one can not claim that
\begin{equation*}
g(x, y) = \frac{\beta}{\lambda} \log \frac{\pi^\star(y \mid x)}{\pi_r^*(y \mid x)}
\end{equation*}
for incomplete output sequence $y$. 
Care should be taken not to confuse this point.

\begin{proof}[Proof of \Cref{prop:logit}]
We denote the safety value associated to $i$-th output token $y_i$ given input sequence $x$ and output sequence $y$ as $g_{\theta}(y_i \mid x\otimes y_{1:i-1}) = g_\theta(x, y_{1:i})$. 
Then, the probability of the $i$-th output token from the safety-aligned policy $\pi_\theta$ is represented as (by following the definition of $g_\theta$)
\begin{equation*}
p_{\pi_\theta}(y_i \mid x \oplus y_{1:i-1}) 
= \frac{1}{Z_{\pi_\theta}(x\oplus y_{1:i-1})} p_{\pi_r^*}(y_i \mid x \oplus y_{1:i-1})  \exp\left( \frac{\lambda}{\beta} g_\theta(y_i \mid x \oplus y_{1:i-1})\right),
\end{equation*}
where $Z_{\pi_\theta}(x\oplus y_{1:i-1})$ is the normalization factor independent of $y_{i}$.

Let $v_k$ denote the $k$-th token in the vocabulary set.
For a given policy $\pi$, the $k$-th element of the logit function is
\begin{equation*}
[f_{\pi}(x \oplus y_{1:i-1})]_k = \log p_{\pi}(v_k \mid x \oplus y_{1:i-1}) + A_{\pi}(x\oplus y_{1:i-1}),
\end{equation*}
where $[\cdot]_k$ represent the $k$-th element of a vector and $A_{\pi}(x \oplus y_{1:i-1})$ is some function independent of $y_{i}$.
The difference between the logit functions for $\pi_\theta$ and $\pi_r^*$ is
\begin{align*}
\MoveEqLeft[2]
[f_{\pi_\theta}(x \oplus y_{1:i-1}) - f_{\pi_r^*}(x \oplus y_{1:i-1}) ]_k \\
&= \log \frac{p_{\pi_\theta}(v_k \mid x \oplus y_{1:i-1})}{p_{\pi_r^*}(v_k \mid x \oplus y_{1:i-1})} - A_{\pi_\theta}(x \oplus y_{1:i-1}) + A_{\pi_r^*}(x \oplus y_{1:i-1}) \\
&= \frac{g_\theta(v_k \mid x\oplus y_{1:i-1})}{\beta / \lambda} \underbrace{- A_{\pi_\theta}(x \oplus y_{1:i-1}) + A_{\pi_r^*}(x \oplus y_{1:i-1}) - \log Z_{\pi_\theta}(x \oplus y_{1:i-1})}_{ =: C(x \oplus y_{1:i-1})}.
\end{align*}
Then, by taking the expectation for $(x, y) \sim \tilde{\rho}$, we have
\begin{align*}
[\mathbf{b}_{i} ]_k
&= \left[ \E_{(x',y') \sim \rhot}[f_{\pi_\theta}(x' \oplus y_{1:i-1}') - f_{\pi_r^*}(x' \oplus y_{1:i-1}') ] \right]_k\\
&= \frac{\E_{(x',y') \sim \rhot}[g_\theta(v_k \mid x' \oplus y_{1:i-1}')]}{\beta / \lambda} + \underbrace{\E_{(x',y') \sim \rhot}[C(x' \oplus y_{1:i-1}')]}_{=: \tilde{C}}.
\end{align*}
Therefore, subtracting it from $f_{\pi_\theta}(x \oplus y_{1:i-1}) - f_{\pi_r^*}(x \oplus y_{1:i-1})$ leads to
\begin{equation*}
[f_{\pi_\theta}(x \oplus y_{1:i-1}) - f_{\pi_r^*}(x \oplus y_{1:i-1}) - \mathbf{b}_{i}]_{k}
= \frac{g_\theta(v_k \mid x \oplus y_{1:i-1} ) - \E_{(x',y') \sim \rhot}[g_\theta(v_k \mid x' \oplus y_{1:i-1}')]}{\beta / \lambda} .
\end{equation*}
Hence,
\begin{align*}
p_{\pi_\theta'}(y_i = v_{k} \mid x \oplus y_{1:i-1}) 
&= \left[ \textsc{softmax}(f_{\pi_\theta}(x \oplus y_{1:i-1}) - \mathbf{b}_{i})\right]_k \\
&= \frac{ \exp\left( \left[ f_{\pi_\theta}(x \oplus y_{1:i-1}) - \mathbf{b}_{i})\right]_k\right) }{ \sum_{\ell=1}^{V} \exp\left( \left[ f_{\pi_\theta}(x \oplus y_{1:i-1}) - \mathbf{b}_{i})\right]_\ell\right) } \\
&\propto  \exp\left( \left[ f_{\pi_\theta}(x \oplus y_{1:i-1}) - \mathbf{b}_{i})\right]_k\right) \\
&\propto \exp\left( [ f_{\pi_r^*}(x \oplus y_{1:i-1})]_k + \frac{g_\theta(v_k \mid x \oplus y_{1:i-1}) - \E_{(x', y') \sim \rhot}[g_\theta(v_k \mid x' \oplus y_{1:i-1}')]}{\beta / \lambda}\right)  \\
&\propto \exp\left( \log p_{\pi_{r}^*}(v_k \mid x\oplus y_{1:i-1}) + \frac{g_\theta(v_k \mid x \oplus y_{1:i-1}) - \E_{(x', y') \sim \rhot}[g_\theta(v_k \mid x' \oplus y_{1:i-1}')]}{\beta / \lambda} \right)  \\
&= p_{\pi_{r}^*}(y_i = v_k \mid x\oplus y_{1:i-1}) \exp\left( \frac{g_\theta(v_k \mid x \oplus y_{1:i-1}) - \E_{(x', y') \sim \rhot}[g_\theta(v_k \mid x' \oplus y_{1:i-1}')]}{\beta / \lambda} \right)  .
\end{align*}
This completes the proof.
\end{proof}

\clearpage