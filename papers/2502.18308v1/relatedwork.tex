\section{Related Work}
\paragraph*{Instruction Following.}
Our work falls in the broader realm of evaluating LLMs' instruction-following capacities.
IFEval~\citep{zhou2023instruction} uses verifiable instruction to evaluate the instruction-following ability of LLMs. 
\cite{instruction-follow-summ} propose a meta-evaluation of the instruction-following for text summarization. \cite{instruction-follow-verbalizer} check LLMs’ instruction-following by checking whether a verbalizer can override the models’ output.
Other efforts are devoted to evaluating the instruction-following for complex instructions~\citep{he2024complex} and sequential instructions~\citep{chen2024sifo}.
Apart from this work, RefuteBench~\citep{yan2024refutebench} first evaluates the instruction-following with refutation, investigating whether LLMs can follow  user's feedback in modifying its output or be stubborn to original outputs. 
We extend this work from several important aspects: (1) integration of another important scenario -- \emph{Transient refutation}; (2) use of agentic dynamic evaluation protocol to replace template-based protocols, which both requires careful efforts in adapting each task with appropriate templates and facilitates \textit{context-aware} evaluation with \textit{versatile} feedback types. 
% Their findings demonstrate that LLMs like \texttt{gpt-3.5-turbo} and \texttt{Mixtral-Instruct} can be 
% the model's instruction-following capability can extend through dialogue history. 
% \elliott{add new literature}

\paragraph*{Dynamic Evaluation.}
In contrast to static evaluation using pre-constructed data, 
dynamic evaluation is proposed to address the “false promise” to data contamination \citep{Bender2021,kocon2023chatgpt} and over-fitting benchmarks \citep{zhu2023dyval}.
% Dynamic evaluation proposes to change the evaluation periodically to avoid this issue.  
% rephrasing the evaluation data and maintaining the concept,  is proposed to address this issue. 
\cite{zhu2024dyval} propose to change MMLU \citep{hendrycksmeasuring}, BBH \citep{suzgun2023challenging}, GSM8k \citep{cobbe2021training} and ARC-C \citep{clark2018think} benchmarks to dynamic evaluation by applying Meta Probing Agents.
\cite{burnell2023revealing} use three basic cognitive abilities -- language understanding, problem-solving, and domain knowledge to conduct dynamic evaluation sample generation and support multifaceted ability analysis.
\cite{fan2023nphardeval}~(NPHardEval) generates new NP-hard math problems and updates the evaluation set monthly.
Using a dynamic evaluation protocol, we evaluate LLMs' refutation instruction following capacities with context-aware, and human-like instructions, comprehensive refutation types, and low human annotation cost.

% Thanks to the nature of dynamic evaluation protocol, our work also avoids the problem of data contamination. Different from these work, 

\paragraph*{LLM Agents in Simulation.}
Increasing research efforts use LLMs as agents to simulate human behavior. For example, in dialogue recommendation systems, some studies employ LLMs to simulate users \citep{bernard2024identifying,fang2024multi,wang2023rethinking}. These LLM agents provide feedback to evaluate the performance of recommendation systems during the conversation, which offers advantages such as simplicity, cost-effectiveness, and time efficiency. Additionally, some research uses LLMs to study model interactivity \citep{bang-etal-2023-multitask}, and to better understand the limits of LLM agents in interactive environments. Studies also propose examining their interactions in benchmark decision-making scenarios \citep{park2024llm}. In role-play settings, work leverages LLMs to emulate users in dynamic, multi-turn conversations and to assess the resulting dialogues \citep{gusev2024pingpong}. Our work is similar in that we all adopt LLMs to simulate users in the multi-turn dialogues. However, different from these efforts, we use LLMs to simulate a user to refute the model response for evaluating the refutation instruction-following capacity.
% as the refuter agent and evaluator agent. 
% to refute the response model.