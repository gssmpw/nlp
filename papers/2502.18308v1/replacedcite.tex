\section{Related Work}
\paragraph*{Instruction Following.}
Our work falls in the broader realm of evaluating LLMs' instruction-following capacities.
IFEval____ uses verifiable instruction to evaluate the instruction-following ability of LLMs. 
____ propose a meta-evaluation of the instruction-following for text summarization. ____ check LLMs’ instruction-following by checking whether a verbalizer can override the models’ output.
Other efforts are devoted to evaluating the instruction-following for complex instructions____ and sequential instructions____.
Apart from this work, RefuteBench____ first evaluates the instruction-following with refutation, investigating whether LLMs can follow  user's feedback in modifying its output or be stubborn to original outputs. 
We extend this work from several important aspects: (1) integration of another important scenario -- \emph{Transient refutation}; (2) use of agentic dynamic evaluation protocol to replace template-based protocols, which both requires careful efforts in adapting each task with appropriate templates and facilitates \textit{context-aware} evaluation with \textit{versatile} feedback types. 
% Their findings demonstrate that LLMs like \texttt{gpt-3.5-turbo} and \texttt{Mixtral-Instruct} can be 
% the model's instruction-following capability can extend through dialogue history. 
% \elliott{add new literature}

\paragraph*{Dynamic Evaluation.}
In contrast to static evaluation using pre-constructed data, 
dynamic evaluation is proposed to address the “false promise” to data contamination ____ and over-fitting benchmarks ____.
% Dynamic evaluation proposes to change the evaluation periodically to avoid this issue.  
% rephrasing the evaluation data and maintaining the concept,  is proposed to address this issue. 
____ propose to change MMLU ____, BBH ____, GSM8k ____ and ARC-C ____ benchmarks to dynamic evaluation by applying Meta Probing Agents.
____ use three basic cognitive abilities -- language understanding, problem-solving, and domain knowledge to conduct dynamic evaluation sample generation and support multifaceted ability analysis.
____~(NPHardEval) generates new NP-hard math problems and updates the evaluation set monthly.
Using a dynamic evaluation protocol, we evaluate LLMs' refutation instruction following capacities with context-aware, and human-like instructions, comprehensive refutation types, and low human annotation cost.

% Thanks to the nature of dynamic evaluation protocol, our work also avoids the problem of data contamination. Different from these work, 

\paragraph*{LLM Agents in Simulation.}
Increasing research efforts use LLMs as agents to simulate human behavior. For example, in dialogue recommendation systems, some studies employ LLMs to simulate users ____. These LLM agents provide feedback to evaluate the performance of recommendation systems during the conversation, which offers advantages such as simplicity, cost-effectiveness, and time efficiency. Additionally, some research uses LLMs to study model interactivity ____, and to better understand the limits of LLM agents in interactive environments. Studies also propose examining their interactions in benchmark decision-making scenarios ____. In role-play settings, work leverages LLMs to emulate users in dynamic, multi-turn conversations and to assess the resulting dialogues ____. Our work is similar in that we all adopt LLMs to simulate users in the multi-turn dialogues. However, different from these efforts, we use LLMs to simulate a user to refute the model response for evaluating the refutation instruction-following capacity.
% as the refuter agent and evaluator agent. 
% to refute the response model.