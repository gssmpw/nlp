\begin{table*}[tp]
\centering
\caption{\textbf{Comparison on multi-label recognition (MLR).} We compare the performance (mAP) and training efficiency (number of parameters) of our approach with SOTA VLM-based MLR methods on VOC2007 and COCO-14 datasets. Our approach is competitive with SOTA on VOC2007, and on the challenging COCO dataset, it outperforms SOTA while requiring only one-third of the parameters. \textcolor{red}{red} and \textcolor{blue}{\underline{blue}} indicate the best and the second best performance}
% \renewcommand{\arraystretch}{1.3} % Adjust row height
% \setlength{\tabcolsep}{5pt} % Adjust column spacing
\small
\begin{tabular}{ccccc}
\toprule
\textbf{Methods}               & \multicolumn{2}{c}{\textbf{VOC2007}}       & \multicolumn{2}{c}{\textbf{COCO-14}}       \\  \cmidrule(lr){2-3} \cmidrule(lr){4-5}
                        \textbf{Arch: RN-101}       & \textbf{\# Params($\downarrow$)} &  \textbf{mAP($\uparrow$)} & \textbf{\# Params ($\downarrow$)} & \textbf{mAP($\uparrow$)} \\ \midrule
DualCoOp \cite{dualcoop}       &  \textcolor{red}{0.3M}           &  94.2          &   1.3M            &   83.6       \\
SCPNet \cite{scpnet}           &  -              &  94.3          &   3.4M            &   84.4       \\
TAI-DPT \cite{TaI-DPT}         & $>$ 0.3M        & -              &   $>$1.3M         &   84.5       \\
DualCoOp++ \cite{dualcoop++}   &  \textcolor{blue}{\underline{0.4M}}           &  \textcolor{red}{94.9} &   1.5M            &   \textcolor{blue}{\underline{85.1}}       \\
MLR-GCN \cite{MLR-GCN}         &  \textcolor{red}{0.3M}           &  94.4          &   1.3M            &    -         \\
PositiveCoOp \cite{PositiveCoOp}    &  0.17M          &  94.4          &  \textcolor{blue}{\underline{0.73M}}           &   84.7        \\
\midrule
Ours                           &  \textcolor{blue}{\underline{0.4M}}          &  \textcolor{blue}{\underline{94.8}}  &  \textcolor{red}{0.4M}   &   \textcolor{red}{85.2}        \\ \bottomrule
\end{tabular}

\label{tab:MLR performance}
\end{table*}
