% 

\input{figs/ZS3}

\begin{figure}[tp]
  \centering
  \includegraphics[width=\linewidth]{figs/sep_miou_mAP.png}
  % \vspace{-8pt}
  \caption{\textbf{Performance vs. MFI Reduction.} Performance of MLR (mAP) and ZS3 (mIoU) on COCO as a function of MFI reduction.}
  \label{fig: mAP_mIOU_MFI_red}
\end{figure}



\textbf{Feature Disentanglement in seen and unseen classes.} 
We pre-train Unmix-CLIP on COCO-14, which contains 80 classes. Despite this, as shown in Sec.\ref{sec: Results}, our approach improves performance even on datasets with previously unseen classes, such as VOC Context. We analyze this improvement by comparing MFI reduction across four datasets: VOC2012 (20 seen classes), COCO-2017 (80 seen classes), Context (59 partially seen classes), and a Context subset (30 unseen classes from COCO-2017). Figure \ref{fig:seperation} shows the self-similarity matrices of class text features from CLIP and Unmix-CLIP, demonstrating the class feature disentanglement. Table \ref{tab:mfi_reduction} quantifies the MFI reduction through the difference in average inter-class similarity between CLIP and Unmix-CLIP. The results show that our framework effectively disentangles representations for both seen and unseen classes, leading to performance improvements.

\input{tables/MFI_reduction}

\textbf{Feature Disentanglement Impact}. Figure \ref{fig: mAP_mIOU_MFI_red} shows how MFI reduction improves performance in both multi-label recognition and zero-shot semantic segmentation on COCO dataset.  We observe that as MFI decreases, the performance of both tasks improves.

\input{tables/loss_ablation}


%%% CODE TO GET THE PLOTS %%%%%%%%%%%%%


% \textbf{2. Sensitivity to alpha} \\
% \textbf{3. Some Analysis on ViT would be good} \\

