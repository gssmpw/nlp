\section{RELATED WORK}
\label{sec:related}

\subsection{Weighted Low Rank Applications}
Weighted low-rank techniques have been widely applied in broad machine learning applications such as grayscale-thermal detection____, object detection____, fault detection____, defect detection____, background estimation____, multi-task learning____, robust visual representation learning____, adversarial learning____, image restoration____, image clustering and classification____, robust principal component analysis____, language models training____, language model compression____, weather prediction____, tensor training____, domain generalization____ and many more.
Weighted low-rank techniques have also been widely used in signal processing for filter design and noise removal____. 

\subsection{Weighted Low Rank in Attention Mechanism} Particularly, a line of works shows that the attention matrix may have some low-rank property, even under softmax activation function by polynomial approximation methods, e.g., ____. Thus, under such conditions, we may use weighted low-rank approximations for transformers' attention acceleration. For a few distinct columns or rows, empirically, we see that the attention matrix has some good patterns ____. In this work, we focus on the theoretical analysis and leave its empirical justification as future work.

\subsection{Weighted Low Rank Approximation and Acceleration}
Many previous works try to solve in an efficient way empirically and theoretically____. Particularly, recently, ____ proposes an algorithm to output a slightly higher rank output as a proxy to solve the weighted low-rank approximation problem efficiently.
____ develops an efficient framework for alternating minimization to get the weighted low-rank approximation. Similarly, ____ proposes a more robust framework to get the solution. 



\subsection{Sketching for Numerical Linear Algebra}
In this work, we use the sketching technique to accelerate a submodular optimization problem. We provide a brief overview of prior sketching work across various domains. Sketching has been utilized to enhance numerous continuous optimization challenges, including linear programming ____, empirical risk minimization ____, the cutting plane method ____, calculating the John Ellipsoid ____, and many more.
Beyond continuous optimization, sketching has also been applied to several discrete optimization issues ____. Additionally, sketching concepts have been implemented in addressing theoretical problems in large language models, such as exponential and softmax regression ____, and reducing the feature dimension of attention matrices ____. Sketching techniques prove valuable in various machine learning tasks, including matrix completion ____, adversarial training ____, training over-parameterized neural tangent kernel regression ____, matrix sensing ____, kernel density estimation ____, and federated learning ____. Moreover, the application of sketching extends to the theory of relational databases ____.