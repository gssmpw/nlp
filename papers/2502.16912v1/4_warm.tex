\section{WARMUP}\label{sec:additive}
 

In this section, to demonstrate the new technique, we prove the following theorem.

\begin{lemma}\label{lem:warmup}
Given two $n \times n$ size matrices $A$ and $W$, $1 \leq k \leq n$  such that: Let each entry of $A,W$ can be represented by $n^{\gamma}$ bits, with $\gamma \in (0,1)$; Let $\OPT$ be defined as Definition~\ref{def:opt}.  
Then, we can show
\begin{itemize}
\item {\bf Part 1.} There is an algorithm that runs in $2^{O(nk\log n)}$ time, and outputs a number $\Lambda$  such that $\OPT \leq \Lambda \leq 2 \OPT $. 
\item {\bf Part 2.} There is an algorithm that runs in $2^{O(n k \log n)}$ time and returns $U \in \R^{n \times k}$ and $V \in \R^{n \times k}$ such that $\| (UV^\top - A) \circ W \|_F^2 \leq 2 \OPT$.
\end{itemize}
\end{lemma}



\begin{proof}

{\bf Proof of Part 1.}

We can create $2nk$ variables to explicitly represent each entry of $U$ and $V$. Let $g(x) =  \| W \circ ( U V^\top - A ) \|_F^2$. Let $L = 2^{n^{\gamma}}$. Then, we can write down a polynomial system (the decision problem defined in Theorem~\ref{thm:decision_problem})
\begin{align*}
   \min & ~  g(x) \\
    \mathrm{~s.t.~} & ~  U_{i,j} \in [-L,L], \forall i,j \\
    & ~ V_{i,j} \in [-L,L], \forall i,j
\end{align*}
Using Theorem~\ref{thm:jpt13}, we know the above system has
\begin{align*}
    \m = 2nk, \v = 2nk, \d = 4, \H = n^{\gamma}, \wt{\H} = n^{\gamma} + O(nk).
\end{align*}
The lower bound on $g(x)$ (if $g(x)$ is not zero) is going to be  
\begin{align*}
    c_{\mathrm{lower}} = & ~ 2^{-2^{3\v \log (\d)} \log (\wt{H}) } \\
    \geq & ~  ~ 2^{-2^{ O( nk )} \log(n^{\gamma} + nk) } \\
    \geq & ~  ~ 2^{-2^{O(nk \log n)}}.
\end{align*}

By Lemma~\ref{lem:opt}, we know the upper bound is $C_{\mathrm{upper}} = \poly(n) \cdot 2^{n^{\gamma}}$.
After knowing the lower bound and upper bound on cost, the number of binary search iterations is upper-bounded by
\begin{align*}
\log( \frac{C_{\mathrm{upper}}}{ c_{\mathrm{lower}} } ) 
= ~ \log( \frac{ \poly(n) 2^{n^{\gamma}} }{ 2^{-2^{ O(nk \log n)} } } ) 
\leq  ~ 2^{O(nk \log n)}.
\end{align*}


In each of the above iterations, we need to run Theorem~\ref{thm:decision_problem} with the system 
\begin{align*}
    \mathrm{~s.t.~} 
    & ~  g(x) \in [\Gamma_t, 2 \Gamma_t] , ~ U_{i,j} \in [-L, L] , ~ V_{i,j} \in [-L, L]
\end{align*}
with parameters,
\begin{align*}
\m = 2nk+1,  \v = 2nk, \d =4, \H = n^{\gamma}.
\end{align*}
Then, running time complexity is
\begin{align*}
 (\m \d)^{O(\v)} \cdot \poly(\H) 
 =  & ~ (10nk)^{O(nk)} \cdot \poly(n^{\gamma}) \\
 =  & ~ 2^{O( n k \log n) }.
\end{align*}

Thus, combining the number of iterations and time for each iteration, we can find the number $\Gamma \in [\OPT, 2\OPT]$.

{\bf Proof of Part 2.}

Next, similar to {\bf Part 1}, we need to repeat the binary search for $2nk$ times for each variable in $U$ and $V$, and each time, the number of total binary search steps is $n^{\gamma}$. Thus, we can output the $U, V$ in the same running time as finding $\Gamma$.
\end{proof}

In the next few sections, we will explain how to reduce the number of variables and how to reduce the number of constraints.