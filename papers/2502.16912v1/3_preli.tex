\section{PRELIMINARY}\label{sec:prelim}

We define $[n]:= \{1,2, \dots, n\}$.
Let $\R$ denote the real numbers, and $\R_{\geq 0}$ denote the nonnegative real numbers. Let $\|A\|$   denote the spectral norm of matrix $A$. Let $\|A\|_{F}^{2}=\sum_{i, j} A_{i, j}^{2}$ denote the Frobenius norm of $A$. Let $W \circ A$ denote the entry-wise product of matrices $W$ and $A$. Let $\|A\|_{W}^{2}=\sum_{i, j} W_{i, j}^{2} A_{i, j}^{2}$ denote the weighted Frobenius norm of $A$. Let $\nnz(A)$ denote the number of nonzero entries of $A$. Let $\det(A)$ denote the determinant of a square matrix $A$. Let $A^{\top}$ denote the transpose of $A$. Let $A^{\dagger}$ denote the Moore-Penrose pseudo-inverse of $A$. Let $A^{-1}$ denote the inverse of a full rank square matrix $A$.

For the weight matrix $W$, we always use $W_{*,j}$ to denote the $j$-th column of $W$, and $W_{i,*}$ to denote the $i$-th row of $W$. Let $\diag(W_{*,j})$ denote the diagonal matrix with entries from the vector $W_{*,j}$. Let $\diag(W_{i,*} )$ denote the diagonal matrix with entries from the  vector $W_{i,*}$.

\begin{definition}[Distinct rows and columns]\label{def:distinct}
Given a matrix $R \in m \times n$, we have $R_{*,1}, R_{*,2}, \dots, R_{*,n} \in \R^{m}$ as its column vectors, and $R_{1,*}^\top, R_{2,*}^\top, \dots, R_{m,*}^\top \in \R^{n}$ as its row vectors. We define $r:= |\{ R_{*,1}, R_{*,2}, \dots, R_{*,n} \}|$ and $p := |\{ R_{1,*}^\top, R_{2,*}^\top, \dots, R_{m,*}^\top \}|$, where $|\cdot|$ means the cardinality of a set, i.e., the number of elements in a set. Then, we say $R$ has  $r$ distinct columns and $p$ distinct rows.
\end{definition}


\begin{assumption}\label{ass:W}
Let $r, p \in \mathbb{N}_+$.  We assume $n \times n$ matrix $W$ has $r$ distinct columns and rows. We also assume that $W\circ A$ has $rp$ distinct columns and rows.    
\end{assumption}

In a real application, when the data has strong periodicity, e.g., signal processing, or uniformly draws from a small set, e.g., classification, or the data has a certain structure, e.g., block attention mask in Transformers \citep{vsp+17,flexattn}, the matrix may have a small number of distinct columns or rows. 
 


Let $\mathbb{Z}[x_1, x_2, \cdots,x_v]$ denote the set of multi-variable polynomial with $v$ variables and the coefficients are from $\mathbb{Z}$. Furthermore, if all the coefficients of a polynomial are from $\{0,1, \cdots, 2^H\}$, then we say the bitsize of coefficients of this polynomial is $H$.

\begin{lemma}[Cramer's rule]
Let $R$ be an $n \times n$ invertible matrix. Then, for each $i \in [n]$, $j \in [n]$,
\begin{align*}
    (R^{-1})_{i,j} = \det( R_{ -j }^{-i} ) / \det(R),
\end{align*}
where $R_{ -j }^{-i}$ is the matrix $R$ with the $i$-th row and $j$-th column removed.
\end{lemma}




\subsection{Polynomial System Decision Solver}

Here, we formally state the theorem of the decision problem. 
For a full discussion of
algorithms in real algebraic geometry, we refer the reader to \cite{bpr5}
and \cite{b14}.
\begin{theorem}[Decision Problem \citep{r92a,r92b,bpr96}]\label{thm:decision_problem}
Given a real polynomial system $P (x_{1}, x_{2}, \cdots, x_{\v} )$ having $\v$ variables and $\m$ polynomial constraints $f_{i} (x_{1}, x_{2}, \cdots, x_{\v} ) \Delta_{i} 0, \forall i \in[\m]$, where $\Delta_{i}$ is any of the ``standard relations'': $\{>, \geq,=, \neq, \leq ,<\}$, let $\d$ denote the maximum degree of all the polynomial constraints and let $\H$ denote the maximum bitsize of the coefficients of all the polynomial constraints.  
Then in
\begin{align*}
(\m \d)^{O(\v)} \poly(\H)
\end{align*}
time, one can determine whether a real solution exists for the polynomial system $P$.
\end{theorem}


\subsection{Lower Bound on Cost}
The key result we used for proving the lower bound is the
following bound on the minimum value attained by an integer
polynomial restricted to a compact connected component
of a basic closed semi-algebraic subset of $\R^{\v}$ (see details in Definition~\ref{def:real_field}) defined by polynomials with integer coefficients in terms of the degrees
and the bitsizes of the coefficients of the polynomials involved. 

\begin{theorem}[\cite{jpt13}] \label{thm:jpt13}
Let $T := \{x \in \R^{\v} \mid f_{1}(x) \geq 0, \cdots ,f_{\ell}(x) \geq 0, f_{\ell+1}(x)=0, \cdots, f_{\m}(x)=0 \}$ be defined by polynomials $f_{1}, \cdots, f_{\m} \in \mathbb{Z} [x_{1}, \cdots, x_{\v} ]$ 
with $\v \geq 2$, degrees bounded by an even integer $\d$ and coefficients of absolute value at most $\H$ bitsize, and let $C$ be a compact connected component of $T$. Let $g \in \mathbb{Z} [x_{1}, \cdots, x_{\v} ]$ (here $g$ can be viewed as an objective function) be a polynomial of degree at most $\d$ and coefficients of absolute value bounded by $\H$. Let $\wt{\H}:=\max \{\H, 2 \v+2 \m\}$. Then, the minimum value that $g$ takes over $C$ satisfies that if it is not zero, then its absolute value is $\geq $  
\begin{align*}
 2^{- 2^{3\v \log(\d)} \log( \wt{\H} )}.
\end{align*}
\end{theorem}




\subsection{Upper Bound on Cost}\label{sec:upper_bound}
Now, we provide the upper bound on the $\OPT$, which is defined below. 

\begin{definition}\label{def:opt}
Given $A, W \in \R^{n \times n}$ and $k \in [n]$, we define $\OPT$ as
    \begin{align*}
        \OPT := \min _{U \in \R^{n \times k}, V \in \R^{n \times k}}\|(U V^\top-A) \circ W\|_F^2 .
    \end{align*}
\end{definition}

\begin{lemma}[folklore]\label{lem:opt}
Let $A, W, \OPT$ be defined in Definition~\ref{def:opt}. Let each entry of $A,W$ can be represented by $n^{\gamma}$ bits, with $\gamma \in (0,1)$. Then, we have
\begin{align*}
\OPT \leq \poly(n) \cdot 2^{n^{\gamma}}.
\end{align*}
\end{lemma}

\begin{proof}
Set $U$ and $V$ to be the zero matrices.
\end{proof}

\subsection{Sketching Tool}
 
We use a sketching tool from previous work.
\begin{lemma}[Theorem 3.1 in \cite{rsw16}]
Let $A^1, \ldots, A^m \in \R^{n \times k}$ be $m$ matrices of size $n \times k$. Let $b^1, \ldots, b^m \in \R^{n \times 1}$ be $m$ column vectors of dimension $n$. For $1 \leq i \leq m$ denote: $x^i= \arg\min_{ x \in \R^{k} } \|A^i x-b^i \|_2^2$ the solution of the $i$-th regression problem. Let $S \in \R^{t \times n}$ be a random matrix with i.i.d. Gaussian entries with zero mean and standard deviation $1 / \sqrt{t}$. For $1 \leq i \leq m$ denote $ y^i= \arg\min_{y \in \R^{k}} \|S A^i y-S b^i \|_2^2 $  the solution of the $i$-th regression problem in the sketch space. We claim that for every $0<\epsilon<1 / 2$, with high probability, one can set $t=O(k / \epsilon)$ such that: 
\begin{align*}
\sum_{i=1}^m \|A^i y^i-b^i \|_2^2 \leq(1+\epsilon) \cdot \sum_{i=1}^m \|A^i x^i-b^i \|_2^2.
\end{align*}
\end{lemma}


\subsection{Backgrounds on Semi-Algebraic Sets}\label{sec:preli_app}


The following real algebraic geometry definitions are needed when proving a lower bound for the minimum nonzero cost of our problem. For a full discussion, we refer the reader to \cite{bcr87}. Here, we use the brief summary by \cite{bpr5}.


\begin{definition}[\cite{bpr5}]\label{def:real_field}
Let $R$ be a real closed field. 
Given $x= (x_{1}, \cdots, x_{v} ) \in R^{v}, r \in R, r>0$, we denote
\begin{align*}
B_{v}(x, r) := & ~ \{y \in R^{v} |\| y-x \|^{2}<r^{2} \}  \mathrm{~~~ (open~ball), } \\
\bar{B}_{v}(x, r) := & ~ \{y \in R^{v}| \| y - x \|^{2} \leq r^{2} \}  \mathrm{~~~ (closed~ball) }.
\end{align*}

$A$ set $S \subset R^{v}$ is open if it is the union of open balls, i.e., if every point of $U$ is contained in an open ball contained in $U$.

A set $S \subset R^{v}$ is closed if its complement is open. Clearly, the arbitrary union of open sets is open, and the arbitrary intersection of closed sets is closed.

Semi-algebraic sets are defined by a finite number of polynomial inequalities and equalities.

A semi-algebraic set has a finite number of connected components, each of which is semi-algebraic. Here, we use the topological definition of a connected component, which is a maximal connected subset (ordered by inclusion), where connected means it cannot be divided into two disjoint nonempty closed sets.

A closed and bounded semi-algebraic set is compact.

A semi-algebraic set $S \subset R^{v}$ is semi-algebraically connected if $S$ is not the disjoint union of two non-empty semialgebraic sets that are both closed in S. Or, equivalently, $S$ does not contain a non-empty semi-algebraic strict subset which is both open and closed in $S$. 

A semi-algebraically connected component of a semi-algebraic set $S$ is a maximal semi-algebraically connected subset of $S$. 
\end{definition}
