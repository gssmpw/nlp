[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhou2020makelttalk",
        "author": "Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu",
        "title": "Makelttalk: speaker-aware talking-head animation"
      },
      {
        "key": "chen2019hierarchical",
        "author": "Chen, Lele and Maddox, Ross K and Duan, Zhiyao and Xu, Chenliang",
        "title": "Hierarchical cross-modal talking face generation with dynamic pixel-wise loss"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "goodfellow2020generative",
        "author": "Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua",
        "title": "Generative adversarial networks"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wen2020photorealistic",
        "author": "Wen, Xin and Wang, Miao and Richardt, Christian and Chen, Ze-Yin and Hu, Shi-Min",
        "title": "Photorealistic audio-driven video portraits"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "paysan20093d",
        "author": "Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas",
        "title": "A 3D face model for pose and illumination invariant face recognition"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wang2021one",
        "author": "Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu",
        "title": "One-shot free-view neural talking-head synthesis for video conferencing"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xing2023codetalker",
        "author": "Xing, Jinbo and Xia, Menghan and Zhang, Yuechen and Cun, Xiaodong and Wang, Jue and Wong, Tien-Tsin",
        "title": "Codetalker: Speech-driven 3d facial animation with discrete motion prior"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "li2017learning",
        "author": "Li, Tianye and Bolkart, Timo and Black, Michael J and Li, Hao and Romero, Javier",
        "title": "Learning a model of facial shape and expression from 4D scans."
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "fan2022faceformer",
        "author": "Fan, Yingruo and Lin, Zhaojiang and Saito, Jun and Wang, Wenping and Komura, Taku",
        "title": "Faceformer: Speech-driven 3d facial animation with transformers"
      },
      {
        "key": "gong2023toontalker",
        "author": "Gong, Yuan and Zhang, Yong and Cun, Xiaodong and Yin, Fei and Fan, Yanbo and Wang, Xuan and Wu, Baoyuan and Yang, Yujiu",
        "title": "ToonTalker: Cross-domain face reenactment"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ye2023geneface",
        "author": "Ye, Zhenhui and Jiang, Ziyue and Ren, Yi and Liu, Jinglin and He, Jinzheng and Zhao, Zhou",
        "title": "Geneface: Generalized and high-fidelity audio-driven 3d talking face synthesis"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "guo2024liveportrait",
        "author": "Guo, Jianzhu and Zhang, Dingyun and Liu, Xiaoqiang and Zhong, Zhizhou and Zhang, Yuan and Wan, Pengfei and Zhang, Di",
        "title": "LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      },
      {
        "key": "song2020denoising",
        "author": "Song, Jiaming and Meng, Chenlin and Ermon, Stefano",
        "title": "Denoising diffusion implicit models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      },
      {
        "key": "ruiz2023dreambooth",
        "author": "Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir",
        "title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation"
      },
      {
        "key": "shi2024motion",
        "author": "Shi, Xiaoyu and Huang, Zhaoyang and Wang, Fu-Yun and Bian, Weikang and Li, Dasong and Zhang, Yi and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and others",
        "title": "Motion-i2v: Consistent and controllable image-to-video generation with explicit motion modeling"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "brooks2023instructpix2pix",
        "author": "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
        "title": "Instructpix2pix: Learning to follow image editing instructions"
      },
      {
        "key": "cao2023masactrl",
        "author": "Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Shan, Ying and Qie, Xiaohu and Zheng, Yinqiang",
        "title": "Masactrl: Tuning-free mutual self-attention control for consistent image synthesis and editing"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "he2022latent",
        "author": "He, Yingqing and Yang, Tianyu and Zhang, Yong and Shan, Ying and Chen, Qifeng",
        "title": "Latent video diffusion models for high-fidelity long video generation"
      },
      {
        "key": "ma2024followpose",
        "author": "Ma, Yue and He, Yingqing and Cun, Xiaodong and Wang, Xintao and Chen, Siran and Li, Xiu and Chen, Qifeng",
        "title": "Follow your pose: Pose-guided text-to-video generation using pose-free videos"
      },
      {
        "key": "wang2024animatelcm",
        "author": "Wang, Fu-Yun and Huang, Zhaoyang and Shi, Xiaoyu and Bian, Weikang and Song, Guanglu and Liu, Yu and Li, Hongsheng",
        "title": "Animatelcm: Accelerating the animation of personalized diffusion models and adapters with decoupled consistency learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "li2024lodge",
        "author": "Li, Ronghui and Zhang, YuXiang and Zhang, Yachao and Zhang, Hongwen and Guo, Jie and Zhang, Yan and Liu, Yebin and Li, Xiu",
        "title": "Lodge: A coarse to fine diffusion network for long dance generation guided by the characteristic dance primitives"
      },
      {
        "key": "qi2023fatezero",
        "author": "Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng",
        "title": "Fatezero: Fusing attentions for zero-shot text-based video editing"
      },
      {
        "key": "zhang2023controlvideo",
        "author": "Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi",
        "title": "Controlvideo: Training-free controllable text-to-video generation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhang2023adding",
        "author": "Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh",
        "title": "Adding conditional control to text-to-image diffusion models"
      },
      {
        "key": "li2025controlnet",
        "author": "Li, Ming and Yang, Taojiannan and Kuang, Huafeng and Wu, Jie and Wang, Zhaoning and Xiao, Xuefeng and Chen, Chen",
        "title": "ControlNet: Improving Conditional Controls with Efficient Consistency Feedback"
      },
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      },
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "tian2024emo",
        "author": "Tian, Linrui and Wang, Qi and Zhang, Bang and Bo, Liefeng",
        "title": "Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions"
      },
      {
        "key": "chen2024echomimic",
        "author": "Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang",
        "title": "Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions"
      },
      {
        "key": "wang2024v",
        "author": "Wang, Cong and Tian, Kuan and Zhang, Jun and Guan, Yonghang and Luo, Feng and Shen, Fei and Jiang, Zhiwei and Gu, Qing and Han, Xiao and Yang, Wei",
        "title": "V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation"
      },
      {
        "key": "xu2024hallo",
        "author": "Xu, Mingwang and Li, Hui and Su, Qingkun and Shang, Hanlin and Zhang, Liwei and Liu, Ce and Wang, Jingdong and Yao, Yao and Zhu, Siyu",
        "title": "Hallo: Hierarchical audio-driven visual synthesis for portrait image animation"
      },
      {
        "key": "ma2024follow",
        "author": "Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others",
        "title": "Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "hu2024animate",
        "author": "Hu, Li",
        "title": "Animate anyone: Consistent and controllable image-to-video synthesis for character animation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "guo2023animatediff",
        "author": "Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo",
        "title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "tian2024emo",
        "author": "Tian, Linrui and Wang, Qi and Zhang, Bang and Bo, Liefeng",
        "title": "Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "chen2024echomimic",
        "author": "Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang",
        "title": "Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2024v",
        "author": "Wang, Cong and Tian, Kuan and Zhang, Jun and Guan, Yonghang and Luo, Feng and Shen, Fei and Jiang, Zhiwei and Gu, Qing and Han, Xiao and Yang, Wei",
        "title": "V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "ma2024follow",
        "author": "Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others",
        "title": "Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "zhang2023adding",
        "author": "Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh",
        "title": "Adding conditional control to text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "xie2024x",
        "author": "Xie, You and Xu, Hongyi and Song, Guoxian and Wang, Chao and Shi, Yichun and Luo, Linjie",
        "title": "X-portrait: Expressive portrait animation with hierarchical motion attention"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "cui2024hallo2",
        "author": "Cui, Jiahao and Li, Hui and Yao, Yao and Zhu, Hao and Shang, Hanlin and Cheng, Kaihui and Zhou, Hang and Zhu, Siyu and Wang, Jingdong",
        "title": "Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "wang2024instructavatar",
        "author": "Wang, Yuchi and Guo, Junliang and Bai, Jianhong and Yu, Runyi and He, Tianyu and Tan, Xu and Sun, Xu and Bian, Jiang",
        "title": "InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "peebles2023scalable",
        "author": "Peebles, William and Xie, Saining",
        "title": "Scalable diffusion models with transformers"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "wang2021one",
        "author": "Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu",
        "title": "One-shot free-view neural talking-head synthesis for video conferencing"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "drobyshev2022megaportraits",
        "author": "Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor",
        "title": "Megaportraits: One-shot megapixel neural head avatars"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "xu2024hallo",
        "author": "Xu, Mingwang and Li, Hui and Su, Qingkun and Shang, Hanlin and Zhang, Liwei and Liu, Ce and Wang, Jingdong and Yao, Yao and Zhu, Siyu",
        "title": "Hallo: Hierarchical audio-driven visual synthesis for portrait image animation"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "jiang2024loopy",
        "author": "Jiang, Jianwen and Liang, Chao and Yang, Jiaqi and Lin, Gaojie and Zhong, Tianyun and Zheng, Yanbo",
        "title": "Loopy: Taming audio-driven portrait avatar with long-term motion dependency"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "siarohin2019first",
        "author": "Siarohin, Aliaksandr and Lathuili{\\`e}re, St{\\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu",
        "title": "First order motion model for image animation"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "paysan20093d",
        "author": "Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas",
        "title": "A 3D face model for pose and illumination invariant face recognition"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "li2017learning",
        "author": "Li, Tianye and Bolkart, Timo and Black, Michael J and Li, Hao and Romero, Javier",
        "title": "Learning a model of facial shape and expression from 4D scans."
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "zhou2021pose",
        "author": "Zhou, Hang and Sun, Yasheng and Wu, Wayne and Loy, Chen Change and Wang, Xiaogang and Liu, Ziwei",
        "title": "Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "wang2023progressive",
        "author": "Wang, Duomin and Deng, Yu and Yin, Zixin and Shum, Heung-Yeung and Wang, Baoyuan",
        "title": "Progressive disentangled representation learning for fine-grained controllable talking head synthesis"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "tan2025edtalk",
        "author": "Tan, Shuai and Ji, Bin and Bi, Mengxiao and Pan, Ye",
        "title": "Edtalk: Efficient disentanglement for emotional talking head synthesis"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "wang2023progressive",
        "author": "Wang, Duomin and Deng, Yu and Yin, Zixin and Shum, Heung-Yeung and Wang, Baoyuan",
        "title": "Progressive disentangled representation learning for fine-grained controllable talking head synthesis"
      },
      {
        "key": "tan2025edtalk",
        "author": "Tan, Shuai and Ji, Bin and Bi, Mengxiao and Pan, Ye",
        "title": "Edtalk: Efficient disentanglement for emotional talking head synthesis"
      }
    ]
  }
]