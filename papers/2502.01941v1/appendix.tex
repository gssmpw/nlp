\clearpage
\onecolumn
\appendix 
% \etocdepthtag.toc{mtappendix}
% \etocsettagdepth{mtchapter}{none}
% \etocsettagdepth{mtappendix}{subsection}
% \renewcommand{\contentsname}{Appendix}
% \tableofcontents 
% \clearpage
% \etocdepthtag.toc{mtappendix}
% \etocsettagdepth{mtchapter}{none}
% \etocsettagdepth{mtappendix}{subsection}
% \renewcommand{\contentsname}{Appendix}
% \tableofcontents 
% \clearpage




\section{Additional Related work}
\label{appendix:related_work}

\paragraph{KV cache sharing}
Recent work has explored various strategies for sharing KV caches across transformer layers. Layer-Condensed KV Cache (LCKV) \citep{wu2024layercondensedkvcacheefficient} computes KVs only for the top layer and pairs them with queries from all layers, while optionally retaining standard attention for a few top and bottom layers to mitigate performance degradation. Similarly, You Only Cache Once (YOCO) \citep{sun2024yoco} computes KVs exclusively for the top layer but pairs them with queries from only the top half of layers, employing efficient attention in the bottom layers to maintain a constant cache size. In contrast, Cross-Layer Attention (CLA) \citep{brandon2024reducing} divides layers into groups, pairing queries from all layers in each group with KVs from that group's bottom layer. MiniCache \citep{liu2024minicache} introduces a novel method that merges layer-wise KV caches while enabling recovery during compute-in-place operations, optimizing KV cache size. These methods illustrate various trade-offs between computation, memory usage, and model performance when sharing KV caches across transformer layers.


\paragraph{Prompting Compression}
Recent advances in prompt compression have yielded innovative approaches to information density optimization in natural language processing. Research by \citet{wingate-etal-2022-prompt} demonstrates how soft prompting techniques can achieve higher information density per token. Building upon this foundation, AutoCompressor \citep{Chevalier2023AdaptingLM} leverages soft prompts to both condense input sequences and expand model context windows. Parallel developments by \citet{zhou2023recurrentgpt} and \citet{wang2023recursively} showcase iterative summarization strategies using LLMs, establishing persistent memory mechanisms particularly beneficial for narrative construction and conversational systems. The progressive development of the LLMLingua framework \citep{jiang-etal-2023-llmlingua,jiang-etal-2024-longllmlingua,fei-etal-2024-extending} has advanced prompt compression capabilities across extended context processing, logical reasoning, and retrieval-augmented generation. Notable contributions from \citet{fei-etal-2024-extending} demonstrate effective context management through automated segmentation and semantic condensation using pre-trained language models.

\paragraph{General Tasks}
General tasks refer to evaluating the overall performance of LLMs under mathematical inference, logic reasoning, and common knowledge GSM8K~\cite{gsm8k} and MMLU~\cite{mmlu} are the representative tasks. The former focuses on the step-by-step reasoning ability of mathematical problem solving while the latter covers assessment of common sense and expertise in multiple areas. Besides, MATH~\cite{math} spans various mathematical fields, ranging from elementary algebra to calculus, aiming to improve the mathematical problem-solving capabilities of LLMs. Meanwhile, MathQA~\cite{mathqa} is a large-scale dataset comprising approximately 37,000 multiple-choice questions with precise annotations, designed to enhance the interpretability and performance of LLMs. In addition, BBH~\cite{bbh}, a subset of BIG-Bench~\cite{bigbench}, focuses on challenging tasks. BBH includes multi-step reasoning problems, highlighting the importance of Chain-of-Thought prompting in LLMs. Similarly, CSQA~\cite{csqa} is a task that combines knowledge graph-based multi-step reasoning with conversational capabilities. CSQA emphasizes inference and context understanding grounded in knowledge graphs. Normally, the general tasks apply automatic evaluation metrics (e.g. multi-choice accuracy) to ensure comparability and standardization. However, optimization strategies like KV cache compression may introduce challenges in executing the mentioned tasks. Filtering and dropping of contexts are involved in the compression strategy which may lead to an intermediate inference steps missing. In addition, in tasks such as MMLU that are highly dependent on knowledge coverage, compression may weaken the model's ability to capture long context or rare domain knowledge~\cite{yuan2024kv}.

\paragraph{Security Tasks}
Security tasks focus on assessing the robustness and protections of LLMs against harmful content, including truthfulness~\cite{lin2021truthfulqa}, toxicity~\cite{hartvigsen2022toxigen}, and bias~\cite{liang2021towards}. Recently, researchers noticed the weakness of LLMs in adversarial prompts~\cite{zhu2023promptbench}, especially in generating illegal or inappropriate content under jailbreak prompts. \citet{shen2024anything} analyze the jailbreak prompts in real cases to reveal the failure of model security mechanism under complex malicious input. Meanwhile, \citet{deng2023multilingual} demonstrates the multilingual jailbreak makes model security in low-resource languages easier to bypass, significantly increasing the probability that users of low-resource languages will generate insecure content. Similar to general tasks, KV optimization techniques can cause the model to ignore potential security threats when dealing with jailbreak prompts, thereby improving the success rate of adversarial prompts~\cite{li2024should}.

\paragraph{Code Generation Tasks}
Code generation tasks test the capacities of LLMs to generate code, which not only requires that the model can generate syntactic code based on natural language description but also has certain logical reasoning abilities. HumanEval~\cite{chen2021evaluating} and MBPP~\cite{austin2021program} are the commonly used benchmarks. They measure the functional correctness of the model by testing the results of the code's execution.

\paragraph{Long-context Tasks}
Recent developments in evaluating long-context models have produced a comprehensive ecosystem of benchmarks, focusing on both comprehension depth and retrieval efficiency. In the comprehension domain, $\infty$-Bench~\citep{zhang2024infty} has established new standards by crafting evaluation scenarios exceeding 100,000 tokens, while LongBench~\citep{longbench,longbenchv2} introduced multilingual assessment frameworks spanning document comprehension, text synthesis, and programming tasks. Further enriching this landscape, ZeroSCROLLS~\citep{shaham2023zeroscrolls} and L-Eval~\citep{an2023eval} have expanded evaluation criteria to encompass real-world applications, particularly in query-based content summarization. The emergence of many-shot learning as a distinct paradigm for extended context processing~\cite{agarwal2024many} has added another dimension to this field. Notable contributions from LongGenBench~\cite{longgenbench} have advanced evaluation methodologies by combining extensive response generation requirements with efficient, cost-effective quality metrics.

The development of retrieval-focused benchmarks has taken a distinct approach, predominantly utilizing constructed datasets that enable precise experimental control, particularly in managing input sequence lengths. This methodology helps neutralize variations in model performance stemming from differences in training approaches. Substantial research efforts have yielded specialized synthetic frameworks for assessing retrieval capabilities~\citep{needle, mohtashami2023landmark, longchat, liu2024lost, hsieh2024ruler}, while concurrent investigations have revealed the broader implications of extended context processing for enhanced reasoning capabilities~\citep{tay2020long}.



\section{Experiment Details}

\subsection{Hyper-parameters}
\label{sec:hyperparameters}
The hyper-parameters for different observations are shown in \cref{tab:hyperparameters}. The temperature for the experiments are set to 0 for ensuring the deterministic results.
\begin{table}[h]
    \centering
    \caption{Hyperparameters for Different Observations}
    \label{tab:hyperparameters}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{l|ccccc|cc}
    \toprule
    \multirow{2}{*}{Benchmarks} & Obs 1 & Obs 2 & Obs 3 & Obs 4 & Obs 5 & \multicolumn{2}{c}{Obs 6} \\
    \cmidrule{2-6} \cmidrule{7-8}
    & \multicolumn{5}{c|}{Number of Shots} & $K$ & $T$ \\
    \midrule
    MMLU~\cite{mmlu} & 5 & 5 & - & - & 0,5 & - & - \\
    CommonsenseQA~\cite{csqa} & 4 & 4 & - & - & - & - & - \\
    GSM8K~\cite{gsm8k} & 8 & 8 & 1-8 & 50 & 0,8 & - & - \\
    HumanEval~\cite{chen2021evaluating} & 8 & 8 & - & - & - & - & - \\
    JailBreakV~\cite{luo2024jailbreakv} & 8 & 8 & - & - & - & - & - \\ \midrule
    LongGenBench-GSM8K~\cite{longgenbench} & - & - & - & - & - & 35 & 20 \\
    \bottomrule
    \end{tabular}
    }
\end{table}



\subsection{Detail Results}
\label{sec:detail-results}
This section provide the detailed results of experiments in this paper, the results are shown in the format of $x_{y}$, where $x$ is the performance of the method and $y$ is the $\Delta P$ from the \cref{eq:performance_change}.

\paragraph{Observation 1.} \textbf{KV cache compression methods show task-dependent performance degradation, with varying sensitivity thresholds across different benchmark categories.}

The detailed results of different KV cache compression methods are shown in \cref{tab:kv-compression-obs1}, different tasks exhibit notably varied sensitivities to KV cache compression, particularly under aggressive compression ratios. At a 10\% compression ratio, MMLU demonstrates remarkable resilience with less than 1\% average performance degradation, while GSM8K experiences a severe average performance drop exceeding 35\%. Other tasks show moderate to significant degradation, ranging from 6.5\% to 17.2\%. This substantial variation in compression sensitivity across tasks suggests that the effectiveness of KV cache compression is highly task-dependent, necessitating careful consideration of the specific task requirements when determining appropriate compression ratios.



The \cref{tab:kv-compression-r1} compares the performance of R1-Distill-Llama-8B and LLaMA-3.1-8B-Instruct under different compression ratios. R1-Distill-Llama-8B demonstrates more robust performance under compression compared to LLaMA-3.1-8B-Instruct. While both models start with similar baseline performance (0.6938 vs 0.7945), R1-Distill shows significantly less performance degradation under aggressive compression. Specifically, at 30\% compression ratio, R1-Distill maintains a performance of 0.6407 (-7.66\%), while LLaMA-3.1-8B-Instruct drops to 0.7469 (-6.00\%). The difference becomes more pronounced at 10\% compression ratio, where R1-Distill achieves 0.5840 (-15.82\%) compared to LLaMA-3.1-8B-Instruct's sharp decline to 0.5143 (-35.30\%). This suggests that the multi-step reasoning capabilities of R1-Distill contribute to its resilience against aggressive KV cache compression, particularly in maintaining reasoning coherence under limited context conditions.
\begin{table}[h]
    \centering
    \caption{Performance Comparison of Different KV Cache Compression Methods on Instruction-Tuning Model and Multi-Step Reasoning Model}
    \label{tab:kv-compression-r1}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lcccccc|c}
    \toprule
    \textbf{Benchmark} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$} \\
    \midrule
        \multirow{10}{*}{R1-GSM8K}
    & Baseline  & \multicolumn{5}{c|}{R1-Distill-Llama-8B FullKV: 0.6938} & \\ \cmidrule{2-8}
    & $90\%$  & $0.7167_{(+3.30\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7100_{(+2.34\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6993_{(+0.79\%)}$ \\
    & $80\%$  & $0.6867_{(-1.02\%)}$ & $0.6933_{(-0.07\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6767_{(-2.47\%)}$ & $0.6913_{(-0.36\%)}$ \\
    & $70\%$  & $0.6933_{(-0.07\%)}$ & $0.6633_{(-4.40\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6953_{(+0.22\%)}$ \\
    & $60\%$  & $0.6833_{(-1.51\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6900_{(-0.55\%)}$ & $0.7133_{(+2.81\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6967_{(+0.42\%)}$ \\
    & $50\%$  & $0.6700_{(-3.43\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7067_{(+1.86\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6920_{(-0.26\%)}$ \\
    & $40\%$  & $0.6767_{(-2.47\%)}$ & $0.6800_{(-1.99\%)}$ & $0.5967_{(-13.99\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7133_{(+2.81\%)}$ & $0.6727_{(-3.04\%)}$ \\
    & $30\%$  & $0.6600_{(-4.87\%)}$ & $0.5900_{(-14.96\%)}$ & $0.5833_{(-15.93\%)}$ & $0.6700_{(-3.43\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6407_{(-7.66\%)}$ \\
    & $20\%$  & $0.6200_{(-10.64\%)}$ & $0.4933_{(-28.90\%)}$ & $0.5633_{(-18.81\%)}$ & $0.6833_{(-1.51\%)}$ & $0.6533_{(-5.84\%)}$ & $0.6026_{(-13.14\%)}$ \\
    & $10\%$  & $0.5167_{(-25.53\%)}$ & $0.5567_{(-19.76\%)}$ & $0.5767_{(-16.88\%)}$ & $0.6267_{(-9.67\%)}$ & $0.6433_{(-7.28\%)}$ & $0.5840_{(-15.82\%)}$ \\

    \midrule
    \multirow{10}{*}{GSM8K}
    & Baseline  & \multicolumn{5}{c|}{LLaMA-3.1-8B-Instruct FullKV: 0.7945} & \\ \cmidrule{2-8}
    & $90\%$  & $0.7695_{(-3.10\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7827_{(-1.50\%)}$ \\
    & $80\%$  & $0.7642_{(-3.80\%)}$ & $0.7938_{(-0.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7826_{(-1.50\%)}$ \\
    & $70\%$  & $0.7642_{(-3.80\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7983_{(+0.50\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7851_{(-1.20\%)}$ \\
    & $60\%$  & $0.7650_{(-3.70\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7830_{(-1.50\%)}$ \\
    & $50\%$  & $0.7657_{(-3.60\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7847_{(-1.20\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7807_{(-1.70\%)}$ \\
    & $40\%$  & $0.7491_{(-5.70\%)}$ & $0.7688_{(-3.20\%)}$ & $0.7756_{(-2.40\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7763_{(-2.30\%)}$ & $0.7707_{(-3.00\%)}$ \\
    & $30\%$  & $0.7051_{(-11.20\%)}$ & $0.7225_{(-9.10\%)}$ & $0.7619_{(-4.10\%)}$ & $0.7718_{(-2.90\%)}$ & $0.7733_{(-2.70\%)}$ & $0.7469_{(-6.00\%)}$ \\
    & $20\%$  & $0.6384_{(-19.70\%)}$ & $0.6406_{(-19.40\%)}$ & $0.6884_{(-13.40\%)}$ & $0.7142_{(-10.10\%)}$ & $0.7763_{(-2.30\%)}$ & $0.6916_{(-13.00\%)}$ \\
    & $10\%$  & $0.4784_{(-39.80\%)}$ & $0.4503_{(-43.30\%)}$ & $0.5034_{(-36.60\%)}$ & $0.4829_{(-39.20\%)}$ & $0.6566_{(-17.40\%)}$ & $0.5143_{(-35.30\%)}$ \\
    \bottomrule
    \end{tabular}
    }
\end{table}

\begin{table}[!h]
    \centering
    \caption{Performance Comparison of Different KV Cache Compression Methods on Multiple Benchmarks}
    \label{tab:kv-compression-obs1}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{lcccccc|c}
    \toprule
    \textbf{Benchmark} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$} \\
    \midrule
    \multirow{10}{*}{MMLU} 
    & Baseline  & \multicolumn{5}{c|}{FullKV: 0.6882} & \\ \cmidrule{2-8}
    & $90\%$  & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ \\
    & $80\%$  & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ \\
    & $70\%$  & $0.6881_{(-0.01\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ \\
    & $60\%$  & $0.6881_{(-0.01\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ \\
    & $50\%$  & $0.6881_{(-0.01\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ \\
    & $40\%$  & $0.6879_{(-0.04\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6881_{(-0.01\%)}$ \\
    & $30\%$  & $0.6876_{(-0.09\%)}$ & $0.6880_{(-0.03\%)}$ & $0.6880_{(-0.03\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6880_{(-0.03\%)}$ \\
    & $20\%$  & $0.6859_{(-0.33\%)}$ & $0.6878_{(-0.06\%)}$ & $0.6880_{(-0.03\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6882_{(+0.00\%)}$ & $0.6876_{(-0.08\%)}$ \\    
    & $10\%$  & $0.6787_{(-1.38\%)}$ & $0.6852_{(-0.44\%)}$ & $0.6831_{(-0.74\%)}$ & $0.6882_{(0.00\%)}$ & $0.6842_{(-0.58\%)}$ & $0.6839_{(-0.63\%)}$ \\
    

    
    % \multirow{10}{*}{R1-GSM8K}
    % & Baseline  & \multicolumn{5}{c|}{FullKV: 0.6938} & \\ \cmidrule{2-8}
    % & $90\%$  & $0.7167_{(+3.30\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7100_{(+2.34\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6993_{(+0.79\%)}$ \\
    % & $80\%$  & $0.6867_{(-1.02\%)}$ & $0.6933_{(-0.07\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6767_{(-2.47\%)}$ & $0.6913_{(-0.36\%)}$ \\
    % & $70\%$  & $0.6933_{(-0.07\%)}$ & $0.6633_{(-4.40\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6953_{(+0.22\%)}$ \\
    % & $60\%$  & $0.6833_{(-1.51\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6900_{(-0.55\%)}$ & $0.7133_{(+2.81\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6967_{(+0.42\%)}$ \\
    % & $50\%$  & $0.6700_{(-3.43\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7067_{(+1.86\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6920_{(-0.26\%)}$ \\
    % & $40\%$  & $0.6767_{(-2.47\%)}$ & $0.6800_{(-1.99\%)}$ & $0.5967_{(-13.99\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7133_{(+2.81\%)}$ & $0.6727_{(-3.04\%)}$ \\
    % & $30\%$  & $0.6600_{(-4.87\%)}$ & $0.5900_{(-14.96\%)}$ & $0.5833_{(-15.93\%)}$ & $0.6700_{(-3.43\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6407_{(-7.66\%)}$ \\
    % & $20\%$  & $0.6200_{(-10.64\%)}$ & $0.4933_{(-28.90\%)}$ & $0.5633_{(-18.81\%)}$ & $0.6833_{(-1.51\%)}$ & $0.6533_{(-5.84\%)}$ & $0.6026_{(-13.14\%)}$ \\
    % & $10\%$  & $0.5167_{(-25.53\%)}$ & $0.5567_{(-19.76\%)}$ & $0.5767_{(-16.88\%)}$ & $0.6267_{(-9.67\%)}$ & $0.6433_{(-7.28\%)}$ & $0.5840_{(-15.82\%)}$ \\


    \midrule
    \multirow{10}{*}{GSM8K}
    & Baseline  & \multicolumn{5}{c|}{FullKV: 0.7945} & \\ \cmidrule{2-8}
    & $90\%$  & $0.7695_{(-3.10\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7827_{(-1.50\%)}$ \\
    & $80\%$  & $0.7642_{(-3.80\%)}$ & $0.7938_{(-0.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7826_{(-1.50\%)}$ \\
    & $70\%$  & $0.7642_{(-3.80\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7983_{(+0.50\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7851_{(-1.20\%)}$ \\
    & $60\%$  & $0.7650_{(-3.70\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7830_{(-1.50\%)}$ \\
    & $50\%$  & $0.7657_{(-3.60\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7847_{(-1.20\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7807_{(-1.70\%)}$ \\
    & $40\%$  & $0.7491_{(-5.70\%)}$ & $0.7688_{(-3.20\%)}$ & $0.7756_{(-2.40\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7763_{(-2.30\%)}$ & $0.7707_{(-3.00\%)}$ \\
    & $30\%$  & $0.7051_{(-11.20\%)}$ & $0.7225_{(-9.10\%)}$ & $0.7619_{(-4.10\%)}$ & $0.7718_{(-2.90\%)}$ & $0.7733_{(-2.70\%)}$ & $0.7469_{(-6.00\%)}$ \\
    & $20\%$  & $0.6384_{(-19.70\%)}$ & $0.6406_{(-19.40\%)}$ & $0.6884_{(-13.40\%)}$ & $0.7142_{(-10.10\%)}$ & $0.7763_{(-2.30\%)}$ & $0.6916_{(-13.00\%)}$ \\
    & $10\%$  & $0.4784_{(-39.80\%)}$ & $0.4503_{(-43.30\%)}$ & $0.5034_{(-36.60\%)}$ & $0.4829_{(-39.20\%)}$ & $0.6566_{(-17.40\%)}$ & $0.5143_{(-35.30\%)}$ \\
    \midrule
    \multirow{10}{*}{CSQA}
    & Baseline  & \multicolumn{5}{c|}{FullKV: 0.7748} & \\ \cmidrule{2-8}
    & $90\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $80\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $70\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $60\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $50\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $40\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $30\%$  & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7748_{(+0.00\%)}$ \\
    & $20\%$  & $0.7174_{(-7.40\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7740_{(-0.10\%)}$ & $0.7748_{(+0.00\%)}$ & $0.7699_{(-0.60\%)}$ & $0.7622_{(-1.60\%)}$ \\
    & $10\%$  & $0.6806_{(-12.20\%)}$ & $0.7510_{(-3.10\%)}$ & $0.7191_{(-7.20\%)}$ & $0.7723_{(-0.30\%)}$ & $0.7002_{(-9.60\%)}$ & $0.7246_{(-6.50\%)}$ \\
%     \bottomrule
% \end{tabular}
% }
% \end{table}

%     \begin{table}[t]
%         \ContinuedFloat
%         \centering
%         \caption{Performance Comparison of Different KV Cache Compression Methods on Multiple Benchmarks (Obs 1 \& 3) (continued)}
%         \label{tab:kv-compression-continued}
%         \resizebox{\textwidth}{!}{
%         \begin{tabular}{lcccccc|c}
%         \toprule
%         \textbf{Benchmark} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$} \\
    \midrule
    \multirow{10}{*}{JailBreakV}
    & Baseline  & \multicolumn{5}{c|}{FullKV: 0.8895} & \\ \cmidrule{2-8}
    & $90\%$  & $0.8893_{(-0.00\%)}$ & $0.8890_{(-0.10\%)}$ & $0.8894_{(-0.00\%)}$ & $0.8893_{(-0.00\%)}$ & $0.8896_{(+0.00\%)}$ & $0.8893_{(-0.00\%)}$ \\
    & $80\%$  & $0.8878_{(-0.20\%)}$ & $0.8885_{(-0.10\%)}$ & $0.8895_{(+0.00\%)}$ & $0.8891_{(-0.00\%)}$ & $0.8894_{(-0.00\%)}$ & $0.8889_{(-0.10\%)}$ \\
    & $70\%$  & $0.8872_{(-0.30\%)}$ & $0.8879_{(-0.20\%)}$ & $0.8896_{(+0.00\%)}$ & $0.8889_{(-0.10\%)}$ & $0.8895_{(+0.00\%)}$ & $0.8886_{(-0.10\%)}$ \\
    & $60\%$  & $0.8845_{(-0.60\%)}$ & $0.8848_{(-0.50\%)}$ & $0.8892_{(-0.00\%)}$ & $0.8887_{(-0.10\%)}$ & $0.8899_{(+0.00\%)}$ & $0.8874_{(-0.20\%)}$ \\
    & $50\%$  & $0.8849_{(-0.50\%)}$ & $0.8749_{(-1.60\%)}$ & $0.8886_{(-0.10\%)}$ & $0.8884_{(-0.10\%)}$ & $0.8894_{(-0.00\%)}$ & $0.8852_{(-0.50\%)}$ \\
    & $40\%$  & $0.8734_{(-1.80\%)}$ & $0.8557_{(-3.80\%)}$ & $0.8880_{(-0.20\%)}$ & $0.8877_{(-0.20\%)}$ & $0.8900_{(+0.10\%)}$ & $0.8790_{(-1.20\%)}$ \\
    & $30\%$  & $0.8329_{(-6.40\%)}$ & $0.8015_{(-9.90\%)}$ & $0.8858_{(-0.40\%)}$ & $0.8899_{(+0.00\%)}$ & $0.8846_{(-0.60\%)}$ & $0.8589_{(-3.50\%)}$ \\
    & $20\%$  & $0.6501_{(-26.90\%)}$ & $0.7178_{(-19.30\%)}$ & $0.8806_{(-1.00\%)}$ & $0.8751_{(-1.60\%)}$ & $0.8902_{(+0.10\%)}$ & $0.8028_{(-9.70\%)}$ \\
    & $10\%$  & $0.5314_{(-40.30\%)}$ & $0.6544_{(-26.40\%)}$ & $0.8434_{(-5.20\%)}$ & $0.8556_{(-3.80\%)}$ & $0.8799_{(-1.10\%)}$ & $0.7529_{(-15.40\%)}$ \\

    \midrule
    \multirow{10}{*}{HumanEval}
    & Baseline  & \multicolumn{5}{c|}{FullKV: 0.5122} & \\ \cmidrule{2-8}
    & $90\%$  & $0.5061_{(-1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ \\
    & $80\%$  & $0.5061_{(-1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5061_{(-1.20\%)}$ & $0.5159_{(+0.70\%)}$ \\
    & $70\%$  & $0.5000_{(-2.40\%)}$ & $0.5244_{(+2.40\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5134_{(+0.20\%)}$ \\
    & $60\%$  & $0.5061_{(-1.20\%)}$ & $0.5366_{(+4.80\%)}$ & $0.5366_{(+4.80\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5244_{(+2.40\%)}$ & $0.5268_{(+2.90\%)}$ \\
    & $50\%$  & $0.4939_{(-3.60\%)}$ & $0.5427_{(+6.00\%)}$ & $0.5061_{(-1.20\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4878_{(-4.80\%)}$ & $0.5049_{(-1.40\%)}$ \\
    & $40\%$  & $0.4817_{(-6.00\%)}$ & $0.5427_{(+6.00\%)}$ & $0.5244_{(+2.40\%)}$ & $0.4939_{(-3.60\%)}$ & $0.5000_{(-2.40\%)}$ & $0.5085_{(-0.70\%)}$ \\
    & $30\%$  & $0.4817_{(-6.00\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5000_{(-2.40\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4817_{(-6.00\%)}$ & $0.4976_{(-2.90\%)}$ \\
    & $20\%$  & $0.4634_{(-9.50\%)}$ & $0.5061_{(-1.20\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4695_{(-8.30\%)}$ & $0.4878_{(-4.80\%)}$ & $0.4841_{(-5.50\%)}$ \\
    & $10\%$  & $0.3659_{(-28.60\%)}$ & $0.4634_{(-9.50\%)}$ & $0.4268_{(-16.70\%)}$ & $0.4207_{(-17.90\%)}$ & $0.4451_{(-13.10\%)}$ & $0.4244_{(-17.20\%)}$ \\
    \bottomrule
    \end{tabular}
    }
\end{table}

\paragraph{Observation 2.} \textbf{Multi-step reasoning LLMs are more robust to KV cache compression.}
As shown in \cref{tab:gsm8k-instruct}, while instruct-tuned models achieve superior baseline performance (0.7945 vs 0.5122), they demonstrate heightened sensitivity to KV cache compression. This sensitivity becomes particularly pronounced at aggressive compression ratios. At 10\% compression ratio, instruct-tuned models suffer an average performance degradation of 35.3\% (from 0.7945 to 0.5143), nearly double the degradation observed in non-instruct-tuned models which show a 17.2\% drop (from 0.5122 to 0.4244). In contrast, R1-Distill-Llama-8B shows better resilience to compression, with only a 15.82\% performance drop (from 0.6938 to 0.5840) at 10\% compression ratio. This pattern suggests that while instruction tuning enhances model capabilities, it also makes the model more dependent on maintaining complete context information. However, models trained with multi-step reasoning capabilities like R1-Distill demonstrate better robustness against aggressive compression, likely due to their enhanced ability to maintain reasoning coherence even with limited context.


\begin{table}[!h]
    \centering
    \caption{KV Cache Compression Performance Comparison on GSM8K with Different Instruction TuningSettings}
    \label{tab:gsm8k-instruct}
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lcccccc|c}
            \toprule
            \textbf{Setting} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$ } \\
            \midrule

            \multirow{10}{*}{w/ Instruct Tuning}
            & Baseline  & \multicolumn{5}{c|}{FullKV: 0.7945} & \\ \cmidrule{2-8}
            & $90\%$  & $0.7695_{(-3.10\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7827_{(-1.50\%)}$ \\
            & $80\%$  & $0.7642_{(-3.80\%)}$ & $0.7938_{(-0.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7826_{(-1.50\%)}$ \\
            & $70\%$  & $0.7642_{(-3.80\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7983_{(+0.50\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7851_{(-1.20\%)}$ \\
            & $60\%$  & $0.7650_{(-3.70\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7830_{(-1.50\%)}$ \\
            & $50\%$  & $0.7657_{(-3.60\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7847_{(-1.20\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7807_{(-1.70\%)}$ \\
            & $40\%$  & $0.7491_{(-5.70\%)}$ & $0.7688_{(-3.20\%)}$ & $0.7756_{(-2.40\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7763_{(-2.30\%)}$ & $0.7707_{(-3.00\%)}$ \\
            & $30\%$  & $0.7051_{(-11.20\%)}$ & $0.7225_{(-9.10\%)}$ & $0.7619_{(-4.10\%)}$ & $0.7718_{(-2.90\%)}$ & $0.7733_{(-2.70\%)}$ & $0.7469_{(-6.00\%)}$ \\
            & $20\%$  & $0.6384_{(-19.70\%)}$ & $0.6406_{(-19.40\%)}$ & $0.6884_{(-13.40\%)}$ & $0.7142_{(-10.10\%)}$ & $0.7763_{(-2.30\%)}$ & $0.6916_{(-13.00\%)}$ \\
            & $10\%$  & $0.4784_{(-39.80\%)}$ & $0.4503_{(-43.30\%)}$ & $0.5034_{(-36.60\%)}$ & $0.4829_{(-39.20\%)}$ & $0.6566_{(-17.40\%)}$ & $0.5143_{(-35.30\%)}$ \\
            \midrule

            \multirow{10}{*}{w/ R1 Distill}
        & Baseline  & \multicolumn{5}{c|}{R1-Distill-Llama-8B FullKV: 0.6938} & \\ \cmidrule{2-8}
        & $90\%$  & $0.7167_{(+3.30\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7100_{(+2.34\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6993_{(+0.79\%)}$ \\
        & $80\%$  & $0.6867_{(-1.02\%)}$ & $0.6933_{(-0.07\%)}$ & $0.6933_{(-0.07\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6767_{(-2.47\%)}$ & $0.6913_{(-0.36\%)}$ \\
        & $70\%$  & $0.6933_{(-0.07\%)}$ & $0.6633_{(-4.40\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7100_{(+2.34\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6953_{(+0.22\%)}$ \\
        & $60\%$  & $0.6833_{(-1.51\%)}$ & $0.6900_{(-0.55\%)}$ & $0.6900_{(-0.55\%)}$ & $0.7133_{(+2.81\%)}$ & $0.7067_{(+1.86\%)}$ & $0.6967_{(+0.42\%)}$ \\
        & $50\%$  & $0.6700_{(-3.43\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7067_{(+1.86\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6867_{(-1.02\%)}$ & $0.6920_{(-0.26\%)}$ \\
        & $40\%$  & $0.6767_{(-2.47\%)}$ & $0.6800_{(-1.99\%)}$ & $0.5967_{(-13.99\%)}$ & $0.6967_{(+0.42\%)}$ & $0.7133_{(+2.81\%)}$ & $0.6727_{(-3.04\%)}$ \\
        & $30\%$  & $0.6600_{(-4.87\%)}$ & $0.5900_{(-14.96\%)}$ & $0.5833_{(-15.93\%)}$ & $0.6700_{(-3.43\%)}$ & $0.7000_{(+0.89\%)}$ & $0.6407_{(-7.66\%)}$ \\
        & $20\%$  & $0.6200_{(-10.64\%)}$ & $0.4933_{(-28.90\%)}$ & $0.5633_{(-18.81\%)}$ & $0.6833_{(-1.51\%)}$ & $0.6533_{(-5.84\%)}$ & $0.6026_{(-13.14\%)}$ \\
        & $10\%$  & $0.5167_{(-25.53\%)}$ & $0.5567_{(-19.76\%)}$ & $0.5767_{(-16.88\%)}$ & $0.6267_{(-9.67\%)}$ & $0.6433_{(-7.28\%)}$ & $0.5840_{(-15.82\%)}$ \\
        \midrule

        
        \multirow{10}{*}{w/o Instruct Tuning} 
        & Baseline  & \multicolumn{5}{c|}{FullKV: 0.5122} & \\ \cmidrule{2-8}
        & $90\%$  & $0.5061_{(-1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5122_{(+0.00\%)}$ \\
        & $80\%$  & $0.5061_{(-1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5061_{(-1.20\%)}$ & $0.5159_{(+0.70\%)}$ \\
        & $70\%$  & $0.5000_{(-2.40\%)}$ & $0.5244_{(+2.40\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5183_{(+1.20\%)}$ & $0.5122_{(+0.00\%)}$ & $0.5134_{(+0.20\%)}$ \\
        & $60\%$  & $0.5061_{(-1.20\%)}$ & $0.5366_{(+4.80\%)}$ & $0.5366_{(+4.80\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5244_{(+2.40\%)}$ & $0.5268_{(+2.90\%)}$ \\
        & $50\%$  & $0.4939_{(-3.60\%)}$ & $0.5427_{(+6.00\%)}$ & $0.5061_{(-1.20\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4878_{(-4.80\%)}$ & $0.5049_{(-1.40\%)}$ \\
        & $40\%$  & $0.4817_{(-6.00\%)}$ & $0.5427_{(+6.00\%)}$ & $0.5244_{(+2.40\%)}$ & $0.4939_{(-3.60\%)}$ & $0.5000_{(-2.40\%)}$ & $0.5085_{(-0.70\%)}$ \\
        & $30\%$  & $0.4817_{(-6.00\%)}$ & $0.5305_{(+3.60\%)}$ & $0.5000_{(-2.40\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4817_{(-6.00\%)}$ & $0.4976_{(-2.90\%)}$ \\
        & $20\%$  & $0.4634_{(-9.50\%)}$ & $0.5061_{(-1.20\%)}$ & $0.4939_{(-3.60\%)}$ & $0.4695_{(-8.30\%)}$ & $0.4878_{(-4.80\%)}$ & $0.4841_{(-5.50\%)}$ \\
        & $10\%$  & $0.3659_{(-28.60\%)}$ & $0.4634_{(-9.50\%)}$ & $0.4268_{(-16.70\%)}$ & $0.4207_{(-17.90\%)}$ & $0.4451_{(-13.10\%)}$ & $0.4244_{(-17.20\%)}$ \\
        \bottomrule
    \end{tabular}
    }
    \end{table}



\paragraph{Observation 3.} \textbf{Short prompt length is more sensitive to KV cache compression.}
As demonstrated in \cref{tab:gsm8k-shots}, the impact of KV cache compression varies significantly with the number of shots in the prompt. One-shot prompts show extreme vulnerability to aggressive compression, with performance plummeting from 0.7149 to 0.0452 (a 93.7\% drop) at 10\% compression ratio. This sensitivity gradually decreases as the number of shots increases. For instance, at the same compression ratio, 4-shot prompts show a 46.2\% performance drop (from 0.7597 to 0.4088), while 8-shot prompts demonstrate relatively better resilience with a 35.3\% reduction (from 0.7945 to 0.5143). This pattern suggests that longer prompts with more examples provide redundancy that helps maintain model performance under compression, while shorter prompts lack this buffer against information loss.


\begin{table}[!h]
    \centering
    \caption{Performance Comparison of Different Shot Numbers on GSM8K}
    \label{tab:gsm8k-shots}
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lcccccc|c}
            \toprule
            \textbf{Shot} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$} \\
            \midrule
            \multirow{10}{*}{1-shot} 
            & Baseline & \multicolumn{5}{c|}{FullKV: 0.7149} & \\ \cmidrule{2-8}
            & $90\%$  & $0.7013_{(-1.90\%)}$ & $0.7172_{(+0.30\%)}$ & $0.7142_{(-0.10\%)}$ & $0.7020_{(-1.80\%)}$ & $0.7172_{(+0.30\%)}$ & $0.7104_{(-0.60\%)}$ \\
            & $80\%$  & $0.6892_{(-3.60\%)}$ & $0.7089_{(-0.80\%)}$ & $0.7066_{(-1.20\%)}$ & $0.6952_{(-2.80\%)}$ & $0.7081_{(-1.00\%)}$ & $0.7016_{(-1.90\%)}$ \\
            & $70\%$  & $0.6816_{(-4.70\%)}$ & $0.6914_{(-3.30\%)}$ & $0.6945_{(-2.90\%)}$ & $0.6884_{(-3.70\%)}$ & $0.7127_{(-0.30\%)}$ & $0.6937_{(-3.00\%)}$ \\
            & $60\%$  & $0.6884_{(-3.70\%)}$ & $0.6831_{(-4.40\%)}$ & $0.6914_{(-3.30\%)}$ & $0.6816_{(-4.70\%)}$ & $0.6990_{(-2.20\%)}$ & $0.6887_{(-3.70\%)}$ \\
            & $50\%$  & $0.6952_{(-2.80\%)}$ & $0.6596_{(-7.70\%)}$ & $0.6611_{(-7.50\%)}$ & $0.6717_{(-6.00\%)}$ & $0.6732_{(-5.80\%)}$ & $0.6722_{(-6.00\%)}$ \\
            & $40\%$  & $0.6657_{(-6.90\%)}$ & $0.6202_{(-13.20\%)}$ & $0.6065_{(-15.20\%)}$ & $0.6475_{(-9.40\%)}$ & $0.6050_{(-15.40\%)}$ & $0.6290_{(-12.00\%)}$ \\
            & $30\%$  & $0.5118_{(-28.40\%)}$ & $0.5004_{(-30.00\%)}$ & $0.5042_{(-29.50\%)}$ & $0.5898_{(-17.50\%)}$ & $0.4011_{(-43.90\%)}$ & $0.5015_{(-29.90\%)}$ \\
            & $20\%$  & $0.2320_{(-67.50\%)}$ & $0.2714_{(-62.00\%)}$ & $0.2654_{(-62.90\%)}$ & $0.3973_{(-44.40\%)}$ & $0.1319_{(-81.60\%)}$ & $0.2596_{(-63.70\%)}$ \\
            & $10\%$  & $0.0296_{(-95.90\%)}$ & $0.0243_{(-96.60\%)}$ & $0.0296_{(-95.90\%)}$ & $0.1236_{(-82.70\%)}$ & $0.0190_{(-97.30\%)}$ & $0.0452_{(-93.70\%)}$ \\
            \midrule
            \multirow{10}{*}{2-shot}
            & Baseline & \multicolumn{5}{c|}{FullKV: 0.7574} &\\ \cmidrule{2-8}
            & $90\%$  & $0.7544_{(-0.40\%)}$ & $0.7604_{(+0.40\%)}$ & $0.7574_{(+0.00\%)}$ & $0.7612_{(+0.50\%)}$ & $0.7627_{(+0.70\%)}$ & $0.7592_{(+0.20\%)}$ \\
            & $80\%$  & $0.7551_{(-0.30\%)}$ & $0.7521_{(-0.70\%)}$ & $0.7559_{(-0.20\%)}$ & $0.7559_{(-0.20\%)}$ & $0.7589_{(+0.20\%)}$ & $0.7556_{(-0.20\%)}$ \\
            & $70\%$  & $0.7521_{(-0.70\%)}$ & $0.7453_{(-1.60\%)}$ & $0.7566_{(-0.10\%)}$ & $0.7574_{(+0.00\%)}$ & $0.7642_{(+0.90\%)}$ & $0.7551_{(-0.30\%)}$ \\
            & $60\%$  & $0.7475_{(-1.30\%)}$ & $0.7506_{(-0.90\%)}$ & $0.7521_{(-0.70\%)}$ & $0.7589_{(+0.20\%)}$ & $0.7695_{(+1.60\%)}$ & $0.7557_{(-0.20\%)}$ \\
            & $50\%$  & $0.7460_{(-1.50\%)}$ & $0.7437_{(-1.80\%)}$ & $0.7437_{(-1.80\%)}$ & $0.7604_{(+0.40\%)}$ & $0.7619_{(+0.60\%)}$ & $0.7511_{(-0.80\%)}$ \\
            & $40\%$  & $0.7445_{(-1.70\%)}$ & $0.7081_{(-6.50\%)}$ & $0.7202_{(-4.90\%)}$ & $0.7309_{(-3.50\%)}$ & $0.7650_{(+1.00\%)}$ & $0.7337_{(-3.10\%)}$ \\
            & $30\%$  & $0.7506_{(-0.90\%)}$ & $0.6133_{(-19.00\%)}$ & $0.6657_{(-12.10\%)}$ & $0.7036_{(-7.10\%)}$ & $0.7445_{(-1.70\%)}$ & $0.6955_{(-8.20\%)}$ \\
            & $20\%$  & $0.6217_{(-17.90\%)}$ & $0.4412_{(-41.70\%)}$ & $0.4936_{(-34.80\%)}$ & $0.5534_{(-26.90\%)}$ & $0.5368_{(-29.10\%)}$ & $0.5293_{(-30.10\%)}$ \\
            & $10\%$  & $0.1516_{(-80.00\%)}$ & $0.1759_{(-76.80\%)}$ & $0.1622_{(-78.60\%)}$ & $0.2244_{(-70.40\%)}$ & $0.0735_{(-90.30\%)}$ & $0.1575_{(-79.20\%)}$ \\
            \midrule
            \multirow{10}{*}{4-shot}
            & Baseline & \multicolumn{5}{c|}{FullKV: 0.7597} & \\ \cmidrule{2-8}
            & $90\%$  & $0.7597_{(+0.00\%)}$ & $0.7604_{(+0.10\%)}$ & $0.7650_{(+0.70\%)}$ & $0.7642_{(+0.60\%)}$ & $0.7657_{(+0.80\%)}$ & $0.7630_{(+0.40\%)}$ \\
            & $80\%$  & $0.7559_{(-0.50\%)}$ & $0.7688_{(+1.20\%)}$ & $0.7695_{(+1.30\%)}$ & $0.7680_{(+1.10\%)}$ & $0.7642_{(+0.60\%)}$ & $0.7653_{(+0.70\%)}$ \\
            & $70\%$  & $0.7597_{(+0.00\%)}$ & $0.7695_{(+1.30\%)}$ & $0.7680_{(+1.10\%)}$ & $0.7710_{(+1.50\%)}$ & $0.7726_{(+1.70\%)}$ & $0.7682_{(+1.10\%)}$ \\
            & $60\%$  & $0.7369_{(-3.00\%)}$ & $0.7726_{(+1.70\%)}$ & $0.7688_{(+1.20\%)}$ & $0.7635_{(+0.50\%)}$ & $0.7718_{(+1.60\%)}$ & $0.7627_{(+0.40\%)}$ \\
            & $50\%$  & $0.7475_{(-1.60\%)}$ & $0.7612_{(+0.20\%)}$ & $0.7619_{(+0.30\%)}$ & $0.7665_{(+0.90\%)}$ & $0.7635_{(+0.50\%)}$ & $0.7601_{(+0.10\%)}$ \\
            & $40\%$  & $0.7165_{(-5.70\%)}$ & $0.7339_{(-3.40\%)}$ & $0.7377_{(-2.90\%)}$ & $0.7483_{(-1.50\%)}$ & $0.7612_{(+0.20\%)}$ & $0.7395_{(-2.70\%)}$ \\
            & $30\%$  & $0.6558_{(-13.70\%)}$ & $0.6603_{(-13.10\%)}$ & $0.7111_{(-6.40\%)}$ & $0.7263_{(-4.40\%)}$ & $0.7597_{(+0.00\%)}$ & $0.7026_{(-7.50\%)}$ \\
            & $20\%$  & $0.6224_{(-18.10\%)}$ & $0.5625_{(-26.00\%)}$ & $0.6065_{(-20.20\%)}$ & $0.6543_{(-13.90\%)}$ & $0.7468_{(-1.70\%)}$ & $0.6385_{(-16.00\%)}$ \\
            & $10\%$  & $0.4708_{(-38.00\%)}$ & $0.3980_{(-47.60\%)}$ & $0.3995_{(-47.40\%)}$ & $0.4321_{(-43.10\%)}$ & $0.3434_{(-54.80\%)}$ & $0.4088_{(-46.20\%)}$ \\
            \midrule
            \multirow{10}{*}{6-shot}
            & Baseline & \multicolumn{5}{c|}{FullKV: 0.7680} & \\ \cmidrule{2-8}
            & $90\%$  & $0.7551_{(-1.70\%)}$ & $0.7748_{(+0.90\%)}$ & $0.7839_{(+2.10\%)}$ & $0.7794_{(+1.50\%)}$ & $0.7794_{(+1.50\%)}$ & $0.7745_{(+0.90\%)}$ \\
            & $80\%$  & $0.7642_{(-0.50\%)}$ & $0.7756_{(+1.00\%)}$ & $0.7809_{(+1.70\%)}$ & $0.7741_{(+0.80\%)}$ & $0.7786_{(+1.40\%)}$ & $0.7747_{(+0.90\%)}$ \\
            & $70\%$  & $0.7513_{(-2.20\%)}$ & $0.7771_{(+1.20\%)}$ & $0.7809_{(+1.70\%)}$ & $0.7771_{(+1.20\%)}$ & $0.7786_{(+1.40\%)}$ & $0.7730_{(+0.70\%)}$ \\
            & $60\%$  & $0.7468_{(-2.80\%)}$ & $0.7748_{(+0.90\%)}$ & $0.7733_{(+0.70\%)}$ & $0.7771_{(+1.20\%)}$ & $0.7809_{(+1.70\%)}$ & $0.7706_{(+0.30\%)}$ \\
            & $50\%$  & $0.7407_{(-3.60\%)}$ & $0.7718_{(+0.50\%)}$ & $0.7718_{(+0.50\%)}$ & $0.7771_{(+1.20\%)}$ & $0.7718_{(+0.50\%)}$ & $0.7666_{(-0.20\%)}$ \\
            & $40\%$  & $0.7377_{(-3.90\%)}$ & $0.7506_{(-2.30\%)}$ & $0.7771_{(+1.20\%)}$ & $0.7688_{(+0.10\%)}$ & $0.7854_{(+2.30\%)}$ & $0.7639_{(-0.50\%)}$ \\
            & $30\%$  & $0.7058_{(-8.10\%)}$ & $0.7255_{(-5.50\%)}$ & $0.7392_{(-3.70\%)}$ & $0.7491_{(-2.50\%)}$ & $0.7763_{(+1.10\%)}$ & $0.7392_{(-3.70\%)}$ \\
            & $20\%$  & $0.5921_{(-22.90\%)}$ & $0.6232_{(-18.80\%)}$ & $0.6732_{(-12.30\%)}$ & $0.6960_{(-9.40\%)}$ & $0.7665_{(-0.20\%)}$ & $0.6702_{(-12.70\%)}$ \\
            & $10\%$  & $0.4572_{(-40.50\%)}$ & $0.4481_{(-41.60\%)}$ & $0.4958_{(-35.40\%)}$ & $0.4458_{(-41.90\%)}$ & $0.5565_{(-27.50\%)}$ & $0.4807_{(-37.40\%)}$ \\
            \midrule
            \multirow{10}{*}{8-shot}
            & Baseline & \multicolumn{5}{c|}{FullKV: 0.7945} & \\ \cmidrule{2-8}
            & $90\%$  & $0.7695_{(-3.10\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7827_{(-1.50\%)}$ \\
            & $80\%$  & $0.7642_{(-3.80\%)}$ & $0.7938_{(-0.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7826_{(-1.50\%)}$ \\
            & $70\%$  & $0.7642_{(-3.80\%)}$ & $0.7900_{(-0.60\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7983_{(+0.50\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7851_{(-1.20\%)}$ \\
            & $60\%$  & $0.7650_{(-3.70\%)}$ & $0.7809_{(-1.70\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7923_{(-0.30\%)}$ & $0.7885_{(-0.80\%)}$ & $0.7830_{(-1.50\%)}$ \\
            & $50\%$  & $0.7657_{(-3.60\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7847_{(-1.20\%)}$ & $0.7854_{(-1.10\%)}$ & $0.7824_{(-1.50\%)}$ & $0.7807_{(-1.70\%)}$ \\
            & $40\%$  & $0.7491_{(-5.70\%)}$ & $0.7688_{(-3.20\%)}$ & $0.7756_{(-2.40\%)}$ & $0.7839_{(-1.30\%)}$ & $0.7763_{(-2.30\%)}$ & $0.7707_{(-3.00\%)}$ \\
            & $30\%$  & $0.7051_{(-11.20\%)}$ & $0.7225_{(-9.10\%)}$ & $0.7619_{(-4.10\%)}$ & $0.7718_{(-2.90\%)}$ & $0.7733_{(-2.70\%)}$ & $0.7469_{(-6.00\%)}$ \\
            & $20\%$  & $0.6384_{(-19.70\%)}$ & $0.6406_{(-19.40\%)}$ & $0.6884_{(-13.40\%)}$ & $0.7142_{(-10.10\%)}$ & $0.7763_{(-2.30\%)}$ & $0.6916_{(-13.00\%)}$ \\
            & $10\%$  & $0.4784_{(-39.80\%)}$ & $0.4503_{(-43.30\%)}$ & $0.5034_{(-36.60\%)}$ & $0.4829_{(-39.20\%)}$ & $0.6566_{(-17.40\%)}$ & $0.5143_{(-35.30\%)}$ \\
    \bottomrule
    \end{tabular}
    }
    \end{table}


\paragraph{Observation 4.} \textbf{Chunk-level compression is more effective for long-context arithmetic reasoning tasks. }
As shown in \cref{tab:kv-compression}, ChunkKV demonstrates superior robustness across different compression ratios, particularly under aggressive compression settings. While other methods show significant performance degradation at 10\% compression ratio (StreamingLLM: -9.8\%, H2O: -37.8\%, SnapKV: -17.1\%, PyramidKV: -14.6\%), ChunkKV maintains relatively stable performance with only a -3.7\% drop. This stark contrast in performance suggests that chunk-level compression better preserves the essential contextual information needed for complex reasoning tasks. The method's effectiveness likely stems from its ability to maintain the structural integrity of related context segments, which is particularly crucial for tasks requiring extended logical reasoning and arithmetic operations.

\begin{table}[!h]
    \centering
    \caption{Performance Comparison of Different KV Cache Compression Methods on Many-shot GSM8K}
    \label{tab:kv-compression}
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lcccccc|c}
            \toprule
            \textbf{Benchmark} & \textbf{Ratio} & \textbf{StreamingLLM} & \textbf{H2O} & \textbf{SnapKV} & \textbf{PyramidKV} & \textbf{ChunkKV} & \textbf{Average $\uparrow$ } \\
            \midrule
            \multirow{21}{*}{\makecell{Many-shot \\GSM8K}}
            & Baseline & \multicolumn{5}{c|}{LLaMA-3.1-8B-Instruct FullKV: 0.8235} &  \\ \cmidrule{2-8}
            & $90\%$  & $0.7728_{(-6.16\%)}$ & $0.8142_{(-1.13\%)}$ & $0.8137_{(-1.19\%)}$ & $0.7932_{(-3.68\%)}$ & $0.8233_{(-0.02\%)}$ & $0.8034_{(-2.44\%)}$ \\
            & $80\%$  & $0.7935_{(-3.64\%)}$ & $0.8334_{(+1.20\%)}$ & $0.8138_{(-1.18\%)}$ & $0.8037_{(-2.40\%)}$ & $0.7932_{(-3.68\%)}$ & $0.8075_{(-1.94\%)}$ \\
            & $70\%$  & $0.8038_{(-2.39\%)}$ & $0.8136_{(-1.20\%)}$ & $0.7832_{(-4.89\%)}$ & $0.7932_{(-3.68\%)}$ & $0.8037_{(-2.40\%)}$ & $0.7995_{(-2.91\%)}$ \\
            & $60\%$  & $0.7932_{(-3.68\%)}$ & $0.8142_{(-1.13\%)}$ & $0.8037_{(-2.40\%)}$ & $0.7935_{(-3.64\%)}$ & $0.8038_{(-2.39\%)}$ & $0.8017_{(-2.65\%)}$ \\
            & $50\%$  & $0.7934_{(-3.65\%)}$ & $0.8137_{(-1.19\%)}$ & $0.7932_{(-3.68\%)}$ & $0.7932_{(-3.68\%)}$ & $0.7835_{(-4.86\%)}$ & $0.7954_{(-3.41\%)}$ \\
            & $40\%$  & $0.8037_{(-2.40\%)}$ & $0.7832_{(-4.89\%)}$ & $0.7935_{(-3.64\%)}$ & $0.7834_{(-4.87\%)}$ & $0.7832_{(-4.89\%)}$ & $0.7894_{(-4.14\%)}$ \\
            & $30\%$  & $0.7835_{(-4.86\%)}$ & $0.7932_{(-3.68\%)}$ & $0.8038_{(-2.39\%)}$ & $0.7934_{(-3.65\%)}$ & $0.7932_{(-3.68\%)}$ & $0.7934_{(-3.65\%)}$ \\
            & $20\%$  & $0.7537_{(-8.47\%)}$ & $0.7428_{(-9.80\%)}$ & $0.7934_{(-3.65\%)}$ & $0.7832_{(-4.89\%)}$ & $0.7835_{(-4.86\%)}$ & $0.7713_{(-6.34\%)}$ \\
            & $10\%$  & $0.7432_{(-9.75\%)}$ & $0.5127_{(-37.74\%)}$ & $0.6827_{(-17.10\%)}$ & $0.7037_{(-14.55\%)}$ & $0.7932_{(-3.68\%)}$ & $0.6871_{(-16.56\%)}$ \\
            \cmidrule{2-8}
            & Baseline & \multicolumn{5}{c|}{R1-Distill-Llama-8B FullKV: 0.7123} &  \\ \cmidrule{2-8}
            & $90\%$  & $0.7123_{(+1.42\%)}$ & $0.6612_{(-5.85\%)}$ & $0.6534_{(-6.96\%)}$ & $0.6912_{(-1.58\%)}$ & $0.6923_{(-1.42\%)}$ & $0.6821_{(-2.88\%)}$ \\
            & $80\%$  & $0.7234_{(+3.00\%)}$ & $0.6534_{(-6.96\%)}$ & $0.7123_{(+1.42\%)}$ & $0.6423_{(-8.54\%)}$ & $0.7123_{(+1.42\%)}$ & $0.6887_{(-1.94\%)}$ \\
            & $70\%$  & $0.7412_{(+5.54\%)}$ & $0.6523_{(-7.12\%)}$ & $0.7234_{(+3.00\%)}$ & $0.6923_{(-1.42\%)}$ & $0.7234_{(+3.00\%)}$ & $0.7065_{(+0.60\%)}$ \\
            & $60\%$  & $0.7423_{(+5.69\%)}$ & $0.6912_{(-1.58\%)}$ & $0.6912_{(-1.58\%)}$ & $0.6823_{(-2.85\%)}$ & $0.6634_{(-5.54\%)}$ & $0.6941_{(-1.17\%)}$ \\
            & $50\%$  & $0.7234_{(+3.00\%)}$ & $0.7134_{(+1.58\%)}$ & $0.7312_{(+4.12\%)}$ & $0.7123_{(+1.42\%)}$ & $0.7123_{(+1.42\%)}$ & $0.7185_{(+2.31\%)}$ \\
            & $40\%$  & $0.7123_{(+1.42\%)}$ & $0.6923_{(-1.42\%)}$ & $0.6923_{(-1.42\%)}$ & $0.7023_{(+0.00\%)}$ & $0.7234_{(+3.00\%)}$ & $0.7045_{(+0.31\%)}$ \\
            & $30\%$  & $0.6523_{(-7.12\%)}$ & $0.7312_{(+4.12\%)}$ & $0.6634_{(-5.54\%)}$ & $0.7423_{(+5.69\%)}$ & $0.6912_{(-1.58\%)}$ & $0.6961_{(-0.88\%)}$ \\
            & $20\%$  & $0.6912_{(-1.58\%)}$ & $0.5834_{(-16.93\%)}$ & $0.5123_{(-27.05\%)}$ & $0.6823_{(-2.85\%)}$ & $0.6634_{(-5.54\%)}$ & $0.6265_{(-10.79\%)}$ \\
            & $10\%$  & $0.6323_{(-9.97\%)}$ & $0.5423_{(-22.78\%)}$ & $0.5412_{(-22.94\%)}$ & $0.5923_{(-15.66\%)}$ & $0.6823_{(-2.85\%)}$ & $0.5981_{(-14.84\%)}$ \\
            \bottomrule
        \end{tabular}
    }
\end{table}



\section{\method{}}
This section provides the detailed description of \method{}.

\subsection{Pseudocode}
The detailed algorithm of \method{} is presented in Algorithm\ref{alg:shotkv}. Our method consists of two main phases: prefill compression and decoding compression. During the prefill phase, we compute an importance score for each shot by averaging the attention weights across all tokens, heads, and layers within that shot. This score $\text{Score}_{\text{prefill}}(s_i)$ is normalized by the shot length $k_i$ to avoid bias towards longer shots. Shots are then sorted by their scores and preserved until reaching the specified prefill ratio $r_p$.

In the decoding phase, compression is performed dynamically at each step. For each token in the decoding KV cache, we calculate its importance score $\text{Score}_{\text{decoding}}(t)$ by summing attention weights across all heads and layers. The top-k tokens are retained based on the decoding ratio $r_d$. Finally, the compressed KV cache is formed by combining both the preserved prefill and decoding caches.

This two-phase approach allows for different compression strategies during prefill and decoding stages, recognizing their distinct roles in the inference process. The shot-aware design during prefill ensures that the most informative examples are preserved, while the token-level compression during decoding maintains essential recent context.
\begin{algorithm}[h]
    \caption{ShotKV: Shot-aware KV Cache Compression}
    \label{alg:shotkv}
    \begin{algorithmic}[1]
        \REQUIRE Prompt with $n$ shots $\{s_1,...,s_n\}$, prefill ratio $r_p$, decoding ratio $r_d$
        \ENSURE Compressed KV cache $KV_{\text{total}}$
        
        \STATE // Phase 1: Prefill Compression (performed once)
        \FOR{each shot $s_i$ in $\{s_1,...,s_n\}$}
            \STATE Compute $\text{Score}_{\text{prefill}}(s_i) = \frac{1}{k_i} \sum_{t \in s_i} \sum_{h=1}^H \sum_{l=1}^L \alpha_{t,h}^l$
        \ENDFOR
        \STATE Sort shots by $\text{Score}_{\text{prefill}}(s_i)$ in descending order
        \STATE $S_{\text{preserved}} \leftarrow$ Select shots until $\sum_{s_i} k_i \leq r_p \times |KV_{\text{prefill}}|$
        \STATE $KV^C_{\text{prefill}} \leftarrow \text{Compress}(\{s_i | s_i \in S_{\text{preserved}}\})$
        
        \STATE // Phase 2: Decoding Compression (performed dynamically)
        \FOR{each decoding step}
            \FOR{each token $t$ in $KV_{\text{decoding}}$}
                \STATE Compute $\text{Score}_{\text{decoding}}(t) = \sum_{h=1}^H \sum_{l=1}^L \alpha_{t,h}^l$
            \ENDFOR
            \STATE $k \leftarrow r_d \times |KV_{\text{decoding}}|$
            \STATE $KV^C_{\text{decoding}} \leftarrow \text{TopK}(KV_{\text{decoding}}, \text{Score}_{\text{decoding}}, k)$
        \ENDFOR
        
        \RETURN $KV^C_{\text{prefill}} \cup KV^C_{\text{decoding}}$
    \end{algorithmic}
    \end{algorithm}

\section{Evaluation Benchmark }

\label{app:eval_bench}
\subsection{Dataset Details}
\label{app:eval_bench_dataset}

Detailed statistics for each benchmark dataset are provided in Table~\ref{tab:dataset_statistic}.

\begin{table}[h]
    \centering
    
    \footnotesize
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l|c|r|c|c}
    \toprule
    \textsc{Dataset}  & \textsc{Task Type}  & \textsc{\# Test} & \textsc{Metric} & \textsc{Evaluation Method}\\ \midrule
    
    MMLU~\cite{mmlu}
    & World Knowledge 
    & 14,079 
    & Accuracy     
    & Generation-Based \\
    
    GSM8K~\cite{gsm8k}
    & Arithmetic      
    & 1,319   
    & Exact match  
    & Generation-Based \\
    
    CSQA*~\cite{csqa}
    & Commonsense
    & 1,221
    & Accuracy 
    & Generation-Based \\
    
    HumanEval~\cite{chen2021evaluating}
    & Code Generation
    & 164
    & Pass@1 rate 
    & Generation-Based \\
    
    JailBreakV~\cite{luo2024jailbreakv}
    & Safety
    & 28,000
    & Attack success rate     
    & Generation-Based \\
    
    \bottomrule
    \end{tabular}
    }
    \vspace{1em}
    \caption{The statistics of the datasets used in this paper. 
    \textsc{\# Test} denote the number of training data and test data, respectively.
    }
    \label{tab:dataset_statistic}
    \end{table}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

