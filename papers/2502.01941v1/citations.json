[
  {
    "index": 0,
    "papers": [
      {
        "key": "pope2023efficiently",
        "author": "Pope, Reiner and Douglas, Sholto and Chowdhery, Aakanksha and Devlin, Jacob and Bradbury, James and Heek, Jonathan and Xiao, Kefan and Agrawal, Shivani and Dean, Jeff",
        "title": "Efficiently scaling transformer inference"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "h2o",
        "author": "Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\\'e}, Christopher and Barrett, Clark and others",
        "title": "H2o: Heavy-hitter oracle for efficient generative inference of large language models"
      },
      {
        "key": "adnan2024keyformer",
        "author": "Adnan, Muhammad and Arunkumar, Akhil and Jain, Gaurav and Nair, Prashant and Soloveychik, Ilya and Kamath, Purushotham",
        "title": "Keyformer: Kv cache reduction through key tokens selection for efficient generative inference"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "snapkv",
        "author": "Li, Yuhong and Huang, Yingbing and Yang, Bowen and Venkitesh, Bharat and Locatelli, Acyr and Ye, Hanchen and Cai, Tianle and Lewis, Patrick and Chen, Deming",
        "title": "SnapKV: LLM Knows What You are Looking for Before Generation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "guo2024attention",
        "author": "Guo, Zhiyu and Kamigaito, Hidetaka and Watanabe, Taro",
        "title": "Attention Score is not All You Need for Token Importance Indicator in KV Cache Reduction: Value Also Matters"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yang2024pyramidinfer",
        "author": "Yang, Dongjie and Han, XiaoDong and Gao, Yan and Hu, Yao and Zhang, Shilin and Zhao, Hai",
        "title": "PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "streamingllm",
        "author": "Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis",
        "title": "Efficient Streaming Language Models with Attention Sinks"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zhangcam",
        "author": "Zhang, Yuxin and Du, Yuxuan and Luo, Gen and Zhong, Yunshan and Zhang, Zhenyu and Liu, Shiwei and Ji, Rongrong",
        "title": "CaM: Cache Merging for Memory-efficient LLMs Inference"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhangcam",
        "author": "Zhang, Yuxin and Du, Yuxuan and Luo, Gen and Zhong, Yunshan and Zhang, Zhenyu and Liu, Shiwei and Ji, Rongrong",
        "title": "CaM: Cache Merging for Memory-efficient LLMs Inference"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yao2024cacheblend",
        "author": "Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen",
        "title": "CacheBlend: Fast Large Language Model Serving with Cached Knowledge Fusion"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "pyramidkv",
        "author": "Cai, Zefan and Zhang, Yichi and Gao, Bofei and Liu, Yuliang and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and others",
        "title": "Pyramidkv: Dynamic kv cache compression based on pyramidal information funneling"
      },
      {
        "key": "feng2024ada",
        "author": "Feng, Yuan and Lv, Junlin and Cao, Yukun and Xie, Xike and Zhou, S Kevin",
        "title": "Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference"
      },
      {
        "key": "chunkkv",
        "author": "Xiang Liu and Zhenheng Tang and Peijie Dong and Zeyu Li and Bo Li and Xuming Hu and Xiaowen Chu",
        "title": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mmlu",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring massive multitask language understanding"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bbh",
        "author": "Suzgun, Mirac and Scales, Nathan and Sch{\\\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others",
        "title": "Challenging big-bench tasks and whether chain-of-thought can solve them"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "csqa",
        "author": "Talmor, Alon  and\nHerzig, Jonathan  and\nLourie, Nicholas  and\nBerant, Jonathan",
        "title": "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "gsm8k",
        "author": "Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others",
        "title": "Training verifiers to solve math word problems"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chen2021evaluating",
        "author": "Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others",
        "title": "Evaluating large language models trained on code"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "luo2024jailbreakv",
        "author": "Weidi Luo and Siyuan Ma and Xiaogeng Liu and Xiaoyu Guo and Chaowei Xiao",
        "title": "JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "longbench",
        "author": "Bai, Yushi and Lv, Xin and Zhang, Jiajie and Lyu, Hongchang and Tang, Jiankai and Huang, Zhidian and Du, Zhengxiao and Liu, Xiao and Zeng, Aohan and Hou, Lei and others",
        "title": "Longbench: A bilingual, multitask benchmark for long context understanding"
      },
      {
        "key": "longbenchv2",
        "author": "Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li",
        "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "needle",
        "author": "Gregory Kamradt",
        "title": "{Needle In A Haystack} - Pressure Testing {LLM}s"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "longgenbench",
        "author": "Liu, Xiang  and\nDong, Peijie  and\nHu, Xuming  and\nChu, Xiaowen",
        "title": "{L}ong{G}en{B}ench: Long-context Generation Benchmark"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "agarwal2024many",
        "author": "Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others",
        "title": "Many-shot in-context learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "longgenbench",
        "author": "Liu, Xiang  and\nDong, Peijie  and\nHu, Xuming  and\nChu, Xiaowen",
        "title": "{L}ong{G}en{B}ench: Long-context Generation Benchmark"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "agarwal2024many",
        "author": "Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others",
        "title": "Many-shot in-context learning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "gsm8k",
        "author": "Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others",
        "title": "Training verifiers to solve math word problems"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "mmlu",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring massive multitask language understanding"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "math",
        "author": "Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring mathematical problem solving with the math dataset"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "mathqa",
        "author": "Amini, Aida and Gabriel, Saadia and Lin, Peter and Koncel-Kedziorski, Rik and Choi, Yejin and Hajishirzi, Hannaneh",
        "title": "Mathqa: Towards interpretable math word problem solving with operation-based formalisms"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "bbh",
        "author": "Suzgun, Mirac and Scales, Nathan and Sch{\\\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others",
        "title": "Challenging big-bench tasks and whether chain-of-thought can solve them"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "bigbench",
        "author": "Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\\`a} and others",
        "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "csqa",
        "author": "Talmor, Alon  and\nHerzig, Jonathan  and\nLourie, Nicholas  and\nBerant, Jonathan",
        "title": "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "yuan2024kv",
        "author": "Yuan, Jiayi and Liu, Hongyi and Zhong, Shaochen and Chuang, Yu-Neng and Li, Songchen and Wang, Guanchu and Le, Duy and Jin, Hongye and Chaudhary, Vipin and Xu, Zhaozhuo and others",
        "title": "Kv cache compression, but what must we give in return? a comprehensive benchmark of long context capable approaches"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "lin2021truthfulqa",
        "author": "Lin, Stephanie and Hilton, Jacob and Evans, Owain",
        "title": "Truthfulqa: Measuring how models mimic human falsehoods"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "hartvigsen2022toxigen",
        "author": "Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece",
        "title": "Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "liang2021towards",
        "author": "Liang, Paul Pu and Wu, Chiyu and Morency, Louis-Philippe and Salakhutdinov, Ruslan",
        "title": "Towards understanding and mitigating social biases in language models"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "zhu2023promptbench",
        "author": "Zhu, Kaijie and Wang, Jindong and Zhou, Jiaheng and Wang, Zichen and Chen, Hao and Wang, Yidong and Yang, Linyi and Ye, Wei and Zhang, Yue and Zhenqiang Gong, Neil and others",
        "title": "Promptbench: Towards evaluating the robustness of large language models on adversarial prompts"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "shen2024anything",
        "author": "Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang",
        "title": "\" do anything now\": Characterizing and evaluating in-the-wild jailbreak prompts on large language models"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "deng2023multilingual",
        "author": "Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong",
        "title": "Multilingual jailbreak challenges in large language models"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "li2024should",
        "author": "Li, Qi and Liu, Xiang and Tang, Zhenheng and Dong, Peijie and Li, Zeyu and Pan, Xinglin and Chu, Xiaowen",
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "chen2021evaluating",
        "author": "Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others",
        "title": "Evaluating large language models trained on code"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "austin2021program",
        "author": "Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others",
        "title": "Program synthesis with large language models"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "longbench",
        "author": "Bai, Yushi and Lv, Xin and Zhang, Jiajie and Lyu, Hongchang and Tang, Jiankai and Huang, Zhidian and Du, Zhengxiao and Liu, Xiao and Zeng, Aohan and Hou, Lei and others",
        "title": "Longbench: A bilingual, multitask benchmark for long context understanding"
      },
      {
        "key": "longbenchv2",
        "author": "Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li",
        "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "needle",
        "author": "Gregory Kamradt",
        "title": "{Needle In A Haystack} - Pressure Testing {LLM}s"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "agarwal2024many",
        "author": "Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others",
        "title": "Many-shot in-context learning"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "longgenbench",
        "author": "Liu, Xiang  and\nDong, Peijie  and\nHu, Xuming  and\nChu, Xiaowen",
        "title": "{L}ong{G}en{B}ench: Long-context Generation Benchmark"
      }
    ]
  }
]