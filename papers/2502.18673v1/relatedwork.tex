\section{Related Work}
\subsection{Intelligent Systems for Clinical Skill Training}

The field of human-computer interaction has recently seen a myriad of intelligent systems that assist clinicians and healthcare providers in improving their skills and enhancing clinical task execution. 

For example, the KiTT tablet-based learning system was designed to help nursing care students learn kinesthetic-based patient transfers. This system provides instructions and feedback, improving the learning experience in a training room context and showing potential in preserving nurses' health by promoting ergonomic patient transfers \cite{durr2021kitt}. In an attempt to maximize knowledge transfer from training to the real world, Zhou et al. created a 3D projection-based augmented reality system for nursing students, evaluated in a stroke simulation scenario, shown to enhance the realism of patient mannequins \cite{zhou2022bringing}. Similarly, Zadow et al. developed an interactive multitouch tabletop system for medical education for real-time diagnosis and treatment simulations, offering cost-effective and engaging learning environments compared to full-scale mannequins \cite{von2013simmed}. These studies underscore the benefits of realistic educational simulations and the trade-off between realism and cost.

The most relevant to our system is ConverSense, which uses machine learning to process social signals from patient-provider interactions to provide feedback to clinicians, facilitating self-reflection and communication improvement. Healthcare providers indicated the potential for long-term communication benefits from using ConverSense \cite{bedmutha2024conversense}.

\subsection{Training Systems for Counseling Conversations} 
The system proposed by Albright et al. \cite{albright2016harnessing} uses MI techniques to guide users through role-playing scenarios with embodied agents, focused on initiating conversations related to mental health. This system prepares individuals to engage in meaningful conversations and provides them with feedback based on their performance.
Similarly, Murali et al. created a system that involves role-playing with a conversational agent to teach counseling skills to laypersons in the context of vaccination promotion \cite{muraliTrainingLayCounselors2022b}. Several commercial products have also been developed that use conversational agents for the training of health conversation skills. These have been deployed and evaluated in various application areas, including prevention of suicide among college students \cite{rein2018}, training for healthcare providers and patients to talk about overuse of antibiotics \cite{schoenthaler2017}, and training for nurses to conduct screening for adolescent substance use \cite{burmester2019}.

\subsection{Standardized Patients and Patient Simulation Systems}
Traditionally, standardized patients--actors who allow providers to practice clinical skills by enacting real-life scenarios as a patient--have been widely used in healthcare to enhance medical education, primarily for communication and clinical skills. Prior research indicates that the use of standardized patients allows trainees to practice real-life scenarios in a controlled environment, fostering a sense of realism and emotional engagement that traditional educational methods may lack. Previous work has emphasized the effectiveness of standardized patients in medical training by showing that engaging with standardized patients leads to better acquisition of communication skills compared to didactic methods \cite{lane2007use}. However, using standardized patients can be costly and time consuming, due to cumbersome recruiting, training, and standardization of their interactions \cite{flanagan2023standardized, whitaker2015motivational, swanson2013assessment}.

Emerging technologies, including chatbots and embodied conversational agents, have significantly transformed the patient simulation process. The introduction of simulated patients provides flexibility in training by allowing learners to interact with computerized patients integrating natural language processing and realistic emotional responses \cite{hubal2000virtual}. These technologies not only reduce costs associated with hiring actors, but also enhance the availability and adaptability of training scenarios, allowing personalized and context-rich interactions for clinicians. One such approach includes patient-focused simulation, which integrates real human patients with high-fidelity simulators, fostering essential communication and decision-making skills alongside technical proficiency \cite{bartlett2021high}. Studies indicate that more realistic simulations lead to improved retention of skills and knowledge, enhanced engagement, and greater confidence in clinical settings \cite{kneebone2006human}.  

Overall, the move towards the integration of human-like interaction has been shown to be crucial to bridge the gap between theoretical education and practical application in healthcare  \cite{bartlett2021high, kneebone2006human, sarker2007simulation}

\subsection{LLMs for Simulated Patient Dialogue}
Recent advancements in LLMs have made them an attractive candidate to drive simulated patient dialogue and system reasoning for training purposes. To this end, CureFun utilizes multiple LLMs to simulate patients for medical diagnosis education, and offers automated feedback on trainee performance by analyzing medical scenarios to inform its responses \cite{li2024leveraging}. Similarly, \citeauthor{liao2024automatic} introduce State-Aware Patient Simulator to bridge the gap between static medical knowledge assessments and dynamic clinical interactions \cite{liao2024automatic}. Their approach allows for more realistic LLM evaluation in multi-turn doctor-patient simulations.

Despite impressive conversational abilities of LLMs, ensuring accurate and nuanced portrayals of specific patient populations requires expert input. \citeauthor{louie2024roleplay} address this challenge with Roleplay-doh, a pipeline that enables domain experts to guide LLM simulations through elicited principles. This work emphasizes the importance of expert feedback, particularly for sensitive domains such as mental health, and provides a mechanism for incorporating such feedback directly into LLM prompting \cite{louie2024roleplay}. \citeauthor{chen2023llm} explore the use of ChatGPT for the simulation of psychiatrists and patients, developing a dialogue system informed by psychiatrist input \cite{chen2023llm}. Their evaluation with real clinicians highlights the feasibility of LLM-powered chatbots in psychiatric scenarios while emphasizing the importance of careful prompt design for realistic and ethical interactions.

The use of LLMs for social skill training, including conflict resolution and communication, presents a promising application \cite{shaikh2024rehearsal, yang2024social}. For example, \citeauthor{yang2024social} discuss a framework leveraging LLMs to create accessible and engaging social skills training environments \cite{yang2024social}. Their AI Partner, AI Mentor framework combines experiential learning with realistic practice and tailored feedback, which aligns with SimPatient's goal of providing a safe space for practicing MI techniques. However, LLMs, especially those trained with reinforcement learning from human feedback as analyzed by Perez et al. \cite{perez2022discovering}, exhibit a positivity bias, tending towards agreeableness and a desire to comply with user requests. This raises challenges for simulating resistant or deceptive patients, scenarios crucial for robust training \cite{lee2024llms, petrov2024limited, mieleszczenko2024dark}. Further research is needed to overcome these limitations and accurately model the full spectrum of patient behaviors.

Closest to our work is that of Wang et al., who proposed a simulated patient framework to enhance Cognitive Behavioral Therapy training \cite{wang2024patient}. In their work, patient cognitive models, such as emotional states and maladaptive cognitions grounded in the principles of Cognitive Behavioral Therapy, are integrated with LLMs to ensure high-fidelity simulated patient interactions. Our approach differs in that: 
(1) SimPatient uses cognitive models grounded in the literature on substance misuse \cite{copersino2017cognitive}; 
(2) SimPatient allows for multiple complete and natural conversations with a simulated patient, followed by an opportunity for reflection through a comprehensive dashboard; and 
(3) the evaluation dashboard visualizes tracked changes in the simulated patient's cognitive model, allowing users to reflect on what they said and the resultant change in the simulated patient's cognitive model.

\subsection{LLMs for Motivational Interviewing Evaluation}
In recent years, language models, and particularly LLMs, have gained traction in evaluating the quality of counseling conversations from both technical and relational perspectives \cite{li2024automatic, ahmed2022automatic, perez2019makes, imel2019design}. These evaluation modules can be integrated with patient simulation platforms, offering a novel approach to evaluating the performance of counselors in MI sessions. For instance, Yosef et al. introduced an LLM-based digital patient platform that generates diverse patient profiles and utilizes LLMs to rate the quality of therapy sessions based on established frameworks such as the Motivational Interviewing Skills Code and the MITI \cite{yosef2024assessing}. These LLMs were found to effectively distinguish between varying levels of therapist expertise by completing questionnaires designed for human patients, indicating the potential for automated feedback in therapeutic settings.

Researchers have also developed datasets of counseling sessions annotated for both the therapist and client behaviors. Among these, the MI-TAGS dataset allows training language models to perform tasks such as utterance-level annotations and overall session scoring, achieving performance comparable to human annotators \cite{cohen2024motivational}. Using similar datasets, LLMs have been trained as evaluators for therapist responses, providing a way to gauge their adherence to MI principles in real time \cite{wu2023natural, wu2022anno}. In our proposed system, we used a mix of zero-shot and few-shot approaches to utilizing LLMs for evaluating counselor actions in terms of adherence to MI principles, which eliminates the need for data-intensive and time-consuming fine-tuning.

\subsection{LLM-Based Multi-Agent Systems}
The rise of LLMs has fueled the development of multi-agent systems where each agent is driven by an LLM \cite{guo2024large}. These LLM-based multi-agent systems leverage the inherent strengths of LLMs, such as natural language understanding/generation and knowledge representation \cite{pezeshkpour2023measuring}, to create agents capable of sophisticated interaction and collaboration. Hippocratic AI's Polaris system \cite{mukherjee2024polaris} provides a compelling example of a multi-agent LLM architecture specifically designed for healthcare applications using embodied agents. Polaris's design incorporates specialized support agents to enhance safety and address nuanced medical queries during patient interactions. 

Despite the rapid progress, several research challenges remain in the field of LLM-based multi-agent systems. Effective communication and coordination between agents are important for successful collaboration, requiring the development of specialized communication protocols and coordination mechanisms \cite{liu2023dynamic, zhang2023proagent}. The tendency of LLMs to generate factually incorrect or nonsensical outputs (hallucinations) poses a significant challenge, necessitating techniques for grounding these systems in real-world knowledge or simulated environments \cite{huang2023survey}. Furthermore, running multiple LLMs simultaneously can be computationally expensive, driving the need for research on optimizing LLM-based multi-agent systems for scalability and efficiency \cite{chen2023agentverse}.