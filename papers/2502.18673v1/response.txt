\section{Related Work}
\subsection{Intelligent Systems for Clinical Skill Training}

The field of human-computer interaction has recently seen a myriad of intelligent systems that assist clinicians and healthcare providers in improving their skills and enhancing clinical task execution. 

For example, the KiTT tablet-based learning system was designed to help nursing care students learn kinesthetic-based patient transfers. This system provides instructions and feedback, improving the learning experience in a training room context and showing potential in preserving nurses' health by promoting ergonomic patient transfers **Zhou et al., "3D Projection-Based Augmented Reality System for Nursing Students"**. In an attempt to maximize knowledge transfer from training to the real world, Zhou et al. created a 3D projection-based augmented reality system for nursing students, evaluated in a stroke simulation scenario, shown to enhance the realism of patient mannequins **Zadow et al., "Interactive Multitouch Tabletop System for Medical Education"**. Similarly, Zadow et al. developed an interactive multitouch tabletop system for medical education for real-time diagnosis and treatment simulations, offering cost-effective and engaging learning environments compared to full-scale mannequins **ConverSense: A Machine Learning-Based Feedback System for Clinicians"**. These studies underscore the benefits of realistic educational simulations and the trade-off between realism and cost.

The most relevant to our system is ConverSense, which uses machine learning to process social signals from patient-provider interactions to provide feedback to clinicians, facilitating self-reflection and communication improvement. Healthcare providers indicated the potential for long-term communication benefits from using ConverSense **Albright et al., "MI Techniques in Clinical Conversations"**.

\subsection{Training Systems for Counseling Conversations} 
The system proposed by Albright et al. uses MI techniques to guide users through role-playing scenarios with embodied agents, focused on initiating conversations related to mental health. This system prepares individuals to engage in meaningful conversations and provides them with feedback based on their performance.
Similarly, Murali et al. created a system that involves role-playing with a conversational agent to teach counseling skills to laypersons in the context of vaccination promotion **"Role-Playing Conversational Agent for Counseling Skills Training"**. Several commercial products have also been developed that use conversational agents for the training of health conversation skills. These have been deployed and evaluated in various application areas, including prevention of suicide among college students **"Chatbot-Based Suicide Prevention System"**, training for healthcare providers and patients to talk about overuse of antibiotics **"Antibiotic Stewardship Chatbot"**, and training for nurses to conduct screening for adolescent substance use **"Substance Use Screening Chatbot"**.

\subsection{Standardized Patients and Patient Simulation Systems}
Traditionally, standardized patients--actors who allow providers to practice clinical skills by enacting real-life scenarios as a patient--have been widely used in healthcare to enhance medical education, primarily for communication and clinical skills. Prior research indicates that the use of standardized patients allows trainees to practice real-life scenarios in a controlled environment, fostering a sense of realism and emotional engagement that traditional educational methods may lack. Previous work has emphasized the effectiveness of standardized patients in medical training by showing that engaging with standardized patients leads to better acquisition of communication skills compared to didactic methods **"Standardized Patient Education System"**. However, using standardized patients can be costly and time consuming, due to cumbersome recruiting, training, and standardization of their interactions **"Challenges in Standardized Patient Recruitment"**.

Emerging technologies, including chatbots and embodied conversational agents, have significantly transformed the patient simulation process. The introduction of simulated patients provides flexibility in training by allowing learners to interact with computerized patients integrating natural language processing and realistic emotional responses **"Simulated Patient System for Clinical Training"**. These technologies not only reduce costs associated with hiring actors, but also enhance the availability and adaptability of training scenarios, allowing personalized and context-rich interactions for clinicians. One such approach includes patient-focused simulation, which integrates real human patients with high-fidelity simulators, fostering essential communication and decision-making skills alongside technical proficiency **"Patient-Focused Simulation System"**. Studies indicate that more realistic simulations lead to improved retention of skills and knowledge, enhanced engagement, and greater confidence in clinical settings **"Impact of Realistic Simulations on Clinical Performance"**.  

Overall, the move towards the integration of human-like interaction has been shown to be crucial to bridge the gap between theoretical education and practical application in healthcare  **"Human-Like Interaction for Healthcare Education"**.

\subsection{LLMs for Simulated Patient Dialogue}
Recent advancements in LLMs have made them an attractive candidate to drive simulated patient dialogue and system reasoning for training purposes. To this end, CureFun utilizes multiple LLMs to simulate patients for medical diagnosis education, and offers automated feedback on trainee performance by analyzing medical scenarios to inform its responses **"CureFun: A Multi-LLM Simulated Patient System"**. Similarly,  introduce State-Aware Patient Simulator to bridge the gap between static medical knowledge assessments and dynamic clinical interactions **"State-Aware Patient Simulator"**. Their approach allows for more realistic LLM evaluation in multi-turn doctor-patient simulations.

Despite impressive conversational abilities of LLMs, ensuring accurate and nuanced portrayals of specific patient populations requires expert input.  address this challenge with Roleplay-doh, a pipeline that enables domain experts to guide LLM simulations through elicited principles **"Roleplay-Doh: An Expert-Guided LLM Simulation Pipeline"**. This work emphasizes the importance of expert feedback, particularly for sensitive domains such as mental health, and provides a mechanism for incorporating such feedback directly into LLM prompting **"Expert Feedback in Mental Health LLMs"**.  explore the use of ChatGPT for the simulation of psychiatrists and patients, developing a dialogue system informed by psychiatrist input **"ChatGPT-Based Psychiatrist-Patient Dialogue System"**. Their evaluation with real clinicians highlights the feasibility of LLM-powered chatbots in psychiatric scenarios while emphasizing the importance of careful prompt design for realistic and ethical interactions.

The use of LLMs for social skill training, including conflict resolution and communication, presents a promising application **"LLMs for Social Skill Training"**. For example,  discuss a framework leveraging LLMs to create accessible and engaging social skills training environments **"Framework for Accessible Social Skills Training"**. Their AI Partner, AI Mentor framework combines experiential learning with realistic practice and tailored feedback, which aligns with SimPatient's goal of providing a safe space for practicing MI techniques. However, LLMs, especially those trained with reinforcement learning from human feedback as analyzed by Perez et al. **"LLMs Trained with Reinforcement Learning"**, exhibit a positivity bias, tending towards agreeableness and a desire to comply with user requests. This raises challenges for simulating resistant or deceptive patients, scenarios crucial for robust training **"Challenges in Simulating Resistant Patients"**. Further research is needed to overcome these limitations and accurately model the full spectrum of patient behaviors.

Closest to our work is that of Wang et al., who proposed a simulated patient framework to enhance Cognitive Behavioral Therapy training **"Cognitive Behavioral Therapy Framework"**. In their work, patient cognitive models, such as emotional states and maladaptive cognitions grounded in the principles of Cognitive Behavioral Therapy, are integrated with LLMs to ensure high-fidelity simulated patient interactions. Our approach differs in that: 
(1) SimPatient uses cognitive models grounded in the literature on substance misuse **"Substance Misuse Literature Review"**; 
(2) SimPatient allows for multiple complete and natural conversations with a simulated patient, followed by an opportunity for reflection through a comprehensive dashboard; and 
(3) the evaluation dashboard visualizes tracked changes in the simulated patient's cognitive model, allowing users to reflect on what they said and the resultant change in the simulated patient's cognitive model.

\subsection{LLMs for Motivational Interviewing Evaluation}
In recent years, language models, and particularly LLMs, have gained traction in evaluating the quality of counseling conversations from both technical and relational perspectives **"LLM-Based Counseling Conversation Evaluation"**. These evaluation modules can be integrated with patient simulation platforms, offering a novel approach to evaluating the performance of counselors in MI sessions. For instance, Yosef et al. introduced an LLM-based digital patient platform that generates diverse patient profiles and utilizes LLMs to rate the quality of therapy sessions based on established frameworks such as the Motivational Interviewing Skills Code and the MITI **"Digital Patient Platform for MI Evaluation"**. These LLMs were found to effectively distinguish between varying levels of therapist expertise by completing questionnaires designed for human patients, indicating the potential for automated feedback in therapeutic settings.

Researchers have also developed datasets of counseling sessions annotated for both the therapist and client behaviors. Among these, the MI-TAGS dataset allows training language models to perform tasks such as utterance-level annotations and overall session scoring, achieving performance comparable to human annotators **"MI-TAGS Dataset"**. Using similar datasets, LLMs have been trained as evaluators for therapist responses, providing a way to gauge their adherence to MI principles in real time **"LLM-Based Therapist Response Evaluation"**. In our proposed system, we used a mix of zero-shot and few-shot approaches to utilizing LLMs for evaluating counselor actions in terms of adherence to MI principles, which eliminates the need for data-intensive and time-consuming fine-tuning.

\subsection{LLM-Based Multi-Agent Systems}
The rise of LLMs has made them an attractive candidate to drive multi-agent systems, enabling more realistic and engaging interactions between simulated patients and healthcare providers. One such approach includes patient-focused simulation, which integrates real human patients with high-fidelity simulators, fostering essential communication and decision-making skills alongside technical proficiency **"Patient-Focused Simulation System"**.

The use of LLMs for social skill training, including conflict resolution and communication, presents a promising application. For example,  discuss a framework leveraging LLMs to create accessible and engaging social skills training environments **"Framework for Accessible Social Skills Training"**. Their AI Partner, AI Mentor framework combines experiential learning with realistic practice and tailored feedback, which aligns with SimPatient's goal of providing a safe space for practicing MI techniques.

The integration of LLMs into patient simulation platforms has the potential to revolutionize healthcare education by providing more realistic and engaging training experiences. However, challenges remain in ensuring the accuracy and nuance of LLM-generated patient interactions, as well as the need for careful prompt design and evaluation metrics **"Challenges in LLM-Generated Patient Interactions"**.

Overall, the integration of LLMs into healthcare education presents a promising opportunity to enhance training experiences and improve clinical outcomes. However, further research is needed to overcome challenges and ensure the accurate and nuanced portrayal of patient interactions in simulated environments **"Future Directions for LLMs in Healthcare Education"**.