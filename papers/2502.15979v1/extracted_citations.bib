@inproceedings{10.1145/3583780.3615142,
author = {Gong, Jiaying and Chen, Wei-Te and Eldardiry, Hoda},
title = {Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615142},
doi = {10.1145/3583780.3615142},
abstract = {Existing attribute-value extraction (AVE) models require large quantities of labeled data for training. However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce. Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples. We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes. Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights. To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set. Extensive experiments with ablation studies conducted on two datasets demonstrate that our proposed model significantly outperforms other SOTA models for information extraction in few-shot learning.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3902–3907},
numpages = {6},
keywords = {multi-label few-shot learning, attribute value extraction},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@INPROCEEDINGS{10020304,
  author={Deng, Zhongfen and Chen, Wei-Te and Chen, Lei and Yu, Philip S.},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction}, 
  year={2022},
  volume={},
  number={},
  pages={1816-1821},
  keywords={Annotations;Semantics;Big Data;Sampling methods;Data models;Data mining;Electronic commerce;product attribute value extraction;multi-label classification;semantic matching},
  doi={10.1109/BigData55660.2022.10020304}}

@INPROCEEDINGS{10386204,
  author={Deng, Zhongfen and Peng, Hao and Zhang, Tao and Liu, Shuaiqi and Zhao, Wenting and Wang, Yibo and Yu, Philip S.},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction}, 
  year={2023},
  volume={},
  number={},
  pages={1087-1094},
  keywords={Training;Predictive models;Multitasking;Data models;Question answering (information retrieval);Generators;Data mining;product attribute value extraction;attribute value generation;value classification;multi-task learning},
  doi={10.1109/BigData59044.2023.10386204}}

@article{baumann2024using,
  title={Using LLMs for the Extraction and Normalization of Product Attribute Values},
  author={Baumann, Nick and Brinkmann, Alexander and Bizer, Christian},
  journal={arXiv preprint arXiv:2403.02130},
  year={2024}
}

@article{brinkmann2023product,
  title={Product Attribute Value Extraction using Large Language Models},
  author={Brinkmann, Alexander and Shraga, Roee and Bizer, Christian},
  journal={arXiv preprint arXiv:2310.12537},
  year={2023}
}

@inproceedings{chen-etal-2023-named,
    title = "Does Named Entity Recognition Truly Not Scale Up to Real-world Product Attribute Extraction?",
    author = "Chen, Wei-Te  and
      Shinzato, Keiji  and
      Yoshinaga, Naoki  and
      Xia, Yandi",
    editor = "Wang, Mingxuan  and
      Zitouni, Imed",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-industry.16",
    doi = "10.18653/v1/2023.emnlp-industry.16",
    pages = "152--159",
    abstract = "The key challenge in the attribute-value extraction (AVE) task from e-commerce sites is the scalability to diverse attributes for a large number of products in real-world e-commerce sites. To make AVE scalable to diverse attributes, recent researchers adopted a question-answering (QA)-based approach that additionally inputs the target attribute as a query to extract its values, and confirmed its advantage over a classical approach based on named-entity recognition (NER) on real-word e-commerce datasets. In this study, we argue the scalability of the NER-based approach compared to the QA-based approach, since researchers have compared BERT-based QA-based models to only a weak BiLSTM-based NER baseline trained from scratch in terms of only accuracy on datasets designed to evaluate the QA-based approach. Experimental results using a publicly available real-word dataset revealed that, under a fair setting, BERT-based NER models rival BERT-based QA models in terms of the accuracy, and their inference is faster than the QA model that processes the same product text several times to handle multiple target attributes.",
}

@inproceedings{chen2022extreme,
  title={Extreme multi-label classification with label masking for product attribute value extraction},
  author={Chen, Wei-Te and Xia, Yandi and Shinzato, Keiji},
  booktitle={Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5)},
  pages={134--140},
  year={2022}
}

@article{fang2024llm,
  title={LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction},
  author={Fang, Chenhao and Li, Xiaohan and Fan, Zezhong and Xu, Jianpeng and Nag, Kaushiki and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
  journal={arXiv preprint arXiv:2403.00863},
  year={2024}
}

@inproceedings{fei2023transferable,
  title={Transferable decoding with visual entities for zero-shot image captioning},
  author={Fei, Junjie and Wang, Teng and Zhang, Jinrui and He, Zhenyu and Wang, Chengjie and Zheng, Feng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3136--3146},
  year={2023}
}

@inproceedings{ghosh2023d,
  title={D-Extract: Extracting dimensional attributes from product images},
  author={Ghosh, Pushpendu and Wang, Nancy and Yenigalla, Promod},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3641--3649},
  year={2023}
}

@inproceedings{gong2024multi,
author = {Gong, Jiaying and Eldardiry, Hoda},
title = {Multi-Label Zero-Shot Product Attribute-Value Extraction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645649},
doi = {10.1145/3589334.3645649},
abstract = {E-commerce platforms should provide detailed product descriptions (attribute values) for effective product search and recommendation. However, attribute value information is typically not available for new products. To predict unseen attribute values, large quantities of labeled training data are needed to train a traditional supervised learning model. Typically, it is difficult, time-consuming, and costly to manually label large quantities of new product profiles. In this paper, we propose a novel method to efficiently and effectively extract unseen attribute values from new products in the absence of labeled data (zero-shot setting). We propose HyperPAVE, a multi-label zero-shot attribute value extraction model that leverages inductive inference in heterogeneous hypergraphs. In particular, our proposed technique constructs heterogeneous hypergraphs to capture complex higher-order relations (i.e. user behavior information) to learn more accurate feature representations for graph nodes. Furthermore, our proposed HyperPAVE model uses an inductive link prediction mechanism to infer future connections between unseen nodes. This enables HyperPAVE to identify new attribute values without the need for labeled training data. We conduct extensive experiments with ablation studies on different categories of the MAVE dataset. The results demonstrate that our proposed HyperPAVE model significantly outperforms existing classification-based, generation-based large language models for attribute value extraction in the zero-shot setting.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2259–2270},
numpages = {12},
keywords = {attribute value extraction, heterogeneous hypergraph, inductive link prediction, zero-shot learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{guo2023images,
  title={From images to textual prompts: Zero-shot visual question answering with frozen large language models},
  author={Guo, Jiaxian and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Li, Boyang and Tao, Dacheng and Hoi, Steven},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10867--10877},
  year={2023}
}

@inproceedings{li2023attgen,
  title={AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction},
  author={Li, Yanzeng and Xue, Bingcong and Zhang, Ruoyu and Zou, Lei},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2139--2152},
  year={2023}
}

@article{liu2022boosting,
  title={Boosting Multi-Modal E-commerce Attribute Value Extraction via Unified Learning Scheme and Dynamic Range Minimization},
  author={Liu, Mengyin and Zhu, Chao and Gao, Hongyu and Gu, Weibo and Wang, Hongfa and Liu, Wei and Yin, Xu-cheng},
  journal={arXiv preprint arXiv:2207.07278},
  year={2022}
}

@inproceedings{liu2023knowledge,
  title={Knowledge-selective pretraining for attribute value extraction},
  author={Liu, Hui and Yin, Qingyu and Wang, Zhengyang and Zhang, Chenwei and Jiang, Haoming and Gao, Yifan and Li, Zheng and Li, Xian and Zhang, Chao and Yin, Bing and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={8062--8074},
  year={2023}
}

@inproceedings{liu2023multimodal,
  title={Multimodal pre-training with self-distillation for product understanding in e-commerce},
  author={Liu, Shilei and Li, Lin and Song, Jun and Yang, Yonghua and Zeng, Xiaoyi},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={1039--1047},
  year={2023}
}

@article{shinzato2022simple,
  title={Simple and effective knowledge-driven query expansion for QA-based product attribute extraction},
  author={Shinzato, Keiji and Yoshinaga, Naoki and Xia, Yandi and Chen, Wei-Te},
  journal={arXiv preprint arXiv:2206.14264},
  year={2022}
}

@inproceedings{tewel2022zerocap,
  title={Zerocap: Zero-shot image-to-text generation for visual-semantic arithmetic},
  author={Tewel, Yoad and Shalev, Yoav and Schwartz, Idan and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17918--17928},
  year={2022}
}

@inproceedings{wang2020learning,
  title={Learning to extract attribute value from product via question answering: A multi-task approach},
  author={Wang, Qifan and Yang, Li and Kanagal, Bhargav and Sanghai, Sumit and Sivakumar, D and Shu, Bin and Yu, Zac and Elsas, Jon},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={47--55},
  year={2020}
}

@inproceedings{wang2022smartave,
  title={Smartave: Structured multimodal transformer for product attribute value extraction},
  author={Wang, Qifan and Yang, Li and Wang, Jingang and Krishnan, Jitin and Dai, Bo and Wang, Sinong and Xu, Zenglin and Khabsa, Madian and Ma, Hao},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={263--276},
  year={2022}
}

@inproceedings{wang2023mpkgac,
  title={MPKGAC: Multimodal Product Attribute Completion in E-commerce},
  author={Wang, Kai and Shao, Jianzhi and Zhang, Tao and Chen, Qijin and Huo, Chengfu},
  booktitle={Companion Proceedings of the ACM Web Conference 2023},
  pages={336--340},
  year={2023}
}

@article{xu2023towards,
  title={Towards open-world product attribute mining: A lightly-supervised approach},
  author={Xu, Liyan and Zhang, Chenwei and Li, Xian and Shang, Jingbo and Choi, Jinho D},
  journal={arXiv preprint arXiv:2305.18350},
  year={2023}
}

@inproceedings{xu2023zero,
  title={Zero-TextCap: Zero-shot Framework for Text-based Image Captioning},
  author={Xu, Dongsheng and Zhao, Wenye and Cai, Yi and Huang, Qingbao},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={4949--4957},
  year={2023}
}

@inproceedings{yang2023mixpave,
  title={Mixpave: Mix-prompt tuning for few-shot product attribute value extraction},
  author={Yang, Li and Wang, Qifan and Wang, Jingang and Quan, Xiaojun and Feng, Fuli and Chen, Yu and Khabsa, Madian and Wang, Sinong and Xu, Zenglin and Liu, Dongfang},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={9978--9991},
  year={2023}
}

@inproceedings{zeng2023conzic,
  title={Conzic: Controllable zero-shot image captioning by sampling-based polishing},
  author={Zeng, Zequn and Zhang, Hao and Lu, Ruiying and Wang, Dongsheng and Chen, Bo and Wang, Zhengjue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23465--23476},
  year={2023}
}

@inproceedings{zhang2022oa,
  title={Oa-mine: Open-world attribute mining for e-commerce products with weak supervision},
  author={Zhang, Xinyang and Zhang, Chenwei and Li, Xian and Dong, Xin Luna and Shang, Jingbo and Faloutsos, Christos and Han, Jiawei},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={3153--3161},
  year={2022}
}

@article{zou2024eiven,
  title={EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM},
  author={Zou, Henry Peng and Yu, Gavin Heqing and Fan, Ziwei and Bu, Dan and Liu, Han and Dai, Peng and Jia, Dongmei and Caragea, Cornelia},
  journal={arXiv preprint arXiv:2404.08886},
  year={2024}
}

@article{zou2024implicitave,
  title={ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction},
  author={Zou, Henry Peng and Samuel, Vinay and Zhou, Yue and Zhang, Weizhi and Fang, Liancheng and Song, Zihe and Yu, Philip S and Caragea, Cornelia},
  journal={arXiv preprint arXiv:2404.15592},
  year={2024}
}

