
\section{Conclusion and Future work}
% In this paper, we introduce a cross-architecture knowledge distillation framework, \method{}, that enables a lightweight MLP model to attain performance comparable to or surpassing more complex teacher models, such as Transformers and CNN-based architectures. By focusing on two fundamental time series patterns i.e. multi-scale and multi-period, \method{} efficiently transfers rich temporal and frequency-domain knowledge from teacher models to the MLP student. Our extensive experiments indicate that \method{} offers a practical solution for scenarios with limited computational resources and stringent latency requirements. Moreover, we show that \method{} is flexible, accommodating various teacher models and different look-back window lengths. Future work includes further exploration of distilling more advanced teacher models such as recently powerful time series foundation models and the integration of other time series patterns such as multi-variate pattern.

We propose \method{}, a cross-architecture \textit{KD} framework enabling lightweight MLP to surpass complex teachers. By distilling multi-scale and multi-period patterns, \method{} efficiently transfers temporal and frequency-domain knowledge. Theoretical interpretations and experiments confirm its effectiveness. Future work includes distilling from advanced time series models, e.g. time series foundation models, and incorporating multivariate patterns.



\clearpage
\section{Impact Statement}

\textbf{Transparency Impact.}  
Transparency is vital to facilitate accountability, competition, and collective understanding~\cite{bommasani2024foundation}. To support these objectives, we will publicly release our code base, data sources, and evaluation pipeline. However, due to the requirements of anonymized submission, these materials are currently included only in the supplementary material.

\textbf{Environmental Impact.}  
\method{} achieves fast inference speed, which significantly reduces its carbon footprint by lowering GPU usage. This reduction also contributes to decreased carbon emissions from the local electricity grid.

\textbf{Ethical Impact.}  
While \method{} performs well in long-term time series forecasting, caution is needed in critical and high-stakes domains like healthcare, where incorrect predictions could have severe consequences.



