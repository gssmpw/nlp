@article{autoformer,
  title={Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={22419--22430},
  year={2021}
}

@article{campos2023lightts,
  title={LightTS: Lightweight time series classification with adaptive ensemble distillation},
  author={Campos, David and Zhang, Miao and Yang, Bin and Kieu, Tung and Guo, Chenjuan and Jensen, Christian S},
  journal={Proceedings of the ACM on Management of Data},
  volume={1},
  number={2},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{dlinear,
  title={Are transformers effective for time series forecasting?},
  author={Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={9},
  pages={11121--11128},
  year={2023}
}

@inproceedings{fedformer,
  title={Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={International conference on machine learning},
  pages={27268--27286},
  year={2022},
  organization={PMLR}
}

@inproceedings{frets,
title={Frequency-domain {MLP}s are More Effective Learners in Time Series Forecasting},
author={Kun Yi and Qi Zhang and Wei Fan and Shoujin Wang and Pengyang Wang and Hui He and Ning An and Defu Lian and Longbing Cao and Zhendong Niu},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023}
}

@article{hinton2015distilling,
  title={Distilling the Knowledge in a Neural Network},
  author={Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{informer,
  title={Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={11106--11115},
  year={2021}
}

@article{lightts,
  title={Less is more: Fast multivariate time series forecasting with light sampling-oriented mlp structures},
  author={Zhang, Tianping and Zhang, Yizhuo and Cao, Wei and Bian, Jiang and Yi, Xiaohan and Zheng, Shun and Li, Jian},
  journal={arXiv preprint arXiv:2207.01186},
  year={2022}
}

@inproceedings{moderntcn,
  title={Moderntcn: A modern pure convolution structure for general time series analysis},
  author={Luo, Donghao and Wang, Xue},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{nbeats,
title={N-BEATS: Neural basis expansion analysis for interpretable time series forecasting},
author={Boris N. Oreshkin and Dmitri Carpov and Nicolas Chapados and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{nhits,
  title={Nhits: Neural hierarchical interpolation for time series forecasting},
  author={Challu, Cristian and Olivares, Kin G and Oreshkin, Boris N and Ramirez, Federico Garza and Canseco, Max Mergenthaler and Dubrawski, Artur},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={6},
  pages={6989--6997},
  year={2023}
}

@article{sparsetsf,
  title={SparseTSF: Modeling Long-term Time Series Forecasting with 1k Parameters},
  author={Lin, Shengsheng and Lin, Weiwei and Wu, Wentai and Chen, Haojun and Yang, Junjie},
  journal={arXiv preprint arXiv:2405.00946},
  year={2024}
}

@article{tide,
  title={Long-term forecasting with tide: Time-series dense encoder},
  author={Das, Abhimanyu and Kong, Weihao and Leach, Andrew and Mathur, Shaan and Sen, Rajat and Yu, Rose},
  journal={arXiv preprint arXiv:2304.08424},
  year={2023}
}

@article{timesnet,
  title={Timesnet: Temporal 2d-variation modeling for general time series analysis},
  author={Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2210.02186},
  year={2022},
  publisher={arXivpreprint}
}

@article{tsmixer,
  title={Tsmixer: An all-mlp architecture for time series forecasting},
  author={Chen, Si-An and Li, Chun-Liang and Yoder, Nate and Arik, Sercan O and Pfister, Tomas},
  journal={arXiv preprint arXiv:2303.06053},
  year={2023}
}

@article{xu2022contrastive,
  title={Contrastive adversarial knowledge distillation for deep model compression in time-series regression tasks},
  author={Xu, Qing and Chen, Zhenghua and Ragab, Mohamed and Wang, Chao and Wu, Min and Li, Xiaoli},
  journal={Neurocomputing},
  volume={485},
  pages={242--251},
  year={2022},
  publisher={Elsevier}
}

