
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Method.pdf}
    \vskip -1.5em
    \caption{Overall framework of \method{}, which distills knowledge from a teacher model to a student MLP using (a) Multi-Scale Distillation and (b) Multi-Period Distillation at both feature and prediction levels. (a) Multi-Scale Distillation involves downsampling the original time series into multiple coarser scales and aligning these scales between the student and teacher. (b) Multi-Period Distillation applies FFT to transform the time series into a spectrogram, followed by matching the period distributions after applying softmax.}
    \label{fig:method}
    \vskip -1em
\end{figure*}

\vskip -2em
\section{Methodology}

% In alignment with our intuition about preserving multi-scale and multi-period pattern knowledge, we introduce a novel distillation framework named \method{}. Unlike conventional approaches that emphasize matching predictions or time series representations directly, \method{} focuses on transferring knowledge of multi-scale patterns in the temporal domain and multi-period patterns in the frequency domain. 
% To efficiently distill this knowledge from the teacher model to the MLP, we propose two specific distillation objectives: \textit{multi-scale distillation} and \textit{multi-period distillation}, which we will detail next. The overall framework of \method{} is shown in Figure~\ref{fig:method}.

% \wei{it could be good to introduce an overall framework for KD (using equations) in time series and the following subsections describe how \method{} address it? }

% \wei{Standardize the notations: (1) bold upper-case letters for matrices; (2) bold lower-case letters for vectors; (3) regular letters for scalars (typically lower cases while upper cases are fine). You can take a look at the itransformer paper}

Motivated by our preliminary studies, we propose a novel \textit{KD} framework \method{} for time series to transfer the knowledge from a fixed, pretrained teacher model \(f_t\) to a student MLP model \(f_s\). The student produces predictions \(\mathbf{\hat{Y}}_s \in \mathbb{R}^{S \times C}\) and internal features \(\mathbf{H}_s\in \mathbb{R}^{D \times C}\). The teacher model produces predictions \(\mathbf{\hat{Y}}_t \in \mathbb{R}^{S \times C}\) and internal features \(\mathbf{H}_t\in \mathbb{R}^{D_t \times C}\). Our general objective is:
\begin{equation}\label{eq:kd_obj}
    \min\nolimits_{\theta_s} \mathcal{L}_{sup}(\mathbf{Y}, \mathbf{\hat{Y}}_s) + \mathcal{L}_{\mathrm{KD}}^\mathbf{Y}(\mathbf{\hat{Y}}_t, \mathbf{\hat{Y}}_s) + \mathcal{L}_{\mathrm{KD}}^\mathbf{H}(\mathbf{H}_t, \mathbf{H}_s),
\end{equation}
where \(\theta_s\) is the parameter of the student; \(\mathcal{L}_{sup}\) is the supervised loss (e.g., MSE) between predictions and ground truth; \(\mathcal{L}_{\mathrm{KD}}^\mathbf{Y}\) and \(\mathcal{L}_{\mathrm{KD}}^\mathbf{H}\) are the distillation loss terms that encourage the student model to learn knowledge from the teacher on both \textbf{prediction level}~\cite{hinton2015distilling} and \textbf{feature level}~\cite{romero2014fitnets}, respectively. Unlike conventional approaches that emphasize matching model predictions, \method{} integrates key time-series patterns including multi-scale and multi-period knowledge. The overall framework of \method{} is shown in Figure~\ref{fig:method}. 
% In the following, we detail each component of our approach.



% In alignment with our intuition about preserving multi-scale and multi-period pattern knowledge, we introduce a novel distillation framework named \method{}. Unlike conventional approaches that emphasize matching predictions directly, \method{} focuses on transferring knowledge of multi-scale patterns in the temporal domain and multi-period patterns in the frequency domain. 
% The overall framework of \method{} is shown in Figure~\ref{fig:method}. In the following, we provide details on each component of our approach.To efficiently distill this knowledge from the teacher model to the MLP, we propose two specific distillation objectives: \textbf{multi-scale distillation} and \textbf{multi-period distillation}. The overall framework of \method{} is shown in Figure~\ref{fig:method}. In the following, we provide details on each component of our approach.

\subsection{Multi-Scale Distillation}
One key component of \method{} is multi-scale distillation, where ``multi-scale'' refers to representing the same time series at different sampling rates. This enables MLP to effectively capture both coarse-grained and fine-grained patterns. By distilling at both the prediction level and the feature level, we ensure that MLP not only replicates the teacher's multi-scale predictions but also aligns with its internal representations from the intermediate layer.

\vspace{-0.5em}
\paragraph{Prediction Level.}
At the prediction level, we directly transfer multi-scale signals from the teacher’s outputs to guide the MLP’s predictions. We first produce multi-scale predictions by downsampling the original predictions from the teacher \(\mathbf{\hat{Y}}_t \in \mathbb{R}^{S \times C}\) and the MLP \(\mathbf{\hat{Y}}_s \in \mathbb{R}^{S \times C}\), where \(S\) is the prediction length and \(C\) is the number of variables. The predictions at \textit{Scale 0} are equal to the original predictions, that is, \(\mathbf{\hat{Y}}_t^0=\mathbf{\hat{Y}}_t\) and \(\mathbf{\hat{Y}}_s^0=\mathbf{\hat{Y}}_s\). We then downsample these predictions across \(M\) scales using convolutional operations with a stride of 2, generating multi-scale prediction sets \(\mathcal{Y}_t = \{\mathbf{\hat{Y}}_t^0, \mathbf{\hat{Y}}_t^1,\cdots,\mathbf{\hat{Y}}_t^M\}\) and \(\mathcal{Y}_s = \{\mathbf{\hat{Y}}_s^0, \mathbf{\hat{Y}}_s^1,\cdots,\mathbf{\hat{Y}}_s^M\}\), where \(\mathbf{\hat{Y}}_t^M, \mathbf{\hat{Y}}_s^M \in \mathbb{R}^{\lfloor S/2^M \rfloor \times C}\). The downsampling is defined as: 
\begin{equation}
    \mathbf{\hat{Y}}_x^m = \mathrm{Conv}(\mathbf{\hat{Y}}_x^{m-1}, \mathrm{stride}=2),
    \label{eq:multiscale_downsample}
\end{equation}
where \(x \in \{t, s\}\), \(m \in \{1, \cdots, M\}\), $\mathrm{Conv}$ denotes a 1D-convolutional layer with a temporal stride of 2. The predictions at the lowest level \(\mathbf{\hat{Y}}_x^0=\mathbf{\hat{Y}}_x\) maintain the original temporal resolution, while the highest-level predictions \(\mathbf{\hat{Y}}_x^M\) represent coarser patterns. We define the multi-scale distillation loss at the prediction level as:
\begin{equation}
    \mathcal{L}_{scale}^\mathbf{Y} = \textstyle\sum_{m=0}^M ||\mathbf{\hat{Y}}_t^m - \mathbf{\hat{Y}}_s^m||^2 /(M+1).
\end{equation}
% \wei{if Y is a vector or matrix, we should not use () but $| |$} 
Here we use MSE loss to match the MLP’s predictions to the teacher’s predictions at multiple scales.

\vspace{-0.5em}
\paragraph{Feature Level.} 
At the feature level, we align MLP’s intermediate features with teacher’s multi-scale representations, enabling MLP to form richer internal structures that support more accurate forecasts.
Let \(\mathbf{H}_s \in \mathbb{R}^{D \times C}\) and \(\mathbf{H}_t \in \mathbb{R}^{D_t \times C}\) denote MLP and teacher features with feature dimensions \(D\) and \(D_t\), respectively. As their dimensions can be different, we first use a parameterized regressor (e.g. MLP) to align their feature dimensions: 
% \wei{what does the regressor mean?? no explanation for this operator: what is the detailed operator; what is the purpose}
\begin{equation}
    \mathbf{H}'_t = \text{Regressor}(\mathbf{H}_t),
\end{equation}
where \(\mathbf{H}'_t \in \mathbb{R}^{D \times C}\).  
% We then downsample both sets of features across multiple scales:
% \begin{equation}
%     \mathbf{H}_x^m = \mathrm{Conv}(\mathbf{H}_x^{m-1}, \mathrm{stride}=2),
% \end{equation}
% where \(x \in \{t, s\}\), \(m \in \{1, \cdots, M\}\), and \(\mathbf{H}_s^0 = \mathbf{H}_s\), \(\mathbf{H}_t^0 = \mathbf{H}'_t\). 
Similar to the prediction level, we compute $\mathbf{H}_x^m$ by downsampling $\mathbf{H}_s$ and $\mathbf{H}'_t$ across multiple scales using the same approach as in Equation~\ref{eq:multiscale_downsample}. We define the multi-scale distillation loss at the feature level as:
\begin{equation}
    \mathcal{L}_{scale}^\mathbf{H} = \textstyle\sum_{m=0}^M ||\mathbf{H}_t^m - \mathbf{H}_s^m||^2 /(M+1).
\end{equation}

\subsection{Multi-Period Distillation}
% \wei{seems that the prediction level and feature level are basically using the same equations? then we probably do not so much space to describe them given the redundancy}
% \wei{we need some transitions: in addition to multi-scale ...temporal domain...}  
{In addition to multi-scale distillation in the temporal domain, we further
propose multi-period distillation to help MLP learn complex periodic patterns in the frequency domain.} By aligning periodicity-related signals from the teacher model at both the prediction and feature levels, the MLP can learn richer frequency-domain representations and ultimately improve its forecasting performance.

\paragraph{Prediction Level.}
For the predictions from the teacher \(\mathbf{\hat{Y}}_t \in \mathbb{R}^{S \times C}\) and the MLP \(\mathbf{\hat{Y}}_s \in \mathbb{R}^{S \times C}\), we first identify their periodic patterns. We perform this in the frequency domain using the Fast Fourier Transform (FFT):
\begin{equation}
    \mathbf{A}_x = \text{Amp}(\text{FFT}(\mathbf{\hat{Y}}_x)),
    \label{eq:multiperiod_spectrograms}
\end{equation}
where \(x \in \{t, s\}\) and spectrograms \(\mathbf{A}_x \in \mathbb{R}^{\frac{S}{2} \times C}\). Here, \(\text{FFT}(\cdot)\) denotes the FFT operation and \(\text{Amp}(\cdot)\) calculates the amplitude. We remove the direct current (DC) component from \(\mathbf{A}_x\). For certain variable \(c\), the \(i\)-th value \(\mathbf{A}_x^{i,c}\) indicates the intensity of the frequency-\(i\) component, corresponding to a period length \(\lceil S/i\rceil\). Larger amplitude values indicate that the associated frequency (period) is more significant.

To reduce the influence of minor frequencies and avoid noise introduced by less meaningful frequencies~\cite{timesnet, fedformer}, we propose a distribution-based matching scheme. We use a softmax function with a colder temperature to highlight the most significant frequencies:
\begin{equation}
    \mathbf{Q}_x^\mathbf{Y} = {\exp\bigl(\mathbf{A}_x^i / \tau\bigr)}/{\sum\nolimits_{j=1}^{S/2} \exp\bigl(\mathbf{A}_x^j /\tau\bigr)},
    \label{eq:multiperiod_distribution}
\end{equation}
where \(\mathbf{Q}_x^\mathbf{Y} \in \mathbb{R}^{\frac{S}{2} \times C}\) and \(\tau\) is a temperature parameter that controls the sharpness of the distribution. We set \(\tau=0.5\) by default. The period distribution \(\mathbf{Q}_x^\mathbf{Y}\) represents the multi-period pattern in the prediction time series, which we want the MLP to learn from the teacher. We use KL divergence to match these distributions~\cite{hinton2015distilling}. We define the multi-period distillation loss at the prediction level as:
\begin{equation}
    \mathcal{L}_{period}^\mathbf{Y} = \text{KL}\bigl(\mathbf{Q}_t^\mathbf{Y}, \mathbf{Q}_s^\mathbf{Y}\bigr).
\end{equation}
% where KL denotes the Kullback--Leibler divergence~\cite{hinton2015distilling}, a common metric to measure distribution difference.

% \paragraph{Feature Level.}
% Similar to the prediction level, we also apply multi-period distillation at the feature level. We compute:
% \begin{equation}
%     \mathbf{B}_x = \text{Amp}(\text{FFT}(\mathbf{\hat{H}}_x)),
% \end{equation}
% \begin{equation}
%     \mathbf{Q}_x^\mathbf{H} = \frac{\exp\bigl(\mathbf{B}_x^i / \tau\bigr)}{\sum_{j=1}^{D/2} \exp\bigl(\mathbf{B}_x^j /\tau\bigr)},
% \end{equation}
% and define:
% \begin{equation}
%     \mathcal{L}_{period}^\mathbf{H} = \text{KL}\bigl(\mathbf{Q}_t^\mathbf{H}, \mathbf{Q}_s^\mathbf{H}\bigr),
% \end{equation}
% where \(\mathbf{B}_x, \mathbf{Q}_x^\mathbf{H} \in \mathbb{R}^{\frac{D}{2} \times C}\). These feature-level distributions represent the multi-period pattern in feature space, enabling the MLP to learn periodic structure from the teacher at the feature level.

\vspace{-0.5em}
\paragraph{Feature Level.}
Similar to the prediction level, we apply multi-period distillation at the feature level. For the features \(\mathbf{H}'_t \in \mathbb{R}^{D \times C}\) and \(\mathbf{H}_s \in \mathbb{R}^{D \times C}\), we compute the spectrograms and the corresponding period distributions \(\mathbf{Q}_x^\mathbf{H}\) using the same approach as in Equations~\ref{eq:multiperiod_spectrograms} and~\ref{eq:multiperiod_distribution}. Multi-period distillation loss at feature level is then defined as:
\begin{equation}
    \mathcal{L}_{period}^\mathbf{H} = \text{KL}\bigl(\mathbf{Q}_t^\mathbf{H}, \mathbf{Q}_s^\mathbf{H}\bigr).
\end{equation}

\subsection{Overall Optimization and Theoretical Analaysis}
During the training of \method{}, we jointly optimize both the multi-scale and multi-period distillation losses at both the prediction and feature levels, together with the supervised ground-truth label loss:
\begin{equation}
    \mathcal{L}_{sup} = ||\mathbf{Y} - \mathbf{\hat{Y}}_s||^2,
\end{equation}
where \(\mathcal{L}_{sup}\) is the ground-truth loss (for example, MSE loss) used to train MLP directly. Thus, the overall training loss for the student MLP is defined as:
\begin{equation}
    \mathcal{L} = \mathcal{L}_{sup} + \alpha \cdot \bigl(\mathcal{L}_{scale}^\mathbf{Y} + \mathcal{L}_{period}^\mathbf{Y}\bigr) + \beta \cdot \bigl(\mathcal{L}_{scale}^\mathbf{H} + \mathcal{L}_{period}^\mathbf{H}\bigr),
    \label{eq:overall_optimization}
\end{equation}
where \(\alpha\) and \(\beta\) are hyper-parameters that control the contributions of the prediction-level and feature-level distillation loss terms, respectively. The teacher model is pretrained and remains frozen throughout the training process of MLP.


\underline{\textbf{Theoretical Interpretations.}} We provide a theoretical understanding of multi-scale and multi-period distillation loss from \textbf{a novel data augmentation perspective}. We further show that the proposed distillation loss can be interpreted as training with augmented samples derived from a special \textit{mixup}~\cite{mixup} strategy. The distillation process augments data by blending ground truth with teacher predictions, analogous to label smoothing in classification, and provides several benefits for time series forecasting:
\textit{\textbf{(1)} Enhanced Generalization:} It enhances generalization by exposing the student model to richer supervision signals from augmented samples, thus mitigating overfitting, especially with limited or noisy data.
{\textit{\textbf{(2)} Explicit Integration of Patterns:} The augmented supervision signals explicitly incorporate patterns across multiple scales and periods, offering insights that are not immediately evident in the raw ground truth.}
\textit{\textbf{(3}) Stabilized Training Dynamics:} The blending of targets softens the supervision signals, which diminishes the model’s sensitivity to noise and leads to more stable training phases. This will in turn support smoother optimization dynamics and fosters improved convergence. For clarity, our discussion is centered at the prediction level.  We present the following theorem:  
% \wei{in eq. 12, we used alpha and beta; we wanna avoid abusing notations. you may use $\lambda_1$ and $\lambda_2$ in eq. 12 or change the threom}
% \begin{theorem} \label{thm:multiscale}
% Let $(x, y)$ denote original input data pairs and $(x, y^t)$ represent corresponding teacher data pairs. Consider a data augmentation function $\mathcal{A}(\cdot)$ applied to $(x, y)$, generating augmented samples $(x', y')$. Define the training loss on these augmented samples as $\mathcal{L}_{aug} = \textstyle\sum_{(x',y') \in \mathcal{A}(x,y)} |f_s(x') - y'|^2$. Then, the following inequality holds: 
% $\mathcal{L}_{sup} + \lambda \mathcal{L}_{scale} \geq \mathcal{L}_{aug}$
% % \begin{equation}
% %    \mathcal{L}_{sup} + \alpha \mathcal{L}_{scale} \geq \mathcal{L}_{aug}
% % \end{equation}
% when $\mathcal{A}(\cdot)$ is instantiated as a mixup function~\cite{mixup} that interpolates between the original input data $(x,y)$ and teacher data $(x,y^t)$ with a mixing coefficient $\lambda \in (0,1)$, i.e. $y' = \lambda y^t + (1-\lambda) y$.
% \end{theorem}
\begin{theorem} \label{thm:multiscale}
Let $(x, y)$ denote original input data pairs and $(x, y^t)$ represent corresponding teacher data pairs. Consider a data augmentation function $\mathcal{A}(\cdot)$ applied to $(x, y)$, generating augmented samples $(x', y')$. Define the training loss on these augmented samples as $\mathcal{L}_{aug} = \sum_{(x',y') \in \mathcal{A}(x,y)} |f_s(x') - y'|^2$. Then, the following inequality holds: 
$
   \mathcal{L}_{sup} + \eta \mathcal{L}_{scale} \geq \mathcal{L}_{aug},
$
when $\mathcal{A}(\cdot)$ is instantiated as a mixup function~\cite{mixup} that interpolates between the original input data $(x,y)$ and teacher data $(x,y^t)$ with a mixing coefficient $\lambda=\frac{1}{1+\eta}$, i.e. $y' = \lambda y + (1-\lambda) y^t$.
\end{theorem}
We provide proof of Theorem~\ref{thm:multiscale} in Appendix~\ref{app:theory}.  Theorem~\ref{thm:multiscale} suggests that optimizing multi-scale distillation loss \(\mathcal{L}_{\text{scale}}\) jointly with supervised loss \(\mathcal{L}_{\text{sup}}\) is equivalent to minimizing an upper bound on a special \textit{mixup} augmentation loss. In particular, we mix multi-scale teacher predictions \(\{\mathbf{\hat{Y}}_t^{(m)}\}_{m=0}^M\) with ground truth \(\mathbf{Y}\), thereby allowing MLP to learn more informative time series temporal pattern. Similarly, we present a theorem for understanding $\mathcal{L}_{period}$.

% \begin{theorem} \label{thm:multiperiod}
% Define the training loss on the augmented samples using KL divergence as $\mathcal{L}_{aug} = \textstyle\sum_{(x',y') \in \mathcal{A}(x,y)} \text{KL}\big(y', \mathcal{X}(f_s(x'))\big)$, where $\mathcal{X}(\cdot) = \text{Softmax}(\text{Amp}(\text{FFT}(\cdot)))$. Then, the following inequality holds: 
% $\mathcal{L}_{sup} + \lambda \mathcal{L}_{period} \geq \mathcal{L}_{aug}$
% % \begin{equation}
% %    \mathcal{L}_{sup} + \alpha \mathcal{L}_{period} \geq \mathcal{L}_{aug}
% % \end{equation}
% where $\mathcal{A}(\cdot)$ is instantiated as a mixup function that interpolates between the period distribution of original input data $(x,\mathcal{X}(y))$ and teacher data $(x,\mathcal{X}(y^t))$ with a mixing coefficient $\lambda \in (0,1)$, i.e. $y' = \lambda \mathcal{X}(y^t) + (1-\lambda) \mathcal{X}(y)$.
% \end{theorem}
\begin{theorem} \label{thm:multiperiod}
Define the training loss on the augmented samples using KL divergence as $\mathcal{L}_{aug} = \sum_{(x',y') \in \mathcal{A}(x,y)} \text{KL}\big(y', \mathcal{X}(f_s(x'))\big)$, where $\mathcal{X}(\cdot) = \text{Softmax}(\text{FFT}(\cdot))$. Then, the following inequality holds: 
$
   \mathcal{L}_{sup} + \eta\mathcal{L}_{period} \geq \mathcal{L}_{aug},
$
where $\mathcal{A}(\cdot)$ is instantiated as a mixup function that interpolates between the period distribution of original input data $(x,\mathcal{X}(y))$ and teacher data $(x,\mathcal{X}(y^t))$ with a mixing coefficient $\lambda=\eta$, i.e. $y' =  \mathcal{X}(y) + \lambda \mathcal{X}(y^t)$.
\end{theorem}
The proof can be found in Appendix~\ref{app:theory}. Theorem~\ref{thm:multiperiod} shows that optimizing the multi-period distillation loss \(\mathcal{L}_{\text{period}}\) jointly with the supervised loss \(\mathcal{L}_{\text{sup}}\) is equivalent to minimizing an upper bound on the KL divergence between the student period distribution \(\mathcal{X}(f_s(x'))\) (or \(\mathbf{Q}_s\)) and a \emph{mixed} period distribution \(y'\) (or \(\mathbf{Q}_y + \lambda\,\mathbf{Q}_t\)). 
% \wei{we probably do not need (or need to rephrase) the following because it is not very related to the theorem (data augmentation); we need to describe the benefit from the data augmtantion perspective like you did for the above paragraph} This helps the model learn multi-period frequency patterns by incorporating the teacher’s period distribution, thereby identifying and modeling cyclic behaviors with overlapping or multiple periodicities.

% \begin{theorem}\label{thm:multiperiod}
% Optimizing the multi-period distillation loss $\mathcal{L}_{\text{period}}$ 
% is equivalent to minimizing an upper bound on the KL divergence between the student distribution \(\mathbf{Q}_s\) and a \emph{mixed} label distribution \(\alpha\,\mathbf{Q}_y + (1-\alpha)\,\mathbf{Q}_t\).
% Formally, for $\alpha \in [0,1]$, the following inequality holds:
% \[
% \begin{aligned}
% &\alpha\,\mathrm{KL}\bigl(\mathbf{Q}_y, \mathbf{Q}_s\bigr)
% \;+\;
% (1-\alpha)\,\mathrm{KL}\bigl(\mathbf{Q}_t, \mathbf{Q}_s\bigr)\\
% &\ge
% \mathrm{KL}\Bigl(\alpha\,\mathbf{Q}_y + (1-\alpha)\,\mathbf{Q}_t
% \;,\;\mathbf{Q}_s\Bigr).
% \end{aligned}
% \]
% \end{theorem}

% \wei{please number these benefits to enhance readability} These two theorems provide a theoretical understanding of multi-scale and multi-period distillation loss from a novel data augmentation perspective. The distillation process augments data by blending ground truth with teacher predictions, analogous to label smoothing in classification, and provides several benefits for time series forecasting. 
% It enhances generalization by exposing the student model to richer supervision signals, mitigating overfitting, especially with limited or noisy data, and 
% capturing trends or patterns not immediately apparent in the ground truth. 
% Furthermore, the softened targets from this blending reduce sensitivity to noise, stabilize training, and facilitate better convergence by ensuring smoother optimization dynamics.

% \wei{this paragraph is very important; please carefully rewrite; the goal is to highglight the novelty of this theoretical perspective and provide benefits of why our distillation framework can benefit the forecasting process} 

