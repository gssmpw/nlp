\section{Related Work}
\subsection{In-Context Learning}
GPT-3 ____ exhibited few-shot and zero-shot learning abilities during the pretraining phase.
CoT____ designed several fixed demonstration examples manually as in-context information, inspired further research on ICL____.

Subsequent research has shown that the key to ICL lies in demonstration examples selection and ordering____.
Regarding example selection, AutoCoT____ used k-means clustering to select representative examples and leveraged zero-shot CoT to generate their reasoning process as demonstration examples.
PromptSO____ used principal component analysis____ to encode text and calculate similarity to select examples.
Another work____ points out that a retriever can be trained using annotated data to determine whether an example is suitable for a query.
Regarding example ordering, a study____ randomly generated multiple combinations of example orderings to create probe sets.
By analyzing the entropy of predicted labels for each probe set, the researchers selected the best-performing order.
KATE____ explored ordering examples based on task relevance as well as length-based sorting.
Relevance-based ordering prioritizes examples closely related to the target task, while length-based sorting considers potential advantages for specific tasks.


\subsection{Curriculum Learning in LLMs}
Numerous applications across various fields have demonstrated that curriculum learning can effectively enhance model training outcome____.

Currently, some works have applied curriculum learning to LLMs____.
A common approach is to train the model with examples progressing from easy to hard during fine-tuning.
For instance, a study____ conducted fine-tuning on a structured dataset that strictly covers multiple educational stages to simulate the progressive learning characteristics of humans.
In the medical field, similarly, human-defined and automatically generated methods were used to annotate data difficulty, and LLMs in the medical question-answering domain were fine-tuned from easy to hard.____.
Additionally, another work____ decomposed datasets into sequences of varying lengths, using sequence length as a metric to measure data difficulty.

Another common approach for applying curriculum learning to LLMs is ICL.
For example, ICCL____ utilized human experts or LLM-driven metrics to assess data difficulty, and gradually increased the difficulty of demonstration examples from easy to hard.