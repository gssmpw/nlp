\begin{abstract}
    Our comprehension of video streams depicting human activities is naturally multifaceted: in just a few moments, we can grasp what is happening, identify the relevance and interactions of objects in the scene, and forecast what will happen soon, everything all at once. To endow autonomous systems with such a holistic perception, learning how to correlate concepts, abstract knowledge across diverse tasks, and leverage tasks synergies when learning novel skills is essential.
    A significant step in this direction is \ourscvpr, a unified framework for understanding human activities across diverse tasks with minimal overhead. \ourscvpr promotes information sharing and collaboration among downstream tasks, essential for efficiently learning new skills.
    In this paper, we introduce \ours, which advances \ourscvpr by enabling reasoning also across diverse temporal granularities, which expands its applicability to a broader range of downstream tasks.
    To achieve this, we propose a novel hierarchical architecture for temporal reasoning equipped with a GNN layer specifically designed to tackle the challenges of multi-granularity reasoning effectively.
    We evaluate our approach on multiple \egofourd benchmarks involving both clip-level and frame-level reasoning, demonstrating how our hierarchical unified architecture effectively solves these diverse tasks simultaneously.
    Project page: \href{https://sapeirone.github.io/hier-egopack/}{sapeirone.github.io/hier-egopack}.
\end{abstract}