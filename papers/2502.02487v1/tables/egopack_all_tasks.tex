\begin{table*}[tb]
  \centering
  \footnotesize
  \caption{\ours on \egofourd Human-Object Interaction (HOI) and Moment Queries (MQ) tasks.}\label{tab:main_results}
  \vspace{-0.25cm}
  \begin{tabularx}{1.0\textwidth}{Xcccccccc}
    \toprule

                                 & \multicolumn{2}{c}{\textbf{AR}} & \multicolumn{1}{c}{\textbf{OSCC}} & \multicolumn{2}{c}{\textbf{LTA}} & \multicolumn{1}{c}{\textbf{PNR}} & \multicolumn{1}{c}{\textbf{MQ}}                                                         \\
    \cmidrule(lr){2-8}

                                 & \textbf{Verbs Top-1 (\%)}       & \textbf{Nouns Top-1 (\%)}         & \textbf{Acc. (\%)}               & \textbf{Verbs ED ($\downarrow$)} & \textbf{Nouns ED ($\downarrow$)} & \textbf{Loc. Err. ($\downarrow$)} & \textbf{mAP}     \\

    \midrule

    Ego4D Baselines~\cite{ego4d} & 22.18                           & 21.55                             & 68.22                            & 0.746                            & 0.789                            & \underline{0.62}                  & 6.03             \\
    EgoT2s~\cite{egot2}          & 23.04                           & 23.28                             & 72.69                            & 0.731                            & 0.769                            & \textbf{0.61}                     & N/A              \\

    %\midrule
    \ourscvpr~\cite{egopack}     & 25.10                           & 31.10                             & 71.83                            & 0.728                            & 0.752                            & \textbf{0.61}                     & N/A              \\

    \midrule
    \midrule

    Single Task                  & \underline{26.93}               & 33.50                             & 75.22                            & \underline{0.728}                & 0.752                            & \underline{0.62}                  & 20.2             \\
    MTL                          & 26.31                           & \underline{33.90}                 & 74.79                            & 0.730                            & 0.754                            & \underline{0.62}                  & 18.5             \\
    MTL + FT                     & 26.71                           & 33.51                             & 75.00                            & 0.728                            & 0.749                            & \textbf{0.61}                     & 19.9             \\
    MTL + HT                     & 26.07                           & 33.20                             & 74.27                            & 0.729                            & 0.748                            & \underline{0.62}                  & N/A              \\
    \midrule
    Task-Translation$^\dagger$   & 26.10                           & 33.83                             & \textbf{76.42}                   & 0.729                            & \underline{0.750}                & 0.63                              & \underline{20.5} \\
    \textbf{\ours}               & \textbf{27.30}                  & \textbf{34.65}                    & \underline{75.60}                & \textbf{0.725}                   & \textbf{0.741}                   & \textbf{0.61}                     & \textbf{21.0}    \\

    \bottomrule
  \end{tabularx}
  \begin{tablenotes}
    \scriptsize
    \item \emph{Single Task} uses the same hierarchical GNN-based architecture to model all tasks, with minimal task-specific differences. \emph{Multi-Task Learning (MTL)} uses hard parameter sharing to jointly learn all tasks, which may result in negative transfers. \emph{Ego-T2s}~\cite{egot2} learns to translate features across tasks to optimize the primary task. \emph{\ours} builds on the unified architecture of the Temporal Graph and learns to exploit the perspective of different tasks for efficient knowledge transfer to the novel task. Performances of \ours are evaluated over three runs with different random seeds using accuracy for AR and OSCC, Edit Distance for LTA, temporal localization error (in seconds) for PNR and mAP for MQ. $^\dagger$\emph{Task-Translation} implements the same cross-task translation mechanism of EgoT2s~\cite{egot2} using a frozen EgoVLP backbone, as for \ours. Best results are reported in bold, second best are underlined.
  \end{tablenotes}
  \vspace{-3mm}
\end{table*}