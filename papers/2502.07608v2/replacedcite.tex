\section{Related Work}
\subsection{Model Reprogramming}

Model reprogramming is a training paradigm that efficiently repurposes a pre-trained, frozen large model across domains using an input transformation layer and an output mapping layer ____. ____ reprogrammed a speech model for univariate time series classification, while ____ proposed an adversarial approach to convert an image model for protein sequence prediction. Similarly, ____ focused on mapping a text model to biochemical sequences. From a reprogramming perspective, our work introduces several key advancements. It demonstrates that a TFM and an LLM can be effectively integrated for health-related tasks. Unlike most prior work, we adopt a self-supervised learning (SSL) framework instead of supervised learning. Additionally, our approach explicitly incorporates periodicity properties, further enhancing time-series understanding.

% \subsection{Mental Health and Behavioral Sensing}

% Recent studies have leveraged diverse sensing data from mobile phones and wearables to detect mental health conditions such as depression and anxiety ____. For instance, ____ evaluated multiple machine learning algorithms for depression detection across various datasets, utilizing behavioral features such as sleep patterns, location, and physical activity. Beyond mental health conditions, passive sensing has also been applied to understand behavioral traits such as personality and detect rare life events ____. For example, ____ proposed an autoencoder-based approach to identify anomalous life events using multivariate sensing. These studies demonstrate substantial progress in passive sensing for mental health and behavioral analysis.

\subsection{LLMs and Healthcare}
Using LLMs to evaluate health outcomes has seen rapid growth ____. For instance, MedPaLM 2 ____, an LLM fine-tuned for medical question answering has demonstrated strong performance by passing medical exam benchmarks. Similarly, models such as MedAlpaca ____ and Me-LLaMA ____ also fine-tune general-purpose LLMs for comprehensive analysis of medical texts. For mental health tasks, ____ comprehensively evaluated different LLMs using online text data. Their work demonstrated that incorporating additional health context information in prompts enhances performance, but specialized domain knowledge is required.

\subsection{LLMs and Sensor Data}

Health sensing data consists of temporal numeric values that change over time. Approaches for time-series forecasting with LLMs involved converting the raw data into text prompts, as demonstrated by methods like LLMTime ____ and PromptCast ____. For instance, ____ highlighted the importance of careful pre-processing, such as handling periods (“.”) and spaces (“ ”), to ensure effective tokenization of floating-point numbers.  Recently, alternative approaches have used multi-modal LLMs that encode sensing data as images ____ or use modality-specific encoders ____. For example, ____ proposed transforming time-series data into visual prompts for use with vision-language models. 

% Health sensing data represents temporal numeric data that indicates change in value over time. Initially, converting time-series to text prompts for forecasting has been proposed in methods such as LLMTime ____ and PromptCast ____. For example, ____ showcase careful pre-processing of periods (``.") and spaces (`` ") is essential for effective tokenization of floating point numbers. Recently, other approaches have used multi-modal LLMs that encode sensing data as images ____ or using modality-specific encoders ____. For example, ____ transforms time series into visual prompts to probe a vision-language model. Nevertheless, the most common approach for health sensing incorporates raw sensor data as text strings into prompts without pre-processing ____.

\begin{figure}
    \centering
    \subfigure[]{\includegraphics[width=0.24\textwidth]{images/mean_prediction.pdf}} 
    \subfigure[]{\includegraphics[width=0.24\textwidth]{images/token_length.pdf}} 
    \caption{\textbf{Effect of Increasing Sequence Length on Prompting Performance.} We evaluate LLaMA 3.2 (1B) on: (a) a mean prediction task, where mean absolute error increases with sequence length, and (b) tokens, where the number of tokens is $\sim 10\times$ the time-series length.} 
    \label{fig:limitations}
\end{figure}

\subsection{Limitations of integrating mobile sensing with LLMs} \label{sec:limitations}


\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{images/SensorBridge.pdf}
    \caption{\textbf{Time2Lang Framework.} To meaningfully integrate Timeseries Foundation Models  (here: Chronos $C$) and Large Language Models (LLaMA $M$), we train two smaller networks $f$ and $g$ that optimally map TFM features ($\mathbf{z^c}$) to an LLM. The learned embeddings from $f$ and $g$ are $\mathbf{z^i}$ and $\mathbf{z^o}$, respectively. To improve positive knowledge transfer, we use a residual connection between the TFM and LLM features ($\mathbf{z^c} \rightarrow \mathbf{z^m}$) only during training.}
    \label{fig:Time2Lang}
\end{figure*}

Despite advances for integrating sensor data into LLMs, the most common approach remains incorporating the raw sensor data as text strings into prompts without extensive pre-processing ____. While this technique has shown promise for aggregated short-duration time series (e.g., $<$ 200 time steps), behavioral sensing data often has long duration sequences. For example, one day of data in one minute intervals consists of 1440 data points. Sampling rates $>1$Hz will have substantially more data points. Therefore, representing sensor data as text has the following limitations. First, an LLM performance decreases with longer duration sequences ____. To empirically demonstrate this using LLaMA 3.2 ____, we perform a mean prediction task using synthetic data, where LLaMA is asked to predict the mean with increasing sequence length. In Figure \ref{fig:limitations}, we notice that the mean absolute error (MAE) increases with increasing sequence length. Second, long duration sequences require significantly more tokens, which may quickly exhaust the models limits. Specifically, observe that the number of tokens required for LLaMA 3.2 is $\sim 10\times$ the length of the time series (Figure \ref{fig:limitations}). Third, effective prompting is challenging and requires strong domain knowledge (adding specific knowledge improves prompting performance -- Table \ref{tab:overall_performance} LLaMA-ICL vs LLaMA-ICL-DK), remaining an active research area in NLP ____.

Our approach offers an alternative perspective for addressing these limitations with mental health as an application. By learning a mapping that seamlessly integrates a TFM into the LLM workflow, \textit{Time2Lang inputs fixed-size embeddings directly into the LLM, eliminating the need for prompting}. We show that the Time2Lang framework is more scalable and efficient compared to generative LLM prompting, while preserving the performance of the TFM.