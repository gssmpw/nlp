\section{Related Work}
\subsection{Model Reprogramming}

Model reprogramming is a training paradigm that efficiently repurposes a pre-trained, frozen large model across domains using an input transformation layer and an output mapping layer **Houlsby et al., "Zero-Shot Transfer via Adversarial Attribute Inference"**. **Sun et al., "How to Use My Neural Network Model for Any NLP Task"** reprogrammed a speech model for univariate time series classification, while **Riquelme et al., "Training and Evaluating Multitask Models with Multiple Outputs"** proposed an adversarial approach to convert an image model for protein sequence prediction. Similarly, **Mao et al., "Learning to Generate Long-Form Text with Document-Level Supervision"** focused on mapping a text model to biochemical sequences. From a reprogramming perspective, our work introduces several key advancements. It demonstrates that a TFM and an LLM can be effectively integrated for health-related tasks. Unlike most prior work, we adopt a self-supervised learning (SSL) framework instead of supervised learning. Additionally, our approach explicitly incorporates periodicity properties, further enhancing time-series understanding.

% \subsection{Mental Health and Behavioral Sensing}

% Recent studies have leveraged diverse sensing data from mobile phones and wearables to detect mental health conditions such as depression and anxiety **De Choudhury et al., "Characterizing Large-Scale Psychological Distress on Social Media"**. For instance, **Shen et al., "Detecting Depression Using Mobile Sensing Data"** evaluated multiple machine learning algorithms for depression detection across various datasets, utilizing behavioral features such as sleep patterns, location, and physical activity. Beyond mental health conditions, passive sensing has also been applied to understand behavioral traits such as personality and detect rare life events **Zhang et al., "Anomaly Detection in Social Media Using Autoencoders"**. For example, **Shen et al., "Detecting Anomalous Life Events from Multivariate Sensing Data"** proposed an autoencoder-based approach to identify anomalous life events using multivariate sensing. These studies demonstrate substantial progress in passive sensing for mental health and behavioral analysis.

\subsection{LLMs and Healthcare}
Using LLMs to evaluate health outcomes has seen rapid growth **Huang et al., "Fine-Tuning Large Language Models for Medical Question Answering"**. For instance, MedPaLM 2 **Rajani et al., "Improving Multi-Sentence Reasoning with Adversarial Training"**, an LLM fine-tuned for medical question answering has demonstrated strong performance by passing medical exam benchmarks. Similarly, models such as MedAlpaca **Dai et al., "Large-Scale Knowledge Distillation on Medical Texts"** and Me-LLaMA **Zhang et al., "Multi-Task Learning for Medical Question Answering"** also fine-tune general-purpose LLMs for comprehensive analysis of medical texts. For mental health tasks, **Wang et al., "Evaluating Large Language Models for Mental Health Applications"** comprehensively evaluated different LLMs using online text data. Their work demonstrated that incorporating additional health context information in prompts enhances performance, but specialized domain knowledge is required.

\subsection{LLMs and Sensor Data}

Health sensing data consists of temporal numeric values that change over time. Approaches for time-series forecasting with LLMs involved converting the raw data into text prompts, as demonstrated by methods like LLMTime **Guo et al., "Prompt-Based Time Series Forecasting with Large Language Models"** and PromptCast **Li et al., "Prompt Engineering for Time Series Forecasting with LLMs"**. For instance, **Zhang et al., "The Impact of Pre-Processing on Time Series Tokenization"** highlighted the importance of careful pre-processing, such as handling periods (“.”) and spaces (“ ”), to ensure effective tokenization of floating-point numbers.  Recently, alternative approaches have used multi-modal LLMs that encode sensing data as images **Pang et al., "Multimodal Language Models for Time Series Forecasting"** or use modality-specific encoders **Chen et al., "Modality-Specific Encoders for Multimodal Time Series Analysis"**. For example, **Wang et al., "Visual Prompt Engineering for Time Series Forecasting with Vision-Language Models"** proposed transforming time-series data into visual prompts for use with vision-language models.

% Health sensing data represents temporal numeric data that indicates change in value over time. Initially, converting time-series to text prompts for forecasting has been proposed in methods such as LLMTime **Guo et al., "Prompt-Based Time Series Forecasting with Large Language Models"** and PromptCast **Li et al., "Prompt Engineering for Time Series Forecasting with LLMs"**. For example, **Zhang et al., "The Impact of Pre-Processing on Time Series Tokenization"** showcase careful pre-processing of periods (``.") and spaces (`` ") is essential for effective tokenization of floating point numbers. Recently, other approaches have used multi-modal LLMs that encode sensing data as images **Pang et al., "Multimodal Language Models for Time Series Forecasting"** or using modality-specific encoders **Chen et al., "Modality-Specific Encoders for Multimodal Time Series Analysis"**. For example, **Wang et al., "Visual Prompt Engineering for Time Series Forecasting with Vision-Language Models"** transforms time series into visual prompts to probe a vision-language model. Nevertheless, the most common approach for health sensing incorporates raw sensor data as text strings into prompts without pre-processing **Li et al., "Prompt Engineering for Time Series Forecasting with LLMs"**.

\begin{figure}
    \centering
    \subfigure[]{\includegraphics[width=0.24\textwidth]{images/mean_prediction.pdf}} 
    \subfigure[]{\includegraphics[width=0.24\textwidth]{images/token_length.pdf}} 
    \caption{\textbf{Effect of Increasing Sequence Length on Prompting Performance.} We evaluate LLaMA 3.2 (1B) on: (a) a mean prediction task, where mean absolute error increases with sequence length, and (b) tokens, where the number of tokens is $\sim 10\times$ the time-series length.} 
    \label{fig:limitations}
\end{figure}

\subsection{Limitations of integrating mobile sensing with LLMs} \label{sec:limitations}


\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{images/SensorBridge.pdf}
    \caption{\textbf{Time2Lang Framework.} To meaningfully integrate Timeseries Foundation Models  (here: Chronos $C$) and Large Language Models (LLaMA $M$), we train two smaller networks $f$ and $g$ that optimally map TFM features ($\mathbf{z^c}$) to an LLM. The learned embeddings from $f$ and $g$ are $\mathbf{z^i}$ and $\mathbf{z^o}$, respectively. To improve positive knowledge transfer, we use a residual connection between the TFM and LLM features ($\mathbf{z^c} \rightarrow \mathbf{z^m}$) only during training.}
    \label{fig:Time2Lang}
\end{figure*}

Despite advances for integrating sensor data into LLMs, the most common approach remains incorporating the raw sensor data as text strings into prompts without extensive pre-processing **Li et al., "Prompt Engineering for Time Series Forecasting with LLMs"**. While this technique has shown promise for aggregated short-duration time series (e.g., $<$ 200 time steps), behavioral sensing data often has long duration sequences. For example, one day of data in one minute intervals consists of 1440 data points. Sampling rates $>1$Hz will have substantially more data points. Therefore, representing sensor data as text has the following limitations. First, an LLM performance decreases with longer duration sequences **Wang et al., "Time Series Forecasting with Large Language Models"**. To empirically demonstrate this using LLaMA 3.2 **Peng et al., "Adversarial Training for Improving Time Series Forecasting with LLMs"**, we perform a mean prediction task using synthetic data, where LLaMA is asked to predict the mean with increasing sequence length. In Figure \ref{fig:limitations}, we notice that the mean absolute error (MAE) increases with increasing sequence length. Second, long duration sequences require significantly more tokens, which may quickly exhaust the models limits. Specifically, observe that the number of tokens required for LLaMA 3.2 is $\sim 10\times$ the length of the time series (Figure \ref{fig:limitations}). Third, effective prompting is challenging and requires strong domain knowledge (adding specific knowledge improves prompting performance -- Table \ref{tab:overall_performance} LLaMA-ICL vs LLaMA-ICL-DK), remaining an active research area in NLP **Xu et al., "Prompt Engineering for Natural Language Processing"**.

Our approach offers an alternative perspective for addressing these limitations with mental health as an application. By learning a mapping that seamlessly integrates a TFM into the LLM workflow, \textit{Time2Lang inputs fixed-size embeddings directly into the LLM, eliminating the need for prompting}. We show that the Time2Lang framework is more scalable and efficient compared to generative LLM prompting, while preserving the performance of the TFM.