\begin{algorithm}
    \caption{$\sdm$ Activation Layer and $\sdm$ Estimator Training}
    \label{alg:sdm-estimator-training}
    \small
    \begin{algorithmic}[1] 
        \Require $\trainSplit$, $\calibrationSplit$, $\alpha'$, $\underlyingNetwork$, $\text{max epochs}$, $\text{rescaler max epochs}$, $\text{rescaler stopping condition}$ %
        \State \textbf{Assumption:} $\trainSplit$, $\calibrationSplit$ are balanced across all class labels, $c \in \gY$
        \Procedure{sdm-iterative-train}{$\trainSplit$, $\calibrationSplit$, $\alpha'$, $\underlyingNetwork$, $\text{max epochs}$}
        \State $\gM_{*} \gets \emptyset$ \Comment{Globally best model}
        \State $\trainSplit_{*} \gets \emptyset$, $\calibrationSplit_{*} \gets \emptyset$  \Comment{Data splits of best model}
        \State $\gE \gets \emptyset$  \Comment{$\sdm$ estimator (i.e., $\pLower$)}
        \State ${\rm{metric}}_{*} \gets 0$ \Comment{Determines final best model}
        \State ${\rm{stats}} \gets \{~\}$ \Comment{Summary statistics to calculate $\CauchyMinValidQBin, \CauchyMagnitudeIteratedLowerEstimate$ (\S~\ref{sec:iterative-uncertainty})}
        \For{$j \in 1, \ldots, J$} \Comment{The learning process is repeated $J$ times}
		\State $\gM_{j*} = \emptyset$ \Comment{Best model for a single learning round}
		\State $\rm{metric}_j \gets 0$
		\State $\trainSplit$, $\calibrationSplit \gets$ Random shuffle and even split of $\trainSplit$ and $\calibrationSplit$
		\State $\gM_j \gets $ Random initialization of $\mG_j, \mW'_j, \vb'_j$
		\State $\q \gets e-2, d \gets 1$ \Comment{Standard $\softmax$ for first epoch}
		 \For{$e \in 1, \ldots, \text{max epochs}$}
		 	\State Minimize $\gL(\mG, \mW', \vb'; \trainSplit)$ \Comment{Eq.~\ref{eq:sdm-loss}}
			\State Update $q,d$ for each $\vx \in \trainSplit$
			\State $\rm{metric} \gets$ mean balanced (across $c \in \gY$) median $\q$ over $\calibrationSplit$
          	 	\If{$\rm{metric} \ge \rm{metric}_j$}
           			\State $\rm{metric}_j \gets \rm{metric}$
				\State $\gM_{j*} \gets \gM_j$
           		\EndIf
		        \If{$\rm{metric}_j \ge {\rm{metric}}_{*}$}
           			\State ${\rm{metric}}_{*} \gets \rm{metric}_j$
				\State $\gM_{*} \gets \gM_{j*}$
				\State $\trainSplit_{*}, \calibrationSplit_{*} \gets \trainSplit, \calibrationSplit$ \Comment{Data splits for calculating $q,d$ at test-time \& model checks}
           		\EndIf
		 \EndFor
		 \State $\gM_{j*} \gets$ update with $\mW^{''}$ from \Call{train-rescaler}{$\cdot$} \Comment{ Alg.~\ref{alg:train-rescaler}}
		 \State ${\rm{stats}} \gets$ update with \Call{find-min-rescaled-q}{$\cdot$} \Comment{ Alg.~\ref{alg:estimate-soft-q-bin}}
        \EndFor
        \State $\gE \gets $ Constructed from globally best model $\gM_{*}$ (and associated values, e.g., $\minValidQBin_*$) and ${\rm{stats}}$
        \State \textbf{return} $\gM_{*}, \trainSplit_{*}, \calibrationSplit_{*}, \gE$
        \EndProcedure
        \Ensure $\gM_{*}, \trainSplit_{*}, \calibrationSplit_{*}, \gE$ 
    \end{algorithmic}
\end{algorithm}