% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage[dvipsnames]{xcolor}
% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{hyperref}
\usepackage{url}
\newcommand{\explain}[2]{\underbrace{#1}_{{\footnotesize\raggedright #2}}}

% for text examples
\newcommand{\delete}[1]{\{\textit{\sout{#1}}\}}
\usepackage[most]{tcolorbox}
\newcommand{\sdelete}[1]{\textit{\sout{#1}}}
\colorlet{lightSalmon}{Salmon!80}
\newcommand{\colorize}[2]{\colorbox{lightSalmon!#1!white}{\strut #2}}

% for figures
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{wrapfig}

% for equation
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{bm}

\usepackage{bbm}
% for table
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}
\usepackage{caption}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}
\usepackage{caption}
\usepackage{color}
\usepackage{colortbl}
\usepackage{tablefootnote}
\usepackage{adjustbox}
\newcommand{\cred}[1]{\textcolor{red}{$_{#1}$}}

% for algorithm
\usepackage{caption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\mycolor}[1]{\textcolor[RGB]{64,101,149}{#1}}
\newcommand{\mydarkcolor}[1]{\textcolor[RGB]{64,101,149}{#1}}
\algnewcommand{\LineComment}[1]{\Statex ~~~~~~\textsc{//}~\textit{#1}}

%for itemize
\usepackage{enumitem}
\setenumerate[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}

% for highlight
\usepackage{soul}

% for taxonomy
\usepackage{tikz}
\usepackage[edges]{forest}
\definecolor{hidden-draw}{RGB}{64,101,149}
% \definecolor{hidden-pink}{RGB}{255,245,247}
\definecolor{hidden-pink}{RGB}{231,239,250}

% for notation
\usepackage[mathscr]{euscript}
\newcommand{\M}{\mathcal{M}}

%for itemize
\usepackage{amssymb}  
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\newcommand{\greenyes}{\textcolor{green}{\ding{51}}}
\newcommand{\redno}{\textcolor{red}{\ding{55}}}

% for title
\usepackage{xspace}

\newcommand{\method}{\texttt{TokenSkip}\xspace}

%% === commands for comments ===
\usepackage{ulem}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{
\texorpdfstring{\includegraphics[width=18pt]{fig/arrow.png}}{}
\method: Controllable Chain-of-Thought Compression in LLMs
}

\author{{Heming Xia}\textsuperscript{\rm 1}, {\textbf{Yongqi Li}}\textsuperscript{\rm 1}\thanks{Corresponding Author}, {\textbf{Chak Tou Leong}}\textsuperscript{\rm 1}, {\textbf{Wenjie Wang}}\textsuperscript{\rm 2}, {\textbf{Wenjie Li}}\textsuperscript{\rm 1}\\
  \textsuperscript{\rm 1}Department of Computing, The Hong Kong Polytechnic University \\
  \textsuperscript{\rm 2}University of Science and Technology of China \\
  {\tt \{he-ming.xia, chak-tou.leong\}@connect.polyu.hk}
}

\begin{document}
\maketitle
\begin{abstract}
Chain-of-Thought (CoT) has been proven effective in enhancing the reasoning capabilities of large language models (LLMs). Recent advancements, such as OpenAI's o1 and DeepSeek-R1, suggest that scaling up the length of CoT sequences during inference could further boost LLM reasoning performance. However, due to the autoregressive nature of LLM decoding, longer CoT outputs lead to a linear increase in inference latency, adversely affecting user experience, particularly when the CoT exceeds 10,000 tokens. To address this limitation, we analyze the semantic importance of tokens within CoT outputs and reveal that their contributions to reasoning vary. Building on this insight, we propose \method, a simple yet effective approach that enables LLMs to selectively skip less important tokens, allowing for controllable CoT compression. Extensive experiments across various models and tasks demonstrate the effectiveness of \method in reducing CoT token usage while preserving strong reasoning performance. Notably, when applied to Qwen2.5-14B-Instruct, \method reduces reasoning tokens by $40\%$ (from 313 to 181) on GSM8K, with less than a $0.4\%$ performance drop. We release our code and checkpoints in \url{https://github.com/hemingkx/TokenSkip}.
\end{abstract}

\input{Sections/1-Introduction}
\input{Sections/2-Preliminaries}
\input{Sections/3-Methodology}
\input{Sections/4-Experiments}
\input{Sections/5-Analysis}
\input{Sections/6-RelatedWork}
\input{Sections/7-Conclusion}
\input{Sections/8-Limitations}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\clearpage

\appendix

\section*{Appendix}
\input{Appendix/A-Recovery}
\input{Appendix/B-Experimental_Details}

\end{document}
