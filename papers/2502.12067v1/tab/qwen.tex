\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{1.4mm}
%\resizebox{\linewidth}{!}{
\begin{tabular}{@{}llcrrc@{}}
\toprule
\textbf{Scale} &\textbf{Methods} &\textbf{Ratio} &Accuracy &Tokens &\textit{Act}Ratio \\ \midrule
\multirow{7}{*}{\texttt{3B}} & \texttt{Original}  & - & 83.7\cred{(0.0 \downarrow)} &314.87 &- \\ \cmidrule{2-6}
&\multirow{6}{*}{\method}  &1.0 & 83.4\cred{(0.3 \downarrow)} &318.79 & 1.00  \\
& &0.9 & 83.2\cred{(0.5 \downarrow)} &262.99 & 0.83\\
& &0.8 & 81.6\cred{(2.1 \downarrow)} &250.71 & 0.79\\
& &0.7 & 80.1\cred{(3.6 \downarrow)} &233.03 & 0.73\\
& &0.6 & 77.3\cred{(6.4 \downarrow)} &199.55 & 0.63\\
& &0.5 & 74.4\cred{(9.3 \downarrow)} &170.55 & 0.54 \\\midrule
\multirow{7}{*}{\texttt{7B}} & \texttt{Original}  & - & 91.4\cred{(0.0 \downarrow)} &297.83 &- \\ \cmidrule{2-6}
&\multirow{6}{*}{\method}  &1.0 & 91.7\cred{(0.3 \uparrow)} &295.78 & 1.00  \\
& &0.9 & 91.1\cred{(0.3 \downarrow)} &254.77 & 0.86\\
& &0.8 & 90.1\cred{(1.3 \downarrow)} &237.27 & 0.80\\
& &0.7 & 89.9\cred{(1.5 \downarrow)} &216.73 & 0.73\\
& &0.6 & 87.9\cred{(3.5 \downarrow)} &178.07 & 0.60\\
& &0.5 & 86.0\cred{(5.4 \downarrow)} &151.44 & 0.51 \\\midrule
\multirow{7}{*}{\texttt{14B}} & \texttt{Original}  & - & 93.1\cred{(0.0 \downarrow)} &313.11 &- \\ \cmidrule{2-6}
&\multirow{6}{*}{\method}  &1.0 & 93.0\cred{(0.1 \downarrow)} &314.55 & 1.00  \\
& &0.9 & 93.3\cred{(0.2 \uparrow)} &269.22 & 0.86\\
& &0.8 & 93.2\cred{(0.1 \uparrow)} &247.24 & 0.79\\
& &0.7 & 93.4\cred{(0.3 \uparrow)} &218.62 & 0.70\\
& &0.6 & 92.7\cred{(0.4 \downarrow)} &180.68 & 0.57\\
& &0.5 & 91.4\cred{(1.7 \downarrow)} &156.85 & 0.50 \\
\bottomrule
\end{tabular}%}
\caption{Experimental results on the Qwen2.5-Instruct series. We report accuracy, average CoT token count, and actual compression ratio (\textit{Act}Ratio) for comparison.}
\label{tab:qwen}
\end{table}