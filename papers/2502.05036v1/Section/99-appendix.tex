% \section{Framework Details}
% Our framework is described in Algorithm~\ref{algorithm}, and compared with former baselines in Table~\ref{table:comparison}. Distinct with several methods generating Python code for visualization directly, we use VQL as an intermediate representation to bridge natural language queries and visualization code. Additionally, our framework can be easily optimized by adding some useful tools such as Retrieval Augmented Generation. Moreover, our method supports handling multi-table data and the visualization can be customized according to humans' preferences. Our framework utilizes the agent-based collaborative workflow, which consists of data preprocessing, generation, and error correction, organized with the modular design.

% \begin{algorithm}
% \small
% \caption{\system Framework}
% \label{algorithm}
% \begin{algorithmic}[1]
% \Function{\nlvis}{$Q$, $S$}
%     \State Initialize $Mem \gets \{Q,S\}$
%     \State $(S', A) \gets \textsc{Processor}(Mem)$
%     \State $Mem.update(S', A)$
%     \State $V \gets \textsc{Composer}(Mem)$
%     \State $Mem.update(V)$
%     \State $Chart, isValid \gets \textsc{Validator}(Mem)$
%     \While{not $isValid$}
%         \State $V \gets \textsc{Refine}(Mem)$
%         \State $Mem.update(V)$
%         \State $Chart, isValid \gets \textsc{Validator}(Mem)$
%     \EndWhile
%     \State \Return $Chart$
% \EndFunction
% \end{algorithmic}

% \end{algorithm}




% \begin{table*}[!t]
%     \centering
    
%     \vspace{-1em}
%     \scalebox{0.68}{
%     \begin{tabular}{lccccccc}
%         \toprule[1.5pt]
%         \multirow{3}{*}{\textbf{Framework}} & \multicolumn{2}{c}{\textbf{System Features}} & \multicolumn{2}{c}{\textbf{Visualization Capabilities}} & \multicolumn{3}{c}{\textbf{Agentic Workflow}} \\
%         \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-8}
%         & \textbf{VQL as} & \textbf{Extensible} & \textbf{Multi-Table} & \textbf{Customizable} & \textbf{Data} & \textbf{Modular} & \textbf{Error-} \\
%         & \textbf{Thoughts} & \textbf{Optimization} & \textbf{Support} & \textbf{Styling} & \textbf{Preprocess} & \textbf{Design} & \textbf{Correction} \\
%         \midrule
%         Chat2VIS~\cite{chat2vis} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} \\
%         Mirror~\cite{mirror} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} \\
        
%         LIDA~\cite{lida} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} \\
%         CoML4VIS~\cite{coml} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} \\
        
%         Prompt4VIS~\cite{prompt4vis} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} \\
        
%         CoT-Vis~\cite{cotvis} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{red}{\ding{56}} & \textcolor{red}{\ding{56}} \\

%         \midrule
%         \SystemName (Ours) & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} & \textcolor{green!60!black}{\ding{52}} \\
%         \bottomrule[1.5pt]
%     \end{tabular}}
% \caption{Comparison of various \nlvis frameworks. }  \label{table:comparison}
% \vspace{-1em}
% \end{table*}

\section{Detailed Experiment Setups}
\label{detailed_experiment_setups}
\paragraph{Baselines.}
\label{detailed_baselines}
% We implemented our experiment compared with three recent baselines. Note that, we also tried to use Code Interpreter as a baseline, but due to the rate limit of API constraint, the evaluation failed to generate visualizations via direct .csv files.
This study compares our approach with three state-of-the-art baselines. We also attempted to include Code Interpreter as a baseline; however, API rate limitations prevent the direct generation of visualizations from CSV files.

\begin{itemize}[leftmargin=*, itemsep=0pt] 
    \item \textbf{Chat2Vis} \cite{chat2vis}: It generates data visualizations by leveraging prompt engineering to translate natural language descriptions into visualizations. It uses a language-based table description, which includes column types and sample values, to inform the visualization generation process.\item \textbf{LIDA} \cite{lida}: It structures visualization generation as a four-step process, where each step builds on the previous one to incrementally translate natural language inputs into visualizations. It uses a JSON format to describe column statistics and samples, making it adaptable across various visualization tasks.
    \item \textbf{CoML4Vis} \cite{coml}: 
    % Building on a data science code generation framework, CoML4Vis 
    It utilizes a few-shot prompt that integrates multiple tables into a single visualization task. It summarizes data table information, including column names and samples, and then applies a few-shot prompt to guide visualization generation.
\end{itemize}

\paragraph{Metrics.}
\label{detailed_metrics}
Our evaluation framework involves five main metrics:
\begin{itemize}[leftmargin=*, itemsep=0pt] 
    \item \textbf{Invalid Rate} represents the percentage of visualizations that fail to render due to issues like incorrect API usage or other code errors.
    \item \textbf{Illegal Rate} indicates the percentage of visualizations that do not meet query requirements, which can include incorrect data transformations, mismatched chart types, or improper visualizations.
    \item \textbf{Readability Score} is the average score (range 1-5) assigned by a vision language model, like GPT-4V, for valid and legal visualizations, assessing their visual clarity and ease of interpretation.
    \item \textbf{Pass Rate} measures the proportion of visualizations in the evaluation set that are both valid (able to render) and legal (meet the query requirements).
    \item \textbf{Quality Score} is set to 0 for invalid or illegal visualizations; otherwise, it is equal to the readability score, providing an overall assessment of visualization quality factoring in both functionality and clarity.
\end{itemize}
To thoroughly evaluate each main metric, we further break them down into the following detailed assessment criteria:
\begin{itemize}[leftmargin=4mm, itemsep=0.05mm] 
    \item \textbf{Code Execution Check} verifies that the Python code generated by the model can be successfully executed.
    \item \textbf{Surface-form Check} ensures that the generated code includes necessary elements to produce a visualization like function calls to display the chart.
    \item \textbf{Chart Type Check} verifies whether the extracted chart type from the visualization matches the ground truth.
    \item \textbf{Data Check} assesses if the data used in the visualization matches the ground truth, taking into consideration potential channel swaps based on specified channels.
    \item \textbf{Order Check} evaluates whether the sorting of visual elements follows the specified query requirements.
    \item \textbf{Layout Check} examines issues like text overflow or element overlap within visualizations.
    \item \textbf{Scale \& Ticks Check} ensures that scales and ticks are appropriately chosen, avoiding unconventional representations.
    \item \textbf{Overall Readability Rating} integrates various readability checks to provide a comprehensive score considering layout, scale, text clarity, and arrangement.
\end{itemize}

% For all evaluation results, these metrics are averaged across the dataset to provide an overarching view of model performance. These metrics collectively ensure that visualizations are not only correct in terms of execution but also effective in communicating the intended data narratives.
The evaluation metrics are averaged across the dataset to provide a comprehensive overview of the model's performance. Together, these metrics ensure that the visualizations are both accurate in execution and effective in conveying the intended data narratives.



\begin{table}[!t]
\centering
\setlength{\belowcaptionskip}{0em} 
% \vspace{-1em}
\begin{tabular}{lcc}
\toprule[1.5pt]
\textbf{Model} & \textbf{P-corr} & \textbf{P-value} \\
\midrule
GPT-4o-mini & \textbf{0.6503} & 0.000 \\
GPT-4o & 0.5648 & 0.000 \\
\bottomrule[1.5pt]
\end{tabular}
\caption{ The Pearson correlations of GPT-4o-mini and GPT-4o with human judgments on readability scores. }
\label{tab:pearson_corr}
\vspace{-1em}
\end{table}

\begin{table*}[!ht]
\centering

\vspace{-1em}
\begin{tabular}{l|ccc|ccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c|}{Single Table} & \multicolumn{3}{c}{Multiple Tables} \\
\cmidrule(l){2-4} \cmidrule(l){5-7}
 & prompt & response & total & prompt & response & total \\
\midrule
LIDA & 1386.23 & 237.90 & 1624.13 & \multicolumn{3}{c}{N/A} \\
Chat2Vis & 414.35 & 451.30 & 865.65 & \multicolumn{3}{c}{N/A} \\
CoML4Vis & 2614.76 & 279.86 & 2894.62 & 3069.62 & 307.67 & 3377.29 \\
\system & 5122.99 & 777.63 & 5900.62 & 5613.96 & 1014.10 & 6628.06 \\
\bottomrule
\end{tabular}
\caption{Token usage comparison for different methods. N/A indicates that LIDA and Chat2Vis cannot handle multiple table scenarios.}
\label{tab:token_usage}
\end{table*}

\begin{table}[ht]
\centering
\scalebox{1}{
\begin{tabular}{l|ccc}
\toprule
Agent & \#Input & \#Output & \#Total \\
\midrule
Processor & 1486.07 & 569.58 & 1755.65\\
Composer & 3268.32 & 221.74 & 3490.07 \\
Validator & 1051.82 & 127.85 & 1179.67  \\
\bottomrule
\end{tabular}}
\caption{Token usage of three agents in \system.} \label{tab:token_agent} 
\vspace{-1em}
\end{table}

\paragraph{Implement Details.}
Our system is implemented in Python 3.9, utilizing GPT-4o \citep{openai_gpt4o_2024}, GPT-4o-mini~\cite{openai2024gpt4omini}, and GPT-3.5-turbo~\cite{chatgpt3.5} as the backbone model for all approaches, with the temperature set to 0 for consistent outputs. GPT-4o-mini serves as the vision language model for readability evaluation. We interact with these models through the Azure OpenAI API. The specific prompt templates for each agent, crucial for guiding their respective roles in the visualization generation process, are detailed in Appendix~\ref{prompt_details}. Token usages of \system and baselines are demonstrated in Table~\ref{tab:token_usage}, and usage for each agent in our \system is shown in Table~\ref{tab:token_agent}. Additionally, our evaluations are conducted in VisEval Benchmark (with MIT license).

\paragraph{Human Annotation.}
\label{human}
The annotation is conducted by 5 authors of this paper independently. As acknowledged, the diversity of annotators plays a crucial role in reducing bias and enhancing the reliability of the benchmark. These annotators have knowledge in the data visualization domain, with different genders, ages, and educational backgrounds. The educational backgrounds of annotators are above undergraduate. To ensure the annotators can proficiently mark the data, we provide them with detailed tutorials, teaching them how to judge the quality of data visualization. We also provide them with detailed criteria and task requirements in each annotation process shown in Figure~\ref{fig:annotation}. Two experiments requiring human annotation are detailed as follows:

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{figure/score_distribution.pdf}
    \caption{Comparison of score density distribution between GPT-4o, GPT-4o-mini and human average score.}
    \label{fig:score_distribution}
\end{figure}

\begin{table*}[!ht]
\centering
\begin{tabular}{l|ccc}
\toprule
& Invalid Rate & Illegal Rate & Pass Rate \\
\midrule
\system & 4.66\% & 23.97\% & 71.35\% \\
w. CoT for Validator & 5.82\% & 23.39\% & 70.78\% \\
w. original schema for Validator & 4.80\% & 24.22\% & 70.97\% \\
\bottomrule
\end{tabular}
\caption{Additional exploration for Validator (using GPT-3.5-turbo).} 
\vspace{-1em} 
\label{tab:ablation_validator}
\end{table*}

\begin{itemize}[leftmargin=*, itemsep=0pt]
    \item \textbf{Pearson Correlation of Visual Language Model.} We conduct human annotation frameworks to compare the ability of the visual language model for MLLM-as-a-Judge~\cite{chen2024mllm}, providing the readability score. Our annotation framework is shown in Figure~\ref{fig:annotation}. The final Pearson scores are demonstrated in Table~\ref{tab:pearson_corr}, with its density distribution in Figure~\ref{fig:score_distribution}. The detailed instructions can be found in Figure~\ref{fig:scoring_instructions}.
    \item \textbf{Qualitative comparison to calculate ELO Scores.} We conduct human-judgments evaluations to compare which visualization generated by different models meets the query requirement more precisely. The leaderboard is shown in Table~\ref{tab:elo_rankings}, and Figure~\ref{fig:elo} shows the judgment framework. Each model starts with a base ELO score of 1500. After each pairwise comparison, the scores are updated based on the outcome and the current scores of the models involved. The hyperparameters are set as follows: the $K$-factor is set to 32, which determines the maximum change in rating after a single comparison. We conduct two sets of evaluations: one for single-table queries and another for multiple-table queries, with 1000 bootstrap iterations for each set to ensure statistical robustness. For each model's ELO rating, we report the 95\% confidence intervals computed through bootstrap resampling, providing a measure of rating stability. The evaluation process involves presenting human judges with a query and two visualizations, asking them to select the one that better meets the query requirements. This process is repeated across all model pairs and queries in our test set. The detailed guidance provides to the human evaluators can be found in Figure~\ref{fig:evaluation_instructions}, which outlines the criteria for judging visualization quality and relevance to the given query.


\end{itemize}

\begin{figure}[!ht]
	\centering
    \setlength{\belowcaptionskip}{-1em}
	\includegraphics[width=0.98\linewidth,scale=1.0]
    {./figure/library.pdf}
    \vspace{-1em}
	\caption{Performance of different models using \texttt{Matplotlib} and \texttt{Seaborn} libraries, using GPT-3.5-turbo.
    % \yao{larger fontsize?}
    }
\label{fig: library}
\end{figure}

\begin{figure*}[!h]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/annotation.pdf}
    \caption{Screenshot of human annotation process in readability score.}
    \label{fig:annotation}
\end{figure*}

\begin{figure*}[ht]
\centering
\vspace{1em}
\begin{tcolorbox}[enhanced,attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},boxrule=0.9pt, 
  colback=gray!00,colframe=black!50,colbacktitle=gray,
  title=Readability Scoring Instruction,
  boxed title style={size=small,colframe=gray} ]
\small
\textbf{Scoring Instructions:} Please evaluate the charts based on the following criteria, with a score range from 1 to 5, where 1 indicates very poor quality and 5 indicates excellent quality. You should focus on the following aspects:

\vspace{0.5em}
\textbf{1. Chart Colors:}
\begin{itemize}
    \item Are the colors clear and natural, effectively conveying the information?
    \item Color blindness accessibility: Are the color combinations easy to distinguish, especially for users with color blindness?
\end{itemize}

\vspace{0.5em}
\textbf{2. Title and Axis Labels:}
\begin{itemize}
    \item Ensure the chart has a clear title.
    \item Do the X-axis and Y-axis labels exist, and are they complete?
    \item Check if the labels are difficult to read, e.g., are they written vertically instead of horizontally?
    \item The title should not be a direct question; instead, it should describe the data or trends being presented.
\end{itemize}

\vspace{0.5em}
\textbf{3. Legend Completeness:}
\begin{itemize}
    \item Is the legend complete, and does it clearly indicate the color labels for different data series?
    \item Ensure each color has a corresponding legend, making it easy for users to understand what the data represents.
\end{itemize}

\vspace{0.5em}
\textbf{Scoring Scale:}
\begin{itemize}
    \item \textbf{1 Point:} Very poor, unable to understand or severely lacking information.
    \item \textbf{2 Points:} Poor quality, multiple issues present, difficult to extract information.
    \item \textbf{3 Points:} Fair, conveys some information but still has room for improvement.
    \item \textbf{4 Points:} Good, generally clear charts with minor areas for improvement.
    \item \textbf{5 Points:} Excellent, outstanding chart design with clear and effective information presentation.
\end{itemize}

Please consider the above factors when assessing the charts and provide the appropriate score. Thank you for your cooperation and effort!
\end{tcolorbox}
\vspace{-7pt}
\caption{Instructions for human annorators in annotating readability scoring.}
\label{fig:scoring_instructions}
\vspace{1em}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/elo.pdf}
    \caption{Screenshot of ELO score evaluation framework for Human-as-a-Judge.}
    \label{fig:elo}
\end{figure*}

\begin{figure*}[ht]
\centering
\vspace{1em}
\begin{tcolorbox}[enhanced,attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},boxrule=0.9pt, 
  colback=gray!00,colframe=black!50,colbacktitle=gray,
  title=Visualization Comparison Guidance,
  boxed title style={size=small,colframe=gray} ]
\small
Welcome to the visualization comparison evaluation. Your task is to judge which model-generated visualization better meets the requirements of the natural language query.

\vspace{0.5em}
\textbf{Evaluation criteria:}
\begin{enumerate}
    \item \textbf{Appropriateness of chart type:} Check if the selected chart type is suitable for expressing the data and relationships required by the query.
    \item \textbf{Data completeness:} Ensure the chart includes all necessary data required by the query.
    \item \textbf{Readability:} Assess the clarity of the chart, accuracy of labels, and overall layout.
    \item \textbf{Aesthetics:} Consider if the chart's color scheme, proportions, and overall design are visually pleasing.
    \item \textbf{Information conveyance:} Judge if the chart effectively conveys the main information or insights required by the query.
\end{enumerate}

\vspace{0.5em}
\textbf{Evaluation process:}
\begin{enumerate}
    \item Carefully read the natural language query.
    \item Observe the visualization results generated by two models.
    \item Based on the above criteria, choose the better visualization or select a tie if they are equally good.
    \item If neither visualization satisfies the query requirements well, please choose the relatively better one.
\end{enumerate}

Remember, your evaluation will help us improve and compare different visualization models. Thank you for your participation!
\end{tcolorbox}
\vspace{-7pt}
\caption{Instructions for human annorators in visualization comparison.}
\label{fig:evaluation_instructions}
\vspace{1em}
\end{figure*}


\section{Additional Experiment Results}
\label{additional_experiment_result}

We also conducted a comparison experiment of different methods using matplotlib or seaborn library. Figure~\ref{fig: library} demonstrates the results, indicating that our method outperforms obviously other baselines not only with matplotlib but also seaborn.

In addition, we test techniques in the Validator Agent, such as Chain-of-Thought. As is shown in Table~\ref{tab:ablation_validator}, integrating Chain-of-Thought reasoning, may affect its performance badly, likely due to the simple refining task with complex reasoning. Moreover, using the original schema to check for false schema filtering seems to be useless in this case.

\section{Evaluation Results with Detailed Metrics}
We demonstrated the main results in Table~\ref{tab:performance_comparison}, and here we reported more detailed results of other metrics in Table~\ref{tab:detailed_results}, which underscored the error rates for each stage, including \textit{Invalid}, \textit{Illegal}, and \textit{Low Readability}. 

\begin{table*}[!ht]
\centering
\footnotesize
\scalebox{0.98}{
\begin{tabular}{ll|cc|cccc|cc}
\toprule[1.5pt]
\multirow{2}{*}{Method} & \multirow{2}{*}{Dataset} & \multicolumn{2}{c|}{Invalid} & \multicolumn{4}{c|}{Illegal} & \multicolumn{2}{c}{Low Readability} \\
&  & Execution & Surface. & Decon. & Chart Type & Data & Order & Layout & Scale\&Ticks \\
\midrule
\multicolumn{10}{c}{ \textbf{\textit{GPT-4o}}}\\
\midrule
\multirow{3}{*}{CoML4Vis} & All & 1.15 & 0.00 & 0.26 & 1.75 & 14.28 & 10.36 & 32.02 & 32.55 \\
& Single & 0.67 & 0.00 & 0.43 & 1.93 & 13.54 & 10.16 & 31.08 & 32.76 \\
& Multiple & 1.87 & 0.00 & 0.00 & 1.48 & 15.39 & 10.66 & 33.43 & 32.23 \\
\cmidrule{2-10}
\multirow{3}{*}{LIDA} & All & 6.61 & 0.00 & 1.60 & 3.24 & 40.53 & 4.07 & 32.68 & 15.77 \\
& Single & 1.13 & 0.00 & 2.11 & 0.89 & 12.26 & 6.79 & 53.93 & 26.22 \\
& Multiple & 14.80 & 0.00 & 0.79 & 8.51 & 80.53 & 0.00 & 1.24 & 0.21 \\
\cmidrule{2-10}
\multirow{3}{*}{Chat2Vis} & All & 16.05 & 0.00 & 0.62 & 3.99 & 30.14 & 5.96 & 2.37 & 20.88 \\
& Single & 0.86 & 0.00 & 0.75 & 2.30 & 10.78 & 9.73 & 3.97 & 34.63 \\
& Multiple & 38.74 & 0.00 & 0.43 & 6.51 & 59.08 & 0.32 & 0.00 & 0.34 \\
\cmidrule{2-10}
\multirow{3}{*}{nvAgent} & All & 0.97 & 0.00 & 0.08 & 1.28 & 11.07 & 4.05 & 5.07 & 40.03 \\
& Single & 0.72 & 0.00 & 0.14 & 1.27 & 9.88 & 3.60 & 3.92 & 39.36 \\
& Multiple & 1.34 & 0.00 & 0.00 & 1.30 & 12.84 & 4.73 & 6.79 & 41.03 \\
\midrule
\multicolumn{10}{c}{ \textbf{\textit{GPT-4o-mini}}}\\
\midrule
\multirow{3}{*}{CoML4Vis} & All & 4.23 & 0.00 & 0.20 & 2.31 & 16.64 & 11.83 & 35.23 & 29.35 \\
& Single & 0.36 & 0.00 & 0.26 & 2.32 & 13.80 & 11.67 & 35.92 & 32.22 \\
& Multiple & 10.01 & 0.00 & 0.10 & 2.31 & 20.87 & 12.07 & 34.19 & 25.05 \\
\cmidrule{2-10}
\multirow{3}{*}{LIDA} & All & 12.50 & 0.00 & 0.40 & 4.92 & 40.02 & 5.80 & 27.87 & 17.05 \\
& Single & 9.09 & 0.00 & 0.44 & 2.53 & 12.91 & 9.68 & 45.69 & 28.32 \\
& Multiple & 17.61 & 0.00 & 0.33 & 8.51 & 80.53 & 0.00 & 1.24 & 0.21 \\
\cmidrule{2-10}
\multirow{3}{*}{Chat2Vis} & All & 15.45 & 0.17 & 0.17 & 4.21 & 31.90 & 8.20 & 2.14 & 18.97 \\
& Single & 2.14 & 0.29 & 0.41 & 2.53 & 11.99 & 9.68 & 45.69 & 28.32 \\
& Multiple & 35.78 & 0.00 & 0.00 & 6.70 & 61.66 & 0.00 & 0.92 & 0.32 \\
\cmidrule{2-10}
\multirow{3}{*}{nvAgent} & All & 5.14 & 0.00 & 0.00 & 2.40 & 16.33 & 10.61 & 41.06 & 27.00 \\
& Single & 1.97 & 0.00 & 0.14 & 2.97 & 15.21 & 7.49 & 39.30 & 32.39 \\
& Multiple & 8.15 & 0.00 & 0.00 & 2.31 & 20.87 & 12.07 & 34.19 & 25.05 \\
\midrule
\multicolumn{10}{c}{ \textbf{\textit{GPT-3.5-turbo}}}\\
\midrule
\multirow{3}{*}{CoML4Vis} & All & 9.28 & 0.00 & 0.62 & 1.91 & 15.83 & 12.86 & 25.09 & 27.73 \\ 
& Single & 6.17 & 0.00 & 0.89 & 2.50 & 14.71 & 13.20 & 26.10 & 29.93 \\ 
& Multiple & 13.92 & 0.00 & 0.21 & 1.04 & 17.51 & 12.36 & 23.57 & 24.43 \\ 
\cmidrule{2-10} 
\multirow{3}{*}{LIDA} & All & 53.43 & 0.00 & 1.27 & 3.56 & 22.33 & 0.53 & 14.90 & 6.62 \\ 
& Single & 47.32 & 0.00 & 1.91 & 2.81 & 13.03 & 0.89 & 24.43 & 11.05 \\ 
& Multiple & 62.57 & 0.00 & 0.32 & 4.68 & 36.23 & 0.00 & 0.65 & 0.00 \\ 
\cmidrule{2-10} 
\multirow{3}{*}{Chat2Vis} & All & 18.68 & 0.00 & 0.28 & 3.66 & 32.47 & 7.20 & 25.45 & 20.15 \\ 
& Single & 3.90 & 0.00 & 0.47 & 2.78 & 15.62 & 12.01 & 41.74 & 33.38 \\ 
& Multiple & 40.77 & 0.00 & 0.00 & 4.97 & 57.66 & 0.00 & 1.12 & 0.37 \\ 
\cmidrule{2-10} 
\multirow{3}{*}{nvAgent} & All & 4.66 & 0.00 & 0.08 & 3.06 & 18.24 & 5.64 & 5.25 & 35.34 \\ 
& Single & 2.98 & 0.00 & 0.14 & 2.84 & 15.08 & 5.69 & 3.62 & 37.57 \\ 
& Multiple & 7.18 & 0.00 & 0.00 & 3.38 & 22.95 & 5.56 & 7.69 & 32.02 \\
\bottomrule[1.5pt]
\end{tabular}
}
\caption{Detailed error rates (\%) for different methods.} 
\label{tab:detailed_results}
\end{table*}

\section{Case Study}
\label{example}
% To demonstrate our approach's effectiveness, we present several illustrative examples. Figure~\ref{fig:nl_vql} shows how our system translates natural language into a structured VQL representation. Figure~\ref{python code} and Figure~\ref{fig:example_chart} demonstrate the complete pipeline from query to visualization.
Figure~\ref{fig:nl_vql} shows an example of a natural language query with its corresponding VQL representation. The output Python code for visualization and the final bar chart are demonstrated in Figure~\ref{python code} and Figure~\ref{fig:example_chart}, respectively.
Furthermore, we provide a case study of \system performance on four hardness-level NL2Vis problems in VisEval in Figure \ref{hardness case}.

The easy case demonstrates accurate grouping in scatter plot relationships. The medium case shows correct handling of multi-table joins for continent-wise statistics. The hard case exhibits temporal data visualization with proper filtering. The extra hard case showcases complex operations including weekday binning and stacked visualization. These cases highlight our system's consistent performance across varying task complexities, particularly excelling in multiple table scenarios and complex aggregations.

\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[enhanced,attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},boxrule=0.9pt, 
  colback=gray!00,colframe=black!50,colbacktitle=gray,
  title=An Example of Natural Language Query and  Corresponding VQL,,
  boxed title style={size=small,colframe=gray} ]

\textbf{Natural Language Query:}\\
How many documents are stored? Bin the store date by weekday in a bar chart.\\
\tcbline
\textbf{Corresponding VQL:}\\
Visualize BAR \\
SELECT Date\_Stored, COUNT(Document\_ID)\\
FROM All\_Documents \\
GROUP BY Date\_Stored \\
BIN Date\_Stored BY WEEKDAY\\
\end{tcolorbox}
\caption{The natural language query case and its corresponding output VQL representation.}
\label{fig:nl_vql}
\end{figure*}

\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    numbers=left,
    numberstyle=\tiny,
    frame=single,
    showstringspaces=false,
    tabsize=4,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{purple},
    breakatwhitespace=false,
    keepspaces=true
}
\begin{figure*}[htbp]
\begin{lstlisting}[
    language=Python,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    basicstyle=\tiny\ttfamily,    
    breaklines=true,
    breakatwhitespace=false,
    showstringspaces=false,
    framesep=1mm,                 % 减小框架边距
    framexleftmargin=1mm,         % 减小框架左边距
    columns=flexible,             % 灵活列宽
    keepspaces=true
]
import matplotlib.pyplot as plt 
import pandas as pd 
import os 
import duckdb

# Set data folder path
data_folder = 'E:/visEval_dataset/databases/cre_Doc_Tracking_DB'  

# Connect to database 
con = duckdb.connect(database=':memory:')  

# Read all CSV files and create view
csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')] 
for file in csv_files:
    table_name = os.path.splitext(file)[0]
    con.execute(f"CREATE VIEW {table_name} AS SELECT * FROM read_csv_auto('{os.path.join(data_folder, file)}')")  
    
# Execute SQL query 
sql = f''' 
    SELECT Date_Stored, COUNT(Document_ID) AS count_Document_ID 
    FROM All_Documents 
    GROUP BY Date_Stored 
''' 
df = con.execute(sql).fetchdf() 
con.close()  

# Rename columns 
df.columns = ['Date_Stored','count_Document_ID'] 

# Apply binning operation
flag = True 
df['Date_Stored'] = pd.to_datetime(df['Date_Stored']) 
df['Date_Stored'] = df['Date_Stored'].dt.day_name()  

# Group by and calculate count 
if flag:
    df = df.groupby('Date_Stored').sum().reset_index() 

# Ensure all seven days of the week are included 
weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 
                 'Friday', 'Saturday', 'Sunday'] 
df = df.set_index('Date_Stored').reindex(weekday_order, fill_value=0).reset_index()
df['Date_Stored'] = pd.Categorical(df['Date_Stored'], 
                                  categories=weekday_order, ordered=True) 
df = df.sort_values('Date_Stored')

# Create visualization 
fig, ax = plt.subplots(1, 1, figsize=(10, 4)) 
ax.spines['top'].set_visible(False) 
ax.spines['right'].set_visible(False) 
ax.bar(df['Date_Stored'], df['count_Document_ID']) 
ax.set_xlabel('Date_Stored') 
ax.set_ylabel('count_Document_ID') 
ax.set_title(f'BAR Chart of count_Document_ID by Date_Stored') 
plt.xticks(rotation=45) 
plt.tight_layout()  
plt.show()
\end{lstlisting}
\caption{An example of python code generating module within \system.}
\label{python code}
\end{figure*}


\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\linewidth,scale=1.0]{figure/bar_chart.pdf}
    \caption{An example of generated bar chart using \system.}
    \label{fig:example_chart}
\end{figure*}

\begin{figure*}[htbp]
\centering
\begin{tcolorbox}[enhanced,attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},boxrule=0.9pt, 
  colback=gray!00,colframe=black!50,colbacktitle=gray,
  title=Examples of \textsc{nvAgent} performance on different hardness levels,
  boxed title style={size=small,colframe=gray} ]
  
\textbf{Hardness Level:} Easy \\
\begin{minipage}{0.45\linewidth}
    \textbf{Dataset}: \textit{Single}\\
    \textbf{Input Tables}: basketball\_match\\
    \textbf{Input Query}: Show the relation between acc percent and all\_games\_percent for each ACC\_Home using a grouped scatter chart.\\
\end{minipage}\hfill
\begin{minipage}{0.45\linewidth}
    \centering
    \textbf{Response}:
    \includegraphics[width=\linewidth]{figure/easy_3085.pdf} 
\end{minipage}
\tcbline

\textbf{Hardness Level:} Medium \\
\begin{minipage}{0.45\linewidth}
    \textbf{Dataset}: \textit{Multiple}\\
    \textbf{Input Tables}: car\_makers, car\_names, cars\_data, continents, countries, model\_list\\
    \textbf{Input Query}: Display a pie chart for what is the name of each continent and how many car makers are there in each one?\\
\end{minipage}\hfill
\begin{minipage}{0.55\linewidth}
    \centering
    \textbf{Response}:
    \includegraphics[width=\linewidth]{figure/medium_433.pdf} 
\end{minipage}
\tcbline

\textbf{Hardness Level:} Hard \\[1em]
\begin{minipage}{0.45\linewidth}
    \textbf{Dataset}: \textit{Multiple}\\
    \textbf{Input Tables}: advisor, classroom, course, department, instructor, prereq, section, student, takes, teaches, time\_slot\\
    \textbf{Input Query}: Find the number of courses offered by Psychology department in each year with a line chart.\\
\end{minipage}\hfill
\begin{minipage}{0.45\linewidth}
    \centering
    \textbf{Response}:
    \includegraphics[width=\linewidth]{figure/hard_611.pdf} 
\end{minipage}
\tcbline

\textbf{Hardness Level:} Extra Hard \\[1em]
\begin{minipage}{0.45\linewidth}
    \textbf{Dataset}: \textit{Multiple}\\
    \textbf{Input Tables}: Accounts, Documents, Documents\_with\_Expenses, Projects, Ref- \_Budget\_Codes, Ref\_Document\_Types, Statements\\
    \textbf{Input Query}: How many documents are created in each day? Bin the document date by weekday and group by document type description with a stacked bar chart, I want to sort Y in desc order.\\
\end{minipage}\hfill
\begin{minipage}{0.45\linewidth}
    \centering
    \textbf{Response}:
    \includegraphics[width=\linewidth]{figure/extra_851.pdf} 
\end{minipage}

\end{tcolorbox}
    \caption{Examples of \textsc{nvAgent}'s performance on different hardness levels in VisEval (easy, medium, hard, and extra hard.}
    \label{hardness case}
\end{figure*}


\clearpage
\onecolumn
\section{Prompts Details}
\label{prompt_details}
We provide detailed prompt design of our \system as follows.



\begin{promptbox}[Prompt template for Processor Agent]
You are an experienced and professional database administrator. Given a database schema and a user query, your task is to analyze the query, filter the relevant schema, generate an optimized representation, and classify the query difficulty. \\
\\
Now you can think step by step, following these instructions below. \\
\textbf{[Instructions]} \\
1. Schema Filtering: \\
\text{\ \ \ \ }- Identify the tables and columns that are relevant to the user query.\\
\text{\ \ \ \ }- Only exclude columns that are completely irrelevant.\\
\text{\ \ \ \ }- The output should be \{\{tables: [columns]\}\}.\\
\text{\ \ \ \ }- Keep the columns needed to be primary keys and foreign keys in the filtered schema.\\
\text{\ \ \ \ }- Keep the columns that seem to be similar with other columns of another table.\\
\\
2. New Schema Generation:\\
\text{\ \ \ \ }- Generate a new schema of the filtered schema, based on the given database schema and your filtered schema.\\
\\
3. Augmented Explanation:\\
\text{\ \ \ \ }- Provide a concise summary of the filtered schema to give additional knowledge.\\
\text{\ \ \ \ }- Include the number of tables, total columns, and any notable relationships or patterns.\\
\\
4. Classification:\\
For the database new schema, classify it as SINGLE or MULTIPLE based on the tables number.\\
\text{\ \ \ \ }- if tables number >= 2: predict MULTIPLE\\
\text{\ \ \ \ }- elif only one table: predict SINGLE\\
\\
==============================\\
Here is a typical example:\\
\textbf{[Database Schema]}\\
\textbf{[DB\_ID]} dorm\_1\\
\textbf{[Schema]}\\
\# Table: Student\\
\text{[}\\
  \text{\ \ \ \ }(stuid, And This is a id type column),\\
  \text{\ \ \ \ }(lname, Value examples: [`Smith', `Pang', `Lee', `Adams', `Nelson', `Wilson'].),\\
  \text{\ \ \ \ }(fname, Value examples: [`Eric', `Lisa', `David', `Sarah', `Paul', `Michael'].),\\
  \text{\ \ \ \ }(age, Value examples: [18, 20, 17, 19, 21, 22].),\\
  \text{\ \ \ \ }(sex, Value examples: [`M', `F'].),\\
  \text{\ \ \ \ }(major, Value examples: [600, 520, 550, 50, 540, 100].),\\
  \text{\ \ \ \ }(advisor, And this is a number type column),\\
  \text{\ \ \ \ }(city code, Value examples: [`PIT', `BAL', `NYC', `WAS', `HKG', `PHL'].)\\
\text{]}\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for Processor Agent]
\# Table: Dorm\\
\text{[}\\
  \text{\ \ \ \ }(dormid, And This is a id type column),\\
  \text{\ \ \ \ }(dorm name, Value examples: [`Anonymous Donor Hall', `Bud Jones Hall', `Dorm-plex 2000', `Fawlty Towers', `Grad Student Asylum', `Smith Hall'].),\\
  \text{\ \ \ \ }(student capacity, Value examples: [40, 85, 116, 128, 256, 355].),
  (gender, Value examples: [`X', `F', `M'].)\\
\text{]}\\
\# Table: Dorm\_amenity\\
\text{[}\\
  \text{\ \ \ \ }(amenid, And This is a id type column),\\
  \text{\ \ \ \ }(amenity name, Value examples: [`4 Walls', `Air Conditioning', `Allows Pets', `Carpeted Rooms', `Ethernet Ports', `Heat'].)\\
\text{]}\\
\# Table: Has\_amenity\\
\text{[}\\
  \text{\ \ \ \ }(dormid, And This is a id type column),\\
  \text{\ \ \ \ }(amenid, And This is a id type column)\\
\text{]}\\
\# Table: Lives\_in\\
\text{[}\\
  \text{\ \ \ \ }(stuid, And This is a id type column),\\
  \text{\ \ \ \ }(dormid, And This is a id type column),\\
  \text{\ \ \ \ }(room number, And this is a number type column)\\
\text{]}\\
\\
\textbf{[Query]}\\
Find the first name of students who are living in the Smith Hall, and count them by a pie chart\\
\\
Now we can think step by step\\
\textbf{[Filtered Schema]}\\
\{\\
  "Student": ["stuid", "fname"],\\
  "Dorm": ["dormid", "dorm name"],\\
  "Lives\_in": ["stuid", "dormid"]\\
\}\\
\\
\textbf{[New Schema]}\\
\# Table: Student\\
\text{[}\\
  (stuid, And This is a id type column),\\
  (fname, Value examples: [`Eric', `Lisa', `David', `Sarah', `Paul', `Michael'].),\\
\text{]}\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for Processor Agent]
\# Table: Dorm
\text{[}\\
  (dormid, And This is a id type column),\\
  (dorm name, Value examples: [`Anonymous Donor Hall', `Bud Jones Hall', `Dorm-plex 2000', `Fawlty Towers', `Grad Student Asylum', `Smith Hall'].),\\
\text{]}\\
\# Table: Lives\_in\\
\text{[}\\
  (stuid, And This is a id type column),\\
  (dormid, And This is a id type column),\\
\text{]}\\
\textbf{[Augmented Explanation]}\\
The filtered schema consists of 3 tables (Student, Dorm, and Lives\_in) with a total of 6 relevant columns. There is a many-to-one relationship between Student and Dorm through the Lives\_in junction table. The query involves joining these three tables to find students living in a specific dorm (Smith Hall).\\
\\
Key points:\\
1. The Lives\_in table acts as a bridge between Student and Dorm, allowing for the association of students with their dorms.\\
2. The `dorm name' column in the Dorm table is crucial for filtering the specific dorm (Smith Hall).\\
3. The `fname' column from the Student table is required for the final output.\\
\\
\textbf{[Classification]}\\
MULTIPLE\\
\\
==============================\\
Here is a new question:\\
\\
\textbf{[DB\_ID]} \{db\_id\}\\
\textbf{[Database Schema]}\\
\{db\_schema\}\\
\\
\textbf{[Query]}\\
\{query\}\\
\\
Now give your answer following this format strictly without other explanation:\\
\\
\textbf{[Filtered Schema]}\\
\\
\textbf{[New Schema]}\\
\\
\textbf{[Augmented Explanation]}\\
\\
\textbf{[Classification]}\\
\\
\end{promptbox}
% \end{figure*}

% \subsection{Composer Agent Prompt}
% \label{composer_prompt}
% \begin{figure*}[!h]
\begin{promptbox}[Prompt template for multiple classification]
Given a [Database schema] with [Augmented Explanation] and a [Question], generate a valid VQL (Visualization Query Language) sentence. VQL is similar to SQL but includes visualization components. \\
\\
Now you can think step by step, following these instructions below. \\
\textbf{[Background]} \\
VQL Structure:\\
Visualize [TYPE] SELECT [COLUMNS] FROM [TABLES] [JOIN] [WHERE] [GROUP BY] [ORDER BY] [BIN BY]\\
\\
You can consider a VQL sentence as "VIS TYPE + SQL + BINNING"\\
You must consider which part in the sketch is necessary, which is unnecessary, and construct a specific sketch for the natural language query.\\
\\
Key Components:\\
1. Visualization Type: bar, pie, line, scatter, stacked bar, grouped line, grouped scatter\\
2. SQL Components: SELECT, FROM, JOIN, WHERE, GROUP BY, ORDER BY\\
3. Binning: BIN [COLUMN] BY [INTERVAL], [INTERVAL]: [YEAR, MONTH, DAY, WEEKDAY]\\
\\
When generating VQL, we should always consider special rules and constraints:\\
\textbf{[Special Rules]} \\
a. For simple visualizations:\\
    \text{\ \ \ \ }- SELECT exactly TWO columns, X-axis and Y-axis(usually aggregate function)\\
b. For complex visualizations (STACKED BAR, GROUPED LINE, GROUPED SCATTER):\\
    \text{\ \ \ \ }- SELECT exactly THREE columns in this order!!!:\\
        \text{\ \ \ \ }\text{\ \ \ \ }1. X-axis\\
        \text{\ \ \ \ }\text{\ \ \ \ }2. Y-axis (aggregate function)\\
        \text{\ \ \ \ }\text{\ \ \ \ }3. Grouping column\\
c. When "COLORED BY" is mentioned in the question:\\
    \text{\ \ \ \ }- Use complex visualization type(STACKED BAR for bar charts, GROUPED LINE for line charts, GROUPED SCATTER for scatter charts)\\
    \text{\ \ \ \ }- Make the "COLORED BY" column the third SELECT column\\
    \text{\ \ \ \ }- Do NOT include "COLORED BY" in the final VQL\\     
d. Aggregate Functions:\\
    \text{\ \ \ \ }- Use COUNT for counting occurrences\\
    \text{\ \ \ \ }- Use SUM only for numeric columns\\
    \text{\ \ \ \ }- When in doubt, prefer COUNT over SUM\\
e. Time based questions:\\
    \text{\ \ \ \ }- Always use BIN BY clause at the end of VQL sentence\\
    \text{\ \ \ \ }- When you meet the questions including "year", "month", "day", "weekday"\\
    \text{\ \ \ \ }- Avoid using window function, just use BIN BY to deal with time base queries\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for multiple classification]
\textbf{[Constraints]} \\
- In SELECT <column>, make sure there are at least two selected!!!\\
- In FROM <table> or JOIN <table>, do not include unnecessary table\\
- Use only table names and column names from the given database schema\\
- Enclose string literals in single quotes\\
- If [Value examples] of <column> has `None' or None, use JOIN <table> or WHERE <column> is NOT NULL is better\\
- Ensure GROUP BY precedes ORDER BY for distinct values\\
- NEVER use window functions in SQL\\
\\
Now we could think step by step:\\
1. First choose visualize type and binning, then construct a specific sketch for the natural language query\\
2. Second generate SQL components following the sketch.\\
3. Third add Visualize type and BINNING into the SQL components to generate final VQL\\
\\
==============================\\
Here is a typical example:\\
\textbf{[Database Schema]}\\
\# Table: Orders, (orders)\\
\text{[}\\
  \text{\ \ \ \ }(order\_id, order id, And this is a id type column),\\
  \text{\ \ \ \ }(customer\_id, customer id, And this is a id type column),\\
  \text{\ \ \ \ }(order\_date, order date, Value examples: [`2023-01-15', `2023-02-20', `2023-03-10'].),\\
  \text{\ \ \ \ }(total\_amount, total amount, Value examples: [100.00, 200.00, 300.00, 400.00, 500.00].)\\
\text{]}\\
\# Table: Customers, (customers)\\
\text{[}\\
  \text{\ \ \ \ }(customer\_id, customer id, And this is a id type column),\\
  \text{\ \ \ \ }(customer\_name, customer name, Value examples: [`John', `Emma', `Michael', `Sophia', `William'].),\\
  \text{\ \ \ \ }(customer\_type, customer type, Value examples: [`Regular', `VIP', `New'].)\\
\text{]}\\
\textbf{[Augmented Explanation]}\\
The filtered schema consists of 2 tables (Orders and Customers) with a total of 7 relevant columns. There is a one-to-many relationship between Customers and Orders through the customer\_id foreign key.\\
\\
Key points:\\
1. The Orders table contains information about individual orders, including the order date and total amount.\\
2. The Customers table contains customer information, including their name and type (Regular, VIP, or New).\\
3. The customer\_id column links the two tables, allowing us to associate orders with specific customers.\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for multiple classification]
4. The order\_date column in the Orders table will be used for monthly grouping and binning.\\
5. The total\_amount column in the Orders table needs to be summed for each group.\\
6. The customer\_type column in the Customers table will be used for further grouping and as the third dimension in the stacked bar chart.\\
\\

The query involves joining these two tables to analyze order amounts by customer type and month, which requires aggregation and time-based binning.\\
\\
\textbf{[Question]}\\
Show the total order amount for each customer type by month in a stacked bar chart.\\
\\
Decompose the task into sub tasks, considering [Background] [Special Rules] [Constraints], and generate the VQL after thinking step by step:\\
\\
\textbf{Sub task 1:} First choose visualize type and binning, then construct a specific sketch for the natural language query\\
Visualize type: STACKED BAR, BINNING: True\\
VQL Sketch:\\
Visualize STACKED BAR SELECT \_ , \_ , \_ FROM \_ JOIN \_ ON \_ GROUP BY \_ BIN \_ BY MONTH\\
\\
\textbf{Sub task 2:} Second generate SQL components following the sketch.\\
Let's think step by step:\\
1. We need to select 3 columns for STACKED BAR chart, order\_date as X-axis, SUM(total\_amout) as Y-axis, customer\_type as group column.\\
2. We need to join the Orders and Customers tables.\\
3. We need to group by customer type.\\
4. We do not need to use any window function for MONTH.\\
\\
\text{sql}\\
```sql\\
SELECT O.order\_date, SUM(O.total\_amount), C.customer\_type\\
FROM Orders AS O\\
JOIN Customers AS C ON O.customer\_id = C.customer\_id\\
GROUP BY C.customer\_type\\
```\\
\\
\textbf{Sub task 3:} Third add Visualize type and BINNING into the SQL components to generate final VQL\\
\textbf{Final VQL:}\\
Visualize STACKED BAR SELECT O.order\_date, SUM(O.total\_amount), C.customer\_type FROM Orders O JOIN Customers C ON O.customer\_id = C.customer\_id GROUP BY C.customer\_type BIN O.order\_date BY MONTH\\
\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for multiple classification]
==============================\\
Here is a new question:\\
\\
\textbf{[Database Schema]}\\
\{desc\_str\}\\
\\
\textbf{[Augmented Explanation]}\\
\{augmented\_explanation\}\\
\\
\textbf{[Query]}\\
\{query\}\\
\\
Now, please generate a VQL sentence for the database schema and question after thinking step by step.\\

\end{promptbox}
% \end{figure*}


% \begin{figure*}[!h]
\begin{promptbox}[Prompt template for single classification]
Given a [Database schema] with [Augmented Explanation] and a [Question], generate a valid VQL (Visualization Query Language) sentence. VQL is similar to SQL but includes visualization components. \\
\\
Now you can think step by step, following these instructions below. \\
\textbf{[Background]} \\
VQL Structure:\\
Visualize [TYPE] SELECT [COLUMNS] FROM [TABLES] [JOIN] [WHERE] [GROUP BY] [ORDER BY] [BIN BY]\\
\\
You can consider a VQL sentence as "VIS TYPE + SQL + BINNING"\\
You must consider which part in the sketch is necessary, which is unnecessary, and construct a specific sketch for the natural language query.\\
\\
Key Components:\\
1. Visualization Type: bar, pie, line, scatter, stacked bar, grouped line, grouped scatter\\
2. SQL Components: SELECT, FROM, JOIN, WHERE, GROUP BY, ORDER BY\\
3. Binning: BIN [COLUMN] BY [INTERVAL], [INTERVAL]: [YEAR, MONTH, DAY, WEEKDAY]\\
\\
When generating VQL, we should always consider special rules and constraints:\\
\textbf{[Special Rules]} \\
a. For simple visualizations:\\
    \text{\ \ \ \ }- SELECT exactly TWO columns, X-axis and Y-axis(usually aggregate function)\\
b. For complex visualizations (STACKED BAR, GROUPED LINE, GROUPED SCATTER):\\
    \text{\ \ \ \ }- SELECT exactly THREE columns in this order!!!:\\
        \text{\ \ \ \ }\text{\ \ \ \ }1. X-axis\\
        \text{\ \ \ \ }\text{\ \ \ \ }2. Y-axis (aggregate function)\\
        \text{\ \ \ \ }\text{\ \ \ \ }3. Grouping column\\
c. When "COLORED BY" is mentioned in the question:\\
    \text{\ \ \ \ }- Use complex visualization type(STACKED BAR for bar charts, GROUPED LINE for line charts, GROUPED SCATTER for scatter charts)\\
    \text{\ \ \ \ }- Make the "COLORED BY" column the third SELECT column\\
    \text{\ \ \ \ }- Do NOT include "COLORED BY" in the final VQL\\     
d. Aggregate Functions:\\
    \text{\ \ \ \ }- Use COUNT for counting occurrences\\
    \text{\ \ \ \ }- Use SUM only for numeric columns\\
    \text{\ \ \ \ }- When in doubt, prefer COUNT over SUM\\
e. Time based questions:\\
    \text{\ \ \ \ }- Always use BIN BY clause at the end of VQL sentence\\
    \text{\ \ \ \ }- When you meet the questions including "year", "month", "day", "weekday"\\
    \text{\ \ \ \ }- Avoid using window function, just use BIN BY to deal with time base queries\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for single classification]
\textbf{[Constraints]} \\
- In SELECT <column>, make sure there are at least two selected!!!\\
- In FROM <table> or JOIN <table>, do not include unnecessary table\\
- Use only table names and column names from the given database schema\\
- Enclose string literals in single quotes\\
- If [Value examples] of <column> has `None' or None, use JOIN <table> or WHERE <column> is NOT NULL is better\\
- Ensure GROUP BY precedes ORDER BY for distinct values\\
- NEVER use window functions in SQL\\
\\
Now we could think step by step:\\
1. First choose visualize type and binning, then construct a specific sketch for the natural language query\\
2. Second generate SQL components following the sketch.\\
3. Third add Visualize type and BINNING into the SQL components to generate final VQL\\
\\
==============================\\
Here is a typical example:\\
\textbf{[Database Schema]}\\
\# Table: course, (course)\\
\text{[}\\
  \text{\ \ \ \ }(course\_id, course id, Value examples: [101, 696, 656, 659]. And this is an id type column),\\
  \text{\ \ \ \ }(title, title, Value examples: [`Geology', `Differential Geometry', `Compiler Design', `International Trade', `Composition and Literature', `Environmental Law'].),\\
  \text{\ \ \ \ }(dept\_name, dept name, Value examples: [`Cybernetics', `Finance', `Psychology', `Accounting', `Mech. Eng.', `Physics'].),\\
  \text{\ \ \ \ }(credits, credits, Value examples: [3, 4].)\\
\text{]}\\
\# Table: section, (section)\\
\text{[}\\
  \text{\ \ \ \ }(course\_id, course id, Value examples: [362, 105, 960, 468]. And this is an id type column),\\
  \text{\ \ \ \ }(sec\_id, sec id, Value examples: [1, 2, 3]. And this is an id type column),\\
  \text{\ \ \ \ }(semester, semester, Value examples: [`Fall', `Spring'].),\\
  \text{\ \ \ \ }(year, year, Value examples: [2002, 2006, 2003, 2007, 2010, 2008].),\\
  \text{\ \ \ \ }(building, building, Value examples: [`Saucon', `Taylor', `Lamberton', `Power', `Fairchild', `Main'].),\\
  \text{\ \ \ \ }(room\_number, room number, Value examples: [180, 183, 134, 143].),\\
  \text{\ \ \ \ }(time\_slot\_id, time slot id, Value examples: [`D', `J', `M', `C', `E', `F']. And this is an id type column)\\
\text{]}\\
\textbf{[Augmented Explanation]}\\
The filtered schema consists of 2 tables (course and section) with a total of 11 relevant columns. There is a one-to-many relationship between course and section through the course\_id foreign key.\\
\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for single classification]
Key points:\\
1. The course table contains information about individual courses, including the course title, department, and credits.\\
2. The section table contains information about specific sections of courses, including the semester, year, building, room number, and time slot.\\
3. The course\_id column links the two tables, allowing us to associate sections with specific courses.\\
4. The dept\_name column in the course table will be used to filter for Psychology department courses.\\
5. The year column in the section table will be used for yearly grouping and binning.\\
6. We need to count the number of courses offered each year, which requires aggregation and time-based binning.\\
\\
The query involves joining these two tables to analyze the number of courses offered by the Psychology department each year, which requires aggregation and time-based binning.\\
\\
\textbf{[Question]}\\
Find the number of courses offered by Psychology department in each year with a line chart.\\
\\
Decompose the task into sub tasks, considering [Background] [Special Rules] [Constraints], and generate the VQL after thinking step by step:\\
\\
\textbf{Sub task 1:} First choose visualize type and binning, then construct a specific sketch for the natural language query\\
Visualize type: LINE, BINNING: True\\
VQL Sketch:\\
Visualize LINE SELECT \_ , \_ FROM \_ JOIN \_ ON \_ WHERE \_ BIN \_ BY YEAR\\
\\
\textbf{Sub task 2:} Second generate SQL components following the sketch.\\
Let's think step by step:\\
1. We need to select 2 columns for LINE chart, year as X-axis, COUNT(year) as Y-axis.\\
2. We need to join the course and section tables to get the number of courses offered by the Psychology department in each year.\\
3. We need to filter the courses by the Psychology department.\\
4. We do not need to use any window function for YEAR.\\
\\
\text{sql}\\
```sql\\
SELECT S.year, COUNT(S.year)\\
FROM course AS C\\
JOIN section AS S ON C.course\_id = S.course\_id\\
WHERE C.dept\_name = `Psychology'\\
```\\
\\
% \end{promptbox}
% \end{figure*}
% \begin{figure*}[!h]
% \begin{promptbox}[Prompt template for single classification]
\textbf{Sub task 3:} Third add Visualize type and BINNING into the SQL components to generate final VQL\\
\textbf{Final VQL:}\\
Visualize LINE SELECT S.year, COUNT(S.year) FROM course C JOIN section S ON C.course\_id = S.course\_id WHERE C.dept\_name = `Psychology' BIN S.year BY YEAR\\
\\
==============================\\
Here is a new question:\\
\\
\textbf{[Database Schema]}\\
\{desc\_str\}\\
\\
\textbf{[Augmented Explanation]}\\
\{augmented\_explanation\}\\
\\
\textbf{[Query]}\\
\{query\}\\
\\
Now, please generate a VQL sentence for the database schema and question after thinking step by step.\\

\end{promptbox}
% \end{figure*}

% \subsection{Validator Agent Prompt}
% \label{validator_prompt}
% \begin{figure*}
\begin{promptbox}[Prompt template for Validator Agent]
As an AI assistant specializing in data visualization and VQL (Visualization Query Language), your task is to refine a VQL query that has resulted in an error. Please approach this task systematically, thinking step by step.\\
\textbf{[Background]}\\
VQL Structure:\\
Visualize [TYPE] SELECT [COLUMNS] FROM [TABLES] [JOIN] [WHERE] [GROUP BY] [ORDER BY] [BIN BY]\\
\\
You can consider a VQL sentence as "VIS TYPE + SQL + BINNING"\\
\\
Key Components:\\
1. Visualization Type: bar, pie, line, scatter, stacked bar, grouped line, grouped scatter\\
2. SQL Components: SELECT, FROM, JOIN, WHERE, GROUP BY, ORDER BY\\
3. Binning: BIN [COLUMN] BY [INTERVAL], [INTERVAL]: [YEAR, MONTH, DAY, WEEKDAY]\\
\\
When refining VQL, we should always consider special rules and constraints:\\
\textbf{[Special Rules]} \\
a. For simple visualizations:\\
    \text{\ \ \ \ }- SELECT exactly TWO columns, X-axis and Y-axis(usually aggregate function)\\
b. For complex visualizations (STACKED BAR, GROUPED LINE, GROUPED SCATTER):\\
    \text{\ \ \ \ }- SELECT exactly THREE columns in this order!!!:\\
        \text{\ \ \ \ }\text{\ \ \ \ }1. X-axis\\
        \text{\ \ \ \ }\text{\ \ \ \ }2. Y-axis (aggregate function)\\
        \text{\ \ \ \ }\text{\ \ \ \ }3. Grouping column\\
c. When "COLORED BY" is mentioned in the question:\\
    \text{\ \ \ \ }- Use complex visualization type(STACKED BAR for bar charts, GROUPED LINE for line charts, GROUPED SCATTER for scatter charts)\\
    \text{\ \ \ \ }- Make the "COLORED BY" column the third SELECT column\\
    \text{\ \ \ \ }- Do NOT include "COLORED BY" in the final VQL\\     
d. Aggregate Functions:\\
    \text{\ \ \ \ }- Use COUNT for counting occurrences\\
    \text{\ \ \ \ }- Use SUM only for numeric columns\\
    \text{\ \ \ \ }- When in doubt, prefer COUNT over SUM
% \end{promptbox}
% \end{figure*}

% \begin{figure*}
% \begin{promptbox}[Prompt template for Validator Agent]
e. Time based questions:\\
    \text{\ \ \ \ }- Always use BIN BY clause at the end of VQL sentence\\
    \text{\ \ \ \ }- When you meet the questions including "year", "month", "day", "weekday"\\
    \text{\ \ \ \ }- Avoid using time function, just use BIN BY to deal with time base queries\\
\\
\textbf{[Constraints]} \\
- In FROM <table> or JOIN <table>, do not include unnecessary table\\
- Use only table names and column names from the given database schema\\
- Enclose string literals in single quotes\\
- If [Value examples] of <column> has `None' or None, use JOIN <table> or WHERE <column> is NOT NULL is better\\
- ENSURE GROUP BY clause cannot contain aggregates\\
- NEVER use date functions in SQL\\
\\
\textbf{[Query]} \\
\{query\}\\
\\
\textbf{[Database info]} \\
\{db\_info\}\\
\\
\textbf{[Current VQL]} \\
\{vql\}\\
\\
\textbf{[Error]} \\
\{error\}\\
\\
Now, please analyze and refine the VQL, please provide:\\
\\
\textbf{[Explanation]}\\
\text{[}Provide a detailed explanation of your analysis process, the issues identified, and the changes made. Reference specific steps where relevant.\text{]}\\
\\
\textbf{[Corrected VQL]}\\
\text{[}Present your corrected VQL here. Ensure it's on a single line without any line breaks.\text{]}\\
\\
Remember:\\
- The SQL components must be parseable by DuckDB.\\
- Do not change rows when you generate the VQL.\\
- Always verify your answer carefully before submitting.\\
\end{promptbox}
% \end{figure*}