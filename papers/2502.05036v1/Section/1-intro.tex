\section{Introduction}
\label{sec:intro}
\textit{``Turning data into insight''} has long been a key goal in our increasingly data-rich, information-driven society~\cite{fiorinagoal}. 
To achieve this, \textit{Natural Language to Visualization} (\nlvis) plays a crucial role in transforming natural-language descriptions into visual representations (\emph{e.g.}, charts, plots, and histograms) grounded on tabular data~\cite{sah2024generating}. This approach enables users to interact with data intuitively, facilitating the extraction of patterns and insights from large and complex datasets~\cite{yin2024data,towardsvisualization}.

\begin{figure}[!t]
	\centering
    % \setlength{\belowcaptionskip}{-1em}   %调整图片标题与下文距离
    \includegraphics[width=0.98\linewidth,scale=1.0]
    {./figure/intro.pdf}
    % \vspace{-1em}
	\caption{An example to illustrate the \nlvis task. Formerly \textit{``One Forward''} workflow struggled with multi-table queries due to its complex and heterogeneous structure, which could easily cause an error. \system uses a collaborative agent-based workflow for iterative interaction with data and validation to ensure accurate and valid visualization.
    }
    \vspace{-1em}
\label{fig: intro}
\end{figure}



Recently, \textit{Large Language Models} (LLMs) have demonstrated promising performance in \nlvis tasks, excelling in various stages such as data pre-processing~\cite{prompt4vis} and code generation for visualization~\cite{chat2vis}. These models effectively generate readable visualizations for individual datasets or databases~\cite{li2024visualizationgenerationlargelanguage}.
However, existing approaches encounter challenges when processing queries involving multiple tables due to incorrect joins or mis-filtering conditions, leading to visualization errors~\cite{chat2vis,lida,viseval}.  These limitations severely restrict their applicability in real-world scenarios where data is typically distributed across multiple related tables~\cite{khan2024data, lu2024large}.


Figure~\ref{fig: intro} shows an example to illustrate the %strong 
motivation of our study.
Given a natural-language (NL) query such as \textit{``Show all the faculty ranks and the number of students advised by each rank in a bar chart''}, the system must understand that \textit{``faculty''} information corresponds to the column \textit{``Advisor''} and \textit{``FacID''} across two tables. These complex cross-table visualization highlights the challenge between NL queries and databases, requiring a framework that can preprocess metadata, think \textit{``step-by-step''} with plans, and iterative validation to ensure correctness.

These observations inspire our \system, a collaborative agent workflow for \nlvis.
\system follows the \textit{``divide-and-conquer''} paradigm, consisting of three specialized LLM agents: a \textit{processor} agent for database processing and context filtering, a \textit{composer} agent for planning visualization generation, and a \textit{validator} agent for code translation and output verification. 
This collaborative workflow provides a more systematic approach that can effectively handle multi-table scenarios while maintaining visualization accuracy and quality.

To validate the effectiveness of \system, we conducted extensive experiments on the VisEval benchmark~\cite{viseval}, which includes two scenarios: the \textit{single-table} scenario, involving generating visualizations from individual tables, and the \textit{multi-table} scenario, which entails integrating information from multiple tables. The results demonstrate that \system outperforms all baseline methods, achieving a 7.88\% higher pass rate in \textit{single-} and 9.23\% in \textit{multi-table} scenarios compared to the state-of-the-art method. Our ablation study that breakdown every module within \system provide solid evidence of our framework design. Qualitative analyses further highlight that \system maintains 3.64\% and 18.15\% margin in \textit{single-} and \textit{multi-table} over previous frameworks, underscoring its efficacy in producing high-quality visual representations from complex, heterogeneous data sources.

In summary, this paper makes the following key contributions:
% \begin{itemize}[leftmargin=*, itemsep=0pt]
    \textbf{(1)} We propose \textbf{\system}, a collaborative agent-based workflow for complex \nlvis tasks, which decomposes the visualization generation process into manageable subtasks.
    \textbf{(2)} Extensive experiments and analysis are performed to validate the effectiveness \textit{divide-and-conquer} strategy of \system for \nlvis.
% \end{itemize}



