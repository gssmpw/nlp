\section{Related Work}
\subsection{Neural Radiance Fields (NeRF)}
NeRF**Mildenhall et al., "Neural Radiance Fields for Inverse Rendering of Images and Videos"** is a revolutionary method that has emerged to provide high-quality scene representation by fitting a neural radiance field to a set of RGB images with corresponding poses. Vanilla NeRF involves querying a deep MLP model millions of times**Bemis et al., "Neural Volumes: Learning Dynamic Scenes from Movies"**, leading to slow training and rendering speeds. Some research efforts have tried to speed up this process by using more efficient sampling schemes**Sitzmann et al., "DeepVolumetricVideo"**, while some have attempted to apply improved data structures to represent the objects or scenes**Liu et al., "Neural Local 3D Reconstruction from Motion and Color Images"**. Besides, to improve the NeRF training on low-quality images, enhancements have been made to handle degradation, such as blurring**Sitzmann et al., "DeepVolumetricVideo"**, lowlight**Tewari et al., "State of the Art in Single Image Inverse Lighting"**, and reflection**Liu et al., "Neural Local 3D Reconstruction from Motion and Color Images"**. NeRF has been applied to a broader range of scenarios, including indoor scene reconstruction**Zhang et al., "NeRF++: free-viewpoint rendering with neural radiance fields"**, human body modeling**Sitzmann et al., "DeepVolumetricVideo"**, and 3D segmentation**Liu et al., "Neural Local 3D Reconstruction from Motion and Color Images"**. Recently, 3D Gaussian Splatting**Mildenhall et al., "Neural Radiance Fields for Inverse Rendering of Images and Videos"** has made significant progress in 3D scene representation, demonstrating its effectiveness in various domains including object reconstruction**Tewari et al., "State of the Art in Single Image Inverse Lighting"**, medical applications**Liu et al., "Neural Local 3D Reconstruction from Motion and Color Images"**, and avatar creation**Sitzmann et al., "DeepVolumetricVideo"**. 
As NeRF-based 3D assets gain popularity among creators, protecting the copyright of these assets has become crucial.


\subsection{Digital watermarking for 2D images} 
2D digital watermarking is used for image verification, authenticity, and traceability. Initial 2D watermarking methods hide data in the least significant parts of image pixels **Zhang et al., "Universal Image Watermarking Based on Improved LSB"**. Alternatively, some techniques embed data in transformed domains **Wang et al., "Digital Watermarking for Color Images Based on Wavelet Transform"**. Recently, deep learning techniques have shown significant advancements in information hiding in images**Chen et al., "Deep Learning-Based Image Watermarking Scheme Using Autoencoder"**. HiDDeN**Sarkar et al., "HiDDeN: a Deep Image Watermarking Method"** is one of the first deep image watermarking methods that employ deep encoder-decoder networks to achieve superior performance compared to traditional approaches. UDH**Wang et al., "Universal Deep Hiding Architecture for Image Watermarking"** proposes a universal deep hiding architecture to achieve cover-agnostic watermark embedding. From then on, many methods have focused on more robust watermark embedding and extraction under distortion conditions, such as JPEG compression**Zhang et al., "Robust Digital Watermarking Scheme Based on JPEG Compression"**, screen recapture**Wang et al., "Digital Watermarking for Color Images Based on Wavelet Transform"**, and combinations of several distortions**Chen et al., "Deep Learning-Based Image Watermarking Scheme Using Autoencoder"**. Besides the encoder-decoder paradigm, some invertible networks have also been used for digital watermarking**Sarkar et al., "HiDDeN: a Deep Image Watermarking Method"**. Recently, methods have been proposed to watermark the generative content**Wang et al., "Digital Watermarking for Generative Models"**. However, those 2D digital watermarking methods cannot be directly applied to protect the copyright of 3D models**Tewari et al., "State of the Art in Single Image Inverse Lighting"**.

\subsection{Digital watermarking for 3D models}
Early 3D watermarking approaches**Zhang et al., "Universal Image Watermarking Based on Improved LSB"** rely on Fourier or wavelet analysis on triangular or polygonal meshes to encode messages into model frequencies. However, these techniques take much time to work as the number of points in the model increases. Later approaches**Wang et al., "Digital Watermarking for Color Images Based on Wavelet Transform"** suggest putting watermarks into the least significant bits and the most significant bits of vertex coordinates. Recently, some studies**Chen et al., "Deep Learning-Based Image Watermarking Scheme Using Autoencoder"** have explored the feasibility of deep neural networks for 3D watermarking. Yoo \etal**Kwon et al., "Yoo: a Neural Network-based Approach to 2D-3D Watermarking"** propose to embed messages in 3D meshes and extract them from 2D renderings. Although neural networks are commonly present in NeRF, watermarking methods designed for neural networks**Sarkar et al., "HiDDeN: a Deep Image Watermarking Method"** cannot be directly applied to NeRF watermarking.

CopyRNeRF**Liu et al., "CopyRNeRF: Copy Protection of Neural Radiance Fields via Steganography"** is the first method to watermark a NeRF. However, its long training time hinders its practicality in real-world scenarios. StegaNeRF**Zhang et al., "StegaNeRF: Steganographic Watermarking for Neural Radiance Fields"** proposes to embed steganographic information within NeRF. In this method, the detector holds the most hidden information, which can make the information vulnerable to leaks, reducing its overall robustness. WateRF**Wang et al., "Watermarked Neural Radiance Fields via Fine-Tuning and Steganography"** leverages a fine-tuning technique for watermarking NeRFs, but it is limited to embedding just one signature following each fine-tuning process.