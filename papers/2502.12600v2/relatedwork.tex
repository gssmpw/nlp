\section{Related Works}
\label{sec:related}
%
This research primarily pertains to the field of deraining studies.
%
Many methods have been proposed to develop state-of-the-art deraining networks.
%
These works include deep network designs \cite{fu2017clearing,wang2019erl}, residual networks \cite{fu2017removing,liu2019dual}, recurrent networks \cite{ren2019progressive,yang2019single,yang2019scale}, multi-task \cite{wang2019dtdn,du2020conditional} and multi-scale designs \cite{jiang2020multi,fu2019lightweight,yasarla2019uncertainty,yu2019gradual,wei2019coarse,wang2020dcsfn,zamir2021multi}, sparsity-based image modeling \cite{gu2017joint,zhu2017joint}, low-rank prior \cite{chang2017transformed}, model-driven solutions \cite{wang2020model,wang2020rethinking}, attention mechanisms \cite{wang2020joint,chen2021pre,fu2021rain}, Transformer-based networks \cite{chen2023learning,chen2022cross}, adversarial learning \cite{li2019heavy}, representation learning \cite{chen2021robust}, semi-supervised \cite{yasarla2020syn2real} and unsupervised learning \cite{chen2022unpaired}.
%
Deep learning methods are data-hungry but collecting rain streaks and background image pairs is challenging.
%
A lot of works have been proposed to synthesize rain streaks with better results.
%
Garg \etal \cite{garg2006photorealistic} first propose a physically-based photo-realistic rendering method for synthesizing rain streaks.
%
Zhang \etal \cite{zhang2018density} and Fu \etal \cite{fu2017clearing} use Photoshop software to manually add rain effects to images to build the synthetic paired data.
%
Due to the poor generalization performance of existing methods, models trained on synthetic images were found to be ineffective in real-world scenarios.
%
Some works \cite{yang2017deep,zhang2019image,wang2019spatial} that have contributed to real collected deraining datasets.
%
However, acquiring these datasets is still expensive and cannot solve the problem of poor generalization.

There are also works that mention the generalization issue of the deraining models.
%
Xiao \etal \cite{xiao2021improving} and Zhou \etal \cite{zhou2021image} attempt to improve the generalization ability of deraining networks by accumulating knowledge from multiple synthetic rain datasets, as most existing methods can only learn the mapping on a single dataset for the deraining task.
%
However, this attempt does not allow the network to generalize beyond the training set.
%
In addition, semi-supervised methods \cite{wei2019semi,huang2021memory} have also been used to improve the deraining effect on real images, and we also include the representative method Syn2Real \cite{yasarla2020syn2real,yasarla2021semi}.
%
There are some semi-supervised deraining methods \cite{wei2019semi,huang2021memory,yasarla2020syn2real,yasarla2021semi} that are proposed to improve the performance of deraining models in real-world scenarios.
%
When obtaining some real images similar to the test images, these works can indeed achieve some improvement. 
%
However, these improvements are not brought about by improving the generalization ability.
%
Their solution is to include real test images in the training set, even if we don't have corresponding clean images. 
%
These methods are effective when we can determine the characteristics of the test image. 
%
However, this does not solve the generalization problem. 
%
Because these methods manage to convert ``rain outside the training set'' to ``rain inside the training set''. 
%
Since data collection is extremely difficult, this method still faces great challenges in practice.
%
Unlike the majority of existing deraining research, we do not propose new network structures, loss functions, or datasets.
%
Our objective is to analyze and understand the generalization problem within the context of the deraining task.
%
We will proceed to review previous works focusing on interpretability and understanding generalization in low-level vision.


Deep learning interpretability research aims to understand the mechanism of deep learning methods and to obtain clues about the success or failure of these methods.
%
Without a deep understanding of these working mechanisms, we are not convinced to move forward in the right direction.
%
The research on deep learning interpretability follows a long line of works, most focusing on the classification task \cite{simonyan2013deep,springenberg2014striving,shrikumar2017learning,sundararajan2017axiomatic,zhou2018interpreting,lundberg2017unified}.
%
Low-level vision tasks have embraced great success with powerful deep learning techniques.
%
There are also works on interpretability for these deep low-level networks \cite{gu2021interpreting,xie2021finding,magid2022texture,shirethinking,hu2024interpreting}.
%
Gu and Dong \cite{gu2021interpreting} bring the first interpretability tool for image super-resolution (SR) networks.
%
Xie \etal \cite{xie2021finding} find the most discriminative filters for each specific degradation in a blind SR network, whose weights, positions, and connections are important for the specific function in blind SR.
%
Magid \etal \cite{magid2022texture} use a texture classifier to assign patches with semantic labels, to identify global and local sources of SR errors.
%
Shi \etal \cite{shi2022rethinking} show that Transformers can directly utilize multi-frame information from unaligned frames, and adopting alignment methods is sometimes harmful to Transformers in video super-resolution.
%
Hu \etal \cite{hu2024interpreting} propose the causal effect map to interpret low-level vision models by focusing on causation rather than mere correlation.
%
The closest work to this paper is the deep degradation representation proposed by \cite{liu2021discovering}.
%
They argue that SR networks tend to overfit to degradations and show degradation ``semantics'' inside the network.
%
The presence of these representations often means a decrease in generalization ability.
%
The utilization of this knowledge can guide us to analyze the generalization performance of SR methods \cite{liu2022evaluating}.

The generalization problem in low-level vision often arises when the testing degradation does not match the training degradation, \eg, different downsampling kernel \cite{gu2019blind,liu2022blind,kong2022reflash,chen2024low,zhang2023crafting} and noise distribution \cite{guo2019toward,chen2023masked}.
%
The existing works either develop blind methods to include more degradation possibilities in the training process or make the training data closer to real-world applications.
%
Only a little work has been proposed to study the reasons for this lack of generalization performance \cite{liu2021discovering,liu2022evaluating}.
%
No research has attempted to investigate the interpretation of the training process of low-level vision networks, especially from the perspective of the generalization problem.