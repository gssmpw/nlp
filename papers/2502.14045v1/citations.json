[
  {
    "index": 0,
    "papers": [
      {
        "key": "BoxPierce1970",
        "author": "George E. P. Box and David A. Pierce",
        "title": "Distribution of residual autocorrelations in autoregressive-integrated moving average time series models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "toda1993",
        "author": "Hiro Y. Toda and Peter C. B. Phillips",
        "title": "Vector Autoregressions and Causality"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hyndman2008forecasting",
        "author": "Hyndman, Rob and Koehler, Anne B and Ord, J Keith and Snyder, Ralph D",
        "title": "Forecasting with exponential smoothing: the state space approach"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "koopmans1995spectral",
        "author": "Koopmans, Lambert H",
        "title": "The spectral analysis of time series"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2016xgboost",
        "author": "Chen, Tianqi and Guestrin, Carlos",
        "title": "Xgboost: A scalable tree boosting system"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "breiman2001random",
        "author": "Breiman, Leo",
        "title": "Random forests"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "friedman2001greedy",
        "author": "Friedman, Jerome H",
        "title": "Greedy function approximation: a gradient boosting machine"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ke2017lightgbm",
        "author": "Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan",
        "title": "Lightgbm: A highly efficient gradient boosting decision tree"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hochreiter1997long",
        "author": "Sepp Hochreiter and J\u00fcrgen Schmidhuber",
        "title": "Long Short-Term Memory"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zeng_are_2022",
        "author": "Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang",
        "title": "Are {Transformers} {Effective} for {Time} {Series} {Forecasting}?"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Oreshkin2020",
        "author": "Boris N. Oreshkin and Dmitri Carpov and Nicolas Chapados and Yoshua Bengio",
        "title": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "challu2023nhits",
        "author": "Challu, Cristian and Olivares, Kin G and Oreshkin, Boris N and Ramirez, Federico Garza and Canseco, Max Mergenthaler and Dubrawski, Artur",
        "title": "Nhits: Neural hierarchical interpolation for time series forecasting"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhou2021informer",
        "author": "Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai",
        "title": "Informer: Beyond efficient transformer for long sequence time-series forecasting"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2022pyraformer",
        "author": "Shizhan Liu and Hang Yu and Cong Liao and Jianguo Li and Weiyao Lin and Alex X. Liu and Schahram Dustdar",
        "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wu2021autoformer",
        "author": "Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng",
        "title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhou2022fedformer",
        "author": "Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong",
        "title": "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhang2023crossformer",
        "author": "Zhang, Yunhao and Yan, Junchi",
        "title": "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wu_timesnet_2023",
        "author": "Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng",
        "title": "{TimesNet}: {Temporal} {2D}-{Variation} {Modeling} for {General} {Time} {Series} {Analysis}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "xue2023promptcast",
        "author": "Xue, Hao and Salim, Flora D",
        "title": "Promptcast: A new prompt-based learning paradigm for time series forecasting"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "gruver2024large",
        "author": "Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew G",
        "title": "Large language models are zero-shot time series forecasters"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "sun2023test",
        "author": "Sun, Chenxi and Li, Yaliang and Li, Hongyan and Hong, Shenda",
        "title": "TEST: Text prototype aligned embedding to activate LLM's ability for time series"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "chang2023llm4ts",
        "author": "Chang, Ching and Peng, Wen-Chih and Chen, Tien-Fu",
        "title": "Llm4ts: Two-stage fine-tuning for time-series forecasting with pre-trained llms"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "cao2023tempo",
        "author": "Cao, Defu and Jia, Furong and Arik, Sercan O and Pfister, Tomas and Zheng, Yixiang and Ye, Wen and Liu, Yan",
        "title": "Tempo: Prompt-based generative pre-trained transformer for time series forecasting"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "ekambaram2024ttms",
        "author": "Ekambaram, Vijay and Jati, Arindam and Nguyen, Nam H and Dayama, Pankaj and Reddy, Chandra and Gifford, Wesley M and Kalagnanam, Jayant",
        "title": "TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "liu2024timer",
        "author": "Yong Liu and Haoran Zhang and Chenyu Li and Xiangdong Huang and Jianmin Wang and Mingsheng Long",
        "title": "Timer: Generative Pre-trained Transformers Are Large Time Series Models"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "woo2024unified",
        "author": "Woo, Gerald and Liu, Chenghao and Kumar, Akshat and Xiong, Caiming and Savarese, Silvio and Sahoo, Doyen",
        "title": "Unified training of universal time series forecasting transformers"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "garza2023timegpt",
        "author": "Garza, Azul and Mergenthaler-Canseco, Max",
        "title": "TimeGPT-1"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "rasul2023lag",
        "author": "Rasul, Kashif and Ashok, Arjun and Williams, Andrew Robert and Khorasani, Arian and Adamopoulos, George and Bhagwatkar, Rishika and Bilo{\\v{s}}, Marin and Ghonia, Hena and Hassen, Nadhir Vincent and Schneider, Anderson and others",
        "title": "Lag-llama: Towards foundation models for time series forecasting"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "ansari2024chronos",
        "author": "Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Sundar and Arango, Sebastian Pineda and Kapoor, Shubham and others",
        "title": "Chronos: Learning the Language of Time Series"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "ansari2024chronos",
        "author": "Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Sundar and Arango, Sebastian Pineda and Kapoor, Shubham and others",
        "title": "Chronos: Learning the Language of Time Series"
      }
    ]
  }
]