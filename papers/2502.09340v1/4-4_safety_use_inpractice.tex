
\subsection{\texorpdfstring{\colorbox[RGB]{242,96,119}{Safety and Use in Practice}}{Safety and Use in Practice}}
\label{ssec:chall:safety}

Human-model interaction has been identified as an open challenge of \ppms~\cite{Nauta2023_wcxai_co-12-for-prototype-models} and has been applied to improve the semantics of prototypes~\cite{Bontempelli_2023_ConceptlevelDebuggingPartPrototype,Li_2024_ImprovingPrototypicalVisual}.
However, while interaction provides valuable human feedback, it carries the risk of reducing the predictive accuracy of the model if the learned features of the model do not match human intuition~\cite{Li_2024_ImprovingPrototypicalVisual}, or of corrupting the model if the human supervision provided is adversarial~\cite{Bontempelli_2023_ConceptlevelDebuggingPartPrototype}.
Another safety concern is training data bias, which \ppms are vulnerable to~\cite{Carmichael_2024_ThisProbablyLooks}, as well as adversarial attacks that may compromise the model's decision making process~\cite{Rymarczyk_2023_ProtoMILMultipleInstance}.


In addition to safety concerns, \ppms face several challenges that make them unusable in practice: The learned prototypes currently struggle to generalize to cases outside of the training data~\citep{Wang_2023_PROMINETPrototypebasedMultiView}, and are not always helpful in understanding the model's prediction. Furthermore, models lack intuitive interfaces to visualize the predictions in a user-friendly way~\citep{Wang_2023_PROMINETPrototypebasedMultiView}. 
There is also limited exploration of possible future application areas of \ppms with domain experts~\cite{Fauvel_2023_LightweightEfficientExplainablebyDesign}.   

\textit{The use of \ppms in practice requires balancing the development of interactive models that learn from human feedback while remaining resilient against adversarial supervision.}


