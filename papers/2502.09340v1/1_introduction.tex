Machine learning systems are increasingly adopted in high-stake domains, from autonomous vehicles (e.g.,~\citealt{Liao_2024_CDSTraj}), to finance (e.g.,~\citealt{Zhou_2024_Astrategicanalysis}), and healthcare (e.g.,~\citealt{Eisemann_2025_Nationwiderealworldimplementation}). 
Operating in areas where trustworthiness is expected~\citep{Li_2023_Trustworthyai}, these systems are required to provide explanations for their decisions. This need for transparency has motivated the rise of eXplainable Artificial Intelligence (XAI). Initially, the focus of XAI has been on building post-hoc methods that explain the reasoning process of already built (black box) models. However, post-hoc methods only approximate the model's predictions without ever reaching perfect faithfulness~\citep{Rudin_2019_Stopexplainingblack}. Thus, a new category of models has emerged that are interpretable by design and transparent about their decision-making process. A prominent class of such ante-hoc models are part-prototype models (\ppms).
To make their predictions, \ppms compare the input data to prototypical parts learned during training. Subsequently, the decision is made based on how similar the prototypical parts are to parts of the input. A schematic of the decision process is shown in Figure~\ref{fig:overview}, top row.

Despite their intrinsic interpretability, \ppms are not yet widely adopted, and often secondary to black box models~\citep{Rudin_2019_Stopexplainingblack}. 
To understand the reasons for this situation, we analyzed recent work (including methods and analysis papers) on \ppms and analyzed open problems and challenges mentioned by the authors. We systematically collected papers from 17 premier venues, published between 2019 and 2024. 
An in-depth analysis of these 45 papers resulted in a taxonomy of challenges with four main categories: i) issues with the quality and amount of prototypes\footnote{A prototype corresponds to the entire object, while prototypical parts and part-prototypes are synonyms and refer to a part of the whole input. 
For brevity, and following most papers on \ppms we use the term `prototypes` in the remainder of this paper.} (category: Prototypes), ii) lack of theoretical foundation and evaluation standards, and limitations in training and inference performance (category: Methodology), iii) limited variety of machine learning tasks and reliance on strong assumptions (category: Generalization), and iv) limitations that prevent safe use in practice (category: Safety and Use in Practice).  
In the second part of this survey, we synthesize the identified challenges and suggest ways to address them. We identify five main research directions and provide more detailed ideas on how to make a significant contribution to the successful application of \ppms in practice.  

\input{1_figure-overview}


\textbf{Relation to other Surveys.} To the best of our knowledge, there is no survey that focuses specifically on \ppms. 
Five surveys in the XAI domain include \ppms and touch on their challenges in terms of the interpretability-accuracy tradeoff~\citep{Ibrahim2022_acm-csur_Explainable-CNNs}, evaluation metrics~\citep{Nauta2023_csur_evaluating-xai-survey,Nauta2023_wcxai_co-12-for-prototype-models}, or from the point of view of specific application areas~\citep{Alpherts2024_facct_perceptive-visual-urban-analytics,Patricio2024_acm-csur_XAI-medical-image-classification}.
However, neither of these surveys systematically analyses open challenges for \ppms, nor includes \ppms designed for modalities other than vision in their analysis.
To address this gap, we focus specifically on \ppms, provide an in-depth analysis of open challenges, and outline directions for further research and application in practice. 

Our survey is organized as follows: Figure~\ref{fig:overview} and Section~\ref{sec:background} provide an introduction to part-prototype models (\ppms). Our survey method is explained in Section~\ref{sec:method}. Figure~\ref{fig:challenges-taxonomy} and Section~\ref{sec:challenges} detail our taxonomy of open challenges. 
We describe promising research directions in Section~\ref{sec:directions} with an overview in Figure~\ref{fig:directions} and conclude in Section~\ref{sec:conclusion}.
