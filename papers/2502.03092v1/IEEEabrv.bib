@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, Brendan and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={374--388},
  year={2019}
}

@article{wangni2018gradient,
  title={Gradient sparsification for communication-efficient distributed optimization},
  author={Wangni, Jianqiao and Wang, Jialei and Liu, Ji and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{strom2015scalable,
  title={Scalable distributed DNN training using commodity GPU cloud computing},
  author={Strom, Nikko},
  booktitle={Sixteenth annual conference of the international speech communication association},
  year={2015}
}

@article{lin2017deep,
  title={Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author={Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
  journal={arXiv preprint arXiv:1712.01887},
  year={2017}
}

@inproceedings{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}

@article{alistarh2017qsgd,
  title={QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{karimireddy2019error,
  title={Error feedback fixes signsgd and other gradient compression schemes},
  author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3252--3261},
  year={2019},
  organization={PMLR}
}

@article{wu2022communication,
  title={Communication-efficient federated learning via knowledge distillation},
  author={Wu, Chuhan and Wu, Fangzhao and Lyu, Lingjuan and Huang, Yongfeng and Xie, Xing},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={1--8},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{li2021communication,
  title={Communication-efficient federated learning based on compressed sensing},
  author={Li, Chengxi and Li, Gang and Varshney, Pramod K},
  journal={IEEE Internet of Things Journal},
  volume={8},
  number={20},
  pages={15531--15541},
  year={2021},
  publisher={IEEE}
}

@article{goetz2020federated,
  title={Federated learning via synthetic data},
  author={Goetz, Jack and Tewari, Ambuj},
  journal={arXiv preprint arXiv:2008.04489},
  year={2020}
}

@article{aji2017sparse,
  title={Sparse communication for distributed gradient descent},
  author={Aji, Alham Fikri and Heafield, Kenneth},
  journal={arXiv preprint arXiv:1704.05021},
  year={2017}
}

@article{sahu2021rethinking,
  title={Rethinking gradient sparsification as total error minimization},
  author={Sahu, Atal and Dutta, Aritra and M Abdelmoniem, Ahmed and Banerjee, Trambak and Canini, Marco and Kalnis, Panos},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8133--8146},
  year={2021}
}

@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth annual conference of the international speech communication association},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@article{hu2022fedsynth,
  title={FedSynth: Gradient Compression via Synthetic Data in Federated Learning},
  author={Hu, Shengyuan and Goetz, Jack and Malik, Kshitiz and Zhan, Hongyuan and Liu, Zhe and Liu, Yue},
  journal={arXiv preprint arXiv:2204.01273},
  year={2022}
}

@article{sattler2019robust,
  title={Robust and communication-efficient federated learning from non-iid data},
  author={Sattler, Felix and Wiedemann, Simon and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3400--3413},
  year={2019},
  publisher={IEEE}
}

@article{deng2012mnist, 
  title={The mnist database of handwritten digit images for machine learning research}, 
  author={Deng, Li}, 
  journal={IEEE Signal Processing Magazine}, 
  volume={29}, 
  number={6}, 
  pages={141--142}, 
  year={2012}, 
  publisher={IEEE} 
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@inproceedings{cohen2017emnist,
  title={EMNIST: Extending MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Van Schaik, Andre},
  booktitle={2017 international joint conference on neural networks (IJCNN)},
  pages={2921--2926},
  year={2017},
  organization={IEEE}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}

@inproceedings{li2022federated,
  title={Federated learning on non-iid data silos: An experimental study},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)},
  pages={965--978},
  year={2022},
  organization={IEEE}
}

@inproceedings{radosavovic2020designing,
  title={Designing network design spaces},
  author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10428--10436},
  year={2020}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{stich2018sparsified,
  title={Sparsified SGD with memory},
  author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{zhou2021communication,
  title={Communication-efficient federated learning with compensated overlap-fedavg},
  author={Zhou, Yuhao and Ye, Qing and Lv, Jiancheng},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={33},
  number={1},
  pages={192--205},
  year={2021},
  publisher={IEEE}
}

@article{ben2019demystifying,
  title={Demystifying parallel and distributed deep learning: An in-depth concurrency analysis},
  author={Ben-Nun, Tal and Hoefler, Torsten},
  journal={ACM Computing Surveys (CSUR)},
  volume={52},
  number={4},
  pages={1--43},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{fedus2021switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  year={2021}
}

@article{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{wang2023batch,
  title={Why Batch Normalization Damage Federated Learning on Non-IID Data?},
  author={Wang, Yanmeng and Shi, Qingjiang and Chang, Tsung-Hui},
  journal={arXiv preprint arXiv:2301.02982},
  year={2023}
}

@inproceedings{zhou2023communication,
  title={Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence},
  author={Zhou, Yuhao and Shi, Mingjia and Li, Yuanxi and Sun, Yanan and Ye, Qing and Lv, Jiancheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5031--5040},
  year={2023}
}

@inproceedings{tan2022fedproto,
  title={Fedproto: Federated prototype learning across heterogeneous clients},
  author={Tan, Yue and Long, Guodong and Liu, Lu and Zhou, Tianyi and Lu, Qinghua and Jiang, Jing and Zhang, Chengqi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={8432--8440},
  year={2022}
}

@article{chen2019communication,
  title={Communication-efficient federated deep learning with layerwise asynchronous model update and temporally weighted aggregation},
  author={Chen, Yang and Sun, Xiaoyan and Jin, Yaochu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={10},
  pages={4229--4238},
  year={2019},
  publisher={IEEE}
}

@inproceedings{radosavovic2018data,
  title={Data distillation: Towards omni-supervised learning},
  author={Radosavovic, Ilija and Doll{\'a}r, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4119--4128},
  year={2018}
}

@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

@article{li2020review,
  title={A review of applications in federated learning},
  author={Li, Li and Fan, Yuxi and Tse, Mike and Lin, Kuo-Yi},
  journal={Computers \& Industrial Engineering},
  volume={149},
  pages={106854},
  year={2020},
  publisher={Elsevier}
}

@article{alistarh2018convergence,
  title={The convergence of sparsified gradient methods},
  author={Alistarh, Dan and Hoefler, Torsten and Johansson, Mikael and Konstantinov, Nikola and Khirirat, Sarit and Renggli, C{\'e}dric},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{shi2023prior,
  title={PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning},
  author={Shi, Mingjia and Zhou, Yuhao and Wang, Kai and Zhang, Huaizheng and Huang, Shudong and Ye, Qing and Lv, Jiangcheng},
  journal={Advances in Neural Information Processing System},
  year={2023}
}

@article{chen2021communication,
  title={Communication-efficient federated learning},
  author={Chen, Mingzhe and Shlezinger, Nir and Poor, H Vincent and Eldar, Yonina C and Cui, Shuguang},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={17},
  pages={e2024789118},
  year={2021},
  publisher={National Acad Sciences}
}

@article{candes2006robust,
  title={Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information},
  author={Cand{\`e}s, Emmanuel J and Romberg, Justin and Tao, Terence},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={2},
  pages={489--509},
  year={2006},
  publisher={IEEE}
}

@article{denil2013predicting,
  title={Predicting parameters in deep learning},
  author={Denil, Misha and Shakibi, Babak and Dinh, Laurent and Ranzato, Marc'Aurelio and De Freitas, Nando},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{zhu2019deep,
  title={Deep leakage from gradients},
  author={Zhu, Ligeng and Liu, Zhijian and Han, Song},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{izzo2023theoretical,
  title={A Theoretical Study of Dataset Distillation},
  author={Izzo, Zachary and Zou, James},
  booktitle={NeurIPS 2023 Workshop on Mathematics of Modern Machine Learning},
  year={2023}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{xu2022detached,
  title={Detached Error Feedback for Distributed SGD with Random Sparsification},
  author={Xu, An and Huang, Heng},
  booktitle={International Conference on Machine Learning},
  pages={24550--24575},
  year={2022},
  organization={PMLR}
}

@inproceedings{xu2021step,
  title={Step-ahead error feedback for distributed training with compressed gradient},
  author={Xu, An and Huo, Zhouyuan and Huang, Heng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10478--10486},
  year={2021}
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@inproceedings{tang2024z,
  title={z-signfedavg: A unified stochastic sign-based compression for federated learning},
  author={Tang, Zhiwei and Wang, Yanmeng and Chang, Tsung-Hui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={15301--15309},
  year={2024}
}

@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{qi2021federated,
  title={Federated reinforcement learning: Techniques, applications, and open challenges},
  author={Qi, Jiaju and Zhou, Qihao and Lei, Lei and Zheng, Kan},
  journal={arXiv preprint arXiv:2108.11887},
  year={2021}
}

@article{t2020personalized,
  title={Personalized federated learning with moreau envelopes},
  author={T Dinh, Canh and Tran, Nguyen and Nguyen, Josh},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21394--21405},
  year={2020}
}

@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International conference on machine learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}

@article{bejani2021systematic,
  title={A systematic review on overfitting control in shallow and deep neural networks},
  author={Bejani, Mohammad Mahdi and Ghatee, Mehdi},
  journal={Artificial Intelligence Review},
  volume={54},
  number={8},
  pages={6391--6438},
  year={2021},
  publisher={Springer}
}

@article{zhao2020idlg,
  title={idlg: Improved deep leakage from gradients},
  author={Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan},
  journal={arXiv preprint arXiv:2001.02610},
  year={2020}
}

@article{yang2023gradient,
  title={Gradient leakage attacks in federated learning: Research frontiers, taxonomy and future directions},
  author={Yang, Haomiao and Ge, Mengyu and Xue, Dongyun and Xiang, Kunlan and Li, Hongwei and Lu, Rongxing},
  journal={IEEE Network},
  year={2023},
  publisher={IEEE}
}

@article{huang2005maximum,
  title={Maximum likelihood estimation of Dirichlet distribution parameters},
  author={Huang, Jonathan},
  journal={CMU Technique report},
  volume={76},
  year={2005},
  publisher={Citeseer}
}

@inproceedings{DBLP:conf/icmcs/TianY0LR0024,
  author       = {Yuxin Tian and
                  Mouxing Yang and
                  Yunfan Li and
                  Dayiheng Liu and
                  Xingzhang Ren and
                  Xi Peng and
                  Jiancheng Lv},
  title        = {An Empirical Study of Parameter Efficient Fine-tuning on Vision-Language
                  Pre-train Model},
  booktitle    = {{IEEE} International Conference on Multimedia and Expo, {ICME} 2024},
  pages        = {1--6}
}

@article{DBLP:journals/tsmc/TianLYWPL24,
  author       = {Yuxin Tian and
                  Yijie Lin and
                  Qing Ye and
                  Jian Wang and
                  Xi Peng and
                  Jiancheng Lv},
  title        = {{UNITE:} Multitask Learning With Sufficient Feature for Dense Prediction},
  journal      = {{IEEE} Trans. Syst. Man Cybern. Syst.},
  volume       = {54},
  number       = {8},
  pages        = {5012--5024},
  year         = {2024}
}

@article{zhou2024defta,
  title={DeFTA: A plug-and-play peer-to-peer decentralized federated learning framework},
  author={Zhou, Yuhao and Shi, Minjia and Tian, Yuxin and Ye, Qing and Lv, Jiancheng},
  journal={Information Sciences},
  volume={670},
  pages={120582},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{zhou2024federated,
  title={Federated CINN Clustering for Accurate Clustered Federated Learning},
  author={Zhou, Yuhao and Shi, Minjia and Tian, Yuxin and Li, Yuanxi and Ye, Qing and Lv, Jiancheng},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5590--5594},
  year={2024},
  organization={IEEE}
}