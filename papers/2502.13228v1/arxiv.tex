\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} %

\usepackage{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}


\usepackage[accepted]{icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage[capitalize,noabbrev]{cleveref}

\usepackage{amsmath}
\usepackage{thmtools}
\usepackage{bbm}
\usepackage{epigraph}
\usepackage{threeparttable}
\usepackage[group-separator={,}]{siunitx}

\input{custom}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}



\icmltitlerunning{Conformal Prediction as Bayesian Quadrature}

\begin{document}

\twocolumn[
\icmltitle{Conformal Prediction as Bayesian Quadrature}




\begin{icmlauthorlist}
\icmlauthor{Jake C. Snell}{cs}
\icmlauthor{Thomas L. Griffiths}{cs,psych}
\end{icmlauthorlist}

\icmlaffiliation{psych}{Department of Psychology, Princeton University}
\icmlaffiliation{cs}{Department of Computer Science, Princeton University}

\icmlcorrespondingauthor{Jake C. Snell}{jsnell@princeton.edu}

\icmlkeywords{Conformal Prediction, Bayesian Quadrature, Uncertainty Quantification}

\vskip 0.3in
]



\printAffiliationsAndNotice{}  %

\begin{abstract}
As machine learning-based prediction systems are increasingly used in
high-stakes situations, it is important to understand how such predictive models
will perform upon deployment. Distribution-free uncertainty quantification
techniques such as conformal prediction provide guarantees about the loss
black-box models will incur even when the details of the models are hidden.
However, such methods are based on frequentist probability, which unduly limits
their applicability.  We revisit the central aspects of conformal prediction
from a Bayesian perspective and thereby illuminate the shortcomings of
frequentist guarantees. We propose a practical alternative based on Bayesian
quadrature that provides interpretable guarantees and offers a richer
representation of the likely range of losses to be observed at test time.
\end{abstract}

\section{Introduction}

Machine learning systems based on deep learning are increasingly used in high-stakes settings, such as medical diagnosis or financial applications. These settings impose unique constraints on the performance of these systems: we want them to produce good outcomes in the aggregate, but also do so fairly and with a guarantee of a low probability of harm. However, predictive models based on deep learning can be difficult to interpret, and commercial models increasingly tend to offer little information about the techniques used in training. This creates a new challenge: How can we flexibly and reliably quantify the
suitability of a model for deployment without making too many assumptions about how the model was trained or in which settings it will be used?

Recent research on quantifying uncertainty has employed methods based on conformal prediction~\citep{vovk2005algorithmic}, which aim to provide guarantees for model performance in a distribution-free way. However, these techniques are based on ideas from frequentist statistics, making it difficult to %
incorporate prior knowledge that might be available about specific models. For example, in a particular setting we might have access to some information about the distribution of the data that is likely to be encountered, and can construct tighter guarantees on the performance of models by making use of this information. Moreover, they focus on controlling the expected loss averaged over many unobserved datasets rather than focusing on the actual set of observations.

In this paper, we show how methods for guaranteeing model performance can be understood and extended by viewing them from a Bayesian perspective. We develop a framework in which we explicitly model uncertainty in the quantile values associated with particular observations, providing a nonparametric tool for characterizing possible distributions where the model might be deployed that is appropriately constrained by observed data. This framework allows us to draw upon methods from the fields of statistical prediction analysis \citep{aitchison1975statistical} and probabilistic numerics \citep{cockayne2019bayesian,hennig2022probabilistic} to develop  guarantees that are interpretable and make adaptive use of available information.

We show that two popular uncertainty quantification methods, split conformal prediction \citep{vovk2005algorithmic, papadopoulos2002inductive} and conformal risk control \citep{angelopoulos2024conformal}, can both be recovered as special cases of our framework. Our approach gives a more complete characterization of the performance of these approaches, as we are able to determine the full distribution of possible outcomes rather than a single point estimate. Since our approach is grounded in Bayesian probability, we can easily incorporate knowledge relevant to evaluating the performance of these models when it is present, such as monotonicity or distributional assumptions, while defaulting to existing methods when absent. Our results show that Bayesian probability, while it is often discarded due to the apparent need to specify prior distributions, is actually well-suited for distribution-free uncertainty quantification.






\section{Background}

Conformal prediction methods apply a wrapper on top of black-box predictive models to be able to subject them to statistical analysis. In order to generate meaningful predictions about future performance, it is assumed that we have access to a small calibration dataset that is representative of the deployment conditions. %
Performance on this dataset then provides the foundation for generating predictions about future performance. We begin by reviewing existing current distribution-free uncertainty quantification techniques and Bayesian quadrature methods.

\subsection{Distribution-free Uncertainty Quantification Techniques}\label{sec:background_conformal}

Uncertainty quantification techniques provide guarantees on the future performance of a black-box predictive model mapping inputs $X$ to outputs $Y$ based on a calibration set consisting of $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_n$. Different approaches do so in different ways.
For more information on these techniques, refer to \citet{shafer2008tutorial} or \citet{angelopoulos2023conformal}.
\paragraph{Split Conformal Prediction} The goal of Split Conformal Prediction~\citep{vovk2005algorithmic,papadopoulos2002inductive} is to generate a prediction set or interval that contains the ground-truth output with high probability. This is often expressed in terms of the coverage level $1 - \alpha$. It relies on a score function $s(x, y)$ which measures the disagreement between a predictor's output and the ground truth.

The conformal guarantee is
\begin{equation}
    \Pr\left(Y_{n+1} \notin \mathcal{C}(X_{n+1}) \right) \le \alpha \label{eq:conformal_guarantee},
\end{equation}
where
\begin{equation}
    \mathcal{C}(X_{n+1}) = \left\{ y : s(X_{n+1}, y) \le \hat{q} \right\}\label{eq:conformal_prediction_set}
\end{equation}
and
    $\hat{q}$ is the $\frac{\lceil (n+1)(1-\alpha) \rceil}{n}$ quantile of  $s_1 = s(X_1, Y_1), \ldots, s_n = s(X_n, Y_n)$.
Here, $\mathcal{C}(X_{{n+1}})$ is a prediction set or interval which aims to include the ground-truth output.
\paragraph{Conformal Risk Control} In Conformal Risk Control~\citep{angelopoulos2024conformal}, the goal is to generalize conformal prediction to more general loss functions that are monotonic functions of a single parameter $\lambda$. Conformal Risk Control (CRC) proceeds by viewing the coverage guarantee~\eqref{eq:conformal_guarantee} as the expected value of a 0-1 loss. It is assumed that the maximum possible value of the loss is $B$ and that the problem is ``achievable'' by design in that there exists some setting $\lambda_\text{max}$ that satisfies the conformal guarantee. Additionally, each loss function $L_i(\lambda)$ is assumed to be a monotonic non-increasing function of $\lambda$. The guarantee offered by Conformal Risk Control is of the  form
\begin{equation}
    E \left( \ell(\mathcal{C}_{\hat{\lambda}}(X_{n+1}), Y_{n+1}) \right) \le \alpha,\label{eq:crc_guarantee}
\end{equation}
where
\begin{equation}
    \hat{\lambda} = \inf \left\{ \lambda : \frac{n}{n+1} \hat{R}_n(\lambda) + \frac{B}{n+1} \le \alpha \right\} \label{eq:crc_estimator}
\end{equation}
and $\hat{R}_n(\lambda) = \frac{1}{n} \sum_{i=1}^n L_i(\lambda)$ is the empirical risk.

\subsection{Bayesian Quadrature}\label{sec:bayesquad}

Bayesian quadrature~\citep{diaconis1988bayesian,ohagan1991bayes} is a general technique for evaluating integrals that allows for uncertainty in the integrand. It estimates the value of an integral $\int_{a}^{b} f(x) \, dx$ by the following four steps: (1) place a prior $p(f)$ on functions, (2) evaluate $f$ at $x_{1}, x_{2}, \ldots, x_{n}$, (3) compute a posterior given the observed values of $f$ by Bayes' rule, and (4) estimate $\int_{a}^{b} f(x) \, dx$. Suppose that $f(x_{i}) = y_{i}$ for $i = 1, 2, \ldots, n$. The posterior over $f$ is %
\begin{equation}
  p(f \mid x_{1:n}, y_{1:n}) \propto p(f) \prod_{i=1}^{n} \delta(y_{i} - f(x_{i})),\label{eq:bayesquad_posterior}
\end{equation}
where $\delta(\cdot)$ is the Dirac delta function. The posterior mean then provides an estimate for the integral:
\begin{align}
  \int_{a}^{b} f(x) \, dx &\approx \int_{a}^{b} f_{n}(x) \,dx, \text{ where } \\
  f_{n}(t) &= E(f(t) \mid x_{1:n}, y_{1:n} ).
\end{align}
It has been demonstrated that many classical quadrature procedures such as the trapezoid rule can be recovered by placing a Gaussian process prior on functions~\citep{karvonen2017classical}.


\subsection{Summary and Prospectus}%

Bayesian quadrature provides an illustration of how a primarily numerical method can be connected to Bayesian inference, and in doing so potentially admit additional information about the underlying function that can be incorporated via a prior distribution. In next section, we will see how a similar approach can be applied to conformal prediction, identifying a Bayesian framework that reproduces existing distribution-free uncertainty quantification techniques. The challenge in doing so is that we want guarantees of the style obtained from Bayesian models, but we want to make the approach as general as possible in its assumptions about the underlying distribution. We solve this problem via an approach inspired by probabilistic numerics to construct a nonparametric characterization of the underlying distribution based on the calibration set.

\section{Decision-theoretic Formulation}\label{sec:decisiontheory}
In this section we show how split conformal prediction and conformal risk control can be formulated as instances of a general decision problem.

Let $z = (z_{1}, \ldots, z_{n})$ be a set of calibration data where each observation $z_{i} = (x_{i}, y_{i})$ consists of an input and a ground truth label. Let $\theta$ denote the true state of nature that defines a shared density $f(z_{i} \mid \theta)$ for the data.\footnote{In the interest of notational convenience, we assume densities and integrals over $z_{i}$ but these may be replaced by probability mass functions and summations as appropriate.} A new test point $z_{\text{new}}$ is assumed to have the same distribution. Let $\lambda$ be a control parameter (e.g.\ threshold) that must be chosen based on the calibration data. We assume the presence of a loss function $L(\theta, \lambda)$ which quantifies the loss incurred by selecting $\lambda$ when the true state of nature is $\theta$.

The decision-theoretic goal is to choose a decision rule $\lambda(z)$ that controls the \emph{risk}:
\begin{equation}
  R(\theta, \lambda) = \int L(\theta, \lambda(z)) f(z \mid \theta) \, dz.\label{eq:risk_definition}
\end{equation}
It is often desirable to choose $\lambda$ so that it is robust to any possible state of nature $\theta$. The \emph{maximum risk} is defined as
\begin{equation}
  \bar{R}(\lambda) = \sup_{\theta} R(\theta, \lambda).\label{eq:maximum_risk}
\end{equation}
In distribution-free uncertainty quantification applications, it is often trivial to achieve arbitrarily low risk (for example by forming prediction sets covering the entire output space). We thus want to find decision rules whose risk is upper bounded by a constant $\alpha$:
\begin{equation}
    \bar{R}(\lambda) \le \alpha,\label{eq:alpha_acceptable_risk}
\end{equation}
and use another criterion (such as expected prediction set size) to select among these.  We call a rule that satisfies~\eqref{eq:alpha_acceptable_risk} an \emph{$\alpha$-acceptable decision rule}.

\subsection{Recovering Split Conformal Prediction}
We now show how split conformal prediction is a special case of this decision-theoretic problem. Let $L_{\text{scp}}(\theta, \lambda)$ be the \emph{miscoverage loss}:
\begin{align}
  L_{\text{scp}}(\theta, \lambda) &= \Pr \{ s(z_{\text{new}}) > \lambda \}\label{eq:miscoverage_loss}\\
  &= 1 - \Pr \{ s(z_{\text{new}}) \le \lambda \} \nonumber \\
  &= 1 - \int \mathbbm{1} \{ s(z_{\text{new}}) \le \lambda \} f(z_{\text{new}} \mid \theta) \, d z_{\text{new}} \nonumber,
\end{align}
where $s$ is an arbitrary nonconformity function.
\begin{restatable}[]{proposition}{scprule}\label{thm:scprule}
  Define $s_{i} \triangleq s(z_{i})$ for $i = 1, \ldots, n$ and let $s_{(1)} \le s_{(2)} \le \ldots \le s_{(n)}$ be the corresponding order statistics. Let $\lambda_{\mathrm{scp}}$ be the following decision rule:
  \begin{equation}
    \lambda_{\mathrm{scp}} = \begin{cases}s_{(\lceil (n + 1) (1 - \alpha) \rceil)}, & \mathrm{if}\, \lceil (n + 1)(1 - \alpha)\rceil \le n \\ \infty, &\mathrm{otherwise}. \end{cases}\label{eq:scprule_formula}
  \end{equation}
  Then $\lambda_{\mathrm{scp}}$ is an $\alpha$-acceptable decision rule for the miscoverage loss $L_{\mathrm{scp}}$ defined in~\eqref{eq:miscoverage_loss}.
\end{restatable}
\begin{proof}
  Proofs for all theoretical results may be found in Appendix~\ref{sec:appendix_proofs}.
\end{proof}
Therefore the prediction set can be constructed as in~\eqref{eq:conformal_prediction_set}:
\begin{equation}
  \mathcal{C}_{\text{scp}}(x_{\text{new}}) = \{ y \in \mathcal{Y} : s(x_{\text{new}}, y) \le \lambda_{\text{scp}}\},
\end{equation}
and by \Cref{thm:scprule}, $\mathcal{C}_{\text{scp}}$ satisfies the conformal guarantee from~\eqref{eq:conformal_guarantee}.

\subsection{Recovering Conformal Risk Control}
Conformal risk control generalizes split conformal prediction by considering losses that are monotonic non-increasing functions of a single parameter $\lambda$.
\begin{equation}
  L_{\text{crc}}(\theta, \lambda) = \int \ell(z_{\text{new}}, \lambda) f(z_{\text{new}} \mid \theta)\, d z_{\text{new}},\label{eq:crc_loss}
\end{equation}
where $\ell(z_{\text{new}}, \lambda)$ is an individual loss function that is monotonically non-increasing in $\lambda$.
\begin{restatable}[]{proposition}{crcrule}\label{thm:crcrule}
  Let $\lambda_{\mathrm{crc}}$ be the following decision rule:
  \begin{equation}
    \lambda_{\mathrm{crc}} = \inf \left\{ \lambda : \frac{1}{n+1} \left(  \sum_{i=1}^{n} \ell(z_{i}, \lambda) + B \right) \le \alpha \right\}.\label{eq:crcrule_formula}
  \end{equation}
  Then $\lambda_{\mathrm{crc}}$ is an $\alpha$-acceptable decision rule for $L_{\mathrm{crc}}$ defined in~\eqref{eq:crc_loss}.
\end{restatable}
Note in particular that when $\ell(z, \lambda)$ can be expressed in the form  $\ell(\mathcal{C}_{\lambda}(x_{n + 1}), y_{n+1})$, this recovers the conformal risk control guarantee from~\eqref{eq:crc_guarantee}.

\section{Our Approach}\label{sec:our_method}

We introduce our approach by reinterpeting conformal prediction as a frequentist special case of a more general Bayesian procedure. In order to do so, we borrow ideas from both Bayesian quadrature~\citep{diaconis1988bayesian,ohagan1991bayes} and distribution-free tolerance regions~\citep{guttman1970statistical}. Bayesian quadrature (Section~\ref{sec:bayesquad}) solves a numerical integration problem by placing a prior on functions and using Bayesian inference to compute a distribution over the value of the integral. Distribution-free tolerance regions provide a distribution over quantile spacings that holds regardless of the original underlying distribution. Putting these ideas together allows us to extend conformal prediction by producing bounds on expected loss tailored to the actual losses observed in the calibration set.

The remainder of this section is structured as follows. In Section~\ref{sec:bayes_risk}, we discuss the relationship between risk control and Bayes risk.  In Section~\ref{sec:methods_goal}, we describe a general approach for using Bayesian quadrature to bound the posterior risk. In Section~\ref{sec:consquantile}, we make the quadrature ``distribution-free'' by removing the dependence on a prior over functions. In Section~\ref{sec:methods_quantiles} we handle uncertainty in the evaluation locations of the function by applying results that characterize the spacing between consecutive quantiles. In Section~\ref{sec:dfub_construction}, we show how to use these results to produce an upper bound on the expected loss. Finally, in Section~\ref{sec:our_recovery}, we show how previous conformal prediction techniques can be viewed as a special case of our procedure that only considers the expectation of the posterior loss.


\subsection{Bayes Risk}\label{sec:bayes_risk}
The risk $R(\theta, \lambda)$ measures the expected loss for one who already knows the true state of nature $\theta$ but not the particular data observed. However, in practical applications the situation is reversed: we \emph{do} know the observed data but there is uncertainty about the state of nature. Therefore, we want a decision rule that protects against high loss for a range of possible $\theta$. This idea is expressed as the \emph{integrated risk}:
\begin{equation}
  r(\pi, \lambda) = \int R(\theta, \lambda) \pi(\theta) \, d\theta,\label{eq:bayes_risk}
\end{equation}
where the prior $\pi(\theta) \ge 0$ measures the relative importance of the different possible states of nature. It is well-known that the minimizer of the integrated risk is the so-called \emph{Bayes decision rule}:
\begin{align}
  \lambda^{\pi} &\triangleq \argmin_{\lambda} r(\lambda \mid z),
\end{align}
where $r(\lambda \mid z)$ is the \emph{posterior risk}
\begin{equation}
  r(\lambda \mid z) = E(L_\lambda \mid z) = \int L(\theta, \lambda(z)) \pi(\theta \mid z) \,d\theta,\label{eq:posterior_risk}
\end{equation}
and $\pi(\theta \mid z) \propto \pi(\theta) f(z \mid \theta)$. Interestingly, the worst-case integrated risk of a decision rule is identical to its maximum risk~\eqref{eq:maximum_risk}
\begin{equation}
  \bar{r}(\lambda) \triangleq \sup_{\pi} r(\pi, \lambda) = \sup_{\theta} R(\theta, \lambda) = \bar{R}(\lambda).\label{eq:worst_integrated_risk}
\end{equation}
We can therefore focus on bounding the worst-case integrated risk $\bar{r}(\lambda)$, since this will also bound the maximum risk $\bar{R}(\lambda)$.

\subsection{Reformulation as Bayesian Quadrature}\label{sec:methods_goal}
We now turn our attention to finding $\lambda$ minimizing the posterior risk~\eqref{eq:posterior_risk}. Consider risks that can be expressed as the expectation over individual losses:
\begin{equation}
    L(\theta, \lambda) = \int \ell( z_{\text{new}}, \lambda) f(z_{\text{new}} \mid \theta) \, dz_{\text{new}}.
\end{equation}
It is well-known that the expectation of a random variable is equal to the definite integral of its quantile function over its domain~\citep[p.~116]{shorack2000probability}. Consider the distribution function of individual losses induced by $\lambda$ for a particular value of $\theta$:
\begin{equation}
    F(\ell) \triangleq \Pr \{ \ell(z_\text{new}, \lambda) \le \ell \mid \theta \}
\end{equation}
The corresponding quantile function is:
\begin{equation}
    K(t) \equiv F^{-1}(t) = \inf \{ \ell: F(\ell) \ge t \},
\end{equation}
and the expected loss given $K$ is simply $\int_0^1 K(t) \,dt$.

Instead of performing posterior inference over $\theta$, we propose to take an approach inspired by Bayesian quadrature that places a corresponding prior over $K$. Please refer to Figure~\ref{fig:prob_numerics} for a schematic overview of Bayesian quadrature in this setting.
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/bernstein4_v3.png}
    \vspace*{-6mm}
    \caption{Bayesian quadrature produces a posterior distribution over the expected loss when applied to the quantile function of the loss distribution. Left: The expected value $L$ of a random variable with distribution function $F(\ell)$ may be computed as the definite integral of the corresponding quantile function $K(t) \equiv F^{-1}(t)$. Middle: When there is uncertainty about $K$, Bayesian quadrature places a prior on $K$ and uses Bayesian inference to obtain a posterior distribution over functions. Right: The posterior over $K$ induces a corresponding posterior over the expected value.}\label{fig:prob_numerics}
\end{figure*}
The posterior risk given the observed individual losses $\ell_i \triangleq \ell(z_i, \lambda)$ for $i = 1, \ldots, n$ becomes:
\begin{equation}
    E(L \mid \ell_{1:n}) = \int J[K]  p(K \mid \ell_{1:n}) \,dK,
\end{equation}
where $J[K] \triangleq \int_0^1 K(t)\,dt$ and we have suppressed the dependence on $\lambda$ for notational convenience. The posterior over quantile functions can be expressed as:
\begin{align}
\hspace{-5mm}    &p(K \mid \ell_{1:n}) = \int p(K \mid t_{1:n}, \ell_{1:n}) p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &p(K \mid t_{1:n}, \ell_{1:n}) \propto \pi(K) \prod_{i=1}^n \delta(\ell_i - K(t_i)).
\end{align}

This resembles the Bayesian quadrature problem from Section~\ref{sec:bayesquad}, except the evaluation sites $t_{1}, \ldots, t_{n}$ are unknown.  Fortunately, the distribution of $t_{1}, \ldots, t_{n}$ is independent of the true distribution of the losses, as we shall now show.

\subsection{Elimination of the Prior Distribution}\label{sec:consquantile}
In order to address the dependence of the posterior risk on the prior $\pi(K)$, we derive an upper bound on the posterior expected loss. The bound takes the form of a weighted sum of the observed losses, where the weights are determined by the spacing between consecutive quantiles.
\begin{restatable}[]{theorem}{consquantile}\label{thm:consquantile}
  Let $t_{{(0)}} = 0$, $t_{{(n+1)}} = 1$, and $\ell_{{(n+1)}} = B$. Then
  \begin{equation}
    \sup_\pi E(L \mid t_{1:n}, \ell_{1:n}) \le \sum_{i=1}^{n+1} u_{i}\ell_{{(i)}},
  \end{equation}
  where $u_{i} = t_{(i)} - t_{(i-1)}$.
\end{restatable}
\Cref{thm:consquantile} is based on the definite integral of the ``worst-case'' quantile function that is consistent with the observations. This strategy eliminates the need to specify a prior or evaluate an integral over functions $K$. We now turn our attention to handling the uncertainty over the quantiles $t_{1:n}$.

\subsection{Random Quantile Spacings}\label{sec:methods_quantiles}

We now appeal to a result about distribution-free tolerance regions that characterizes the distribution of spacings between consecutive ordered quantiles. Knowledge of this distribution will allow us to handle the input noise in the quadrature problem.

\begin{restatable}[Distribution of Quantile Spacings~\protect{\citep[p.~140]{aitchison1975statistical}}]{lemma}{dirspacings}\label{thm:dirspacings}
Suppose that $\ell_1, \ldots, \ell_n$ are drawn i.i.d.\ with continuous\footnote{The correspondence to a Dirichlet distribution holds exactly for continuous distributions. Weighted sums of Dirichlet random variates stochastically dominate weighted sums of discrete quantile spacings, and thus due to space constraints we only consider continuous distributions here.} distribution function $F$. Let $t_i = F(\ell_{i})$ and $u_i = t_{(i)} - t_{(i-1)}$, where by convention $t_{(0)} = 0$ and $t_{(n+1)} = 1$. Then $(u_1, u_2, \ldots, u_{n+1}) \cong \Dir(1, \ldots, 1)$.
\end{restatable}
We are now ready to present our algorithm for bounding the expected loss $E(L \mid \ell_{1:n})$.
\subsection{Bound on Maximum Posterior Risk}\label{sec:dfub_construction}
Putting together \Cref{thm:dirspacings} and \Cref{thm:consquantile} allows us to bound the maximum posterior risk.
\begin{restatable}[]{theorem}{stochasticub}\label{thm:stochasticub}
Define $\ell_{(i)}$ to be the order statistics of $\ell_1, \ldots, \ell_n$ for $i = 1, \ldots, n$ and $\ell_{(n+1)} \triangleq B$. Let $L^{+}$ be the random variable defined as follows:
\begin{equation}
U_{1}, \ldots, U_{n+1} \sim \Dir(1, \ldots, 1),\,  L^{+} = \sum_{i=1}^{n+1} U_{i} \ell_{{(i)}}.\label{eq:l_plus_definition}
\end{equation}
Then for any $b \in \halfclosed{-\infty}{B}$,
\begin{equation}
\inf_\pi \Pr(L \le b \mid \ell_{1:n}) \ge \Pr(L^+ \le b).\label{eq:stochasticub_statement}
\end{equation}
\end{restatable}
\Cref{thm:stochasticub} states that $L^+$ stochastically dominates the posterior risk, which allows us to directly form upper confidence bounds as follows.
\begin{restatable}[]{corollary}{ucbdf}\label{thm:ucbdf}
  For any desired confidence level $\beta \in (0, 1)$, define
  \begin{equation}
    b^{*}_\beta = \inf_{b} \{ b : \Pr(L^{+} \le b \mid \ell_{1:n} ) \ge \beta \}.\label{eq:ucbdf}
  \end{equation}
  Then $\inf_\pi \Pr(L \le b \mid \ell_{1:n}) \ge \beta$ for any $b \ge b^{*}_{\beta}$.
\end{restatable}
The critical value $b^{*}_\beta$ can be calculated by applying techniques for bounding linear combinations of Dirichlet random variables~\citep[p.~63]{ng2011dirichlet}. Alternatively, straightforward Monte Carlo simulation of $L^+$ is often sufficient, and is the approach we take in our experiments. An illustration is shown in Figure~\ref{fig:our_approach_sketch}.
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/quadrature_simulation.png}
    \vspace*{-6mm}
    \caption{Our Bayesian approach to conformal prediction accounts for the variability in quantile levels better than previous approaches. Left: Conformal Risk Control~\citep{angelopoulos2024conformal} considers only the expectation over the unobserved quantile values $t_1, \ldots, t_n$. This can underestimate the true expected loss (shown here: estimated expected loss $0.45$ vs.\ true expected loss $0.50$). Right: Our approach makes use of the fact that the quantile spacings are drawn from a Dirichlet distribution. By considering the full distribution over quantiles, we gain a more complete view of the expected loss. Shown here is one sample drawn from this distribution, which estimates the expected loss as $0.58$.}\label{fig:our_approach_sketch}
\end{figure*}

\subsection{Recovering Conformal Methods}\label{sec:our_recovery}
This perspective puts the previous distribution-free uncertainty techniques in a new light. Taking the expected value of $L^+$, we find
\begin{equation}
    E(L^+) = \sum_{i=1}^{n+1} E(U_i) \ell_{(i)} = \frac{1}{n + 1} \left( \sum_{i=1}^n \ell_i + B \right).
\end{equation}
The Conformal Risk Control decision rule \eqref{eq:crcrule_formula} then is simply the infimum over $\lambda$ for which $E(L^+) \le \alpha$.

For, split conformal prediction, the individual loss is defined as $\ell_i = 1 - \mathbbm{1} \{ s_i \le \lambda \}$. Therefore, suppose that $\lambda = s_{(k)}$. The expected value of $L^+$ then becomes:
\begin{align}
    E(L^+) &= \frac{1}{n+1} \left(n + 1 - \sum_{i=1}^n \mathbbm{1}\{ s_i \le s_{(k)}\} \right) \\
    &= 1 - \frac{k}{n + 1}
\end{align}
Therefore, $E(L^+) \le \alpha$ is satisfied whenever $k \ge (n + 1)(1 - \alpha)$, and in particular by $k^* = \lceil (n + 1) (1 - \alpha) \rceil$. This recovers \eqref{eq:scprule_formula} when $\lceil (n + 1)( 1- \alpha) \rceil \le n$.

Putting these results together, we have recovered standard conformal prediction techniques but have the additional flexibility of considering the distribution of $L^+$ rather than the expected value alone. Our experiments explore the value of this approach.


\section{Experiments}

The primary goal of our experiments is to demonstrate the utility of producing a posterior distribution over the expected loss. We conduct experiments on both syntheticldata and calibration data collected from MS-COCO~\citep{lin2014microsoft}. For each data setting, we randomly generate $M = \num{10000}$ data splits. Each method is used to select $\lambda$ with the goal of controlling the risk such that $R(\theta, \lambda) \le \alpha$ for unknown $\theta$. We compare algorithms on the basis of both the relative frequency of incurring risk greater than $\alpha$ and the prediction set size of the chosen $\lambda$. The ideal algorithm would select $\lambda$ such that the relative frequency of exceeding the target risk is at most a target failure rate of $1 - \beta = 0.05$ while minimizing prediction set size.

As demonstrated in Section~\ref{sec:our_recovery}, our method recovers conformal risk control by taking the expected value of $L^+$. Therefore, in order to demonstrate the effect of targeting a conditional guarantee (as opposed to a marginal one as in conformal risk control), we use our Bayesian quadrature-based method to compute the decision rule based on the one-sided highest posterior density (HPD) interval:
\begin{equation}
    \lambda^{\beta}_{\text{hpd}} \triangleq \inf_\lambda \{ \lambda : \Pr(L^+ \le \alpha \mid \ell_{1:n}) \ge \beta \},
\end{equation}
by finding the corresponding critical values $b_\beta^*$ according to~\eqref{eq:ucbdf} via Monte Carlo simulation of Dirichlet random variates with $\num{1000}$ samples. 
 
\subsection{Synthetic Data}

\paragraph{Setup.} In our synthetic experiments, we sample from a known loss distribution so that we can directly compute the frequency of excessively large risk. Here the loss distribution is chosen to be a scaled binomial distribution, normalized to have a maximum loss of $B = 1$ and probability of failure set to $1 - \lambda$. This was simulated by computing
\begin{equation}
    \ell(z_i, \lambda) = \frac{1}{K} \sum_{k=1}^{K} \mathbbm{1}\{V_{ik} > \lambda \},\label{eq:experimental_loss}
\end{equation}
where $V_{ik} \sim \Uniform(0, 1)$ for $i = 1, \ldots, n$ and $k = 1, \ldots, K$. This loss is therefore monotonically non-increasing in $\lambda$ and achieves zero loss at $\lambda_\text{max} = 1$. We set $n$ = 10, $K = 4$, and $\alpha = 0.4$.

\paragraph{Results.} Since the expectation of the loss \eqref{eq:experimental_loss} is $1 - \lambda$, any trial for which $\lambda < 0.6$ constitutes a risk exceeding the $\alpha$ threshold. The relative frequency of trials exceeding this risk threshold are tabulated in Table~\ref{tab:risk_count}.
\begin{table}[tb]
    \centering
    \begin{threeparttable}
        \caption{Relative frequency of trials (out of 10,000) for which the resulting decision rule $\lambda$ exceeded the target risk threshold $\alpha$. }
        \begin{tabular}{lccc}
        \toprule
        Decision Rule &  Relative Freq. & 95\% CI \\
        \midrule
        CRC & 20.92\% & [20.13\%, 21.73\%] \\
        Ours ($\beta = 0.95$) & 0.11\% & [0.05\%, 0.20\%] \\
        \bottomrule
        \end{tabular}
        \begin{tablenotes}
        \item Note: Error bars are computed as 95\% Clopper-Pearson confidence intervals for binomial proportions.
        \end{tablenotes}
    \end{threeparttable}
    \label{tab:risk_count}
\end{table}
A histogram of the chosen $\lambda$ for each of the methods across all 10,000 trials is shown in Figure~\ref{fig:binomial_comparison}. For conformal risk control, the mean risk across all trials was $0.3363 \pm 0.0007$ and for our approach $\lambda_{\text{hpd}}^{0.95}$ the mean risk was $0.1758 \pm 0.0006$. In order to visualize the distribution of $L^+$, we plot a histogram of $L^+$ according to~\eqref{eq:l_plus_definition} estimated with 100,000 Dirichlet samples for three settings of $\lambda \in \{0.7, 0.8, 0.9\}$. The results are shown in  Figure~\ref{fig:posterior}.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/lambda_hat_composite.png}
  \vspace*{-6mm}
  \caption{Comparison of risk incurred by each procedure across multiple trials. Left: Histogram of the decision rule $\lambda_\text{crc}$ chosen by Conformal Risk Control across $M$ = 10,000 randomly sampled calibration sets. The region where per-trial risk exceeds $\alpha$ is highlighted in red.  Right: Histogram of the $\lambda_\text{hpd}^{0.95}$ chosen according to our 95\% Bayesian posterior interval.}\label{fig:binomial_comparison}
\end{figure*}

\begin{figure}[tb]
  \centering
  \includegraphics[width=\linewidth]{figures/bayesian_posterior.png}
  \vspace*{-6mm}
  \caption{Probability density for $L^+$ with $\lambda \in \{0.7, 0.8, 0.9\}$ estimated using 100,000 Dirichlet samples. }\label{fig:posterior}
\end{figure}

\subsection{False Negative Rate on MS-COCO}

We also compare methods on controlling the false negative rate of multilabel classification on the MS-COCO dataset~\citep{lin2014microsoft}. The experimental setup mirrors that used by~\citet[Section~5.1]{angelopoulos2023conformal}. Each random split contains $\num{1000}$ calibration examples and $\num{3952}$ test examples. We also include Risk-controlling Prediction Sets (RCPS)~\citep{bates2021distributionfree} with Hoeffding upper conﬁdence bound as an additional baseline. The results of this experiment are summarized in Table~\ref{tab:risk_count_mscoco}.

\begin{table}[tb]
    \centering
    \begin{threeparttable}
        \caption{Results on MS-COCO comparing relative frequency of trials for which the resulting decision rule $\lambda$ exceeded the target risk threshold $\alpha$ and average prediction set size.}
        \begin{tabular}{lcc}
        \toprule
        Method &  Relative Freq. & Pred. Set Size\\
        \midrule
        CRC & 43.76\% & 2.93 \\
        RCPS & 0.0\% & 3.57 \\
        Ours ($\beta = 0.95$) & 5.11\% & 3.04 \\
        \bottomrule
        \end{tabular}
    \end{threeparttable}
    \label{tab:risk_count_mscoco}
\end{table}

\section{Discussion}\label{sec:discussion}
\epigraph{An astronaut starting a five-year flight to Mars would not be particularly comforted to be told, ``We are 95 percent confident that the average life of an imaginary population of space vehicles like yours, is at least ten years''. He would much rather hear, ``There is 95 percent probability that \emph{this} vehicle will operate without breakdown for ten years''.}{E.T. Jaynes, Confidence Intervals vs Bayesian Intervals \citep{jaynes1976confidence}}

Our results in Table~\ref{tab:risk_count} demonstrate that even though the Conformal Risk Control marginal guarantee holds, a significant number of individual trials (20.92\%) may incur risk exceeding the target threshold. In contrast, by using the more conservative HPD criterion, very few of the trials (0.11\%) exceeded the target risk. This points to the qualitative difference in a marginal guarantee, which averages over an ``imaginary population'' of unobserved data sets vs.\ a conditional guarantee which focuses on knowledge about the state of nature conditioned on the calibration data actually observed. These results are confirmed in Table~\ref{tab:risk_count_mscoco} on MS-COCO, which show that the marginal guarantees of Conformal Risk Control lead to an even greater percentage of trials exceeding the risk threshold. On the other hand, RCPS is able to control the risk but this comes at the cost of larger prediction sets. Our approach successfully balances these two concerns. It is also clear that the distribution of the expected loss upper bound $L^+$ in Figure~\ref{fig:posterior} provides a more complete view of the range of possible losses and its dependence on $\lambda$, a perspective that is not offered by previous methods.


The limitations of our method lie primarily in the two main assumptions it makes. First, it assumes that the data at deployment time are independent and identically distributed to the calibration data. Second, it assumes an upper bound $B$ on the losses. If either of these assumptions do not hold, then the guarantees produced by our method are no longer valid. Additionally, the bounds produced by our method are conservative in the sense that they hold for any choice of prior for the loss distribution (provided that the prior is consistent with the calibration data). Therefore, if the two aforementioned assumptions do hold, the actual loss values may be significantly less than indicated by our method.


Overall, our approach demonstrates how conformal prediction techniques can be recovered and extended using Bayesian probability, all without having to specify a prior distribution. This Bayesian formulation is highly flexible due to its nonparametric nature, yet is amenable to incorporating specific information about the distribution of losses likely to be encountered. In practical applications, maximizing the risk with respect to all possible priors may be too conservative, and thus future work may explore the effect of specific priors on the risk estimate.


\section{Related Work}

\paragraph{Statistical Prediction Analysis.} Statistical prediction analysis~\citep{aitchison1975statistical} deals with the use of statistical inference to reason about the likely outcomes of future prediction tasks given past ones. Within statistical prediction analysis, the area of distribution-free prediction assumes that the parameters or the form of the distributions involved cannot be identified. This idea can be traced back to \citet{wilks1941determination}, who constructed a method to form distribution-free tolerance regions. \citet{tukey1947nonparametric,tukey1948nonparametric} generalized distribution-free tolerance regions and introduced the concept of statistically equivalent blocks, which are analogous to the intervals between consecutive order statistics of the losses. Much of the relevant theory is summarized by~\citet{guttman1970statistical}, and the Dirichlet distribution of quantile spacing is discussed by~\citet{aitchison1975statistical}. We build upon these works by connecting them to Bayesian quadrature and applying them in the more modern context of distribution-free uncertainty quantification.

\paragraph{Bayesian Quadrature.} The use of Bayesian probability to represent the outcome of a arbitrary computation is termed \emph{probabilistic numerics}~\citep{cockayne2019bayesian,hennig2022probabilistic}. Since our approach is fundamentally based on integration, we focus primarily on the relationship with the more narrow approach of Bayesian quadrature, which employs Bayes rule to estimate the value of an integral. A lucid overview of this approach is discussed under the term \emph{Bayesian numerical analysis} by \citet{diaconis1988bayesian}, who traces it back to the late nineteenth century \citep{poincare1896calcul}. The use of Gaussian processes in performing Bayesian quadrature is discussed in detail by \citet{ohagan1991bayes}. Our approach is formulated similarly but differs in two main ways: (a) we use a conservative bound instead of an explicit prior, and (b) we have input noise induced by the random quantile spacings.

\paragraph{Distribution-Free Uncertainty Quantification.}
Relevant background on distribution-free uncertainty quantification techniques is discussed in Section~\ref{sec:background_conformal}. A recent and comprehensive introduction to conformal prediction and related techniques may be found in~\citep{angelopoulos2023conformal}. Some recent works, like ours, also make use of quantile functions~\citep{snell2023quantile,farzaneh2024quantile} but remain grounded in frequentist probability.  Separately, Bayesian approaches to predictive uncertainty are popular~\citep{hobbhahn2022fast} but make extensive assumptions about the form of the underlying predictive model. To our knowledge, we are the first to apply statistical prediction analysis and Bayesian quadrature in order to analyze the performance of black-box predictive models in a distribution-free way.


\section{Conclusion}

Safely deploying black-box predictive models, such as those based on deep neural networks, requires developing methods that provide guarantees of their performance.  Existing techniques for solving this problem are based on frequentist statistics, and  %
are thus difficult to extend to incorporate knowledge about the situation in which models may be deployed. In this work we provided a Bayesian alternative to distribution-free uncertainty quantification, showing that two popular existing methods are special cases of this approach. Our results show that Bayesian probability can be used to extend uncertainty quantification techniques, making their underlying assumptions more explicit, allowing incorporation of additional knowledge, and providing a more intuitive foundation for constructing performance guarantees that avoids overly-optimistic guarantees that can be produced by existing methods.






\section*{Acknowledgements}

This work was supported by grant N00014-23-1-2510 from the Office of Naval Research.



\bibliography{arxiv}
\bibliographystyle{icml2025}


\newpage
\appendix
\onecolumn

\section{Theoretical Preliminaries}\label{sec:theoretical_preliminaries}

\subsection{Review of Problem Setup}
We first review some relevant aspects of our problem setup.
\paragraph{Loss Function.} We assume an upper bound on the losses: $\ell_i \in \halfclosed{-\infty}{B}$ for $i = 1, \ldots, n$. We assume the same upper bound for $\ell_\text{new}$.

\paragraph{Bayesian Quadrature of Quantile Functions.} Recall Bayes rule for quantile functions:
\begin{equation}
    p(K \mid t_{1:n}, \ell_{1:n}) \propto \pi(K) \prod_{i=1}^n \delta(\ell_i - K(t_i)),\label{eq:posterior_review}
\end{equation}
where $\delta$ is the Dirac delta function. The prior $\pi(K)$ is assumed to be sufficiently expressive to have nonzero measure for the set $\mathcal{K}_n$ of quantile functions such that $K(t_i) = \ell_i$ for $i = 1, \ldots, n$ and $K \in \mathcal{K}_n$. This is necessary to prevent the posterior distribution in~\eqref{eq:posterior_review} from becoming degenerate.

\subsection{Background}
We begin by recalling some basic properties of distribution functions and quantile functions.

\begin{restatable}[Properties of Distribution Functions~\protect{\citep[p.~4]{shao2003mathematical}}]{proposition}{dfproperties}\label{thm:dfproperties}
Let $F(x) = \Pr(X \le x)$ be a distribution function. Then $F(-\infty) = \lim_{x \rightarrow -\infty} F(x) = 0$, $F(\infty) = \lim_{x \rightarrow \infty} F(x) = 1$, $F$ is nondecreasing (i.e., $F(x) \le F(y)$ if $x \le y$), and $F$ is right continuous (i.e., $\lim_{y \rightarrow x, y>x} F(y) = F(x)$).
\end{restatable}

Let $F$ be a distribution function and $K(t) \equiv F^{-1}(t) = \inf \{x : F(x) \ge t \} $ be the corresponding quantile function.

\begin{restatable}[Quantile Functions are Nondecreasing]{proposition}{qfmonotonic}\label{thm:qfmonotonic}
If $t \le u$, then $K(t) \le K(u)$.
\end{restatable}
\begin{proof}
Since $u \ge t$, it follows that $\{ x : F(x) \ge u \} \subseteq \{x : F(x) \ge t \}$. Taking the infimum of both sides yields
\begin{equation}
    \inf \{ x: F(x) \ge u \} \ge \inf \{ x : F(x) \ge t \} \Rightarrow  K(u) \ge K(t).
\end{equation}
\end{proof}

We also will make use of the probability integral transformation, which we state here for convenience.
\begin{restatable}[Probability Integral Transformation~\protect{\citep[p.~5]{shorack2009empirical}}]{proposition}{pit}\label{thm:pit}
    If $X$ has distribution function $F$, then
    \begin{equation}
        \Pr( F(X) \le t) \le t \qquad \text{ for all } 0 \le t \le 1,
    \end{equation}
    with equality failing if and only if $t$ is not in the closure of the range of $F$. Thus if $F$ is continuous, then $T = F(X)$ is $\Uniform(0, 1)$.
\end{restatable}


\section{Proof of Results from the Main Paper}\label{sec:appendix_proofs}
\subsection{Proof of Proposition~\ref{thm:scprule}}
Recall that $L_{\text{scp}}(\theta, \lambda)$ is the \emph{miscoverage loss}:
\begin{align}
  L_{\text{scp}}(\theta, \lambda) &= \Pr \{ s(z_{\text{new}}) > \lambda \}\label{eq:appendix_miscoverage_loss}\\
  &= 1 - \Pr \{ s(z_{\text{new}}) \le \lambda \} \nonumber \\
  &= 1 - \int \mathbbm{1} \{ s(z_{\text{new}}) \le \lambda \} f(z_{\text{new}} \mid \theta) \, d z_{\text{new}} \nonumber,
\end{align}
where $s$ is an arbitrary nonconformity function.
\scprule*
\begin{proof}
By \citet[Section 2]{lei2018distributionfree},
\begin{equation}
    \Pr(s_{\text{new}} \le \hat{q}_{1-\alpha}) \ge 1 - \alpha,
\end{equation}
where
\begin{equation}
    \hat{q}_{1-\alpha} = \begin{cases}
        s_{(\lceil (n+1)(1-\alpha) \rceil} & \text{if }\lceil (n+1)(1-\alpha) \rceil \le n \\
        \infty, & \text{otherwise}.
    \end{cases}
\end{equation}
\end{proof}
But $L_{\text{scp}}(\theta, \lambda) = 1 - \Pr(s_{\text{new}} \le \lambda \mid \theta )$, so for $\lambda = \hat{q}_{1-\alpha}$, $R(\theta, \lambda_\text{scp}) \le \alpha$. This statement not depend on $\theta$, and so $\bar{R}(\lambda_\text{scp}) \le \alpha$.

\subsection{Proof of Proposition~\ref{thm:crcrule}}
Recall that the $L_{\text{crc}}$ is defined as:
\begin{equation}
  L_{\text{crc}}(\theta, \lambda) = \int \ell(z_{\text{new}}, \lambda) f(z_{\text{new}} \mid \theta)\, d z_{\text{new}},
\end{equation}
where $\ell(z_{\text{new}}, \lambda)$ is an individual loss function that is monotonically non-increasing in $\lambda$.
\crcrule*
\begin{proof}
Let $L_1, \ldots, L_n, L_{n+1}$ be an exchangeable collection of non-increasing random functions $L_i : \Lambda \rightarrow \halfclosed{-infty}{B}$. By~\citet[Theorem 1]{angelopoulos2024conformal},
\begin{equation}
    \mathbb{E}[L_{n+1}(\hat{\lambda})] \le \alpha,\label{eq:supplemental_crc_guarantee}
\end{equation}
where
\begin{equation}
    \hat{\lambda} = \inf \left\{\lambda : \frac{n}{n+1} \hat{R}_n(\lambda) + \frac{B}{n+1} \le \alpha \right\}\label{eq:supplemental_crc_lambda_hat}
\end{equation}
and $\hat{R}_n(\lambda) = (L_1(\lambda) + \ldots + L_n(\lambda)) / n$.

Interpreting these results using the notation from Section~3 of the main paper, we identify:
\begin{itemize}
    \item $L_i(\lambda) = \ell(z_i, \lambda)$ for $i=1, \ldots, n$ and $L_{n+1}(\lambda) = \ell(z_\text{new}, \lambda)$,
    \item $\lambda_\text{crc}$ is identical to $\hat{\lambda}$ from~\eqref{eq:supplemental_crc_lambda_hat}, and
    \item \eqref{eq:supplemental_crc_guarantee} states that $R(\theta, \lambda_\text{crc}) \le \alpha$ for any $\theta$.
\end{itemize}
Therefore, $\bar{R}(\lambda_\text{crc}) = \sup_\theta R(\theta, \lambda_\text{crc}) \le \alpha$.
\end{proof}

\subsection{Proof of Theorem~\ref{thm:consquantile}}
In order to prove Theorem~\ref{thm:consquantile}, we will need to make use of two auxiliary propositions (\Cref{thm:aux1a} and \Cref{thm:aux1}). We state and prove these first, and then proceed to prove Theorem~\ref{thm:consquantile}.

\begin{restatable}[]{proposition}{aux1a}\label{thm:aux1a}
Consider the following variational maximization problem:
\begin{equation}
    I[f] = \int_a^b f(x) \,dx
\end{equation}
subject to $f(a) = f_a$, $f(b) = f_b$, and $f_a \le f(x) \le f_b$ for all $x \in [a, b]$, where $f_a \le f_b$.  Then $I[f]$ is maximized by
\begin{equation}
    f^*(x) = \begin{cases}
        f_a & \text{if } x = a, \\
        f_b & \text{otherwise},
    \end{cases}\label{eq:generic_variational_solution}
\end{equation}
and $I[f^*] = (b - a) f_b$.
\end{restatable}
\begin{proof}
    We apply Euler's method~\citep[Section 2.2]{kot2014first}, which approximates the variational problem as an $m$-dimensional problem and takes the limit as $m \rightarrow \infty$. Let the interval $[a, b]$ be divided into $m + 1$ subintervals of equal width $\displaystyle \Delta x = \frac{b - a}{m + 1}$. The objective functional can then be approximated as
    \begin{equation}
        I(f_1, \ldots, f_m) \equiv \sum_{j=0}^m f_j \Delta x,
    \end{equation}
    where $f_0 = f_a$ and $f_{m + 1} = f_b$ due to the boundary conditions. In order to handle the $f_a \le f(x) \le f_b$ constraint, we first impose $f(x) \le f_b$ and check if the solution also satisfies $f(x) \ge f_a$. To that end, we substitute $f_j = f_b - \xi_j^2$:
    \begin{equation}
        I(\xi_1, \ldots, \xi_m) = \sum_{j=0}^m (f_b - \xi_j^2) \Delta x.
    \end{equation}
    We then take partial derivatives with respect to $\xi_k$:
    \begin{equation}
        \frac{\partial I}{\partial \xi_k} = -2 \xi_k \Delta x \Rightarrow \frac{1}{\Delta x} \frac{\partial I}{\partial \xi_k} = -2 \xi_k.
    \end{equation}
    Taking the limit as $m \rightarrow \infty$ and $\Delta x \rightarrow 0$, the variational derivative becomes:
    \begin{equation}
        \frac{\delta I}{\delta \xi} = -2\xi.
    \end{equation}
    Setting $\displaystyle \frac{\delta I}{\delta \xi} = 0$ yields $\xi(x) = 0$, which recovers $f(x) = f_b$, except at $x = a$, where $f(a) = f_a$ by the boundary conditions. This recovers $f^*(x)$ from~\eqref{eq:generic_variational_solution}, which indeed satisfies $f(x) \ge f_a$. For $f^*$, it is evident that the value of the value of the functional is $I[f^*] = (b - a) f_b$.
\end{proof}

\begin{restatable}[]{proposition}{aux1}\label{thm:aux1}
Let $\mathcal{K}_n$ be the set of quantile functions for which $K(t_i) = \ell_i$ for $i = 1, \ldots, n$. Then
\begin{equation}
    \sup_{K \in \mathcal{K}_n} J[K] = \sum_{i=1}^{n+1} (t_{(i)} - t_{(i-1)}) \ell_{(i)},
\end{equation}
where $t_{(0)} = 0$, $t_{(n+1)} = 1$, $\ell_{(n+1)} = B$, and $J[K] \triangleq \int_0^1 K(t) \, dt$.

\end{restatable}
\begin{proof}
By \Cref{thm:qfmonotonic}, quantile functions preserve orderings and therefore $K(t_{(i)}) = \ell_{(i)}$. We divide $J[K]$ into intervals with endpoints $(0, t_{(1)}), (t_{(1)}, t_{(2)}), \ldots, (t_{(n)}, 1)$:
\begin{align}
\sup_{K \in \mathcal{K}_n} J[K] &= \sup_{K \in \mathcal{K}_n} \int_0^1 K(t) \, dt \\
&= \sup_{K \in \mathcal{K}_n} \sum_{i=1}^{n+1} \int_{t_{(i-1)}}^{t_{(i)}}K(t) \, dt \\
&\le \sum_{i=1}^{n+1} \sup_{K \in \mathcal{K}_n} \int_{t_{(i-1)}}^{t_{(i)}}K(t) \, dt
\end{align}
By \Cref{thm:qfmonotonic}, $K(t_{(i-1)}) \le K(t) \le K(t_{(i)})$ for any $t \in [t_{(i-1)}, t_{(i)}]$. We view each term as a variational subproblem where $\displaystyle J_i[K_i] \triangleq \int_{t_{(i-1)}}^{t_{(i)}} K_i(t) \, dt$ with boundary conditions $K_i(t_{(i-1)}) = \ell_{(i-1)}$ and $K_i(t_{(i)}) = \ell_{(i)}$. We therefore appeal to \Cref{thm:aux1a} to conclude that
\begin{equation}
    K_i^*(t) =  \begin{cases}
        \ell_{(i-1)} & \text{if } t = t_{(i-1)}, \\
        \ell_{(i)} & \text{otherwise},
    \end{cases}
\end{equation}
and $J[K_i^*] = (t_{(i)} - t_{(i-1)}) \ell_{(i)}$. We therefore have
\begin{equation}
    \sup_{K \in \mathcal{K}_n} J[K] \le \sum_{i=1}^{n+1} (t_{(i)} - t_{(i-1)}) \ell_{(i)}.
\end{equation}
By composing $K_i^*$ from each subinterval, it is straightforward to see that the bound is tight for
\begin{equation}
    K^*_{t_{1:n}, \ell_{1:n}}(t) = \begin{cases}
        \ell_{(1)} & \text{ if } t \le t_{(1)} \\
        \ell_{(2)} & \text{ if } t_{(1)} < t \le t_{(2)} \\
        \ldots \\
        \ell_{(n)} & \text{ if } t_{(n-1)} < t \le t_{(n)} \\
        B & \text{ if } t > t_{(n)}.
    \end{cases}\label{eq:worst_case_quantile_function}
\end{equation}
$K^*_{t_{1:n}, \ell_{1:n}}$ is therefore the ``worst-case'' quantile function that is consistent with the observations, and $J[K^*_{t_{1:n}, \ell_{1:n}}] = \sum_{i=1}^{n+1} (t_{(i)} - t_{(i-1)}) \ell_{(i)}$.
\end{proof}

We are now ready to prove Theorem~\ref{thm:consquantile}.

\consquantile*
\begin{proof}
    Let $J[K] = \int_0^1 K(t) \, dt$. The conditional expected loss can be expressed as:
    \begin{align}
        E(L \mid t_{1:n}, \ell_{1:n}) &= \int J[K] p(K \mid t_{1:n}, \ell_{1:n}) \, dK \\
        &\le \sup_{K \in \mathcal{K}_n} J[K],
    \end{align}
    where $\mathcal{K}_n$ is the set of quantile functions for which $K(t_i) = \ell_i$ for $i = 1, \ldots, n$. By~\Cref{thm:aux1}, it follows that
    \begin{equation}
        E(L \mid t_{1:n}, \ell_{1:n}) \le \sum_{i=1}^{n+1} (t_{(i)} - t_{(i-1)}) \ell_{(i)} = \sum_{i=1}^{n+1} u_i \ell_{(i)}
    \end{equation}
\end{proof}

\subsection{Proof of Lemma~\ref{thm:dirspacings}}
\dirspacings*
\begin{proof}
By the probability integral transformation~(\Cref{thm:pit}), $T_i$ is $\Uniform(0, 1)$ for $i = 1, \ldots, n$.  Since the transformation from $(t_1, \ldots, t_n) \rightarrow (t_{(1)}, \ldots, t_{(n)})$ is a sorting operation where $n!$ permutations map to the same vector of order statistics, the probability density for  $t_{(1)}, \ldots, t_{(n)}$ is therefore
\begin{equation}
    f_{t_{(1:n)}}(t_{(1)}, \ldots, t_{(n)}) = n!, \qquad 0 \le t_{(1)} \le t_{(2)} \le \ldots \le t_{(n)} \le 1.
\end{equation}
If $u_{1:n} = G(t_{(1:n)})$ where $G$ is differentiable and invertible, then by change of variables the density for $u_{1:n}$ can be expressed as
\begin{equation}
    f_{u_{1:n}}(u_{1:n}) = f_{t_{(1:n)}}(G^{-1}(u_{1:n})) \left| \det \left( \frac{\partial}{\partial u_{1:n}} G^{-1}(u_{1:n}) \right) \right|.
\end{equation}
Observe that the inverse transformation $t_{(1:n)} = G^{-1}(u_{1:n})$ can be expressed as
\begin{equation}
    \begin{bmatrix}
    t_{(1)} \\ t_{(2)} \\ t_{(3)} \\ \vdots \\ t_{(n-1)} \\ t_{(n)}
    \end{bmatrix}
    =
    \begin{bmatrix}
    1 & 0 & 0 & \ldots & 0 & 0 \\
    1 & 1 & 0 & \ldots & 0 & 0 \\
    1 & 1 & 1 & \ldots & 0 & 0 \\
    \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
    1 & 1 & 1 & \ldots & 1 & 0 \\
    1 & 1 & 1 & \ldots & 1 & 1 \\
    \end{bmatrix}
    \begin{bmatrix}
    u_{1} \\ u_{2} \\ u_{3} \\ \vdots \\ u_{n-1} \\ u_{n}
    \end{bmatrix}.
\end{equation}
Hence the absolute Jacobian of inverse transformation $t_{(1:n)} = G^{-1}(u_{1:n})$ is 1. The density of $u_{1:n}$ is therefore
\begin{equation}
    f_{u_{1:n}}(u_{1:n}) = f_{t_{(1:n)}}(G^{-1}(u_{1:n})) = n!, \quad \text{ where } u_i \ge 0 \text{ for } i = 1, \ldots, n \text{ and }\sum_{i=1}^n u_i \le 1.\label{eq:spacing_density}
\end{equation}
Recall that the Dirichlet density with parameter $\alpha_1, \ldots, \alpha_{n+1}$ is:
\begin{equation}
    \Dir(u_{1:n+1} \mid \alpha_{1:n+1}) = \frac{ \Gamma( \sum_{i=1}^{n+1} \alpha_i)}{\Gamma (\alpha_1) \ldots \Gamma(\alpha_{n+1})} \prod_{i=1}^{n+1} u_i^{\alpha_i - 1}, \quad \text{ where } u_i \ge 0 \text{ and } \sum_{i=1}^{n+1} u_i = 1.
\end{equation}
In particular, if $\alpha_1 = \alpha_2 = \ldots = \alpha_{n+1} = 1$,
\begin{equation}
    \Dir(u_{1:n+1} \mid 1, \ldots, 1) = \Gamma(n+1) = n!,
\end{equation}
which is identical to~\eqref{eq:spacing_density} with $u_{n+1} = 1 - u_1 - \ldots - u_n$. Therefore, $(u_1, u_2, \ldots, u_{n+1}) \cong \Dir(1, \ldots, 1)$.

\end{proof}

\subsection{Proof of Theorem~\ref{thm:stochasticub}}

\stochasticub*
\begin{proof}
\begin{align}
    \inf_\pi \Pr(L \le b \mid \ell_{1:n}) &= \inf_\pi \int \mathbbm{1} \left\{ J[K] \le b \right\} p(K \mid \ell_{1:n}) \, dK \\
    &= \inf_\pi \int \mathbbm{1} \left\{ J[K] \le b \right\} \left( \int p(K \mid t_{1:n}, \ell_{1:n}) p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \right)  \, dK \\
    &= \inf_\pi \int \left(\int \mathbbm{1} \left\{ J[K] \le b \right\} p(K \mid t_{1:n}, \ell_{1:n}) \, dK \right) p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &\ge  \int \left(\inf_\pi \int \mathbbm{1}\left\{ J[K] \le b \right\} p(K \mid t_{1:n}, \ell_{1:n}) \, dK \right) p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &\ge  \int \left(\inf_{K \in \mathcal{K}_n} \mathbbm{1}\left\{ J[K] \le b \right\} \right) p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &\ge  \int \mathbbm{1}\left\{ J[K^*_{t_{1:n}, \ell_{1:n}}] \le b \right\} p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &= \int \mathbbm{1}\left\{ \sum_{i=1}^{n+1} (t_{(i)} - t_{(i-1)}) \ell_{(i)} \le b \right\} p(t_{1:n} \mid \ell_{1:n}) \, dt_{1:n} \\
    &= \int \mathbbm{1}\left\{ \sum_{i=1}^{n+1} u_i \ell_{(i)} \le b \right\} p(u_{1:n+1} \mid \ell_{1:n}) \, du_{1:n+1} \\
    &= \Pr( L^+ \le b)
\end{align}
\end{proof}

\subsection{Proof of Corollary~\ref{thm:ucbdf}}

\ucbdf*
\begin{proof}
For any $b \ge b_\beta^*$, $\Pr(L^+ \le b \mid \ell_{1:n}) \ge \beta$. Substitution into \eqref{eq:stochasticub_statement} provides the desired result.
\end{proof}

\end{document}
