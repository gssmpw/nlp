\begin{abstract}
% Inspired by their extraordinary code generation capabilities, researchers are progressively using large language models (LLMs) to fix vulnerabilities and issues in real-world software systems.
Recent research builds various patching agents that combine large language models (LLMs) with non-ML tools and achieve promising results on the state-of-the-art (SOTA) software patching benchmark, SWE-Bench. 
Based on how to determine the patching workflows, existing patching agents can be categorized as agent-based planning methods, which rely on LLMs for planning, and human-based planning methods, which follow a pre-defined workflow.
At a high level, agent-based planning methods achieve high patching performance but with a high cost and limited stability. 
Human-based planning methods, on the other hand, are more stable and efficient but have key workflow limitations that compromise their patching performance.
In this paper, we propose \sys, an agentic patcher that strikes a balance between patching efficacy, stability, and cost-efficiency. 
\sys proposes a novel human-based planning workflow with five components: reproduction, localization, generation, validation, and refinement (where refinement is unique to \sys).
We introduce novel and customized designs to each component to optimize their effectiveness and efficiency. 
Through extensive experiments on the SWE-Bench benchmarks, PatchPilot shows a superior performance than existing open-source methods while maintaining low cost (less than 1\$ per instance) and ensuring higher stability.
We also conduct a detailed ablation study to validate the key designs in each component. 
\end{abstract}