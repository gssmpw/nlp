\section{Discussion}
\label{sec:discussion}

\noindent\textbf{Resolved rates vs. stability and cost.}
As a human-based planning method, \sys achieves a well-balanced trade-off between resolved rates, stability, and cost-efficiency.
We believe that emphasizing stability and cost-efficiency is essential for a patching agent to be practical in real-world applications. 
Although \sys is not on the top of the leaderboard, it has been shown to be a stable and affordable method, confirming its practicality. 
Furthermore, \sys outperforms all open-source methods on the leaderboard, establishing reasonably good performance. 

\noindent\textbf{Static analysis vs. LLMs.}
We tried multiple static program analysis approaches in different components which were not effective and cannot outperform LLMs.
First, we added function summaries for the functions in the root cause to the generation component.
It improves the performance of \sys with \gpt.
However, it is not helpful when using more advanced models (\oo{} and \claude{}), indicating that advanced models may be able to infer function behaviors. 
In validation, we tried to apply rule-based criteria to the PoC outputs to decide whether an issue is fixed.
This is worse than using LLM as a judge, given that many issues are ``logical bugs'' that do not cause crashes. 
LLMs can better understand the issue and make decisions based on PoC outputs.
We also tried to use CodeQL to infer patch-related locations that needed to be changed together with the current patch, but it failed due to CodeQL's limited performance. 

\noindent\textbf{Complex prompting strategy.}
We tried Tree of Thoughts (ToT)~\cite{yao2024tree} in generation, i.e., generating multiple candidates for each step of a plan.
While significantly increasing costs, this approach does not improve the resolved rate given the LLMs cannot generate candidates with enough diversity for specific patching steps. 
