\section*{Appendix}
This appendix contains additional implementation/experimental details, mathematical and experimental details.

We also included a document with additional results and a video showing the behavior of our proposed method in some experiments and the code \revisedtext{of the proposed method, as well as of all the baselines we implemented}. %

%
\section{LSTM-based prediction details}
Our proposed model for predicting trajectories includes a Long Short-Term Memory (LSTM) layer, designed to understand the temporal relationships within the trajectory data, and a three-layer multi-layer perceptron (MLP) that outputs the predicted trajectory (see \fig{lstm-arch}). 

%
\begin{figure}[b!]
  \centering
  \includegraphics[width=\columnwidth]{figs/lstm-architecture.pdf}
  \caption{LSTM-MLP module architecture. The {\inputtraj input trajectory} has coordinates from $x_{t_{\textit{past}}}$ to $x_t$ and the {\outputtraj output trajectory} has coordinates from $x_t$ to $x_{t_{\textit{pred}}}$.} 
  \label{fig:lstm-arch}
\end{figure}

This LSTM-MLP framework processes an input of $10$ previous coordinates and forecasts a future trajectory consisting of $15$ coordinates, matching the length used in our trajectory tracking evaluation. However, the past and future trajectory length is not strictly constrained to $10, 15$, respectively. Users can adaptively choose the parameters based on the size of the environments, robots, and frequency of sensors. After normalization of an input trajectory, we used data augmentation by rotating the trajectory into every $\SI{45}{\degree}$ angle, i.e., total $8$ trajectories per one input trajectory. During training, we used $32$ batch size, $300$ epoch, drop out $0.4$, learning rate $0.0001$, Adam optimizer, and MSE loss function. The example results of the trajectory prediction are shown in \fig{lstm-result}. 

\revisedtext{We also demonstrate the trajectory prediction results using the Gaussian Process (GP) with the Mat\'ern kernel (\fig{gp-result}). Despite being tested under the same conditions as the LSTM, the GP exhibited low performance. The limitations of the GP--(1) the need for an explicit choice of kernel and its high computational complexity; (2) the requirement for continuous training with new input data and newly detected target objects within the sensor range; and (3) the assumption of independence between $x$ and $y$ coordinates--make it not an ideal choice for real-time trajectory prediction during the search and tracking of multiple targets.}

%

%



\begin{figure}[t!]
    \centering
    \begin{minipage}[t]{0.49\columnwidth}
        \begin{subfigure}[b]{\textwidth}            
            \includegraphics[width=\textwidth]{figs/lstm-linear-result-new.pdf}
        \end{subfigure}
    \end{minipage}
    \begin{minipage}[t]{0.49\columnwidth}
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{figs/lstm-non-linear-result-new-new.pdf}
        \end{subfigure}
    \end{minipage}
    \caption{LSTM-based trajectory prediction results. X,Y coordinate is based on meters. \textit{(left)}: simpler scenario with linear motion of a target object; \textit{(right)}: complex scenario with non-linear motion of a target object.}
    \label{fig:lstm-result}
\end{figure}


\begin{figure}[t!]
    \centering
    \begin{minipage}[t]{0.49\columnwidth}
        \begin{subfigure}[b]{\textwidth}            
            \includegraphics[width=\textwidth]{figs/gp_linear.pdf}
        \end{subfigure}
    \end{minipage}
    \begin{minipage}[t]{0.49\columnwidth}
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{figs/gp_non_linear.pdf}
        \end{subfigure}
    \end{minipage}
    \caption{\revisedtext{GP-based trajectory prediction results. X,Y coordinate is based on meters. \textit{(left)}: simpler scenario with linear motion of a target object; \textit{(right)}: complex scenario with non-linear motion of a target object.}}
    \label{fig:gp-result}
\end{figure}

%
\section{\revisedtext{Action Algorithm Details}}
\revisedtext{We include the algorithmic detail about how the HQ places bids for search to agents and assign the search task with the best utility.}

\revisedtext{\textbf{Search} (\alg{alg:search-task-assignment}): the headquarters (HQ) identifies best frontiers by \texttt{getBestFrontiers} (line 2) based on the highest expected utility (calculated by $\jexplore$ and $\jexploit$) and then starts an auction for the frontiers in order at each round (line 3--4). The HQ communicates to \textit{non-active} agents, i.e., not conducting a \emph{tracking} task at that time, by \texttt{findNonActiveAgents} (line 5). The HQ places bids among unassigned agents and collect the submitted bid result (lines 9--11). Finally, the HQ selects $\ag_{\mi{opt}}$ with the best utility by \texttt{getBestBid} (line 12) and updates the auction result (lines 13--14).
}


\begin{algorithm}[t]
\caption{\revisedtext{Search Task Assignment (HQ).}}
\label{alg:search-task-assignment}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
    \scriptsize
    \REQUIRE \,
    \vspace{-1em}
    \begin{itemize}
        \itemsep-0.2em
        \item Agents set $\A$, active agent set $\A_{act}$
        \item Frontiers set $F$
        %
    \end{itemize} 
    \vspace{-0.5em}
    \ENSURE hash table $Q$ for optimal trajectory $\tau^*$ and corresponding $\ag_{\mi{opt}}$ assigned to $\tau^*$
    \IF{$F \neq \emptyset $}
        \STATE $F_{\search}$ $\gets$ $\texttt{getBestFrontiers}(F)$ \comment{priority queue}
        \WHILE{$F_{\search} \neq \emptyset$}
            \STATE $fr_{\search}$ $\gets$ $F_{\search}$\textrm{.pop()}
            \STATE $\A_{\neg \mi{act}}$ $\gets$ $\texttt{findNonActiveAgents}(\A \setminus \A_{\mi{act}})$
            \IF{$\A_{\neg \mi{act}} == \emptyset$}
                \BREAK
            \ENDIF
            \STATE $Q_{\mi{search}}$ $\gets$ \textrm{empty} \comment{hash table for searching}
            \FOR{$\ag_{\neg \mi{act}} \in \A_{\neg act}$}
                %
                \STATE $\tau_{\ag_{\neg \mi{act}}}$ $\gets$ \texttt{requestBid}($\ag_{\neg \mi{act}}$)
                \comment{$\ag_{\neg \mi{act}}$ submits a bid for $fr_{\mi{search}}$}
                \STATE $Q_{\search} \gets \textrm{update}(Q_{\search}, \tau_{\ag_{\neg \mi{act}}}, \ag_{\neg \mi{act}})$
            \ENDFOR
            \STATE $\tau^*_{fr_{\mi{search}}}, \ag_{\mi{opt}}$ $\gets$ $\texttt{getBestBid}(Q_{\search})$
            \STATE $Q$ $\gets$ $\textrm{update}(\tau^*_{fr_{\mi{search}}}, \ag_{\mi{opt}})$
            \STATE $\A_{\mi{act}}$ $\gets$ $\A_{\mi{act}} \cup \{\ag_{\mi{opt}}\}$
        \ENDWHILE
    \ENDIF
    \RETURN $Q$ 
\end{algorithmic} 
\end{algorithm}

%
\section{\revisedtext{Bayesian Filtering Details}}
\revisedtext{We include the math derivation for the prediction and update steps as a Bayesian filtering on the belief of object's positions measured by an agent.}

\revisedtext{
\textbf{Prediction step:}
\begin{equation}
    \obelieftrack{\ag}{\ob}{t} = \sum_{q_\ag^{t}} \, p(\ob^t|\ob^{t-1}, q_\ag^{t}) \cdot \belieftrack{\ag}{\ob}{t-1}
    \label{eq:predict}
\end{equation}
To derive this model, we use the \textit{total probability} theorem:
\begin{align}
    & \obelieftrack{\ag}{\ob}{t} \nonumber \\
    & = p(\ob^t|\zlocag^{0:t-1}, q_\ag^{0:t}) \nonumber \\
    & = \sum_{q_\ag^{t}} p(\ob^t | \ob^{t-1}, \zlocag^{0:t-1}, q_\ag^{0:t}) \cdot p(\ob^{t-1} | \zlocag^{0:t-1}, q_\ag^{0:t}) \nonumber
\end{align}  
Given the Markov assumption, we get $p(\ob^t | \ob^{t-1}, \zlocag^{0:t-1}, q_\ag^{0:t}) =  p(\ob^t|\ob^{t-1}, q_\ag^{t})$. Also, the second term can be omitted $q_\ag^{t}$ as it does not affect $\ob^{t-1}$ directly. Hence, 
\begin{align}
    & \sum_{q_\ag^{t}} p(\ob^t | \ob^{t-1}, \zlocag^{0:t-1}, q_\ag^{0:t}) \cdot p(\ob^{t-1} | \zlocag^{0:t-1}, q_\ag^{0:t-1}) \nonumber  \\
    & = \sum_{q_\ag^{t}} \, p(\ob^t|\ob^{t-1}, q_\ag^{t}) \cdot \belieftrack{\ag}{\ob}{t-1} \nonumber
\end{align}
}

\revisedtext{
\textbf{Update step:} By using \textit{Bayes rule}, we can get the belief state updated:
\begin{equation}
\belieftrack{\ag}{\ob}{t} = \eta \,\, p(\zlocag^{t}|\ob^t) \cdot \obelieftrack{\ag}{\ob}{t}
\label{eq:update}
\end{equation} where $\belieftrack{\ag}{\ob}{t}$ is a corrected state, $\eta$ is a normalizer, $\zlocag^{t}$ is a sensor measurement of the target $\ob$ at time $t$, and $\obelieftrack{\ag}{\ob}{t}$ is a predicted state. The derivation is as follows:
\begin{align}
    & \belieftrack{\ag}{\ob}{t} \nonumber 
    = p(\ob^t|\zlocag^{0:t}, q_\ag^{0:t}) \nonumber \\
    & = \frac{p(\zlocag^{t}|\ob^t, \zlocag^{0:t-1}, q_\ag^{0:t}) \cdot p(\ob^t | \zlocag^{0:t-1}, q_\ag^{0:t})}
    {p(\zlocag^{t} | \zlocag^{0:t-1}, q_\ag^{0:t})} \nonumber \\
    & = \eta \,\, p(\zlocag^{t}|\ob^t) \cdot \obelieftrack{\ag}{\ob}{t} \nonumber
\end{align}
Using \textit{conditional independence}, $p(\zlocag^{t}|\ob^t, \zlocag^{0:t-1}, q_\ag^{0:t}) = p(\zlocag^{t}|\ob^t)$. Also, $p(\ob^t | \zlocag^{0:t-1}, q_\ag^{0:t}) = \obelieftrack{\ag}{\ob}{t}$ according to the \textit{definition of the predicted belief}.
}

%
%
%
%
%
%
%

%
\section{Experimental setup details}
The following parameters in \tab{experimental_parameters} were what we have used for the experimental configurations as discussed in the paper. Unlike the literature, for heterogeneous capabilities, we modeled varying parameters  $vr_a, \Sigma_o$ for agents, and $\Sigma_e$ for external reports. \revisedtext{For 3D simulations, we tested our method and the baselines in diverse environments (see \fig{gazebo-env-app}) in addition to \emph{office1} in the paper.}
\begin{table}[t!]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Parameter} & \textbf{Values}  \\ \hline \hline
        \multicolumn{2}{|c|}{for simulation} \\ \hline
        $s_o$ & $\SI{0.2}{\meter/\second}$ \\
        $s_a$ & $\SI{0.4}{\meter/\second}$\\
        $vr_a$ & $\SIrange{5}{8}{\meter}$\\
        $\alpha$ & $\SIrange{0.08}{0.2}{}$\\
        $\beta$ & $0$ \\
        $\Sigma_o$ & $\SIrange{0.7}{1.3}{\meter}$\\
        $\Sigma_e$ & $\SIrange{0.5}{1.0}{\meter}$\\
        \hline
        \multicolumn{2}{|c|}{for method} \\ \hline
        $r$ & $1/90$ \\
        $w$ & $0.3$ (search), $0.2$ (track) \\
        $D_\textit{thre}$ & $\SI{3.5}{\meter}$ \\
        $\trace(\Sigma_{\mi{thre}})$  & $2.0$ \\ \hline
        %
    \end{tabular}
    \caption{Parameters used in the experiments.}
    \label{tab:experimental_parameters}
\end{table}



\begin{figure}[t]
    \centering
    %
    %
    \begin{minipage}[t]{0.40\columnwidth}
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{figs/environments/office-gazebo-3d.jpg}
            %
            %
            %
        \end{subfigure}
    \end{minipage}
    \begin{minipage}[t]{0.42\columnwidth}
        \begin{subfigure}[b]{\textwidth}
            \includegraphics[width=\textwidth]{figs/environments/empty-gazebo.png}
            %
            %
        \end{subfigure}
    \end{minipage}
    \caption{\revisedtext{3D simulation \qtyproduct{50 x 50}{m} environments: (\textit{left}): \emph{office2} (\textit{right}): \emph{empty}}.}
    \label{fig:gazebo-env-app}
\end{figure}



\section{Supplementary material}
We included the following supplementary material:
\begin{itemize}
 \item a document with additional results,
 \item a video describing the proposed method and highlighting experiments and results.
\end{itemize}



%
%
%
%
%

