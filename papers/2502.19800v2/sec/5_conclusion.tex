\section{Conclusion}
\label{sec:conclution&limitation}
In this work, for the first time, we integrate global tracks with 3DGS and propose a joint optimization framework for COLMAP-Free 3DGS training pipeline. Specifically, this is to avoid the instability, pose drift, and the limitations in handling complex scenes that arise from using local constraints in prior works. In our design, we introduce 2D and 3D track losses to simultaneously constrain geometric consistency in both the 2D and 3D spaces, while also constraining the scale of the track Gaussians to ensure higher spatial accuracy of 3D Gaussians. Additionally, we derive the gradient of the camera intrinsics, an important factor that was previously ignored, allowing the joint optimization of camera parameters and 3DGS to be fully differentiable. We have conducted extensive experiments on challenging datasets, where cameras have severe movements, to validate the effectiveness of our method. However, our current method does not yet support different intrinsic matrices for different views or camera distortion, which we plan to address in the future work.

% We introduce a novel joint optimization method to train 3DGS without using intrinsic and extrinsic parameters. To address this challenge, we first derive the gradients of the camera intrinsics, allowing these intrinsic parameters to be updated during back-propagation.Additionally, we integrate global track information and select the Gaussian kernels associated with each track. We then combine two new loss functions, i.e., \emph{track loss} and \emph{scale loss}, with the photometric losses from the original 3DGS. Extensive evaluations on both public and challenging synthetic datasets demonstrate that our approach outperforms previous methods that require camera intrinsics and achieves state-of-the-art (SOTA) performance in novel view synthesis.
% However, we assume that all cameras follow a standard pinhole model with no distortion and share the same intrinsics. This direction is worth further exploration.


%In this work, we introduce a novel joint optimization method to train 3DGS without any camera parameters. Compared to previous methods, our approach can handle complex camera trajectories, dramatic camera viewpoint changes,unsequential image inputs without camera intrinsics and extrinsics. To tackle these challenges, our method begins by re-establishing the association relationships among input images through explicit feature matching for optimization. Then we use the correspondences and dpt depth to compute the initial camera parameters from scratch. In addition, we theoretically derive the gradients of the parameters in relation to 3DGS and propose a joint optimization method based on global track information.Extensive evaluations on benchmark datasets demonstrate our superior performance and robustness, even in challenging scenes. 
% \textbf{Limitations.}
% Our method relies on global tracks that are established explicitly between images. For scenes with few or repetitive textures, this may lead to mis-matching and affect the joint optimization. Integrating track establishment and maintenance into the whole framework is a meaningful direction in the future.