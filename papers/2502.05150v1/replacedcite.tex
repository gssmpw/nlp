\section{Related Work}
% {\bf Automatic Code Generation.} 
\paragraph{Automatic Code Generation.}
Code generation with multi-modal prompts has been explored by some earlier works such as ____. Recent works have either adopted the transformer architecture ____ or leveraged the GPT ____ skeleton with massive pretraining for code pretraining ____.

\paragraph{Prompt-Tuning.} 
Various approaches to prompt-tuning ____ have been explored for various domains and modalities ____, such as Chain-of-Thought reasoning ____, Tree of Thoughts ____, discrete prompt optimization ____, and few-shot learning ____. In the context of code generation, prompt engineering has been leveraged for human-in-loop debugging ____, correctness evaluation of generated code ____, multistep planning, and generation ____. Our work explores the effects of modalities in prompts on code generation, which can be further used for targeted prompt-tuning processes for better performance.

\paragraph{Causal Inference in Code/NLP.} 
Recent research has applied causal inference to the NLP domain ____ to better understand model behavior, which is now formalized as causal NLP ____. 
In the context of code, prior approaches have applied causal framework for various classification tasks such as vulnerability detection ____ and code performance prediction ____.
%____ apply a causal framework for a vulnerability detection task, a classification problem. 
To the best of our knowledge, we are the first to apply causal inference to study modal effects on code generation task.