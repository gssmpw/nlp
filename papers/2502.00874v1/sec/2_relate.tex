\section{Related Works}
% \textcolor{red}{GPT: replace citations}

\subsection{Open Peer Review}

Open peer review (OPR) enhances transparency by publishing reviews, revealing reviewer identities, or enabling public discussions~\cite{ross2017open, henriquez2023open, wolfram2020open}. In AI and ML, OpenReview~\cite{openreview_api} has facilitated OPR, with ICLR pioneering public discourse alongside formal reviews~\cite{wang2023have}. Proponents argue that open reviews improve feedback quality, help reviewers refine their assessments~\cite{church2024peer}, and enable confidence estimation from review text~\cite{bharti2022confident}. However, experiments at NeurIPS reveal inconsistencies in peer review~\cite{cortes2021inconsistency, Lawrence2022NeurIPSExperiment, beygelzimer2023has}, raising concerns about subjective scoring~\cite{xie2024reviewer} and the impact of increasing submissions~\cite{tran2021an}. Some studies suggest interventions to reduce uncertainty in reviewer judgments~\cite{chen2023judgment} or explore author self-assessments as a complement to peer review~\cite{su2024analysis}.

Despite its benefits, OPR within double-blind settings poses challenges. Publishing reviews, even anonymously, may reveal sensitive details or invite targeted criticism~\cite{tran2021an}. Computational studies highlight fairness disparities in peer review~\cite{zhang2022investigating}, and alternatives like managing research evaluation on GitHub have been proposed~\cite{takagi2022managing}. Broader concerns persist, including whether reviewing efforts align with academic impact~\cite{church2024peer} and how best to address systemic biases~\cite{shah2022challenges}. As NeurIPS discussions occur mid-year and ICLR discussions happen later, the timing of transparency measures may also shape reviewer behavior and decision-making.

% An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process \cite{tran2021an}

% Inconsistency in conference peer review: Revisiting the 2014 neurips experiment \cite{cortes2021inconsistency}

% The NeurIPS Experiment \cite{Lawrence2022NeurIPSExperiment}

% Challenges, experiments, and computational solutions in peer review \cite{shah2022challenges}

% Has the machine learning review process become more arbitrary as the field has grown? The NeurIPS 2021 consistency experiment \cite{beygelzimer2023has}

% Judgment sieve: Reducing uncertainty in group judgments through interventions targeting ambiguity versus disagreement\cite{chen2023judgment}

% Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills \cite{buccinca2024contrastive}

% Investigating fairness disparities in peer review: A language model enhanced approach \cite{zhang2022investigating}

% How confident was your reviewer? estimating reviewer confidence from peer review texts \cite{bharti2022confident}

% Are reviewer scores consistent with citations? \cite{xie2024reviewer}

% Analysis of the ICML 2023 Ranking Data: Can Authors' Opinions of Their Own Papers Assist Peer Review in Machine Learning? \cite{su2024analysis}

% Is Peer-Reviewing Worth the Effort?\cite{church2024peer}

% Managing the Whole Research Process on GitHub \cite{takagi2022managing}

% What have we learned from OpenReview? \cite{wang2023have}

% Open peer review (OPR) encompasses a spectrum of practices that aim to increase the transparency of the reviewing process, ranging from publishing reviewer identities and comments to enabling public commenting on manuscripts \cite{ross2017open, henriquez2023open}. The approach is intended to foster accountability, reduce biases, and promote more constructive critique. In machine learning and AI domains, conferences such as ICLR have pioneered variations of OPR on platforms like OpenReview, allowing public commentary alongside official reviews. Proponents argue that exposing the reasoning behind acceptance or rejection can provide valuable feedback to authors while also helping reviewers refine their assessments.

% Nonetheless, implementing OPR in double-blind settings requires careful balancing of transparency and anonymity. Even without revealing identities, publishing reviews can inadvertently disclose sensitive information or lead to targeted criticism \cite{ross2017open}. Critics also contend that reviewers, especially early-career researchers, might be reluctant to offer candid assessments if their comments are made public \cite{bianchi2023state}. Thus, while OPR has gained traction across some AI and ML venues, questions remain regarding its effect on review quality and reviewer willingness to participate.

\subsection{Regulations}

As OPR evolves, regulatory guidelines ensure integrity, fairness, and privacy~\cite{ross2019guidelines}. Some researchers caution that excessive transparency may undermine review quality~\cite{bianchi2022can}, while others highlight the challenge of balancing confidentiality with open science~\cite{baez2002confidentiality, dennis2019privacy}.

AI/ML conferences face additional regulatory challenges. Public review platforms can expose researchers to scrutiny or harassment, raising ethical concerns~\cite{wang2023have}. AI-powered peer review introduces risks that require human oversight~\cite{seghier2024ai}, while plagiarism in review reports and the rise of review mills threaten review integrity~\cite{piniewski2024emerging, oviedo2024review, ezhumalai2024design}. To address these risks, researchers advocate for clearer policies on reviewer disclosures, public critique, and misconduct prevention, ensuring transparency strengthens rather than undermines the review process~\cite{kaltenbrunner2022innovating, kuznetsov2024can}.

% What have we learned from OpenReview? \cite{wang2023have}

% Confidentiality and peer review: The paradox of secrecy in academe \cite{baez2002confidentiality}

% Can transparency undermine peer review? A simulation model of scientist behavior under open peer review \cite{bianchi2022can}

% Guidelines for open peer review implementation \cite{ross2019guidelines}

% Innovating peer review, reconfiguring scholarly communication: An analytical overview of ongoing peer review innovation activities \cite{kaltenbrunner2022innovating}

% Emerging plagiarism in peer-review evaluation reports: a tip of the iceberg? \cite{piniewski2024emerging}

% What Can Natural Language Processing Do for Peer Review? \cite{kuznetsov2024can}


% AI-powered peer review needs human supervision \cite{seghier2024ai}

% Design of an Integrated Collaborative Environment for Projects with Plagiarism Checker \cite{ezhumalai2024design}

% The review mills, not just (self-) plagiarism in review reports, but a step further \cite{oviedo2024review}

% Privacy versus open science \cite{dennis2019privacy}


% As open peer review practices evolve, various regulatory guidelines and ethical frameworks have emerged to maintain standards of integrity, fairness, and privacy \cite{cope2021guidelines, ieee2024guidelines}. The Committee on Publication Ethics (COPE), for instance, provides recommendations on managing conflicts of interest, ensuring reviewer anonymity, and handling appeals or disputes. Likewise, major professional bodies (e.g., IEEE, ACM) are increasingly specifying rules to safeguard data privacy and outline responsibilities for both authors and reviewers in open and semi-open reviewing environments.

% Beyond institutional guidelines, researchers have called for broader oversight and governance to address the unique challenges of open review in AI/ML \cite{ratanaworabhan2022bridging}. For example, complex or controversial findings may attract public scrutiny on review platforms, raising concerns over potential harassment or misuse of research insights. Regulatory measures that standardize reviewer disclosure policies, define acceptable forms of public critique, and penalize unethical behaviors are seen as critical for protecting contributors while preserving the benefits of transparency. These considerations underscore the need for a well-defined regulatory framework that complements the goals of open peer review.
