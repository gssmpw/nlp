
\newpage
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\theequation}{S\arabic{equation}}
\setcounter{figure}{0} 
\setcounter{table}{0}
\setcounter{equation}{0}


\section*{Supporting Information: First-Passage Approach to Optimizing Perturbations for Improved Training of Machine Learning Models}


\subsection{Derivation of Eq.~3 of the main text}
This appendix shows the derivation of \cref{eq:LR-prediction}. Note that a similar derivation is presented in \cite{keidar2024universal}, but for exponentially distributed perturbation times instead of a constant P.
Using the law of total expectation on \cref{eq:T_P_cases_description}, the mean FPT is,
\begin{equation}
    \mathbb{E}[T_P] = \Pr(T \leq P)\mathbb{E}[T \mid T \leq P] + \Pr(T>P)\left(\mathbb{E}[P \mid T > P] + \mathbb{E}\left[\mathbb{E}[\tau_P(\boldsymbol{\theta})] \mid T > P\right]\right).
\end{equation}
We define
\begin{equation}
    \Bar{\tau}_P \equiv \mathbb{E}\left[\mathbb{E}[\tau_P(\boldsymbol{\theta})] \mid T > P\right] = 
    \int_{\Theta} \mathbb{E}[\tau_P(\boldsymbol{\theta})] \frac{G(\boldsymbol{\theta},P)}{\Pr(T>P)} \mathrm{d}\boldsymbol{\theta} = \int_{\Theta} \mathbb{E}[\tau_P(\boldsymbol{\theta})] \frac{G(\boldsymbol{\theta},P)}{\Psi_T(P)} \mathrm{d}\boldsymbol{\theta},
\end{equation}
as taking the expectation value of $\tau_P(\boldsymbol{\theta})$ first over all possible noise realizations of the stochastic training process after the perturbation was applied to a given state $\boldsymbol{\theta}$ at time $P$, and then over all possible $\boldsymbol{\theta}$ generated by the unperturbed process at time $P$ right before the perturbation has been applied. The mean FPT with the perturbation is then given by
\begin{equation}
    \mathbb{E}[T_P] = \Pr(T \leq P)\mathbb{E}[T \mid T \leq P] + \Pr(T>P)\left(\mathbb{E}[P \mid T > P] +\Bar{\tau}_P\right).
    \label{eq:SI-law_tot_expectation}
\end{equation}

Next, we write the survival function $\Psi_T(t)$ in terms of the probability mass function of $T$, $\mathcal{P}_T(t)$,
\begin{equation}
    \Psi_T(t) = \Pr(T>t) = 1 - \sum_{n=0}^t \mathcal{P}_T(n),
\end{equation}
such that $\mathcal{P}_T(t) = \Psi_T(t-1)-\Psi_T(t)$. With this definition, we can compute each conditional expectation in \cref{eq:SI-law_tot_expectation}. The first term is,
\begin{equation}
    \mathbb{E}[T \mid T \leq P]=\frac{1}{\Pr(T \leq P)}\sum_{t=0}^P t \mathcal{P}_T(t),
\end{equation}
where the normalization factor is $\Pr(T \leq P)$ due to the conditional average. Since the first term in the sum is zero, we get
\begin{equation}
    \mathbb{E}[T \mid T \leq P]=\frac{1}{\Pr(T \leq P)}\sum_{t=1}^P t \mathcal{P}_T(t)=\frac{1}{\Pr(T \leq P)}\sum_{t=1}^P t (\Psi_T(t-1)-\Psi_T(t)).
\end{equation}
By changing the summation index of the first sum, we can rewrite
\begin{equation}
    \mathbb{E}[T \mid T \leq P]=\frac{1}{\Pr(T \leq P)}\left( \sum_{t=0}^{P-1} (t+1)\Psi_T(t) -  \sum_{t=1}^P t\Psi_T(t)\right) = \frac{1}{\Pr(T \leq P)}\left( \sum_{t=0}^{P-1} \Psi_T(t)  - P\Psi_T(P) \right),
\end{equation}
which is the final expression for the first expectation value.
% \begin{equation}
% \begin{split}
%     \mathbb{E}[T \mid T \leq P]=\sum_{t=0}^{\infty} t \mathcal{P}_{T \mid T \leq P}(t) = \sum_{t=0}^P \frac{t \mathcal{P}_T(t)}{\Pr(T \leq P)} = \frac{1}{\Pr(T \leq P)}\sum_{t=1}^P t \mathcal{P}_T(t) = \\
%     =\frac{1}{\Pr(T \leq P)}\sum_{t=1}^P t (\Psi_T(t-1)-\Psi_T(t))  = \frac{1}{\Pr(T \leq P)}\left( \sum_{t=1}^P t \Psi_T(t-1) -  \sum_{t=1}^P t\Psi_T(t)\right) = \\
%     = \frac{1}{\Pr(T \leq P)}\left( \sum_{t=0}^{P-1} (t+1)\Psi_T(t) -  \sum_{t=1}^P t\Psi_T(t)\right) = \frac{1}{\Pr(T \leq P)}\left( \sum_{t=0}^{P-1} \Psi_T(t)  - P\Psi_T(P) \right) .
% \end{split}
% \end{equation}
The second term is,
\begin{equation}
    \mathbb{E}[P \mid T > P] =P= \frac{P\Psi_T(P)}{\Pr(T>P)}.
\end{equation}
% and the third term is the definition of $\Bar{\tau}_P$ according to \cref{eq:tau_P-definition},
% \begin{equation}
%     \mathbb{E}\left[\mathbb{E}\left[\tau_P(\boldsymbol{\theta})\right] \mid T > P\right] \equiv  \Bar{\tau}_P = \int_{\Theta} \mathbb{E}[\tau_P(\boldsymbol{\theta})] \frac{G(\boldsymbol{\theta},P)}{\Pr(T>P)} \mathrm{d}\boldsymbol{\theta} = \int_{\Theta} \mathbb{E}[\tau_P(\boldsymbol{\theta})] \frac{G(\boldsymbol{\theta},P)}{\Psi_T(P)} \mathrm{d}\boldsymbol{\theta}.
% \end{equation}
Plugging these two terms back into \cref{eq:SI-law_tot_expectation},
\begin{equation}
     \mathbb{E}[T_P] = \sum_{t=0}^{P-1} \Psi_T(t) - \cancel{P\Psi_T(P)} + \cancel{P\Psi_T(P)} +  \Psi_T(P)\Bar{\tau}_P ,
\end{equation}
results in \cref{eq:LR-prediction}.

\subsection{Computational details of testing the QSS hypothesis}
This appendix includes computational details and provides additional support for the QSS of the test accuracy during SGD training without perturbations. The CDF $F_t(A)$ of the accuracy $A$ at epoch $t$ was calculated according to,
\begin{equation}
    F_t(A)=\frac{1}{N(t)}\sum_{i=1}^{N(t)}I\{A_i(t)\leq A\}.
\end{equation}
Here, $N(t)$ is the number of models that did not reach the target accuracy at time $t$, $I\{E\}$ is the indicator function of the event $E$, and $A_i(t)$ is the accuracy of the $i$-th model at time $t$. The average CDF $\Bar{F}(A)$ of $A$ over epochs 20 to 100 was taken as an arithmetic average of the accuracy CDFs, i.e.,
\begin{equation}
    \Bar{F}(A)=\frac{1}{t_2-t_1+1}\sum_{t=t_1}^{t_2}F_t(A).
\end{equation}

\subsection{Other statistical tests}
In \cref{fig:SI_qss_distance} we plot the CDFs of the test accuracy versus the values of the mean CDF of $A$ over epochs 20 to 100. The mean CDF is plotted in black for qualitative comparison between other CDFs (see legend). 
\begin{figure}[H]
\begin{center}
\centerline{\includegraphics[width=0.9\linewidth]{SI_qss_distance.pdf}}
\caption{CDFs versus the mean CDF. Blue and red colors indicate CDFs before and after reaching a QSS respectively. }
\label{fig:SI_qss_distance}
\end{center}
\end{figure}

In \cref{fig:SI_qss_mc_test} we compare the CDFs of the test accuracy $A$ to the average CDF of $A$ over epochs 20 to 100 with another measure, the Cram{\'e}r–von Mises (CM) criterion. The CM criterion at epoch $t$ is calculated as follows,
\begin{equation}
    CM(t) = \int_{0}^{1} \left( F_t(A) - \Bar{F}(A) \right)^2\mathrm{d}\Bar{F}(A).
\end{equation}
Here, $\Bar{F}(A)$ is the average CDF of $A$ over epochs 20 to 100.
In practice, we take the square of the difference between each curve of \cref{fig:SI_qss_distance} and the mean CDF, and integrate along the x-axis.
\begin{figure}[H]
\begin{center}
\centerline{\includegraphics[width=0.5\linewidth]{SI_qss_mc_test.pdf}}
\caption{Cram{\'e}r–von Mises criterion}
\label{fig:SI_qss_mc_test}
\end{center}
\end{figure}

\subsection{Training with and without perturbations}
This appendix shows in \cref{fig:test_acc} the mean test accuracy curves of standard SGD training (black), and training with SR (blue), S\&P (orange), and partial SR (green).
\begin{figure}[H]
\begin{center}
\centerline{\includegraphics[width=0.55\linewidth]{test_acc.pdf}}
\caption{Test accuracy of different training protocols with perturbation time $P=20$ epochs. Standard training in black, SR in blue, S\&P in orange, and partial SR in green. }
\label{fig:test_acc}
\end{center}
\end{figure}



