[
  {
    "index": 0,
    "papers": [
      {
        "key": "ptq2020",
        "author": "Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen",
        "title": "Up or down? adaptive rounding for post-training quantization"
      },
      {
        "key": "ptq2021",
        "author": "Li, Yuhang and Gong, Ruihao and Tan, Xu and Yang, Yang and Hu, Peng and Zhang, Qi and Yu, Fengwei and Wang, Wei and Gu, Shi",
        "title": "Brecq: Pushing the limit of post-training quantization by block reconstruction"
      },
      {
        "key": "ptq2022",
        "author": "Zheng, DanDan and Liu, Yuanliu and Li, Liang and others",
        "title": "Leveraging inter-layer dependency for post-training quantization"
      },
      {
        "key": "ptq2022b",
        "author": "Wei, Xiuying and Gong, Ruihao and Li, Yuhang and Liu, Xianglong and Yu, Fengwei",
        "title": "Qdrop: Randomly dropping quantization for extremely low-bit post-training quantization"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "integer-only",
        "author": "Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry",
        "title": "Quantization and training of neural networks for efficient integer-arithmetic-only inference"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "int_vs_fp",
        "author": "van Baalen, Mart and Kuzmin, Andrey and Nair, Suparna S and Ren, Yuwei and Mahurin, Eric and Patel, Chirag and Subramanian, Sundar and Lee, Sanghyuk and Nagel, Markus and Soriaga, Joseph and others",
        "title": "FP8 versus INT8 for efficient deep learning inference"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "loss_2015",
        "author": "Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\\'e}rard Ben and LeCun, Yann",
        "title": "The loss surfaces of multilayer networks"
      },
      {
        "key": "large_batch2016",
        "author": "Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter",
        "title": "On large-batch training for deep learning: Generalization gap and sharp minima"
      },
      {
        "key": "loss_2019",
        "author": "Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji",
        "title": "Deep ensembles: A loss landscape perspective"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "loss2021",
        "author": "Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya",
        "title": "Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel"
      },
      {
        "key": "loss_landscape",
        "author": "Yang, Yaoqing and Hodgkinson, Liam and Theisen, Ryan and Zou, Joe and Gonzalez, Joseph E and Ramchandran, Kannan and Mahoney, Michael W",
        "title": "Taxonomizing local versus global structure in neural network loss landscapes"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "loss_landscape",
        "author": "Yang, Yaoqing and Hodgkinson, Liam and Theisen, Ryan and Zou, Joe and Gonzalez, Joseph E and Ramchandran, Kannan and Mahoney, Michael W",
        "title": "Taxonomizing local versus global structure in neural network loss landscapes"
      }
    ]
  }
]