@article{emdimage,
  author  = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J.},
  doi     = {10.1023/A:1026543900054},
  isbn    = {1573-1405},
  journal = {Int. J. Comput. Vis.},
  pages   = {99},
  title   = {The {Earth} Mover's Distance as a Metric for Image Retrieval},
  volume  = {40},
  year    = {2000}
}

@inproceedings{Duarte:2022hdp,
    author = "Duarte, Javier and Tran, Nhan and Hawks, Ben and Herwig, Christian and Muhizi, Jules and Prakash, Shvetank and Reddi, Vijay Janapa",
    title = "{FastML Science Benchmarks: Accelerating Real-Time Scientific Edge Machine Learning}",
    booktitle = "{5th Conference on Machine Learning and Systems}",
    eprint = "2207.07958",
    archivePrefix = "arXiv",
    primaryClass = "cs.LG",
    reportNumber = "FERMILAB-CONF-22-534-PPD-SCD",
    month = "7",
    year = "2022"
}

@article{econ,
  title={A reconfigurable neural network ASIC for detector front-end data compression at the HL-LHC},
  author={Di Guglielmo, Giuseppe and Fahim, Farah and Herwig, Christian and Valentin, Manuel Blanco and Duarte, Javier and Gingu, Cristian and Harris, Philip and Hirschauer, James and Kwok, Martin and Loncar, Vladimir and others},
  journal={IEEE Transactions on Nuclear Science},
  volume={68},
  number={8},
  pages={2179--2186},
  year={2021},
  publisher={IEEE}
}


@article{Wei:2023mma,
    author = "Wei, Y. and Forelli, R. F. and Hansen, C. and Levesque, J. P. and Tran, N. and Agar, J. C. and Di Guglielmo, G. and Mauel, M. E. and Navratil, G. A.",
    title = "{Low latency optical-based mode tracking with machine learning deployed on FPGAs on a tokamak}",
    eprint = "2312.00128",
    archivePrefix = "arXiv",
    primaryClass = "physics.plasm-ph",
    reportNumber = "FERMILAB-PUB-23-655-CSAID",
    doi = "10.1063/5.0190354",
    journal = "Rev. Sci. Instrum.",
    volume = "95",
    number = "7",
    pages = "073509",
    year = "2024"
}

@article{Deiana:2021niw,
    author = "Deiana, Allison McCarn and others",
    title = "{Applications and Techniques for Fast Machine Learning in Science}",
    eprint = "2110.13041",
    archivePrefix = "arXiv",
    primaryClass = "cs.LG",
    reportNumber = "FERMILAB-PUB-21-502-AD-E-SCD",
    doi = "10.3389/fdata.2022.787421",
    journal = "Front. Big Data",
    volume = "5",
    pages = "787421",
    year = "2022"
}

@article{orthQNN,
  title={Understanding how orthogonality of parameters improves quantization of neural networks},
  author={Eryilmaz, Sukru Burc and Dundar, Aysegul},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={34},
  number={12},
  pages={10737--10746},
  year={2022},
  publisher={IEEE}
}


@inproceedings{orthCNN,
  title={Orthogonal convolutional neural networks},
  author={Wang, Jiayun and Chen, Yubei and Chakraborty, Rudrasis and Yu, Stella X},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11505--11515},
  year={2020}
}

@article{orth2018,
  title={Spectral normalization for generative adversarial networks},
  author={Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  journal={arXiv preprint arXiv:1802.05957},
  year={2018}
}

@article{orth2018b,
  title={Can we gain more from orthogonality regularizations in training deep cnns? arXiv 2018},
  author={Bansal, N and Chen, X and Wang, Z},
  journal={arXiv preprint arXiv:1810.09102}
}

@article{orth2018c,
  title={Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author={Brock, Andrew},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}



@article{jacobian,
  title={Robust learning with jacobian regularization},
  author={Hoffman, Judy and Roberts, Daniel A and Yaida, Sho},
  journal={arXiv preprint arXiv:1908.02729},
  volume={5},
  number={6},
  pages={7},
  year={2019}
}


@ARTICLE{jacobian2,
  author={Sokolić, Jure and Giryes, Raja and Sapiro, Guillermo and Rodrigues, Miguel R. D.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Robust Large Margin Deep Neural Networks}, 
  year={2017},
  volume={65},
  number={16},
  pages={4265-4280},
  keywords={Jacobian matrices;Robustness;Neural networks;Training;Optimization;Electronic mail;Transforms;Deep learning;deep neural networks;generalization error;robustness},
  doi={10.1109/TSP.2017.2708039}}



@article{loss_landscape,
  title={Taxonomizing local versus global structure in neural network loss landscapes},
  author={Yang, Yaoqing and Hodgkinson, Liam and Theisen, Ryan and Zou, Joe and Gonzalez, Joseph E and Ramchandran, Kannan and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18722--18733},
  year={2021}
}


@article{visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


@article{visulazing2014,
  title={Qualitatively characterizing neural network optimization problems},
  author={Goodfellow, Ian J and Vinyals, Oriol and Saxe, Andrew M},
  journal={arXiv preprint arXiv:1412.6544},
  year={2014}
}

@misc{visualizing2017b,
      title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima}, 
      author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
      year={2017},
      eprint={1609.04836},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1609.04836}, 
}

@inproceedings{visualizing2017,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={1019--1028},
  year={2017},
  organization={PMLR}
}

@article{visualizing2016,
  title={An Empirical Analysis of Deep Network Loss Surfaces},
  author={Daniel Jiwoong Im and Michael Tao and Kristin Branson},
  journal={ArXiv},
  year={2016},
  volume={abs/1612.04010},
  url={https://api.semanticscholar.org/CorpusID:13651606}
}

@inproceedings{pyhessian,
  title={Pyhessian: Neural networks through the lens of the hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={2020 IEEE international conference on big data (Big data)},
  pages={581--590},
  year={2020},
  organization={IEEE}
}


@article{mode_connectivity,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{mode_connectivity2,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},
  booktitle={International conference on machine learning},
  pages={1309--1318},
  year={2018},
  organization={PMLR}
}


@article{cka,
  title={Do Wide and Deep Networks Learn the Same Things},
  author={Nguyen, Thao and Raghu, Maithra and Kornblith, Simon},
  journal={Uncovering How Neural Network Representations Vary with Width and Depth Cs. Lg: arXiv: 2010.15327},
  year={2021}
}

@inproceedings{cka2,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={3519--3529},
  year={2019},
  organization={PMLR}
}


@article{fkeras,
  title={Fkeras: A sensitivity analysis tool for edge neural networks},
  author={Weng, Olivia and Meza, Andres and Bock, Quinlan and Hawks, Benjamin and Campos, Javier and Tran, Nhan and Duarte, Javier Mauricio and Kastner, Ryan},
  journal={Journal on Autonomous Transportation Systems},
  year={2024},
  publisher={ACM New York, NY}
}


@inproceedings{parseval,
  title={Parseval networks: Improving robustness to adversarial examples},
  author={Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas},
  booktitle={International conference on machine learning},
  pages={854--863},
  year={2017},
  organization={PMLR}
}

@article{defensive,
  title={Defensive quantization: When efficiency meets robustness},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  journal={arXiv preprint arXiv:1904.08444},
  year={2019}
}


@software{brevitas,
  author       = {Alessandro Pappalardo},
  title        = {Xilinx/brevitas},
  year         = {2023},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3333552},
  url          = {https://doi.org/10.5281/zenodo.3333552}
}

@inproceedings{ptq2020,
  title={Up or down? adaptive rounding for post-training quantization},
  author={Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
  booktitle={International Conference on Machine Learning},
  pages={7197--7206},
  year={2020},
  organization={PMLR}
}

@article{ptq2021,
  title={Brecq: Pushing the limit of post-training quantization by block reconstruction},
  author={Li, Yuhang and Gong, Ruihao and Tan, Xu and Yang, Yang and Hu, Peng and Zhang, Qi and Yu, Fengwei and Wang, Wei and Gu, Shi},
  journal={arXiv preprint arXiv:2102.05426},
  year={2021}
}


@article{ptq2022,
  title={Leveraging inter-layer dependency for post-training quantization},
  author={Zheng, DanDan and Liu, Yuanliu and Li, Liang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={6666--6679},
  year={2022}
}


@article{ptq2022b,
  title={Qdrop: Randomly dropping quantization for extremely low-bit post-training quantization},
  author={Wei, Xiuying and Gong, Ruihao and Li, Yuhang and Liu, Xianglong and Yu, Fengwei},
  journal={arXiv preprint arXiv:2203.05740},
  year={2022}
}


@incollection{survey_quant,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Low-Power Computer Vision},
  pages={291--326},
  year={2022},
  publisher={Chapman and Hall/CRC}
}

@article{survey_quant2,
author = {Rokh, Babak and Azarpeyvand, Ali and Khanteymoori, Alireza},
title = {A Comprehensive Survey on Model Quantization for Deep Neural Networks in Image Classification},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3623402},
doi = {10.1145/3623402},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {97},
numpages = {50},
keywords = {discrete neural network optimization, image classification, deep neural network acceleration, model compression, Quantization}
}

@article{int_vs_fp,
  title={FP8 versus INT8 for efficient deep learning inference},
  author={van Baalen, Mart and Kuzmin, Andrey and Nair, Suparna S and Ren, Yuwei and Mahurin, Eric and Patel, Chirag and Subramanian, Sundar and Lee, Sanghyuk and Nagel, Markus and Soriaga, Joseph and others},
  journal={arXiv preprint arXiv:2303.17951},
  year={2023}
}


@inproceedings{integer-only,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}

@article{large_batch2016,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{hessian_2018,
  title={Hessian-based analysis of large batch training and robustness to adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{loss_2015,
  title={The loss surfaces of multilayer networks},
  author={Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'e}rard Ben and LeCun, Yann},
  booktitle={Artificial intelligence and statistics},
  pages={192--204},
  year={2015},
  organization={PMLR}
}

@article{loss_2019,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02757},
  year={2019}
}

@article{loss2021,
  title={Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel},
  author={Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5850--5861},
  year={2020}
}

@article{loss_survey,
  title={The global landscape of neural networks: An overview},
  author={Sun, Ruoyu and Li, Dawei and Liang, Shiyu and Ding, Tian and Srikant, Rayadurgam},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={5},
  pages={95--108},
  year={2020},
  publisher={IEEE}
}

@article{pruning_survey,
  title={A survey on deep neural network pruning: Taxonomy, comparison, analysis, and recommendations},
  author={Cheng, Hongrong and Zhang, Miao and Shi, Javen Qinfeng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{pruning_survey_2,
  title={Methods for pruning deep neural networks},
  author={Vadera, Sunil and Ameen, Salem},
  journal={IEEE Access},
  volume={10},
  pages={63280--63300},
  year={2022},
  publisher={IEEE}
}

@article{nas_survey,
  title={Neural architecture search: A survey},
  author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={55},
  pages={1--21},
  year={2019}
}

@article{telescope_loss,
  title={Differentiable Earth mover’s distance for data compression at the high-luminosity LHC},
  author={Shenoy, Rohan and Duarte, Javier and Herwig, Christian and Hirschauer, James and Noonan, Daniel and Pierini, Maurizio and Tran, Nhan and Suarez, Cristina Mantilla},
  journal={Machine Learning: Science and Technology},
  volume={4},
  number={4},
  pages={045058},
  year={2023},
  publisher={IOP Publishing}
}

@article{adv_training,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}
