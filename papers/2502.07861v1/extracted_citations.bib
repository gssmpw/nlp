@Article{ALS21,
  title= "Discrepancy minimization via a self-balancing walk",
  author= "Ryan Alweiss and Yang P. Liu and Mehtaab Sawhney",
  journal="Proceedings of the 53rd ACM Symposium on the Theory of Computing (STOC ’2021)",
  year="2021"
}

@article{B10,
    author = {Bansal, Nikhil},
    title = {Constructive algorithms for discrepancy minimization},
    journal = {51th Annual IEEE Symposium on Foundations of Computer Science (FOCS ’2010), arXiv:1002.2259},
    year = {2010}
}

@article{B12,
    author = {Banaszczyk, Wojciech},
    title = {On series of signed vectors and their rearrangements},
    journal = {Random Structures and Algorithms 40 (2012), 301–316},
    year = {2012}
}

@article{B98,
    author = {Banaszczyk, Wojciech},
    title = {Balancing vectors and gaussian measures of n-dimensional convex bodies},
    journal = {Random Structures and Algorithms 12 (1998), 351–360},
    year = {1998}
}

@article{BJSS19,
    author = {Bansal, Nikhil and Jiang, Haotian and Singla, Sahil and Sinha, Makrand},
    title = {Online vector balancing and geometric discrepancy},
    journal = {In Proceedings of the 52nd Annual ACM Symposium on Theory of Computing (STOC ’2020), arXiv:1912.03350},
    year = {2019}
}

@article{CKW24,
    author = {Charikar, Moses and Kapralov, Michael and Waingarten, Erik},
    title = {A Quasi-Monte Carlo Data Structure for Smooth Kernel Evaluations},
    journal = {In Proceedings of the 35th ACM-SIAM Symposium on Discrete Algorithms (SODA ’2024), arXiv:2401.02562},
    year = {2024}
}

@article{DNTT18,
    author = {Dadush, Daniel and Nikolov, Aleksandar and Talwar, Kunal and Tomczak-Jaegermann, Nicole},
    title = {Balancing vectors in any
norm},
    journal = {59th Annual IEEE Symposium on Foundations of Computer Science (FOCS ’2018)},
    year = {2018} 
}

@article{KRR23,
    author = {Kulkarni, Janardhan and Reis, Victor and Rothvoss, Thomas},
    title = {Optimal Online Discrepancy Minimization},
    journal = {In Proceedings of the 56th Annual ACM Symposium on Theory of Computing (STOC ’2024), arXiv:2308.01406},
    year = {2023}
}

@article{PT20,
    author = {Phillips, Jeff M and Tai, Wai Ming},
    title = {Near-optimal coresets for kernel density estimates},
    journal = {Discrete and Computational Geometry, 63(4):867–887},
    year = {2020}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{cai2024pyramidkv,
  title={Pyramidkv: Dynamic kv cache compression based on pyramidal information funneling},
  author={Cai, Zefan and Zhang, Yichi and Gao, Bofei and Liu, Yuliang and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and others},
  journal={arXiv preprint arXiv:2406.02069},
  year={2024}
}

@article{dong2024qaq,
  title={QAQ: Quality Adaptive Quantization for LLM KV Cache},
  author={Dong, Shichen and Cheng, Wen and Qin, Jiayu and Wang, Wei},
  journal={arXiv preprint arXiv:2403.04643},
  year={2024}
}

@article{fu2024not,
  title={Not all heads matter: A head-level KV cache compression method with integrated retrieval and reasoning},
  author={Fu, Yu and Cai, Zefan and Asi, Abedelkadir and Xiong, Wayne and Dong, Yue and Xiao, Wen},
  journal={arXiv preprint arXiv:2410.19258},
  year={2024}
}

@article{hooper2024kvquant,
  title={KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization},
  author={Hooper, Coleman and Kim, Sehoon and Mohammadzadeh, Hiva and Mahoney, Michael W and Shao, Yakun Sophia and Keutzer, Kurt and Gholami, Amir},
  journal={arXiv preprint arXiv:2401.18079},
  year={2024}
}

@article{kang2024gear,
  title={Gear: An efficient kv cache compression recipefor near-lossless generative inference of llm},
  author={Kang, Hao and Zhang, Qingru and Kundu, Souvik and Jeong, Geonhwa and Liu, Zaoxing and Krishna, Tushar and Zhao, Tuo},
  journal={arXiv preprint arXiv:2403.05527},
  year={2024}
}

@article{kim2024lexico,
  title={Lexico: Extreme KV Cache Compression via Sparse Coding over Universal Dictionaries},
  author={Kim, Junhyuck and Park, Jongho and Cho, Jaewoong and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2412.08890},
  year={2024}
}

@article{li2024snapkv,
  title={Snapkv: Llm knows what you are looking for before generation},
  author={Li, Yuhong and Huang, Yingbing and Yang, Bowen and Venkitesh, Bharat and Locatelli, Acyr and Ye, Hanchen and Cai, Tianle and Lewis, Patrick and Chen, Deming},
  journal={arXiv preprint arXiv:2404.14469},
  year={2024}
}

@article{liu2024kivi,
  title={KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache},
  author={Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia},
  journal={arXiv preprint arXiv:2402.02750},
  year={2024}
}

@article{liu2024scissorhands,
  title={Scissorhands: Exploiting the persistence of importance hypothesis for llm kv cache compression at test time},
  author={Liu, Zichang and Desai, Aditya and Liao, Fangshuo and Wang, Weitao and Xie, Victor and Xu, Zhaozhuo and Kyrillidis, Anastasios and Shrivastava, Anshumali},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xiao2023efficient,
  title={Efficient streaming language models with attention sinks},
  author={Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
  journal={arXiv preprint arXiv:2309.17453},
  year={2023}
}

@article{yang2024no,
  title={No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization},
  author={Yang, June Yong and Kim, Byeongwook and Bae, Jeongin and Kwon, Beomseok and Park, Gunho and Yang, Eunho and Kwon, Se Jung and Lee, Dongsoo},
  journal={arXiv preprint arXiv:2402.18096},
  year={2024}
}

@article{yue2024wkvquant,
  title={Wkvquant: Quantizing weight and key/value cache for large language models gains more},
  author={Yue, Yuxuan and Yuan, Zhihang and Duanmu, Haojie and Zhou, Sifan and Wu, Jianlong and Nie, Liqiang},
  journal={arXiv preprint arXiv:2402.12065},
  year={2024}
}

@article{zandieh2024qjl,
  title={QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead},
  author={Zandieh, Amir and Daliri, Majid and Han, Insu},
  journal={arXiv preprint arXiv:2406.03482},
  year={2024}
}

@article{zandieh2024subgen,
  title={SubGen: Token Generation in Sublinear Time and Memory},
  author={Zandieh, Amir and Han, Insu and Mirrokni, Vahab and Karbasi, Amin},
  journal={arXiv preprint arXiv:2402.06082},
  year={2024}
}

@article{zhang2024h2o,
  title={H2o: Heavy-hitter oracle for efficient generative inference of large language models},
  author={Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\'e}, Christopher and Barrett, Clark and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhang2024kv,
  title={KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization},
  author={Zhang, Tianyi and Yi, Jonah and Xu, Zhaozhuo and Shrivastava, Anshumali},
  journal={arXiv preprint arXiv:2405.03917},
  year={2024}
}

