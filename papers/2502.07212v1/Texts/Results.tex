\section{Evaluation}
\label{sec:Results}
\subsection{Computation Accuracy}

Since the exponent array is implemented in the digital domain without computation errors, we focus on presenting the computing accuracy of our mantissa MAC array.
We compare the results from circuit-level simulations through the CIM macro and its ground truth which
%based on a Python script.
% The ground truth of the test 
is obtained by simulating the computation flow through a Python script. 
We obtain the product of $4\times4$-b inputs and the $4\times4$-b weights.  
The computation error across multiple combinations of 4-b inputs and 4-b weights are shown in Fig.~\ref{computation error}.
It is small within 1.51\% range.
The result shows that the proposed hybrid-domain computing introduces minimal computation error.

\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{Figures/output6.png} % 
     \vskip -6pt
    \caption{The
computation error across multiple combinations of 4-b inputs
and 4-b weight}
    \label{computation error}
     \vskip -15pt
\end{figure}
% This accuracy is mainly focus on charge accumulator and ADC encoder.

% \subsubsection{Baseline}
% The ground truth of test is obtained by simulating the computation flow through python script. We obtain the sum and product of a input $4\times4$ matrix X and a weight $4\times4$  matrix W, respectively.  

% \subsubsection{Result}


We then apply the computed error to FP products based on FP arithmetic and inject this error into FP8 models to examine its effect on model accuracy.
We evaluate accuracy across various FP DNN models using the MLPerf Edge Inference Benchmark Suite v4.0, which encompasses a diverse range of deep learning tasks. 
As shown in Table~\ref{tab:model_performance}, our proposed hybrid-domain architecture effectively maintains inference accuracy, with only approximately 1\% variation observed for ResNet and BERT models, and virtually no accuracy loss for RetinaNet. 
This outcome underscores our macro’s reliability in preserving system-level inference accuracy, likely due to the inherent robustness of these models.

% Specifically, we evaluate ResNet-50 v1.5 on ImageNet, RetinaNet on OpenImages, and BERT-large on SQuAD v1.1 undering FP16 format. 



\iffalse
We present the accuracy of our mantissa MAC  is to compare the multiplication of FP through CIM macro and its truth value. This accuracy is mainly focus on charge accumulator and ADC encoder.
\subsubsection{Baseline}
The ground truth of test is obtained by simulating the computation flow through python script. We obtain the sum and product of a input $4\times4$ matrix X and a weight $4\times4$  matrix W, respectively.  
%input Xm and weight Wm are 4x4 matrix, so there are 2^16 times 2^16 situations. we can randomly pick some of them for verification.
\subsubsection{Result}
To evaluate the system-level inference performance of our proposed SRAM CIM structure, we assess its accuracy across various FP DNN models using the MLPerf Edge Inference Benchmark Suite v4.0, which spans diverse deep learning tasks []. Specifically, we evaluate ResNet-50 v1.5 on ImageNet, RetinaNet on OpenImages, and BERT-large on SQuAD v1.1 undering FP16 format. Table  \label{model_performance}  shows that our HyCIM structure maintains inference accuracy effectively, with approximately a 1\% accuracy variation for ResNet and BERT, and nearly no accuracy drop for RetinaNet. This demonstrates that our macro reliably preserves system-level inference accuracy. This observation may be attributed to the inherent robustness of the models.


\fi




\begin{table}[h]
    \centering
        \caption{Model Performance on Different Datasets.} 
    \renewcommand{\arraystretch}{1.2} % 调整行距
             \vskip -6pt
    \begin{tabular}{|p{1.5cm}|p{1.5cm}|p{2.5cm}|p{1cm}|}
        \hline
        \textbf{Model} & \textbf{Dataset} & \textbf{Baseline} \textbf{Accuracy}& \textbf{Result} \\
        
        \hline
        ResNet50 & ImageNet & 76.01\% (top1 Acc)& 75.68\% \\
        \hline
        BERT-base & SQuAD v1.1 & 90.73\% (f1\_score)& 89.49\% \\
        \hline
        Retinanet & Open Images & 0.3759 (mAP)& 0.3709\\
        \hline
    \end{tabular}   \label{tab:model_performance}
             \vskip -12pt
\end{table}

 
\subsection{Energy Comparison}

We designed the proposed Mantissa MAC unit using 28 nm CMOS technology and compared its energy efficiency to a fully digital baseline, which includes a digital multiplier at each memory cell (enabled by a NAND gate), a local digital adder tree, an accumulator, and registers.
Energy data for the digital baseline is derived from the quantitative model in ~\cite{sun2023analog}. 
Table~\ref{tab:energy_breakdown} illustrates the comparison, showing our design achieves $1.53\times$ energy efficiency compared to the digital CIM.


% scale the sub-ADD and sub-MUL with capacitance, delay, area of single NAND2 gate. 


% The traditional fully digital CIM macro consists of a 6T-SRAM and a NAND gate.
% It totally has 10 transistors (4 PMOS and 6 NMOS) which is the same as our macro. 
% Thus, the configuration like capacitance, area and delay will be close. 
% The result of this comparison is convincing. 
% From the Table.\textcolor{blue}{ \label{energy_breakdown}} , it captured the energy of sub-ADD, sub-MUL and baseline which is DCIM.
% The energy efficiency of our design is 34.8\% than DCIM.




\iffalse

Energy breakdown from the Quantitative model of paper ~\cite{sun2023analog}, scale the sub-ADD and sub-MUL with capacitance, delay, area of single NAND2 gate. The traditional fully digital CIM macro consists of a 6T-SRAM and a NAND gate. It totally has 10 transistors (4 PMOS and 6 NMOS) which is the same as our macro. Thus, the configuration like capacitance, area and delay will be close. The result of this comparison is convincing. From the Table.{ \label{energy_breakdown}} , it captured the energy of sub-ADD, sub-MUL and baseline which is DCIM. The energy efficiency of our design is 34.8\% than DCIM.

\fi


\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.2} % 调整行距
    \caption{Energy Breakdown Estimation (fJ/MAC).}
                 \vskip -6pt
    \begin{tabular}{|p{1.2cm}|p{1cm}|p{1cm}|p{1.5cm}|p{1.1cm}|p{0.8cm}|}
        \hline
        \textbf{Operation} & \textbf{Add/} 
        \textbf{Multi}& \textbf{Adder Tree} & \textbf{Accumulator}/ \textbf{ADC}& \textbf{Register} & \textbf{Total} \\
        \hline
        sub-ADD  & 0.896 & 10.752 & 10.752 & 6.720 & 29.120\\
        \hline
        sub-MUL  & 1.792 & 8.064& 7.04& 5.376& 22.272 \\
        \hline
        Baseline  & 3.584 & 34.944 & 26.880 & 13.440  & 78.848\\
        \hline
        Efficiency & - & - & - &- & 1.53$\times$ \\
        \hline
    \end{tabular}  \label{tab:energy_breakdown}
             \vskip -12pt
\end{table}

\subsection{Area Breakdown Estimation}
%Area overhead

We finally show the area efficiency of the proposed mantissa MAC unit.
Each cell consists of a 6T-SRAM cell, a pseudo AND, and a pseudo XOR, totaling 11 transistors (4 PMOS and 7 NMOS). 
The SRAM cell and pseudo AND are symmetrical, resulting in a compact and efficient mantissa computing unit, as shown in Fig.~\ref{fig:mantissa_layouts}(a).
It leads to a 42.8\% area overhead of the initial 6T SRAM cell.
When expanded to configurations of two or four cells, the layout achieves even greater symmetry and space efficiency, as shown in Fig.~\ref{fig:mantissa_layouts}(b).
As noted, a traditional digital CIM macro, which uses NAND gates attached to each memory cell, employs a nearly identical number of transistors, thus resulting in minimal area variation between the two macros.



% As is mentioned above, a traditional DCIM macro has the same transistors number as our macro, only one transistor difference in doping type. Thus, there is no large area variation on these two macros.


\iffalse
The element mantissa MAC unit includes a 6T-SRAM cell, a pseudo AND and a pseudo XOR. It has totally 11 transistors(4 PMOS and 7 NMOS). Notice that the SRAM cell and pseudo AND are symmetric. 
Thus, a nearly high compact mantissa computing unit is constructed as Fig.~\ref{fig:mantissa_layouts}(a) is shown. The initial SRAM cell is surrounded by yellow square, so the area overhead of mantissa MAC is 42.8\% than the initial SRAM cell.
Continue to expand the structure to 2 cells, 4 cells, it can be placed in a more symmetrical structure as shown in ~\ref{fig:mantissa_layouts}(b),  thus saving more space.
As is mentioned above, a traditional DCIM macro has the same transistors number as our macro, only one transistor difference in doping type. Thus, there is no large area variation on these two macros.

\fi


% SRAM cell area: 635.04
% MAC cell area  : 906.84

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.20\textwidth}
        \centering
        \includegraphics[width=0.8\linewidth]{Figures/layout.png} 
        \label{fig:mantissa_unit}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.215\textwidth}
        \centering
        \includegraphics[width=0.8\linewidth]{Figures/layout_4_cells.png} 
        \label{fig:four_cells}
    \end{subfigure}
         \vskip -6pt
    \caption{Mantissa MAC unit layouts: (a) Single mantissa computing unit, (b) Layout of 4 cells.}
         \vskip -15pt
    \label{fig:mantissa_layouts}
\end{figure}