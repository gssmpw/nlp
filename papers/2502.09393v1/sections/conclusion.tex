\section{Conclusion}
\label{sec:conclusion}

\noindent
The efficacy of hyperdimensional OGM techniques as an alternative for traditional OGM methods when leveraged for environmental exploration and autonomous driving remains largely unstudied. In this work, we investigate a hyperdimensional OGM technique, known as VSA-OGM~\cite{snyder2024brain}, and compare it against a well-established, traditional, OGM method known as BHM~\cite{senanayake2017bayesian}.
We evaluate the efficacy of VSA-OGM on two distinct reinforcement learning environments known as \textit{MarsExplorer}~\cite{Koutras2021MarsExplorer} and \textit{RaceCarGym}~\cite{Brunnbauer_racecar_gym}. We perform multiple tests with both environments across a range of scenarios and hyper-parameter combinations.

Our results show that VSA-OGM provides downstream policy networks with sufficient information to learn the environment and effectively perform unknown environment exploration and autonomous driving. We also perform multi-map training and evaluation where VSA-OGM presents approximately 47\% increased generalization performance compared to BHM on \textit{RaceCarGym} and 53\% on \textit{MarsExplorer} at the cost of 2 orders of magnitude increased latency because of increased point cloud densities.

% \hl{MP: Here you also need to add the latency issue with VSA-OGM}

Moving forward, we investigate methods to minimize the memory complexity of VSA-OGM by creating information theoretic methods to minimize adding redundant information to the memory hypervectors. We also investigate methods to minimize the encoding complexity with VSA-OGM as this is the major limitation when point cloud density increases.
% Moreover, we would like to quantify the problem complexity at which VSA-OGM improve policy generalizability to provide the broader academic community with a set of guidelines for the applicability of VSA-OGM. 
We also expand the scope of this exploration to also include model-based reinforcement learning algorithms.