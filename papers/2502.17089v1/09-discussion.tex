\section{Discussion}


The value of hybrid paper-digital interfaces that augment physical documents with digital content has been well established~\cite{han_hybrid_2021}. To realize hybrid documents, we propose a novel watermarking method that uses IR-based printing to store digital content as an intrinsic part of the document. Unlike previous approaches that rely on a network connection and external storage for the digital assets, our approach with \systemName~ maintains the document format as the single container of both physical and digital contents. 
% \hl{This approach provides additional benefits that interactions are network-free and more privacy-preserving.}
In this section, we discuss the limitations of using \systemName~ from the perspectives of authoring, printing, detection, and consumption. We also discuss future work to improve the approach.



\subsection{Towards Multimodal Content}
\systemName's interface currently supports only a rudimentary form of AR that only permits 2D visual content and audio and does not leverage multimodal content to its full potential. We hope that we will enable authors to embed more intricate objects and interactions in the future. Adding support for multimedia assets will pave the way to expanding on previously examined use cases ~\cite{alessandrini_audio-augmented_2014, rajaram_paper_2022}. The most impactful addition would be that of 3D assets since that would allow users to utilize the document as a spatial anchor. 



\subsection{Effects on Printed IR Ink}




\new{Our experiments investigated human and machine detectability under controlled indoor lighting and viewing conditions.}
\newCameraReady{However, the perception and reliability of printed IR ink can vary significantly depending on external factors such as illumination levels, viewing angles, and the type of paper used.
One key limitation is that low-light conditions may reduce the effectiveness of human detectability due to insufficient IR reflection, while excessive illumination, such as direct sunlight, could lead to overexposure, affecting both machine readability and ink longevity. Future work could explore adaptive imaging techniques or optimized illumination setups to mitigate these issues. 
Regarding \textit{paper type}, we anticipate that glossy or coated paper may introduce reflection artifacts, which could interfere with machine-based recognition systems by creating specular highlights that obscure ink contrast.
Conversely, highly porous or rough-textured paper might cause ink diffusion, potentially reducing print sharpness and affecting detection accuracy.
A promising direction is to systematically evaluate these effects using an experimental framework similar to Xu et al.'s methodology, where QR code robustness was tested under varying lighting conditions, scanning angles, and environmental factors \cite{xu_art-up_2021}. Applying a similar protocol could help quantify how different conditions impact IR ink detection and visibility.}



As with any other dye-based ink, UV-dependent fading is an inherent limitation~\cite{maxmax_-_llewellyn_data_processing_ir_2022} that is important to consider for document reliability and permanence. Constant exposure to heavy UV sources such as the sun can cause the inks to fade over time.
\citet{willis_hideout_2013} showed how different IR ink types can be used in conjunction with UV-resistant coatings to achieve 98\% contrast preservation under office lighting conditions. We envision that for commercial use cases where long-term preservation is desired, a similar coating can be applied, which is sufficient for indoor applications.


\subsection{Invisible IR Ink}
We used a psychophysical experiment to determine conservative estimates for the IR ink densities that remain invisible to users for a wide range of different background colors. As with most experiments, we were limited by the number of background colors that we could include in the experiment. \new{Therefore, we do not know how our results generalize to other background colors, combinations of colors, and different graphic patterns. Nevertheless, we developed a system that facilitates embedding with invisible IR ink for any RGB color. Note that our method is very conservative and favors invisibility over machine detection. The actual DTs are likely much higher, which should further improve machine detectability. Nevertheless, we contribute a methodology that designers can apply to determine the "sweet spot" between visibility, data capacity, and machine detectability.}




We also want to highlight that the gradient IR ink and background color bars used in our psychophysical experiment differ from QR codes which may have had an effect on our estimated invisible IR ink DTs. We decided against using QR codes in the experiment because (1) it would have only been possible to test QR codes at predefined densities (e.g., at 20\%, 40\%, ...), limiting the precision of the study, and (2) the limited number of samples, which would not reflect the variability of QR codes of different sizes. As a result, our experiment also aims to provide general estimates for shapes other than QR codes and may, therefore, be used as a starting point for any type of invisible IR-printed marker.   



\subsection{Discoverability and Practicality}
\label{NIR_AR_FormFactor}

\new{
To demonstrate \systemName, we used NIR-based fabrication and detection tools. While NIR cameras are getting popular in many handheld devices (e.g., \textit{iPhone} and \textit{iPad} use it for facial recognition and LIDAR 3D scanning), not all platforms currently give 3rd-party developers access to the raw NIR stream (e.g., only the processed depth map can be accessed on \textit{iOS}). We argue the interest in NIR applications will increase as more use cases are demonstrated by future projects.}
% And we want to add this to AR headsets in the future, which already come with NIR cameras (conventionally used for depth sensing).

In our current implementation, \systemName~ documents can optionally be marked with a small icon or visual label on the document in our embedding tool
to allow users to discover embedded AR content.
\new{We envision that next-generation AR hardware can more fully leverage \systemName's utility. Compared to using a handheld device, always-on AR smart glasses such as \textit{Meta} \textit{Orion} could be constantly scanning the environment for hidden AR content~\cite{di_gioia_investigating_2022, campos_zamora_moirewidgets_2024}.
Currently, most AR glasses already leverage NIR cameras, but mainly for localizing the user and mapping their environment for 3D tracking purposes. With head-worn AR glasses with integrated NIR cameras used for \systemName~ sensing, the user would not have to manually capture objects using the phone during the interaction. We recommend future research to focus on implementing this on AR glasses.}


