\section{Related Work}
Combining the digital and the physical worlds has been one of the main uses cases of augmented reality~\cite{dogan_fabricate_2022, dogan_augmented_2024}. %(also interchangeably used with the term ``mixed reality"~\cite{speicher_what_2019}). 
Below we explain how the two worlds interact with each other, how paper specifically is used for these interactions, %and how interactions are specified using tags in previous works.
and how tags are used to specify interactions in previous works.





\subsection{Hybrid Paper-Digital Interfaces}
The benefits of hybrid paper-digital interfaces have been extensively explored in prior work~\cite{rajaram_paper_2022, li_holodoc_2019, alessandrini_audio-augmented_2014, song_penlight_2009}. Han et al. conducted a systematic literature review and defined hybrid paper-digital interfaces as \textit{"any interface embedding digital or electronic functionality in physical paper to enable its use as an input or output device"}~\cite{han_hybrid_2021}.

To enable input and enhance digital paper applications, researchers proposed integrating electronics into paper sheets, such as sensors~\cite{gong_printsense_2014, jacoby_drawing_2013}, actuators~\cite{qi_electronic_2010}, or illuminated displays~\cite{klamka_illuminated_2017, klamka_illumipaper_2017}.
Buechley et al. further proposed \textit{paper computing}~\cite{buechley_paints_2009} as a concept to allow users to create functional computational artifacts on painted paper substrates using a combination of these paper-embedded components as well as microcontrollers.
On the other hand, leveraging AR  is a common technique used to add a digital information layer but avoid integrating electronics into paper.
For instance, \textit{Dually Noted}~\cite{qian_dually_2022} and \textit{HoloDoc}~\cite{li_holodoc_2019} demonstrate the utility of augmenting paper for improving productivity tasks for phone- or headset-based AR.
\textit{PapARVis}~\cite{chen_augmenting_2020} and \textit{Paper Trail}~\cite{rajaram_paper_2022} explore authoring workflows that support educational and data visualization use cases.
%These include dynamic media  such as animations and interactive UI components.
\textit{PaperLens}~\cite{spindler_paperlens_2009} tracks sheets in 3D space above a top-projected tabletop~\cite{steimle_physical_2010} to visualize and interact with 3D information spaces.
\textit{SpARklingPaper}~\cite{drey_sparklingpaper_2022} augments paper sheets from below using a tabletâ€™s screen placed underneath.
The paper augmentation in these projects are enabled by systems such as dedicated standalone apps that were tailored for specific use cases. Most of these leverage image tracking libraries such as \textit{Vuforia}\footnote{\url{https://developer.vuforia.com/}}, \textit{ARKit}\footnote{\url{https://developer.apple.com/augmented-reality/arkit/}}, and \textit{ARCore}\footnote{\url{https://developers.google.com/ar/}}. These utilize visual features (\textit{SURF}, \textit{SIFT}) or fiducial markers (\textit{ArUco}~\cite{garrido2014automatic}, QR codes\footnote{\url{https://www.qrcode.com/en/}}, \textit{ARToolKit}~\cite{kato1999marker}),  which is based on previous research in computer vision (CV)~\cite{wagner2010RealTimeDetection, Wagner2008PoseTracking}. While visual feature based tracking does not require the addition of new visual elements such as QR codes, they do not carry high capacity to be able to represent a \textit{\textbf{unique and direct} anchor %or connection
to digital experiences}.
% These systems maintain the AR content in a separate database, and are configured for a specific use case, which hinders portability.
In contrast, \textit{AniCode}~\cite{wang_anicode_2019} uses QR codes to store entire animation sequences contextual to an object, without having to access digital content from an external service.
A remaining limitation is that %the pre-encoded content is not interactive and
the visible QR codes become obtrusive in the user's view as longer sequences are embedded.






In this work, we investigate invisible IR watermarking as the fabrication method to enable hybrid documents to be portable containers of \textit{both} physical (visual) and digital (invisible) content. Our aim is to preserve documents' defining attribute of portability by \textit{making its digital link \textbf{an intrinsic part} of the document}.









\subsection{Linking Digital Information to Physical}


To connect paper documents to digital content, machine-readable printed codes, such as barcodes, have been actively used as a compact and cheaper way to embed digital information~\cite{dogan_ubiquitous_2024}. 
2D barcodes, such as QR codes, store information in the form of contrasting bits, but affect the original design as they occupy space and impact the visual look of the final artifact~\cite{getschmann_seedmarkers_2021, song_my_2018}, particularly those that store large amounts of data~\cite{denso_wave_information_2022}. 
Thus, researchers explored making more unobtrusive camera-detectable tags to create a more seamless, discreet user experience~\cite{dogan_g-id_2020, dogan_structcode_2023}.
For this goal, works investigated subtle pixel manipulations to encode data \textit{unobtrusively}~\cite{fu_chartem_2021, xiao_fontcode_2018, tancik_stegastamp_2020, zhang_viscode_2021}.
For instance, \textit{Chartem}~\cite{fu_chartem_2021} encodes subtle pixels into chart background, %, which can be used to restore the data used to create the chart.
however, it only supports digital versions of charts, i.e., the data cannot be robustly decoded once they are printed.
% For example, \textit{Chartem}~\cite{fu_chartem_2021} encodes subtle pixels into the background of data visualizations, which can be used to restore the data used to create the chart.
% \textit{FontCode}~\cite{xiao_fontcode_2018} embeds information into text documents by perturbing the pixels of a given font.
% \textit{StegaStamp}~\cite{tancik_stegastamp_2020} subtly perturbs photographs to encode data bits unobtrusively.
% \hl{However, these approaches only work with digital versions of the visualizations, i.e., the information cannot be robustly decoded once the document is printed.}
Methods that support printed documents can only leverage colored pixels and are thus limited in the amount of stored information. % that can be stored.
For instance, \textit{StegaStamp}~\cite{tancik_stegastamp_2020} can encode up to 7 characters into a single image, and \textit{FontCode}~\cite{xiao_fontcode_2018}  encodes 1.77 bits per character (e.g., a 1,000-character paper abstract would store 221 encoded characters).
Furthermore, they cannot store information in non-printed white space, which is a typical part of documents.



\systemName~leverages the \textit{\textbf{whole} document area, including text, graphics, and white space, to increase capacity and support the embedding of \textbf{digital (invisible)} content regardless of the physical (visual) content layout.}



\subsection{Aesthetically Integrated Visual Markers}
Another relevant approach is to make the markers human-designable so that they seamlessly blend into the aesthetics of the content.
This relies on visual features that follow a predefined set of rules, allowing the system to decode the integrated marker. 
For example, \textit{d-touch} \cite{Enrico_visualMarkers_2009} uses the relationship of dark and light regions in the image for binary encoding.
%To achieve this, it represents the image topologically in a region adjacency black and white tree.
While the initial technique was limited to smaller areas and black and white, \citet{Preston_MarkerScale_2017} extend this approach to impressive scale and aesthetics by adding area order codes and visual checksums.
\citet{Benford_Decoration_2017} went beyond paper-based interfaces by embedding computer-readable codes in the form of decorations to ceramic bowls, fabric souvenirs, and an acoustic guitar, demonstrating the wide application space.

Studies showed that designers can incorporate these high-capacity codings in their visual designs \cite{Enrico_visualMarkers_2009, Jung_HumanDesignable_2019}.
However, it may require additional mental effort, be prone to errors, and limit artistic freedom.
%To address some of these issues, \citet{Jung_HumanMarker_2019} presented the \textit{Helper Overlay} to assist artists, indicating where visual features should be added or removed, and an \textit{Autocomplete Tool} which directly adds required features to the drawing to produce a decodable result.
They are further challenged by the necessity to adapt the visual design to specific rules and remain limited to areas displaying content. Moreover, visual markers can only be used during the creation process \cite{Jung_HumanMarker_2019}, whereas \systemName~\textit{can be used as \textbf{part of the fabrication process} or added \textbf{on demand}.}
Nevertheless, this impressive line of research demonstrates how high-capacity markers can seamlessly blend into artistic images, inspiring us to look into alternative approaches that allow invisible data embeddings while preserving the aesthetics of new and existing content.
Ultimately, we hope the techniques could complement one another to allow for even higher data capacities.




\begin{figure*}[]
  \centering
  \includegraphics[width=0.85\linewidth]{figures-new/FigureSpectralAnalysis.png}
  \caption{Spectral analysis of the inkjet inks.}
  \Description{.}
  \label{fig:inkSpectrumFigure}
\end{figure*}






\subsection{Infrared-Based Tags}
%To store invisible tags, infrared (IR) based approaches have emerged as a robust alternative. 
\new{IR based approaches such as patterns projected by external sources~\cite{lee_hybrid_2007, Kakehi2006Transparent}, materials that pass~\cite{dogan_infraredtags_2022}, reflect~\cite{kim_ministudio_2016, balaji_retrosphere_2023}, absorb~\cite{rosner_spyn_2010, willis_hideout_2013}, or fluoresce~\cite{dogan_brightmarker_2023} IR light to embed patterns have emerged.}
%\hl{Lee et al.}~\cite{lee_hybrid_2007} use hybrid projection of infrared and visible light to track the location of physical surfaces via invisible projected patterns.
For instance, 
\textit{MiniStudio}~\cite{kim_ministudio_2016} tracks objects by adding IR-reflective stickers
%attached to them, which were augmented
with fiducial markers
using screen printing.
\textit{InfraredTags}~\cite{dogan_infraredtags_2022} covers fiducial markers with an opaque material that passes IR light to make them imperceptible.

As for IR-absorbing materials, 
\textit{Spyn}~\cite{rosner_spyn_2010} adds such inks into knitted artifacts to embed hidden information.
\textit{HideOut}~\cite{willis_hideout_2013} creates hidden tracking markers from IR-absorbing ink to project digital imagery on physical paper; however, a spray gun is needed to evenly coat the paper surface.
Wang et al.~\cite{wang_design_2008} showed how different IR absorption characteristics of CMY and black ink can be used to subtly embed fiducial markers; however, it is limited to dark areas\footnote{\url{https://frauzufall.de/en/2020/print-invisible-ir-markers-using-a-standard-printer/}}.
Similar to this work, we leverage the convenience and accessibility of commodity inkjet printers, commonly used in ubiquitous computing research~\cite{kawahara_instant_2013,cheng_silver_2020}, which allow us to print hybrid interfaces rapidly using the encoded data, but \systemName~\textit{also makes use of the \textbf{empty space} in the document}.



\vspace{0.2cm}
To summarize, %In contrast to previous approaches, 
\systemName~ has three main benefits that allow it to rapidly create portable %and privacy-preserving 
hybrid document experiences:
(1) We utilize the whole document area, including text, graphics, and white space to increase the freedom of placement and amount of data that can be invisibly stored in new and exciting content. % (up to 3,080 characters).
(2) We can rapidly create these encoded documents without having to use complicated or manual processes such as spraying or screen printing, thanks to commercially available inkjet printers and inks.
(3) We build on previous demonstrations~\cite{dogan_standarone_2023} and establish a scientific basis on how to use perception research to truly hide digital IR content for different classes of visibly printed content, while optimizing for machine detection and information capacity using ML.