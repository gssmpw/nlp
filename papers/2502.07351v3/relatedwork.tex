\section{Related Work}
\label{sec:relatedwork}
%
    Deep learning-based methods have achieved remarkable performance in ID, LLIE, and NHIE. For daytime image hazing, researchers have proposed a variety of deep neural network methods, including single-image dehazing networks \cite{qin2020ffa,song2023vision,cai2016dehazenet,li2017aod}, multi-scale feature fusion networks \cite{xu2024mvksr,gong2024tsnet}, and frameworks that combine deep learning with physical scattering models \cite{lu2024aosrnet,yin2024multi}. Similarly, deep learning methods have also led to notable advancements in LLIE \cite{liu2022rank,lin2023smnet,hou2024global,guo2020zero,wu2022uretinex}. Nighttime dehazing remains more challenging, as low-light conditions often introduce noise and color distortion, while haze causes light scattering and contrast reduction, further complicating visibility restoration. To address these issues, researchers have explored methods such as multi-dimensional information fusion \cite{liao2018hdp,cong2024semi}, combined low-light image processing algorithms \cite{li2015nighttime,jin2023enhancing,zhang2016nighttime}, and generative adversarial network-based models \cite{zheng20234k,koo2020nighttime}. These recent works have not only enriched the research methods, but also yielded more effective solutions for practical applications \cite{zhang2019kindling}.
%    
\subsection{Daytime Image Dehazing}
%
    He et al. \cite{he2010single} introduced the influential Dark Channel Prior method, and other early dehazing methods similarly rely on the physical atmospheric scattering model to estimate parameters such as atmospheric light, transmission maps, and scene radiance \cite{yu2011fast,fattal2014dehazing}. However, these physics-based methods often struggle under complex lighting conditions or when scene depth varies significantly. Qin et al. \cite{qin2020ffa} proposed FFANet that fuses multi-scale features to enhance detail recovery in hazy images, which exhibits limited adaptability to scenes with non-uniform haze distributions. Gong et al. \cite{gong2024tsnet} developed a two-stage network, which combines multi-scale feature fusion with an adaptive learning mechanism.But introduces additional computational overhead and demands a large amount of labeled training data. Yin et al. \cite{yin2024multi} integrated the atmospheric scattering model into a multi-stage dehazing framework, effectively blending physics-based and learning-based approaches. However, their method shows limited generalization in real-world scenarios and requires additional parameter tuning to handle different haze conditions.
%    
\subsection{Low-light Image Enhancement}
%
    Traditional LLIE methods \cite{land1977retinex,guo2016lime,pizer1987adaptive}, such as Retinex-based algorithms, histogram equalization and gamma correction, aim to enhance contrast by redistributing pixel intensity, clarifying dark regions but often amplifying noise. Recent state-of-the-art LLIE strategies incorporate deep neural networks. For instance, URetinexNet \cite{wu2022uretinex} unrolls a Retinex-based optimization problem into a deep network guided by implicit prior regularization, featuring modules for data-dependent initialization and iterative optimization, enabling adaptive illumination adjustment. Retinexformer \cite{cai2023retinexformer} integrates Retinex theory with a Transformer architecture in a one-stage model that simultaneously estimates illumination and corrects artifacts caused by overexposure. Hou et al. \cite{hou2024global} proposed a diffusion-based framework with global structure-aware curvature regularization to enhance contrast and preserve details for structure-aware contrast enhancement. However, challenges such as noise amplification, color distortion, and susceptibility to overexposure persist, limiting real-world applicability.
%    
\subsection{Nighttime Image Dehazing}
%
    Optical model-based methods \cite{zhang2014nighttime,li2015nighttime,zhang2017fast,pei2012nighttime} extend daytime dehazing models by estimating atmospheric light and transmission maps, often incorporating preprocessing to handle nighttime-specific distortions.  Li et al. \cite{li2015nighttime} proposed a glow removal technique  that separates halo artifacts from the scene using layer decomposition and adjusts for multi-colored light sources. Koo et al. \cite{koo2020nighttime} introduced a GAN-based framework that decomposes images into haze and glow components, allowing the generator to specifically suppress halos from bright light sources. Zheng et al. \cite{zheng20234k} employed a channel-spatial mixer for depth estimation and a domain adaptation module to translate synthetic hazy data to real-world haze. Cong et al. \cite{cong2024semi} proposed a spatial-frequency interaction module to address localized distortions while preserving realistic brightness levels. Despite these advances, nighttime dehazing remains challenging due to the combined effects of dense haze, low illumination, and glare from artificial light sources. Even state-of-the-art methods often struggle with residual glow artifacts or color distortions in such conditions, indicating the need for more robust and adaptive solutions.
    
%
    %
    \begin{figure*}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=1.00\linewidth]{Figure_MKoIE}
        \caption{Overall architecture of the multi-knowledge-oriented nighttime haze image enhancement (MKoIE) framework. The framework is designed to simultaneously handle three types of degradation tasks: ID, LLIE, and NHIE. By integrating multi-knowledge learning mechanisms, SA module, and MRFE module, it effectively improves image quality under complex degradation scenarios. The whole process of MKoIE is summarized in Algorithm \ref{alg:allprocess}.}
        \label{figure:MKoIE}
    \end{figure*}
    %