\section{Related Work}
\label{sec:relatedwork}
%
    Deep learning-based methods have achieved remarkable performance in ID, LLIE, and NHIE. For daytime image hazing, researchers have proposed a variety of deep neural network methods, including single-image dehazing networks **He et al., "Single Image Haze Removal using Dark Channel Prior"**, multi-scale feature fusion networks **Qin et al., "Multi-Scale Feature Fusion Network for Single Image Dehazing"**, and frameworks that combine deep learning with physical scattering models **Yin et al., "Hybrid Physics-Based and Deep Learning Model for Daytime Image Dehazing"**. Similarly, deep learning methods have also led to notable advancements in LLIE **Chen et al., "Retinex-Based Low-Light Image Enhancement Using Deep Neural Networks"**. Nighttime dehazing remains more challenging, as low-light conditions often introduce noise and color distortion, while haze causes light scattering and contrast reduction, further complicating visibility restoration. To address these issues, researchers have explored methods such as multi-dimensional information fusion **Wang et al., "Multi-Dimensional Information Fusion for Nighttime Image Dehazing"**, combined low-light image processing algorithms **Hou et al., "Diffusion-Based Framework with Global Structure-Aware Curvature Regularization for Low-Light Image Enhancement"**, and generative adversarial network-based models **Koo et al., "GAN-Based Framework for Nighttime Image Dehazing"**. These recent works have not only enriched the research methods, but also yielded more effective solutions for practical applications **Li et al., "Glow Removal Technique for Nighttime Image Dehazing"**.
%    
\subsection{Daytime Image Dehazing}
%
    He et al. **He et al., "Single Image Haze Removal using Dark Channel Prior"** introduced the influential Dark Channel Prior method, and other early dehazing methods similarly rely on the physical atmospheric scattering model to estimate parameters such as atmospheric light, transmission maps, and scene radiance **Qin et al., "Estimating Atmospheric Light and Transmission Maps for Daytime Image Dehazing"**. However, these physics-based methods often struggle under complex lighting conditions or when scene depth varies significantly. Qin et al. **Qin et al., "Multi-Scale Feature Fusion Network for Single Image Dehazing"** proposed FFANet that fuses multi-scale features to enhance detail recovery in hazy images, which exhibits limited adaptability to scenes with non-uniform haze distributions. Gong et al. **Gong et al., "Two-Stage Network for Daytime Image Dehazing"** developed a two-stage network, which combines multi-scale feature fusion with an adaptive learning mechanism.But introduces additional computational overhead and demands a large amount of labeled training data. Yin et al. **Yin et al., "Hybrid Physics-Based and Deep Learning Model for Daytime Image Dehazing"** integrated the atmospheric scattering model into a multi-stage dehazing framework, effectively blending physics-based and learning-based approaches. However, their method shows limited generalization in real-world scenarios and requires additional parameter tuning to handle different haze conditions.
%    
\subsection{Low-light Image Enhancement}
%
    Traditional LLIE methods **Chen et al., "Retinex-Based Low-Light Image Enhancement Using Deep Neural Networks"**, such as Retinex-based algorithms, histogram equalization and gamma correction, aim to enhance contrast by redistributing pixel intensity, clarifying dark regions but often amplifying noise. Recent state-of-the-art LLIE strategies incorporate deep neural networks. For instance, URetinexNet **Liu et al., "URetinexNet: Unrolling Retinex-Based Optimization for Low-Light Image Enhancement"** unrolls a Retinex-based optimization problem into a deep network guided by implicit prior regularization, featuring modules for data-dependent initialization and iterative optimization, enabling adaptive illumination adjustment. Retinexformer **Xu et al., "Retinexformer: A One-Stage Model for Simultaneous Illumination Estimation and Artifact Correction"** integrates Retinex theory with a Transformer architecture in a one-stage model that simultaneously estimates illumination and corrects artifacts caused by overexposure. Hou et al. **Hou et al., "Diffusion-Based Framework with Global Structure-Aware Curvature Regularization for Low-Light Image Enhancement"** proposed a diffusion-based framework with global structure-aware curvature regularization to enhance contrast and preserve details for structure-aware contrast enhancement. However, challenges such as noise amplification, color distortion, and susceptibility to overexposure persist, limiting real-world applicability.
%    
\subsection{Nighttime Image Dehazing}
%
    Optical model-based methods **Li et al., "Glow Removal Technique for Nighttime Image Dehazing"** extend daytime dehazing models by estimating atmospheric light and transmission maps, often incorporating preprocessing to handle nighttime-specific distortions.  Li et al. **Li et al., "Glow Removal Technique for Nighttime Image Dehazing"** proposed a glow removal technique  that separates halo artifacts from the scene using layer decomposition and adjusts for multi-colored light sources. Koo et al. **Koo et al., "GAN-Based Framework for Nighttime Image Dehazing"** introduced a GAN-based framework that decomposes images into haze and glow components, allowing the generator to specifically suppress halos from bright light sources. Zheng et al. **Zheng et al., "Channel-Spatial Mixer for Depth Estimation and Domain Adaptation Module for Real-World Haze Translation"** employed a channel-spatial mixer for depth estimation and a domain adaptation module to translate synthetic hazy data to real-world haze. Cong et al. **Cong et al., "Spatial-Frequency Interaction Module for Localized Distortion Correction and Realistic Brightness Preservation"** proposed a spatial-frequency interaction module to address localized distortions while preserving realistic brightness levels. Despite these advances, nighttime dehazing remains challenging due to the combined effects of dense haze, low illumination, and glare from artificial light sources. Even state-of-the-art methods often struggle with residual glow artifacts or color distortions in such conditions, indicating the need for more robust and adaptive solutions.
    
%
    %
    \begin{figure*}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=1.00\linewidth]{Figure_MKoIE}
        \caption{Overall architecture of the multi-knowledge-oriented nighttime haze image enhancement (MKoIE) framework. The framework is designed to simultaneously handle three types of degradation tasks: ID, LLIE, and NHIE. By integrating multi-knowledge learning mechanisms, SA module, and MRFE module, it effectively improves image quality under complex degradation scenarios. The whole process of MKoIE is summarized in Algorithm \ref{alg:allprocess}.}
        \label{figure:MKoIE}
    \end{figure*}