\section{Upper Bounds of Shortest Paths}
\label{sec:UpperBounds}

Although Corollary~\ref{acpte} reduces the number of computations required to establish the arc consistency of the constraint, it systematically computes a large number of shortest paths. 
Precisely, the algorithm involves computing the shortest path between each assigned value and all other values which makes it difficult to use in practice. 
In addition, the constraint is often arc consistent, rendering any computation useless.
The aim of our approach is therefore to reduce the number of operations computed unnecessarily. 

We present a much more applied approach, based on the fact that Corollary~\ref{acpte} relies on the existence of a path of length less than a given value. It is not necessary to know the path precisely, or even to know its value. An upper bound is sufficient.

We can therefore immediately establish the following proposition:
    \begin{proposition}
         Let $B^+(x, a) \geq d_{R(f)}(x,a)$ be any upper bound on the length of the shortest path from $x$ to $a$. If 
            \[B^+(x, a) \leq H-cost(f)-rc_{ax}\]
        then the value $a$ of a variable $x$ is consistent with $C$.
    \end{proposition}

A good way of obtaining an upper bound on a distance between two points is to use the triangle inequality.
Here we are talking about the triangle inequality with respect to the shortest path distances in the graph, not an embedding in Euclidean space or some other metric, which need not be present.
    \begin{property}
        Let $x$, $y$, and $p$ be three nodes of a graph. According to the triangle inequality computed on shortest paths, we have:
        \[d(x, p) + d(p, y) \geq d(x, y)\]
        \label{property:triangleInequality}
        Here, $p$ is a particular node called landmark.
    \end{property}

Upper bounds obtained by the triangular inequality have been shown to be useful for guiding the computation of shortest paths. The ALT algorithm, yielding excellent results in practice for computing shortest paths in a very large graph, is based on this technique~\cite{Goldberg:ComputingtheShortestPath:ASearchMeetsGraphTheory}. 
    
Property~\ref{acxpte} and Corollary~\ref{acpte} can be rewritten for landmarks:
\begin{proposition}        \label{proposition:consistentArcWithHub}
    Given any variable $x$ such that $f_{bx} = 1$, $a$ any value of $x$ and $p$ any landmark. If one of the two condition is satisfied
   \[d_{R(f)}(x, p) + d_{R(f)}(p, a) \leq H - cost(f) - rc_{ax}\] 
    \[d_{R(f)}(b, p) + d_{R(f)} (p, a) \leq H - cost(f) - rc_{ax} - rc_{xb}\]
    
    then the value $a$ of $x$ is consistent with $C$.
\end{proposition}

The residual graph may have several strongly connected components. Each component must be treated separately. Thus, at least one landmark per component must be selected.

Thanks to the use of upper bounds we can go even further. It is possible to compute the consistency of all values of variables of a strongly connected component by checking a single condition.

\begin{definition}
    Consider $S$ a strongly connected component of $R(f)$, $p$ a landmark in $S$, $x \in S$ a variable, and $a$ a value of $x$. We define:
\begin{itemize}
    \item $d^{max}_{R(f)}(\cdot, p)=\max_{x \in S}(d_{R(f)}(x, p))$ 
    \item $d^{max}_{R(f)}(p, \cdot)=\max_{x \in S}(d_{R(f)}(p, x))$
    \item $rc^{max}=\max_{x \in S, a \in D(x)}(rc_{ax})$ 
\end{itemize}
\end{definition}

This leads to the following proposition:
\begin{proposition}        \label{proposition:formulemagique}
        Given $S$ a strongly connected component of $R(f)$ and $p$ a landmark in $S$. If 
        $$d^{max}_{R(f)}(\cdot, p) + d^{max}_{R(f)}(p, \cdot) \leq H - cost(f) - rc^{max}$$
        then all the values of all the variables involved in $S$ are consistent with $C$.
    \end{proposition}


The advantage of this method is that if the condition is satisfied, we can guarantee that all the values of a strongly connected component are consistent by computing only two shortest paths per landmark.

\begin{figure}
    \centering
    \begin{tikzpicture}[
        round/.style={regular polygon, regular polygon sides=6, draw=black},
        square/.style={rectangle, draw=black},
        oval/.style={rounded rectangle, draw=black, minimum width=1.5cm, minimum height=0.7cm},
        flecheG/.style={{Stealth[scale=1.3]}-},
        flecheD/.style={-{Stealth[scale=1.3]}},
        align=center
        every node/.style={transform shape}
        ]
    %Nodes
    
    \node[oval] (x1) [] {Peter};
    \node[oval] (x2) [below of=x1] {Paul};
    \node[oval] (x7) [below of=x2, yshift=-0.5cm] {Julia};

    \node[square] (x8) [right of=x1, yshift=0cm, xshift= 1.5cm] {A};
    \node[square] (x9) [draw=red, below of=x8, thick] {B};
    \node[square] (x11) [below of=x9] {D};
    \node[square] (x12) [below of=x11] {E};

    \node[oval] (x3) [right of=x8, yshift=0cm, xshift= 1.5cm] {Mary};
    \node[oval] (x4) [below of=x3] {John};
    \node[round] (xs) [draw=red, below of=x4, yshift=-0.5cm, xshift= 0cm, thick]      {s};

    

    \node (w1) [right of=x1, yshift=0.2cm, xshift= -0cm] {-1};
    \node (w2) [right of=x1, yshift=-0.2cm, xshift= -0cm] {4};
    \node (w3) [right of=x2, yshift=0.2cm, xshift= -0cm] {-1};
    \node (w4) [right of=x2, yshift=-0.2cm, xshift= -0cm] {4};
    
    \node (w5) [left of=x3, yshift=0.2cm, xshift= 0cm] {3};
    \node (w6) [left of=x3, yshift=-0.2cm, xshift= -0cm] {-1};
    \node (w7) [left of=x4, yshift=0.2cm, xshift= 0cm] {3};
    \node (w8) [left of=x4, yshift=-0.2cm, xshift= -0cm] {-1};
    
    \node (w11) [right of=x7, yshift=0.4cm, xshift= -0.2cm] {-1};
    \node (w12) [right of=x7, yshift=-0.4cm, xshift= -0.2cm] {1};
    \node (w13) [left of=xs, yshift=0.4cm, xshift= 0.4cm] {0};
    \node (w14) [left of=xs, yshift=-0.4cm, xshift= 0.4cm] {0};


    
    
    %%%

    \draw[flecheG] (xs) -- (x11);
    \draw[flecheD] (xs) -- (x12);

    \draw[flecheG] (x8) -- (x1);
    \draw[flecheG] (x8) -- (x2);
    \draw[flecheD] (x8) -- (x3);
    \draw[flecheD] (x8) -- (x4);

    \draw[flecheD] (x9) -- (x1);
    \draw[flecheD] (x9) -- (x2);
    \draw[flecheG] (x9) -- (x3);
    \draw[flecheG] (x9) -- (x4);

    \draw[flecheG] (x11) -- (x7);
    \draw[flecheD] (x12) -- (x7);

    \end{tikzpicture} 

    \caption{Example of landmark use. Nodes $B$ and $s$, shown in red, are selected as landmarks.}
    \label{fig:exampleLandmark}
\end{figure}



Figure~\ref{fig:exampleLandmark} gives an example of a residual graph on which Proposition~\ref{proposition:consistentArcWithHub} or~\ref{proposition:formulemagique} can be applied. There are 2 strongly connected components $\{Peter, A, Mary, Paul, B, John\}$ and $\{Julia, D, s, E\}$. At least 2 landmarks are required (one for each component). We select $B$ and $s$ arbitrarily. 

Thanks to Proposition~\ref{proposition:formulemagique} we see that the maximum shortest path through $s$ is the path from $D$ to $Julia$ with $d^{max}_{R(f)}(\cdot, S)=d(D, s)=0$ and $d^{max}_{R(f)}(s, \cdot)=d(s, Julia)=1$. Furthermore, the longest arc of this strongly connected component is $rc^{max}=rc_{EJulia}=1$. Thus we have $d(D, s)+d(s, Julia)=1$ and $H-cost(f) - rc_{EJulia}=3$, so we have $1 \leq 3$. This confirms that all the values of variables in the strongly connected component of $s$ are consistent with the constraint.
If the Proposition~\ref{proposition:formulemagique} can guarantee that all values of variables are consistent in this strongly connected component then we can easily deduce that the Proposition~\ref{proposition:consistentArcWithHub} can also do it.

For the first strongly connected component, Proposition~\ref{proposition:consistentArcWithHub} and~\ref{proposition:formulemagique} do not guarantee the consistency 
of the values of the variables. It is therefore necessary to compute exact shortest paths between values and variables.

\section{Improved Filtering Algorithm}
\label{sec:ImprovedFilteringAlgorithm}
We can now describe Algorithm~\ref{alg:algorithm}, which eliminates values that are inconsistent with the constraint. The algorithm takes as parameters a min cost flow $f$, its residual graph $R(f)$, a strongly connected component represented by its set of nodes $S$ and $P$ a set of landmarks of $S$. This algorithm must therefore be called for each strongly connected component. The algorithm begins by checking whether Proposition~\ref{proposition:formulemagique} holds. If true, then the algorithm stops, since this means that all the values of the variables in the connected component $S$ are consistent.
Otherwise, it is necessary to check each value potentially inconsistent individually.
So, for each of those values Proposition~\ref{proposition:consistentArcWithHub} is checked. If it is satisfied, then the value is consistent, otherwise an explicit shortest path is computed to determine whether the value is consistent or not.

\begin{algorithm}[tb]
{\footnotesize
\fntitrealgo{arcConsistencyWithLandmarks}$(f,R_f,S,P)$\;
    \For{$p \in P$}{
        $d(p, \cdot) \leftarrow shortestPath_{R(f)}(p, \cdot)$ // shortest path in $R(f)$ \; 
        $d(\cdot, p) \leftarrow shortestPath_{\overline{R}(f)}(p, \cdot)$ // shortest path in $\overline{R}(f)$, the reverse graph of $R(f)$ \;
    }
    // Check of Proposition~\ref{proposition:formulemagique} \;
    $rc^{max} \leftarrow \max_{x \in S, a \in D(x)}(rc_{ax})$ \;
    \For{$p \in P$}{
    $d^{max}_{R(f)}(\cdot, p) \leftarrow \max_{x \in S}(d_{R(f)}(x, p))$ \; 
    $d^{max}_{R(f)}(p, \cdot) \leftarrow \max_{x \in S}(d_{R(f)}(p, x))$ \;
    \If{$d^{max}_{R(f)}(\cdot, p) + d^{max}_{R(f)}(p, \cdot) \leq H - cost(f) - rc^{max}$}{
        // all values of all variables of $S$ are consistent \;
        return \;
    }
    }
    $\Delta \leftarrow \{a$ such that $f_{sa} > 0\}$ \;
    \For{value b $\in \Delta$}{
        \For{$x$ such that $f_{bx} =1$}{
            $\delta (b) \leftarrow \{a$ such that $a \in D(x)$ and $a \neq b\}$ \;
            $computePath \leftarrow false$ \;
            // Check of Proposition~\ref{proposition:consistentArcWithHub} \;
            \For{$a \in D(x)$ {\bf while not} $computePath$}{
                $dpmin \leftarrow \min_{p \in P}(d_{R(f)}(x, p) + d_{R(f)}(p, a))$\;
                \If{ $dpmin > H - cost(f) - rc_{ax}$}{$computePath \leftarrow true$ \;}
            }
            // Check for an explicit shortest path computation \;
            \If{$computePath$}{
                $d_{R(f)}(b, \cdot) \leftarrow shortestPath(b, \cdot)$ \;
                \For{$a \in D(x)$}{
                    \lIf{$d_{R(f)}(b, a) > H - cost(f) - rc_{ax} - rc_{xb}$}{
                        remove $a$ from $D(x)$}
                }
            }
        }
    }
    }
    \caption{Arc Consistency Algorithm for a Strongly Connected Component}
    \label{alg:algorithm}
\end{algorithm}

When testing Corollary \ref{acpte}, we could refine the algorithm by identifying the nodes for which we need to search for a shortest path from $b$ to them, but this is not interesting in practice as the shortest path algorithm will quickly find that they are at an acceptable distance from $b$. 

\paragraph*{Practical improvements:}

One can compute landmarks only when they are needed. This consideration is effective in practice and a simple modified version of the basic algorithm is possible. This modification proceeds by iteration over the landmarks. Consider $V$ the set of values for which a shortest path must be computed. 

The following process is defined:
The landmark $p$ is considered. 
Proposition~\ref{proposition:formulemagique} is checked according to $p$. If it is satisfied then $V$ is emptied (all values are consistent) otherwise the values $V$ that satisfies Proposition~\ref{proposition:consistentArcWithHub} according to $p$ are removed from $V$, because they are consistent.

This process is repeated while $V$ is not empty and some landmarks remain. 
In other words, the landmarks are successively considered while the status of some values is not determined.

If there are no more landmarks to compute, then, and only then, shortest paths are explicitly computed for the value in $V$. 
In practice, it is frequent to find that all values are consistent without using all the landmarks.
This practical improvement means that not all landmarks need to be systematically computed.

Note that the landmark approach subsumes all the practical improvements proposed by Régin.

As far as the shortest path algorithm is concerned, it is interesting to remove the negative costs from the residual graph in order to use Dijkstra's algorithm, as mentioned by Régin. It only requires one shortest path computation~\cite{Regin:CostbasedArcConsistencyforGlobalCardinalityConstraints}. 

\paragraph*{Complexity:}

Let $SP$ be the complexity of computing a shortest path from one node to all others.
Régin's algorithm has a complexity of $\Omega(\delta \times SP)$ in the best case and $O(\delta \times SP)$ in the worst case, where $\delta$ is the number of assigned values.
With landmarks, the complexity in the best case is in $\Omega(FindP + |P| \times SP)$ where $|P|$ is the number of landmarks and $FindP$ is the complexity of finding the landmarks. This complexity is obtained when Proposition~\ref{proposition:formulemagique} detects that every value is consistent. Note that, this detection can happen on the first landmark and so we can have $|P|=1$. In the worst case, the complexity is the same as that of Régin's algorithm, provided that $|P|$ is in $O(\delta)$ and $FindP$ is in $O(\delta \times SP)$.
As with the ALT method, we consider several landmarks in order to have a better chance of finding landmarks that avoid explicit shortest path computations.
