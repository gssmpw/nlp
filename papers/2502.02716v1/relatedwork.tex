\section{Related Works}
\paragraph{Model Alignment} A wide body of research addresses the problem of model alignment~\citep{casper2023open, ji2023ai, hendrycks2021unsolved, leike2018scalable}. One of the primary approaches for model alignment is training the model on datasets consisting of human preferences on model generations~\citep{bai2022training, ouyang2022training, christiano2017deep, ziegler2019fine, yuan2023rrhf, rafailov2023direct, dong2023raft, liu2023chain, song2023preference, pal2024smaug, meng2024simpo}. A similar approach utilizes model-generated feedback to train other models for alignment~\citep{bai2022constitutional, lee2023rlaif, burns2023weak}. There are also a wide range of works that involve detecting when a language model may generate harmful text or hallucinations~\citep{du2024haloscope, yi2024jailbreak, jain2023baseline, malinin2020uncertainty, kuhn2023semantic, duan2023shifting, su2024unsupervised, yin2024characterizing, chen2024inside}. Another line of work aims to apply modifications to the model at generation time, including steering methods~\citep{khanov2024alignment, li2024inference, zou2023representation, rimsky-etal-2024-steering, liu2023context, lee2024programming, cao2024nothing, cao2024personalized, stickland2024steering, wang2024adaptive, subramani2022extracting, turner2023activation}. 

\textbf{Steering Model Behavior} \citet{subramani2022extracting} introduces the idea of learning a steering vector by optimizing the vector to maximize the probability of outputting target sentences. \citet{cao2024personalized} learns a steering vector by optimizing an objective that increases the ratio between the likelihood of the positive target sentence and that of a negative sentence. Other steering methods learn the steering vector by using the model's intermediate activations on contrastive examples such as replacing ``love" with ``hate"~\cite{turner2023activation, li2024inference, zou2023representation, rimsky-etal-2024-steering}. Recent works have introduced methods that allow for more controlled applications of steering vectors by using thresholds or having multiple vectors~\citep{lee2024programming, stickland2024steering, wang2024adaptive, cao2024nothing, chu2024causal}. \citet{tan2024analyzing} analyzes the generalization and reliability of steering vectors learned from CAA~\citep{rimsky-etal-2024-steering}, and \citet{singhrepresentation} analyzes affine steering functions. Our analysis focuses on the performance and theoretical understanding behind different steering methods. In existing literature~\citep{marks2023geometry, li2024inference, zou2023representation}, the comparison among different steering methods is limited to a single dataset or to simpler tasks such as classifying True/False statements. In contrast, we perform a more thorough evaluation and additionally provide theoretical reasoning to explain the performance of different methods in practice.