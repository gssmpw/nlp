[
  {
    "index": 0,
    "papers": [
      {
        "key": "casper2023open",
        "author": "Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\\'e}r{\\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others",
        "title": "Open problems and fundamental limitations of reinforcement learning from human feedback"
      },
      {
        "key": "ji2023ai",
        "author": "Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others",
        "title": "Ai alignment: A comprehensive survey"
      },
      {
        "key": "hendrycks2021unsolved",
        "author": "Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob",
        "title": "Unsolved problems in ml safety"
      },
      {
        "key": "leike2018scalable",
        "author": "Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane",
        "title": "Scalable agent alignment via reward modeling: a research direction"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "christiano2017deep",
        "author": "Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario",
        "title": "Deep reinforcement learning from human preferences"
      },
      {
        "key": "ziegler2019fine",
        "author": "Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey",
        "title": "Fine-tuning language models from human preferences"
      },
      {
        "key": "yuan2023rrhf",
        "author": "Zheng Yuan and Hongyi Yuan and Chuanqi Tan and Wei Wang and Songfang Huang and Fei Huang",
        "title": "RRHF: Rank Responses to Align Language Models with Human Feedback without tears"
      },
      {
        "key": "rafailov2023direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      },
      {
        "key": "dong2023raft",
        "author": "Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong",
        "title": "Raft: Reward ranked finetuning for generative foundation model alignment"
      },
      {
        "key": "liu2023chain",
        "author": "Hao Liu and Carmelo Sferrazza and Pieter Abbeel",
        "title": "Chain of Hindsight Aligns Language Models with Feedback"
      },
      {
        "key": "song2023preference",
        "author": "Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng",
        "title": "Preference ranking optimization for human alignment"
      },
      {
        "key": "pal2024smaug",
        "author": "Pal, Arka and Karkhanis, Deep and Dooley, Samuel and Roberts, Manley and Naidu, Siddartha and White, Colin",
        "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive"
      },
      {
        "key": "meng2024simpo",
        "author": "Meng, Yu and Xia, Mengzhou and Chen, Danqi",
        "title": "Simpo: Simple preference optimization with a reference-free reward"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      },
      {
        "key": "lee2023rlaif",
        "author": "Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav",
        "title": "Rlaif: Scaling reinforcement learning from human feedback with ai feedback"
      },
      {
        "key": "burns2023weak",
        "author": "Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker, Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien and Joglekar, Manas and Leike, Jan and others",
        "title": "Weak-to-strong generalization: Eliciting strong capabilities with weak supervision"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "du2024haloscope",
        "author": "Du, Xuefeng and Xiao, Chaowei and Li, Yixuan",
        "title": "Haloscope: Harnessing unlabeled llm generations for hallucination detection"
      },
      {
        "key": "yi2024jailbreak",
        "author": "Yi, Sibo and Liu, Yule and Sun, Zhen and Cong, Tianshuo and He, Xinlei and Song, Jiaxing and Xu, Ke and Li, Qi",
        "title": "Jailbreak attacks and defenses against large language models: A survey"
      },
      {
        "key": "jain2023baseline",
        "author": "Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom",
        "title": "Baseline defenses for adversarial attacks against aligned language models"
      },
      {
        "key": "malinin2020uncertainty",
        "author": "Malinin, Andrey and Gales, Mark",
        "title": "Uncertainty estimation in autoregressive structured prediction"
      },
      {
        "key": "kuhn2023semantic",
        "author": "Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation"
      },
      {
        "key": "duan2023shifting",
        "author": "Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Wang, Chenan and Zavalny, Alex and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi",
        "title": "Shifting attention to relevance: Towards the uncertainty estimation of large language models"
      },
      {
        "key": "su2024unsupervised",
        "author": "Su, Weihang and Wang, Changyue and Ai, Qingyao and Hu, Yiran and Wu, Zhijing and Zhou, Yujia and Liu, Yiqun",
        "title": "Unsupervised real-time hallucination detection based on the internal states of large language models"
      },
      {
        "key": "yin2024characterizing",
        "author": "Yin, Fan and Srinivasa, Jayanth and Chang, Kai-Wei",
        "title": "Characterizing truthfulness in large language model generations with local intrinsic dimension"
      },
      {
        "key": "chen2024inside",
        "author": "Chen, Chao and Liu, Kai and Chen, Ze and Gu, Yi and Wu, Yue and Tao, Mingyuan and Fu, Zhihang and Ye, Jieping",
        "title": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "khanov2024alignment",
        "author": "Khanov, Maxim and Burapacheep, Jirayu and Li, Yixuan",
        "title": "ARGS: Alignment as Reward-Guided Search"
      },
      {
        "key": "li2024inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-time intervention: Eliciting truthful answers from a language model"
      },
      {
        "key": "zou2023representation",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others",
        "title": "Representation engineering: A top-down approach to ai transparency"
      },
      {
        "key": "rimsky-etal-2024-steering",
        "author": "Rimsky, Nina  and\nGabrieli, Nick  and\nSchulz, Julian  and\nTong, Meg  and\nHubinger, Evan  and\nTurner, Alexander",
        "title": "Steering Llama 2 via Contrastive Activation Addition"
      },
      {
        "key": "liu2023context",
        "author": "Liu, Sheng and Ye, Haotian and Xing, Lei and Zou, James",
        "title": "In-context vectors: Making in context learning more effective and controllable through latent space steering"
      },
      {
        "key": "lee2024programming",
        "author": "Lee, Bruce W and Padhi, Inkit and Ramamurthy, Karthikeyan Natesan and Miehling, Erik and Dognin, Pierre and Nagireddy, Manish and Dhurandhar, Amit",
        "title": "Programming refusal with conditional activation steering"
      },
      {
        "key": "cao2024nothing",
        "author": "Cao, Zouying and Yang, Yifei and Zhao, Hai",
        "title": "Nothing in excess: Mitigating the exaggerated safety for llms via safety-conscious activation steering"
      },
      {
        "key": "cao2024personalized",
        "author": "Cao, Yuanpu and Zhang, Tianrong and Cao, Bochuan and Yin, Ziyi and Lin, Lu and Ma, Fenglong and Chen, Jinghui",
        "title": "Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization"
      },
      {
        "key": "stickland2024steering",
        "author": "Stickland, Asa Cooper and Lyzhov, Alexander and Pfau, Jacob and Mahdi, Salsabila and Bowman, Samuel R",
        "title": "Steering without side effects: Improving post-deployment control of language models"
      },
      {
        "key": "wang2024adaptive",
        "author": "Wang, Tianlong and Jiao, Xianfeng and He, Yifan and Chen, Zhongzhi and Zhu, Yinghao and Chu, Xu and Gao, Junyi and Wang, Yasha and Ma, Liantao",
        "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories"
      },
      {
        "key": "subramani2022extracting",
        "author": "Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E",
        "title": "Extracting latent steering vectors from pretrained language models"
      },
      {
        "key": "turner2023activation",
        "author": "Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J and Mini, Ulisse and MacDiarmid, Monte",
        "title": "Activation addition: Steering language models without optimization"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "subramani2022extracting",
        "author": "Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E",
        "title": "Extracting latent steering vectors from pretrained language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cao2024personalized",
        "author": "Cao, Yuanpu and Zhang, Tianrong and Cao, Bochuan and Yin, Ziyi and Lin, Lu and Ma, Fenglong and Chen, Jinghui",
        "title": "Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "turner2023activation",
        "author": "Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J and Mini, Ulisse and MacDiarmid, Monte",
        "title": "Activation addition: Steering language models without optimization"
      },
      {
        "key": "li2024inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-time intervention: Eliciting truthful answers from a language model"
      },
      {
        "key": "zou2023representation",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others",
        "title": "Representation engineering: A top-down approach to ai transparency"
      },
      {
        "key": "rimsky-etal-2024-steering",
        "author": "Rimsky, Nina  and\nGabrieli, Nick  and\nSchulz, Julian  and\nTong, Meg  and\nHubinger, Evan  and\nTurner, Alexander",
        "title": "Steering Llama 2 via Contrastive Activation Addition"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lee2024programming",
        "author": "Lee, Bruce W and Padhi, Inkit and Ramamurthy, Karthikeyan Natesan and Miehling, Erik and Dognin, Pierre and Nagireddy, Manish and Dhurandhar, Amit",
        "title": "Programming refusal with conditional activation steering"
      },
      {
        "key": "stickland2024steering",
        "author": "Stickland, Asa Cooper and Lyzhov, Alexander and Pfau, Jacob and Mahdi, Salsabila and Bowman, Samuel R",
        "title": "Steering without side effects: Improving post-deployment control of language models"
      },
      {
        "key": "wang2024adaptive",
        "author": "Wang, Tianlong and Jiao, Xianfeng and He, Yifan and Chen, Zhongzhi and Zhu, Yinghao and Chu, Xu and Gao, Junyi and Wang, Yasha and Ma, Liantao",
        "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories"
      },
      {
        "key": "cao2024nothing",
        "author": "Cao, Zouying and Yang, Yifei and Zhao, Hai",
        "title": "Nothing in excess: Mitigating the exaggerated safety for llms via safety-conscious activation steering"
      },
      {
        "key": "chu2024causal",
        "author": "Chu, Zhixuan and Wang, Yan and Li, Longfei and Wang, Zhibo and Qin, Zhan and Ren, Kui",
        "title": "A causal explainable guardrails for large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tan2024analyzing",
        "author": "Tan, Daniel and Chanin, David and Lynch, Aengus and Kanoulas, Dimitrios and Paige, Brooks and Garriga-Alonso, Adria and Kirk, Robert",
        "title": "Analyzing the generalization and reliability of steering vectors"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "rimsky-etal-2024-steering",
        "author": "Rimsky, Nina  and\nGabrieli, Nick  and\nSchulz, Julian  and\nTong, Meg  and\nHubinger, Evan  and\nTurner, Alexander",
        "title": "Steering Llama 2 via Contrastive Activation Addition"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "singhrepresentation",
        "author": "Singh, Shashwat and Ravfogel, Shauli and Herzig, Jonathan and Aharoni, Roee and Cotterell, Ryan and Kumaraguru, Ponnurangam",
        "title": "Representation Surgery: Theory and Practice of Affine Steering"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "marks2023geometry",
        "author": "Marks, Samuel and Tegmark, Max",
        "title": "The geometry of truth: Emergent linear structure in large language model representations of true/false datasets"
      },
      {
        "key": "li2024inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-time intervention: Eliciting truthful answers from a language model"
      },
      {
        "key": "zou2023representation",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others",
        "title": "Representation engineering: A top-down approach to ai transparency"
      }
    ]
  }
]