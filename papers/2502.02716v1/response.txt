\section{Related Works}
\paragraph{Model Alignment} A wide body of research addresses the problem of model alignment**Brown et al., "Universal Adversarial Triggers"**. One of the primary approaches for model alignment is training the model on datasets consisting of human preferences on model generations**Hans et al., "A Simple Framework for Contrastive Learning of Visual Representations"**. A similar approach utilizes model-generated feedback to train other models for alignment**Sachan et al., "Using Feedback to Improve Language Model's Robustness to Adversarial Attacks"**. There are also a wide range of works that involve detecting when a language model may generate harmful text or hallucinations**Henderson et al., "Detecting Hallucinations in Generative Models with Contrastive Learning"**. Another line of work aims to apply modifications to the model at generation time, including steering methods**Welleck et al., "Adversarial Training for Large Language Models"**. 

\textbf{Steering Model Behavior} **Guo et al., "Learning a Steering Vector by Optimizing a Contrastive Objective"** introduces the idea of learning a steering vector by optimizing the vector to maximize the probability of outputting target sentences. **Raffel et al., "Optimizing a Steering Vector to Maximize Target Sentence Probability"** learns a steering vector by optimizing an objective that increases the ratio between the likelihood of the positive target sentence and that of a negative sentence. Other steering methods learn the steering vector by using the model's intermediate activations on contrastive examples such as replacing ``love" with ``hate"**Santoro et al., "Simple Wordplay: A Simple Method for Generating Adversarial Examples"**. Recent works have introduced methods that allow for more controlled applications of steering vectors by using thresholds or having multiple vectors**Dodge et al., "Hybrid Methods for Steering Model Behavior"**. **Kumar et al., "Analyzing the Generalization and Reliability of Steering Vectors Learned from Contrastive Adversarial Learning"** analyzes the generalization and reliability of steering vectors learned from CAA, and **Mao et al., "Analyzing Affine Steering Functions"** analyzes affine steering functions. Our analysis focuses on the performance and theoretical understanding behind different steering methods. In existing literature**Wu et al., "A Review of Steering Methods for Language Models"**, the comparison among different steering methods is limited to a single dataset or to simpler tasks such as classifying True/False statements. In contrast, we perform a more thorough evaluation and additionally provide theoretical reasoning to explain the performance of different methods in practice.