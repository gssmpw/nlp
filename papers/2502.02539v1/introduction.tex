Ever since the inception of the field of Software Architecture (SA)~\cite{garlan1993_component_connector}, one of the goals has been to automate/semi-automate the generation of executable systems from architecture descriptions as this would increase compliance, promote traceability, etc. Over the years the SA community has been working towards realizing this goal through defining Architecture Description Languages (ADLs) and Domain Specific Languages (DSLs)~\cite{mehmood2013aspect,malavolta2012industry,aadl-robotics} and further developing approaches for code generations using model transformations. However, their application to practice has been limited due to the steep learning curve, lack of extensibility, support for tooling, etc~\cite{malavolta2012industry}.  On the other hand, with recent advancements in AI, Large Language Models (LLMs) are moving us ever closer to a world of increased automation, with applications across multiple Software Engineering (SE) tasks, as described by Hou et al. \cite{davidlo_llm_slr}. They have been used for software development, maintenance, requirements engineering, and more, with code generation and program repair being the most common applications \cite{davidlo_llm_slr}. There have also been several commercial tools such as ChatGPT, GitHub Copilot, and Cursor. However, this code generation has been in the context of generating low level code snippets, with the generation of software architecture components using LLMs being an unexplored space. 

%This is in contrast to the Software Architecture (SA) community, which has been working towards realizing automatic component generation through Architecture Description Languages (ADLs) and Domain Specific Languages (DSLs)~\cite{mehmood2013aspect,malavolta2012industry,aadl-robotics}.\\
To this end, we conduct an exploratory empirical study on the capability of LLMs to generate architectural components in the context of Functions-as-a-Service (FaaS), commonly referred to as serverless functions. FaaS supports event-driven architectural style and enables easy development due to the abstractions provided by the cloud provider, who manages the infrastructure for running the basic units of FaaS, called serverless functions. We choose serverless functions primarily due to the small size of their architectural component, as opposed to microservices or monoliths, where a single component may consist of thousands or even millions of lines of code. We believe that this can provide a first step when evaluating the architectural component generation capabilities of LLMs. We emphasize that the architectural components we deal with in our study are serverless functions, and we refer to the architectural component of FaaS as serverless functions in the remainder of this paper. As part of our study, we utilize 3 kinds of prompts containing information at different levels of abstraction, systematically select 4 open-source serverless repositories and 5 code-generation LLMs, generating a total of 145 serverless functions that we evaluate for functionality and code quality both with and without human intervention. 
The code and data for our study is available publicly. \footnote{Code and data available at: \url{https://doi.org/10.5281/zenodo.14539782}}

% \footnote{\url{https://anonymous.4open.science/r/LLM-ComponentGen-62DE/README.md}}.

The remainder of this paper is structured as follows: Section \ref{background} provides background information about Serverless Functions, LLMs and some prompting methods. Section \ref{related-work} describes related work. Section \ref{study-design} describes our research questions and the design of our study. Section \ref{results} presents results, which are discussed in Section \ref{discussion} along with a look into a possible future for GenAI for Software Architecture and the threats to validity of our study. Finally, Section \ref{conclusion} presents our conclusion and future work. 
