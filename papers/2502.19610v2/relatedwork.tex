\section{Related Work}
\label{sec:related_work}
% \subsection{Dialog Agents}

Many dialog agent tasks have been proposed, including offline task-oriented dialog \cite{andreas2020task} \cite{budzianowski2018multiwoz} and online user simulations using real humans or LM agents as responders \cite{gur2018user} \cite{he2018decoupling}. 
Question generation is a related task where agents seek information relevant to a downstream task, such as user intent \cite{min2020ambigqa} or relevant facts \cite{toles2023good}.
Some task-oriented dialog datasets focus on clarification and information seeking, such as \citet{zhang2023groundialog}.
However, datasets such as ShARC \cite{saeidi2018interpretation} and ClariT \cite{feng2023towards} only require "yes" or "no" questions.
BeNYfits expands on these works by adding a highly realistic, multi-turn dialog agent task requiring logical reasoning and domain-specific knowledge.
Similar tasks include MediQ \cite{li2024mediq}, which benchmarks medical diagnosis through dialog, and ClarQ-LLM \cite{gan2024clarq}, which focuses on discovering hidden information while playing an adventurer.
In comparison, BeNYfits focuses on logically reasoning legalistic tasks to reach a binary prediction.
% Additionally, the ability to combine overlapping opportunities into multi-label tasks (e.g., determine eligibility for school programs \textbf{and} child care) allows for the creation of increasingly complex tasks.
% These 
% \subsection{Code Generation-based Task-oriented Dialog}

Many works on tool-use have equipped language models with a code interpreter \cite{gupta2023visual} \cite{shen2024hugginggpt}, though fewer have specifically studied tool creation, e.g., \citet{qian2023creator}.
Several prior works have established the efficacy of code generation in dialog systems. 
\citet{chiu2023symbolic} propose grounding in code generated based on partner utterances and using symbolic planning to reason over the code. 
\citet{suris2023vipergpt} find code translations an effective intermediate representation for natural language questions.
\citet{nguyen2024dynasaur} create an LLM agent framework for dynamically creating and composing subtask actions based on code.
To the best of our knowledge, no other code generation-based approaches have been proposed for question generation in dialog. 
% Since most modern language models are trained on both natural language and code, using code as a proxy for natural language allows them to structure information into a compositional knowledge representation. 
% In addition, grounding can be done by executing the code or using the code as reference in the reasoning prompt.