% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

\usepackage{multirow}


% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

%Please add the following packages if necessary:
\usepackage{booktabs, multirow} % for borders and merged ranges
\usepackage{soul}% for underlines
\usepackage{xcolor,colortbl} % for cell colors
\usepackage{changepage,threeparttable} % for wide tables

% Import the listings package for code formatting
\usepackage{listings}  % For displaying code

\lstset{
    basicstyle=\ttfamily\footnotesize, % Font style for the code
    keywordstyle=\bfseries\color{blue},  % Color for keywords
    commentstyle=\itshape\color{green},      % Color for comments
    stringstyle=\color{red},         % Color for strings
    numbers=left,                   % Display line numbers on the left
    numberstyle=\tiny\color{gray},  % Style of line numbers
    stepnumber=1,                   % Step between line numbers
    numbersep=5pt,                  % Distance between code and line numbers
    backgroundcolor=\color{white},  % Background color of code blocks
    showstringspaces=false,         % Do not highlight spaces in strings
    breaklines=true,                % Enable line breaking
    breakatwhitespace=true,         % Break at whitespaces
    frame=single,                   % Add a frame around the code
    rulecolor=\color{black},        % Frame color
}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

\usepackage{pgf-pie}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}


% Custom
\usepackage{amsmath}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Program Synthesis Dialog Agents for Interactive Decision-Making}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Matthew Toles\textsuperscript{1}},
 \textbf{Nikhil Balwani\textsuperscript{1,2*}},
 \textbf{Rattandeep Singh\textsuperscript{1}},
 \textbf{Valentina Giulia Sartori Rodriguez\textsuperscript{1,3}},
 \textbf{Zhou Yu\textsuperscript{1}}
\\
 \textsuperscript{1}Columbia University,
 \textsuperscript{2}Amazon,
 \textsuperscript{3}Sciences Po Paris
\\
 \small{
   \textbf{Correspondence:} \href{mailto:mt3639@columbia.edu}{m.toles@columbia.edu}
 }\\
    \small{$^*$ This work was finished before author joined Amazon}
}

\begin{document}
\maketitle
\begin{abstract}
Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on the features of the user. 
% These problems have traditionally been solved by hand-coding web forms or decision trees.
Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, suggesting a need for agents that can automatically assist in decision-making.
Since relevant information is often only known to the user, it is important that these agents can ask the right questions.
Since agents determine when to terminate a conversation, they face a trade-off between accuracy and total questions asked, a useful metric for both user experience and cost.
To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making.
Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought.
We therefore introduce ProADA, a novel approach that uses program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action.
Our agent, ProADA, improves the F1 score to 55.6 while using nearly the same number of dialog turns.

\end{abstract}

\section{Introduction}

% Zach: I think the crux of this paper is that you have found a setting that 1a) is a real-world text-based task that requires multi-step reasoning, 1b) is a very important task for the broader adoption and impact of these models, 2) a task that GPT4o struggles at, and 3) you have a principled approach that does better. In my mind, this is very different from many other prog-synth dialogue agent papers, which focus on toy tasks and existing datasets.
% To me, I think in the intro (if you wanted) you could really push 1a and 1b before jumping into more technical formulations of decision problems/policies. I think ACL is quite applications/real-world oriented, and this would resonate.

% Something like: " The improved capabilities of large language models have refocused attention away from traditional benchmarks, and towards real-world tasks where automated systems could broadly benefit the public. Such tasks include helping users file taxes or apply for government benefits, and require determining a user's eligibility given limited information. This type of task is formally referred to as a decision problem ...

The improved capabilities of large language models have refocused attention away from traditional benchmarks and towards real-world tasks where automated systems could broadly benefit the public, such as improving access to public services. 
Many such opportunities require determining the user's eligibility based on the user's features and the task at hand, formally referred to as decision problems.
In adaptive decision scenarios, where information is revealed iteratively (e.g., medical diagnosis), one also wishes to minimize the number of queries.
For many important decision problems, the requirements are written in natural language, which must be translated into formal language or interpreted logically.
Also, critical information may be user-specific and known only to certain people, meaning that it often \textbf{must} be requested through dialog.
Finally, the diversity of problems in the real world places a premium on whether agents can generalize information gathering and logical reasoning to new domains.

User-facing decision problems have traditionally been solved using hard-coded forms (as in the American tax filing software TurboTax\footnote{https://turbotax.intuit.com/}) or dialog trees (as in video games).
However, hard-coded solutions struggle to generalize or extend to web-scale decision problems; opportunities found by web-scraping, crowd-sourcing, or from extremely large corpora such as national tax codes may be challenging to formalize, let alone decide on in real-time.
Methods to approach adaptive decision problems include multi-armed bandits, reinforcement learning, dynamic programming, and decision trees, but adapting these strategies to online natural language tasks is not trivial.
% However, adapting these strategies to online natural language tasks is not trivial, and constructing optimal decision trees is NP-complete \cite{laurent1976constructing}.
Recently, large language models have improved on a wide range of related tasks.
However, language models are known to struggle with reasoning over long contexts and hallucinating unstated information, both of which, as we will see, are common in adaptive decision problems.


To evaluate interactive decision-making, in Section \ref{sec:benyfits} we introduce BeNYfits, a language model agent task for determining user eligibility for real-world public benefits opportunities with overlapping eligibility requirements. \ref{fig:dialog-loop}.
In the single-opportunity scenario, the assistant agent could simply repeat the requirements and ask the user if they qualify.
However, BeNYfits' overlapping requirements present an interesting optimization challenge for dialog planning: how should models ``merge" eligibility requirements to avoid duplicating questions and maximize information gain?
We find that current large language models, including GPT-4o, struggle to perform significantly better than chance at determining user eligibility, suffering from hallucination, poor reasoning under uncertainty, overconfidence, and lost-in-the-middle problems observed in prior work \cite{huang2024survey}.


% We therefore introduce ProADA, however, achieves notably better accuracy without significantly increasing the number of dialog turns needed.


Given these weaknesses, we introduce a method for an agent that, given a natural language description of the user-facing decision problem, generates a program to request user input conversationally to solve the problem.
Specifically, we construct an agent consisting of a code module, which conducts dialog planning in the form of a Python program, and a dialog module, which asks questions based on the program state.
The agent then uses the dialog module to parse the user's response into structured data.
Our approach exploits a distinction that we observe between how dialog and code generation models handle long-range planning and uncertainty.
% We find that dialog models usually try to satisfy users in only one or two dialog turns, hedging their responses in the case of unknown variables, instead of conducting multiple quick turns before deciding on the final, precise response.
% Our agent, on the other hand, uses program synthesis to model uncertainties in the form of input variables.
% It is common for functions to receive numerous input parameters at their head but only use them far later in the execution or in rare edge cases depending on the program's logic.
Effectively, the formality and long-range conditional dependencies present in program synthesis training make them strong candidates for dialog planning.
% Additionally, the generated code can be executed deterministically in place of expensive language model calls, improving consistency, and interpretability while reducing cost and latency.
As a key contribution, in Section \ref{sec:proada} we present \underline{Pro}gram Synthesis \underline{A}daptive \underline{D}ecision \underline{A}gent, or ProADA, an agent that, given a natural language policy of a decision problem, generates Python code to structure the decision-making process and request minimal user input to make the correct decision.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/dialog_loop.png}
    \caption{Interactive decision-making dialog loop in BeNYfits. The agent is initialized with opportunity eligibility requirements for the "Train \& Earn" opportunity (simplified). The agent then asks questions to the user until the agent answers \textsc{Yes} to the \textsc{Ready} prompt, at which point it \textsc{Predict}s the user's eligibility. Note that the agent skips requirement 3a because youth cannot register for selective service. Similarly, it skips requirement 3c because it becomes irrelevant if the user is a former foster care youth.}
    \label{fig:dialog-loop}
\end{figure}





% ProADA first generates a Python program that determines user eligibility based on an input dictionary of user data, although at the outset the dictionary is empty.
% Upon running the program, whenever the program encounters an empty key, instead of throwing an error, the agent calls a chat model to generate a question to the user seeking the missing information.
% From the user's response, the chat model adds the missing value to the dictionary.
% The agent then repeats this process until the program terminates, returning the returned value.
% This method achieves \textcolor{red}{XX} improvement over baseline models by avoiding \textcolor{red}{[hallucination, etc.]}
% We hope that ProADA and the BeNYfits benchmark enable the development of agents capable of real-world information-seeking, thereby improving access to public services, government benefits, and other opportunities.

\noindent Our main contributions are as follows.\\
\noindent \textbf{1.} A novel agent benchmark for adaptive decision-making in dialog measuring agent accuracy and dialog turn efficiency in helping users determine eligibility for public, real-world opportunities.\\
\noindent \textbf{2.} A general and effective agent for adaptive decision-making in dialog that exploits program synthesis and tool use to plan dialog and adaptively request user information, improving both F1 score and dialog completion speed. 
\footnote{\href{https://github.com/mtoles/BeNYfits-ProADA/}{https://github.com/mtoles/BeNYfits-ProADA/}}



\section{BeNYfits: An Agent Benchmark for Public Benefit Eligibility Decisions} 
\label{sec:benyfits}

The determination of eligibility for many public opportunities, such as tax credits, scholarships, research funding opportunities, business incentives, charities, job listings, and social services, can be reduced to a binary decision problem. 
Since many requirements, such as age and income, overlap between programs, this creates an opportunity for agent assistants to make more efficient and adaptive decisions as compared to traditional methods like static web forms.
At the same time, determinations often require domain-specific knowledge to make accurate determinations, presenting a challenge in natural language understanding.
We present BeNYfits, a benchmark for decision-making on public benefits eligibility.
In BeNYfits, the agent's goal is to help users navigate complex decision-making processes, focusing on objective, documented opportunities requiring user input, then make a final determination on the user's eligibility based on the dialog, in the minimum number of dialog turns.

\subsection{Efficiency, Generalization, and User Experience}

Traditional methods for determining eligibility present several opportunities for improvement by intelligent agent assistants.
For small numbers of opportunities, we might convert natural language requirements into a web form or static chatbot dialog tree serving as an interface for hard-coded checking logic, similar to TurboTax.
However, this approach has several drawbacks.
First, many eligibility requirements are updated without notice, often annually, meaning eligibility performance will degrade over time without ongoing maintenance.
Second, opportunities may be crowdsourced or scraped from the Web dynamically, rendering manual coding impractical in favor of more generalizable, lower-latency solutions, such as language agents.
Moreover, due to the specificity of eligibility requirements, a potential applicant may need to find and examine many opportunities before discovering one for which they qualify.
Furthermore, requirements between similar opportunities frequently overlap, forcing users to answer the same questions repeatedly.
On the other hand, users may waste a lot of time if they discover that they are ineligible very late in the examination process, presenting an opportunity for adaptive decision-making algorithms.
An intelligent agent, however, should adaptively query the user for only the minimum necessary information, saving time, and improving user experience.

In BeNYfits, an agent must interact with a simulated user to determine their household's eligibility for multiple overlapping benefits opportunities based only on the opportunity requirements and conversation with the user.
We define the task as follows. Given a set of opportunities, each with a unique set of eligibility requirements, determine whether the user is eligible for each of them in the minimum number of dialog turns (Figure \ref{fig:dialog-loop}).
We simulate a user by prompting a language model with detailed information about themselves and their household.
Each simulated user is interested in a subset of all opportunities.
Assistant agents possess the natural language eligibility requirements for those opportunities and must determine the simulated user's eligibility by asking a series of questions.
After each dialog turn, the agent determines whether it is ready to make a decision and, if so, outputs a final eligibility prediction for each opportunity.

\subsection{Opportunity Requirements}
We source the plain English eligibility requirements for 82 benefits opportunities from NYC Open Data\footnote{https://data.cityofnewyork.us/}. 
We minimally edit requirements manually to remove ambiguity ("may be eligible"), future expectations ("can commit to"), and dates ("since 2023"). 
Opportunities include tax credits, youth programming, housing, nutrition assistance, healthcare, parental services, and career advancement, among other categories.
Eligibility requirements range from broad (State ID card: all residents age 10+) to extremely specific (Air conditioner subsidy: ten independent requirements).
Opportunities may apply to either the individual or the household as a whole, offering additional logical complexity.
Opportunities depend on 1-18 unique user features each (mean: 4.66 standard deviation: 3.56).
Each user feature appears in 1-52 opportunities (mean: 3.25, standard deviation: 6.66), falling on a long-tailed distribution (Figure \ref{fig:feature-distribution}). 
We define a household as eligible for an opportunity if \textbf{any} of its members are eligible.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/references_bar_chart.png}
    \caption{Number of opportunities dependent on each household feature. For example, 53 of 82 programs rely on age to determine eligibility. Top 20 features shown.}
    \label{fig:feature-distribution}
\end{figure}

\subsection{User Simulation}
For each opportunity, we enumerate relevant user features (age, income, number of dependents, etc.).
We create simulated user households by randomly sampling each feature for each member, with up to 6 members per household.
Features are independently sampled, except when subject to constraints preventing illogical combinations (5-year-old grandparents, adults in foster care, multiple spouses, etc.)
From these structured feature sets, we generate a natural language profile for the household.
We prompt Llama 3.1 70B with the natural language profile to answer questions from the information seeking agent.

\subsection{Eligibility Checker Programs}
To determine the ground truth eligibility of simulated users for specific opportunities, we manually write an eligibility checker Python program for each opportunity based on its plain language requirements.
The eligibility checker takes a simulated user's structured features as input and outputs the user's eligibility for the opportunity.
We take care to avoid Python \textsc{or} and \textsc{and} keywords and other patterns such as list comprehension.
In this way, we ensure that if and only if two households qualify (or fail to qualify) for an opportunity \textbf{for the same reasons}, they cause the eligibility checker to execute the same unique set of lines of code, its trace.


\subsection{Diverse Dataset}

Due to the time and cost of benchmarking new models, we attempt to construct the smallest possible dataset with the most "coverage" of unique traces to qualification or disqualification using input fuzzing.
Each example consists of a simulated user, a subset of opportunities in which they are interested, and the ground truth eligibility for those opportunities.
We first randomly generate 10,000 simulated users, sampling each variable from a distribution chosen to produce a balanced distribution across traces, typically uniformly, except when eligibility is based on thresholds of numeric features.
We then greedily add households to the dataset whose trace through all eligibility checkers contributes the most lines not yet present in the dataset.
Finally, we greedily remove opportunities from simulated users if the user-opportunity trace contributes no unique lines.
We refer to this dataset as the Diverse Dataset, which contains only 56 of the original 10,000 households (305 of 82,000 user-opportunity pairs) but covers the same traces as the full set.
Each household is interested in between 1-10 opportunities, with a mean of 5.4.

\subsection{Representative Dataset}
To model a realistic distribution of potential users, we construct a second Representative Dataset.
Each feature for each user household (e.g., housing type) is independently sampled from distributions derived from 78 different sources.
We use data from New York City when available, but fall back to state- or national-level statistics if necessary.
We assign opportunities to users at random.
The representative contains 25 user households, each interested in 6-19 opportunities, with a mean of 9.8.

\subsection{Dialog Loop}

Agents are provided eligibility requirements and then must determine simulated user eligibility by asking questions, one at a time. 
After each response, the agent is prompted with \textsc{Ready}, where it is asked if it has enough information to determine the eligibility of the user with certainty (Figure \ref{fig:dialog-loop}).
If the agent responds with \textsc{True}, it is prompted to \textsc{Predict} the user's eligibility for each opportunity.
Otherwise, it asks another question.
We limit conversations to 20 questions per opportunity, to a maximum of 100 questions.


\section{ProADA}
\label{sec:proada}

To solve interactive decision problems, we propose a Program Synthesis Adaptive Decision Agent, or ProADA, which uses agent-created Python tools as reasoning aids for adaptive decision problems in dialog.
State-of-the-art code generation models often generate code that involves a dozen variables \cite{wan2024deep}, yet the models suffer from basic reasoning errors and hallucinations when working in natural language.
By offloading dialog planning and memory into static Python code, ProADA achieves the flexibility and usability of natural language while leveraging the long-range planning and reasoning of program synthesis.
ProADA consists of a code generation module and a dialog module.
% \textcolor{red}{explain better}
The code generation module creates one Python \textsc{Decide} tool per opportunity, formalizing the logic of the decision problem and deciding the result.
The dialog module serves as an interface between the user and the \textsc{Decide} tool, asking questions and storing answers in a structured form (Figure \ref{fig:ProADA}).
% The dialog module serves to request relevant information from the user and process user dialog into structured form.

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/ProADA.png}
    \caption{ProADA architecture. ProADA consists of the checker tool created by the code generation module (left) and the dialog module (center). The checker tool is a Python function that determines user eligibility from a structured user representation dictionary (right). The ProADA dialog module acts as an interface between the checker tool and the user. On each dialog turn, the agent runs the checker tool on the user dictionary, which is initially empty. On a key error, the dialog module fills in a single key-value pair by asking a user a question and converting the answer to a value consistent with the checker tool logic. The dialog ends once a value is returned by the checker tool for every opportunity.}
    \label{fig:ProADA}
\end{figure*}
% \subsubsection{Code Generation Module}

To best explain ProADA, we instantiate it in the context of our proposed BeNYfits benchmark.
Before starting a dialog, ProADA uses the code generation model to convert the eligibility requirements in natural language into a Python \textsc{Decide} Checker tool used by the agent \ref{fig:ProADA}.  
% \textsc{Decide} is a python function that takes \texttt{UserFeatures} (e.g., \texttt{household\_income}) as dictionary input and outputs the household's eligibility.
\textsc{Decide} is a Python function that takes a \texttt{UserFeatures} dictionary containing known user properties (e.g., \texttt{``homeless\_or\_runaway"}) as input and outputs the household eligibility.
For each key used to access \texttt{UserFeatures}, the code generation model defines a type (\texttt{int}, \texttt{float}, etc.) constraint, or a list of string choices that the feature can take.
At the start of the dialog, the agent runs the \textsc{Decide} tool, passing in an empty \texttt{UserFeatures} dictionary, since it knows nothing about the user yet.
An empty dictionary would normally cause a key error, which we exploit by wrapping \textsc{Decide} in a try/catch block.
In an exception, the agent passes the offending key, relevant code, eligibility requirements, and dialog history to the dialog module.
The dialog module constructs a question seeking the necessary information (``Are you a homeless or a runaway youth?") and presents it to the user.
The dialog module then converts the user's response (``I am a homeless youth") into a valid value according to the predetermined constraint using constrained generation, storing the key-value pair (\texttt{``homeless\_or\_runaway": ``yes")} in \texttt{UserFeatures}.
The agent repeats running \textsc{Decide} with the updated \texttt{UserFeatures} dictionary until it returns a value.



\section{Experimental Setup}
\label{sec:experiments}

% \subsection{Age}
As baselines, we choose Llama 3.1 Instruct 8B and 70B, as well as GPT-4o. 
In direct prompting, we instruct these models to assess readiness and generate questions at each step in the dialog loop, and finally to predict eligibility.
We also assess prompting models to conduct ReAct-style chain-of-thought before each step.
During \textsc{Readly} and \textsc{Decide}, we use constrained decoding to ensure ProADA and baseline models generate a valid output.
For ProADA, we choose the same models for the dialog module and always use GPT-4o for the code generation module.
We choose Llama 3.1 Instruct 70B to implement our simulated user for all experiments, in order to reduce the hallucinations that we observed in smaller 8B parameter models.
To reduce memory usage, we use 4-bit quantization on all 70B-parameter models.
We report three trials for all tests, except for the following, which we run once, due to resource constraints: GPT-4o + direct prompting, ReAct, and ProADA; and Llama 3.1 70B + ReAct.

To measure human performance on this task, one expert author performed the role of the agent on 39 user-opportunity pairs from the Diverse Dataset, achieving 89.7\% accuracy. 
Upon review, we find all inaccuracies are due to human error rather than unfaithful simulated user responses, suggesting a performance ceiling of nearly 100\% on this benchmark.


\section{Experimental Results}
\label{sec:results}

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/main.png}
    \caption{Average of Representative and Diverse dataset F1 vs. dialog turns to completion for ProADA and baseline models.}
    \label{fig:main}
\end{figure*}

Since our datasets are unbalanced (Diverse: 47.9\% positive, Representative: 15.5\%), we choose micro F1 as our primary accuracy metric. 
Let F1 and T be the average F1 score and the number of turns across both datasets, respectively. 
To reward efficient questioning, we define a turn-weighted F1 score as:

\begin{align*}
    \text{Turn-Weighted F1} = \frac{100 \cdot \text{F1}}{\text{T} / 100 + 1}
\end{align*}

since dialogs can have at most 100 turns.

We find that our method, ProADA, outperforms all others by a significant margin with a turn-weighted F1 score of 47.7.
The turn-weighted F1 score drops to 38.5 when using Llama 3.1 8B versus GPT-4o as the dialog model.
However, Llama 3.1 8B + ProADA still surpasses the next best strategy, Llama 3.1 70B + ReAct at 34.1 and GPT-4o + direct prompting, despite using a dialog model with many times fewer parameters. 
ProADA F1 scores exceed those of equivalent models using direct or ReAct prompting in all but two cases in both datasets (Table \ref{tab:results}).
Among directly prompted models, GPT-4o and Llama 3.1 8B score highest (29.9 and 31.7, respectively).
GPT-4o achieves a relatively high average F1 score (40.8), but uses 27.2 turns per dialog, while Llama 3.1 8B appears to terminate prematurely after only 6.0 turns, achieving only 33.6 F1.
Dialog completion speed varies widely across models and strategies, with Llama 3.1 70B + direct prompting frequently hitting the turn limit without terminating, resulting in an average turn count of 81.7. 
Program synthesis guidance, and to a lesser degree ReAct prompting, appear to moderate the number of turns needed without negatively impacting F1 score.



% We find that baseline models do not perform significantly better than random, even when prompted with chain-of-thought.
% Our method, however, shows improvement to both accuracy and f1 compared to equivalent baselines while also substantially reducing the number of dialog turns needed.
% In the best case, Llama 3.1 70B achieves \textcolor{red}{XX} accuracy and \textcolor{red}{XX} f1 score.
% ProADA, achieves noticeable improvement versus equivalent baselines, improving f1 score from \textcolor{red}{XX} to \textcolor{red}{XX} with Llama 3.1 8B and \textcolor{red}{XX} to \textcolor{red}{XX} with Llama 3.1 70B.
% Our method reduces average dialog turns per conversation from \textcolor{red}{XX} to \textcolor{red}{XX (YY\%)}.
% We report the average of 3 trials in all cases except for GPT-4o, which we limit to \textcolor{red}{X} examples.
%

\begin{table*}[h]\centering
\footnotesize
\begin{tabular}{lrrrrrrrcc}\toprule
\textbf{} &\textbf{Dialog Model} &\multicolumn{2}{c}{\textbf{Diverse Set}} &\multicolumn{2}{c}{\textbf{Representative Set}} &\multicolumn{2}{c}{\textbf{Average}} &\textbf{Turn-Weighted } \\\cmidrule{2-8}
\textbf{Strategy} &\textbf{Llama} &\textbf{F1 ↑} &\textbf{Turns ↓} &\textbf{F1 ↑} &\textbf{Turns ↓} &\textbf{F1 ↑} &\textbf{Turns ↓} &\textbf{F1 ↑} \\\midrule
Random &P(True)=0.5 &23.6 &0.0 &48.9 &0.0 &36.3 &0.0 &36.3 \\
\midrule
Direct Prompting &Llama 3.1 8B &44.6 &\textbf{5.5} &22.5 &\textbf{6.4} &33.6 &\textbf{6.0} &31.7 \\
&Llama 3.1 70B &54.3 &41.6 &27.2 &81.7 &40.8 &61.7 &25.2 \\
&GPT-4o &31.2 &16.8 &45.0 &37.6 &38.1 &27.2 &29.9 \\
\midrule
ReAct Agent &Llama 3.1 8B &40.4 &9.5 &26.1 &10.9 &33.2 &10.2 &30.2 \\
&Llama 3.1 70B &\textbf{58.3} &9.5 &26.1 &37.9 &42.2 &23.7 &34.1 \\
&GPT-4o &50.4 &18.4 &20.9 &13.3 &35.7 &15.8 &30.8 \\
\midrule
ProADA (Ours) &Llama 3.1 8B &50.6 &16.8 &41.9 &23.4 &46.2 &20.1 &38.5 \\
&Llama 3.1 70B &54.0 &18.2 &49.7 &19.8 &51.8 &19.0 &43.5 \\
&GPT-4o &50.4 &15.7 &\textbf{60.8} &17.2 &\textbf{55.6} &16.5 &\textbf{47.7} \\
\bottomrule
\end{tabular}
\caption{F1 score and dialog turns to completion for ProADA and baseline models.}\label{tab:results}
\end{table*}

\section{Failure Analysis}
\label{sec:failure}

We observe multiple distinct types of errors that contribute to poor reasoning and inefficient dialog. 
Program synthesis-guided dialog reduces errors overall, but introduces unique failure modes associated with code generation.

\subsection{General Errors}

Several failure modes persist across all strategies, indicating core weaknesses in foundational model reasoning ability.

\noindent \textbf{Suggestibility:} Models suffer from hallucination prompted by implications in eligibility requirements.
For example, when prompted with a child care program, models ask for the child's age without checking whether the household contains any children to begin with.

\noindent \textbf{Domain knowledge \& edge cases:} Models fail to account for uncommon edge cases, such as children living with parents but not being claimed as tax dependents.

\subsection{Baseline Errors}
Although it is difficult to confidently attribute final predictions to specific mistakes during question generation, we observe several flawed reasoning patterns when using direct and ReAct prompting:

\noindent \textbf{Hallucination:} Baseline models frequently return \textsc{True} in \textsc{Ready} before collecting all relevant information, implying either a logical reasoning failure or a hallucination of relevant facts. 

\noindent \textbf{Ultra-specificity:} Models ask needlessly specific questions ("Is your total annual income below \$69,900?") when a more general question ("What is your total annual investment income?") would produce information useful elsewhere, resulting in superfluous dialog turns.


\noindent \textbf{Repetition:} Baseline models get stuck in loops, asking slight variations of the same question. 

\noindent \textbf{Multi-member households:} Baseline models often inquire only about the user, rather than all members of the family, despite being specifically prompted to do so.
They rarely ask for the family size or composition when eligibility is determined at the individual level, substantially reducing recall.

\noindent \textbf{Conflating users:} Baseline models sometimes conflate household members or fail to specify which member they are asking about. 
% If two members each have one necessary criteria but no member has both, models may predict a false positive.

\subsection{ProADA Errors}
Program synthesis-guided dialog introduces several distinct new failure modes:

\noindent \textbf{Code generation:} Logical or domain-specific reasoning errors can create flawed code that propagates errors through subsequent conversations. 

\noindent \textbf{Code to question:} Although the code generated for the \textsc{Decide} tool usually represents multiple family members correctly as a list, the dialog module struggles to track and specify which member is being discussed at any time. 
Interestingly, we observe improved performance when users provide the names of their family members.

\noindent \textbf{No recovery:} Since ProADA models strictly adhere to dialog planning according to the generated code, they have no ability to recover or deviate when users generate an unexpected response, such as "I don't know."



% \begin{table*}[h!]
% \centering
% \begin{tabular}{|c|c|}
% \hline
% \textbf{Error Type} & \textbf{Percentage (\%)} \\
% \hline
% Misread the prompt & 1.2 \\
% Drops requirement(s) & 7.3 \\
% Lack of domain knowledge & 4.9 \\
% Hallucinates new requirement(s) & 8.1 \\
% Logical error & 16.3 \\
% Correct & 62.2 \\
% \hline
% \end{tabular}
% \caption{Distribution of Errors in Generated Checkers}
% \end{table*}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/pie.png}
    \caption{ProADA program synthesis errors}
    \label{fig:enter-label}
\end{figure}


\subsection{Errors by Simulated Users}
Authors annotated 61 simulated user responses for faithfulness to the user profile, finding 60 (98.4\%) of questions are answered faithfully.
The simulated user tends towards verbosity, providing additional unrequested information in 5 cases (8.2\%).
We find unnatural but faithful responses in 2 cases (3. 3\%), indicating that the frequency of errors due to simulated user misbehavior is low.
In qualitative probing, we find that the simulated user can respond accurately to diverse questions up to two hops (e.g., "How many children do you have under the age of 5?").
Sufficiently complex queries or those with more than two hops tend to cause the simulated user to respond that it cannot answer the question, but we rarely observe models generating such questions in our experiments.
% High accuracy and naturalness suggest this benchmark has precision, despite introducing 

\section{Discussion}
\label{sec:discussion}

Program-synthesis-guided dialog improves accuracy in adaptive decision problems while reducing the number of dialog turns needed.
This provides multiple benefits by exposing the agent's reasoning process in a human-readable format.
Agent decisions become more transparent and consistent, improving interpretability, and enabling several avenues for further improvements.
% Our ProADA method demonstrates that leveraging program synthesis-guided dialog for adaptive decision problems can improve accuracy and dialog turn efficiency

Since the Python tool only needs to be created once, we can use a stronger model for program synthesis without incurring significantly increased inference costs or latency.
Then, by replacing the \textsc{Ready} and \textsc{Predict} language model calls in the dialog loop with simple Python functions, we reduce the number of language model calls by over 50\%.
Unlike in black-box models where we observe disparate behavior based on surface form variation, especially in out-of-distribution contexts, our technique forces the agent to behave consistently across users.
As a form of prompt transformation, this may also reduce the susceptibility of public-facing agents to jailbreak \cite{peng2024jailbreaking}.

Synthesized code also serves as a window into the agent's decisions.
Although we generate code automatically in this work, the code may be checked manually or with software tools to ensure correctness before deployment.
Unlike black-box models, program synthesis-guided models like ProADA may also be subject to unit tests to ensure code quality.

AI faces increasing regulation, especially in public services or where systemic bias may disenfranchise certain groups, such as credit offerings.
In certain scenarios, providers are required to prove that their models are unbiased or to provide a human-readable basis for any given AI decision.
Although questions are generated neurally, eligibility decisions are made with static code that can be automatically traced to produce a rationale.
However, we note that the parsing of user utterances into structured data may still introduce bias.

Many opportunities in BeNYfits and other public opportunities are contingent on sensitive personal information, such as income, substance abuse, domestic violence, and being HIV positive.
By limiting closed-source model use only to program synthesis, solutions like ProADA avoid leaking user data to commercial entities while harnessing their models' advanced reasoning.

% We limit BeNYfits example households to at most 19 desired opportunities for cost reasons and because current models struggle even at this level.
% As this benchmark saturates, future work could increase the task difficulty by requiring agents to determine eligibility for all 82 tasks.
% Future versions may also wish to update or add opportunities. 
% In such cases, it is only required to update the natural language requirements and eligibility checker program.

ProADA represents a reverse of the traditional tool-use paradigm in which language models call tools by generating special tokens.
Instead, our agent creates a tool which in turn calls the language model.
Future work may explore more sophisticated agent-tool relationships.

\section{Related Work}
\label{sec:related_work}
% \subsection{Dialog Agents}

Many dialog agent tasks have been proposed, including offline task-oriented dialog \cite{andreas2020task} \cite{budzianowski2018multiwoz} and online user simulations using real humans or LM agents as responders \cite{gur2018user} \cite{he2018decoupling}. 
Question generation is a related task where agents seek information relevant to a downstream task, such as user intent \cite{min2020ambigqa} or relevant facts \cite{toles2023good}.
Some task-oriented dialog datasets focus on clarification and information seeking, such as \citet{zhang2023groundialog}.
However, datasets such as ShARC \cite{saeidi2018interpretation} and ClariT \cite{feng2023towards} only require "yes" or "no" questions.
BeNYfits expands on these works by adding a highly realistic, multi-turn dialog agent task requiring logical reasoning and domain-specific knowledge.
Similar tasks include MediQ \cite{li2024mediq}, which benchmarks medical diagnosis through dialog, and ClarQ-LLM \cite{gan2024clarq}, which focuses on discovering hidden information while playing an adventurer.
In comparison, BeNYfits focuses on logically reasoning legalistic tasks to reach a binary prediction.
% Additionally, the ability to combine overlapping opportunities into multi-label tasks (e.g., determine eligibility for school programs \textbf{and} child care) allows for the creation of increasingly complex tasks.
% These 
% \subsection{Code Generation-based Task-oriented Dialog}

Many works on tool-use have equipped language models with a code interpreter \cite{gupta2023visual} \cite{shen2024hugginggpt}, though fewer have specifically studied tool creation, e.g., \citet{qian2023creator}.
Several prior works have established the efficacy of code generation in dialog systems. 
\citet{chiu2023symbolic} propose grounding in code generated based on partner utterances and using symbolic planning to reason over the code. 
\citet{suris2023vipergpt} find code translations an effective intermediate representation for natural language questions.
\citet{nguyen2024dynasaur} create an LLM agent framework for dynamically creating and composing subtask actions based on code.
To the best of our knowledge, no other code generation-based approaches have been proposed for question generation in dialog. 
% Since most modern language models are trained on both natural language and code, using code as a proxy for natural language allows them to structure information into a compositional knowledge representation. 
% In addition, grounding can be done by executing the code or using the code as reference in the reasoning prompt.


\section{Conclusion}
\label{sec:conclusion}


% Current language models struggle with interactive decision-making in dialog.
% Program synthesis using ProADA represents one method for improving agent dialog planning.
% \textcolor{red}{what else goes here?}

We present a strong tool-augmented method to solve interactive decision-making in dialogs and a novel and realistic benchmark for measuring decision-problem accuracy and dialog efficiency.
Our method ameliorates memory and planning issues by converting key information in user utterances into structured key-value pairs to improve reasoning, latency, and cost by offloading computations onto an agent-created Python tool.
Such structured coding support overcomes many problems of pure LLM baselines such as hallucination of missing information, lack of object tracking, being over-confident, etc. 
Ultimately, our proposed method achieved an F1 score of 55.6 (compared to at most 42.2 for the baselines) while reducing the dialog turns needed by more than 30\% compared to the next best agent, raising hopes for reducing user burden and increasing access to public opportunities using language models.

\section{Limitations}

The eligibility requirements for this benchmark were derived from plain English summaries rather than official documents.
Requirements for some opportunities omit details present in more complete sources.

The population data used to construct the Representative Dataset were collected from numerous independent sources.
Some features were not available, such as the percentage of people currently struggling to pay their electricity bill.
In such cases, we make estimates based on the most similar available data.
At the same time, features are each collected from disparate sources, rather than from a single census, so our dataset is unable to express accurate correlations between related features.
Users of our dataset should be aware of these limitations.

Because our evaluation method weights the F1 score against dialog turns, complex, multi-hop queries are weighted the same as simple yes or no questions.
However, in practice, we rarely observe complex queries.
The trade-offs of question complexity, length, and user burden may be addressed in future work.

\section{Ethical Considerations}

Empirically, we observe that model-generated code in this study does not contain harmful side effects.
However, it is always safer to run untrusted code in a sandboxed environment like Docker.

Introducing AI models into the social benefits system poses risks of false determinations and inequitable user experiences.
We encourage stakeholders to use AI to increase accessibility to public opportunities, but to avoid using them as the final determiner in any step due to the harm caused by errors.
Similarly, user-facing deployments should consider the relative harm of false acceptances versus false refusals and calibrate their models accordingly.


\bibliography{custom}

\appendix


\begin{table*}[!htp]\centering
\scriptsize
\begin{tabular}{lrrrrrrrrr}\toprule
\textbf{Dataset} &\textbf{Strategy} &\textbf{Model} &\textbf{} &\textbf{Accuracy} &\textbf{Recall} &\textbf{Precision} &\textbf{F1} &\textbf{Turns} \\\midrule
Diverse &Direct Prompting &Llama 3.1 8B & &51.5 &37.7 &49.1 &42.6 &8.9 \\
& & & &51.5 &37.7 &49.1 &42.6 &3.9 \\
& & & &55.7 &43.8 &54.7 &48.7 &3.7 \\
& & &Mean &52.9 &39.7 &51.0 &44.6 &5.5 \\
& &Llama 3.1 70B & &52.1 &53.4 &50.0 &51.7 &46.8 \\
& & & &53.8 &63.0 &51.4 &56.6 &37.0 \\
& & & &53.4 &58.9 &51.2 &54.8 &41.1 \\
& & &Mean &53.1 &58.4 &50.9 &54.3 &41.6 \\
& &GPT-4o &Mean &77.4 &33.3 &29.3 &31.2 &16.7 \\
&ReAct Agent &Llama 3.1 8B & &56.2 &41.7 &15.5 &22.6 &14.0 \\
& & & &50.8 &49.3 &48.6 &49.0 &6.1 \\
& & & &52.1 &49.3 &50.0 &49.7 &8.4 \\
& & &Mean &53.0 &46.8 &38.0 &40.4 &9.5 \\
& &Llama 3.1 70B & &57.4 &62.3 &54.8 &58.3 &9.5 \\
& &GPT-4o & &56.7 &45.9 &55.8 &50.4 &18.4 \\
&ProADA (Ours) &Llama 3.1 8B & &62.6 &41.8 &67.8 &51.7 &16.6 \\
& & & &61.6 &43.8 &64.6 &52.2 &18.1 \\
& & & &59.2 &39.0 &62.0 &47.9 &15.6 \\
& & &Mean &61.2 &41.6 &64.8 &50.6 &16.8 \\
& &Llama 3.1 70B & &64.9 &49.3 &68.6 &57.4 &18.8 \\
& & & &63.0 &43.8 &67.4 &53.1 &18.6 \\
& & & &61.5 &42.5 &65.3 &51.5 &17.3 \\
& & &Mean &63.1 &45.2 &67.1 &54.0 &18.2 \\
& &GPT-4o &Mean &63.3 &39.0 &71.3 &50.4 &15.7 \\
& & & & & & & & \\
Representative &Direct Prompting &Llama 3.1 8B & &63.8 &41.7 &19.0 &26.1 &5.0 \\
& & & &65.1 &22.2 &12.9 &16.3 &10.0 \\
& & & &66.8 &36.1 &19.1 &25.0 &4.3 \\
& & &Mean &65.2 &33.3 &17.0 &22.5 &6.4 \\
& &Llama 3.1 70B & &66.8 &52.8 &23.8 &32.8 &76.1 \\
& & & &66.0 &41.7 &20.3 &27.3 &84.1 \\
& & & &62.6 &33.3 &15.8 &21.4 &85.1 \\
& & &Mean &65.1 &42.6 &19.9 &27.2 &81.7 \\
& &GPT-4o & &55.1 &38.4 &54.4 &45.0 &37.6 \\
&ReAct Agent &Llama 3.1 8B & &56.2 &41.7 &15.5 &22.6 &14.0 \\
& & & &56.6 &47.2 &17.0 &25.0 &8.52 \\
& & & &63.4 &52.8 &21.6 &30.6 &10.36 \\
& & &Mean &58.7 &47.2 &18.0 &26.1 &10.9 \\
& &Llama 3.1 70B & &63.8 &41.7 &19.0 &26.1 &37.9 \\
& &GPT-4o & &71.1 &25.0 &18.0 &20.9 &13.3 \\
&ProADA (Ours) &Llama 3.1 8B & &75.7 &58.3 &33.3 &42.4 &23.0 \\
& & & &78.7 &61.1 &37.9 &46.8 &28.0 \\
& & & &76.2 &44.4 &30.8 &36.4 &19.2 \\
& & &Mean &76.9 &54.6 &34.0 &41.9 &23.4 \\
& &Llama 3.1 70B & &86.0 &72.2 &53.1 &61.2 &19.1 \\
& & & &83.0 &61.1 &45.8 &52.4 &20.2 \\
& & & &78.3 &38.9 &32.6 &35.4 &20.2 \\
& & &Mean &82.4 &57.4 &43.8 &49.7 &19.8 \\
& &GPT-4o &Mean &86.8 &66.7 &55.8 &60.8 &17.2 \\
\bottomrule

\end{tabular}
\caption{Accuracy metrics and turns for all models and strategies on the Diverse and Representative Datasets}\label{tab: }
\end{table*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Eligibility requirements: {eligibility_requirements}. 

Is the information sufficient to determine whether any member of the user's household is eligible for all programs? Answer only in one word True or False.
    \end{lstlisting}
    \caption{``Are Benefits Ready?'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Eligibility: {eligibility_requirements}. 

Predict the programs for which any member of the user's household is eligible. Return only a boolean array of length {num_programs}, e.g. {example_array}, where the value at index `i` is true iff the user is eligible for program `i`. Only return the array. Do not return anything else in the response. If a user's eligibility is unclear, make your best guess.
    \end{lstlisting}
    \caption{``Predict Benefits Eligibility'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Eligibility: {eligibility_requirements}. 

Ask a clarifying question that will help you determine if any member of the user's household is eligible for benefits as efficiently as possible. Only ask about one fact at a time.
    \end{lstlisting}
    \caption{``Ask a Clarifying Question'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Eligibility requirements: {eligibility_requirements}. 

Is the information sufficient to determine whether any member of the user's household is eligible for all programs? Think through your reasoning out loud. Then answer with True or False.
\end{lstlisting}
    \caption{``Predict Benefits Eligibility'' for CoT Prompt}
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Eligibility: {eligibility_requirements}. 

Predict the programs for which any member of the user's household is eligible. Return only a boolean array of length {num_programs}, e.g. {example_array}, where the value at index `i` is true iff the user is eligible for program `i`. Only return the array. Do not return anything else in the response. If a user's eligibility is unclear, make your best guess.Think through your reasoning out loud.

\end{lstlisting}
    \caption{``Predict Benefits Reasoning'' for CoT Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Reasoning: {reasoning}. 

Using the reasoning above, predict the programs for which any member of the user's household is eligible. Output a boolean array of length {num_programs}, e.g. {example_array}, where the value at index `i` is true iff the user is eligible for program `i`. If a user's eligibility is unclear, make your best guess.

\end{lstlisting}
    \caption{``Predict Benefits Constrained'' for CoT Prompt}
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}

Eligibility: {eligibility_requirements}. 

Ask a clarifying question that will help you determine if any member of the user's household is eligible for benefits as efficiently as possible. Only ask about one fact at a time. Think through your reasoning out loud, then state your question after a colon, e.g. Question: What is the user's age?"

\end{lstlisting}
    \caption{``Predict Clarifying Questions'' for ReAct Chain-of-Thought Prompt}
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
{attempt_no}

Eligibility Requirements:
{eligibility_requirement}

Write a python function called `check_eligibility` that takes a dictionary `hh` containing relevant information and determines user eligibility. hh is a special dictionary connected to a language model that is conversing with the user. Any time it does not contain a key, it will determine that information from the user. As a result here are some requirements for interacting with `hh`:

- DO NOT use `dict.get()` anywhere in the code. Key errors will be handled elsewhere.
- Do not use default values.
- Do not use any f-strings, curly brackets, or dynamically generated strings in your keys.
- Use only literal strings in keys.
- Do not use try-except blocks.
- If you need to access data for individuals (rather than the household as a whole) you can use integer indexing. hh[0] is the head of the household. 

`check_eligibility` returns a bool. All keys and values of `hh` are strings. If you write helper functions, keep them inside the `check_eligibility` function. Make your code as detailed as possible capturing every edge case. Remember that the household may have no relevant members, so be sure to ask about the composition of the household. For example, for childcare programs, check that the household has at least one child. After each new lookup in `hh`, write a comment suggesting a question to ask. Here is an example:

def check_eligibility(hh: dict) -> bool:
    def _helper(individual):
        if individual["has_id"]=="yes": # "Does the individual have an ID?"
            return True
        else:
            return False
    if hh["has_dependents"]=="yes": # "How many dependents does the household have?"
        num_dependents = hh["num_dependents"]
        for i in range(len(num_dependents)):
            if float(hh[i]["dependent_age"]) < 18 and _helper(hh[i]): # "Is the first dependent under 18?"
                return True
    return False

The following is a set of preexisting keys and values in the `hh` dictionary; take care not to duplicate them.

{preexisting_keys}

Avoid using int() and use float() instead. Do not provide anything besides code in your response. Do not use `input` for user input.
    \end{lstlisting}
    \caption{``Generate Checker'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Context:
{eligibility_requirements}

Code:
{code}

Target key:
{key}

Question: Given the code and context above, what do you expect {key} to be an integer, a float, or one choice from a set of strings? Return ONLY int, float, or choice.
    \end{lstlisting}
    \caption{``Get Type'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Context:
{eligibility_requirements}

Code:
{code}

Target key:
{key}

Question: Given the code and context above, what are the possible values of {key}? Return ONLY the list of possible values in a list of strings. For example, return `["a", "b", "c"]`.
    \end{lstlisting}
    \caption{``Get Values'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Context:
{eligibility_requirements}

Line:
```{line}```

We need to extract the value of {key} from the following dialog:

Question: {cq}
Answer:
{answer}

What should we set as the value of {key}? Return ONLY the value.
    \end{lstlisting}
    \caption{``Extract Values from Answer'' Prompt}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{lstlisting}
Context:
{eligibility_requirements}

Line:
```{line}```

We need to determine what value of {key} should be stored in the `hh` dictionary. Ask a question to the user that would get this value. For example, for age_i, ask "What is the age of person i?". Return ONLY the question.
    \end{lstlisting}
    \caption{``Key Error'' Prompt}
\end{figure*}

\begin{table*}[!htp]\centering
\scriptsize
\begin{tabular}{lrrrrrrrrr}\toprule
\textbf{Benefits Program} & \textbf{Positive Count} & \textbf{Negative Count} & \textbf{Percentage True (\%)} \\\midrule
FamilyHomelessnessAndEvictionPreventionSupplement & 4 & 3 & 57.14 \\
WorkforceoneCareerCenters & 1 & 1 & 50.00 \\
SilverCorps & 1 & 1 & 50.00 \\
AdultProtectiveServices & 1 & 2 & 33.33 \\
DisabilityRentIncreaseExemption & 8 & 7 & 53.33 \\
ChildTaxCredit & 1 & 4 & 20.00 \\
SeniorCitizenHomeownersExemption & 1 & 9 & 10.00 \\
InfantToddlerPrograms & 3 & 6 & 33.33 \\
LearnEarn & 7 & 1 & 87.50 \\
DisabledHomeownersExemption & 1 & 6 & 14.29 \\
PreKForAll & 1 & 1 & 50.00 \\
JobsPlus & 1 & 1 & 50.00 \\
HeadStart & 6 & 2 & 75.00 \\
KindergartenAndElementarySchool & 1 & 1 & 50.00 \\
CoolingAssistanceBenefit & 4 & 5 & 44.44 \\
HomeEnergyAssistanceProgram & 4 & 3 & 57.14 \\
VeteransAffairsSupportedHousing & 1 & 1 & 50.00 \\
NYCFreeTaxPrep & 2 & 1 & 66.67 \\
FamilyPlanningBenefitProgram & 1 & 6 & 14.29 \\
ChildrenAndYouthWithSpecialHealthCareNeeds & 3 & 2 & 60.00 \\
EnhancedSchoolTaxReliefProgram & 0 & 2 & 0.00 \\
SummerMeals & 1 & 1 & 50.00 \\
TrainEarn & 6 & 3 & 66.67 \\
NYCFinancialEmpowermentCenters & 1 & 1 & 50.00 \\
NYCHAPublicHousing & 3 & 5 & 37.50 \\
ChildAndDependentCareTaxCredit & 4 & 4 & 50.00 \\
ChildCareVouchers & 8 & 2 & 80.00 \\
HIVAIDSServicesAdministration & 1 & 1 & 50.00 \\
BigAppleConnect & 1 & 1 & 50.00 \\
OfficeOfChildSupportServices & 1 & 3 & 25.00 \\
BeaconPrograms & 1 & 1 & 50.00 \\
SafeAndSickLeave & 1 & 5 & 16.67 \\
NYSUnemploymentInsurance & 1 & 1 & 50.00 \\
FamilyTypeHomesForAdults & 1 & 6 & 14.29 \\
EarnedIncomeTaxCredit & 1 & 6 & 14.29 \\
Homebase & 1 & 1 & 50.00 \\
HomeFirstDownPaymentAssistance & 2 & 1 & 66.67 \\
HighSchool & 1 & 1 & 50.00 \\
SeniorCitizenRentIncreaseExemption & 1 & 1 & 50.00 \\
AccessARideParatransitService & 2 & 1 & 66.67 \\
TextTwoWork & 4 & 1 & 80.00 \\
TheEarlyInterventionProgram & 1 & 1 & 50.00 \\
EarlyHeadStart & 2 & 4 & 33.33 \\
Lifeline & 6 & 1 & 85.71 \\
IDNYC & 1 & 1 & 50.00 \\
NYSPaidFamilyLeave & 2 & 1 & 66.67 \\
COVIDnineteenFuneralAssistance & 1 & 1 & 50.00 \\
SchoolAgeAndEarlyChildhoodFamilyAndCommunityEngagementFACECenters & 1 & 1 & 50.00 \\
FairFaresNYC & 1 & 2 & 33.33 \\
NYCYouthHealth & 1 & 1 & 50.00 \\
NewbornHomeVisitingProgram & 4 & 2 & 66.67 \\
AcceleratedStudyInAssociatePrograms & 1 & 1 & 50.00 \\
STEMMattersNYC & 1 & 1 & 50.00 \\
CommoditySupplementalFoodProgram & 1 & 2 & 33.33 \\
CareerAndTechnicalEducation & 1 & 1 & 50.00 \\
NYCHAResidentEconomicEmpowermentAndSustainability & 1 & 1 & 50.00 \\
OutpatientTreatmentServices & 1 & 1 & 50.00 \\
CUNYFatherhoodAcademy & 1 & 3 & 25.00 \\
SummerYouthEmploymentProgram & 1 & 1 & 50.00 \\
ThreeK & 1 & 1 & 50.00 \\
MedicaidForPregnantWomen & 1 & 2 & 33.33 \\
ActionNYC & 1 & 1 & 50.00 \\
FamilyResourceCenters & 2 & 1 & 66.67 \\
NYCCare & 1 & 1 & 50.00 \\
PrimaryAndPreventiveHealthCare & 1 & 1 & 50.00 \\
NYCTenantResourcePortal & 1 & 1 & 50.00 \\
OlderAdultEmploymentProgram & 1 & 1 & 50.00 \\
NYCLaddersForLeaders & 1 & 1 & 50.00 \\
CornerstonePrograms & 1 & 1 & 50.00 \\
ComprehensiveAfterSchoolSystemOfNYC & 1 & 1 & 50.00 \\
WeSpeakNYC & 1 & 1 & 50.00 \\
NYCMitchellLama & 1 & 0 & 100.00 \\
CUNYStart & 1 & 1 & 50.00 \\
NYCNurseFamilyPartnership & 1 & 1 & 50.00 \\
MiddleSchool & 1 & 1 & 50.00 \\
AdvanceEarn & 1 & 1 & 50.00 \\
SectionEightHousingChoiceVoucherProgram & 1 & 0 & 100.00 \\
NYCYouthLeadershipCouncils & 1 & 1 & 50.00 \\
ChildHealthPlusAndChildrensMedicaid & 1 & 2 & 33.33 \\
VeteransPropertyTaxExemption & 1 & 1 & 50.00 \\
FamilyAssessmentProgram & 1 & 1 & 50.00 \\
BasicSchoolTaxReliefProgram & 1 & 0 & 100.00 \\
\hline
\textbf{Total} & \textbf{146} & \textbf{159} & \textbf{47.88} \\
\hline
\end{tabular}
\caption{Benefits Program-wise Positive/Negative Counts and Percentages for the Diversity Dataset}
\end{table*}

\begin{table*}[!htp]\centering
\scriptsize
\begin{tabular}{lrrrrrrrrr}\toprule
\textbf{Benefits Program} & \textbf{Positive Count} & \textbf{Negative Count} & \textbf{Percentage True (\%)} \\\midrule
AdultProtectiveServices & 0 & 3 & 0.00 \\
HomeEnergyAssistanceProgram & 0 & 3 & 0.00 \\
MiddleSchool & 0 & 3 & 0.00 \\
NYCFreeTaxPrep & 0 & 3 & 0.00 \\
NYSPaidFamilyLeave & 1 & 2 & 33.33 \\
NYSUnemploymentInsurance & 0 & 3 & 0.00 \\
WorkforceoneCareerCenters & 1 & 2 & 33.33 \\
FamilyTypeHomesForAdults & 2 & 1 & 66.67 \\
HeadStart & 0 & 3 & 0.00 \\
NYCFinancialEmpowermentCenters & 3 & 0 & 100.00 \\
TextTwoWork & 3 & 0 & 100.00 \\
ThreeK & 0 & 3 & 0.00 \\
CornerstonePrograms & 0 & 3 & 0.00 \\
JobsPlus & 0 & 3 & 0.00 \\
CommoditySupplementalFoodProgram & 0 & 3 & 0.00 \\
NYCCare & 0 & 3 & 0.00 \\
SilverCorps & 0 & 3 & 0.00 \\
SummerMeals & 1 & 2 & 33.33 \\
PrimaryAndPreventiveHealthCare & 1 & 2 & 33.33 \\
IDNYC & 3 & 0 & 100.00 \\
NYCYouthLeadershipCouncils & 0 & 3 & 0.00 \\
Homebase & 1 & 2 & 33.33 \\
NYCMitchellLama & 2 & 1 & 66.67 \\
NYCNurseFamilyPartnership & 0 & 3 & 0.00 \\
AdvanceEarn & 0 & 3 & 0.00 \\
BeaconPrograms & 1 & 2 & 33.33 \\
ChildHealthPlusAndChildrensMedicaid & 0 & 3 & 0.00 \\
BasicSchoolTaxReliefProgram & 0 & 3 & 0.00 \\
TheEarlyInterventionProgram & 0 & 3 & 0.00 \\
AccessARideParatransitService & 3 & 0 & 100.00 \\
ChildAndDependentCareTaxCredit & 0 & 3 & 0.00 \\
FamilyResourceCenters & 0 & 3 & 0.00 \\
InfantToddlerPrograms & 0 & 3 & 0.00 \\
NYCTenantResourcePortal & 3 & 0 & 100.00 \\
NYCYouthHealth & 1 & 2 & 33.33 \\
DisabledHomeownersExemption & 0 & 3 & 0.00 \\
OutpatientTreatmentServices & 0 & 3 & 0.00 \\
STEMMattersNYC & 0 & 3 & 0.00 \\
SeniorCitizenHomeownersExemption & 0 & 3 & 0.00 \\
CareerAndTechnicalEducation & 0 & 3 & 0.00 \\
NewbornHomeVisitingProgram & 0 & 3 & 0.00 \\
SchoolAgeAndEarlyChildhoodFamilyAndCommunityEngagementFACECenters & 0 & 3 & 0.00 \\
BigAppleConnect & 0 & 3 & 0.00 \\
CUNYFatherhoodAcademy & 0 & 3 & 0.00 \\
HomeFirstDownPaymentAssistance & 0 & 3 & 0.00 \\
DisabilityRentIncreaseExemption & 0 & 3 & 0.00 \\
KindergartenAndElementarySchool & 0 & 3 & 0.00 \\
EarnedIncomeTaxCredit & 1 & 2 & 33.33 \\
HIVAIDSServicesAdministration & 0 & 3 & 0.00 \\
OlderAdultEmploymentProgram & 0 & 3 & 0.00 \\
FamilyHomelessnessAndEvictionPreventionSupplement & 0 & 3 & 0.00 \\
ChildCareVouchers & 1 & 2 & 33.33 \\
ComprehensiveAfterSchoolSystemOfNYC & 1 & 2 & 33.33 \\
COVIDnineteenFuneralAssistance & 0 & 3 & 0.00 \\
TrainEarn & 0 & 3 & 0.00 \\
LearnEarn & 0 & 3 & 0.00 \\
SectionEightHousingChoiceVoucherProgram & 0 & 3 & 0.00 \\
CoolingAssistanceBenefit & 0 & 3 & 0.00 \\
MedicaidForPregnantWomen & 0 & 3 & 0.00 \\
SummerYouthEmploymentProgram & 1 & 2 & 33.33 \\
FairFaresNYC & 0 & 3 & 0.00 \\
PreKForAll & 0 & 3 & 0.00 \\
ChildrenAndYouthWithSpecialHealthCareNeeds & 1 & 2 & 33.33 \\
CUNYStart & 2 & 1 & 66.67 \\
NYCLaddersForLeaders & 0 & 3 & 0.00 \\
FamilyAssessmentProgram & 1 & 2 & 33.33 \\
FamilyPlanningBenefitProgram & 0 & 3 & 0.00 \\
NYCHAPublicHousing & 0 & 3 & 0.00 \\
SafeAndSickLeave & 2 & 1 & 66.67 \\
WeSpeakNYC & 1 & 2 & 33.33 \\
VeteransAffairsSupportedHousing & 0 & 3 & 0.00 \\
NYCHAResidentEconomicEmpowermentAndSustainability & 0 & 3 & 0.00 \\
SeniorCitizenRentIncreaseExemption & 0 & 3 & 0.00 \\
AcceleratedStudyInAssociatePrograms & 0 & 3 & 0.00 \\
EnhancedSchoolTaxReliefProgram & 0 & 3 & 0.00 \\
EarlyHeadStart & 0 & 3 & 0.00 \\
ActionNYC & 0 & 3 & 0.00 \\
Lifeline & 1 & 2 & 33.33 \\
VeteransPropertyTaxExemption & 0 & 3 & 0.00 \\
HighSchool & 0 & 3 & 0.00 \\
OfficeOfChildSupportServices & 0 & 3 & 0.00 \\
ChildTaxCredit & 0 & 3 & 0.00 \\
\hline
\textbf{Total} & \textbf{38} & \textbf{208} & \textbf{15.42} \\
\hline
\end{tabular}
\caption{Benefits Program-wise Positive/Negative Counts and Percentages for the Representative Dataset}
\end{table*}



\end{document}

\end{document}