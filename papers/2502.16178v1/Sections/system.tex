\section{System Design and Implementation}
\label{sec:system_design}


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figs/systemOverview.png}
    \caption{\textbf{TutorUp} consists of multiple views and functions, including Scenario Selection (A), Scenario Description (B), Math Problem (C), and Student Information (D), which displays details for three students (D1, D2, and D3) under each scenario. The system also features an Interactive Dialogue (E), an Input Box for Tutor Instructions (F), a Get Immediate Feedback Button (G1) that provides Immediate Feedback (G2), a Reset Button (H), and a Get Asynchronous Feedback Button (J1) that provides Asynchronous Feedback (J2). Users can also click on Tutor Dialogue Bubbles To Retrieve the Instruction (I)}
    \label{fig:system}
\end{figure*} 


\subsection{System Usage Introduction}
We designed \textit{TutorUp}  (Fig.~\ref{fig:system}), a training system to help novice tutors address student engagement challenges in online tutoring. 
Users begin by selecting one of four scenarios (summarized in Subsection \ref{subsec:survey2} and listed in Tab. \ref{tab:reactiv_scenarios}) representing different disengagement issues (Fig. \ref{fig:system} A). Each scenario includes a description of the disengagement problem (Fig. \ref{fig:system} B) and a mathematical problem (Fig. \ref{fig:system} C) which serves as session context. Tutors aim to enhance student engagement through discussions based on the scenario information.

Before instructing the simulated students, tutors can review their information in the current scenario (Fig.~\ref{fig:system} D), including their grade level, age, personal characteristics (e.g., anxious about making mistakes), and their level of prior knowledge (e.g., limited understanding due to learning difficulties). These student profiles align with the general scenario description provided above (Fig. \ref{fig:system} A). The simulated students are age 10-11 years (4th-5th grade), an age group identified through iterative design (Subsection \ref{subsec:iteration}) as particularly prone to engagement issues.

After reviewing the scenario information, tutors gain an understanding of the students' situations and discussion topic. They initiate the online session by responding to an initial prompt in the dialogue window (Fig. ~\ref{fig:system} E). Tutors enter their instructions in the text box (Fig. \ref{fig:system} F), and the simulated students respond to the tutor and peers accordingly. Tutors' primary task is to engage the students, with the mathematical problem as context. The focus for tutors is on fostering student engagement rather than correct answers, as a student may give the correct answer but still be disengaged, for example, by guessing or repeating a peer’s answer without genuine involvement.

While interacting with the simulated students, whenever the tutor is in need—e.g., when they feel that their current strategy is ineffective—they can click on the \textit{Get Immediate Feedback} button (Fig. ~\ref{fig:system} G1). This provides immediate feedback (Fig. ~\ref{fig:system} G2) with an analysis of the classroom situation and suggested teaching strategies. Tutors can choose to implement the suggested strategies or continue with their teaching approach. To try different strategies, tutors can click the Reset button (Fig.~\ref{fig:system} H) to return to the initial dialogue or click on a previous dialogue bubble (Fig.~\ref{fig:system} I) to revert to an earlier state in the conversation.

Once tutors feel they have practiced enough, they can end the conversation and click the \textit{Get Asynchronous Feedback} button (Fig. ~\ref{fig:system} J1) to receive a comprehensive assessment of their teaching (Fig.~\ref{fig:system} J2). This feedback evaluates their performance and offers suggestions for improvement. Tutors can then apply these insights in further practice to test and refine their strategies.

To build the \textit{TutorUp} system, we developed three key components: first, we summarized typical disengagement scenarios from survey results and designed student personas to represent each scenario. Second, we implemented the BigPicture-Character prompting pipeline to simulate tutoring discussions with multiple students. These two components meet \textbf{R1}. Third, we utilized LLMs to review these dialogues to give immediate feedback and asynchronous evaluations for tutors to reference, which meets \textbf{R2}. The following subsections will introduce these three components in detail. The full prompts used for scenario simulation and feedback generation with LLMs, as described in the following subsections, can be found in the supplementary materials.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scenario Simulation Design}
\label{subsec:senario_design}

Each simulated scenario features a scenario theme, student information, and a math problem. We discussed scenario themes in Subsection \ref{subsec:survey2} and show them in Tab. \ref{tab:reactiv_scenarios}. This section introduces the design for students under each scenario and the Math Problems.

\subsubsection{Student Design}
Based on the scenario themes (Tab. ~\ref{tab:reactiv_scenarios}), we designed student personas for each disengagement theme. Fig.\ref{fig:system} shows an example for the \textit{Varying Learning Paces} scenario. Details for all four scenarios are in the supplementary materials. From prior literature~\cite{gpteach,li2024agent} and survey responses (Section ~\ref{sec:formative_study}), we identified four key components for student personas: name, characteristics, command of knowledge, and initial behaviors. During the iterative design process (Subsection \ref{subsec:iteration}) tutors further suggested adding age and grade to help them adjust expectations regarding the tone and content of conversations, which we incorporated. The characteristics cover the student's personality (e.g., shyness), attitude (e.g., finding academic topics dull), emotions (e.g., fear of peer judgment), and tendencies (e.g., second-guessing themselves). Command of knowledge captures varying learning abilities (e.g., a good grasp of concepts) and preferences (e.g., a quick learner who prefers challenging problems). Initial behavior represents student's early disengagement signs (e.g., unwillingness to answer), which may change based on the tutor's instructions. This behavior is not displayed in the interface but is revealed through conversational interactions.
%
For each scenario, personas emphasize key traits related to the theme. For example, in the \textit{Lack of Interest and Engagement} scenario, the personas primarily highlight disinterested traits through their characteristics, while maintaining similar levels of knowledge.



\subsubsection{Math Problems}
To enhance realism and provide context, we designed algebraic math problems with simple structures and fixed answers for tutors and students to discuss. These problems allow tutors to focus on managing student engagement without additional complexity. In our iterative design interviews (Subsection \ref{subsec:iteration}), tutors confirmed that simple math problems are effective for general education and can be tied to real-world scenarios (e.g., counting apples), making them useful for guiding students.  Here is an example problem in our system: ``\textit{A farmer has two types of fruit trees: apple trees and pear trees. The total number of fruit trees on the farm is 120. The number of apple trees is twice the number of pear trees. Your task is to find out how many apple trees and pear trees there are on the farm.}'' We designed four similar problems, which can be combined with any scenario theme. Descriptions of all problems are in the supplementary materials.

\subsection{Generation of LLM-simulated Scenario}
To simulate scenarios for online tutoring sessions, \textit{TutorUp} formulates specific prompts to send API calls to GPT-4o. Throughout system development and evaluation we set the temperature parameter to $0$ to make system outputs more predictable. Future iterations will consider higher temperatures to introduce variations within scenarios supporting tutors in repeated practice. The prompt scheme for simulation in \textit{TutorUp} consists of two core components: one prompts LLMs to simulate individual student behavior, and another to govern interactions among students and the tutor, ensuring coherence and realism in the online learning environment.


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figs/prompt.png}
%award level: inter school
\caption{BigPicture-Character Pipeline Demonstration: Beginning with the initial dialogue and tutor's first input, the BigPicture Agent starts to write the ``story'' of the dialogue and decides which Character (Tutor or Student Agent) to speak next.}
    \label{fig:promptPipeline}
\end{figure*}

\subsubsection{Generation of LLM-simulated Student Agent}
To accurately simulate an online discussion environment, the simulated students should closely align with real student behaviors in our specifications (Subsection ~\ref{subsec:senario_design}) and their dialogue should closely resemble that of real students in similar settings. To achieve this, we developed a \textit{student prompt} template, which models student personas and generate dialogues in the online context. The template was developed through multiple experiments. Initially, for example, we defined student behavior in the input prompt but this led to simulated students remaining disengaged, regardless of the tutor's instructions. Instead, we revised the prompt to establish an initial behavior and allow students' responses, which reflect their engagement, to evolve according to the tutor's guidance. Feedback from design interviews (Subsection \ref{subsec:iteration}) led to further updates, such as ensuring students maintain polite and respectful language. We kept the best-performing template. Below, we describe the main components of the prompt design:
\begin{enumerate}
    \item \textbf{Scenario Context Prompt}: \texttt{Please assume the role of a disengaged student in an online mathematics class. Your objective is to exhibit disengaged behavior, making it challenging for the tutor to engage you. The problem to be solved is: [INTRODUCE THE MATH PROBLEM].}
    \item \textbf{Student Information Prompt}: \texttt{Your name is [STUDENT NAME]. You are a [STUDENT AGE]-year-old student. Communicate in a manner appropriate for your age; you are not exceptionally quick to understand the problem. You possess characteristics of [STUDENT CHARACTERISTICS], and your understanding of the math problem is [STUDENT ABILITY]. Your initial disengaged behavior is [STUDENT BEHAVIOR]. Please respond politely to the tutor's greetings and questions. Your engagement level starts low but may increase if the tutor's strategies are effective.}
    \item \textbf{Output Requirements Prompt}: \texttt{Your responses should be brief, natural, and reflective of a disengaged student. You must maintain politeness and respect in all interactions with the tutor and classmates.}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{BigPicture-Character Prompting Pipeline}
While student agents simulate individual student dialogue, the online scenario requires both student-to-student and student-to-tutor interactions. We addressed four key questions: Q1: When should students speak? Q2: When should the tutor provide instructions? Q3: Which students should respond? Q4: In what order should student agents speak? We found that using a single agent to manage both the flow and content of the dialogue risks losing context and coherence over longer dialogues easily. To address this, we separated the responsibilities, with the BigPicture Agent focusing on managing the overall conversational flow and assigning speaking turns, while the Student Agents handle the individual student responses. We introduce the \textit{BigPicture-Character prompt} scheme below.


\textbf{BigPicture-Character Design Consideration:} It is assumed that each student can think independently and respond naturally to both tutor instructions and input from other students. A natural dialogue among students and tutor can be treated as a story. 
 
Inspired by previous work that utilizes LLMs to tell stories~\cite{mirowski2023co,shakeri2021saga,grigis2024playwriting}, we utilize this method to comprehensively manage the dialogue. We adopt a ``divide-and-conquer'' approach by introducing a BigPicture Agent to manage the overall flow of the conversation and determine the speaking order. If the speaker is a student, the corresponding Student Agent is called to respond; if it is a tutor, the system pauses and waits for the tutor's instruction. The BigPicture Agent focuses solely on determining which character will speak next. The specific content of each character's dialogue is decided by the student agent or the tutor's input. We include the scenario context, the profiles of three students, and the math problem as part of the big-picture agent's prompt input to ensure that the generated dialogue follows a logical order and interaction pattern~\cite{stamper2024enhancing}. 

\textbf{Dialogue Flow under the Picture-Character Prompt Pipeline:} As can be seen in Fig. \ref{fig:promptPipeline}, the BigPicture Agent maintains a dialog list that starts with an initial dialog, which is shared with each Student Agent. When the Tutor gives guidance for the first time, Tutor's speech will be added to both the BigPicture and Student Agent dialog lists, updating the scene’s ``story.'' Next, The system calls the BigPicture Agent to continue the ``story'' and determine the next character to speak. In this example, the BigPicture Agent assigns the next turn to Lily, a Student Agent, who generates a response based on the updated dialog. Lily's response is then added to the dialog lists of the BigPicture and all Student Agents. Afterward, the BigPicture Agent continues the conversation, pointing to James's speech, which is also updated in the log. The BigPicture Agent then continues with the Tutor's speech, and instead of calling other agents, the system waits for the Tutor's input, updating all dialog records accordingly. This pipeline creates a natural, interactive dialog between Tutor and Students. Refer to Fig.~\ref{fig:promptPipeline} for the detailed prompt pipeline corresponding to the example described above.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Feedback Design}
\textit{TutorUp} combines GPT-4o~\cite{openai2023chatgpt4} with evidence-based teaching strategies to provide personalized feedback for tutors interacting with simulated students. Two types of feedback are provided: Immediate and Asynchronous feedback~\cite{wong2017using}, each with different timing and content. Below are design considerations for both.


\subsubsection{Immediate Feedback} Immediate Feedback provides contextually relevant and personalized support during tutor-student interactions, providing assistance on request. This feedback is concise, allowing tutors to quickly read and continue teaching. It includes two main components: (1) a description of students' current engagement and how the tutor engages them, and (2) teaching strategy recommendations to address immediate issues. To generate (1), the system uses the latest tutor-student conversation to summarize the current situation. By incorporating matched teaching strategies (Subsections \ref{subsec:survey2} and \ref{subsec:iteration}), it identifies effective strategies for the three students and provides actionable insights for the tutor.
%
Immediate Feedback allows tutors to create a practice loop by testing strategies, observing student responses, and adjusting their approach if needed. When a strategy isn’t effective, tutors can consult the feedback to find alternatives, expanding their repertoire and improving their application of strategies in real teaching scenarios.

\subsubsection{Asynchronous Feedback}
\label{subsec:Asynchronous Feedback }
Compared to Immediate Feedback, Asynchronous Feedback is more detailed and comprehensive, designed to help tutors reflect on their practice for improvement. To structure Asynchronous Feedback we use the Integrated Reflective Cycle~\cite{bassot2015reflective}, which includes four steps: (1) describing the experience, (2) reflecting on what went well and what could be improved, (3) connecting the experience to broader theories, and (4) using the reflection for future preparation. %Following this structure, Asynchronous Feedback is organized around four core components. 
Tab.~\ref{tab:asynchoronous_feedback} outlines the themes of each step in the context of Asynchronous Feedback and provides examples of feedback content.

% \usepackage{color}
% \usepackage{tabularray}

\aptLtoX{\begin{table}
\centering
\caption{Asynchronous Feedback generated following the Integrated Reflective Cycle.}
\label{tab:asynchoronous_feedback}
\begin{tabular}{lp{80pt}p{110pt}}
\toprule
Stage                             & Explanation                                           & Feedback Example                                                                                                                                                                                                  \\
\midrule
Overview              & Dialogue Overview                                     & The
  conversation depicts a tutor facilitating a math problem-solving session
  with three students, Ethan, Chloe, and Noah. The tutor asks them to
  calculate.                                             \\
  \hline
Reflection &  Student Engagement Analysis                 & Ethan's Cognitive Engagement: 
Ethan shows high cognitive engagement by quickly providing answers and later explaining the math problem to his peers.                                                               \\
\hline
Theory                           & Evaluation of Tutor's Strategies                   & Distributed Questioning:
  Calling on each student to answer questions increased participation but
  highlighted varying levels of engagement and understanding.                                                  \\
  \hline
Preparation               & Suggestions and Recommendations for Future Interactions & Targeted Support for Noah: Provide Noah with more direct and supportive instructional strategies, such as one-on-one follow-ups or scaffolded questioning to build his confidence and understanding incrementally. \\
\bottomrule
\end{tabular}
\end{table}}{\begin{table}
\centering
\caption{Asynchronous Feedback generated following the Integrated Reflective Cycle.}
\label{tab:asynchoronous_feedback}
\begin{tblr}{
  width = \linewidth,
  colspec = {Q[16]Q[29]Q[55]},
  row{1} = {c},
  hlines,
}
Stage                             & Explanation                                           & Feedback Example                                                                                                                                                                                                  \\
Overview              & Dialogue Overview                                     & The
  conversation depicts a tutor facilitating a math problem-solving session
  with three students, Ethan, Chloe, and Noah. The tutor asks them to
  calculate.                                             \\
Reflection &  Student Engagement Analysis                 & Ethan's Cognitive Engagement: 
Ethan shows high cognitive engagement by quickly providing answers and later explaining the math problem to his peers.                                                               \\
Theory                           & Evaluation of Tutor's Strategies                   & Distributed Questioning:
  Calling on each student to answer questions increased participation but
  highlighted varying levels of engagement and understanding.                                                  \\
Preparation               & Suggestions and Recommendations for Future Interactions & Targeted Support for Noah: Provide Noah with more direct and supportive instructional strategies, such as one-on-one follow-ups or scaffolded questioning to build his confidence and understanding incrementally. 
\end{tblr}
\end{table}}
