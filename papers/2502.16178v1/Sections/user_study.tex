\section{User Study: Evaluation of TutorUp System}
\label{sec:user_study}

\textit{TutorUp} is designed to help novice tutors practice teaching strategies for promoting student engagement in online tutoring through scenario-based training. To validate its effectiveness, we employed mixed methods and designed a within-subjects study comparing \textit{TutorUp} with a baseline system lacking its core features--further introduced in Subsection~\ref{subsec:baseline}. We analyzed participant evaluations of both systems to highlight the advantages of \textit{TutorUp} in key areas. Additionally, an expert-driven qualitative assessment was conducted to evaluate tutor performance in addressing student engagement challenges after training with each system. 
% To assess the effectiveness of our proposed system, w

\subsection{Participants} 
\label{subsec:participants}

We recruited 16 participants (6 females and 10 males) proficient in English as the targeted users for training with \textit{TutorUp} and the baseline system. Among them, four were novice tutors from JANN, and twelve were full-time university students from China and the U.S. All participants were novice online tutors or interested in online teaching, with less than 30 hours of experience and no formal tutor training. Sessions were conducted via Zoom, and participants were compensated at a rate of \$10 per hour. 
%
For the qualitative assessment, we recruited two experienced online tutors, each with over 15 months of online teaching experience. They were tasked with evaluating the participants' test results using co-designed metrics (details in Subsection~\ref{subsec:qualitative_assessment})

\subsection{Baseline System}
\label{subsec:baseline}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figs/baseline.png}
    \caption{Baseline System: The baseline system consists of three main panels:  A) \textit{Task Introduction Panel: }This panel introduces the general scenario to the tutors, prompting them to consider how they would engage students in the given scenario. Tutors are then asked to write down their proposed strategies for student engagement.  B) \textit{Scenario Information Panel:} This panel provides the scenario's theme, the math problem, and relevant student information, all of which are also included in \textit{TutorUp}.  C) \textit{Feedback Panel:} After tutors complete their responses, this panel offers scenario-strategy pairs as feedback. These pairs are also used as part of the feedback prompts in \textit{TutorUp}.}
    \label{fig:baseline}
\end{figure*} 


To test how our system performed versus other scenario-based tutor training tools, we built a baseline system. Specifically, we wanted to explore how the core features--the scenario scheme (LLMs simulating students) and the feedback scheme (LLMs providing personalized feedback based on learning theories)--performed in comparison to other systems. The design of the baseline system was inspired by the tutoring system created by \citet{personalizedlearning}, which also provides tutoring scenarios and feedback for tutors. However, the scenarios are described only in text and do not simulate a realistic multi-turn conversation and the feedback is not tailored to the tutor's responses~\cite{developmentofscenario, whenthetutorbecomes}. Specifically, while keeping other information and design elements (scenario theme, student information, math problems, and matched teaching strategies) unchanged, we removed the mechanism of simulating students to present the scenario. Instead, the scenario was presented through static text descriptions. We also removed the use of LLMs in providing feedback and instead directly provided a corresponding strategy-scenario matching table (Section~\ref{subsec:survey2}). The key differences between the baseline system and \textit{TutorUp} in scenario and feedback scheme are listed in Tab. \ref{baseline-differences}.

To receive training from the baseline system, users first review the task introduction panel (Fig. \ref{fig:baseline} A) to see the scenario description, which provides the context of the present student engagement challenges. Users are then prompted to think about how to engage these students. Without simulated students for them to interact with, their task is to write down teaching strategies they would implement to address the scenario, combined with the information on scenario background panel(Fig. \ref{fig:baseline} B) listed on the left. When users finish writing down teaching strategies, they can submit their responses and click ``Get Feedback'' to view a table (Fig. \ref{fig:baseline} C) of scenario-strategy pairs as feedback. 




\subsection{Study Setup}
\label{subsec:setup}
To counterbalance potential order effects, the recruited novice tutors were divided into two groups with eight tutors each. We asked one group to experience the Baseline condition first, followed by the \textit{TutorUp} condition, while the other group followed the reverse order. Since both the baseline system and \textit{TutorUp} are scenario-based training systems, we randomized the four designed scenario assignments across participants to avoid bias and ensure a balanced training experience. To prevent cross-condition influence in this within-subjects study, different math problems were presented in each condition to maintain contextual distinction. 

To assess the training effectiveness, we designed a separate test for participants to complete after each system’s training. 
On one hand, the test should be realistic, so ideally, tutors would teach in actual online learning scenarios with disengaged students to evaluate their performance. On the other hand, setting up real scenarios is costly and could potentially have negative impacts on students. Therefore, our test uses simulated scenarios, with the same mechanism as \textit{TutorUp}, but without the reset or feedback functions. To minimize the potential effects caused by the test system, which differs from the baseline condition but is similar to the \textit{TutorUp} condition, users of the baseline system were asked to first learn and familiarize themselves with the test system in order to adapt to the simulated teaching scenario.



\aptLtoX{\begin{table}
\centering
\caption{Comparison between instructional conditions within the Baseline and the \textit{TutorUp} system. The Baseline system features textual scenario descriptions, a writing tasks, and summative feedback. The \textit{TutorUp} system implements scenario-based training via interactions with LLM-based conversational agents and LLM-based feedback on user inputs and teaching strategies.}
\label{baseline-differences}
\begin{tabular}{p{50pt}p{70pt}p{120pt}}
\toprule
Condition & Baseline & \textit{TutorUp} \\
\midrule
Scenario Scheme & Text description & Interactions with simulated students\\
\hline
Feedback Scheme & A list of strategies & LLM-generated immediate and asynchronous feedback \\
\hline
Training Task   & Write down the measures and strategies to engage students with strategy list & Have conversations with simulated students to engage them with immediate and asynchronous feedback \\
\hline
Test Task & Engage simulated students for the same scenario where they have been trained &                            \\
\bottomrule    
\end{tabular}
\end{table}}{\begin{table}
\centering
\caption{Comparison between instructional conditions within the Baseline and the \textit{TutorUp} system. The Baseline system features textual scenario descriptions, a writing tasks, and summative feedback. The \textit{TutorUp} system implements scenario-based training via interactions with LLM-based conversational agents and LLM-based feedback on user inputs and teaching strategies.}
\label{baseline-differences}
\begin{tblr}{
  width = 0.9\linewidth,
  colspec = {Q[20]Q[40]Q[40]},
  cells = {l},
  cell{5}{2} = {c=2}{0.72\linewidth},
  hlines,
  vline{2-3} = {1-4}{},
  vline{2} = {5}{},
}
Condition & Baseline & \textit{TutorUp} \\
Scenario Scheme & Text description & Interactions with simulated students\\
Feedback Scheme & A list of strategies & LLM-generated immediate and asynchronous feedback \\
Training Task   & Write down the measures and strategies to engage students with strategy list & Have conversations with simulated students to engage them with immediate and asynchronous feedback \\
Test Task & Engage simulated students for the same scenario where they have been trained &                                
\end{tblr}
\end{table}}


\subsection{Study Procedure}

The study was conducted online via Zoom and was recorded for review and verification. Each participant, based on their assigned group, received training with both systems in sequence. 


In each system, participants received training on one of different designed scenarios. During the baseline system training, tutors stopped whenever they felt they had done everything they would typically do to engage students and then review the feedback. In the \textit{TutorUp} training, tutors could engage with simulated students and request immediate feedback at any time. They could reset the scenario and try multiple approaches, and once they felt they had received sufficient training, they could end the session and review the asynchronous feedback. After each training session, participants completed a test, where they had 10 minutes to engage these simulated students. Each test after the training featured the same scenario and students as in the training, but with a different math problem to ensure participants apply the skills they've learned, rather than relying on rote memorization of the scenario. In both systems, participants were asked to try to learn and remember something useful and helpful from the training and apply it during the simulated teaching test. 

After completing each system’s training, they took a separate test designed by us, resulting in two sets of test results. The training and test records from all participants were collected for a comprehensive comparative analysis. Following each training and test, participants completed a post-task survey consisting of a questionnaire with 5-point Likert scale questions derived from the existing literature~\cite{kirkpatrick1994, howcroft2020twenty}, as listed in Tab. \ref{tab:questionnaire}. 

After both training, we also conducted an interview with open-ended questions to gather participants' thoughts on the key features of \textit{TutorUp} in terms of Scenario Simulation, Feedback scheme, and Overall system usage.


\subsection{Qualitative Assessment}
\label{subsec:qualitative_assessment}

Two experienced tutors were asked to provide a qualitative assessment of participants' test results to determine which system led to better training outcomes. The test results consisted of dialogue records from tutoring sessions with the simulated students. In collaboration with the tutors, we designed four evaluation criteria (Fig. ~\ref{fig:expert_ratings}). Each dialogue record was rated on a scale of 1 to 3. To ensure fairness in the assessment, the tutors were blinded to whether each dialogue came from the \textit{TutorUp} system or the baseline system.



\input{tables/questionaire_overview}

\subsection{Hypothesis}
We propose the following alternative hypotheses, informed by prior literature on tutor training systems ~\cite{kirkpatrick1994, howcroft2020twenty}, targeting both participants' evaluations of the system and the qualitative assessment from the experienced tutors.

H1. \textit{TutorUp} performs better than the baseline system in terms of training relevance (H1a) and  necessity (H1b)

H2. \textit{TutorUp} performs better than the baseline system in terms of training effectiveness. Specifically, \textit{TutorUp} features more practical scenario presentation (H2a) and usefulness of feedback (H2b) compared to the baseline system.

H3. \textit{TutorUp} performs better than the baseline system in terms of tutors' skill and confidence increase. Specifically, \textit{TutorUp} achieves higher increase in confidence (H3a), applicability (H3b), strategies (H3c), and future benefits (H3d) to tackle engagement challenges.

H4. \textit{TutorUp} performs better than the baseline system in terms of usability. Specifically, the system is easier to use (H4a), more engaging and enjoyable (H4b), and more likely to be used in the future (H4c).

H5. Tutors trained by \textit{TutorUp} use strategies more appropriately compared to the baseline system. 

H6. \textit{TutorUp} encourages higher student engagement compared to the baseline system. 
% Specifically, students are more prompted to be actively engaged in learning through \textit{TutorUp}.

H7. \textit{TutorUp} enables tutors to deliver strategies in a better manner compared to the baseline system. Specifically, tutors' instructions to apply strategies are more accessible (H7a) and effective (H7b) for students to engage. 