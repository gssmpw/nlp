\section{Related Work}
\label{sec:related_worl}

\subsection{Scenario-Based Tutor Training}



Scenario-based training is an educational paradigm advocating for practice in authentic contexts that simulate real-world situations~\cite{preservice}.
For tutor education, scenario-based learning offers a solution to a common challenge faced by novice teachers--\textit{learning passively from observing others with limited opportunities for active practice of teaching strategies in low-stakes settings}~\cite{prospectsforchange}.
%  before starting their practicum
Scenarios that are authentic and aligned with real-world contexts enable learners to build strong connections with applications they will encounter in their professional lives~\cite{teachingearly}.
% Simulations facilitate effective scenario creation.
A prominent example is clinical simulations, where participants respond to scenarios they are likely to face in their profession~\cite{dotger2013had,teachermoments}. This method has been utilized in healthcare for decades and has since been widely adopted in the field of tutor education~\cite{teachermoments,simulationbasedlearning}. \citet{dotger2013had} and~\citet{designingandusing} both developed simulations in which trained actors assume the roles of ``representative'' characters (e.g., a parent or student). These actors engage with participating educators and reliably introduce specific, scripted dialogue and themes into the simulation~\cite{dotger2013had,clinicalsimulations}. However, despite the value of such simulations, they are challenging to organize and costly to implement. To address these issues,~\citet{teachermoments} developed Teacher Moments as a digital version of simulations. The platform offers a cost-effective and efficient way to simulate scenarios, enabling tutors to repeatedly practice various teaching situations. The PLUS platform, developed by Lin et al.~\cite{developmentofscenario, whenthetutorbecomes,usinglarge,personalizedlearning}, recently advanced scenario-based simulated courses to train tutors in addressing math difficulties and motivational barriers. However, their scenarios are written as text, and tutors only provide solutions but cannot interact with students in the designed scenarios.
%
These previous studies have demonstrated the effectiveness of scenario-based training. However, more work is needed to investigate what typical engagement issue scenarios are and how to utilize LLMs to simulate the scenarios and provide tutors with feedback to address engagement issues in online learning. This paper develops a tutor training system where scenarios are simulated by intelligent systems (LLMs) and are designed with theories and insights from learning science literature~\cite{casestudy, abou2021emergency, enhancing,sevenprinciples,motivation} and a formative study with dozens of ($N_1=86$, $N_2=102$) real tutors. 

\subsection{LLM-based Human Simulation and Feedback Generation in Education}
LLMs like ChatGPT-4o~\cite{openai2023chatgpt4} have proven highly effective in simulating human interactions and activities in educational contexts, including classroom scenarios~\cite{zhang2024simulating, thomas2023so, ma2024students}, learning by teaching~\cite{jin2024teach, schmucker2023ruffle}, and feedback generation~\cite{hirunyasiri2023comparative, lin2024can, dai2024assessing, stamper2024enhancing, demszky2024does}. 
 
Our work develops a scenario-based tutor training system and leverages LLMs to 1) simulate the interactions between students and tutor and 2) provide personalized feedback for tutors to practice.

In terms of using LLMs to simulate students' interactions, a significant work is SimClass~\cite{zhang2024simulating}, a multi-agent classroom simulation. SimClass deploys multiple agents with distinct roles, such as teacher, assistant, and classmates, to simulate a dynamic classroom environment, enhancing collaborative learning experiences among virtual students. \citet{lee23generative} integrated LLMs into immersive problem-solving environments, showing their effectiveness in simulating realistic student personas and challenges. Similarly, GPTeach~\cite{gpteach} is a chat-based tool allowing novice tutors to interact with GPT-based simulated students exhibiting varied personas, learning goals, and engagement levels. However, these works including GPTeach lack feedback for more effective training practice and improvement.

LLMs have been widely applied to assess tutors' open-text responses and provide personalized feedback both immediately~\cite{aleven2006toward} and asynchronously~\cite{dai2024assessing, stamper2024enhancing}. This offers an efficient alternative to the traditionally time-intensive process of feedback generation~\cite{dai2024assessing,stamper2024enhancing}. Researchers have employed various  techniques, including few-shot prompting~\cite{fewshot} and chain-of-thought (CoT) prompting~\cite{chain} to provide qualified feedback. For example,~\citet{hirunyasiri2023comparative} explored zero-shot and few-shot CoT prompting to provide timely feedback on tutors' use of praise for students~\cite{hirunyasiri2023comparative}. Notably,~\citet{learningandAI} employed zero-shot learning and prompt chaining to provide feedback specifically in scenario-based tutor training~\cite{learningandAI}, showing that LLMs can deliver high-quality feedback on tutors' scenario-based responses. These studies collectively highlight the effectiveness of LLMs in providing feedback for tutor training. 
% Our work builds upon these foundations to further advance the application of LLMs in this context.

% Studies on using LLMs for simulating human interactions and generating feedback demonstrate the feasibility and effectiveness of creating an LLM-based tutor training system. 
Building on these foundations, we integrate LLMs into our system, \textit{TutorUp}, for scenario simulation and feedback generation, creating a realistic and accessible training system that enhances tutors' ability to engage students in online learning environments.

\subsection{Measuring Engagement in Online Learning Environments}
\label{subsec:engagement}

To provide feedback on engagement issues, we surveyed works on engagement definition and measurement. Engagement is recognized as a complex and multifaceted concept, with its precise definition varying across contexts and domains~\cite{Hagerup1993, joshi2022behavioral, redmond2018online,fredricks2004school}. A prevalent definition by~\citet{fredricks2004school} breaks down engagement into three distinct dimensions, capturing emotional, behavioral, and cognitive aspects. In the context of online learning, scholars added dimensions of collaborative engagement, focusing on peer interaction, as well as social engagement, facilitated through teaching strategies promoting community and sense of belonging~\cite{joshi2022behavioral,redmond2018online}. 

Numerous approaches have been designed to measure learners' engagement levels, based on the diverse ways in which learners display behaviors, convey emotions, and direct cognitive efforts towards learning tasks.~\citet{booth2023engagement} have comprehensively reviewed engagement measurement methods, categorizing them into traditional and modern methods. Traditional methods rely on human-driven assessments, including retrospective self-reports (e.g., questionnaires, interviews)~\cite{turner2000studying,gorin2001recall}, momentary self-reports (e.g., experience sampling~\cite{csikszentmihalyi1987validity, hutt2019time}), and observer-based measures (e.g., video coding~\cite{zaletelj2017predicting,yun2018automatic,sumer2021multimodal}, or live observations like the BROMP protocol~\cite{ocumpaugh2015baker}). While effective, traditional methods face challenges such as scalability, time intensity, and potential human biases. In contrast, modern methods utilize machine learning and sensor technologies to dynamically infer engagement from features such as video~\cite{bidwell2011classroom,dhall2018emotiw}, audio~\cite{dhall2018emotiw}, and interaction logs~\cite{grawemeyer2017affective,dewan2019engagement}. This automation enhances scalability, reduces costs, and enables real-time interventions, addressing limitations of traditional methods~\cite{booth2023engagement}.

In this work, with the guidance of previous learning theories on engagement~\cite{fredricks2004school, joshi2022behavioral}, we explore how to use LLMs to automatically analyze simulated students' engagement changes by examining their conversational responses and provide feedback from four dimensions: emotional, behavioral, cognitive, and collaborative.