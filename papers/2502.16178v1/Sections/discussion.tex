\section{Discussion}

\subsection{Enhancing Novice Teachers' Understanding of Student Disengagement}
\label{subsec:enhancing_understanding}

In this work, we summarized scenarios of online tutoring challenges through survey questions like, ``Have you employed a specific strategy and how and when did you use it?'' The scenarios were based on tutors' descriptions of student situations (e.g., fast learners get bored easily). However, only a small number of responses ($138/1326$) provided detailed scenario descriptions, with many answers being vague, such as ``always'' or ``at the beginning.'' This suggests that while tutors can sense disengagement, they struggle to accurately link it to students' underlying states behaviors. While other studies~\cite{fredricks2004school,joshi2022behavioral} on engagement focus on abstract dimensions like cognitive, emotional, and social engagement, our study uses more observable and concrete features, such as a student’s behavior, knowledge level, and initial actions, to represent engagement. This shift to tangible metrics makes signs of disengagement more visible and helps tutors better understand student behavior.



\subsection{Interactive Scenarios Foster Immersive Learning and Adaptive Strategy Development}

Our study found that by providing more interactive and concrete student simulations, \textit{TutorUp} enables tutors to engage directly with specific problems and apply strategies more practically and effectively. The dialogue-based format fosters a relaxed, realistic environment, encouraging tutors to experiment with different strategies, thus reducing the fear and anxiety of making mistakes that they might face in real classrooms.
%
Additionally, in our system, students' reactions serve as another form of feedback, closely mirroring real-life scenarios. Teachers can assess whether their chosen strategies are effective based on the simulated students' responses and adjust their approach accordingly. The presence of a reset feature encourages teachers to undo actions and try different strategies, providing additional practice opportunities. In this way, the reactive scenario-based training system demonstrates its distinct advantages.

\subsection{Simulating Natural Online Students-Tutor Session }

Inspired by prior work on LLMs for creating and extending logically coherent stories and scripts ~\cite{mirowski2023co,shakeri2021saga,grigis2024playwriting}, we introduced the BigPicture Agent to manage the sequence of interactions between students and tutors. It handled student responses, ensuring logical progression in the dialogue. For example, if a tutor asks a question, the BigPicture Agent ensures the correct student responds, maintaining conversational consistency.

During development, we found it necessary to implement some rules for the BigPicture agent to structure dialogues. For instance, when the tutor greets the students, all students must respond to create a polite and friendly environment. Additionally, consecutive student responses were limited to leave space for the tutor’s instructions. However, in practice, as the conversation lengthened, LLM-based agents sometimes deviated from instructions, leading to inconsistent behavior, such as students ``forgetting'' previous parts of the conversation or responding only one at a time unless directly addressed by the tutor. This highlights the limitations of current LLMs in simulating dialogue, as they cannot perfectly replicate the dynamics of real-world interactions. Future work could focus on enhancing memory management and context retention in LLMs to handle long, dynamic conversations more effectively, possibly by incorporating techniques like context tracking or memory augmentation, which have been explored in recent research~\cite{wang2024augmenting, yi2024survey}. Additionally, hallucinations can occur, where the model fabricates unrealistic or inconsistent student behaviors, like a disengaged student suddenly giving detailed answers. To mitigate this, we designed student prompts to enforce consistency and limit unrealistic responses. For example, the prompt explicitly instructs that the student behavior should be gradually adjusted based on tutor interactions, but not instantly, which helps prevent the model from ``hallucinating'' a sudden shift in behavior. Future research will focus on developing more accurate student simulations and develop quantitative measures to evaluate their accuracy across various dimensions (e.g., cognitive and affective)~\cite{kaser2024simulated}.
 


\subsection{Using LLMs to Simulate Disengaged Students}
\label{subsec:simulateEngagement}

In our student agent's prompt, we did not specify how the students should \textit{change} their engagement levels over time in response to the tutors' teaching. Instead, we provided basic personality traits and instructed the agents to follow these traits. Following initial disengaged behaviors, their engagement would change based on the tutor's instructions. In other words, when and how much the students' engagement shifts, as well as how that change is displayed, is entirely determined by the LLM. This approach explores how LLMs model human-like behavior, but it also explains why H6, which supposes \textit{TutorUp} encourages higher student engagement compared to the baseline system, does not hold in the User Study. Despite the tutor using more appropriate strategies, the LLMs simulation may not reflect a consistent shift in student engagement as intended, as the model decides when and how engagement changes. Related work~\cite{shu2023you} has noted that current LLMs are unable to consistently and accurately model the subtle cognitive and psychological behaviors of humans. Nevertheless, even if the simulations are not perfectly accurate, tutors can still familiarize themselves with the teaching strategies and prototypical disengagement patterns, which can help improve their responses and adaptability in real-life situations. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations and Future Work}

\subsection{The Presentation and Measurement of Engagement Status}
Since the students are simulated, and cannot accurately mimic the true state of human students, using precise quantitative data for analysis does not seem meaningful. So we utilize the LLM to give analysis of changes in student engagement (Subsection~\ref{subsec:Asynchronous Feedback }), considering it qualitatively through cognitive, behavioral, emotional, and collaborative aspects ~\cite{joshi2022behavioral}, over tutor-students dialogues. This qualitative assessment on engagement fails to offer tutors precise numerical metrics. Additionally, we allowed the LLMs to fully control how student engagement changes over time, which is likely not fully representative of human students. In future work, we plan to explore better methods for quantifying engagement to help tutors more accurately assess whether their strategies are effective and whether student engagement has truly shifted. We also aim to improve the prompts to make the LLMs’ simulation of student engagement more natural and realistic.

\subsection{More Fine-grained Scenario Design}

% We identified student disengagement scenarios from survey responses and designed student personas based on them. However, a
As discussed in Subsection ~\ref{subsec:enhancing_understanding}, novice tutors often struggle to accurately perceive disengagement, resulting in survey results that lacked detailed descriptions of what disengaged students look like. Instead, tutors provided broad characteristics limiting the accuracy and realism of our student personas.

Another limitation is that we did not consider factors such as gender, race, or cultural background, which can influence student behavior, learning abilities and communication styles~\cite{lee23generative}. For example, P3 in our user study mentioned that students aged 10-11 in their country would neither have internet access nor express themselves with such logical precision, making the scenario unrealistic for them.
%
Thus, while our current approach represents a general attempt at student design, future work should consider more diverse factors and ensure scenarios are authentic across different cultural contexts. Future iterations could also include greater customization options, allowing tutors to extend TutorUp to other domains, such as science, language arts, or social studies, by tailoring content to each domain's learning objectives. Moreover, the system’s conversational and scenario-based features could also be adapted to other settings, such as clinical environments for medical training or sales training for practicing customer interactions.


% \subsection{More Reasonable and Comprehensive Depiction of Scenarios}
\subsection{More Realistic Scenarios Depiction}

We used LLMs to simulate disengaged students through prompt design. We found that the student agents generally followed their assigned personalities and adjusted their engagement based on the tutor’s instructions, though not always perfectly. Participants (P7 and P8) noted that the simulated students were ``too smart'' and ``lacked complexity.'' This highlights one limitation of using LLMs to simulate young, disengaged students, as they sometimes fail to mimic the illogical or unpredictable behaviors typical of this age group, especially when simulating inattentiveness or poor performance. This "overly smart" behavior is a key challenge in using LLMs to model younger students accurately~\cite{gpteach,argyle2023out}. To address these limitations, future work should focus on improving the realism of LLM-based student simulations. This could involve refining prompt designs to capture the unpredictable behaviors of disengaged or struggling students, as well as using fine-tuning techniques with age-specific data. Introducing randomness in student behaviors could also enhance the realism of the interactions. 

Additionally, establishing guidance for measuring realism could be valuable for future studies. In our paper, we evaluated realism by asking users to compare the results of simulations with those observed in the real world, which is subjective and based on impression. One solution to solve this limitation is to calculate the similarity metrics (e.g.,cosine similarity and Jaccard similarity) between the simulated dialogue and real student-tutor conversations, which can assess how closely the dialogues and interaction patterns of the simulated students reflect real-world scenarios~\cite{lau2016empirical, niwattanakul2013using}. 




\label{sec:discussion}
