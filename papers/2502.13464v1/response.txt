\section{Related Work}
% 加上和我们的关系
\subsection{CSPE Based on Internal Knowledge}

The sentence probability and perplexity computed by LMs can serve as indicators of commonsense plausibility, even in zero-shot settings**Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. For LLMs with instruction-following capability, they can be directly prompted to judge whether a given input is consistent with commonsense or not**Brown et al., "Language Models as Zero-Shot Learners"**. Beyond directly judging plausibility, some methods**Holtzman et al., "The Curious Case of Neural Text Degeneration"**, evaluate the plausibility of hypotheses by scoring the validity of entailment paths generated by the LLMs, i.e., the reasoning chains justifying `reasonable' or `unreasonable' conclusions, and selecting the final prediction based on the highest-scoring path. VERA**Zellers et al., "REDD: Reference-based Reading Comprehension Dataset"**, adopts a discriminative approach, training a classification head to make predictions based on model representations, which fine-tunes LLMs on\textasciitilde7 million commonsense statements. In contrast, our approach also leverages internal knowledge from a discriminative perspective but does not require additional training.

\subsection{CSPE Based on External Knowledge}

Language models (LMs) may have insufficient or inaccurate knowledge, which led to some methods to incorporate external knowledge to better estimate commonsense plausibility. A typical approach is to augment the model's knowledge by retrieving relevant sentences from external sources**Bart et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. Commonsense knowledge bases (KBs)**Lin et al., "Automated Knowledge Graph Construction Using Entity Embeddings"**, store extensive commonsense knowledge, enabling the extraction of relevant subgraphs to evaluate sentence consistency with commonsense**Huang et al., "Deep Learning for Natural Language Processing: A Survey"**. To alleviate the coverage limitations of the KBs while leveraging the extensive knowledge encoded in LMs, COMET**Madarasz et al., "COMET: Commonsense Models for Transforming Existing Sentences into Question-Answer Pairs"**, introduced a dynamic KB by pre-training LM on existing commonsense KBs. Methods that utilize this dynamic KB**Talmor et al., "OLMPACK: A Large-Scale Open-Domain Reasoning Corpus"**, demonstrate improved generalization across various commonsense reasoning tasks.