@inproceedings{DBLP:conf/acl/KumarT21,
    title = "Reordering Examples Helps during Priming-based Few-Shot Learning",
    author = "Kumar, Sawan  and
      Talukdar, Partha",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.395/",
    pages = "4507--4518"
}

@inproceedings{FLARE,
    title = "Active Retrieval Augmented Generation",
    author = "Jiang, Zhengbao  and
      Xu, Frank  and
      Gao, Luyu  and
      Sun, Zhiqing  and
      Liu, Qian  and
      Dwivedi-Yu, Jane  and
      Yang, Yiming  and
      Callan, Jamie  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.emnlp-main.495",
    pages = "7969--7992",
}

@inproceedings{benchmarkOfAnswerEvaluationFromRetriever,
    author = {Arabzadeh, Negar and Bigdeli, Amin and Clarke, Charles L. A.},
    title = {Adapting Standard Retrieval Benchmarks to Evaluate Generated Answers},
    year = {2024},
    isbn = {978-3-031-56059-0},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
    doi = {10.1007/978-3-031-56060-6_26},
    booktitle = {Advances in Information Retrieval: 46th European Conference on Information Retrieval, ECIR 2024, Glasgow, UK, March 24–28, 2024, Proceedings, Part II},
    pages = {399–414},
    numpages = {16},
    location = {Glasgow, United Kingdom}
}

@misc{bertScore,
      title={{BERTScore}: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}

@inproceedings{bleuScore,
    author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
    title = {{BLEU: a method for automatic evaluation of machine translation}},
    year = {2002},
    publisher = {Association for Computational Linguistics},
    address = {USA},
    doi = {10.3115/1073083.1073135},
    booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
    pages = {311–318},
    numpages = {8},
    location = {Philadelphia, Pennsylvania},
    series = {ACL '02}
}

@misc{demoRetrieveInICL,
      title={Dr. {ICL}: Demonstration-Retrieved In-context Learning}, 
      author={Man Luo and Xin Xu and Zhuyun Dai and Panupong Pasupat and Mehran Kazemi and Chitta Baral and Vaiva Imbrasaite and Vincent Y Zhao},
      year={2023},
      eprint={2305.14128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14128}, 
}

@misc{edge2024localglobalgraphrag,
      title={From Local to Global: A Graph {RAG} Approach to Query-Focused Summarization}, 
      author={Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Jonathan Larson},
      year={2024},
      eprint={2404.16130},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.16130}, 
}

@inproceedings{factScore_EMNLP23,
    title = "{FA}ct{S}core: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
    author = "Min, Sewon  and
      Krishna, Kalpesh  and
      Lyu, Xinxi  and
      Lewis, Mike  and
      Yih, Wen-tau  and
      Koh, Pang  and
      Iyyer, Mohit  and
      Zettlemoyer, Luke  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.emnlp-main.741",
    pages = "12076--12100",
}

@inproceedings{finegrainedAnalysisOfBERTScore,
    title = "A Fine-Grained Analysis of {BERTS}core",
    author = "Hanna, Michael  and
      Bojar, Ond{\v{r}}ej",
    booktitle = "Proceedings of the Sixth Conference on Machine Translation",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.wmt-1.59",
    pages = "507--517",
}

@misc{huang2024empiricalstudyllmasajudgellm,
      title={{An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4}}, 
      author={Hui Huang and Yingqi Qu and Xingyuan Bu and Hongli Zhou and Jing Liu and Muyun Yang and Bing Xu and Tiejun Zhao},
      year={2024},
      eprint={2403.02839},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.02839}, 
}

@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
    pages = "452--466",
}

@inproceedings{levy-etal-2023-diverse,
    title = "Diverse Demonstrations Improve In-context Compositional Generalization",
    author = "Levy, Itay  and
      Bogin, Ben  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.78",
    pages = "1401--1422",
}

@misc{li2023acecoderutilizingexistingcode,
      title={AceCoder: Utilizing Existing Code to Enhance Code Generation}, 
      author={Jia Li and Yunfei Zhao and Yongmin Li and Ge Li and Zhi Jin},
      year={2023},
      eprint={2303.17780},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2303.17780}, 
}

@inproceedings{liu-etal-2022-makes,
    title = "What Makes Good In-Context Examples for {GPT}-3?",
    author = "Liu, Jiachang  and
      Shen, Dinghan  and
      Zhang, Yizhe  and
      Dolan, Bill  and
      Carin, Lawrence  and
      Chen, Weizhu",
    booktitle = "Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
    month = may,
    year = "2022",
    address = "Dublin, Ireland and Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.deelio-1.10",
    pages = "100--114",
}

@article{lostInTheMiddle,
    title = "Lost in the Middle: How Language Models Use Long Contexts",
    author = "Liu, Nelson F.  and
      Lin, Kevin  and
      Hewitt, John  and
      Paranjape, Ashwin  and
      Bevilacqua, Michele  and
      Petroni, Fabio  and
      Liang, Percy",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00638",
    pages = "157--173",
}

@inproceedings{lu-etal-2022-fantastically,
    title = "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    author = "Lu, Yao  and
      Bartolo, Max  and
      Moore, Alastair  and
      Riedel, Sebastian  and
      Stenetorp, Pontus",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.556",
    pages = "8086--8098",
    abstract = "When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are {``}fantastic{''} and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13{\%} relative improvement for GPT-family models across eleven different established text classification tasks.",
}

@inproceedings{metero,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with High Levels of Correlation with Human Judgments",
    author = "Lavie, Alon  and
      Agarwal, Abhaya",
    booktitle = "Proceedings of the Second Workshop on Statistical Machine Translation",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W07-0734/",
    pages = "228--231"
}

@inproceedings{petroni-etal-2021-kilt,
    title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
    author = {Petroni, Fabio  and
      Piktus, Aleksandra  and
      Fan, Angela  and
      Lewis, Patrick  and
      Yazdani, Majid  and
      De Cao, Nicola  and
      Thorne, James  and
      Jernite, Yacine  and
      Karpukhin, Vladimir  and
      Maillard, Jean  and
      Plachouras, Vassilis  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.200/",
    pages = "2523--2544",
}

@inproceedings{powerOfNoise,
    author = {Cuconasu, Florin and Trappolini, Giovanni and Siciliano, Federico and Filice, Simone and Campagnano, Cesare and Maarek, Yoelle and Tonellotto, Nicola and Silvestri, Fabrizio},
    title = {{The Power of Noise: Redefining Retrieval for RAG Systems}},
    year = {2024},
    isbn = {9798400704314},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3626772.3657834},
    booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
    pages = {719–729},
    numpages = {11},
    keywords = {information retrieval, llm, rag},
    location = {Washington DC, USA},
    series = {SIGIR '24}
}

@inproceedings{ragInKnowledgeIntensiveNLP,
author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
title = {Retrieval-augmented generation for knowledge-intensive {NLP} tasks},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {793},
numpages = {16},
location = {Vancouver, BC, Canada},
series = {NIPS '20},
url={https://arxiv.org/abs/2005.11401}, 
}

@misc{ragReview,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.10997}, 
}

@inproceedings{ragsurvey,
author = {Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
title = {{A Survey on {RAG} Meeting {LLMs}: Towards Retrieval-Augmented Large Language Models}},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671470},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6491–6501},
numpages = {11},
keywords = {fine-tuning, in-context learning, large language model (llm), pre-training, prompting, retrieval augmented generation (rag)},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{roleOfRelevanceInNLP,
    author = {Sauchuk, Artsiom and Thorne, James and Halevy, Alon and Tonellotto, Nicola and Silvestri, Fabrizio},
    title = {On the Role of Relevance in Natural Language Processing Tasks},
    year = {2022},
    isbn = {9781450387323},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3477495.3532034},
    booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
    pages = {1785–1789},
    numpages = {5},
    keywords = {effectiveness, ir, neural databases, nlp, relevance},
    location = {Madrid, Spain},
    series = {SIGIR '22}
}

@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{rubin-etal-2022-learning,
    title = "Learning To Retrieve Prompts for In-Context Learning",
    author = "Rubin, Ohad  and
      Herzig, Jonathan  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.191",
    pages = "2655--2671",
    abstract = "In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompts). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and an LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially outperforms prior work and multiple baselines across the board.",
}

@article{surveyLLMEvaluation,
    author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
    title = {A Survey on Evaluation of Large Language Models},
    year = {2024},
    issue_date = {June 2024},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {15},
    number = {3},
    issn = {2157-6904},
    doi = {10.1145/3641289},
    journal = {ACM Trans. Intell. Syst. Technol.},
    articleno = {39},
    numpages = {45},
    keywords = {Large language models, evaluation, model assessment, benchmark}
}

@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
}

@inproceedings{zamani-rag,
    author = {Salemi, Alireza and Zamani, Hamed},
    title = {Evaluating Retrieval Quality in Retrieval-Augmented Generation},
    year = {2024},
    isbn = {9798400704314},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3626772.3657957},
    booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
    pages = {2395–2400},
    numpages = {6},
    keywords = {evaluation, retrieval quality, retrieval-augmented generation},
    location = {Washington DC, USA},
    series = {SIGIR '24}
}

@misc{zhuo2024icescoreinstructinglargelanguage,
      title={{ICE}-{Score}: Instructing Large Language Models to Evaluate Code}, 
      author={Terry Yue Zhuo},
      year={2024},
      eprint={2304.14317},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2304.14317}, 
}

