% TODO more details in methodology and data processing
% merge methodology and 
\section{Framework for Analyzing Emotion}
In this section, we present our framework for analyzing emotion. We first establish a basic understanding of emotion polarity by determining the sentiment valence of each root tweet and comment. We then use multi-label emotion detection to predict the emotion categories associated with each post. Based on this data, we explore the interactive nature of emotions, by identifying common patterns in emotion transition pairs between temporally-adjacent posts. Finally we investigate the emotional trajectory within threads to understand how emotional intensity and type shift over time, by aggregating the predicted labels for posts at each time stamp in a given thread. As part of this, we contrast rumour with non-rumour threads, to gain a holistic understanding of emotional expression in rumours and non-rumours on Twitter.

% elaborate a bit on why we choose EmoLLM, compared with other automatic emotion detection methods
\paragraph{Affective Computing: Automatic Emotion Detection}
Manually annotating emotions is both costly and time-consuming, so we use an LLM-based emotion detection model, EmoLLM~\citep{liu2024emollms}, which is specifically designed for sentiment analysis and emotion detection. The model was instruction-tuned on SemEval 2018 Task1 using a comprehensive emotion labeling scheme grounded in established theoretical frameworks. We prompt the model to perform Valence Ordinal Classification (V-oc), Emotion Classification (E-c), and Emotion Intensity regression (E-i). Detailed prompts are shown in \Cref{tab:emollm_ins}.

\paragraph{Categorical Emotion Labeling Scheme} \label{para:emotion_label}
Numerous emotion label sets  have been proposed~\citep{Ekman1992AnAF, Plutchik1980AGP, Russell1980ACM}. According to \citet{Ekman1992AnAF, Plutchik1980AGP}, certain emotions, such as joy, fear, and sadness, are considered more fundamental than others, both physiologically and cognitively. The Valence-Arousal-Dominance (VAD) model \citep{Russell1980ACM} categorizes emotions within a three-dimensional space of valence (positivity-negativity), arousal (active-passive), and dominance (dominant-submissive). Inspired by \citet{mohammad-etal-2018-semeval}, we incorporate elements from both basic emotion theories and the VAD model, and further ground EmoLLM emotion predictions to develop the following emotion label schemes: (1) \textit{neutral or no emotion}; (2) \textit{negative emotions}: anger (also includes annoyance and rage),  disgust (also includes disinterest, dislike, and loathing), fear (also includes apprehension, anxiety, and terror), pessimism (also includes cynicism, and no confidence), sadness (also includes pensiveness and grief); 3) \textit{positive emotions}: joy (also includes serenity and ecstasy), love (also includes affection), optimism (also includes hopefulness and confidence), anticipation (also includes interest and vigilance), surprise (also includes distraction and amazement) and trust (also includes acceptance, liking, and admiration). 


\paragraph{Emotion Polarity: Sentiment Valence} 
To understand the basic emotion polarity expressed in rumour and non-rumour content, we begin with sentiment valence analysis. Sentiment valence aims to capture the overall emotional tone conveyed by a post, in terms of how positive or negative it is~\citep{liu2024emosurvey}. We frame the sentiment valence task as ordinal regression~\citep{mohammad-etal-2018-semeval}. As shown in \Cref{tab:emollm_ins}, for a given tweet post, we classify it into one of seven ordinal levels of sentiment intensity, spanning varying degrees of positive and negative valence, that best represents the tweeter's mental state. The tweet posts within a thread can be divided into two categories: root tweets, which are posted by the publisher, and follow posts, which include all subsequent replies under the root post. We begin by conducting sentiment valence analysis on each post within the thread conversation. 
% TJB: confused by how comments can include all subsequent replies; we seem to be overloading the terminology, for comments to be both individual posts and series of posts
% RX: yes, I am unifiying all terms.
For each category, we compute the mean sentiment valence to enable further investigation into the specific emotions associated with different sentiment valences over a thread.
% TJB: clarify for comments whether the classification is done over the combined meta-document (i.e. the root + all comments to that point) or individually over the separate documents and then combined ... or over individual documents, in which case the statement about "all replies" needs clarification
% RX: we separate root and comments for each tweet conversation, the former is the root tweet posted by the publisher while the rest are comments. "all replies" mean all comments under root tweet, we aggregate them by computing the mean sentiment, and then average over each part.

\paragraph{Emotion Distribution} 
Following sentiment valence analysis, we then examine specific emotions and their distribution in rumour and non-rumour tweet posts.
Motivated by the fact that a certain tweet might exhibit more than one emotion, we frame the task as multi-label emotion detection problem. As shown as V-oc in \Cref{tab:emollm_ins}, given a tweet, we classify it into one of seven ordinal classes, corresponding to various levels of positive and negative sentiment intensity. To reduce noise from automatic emotion detectors, we take the top-three predicted emotions for each tweet. We then aggregate and plot the emotion distribution to provide an overview of dominant emotional trends across the rumour and non-rumour posts. Given that the follow posts make up the majority of the data compared to the root posts, we will focus on using follow posts in our next analysis.
% TJB: what is the basis of saying that the signal is richer? simply that there are more reply posts than root posts? clarify
% RX: yes, and we are more interested in interaction in comments.

\paragraph{Emotion Transitions} 
Emotions are contagious and highly interactive~\citep{Ferrara_2015}. When publishers write tweets that convey their emotions, readers are likely to respond with emotional reactions of their own~\citep{Ferrara_2015,emotion_dynamics}. In this part, we model this interactive nature of emotions in the form of emotion transition pairs, which are built from two chronologically-adjacent tweets. In each pair, the first element represents the emotion inferred from the initial content published at a given time, and the second element represents the emotion inferred from the reply content published immediately after. For example, if the first tweet exhibits \textit{joy} \textit{trust} and \textit{anticipation}, and the second tweet shows \textit{anger}, \textit{disgust} and \textit{surprise}, we form the pairs (\textit{joy}, \textit{anger}), (\textit{joy}, \textit{disgust}), (\textit{joy}, \textit{surprise}), (\textit{trust}, \textit{surprise}), (\textit{trust}, \textit{surprise}), (\textit{trust}, \textit{disgust}), (\textit{anticipation}, \textit{anger}), (\textit{anticipation}, \textit{surprise}) and (\textit{anticipation}, \textit{disgust}). We create transitions for all combinations of emotion pairs and explore the likelihood of emotion transition pairs occurring in rumour and non-rumour content. Exploring emotion transitions allows us to understand the emotional flow in social media conversations and uncover typical patterns of rumour and non-rumour content, and any differences between the two.

\paragraph{Emotion Trajectories} 
We explore the cumulative trajectory of emotion over time to observe how emotions evolve during the conversational thread. We collect all detected emotion labels for each tweet from both rumour and non-rumour content, then track cumulative emotion counts at each chronological step. Finally, we visualize these trends and apply regression models to analyze the growth of emotions over time. This temporal analysis reveals how emotions accumulate or intensify across time, offering insight into the trajectory of emotions in rumour and non-rumour content.

\begin{table*}[!h]
    \centering
    \small
    \begin{tabular}{cccccccccccc}
        \toprule
        \textbf{Setting} & \textbf{Ru} & \textbf{Non} & \textbf{p} & \textbf{\#Ru/Non} & \textbf{T} & \textbf{F} & \textbf{U} & \textbf{$p$ (U vs T)} & \textbf{$p$ (U vs F)} & \textbf{\#T/\#F/\#U} \\
        \midrule
        \textbf{PHEME root} & \textbf{$-$0.25} & $-$0.17 & 0.00 & 2602/2602 & $-$0.21 & $-$0.11 & \textbf{$-$0.39} & 7.75e-11 & 4.41e-11 & 629/629/629 \\
        \textbf{PHEME follow} & \textbf{$-$0.33} & $-$0.26 & 6.47e-09 & & $-$0.35 & $-$0.20 & \textbf{$-$0.39} & 0.03 & 8.38e-15 & \\
        \textbf{Twitter15 root} & \textbf{$-$0.26} & $-$0.01 & 3.51e-05 & 372/372 & $-$0.21 & $-$0.20 & \textbf{$-$0.34} & 0.01 & 0.01 & 359/359/359 \\
        \textbf{Twitter15 follow} & \textbf{$-$0.27} & $-$0.06 & 1.65e-09 & & $-$0.24 & $-$0.25 & \textbf{$-$0.30} & 0.16 & 0.21 & \\
        \textbf{Twitter16 root} & \textbf{$-$0.18} & \z0.07 & 0.00 & 205/205 & \z0.11 & $-$0.22 & \textbf{$-$0.30} & 1.35e-06 & 0.18 & 63/63/63 \\
        \textbf{Twitter16 follow} & \textbf{$-$0.31} & $-$0.12 & 9.19e-06 & & $-$0.30 & \textbf{$-$0.36} & $-$0.27 & 0.67 & 0.90 & \\
        % \textbf{CoAID root} & \textbf{$-$0.34} & $-$0.16 & 0.01 & 167/167 & - & - & - & - & - & - \\
        % \textbf{CoAID follow} & \textbf{$-$0.24} & $-$0.13 & 0.01 & & - & - & - & - & - & \\
        \bottomrule
    \end{tabular}
    \caption{Valence Ordinal Regression results for all datasets. root = root posts, follow = follow posts, Ru = rumour, Non = Non-rumour, T = True rumour, F = False rumour, U = Unverified rumour; $p$ values indicates significance of a one-tailed t-test.}
\label{tab:voc_results}
\end{table*}

\begin{algorithm}[ht!] 
\caption{PC Algorithm}
\label{pc}
\begin{algorithmic}[1] 
\State \textbf{Input:} Data $\mathbf{X}$, significance level $\alpha$
\State \textbf{Output:} Completed Partially Directed Acyclic Graph (CPDAG)

\State Initialize a complete undirected graph $G$ with all variables as nodes.

\State \textbf{Step 1: Skeleton Identification}
\For{each pair of variables $(X, Y)$ in $G$}
    \State Find the subset $S \subseteq \text{Adj}(X, G) \setminus \{Y\}$ such that 
    $X \indep Y \mid S$ with significance $\alpha$.
    \If{such a subset $S$ exists}
        \State Remove the edge $X - Y$ from $G$.
    \EndIf
\EndFor

\State \textbf{Step 2: Edge Orientation}
\For{each triple of variables $(X, Y, Z)$ in $G$ where $X - Z - Y$ and $X, Y$ are not adjacent}
    \If{$Z \notin S$ for all separating sets $S$ for $X$ and $Y$}
        \State Orient as $X \to Z \leftarrow Y$ (identify a collider).
    \EndIf
\EndFor

\While{possible}
    \For{each edge $(X - Y)$ in $G$}
        \If{there exists a directed path $X \to \dots \to Z$ such that $Z - Y$}
            \State Orient as $X \to Y$ (acyclicity rule).
        \ElsIf{orienting $X - Y$ as $X \to Y$ creates a new v-structure}
            \State Orient as $X \to Y$ (v-structure rule).
        \EndIf
    \EndFor
\EndWhile

\State \textbf{return} the CPDAG representing the equivalence class of causal graphs.

% how we frame the task, compute the emotion intensity, how to aggregate on conversation level

\end{algorithmic}
\end{algorithm}


\paragraph{Causal Relationship of Emotions in Rumour \& Non-Rumour Threads}
To gain a deeper insight into the relationship between rumours and the emotions underlying them, we extend our analysis beyond statistical correlation by conducting a causal analysis. Specifically, we apply the Peter-Clark (PC) algorithm \cite{Spirtes2000}, a classical constraint-based causal discovery algorithm on the three merged datasets. 

Uncovering causal relations between variables of interest is never an easy problem. Under the fundamental assumption of \textit{causal Markov condition} that a variable is conditionally independent of all its non-effects given its direct cause, \textit{faithfulness} ensures that the casual graph exactly encodes the independence and conditional independence relations among variables. These two assumptions allow us to infer causal relationships from observed statistical independencies, forming the cornerstone of constraint-based causal discovery methods. 

The PC algorithm identifies causal relationships among the variables of interest, represented as a directed acyclic graph (DAG), by numerating the independence and conditional independence relationships. The algorithm consists of two main steps: 
\begin{enumerate}
    \item \textbf{Skeleton Identification}: Starting with a complete undirected graph where all variables are connected, edges are iteratively removed based on conditional independence and independence relationships among variables, inferred by a conditional independence test. This step returns an undirected graph, which we call a skeleton. 
    \item \textbf{Edge Orientation}: After constructing the skeleton, edges are oriented by a set of predefined rules (Meek's Rule \cite{meek1997graphical}) to avoid cycles and orient collider structures.
\end{enumerate}

The complete PC algorithm is provided in algorithm \ref{pc}. It returns a  completed partially directed acyclic graph (CPDAG), which represents an equivalence class of causal graphs that are consistent with the observed dataâ€™s independence and conditional independence relations. In our implementation, we adopt the  Fisher-z test \cite{fisher_probable_1921} to infer the conditional independence relations.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main_anonymous"
%%% End:
