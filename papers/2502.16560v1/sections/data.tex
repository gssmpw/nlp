% TODO
% more detailed introduction of dataset creation
% the rumour label in such datasets
\section{Data} \label{sec:data}
We use three rumour datasets in this work, namely: PHEME~\citep{pheme2015,kochkina-etal-2018-one}, Twitter15, and Twitter16~\citep{ma-etal-2017-detect}:

% TJB: how can the number of threads be greater than the number of tweets? these numbers don't make sense
% RX: fixed, the numbers were incorrect
\paragraph{PHEME}~\citet{pheme2015} contains 6,425 tweet posts of rumours and non-rumours related to 9 events. To avoid using specific a priori keywords to search for tweet posts, PHEME used the Twitter (now X) steaming API to identify newsworthy events from breaking news and then selected from candidate rumours that met rumour criteria, finally they collected associated conversations and annotate them. They engaged journalists to annotate the threads. The data were collected between 2014 and 2015. The 9 events are split into two groups, the first being breaking news that contains rumours, including Ferguson unrest, Ottawa shooting, Sydney siege, Charlie Hebdo shooting, and Germanwings plane crash. The rest are specific rumours, namely Prince to play in Toronto, Gurlitt collection, Putin missing, and Michael Essien contracting Ebola.
% TJB: say something about the time period when this data was collected
% RX: added

\paragraph{Twitter 15}~\citet{twitter15} was constructed by collecting rumour and non-rumour posts from the tracking websites snopes.com and emergent.info. They then used the Twitter API to gather corresponding posts, resulting in 94 true and 446 false posts. This dataset further includes 1,490 root posts and their follow posts, comprising 1,116 rumours and 374 non-rumours.
% TJB: the "tweet" vs. "comment" terminology is potentially confusing and needs to be clarified
% RX: unified, used root and follow posts to refer to root posts and the comment posts, posts are used to describe tweets in general.

\paragraph{Twitter 16}
Similarly to Twitter 15, \citet{twitter16} collected rumours and non-rumours from snopes.com, resulting in 778 reported events, 64\% of which are rumours. For each event, keywords were extracted from the final part of the Snopes URL and refined manually---adding, deleting, or replacing words iteratively---until the composed queries yielded precise Twitter search results. The final dataset includes 1,490 root tweet posts and their follow posts, comprising 613 rumours and 205 non-rumours.

\begin{table*}[!t]
    \centering
    \small
    \begin{tabular}{p{0.05\linewidth}p{0.9\linewidth}}
    \toprule
    Task & Prompt \\
    \midrule
    V-oc & Categorize the text into an ordinal class that best characterizes the writer's mental state, considering various degrees of positive and negative sentiment intensity. 3: very positive mental state can be inferred. 2: moderately positive mental state can be inferred. 1: slightly positive mental state can be inferred. 0: neutral or mixed mental state can be inferred. -1: slightly negative mental state can be inferred. -2: moderately negative mental state can be inferred. -3: very negative mental state can be inferred.\\
    \midrule
    E-c & Categorize the text's emotional tone as either `neutral or no emotion' or identify the presence of one or more of the given emotions (anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust).\\
    \midrule
    E-i & Assign a numerical value between 0 (least E) and 1 (most E) to represent the intensity of emotion E expressed in the text.\\
    \bottomrule
    \end{tabular}
    \caption{Prompts used for EmoLLM to detect emotion information in tweets. V-oc = Valence Ordinal Classification, E-c = Emotion Classification, and E-i = Emotion Intensity Regression.}
    \label{tab:emollm_ins}
\end{table*}


  
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main_anonymous"
%%% End:
