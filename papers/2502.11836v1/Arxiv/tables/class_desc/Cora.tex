\begin{table}[t]
\scriptsize
\begin{tabular}{|p{1.2cm}|p{15cm}|}
\toprule
Class & \multicolumn{1}{c}{Description} \\ \midrule
\begin{tabular}[c]{@{}c@{}}Case \\ Based\end{tabular} & Case-based research solves problems by retrieving and adapting past cases, emphasizing analogy-based reasoning. It integrates memory structures for incremental learning and leverages domain-specific knowledge for interpretability and adaptability, excelling in fields like medical diagnosis and legal reasoning. \\ \midrule
\begin{tabular}[c]{@{}c@{}}Genetic \\ Algorithms\end{tabular} & Genetic Algorithms (GA), inspired by evolutionary biology, use selection, crossover, and mutation to iteratively optimize solutions. Their stochastic, population-based search excels in large or rugged spaces.\\ \midrule
\begin{tabular}[c]{@{}c@{}}Neural \\ Networks\end{tabular} & Neural Networks (NNs) are models to learn representation from data. Paper of  deep neural networks explores tasks on large-scale datasets. Novel architectures, combining multiple convolutional layers, pooling operations, and fully connected layers, are proposed to efficiently extract hierarchical features. Additionally, techniques such as dropout regularization and data augmentation are integrated to enhance generalization. \\ \midrule
\begin{tabular}[c]{@{}c@{}}Probabilistic \\ Methods\end{tabular} & Probabilistic methods model uncertainty and reason under incomplete information using Bayes' theorem. Key components include prior distributions, likelihood functions, and posterior distributions, enabling systems to adapt as new data. Advanced techniques such as Markov Chain Monte Carlo (MCMC), variational inference, and Bayesian optimization can approximate complex posterior distributions. Gaussian processes, Bayesian networks, and hierarchical models excel in tasks requiring uncertainty quantification, small-data generalization, and interpretable probabilistic predictions. Applications include model calibration, decision-making under ambiguity, and domains such as medical diagnosis, sensor fusion, and automated experimentation. \\ \midrule
\begin{tabular}[c]{@{}c@{}}Reinforcement \\ Learning\end{tabular} & Reinforcement Learning (RL) trains agents to optimize decisions by maximizing cumulative rewards in a Markov Decision Process (MDP). Key concepts include value functions, Q-learning, policy gradients, and the exploration-exploitation trade-off. Algorithms like DQN, Actor-Critic, and PPO solve high-dimensional decision problems. RL tackles challenges such as reward sparsity, credit assignment, and uncertainty, with applications in game playing, robotics, resource allocation, and autonomous systems. \\ \midrule
\begin{tabular}[c]{@{}c@{}}Rule \\ Learning\end{tabular} & Rule Learning involves discovering interpretable if-then rules from data to represent patterns or decision processes. Its uniqueness is its ability to produce human-readable and explainable models. Algorithms such as RIPPER and CN2 emphasize learning concise and accurate rule sets. \\ \midrule
Theory & Machine learning theory establishes the mathematical foundations and guarantees of learning algorithms, ensuring reliability, efficiency, and generalization. Key areas include statistical learning theory (model generalization) and computational learning theory (learning feasibility). Core concepts include VC dimension, PAC learning, generalization bounds, and convergence guarantees. Research analyzes overfitting, underfitting, bias-variance trade-offs, and sample complexity. \\ \bottomrule
\end{tabular}
\vspace{-0.3cm}
\caption{Class descriptions for Cora~\cite{mccallum2000automating}.}
\label{tab:class_description_cora}
\end{table}