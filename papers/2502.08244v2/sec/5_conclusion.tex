



\begin{figure}[!t]
\centering
\includegraphics[width=0.9\linewidth]{fig/application_video_editing_small.pdf}
\vspace{-3mm}
\caption{
Temporally-consistent video editing.
}
\label{fig:video_editing}
\vspace{-1mm}
\end{figure}



\section{Conclusion}
\label{sec:conclusion}
This paper proposed \MethodName{}, a novel optical-flow-based video diffusion model for camera-controllable video generation.
Since existing methods require a training dataset with ground-truth camera parameters, they are mainly trained on restricted datasets that primarily consist of static scenes, leading to video synthesis with unnatural object motion.
Unlike previous methods, our method leverages optical flow maps to represent both camera and object motions, enabling the use of arbitrary training videos without ground-truth camera parameters.
Moreover, our method facilitates detailed camera control by leveraging background motions of optical flow, which encodes 3D correlation across different viewpoints.
Our extensive experiments demonstrate that \MethodName{} provides realistic video synthesis with natural object motion and accurate camera control.


\vspace{-4mm}
\paragraph{Limitations.}
Our method is not free from limitations.
Errors from both the object motion synthesis model and the semantic segmentation model may result in unnatural object motion in the synthesized videos.
The estimation error of the segmentation model can be alleviated through user interaction by providing point prompts for object regions.
Our future work will involve a seamless integration of camera and object motions to synthesize more natural videos.

\vspace{-3.5mm}
\paragraph{Acknowledgment.}
This work was supported by the Korea government (MSIT), through the IITP grant (Global Research Support Program in the Digital Field program, RS-2024-00436680; Development of VFX creation and combination using generative AI, RS-2024-00395401; Artificial Intelligence Graduate School Program (POSTECH), RS-2019-II191906) and NRF grant (RS-2023-00211658; RS-2024-00438532), and Microsoft Research Asia.


\vspace{-3.5mm}
\paragraph{Ethical considerations.}
FloVD is purely a research project. Currently, we have no plans to incorporate FloVD into a product or expand access to the public. We will also put Microsoft AI principles into practice when further developing the models. In our research paper, we account for the ethical concerns associated with video generation research. To mitigate issues associated with training data, we have implemented a rigorous filtering process to purge our training data of inappropriate content, such as explicit imagery and offensive language, to minimize the likelihood of generating inappropriate content. 

