\section{The \EngineName{} Engine}
\label{sec:engine}

\EngineName{} %employs a pipeline architecture, meaning that it 
consists of a number of components, each of which performs a specific task. Information is propagated from one component to the next. This pipeline is split in four distinct conceptual steps.

% \begin{itemize}
%     \item WHERE clause generation
%     \item SELECT/ASK clause generation
%     \item Query generation
%     \item Query rewriting
% \end{itemize}

First, the WHERE clause is generated by combining basic SPARQL/GeoSPARQL building blocks. This is subsequently passed as additional input to the components responsible for the generation of the SELECT/ASK clause. When both clauses have been constructed, the query generator merges them and makes any necessary additions to construct a complete SPARQL query. In the last step, the query is rewritten to make use of materialized geospatial relations.

The complete architecture of \EngineName{} is shown in Figure~\ref{fig:system_arch}. Below, we present the functionality of the system in detail. As our running example we use the request ``Show me all images taken in January 2021 with rivers less than 2km away from towns and forests in the Emilia Romagna region, having cloud coverage less than 10\%''.

\begin{figure*}[h]
\begin{center}
\includegraphics[width=15cm]{earthqa_paper.drawio.png}
\end{center}
\caption{The conceptual architecture of the \EngineName{} system}
\label{fig:system_arch}
\end{figure*} 

\textbf{Dependency Parse Tree Generator.} This module generates a dependency parse tree of the input question using StanfordCoreNLP~\cite{corenlp}. The dependency parse tree is used to identify and store information.

\textbf{Instance Identifier.} This module does named-entity recognition and disambiguation.
%identifies and maps named entities present in the input question to the appropriate resources of the KG. 
In the example question, it identifies the entity “Emilia Romagna” and maps it to the resource \textit{yago:Emilia\_(region\_of\_Italy)} in the KG. The mapping to the KG resource happens in two steps. First, WAT~\cite{WAT} links the named entity to a Wikipedia page. Subsequently, the component searches the Knowledge Graph for the resource that best matches the entity returned by WAT.
In addition to identifying the instance, this component is responsible for creating the block that will be used in the WHERE clause for the identified instance. The generated block is the following:

\begin{lstlisting}[language=SPARQL]
<URI> geo:hasGeometry/geo:asWKT ?iWKTID .
\end{lstlisting}

% We use TagMeDisambiguate based on an evaluation of named-entity recognition and disambiguation models on the geospatial question-answering dataset GeoQuestions201 [PIS+20]. Since then, a few promising systems have been developed but no system has proven to be significantly better for the task of geospatial question-answering, which is most relevant to this project.

\textbf{Concept Identifier.} This module identifies and maps concepts present in the input question to the appropriate resource of the KG ontology. For instance, from the example question, it will identify and map the concepts \textit{River, Town, Forest}. The mapping is done using a class label dictionary and string similarity based on n-grams.
Additionally, this component is responsible for creating the block that will be used in the WHERE clause for the identified concepts:

\begin{lstlisting}[language=SPARQL]
?cID a <URI> ; 
    geo:hasGeometry/geo:asWKT ?cWKTID .
\end{lstlisting}

At the end of the concept identification stage, and after all Instances have been identified, we employ a heuristic of consolidation between concepts and instances. Concepts and Instances that are not separated by any token are consolidated to reduce the complexity of the generated WHERE-clause and help the query generator produce a correct query. For example, in the question “Where is the Tagus river located?” only the Instance of Tagus is kept and the river concept is consolidated into it.

\textbf{Property Identifier.} The property identifier identifies attributes of features or types of features specified by the user in input questions and maps them to the corresponding properties in the knowledge graph. In the example question, the property ``cloud coverage'' of the type of feature image will be identified and mapped to the corresponding property in the KG.
% In the previous engines of \EngineName{}’s family, only one property per question was supported. For \EngineName{}, we wanted to overcome this limitation to be able to answer a wider array of questions.
For each identified concept, we try to match, using string similarity on n-grams, its properties to the words in the sentence. Matched properties are identified as candidate properties for this concept. Multiple concepts might have the same candidate property. To resolve this conflict, we introduced a heuristic that selects the closest concepts as the targets to the properties. This process is similar for instances inside the question.

Again, this component is also responsible for generating the block that will be used in the WHERE clause for the identified properties:

\begin{lstlisting}[language=SPARQL]
INSTANCE/CONCEPT_VARIABLE <URI> ?pID.
\end{lstlisting}

In addition, this component uses the dependency parse tree and Part-of-Speech tags to identify words that denote the use of comparatives and superlatives. These are subsequently matched to the appropriate Concept or Property, using a node-distance heuristic on the dependency parse tree.

\textbf{Spatial relation Identifier.} This module identifies spatial relations present in the input question and maps them to appropriate stSPARQL/GeoSPARQL functions. For instance, in the example question, it will identify the spatial relations ``in'' and ``away from'' and map them to \textit{geof:sfWithin} and \textit{geof:distance} respectively. Then these relations are mapped to the appropriate previously identified Instances and Concepts by using the following heuristic: 

\[
\text{distance} = \text{dependency\_parse\_tree\_distance} + \left(\frac{\text{word\_distance}}{100}\right)
\]

Again, this component is also responsible for generating the block that will be used in the WHERE clause:

\begin{lstlisting}[language=SPARQL]
FILTER (<URI> (FIRST_FEATURE, 
    SECOND_FEATURE))
\end{lstlisting}
and
\begin{lstlisting}[language=SPARQL]
FILTER (geof:distance (FIRST_FEATURE, 
    SECOND_FEATURE, uom:metre) 
    {<, >, <=, >=, =, ~} DISTANCE)
\end{lstlisting}

\textbf{Numeric Solver.} This module is responsible for identifying numbers, understanding their use in the input question and enhancing the previously identified elements with additional information. For this purpose we utilize Part-of-Speech tags and the previously described distance heuristic.
% For identifying numbers, the CD (cardinal number) Part-of-Speech tag produced by CoreNLP is used. Subsequently we use the NER components of CoreNLP to gather additional information about the number (whether it refers to an equality, an inequality or an approximation). We take special care to not include in our actions numbers that are related dates and/or durations.

% After the number and its context are identified we once again employ our distance heuristic to locate the most relevant to the number Concept/Property/Spatial-Relation, which is afterwards enhanced with information about the number and its context.
In our working example, ``less than 2km'' is matched to the spatial function of distance and ``less than 10\%'' is matched to the cloud coverage property.

\textbf{Conjunction Solver.} The Conjunction Solver is responsible for handling conjunctions, as those are identified by the dependency parse tree. To that end, it selects all edges of the parse tree tagged as ``conj:and''. The vertices connected by each of those edges are checked for meaningful conjunctions. Number-to-Property, Number-to-Number and Geospatial-to-Geospatial conjunctions are supported.
For Geospatial-to-Geospatial conjunctions additional spatial relations are generated and stored, as if they were created by the Geospatial Relation Identifier, according to the information provided by the vertices. In our example, this is the case with ``towns and forests''. Number and Property conjunctions faction similarly.

\textbf{Temporal Identifier.} This module uses HeidelTime~\cite{heideltime} to identify temporal keywords in the input question and annotates them with the appropriate date and/or duration. For instance, in the example input question it will identify ``January 2021'' and map it to 2021-01. 

% To that end, the temporal tagger HeidelTime~\cite{heideltime} is used. In addition, durations are identified and can potentially be combined with dates. For example, in the question “Give me images in a span of 3 days in 2023”, the Temporal identifier will combine the timespan of 3 days with the timestamp of 2023 to produce a date-duration object which will be used for query generation.

\textbf{Return Type Identifier.} This module is responsible for identifying the expected form/type of the answer to the question. The supported types are \textit{ Name, Coordinates, Number-Property, Number-Count, Image }. For our example, \textit{Image} is the most appropriate return type.
For identifying the expected return types, this component leverages the sophisticated language understanding of Llama 2~\cite{llama2}. We fine-tune our model to output correctly formatted answers. A fallback mechanism that uses heuristics is provided to enable using \EngineName{} without hardware acceleration (GPU).
% It's worth noting that we refrained from using Llama 2 to determine whether the generated query should be a SELECT or an ASK query. This decision was made because this task can be readily identified through lexical analysis, which offers both speed and effectiveness comparable to the results achieved by Llama 2.

\textbf{Query Form Identifier.} This component is responsible for generating the final ASK/SELECT clause, which will be used by the query generator. It takes as input the return types generated by the return type identifier. For each expected return type, we follow an iterative approach as follows: If the type is \textit{Name}, we search for the next concept. If the type is \textit{Coordinates}, we seek the next concept or instance. When the return type is \textit{Number-Property}, we look for the next property, and if it's \textit{Number-Count}, we search for the next concept. Additionally, we enhance the query by introducing a COUNT aggregation and the necessary GROUP BY clauses. In the case of \textit{Image}, we insert the appropriate code in the query. To determine the 'next' object, we traverse the dependency parse tree.
% To determine the 'next' object, we traverse the dependency parse tree. The traversal begins from the Wh-word of the sentence. Wh-words are those that are tagged as { WP, WFT, WRB } by the CoreNLP part of speech tagger. After locating Wh-words, we identify the objects that are closest based on the dependency parse tree distance. 
% Again, we provide a fallback implementation, for running the engine without hardware acceleration.

\textbf{Query Generator.} The query generator is responsible for generating the final query. Within this stage of the pipeline, it assimilates all the information provided by the preceding components and combines them into a suitable, executable SPARQL or GeoSPARQL query. Information about superlatives, limits and other structures is taken into account in the generation process.

\textbf{Query Enhancer.} The query enhancer is an optional component responsible for modifying the query produced by the Query Generator to fix any mistakes and/or oversights. It is implemented using the Mistral-7b LLM fine-tuned on the dataset GeoQuestions1089~\cite{geoquestions1089}. It serves as a performance-enhancement module that increases the capacity of \EngineName{} to answer complex questions following the Execution Refinement paradigm~\cite{neural-interfaces}.

\textbf{GoST.} The GoST transpiler~\cite{geoquestions1089} takes the query generated by the Query Generator and rewrites it to use materialized geospatial relations if that is possible. Because geospatial relations like \textit{geof:sfWithin} are computationally expensive we do offline materialization using the tool JedAI-Spatial~\cite{jedai-spatial}.