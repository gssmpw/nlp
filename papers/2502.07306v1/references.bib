@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{gm-gw,
 ISSN = {00426636},
 URL = {http://www.jstor.org/stable/4249070},
 author = {Peter R. Henriques},
 journal = {The Virginia Magazine of History and Biography},
 number = {2},
 pages = {185--204},
 publisher = {Virginia Historical Society},
 title = {An Uneven Friendship: The Relationship between {George Washington} and {George Mason}},
 urldate = {2023-04-27},
 volume = {97},
 year = {1989}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRO %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{radford2018gpt1,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{achiam2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

##################################################################
##################################################################
# EMQA
##################################################################
##################################################################

@misc{ram2021fewshot,
      title={{F}ew-{S}hot {Q}uestion {A}nswering by {P}retraining {S}pan {S}election}, 
      author={Ori Ram and Yuval Kirstain and Jonathan Berant and Amir Globerson and Omer Levy},
      year={2021},
      eprint={2101.00438},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{Github:NLP-Assignment-3,
  author = {Github:NLP-Assignment-3},
  title = {Github:Assignment-3:TyDi QA Baseline Results Re-production},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/NavidRajabi/CS695-Project/tree/main/Assignment-3}},
  
}


@misc{conneau2020unsupervised,
      title={Unsupervised Cross-lingual Representation Learning at Scale}, 
      author={Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzmán and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov},
      year={2020},
      eprint={1911.02116},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lample2019crosslingual,
      title={Cross-lingual Language Model Pretraining}, 
      author={Guillaume Lample and Alexis Conneau},
      year={2019},
      eprint={1901.07291},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Wolf2019HuggingFacesTS,
    title = "{T}ransformers: {S}tate-of-the-{A}rt {N}atural {L}anguage {P}rocessing",
    author={Wolf, Thomas and Chaumond, Julien and Debut, Lysandre and Sanh, Victor and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and others},
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45",
}



@inproceedings{devlin2019bert,
    title = "{BERT}: {P}re-training of {D}eep {B}idirectional {T}ransformers for {L}anguage {U}nderstanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Vol 1",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    pages = "4171--4186",
}



@inproceedings{lewis2019mlqa,
    title = "{MLQA}: {E}valuating {C}ross-lingual {E}xtractive {Q}uestion {A}nswering",
    author = "Lewis, Patrick  and
      Oguz, Barlas  and
      Rinott, Ruty  and
      Riedel, Sebastian  and
      Schwenk, Holger",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.653",
    pages = "7315--7330",
}


@inproceedings{artetxe2020crosslingual,
    title = "On the {C}ross-lingual {T}ransferability of {M}onolingual {R}epresentations",
    author = "Artetxe, Mikel  and
      Ruder, Sebastian  and
      Yogatama, Dani",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.421",
    pages = "4623--4637",
}



@misc{conneau2020unsupervised,
      title={Unsupervised Cross-lingual Representation Learning at Scale}, 
      author={Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzmán and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov},
      year={2020},
      eprint={1911.02116},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lample2019crosslingual,
      title={Cross-lingual Language Model Pretraining}, 
      author={Guillaume Lample and Alexis Conneau},
      year={2019},
      eprint={1901.07291},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ wiki:QA,
  author = {{Question answering}},
  title = "Question answering --- {W}ikipedia{,} The Free Encyclopedia",
  url = "https://en.wikipedia.org/wiki/Question_answering#:~:text=Question",
  note = "[Online; accessed 29-September-2020]"}


@misc{huggingface:mBERT,
  author = {{Hugging Face - mBERT}},
  title = "{H}ugging {F}ace -bert-base-multilingual-cased",
  url = "https://huggingface.co/bert-base-multilingual-cased",
  note = "[Online; accessed 01-Novemberr-2020]",
  year = "2020"
}


@misc{huggingface:distilbert,
  author = {{Huggingface - distilbert}},
  title = "huggingface -distilbertd",
  url = "https://huggingface.co/transformers/model_doc/distilbert.html",
  note = "[Online; accessed 01-November-2020]"}


@misc{huggingface:xlmroberta,
  author = {{Huggingface - xlmroberta}},
  title = "huggingface -xlmroberta",
  url = "https://huggingface.co/transformers/model_doc/xlmroberta.html",
  note = "[Online; accessed 01-November-2020]"}

@misc{huggingface:xlm-roberta-large,
  author = {{Huggingface - xlm-roberta-large}},
  title = "huggingface -xlm-roberta-large",
  url = "https://huggingface.co/xlm-roberta-large",
  note = "[Online; accessed 01-November-2020]"}


@misc{huggingface:xlm,
  author = {{Huggingface - xlm}},
  title = "huggingface -xlm",
  url = "https://huggingface.co/transformers/model_doc/xlm.html",
  note = "[Online; accessed 01-November-2020]"}

@misc{huggingface:run_squad,
  author = {{Huggingface - run_squad}},
  title = "huggingface -run_squad",
  url = "https://github.com/huggingface/transformers/blob/master/examples/question-answering/run_squad.py",
  note = "[Online; accessed 21-October-2020]"}
  


@article{CALIJORNESOARES2020635,
title = "A literature review on question answering techniques, paradigms and systems",
journal = "Journal of King Saud University - Computer and Information Sciences",
volume = "32",
number = "6",
pages = "635 - 646",
year = "2020",
issn = "1319-1578",
doi = "https://doi.org/10.1016/j.jksuci.2018.08.005",
url = "http://www.sciencedirect.com/science/article/pii/S131915781830082X",
author = "Marco Antonio {Calijorne Soares} and Fernando Silva Parreiras"
}



@article{clark2020tydi,
     title={{T}y{D}i {QA}: {A} {B}enchmark for {I}nformation-{S}eeking {Q}uestion {A}nswering in {T}ypologically {D}iverse {L}anguages},
    author = "Clark, Jonathan H.  and
      Choi, Eunsol  and
      Collins, Michael  and
      Garrette, Dan  and
      Kwiatkowski, Tom  and
      Nikolaev, Vitaly  and
      Palomaki, Jennimaria",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.tacl-1.30",
    pages = "454--470",
}



@article{DBLP:journals/corr/JoshiCWZ17,
  author    = {Mandar Joshi and
               Eunsol Choi and
               Daniel S. Weld and
               Luke Zettlemoyer},
  title     = {TriviaQA: {A} Large Scale Distantly Supervised Challenge Dataset for
               Reading Comprehension},
  journal   = {CoRR},
  volume    = {abs/1705.03551},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.03551},
  archivePrefix = {arXiv},
  eprint    = {1705.03551},
  timestamp = {Mon, 13 Aug 2018 16:46:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JoshiCWZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Park2017QuestionAO,
  title={Question Answering on the SQuAD Dataset},
  author={Do-Hyoung Park},
  year={2017}
}
@article{DBLP:journals/corr/abs-1806-03822,
  author    = {Pranav Rajpurkar and
               Robin Jia and
               Percy Liang},
  title     = {Know What You Don't Know: Unanswerable Questions for SQuAD},
  journal   = {CoRR},
  volume    = {abs/1806.03822},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.03822},
  archivePrefix = {arXiv},
  eprint    = {1806.03822},
  timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-03822.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/RajpurkarZLL16,
  author    = {Pranav Rajpurkar and
               Jian Zhang and
               Konstantin Lopyrev and
               Percy Liang},
  title     = {SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  journal   = {CoRR},
  volume    = {abs/1606.05250},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.05250},
  archivePrefix = {arXiv},
  eprint    = {1606.05250},
  timestamp = {Mon, 24 Aug 2020 14:01:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RajpurkarZLL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/abs-1904-09077,
  author    = {Shijie Wu and
               Mark Dredze},
  title     = {Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of
               {BERT}},
  journal   = {CoRR},
  volume    = {abs/1904.09077},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.09077},
  archivePrefix = {arXiv},
  eprint    = {1904.09077},
  timestamp = {Fri, 26 Apr 2019 13:18:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-09077.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{wu2020languages,
      title={Are All Languages Created Equal in Multilingual BERT?}, 
      author={Shijie Wu and Mark Dredze},
      year={2020},
      eprint={2005.09093},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{DBLP:journals/corr/abs-1809-05053,
  author    = {Alexis Conneau and
               Guillaume Lample and
               Ruty Rinott and
               Adina Williams and
               Samuel R. Bowman and
               Holger Schwenk and
               Veselin Stoyanov},
  title     = {{XNLI:} Evaluating Cross-lingual Sentence Representations},
  journal   = {CoRR},
  volume    = {abs/1809.05053},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.05053},
  archivePrefix = {arXiv},
  eprint    = {1809.05053},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1809-05053.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}
@article{artetxe2019cross,
  title={On the cross-lingual transferability of monolingual representations},
  author={Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani},
  journal={arXiv preprint arXiv:1910.11856},
  year={2019}
}
@article{wang2016machine,
  title={Machine comprehension using match-lstm and answer pointer},
  author={Wang, Shuohang and Jiang, Jing},
  journal={arXiv preprint arXiv:1608.07905},
  year={2016}
}
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}
@inproceedings{liu2019xqa,
  title={XQA: A cross-lingual open-domain question answering dataset},
  author={Liu, Jiahua and Lin, Yankai and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2358--2368},
  year={2019}
}


@inproceedings{conneau2019unsupervised,
    title = "{U}nsupervised {C}ross-lingual {R}epresentation {L}earning at {S}cale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.747",
    pages = "8440--8451",
}



@article{kwiatkowski2019natural,
    title = "{N}atural {Q}uestions: {A} {B}enchmark for {Q}uestion {A}nswering {R}esearch",
    author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    url = "https://www.aclweb.org/anthology/Q19-1026",
}



@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019}
}



@inproceedings{rajpurkar2016squad,
    title = "{SQ}u{AD}: 100,000+ {Q}uestions for {M}achine {C}omprehension of {T}ext",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    year = "2016",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1264",
    pages = "2383--2392",
}

@article{trischler2016newsqa,
  title={Newsqa: A machine comprehension dataset},
  author={Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},
  journal={arXiv preprint arXiv:1611.09830},
  year={2016}
}


@inproceedings{yang2015wikiqa,
    title = "{W}iki{QA}: {A} {C}hallenge {D}ataset for {O}pen-{D}omain {Q}uestion {A}nswering",
    author={Yang, Yi and Yih, Wen-tau and Meek, Christopher},
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    year = "2015",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1237",
    pages = "2013--2018",
}

@inproceedings{nguyen2016ms,
  title={{MS MARCO}: {A} human generated machine reading comprehension dataset},
  author={Nguyen, Tri and Rosenberg, Mir and Song, Xia and Gao, Jianfeng and Tiwary, Saurabh and Majumder, Rangan and Deng, Li},
  booktitle={CoCo@ NIPS},
  year={2016}
}



@inproceedings{choi2018quac,
    title = "{Q}u{AC}: {Q}uestion {A}nswering in {C}ontext",
    author = "Choi, Eunsol  and
      He, He  and
      Iyyer, Mohit  and
      Yatskar, Mark  and
      Yih, Wen-tau  and
      Choi, Yejin  and
      Liang, Percy  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1241",
    pages = "2174--2184"
}

@article{reddy2019coqa,
  title = "{C}o{QA}: {A} {C}onversational {Q}uestion {A}nswering {C}hallenge",
  author={Reddy, Siva and Chen, Danqi and Manning, Christopher D},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={249--266},
  year={2019},
  url = "https://www.aclweb.org/anthology/Q19-1016",
  publisher={MIT Press}
}




@inproceedings{joshi2020state,
  title={The {S}tate and {F}ate of {L}inguistic {D}iversity and {I}nclusion in the {NLP} {W}orld},
    author = "Joshi, Pratik  and
      Santy, Sebastin  and
      Budhiraja, Amar  and
      Bali, Kalika  and
      Choudhury, Monojit",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.560",
    pages = "6282--6293",
}




@inproceedings{ponti2020xcopa,
    title = "{XCOPA}: {A M}ultilingual {D}ataset for {C}ausal {C}ommonsense {R}easoning",
    author = "Ponti, Edoardo Maria  and
      Glava{\v{s}}, Goran  and
      Majewska, Olga  and
      Liu, Qianchu  and
      Vuli{\'c}, Ivan  and
      Korhonen, Anna",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.185",
    pages = "2362--2376",

}

@inproceedings{nordhoff2012glottolog,
    title = "Glottolog/{L}angdoc:{I}ncreasing the visibility of grey literature for low-density languages",
    author = {Nordhoff, Sebastian  and
      Hammarstr{\"o}m, Harald},
    booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)",
    year = "2012",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2012/pdf/733_Paper.pdf",
    pages = "3289--3294",
}
@misc{alberti2019bert,
  title={A {BERT} baseline for the natural questions},
  author={Alberti, Chris and Lee, Kenton and Collins, Michael},
  note={{arXiv}:1901.08634},
  year={2019}
}


@inproceedings{clark2018simple,
    title = "{S}imple and {E}ffective {M}ulti-{P}aragraph {R}eading {C}omprehension",
    author = "Clark, Christopher  and
      Gardner, Matt",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1078",
    pages = "845--855"
}



@inproceedings{parikh2016decomposable,
    title = "A {D}ecomposable {A}ttention {M}odel for {N}atural {L}anguage {I}nference",
    author = {Parikh, Ankur  and
      T{\"a}ckstr{\"o}m, Oscar  and
      Das, Dipanjan  and
      Uszkoreit, Jakob},
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    year = "2016",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1244",
    pages = "2249--2255",
}

@inproceedings{shah2010synergy,
  title={SYNERGY: a named entity recognition system for resource-scarce languages such as Swahili using online machine translation},
  author={Shah, Rushin and Lin, Bo and Gershman, Anatole and Frederking, Robert},
  booktitle={Proceedings of the Second Workshop on African Language Technology (AfLaT 2010)},
  pages={21--26},
  year={2010}
}


@inproceedings{yarowsky2001inducing,
    title = "Inducing Multilingual Text Analysis Tools via Robust Projection across Aligned Corpora",
    author = "Yarowsky, David  and
      Ngai, Grace  and
      Wicentowski, Richard",
    booktitle = "{P}roceedings of the {F}irst {I}nternational {C}onference on {H}uman {L}anguage {T}echnology {R}esearch",
    year = "2001",
    url = "https://www.aclweb.org/anthology/H01-1035",
}
@misc{xue2020mt5,
  title={m{T5}: {A} massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  note={{arXiv}:2010.11934},
  year={2020}
}

@misc{faisal-etal-21-sdqa,
 title = {{SD-QA}: {S}poken {D}ialectal {Q}uestion {A}nswering for the {R}eal {W}orld},
  author = {Faisal, Fahim and Keshava, Sharlina and ibn Alam, Md Mahfuz and Anastasopoulos, Antonios},
  url={https://cs.gmu.edu/~antonis/publication/faisal-etal-21-sdqa/SD-QA.pdf},
  year = {2021},
  note = {preprint}
}

@article{eberhard22simons,
  title={Ethnologue: Languages of the world. 2019},
  author={Eberhard, David M and Simons, Gary F and Fennig, Charles D. (eds.)},
  journal={online. Dallas, Texas: SIL International.},
  year = 2019,
  url = {http://www.ethnologue.com/}
}


@inproceedings{debnath-etal-21-towards,
    title = "Towards More Equitable Question Answering Systems: How Much More Data Do you Need?",
    author={Debnath, Arnab and Rajabi, Navid and Alam, Fardina Fathmiul and Anastasopoulos, Antonios},
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP) ",
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "",
    pages = "",
}

@article{hammarstrom2015ethnologue,
  title={" Ethnologue" 16/17/18th editions: A comprehensive review},
  author={Hammarstr{\"o}m, Harald},
  journal={Language},
  pages={723--737},
  year={2015},
  publisher={JSTOR}
}

@inproceedings{xia-etal-2020-predicting,
 abstract = {Given the complexity of combinations of tasks, languages, and domains in natural language processing (NLP) research, it is computationally prohibitive to exhaustively test newly proposed models on each possible experimental setting. In this work, we attempt to explore the possibility of gaining plausible judgments of how well an NLP model can perform under an experimental setting, \textitwithout actually training or testing the model. To do so, we build regression models to predict the evaluation score of an NLP experiment given the experimental settings as input. Experimenting on~9 different NLP tasks, we find that our predictors can produce meaningful predictions over unseen languages and different modeling architectures, outperforming reasonable baselines as well as human experts. %we represent experimental settings using an array of features. Going further, we outline how our predictor can be used to find a small subset of representative experiments that should be run in order to obtain plausible predictions for all other experimental settings.},
 address = {Online},
 author = {Xia, Mengzhou  and
Anastasopoulos, Antonios  and
Xu, Ruochen  and
Yang, Yiming  and
Neubig, Graham},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
 doi = {10.18653/v1/2020.acl-main.764},
 month = {July},
 pages = {8625--8646},
 publisher = {Association for Computational Linguistics},
 title = {Predicting Performance for Natural Language Processing Tasks},
 url = {https://www.aclweb.org/anthology/2020.acl-main.764},
 year = {2020}
}

@inproceedings{wang-etal-2020-negative,
    title = "On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment",
    author = "Wang, Zirui  and
      Lipton, Zachary C.  and
      Tsvetkov, Yulia",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.359",
    doi = "10.18653/v1/2020.emnlp-main.359",
    pages = "4438--4450",
    abstract = "Modern multilingual models are trained on concatenated text from multiple languages in hopes of conferring benefits to each (positive transfer), with the most pronounced benefits accruing to low-resource languages. However, recent work has shown that this approach can degrade performance on high-resource languages, a phenomenon known as negative interference. In this paper, we present the first systematic study of negative interference. We show that, contrary to previous belief, negative interference also impacts low-resource languages. While parameters are maximally shared to learn language-universal structures, we demonstrate that language-specific parameters do exist in multilingual models and they are a potential cause of negative interference. Motivated by these observations, we also present a meta-learning algorithm that obtains better cross-lingual transferability and alleviates negative interference, by adding language-specific layers as meta-parameters and training them in a manner that explicitly improves shared layers{'} generalization on all languages. Overall, our results show that negative interference is more common than previously known, suggesting new directions for improving multilingual representations.",
}

@inproceedings{muller-etal-2021-unseen,
    title = "When Being Unseen from m{BERT} is just the Beginning: Handling New Languages With Multilingual Language Models",
    author = "Muller, Benjamin  and
      Anastasopoulos, Antonios  and
      Sagot, Beno{\^\i}t  and
      Seddah, Djam{\'e}",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2021.naacl-main.38",
    pages = "448--462",
    abstract = "Transfer learning based on pretraining language models on a large amount of raw data has become a new norm to reach state-of-the-art performance in NLP. Still, it remains unclear how this approach should be applied for unseen languages that are not covered by any available large-scale multilingual language model and for which only a small amount of raw data is generally available. In this work, by comparing multilingual and monolingual models, we show that such models behave in multiple ways on unseen languages. Some languages greatly benefit from transfer learning and behave similarly to closely related high resource languages whereas others apparently do not. Focusing on the latter, we show that this failure to transfer is largely related to the impact of the script used to write such languages. We show that transliterating those languages significantly improves the potential of large-scale multilingual language models on downstream tasks. This result provides a promising direction towards making these massively multilingual models useful for a new set of unseen languages.",
}


##################################################################
##################################################################
# QLoRA
##################################################################
##################################################################

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

%%%%%%%%%%%%%%Doc%%%%%%%%%%%%%%%%%%%%%
@inproceedings{tan2019hierarchical,
  title={Hierarchical modeling of global context for document-level neural machine translation},
  author={Tan, Xin and Zhang, Longyin and Xiong, Deyi and Zhou, Guodong},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={1576--1585},
  year={2019}
}

@inproceedings{xu2021efficient,
  title={Efficient context-aware neural machine translation with layer-wise weighting and input-aware gating},
  author={Xu, Hongfei and Xiong, Deyi and Van Genabith, Josef and Liu, Qiuhui},
  booktitle={Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence},
  pages={3933--3940},
  year={2021}
}

@article{tu2018learning,
  title={Learning to remember translation history with a continuous cache},
  author={Tu, Zhaopeng and Liu, Yang and Shi, Shuming and Zhang, Tong},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={407--420},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
%%%%%%%%%%%%%%Intro%%%%%%%%%%%%%%%%%%%%%%%
@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

%prompting
@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

%prompting
@inproceedings{sanh2022multitask,
  title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Le Scao, Teven and Raja, Arun and others},
  booktitle={ICLR 2022-Tenth International Conference on Learning Representations},
  year={2022}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others}
}

%%%%%%%%%%%%%%%%%%LLMs%%%%%%%%%%%%%%%%%%%%%%
@software{gpt-neo,
  author       = {Black, Sid and
                  Gao, Leo and
                  Wang, Phil and
                  Leahy, Connor and
                  Biderman, Stella},
  title        = {{GPT-Neo: Large Scale Autoregressive Language 
                   Modeling with Mesh-Tensorflow}},
  month        = mar,
  year         = 2021,
  note         = {{If you use this software, please cite it using 
                   these metadata.}},
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.5297715},
  url          = {https://doi.org/10.5281/zenodo.5297715}
}
%Pile
@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}
%gpt2
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

%opt
@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

%llama2
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

%xglm
@article{lin2021few,
  title={Few-shot learning with multilingual language models},
  author={Lin, Xi Victoria and Mihaylov, Todor and Artetxe, Mikel and Wang, Tianlu and Chen, Shuohui and Simig, Daniel and Ott, Myle and Goyal, Naman and Bhosale, Shruti and Du, Jingfei and others},
  journal={arXiv preprint arXiv:2112.10668},
  year={2021}
}

%bloomz
@article{muennighoff2022crosslingual,
  title={Crosslingual generalization through multitask finetuning},
  author={Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2211.01786},
  year={2022}
}

% bloom
@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

%gpt3
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

%%%%%%%%%%%%%%%%%%Miscs%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{koehn2017six,
  title={Six Challenges for Neural Machine Translation},
  author={Koehn, Philipp and Knowles, Rebecca},
  booktitle={Proceedings of the First Workshop on Neural Machine Translation},
  pages={28--39},
  year={2017}
}

%ter
@inproceedings{snover2006study,
  title={A study of translation edit rate with targeted human annotation},
  author={Snover, Matthew and Dorr, Bonnie and Schwartz, Richard and Micciulla, Linnea and Makhoul, John},
  booktitle={Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers},
  url={https://aclanthology.org/2006.amta-papers.25.pdf},
  pages={223--231},
  year={2006}
}

%sacreBLEU
@inproceedings{post-2018-call,
    title = "A Call for Clarity in Reporting {BLEU} Scores",
    author = "Post, Matt",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-6319",
    doi = "10.18653/v1/W18-6319",
    pages = "186--191",
    abstract = "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to {``}the{''} BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SACREBLEU, to facilitate this.",
}

%COMET
@inproceedings{rei-etal-2020-comet,
    title = "{COMET}: A Neural Framework for {MT} Evaluation",
    author = "Rei, Ricardo  and
      Stewart, Craig  and
      Farinha, Ana C  and
      Lavie, Alon",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.213",
    doi = "10.18653/v1/2020.emnlp-main.213",
    pages = "2685--2702",
    abstract = "We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metric. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.",
}

% doc mark-up
@inproceedings{junczys2019microsoft,
  title={Microsoft Translator at WMT 2019: Towards Large-Scale Document-Level Neural Machine Translation},
  author={Junczys-Dowmunt, Marcin},
  booktitle={Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},
  pages={225--233},
  year={2019}
}

%flores101
@article{goyal2022flores,
  title={The flores-101 evaluation benchmark for low-resource and multilingual machine translation},
  author={Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and Ju, Da and Krishnan, Sanjana and Ranzato, Marc’Aurelio and Guzm{\'a}n, Francisco and Fan, Angela},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={522--538},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

% europarl
@inproceedings{koehn-2005-europarl,
    title = "{E}uroparl: A Parallel Corpus for Statistical Machine Translation",
    author = "Koehn, Philipp",
    booktitle = "Proceedings of Machine Translation Summit X: Papers",
    month = sep # " 13-15",
    year = "2005",
    address = "Phuket, Thailand",
    url = "https://aclanthology.org/2005.mtsummit-papers.11",
    pages = "79--86",
    abstract = "We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.",
}
% sockeye 3
@article{hieber2022sockeye,
  title={Sockeye 3: Fast neural machine translation with pytorch},
  author={Hieber, Felix and Denkowski, Michael and Domhan, Tobias and Barros, Barbara Darques and Ye, Celina Dong and Niu, Xing and Hoang, Cuong and Tran, Ke and Hsu, Benjamin and Nadejde, Maria and others},
  journal={arXiv preprint arXiv:2207.05851},
  year={2022}
}

%BPE
@inproceedings{sennrich2016neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={54th Annual Meeting of the Association for Computational Linguistics},
  pages={1715--1725},
  year={2016},
  organization={Association for Computational Linguistics (ACL)}
}

%wmt22
@inproceedings{kocmi-etal-2022-findings,
    title = "Findings of the 2022 Conference on Machine Translation ({WMT}22)",
    author = "Kocmi, Tom  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Gowda, Thamme  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Knowles, Rebecca  and
      Koehn, Philipp  and
      Monz, Christof  and
      Morishita, Makoto  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Nov{\'a}k, Michal  and
      Popel, Martin  and
      Popovi{\'c}, Maja",
    booktitle = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wmt-1.1",
    pages = "1--45",
    abstract = "This paper presents the results of the General Machine Translation Task organised as part of the Conference on Machine Translation (WMT) 2022. In the general MT task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting of four different domains. We evaluate system outputs with human annotators using two different techniques: reference-based direct assessment and (DA) and a combination of DA and scalar quality metric (DA+SQM).",
}

%huggingface
@inproceedings{wolf-etal-2020-transformers,
    title = "HuggingFace's Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
    abstract = "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.",
}

@article{li2018measuring,
  title={Measuring the intrinsic dimension of objective landscapes},
  author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
  journal={arXiv preprint arXiv:1804.08838},
  year={2018}
}

@article{aghajanyan2020intrinsic,
  title={Intrinsic dimensionality explains the effectiveness of language model fine-tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2012.13255},
  year={2020}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{dettmers2023qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}

%%%%%%%%%%%%%%%%% LLMs for Downstream Tasks %%%%%%%%%%%%%%%%%%%%

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

%%%%%%%%%%%%%%%%% LLMs for MT Related Works %%%%%%%%%%%%%%%%%%%%

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}

%mbart
@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={726--742},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{xue2021mt5,
  title={mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={483--498},
  year={2021}
}

@article{costa2022nllb,
  title={No language left behind: Scaling human-centered machine translation},
  author={Costa-juss{\`a}, Marta R and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and others},
  journal={arXiv preprint arXiv:2207.04672},
  year={2022}
}

@article{yang2023harnessing,
  title={Harnessing the power of llms in practice: A survey on chatgpt and beyond},
  author={Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Yin, Bing and Hu, Xia},
  journal={arXiv preprint arXiv:2304.13712},
  year={2023}
}

@article{llm-mt-chatgpt,
  title={New trends in machine translation using large language models: Case examples with chatgpt},
  author={Lyu, Chenyang and Xu, Jitao and Wang, Longyue},
  journal={arXiv preprint arXiv:2305.01181},
  year={2023}
}

@article{llm-mt-bloom,
  title={Investigating the translation performance of a large multilingual language model: the case of bloom},
  author={Bawden, Rachel and Yvon, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:2303.01911},
  year={2023}
}

@article{llm-mt-empirical,
  title={Multilingual machine translation with large language models: Empirical results and analysis},
  author={Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Kong, Lingpeng and Chen, Jiajun and Li, Lei and Huang, Shujian},
  journal={arXiv preprint arXiv:2304.04675},
  year={2023}
}

@article{moslem2023adaptive,
  title={Adaptive machine translation with large language models},
  author={Moslem, Yasmin and Haque, Rejwanul and Way, Andy},
  journal={arXiv preprint arXiv:2301.13294},
  year={2023}
}

@article{wang2023document,
  title={Document-level machine translation with large language models},
  author={Wang, Longyue and Lyu, Chenyang and Ji, Tianbo and Zhang, Zhirui and Yu, Dian and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2304.02210},
  year={2023}
}

@article{zhang2023prompting,
  title={Prompting large language model for machine translation: A case study},
  author={Zhang, Biao and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:2301.07069},
  year={2023}
}


@inproceedings{lin2022few-shot-meta,
  title={Few-shot Learning with Multilingual Generative Language Models},
  author={Lin, Xi Victoria and Mihaylov, Todor and Artetxe, Mikel and Wang, Tianlu and Chen, Shuohui and Simig, Daniel and Ott, Myle and Goyal, Naman and Bhosale, Shruti and Du, Jingfei and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={9019--9052},
  year={2022}
}

@article{hendy2023gpt-microsoft,
  title={How good are gpt models at machine translation? a comprehensive evaluation},
  author={Hendy, Amr and Abdelrehim, Mohamed and Sharaf, Amr and Raunak, Vikas and Gabr, Mohamed and Matsushita, Hitokazu and Kim, Young Jin and Afify, Mohamed and Awadalla, Hany Hassan},
  journal={arXiv preprint arXiv:2302.09210},
  year={2023}
}

@inproceedings{briakou-etal-2023-searching,
    title = "Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in {P}a{LM}{'}s Translation Capability",
    author = "Briakou, Eleftheria  and
      Cherry, Colin  and
      Foster, George",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.524",
    doi = "10.18653/v1/2023.acl-long.524",
    pages = "9432--9452",
    abstract = "Large, multilingual language models exhibit surprisingly good zero- or few-shot machine translation capabilities, despite having never seen the intentionally-included translation examples provided to typical neural translation systems. We investigate the role of incidental bilingualism{---}the unintentional consumption of bilingual signals, including translation examples{---}in explaining the translation capabilities of large language models, taking the Pathways Language Model (PaLM) as a case study. We introduce a mixed-method approach to measure and understand incidental bilingualism at scale. We show that PaLM is exposed to over 30 million translation pairs across at least 44 languages. Furthermore, the amount of incidental bilingual content is highly correlated with the amount of monolingual in-language content for non-English languages. We relate incidental bilingual content to zero-shot prompts and show that it can be used to mine new prompts to improve PaLM{'}s out-of-English zero-shot translation quality. Finally, in a series of small-scale ablations, we show that its presence has a substantial impact on translation capabilities, although this impact diminishes with model scale.",
}

@inproceedings{sia-duh-2022-prefix,
    title = "Prefix Embeddings for In-context Machine Translation",
    author = "Sia, Suzanna  and
      Duh, Kevin",
    booktitle = "Proceedings of the 15th biennial conference of the Association for Machine Translation in the Americas (Volume 1: Research Track)",
    month = sep,
    year = "2022",
    address = "Orlando, USA",
    publisher = "Association for Machine Translation in the Americas",
    url = "https://aclanthology.org/2022.amta-research.4",
    pages = "45--57",
    abstract = "Very large language models have been shown to translate with few-shot in-context examples. However, they have not achieved state-of-art results for translating out of English. In this work, we investigate an extremely lightweight fixed-parameter method for conditioning a large language model to better translate into the target language. Our method introduces additional embeddings, known as prefix embeddings which do not interfere with the existing weights of the model. Using unsupervised and weakly semi-supervised methods that train only 0.0001{\%} of the model parameters, the simple method improves {\textasciitilde}0.2-1.3 BLEU points across 3 domains and 3 languages. We analyze the resulting embeddings{'} training dynamics, and where they lie in the embedding space, and show that our trained embeddings can be used for both in-context translation, and diverse generation of the target sentence.",
}

@InProceedings{sia23incontext, 
    author = {Suzanna Sia and Kevin Duh}, 
    title = {In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models}, 
    booktitle = {Proceedings of Machine Translation Summit XIV (Volume 1: Research Track)}, year = {2023}, 
  }

@inproceedings{vilar-etal-2023-prompting,
    title = "Prompting {P}a{LM} for Translation: Assessing Strategies and Performance",
    author = "Vilar, David  and
      Freitag, Markus  and
      Cherry, Colin  and
      Luo, Jiaming  and
      Ratnakar, Viresh  and
      Foster, George",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.859",
    doi = "10.18653/v1/2023.acl-long.859",
    pages = "15406--15427",
    abstract = "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM{'}s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM{'}s MT output which reveals some interesting properties and prospects for future work.",
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.",
}

@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}






##################################################################
##################################################################
# Auto-Labeling
##################################################################
##################################################################

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@inproceedings{Detic_Zhou2022DetectingTC,
  title={Detecting Twenty-Thousand Classes Using Image-Level Supervision},
  author={Xingyi Zhou and Rohit Girdhar and Armand Joulin and Phillip Krahenbuhl and Ishan Misra},
  booktitle=ECCV,
  year={2022},
}

@inproceedings{Maskformer_Cheng2021PerPixelCI,
  title={Per-Pixel Classification is Not All You Need for Semantic Segmentation},
  author={Bowen Cheng and Alexander G. Schwing and Alexander Kirillov},
  booktitle=NIPS,
  year={2021},
}

@article{SAM_Kirillov2023SegmentA,
  title={Segment Anything},
  author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Doll{\'a}r and Ross B. Girshick},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.02643},
}

@article{Yadav2022HabitatMatterport3S,
  title={Habitat-Matterport 3D Semantics Dataset},
  author={Karmesh Yadav and Ram Ramrakhya and Santhosh Kumar Ramakrishnan and Theo Gervet and John Turner and Aaron Gokaslan and Noah Maestre and Angel Xuan Chang and Dhruv Batra and Manolis Savva and Alexander William Clegg and Devendra Singh Chaplot},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.05633},
  url={https://api.semanticscholar.org/CorpusID:252815804}
}

@article{Zhou2017ScenePT,
  title={Scene Parsing through ADE20K Dataset},
  author={Bolei Zhou and Hang Zhao and Xavier Puig and Sanja Fidler and Adela Barriuso and Antonio Torralba},
  journal=CVPR,
  year={2017},
  pages={5122-5130},
  url={https://api.semanticscholar.org/CorpusID:5636055}
}

@article{Gupta2019LVISAD,
  title={LVIS: A Dataset for Large Vocabulary Instance Segmentation},
  author={Agrim Gupta and Piotr Doll{\'a}r and Ross B. Girshick},
  journal=CVPR,
  year={2019},
  pages={5351-5359},
  url={https://api.semanticscholar.org/CorpusID:195441339}
}

@article{Ammirato2017ADF,
  title={A dataset for developing and benchmarking active vision},
  author={Phil Ammirato and Patrick Poirson and Eunbyung Park and Jana Kosecka and Alexander C. Berg},
  journal=ICRA,
  year={2017},
  pages={1378-1385},
  url={https://api.semanticscholar.org/CorpusID:6126746}
}

@article{Reza2019AutomaticAF,
  title={Automatic Annotation for Semantic Segmentation in Indoor Scenes},
  author={Md. Alimoor Reza and Akshay U. Naik and Kai Chen and David J. Crandall},
  journal=IROS,
  year={2019},
  pages={4970-4976},
  url={https://api.semanticscholar.org/CorpusID:203583206}
}

@article{Zhi2021InPlaceSL,
  title={In-Place Scene Labelling and Understanding with Implicit Scene Representation},
  author={Shuaifeng Zhi and Tristan Laidlow and Stefan Leutenegger and Andrew J. Davison},
  journal=ICCV,
  year={2021},
  pages={15818-15827},
  url={https://api.semanticscholar.org/CorpusID:232417682}
}

@inproceedings{Lin2014MicrosoftCC,
  title={Microsoft COCO: Common Objects in Context},
  author={Tsung-Yi Lin and Michael Maire and Serge J. Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
  booktitle={ECCV},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:14113767}
}

@article{Shao2019Objects365AL,
  title={Objects365: A Large-Scale, High-Quality Dataset for Object Detection},
  author={Shuai Shao and Zeming Li and Tianyuan Zhang and Chao Peng and Gang Yu and Xiangyu Zhang and Jing Li and Jian Sun},
  journal={ICCV},
  year={2019},
  pages={8429-8438},
  url={https://api.semanticscholar.org/CorpusID:207967883}
}

@inproceedings{vlmaps,
  title={Visual language maps for robot navigation},
  author={Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10608--10615},
  year={2023},
  organization={IEEE}
}

@InProceedings{Frakiadaki_BMVC21,
    author    = {Zhaoyuan Fang and Ayush Jain and Gabriel Sarch and Adam W. Harley and Katerina Fragkiadaki},
    title     = {Move to See Better: Self-Improving Embodied Object Detection},
    booktitle = {BMVC},
    optmonth     = {October},
    year      = {2021},
    optpages     = {8219-8228}
}

@INPROCEEDINGS{Badrinarayanan_CVPR_2010,
  author={Badrinarayanan, Vijay and Galasso, Fabio and Cipolla, Roberto},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, 
  title={Label propagation in video sequences}, 
  year={2010},
  volume={},
  number={},
  pages={3265-3272},
  doi={10.1109/CVPR.2010.5540054}}

@INPROCEEDINGS{Zhu_2019_CVPR,
  author={Zhu, Yi and Sapra, Karan and Reda, Fitsum A. and Shih, Kevin J. and Newsam, Shawn and Tao, Andrew and Catanzaro, Bryan},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Improving Semantic Segmentation via Video Propagation and Label Relaxation}, 
  year={2019},
  volume={},
  number={},
  pages={8848-8857},
  doi={10.1109/CVPR.2019.00906}}

@InProceedings{pmlr-v80-hoffman18a,
  title = 	 {{C}y{CADA}: Cycle-Consistent Adversarial Domain Adaptation},
  author =       {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei and Darrell, Trevor},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1989--1998},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/hoffman18a/hoffman18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/hoffman18a.html},
  abstract = 	 {Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.}}

@InProceedings{Yang-wacv21,
    author    = {Jinyu Yang and Weizhi An and Chaochao Yan and Peilin Zhao and Junzhou Huang},
    title     = {Context-Aware Domain Adaptation in Semantic Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    optmonth     = {October},
    year      = {2021},
    optpages     = {8219-8228}
}

@InProceedings{Zhang-cvpr21,
    author    = {Pan Zhang and Bo Zhang and Ting Zhang and Dong Chen and Yong Wang and Fang Wen},
    title     = {Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    optmonth     = {October},
    year      = {2021},
    optpages     = {8219-8228}
}

@InProceedings{Tranheden-wacv21,
    author    = {Wilhelm Tranheden and Viktor Olsson and Juliano Pinto and Lennart Svensson},
    title     = {DACS: Domain Adaptation via Cross-Domain Mixed Sampling},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    optmonth     = {October},
    year      = {2021},
    optpages     = {8219-8228}
}


@article{clip-nav,
  title={Clip-nav: Using clip for zero-shot vision-and-language navigation},
  author={Dorbala, Vishnu Sashank and Sigurdsson, Gunnar and Piramuthu, Robinson and Thomason, Jesse and Sukhatme, Gaurav S},
  journal={arXiv preprint arXiv:2211.16649},
  year={2022}
}

@article{clip-on-wheels,
  title={Clip on wheels: Zero-shot object navigation as object localization and exploration},
  author={Gadre, Samir Yitzhak and Wortsman, Mitchell and Ilharco, Gabriel and Schmidt, Ludwig and Song, Shuran},
  journal={arXiv preprint arXiv:2203.10421},
  volume={3},
  number={4},
  pages={7},
  year={2022}
}

@article{replica19arxiv,
  title =   {The {R}eplica Dataset: A Digital Replica of Indoor Spaces},
  author =  {Julian Straub and Thomas Whelan and Lingni Ma and Yufan Chen and Erik Wijmans and Simon Green and Jakob J. Engel and Raul Mur-Artal and Carl Ren and Shobhit Verma and Anton Clarkson and Mingfei Yan and Brian Budge and Yajie Yan and Xiaqing Pan and June Yon and Yuyang Zou and Kimberly Leon and Nigel Carter and Jesus Briales and  Tyler Gillingham and  Elias Mueggler and Luis Pesqueira and Manolis Savva and Dhruv Batra and Hauke M. Strasdat and Renzo De Nardi and Michael Goesele and Steven Lovegrove and Richard Newcombe },
  journal = {arXiv preprint arXiv:1906.05797},
  year =    {2019}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zson,
  title={Zson: Zero-shot object-goal navigation using multimodal goal embeddings},
  author={Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32340--32352},
  year={2022}
}

@inproceedings{
lseg,
title={Language-driven Semantic Segmentation},
author={Boyi Li and Kilian Q Weinberger and Serge Belongie and Vladlen Koltun and Rene Ranftl},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=RriDjddCLN}
}


@inproceedings{vlnce,
  title={Beyond the nav-graph: Vision-and-language navigation in continuous environments},
  author={Krantz, Jacob and Wijmans, Erik and Majumdar, Arjun and Batra, Dhruv and Lee, Stefan},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVIII 16},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{vsr,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023},
  publisher={MIT Press}
}

@article{fiber,
  title={Coarse-to-fine vision-language pre-training with fusion in the backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={32942--32956},
  year={2022}
}

@inproceedings{glip,
      title={Grounded Language-Image Pre-training},
      author={Liunian Harold Li* and Pengchuan Zhang* and Haotian Zhang* and Jianwei Yang and Chunyuan Li and Yiwu Zhong and Lijuan Wang and Lu Yuan and Lei Zhang and Jenq-Neng Hwang and Kai-Wei Chang and Jianfeng Gao},
      year={2022},
      booktitle={CVPR},
}




##################################################################
##################################################################
# Spatial Reasoning
##################################################################
##################################################################


@article{kamath2023whatsupvlms,
  title={What's" up" with vision-language models? Investigating their struggle with spatial reasoning},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2310.19785},
  year={2023}
}

@article{xvlm,
  title={Multi-grained vision language pre-training: Aligning texts with visual concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@article{bugliarello2023weakly,
  title={Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining},
  author={Bugliarello, Emanuele and Nematzadeh, Aida and Hendricks, Lisa Anne},
  journal={arXiv preprint arXiv:2305.14281},
  year={2023}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@inproceedings{gradcam,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}


@article{herzig2023incorporating,
  title={Incorporating structured representations into pretrained vision \& language models using scene graphs},
  author={Herzig, Roei and Mendelson, Alon and Karlinsky, Leonid and Arbelle, Assaf and Feris, Rogerio and Darrell, Trevor and Globerson, Amir},
  journal={arXiv preprint arXiv:2305.06343},
  year={2023}
}


@article{kamath2023s,
  title={What's" up" with vision-language models? Investigating their struggle with spatial reasoning},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2310.19785},
  year={2023}
}

@inproceedings{crf,
  title={Image retrieval using scene graphs},
  author={Johnson, Justin and Krishna, Ranjay and Stark, Michael and Li, Li-Jia and Shamma, David and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3668--3678},
  year={2015}
}


@inproceedings{mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{nlvr,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}


@inproceedings{referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}

@inproceedings{vln,
  title={Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3674--3683},
  year={2018}
}


@article{dalle2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@inproceedings{owl,
author = {Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and Wang, Xiao and Zhai, Xiaohua and Kipf, Thomas and Houlsby, Neil},
title = {Simple Open-Vocabulary Object Detection},
year = {2022},
isbn = {978-3-031-20079-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20080-9_42},
doi = {10.1007/978-3-031-20080-9_42},
abstract = {Combining simple architectures with large-scale pre-training has led to massive improvements in image classification. For object detection, pre-training and scaling approaches are less well established, especially in the long-tailed and open-vocabulary setting, where training data is relatively scarce. In this paper, we propose a strong recipe for transferring image-text models to open-vocabulary object detection. We use a standard Vision Transformer architecture with minimal modifications, contrastive image-text pre-training, and end-to-end detection fine-tuning. Our analysis of the scaling properties of this setup shows that increasing image-level pre-training and model size yield consistent improvements on the downstream detection task. We provide the adaptation strategies and regularizations needed to attain very strong performance on zero-shot text-conditioned and one-shot image-conditioned object detection. Code and models are available on GitHub .},
booktitle = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part X},
pages = {728–755},
numpages = {28},
keywords = {One-shot object detection, Foundation models, Image-text models, Image-conditioned detection, Zero-shot detection, Transformer, Contrastive learning, Vision transformer, CLIP, Open-vocabulary detection},
location = {Tel Aviv, Israel}
}



@inproceedings{detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}


@inproceedings{flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}

@article{coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}


@article{simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@inproceedings{vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5579--5588},
  year={2021}
}

@inproceedings{oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}


@inproceedings{uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{albef,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{align,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@inproceedings{blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}


@inproceedings{glip,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{attentionisall,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{vsr,
  title={Visual Spatial Reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={arXiv preprint arXiv:2205.00363},
  year={2022},
  url={https://arxiv.org/pdf/2205.00363.pdf}
}

@article{parcalabescu2020seeing,
  title={Seeing past words: Testing the cross-modal capabilities of pretrained V\&L models on counting tasks},
  author={Parcalabescu, Letitia and Gatt, Albert and Frank, Anette and Calixto, Iacer},
  journal={arXiv preprint arXiv:2012.12352},
  year={2020}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@inproceedings{mdetr,
  title={MDETR-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://openaccess.thecvf.com/content/ICCV2021/papers/Kamath_MDETR_-_Modulated_Detection_for_End-to-End_Multi-Modal_Understanding_ICCV_2021_paper.pdf}
}

@inproceedings{yezhou-spatial,
  title={Weakly Supervised Relative Spatial Reasoning for Visual Question Answering},
  author={Pratyay Banerjee and Tejas Gokhale and Yezhou Yang and Chitta Baral},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://arxiv.org/abs/2109.01934} 
}

@InProceedings{gpv,
    author    = {Gupta, Tanmay and Kamath, Amita and Kembhavi, Aniruddha and Hoiem, Derek},
    title     = {Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16399-16409},
    url={https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.html}
}


  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@article{stanford-bag-of-words,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@inproceedings{winoground,
  title={Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{reclip,
  title={ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension},
  author={Subramanian, Sanjay and Merrill, Will and Darrell, Trevor and Gardner, Matt and Singh, Sameer and Rohrbach, Anna},
  journal={arXiv preprint arXiv:2204.05991},
  year={2022}
}

@article{svo,
  title={Probing image-language transformers for verb understanding},
  author={Hendricks, Lisa Anne and Nematzadeh, Aida},
  journal={arXiv preprint arXiv:2106.09141},
  year={2021}
}

@article{kojima2020learned,
  title={What is learned in visually grounded neural syntax acquisition},
  author={Kojima, Noriyuki and Averbuch-Elor, Hadar and Rush, Alexander M and Artzi, Yoav},
  journal={arXiv preprint arXiv:2005.01678},
  year={2020}
}

@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={Communications of the ACM},
  volume={38},
  number={11},
  pages={39--41},
  year={1995},
  publisher={ACM New York, NY, USA}
}


@article{vision-for-language,
   title={Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers},
   author={Frank, Stella and Bugliarello, Emanuele and Elliott, Desmond},
   journal={arXiv preprint arXiv:2109.04448},
   year={2021}
 }


@inproceedings{explainability,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}


@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2901--2910},
  year={2017}
}

@inproceedings{bird2006nltk,
  title={NLTK: the natural language toolkit},
  author={Bird, Steven},
  booktitle={Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions},
  pages={69--72},
  year={2006}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}


@Article{chow:68,
  author = 	 {C. K. Chow and C. N. Liu},
  title = 	 {Approximating discrete probability distributions with dependence trees},
  journal = 	 {IEEE Transactions on Information Theory},
  year = 	 {1968},
  volume = 	 {IT-14},
  number = 	 {3},
  pages = 	 {462--467}}


@Book{pearl:88,
  author = 	 {Judea Pearl},
  title = 	 {Probabilistic {R}easoning in {I}ntelligent {S}ystems: 
		  {N}etworks of {P}lausible {I}nference},
  publisher = 	 {Morgan Kaufman Publishers},
  year = 	 {1988},
  address = 	 {San Mateo, CA}
}




##################################################################
##################################################################
# PrimitiveVLN
##################################################################
##################################################################


@article{fried2018speaker,
  title={Speaker-follower models for vision-and-language navigation},
  author={Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{hu2019areyoulooking,
  title={Are you looking? grounding to multiple modalities in vision-and-language navigation},
  author={Hu, Ronghang and Fried, Daniel and Rohrbach, Anna and Klein, Dan and Darrell, Trevor and Saenko, Kate},
  journal={arXiv preprint arXiv:1906.00347},
  year={2019}
}

@inproceedings{agarwal2019visuallandmarkselection,
  title={Visual landmark selection for generating grounded and interpretable navigation instructions},
  author={Agarwal, Sanyam and Parikh, Devi and Batra, Dhruv and Anderson, Peter and Lee, Stefan},
  booktitle={CVPR Workshop},
  volume={3},
  pages={7},
  year={2019}
}

@inproceedings{majumdar2020vlnbert,
  title={Improving vision-and-language navigation with image-text pairs from the web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
  pages={259--274},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2019reinforcedxmm,
  title={Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation},
  author={Wang, Xin and Huang, Qiuyuan and Celikyilmaz, Asli and Gao, Jianfeng and Shen, Dinghan and Wang, Yuan-Fang and Wang, William Yang and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6629--6638},
  year={2019}
}

@article{tan2019envdrop,
  title={Learning to navigate unseen environments: Back translation with environmental dropout},
  author={Tan, Hao and Yu, Licheng and Bansal, Mohit},
  journal={arXiv preprint arXiv:1904.04195},
  year={2019}
}

@inproceedings{hong2021vlnrecbert,
  title={Vln bert: A recurrent vision-and-language bert for navigation},
  author={Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={1643--1653},
  year={2021}
}

@article{moudgil2021soat,
  title={Soat: A scene-and object-aware transformer for vision-and-language navigation},
  author={Moudgil, Abhinav and Majumdar, Arjun and Agrawal, Harsh and Lee, Stefan and Batra, Dhruv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7357--7367},
  year={2021}
}

@article{chen2021historyhamt,
  title={History aware multimodal transformer for vision-and-language navigation},
  author={Chen, Shizhe and Guhur, Pierre-Louis and Schmid, Cordelia and Laptev, Ivan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={5834--5847},
  year={2021}
}

@inproceedings{georgakis2022crosscm2,
  title={Cross-modal map learning for vision and language navigation},
  author={Georgakis, Georgios and Schmeckpeper, Karl and Wanchoo, Karan and Dan, Soham and Miltsakaki, Eleni and Roth, Dan and Daniilidis, Kostas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15460--15470},
  year={2022}
}

###############################################################
###############################################################
############### Zero-shot for Primitive VLN ###################
###############################################################
###############################################################


@inproceedings{huang2022lmzeroshotplanners,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@inproceedings{puig2018virtualhome,
  title={Virtualhome: Simulating household activities via programs},
  author={Puig, Xavier and Ra, Kevin and Boben, Marko and Li, Jiaman and Wang, Tingwu and Fidler, Sanja and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8494--8502},
  year={2018}
}

@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chen2021codex,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{huang2023vlmaps,
  title={Visual language maps for robot navigation},
  author={Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10608--10615},
  year={2023},
  organization={IEEE}
}

@article{ahn2022saycan,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}


@inproceedings{zhu2015bookcorpus,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={19--27},
  year={2015}
}

@article{radford2019gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{kamath2023marval,
  title={A new path: Scaling vision-and-language navigation with synthetic instructions and imitation learning},
  author={Kamath, Aishwarya and Anderson, Peter and Wang, Su and Koh, Jing Yu and Ku, Alexander and Waters, Austin and Yang, Yinfei and Baldridge, Jason and Parekh, Zarana},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10813--10823},
  year={2023}
}

@inproceedings{liu2023lang2ltl,
  title     = {Grounding Complex Natural Language Commands for Temporal Tasks in Unseen Environments},
  author    = {Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
  booktitle = {Conference on Robot Learning},
  url       = {https://arxiv.org/abs/2302.11649},
  year      = {2023},
}

@inproceedings{shah2023lmnav,
  title={Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action},
  author={Shah, Dhruv and Osi{\'n}ski, B{\l}a{\.z}ej and Levine, Sergey and others},
  booktitle={Conference on robot learning},
  pages={492--504},
  year={2023},
  organization={PMLR}
}

@inproceedings{shah2021ving,
  title={Ving: Learning open-world navigation with visual goals},
  author={Shah, Dhruv and Eysenbach, Benjamin and Kahn, Gregory and Rhinehart, Nicholas and Levine, Sergey},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13215--13222},
  year={2021},
  organization={IEEE}
}

@inproceedings{reverie,
  title={REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments},
  author={Yuankai Qi and Qi Wu and Peter Anderson and Xin Wang and William Yang Wang and Chunhua Shen and Anton van den Hengel},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@inproceedings{rxr,
  title={{Room-Across-Room}: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding},
  author={Alexander Ku and Peter Anderson and Roma Patel and Eugene Ie and Jason Baldridge},
  booktitle={Conference on Empirical Methods for Natural Language Processing (EMNLP)},
  year={2020}
}

@inproceedings{r2r,
  title={Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3674--3683},
  year={2018}
}

@article{pointinggameinit,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}

%###############################################
%#### GroundCAM

@article{bag-of-words,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@inproceedings{selvaraju2017gradcam,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{kamath-etal-2023-whatsupvlms,
    title = "What{'}s {``}up{''} with vision-language models? Investigating their struggle with spatial reasoning",
    author = "Kamath, Amita  and
      Hessel, Jack  and
      Chang, Kai-Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.568",
    doi = "10.18653/v1/2023.emnlp-main.568",
    pages = "9161--9175",
    abstract = "Recent vision-language (VL) models are powerful, but can they reliably distinguish {``}right{''} from {``}left{''}? We curate three new corpora to quantify model comprehension of such basic spatial relations. These tests isolate spatial reasoning more precisely than existing datasets like VQAv2, e.g., our What{'}sUp benchmark contains sets of photographs varying only the spatial relations of objects, keeping their identity fixed (see Figure 1: models must comprehend not only the usual case of a dog under a table, but also, the same dog on top of the same table). We evaluate 18 VL models, finding that all perform poorly, e.g., BLIP finetuned on VQAv2, which nears human parity on VQAv2, achieves 56{\%} accuracy on our benchmarks vs. humans at 99{\%}. We conclude by studying causes of this surprising behavior, finding: 1) that popular vision-language pretraining corpora like LAION-2B contain little reliable data for learning spatial relationships; and 2) that basic modeling interventions like up-weighting preposition-containing instances or fine-tuning on our corpora are not sufficient to address the challenges our benchmarks pose. We are hopeful that these corpora will facilitate further research, and we release our data and code at https://github.com/amitakamath/whatsup{\_}vlms.",
}

@inproceedings{yang2023amc,
  title={Improving visual grounding by encouraging consistent gradient-based explanations},
  author={Yang, Ziyan and Kafle, Kushal and Dernoncourt, Franck and Ordonez, Vicente},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19165--19174},
  year={2023}
}

@inproceedings{zhou2022detic,
  title={Detecting twenty-thousand classes using image-level supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Philipp and Misra, Ishan},
  booktitle={European Conference on Computer Vision},
  pages={350--368},
  year={2022},
  organization={Springer}
}

@inproceedings{habitat19iccv,
  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},
  author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},
  booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      =     {2019}
}

@inproceedings{mattersim,
  title={Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko S{\"u}nderhauf and Ian Reid and Stephen Gould and Anton van den Hengel},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@article{chang2017matterport3d,
  title={Matterport3d: Learning from rgb-d data in indoor environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  journal={arXiv preprint arXiv:1709.06158},
  year={2017}
}



%###############################################
%#### QGroundCAM - CVPR 2024
%###############################################

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{dosovitskiy2020imagevit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International conference on machine learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}

@online{ssegmetrics,
  author = {Angelo Monteux},
  title = {Metrics for semantic segmentation},
  year = {2019},
  month = {May},
  url = {https://ilmonteux.github.io/2019/05/10/segmentation-metrics.html}
}

@article{peng2023kosmos2,
  title={Kosmos-2: Grounding multimodal large language models to the world},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{huang2302languagekosmos1,
  title={Language is not all you need: aligning perception with language models. 2023},
  author={Huang, S and Dong, L and Wang, W and Hao, Y and Singhal, S and Ma, S and Lv, T and Cui, L and Mohammed, OK and Liu, Q and others},
  journal={arXiv preprint arXiv:2302.14045}
}

@inproceedings{liu2023llava,
    author      = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    title       = {Visual Instruction Tuning},
    booktitle   = {NeurIPS},
    year        = {2023}
  }

@article{chen2022pali,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  journal={arXiv preprint arXiv:2209.06794},
  year={2022}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{virtanen2020scipy,
  title={SciPy 1.0: fundamental algorithms for scientific computing in Python},
  author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
  journal={Nature methods},
  volume={17},
  number={3},
  pages={261--272},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{dou2022coarsefiber,
  title={Coarse-to-fine vision-language pre-training with fusion in the backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={32942--32956},
  year={2022}
}

@inproceedings{singh2022flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{li-etal-2023-lavis,
    title = "{LAVIS}: A One-stop Library for Language-Vision Intelligence",
    author = "Li, Dongxu  and
      Li, Junnan  and
      Le, Hung  and
      Wang, Guangsen  and
      Savarese, Silvio  and
      Hoi, Steven C.H.",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-demo.3",
    pages = "31--41",
    abstract = "We introduce LAVIS, an open-source deep learning library for LAnguage-VISion research and applications. LAVIS aims to serve as a one-stop comprehensive library that brings recent advancements in the language-vision field accessible for researchers and practitioners, as well as fertilizing future research and development. It features a unified interface to easily access state-of-the-art image-language, video-language models and common datasets. LAVIS supports training, evaluation and benchmarking on a rich variety of tasks, including multimodal classification, retrieval, captioning, visual question answering, dialogue and pre-training. In the meantime, the library is also highly extensible and configurable, facilitating future development and customization. In this technical report, we describe design principles, key components and functionalities of the library, and also present benchmarking results across common language-vision tasks.",
}

@article{dai2024instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{amc,
  title={Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations},
  author={Yang, Ziyan and Kafle, Kushal and Dernoncourt, Franck and Ordonez, Vicente},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19165--19174},
  year={2023}
}

@InProceedings{flickr30ke,
author = {Plummer, Bryan A. and Wang, Liwei and Cervantes, Chris M. and Caicedo, Juan C. and Hockenmaier, Julia and Lazebnik, Svetlana},
title = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@inproceedings{kazemzadeh2014referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}

@inproceedings{yang2019spatialsense,
  title={SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition},
  author={Yang, Kaiyu and Russakovsky, Olga and Deng, Jia},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@inproceedings{qu2022siri,
  title={Siri: A simple selective retraining mechanism for transformer-based visual grounding},
  author={Qu, Mengxue and Wu, Yu and Liu, Wu and Gong, Qiqi and Liang, Xiaodan and Russakovsky, Olga and Zhao, Yao and Wei, Yunchao},
  booktitle={European Conference on Computer Vision},
  pages={546--562},
  year={2022},
  organization={Springer}
}

@article{young2014imageflickr,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{silberman2012indoornyu,
  title={Indoor segmentation and support inference from rgbd images},
  author={Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle={Computer Vision--ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part V 12},
  pages={746--760},
  year={2012},
  organization={Springer}
}

@inproceedings{akbari2019multi,
  title={Multi-level multimodal common semantic space for image-phrase grounding},
  author={Akbari, Hassan and Karaman, Svebor and Bhargava, Surabhi and Chen, Brian and Vondrick, Carl and Chang, Shih-Fu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12476--12486},
  year={2019}
}

@article{krishna2017visualgenome,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{wang2021improving,
  title={Improving weakly supervised visual grounding by contrastive knowledge distillation},
  author={Wang, Liwei and Huang, Jing and Li, Yin and Xu, Kun and Yang, Zhengyuan and Yu, Dong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14090--14100},
  year={2021}
}

@inproceedings{arbelle2021detector,
  title={Detector-free weakly supervised grounding by separation},
  author={Arbelle, Assaf and Doveh, Sivan and Alfassy, Amit and Shtok, Joseph and Lev, Guy and Schwartz, Eli and Kuehne, Hilde and Levi, Hila Barak and Sattigeri, Prasanna and Panda, Rameswar and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1801--1812},
  year={2021}
}

@inproceedings{gupta2020contrastive,
  title={Contrastive learning for weakly supervised phrase grounding},
  author={Gupta, Tanmay and Vahdat, Arash and Chechik, Gal and Yang, Xiaodong and Kautz, Jan and Hoiem, Derek},
  booktitle={European Conference on Computer Vision},
  pages={752--768},
  year={2020},
  organization={Springer}
}

@inproceedings{datta2019align2ground,
  title={Align2ground: Weakly supervised phrase grounding guided by image-caption alignment},
  author={Datta, Samyak and Sikka, Karan and Roy, Anirban and Ahuja, Karuna and Parikh, Devi and Divakaran, Ajay},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2601--2610},
  year={2019}
}

@article{pointinggameinit,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}


@inproceedings{kamath2021mdetr,
  title={Mdetr-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021}
}


% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{kamath2023whatsupvlms,
  title={What's" up" with vision-language models? Investigating their struggle with spatial reasoning},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2310.19785},
  year={2023}
}

@article{xvlm,
  title={Multi-grained vision language pre-training: Aligning texts with visual concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@article{bugliarello2023weakly,
  title={Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining},
  author={Bugliarello, Emanuele and Nematzadeh, Aida and Hendricks, Lisa Anne},
  journal={arXiv preprint arXiv:2305.14281},
  year={2023}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@inproceedings{gradcam,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}


@article{herzig2023incorporating,
  title={Incorporating structured representations into pretrained vision \& language models using scene graphs},
  author={Herzig, Roei and Mendelson, Alon and Karlinsky, Leonid and Arbelle, Assaf and Feris, Rogerio and Darrell, Trevor and Globerson, Amir},
  journal={arXiv preprint arXiv:2305.06343},
  year={2023}
}


@article{kamath2023s,
  title={What's" up" with vision-language models? Investigating their struggle with spatial reasoning},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2310.19785},
  year={2023}
}

@inproceedings{crf,
  title={Image retrieval using scene graphs},
  author={Johnson, Justin and Krishna, Ranjay and Stark, Michael and Li, Li-Jia and Shamma, David and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3668--3678},
  year={2015}
}


@inproceedings{mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{nlvr,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}


@inproceedings{referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}

@inproceedings{vlnpanderson,
  title={Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3674--3683},
  year={2018}
}


@article{dalle2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@inproceedings{owl,
author = {Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and Wang, Xiao and Zhai, Xiaohua and Kipf, Thomas and Houlsby, Neil},
title = {Simple Open-Vocabulary Object Detection},
year = {2022},
isbn = {978-3-031-20079-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20080-9_42},
doi = {10.1007/978-3-031-20080-9_42},
abstract = {Combining simple architectures with large-scale pre-training has led to massive improvements in image classification. For object detection, pre-training and scaling approaches are less well established, especially in the long-tailed and open-vocabulary setting, where training data is relatively scarce. In this paper, we propose a strong recipe for transferring image-text models to open-vocabulary object detection. We use a standard Vision Transformer architecture with minimal modifications, contrastive image-text pre-training, and end-to-end detection fine-tuning. Our analysis of the scaling properties of this setup shows that increasing image-level pre-training and model size yield consistent improvements on the downstream detection task. We provide the adaptation strategies and regularizations needed to attain very strong performance on zero-shot text-conditioned and one-shot image-conditioned object detection. Code and models are available on GitHub .},
booktitle = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part X},
pages = {728–755},
numpages = {28},
keywords = {One-shot object detection, Foundation models, Image-text models, Image-conditioned detection, Zero-shot detection, Transformer, Contrastive learning, Vision transformer, CLIP, Open-vocabulary detection},
location = {Tel Aviv, Israel}
}



@inproceedings{detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}


@inproceedings{flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}

@article{coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}


@article{simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@inproceedings{vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5579--5588},
  year={2021}
}

@inproceedings{oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}


@inproceedings{uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{albef,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{align,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@inproceedings{blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}


@inproceedings{glip,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{attentionisall,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{vsr,
  title={Visual Spatial Reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={arXiv preprint arXiv:2205.00363},
  year={2022},
  url={https://arxiv.org/pdf/2205.00363.pdf}
}

@article{parcalabescu2020seeing,
  title={Seeing past words: Testing the cross-modal capabilities of pretrained V\&L models on counting tasks},
  author={Parcalabescu, Letitia and Gatt, Albert and Frank, Anette and Calixto, Iacer},
  journal={arXiv preprint arXiv:2012.12352},
  year={2020}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@inproceedings{mdetr,
  title={MDETR-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://openaccess.thecvf.com/content/ICCV2021/papers/Kamath_MDETR_-_Modulated_Detection_for_End-to-End_Multi-Modal_Understanding_ICCV_2021_paper.pdf}
}

@inproceedings{yezhou-spatial,
  title={Weakly Supervised Relative Spatial Reasoning for Visual Question Answering},
  author={Pratyay Banerjee and Tejas Gokhale and Yezhou Yang and Chitta Baral},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://arxiv.org/abs/2109.01934} 
}

@InProceedings{gpv,
    author    = {Gupta, Tanmay and Kamath, Amita and Kembhavi, Aniruddha and Hoiem, Derek},
    title     = {Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16399-16409},
    url={https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.html}
}

@inproceedings{openaiclip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@article{bag-of-words,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@inproceedings{winoground,
  title={Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@article{reclip,
  title={ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension},
  author={Subramanian, Sanjay and Merrill, Will and Darrell, Trevor and Gardner, Matt and Singh, Sameer and Rohrbach, Anna},
  journal={arXiv preprint arXiv:2204.05991},
  year={2022}
}

@article{svo,
  title={Probing image-language transformers for verb understanding},
  author={Hendricks, Lisa Anne and Nematzadeh, Aida},
  journal={arXiv preprint arXiv:2106.09141},
  year={2021}
}

@article{kojima2020learned,
  title={What is learned in visually grounded neural syntax acquisition},
  author={Kojima, Noriyuki and Averbuch-Elor, Hadar and Rush, Alexander M and Artzi, Yoav},
  journal={arXiv preprint arXiv:2005.01678},
  year={2020}
}

@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={Communications of the ACM},
  volume={38},
  number={11},
  pages={39--41},
  year={1995},
  publisher={ACM New York, NY, USA}
}


@article{vision-for-language,
   title={Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in Multimodal Transformers},
   author={Frank, Stella and Bugliarello, Emanuele and Elliott, Desmond},
   journal={arXiv preprint arXiv:2109.04448},
   year={2021}
 }


@inproceedings{explainability,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}


@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2901--2910},
  year={2017}
}

@inproceedings{bird2006nltk,
  title={NLTK: the natural language toolkit},
  author={Bird, Steven},
  booktitle={Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions},
  pages={69--72},
  year={2006}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}


@inproceedings{chen2022gscorecam,
  title={gScoreCAM: What objects is CLIP looking at?},
  author={Chen, Peijie and Li, Qi and Biaz, Saad and Bui, Trung and Nguyen, Anh},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={1959--1975},
  year={2022}
}

@article{ha2022semanticAbstraction,
  title={Semantic abstraction: Open-world 3d scene understanding from 2d vision-language models},
  author={Ha, Huy and Song, Shuran},
  journal={arXiv preprint arXiv:2207.11514},
  year={2022}
}

@inproceedings{huang2023vlmaps,
  title={Visual language maps for robot navigation},
  author={Huang, Chenguang and Mees, Oier and Zeng, Andy and Burgard, Wolfram},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10608--10615},
  year={2023},
  organization={IEEE}
}

@article{dorbala2022clipNav,
  title={Clip-nav: Using clip for zero-shot vision-and-language navigation},
  author={Dorbala, Vishnu Sashank and Sigurdsson, Gunnar and Piramuthu, Robinson and Thomason, Jesse and Sukhatme, Gaurav S},
  journal={arXiv preprint arXiv:2211.16649},
  year={2022}
}

@article{majumdar2022zson,
  title={Zson: Zero-shot object-goal navigation using multimodal goal embeddings},
  author={Majumdar, Arjun and Aggarwal, Gunjan and Devnani, Bhavika and Hoffman, Judy and Batra, Dhruv},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32340--32352},
  year={2022}
}


@article{rajabi2023towards,
  title={Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models},
  author={Rajabi, Navid and Kosecka, Jana},
  journal={arXiv preprint arXiv:2308.09778},
  year={2023}
}

@inproceedings{nejatishahidin2024spatial,
  title={Spatial Reasoning with Open Set Vocabulary Object Detectors for Robot Perception},
  author={Nejatishahidin, Negar and Kosecka, Jana},
  booktitle={ICRA 2024 Workshop $\{$$\backslash$textemdash$\}$ Back to the Future: Robot Learning Going Probabilistic}
}

@inproceedings{li2024labeling,
  title={Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models},
  author={Li, Yimeng and Rajabi, Navid and Shrestha, Sulabh and Alimoor, Reza and Ko{\v{s}}eck{\'a}, Jana},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={578--587},
  year={2024}
}

@inproceedings{shrestha2024self,
  title={Self-supervised pre-training for semantic segmentation in an indoor scene},
  author={Shrestha, Sulabh and Li, Yimeng and Ko{\v{s}}eck{\'a}, Jana},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={625--635},
  year={2024}
}



@Article{chow:68,
  author = 	 {C. K. Chow and C. N. Liu},
  title = 	 {Approximating discrete probability distributions with dependence trees},
  journal = 	 {IEEE Transactions on Information Theory},
  year = 	 {1968},
  volume = 	 {IT-14},
  number = 	 {3},
  pages = 	 {462--467}}


@Book{pearl:88,
  author = 	 {Judea Pearl},
  title = 	 {Probabilistic {R}easoning in {I}ntelligent {S}ystems: 
		  {N}etworks of {P}lausible {I}nference},
  publisher = 	 {Morgan Kaufman Publishers},
  year = 	 {1988},
  address = 	 {San Mateo, CA}
}














@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% GSR-Bench %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@inproceedings{kamath-etal-2023-whats,
    title = "What{'}s {``}up{''} with vision-language models? Investigating their struggle with spatial reasoning",
    author = "Kamath, Amita  and
      Hessel, Jack  and
      Chang, Kai-Wei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.568",
    doi = "10.18653/v1/2023.emnlp-main.568",
    pages = "9161--9175",
    abstract = "Recent vision-language (VL) models are powerful, but can they reliably distinguish {``}right{''} from {``}left{''}? We curate three new corpora to quantify model comprehension of such basic spatial relations. These tests isolate spatial reasoning more precisely than existing datasets like VQAv2, e.g., our What{'}sUp benchmark contains sets of photographs varying only the spatial relations of objects, keeping their identity fixed (see Figure 1: models must comprehend not only the usual case of a dog under a table, but also, the same dog on top of the same table). We evaluate 18 VL models, finding that all perform poorly, e.g., BLIP finetuned on VQAv2, which nears human parity on VQAv2, achieves 56{\%} accuracy on our benchmarks vs. humans at 99{\%}. We conclude by studying causes of this surprising behavior, finding: 1) that popular vision-language pretraining corpora like LAION-2B contain little reliable data for learning spatial relationships; and 2) that basic modeling interventions like up-weighting preposition-containing instances or fine-tuning on our corpora are not sufficient to address the challenges our benchmarks pose. We are hopeful that these corpora will facilitate further research, and we release our data and code at https://github.com/amitakamath/whatsup{\_}vlms.",
}


@inproceedings{liu2023llava,
    author      = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    title       = {Visual Instruction Tuning},
    booktitle   = {NeurIPS},
    year        = {2023}
  }

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@misc{li2024llavanext-strong,
    title={LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild},
    url={https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/},
    author={Li, Bo and Zhang, Kaichen and Zhang, Hao and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Yuanhan and Liu, Ziwei and Li, Chunyuan},
    month={May},
    year={2024}
}

@article{chen2024spatialvlm,
  title={Spatialvlm: Endowing vision-language models with spatial reasoning capabilities},
  author={Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brian and Driess, Danny and Florence, Pete and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  journal={arXiv preprint arXiv:2401.12168},
  year={2024}
}

@article{liu2023mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{yue2023mmmu,
  title={Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  journal={arXiv preprint arXiv:2311.16502},
  year={2023}
}

@article{reid2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Reid, Machel and Savinov, Nikolay and Teplyashin, Denis and Lepikhin, Dmitry and Lillicrap, Timothy and Alayrac, Jean-baptiste and Soricut, Radu and Lazaridou, Angeliki and Firat, Orhan and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{chen2024finternVL,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@inproceedings{zheng2023llmsnotrobustmc,
  title={Large language models are not robust multiple choice selectors},
  author={Zheng, Chujie and Zhou, Hao and Meng, Fandong and Zhou, Jie and Huang, Minlie},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{pezeshkpour2023largemodelssensitivity,
  title={Large language models sensitivity to the order of options in multiple-choice questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2308.11483},
  year={2023}
}

@article{wang2023llmsnotfairevals,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@inproceedings{Xue2024StrengthenedSBMC,
  title={Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors},
  author={Mengge Xue and Zhenyu Hu and Meng Zhao and Liqun Liu and Kuo Liao and Shuang Li and Honglin Han and Chengguo Yin},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:270217203}
}

@article{wang2024lookatthetext,
  title={Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think},
  author={Wang, Xinpeng and Hu, Chengzhi and Ma, Bolei and R{\"o}ttger, Paul and Plank, Barbara},
  journal={arXiv preprint arXiv:2404.08382},
  year={2024}
}

@article{liu2023groundingdino,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}

@inproceedings{kirillov2023sam,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@article{bhat2023zoedepth,
  title={Zoedepth: Zero-shot transfer by combining relative and metric depth},
  author={Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and M{\"u}ller, Matthias},
  journal={arXiv preprint arXiv:2302.12288},
  year={2023}
}

@article{liu2023vsrTACL,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{peng2023kosmos2,
  title={Kosmos-2: Grounding multimodal large language models to the world},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{huang2302languagekosmos1,
  title={Language is not all you need: aligning perception with language models. 2023},
  author={Huang, S and Dong, L and Wang, W and Hao, Y and Singhal, S and Ma, S and Lv, T and Cui, L and Mohammed, OK and Liu, Q and others},
  journal={arXiv preprint arXiv:2302.14045}
}


@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{lin2014microsoftcoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{rajabi2023towards,
  title={Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models},
  author={Rajabi, Navid and Kosecka, Jana},
  journal={arXiv preprint arXiv:2308.09778},
  year={2023}
}


@inproceedings{explainability,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}

@article{reclip,
  title={ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension},
  author={Subramanian, Sanjay and Merrill, Will and Darrell, Trevor and Gardner, Matt and Singh, Sameer and Rohrbach, Anna},
  journal={arXiv preprint arXiv:2204.05991},
  year={2022}
}

@article{svo,
  title={Probing image-language transformers for verb understanding},
  author={Hendricks, Lisa Anne and Nematzadeh, Aida},
  journal={arXiv preprint arXiv:2106.09141},
  year={2021}
}

@inproceedings{openaiclip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{bag-of-words,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@inproceedings{winoground,
  title={Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5238--5248},
  year={2022}
}

@inproceedings{yezhou-spatial,
  title={Weakly Supervised Relative Spatial Reasoning for Visual Question Answering},
  author={Pratyay Banerjee and Tejas Gokhale and Yezhou Yang and Chitta Baral},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://arxiv.org/abs/2109.01934} 
}

@InProceedings{gpv,
    author    = {Gupta, Tanmay and Kamath, Amita and Kembhavi, Aniruddha and Hoiem, Derek},
    title     = {Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16399-16409},
    url={https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.html}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@inproceedings{mdetr,
  title={MDETR-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021},
  url= {https://openaccess.thecvf.com/content/ICCV2021/papers/Kamath_MDETR_-_Modulated_Detection_for_End-to-End_Multi-Modal_Understanding_ICCV_2021_paper.pdf}
}

@article{vsr,
  title={Visual Spatial Reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={arXiv preprint arXiv:2205.00363},
  year={2022},
  url={https://arxiv.org/pdf/2205.00363.pdf}
}

@inproceedings{align,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@inproceedings{blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}


@inproceedings{glip,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}


@inproceedings{detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}


@inproceedings{flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}

@article{coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}


@article{simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@inproceedings{vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5579--5588},
  year={2021}
}

@inproceedings{oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}


@inproceedings{uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{albef,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@inproceedings{referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}


@inproceedings{mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{nlvr,
  title={A corpus for reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}

@article{blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}


@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{xvlm,
  title={Multi-grained vision language pre-training: Aligning texts with visual concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@inproceedings{kamath2021mdetr,
  title={Mdetr-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1780--1790},
  year={2021}
}


@article{krishna2017visualgenome,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{yang2019spatialsense,
  title={SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition},
  author={Yang, Kaiyu and Russakovsky, Olga and Deng, Jia},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{dai2024instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{dou2022coarsefiber,
  title={Coarse-to-fine vision-language pre-training with fusion in the backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={32942--32956},
  year={2022}
}

@inproceedings{singh2022flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15638--15650},
  year={2022}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{driess2023palmE,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{siglip,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}

@article{vlnpathfidelity,
  title={Stay on the path: Instruction fidelity in vision-and-language navigation},
  author={Jain, Vihan and Magalhaes, Gabriel and Ku, Alexander and Vaswani, Ashish and Ie, Eugene and Baldridge, Jason},
  journal={arXiv preprint arXiv:1905.12255},
  year={2019}
}

@article{zhu2021diagnosing,
  title={Diagnosing vision-and-language navigation: What really matters},
  author={Zhu, Wanrong and Qi, Yuankai and Narayana, Pradyumna and Sone, Kazoo and Basu, Sugato and Wang, Xin Eric and Wu, Qi and Eckstein, Miguel and Wang, William Yang},
  journal={arXiv preprint arXiv:2103.16561},
  year={2021}
}


@inproceedings{wang2022lessismore,
  title={Less is more: Generating grounded navigation instructions from landmarks},
  author={Wang, Su and Montgomery, Ceslee and Orbay, Jordi and Birodkar, Vighnesh and Faust, Aleksandra and Gur, Izzeddin and Jaques, Natasha and Waters, Austin and Baldridge, Jason and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15428--15438},
  year={2022}
}


@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


@inproceedings{mooneychen2011learning,
  title={Learning to interpret natural language navigation instructions from observations},
  author={Chen, David and Mooney, Raymond},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={25},
  number={1},
  pages={859--865},
  year={2011}
}

@inproceedings{mei2016listen,
  title={Listen, attend, and walk: Neural mapping of navigational instructions to action sequences},
  author={Mei, Hongyuan and Bansal, Mohit and Walter, Matthew},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{misra2017mapping,
  title={Mapping instructions and visual observations to actions with reinforcement learning},
  author={Misra, Dipendra and Langford, John and Artzi, Yoav},
  journal={arXiv preprint arXiv:1704.08795},
  year={2017}
}

@inproceedings{anderson2018vision,
  title={Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  author={Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3674--3683},
  year={2018}
}

@article{fried2018speakerfollower,
  title={Speaker-follower models for vision-and-language navigation},
  author={Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


@inproceedings{qi2020reverie,
  title={Reverie: Remote embodied visual referring expression in real indoor environments},
  author={Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9982--9991},
  year={2020}
}

@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9339--9347},
  year={2019}
}

@inproceedings{majumdar2020improving,
  title={Improving vision-and-language navigation with image-text pairs from the web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
  pages={259--274},
  year={2020},
  organization={Springer}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@article{tan2019learning,
  title={Learning to navigate unseen environments: Back translation with environmental dropout},
  author={Tan, Hao and Yu, Licheng and Bansal, Mohit},
  journal={arXiv preprint arXiv:1904.04195},
  year={2019}
}

@inproceedings{kamath2023new,
  title={A new path: Scaling vision-and-language navigation with synthetic instructions and imitation learning},
  author={Kamath, Aishwarya and Anderson, Peter and Wang, Su and Koh, Jing Yu and Ku, Alexander and Waters, Austin and Yang, Yinfei and Baldridge, Jason and Parekh, Zarana},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10813--10823},
  year={2023}
}

@inproceedings{majumdar2020improving,
  title={Improving vision-and-language navigation with image-text pairs from the web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
  pages={259--274},
  year={2020},
  organization={Springer}
}


@inproceedings{zhu2021soon,
  title={Soon: Scenario oriented object navigation with graph-based exploration},
  author={Zhu, Fengda and Liang, Xiwen and Zhu, Yi and Yu, Qizhi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12689--12699},
  year={2021}
}


@article{kolve2017ai2thor,
  title={Ai2-thor: An interactive 3d environment for visual ai},
  author={Kolve, Eric and Mottaghi, Roozbeh and Han, Winson and VanderBilt, Eli and Weihs, Luca and Herrasti, Alvaro and Deitke, Matt and Ehsani, Kiana and Gordon, Daniel and Zhu, Yuke and others},
  journal={arXiv preprint arXiv:1712.05474},
  year={2017}
}