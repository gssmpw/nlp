% \begin{table*}[t]
% % \setlength{\belowcaptionskip}{-0.5cm}
% \setlength{\tabcolsep}{2pt}
% % \footnotesize
% \centering
% \resizebox{\linewidth}{!}{\begin{tabular}{lccccccccccc|ccc}
%     \toprule
%     \multirow{2}{*}[-1ex]{\bf Method} & \multirow{2}{*}[-1ex]{\shortstack{\bf Backbone}} & \multirow{2}{*}[-1ex]{\shortstack{\bf \# Total \\ \bf Params}} & \multirow{2}{*}[-1ex]{\shortstack{\bf Pre-training \\ \bf Data}} & \multirow{2}{*}[-1ex]{\shortstack{\bf Fine-tuning \\ \bf Data}} & \multicolumn{7}{c|}{F1} & \multicolumn{3}{c}{Macro Average} \\
%     \cmidrule(lr){6-12} \cmidrule(lr){13-15}
%     & & & & & \bf Ar & \bf Bn & \bf Fi & \bf Ja & \bf Ko & \bf Ru & \bf Te & \bf F1 & \bf EM & \bf BLEU \\

%     \midrule
%     % \rowcolor{blue!15} \multicolumn{15}{c}{\emph{Zero-shot Readers}} \\
%     \multicolumn{15}{l}{\bf\emph{Zero-shot Readers}} \\
%     MT+DPR$^\dagger$ & \footnotesize $\operatorname{mBERT}$ & --- & --- & \footnotesize NQ & 7.2 & 4.3 & 17.0 & 7.9 & 7.1 & 13.6 & 0.5 & 8.2 & 3.8 & 6.8 \\
%     ReAtt+MT$^\ast$ & \footnotesize $\operatorname{T5-L}$ & 1.19B & --- & \footnotesize NQ & 15.0 & 10.5 & 1.8 & 13.1 & 14.9 & 15.4 & 8.2 & 11.3 & 5.5 & 9.5 \\
%     GMT+GS$^\dagger$ & --- & --- & --- & \footnotesize NQ & 18.0 & 29.1 & 13.8 & 5.7 & 15.2 & 14.9 & 15.6 & 16.0 & 9.9 & 14.9 \\

%     \midrule
%     % \rowcolor{blue!15} \multicolumn{15}{c}{\emph{Supervised Readers}} \\
%     \multicolumn{15}{l}{\bf\emph{Supervised Readers}} \\
%     BM25$^\dagger$ & --- & --- & --- & \footnotesize XOR & 31.1 & 21.9 & 21.4 & 12.4 & 12.1 & 17.7 & – & – & – & – \\
%     MT+Mono$^\dagger$ & \footnotesize $\operatorname{mBERT}$ & --- & --- & \footnotesize NQ + XOR & 15.8 & 9.6 & 20.5 & 12.2 & 11.4 & 16.0 & 0.5 & 17.3 & 7.5 & 10.7 \\
%     CORA & \footnotesize $\operatorname{mBERT+mT5-B}$ & 1.14B & --- & \footnotesize NQ + XOR & 42.9 & 26.9 & 41.4 & 36.8 & 30.4 & 33.8 & 30.9 & 34.7 & 25.8 & 23.3 \\
%     \class & \footnotesize $\operatorname{mT5-L}$ & 1.23B & \small Wikipedia & \footnotesize NQ + XOR & 49.1 &  32.0 & 46.7 & 44.1 &  38.4 & 39.9 & 41.1 & 41.6 & 32.5 & 28.2 \\
%     Sentri & \footnotesize $\operatorname{XLM-R+MT5-B}$ & 1.14B & --- & \footnotesize NQ + TQA + XOR & 52.5 & 31.2 & 45.5 &  44.9 & 43.1 & 41.2 & 30.7 & 41.3 & 34.9 & 30.7 \\
%     LAPCA & \footnotesize $\operatorname{XLM-R+MT5-B}$ & 1.14B & \small Wikipedia & \footnotesize NQ + XPAQ + XOR &  53.4 &  50.2 &  49.3 & 44.7 &  49.5 &  49.3 &  38.9 &  47.8 &  38.7 &  35.5 \\

%     \midrule
%     % \rowcolor{blue!15} \multicolumn{15}{c}{\emph{Few-shot Readers}} \\
%     \multicolumn{15}{l}{\bf\emph{Few-shot Readers}} \\
%     Gemma (5-shot) & \footnotesize $\operatorname{Gemma}$ & 7B & --- & --- & 13.4 & 19.0 & 21.7 & 20.2 & 20.5 & 23.0 & 23.4 & 20.2 & 12.2 & 15.3 \\
%     LLaMA3 (5-shot) & \footnotesize $\operatorname{LLaMA3}$ & 8B & --- & --- & 22.7 & 13.2 & 22.9 & 17.8 & 19.0 & 19.2 & 28.9 & 20.5 & 12.8 & 15.6 \\
%     % \class (5-shot) & \footnotesize $\operatorname{mT5-L}$ & 1.23B & \small Wikipedia & \footnotesize NQ + XOR (5-shot) & 29.8 & 25.2 & 27.0 & 22.8 & 26.6 & 23.8 & 30.8 & 26.6 & 17.9 & 21.0 \\ % \fan{need to check the results again}
%     \class (5-shot) & \footnotesize $\operatorname{mT5-L}$ & 1.23B & \small Wikipedia & \footnotesize NQ + XOR (5-shot) & 32.3 & 28.1 & 29.9 & 25.7 & 29.5 & 27.7 & 24.7 & 29.8 & 20.5 & 21.2 \\
%     \rowcolor{gray!23} \bf \ours & \footnotesize $\operatorname{mT5-L}$ & 1.23B & \small \ourptdata & \footnotesize NQ + \ourdata & \bf 41.3 & \bf 35.4 & \bf 39.6 & \bf 41.5 & \bf 35.0 & \bf 38.2 & \bf 36.3 & \bf 38.2 & \bf 27.9 & \bf 24.4 \\
%     \bottomrule

%     \end{tabular}}
%     \caption{Multilingual QA results on the XOR-Full dev set. Best performance is in bold. $\dagger$ and $\ast$ denotes results taken from~\citet{asai2021one} and~\citet{jiang-etal-2024-pre}. Others are copied from original papers.}
% \label{tab:xor_full_results}
% \end{table*}


\begin{table*}[t]
\setlength{\belowcaptionskip}{-0.1cm}
\setlength{\tabcolsep}{2.3pt}
\scriptsize
\centering
\begin{tabular}{lccccccccccc|ccc}
    \toprule
    \multirow{2}{*}[-1ex]{\bf Method} & \multirow{2}{*}[-1ex]{\shortstack{\bf Backbone}} & \multirow{2}{*}[-1ex]{\shortstack{\bf \# Total \\ \bf Params}} & \multirow{2}{*}[-1ex]{\shortstack{\bf Pre-training \\ \bf Data}} & \multirow{2}{*}[-1ex]{\shortstack{\bf Fine-tuning \\ \bf Data}} & \multicolumn{7}{c|}{F1} & \multicolumn{3}{c}{Macro Average} \\
    \cmidrule(lr){6-12} \cmidrule(lr){13-15}
    & & & & & \bf Ar & \bf Bn & \bf Fi & \bf Ja & \bf Ko & \bf Ru & \bf Te & \bf F1 & \bf EM & \bf BLEU \\

    \midrule
    \multicolumn{15}{l}{\bf\emph{Zero-shot Readers}} \\
    MT+DPR$^\dagger$ & $\texttt{mBERT}$ & --- & --- & NQ & 7.2 & 4.3 & 17.0 & 7.9 & 7.1 & 13.6 & 0.5 & 8.2 & 3.8 & 6.8 \\
    ReAtt+MT$^\ast$ & $\texttt{T5-L}$ & 1.19B & --- & NQ & 15.0 & 10.5 & 1.8 & 13.1 & 14.9 & 15.4 & 8.2 & 11.3 & 5.5 & 9.5 \\
    GMT+GS$^\dagger$ & --- & --- & --- & NQ & 18.0 & 29.1 & 13.8 & 5.7 & 15.2 & 14.9 & 15.6 & 16.0 & 9.9 & 14.9 \\

    \midrule
    \multicolumn{15}{l}{\bf\emph{Supervised Readers}} \\
    BM25$^\dagger$ & --- & --- & --- & XOR & 31.1 & 21.9 & 21.4 & 12.4 & 12.1 & 17.7 & – & – & – & – \\
    MT+Mono$^\dagger$ & $\texttt{mBERT}$ & --- & --- & NQ + XOR & 15.8 & 9.6 & 20.5 & 12.2 & 11.4 & 16.0 & 0.5 & 17.3 & 7.5 & 10.7 \\
    CORA & $\texttt{mBERT+mT5-B}$ & 1.14B & --- & NQ + XOR & 42.9 & 26.9 & 41.4 & 36.8 & 30.4 & 33.8 & 30.9 & 34.7 & 25.8 & 23.3 \\
    \class & $\texttt{mT5-L}$ & 1.23B & Wikipedia & NQ + XOR & 49.1 &  32.0 & 46.7 & 44.1 &  38.4 & 39.9 & 41.1 & 41.6 & 32.5 & 28.2 \\
    Sentri & $\texttt{XLM-R+mT5-B}$ & 1.14B & --- & NQ + TQA + XOR & 52.5 & 31.2 & 45.5 &  44.9 & 43.1 & 41.2 & 30.7 & 41.3 & 34.9 & 30.7 \\
    LAPCA & $\texttt{XLM-R+mT5-B}$ & 1.14B & Wikipedia & NQ + XPAQ + XOR &  53.4 &  50.2 &  49.3 & 44.7 &  49.5 &  49.3 &  38.9 &  47.8 &  38.7 &  35.5 \\

    \midrule
    \multicolumn{15}{l}{\bf\emph{Few-shot Readers}} \\
    Gemma (5-shot) & $\texttt{Gemma}$ & 7B & --- & --- & 13.4 & 19.0 & 21.7 & 20.2 & 20.5 & 23.0 & 23.4 & 20.2 & 12.2 & 15.3 \\
    LLaMA3 (5-shot) & $\texttt{LLaMA3}$ & 8B & --- & --- & 22.7 & 13.2 & 22.9 & 17.8 & 19.0 & 19.2 & 28.9 & 20.5 & 12.8 & 15.6 \\
    \class (5-shot) & $\texttt{mT5-L}$ & 1.23B & Wikipedia & NQ + XOR (5-shot) & 32.3 & 28.1 & 29.9 & 25.7 & 29.5 & 27.7 & 24.7 & 29.8 & 20.5 & 21.2 \\
    \rowcolor{gray!23} \bf \ours & $\texttt{mT5-L}$ & 1.23B & \ourptdata & NQ + \ourdata & \bf 41.3 & \bf 35.4 & \bf 39.6 & \bf 41.5 & \bf 35.0 & \bf 38.2 & \bf 36.3 & \bf 38.2 & \bf 27.9 & \bf 24.4 \\
    \bottomrule

    \end{tabular}
    \caption{Multilingual QA results on the XOR-Full dev set. Best performance is in bold. $\dagger$ and $\ast$ denotes results taken from~\citet{asai2021one} and~\citet{jiang-etal-2024-pre}. Others are copied from original papers.}
\label{tab:xor_full_results}
\end{table*}