\section{Related Work}
\subsection{Trends}

Research by \cite{alzaabi_review_2024} in their review of insider threat research with natural language processing determine the viability of research using the CERT dataset~\cite{cmu_insider_2020}. Use of the CERT dataset is common among NLP insider threat researchers to establish a performance benchmark \cite{anul_haq_insider_2022,kumar_thee_2023,mittal_prediction_2023}, as well as researchers focusing on custom machine learning models \cite{he_insider_2021,apau_theoretical_2019}. Observed trends include manual \cite{weitl-harms_using_2024,soh_employee_2019} and automated labeling \cite{mittal_design_2023,moallem_understanding_2020,park_detecting_2018} of data fields for efficient data matching. Concerns are noted on accuracy of automated labeling. Technology trends lean on performance for insider threat models to improve detection \cite{yadav_sentiment_2022} and influence organizational policy \cite{osterritter_conversations_2021,randle_critical_2017,reegard_concept_2019}. Performance trending can be seen in LLM performance ranking by \cite{vardhni_performance_2024,metcalfe_enhancing_2024}.

\subsection{Challenges}

  \cite{weitl-harms_using_2024} researched measurement improvement of software approval ratings through NLP sentiment analysis by capturing statistical values from qualitative perceptions. Where \cite{weitl-harms_using_2024} used manual labels as the ``gold standard", \cite{park_detecting_2018} used automated labeling for insider threat machine learning analysis of secondary social media data, presenting research with label fidelity issues. \cite{camargo-henriquez_web_2022,mahto_dive_2016,yadav_sentiment_2022,nalawati_sentiment_2022,singh_enumerable_2022} applied web scraping techniques, NLP, and machine learning analysis to assist the research community, where their research is more appropriately applied to policy influence. \cite{soh_employee_2019} implemented an insider threat profiling mechanism based on sentiment analysis, and \cite{dai_bias_2024} addresses bias in data retrieval using LLMs.
    
\subsection{Gaps}

\cite{osterritter_conversations_2021} demonstrated policy influence, where \cite{cao_llm-assisted_2024} performed research on LLMs in public-sector decision making. Previously noted examples in the use of LLMs with sentiment analysis \cite{weitl-harms_using_2024,nalawati_sentiment_2022,singh_enumerable_2022,tan_unified_2019} along with research combining web scraping, LLM, and sentiment analysis was demonstrate the burgeoning state of the field \cite{camargo-henriquez_web_2022,yadav_sentiment_2022}. Use of LLM generated synthetic data is is observed by \cite{wu_exploring_2024} for improving job recommendations by reducing bias. \cite{skondras_generating_2023} applied synthetic data to improve job stratification. Similarly, \citeauthor{myronenko_improving_2024} utilized synthetic data to draw skill requirements for job roles from online job postings. 

By both generating synthetic datasets using LLMs and analyzing publicly available data, this study assesses the viability of synthetic data generation in this domain, and the comparative accuracy and validity of LLMs in identifying indicators of insider threats. Contributions of this research will address the use of synthetically generated job reviews to discover insider threat sentiment compared to a curated dataset. Policy influence to encourage organizational, informational, and reputational policy are its contributions.