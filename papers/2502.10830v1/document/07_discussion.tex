\section{Discussion and Limitations}

\begin{figure*}[t]
  \includegraphics[width=\linewidth]{document/figures/use_case.png}
  \caption{Potential Use cases of SpellRing: Web search, map navigation, and text input on a mobile phone}
  \Description{Potential Use case of SpellRing: Web search, map navigation, and text input on a mobile phone}
  \label{fig:use_case}
\end{figure*}

\textcolor{black}{In this section, we discuss the limitations of SpellRing, followed by the challenges and design implications of developing a ring-based ASL fingerspelling recognition system for potential future use by DHH individuals.}



\subsection{Continuous Finger Tracking vs. Continuous Fingerspelling Recognition}
\textcolor{black}{
Although accurately tracking finger movement is fundamental for fingerspelling recognition, it does not guarantee successful recognition of continuous fingerspelling. Continuous fingerspelling recognition requires an additional layer of linguistic and sequential processing, separating indistinct handshapes and transitions between letters of fingerspelled words. First, finger movement tracking typically focuses on broad, fluid motions without the need to recognize distinct handshapes or subtle transitions between them. Continuous fingerspelling, however, requires high precision to differentiate between similar handshapes, such as those for `M' and `N' in ASL. This requires detailed recognition of finger positions and transitions, meaning that recognition performance can vary depending on the accuracy of the tracking \cite{taylor2018real}. 
Second, fingerspelling involves interpreting static handshapes as letters in sequence to form words. Misrecognizing even a single letter can change the entire meaning of the misrecognized word or phrase, highlighting the critical need for high accuracy and use of a language model to correct errors. In contrast, finger movement tracking does not require the same level of interpretation and can often tolerate minor errors in finger positioning. Finally, continuous fingerspelling recognition requires advanced algorithms, such as Connectionist Temporal Classification (CTC), to parse specific handshape sequences since it allows the system to recognize fingerspelling continuously without needing to label each fingerspelled letter. In contrast, finger movement tracking often relies on motion patterns or positions and lacks the nuanced training necessary to distinguish different handshapes of ASL letters and the transitions between them.
}


\subsection{Extending SpellRing for Large-Scale Fingerspelling }

In this study, we demonstrated how a single ring can recognize 1,164 fingerspelled words across 500 phrases using the MacKenzie dataset, representing a significant advancement over prior wearable-based ASL fingerspelling recognition systems. \textcolor{black}{ While the MacKenzie dataset provides an effective prototype for input systems, enabling us to estimate performance and potential, it also underscores the limitations of our system. We acknowledge that 1,164 words represent a small fraction of the vocabulary compared to commonly used fingerspelled words \cite{shi2018american}, including proper nouns, names, and specific terms essential for ASL conversational vocabulary.}
Since a more extensive vocabulary would encompass a broader range of fingerspelling behaviors and transitions within words, our system could benefit from a significantly larger dataset, which we believe extends beyond the scope of a single research paper. 

Our experiments, however, revealed that pre-training a model on data from other participants and fine-tuning it with the target participant's data significantly improved performance. We evaluated \theDevice{} using a two-step training model, incorporating data from all participants to explore how leveraging cross-participant information could enhance system performance. For comparison, we tested the model using each participant’s individual data with leave-one-session-out cross-validation. The results from both Study 1 and Study 2 showed a top-1 accuracy of 77.21\% (SD=8.94) when trained on individual data, while the pre-trained model with data from other participants improved performance by 5.24\%, achieving 82.45\%. This improvement suggests that cross-participant data enhances the model's ability to generalize across users, leading to better accuracy. This finding suggests a promising approach for collecting a large-scale dataset for pre-trained models, reducing the amount of training data needed per signer. Thus, our system validation could be extended from text input to conversational fingerspelled words, forming part of a comprehensive ASL recognition system.




\subsection{Potential Uses Cases of \theDevice{}}
\textcolor{black}{
ASL fingerspelling, as noted in related work \cite{martin2023fingerspeller, hassan2023tap}, can serve as a fast and accessible text entry tool, outperforming virtual keyboards. Specifically, ASL fingerspelling can be significantly faster than typing on a smartphone’s virtual keyboard \footnote{https://www.kaggle.com/competitions/asl-fingerspelling} \cite{hassan2023tap, martin2023fingerspeller}. In this paper, we highlighted SpellRing’s potential as a text input tool, which could be suitable for devices such as mobile phones, home assistants, and VR/AR glasses, addressing challenges like the restricted camera field of view on these devices. We demonstrated potential applications, including web searches, map navigation, and text entry (as illustrated in Figure \ref{fig:use_case}).}

\textcolor{black}{
We emphasized that while SpellRing is not a comprehensive ASL recognition system and focuses solely on recognizing fingerspelled sequences, its ability to distinguish between different handshapes, palm orientations, and movements in continuous fingerspelling represents a foundational step toward developing a comprehensive ASL recognition system. Building on prior work, such as SignRing \cite{li2023signring}—which uses a single embedded IMU to classify signs—our system shows potential to enhance ASL sentence-level recognition by combining sign classification and fingerspelling recognition, especially in contexts where signs and fingerspelled words are used together (e.g., "MY NAME D-A-V-I-D"). This ability suggests a promising direction for future research and development.
}


\subsection{Auto-Correction and Language Model}\label{auto_correction}

\textcolor{black}{We evaluated our system using the MacKenzie-Soukoreff phrase set \cite{mackenzie2003phrase} to align with previous work \cite{martin2023fingerspeller}, allowing us to estimate performance and potential. Since our auto-correction and n-gram model were developed with our dataset, we conducted additional analysis of auto-correction to assess the generalization of our system by incorporating different reference sets and utilizing large language models. When adding the ChicagoFSWild sets \cite{shi2019fingerspelling, shi2018american} to the reference for auto-correction, our model's top-1 word-level accuracy decreased by 7.1\%, with a smaller drop of 2.5\% in top-5 accuracy, while the word error rate (WER) increased slightly from 0.099 to 0.108. Using a general large language model (LLM), i.e., Llama 3.3 \footnote{https://www.llama.com/}, for phrase-level correction, WER improved to 0.142, demonstrating the potential of language models to mitigate the decline in word-level accuracy. Since the word dictionary used for reference affects performance, we believe that SpellRing could be improved with customized word lists, such as user-defined lists based on their own common language usage, including names and colloquialisms. These lists can be created from their mobile messages or by allowing users to add words themselves.}


 





\subsection{Design Optimization for Form Factors}

Our system currently utilizes a set of miniature sensors, including a microphone, speaker, and IMU sensor, but as a research prototype, these components are not yet fully optimized in terms of hardware design. For instance, the IMU sensor is housed on a separate PCB board, rather than being integrated with the microcontroller and acoustic sensors on a single, compact PCB. Despite these design limitations, the prototype performed well in initial user studies. However, further hardware optimization is essential to improve its long-term wearability and user comfort. A potential next step would involve fully integrating all sensors and the microcontroller into a single flexible PCB, which could be powered by a curved battery, similar to the compact designs used in commercially available smart rings. This integration would not only streamline the design but also reduce the system's size and improve its overall form factor, making it less obtrusive for everyday use. With these advancements, we envision the prototype evolving into a fully functional, minimally obtrusive ring system that closely resembles off-the-shelf smart rings, offering enhanced practicality and user-friendliness for long-term use.


 
\subsection{Impact of Speed, Variation, and Clarity on Performance} \label{impact_speed}
From our results, we observed a strong correlation between signing speed and performance, as shown in Figure \ref{fig:performance_time}. This relationship stems from differences in individual signing habits, irrespective of whether or not the signer is Deaf. When signers fingerspell quickly, they do not always articulate each letter clearly, which affects the clarity of certain letters within words. For instance, the letter `E' exhibits considerable variation, especially when positioned in the middle of a word that is fingerspelled rapidly, which poses challenges for the model to accurately learn this letter. However, this variability in performance is largely dependent on individual signers. For instance, the model performed at different levels for fluent signers P7 and P8 from Study 1, stemming from key differences in how clearly and distinctly the participant fingerspelled each letter. Previous work \cite{keane2016fingerspelling} also highlights variation in fingerspelling beyond handshape, including speed and transitions. From Study 2, we gained insight into how signers adjusted their fingerspelling habits based on real-time feedback from the system. For example, they adjusted their fingerspelling speed and clarity to accommodate the system's performance. Signers also reported that for real-time systems, they made an effort not to miss any letters to achieve better performance, whereas in a natural fingerspelling context, signers may have omitted certain letters.

% \begin{figure}[h]
%   \includegraphics[width=0.8\linewidth]{document/figures/output_study2.png}
%   \caption{Offline Performance over Completion Time in Study 2. Dots indicate each sessions }
%   \Description{Offline Performance over Completion Time in Study 2. Dots indicate each sessions }
%   \label{fig:output_study2}
% \end{figure}



\subsection{User-Independence Performance} \label{pretrained model}
Given the success of Ring-a-Pose \cite{yu2024ring} in achieving strong user-independent performance, \textcolor{black}{we anticipated that our system would also perform well in a user-independent setting. To evaluate this, we conducted a leave-one-participant-out assessment. \textcolor{black}{However, the overall performance achieved was 48.42\% (SD = 12.38), ranging from 32.1\% to 72.13\%, likely due to variations in signers' habits such as fast fingerspelling speed, blurred transitions, and individual fingerspelling styles; the system's performance reflects the real-world complexity of continuous fingerspelling recognition and accounting for variations in users' natural behaviors.}}

{Nevertheless, we recognize the potential of our system, as five participants with slightly slower and clearer signing habits achieved over 63\% accuracy using a user-independent model.} We believe that further expanding the dataset with more diverse participants could yield even greater gains. A larger dataset would likely enhance the model's ability to generalize across different users and recognize more complex actions, gestures, movements, or handshapes. Future work will focus on expanding the dataset and refining the model to optimize its effectiveness in both user-dependent and user-independent scenarios, providing a deeper understanding of how best to enhance \theDevice{}'s performance. Additionally, we expect that future work on transfer learning will help lower the barrier and enhance the usability of a user-independent recognition model.

\subsection{Combining IMU and Acoustic Data for Improving Performance}
We experimented with a sensor fusion approach for ASL fingerspelling recognition by combining acoustic sensing and IMU (Inertial Measurement Unit) data. To evaluate the effectiveness of this multimodal approach, we tested our model using each participant's data from Study 1 and 2 with leave-one-session-out cross-validation under three different conditions: acoustic-only, IMU-only, and sensor fusion. 
Overall, the results showed that the acoustic-only model achieved an accuracy of 72.42\% (SD=12.11\%), while the IMU-only model performed slightly better with 74.29\% (SD=9.22\%). The sensor fusion model, which integrated both data sources, achieved the highest accuracy at 78.11\% (SD=7.88\%), indicating that the multimodal approach outperformed using either modality alone. \textcolor{black}{We note that across all sessions per participant in Study 1 and 2, the sensor fusion model outperformed the other two models. Additionally, the large standard deviation in performance observed across participants was primarily due to variations in their signing speeds rather than the ablation studies.} The fusion model was particularly effective at resolving commonly misclassified letter pairs, such as `P' and `K', `G' and `Q', and `M' and `N', which were frequently confused by the single-modality models. These results suggest that sensor fusion can improve the accuracy and robustness of ASL fingerspelling recognition by leveraging the complementary strengths of both acoustic and IMU data. \textcolor{black}{Nevertheless, while adding IMU sensors proved helpful, we acknowledge that incorporating IMU data did not significantly improve performance. We assume that the acoustic sensor captures some movement information; native and fluent signers fingerspell rapidly, and distinct signals are generated during transitions between letters. We believe this insight will contribute to future design implications of ring-based ASL recognition systems.}

\subsection{Environmental Noise}
\textcolor{black}{Our multimodal approach, utilizing both acoustic and IMU data, enhances the system's robustness against environmental noise, particularly since the IMU sensor is unaffected by such noise. Our ablation study demonstrated that the system performs reliably using a single IMU only but achieves better performance when acoustic signals are included. Conducted in semi-controlled environments, ranging from quiet rooms to participants' homes with background noise from roommates, our study showed that the system delivers reliable performance in everyday noise conditions. Nevertheless, environmental acoustic noise, such as conversations or keyboard typing, can degrade signal quality and affect performance. To mitigate this, we applied band-pass filtering during signal processing to address lower-frequency environmental noise. Drawing on similar work using active acoustic sensing \cite{yu2024ring, lee2024echowrist, zhang2023echospeech, li2022eario}, incorporating environmental noise data into the model could further enhance the system's resilience against acoustic interference.}

\subsection{Future Work}
\label{future}
%While fingerspelling recognition is a crucial first step toward ASL recognition, fingerspelling is not at all representative of the complexity of ASL as a language, both in form and structure. While the MacKenzie dataset serves as an effective prototype for input systems, allowing us to estimate performance and potential, it also highlights the key challenge of our system: that high fluency and variance in signing requires substantial training data for optimal performance. To address this challenge, we collected over 76 hours of ASL fingerspelling data, comprising 4 hours of data per signer. This extensive dataset enabled our system to perform well in real-time and maintain consistency across different days. However, to enhance the system's generalizability to a larger population and more extensive vocabulary while reducing the required training data per signer, we believe that a significantly larger dataset is necessary. Such a dataset would need to cover a broader range of fingerspelling behaviors and transitions within words, an undertaking that extends beyond the scope of a single research paper. Our experiments revealed that using data from other participants to pre-train a model, which was then fine-tuned with the target participant's data, significantly improved performance. This finding suggests a promising direction for future research and development.


The primary goal of this paper is to demonstrate the potential of a single, cost-effective ring \textcolor{black}{(with a prototype cost of approximately US\$30 \cite{yu2024ring}, which could decrease with mass production)} for ASL fingerspelling recognition. By sharing our findings, we aim to encourage more researchers in the field to collaborate in further developing this system.  Our ultimate goal is to create an ASL translation system that Deaf and hard of hearing individuals could use in their daily lives to aid in communication between DHH and hearing individuals. 

\textcolor{black}{As we move forward, future work should focus on integrating our system into AR smart glasses, where the entire system can recognize and distinguish subtle differences and individual variations in all ASL phonological parameters (i.e., handshape, palm orientation, movement, location, and non-manual markers) \cite{valli1992linguistics} to advance progress toward ASL translation, sign-to-speech, and/or speech-to-text/sign-on-glass displays for DHH users. Our system's ability to track handshape, palm orientation, and movement could enhance the system's robustness by overcoming the limitations of camera use, such as restricted field-of-view and poor lighting conditions.} Future work should also incorporate tracking of both hands to advance recognition of full ASL signs and sentences, rather than of just fingerspelled words.

Additionally, future work should focus on developing more robust machine learning models capable of handling a larger vocabulary and more varied signing styles while maintaining or improving accuracy. Expanding the dataset, refining algorithms, and incorporating contextual information—such as preceding words or signs—could allow us to leverage language models for more accurate predictions. For example, in a conversation about closed captioning, fingerspelled words related to captioning could be corrected more accurately using statistical approaches.

Most notably, training systems to recognize actual ASL signs (as opposed to just fingerspelled English words), is a crucial next step in working toward developing a wearable ASL translation/ recognition tool. While SpellRing focuses on fingerspelling recognition, systems like SignRing \cite{li2023signring} have shown the potential of ring devices with IMU sensors to recognize ASL signs. Our system, which can track handshape, palm orientation, and movement, could also be expanded to recognize ASL signs that share all properties except for handshape (e.g., FAMILY, CLASS, and TEAM), palm orientation (e.g., MAYBE and BALANCE), or movement (e.g., SIT and CHAIR). This capability could significantly enhance the accuracy and applicability of the system for DHH users. 

Continual feedback from Deaf and hard of hearing (DHH) signers will be essential in ensuring future systems meet user needs and preferences. \textcolor{black}{One example is the need to evaluate preferences on ring placement; as demonstrated by Ring-a-Pose \cite{yu2024ring}, changing ring placement maintains potential for fingerspelling recognition, though it may sacrifice performance to improve user experience.}
As we expand SpellRing’s capabilities, we must strike a balance between technological advancement and user comfort, always prioritizing the user's experience and input while creating a tool that recognizes natural signing data in real-time.


