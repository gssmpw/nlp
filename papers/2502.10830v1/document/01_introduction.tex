\section{INTRODUCTION}




Fingerspelling is used in American Sign Language (ASL) to spell out words without corresponding signs, such as proper nouns, names, and technical terms~\cite{keane2016fingerspelling, hanson1982use}. It is estimated that between 12-35\% of casual ASL conversation comprises fingerspelling~\cite{padden2003alphabet, morere2012fingerspelling}. \textcolor{black}{Recently, fingerspelling has also become a more feasible option for text entry \footnote{https://www.kaggle.com/competitions/asl-fingerspelling} on devices such as mobile phones \cite{hassan2023tap, martin2023fingerspeller}, home assistants \cite{glasser2022analyzing, maria2024alexa}, and VR/AR devices \cite{hirabayashi2019development, gangakhedkar2024fingarspell,fujikawa2019development}, thereby enhancing accessibility for Deaf and Hard of Hearing (DHH) individuals.} Given that ASL fingerspelling involves differentiating handshape, palm orientation, and movement on a single hand, while ASL signs require distinguishing these properties on both hands in addition to sign location (where the sign is articulated relative to the signer's body) and non-manual markers (such as facial expression and body position) \cite{keane2015segmentation, valli1992linguistics}, accurate fingerspelling recognition is a crucial first step in creating comprehensive ASL recognition systems \textcolor{black}{ and is essential for providing DHH individuals with accessible text entry tools.}
While the computer vision community has achieved promising performance in using cameras to detect hands and track finger movements~\cite{aloysius2020understanding, shi2019fingerspelling,hu2020fingertrak}, vision-based approaches are not always portable and raise privacy concerns ( e.g., placing a camera in front of a user's hand is not always feasible.) To address these issues, researchers have explored wearable systems like gloves~\cite{kakoty2018recognition, ahmed2018review, oz2005recognition}, rings~\cite{martin2023fingerspeller,yu2024ring}, and wristbands~\cite{chen2018finger,lee2024echowrist}. However, previous studies suggest that signers prefer for wearable ASL recognition systems to be minimally obtrusive, accurate, and non-disruptive to their natural signing behavior~\cite{kudrinko2022assessing}. Unfortunately, existing wearable ASL systems often fall short in at least one of these areas. Many require bulky hardware~\cite{rizwan2019american, rinalduzzi2021gesture, lee2020sensor, martin2023fingerspeller, singh2023reliable,zhang2018fingerping} that instruments the entire hand or all fingers, which is not practical for everyday use. Furthermore, most systems only recognize isolated manual letters, a significantly easier task for recognition that also forces signers to change their natural signing behavior by pausing between letters while fingerspelling.
\begin{figure}[t]
  \includegraphics[width=0.9\linewidth]{document/figures/variation.png}
  \caption{Handshape variation resulting from coarticulation of adjacent fingerspelled letters: Note that the final `E' appears differently from other occurrences of the same letter, and `I' is coarticulated with `L' (in red). }
  \Description{Handshape variation in fingerspelling due to surrounding letters and individual habits: For example, 'E' and 'I' (marked in red) are represented differently.}
  \label{fig:variation}
\end{figure}
While fingerspelling, signers naturally transition between letters continuously, and individual letters are not always distinct. Moreover, the handshape and other properties of a letter may vary depending on articulatory properties of neighboring letters within the word \cite{keane2015segmentation}. As shown in Figure ~\ref{fig:variation}, the same signer may produce different handshapes for the letter ‘E’ within a single word, such as in B-E-L-I-E-V-E; similarly, ‘I' differs from its standard form due to coarticulation with the preceding ‘L'. Accounting for this natural variation complicates continuous fingerspelling recognition. Given these challenges, the central research question we address in this paper is:
\begin{itemize}
    \item Can we design a minimally obtrusive wearable system that can continuously recognize fingerspelled strings without changing signers' behaviors?
\end{itemize}

To tackle this challenge, we introduce \theDevice{}, a deep-learning-powered ring capable of recognizing 1,164 continuously fingerspelled words~\cite{mackenzie2003phrase} without altering signers' fingerspelling behavior. \theDevice{} is a single ring worn on the thumb, utilizing two sensing modalities to capture subtle variations in handshape and movement. The first modality is active acoustic sensing, where a microphone and speaker pair embedded in the ring detect the shape of the entire hand (including all fingers), as demonstrated in~\cite{yu2024ring}. The second is inertial sensing with a gyroscope, which tracks finger motion and helps distinguish between letters with similar handshapes but different palm orientations or movements (e.g., ‘K’ and ‘P’, ‘I’ and ‘J’) \cite{zhang2017fingorbits,zhang2017fingersound}. For instance, ‘K’ and ‘P’ involve identical handshapes but different palm orientations — for ‘K' the palm faces the interlocuter (outward), while for `P' the palm faces downward. The data from these sensors are fused and processed through a custom data processing pipeline and \textcolor{black}{multimodal} deep-learning model incorporating Connectionist Temporal Classification (CTC)~\cite{graves2012connectionist}, which allows the system to recognize English words from a time series of continuous fingerspelling. This algorithm enables the system to recognize words without the need to label individual letters. 

To understand how \theDevice{} performs with signers, we conducted two user studies with 20 participants, focusing on word-level recognition and real-time phrase-level recognition of the system across several days. In both studies, participants naturally fingerspelled words. In Study 1, we evaluated word-level fingerspelling recognition with 9 participants, including 5 ASL learners and 4 fluent signers, collecting approximately 40 hours of data (20,952 words) with an average accuracy of 89.8\%, where recognition for ASL learners (M = 94.38\%, SD = 4.28\%) outperformed that for fluent signers (M = 84.06\%, SD = 9.26\%). In Study 2, we assessed phrase-level fingerspelling recognition with 11 participants in real-time, collecting about 45 hours of training data and testing 100 phrases over approximately 20 hours. The Word Error Rate (WER) was 0.099 (SD = 0.039) with the aid of a language model. After Study 2, a qualitative survey revealed that most participants (N=8) were satisfied with \theDevice{}’s real-time performance. Based on these findings, we provide design recommendations for improving interaction and algorithm development to enhance usability for DHH individuals.

\begin{table*}[t]
\caption{Comparison with Previous Work: \textcolor{black}{ "O" indicates a real-time system, while "X" indicates no real-time capability. Note that SpellRing is a single ring that enables continuous real-time fingerspelling recognition, as evaluated by DHH users.}}
\Description{Comparison with Other Previous work}
\begin{tabular}{r|c|c|c|c|c|c}
\hline
     & \textbf{\textcolor{black}{Evaluation Set}} & \textbf{Form factor} & \textbf{Types} & \textbf{Real-time} & \textbf{Acc.} & \textbf{\# of signers}            \\ \hline
Jani, et al.    \cite{jani2018sensor} & 26 ASL letters   & Data Glove           & isolated       & \textcolor{black}{"O"}                 & 96.5\%       & 8 (N/A)                                    \\ \hline
Yoon, et al. \cite{yoon2012adaptive}   & 24 ASL letters   & 5DT DataGlove        & isolated       & \textcolor{black}{"O"}                       & 91.1\%       & 5 (N/A)                                    \\ \hline
  Savur, et al. \cite{savur2016american}  & 26 ASL letters   & Myo Armband          & isolated       & \textcolor{black}{"O"}                       & 60.8\%       & 10 (all DHH)                                   \\ \hline
 Saquib, et al. \cite{saquib2020application}   & 26 ASL letters   & Data Glove           & isolated       & \textcolor{black}{"O"}                      & 96.0\%         & 5 (N/A)                                \\ \hline
  Lee, et al. \cite{lee2020sensor}   & 27 words         & IMUs on fingertips   & continuous     & \textcolor{black}{"X"}                       & 99.8\%       & 12 (All ASL Learners)                   \\ \hline
  Martin, et al. \cite{martin2023fingerspeller}   & 1164 words       & 5 smart rings        & continuous     & \textcolor{black}{"X"}                   & 91.0\%         & 3 (1 DHH, 2 Experienced)    \\ \hline
SpellRing & 1164 words       & Single ring          & continuous     & \textcolor{black}{"O"}                      & 82.5\%       & 20 (13  DHH, 7 ASL Learners) \\ \hline
\end{tabular}
\end{table*}
\label{table:1}


The contributions of this paper are:
\begin{itemize}
  \item \textcolor{black}{The first wearable-based real-time ASL fingerspelling recognition system that fuses active acoustic sensing with IMU on a ring.}

  \item A multimodal deep-learning pipeline that integrates active acoustic sensing and motion data for continuous fingerspelled word recognition, using Connectionist Temporal Classification (CTC) loss.

  \item A comprehensive evaluation involving 20 ASL signers (13 fluent signers and 7 ASL learners), demonstrating the system's performance across a range of signing experiences, speeds, and personal habits.

  \item A discussion on the opportunities and challenges in designing AI-powered wearables to support DHH individuals in ASL communication.
\end{itemize}










