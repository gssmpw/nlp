
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{floatrow}
\usepackage{caption}

\newfloatcommand{capbtabbox}{table}[][\FBwidth]

\title{MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
Hanzhuo Huang\textsuperscript{1}\thanks{Equal contribution.},~~
Yuan Liu\textsuperscript{2$\ast$},~~
Ge Zheng\textsuperscript{1},~~
Jiepeng Wang\textsuperscript{3},~~
Zhiyang Dou\textsuperscript{3},~~
Sibei Yang\textsuperscript{1}\thanks{Corresponding author.}\\
\textsuperscript{1}ShanghaiTech University,~~
\textsuperscript{2}The Hong Kong University of Science and Technology,~~\\
\textsuperscript{3}The University of Hong Kong~~
\\
\texttt{\{huanghzh2022, zhengge2023, yangsb\}@shanghaitech.edu.cn},~~\\
\texttt{yuanly@ust.hk},~~\texttt{\{jiepeng, zhiyang0\}@connect.hku.hk}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\newcommand{\tr}[1]{\textcolor{red}{#1}}
\newcommand{\tb}[1]{\textcolor{blue}{#1}}
\newcommand{\methodname}{MVTokenFlow\ }

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
In this paper, we present \methodname for high-quality 4D content creation from monocular videos. Recent advancements in generative models such as video diffusion models and multiview diffusion models enable us to create videos or 3D models. However, extending these generative models for dynamic 4D content creation is still a challenging task that requires the generated content to be consistent spatially and temporally. To address this challenge, \methodname utilizes the multiview diffusion model to generate multiview images on different timesteps, which attains spatial consistency across different viewpoints and allows us to reconstruct a reasonable coarse 4D field. Then, \methodname further regenerates all the multiview images using the rendered 2D flows as guidance. The 2D flows effectively associate pixels from different timesteps and improve the temporal consistency by reusing tokens in the regeneration process. Finally, the regenerated images are spatiotemporally consistent and utilized to refine the coarse 4D field to get a high-quality 4D field. Experiments demonstrate the effectiveness of our design and show significantly improved quality than baseline methods. Project page: \href{https://soolab.github.io/MVTokenFlow}{https://soolab.github.io/MVTokenFlow}.
\end{abstract}

\input{tex/1_intro}
\input{tex/2_rw}
\input{tex/3_Preliminaries}
\input{tex/4_method}
\input{tex/5_experiment}


\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\input{tex/6_appendix}


\end{document}
