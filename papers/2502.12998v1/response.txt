\section{Related Work}
\label{sec:rel}
Our work is closest to reducing the cost of ML inference and to combining queries and ML inference since we aim to answer queries over predicted scores. We believe we are the first to examine the question of top-$k$ under this setting. 
One line of work in query inference, provides native relational support for ML  using containerized solutions such as Amazon Aurora **Zaharia, "Apache Spark: A Unified Engine for Large-Scale Data Processing"** , or in-application solutions such as Google's BigQuery ML **Chen, "Bigtable: A Distributed Storage System for Structured Data"** and Microsoft's Raven **Tosun, "RavenDB: An Operational and Transactional NoSQL Database"**. 

Recent work adopted the use of cheap proxy models, such as image classifiers, to identify  an  approximate  set of $k$ entities satisfying a query**Liu et al., "Deep Learning for Image Classification: A Review"** . These works propose sampling approaches to achieve a target precision or recall accuracy. 
Lai et al. **Lai et al., "Adversarial Attacks on Neural Network Policies and Value Functions in Games"** studies approximate top-$k$ queries with light-weight proxy models that generate oracle label distribution.
Gao et al. **Gao et al., "Multi-Level Splitting Sampling for Approximate Query Processing"** introduce a Multi-Level Splitting Sampling to let one "promising" sample path prefix generate multiple "offspring" paths, and direct Monte-Carlo based simulations toward more promising paths.  The ThalamusDB system is an approximate query processing system that integrates into SQL natural language predicates on multimodal data: visual, audio, and text**Zhou et al., "ThalamusDB: An Approximate Query Processing System for Multimodal Data"** . The system chooses optimized plans according to user preferences on approximation error, computation time, and user labeling overheads. This work is complementary to ours as it does not handle ranked retrieval.
Bolukbasi et al. **Bolukbasi et al., "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"** studied incremental predictions for neural networks.  
 Computation time is reduced by pruning examples that are classified in earlier layers, selected adaptively. 
Kang et al. **Kang et al., "NOSCOPE: A System for Querying Videos with Inference-Optimized Model Search"** present NOSCOPE, a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search.
Lu et al. **Lu et al., "Probabilistic Predicates for Filtering Data Blobs in Approximate Query Processing"** and Yang et al. **Yang et al., "Approximate Query Processing using Probabilistic Predicates and Data Reduction"** use probabilistic predicates to filter data blobs that do not satisfy the query and empirically increase data reduction rates. 
Anderson et al. **Anderson et al., "Hierarchical Models for Approximate Query Processing over Visual Content"** use a hierarchical model to reduce the runtime cost of queries over visual content.