\begin{abstract}
This work studies the applicability of expensive external oracles (e.g., deep neural networks, large language models) in answering top-$k$ queries over predicted scores. Such scores are incurred by user defined scoring functions over multi-modal data. We propose a generic computational framework that handles arbitrary set based scoring functions, as long as the  functions could be decomposed into constructs, each of which could be sent to an oracle to predict partial scores. At a given point in time, the framework assumes a set of responses and their partial predicted scores, and it maintains a set of possible sets that are likely to be the true top-$k$. Since calling oracles is costly, our framework judiciously identifies the next construct, i.e., the next best question, to be asked to the oracle such that the response to this question has the maximum likelihood of identifying the true top-$k$. We model an oracle's response to be deterministic or probabilistic and propose a principled probabilistic model that quantifies the likelihood of a candidate set to be the true top-$k$ to identify the next best question. We study a suite of efficiency opportunities in designing different tasks in our framework. We run an evaluation with multiple datasets, scoring functions, and  appropriate baselines. Our experimental results corroborate our theoretical analysis.
\end{abstract}