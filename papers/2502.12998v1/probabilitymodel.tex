\section{Proposed Framework}\label{sec:framework}
Depending on the scoring function $\mathcal{F}$ the framework identifies one, several, or all candidate top-$k$ sets as answers to a query $q$. Wlog, we assume a set $C$ of $m$ such candidate sets and present $4$ essential tasks to solve our problem.
%Using the running example, two possible candidates could be: 
     %   \[
     %   c_1 = \{\text{HNY, MLN, HYN}\}, \quad c_2 = \{\text{MLN, HYN, WLD}\}
     %   \]
     %%   Hence, we can define the candidates' set C as follows:
     %   \[
     %   C = \{c1, c2\}
     %   \]

\noindent {\bf Task 1. Computing Score Bounds of Candidate Sets.}
At a given point in time, only the partial score of a candidate $c \in C$ is known. 

\noindent {\bf Technical Problem: Lower and upper bounds of score of $c$.} 
Given $\mathcal{F}$, and known information $Q_K$, compute the lower (resp. upper) bound of score of $c$ as the smallest (resp. largest) score of $c$.

Considering our example, to find the lowest and highest possible scores of $c_1$, we should replace known values from \autoref{tab:ny_hotels_relevance} and \autoref{tab:ny_hotels_diversity} in $\mathcal{F}_{\text{min}}(c_1, q)$ and $\mathcal{F}_{\text{max}}(c_1, q)$ and substitute unknown values in the formula with minimum and maximum possible response values, which are assumed to be $0$ and $1$ respectively. Therefore, we can compute the minimum and maximum overall scores of $c_1$ as follows:
\[
\mathcal{F}_{\text{min}}(c_1, q) = Rel(\text{HNY},q) + Rel(\text{MLN},q) + 0 + Div(\text{HNY, MLN}) + 0 + 0
\]
\[
\mathcal{F}_{\text{min}}(c_1, q) = 0.5 + 1.0 + 0 + 0.5 + 0 + 0 = 2.0
\]

\[
\mathcal{F}_{\text{max}}(c_1, q) = Rel(\text{HNY},q) + Rel(\text{MLN},q) + 1 + Div(\text{HNY, MLN}) + 1 + 1
\]
\[
\mathcal{F}_{\text{max}}(c_1, q) = 0.5 + 1.0 + 1 + 0.5 + 1 + 1 = 5.0
\]

Hence, the lower bound (LB) and upper bound (UB) of \( c_1 \) are:
\begin{align*}
    (\text{LB, UB})_{c_1} &= (2.0, 5.0)
\end{align*}
    
\noindent {\bf Task 2: Probabilistic Model for Finding the Answer.} 
 Given a set $\mathcal{C}$ of $m$ candidate top-$k$ sets, the probability $P(c)$ represents that candidate $c$ is the answer ($c^*$) of the query.
 
\noindent{\bf Technical Problem:} The probability of a candidate $c$ being the query answer $c^*$ is:
 \begin{align}\label{eq:prob}
    P(c = c^*) &= P\left(\bigcap_{c_j \in \mathcal{C}} \mathcal{F}(c, q) \geq \mathcal{F}(c_j, q)\right)
\end{align}

%There are two possible scenarios.

\noindent{\bf Independence among candidates.}
In the simplest case, each candidate has unique entities with no entity in common across any two candidates. The joint probability could be calculated as:

\begin{align}\label{eq:ind}
P(c = c^*) &= \prod_{i=1}^{M} P\left(\mathcal{F}(c, q) \geq \mathcal{F}(c_i, q)\right)
\end{align}

\noindent{\bf Dependence among candidates.}
When there exist entities that are common across multiple candidates, the probabilistic model capturing a candidate being the winner (or query answer) needs to account for conditional probabilities, as follows:

%\textcolor{red}{put this in align environment and give it an equation no}

\begin{align}\label{eq:joint}
P(c = c^*) = \prod_{i=1}^{M} P\left(\mathcal{F}(c, q) \geq \mathcal{F}(c_i, q) \mid \bigcap_{j=1}^{i-1} \left( \mathcal{F}(c, q) \geq \mathcal{F}(c_j, q) \right) \right)
\end{align}

Equation~\ref{eq:joint} takes the following form once expanded.
\begin{align}\label{eq:jointexpand}
P(c = c^*) &= P\left(\mathcal{F}(c, q) \geq \mathcal{F}(c_1, q)\right) \times \notag \\
& \quad P\left(\mathcal{F}(c, q) \geq \mathcal{F}(c_2, q)  \mid \mathcal{F}(c, q) \geq \mathcal{F}(c_1, q) \right) \times \notag \\
& \quad \ldots \times P\left( \mathcal{F}(c, q) \geq \mathcal{F}(c_M, q) \mid \mathcal{F}(c, q) \geq \mathcal{F}(c_1, q), \right. \notag \\
& \quad \quad \left. \mathcal{F}(c_2, q) \geq \mathcal{F}(c_2, q), \mathcal{F}(c_2, q) \geq \mathcal{F}(c_3, q), \right. \notag \\
& \quad \quad \left. \ldots, \mathcal{F}(c, q) \geq \mathcal{F}(c_{M-1}, q)\right)
\end{align}





\begin{comment}
This formula is basically a multiplication of probabilities of the following type:
\[
P(\mathcal{F}(c, q) \geq \mathcal{F}(c_i, q) \mid \bigcap_{j=1}^{i-1} \left( \mathcal{F}(c, q) \geq \mathcal{F}(c_j, q) \right))
\]


    Hence, We need to compute probabilities of the following form:

\[
P(f(c_1) \geq f(c_2) \mid \text{conditions})
\]

This probability represents the likelihood that candidate \( c_1 \) scores higher than candidate \( c_2 \), given a set of constraints imposed by previous comparisons between candidates.

To compute this probability, we can rewrite it as follows:
\[
P(f(c_1) > f(c_2) \mid \text{constraints}) = \frac{p((f(c_1) \geq f(c_2)) \land \text{constraints})}{p(\text{constraints})} 
\]
\[
= \frac{n((f(c_1) \geq f(c_2)) \land \text{constraints})}{n(\text{constraints})}
\]

Where the denominator represents the size or number of all possible score assignments to candidates that satisfy given constraints. Similarly, the numerator is just the size of a subset of scoring assignments of the denominator that capture the additional constraint: \( f(c_1) \geq f(c_2) \). 
\end{comment}

Using our running example, 
\begin{align*}
P(c_2= c^*) &= P\left(\mathcal{F}(c_2, q) \geq \mathcal{F}(c_1, q)\right) \times \notag \\
& \quad P\left(\mathcal{F}(c_2, q) \geq \mathcal{F}(c_3, q) \mid \left( \mathcal{F}(c_2, q) \geq \mathcal{F}(c_1, q) \right)\right) 
\end{align*}


\begin{comment}
    In section \ref{winning_probability}, we will elaborate how we compute candidates winning probabilities using the above formula. Given the running example, assuming we only have $c_1, c_2$, and $c_3$ as the candidates, after computing winning probability distribution function, we will have:

\[
P(c = c^*) =
\begin{cases} 
0.75 & \text{ } c = c_1, \\
0.24 & \text{ } c = c_2, \\
0.01 & \text{ } c = c_3.
\end{cases}
\]
\end{comment}



%{\color{blue} The notion of constraint is too abstract.}
%\textcolor{red}{Sohrab: just write the value: Using the running example, $P(c_1)=xx$, such that $c_1=c*$.}

\noindent {\bf Task 3: Determining the Next Question.} 
For a candidate $c$,  $P(c)$ represents the probability of $c$ being the answer. Given the set of candidates $C$, the actual answer $c^*$ is thus a random variable with probability distribution $\mathcal{A}$, representing the probability of each candidate being the answer.
 \begin{definition}
     {\bf Uncertainty in $\mathcal{A}$.} The uncertainty in $c^*$ is modeled as the entropy~\cite{renyi1961measures} in $\mathcal{A}$, as follows:
    \begin{align*}
    H(\mathcal{A}) &= - \sum_{c \in \mathcal{C}} P(c) \log(P(c))
\end{align*}
where $P(c)$ is the probability of candidate $c$ to be the query answer. 
 \end{definition}

\noindent{\bf Technical Problem: Selecting the next best question.} Let $H(\mathcal{A})$ be the entropy associated with the query answer $c^*$. When $Q \in Q_U$ is provided by the oracle, let $H(\mathcal{A'})$ be the reduced entropy, select $Q \in Q_U$ such that $H(\mathcal{A}) - H(\mathcal{A'})$ is maximized. In other words, maximizing the difference between $H(\mathcal{A}) - H(\mathcal{A'})$ is equivalent to minimizing  $H(\mathcal{A'})$. Entropy measures the uncertainty associated with the query answer - thus, minimizing this enhances predictability. In fact, when the entropy is $0$, the query answer could be decided with complete certainty.

Using our running example with the three candidates, $C = \{c_1, c_2, c_3\}$, the associated entropy is $0.604$.

\begin{comment}
    \begin{align*}
    H(\mathcal{A}) &= - (p_{c_1} \log(p_{c_1}) + p_{c_2} \log(p_{c_2}) + p_{c_3} \log(p_{c_3}))
    \end{align*}


\[
    H(c^*) \approx \text{0.604}
\]
\end{comment}


In Section~\ref{subsec:nextquestion}, we will propose algorithms that select the next question to ask s.t. entropy is minimized. Minimizing entropy will minimize uncertainty in finding the query answer $c^*$. Given the running example, we shall show that our solution will choose $Q = Div(HNY, MLN)$ as the next question. Given the LLM returns $Div(HNY, MLN) = 1$, $H(c^*) = 0$ and $c_1$ becomes the query answer.


\noindent {\bf Task 4: Response Processing.} The final task is to process the obtained response from the oracle. There are two obvious possibilities: a. the oracle returns a discrete value, b. the oracle returns a range. There are also other types of responses such as aggregating multiple discrete oracle responses, or aggregating multiple oracle responses each providing a range. 

We study the first case closely in this work. In Section~\ref{subsec:resp}, we discuss how a discrete response (e.g., 0.7) from a single oracle is processed. In Section~\ref{sec:ext}, we discuss other alternatives and how they could be adapted.


%\textcolor{red}{comment from Sohrab: I think the following technical problem definition is for task 2. Task 4 doesn't update bounds. just processes responses from expert(s). since we have mentioned here we study first case closely and discuss others in section 7, maybe no running example is needed here? because first case is simply single expert single response so no further processing is needed. The example i have mentioned for this task in next section is for multiple experts discrete values.  }

%\noindent{\bf Technical Problem: Response processing.} 
%Given $\mathcal{F}$ and the newly acquired response $Q_r$, update score bounds of $C$.

%\textcolor{red}{Sohrab: just write the value: Using the running example, write the task if a specific answer is obtained.}

