%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%

\documentclass[sigconf]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{10.1145/3696410.3714758}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[WWW '25] {Proceedings of the ACM Web Conference 2025}{April 28--May 2, 2025}{Sydney, NSW, Australia.}
\acmBooktitle{Proceedings of the ACM Web Conference 2025 (WWW '25), April 28--May 2, 2025, Sydney, NSW, Australia}
\acmISBN{979-8-4007-1274-6/25/04}

\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{bbm}
\usepackage{array}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{newfloat}
\usepackage{listings}

\usepackage{colortbl}
\usepackage{color}
% \usepackage{subfig}
\usepackage{subfigure}
\usepackage{stfloats}

%LATER added
\newcommand{\Lapl}{\mathbf{\mathop{\mathcal{L}}}}
\newcommand{\lapl}{\mathcal{L}}
\newcommand{\Trans}[1]{{#1}^{\top}}
\newcommand{\Trace}[1]{tr\left({#1}\right)}
\newcommand{\Bracs}[1]{\left({#1}\right)}
\newcommand{\Mat}[1]{\mathbf{#1}}
\newcommand{\MatS}[3]{\mathbf{#1}^{#2}_{#3}}
\newcommand{\Space}[1]{\mathbb{#1}}
\newcommand{\Set}[1]{\mathcal{#1}}
\newcommand{\vectornorm}[1]{\left|\left|#1\right|\right|}
\newcommand{\std}[1]{\scriptsize{$\pm$#1}}
\newcommand{\boldit}[1]{\textbf{\textit{#1}}}
\newcommand{\ie}{\textit{i.e., }}
\newcommand{\eg}{\textit{e.g., }}
\newcommand{\ifff}{\textit{iff. }}
\newcommand{\etal}{\textit{et al.}}
\newcommand{\st}{\textit{s.t. }}
\newcommand{\etc}{\textit{etc.}}
\newcommand{\wrt}{\textit{w.r.t. }}
\newcommand{\cf}{\textit{cf. }}
\newcommand{\aka}{\textit{aka. }}

% \definecolor{darkgreen}{RGB}{34, 139, 34}
\definecolor{darkgreen}{RGB}{30, 110, 30}
\definecolor{myred}{RGB}{220, 0, 0}
\newcommand{\cred}[1]{{\color{myred}{#1}}}
\newcommand{\cgreen}[1]{{\color{darkgreen}{#1}}}

\usepackage{multirow}
\usepackage{makecell}
\usepackage{diagbox}

\usepackage{pifont}
\usepackage{booktabs}
\newtheorem{assumption}{Assumption}[section] 
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{problem}{Problem}
\newtheorem{principle}{Principle}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Unleashing the Power of Large Language Model for Denoising Recommendation]{Unleashing the Power of Large Language Model \\ for Denoising Recommendation}



\author{Shuyao Wang}
\affiliation{%
    \institution{School of Data Science, University of Science and Technology of China}
    \city{Hefei}
    \country{China}}
\email{shuyaowang@mail.ustc.edu.cn}

\author{Zhi Zheng}
\authornotemark[1]
\affiliation{%
  \institution{State Key Laboratory of Cognitive Intelligence, University of Science and Technology of China}
    \city{Hefei}
    \country{China}}
\email{zhengzhi97@ustc.edu.cn}

% State Key Laboratory of Cognitive Intelligence,
% School of Computer Science and Technology,
% University of Science and Technology of China (USTC),
% USTC Hi-Tech Zone Camp.
% Shushan Dist., Hefei, Anhui
% E-mail: zhengzhi97@ustc.edu.cn
\author{Yongduo Sui}
\affiliation{%
  \institution{Tencent}
    \city{Shenzhen}
    \country{China}}
\email{yongduosui@tencent.com}


\author{Hui Xiong}
\authornote{Corresponding authors.}
\affiliation{%
    \institution{Thrust of Artificial Intelligence, The Hong Kong University of Science and Technology (Guangzhou)}
    \institution{Department of Computer Science and Engineering, The Hong Kong University of Science and Technology}
    \city{Hong Kong SAR}
    \country{China}}
\email{xionghui@ust.hk}

\renewcommand{\shortauthors}{Shuyao Wang, Zhi Zheng, Yongduo Sui, \& Hui Xiong}
%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}

Recommender systems are crucial for personalizing user experiences but often depend on implicit feedback data, which can be noisy and misleading. 
Existing denoising studies involve incorporating auxiliary information or learning strategies from interaction data. However, they struggle with the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, hindering accurate noise identification. 
Recently, large language models (LLMs) have gained attention for their extensive world knowledge and reasoning abilities, yet their potential in enhancing denoising in recommendations remains underexplored. 
In this paper, we introduce LLaRD, a framework leveraging LLMs to improve denoising in recommender systems, thereby boosting overall recommendation performance. 
Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data via LLMs and inferring user-item preference knowledge. 
It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to reveal relation knowledge for denoising. Finally, it applies the Information Bottleneck (IB) principle to align LLM-generated denoising knowledge with recommendation targets, filtering out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's effectiveness in enhancing denoising and recommendation accuracy.
The code is available at https://github.com/shuyao-wang/LLaRD.

% Recommender systems are vital for personalizing user experiences, yet they often rely on implicit feedback data that can be noisy and misleading. 
% Existing denoising studies typically involve either incorporating auxiliary information or learning denoising strategies from interaction data. Nonetheless, they face challenges due to the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, which hinder their ability to accurately identify noise.
% Recently, large language models (LLMs) have garnered significant attention due to their extensive world knowledge and powerful reasoning capabilities. 
% Despite this, the potential of LLMs to enhance the denoising process in recommendations remains largely unexplored.
% In this paper, we introduce LLaRD, a novel framework that leverages LLMs to improve the denoising process in recommender systems, thereby enhancing overall recommendation performance.
% Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data through LLMs, facilitating a comprehensive inference of user-item preference knowledge.
% It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to uncover relation knowledge pertinent to denoising.
% Finally, it utilizes the Information Bottleneck (IB) principle to align the denoising knowledge generated by LLMs with the recommendation targets, effectively filtering out both data noise and irrelevant knowledge produced by the LLMs.
% Empirical results demonstrate the effectiveness of our proposed framework, showcasing its superior performance in denoising and recommendation accuracy. 
% The code is available at https://github.com/shuyao-wang/LLaRD.

\begin{figure}[t]
\centering
\includegraphics[width=0.98\linewidth]{teaser.pdf}
\vspace{-2mm}
\caption{(a) An intuitive example of learning user preferences from observational data.
(b) Improvements of our method (\cred{red}) over existing methods (\cgreen{dark green}).}
\label{fig:teaser}
\vspace{-2mm}
\end{figure}

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003331.10003271</concept_id>
<concept_desc>Information systems~Personalization</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Personalization}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Large Language Models; Recommendation; Denoising}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle





\section{Introduction}
Recommender systems~\cite{rendle2012bpr,he2020lightgcn,zhang2024temporal,liang2018variational,zheng2022cbr,wang2024dynamic} have become essential for mitigating information overload and delivering personalized services~\cite{sui2024simple,xiao2023contextual,xiao2021c}. High-quality interaction data that accurately reflect user preferences play a crucial role in enhancing the performance of these recommendation models~\cite{zheng2023generative,zheng2022ddr,zheng2021drug}. In the context of limited explicit feedback~\cite{ellis2006implicit,jawaheer2010comparison,zheng2023interaction}, implicit feedback (\eg click, purchase and views) has emerged as a popular alternative due to its abundance and ease of collection~\cite{hu2008collaborative,joachims2017accurately}. However, implicit feedback data are often noisy and influenced by various incidental factors, which can hinder their ability to accurately represent user preferences ~\cite{wang2021implicit,ding2019sampler,sun2021does}. For instance, false positive interactions~\cite{pan2013gbpr,bian2021denoising} may arise from users' curiosity-driven clicks or unsatisfactory purchases, while false negative interactions~\cite{gao2022self} can result from limited exposure or restricted browsing opportunities.

To tackle the challenge of noisy implicit feedback, denoising has become a significant focus in recommendation research, which can be broadly categorized into two main approaches:
1) \textbf{Denoising based on side information}: Initial methodologies~\cite{buscher2009segment,fu2010towards,zhao2016gaze,joachims2017unbiased} exploit user dwell time and gaze patterns, while subsequent research incorporates sequence analysis~\cite{zhang2024ssdrec,zhang2023denoising,han2024efficient,xin2023improving} and knowledge graph integration~\cite{chen2023entity,jiang2024diffkg,zhu2023knowledge,wang2024unleashing,fan2019graph,yang2024graph,xiao2023spatial} to enhance noise detection and modeling of user preferences. Nevertheless, these methods often entail high data collection costs and may introduce extraneous noise~\cite{gao2022self,zhu2023knowledge} due to non-essential attributes or basic graph integration strategies.
2) \textbf{Denoising driven by interaction data}: This category involves employing data selection~\cite{lin2023autodenoise, wang2021denoising, ge2023automated,tolomei2019you} and weighting mechanisms~\cite{wang2021denoising,wang2023efficient} to identify and mitigate noisy interactions, utilizing data features and decision networks~\cite{ge2023automated, lin2023autodenoise}. Such approaches include adaptive training algorithms~\cite{wang2021denoising,kaplan2021unbiased} and sophisticated reweighting methods, which leverage interaction-based priors to effectively diminish noise during the training process.


Despite the effectiveness of interaction data-driven methods, they usually exhibit notable limitations. 
Firstly, they focus on learning user preferences from interaction data to identify noise. However, limited observational data result in only a partial understanding of user preferences, particularly in recognizing interactions that signal new interests or exploration tendencies~\cite{sharma2015estimating,chen2024treatment}. 
For instance, in Figure~\ref{fig:teaser}(a), the pink area represents the user's true preference space \(P\), while the green area denotes the observable preference space \(\hat{P}\). The intersection \(P \cap \hat{P}\) reflects the true preferences inferred from observational data. Interactions deemed as noise often consist of data inconsistent with currently learned preferences. For example, if an art enthusiast accidentally clicks on a gardening video, it may be labeled as noise, but it might indicate a latent interest in gardening sketches. Secondly, some studies rely on predefined assumptions~\cite{wang2022learning,lin2023autodenoise} in the noise identification process.
For instance, \cite{wang2021denoising} judging high-loss samples in training as noise, which inadequately captures user preferences and potential associations during noise identification (\eg links between fine arts and gardening).
Consequently, it will diminish the model's effectiveness in denoising.
To enhance the understanding of user preferences, large language models (LLMs)~\cite{bao2023tallrec,zhang2024text,wu2023survey,zhi2023generative} present a promising direction due to their extensive world knowledge and reasoning capabilities~\cite{xiao2024refound,chen2024tmea,chen2024pog}. Recent studies~\cite{ren2024representation,wei2024llmrec} have explored the application of LLMs in recommendation systems to improve the robustness of user representations by incorporating additional semantic and textual information. 
However, these approaches primarily enhance the semantic richness of representations while they insufficiently leveraging the potential of LLMs for denoising.


To explore the potential of LLMs for denoising in recommendation, we must address several significant challenges.
\begin{itemize}[leftmargin=*,topsep=1.5mm]
\item \textbf{C1: How can LLMs effectively mine information relevant to denoising?}
LLMs excel at processing textual information, allowing us to expand and enrich semantic insights that can inform denoising efforts. However, the interactive data represented in the graph structure of users and items contains rich collaborative information that is also valuable for denoising. Unfortunately, LLMs struggle to process this complex graph data effectively.

\item \textbf{C2: How can we utilize the information generated by LLMs for denoising?}
While LLMs can produce additional knowledge for denoising, they may also generate hallucinations~\cite{yao2023llm}, making direct application potentially suboptimal. Thus, it is crucial to consider how to constrain the knowledge generated by LLMs to align with the specific prediction targets in recommendations.
\end{itemize}

To address these challenges, we propose the \textbf{L}arge \textbf{La}nguage Model-enhanced \textbf{R}ecommendation \textbf{D}enoiser (LLaRD), a novel framework designed to develop recommendation models that are robust to noisy data. LLaRD consists of two main components: a knowledge generation module and a knowledge-enhanced denoising module.
To tackle \textbf{C1}, the knowledge generation module leverages LLMs to extract two types of denoising-related knowledge: 
1) \textbf{Preference knowledge}. Utilizing the inherent world knowledge of LLMs, we enrich the semantic information of the data through the analysis, reasoning, and refinement of text and interaction data. This process extrapolates the scope of observational data and infers user and item preferences more comprehensively.
2) \textbf{Relation knowledge}. We implement a novel chain-of-thought (CoT) prompting strategy~\cite{wei2022chain,xia2024beyond,xia2024chain} over graph structures to expand relation knowledge by iteratively reasoning about connections among users, items, and their neighborhood subgraphs. This approach encourages LLMs to consider key collaborative information hidden within the graph structure, thereby capturing relation knowledge pertinent to denoising.
To address \textbf{C2}, the knowledge-enhanced denoising module is built upon the Information Bottleneck (IB)~\cite{sun2022graph,wu2020graph,wei2022contrastive}. 
It maximizes the mutual information across denoised data, generated knowledge, and recommendation targets, while minimizing the mutual information between the denoised data and the original data. 
This mechanism further filters out knowledge irrelevant to denoising from the information generated by LLMs, reducing the integration of irrelevant information, such as hallucinations, and thereby enhancing denoising performance.
As illustrated in Figure \ref{fig:teaser}(b), we anticipate that LLMs will improve the learning process of the denoising model, enabling it to more accurately capture the trajectory of true user preferences (orange arrow) and extensively encompass the preference area (pink region). In summary, our approach facilitates enhanced denoising by utilizing LLM-driven insights to improve recommendation performance.

The main contributions of this paper are summarized as follows:
\begin{itemize}[leftmargin=*,topsep=1.5mm]
    \item We identify and address the limitations of existing denoising recommendation methods, proposing a novel application of LLMs' world knowledge and reasoning capabilities to enhance the performance of recommendation models.
    \item We introduce LLaRD, a framework that integrates knowledge generation and knowledge-enhanced denoising strategies to leverage the capabilities of LLMs for achieving noise-robust recommendation models.
    \item We validate the effectiveness of LLaRD through extensive experiments on three benchmark datasets and two mainstream backbone models, demonstrating the framework’s superior performance in denoising recommendation.
\end{itemize}


\section{Preliminaries}
\subsection{Denoising Recommendation}
Let the user set be $\mathcal{U} = \{u\}$ and the item set be $\mathcal{I} = \{i\}$, with $|\mathcal{U}|$ and $|\mathcal{I}|$ representing the number of users and items, respectively. The interaction matrix is $\Mat{R} \in \{0, 1\}^{|\mathcal{U}| \times |\mathcal{I}|}$, where $r_{ui} = 1$ indicates that user $u$ has interacted with item $i$. Given the interaction data $\mathcal{D} = \{(u,i, r_{ui}) | u \in \mathcal{U}, i \in \mathcal{I}\}$, we train a recommendation model $f$ with parameters $\theta_f$ to predict the likelihood of user interactions with unseen items, formulated as $\theta_f = \arg\min_{\theta_f} \mathcal{L}_{\textit{rec}}(\mathcal{D})$, where $\mathcal{L}_{\textit{rec}}$ is the recommendation loss.
Using the BPR~\cite{rendle2012bpr} loss as an example, we have:
% \vspace{-1mm}
\begin{equation}
    % \vspace{-2mm}
    \mathcal{L}_{\textit{rec}} = \mathbb{E}_{(u,i,j) \sim \mathcal{D}} \log(\sigma(f(\mathbf{h}_u)^\top f(\mathbf{h}_i)) - f(\mathbf{h}_u)^\top f(\mathbf{h}_j)),
\end{equation}
% \vspace{-1mm}
where $\mathbf{h}_{u/i} \in \mathbb{R}^d$ is the user/item representations, and $\sigma(\cdot)$ is the sigmoid function. The triple $(u, i, j)$ consists of user $u$, positive sample $i$, and negative sample $j$, sampled pairwise from $\mathcal{D}$. 
While $r_{ui} = 1$ typically indicates a positive preference, observed interactions (\eg views, clicks, and purchases) may introduce noise that does not accurately reflect true preferences. The denoising recommendation task aims to learn a clean interaction matrix $\Mat{R}^* \in \{0, 1\}^{|\mathcal{U}| \times |\mathcal{I}|}$ representing users' genuine preferences or to derive noise-free representations $\mathbf{h}_{u/i}^* \in \mathbb{R}^d$ from the noisy data.


\subsection{Information Bottleneck}

The Information Bottleneck (IB) ~\cite{tishby2015deep,wu2020graph,sun2022graph} is a powerful framework rooted in information theory, commonly used for representation learning~\cite{sui2021causal,sui2023unleashing}. Its goal is to enhance the robustness of learned representations for downstream tasks by discarding task-irrelevant information from the input data. We give the following definition:
% \vspace{-4mm}
\begin{definition}[Information Bottleneck]\label{def:1}
Let $X \in \mathcal{X}$ and $Y \in \mathcal{Y}$ be random variables with joint distribution $p(X, Y)$, where $X$ contains information relevant to $Y$. The relevant information is quantified by the mutual information $I(X; Y)$. The IB framework seeks the most informative yet compressed representation $Z$ by optimizing the objective: $\max_{Z} \left\{I(Y; Z), \; \text{s.t.} \; I(X; Z) \leq I_c \right\}$
, where $I_c$ is the information constraint between $X$ and $Z$.
\end{definition}
\vspace{-1mm}
By introducing a Lagrange multiplier $\lambda$, the constrained optimization is reformulated as an unconstrained objective: $\max_{Z} I(Y; Z) - \lambda I(X; Z)$.
The IB principle is widely applied to generalization and denoising tasks. Several studies~\cite{wu2020graph,sun2022graph,sui2025unified} employ the Graph Information Bottleneck (GIB) principle to identify stable subgraphs to enhance model generalization~\cite{sui2024enhancing,sui2024invariant,JCST-2206-12583}, while methods like CGI~\cite{wei2022contrastive} leverage the IB framework for denoising recommendation.

% \subsection{Chain-of-Thought Prompting}
% Chain-of-Thought (CoT) prompting~\cite{wang2022self,wei2022chain,xia2024beyond,xia2024chain} enhances the reasoning capabilities of LLMs by guiding them to generate intermediate reasoning steps structured as $<\text{input}, \text{thoughts}, \text{output}>$ instead of directly producing answers. This approach improves both interpretability and accuracy, particularly for tasks requiring multi-step reasoning or logical deductions.
% \begin{definition}[CoT Prompting]\label{def:cot}
% CoT prompting directs a language model to produce a sequence of intermediate reasoning steps $R$ before generating the final output $Y$, given an input prompt $X$. Mathematically, this framework models the output $Y$ as:
% \begin{equation}\label{equ:cot}
% p(Y|X) = \sum_{R} p(Y|R, X) , p(R|X).
% \end{equation}
% This decomposition transforms complex tasks into manageable sub-tasks, enhancing the reasoning capabilities of model.
% \end{definition}
% By generating structured reasoning steps, CoT prompting enables more accurate and reliable responses in complex tasks.

\section{Methodology}
In this section, we introduce the \textbf{L}arge \textbf{La}nguage Model-enhanced \textbf{R}ecommendation \textbf{D}enoiser (LLaRD). As illustrated in Figure~\ref{fig:model}, it comprises two knowledge generation modules and a denoising module. Below, we provide a detailed overview of each component.

\subsection{\textbf{Preference Knowledge Generation}}
In this module, we extract semantic preference information from textual data and user-item interactions despite inherent data noise. For example, the Amazon-Book dataset includes descriptions with irrelevant attributes, and reader reviews are often subjective and unstructured, featuring imaginative content, citations, or counterfactual statements. These factors complicate the direct extraction of meaningful preference semantics.
To address this issue, we adopt methods from prior studies~\cite{ren2024representation,xi2024towards}, utilizing LLMs for text denoising and preference knowledge reasoning.
We design system prompts \( S_u \) and \( S_i \) for users and items, respectively, and construct configuration texts \( \mathcal{T}_u=\{T_u^1, T_u^2, ..., T_u^{|\mathcal{U}|}\} \) and \( \mathcal{T}_i=\{T_i^1, T_i^2, ..., T_i^{|\mathcal{I}|}\} \) for each user and item as follows:
\begin{equation}
% T_u = [Item\_title] + [Item\_description] + [User\_comments]
T_u^k = \text{Item\_title} \parallel \text{Item\_description} \parallel \text{User\_comments},
\end{equation}
\begin{equation}
% T_i = [Item\_title] + [Item\_category] +[Item\_description]
T_i^k = \text{Item\_title} \parallel \text{Item\_category} \parallel \text{Item\_description}.
\end{equation}
The reasoning process of profile information is defined as:
\begin{equation}
\mathcal{P}_u, \mathcal{P}_i= \text{LLM}([S_u \| {\mathcal{T}_u}], [S_i \| {\mathcal{T}_i}]),
\end{equation}
where $ \text{LLM}(\cdot)$ denotes the LLM reasoning process, $\|$ denotes the concatenation of the system prompt and configuration texts. \(\mathcal{P}_{u}\) and \(\mathcal{P}_{i}\) denote the profile information for each user and item, respectively.
While LLMs effectively refine user preferences and item features, integrating extensive textual knowledge for collaborative analysis across thousands of users and items leads to semantic imprecision and high token inference costs. To mitigate these issues, we propose a keyword condensation technique for each user and item, reducing semantic ambiguity and enabling incremental updates to preference semantics. This approach accommodates the dynamic nature of users and items, ensuring robust and efficient preference extraction.
Furthermore, we enhance system prompts by introducing the $S'_{u/i}$ which guides LLMs to refine the keywords of user preferences and item features based on the obtained profile information $\mathcal{P}_u$ and $\mathcal{P}_i$. 
The keyword generation process is defined as follows:
\begin{equation}
    \mathcal{A}_u, \mathcal{A}_i = \text{LLM}\left([S'_u \| \mathcal{P}_u], [S'_i \| \mathcal{P}_i]\right),
\end{equation}
where $\mathcal{A}_{u}=\{A_{u}^1, A_{u}^2,..., A_{u}^{|\mathcal{U}|}\}$ and $\mathcal{A}_{i}=\{A_{i}^1, A_{i}^2,..., A_{i}^{|\mathcal{I}|}\}$.
We then combine the profile information $\mathcal{P}_{u/i}$ with keywords $\mathcal{A}_{u/i}$to form the preference knowledge $\mathcal{F}_{u/i}$.
The preference knowledge $\mathcal{F}_{u/i}$  is converted into token sequences, resulting in token embedding matrices ${\mathbf{T}}_{u/i}=\{\mathbf{t}_{1}, \mathbf{t}_{2}, ...\}$. These token embeddings  are processed through a multi-layer perceptron (MLP) network $W_t$ to generate semantic embeddings for each user and item:
\begin{equation}
 \tilde{\mathbf{E}}_u, \tilde{\mathbf{E}}_i= W_t(\text{LLM}([{\mathbf{T}}_u, {\mathbf{T}}_i])) + b.
\end{equation}
Finally, we encapsulate the obtained preference semantic embeddings $\tilde{\mathbf{E}}_u$ and $\tilde{\mathbf{E}}_i$ into the preference knowledge $\mathcal{K}_p$ as:
\begin{equation}
\mathcal{K}_p=\left\{\tilde{\mathbf{E}}_u=\{\tilde{\mathbf{e}}_{u1}, \tilde{\mathbf{e}}_{u2}, ...\}, \tilde{\mathbf{E}}_i=\{\tilde{\mathbf{e}}_{i1}, \tilde{\mathbf{e}}_{i2}, ...\}\right\}.
\end{equation}

\begin{figure*}[t]
\centering
\includegraphics[width=0.98\linewidth]{framework.pdf}
\vspace{-3mm}
\caption{The overview of the proposed LLaRD framework.}
\label{fig:model}
\vspace{-2mm}
\end{figure*}

\subsection{\textbf{Relation Knowledge Generation}}
Previous studies utilizing LLMs to infer user preferences from interaction sequences often struggle to capture multi-hop relationships and long-path dependencies essential for understanding complex interactions. In contrast, our approach leverages the reasoning capabilities of LLMs over graph-structured data. By integrating preference semantics with collaborative information, we enable LLMs to identify associative semantics among multiple interaction nodes. Furthermore, we iteratively infer additional interaction edges to construct a relation knowledge graph, enhancing the graph learning process and improving the denoising of implicit feedback.

\subsubsection{\textbf{User-Centric CoT Reasoning Framework.}}
The collaborative information within the user-item interaction graph is invaluable for denoising. However, LLMs often struggle to achieve strong reasoning performance when dealing with complex interconnected data.
To address this, we introduce a user-centric CoT reasoning framework. It meticulously designs inputs for multi-hop interactions within user-centric neighborhoods and analyzes noisy and latent interactions based on semantic associations. By mining associative semantics between multi-hop neighbors through a multi-step reasoning process, we maintain LLM performance despite the complexity and volume of historical data.
Additionally, the LLM is required to provide reasoning foundations and explanatory text when inferring potential interaction edges, enhancing the interpretability and transparency of the decision-making mechanisms. 

\vspace{2mm}
\noindent\textbf{Step1: Preference Ratings.} We represent the preference of each user for items in their interaction sequence using a three-tier rating system: $\{\textit{High, Medium, Low}\}$. 
For a user $u$, given the preference knowledge containing profile information and preference keywords, along with the interaction sequence $\mathcal{N}_u^{(1)}=\{i_1, i_2, ...\}$ and attribute keywords list $A_{i}^{k}$ for each item $i_k$, we follow the steps referring the Figure~\ref{fig:model} for LLM inference.
The output is a rated interaction sequence $\mathcal{N}_u^{Rated}=\{(i_1, l_{ui_1}), (i_2, l_{ui_2}), ...\}$, where $i_k$ denotes an item interacted with by user $u$, and 
$l_{ui_k} \in \{\textit{High, Medium, Low}\}$ represents the user's preference rating for $i_k$. 

\vspace{2mm}
\noindent\textbf{Step2: Noise Identification.} Building on Step 1, we enable the LLM to identify noise among interactions rated as \textit{Low}, denoted by $\mathcal{N}_{u(low)}^{(1)}=\{i_k \in \mathcal{N}_u^{(1)} \mid l_{ui_k}=Low\}$. The set of noise interactions is defined as:
\begin{equation}
    \mathcal{I}_u^{\textit{Noise}} = \{i_k \in \mathcal{N}_{u(low)} \mid \text{LLM identifies } i_k \text{ as noise}\}.
\end{equation}
Consequently, the noise interaction edges for each user are represented by:
\begin{equation}
\mathcal{E}^{\textit{Noise}} = \{(u, i_k) \mid u \in \mathcal{U}, i_k \in \mathcal{I}_u^{\textit{Noise}}\}.
\end{equation}
By rigorously analyzing the semantic associations between user preferences and item attributes, our approach minimizes the misclassification of interactions that may reflect latent user interests. This sophisticated semantic analysis enables the model to discern and retain interactions that, although rated \textit{Low}, may indicate emerging or subtle preferences. 

\vspace{2mm}
\noindent\textbf{Step3: Collaborative Enhancement.}
We perform second-hop neighbor exploration within the neighborhood of user $u$ to identify users with similar preferences,  constructing enhanced collaborative interactions through semantic associations.  Utilizing the preference ratings from Step 1, we focus on items rated as \textit{High}, defined as $\mathcal{N}_{u(high)}^{(1)}=\{i_k \in \mathcal{N}_u^{(1)} \mid l_{ui_k}=High\}$.
The set of second-hop neighbors is then determined by:
$\mathcal{N}_u^{(2)} = \bigcup_{i_k \in \mathcal{N}_{u(\textit{High})}} U_{i_k} \setminus \{u\}$, where $U_{i_k}$ represents users who have interacted with item $i_k$, $\bigcup$ represents the union operation, and $\setminus \{u\}$ ensures that user $u$  is excluded from their own set of neighbors.
Subsequently, we identify collaboratively enhanced users through LLM inference:
\begin{equation}
\mathcal{U}_u^{\textit{Collab}} = \{u_k \in \mathcal{N}_u^{(2)} \mid \text{LLM identifies } u_k \text{ as enhancement}\}.
\end{equation}
The corresponding set of collaborative enhancement interaction edges for each user is represented as:
\begin{equation}
\mathcal{E}^{\textit{Collab}} = \{(u, u_k) \mid u \in \mathcal{U}, u_k \in \mathcal{U}_u^{\textit{Collab}}\}.
\end{equation}
This collaborative enhancement leverages semantic associations to connect users with similar high-preference interactions, thereby enriching the recommendation capability to accurately discern and predict user preferences. 

\vspace{2mm}
\noindent\textbf{Step4: Interests Exploration.}
In this step, we utilize LLM reasoning to explore interests within the third-hop neighborhood of user $u$. 
To prevent an exponential growth of high-order neighbors in the interaction graph, we selectively retain only interaction edges labeled as \textit{High}, emphasizing their importance in accurately reflecting user preferences.
Building on the preference intensities from previous steps and the analysis of first- and second-order neighbors, we infer potential interest interactions among third-order neighbors, defined as: $\mathcal{N}_u^{(3)} = \bigcup_{u_k \in {\mathcal{N}_{u(\text{High})}^{(2)}}} I_{u_k} \setminus \mathcal{N}_u^{(1)}$.
We then identify the set of interest items for user $u$ as:
\begin{equation}
\mathcal{I}_u^{\textit{Interests}} = \{i_k \in \mathcal{N}_u^{(3)} \mid \text{LLM identifies } i_k \text{ as interests}\}.
\end{equation}
The corresponding set of interest interaction edges is represented by:
\begin{equation}
\mathcal{E}^{\textit{Interests}} = \{(u, i_k) \mid u \in \mathcal{U}, i_k \in \mathcal{I}_u^{\textit{Interests}}\}.
\end{equation}
Utilizing our user-centric CoT reasoning framework, we integrated collaborative information from the interaction graph with preference semantics. This integration enabled the identification of potential interactions that accurately reflect users' true preferences and encapsulate associative semantics. Through this multi-step reasoning process, we effectively capture the underlying association semantics, enhancing the ability of discerning and predicting nuanced user preferences and improving recommendation.

\subsubsection{\textbf{Relation Knowledge Construction.}}
To effectively leverage the reasoning results, we construct the above three distinct groups of interaction edges as relation knowledge:
\begin{equation}
    \mathcal{K}_r = \{\mathcal{E}^{\textit{Noise}}, \mathcal{E}^{\textit{Collab}}, \mathcal{E}^{\textit{Interests}}\}.
\end{equation}
Subsequently, we integrate this relation knowledge into the original interaction graph $\mathcal{G}=(\mathcal{U},\mathcal{I},\mathcal{E})$, where $\mathcal{U}$ and $\mathcal{I}$ represent the sets of users and items, respectively, and $\mathcal{E}=\{(u,i)|u \in \mathcal{U}, i \in \mathcal{I}, r_{ui}=1\}$ denotes the existing interaction edges. The enriched interaction graph $\mathcal{G}_{rel}$ is formulated as:
\begin{equation}
\mathcal{G}_{rel} = \left( \mathcal{U}, \mathcal{I}, (\mathcal{E} \setminus \mathcal{E}^{\textit{Noise}}) \cup \mathcal{E}^{\textit{Collab}} \cup \mathcal{E}^{\textit{Interests}} \right).
\end{equation}
This enriched graph incorporates the relation knowledge by removing noise interactions and adding collaborative and interest-based interactions. This integration enhances the downstream denoising learning process, enabling more accurate and semantically rich preference extraction.

\subsection{Knowledge-enhanced Denoising}
After generating denoising knowledge, it is essential to use this to guide the denoising process. To achieve this, we propose a knowledge-enhanced denoising learning approach. As illustrated in the lower half of Figure~\ref{fig:model}, this approach includes a mask generator and a knowledge-guided information bottleneck framework.

\subsubsection{\textbf{Mask Generator}}
To effectively capture comprehensive user preferences and latent semantic associations within the graph structure, we incorporate additional injected knowledge. This enhanced understanding facilitates data selection, reweighting, and representation learning, enabling a robust recommendation model even when denoising is limited to observed data.
We employ a mask generator to create a learnable mask that distinguishes noisy interaction edges from informative ones in the original interaction data. Specifically, given the interaction graph $\mathcal{G}=(\mathcal{V}, \mathcal{E})$, where $\mathcal{V}=\mathcal{U} \cup \mathcal{I}$ and $\mathcal{E}=\{(u,i)|u \in \mathcal{U}, i \in \mathcal{I}, r_{ui}=1\}\}$, each edge is associated with a random variable $q \sim \text{Bernoulli}(\lambda)$. An edge is retained if $q=1$ and deleted otherwise.
We parameterize the Bernoulli parameter $\lambda$ using a MLP network $\Phi$ as $\lambda = \Phi(\mathbf{e}_u \| \mathbf{e}_i)$, where $\|$ denotes concatenation, and $ \mathbf{e}_u, \mathbf{e}_i \in \mathbb{R}^d$ are the embeddings of user $u$ and item $i$ from the original interaction graph $\mathcal{G}$.
To enable end-to-end training, we adopt the Gumbel-Softmax reparametrization trick, converting the discrete variable $q$ into a continuous variable in the range $[0, 1]$: 
\begin{equation}
q = \sigma((\log\delta - \log(1 - \delta) + \lambda_m) / \tau),
\end{equation}
% $q = \text{sigmoid}((\log\delta - \log(1 - \delta) + \lambda_m) / \tau)$, 
where $\tau$ is the temperature hyperparameter and $\delta \sim \text{Uniform}(0, 1)$.
As ${\tau} \rightarrow 0$, $q$ approaches a binary value. Finally, we obtain the masked graph $\mathcal{G}^{\prime}=(\mathcal{U}, \mathcal{I}, \mathcal{E}^{\prime})$, where $\mathcal{E}^{\prime} = \{(u, i) \mid (u, i) \in \mathcal{E}, q_m \rightarrow 1\}$. This denoised graph retains only the informative interaction edges deemed relevant by the mask generator, thereby enhancing the downstream denoising learning process.
\subsubsection{\textbf{Knowledge-guided Information Bottleneck for Denoising.}}
Building on the Information Bottleneck (IB) principle, we present an optimization framework for denoising interaction graphs. Our dual objectives are to maximize the retention of user preference information in the denoised graph and to minimize the mutual information between the denoised and original graphs. To comprehensively capture true user preferences, we integrate supervisory signals from interaction data with additional knowledge from LLMs, encompassing both explicit preferences and latent semantic associations. This combined approach effectively guides the denoising process.
The optimization objective is formally expressed as:
\begin{equation}\label{equ:IB} 
\max_{\mathcal{G}^{\prime}} I(\mathcal{R}; \mathcal{G}^{\prime}) + \alpha I(\mathcal{K}_p, \mathcal{K}_r; \mathcal{G}^{\prime})- \beta I(\mathcal{G}^{\prime}; \mathcal{G}),
\end{equation}
where $I(\mathcal{R}; \mathcal{G}^{\prime})$ denotes the mutual information between recommendation targets $\mathcal{R}$ and the denoised graph $\mathcal{G}^{\prime}$. $I(\mathcal{K}_p, \mathcal{K}_r; \mathcal{G}^{\prime})$ incorporates the mutual information between preference knowledge $\mathcal{K}_p$ relation knowledge $\mathcal{K}_r$, and the denoised graph $\mathcal{G}^{\prime}$
integrating additional supervisory signals from LLMs.
$I(\mathcal{G}^{\prime}; \mathcal{G})$ denotes the mutual information between the denoised graph $\mathcal{G}^{\prime}$ and the original graph $\mathcal{G}$ 
Here, $\alpha$ and $\beta$ are the hyperparameters that balance the influence of knowledge integration and noise reduction, respectively.
Next, we detail the implementation of each term in Equation~\eqref{equ:IB}.

\vspace{1mm}
\noindent\textbf{Term1: Maximizing Mutual Information with Recommendation Information.} 
The first term aims to maximize information relevant to the recommendation task.
We maximizes mutual information with the task-related information within $\mathcal{G}^{\prime}$ by minimizing the BPR loss:
\begin{equation}\label{loss:rec}
    \mathcal{L}_{rec} = \sum_{(u,i,j) \in \mathcal{D}} -\log \sigma({y}_{ui}^{\prime} - {y}_{uj}^{\prime}) \quad {y}_{ui}^{\prime} = \mathbf{h}_u^{{\prime}\top} \mathbf{h}_i^{\prime},
\end{equation}
where $\mathcal{D} = \{(u,i,j)|(u,i) \in \mathcal{D}^+, (u,j) \in \mathcal{D}^-\}$ is the training set, $\mathbf{h}_{u/i}$ and $\mathbf{h}_{u/i}^{\prime}$ are the user and item representations after $L$ GNN layers on $\mathcal{G}^{\prime}$.
Minimizing $\mathcal{L}_{rec}$ effectively maximizes $I(\mathcal{R}; \mathcal{G}^{\prime})$, ensuring that the denoised graph retains essential preference information from recommendation prediction.



\vspace{1mm}
\noindent\textbf{Term2: Preference \& Relation Knowledge Integration.}
The second term promotes retaining information in the denoised graph $\mathcal{G}^{\prime}$ that integrate with both preference knowledge $\mathcal{K}_p$ and relation knowledge $\mathcal{K}_r$. 
Given the collaborative embeddings $\mathbf{e}_u$ and the preference knowledge embedding $\tilde{\mathbf{e}}_u$ and $\tilde{\mathbf{e}}_i$ from $\mathcal{K}_p$, our optimization objective uses the InfoNCE~\cite{gutmann2010noise} loss to denote:
\begin{equation}\label{loss:prf}
\mathcal{L}_{prf} = \sum_{v \in \mathcal{V}} -\log \frac{\exp(\text{sim}(\mathbf{h}_v^{\prime}, \tilde{\mathbf{e}}_v)/{\tau}')}{\sum_{v' \in \mathcal{V}', v' \neq v} \exp(\text{sim}(\mathbf{h}_v^{\prime}, \tilde{\mathbf{e}}_{{v}'})/{\tau}')},
\end{equation}
which $\text{sim}(\cdot)$ is the cosine similarity function, and ${\tau}'$ is the temperature parameter. 
$\mathbf{h}_v^{\prime}$ is the final representation on $\mathcal{G}^{\prime}$ after $L$ GNN layers, and $\tilde{\mathbf{e}}_v$ are embeddings derived from preference knowledge $\mathcal{K}_p$
Minimizing $\mathcal{L}_{prf}$ enhances the agreement between $\mathcal{G}^{\prime}$ and preference knowledge, capturing user preferences within semantic information. 
% \vspace{1mm}
% \noindent\textbf{Relation Knowledge Integration.}
For the relation knowledge $\mathcal{K}_r$, we treat the relation knowledge graph $\mathcal{G}_{rel}$ with embeddings $\hat{\mathbf{E}}_u=\{\hat{\mathbf{e}}_{u1}, \hat{\mathbf{e}}_{u2}, ...\}$ and $\hat{\mathbf{E}}_i=\{\hat{\mathbf{e}}_{i1}, \hat{\mathbf{e}}_{i2}, ...\}$ as an augmented view of the interaction graph.
After $L$ GNN layers on $\mathcal{G}_{rel}$, we obtain representation $\hat{\mathbf{h}}_u$ and $\hat{\mathbf{h}}_i$. The optimization objectives is defined as:
\begin{equation}\label{loss:rkg}
\mathcal{L}_{rel} = \sum_{v \in \mathcal{V}} -\log \frac{\exp(\text{sim}(\mathbf{h}_v^{\prime}, \hat{\mathbf{h}}_v)/{\tau}')}{\sum_{v' \in \mathcal{V}', v' \neq v} \exp(\text{sim}(\mathbf{h}_v^{\prime}, \hat{\mathbf{h}}_{{v}'})/{\tau}')},
\end{equation}
where ${\tau}'$ is the temperature parameter and $\text{sim}(\cdot)$ is the cosine similarity function.
Minimizing $\mathcal{L}_{rel}$ integrates $\mathcal{G}^{\prime}$ with relation knowledge $\mathcal{K}_r$, capturing latent semantic associations within the graph structure.

\vspace{1mm}
\noindent\textbf{Term3: Minimizing Mutual Information for Denoising.}
The third term facilitates the compression of information in the original interaction graph, filtering out of redundant interactions.
Directly minimizing mutual information between two high-dimensional graph representations is computationally intractable. To overcome this, we utilize the Hilbert-Schmidt Independence Criterion (HSIC) as an approximation for mutual information between $\mathcal{G}$ and $\mathcal{G}^{\prime}$.

First, we select appropriate kernel functions $k(\cdot)$ and $m(\cdot)$ for $\mathcal{G}$ and $\mathcal{G}^{\prime}$, respectively. For instance, Gaussian kernels are employed:
\begin{equation}\label{equ:kernel_functions}
k({\mathbf{h}}_v, {\mathbf{h}}_j) = \exp \left( -\frac{\|{\mathbf{h}}_v - {\mathbf{h}}_j\|^2}{2\sigma_k^2} \right), \;
m({\mathbf{h}}_v', {\mathbf{h}}_j') = \exp \left( -\frac{\|{\mathbf{h}}_v' - {\mathbf{h}}_j'\|^2}{2\sigma_m^2} \right),
\end{equation}
where $\theta_k$ and $\theta_m$ are kernel bandwidth parameter, $\mathbf{h}$ and $\mathbf{h}'$ are the user/item representation of $\mathcal{G}$ and $\mathcal{G}^{\prime}$, respectively.
Using these kernel functions, we compute the kernel matrices $K$ and $M$ from the $\mathcal{G}$ and $\mathcal{G}'$:
\begin{equation}
    \Mat{K} = [k(\mathbf{h}_v, \mathbf{h}_j)]_{n \times n}, \quad
    \Mat{M} = [m(\mathbf{h}'_v, \mathbf{h}'_j)]_{n \times n},
\end{equation}
where $n$ is the number of users/items in the graph and $v,j \in [0,n]$.
To center the kernel matrices and remove the mean, we apply the centering matrix $\Mat{H} = \Mat{I} - \frac{1}{n}\mathbf{11}^\top$, where $\Mat{I}_n$ is the $n \times n$ identity matrix and $\mathbf{1}$ is an $n$-dimensional vector of ones. The centralized kernel matrices are $\tilde{\Mat{K}} = {\Mat{H}}{\Mat{K}}{\Mat{H}}$ and $\tilde{\Mat{M}} = {\Mat{H}}{\Mat{M}}{\Mat{H}}$.
Using the centralized matrices $\tilde{\Mat{K}}$ and $\tilde{\Mat{M}}$, we compute HSIC as an approximation of mutual information between $\mathcal{G}$ and $\mathcal{G}^{\prime}$:
\begin{equation}\label{equ:hsic}
\text{HSIC}(\mathcal{G}, \mathcal{G}^{\prime}) = \frac{1}{(n-1)^2} \text{trace}(\tilde{\Mat{K}} \tilde{\Mat{M}}).
\end{equation}
The loss term for information compression using HSIC is defined as:
\begin{equation}\label{loss:comp}
\mathcal{L}_{comp} = \text{HSIC}(\mathcal{G}, \mathcal{G}^{\prime}) = \frac{1}{(n-1)^2} \text{trace}(\tilde{\Mat{K}} \tilde{\Mat{M}}).
\end{equation}
Minimizing HSIC effectively reduces the mutual information between the original graph $\mathcal{G}$ and the denoised graph $\mathcal{G}^{\prime}$, ensuring that $\mathcal{G}^{\prime}$ retains only the information necessary for the recommendation task, thereby achieving maximum compression and eliminating redundant interactions.

\vspace{1mm}
\noindent\textbf{Model Optimization.}
% Combining the BPR loss, the preference alignment loss using contrastive learning, and the information compression loss, the overall loss function is expressed as:
% 整体的优化目标由
The overall loss function combines the BPR loss, preference \& relation knowledge and information compression loss, defined as:
\begin{equation}\label{loss:total}
\mathcal{L} = \mathcal{L}_{rec} + \alpha (\mathcal{L}_{prf} + \mathcal{L}_{rel}) + \beta \mathcal{L}_{comp},
\end{equation}
where $\alpha$ and $\beta$ are hyperparameters that balance the contribution of the preference alignment loss and the information compression loss, respectively.


\section{Experiments}
To evaluate the effectiveness of LLaRD, we carry out a series of experiments to address the following \textbf{R}esearch \textbf{Q}uestions:

\begin{itemize}[leftmargin=4mm]
\item \textbf{RQ1:} How does LLaRD perform compared to various state-of-the-art denoising models when applied to different backbones?
\item \textbf{RQ2:} How can we verify the effectiveness of denoising knowledge mined by LLMs in denoising learning?
\item \textbf{RQ3:} How effectively can LLaRD help the model acquire robust representations mitigate noise issues?
\item \textbf{RQ4:} Is LLaRD effective in boosting the performance of cold-start users?
\end{itemize}

\subsection{Experimental Settings}
We conduct experiments on three benchmark datasets: Steam, Yelp, and Amazon-Book.  
We use two backbone models: GMF~\cite{koren2009matrix} and LightGCN~\cite{he2020lightgcn}. 
Our baseline methods consist of instance-level denoising and representation-level denoising. The instance-level method include WBPR~\cite{gantner2012personalized}, T-CE~\cite{wang2021denoising}, R-CE~\cite{wang2021denoising}, DeCA~\cite{wang2022learning}, SGDL~\cite{gao2022self}, BOD~\cite{wang2023efficient} and DCF~\cite{he2024double}.
The representation-level method include
SGL~\cite{wu2021self}, SimGCL~\cite{yu2022graph} and RLMRec~\cite{ren2024representation}.
More details of the dataset and implementation are provided in Appendix \ref{apd:details}.

\begin{table*}[t]
\centering
% \vspace{-4mm}
% \caption{Overall performance comparison on different backbone model with baseline.}
\caption{Overall performance comparison of different baselines on the backbone models. Bold numbers indicate the best performance, and underlined numbers indicate the second-best performance. "R" and "N" stand for Recall and NDCG, respectively.}
\vspace{-2mm}
\label{table:main_all}
\resizebox{0.98\textwidth}{!}{\begin{tabular}{clcccccccccccc}
\toprule
\multicolumn{2}{c}{\textbf{Dataset}}  & \multicolumn{4}{c}{\textbf{Amazon-Book}} & \multicolumn{4}{c}{\textbf{Yelp}} & \multicolumn{4}{c}{\textbf{Steam}}   \\ 
\cmidrule(r){1-2}  \cmidrule(r){3-6} \cmidrule(r){7-10} \cmidrule(r){11-14}
\textbf{Backbone} & \textbf{Method} & \textbf{R@10} & \textbf{N@10} & \textbf{R@20} & \textbf{N@20} & \textbf{R@10} & \textbf{N@10} & \textbf{R@20} & \textbf{N@20} & \textbf{R@10} & \textbf{N@10} & \textbf{R@20} & \textbf{N@20}  \\ 
\midrule
\midrule
\multirow{8}{*}{\makecell[c]{GMF}} & Normal & 0.0506 & 0.0399 & 0.0740 & 0.0463 & 0.0437
 & 0.0352  & 0.0787 & 0.0465 & 0.0603
 & 0.0512 & 0.0984 & 0.0599
 \\
& WBPR   & 0.0513 & 0.0404 & 0.0753 & 0.0477 & 0.0440 & 0.0359 & 0.0793 & 0.0569 & 0.0599 & 0.0505 & 0.0984 & 0.0597 \\
% & WRMF   & 0.0521 & 0.0412 & 0.0759 & 0.0481 &  &  \\
& R-CE    & 0.0664 & 0.0508 & 0.0995 & 0.0615 & 0.0550 & 0.0464 & 0.0894 & 0.0578 & 0.0636 & 0.0536 & 0.1030 & 0.0665 \\
& T-CE    & 0.0679 & 0.0533 & 0.1017 & 0.0641 & 0.0535 & 0.0453 & 0.0871 & 0.0565 & 0.0641 & 0.0536 & 0.1029 & 0.0663 \\

% & DCF    &  &  &  & &  &   \\
& DeCA   & 0.0814 & 0.0619 & 0.1237 & 0.0710 & 0.0600 & 0.0515 & 0.0981 & 0.0619 & 0.0677 & 0.0555 & 0.1047 & 0.0676 \\
& SGDL   & 0.0975 & 0.0741 & 0.1489 & 0.0902 & 0.0683 & 0.0560 & 0.1098 & 0.0696 & 0.0704 & 0.0582 & 0.1084 & 0.0699  \\
& RLMRec & 0.0968 & 0.0728 & 0.1483 & 0.0896 & 0.0662 & 0.0548 & 0.1092 & 0.0693 & \underline{0.0810} & \underline{0.0654} & \underline{0.1283} & \underline{0.0811}  \\
& BOD    & \underline{0.1009} & \underline{0.0779} & \underline{0.1520} & \underline{0.0944} & \underline{0.0706} & \underline{0.0574} & \underline{0.1126} & \underline{0.0712} & 0.0718 & 0.0596 & 0.1135 & 0.0744   \\
\midrule
&  LLaRD   & \textbf{0.1083} & \textbf{0.0851} & \textbf{0.1619} & \textbf{0.1027} & \textbf{0.0708} & \textbf{0.0578} & \textbf{0.1135} & \textbf{0.0723} & \textbf{0.0819} & \textbf{0.0657} & \textbf{0.1291} & \textbf{0.0817}  \\
\midrule
\midrule

\multirow{10}{*}{\makecell[c]{LightGCN}} & Normal  & 0.0670 & 0.0495  & 0.1010 & 0.0613 & 0.0539 & 0.0452 & 0.0871 & 0.0566 & 0.0731 & 0.0627 & 0.1170 & 0.0784 \\
& WBPR   & 0.0674 & 0.0496 & 0.1016 & 0.0620 & 0.0539 & 0.0450 & 0.0877 & 0.0571 & 0.0735 & 0.0629 & 0.1165 & 0.0777 \\
& T-CE    & 0.0693 & 0.0530 & 0.1079 & 0.0715 & 0.0585 & 0.0501 & 0.0906 & 0.0612 & 0.0736 & 0.0624 & 0.1133 & 0.0754 \\
& DCF    & 0.0723 & 0.0557 & 0.1112 & 0.0743 & 0.0614 & 0.0524 & 0.0926 & 0.0627 & 0.0768 & 0.0672 & 0.1164 & 0.0771 \\
& DeCA   & 0.0832  & 0.0611 & 0.1291 & 0.0799 & 0.0652 & 0.0576 & 0.1092 & 0.0689 & 0.0827 & 0.0711 & 0.1288 & 0.0882  \\
& SGL    & 0.1018 & 0.0791 & 0.1498 & 0.0949 & 0.0718 & 0.0603 & 0.1171 & 0.0759 & 0.0795 & 0.0671 & 0.1254 & 0.0833 \\
& SimGCL    & 0.1109 & 0.0873 & 0.1538 & 0.1013 & 0.0709 & 0.0599 & 0.1146 & 0.0748 & 0.0576 & 0.0471 & 0.0903 & 0.0587 \\
& SGDL   & 0.1135 & 0.0872 & 0.1675 & 0.1054 & 0.0800 & 0.0661 & 0.1323 & 0.0841 & 0.0933 & 0.0769 & 0.1458 & 0.0755   \\

% & BOD    & 0.1135 & 0.0872 & 0.1675 & 0.1054 & 0.0800 & 0.0661 & 0.1323 & 0.0841 & 0.0933 & 0.0769 & 0.1458 & 0.0587 \\
& RLMRec  & 0.1034 & 0.0788 & 0.1600 & 0.0960 & 0.0794 & 0.0652 & 0.1275 & 0.0815 & 0.0926 & 0.0746 & 0.1452 & \underline{0.0924} \\
& BOD    & \underline{0.1244} & \underline{0.0985} & \underline{0.1777} & \underline{0.1131} & \underline{0.0922} & \underline{0.0739} & \underline{0.1432} & \underline{0.0884} & \underline{0.1001} & \underline{0.0802} & \underline{0.1469} & 0.0891 \\
\midrule
&  LLaRD   & \textbf{0.1408} & \textbf{0.1126} & \textbf{0.2028} & \textbf{0.1326} & \textbf{0.0975} & \textbf{0.0809} & \textbf{0.1574} & \textbf{0.1008} & \textbf{0.1054} & \textbf{0.0868} & \textbf{0.1631} & \textbf{0.1059}  \\
\bottomrule
\end{tabular}}
% \vspace{-2mm}
\end{table*}

\subsection{Performance Comparison (RQ1)}

To evaluate the effectiveness and generalizability of our framework, we compared our proposed LLaRD method with existing denoising baselines across three datasets and two backbone models. The following observations summarize our findings:

\begin{itemize}[leftmargin=4mm]

\item Our proposed LLaRD consistently outperforms mainstream denoising techniques across all three datasets and both backbone models.
On average, LLaRD surpasses the second-best model, BOD, by approximately 6.92\% when integrated with GMF, and by 11.79\% with LightGCN.
Although BOD employs a bi-level optimization strategy to extract prior knowledge, it lacks a comprehensive understanding of preferences and mining the relational semantics within interaction samples, resulting in inferior performance compared to our method.
\item Against interaction data-driven methods such as T-CE, DeCA, DCF, and SGDL, which are constrained to identifying patterns within observed data and  and rely on training loss for noise identification, LLaRD demonstrates a substantial performance improvement ranging from 46.1\% to 68.53\%. 
This significant enhancement is attributed to our utilization of LLMs to infer user preferences beyond the available interaction data and the application of CoT reasoning to progressively uncover complex semantic associations within the interaction graph, thereby eliminating dependence on predefined assumptions.

\item 
LLaRD outperforms robust representation learning methods by approximately 34.34\% to 49.31\%.
The LLM-enhanced method, RLMRec, also achieves a significant 14.93\% improvement over traditional approaches like SGL and SimGCL by aligning user preferences across semantic and collaborative spaces, demonstrating the effectiveness of LLMs in providing task-relevant information. 
However, LLaRD surpasses these methods by not only ensuring robust representations but also addressing data-level denoising. It leverages higher-order associative semantics compared to RLMRec and enhances noise recognition capabilities, resulting in superior performance.
\end{itemize}


% \subsection{Case Study (RQ2)}
\subsection{Ablation Study (RQ2)}


\begin{table}[t]
\centering
% \vspace{-4mm}
\caption{The impact of different components in LLaRD.}
\vspace{-2mm}
\label{table:ablation}
\resizebox{0.44\textwidth}{!}{\begin{tabular}{lcccccccc}
\toprule
& \multicolumn{4}{c}{Amazon-Book} & \multicolumn{4}{c}{Steam} \\ 
\cmidrule(r){2-5}  \cmidrule(r){6-9}  
Ablation & R@10 & N@10 & R@20 & N@20 & R@10 & N@10 & R@20 & N@20 \\ 
\midrule
LLaRD  & \textbf{0.1408} & \textbf{0.1126} & \textbf{0.2028} & \textbf{0.1326} & \textbf{0.1054} & \textbf{0.0868} & \textbf{0.1631} & \textbf{0.1059} \\
\midrule
% Base & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\
% Base (Only mask)  & 0.1301 & 0.1039 & 0.1856 & 0.1215 & 0.0949 & 0.0774 & 0.1494 & 0.0957 \\
w/o MI$_{min}$  & 0.1259 & 0.1009 & 0.1868 & 0.1205 & 0.0977 & 0.0800 & 0.1525 & 0.0982 \\
w/o MI$_{max}$  & 0.1301 & 0.1039 & 0.1856 & 0.1215 & 0.0949 & 0.0774 & 0.1494 & 0.0957 \\
% w/o PK    & 0.1399 & 0.1108 & 0.2016 & 0.1317 & 0.1039 & 0.0862 & 0.1610 & 0.1049 \\
w/o PK    & 0.1385 & 0.1090 & 0.1983 & 0.1292 & 0.1012 & 0.0837 & 0.1559 & 0.1017 \\
w/o RK  & 0.1369 & 0.1075 & 0.1947 & 0.1244 & 0.1001 & 0.0819 & 0.1532 & 0.0904 \\
\bottomrule
\end{tabular}}
\vspace{-2mm}
\end{table}

% \subsubsection{\textbf{ of different components in LLaRD.}}
To verify the effectiveness of denoising knowledge mined by LLMs and ensure its effective utilization in model learning, we conduct ablation studies to assess the contributions of various components within LLaRD. We design the following four model variants:
% \vspace{-2mm}
\begin{itemize}[leftmargin=4mm]
    \item w/o MI$_{min}$: Removes the process of minimizing mutual information between the denoised and original interaction graph.
    \item w/o MI$_{max}$: Removes the process of maximizing mutual information between the denoised graph and denoising knowledge.
    \item w/o PK: Removes the integration of preference knowledge in the denoising framework.
    \item w/o RK: Removes the integration of relation knowledge in the denoising framework.
\end{itemize}

\begin{figure}[t] 
\centering
\subfigbottomskip=-1pt
\subfigcapskip=-1mm
\subfigure[Amazon-Book dataset]{
\label{fig:noise1}
\includegraphics[width=0.46\linewidth]{Robust-Amazon-IG.pdf}}
% \hspace{1mm}
\subfigure[Steam dataset]{
\label{fig:noise2}
\includegraphics[width=0.46\linewidth]{Robust-Steam-IG.pdf}}
\hspace{1mm}
\vspace{-2mm}
\caption{Impact comparison \wrt noise ratio in added interaction data. The bars display Recall@20, while the curve shows the drop rate in performance.}
\label{fig:robust}
\vspace{-4mm}
\end{figure}

% \begin{figure}[t] 
% \centering
% \captionsetup[subfigure]{justification=centering, skip=1pt, singlelinecheck=false} % 可根据需要调整设置

% \subfloat[Amazon-Book dataset]{
%   \includegraphics[width=0.46\linewidth]{Robust-Amazon-IG.pdf}
%   \label{fig:noise1}
% }
% \hspace{1mm}
% \subfloat[Steam dataset]{
%   \includegraphics[width=0.46\linewidth]{Robust-Steam-IG.pdf}
%   \label{fig:noise2}
% }
% \vspace{-2mm}
% \caption{Impact comparison \wrt noise ratio in added interaction data. The bars display Recall@20, while the curve shows the drop rate in performance.}
% \label{fig:robust}
% \vspace{-4mm}
% \end{figure}

As shown in Table~\ref{table:ablation}, removing certain components leads to varying degrees of the performance degradation in LLaRD.
The most significant decline occurs with the \textbf{w/o MI$_{\text{min}}$} variant, demonstrating the effectiveness of our denoising approach based on the information bottleneck principle.
Additionally, omitting either preference knowledge (\textbf{w/o PK}) or relation knowledge (\textbf{w/o RK}) results in performance reductions, highlighting their importance for denoising recommendations.
Furthermore, when using the \textbf{w/o MI$_{\text{max}}$}, the performance decreases, underscoring the significance of denoising knowledge for model learning.


\subsection{Model Benefits Analysis (RQ3 \& RQ4)}
% \vspace{1mm}
\textbf{Robustness to Noisy Interactions.}
To evaluate the robustness of LLaRD to noisy interactions, following previous studies~\cite{wu2021self, wang2023efficient}, we conducted experiments by introducing adversarial interaction examples (\ie 5\%, 10\%, 15\%, and 20\% negative user-item interactions) into the training set, while keeping the test set unchanged.
Figures~\ref{fig:noise1} and~\ref{fig:noise2} present the results on the Amazon-Book and Steam datasets, respectively. This demonstrates that LLaRD consistently outperforms all baseline methods across all noise levels.
Additionally, the performance drop of LLaRD remains relatively stable compared to the baselines, highlighting its superior resilience to differing noise intensities. These results indicate that the denoising framework LLaRD effectively identifies and leverages useful patterns even in the presence of significant noise.

\vspace{1mm}
\noindent\textbf{Cold-Start Recommendation.}
To evaluate the effectiveness in cold-start scenarios characterized by extremely
sparse interaction data, we divide all users into five groups based on their interaction frequency. A lower group ID corresponds to sparser user activity and more severe cold-start issues. 
We compare LLaRD with various baseline methods across different cold-start levels. As shown in Figure~\ref{fig:bar}, the results clearly indicate that LLaRD consistently outperforms baselines across all cold-start levels. This superior performance is  attributed to the ability of LLaRD to derive preference knowledge and relation knowledge from LLMs, thereby enabling effective noise identification and robust modeling of both users and items, even in cold-start scenarios.




\begin{figure}[t]
\centering
\subfigbottomskip=0pt
\subfigcapskip=0mm
\subfigure[Recall@20]{
\label{fig:bar1}
\includegraphics[width=0.44\linewidth]{Coldstart-Amazon_Recall.pdf}}
% \hspace{1mm}
\subfigure[NDCG@20]{
\label{fig:bar2}
\includegraphics[width=0.44\linewidth]{Coldstart-Amazon_NDCG.pdf}}
% \hspace{1mm}
\subfigure[Recall@20]{
\label{fig:bar3}
\includegraphics[width=0.44\linewidth]{Coldstart-Steam_Recall.pdf}}
% \hspace{1mm}
\subfigure[NDCG@20]{
\label{fig:bar4}
\includegraphics[width=0.44\linewidth]{Coldstart-Steam_NDCG.pdf}}
\vspace{-2mm}
\caption{Recommendation performance over different cold-start user groups on Amazon-Book (upper) and Steam (lower) dataset.}
\label{fig:bar}
\vspace{-4mm}
\end{figure}
\vspace{-2mm}

% \begin{figure}[t]
% \centering
% \captionsetup[subfigure]{justification=centering, skip=1pt, singlelinecheck=false}

% \subfloat[Recall@20]{
%   \includegraphics[width=0.44\linewidth]{Coldstart-Amazon_Recall.pdf}
%   \label{fig:bar1}
% }
% \subfloat[NDCG@20]{
%   \includegraphics[width=0.44\linewidth]{Coldstart-Amazon_NDCG.pdf}
%   \label{fig:bar2}
% }

% \subfloat[Recall@20]{
%   \includegraphics[width=0.44\linewidth]{Coldstart-Steam_Recall.pdf}
%   \label{fig:bar3}
% }
% \subfloat[NDCG@20]{
%   \includegraphics[width=0.44\linewidth]{Coldstart-Steam_NDCG.pdf}
%   \label{fig:bar4}
% }
% \vspace{-2mm}
% \caption{Recommendation performance over different cold-start user groups on Amazon-Book (upper) and Steam (lower) dataset.}
% \label{fig:bar}
% \vspace{-4mm}
% \end{figure}
% \vspace{-2mm}


\section{Related Work}

\textbf{Denoising in Recommendation.}
Recommendation typically treat observed interactions as positive and unobserved ones as negative in implicit feedback~\cite{ding2019sampler,gao2022self}. However, this approach can incorporate erroneous clicks or biased behaviors, leading to false positives and negatives that degrade user experience~\cite{sun2021does}. Existing denoising methods are generally categorized as follows:
\textbf{1) Selection-Based Methods}: These methods~\cite{gantner2012personalized,wen2019leveraging} filter out noisy feedback while retaining clean data. Early approaches~\cite{nguyen2019self,hu2008collaborative} use samplers based on data characteristics, whereas adaptive strategies later identify unreliable instances by detecting significant loss early in training. Recent techniques~\cite{lin2023autodenoise} employ deep reinforcement learning for effective noise removal. DCF~\cite{he2024double} uses a dual-correction framework to identify noise through changes in sample loss over time.
\textbf{2) Re-weighting-Based Methods}: This approach assigns higher weights to informative interactions. Initial methods~\cite{wang2022learning,wang2021implicit} utilize training loss to assign lower weights to high-loss samples. Recent works like DeCA~\cite{wang2022learning} and BOD~\cite{wang2023efficient} have introduced novel evaluation criteria and optimization strategies for more accurate weight learning.
\textbf{3) Side-Information-Based Methods and Special Strategies}~\cite{gao2022self,wu2021self,yang2021enhanced}: Early approaches~\cite{buscher2009segment,fu2010towards,zhao2016gaze} utilize dwell time and annotations to detect noise. \cite{zhang2024ssdrec,han2024efficient,xin2023improving} incorporate sequential or multi-behavior data to capture unexpected interactions. \cite{zhu2023knowledge,wang2024unleashing} have employed knowledge graphs to enhance preference modeling, facilitating denoising frameworks. 
In addition, there are some studies that learn robust representations by designing special denoising strategies. Early work~\cite{wu2016collaborative,khawar2020learning,strub2015collaborative} employ autoencoders to reduce noise in representations. \cite{wu2021self,yu2022graph} leverage self-supervised learning on graph-structured data for greater stability. 
Despite their effectiveness, existing methods rely heavily on observed data and predefined assumptions to model user preferences and distinguish noise. In contrast, our approach leverages LLMs to acquire denoising knowledge, extracting inferred preference and relational semantics to capture noise interactions.

\vspace{-2mm}
\section{Conclusion}
In this paper, we introduced LLaRD, a novel framework that leverages large language models (LLMs) to enhance the denoising process in recommendation. 
It improved denoising ability of the model by guiding LLMs to mine and inferred denoising-related knowledge from text and interaction data.
Specifically, it first enriched semantic insights via LLMs, enabling a more comprehensive inference of user-item preferences. Then it employed a Chain-of-Thought (CoT) strategy over user-item interaction graphs to uncover relation knowledge relevant to denoising. 
Finally, the Information Bottleneck (IB) principle effectively aligned the denoised knowledge with recommendation targets.
Through extensive empirical evaluations, we demonstrated that LLaRD significantly improves both denoising and recommendation accuracy compared to existing methods. 
Future work will explore further refinements to the framework and its applicability across diverse recommendation scenarios.



\section{Acknowledgments}
This work was supported in part by the National Key R\&D Program of China (Grant No.2023YFF0725001),in part by the National Natural Science Foundation of China (Grant No.92370204),in part by the Guangdong Basic and Applied Basic Research Foundation(Grant No.2023B1515120057),in part by Guangzhou-HKUST(GZ) Joint Funding Program(Grant No.2023A03J0008), Education Bureau of Guangzhou Municipality.



\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{LLaRD}

\appendix

\clearpage

\section{PRELIMINARIES}
\subsection{Chain-of-Thought Prompting}
Chain-of-Thought (CoT) prompting~\cite{wang2022self,wei2022chain,xia2024beyond,xia2024chain} enhances the reasoning capabilities of LLMs by guiding them to generate intermediate reasoning steps structured as $<\text{input}, \text{thoughts}, \text{output}>$ instead of directly producing answers. This approach improves both interpretability and accuracy, particularly for tasks requiring multi-step reasoning or logical deductions.
\begin{definition}[CoT Prompting]\label{def:cot}
CoT prompting directs a language model to produce a sequence of intermediate reasoning steps $R$ before generating the final output $Y$, given an input prompt $X$. Mathematically, this framework models the output $Y$ as:
\begin{equation}\label{equ:cot}
p(Y|X) = \sum_{R} p(Y|R, X) , p(R|X).
\end{equation}
This decomposition transforms complex tasks into manageable sub-tasks, enhancing the reasoning capabilities of model.
\end{definition}
By generating structured reasoning steps, CoT prompting enables more accurate and reliable responses in complex tasks.
\section{RELATED WORK}
% \vspace{2mm}
\noindent\textbf{LLMs in Recommendation.}
LLMs~\cite{chen2024sac, zhang2024interpreting} have emerged as powerful tools for enhancing recommendation by leveraging deep semantic understanding and extensive pre-trained knowledge~\cite{zhang2023recommendation, dai2023uncovering, xi2024towards}. 
Some approaches~\cite{zhang2024generative,zhang2024generative} capture latent preferences by generating textual tokens derived from user and item semantics, effectively modeling user preferences through LLMs' rich semantic capabilities.
Other studies~\cite{zhang2024text,geng2022recommendation,liu2023chatgpt,liao2024llara} employ LLMs as recommenders by crafting specific instructions and fine-tuning them for recommendation tasks, utilizing their adaptability for tailored functionalities.
Additionally, certain research~\cite{kieu2024keyword,he2023large} adapts LLMs to downstream tasks using prompts without fine-tuning. For example, \cite{he2023large} introduce LLMs as zero-shot conversational recommender systems, while ToolRec~\cite{zhao2024let} and RecMind~\cite{wang2023recmind} design CoT prompts to enable LLMs to handle complex reasoning within recommendation scenarios.
Furthermore, methods~\cite{xi2024towards,yang2024sequential,wei2024llmrec,ren2024representation} generate rich-semantic embeddings and integrate reasoning knowledge into traditional models, improving understanding of user preferences and item features, thereby improving recommendation.
Despite advancements in utilizing LLMs for various tasks, exploration in denoising recommendations remains limited. Our approach leverages LLMs to extract denoising-related knowledge, enhancing robustness by addressing noise interactions.
\section{More Implementation Details}\label{apd:details}
\subsection{\textbf{Dataset Details}}
We conduct experiments on three benchmark datasets: Steam, Yelp, and Amazon-Book. Following the methods of \cite{he2020lightgcn,ren2024representation}, we apply k-core filtering and divide each dataset into training, validation, and testing sets with a 3:1:1 ratio. Additionally, we remove interactions with ratings below 3, except for the Steam dataset, which does not include rating information and is therefore unfiltered.
We provide the statistics of experimental datasets in Table~\ref{table:data}.

\begin{table}[h]
\footnotesize
\centering
\caption{Statistics of experimental datasets.}
\vspace{-2mm}
\label{table:data}
\resizebox{0.35\textwidth}{!}{\begin{tabular}{lccccc}
\toprule
Statistics & Amazon-Book  & Steam & Yelp  \\
\toprule
% \hline
\# Users & 11,000   & 23,310 & 11,091  \\
\# Items & 9,332  & 5,237 & 11,010  \\
\# Interactions & 120,464  & 316,190 & 166,620 \\
\# Density & 1.2e-3  & 2.6e-4 & 1.4e-4 \\
\bottomrule
\end{tabular}}
\vspace{-2mm}
\end{table}

% \begin{table}[h]
% \footnotesize
% \centering
% \caption{Statistics of experimental datasets.}
% \vspace{-2mm}
% \label{table:data}
% \resizebox{0.40\textwidth}{!}{\begin{tabular}{lccccc}
% \toprule
% Statistics & Amazon-Book  & Steam & Yelp  \\
% \toprule
% % \hline
% \# Users & 11,000   & 23,310 & 11,091  \\
% \# Items & 9,332  & 5,237 & 11,010  \\
% \# Interactions & 120,464  & 316,190 & 166,620 \\
% \# Density & 1.2e-3  & 2.6e-4 & 1.4e-4 \\
% \bottomrule
% \end{tabular}}
% \vspace{-2mm}
% \end{table}


\begin{figure*}[t]
\centering
\includegraphics[width=0.94\linewidth]{case.pdf}
\vspace{-6mm}
\caption{The CoT reasoning case of LLaRD.}
\label{fig:case}
\vspace{-2mm}
\end{figure*}

\subsection{\textbf{Evaluation Metrics}}
To ensure a fair evaluation and minimize bias, we adopt the all-rank protocol, considering all non-interacted items as candidates. We assess performance using Recall@$N$ and NDCG@$N$, reporting average values for \(N=10\) and \(N=20\).



\subsection{\textbf{Baselines and Backbone Models}}\label{apd:base}
We conduct experiments using two backbone models. 
\begin{itemize}[leftmargin=4mm]
\item \textbf{GMF}~\cite{koren2009matrix} decomposes the interaction matrix into implicit vectors and computes their element-wise product to capture features.
\item \textbf{LightGCN}~\cite{he2020lightgcn} is a widely adopted graph-based recommendation model. To demonstrate the effectiveness of our proposed method, we perform a fair comparison against traditional denoising techniques and state-of-the-art baselines. 
\end{itemize}
Our baseline methods include instance-level denoising methods and representation-level denoising methods.

\noindent\textbf{Instance-level Denoising.}
\begin{itemize}[leftmargin=4mm]
\item \textbf{WBPR}~\cite{gantner2012personalized} is a sampling-based denoising method that assumes a negative item should be both highly popular and non-interacted.
\item \textbf{T-CE}~\cite{wang2021denoising} is a re-weighting based method with truncated loss and dynamic thresholds during training.
\item \textbf{R-CE}~\cite{wang2021denoising} is a re-weighting based method with reweighted loss and dynamic thresholds during training.
\item \textbf{DeCA}~\cite{wang2022learning} is a re-weighting based method addressing prediction disagreements of noisy interactions across models.
\item \textbf{SGDL}~\cite{gao2022self} collects clean interactions at training onset, using similarity as a distinguishing criterion.
\item \textbf{BOD}~\cite{wang2023efficient} models denoising as a bi-level optimization problem, extracting prior data information to generate weights.
\item \textbf{DCF}~\cite{he2024double} designs correction strategies for sample dropping and progressive labeling for precise denoising.
\end{itemize}
\vspace{1mm}
\noindent \textbf{Representation-level Denoising.}
\begin{itemize}[leftmargin=4mm]
\item \textbf{SGL}~\cite{wu2021self} is a self-supervised framework performing graph contrastive learning with multiple views for robust representations.
\item \textbf{SimGCL}~\cite{yu2022graph} is a self-supervised framework adding uniform noise to embeddings to create contrasting views.
\item \textbf{RLMRec}~\cite{ren2024representation} utilizes LLMs to capture the complex user behavior semantics,  enhancing recommendations through contrastive and generative techniques.
\end{itemize}

\subsection{Hyper-parameter Settings}\label{apd:hyper}

To ensure a fair comparison with the baselines, the dimension of representations and MLP is set to 64, and the GNN layer is set to 3, for all base models. The temperature value of contrastive learning from the range of \{0.1, ..., 0.5\}. The temperature value of gumbel-max is 0.0001, and the hidden dim of attention is set to 64.
During training, all methods are trained with a fixed batch size of 1024. We train all models using the learning rate 1e-3 with Adam optimizer without weight decay. We adopt the early stop technique based on the model’s performance on the validation set.
To generate the preference knowledge and relation knowledge, we leverage the Qwen model (specifically, qwen-long).
For other parameters, we mainly use the official setting from the original paper and open-source code for fair comparisons.
To allow for reproducibility, we also provide an anonymous code link of our work: https://github.com/shuyao-wang/LLaRD.


\subsection{Time Complexity}
While LLaRD includes multiple components, its overall time complexity remains comparable to mainstream denoising methods. The knowledge generation process is a one-time LLM inference step that does not require training and is excluded from the training phase complexity analysis.
During training, the time complexity consists of three main components:
1) Knowledge utilization phase: For preference knowledge, the multilayer perceptron has a complexity of $\mathcal{O}((|\mathcal{U}| + |\mathcal{I}|) \cdot d_h \cdot d_t)$, where $d_h$ and $d_t$ are the hidden layer size and token embedding size. For relational knowledge, graph convolution over $\mathcal{G}_{\text{rel}}$ has a complexity of $\mathcal{O}(|\mathcal{E}_{\text{r}}| \cdot d_e \cdot L)$, where $|\mathcal{E}_{\text{r}}|$ is the number of edges in the graph embedding size.
2) Denoising graph learning phase: Mask generation for the interaction graph has a complexity of $\mathcal{O}(|\mathcal{E}| \cdot d_h)$, where $|\mathcal{E}|$ is the number of edges in the interaction graph. The denoising graph learning and recommendation prediction have complexities of $\mathcal{O}(|\mathcal{E}| \cdot d_e \cdot L)$, and $\mathcal{O}(B \cdot d_e)$, respectively, where $B$ is the batch size.
3) Information Bottleneck Learning Phase: The complexity of HSIC and InfoNCE is: $\mathcal{O}(B^2 \cdot d_e)$. 
The total complexity is: $\mathcal{O}(B^2 \cdot d_e + |\mathcal{I}_{\text{r}}| \cdot d_e \cdot L + B \cdot d_e + B^2 \cdot d_e)$.
This is comparable to mainstream denoising methods, with reasonable marginal complexity.

\subsection{Running Time Comparison}
We additionally provide a running time comparison with the baseline method. Table~\ref{table:time} presents the running time (in seconds per epoch) measured on a server equipped with an NVIDIA GeForce RTX 4090 GPU.
\begin{table}[h]
\footnotesize
\centering
\caption{Comparison of running time across different datasets}
\vspace{-2mm}
\label{table:time}
\resizebox{0.40\textwidth}{!}{\begin{tabular}{lccc}
\toprule
Model / Dataset & Yelp & Steam & Amazon\_Book \\
\midrule
T-CE & 33.12 & 67.84 & 27.30 \\
SGDL & 122.65 & 386.26 & 98.75 \\
SGL & 15.67 & 28.92 & 15.86 \\
SimGCL & 21.41 & 35.45 & 18.93 \\
BOD & 18.84 & 31.62 & 14.77 \\
LLaRD & 51.14 & 78.91 & 19.21 \\
\bottomrule
\end{tabular}}
\vspace{-2mm}
\end{table}

\subsection{Case Study}\label{apd:case}
To facilitate a deeper understanding of the process by which LLaRD generate relation knowledge through chain-of-thought (CoT) reasoning, we present a case study as illustrated in the Figure~\ref{fig:case}.



\end{document}
