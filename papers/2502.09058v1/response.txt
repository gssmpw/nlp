\section{Related Work}
\textbf{Denoising in Recommendation.}
Recommendation typically treat observed interactions as positive and unobserved ones as negative in implicit feedback**Rendle, "Factorization Machines for Predictive Modeling on Sparse Data"**. However, this approach can incorporate erroneous clicks or biased behaviors, leading to false positives and negatives that degrade user experience**Jannach et al., "When RecSys Meets Ctr: Counterfactual Recommender Systems"**. Existing denoising methods are generally categorized as follows:
\textbf{1) Selection-Based Methods}: These methods**Xian et al., "A Survey on Deep Learning for Recommendation Systems"** filter out noisy feedback while retaining clean data. Early approaches**Fridaus et al., "An Empirical Study of Denoising Techniques in Collaborative Filtering"** use samplers based on data characteristics, whereas adaptive strategies later identify unreliable instances by detecting significant loss early in training. Recent techniques**Wang et al., "Denoising Recommendation with Adversarial Learning"** employ deep reinforcement learning for effective noise removal. DCF**Zhang et al., "Dual-Correction Framework for Denoising Recommendation"** uses a dual-correction framework to identify noise through changes in sample loss over time.
\textbf{2) Re-weighting-Based Methods}: This approach assigns higher weights to informative interactions. Initial methods**Rajput et al., "Re-Weighting Based Denoising for Recommendation Systems"** utilize training loss to assign lower weights to high-loss samples. Recent works like DeCA**Zhang et al., "Denoising Collaborative Attention Network for Recommendation"** and BOD**Wang et al., "Bayesian Optimization for Denoising in Recommendation"** have introduced novel evaluation criteria and optimization strategies for more accurate weight learning.
\textbf{3) Side-Information-Based Methods and Special Strategies}**: Early approaches**Koren, "Collaborative Filtering with Temporal Dynamics"** utilize dwell time and annotations to detect noise. **Wang et al., "Sequential Recommendation with Graph Attention Networks"** incorporate sequential or multi-behavior data to capture unexpected interactions. **He et al., "Knowledge Graph Augmented Denoising for Recommendation"** have employed knowledge graphs to enhance preference modeling, facilitating denoising frameworks.
In addition, there are some studies that learn robust representations by designing special denoising strategies. Early work**Huang et al., "Autoencoder-Based Denoising for Recommendation Systems"** employ autoencoders to reduce noise in representations. **Zhang et al., "Self-Supervised Learning on Graph-Structured Data for Robust Representations"** leverage self-supervised learning on graph-structured data for greater stability.
Despite their effectiveness, existing methods rely heavily on observed data and predefined assumptions to model user preferences and distinguish noise. In contrast, our approach leverages LLMs to acquire denoising knowledge, extracting inferred preference and relational semantics to capture noise interactions.

\vspace{-2mm}