\section{Formulation}

In RS, let $\mathcal{U}, \mathcal{I}$ be the set of users and items, and each item $i\in \mathcal{I}$ is associated with a unique group $g\in \mathcal{G}$, where the set of items associated with $g$ is denoted as $\mathcal{I}_g$. In RS, an item $i$ may belong to a different group $g$ (\eg a movie can be categorized under various genres such as action, or drama). We define the number of groups to which the item $i$ belongs as $n_i$.


Suppose that the RS manages a set of user-item historical interactions $\mathcal{D} = \{(u,i, 
c_{u,i})\}$, where each tuple $(u, i, c_{u,i})$ records that a user $u\in\mathcal{U}$ accessed the system and interacted with an item $i\in\mathcal{I}$ with behavior $c_{u,i}\in\{0,1\}$. $c_{u,i} = 1$ means that the user $u$ clicked/purchased the item $i$, and 0 otherwise. The task of recommendation becomes, based on the user-item interactions in $\mathcal{D}$, learning an empirical estimation $\hat{c}_{u,i} = f(u, i)$ for real label $c_{u,i}$. Then RS will suggest $K$ items to the user according to predicted preference scores $\hat{c}_{u,i}$, with the ranking list denoted as $L_K(u) \in \mathcal{I}^{K}$. In general, the $f(\cdot)$ can be either the traditional matrix factorization model~\citep{he2016fast} or more advanced LLMs-based recommender models~\citep{bao2023bi}.

Following the practice in recommendation tasks~\citep{he2017neural, he2016fast}, the cross-entropy loss $-c_{u,i}\log (\hat{c}_{u,i})$ is regarded as a common and better choice compared to other loss functions. Meanwhile, to fulfill the group MMF requirement~\citep{fairrec, xu2024fairsync}, the recommendation model also strives to maintain the expected utility of a specific group 
$g$ (where the group's utility is defined as the negative sum of the entropy loss within the group) exceeds a basic threshold $M$. MMF constraint aims to ensure every group can receive the required group-specific ``minimum wage'' during the training phases. Formally, we can write the ideal optimization objective as follows:
\begin{equation}
\label{eq:obj}
    \begin{aligned}
        \mathcal{L} = \min_{\hat{c}_{u,i}} ~ \underbrace{-\sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}} c_{u,i}\log (\hat{c}_{u,i})}_{\text{recommendation accuracy loss}}\quad \textrm{s.t.}~ \underbrace{\max_{g\in\mathcal{G}}\sum_{u\in\mathcal{U}} \sum_{i\in L_K(u)} -\frac{\mathbb{I}(i\in \mathcal{I}_g)}{n_i m_g}c_{u,i}\log(\hat{c}_{u,i}) \leq M}_{\text{MMF constraint: loss of worst-off group $g$ should at or smaller than $M$}}, \\
            %& \sum_{i\in\mathcal{I}} c_{u,i} \leq K, \forall u\in\mathcal{U},
    \end{aligned}
\end{equation}

%Note that the constraint ensures the expected scores $\bm{w}_g$  of group $g$ are accumulated in the all-ranking list $\{L_K(u)\}_{u\in\mathcal{U}}$. 

where $\mathbb{I}(\cdot)$ denotes the indicator function, and the number of users $|\mathcal{U}|$ could represent the daily or weekly user traffic. The $m_g$ can be regarded as the weight for different group $g$. Note that, following the practice in time-aware RS~\citep{kang2018self, sun2019bert4rec}, we utilize the recent $H$ interactions,  which represent the truncated user historical behavior numbers.


%there may be users with interactions $c_{u,i}$ greater than the ranking size $K$, in which case we will only consider the least recent $K$ interactions to represent their recent preferences.



%The third constraint ensures that the size of the user preference list (\ie ranking size) should be less than ranking size $K$. 
%However, in practice, there will be new users with fewer interactions than the predefined $K$. Most previous recommendation system approaches tend to filter out these users, treating them as a cold-start problem.


% In real-world scenarios, the number of users $|\mathcal{U}|$ is often large, and a mini-batch sampling strategy is often necessary due to the large computational costs. This involves dividing the $|\mathcal{U}|$ users into $|\mathcal{U}|/B$ batches and performing gradient descent methods on each batch.

