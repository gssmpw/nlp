\newpage

\appendix
\section*{Appendix}

\section{Proof of Theorem~\ref{theo:alpha_fair}}\label{app:prof_alpha_fair}

\begin{proof}
    Let $\bm{A}\in\mathbb{R}^{|\mathcal{I}|\times|\mathcal{G}|}$ is the item-group adjacent matrix, and $\bm{A}_{ig} = 1$ indicates item $i\in \mathcal{I}_g$, and 0 otherwise. Let $\bm{w}\in\mathbb{R}^{|\mathcal{I}|} = [-\sum_{u\in\mathcal{U}}c_{u,i}\log(\hat{c}_{u,i})]_{i\in\mathcal{I}}$. 

    Firstly, if an item belongs to multiple groups, it often has a greater impact on other items in the model. Therefore, we will conduct row normalization on the adjacency matrix $A$ with size $I \times G$ to mitigate this influence: we conduct $\hat{\bm{A}}$ is the row-normalized matrix for $\bm{A}$: $\hat{\bm{A}}=\text{diag}(\bm{A}\bm{1})^{-1}\bm{A}$. $\text{diag}(\bm{x})$ denotes to construct a diagonal matrix based on vector $\bm{x}$.

    Then, in RS, since the ranking list $L_K(u)$ is selected according to the highest preference score $c_{u,i}$, therefore
    we can re-write Equation~\eqref{eq:obj} as:
    \begin{equation}
    \begin{aligned}
        \min \quad& \bm{1}^{\top}(\hat{\bm{A}}^{\top}\bm{w}) \\
            \textrm{s.t.}\quad & s_g = \sum_{u\in\mathcal{U}} \sum_{i\in L_K(u)} -\frac{\mathbb{I}(i\in \mathcal{I}_g)}{n_i}c_{u,i}\log(\hat{c}_{u,i}) \leq m_g M, \forall g\in\mathcal{G} \\
            & \sum_{i\in\mathcal{I}} c_{u,i} \leq K, \forall u\in\mathcal{U}.
    \end{aligned}
    \end{equation}

    Then we can still write the Equation as
    \begin{equation}
    \begin{aligned}
        \min \quad& \bm{1}^{\top}(\hat{\bm{A}}^{\top}\bm{w}) \\
            \textrm{s.t.}\quad & \max_{g\in\mathcal{G}} (\hat{\bm{A}}^{\top}\bm{w})_g \leq m_g M.
    \end{aligned}
    \end{equation}

    Due to Lagrange dual method~\citep{boct2008strong}, we can still convert the problem as:
     \begin{equation}
        \min \max_{\lambda} - \bm{1}^{\top}(\hat{\bm{A}}^{\top}\bm{w}) + \lambda (\max_{g\in\mathcal{G}} \frac{(\hat{\bm{A}}^{\top}\bm{w})_g}{m_g} - M).
    \end{equation}

    % Then we utilize max-min theorem~\citep{boct2008strong}, we have
    % \begin{equation}
    %     \mathcal{L} \leq \min_{\lambda} \max \bm{1}^{\top}\bm{A}^{\top}\bm{w} + \lambda (\min_{g\in\mathcal{G}} (\bm{A}^{\top}\bm{w})_g).
    % \end{equation}
    %when we set the fairness threshold $m\in [0, |\mathcal{U}|K/|\mathcal{G}|\max(-c_{u,i}\log(\hat{c}_{u,i}))]$ (since the most fair situation would be different group receive same exposure $\mathcal{U}|K/|\mathcal{G}|$),
    Therefore, we can always find a $\lambda \ge 0$ ($\lambda$ value relates to the value of $M$), such that we can directly optimize 
    \begin{equation}
        \min \bm{1}^{\top}\hat{\bm{A}}^{\top}\bm{w} + \lambda \max_{g\in\mathcal{G}} \frac{(\hat{\bm{A}}^{\top}\bm{w})_g}{m_g}.
    \end{equation}

    Let $\bm{\gamma}\in\mathbb{R}^{|\mathcal{G}|}$ be the vector $[1/m_1, 1/m_2, \cdots, 1/m_{|\mathcal{G}|}]$, then the equation can be written as:
    
    \begin{equation}\label{eq:linear_trade_off}
        \min \bm{1}^{\top}\hat{\bm{A}}^{\top}\bm{w} + \lambda \max_{g\in\mathcal{G}} \bm{\gamma}_g (\hat{\bm{A}}^{\top}\bm{w})_g.
    \end{equation}

   Furthermore, the minimum function $\max(\cdot)$ can be viewed as the infinite norm function:
    \[
        \max \bm{x} = \lim_{t \to \infty} (\bm{1}^{\top} \bm{x}^t)^{1/t}.
    \]

    Then we consider the following function:
    \[
        g(\bm{x}; \bm{k}; s)= (\bm{k}^{\top} \bm{x}^{1+s})^{\frac{1}{1+s}},
    \]
    where $\bm{0} \leq \bm{x} \leq M\bm{1}$. Therefore, Equation~\eqref{eq:linear_trade_off} can be regarded as a linear trade-off between two points with the $\lambda \ge 0$ as the trade-off coefficient:
    \[
       \min_{w\in\mathcal{W}} g(\hat{\bm{A}}^{\top}\bm{w}; \bm{1}; 0) + \lambda g(\hat{\bm{A}}^{\top}\bm{w}; \bm{\gamma} ;\infty).
    \]

    Since $g(\bm{x}; t)$ is continuous \wrt $t$ and the feasible region of $\bm{x}$ is convex and continuous (because $\bm{w}\in\mathcal{W}$ is the linear transformation over a simplex space~\citep{lindenstrauss1978poulsen}), there exists a constant number $t\ge 0$ and $\bm{b}\in\mathbb{R}^{|\mathcal{G}|}$,
    s.t.
    Equation~\eqref{eq:obj} can be optimized as:
    % \[
    %     \mathcal{L} = \min \left(\bm{1}^{\top}(\hat{\bm{A}}^{\top}\bm{w})^{1+t}\right)^{\frac{1}{1+t}}
    % \]
    % From Equation~\eqref{eq:obj}, $t$ is a constant number, therefore, optimizing Equation~\eqref{eq:obj} can be regarded as 
    \[
        \mathcal{L} = \min \bm{b}^{\top}(\hat{\bm{A}}^{\top}\bm{w})^{1+t}.
    \]
    This is because $t$ is a constant number and $\bm{k}$ for optimizing $g(\bm{x}; \bm{k}; s)$ is linear w.r.t. to $x^{(1+s)}$ (Since the $x$ is the variable and $s$ is constant). 

    Note that the specific value of $t$ is an implicit function and cannot be solved explicitly in closed form. This is because according to the fact that the function $g$ is continuous with respect to $s$ over its entire domain and based on the intermediate value theorem for continuous functions, there must exist a $t$ such that the linear combination of the linear functions at the two endpoints equals.
    
    Nonetheless, we emphasize that the subsequent methods and proof strategies are independent of the explicit solution for $t$. As long as there exists a $t\neq0$, the Jansen gap exists, and as $\lambda$ increases, $t$ will also increase.
    
    
    % \[
    %  \mathcal{L} = \max    \begin{cases} 
    %    \left(\bm{1}^{\top}(\bm{A}^{\top}\bm{w})^{1-t}\right)^{\frac{1}{1-t}} & \text{if } t \ge 0, t \neq 1 \\
    %    \bm{1}^{\top}\log(\bm{A}^{\top}\bm{w}) & \text{if } t=1. \\
    %  \end{cases}\\
    % \]

    % From Equation~\eqref{eq:obj}, when $t\neq 1$ and $t$ is a constant number, therefore, optimizing Equation~\eqref{eq:obj} can be regarded as 
    % \[
    %     \mathcal{L}' = \max    \begin{cases} 
    %    \bm{1}^{\top}(\bm{A}^{\top}\bm{w})^{1-t} & \text{if } t \ge 0, t \neq 1 \\
    %    \bm{1}^{\top}\log(\bm{A}^{\top}\bm{w}) & \text{if } t=1. \\
    %  \end{cases}\\
    % \]

    % \begin{cases} 
    %   \left(\bm{1}^{\top}(\bm{A}^{\top}\bm{w})^{1-t}\right)^{\frac{1}{1-t}} & \text{if } t \ge 0, t \neq 1 \\
    %   \bm{1}^{\top}\log(\bm{A}^{\top}\bm{w}) & \text{if } t=1 \\
    % \end{cases}\\
    
    
\end{proof}

\section{Lemma~\ref{lemma:partition}}
\begin{lemma}\label{lemma:partition}
    When $t\ge 0$, let 
    \[
    f(x)=x^{t+1}
    \]
    
    where $x>0$. And
    \begin{equation}
        \begin{aligned}
            \quad& e(i) = \sum_{l=1}^i f(y_l) \\
            \textrm{s.t.}\quad & \sum_{l=1}^i y_l \leq c, \quad y_l \ge 0\\
           % & y_l \leq g_l, \quad \forall i\in [1,2,\cdots, l],
        \end{aligned}
    \end{equation}
    where $c$ is a constant number. Then we have when $j\ge i$: we have $\min_{y_j} e(j) \leq \min_{y_i} e(i)$. 
    

\end{lemma}

\begin{proof}

    According to the Lagrange dual method, we have
    \[
        \min e(i) = \min \max_{\lambda\ge 0} \sum_{l=1}^i f(y_l) + \lambda (\sum_{l=1}^i y_l) - \lambda c,
    \]
    then according to the condition of the first derivative equaling zero, we have
    \[
        \frac{\partial e(i)}{\partial y_l} = y_i^{t} + \lambda = 0, \quad \frac{\partial e(i)}{\partial \lambda} = \sum_{l=1}^i y_l - c = 0.
    \]
    Taking these two condition together, we have:
    \[
        y_k = y_m = \frac{c}{i}, \quad \forall k,m = [1,2,\cdots, i].    
    \]
    %\sum_{l=1}^i\lambda^{\frac{1}{t}} = c, \quad 
    Therefore, we have

    \begin{align*}
        \min_{y_j} e(j) - \min_{y_i} e(i) & =\min_{y_j} \sum_j f(y_j) - \min_{y_i}\sum_i f(y_i)\\
        &= (\frac{c}{j})^{1+t} - (\frac{c}{i})^{1+t} 
    \end{align*}

    Then we can see function $\frac{1}{x^{1+t}}$ is a decreasing function function, therefore, $\min_{y_j} e(j) \leq \min_{y_i} e(i)$.
    

    % $\bullet$ When $0< t<1$, we can see function $\frac{1}{x^{1-t}}$ is a decreasing function function, therefore, $\max_{y_j} e(j) \leq \max_{y_i} e(i)$.

    % $\bullet$ Similarly, When $t>1$, we can see function $\frac{1}{x^{1-t}}$ is a increasing function function, $\max_{y_j} e(j) \ge \max_{y_i} e(i)$. 

    % $\bullet$ When $t=1$, the same approach as before, we can see the function $\log(\frac{1}{x})$ is also a decreasing function, therefore, $\max_{y_j} e(j) \leq \max_{y_i} e(i)$.
    
\end{proof}

\section{Proof of Theorem~\ref{theo:error}}\label{app:prof_error}

\begin{proof}
    Under mini-batch sample strategies, we partition the user set $\mathcal{U}$ into $|\mathcal{U}|/B$ subsets and perform optimization on each subset. For each batch, the optimization becomes
    \begin{equation}\label{eq:partition}
         \begin{aligned}
        \mathcal{L}^B = \min \quad& \sum_{j=1}^{|\mathcal{U}|/B} \bm{b}^{\top}(\hat{\bm{A}}^{\top}\bm{w}_j)^{1+t} \\
            \textrm{s.t.}\quad & \bm{w}_{j,i} = -\sum_{u\in\mathcal{U}_j}c_{u,i}\log (\hat{c}_{u,i}), \forall i\in\mathcal{I}, j\in [1,2,\cdots, |\mathcal{U}|/B],
    \end{aligned}
    \end{equation}
    where $\mathcal{U}_b$ is the $b-$th partition of the user set $\mathcal{U}$.

     Since the function $f(x) = x^{1+t}$ is not a linear function, we have 
    \[
        \sum_{j=1}^{|\mathcal{U}|/B} \bm{b}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1+t} \neq \bm{b}^{\top}(\bm{A}^{\top}\bm{w})^{1+t}.
    \]
    and we can get the Jensen gap
    \[
        J(B) = |\mathcal{L}^B - \mathcal{L}| \neq 0.
    \]

    Then we will observe how $e(B)$ changes \wrt the mini-batch size $B$.
    
    Let $\bm{e} = \hat{\bm{A}}^{\top}\bm{w}$, where each element $\bm{e}_g$ represents the utility (sum of user-item scores) of group $g$. According to the recommendation constraint, we have $\bm{e}_g \leq L$, meaning that the utility of group $g$ is at least as high as when all items belonging to group $g$ are recommended to the users. 
    
    Therefore, taking $f(\bm{e}_g)=\bm{e}_g^{1+t}$ into Lemma~\ref{lemma:partition}, without loss of generality, when batch size $B_2\leq B_1$, we have: $|\mathcal{U}|/B_2\ge |\mathcal{U}|/B_1$,
    we can easily have:
    %when $0<t \leq 1$, we have when batch size $B_2\leq B_1$, 
    \[
         \min \sum_{j=1}^{|\mathcal{U}|/B_2} (\bm{A}^{\top}\bm{w}_j)_g^{1+t}\leq \min \sum_{j=1}^{|\mathcal{U}|/B_1} (\bm{A}^{\top}\bm{w}_j)_g^{1+t} \leq \min \bm{e}_g^{1+t}.
    \]
    Therefore, we have
    \[
        \min \sum_{j=1}^{|\mathcal{U}|/B_2} \bm{b}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1+t}\leq \min \sum_{j=1}^{|\mathcal{U}|/B_1} \bm{b}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1+t} \leq \min \bm{b}^{\top}\bm{e}^{1+t}.
    \]
    In other words, the mini-batch size becomes smaller, and we are more likely to underestimate the original loss function that trades off MMF and recommendation accuracy. The recommendation loss underestimation will result in the Jensen gap when optimizing the loss function constraint with MMF.
    %In other words, when the fairness degree is small, the mini-batch size becomes smaller, and we are more likely to underestimate the original loss function that trades off MMF and recommendation accuracy. 

    
   %   Similarly, When $t>1$,  we have when batch size $B_2\leq B_1$, 
   %   \[
   %       \max \sum_{j=1}^{|\mathcal{U}|/B_2} (\bm{A}^{\top}\bm{w}_j)_g^{1-t} \ge \max \sum_{j=1}^{|\mathcal{U}|/B_1} (\bm{A}^{\top}\bm{w}_j)_g^{1-t} \ge \max \bm{e}_g^{1-t}.
   %  \]
   %  Therefore, we have
   %  \[
   %      \max \sum_{j=1}^{|\mathcal{U}|/B_2} \bm{1}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1-t}\ge \max \sum_{j=1}^{|\mathcal{U}|/B_1} \bm{1}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1-t} \ge \max \bm{1}^{\top}(\bm{A}^{\top}\bm{w})^{1-t}.
   %  \]
   %  In other words, when the fairness degree is high and the mini-batch size becomes smaller, we are more likely to overestimate the original loss function.

    
   % Following a similar proof structure, the group size $|\mathcal{G}|$ is also employed to partition the dataset. Moreover, the partitioned groups are also embedded in a simplex space:
   %  \[
   %      \sum_{g\in\mathcal{G}} |\mathcal{I}_g| = \mathcal{I}, |\mathcal{I}_g|\ge 0.
   %  \]
   %  Therefore, the conclusion remains the same: when $0< t\leq 1$, when the mini-batch size becomes smaller, we are more likely to underestimate the original loss and when $t>1$, we are more likely to overestimate the original loss function with mini-batch size becomes smaller.
    
\end{proof}



\section{Lemma~\ref{lem:reg_form}}
\begin{lemma}\label{lem:reg_form}
Considering the following function, for $\lambda>0, L>0$ and for the $d$-th dimension variable $\bm{\mu}\in\mathbb{R}^d$, when $\bm{\mu}\in\mathcal{M}$:
\begin{equation}
    r(\bm{\mu}) = \max_{\bm{x}\leq \bm{m}} (\min {\bm{x}}/\bm{m}+\bm{\mu}^{\top}\bm{x}/\lambda),
\end{equation}
where 
\[
    \mathcal{M} =\left\{\bm{\mu} ~\left|~ \sum_{i\in [d]} \bm{\mu}_im_i \ge -\lambda, \forall [d]\in \mathcal{S}\right.\right\},
\]  
where $\mathcal{S}$ is power set of $[1,2,\cdots, d]$, \ie the set of all subsets of $[1,2,\cdots, d]$. 

When $\bm{\mu}\in\mathcal{M}$, the optimization function $r(\cdot)$ has a closed form:
$
    r(\bm{\mu}) = \bm{m}^{\top}\bm{\mu}/\lambda + 1,
$
and
$
    \bm{m} = \argmax_{\bm{x}\leq \bm{m}} (\min {\bm{x}}/\bm{m}+\bm{\mu}^{\top}\bm{x}/\lambda).
$

When $\bm{\mu} \notin\mathcal{M}$, the function $r(\cdot)$ will diverge to $\infty$.
\end{lemma}

\begin{proof}
    Let the variable $\bm{z} = \bm{x}/\bm{m}-\bm{1}$. Then we have:
\begin{align*}
    r(\bm{\mu}) &= \max_{\bm{x}\leq \bm{m}}\left[\min \bm{x}/\bm{m} + \bm{\mu}^{\top}\bm{x}/\lambda\right]\\
    &= \bm{\mu}^{\top}\bm{m} /\lambda +  1 + \max_{\bm{z} \leq \bm{0}}\left[\min_i \bm{z}_i + (1/\lambda) \bm{\mu}^{\top}(\bm{z}\odot\bm{m})\right],
\end{align*}
where $\odot$ is the Hadamard product.


Let 
\[
    \bm{v} = \bm{m}\odot\bm{\mu}/\lambda,
\]
then we define 
\[
    s(\bm{v}) = \max_{\bm{z}\leq 0}\left( \min_i \bm{z}_i + \bm{z}^{\top}\bm{v}\right).
\]

From the definition of the region $\mathcal{M}$, we can re-wright $\mathcal{M}$ as
\[
    \mathcal{M} = \{\bm{v}|\sum_{i\in [d]}\bm{v}_i \ge -1, \forall [d]\in \mathcal{S}\}.
\]

Suppose that there exists a subset $\mathcal{S}\in [1,2,\cdots, d]$ such that $\sum_{i\in\mathcal{S}} \mathbf{v}_i < -1$. For any $\epsilon/|\mathcal{S}| > 1$, we can get a feasible solution:
\begin{align*}
\begin{split}
\bm{v}_i= \left \{
\begin{array}{ll}
   -\epsilon/|\mathcal{S}|,                    & i\in \mathcal{S}\\
    0,                    & otherwise.
\end{array}
\right.
\end{split}
\end{align*}
Then, because such solution is feasible and $\min_i \bm{z}_i = -\epsilon$, and $|\mathcal{S}|\ge 1$, we obtain that 
\begin{align*}
    s(\bm{v}) &\ge \min_i \bm{z}_i - (\epsilon/|\mathcal{S}|)(\sum_{i\in\mathcal{S}}\bm{v}_i) = -\epsilon(\sum_{i\in\mathcal{S}}\bm{v}_i+1/|\mathcal{S}|)\\
    &\ge \epsilon(\sum_{i\in\mathcal{S}}\bm{v}_i+1).   
\end{align*}

Let $\epsilon\rightarrow\infty$, we have $s(\bm{v})\rightarrow\infty$.

Then we show that $s(\bm{\mu}) = 0$ for $\bm{v}\in\mathcal{M}$. Note that $\bm{z} = 0$ is feasible. Therefore, we have
\[
    \min_i \bm{v}_i \ge s(0) = 0.
\]

Then we have $\bm{z} \leq 0$ and without loss of generality, that the vector $\bm{z}$ is sorted in increasing order, i.e., $\bm{z}_1\leq \bm{z}_2, \cdots, \leq \bm{z}_d$.
The objective value is
\begin{align*}
     s(\bm{v}) &= \mathbf{z}_1 + \bm{v}^{\top}\bm{z} \\
     &= \sum_{j=1}^{d}\left(\bm{z}_j-\bm{z}_{j+1}\right)\left(1+\sum_{i=1}^{j}\bm{v}_j\right)\leq 0.
\end{align*}

Thus we can have $s(\bm{\mu}) = 0$ for $\mathbf{v}\in\mathcal{M}$. Finally, we can have 
$
    \argmax_{\bm{x}\leq \bm{m}} (\min_g {\bm{x}_g}/\bm{m}_g+\bm{\mu}^{\top}\bm{x}/\lambda)=\bm{m}.
$


% We firstly show that if $\sum_{p\in\mathcal{S}}\mathbf{v}_p \ge -1, \forall \mathcal{S}\in\mathcal{P}_s$, then $s^*(\mathbf{v}) = 0$ and $\mathbf{z} = 0$ is the optimal solution, otherwise $s^*(\mathbf{v}) = \infty$.

% \begin{aligned}
%         \mathcal{L}^B = \max \quad& \sum_{j=1}^{|\mathcal{U}|/B} \bm{1}^{\top}(\bm{A}^{\top}\bm{w}_j)^{1-t} \\
%             \textrm{s.t.}\quad & \bm{w}_{b,i} = \sum_{u\in\mathcal{U}_b}c_{u,i}\log (\hat{c}_{u,i}), \forall i\in\mathcal{I}, b\in [1,2,\cdots, |\mathcal{U}|/B],
% \end{aligned}
    
\end{proof}

\section{Lemma~\ref{lem:convex}}
\begin{lemma}\label{lem:convex}
The feasible space $\mathcal{M}$ of dual variable $\bm{\mu}$ is convex.
\end{lemma}

\begin{proof}
    Suppose $\bm{\mu}\in\mathcal{M}$, from Lemma~\ref{lem:reg_form}, we have
    \begin{align*}
       r(\bm{\mu}) = \max_{\bm{x}\leq \bm{\gamma}} (\min {\bm{x}}/\bm{\gamma}+\bm{\mu}^{\top}\bm{x}/\lambda) < \infty,
    \end{align*}
    therefore, for any $\bm{b}\in\mathbb{R}_{+}^{|G|}$ and $c>0$, we have
    \begin{align*}
       r(\bm{\mu}+c\bm{b}) &= \max_{\bm{x}\leq \bm{\gamma}} (\min {\bm{x}}/\bm{\gamma}+(\bm{\mu}+c\bm{b})^{\top}\bm{x}/\lambda) \\
       &=r(\bm{\mu}) + Lc\bm{b}^{\top}\bm{1} < \infty.
    \end{align*}
    Therefore, $\bm{\mu}+c\bm{b}\in\mathcal{M}$.
\end{proof}

\section{Proof of Theorem~\ref{theo:reweight}}\label{app:prof_reweight}

\begin{proof}
    Let $\bm{e} = \bm{A}\bm{w}$, where each element $\bm{e}_g$ measures the ranking score accumulated among group $g$. Let $L$ be the maximum ranking score for each group, \ie $\bm{e}\leq L\bm{1}$.
    
    According to the proof in Theorem~\ref{theo:alpha_fair}, we can see the Equation~(\ref{eq:obj}) can be written as:
     \begin{align*}
            \quad& \min \sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}}c_{u,i}\log(\hat{c}_{u,i}) + \lambda (\max_{g\in\mathcal{G}} \bm{e}_g/m_g) \\
            \textrm{s.t.}\quad & \bm{e}_g = -\frac{\mathbb{I}(i\in \mathcal{I}_g)}{n_i}c_{u,i}\log(\hat{c}_{u,i}), \forall g\in\mathcal{G}.
    \end{align*}

    Then the equation can be re-written as:

    
    \begin{equation}\label{eq:allocation}
        \begin{aligned}
            \quad& \max_{\hat{c}_{u,i}} \sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}}c_{u,i}\log(\hat{c}_{u,i}) + \lambda (\min_{g\in\mathcal{G}} \bm{e}_g/m_g) \\
            \textrm{s.t.}\quad & \bm{e}_g = \sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}} \mathbb{I}(i\in\mathcal{I}_g)c_{u,i}\log(\hat{c}_{u,i}), \forall g\in\mathcal{G}.
        \end{aligned}
    \end{equation}
    Then e can utilize the Lagrangian condition~\citep{balseiro2021regularized} to decompose the relation between $\bm{e}$ and model prediction $\hat{c}_{u,i}$ in Equation~\eqref{eq:allocation}:
    \begin{equation}\label{eq:dual_form}
        \begin{aligned}
        \quad& \max_{\hat{c}_{u,i}} \min_{\bm{\mu}} \sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}}c_{u,i}\log(\hat{c}_{u,i}) + \lambda (\min_{g\in\mathcal{G}} \bm{e}_g/m_g) - \sum_{g\in\mathcal{G}}\bm{\mu}_g\left(\bm{e}_g-\sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}} \mathbb{I}(i\in\mathcal{I}_g)c_{u,i}\log(\hat{c}_{u,i})\right)\\
        &\leq \min_{\bm{\mu}} \max_{\hat{c}_{u,i}} \sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}}c_{u,i}\log(\hat{c}_{u,i}) + \lambda (\min_{g\in\mathcal{G}} \bm{e}_g/m_g) + \sum_{g\in\mathcal{G}}\bm{\mu}_g\left(\bm{e}_g-\sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}} \mathbb{I}(i\in\mathcal{I}_g)c_{u,i}\log(\hat{c}_{u,i})\right)\\
        &= \min_{\bm{\mu}} \max_{\hat{c}_{u,i}}  \left(\sum_{u\in\mathcal{U}}\sum_{i\in \mathcal{I}} (1-\sum_{g\in\mathcal{G}}\bm{\mu}_g\mathbb{I}(i\in\mathcal{I}_g))c_{u,i}\log(\hat{c}_{u,i})\right) + \lambda \min_g \bm{e}_g/m_g + \bm{\mu}^{\top}\bm{e}\\
        &= \min_{\bm{\mu}} \max_{\hat{c}_{u,i}}  \left(\sum_{u\in\mathcal{U}}\sum_{g\in\mathcal{G}}(1-\bm{\mu}_g)\sum_{i\in\mathcal{I}_g}c_{u,i}\log(\hat{c}_{u,i})\right) + \lambda \min_g \bm{e}_g/m_g + \bm{\mu}^{\top}\bm{e}.\\
        \end{aligned}
    \end{equation}

    From the Equation~\eqref{eq:dual_form}, we can observe that the recommendation task constrained by max-min fairness can be viewed as a re-weighting approach across different groups on the original loss function solely optimized for accuracy:
    \[
        \mathcal{L} = \min -\sum_{u\in\mathcal{U}}\sum_{g\in\mathcal{G}}\bm{s}_g\sum_{i\in\mathcal{I}_g}c_{u,i}\log(\hat{c}_{u,i}),
    \]
    where the fairness weight $\bm{\mu}$ is determined by 
     \[
    \bm{\mu} =  \argmin_{\bm{\mu}\in\mathcal{M}} \left(\max \sum_{u\in\mathcal{U}}\sum_{g\in\mathcal{G}}\bm{s}_g\sum_{i\in\mathcal{I}_g}c_{u,i}\log(\hat{c}_{u,i}) + \lambda r^*(\bm{\mu})\right),
    \]
    \[
    r^*(\bm{\mu}) = \max_{\bm{w}\leq \bm{m}} \left(\min_g (\bm{A}\bm{w})_gm_g+\bm{A}^{\top}\bm{w}\bm{\mu}/\lambda\right)=\bm{m}^{\top}\bm{\mu}/\lambda+1.
    \]

    To make sure the functions do not diverge, we need to ensure $r^*(\bm{\mu})< \infty$. Taking the $r^*(\bm{\mu})$ into Lemma~\ref{lem:reg_form}, we show
    $\bm{\mu}\in\mathcal{M}$, where
    \[
    \mathcal{M}=\left\{\bm{\mu} ~\left|~ \sum_{g\in\mathcal{S}} \bm{\mu}_gm_g \ge -\lambda, \forall \mathcal{S}\in\mathcal{G}_s\right.\right\},
    \]
    where $\mathcal{G}_s$ is power set of $\mathcal{G}$, i.e., the set of all subsets of $\mathcal{G}$.
    


    

    

    
    
    
    % Following the Theorem 1 and Theorem 2 in~\citet{xu2023p}, we can write the dual form of Equation~(\ref{eq:linear_trade_off}) as:
    % \begin{equation}
    %     \min_{\mu\in\mathcal{M}} \left(\max \sum_{u\in\mathcal{U}}\sum_{i\in\mathcal{I}}(1+\bm{A}\bm{\mu})c_{u,i}\log(\hat{c}_{u,i}) + r^*(\bm{\mu})\right),      
    % \end{equation}
    % where exist a $L>0$, $r^*(\mu) = \max_{\bm{A}^{\top}\bm{w}\leq L\bm{1}} \left(\lambda \min (\bm{A}^{\top}\bm{w})+\bm{\mu}^{\top}\bm{A}^{\top}\bm{w}\right)=\bm{1}^{\top}\bm{\mu}/(\lambda L)$, $\mathcal{M}=\{\bm{\mu}|\bm{1}^{\top}\bm{\mu}\ge -\lambda/L\}$. Therefore, the weight would be $s_g= (1+\bm{\mu}_g)$.
\end{proof}

\section{Proof of Theorem~\ref{theo:Jensen_Gap}}\label{app:prof_Jensen_Gap}
\begin{proof}
    \textbf{We first bound the performance on the primal space}. 
    
    Let $N=\frac{|\mathcal{U}|}{B}$ be the total batch number.
    Considering the $j-$th batch, we have the accuracy loss function without fairness at $j-$th batch as:
    \[
        \mathcal{L}^j(\text{ACC}) = (\bm{s}^j + \bm{A}^j\bm{\mu}^j)^{\top}\bm{l}^j = \bm{1}^{\top}\bm{l}^j,
    \]
    and the max-min fairness loss function will become:
    \[
        \mathcal{L}^j(\text{Fair}) =  r^*(\bm{\mu}) - (\bm{\mu}^j)^{\top}\bm{e}/\lambda,
    \]
    therefore, the overall loss across $\mathcal{L}^B$ on the primal space utilizing batch training will become:
    \begin{align*}
        N\mathbb{E}_j[\mathcal{L}^j] &= N\mathbb{E}_j[\mathcal{L}^j(\text{ACC})+\lambda \mathcal{L}^j(\text{Fair})] \\
        &= N\mathbb{E}_j[(\bm{s}^j + \bm{A}^j\bm{\mu}^j)^{\top}\bm{l}^j + \lambda r^*(\bm{\mu}) - (\bm{\mu}^j)^{\top}\bm{e}]\\
        &= \mathcal{L}^{'B} - N\mathbb{E}_j[(\bm{\mu}^j)^{\top}(\bm{e}-(\bm{A}^j)^{\top}\bm{l}^j)].
    \end{align*}

    The term 
    \[
    w(\bm{\mu}^j)= (\bm{\mu}^j)^{\top}(\bm{e}-(\bm{A}^j)^{\top}\bm{l}^j)
    \]
    is considered as the complementary slackness in dual theory~\citep{churchman1957introduction}, which captures error from the dual transformation. And $\mathcal{L}^{'B}$ is the same in Equation~\eqref{eq:dual_loss}. Therefore, the original loss can be viewed as the dual form augmented with a complementary slackness form. 

    \textbf{Then we utilize the online gradient descent to bound the complementary slackness}.

    Let $\bm{\mu} = \sum_{j=1}^N \bm{\mu}^j$, then the loss without dividing the full dataset into batches can be represented as:
    \[
        \mathcal{L} = \mathcal{L}' - w(\bm{\mu}).
    \]

    After observing the dual form of $\mathcal{L}'$, we can see the $\mathcal{L}'$ is linear \wrt dual variable $\bm{\mu}$, therefore, we have
    \[
        \mathcal{L}' = \mathcal{L}^{'B},
    \]
    and the Jensen gap 
    \[
        J(B) = |\sum_{j=1}^Nw(\bm{\mu}^j)-w(\bm{\mu})|.
    \]

    Given $\|\widetilde{g}^j\|_2\leq G$, for all $j$, we have:
    \[
        \| \mathbf{g}^j \|_2 = \|(1-\alpha)\sum_{s=1}^j\alpha^{j-s}(\widetilde{\mathbf{g}}^s)\|_2 \leq G.
    \]
    Next, we will bound the value of $G$. Firstly, according to the dual gradient descent, we have:
    \[
        \widetilde{\bm{g}}^j=\partial (\bm{s}^j\mathcal{L}^j + \lambda r^*(\bm{\mu}^j)) = -(\mathbf{A}^j)^{\top} \widetilde{\bm{w}}+ \bm{\gamma}_j.
    \]
    where $\bm{\gamma}_j$ is the remain maximum loss column at $j-$th updating batch. 
    
    Therefore, we have the each element of $\widetilde{\bm{w}}_b$ has the bound of
    \[
        \widetilde{\bm{w}}_b \leq K,
    \]
   since each user can obtain a maximum ranking score of 1 for each preferred item in the ranking list with a size of $K$. Typically, the group size is smaller than batch size ($|\mathcal{G}|<B$) and there exists $c=\max_g m_g$ (typically, $m_g$ is proportional to the group size $|\mathcal{G}|$. Then we get
    \[
        \|\widetilde{\bm{g}}^j\|_2^2 \leq |\mathcal{G}|(c + K)^2 \leq L|\mathcal{G}|^2,
    \]
    where $L>0$.

    
    According to the Theorem 2 in~\cite{balseiro2021regularized}, we have
    \begin{align*}
        J(B) = |\sum_{j=1}^{N}w(\bm{\mu}^j) - w_t(\bm{\mu})| &\leq \frac{H}{\eta} + \frac{G^2}{(1-\alpha)\sigma}\eta\frac{|\mathcal{U}|}{B} + \frac{G^2}{2(1-\alpha)^2\sigma\eta} \\
        &= \frac{H}{\eta} + \frac{|\mathcal{U}|L|\mathcal{G}|^2}{B(1-\alpha)\sigma}\eta + \frac{L|\mathcal{G}|^2}{2(1-\alpha)^2\sigma\eta}
    \end{align*}

    where function $\|\cdot\|_2^2$ is $\sigma-$strongly convex.
    When setting learning rate $\eta=O(B^{-1/2})$, the Jensen Bound is comparable with $O(B^{-1/2})$.
    


    
    
\end{proof}


\section{Generalizability to Other Forms of Fairness}\label{app:generalize}
In fact, our method can be easily generalized to the user group level by replacing the adjacency matrix with a user-side equivalent while keeping the rest unchanged. For the two-sided form, it simply requires introducing two coefficients, $\lambda_1$ and $\lambda_2$, and applying two independent dual gradient descent updates as described in our algorithm.

In Theorem~\ref{theo:alpha_fair}, we demonstrate that our optimization objective is equivalent to the power-family fairness framework, which encompasses mainstream fairness definitions such as Entropy Fairness, $\alpha$-Fairness, and Theil Index~\cite{lan2011axiomatic}. Consequently, our method is highly adaptable and can be generalized to various fairness objectives within this framework.

\section{Details of Experimental Settings}\label{app:exp_settings}
Here we will provide the details of experimental settings.

\textbf{Detailed Implementation Details.} 


\begin{itemize}
\item Environment: our experiments were implemented using Python 3.9 and PyTorch 2.0.1+cu117~\citep{pytorch}. All experiments were conducted on a server with an NVIDIA A5000 running Ubuntu 18.04. We implement FairDual with the cvxpy~\citep{cvxpy} for optimization.

\item Hyper-parameter settings: the learning rate $\eta\in [1e^{-2},1e^{-4}]$ (results shown in Figure~\ref{fig:para_analysis2}), and trade-off factor $\lambda\in [0, 10]$ (results shown in Figure~\ref{fig:analysis}). We set the $m_g$ as the group size $m_g=|\mathcal{I}_g|$. We also tune sample number $Q\in [50, 400]$ (results shown in the Table~\ref{tab:sample_size}), historical length $H\in [3,7]$ (results shown in Table~\ref{tab:history_length}), freeze parameter updating gap $\beta\in[128, 3840]$ (results shown in Figure~\ref{fig:para_analysis}). 

\item LLMs settings: To mitigate the impact of randomness, we set the temperature coefficient to 0.2 for the LLM and ran each model three times, taking the average of the results. Other LLMs settings are: the penalty for frequency is 0.0, and the penalty for presence is 0.0, the maximum generated token number to 1024.

\item Used toolkit: For the Non-LLMs-RS backbones, we mainly reference the RecBole toolkit\footnote{https://github.com/RUCAIBox/RecBole}. For the LLMs tuning, we reference the BigRec pipelines \footnote{https://github.com/SAI990323/BIGRec}. And we have also included our code in the supplementary materials to ensure reproducibility.
\end{itemize}



\textbf{Datasets}. The experiments are conducted on the commonly used two widely used and publicly available recommendation datasets, including: 
\begin{itemize}
    \item MIND~\citep{wu2020mind}\footnote{\url{https://microsoftnews.msn.com}}: it is constructed from user news click behavior logs on the Microsoft News platform. we utilize the major topic category of the news to group the items. The dataset contains 94,057 users, 18,801 items, 124,154 interactions, and 17 groups.
    \item Amazon-Book~\footnote{\url{http://jmcauley.ucsd.edu/data/amazon/}}: 
The Amazon dataset from the book domain~\citep{he2016ups} with item grouping based on the "categories" field. As part of the preprocessing~\citep{xu2024fairsync}, groups containing fewer than 50 items are amalgamated into a single group, referred to as the ``infrequent group''. The dataset contains 15,362,619 users, 1,175,085 items, 1,051,862 interactions, and 25 groups.
    \item Amazon-Electronic~\footnote{\url{http://jmcauley.ucsd.edu/data/amazon/}}: 
The Amazon dataset from the electronic products~\citep{he2016ups} with item grouping based on the "categories" field. As part of the preprocessing~\citep{xu2024fairsync}, groups containing fewer than 50 items are amalgamated into a single group, referred to as the ``infrequent group''. The dataset contains 728,719 users, 160,052 items, 6,739,590 interactions, and 19 groups.
\end{itemize}

\textbf{Backbones}. For the backbone, we first select three large-scale recommender models:
\begin{itemize}
    \item \textbf{NRMS}~\citep{wu-etal-2019-neural-news} with 110M parameters utilizes BERT~\citep{devlin2018bert} as the feature extractor.
    \item \textbf{RecFormer}~\citep{Recformer} with 150M parameters utilizes LongFormer~\citep{beltagy2020longformer} to learn text-based representation from items
    \item \textbf{BigRec}~\citep{bao2023bi} utilizes Lora techniques~\citep{hu2021lora} to fine-tune Llama 2~\citep{touvron2023llama} (with 7B parameters). Note that BigRec only utilizes 1024 samples to train due to large computational cost.
\end{itemize}

Meanwhile, we also cover three traditional recommender models:
\begin{itemize}
    \item \textbf{BPR}~\cite{BPR} utilized a pair-wise loss function to train a matrix factorization model for recommendation.
    \item \textbf{GRU4Rec}~\cite{gru4rec} utilized gated recurrent unit network to learn the historical behaviors of users.
    \item \textbf{SASRec}~\cite{SASRec} utilized attention network to learn the historical behaviors of users.
\end{itemize}

\textbf{Baselines.}

For the baselines, we choose several fair-aware re-weight baselines that aim to improve group MMF: 
\begin{itemize}
    \item \textbf{UNI}: each sample has the same weight during training.
    \item \textbf{DRO}~\citep{hashimoto2018fairness}: every step, the model only optimizes the worst-off groups to enhance grou MMF.
    \item \textbf{S-DRO}~\citep{wen2022distributionally}: improves DRO with the distributional shift to optimize group MMF.
    \item \textbf{Prop}~\citep{hu2023adaptive}  assigns higher group weight to the samples closer to the decision boundary in each group.
    \item \textbf{IFairLRS}~\citep{jiang2024itemside} employs the reciprocal of the sum popularity of items within the group as the weight assigned to that group. 
    \item \textbf{Maxmin Sample}~\citep{abernethy2022active} applies optimizing techniques to dynamically sample groups.
\end{itemize}



Meanwhile, we also choose three fair-aware non-LLMs recommender models that aim to improve group fairness:
\begin{itemize}
    \item \textbf{FOCF}~\citep{FOCF} applies a fair-aware regularization loss of different groups into non-LLMs RS.
    \item \textbf{Reg}~\citep{Reg} penalizes the squared difference between the average scores of two groups for all positive user-item pairs into non-LLMs RS.
    \item \textbf{FairNeg}~\citep{FairNeg} proposed a negative sampling way for pair-wise recommendation into non-LLMs RS. Note that FairNeg only can be applied to pair-wise RS models. 
\end{itemize}


\begin{table*}[t]
\caption{Performance comparisons between ours under other non-LLMs backbones on MIND dataset. The $*$ means the improvements are statistically significant (t-tests and $p$-value $< 0.05$). The bold number indicates that the accuracy value exceeds that of all the baselines.}\label{exp:non_llm_backbones}
\centering
\resizebox{0.98\linewidth}{!}{
        %\renewcommand\arraystretch{1.1}
    \centering
   % \setlength{\tabcolsep}{5mm}
\begin{tabular}{@{}clrrrrrrrrr@{}}
\toprule
\multicolumn{2}{c}{\multirow{2}{*}{\textbf{Models/Metrics}}} & \multicolumn{3}{c}{top-5} & \multicolumn{3}{c}{top-10} & \multicolumn{3}{c}{top-20} \\ \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
\multicolumn{2}{c}{} & NDCG (\%) & MRR (\%) & MMF (\%) & NDCG (\%) & MRR (\%) & MMF (\%) & NDCG (\%) & MRR (\%) & MMF (\%) \\ \midrule
  \multirow{10}{*}{\textbf{BPR}}  & DRO & 0.73 & 0.62 & 12.9 & 0.87 & 0.72 & 11.8 & 1.12 & 0.79 & 12.9 \\ 
 & Prop & 0.42 & 0.32 & 0.05 & 0.57 & 0.38 & 0.06 & 0.95 & 0.48 & 10.0 \\ 
 & S-DRO & 0.67 & 0.61 & 3.88 & 0.84 & 0.68 & 6.87 & 1.04 & 0.73 & 12.03 \\ 
 & IFairLRS & 0.68 & 0.57 & 0.13 & 0.77 & 0.61 & 0.23 & 1.07 & 0.69 & 1.38 \\ 
 & Maxmin sample & 0.66 & 0.58 & 6.54 & 0.81 & 0.64 & 8.8 & 1.05 & 0.71 & 10.87 \\
 & FOCF & 0.40 & 0.32 & 0.05 & 0.57 & 0.38 & 0.07 & 0.95 & 0.48 & 10.0\\
 & Reg & 0.67 & 0.61 & 3.27 & 0.83 & 0.67 & 5.89 & 1.06 & 0.73 & 11.25 \\
 & FairNeg & 0.72 & 0.63 & 6.07 & 0.91 & 0.71 & 8.8 & 1.21 & 0.79 & 12.64 \\
 \cmidrule(l){2-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
 & \textbf{Ours} & \textbf{0.76}$^*$ & \textbf{0.64}$^*$ & \textbf{11.84}$^*$ & \textbf{0.94}$^*$ & \textbf{0.72} & \textbf{13.87}$^*$ & \textbf{1.27}$^*$ & \textbf{0.81} & \textbf{14.6}$^*$  \\
 \bottomrule
 \multirow{9}{*}{\textbf{GRU4Rec}}  & DRO & 0.56 &  0.56 &  0.86 &  0.76 &  0.64 &  5.56 &  1.13 &  0.71 &  10.7 \\ 
 & Prop & 0.42 &  0.35 &  7.94 &  0.63 &  0.44 &  10.19 &  0.90 &  0.51 &  13.10 \\ 
 & S-DRO & 0.45 &  0.36 &  11.42  &  0.67 &  0.44 &  12.05 &  0.97 &  0.53 &  13.15 \\ 
 & IFairLRS & 0.45 &  0.38  &  7.12   &  0.68 &  0.47  &  9.21  &  1.02 &  0.56  &  11.70 \\ 
 & Maxmin sample & 0.43 &  0.33 &  10.9 &  0.62 &  0.41 &  14.27 &  0.91 &  0.48 &  13.06 \\
 & FOCF & 0.56 &  0.41 &  5.62 &  0.79 &  0.63 &  7.11 &  1.10 &  0.70 &  10.29 \\
 & Reg & 0.45 &  0.37 &  6.93 &  0.67 &  0.46 &  8.60 &  1.02 &  0.55 &  10.92\\
 \cmidrule(l){2-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
 & \textbf{Ours} & \textbf{0.59}$^*$ & \textbf{0.47}$^*$ & \textbf{12.13}$^*$ & \textbf{0.85}$^*$ & \textbf{0.68}$^*$ & \textbf{12.77}$^*$ & \textbf{1.16}$^*$ & \textbf{0.76}$^*$ & \textbf{14.09}$^*$  \\
 \bottomrule
 \multirow{9}{*}{\textbf{SASRec}}  & DRO & 0.54 &  0.40 &  8.07 &  0.72 &  0.47 &  11.34 &  1.11 &  0.57 &  12.26 \\ 
 & Prop & 0.54 &  0.45 &  11.69  &  0.80 &  0.55 &  12.10 &  1.16 &  0.57 &  13.01 \\ 
 & S-DRO & 0.49 &  0.40 &  10.66  &  0.74 &  0.49 &  11.64 &  1.09 &  0.59 &  14.02 \\ 
 & IFairLRS & 0.58 &  0.57 &  \textbf{12.63}  &  0.60 &  0.58 &  12.35 &  0.62 &  0.58 &  13.73 \\ 
 & Maxmin sample & 0.56 &  0.47 &  9.05 &  0.74 &  0.54 &  12.45 &  1.09 &  0.64 &  14.06 \\
 & FOCF & 0.47 &  0.46 &  10.52  &  0.50 &  0.47 &  12.73 &  0.53 &  0.48 &  14.46 \\
 & Reg & 0.47 &  0.38 &  9.42 &  0.70 &  0.47 &  9.52 &  1.03 &  0.55 &  10.91\\
 \cmidrule(l){2-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
 & \textbf{Ours} & \textbf{0.64}$^*$ & \textbf{0.63}$^*$ & 11.98 & \textbf{0.78}$^*$ & \textbf{0.64}$^*$ & \textbf{13.08}$^*$ & \textbf{1.31}$^*$ & \textbf{0.67}$^*$ & \textbf{14.51}$^*$  \\
 \bottomrule
\end{tabular}
}
\end{table*}


% (1) \textbf{UNI}: each sample has the same weight during training; (2) \textbf{DRO}~\citep{hashimoto2018fairness}: every step, the model only optimizes the worst-off groups to enhance grou MMF;
% ; (3) \textbf{S-DRO}~\citep{wen2022distributionally}: improves DRO with the distributional shift to optimize group MMF; (4) \textbf{Prop}~\citep{hu2023adaptive}  assigns higher group weight to the samples closer to the decision boundary in each group; and (5) \textbf{IFairLRS}~\citep{jiang2024itemside} employs the reciprocal of the sum popularity of items within the group as the weight assigned to that group. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/para_analysis.pdf}
    \caption{Sub-figure (a) and (b) describe the NDCG and MMF changes \wrt freeze parameter updating gap $\beta$. }
    \label{fig:para_analysis}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/para_analysis2.pdf}
    \caption{Sub-figure (a) and (b) describe the NDCG and MMF changes \wrt dual learning rate $\eta$.}
    \label{fig:para_analysis2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/emb_analysis.pdf}
    \caption{Sub-figure (a) illustrates the density distribution of embeddings for each hidden layer of Llama2. Sub-figures (b) and (c) depict the changes in NDCG and MMF metrics when different hidden layers are utilized to represent user or item embeddings. }
    \label{fig:emb_analysis}
\end{figure}

\begin{table}[t]
\centering
\small
\caption{We conduct empirical experiments to show the effect of the length of item-clicked sequences. The experiments are conducted on the MIND dataset under BigRec backbones. }
\label{tab:history_length}
\resizebox{0.98\linewidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\textbf{History length $H$} & \textbf{NDCG@5 (\%)} & \textbf{MMF@5 (\%)} & \textbf{NDCG@10 (\%)} & \textbf{MMF@10 (\%)} & \textbf{NDCG@20 (\%)} & \textbf{MMF@20 (\%)} \\ \midrule
3                       & 0.79            & 1.88           & 1.35              & 2.79            & 1.85             & 3.23            \\
4                       & 0.81            & 1.63           & 1.36              & 2.65            & 1.99             & 3.21            \\
5                       & 1.15            & 2.82           & 1.69              & 2.99            & 2.28             & 3.39            \\
6                       & 1.04            & 2.57           & 1.64              & 2.66            & 2.26             & 3.29            \\
7                       & 1.02            & 3.27           & 1.40              & 3.5             & 2.16             & 4.29            \\ \bottomrule
\end{tabular}
}
\end{table}


\begin{table}[t]
\centering
\caption{We conduct empirical experiments to show the effect of the sample size $Q$. The experiments are conducted on the MIND dataset under BigRec backbones.}
\label{tab:sample_size}
\begin{tabular}{ccccccc}
\toprule
\textbf{sample size $Q$} & \textbf{50} & \textbf{100} & \textbf{200} & \textbf{300} & \textbf{400} & \textbf{full (unbiased)} \\ \midrule
NDCG(\%) & 1.08            & 1.08           & 1.15              & 1.19            & 1.19             & 1.29            \\
MMF(\%)                       & 1.2             & 1.28           & 2.18              & 2.10            & 2.29             & 2.31            \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
%\small
\caption{The convergence time (performance stabilizing within 50 steps) of our method compared to other baselines under BigRec backbones on the MIND dataset. }
\label{tab:convergence}
\begin{tabular}{lllllll}
\toprule
Model            & DRO   & Prop  & S-DRO & IFairLRS & \textbf{FairDual(ours)} & Improvment \\ \midrule
Convergence time & 10.1h & 11.7h & 7.9h  & 7.1h     & \textbf{5h}             & 28.5\%  \\ \bottomrule
\end{tabular}
%\vspace{-0.3cm}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}


\section{Main Experiments on Non-LLMs Backbones.}\label{app:sec:non_llms}

We choose three non-LLMs recommender models: \textbf{BPR}~\citep{BPR}, \textbf{GRU4Rec}~\citep{gru4rec} and \textbf{SASRec}~\citep{SASRec}.
And we also compare three group fair-aware on-LLMs recommender models: \textbf{FOCF}~\citep{FOCF},  \textbf{Reg}~\citep{Reg}, and  \textbf{FairNeg}~\citep{FairNeg}. These models are compared using traditional recommender system backbones, as detailed in Appendix~\ref{app:sec:non_llms}.

From Table~\ref{exp:non_llm_backbones}, we further observe that FairDual consistently surpasses all baseline methods across various datasets under non-LLM backbones and different top-K ranking sizes. These results demonstrate that FairDual remains highly effective even when applied to non-LLM-based models.


Also note that another widely used loss function is the BPR loss~\cite{BPR}, which aims to increase the distance between positive and negative samples. Interestingly, from the table, we can observe that our methods can also be applied to this loss, as BPR loss is a convex function with respect to positive items, and our dual formulation remains valid.


\section{Analysis for Hyper-parameters}\label{app:para_analysis}
We also conduct analysis for other important hyper-parameters of FairDual on MIND dataset under BigRec base models.

\textbf{Inference on Updating Gap $\beta$.} We first will investigate the impacts of freeze parameter updating gap $\beta$. As shown in Figure~\ref{fig:para_analysis}, we can observe that the accuracy degree (NDCG) increases when $\beta\in [128, 1280]$ and then drops slightly when $\beta\in [1280,3840]$. Similarly,  we can observe that the fairness degree (MMF) increases when $\beta\in [128, 640]$ and then drops with a large margin when $\beta\in [640,3840]$. 
The results align with our expectations: excessively frequent updates can lead to instability during training, while infrequent updates may cause the model to miss new ranking patterns, ultimately affecting performance negatively.




\begin{table}[t]
\centering
\caption{Performances of other fairness metric Gini Index.}
\label{tab:gini}
\begin{tabular}{llll}
\toprule
Models            & GINI@5   & GINI@10  & GINI@20 \\ \midrule
Prop & 0.488 & 0.488 & 0.472   \\
DRO & 0.511 & 0.476 & 0.487 \\
SDRO & 0.503 & 0.478 & 0.453 \\
IFairLRS & 0.458 & 0.454 & 0.448 \\
\textbf{FairDual(ours)} & \textbf{0.444} & \textbf{0.450} & \textbf{0.441} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{Popularity bias effect utilizing Inverse Propensity Score (IPS)-based~\cite{xu2022dually} reweighting method.}
\label{tab:pop_bias}
\begin{tabular}{lllll}
\toprule
$\lambda$  &  0.1  & 1  & 2 & 5 \\ \midrule
\multicolumn{5}{c}{NDCG(\%)} \\
\midrule
 IPS & 0.58 & 0.58 & 0.58 & 0.58 \\
 FairDual & 0.53 & 0.60 & 0.57 & 0.67 \\ 
 FairDual+IPS & 0.59 & 0.56 & 0.56 & 0.58 \\ 
 \midrule
\multicolumn{5}{c}{MMF(\%)} \\
\midrule
 IPS & 12.63 & 12.63 & 12.63 & 12.63 \\
 FairDual & 4.50 & 11.98 & 13.46 & 13.76 \\
 FairDual+IPS & 10.90 & 12.40 & 12.40 & 14.36 \\ 
\bottomrule
\end{tabular}
\end{table}

\textbf{Inference on dual learning rate $\eta$.} We then investigate the impacts of dual learning rate $\eta$. As shown in Figure~\ref{fig:para_analysis2}, we can observe that the accuracy degree (NDCG) increases when $\eta\in [1e^{-5}, 5e^{-5}]$ and then drops when $\eta\in [5e^{-5}, 5e^{-3}]$. On the other hand, the fairness performance drops when $\eta$ goes larger.
The results demonstrate that the learning rate $\eta$ serves as a trade-off factor: excessively large values detrimentally affect both accuracy and fairness, whereas excessively small values improve fairness at the expense of accuracy in recommendation system models.

% Firstly, from Figure~\ref{fig:emb_analysis} (a), We can observe that the middle layer of Llama2 exhibits a distribution similar to that of other layers, whereas the last layer shifts towards a low-variance standard Gaussian distribution. 

\textbf{Performances under Different Hidden Layers.} In this experiment, we aim to analyze the FairDual performance under different hidden layers in Llama2. We test the NDCG and MMF performance when we utilize different hidden layers to represent user or item embeddings. 
From Figure~\ref{fig:emb_analysis} (a) and (b), it is evident that the accuracy (NDCG) and fairness (MMF) trends exhibit distinct patterns: accuracy performance initially ascends, peaking in the middle layer before gradually declining, whereas fairness performance initially descends, hitting a nadir before steadily increasing. 


This phenomenon can be interpreted as follows: in the initial layers, which are not yet fully trained, the recommendation system tends to suggest more random items, resulting in lower accuracy but higher fairness. As the layers deepen, the accuracy increases, but it also tends to recommend more unipolar items. Eventually, as the layers approach the last layer, our FairDual model emphasizes fairness more by adjusting the weights for the weaker groups. This will also help us to better understand the mechanisms of FairDual.





\textbf{Performances under different lengths $H$ of item-clicked sequences.} In Table~\ref{tab:history_length}, we conduct the empirical experiments to show the effect for the length of item-clicked sequences. The experiments are conducted on MIND dataset under BigRec backbones. 

From the experiments, we can observe that the length of history is a trade-off factor for the methods: initially, increasing the length improves accuracy and fairness, but once it reaches a peak, performance begins to drop. We analyze the reason as follows: the length of history sequences indeed influences performance. Sequences that are too short make it difficult to learn user preferences, while sequences that are too long increase computational costs and risk hitting the prompt limit of LLMs.





\textbf{Performances under different sample sizes $Q$.} Intuitively, a larger $Q$ provides a more accurate gradient estimation but also incurs higher computational costs. We have conducted experiments to evaluate the impact of Q and will present the results. The results were conducted under the same settings as the analysis section. The experiments were conducted under BigRec on MIND dataset with ranking size $K=5$.




From the results in Table~\ref{tab:sample_size}, we observe that increasing the sample value Q leads to improvements in both accuracy and fairness performance. However, in LLM-based recommender systems, a larger Q significantly increases training time (with each item requiring an additional $1.5$ seconds) and storage space. Different applications should select appropriate Q values based on their specific accuracy, fairness requirements, and computational constraints.





\section{Computational And Storage Costs}\label{app:computational}

In Table~\ref{tab:convergence}, we measured the convergence time (performance stabilizing within 50 steps) of our method compared to other baselines under BigRec backbones on MIND dataset.

Firstly, we all have parameters of the same magnitude (i.e., group size parameters (hundred level), which are in the range of hundreds and negligible compared to the backbone (million level)). 
Our method only requires additional space for $Q$ item embeddings and extra training time ($1.5Q$s). Applications can trade off $Q$ based on available resources (as discussed in a previous response).

Secondly, as observed in Table~\ref{tab:convergence} of the original paper, although there is an additional time overhead per round, our convergence speed accelerates by 30\% compared to the best baseline. This 30\% improvement in convergence speed is highly significant for industrial applications, along with enhanced performance.

\section{Performances on Other Fairness Metrics}\label{app:GINI}

We test the performances of another fairness metric Gini Index~\citep{do2022optimizing} Compared to the baselines (Table~\ref{tab:gini}) on MIND datasets. Note that a smaller Gini Index means more fairness. From the results, we can observe that our model can still perform well on other fairness metrics. We believe our paper can help other researchers explore its applicability to various loss functions, and other fairness metrics, which is also our contribution to the communities.


\section{Effect of Popularity Bias}\label{app:pop_bias}
Since the popularity bias will influence the accuracy estimation in real dataset shown in Figure~\ref{fig:analysis}, we conduct the experiments on a relatively light transformer-based SASRec~\citep{SASRec} backbones and MIND datasets. We apply the Inverse Propensity Score (IPS)-based~\cite{xu2022dually} to our method to see whether it can improve our methods.


Table~\ref{tab:pop_bias} shows the results on $K=5$ results. From the results, we can observe that when the $\lambda$ is small, adding the IPS will increase the accuracy and fairness with a large margin due to the popularity bias. However, when $\lambda$ is large, the FairDual+IPS will not perform very well. This is because IPS will break the convergence condition of FairDual. Therefore, when $\lambda$ is large, it is preferable not to involve IPS. We will include the related experiments and discussion in the Appendix of the revised paper.



