\section{Introduction}
% With the development of Large Language Models (LLMs), its general capabilities are creasingly powerful. State-of-the-art LLMs continue to struggle with factual errors (Mallen et al., 2023; Min et al., 2023). 一方面，LLMs 的参数化记忆是静态的，无法适应动态变化的知识需求，也难以覆盖训练数据之外的未知领域；另一方面，其生成内容可能出现幻觉（hallucination），即输出看似合理但缺乏事实依据的结果。这些问题限制了 LLMs 在知识密集型任务中的表现。为此，RAG通过从外部数据库检索相关片段并将其加入输入上下文，显著提升了模型在开放领域问答和动态知识获取任务中的可靠性与表现，有效补充了 LLMs 的不足。

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.95\linewidth]{figure/figure1_redundency_phenomenon.pdf}
    \caption{The examples show that a large amount of noise impedes the LLM from acquiring accurate knowledge from the retrieved content and could potentially misdirect its reasoning. Finding the correct answer relies on the ability of LLM to identify a small portion of key information.}
    \label{fig1:redundency phenomenon}
\end{figure}

With the development of Large Language Models (LLMs), their general capabilities have become increasingly powerful \cite{achiamGPT4TechnicalReport2023, dubey2024llama}. However, even the most advanced LLMs still face challenges with factual errors \cite{minFActScoreFinegrainedAtomic2023, huangFactAlignLongformFactuality2024}. One major limitation lies in their static parametric memory, which prevents them from adapting to dynamically evolving knowledge demands or covering unknown domains beyond their training data \cite{kasaiRealTimeQAWhats2023}. Furthermore, LLMs are prone to generating hallucinations that appear plausible but lack factual accuracy \cite{huangSurveyHallucinationLarge2024}. These challenges significantly hinder the performance of LLMs in knowledge-intensive tasks \cite{ramInContextRetrievalAugmentedLanguage2023}. To address these limitations, Retrieval-Augmented Generation (RAG) \cite{lewisRetrievalaugmentedGenerationKnowledgeintensive2020, xiongApproximateNearestNeighbor2020, izacardUnsupervisedDenseInformation2021} integrates relevant passages from external databases into the input context, effectively enhancing the reliability and performance of models in open-domain question answering and dynamic knowledge retrieval tasks. 

% The heavy reliance of generation on the retrieved knowledge raises significant concerns about the model’s behavior and performance in scenarios where retrieval may fail or return inaccurate results


% 然而, RAG的效果在很大程度上取决于检索到的信息质量，冗余信息的干扰和输入长度的增加同样是影响模型性能的关键因素。具体表现在以下几个方面：
% 在召回器阶段，核心句子的相关性分数可能因同一文档级别的其他冗余内容的相关性分数而被稀释，导致关键信息在检索内容中的突出性下降。在生成阶段，过多的召回内容虽然旨在提供丰富的上下文信息，但可能导致模型因输入内容过长而分心，从而降低其对关键信息的聚焦能力[]。如图1所示，对于某些问题的答案，检索到的Top k内容中关键句子仅占极少部分，而大量无关或冗余信息不仅妨碍模型从检索内容中获取准确知识，还可能导致其生成幻觉现象[]。
\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{figure/figure2_ParetoRAG.pdf}
    \caption{Comparison of the traditional RAG (red path) and ParetoRAG(green path). The traditional method retrieves and directly uses entire passages, which often introduces redundant information, leading to inaccurate answers. In contrast, our method utilizes a preprocessed sentence-level corpus, assigning higher weights to key sentences while appropriately preserving and weighting contextual information to avoid loss of coherence. Inspired by the Pareto principle (the 80/20 rule), this design emphasizes critical information while maintaining necessary semantic consistency. The selected sentences are then fed into the LLM, resulting in more accurate answers.}
    \label{fig2:ParetoRAG pipeline}
\end{figure*}

However, the effectiveness of RAG highly depend on the quality of the retrieved information \cite{fan2024survey}. Additionally, interference from redundant information and increased input length are critical factors that significantly impact model performance.
In the retrieval stage, the relevance scores of core sentences can be overshadowed by those of redundant content at the same passage level, reducing the prominence of key information in the retrieved content. In the generation stage, retrieving excessive content to provide rich context can result in overly lengthy inputs, which may cause the model to lose focus and diminish its ability to concentrate on critical information \cite{jin2024longcontextllmsmeetrag, largelanguagemodelsCanbeEasilyDistractedbyInrelevantContext}. As Figure \ref{fig1:redundency phenomenon} shows that core sentences account for only a small portion of the top k retrieved content. Excessive irrelevant or redundant information hinders the ability of the model to extract accurate knowledge and increases the risk of generating hallucinations \cite{zhang2024raft, liu-etal-2024-lost}.
%  此外，在零样本链式推理（zero-shot chain-of-thought, CoT）提示设置下，模型随着输入长度增加，其指令跟随能力会显著下降，表现为更倾向于在推理步骤之前直接生成答案, 且这一倾向会随着输入长度的增加而加剧。这也表明，随着输入规模的扩大，模型的指令跟随能力呈现下降趋势。
%  因此，有效减少冗余信息，提升核心信息的突出性，并优化输入内容的长度，是提高模型性能和生成可靠性的有效方向。
In addition, in the zero-shot Chain-of-Thought \cite{wei2022chain} prompting setup, the ability of LLM to follow instructions shows a significant decline as the input size increases. The model tends to directly generate answers before completing reasoning steps, and this tendency becomes more pronounced as inputs grow longer \cite{levy-etal-2024-task}. 
% Therefore, reducing redundant information, emphasizing core sentences, and optimizing input length are effective strategies to improve the model's instruction-following ability, overall performance, and output reliability.

% RALMs（Retrieval-augmented language models）、长文本输入模型（long-form input models）以及经过抗噪训练的大型语言模型（LLMs）是目前解决冗余信息干扰和输入长度问题的一些可能方案。这些模型通过增强对长文本的处理能力和提高对噪音信息的鲁棒性，能够更有效地聚焦于关键信息，并减少冗余内容的影响。然而，这些方法通常需要额外的训练资源和高计算成本，以进行额外的训练和模型调优。 一种可能的解决方案是将召回的粒度从文档级降低到句子级。然而，这种做法也可能无意中丧失一些重要的上下文信息（例如，在图1的示例中，“The season”分别指代的是《芝加哥烈焰》第四季和第二季），这些信息对于准确回答给定的查询至关重要。为此，我们提出了一种方法，既无需额外的训练资源，又能在减少文档冗余信息的同时有效保留上下文信息。

% \FloatBarrier
Retrieval-augmented language models (RALMs) \cite{zhang2024raft, lin2024radit}, Long-context LLMs \cite{dubey2024llama, team2024gemini}, and Adaptive Noise-Robust Model \cite{yoran2024making, fangEnhancingNoiseRobustness2024a} can be considered as solutions. These models enhance the ability to process long-form text and improve the robustness to noisy information, enabling them to focus more effectively on key information and reduce the impact of redundant content. However, these approaches generally require additional training resources and high computational costs for further training and model fine-tuning. Another possible solution is to reduce the granularity of retrieval from the document level to the sentence level \cite{leePhraseRetrievalLearns2021, chenDenseRetrievalWhat2024a}. However, this approach may inadvertently lose some important contextual information (e.g., in the example in Figure \ref{fig1:redundency phenomenon}, "The season" refers to Chicago Fire season 4 in one context and season 2 in another), which is crucial for accurately answering the given query \cite{choiDecontextualizationMakingSentences2021}. Therefore, we propose a method that does not require additional training resources while effectively preserving contextual information and reducing document redundancy.

In this work, we present \textbf{ParetoRAG}, an unsupervised framework built upon the RAG system. Our approach leverages a preprocessed sentence-level corpus, assigning higher weights to key sentences while carefully preserving and weighting contextual information to maintain coherence. Drawing inspiration from the \textbf{Pareto principle} (the 80/20 rule), ParetoRAG prioritizes critical information while ensuring semantic consistency, effectively enhancing both the retrieval and generation stages of the RAG pipeline. Notably, ParetoRAG requires neither additional training resources nor extra API
calls. The overall ParetoRAG framework is illustrated in Figure \ref{fig2:ParetoRAG pipeline}. 

We validate ParetoRAG across three datasets over three retrievers. 
Our main contributions are as follows:
\begin{itemize}
    % 提出了一种即插即用的方法，名为ParetoRAG，用于实现从段落级到句子级的分解，在检索阶段有效保留上下文信息，无需额外训练。
    \item A plug-and-play method named ParetoRAG is proposed to achieve the decomposition from paragraph-level to sentence-level, effectively retaining contextual information during the retrieval stage without requiring additional training.
    % ParetoRAG 在准确率和流畅度方面取得了显著提升，同时将 token 消耗减少至原来的约 30%。此外，该方法具有较强的泛用性，这一结论在多种数据集、LLMs 和检索器（retrievers）上均得到了验证。
    \item ParetoRAG achieves notable improvements in accuracy and fluency while reducing token consumption to approximately 30\% of the original cost. Furthermore, it demonstrates strong generalization, as this conclusion is consistently validated across various datasets, LLMs, and retrievers.
    % 我们探索并分析了 ParetoRAG 与经过鲁棒训练的增强型语言模型之间的协同作用，说明了它们的结合如何可能提升生成的质量。本研究提供了一些初步见解，或可为未来在检索增强方法与抗噪鲁棒训练策略相结合的研究提供启发。 这里协同作用用词不太合适, 会让别人误会 ParetoRAG 和 经过抗噪训练的LLM使用了什么机制产生了协同作用?
    % \item We explore and analyze the synergy between ParetoRAG and adaptive noise-robust model, illustrating how their combination can enhance generation quality. This work offers preliminary insights that could inspire future research on integrating retrieval-augmented methods with robust training strategies.
    % 我们研究了ParetoRAG的改进和自适应噪声鲁棒模型之间的方法兼容性。研究结果表明，检索增强架构和鲁棒训练策略可以正交有益，提供架构级增强，补充而不是干扰现有的噪声缓解方法。
    \item We investigate the methodological compatibility between ParetoRAG's improvements and the adaptive noise-robust model. The findings suggest that retrieval-augmented architectures and robust training strategies can be orthogonally beneficial, providing architectural-level enhancements that complement rather than interfere with existing noise mitigation approaches.
\end{itemize}




% 传统RAG（红色路径）和ParetoRAG（绿色路径）之间的比较， 传统方法在检索时直接使用完整段落，这种方式容易引入冗余信息，进而导致问答结果不准确。而我们的方法使用预处理后的句子级语料库，通过赋予核心句子更高权重，同时适当保留上下文信息并给予一定权重，以避免上下文丢失。这一设计受帕累托原理（二八定律）的启发，旨在突出关键信息并保持必要的语义连贯性。最终，筛选后的句子被输入到LLM中，从而生成更加准确的回答。
% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=1\linewidth]{figure/figure2_ParetoRAG.pdf}
%     \caption{Comparison of the traditional RAG (red path) and ParetoRAG(green path). The traditional method retrieves and directly uses entire passages, which often introduces redundant information, leading to inaccurate answers. In contrast, our method utilizes a preprocessed sentence-level corpus, assigning higher weights to key sentences while appropriately preserving and weighting contextual information to avoid loss of coherence. Inspired by the Pareto principle (the 80/20 rule), this design emphasizes critical information while maintaining necessary semantic consistency. The selected sentences are then fed into the LLM, resulting in more accurate answers.}
%     \label{fig2:ParetoRAG pipeline}
% \end{figure*}
% % \FloatBarrier


