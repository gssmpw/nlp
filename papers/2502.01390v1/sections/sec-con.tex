\section{Conclusion}
This work empirically studied human-AI collaboration based on plan-then-execute LLM agents. 
Adopting such LLM agents in various everyday scenarios, % of different task characteristics (\ie risk perception and plan quality), 
we analyzed the impact of user involvement in the planning and execution stages on user trust and overall task performance. 
We provide various interactions in each stage to help users fix imperfect plans and modify execution outcomes. 
Our results suggest that the LLM agents can provide plausible text plans to cover task requirements, which can be convincingly wrong. 
As a result, users develop uncalibrated trust in the planning and execution outcomes, and user involvement in the planning and execution stages fails to calibrate user trust (\textbf{RQ1}). 
We also found that the plan quality substantially affects the subsequent execution accuracy. 
Thus, when user involvement in planning can fix imperfect plans, the overall task performance (\ie plan quality, accuracy of action sequence, and execution accuracy) gets improved. 
However, user involvement in planning can also harm task plan quality where the original plan is good to begin with. As a result, the LLM agents demonstrate worse task performance in these tasks. 
In contrast, %\glcomment{another phrase here?}
user involvement in execution brings a more stable positive impact on task performance (\textbf{RQ2}). 
Our results suggest that plausible but wrong LLM outcomes can be detrimental to user trust calibration and overall task performance. 
We discussed the impact of convincingly wrong LLM outcomes and provided potential solutions and insights for future work. 
Furthermore, we synthesized key insights for better control and effective collaboration with plan-then-execute LLM agents. \revise{We also shed light on opportunities to design flexible collaborative workflows with human oversight for effective collaboration with LLM agents.} %  \glcomment{shall we rephrase a bit for the last sent? As we add one new implication paragraph, `human oversight and more flexible collaborative workflow'. we may replace the previous sent with `synthesized key insights about leveraging human oversight and more flexible collaborative workflow for better control and effective collaboration with LLM agents'}

Our results indicate that user involvement in the LLM agent workflow can be important in ensuring reliable task outcomes. 
Future work can further investigate how to detect and handle plausible but imperfect LLM outcomes and design effective interventions to fix such problems. 
We hope that our key findings and implications reported in this work will inspire further research on human-AI collaboration with LLM agents.