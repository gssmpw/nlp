\section{Introduction}
%\gdcomment{I think the 'why' could be stronger. We should talk about the risks of delegating to AI, what could go wrong, fear of loss, risk aversion, people want to feel in control while also being able to delegate}

% \glcomment{Background: LLM agent, daily assistance}
Autonomous agents have been regarded as a research focus for artificial intelligence (AI) over the last century~\cite{albrecht2018autonomous}. 
With the wish that autonomous agents can make our life better, many autonomous agents have been designed as virtual personal assistants~\cite{kepuska2018next}. 
These AI assistants (\eg Siri) perform well (albeit imperfectly) in following user instructions to execute low-risk tasks like playing a song, reporting weather forecasts, or searching for an image to support everyday tasks. %daily life. 
However, on tasks entailing potential risks (\eg monetary payments or hiring an employee), humans hesitate to trust such AI systems due to loss aversion~\cite{tversky1991loss} and algorithmic aversion~\cite{hou2021expert,mahmud2022influences,dietvorst2015algorithm}. 
Only when users can obtain a sense of control by being able to modify the outcomes of imperfect AI can they overcome such algorithm aversion and be willing to collaborate with imperfect AI systems~\cite{dietvorst2018overcoming}. 
% While these AI systems can provide convenience to our life, the risks of using them are also unneglectable. 


% \glcomment{Provide a strong motivation why we look into LLM agents}\glcomment{A strong motivation for using LLM agents: equipped with external tools, LLM agents provide a convenient way for users to master different skills with reduced manual efforts over tool usage. Reduce the time used for information seeking tasks}
%\glcomment{I try to motivate ``Why LLM agents as daily assistant''}
With the recent rise of large language models (LLMs) in natural language understanding and generation~\cite{zhao2023survey}, researchers have started to analyze LLM-based agents and their applicability in a plethora of tasks %(\ie LLM agents)
~\cite{xi2023rise,wang2024survey}. 
% While LLMs can generate high-quality text responses to user queries, the text generation itself constrains its application. 
The term `\textit{LLM agent}' refers to an artificial entity based on LLMs that perceives its context, makes decisions, and then takes actions in response~\cite{xi2023rise}.
% ~\glcomment{It would be too long to formally define LLM agents or autonomous agents. I only briefly mentioned how it works in a high level}
Compared to existing deep learning and LLM-based methods (\eg chaining multiple LLMs~\cite{wu2022ai}), LLM agents provide more flexibility in task solving and user interaction, which makes them suitable for daily assistance. This is primarily due to three reasons.
First, with a planning module, LLM agents can generate a dynamic plan based on the tools provided~\cite{xi2023rise,wang2024survey}. 
Such plans are typically defined in a logical structure --- step-wise plans, which can be easily understood by humans. 
Second, with LLMs as a core control module, users can access and interact with external toolkits via a more natural interaction (\ie conversation) with LLM agents~\cite{bommasani2021opportunities,zhao2023survey}, reducing manual control efforts over function-specific tools. 
For example, LLM agents can complete time-consuming jobs like information seeking and information filtering (\eg searching for a flight in itinerary planning) based on specific user needs. 
% This may provide convenience to our daily life by reducing time spent in information seeking (\eg searching for a flight or hotel in itinerary planning). 
% information seeking (\eg searching for a flight or hotel in itinerary planning). 
Third, the Markov decision process of LLM agents can generate a sequence of actions (\ie using external toolkits)\footnote{In our study, the usage of one tool is the same as executing one action. Therefore, we refer to a tool and action interchangeably.} as output. 
Paired with an understanding of actions and necessary parameters for the interaction with the LLM agents, users can get involved in the real-time execution of tasks with LLM agents and fix potential problems while benefiting from task delegation~\cite{lubars2019ask}. {Based on an intuitive framework for task delegation, Lubars \etal~\cite{lubars2019ask} found that user trust can play an important role in human delegation behaviors to AI systems. However, there is a relatively limited understanding of user trust development and calibration in collaboration with LLM agents.} 
% \glcomment{add  reference in some claims}
%\glcomment{Is the last sent too intuitive? This seems very common for CS people, like checking new APIs. But it may not be a common skill for everyone.}\gdcomment{I think the need to refer to a manual is an issue, as modern technology usage does not require a manual to get started with.}

% To expand the impact of LLMs on the real world, researchers and practitioners equipped LLM agents with external toolkits (like mathematical calculators and flight booking toolkits). 
% When suitable toolkits are provided, LLM agents can easily arrange a plan and solve complex tasks using toolkits (\eg itinerary planning and flight ticket booking). 
% For a more comprehensive understanding of the concepts and definition of LLM agents, readers can refer to recent literature surveys~\cite{xi2023rise,wang2024survey}.

% \glcomment{Why human-AI collaboration with LLM agents. Risk perception, trust}

%\glcomment{Why human-AI collaboration with LLM agents: (1) a need for user control in real-time execution to tolerate risk/error control. (2) while LLMs can not automate planning, they can provide high-quality candidates, reducing sound planners' search efforts. (3) this topic is under-explored, lack of empirical evidence and limited understanding of how user trust and team performance is shaped in that collaboration}

There is also a growing debate in the machine learning and AI research communities about whether LLMs can be truly considered as reasoning and planning agents~\cite{kambhampati2024llms}. With this in the backdrop, existing work on automated task completion has revealed that LLM agents can exhibit promising performance in handling complex tasks like playing games~\cite{wang2023describe}, answering complex questions~\cite{zhuang2024toolqa}, and in simulating social behavior~\cite{park2023generative}. 
%While LLM agents have shown promising performance across various tasks, 
However, such agents are still far from perfect. Due to the probabilistic nature of LLMs, there is much uncertainty in automating LLM agents for tasks with high risks attached. %with a potential loss. \glcomment{Do we want to highlight tasks with risk?} 
To avoid unintended or unexpected consequences, %any unexpected results caused by such uncertainty, 
there is a need for user control over the real-time execution process. %\ujcomment{Will continue from here ---> }
%Meanwhile, there is a debate about ``Can LLMs Really Reason and Plan?''.\footnote{\url{https://cacm.acm.org/blogcacm/can-llms-really-reason-and-plan/}} 
{Through an empirical study of LLM planning capabilities, planning experts found that ``LLMsâ€™ ability to generate executable plans autonomously is rather limited''~\cite{valmeekam2023planning}. 
However, when combined with a sound planner in an `LLM-Modulo' mode, ``the LLM-generated plans can improve the search process for underlying sound planners''~\cite{valmeekam2023planning}. 
Humans can potentially be the `sound planners' who can work in conjunction and optimize plans drafted by LLMs, which can then be executed by LLM agents. %\ujcomment{Check!}
Such human-AI collaboration can reduce human efforts in generating a reliable plan from scratch. 
} 
%Under such circumstances, human-AI collaboration provides a promising avenue for obtaining reliable and accountable service from LLM agents. 

Attracted by the promise of LLM agents, there have been some early explorations~\cite{geissler2024concept} of adopting them in human-AI collaboration. 
However, the existing works have mainly analyzed how LLM agents can serve specific use cases (\eg design creation~\cite{geissler2024concept}), and others have conducted structured interviews to obtain expert insights~\cite{zhang2024s,zheng2023synergizing}. 
% human-AI collaboration with LLM agents in domain-specific use cases. 
It is still unknown how well LLM agents can work as general daily assistants to assist users in everyday tasks with varying stakes and how user trust and team performance are shaped by interacting with LLM agents. % \glcomment{here we still highlight daily assistance. I do not plan to highlight it in a sequential decision making setup, which is not our highlight.}

%\glcomment{Justify our design choice: Why plan then execute}
In our work, we address this research gap and adopt LLM agents to assist humans in everyday tasks by following a %to assist humans in solving some daily tasks with risky actions (\eg bank transfer). 
%Specifically, we adopt LLM agents 
%working with a 
plan-then-execute workflow~\cite{wang2023plan}. 
First, the LLM agent generates a step-wise plan formulated with a hierarchical structure. 
Then, the LLM agent executes the generated plan by transforming it into a sequence of actions (leveraging external toolkits). 
The benefits of such a plan-then-execute framing are three-fold: 
(1) Compared to a dynamic process where planning and execution are bound closely, separating planning and execution into two stages provides more task clarity to the users, which reduces user cognitive load and contributes to the quality of task outcomes~\cite{gadiraju2017clarity}. 
% With planning at the beginning of the task, users may develop a global understanding of how LLM agents will execute the task.
% With a clear and hierarchical plan structure, users can easily develop a logical understanding of how LLM agents work and be involved in improving the planning. 
(2) With planning at the beginning of the task, users can develop a global understanding of how the LLM agents will execute the task. 
Based on a follow-up step-by-step execution, it would be straightforward for users to be involved in such a process and control the outcomes of task execution. % outcomes. 
(3) Planning and execution are representative abstractions of how LLM agents work. 
The findings of such an empirical study can be generalized to human-AI collaboration with other kinds of LLM agents (\eg dynamic planning-execution). %\glcomment{I find some expression may be not clear enough, to improve}
% \glcomment{The question comes: do we start with a user needs of reasoning/planning process and real-time execution or we should start with LLM agent, and then identify plan-then-execute is suitable for analysis?}
%
%This work explored how user involvement in the plan-then-execute LLM agent working process will shape user trust and affect overall task performance. 
To this end, we propose the following research questions:
% \begin{framed}
\begin{itemize}
\item \textbf{RQ1}: How does human involvement in the high-level planning and real-time execution shape their trust in an AI system powered by LLM agents?
\item \textbf{RQ2}: How does human involvement in the high-level planning and real-time execution of tasks with an AI system powered by LLM agents affect the overall task performance?
    %\item RQ1: How does human involvement in the high-level planning and real-time execution shape their trust in the AI system?
    %\item RQ2: How does human involvement in the high-level planning and real-time execution affect the overall task performance?
\end{itemize}
% \end{framed}

%To answer these questions, and based on existing literature, we proposed four hypotheses considering the effect of user involvement in planning on \gladd{trust calibration}\gdcomment{might be good to have a sentence earlier to introduce the idea of trust calibration}\glcomment{add two cents after where delegation is mentioned} and overall task performance, as well as the effect of user involvement in execution on \gladd{trust calibration} and overall task performance. 
%We tested these hypotheses in 
Addressing these research questions, we carried out an empirical
study ($N$ = 248) of human-AI collaboration in six different everyday scenarios with varying stakes and risks attached (\eg credit card payment and itinerary planning). 
We found that user involvement in the planning and execution can be beneficial in addressing imperfect plans and fixing execution errors. 
As a result, LLM agents can achieve better task performance. %with human-AI collaboration. 
However, we also found that user involvement in the planning and execution stages of the LLM agent fails to calibrate user trust in corresponding task outcomes. 
{A potential reason here is that the plausible plans generated by the LLMs can mislead users into trusting the LLM agents when they are in fact wrong.} 
Our findings highlight that user involvement can also bring about additional trade-offs to consider: %impacts: 
(1) user involvement in the planning and execution poses a high cognitive load on users and decreases user confidence in their decisions; (2) user involvement can be harmful in some task contexts (\eg user involvement reduces plan quality). 
Further research is required to understand when to provide necessary user involvement.
%
% \glcomment{Summarize our contributions}
%Our results highlight that necessary user involvement can facilitate effective human-AI teaming and provide better task performance. 
Our key insight is that as opposed to following a fixed mode of user involvement, it is prudent to explore how user involvement in planning and execution can be tailored to fit the task and the user. %figure out when user involvement is necessary. 
% Based on quantitative analysis of planning and execution outcomes and qualitative analysis of the open feedback from participants, we synthesize 
Based on our quantitative and qualitative findings, %empirical study's quantitative and qualitative results, 
we share insights for designing effective LLM agents as daily assistants and synthesize promising directions for further research around LLM agents in the context of human-AI collaboration. 
Our work has important theoretical implications for human-AI collaboration with LLM assistance and design implications for plan-then-execute LLM agents to support human-AI collaboration.