\section{Results} 
In this section, we will present the main experimental results and exploratory analysis for our study. %\glcomment{R2 suggests a clearer results section, especially when reporting null effects. The current results section may confuse reviewers by interpreting null results.}\ujcomment{1. Look at the text once again to make sure our claims are consistent with the hypotheses tests. Consider highlighting the fact that there are null results in some cases. 2. Consider adding a table that summarizes the hypotheses findings.}\glcomment{I would recommend inviting the authors to revise the paper to rewrite the results section with interpretations that are faithful to the otherwise frequentist approach of the paper.}

\subsection{Descriptive Statistics}

In total, our analysis is based on 248 participants, who are balanced across conditions: AP-AE (63), AP-UE (64), UP-AE (61), and UP-UE (60). 
All edited plans in user-involved planning conditions are evaluated by the authors following the plan quality criteria \revise{described} in Section~\ref{sec-measure}. 
% And we keep a balanced gender distribution: 124 males (), 123 females ($49.6\%$), and 1 other. The participants age range from 

\paratitle{Distribution of Covariates}. In our study, most participants claimed to have some experience with using large language models ($M=3.6, SD=1.0$) and automatic assistants ($M=3.4, SD=1.1$). In the trust in automation questionnaire, participants indicated a medium level of \textit{Familiarity} ($M=2.9, SD=1.2$) and \textit{Propensity to Trust} ($M=3.0, SD=0.7$).

\paratitle{Performance Overview}. Overall, users show calibrated trust in the planning ($M= 0.50, SD=0.13$) and calibrated trust in the execution ($M=0.64, SD=0.19$). 
For the execution outcome, we find that although it is tricky to obtain a ground truth action sequence ($M=0.48, SD=0.17$), the action sequence has a relatively high recall of ground truth actions ($M=0.77, SD=0.11$). %\glcomment{recall only used once here, shall we remove it?}\gdcomment{I would keep it}
The successful rate for correct execution ($M=0.52, SD=0.18$) is higher than the strict evaluation of the action sequence. 
We also collected user subjective trust with four subscales of the trust in automation questionnaire: \textit{Reliability/Competence} ($M=3.49, SD=0.77$),  \textit{Understanding/Predictability} ($M=3.30, SD=0.56$),  \textit{Intention of Developers} ($M=3.61, SD=0.81$),  \textit{Trust in Automation} ($M=3.52, SD=1.01$). 
With a two-way ANOVA analysis considering user involvement in planning and execution, we do not find any significant impact of user involvement on subjective user trust in AI systems across conditions.

% \begin{figure*}[h]
%     \centering
%     \includegraphics[width=\textwidth]{figures/cognitive_load_bar_plot_new.pdf}
%     \caption{\revise{Bar plot for cognitive load across all conditions. ** indicates significance ($p < 0.0125$) through post-hoc Tukey HSD test. The error bars represent the 95\% confidence interval.}}%\glcomment{I changed the colors of bars to keep consistent with the confidence plot.}} 
%     \label{fig:cognitive_load}
%     \Description{Bar plot for cognitive load across all conditions. User involvement in planning shows a significant impact on Mental Demand, Temporal Demand, and Frustration. User involvement in execution shows a significant impact on Performance and Effort. These results indicate that user involvement in planning and execution will require a relatively high cognitive load.}
% \end{figure*}

\paratitle{Cognitive Load}. The cognitive load of participants across the four experimental conditions is shown in Figure~\ref{fig:cognitive_load}. 
% Based on the bar plot, we can infer that involvement in both planning and execution will pose a higher cognitive load on participants. 
% Overall, user involvement in planning seems to have more impact on cognitive load (reflected by dimensions of mental demand, temporal demand, and frustration). 
Based on two-way ANOVA, we analyzed the impact of user involvement in planning and execution affect user cognitive load. 
User involvement in planning shows a significant impact on \textit{Mental Demand}, \textit{Temporal Demand}, and \textit{Frustration}. User involvement in execution shows a significant impact on \textit{Performance} and \textit{Effort}. 
With post-hoc Tukey HSD test, we confirmed such impact --- involvement in both planning and execution  posed a higher cognitive load on participants.

% \subsubsection{Qualitative Analysis of User Involvement} We also look into, how user interact with the AI system in the planning and execution stages.

\begin{table*}[h]
	\centering
	\caption{Task-specific evaluation results for user-involvement in planning on calibrated trust in planning (CT$_p$) and plan quality. We also report the mean value for each measure on each condition.}
	\label{tab:h1-res}
    \begin{small}
	\begin{tabular}{c | c c c  c | c | c  c c c | c}
	    \hline
        &     \multicolumn{5}{c|}{CT$_p$}&  \multicolumn{5}{c}{Plan Quality}\\
        \cline{2-11}
        Tasks& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
        \hline 
        \hline
        Avg & 0.51& 0.50& 0.50& 0.50& - & 3.8& 3.8& 3.6& 3.7& AP > UP\\
        \hline
        task-1& 0.11 & 0.20 & 0.13 & 0.27& -& 2.0 & 2.0 & 2.3 & 2.4& AP < UP\\
        task-2 &0.21 & 0.11 & 0.20 & 0.17& -& 3.0 & 3.0 & 2.9 & 2.9& -\\
        task-3 & 0.10 & 0.03 & 0.10 & 0.07& -& 3.0 & 3.0 & 2.7 & 2.9& AP > UP\\
        task-4 & 0.94 & 0.97 & 0.80 & 0.90& AP > UP& 5.0 & 5.0 & 4.3 & 4.8& AP > UP\\
        task-5 & 0.87 & 0.84 & 0.90 & 0.82& -& 5.0 & 5.0 & 4.6 & 4.8& AP > UP\\
        task-6 & 0.81 & 0.81 & 0.85 & 0.75& -& 5.0 & 5.0 & 4.7 & 4.6& AP > UP\\
    \hline
	\end{tabular}
 \end{small}
\end{table*}

\begin{table*}[h]
	\centering
	\caption{Task-specific evaluation results for user-involvement in planning on task performance. ACC$_s$ denotes the strict accuracy of an action sequence, and ACC$_e$ denotes the correctness of execution results. Bold fonts are used to highlight the best performance across conditions.}
	\label{tab:h2-res}
    \begin{small}
	\begin{tabular}{c | c c c  c | c | c  c c c | c}
	    \hline
        \multirow{2}{*}{Tasks}&     \multicolumn{5}{c|}{ACC$_s$}&  \multicolumn{5}{c}{ACC$_e$}\\
        \cline{2-11}
        & AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
        \hline 
        \hline
        Avg& \textbf{0.53} & 0.46 & 0.46 & 0.48 & - & 0.54 & 0.53 & 0.47 & \textbf{0.56} & -\\
        \hline
        task-1& 0.00 & 0.00 & 0.10 & \textbf{0.12} & AP < UP & 0.00 & 0.00 & 0.10 & \textbf{0.13} & AP < UP\\
        task-2 &\textbf{0.78} & 0.64 & 0.61 & 0.57 & - & \textbf{0.78} & 0.72 & 0.66 & 0.75 & - \\
        task-3 & \textbf{0.44} & 0.12 & 0.36 & 0.28 & - & 0.44 & 0.42 & 0.36 & \textbf{0.52} & - \\
        task-4 & \textbf{0.95} & 0.89 & 0.75 & 0.82 & AP > UP & \textbf{0.95} & 0.89 & 0.75 & 0.82 & AP > UP \\
        task-5 & \textbf{0.98} & 0.91 & 0.90 & 0.90 & - & \textbf{0.98} & 0.91 & 0.92 & 0.90 & - \\
        task-6 & 0.05 & \textbf{0.22} & 0.02 & 0.18 & - & 0.06 & \textbf{0.23} & 0.03 & 0.22 & - \\
    \hline
	\end{tabular}
 \end{small}
\end{table*}

\paratitle{User Involvement}. Among 121 participants in conditions with user-involved planning, 104 participants edited at least one task plan. Meanwhile, 90 participants used the provided buttons (\ie add/delete/split step) in our study. In total, \textit{delete step} is used 394 times, \textit{add step} is used 183 times, \textit{split step} is used 126 times. Among 124 participants in conditions with user-involved execution, 114 participants interacted with the conversation interface to change action prediction (\ie have at least one task where they choose to give feedback or override predicted action). 
Meanwhile, 105 participants specified at least one action in the task batch. 
In total, \textit{Specify Action} is used 445 times, feedback to the LLM agent is used 91 times before action execution, and feedback to the LLM agent is used 163 times after execution.


\subsection{Hypothesis Verification}
As the tasks selected in our study are of different initial plan quality and risk levels, we conducted a task-specific analysis in each hypothesis verification.

\subsubsection{The Impact of User Involvement in Planning on Calibrated Trust} 
% To verify the impact of user involvement in the planning stage on calibrated trust in the planning outcome (\textbf{H1}), we need to also consider the potential impact of user involvement in the execution stage. 
To verify \textbf{H1}, we adopted the one-way ANOVA test and post-hoc Tukey HSD test on the calibrated user trust in planning (\ie CT$_p$). 
The results are shown in Table~\ref{tab:h1-res}. 
Only in task-4, we found user involvement in planning will have a negative impact on calibrated trust in planning. 
To avoid a potential impact of user involvement in the execution stage, we conducted a two-way ANOVA test to confirm the findings. 
% Overall, the test results are highly consistent: there is only a significant difference on task-4.
We only find a significant difference in task-4.
Post-hoc Tukey HSD results show that participants in conditions with automatic planning (AP) showed significantly higher calibrated trust in planning outcomes than those in conditions with user-involved planning (UP). 
Thus, our experimental results do not support \textbf{H1}.
% \glcomment{show task-specific analysis / mean values. Then mention the aggregation of results for high-risk tasks and low-risk tasks}

% \begin{table*}[h]
% 	\centering
% 	\caption{Task-specific evaluation results for user-involvement in planning on calibrated trust in planning (CT$_p$) and plan quality. We also report the mean value for each measure on each condition.}
% 	\label{tab:h1-res}
%     \begin{small}
% 	\begin{tabular}{c | c c c  c | c | c  c c c | c}
% 	    \hline
%         &     \multicolumn{5}{c|}{CT$_p$}&  \multicolumn{5}{c}{Plan Quality}\\
%         \cline{2-11}
%         Tasks& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
%         \hline 
%         \hline
%         Avg & 0.51& 0.50& 0.50& 0.50& - & 3.8& 3.8& 3.6& 3.7& AP > UP\\
%         \hline
%         task-1& 0.11 & 0.20 & 0.13 & 0.27& -& 2.0 & 2.0 & 2.3 & 2.4& AP < UP\\
%         task-2 &0.21 & 0.11 & 0.20 & 0.17& -& 3.0 & 3.0 & 2.9 & 2.9& -\\
%         task-3 & 0.10 & 0.03 & 0.10 & 0.07& -& 3.0 & 3.0 & 2.7 & 2.9& AP > UP\\
%         task-4 & 0.94 & 0.97 & 0.80 & 0.90& AP > UP& 5.0 & 5.0 & 4.3 & 4.8& AP > UP\\
%         task-5 & 0.87 & 0.84 & 0.90 & 0.82& -& 5.0 & 5.0 & 4.6 & 4.8& AP > UP\\
%         task-6 & 0.81 & 0.81 & 0.85 & 0.75& -& 5.0 & 5.0 & 4.7 & 4.6& AP > UP\\
%     \hline
% 	\end{tabular}
%  \end{small}
% \end{table*}

We noticed that the calibrated trust in planning is quite low in the high-risk tasks where all initial plans are imperfect. 
This indicates that many users across all conditions consider the generated plan trustworthy. 
On tasks with low risk, where the initial plan is of high quality, users achieved much higher calibrated trust in the planning outcome. 
We also find that conditions with user-involved execution (UE) show slightly higher CT$_p$ in task-1 and task-4 than conditions with automatic execution (AE). With the same statistical test as \textbf{H1} analysis, such differences are not significant.

% \begin{table}[h]
% 	\centering
% 	\caption{Task-specific evaluation results for user-involvement in planning on calibrated trust in planning (CT$_p$) and plan quality. We also report the mean value for each measure on each condition. \glcomment{We can consider use `Calibrated Trust-planning' directly}}
% 	\label{tab:h1-res}
%     \begin{small}
% 	\begin{tabular}{c | c c c  c | c | c  c c c | c}
% 	    \hline
%         &     \multicolumn{5}{c|}{CT$_p$}&  \multicolumn{5}{c}{Plan Quality}\\
%         \cline{2-11}
%         Tasks& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
%         \hline 
%         \hline
%         Avg & 0.51& 0.50& 0.50& 0.50& - & 3.8& 3.8& 3.6& 3.7& AP > UP\\
%         \hline
%         task-1& 0.11 & 0.20 & 0.13 & 0.27& -& 2.0 & 2.0 & 2.3 & 2.4& AP < UP\\
%         task-2 &0.21 & 0.11 & 0.20 & 0.17& -& 3.0 & 3.0 & 2.9 & 2.9& -\\
%         task-3 & 0.10 & 0.03 & 0.10 & 0.07& -& 3.0 & 3.0 & 2.7 & 2.9& AP > UP\\
%         task-4 & 0.94 & 0.97 & 0.80 & 0.90& AP > UP& 5.0 & 5.0 & 4.3 & 4.8& AP > UP\\
%         task-5 & 0.87 & 0.84 & 0.90 & 0.82& -& 5.0 & 5.0 & 4.6 & 4.8& AP > UP\\
%         task-6 & 0.81 & 0.81 & 0.85 & 0.75& -& 5.0 & 5.0 & 4.7 & 4.6& AP > UP\\
%     \hline
% 	\end{tabular}
%  \end{small}
% \end{table}



% \begin{table}[h]
% 	\centering
% 	\caption{Task-specific Evaluation Results for calibrated trust. CT$_p$ denotes the calibrated trust in the planning outcome, and CT$_e$ denotes the calibrated trust in the execution outcome.\glcomment{Shall we split calibrated trust into two measures?}}
% 	\label{tab:calibrated_trust}
%     \begin{small}
% 	\begin{tabular}{c | c c | c c| c c| c c| c c| c c | c c}
% 	    \hline
%         Tasks&\multicolumn{2}{c|}{Avg}&\multicolumn{2}{c|}{Task-1}&\multicolumn{2}{c|}{Task-2}&\multicolumn{2}{c|}{Task-3}&\multicolumn{2}{c|}{Task-4}&\multicolumn{2}{c|}{Task-5}&\multicolumn{2}{c}{Task-6}\\
%         \hline
%         % Characteristics& Risk& Plan& Risk& Plan& Risk& Plan& Risk& Plan& Risk& Plan& Risk& Plan& Risk& Plan\\\
%         % Notes& -& -& High& 2& High& 3& High& 3& Low& 5& Low& 5& Low& 5\\
%         % \hline
%         Conditions& CT$_p$& CT$_e$& CT$_p$& CT$_e$& CT$_p$& CT$_e$& CT$_p$& CT$_e$& CT$_p$& CT$_e$& CT$_p$& CT$_e$& CT$_p$& CT$_e$\\
%         \hline 
%         \hline
%         AP-AE& 0.51& 0.66& 0.11 & 0.48 & 0.21 & 0.78 & 0.10 & 0.51 & 0.94 & 0.94 & 0.87 & 0.89 & 0.81 & 0.37\\
%         AP-UE & 0.50& 0.65& 0.20 & 0.44 & 0.11 & 0.83 & 0.03 & 0.41 & 0.97 & 0.92 & 0.84 & 0.92 & 0.81 & 0.38\\
%         UP-AE & 0.50& 0.62&  0.13 & 0.49 & 0.20 & 0.67 & 0.10 & 0.56 & 0.80 & 0.77 & 0.90 & 0.90 & 0.85 & 0.30\\
%         UP-UE & 0.49& 0.63& 0.27 & 0.48 & 0.17 & 0.75 & 0.07 & 0.45 & 0.90 & 0.82 & 0.82 & 0.90 & 0.75 & 0.40\\
%     \hline
%     % Plan& Imperfect& 
%     % \hline 
% 	\end{tabular}
%  \end{small}
% \end{table}

\subsubsection{The Impact of User Involvement in Planning on Task Performance} \label{sec-exp-h2}
To verify \textbf{H2}, we considered plan quality, the accuracy of action sequences (ACC$_s$), and the execution accuracy of the plan (ACC$_e$) for analysis.
For plan quality (cf. Table~\ref{tab:h1-res}), we conducted one-way ANOVA on plan quality considering the user involvement in the planning stage. 
We found that overall user involvement in the planning stage caused a decrease plan quality, especially on tasks with a perfect plan (\ie task 4, 5, 6, where plan quality = 5) and task-3. 
However, in task-1, where the original plan contains a grammar error, we find that user involvement in planning can improve the plan quality. 
As the action sequence accuracy (ACC$_s$) and execution accuracy (ACC$_e$) are not normally distributed, we conducted the Kruskal-Wallis H-test by considering the user involvement in the planning as the independent variable. \revise{The results are shown in Table~\ref{tab:h2-res}.}
With further post-hoc Mann-Whitney tests, we found that while participants achieved a relatively higher accuracy of action sequences in condition AP-AE, the condition UP-UE achieved the best execution accuracy. 
In most tasks, condition UP-UE achieved better or compatible performance as other conditions. The only exception is task-4, where user involvement in the planning caused a significantly worse performance (both ACC$_s$ and ACC$_e$). 
% While user involvement can not consistently bring benefits to the task performance, we did find it can help in specific scenarios (\eg task-1, where the plan is with a grammar error). 
\revise{As user involvement does not consistently lead to improved performance, these results are not enough to support \textbf{H2}.}
% Thus, \textbf{H2} is partially supported.\glcomment{I think we can still claim partial support for H2 instead of no support. right? @Ujwal} \ujcomment{To align with the reviewer comments (esp. regarding null results), maybe it is better to say no support for H2 but leave the other points and discussion as they are.}

% \revise{We found that in task-1 and task-6 most participants in the AP-AE condition achieved a very low success rate. This is mainly due to the imperfect plans and imperfect execution generated by LLMs. 
% In task-1, the plan generated by LLMs includes one step which contains two actions to execute. 
% Due to the inability to edit the plan, the LLM agent execution missed one transaction in conditions with automatic planning. 
% In task-6, the plan generated by LLMs is correct. 
% However, in the automatic execution of step 2 of the plan (\ie selecting an itinerary suggested), the LLM agent has a high probability of choosing an itinerary that does not match the task description. 
% If the participants do not carefully check the task description, and correct this agent behavior, the execution results would be wrong.
% This also helps explain why user involvement substantially improves the task outcome accuracy in task-6. More details about tasks can be found in supplementary materials.}
%\glcomment{I was struck by the difference in results for the six tasks shown in Table 4. For task-1, which was simple, but had an imperfect plan, basically all trials were failures. For task-6, which was complex but had a correct plan, failure was also extremely high. I was left wondering how these tasks differed from each other. I don't quite trust the simple argument that "user involvement can help" when the failure rate is around 90\%. I was hoping for something that can explain what is happening. Is the problem in the interests, capabilities, capacities, or incentives of the participants? 
%}\glcomment{After addressing this comment, I feel it would be better if we could provide the generated plans and further explain the flaws of automation of LLM agent in each task in supplementary materials.}
% We found that, for the ACC$_s$ over the task batch, AP-AE > UP-AE, AP-UE. \glcomment{Shall we only conduct one-way ANOVA for plan quality?} \glcomment{only compare AP with UP}

% \begin{table}[h]
% 	\centering
% 	\caption{Task-specific Evaluation Results for calibrated trust. ACC$_s$ denotes the strict accuracy of an action sequence, and ACC$_e$ denotes the correctness of execution results.}
% 	\label{tab:h2-res}
%     \begin{small}
% 	\begin{tabular}{c | c | c | c}
% 	    \hline
%         Tasks& Plan Quality& ACC$_s$& ACC$_e$\\
%         \hline 
%         \hline
%         Avg& -& - & -\\
%         task-1 & AP < UP & AP < UP& AP < UP\\
%         task-2 & -& -& -\\
%         task-3 & AP > UP& AE > UE& -\\
%         task-4 & AP > UP& AP > UP& AP > UP\\
%         task-5 & AP > UP& -& -\\
%         task-6 & AP > UP& AE < UE & AE < UE\\
%     \hline
% 	\end{tabular}
%  \end{small}
% \end{table}

% \begin{table*}[h]
% 	\centering
% 	\caption{Task-specific evaluation results for user-involvement in planning on task performance. ACC$_s$ denotes the strict accuracy of an action sequence, and ACC$_e$ denotes the correctness of execution results. Bold fonts are used to highlight the best performance across conditions.}
% 	\label{tab:h2-res}
%     \begin{small}
% 	\begin{tabular}{c | c c c  c | c | c  c c c | c}
% 	    \hline
%         \multirow{2}{*}{Tasks}&     \multicolumn{5}{c|}{ACC$_s$}&  \multicolumn{5}{c}{ACC$_e$}\\
%         \cline{2-11}
%         & AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
%         \hline 
%         \hline
%         Avg& \textbf{0.53} & 0.46 & 0.46 & 0.48 & - & 0.54 & 0.53 & 0.47 & \textbf{0.56} & -\\
%         \hline
%         task-1& 0.00 & 0.00 & 0.10 & \textbf{0.12} & AP < UP & 0.00 & 0.00 & 0.10 & \textbf{0.13} & AP < UP\\
%         task-2 &\textbf{0.78} & 0.64 & 0.61 & 0.57 & - & \textbf{0.78} & 0.72 & 0.66 & 0.75 & - \\
%         task-3 & \textbf{0.44} & 0.12 & 0.36 & 0.28 & - & 0.44 & 0.42 & 0.36 & \textbf{0.52} & - \\
%         task-4 & \textbf{0.95} & 0.89 & 0.75 & 0.82 & AP > UP & \textbf{0.95} & 0.89 & 0.75 & 0.82 & AP > UP \\
%         task-5 & \textbf{0.98} & 0.91 & 0.90 & 0.90 & - & \textbf{0.98} & 0.91 & 0.92 & 0.90 & - \\
%         task-6 & 0.05 & \textbf{0.22} & 0.02 & 0.18 & - & 0.06 & \textbf{0.23} & 0.03 & 0.22 & - \\
%     \hline
% 	\end{tabular}
%  \end{small}
% \end{table*}

\revise{We found that in task-1 and task-6 most participants in the AP-AE condition achieved a very low success rate. This is mainly due to the imperfect plans and imperfect execution generated by LLMs. 
In task-1, the plan generated by LLMs includes one step which contains two actions to execute. 
Due to the inability to edit the plan, the LLM agent execution missed one transaction in conditions with automatic planning. 
In task-6, the plan generated by LLMs is correct. 
However, in the automatic execution of step 2 of the plan (\ie selecting an itinerary suggested), the LLM agent has a high probability of choosing an itinerary that does not match the task description. 
If the participants do not carefully check the task description, and correct this agent behavior, the execution results would be wrong.
This also helps explain why user involvement substantially improves the task outcome accuracy in task-6. More details about tasks can be found in the appendix.}

\begin{table*}[h]
	\centering
	\caption{Task-specific evaluation results for user-involvement in execution on task performance. Bold fonts are used to highlight the best performance across conditions.}
	\label{tab:h4-res}
    \begin{small}
	\begin{tabular}{c | c c c  c | c | c  c c c | c}
	    \hline
        \multirow{2}{*}{Tasks}&     \multicolumn{5}{c|}{ACC$_s$}&  \multicolumn{5}{c}{ACC$_e$}\\
        \cline{2-11}
        & AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
        \hline 
        \hline
        Avg& \textbf{0.53} & 0.46 & 0.50 & 0.51 & - & 0.54 & 0.53 & 0.50 & \textbf{0.58} & -\\
        \hline
        task-1& 0.00 & 0.00 & 0.10 & \textbf{0.12} & - & 0.00 & 0.00 & 0.10 & \textbf{0.14} & -\\
        task-2 &\textbf{0.78} & 0.64 & 0.67 & 0.62 & - & \textbf{0.78} & 0.72 & 0.69 & \textbf{0.78} & - \\
        task-3 & \textbf{0.44} & 0.12 & 0.42 & 0.29 & AE > UE & 0.44 & 0.42 & 0.42 & \textbf{0.53} & - \\
        task-4 & \textbf{0.95} & 0.89 & 0.94 & 0.88 & - & \textbf{0.95} & 0.89 & 0.94 & 0.88 & - \\
        task-5 & 0.98 & 0.91 & \textbf{1.00} & 0.98 & - & 0.98 & 0.91 & \textbf{1.00} & 0.98 & -\\
        task-6 & 0.05 & \textbf{0.22} & 0.02 & 0.19 & AE < UE & 0.06 & \textbf{0.23} & 0.04 & \textbf{0.23} & AE < UE\\
    \hline
	\end{tabular}
 \end{small}
\end{table*}

\subsubsection{The Impact of User Involvement in Execution on Calibrated Trust in Execution Outcome}
As we observe in Table~\ref{tab:h1-res}, user involvement in planning can have some negative impact on the plan quality, which further impacts the execution stage. 
To control such impact, we filtered out the tasks where plan quality decreased after user-involved planning in the analysis of user involvement in the execution stage. 
To verify \textbf{H3}, we conducted one-way ANOVA on calibrated trust in execution outcome (CT$_e$). The results are shown in Table~\ref{tab:h3-res}. 
We found that user involvement in execution causes no significant difference across conditions. 
Thus, \textbf{H3} is not supported by our experimental results.
% However, such results are heavily impacted by the plan quality, which is impacted by the user involvement in the planning stages. 
% To control such impact, we filtered out tasks where users generate a low-quality plan (plan quality = 1, 2). 
% \glcomment{fair comparison, AP-AE vs AP-UE; unfair comparison, UP-AE vs UP-UE?} \glcomment{how to control plan quality in UP conditions? >= initial plan?}


\begin{table}[h]
	\centering
	\caption{Task-specific evaluation results for user-involvement in execution on calibrated trust in execution (CT$_e$). We also report the mean value for each measure on each condition.}%\glcomment{Shall we adopt calibrated trust based on two dimensions? correct, wrong?}}
	\label{tab:h3-res}
    \begin{small}
	\begin{tabular}{c | c c c  c | c }
	    \hline
        \multirow{2}{*}{Tasks}&     \multicolumn{5}{c}{CT$_e$}\\
        \cline{2-6}
        & AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
        \hline 
        \hline
        Avg & \textbf{0.66} & 0.65 & 0.64 & 0.65 & - \\
        \hline
        task-1& 0.48 & 0.44 & \textbf{0.51} & 0.49 & -\\
        task-2 &0.78 & \textbf{0.83} & 0.71 & 0.80 & -\\
        task-3 & 0.51 & 0.41 & \textbf{0.60} & 0.47 & -\\
        task-4 & \textbf{0.94} & 0.92 & 0.88 & 0.86 & -\\
        task-5 & 0.89 & 0.92 & \textbf{0.96} & 0.94 & -\\
        task-6 & 0.37 & 0.38 & 0.28 & \textbf{0.42} & -\\
    \hline
	\end{tabular}
 \end{small}
\end{table}


%\glcomment{All of section 5.2.4 is riddled with interpretations that confuse the reader, such as “One point to note is that on the three tasks with high risks (tasks 1, 2, 3), condition UP-UE achieved the best execution accuracy (non-significant difference between AE and UE)”. My interpretation of 5.2.4 at first glance was that there is no support for H4, counter to what the paper reports through selective interpretation. Reporting null effects is not a problem: it is also an interesting finding if you observe no differences between when there is and isn’t user involvement. The somewhat convoluted interpretation makes it harder to understand the actual results and undermines credence in the findings.}

\subsubsection{The Impact of User Involvement on Overall Task Performance} Similar to the verification of \textbf{H3}, we excluded the tasks where plan quality decreased after user-involved planning in this analysis. 
As the plan is generated before user involvement in the execution, we only considered ACC$_s$ and ACC$_e$ in the analysis of user involvement in the execution stage. 
To verify \textbf{H4}, we conducted Kruskal-Wallis H-test by considering the user involvement in the execution as the independent variable. The results are shown in Table~\ref{tab:h4-res}. 
With post-hoc Mann-Whitney tests, we found that user involvement in the execution stage showed significantly higher ACC$_s$ and ACC$_e$ in task-6 (where the LLM assistant mainly failed to choose the most suitable itinerary plan). 
% \revise{While ACC$_s$ assesses how often the execution action sequence strictly the same as ground truth (annotated by the authors).}
% While participants achieved a relatively higher accuracy of action sequences in condition AP-AE, condition UP-UE achieved the best execution accuracy. 
\revise{We found that participants in the AP-AE condition achieved the best accuracy of action sequences (\ie ACC$_s$), and participants in condition UP-UE achieved the best execution accuracy (\ie ACC$_e$). 
In other words, the executed action sequence in condition AP-AE is more aligned with the ground truth action sequence annotated by the authors. 
However, with user involvement in the execution stage, participants in condition UP-UE have a better opportunity to obtain correct task outcomes by correcting potentially flawed actions. 
Such a difference is due to our measure of ACC$_e$, which tolerates the non-risky actions (\eg search flight) and failure of action predictions. 
In contrast, our measure of ACC$_s$ considers this as a wrong action sequence. 
% being tolerant in the evaluation of task outcome with ACC$_e$. %\ujcomment{This prev. sentence is not clear.}
} %\glcomment{To check in our online meeting}
\revise{Thus,} in task-3, \revise{even if} we find automatic execution achieved \revise{significantly} better ACC$_s$ than user-involved execution, participants in condition AP-UE and UP-UE %\revise{still} 
obtained comparable or higher execution accuracy \revise{(\ie ACC$_e$) than conditions with automatic execution}. 
% One point to note is that on the three tasks with high risks (tasks 1, 2, 3), condition UP-UE achieved the best execution accuracy (non-significant difference between AE and UE). 
% Meanwhile, we also noticed that after filtering out low-quality plans, participants in condition UP-AE achieved $100\%$ accuracy in both action sequence generation and execution. 
% Thus, on the whole, we find support for \textbf{H4}.
\revise{While user involvement shows some positive impact on the execution accuracy, such impact is not significant and consistent across all tasks. 
Only in task-6, where users can correct the errors made by the LLM agent (\ie the wrong itinerary selection mentioned in Section~\ref{sec-exp-h2}), user involvement in the execution shows a significant contribution to the task performance. 
% Thus, these results only provide partial support for \textbf{H4}.
Thus, these results are not enough to strictly support \textbf{H4}.
}
%\glcomment{I still take this as a supporting signal to H4 instead of a null effect. Meanwhile, I removed many sentences of claiming the better performance achieved by UE (such as UP-AE achieved 100 percent accuracy and task 1, 2, 3 are of high risks). I guess these sents may bring the confusion.How do you think about it?} \ujcomment{Same as previous comment for H2. Let's discuss how to best win over this reviewer.}
% \glcomment{Kruskal. As the execution results are affected by the plan quality. Shall we control the plan quality, then compare them? For example, compare AP-AE with AP-UE; compare UP-AE with UP-UE}

% \paratitle{Task-specific Analysis}. 

% \begin{table}[tbp]
% 	\centering
% 	\caption{Task-specific evaluation results for overall task performance. ACC$_s$ denotes the strict accuracy of an action sequence, and ACC$_e$ denotes the correctness of execution results.}
% 	\label{tab:task_execution_res}
%     \begin{small}
%     \scalebox{0.9}{
% 	\begin{tabular}{c| c c | c c| c c| c c| c c| c c | c c}
% 	    \hline
%         Tasks&\multicolumn{2}{c|}{Avg}&\multicolumn{2}{c|}{Task-1}&\multicolumn{2}{c|}{Task-2}&\multicolumn{2}{c|}{Task-3}&\multicolumn{2}{c|}{Task-4}&\multicolumn{2}{c|}{Task-5}&\multicolumn{2}{c}{Task-6}\\
%         \hline
%         Conditions& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$& ACC$_s$& ACC$_e$\\
%         \hline 
%         \hline
%         AP-AE & 0.53& 0.54& 0.00 & 0.00 & 0.78 & 0.78 & 0.44 & 0.44 & 0.95 & 0.95 & 0.98 & 0.98 & 0.05 & 0.06\\
%         AP-UE & 0.46& 0.53& 0.00 & 0.00 & 0.64 & 0.72 & 0.12 & 0.42 & 0.89 & 0.89 & 0.91 & 0.91 & 0.22 & 0.23\\
%         UP-AE & 0.46& 0.47& 0.10 & 0.10 & 0.61 & 0.66 & 0.36 & 0.36 & 0.75 & 0.75 & 0.90 & 0.92 & 0.02 & 0.03\\
%         UP-UE & 0.48& 0.56& 0.12 & 0.13 & 0.57 & 0.75 & 0.28 & 0.52 & 0.82 & 0.82 & 0.90 & 0.90 & 0.18 & 0.22\\
%     \hline
%     % Plan& Imperfect& 
%     % \hline 
% 	\end{tabular}
%  }
%  \end{small}
% \end{table}

% \begin{table*}[h]
% 	\centering
% 	\caption{Task-specific evaluation results for user-involvement in execution on task performance. Bold fonts are used to highlight the best performance across conditions.}
% 	\label{tab:h4-res}
%     \begin{small}
% 	\begin{tabular}{c | c c c  c | c | c  c c c | c}
% 	    \hline
%         \multirow{2}{*}{Tasks}&     \multicolumn{5}{c|}{ACC$_s$}&  \multicolumn{5}{c}{ACC$_e$}\\
%         \cline{2-11}
%         & AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results& AP-AE& AP-UE& UP-AE& UP-UE& Post-hoc results\\
%         \hline 
%         \hline
%         Avg& \textbf{0.53} & 0.46 & 0.50 & 0.51 & - & 0.54 & 0.53 & 0.50 & \textbf{0.58} & -\\
%         \hline
%         task-1& 0.00 & 0.00 & 0.10 & \textbf{0.12} & - & 0.00 & 0.00 & 0.10 & \textbf{0.14} & -\\
%         task-2 &\textbf{0.78} & 0.64 & 0.67 & 0.62 & - & \textbf{0.78} & 0.72 & 0.69 & \textbf{0.78} & - \\
%         task-3 & \textbf{0.44} & 0.12 & 0.42 & 0.29 & AE > UE & 0.44 & 0.42 & 0.42 & \textbf{0.53} & - \\
%         task-4 & \textbf{0.95} & 0.89 & 0.94 & 0.88 & - & \textbf{0.95} & 0.89 & 0.94 & 0.88 & - \\
%         task-5 & 0.98 & 0.91 & \textbf{1.00} & 0.98 & - & 0.98 & 0.91 & \textbf{1.00} & 0.98 & -\\
%         task-6 & 0.05 & \textbf{0.22} & 0.02 & 0.19 & AE < UE & 0.06 & \textbf{0.23} & 0.04 & \textbf{0.23} & AE < UE\\
%     \hline
% 	\end{tabular}
%  \end{small}
% \end{table*}


\subsection{Exploratory Analysis}

\subsubsection{The Impact of Covariates}
For further insights into all user factors on user trust and team performance, we calculated Spearman rank-order correlation coefficients for user trust, calibrated trust, risk perception, and task performance. 
As can be seen in Table~\ref{tab:correlation}, we found these covariates mainly show correlations with subjective user trust, calibrated trust in execution, and risk perception. 
% However, these user factors do not significantly correlate with task performance. 
First, all covariates (\ie user factors) positively correlated with user trust (four subscales in the trust in automation questionnaire~\cite{korber2019theoretical}) and negatively correlated with perceived risk (average over six tasks). 
It indicates that users with more expertise or familiarity with such systems tend to trust the daily assistant and show less perceived risk when using it. 
Meanwhile, users with a general propensity to trust also tend to trust the AI system. 
Besides user trust, \textit{Assistant Expertise} and \textit{Propensity to Trust} show a significant negative correlation with calibrated trust in the execution outcome. 
Apart from the above correlation, these user factors do not significantly correlate with task performance measures or calibrated trust in the planning outcome.

\begin{table*}[ht]
% the environment \color{blue} change all cell color
	\centering
	\caption{Spearman rank-order correlation coefficient for covariates level on dependent variables. All measures are calculated based on average over task batch. ``${\dagger}$'' and ``${\dagger\dagger}$'' indicate the effect of the variable is significant at the level of 0.05 and 0.0125, respectively.}
	\label{tab:correlation}%
	\begin{small}
        \scalebox{0.95}{
	\begin{tabular}{l | l| c c | c c | c c | c c}
	    \hline
	    \multicolumn{2}{c|}{\textbf{Covariates}}& \multicolumn{2}{c|}{llm expertise} &  \multicolumn{2}{c|}{assistant expertise}& \multicolumn{2}{c|}{Familiarity}& \multicolumn{2}{c}{Propensity to Trust}\\
     \hline
     \textbf{Category} &\textbf{Variables}&  $r$& $p$ &  $r$& $p$ &  $r$& $p$ &  $r$& $p$ \\
	    \hline \hline
    % Mental demand & -0.046 & .472& -0.003 & .968& -0.163 &\textbf{.010}$^{\dagger\dagger}$& -0.188 &\textbf{.003}$^{\dagger\dagger}$\\
    % Physical demand & 0.314 &\textbf{.000}$^{\dagger\dagger}$& 0.267 &\textbf{.000}$^{\dagger\dagger}$& 0.166 &\textbf{.009}$^{\dagger\dagger}$& 0.219 &\textbf{.001}$^{\dagger\dagger}$\\
    % Temporal demand & 0.031 & .623& 0.034 & .593& -0.077 & .225& -0.039 & .542\\
    % Performance & -0.133 & .036$^{\dagger}$& -0.154 & .016$^{\dagger}$& -0.154 & .015$^{\dagger}$& -0.080 & .209\\
    % Effort & 0.037 & .562& 0.109 & .087& -0.046 & .470& -0.013 & .839\\
    % Frustration & -0.249 &\textbf{.000}$^{\dagger\dagger}$& -0.131 & .039$^{\dagger}$& -0.296 &\textbf{.000}$^{\dagger\dagger}$& -0.348 &\textbf{.000}$^{\dagger\dagger}$\\
    % \hline
    \multirow{4}{*}{\textbf{User Trust}}& Reliability/Competence & 0.334 &\textbf{.000}$^{\dagger\dagger}$& 0.245 &\textbf{.000}$^{\dagger\dagger}$& 0.321 &\textbf{.000}$^{\dagger\dagger}$& 0.679 &\textbf{.000}$^{\dagger\dagger}$\\
    &Understanding/Predictability & 0.307 &\textbf{.000}$^{\dagger\dagger}$& 0.164 &\textbf{.010}$^{\dagger\dagger}$& 0.208 &\textbf{.001}$^{\dagger\dagger}$& 0.380 &\textbf{.000}$^{\dagger\dagger}$\\
    &Intention of Developers & 0.406 &\textbf{.000}$^{\dagger\dagger}$& 0.324 &\textbf{.000}$^{\dagger\dagger}$& 0.362 &\textbf{.000}$^{\dagger\dagger}$& 0.517 &\textbf{.000}$^{\dagger\dagger}$\\
    &Trust in Automation & 0.380 &\textbf{.000}$^{\dagger\dagger}$& 0.278 &\textbf{.000}$^{\dagger\dagger}$& 0.356 &\textbf{.000}$^{\dagger\dagger}$& 0.698 &\textbf{.000}$^{\dagger\dagger}$\\
    % &Trust-p & 0.099 & .119& 0.163 &\textbf{.010}$^{\dagger\dagger}$& 0.233 &\textbf{.000}$^{\dagger\dagger}$& 0.137 & .030$^{\dagger}$\\
    % &Trust-e & 0.096 & .130& 0.168 &\textbf{.008}$^{\dagger\dagger}$& 0.091 & .154& 0.292 &\textbf{.000}$^{\dagger\dagger}$\\
	    \hline
    \multirow{2}{*}{\textbf{Calibrated Trust}}&CT$_p$ & 0.053 & .404& 0.053 & .402& 0.056 & .378& 0.037 & .566\\
    &CT$_e$ & -0.120 & .059& -0.195 &\textbf{.002}$^{\dagger\dagger}$& -0.032 & .621& -0.174 &\textbf{.006}$^{\dagger\dagger}$\\
    \hline
    \textbf{Risk Perception}& Perceived Risk & -0.187 &\textbf{.003}$^{\dagger\dagger}$& -0.180 &\textbf{.004}$^{\dagger\dagger}$& -0.237 &\textbf{.000}$^{\dagger\dagger}$& -0.363 &\textbf{.000}$^{\dagger\dagger}$\\
    \hline
    
    % &Recall & -0.075 & .238& -0.077 & .230& -0.003 & .965& -0.013 & .843\\
    \multirow{3}{*}{\textbf{Task Performance}}&ACC$_s$ & 0.037 & .560& -0.014 & .823& 0.110 & .085& 0.018 & .772\\
    &ACC$_e$ & -0.000 & .995& -0.037 & .567& 0.085 & .184& 0.007 & .911\\
    &Plan Quality& -0.035 & .587& -0.037 & .560& 0.080 & .211& -0.032 & .611\\
    \hline
	\end{tabular}
        }
	\end{small}
\end{table*}

\begin{table}[ht]
% the environment \color{blue} change all cell color
	\centering
	\caption{Task-specific spearman rank-order correlation coefficient for plan quality and risk perception. ``${\dagger}$'' and ``${\dagger\dagger}$'' indicate the effect of the variable is significant at the level of 0.05 and 0.0125, respectively.}
	\label{tab:correlation-2}%
	\begin{small}
        \scalebox{0.95}{
	\begin{tabular}{l | l| c c | c c }
	    \hline
	    \multirow{2}{*}{\textbf{Category}}&\multirow{2}{*}{\textbf{Variables}}& \multicolumn{2}{c|}{Plan Quality} &  \multicolumn{2}{c}{Risk Perception}\\
     \cline{3-6}
     & &  $r$& $p$ &  $r$& $p$\\
	    \hline \hline
    \multirow{2}{*}{\textbf{User Trust}}&Trust-p & 0.056 & .032$^{\dagger}$& -0.293 &\textbf{.000}$^{\dagger\dagger}$\\
    &Trust-e & 0.258 &\textbf{.000}$^{\dagger\dagger}$& -0.160 &\textbf{.000}$^{\dagger\dagger}$\\
    \hline
    \multirow{2}{*}{\textbf{Calibrated Trust}}& CT$_p$ & 0.723 &\textbf{.000}$^{\dagger\dagger}$& -0.102 &\textbf{.000}$^{\dagger\dagger}$\\
    & CT$_e$& 0.221 &\textbf{.000}$^{\dagger\dagger}$& 0.000 & .995\\
    \hline
    \multirow{3}{*}{\textbf{Task Performance}}&Plan Quality & - &-& -0.141 &\textbf{.000}$^{\dagger\dagger}$\\
     % \cline{3-6}
    &ACC$_e$ & 0.400 &\textbf{.000}$^{\dagger\dagger}$& -0.110 &\textbf{.000}$^{\dagger\dagger}$\\
    &ACC$_s$ & 0.446 &\textbf{.000}$^{\dagger\dagger}$& -0.096 &\textbf{.000}$^{\dagger\dagger}$\\
    \hline
    \multirow{2}{*}{\textbf{Confidence}}&Confidence-p & 0.137 &\textbf{.000}$^{\dagger\dagger}$& -0.532 &\textbf{.000}$^{\dagger\dagger}$\\
    &Confidence-e & 0.225 &\textbf{.000}$^{\dagger\dagger}$& -0.271 &\textbf{.000}$^{\dagger\dagger}$\\
    \hline
	\end{tabular}
        }
	\end{small}
\end{table}

\subsubsection{Impact of Plan Quality and Risk Percetion.} Besides the measures calculated over task batch, a task-level 
%~\glcomment{Is `task-specific' the correct phrase? I mean calculating the correlation at the level of each task, but not really check how these variables correlate at each task}
analysis of plan quality and risk perception can deepen our understanding of their impacts. 
Besides measures adopted in Table~\ref{tab:correlation}, we include task-level confidence in this analysis and exclude the subscales from the trust in automation questionnaire.
Thus, we calculated Spearman rank-order correlation coefficients for task-level measures across all groups of participants (shown in Table~\ref{tab:correlation-2}). 
As we can see, both plan quality and risk perception significantly correlate with user trust, calibrated trust, task performance, and user confidence. 
The \textit{plan quality} shows a significant positive correlation with most measures, which indicates users perform better and calibrate their trust in the LLM agents in tasks with a high-quality plan. 
By contrast, the \textit{risk perceptions} shows a negative correlation with most measures and also a negative correlation with the plan quality. %\gladd{Impacts of these factors will be further discussed in Section~\ref{sec:discussion-findings}.}

% \begin{table*}[ht]
% % the environment \color{blue} change all cell color
% 	\centering
% 	\caption{Task-specific spearman rank-order correlation coefficient for plan quality and risk perception. ``${\dagger}$'' and ``${\dagger\dagger}$'' indicate the effect of the variable is significant at the level of 0.05 and 0.0125, respectively.}
% 	\label{tab:correlation-2}%
% 	% \begin{small}
%         % \scalebox{0.95}{
% 	\begin{tabular}{l | l| c c | c c }
% 	    \hline
% 	    \multirow{2}{*}{\textbf{Category}}&\multirow{2}{*}{\textbf{Variables}}& \multicolumn{2}{c|}{Plan Quality} &  \multicolumn{2}{c}{Risk Perception}\\
%      \cline{3-6}
%      & &  $r$& $p$ &  $r$& $p$\\
% 	    \hline \hline
%     \multirow{2}{*}{\textbf{User Trust}}&Trust-p & 0.056 & .032$^{\dagger}$& -0.293 &\textbf{.000}$^{\dagger\dagger}$\\
%     &Trust-e & 0.258 &\textbf{.000}$^{\dagger\dagger}$& -0.160 &\textbf{.000}$^{\dagger\dagger}$\\
%     \hline
%     \multirow{2}{*}{\textbf{Calibrated Trust}}& CT$_p$ & 0.723 &\textbf{.000}$^{\dagger\dagger}$& -0.102 &\textbf{.000}$^{\dagger\dagger}$\\
%     & CT$_e$& 0.221 &\textbf{.000}$^{\dagger\dagger}$& 0.000 & .995\\
%     \hline
%     \multirow{3}{*}{\textbf{Task Performance}}&Plan Quality & - &-& -0.141 &\textbf{.000}$^{\dagger\dagger}$\\
%      % \cline{3-6}
%     &ACC$_e$ & 0.400 &\textbf{.000}$^{\dagger\dagger}$& -0.110 &\textbf{.000}$^{\dagger\dagger}$\\
%     &ACC$_s$ & 0.446 &\textbf{.000}$^{\dagger\dagger}$& -0.096 &\textbf{.000}$^{\dagger\dagger}$\\
%     \hline
%     \multirow{2}{*}{\textbf{Confidence}}&Confidence-p & 0.137 &\textbf{.000}$^{\dagger\dagger}$& -0.532 &\textbf{.000}$^{\dagger\dagger}$\\
%     &Confidence-e & 0.225 &\textbf{.000}$^{\dagger\dagger}$& -0.271 &\textbf{.000}$^{\dagger\dagger}$\\
%     \hline
% 	\end{tabular}
%         % }
% 	% \end{small}
% \end{table*}

% \subsubsection{Risk perception} \glcomment{Task-specific analysis? What is the connection between user trust and risk perception}

\subsubsection{Failure Analysis}
\label{sec-failure-analysis}
% For tasks where the plan is imperfect (plan quality $<5$), we identify the imperfect plan to be the main cause of execution failure. 
As we find that plan quality substantially affects task execution accuracy, we look into task performance across different plan qualities. 
For the tasks with low-quality plans (plans fail to cover task information or plan with grammar errors, \ie plan quality=1, 2), the execution accuracy is $1.8\%$. 
While for tasks with a plan that may mislead action prediction (plan quality = 3, 4), our LLM agent-based daily assistant achieved $59\%$ execution accuracy. 
The average execution accuracy for tasks with a high-quality plan (plan quality =5) is $66.7\%$.

We further check 717 tasks where a high-quality plan (plan quality = 5) is provided. Among them, 235 tasks provide wrong execution results. The main causes are: 
(1) Wrong action parameter prediction ($48.9\%$). 
While action names match, one or more parameters mismatch the expected value at some step of the action sequence. 
(2) Invalid actions ($48.5\%$). Given a perfect plan, the LLM agent failed to predict one valid action (failed to predict one action name or failed to predict some action parameter value) to execute in some steps. 
(3) Wrong action name prediction ($2.6\%$). The generated action sequence has at least one action name prediction that mismatches the ground truth. %\glcomment{To discuss, these problems can be covered by the user. Shall we further discuss the errors made in each condition?}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/confidence_planning_execution_barplot.pdf}
    \caption{\revise{Bar plot for confidence dynamics, the x-axis denotes the task ordering index (shuffled for every participant). The error bars represent the 95\% confidence interval.}} 
    \label{fig:confidence}
    \Description{Bar plot for confidence dynamics, the x-axis denotes the task ordering index (shuffled for every participant). We observe that participants show higher confidence in the task execution outcomes, compared to planning outcomes. The confidence gap between the two stages get narrowed with user involvement in the execution stages.}
\end{figure}

\begin{table*}[htbp]
	\centering
	\caption{Excerpts from participants' responses to open questions regarding opinion.}
	\label{tab:example-opinion}%
	\scalebox{.9}{
    \begin{tabular}{p{0.72\textwidth}| p{0.08\textwidth} |p{0.24\textwidth}}
		\hline
		\textbf{Opinion towards Planning} &  \textbf{Sentiment}& \textbf{Reason}  \\
		\hline \hline
		I really like how organized it is. The step by step and numerical planning allows it to make sense in a clear and structured way, meaning there is less room for errors or misinformation& Positive&  helpful with reducing error\\
        \hline
        It was remarkable how quickly. It was able to achieve the goals which was set out in the tasks. I quite liked it I would definitely want something like this in my life as It would my my life much easier& Positive& Effective and make life easy\\
		% \hline
		% I'm not sure if that was supposed to be very mentally challenging but it was! I felt like I needed to understand coding or be some kind of computer nerd& Negative& high cognitive load and difficult for laypeople\\
		% \hline
		% While certainly useful, in its current form it is likely too complex for the layperson, who could easily fall into grievous error using such a system.& Negative& difficult for laypeople\\
		\hline
		As I said previously, it's far, far too detailed in an unnecessary way.  I'm not sure people need the entire plan of what the AI will do, as long as the job gets done.& Negative& too detailed\\
  \hline
        I found it really helpful, but made me slightly nervous thinking all my plans being successful are in the hands of ai tech& Mixed& helpful assistant, agency concerns \\
  \hline
  \textbf{Opinion towards Execution} &  \textbf{Sentiment}& \textbf{Reason}  \\
		\hline \hline
        The execution stage was amazing. I feel like this could be the future and we wont need to call or talk to people to get this kind of thing done ever again.& Positive& promising future\\
        \hline
        The execution stage went smoothly, except for a few rare instances of an error response before also saying the AI's automatic reply (which was correct).& Mixed& Smooth user experience, error response\\
		\hline
		I found it clunky and nit that user friendly& Negative& clunky, not user-friendly\\
        \hline
        This bit is user friendly, but very robotic, which makes it difficult to trust& Mixed& user-friendly, distrust due to robotic nature\\
		\hline
    \end{tabular}}
\end{table*}%

\subsubsection{Confidence Dynamics}
To visualize the user confidence in the planning and execution stage, we draw \revise{point plots} (see Figure~\ref{fig:confidence}) for user confidence in the task order. 
Overall, condition AP-AE shows the highest confidence in both the planning and execution stages. 
To verify the impact of user involvement in confidence, we adopted two-way ANOVA and post-hoc Tukey HSD test. 
We find that: (1) with user involvement in the planning, participants showed significantly lower confidence in planning (AP-AE > UP-AE, UP-UE); (2) with user involvement in the execution, participants showed a significantly lower confidence in execution (AP-AE > AP-UE, UP-UE). 
Meanwhile, users typically showed a higher confidence in the execution stage. 
Compared with conditions with automation execution (\ie condition AP-AE and UP-AE), the confidence gap narrows down in the conditions with user-involved execution (\ie condition AP-UE and UP-UE). %\glcomment{Try to combine user trust with confidence, but it seems not very explicit. I decide to first keep it as is}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=\textwidth]{figures/confidence_dynamics_barplot.pdf}
%     \caption{Line plot for confidence dynamics, the x-axis denotes the task ID.\glcomment{How about the new barplot. Besides, I want to check with you, which one works better? confidence based on each of the tasks (based on task ID) or confidence based on task ordering?}} 
%     \label{fig:confidence}
%     \Description{Line plot for confidence dynamics, the x-axis denotes the task ordering index (shuffled for every participant). We observe that participants show higher confidence in the task execution outcomes, compared to planning outcomes. The confidence gap between the two stages get narrowed with user involvement in the execution stages.}
% \end{figure}

% \begin{figure*}[h]
%     \centering
%     \includegraphics[width=\textwidth]{figures/confidence_planning_execution_pointplot.pdf}
%     \caption{\revise{Point plot for confidence dynamics, the x-axis denotes the task ordering index (shuffled for every participant). The error bars represent the 95\% confidence interval.}} 
%     \label{fig:confidence}
%     \Description{Point plot for confidence dynamics, the x-axis denotes the task ordering index (shuffled for every participant). We observe that participants show higher confidence in the task execution outcomes, compared to planning outcomes. The confidence gap between the two stages get narrowed with user involvement in the execution stages.}
% \end{figure*}

\subsection{Analysis of Open Feedback} At the end of our study, we collected open feedback regarding the planning stage, execution stage, and any other feedback using the following question: %is framed as :
`\textit{Please share any comments, remarks or suggestions regarding the planning/execution stage of LLM Assistant}' and `\textit{Do you have any other comments, remarks or suggestions regarding the study?}'. 
Overall, we analyzed all the feedback based on user opinions (positive, negative, mixed, neutral) and their suggestions. 
In our analysis, we ignored all phrases without any useful information like `None', `N/A', and `No comment'. 

\paratitle{\revise{Feedback and Suggestions}}. While most comments tended to show positive opinions (more than $80\%$) towards LLM agents as daily assistants, there are also negative opinions regarding the difficulty, expertise, trust, etc. We provide example excerpts from participants in Table~\ref{tab:example-opinion}. Besides opinions towards the system, some participants also appreciated our user-centric setup:"\textit{The study does a good job of emphasizing user experience by asking about perceptions of risk, trust, and confidence. This approach ensures that the evaluation is user-centric, which is important for assessing the real-world applicability of the LLM Assistant}."

% \begin{table*}[htbp]
% 	\centering
% 	\caption{Excerpts from participants' responses to open questions regarding opinion.}
% 	\label{tab:example-opinion}%
% 	\scalebox{.9}{
%     \begin{tabular}{p{0.7\textwidth}| p{0.1\textwidth} |p{0.2\textwidth}}
% 		\hline
% 		\textbf{Opinion towards Planning} &  \textbf{Sentiment}& \textbf{Reason}  \\
% 		\hline \hline
% 		I really like how organized it is. The step by step and numerical planning allows it to make sense in a clear and structured way, meaning there is less room for errors or misinformation& Positive&  helpful with reducing error\\
%         \hline
%         It was remarkable how quickly. It was able to achieve the goals which was set out in the tasks. I quite liked it I would definitely want something like this in my life as It would my my life much easier& Positive& Effective and make life easy\\
% 		% \hline
% 		% I'm not sure if that was supposed to be very mentally challenging but it was! I felt like I needed to understand coding or be some kind of computer nerd& Negative& high cognitive load and difficult for laypeople\\
% 		% \hline
% 		% While certainly useful, in its current form it is likely too complex for the layperson, who could easily fall into grievous error using such a system.& Negative& difficult for laypeople\\
% 		\hline
% 		As I said previously, it's far, far too detailed in an unnecessary way.  I'm not sure people need the entire plan of what the AI will do, as long as the job gets done.& Negative& too detailed\\
%   \hline
%         I found it really helpful, but made me slightly nervous thinking all my plans being successful are in the hands of ai tech& Mixed& helpful assistant, agency concerns \\
%   \hline
%   \textbf{Opinion towards Execution} &  \textbf{Sentiment}& \textbf{Reason}  \\
% 		\hline \hline
%         The execution stage was amazing. I feel like this could be the future and we wont need to call or talk to people to get this kind of thing done ever again.& Positive& promising future\\
%         \hline
%         The execution stage went smoothly, except for a few rare instances of an error response before also saying the AI's automatic reply (which was correct).& Mixed& Smooth user experience, error response\\
% 		\hline
% 		I found it clunky and nit that user friendly& Negative& clunky, not user-friendly\\
%         \hline
%         This bit is user friendly, but very robotic, which makes it difficult to trust& Mixed& user-friendly, distrust due to robotic nature\\
% 		\hline
%     \end{tabular}}
% \end{table*}%

Some participants also provided suggestions on how to further improve the design of LLM agent-based daily assistants. 
% Example excerpts from participants in Table~\ref{tab:example-suggestion}. 
Regarding the plan edit, participants hope we can provide more convenient edit operations like `drop/drag' to adjust plan text ordering and `undo' operation to tolerate unexpected mistakes. 
Some participants also found the plans too detailed, which could increase the cognitive load (cf. Table~\ref{tab:example-opinion} except 3). 
%\revise{The granularity of the plan can be a factor that may affect the effectiveness of human-AI collaboration. For example, a detailed plan can be useful when precise parameters are required, but a simple plan may prove to be more effective when to m.} 
As for the execution, many participants found it to be smooth. %think it works smoothly. 
At the same time, they think additional verification in each step may further enhance the reliability of daily assistants: ``\textit{For the execution stage, I commend it for creating an input formatting box to execute the user's request validating each requirement}.''
There are also comments about the whole plan-then-execute workflow: ``\textit{The planning was really challenging, and I mostly left the default plans (they looked fine). 
This worked in the main, but a couple clearly needed revisiting. I would approach this iteratively: plan, test, observe, back to planning, then another test, before reaching the desired outcome}.'' \revise{Our findings suggest open research opportunities to explore more effective ways to provide an overview of plans that trade-off user cognitive load resulting from granular descriptions, with the need to provide details to help users identify flaws. For example, we can consider developing methods to interactively allow users to flesh out further details in a plan. }
%Iteration upon the current plan-then-execute workflow to ensure the correct final outcome can be a future direction to explore.


% \begin{table}[htbp]
% 	\centering
% 	\caption{Excerpts from participants' responses to open questions as suggestions.}
% 	\label{tab:example-suggestion}%
% 	\scalebox{.85}{
%     \begin{tabular}{p{0.65\textwidth}| p{0.1\textwidth} |p{0.3\textwidth}}
% 		\hline
%   \textbf{Suggestion towards Planning} &  \textbf{Sentiment}& \textbf{Reason}  \\
% 		\hline \hline
%     The planning was really challenging, and I mostly left the default plans (they looked fine). This worked in the main, but a couple clearly needed revisiting. I would approach this iteratively : plan, test, observe, back to planning, then another test, before reaching the desired outcome.& &\\
%     \hline
%     I think being able to expand or collapse the steps in the planning stage would help make it easier. Also, a drag and drop facility with the required fields would also help.& &\\
%     \hline
%     Well thought out study and is explained well. I still would like see the instruction have a video-format for people less "technologically able". But I am very interested to see what comes next.& &\\
%   \hline
%   \textbf{Suggestion towards Execution} &  \textbf{Sentiment}& \textbf{Reason}  \\
% 		\hline \hline
%   The study provides a structured approach to task execution with an emphasis on clarity and verification. Incorporating real-time adjustments based on feedback could further improve its effectiveness.& & \\ \hline
%   Additional verification in each step would have been helpful.& & \\
%   \hline
%     \end{tabular}}
% \end{table}%

% \begin{table}[htbp]
% 	\centering
% 	\caption{Resulting main themes from the thematic analysis of participants' responses to the open questions pertaining to analogy-based explanations across stages.} %\glcomment{@Ujwal,@Gianluca. If you find some comments for the topic `Tutorial and Instruction' is not desirable, we can remove them}}
% 	\label{tab:example-topic}%
% 	\scalebox{.9}{
%     \begin{tabular}{p{0.1\textwidth}|p{0.3\textwidth}|p{0.3\textwidth}|p{0.3\textwidth}}
% 		\hline
% % 		\textbf{Participant Feedback} &  \textbf{Sentiment}& \textbf{Reason}  \\
% 		\multirow{2}{*}{\textbf{Topic}}&\multicolumn{3}{c}{\textbf{Participant Feedback}}\\
% 		\cline{2-4}
% 		&Planning& Execution& Other\\
% 		\hline \hline
% 		Expertise and Familiarity& %(1) the whole study felt like it was geared toward a computer science course rather than the average person 
%   (1) I felt like I needed to understand coding or be some kind of computer nerd (2) While certainly useful, in its current form it is likely too complex for the layperson, who could easily fall into grievous error using such a system.& (1) There is little knowledge on how The LLM Assistant executes actions and why it may not complete the whole agenda, making it difficult to identify the error when it makes mistakes. (2) I've used booking systems like this in the past. They seem very reliable. They often work well with a human back up at the end of the line.& It was a little hard for someone with little experience of the LLM Assistant. \\
% 		\hline
% 		Work Load& %(1) I'm not sure if that was supposed to be very mentally challenging but it was! 
%   (1) The planning stage required a fair bit of effort to complete. %(2) The planning was very time-consuming. 
%   (2) it took some time and effort to double check if the AI's planning was accurate & (1) This also seems very hands on, defeating the purpose. (2) An AI assistant should be streamlined and easy to use.  All that reading of the tasks and checking, a person might as well do the task themselves if they have to approve every step.& (1) The task was mentally exhausting. (2) Not enough reward payment for a lot of cognitive load and a long time of work (3) It was mentally challenging and time-consuming (4) The study was too long for the assigned time hence creating anxiety about the completion of the study.\\
% 		\hline
% 		% Time concern& & & (1) The study was too long for the assigned time hence creating anxiety about the completion of the study. (2) I felt like this study was interesting but took much longer than stated.\\
%   %       \hline
%         Tutorial and Instruction& (1) after doing the planning several times, I found that easier to understand. (2) The step by step instruction in the planning stage helps to understand the big picture and the elements or variables that require to be captured to achieve the outcome. (3) Instructions were wordy and would benefit from being reduced (4) The planning stage is clear but could use more examples to guide when to split, add, or delete steps.& (1) The execution stage was more intuitive. The tutorial made it seem more complicated than it actually was. (2) Instructions during the tutorial are a bit confusing. I was only able to understand fully when interacting with the execution system and through the tasks (3) It wasn't totally clear when something had failed if the system had corrected itself. and I got into an instruction loop a few times & (1) The instructions need to be "dumbed down". (2) More examples to start with and maybe start with the simpler tasks first. (3) I would rather a hand holding guide at the start to take me through the steps piece by piece. I found that I learned as I engaged in the task rather than reading the instructions at the start.\\
%         \hline
%         Trust and Uncertainty& (1) the planning stage of the LLM assistant was helpful and trustworthy. (2) A bit unreliable as it can make mistakes.& (1) This bit is user-friendly, but very robotic, which makes it difficult to trust (2) Seemed to work well but unsure if I'd trust it. (3) I would still rather do things myself& I would not trust LLM to do the tasks in the examples, I would prefer to do them myself.\\
% 		\hline
%     \end{tabular}}
% \end{table}%


% \paratitle{Themes}. 
% To dive deeper into the user feedback, we conducted thematic analysis using the ATLAS.TI tool. The thematic analysis results are presented in Table~\ref{tab:example-topic}. Most participants had positive experiences. However, we present a balanced set of excerpts in the 
% %While most participants show positive opinions, we tend to show more criticism in 
% Table~\ref{tab:example-topic}. The complete anonymized data  will be shared publicly.
% %Such reviews can give 
% This presents a critical reflection of our plan-then-execute LLM agent-based daily assistant and can help point out future directions worth exploring. 
% In summary, we found that the participants mainly gave feedback surrounding four aspects: (1) expertise and familiarity, (2) workload, (3) tutorial and instruction, and (4) trust and uncertainty. 
% We summarize the feedback into four themes. 
% First, some participants argue this daily assistant may be difficult for laypeople, who lack knowledge about computer science or LLM, to use. 
% Second, some participants feel the whole study is too long and mentally challenging. Third, some participants hope there can be a simplified tutorial with clear instructions, and more examples and practice will help user onboarding. 
% Last, while some participants think the daily assistant is trustworthy and accurate, others doubt its reliability and prefer to do things themselves. \glcomment{Check whether we should remove some negative feedback, especially about tutorial and instruction}