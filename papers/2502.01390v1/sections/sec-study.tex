\section{Study Design}

This section describes our experimental conditions, tasks,  variables, procedure, and participants in our study. {Our
study was approved by the human research ethics committee of our institution.}

\subsection{Experimental Conditions}
In our study, users collaborate with LLM agent-based daily assistants in two stages: planning and execution. 
To comprehensively understand the effect of user involvement at each stage, we considered a 2 × 2 factorial design with four experimental conditions: (1) automatic planning, automatic execution (represented as AP-AE), (2) automatic planning, user-involved execution (represented as AP-UE), (3) user-involved planning, automatic execution (represented as UP-AE), (4) user-involved planning, user-involved execution (represented as UP-UE). 
In conditions with user-involved planning, users are allowed to edit the plan generated by LLM with the actions of edit/add/delete/split step. 
By comparison, in conditions with automatic planning, users will directly adopt the plan generated by the daily assistant.
In conditions with user-involved execution, users can interact with the step-by-step execution LLM agent (cf. Section~\ref{sec-method-execution}) and refine execution results with text feedback or manual specification. 
By comparison, in conditions with automatic execution, users will directly accept the automatic execution results.

\begin{table*}[htbp]
	\centering
	\caption{Selected tasks in our study. The `Risk' is based on the risk feedback obtained with pilot study. \#A and \#C refer to the number of actions and the number of named concepts in each task, respectively. }
	\label{tab:tasks}%
	\scalebox{.8}{
    \begin{tabular}{p{0.02\textwidth}|p{0.04\textwidth}|p{0.06\textwidth}|p{0.8\textwidth}|p{0.03\textwidth}|p{0.03\textwidth}| p{0.12\textwidth}}
		\hline
% 		\textbf{Participant Feedback} &  \textbf{Sentiment}& \textbf{Reason}  \\
        \textbf{ID}&\textbf{Risk}& \textbf{Domain}&  \textbf{Task Description}& \textbf{\#A}& \textbf{\#C}& \textbf{Notes}\\
		\hline \hline
		% Low& Finance& Can you help me log into my two different platform accounts and then check their account balances? The first account ID is 12345678, password is Password123; the second account ID is 87654321, password is 123Password.& Tutorial\\
		% \hline \hline
		1& High& Finance& My account ID is 54321, and the password is PWD2023. I plan to make two foreign exchange transactions. The first is to buy 10,000 euros (with USD), and the second is to sell 5,000 US dollars (to EUR). Please help me operate.&4&4& simple task, imperfect plan\\
        % \hline
        % High& Finance& I need to know the detailed information about the 'Happy Savings High Gold' deposit product, including its minimum deposit amount, annual interest rate, and deposit term. Also, I want to use my account number 123456 and password 789123 along with the most recently received verification code 8888 to apply for a loan, and I would like to know the review time for this loan application as well as how to check the status of all my current loan applications.\\
        \hline
        2& High& Finance& Please inquire about the current debt amount of my credit card with the last five digits 12345, and deduct the corresponding 12000 USD from my savings card number 6212345678900011 to repay this debt, then help me check the amount of the outstanding bill for the same credit card within 30 days after today.&4&6& complex task, imperfect plan\\
        \hline
        3& High& Repair& I need to schedule a repair for my TV at 6 PM tomorrow evening. The brand is Sony, model X800H, and there is an issue with the screen. Please book the repair service and tell me the reservation number.&4&7& complex task, imperfect plan\\
        % \hline
        % Low& Tracking& Please check the latest status of my two orders with the numbers 123456789 and 987654321, and confirm whether they are both associated with my customer ID A123456.\\
        % \hline
        % High& Restaurant& Please order a Spicy Hot Pot for me at the restaurant, add two extra servings of beef and a plate of hand-torn cabbage, then place the order using my table ID 10, and help me check out.\\
        \hline
        4& Low& Alarm& I need to set an alarm for every weekday morning at 7:30, and then cancel the alarm for Thursday, changing it to 8:00 in the evening.&2&3& simple task, correct plan\\
        \hline
        5& Low& Flight& I have an important meeting to attend next Wednesday, and I need to book a flight ticket from London to Amsterdam for tomorrow, it must be a morning flight, and then return from Amsterdam to London tomorrow night, please handle it for me.&2&6& simple task, correct plan\\
        \hline
        6& Low& Travel& Please plan a trip for me departing on October 1st at 8:00 AM to Japan, returning on October 7th at 11:00 PM, including Tokyo Disneyland, Senso-ji Temple, Ginza, Mount Fuji, Kyoto cultural experience, Universal Studios Osaka, and visiting the Nara Deer Park on October 4th, and help me find hotels where the nightly cost does not exceed 10,000 Japanese yen.&3&11& complex task, correct plan\\
        \hline
            \hline
    \end{tabular}}
\end{table*}%

\subsection{Tasks}
To analyze how LLM agents can serve as daily assistants, we adopted tasks from a planning dataset designed for LLM agents --- UltraTool~\cite{huang2024planning}. 
We selected daily scenarios: currency transactions, credit card payments, repair service appointments, alarm setting, flight ticket booking, and trip itinerary planning. 
The selected tasks are shown in Table~\ref{tab:tasks}. \revise{For more details about how the plan-then-execute LLM agent works on the selected tasks (\eg automatic plan, pre-defined actions, automatic evaluation, and explanation for errors in automation), please refer to the appendix.}
All tasks in UltraTool dataset are annotated with the step-wise plan format described in Section~\ref{sec-method-planning}. \revise{The execution of these tasks is based on a simulation environment (described in Section~\ref{sec-method-execution}) where all required actions are implemented as backend APIs. 
In our study, all tasks are executed in a simulation setup, which has been a popular method for orchestrating meaningful human-centered AI studies~\cite{doshi2017towards,salimzadeh2024dealing}.} %is effective in developing and validating theory~\cite{davis2007developing} and has been widely adopted in existing research on agent-based modeling and HCI studies~\cite{olson2014ways}.}
%\glcomment{It is unclear if the participants were performing the real tasks or were in a scenario-based setting. The concern impacts the validity of the study design. The clarification along with simulation design justification, would help readers better understand the results.}\ujcomment{Clarify, justify this as a valid method used widely in HCAI research.}\glcomment{I clarified in the execution part (Section 3.3). If you feel it is not necessary to highlight again, we can remove the last sent here.}

% \begin{table*}[htbp]
% 	\centering
% 	\caption{Selected tasks in our study. The `Risk' is based on the risk feedback obtained with pilot study.}
% 	\label{tab:tasks}%
% 	\scalebox{.84}{
%     \begin{tabular}{p{0.02\textwidth}|p{0.04\textwidth}|p{0.07\textwidth}|p{0.8\textwidth}| p{0.12\textwidth}}
% 		\hline
% % 		\textbf{Participant Feedback} &  \textbf{Sentiment}& \textbf{Reason}  \\
%         \textbf{ID}&\textbf{Risk}& \textbf{Domain}&  \textbf{Task Description}& \textbf{Notes}\\
% 		\hline \hline
% 		% Low& Finance& Can you help me log into my two different platform accounts and then check their account balances? The first account ID is 12345678, password is Password123; the second account ID is 87654321, password is 123Password.& Tutorial\\
% 		% \hline \hline
% 		1& High& Finance& My account ID is 54321, and the password is PWD2023. I plan to make two foreign exchange transactions. The first is to buy 10,000 euros (with USD), and the second is to sell 5,000 US dollars (to EUR). Please help me operate.& simple task, imperfect plan\\
%         % \hline
%         % High& Finance& I need to know the detailed information about the 'Happy Savings High Gold' deposit product, including its minimum deposit amount, annual interest rate, and deposit term. Also, I want to use my account number 123456 and password 789123 along with the most recently received verification code 8888 to apply for a loan, and I would like to know the review time for this loan application as well as how to check the status of all my current loan applications.\\
%         \hline
%         2& High& Finance& Please inquire about the current debt amount of my credit card with the last five digits 12345, and deduct the corresponding 12000 USD from my savings card number 6212345678900011 to repay this debt, then help me check the amount of the outstanding bill for the same credit card within 30 days after today.& complex task, imperfect plan\\
%         \hline
%         3& High& Repair& I need to schedule a repair for my TV at 6 PM tomorrow evening. The brand is Sony, model X800H, and there is an issue with the screen. Please book the repair service and tell me the reservation number.& complex task, imperfect plan\\
%         % \hline
%         % Low& Tracking& Please check the latest status of my two orders with the numbers 123456789 and 987654321, and confirm whether they are both associated with my customer ID A123456.\\
%         % \hline
%         % High& Restaurant& Please order a Spicy Hot Pot for me at the restaurant, add two extra servings of beef and a plate of hand-torn cabbage, then place the order using my table ID 10, and help me check out.\\
%         \hline
%         4& Low& Alarm& I need to set an alarm for every weekday morning at 7:30, and then cancel the alarm for Thursday, changing it to 8:00 in the evening.& simple task, correct plan\\
%         \hline
%         5& Low& Flight& I have an important meeting to attend next Wednesday, and I need to book a flight ticket from London to Amsterdam for tomorrow, it must be a morning flight, and then return from Amsterdam to London tomorrow night, please handle it for me.& simple task, correct plan\\
%         \hline
%         6& Low& Travel& Please plan a trip for me departing on October 1st at 8:00 AM to Japan, returning on October 7th at 11:00 PM, including Tokyo Disneyland, Senso-ji Temple, Ginza, Mount Fuji, Kyoto cultural experience, Universal Studios Osaka, and visiting the Nara Deer Park on October 4th, and help me find hotels where the nightly cost does not exceed 10,000 Japanese yen.& complex task, correct plan\\
%         \hline
%             \hline
%     \end{tabular}}
% \end{table*}%

\paratitle{Task Selection}. First, based on the domain distribution of the UltraTool dataset, we selected seven domains: Finance, Alarm, Travel, Tracking, Restaurant, Flight, and Repair. 
For each domain, we only \revise{consider} tasks that contain more than ten steps (including all sub-steps) and require at least three uses of actions. 
Then, we manually selected ten tasks: four from the finance domain and one for each of the others. 
With a pilot study, we tested how users work on the ten tasks. 
We recruited 10 participants from the Prolific platform and only considered the feedback of 9 participants who passed all attention checks. 
\revise{Using} the question “How much risk do you perceive in this task when relying on this daily AI assistant?”, we collected the perceived risk of working with the LLM agents on each task \revise{using a 5-point Likert scale, ranging from \textit{1: not risky at all}---to---\textit{5:very risky}.} %\ujcomment{mention the scale}
We categorize the ten tasks into a high-risk group (top 5) and a low-risk group (bottom 5). 
We selected three tasks from each group while balancing the complexity of the task description (three simple tasks and three complex tasks) and the correctness of the provided plan (three correct plans and three imperfect plans). 
\revise{Based on existing literature on task complexity~\cite{wood1986task,salimzadeh2023missing}, we  considered component complexity to inform our selection. 
This is assessed as the `total number of distinct information cues that need to be processed to perform the task'. 
Here, we considered the number of unique actions and the number of named concepts provided in each task.}
According to prior work~\cite{miller1956magical}, most people can only handle 5 to 9 concepts at the same time. 
The component complexity of all complex tasks in our study is more than nine.
% \glcomment{Clarify here for the design of simple/complex tasks}\ujcomment{Task complexity (Robert Wood) -> Task Complexity (cite Sara's work)}
The six tasks selected are shown in Table~\ref{tab:tasks}. 
Besides the six tasks, we used one simple task (\ie checking bank account balance) as the example in the onboarding tutorial.


\subsection{Measures and Variables}
% \subsection{Evaluation}
\label{sec-measure}

The variables and measures used in our study refer to existing empirical studies of human-AI collaboration~\cite{lai2021towards}. 
All measures adopted in our study can be summarized in Table~\ref{tab:variables}. 
\begin{table*}[htbp]
	\centering
	\caption{The different variables considered in our experimental study. ``DV'' refers to the dependent variable.}
	\label{tab:variables}
	\begin{footnotesize}
	\begin{tabular}{c | c | c | c}
	    \hline
	    \textbf{Variable Type}&	\textbf{Variable Name}& \textbf{Value Type}& \textbf{Value Scale}\\
	    \hline \hline

	    \hline
         \multirow{2}{*}{Calibrated Trust (DV)}& Calibrated Trust in planning (CT$_p$)& Binary& 0: miscalibrated trust, 1: calibrated trust\\
        & Calibrated Trust in execution (CT$_e$)& Binary& 0: miscalibrated trust, 1: calibrated trust\\
        \hline
	    \multirow{3}{*}{Task Performance (DV)}& Plan Quality& Likert& 5-point, 1: low, 5: high\\
        % & Outcome Accuracy& Continuous, Interval& [0.0, 1.0]\\
        % & Action Sequence Accuracy - Relaxed& Continuous, Interval& [0.0, 1.0]\\
        & Action Sequence Accuracy (ACC$_s$)& Binary& 0: mismatch, 1: exact match with ground truth\\
        & Execution Accuracy (ACC$_e$)& Binary& 0: wrong execution result, 1: correct execution result\\
        % & Action Sequence Recall& Continuous, Interval& [0.0, 1.0]\\
	    % \hline
	    % \multirow{4}{*}{Reliance (DV)}& Agreement Fraction& Continuous, Interval& [0.0, 1.0]\\
	    % & Switch Fraction& Continuous& [0.0, 1.0]\\
	    % & RAIR& Continuous& [0.0, 1.0]\\
	    % & RSR& Continuous& [0.0, 1.0]\\
	    \hline
     % \multirow{2}{*}{Assessment (DV)}& Degree of Miscalibration& Continuous, Interval& [0,6]\\
     % & Self-assessment& Continuous, Interval& [-6,6]\\
     % \hline
     \multirow{4}{*}{Trust}& Reliability/Competence& Likert& 5-point, 1: poor, 5: good\\
    & Understanding/Predictability& Likert& 5-point, 1: poor, 5: good\\
    & Intention of Developers& Likert& 5-point, 1: poor, 5: good\\
    & Trust in Automation& Likert& 5-point, 1:strong distrust, 5: strong trust\\
    \hline
     % \multirow{4}{*}{Trust (DV)}& TiA-Trust& Likert& 5-point, 1:strong distrust, 5: strong trust\\
     % & TiA-Trust& Likert& 5-point, 1:strong distrust, 5: strong trust\\
     % & TiA-Trust& Likert& 5-point, 1:strong distrust, 5: strong trust\\
     % & TiA-Trust& Likert& 5-point, 1:strong distrust, 5: strong trust\\
     % \hline
     \multirow{4}{*}{Covariates}& LLM Expertise& Likert& 5-point, 1: No experience, 5: Extensive experience\\
     & Automatic Assistant Expertise& Likert& 5-point, 1: No experience, 5: Extensive experience\\
     & Propensity to Trust& Likert& 5-point, 1: tend to distrust, 5: tend to trust \\
     & Familiarity& Likert& 1: unfamiliar, 5: very familiar\\
     \hline
	\multirow{5}{*}{Exploratory}& Confidence& Likert& 5-point, 1: unconfident, 5: confident\\
    & Risk Perception& Likert& 5-point, 1: not risky at all, 5: very risky\\
    & Open Feedback on Planning& Text& Open Text\\
    & Open Feedback on Execution& Text& Open Text\\
    & Other Open Feedback& Text& Open Text\\
    % & Cognitive Load& Likert& -7: very low, 7: very high\\
	    \hline
     \multirow{6}{*}{{Cognitive Load }}& Mental Demand& Likert& -7: very low, 7: very high\\
	    & Physical Demand& Likert& -7: very low, 7: very high\\
	    & Temporal Demand& Likert& -7: very low, 7: very high\\
	    & Performance& Likert& -7: Perfect, 7: Failure\\
        & Effort& Likert& -7: very low, 7: very high\\
        & Frustration& Likert& -7: very low, 7: very high\\
     \hline
	\end{tabular}
	\end{footnotesize}
\end{table*}

\paratitle{Calibrated Trust}. To assess calibrated trust in the planning stage and execution stage, we assessed user trust at each stage with a question ``Do you trust that [the execution of this plan / the execution process] can provide a correct outcome based on the task instructions?''. 
Based on the plan quality evaluation (5-point Likert), the calibrated trust in the planning (CT$_p$) is calculated based on the frequency at which users trusted the high-quality plan (expert annotation with 5) and users distrusted the plan with other evaluation results.
% will expect that users can trust the plan when the plan quality is annotated as 5. Otherwise, users should indicate distrust. 
Similarly, for the calibrated trust in execution (CT$_e$), we calculated the frequency at which users trusted the correct execution results and distrusted the wrong execution results. 
The two measures can be calculated as:

\begin{equation}
\begin{aligned}
    \textnormal{CT}_p = &\mathbb{I}\left( \textnormal{trust = `Yes'}, \textnormal{plan quality} = 5\right) \\ & +\mathbb{I}\left( \textnormal{trust = `No'}, \textnormal{plan quality} < 5\right)
\end{aligned}
\end{equation}

\begin{equation}
    \textnormal{CT}_e = \mathbb{I}\left( \textnormal{trust = `Yes'}, \textnormal{ACC}_e = 1\right) + \mathbb{I}\left( \textnormal{trust = `No'}, \textnormal{ACC}_e = 0 \right)
\end{equation}

To assess the task performance, we mainly considered the task outcome from the planning and execution stages. 

\paratitle{Plan Quality}. As for the planning outcome, we evaluate the plan quality based on a 5-point Likert scale: 
1. low-quality plan, task requirements not covered; 
2. low-quality plan, task requirements covered but with grammar errors; 
3. medium-quality plan, task requirement covered but with at least one action intent mismatch with ground truth action sequence; 
4. medium-quality plan, task requirements covered but miss or have wrong details for action parameters; 
5. high-quality plan, covering all task requirements and providing all necessary details.

\paratitle{Execution Performance}. 
The execution of the step-wise plan will result in an action sequence. 
We provide a ground truth action sequence as a reference to evaluate the generated action sequence. 
We measure the action sequence accuracy (ACC$_s$) as the strict match of the action sequence and ground truth. 
% Meanwhile, there are some actions that do not harm the execution results (\eg searching for flights). 
Meanwhile, if one action sequence contains some redundant actions that are not harmful (\eg searching for flights), the execution results should still be correct. 
Thus, we also consider execution accuracy (ACC$_e$) as a task performance measure.

\paratitle{Subjective Trust and Covariates}. To enrich our analysis of user trust, we followed existing work to adopt the six subscales from the Trust-in-automation questionnaire~\cite{korber2019theoretical}. 
The four subscales --- \textit{Reliability/Competence},  \textit{Understanding/Predictability},  \textit{Intention of Developers},  \textit{Trust in Automation} are used as subjective measures of user trust in the LLM agent. 
Meanwhile, the \textit{Familiarity} and \textit{Propensity to Trust} are also used as covariates. Besides them, we considered user expertise in LLMs and user expertise in automatic assistants as covariates. 

\paratitle{Exploratory Variables}. To enrich our understanding of LLM agent as daily assistant, we assessed user confidence (both planning and execution) and risk perception along with each task. 
After users finish the study, we also ask for their open-text feedback on the planning and execution stages as well as other comments. 
To check the cognitive load of user involvement in our study, we adopted the NASA-TLX questionnaire~\cite{colligan2015cognitive}, which contains six subscales.

% The variables and measures used in our study refer to existing empirical studies of human-AI collaboration~\cite{lai2021towards}. 
% All measures adopted in our study can be  summarized in Table~\ref{tab:variables}. %\glcomment{We can consider removing this table to save space, or move it to supplementary materials}

\subsection{Participants}

\paratitle{Sample Size Estimation}. 
To ensure sufficient statistical power, we estimated the required sample size for a 2 × 2 factorial design based on G*Power~\cite{faul2009statistical}. 
{To correct for testing multiple hypotheses, we applied a Bonferroni correction so that the significance threshold decreased to $\frac{0.05}{4}=0.0125$.} 
We specified the default effect size $f = 0.25$
(\textit{i.e.,} indicating a moderate effect), a significance threshold $\alpha = 0.0125$ (\textit{i.e.,} due to testing multiple hypotheses), a statistical power of $(1 - \beta) = 0.8$, and that we will investigate $4$ different experimental conditions/groups. 
This resulted in a required sample size of $244$ participants. 
We thereby recruited 347 participants from the crowdsourcing platform Prolific\footnote{\url{https://www.prolific.co}}, to accommodate potential exclusion.

\paratitle{Compensation}. All participants were rewarded with an hourly wage of \pounds 8.1 deemed to be ``\textit{Fair}'' payment by the platform (estimated completion time was 30 minutes). 
As participants in condition UP-UE spent longer in the study, we paid each participant a commensurate bonus accounting for an extra 10 minutes. % with a bonus.
% \stcomment{This makes for 1.8 * 6 = 8.1 pounds hourly wage. If I do 1.8/7.5 then I get to estimated completion time of 14.4 minutes}~\glcomment{I checked it again, actually we run two rounds for main studt. First with estimation of 12 minutes (\pound 1.5), and second with 10 minutes (\pound 1.25). I think we can write it as 1.5. I included the service fee and calculated the mean for all participants.}
We rewarded participants with extra bonuses of \pounds 0.05 for every high-quality plan and correct execution result. 
According to existing literature~\cite{lee2004trust}, such a bonus setup can help incentivize participants to reach a correct decision. 
\revise{In comparison with existing literature exploring human-AI decision making~\cite{lai2021towards}, our reward setup is above the average payment and can be considered as being sufficient to elicit ecologically valid behavior among participants (\ie aiming to arrive at accurate execution results). Moreover, similar bonus structures akin to our setup have been effective in incentivizing reliable participant behavior and improving data quality across different studies with crowdsourced participants~\cite{fan2020crowdco, salimzadeh2024dealing,liutilizing,ma2024you}.}
%\glcomment{R3 also asked the authors to clarify the participants' incentive to achieve better performance in this dataset.} \ujcomment{Yes, these incentives are meaningful for participants. Two arguments to make:  1. Show that this is a good incentive compared to other HCAI studies. 2. Show that this is meaningful to participants in crowdsourcing platforms. Both can be supported by references.}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/cognitive_load_bar_plot_new.pdf}
    \caption{\revise{Bar plot for cognitive load across all conditions. ** indicates significance ($p < 0.0125$) through post-hoc Tukey HSD test. The error bars represent the 95\% confidence interval.}}%\glcomment{I changed the colors of bars to keep consistent with the confidence plot.}} 
    \label{fig:cognitive_load}
    \Description{Bar plot for cognitive load across all conditions. User involvement in planning shows a significant impact on Mental Demand, Temporal Demand, and Frustration. User involvement in execution shows a significant impact on Performance and Effort. These results indicate that user involvement in planning and execution will require a relatively high cognitive load.}
\end{figure*}

\paratitle{Filter Criteria}. All participants were proficient English speakers between the ages of 18 - 50. 
We also constrained their prior experience (at least 40 successful submissions) and had an approval rate of above 90\% on the Prolific platform. 
We excluded participants from our analysis if they failed any attention check, or represented an outlier regarding the plan quality. 
Outliers were 4 participants who generated more than three low-quality plans among six tasks. 
The reserved 248 participants had an average age of 32.5 ($SD$= 8.1) and a balanced gender distribution
($50\%$, $49.6\%$ female, $0.4\%$ other).


% We filter out participants who provide low-quality plans (with a manual check), four participants. 


\subsection{Procedure}
At the beginning of our study, we showed informed consent for data collection and the study's purpose. 
Only participants who signed the informed consent \revise{were allowed to} continue to work on our study. 
Next, participants were asked to complete a pre-task questionnaire to measure their expertise in LLM and automatic assistants. %\glcomment{Do you think it's fine not to provide a flow chart for the whole process? As our paper can be quite long}\gdcomment{I seems pretty standard steps, so not necessary imo}

Participants were then assigned to one of the experimental conditions, which differed in the level of user involvement in the planning stage and execution stage. 
With an onboarding tutorial, we showcased the necessary interactions that participants were expected to perform in the planning and execution stages. 
We used an example task to help participants understand how to work with the plan-then-execute LLM agent. 
After the onboarding tutorial, participants worked on the selected tasks, which were shuffled at random for every participant to prevent task ordering effects. 
After the participants finished the task batch, we measured their perceived cognitive load using the NASA-TLX questionnaire~\cite{colligan2015cognitive}, their overall trust in the daily assistant using the trust in automation questionnaire~\cite{korber2019theoretical}, and we gathered their feedback on our system (related to planning, execution, and other aspects) using open-ended text.