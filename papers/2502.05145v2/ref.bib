@article{michel2022regret,
  title={Regret bounds for satisficing in multi-armed bandit problems},
  author={Michel, Thomas and Hajiabolhassan, Hossein and Ortner, Ronald},
  journal={Transactions on Machine Learning Research},
  year={2022}
}

@inproceedings{Lihong2010,
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
title = {A contextual-bandit approach to personalized news article recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {661–670},
numpages = {10},
keywords = {web service, recommender systems, personalization, exploration/exploitation dilemma, contextual bandit},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@inproceedings{bouneffouf2012,
  TITLE = {{A contextual-bandit algorithm for mobile context-aware recommender system}},
  AUTHOR = {Bouneffouf, Djallel and Bouzeghoub, Amel and Lopes Gan{\c c}arski, Alda},
  URL = {https://hal.science/hal-00753401},
  BOOKTITLE = {{ICONIP '12 : The 19th International Conference on Neural Information Processing}},
  ADDRESS = {Doha, Qatar},
  HAL_LOCAL_REFERENCE = {12606},
  PUBLISHER = {{Springer}},
  VOLUME = {7665},
  PAGES = {324-331},
  YEAR = {2012},
  MONTH = Nov,
  KEYWORDS = {Recommender system ; Machine learning ; Exploration/exploitation dilemma ; Artificial intelligence},
  HAL_ID = {hal-00753401},
  HAL_VERSION = {v1},
}

@Article{Yom-Tov2017,
author="Yom-Tov, Elad
and Feraru, Guy
and Kozdoba, Mark
and Mannor, Shie
and Tennenholtz, Moshe
and Hochberg, Irit",
title="Encouraging Physical Activity in Patients With Diabetes: Intervention Using a Reinforcement Learning System",
journal="J Med Internet Res",
year="2017",
month="Oct",
day="10",
volume="19",
number="10",
pages="e338",
issn="1438-8871"}

@article{Liao2020,
author = {Liao, Peng and Greenewald, Kristjan and Klasnja, Predrag and Murphy, Susan},
title = {Personalized HeartSteps: A Reinforcement Learning Algorithm for Optimizing Physical Activity},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
month = mar,
articleno = {18},
numpages = {22},
keywords = {Just-in-Time Adaptive Intervention, Mobile Health, Reinforcement Learning}
}

@article{Prins2020,
  author = {Aviva Prins and Aditya Mate and Jackson Killian and Rediet Abebe and Milind Tambe},
  title = {Incorporating Healthcare Motivated Constraints in Restless Bandit Based Resource Allocation},
  year = {2020},
  journal = {NeurIPS 2020 Workshops: Challenges of Real World Reinforcement Learning, Machine Learning in Public Health (Best Lightning Paper), Machine Learning for Health (Best on Theme), Machine Learning for the Developing World},
  language = {eng},
}

@misc{baek2024,
      title={Policy Optimization for Personalized Interventions in Behavioral Health}, 
      author={Jackie Baek and Justin J. Boutilier and Vivek F. Farias and Jonas Oddur Jonasson and Erez Yoeli},
      year={2024},
      eprint={2303.12206},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.12206}, 
}


@article{Lee2019,
author = {Lee, Elliot and Lavieri, Mariel S. and Volk, Michael},
title = {Optimal Screening for Hepatocellular Carcinoma: A Restless Bandit Model},
year = {2019},
issue_date = {Winter 2019},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {21},
number = {1},
issn = {1526-5498},
url = {https://doi.org/10.1287/msom.2017.0697},
doi = {10.1287/msom.2017.0697},
journal = {Manufacturing \& Service Operations Management},
month = jan,
pages = {198–212},
numpages = {15},
keywords = {dynamic programming, healthcare management, simulation, medical decision making, multiarmed bandits}
}




@inproceedings{Liu2014,
  title={Trading Off Scientific Knowledge and User Learning with Multi-Armed Bandits},
  author={Yun-En Liu and Travis Mandel and Emma Brunskill and Zoran Popovic},
  booktitle={Educational Data Mining},
  year={2014},
}

@misc{delrío2024,
      title={Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx}, 
      author={Ana Fernández del Río and Michael Brennan Leong and Paulo Saraiva and Ivan Nazarov and Aditya Rastogi and Moiz Hassan and Dexian Tang and África Periáñez},
      year={2024},
      eprint={2408.08024},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{delrío2024Pharmacy,
      title={Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services}, 
      author={Ana Fernández del Río and Michael Brennan Leong and Paulo Saraiva and Ivan Nazarov and Aditya Rastogi and Moiz Hassan and Dexian Tang and África Periáñez},
      year={2024},
      eprint={2408.07647},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@inproceedings{Shaikh2019,
  title={Balancing Student Success and Inferring Personalized Effects in Dynamic Experiments},
  author={Hammad Shaikh and Arghavan Modiri and Joseph Jay Williams and Anna N. Rafferty},
  booktitle={Educational Data Mining},
  year={2019},
}

@misc{mate2021,
      title={Field Study in Deploying Restless Multi-Armed Bandits: Assisting Non-Profits in Improving Maternal and Child Health}, 
      author={Aditya Mate and Lovish Madaan and Aparna Taneja and Neha Madhiwalla and Shresth Verma and Gargi Singh and Aparna Hegde and Pradeep Varakantham and Milind Tambe},
      year={2021},
      eprint={2109.08075},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{feng2024satisficing,
  title={Satisficing Exploration in Bandit Optimization},
  author={Feng, Qing and Ma, Tianyi and Zhu, Ruihao},
  journal={arXiv preprint arXiv:2406.06802},
  year={2024}
}

@article{10.1214/20-AOS1991,
author = {Steven R. Howard and Aaditya Ramdas and Jon McAuliffe and Jasjeet Sekhon},
title = {{Time-uniform, nonparametric, nonasymptotic confidence sequences}},
volume = {49},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {1055 -- 1080},
keywords = {Confidence sequence, empirical-Bernstein bound, finite LIL bound, matrix concentration, potential outcomes, sequential probability ratio test},
year = {2021},
}

@article{wang2020restless,
  title={Restless-UCB, an efficient and low-complexity algorithm for online restless bandits},
  author={Wang, Siwei and Huang, Longbo and Lui, John},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11878--11889},
  year={2020}
}

@inproceedings{10.1007/978-3-642-34106-9_19,
author = {Ortner, Ronald and Ryabko, Daniil and Auer, Peter and Munos, R\'{e}mi},
title = {Regret bounds for restless markov bandits},
year = {2012},
isbn = {9783642341052},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 23rd International Conference on Algorithmic Learning Theory},
pages = {214–228},
numpages = {15},
location = {Lyon, France},
series = {ALT'12}
}

@article{jung2019regret,
  title={Regret bounds for thompson sampling in episodic restless bandit problems},
  author={Jung, Young Hun and Tewari, Ambuj},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{wang2023optimistic,
  title={Optimistic whittle index policy: Online learning for restless bandits},
  author={Wang, Kai and Xu, Lily and Taneja, Aparna and Tambe, Milind},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={10131--10139},
  year={2023}
}

@article{liang2024bayesian,
  title={A bayesian approach to online learning for contextual restless bandits with applications to public health},
  author={Liang, Biyonka and Xu, Lily and Taneja, Aparna and Tambe, Milind and Janson, Lucas},
  journal={arXiv preprint arXiv:2402.04933},
  year={2024}
}

@inproceedings{xiong2022reinforcement,
  title={Reinforcement learning augmented asymptotically optimal index policy for finite-horizon restless bandits},
  author={Xiong, Guojun and Li, Jian and Singh, Rahul},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={8726--8734},
  year={2022}
}

@article{akbarzadeh2023learning,
  title={On learning Whittle index policy for restless bandits with scalable regret},
  author={Akbarzadeh, Nima and Mahajan, Aditya},
  journal={IEEE Transactions on Control of Network Systems},
  year={2023},
  publisher={IEEE}
}

@article{xiong2025finite,
  title={Finite-Horizon Single-Pull Restless Bandits: An Efficient Index Policy For Scarce Resource Allocation},
  author={Xiong, Guojun and Wang, Haichuan and Pan, Yuqi and Mandal, Saptarshi and Shah, Sanket and Boehmer, Niclas and Tambe, Milind},
  journal={arXiv preprint arXiv:2501.06103},
  year={2025}
}

@article{whittle1988restless,
  title={Restless bandits: Activity allocation in a changing world},
  author={Whittle, Peter},
  journal={Journal of applied probability},
  volume={25},
  number={A},
  pages={287--298},
  year={1988},
  publisher={Cambridge University Press}
}

@article{zhang2021restless,
  title={Restless bandits with many arms: Beating the central limit theorem},
  author={Zhang, Xiangyu and Frazier, Peter I},
  journal={arXiv preprint arXiv:2107.11911},
  year={2021}
}

@misc{hong2024achievingexponentialasymptoticoptimality,
      title={Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption}, 
      author={Yige Hong and Qiaomin Xie and Yudong Chen and Weina Wang},
      year={2024},
      eprint={2405.17882},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{Weber_Weiss_1990, title={On an index policy for restless bandits}, volume={27},  number={3}, journal={Journal of Applied Probability}, author={Weber, Richard R. and Weiss, Gideon}, year={1990}, pages={637–648}} 

@article{b0e74184-2114-3e45-b092-dfbc8fefcf91,
 ISSN = {0364765X, 15265471},
 author = {Christos H. Papadimitriou and John N. Tsitsiklis},
 journal = {Mathematics of Operations Research},
 number = {2},
 pages = {293--305},
 publisher = {INFORMS},
 title = {The Complexity of Optimal Queuing Network Control},
 volume = {24},
 year = {1999}
}

@article{xiong2022learning,
  title={Learning infinite-horizon average-reward restless multi-action bandits via index awareness},
  author={Xiong, Guojun and Wang, Shufan and Li, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17911--17925},
  year={2022}
}

@inproceedings{10.1109/ISIT.2018.8437712,
author = {Hsu, Yu-Pin},
title = {Age of Information: Whittle Index for Scheduling Stochastic Arrivals},
year = {2018},
publisher = {IEEE Press},
pages = {2634–2638},
numpages = {5},
location = {Vail, CO, USA}
}

@INPROCEEDINGS{7852321,
  author={Kadota, Igor and Uysal-Biyikoglu, Elif and Singh, Rahul and Modiano, Eytan},
  booktitle={2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Minimizing the Age of Information in broadcast wireless networks}, 
  year={2016},
  pages={844-851},
 }

@article{xiong2023finite,
  title={Finite-time analysis of whittle index based Q-learning for restless multi-armed bandits with neural network function approximation},
  author={Xiong, Guojun and Li, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={29048--29073},
  year={2023}
}

@article{xiong2024whittle,
  title={Whittle index-based q-learning for wireless edge caching with linear function approximation},
  author={Xiong, Guojun and Wang, Shufan and Li, Jian and Singh, Rahul},
  journal={IEEE/ACM Transactions on Networking},
  year={2024},
  publisher={IEEE}
}

@article{kakarapalli2024faster,
  title={Faster Q-Learning Algorithms for Restless Bandits},
  author={Kakarapalli, Parvish and Kayande, Devendra and Meshram, Rahul},
  journal={arXiv preprint arXiv:2409.05908},
  year={2024}
}

@inproceedings{killian2021q,
  title={Q-learning Lagrange policies for multi-action restless bandits},
  author={Killian, Jackson A and Biswas, Arpita and Shah, Sanket and Tambe, Milind},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={871--881},
  year={2021}
}

@article{brown2023fluid,
  title={Fluid policies, reoptimization, and performance guarantees in dynamic resource allocation},
  author={Brown, David B and Zhang, Jingwei},
  journal={Operations Research},
  year={2023},
  publisher={INFORMS}
}

@article{verloop2016asymptotically,
  title={Asymptotically optimal priority policies for indexable and nonindexable restless bandits},
  author={Verloop, Ina Maria},
  year={2016}
}

@article{gast2024linear,
  title={Linear program-based policies for restless bandits: Necessary and sufficient conditions for (exponentially fast) asymptotic optimality},
  author={Gast, Nicolas and Gaujal, Bruno and Yan, Chen},
  journal={Mathematics of Operations Research},
  volume={49},
  number={4},
  pages={2468--2491},
  year={2024},
  publisher={INFORMS}
}

@article{wang2019opportunistic,
  title={Opportunistic scheduling revisited using restless bandits: Indexability and index policy},
  author={Wang, Kehao and Yu, Jihong and Chen, Lin and Zhou, Pan and Ge, Xiaohu and Win, Moe Z},
  journal={IEEE Transactions on Wireless Communications},
  volume={18},
  pages={4997--5010},
  year={2019},
  publisher={IEEE}
}

@article{simchi2022bypassing,
  title={Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability},
  author={Simchi-Levi, David and Xu, Yunzong},
  journal={Mathematics of Operations Research},
  volume={47},
  pages={1904--1931},
  year={2022},
  publisher={INFORMS}
}

@article{villar2015multi,
  title={Multi-armed bandit models for the optimal design of clinical trials: benefits and challenges},
  author={Villar, Sof{\'\i}a S and Bowden, Jack and Wason, James},
  journal={Statistical science: a review journal of the Institute of Mathematical Statistics},
  volume={30},
  pages={199},
  year={2015},
  publisher={Europe PMC Funders}
}

@article{borkar2017opportunistic,
  title={Opportunistic scheduling as restless bandits},
  author={Borkar, Vivek S and Kasbekar, Gaurav S and Pattathil, Sarath and Shetty, Priyesh Y},
  journal={IEEE Transactions on Control of Network Systems},
  volume={5},
  pages={1952--1961},
  year={2017},
  publisher={IEEE}
}

@article{brown2020index,
  title={Index policies and performance bounds for dynamic selection problems},
  author={Brown, David B and Smith, James E},
  journal={Management Science},
  volume={66},
  pages={3029--3050},
  year={2020},
  publisher={INFORMS}
}

@article{tamatsukuri2019guaranteed,
  title={Guaranteed satisficing and finite regret: Analysis of a cognitive satisficing value function},
  author={Tamatsukuri, Akihiro and Takahashi, Tatsuji},
  journal={Biosystems},
  volume={180},
  pages={46--53},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{hajiabolhassan2023online,
  title={Online Regret Bounds for Satisficing in MDPs},
  author={Hajiabolhassan, Hossein and Ortner, Ronald},
  booktitle={Sixteenth European Workshop on Reinforcement Learning},
  year={2023}
}

@article{biswas2021learn,
  title={Learn to intervene: An adaptive learning policy for restless bandits in application to preventive healthcare},
  author={Biswas, Arpita and Aggarwal, Gaurav and Varakantham, Pradeep and Tambe, Milind},
  journal={arXiv preprint arXiv:2105.07965},
  year={2021}
}

@inproceedings{wang2023scalable,
  title={Scalable decision-focused learning in restless multi-armed bandits with application to maternal and child health},
  author={Wang, Kai and Verma, Shresth and Mate, Aditya and Shah, Sanket and Taneja, Aparna and Madhiwalla, Neha and Hegde, Aparna and Tambe, Milind},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={12138--12146},
  year={2023}
}

@article{raman2024global,
  title={Global Rewards in Restless Multi-Armed Bandits},
  author={Raman, Naveen and Shi, Zheyuan Ryan and Fang, Fei},
  journal={arXiv preprint arXiv:2406.00738},
  year={2024}
}

@inproceedings{killian2023robust,
  title={Robust planning over restless groups: engagement interventions for a large-scale maternal telehealth program},
  author={Killian, Jackson A and Biswas, Arpita and Xu, Lily and Verma, Shresth and Nair, Vineet and Taneja, Aparna and Hegde, Aparna and Madhiwalla, Neha and Diaz, Paula Rodriguez and Johnson-Yu, Sonja and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={14295--14303},
  year={2023}
}

@article{perianez2024reform,
    author={Peri{\'a}{\~n}ez, {\'A}frica and Ana Fern{\'a}ndez Del R{\'i}o and Ivan Nazarov and Enric Jan{\'e} and Moiz Hassan and Aditya Rastogi and Dexian Tang},
    title={The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems},
    journal={Health Systems \& Reform},
    year={2024}
}

@article{tamura2024cardiology,
    author={Yuichi Tamura and Akihiro Nomura and Nobuyuki Kagiyama and Atsushi Mizuno and Koichi Node},
    title={Digitalomics, digital intervention, and designing future: The next frontier in cardiology},
    journal={Journal of Cardiology},
    year={2024}
}

@article{shani2017jit,
    author={Inbal Nahum-Shani and Shawna N Smith and Bonnie J Spring and Linda M Collins and Katie Witkiewitz and Ambuj Tewari and Susan A Murphy},
    title={Just-in-Time Adaptive Interventions (JITAIs) in Mobile Health: Key Components and Design Principles for Ongoing Health Behavior Support},
    journal={Annals of Behavioral Medicine},
    year={2017}
}

@inproceedings{garivier2016optimal,
  title={Optimal best arm identification with fixed confidence},
  author={Garivier, Aur{\'e}lien and Kaufmann, Emilie},
  booktitle={Conference on Learning Theory},
  pages={998--1027},
  year={2016},
  organization={PMLR}
}