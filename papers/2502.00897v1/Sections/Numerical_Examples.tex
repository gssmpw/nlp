\section{\textbf{Numerical examples}}\label{examples}
In this section, we will validate the proposed Meta-LRPINN framework through a series of numerical examples. We begin by providing details of the meta-training stage, including the dataset construction, and the network and the training configurations. Then, we evaluate the performance of our method on two distinct models. First, we share our test on a layered velocity model to assess its ability to handle simple subsurface configurations and multi-frequency wavefields. Next, we apply the framework to the overthrust model, a more complex and realistic geological scenario, to demonstrate its scalability and adaptability. Finally, we evaluate the effectiveness of our rank-adaptive reduction strategy, highlighting its impact on computational efficiency and model performance.

\subsection{Meta-training procedure}\label{example1}
As stated earlier, the meta-training stage is designed to optimize the initialization parameters of the LRPINN and the FEH across various velocity models and a range of frequencies, enabling rapid adaptation to new velocity models and frequency configurations during the meta-testing phase. To achieve this, we construct a diverse set of tasks that encompass varying geological scenarios and frequency characteristics.

We generate a total of 40 velocity models with velocities ranging from 1.5 km/s to 5 km/s. The velocity models vary in size, with dimensions ranging from 2 km $\times$ 2 km (smallest) to 5 km Ã— 20 km (largest). This range ensures the inclusion of both compact and large-scale geological settings. For each velocity model, we consider 14 discrete frequencies between 2 and 15 Hz, resulting in a total of 560 tasks. To generate training data, we randomly sample 40000 spatial points within the domain, where the samples include spatial coordinates $x$ and $z$, the corresponding source's location $x_s$, the velocity $v$, and the background velocity $v_0$ at the random drawn location. All the source corresponding the training data, as well as the following meta-testing data, are fixed in a depth of 0.025 km. 

The LRPINN, in addition to the input and output layers, consists of six hidden layers, where the weight matrices in each hidden layer are decomposed into low-rank representations. Specifically, the decomposed matrices $U_l$ and $V_l$ of each hidden layer are of size 320$\times$100, while the singular value matrix $\Theta_l$ is 100$\times$100. This corresponds to a fixed rank of 100 across all layers, balancing expressiveness and computational efficiency. The FEH network, responsible for predicting frequency-dependent singular values, consists of three fully connected layers with 80 neurons per layer. 

The meta-training process is conducted for a total of 50000 epochs using an AdamW optimizer \citep{loshchilov2017decoupled}. In each epoch, we sample five support-query task pairs along with their corresponding frequencies from the created 560 tasks (sets of velocity models and frequencies). The inner loop, responsible for task-specific adaptation, uses a learning rate of 2e-3 and performs a single gradient descent step per iteration. The outer loop updates the global initialization parameters with a learning rate of 1e-3, which decayed by a factor of 0.8 every 5000 epochs to ensure convergence. The meta-training phase is conducted on an NVIDIA A100 GPU [80 GB]. The entire training process takes approximately 34 hours. 

\subsection{A layered model}
To demonstrate the effectiveness of our proposed Meta-LRPINN framework, we first evaluate it on a layered velocity model extracted from the Marmousi model. Importantly, this model is not included in the meta-training stage, ensuring a fair assessment of the generalization capability of our method. Figure~\ref{fig2} shows the layered velocity model, which spans a domain of 2.25 km $\times$ 2.25 km. For this test, we leverage the initialization obtained from the meta-training stage to start the meta-testing process. The networks are trained for three frequencies, including 3 Hz, 6 Hz, and 12 Hz, with each frequency corresponding to a separate Meta-LRPINN network. 

To provide meaningful benchmarks, we compare our Meta-LRPINN against two baseline methods: Meta-PINN and vanilla PINN. The Meta-PINN framework also undergoes a meta-training process using the same dataset and configurations described in the previous subsection. For fairness, both vanilla PINN and Meta-PINN employ six hidden layers, identical to the configuration of Meta-LRPINN, while each hidden layer has 320 neurons. During meta-testing of Meta-LRPINN and Meta-PINN and, also, the training of vanilla PINN, we use the same setup, including 40000 randomly sampled spatial points, an initial learning rate of $1e-3$, and the AdamW optimizer. The learning rate is decayed by a factor of 0.5 at 2000th, 4000th, and 8000th epochs. This standard setup is chosen to ensure a fair comparison and to test the general applicability of our Meta-LRPINN framework. 

Figures~\ref{fig3} presents comparisons of physical loss and accuracy curves between our Meta-LRPINN and two benchmarks. Here, the accuracy is calculated using the mean squared error (MSE) between the network-predicted wavefields and the numerical references, where the numerical references are computed using a finite-difference method. In this figure, the physical loss and accuracy curves are shown for 3 Hz (top row), 6 Hz (middle row), and 12 Hz (bottom row), with physical loss on the left and accuracy on the right for each frequency. We can see that our Meta-LRPINN significantly outperforms both Meta-PINN and vanilla PINN in terms of physical loss for 3 Hz and 6 Hz. At 12 Hz, although Meta-LRPINN initially exhibits better performance than Meta-PINN, the loss reduction for Meta-PINN accelerates during later epochs. However, the accuracy curves reveal that our Meta-LRPINN consistently outperforms both benchmarks across all frequencies. Notably, the accuracy of Meta-PINN decreases as training progresses for 12 Hz, suggesting that it converges to a trivial solution or a local minimum, despite the observed loss reduction. 

After training, we evaluate the NN multi-frequencies wavefield representations for the given layered velocity model.  Figures~\ref{fig4}, \ref{fig5}, and \ref{fig6} provide visual comparisons of the real part of the predicted scattered wavefields at 3 Hz, 6 Hz, and 12 Hz, respectively. For brevity, the imaginary parts are omitted here, as well as in the following tests, to avoid redundant presentation. In each figure, panel (a) shows the numerical reference wavefield, while subsequent rows correspond to Meta-LRPINN, Meta-PINN, and vanilla PINN predictions. Each column represents different training epochs, with specific epoch numbers indicated in the top. These figures clearly demonstrate that Meta-LRPINN provides reliable wavefield representations after very limited training epochs, even for higher frequencies. In contrast, neither Meta-PINN nor vanilla PINN produces acceptable prediction results under similar conditions. For instance, Meta-LRPINN achieves near-perfect wavefield representation by the 500th epoch for 3 Hz, while Meta-PINN and vanilla PINN fail to converge to accurate solutions within the tested training epochs. 


\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{Figure/fig2.png}
\caption{The layered velocity model extracted from the Marmousi model.}
\label{fig2}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{Figure/fig3.png}
\caption{Comparison of physical loss and accuracy curves between our Meta-LRPINN (blue), Meta-PINN (orange), and vanilla PINN (yellow) on the layered velocity model. The rows correspond to different frequencies (top: 3 Hz, middle: 6 Hz, bottom: 12 Hz). For each frequency, the left column shows the physical loss curves, and the right column presents the accuracy curves (measured as MSE against the numerical reference).}
\label{fig3}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig4.png}
\caption{Comparison of the real part of the scattered wavefield solutions at 3 Hz for the layered velocity model. (a) Numerical reference solution. Subsequent rows represent wavefields predicted by Meta-LRPINN, Meta-PINN, and vanilla PINN, respectively. Columns correspond to different training epochs, where the specific epoch numbers are indicated in the top.}
\label{fig4}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig5.png}
\caption{Similar with Figure \ref{fig4}, but for the scattered wavefield solutions of 6 Hz.}
\label{fig5}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig6.png}
\caption{Similar with Figure \ref{fig4}, but for the scattered wavefield solutions of 12 Hz.}
\label{fig6}
\end{figure}


\subsection{Overthrust model}
We further evaluate the performance of Meta-LRPINN on the overthrust model, a more complex velocity with uneven dimensions of 4 km $\times$ 10 km, which is usually a challenge for PINNs. A slightly smoothed version of the velocity model is shown in Figure \ref{fig7}. Similar to the layered model experiment, we, here, also consider three frequencies, 3 Hz, 6 Hz, and 12 Hz, and train separate (already meta-trained) Meta-LRPINN networks for each frequency. We compare the results against two benchmarks: Meta-PINN and vanilla PINN. The training configurations for all three methods remain consistent with those used in the layered model experiments. 

Figure \ref{fig8} presents the PDE loss and accuracy curves for the three frequencies, with rows corresponding to 3 Hz, 6 Hz, and 12 Hz, and columns showing the PDE loss (left) and the accuracy (right). The results demonstrate that Meta-LRPINN significantly outperforms both benchmarks at 3 Hz and 6 Hz in terms of convergence speed and accuracy. For 12 Hz, Meta-LRPINN initially shows better performance than Meta-PINN; however, as training progresses, Meta-PINN exhibits faster reductions in loss and accuracy improvements. This suggests that for representing high-frequency wavefields in large models, Meta-LRPINN may require a higher rank to further enhance performance. 

Figures \ref{fig9}, \ref{fig10}, and \ref{fig11} compare the real part of the scattered wavefield solutions for 3 Hz, 6 Hz, and 12 Hz, respectively. Each figure follows the layout used in the layered model experiment: panel (a) displays the numerical reference, and subsequent rows correspond to Meta-LRPINN, Meta-PINN, and vanilla PINN. Columns depict the wavefield solutions at different training epochs, as indicated by the above label. 

From Figure \ref{fig9}, for the 3 Hz wavefield, Meta-LRPINN delivers a wavefield representation closely matching the reference as early as the 1000th epoch. In contrast, Meta-PINN and vanilla PINN struggles to converge, and even at the 4000th epoch, they fail to provide acceptable solutions. In Figure  \ref{fig10}, which shows the 6 Hz wavefield, Meta-LRPINN provides an acceptable wavefield representation by the 2000th epoch and continues to refine it with further training. Meta-PINN requires up to 6000 epochs to achieve a wavefield solution, but its details remain inferior to the solution provided by Meta-LRPINN at the 2000th epoch. Vanilla PINN again fails to produce any meaningful results. For the high-frequency 12 Hz wavefield shown in Figure \ref{fig11}, Meta-LRPINN achieves a moderately reasonable wavefield representation by the 2000th epoch. While Meta-PINN starts to show wavefield features only by the 6000th epoch, its representation lags behind the solution provided by Meta-LRPINN, especially for some details. Vanilla PINN remains incapable of modeling the high-frequency wavefield. However, the Meta-LRPINN overall could not capture the details in the reference wavefield solution. This is mainly because this wavefield is complex and it spans an uneven domain. Note in Figure \ref{fig10}, how well the prediction is for the parts deeper directly below the source, compared to the sides. Some of this limitation could be related to the rank of the weight SVD representation we chose, which will be discussed next.


\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{Figure/fig7.png}
\caption{Overthrust velocity model.}
\label{fig7}
\end{figure}


\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{Figure/fig8.png}
\caption{Comparison of physical loss and accuracy curves between our Meta-LRPINN (blue), Meta-PINN (orange), and vanilla PINN (yellow) on the overthrust model. The rows correspond to different frequencies (top: 3 Hz, middle: 6 Hz, bottom: 12 Hz). For each frequency, the left column shows the physical loss curves, and the right column presents the accuracy curves (measured as MSE against the numerical reference).}
\label{fig8}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig9.png}
\caption{Comparison of the real part of the scattered wavefield solutions at 3 Hz for the overthrust model. (a) Numerical reference solution. Subsequent rows represent wavefields predicted by Meta-LRPINN, Meta-PINN, and vanilla PINN, respectively. Columns correspond to different training epochs, where the specific epoch numbers are indicated in the top.}
\label{fig9}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig10.png}
\caption{Similar with Figure \ref{fig9}, but for the scattered wavefield solutions of 6 Hz.}
\label{fig10}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig11.png}
\caption{Similar with Figure \ref{fig9}, but for the scattered wavefield solutions of 12 Hz.}
\label{fig11}
\end{figure}


\subsection{Rank reduction}
Finally, we evaluate the proposed rank-adaptive reduction strategy. We, here, use the layered velocity model as an example. As described in the Meta-training procedure, the rank for our Meta-LRPINN during meta-training is set to 100. While the results in the layered model test directly apply this configuration without rank reduction, here we explore the effect of reducing the rank during the meta-testing stage. We consider three levels of rank reduction relative to the meta-trained rank of 100: 50\% reduction (rank = 50), 75\% reduction (rank = 25), and 90\% reduction (rank = 10). The objective is to assess the impact of reduced ranks on the physical loss, accuracy, and wavefield representation. We also consider the wavefield representation at 3 Hz, 6 Hz, and 12 Hz, like we did in the layered model test. 

Figure~\ref{fig12} compares the physical loss (left column) and accuracy (right column) curves for the four rank configurations, where each column from top to bottom corresponds to 3, 6, and 12Hz, respectively. From the physical loss curves, we can observe that as the rank decreases, the physical loss increases across all frequencies, with the most significant degradation occurring at the 90\% rank reduction level. The original rank-100 configuration consistently achieves the lowest physical loss, followed by the 50\% and 75\% reductions. Interestingly, at 12 Hz, the physical loss curves for the 50\% and 75\% reductions exhibit convergence speeds and loss values that are very close to the original rank-100 configuration. This suggests that moderate rank reductions retain sufficient capacity to minimize the physical loss even for high-frequency components, although further reductions (e.g., 90\%) introduce noticeable errors. 

The accuracy curves reveal interesting insights. We can see that, at 3 Hz, reducing the rank improves accuracy compared to the original rank-100 configuration. The 75\% reduction (rank = 25) achieves the highest accuracy, surpassing all other configurations, while the 90\% reduction (rank = 10) also performs well, with only a slight drop in accuracy compared to the 75\% reduction. This suggests that adaptively reducing the rank effectively regularizes the model, enhancing generalization for low-frequency wavefields. At 6 Hz, the accuracy curves reveal a two-stage trend: during the initial epochs, the rank-100 configuration exhibits much fast accuracy improvement. However, as training progresses, the 50\% and 75\% reductions surpass the rank-100 configuration. This further indicates that moderate rank reductions retain sufficient representational capacity while reducing overparameterization. However, at 12 Hz, the rank-100 configuration provides the best accuracy, with a clear decline in performance as the rank reduction increases. This is expected, as high-frequency wavefields contain finer details that require more singular values to accurately capture. Nonetheless, the 50\% reduction retains reasonable accuracy at 12 Hz, demonstrating that moderate reductions are still effective for certain high-frequency scenarios. 

Figures~\ref{fig13}, \ref{fig14}, and \ref{fig15} further illustrate the impact of rank reduction on the real part of the scattered wavefields at 3 Hz, 6 Hz, and 12 Hz, respectively. Each figure consists of: Panel (a) corresponds to numerical reference wavefield. Panels (bâ€“m): Predicted wavefields at different epochs (indicated above each column) under the four rank configurations, where each column from top to bottom corresponds to rank = 100, rank = 50 (50\% reduction), rank = 25 (75\% reduction), and rank = 10 (90\% reduction), respectively. 

For the 3 Hz low-frequency wavefield representation, rank reductions of 75\% and 90\% demonstrate the ability to quickly provide more accurate wavefield approximations. By the 200th epoch, the wavefields predicted by the 75\% and 90\% rank reductions are significantly closer to the reference wavefield compared to the original rank-100 and 50\% rank reduction models, with the 90\% reduction producing wavefields that closely match the reference in both phase and amplitude. In contrast, the rank-100 and 50\% reduction models still exhibit noticeable differences from the reference wavefield at this early stage. As training progresses to the 500th epoch, all configurations, including the rank-100 and three rank-reduction models, converge to produce wavefields that visually resemble the reference wavefield, making it difficult to discern any significant differences among them. This suggests that for low frequencies, rank reductions can achieve faster convergence with fewer parameters while still maintaining accuracy. 

At 6 Hz, the wavefield representation exhibits different characteristics. During the initial epochs, such as at the 1000th epoch, the original rank-100 configuration provides wavefields that are closer to the reference, particularly in the deeper regions of the wavefield where details are more prominent. Rank reductions, especially the 90\% reduction, show some limitations in representing these deep wavefield details. These limitations are particularly evident in regions with lower amplitudes, where smaller singular values are responsible for capturing fine-grained information. Removing a significant portion of these singular values in aggressive rank reductions (e.g., 90\%) results in a less detailed representation of the deeper wavefields. However, as training progresses, the rank-100 model and the 50\% and 75\% reductions converge to provide comparable wavefield representations, with all three showing better detail retention in the deeper regions compared to the 90\% reduction model. This highlights that moderate rank reductions are effective for mid-frequency wavefields, but aggressive reductions may compromise fine-detail representation. 

At 12 Hz, the high-frequency wavefield representation highlights the necessity of maintaining higher ranks. The original rank-100 model provides the best match to the reference wavefield throughout the training process, particularly in capturing the intricate details of the high-frequency components. As the rank is reduced, the ability to accurately represent these details decreases, with the 75\% and 90\% reductions exhibiting noticeable wavefield deformation. However, it is important to note that even with significant rank reductions (e.g., 90\%), the degradation in wavefield representation remains relatively mild given the corresponding substantial reduction in model parameters. This suggests that while retaining a higher rank is critical for accurately representing high-frequency wavefields, moderate reductions can still provide acceptable results for applications where computational efficiency is a priority. 

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{Figure/fig12.png}
\caption{Comparison of physical loss and accuracy curves between four rank configurations on the layered velocity model: rank = 100 (blue), 50\% reduction (orange), 75\% reduction (yellow), and 90\% reduction (purple). The rows correspond to different frequencies (top: 3 Hz, middle: 6 Hz, bottom: 12 Hz). For each frequency, the left column shows the physical loss curves, and the right column presents the accuracy curves (measured as MSE against the numerical reference).}
\label{fig12}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig13.png}
\caption{Comparison of the real part of the scattered wavefield solutions at 3 Hz for the layered velocity model (Figure \ref{fig2}), where we use four rank configurations. (a) Numerical reference solution. Subsequent rows represent wavefields predicted by: rank = 100 (blue), 50\% reduction (orange), 75\% reduction (yellow), and 90\% reduction (purple). Columns correspond to different training epochs, where the specific epoch numbers are indicated on the top.}
\label{fig13}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig14.png}
\caption{Similar with Figure \ref{fig13}, but for the scattered wavefield solutions of 6 Hz.}
\label{fig14}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{Figure/fig15.png}
\caption{Similar with Figure \ref{fig13}, but for the scattered wavefield solutions of 12 Hz.}
\label{fig15}
\end{figure}

