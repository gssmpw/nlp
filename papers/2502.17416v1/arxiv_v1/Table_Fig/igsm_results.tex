% \begin{table}[!tbp]
% \centering
% \caption{\looseness-1Accuracy of looped and non-looped models on the i-GSM problem from \Cref{sec:synthetic_reasoning}. Note that a random guessing baseline would get at least 14\% accuracy (since the answer is modulo 7). As we see, a \loopy{k}{L} looped model is significantly better than the iso-param \loopy{k}{1} model and also nearly as good as the non-looped iso-flop \loopy{kL}{1} model.}
% \scalebox{0.8}{
% \begin{tabular}{lc|c}
% \toprule
%  & Params / FLOPs & Accuracy \\
% \midrule
% \midrule
% Base \loopy{8}{1} & 8x / 8x & 73.2 \\
% \hline
% \hline
% \rowcolor{lightgray}
% \multicolumn{3}{c}{1 layer model}  \\
% \hline
% Base \loopy{1}{1} & 1x / 1x &  24.5 \\
% Loop \loopy{1}{2} & 1x / 2x & 52.3\\
% Loop \loopy{1}{4} & 1x / 4x & 69.9\\
% Loop \loopy{1}{8} & 1x / 8x & 73.2\\
% \hline
% \hline
% \rowcolor{lightgray}
% \multicolumn{3}{c}{2 layer model}  \\
% \hline
% Base \loopy{2}{1} & 2x / 2x & 54.0 \\
% Loop \loopy{2}{2} & 2x / 4x & 66.9 \\
% Loop \loopy{2}{4} & 2x / 8x & 73.6 \\
% \hline
% \hline
% \rowcolor{lightgray}
% \multicolumn{3}{c}{4 layer model}  \\
% \hline
% Base \loopy{4}{1} & 4x / 4x & 71.3 \\
% Loop \loopy{4}{2} & 4x / 8x & 71.6 \\
% \hline
% \end{tabular}
% }
% \label{table:igsm-results}
% \end{table}

\begin{table}[t]
    \centering
    \caption{\textbf{Left.} Symbolic i-GSM problem and its solution. \textbf{Right.} Accuracy of looped and non-looped models on the i-GSM task from \Cref{sec:synthetic_reasoning}.  \loopy{k}{L} looped model is significantly better than the iso-param \loopy{k}{1} model and performs as well as non-looped iso-flop \loopy{kL}{1} model.}
    \scalebox{0.8}{
    \begin{minipage}{0.4\textwidth}
        \centering
        \small
        \parbox{\linewidth}{
        \paragraph{Question.} \textit{E\#I := 4. E\#J := E\#I. K\#N := I\#N + J\#O + F\#K. F\#K := E\#J. J\#O := F\#K + K\#O + E\#J. H\#J := E\#J + F\#K. I\#P := L\#M + I\#N + K\#O. I\#M := J\#O + J\#P + F\#K. J\#P := H\#J - F\#K. L\#M := I\#N + J\#P + F\#K. I\#N := 2 * J\#P + H\#J + E\#I. K\#O := J\#P + I\#N + E\#J. I\#P?}\\
        \paragraph{Answer with CoT.} \textit{E\#I = 4. $\implies$ E\#I = 4. E\#J = E\#I. $\implies$ E\#J = 4. F\#K = E\#J. $\implies$ F\#K = 4. H\#J = E\#J+F\#K. $\implies$ H\#J = 1. J\#P = H\#J-F\#K. $\implies$ J\#P = 4. I\#N = 2J\#P+2H\#J+2E\#I. $\implies$ I\#N = 4. L\#M = I\#N+J\#P+F\#K. $\implies$ L\#M = 5. K\#O = J\#P+I\#N+E\#J. $\implies$ K\#O = 5. I\#P = L\#M+I\#N+K\#O. $\implies$ I\#P = 0.}
        }
        % \normalsize
        % \caption{Symbolic i-GSM problem and its solution.}
        \label{fig:sample-eigsm-problem}
    \end{minipage}%
    }
    \hspace{0.5cm}
    \begin{minipage}{0.55\textwidth}
        \centering
        \scalebox{0.8}{
\begin{tabular}{lc|c}
\toprule
 & Params / FLOPs & Accuracy \\
\midrule
\midrule
Base \loopy{8}{1} & 8x / 8x & \textbf{73.2} \\
\hline
\hline
\rowcolor{lightgray}
\multicolumn{3}{c}{1 layer model}  \\
\hline
Base \loopy{1}{1} & 1x / 1x &  24.5 \\
Loop \loopy{1}{2} & 1x / 2x & 52.3\\
Loop \loopy{1}{4} & 1x / 4x & 69.9\\
Loop \loopy{1}{8} & 1x / 8x & \textbf{73.2}\\
\hline
\hline
\rowcolor{lightgray}
\multicolumn{3}{c}{2 layer model}  \\
\hline
Base \loopy{2}{1} & 2x / 2x & 54.0 \\
Loop \loopy{2}{2} & 2x / 4x & 66.9 \\
Loop \loopy{2}{4} & 2x / 8x & \textbf{73.6} \\
\hline
\hline
\rowcolor{lightgray}
\multicolumn{3}{c}{4 layer model}  \\
\hline
Base \loopy{4}{1} & 4x / 4x & 71.3 \\
Loop \loopy{4}{2} & 4x / 8x & \textbf{71.6} \\
\hline
\end{tabular}
}
% \caption{\looseness-1Accuracy of looped and non-looped models on the i-GSM task from \Cref{sec:synthetic_reasoning}. We consistently see that a \loopy{k}{L} looped model is significantly better than the iso-param \loopy{k}{1} model and also nearly as good as the non-looped iso-flop \loopy{kL}{1} model.}
\label{table:igsm-results}
\end{minipage}
\end{table}