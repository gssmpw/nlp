\begin{figure*}[tbp]% [H] is so declass\'e!
\centering
    \hspace{-0.1in}
    \begin{subfigure}{0.33\textwidth}
    \centering    \includegraphics[scale=0.36]{Media/Heatmap.Model_Pile_Baseline_blk4.VariableKind_self_attention.post.w.png}
    \caption{Attn:Q}
    \label{fig:cosines_baseline_attn_q}
    \end{subfigure}\hfill
\centering
    \begin{subfigure}{0.33\textwidth}
    \centering    \includegraphics[scale=0.36]{Media/Heatmap.Model_Pile_Baseline_blk4.VariableKind_ff_layer.ffn_layer1.linear.w.png}
    \caption{FFN:W1}
    \label{fig:cosines_baseline_ffn_w1}
    \end{subfigure}\hfill
\centering
    \begin{subfigure}{0.33\textwidth}
    \centering   
    % width=\textwidth
     \includegraphics[scale=0.36]{Media/Heatmap.Model_Pile_Baseline_blk4.VariableKind_self_attention.post.w.png}
    \caption{Attn:PostNorm}
    \label{fig:cosines_baseline_postnorm}
    \end{subfigure}\hfill
    \caption{\looseness-1Cosine similarities for different layers in the baseline model trained without any regularization strength. Overall the cosine similarities are very low for large matrices, as expected for high dimensions matrices.}
    \label{fig:cosine_similarity}
\end{figure*}


