% \vspace{-2mm}
\section{Experiment}
% \vspace{-2mm}
\subsection{Wi-Chat Dataset}
% \vspace{-2mm}
\input{tables/data}
We conducted experiments using a self-collected Wi-Fi CSI dataset, leveraging commodity Wi-Fi devices, specifically Dell LATITUDE laptops, as both the Wi-Fi transmitter and receivers for data collection. Each Wi-Fi transmitter and receiver is equipped with three antennas. The Wi-Fi channel operated at 5.32 GHz with a bandwidth of 40 MHz, and the packet transmission rate was set to 1000 packets per second. We utilized the Linux 802.11 CSI tool~\cite{halperin2011tool} to extract CSI data from 30 OFDM subcarriers per packet. The dataset comprises over 1,965,000 Wi-Fi CSI packets collected from participants with varying heights, weights, and ages. These packets were segmented into 393 segments, each lasting 5 seconds, during which participants performed one of four activities: walking, falling, breathing, or no event (i.e., an empty environment). The collected data were then converted into both image and text representations, as detailed in Table~\ref{tab:data_stats}. Data collection was conducted across three real-world environments, a bedroom, a kitchen, and a living room, over a two-month period. The study was reviewed and approved by the IRB of the authors' institution.

%\textcolor{red}{add table}

\vspace{-1mm}
\subsection{Baselines}
\vspace{-2mm}
We compare Wi-Chat with the following systems: 

\textbf{Conventional Wi-Fi-based Systems.} These systems follow a multi-step pipeline, including signal denoising, signal transformation, feature extraction, and model construction, as described in Section~\ref{systems}. Specifically, we reproduce two well-known systems:
\textit{1) CARM}~\cite{wang2015understanding}: It utilizes a PCA-based method for signal denoising, applies DWT for feature extraction, and employs a Hidden Markov Model for activity recognition.
\textit{2) E-eyes}~\cite{wang2014eyes}: This system first removes data outliers using a low-pass filter and then builds activity classifiers using Earth Mover's Distance.

\textbf{Machine Learning Models with Raw Signals.} 
We evaluate the performance of machine learning models, including \textit{3) CNN}, \textit{4) RNN}, and \textit{5) SVM}. These models take textual or visual representations of raw Wi-Fi signals as input and are trained in a supervised manner using labeled datasets.

\subsection{Experimental Settings}

For LLMs, we first apply signal smoothing using the Savitzky-Golay filter~\cite{schafer2011savitzky} and then convert the signals into textual or visual representations. When experimenting with the few-shot setting, we pick 4 examples, including one example from each label class. The prompts used for experiments are presented in Appendix~\ref{sec:prompt}.

%For all supervised baselines, the dataset was randomly split into two parts: $70\%$ for training and $30\%$ for testing. Note that we perform the same signal smoothing and convert them into text and images. We train CNN and RNN on an NVIDIA GeForce RTX 4090 GPU. The learning rate of CNN and RNN is set to 0.001 and they both use Adam optimizer and the max Number of Epochs is 30. The batch size is set to 32 during training for both CNN and RNN. For the SVM, we use RBF as the Kernel Type. For CARM and E-eyes systems, we follow their signal processing procedures.
%Performance evaluation was conducted using standard classification metrics, including Accuracy, Precision, Recall, and F1 Score. Savitzky-Golay filter~\cite{ren2021winect}

For all supervised baselines, we randomly split the dataset into $70\%$ for training and $30\%$ for testing to ensure fair evaluation. Prior to model training, we apply the same signal smoothing techniques and convert the signals into textual and visual representations for consistency across methods. The CNN and RNN models are trained on an NVIDIA GeForce RTX 4090 GPU with a learning rate of 0.001 using the Adam optimizer, with a maximum of 30 epochs and a batch size of 32. For the SVM model, we use the Radial Basis Function as the kernel type. For CARM and E-eyes, we follow their original signal processing pipelines, including denoising, feature extraction, and model construction as described in their respective works. 
Zero-shot evaluations for CNN, RNN, SVM, and conventional systems are also conducted using the same approaches, but with untrained models to test their zero-shot performance. Performance evaluation is conducted using standard classification metrics, including accuracy, precision, recall, and F1 score, to assess the ability of each system to recognize human activities from Wi-Fi CSI data.

\vspace{-2mm}
\input{tables/summary}

\subsection{Results}
\vspace{-2mm}


\textbf{Overall Results.} Table~\ref{summary} presents the best-performing models across different method categories. In the zero-shot category, the best model GPT-4o model achieved an accuracy of 0.62, demonstrating its ability to generalize effectively without task-specific examples. In the 4-shot category, GPT-4o is still the best model, exhibiting substantial improvement, attaining an accuracy of 0.77. This result highlights the effectiveness of in-context learning, where additional prompt examples help refine model predictions.

In the vision models category, the GPT-4o-mini with CoT demonstrated the strongest performance with an accuracy of 0.90. This result indicates the model's capacity to integrate visual and textual reasoning through CoT prompting, which likely aids in complex decision-making.

For supervised learning, the E-eyes (with complex signal processing techniques) outperformed all other models. This result is expected, as supervised models are explicitly trained on labeled data, allowing them to learn precise decision boundaries. However, despite the high accuracy, supervised methods typically require extensive labeled datasets, which may not always be feasible in real-world applications.

\input{tables/present_result}
Overall, the results indicate that LLMs exhibit strong performance in zero-shot and few-shot settings for the task of Wi-Fi-based human activity recognition, making them valuable for scenarios with limited annotated data. Additionally, the impressive accuracy of the vision-language model suggests promising directions for integrating multimodal learning into the task.

% \input{tables/result}

\textbf{Methods Comparison.}
Table~\ref{present} summarizes the classification results across different methods. In the zero-shot setting, traditional machine learning models such as SVM, CNN, and RNN demonstrate relatively low classification performance. LLM models GPT-4o achieved an accuracy of 0.61, significantly outperforming traditional machine learning models. The ICL approach further improved performance, demonstrating the benefits of in-context learning.


Furthermore, GPT-4o-mini combined with CoT reasoning achieves the highest accuracy among zero-shot methods at 0.90, demonstrating the effectiveness of advanced prompting techniques in enhancing LLM-based classification performance. Notably, this performance is already comparable to conventional Wi-Fi activity recognition systems and machine learning models trained in supervised settings. These results reaffirm that while supervised models achieve superior performance with labeled data, LLMs exhibit strong generalization capabilities, particularly when leveraging few-shot learning and vision-language integration.



\subsection{Analysis}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.49\textwidth]{figures/bar.png}
    %\vspace{-8mm}
    \caption{Comparison of COT and knowledge}
   % \vspace{-3mm}
    \label{bar}
\end{figure}


\textbf{Effectiveness of CoT and Domain Knowledge.}
Figure~\ref{bar} illustrates the impact of CoT reasoning and domain knowledge on different language models across time series and vision-based settings. Among the zero-shot models, GPT-4o-mini demonstrates notable improvements when domain knowledge is incorporated, highlighting the benefits of integrating prior knowledge into the inference process. However, a substantial performance drop is observed in both models when CoT reasoning is applied to time series data. We argue that this decline stems from the inherent complexity of time series signals, particularly in the case of Wi-Fi raw signals, which are challenging to interpret directly. The step-by-step reasoning introduced by CoT may inadvertently add confusion, as the model struggles to generate coherent intermediate steps for highly dynamic and noisy input sequences.  

For vision-enhanced models, the GPT-4o-mini-Vision variant achieves the highest performance, with CoT prompting yielding an accuracy of 0.90. This suggests that CoT reasoning is particularly effective when paired with visual input, likely because images provide additional context that facilitates structured reasoning. A similar, albeit less pronounced, effect is observed for GPT-4o-Vision. These results indicate that while CoT reasoning can be beneficial, its effectiveness varies depending on the specific vision-language model and its alignment with the task. The structured nature of visual input may better support multi-step reasoning, whereas time series data lacks the same level of interpretability, limiting the effectiveness of CoT in those scenarios.  

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.49\textwidth]{figures/box.png}
    %\vspace{-8mm}
    \caption{Comparison of LLMs under zero-shot settings}
    %\vspace{-3mm}
    \label{box}
\end{figure}

\textbf{Comparing Different LLMs.} Figure~\ref{box} presents the accuracy distribution of different LLM variants (Base, CoT, and Knowledge) under zero-shot settings. The box plots illustrate the variability in accuracy across models, with GPT-4o and DeepSeek demonstrating the highest median performance, while Mistral and LLaMA exhibit greater variance and lower median accuracy.

Among the models, GPT-4o-mini and DeepSeek show a more stable accuracy distribution, indicating consistent performance across different variants. In contrast, LLaMA has a wider spread, suggesting that its performance is more sensitive to the specific reasoning approach used. Gemma2 maintains a relatively narrow distribution, indicating lower variance but also a more limited improvement potential.

These results highlight that larger models like GPT-4o benefiting from more robust reasoning capabilities, while smaller models show varying degrees of improvement depending on the applied enhancements.

