\section{Algorithm} \label{app:algo}

\begin{algorithm}
\caption{Training algorithm for the adversarial dependence minimization}
\label{alg:adversarialgame}
\begin{algorithmic}[1]
\For {number of training iterations}
    \For {k steps}
        \State Sample a minibatch of n examples $\{\vx^{(1)}, \vx^{(2)}, \dots, \vx^{(n)}\}$ from the dataset
        \State Compute the representations from the encoder $\vz^{(i)} = f_{\vtheta}(\vx^{(i)})$ for every sample i
        \State Compute $\mu_{j} = \frac{1}{n} \sum_{i=1}^n z^{(i)}_j$ and $\sigma_{j} = \frac{1}{n-1} \sum_{i=1}^n (z^{(i)}_j - \mu_{j})^2$ for every dimension j
        \State Standardize the representations $z^{(i)}_{j} \gets \frac{z^{(i)}_{j} - \mu_{j}}{\sigma_{j}}$
        \State Reconstruct the embedding dimensions $\hat{z}^{(i)}_j = h_{\vphi_j}(z^{(i)}_1, \dots, z^{(i)}_{j-1}, z^{(i)}_{j+1}, \dots, z^{(i)}_{d})$ for every dimension j and every sample i
        \State Update the dependency predictors by gradient descent $\nabla_{\vphi} \frac{1}{n} \sum_{i=1}^n \lVert \vz^{(i)} - \hat{\vz}^{(i)} \rVert_2^2$
    \EndFor
    \State Sample a minibatch of n examples $\{\vx^{(1)}, \vx^{(2)}, \dots, \vx^{(n)}\}$ from the dataset
    \State Compute the representations from the encoder $\vz^{(i)} = f_{\vtheta}(\vx^{(i)})$ for every sample i
    \State Compute $\mu_{j} = \frac{1}{n} \sum_{i=1}^n z^{(i)}_j$ and $\sigma_{j} = \frac{1}{n-1} \sum_{i=1}^n (z^{(i)}_j - \mu_{j})^2$ for every dimension j
    \State Standardize the representations $z^{(i)}_{j} \gets \frac{z^{(i)}_{j} - \mu_{j}}{\sigma_{j}}$
    \State Reconstruct the embedding dimensions $\hat{z}^{(i)}_j = h_{\vphi_j}(z^{(i)}_1, \dots, z^{(i)}_{j-1}, z^{(i)}_{j+1}, \dots, z^{(i)}_{d})$ for every dimension j and every sample i
    \State Update the encoder by gradient descent $\nabla_{\vtheta} 1 - \frac{1}{n} \sum_{i=1}^n \lVert \vz^{(i)} - \hat{\vz}^{(i)} \rVert_2^2$
\EndFor
\end{algorithmic}
\end{algorithm}
