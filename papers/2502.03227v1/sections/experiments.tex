Our experimental evaluation aims to: assess the convergence of the algorithm, 
demonstrate the potential of the supervised and SSL applications on synthetic data, 
and study the SSL method on real-world data. 

\begin{figure} %
    \centering %
    \begin{subfigure}{0.495\columnwidth}
        \def\svgwidth{\textwidth}
        {\tiny \input{TIN_convergence_loss.pdf_tex}}
        %\includesvg[pretex=\tiny,width=\textwidth]{TIN_convergence_loss.svg}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.495\columnwidth}
        \def\svgwidth{\textwidth}
        {\tiny \input{TIN_convergence_corr.pdf_tex}}
        %\includesvg[pretex=\tiny,width=\textwidth]{TIN_convergence_corr.svg}
    \end{subfigure}%
    \vspace{-8px}
    \caption{Convergence analysis on TinyImageNet for linear and non-linear \textit{dependency predictors}. \textbf{Left:} the reconstruction MSE converges to one. \textbf{Right:} logarithmic plot of the average absolute value of the Pearson correlation\protect\footnotemark~on the validation set: correlation decreases over time.}
    \label{fig:TIN_convergence}  %
\end{figure}
\footnotetext{Due to computational constraints, we use Pearson correlation instead of distance correlation for tracking training dynamics.}


\subsection{Convergence} \label{sec:results_convergence}

This section analyzes the convergence of the adversarial game with standardized representations. 
Specifically, we trained a ResNet-18~\citep{he2016resnet} on the TinyImageNet dataset~\citep{le2015tinyimagenet} without data augmentations. 
Both linear and two-layer dependency models were tested. 
We additionally trained a ResNet-18 encoder and two-layer \textit{dependency predictors} on the ImageNet dataset~\citep{deng2009imagenet} with data augmentations. Detailed experimental setups are provided in Appendix~\ref{subapp:setup_convergence}.

\paragraph{Metrics.} We reported the average of the absolute value of the Pearson correlation between all pairs of embedding dimensions over time. 
Additionally, we estimated non-linear dependences with the distance correlation between one dimension and the random vector composed of the remaining $d-1$ dimensions. We reported the value averaged over the estimates from the $d$ dimensions. 

\paragraph{Results.} The MSE and Pearson correlation for the TinyImageNet experiments are reported in Figure~\ref{fig:TIN_convergence}. 
The methods trained with linear and non-linear \textit{dependency predictors} both converge to low Pearson correlation coefficients of respectively 0.0107 and 0.0088, and the reconstruction error converges to a value of one for both dependency networks. 
We further estimate the distance correlation: the approach with non-linear \textit{dependency predictors} reached a lower squared distance correlation than the linear variant, with average values of $5.7 \times 10^{-4}$ and $2.9 \times 10^{-3}$ respectively. 
On the larger ImageNet dataset, the MSE again converges to one and the final squared distance correlation is only $2.1 \times 10^{-4}$. 
These results support the convergence hypothesis. 

\subsection{Redundancy Minimization on Synthetic Data} \label{sec:results_infomax}

This section investigates the impact of our algorithm on redundancy reduction in two different applications: classification and self-supervised learning. 
To ease the analysis of the representations, both methods were trained on a synthetic dataset for which the latent factors are known. 

\paragraph{Clevr-4 dataset.} The Clevr-4~\citep{vaze2024clevr4} dataset is an extension of the CLEVR dataset~\citep{johnson2017clevr}. 
It comprises 100,000 synthetic images representing 3D objects of various shapes, colors, textures, and counts. Each taxonomy has 10 classes. 
The label for one taxonomy is sampled uniformly and independently from the others, which means that knowing the label for one taxonomy provides no information about the other taxonomies. 

\paragraph{Evaluation protocols.} We investigated generalization capabilities by training a classifier on one taxonomy (\textit{shape}) and evaluating its accuracy on the remaining taxonomies to assess if representations encode features beyond the ones relevant to the training classes. The model is compared with a baseline classifier trained without the adversarial objective. 
We evaluate the accuracy with a simple weighted-nearest neighbor (kNN) classifier trained on top of frozen features following common practice in SSL~\citep{wu2018unsupervised, caron2021DINO_ssl}. 
The kNN algorithm classifies predictions based on the majority class of their nearest neighbors in the embedding space, providing an easy way to assess the clustering quality for every taxonomy. 
Similarly, the SSL approach is evaluated with a kNN classifier on the four taxonomies.

\paragraph{Implementation details.} Both the supervised and SSL models are trained for 200 epochs. We apply two data augmentations during training: random horizontal flipping and random cropping by keeping at least 60\% of the image area, then resizing to 224 $\times$ 224 pixels. 
We train ResNet-18 encoders and two-layer \textit{dependency predictors}. The networks are trained alternately, with one step for each network per iteration. We set the loss coefficient in both settings to $\lambda = 5$. More details are provided in Appendix~\ref{subapp:setup_clevr4}. 
We trained the adversarial networks of the classification and SSL models with respectively an l1 reconstruction loss with a margin of $\alpha = 0.4$ and an MSE reconstruction loss on the standardized representations. 
The two problem formulations are further discussed and compared in Appendix~\ref{subapp:redundancy_analysis}. 

\begin{table*}
    \small
    \centering
    \caption{kNN evaluation on the Clevr-4 dataset for two different tasks: classification and self-supervised learning. 
    On classification, our method generalizes beyond the training taxonomy. It also learns strong representations when combined with invariance to data augmentations. }
    \label{tab:results_clevr4_infomax}
    \vskip 0.15in
    \begin{tabular}{l rrrr r} %
    \toprule
        \multirow{2}{*}{method} & \multicolumn{4}{c}{kNN top-1 accuracy [\%]} & \multirow{2}{*}{mean $\mathcal{R}^2$}  \\ %
         & shape & texture & color & count & \\   %
    \midrule
        \multicolumn{6}{c}
        {\textit{supervised classification (with shape labels)}} \\
        cross-entropy (baseline)         & \textbf{100.0} & 25.0 & 16.4 & 36.1 &  0.409 \\ %
        \rowcolor{lightgray}
        cross-entropy + ADMin (ours)    & \textbf{100.0} & \textbf{83.7} & \textbf{100.0} & \textbf{39.6} &  0.067 \\ %
    \midrule
        \multicolumn{6}{c}{\textit{self-supervised learning (no labels)}} \\ %
        invariance + "push" (SimCLR)       & 58.8 & 50.3 & 91.6 & 28.4 & 0.029  \\
        invariance + cov. + var. (VICReg) & 93.1 & \textbf{89.2} & 99.5 & 27.5 & 0.035 \\
        \rowcolor{lightgray}
        invariance + ADMin (ours)     & \textbf{93.8} & 88.5 & \textbf{100.0} & \textbf{30.6} & 0.081 \\ 
    \bottomrule
    \end{tabular}
\end{table*}
\paragraph{Results on classification.}
We first compared our regularized classifier to the baseline classifier. Table~\ref{tab:results_clevr4_infomax} (top part) reports the validation accuracy and feature correlation. 
The embedding dimensions of the baseline are highly correlated, with an average squared distance correlation of 0.409. Furthermore, the performance on the taxonomies for which the model received no supervision is low, which was expected since the model was not incentivized to retain information about the remaining taxonomies. 
When combining the cross-entropy loss with our adversarial objective, the correlation drops to 0.067 and the accuracy on the \textit{texture} and \textit{color} taxonomies rises significantly. 
These results suggest that the adversarial objective reduces redundancy, leading to representations that generalize better. 

\paragraph{Results on SSL.}
We then compared the SSL approach to two popular frameworks: SimCLR~\citep{chen2020SimCLR_ssl} and VICReg~\citep{bardes2021vicreg_ssl}. 
We re-implemented and extensively tuned the two models. We considered variants with and without projection heads. A detailed description of the hyper-parameters tuning is provided in Appendix~\ref{app:clevr4_baselines} and the best-performing models are reported in Table~\ref{tab:results_clevr4_infomax} (bottom part). 
Without the labels from the \textit{shape} taxonomy, our approach still learns rich representations according to the high accuracy on \textit{shape}, \textit{texture}, and \textit{color}. 
The linear decorrelation method (VICReg) performs similarly, while the contrastive learning method (SimCLR) performs much worse. 
These results suggest that decorrelation is an effective approach to SSL and that, in this simple setting, linear decorrelation on high-dimensional representations ($d=512$) is sufficient for achieving high accuracy. 

\begin{table}[t]
            
    \small
    \centering
    \caption{Linear evaluation of SSL techniques trained with a ResNet-50 backbone on the ImageNet-1k dataset.}
    \label{tab:results_imagenet_ssl}
    \vskip 0.15in
    \begin{tabular}{lr}
    \toprule
        method  & acc. [\%] \\
    \midrule
        MoCo \citep{he2020MoCo_ssl}                 & 60.6  \\
        SimCLR \citep{chen2020SimCLR_ssl}           & 69.3  \\
        Barlow Twins \citep{zbontar2021barlow_ssl}  & 73.2  \\
        VICReg \citep{bardes2021vicreg_ssl}         & 73.2  \\
        BYOL \citep{grill2020BYOL_ssl}              & 74.3  \\
        DINO \citep{caron2021DINO_ssl}              & 75.3  \\
        RELICv2 \citep{tomasev2022pushing_ssl}      & 77.1 \\
        \rowcolor{lightgray}
        Ours                                        & 63.2 \\
    \bottomrule
    \end{tabular}
    \vskip -0.1in
\end{table}

\subsection{Validation of the SSL approach on ImageNet} \label{sec:results_imagenet}

We then investigated if our method still learns useful representations when the training data distribution does not exhibit independence among its underlying latent factors\footnote{Take for instance the concepts of road and car. While the concepts are distinct, they are likely to often co-appear in the dataset and are therefore correlated.}. %

\paragraph{ImageNet dataset.} We trained our SSL technique on the Imagenet-1k dataset~\citep{deng2009imagenet}, a standard benchmark dataset for SSL. It contains 1,281,167 training images across 1000 classes. This dataset provides a diverse image collection for evaluating our method on real-world data. 

\paragraph{Implementation and evaluation.} We trained a ResNet-50 backbone with a three-layer projection head with output dimension 512, and two-layer \textit{dependency predictors} on the standardized representations. 
At evaluation, the projection head is discarded and the representations' quality is evaluated by training a linear classifier on top of the backbone with frozen weights. 
The detailed experimental setup is described in Appendix~\ref{subapp:setup_imagenet_ssl}. 

\paragraph{Results and discussion.} The main SSL techniques are compared in Table~\ref{tab:results_imagenet_ssl}. 
After 100 epochs, the average squared distance correlation of our method is 0.015, which demonstrates the algorithm successfully prevented dimensional collapse~\citep{jing2021understand_ssl_dim_collapse}. 
Furthermore, the approach reaches a reasonably high accuracy, suggesting that it can be used even on real-world data (see Appendix~\ref{app:visualization} for a qualitative evaluation). %
However, its performance lags behind state-of-the-art approaches. This gap may be attributed to the fact that most gains in current techniques stem from inductive biases induced by the invariance to carefully designed data augmentations. Our strong nonlinear and mutual dependence minimization term might force the model to compromise when jointly optimizing both objectives~\citep{li2019pairwise_ssl}. 
Future work could investigate alternatives to invariance that would better leverage our algorithm's ability to reduce all dependencies/redundancies. 

