We begin by defining the notion of statistical independence, before highlighting two shortcomings of current methods. %

Let ${\rx_1, \ldots, \rx_d}$ be a finite set of random variables. These variables are mutually independent if and only if: 
\begin{equation}
F_{\rx_1, \dots, \rx_d}(x_1, \dots, x_d) = \prod_{i=1}^d F_{\rx_i}(x_i) \quad \forall x_1, \dots, x_d \in \mathbb{R}
\end{equation}
where $F_{\rx_1, \dots, \rx_d}$ is the joint cumulative distribution function and $F_{\rx_i}$ are the marginal cumulative distribution functions. 
Similarly, two continuous random variables $\rx_1$ and $\rx_2$ are pairwise independent if and only if their joint cumulative distribution function is equal to the product of their cumulative distribution functions. 
It is worth highlighting that random variables can all be pairwise independent without being mutually independent~\citep{driscoll1978pairwise_mutual_indep_example}. We refer to Appendix~\ref{subapp:pairwise_vs_mutual_ex} for an example. 

The statistical dependence between two random variables can be measured by correlation. The term generally refers to Pearson's correlation coefficient, which captures the degree of linear dependence between a pair of random variables. 
However, it fails to capture non-linear dependencies; thus, a zero correlation does not imply independence. 

\textbf{Therefore, one must consider mutual and non-linear dependencies when designing an algorithm to minimize redundancy among feature dimensions. }

Finally, a metric is required to estimate correlations beyond linearity. 
Distance correlation~\citep{szekely2007_dcorr} is a non-negative coefficient that characterizes both linear and nonlinear correlations between random vectors by measuring the distance between their joint characteristic function and the product of the marginal characteristic functions. For more details, see Appendix~\ref{subapp:dcorr_details}. 
Of particular interest, the distance correlation is zero $\mathcal{R}(\rx_1, \rx_2) = 0$ if and only if $\rx_1$ and $\rx_2$ are independent. Returning to Example~\ref{example:uncorrelated_but_dependent}, we find a nonzero distance correlation between the random variables: $\mathcal{R}(\rx_1, \rx_2) = \sqrt{1/2}$. 
