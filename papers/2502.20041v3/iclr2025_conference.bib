@article{matheson2019human,
  title={Human--robot collaboration in manufacturing applications: A review},
  author={Matheson, Eloise and Minto, Riccardo and Zampieri, Emanuele GG and Faccio, Maurizio and Rosati, Giulio},
  journal={Robotics},
  volume={8},
  number={4},
  pages={100},
  year={2019},
  publisher={MDPI}
}
@inproceedings{hou2021affordance,
  title={Affordance transfer learning for human-object interaction detection},
  author={Hou, Zhi and Yu, Baosheng and Qiao, Yu and Peng, Xiaojiang and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={495--504},
  year={2021}
}
@article{roy2021action,
  title={Action anticipation using pairwise human-object interactions and transformers},
  author={Roy, Debaditya and Fernando, Basura},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={8116--8129},
  year={2021},
  publisher={IEEE}
}
@inproceedings{chen2023affordance,
  title={Affordance grounding from demonstration video to target image},
  author={Chen, Joya and Gao, Difei and Lin, Kevin Qinghong and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6799--6808},
  year={2023}
}
@inproceedings{li2023locate,
  title={Locate: Localize and transfer object parts for weakly supervised affordance grounding},
  author={Li, Gen and Jampani, Varun and Sun, Deqing and Sevilla-Lara, Laura},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10922--10931},
  year={2023}
}
@article{min2016affordance,
  title={Affordance research in developmental robotics: A survey},
  author={Min, Huaqing and Luo, Ronghua and Zhu, Jinhui and Bi, Sheng and others},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={8},
  number={4},
  pages={237--255},
  year={2016},
  publisher={IEEE}
}
@article{liu2019deep,
  title={Deep learning on point clouds and its application: A survey},
  author={Liu, Weiping and Sun, Jia and Li, Wanyi and Hu, Ting and Wang, Peng},
  journal={Sensors},
  volume={19},
  number={19},
  pages={4188},
  year={2019},
  publisher={MDPI}
}
@article{AshishVaswani16,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
journal = {NeurIPS},
pages = {},
title = {Attention Is All You Need},
volume = {30},
year = {2017}
}
@inproceedings{lai2024lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9579--9589},
  year={2024}
}
@article{hong20233d,
  title={3d-llm: Injecting the 3d world into large language models},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20482--20494},
  year={2023}
}
@article{qi2024shapellm,
  title={Shapellm: Universal 3d object understanding for embodied interaction},
  author={Qi, Zekun and Dong, Runpei and Zhang, Shaochen and Geng, Haoran and Han, Chunrui and Ge, Zheng and Yi, Li and Ma, Kaisheng},
  journal={arXiv preprint arXiv:2402.17766},
  year={2024}
}
@InProceedings{Mo_2019_CVPRPartnet,
    author = {Mo, Kaichun and Zhu, Shilin and Chang, Angel X. and Yi, Li and Tripathi, Subarna and Guibas, Leonidas J. and Su, Hao},
    title = {{PartNet}: A Large-Scale Benchmark for Fine-Grained and Hierarchical Part-Level {3D} Object Understanding},
    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2019}
}
@inproceedings{deng20213daffordancenet,
  title={3d affordancenet: A benchmark for visual object affordance understanding},
  author={Deng, Shengheng and Xu, Xun and Wu, Chaozheng and Chen, Ke and Jia, Kui},
  booktitle={proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1778--1787},
  year={2021}
}
@inproceedings{nguyen2023open,
  title={Open-vocabulary affordance detection in 3d point clouds},
  author={Nguyen, Toan and Vu, Minh Nhat and Vuong, An and Nguyen, Dzung and Vo, Thieu and Le, Ngan and Nguyen, Anh},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5692--5698},
  year={2023},
  organization={IEEE}
}
@book{Gibson1966-GIBTSC-5,
	address = {Boston, USA},
	author = {James Jerome Gibson},
	editor = {},
	publisher = {Houghton Mifflin},
	title = {The Senses Considered as Perceptual Systems},
	year = {1966}
}
@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}
@inproceedings{nguyen2016detecting,
  title={Detecting object affordances with convolutional neural networks},
  author={Nguyen, Anh and Kanoulas, Dimitrios and Caldwell, Darwin G and Tsagarakis, Nikos G},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2765--2770},
  year={2016},
  organization={IEEE}
}
@inproceedings{do2018affordancenet,
  title={Affordancenet: An end-to-end deep learning approach for object affordance detection},
  author={Do, Thanh-Toan and Nguyen, Anh and Reid, Ian},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={5882--5889},
  year={2018},
  organization={IEEE}
}
@inproceedings{pacheco2022one,
  title={One-shot learning for human affordance detection},
  author={Pacheco-Ortega, Abel and Mayol-Cuervas, Walterio},
  booktitle={European Conference on Computer Vision},
  pages={758--766},
  year={2022},
  organization={Springer}
}
@inproceedings{mo2022o2o,
  title={O2o-afford: Annotation-free large-scale object-object affordance learning},
  author={Mo, Kaichun and Qin, Yuzhe and Xiang, Fanbo and Su, Hao and Guibas, Leonidas},
  booktitle={Conference on robot learning},
  pages={1666--1677},
  year={2022},
  organization={PMLR}
}
@inproceedings{geng2023rlafford,
  title={Rlafford: End-to-end affordance learning for robotic manipulation},
  author={Geng, Yiran and An, Boshi and Geng, Haoran and Chen, Yuanpei and Yang, Yaodong and Dong, Hao},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5880--5886},
  year={2023},
  organization={IEEE}
}
@inproceedings{moldovan2012learning,
  title={Learning relational affordance models for robots in multi-object manipulation tasks},
  author={Moldovan, Bogdan and Moreno, Plinio and Van Otterlo, Martijn and Santos-Victor, Jos{\'e} and De Raedt, Luc},
  booktitle={2012 ieee International Conference on Robotics and Automation},
  pages={4373--4378},
  year={2012},
  organization={IEEE}
}
@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}
@inproceedings{yu2022pointbert,
  title={Point-bert: Pre-training 3d point cloud transformers with masked point modeling},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19313--19322},
  year={2022}
}
@inproceedings{xue2024ulip2,
  title={Ulip-2: Towards scalable multimodal pre-training for 3d understanding},
  author={Xue, Le and Yu, Ning and Zhang, Shu and Panagopoulou, Artemis and Li, Junnan and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27091--27101},
  year={2024}
}
@inproceedings{deitke2023objaverse,
  title={Objaverse: A universe of annotated 3d objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13142--13153},
  year={2023}
}
@inproceedings{vishwanath2009modelnet,
  title={Modelnet: Towards a datacenter emulation environment},
  author={Vishwanath, Kashi Venkatesh and Gupta, Diwaker and Vahdat, Amin and Yocum, Ken},
  booktitle={2009 IEEE Ninth International Conference on Peer-to-Peer Computing},
  pages={81--82},
  year={2009},
  organization={IEEE}
}
@inproceedings{li2024laso,
  title={LASO: Language-guided Affordance Segmentation on 3D Object},
  author={Li, Yicong and Zhao, Na and Xiao, Junbin and Feng, Chun and Wang, Xiang and Chua, Tat-seng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14251--14260},
  year={2024}
}
@inproceedings{cheraghian2020TZSLPC,
  title={Transductive zero-shot learning for 3d point cloud classification},
  author={Cheraghian, Ali and Rahman, Shafin and Campbell, Dylan and Petersson, Lars},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={923--933},
  year={2020}
}
@inproceedings{michele20213DGenZ,
  title={Generative zero-shot learning for semantic segmentation of 3d point clouds},
  author={Michele, Bj{\"o}rn and Boulch, Alexandre and Puy, Gilles and Bucher, Maxime and Marlet, Renaud},
  booktitle={2021 International Conference on 3D Vision (3DV)},
  pages={992--1002},
  year={2021},
  organization={IEEE}
}
@inproceedings{cheraghian2019ZSLPC,
  title={Zero-shot learning of 3d point cloud objects},
  author={Cheraghian, Ali and Rahman, Shafin and Petersson, Lars},
  booktitle={2019 16th International Conference on Machine Vision Applications (MVA)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}
@inproceedings{yang2023IAGNet,
  title={Grounding 3d object affordance from 2d interactions in images},
  author={Yang, Yuhang and Zhai, Wei and Luo, Hongchen and Cao, Yang and Luo, Jiebo and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10905--10915},
  year={2023}
}
@inproceedings{jian2023affordpose,
  title={Affordpose: A large-scale dataset of hand-object interactions with affordance-driven hand pose},
  author={Jian, Juntao and Liu, Xiuping and Li, Manyi and Hu, Ruizhen and Liu, Jian},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14713--14724},
  year={2023}
}
@article{zhou2023uni3d,
  title={Uni3d: Exploring unified 3d representation at scale},
  author={Zhou, Junsheng and Wang, Jinsheng and Ma, Baorui and Liu, Yu-Shen and Huang, Tiejun and Wang, Xinlong},
  journal={arXiv preprint arXiv:2310.06773},
  year={2023}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{lu2022phrase,
  title={Phrase-based affordance detection via cyclic bilateral interaction},
  author={Lu, Liangsheng and Zhai, Wei and Luo, Hongchen and Kang, Yu and Cao, Yang},
  journal={IEEE Transactions on Artificial Intelligence},
  volume={4},
  number={5},
  pages={1186--1198},
  year={2022},
  publisher={IEEE}
}
@article{mi2020intention,
  title={Intention-related natural language grounding via object affordance detection and intention semantic extraction},
  author={Mi, Jinpeng and Liang, Hongzhuo and Katsakis, Nikolaos and Tang, Song and Li, Qingdu and Zhang, Changshui and Zhang, Jianwei},
  journal={Frontiers in Neurorobotics},
  volume={14},
  pages={26},
  year={2020},
  publisher={Frontiers Media SA}
}
@inproceedings{luo2022learning,
  title={Learning affordance grounding from exocentric images},
  author={Luo, Hongchen and Zhai, Wei and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2252--2261},
  year={2022}
}
@inproceedings{nagarajan2019grounded,
  title={Grounded human-object interaction hotspots from video},
  author={Nagarajan, Tushar and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8688--8697},
  year={2019}
}
@inproceedings{xue2023ulip,
  title={Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1179--1189},
  year={2023}
}
@article{wang2023chat3d,
  title={Chat-3d: Data-efficiently tuning large language model for universal dialogue of 3d scenes},
  author={Wang, Zehan and Huang, Haifeng and Zhao, Yang and Zhang, Ziang and Zhao, Zhou},
  journal={arXiv preprint arXiv:2308.08769},
  year={2023}
}
@inproceedings{chen2024ll3da,
  title={LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding Reasoning and Planning},
  author={Chen, Sijin and Chen, Xin and Zhang, Chi and Li, Mingsheng and Yu, Gang and Fei, Hao and Zhu, Hongyuan and Fan, Jiayuan and Chen, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26428--26438},
  year={2024}
}
@article{huang2023chat3dv2,
  title={Chat-3d v2: Bridging 3d scene and large language models with object identifiers},
  author={Huang, Haifeng and Wang, Zehan and Huang, Rongjie and Liu, Luping and Cheng, Xize and Zhao, Yang and Jin, Tao and Zhao, Zhou},
  journal={arXiv preprint arXiv:2312.08168},
  year={2023}
}
@article{hong20233dllm,
  title={3d-llm: Injecting the 3d world into large language models},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20482--20494},
  year={2023}
}
@inproceedings{radford2021cliplearning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{zhao2021point_transformer,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16259--16268},
  year={2021}
}
@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={ACM Transactions on Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={Acm New York, NY, USA}
}