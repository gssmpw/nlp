@inproceedings{chen2023affordance,
  title={Affordance grounding from demonstration video to target image},
  author={Chen, Joya and Gao, Difei and Lin, Kevin Qinghong and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6799--6808},
  year={2023}
}

@inproceedings{chen2024ll3da,
  title={LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding Reasoning and Planning},
  author={Chen, Sijin and Chen, Xin and Zhang, Chi and Li, Mingsheng and Yu, Gang and Fei, Hao and Zhu, Hongyuan and Fan, Jiayuan and Chen, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26428--26438},
  year={2024}
}

@inproceedings{deitke2023objaverse,
  title={Objaverse: A universe of annotated 3d objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13142--13153},
  year={2023}
}

@inproceedings{deng20213daffordancenet,
  title={3d affordancenet: A benchmark for visual object affordance understanding},
  author={Deng, Shengheng and Xu, Xun and Wu, Chaozheng and Chen, Ke and Jia, Kui},
  booktitle={proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1778--1787},
  year={2021}
}

@inproceedings{do2018affordancenet,
  title={Affordancenet: An end-to-end deep learning approach for object affordance detection},
  author={Do, Thanh-Toan and Nguyen, Anh and Reid, Ian},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={5882--5889},
  year={2018},
  organization={IEEE}
}

@article{hong20233dllm,
  title={3d-llm: Injecting the 3d world into large language models},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20482--20494},
  year={2023}
}

@article{huang2023chat3dv2,
  title={Chat-3d v2: Bridging 3d scene and large language models with object identifiers},
  author={Huang, Haifeng and Wang, Zehan and Huang, Rongjie and Liu, Luping and Cheng, Xize and Zhao, Yang and Jin, Tao and Zhao, Zhou},
  journal={arXiv preprint arXiv:2312.08168},
  year={2023}
}

@inproceedings{li2023locate,
  title={Locate: Localize and transfer object parts for weakly supervised affordance grounding},
  author={Li, Gen and Jampani, Varun and Sun, Deqing and Sevilla-Lara, Laura},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10922--10931},
  year={2023}
}

@article{lu2022phrase,
  title={Phrase-based affordance detection via cyclic bilateral interaction},
  author={Lu, Liangsheng and Zhai, Wei and Luo, Hongchen and Kang, Yu and Cao, Yang},
  journal={IEEE Transactions on Artificial Intelligence},
  volume={4},
  number={5},
  pages={1186--1198},
  year={2022},
  publisher={IEEE}
}

@inproceedings{luo2022learning,
  title={Learning affordance grounding from exocentric images},
  author={Luo, Hongchen and Zhai, Wei and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2252--2261},
  year={2022}
}

@article{mi2020intention,
  title={Intention-related natural language grounding via object affordance detection and intention semantic extraction},
  author={Mi, Jinpeng and Liang, Hongzhuo and Katsakis, Nikolaos and Tang, Song and Li, Qingdu and Zhang, Changshui and Zhang, Jianwei},
  journal={Frontiers in Neurorobotics},
  volume={14},
  pages={26},
  year={2020},
  publisher={Frontiers Media SA}
}

@inproceedings{nagarajan2019grounded,
  title={Grounded human-object interaction hotspots from video},
  author={Nagarajan, Tushar and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8688--8697},
  year={2019}
}

@inproceedings{nguyen2023open,
  title={Open-vocabulary affordance detection in 3d point clouds},
  author={Nguyen, Toan and Vu, Minh Nhat and Vuong, An and Nguyen, Dzung and Vo, Thieu and Le, Ngan and Nguyen, Anh},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5692--5698},
  year={2023},
  organization={IEEE}
}

@article{qi2024shapellm,
  title={Shapellm: Universal 3d object understanding for embodied interaction},
  author={Qi, Zekun and Dong, Runpei and Zhang, Shaochen and Geng, Haoran and Han, Chunrui and Ge, Zheng and Yi, Li and Ma, Kaisheng},
  journal={arXiv preprint arXiv:2402.17766},
  year={2024}
}

@inproceedings{vishwanath2009modelnet,
  title={Modelnet: Towards a datacenter emulation environment},
  author={Vishwanath, Kashi Venkatesh and Gupta, Diwaker and Vahdat, Amin and Yocum, Ken},
  booktitle={2009 IEEE Ninth International Conference on Peer-to-Peer Computing},
  pages={81--82},
  year={2009},
  organization={IEEE}
}

@article{wang2023chat3d,
  title={Chat-3d: Data-efficiently tuning large language model for universal dialogue of 3d scenes},
  author={Wang, Zehan and Huang, Haifeng and Zhao, Yang and Zhang, Ziang and Zhao, Zhou},
  journal={arXiv preprint arXiv:2308.08769},
  year={2023}
}

@inproceedings{xue2023ulip,
  title={Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1179--1189},
  year={2023}
}

@inproceedings{yang2023IAGNet,
  title={Grounding 3d object affordance from 2d interactions in images},
  author={Yang, Yuhang and Zhai, Wei and Luo, Hongchen and Cao, Yang and Luo, Jiebo and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10905--10915},
  year={2023}
}

@inproceedings{yu2022pointbert,
  title={Point-bert: Pre-training 3d point cloud transformers with masked point modeling},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19313--19322},
  year={2022}
}

@article{zhou2023uni3d,
  title={Uni3d: Exploring unified 3d representation at scale},
  author={Zhou, Junsheng and Wang, Jinsheng and Ma, Baorui and Liu, Yu-Shen and Huang, Tiejun and Wang, Xinlong},
  journal={arXiv preprint arXiv:2310.06773},
  year={2023}
}

