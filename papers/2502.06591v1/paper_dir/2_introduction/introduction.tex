\IEEEraisesectionheading{\section{Introduction}\label{Sec:Introduction}}


Time-series data often exhibits a significant amount of misalignment (also known as nonlinear time warping);
i.e., typically the observations are
\begin{align}\label{Eqn:MisalignedDataFwd}
  (u_i)_{i=1}^N = (v_i \circ w_i)_{i=1}^N 
\end{align}
where
$u_i$ is the $i^\mathrm{th}$ misaligned signal,
$v_i$ is the $i^\mathrm{th}$ latent aligned signal, 
$w_i$ is a latent warp of the domain of $v_i$, 
and $N$ is the number of signals.
%
For technical reasons, the misalignment is usually viewed 
in terms of $T_i \triangleq w_i^{-1}$, the inverse warp
of $w_i$, implicitly suggesting $w_i$ is invertible.
It is also typically assumed that 
$(T_i)_{i=1}^N$ belong to some nominal family of warps, parametrized by
$\btheta$:
 \begin{align}\label{Eqn:MisalignedDataInv}
 (v_i)_{i=1}^N = (u_i\circ {T^{\btheta_i}})_{i=1}^N  \,, \quad  T_i=T^{\btheta_i}\in\Tcal\; \forall i\in(1,\ldots,N)
\, .
\end{align}
The nuisance warps, $(T^{\btheta_i})_{i=1}^N$, 
create a fictitious variability in the range of the signals, 
confounding their statistical analysis. 

To fix ideas, consider ECG recordings from healthy patients during rest. Suppose that the signals
were partitioned correctly such that each segment corresponds to a heartbeat, and that these segments were resampled %(in the signal-processing sense)
to have equal length (\eg, see~\autoref{fig:intro}). Each resampled segment is then 
viewed as a distinct signal.
The sample mean of these usually-misaligned signals (even when restricted to single-patient recordings) would not look like
the iconic
ECG sinus rhythm; rather, it would smear the correct peaks and valleys and/or contain superfluous ones. This is unfortunate as the sample mean 
has numerous applications in data analysis.  

Moreover, even if one succeeds somehow
in aligning a currently-available recording batch,
upon the arrival of new data batches, the latter will also need to be aligned; \ie, one would like to generalize the inferred alignment from the original batch to the new data
without having to solve a new optimization problem. This is especially the case if the new dataset is much larger than the original one; \eg, imagine a hospital solving the problem once,
and then generalizing its solution, essentially at no cost, to align all the data 
collected in the following year. 
Finally,
these issues become even more critical for multi-class data (\eg, healthy/sick patients), where only in the original batch
we know which signal belongs to which class; \ie, seemingly, the new data will have to be
explicitly classified before its within-class alignment. 

To further contextualize this concept, let us consider the application of dimensionality reduction in time-series data, using Principal Component Analysis (PCA) as an example. PCA is designed to identify the Principal Components (PCs) that capture the maximum variance in a dataset. For time series, the initial step in PCA involves centering the data by subtracting the mean sequence from each signal. 
However, if the sequences are misaligned, this mean might not accurately represent the true underlying structure. This, in turn, will lead to 
more variance at each time step, which will subsequently require more PCs to explain the data. 
Thus, unwarping the signals will allow for fewer PCs to be needed to effectively describe the data, as they are no longer compensating for the distortions caused by misalignment (see~\autoref{fig:pca} for an illustration).


A popular attempt to solve the problem relies on \textbf{pairwise alignments}. 
 Let $u_i=(u_i(t))_{t=1}^n$ and $u_j=(u_j(t))_{t=1}^m$ be two real-valued discrete-time signals of lengths $n$ and $m$, respectively. 
 The optimal pairwise alignment of $u_j$ towards $u_i$, under some dissimilarity  measure $D$, is defined by 
 \begin{align}\label{Eq:pairwise}
     T^* = \argmin{T\in\Tcal}D(u_i, u_j\circ T)
 \end{align}
 where $\circ$ denotes function composition and $\Tcal$ is a family of \emph{warps} (or warping functions); namely, every $T\in\Tcal$ 
 is a function  $T:\Omega \to \RR$ where $\Omega\subset \RR $ is an interval containing $\set{1,\ldots,m}$. 
 For instance, Dynamic Time Warping (DTW) provides the optimal discrete warping path between the time indices of $u_i$ and $u_j$ via dynamic programming, where $D$ is (usually) a Euclidean distance~\cite{Sakoe:ICA:1971:DTW1}.
 More generally, while $u_i$ and $u_j$ are defined over discrete domains (\ie, $\set{1,\ldots,n}$ and $\set{1,\ldots,m}$), 
 the notation $u_j\circ T$ in \autoref{Eq:pairwise} implicitly assumes that the value of  $u_j(t')$ at every $t'\in \RR$
 is determined, using interpolation techniques, from (possibly a subset of) the $m$ given values, $(u_j(t))_{t=1}^m$. 

 
  In this paper, which extends our two conference papers~\cite{Shapira:NIPS:2019:DTAN, Shapira:ICML:2023:RFDTAN}, we focus on continuously-defined warps that are 
 order-preserving \emph{diffeomorphisms}. 
A diffeomorphism (namely, a differentiable invertible function whose inverse is differentiable),
 is a natural choice for representing time warping~\cite{Mumford:Book:2010:PT}. 
Since spaces of diffeomorphisms are large, and to discourage unfavorable solutions, typically a regularization 
term, denoted by $T\mapsto\Rcal(T;\lambda)$ and parameterized by \emph{hyperparameters} (HP), $\lambda$, is added to the objective function; \eg, $\Rcal$ might penalize lack of smoothness (in the machine-learning sense, not calculus) or large deviations from the identity map.
Hence, \autoref{Eq:pairwise} is commonly replaced with 
  \begin{align}
     T^* = \argmin{T\in\Tcal}D(u_i, u_j\circ T)+\Rcal(T;\lambda)
 \end{align}\label{Eq:pairwiseWithReg}
 where $\Tcal$ is a space of 1D diffeomoprhisms from $\Omega$ into $\RR$. 
%%%%% Figure %%%%%
\subimport{./paper_dir}{2_introduction/fig_intro}
%%%%% Figure %%%%%
\subimport{./paper_dir}{2_introduction/fig_pca}
%%%%%%%%%%%%%%%%%%

In the case of an ensemble of $N$ signals, $(u_i)_{i=1}^N$ where $N>2$, the pairwise approach usually does not generalize well,
is prone to drift errors, and might introduce inconsistent solutions. 
This motivates approaches for \textbf{joint alignment} (JA),
also known as global alignment or multiple-sequence alignment.
The JA problem is often formulated as
\begin{align}\label{eq:JA}
    (T_i^*)_{i=1}^N,\mu   = \argmin{(T_i)_{i=1}^N\in\Tcal, u } \sum\limits_{i=1}^N 
     D(u , u_i\circ T_i)+ \Rcal(T_i;\lambda) \,    
\end{align}
where $\Tcal$, $\Rcal(\cdot;\lambda)$, and $D$ are as before, 
 $T_i$ is the latent warp associated with $u_i$, and $\mu $ is a latent signal, conceptually thought of as the \emph{average signal} (or \emph{centroid}) of the ensemble. This optimization task may also be amortized
via the training of a deep net (\eg,~\cite{Shapira:NIPS:2019:DTAN,huang:2021:residual,Martinez:ICML:2022:closed,Shapira:ICML:2023:RFDTAN}).

%
\emph{We argue that this problem should be seen as a learning one,
mostly due to the need for generalization}.
Particularly, we propose a novel deep-learning (DL) approach for the joint alignment of time-series data.
%
More specifically, inspired by computer-vision 
and/or pattern-theoretic solutions for misaligned images
(\eg, congealing~\cite{Miller:CVPR:2000:learning,Learned:PAMI:2006:align,Huang:CVPR:2007:unsupervised,Huang:NIPS:2012:learning,Cox:CVPR:2008:LS,Cox:ICCV:2009:LS}, 
efficient diffeomorphisms~\cite{Freifeld:ICCV:2015:CPAB,Freifeld:PAMI:2017:CPAB, Zhang:IPMI:2015,Zhang:IJCV:2018:fast}, and spatial transformer nets~\cite{Jaderberg:NIPS:2015:spatial,Lin:CPVR:2017:inverse,Skafte:CVPR:2018:DDTN}),
we introduce the Diffeomorphic Temporal Alignment Network (DTAN) which learns an input-dependent diffeomorphic 
time warping to its input signal to minimize a joint-alignment loss (see~\autoref{fig:fig_main} for a detailed illustration of the proposed model). The diffeomorphism family we use, called CPAB
\cite{Freifeld:ICCV:2015:CPAB,Freifeld:PAMI:2017:CPAB}, is 
based on the integration of piecewise affine velocity fields 
 and will be further discussed in~\autoref{cpab}.
In the single-class case, DTAN is completely unsupervised. For multi-class problems, 
we propose a weakly-supervised method that results in a single model (for all classes) that learns how to perform within-class joint alignment.
We demonstrate the utility of the proposed framework on real-world datasets with applications to time-series
 joint alignment, averaging, classification, and dimensionality reduction. 
 
Below we list our 6 key contributions. Contributions 1-2-3 appeared  in~\cite{Shapira:NIPS:2019:DTAN,Shapira:ICML:2023:RFDTAN}) 
while contributions 4-5-6 are new. 
\begin{enumerate}[leftmargin=.5cm]
\item DTAN, a DL framework for learning time series joint alignment and averaging~\cite{Shapira:NIPS:2019:DTAN}.
\item RDTAN: a recurrent version of DTAN which predicts diffeomorphisms derived from non-stationary velocity fields~\cite{Shapira:NIPS:2019:DTAN}.
\item A regularization-free objective function for the JA task - the \emph{Inverse-Consistency Averaging Error} (ICAE)~\cite{Shapira:ICML:2023:RFDTAN}.
\item DTAN-MT: a multi-task version of DTAN that learns both time-series alignment and classification, resulting in
better separation between the aligned classes.
\item Evaluation of prominent time-series classification DL architectures as the backbone of the Temporal Transformer module.
\item Analyzing DTAN's effect on dimensionality reduction via PCA.
\end{enumerate}
 We conclude this section with a timely remark: throughout the paper, the term ``transformer net" should be  understood in the same sense it was used in STN~\cite{Jaderberg:NIPS:2015:spatial} 
 or TTN~\cite{Shapira:NIPS:2019:DTAN} (\ie, a Spatial or Tempiral Transform Net), and is not to be confused with how it is used in Natural Language Processing or Vision Transformers. 
%%%% FIGURE %%%%%%
\subimport{./paper_dir}{4_background/fig_arch}
%%%%%%%%%%%%%%%%%