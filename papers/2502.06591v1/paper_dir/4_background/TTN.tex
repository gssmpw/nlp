\subsection{Temporal Transformer Nets} 
Given $\Tcal$ , a differentiable transformation family parameterized by $\btheta$, a Spatial Transformer (ST) layer performs a
 learnable input-dependent warp w.r.t a given objective function~\cite{Jaderberg:NIPS:2015:spatial}.
  Reducing this from images (a 2D domain) to time series (1D), one obtains a Temporal Transformer (TT) layer. A TTN is a neural net with at least one TT layer. In more detail, let $u$ denote the input of the TT layer. Its outputs consist of $\btheta = f_{\mathrm{loc}}(u)$ and
$v=u\circ T^{\btheta}$, where
$T^{\btheta} \in \Tcal$ is a 1D warp parameterized by $\btheta$. The function $f_{\mathrm{loc}}: u \mapsto \btheta$ is itself a
 neural net called the localization net. Let $\bw$ denote the parameters (also known as weights) of $f_{\mathrm{loc}}$ and let
\begin{align}
  \Lcal((u_i,\btheta_i(u_i;\bw))_{i=1}^N)
\end{align}
denote a loss function. Recall that, as usual, the back-propagation algorithm requires certain partial derivatives and note that one of these derivatives, $\nabla_\btheta (T^{\btheta}( \cdot))$, depends on the choice of $\Tcal$.

The TTN consists of 3 modules:
\begin{enumerate}[leftmargin=.5cm]
%
 \item \textbf{Localization network.} For an input signal, $u$, the localization network, $f_{\mathrm{loc}}$, predicts the warp's parameters; \ie, $f_{\mathrm{loc}}(u)=\btheta$. 
 Any form of neural network architecture can be used for  $f_{\mathrm{loc}}$, 
 as long as the output layer has $d$ 
 neurons, where $d=\dim(\btheta)$.
 %
 \item \textbf{Parameterized grid generator}. This generator creates a discrete 1D grid 
 of length $M$ (where $M$ is the length of the signals):
 $G=\tuple{x_m}_{m=1}^M\subset[-1,1]$ of evenly-spaced points which are later transformed by the parametrized warp, $T^\btheta$.
 %
 \item \textbf{Differentiable time-series resampler}. The output signal, $v$, is computed 
 by interpolating the values of $v$ at $T^\btheta(G)$ from $u$.
Let $x_{i,m}^{\mathrm{new}} = T^{\btheta_i}(x_m)$ and write the discrete-time $i$-th aligned signal
as
\begin{align}
 v_i &= (v_{i,m})_{m=1}^M=(v_{i,1},\ldots,v_{i,M})\, .
\end{align} 
Note that due to the need to resample the  signal,
rather than having $v_i = u_i \circ T^{\btheta_i}$, we need to also account for the resampling kernel. 
For the popular linear kernel, which is the one used in our work, we obtain (based on~\cite{Jaderberg:NIPS:2015:spatial}),
\begin{align}
   v_{i,m} &= \sum_{m'=1}^M u_{i,m'} \max(0, 1 - |x_{i,m}^{\mathrm{new}}  -m'|) \, .
\end{align}
%
\end{enumerate}
To propagate the loss to $f_{\mathrm{loc}}$, the resampling kernel must be differentiable, 
which is the case for the linear kernel:
 \begin{align}
   \frac{\partial v_{i,m}}{\partial u_{i,m'}  }  &= \sum_{m'=1}^M \max(0, 1 - |p_{i,m}^{\mathrm{warped}}  -m'|) \\ 
     \frac{\partial v_{i,m}}{\partial (p_{i,m}^{\mathrm{warped}})  }  &= 
     \sum_{m'=1}^M u_{i,m'} 
     \left\{
     \begin{matrix}
 0 & \text{if }& |m' - p_{i,m}^{\mathrm{warped}}| \ge 1  \\
 1 & \text{if }& m' \ge p_{i,m}^{\mathrm{warped}}  \\
 -1& \text{if }& m' < p_{i,m}^{\mathrm{warped}}
     \end{matrix}
     \right.
     \, .
 \end{align}
Here $v_{i,m}$ is the $i^{th}$ warped signal at time point $m$, $u_{i,m'}$ is the input signal at time point $m'$ and $p_{i,m}^{\mathrm{warped}}$ is the $m^{\text{th}}$ point of the sampling grid.
The generalization of these results to multichannel time series is straightforward and thus omitted. 
In~\autoref{cpab} we will specify $\Tcal$ and will discuss its associated derivative, $\nabla_\btheta (T^{\btheta}( \cdot))$.