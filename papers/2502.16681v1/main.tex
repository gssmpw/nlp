%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{hyperref}

\newcommand{\saeneuronpedia}
{\mathrm{width} = 131\mathrm{k}, \mathrm{L0} = 114}
\newcommand{\saesmall}
{\mathrm{width} = 16\mathrm{k}}
\newcommand{\saemid}{\mathrm{width} = 131\mathrm{k}}
\newcommand{\saelarge}{\mathrm{width} = 1\mathrm{M}}
\newcommand{\lzero}{\mathrm{L0}}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables


% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{arxiv}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% new packages
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{graphicx}

% Macros
\DeclareMathOperator*{\ArgTopK}{arg\,top\,k}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Are Sparse Autoencoders Useful? A Case Study in Sparse Probing
}

\begin{document}

\twocolumn[
\icmltitle{Are Sparse Autoencoders Useful? A Case Study in Sparse Probing}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Subhash Kantamneni}{equal,mit}
\icmlauthor{Joshua Engels}{equal,mit}
\icmlauthor{Senthooran Rajamanoharan}{}
\icmlauthor{Max Tegmark}{mit}
\icmlauthor{Neel Nanda}{}
\end{icmlauthorlist}

\icmlaffiliation{mit}{Massachusetts Institute of Technology}


\icmlcorrespondingauthor{Subhash Kantamneni}{subhashk@mit.edu}
\icmlcorrespondingauthor{Joshua Engels}{jengels@mit.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Sparse autoencoders (SAEs) are a popular method for interpreting concepts represented in large language model (LLM) activations. However, there is a lack of evidence regarding the validity of their interpretations due to the lack of a ground truth for the concepts used by an LLM, and a growing number of works have presented problems with current SAEs. One alternative source of evidence would be demonstrating that SAEs improve performance on downstream tasks beyond existing baselines. We test this by applying SAEs to the real-world task of LLM activation probing in four regimes: data scarcity, class imbalance, label noise, and covariate shift\footnote{We make our code publicly available  \href{https://github.com/JoshEngels/SAE-Probes}{here.}}. Due to the difficulty of detecting concepts in these challenging settings, we hypothesize that SAEs' basis of interpretable, concept-level latents should provide a useful inductive bias. However, although SAEs occasionally perform better than baselines on individual datasets, we are unable to design ensemble methods combining SAEs with baselines that consistently outperform ensemble methods solely using baselines. Additionally, although SAEs initially appear promising for identifying spurious correlations, detecting poor dataset quality, and training multi-token probes, we are able to achieve similar results with simple non-SAE baselines as well. Though we cannot discount SAEs' utility on other tasks, our findings highlight the shortcomings of current SAEs and the need to rigorously evaluate interpretability methods on downstream tasks with strong baselines. 
% Sparse autoencoders (SAEs) have gathered significant attention in the field of mechanistic interpretability. However, there remains a lack of rigorous evidence showing their efficacy on downstream tasks, and a growing number of works have presented problems with current SAEs. In this work, we test SAE effectiveness on the well studied task of probing: learning a map from model hidden states to targets. We hypothesize that if SAEs indeed find a more interpretable or true-to-the-model basis for activations, probes trained on their latent space should offer advantages over traditional raw activation based methods. We investigate probing in multiple regimes--data scarcity, label corruption, class imbalance, and distribution shifts--and 
% % find  probing regimes
% % % aim to create the strongest possible case for SAEs, 
% % investigate multiple regimes where we hypothesize SAEs' inductive biases might help: data scarcity, label corruption, class imbalance, and distributional shifts, We find 
% find weakly positive results for SAE probes when compared to traditional activation probes. Additionally, we show through case studies on two datasets how SAE probes can identify spurious correlations and label errors. We also investigate the reasons behind the underperformance of SAEs relative to our expectations. Our findings highlight the necessity for further empirical evaluation of SAEs in real-world applications and raise the question of whether current SAEs have fundamental flaws.
% revealing significant shortcomings in current methodologies that require rectification. 
\end{abstract}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/fig1.pdf}
    \caption{SAE probes underperform the baseline of logistic regression in each regime when taking the mean across datasets. Additionally, we find that baseline methods can provide many of the interpretability insights of SAE probes.}
    \label{fig:fig1}
\end{figure}



\section{Introduction}
Dictionary learning is a popular method for interpreting LLM activations \cite{arora2018linear, yun2021transformer}; most notably, \citet{dictionary_monosemanticity_anthropic, other_sae_paper} demonstrated the promise of sparse autoencoders (SAEs) and sparked considerable follow-up work. This includes papers focused on improving the downstream cross entropy loss of SAE reconstructions \cite{gao2024scalingevaluatingsparseautoencoders, braun2024identifyingfunctionallyimportantfeatures, rajamanoharan2024improving,rajamanoharan2024jumpingaheadimprovingreconstruction}, improving SAE training efficiency \cite{mudide2024efficientdictionarylearningswitch, gao2024scalingevaluatingsparseautoencoders}, finding weaknesses in SAEs and proposing solutions \cite{chanin2024absorption, bussmann2024matryoshka}, using SAEs to understand model representation structure \cite{engels2024languagemodelfeatureslinear, engels2024decomposing, li2024geometry}, training large suites of SAEs \cite{gemmascope, LlamaScope}, and developing benchmarks for SAEs \cite{huang2024ravel, karvonen2408measuring, neuronpediaSAEBenchComprehensive}.
% Since then, the mechanistic interpretability community has published a large number of followup papers \cite{}. Many of these papers focus on improving the performance of sparse autoencoders themselves; a popular metric is the average number of active latents versus the downstream cross entropy loss when the SAE is inserted into the model. 

Unfortunately, we lack a ``ground truth'' to know whether SAEs truly extract the interpretable concepts used by language models. Prior work has largely avoided this limitation by evaluating SAEs with proxy metrics like reconstruction loss \cite{rajamanoharan2024improving, rajamanoharan2024jumpingaheadimprovingreconstruction, gao2024scalingevaluatingsparseautoencoders, olmo2024featuresmakedifferenceleveraging, braun2024identifyingfunctionallyimportantfeatures}. These metrics are tractable to optimize for, but do not necessarily align with mechanistic interpretability's (MI) goal of better understanding neural networks (see \citet{bereska2024mechanistic} and \citet{sharkey2025openproblemsmechanisticinterpretability} for surveys of MI). We argue that if SAEs truly advance MI's goal, they should improve performance on a real, hard-to-fake model control or explainability task.

However, despite the extensive body of work on SAEs, there are relatively few cases where SAEs have been shown to help on such a task: \citet{marks2024sparse} show that SAE feature circuits can help identify and remove bias from classifiers; \citet{smith2024sparse_autoencoders} show that SAEs can identify misaligned features learned by a preference model; and \citet{karvonen2024sieve} show that SAE feature ablations are better at preventing regex output than baselines in a setting with scarce supervised data. While these results are promising, they all study a single example in detail, and consider comparative baselines with varying levels of rigor. 

% \citet{bricken2024features_classifiers} show that a probe trained on SAE latents to identify harmful bio-weapons prompts outperforms one trained on activations;

At the same time, there are also surprisingly few negative results finding that SAEs do \textit{not} help on downstream tasks; in fact, we are only aware of \citet{chaudhary2024evaluating}, which finds that SAE latents are worse than neurons at disentangling geographic data, and \citet{FarrelSAEBio}, which finds that pinning related SAE latents is less effective than baselines for unlearning bioweapon knowledge. Thus, it is not clear whether SAEs are just one result away from being differentially useful, or if MI should seek fundamentally different methods. We defer a thorough examination of related work to \cref{sec:app-related-work}. 


In this work, we attempt to fairly evaluate the utility of SAEs by examining their competitive advantage on a concrete task: training probes from language model activations to targets \cite{alain2016understanding}. Probing has two important qualities:
\vspace{-0.1cm}
\begin{enumerate}[topsep=1pt,itemsep=0pt,parsep=0pt,leftmargin=12pt]
\item \textbf{Probing is practically useful:} Probing has been used to investigate LLM representations \cite{space_time, othello_neel_linear, monotonic_numeric_representations}, detect safety relevant quantities \cite{zou2023representation}, remove knowledge from models \citep{Elazar2021}, and catch synthetic sleeper agents \cite{macdiarmid2024sleeperagentprobes}.
\item \textbf{SAEs might reasonably improve probing:} Theoretically, SAE latents are a more interpretable basis of model activations, and we hypothesize that this inductive bias will help train probes in difficult regimes. Recent work has also found some positive results for the utility of SAE probes \cite{bricken2024features_classifiers, probingGallifant}.
\end{enumerate}
\vspace{-0.15cm}
Thus, we curate 113 linear probing datasets from a variety of settings and train linear probes on corresponding SAE latent activations (see \cref{fig:method_diagram}). We compare to a suite of baseline methods across 4 difficult probing regimes: 1) data scarcity, 2) class imbalance, 3) label noise, and 4) co-variate shift.
% \vspace{-0.1cm}
% \begin{enumerate}[topsep=1pt,itemsep=0pt,parsep=0pt,leftmargin=20pt]
% \item Low data
% \item Label noise (concept drift)
% \item Out of distribution data (co-variate shift)
% \item Class imbalance 
% \end{enumerate}
% \vspace{-0.15cm}
Unfortunately, we find that \textbf{SAE probes fail to offer a consistent overall advantage when added to a simulated practitioner's toolkit}. 


Further, we explore areas that \citet{bricken2024features_classifiers} suggest SAEs may be valuable for, including detecting attributes distributed over multiple tokens and identifying dataset issues. Although SAEs initially seemed promising in these settings, we were able to achieve the same results with improved baselines. Our results underscore the necessity for MI works to rigorously design baselines when evaluating the utility of interpretability techniques.

% Further, although we found initially promising results for SAE probes in some settings, by using more rigorous baselines we concluded these were illusory. Namely, we find that \citet{bricken2024features_classifiers}'s preliminary work demonstrating the advantage of SAE probes when applied to multiple tokens did not properly consider a multi-token comparative baseline. In our own work, we initially falsely concluded that SAE probes offered an advantage for evaluating dataset quality when baseline methods provided the same insight. 

% sparse probes have inductive bias towards interp, hypothesize that this interp bias can help in some settings
% Summary of results, somewhat evidence against current SAEs being a game changer, further iteration needed, possibly larger SAEs, … 
% Check out meta SAEs paper
% Contributions:


% Dataset interp.




\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/probing_drawio_10.pdf}
    \caption{\textbf{Left:} An illustration of our SAE probing method. We pass in training activation vectors from each class and train an $L_1$ regularized logistic regression probe on the latents that differ the most between classes. \textbf{Right:} We ensure robustness of our results with the "quiver of arrows" approach (see \cref{sec:quiver}): we add SAE regression into a set of methods, and see if the test accuracy of the best method (chosen by validation accuracy) increases.}
    \label{fig:method_diagram}
\end{figure}


\begin{table*}[h]
    \centering
    \caption{Example probing tasks. Only tasks with short prompts shown for conciseness.}
    \begin{tabular}{c|p{10cm}|c}
    \hline
    \textbf{Dataset Name} & \textbf{Prompt} & \textbf{Target} \\ \hline
    26\_headline\_isfrontpage & Sebelius’s Slow-Motion Resignation From the Cabinet. & 1 \\
     & MI5 References Emerge in Phone Hacking Lawsuit. & 0 \\ \hline
    36\_sciq\_tf & Q: Binary fission is an example of which type of production? A: asexual & 1 \\
     & Q: What occurs when light interacts with our atmosphere? A: prism effect & 0 \\ \hline
    114\_nyc\_borough\_Manhattan & INWOOD BASKETBALL COURTS & 1 \\
     & PS 18 JOHN G WHITTIER & 0 \\ \hline
     149\_twt\_emotion\_happiness & All moved in to our new apartment. So exciting & 1 \\
     & is noow calmmm  eating polvoron .. yuumm & 0 \\ \hline
    155\_athlete\_sport\_basketball & Jimmy Butler & 1 \\
     & Steve Balboni & 0
     \\
    \end{tabular}
    \label{tab:example_data}
\end{table*}

\section{Methodology}

We apply probes to the hidden states of two language models, Gemma-2-9B \cite{gemma2} and Llama-3.1-8B \cite{llama3.1-8B}. Our main paper results use Gemma-2-9B. We replicate core results on Llama-3.1-8B in \cref{sec:app-llama}. We use JumpReLU~\cite{rajamanoharan2024jumpingaheadimprovingreconstruction} sparse autoencoders (SAEs) from Gemma Scope \cite{gemmascope} for Gemma-2-9B and TopK~\cite{gao2024scalingevaluatingsparseautoencoders} SAEs from Llama Scope \cite{LlamaScope} for Llama-3.1-8B. See \cref{sec:app-related-work} for further background on SAEs.

\subsection{Classification Datasets}
We collect a diverse set of 113 binary classification datasets listed in \cref{tab:app_all_tasks} (\cref{sec:app_class_datasets}), including datasets that we expect to be challenging for probes.
% We gather tasks from both academic works and more informal settings like Kaggle. 
% To avoid observational bias, we . 
For example, 26\_headline\_isfrontpage requires probes to identify front-page headlines and 136\_glue\_mnli\_entailment requires probes to identify logically entailment. For other example datasets, refer to \cref{tab:example_data}. All datasets are titled in the form $\mathrm{ID}\_\mathrm{description}$. We originally collected datasets for other purposes and discarded some of them; thus, while we have 113 datasets, $\mathrm{ID}$ ranges from $[5,163]$.


All datasets contain $\mathrm{prompts}$ and $\mathrm{targets}$. Probes are tasked with predicting the $\mathrm{target}$ from the model's hidden activations when run on a $\mathrm{prompt}$. We focus on binary classification, since SAEs are mostly thought of as representing binarized latents (see \citet{dictionary_monosemanticity_anthropic}). Thus, $\mathrm{target}$ is either $0$ or $1$. The prompts in our datasets range in length from 5 tokens to a (left-truncated) maximum of 1024 tokens. 


% e.g. automated-interpretability methods just seek to predict whether or not a latent fires,

\subsection{Probing Strategy}
\label{sec:probing_strat}
To train a probe on a given dataset, we first run the model on all $\mathrm{prompts}$ from that dataset to generate model activations at each layer $l$ on the last token, $X_{-1}^l$.$X_{-1}^l$ is of shape $\mathrm{(len(prompts), model\_dim)}$. We probe the last token to ensure the target information was present in the preceding context. For activation probes, we then train a probe $p$ to map from $X_{-1}^l \mapsto t$, where $t$ are the $\mathrm{targets}$ in our dataset. 


Our SAE probe training technique is summarized in \cref{fig:method_diagram}. We first pass the training dataset $X_{-1}^l$ through the SAE encoder, resulting in a batch of vectors in the SAE latent space $Z = \mathrm{SAE}(X_{-1}^l)$ of shape $(\mathrm{len(prompts)}, W)$, where $W$ is the width of the SAE. We do not train probes directly on the SAE latent space because we hypothesize that a small number of SAE latents encodes the desired concept. Instead, we create a basis of latents with the highest average absolute difference between the set of training prompts $T_1$ with $\mathrm{target} = 1$ and the set of training prompts $T_0$ with $\mathrm{target} = 0$. More formally, if $\mathrm{SAE}(X_{-1}^l) \in \mathbb{R}^{W}$, where $ W \gg d_\textrm{model}$, we choose $k \ll W$ and find indices $\mathcal{I}$ as follows:
% \begin{align}\label{eqn:select_k_indices}
% \mathcal{I} = \ArgTopK_{i \in \{W\}}\left | \frac{1}{n_1} \sum_{\substack{j \in \{n_1\}}} SAE(X^l_{-1})[j, i]  - \frac{1}{n_0} \sum_{\substack{j \in \{n_0\}}} SAE(X^l_{-1})[j, i]  \right |
% \end{align}
\begin{align}\label{eqn:select_k_indices}
\mathcal{I} = \ArgTopK_{i \in \{W\}} \left| \frac{1}{|T_1|} \sum_{j \in T_1} Z_{j,i} - \frac{1}{|T_0|} \sum_{j \in T_0} Z_{j,i} \right|
\end{align}

We then train a probe $p_\textrm{SAE}$ to map from $Z[:, \mathcal{I}] \mapsto t$.

Note that previous work in SAE probing has aggregated SAE latents across tokens to provide a richer input space for SAE probes \cite{neuronpediaSAEBenchComprehensive, features_as_classifiers}. However, most probing studies operate on the final token, which we choose to emulate. In \cref{sec:why-didnt-this-work}, we present results considering probes on multiple tokens.
% , more closely emulating an ML scientist's realistic probing workflow, as well as to eliminate the confounding variable of aggregation technique (SAE activations are naturally easier to aggregate across tokens, but stronger baselines for activations . 

Throughout this study, we use the area under the ROC curve (AUC) to evaluate the quality of a probe. AUC is the likelihood that the classifier assigns a higher probability of $\mathrm{target}=1$ to a $\mathrm{target}=1$ example than to a $\mathrm{target}=0$ example. Using AUC allows us to comprehensively assess probe performance agnostic to classification thresholds. For additional details on AUC, see \cref{sec:app_auc_explainer}.
 % providing a comprehensive evaluation of its discriminatory capability. 
 
Often, a probe $p$ has hyperparameters $h_{p}$ we would like to optimize. 
% To mimic real life probing situations, 
We select $h_p$ that has the maximal validation AUC using the cross-validation strategy described in \cref{tab:crossval}. We then test $p$ with optimal $h_p$ on a held out test set to calculate $\mathrm{AUC}_p^{\mathrm{test}}$. All datasets have at least $100$ testing examples, with most having more (the average test set size is $1945$). 


\subsection{Probing Methods}
\label{sec:probing_methods}
We use the following 5 probing methods, with hyperparameters in parenthesis:
\begin{enumerate}
[topsep=1pt,itemsep=0.2pt,parsep=0pt,leftmargin=10pt]

    \item Logistic Regression ($\mathrm{L}_1$ regularization for SAE probes, $\mathrm{L}_2$ otherwise).
    \item PCA Regression (\# of PCA components to reduce $X_{-1}^l$ to before using unregularized logistic regression).
    \item K-Nearest Neighbors (KNN) (\# of nearest neighbors).
    \item XGBoost \cite{xgboost} ($\mathrm{n\_estimators}$, $\mathrm{max\_depth}$, $\mathrm{learning\_rate}$, $\mathrm{subsample}$, $\mathrm{colsample\_bytree}$, $\mathrm{reg\_alpha}$, $\mathrm{reg\_lambda}$, and $\mathrm{min\_child\_weight}$).
    \item Multilayer Perceptron (MLP) (network depth, hidden state width, learning rate, and weight decay).
\end{enumerate}

We evaluate 10 hyperparameter values $h_p$ for each probing method $p$. For the first three probing methods, we use grid search, while for MLPs and XGBoost, we randomly sample from a hyperparameter grid to manage the larger search space. For additional details on hyperparameter ranges, see \cref{sec:app_probe_hyperparam}. We use all five probing methods as baselines, but for SAE probes we only use logistic regression.

\subsection{Experimental Setup: Quiver of Arrows}
\label{sec:quiver}
To evaluate whether SAE probes provide an advantage over baselines, we use an evaluation metric we call the ``Quiver of Arrows'': we ask whether adding SAE probes (a new ``arrow'') to the set of existing probing methods available to a practitioner (the ``quiver'') increases performance compared to a practitioner \textit{without} access to SAE probes. In other words, over a collection of methods we choose the best method by validation AUC and then report the test AUC of that method. We can then compare the marginal improvement of adding SAE probes to a practitioner's toolkit by comparing the Quiver of Arrows AUC of baeline methods with and without SAE probes. We describe the Quiver of Arrows more formally in \cref{app:quiver}.

The quiver of arrows approach is designed as a robustness check to fairly evaluate the benefit of adding SAE probes to a practioner's toolkit. If we instead constructed probes from a large set of SAEs and chose the best one based on test AUC, we could be tricked into thinking SAEs outperform baselines because we accessed the held-out test set. With the quiver of arrows approach, we emulate the information a real practioner has access to, allowing us to make a robust recommendation on the usefulness of SAE probes.


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/Normal/sae_l0_k_normal_pareto_16k.pdf}
    \vspace{-0.6cm}
    \caption{For a given width, using higher L0 and constructing probes with a larger basis of latents ($k$) is more performant.}
    \label{fig:sae_normal_l0_k_pareto}
\end{figure}



% While e.g. comparing test accuracies might be simpler, it is unrealistic, as in the regimes we consider a practitioner does not have access to a large ground truth test set to choose the best method. 
% CV: Leave 2 out for < 12. k = 6 CV < 128. otherwise 20\% val. 


% \subsection{Experiment Setup: Noisy Labels}
% In this setting, we assume that the practitioner suspects that there will be some sort of distribution shift, or that their labels are noisy, and so cannot trust the validation data to select between methods. Thus, we just show the difference between a \textit{global} choice of the 16k width SAE with highest L0 versus logistic regression.


\section{Comparing Probing Techniques in Different Regimes}

\subsection{Standard Conditions}
We initially assess probes under standard conditions, characterized by sufficient data for probe convergence and balanced classes. We find that baseline methods perform the best on layer 20 (see \cref{fig:app-baseline-layer}, \cref{sec:app_baselines}), so we run experiments with this layer. We train baselines on 1024 data points (or the maximum number of points in the dataset). 
% This simulates where a practitioner without SAEs would probe, establishing a proper counterfactual for when we add SAEs to the quiver.

% Since Gemma Scope contains 34 SAEs of $\saesmall$ to $\saelarge$ with multiple $\lzero$ values, w
We first conduct a preliminary investigation to cut down the large space of Gemma Scope SAEs. We train probes for all SAEs using $k$ latents (for logspaced values of $k$) on all datasets using 1024 training examples. We calculate the average test AUC for each SAE probe across all datasets. We find that SAE $\mathrm{width}$ is relatively unimportant to probe success, while larger $\lzero$s lead to more performant probes (\cref{sec:app_sae_normal}). Additionally, as we might expect, using a larger value of $k$ leads to better probe performance, as shown in \cref{fig:sae_normal_l0_k_pareto}.


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/Normal/sae_vs_nosae_normal_comparison.pdf}
    \vspace{-0.6cm}
    \caption{In standard conditions, when SAE probes are added to the quiver, we find a slight decrease in performance.}
    \label{fig:sae_normal}
\end{figure}

% In the appendix (\cref{fig:all_datasets_vs_k}), we plot the test AUC vs. $k$ for every individual dataset.


Thus, throughout the paper we train probes using the largest $\lzero$ for SAEs $\saesmall, \saemid$, and $\saelarge$. We use $k = 16$ to construct easily interpretable probes that potentially overfit less and use $k = 128$ for performance. 


Using this set of probes, we consider our quiver of arrows approach in standard conditions. SAEs are chosen as the ``arrow'' for 14/113 tasks, however, we see a slight \textit{decrease} in performance when they are added to the quiver in \cref{fig:sae_normal}.


It is unsurprising that SAE probes underperform baselines in standard conditions, as their inductive bias is marginal given a large, balanced dataset. Thus, we now investigate more difficult settings to test if the inductive bias of SAEs translates into a competitive advantage for probing.



\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/combined/target_datasets_quiver_combined_new.pdf}
    \vspace{-0.5cm}
    \caption{For three of the datasets in \cref{tab:example_data}, we visualize the performance when SAE probes are in the quiver (dashed) versus when they are not (solid) for the regimes of data scarcity (left), class imbalance (middle), and label noise (right). In all three regimes, we see that on average (bottom row), SAEs do not help.}
    \label{fig:combined-target-datasets}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    % First figure
    \includegraphics[width=\linewidth]{figures/combined/quiver_improve_regimes.pdf}
    \vspace{-0.6cm}
    \caption{For the regimes of data scarcity, class imbalance, and label noise, we see no average improvement across datasets when adding SAEs to the quiver. Shading represents 95\% confidence intervals.}
    \label{fig:combined-improvement}
\end{figure*}




\subsection{Data Scarcity, Class Imbalance, and Label Noise}


In this section, we consider more difficult probing regimes: limiting the training data (Data Scarcity), changing the relative frequency of $\mathrm{target}=1$ examples (Class Imbalance), and randomly flipping a fraction of the $\mathrm{targets}$ (Label Noise). All of these settings are realistic workflows - for example, a researcher observing a rare model phenomena would like a probe that generalizes with few total examples or few examples of the desired class, while a researcher working with collected user data wants a generalizable probe even if some fraction of users respond randomly.

Each regime is characterized by a parameter which we vary to compare SAEs and baselines.
\begin{itemize}
[topsep=0.3pt,itemsep=0.2pt,parsep=0pt,leftmargin=10pt]
    \item Data Scarcity - We use 20 values of $n$ logspaced in $[2,1024]$, where $n$ is the number of training examples. We use a standard test set.
    \item Class Imbalance - We use 19 values of $\mathrm{ratio}$ linearly spaced between $[0.05, 0.95]$, where $\mathrm{ratio} = \frac{n_1}{n}$ and $n_1$ is the number of $\mathrm{target}=1$ training examples. The test set uses the same $\mathrm{ratio}$.
    \item Label Noise - We use 11 values of $\mathrm{fraction}$ linearly spaced between $[0,0.5]$, where $\mathrm{fraction} = \frac{n_{\mathrm{corrupted}}}{n}$. We use a standard test set (uncorrupted).
\end{itemize}

We evaluate the first two regimes with the quiver of arrows method. However, the quiver of arrows method relies on the validation data being representative of the test data. This assumption fails for the label noise setting since the validation data is corrupted. Thus, a hypothetical practitioner would likely deploy their most performant method from other settings instead of allowing corrupted validation AUC to arbitrarily choose a method. To emulate this, we compare logistic regression and the $\saesmall$, $k = 128$ SAE probe head-to-head in the setting of label noise. 
% These methods represent the most performant baseline and SAE probe in standard settings (\cref{sec:app_baselines}, \ref{sec:app_sae_normal}).

In \cref{fig:combined-target-datasets}, we visualize the SAE versus non-SAE quivers for a sample of datasets listed in \cref{tab:example_data} across the three regimes. Additionally, we visualize the average performance difference between the SAE and non-SAE quivers for each regime across all datasets in \cref{fig:combined-improvement}. At all parameter values in each regime, SAEs show no meaningful improvement over baselines. This is not because SAEs are not chosen from the quiver; in \cref{sec:app-regimes} we see that SAEs are chosen for up to 40 datasets in each regime. SAEs simply underperform baselines in these settings. See \cref{sec:app-regimes} for results for individual datasets. 



\subsection{Covariate Shift}

We now investigate if SAE probes are more resilient to distribution shifts in prompts. To model this covariate shift, we create or use 8 out-of-distribution (OOD) datasets: two pre-existing GLUE-X datasets which are designed as ``extreme'' versions of tasks 87 and 90 to test grammaticality and logical entailment respectively; three datasets (tasks 66, 67, and 73) which we alter the language of; and three datasets (tasks 5, 6, and 7) where we use syntactical alterations to names or use cartoon characters instead of historical figures. We train probes on these datasets in standard settings and evaluate on 300 covariate shifted test examples.

Like the label noise setting, our validation data is unfaithful to our test data. Thus, we compare logistic regression to a single SAE probe. We construct SAE probes from the $\saeneuronpedia$ SAE, as latent descriptions are available for this SAE on Neuronpedia \citep{neuronpedia}. Our results (\cref{fig:ood}) show that baselines outperform SAE probes when generalizing to covariate shifted data.



\section{Interpretability}
While we find that SAE probes are not helpful in traditional probing settings, one intrinsic advantage of SAE probes is that their input basis is interpretable. To leverage this, we use the technique of automatic interpretation, or autointerp, to create natural language descriptions of top latents for each dataset  (see \citet{bills2023language}).
% by providing a language model with each latent's maximally activating examples. 
We investigate three applications of labeled latents:
\begin{enumerate}[topsep=1pt,itemsep=0pt,parsep=0pt,leftmargin=10pt]
\item \textbf{Probe Interpretability}: In \cref{sec:probe_interp}, we investigate why SAE probes fail to perform well by pruning latents that o1 \cite{o1} ranks as spurious.
\item \textbf{Latent Interpretability}: In \cref{sec:latent_interp}, we generate autointerp explanations of each dataset's top latent to find spurious latents and latents that fit well to our probes in a way not explained by the autointerp label.
\item \textbf{Detecting Dataset Quality Issues}: In \cref{sec:dataset_interp}, we invesigate spurious dataset features and label errors using insights from the top latent descriptions and firing patterns.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/OOD/ood_task_comp.pdf}
    \vspace{-0.8cm}
    \caption{SAE probes often generalize worse than baseline logistic regression with covariate shift.}
    \label{fig:ood}
    \vspace{-0.3cm}
\end{figure}


% By generating a description of probe latents, we can determine if a given latent represents a spurious correlation. We can use this information to construct probes with fewer spurious correlations, which we expect will generalize better, or we can easily identify datasets with potential errors. We consider each of these situations in turn.



\subsection{Probe Intepretability: Pruning and Latent Generalization}
\label{sec:probe_interp}
We first use autointerp to investigate why SAE probes fail to generalize to covariate shift. We have two initial hypotheses: 1) the latents SAE probes rely on leverage spurious correlations in the training data and 2) the latents are not spurious, but they are not robust to the distribution shift.

First, we investigate hypothesis 1. Specifically, we attempt to improve SAE probes OOD performance by pruning latents deemed spurious by their autointerp description. We focus on three OOD tasks that SAE probes perform poorly on: 7\_hist\_fit\_ispolitician, 66\_living-room, and 90\_glue\_qnli (\cref{fig:ood}). We use the $\saeneuronpedia$ SAE.

For each task, we take the $k = 8$ top latents by mean difference and use Claude-3.5-Sonnet \cite{sonnet} to generate latent descriptions with autointerp. We then use OpenAI's o1 model to rank the relevance of each latent's description to the task. We also prompt o1 to downrank spurious latents given the OOD transformation. An example of this procedure for the task 66\_living-room, which identifies if the phrase ``living room'' is in an English sentence, is shown in \cref{tab:latents-description}, \cref{sec:app-pruning}. For this task, o1 ranked latent 12274, which identifies ``mentions of living rooms'' first, while ranking latent 51330, which identifies ``objects and materials related to scientific experiments,'' last. 

We then construct a probe with the top $k$ latents using o1's relevance rank for $k \in [1,8]$. If there are spurious latents in the $k = 8$ probe, we expect a probe with $k<8$ to have better OOD generalization. We visualize each task's performance by $k$ in \cref{fig:ood-pruning}, \cref{sec:app-pruning}. For two of the datasets, 66\_living-room and 90\_glue\_qnli, we see that pruning works, with a 0.024 and 0.052 increase in AUC between the $k=8$ and $k=1$ probe for each dataset. However, for 7\_hist\_fig\_ispolitician, OOD test AUC \textit{increases} by 0.077 after pruning. This indicates that the task 7\_hist\_fig\_ispolitician requires $k=8$ latents to represent.


Our preliminary results show that pruning helps SAE probes generalize. However, the drop between in-distribution (ID) and OOD performance is much larger than the modest improvement from pruning. This indicates that spurious correlations are not the primary reason SAE probes fail to generalize. Thus, we consider the second hypothesis - that the underlying SAE latents do not generalize well OOD.

On the task 66\_living-room, latent 122774 has an ID test AUC of 0.99 while only having an OOD test AUC of 0.64. Since the OOD transformation involves translating the prompts to French, we hypothesize that this latent is active on the phrase ``living room'' in English but not other languages. We use GPT-4o to translate ``living room'' to 15 languages, and in \cref{fig:ood-living-room} we indeed observe that latent 122774 is more active on the English translation than all other languages, and it is not active on the French translation at all. Thus, latent 122774 does not generalize OOD, which explains why the SAE probe also failed to generalize. 
% This highlights a failing of robustness in the Gemma Scope SAEs.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/OOD/living_room_latent_translations.pdf}
    \vspace{-0.8cm}
    \caption{Latent 122774 is most active on the English translation of ``living room,'' and does not fire on French.}
    \label{fig:ood-living-room}
\end{figure}



\subsection{Latent Interpretability}
\label{sec:latent_interp}
We next generate autointerp descriptions for the most determinative latent for each dataset, allowing us to identify interesting categories of latents. Specifically, we consider each of the top 128 latents for each dataset for the $\saeneuronpedia$ SAE, and evaluate each latent's $k=1$ SAE probe in standard settings. We then generate an autointerp explanation with GPT-4o for the best latent. 

\cref{tab:latents-description} (\cref{sec:app-latents}) contains a breakdown of a selection of interesting top latents that we find. We see that some latents' descriptions fit their tasks, like latent 81210 for 5\_hist\_fig\_ismale, which activates on ``references to female individuals.'' Another interesting category is incorrect autointerp labels (e.g. for 125\_wold\_country\_Italy, latent 50817 has 0.989 AUC, implying (correctly) that it fires on Italian concepts; however, the description reads ``names of researchers and scientific authors''). However, some latents appear to be spurious and unrelated to the semantics of their dataset. For example, 22\_headline\_isobama, which targets headlines published during the Obama administration, is classified with $0.782$ AUC by latent 10555, which activates on ``strings of numbers, often with mathematical notations.'' 
% For more latent examples, see \cref{tab:latents-description}, \cref{sec:app-latents}.

Note that these findings may be possible using baseline classifiers. For example, we could take a baseline classifier and apply it to model hidden states on tokens from the Pile \cite{pile} and then examine maximally activating examples. However, a practical advantage for SAEs is that the infrastructure to perform autointerp is pre-existing through platforms like Neuronpedia, and a theoretical advantage is that the baseline classifier can only identify the single most relevant coarse-grained feature, while the decomposability of SAE probes into latents allows for identifying many independent features of various importance.

% component fine-grained interpretability.

% and a theoretical advantage is that the baseline classifier might only identify spurious features through top activations if they are the ``most dominant'' feature, while SAEs do not have this limitation. 
% this baseline approach may only find examples with high activation on the largest latent. 


% We can look at individual latents to hopefully identify spurious correlations. We could do this with baselines but do not. We identify some interest categories, see \cref{tab:latents} for some examples.


% \begin{table*}[ht]
%     \centering
%     \caption{Example of a single latent for each category. See \cref{tab:app-latents} in \cref{sec:app-latents} for more examples.}
%     \begin{tabular}{p{3cm} c c c p{5cm}}
%     \textbf{Latent Category} & \textbf{Dataset} & \textbf{Latent Number} & \textbf{Test AUC} & \textbf{Latent Description} \\ \hline
%     Description Fits Task & 155\_athlete\_sport\_basketball & 83267 & 0.943 & references to basketball teams, players, and related sports terms. \\
%     Clever Latents & 100\_news\_fake & 31726 & 0.968 & references to conspiracy theories and secretive organizations. \\
%     Potentially Spurious & 22\_headline\_isobama & 10555 & 0.782 & strings of numbers, often with mathematical notations or identifiers. \\
%     Classified by Context Length (Spurious) & 161\_agnews\_0 & 106376 & 0.990 & sections of text related to mathematical or programming notation and expressions. \\
%     Task Shows Description is Imperfect & 125\_world\_country\_Italy & 50817 & 0.989 & names of researchers and scientific authors. \\
%     \end{tabular}
%     \label{tab:latents}
% \end{table*}


\subsection{Detecting Dataset Quality Issues}
\label{sec:dataset_interp}
We now investigate the top latents of two datasets, 87\_glue\_cola and 110\_aimade\_humangpt3. We find that although the latents identify errors in each dataset, baseline methods are also able to identify these dataset errors.

\subsubsection{GLUE CoLA}
We first examine 87\_glue\_cola, an established linguistic acceptability dataset. CoLA prompts are standard English sentences with $\mathrm{target} = 1$ if the sentence is grammatically correct and $0$ otherwise. Latent 369585 from the $\saelarge$ SAE has a test AUC of 0.76 and appears to fire on ungrammatical text. Surprisingly, when we look at prompts that latent 369585 fires on, those that it ``disagrees'' with the labels on (ones that are labeled grammatical), often appear to be ungrammatical. Although we first found this result with SAE probes, we later found that logistic regression was also capable of the same identification. In \cref{tab:cola}, we show the sentences that a baseline logistic regression classifier and latent 369585 mark as ungrammatical while the label is grammatical; most such sentences are truly ungrammatical. Thus, both SAE and baseline methods lead us to hypothesize that the CoLA dataset is partially mislabeled.

To test our hypothesis, we choose 3 LLMs - GPT-4o \citep{gpt4o}, Claude-3.5-Sonnet-New, and Llama-3.1-405B  Instruct \citep{llama3.1-8B} - to judge the linguistic acceptability of 1000 random CoLA prompts. We take the LLM majority vote as the ensembled, clean label. This is analogous to the experiment performed in \citet{warstadt-etal-2019-neural} that validated the CoLA dataset by ensembling the predictions of native English speakers, but with LLM judges instead of English speakers. We find that \~25\% of CoLA labels are mislabeled by this metric (higher than the 13\% disagreement rate from \citet{warstadt-etal-2019-neural}). Notably, the \cref{tab:cola} sentences are identified as ungrammatical by the ensemble while being labeled as grammatical in CoLA.



\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/Investigate/glue_cola_barchart.pdf}
    \vspace{-0.8cm}
    \caption{Latent 369585 outperforms a dense SAE probe and logistic regression when testing on mislabeled CoLA examples.}
    \label{fig:cola-results}
\end{figure}

Next, we train a baseline logistic regression, a $k=128$ dense SAE probe, and the latent 369585 classifier on the original CoLA labels. We then test on a held-out set with the clean, ensembled predictions. In \cref{fig:cola-results}, we find that the original labels, the baseline classifier, the dense SAE probe, and latent 369585 all have about the same accuracy on the clean labels. Remarkably, when we test all classifiers on examples which were misclassified in CoLA (where the ensembled labels disagree with the original labels), we find that the latent 369585 classifier outperforms the dense SAE probe, which itself outperforms the baseline considerably. 
% Thus, although SAE probes generally perform worse in our synthetic label corruption tests, in at least this limited task of classifying mislabeled data the SAE probe outperforms the baseline.


\subsubsection{AI vs Human}

\begin{figure}
    \centering
    \includegraphics[]{figures/Investigate/ai_vs_human_analysis.pdf}
    \vspace{-0.4cm}
    \caption{\textbf{Left:} Top 3 latents (w/ descriptions) by mean activation difference between AI generated and human SAE latent activations. \textbf{Right:} Histograms of the identity of the 4 most common last tokens in AI generated and human text.}
    \label{fig:ai-vs-human-results}
\end{figure}

% It is surprising that our probes do so well classifying AI vs. Human text.
% ; even with $k = 1$, the SAE probe gets FILL IN AUC. 
We also investigate 110\_aimade\_humangpt3, which tests if probes can distinguish between human and ChatGPT-3.5 generated text. Latent 105150 has an AUC of 0.82 on this task, yet appears to fire primarily on periods and punctuation.\footnote{See \href{https://www.neuronpedia.org/gemma-2-9b/20-gemmascope-res-131k/105150}{Neuronpedia} for examples.} Since this latent is syntactical and unrelated to the content of the dataset, we hypothesize it represents a spurious correlation in the dataset.
% SAE probes do suprisngly well on 
% % , as another case study, we look at the dataset 
% 110\_aimade \_humangpt3, a dataset testing whether probes can distinguish between human and AI text. Thus, as another case study we examine the latents from the $\saeneuronpedia$ SAE whose average values differ most between human and AI text (as in \cref{eqn:select_k_indices}). 
% We choose this SAE because of the availability of SAE firing data on Neuronpedia \cite{neuronpedia}. 
% As shown on the right side of \cref{fig:ai-vs-human-results}, the top latent fires mostly on periods (), while the next top two are both space latents (\href{https://www.neuronpedia.org/gemma-2-9b/20-gemmascope-res-131k/116246}{link 1} and \href{https://www.neuronpedia.org/gemma-2-9b/20-gemmascope-res-131k/3764}{link 2}). 
% This result suggests the dataset might have a spurious correlation, as how a sentence ends should be unrelated to whether it is AI or human generated. 

We examine the final token of each prompt in the dataset and indeed find a spurious feature: AI text is more likely to end in a period while human text is more likely to end in a space (see \cref{fig:ai-vs-human-results}). Although we discovered this by investigating SAE latents, we could reach the same conclusion with baselines: in \cref{tab:aimade-tokens} (\cref{sec:app_aimade}), we apply the logistic regression classifier to 2.8 million tokens from the Pile, and find that it is most active on punctuation tokens. 



\section{Why Didn't This Work: Illusions of SAE Probes}
\label{sec:why-didnt-this-work}
\label{sec:multi-token}
\citet{bricken2024features_classifiers} report that SAE probes outperform baselines slightly. A natural question is why our experiments fail to replicate this result. One possible explanation is that \citet{bricken2024features_classifiers}'s findings were based on a single dataset, whereas we evaluate across multiple datasets. We find that SAE probes outperform baselines on only a small subset of these datasets (2.2\%, see \cref{fig:multi_token}). It is possible that the dataset used by \citet{bricken2024features_classifiers} falls within this subset; however, without access to it, we cannot confirm this.


A separate explanation involves a potential illusion due to insufficiently strong baselines. Unlike our work, \citet{bricken2024features_classifiers} uses multi-token SAE probing: they aggregate the maximum value for each latent across all prompt tokens, while we only use last token latents. Crucially, they similarly max-pool each model dimension across prompt tokens for their comparative baseline, even though activations are unlikely to have privileged dimensions (in \cref{tab:multi_token} we show that pooling activations in this way works poorly). We implement multi-token SAE probing using max-aggregation on $60$ random datasets from our list and $k = 128$; see \cref{tab:multi_token} for full results on these datasets. We \textit{also} implement a better baseline: we train attention-pooled probes of the form
\begin{align}
\label{eqn:multi-token}
    \left[\textrm{softmax}_{t \in [1, CtxLen]}\{X^l_t \cdot q\} \right] \cdot \left[X^l \cdot v\right]
\end{align}
for $q, v \in \mathbb{R}^d$. We find that when compared to the last-token baseline, max-pooled SAE probes win $19.6\%$ of the time, a considerable improvement over win rate of last-token SAE probes (2.2\%, see \cref{fig:multi_token}). However, when implementing attention-pooled baselines and using the quiver of arrows approach to select between pooled and last-token strategies for SAE probes and baselines, the SAE probe win rate drops more than $50\%$ to $8.7\%$ (see \cref{fig:multi_token}). 

 

\begin{figure}
    \centering
    \includegraphics[]{figures/Multi-token/consolidated_probing_comparison_bars_unbinarized.pdf}
    \vspace{-0.4cm}
    \caption{Illustration of a potentially misleading result we find: when comparing activation probes to pooled SAE probes, SAE probe win rate increases considerably, but adding in a ``pooled'' attention-inspired probe brings down the SAE win-rate. }
    \label{fig:multi_token}
\end{figure}

\section{Assessing Improvements in SAE Architectures}
While SAE probes do not robustly outperform baselines, a separate interesting question is whether recent SAE architectural developments have improved SAE probing performance. We investigate this question by examining the performance of eight different SAE architectures released in the last two years, as outlined in \cref{tab:saes}.


\begin{table}[t]
\centering
\caption{Timeline of SAE Architecture Improvements.}
\begin{tabular}{ll}
\hline
\textbf{SAE Architecture} & \textbf{Publication Date} \\
\hline
\begin{tabular}[t]{@{}l@{}}ReLU (original) \\ \citet{dictionary_monosemanticity_anthropic}\end{tabular} & October 4, 2023 \\
\hline
\begin{tabular}[t]{@{}l@{}}ReLU (updated) \\ \citet{transformercircuitsCircuitsUpdates}\end{tabular} & April 26, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}Gated \\ \citet{rajamanoharan2024improving}\end{tabular} & May 1, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}TopK \\ \citet{gao2024scalingevaluatingsparseautoencoders}\end{tabular} & June 6, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}JumpReLU \\ \citet{rajamanoharan2024jumpingaheadimprovingreconstruction}\end{tabular} & July 19, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}BatchTopK \\ \citet{BatchTopK}\end{tabular} & July 19, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}p-annealing \\ \citet{karvonen2408measuring}\end{tabular} & July 31, 2024 \\
\hline
\begin{tabular}[t]{@{}l@{}}Matryoshka \\ \citet{bussmann2024matryoshka}\end{tabular} & December 19, 2024 \\
\hline
\end{tabular}
\label{tab:saes}
\end{table}
We use $\mathrm{width} = 16\mathrm{k}$ Gemma-2-2B layer $12$ SAEs with a variety of $\lzero$ values trained by \citet{neuronpediaSAEBenchComprehensive}. We create $k=16,128$ SAE probes on all regimes and datasets for each architecture, and additionally $k = 1$ for standard conditions. In \cref{fig:saeimprovement}, we plot each SAE architecture's $k=16$ probe performance in standard conditions. We find the average test AUC of each SAE and then take the max across $\lzero$ for each SAE architecture (using a single $\lzero$ value is somewhat noisy, see \cref{sec:app_improvements}). This metric tests how expressive individual SAE latents are for different SAE architectures. While we see a slight positive trend for probing performance with more recently released SAE architectures, the effect is not statistically significant. For plots in all regimes, see \cref{sec:app_improvements}; in other regimes there seems to be a possible slight improvement with newer SAE architectures.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/Improvement/boxplot_k=16.pdf}
    \caption{We see that there is a slight uptick in probing performance compared to baselines in standard conditions with more recent architectures. However, the spread of the data is considerably larger than this improvement.}
    \label{fig:saeimprovement}
\end{figure}

\section{Conclusion} 
Our evaluation of sparse autoencoders (SAEs) reveals fundamental limitations in current SAE methodologies. Despite expectations that interpretable SAE latents would provide a competitive advantage in probing, we found no improvement over traditional methods across multiple regimes and over 100 datasets. Some failures expose critical weaknesses -- for instance, SAE latents struggle to be robust to distributional shifts and fail to represent complex concepts -- while others are more mundane -- lower L0 SAEs create worse sparse probes. More broadly, our findings highlight the need for the field of mechanistic interpretability to evaluate techniques with rigorous baselines. While prior work reported advantages for SAE probes, our robust quiver of arrows methodology, use of stronger baselines, and evaluation on a large set of datasets demonstrate these advantages to be illusory. Even in our own analysis, initial conclusions favoring SAE interpretability were later overturned when proper baselines were considered. We do not consider this work to be a wholesale critique of the SAE paradigm. Instead, we view it as a single rigorously evaluated datapoint to contextualize SAE utility and to motivate a more thorough examination of methods in mechanistic interpretability.

\textbf{Limitations} We study the performance of SAE probes as a proxy for SAE utility. While we believe that probing performance is a more effective measurement than typical SAE evaluations like downstream cross-entropy loss or reconstruction error, it is ultimately still a proxy metric. We chose to study difficult probing regimes to try to find cases where the inductive bias of SAE latents outweighed imperfect SAE reconstruction, but it is possible that even a basis of ``true'' model representations would offer only a mild inductive bias advantage over traditional linear probing. We are thus excited for future work studying probing on toy models (e.g. models trained on board games \cite{karvonen2024measuring}) where the ``true'' model features are known. 

Finally, it is possible that further optimization of the SAE probe baseline might increase performance such that it beats baseline methods. For example, \citet{probingGallifant} find that SAE probing with a number of modifications (multi-token probes, binarization of latents, and probing with $k =$ full SAE dimension) beats baseline methods on safety-relevant datasets (albeit only comparing to single-token baseline probes). However, we believe a main takeaway of our paper is that equivalent effort should be put into optimizing baselines. Indeed, we examine the effect of binarizing latents in \cref{sec:app_binarize} and find that it does not significantly help.

\section{Acknowledgments}
This work was conducted as part of the ML Alignment \& Theory Scholars (MATS) Program. We would like to thank the members of the Tegmark group and Neel Nanda's MATS stream for helpful comments and feedback. JE was supported by the NSF Graduate Research Fellowship (Grant No. 2141064).

\section{Author Contributions}
JE and SK jointly led the project and wrote the paper. JE came up with the Quiver of Arrows approach, ran the SAE methods, discovered the initial GLUE CoLA and AI vs. Human results, discovered Gemma Scope SAE latent reliance on language, and ran multi-token experiments. SK cleaned a majority of the datasets, ran baseline methods, did the probe interpretability experiments, ran the main text covariate shift experiments, did follow-up experiments on dataset errors and latent interpretability, and made most of the final main body plots. SR and MT provided advice, guidance, and general mentorship, and edited the paper. NN was the primary senior author of the project and provided leadership, direction, and advice throughout.

% Chiefly, in standard conditions for probing, SAEs are naturally limited by the fact that they imperfectly reconstruct the input. Thus, we chose to study difficult probing regimes to attempt find cases where the inductive bias of SAE latents outweighed SAE's relative lack of expressiveness. 


% Even if SAEs perfectly decomposed model activations into ``true'' linear features, it's possible they still would not outperform baseline methods as the in standard probing conditions because . For example, a probing task that 

% a complex probing task that requires 150 linear model features. Using a $k = 128$ SAE probe is not expressive enough for this task, but traditional activation probing is likely to find the combined direction that represents the task well. Understanding this natural limitation of SAE probes, we chose to study difficult probing regimes to find cases where the inductive bias of SAE latents outweighed SAE's relative lack of expressiveness. However, we were unable to find advantages for SAE probes.
%Sparse autoencoders (SAEs) are a largely untested interpretability tool on legitimate downstream tasks. Mechanistic interpretability should 
% - MI has been accused been superfluous in explanations and tools
% - An example of this is sparse autoencoders, which despite their immense popularity, have been largely untested in mech interp
% - We evaluate SAEs on a grounded task to thoroughly underperform traditional methods when we expect some of their magic to translate to competitive advantages. 
% - The lack of competitive advantage indicates a potentially serious flaw in SAEs. For example, unrobust features
% - More broadly, mech interp studies should have more baselines like us, otherwise it's easy to get foolded (like Anthropic)
% - Case in point - we nearly got fooled when looking at probe interpretability
% - Our results are not a damning critique to SAEs, instead we view them as a single, low error bar datapoint on their viability


% We find that probes constructed from sparse autoencoder (SAE) latents underperform baselines in the regimes of data scarcity, class imbalance, label noise, and covariate shift when comprehensively tested on more than 100 datasets. While SAEs probes are intepretable and allow for the identification of dataset errors, we are able to achieve similar insights using traditional methods with additional analysis. Our work underscores the importance of rigorously evaluating interpretability techniques on downstream tasks and suggests the need to advance beyond current SAE methodologies to develop more effective interpretability tools.



% \section*{Impact Statement}


% % \section*{Acknowledgments}
% % \section*{Contribution}

% We are motivated by increasing our understanding of language models in our study of probing. There are many positive social impacts of such an increased understanding of models, including detecting deception, bias, and misalignment. Thus, we do not foresee any negative consequences of our work. 

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite


\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn


\section{Related Work}
\label{sec:app-related-work}

\subsection{Probing}
Probing has a rich history in computational neuroscience, where linear decoders were used to study information representation in biological neural networks \cite{mur2009revealing}. This technique was later adapted to study artificial neural networks by \citet{alain2016understanding}. Since then, probing has become a fundamental tool in neural network interpretability, revealing that many high-level concepts are linearly represented in model activations \cite{space_time, monotonic_numeric_representations, othello_neel_linear}. Similar to our work studying sparse probing, \citet{gurnee2023finding} study sparse probing of activations and identify individual monosemantic neurons by setting $k = 1$. Recent work has also used probing to study safety-relevant properties of language models, such as truthfulness \cite{linear_truth_sam} and the presence of sleeper agents \cite{macdiarmid2024sleeperagentprobes}, without relying on potentially unreliable model outputs. Two recent works have investigated the utility of SAEs for probing. First, \citet{bricken2024features_classifiers} investigate a synthetic bioweapons dataset and show that SAE probes can sometimes offer an advantage against baseline probes when aggregated across multiple tokens; we discuss these results in our section on multi-token probing in \cref{sec:why-didnt-this-work}. Second, \citet{probingGallifant} use feature binarization, multi-token feature pooling, and probing on the entire SAE vector to report that SAE probes outperform baselines. We discuss \citeauthor{probingGallifant}'s (\citeyear{probingGallifant}) results in our limitations section and in \cref{sec:app_binarize}.

\subsection{Challenges in Neural Network Interpretability}
Our work connects to broader concerns about the reliability of neural network interpretation methods. \citet{adebayo2018sanity} studied saliency methods, a classical technique for understanding models, and found that randomizing the model and dataset labels did not change many aspects of saliency maps; thus, while the method produced plausible-looking explanations, they were not faithful to the true model and dataset. Similarly, \cite{bolukbasi2021interpretability} demonstrated that seemingly interpretable neurons in BERT were artifacts of running on only a particular dataset rather than more general representations. For SAEs specifically, \cite{chanin2024absorption} identified feature absorption and splitting as fundamental challenges, \citet{gao2024scalingevaluatingsparseautoencoders} showed that SAEs have an irreducible error component, and in extremely recent work \citet{heap2025sparseautoencodersinterpretrandomly} show that SAEs trained on random models also result in interpretable features. Our work extends these critiques by finding that many settings where SAE probes were thought to be helpful turn out not to be when compared to stronger baselines.

\subsection{SAE and SAE Applications}
Sparse autoencoders (SAEs) provide a map from model activations to a sparse, higher dimensional latent space \cite{dictionary_monosemanticity_anthropic, other_sae_paper}. Individual latents are hypothesized to represent mono-semantic concepts LLMs use for computation. An SAE is parameterized by its $\mathrm{width}$, or the dimension of its latent space, and its $\lzero$, or how many latents are nonzero on average. While our work focuses on evaluating SAEs as probing tools, prior work has explored various downstream applications of SAEs. \citet{templeton2024scaling} first used SAE latents for steering, and in follow-up work \citet{chalnev2024improving} found that SAEs can help find better steering vectors (although see \cite{wu2025axbenchsteeringllmssimple} for a very recent work finding that SAEs are not competitive for steering). \citet{neuronpediaSAEBenchComprehensive} implement a set of comprehensive benchmarks for evaluating SAE performance, including SHIFT \cite{marks2024sparse}, sparse probing, unlearning, and feature absorption. Recent work has also used SAEs to interpret preference models \cite{smith2024sparse_autoencoders} and prevent unwanted behavior in model output \cite{karvonen2024sieve}, both specific applications where SAEs seem to be state of the art. 


\section{Classification Datasets}
\label{sec:app_class_datasets}
Below we list in a (large) table all of the classification datasets we use, as well as their source. 

% Updated table
% Caption and label should come after \begin{longtable} in the first header
\begin{longtable}{ll}
\caption{Binary classification tasks used.\label{tab:app_all_tasks}} \\  % Add caption and label
\hline
\textbf{Citation} & \textbf{Dataset Name} \\ \hline
\endfirsthead

\hline
\textbf{Citation} & \textbf{Dataset Name} \\
\hline
\endhead

\hline
\multicolumn{2}{r}{Continued on next page} \\
\endfoot

\hline
\endlastfoot

\citet{gurnee2024language}
  & 5\_hist\_fig\_ismale \\
  & 6\_hist\_fig\_isamerican \\
  & 7\_hist\_fig\_ispolitician \\
  & 21\_headline\_istrump \\
  & 22\_headline\_isobama \\
  & 23\_headline\_ischina \\
  & 24\_headline\_isiran \\
  & 26\_headline\_isfrontpage \\
  & 114\_nyc\_borough\_Manhattan \\
  & 115\_nyc\_borough\_Brooklyn \\
  & 116\_nyc\_borough\_Bronx \\
  & 117\_us\_state\_FL \\
  & 118\_us\_state\_CA \\
  & 119\_us\_state\_TX \\
  & 120\_us\_timezone\_Chicago \\
  & 121\_us\_timezone\_New\_York \\
  & 122\_us\_timezone\_Los\_Angeles \\
  & 123\_world\_country\_United\_Kingdom \\
  & 124\_world\_country\_United\_States \\
  & 125\_world\_country\_Italy \\
  & 126\_art\_type\_book \\
  & 127\_art\_type\_song \\
  & 128\_art\_type\_movie \\
\citet{SciQ}
  & 36\_sciq\_tf \\
\citet{lin-etal-2022-truthfulqa}
  & 41\_truthqa\_tf \\
\citet{ZKNR19}
  & 42\_temp\_sense \\
  & 130\_temp\_cat\_Frequency \\
  & 131\_temp\_cat\_Typical Time \\
  & 132\_temp\_cat\_Event Ordering \\
\citet{Bisk2020}
  & 44\_phys\_tf \\
\citet{quartz}
  & 47\_reasoning\_tf \\
\citet{hendrycks2021ethics}
  & 48\_cm\_correct \\
  & 49\_cm\_isshort \\
  & 50\_deon\_isvalid \\
  & 51\_just\_is \\
  & 52\_virtue\_is \\
\citet{talmor2022commonsenseqa}
  & 54\_cs\_tf \\
\citet{gurnee2023finding}
  & 56\_wikidatasex\_or\_gender \\
  & 57\_wikidatais\_alive \\
  & 58\_wikidatapolitical\_party \\
  & 59\_wikidata\_occupation\_isjournalist \\
  & 60\_wikidata\_occupation\_isathlete \\
  & 61\_wikidata\_occupation\_isactor \\
  & 62\_wikidata\_occupation\_ispolitician \\
  & 63\_wikidata\_occupation\_issinger \\
  & 64\_wikidata\_occupation\_isresearcher \\
  & 65\_high-school \\
  & 66\_living-room \\
  & 67\_social-security \\
  & 68\_credit-card \\
  & 69\_blood-pressure \\
  & 70\_prime-factors \\
  & 71\_social-media \\
  & 72\_gene-expression \\
  & 73\_control-group \\
  & 74\_magnetic-field \\
  & 75\_cell-lines \\
  & 76\_trial-court \\
  & 77\_second-derivative \\
  & 78\_north-america \\
  & 79\_human-rights \\
  & 80\_side-effects \\
  & 81\_public-health \\
  & 82\_federal-government \\
  & 83\_third-party \\
  & 84\_clinical-trials \\
  & 85\_mental-health \\
\citet{wang2018glue}
  & 87\_glue\_cola \\
  & 89\_glue\_mrpc \\
  & 90\_glue\_qnli \\
  & 91\_glue\_qqp \\
  & 92\_glue\_sst2 \\
  & 136\_glue\_mnli\_entailment \\
  & 137\_glue\_mnli\_neutral \\
  & 138\_glue\_mnli\_contradiction \\
\citet{kaggleHumanText}
  & 94\_ai\_gen \\
\citet{lin2023toxicchat}
  & 95\_toxic\_is \\
\citet{kaggleSpamText}
  & 96\_spam\_is \\
\citet{kaggleFakeandrealnewsdataset}
  & 100\_news\_fake \\
\citet{huggingfaceRkotariclickbaitDatasets}
  & 105\_click\_bait \\
\citet{hateoffensive}
  & 106\_hate\_hate \\
  & 107\_hate\_offensive \\
\citet{aihumanmade}
  & 110\_aimade\_humangpt3 \\
\citet{Pang+Lee:05a}
  & 113\_movie\_sent \\
\citet{huggingfaceAllenaibasic_arithmeticDatasets}
  & 129\_arith\_mc\_A \\
\citet{DBLP:conf/aaai/RogersKDR20}
  & 133\_context\_type\_Causality \\
  & 134\_context\_type\_Belief\_states \\
  & 135\_context\_type\_Event\_duration \\
\citet{kaggleTextClassification}
  & 139\_news\_class\_Politics \\
  & 140\_news\_class\_Technology \\
  & 141\_news\_class\_Entertainment \\
\citet{kaggleMedicalText}
  & 142\_cancer\_cat\_Thyroid\_Cancer \\
  & 143\_cancer\_cat\_Lung\_Cancer \\
  & 144\_cancer\_cat\_Colon\_Cancer \\
\citet{kaggleMedicalText2}
  & 145\_disease\_class\_digestive system diseases \\
  & 146\_disease\_class\_cardiovascular diseases \\
  & 147\_disease\_class\_nervous system diseases \\
\citet{kaggleEmotionDetection}
  & 148\_twt\_emotion\_worry \\
  & 149\_twt\_emotion\_happiness \\
  & 150\_twt\_emotion\_sadness \\
\citet{kaggleServiceTicket}
  & 151\_it\_tick\_HR Support \\
  & 152\_it\_tick\_Hardware \\
  & 153\_it\_tick\_Administrative rights \\
\citet{statheadStatheadYour}
  & 154\_athlete\_sport\_football \\
  & 155\_athlete\_sport\_basketball \\
  & 156\_athlete\_sport\_baseball \\
\citet{neuronpediaSAEBenchComprehensive}
  & 157\_amazon\_5star \\
  & 158\_code\_C \\
  & 159\_code\_Python \\
  & 160\_code\_HTML \\
  & 161\_agnews\_0 \\
  & 162\_agnews\_1 \\
  & 163\_agnews\_2 \\
\end{longtable}


\section{Probing Setup}
\subsection{AUC}
\label{sec:app_auc_explainer}
The Area Under the Curve (AUC) quantifies the overall performance of a binary classifier using the Receiver Operating Characteristic (ROC) curve. An ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold levels, illustrating the trade-offs between correctly predicting positives and incorrectly predicting negatives. The AUC, ranging from 0 to 1, measures the entire two-dimensional area beneath this curve. An AUC of 1.0 signifies perfect classification, 0.5 indicates performance no better than random chance, and closer to 0 implies poor classification. This metric provides a single, aggregate measure of performance across all possible classification thresholds, making it particularly useful for 
comparing different classifiers.

Technically, when choosing $k$ and the baseline SAE to use for the other section, we use test AUC on normal datasets, which constitutes a slight leakage of test data. However, we used trends observed over a large number of datasets, in the same way we might provide heuristics for constructing SAE probes to a future practitioner.

\subsection{Probing Method Validation Details}
For each strategy, we use $h_p$ that has the maximal average AUC across held out validation sets, $\mathrm{AUC}_p^{\mathrm{val}}$. We choose a validation method from \cref{tab:crossval} based on the dataset size $n$ (most of the time this is the last row in the table for large $n$, except for the low data regime tests).

\begin{table}[h]
    \centering
    \vspace{-0.4cm}
    \caption{Selection methods to choose hyperparameters $h_p$ when training on different dataset sizes}
    \vspace{0.2cm}
    \begin{tabular}{|c|p{5.3cm}|}
    \hline
    Data Size ($n$) & Selection method for probe $p$ \\
    \hline
    $n \leq 3$ & Train $p$ with each $h_p$ on all $n$ points; choose $h_p$ which maximizes AUC on training set. \\
    \hline
    $3 < n \leq 12$ & Use leave-two-out cross validation; train $p$ with each $h_p$ on all training splits of size $n - 2$ and evaluate on the last 2 held out points \\
    \hline
    $12 < n \leq 128$ & Use 6-fold cross validation; split $n$ in sixths, train $p$ with each $h_p$ on all sets of 5 splits, and evaluate on the remaining fold \\
    \hline
    $n > 128$ & Use 80\%/20\% training/validation split \\
    \hline
    \end{tabular}
    \label{tab:crossval}
\end{table}

\subsection{Probing Method Hyperparameter Details}
In this section, we list each baseline method and the hyperparameters that we search over for that method. 

\label{sec:app_probe_hyperparam}
\begin{itemize}
    \item \textbf{Logistic Regression}:
    \begin{itemize}
        \item $C$: Ranges logarithmically from $10^5$ to $10^{-5}$. The $L_2$/$L_1$ regularization is $1/C$.
    \end{itemize}
    \item \textbf{PCA Regression}:
    \begin{itemize}
        \item Number of PCA Components: Varies logarithmically from 1 up to the minimum of the number of samples, latents, or 100.
    \end{itemize}
    \item \textbf{K-Nearest Neighbors (KNN)}:
    \begin{itemize}
        \item Number of Neighbors: Logarithmically spaced values up to the smaller of 100 or the number of samples minus one.
    \end{itemize}
    \item \textbf{XGBoost}:
    \begin{itemize}
        \item $\mathrm{n\_estimators}$: Ranges from 50 to 250 in steps of 50.
        \item $\mathrm{max\_depth}$: Ranges from 2 to 5.
        \item $\mathrm{learning\_rate}$: Ranges logarithmically from 0.001 to 0.1.
        \item $\mathrm{subsample}$ and $\mathrm{colsample\_bytree}$: Range from 0.7 to 1.0.
        \item $\mathrm{reg\_alpha}$ and $\mathrm{reg\_lambda}$: Range logarithmically from 0.001 to 10.
        \item $\mathrm{min\_child\_weight}$: Ranges from 1 to 9.
    \end{itemize}
    \item \textbf{Multilayer Perceptron (MLP)}:
    \begin{itemize}
        \item Network depth: 1 to 3 hidden layers
        \item Hidden layer width: 16,32, or 64.
        \item $\mathrm{learning\_rate\_init}$: Five values ranging logarithmically from $10^{-4}$ to $10^{-2}$.
        \item $\mathrm{alpha}$: Weight decay parameter, with 5 values ranging logarithmically from $10^{-5}$ to $10^{-2}$.
        \item Activation function: ReLU.
        \item Optimizer: Adam.
    \end{itemize}
\end{itemize}

\subsection{Formal Discussion of Quiver of Arrows}
\label{app:quiver}
The quiver of arrows can be defined formally as follows. Given a set of probing methods $P = p_1, \ldots, p_n$ (listed in Section \ref{sec:probing_methods}), we find $\mathrm{AUC}^{\mathrm{val}}_{p_i}$ for each method using the procedure described in \cref{sec:probing_strat}. We then choose the probing method $p_*$ with maximal $\mathrm{AUC}^{\mathrm{val}}_{p_i}$ and record its $\mathrm{AUC}^{\mathrm{test}}_P = \mathrm{AUC}^{\mathrm{test}}_{p_*}$. We can then compare $\mathrm{AUC}^{\mathrm{test}}_P$ to $\mathrm{AUC}^{\mathrm{test}}_{P'}$ for a different set of methods $P' = p_1', \ldots, p_n'$. If we let $P$ be a set of baseline methods, and $P' = P \cup \{\text{SAE probes}\}$, then $\mathrm{AUC}^{\mathrm{test}}_{P'} - \mathrm{AUC}^{\mathrm{test}}_P$ directly represents the increase in test performance when adding SAE probes to a practitioner's toolbox. We then aggregate $\mathrm{AUC}^{\mathrm{test}}_P - \mathrm{AUC}^{\mathrm{test}}_{P'}$ across many different datasets and testing regimes (e.g., dataset size) to give an overall sense of the improvement due to SAE probing.
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Normal/full_baselines_by_layer_normal.pdf}
        \caption{Layer 20 is best for baselines.}
        \label{fig:app-baseline-layer}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Normal/best_method_by_layer.pdf}
        \caption{Logistic regression is often the most performant across datasets.}
        \label{fig:app-normal-stackplot}
    \end{subfigure}
    \caption{Analysis of layer performance and methods. (a) Shows the optimal layer for baseline performance. (b) Demonstrates the effectiveness of different methods across layers.}
    \label{fig:combined-analysis}
\end{figure}
We note that adding a batch of SAE probes as additional arrows to the quiver is potentially disadvantageous for SAE probes. This is because using multiple SAE probes presents additional opportunities for these probes to overfit to the training data and be chosen by the quiver of arrows approach without properly generalizing to the test data. Regardless, we see the quiver of arrows as a proper counterfactual for a practitioner without SAE probes. Additionally, the quiver of arrows approach is not the reason we find negative results for SAE probes. For instance, in \cref{fig:fig1}, we directly compare the test AUC of the most performant SAE probe and baseline in standard conditions across all regimes. Without using the quiver of arrows approach, we still find SAEs underperform baselines.

\section{Normal Conditions}



\subsection{Evaluating Baselines}
\label{sec:app_baselines}

We see that layer 20 is best for baselines, so we choose to use that layer moving forward (\cref{fig:app-baseline-layer}). Logistic regression most often has the highest test AUC across datasets in these conditions at layer 20 (\cref{fig:app-normal-stackplot}).



\subsection{Choosing which SAEs to Test}
\label{sec:app_sae_normal}
When constructing a pareto curve based on the width and L0 of all available SAEs at layer 20 of Gemma-2-9B, we find that width is unimportant, while constructing probes from a higher L0 seems to improve probe performance (\cref{fig:app_sae_width_l0_pareto}).

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Normal/sae_pareto_l0_width_layer20.pdf}
        \caption{We find that L0 is important in creating effective probes, while width plays a minimal role. Test AUC averaged over all values of $k$ and datasets.}
        \label{fig:app_sae_width_l0_pareto}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Normal/sae_width_auc.pdf}
        \caption{When averaging over other factors, smaller width SAEs perform best as probes. However, the relationship is minimal.}
        \label{fig:app_sae_width}
    \end{subfigure}
    \caption{Analysis of SAE width and L0 regularization effects on probe performance. (a) Shows the Pareto frontier of L0 vs width trade-offs. (b) Illustrates the relationship between SAE width and probe performance.}
    \label{fig:combined-sae-analysis}
\end{figure}

To ensure that width plays a minimal role, we average over all datasets, $k$, and L0s in \cref{fig:app_sae_width}. There is a clear negative trend indicating that smaller SAE widths are better, but with almost 0 slope. Because we aim to make as few decisions based off the test data as possible, we consider three widths throughout our experiments, $16,000$, $131,000$, and $1,000,000$.



\subsection{Plotting Dataset Performance vs. K}
In \cref{fig:all_datasets_vs_k}, we show the performance on all datasets vs. the number of latents we train the sparse probe on. Almost all datasets are monotonically increasing in $k$; some have a sharp increase at some $k$ value, but most increase relatively smooththly.

\begin{figure*}
    \centering        
\includegraphics[height=8.8in]{figures/Normal/test_auc_vs_k_by_dataset_layer_20_width_1m_average_l0_193.pdf}
    \label{All datasets vs k}
    \vspace{-0.4cm}
    \caption{Test AUC on all datasets vs. $k = |\mathcal{I}|$ using the Gemma Scope layer 20 SAE with width 131k and $L_0 = 193$.}
    \label{fig:all_datasets_vs_k}
\end{figure*}

\section{Additional Results for Various Regimes}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/combined_analysis.pdf}
    \caption{Improvement from using SAE methods in the quiver across all datasets for various corruption ratios, ratios of positive classes, and number of training examples}
    \label{fig:app-all-metrics-all-datasets}
\end{figure}

\label{sec:app-regimes}
\subsection{Data Scarcity}
\label{sec:app-scarcity}
In the data scarce setting, we see that we choose mostly the SAE method from the quiver at smaller training fractions (\cref{fig:app-scarcity-methods}). This is because we break ties by explicitly preferring the SAE method, and most methods have perfect validation AUC at small training fractions. Specifically, we first prefer the smallest width SAE, and then the SAE with the largest value of $k$. In \cref{fig:app-all-metrics-all-datasets}, we visualize the improvement by using the quiver of arrows approach with SAE probes across all datasets.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\linewidth]{figures/Scarcity/dataset_imshow_scarcity.pdf}
%     \caption{Improvement with the }
%     \label{fig:app-scarcity-imshow}
% \end{figure}


% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\linewidth]{figures/Imbalance/dataset_imshow_imbalance.pdf}
%     \caption{We present the improvement from using the SAE methods in the quiver across all datasets for various class imbalance ratios.}
%     \label{fig:app-imbalance-imshow}
% \end{figure}

\subsection{Class Imbalance}
\label{sec:class-imbalance}
We show the improvement for all datasets in \cref{fig:app-all-metrics-all-datasets} across all class imbalances. Generally, the SAE method is chosen at more extreme imbalance ratios (\cref{fig:app-imbalance-stackplot})


\subsection{Label Corruption}
We show the performance of the SAE across datasets with all values of label corruption. Interestingly, the SAE still has highest test AUC at many places (\cref{fig:app-corrupt-stackplot} shows the percent of time that the SAE test AUC is larger). However, it is clear from the per dataset imshow (\cref{fig:app-all-metrics-all-datasets}) that it struggles with more label noise.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Scarcity/stack_scarcity.pdf}
        \caption{SAE probes are chosen by our method at small training fractions because multiple methods have perfect validation AUC and we break ties by choosing an SAE probe.}
        \label{fig:app-scarcity-methods}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Imbalance/stack_imbalance.pdf}
        \caption{SAE probes are generally chosen at more extreme imbalances.}
        \label{fig:app-imbalance-stackplot}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.31\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Corrupted/stack_corrupt.pdf}
        \caption{Corruption fraction has a minor influence on the percent of time SAE probes or logistic regression probes are chosen.}
        \label{fig:app-corrupt-stackplot}
    \end{subfigure}
    \caption{Method selection analysis under different data conditions. (a) Selection under data scarcity. (b) Selection under class imbalance. (c) Selection under data corruption.}
    \label{fig:combined-method-selection}
\end{figure}





\section{Reproducing Core Results on Llama-3.1-8b}
\label{sec:app-llama}
We use SAEs provided by Llama Scope to replicate our core results, namely, that SAEs underperform baseline probes in normal, data scarce, class imbalance, and label noise settings when testing on Llama-3.1-8B. In \cref{fig:app-llama-layers}, we show the results for baseline probes applied to various layers of Llama-3.1-8b in standard settings. We see that the layer roughly halfway through the model, layer 16, is best for probing experiments. In \cref{fig:app-llama-normal}, we show that SAE probes in normal settings on layer 16 of Llama-3.1-8b are not more performant than baselines, although there are a few positive outliers we did not observe in Gemma-2-9b. Lastly, we use the quiver of arrows approach to show that SAE probes are not more performant in the conditions of data scarcity, class imbalance, and label noise (\cref{fig:app-llama-quivers}). Because of the increased effort of testing OOD and interpretability, we do not replicate those results. Note that in all experiments, we use the provided width 128k, L0 55 SAE.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/llama/full_baselines_by_layer_normal_llama-3.1-8b.pdf}
        \caption{When testing baseline methods at different layers of Llama-3.1-8b, we find the middle layer 16 works best by a slim margin.}
        \label{fig:app-llama-layers}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/llama/sae_vs_nosae_normal_comparison.pdf}
        \caption{In standard conditions, we see that SAE probes are not statistically more performant than baselines for Llama-3.1-8b}
        \label{fig:app-llama-normal}
    \end{subfigure}
    \caption{Analysis of Llama-3.1-8b probe performance. (a) Layer-wise performance of baseline methods. (b) Comparison between SAE and baseline probes under standard conditions.}
    \label{fig:combined-llama-analysis}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/llama/quiver_improve_regimes.pdf}
    \caption{We find that Llama-3.1-8b SAE probes do not improve on baselines in the settings of data scarcity, class imbalance, and label noise.}
    \label{fig:app-llama-quivers}
\end{figure}


\section{Interpretability}
\subsection{Pruning}
\label{sec:app-pruning}
We demonstrate the latent ranking procedure for the task 66\_living-room in \cref{tab:latents-description}. We see that pruning works, for two of the tasks, 66\_living-room and 90\_glue\_qnli, while failing for 7\_hist\_fig\_ispolitician (\cref{fig:ood-pruning}). However, even when pruning works, the improvement is marginal compared to the decrease in performance when moving from an in-distribution test set to an OOD test set. Thus, we hypothesize that the underlying latents are not sufficiently expressive. For example, latent 122774 is most active on the English translation of ``living room,'' and not activate at all for the French translation (\cref{fig:ood-living-room}). This indicates this latent does not sufficiently represent the concept of ``living room'' to be robust to OOD transformations.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/OOD/OOD_pruned.pdf}
    \caption{Two datasets improve with pruning, but one does not. Indicates that it needs more latents to construct answer.}
    \label{fig:ood-pruning}
\end{figure}


\begin{table}[h!]
    \centering
    \caption{Description of Latent Variables for Out-of-Distribution Detection. We find that this procedure ranks latents roughly according to their OOD test AUC, even though o1 did not have access to this information. However, the system is not perfect. For example, latent 51330's natural language description is ranked last and seems unreleated to the task at hand. However, its OOD test AUC is the highest of all latents. We do not investigate this further, but hypothesize that either the latent descriptions require additional tuning, or the test set truly has some spurious quality that this latent identifies.}
    \begin{tabular}{|c|c|p{5cm}|c|c|}
    \hline
\makecell{\textbf{Latent}\\ \textbf{}} & \makecell{\textbf{o1}\\ \textbf{rank}} & \makecell{\textbf{Latent}\\ \textbf{Description}} & \makecell{\textbf{Val ID}\\ \textbf{AUC}} & \makecell{\textbf{Test OOD}\\ \textbf{AUC}}\\ \hline
    122774 & 1 & mentions of living rooms or parlors in houses or apartments. & 1.0 & 0.6402 \\
    98707 & 2 & phrases and words related to locations or settings, particularly indoor spaces like rooms, parlors, or living areas, as well as time references like afternoon or specific times. & 0.8698 & 0.6177 \\
    100016 & 3 & mentions of rooms or enclosed spaces, particularly when discussing physical locations or settings. & 0.6895 & 0.4736 \\
    7498 & 4 & locations within a house, particularly upstairs, downstairs, basement, bathroom, and kitchen areas. & 0.7524 & 0.6206 \\
    78823 & 5 & words and phrases related to specific places, attractions, and experiences, particularly in the context of travel and tourism. & 0.6697 & 0.4526 \\
    116246 & 6 & numbers, dates, and numerical measurements, particularly in scientific or technical contexts. & 0.7470 & 0.5398 \\
    40168 & 7 & technical terms and components related to computer systems, engineering, and scientific analysis. & 0.9219 & 0.4513 \\
    51330 & 8 & objects and materials related to scientific experiments and laboratory equipment, particularly those involving fluids, particles, or microscopic samples. & 0.7320 & 0.6483 \\ \hline
    \end{tabular}
    \label{tab:latents-description}
\end{table}





\subsection{Latent Investigation}
\label{sec:app-latents}

We generate natural language descriptions of all the latents with GPT-4o. We find that most are either relevant to the task or visibly spurious. We hypothesize that some latents have incomplete descriptions given their performance on the task. We list a selection of the most interesting of these latents from each category in \cref{tab:app-latents}.

\begin{table}[ht]
    \centering
    \caption{Latent categorization, characteristics, and performance.}
    \begin{tabular}{p{2cm} c p{1cm} p{1cm} p{5.5cm}}
    \textbf{Latent Category} & \textbf{Dataset} & \textbf{Latent Number} & \textbf{Test AUC} & \textbf{Latent Description} \\ \hline
    Description Fits Task & 5\_hist\_fig\_ismale & 81210 & 0.892 & references to female individuals, especially focusing on pronouns and names. \\
     & 61\_wikidata\_occupation\_isactor & 91505 & 0.830 & names of well-known actors and film industry personalities. \\
     & 66\_living-room & 122774 & 0.999 & references to specific rooms in a house, particularly living rooms and parlors. \\
     & 155\_athlete\_sport\_basketball & 83267 & 0.943 & references to basketball teams, players, and related sports terms. \\ \hline
    Clever Latents & 96\_spam\_is & 35460 & 0.907 & keywords and phrases related to text messaging and SMS communications. \\
     & 100\_news\_fake & 31726 & 0.968 & references to conspiracy theories and secretive organizations. \\ \hline
    Potentially Spurious & 21\_headline\_istrump & 22915 & 0.812 & numerical dates and percentages within a political or historical context. \\
     & 22\_headline\_isobama & 10555 & 0.782 & strings of numbers, often with mathematical notations or identifiers. \\
     & 110\_aimade\_humangpt3 & 105150 & 0.816 & statistical or numerical data and measurements. \\
     & 133\_context\_type\_Causality & 89524 & 0.947 & questions or questioning phrases, particularly those beginning with "Why?". \\
     & 134\_context\_type\_Belief\_states & 113152 & 0.638 & words related to status or condition in technical or medical contexts. \\
     & 135\_context\_type\_Event\_duration & 18897 & 0.876 & questions and phrases related to cost or quantity. \\ \hline
    Classified by Context Length (Spurious) & 49\_cm\_isshort & 106376 & 1.000 & sections of text related to mathematical or programming notation and expressions. \\
     & 161\_agnews\_0 & 106376 & 0.990 & sections of text related to mathematical or programming notation and expressions. \\
     & 162\_agnews\_1 & 106376 & 0.988 & sections of text related to mathematical or programming notation and expressions. \\
     & 163\_agnews\_2 & 106376 & 0.991 & sections of text related to mathematical or programming notation and expressions. \\ \hline
    Task Shows Latent Description is Imperfect & 105\_click\_bait & 78823 & 0.967 & mentions of specific events, activities, or items in particular locations or settings. \\
     & 123\_world\_country\_United\_Kingdom & 100153 & 0.978 & information related to professional roles, locations, and organizations. \\
     & 125\_world\_country\_Italy & 50817 & 0.989 & names of researchers and scientific authors. \\
    \end{tabular}
    \label{tab:app-latents}
\end{table}


% \subsection{Dataset Investigation}

\subsection{Glue CoLA}

In \cref{tab:cola}, we show the top 5 examples where latent 369585 and the activation probe have the highest confidence that a prompt is ungrammatical, but it is (incorrectly) labeled as grammatical in the CoLA ground truth.

\begin{table*}[t]
    \centering
    \caption{\textbf{Left} We show the top 5 examples where latent 369585 is active while the CoLA prompt is labeled as grammatical. Most of these sentences are clearly ungrammatical, which illustrates that the CoLA data is corrupted. \textbf{Right} We then look at sentences a baseline classifier trained on CoLA marks as ungrammatical when the label is grammatical. We reach the same conclusion - the CoLA data is mislabeled.}
    \begin{minipage}{.5\textwidth}
        \centering
        \begin{tabular}{@{}p{6.25cm}c@{}}
        \toprule
        \textbf{Prompt (Labeled Grammatical)} & \textbf{Latent 369585} \\ \midrule
        I don't remember what all I said? & 23.09 \\
        Aphrodite said he would free the animals and free the animals he will & 15.87 \\
        Gilgamesh wanted to seduce Ishtar, and seduce Ishtar he did. & 14.92 \\
        An example of these substances be tobacco. & 14.85 \\
        He will can go & 14.43 \\ \bottomrule
        \end{tabular}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \begin{tabular}{@{}p{6.25cm}c@{}}
        \toprule
        \textbf{Prompt (Labeled Grammatical)} & \textbf{P(y=0)} \\ \midrule
        Rub the cloth on the baby torn. & 0.933 \\
        In front of them happen. & 0.926 \\ \\
        Who did you give pictures of to friends of? & 0.911 \\ \\
        An example of these substances be tobacco. & 0.893 \\
        Susan hopes herself to sleep. & 0.890 \\ \bottomrule
        \end{tabular}
    \end{minipage}
    \label{tab:cola}
\end{table*}


\subsection{AI Made}
\label{sec:app_aimade}
In \cref{tab:aimade-tokens}, we show the tokens that the 110\_aimade\_humangpt3 classifier activates on across the pile with the highest average activation. Like the SAE feature, the baseline classifier has top activations on punctuation tokens.
\begin{table}[ht]
    \centering
    \caption{Logistic regression classifier for 110\_aimade\_humangpt3's top activating tokens when run on more than 2.5 million tokens from the Pile. The classifier predominantly activates on punctuation. Only tokens with at least 10 occurences shown.}
    \begin{tabular}{lcc}
    \hline
    \textbf{Token} & \textbf{Mean Activation} & \textbf{Occurrences} \\
    \hline
    \textless bos\textgreater & 6.8863 & 7625 \\
    !). & 6.2529 & 10 \\
    Q & 6.2271 & 1436 \\
    ”. & 6.0338 & 144 \\
    .” & 5.9111 & 975 \\
    .). & 5.7334 & 24 \\
    \textvisiblespace & 5.5035 & 17 \\
    ." & 5.4455 & 1057 \\
    ``. & 5.4132 & 319 \\
    \}\$. & 5.3990 & 24 \\
    \hline
    \end{tabular}
    \label{tab:aimade-tokens}
\end{table}




\section{Multiple tokens results}
In \cref{tab:multi_token}, we show a comparison of all methods (including the attention based probes and multi-token SAE methods discussed in \cref{sec:multi-token}) on a random sample of 60 datasets.
\begin{table}
\centering
\caption{Comparison of different logistic regression (``base'') and SAE probing methods on a selection of 60 random datasets. Last is last token probing as in the rest of our paper, concat is concatenating the top 20 PCA dimensions of all tokens, mean is taking the mean across activation dimensions across the context, max is taking the max across activation dimensions across the context, and Attn-like probe is described in \cref{sec:multi-token}.}
\label{tab:multi_token}
\begin{tabular}{lcccccccccc}
\toprule
Dataset & \makecell{Base\\(last)} & \makecell{Base\\(concat)} & \makecell{SAE\\(last)\\l0=68} & \makecell{SAE\\(mean)\\l0=68} & \makecell{SAE\\(max)\\l0=68} & \makecell{SAE\\(last)\\l0=408} & \makecell{SAE\\(mean)\\l0=408} & \makecell{SAE\\(max)\\l0=408} & \makecell{Attn\\-Like\\Probe} \\
\midrule
6\_hist\_fig & $\textbf{0.990}$ & 0.977 & 0.982 & 0.914 & 0.984 & 0.983 & 0.883 & 0.985 & 0.987 \\
7\_hist\_fig & 0.750 & 0.698 & 0.738 & 0.661 & 0.739 & 0.746 & 0.613 & 0.738 & $\textbf{0.760}$ \\
21\_headlin & 0.987 & 0.986 & 0.950 & 0.993 & $\textbf{1.000}$ & 0.964 & 0.990 & 1.000 & 1.000 \\
24\_headlin & 0.991 & 0.979 & 0.892 & 0.995 & 0.997 & 0.947 & 0.994 & $\textbf{0.998}$ & 0.996 \\
44\_phys\_tf & 0.885 & 0.541 & 0.836 & 0.657 & 0.760 & 0.854 & 0.656 & 0.790 & $\textbf{0.903}$ \\
48\_cm\_corr & 0.833 & 0.659 & 0.788 & 0.699 & 0.779 & 0.794 & 0.708 & 0.784 & $\textbf{0.860}$ \\
54\_cs\_tf & 0.695 & 0.554 & 0.689 & 0.588 & 0.680 & $\textbf{0.708}$ & 0.580 & 0.697 & 0.697 \\
59\_wikidat & $\textbf{0.961}$ & 0.787 & 0.933 & 0.809 & 0.864 & 0.939 & 0.809 & 0.875 & 0.935 \\
62\_wikidat & $\textbf{0.981}$ & 0.878 & 0.948 & 0.892 & 0.923 & 0.959 & 0.898 & 0.925 & 0.954 \\
63\_wikidat & $\textbf{0.959}$ & 0.840 & 0.925 & 0.869 & 0.893 & 0.946 & 0.848 & 0.862 & 0.928 \\
66\_living- & $\textbf{1.000}$ & 0.985 & 1.000 & 0.968 & 0.999 & 1.000 & 0.950 & 0.998 & 0.998 \\
67\_social- & $\textbf{1.000}$ & 0.992 & 0.999 & 0.985 & 0.999 & 1.000 & 0.971 & 0.998 & 0.999 \\
68\_credit- & $\textbf{1.000}$ & 0.959 & 0.998 & 0.942 & 0.986 & 0.998 & 0.920 & 0.981 & 0.993 \\
71\_social- & 0.998 & 0.985 & $\textbf{0.998}$ & 0.969 & 0.993 & 0.998 & 0.950 & 0.989 & 0.995 \\
73\_control & $\textbf{0.998}$ & 0.970 & 0.995 & 0.945 & 0.984 & 0.998 & 0.935 & 0.986 & 0.982 \\
78\_north-a & $\textbf{1.000}$ & 0.933 & 0.998 & 0.907 & 0.990 & 0.999 & 0.883 & 0.976 & 0.995 \\
79\_human-r & $\textbf{0.999}$ & 0.974 & 0.995 & 0.964 & 0.988 & 0.996 & 0.947 & 0.990 & 0.992 \\
89\_glue\_mr & $\textbf{0.891}$ & 0.761 & 0.785 & 0.784 & 0.796 & 0.823 & 0.796 & 0.777 & 0.867 \\
90\_glue\_qn & 0.926 & 0.729 & 0.886 & 0.830 & 0.909 & 0.910 & 0.859 & 0.909 & $\textbf{0.931}$ \\
94\_ai\_gen & $\textbf{0.998}$ & 0.996 & 0.993 & 0.997 & 0.996 & 0.996 & 0.996 & 0.997 & 0.996 \\
96\_spam\_is & $\textbf{0.999}$ & 0.999 & 0.997 & 0.996 & 0.997 & 0.998 & 0.995 & 0.999 & 0.999 \\
100\_news\_f & $\textbf{1.000}$ & $\textbf{1.000}$ & 1.000 & 1.000 & $\textbf{1.000}$ & 1.000 & 1.000 & $\textbf{1.000}$ & 1.000 \\
105\_click\_ & 1.000 & $\textbf{1.000}$ & 1.000 & 0.999 & 1.000 & 0.999 & 1.000 & 1.000 & 1.000 \\
106\_hate\_h & 0.722 & 0.612 & 0.661 & 0.742 & 0.785 & 0.674 & 0.735 & 0.788 & $\textbf{0.812}$ \\
110\_aimade & 0.975 & 0.865 & 0.953 & 0.919 & 0.970 & 0.953 & 0.916 & 0.960 & $\textbf{0.979}$ \\
114\_nyc\_bo & 0.780 & 0.755 & 0.740 & 0.716 & 0.797 & 0.745 & 0.733 & 0.805 & $\textbf{0.872}$ \\
119\_us\_sta & $\textbf{0.997}$ & 0.957 & 0.994 & 0.982 & 0.990 & 0.994 & 0.952 & 0.992 & 0.995 \\
120\_us\_tim & 0.944 & 0.803 & 0.942 & 0.785 & $\textbf{0.946}$ & 0.936 & 0.751 & 0.940 & 0.941 \\
121\_us\_tim & 0.952 & 0.815 & 0.948 & 0.776 & 0.954 & 0.950 & 0.754 & $\textbf{0.957}$ & 0.951 \\
124\_world\_ & 0.999 & 0.999 & $\textbf{0.999}$ & 0.965 & 0.999 & 0.998 & 0.968 & 0.999 & 0.999 \\
127\_art\_ty & 0.913 & 0.872 & 0.894 & 0.834 & 0.889 & 0.905 & 0.845 & 0.900 & $\textbf{0.916}$ \\
129\_arith\_ & $\textbf{0.979}$ & 0.903 & 0.880 & 0.867 & 0.951 & 0.938 & 0.861 & 0.975 & 0.977 \\
132\_temp\_c & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & 0.991 \\
133\_contex & 0.984 & 0.982 & 0.975 & 0.973 & 0.979 & 0.968 & 0.973 & 0.980 & $\textbf{0.986}$ \\
134\_contex & 0.985 & 0.977 & 0.953 & 0.966 & 0.989 & 0.966 & 0.963 & $\textbf{0.994}$ & 0.987 \\
137\_glue\_m & $\textbf{0.856}$ & 0.551 & 0.788 & 0.632 & 0.734 & 0.807 & 0.658 & 0.742 & 0.844 \\
139\_news\_c & $\textbf{0.978}$ & 0.950 & 0.944 & 0.972 & 0.953 & 0.962 & 0.967 & 0.973 & 0.965 \\
141\_news\_c & 0.951 & 0.942 & 0.917 & 0.967 & 0.968 & 0.933 & 0.965 & $\textbf{0.973}$ & 0.965 \\
144\_cancer & $\textbf{1.000}$ & 1.000 & 0.981 & $\textbf{1.000}$ & $\textbf{1.000}$ & 0.991 & $\textbf{1.000}$ & $\textbf{1.000}$ & 1.000 \\
145\_diseas & 0.618 & 0.677 & 0.501 & 0.618 & 0.678 & 0.563 & 0.606 & $\textbf{0.686}$ & 0.655 \\
149\_twt\_em & 0.787 & 0.756 & 0.730 & 0.780 & 0.843 & 0.759 & 0.813 & $\textbf{0.853}$ & 0.851 \\
150\_twt\_em & 0.710 & 0.612 & 0.652 & 0.700 & 0.730 & 0.672 & 0.717 & 0.746 & $\textbf{0.777}$ \\
155\_athlet & 0.995 & 0.988 & 0.990 & 0.970 & 0.988 & 0.988 & 0.960 & 0.985 & $\textbf{0.996}$ \\
158\_code\_C & $\textbf{1.000}$ & 0.998 & 1.000 & 0.999 & 1.000 & 1.000 & 0.999 & 1.000 & 0.997 \\
162\_agnews & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & 1.000 & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & 1.000 \\
163\_agnews & $\textbf{1.000}$ & 1.000 & 1.000 & 1.000 & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & $\textbf{1.000}$ & 1.000 \\
\bottomrule
\end{tabular}
\end{table}


\section{SAE Architectural Improvements}
\label{sec:app_improvements}
We test if improvements in SAE architectures have led to improvements in probing performance. We test eight SAE architectures on Gemma-2-2B in all regimes with $k = 16,128$ SAE probes. We plot the performance of SAE probes for all architectures in \cref{fig:improvementRegimes} when averaging over all datasets. While there seems to be some improvement with later architectures, we note that there is significant variance in the average across datasets that is not visualized.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/Improvement/L0_grid.pdf}
    \caption{Across regimes, we see a slight positive trend in probing performance with more recent SAE architectures.}
    \label{fig:improvementRegimes}
\end{figure}

\newpage
\section{Assessing SAE Probe Binarization}
\label{sec:app_binarize}


\begin{figure}
    \centering
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Multi-token/consolidated_probing_comparison_bars_binarized.pdf}
        \caption{Multi-token \textbf{non-binarized} experiments (the same as \cref{fig:multi_token}).}
        \label{fig:app_sae_width_l0_pareto}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/Multi-token/consolidated_probing_comparison_bars_unbinarized.pdf}
        \caption{Multi-token \textbf{binzarized} experiments.}
        \label{fig:app_sae_width}
    \end{subfigure}
    \caption{We run the multi-token experiments from \cref{sec:multi-token} with and without binarizing aggregated latents.}
    \label{fig:multi_token_binarized}
\end{figure}

\citet{probingGallifant} find that binarizing latents with a threshold improves probe performance. Binarization entails setting a latent equal to $1$ if its firing value is greater than a threshold, and setting it equal to $0$ otherwise. \citet{probingGallifant} use a threshold equal to $1$.

\citet{probingGallifant} performs probing in the multi-token pooled setting, so to use as similar of a setup as possible we repeat our multi-token experiment with binarization and a threshold equal to $1$. Following \citet{probingGallifant}, we binarize after the max-pooling aggregation.  As shown in in \cref{fig:multi_token_binarized}, we find that binarizing results in worse performance than not-binarizing. 



\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.


