\section{Baselines}
\label{app:baselines}
\subsection{Open-source PRM}
\begin{figure*}
  \centering
  % \vspace{-10pt}
  \includegraphics[width=\textwidth]{imgs/Prompt_Illusttration.pdf}
  \vspace{-20pt}
  \caption{The illustration of PRM input template.}
  % \vspace{-10pt}
  \label{fig:prompt template example}
\end{figure*}
\begin{figure*}
  \centering
  % \vspace{-10pt}
  \includegraphics[width=\textwidth]{imgs/Prompt_Illusttration2.pdf}
  \vspace{-20pt}
  \caption{The illustration of RetrievalPRM input template.}
  % \vspace{-10pt}
  \label{fig:prompt template example2}
\end{figure*}


\begin{itemize}[leftmargin=10pt] 
\item Skywork-PRM~\cite{skyworkopeno12024} is a Qwen2.5-Math-based PRM published by KunLun. 
\item Qwen2.5-PRM~\cite{zheng2024processbench} is trained by fine-tuning the Qwen2.5-Math-7B-Instruct model on the PRM800K dataset. 
\item Math-Shepherd~\cite{wang2024math} generates process labels for each step by estimating the empirical probability that a given step leads to the correct final answer and trains a PRM based on their published dataset. 
\item RLHFlow-PRM~\cite{xiong2024rlhflowmath} is an 8-billion-parameter reward model trained with process supervision. 
\end{itemize}


\subsection{Language Models as Critic}
\begin{itemize}[leftmargin=10pt] 
\item Llama~\cite{dubey2024llama} is an open-source model developed by Meta (formerly Facebook), designed for natural language understanding and generation tasks. 
\item Qwen2~\cite{yang2024qwen2} is a large language model developed by Alibaba Cloud, offering multilingual support and strong capabilities in language understanding and generation. \item Qwen2.5~\cite{qwen2.5} is an advanced iteration of the Qwen series, pretrained on 18 trillion tokens, enhancing knowledge retention, programming, and mathematical reasoning. 
\item Qwen2.5-MATH~\cite{yang2024qwen25mathtechnicalreportmathematical} is a specialized model for mathematical problem-solving, trained on extensive math-focused data and incorporating Chain-of-Thought (CoT) and Tool-Integrated Reasoning (TIR). 
\item Qwen2.5-Coder~\cite{hui2024qwen25codertechnicalreport} is a programming-oriented model trained on 5.5 trillion code-related tokens, excelling in code generation, debugging, and multilingual programming tasks. 
\item GPT-4o~\cite{openai2024gpt4ocard} is a multimodal AI model developed by OpenAI that processes and generates text, audio, and images in real-time, with enhanced speed and natural interaction capabilities. 
\end{itemize}



\section{Implementation Details}
\label{app:implementation details}
\subsection{Basemodel and Training hyperparameters}

We selected Qwen-2.5-Math-7b-instruct\cite{qwen2.5} as the foundational large language model (LLM) for our experiments. All computations were performed using H100 GPUs. To enhance training resource efficiency, we employed Parameter-Efficient Fine-tuning techniques LoRA. The LoRA configuration was set with a rank of 32, an alpha value of 64, and dropout set to 0.1. LoRA update matrices were specifically applied to the query and value projection matrices within the attention blocks. 

We use PRM800K as our training data and both PRM800K and Math-Shepherd as our retrieval pool. The training process was carried out with batch sizes chosen from \(\{64, 128, 256, 512\}\) and initial learning rates selected from \(\{1\times 10^{-3},1\times 10^{-4}, 3 \times 10^{-4}, 1\times 10^{-5}, 3 \times 10^{-5}\}\) using a linear scheduler.

\subsection{Prompts}
\label{app:prompts}
In this section, we show our training prompts for PRM in details as is shown in Figure~\ref{fig:prompt template example} and Figure~\ref{fig:prompt template example2}.
% \begin{figure*}
%   \centering
%   % \vspace{-10pt}
%   \includegraphics[width=\textwidth]{imgs/Prompt Illusttration.pdf}
%   \vspace{-20pt}
%   \caption{The illustration of PRM input template.}
%   % \vspace{-10pt}
%   \label{fig:prompt template example}
% \end{figure*}



\section{Datasets}
\label{app:datasets}

\textit{GSM8K}~\cite{gsm8k}: Grade School Math is a dataset for basic to intermediate math problems, covering arithmetic, algebra, geometry and other fields. Its difficulty is suitable for math problems in elementary to middle school.

\textit{MATH}~\cite{hendrycks2021measuring}: The MATH dataset contains a variety of math problems from basic to university level, covering multiple mathematical fields such as algebra, geometry, calculus, number theory, etc.

\textit{OlympiadBench}~\cite{he2024olympiadbenchchallengingbenchmarkpromoting}: The Olympiadbench dataset contains questions from the Mathematical Olympiad. The questions are of high difficulty and involve complex combinatorial mathematics, number theory, geometry and other advanced mathematical fields.

\textit{Omni-MATH}~\cite{gao2024omnimathuniversalolympiadlevel}: Omni-MATH is a general Olympiad-level mathematics benchmark dataset for large language models, covering multi-domain and high-difficulty mathematics problems, and is designed to evaluate the reasoning ability of models in various mathematical fields.

Except for GSM8K, which focuses on grade school math problems, the other three datasets feature problems of competition or Olympiad-level difficulty.
\section{Supplementary Evaluation Results}
\label{app: supplementary results}
In this section, we show the breakdown of our main results in Table~\ref{tab:All performance addition} and ablation results in Table~\ref{tab:ablation performance addition}

\begin{table*}[h]
\centering    

\vspace{-10pt}
\caption{Breakdown of evaluation results of different models on ProcessBench. 
The best result is given in bold, and the second-best value is underlined. 
}
\vspace{-5pt}

\label{tab:All performance addition}
\resizebox{1.0\textwidth}{!}{
\renewcommand\arraystretch{1.1}
\begin{tabular}{cccccccccccccc}
% \toprule
\hline

\multicolumn{2}{c}{\multirow{2}{*}{Model}} & \multicolumn{3}{c}{GSM8k} &\multicolumn{3}{c}{MATH} &\multicolumn{3}{c}{OlympiadBench}&\multicolumn{3}{c}{OmniMATH}\\ 

 \cmidrule(r){3-5} \cmidrule(r){6-8}  \cmidrule(r){9-11}  \cmidrule(r){12-14}
\multicolumn{2}{c}{} & error  & correct & F1 & error  & correct & F1 & error  & correct & F1 & error  & correct & F1 \\ 
   \hline 
   

\multicolumn{1}{c|}{\multirow{7}{*}{\makecell{Open-source \\ PRM}}}
& \multicolumn{1}{l}{RetrievalPRM-7B(Ours)} & 64.7 &88.1&\textbf{ 74.6} &67.2 & 75.6& \textbf{71.1 }& 56.0 & 65.2&\textbf{ 60.2}&52.8 & 62.65& \textbf{57.33}\\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & \multicolumn{1}{l}{Qwen2.5-Math-7B-PRM800K} & 53.1 & 95.3 & 68.2 & 48.0 & 90.1 & \underline{62.6} & 35.7 & 87.3 & \underline{50.7} & 29.8 & 86.3 & \underline{44.3} \\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & \multicolumn{1}{l}{Skywork-PRM-7B} & 61.8 & 82.9 & \underline{70.8} & 43.8 & 69.2 & 53.6 & 17.9 & 31.9 & 22.9 & 14.0 & 41.9 & 21.0\\
\multicolumn{1}{c|}{\multirow{4}{*}{}} &\multicolumn{1}{l}{ RLHFlow-PRM-Mistral-8B} & 33.8 & 99.0 & 50.4 & 21.7 & 72.2 & 33.4 & 8.2 & 43.1 & 13.8 & 9.6 & 45.2 & 15.8 \\
\multicolumn{1}{c|}{\multirow{4}{*}{}} &\multicolumn{1}{l}{ RLHFlow-PRM-Deepseek-8B} & 24.2 & 98.4 & 38.8 & 21.4 & 80.0 & 33.8 & 10.1 & 51.0 & 16.9 & 10.1 & 51.9 & 16.9 \\
\multicolumn{1}{c|}{\multirow{4}{*}{}} &\multicolumn{1}{l}{ Skywork-PRM-1.5B} & 50.2 & 71.5 & 59.0 & 37.9 & 65.3 & 48.0 & 15.4 & 26.0 & 19.3 & 13.6 & 32.8 & 19.2\\
\multicolumn{1}{c|}{\multirow{4}{*}{}} & \multicolumn{1}{l}{Math-Shepherd-PRM-7B} & 32.4 & 91.7 & 47.9 & 18.0 & 82.0 & 29.5 & 15.0 & 71.1 & 24.8 & 14.2 & 73.0 & 23.8 \\
\hline

\multicolumn{1}{c|}{\multirow{17}{*}{\makecell{Language \\ Models}}}
& \multicolumn{1}{l}{QwQ-32B-Preview} & 81.6 & 95.3 & \textbf{88.0} & 78.1 & 79.3 & \textbf{78.7} & 61.4 & 54.6 & \textbf{57.8} & 55.7 & 68.0 & \textbf{61.3}\\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{GPT-4o}& 70.0& 91.2 & 79.2 & 54.4 & 76.6 &\underline{63.6} & 45.8 & 58.4 & 51.4 & 45.2 &\underline{53.5}&\underline{61.9} \\ 
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Qwen2.5-72B-Instruct }& 62.8 & 96.9 & 76.2 & 46.3 & 93.1 & 61.8 & 38.7 & 92.6 & \underline{54.6} & 36.6 & 90.9 & 52.2 \\ 
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Llama-3.3-70B-Instruct }& 72.5 & 96.9 & \underline{82.9} & 43.3 & 94.6 & 59.4 & 31.0 & 94.1 & 46.7 & 28.2 & 90.5 & 43.0 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2.5-32B-Instruct} & 49.3 & 97.9 & 65.6 & 36.7 & 95.8 & 53.1 & 25.3 & 95.9 & 40.0 & 24.1 & 92.5 & 38.3\\ 
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2.5-14B-Instruct} & 54.6 & 94.8 & 69.3 & 38.4 & 87.4 & 53.3 & 31.5 & 78.8 & 45.0 & 28.3 & 76.3 & 41.3 \\ 
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2.5-Coder-32B-Instruct} & 54.1 & 94.8 & 68.9 & 44.9 & 90.6 & 60.1 & 33.4 & 91.2 & 48.9 & 31.5 & 87.6 & 46.3 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Qwen2.5-Coder-14B-Instruct }& 33.8 & 96.4 & 50.1 & 25.4 & 92.4 & 39.9 & 20.7 & 94.1 & 34.0 & 15.9 & 94.2 & 27.3 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2.5-Coder-7B-Instruct} & 7.7 & 100.0 & 14.3 & 3.4 & 98.3 & 6.5 & 2.1 & 99.1 & 4.1 & 0.9 & 98.3 & 1.8\\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Qwen2.5-Math-72B-Instruct} & 49.8 & 96.9 & 65.8 & 36.0 & 94.3 & 52.1 & 19.5 & 97.3 & 32.5 & 19.0 & 96.3 & 31.7 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Qwen2.5-Math-7B-Instruct} & 15.5 & 100.0 & 26.8 & 14.8 & 96.8 & 25.7 & 7.7 & 91.7 & 14.2 & 6.9 & 88.0 & 12.7 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Llama-3.1-70B-Instruct} & 64.3 & 89.6 & 74.9 & 35.4 & 75.6 & 48.2 & 35.1 & 69.9 & 46.7 & 30.7 & 61.8 & 41.0 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{Meta-Llama-3-70B-Instruct} & 35.7 & 96.9 & 52.2 & 13.0 & 93.3 & 22.8 & 12.0 & 92.0 & 21.2 & 11.2 & 91.7 & 20.0 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2-72B-Instruct} & 57.0 & 82.9 & 67.6 & 37.7 & 70.9 & 49.2 & 34.0 & 55.2 & 42.1 & 32.3 & 53.1 & 40.2 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} & \multicolumn{1}{l}{Qwen2.5-7B-Instruct} & 40.6 & 33.2 & 36.5 & 30.8 & 45.1 & 36.6 & 26.5 & 33.9 & 29.7 & 26.2 & 28.6 & 27.4\\ 
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Qwen2-7B-Instruct} & 40.6 & 4.7 & 8.4 & 30.5 & 13.8 & 19.0 & 22.4 & 10.9 & 14.7 & 20.0 & 8.7 & 12.1 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{ Llama-3.1-8B-Instruct} & 44.4 & 6.2 & 10.9 & 41.9 & 2.7 & 5.1 & 32.4 & 1.5 & 2.8 & 32.0 & 0.8 & 1.6 \\
\multicolumn{1}{c|}{\multirow{13}{*}{}} &\multicolumn{1}{l}{Meta-Llama-3-8B-Instruct} & 42.5 & 7.8 & 13.1 & 28.6 & 9.1 & 13.8 & 27.1 & 2.7 & 4.8 & 26.1 & 8.3 & 12.6 \\

\hline

   % \bottomrule          
\end{tabular}
\vspace{-5pt}
}

\end{table*}


\begin{table*}[h]
\centering    

\vspace{-10pt}
\caption{Breakdown of evaluation results of different variants of RetrievalPRM on ProcessBench.  We remove different components of RetrievalPRM to evaluate the contribution of each part to the model. The best result is given in bold, and the second-best value is underlined.
}
\vspace{-5pt}

\label{tab:ablation performance addition}
\resizebox{1.0\textwidth}{!}{
\renewcommand\arraystretch{1.1}
\begin{tabular}{cccccccccccccccc}
% \toprule
\hline

\multicolumn{2}{c}{Retrieval Components} & \multicolumn{3}{c}{GSM8k} &\multicolumn{3}{c}{MATH} &\multicolumn{3}{c}{OlympiadBench}&\multicolumn{3}{c}{OmniMATH}&\multirow{2}{*}{Avg.F1}\\ 

 \cmidrule(r){3-5} \cmidrule(r){6-8}  \cmidrule(r){9-11}  \cmidrule(r){12-14}
Question-level &Step-level & error  & correct & F1 & error  & correct & F1 & error  & correct & F1 & error  & correct & F1 & \\ 
   \hline 
   



\checkmark &\checkmark& 64.7 &88.1&\underline{74.6} &67.2 & 75.6& \underline{71.1 }& 56.0 & 65.2&\textbf{ 60.2}&52.8 & 62.65& \textbf{57.33}&\textbf{65.8}\\
\checkmark&$\times$ &61.8& 94.8 &\textbf{74.9} &62.1&83.3 &\textbf{71.2}& 48.7&77.3&\underline{59.8} & 43.2 &73.4 &54.4&\underline{65.0}\\
$\times$& \checkmark& 51.7 &97.4 &67.5 &57.2 &87.4 & 69.2&46.0 & 82.0& 58.9& 43.9&78.4 & \underline{56.3} &63.0\\
$\times$&$\times$&50.7 & 92.7&65.6 & 57.9 & 81.0 & 67.5&46.9&68.7 & 55.8 &39.7& 71.0&50.9 &59.9\\

\hline   
\end{tabular}
\vspace{-5pt}
}

\end{table*}



