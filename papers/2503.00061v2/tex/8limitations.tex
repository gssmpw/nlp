\section{Limitations}
We percieve the following limitations of our work:
\begin{itemize}
    \item  Our adaptive attacks focus solely on the agent's first-step action. We train all adversarial strings to produce the output: ``Thought: I will use the \{Attacker tool name\} tool to,'' which directly influences only the agentâ€™s initial step. Our experiments show that adaptive attacks provide the least improvement in the second step of the data-stealing attack. Refining the attack strategy to account for long-term impact is a valuable direction for further study.
    \item Our attacks assume the attacker has white-box access to the agent model, defense models, and detailed prompts. This approach aligns with our goal of testing defense robustness using adaptive attacks. However, studying black-box and grey-box attacks is also crucial for a more comprehensive evaluation.
    \item We do not account for the combination of defenses. Currently, we design adaptive attacks for individual defenses, but combining different defenses can create stronger protective mechanisms. For example, applying all three detection strategies together could improve the detection rate of IPI attacks in external content. Exploring adaptive attacks that target combinations of defenses is an important area for future work.
    \item Our research is not an exhaustive exploration of all potential defenses that could be adapted for IPI attacks. For example, we do not cover LLM self-evaluation~\cite{DBLP:conf/iclr/PhuteHHPSCC24}, alternative model finetuning methods~\cite{DBLP:conf/acl/ZhangYKMWH24}, or others~\cite{DBLP:journals/corr/abs-2309-02705}. Our goal is to emphasize the importance of adaptive attacks in developing defenses and to advocate for more robust evaluations of defense mechanisms.
\end{itemize}