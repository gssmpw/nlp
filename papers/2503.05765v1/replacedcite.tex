\section{Related Work}
Research has consistently shown that LLMs, such as GPT-based models, encode and perpetuate biases from their training data ____. Studies have documented biases in gendered language ____, racial and ethnic stereotypes ____, and disparities in sentiment and lexical framing ____. These biases can influence LLM-driven decision-making, leading to discriminatory or unequal outcomes in domains such as hiring, healthcare, and content moderation. However, fewer studies have examined how bias in LLMs affects robot caregiving interactions, an area where fairness and inclusivity are particularly critical.

The field of HRI has increasingly focused on ensuring that robots interact ethically and equitably with diverse users ____. Prior research has explored biases in robot perception, demonstrating that users may assign gender, race, and personality traits to robots based on their design and behavior ____. Studies on caregiving robots have highlighted concerns that robots may reinforce stereotypes about gendered caregiving roles ____ or exhibit racial and cultural insensitivity in cross-cultural care settings ____. One recent study intentionally incorporated participant's nationality, mental and physical condition in LLM prompts to generate dialogue in a human-robot interaction but did not consider the potential biases introduced by the LLM ____.

Recent research showed that LLM-generated responses for HRI tasks such as facial emotion expression, trust evaluation, proximity preference, and security risk evaluation were biased and discriminatory when prompted with similar labels as the ones examined here ____. This paper's analysis complement's their work by examining bias in LLM generation in the robot caregiving context. Existing approaches to measuring bias in LLM-generated text include lexical analysis, sentiment analysis, syntactic complexity analysis, and embedding-based similarity metrics ____. In this study, we apply statistical and computational methods to analyze disparities in LLM-generated caregiving descriptions, identifying patterns of bias across demographic groups.