\section{Related Work}

\textbf{Image \geoloc.}
Image \geoloc falls into three
methods: (1) \textit{Retrieval-based methods}
retrieves the most similar images~\cite{hays2008im2gps, zhu2023r2former}. Various
retrievers~\cite{vo2017revisiting, pramanick2022world,
haas2023learning} and gallery types~\cite{vivanco2024geoclip} have
been proposed.
(2) \textit{Classification-based
methods} divide geographical maps into distinct classes
% ---such as countries, cities, or geographical cells---
and train models to classify
the images into these categories with different model structures~\cite{radford2021learning,
wu2022im2city} and map division strategies~\cite{weyand2016planet,
theiner2022interpretable, haas2024pigeon}. 
(3) \textit{Generation-based methods} use visual understanding and generation in Vision
Language Models (\textsc{vlm}s) to directly generate the location or
coordinates for \geoloc. Aligning visual content with rich
text descriptions and reasoning~\cite{jia2024g3, ligeoreasoner,
zhang2024can} and incorporating external knowledge through
Retrieval-Augmented Generation~\cite{luo2022g, zhou2024img2loc} are state-of-the-art. However, challenges
persist in effectively using \textsc{vlm}s, including limited reasoning
data and relying on constrained knowledge
sources.

\textbf{Visual Reasoning.}
Unlike previous methods, we treat \geoloc as a complex visual reasoning task that deduces the correct location with language, requiring both visual
understanding and reasoning capabilities~\cite{hudson2019gqa,
gupta2023visual}.
As \textsc{vlm}s have demonstrated exceptional accuracy in visual
reasoning tasks~\cite{alayrac2022flamingo, lu2024chameleon}, methods enhancing the visual reasoning of \textsc{vlm}s in specific tasks include:
(1) \textit{High-quality reasoning data}, which researchers
have shown to be particularly effective in improving the performance
of \textsc{vlm}s~\cite{du2023makes, chen2023shikra}; (2) \textit{Vision
grounding}, which enables models to ground in the details of the image
and perform step-by-step reasoning~\cite{qi2024cogcom, wu2023textit,
zhang2024can}; and (3) \textit{Tool using and retrieval-augmented generation},
which aid the model by leveraging tools to retrieve additional knowledge~\cite{yang2023mm, marino2021krisp, chen2022lako} and reduce hallucinations. 
We integrate these insights to improve \modelname.