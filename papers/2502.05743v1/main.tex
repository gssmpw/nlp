\documentclass[11pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{tgpagella}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts

\input{macro_2}
\usepackage{authblk}
\usepackage{booktabs}
\usepackage{cleveref}
\usepackage{cite}
\usepackage{natbib}
\usepackage{mathtools}
\usepackage[toc, page]{appendix}
\usepackage{wrapfig}
\definecolor{c1}{HTML}{A7BEAE}
\definecolor{c2}{HTML}{B85042}

\def\MoG{\texttt{MoG}}
\def\MoLRG{\texttt{MoLRG}}
\def\CSNR{$\mathrm{CSNR}$}
\def\SWD{$\mathrm{SWD}$}

% \title{Understanding Diffusion-based Representation Learning via Low-Dimensional Modeling}
\title{Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling}

\author[$\Diamond$]{Xiao Li\thanks{The first two authors contributed equally to the work.}}
\author[$\Diamond$]{Zekai Zhang\samethanks}
\author[$\Diamond$]{Xiang Li}
\author[$\Diamond$]{Siyi Chen}
\author[$\dagger$]{Zhihui Zhu}
\author[$\Diamond$]{Peng Wang}
\author[$\Diamond$]{\\ Qing Qu}


\affil[$\Diamond$]{Department of Electrical Engineering and Computer Science, University of Michigan}
\affil[$\dagger$]{Department of Computer Science \& Engineering, Ohio State University}

\date{}

\date{\today}

\begin{document}

\maketitle


\begin{abstract}
This work addresses the critical question of why and when diffusion models, despite being designed for generative tasks, can excel at learning high-quality representations in a self-supervised manner. To address this, we develop a mathematical framework based on a low-dimensional data model and posterior estimation, revealing a fundamental trade-off between generation and representation quality near the final stage of image generation. Our analysis explains the unimodal representation dynamics across noise scales, mainly driven by the interplay between data denoising and class specification. Building on these insights, we propose an ensemble method that aggregates features across noise levels, significantly improving both clean performance and robustness under label noise. Extensive experiments on both synthetic and real-world datasets validate our findings.

\end{abstract}

\section{Introduction}\label{sec:intro}
\input{sections/intro}

\section{Problem Setup}\label{sec:problem}
\input{sections/problem}

\section{Study of Representation Dynamics}\label{sec:main}
\input{sections/when}

\section{Practical Insights}\label{sec:exp}
\input{sections/ensemble}

\section{Discussion}
In this work, we develop a mathematical framework for analyzing the representation dynamics of diffusion models. By introducing the concept of \CSNR~and leveraging a low-dimensional mixture of low-rank Gaussians, we characterize the trade-off between generative quality and representation quality. Our theoretical analysis explains how the unimodal representation learning dynamics observed across noise scales emerge from the interplay between data denoising and class specification.

Beyond theoretical insights, we propose an ensemble method inspired by our findings that enhances classification performance in diffusion models, both with and without label noise. Additionally, we empirically uncover an inherent weight-sharing mechanism in diffusion models, which accounts for their superior representation quality compared to traditional DAEs. Experiments on both synthetic and real-world datasets validate our findings. Additionally, our findings also open up new avenues for future research that we discuss in the following.

\begin{itemize}[leftmargin=*]
    \item \textbf{Principled diffusion-based representation learning.} While diffusion models have shown strong performance in various representation learning tasks, their application often relies on trial-and-error methods and heuristics. For example, determining the optimal layer and noise scale for feature extraction frequently involves grid searches. Our work provides a theoretical framework to understand representation dynamics across noise scales. A promising future direction is to extend this analysis to include layer-wise dynamics. Combining these insights could pave the way for more principled and efficient approaches to diffusion-based representation learning.

    \item \textbf{Representation alignment for better image generation.} Recent work REPA \citet{yu2024repa} has demonstrated that aligning diffusion model features with features from pre-trained self-supervised foundation models can enhance training efficiency and improve generation quality. By providing a deeper understanding of the representation dynamics in diffusion models, our findings could further advance such representation alignment techniques, facilitating the development of diffusion models with superior training and generation performance.
\end{itemize}

\section*{Acnkowledgement}
We acknowledge funding support from NSF CAREER CCF-2143904, NSF CCF-2212066, NSF CCF-
2212326, NSF IIS 2312842, NSF IIS 2402950, ONR N00014-22-1-2529, and MICDE Catalyst Grant.

\bibliographystyle{abbrvnat}
\bibliography{refs}

\newpage
\appendix
\section{Appendix}
\input{sections/app}

\end{document}
