{\color{blue}
We start this section by demonstrating that the \textbf{denoising objective}, not the \textbf{diffusion process}, primarily drives the representation ability of diffusion models. We then show a direct link between feature quality and posterior estimation quality. Lastly, we highlight how the loss design of diffusion models enables an inherent weight-sharing mechanism, enhancing their representation learning compared to traditional denoising autoencoders.

\begin{figure}[t]
    \begin{center}
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width = 0.995\textwidth]{figs/teaser_ddpm.pdf}
    \caption{Classification} 
    \end{subfigure} \quad %\hspace*{\fill}
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width = 0.995\textwidth]{figs/teaser_seg.pdf}
    \caption{Segmentation} 
    \end{subfigure}
    \end{center}
    \vspace{-0.1in}
\caption{\textbf{Using clean images as inputs improves representation learning performance.} We train DDPM/EDM-based diffusion models on CIFAR datasets and compare feature accuracy when clean images $\bm x_0$ or corrupted images $\bm x_t$ are used as inputs. Clean images achieve comparable performance at low noise levels and significantly outperform corrupted inputs as noise levels increase.}
\label{fig:clean_feature}
\end{figure}

\subsection{Denoising Objective vs. Diffusion Process in Representation Learning}\label{subsec:feature-extraction}
Despite the vast success of diffusion models in representation learning, it remains largely unclear whether the representation learning abilities of diffusion models are driven by the diffusion process, or by the model’s denoising capabilities \citep{fuest2024diffusion}. We tackle the problem by comparing the following settings:
\begin{itemize}
    \item \textbf{Image with stochastic noise (Extracting features with $\hat{\bm x}_{\bm \theta}(\bm x_t, t)$).} If the representation ability of diffusion models is primarily driven by the diffusion process—specifically, the gradual addition and removal of Gaussian noise $\sigma_t$—then incorporating the additive noise along with the corresponding noise level at each time step is crucial during feature extraction. 
    % \textcolor{orange}{(Zekai: also this is the approach we take during generation)}
    \item \textbf{Clean image (Extracting features with $\hat{\bm x}_{\bm \theta}(\bm x_0, t)$).} Conversely, if the representational ability of diffusion models is independent of the diffusion process, then adding noise to the inputs should not be necessary, and feature extraction could rely solely on the clean image $\bm{x}_0$. This approach also enables a clearer comparison of feature extraction quality across different noise scales by removing entirely the effects of varying input image degradation. 
    % \textcolor{orange}{(Zekai: make more sense when we already have a clean image, and only care about feature extraction rather than generation)}
    % \item \textcolor{orange}{(Zekai: What about deterministic noise? Also can be more concise for above setup)}
\end{itemize}

The comparison results are presented in \Cref{fig:clean_feature}, revealing two key findings: (1) using clean images $\bm{x}_0$ as input consistently matches or outperforms using corrupted inputs $\bm{x}_t$, and (2) the performance gap widens as $t$ ($\sigma_t$) increases. These observations suggest that the representation ability of diffusion models primarily stems from their denoising objective, with the diffusion process playing a negligible role.

Now, a natural question one would ask is that: since diffusion models are trained on corrupted inputs, isn’t using clean images during inference out of distribution? Why would this approach yield better performance? In fact, we can draw an analogy with traditional supervised and self-supervised learning. In these paradigms, data augmentations—such as cropping~\cite{caron2021emerging}, color jittering, or masking~\cite{he2022masked}—are applied during training to improve model robustness and performance. However, clean, unaugmented images are typically used during inference. Similarly, in diffusion models, additive Gaussian noise acts as a form of data augmentation necessary for training~\cite{chen2024deconstructing}. For inference, when the focus is on representation learning, using clean images $\bm{x}_0$ as input is sufficient and aligns with standard practices in representation learning. 
% \textcolor{orange}{(Zekai: we should highlight more here: 1.refer to fig2 (to-appear with segmentation), 2.compare to Kaiming's observation that using noisy image is better (not sure yet), 3.We establish the standard way of extracting representation with DMs that aligns with traditional rep learning, cite CleanDIFT to support us)}

Therefore, we establish the use of clean images as input as the standard protocol for feature extraction during inference. This setup will be maintained throughout the remainder of our analysis unless otherwise specified.


\subsection{Posterior Quality Decides Feature Quality}\label{subsec:posterior}
% \xiao{Use posterior image in appendix to demonstrate that posterior quality directly reflects feature quality, motivate the next section}
% \xiao{Do we need this?}

\begin{figure}[t]
    \begin{center}
    \begin{subfigure}{0.98\textwidth}
    \includegraphics[width = 0.985\textwidth]{figs/noise_image_posterior.pdf}
    \caption{$\hat{\bm x}_{\bm \theta}(\bm x_t, t)$: Posterior estimation using \textbf{noise image} as inputs.} 
    \end{subfigure} \quad %\hspace*{\fill}
    \begin{subfigure}{0.98\textwidth}
    \includegraphics[width = 0.985\textwidth]{figs/clean_image_posterior.pdf}
    \caption{$\hat{\bm x}_{\bm \theta}(\bm x_0, t)$: Posterior estimation using \textbf{clean image} as inputs.} 
    \end{subfigure}
    \end{center}
    \vspace{-0.1in}
\caption{{\color{blue}\textbf{Using clean images as inputs improves posterior estimation quality.} We use a pre-trained DDPM diffusion model on CIFAR10 to visualize posterior estimation for clean inputs and noisy inputs across varying noise scales $\sigma_t$. Clean inputs produce smooth and descriptive estimations even at high noise levels, whereas noisy inputs result in blurry and lossy estimations at large $\sigma_t$, making it difficult to extract meaningful representations.}}
\label{fig:clean_vs_noise}
\end{figure}

Diffusion models $\hat{\bm{x}}_{\bm{\theta}}$ are trained to perform posterior estimation at a given time step $t$ using corrupted inputs, with the features for representation learning emerging as an intermediate byproduct of this process. This leads to a natural conjecture:
\emph{changes in feature quality should directly correspond to changes in posterior estimation quality.}
\textcolor{orange}{(Zekai: I suggest to put this in a rect box)}


% \textcolor{orange}{(Zekai: while posterior estimation can also be seen as the last-layer representaion somehow)}. 
To test this hypothesis, we visualize the posterior estimation results for clean inputs ($\hat{\bm{x}}_{\bm{\theta}}(\bm{x}_0, t)$) and noisy inputs ($\hat{\bm{x}}_{\bm{\theta}}(\bm{x}_t, t)$) across varying noise scales $\sigma_t$ in \Cref{fig:clean_vs_noise}. The results reveal that, similar to the findings for feature representation, clean inputs yield superior posterior estimation compared to corrupted inputs, with the performance gap widening as the noise scale increases. Furthermore, as illustrated in the (teaser image), if we consider posterior estimation as the last-layer features and directly use it for classification, the accuracy curve reveals a unimodal trend as noise level progresses, similar to the behavior observed in feature classification accuracy. These findings strongly validate the conjecture. 
% \textcolor{orange}{(Zekai: only validating the conjecture with current figure 2 is too vague... Maybe we should refer to the x0 acc vs fearure acc/peak shift part in following sections?)}

Building on this insight, we use posterior estimation as a proxy to analyze the dynamics of diffusion-based representation learning in \Cref{sec:main}. Moreover, since the unimodal representation dynamic persists across different network architectures and feature extraction layers, analyzing posterior estimation also enables us to study the problem without relying on specific architectural or layer-dependent assumptions.


\subsection{Weight Sharing in Diffusion Models Helps Representation Learning}\label{subsec:weight_share}

\begin{figure}[t]
    \begin{center}
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width = 0.995\textwidth]{figs/dae_diffusion_c10.pdf}
    \caption{CIFAR10} 
    \end{subfigure} \quad %\hspace*{\fill}
    \begin{subfigure}{0.48\textwidth}
    \includegraphics[width = 0.995\textwidth]{figs/dae_diffusion_c100.pdf}
    \caption{CIFAR100} 
    \end{subfigure}
    \end{center}
    \vspace{-0.1in}
\caption{\textbf{Diffusion models exhibit higher and smoother feature accuracy and similarity compared to individual DAEs.} We train DDPM-based diffusion models and individual DAEs on the CIFAR datasets and evaluate their representation learning performance. Feature accuracy, and feature differences from the optimal features (indicated by {\color{cyan} $\star$}) are plotted against increasing noise levels. The results reveal an inverse correlation between feature accuracy and feature differences, with diffusion models achieving both higher/smoother accuracy and smaller/smoother feature differences compared to DAEs.}
\label{fig:dae_diffusion}
\end{figure}

% Now that we have established the denoising objective as the primary driver of diffusion models' superior representation learning capabilities, we now turn to a key question: what makes diffusion models outperform traditional single-step denoising autoencoders (DAEs) \citep{vincent2008extracting,vincent2010stacked} and achieve on-par or superior representation performance compared to state-of-the-art self-supervised methods? In this subsection, we reveal that the key advantage of diffusion models over traditional DAEs lies in their inherent weight-sharing mechanism.

In this subsection, we reveal that although both leverage the denoising objective, diffusion models surpass traditional single-step denoising autoencoders (DAEs) in representation learning performance due to their inherent weight-sharing mechanism.

Diffusion models minimize their loss across all noise levels (\ref{eq:dae_loss}), facilitating interactions and parameter sharing among denoising subcomponents. We hypothesize that this creates an implicit "ensemble" effect, enabling diffusion models to learn more consistent and robust features across noise scales compared to DAEs \citep{chen2024deconstructing}, as illustrated in \Cref{fig:dae_diffusion} (also in later sections \Cref{fig:ucurve_molrg3class}(a) and \Cref{fig:cifar}(a).)

To test this hypothesis, we trained 10 DAEs, each specialized for a single noise level, alongside a DDPM-based diffusion model on CIFAR10 and CIFAR100. Feature performance was compared using linear probing accuracy, while feature similarity was evaluated via sliced Wasserstein distance (\SWD) \citep{doan2024assessing}, relative to the optimal features at $\sigma_t = 0.06$, where accuracy peaks.

The results, shown in \Cref{fig:dae_diffusion}, highlight a clear advantage for diffusion models. They consistently outperform DAEs, especially in low-noise regimes where DAEs tend to collapse into trivial, identity-like mappings. In contrast, diffusion models leverage weight-sharing to maintain high-quality features, achieving smoother and higher accuracy even as noise increases.

The \SWD~curve further supports this finding, revealing an inverse correlation between feature accuracy and feature differences. Diffusion model features remain significantly closer to their optimal state across noise levels, demonstrating their superior representational capacity.

This weight-sharing advantage aligns with prior findings that sequential training of DAEs across multiple noise levels improves representation quality \citep{chandra2014adaptive,geras2014scheduled,zhang2018convolutional}. Our ablation study also confirms this finding, showing that multi-scale training is essential for enhancing DAE performance in low-noise settings (details in \Cref{app:add_exp}, \Cref{tab:dae_trial}).

}


% % \vspace{-0.1in}
% In this work, we {\color{blue} always refer representation quality to the quantitative metrics used in downstream tasks—such as accuracy in classification} and adopt the following feature extraction setups to leverage diffusion models for representation learning:
% % To use diffusion models for representation learning, we 
% % adopt the following steps:

% \paragraph{Use clean images as network inputs.} First, we use the clean image $\bm x_0$ as input to the network in contrast to conventional approaches that use the noisy image $\bm x_t$ \citep{xiang2023denoising, baranchuk2021label, tang2023emergent}. This setup aligns with the goal of representation learning: {\color{blue} when training neural networks for classical representation tasks, whether in a supervised or self-supervised manner, it is standard practice to apply some kind of data augmentations or corruptions—such as cropping, color jittering, or masking. These augmentations improve the robustness of the trained model and enhance performance. However, during inference, clean, unaugmented images are typically used as inputs. Similarly, in diffusion models, since our focus is on their role in representation learning, additive Gaussian noise serves as a form of data augmentation, necessary only during training. During inference, using the clean image $\bm x_0$ as input is sufficient.} As demonstrated in \Cref{fig:use_clean}(c)-(d), this approach preserves the overall unimodal representation dynamic while achieving better performance at higher noise levels. As such, throughout the remainder of this paper, we use the clean data $\bm x_0$ as input to the diffusion model, i.e., we always consider $\bm x_{\bm \theta}(\bm x_0, t)$ where $t$ serves solely as an indicator of the noise level for diffusion model to adopt during feature extraction. 

% % \ZK{with certain fixed time step $t$}, where $t$ indicates the specific ``sub-network" of the diffusion model used as the feature extractor. 
% % \ZK{And we see the trained models as general "feature extractor"s regardless of the actual noise level of the input}
% % \qq{I am a bit confused here. In your analysis, you are using $\mb x_t$?}
% %This setup allows us to decouple denoising from representation learning, enabling a clearer analysis of the true representation ability of diffusion models.\Xiang{it might be better to explicitly state here that for the purpose of representation, the additive noise is not necessary. 'Decouple' is a little bit ambiguous}

% \vspace{-0.15in}
% \paragraph{Layer selection for representations.} Second, we extract features only from the bottleneck layer of the U-Net architecture \citep{ronneberger2015u},\footnote{In other words, the layer with the smallest feature resolution.} following the protocols used in \citep{kwon2022diffusion,park2023unsupervised}.\footnote{After feature extraction, we apply a global average pooling to the features. For instance, given a feature map of dimension $256 \times 4 \times 4$, we pool the last two dimensions, resulting in a 256-dimensional vector.} Unlike prior methods \citep{xiang2023denoising, baranchuk2021label}, we do not conduct a grid search for the optimal layer, as our focus is on understanding the process rather than achieving state-of-the-art results. 

% %In practice, choosing the bottleneck layer demonstrates competitive performance, which is also easier for simplification of analysis.


% %For a given image $\bm{x}_0$, conventional diffusion-based representation learning \citep{xiang2023denoising, baranchuk2021label, tang2023emergent} typically follows the protocol of first corrupting $\bm{x}_0$ by adding Gaussian noise according to a specified noise level. The resulting noisy image $\bm x_t = s_t \bm x_0 + \gamma_t \eps$ is then fed into a diffusion model, from which features are extracted from some intermediate network layers where the optimal layer for feature extraction is typically determined through a grid search across all layers \citep{xiang2023denoising,baranchuk2021label}.

% %In this work, to better understand the representation learning dynamics of diffusion models, we made the following two modifications.

% %\begin{itemize}[leftmargin=*]
% %    \item \textbf{Layer selection.} Since our focus in this paper is not on achieving state-of-the-art results but rather on understanding diffusion-based representation learning, we adopt the protocols used in works such as \citep{kwon2022diffusion,park2023unsupervised}, where feature representations are extracted from the bottleneck layer of the U-Net architecture (i.e., the layer with the smallest feature resolution) \citep{ronneberger2015u}\footnote{After feature extraction, we apply global average pooling to the features. For instance, given a feature map of dimensions $256 \times 4 \times 4$, we pool the last two dimensions, resulting in a 256-dimensional vector.}. 

% %    \item \textbf{Use clean images as inputs.} The conventional approach, which uses $\bm x_t$ as the network input, requires the model to extract meaningful feature representations from noisy data. As the noise level increases, the inputs become increasingly corrupted, which inevitably hinders us for assessing the true representational capacity of diffusion models. To address this limitation and examine the true dynamics of representation learning, we decouple denoising from representation by directly using the clean image $\bm{x}_0$ as input (i.e., we use $\epsilon_{\bm \theta}(\bm x_0, t)$ to extract intermediate features). As shown in \Cref{fig:use_clean}(c)-(d), using clean images results in (i) a similar unimodal trend in test accuracy and (ii) improved performance compared to noisy inputs as noise levels in $\bm{x}_t$ increase. Therefore, for the remainder of this paper, any reference to representation ability will specifically refer to the model's performance on \textbf{\emph{clean} images $\bm x_0$}.
% %\end{itemize}

% % Additionally, \Cref{fig:use_clean} highlights that utilizing clean images as inputs serves as a simple yet effective modification to enhance representation performance. In \Cref{sec:exp}, we further expand on this point, demonstrating that this straightforward adjustment leads to superior performance across various downstream tasks compared to prior methods. \xiao{mind this when writing section experiment}

% %\qq{this figure can be separated, the first low is less important here can be moved to later sections} 
% \vspace{-0.05in}
% \subsection{Relationship Between Learned Representations \& Posterior Estimation}\label{subsec:posterior}
% \vspace{-0.05in}
% % \paragraph{Using posterior estimation to uncover representation dynamics in diffusion models.}
% % For a given input $\bm x_t$, diffusion models ($\bm x_{\bm \theta}(\bm x_t, t)$) and DAEs ($f_t(\bm x_t)$) are trained to predict the posterior mean ($\E[\bm x_0 | \bm x_t]$) at a specified noise level. The feature representations extracted from intermediate network layers are, in fact, a byproduct of this prediction process\cite{xx}. Therefore, any differences in representation learning should be a reflection of differences in the quality of posterior predictions\ZK{It is worth noting that the 'quality' here is not equivalent to the common visual quality such as high-resolution, it is not because with larger noise is more; however the output image may contain less information}. To test this hypothesis, we conducted an experiment in which we used the DAE-predicted posterior on clean inputs (i.e., $f_t(\bm x_0)$) for linear probing and tracked accuracy changes across increasing noise levels, as shown in Figure XX. The plot demonstrates a similar unimodal trend for both feature accuracy and posterior accuracy, indicate that variations in feature quality across noise levels could be traced back to differences in posterior prediction quality.

% % Additionally, as demonstrated in \Cref{fig:use_clean}, the unimodal representation learning dynamic appears to be a universal phenomenon, independent of the specific network architecture. However, both diffusion models and DAEs can be trained using various network configurations, and the optimal layer for feature extraction often varies depending on the specific case \citep{xiang2023denoising}. To investigate the root cause of this unimodal dynamic in a way that is agnostic to network architecture, it is more appropriate to focus directly on differences in posterior prediction quality, which we analyze in the following section.

% %In this section, we investigate the representation learning ability of diffusion models at each noise level by studying the quality of posterior estimation $\E[\bm x_0 \vert \bm x_t]$. There are strong relationship between the quality of the learned representation and the quality of posterior estimation at multiple levels, that we elaborate in the following.

% % Since directly studying representation ability is challenging, in \Cref{sec:main} we approach the problem through its strong correlation with posterior mean estimation, $\E[\bm x_0 \vert \bm x_t]$. As we will argue, improved posterior mean estimation implies better representation quality, and vice versa. Additionally, empirical validations can be found in \Cref{fig:use_clean}.

% \paragraph{Relationship among posterior estimation, distribution recovery, and representation learning.}

% Since directly studying representation ability is challenging, in \Cref{sec:main} we approach the problem through its strong correlation with posterior mean estimation, $\E[\bm x_0 \vert \bm x_t]$. As we will argue, diffusion representation quality is closely linked with the semantic information encoded in the posterior estimation. Additionally, empirical validations can be found in \Cref{fig:use_clean}.

% \begin{itemize}[leftmargin=*]
%     \vspace{-0.1in}
%     \item \emph{Posterior estimation and distribution recovery.} Diffusion models are trained to learn the underlying data distribution by reconstructing the posterior mean $\E[\bm x_0 | \bm x_t]$ for a given input $\bm x_t$ at the specified noise level. Therefore, the quality of posterior estimation $\E[\bm x_0 \vert \bm x_t]$ reflects the degree to which the underlying distribution is captured \citep{choi2022perception,deja2023learning}. 
%     % \vspace{-0.1in}
%     \item \emph{Representation learning through distribution approximation.} On the other hand, achieving high-quality distribution approximation results in more meaningful and informative representations in unsupervised learning. This is supported by \Cref{fig:phase_transit}, where the findings, inspired by recent works \citep{zhang2024emergence}, demonstrate that diffusion models transition from memorizing the training data distribution to accurately approximating the underlying data distribution as the amount of training data increases. Consequently, better approximation of the underlying data distribution improves the quality of representation learning.
    
%     % \item \emph{Posterior estimation and distribution recovery.} Diffusion models are trained to learn the underlying data distribution by reconstructing the posterior mean $\E[\bm x_0 | \bm x_t]$ for a given input $\bm x_t$ at the specified noise level. Therefore, the quality of posterior estimation $\E[\bm x_0 \vert \bm x_t]$ reflects the degree to which the underlying distribution is captured \citep{choi2022perception}. 
%     % \item \emph{Representation learning and posterior estimation.} The feature representations learned by the network are intermediate results of the posterior reconstruction process \citep{geras2014scheduled, kwon2022diffusion}. Consequently, variations in representation learning performance reflect differences in the level of detail captured in the posterior predictions, thus indicating how comprehensively the underlying data distribution is recovered \citep{park2023understanding}.
    
%     % This is supported by \Cref{fig:phase_transit}, where the findings, inspired by recent works \citep{zhang2024emergence}, demonstrate that diffusion models transition from memorizing the training data distribution to accurately approximating the underlying data distribution as the amount of training data increases. Consequently, better approximation of the underlying data distribution improves the quality of representation learning.
% \end{itemize}
% % \qq{draw conclusion}
% Given this relationship, we use posterior estimation as a proxy for representation quality throughout our analysis. Additionally, since diffusion models tend to memorize the training data instead of learning underlying data distribution when the training dataset is small \citep{zhang2024emergence}, we focus on the case where sufficient training data is available throughout our analysis in \Cref{sec:main}. 
% % and study the effect of data complexity in representation learning in \Cref{subsec:mem_gen}.

% % and effectively learn the underlying data distribution with sufficient data , we focus on the asymptotic case where $N \rightarrow +\infty$ in \Cref{sec:main}.

% \vspace{-0.1in}