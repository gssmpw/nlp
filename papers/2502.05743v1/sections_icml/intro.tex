%Diffusion models, a new family of likelihood-based generative models, have demonstrated superior performance among many generative tasks, including image generation \citep{alkhouri2024diffusion,ho2020denoising,rombach2022high,zhang2024improving}, video generation \citep{bar2024lumiere,ho2022imagen}, speech and audio synthesis \citep{kong2020hifi,kongdiffwave2021}, semantic editing \citep{roich2022pivotal,ruiz2023dreambooth,chen2024exploring}and solving inverse problem \citep{chung2022improving,song2024solving, li2024decoupled,alkhouri2023diffusion}. At its core, diffusion models are learning a data distribution from training samples by imitating the non-equilibrium thermodynamic diffusion process \citep{sohl2015deep,ho2020denoising, song2020score}. In the forward process, training samples are gradually combined with increasing Gaussian noise until the data structure is completely destroyed while in the backward process, a model is trained to restore the structure from the noised data \citep{hyvarinen2005estimation, song2020score}. 


Diffusion models, a new class of likelihood-based generative models, have achieved great empirical success in various tasks such as image and video generation, speech and audio synthesis, and solving inverse problems \citep{alkhouri2024diffusion, ho2020denoising, rombach2022high, zhang2024improving, bar2024lumiere, ho2022imagen, kong2020hifi, kongdiffwave2021, roich2022pivotal, ruiz2023dreambooth, chen2024exploring, chung2022improving, song2024solving, li2024decoupled}. These models, consisting of forward and backward processes, learn data distributions by simulating the non-equilibrium thermodynamic diffusion process \citep{sohl2015deep, ho2020denoising, song2020score}. The forward process progressively adds Gaussian noise to training samples until the data is fully destroyed, while the backward process involves training the score to generate samples from the noisy inputs \citep{hyvarinen2005estimation, song2020score}.

% \xiao{Start from here, talk about the coarse-to-fine discovered in generation, and the unimodal representation dynamic, our focus of the paper is to theoretically study the representation dynamic, thus unveiling the trade-off between representation and generation. Also mention figure 1?}


%\xiao{discuss iclr 2025 work }  %, implying that they could serve as a unified foundation model for both generative and discriminative vision tasks.
%begun investigating their representational capacity, aiming to establish a unified foundation model capable of handling both generative and recognition-based vision tasks. 

In addition to their impressive generative capabilities, recent studies \citep{baranchuk2021label,xiang2023denoising,mukhopadhyay2023diffusion,chen2024deconstructing,tang2023emergent,han2024feature} have found the exceptional representation power of diffusion models.
They showed that the encoder in the learned denoisers can act as a powerful self-supervised representation learner, enabling strong performance on downstream tasks such as classification \citep{xiang2023denoising,mukhopadhyay2023diffusion}, semantic segmentation \citep{baranchuk2021label}, and image alignment \citep{tang2023emergent}. Notably, these learned features often match or even surpass existing methods specialized for self-supervised learning. These findings indicate the potential of diffusion models to serve as a unified foundation model for both generative and recognition vision tasks—paralleling the role of large language models like the GPT family in the NLP domain \citep{radford2019language,achiam2023gpt}. 

However, it remains unclear whether the representation capabilities of diffusion models stem from the diffusion process or the denoising mechanism \citep{fuest2024diffusion}. Moreover, despite recent endeavors \citep{chen2024deconstructing,han2024feature}, our understanding of the representation power of diffusion models across noise levels remains limited. As shown in \citet{baranchuk2021label, xiang2023denoising,tang2023emergent}, while these models exhibit a coarse-to-fine progression in generation quality from noise to image, their representation quality follows an unimodal curve—indicating a trade-off between generation and representation quality near the final stage of image generation. Understanding this unimodal representation curve is key to uncovering the mechanisms underlying representation learning in diffusion models. These insights can inform the development of more principled approaches for downstream representation learning, including improved feature selection and ensemble or distillation methods. Furthermore, understanding and balancing the trade-off between representation capacity and generative performance is essential for developing diffusion models as unified foundation models for both generative and recognition tasks. 
% a fundamental challenge lies in understanding and balancing the trade-off between their representational capacity and generative power. 
% \qq{Expand here: describe the significance of understanding the unimodal curve? facilitates feature selection? help understanding the representation mechanism, i.e., whether the representation capabilities of diffusion models stem from the diffusion process or the denoising mechanism? practical values/insights of the study? }\pw{agree!}

%Therefore, it remains unclear whether the representation capabilities of diffusion models stem from the diffusion process or the denoising mechanism \citep{fuest2024diffusion}. More fundamentally, given their generative design, \emph{when and why diffusion models can learn high-quality representations in a self-supervised manner?}

% \pw{It is better to move the discussion on the motivation of low-dimensional models before the contribution.}

\paragraph{Summary of contributions.}
% \pw{add a sentence here to motivate why we can use a low-dimensional model.}  
We introduce a mathematical framework for studying representation learning in diffusion models using low-dimensional data models that capture the intrinsic structure of image datasets \citep{pope2021intrinsic,stanczuk2022your}. Building on the denoising auto-encoder (DAE) formulation \citep{vincent2008extracting,vincent2010stacked,vincent2011connection}, we derive insights into unimodal representation quality across noise levels and the representation–generation trade-off by analyzing how diffusion models learn low-dimensional distributions. We further demonstrate how these theoretical findings enhance representation learning in practice. Our main contributions are:
%To address these challenges, we propose a mathematical framework for understanding representation learning in diffusion models via low-dimensional modeling.  Building on the denoising auto-encoder (DAE) formulation \citep{vincent2008extracting,vincent2010stacked,vincent2011connection}, we derive theoretical insights into the unimodal representation quality across noise levels and the representation–generation trade-off by examining how diffusion models learn low-dimensional data distributions. The low-dimensional model is motivated by the observation that image datasets typically have a much lower intrinsic dimension than their ambient dimensionality \citep{pope2021intrinsic,stanczuk2022your,wang2024diffusion}. Furthermore, we demonstrate that these theoretical findings provide practical guidance for enhancing representation learning. Specifically, our main contributions are as follows:
% \qq{discuss the mixture of gaussian, CSNR, DAE, using clean image as input for feature extraction. }
\begin{itemize}[leftmargin=*]
    \item \textbf{Mathematical framework for studying representation learning in diffusion models.} We introduce the Class-Specific Signal-to-Noise Ratio (CSNR) to quantify representation quality and analyze representation dynamics through the lens of how diffusion models learn a noisy mixture of low-rank Gaussians (MoLRG) distribution \citep{wang2024diffusion}. Our analysis reveals that the denoising objective is the primary driver of representation learning, while the diffusion process itself has a minimal impact. Based on these insights, we recommend using clean images as inputs for feature extraction in diffusion-based representation learning.
%    We introduce a practical metric, termed Class-Specific Signal-to-Noise Ratio (CSNR), to quantify the representation quality, and we analyze representation learning through how diffusion models learn a low-dimensional distribution - a noisy mixture of low-rank Gaussians (MoLRG). The MoLRG is motivated by the fact that image datasets typically have a much lower intrinsic dimension than their ambient dimensionality \citep{pope2021intrinsic,stanczuk2022your,wang2024diffusion}. Our study reveals that the denoising objective serves as the primary driver of the representation power in diffusion models, while the diffusion process itself plays a minimal role. Based on these insights, we advocate using clean images as inputs during feature extraction for diffusion-based representation learning. 
    
    
  %  We establish a theoretical framework to analyze the representation learning capabilities of diffusion models through the lens of optimal score matching.   Motivated by the low intrinsic dimensionality of image datasets \citep{pope2021intrinsic,stanczuk2022your,wang2024diffusion}
    % \zk{We aim to develop a framework based on the MoLRG data assumption to investigate the relationship between the levels of inner representation learned by a diffusion model and the corresponding timesteps. Additionally, we propose a practical metric to estimate the representation quality of diffusion models through posterior estimation, (showcasing applications demonstrated on classification tasks?) Building on this framework, we also offer insights into leveraging the inner representations of diffusion models. These include using clean image inputs, approximating the optimal timestep for representation extraction, principled ensembles of high- and low-level features, and so on.}
    \item \textbf{Theoretical characterization of unimodal curve and representation–generation trade-off.} Building on our mathematical framework, we theoretically characterize the unimodal behavior of representation quality across noise levels in diffusion models. By linking representation quality to the CSNR of optimal posterior estimation, we show that unimodality arises from the interplay between denoising strength and class confidence across varying noise scales. This analysis provides fundamental insights into the trade-off between representation quality and generative performance. 
    
    % \qq{refine, refer to Figure 3}
  %  We mathematically characterize the unimodal curve of representation quality in diffusion models across noise levels. We assume the data follows a noisy mixture of low-rank Gaussians distribution to capture the intrinsic low-dimensionality of image data. We analyze the unimodal trend in representation performance by relating it to the Class-specific Signal-to-Noise Ratio (\CSNR). Specifically, we consider the optimal posterior estimation function under our data assumption and show that the \CSNR~is determined by the interplay between data ``denoising" and class confidence rate as the noise scale increases. Additionally, .
    \item \textbf{Empirical insights into diffusion-based representation learning.} Our findings offer practical guidance for optimizing diffusion models in representation learning. Specifically, we introduce a soft-voting ensemble method that aggregates features across noise levels, leading to significant improvements in classification performance and robustness to label noise. Additionally, we uncover an implicit weight-sharing mechanism in diffusion models, which explains their superior performance and more stable representations compared to traditional DAEs.
    % Finally, by connecting to prior work on phase transitions in memorization vs. generalization \citep{zhang2024emergence}, we show that high-quality representations emerge only in the generalization regime, where sufficient samples enable effective data distribution learning.
 %   To this end, we propose a soft-voting ensemble method that aggregates features from diffusion models across different noise levels. Experimental results demonstrate that this approach significantly enhances the diffusion model's resilience to label noise, achieving superior and more robust performance compared to prior self-supervised methods. Furthermore, our empirical analysis reveals an implicit weight-sharing mechanism inherent in diffusion models, providing an explanation for their superior and more consistent representation performance compared to traditional denoising autoencoders (DAEs). We further connect our analysis to prior work on the phase transition between the memorization and generalization regimes with respect to sample complexity in training diffusion models \citep{zhang2024emergence}. Our findings reveal that high-quality representations are learned exclusively in the generalization regime, where sufficient samples enable diffusion models to effectively capture the underlying data distribution. 
 %   \xiao{I added this last point to connect to mem/gen, we can remove this part if we don't have enough space to discuss adequately in experiment section.}
    
    % \item \textbf{Theoretically guided design of diffusion models for robust representation learning.\zk{not designing DMs here but leveraging diffusion representations, subject to change}} We show that our theoretical studies provide insights for better leveraging trained diffusion models for representation learning. First, our study reveals an implicit weight-sharing mechanism inherent in diffusion models, which helps explain their superior and more consistent representation performance compared to traditional DAEs.\zk{Say less on DAE and put soft-voting foward? Also can we say the diffusion representations are already robust towards label noise, which can also be a novelty.} Second, we propose a soft-voting ensemble method that aggregates features across different noise levels for more robust representation learning. Our experimental results demonstrate that this approach shows better performance under noise corruptions, enabling it to achieve superior and more robust performance compared to previous supervised and self-supervised methods. \qq{maybe we can also mention memorization to generalization here}
%    Building on these theoretical insights, we propose a soft-voting ensemble method that aggregates features from diffusion models across different noise levels. Our experimental results demonstrate that this approach unleashes the diffusion model’s potential in combating label noise, enabling it to achieve superior and more robust performance compared to previous supervised and self-supervised methods. \qq{expand here}
\end{itemize}

% \qq{add a short paragraph to reiterate the significance of our result}

\paragraph{Relationship to prior results.}As discussed in \Cref{app:related},
empirical developments of leveraging diffusion models for downstream representation learning have gained significant attention. However, a theoretical understanding of how diffusion models learn representations across different noise levels remains largely unexplored. A concurrent study by \citep{han2024feature} takes initial steps in this direction by analyzing the optimization dynamics of a two-layer CNN trained with diffusion loss on binary class data. Since their framework does not explicitly distinguish between timesteps, their conclusions remain general across different noise levels. In contrast, our work characterizes and compares representations learned at different timesteps, provides a deeper understanding of diffusion-based representation learning and also extends to multi-class settings. A recent study by \citep{yue2024exploring} also investigates the influence of timesteps in diffusion-based representation learning, but with a methodological focus. Unlike our work, it does not provide a theoretical explanation or practical metrics for the emergence of unimodal representation dynamics or the trade-off between representation quality and generative performance.


 % As discussed in \Cref{app:related}, empirical developments of leveraging diffusion models for downstream representation learning have gained significant attention. Despite the empirical success, however, a theoretical understanding of how diffusion models learn representations across different noise levels remains largely unexplored. A concurrent study by \citep{han2024feature} takes initial steps in this direction by analyzing the training dynamics of representations in a two-layer convolutional network trained with a diffusion loss. In contrast, our approach focuses on the optimal posterior function, making it independent of specific model architectures. A key distinction is that \citet{han2024feature} assumes a sufficiently overparameterized network, reducing their analysis to the learning dynamics of networks trained separately on single-timestep DAE losses. Since their framework does not explicitly distinguish between timesteps, their conclusions remain general across different noise levels. In contrast, our work characterizes and compares representations learned at different timesteps, providing a deeper understanding of diffusion-based representation learning. Furthermore, while \citet{han2024feature} primarily studies binary classification, our analysis extends to multi-class settings. Although another relevant study \citep{yue2024exploring} empirically examines the role of timesteps in diffusion-based representation learning, unlike our work, it does not offer a theoretical explanation for the emergence of unimodal representation dynamics or the trade-off between representation quality and generative performance.




%Empirical efforts to utilize diffusion models for downstream representation learning tasks have become a highly active research area, as discussed in more detail in \Cref{app:related}. However, despite their empirical success, the theoretical understanding of the representation capabilities and dynamics of diffusion models across different noise levels remains largely unexplored. A concurrent study by \citep{han2024feature} has taken initial steps in this direction, analyzing the training dynamics of representations in a two-layer convolutional network trained with a diffusion loss. In contrast, our approach focuses on the optimal posterior function, making it independent of specific model architectures. \zk{A key distinction is that their approach assumes the network is sufficiently overparameterized, reducing the analysis to the learning dynamics of networks separately trained on single-timestep DAE loss. Their analysis does not rely on a specific timestep, leading to a general conclusion that does not distinguish between timesteps. In contrast, our goal is to characterize and compare the representations learned across different timesteps.} Moreover, while \citep{han2024feature} primarily addresses binary classification, our analysis is applicable to multi-class scenarios. A recent study \citep{yue2024exploring} also examines the role of timesteps in diffusion-based representation learning but their focus is more on the empirical side. Unlike our work, it does not provide a theoretical explanation for the unimodal representation dynamics or the trade-off with generation quality.

%  \qq{emphasize on significance of our results} \qq{discuss the limitations of prior work of understanding diffusion representation, and the difference from our results. Focusing on how our work is significant over existing results?} \zk{While many prior studies have leveraged the internal representations of diffusion models for various downstream tasks and observed an unimodal performance trend with respect to the timestep \citep{xiang2023denoising, baranchuk2021label}, the underlying mechanisms driving this behavior remain unclear, while we try to address such. \citep{yue2024exploring} utilized the coarse-to-fine generation bias of diffusion models to learn features of varying granularity at different timesteps. Our analysis resonates with these observations; however, we focus on understanding the representations learned by diffusion models through their outputs (i.e., posterior estimation) and establishing a generalizable framework for this purpose.
% On the theoretical side, prior works have studied the learning dynamics \citep{pretorius2018learning,steck2020autoencoders} and optimization landscape \citep{kunin2019loss} through simplified linear models trained with DAE loss which is equivalent to diffusion loss at a specific timestep. Notably \citep{han2024feature} analyzed the representations of a two-layer convolutional network trained with diffusion loss. In contrast, our approach adopts a model-free assumption, emphasizing the role of posterior estimation in shaping internal representations and accommodating a broader range of models. A key distinction is that their analysis is agnostic to the diffusion timestep, whereas timestep is a major factor in our investigation. It is also worth noting that their data assumption closely aligns with ours but restricting the number of classes to 2.} 

%================
 
%  and using a noisy mixture of low-rank Gaussian distribution, we provide theoretical insights on understanding the unimodal representation quality across noise levels.  We analyze the unimodal trend in representation performance by relating it to the Class-specific Signal-to-Noise Ratio (\CSNR). Specifically, we consider the optimal posterior estimation function under our data assumption and show that the \CSNR~is determined by the interplay between data ``denoising" and class confidence rate as the noise scale increases.



%Although image datasets can be very high-dimensional, recent results \citep{pope2021intrinsic,stanczuk2022your,wang2024diffusion} demonstrate that the intrinsic dimension of these datasets are much lower than the ambient dimension, and it has shown that the number of samples to learn the underlying distribution using diffusion models scales with the intrinsic low-dimensionality. Therefore, by being trained to capture the underlying structure of data through a controlled process of noise injection and denoising, diffusion models effectively learn meaningful and compact features. 




%This work provides a comprehensive investigation of the representation ability of diffusion models across different noise levels, based on the hypothesis that diffusion models can learn high-quality representations without supervision due to their superior ability to approximate the low-dimensional distributions of image datasets, as supported by recent findings \citep{chen2023score,wang2024diffusion} \qq{cite more recent papers here}. B We provide theoretical insights using a noisy mixture of low-rank Gaussian distributions which captures the inherent low-dimensionality of the image data distribution \citep{pope2021intrinsic,gong2019intrinsic,stanczuk2022your}. We analyze the unimodal trend in representation performance by relating it to the Class-specific Signal-to-Noise Ratio (\CSNR).

%Building on these empirical observations, we provide theoretical insights using a noisy mixture of low-rank Gaussian distributions. Our assumption captures the inherent low-dimensionality of the image data distribution \citep{pope2021intrinsic,gong2019intrinsic,stanczuk2022your}, where the data lies on a union of low-dimensional subspaces. We analyze the unimodal trend in representation performance by relating it to the Class-specific Signal-to-Noise Ratio (\CSNR). Specifically, we consider the optimal posterior estimation function under our data assumption and show that the \CSNR~is determined by the interplay between data ``denoising" and class confidence rate as the noise scale increases. Additionally, our study reveals an implicit weight-sharing mechanism inherent in diffusion models, which helps explain their strengths compared to traditional one-step DAEs, particularly in the small noise regions.


% \xiao{1. Theoretical analysis of the unimodal trend in representation quality, the coarse-to-fine generation implies the unimodal representation dynamic; 2. Motivated by our theoretical results, we propose a simple strategy to utilize features from different noise scales/granularity to achieve better classification performance and greatly enhance robustness under label noise}
%{\color{blue}
%\begin{itemize}[leftmargin=*]

%    \item \textbf{Theoretical analysis of the unimodal trend in representation quality.} Using a mixture of low-rank Gaussian distributions, we develop a theoretical framework to analyze the unimodal evolution of representation quality in diffusion models as noise levels increase. We show that this trend arises from the fine-to-coarse shift inherent in diffusion models and the interplay between denoising strength and class confidence across varying noise scales.

%    \item \textbf{Soft-voting ensemble method for enhanced robustness against label noise.} Inspired by our theoretical insights, we propose a simple yet effective strategy to aggregate features from different noise levels, enabling diffusion models to achieve superior robustness against label noise compared to traditional supervised and self-supervised methods.

%    \item \textbf{Extensive empirical validation across diverse datasets.} We validate our theoretical findings and demonstrate the effectiveness of the proposed ensemble method through comprehensive experiments on both synthetic and real-world datasets. \qq{this does not count as a contribution}

    
    % \item \textbf{Denoising objective drives the representation ability of diffusion models.} We empirically establish that the denoising objective is the primary driver of the representation ability of diffusion models, with the diffusion process playing a negligible role. Additionally, we advocate for using clean images as input during feature extraction in diffusion-based representation learning, aligning with standard practices in supervised/self-supervised learning.

    % \item \textbf{Weight sharing enhances representation learning in diffusion models.} By minimizing losses across all noise levels simultaneously, diffusion models inherently implement an implicit parameter-sharing mechanism. This mechanism is crucial for achieving superior and more consistent representation performance compared to traditional denoising autoencoders (DAEs).

%\end{itemize}
%}

%This work aims to address this question through a comprehensive investigation, both empirically and theoretically, grounded in the formulation of denoising auto-encoders (DAEs) for learning diffusion models \citep{vincent2008extracting,vincent2010stacked,vincent2011connection}. 







%\qq{what is needed to understand diffusion representation and why? unimodal, why need to understand unimodal?}



%{\color{blue}
%Moreover, previous studies have consistently revealed an intriguing phenomenon: the representation learning capabilities of diffusion models, as measured by downstream task performance, exhibit a unimodal trend as noise levels increase \citep{xiang2023denoising,baranchuk2021label,tang2023emergent}. Specifically, diffusion models attain their highest representation quality at intermediate noise levels, near the clean image, while performance deteriorates when noise levels approach either extreme—pure noise or the clean image itself. Despite the ubiquity of this observation, its underlying mechanisms remain largely unexplored. More importantly, this phenomenon contrasts with the generative performance dynamics of diffusion models, where image fidelity is maximized as the noise level approaches zero. This contrast highlights an inherent trade-off in diffusion models between generative quality and representation quality, as illustrated in \Cref{fig:use_clean}.

%In this work, we aim to demystify this trade-off by providing a theoretical analysis of the unimodal trend in representation performance, utilizing a noisy mixture of low-rank Gaussian distributions. By establishing a connection to the Class-specific Signal-to-Noise Ratio (\CSNR), we demonstrate that the unimodal representation trend arises from the fine-to-coarse shift \citep{wang2023diffusion} in posterior estimations of diffusion models as noise levels change.







% Despite the universality of this observation, its underlying mechanism remains largely unexplored, raising another critical question to theoretically understand \emph{when do diffusion models learn high-quality representations?}

% This work seeks to address two key questions, both empirically and theoretically. Empirically, we dissect the diffusion model into its denoising and diffusion processes, demonstrating that the denoising process is the primary driver of the model's representational ability, thus answering the "why" question. Theoretically, we analyze the unimodal trend in representation performance using a noisy mixture of low-rank Gaussian distributions. By relating the trend to the Class-specific Signal-to-Noise Ratio (\CSNR), we provide insights into the conditions under which high-quality representations emerge, addressing the "when" question.
%}

% This work aims to address this question through a comprehensive investigation, both empirically and theoretically, grounded in the formulation of denoising auto-encoders (DAEs) for learning diffusion models \citep{vincent2008extracting,vincent2010stacked,vincent2011connection}. We hypothesize that diffusion models can learn high-quality representations without supervision due to their superior ability to approximate the low-dimensional distributions of image datasets, as supported by recent findings \citep{wang2024diffusion}. Although image dataset can be very high-dimensional, recent results \citep{pope2021intrinsic,stanczuk2022your,wang2024diffusion} demonstrate that the intrinsic dimension of these datasets are much lower than the ambient dimension, and it has shown that the number of samples to learn the underlying distribution using diffusion models scales with the intrinsic low-dimensionality. Therefore, by being trained to capture the underlying structure of data through a controlled process of noise injection and denoising, diffusion models effectively learn meaningful and compact features. 
% On the empirical side, we support our claim by reconciling several intriguing phenomena related to the quality of learned representations in diffusion models. Recent studies \cite{zhang2024emergence} reveal that diffusion models operate in two regimes: memorization and generalization, depending on training data size. In the memorization regime with limited samples, the model captures only the empirical distribution of training data without the ability to generate new samples. In contrast, in the generalization regime, diffusion models are able to learn the underlying distribution. Our experiments in \Cref{fig:phase_transit} confirm that high-quality representations are \emph{only} learned in the generalization regime with sufficient samples due to its ability of learning the underlying distribution. More importantly, in the generalization regime, we show that the quality of hidden representations in diffusion models/DAEs follows a uni-modal curve (see \Cref{fig:use_clean} and \Cref{fig:phase_transit_2}): high-quality representations are learned at an intermediate step close to the clean image, whereas the representation quality degrades as it approaches either pure noise or the clean image.


% Building on these empirical observations, we provide theoretical insights using a noisy mixture of low-rank Gaussian distributions. Our assumption captures the inherent low-dimensionality of the image data distribution \citep{pope2021intrinsic,gong2019intrinsic,stanczuk2022your}, where the data lies on a union of low-dimensional subspaces. We analyze the unimodal trend in representation performance by relating it to the Class-specific Signal-to-Noise Ratio (\CSNR). Specifically, we consider the optimal posterior estimation function under our data assumption and show that the \CSNR~is determined by the interplay between data ``denoising" and class confidence rate as the noise scale increases. Additionally, our study reveals an implicit weight-sharing mechanism inherent in diffusion models, which helps explain their strengths compared to traditional one-step DAEs, particularly in the small noise regions.



