\begin{table*}[h!]
\renewcommand{\arraystretch}{0.90} % Adjust row height for clarity
\centering
\small
\begin{tabular}{p{0.45\textwidth}p{0.6\textwidth}}
\toprule
\textbf{Model Type and Models} & \textbf{Description} \\ \midrule

\textbf{nemo\_asr} \newline 
-- parakeet-ctc-1.1b \newline 
-- parakeet-ctc-0.6b \newline 
-- stt\_en\_conformer\_ctc\_large \newline 
-- stt\_en\_fastconformer\_ctc\_large \newline 
-- stt\_en\_conformer\_ctc\_small \newline 
-- parakeet-tdt-1.1b \newline 
-- parakeet-rnnt-1.1b \newline 
-- parakeet-rnnt-0.6b \newline 
-- stt\_en\_fastconformer\_transducer\_large \newline 
-- parakeet-tdt\_ctc-110m \newline 
-- canary-1b & 
NVIDIA's NeMo ASR models offer diverse architectures for speech-to-text applications. The Conformer-CTC model combines self-attention and convolutional operations, using Connectionist Temporal Classification (CTC) loss for efficient transcription. The Conformer-Transducer extends this by incorporating a Recurrent Neural Network Transducer (RNNT) decoder for autoregressive modeling. The Conformer-HAT variant separates label and blank score predictions, enhancing integration with external language models. For improved performance, the Fast-Conformer introduces depthwise convolutional subsampling, achieving approximately 2.4x faster encoding with minimal accuracy loss. \\ \hline

\textbf{speechbrain} \newline 
-- asr-wav2vec2-librispeech & 
SpeechBrain provides robust models for ASR and speaker recognition. \\ \hline

\textbf{data2vec} \newline 
-- data2vec-audio-large-960h \newline 
-- data2vec-audio-base-960h & 
Data2Vec models by Facebook are designed for speech representation learning and ASR. These models use a unified learning framework for multiple modalities. \\ \hline

\textbf{wav2vec2} \newline 
-- wav2vec2-large-960h-lv60-self \newline 
-- wav2vec2-large-robust-ft-libri-960h \newline 
-- wav2vec2-large-960h \newline 
-- wav2vec2-base-960h \newline 
-- wav2vec2-conformer-rope-large-960h-ft \newline 
-- wav2vec2-conformer-rel-pos-large-960h-ft & 
Wav2Vec2 models leverage self-supervised learning on raw audio for ASR. With advanced configurations, these models provide high accuracy for diverse speech-to-text tasks. \\ \hline

\textbf{mms} \newline 
-- mms-1b-all \newline 
-- mms-1b-fl102 & 
The Multilingual Speech (MMS) models by Facebook excel at speech recognition for multiple languages and accents. \\ \hline

\textbf{hubert} \newline 
-- hubert-xlarge-ls960-ft \newline 
-- hubert-large-ls960-ft & 
HuBERT models provide high-quality speech representations for ASR and other downstream speech tasks. \\ \hline

\textbf{seamless} \newline 
-- hf-seamless-m4t-large \newline 
-- hf-seamless-m4t-medium \newline 
-- seamless-m4t-v2-large & 
Seamless models focus on multilingual transcription and translation, offering robust real-time speech processing solutions. \\ \hline

\textbf{speechllm} \newline 
-- speechllm-1.5B \newline 
-- speechllm-2B & 
SpeechLLM models are fine-tuned for ASR and text generation, leveraging billions of parameters for high performance. \\ \hline

\textbf{whisper} \newline 
-- whisper-large-v3 \newline 
-- distil-large-v3 \newline 
-- whisper-large-v2 \newline 
-- whisper-large-v3-turbo \newline 
-- distil-large-v2 \newline 
-- whisper-large \newline 
-- whisper-tiny \newline 
-- whisper-medium.en \newline 
-- distil-small.en \newline 
-- whisper-small.en & 
Whisper models by OpenAI provide state-of-the-art transcription and translation capabilities for multilingual ASR. These models range from tiny to large configurations. \\ \hline

\textbf{moonshine} \newline 
-- moonshine-base \newline 
-- moonshine-tiny & 
Moonshine models are lightweight and optimized for efficient ASR on edge devices with minimal computational resources. \\ \bottomrule

\end{tabular}
\caption{Overview of various ASR along with brief description.}

\label{tab:list_of_models}
\end{table*}
