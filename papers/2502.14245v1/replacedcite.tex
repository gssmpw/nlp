\section{Related Work}
In this section, we review related work and discuss how our method differs from them.

\subsection{Retrieval-Augmented Generation}
RAG____ is a widely-used technique for addressing knowledge-intensive tasks. 
It enables LLMs to fetch relevant information from external knowledge bases, enhancing their effectiveness for complex QA, such as multi-hop KBQA.
The biggest challenge of RAG lies in how to retrieve relevant and comprehensive information.
One solution is to perform multiple rounds of retrieval to gather relevant passages____.
The other solution seeks to remove irrelevant information from retrieved texts____. 
Besides, recent work pays more attention to the effective utilization of retrieved texts using techniques like
gist memory____,
text summarization____, 
reranking____, 
context compression____.

Despite the aforementioned methods, RAG still encounters challenges when handling long texts or complex questions, since relevant information is usually scattered across different parts of the text.
To address this issue, many studies incorporate graph structures to organize the text. 
RAPTOR____ structures the text into a tree structure.
GraphRAG____, GraphReader____, and HippoRAG____ use LLMs to extract entities and relations from the text, constructing knowledge graphs (KGs). 
While effective, these methods rely on LLMs for entities and facts extraction, which increases costs.

Our work investigates a subtle problem in RAG for multi-hop QA, i.e., ``lost in retrieval'', caused by the missing topic entities in sub-questions.
Our method resolves the problem by iteratively completing the missing entities and retrieving relevant sentences containing these entities.
It eliminates the need for a complex reasoning process or an expensive KG construction pipeline.

\subsection{Multi-hop QA}
Multi-hop QA is an ideal scenario for evaluating RAG systems, since it requires strong capabilities from both the knowledge retriever and the answer generator. 
RoG____ adopts a planning-retrieval-reasoning paradigm, using relation paths in KGs to guide the retrieval of effective reasoning paths.
EfficientRAG____ fine-tunes the DeBERTa-v3-large model____ to construct a labeler and a filter for handling multi-round queries, reducing the frequency of LLM calls.
OneGen____ unifies generation and retrieval by fine-tuning the model to perform both tasks simultaneously in a single-step inference. 
Many existing multi-hop QA methods use LLMs for query decomposition____. 
However, as demonstrated in the empirical study in Section~\ref{sect:intro}, this strategy suffers from ``lost-in-retrieval''.
Our work resolves this issue without fine-tuning and frequent API calls.

\begin{figure*}[!t]
  \includegraphics[width=0.95\textwidth]{figs/framework.pdf}
  \caption{Framework overview of \modelname. 
  It first constructs a sentence graph, where the edges between sentence nodes are labeled by their common named entities.
  Given a question, it is decomposed into sub-questions. 
  Then, our iterative process involves retrieval, answering, and rewriting the unclear sub-question by filling in missing entities. 
  Finally, it integrates all retrieved sentences and answers to produce a comprehensive answer.}
  \label{fig:framework}
\end{figure*}