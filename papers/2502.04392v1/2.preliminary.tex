\section{Preliminaries}

% 这一部分需要修改
\textbf{Problem Definition}
Denote the local deployed SLM as $\mathcal{M}_\mathcal{D}$, and the cloud-based LLM as $\mathcal{M}_\mathcal{C}$.
The user's original query is restricted to the edge model for task decomposition and allocation, while the resulting sub-tasks can be resolved by either $\mathcal{M}_\mathcal{D}$ or $\mathcal{M}_\mathcal{C}$.
The entire set of reasoning tasks is represented as $\mathcal{T} = \{T_1, T_2, \dots, T_n\}$.
Let the reasoning accuracy over the entire task set be denoted as $Acc$, with the API cost represented by $C_{Api}$, and the completion time denoted as $C_{Time}$. 
For each task $T$, denote the decomposition process as:
\begin{equation}
T\rightarrow \{t^1,t^2,...t^{k}\}
\end{equation}
Based on the decomposed subtasks $t^i$, the model allocation scheme can be denoted as:
\begin{equation}
M :t^i\mapsto\{ \mathcal{M}_\mathcal{D} , \mathcal{M}_\mathcal{C}\}
\end{equation}
which prioritizes assigning simple subtasks to on-device SLM, while invoking the cloud-based LLM for handling complex subtasks.

The goal of our optimization is to minimize the discrepancy between the model's allocation scheme $M$ and the optimal scheme $M^*$:
\begin{equation}
   \min|M - M^*| 
\end{equation}
The optimal scheme $M^*$ is derived through a search strategy that maximizes SLM usage while maintaining accuracy. During the optimization process, as the allocation scheme gradually approaches the optimal solution, both time cost $C_{Time}$ and API cost $C_{Api}$ decrease, while $Acc$ remains well-maintained.

 