\begin{table*}
\centering
\renewcommand\arraystretch{1}
\setlength{\tabcolsep}{0.5mm}
\resizebox{\textwidth}{!}
{
\begin{tabular}{c|ccc|ccc|ccc|ccc|ccc|ccc|ccc}
\multirow{3}{*}{\textbf{Model}} & \multicolumn{6}{c|}{\textbf{Logical Reasoning}}                                                                                       & \multicolumn{3}{c|}{\textbf{Web Browsing}}                      & \multicolumn{9}{c|}{\textbf{Solving Math Problems}}                                                                                                                                             & \multicolumn{3}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Commonsense}\\\textbf{Reasoning}\end{tabular}}  \\ 
\cline{2-22}
                       & \multicolumn{3}{c|}{\textbf{P3}}                                  & \multicolumn{3}{c|}{\textbf{SCAN}}                                & \multicolumn{3}{c|}{\textbf{WebShop}}                           & \multicolumn{3}{c|}{\textbf{MATH}}                                & \multicolumn{3}{c|}{\textbf{CHAMP}}                          & \multicolumn{3}{c|}{\textbf{DROP}}                           & \multicolumn{3}{c}{\textbf{CSQA}}                                                                     \\ 
\cline{2-22}
                       & $Acc$                 & $C_{Time}$            & $C_{API}$             & $Acc$                 & $C_{Time}$            & $C_{API}$             & \textit{Acc}          & $C_{Time}$            & $C_{API}$           & $Acc$                 & $C_{Time}$            & $C_{API}$             & $Acc$            & $C_{Time}$            & $C_{API}$             & $Acc$            & $C_{Time}$            & $C_{API}$             & $Acc$         & $C_{Time}$            & $C_{API}$                                                         \\ 
\hline
COT (GPT-4o)           & \textbf{\underline{42\%}}  & \underline{35.8} & \underline{4.45\textcent}  & \textbf{\underline{68\%}}   & \underline{9.21}  & \underline{2.75\textcent}   &     35\% &      30.9  &    10.65\textcent                       & 51.5\% & 34.5 & 5.34\textcent  & 55.5\% & 26.4  & 4.45\textcent  & 80\%   & 11.6   & 1.30\textcent   & 80\%   &  17.0  & 3.60\textcent        \\
TOT (GPT-4o)           & 38\%  & 93.1 & 14.55\textcent & 52\%   & 32.5 & 9.82\textcent &  \textbf{\underline{36\%}}  &  \underline{62.4}    & \underline{47.34\textcent}                              & \textbf{\underline{63\%}}   & \underline{60.5} & \underline{9.97\textcent}  & \underline{57\%}   & \underline{64.2}  & \underline{11.65\textcent}  & \underline{80.5\%} & \underline{40.2} & \underline{5.41\textcent}  & \underline{82\%}   & \underline{98.8} & \underline{20.50\textcent}         \\
COT (Llama 3-8B)        & 5.5\% & 18.1 & N/A  & 17\%   & 5.0  & N/A   &   0.0\%  &   10.5   &  N/A                             & 10\%   & 21.1  & N/A   & 19\% & 13.1 & N/A   & 72\%   & 3.8  & N/A   & 70\%   & 8.4 & N/A          \\
TOT (Llama 3-8B)        & 5.5\% & 58.3 & N/A  & 13\%   & 21.8 & N/A   &   1.4\%  &   22.5  &  N/A                             & 29.5\% & 49.0 & N/A   & 25\%   & 68.1 & N/A   & 65\%   & 27.8 & N/A   & 68.5\% & 89.4 & N/A          \\
DataShunt              & 14\%  & 25.1 & 2.45\textcent  & 23.5\% & 7.6  & 1.72\textcent  &   34\%  &  30.9   & 8.35\textcent                            & 16\%   & 24.9 & 1.66\textcent & 34\%   & 19.1 & 2.98\textcent  & 74\%   & 8.6  & 0.60\textcent & 73\%   & 10.4  & 1.28\textcent        \\ 
% \hdashline
DoT (ours)             & 41\%  & 23.5 & 1.58\textcent & 63\%   & 5.5  & 1.20\textcent  &  31\%   &   17.2   &     4.97\textcent                      & 59\% & 22.6 & 1.02\textcent   & \textbf{58\%}   &  16.1   & 0.84\textcent   & \textbf{85\%}   & 4.9 & 0.32\textcent  &   \textbf{82\%}   & 9.9  & 0.49\textcent    \\     
Improvement             &  $\downarrow$2.38\%   &    $\downarrow$34.36\%      &    $\downarrow$64.49\%  &  $\downarrow$7.35\%  & $\downarrow$40.28\% & $\downarrow$56.36\%  & $\downarrow$13.89\% & $\downarrow$72.43\% & $\downarrow$89.95 & $\downarrow$6.35\%  &  $\downarrow$62.72\%              &     $\downarrow$89.50\%     &    $\uparrow$1.75\%   &  $\downarrow$74.92\%        &       $\downarrow$92.79\%              &  $\uparrow$5.59\%      & $\downarrow$87.81\%               &      $\downarrow$94.09\%    &    0\%    &      $\downarrow$89.98\%          &    
$\downarrow$97.60\%                                           
\end{tabular}
}
\vspace{2mm}
\caption{Performance of DoT and baselines on 7 benchmarks. 
$\textbf{C}_{\textbf{Time}}$ and $\textbf{C}_{\textbf{API}}$ are averaged expense for each task, where time consumption is measured in seconds, and API cost is measured in US dollar cents (\textcent). \textit{N/A} appears in experiments where reasoning is conducted solely using LlaMA without invoking the OpenAI's API key. In each benchmark, the highest reasoning accuracy is highlighted in bold. The results of the baseline with the highest \textit{Acc} are underlined which will be used to compute the "Improvement" in the last row.}
\label{tbl:mainResult}
\vspace{-7mm}
\end{table*}
