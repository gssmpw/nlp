\begin{table*}[t]
\centering
\caption{A case study examining \model's response to a query about ``\emph{graders}'' in OpenAI's 12-day edu    cational series demonstrates its video retrieval capabilities and knowledge synthesis.}
\label{tab:case study}
\small
\begin{tabularx}{\textwidth}{X X}

\toprule
\textbf{Query:} Explain the purpose and functionality of 'graders' in the context of reinforcement fine-tuning.\\

\midrule
\textbf{Input Videos:} \href{https://www.youtube.com/playlist?list=PLOXw6I10VTv9lin5AzsHAHCTrC7BdVdEM}{12 Days of OpenAI} (A total of 12 videos) \\

\midrule

\textbf{\model\ Response:} 

\texttt{\#\#\# Understanding Gradation in Reinforcement Fine-Tuning}

\texttt{**Purpose of Graders**}

\texttt{Graders are integral components in the process of reinforcement fine-tuning, mainly utilized to evaluate and improve the performance of machine learning models...} (Omitted for brevity)

\texttt{**Functionality of Graders**}

\texttt{\colorbox{lightgreen}{The grading system operates by comparing a model's outputs against those of}}

\texttt{\colorbox{lightgreen}{verified correct responses. The mechanics of this assessment involve assigning}}

\texttt{\colorbox{lightgreen}{scores to the model's outputs based on their correctness. These scores range}}

\texttt{\colorbox{lightgreen}{from zero to one, where:}}


\texttt{\colorbox{lightblue}{- A score of **0** indicates that the model's answer is completely incorrect.}}

\texttt{\colorbox{lightblue}{- A score of **1** signals that the answer is fully correct.}}

\texttt{- Scores can also be fractional, allowing for partial credit. For instance, \colorbox{lightpink}{a score of **0.7** may denote that the model's suggestion was }}
\texttt{\colorbox{lightpink}{correct but not the highest in a ranked list of possible answers.}} 

\\

\texttt{The process includes:}

\texttt{1. **Input Comparison**: The grader takes both the model’s output and the correct answer, analyzing them to derive a score.}

\texttt{2. **Graded Outputs**: This interaction allows for a dynamic reflection of the model's performance, where the scores directly influence how the model is fine-tuned in subsequent training iterations.}

\texttt{3. **Feedback Loop**: The scores obtained from graders provide feedback that can be used to adjust learning parameters and improve the model’s future responses. This highlights the feedback mechanism that is crucial for reinforcement learning.}

\\

(The remaining content are omitted for brevity.)

\\

\midrule
\textbf{Retrieved Sources by \model:}

\model\ accurately retrieved four continuous video segments from the OpenAI's 12-day show, ranging from 10:00 to 12:00 in Day 2 of the video "\href{https://www.youtube.com/watch?v=yCIYS9fx56U}{Reinforcement Fine-Tuning}." Here, we highlight key moments relevant to the detailed content in the answer. From left to right, these are retrieved moments at timestamps \colorbox{lightgreen}{10:35}, \colorbox{lightblue}{10:39}, and \colorbox{lightpink}{11:10}, which provide informative insights that help \model\ give a comprehensive answer to the query.

\\

\begin{tabular}{ccc}
    {\includegraphics[width=0.3\textwidth]{figs/openai-1.png}} &
    {\includegraphics[width=0.3\textwidth]{figs/openai-2.png}} &
    {\includegraphics[width=0.3\textwidth]{figs/openai-3.png}} \\
\end{tabular}

\\

\bottomrule

\end{tabularx}
\vspace{-0.2in}
\end{table*}