\begin{figure*}[t]
\centering
\begin{tcolorbox}[title=\texttt{Instructions for Win-Rate \& Quantitative Comparison}]
\textbf{Win-Rate Comparison\\}

You will evaluate two answers to the same question based on these criteria: **Comprehensiveness**, **Empowerment**, **Trustworthiness**, **Depth** and **Density**.\\

- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?\\
- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?\\
- **Trustworthiness**: Does the answer provide sufficient detail and align with common knowledge, enhancing its credibility?\\
- **Depth**: Does the answer provide in-depth analysis or details, rather than just superficial information?\\
- **Density**: Does the answer contain relevant information without less informative or redundant content?\\
For each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these criteria.\\

Here is the question:
\texttt{\{query\}\\}
\texttt{Here are the two answers:\\}
**Answer 1:**
\texttt{\{answer1\}\\}
**Answer 2:**
\texttt{\{answer2\}\\}

Evaluate both answers using the criteria listed above and provide detailed explanations for each criterion.
Output your evaluation in the following JSON format:

(The remaining content are omitted for brevity.)

\tikz \draw[dashed] (0,0) -- (\linewidth,0);
\textbf{Quantitative Comparison\\}

You are an expert evaluating an answer against a baseline answer based on these criteria: **Comprehensiveness**, **Empowerment**, **Trustworthiness**, **Depth** and **Density**. \\

(We omit the similar part on win-rate comparison here for brevity.)\\

For the evaluated answer labeled "Evaluation Answer," assign a score from 1 to 5 for each criterion compared to the baseline answer labeled "Baseline Answer." Then, assign an overall score based on these criteria.
The evaluation scores are defined as follows:\\
- 1: Strongly worse than the baseline answer\\
- 2: Weakly worse than the baseline answer\\
- 3: Moderate compared to the baseline answer\\
- 4: Weakly better than the baseline answer\\
- 5: Strongly better than the baseline answer\\


Here is the question:
\texttt{\{query\}}

Here are the answers:

**Baseline Answer:**
\texttt{\{baseline\_answer\}}

**Evaluation Answer:**
\texttt{\{evaluation\_answer\}\\}


Evaluate the answer using the criteria listed above and provide detailed explanations for the scores.
Output your evaluation in the following JSON format:

(The remaining content are omitted for brevity.)

\end{tcolorbox}
% \caption{Instructions for answer comparison using LLM-based judgment and score assignment.}
\caption{Instructions for LLM-based answer comparison and scoring}
\label{fig:prompt}
\end{figure*}