%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% MPNN %%%%%%%%%%%%%%%%%%%%

@InProceedings{pmlr-v70-gilmer17a,
  title = 	 {Neural Message Passing for Quantum Chemistry},
  author =       {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1263--1272},
  year = 	 {2017},
  volume = 	 {70},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf},
  abstract = 	 {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.}
}


@inproceedings{hamilton2017inductive,
 author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Inductive Representation Learning on Large Graphs},
 volume = {30},
 year = {2017}
}



@inproceedings{kipf2017semisupervised,
  title={Semi-supervised classification with graph convolutional networks},
  author={Welling, Max and Kipf, Thomas N.},
  booktitle={International Conference on Learning Representations },
  year={2016}
}



%%%% expressiveness of MPNN


@inproceedings{
xu2018powerful,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2019}
}


@inproceedings{morris2019weisfeiler,
  title={Weisfeiler and leman go neural: Higher-order graph neural networks},
  author={Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33}, 
  pages={4602--4609},
  year={2019}
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% SubGNNs %%%%%%%%%%%%%%%%%


@inproceedings{you2021identity,
  title={Identity-aware graph neural networks},
  author={You, Jiaxuan and Gomes-Selman, Jonathan M and Ying, Rex and Leskovec, Jure},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  pages={10737--10745},
  year={2021}
}

@article{zhang2021nested,
  title={Nested graph neural networks},
  author={Zhang, Muhan and Li, Pan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15734--15747},
  year={2021}
}

@article{bevilacqua2021equivariant,
  title={Equivariant subgraph aggregation networks},
  author={Bevilacqua, Beatrice and Frasca, Fabrizio and Lim, Derek and Srinivasan, Balasubramaniam and Cai, Chen and Balamurugan, Gopinath and Bronstein, Michael M and Maron, Haggai},
  journal={arXiv preprint arXiv:2110.02910},
  year={2021}
}

@article{qian2022ordered,
  title={Ordered subgraph aggregation networks},
  author={Qian, Chendi and Rattan, Gaurav and Geerts, Floris and Niepert, Mathias and Morris, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21030--21045},
  year={2022}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% MPNN vs. SubGNNs %%%%%%%%%%%%%%%


@article{zhang2024beyond,
  title={Beyond weisfeiler-lehman: A quantitative framework for GNN expressiveness},
  author={Zhang, Bohang and Gai, Jingchu and Du, Yiheng and Ye, Qiwei and He, Di and Wang, Liwei},
  journal={arXiv preprint arXiv:2401.08514},
  year={2024}
}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%$$% Equivariant NN  %%%%%%%%%%%%%
@inproceedings{worrall2017harmonic,
  title={Harmonic networks: Deep translation and rotation equivariance},
  author={Worrall, Daniel E and Garbin, Stephan J and Turmukhambetov, Daniyar and Brostow, Gabriel J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5028--5037},
  year={2017}
}


@article{thomas2018tensor,
  title={Tensor field networks: Rotation-and translation-equivariant neural networks for {3D} point clouds},
  author={Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  journal={arXiv preprint arXiv:1802.08219},
  year={2018}
}

@inproceedings{
cohen2017steerable,
title={Steerable {CNN}s},
author={Taco Cohen and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017}
}


@article{fuchs2020se,
  title={Se (3)-transformers: 3d roto-translation equivariant attention networks},
  author={Fuchs, Fabian and Worrall, Daniel and Fischer, Volker and Welling, Max},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1970--1981},
  year={2020}
}

@article{jenner2021steerable,
  title={Steerable partial differential operators for equivariant neural networks},
  author={Jenner, Erik and Weiler, Maurice},
  journal={arXiv preprint arXiv:2106.10163},
  year={2021}
}

@article{weiler2021coordinate,
  title={Coordinate Independent Convolutional Networks--Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds},
  author={Weiler, Maurice and Forr{\'e}, Patrick and Verlinde, Erik and Welling, Max},
  journal={arXiv preprint arXiv:2106.06020},
  year={2021}
}



@inproceedings{
cesa2022a,
title={A Program to Build {E(n)}-Equivariant Steerable {CNN}s },
author={Gabriele Cesa and Leon Lang and Maurice Weiler},
booktitle={International Conference on Learning Representations},
year={2022}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% Equivariant MPNN  %%%%%%%%%%%%%


@InProceedings{pmlr-v139-satorras21a,
  title = 	 {E(n) Equivariant Graph Neural Networks},
  author =       {Satorras, V\'{\i}ctor Garcia and Hoogeboom, Emiel and Welling, Max},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {9323--9332},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/satorras21a/satorras21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/satorras21a.html},
  abstract = 	 {This paper introduces a new model to learn graph neural networks equivariant to rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. In addition, whereas existing methods are limited to equivariance on 3 dimensional spaces, our model is easily scaled to higher-dimensional spaces. We demonstrate the effectiveness of our method on dynamical systems modelling, representation learning in graph autoencoders and predicting molecular properties.}
}


@inproceedings{
brandstetter2021geometric,
title={Geometric and Physical Quantities improve {E(3)} Equivariant Message Passing},
author={Johannes Brandstetter and Rob Hesselink and Elise van der Pol and Erik J Bekkers and Max Welling},
booktitle={International Conference on Learning Representations},
year={2022}
}



@article{batzner20223,
  title={E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials},
  author={Batzner, Simon and Musaelian, Albert and Sun, Lixin and Geiger, Mario and Mailoa, Jonathan P and Kornbluth, Mordechai and Molinari, Nicola and Smidt, Tess E and Kozinsky, Boris},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={1--11},
  year={2022},
  publisher={Nature Publishing Group}
}


@inproceedings{du2022se,
  title={SE (3) equivariant graph neural networks with complete local frames},
  author={Du, Weitao and Zhang, He and Du, Yuanqi and Meng, Qi and Chen, Wei and Zheng, Nanning and Shao, Bin and Liu, Tie-Yan},
  booktitle={International Conference on Machine Learning},
  pages={5583--5608},
  year={2022},
  organization={PMLR}
}


@article{du2024new,
  title={A new perspective on building efficient and expressive 3D equivariant graph neural networks},
  author={Du, Yuanqi and Wang, Limei and Feng, Dieqiao and Wang, Guifeng and Ji, Shuiwang and Gomes, Carla P and Ma, Zhi-Ming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}



@article{musaelian2023learning,
  title={Learning local equivariant representations for large-scale atomistic dynamics},
  author={Musaelian, Albert and Batzner, Simon and Johansson, Anders and Sun, Lixin and Owen, Cameron J and Kornbluth, Mordechai and Kozinsky, Boris},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={579},
  year={2023},
  publisher={Nature Publishing Group UK London}
}


%%%%%%%% Expressiveness of Equivariant MPNN  %%%%%%%%

@inproceedings{joshi2023expressive,
  title={On the expressive power of geometric graph neural networks},
  author={Joshi, Chaitanya K and Bodnar, Cristian and Mathis, Simon V and Cohen, Taco and Lio, Pietro},
  booktitle={International conference on machine learning},
  pages={15330--15355},
  year={2023},
  organization={PMLR}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Substructure-based GNNs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{wollschlager2024expressivity,
  title={Expressivity and Generalization: Fragment-Biases for Molecular GNNs},
  author={Wollschl{\"a}ger, Tom and Kemper, Niklas and Hetzel, Leon and Sommer, Johanna and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2406.08210},
  year={2024}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@inproceedings{
ganea2022independent,
title={Independent {SE}(3)-Equivariant Models for End-to-End Rigid Protein Docking},
author={Octavian-Eugen Ganea and Xinyuan Huang and Charlotte Bunne and Yatao Bian and Regina Barzilay and Tommi S. Jaakkola and Andreas Krause},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=GQjaI9mLet}
}

@article{merchant2023scaling,
  title={Scaling deep learning for materials discovery},
  author={Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
  journal={Nature},
  volume={624},
  number={7990},
  pages={80--85},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@article{watson2023novo,
  title={De novo design of protein structure and function with RFdiffusion},
  author={Watson, Joseph L and Juergens, David and Bennett, Nathaniel R and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and Ahern, Woody and Borst, Andrew J and Ragotte, Robert J and Milles, Lukas F and others},
  journal={Nature},
  volume={620},
  number={7976},
  pages={1089--1100},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@article{zhang2023artificial,
  title={Artificial intelligence for science in quantum, atomistic, and continuum systems},
  author={Zhang, Xuan and Wang, Limei and Helwig, Jacob and Luo, Youzhi and Fu, Cong and Xie, Yaochen and Liu, Meng and Lin, Yuchao and Xu, Zhao and Yan, Keqiang and others},
  journal={arXiv preprint arXiv:2307.08423},
  year={2023}
}

@article{dill2012protein,
  title={The protein-folding problem, 50 years on},
  author={Dill, Ken A and MacCallum, Justin L},
  journal={science},
  volume={338},
  number={6110},
  pages={1042--1046},
  year={2012},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{
wang2024rethinking,
title={Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks},
author={Shih-Hsin Wang and Yung-Chang Hsu and Justin Baker and Andrea L. Bertozzi and Jack Xin and Bao Wang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=mGHJAyR8w0}
}



%%%% substructure meaningful

@article{merlot2003chemical,
  title={Chemical substructures in drug discovery},
  author={Merlot, C{\'e}dric and Domine, Daniel and Cleva, Christophe and Church, Dennis J},
  journal={Drug Discovery Today},
  volume={8},
  number={13},
  pages={594--602},
  year={2003},
  publisher={Elsevier}
}

@incollection{singh2002identifying,
  title={Identifying structural motifs in proteins},
  author={Singh, Rohit and Saha, Mitul},
  booktitle={Biocomputing 2003},
  pages={228--239},
  year={2002},
  publisher={World Scientific}
}



@article{fey2020hierarchical,
  title={Hierarchical inter-message passing for learning on molecular graphs},
  author={Fey, Matthias and Yuen, Jan-Gin and Weichert, Frank},
  journal={arXiv preprint arXiv:2006.12179},
  year={2020}
}



%%%%Fragment Generation
@inproceedings{zhang2023molecule,
  title={Molecule generation for target protein binding with structural motifs},
  author={Zhang, Zaixi and Min, Yaosen and Zheng, Shuxin and Liu, Qi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{zhang2023learning,
  title={Learning subpocket prototypes for generalizable structure-based drug design},
  author={Zhang, Zaixi and Liu, Qi},
  booktitle={International Conference on Machine Learning},
  pages={41382--41398},
  year={2023},
  organization={PMLR}
}

@article{feng2024generation,
  title={Generation of 3D molecules in pockets via a language model},
  author={Feng, Wei and Wang, Lvwei and Lin, Zaiyun and Zhu, Yanhao and Wang, Han and Dong, Jianqiang and Bai, Rong and Wang, Huting and Zhou, Jielong and Peng, Wei and others},
  journal={Nature Machine Intelligence},
  volume={6},
  number={1},
  pages={62--73},
  year={2024},
  publisher={Nature Publishing Group UK London}
}


%%%% residues as nodes GNN
@article{wang2022learning,
  title={Learning hierarchical protein representations via complete 3d graph networks},
  author={Wang, Limei and Liu, Haoran and Liu, Yi and Kurtin, Jerry and Ji, Shuiwang},
  journal={arXiv preprint arXiv:2207.12600},
  year={2022}
}

@article{zhang2022protein,
  title={Protein representation learning by geometric structure pretraining},
  author={Zhang, Zuobai and Xu, Minghao and Jamasb, Arian and Chenthamarakshan, Vijil and Lozano, Aurelie and Das, Payel and Tang, Jian},
  journal={arXiv preprint arXiv:2203.06125},
  year={2022}
}

@article{jing2020learning,
  title={Learning from protein structure with geometric vector perceptrons},
  author={Jing, Bowen and Eismann, Stephan and Suriana, Patricia and Townshend, Raphael JL and Dror, Ron},
  journal={arXiv preprint arXiv:2009.01411},
  year={2020}
}


%%%%%%%%%%%%% Alignment:
@inproceedings{baker2024explicit,
  title={An Explicit Frame Construction for Normalizing 3D Point Clouds},
  author={Baker, Justin and Wang, Shih-Hsin and de Fernex, Tommaso and Wang, Bao},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}



@article{sverdlov2024expressive,
  title={On the Expressive Power of Sparse Geometric MPNNs},
  author={Sverdlov, Yonatan and Dym, Nadav},
  journal={arXiv preprint arXiv:2407.02025},
  year={2024}
}

%%% SUbgraph high order fails to generalize
@article{campi2023expressivity,
  title={Expressivity of graph neural networks through the lens of adversarial robustness},
  author={Campi, Francesco and Gosch, Lukas and Wollschl{\"a}ger, Tom and Scholten, Yan and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2308.08173},
  year={2023}
}




%%% DSSP algorithm

@article{DSSPoriginal,
author = {Kabsch, Wolfgang and Sander, Christian},
title = {Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features},
journal = {Biopolymers},
volume = {22},
number = {12},
pages = {2577-2637},
doi = {https://doi.org/10.1002/bip.360221211},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bip.360221211},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/bip.360221211},
abstract = {Abstract For a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. We have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern-recognition process of hydrogen-bonded and geometrical features extracted from x-ray coordinates. Cooperative secondary structure is recognized as repeats of the elementary hydrogen-bonding patterns “turn” and “bridge.” Repeating turns are “helices,” repeating bridges are “ladders,” connected ladders are “sheets.” Geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. Local chain “chirality” is the torsional handedness of four consecutive Cα positions and is positive for right-handed helices and negative for ideal twisted β-sheets. Curved pieces are defined as “bends.” Solvent “exposure” is given as the number of water molecules in possible contact with a residue. The end result is a compilation of the primary structure, including SS bonds, secondary structure, and solvent exposure of 62 different globular proteins. The presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. The dictionary is also available in computer-readable form for protein structure prediction work.},
year = {1983}
}

@article{DSSPnew,
    author = {Joosten, Robbie P. and te Beek, Tim A.H. and Krieger, Elmar and Hekkelman, Maarten L. and Hooft, Rob W.W. and Schneider, Reinhard and Sander, Chris and Vriend, Gert},
    title = {A series of PDB related databases for everyday needs},
    journal = {Nucleic Acids Research},
    volume = {39},
    number = {suppl_1},
    pages = {D411-D419},
    year = {2010},
    month = {11},
    abstract = {The Protein Data Bank (PDB) is the world-wide repository of macromolecular structure information. We present a series of databases that run parallel to the PDB. Each database holds one entry, if possible, for each PDB entry. DSSP holds the secondary structure of the proteins. PDBREPORT holds reports on the structure quality and lists errors. HSSP holds a multiple sequence alignment for all proteins. The PDBFINDER holds easy to parse summaries of the PDB file content, augmented with essentials from the other systems. PDB\_REDO holds re-refined, and often improved, copies of all structures solved by X-ray. WHY\_NOT summarizes why certain files could not be produced. All these systems are updated weekly. The data sets can be used for the analysis of properties of protein structures in areas ranging from structural genomics, to cancer biology and protein design.},
    issn = {0305-1048},
    doi = {10.1093/nar/gkq1105},
    url = {https://doi.org/10.1093/nar/gkq1105},
    eprint = {https://academic.oup.com/nar/article-pdf/39/suppl\_1/D411/7629557/gkq1105.pdf},
}

%%% Prions

@Article{pathogens7010020,
AUTHOR = {Wille, Holger and Requena, Jesús R.},
TITLE = {The Structure of PrPSc Prions},
JOURNAL = {Pathogens},
VOLUME = {7},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {20},
URL = {https://www.mdpi.com/2076-0817/7/1/20},
PubMedID = {29414853},
ISSN = {2076-0817},
ABSTRACT = {PrPSc (scrapie isoform of the prion protein) prions are the infectious agent behind diseases such as Creutzfeldt–Jakob disease in humans, bovine spongiform encephalopathy in cattle, chronic wasting disease in cervids (deer, elk, moose, and reindeer), as well as goat and sheep scrapie. PrPSc is an alternatively folded variant of the cellular prion protein, PrPC, which is a regular, GPI-anchored protein that is present on the cell surface of neurons and other cell types. While the structure of PrPC is well studied, the structure of PrPSc resisted high-resolution determination due to its general insolubility and propensity to aggregate. Cryo-electron microscopy, X-ray fiber diffraction, and a variety of other approaches defined the structure of PrPSc as a four-rung β-solenoid. A high-resolution structure of PrPSc still remains to be solved, but the four-rung β-solenoid architecture provides a molecular framework for the autocatalytic propagation mechanism that gives rise to the alternative conformation of PrPSc. Here, we summarize the current knowledge regarding the structure of PrPSc and speculate about the molecular conversion mechanisms that leads from PrPC to PrPSc.},
DOI = {10.3390/pathogens7010020}
}








%%%%% High order EGNN
@article{li2024distance,
  title={Is distance matrix enough for geometric deep learning?},
  author={Li, Zian and Wang, Xiyuan and Huang, Yinan and Zhang, Muhan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{batatia2022mace,
  title={MACE: Higher order equivariant message passing neural networks for fast and accurate force fields},
  author={Batatia, Ilyes and Kovacs, David P and Simm, Gregor and Ortner, Christoph and Cs{\'a}nyi, G{\'a}bor},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={11423--11436},
  year={2022}
}



%% fragment generation
@article{powers2022fragment,
  title={Fragment-based ligand generation guided by geometric deep learning on protein-ligand structure},
  author={Powers, Alexander S and Yu, Helen H and Suriana, Patricia and Dror, Ron O},
  journal={bioRxiv},
  pages={2022--03},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}


%%% protein multiscale:
@article{zhang2024multi,
  title={Multi-Scale Representation Learning for Protein Fitness Prediction},
  author={Zhang, Zuobai and Notin, Pascal and Huang, Yining and Lozano, Aur{\'e}lie and Chenthamarakshan, Vijil and Marks, Debora and Das, Payel and Tang, Jian},
  journal={arXiv preprint arXiv:2412.01108},
  year={2024}
}



%%% Graph construction


@article{schutt2017schnet,
  title={Schnet: A continuous-filter convolutional neural network for modeling quantum interactions},
  author={Sch{\"u}tt, Kristof and Kindermans, Pieter-Jan and Sauceda Felix, Huziel Enoc and Chmiela, Stefan and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}



@article{unke2019physnet,
  title={PhysNet: A neural network for predicting energies, forces, dipole moments, and partial charges},
  author={Unke, Oliver T and Meuwly, Markus},
  journal={Journal of chemical theory and computation},
  volume={15},
  number={6},
  pages={3678--3693},
  year={2019},
  publisher={ACS Publications}
}

@article{jorgensen2018neural,
  title={Neural message passing with edge updates for predicting properties of molecules and materials},
  author={J{\o}rgensen, Peter Bj{\o}rn and Jacobsen, Karsten Wedel and Schmidt, Mikkel N},
  journal={arXiv preprint arXiv:1806.03146},
  year={2018}
}

@inproceedings{gilmer2017neural,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle={International conference on machine learning},
  pages={1263--1272},
  year={2017},
  organization={PMLR}
}

