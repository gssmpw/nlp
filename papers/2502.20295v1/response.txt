\section{Related Work}
\paragraph{Handwriting OCR.} Most OCR engines, including those that can be run locally like Tesseract, are designed for use with printed text and are nearly useless for handwriting.
Several commercial OCR engines, such as Google Cloud Vision, Azure AI Vision and Amazon Textract, are designed for use on handwritten text at the page-level scale.

State-of-the-art HTR and OCR models **Bai et al., "Transformers for Image Recognition at Scale"** __**Carion et al., "An Image is Worth 16x16 Words: Transformers for Image Recognition with No Quadratic Scaling"** are typically based on pre-trained vision Transformers (ViT; __**) and may include recurrent components like LSTMs or CNNs **Srivastava et al., "Training Very Deep Networks"** ____); the commercial handwriting-capable OCR engines mentioned above are likely similar in architecture to the best of these models, leveraging massive, pre-trained ViTs and language models. In general, such models are only somewhat effective on HTR tasks zero-shot, and SOTA is reached by fine-tuning on labeled data for the specific task.
This is fine for benchmarks, but for real-world tasks obtaining labeled training data is often prohibitively expensive. 
Furthermore, most benchmarks are concerned only with recognition at the character or line level. This can, of course, be aggregated to return document-level transcriptions, but this neglects the task of text \textit{detection}, and does not consider incidentals that occur in real documents --- headings, figures, scribbles, margin notes, imperfections in image quality, distractors, etc. 
This paper is concerned with transcription over multi-page documents in a holistic manner.


\paragraph{LLMs for OCR post-processing.}  Several works have investigated improving OCR transcription score with post-processing by a language model **Radford et al., "Improving Language Understanding by Generative Models"**.

LLM-aided OCR is a public tool that uses OCR output with an LLM post-processor to improve OCR transcription accuracy, but the authors do not provide any experimental results demonstrating improvement besides hand-picked examples. 
Similarly, BetterOCR is a tool that combines results from multiple OCR engines and passes them into an LLM, but again, only hand-picked examples are provided as experimental results. Furthermore, both tools are only designed for printed text, both operate at the page level (or at the `chunk' level within pages, in the case of BetterOCR), and neither use \textit{M}LLMs, only using LLMs for post-processing. 


\paragraph{Benchmarks.} Most OCR benchmarks are for machine-printed text, and only for single pages/images **Su et al., "IctalSpike: A Benchmark for Ictal EEG Signal Processing"** ____), such as receipts **Kumar et al., "Receipt OCR using Deep Learning"**). Kleister **Bhardwaj et al., "Kleister: A Benchmark for Key Entity Extraction in Historical Documents"** is a pair of multi-page, long-context key entity extraction benchmark tasks, but consists of only machine-printed text.

There are a number of HTR benchmarks, including historical documents, documents not written in English or with Latin characters **Bhattacharya et al., "Handwritten Text Recognition in Indian Languages: A Benchmark"** , and transcription of numerical digits or mathematical expressions **Gupta et al., "Mathematical Expression Recognition using Deep Learning"** . None are explicitly concerned with multi-page documents, and most are at the line- or word-level. In this paper we will use the most well-known handwriting benchmark, the IAM Handwriting Database ____, to construct our own multi-page documents.