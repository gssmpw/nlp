\subsection{Compressed Real-World Face Image Restoration}\label{app:dmax-ot}
\subsubsection{Explaining the Choice of $\vr(\rvy)$}
To explain our choice of $\vr(\rvy)\approx\mathbb{E}[\rvx_{0}|\rvy]$, first note that the MSE of \emph{any} estimator $\hat{\rvx}_{0}$ of $\rvx_{0}$ given $\rvy$ can be written as~\citep{freirich2021a}
\begin{align}
    \text{MSE}(\rvx_{0},\hat{\rvx}_{0})
    &=\text{MSE}(\rvx_{0},\vr(\rvy))+\text{MSE}(\vr(\rvy),\hat{\rvx}_{0})\nonumber\\
    &=\text{MSE}(\vr(\rvy),\hat{\rvx}_{0})+c\label{eq:orthogonality}.
\end{align}
where $c$, the MMSE, does not depend on $\hat{\rvx}_{0}$.
In theory, our goal is to optimize the tradeoff between the MSE of $\hat{\rvx}_0$ and its output perceptual quality according to some quality measure $Q$. This can be accomplished by solving
\begin{align}\label{eq:desired_tradeoff}
    \min_{\hat{\rvx}_{0}}\text{MSE}(\rvx_{0},\hat{\rvx}_{0})+\lambda Q(\hat{\rvx}_{0}),
\end{align}
where $\lambda$ is some hyper-parameter that controls the perception-distortion tradeoff.
At test time, however, we do not have access to the original image $\rvx_0$.
By plugging \Cref{eq:orthogonality} into \Cref{eq:desired_tradeoff} we obtain
\begin{align}
    \min_{\hat{\rvx}_{0}}\text{MSE}(\rvx_{0},\hat{\rvx}_{0})+\lambda Q(\hat{\rvx}_{0})&=\min_{\hat{\rvx}_{0}}\text{MSE}(\vr(\rvy),\hat{\rvx}_{0})+c+\lambda Q(\hat{\rvx}_{0})\nonumber\\
    &=\min_{\hat{\rvx}_{0}}\text{MSE}(\vr(\rvy),\hat{\rvx}_{0})+\lambda Q(\hat{\rvx}_{0}).\label{eq:opt-mse-real-world}
\end{align}
Namely, as long as $\vr(\rvy)$ is a good approximation of the \emph{true} MMSE estimator, we can rely on it for optimizing tradeoff (\ref{eq:desired_tradeoff}) without having access to $\rvx_{0}$.
This resembles our approach in \Cref{sec:bfr}, where we \emph{greedily} optimize \Cref{eq:opt-mse-real-world} throughout the trajectory of the DDCM sampling process.



\subsubsection{Additional Details and Experiments}
We use the PyIQA package to compute all perceptual quality measures, with \texttt{niqe} for NIQE, \texttt{topiq\_nr-face} for TOPIQ, \texttt{clipiqa+} for $\text{CLIP-IQA}^{+}$, and \texttt{fid\_dinov2} for $\text{FD}_{\text{DINOv2}}$, adopting the default settings for each measure.
Additional qualitative and quantitative comparisons are shown in \cref{fig:real-world-qualitative-appendix,,fig:lfw-quantitative-appendix,,fig:celeba-quantitative-appendix,,fig:webphoto-quantitative-appendix}.

\begin{figure}
    \centering
    \includegraphics[height=21cm]{figures/blind_face_restoration/real-world-comparison-appendix.pdf}
    \caption{\textbf{Qualitative comparison of real-world face image restoration methods}. Our method produces high perceptual quality results with less artifacts compared to previous methods, especially for challenging datasets such as WIDER-Test.}
    \label{fig:real-world-qualitative-appendix}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/blind_face_restoration/blind_face_restoration_main_text_celeba.pdf}
    \caption{\textbf{Quantitative comparison of real-world face image restoration methods, evaluated on the CelebA-Test dataset.} We successfully optimize each NR-IQA measure, surpassing the scores of previous methods. Here, only our NIQE-based solution generalizes well to $\text{FD}_{\text{DINOv2}}$ in terms of perceptual quality.}
    \label{fig:celeba-quantitative-appendix}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/blind_face_restoration/blind_face_restoration_main_text_lfw.pdf}
    \caption{\textbf{Quantitative comparison of real-world face image restoration methods, evaluated on the LFW-Test dataset.} We successfully optimize each NR-IQA measure, surpassing the scores of previous methods. All our solutions achieve impressive $\text{FD}_{\text{DINOv2}}$ scores, while our NIQE-based solution surpasses all methods according to this measure.}
    \label{fig:lfw-quantitative-appendix}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/blind_face_restoration/blind_face_restoration_main_text_webphoto.pdf}
    \caption{\textbf{Quantitative comparison of real-world face image restoration methods, evaluated on the WebPhoto-Test dataset.} We successfully optimize each NR-IQA measure, surpassing the scores of previous methods. Our TOPIQ-based solution achieves the best $\text{FD}_{\text{DINOv2}}$ scores compared to all methods..}
    \label{fig:webphoto-quantitative-appendix}
\end{figure}
