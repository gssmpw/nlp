\subsection{Compressed Text-Based Image Editing}\label{app:editing}

Image editing has seen significant progress in recent years, particularly in solutions that rely on pre-trained DDMs.
Generally speaking, most methods rely on inversion~\citep{huberman2024edit,manor2024zeroshot,wu2023latent,wallace2023edict,hertz2023delta}, noising and denoising the original input~\citep{meng2022sdedit}, or manipulating the DDM's attention layers~\citep{hertz2023prompttoprompt,tumanyan2023plug}.
We demonstrate a simple approach for editing images using DDCM with a text-conditional DDM. 

Specifically, we compress an image while feeding the DDM with a source prompt $c_{\text{src}}$ describing the image.
To edit the image, we start by decoding it up to timestep $T_\text{edit}$ while feeding the DDM with the original prompt $c_{\text{src}}$.
We then continue with the decoding from timestep $T_\text{edit}$, while feeding the DDM with the target prompt $c_{\text{dst}}$.
Intuitively, this approach should preserve the low frequency contents in the original image (e.g., objects), while guiding the image towards the described edit.

We compare our approach to DDPM inversion~\citep{huberman2024edit} and DDIM inversion~\citep{song2021denoising}. 
For DDPM inversion we set $T=100, T_\text{skip}=36$, as recommended by the authors. For DDIM inversion we set $T=100$, and follow \citet{huberman2024edit} to additionally apply DDIM inversion mid-way, using $T_\text{skip}=40$.
For our approach, we set $T=1000$ and $T_\text{edit}=600$. Note that this value of $T_\text{edit}$ is equivalent to $T_\text{skip}=40$ if $T=100$ sampling steps were used. 
For all methods we use the pre-trained Stable Diffusion 1.4 checkpoint from \href{https://huggingface.co/CompVis/stable-diffusion-v1-4}{Hugging Face}. Images are taken from the modified-ImageNetR-TI2I dataset~\citep{huberman2024edit, tumanyan2023plug}.

Preliminary qualitative results are shown \Cref{fig:editing}.
Our approach is less structure preserving than DDPM inversion, while offering more semantic object preservation than DDIM inversion. 
We encourage future works to investigate DDCM-based image editing methods.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{figures/editing.pdf}
    \caption{\textbf{Qualitative comparison of image editing methods.} Our approach preserves less image structure compared to DDPM inversion, while offering more semantic object preservation than DDIM inversion. This can be quite useful in scenarios where the editing prompt requires major structural changes, such as transforming a sketch of a cat into an origami of a bear.}
    \label{fig:editing}
\end{figure}
