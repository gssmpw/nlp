%%
%% Copyright 2007-2020 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%%
%%
%% $Id: elsarticle-template-num.tex 190 2020-11-23 11:12:32Z rishi $
%%
%%
\documentclass[3p,12]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{float}
\usepackage[numbers]{natbib}
\usepackage{comment}
\usepackage{adjustbox}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{soul}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{tabularx}
\usepackage{array}
\usepackage[colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue]{hyperref}
\renewcommand{\equationautorefname}{Eq.}
\biboptions{sort&compress}
\renewcommand{\vec}[1]{\ensuremath\boldsymbol{#1}}
\newcommand{\newtext}[1]{\textcolor{red}{#1}}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\journal{Applied Mathematics Letters}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Modified Hermite Radial Basis Functions}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author[1]{Amirhossein Fashamiha}
%\ead{afashami@buffalo.edu}
\author[1]{David Salac\corref{cor1}}
\ead{davidsal@buffalo.edu}
\cortext[cor1]{Corresponding author}


\affiliation[1]{organization={Department of Mechanical and Aerospace Engineering, University at Buffalo},%Department and Organization
            %addressline={},
            city={Buffalo},
            state={NY},
            postcode={14260-4400},
            country={United States}}

\begin{abstract}
%% Text of abstract
Accurate interpolation of functions and derivatives is crucial in solving partial differential equations. Hermite Radial Basis Function (HRBF) methods improve accuracy by incorporating derivative information but suffer from ill-conditioning at low to moderate shape parameters for infinitely smooth kernels. This work proposes a Modified HRBF (MHRBF) method that introduces an additional polynomial to balance kernel behavior, improving accuracy while maintaining or lowering computational cost. The numerical results show that MHRBF achieves lower $L_\infty$-errors with fewer unknowns compared with the original HRBF, making it a robust alternative for stable and accurate RBF-based interpolation.
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Hermite Radial Basis Functions \sep Numerical Stability \sep High-Order Interpolation \sep Computational Cost
%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}
\label{}
Achieving high-order approximations of functions and their derivatives, particularly for solving partial differential equations (PDEs)~\cite{kansa1990multiquadrics, mai2003approximation, kansa2004volumetric, li2013localized, dehghan2014numerical}, has become a central focus in scientific and engineering research. While the term Radial Basis Function (RBF) was first introduced in 1983 by Dyn and Levin~\cite{Dyn1983}, functions which are now recognized such as the Multiquadric (MQ)~\cite{Hardy1971} and Thin Plate Splines (TPS)~\cite{Harder1972} were introduced in the 1970s. Notably, Franke~\cite{franke1979critical, franke1982scattered} demonstrated that the MQ RBF offered superior accuracy and smoothness for reconstructing surfaces from irregularly distributed points compared to other methods available at that time. Subsequently, Kansa pioneered the use of RBFs for solving PDEs~\cite{kansa1990multiquadrics}.

Hermite interpolation, introduced by Charles Hermite in 1878, evaluates a function and its derivatives at specific points using predefined nodal values~\cite{davis1975interpolation}. Building on this, Birkhoff proposed Hermite-Birkhoff interpolation~\cite{birkhoff1906general}, enabling the interpolation of higher-order derivatives based solely on prescribed nodal values of those derivatives. Wu later extended RBFs to the Hermite-Birkhoff framework, creating the Hermite RBF (HRBF) approach, which combines RBFs with their derivatives~\cite{zongmin1992hermite}. This HRBF method enables both function and derivative interpolation, making it well-suited to handle gradient and higher-order derivative constraints in applications.

In this paper, we propose a Modified Hermite Radial Basis Function (MHRBF) method that introduces spatially varying coefficients into the kernel, enabling improved interpolation accuracy without increasing computational cost. Unlike conventional HRBF methods, which rely solely on the RBF and its derivatives, the proposed approach modifies the kernel to explicitly control localized behavior through multiplicative coefficients. By reducing the influence of the kernel near interpolation points and balancing it across the domain, this modification enhances the ability of the method to capture fine details while maintaining or even reducing computational expense. Furthermore, the new formulation reduces the dependency on higher-order derivatives by limiting their contribution to one order lower than in conventional HRBF methods. Overall, the MHRBF method bridges the gap between accuracy and computational cost, offering a robust approach to interpolation problems.

\section{Hermite and Modified Hermite Radial Basis Functions}
RBFs are a class of functions employed for interpolating multivariate data in a mesh-free manner. The sole constraint in standard RBFs for function representation is $s(\vec{x}_p)=f_p$, where $(\vec{x}_p,f_p)$ for $p\in[1,N]$ is the set of given data and $s(\vec{x})=\sum_{i=1}^N w_i \phi(\|\vec{x}-\vec{x}_i\|)$ denotes the interpolating function. Here $w_i$ is a set of weights and $\phi(\|\vec{x}-\vec{x}_i\|)$ is the RBF kernel. Sample kernels include those shown in~\autoref{kernels} where $r=\|\vec{x}-\vec{x}_i\|$ is the distance between two points and $\varepsilon$ is a shape parameter. The RBF weights, $w_i$, are calculated to enforce the constraint that $s(\vec{x}_p)=f_p$, which results in a linear system that must be solved for a given data-set.

\begin{table}[h]
\centering
\caption{Classes of Basis Functions and Their Radial Functions}
\resizebox{0.85\textwidth}{!}{
\begin{tabular}{>{\raggedright\arraybackslash}p{0.45\textwidth} >{\raggedright\arraybackslash}p{0.5\textwidth}}
\toprule
Class of Basis Function & Radial Function $\phi(r)$ \\
\midrule
Gaussian (GA)           & $e^{-(\varepsilon r)^2}$ \\
Polyharmonic Spline (PHS) & $r^{2k-1}$ or $r^{2k}\log r$, $k \in \mathbb{N}$ \\
Multiquadric (MQ)       & $\sqrt{1+(\varepsilon r)^2}$ \\
\bottomrule
\end{tabular}
}
\label{kernels}
\end{table}

In \autoref{kernels}, the shape parameter ($\varepsilon$) for infinitely smooth RBFs influences both the flatness of the function and the accuracy of the interpolant. Lowering $\varepsilon$ can improve accuracy but may lead to ill-conditioning and numerical instability~\cite{flyer2016role}, especially as $\varepsilon$ approaches zero, resulting in the ``flat limit''~\cite{driscoll2002interpolation} where basis functions converge to a constant, nearly making the interpolation matrix singular. Conversely, larger values of $\varepsilon$ can result in excessive localization, causing the interpolation to miss smooth trends and a degradation in accuracy. One common modification is to augment the interpolant with a polynomial of order $l$ such that $s(\vec{x})=\sum_{i=1}^N w_i \phi(\|\vec{x}-\vec{x}_i\|) + \sum_{k=1}^M\lambda_k p_k(\vec{x})$ where $M$ is the number of basis functions needed to describe an $l^{th}$-order polynomial in $d$-dimensions. Related methods, such as RBF-CP~\cite{fornberg2004stable}, RBF-QR \cite{driscoll2002interpolation, larsson2013stable}, and RBF-GA~\cite{fornberg2013stable} have also been developed to address the stability issues, though they can be computationally intensive.

The HRBF interpolant extends the standard RBF by incorporating constraints on both the function values and gradients at each interpolation point $\vec{x}_p$, ensuring gradient continuity; an essential feature for derivative based problems like PDEs~\cite{lehto2017radial}. Specifically, the HRBF satisfies $s(\vec{x}_p)=f_p$ and $\nabla s(\vec{x}_p)=\vec{g}_p$, where $f_p$ and $\vec{g}_p$ are the known function values and gradients, respectively, at $\vec{x}_p$.  The formulation for HRBF can be expressed as:
\begin{equation}\label{hermite-first}
s(\vec{x})=\sum^{N}_{i=1}\left(w_{i}\phi(\|\vec{x}- \vec{x}_{i}\|)+\vec{b}_{i}\cdot\nabla\phi(\|\vec{x}-\vec{x}_{i}\|)\right)+\sum^{M}_{k=1}\lambda_{k}p_k(\vec{x}).
\end{equation}
The second term incorporates gradient information, with $\nabla$ as the gradient operator acting on $\phi$, and
$\vec{b}_{i} = \begin{bmatrix} \alpha_{i} & \beta_{i} & \gamma_{i} \end{bmatrix}^T$ (in 3D) representing the weight vector associated with the gradients at the interpolation points $\vec{x}_{i}$.


In two dimensions, computing the HRBF weights requires solving the following linear system:
\begin{equation}\label{augmentedmatrix}
\begin{bmatrix}
    \vec{A} & \vec{A}_x & \vec{A}_y & \vec{P}\\
    \vec{A}_x & \vec{A}_{xx} & \vec{A}_{yy} & \vec{P}_x\\
    \vec{A}_y & \vec{A}_{xy} & \vec{A}_{yy} & \vec{P}_y\\
    \vec{P}^T & \vec{P}^T_x & \vec{P}^T_y & \vec{0}
\end{bmatrix}
\begin{bmatrix}
   \vec{w} \\
   \vec{\alpha}\\
   \vec{\beta}\\
   \vec{\lambda}
\end{bmatrix}
=
\begin{bmatrix}
    \vec{f}\\
    \vec{f}_x\\
    \vec{f}_y\\
    \vec{0}
\end{bmatrix}
\end{equation}
where $\vec{A}$ is the matrix of kernel and $\vec{P}$ is the matrix of polynomial terms, with subscripts representing the derivatives of the kernel or polynomial, as appropriate. Micchelli's Theorem~\cite{micchelli1984interpolation} guarantees that the interpolation matrix in~\autoref{augmentedmatrix} is non-singular for various classes of RBFs when distinct nodes are used in the dataset. While non-singularity ensures a unique solution, it does not address the matrix conditioning or the accuracy of the interpolant. Therefore, the selection of $\varepsilon$ remains critical in the sense of balance between accuracy and numerical stability for infinitely smooth RBFs such as GA and MQ. Infinitely smooth RBFs are widely used due to their superior approximation accuracy and ability to capture fine-scale features~\cite{larsson2003numerical}. However, their sensitivity to $\varepsilon$ introduces major challenges. As $\varepsilon$ decreases, the kernel flattens, leading to ill-conditioning and stagnation errors, where accuracy ceases to improve despite increasing node density. In contrast, larger $\varepsilon$ values localize the kernel, improving conditioning but increasing interpolation error due to underfitting. One common alternative is piecewise smooth RBFs such as PHS, which do not require a shape parameter and are less prone to ill-conditioning. However, these functions lack the exponential convergence rates of infinitely smooth RBFs, making them unsuitable for high accuracy applications that benefit from smooth kernels like GA and MQ~\cite{fornberg2007runge}. Therefore, instead of replacing smooth RBFs with PHS, a more effective strategy is to modify the HRBF formulation to enhance accuracy while maintaining or even reducing the computational cost.

The MHRBF interpolant attempts to enhance interpolation accuracy by incorporating polynomial scaling terms into the kernel. This modification mitigates the sensivity to $\varepsilon$ and reduces the need for higher-order derivatives of the kernel. Specifically the interpolant is now defined as:
\begin{equation}\label{xx}
    s(\vec{x})=\sum^{N}_{i=1}\left\{w_{i}\left[\prod_{j=1}^{3} \left( \vec{x}_{j}-\vec{x}_{i,j} \right)^n\right]+(\vec{x}-\vec{x}_i)^{2n}\cdot\vec{b}_i\right\}\phi(\|\vec{x}-\vec{x}_i\|) + \sum^{M}_{k=1}\lambda_{k}p_k(\vec{x}),
\end{equation}
where $w_i$, $\vec{b}_i$, and $\lambda_i$ have the same meaning as in~\autoref{hermite-first} and powers are performed component-wise. For clarity, in two-dimensions the first portion of~\autoref{xx} can be written as
\begin{equation}
    \sum_i^N\left((x-x_i)^n(y-y_i)^nw_i + (x-x_i)^{2n}\alpha_i + (y-y_i)^{2n}\beta_i\right)\phi(\|\vec{x}-\vec{x}_i\|)
\end{equation}
while the resulting linear system can be written as:
\begin{equation}\label{augmentedmatrix2}
\begin{bmatrix}
    \vec{M}\vec{A} & \vec{N}\vec{A} & \vec{Q}\vec{A} & \vec{P}\\
    \vec{M}_{x}\vec{A} + \vec{M}\vec{A}_{x} & \vec{N}_{x}\vec{A} + \vec{N}\vec{A}_{x} & \vec{Q}\vec{A}_{x} & \vec{P}_x\\
    \vec{M}_{y}\vec{A} + \vec{M}\vec{A}_{y} & \vec{N}\vec{A}_{y} & \vec{Q}_{y}\vec{A} + \vec{Q}\vec{A}_{y} & \vec{P}_y\\
    \vec{P}^T & \vec{P}^T_x & \vec{P}^T_y & \vec{0}
\end{bmatrix}
\begin{bmatrix}
   \vec{w} \\
   \vec{\alpha}\\
   \vec{\beta}\\
   \vec{\lambda}
\end{bmatrix}
=
\begin{bmatrix}
    \vec{f}\\
    \vec{f}_x\\
    \vec{f}_y\\
    \vec{0}
\end{bmatrix},
\end{equation}
where \( \vec{M} \), \( \vec{N} \), and \( \vec{Q} \) are matrices containing the terms \( (x - x_i)^n (y - y_i)^n \), \( (x - x_i)^{2n} \), and \( (y - y_i)^{2n} \), respectively, each representing pairwise distances between points in their respective directions. While the system is no longer symmetric, the MHRBF only requires first derivatives of the kernel which scale as $h^2$ if $\varepsilon\propto h$, where $h$ is the characteristic spacing between nodes. The HRBF, on the other hand, requires second derivatives which scale as $h^4$. This modification will improve the stability of the method as $h$ decreases.

\section{Results and Discussion}
This study evaluates the MHRBF method against the original HRBF on benchmark case inspired by Ref.~\cite{flyer2016role} using the GA RBF kernel. The given data consists of 56 nodes arranged in a minimum-energy configuration~\cite{Moreno2025} contained in a radius of $R=0.1$. The errors are computed using 60 Halton set evaluation nodes contained near the center, see \autoref{minenergy}.

The function used throughout this study is defined as $f(x,y)=1+\sin(4x)+\cos(3x)+\sin(2y)$. The first scenario examines accuracy by computing the $L_\infty$ error for function interpolation and its first derivatives in both the $x$ and $y$ directions. Additionally, we report the condition number ($\kappa$) of the system matrices, although numerical stability is not the primary focus of this work. The goal is to assess the accuracy benefits of MHRBF across a range of shape parameters ($\varepsilon$), varying from $0.001$ to $10$. To avoid excessive complexity in the plots, we augment the kernels with a fixed polynomial degree of $6$. Similarly, the MHRBF method introduces an exponent parameter $n$, set to $4$ in this study, deferring an in-depth analysis of its optimal selection to future work. The results, presented in \autoref{results1}, include plots of the $L_\infty$ error and condition numbers as functions of $\varepsilon$.

\begin{figure}[H]
    \centering
    \makebox[0.6\textwidth]{ % Ensures the subfigures span the full width
        \begin{subfigure}{0.25\textwidth}
            \centering
            \includegraphics[width=\linewidth]{fig1.pdf}
            \caption{Interpolation nodes}
        \end{subfigure}
        \hfill % Automatically distributes space
        \begin{subfigure}{0.25\textwidth}
            \centering
            \includegraphics[width=\linewidth]{fig2.pdf}
            \caption{Center evaluation nodes}
        \end{subfigure}
    }
    \captionsetup{font=small}
    \caption{Distribution of interpolation and evaluation nodes within a circle of radius 0.1.}
    \label{minenergy}
\end{figure}

\begin{figure}[H]
    \centering
    % First part of the figure (top row)
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{fig3.pdf}
        \caption{Error in $f$ vs. shape parameter}
        \label{fig:error_f}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{fig4.pdf}
        \caption{Error in $f_x$ vs. shape parameter}
        \label{fig:error_fx}
    \end{subfigure}
    \vspace{0.15cm}

    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{fig5.pdf}
        \caption{Error in $f_y$ vs. shape parameter}
        \label{fig:error_fy}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{fig6.pdf}
        \caption{Condition number vs. shape parameter}
        \label{fig:cond}
    \end{subfigure}

    \captionsetup{font=footnotesize}
    \caption{Comparison of Accuracy and Numerical Stability for HRBF and MHRBF: The errors (function, $f$, and its first derivatives, $f_x$ and $f_y$) and condition number computed in double precision for GA kernel, as functions of shape parameter $\varepsilon$, with polynomial degree of $6$ and $n=4$ for MHRBF.}
    \label{results1}
\end{figure}

The results in \autoref{results1} reveal significant accuracy improvements with MHRBF compared to HRBF. Since the error trends for $\nabla f$ closely follow that of $f$, the subsequent analysis focuses primarily on the function interpolation. \autoref{fig:error_f} demonstrates that the MHRBF achieves low error over a large range of $\varepsilon$ values, with the error $\sim 10^{-14}$ for all $\varepsilon\gtrsim0.5$, despite the fact that the condition number of the MHRBF being higher than the HRBF in this range, compared to the HRBF method, which has a minimum of $\sim 10^{-13}$ for $\varepsilon=10$. Unlike the MHRBF method, the error for the HRBF method rapidly increases with smaller $\varepsilon$.

In the original HRBF, for very small shape parameters ($\varepsilon<<1$), the GA kernel becomes nearly flat, making the entries in the upper left block of the system matrix (\autoref{augmentedmatrix}) almost identical to 1. Meanwhile, derivative related terms approach zero, failing to sufficiently break the near linear dependencies in the matrix. Combined with the symmetry of the system matrix, this near linear dependence leads to severe ill-conditioning. The key innovation of MHRBF lies in its polynomial scaling terms, which introduce asymmetry by weighting points differently based on their position relative to ($x_0,y_0$). Consequently, the MHRBF addresses the issue of symmetry and near linear dependencies in original HRBF, stabilizing the matrix and improving accuracy for very small $\varepsilon$. For moderate values of the shape parameter ($\varepsilon\approx1$), in addition to the symmetric structure of the system matrix (\autoref{augmentedmatrix}), the dominant kernel terms in the upper left block still overshadow the derivative terms. However, the polynomial scaling terms in MHRBF mitigate this imbalance, allowing derivative terms to play a more proportional role in interpolation, thereby preserving accuracy. For large shape parameters ($\varepsilon\approx10$), both methods experience accuracy degradation due to underfitting. The GA kernel and its derivatives rapidly decay to zero, leading to sparse interactions between nodes and reduced interpolation quality.

Next, consider the computational cost of the MHRB and the original HRBF by determining the computational cost necessary to achieve an error threshold assuming a fixed radius of $R=0.1$, \newtext{\autoref{results2}}. The MHRBF is augmented with polynomial degree of 0 and 1 while the original HRBF is augmented with polynomial degrees 0, 1, 3, and 5. The computational cost is defined as the total number of unknowns in the interpolation matrix, see \autoref{augmentedmatrix} and \autoref{augmentedmatrix2}. This is equivalent to three times the number of nodes within $R=0.1$ plus the number of basis functions necessary to describe the augmenting polynomial. The shape parameter for MHRBF is set to $0.5$ and for the original HRBF it is set to 10, both of which serve as a rough estimate for the optimal accuracy for both methods. As before we consider an exponent of $n=4$ in the MHRBF.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{fig7.pdf}
    \captionsetup{font=footnotesize}
    \caption{Comparison of the minimum number of unknowns needed to reach a target error for HRBF and MHRBF. HRBF uses polynomials of degrees 0, 1, 3, 5, 7 with $\varepsilon = 10$, while MHRBF uses $\varepsilon = 0.5$ and $n = 4$, with polynomial degree 0 and 1.}
    \label{results2}
\end{figure}

As expected the achievable error decreases as the number of nodes for both the HRBF and the MHRBF increases. The HRBF had minimum errors ranged from $4\times10^{-9}$ using 127 unknowns (42 nodes) for a polynomial degree of order 0 to $2\times10^{-13}$ using 168 unknowns (49 nodes) for a polynomial degree of order 5. In contrast, the MHRBF with polynomial degree of order 0 was able to reach an error of $4\times10^{15}$ with 106 unknowns (35 nodes) and an error of $2\times10^{-15}$ with 81 unknowns (26 nodes) using a first-order augmenting polynomial. Overall the MHRBF method is able to achieve the same accuracy as the HRBF using much fewer unknowns, particularly when using a first-order augmenting polynomial.

\section{Conclusion}
This study demonstrates that the MHRBF method significantly improves accuracy and computational efficiency compared to the original HRBF. The accuracy results show that MHRBF consistently achieves lower $L_\infty$ errors across a wide range of shape parameters, particularly excelling for small to moderate $\varepsilon$. The polynomial scaling terms in MHRBF effectively mitigate symmetry induced numerical instability, leading to enhanced interpolation accuracy. Additionally, the computational cost analysis reveals that MHRBF achieves superior accuracy with fewer unknowns, reducing the number of required grid points compared to HRBF. These findings highlight MHRBF as a promising approach for improving RBF-based interpolation while maintaining numerical stability and efficiency.

\bibliographystyle{unsrt}  % You can choose a different style (e.g., IEEE, ACM, etc.)
\begin{thebibliography}{10}

\bibitem{kansa1990multiquadrics}
Edward~J Kansa.
\newblock Multiquadrics—{A} scattered data approximation scheme with
  applications to computational fluid-dynamics—{II} {S}olutions to parabolic,
  hyperbolic and elliptic partial differential equations.
\newblock {\em Computers \& Mathematics with Applications}, 19(8-9):147--161,
  1990.

\bibitem{mai2003approximation}
Nam Mai-Duy and Thanh Tran-Cong.
\newblock Approximation of function and its derivatives using radial basis
  function networks.
\newblock {\em Applied Mathematical Modelling}, 27(3):197--220, 2003.

\bibitem{kansa2004volumetric}
EJ~Kansa, H~Power, GE~Fasshauer, and L~Ling.
\newblock A volumetric integral radial basis function method for time-dependent
  partial differential equations. {I}. formulation.
\newblock {\em Engineering Analysis with Boundary Elements}, 28(10):1191--1206,
  2004.

\bibitem{li2013localized}
Ming Li, Wen Chen, and CS~Chen.
\newblock The localized rbfs collocation methods for solving high dimensional
  pdes.
\newblock {\em Engineering Analysis with Boundary Elements}, 37(10):1300--1304,
  2013.

\bibitem{dehghan2014numerical}
Mehdi Dehghan and Vahid Mohammadi.
\newblock The numerical solution of {F}okker--{P}lanck equation with radial
  basis functions (rbfs) based on the meshless technique of kansa's approach
  and galerkin method.
\newblock {\em Engineering Analysis with Boundary Elements}, 47:38--63, 2014.

\bibitem{Dyn1983}
Nira Dyn and David Levin.
\newblock Iterative solution of systems originating from integral equations and
  surface interpolation.
\newblock {\em SIAM Journal on Numerical Analysis}, 20(2):377--390, 1983.

\bibitem{Hardy1971}
Rolland~L. Hardy.
\newblock Multiquadric equations of topography and other irregular surfaces.
\newblock {\em Journal of Geophysical Research (1896-1977)}, 76(8):1905--1915,
  1971.

\bibitem{Harder1972}
Robert~L. Harder and Rober~N. Desmarais.
\newblock Interpolation using surface splines.
\newblock {\em Journal of Aircraft}, 9(2):189--191, 1972.

\bibitem{franke1979critical}
Richard Franke.
\newblock {\em A critical comparison of some methods for interpolation of
  scattered data}.
\newblock Naval Postgraduate School Monterey, CA, 1979.

\bibitem{franke1982scattered}
Richard Franke.
\newblock Scattered data interpolation: {T}ests of some methods.
\newblock {\em Mathematics of Computation}, 38(157):181--200, 1982.

\bibitem{davis1975interpolation}
Philip~J Davis.
\newblock {\em Interpolation and Approximation}.
\newblock Courier Corporation, 1975.

\bibitem{birkhoff1906general}
George~David Birkhoff.
\newblock General mean value and remainder theorems with applications to
  mechanical differentiation and quadrature.
\newblock {\em Transactions of the American Mathematical Society},
  7(1):107--136, 1906.

\bibitem{zongmin1992hermite}
Wu~Zongmin.
\newblock Hermite-{B}irkhoff interpolation of scattered data by radial basis
  functions.
\newblock {\em Approximation Theory and its Applications}, 8(2):1--10, 1992.

\bibitem{flyer2016role}
Natasha Flyer, Bengt Fornberg, Victor Bayona, and Gregory~A Barnett.
\newblock On the role of polynomials in {RBF-FD} approximations: {I}.
  {I}|nterpolation and accuracy.
\newblock {\em Journal of Computational Physics}, 321:21--38, 2016.

\bibitem{driscoll2002interpolation}
Tobin~A Driscoll and Bengt Fornberg.
\newblock Interpolation in the limit of increasingly flat radial basis
  functions.
\newblock {\em Computers \& Mathematics with Applications}, 43(3-5):413--422,
  2002.

\bibitem{fornberg2004stable}
Bengt Fornberg and Grady Wright.
\newblock Stable computation of multiquadric interpolants for all values of the
  shape parameter.
\newblock {\em Computers \& Mathematics with Applications}, 48(5-6):853--867,
  2004.

\bibitem{larsson2013stable}
Elisabeth Larsson, Erik Lehto, Alfa Heryudono, and Bengt Fornberg.
\newblock Stable computation of differentiation matrices and scattered node
  stencils based on gaussian radial basis functions.
\newblock {\em SIAM Journal on Scientific Computing}, 35(4):A2096--A2119, 2013.

\bibitem{fornberg2013stable}
Bengt Fornberg, Erik Lehto, and Collin Powell.
\newblock Stable calculation of {G}aussian-based {RBF-FD} stencils.
\newblock {\em Computers \& Mathematics with Applications}, 65(4):627--637,
  2013.

\bibitem{lehto2017radial}
Erik Lehto, Varun Shankar, and Grady~B Wright.
\newblock A radial basis function ({RBF}) compact finite difference ({FD})
  scheme for reaction-diffusion equations on surfaces.
\newblock {\em SIAM Journal on Scientific Computing}, 39(5):A2129--A2151, 2017.

\bibitem{micchelli1984interpolation}
Charles~A Micchelli.
\newblock {\em Interpolation of scattered data: distance matrices and
  conditionally positive definite functions}.
\newblock Springer, 1984.

\bibitem{larsson2003numerical}
Elisabeth Larsson and Bengt Fornberg.
\newblock A numerical study of some radial basis function based solution
  methods for elliptic {PDE}s.
\newblock {\em Computers \& Mathematics with Applications}, 46(5-6):891--902,
  2003.

\bibitem{fornberg2007runge}
Bengt Fornberg and Julia Zuev.
\newblock The runge phenomenon and spatially variable shape parameters in {RBF}
  interpolation.
\newblock {\em Computers \& Mathematics with Applications}, 54(3):379--398,
  2007.

\bibitem{Moreno2025}
Miguel Moreno.
\newblock {OptiCloud: Generate Optimal Point Clouds with Minimal Energy}.
\newblock
  \url{https://www.mathworks.com/matlabcentral/fileexchange/173255-opticloud-generate-optimal-point-clouds-with-minimal-energy},
  2025.
\newblock Retrieved February 9, 2025.

\end{thebibliography}
\end{document}
\endinput
%%
%% End of file `elsarticle-template-num.tex'.
