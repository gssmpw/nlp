\section{Related Work}
Real sparse datasets often exhibit specific structural patterns (e.g., clusters of non-zero values or correlations), which naive approaches such as simple thresholding of dense data cannot replicate. Sparse data often retains critical information in specific locations (e.g., sensor data in particle physics, occurrences of rare events). Thus, domain-specific approaches have been introduced \citep{Lu:2019,Lu:2021}.

\paragraph{Sparse continuous data generation}
Past work on sparse, continuous data generation focuses on simple architectures and specific applications, such as calorimeter sensor data in physics, which are incomparable to recent state-of-the-art generative models. They decouple the sparsity information for generating data by introducing decoupled generative models where the sparsity is introduced as a learnable Dirac delta mass at zero \citep{Lu:2019,Lu:2021}. 

\paragraph{Sparse discrete data generation} Other works focusing on sparse discrete data generation use Poisson distributions to model sparse count data with bursts \citep{Schein:2016}. There are also deep variants \citep{Gong:2017,Guo:2018, Schein:2019}. However, as already indicated, they are not applicable to our setting, which has continuous sparse data that do not exhibit the traits of a Poisson distribution. 

\paragraph{Dense data generation using diffusion models} Diffusion models fall into two main categories: continuous state-space \citep{Sohl-Dickstein:2015,Ho:2020,Song:2020,Song:2021} for continuous data and discrete state-space diffusion models \citep{Austin:2021, Gu:2022} for discrete data. Discrete state-space diffusion models can model sparse discrete data exactly as zero might be one of its tokens. However, they do not apply to our broad setting with continuous data. Also, Bit Diffusion \citet{Chen:2023} has shown that continuous state-space diffusion models can model discrete data reliably, even outperforming discrete state-space models. Bit Diffusion is an approach to generate discrete data with continuous state-space diffusion models. Bit Diffusion uses real numbers to represent the bit representations of discrete data. Because of the flexibility and better performance of continuous state-space diffusion models, we focus on them as they are the most versatile and can be applied to continuous and discrete data. 


\paragraph{Enforcing sparsity} Sparsity is not just an inherent trait in datasets that can be, e.g., exploited to store data efficiently. Sparsity can also help in the model architecture. Previous work \citep{Han:2015,Ullrich:2017} shows that neural networks are greatly overparameterized and multiple methods \citep{Molchanov:2017,Louizos:2018,Sun:2024,Lee:2018} inter alia have been introduced to mitigate this overparameterization by sparsifying the underlying neural network weights. Others \citep{Hu:2022} exploit this property to train sparse weight matrices added to existing weights efficiently. However, these methods focus on enforcing sparsity in the model weights and are therefore not applicable to our setting, where we enforce sparsity in the model's output.