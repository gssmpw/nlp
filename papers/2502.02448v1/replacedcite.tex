\section{Related Work}
Real sparse datasets often exhibit specific structural patterns (e.g., clusters of non-zero values or correlations), which naive approaches such as simple thresholding of dense data cannot replicate. Sparse data often retains critical information in specific locations (e.g., sensor data in particle physics, occurrences of rare events). Thus, domain-specific approaches have been introduced ____.

\paragraph{Sparse continuous data generation}
Past work on sparse, continuous data generation focuses on simple architectures and specific applications, such as calorimeter sensor data in physics, which are incomparable to recent state-of-the-art generative models. They decouple the sparsity information for generating data by introducing decoupled generative models where the sparsity is introduced as a learnable Dirac delta mass at zero ____. 

\paragraph{Sparse discrete data generation} Other works focusing on sparse discrete data generation use Poisson distributions to model sparse count data with bursts ____. There are also deep variants ____. However, as already indicated, they are not applicable to our setting, which has continuous sparse data that do not exhibit the traits of a Poisson distribution. 

\paragraph{Dense data generation using diffusion models} Diffusion models fall into two main categories: continuous state-space ____ for continuous data and discrete state-space diffusion models ____ for discrete data. Discrete state-space diffusion models can model sparse discrete data exactly as zero might be one of its tokens. However, they do not apply to our broad setting with continuous data. Also, Bit Diffusion ____ has shown that continuous state-space diffusion models can model discrete data reliably, even outperforming discrete state-space models. Bit Diffusion is an approach to generate discrete data with continuous state-space diffusion models. Bit Diffusion uses real numbers to represent the bit representations of discrete data. Because of the flexibility and better performance of continuous state-space diffusion models, we focus on them as they are the most versatile and can be applied to continuous and discrete data. 


\paragraph{Enforcing sparsity} Sparsity is not just an inherent trait in datasets that can be, e.g., exploited to store data efficiently. Sparsity can also help in the model architecture. Previous work ____ shows that neural networks are greatly overparameterized and multiple methods ____ inter alia have been introduced to mitigate this overparameterization by sparsifying the underlying neural network weights. Others ____ exploit this property to train sparse weight matrices added to existing weights efficiently. However, these methods focus on enforcing sparsity in the model weights and are therefore not applicable to our setting, where we enforce sparsity in the model's output.