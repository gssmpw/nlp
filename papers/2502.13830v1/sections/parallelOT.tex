%!TEX root = ../main.tex
\section{Post-Quantum Multi-Party Parallel OT}
\label{sec:parallel-OT}


In this section, we describe a black-box, constant-round protocol implementing the $n$-party %{\em parallel} 
OT functionality (as defined in \Cref{fig:F-OT}) w.r.t.\ the $\epsilon$-simulatable PQ-MPC security notion (as per \Cref{def:mpc}).  We state the definition we will be able to realize and work-with in \Cref{def:eps-mal-par-OT}.

%We define this notion using the real-ideal paradigm. Namely, we want a malicious and parallel-secure OT protocol to realize the following ideal functionality (in the standalone setting): 

\begin{FigureBox}[label={fig:F-OT}]{The Ideal Functionality $\mathcal{F}^n_{\text{OT}}$}
The functionality $\mathcal{F}^n_{\text{OT}}$ is specified by the number of distinct senders $S_i$ and receivers $R_j$ (for $i,j \in [n]$). It acts as follows: 

\para{Sender's Message:} $\mathcal{F}^n_{\text{OT}}$ receives $(\algo{send},i,j,s_0^i,s_1^i)$ from a sender $S_i$ (which also specifies a purported receiver $R_j$). It ignores this message if $i=j$. Otherwise, it records this quintuple, and ignores subsequent messages that have the same initial triple $(\algo{send},i,j)$. 

\para{Receiver's Message:} $\mathcal{F}^n_{\text{OT}}$ receives $(\algo{receive},i,j,b)$ from a receiver $R_j$. %If {\em not} all senders $S_i$ have sent a valid message to all receivers $R_j$, it simply waits. Once this is done, 
It responds with $(\algo{open},i,j,s_b^i)$ to the receiver $R_j$.  
    
\end{FigureBox}

\iffalse
The formal definition of security is below. 

\rohit{Changing the def as discussed}
\begin{definition}[Malicious Multiparty Secure Oblivious Transfer]\label{def:mal-par-OT}
A protocol $\Prot$ is called a malicious  multiparty secure oblivious transfer protocol if for every polynomial $n \coloneqq n(\secpar)$, %the n-times parallel execution of 
$\Prot$ %(denoted by $\Prot^n$) 
is a post-quantum MPC protocol for $\mathcal{F}^n_{\text{OT}}$ precisely as stated in \Cref{def:mpc}. 

%\xiao{This is not correct: it should be the joint distribution of the $\Adv$'s output and the honest parties' output} in the parallel execution $\Prot^n$. \xiao{Also, the notation here is accurate. For example, the ensembles need to be indexed by the security parameter $\secpar$, which is different from $n = \poly(\secpar)$. I know that many paper didn't define it accurately, but let's do this formally. Check the notation I wrote in \cite{C:CCLY22} for 2PC and use the notation here.}
\end{definition}

\xiao{Also, we can define the $\epsilon$ version directly. No need to define the fully-simulatable version.}
\fi




%Notes: Parallel execs are a feature of the construction, not the definition. Modify accordingly. 

\begin{definition}[Post-Quantum Multi-Party OT with $\epsilon$-Simulation]\label{def:eps-mal-par-OT}
A protocol $\Prot$ is called a malicious  multiparty secure oblivious transfer protocol if for every polynomial $n \coloneqq n(\secpar)$, %the n-times parallel execution of 
$\Prot$ %(denoted by $\Prot^n$) 
is a post-quantum ($\epsilon$-simulatable) MPC protocol for $\mathcal{F}^n_{\text{OT}}$ precisely as stated in \Cref{def:mpc}. 
\end{definition}

Below we will describe a constant-round, black-box protocol and prove that it satisfies \Cref{def:eps-mal-par-OT}. Our approach will in fact be to first describe a {\em 2-party} OT protocol $\Prot$ running in {\em constant rounds}, and then show that the {\em parallel repetition} of $\Prot$ satisfies the requirements of \Cref{def:eps-mal-par-OT}.

More precisely for a 2-party protocol $\Prot$, let us define the {\em n-fold parallel repetition} as follows: consider $n$ entities where each entity would like to participate in an OT session {\em both} as a sender and as a receiver against all the other entities in parallel. In other words, for each $i\neq j \in [n]$, we consider two OT sessions between parties $P_i$ and $P_j$ where in one $P_i$ plays the role of sender and $P_j$ that of the receiver, and vice versa in the other.  
%\xiao{@Rohit: can you add a more explicit explanation?} 
This comprises $2 \cdot \binom{n}{2}$ parallel independent executions of $\Prot$.  We will show that the $n$-fold %\xiao{it's actually $2n$. add some explanation}  
parallel repetition of $\Prot$ (denoted by $\Prot^n$) is a post-quantum ($\epsilon$-simualatable) MPC protocol for $\mathcal{F}^n_{\text{OT}}$. 

We note that sequential composition would serve the same purpose were we not constrained by the constant-round requirement. Relying on parallel composition, however, we get the desired constant-round OT protocol since $\Prot^n$ has the same round complexity as $\Prot$. 


%\UpdateLine


\subsection{Building Blocks}
\label{sec:parallelOT:building-blocks}
Before diving into the main construction of the parallel malicious secure OT protocol, we need some building blocks. 

\para{Malicious-Sender Secure OT:} The first component we require is a constant-round OT protocol with a simpler or weaker property: namely, with security against {\em malicious senders} and {\em semi-honest receivers}. Additionally, we require that the associated simulator for proving security be straight-line. Fortunately, such schemes are known to be easily obtainable from any of the following: 
% certifiable enhanced trapdoor permutations,
 post-quantum dense cryptosystems, post-quantum linearly homomorphic PKE, or post-quantum lossy PKE (see, e.g., \cite{TCC:CDMW09,FOCS:Wee10}). These schemes are black-box constructions and also work in the post-quantum setting (due to straightline security proofs).  

%\rohit{Add theorem or claim.}

\begin{theorem}[\cite{TCC:CDMW09,FOCS:Wee10}]
    There exist two-round and black-box post-quantum OT schemes with indistinguishability security against honest receivers and simulation security against malicious QPT senders, based on (any of) post-quantum 
    % certifiable enhanced trapdoor permutations, 
    dense cryptosystems, linearly homomorphic public key encryption, or lossy public key encryption. 

\end{theorem}

We will denote such a protocol by $\Gamma$, where the sender uses as inputs two strings $(s_0,s_1)$ and receiver uses as input a bit $r$. For technical reasons we will also refer in our construction to the receiver's private random tape in the protocol, which we denote as a string $\tau$ of length $t(\secpar)$ that is a polynomial in the security parameter.

\para{Post-Quantum Extractable Commitment:} We make use of the post-quantum parallelly extractable commitment scheme $\ExtCom$ with $\epsilon$-simulation (as per \Cref{def:epsilon-sim-ext-com:parallel}), which can be built in black-box from any post-quantum OWFs (see \Cref{lem:parallel-extcom:CCLY}).

% The second component we require is a black-box commitment scheme allowing {\em strong parallel $\epsilon$-simulation extraction}. A constant-round protocol with these properties is available assuming post-quantum one-way functions from the work of \cite{C:CCLY22}. 

\para{1-Many Weak Non-Malleable Commitment:} The final component we require is a constant-round, post-quantum, {\em 1-many weakly} non-malleable commitment scheme that is also parallel $\epsilon$-simulation extractable. %\xiao{do you really need this?}.
To make our overall OT construction fully black-box, we also require this construction to be fully black-box. Fortunately, such a construction is available to us from \Cref{sec:BB-NMCom:one-many}. 

We note that the extractablity property mentioned above is easily observed due to the intrinsic execution of $\ExtCom$ in \Cref{prot:bbnmc:extcom} of \Cref{protocol:BB-NMCom}, for which we can invoke the associated $\SimExt_\ExtCom$ (it is easy to see that this step also commmits to the initial committed value with overwhelming probability). Indeed, such an observation was made in \cite{FOCS:LPY23}. We denote this protocol by $\ENMC$.  



%\xiao{I think you'll need weak-parallel $\epsilon$-simulatable extractable. stande-alone extraction does not suffice.}


\subsection{Construction}

\iffalse
\xiao{does this repeat the last subsection?}
As outlined above, our construction makes use of the following component schemes with the outlined syntax: 
\begin{itemize}
    \item A malicious sender secure bit OT protocol $\Gamma$, where the sender uses as inputs two strings $(s_0,s_1)$ and receiver uses as input a bit $r$. For technical reasons we will also refer in our construction to the receiver's private random tape in the protocol, which we denote as a string $\tau$ of length $t(\secpar)$ that is a polynomial in the security parameter. We require this scheme to have straightline simulation.  
    \item A parallel $\epsilon$-simulation extractable commitment scheme $\ExtCom$. This consists of an interactive commitment protocol, and a noninteractive decommitment protocol. \xiao{do you really need this?}
    \item A post-quantum many-many \xiao{do you need 1-many or many-many?} non-malleable commitment scheme $\ENMC$, which is also parallel $\epsilon$ simulation-extractable. This also consists of an interactive commitment protocol, and a noninteractive decommitment protocol.  
\end{itemize}
\fi 

Our construction is given below in \Cref{prot:mal-OT}. 


%\xiao{It seems in one of the place, the ENMC can be replaced with an ExtCom (i.e., only need weak-parallel $\epsilon$-simulatable extractability, but not non-malleability. It would be great if we can split this clearly.)}

\begin{ProtocolBox}[label={prot:mal-OT}]{The parallel malicious secure OT scheme $\Prot$}

{\bf Parameters:} The security parameter is denoted by $\secpar$. Other parameters will be specified by polynomials in $\secpar$ unless otherwise specified. 

{\bf Receiver's input:} A bit $r \in \bits$ 

{\bf Sender's input:} Strings $s_0,s_1 \gets \bits^\ell$

The protocol proceeds as follows:

\begin{enumerate}


\item\label[Step]{prot:parOT:cointoss} {\bf Phase I: Random Tape Coin Tossing}
\begin{enumerate}
    \item\label[Step]{prot:parOT:cointoss:rec-sample} The receiver samples $2\secpar$ uniform random strings $(r_1^R,\tau_1^R),\dots,(r_{2\secpar}^R,\tau_{2\secpar}^R)$ of length $t+1$ corresponding to samples of the receiver's input bit and randomness for $\Gamma$.
    \item\label[Step]{prot:parOT:cointoss:rec-extcom} The receiver then runs $2\secpar$ parallel executions of $\ExtCom$ with the sender, where the receiver commits to the values $(r_1^R,\tau_1^R),\dots,(r_{2\secpar}^R,\tau_{2\secpar}^R)$ independently.

    \item\label[Step]{prot:parOT:cointoss:com-sample} The sender then samples $2\secpar$ uniform random strings $(r_1^S,\tau_1^S),\dots,(r_{2\secpar}^S,\tau_{2\secpar}^S)$ of its own and sends these back to the receiver. 
    \item\label[Step]{prot:parOT:cointoss:mix} The receiver sets $r_i= r_i^R \oplus r_i^S$ and $\tau_i = \tau_i^R \oplus \tau_i^S$ for $i \in [2\secpar]$. 
\end{enumerate}

\item\label[Step]{prot:parOT:baseOT}{\bf Phase II: Base OT Execution}
\begin{enumerate}
    \item\label[Step]{prot:parOT:baseOT:com-sample} The sender samples $2\secpar$ pairs of uniform random strings $(s_1^0,s_1^1),\dots,(s_{2\secpar}^0,s_{2\secpar}^1)$. 
    \item\label[Step]{prot:parOT:baseOT:OT} The sender and receiver then execute $2\secpar$ parallel executions of $\Gamma$. For the $i$th execution, the sender uses the inputs $(s_i^0,s_i^1)$ and the receiver uses input $r_i$ and randomness $\tau_i$ (for each $i \in [2\secpar]$). 
\end{enumerate}

\item\label[Step]{prot:parOT:cut-n-choose}{\bf Phase III: Cut \& Choose}
\begin{enumerate}
    \item\label[Step]{prot:parOT:cut-n-choose:enmc} The sender samples an uniform random string $q_S \pick \bits^\secpar$. It then runs an execution of $\ENMC$ with the receiver to commit to the string $q_S$. 
    \item\label[Step]{prot:parOT:cut-n-choose:resp} The receiver then samples an uniform string $q_R \pick \bits^\secpar$ and sends this back to the sender. 
    \item\label[Step]{prot:parOT:cut-n-choose:rec-sample} The sender provides the {\em decommitment} of its commitment to $q_S$ to the receiver.  
    
    \item\label[Step]{prot:parOT:cut-n-choose:mix}
     Both parties then compute $q = q_S \oplus q_R$. They also compute the description of a subset $Q \subset [2\secpar]$ of size $\secpar$ using the following correspondence: $Q= \Set{2i-q_i}_{i=1}^\secpar$ where $q_i$ is the $i$th bit of $q$. More descriptively, we imagine the previous $2\secpar$ executions of $\Gamma$ to be laid out in $\secpar$ pairs (of adjacent executions). Then $Q$ marks the subset of executions to be `opened', including the first or second execution in each of the $\secpar$ pairs depending on whether $q_i$ is $0$ or $1$ (so $Q$ has exactly one member in each pair). 
     
     %visualize the set $[2\secpar]$ laid out as a $2\times \secpar$ matrix (with columns $(1,2),\ (3,4)$ and so on) and let $Q$ correspond to the size $\secpar$ subset where each bit $q_i$ is used as a selector over the $i$th column to pick the $i$th $Q$ element.  \red{ask rohit}
    
    \item\label[Step]{prot:parOT:cut-n-choose:decom} 
    For each $i \in Q$, the receiver {\em decommits} its phase I commitment to $(r_i^R,\tau_i^R)$. 
    \item \label[Step]{prot:parOT:cut-n-choose:consis-check}The sender then computes $(r_i,\tau_i)$ for all such sessions $i \in Q$. It next checks that $(r_i,\tau_i)$ is consistent with the receiver's messages in the $i$th parallel session of $\Gamma$ in phase II. The sender aborts if this is not the case. 
\end{enumerate}


\item\label[Step]{prot:parOT:combine}{\bf Phase IV: OT Combiner}
\begin{enumerate}
    \item\label[Step]{prot:parOT:combine:mask} For every $j \notin Q$, the receiver computes $\alpha_j = r \oplus r_j$ (recall $r$ is its original input bit) and sends the list $\Set{\alpha_j}_{j \notin Q}$ to the sender. 
    \item\label[Step]{prot:parOT:combine:send} The sender then computes $\sigma_0 =  s_0 \oplus (\bigoplus_{j \notin Q} s_j^{\alpha_j})$ and $\sigma_1 =  s_1 \oplus (\bigoplus_{j \notin Q} s_j^{1-\alpha_j})$. It sends $(\sigma_0,\sigma_1)$ to the receiver. 
    \item\label[Step]{prot:parOT:open} Finally, the receiver computes and outputs the string $s_r = \sigma_r \oplus (\bigoplus_{j \notin Q} s_j^{r_j})$. 
\end{enumerate}

\end{enumerate}
    
\end{ProtocolBox}

\begin{remark}
    We note here that we can use an $\ENMC$ scheme as described above in lieu of $\ExtCom$ in \Cref{prot:parOT:cointoss} without losing anything in terms of functionality (indeed, earlier works do exactly this). We use the extractable commitment $\ExtCom$ separately for modularity and to invite a clearer examination of how the separate components and assumptions are used in our construction and what role they play in security. 
\end{remark}

\subsection{Security}

The correctness of \Cref{prot:mal-OT} is straightforward. We turn to proving security for this scheme. This is captured formally by the following theorem. 

\begin{theorem}\label{thm:mal-OT}
    Let $\secpar$ denote the security parameter. Let $\Gamma$, $\ExtCom$, and $\ENMC$ be as described in \Cref{sec:parallelOT:building-blocks}. 
    % Let $\Gamma$ be a constant-round OT protocol with malicious-sender security, as specified in the construction. Additionally, let $\ExtCom$ be a parallel $\epsilon$-simulation-extractable commitment scheme, and let $\ENMC$ be a constant-round post-quantum many-many non-malleable commitment scheme that is also parallel $\epsilon$-simulation-extractable. 
    Then, the $n$-fold parallel execution of \Cref{prot:mal-OT} (i.e., an execution among $n$ parties, where each pair of parties run two independent parallel instances with reversed roles of sender and receiver) realizes \Cref{def:eps-mal-par-OT}, for any polynomial $n=n(\secpar)$.   
\end{theorem}

%simulator here




\begin{AlgorithmBox}[label={fig:OT-Sim}]{The simulator $\Sim$ for the parallel malicious secure OT protocol}

\para{Description:} The simulator $\Sim$ enjoys black-box access to the possibly quantum adversary $\Adv$. The simulator may interact using quantum communication with the adversary occasionally (indeed, this is required to carry out the quantum analog of rewinding). It also takes in as input the security parameter as $1^\secpar$, and the error parameter as $1^{1/\epsilon}$. Thus its runtime is $\poly(\secpar,\epsilon^{-1})$. 

\para{Operation:} Note that the simulation is for an $n$-fold parallel execution of $\Prot$, where $\Adv$ may corrupt a single party in each session of $\Prot$. In each session, $\Sim$ will act according to which of the parties $\Adv$ corrupts. Its operation is detailed below. 

\subpara{Sender Corruption:} $\Sim$ takes over the receiver operation for the session. It acts as follows:  
\begin{itemize}
    \item {\bf Preamble:} It starts by sampling an uniform string $q \pick \bits^\secpar$ and computing the associated subset $Q \subset [2\secpar]$.
    \item {\bf Phase I:} For each $i \in Q$, $\Sim$ acts just as the honest receiver for this phase, committing to uniformly sampled $(r_i^R,\tau_i^R)$. However, for each $i \notin Q$, $\Sim$ commits to the strings $(0,0^t)$ (i.e., sets $r_i,\tau_i$ to be the zero strings of appropriate length).  
    \item {\bf Phase II:} For each $i \in Q$, $\Sim$ plays out the execution of $\Gamma$ honestly with the above sampled $(r_i^R,\tau_i^R)$. However, for each $i \notin Q$, it $\Sim$ runs the simulator $\Sim_\Gamma$ for $\Gamma$ to simulate the view of $\Adv$ in this phase, and also extracts $\Adv$'s inputs in this phase, namely the strings $\Set{(s_i^0,s_i^1)}_{i \notin Q}$. 
    \item {\bf Phase III:} $\Sim$ uses the weak parallel $\epsilon$-simulator-extractor for $\ENMC$ to extract the value $q_S$ from the sender-side non-malleable commitment. Note that such an extractor returns $\bot$ if even one of the component executions was declared invalid by the $\ENMC$ receiver. In such a scenario, the simulator calls for the ideal functionality $\mathcal{F}^n_{\text{OT}}$ to abort the {\em entire} execution, and halts its own operation, outputting the adversary's state. 
    Otherwise, it then sets $q_R = q \oplus q_S$ and sends this back to the sender. Next, when the corrupted sender opens its commitment to $q_S$, $\Sim$ opens its own commitments to $\Set{(r_i^R,\tau_i^R)}_{i \in Q}$. 
    \item {\bf Phase IV:} $\Sim$ sends uniformly chosen bits $\Set{\alpha_j}_{j \notin Q}$ to the corrupted sender, which sends strings $(\sigma_0,\sigma_1)$ back in turn. $\Sim$ then computes $s_0 =  \sigma_0 \oplus (\bigoplus_{j \notin Q} s_j^{\alpha_j})$ and $s_1 =  \sigma_1 \oplus (\bigoplus_{j \notin Q} s_j^{1-\alpha_j})$ (recall that it extracted $\Set{(s_i^0,s_i^1)}_{i \notin Q}$ earlier in {\bf Phase II}). $\Sim$ then sends the functionality $\Func^n_\algo{OT}$ for the relevant session with inputs $(s_0,s_1)$. This completes its execution for this session. 
\end{itemize}

\para{Receiver corruption:} $\Sim$ takes over the sender operation for this session. It proceeds as follows: 
\begin{itemize}
    \item {\bf Phase I:} For $i \in [2\secpar]$, $\Sim$ 
    \begin{itemize}
    \item
     uses the $\epsilon$-simulator-extractor for $\ExtCom$ to extract the values $(r_i^R,\tau_i^R)$ committed by the corrupted receiver, 
     \item
      samples uniformly random strings $(r_i,\tau_i)$, and 
      \item
      sets $r_i^S = r_i \oplus r_i^R$, $\tau_i^S = \tau_i \oplus \tau_i^R$ and sends these values to the corrupted receiver. 
    \end{itemize}
    \item {\bf Phase II:} $\Sim$ acts exactly as the honest sender does in this phase. 
    \item {\bf Phase III:} $\Sim$ acts exactly as the honest sender does in this phase.
    \item {\bf Phase IV:} $\Sim$ computes an index $j^* \notin Q$ such that the values $(r_{j^*},\tau_{j^*})$ are consistent with the messages the corrupted receiver sent in the $j^*$th execution of $\Gamma$ in {\bf Phase II} (note that to perform this check, $\Sim$ crucially needs the values it extracted in {\bf Phase I}). \underline{If there exists no such session, $\Sim$ outputs a special symbol $\algo{Fail}$ and halts immediately.} If the execution continues, it next receives the values $\Set{\alpha_j}_{j \notin Q}$ from the corrupted receiver, and computes $r=\alpha_{j^*} \oplus r_{j^*}$ and queries $\Func^n_\algo{OT}$ for the appropriate session with input $r$. Upon receiving a reply $s_r$ from $\Func^n_\algo{OT}$, $\Sim$ then computes the values $(\sigma_0,\sigma_1)$ as follows: 
    \begin{itemize}
        \item If $r=0$, then it sets $\sigma_0 =  s_0 \oplus (\bigoplus_{j \notin Q} s_j^{\alpha_j})$ and samples an uniform $\sigma_1 \pick \bits^\ell$. 
        \item If $r=1$, then it samples an uniform $\sigma_0 \pick \bits^\ell$ and sets $\sigma_1 =  s_1 \oplus (\bigoplus_{j \notin Q} s_j^{1-\alpha_j})$. 
    \end{itemize}
\end{itemize}
\end{AlgorithmBox}

%\red{
    %Our proof, very broadly, rests primarily on two claims. The first is that the special abort condition $\algo{Fail}$ specified in the description of $\Sim$ is triggered with at most negligible probability. The second claim says that in the event that $\Sim$ does manage to not trigger $\algo{Fail}$, it goes on to furnish a viable simulation of the execution $\Prot^n$. The logic of the proof is thus fairly straightforward, and we now turn to formalizing these claims and their respective proofs. 
%}
\begin{proof}
    Our proof relies on a simulator for the $n$-fold parallel execution of the scheme $\Prot$, which we can denote by $\Prot^n$. Our simulator $\Sim$ for this protocol is described in \Cref{fig:OT-Sim}. It is easily seen that this simulator runs in (quantum) polynomial time. 

    Our proof, very broadly, rests primarily on two claims \Cref{malOT:lem:fail,lem:malOT:cond}. The first is that the special abort condition $\algo{Fail}$ specified in the description of $\Sim$ is triggered with at most negligible probability. The second claim says that in the event that $\Sim$ does manage to not trigger $\algo{Fail}$, it goes on to furnish a viable simulation of the execution $\Prot^n$. The logic of the proof is thus fairly straightforward, and we now turn to formalizing these claims and their respective justifications. 

    \begin{lemma}\label{malOT:lem:fail}
        Denote the adversary for $\Prot^n$ by $\Adv$. Recall that $\Sim = \Sim^\Adv$ is the simulator for $\Prot^n$ (i.e., the procedure that produces $\IDEAL_{\mathcal{F}^n_{\text{OT}}, \Sim^\Adv}(\secpar, \vb{x}, \rho_\secpar)$). Then we have $$\Pr[\algo{Fail} \gets \Sim] \leq \negl(\secpar)$$
    \end{lemma}

    \begin{proof}
        A similar proof already appears in \cite{FOCS:Wee10,STOC:Goyal11}. The proof is in fact almost identical, with two notable differences: (1) we need to take care of the $\epsilon$ simulation error; (2) while \cite{FOCS:Wee10} defines non-malleability w.r.t.\ extractability and \cite{STOC:Goyal11} defines non-malleability w.r.t.\ replacement, we do not need such adjustments since we have fully many-many non-malleability.

        Assume that there is in fact an adversary $\Adv$ for $\Prot^n$ that runs in polynomial time, and also is such that $\Pr[\algo{Fail} \gets \Sim] = \nu(\secpar)$ where $\nu(\cdot)$ is non-negligible. Assume that $\Sim$ outputs $\algo{Fail}$ in a specific session $k \in [n']$ (where $n'\coloneqq 2 \cdot\binom{n}{2}$). 
        % We will argue later that this assumption is essentially without loss of generality. 
        
        We begin by examining exactly when $\Sim$ outputs $\algo{Fail}$ during simulation. From the description of $\Sim$, this happens only when the receiver is corrupted in session $k$, {\em and} there is {\em no} sub-index $j^* \in [2\secpar]$ which is (i) {\em not} opened in the cut and choose phase, and (ii) $\Adv$ behaves honestly in the session of $\Gamma$ corresponding to $j^*$. In fact, with further consideration, we can infer that the following must also happen: 
        \begin{itemize}
            \item For each pair in the $2\secpar$ executions, $\Adv$ behaves honestly in {\em exactly} one execution in the pair: if it did cheat in both, then it cannot succeed in opening either execution in the pair during the cut and choose execution; if indeed it did not cheat in either, we have nothing to worry about and can set $j^*$ to be the index of the unopened execution. Consequently, there is an {\em unique} bit for every pair of (sub-)executions of $\Gamma$, and therefore a {\em unique} string $q^* \in \bits^\secpar$ across the $2\secpar$ executions of $\Gamma$, which when picked in the cut and choose phase will allow $\Adv$ to cheat. 
            \item Further, $\Adv$ must ensure in \Cref{prot:parOT:cut-n-choose} that $q^*$ is indeed the result, i.e., it sends $q_R$ such that $q_S \oplus q_R = q^*$. 
        \end{itemize}
        
        We will use this observation to attack the non-malleability of $\ENMC$ and eventually derive a contradiction. To begin, we consider certain hybrids relating to \Cref{prot:parOT:cut-n-choose} of $\Prot^n$. We define the view or output of a hybrid to be the adversary's view of the $\Prot^n$ of the hybrid execution (therefore, corresponding to the output variable $\IDEAL$ for the simulator).


        \para{Hybrid $H_0$:} This is simply the simulated execution of $\Prot^n$. For clearer contrast with subsequent hybrids, we make note of the index $k$ identified as above. Further, we use   $K' \subset [n']$ to denote the {\em indices of the sessions in which $\Adv$ corrupts the sender} (note that $k$ and $K'$ are random variables). In particular, we emphasize that $H_0$ aborts the entire execution if any of the $\ENMC$ executions for  \Cref{prot:parOT:cut-n-choose:enmc} in the OT sessions in $K'$ are not accepted by the corresponding receiver (see {\bf Phase-III} for sender corruption in \Cref{fig:OT-Sim}). Further, the hybrid also records the values $\Set{q_S^{k'}}_{k' \in K'}$ that it extracts in \Cref{prot:parOT:cut-n-choose:enmc}. 

        \begin{remark}
            In $H_0$, we have that the following condition holds by the above analysis: with probability $\nu$, the receiver picks $q^k_R$ such that $q^k_S \oplus q^k_R = q^*$.
        \end{remark}
           

        \para{Hybrid $H_1$:} This hybrid only differs from $H_0$ in the following operation: instead of using the simulator-extractor for $\ENMC$ to extract the values $\Set{q_S^{k'}}_{k' \in K'}$ from \Cref{prot:parOT:cut-n-choose:enmc}, it instead extracts them by running a {\em brute force attack} on the transcript of the \Cref{prot:parOT:cut-n-choose:enmc} $\ENMC$ execution (recall that the hybrid then requires these values to finish its execution of \Cref{prot:parOT:combine}). If however any of the $\ENMC$ sessions in $K'$ corresponding to \Cref{prot:parOT:cut-n-choose:enmc} are not completed successfully, the extracted values for {\em all} $\ENMC$ sessions in $K'$ are set to be $\bot$. 
        
        Additionally, we make the following syntactic change for \Cref{prot:parOT:cut-n-choose:resp} in session $k$: instead of the hybrid sampling $q^k_S$ directly, it instead samples an uniform value ${q'}_S^k \pick \bits^\secpar$, and then sets $q_S^k = {q'}_S^k$. 

        

        % \xiao{In this hybrid, we need to say that for if one $\ENMC$ session is $\bot$, the extracted values are all set to be $\bot$ as well. Only in this way can we consistent with the weak-parallel simulatable extractability of $\ENMC$. More importantly, this facilitates our later argument using the weakly 1-many NMCom.}

        \subpara{$\Output(H_0) \sind_\epsilon \Output(H_1)$:} A cursory examination reveals that the actual view of the adversary remains identical in both hybrids till \Cref{prot:parOT:cut-n-choose}. The extracted values $\Set{q_S^{k'}}_{k' \in K'}$, and the resulting adversary state, are $\epsilon$-indistinguishable in $H_0$ and $H_1$ by the (weak-parallel) $\epsilon$-simulation-extraction guarantees of $\ENMC$ (as per \Cref{def:epsilon-sim-ext-com:parallel}), and  \Cref{prot:parOT:combine} is otherwise unaffected (crucially, note that both hybrids suspend the entire execution whenever any $\ENMC$ within OT sessions in $K'$ is not accepted by the corresponding receiver, and the `extracted' values are set to $\bot$ in such cases). Indistinguishability of the entire view of $\Adv$ follows. 

        \begin{remark}
            We note from the above indistinguishability  condition that in particular, the receiver in session $k$ continues to pick $q^k_R$ such that $q^k_S \oplus q^k_R = q^*$ with probability at least $\nu-\epsilon$. 
        \end{remark}

        \para{Hybrid $H_2$:} This hybrid samples an uniform ${q'}^k_S$ as in $H_1$, but sets $q_S^k = 0^\secpar$ instead of ${q'}_S^k$. All other steps remain the same as in $H_1$. We note here that the operation of $H_2$ is efficient {\em but} for the brute force extraction from \Cref{prot:parOT:cut-n-choose:enmc}. 

        \subpara{$\Output(H_1) \cind \Output(H_2)$:} At first glance it may appear that this should be guaranteed directly by the hiding guarantee of the $\ENMC$ in \Cref{prot:parOT:cut-n-choose:enmc}. This is however not the case: the reason is that while we have so far focused only on the session $k$, in truth the hybrid is also following the simulation strategy for corrupted {\em senders} in the sessions in $K'$. Note that in these sessions, the simulator itself is extracting the sender side $\ENMC$ values {\em using brute force} (starting from $H_1$)! This happens in parallel to the change we would make in $H_2$, and hence we cannot appeal to the computational hiding property. 
        % since it is not guaranteed in the presence of extraction procedures that are run in parallel to the commitment in question (intuitively, in the classical setting, we would be rewinding the $\ENMC$ executions in $K'$, which would allow the adversary to itself potentially obtain sensitive information from the $\ENMC$ in session $k$). 
        % Whilst we are indeed extracting from the transcript in $H_1$ and $H_2$, this makes them inefficient and so we can still not rely on hiding for our argument, since it still does not hold. 
        
        % \xiao{In this paragraph, need to explain why the weakly 1-many NMCom suffices.} 
        What we can do however is appeal to the {\em weak 1-many non-malleability} property of $\ENMC$. As pointed out, the executions of $\ENMC$ resemble that of a 1-many man-in-the-middle attack, where the one in session $k$ is the `left' session, and those in the sessions in $K'$ form the `right' sessions. Note that such a reduction, argued naively, will still inherit the brute-force extraction issue (whereas non-malleability is still a computational property). However, one can maneuver around this difficulty using the design of the non-malleability challenge: the extracted values $\Set{q_S^{k'}}_{k' \in K'}$ (required by the hybrid to complete the execution and manufacture its output) are not extracted by the adversary itself --- instead, the challenger does so itself and then presents them to the distinguisher. Then, if all the right sessions are successfully completed, we allow the distinguisher (using a standard nonuniformity argument) to `resurrect' the hybrid and complete the execution. Since the only brute force step by the hybrid is actually carried out by the challenger, this makes the adversary-distinguisher pair efficient, giving us a valid reduction to weak 1-many non-malleability.      

        Note that {\em weak} 1-many non-malleability indeed suffices in this setting, because of the deliberate construction of our hybrids. In more detail, observe that at the end of \Cref{prot:parOT:cut-n-choose:enmc}, $H_1$ has the corresponding information to exactly reconstruct $\Gamma_{\{d_j\}_{j=1}^{k}}(\msf{mim}[k]^{\mcal{M}_\secpar}_{\langle C, R \rangle}({q'}_S^k, \rho_\secpar))$, whereas $H_2$ has the information to exactly reconstruct $\Gamma_{\{d_j\}_{j=1}^{k}}(\msf{mim}[k]^{\mcal{M}_\secpar}_{\langle C, R \rangle}(0^\secpar, \rho_\secpar))$. In other words, any cases where the adversary chooses to selectively not complete some of the right $\ENMC$ sessions are discarded by the hybrids --- and so only cases where all right sessions are successfully completed are considered. This ensures that we can then successfully rely on weak one-may non-malleability to argue similarity.    
        
        We proceed to formally reduce this claim to the weak 1-many nonmalleability of $\ENMC$ as defined in \Cref{def:NMCom:weak:pq}. In more detail,  assume there is a distinguisher $D$ that can distinguish (with non-negligible advantage $\kappa(\secpar)$) between the outputs of $H_2$ and $H_1$. 
        We describe a valid man-in-the-middle adversary and distinguisher pair $(\tilde{A},\tilde{D})$ for the weak 1-many non-malleability game. We make use of the original adversary $\Adv$ and the assumed distinguisher $D$. The description of $\tilde{A}$ and $\tilde{D}$ are given below. 

        The adversary $\tilde{\Adv}$ works as follows: 
        \begin{itemize}
            \item Internally, it runs the hybrid $H_2$ with $\Adv$ embedded in the execution. It continues this up to the start of \Cref{prot:parOT:cut-n-choose}. 
            \item Next, it externally begins participating in a 1-many challenge for $\ENMC$, with challenge messages $0^\secpar$ and ${q'}_S^k$ (uniformly sampling the latter). 
            \item It forwards the challenger's sender (or `left-side') messages as the \Cref{prot:parOT:cut-n-choose:enmc} sender messages in session $k$ of $\Prot$, and forwards out the receiver's session $k$ replies out to the challenger as its own left-side receiver messages. Similarly, it cross-forwards the $\ENMC$ interactions for \Cref{prot:parOT:cut-n-choose:enmc} in the sessions in $K'$ to act as the `right-side' $\ENMC$ interactions in the external challenge. 
            \item At the end of \Cref{prot:parOT:cut-n-choose:enmc}, it records its view and the adversary's state as its output, and halts. Note that the adversary' state may be quantum, but this is okay as the MIM adversary for post-quantum non-malleability is allowed to output quantum information. 
        \end{itemize}

        The distinguisher $\tilde{D}$ works as follows: 
        \begin{itemize}
            \item $\tilde{D}$ receives the output of $\tilde{A}$ from the challenger, along with the left-side committed values ${q'}_S^k$. It then reconstructs the operation of the hybrid up to the start of \Cref{prot:parOT:combine} (along with the appropriate state of $\Adv$ at this stage).  
            \item From the 1-many non-malleability challenger, it then receives the values committed by $\tilde{\Adv}$ in the right side sessions, namely $\Set{q_S^{k'}}_{k' \in K'}$. 
            \item It then completes the execution of the hybrid and feeds the resulting hybrid output to $D$. It then outputs whatever $D$ does. 
        \end{itemize}

        It is easy to see that the operation of $\tilde{A}$ and $\tilde{D}$ follow exactly the execution of the hybrid $H_1$ if the $\ENMC$ challenger commits to $q'^k_S$ in the left side commitment, and conversely these follow exactly the execution of $H_2$ when the $\ENMC$ challenger commits to $0^\secpar$. Consequently, within $\tilde{D}$, the view fed to the distinguisher $D$ comes either from $H_1$ or $H_2$. Therefore $\tilde{D}$ succeeds in winning the weak 1-many nonmalleability challenge whenever $D$ distinguishes successfully within these hybrids. Thus $(\tilde{A},\tilde{D})$ win the weak 1-many non-malleability challenge with non-negligible probability $\kappa$, which contradicts the security of $\ENMC$. We conclude that there is no such efficient distinguisher $D$ that manages to distinguish between $H_1$ and $H_2$ with non-negligible probability. 

        Finally, in the hybrid $H_2$, we obtain a contradiction. Set $\epsilon = \nu/2$. From the above, we can conclude that even in $H_2$, we have that the receiver in session $k$ continues to pick $q^k_R$ such that $q'^k_S \oplus q^k_R = q^*$ with non-negligible probability $\nu/2$. Recall that $q'^k_S$ is sampled uniformly by $H_2$ and not used in its internal execution of $\Prot^n$. Therefore, $q'^k_S$ is not seen by $\Adv$. This is a clear contradiction, since an uniformly sampled string of $\secpar$ bits that is absent from the view of $\Adv$ has entropy $\secpar$ from $\Adv$'s point of view; and so even a quantum (or even unbounded) machine can predict this string with probability $\frac{1}{2^\secpar}$, which is negligible. 
        

        This concludes the proof of \Cref{malOT:lem:fail}.

    \end{proof}

% \begin{remark}
%     Note that we assumed at the outset that there was a clearly identifiable session in which $\Sim$ could have output $\algo{Fail}$ with non-negligible probability. There is a remaining obstacle to removing this assumption; namely, identifying such a session, %and (ii) dealing with the case where there are more than one sessions.
%     This is solved by a random guess by the reduction as to which session $\Sim$ is likely to output $\algo{Fail}$ in, which adds a polynomial loss in security but ensures that the above proof still goes through. %For the multiple session case, we rely on the many-many non-malleability of $\ENMC$ to switch out the commitment values in the `problematic' sessions to obtain a similar contradiction to the one above, relying on a straightforward repetitive extension of the hybrid argument above. 
% \end{remark}

We turn now to the second claim. 
%Before stating the lemma, we develop a bit of notation. Let $\Delta_D(X,Y)$ denote the distinguishing advantage for a particular distinguisher $D$, for two random variables $X$ and $Y$. Let $\Delta_c(X,Y)$ further denote the supremum of the values $\Delta_D(X,Y)$ where these range over all computationally efficient distinguishers $D$. 

\begin{lemma}\label{lem:malOT:cond}
    Conditioned on the event $E$ where $\Sim$ does {\em not} output $\algo{Fail}$, $\Sim$ produces a valid simulation of $\Prot^n$ with respect to $\Adv$. Namely, given that $E$ occurs, we have 
    $$\REAL_{\Prot^n, \Adv}(\secpar, \vb{x}, \rho_\secpar) \cind_\epsilon \IDEAL_{\mathcal{F}^n_{\text{OT}}, \Sim^\Adv}(\secpar, \vb{x}, \rho_\secpar)$$
\end{lemma}

\begin{proof}
    This is essentially the same argument that is used in previous work \cite{FOCS:Wee10,STOC:IKLP06}. We refer the reader to these for a full proof, and include a sketch of the proof for the sake of completeness. 
    
    The case for simulating for a corrupted sender is straightforward, relying directly on the malicious sender security of $\Gamma$. The only thing of note here is that since the simulator relies on the simulator-extractor for $\ENMC$, it inherits an $\epsilon$ simulation error for the portion of the view from \Cref{prot:parOT:cut-n-choose:enmc} onwards. This is reflected in the final simulation guarantee stated in the lemma.  
    
    We focus instead on the corrupted receiver case. Here we observe that if $\Sim$ does not output $\algo{Fail}$, then everything in the first three phases is essentially identical to how an honest sender acts, and it is only in the values $(\sigma_0,\sigma_1)$ that the simulator's distribution changes. A distinguisher for the real and simulated view can then be used to attack the honest receiver security of $\Gamma$. 

    The attack is somewhat subtle, but it essentially uses the following observation: the `hidden' value $\sigma_{1-r}$ has the `correct' distribution in the real execution, while in the simulated execution it is uniformly sampled. Thus a distinguisher for the real and simulated executions will be biased towards identifying an execution as `real' when the hidden value has the correct distribution. The actual reduction makes an initial guess as to the hidden value and performs a sort of retroactive check, and uses the distinguisher's output cleverly to gain advantage in the honest receiver security game for $\Gamma$. 

    Of course, to make this reduction meaningful, care has to be taken to make sure that the internal $\Gamma$ sub-execution within $\Prot$ is indeed honest. This is essentially the function of the session $j^*$ tracked by the simulator: for this session of $\Gamma$, we are guaranteed that the adversary uses honest inputs - as the simulator extracts all the receiver inputs initially and aborts if this is not the case. 
    
    Note that again we have to account for the $\epsilon$-simulation guarantee from the extraction step in phase I, but this can be handled by a standard `funneling' argument (i.e., start by assuming an distinguisher with a certain distinguishing advantage, and set $\epsilon$ to be significantly smaller to still derive a contradiction). %\xiao{Great! This summary of strategy looks perfect to me.}
     
This concludes the proof of \Cref{lem:malOT:cond}.

\end{proof}

Finally, we tie together these claims to obtain the stated result. Since $\algo{Fail}$ is a simulator specific abort message, it is very easy to distinguish real and simulated executions whenever $\algo{Fail}$ is output. Now by \Cref{lem:malOT:cond}, the maximum possible distinguishing advantage for a computationally bounded distinguisher (which we denoted by $\Delta_c$) is $\epsilon$ whenever $E$ occurs. Formally, we define $\Delta_c(X,Y) := \text{sup}_{D \in\text{PPT}}|\Pr[D(X)=1] - \Pr[D(Y)=1]|$. For brevity we will denote $\REAL_{\Prot^n, \Adv}(\secpar, \vb{x}, \rho_\secpar)$ by $\REAL$ and $\IDEAL_{\mathcal{F}^n_{\text{OT}}, \Sim^\Adv}(\secpar, \vb{x}, \rho_\secpar)$ by $\IDEAL$ below. 

We begin with the following decomposition 
\begin{align*}
    \Delta_c(\REAL,\IDEAL) = &[\Delta_c(\REAL,\IDEAL)|E]\cdot\Pr[E] \\ & + [\Delta_c(\REAL,\IDEAL)|\bar{E}]\cdot\Pr[\bar{E}]
\end{align*}
By \Cref{malOT:lem:fail}, we can write the RHS as 
\begin{align*}
     = &[\Delta_{D^*}(\REAL,\IDEAL)|E]\cdot(1-\negl(\secpar)) \\ & + [\Delta_{D^*}(\REAL,\IDEAL)|\bar{E}]\cdot\negl(\secpar),
\end{align*}
which is of course simply $$ \leq \epsilon\cdot(1-\negl(\secpar) ) + 1\cdot\negl(\secpar)$$ Which yields $$\Delta_c(\REAL,\IDEAL)\leq \epsilon' = \epsilon + \negl(\secpar)$$ Readjusting $\epsilon \rightarrow \epsilon/2$ gives us the stated result. 


\iffalse
From lemma 3, we have that: $$\Pr[\Delta_c(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim}) \leq \eta(\secpar)|E] \geq 1-\delta(\secpar)$$
and from lemma 2, we have that: 
$$\Pr[\bar{E}] \leq \beta(\secpar)$$ where $\beta(\cdot)$ is a specific negligible function. 

To conclude the argument, consider an (imaginary) `best possible' albeit still efficient distinguisher $D^*$, which distinguishes between real and ideal executions {\em perfectly}, in any case that is not covered by lemma 2. Consider its advantage $\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})$. We can break this down as follows:
\begin{align*}
    \Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim}) = &[\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})|E]\cdot\Pr[E] \\ & + [\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})|\bar{E}]\cdot\Pr[\bar{E}]
\end{align*}
From the description of $D^*$, we can write $$[\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})|E]  = \eta\cdot (1-\delta) + 1\cdot \delta$$ and hence $$[\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})|E]\cdot\Pr[E] = \eta\cdot(1-\delta)\cdot(1-\beta) + 1\cdot\delta\cdot(1-\beta)$$ 
Further, we have from lemma 2 that $$[\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})|\bar{E}]\cdot\Pr[\bar{E}] = 1\cdot\beta$$ and hence $$\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim}) = \eta\cdot(1-\delta)\cdot(1-\beta) + 1\cdot\delta\cdot(1-\beta) + 1\cdot\beta$$ 
With some simple manipulation, we can obtain $$\Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim}) \leq (1-\beta)(\eta + \delta) + \beta = \negl(\secpar)$$

Clearly, no efficient distinguisher can do better in distinguishing between these distributions, i.e. we have $$\Delta_c(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})  \leq \Delta_{D^*}(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim})$$ Hence we can conclude $$\Delta_c(\REAL_{\Prot^n,\Adv,n},\IDEAL_{\Func^n_\algo{OT},\Sim}) \leq \negl(\secpar)$$ 
In other words, $$\REAL_{\Prot^n,\Adv,n} \cind \IDEAL_{\Func^n_\algo{OT},\Sim}$$
\fi




This concludes the proof of \Cref{thm:mal-OT}.

\end{proof}