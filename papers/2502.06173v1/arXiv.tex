%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
% \documentclass{article}
% \usepackage{spconf}
% \documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{amsmath,amsfonts,bm}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{array}
\usepackage{mathtools}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{float}
\newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}
\input{math_commands.tex}

\title{\LARGE \bf
Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis
}

\author{Sanket Jantre$^{1 \star}$,  Tianle Wang$^{1}$, Gilchan Park$^{1}$, Kriti Chopra$^{1}$, Nicholas Jeon$^{2}$, \\ Xiaoning Qian$^{1,2}$, Nathan M. Urban$^{1}$, and Byung-Jun Yoon$^{1,2}$% <-this % stops a space
\thanks{\copyright This work has been submitted to the IEEE for possible publication.}% <-this % stops a space
\thanks{$^{1}$ Computing and Data Sciences Directorate, Brookhaven National Laboratory, Upton, NY, USA.}%
\thanks{$^{2}$ Department of Electrical and Computer Engineering, Texas A\&M University, College Station, TX, USA.}%
\thanks{$^\star$ corresponding author.}
}


\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Identification of protein-protein interactions (PPIs) helps derive cellular mechanistic understanding, particularly in the context of complex conditions such as neurodegenerative disorders, metabolic syndromes, and cancer. Large Language Models (LLMs) have demonstrated remarkable potential in predicting protein structures and interactions via automated mining of vast biomedical literature; yet their inherent uncertainty remains a key challenge for deriving reproducible findings, critical for biomedical applications. In this study, we present an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging fine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we integrate LoRA ensembles and Bayesian LoRA models for uncertainty quantification~(UQ), ensuring confidence-calibrated insights into protein behavior. Our approach achieves competitive performance in PPI identification across diverse disease contexts while addressing model uncertainty, thereby enhancing trustworthiness and reproducibility in computational biology. These findings underscore the potential of uncertainty-aware LLM adaptation for advancing precision medicine and biomedical research.

% {\textbf{\textit{Clinical Relevance}}}\textemdash This is a brief statement on why a this might be of interest to practicing clinicians. Example: This establishes the anesthetic efficacy of 10\% intraosseous injections with epinephrine to positively influence cardiovascular function.

\end{abstract}

\begin{keywords}
Large Language Model (LLM), Low Rank Adaptation (LoRA), Uncertainty Quantification (UQ),  Bayesian Inference, Deep Ensemble, Protein-Protein Interaction (PPI).
\end{keywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}
Proteinâ€“protein interactions (PPIs) form the molecular foundation of cellular function, orchestrating everything from gene regulation and signal transduction to metabolic processes and immune response. The intricate network of these interactions, often termed the interactome, represents one of the most complex and dynamic systems in biology~\cite{Cusick2005}. Understanding this complex PPI network is particularly crucial in disease contexts, where aberrant protein interactions can lead to pathological states. Alterations in PPI networks have been implicated in numerous diseases, affecting fundamental cellular processes such as protein homeostasis, cell cycle regulation, and metabolic control. These disease-associated changes in the interactome can manifest through various mechanisms, from disrupted protein complex formation to altered signaling cascades, ultimately contributing to disease progression and severity. Elucidating these interaction networks is therefore essential for understanding disease mechanisms and developing therapeutic strategies \cite{ppis_disease}.

Traditional experimental methods for identifying PPIs, such as yeast two-hybrid screening and co-immunoprecipitation, have generated vast amounts of validated interaction data. These experimentally determined interactions have been systematically collected in comprehensive databases such as STRING~\cite{szklarczyk2023string}, BioGRID~\cite{oughtred2019biogrid}, and IntAct~\cite{orchard2014intact}, creating valuable resources for the research community. While experimental methods remain the gold standard for PPI validation, their labor-intensive and time-consuming nature has motivated the development of computational approaches to predict novel protein interactions. 

Early computational methods for PPI prediction primarily relied on sequence-based evolutionary patterns across species~\cite{weigt2009messagepassing, sanchezgarcia2019bipspi, chopra2020cornea}. As the field advanced, machine learning~(ML) approaches emerged, offering new ways to integrate multiple types of biological data~\cite{kewalramani2023state}. These included convolutional neural networks (CNNs) for analyzing protein sequence patterns, recurrent neural networks (RNNs) for capturing sequential dependencies, and graph neural networks~(GNNs) for modeling the topology of protein interaction networks~\cite{soleymani2022ppi}.

The advancements of large language models~(LLMs)~\cite{shorinwa2024surveyuncertaintyquantificationlarge, minaee2024largelanguagemodelssurvey, radford2019language, brown2020languagemodelsfewshotlearners,openai2024gpt4technicalreport,touvron2023llama2openfoundation, grattafiori2024llama3herdmodels} have transformed multiple scientific domains through their unprecedented capabilities in understanding complex patterns and relationships in text data~\cite{Cui2024,luo2022biogpt,Singhal2023-zh,yang2022gatortronlargeclinicallanguage,bran2023chemcrowaugmentinglargelanguagemodels,taylor2022galacticalargelanguagemodel,yang2023fingptopensourcefinanciallarge,wu2023bloomberggptlargelanguagemodel,thulke2024climategptaisynthesizinginterdisciplinary, chen2021evaluatinglargelanguagemodels}. Building on their powerful language-processing capabilities, biology-specific models have been developed to tackle diverse tasks: ProtBERT~\cite{brandes2022proteinbert} and ESM3~\cite{hayes2025esm3} focus on protein sequence analysis, while BioGPT~\cite{luo2022biogpt} and BioMedGPT~\cite{luo2023biomedgpt} have shown promise in extracting biological knowledge from scientific literature. Recently, \cite{engel-park-2024-evaluating} has investigated PPI prediction using LLM-based approaches, demonstrating the potential of these models in specialized biomedical tasks. However, a critical challenge remains: such models often produce overly confident predictions, especially when trained on limited data, posing serious risks in high-stakes biomedical applications \cite{li2024thinktwicetrustingselfdetection, xiong2024llmsexpressuncertaintyempirical, leng2024tamingoverconfidencellmsreward, he2023preservingpretrainedfeatureshelps}. Uncertainty-aware adaptation of LLMs is particularly critical in biomedical applications where miscalibrated confidence levels could lead to erroneous conclusions about disease mechanisms or therapeutic targets. By incorporating principled uncertainty estimation and confidence calibration techniques, we can ensure that LLM-driven predictions are not only powerful but also reliable for guiding biomedical discoveries.

\begin{figure*}
    \centering
    \includegraphics[width=0.85\linewidth]{workflow.pdf}
    \caption{Illustration of our uncertainty-aware low-rank adaptation approach for pre-trained LLMs in protein-protein interaction prediction.}
    \label{fig:workflow}
\end{figure*}

Within the broader machine learning community, uncertainty quantification has long been a challenge due to the high-dimensional parameter spaces of deep learning models. Traditional Bayesian methods relying on Markov chain Monte Carlo sampling often become intractable at scale \cite{Neal-1996, Izmailov-et-al-2021}. Consequently, approximate Bayesian methods such as variational inference~\cite{blundell2015weightuncertaintyneuralnetworks}, sparse learning \cite{jantre2023layer,jantre2023shrinkage}, and dimension reduction \cite{jantre2024active} have been explored. Alternately, ensemble-based methods like deep ensembles~\cite{lakshminarayanan2017simplescalablepredictiveuncertainty}, SWAG~\cite{maddox2019simple}, and SeBayS~\cite{jantre2022sequential} also provide principled strategies for capturing predictive variability. On the other hand, parameter-efficient fine-tuning techniquesâ€”particularly Low-Rank Adaptation~(LoRA)~\cite{hu2021loralowrankadaptationlarge}â€”makes it more tractable to adapt large models for specific downstream tasks. To this end, novel UQ-aware fine-tuning approaches have emerged that combine LoRA with Bayesian or ensemble-based ideas, such as Bayesian LoRA \cite{yang2024bayesianlowrankadaptationlarge, wang2024blobbayesianlowrankadaptation, meo2024bloragates,onal2024gaussian} and LoRA ensembles \cite{wang2023loraensembleslargelanguage, balabanov2024uncertainty}.

In this study, we specifically focus on LLaMA-3 \cite{grattafiori2024llama3herdmodels} and BioMedGPT \cite{luo2023biomedgpt} as our primary LLM frameworks. We integrate LoRA-based fine-tuning with uncertainty-aware techniques to improve disease-specific PPI prediction. More concretely, we adopt Bayesian LoRA and LoRA ensemble methods to mitigate overconfidence and capture richer predictive variability. By leveraging the language-like structure of protein sequences, our approach naturally models intricate dependencies while generating well-calibrated estimates. To this end, our contributions include:
\begin{enumerate}
    \item Low rank adaptation-based fine-tuning of LLaMA-3-8B and BioMedGPT-LM-7B, comparing standard LoRA fine-tuning with Bayesian LoRA and LoRA ensembles to tackle disease-focused PPI prediction.
    \item Uncertainty quantification (UQ) integration to assess the reliability and robustness of PPI predictions.
    \item Comprehensive uncertainty-aware evaluation across disease-specific protein interaction networks, specifically those relevant to neurodegenerative disorders, metabolic diseases, and cancer.
\end{enumerate}
Overall, our results confirm that incorporating UQ strategies not only enhances PPI prediction accuracy but also yields better-calibrated confidence measuresâ€”critical for drawing robust conclusions in biomedical research. By advancing uncertainty-aware methods in LLM-based modeling, we lay the groundwork for safer, more reliable, and more informative computational tools in precision medicine.

\section{Preliminaries}
\label{sec:preliminaries}
Throughout the paper, all vectors and matrices are denoted by bold lowercase $(\boldl)$ and uppercase letters $(\boldL)$ respectively.

\subsection{Low-Rank Adaptation}
To adapt a pre-trained language model to downstream tasks, The authors of \cite{hu2021loralowrankadaptationlarge} introduced LoRA, a parameter-efficient fine-tuning approach. Assuming that weight changes exhibit a low intrinsic rank, LoRA optimizes rank decomposition matrices while keeping the pre-trained weights frozen.

Specifically, given that the weight update has a low-rank structure, the adapted forward pass is expressed as: 
\[
\boldh = (\boldW_0 + \Delta\boldW) \bolda = (\boldW_0 + \boldB\boldA) \bolda.
\] 
Here $\bolda$ and $\boldh$ represent the input and output vectors, respectively, of a large frozen pre-trained weight matrix $\boldW_0 \in \R^{d_1\times d_2}$. The matrices $\boldB\in\R^{d_1\times r}$ and $\boldA\in\R^{r\times d_2}$ contain trainable parameters, with $r \ll \min(d_1,d_2)$. This reduction in the number of parameters, allows LoRA to provide efficient fine-tuning with a decrease in storage requirements. We adopt this model as a baseline in our experiments.

\subsection{Bayesian model formulation}
Let $\calD=\{(\boldx_i,y_i)\}_{i=1,\cdots,N}$ be a training dataset with $N$ i.i.d. samples, where $\boldx$ represents the input samples and $y$ represents the output samples. Bayesian inference captures model uncertainty by inferring a probability distribution over model parameters, $\btheta = (\theta_1,\cdots,\theta_T) \in \R^T$, instead of learning a single deterministic model--$p(y|\boldx, \btheta)$. The posterior distribution follows Bayesâ€™ rule: $p(\btheta|\calD) \propto p(\calD|\btheta) p(\btheta)$, where $p(\calD|\btheta)$ is the model likelihood and $p(\btheta)$ is the prior distribution. To make predictions for a new input $\boldx_{\rm new}$, Bayesian model averaging (BMA) is applied using the posterior distribution $p(\btheta|\calD)$ as follows:
\begin{align*}
p(y_{\rm new}|\boldx_{\rm new}, \calD) & = \int p(y_{\rm new}|\boldx_{\rm new}, \btheta) p(\btheta|\calD) d\btheta \\
& \approx \frac{1}{B} \sum_{b=1}^B p(y_{\rm new}|\boldx_{\rm new}, \btheta_b), \enskip \btheta_b \sim p(\btheta|\calD).
\end{align*}
This approach improves generalizability and model calibration by incorporating parameter uncertainty into predictions.

\section{Methodology}
\label{sec:methodology}
\subsection{LoRA Ensemble}
We employ an ensemble of LoRA models -- \emph{LoRA Ensemble} \cite{wang2023loraensembleslargelanguage, balabanov2024uncertainty} as an efficient strategy for uncertainty quantification in LLMs. Traditional deep ensembles yield better predictive performance and uncertainty estimation by training multiple models independently, but applying this directly to LLMs is often infeasible due to high memory and computational costs.

To circumvent these issues, each LoRA Ensemble member fine-tunes the same pre-trained backbone $\boldW_0$ with a low-rank trainable modification $\Delta \boldW_m = \boldB_m \boldA_m$, where $\boldB_m \in \R^{d_1 \times r} $ and $\boldA_m \in \R^{r \times d_2}$ have significantly fewer parameters than the full model, $r_m \ll \min(d_1, d_2)$. These adapters are trained independently and in parallel, ensuring diverse solutions--$\{\boldW_1, \boldW_2, \dots, \boldW_M\}$. The ensemble prediction is computed by averaging outputs across $M$ ensemble members. For a given input $\boldx_{\rm new}$, if $y^m_{\rm new}$ represents the prediction from the $m$-th ensemble member, the final ensemble output (for continuous outcomes) is given by:
\[
p_{\rm ens} (y_{\rm new}|\boldx_{\rm new}) = \frac{1}{M} \sum_{m=1}^{M} p(y^m_{\rm new}|\boldx_{\rm new},\boldW_m).
\]
This approach retains the benefits of ensembling--improved accuracy, calibration, and robustness--while preserving efficiency by reusing the frozen backbone and only training lightweight LoRA adapters.

\subsection{Bayesian Low-Rank Adaptation}
Despite the availability of scalable posterior inference methods like variational inference \cite{blundell2015weightuncertaintyneuralnetworks}, a fully Bayesian treatment of LLMs remains computationally prohibitive. Instead, limiting Bayesian inference to LoRA parameters offers a more tractable means of capturing uncertainty in model predictions. However, even Markov chain Monte Carlo approaches can become excessively costly for inferring posteriors over the millions of LoRA parameters involved in large-scale models. As a practical compromise, \emph{Bayesian LoRA} \cite{yang2024bayesianlowrankadaptationlarge} employs the Laplace approximation to estimate the posterior over these low-rank parameters, centered around their \emph{maximum a posteriori} (MAP) estimate together with covariance equaling the Fisher information matrix \cite{daxberger2021laplace}.

To this end, let $\btheta$ denote the trainable LoRA parameters with a prior distribution of $\calN(\boldsymbol{0}, \lambda^{-1}\boldI)$. The Laplace approximation first calculates MAP estimate which is equivalent to maximizing the log-joint, $\log {\rm P} (\boldy, \boldX, \btheta)$
\begin{align*}
    \btheta_{\rm MAP} & = \underset{\btheta}{\arg\!\max} \log {\rm P}(\boldy,\boldX,\btheta) \\
    &= \underset{\btheta}{\arg\!\max} \log {\rm P}(\boldy|\boldX,\btheta) + \log {\rm P}(\btheta) \\
    &= \underset{\btheta}{\arg\!\max} \log {\rm P}(\boldy|\boldX,\btheta) + \frac{\lambda}{2} ||\btheta||^2_2 + {\rm const}
\end{align*}
where $\boldX$ represents the model inputs. The term associated with log of the prior distribution provides us $L_2$-regularization on the trainable parameters. We can incorporate this in frequentist model training via weight decay term with $\lambda/2$ strength. As a result, parameters from any previously trained model that used a reasonable weight decay setting (for example, via AdamW with its weight decay) can be directly reused.

Next, to obtain an approximate posterior around $\btheta_{\rm MAP}$, Laplace method proceeds with a second-order Taylor expansion of the log-joint $\calL(\calD,\btheta)=\log p(\boldy, \boldX, \btheta)$ around $\btheta_{\rm MAP}$. Hence, by ignoring the higher-order terms, this yields
\[
    \calL (\calD,\btheta) \approx \calL (\calD,\btheta_{\rm MAP})
    + \frac{1}{2} (\btheta - \btheta_{\rm MAP})^\top \boldH \,(\btheta - \btheta_{\rm MAP}),
\]
where the first-order term zeros out due to the zero gradient at $\btheta_{\rm MAP}$ and $\boldH$ is the Hessian of the log-joint at $\btheta_{\rm MAP}$, $\nabla^2_{\btheta} \calL (\calD,\btheta)|_{\btheta_{\rm MAP}}$. Under this quadratic approximation,
\begin{equation}
\label{eqn:posterior}
    p(\btheta \mid \calD) \approx \calN \bigl(\btheta|\btheta_{\rm MAP},\, \boldH^{-1}\bigr).
\end{equation}
Hence, Laplace approximation turns out to be post-hoc Bayesian inference method which requires the additional step of computing the $H^{-1}$ matrix at $\btheta_{\rm MAP}$. In practice, computing the full Hessian $\boldH$ can be expensive, especially for large models due to quadratic complexity with respect to the number of model parameters. We use the positive semi-definite Fisher information matrix to circumvent the issue of the potentially indefinite Hessian, which arises when local convexity conditions fail to hold in large machine learning models. Accordingly, the Fisher information is defined by
\[
\boldF(\btheta) = \sum_{n}^N \E_{\hat{y}\sim{\rm P}(y|f_{\btheta}(\boldx_n))} \bigl[\boldG \boldG^\top \bigr]
\]
where $G=\nabla_{\btheta} {\rm P}(\hat{y}|f_{\btheta}(\boldx_n))$ represents the gradient and the expectation above is over the modelâ€™s output distribution. Next, in order to estimate the Fisher information in a manner that is both tractable and memory-efficient, we employ a \emph{Kronecker-Factored Approximate Curvature} (K-FAC) approach similar to \cite{ yang2024bayesianlowrankadaptationlarge}. In K-FAC, we treat Fisher as a block-diagonal matrix for each linear layer and factorize each block into two smaller matrices. For the $l$-th linear layer, we compute Fisher block $F_l$ using that layer's input activations $\bolda_{l-1}$ and log-likelihood gradients with respect to layer's pre-activation output $s_l$ denoted by $\boldG_{\bolds_l} = \nabla_{\bolds_l} \log {\rm P}(\boldy|\boldX,\btheta)$. Hence the expression is
\begin{equation}
\label{eqn:kfac}
   \boldF_l = \sum_{n=1}^N \E_{{\rm P}(y|f_{\btheta}(\boldx_n))} \bigl[ \bolda_{l-1}\bolda_{l-1}^\top \bigr] \otimes \E_{{\rm P}(y|f_{\btheta}(\boldx_n))} \bigl[ \boldG_{\bolds_l} \boldG_{\bolds_l}^\top \bigr] 
\end{equation}
This approach avoids storing the full, dense Hessian, thereby reducing computational overhead.
By applying K-FAC to the LoRA parameters, we maintain a compact representation of uncertainty while keeping the overhead similar to standard training. However,
in Equation~(\ref{eqn:kfac}), the first expectation grows with the square of the layerâ€™s input width, while the second grows with the square of the output width. Because LoRA adapters alternate between wide-input-narrow-output configuration and vice versa, one of these expectations can become especially large. To address this, we use an incremental SVD to factorize the large matrix into two new low-rank factors thereby saving memory. Further mathematical details are provided in Appendix~E of \cite{yang2024bayesianlowrankadaptationlarge}.

Once we infer the approximate posterior which is Gaussian as per Equation~\ref{eqn:posterior}, we can linearize the model predictions around the MAP estimate $\boldsymbol{\theta}_{\mathrm{MAP}}$ \cite{antoran2022adapting}. For a test input \(\mathbf{x}_{\rm new}\),
\[
f_{\btheta}(\boldx_{\rm new}) \approx f_{\btheta_{\rm MAP}}(\boldx_{\rm new}) + 
\nabla_{\btheta} f_{\btheta}(\boldx_{\rm new})\bigl|_{\btheta_{\rm MAP}}^\top
\bigl(\btheta - \btheta_{\rm MAP}\bigr).
\]
Because this expression is linear in \(\boldsymbol{\theta}\), integrating out 
the Gaussian posterior over \(\boldsymbol{\theta}\) yields a Gaussian predictive 
distribution for the logits:
\begin{align*}
f_{\btheta}(\boldx_{\rm new}) & \sim \calN \bigl(\boldy| f_{\btheta_{\rm MAP}}(\boldx_{\rm new}), \Lambda \bigr), \\
\text{wh}&\text{ere }  \Lambda  = \nabla_{\btheta} f_{\btheta_{\rm MAP}}(\boldx_{\rm new})^\top H^{-1} \nabla_{\btheta} f_{\btheta_{\rm MAP}}(\boldx_{\rm new}).
\end{align*}
Finally to efficiently sample from this predictive posterior, we use the Cholesky decomposition of 
$\Lambda = \mathbf{L} \mathbf{L}^\top$. Then,
\[
\hat{\boldy} = f_{\btheta}(\boldx_{\rm new}) = f_{\btheta_{\rm MAP}}(\boldx_{\rm new}) + \boldL \boldz, \quad
\boldz \sim \calN \bigl(\bzero, \boldI \bigr).
\]
This linearized predictive step, combined with a Gaussian approximate posterior, yields efficient uncertainty estimates in Bayesian LoRA approach for downstream tasks.


\input{tables}

\section{Experimental Results}
\label{sec:expts_results}
In this section, we assess the performance of two uncertainty-aware LoRA adaptations---LoRA Ensemble and Bayesian LoRA---applied to LLaMA-3-8B and BioMedGPT-LM-7B models on publicly available protein-protein interaction datasets. As a baseline, we include a single LoRA model trained in a deterministic manner. All LoRA-based approaches were implemented using the PEFT library \cite{mangrulkar2022peft}, with each configuration run three times using different random seeds. We evaluate model performance and robustness by accuracy (Acc), negative log-likelihood (NLL), and expected calibration error (ECE) on the test sets. Additional details on the NLL and ECE metrics can be found in Appendix~\ref{app:uncertainty-metrics}. Furthermore, we report Matthews Correlation Coefficient
(MCC), specificity (Spec.), precision (Prec.), F1-score, and Area under Receiver Operating Characteristic curve (AUROC) over test sets for a comprehensive view of predictive capabilities. Final metrics are summarized by the mean and standard deviation across three independent runs.

\vspace{1mm}
\noindent \textbf{PPI Datasets.}
The datasets analyzed here explore PPIs related to various diseases, providing valuable insights into their underlying mechanisms. The Neurodegenerative diseases PPI (ND-PPI) dataset, sourced from the study \cite{pei2021predicting}, focuses on neurodegenerative diseases and examines a network of 820 proteins forming 11,762 interactions, evenly split between positive and negative pairs. The dataset is structured to assess whether specific protein pairs interact in the presence of neurodegenerative conditions. Similarly, the metabolic disorders PPI (M-PPI) dataset, also from \cite{pei2021predicting}, investigates metabolic disorders, encompassing 1,063 proteins and a total of 10,262 interactions. %Like ND-PPI Dataset, it employs a query format that prompts models to determine the presence of interactions in the context of metabolic dysfunction.
The cancer PPI (C-PPI) dataset, derived from the study \cite{qiu2021network}, consisted of 933 positive and 1,308 negative interactions. To ensure balanced representation, this dataset was curated to create an equal-sized collection of 1,866 total interactions. These datasets %uses a similar querying approach as the previous two, 
have been evaluated by prompting models to assess whether proteins interact in the corresponding conditions % a cancerous environment. These datasets 
and collectively contribute to advancing computational models for predicting PPIs across different disease contexts, enhancing our understanding of disease-specific interaction networks. These tasks are formalized into binary (True/False) classification problems as illustrated in Fig.~\ref{fig:workflow}. Furthermore, each dataset is divided into $80\%$ for training and $20\%$ for testing, with all models evaluated on the fixed test set in each PPI prediction task. We refer readers to \cite{engel-park-2024-evaluating}, for additional details and exploratory analyses of these datasets.

\vspace{1mm}
\noindent \textbf{Implementation Details.}
In all experiments, we construct a LoRA ensemble using three individually fine-tuned LoRA learners. The LoRA matrices $\boldB$ are initialized to zero, while the entries of $\boldA$ follow a Kaiming Uniform initialization \cite{he-2015}. Optimization is performed using the AdamW optimizer with a learning rate of \(1\times 10^{-4}\), default hyperparameters, and a total of four training epochs. The batch size is set to $4$ for the ND-PPI and M-PPI cases and $16$ for the C-PPI case, following \cite{engel-park-2024-evaluating}. For Bayesian LoRA, the prior precision \(\lambda\) is fixed at $0.1$. Lastly, LoRA is applied to the queries, values, and output layer across all methods, with specific hyperparameters set to \(r=16\), \(\alpha=32\), a dropout rate of $0.05$, and a maximum sequence length of $50$.

\vspace{1mm}
\noindent \textbf{Results.} 
The results for ND-PPI, M-PPI, and C-PPI tasks are summarized in Tables~\ref{table:nd-ppi}, \ref{table:m-ppi}, and~\ref{table:c-ppi}, respectively. 

In the ND-PPI prediction task (Table~\ref{table:nd-ppi}), we demonstrate that the LoRA ensemble achieves the highest predictive accuracy among all models in both LLM settings and has the lowest NLL in the LLaMA-3 fine-tuning case. Conversely, Bayesian LoRA demonstrates the best calibration in both scenarios, exhibiting the lowest ECE and achieving the lowest NLL in the BioMedGPT fine-tuning case. Lastly, the LoRA ensemble reports the highest values for specificity, precision, F1-score, MCC, and AUROC among all models. In the M-PPI prediction task (Table~\ref{table:m-ppi}), we show that the LoRA ensemble achieves the highest predictive accuracy and lowest NLL in both LLM scenarios, while also attaining the lowest ECE in the LLaMA-3 case. Conversely, Bayesian LoRA achieves the best calibration in the BioMedGPT case and the highest specificity in both scenarios. Finally, the LoRA ensemble outperforms all the models by achieving best precision, F1-score, MCC, and AUROC values.

In the C-PPI prediction task (Table~\ref{table:c-ppi}), we demonstrate that the LoRA ensemble once again achieves the highest predictive accuracy and lowest NLL in both settings, while also attaining the lowest ECE in the BioMedGPT scenario. Bayesian LoRA matches the best predictive accuracy in the BioMedGPT case and achieves the lowest ECE in the LLaMA-3 case. In the LLaMA-3 setting, the LoRA ensemble reports the highest values for specificity, precision, F1-score, MCC, and AUROC among all models. Additionally, it achieves the best specificity in the BioMedGPT case. Notably, both Bayesian LoRA and the LoRA ensemble attain the best precision, F1-score, and MCC values in the BioMedGPT case. Lastly, all three models yield identical AUROC values in the BioMedGPT case.

\section{Conclusion and Discussion}
In this study, we presented a novel uncertainty-aware adaptation of LLMs approach for predicting protein-protein interactions across multiple disease contexts. Leveraging fine-tuned LLaMA-3 and BioMedGPT models with LoRA ensemble and Bayesian LoRA, our approach consistently improved prediction accuracy, reliability, and robustness, as confirmed by comprehensive metrics such as negative log-likelihood and calibration error. LoRA ensembles excelled at achieving higher accuracy and reliable uncertainty estimates, while Bayesian LoRA provided well-calibrated predictions. Together, they demonstrated robustness in neurodegenerative, metabolic, and cancer-related PPI tasks. These findings underscore the benefits of incorporating principled uncertainty quantification into parameter-efficient fine-tuning for LLMs. Future work will explore more advanced LLM uncertainty quantification methods and apply this methodology to broader biomedical applications. Potential directions include elucidating disease mechanisms by predicting disrupted protein interactions and, consequently, advance computational protein target discovery for therapeutic design.


\section*{APPENDIX}
\subsection{Robustness \& Predictive Uncertainty Evaluation Metrics}
% \label{app:implementation-baselines}
\label{app:uncertainty-metrics}
To assess model robustness and predictive uncertainty, we use Negative Log-Likelihood (NLL) and Expected Calibration Error (ECE). NLL evaluates how confidently a model predicts the correct labels. Given a test dataset \(\{\boldx_i, y_i\}_{i=1}^N\), NLL is computed as:
\[
\text{NLL} = \frac{1}{N}\sum_{i=1}^{N} -\log {\rm P}_{\btheta}(y_n).
\]
A lower NLL indicates better confidence calibration, as overconfident incorrect predictions increase this value. On the other hand, ECE measures how well predicted confidence aligns with actual accuracy. Predictions are grouped into bins based on confidence, and ECE is calculated as:
\[
\text{ECE} = \sum_{m=1}^{M} \frac{|B_m|}{n} \left| \text{acc}(B_m) - \text{conf}(B_m) \right|.
\]
Here, \(\text{acc}(B_m)\) and \(\text{conf}(B_m)\) represent the average accuracy and confidence within bin \(B_m\), respectively:
\begin{equation*}
\begin{aligned}
    \text{acc}(B_m) &= \frac{1}{|B_m|} \sum_{i \in B_m} \mathbf{1}(\hat{y}_i = y_i), \\
    \quad \text{conf}(B_m) &= \frac{1}{|B_m|} \sum_{i \in B_m} P(\hat{y}_i),
\end{aligned}
\end{equation*}
where \(|B_m|\) is the number of samples in bin \(m\). Across all experiments, we set \(|B_m| = 15\).

% Appendixes should appear before the acknowledgment.

% \section*{ACKNOWLEDGMENT}

% The preferred spelling of the word "acknowledgment" in America is without an "e" after the "g". Avoid the stilted expression, "One of us (R. B. G.) thanks . . ."  Instead, try "R. B. G. thanks". Put sponsor acknowledgments in the unnumbered footnote on the first page.


% \addtolength{\textheight}{0.5cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{10}

\bibitem{Cusick2005}
Michael~E Cusick, Niels Klitgord, Marc Vidal, and David~E Hill,
\newblock ``Interactome: gateway into systems biology,''
\newblock {\em Human molecular genetics}, vol. 14, no. suppl\_2, pp. R171--R181, 2005.

\bibitem{ppis_disease}
Mileidy~W. Gonzalez and Maricel~G. Kann,
\newblock ``Chapter 4: Protein interactions and disease,''
\newblock {\em PLoS Computational Biology}, vol. 8, no. 12, pp. e1002819, 2012.

\bibitem{szklarczyk2023string}
Damian Szklarczyk, Rebecca Kirsch, Mikaela Koutrouli, Katerina Nastou, Farrokh Mehryary, Radja Hachilif, Annika~L. Gable, Tao Fang, Nadezhda~T. Doncheva, Sampo Pyysalo, et~al.,
\newblock ``The {STRING} database in 2023: protein-protein association networks and functional enrichment analyses for any sequenced genome of interest,''
\newblock {\em Nucleic Acids Research}, vol. 51, no. D1, pp. D638--D646, 2023.

\bibitem{oughtred2019biogrid}
Rose Oughtred, Chris Stark, Bobby-Joe Breitkreutz, Jennifer Rust, Lorrie Boucher, Christie Chang, Nadine Kolas, Lara O'Donnell, Genie Leung, Rochelle McAdam, et~al.,
\newblock ``The {BioGRID} interaction database: 2019 update,''
\newblock {\em Nucleic Acids Research}, vol. 47, no. D1, pp. D529--D541, 2019.

\bibitem{orchard2014intact}
Sandra Orchard, Mais Ammari, Bruno Aranda, Lionel Breuza, Leonardo Briganti, Fiona Broackes-Carter, Nancy~H. Campbell, Gayatri Chavali, Carol Chen, Noemi del Toro, et~al.,
\newblock ``The {MIntAct} project--intact as a common curation platform for 11 molecular interaction databases,''
\newblock {\em Nucleic Acids Research}, vol. 42, no. D1, pp. D358--D363, 2014.

\bibitem{weigt2009messagepassing}
Martin Weigt, Robert~A White, Hendrik Szurmant, James~A Hoch, and Terence Hwa,
\newblock ``Identification of direct residue contacts in proteinâ€“protein interaction by message passing,''
\newblock {\em Proceedings of the National Academy of Sciences}, vol. 106, no. 1, pp. 67--72, 2009.

\bibitem{sanchezgarcia2019bipspi}
Ruben Sanchez-Garcia, C.O.S. Sorzano, J.~M. Carazo, and Joan Segura,
\newblock ``{BIPSPI}: A method for the prediction of partner-specific protein-protein interfaces,''
\newblock {\em Bioinformatics}, vol. 35, no. 3, pp. 470--477, 2019.

\bibitem{chopra2020cornea}
Kriti Chopra, Bhawna Burdak, Kaushal Sharma, Ajit Kembhavi, Shekhar~C. Mande, and Radha Chauhan,
\newblock ``Cornea: A pipeline to decrypt the inter-protein interfaces from amino acid sequence information,''
\newblock {\em Biomolecules}, vol. 10, no. 6, pp. 938, 2020.

\bibitem{kewalramani2023state}
Neel Kewalramani, Andrew Emili, and Mark Crovella,
\newblock ``State-of-the-art computational methods to predict protein--protein interactions with high accuracy and coverage,''
\newblock {\em Proteomics}, vol. 23, no. 1-2, pp. e2200292, 2023.

\bibitem{soleymani2022ppi}
Farzaneh Soleymani, Eric Paquet, Herna Viktor, Wojtek Michalowski, and Davide Spinello,
\newblock ``Protein-protein interaction prediction with deep learning: A comprehensive review,''
\newblock {\em Computational and Structural Biotechnology Journal}, vol. 20, pp. 5316--5341, 2022.

\bibitem{shorinwa2024surveyuncertaintyquantificationlarge}
Ola Shorinwa, Zhiting Mei, Justin Lidard, Allen~Z Ren, and Anirudha Majumdar,
\newblock ``A survey on uncertainty quantification of large language models: Taxonomy, open research challenges, and future directions,''
\newblock {\em arXiv:2412.05563}, 2024.

\bibitem{minaee2024largelanguagemodelssurvey}
Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao,
\newblock ``Large language models: A survey,''
\newblock {\em arXiv:2402.06196}, 2024.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever,
\newblock ``Language models are unsupervised multitask learners,''
\newblock {\em OpenAI}, 2019.

\bibitem{brown2020languagemodelsfewshotlearners}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.,
\newblock ``Language models are few-shot learners,''
\newblock in {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{openai2024gpt4technicalreport}
OpenAI et~al.,
\newblock ``{GPT-4} technical report,''
\newblock {\em arXiv:2303.08774}, 2023.

\bibitem{touvron2023llama2openfoundation}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.,
\newblock ``Llama 2: Open foundation and fine-tuned chat models,''
\newblock {\em arXiv:2307.09288}, 2023.

\bibitem{grattafiori2024llama3herdmodels}
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et~al.,
\newblock ``The llama 3 herd of models,''
\newblock {\em arXiv:2407.21783}, 2024.

\bibitem{Cui2024}
Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo~Wang,
\newblock ``scgpt: toward building a foundation model for single-cell multi-omics using generative ai,''
\newblock {\em Nature Methods}, pp. 1--11, 2024.

\bibitem{luo2022biogpt}
Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu,
\newblock ``{BioGPT}: Generative pre-trained transformer for biomedical text generation and mining,''
\newblock {\em Briefings in Bioinformatics}, vol. 23, no. 6, pp. bbac409, 2022.

\bibitem{Singhal2023-zh}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S~Sara Mahdavi, Jason Wei, Hyung~Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et~al.,
\newblock ``Large language models encode clinical knowledge,''
\newblock {\em Nature}, vol. 620, no. 7972, pp. 172--180, 2023.

\bibitem{yang2022gatortronlargeclinicallanguage}
Xi~Yang, Aokun Chen, Nima PourNejatian, Hoo~Chang Shin, Kaleb~E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Mona~G Flores, Ying Zhang, et~al.,
\newblock ``Gatortron: A large clinical language model to unlock patient information from unstructured electronic health records,''
\newblock {\em arXiv:2203.03540}, 2022.

\bibitem{bran2023chemcrowaugmentinglargelanguagemodels}
Andres~M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew~D White, and Philippe Schwaller,
\newblock ``{ChemCrow}: Augmenting large-language models with chemistry tools,''
\newblock {\em arXiv:2304.05376}, 2023.

\bibitem{taylor2022galacticalargelanguagemodel}
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic,
\newblock ``Galactica: A large language model for science,''
\newblock {\em arXiv:2211.09085}, 2022.

\bibitem{yang2023fingptopensourcefinanciallarge}
Hongyang Yang, Xiao-Yang Liu, and Christina~Dan Wang,
\newblock ``{FinGPT}: Open-source financial large language models,''
\newblock {\em arXiv:2306.06031}, 2023.

\bibitem{wu2023bloomberggptlargelanguagemodel}
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann,
\newblock ``{BloombergGPT}: A large language model for finance,''
\newblock {\em arXiv:2303.17564}, 2023.

\bibitem{thulke2024climategptaisynthesizinginterdisciplinary}
David Thulke, Yingbo Gao, Petrus Pelser, Rein Brune, Rricha Jalota, Floris Fok, Michael Ramos, Ian van Wyk, Abdallah Nasir, Hayden Goldstein, et~al.,
\newblock ``{ClimateGPT}: Towards ai synthesizing interdisciplinary research on climate change,''
\newblock {\em arXiv:2401.09646}, 2024.

\bibitem{chen2021evaluatinglargelanguagemodels}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.,
\newblock ``Evaluating large language models trained on code,''
\newblock {\em arXiv:2107.03374}, 2021.

\bibitem{brandes2022proteinbert}
Nadav Brandes, Dan Ofer, Yam Peleg, Nadav Rappoport, and Michal Linial,
\newblock ``{ProteinBERT}: a universal deep-learning model of protein sequence and function,''
\newblock {\em Bioinformatics}, vol. 38, no. 8, pp. 2102--2110, 2022.

\bibitem{hayes2025esm3}
Thomas Hayes, Roshan Rao, Halil Akin, Nicholas~J. Sofroniew, Deniz Oktay, Zeming Lin, Robert Verkuil, Vincent~Q. Tran, Jonathan Deaton, Marius Wiggert, et~al.,
\newblock ``Simulating 500 million years of evolution with a language model,''
\newblock {\em Science}, 2025.

\bibitem{luo2023biomedgpt}
Yizhen Luo, Jiahuan Zhang, Siqi Fan, Kai Yang, Yushuai Wu, Mu~Qiao, and Zaiqing Nie,
\newblock ``{BioMedGPT}: Open multimodal generative pre-trained transformer for biomedicine,''
\newblock {\em arXiv:2308.09442}, 2023.

\bibitem{engel-park-2024-evaluating}
Ryan Engel and Gilchan Park,
\newblock ``Evaluating large language models for predicting protein behavior under radiation exposure and disease conditions,''
\newblock in {\em Proceedings of the 23rd Workshop on Biomedical Natural Language Processing}, 2024, pp. 427--439.

\bibitem{li2024thinktwicetrustingselfdetection}
Moxin Li, Wenjie Wang, Fuli Feng, Fengbin Zhu, Qifan Wang, and Tat-Seng Chua,
\newblock ``Think twice before trusting: Self-detection for large language models through comprehensive answer reflection,''
\newblock in {\em Findings of the Association for Computational Linguistics: EMNLP 2024}, 2024.

\bibitem{xiong2024llmsexpressuncertaintyempirical}
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi,
\newblock ``Can {LLMs} express their uncertainty? an empirical evaluation of confidence elicitation in {LLMs},''
\newblock {\em arXiv:2306.13063}, 2023.

\bibitem{leng2024tamingoverconfidencellmsreward}
Jixuan Leng, Chengsong Huang, Banghua Zhu, and Jiaxin Huang,
\newblock ``Taming overconfidence in {LLMs}: Reward calibration in {RLHF},''
\newblock {\em arXiv:2410.09724}, 2024.

\bibitem{he2023preservingpretrainedfeatureshelps}
Guande He, Jianfei Chen, and Jun Zhu,
\newblock ``Preserving pre-trained features helps calibrate fine-tuned language models,''
\newblock {\em arXiv:2305.19249}, 2023.

\bibitem{Neal-1996}
R.~M. Neal,
\newblock {\em {Bayesian} Learning for Neural Networks},
\newblock New York: Springer Verlag, 1996.

\bibitem{Izmailov-et-al-2021}
Pavel Izmailov, Sharad Vikram, Matthew~D Hoffman, and Andrew Gordon~Gordon Wilson,
\newblock ``What are {Bayesian} neural network posteriors really like?,''
\newblock in {\em International Conference on Machine Learning (ICML)}, 2021.

\bibitem{blundell2015weightuncertaintyneuralnetworks}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra,
\newblock ``Weight uncertainty in neural network,''
\newblock in {\em International Conference on Machine Learning (ICML)}, 2015.

\bibitem{jantre2023layer}
Sanket Jantre, Shrijita Bhattacharya, and Tapabrata Maiti,
\newblock ``Layer adaptive node selection in {Bayesian} neural networks: Statistical guarantees and implementation details,''
\newblock {\em Neural Networks}, vol. 167, pp. 309--330, 2023.

\bibitem{jantre2023shrinkage}
Sanket Jantre, Shrijita Bhattacharya, and Tapabrata Maiti,
\newblock ``Spike-and-slab shrinkage priors for structurally sparse {Bayesian} neural networks,''
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 2024.

\bibitem{jantre2024active}
Sanket Jantre, Nathan~M Urban, Xiaoning Qian, and Byung-Jun Yoon,
\newblock ``Learning active subspaces for effective and scalable uncertainty quantification in deep neural networks,''
\newblock in {\em IEEE International Conference on Acoustics, Speech and Signal Processing}, 2024.

\bibitem{lakshminarayanan2017simplescalablepredictiveuncertainty}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell,
\newblock ``Simple and scalable predictive uncertainty estimation using deep ensembles,''
\newblock in {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem{maddox2019simple}
Wesley~J Maddox, Pavel Izmailov, Timur Garipov, Dmitry~P Vetrov, and Andrew~Gordon Wilson,
\newblock ``A simple baseline for {Bayesian} uncertainty in deep learning,''
\newblock in {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem{jantre2022sequential}
Sanket Jantre, Shrijita Bhattacharya, Nathan~M Urban, Byung-Jun Yoon, Tapabrata Maiti, Prasanna Balaprakash, and Sandeep Madireddy,
\newblock ``Sequential {Bayesian} neural subnetwork ensembles,''
\newblock {\em arXiv:2206.00794}, 2022.

\bibitem{hu2021loralowrankadaptationlarge}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen,
\newblock ``Lo{RA}: Low-rank adaptation of large language models,''
\newblock in {\em International Conference on Learning Representations (ICLR)}, 2022.

\bibitem{yang2024bayesianlowrankadaptationlarge}
Adam~X. Yang, Maxime Robeyns, Xi~Wang, and Laurence Aitchison,
\newblock ``{Bayesian} low-rank adaptation for large language models,''
\newblock in {\em International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{wang2024blobbayesianlowrankadaptation}
Yibin Wang, Haizhou Shi, Ligong Han, Dimitris~N. Metaxas, and Hao Wang,
\newblock ``{BLoB: Bayesian} low-rank adaptation by backpropagation for large language models,''
\newblock in {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2024.

\bibitem{meo2024bloragates}
Cristian Meo, Ksenia Sycheva, Anirudh Goyal, and Justin Dauwels,
\newblock ``{Bayesian-LoRA: LoRA} based parameter efficient fine-tuning using optimal quantization levels and rank values trough differentiable {Bayesian} gates,''
\newblock in {\em 2nd Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization (WANT@ICML 2024)}, 2024.

\bibitem{onal2024gaussian}
Emre Onal, Klemens Fl{\"o}ge, Emma Caldwell, Arsen Sheverdin, and Vincent Fortuin,
\newblock ``Gaussian stochastic weight averaging for {Bayesian} low-rank adaptation of large language models,''
\newblock in {\em 6th Symposium on Advances in Approximate Bayesian Inference - Non Archival Track}, 2024.

\bibitem{wang2023loraensembleslargelanguage}
Xi~Wang, Laurence Aitchison, and Maja Rudolph,
\newblock ``{LoRA} ensembles for large language model fine-tuning,''
\newblock {\em arXiv:2310.00035}, 2023.

\bibitem{balabanov2024uncertainty}
Oleksandr Balabanov and Hampus Linander,
\newblock ``Uncertainty quantification in fine-tuned {LLMs} using {LoRA} ensembles,''
\newblock {\em arXiv:2402.12264}, 2024.

\bibitem{daxberger2021laplace}
Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig,
\newblock ``Laplace redux-effortless {Bayesian} deep learning,''
\newblock in {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{antoran2022adapting}
Javier Antor{\'a}n, David Janz, James~U Allingham, Erik Daxberger, Riccardo~Rb Barbano, Eric Nalisnick, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato,
\newblock ``Adapting the linearised laplace model evidence for modern deep learning,''
\newblock in {\em International Conference on Machine Learning (ICML)}, 2022.

\bibitem{mangrulkar2022peft}
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and B~Bossan,
\newblock ``Peft: State-of-the-art parameter-efficient fine-tuning methods,''
\newblock {\em URL: https://github. com/huggingface/peft}, 2022.

\bibitem{pei2021predicting}
Fen Pei, Qingya Shi, Haotian Zhang, and Ivet Bahar,
\newblock ``Predicting protein--protein interactions using symmetric logistic matrix factorization,''
\newblock {\em Journal of chemical information and modeling}, vol. 61, no. 4, pp. 1670--1682, 2021.

\bibitem{qiu2021network}
Jiajun Qiu, Kui Chen, Chunlong Zhong, Sihao Zhu, and Xiao Ma,
\newblock ``Network-based protein-protein interaction prediction method maps perturbations of cancer interactome,''
\newblock {\em PLoS genetics}, vol. 17, no. 11, pp. e1009869, 2021.

\bibitem{he-2015}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun,
\newblock ``Delving deep into rectifiers: Surpassing human-level performance on imagenet classification,''
\newblock in {\em Proceedings of the IEEE International Conference on Computer Vision (ICCV)}, 2015.

\end{thebibliography}

\end{document}