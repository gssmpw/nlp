\section{Related Works}
The cognitive characteristics of achieving adversarial learning through classification and comparison are not rare in nature, such as in primates \citep{firestone2020performance}, cetaceans \citep{connor2006social}, and humans\citep{firestone2020performance}. With the significant progress made by Wang in introducing adversarial learning into the field of computer science \citep{wang2017generative}, there has now been a wealth of exploratory practices in research on adversarial sample learning. In the area of computer vision, adversarial learning has primarily been used to enhance model robustness against adversarial attacks. For instance, Goyal introduced adversarial training as a defense mechanism, where models are trained on adversarial examples to improve their robustness \citep{goyal2023survey}. Meanwhile, Goyalâ€™s framework has been extended to improve generative tasks, such as image synthesis and style transfer, leveraging frameworks like Generative Adversarial Networks (GANs) \citep{goodfellow2020generative}. For example, Su demonstrated the utility of adversarial examples in domain adaptation tasks \citep{su2020active}, and the result indicates that such method enables models to generalize better across diverse datasets. Adversarial learning has also been widely adopted in natural language processing (NLP) tasks. For example, Zhang explored adversarial attacks to reveal vulnerabilities in text classification models and achieved great performance \citep{zhang2020adversarial}. Beyond attacks, adversarial learning has been employed to improve the generalization and robustness of NLP models. For instance, adversarial data augmentation has been utilized to train models that are less sensitive to noise in input text. Moreover, adversarial robust methods have been developed to mitigate biases in text generation and sentiment analysis tasks, as Textbugger proposed by Li et al. had demonstrated great performance on text generation tasks.

With the widespread application of Large Language Models (LLMs), some studies have indicated that LLMs possess the potential to pass the Turing Test \citep{sejnowski2023large}. Even more optimistically, certain research suggests that LLMs have, to a certain extent, already passed the Turing Test \citep{sejnowski2023large}. However, the current cognitive level of LLMs still lags significantly behind that of humans and has considerable room for improvement. Therefore, many studies explore the differences between AI and humans, hoping to conduct comparative research through these differences to promote the development of AI \citep{djeffal2022role}. Existing studies have sought to compare AI and human information processing from a cognitive science perspective and obtain valuable insights. For instance, recent work has focused on the discrepancies between LLMs and humans in reasoning tasks, particularly in commonsense reasoning and contextual understanding. These studies often design adversarial datasets or specific cognitive tasks to evaluate the logical consistency and generalization capabilities of LLMs \citep{ying2023intuitive, gu2024survey}. Such comparative research not only highlights the weaknesses of AI models but also offers guidance for their optimization \citep{surianarayanan2023survey}. Second, some research efforts have drawn inspiration from human learning mechanisms to enhance AI models. Techniques like meta-learning and analogy-based reasoning have been applied to improve the performance of LLMs in few-shot learning tasks \citep{yuan2023analogykb}. Humans' ability to reason by analogy has inspired researchers to integrate this cognitive trait into LLMs, significantly boosting their performance in low-resource or unfamiliar domains \citep{guo2024teaching}. Additionally, other work has focused on addressing the differences between AI and humans in handling ambiguity and uncertainty, leading to the development of more robust model architectures \citep{chander2024toward}. Overall, these works demonstrate that leveraging insights from the differences between AI and humans can not only drive the advancement of AI models but also enhance their value in real-world applications. This research builds upon this foundation by introducing a bidirectional improvement mechanism inspired by generative adversarial networks (GANs), simulating ``mutual learning" between AI and humans to optimize the generation capabilities of the model.