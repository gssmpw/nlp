\section{Introduction}

Solving multiple-query or forecasting problems, often requires to solve multiple parametric partial differential equations quickly and reliably. Unfortunately, numerical approximations are often either too expensive or not accurate enough. At this point, the development of surrogate models that are fast and reliable becomes necessary. Reduced basis methods are suitable surrogate models, where the original high-dimensional problem is replaced by a low-rank approximation. These methods consist of two stages: an offline part, where we construct a reduced basis from a collection of `high-fidelity' solutions at selected sample points, and an online part, where we solve the low-dimensional problem defined as the projection of the original equation onto the subspace spanned by this reduced basis.

Reduced bases for time-dependent problems are usually constructed using a standard \gls{pod} \cite{Hesthaven2022,schleus_randomized_2022,baurChapterComparisonMethods2017}, which allows for a detailed data sampling. In problems where the solution can evolve without a clear pattern or at least without one that we can easily predict, we may need to sample data at a high frequency and over a long time window to be able to construct an appropriate reduced basis. If we also consider any other additional parametrization (for example physical or geometrical parameters), we may face issues sampling the data for large problems as they can become prohibitively expensive and time consuming. 

For general parametrised problems, a substantial body of work applies a Greedy sampling technique \cite{bui-thanh_model_2008,buffa_priori_2012,devore_greedy_2013}, which decreases the computational burden of sampling. Although this is ideal for most parametric problems, the evolution behavior of a time-dependent problem does not allows us to follow a random sampling in most cases. Therefore, when we deal with parametrised time-dependent problems it is common to find techniques that have a mix of both methods: a Greedy approach to select the sample set in the parameter space, and either an impulse response \cite{lall_subspace_2002,grepl_posteriori_2005,haasdonk_reduced_2008}, or a regular interval sampling \cite{rovas_reduced-basis_2006,nguyen_reduced_2009,grepl_certified_2012,guo_data-driven_2019,baurChapterComparisonMethods2017} in the time-domain. Although any of these approaches can give accurate results with a good enough sampling, we still face the same problem, a big computational cost for large problems. Thus, for real-world applications with computational and time constraints it is not always possible to construct an affordable and accurate reduced basis by following a traditional reduced-basis method.\footnote{In \cite{schleus_randomized_2022} Schleus√ü et al. take an original approach to basis generation of the time-dependent problem, where rather than sampling over the global solution, the method captures a general behaviour of the problem by sampling randomly drawn starting points with random initial conditions in parallel.}\footnote{It is worth noting the work in space-time approximations where the method aims to construct a reduced basis to project the entire space-time system, rather than solving a low-dimensional system for each time step \cite{yano_space-time_2014,Choi2017}}

An alternative approach to create a reduced model %used in signal processing and control theory% where the problem is written as an input-output linear time-invariant system (modal truncation and transfer function interpolation),
consists in finding a surrogate for the transfer function in the frequency domain \cite{huynh_laplace_2011,Bigoni2020a,Bhouri2020,baurChapterComparisonMethods2017}. In this approach, mostly used in signal processing and control problems, the problem is written as an input-output linear time-invariant system, with a clearly defined transfer function. Then by using the Laplace transform we can convert the problem from the time domain to the frequency domain, find a surrogate for the transfer function and bring it back to the time domain using and inverse transform. (In this case it would be necessary to review some inverse Laplace transform methods \cite{kuhlman_review_2013}.) The major issue with this approach is how difficult and costly can be to compute the numerical approximation of the inverse Laplace transform, which may be problem dependent and sometimes unattainable in practice.

We propose a method that integrates some of the ideas of these two groups of methods. First, we use the Laplace transform to transform the time-dependent problem into a frequency-domain problem. Then, we construct the reduced basis using a standard  \gls{pod} in a method that resembles the one used to solve frequency-domain problems \cite{huynh_laplace_2011,peng_symplectic_2015} with a key difference: Instead of sampling in the half-complex plane, we sample a set of discrete frequencies over complex-valued functions in the unit circle. And finally, instead of solving a frequency-domain reduced order problem and approximating the inverse Laplace transform, we use the obtained reduced basis to solve the time-dependent problem.

We intend to explain why this method works using some elements of harmonic analysis. We start by defining the approximation spaces for each problem and the equivalence between their norms: a $L^2$ Hilbert space for the time-domain problem and a $H^2$ Hardy space for the frequency-domain problem. Then we map the frequency-domain problem, set in the complex half-plane, onto the unit circle. And lastly, we justify why we only use the real part of the solution as data input using the properties of analytic functions. 

We validate the method using a few simple examples. A heat equation and a wave equation, where we evaluate the method. And a linear elasticity problem, where we showcase the accuracy and performance of the method. 

\subsection*{Outline}
The paper is organized as follows: In \cref{sec:Problem} we describe a general time-dependent problem, in \cref{sec:Analysis} we follow some elements of harmonic analysis needed to explain the method, in \cref{sec:Examples} we solve numerical examples to test the new method, and in \cref{sec:Summary} we close with a summary of the findings.