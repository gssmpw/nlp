\section{Literature Review}
\label{litreview}

Studies have been conducted on applying Automatic Speech Recognition (ASR) on Air Traffic Control (ATC) communications, as well as ASR on accented speech. However, few studies focus on the combined problem of accented speech, within the domain of ATC. The literature review of existing datasets, proposed models, and projects is below.
%-------------------------------------------------------------------------------------------------------------------------
% Available Public Datasets
%-------------------------------------------------------------------------------------------------------------------------
\subsection{Public ATC Speech Datasets}

Many research projects have collected ATC speech datasets that are used in research today. The prominent ATC Speech datasets that are commonly used in research and their featured languages and accents are depicted in Table \ref{table:1} \cite{Wang2024EnhancingAT}. 

\begin{table}[htbp]
\centering
\caption{Public ATC Transcription Datasets Available}

\begin{threeparttable}
\begin{tabular}{|l|c|p{0.5\linewidth}|}
    \hline
    \textbf{Dataset Name} & \textbf{Data Size} & \textbf{Language and Accent} \\
    \hline
    LDC94S14A~\cite{LDC94S14A} & 72.5h & US English\\
    \hline
    N4 NATO & 72.5h & Canadian, German, Dutch and British-accented English\\
    \hline
    HIWIRE~\cite{segura2007hiwire} & 28.3h & French, Greek, Italian and Spanish-accented English \\
    \hline
    Madrid Airport & 11.8h & Spanish, English \\
    \hline
    Madrid ACC & 100h & Spanish, English \\
    \hline
    ATCOSIM~\cite{hofbauer2008atcosim} & 10.7h & German, Swiss, and French accented English \\
    \hline
    AcListant & 8h & German and Czech-accented English \\
    \hline
    DataComm & 120h & US English \\
    \hline
    ATCSC & 4800u* & English \\
    \hline
    AIRBUS-ATC & 59h & French-accented English \\
    \hline
    MALORCA & 10.9h & German and Czech-accented English \\
    \hline
    UWB-ATCC & 179h & Czech-accented English\\
    \hline
    SOL-Twr & 1993u* & Lithuanian-accented English \\
    \hline
    SOL-Cnt & 800u* & German-accented English \\
    \hline
    HAAWAII & 34h & Icelandic and British-accented English \\
    \hline
    ATCO$^2$~\cite{zuluaga2023atco2} & 5285h & English \\
    \hline
    ATCSpeech~\cite{yang2019atcspeech} & 58h & Mandarin Chinese, English \\
    \hline
\end{tabular}
\begin{tablenotes}
\item *utterances
\end{tablenotes}
\end{threeparttable}
\label{table:1}
\end{table}

% https://www.semanticscholar.org/reader/c38b2029f5aa484accc5feeeda3658dbe9d3cc41 refer to this

Notable corpora include ATCOSIM\cite{hofbauer-etal-2008-atcosim}, the first publicly available civil aviation ATC corpus, featuring 10 hours of utterances by non-native English speakers recorded in simulated environments. The AcListant project\cite{rataj2019aclistant} created a dataset with recordings from three European controllers using ICAO-standardized phraseologies. Similarly, the AIRBUS-ATC\cite{pellegrini2018airbus} corpus targets non-native speech and poor audio quality, often serving as a benchmark in ASR research.

The MALORCA project\footnote{\url{https://www.malorca-project.de/}} provided high-quality datasets with semi-supervised learning methods for unlabeled data, while UWB-ATCC\cite{smidl2019ATCC} offers annotated ATC recordings from Czech airspace. The SOL-Twr and SOL-Cnt datasets from SESAR projects\cite{Wang2024EnhancingAT} capture communications in Lithuanian and Viennese airspaces. The HAAWAII project\cite{helmke2023haawaii} includes 19 hours of annotated London approach data and 15 hours of Icelandic en-route communications.

The ATCO2 project\cite{zuluaga2023atco2} constructed the largest ATC corpus to date, with over 5281 hours of automatically transcribed recordings from 10 international airports. Meanwhile, ATCSpeech\cite{yang2019atcspeech} is notable for including accented Mandarin Chinese and English utterances, tailored for multilingual ATC communications. Finally, LiveATC, an online platform, provides an extensive archive of real-time ATC recordings, which can be manually transcribed or processed with semi-supervised methods.

The corpora above mainly feature Western languages and Western-accented English as their training data. Because studies have shown that \emph{Whisper}-based ASR models are unable to effectively generalize to new accents absent from their training data \cite{Pan2024AssessmentAA}, the lack of Southeast Asian-accented (SEA-accented) English means that current ATC models available that are trained on them will not perform as well on SEA-accented English. This is also reflected in our model tests in Table \ref{table:werresults}.

The implications of the lack of accent representation mean that current models trained on these datasets may not be suitable for military organizations coming from countries that do not speak western-accented English.

\subsection{ASR Metrics}
% \textcolor{red}{yz: wer is nice to see and use but no reference} \\
Word error rate (WER) is a commonly used metric in model selection and to benchmark ASR model performance \cite{Kheddar2023DeepTL}. This metric is used in most of the papers \cite{Zuluaga2023LessonsLI, Wang2024EnhancingAT, Ahrenhold2023ValidatingAS, Iwamoto2022HowBA, Prabhu2023AccentedSR,li2021accent,Deng2021ImprovingAI, jahchan2021towards, Jelassi2024RevolutionizingRA, Graham2024EvaluatingOW, Sanabria2023TheEI, pan2024assessment, han2021supervised, aksenova2022AccentedSR, Maison2023ImprovingAS}, and also used by \emph{Whisper} \cite{RadfordWhisper2022}. In our subsequent evaluation and tests conducted, Combined WER is used, calculating the WER from the combined predicted transcriptions and ground truths across the entire dataset. The formula for Combined WER used is as such:

\begin{equation*}
    \text{Combined WER} = \frac{S + D + I}{N}
\end{equation*}

where:
\begin{itemize}
    \item \( S \) = Total number of substitutions (words incorrectly replaced by other words),
    \item \( D \) = Total number of deletions (words missing in the recognized output),
    \item \( I \) = Total number of insertions (extra words added in the recognized output),
    \item \( N \) = Total number of words in the reference (ground truth).
\end{itemize}

%-------------------------------------------------------------------------------------------------------------------------
% Public ATC Speech Transcription Models
%-------------------------------------------------------------------------------------------------------------------------
\subsection{ATC Speech Recognition}
% Radio Noise
ASR speech transcription models perform to high degrees of accuracy in benchmarks for state-of-the-art speech datasets\footnote{\url{https://paperswithcode.com/sota/automatic-speech-recognition-on-lrs2}}. Studies show that ASR models still struggle to transcribe ATC speech due to the presence of large amounts of noise and high speech rates \cite{Lin2021SpokenIU,Zuluaga2023LessonsLI} as well as ATC-specific language ontologies \cite{Ahrenhold2023ValidatingAS}. 

\subsubsection{ATC Speech Rate} Air Traffic Controllers (ATCOs) have to relay information to each other quickly due to the high-speed nature of air traffic, which reduces the intelligibility of spoken utterances, causing ASR models trained on regular speech to be unable to transcribe effectively ~\cite{Wang2024EnhancingAT}.

\subsubsection{Radio Noise} The ATC environment is characterized by complex background noise, including environmental noise, device noise, radio transmission noise, and speech echo \cite{Yu2023ROSEAR}. The speech echo, in particular, is a specific overlapping phenomenon generated by the ATC communication between the sent and received ATCO speech. Another component of noise, radio transmission noise, is the result of ATC being transmitted over High Frequency (HF), Very High Frequency (VHF) or Ultra High Frequency (UHF) bandwidths that are susceptible to noise caused by static, radio frequency interference, or thermal noise \cite{Lin2021SpokenIU}. Auditory information is encoded using amplitude modulation (AM) because it is less susceptible to the capture effect than frequency modulation (FM)~\cite{zeek1949investigation}. However, AM signals are also less robust against noise and interference, which has been shown to degrade the performance of ASR models~\cite{fritz2024analyzing}.

Due to the complex amalgamation of noises, ATC speech often sounds muffled and unintelligible with a low signal-to-noise ratio (SNR). This poses a problem to ASR systems as the noise will either have to be learned by the ASR model or removed through de-noising measures in pre-processing. However, studies have also shown that the use of de-noisers and enhancers could potentially also result in degraded performance in ASR models, making ASR transcription a tricky problem to address \cite{Iwamoto2022HowBA}.

\subsubsection{ATC-Specific Language Ontologies}

ATC Communications has many region-specific phraseologies and language ontologies~\cite{Chen2023EffectsOL,Ahrenhold2023ValidatingAS}. ATC-specific vocabulary could include landmark names, callsigns, and keywords that ATCOs use to refer to protocols and flight actions. 

Studies have shown that \emph{Whisper} Models~\cite{radford2023robust} far outperform other ASR models in robustness towards transcribing domain-specific terminologies from diverse speech recognition contexts, seen in healthcare radiology transcription~\cite{Jelassi2024RevolutionizingRA}. Hence, we selected \emph{Whisper} as our candidate model for research.

\subsubsection{Available Whisper Models}

Before \emph{Whisper}, many ASR models were researched in the ATC field with varying degrees of accuracy. Most notably, Convolutional Neural Networks chained with factorized Time Delayed Neural Networks (CNN-TDNNF) were shown to perform well, achieving approximately 5.0\% WER for the ATCOSim dataset.

Subsequently, with the introduction of \emph{Whisper}, the Huggingface platform\footnote{\url{https://huggingface.co/}} has featured many community-trained \emph{Whisper} models for ATC data. Most notably, the \emph{Whisper-ATC}~\cite{jlvdoorn2024WhisperATC} project fine-tuned \emph{Whisper} ASR models for Western-accented ATC datasets and achieved significant results. \emph{Whisper-ATC} fine-tuned \emph{Whisper} models on ATCO2 and ATCOSim, beating the prior model with only 1.19\% WER on the ATCOSim dataset. 

%-------------------------------------------------------------------------------------------------------------------------
% Accented ATC
%-------------------------------------------------------------------------------------------------------------------------
\subsection{Study on Accents in ATC ASR}

\subsubsection{Accent Analysis in ASR}
Although studies show that accents affect the performance of ASR models due to the variations in pronunciation, intonation, and speech patterns \cite{Prabhu2023AccentedSR,Graham2024EvaluatingOW}, the impact of accents is less researched in the domain of ATC speech transcription.

Traditional analysis of accents shows that accents are complex as every individual has a unique accent, making it difficult to classify ~\cite{Sanabria2023TheEI}. Despite the difficulties in accent classification, studies show that people in the same geographical region usually share common accent features while having different accents \cite{Xie2024FromFE}. 

The main study conducted on the impact of accents on ATC transcriptions is a performance survey on how pre-trained models, such as \emph{Whisper} and other architectures, inferred on different accents of ATC Speech data causes transcription accuracy differences of up to 26.37\%~\cite{pan2024assessment}. Studies on how models fine-tuned to transcribe certain accents of ATC perform on other accents have yet to be explored.

This is relevant to military organizations because studies have shown that military organizations internally share accent features and speech styles that are reflective of their unique cultural and historical contexts \cite{Romanov2021TheUM}. This could pose further issues in the domain of accent-specific ATC speech transcription.

\subsubsection{Accent Fine-Tuning}

Accent variability remains a significant challenge in ASR systems, especially for non-Air Traffic Control (ATC) accented speech. Various approaches have been explored to enhance ASR performance under such conditions. These include accent-aware techniques~\cite{Prabhu2023AccentedSR,li2021accent}, accent-agnostic methods~\cite{sun2018domain,han2021supervised}, and accent adaptation using both supervised and unsupervised strategies~\cite{Deng2021ImprovingAI,Prabhu2023AccentedSR}. 

For ATC ASR, Airbus proposed a HMM-TDNN-based accent-agnostic approach~\cite{jahchan2021towards}. However, this method exhibited catastrophic forgetting, as the Word Error Rate (WER) for previously seen accents increased when fine-tuning the model with Chinese-accented data.

A promising solution for accent-specific fine-tuning involves constructing datasets with sufficient accent representation. Such datasets have demonstrated the potential to significantly improve ASR performance, even when using limited real accented data during supervised fine-tuning~\cite{aksenova2022AccentedSR}. Additionally, region-specific fine-tuning for accent adaptation in general speech has shown notable improvements in accuracy for targeted accents~\cite{Maison2023ImprovingAS}.

Building upon these findings, we hypothesize that combining region-specific fine-tuning with robust accent representation in the training data can effectively mitigate the challenges of accent variability, particularly in ATC ASR contexts.


% https://www.semanticscholar.org/paper/Global-Performance-Disparities-Between-Accents-in-DiChristofano-Shuster/e4cd09e554794cc3db5a7104abf0879ad1cbf0d9

% another interesting thing to note is that in the above study, they found that including the Chinese-accented data in the train set actually worsened the model's performance on all other accents
%-------------------------------------------------------------------------------------------------------------------------
% Military Limitations
%-------------------------------------------------------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESEARCH OBJECTIVES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The overarching goal of this project is to establish a framework for building reliable, accent-specific ASR systems that balance accuracy, efficiency, and scalability for specialized domains such as military ATC communications.

% Military Security + Potential Limitations
% \subsection{Military Limitations}
% The Speed-Accuracy Trade-off is widely accepted in machine learning, where accuracy and trained model performance correlate positively with model size and slower inference and training speeds \cite{ivanov_speed_nodate} \cite{Villalobos2022MachineLM}. This holds true in ASR, where models like \emph{Whisper} have also demonstrated better performance using larger-sized versions of the model \cite{Li2024SONARAS}. This gives rise to increasing requirements for technology, finances, and expertise to train and deploy effective models in ATC Speech Transcription.

% However, larger models may not be easy to implement reliably for cloud deployment \cite{Abel2021DeploymentOI} or on Internet-of-Things (IoT) devices which may be limited by hardware \cite{HS2024HybridAU}. Large amounts of processing power, storage capacity, and energy are required to store and run inference on larger models, which may render larger models unfeasible for deployment \cite{Rashid2023ArtificialII}.

% Furthermore, significant amounts of data are required to create datasets for machine learning models, which may not be available in compliance with the security rules and limitations \cite{Rashid2023ArtificialII}. Concerns over data quality, regulatory constraints, and risk raise the difficulty in acquiring ATC data. As such, military organizations may have to look towards open-source alternatives that are similar to ATC speech to train ATC speech transcription models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% METHODOLOGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%